0,1,label2,summary_sentences
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3622–3631 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
3622",text,[0],[0]
"Despite the massive success brought by neural machine translation (NMT, Sutskever et al., 2014; Bahdanau et al., 2015; Vaswani et al., 2017), it has been noticed that the vanilla NMT often lags behind conventional machine translation systems, such as statistical phrase-based translation systems (PBMT, Koehn et al., 2003), for low-resource language pairs (see, e.g., Koehn and Knowles, 2017).",1 Introduction,[0],[0]
"In the past few years, various approaches have been proposed to address this issue.",1 Introduction,[0],[0]
"The first attempts at tackling this problem exploited the availability of monolingual corpora (Gulcehre
* Equal contribution.
",1 Introduction,[0],[0]
"et al., 2015; Sennrich et al., 2015; Zhang and Zong, 2016).",1 Introduction,[0],[0]
"It was later followed by approaches based on multilingual translation, in which the goal was to exploit knowledge from high-resource language pairs by training a single NMT system on a mix of high-resource and low-resource language pairs (Firat et al., 2016a,b; Lee et al., 2016; Johnson et al., 2016; Ha et al., 2016b).",1 Introduction,[0],[0]
"Its variant, transfer learning, was also proposed by Zoph et al. (2016), in which an NMT system is pretrained on a high-resource language pair before being finetuned on a target low-resource language pair.
",1 Introduction,[0],[0]
"In this paper, we follow up on these latest approaches based on multilingual NMT and propose a meta-learning algorithm for low-resource neural machine translation.",1 Introduction,[0],[0]
"We start by arguing that the recently proposed model-agnostic meta-learning algorithm (MAML, Finn et al., 2017) could be applied to low-resource machine translation by viewing language pairs as separate tasks.",1 Introduction,[0],[0]
This view enables us to use MAML to find the initialization of model parameters that facilitate fast adaptation for a new language pair with a minimal amount of training examples (§3).,1 Introduction,[0],[0]
"Furthermore, the vanilla MAML however cannot handle tasks with mismatched input and output.",1 Introduction,[0],[0]
"We overcome this limitation by incorporating the universal lexical representation (Gu et al., 2018b) and adapting it for the meta-learning scenario (§3.3).
",1 Introduction,[0],[0]
We extensively evaluate the effectiveness and generalizing ability of the proposed meta-learning algorithm on low-resource neural machine translation.,1 Introduction,[0],[0]
"We utilize 17 languages from Europarl and Russian from WMT as the source tasks and test the meta-learned parameter initialization against five target languages (Ro, Lv, Fi, Tr and Ko), in all cases translating to English.",1 Introduction,[0],[0]
"Our experiments using only up to 160k tokens in each of the target task reveal that the proposed meta-learning approach outperforms the multilingual translation
approach across all the target language pairs, and the gap grows as the number of training examples decreases.",1 Introduction,[0.9606269472038389],"['Using elementary techniques, we provide explicit bounds on the bias of empirical arm means maintained by bandit algorithms in the simple stochastic setting that make their selection decisions as a differentially private function of their observations.']"
Neural Machine Translation (NMT),2 Background,[0],[0]
"Given a source sentence X = {x1, ..., xT 0}, a neural machine translation model factors the distribution over possible output sentences Y = {y1, ..., yT } into a chain of conditional probabilities with a leftto-right causal structure:
p(Y |X; ✓) = T+1Y
t=1
p(yt|y0:t 1, x1:T 0 ; ✓), (1)
where special tokens y0 (hbosi) and yT+1 (heosi) are used to represent the beginning and the end of a target sentence.",2 Background,[0],[0]
These conditional probabilities are parameterized using a neural network.,2 Background,[0],[0]
"Typically, an encoder-decoder architecture (Sutskever et al., 2014; Cho et al., 2014; Bahdanau et al., 2015) with a RNN-based decoder is used.",2 Background,[0],[0]
"More recently, architectures without any recurrent structures (Gehring et al., 2017; Vaswani et al., 2017) have been proposed and shown to speed up training while achieving state-of-the-art performance.
",2 Background,[0],[0]
"Low Resource Translation NMT is known to easily over-fit and result in an inferior performance when the training data is limited (Koehn and Knowles, 2017).",2 Background,[0],[0]
"In general, there are two ways for handling the problem of low resource translation: (1) utilizing the resource of unlabeled monolingual data, and (2) sharing the knowledge between low- and high-resource language pairs.",2 Background,[0],[0]
"Many research efforts have been spent on incorporating the monolingual corpora into machine translation, such as multi-task learning (Gulcehre et al., 2015; Zhang and Zong, 2016), back-translation (Sennrich et al., 2015), dual learning (He et al., 2016) and unsupervised machine translation with monolingual corpora only for both sides (Artetxe et al., 2017b; Lample et al., 2017; Yang et al., 2018).
",2 Background,[0],[0]
"For the second approach, prior researches have worked on methods to exploit the knowledge of auxiliary translations, or even auxiliary tasks.",2 Background,[0],[0]
"For instance, Cheng et al. (2016); Chen et al. (2017); Lee et al. (2017); Chen et al. (2018) investigate the use of a pivot to build a translation path between two languages even without any directed resource.",2 Background,[0],[0]
The pivot can be a third language or even an image in multimodal domains.,2 Background,[0],[0]
"When pivots are
not easy to obtain, Firat et al. (2016a); Lee et al. (2016); Johnson et al. (2016) have shown that the structure of NMT is suitable for multilingual machine translation.",2 Background,[0],[0]
"Gu et al. (2018b) also showed that such a multilingual NMT system could improve the performance of low resource translation by using a universal lexical representation to share embedding information across languages.
",2 Background,[0],[0]
"All the previous work for multilingual NMT assume the joint training of multiple high-resource languages naturally results in a universal space (for both the input representation and the model) which, however, is not necessarily true, especially for very low resource cases.
",2 Background,[0],[0]
"Meta Learning In the machine learning community, meta-learning, or learning-to-learn, has recently received interests.",2 Background,[0],[0]
Meta-learning tries to solve the problem of “fast adaptation on new training data.”,2 Background,[0],[0]
"One of the most successful applications of meta-learning has been on few-shot (or oneshot) learning (Lake et al., 2015), where a neural network is trained to readily learn to classify inputs based on only one or a few training examples.",2 Background,[0],[0]
"There are two categories of meta-learning:
1.",2 Background,[0],[0]
"learning a meta-policy for updating model parameters (see, e.g., Andrychowicz et al., 2016; Ha et al., 2016a; Mishra et al., 2017)
2.",2 Background,[0],[0]
"learning a good parameter initialization for fast adaptation (see, e.g., Finn et al., 2017; Vinyals et al., 2016; Snell et al., 2017).
",2 Background,[0],[0]
"In this paper, we propose to use a meta-learning algorithm for low-resource neural machine translation based on the second category.",2 Background,[0],[0]
"More specifically, we extend the idea of model-agnostic metalearning (MAML, Finn et al., 2017) in the multilingual scenario.",2 Background,[0],[0]
"The underlying idea of MAML is to use a set of source tasks T 1, . . .",3 Meta Learning for Low-Resource Neural Machine Translation,[0],[0]
", T K to find the initialization of parameters ✓0 from which learning a target task T 0 would require only a small number of training examples.",3 Meta Learning for Low-Resource Neural Machine Translation,[0],[0]
"In the context of machine translation, this amounts to using many high-resource language pairs to find good initial parameters and training a new translation model on a low-resource language starting from the found initial parame-
ters.",3 Meta Learning for Low-Resource Neural Machine Translation,[0],[0]
"This process can be understood as
✓⇤ = Learn(T 0;MetaLearn(T 1, . . .",3 Meta Learning for Low-Resource Neural Machine Translation,[0],[0]
", T K)).
",3 Meta Learning for Low-Resource Neural Machine Translation,[0],[0]
"That is, we meta-learn the initialization from auxiliary tasks and continue to learn the target task.",3 Meta Learning for Low-Resource Neural Machine Translation,[0],[0]
We refer the proposed meta-learning method for NMT to MetaNMT.,3 Meta Learning for Low-Resource Neural Machine Translation,[0],[0]
See Fig. 1 for the overall illustration.,3 Meta Learning for Low-Resource Neural Machine Translation,[0],[0]
"Given any initial parameters ✓0 (which can be either random or meta-learned),
the prior distribution of the parameters of a desired NMT model can be defined as an isotropic Guassian:
✓i ⇠ N (✓0i , 1/ ),
where 1/ is a variance.",3.1 Learn: language-specific learning,[0],[0]
"With this prior distribution, we formulate the language-specific learning process Learn(DT ; ✓0) as maximizing the logposterior of the model parameters given data DT :
Learn(DT ; ✓0) = argmax ✓ LDT (✓)
= argmax
✓
X
(X,Y )2DT
log p(Y |X, ✓) k✓ ✓0k2,
where we assume p(X|✓) to be uniform.",3.1 Learn: language-specific learning,[0],[0]
The first term above corresponds to the maximum likelihood criterion often used for training a usual NMT system.,3.1 Learn: language-specific learning,[0],[0]
"The second term discourages the newly learned model from deviating too much from the initial parameters, alleviating the issue of overfitting when there is not enough training data.",3.1 Learn: language-specific learning,[0],[0]
"In practice, we solve the problem above by maximizing the first term with gradient-based optimization and early-stopping after only a few update steps.
",3.1 Learn: language-specific learning,[0],[0]
"Thus, in the low-resource scenario, finding a good initialization ✓0 strongly correlates the final performance of the resulting model.",3.1 Learn: language-specific learning,[0],[0]
"We find the initialization ✓0 by repeatedly simulating low-resource translation scenarios using auxiliary, high-resource language pairs.",3.2 MetaLearn,[0],[0]
"Following Finn et al. (2017), we achieve this goal by defining the meta-objective function as
L(✓) =EkEDT k ,D0T k (2)2
64 X
(X,Y )2D0 T k
log p(Y |X;Learn(DT k ; ✓))
3
75 ,
where k ⇠ U({1, . . .",3.2 MetaLearn,[0],[0]
",K}) refers to one metalearning episode, and DT , D0T follow the uniform distribution over T ’s data.
",3.2 MetaLearn,[0],[0]
"We maximize the meta-objective function using stochastic approximation (Robbins and Monro, 1951) with gradient descent.",3.2 MetaLearn,[0],[0]
"For each episode, we uniformly sample one source task at random, T k.",3.2 MetaLearn,[0],[0]
"We then sample two subsets of training examples independently from the chosen task, DT k and D0T k .",3.2 MetaLearn,[0],[0]
We use the former to simulate languagespecific learning and the latter to evaluate its outcome.,3.2 MetaLearn,[0],[0]
"Assuming a single gradient step is taken only the with learning rate ⌘, the simulation is:
✓0k = Learn(DT k ;",3.2 MetaLearn,[0],[0]
✓) =,3.2 MetaLearn,[0],[0]
"✓ ⌘r✓LDT k (✓).
",3.2 MetaLearn,[0],[0]
"Once the simulation of learning is done, we evaluate the updated parameters ✓0k on D 0 T k , The gradient computed from this evaluation, which we refer to as meta-gradient, is used to update the
meta model ✓.",3.2 MetaLearn,[0],[0]
"It is possible to aggregate multiple episodes of source tasks before updating ✓:
✓ ✓ ⌘0 X
k
r✓LD 0 T k (✓0k),
where ⌘0 is the meta learning rate.",3.2 MetaLearn,[0],[0]
"Unlike a usual learning scenario, the resulting model ✓0 from this meta-learning procedure is not necessarily a good model on its own.",3.2 MetaLearn,[0],[0]
It is however a good starting point for training a good model using only a few steps of learning.,3.2 MetaLearn,[0],[0]
"In the context of machine translation, this procedure can be understood as finding the initialization of a neural machine translation system that could quickly adapt to a new language pair by simulating such a fast adaptation scenario using many high-resource language pairs.
",3.2 MetaLearn,[0],[0]
"Meta-Gradient We use the following approximation property
H(x)v ⇡ r(x+ ⌫v) r(x) ⌫
to approximate the meta-gradient:1
r✓LD 0",3.2 MetaLearn,[0],[0]
(✓0),3.2 MetaLearn,[0],[0]
= r✓0LD 0,3.2 MetaLearn,[0],[0]
"(✓0)r✓(✓ ⌘r✓LD(✓))
",3.2 MetaLearn,[0],[0]
= r✓0LD 0,3.2 MetaLearn,[0],[0]
(✓0) ⌘,3.2 MetaLearn,[0],[0]
r✓0LD 0,3.2 MetaLearn,[0],[0]
"(✓0)H✓(LD(✓))
⇡ r✓0LD 0",3.2 MetaLearn,[0],[0]
"(✓0) ⌘
⌫
 r✓LD(✓)
",3.2 MetaLearn,[0],[0]
"✓̂ r✓LD(✓) ✓ ,
where ⌫ is a small constant and
ˆ✓ = ✓ + ⌫r",3.2 MetaLearn,[0],[0]
✓0LD 0,3.2 MetaLearn,[0],[0]
"(✓0).
",3.2 MetaLearn,[0],[0]
"In practice, we find that it is also possible to ignore the second-order term, ending up with the following simplified update rule:
r✓LD 0 (✓0) ⇡ r✓0LD 0",3.2 MetaLearn,[0],[0]
(✓0).,3.2 MetaLearn,[0],[0]
"(3)
1We omit the subscript k for simplicity.
",3.2 MetaLearn,[0],[0]
"Related Work: Multilingual Transfer Learning The proposed MetaNMT differs from the existing framework of multilingual translation (Lee et al., 2016; Johnson et al., 2016; Gu et al., 2018b) or transfer learning (Zoph et al., 2016).",3.2 MetaLearn,[0],[0]
"The latter can be thought of as solving the following problem:
max ✓ Lmulti(✓) =",3.2 MetaLearn,[0],[0]
"Ek
2 4 X
(X,Y )2Dk
log p(Y |X; ✓)
3
5 ,
where Dk is the training set of the k-th task, or language pair.",3.2 MetaLearn,[0],[0]
"The target low-resource language pair could either be a part of joint training or be trained separately starting from the solution ✓0 found from solving the above problem.
",3.2 MetaLearn,[0],[0]
"The major difference between the proposed MetaNMT and these multilingual transfer approaches is that the latter do not consider how learning happens with the target, low-resource language pair.",3.2 MetaLearn,[0],[0]
The former explicitly incorporates the learning process within the framework by simulating it repeatedly in Eq.,3.2 MetaLearn,[0],[0]
(2).,3.2 MetaLearn,[0],[0]
"As we will see later in the experiments, this results in a substantial gap in the final performance on the low-resource task.
",3.2 MetaLearn,[0],[0]
"Illustration In Fig. 2, we contrast transfer learning, multilingual learning and meta-learning using three source language pairs (Fr-En, Es-En and Pt-En) and two target pairs (Ro-En and Lv-En).",3.2 MetaLearn,[0],[0]
"Transfer learning trains an NMT system specifically for a source language pair (Es-En) and finetunes the system for each target language pair (RoEn, Lv-En).",3.2 MetaLearn,[0],[0]
"Multilingual learning often trains a single NMT system that can handle many different language pairs (Fr-En, Pt-En, Es-En), which may or may not include the target pairs (Ro-En, LvEn).",3.2 MetaLearn,[0],[0]
"If not, it finetunes the system for each target pair, similarly to transfer learning.",3.2 MetaLearn,[0],[0]
Both of these however aim at directly solving the source tasks.,3.2 MetaLearn,[0],[0]
"On the other hand, meta-learning trains the NMT system to be useful for fine-tuning on various tasks including the source and target tasks.",3.2 MetaLearn,[0],[0]
"This is done by repeatedly simulating the learning process on
low-resource languages using many high-resource language pairs (Fr-En, Pt-En, Es-En).",3.2 MetaLearn,[0],[0]
I/O mismatch across language pairs One major challenge that limits applying meta-learning for low resource machine translation is that the approach outlined above assumes the input and output spaces are shared across all the source and target tasks.,3.3 Unified Lexical Representation,[0],[0]
"This, however, does not apply to machine translation in general due to the vocabulary mismatch across different languages.",3.3 Unified Lexical Representation,[0],[0]
"In multilingual translation, this issue has been tackled by using a vocabulary of sub-words (Sennrich et al., 2015) or characters (Lee et al., 2016) shared across multiple languages.",3.3 Unified Lexical Representation,[0],[0]
"This surface-level sharing is however limited, as it cannot be applied to languages exhibiting distinct orthography (e.g., IndoEuroepan languages vs. Korean.)
",3.3 Unified Lexical Representation,[0],[0]
"Universal Lexical Representation (ULR) We tackle this issue by dynamically building a vocabulary specific to each language using a keyvalue memory network (Miller et al., 2016; Gulcehre et al., 2018), as was done successfully for low-resource machine translation recently by Gu et al. (2018b).",3.3 Unified Lexical Representation,[0],[0]
"We start with multilingual word embedding matrices ✏kquery 2 R|Vk|⇥d pretrained on large monolingual corpora, where Vk is the vocabulary of the k-th language.",3.3 Unified Lexical Representation,[0],[0]
"These embedding vectors can be obtained with small dictionaries of seed word pairs (Artetxe et al., 2017a; Smith et al., 2017) or in a fully unsupervised manner (Zhang et al., 2017; Conneau et al., 2018).",3.3 Unified Lexical Representation,[0],[0]
"We take one of these languages k0 to build universal lexical representation consisting of a universal embedding matrix ✏u 2 RM⇥d and a corresponding key matrix ✏key 2 RM⇥d, where M < |V 0k|.",3.3 Unified Lexical Representation,[0],[0]
Both ✏kquery and ✏key are fixed during meta-learning.,3.3 Unified Lexical Representation,[0],[0]
"We then compute the language-specific embedding of token x from the language k as the convex sum of the universal embedding vectors by
✏0[x] = MX
i=1
↵i✏u[i],
where ↵i / exp 1⌧ ✏key[i]",3.3 Unified Lexical Representation,[0],[0]
>A✏kquery[x] and ⌧ is set to 0.05.,3.3 Unified Lexical Representation,[0],[0]
"This approach allows us to handle languages with different vocabularies using a fixed number of shared parameters (✏u, ✏key and A.)
",3.3 Unified Lexical Representation,[0],[0]
"Learning of ULR It is not desirable to update the universal embedding matrix ✏u when fine-
tuning on a small corpus which contains a limited set of unique tokens in the target language, as it could adversely influence the other tokens’ embedding vectors.",3.3 Unified Lexical Representation,[0],[0]
"We thus estimate the change to each embedding vector induced by languagespecific learning by a separate parameter ✏k[x]:
✏k[x] = ✏0[x] + ✏k[x].
",3.3 Unified Lexical Representation,[0],[0]
"During language-specific learning, the ULR ✏0[x] is held constant, while only ✏k[x] is updated, starting from an all-zero vector.",3.3 Unified Lexical Representation,[0],[0]
"On the other hand, we hold ✏k[x]’s constant while updating ✏u and A during the meta-learning stage.",3.3 Unified Lexical Representation,[0],[0]
"Target Tasks We show the effectiveness of the proposed meta-learning method for low resource NMT with extremely limited training examples on five diverse target languages: Romanian (Ro) from WMT’16,2 Latvian (Lv), Finnish (Fi), Turkish (Tr) from WMT’17,3 and Korean (Ko) from Korean Parallel Dataset.4 We use the officially provided train, dev and test splits for all these languages.",4.1 Dataset,[0],[0]
The statistics of these languages are presented in Table 1.,4.1 Dataset,[0],[0]
"We simulate the low-resource translation scenarios by randomly sub-sampling the training set with different sizes.
",4.1 Dataset,[0],[0]
"Source Tasks We use the following languages from Europarl5: Bulgarian (Bg), Czech (Cs), Danish (Da), German (De), Greek (El), Spanish (Es), Estonian (Et), French (Fr), Hungarian (Hu), Italian (It), Lithuanian (Lt), Dutch (Nl), Polish (Pl), Portuguese (Pt), Slovak (Sk), Slovene (Sl) and
2 http://www.statmt.org/wmt16/translation-task.html 3 http://www.statmt.org/wmt17/translation-task.html 4 https://sites.google.com/site/koreanparalleldata/ 5 http://www.statmt.org/europarl/
Swedish (Sv), in addition to Russian (Ru)6 to learn the intilization for fine-tuning.",4.1 Dataset,[0],[0]
"In our experiments, different combinations of source tasks are explored to see the effects from the source tasks.
",4.1 Dataset,[0],[0]
Validation We pick either Ro-En or Lv-En as a validation set for meta-learning and test the generalization capability on the remaining target tasks.,4.1 Dataset,[0],[0]
"This allows us to study the strict form of metalearning, in which target tasks are unknown during both training and model selection.
",4.1 Dataset,[0],[0]
"Preprocessing and ULR Initialization As described in §3.3, we initialize the query embedding vectors ✏kquery of all the languages.",4.1 Dataset,[0],[0]
"For each language, we use the monolingual corpora built from Wikipedia7 and the parallel corpus.",4.1 Dataset,[0],[0]
"The concatenated corpus is first tokenized and segmented using byte-pair encoding (BPE, Sennrich et al., 2016), resulting in 40, 000 subwords for each language.",4.1 Dataset,[0],[0]
"We then estimate word vectors using fastText (Bojanowski et al., 2016) and align them across all the languages in an unsupervised way
6 A subsample of approximately 2M pairs from WMT’17.",4.1 Dataset,[0],[0]
"7 We use the most recent Wikipedia dump (2018.5) from
https://dumps.wikimedia.org/backup-index.html.
using MUSE (Conneau et al., 2018) to get multilingual word vectors.",4.1 Dataset,[0],[0]
"We use the multilingual word vectors of the 20,000 most frequent words in English to form the universal embedding matrix ✏u.",4.1 Dataset,[0],[0]
"Model We utilize the recently proposed Transformer (Vaswani et al., 2017) as an underlying NMT system.",4.2 Model and Learning,[0],[0]
"We implement Transformer in this paper based on (Gu et al., 2018a)8 and modify it to use the universal lexical representation from §3.3.",4.2 Model and Learning,[0],[0]
"We use the default set of hyperparameters (dmodel = dhidden = 512, nlayer = 6, nhead = 8, nbatch = 4000, twarmup = 16000) for all the language pairs and across all the experimental settings.",4.2 Model and Learning,[0],[0]
"We refer the readers to (Vaswani et al., 2017; Gu et al., 2018a) for the details of the model.",4.2 Model and Learning,[0],[0]
"However, since the proposed metalearning method is model-agnostic, it can be easily extended to any other NMT architectures, e.g. RNN-based sequence-to-sequence models with attention (Bahdanau et al., 2015).
",4.2 Model and Learning,[0],[0]
8,4.2 Model and Learning,[0],[0]
"https://github.com/salesforce/nonauto-nmt
Learning We meta-learn using various sets of source languages to investigate the effect of source task choice.",4.2 Model and Learning,[0],[0]
"For each episode, by default, we use a single gradient step of language-specific learning with Adam (Kingma and Ba, 2014) per computing the meta-gradient, which is computed by the first-order approximation in Eq.",4.2 Model and Learning,[0],[0]
"(3).
",4.2 Model and Learning,[0],[0]
"For each target task, we sample training examples to form a low-resource task.",4.2 Model and Learning,[0],[0]
"We build tasks of 4k, 16k, 40k and 160k English tokens for each language.",4.2 Model and Learning,[0],[0]
We randomly sample the training set five times for each experiment and report the average score and its standard deviation.,4.2 Model and Learning,[0],[0]
"Each fine-tuning is done on a training set, early-stopped on a validation set and evaluated on a test set.",4.2 Model and Learning,[0],[0]
"In default without notation, datasets of 16k tokens are used.
",4.2 Model and Learning,[0],[0]
"Fine-tuning Strategies The transformer consists of three modules; embedding, encoder and decoder.",4.2 Model and Learning,[0],[0]
"We update all three modules during metalearning, but during fine-tuning, we can selectively tune only a subset of these modules.",4.2 Model and Learning,[0],[0]
"Following (Zoph et al., 2016), we consider three fine-tuning
strategies; (1) fine-tuning all the modules (all), (2) fine-tuning the embedding and encoder, but freezing the parameters of the decoder (emb+enc) and (3) fine-tuning the embedding only (emb).",4.2 Model and Learning,[0],[0]
vs. Multilingual Transfer Learning We metalearn the initial models on all the source tasks using either Ro-En or Lv-En as a validation task.,5 Results,[0],[0]
We also train the initial models to be multilingual translation systems.,5 Results,[0],[0]
"We fine-tune them using the four target tasks (Ro-En, Lv-En, Fi-En and Tr-En; 16k tokens each) and compare the proposed meta-learning strategy and the multilingual, transfer learning strategy.",5 Results,[0],[0]
"As presented in Fig. 3, the proposed learning approach significantly outperforms the multilingual, transfer learning strategy across all the target tasks regardless of which target task was used for early stopping.",5 Results,[0],[0]
We also notice that the emb+enc strategy is most effective for both meta-learning and transfer learning approaches.,5 Results,[0],[0]
"With the proposed meta-learning and emb+enc fine-tuning, the final NMT systems trained using only a fraction of all available training examples achieve 2/3 (Ro-En) and 1/2 (Lv-En, Fi-En and Tr-En) of the BLEU score achieved by the models trained with full training sets.
",5 Results,[0],[0]
"vs. Statistical Machine Translation We also test the same Ro-En datasets with 16, 000 target tokens using the default setting of Phrase-based MT (Moses) with the dev set for adjusting the parameters and the test set for calculating the final performance.",5 Results,[0],[0]
"We obtain 4.79(±0.234) BLEU point, which is higher than the standard NMT performance (0 BLEU).",5 Results,[0],[0]
"It is however still lower than both the multi-NMT and meta-NMT.
",5 Results,[0],[0]
"Impact of Validation Tasks Similarly to training any other neural network, meta-learning still requires early-stopping to avoid overfitting to a
specific set of source tasks.",5 Results,[0],[0]
"In doing so, we observe that the choice of a validation task has nonnegligible impact on the final performance.",5 Results,[0],[0]
"For instance, as shown in Fig. 3, Fi-En benefits more when Ro-En is used for validation, while the opposite happens with Tr-En.",5 Results,[0],[0]
"The relationship between the task similarity and the impact of a validation task must be investigated further in the future.
",5 Results,[0],[0]
"Training Set Size We vary the size of the target task’s training set and compare the proposed meta-learning strategy and multilingual, transfer learning strategy.",5 Results,[0],[0]
We use the emb+enc fine-tuning on Ro-En and Fi-En.,5 Results,[0],[0]
Fig. 4 demonstrates that the meta-learning approach is more robust to the drop in the size of the target task’s training set.,5 Results,[0],[0]
"The gap between the meta-learning and transfer learning grows as the size shrinks, confirming the effectiveness of the proposed approach on extremely lowresource language pairs.
",5 Results,[0],[0]
"Impact of Source Tasks In Table 2, we present the results on all five target tasks obtained while varying the source task set.",5 Results,[0],[0]
We first see that it is always beneficial to use more source tasks.,5 Results,[0],[0]
"Although the impact of adding more source tasks varies from one language to another, there is up to 2⇥ improvement going from one source task to 18 source tasks (Lv-En, Fi-En, Tr-En and Ko-En).",5 Results,[0],[0]
"The same trend can be observed even without any fine-tuning (i.e., unsupervised translation, (Lample et al., 2017; Artetxe et al., 2017b)).",5 Results,[0],[0]
"In addition, the choice of source languages has different implications for different target languages.",5 Results,[0],[0]
"For instance, Ro-En benefits more from {Es, Fr, It, Pt} than from {De, Ru}, while the opposite effect is observed with all the other target tasks.
",5 Results,[0],[0]
Training Curves,5 Results,[0],[0]
The benefit of meta-learning over multilingual translation is clearly demonstrated when we look at the training curves in Fig. 5.,5 Results,[0],[0]
"With the multilingual, transfer learning ap-
",5 Results,[0],[0]
"proach, we observe that training rapidly saturates and eventually degrades, as the model overfits to the source tasks.",5 Results,[0],[0]
MetaNMT,5 Results,[0],[0]
"on the other hand continues to improve and never degrades, as the metaobjective ensures that the model is adequate for fine-tuning on target tasks rather than for solving the source tasks.
",5 Results,[0],[0]
Sample Translations We present some sample translations from the tested models in Table 3.,5 Results,[0],[0]
Inspecting these examples provides the insight into the proposed meta-learning algorithm.,5 Results,[0],[0]
"For instance, we observe that the meta-learned model without any fine-tuning produces a word-by-word translation in the first example (Tr-En), which is due to the successful use of the universal lexcial representation and the meta-learned initialization.",5 Results,[0],[0]
"The system however cannot reorder tokens from Turkish to English, as it has not seen any training example of Tr-En.",5 Results,[0],[0]
"After seeing around 600 sentence pairs (16K English tokens), the model rapidly learns to correctly reorder tokens to form a better translation.",5 Results,[0],[0]
A similar phenomenon is observed in the Ko-En example.,5 Results,[0],[0]
These cases could be found across different language pairs.,5 Results,[0],[0]
"In this paper, we proposed a meta-learning algorithm for low-resource neural machine translation that exploits the availability of high-resource languages pairs.",6 Conclusion,[0],[0]
"We based the proposed algorithm on the recently proposed model-agnostic metalearning and adapted it to work with multiple languages that do not share a common vocabulary using the technique of universal lexcal representation, resulting in MetaNMT.",6 Conclusion,[0],[0]
"Our extensive evaluation, using 18 high-resource source tasks and 5 low-resource target tasks, has shown that the proposed MetaNMT significantly outperforms the existing approach of multilingual, transfer learning in low-resource neural machine translation across all the language pairs considered.
",6 Conclusion,[0],[0]
The proposed approach opens new opportunities for neural machine translation.,6 Conclusion,[0],[0]
"First, it is a principled framework for incorporating various extra sources of data, such as source- and targetside monolingual corpora.",6 Conclusion,[0],[0]
"Second, it is a generic framework that can easily accommodate existing and future neural machine translation systems.",6 Conclusion,[0],[0]
This research was supported in part by the Facebook Low Resource Neural Machine Translation Award.,Acknowledgement,[0],[0]
This work was also partly supported by Samsung Advanced Institute of Technology (Next Generation Deep Learning: from pattern recognition to AI) and Samsung Electronics (Improving Deep Learning using Latent Structure).,Acknowledgement,[0],[0]
"KC thanks support by eBay, TenCent, NVIDIA and CIFAR.",Acknowledgement,[0],[0]
"In this paper, we propose to extend the recently introduced model-agnostic meta-learning algorithm (MAML, Finn et al., 2017) for lowresource neural machine translation (NMT).",abstractText,[0],[0]
"We frame low-resource translation as a metalearning problem, and we learn to adapt to low-resource languages based on multilingual high-resource language tasks.",abstractText,[0],[0]
"We use the universal lexical representation (Gu et al., 2018b) to overcome the input-output mismatch across different languages.",abstractText,[0],[0]
"We evaluate the proposed meta-learning strategy using eighteen European languages (Bg, Cs, Da, De, El, Es, Et, Fr, Hu, It, Lt, Nl, Pl, Pt, Sk, Sl, Sv and Ru) as source tasks and five diverse languages (Ro, Lv, Fi, Tr and Ko) as target tasks.",abstractText,[0],[0]
"We show that the proposed approach significantly outperforms the multilingual, transfer learning based approach (Zoph et al., 2016) and enables us to train a competitive NMT system with only a fraction of training examples.",abstractText,[0.954737657054309],"['(Nie et al., 2017) give a selective inference approach: in simple stochastic bandit settings, if the data was gathered by a specific stochastic algorithm that they design, they give an MCMC based procedure to perform maximum likelihood estimation to recover de-biased estimates of the underlying distribution means.']"
"For instance, the proposed approach can achieve as high as 22.04 BLEU on Romanian-English WMT’16 by seeing only 16,000 translated words (⇠ 600 parallel sentences).",abstractText,[0],[0]
Meta-Learning for Low-Resource Neural Machine Translation,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 375–385 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics",text,[0],[0]
"Online platforms have revolutionized the way individuals collect and share information (O’Connor et al., 2010; Lee and Ma, 2012; Bakshy et al., 2015), but the vast bulk of online content is irrelevant or unpalatable to any given individual.",1 Introduction,[0.9543736811793847],"['By leveraging existing connections between differential privacy and adaptive data analysis (Dwork et al., 2015c; Bassily et al., 2016; Rogers et al., 2016), we can extend the generality of our approach to bound not just bias, but to correct for effects of adaptivity on arbitrary statistics of the gathered data.']"
"A user interested in political discussion, for instance, might prefer content concerning a specific candidate or issue, and only then if discussed in a positive light without controversy (Adamic and Glance, 2005; Bakshy et al., 2015).
",1 Introduction,[0],[0]
"How do individuals facing such large quantities of superfluous material select which conversations to engage in, and how might we better algorithmically recommend conversations suited to individual users?",1 Introduction,[0],[0]
We approach this problem from a microblog conversation recommendation framework.,1 Introduction,[0],[0]
"Where prior work has focused on the content of individual posts for recommendation (Chen
et al., 2012; Yan et al., 2012; Vosecky et al., 2014; He and Tan, 2015), we examine the entire history and context of a conversation, including both topical content and discourse modes such as agreement, question-asking, argument and other dialogue acts (Ritter et al.,",1 Introduction,[0],[0]
"2010).1 And where Backstrom et al. (2013) leveraged conversation reply structure (such as previous user engagement), their model is unable to predict first entry into new conversations, while ours is able to predict both new
1In this paper, discourse mode refers to a certain type of dialogue act, e.g., agreement or argument.",1 Introduction,[0],[0]
"The discourse structure of a conversation means some combination (or a probability distribution) of discourse modes.
375
and repeated entry into conversations based on a combination of topical and discourse features.
",1 Introduction,[0],[0]
"To illustrate the interplay between topics and discourse, Figure 1 displays two snippets of conversations on Twitter collected during the 2016 United States presidential election.",1 Introduction,[0],[0]
User U1 participates in both conversations.,1 Introduction,[0],[0]
"The first conversation is centered around Clinton, and U1, who is more typically involved with conversations about candidate Sanders, does not return.",1 Introduction,[0],[0]
"In the second conversation, however, U1 is involved in a heated back-and-forth debate, and thus is drawn back to a conversation that they may otherwise have abandoned but for their enjoyment of adversarial discourse.
",1 Introduction,[0],[0]
"Effective conversation prediction and recommendation requires an understanding of both user interests and discourse behaviors, such as agreement, disagreement, inquiry, backchanneling, and emotional reactions.",1 Introduction,[0],[0]
"However, acquiring manual labels for both is a time-consuming process and hard to scale for new datasets.",1 Introduction,[0],[0]
"We instead propose a unified statistical learning framework for conversation recommendation, which jointly learns (1) hidden factors that reflect user interests based on conversation history, and (2) topics and discourse modes in ongoing conversations, as discovered by a novel probabilistic latent variable model.",1 Introduction,[0],[0]
"Our model is built on the success of collaborative filtering (CF) in recommendation systems, where latent dimensions of product ratings or movie reviews are extracted to better capture user preferences (Linden et al., 2003; Salakhutdinov and Mnih, 2008; Wang and Blei, 2011; McAuley and Leskovec, 2013).",1 Introduction,[0],[0]
"To the best of our knowledge, we are the first to model both topics and discourse modes as part of a CF framework and apply it to microblog conversation recommendation.2
Experimental results on two Twitter conversation datasets show that our proposed model yields significantly better performance than state-of-theart post-level recommendation systems.",1 Introduction,[0],[0]
"For example, by leveraging both topical content and discourse structure, our model achieves a mean average precision (MAP) of 0.76 on conversations about the U.S. presidential election, compared with 0.70 by McAuley and Leskovec (2013), which only considers topics.",1 Introduction,[0],[0]
"We further con-
2To ensure the general applicability of our approach to domains lacking such information, we do not utilize external features such as network structure, but it may certainly be added in future, more narrowly targeted applications.
ducted detailed analysis on the latent topics and discourse modes and find that our model can discover reasonable topic and discourse representations, which play an important role in characterizing reply behaviors.",1 Introduction,[0.9592869515107403],"['We briefly define max information, state the connection to differential privacy, and illustrate how max information bounds can be used to perform adaptive analyses in the private data gathering framework.']"
"Finally, we also provide a pilot study on recommendation for first time replies, which shows that our model outperforms comparable recommendation systems.
",1 Introduction,[0],[0]
The rest of this paper is structured as follows.,1 Introduction,[0],[0]
The related work is discussed in Section 2.,1 Introduction,[0],[0]
We then present our microblog conversation recommendation model in Section 3.,1 Introduction,[0],[0]
The experimental setup and results are described in Sections 4 and 5.,1 Introduction,[0],[0]
"Finally, we conclude in Section 6.",1 Introduction,[0],[0]
"Social media has attracted increasing attention in digital communication research (Agichtein et al., 2008; Kwak et al., 2010; Wu et al., 2011).",2 Related Work,[0],[0]
"The problem studied here is closely related to work on recommendation and response prediction in microblogs (Artzi et al., 2012; Hong et al., 2013), where the goal is to predict whether a user will share or reply to a given post.",2 Related Work,[0],[0]
"Existing methods focus on measuring features that reflect personalized user interests, including topics (Hong et al., 2013) and network structures (Pan et al., 2013; He and Tan, 2015).",2 Related Work,[0],[0]
"These features have been investigated under a learning to rank framework (Duan et al., 2010; Artzi et al., 2012), graph ranking models (Yan et al., 2012; Feng and Wang, 2013; Alawad et al., 2016), and neural network-based representation learning methods (Yu et al., 2016).
",2 Related Work,[0],[0]
"Distinguishing from prior work that focuses on post-level recommendation, we tackle the challenges of predicting user reply behaviors at the conversation-level.",2 Related Work,[0],[0]
"In addition, our model not only captures latent factors such as the topical interests of users, but also leverages the automatically learned discourse structure.",2 Related Work,[0],[0]
"Much of the previous work on discourse structure and dialogue acts has relied on labeled data (Jurafsky et al., 1997; Stolcke et al., 2000), while unsupervised approaches have not been applied to the problem of conversation recommendation (Woszczyna and Waibel, 1994; Crook et al., 2009; Ritter et al., 2010; Joty et al., 2011).
",2 Related Work,[0],[0]
"Our work is also in line with conversation modeling for social media discussions (Ritter et al., 2010; Budak and Agrawal, 2013; Louis and Cohen, 2015; Cheng et al., 2017).",2 Related Work,[0],[0]
"Topic modeling
has been employed to identify conversation content on Twitter (Ritter et al., 2010).",2 Related Work,[0],[0]
"In this work, we propose a probabilistic model to capture both topics and discourse modes as latent variables.",2 Related Work,[0],[0]
"A further line of work studies the reposting and reply structure of conversations (Gómez et al., 2011; Laniado et al., 2011; Backstrom et al., 2013; Budak and Agrawal, 2013).",2 Related Work,[0],[0]
"But none of this work distinguishes the rich discourse functions of replies, which is modeled and exploited in our work.",2 Related Work,[0],[0]
Our proposed microblog conversation recommendation framework is based on collaborative filtering and a novel probabilistic graphical model.,3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"Concretely, our objective function takes the form:
minL+ µ ·NLL(C |Θ) (1)
",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
This function encodes two types of information.,3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"First, L models user reply preference in a similar fashion to collaborative filtering (CF) (Hu et al., 2008; Pan et al., 2008).",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"It captures topics of interests and discourse structures users are commonly involved (e.g., argumentation), and takes the form of mean square error (MSE) based on user reply history.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"This part is detailed in Section 3.1.
",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"The second term, NLL(C |Θ), denotes the negative log-likelihood of a set of conversations C, with Θ containing all parameters.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"A probabilistic model is described in Section 3.2 that shows how the topical content and discourse structures of conversations are captured by these latent variables.
",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
The hyperparameter µ controls the trade-off between the two effects.,3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"`2 regularization is also added for parameters to avoid model overfitting.
",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"For the rest of this section, we first present the construction of L andNLL(C |Θ) in Sections 3.1 and 3.2.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
We then discuss how these two components can be mutually informed by each other in Section 3.3.,3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"Finally, the generative process and parameter learning are described in Section 3.4.
3.1 Reply Preference (L) Our user reply preference modeling is built on the success of collaborative filtering (CF) for product ratings.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"However, classic CF problems, such as product recommendation, generally rely on explicit user feedback.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"Unlike user ratings on products, our input lacks explicit feedback from users about negative preferences and nonresponse.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"Therefore, we follow one-class Collaborative Filtering (Hu et al., 2008; Pan et al., 2008),
which weights positive instances higher during training and is thus suited to our data.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"Formally, for user u and conversation c, we measure reply preference based on the MSE between predicted preference score pu,c and reply history ru,c. ru,c equals 1 if u is in the conversation history; otherwise, it is 0.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"The first term of objective (Eq. 1) takes the following form:
L = |U|∑
u=1
|C|∑
c=1
fu,c · (pu,c − ru,c)2 (2)
where U consists of users {u} and C is a set of conversations {c} in a dataset.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"fu,c is the corresponding weight for a conversation c and a target user u. Intuitively, it has a large value if positive feedback (user replied) is observed.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"Therefore, we adapt the formulation from Pan et al. (2008):
fu,c = { s if ru,c = 1 (i.e., user replied) 1 if ru,c = 0
(3)
where s > 1, an integer hyperparameter to be tuned.
",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"Inspired by prior models (Koren et al., 2009; McAuley and Leskovec, 2013), we propose the following latent factor model to describe pu,c:
pu,c = λ · γUu · γCc + (1− λ) ·",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
δUu · δCc,3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"+ bu + bc + a (4)
γUu and γ C c are K-dimensional latent vectors that encode topic-specific information (where K is the number of latent topics) for users and conversations.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"Specifically, γUu reflects the topical interests of u, with higher value γUu,k indicating greater interest by u in topic k. γCc captures the extents that topics are discussed in conversation c.
Similarly, D-dimensional vectors δUu and δ C c capture discourse structures in shaping reply behaviors (where D is the number of discourse clusters).",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"δUu reflects the discourse behaviors u prefers, such as u1 often enjoys arguments as in the second conversation of Figure 1, while δCc captures the discourse modes used throughout conversation c. By multiplying user and conversation factors, we can measure the corresponding similarity.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"The predicted score pu,c thereby reflects the tendency for a user u to be involved in conversation c.
As pointed out by McAuley and Leskovec (2013), these latent vectors often encode hidden factors that are hard to interpret under a CF framework.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"Therefore, in Section 3.2, we present a novel probabilistic model which can extract interpretable topics and discourse modes as word
distributions.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"We then describe how they can be aligned with the latent vectors of γC and δU .
",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"Parameter a is an offset parameter, bu and bc are user and conversation biases, and λ ∈",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"[0, 1] serves as the weight for trading offs of topic and discourse factors in reply preference modeling.
",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
3.2 Corpus Likelihood NLL(C |Θ),3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
Here we present a novel probabilistic model that learns coherent word distributions for latent topics and discourse modes of conversations.,3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"Formally, we assume that each conversation c ∈ C contains Mc messages, and each message m has Nc,m words.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"We distinguish three latent components – discourse, topic, and background – underlying conversations, each with their own type of word distribution.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"At the corpus level, there are K topics represented by word distribution φTk (k = 1, 2, ...,K), while φDd (d = 1, 2, ..., D) represents the D discourse modes embedded in corpus.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"In addition, we add a background word distribution φB to capture general information (e.g., common words), which do not indicate either discourse or topic information.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"φDd , φ T k , and φ
B are all multinomial word distributions over vocabulary size V .",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"Below describes more details.
",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
Message-level Modeling.,3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"Our model assigns two types of message-level multinomial variables to each message: zc,m reflects its latent topic and dc,m represents its discourse mode.
",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
Topic assignments.,3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"Due to the short nature of microblog posts, we assume each message m in conversation c contains only one topic, indexed as zc,m. This strategy has been proven useful to alleviate data sparsity for topic inference (Quan et al., 2015).",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
We further assume messages in the same conversation would focus on similar topics.,3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"We thus draw topic zc,m ∼ θc, where θc denotes the fractions of topics discussed in conversation c.
Discourse assignments.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"To capture discourse behaviors of u, distribution πu is used to represent the discourse modes in messages posted by u.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"The discourse mode dc,m for message m is then generated from πuc,m , where uc,m is the author of m in c.
Word-level Modeling.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"We aim to separate discourse, topic, and background information for conversations.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"Therefore, for each word wc,m,n of message m, a ternary switcher xc,m,n ∈ {DISC, TOPIC,BACK} controls word wc,m,n to
fall into one of the three types: discourse, topic, and background.
",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
Discourse words (DISC) are indicative of the discourse modes of messages.,3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"When xc,m,n = DISC (i.e., wc,m,n is assigned as a discourse word), word wc,m,n is generated from the discourse word distribution φDdc,m where dc,m is discourse assignment to",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"message m.
Topic words (TOPIC) describe the topical focus of a conversation.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"When xc,m,n = TOPIC, wc,m,n is assigned as a topic word and generated from φTzc,m – word distribution given topic of m.
Background words (BACK) capture the general information that is not related to discourse or topic.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"When word wc,m,n is assigned as a background word (xc,m,n = BACK), it is drawn from background distribution φB .
",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"Switching among Topic, Discourse, and Background.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"We further assume the word type switcher xc,m,n is sampled from a multinomial distribution which depends on the current discourse mode dc,m. The intuition is that messages of different discourse modes may show different distributions of the three word types.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"For instance, a statement message may contain more content words than a rhetorical question.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"Specifically, xc,m,n ∼ Multi(τdc,m), where τd is a 3-dimension stochastic vector that expresses the appearing probabilities of three kinds of words (DISC, TOPIC, BACK), when the discourse assignment is d. Stop words and punctuations are forced to be labeled as discourse or background.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"By explicitly distinguishing different types of words with switcher xc,m,n, we can thus separate word distributions that reflect discourse, topic, and background information.
",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
Likelihood.,3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"Based on the message-level and the word-level generation process, the probability of observing words in the given corpus is:
Pr(C |θ,π,φ, τ , z,d,x)
=
C∏
c=1
Mc∏
m=1
θc,zc,mπuc,m,dc,m
× ∏
xc,m,n=BACK
τdc,m,BACKφ B wc,m,n
× ∏
xc,m,n=DISC
τdc,m,DISCφ D dc,m,wc,m,n
× ∏
xc,m,n=TOPIC
τdc,m,TOPICφ T zc,m,wc,m,n
(5)
",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"And we use negative log likelihood to model corpus likelihood effect in Eq. 1, i.e., NLL(C |Θ) =
− log(Pr(C |Θ), where parameters set Θ = {θ,π,φ, τ , z,d,x}.",3 The Joint Model of Topic and Discourse for Recommendation,[0],[0]
"Latent Variables
As mentioned above, the hidden factors discovered in Section 3.1 lack interpretability, which can be boosted by the learned latent topics and discourse modes in Section 3.2.",3.3 Mutually Informed User Preference and,[0],[0]
"However, it is nontrivial to link the topic-related parameters of γCc to the conversation topic distributions of θc, since the former takes real values from −∞ to +∞ while the latter is a stochastic vector.",3.3 Mutually Informed User Preference and,[0],[0]
"Therefore, we follow the strategy from McAuley and Leskovec (2013) to apply a softmax function over γCc :
θc,k = exp(κT γCc,k)∑K
k′=1 exp(κ T γCc,k′)
(6)
",3.3 Mutually Informed User Preference and,[0],[0]
"We further assume that the discourse mode preference by users, δUu , can also be informed by the discourse mode distribution captured by πu, i.e., a user who enjoys arguments may be willing to participate another.",3.3 Mutually Informed User Preference and,[0],[0]
"So similarly, we define:
πu,d = exp(κDδUu,d)∑D
d′=1 exp(κ DδUu,d′)
(7)
where κT and κD are learnable parameters that control the “peakiness” of the transformation.",3.3 Mutually Informed User Preference and,[0],[0]
"For example, a larger κT indicates a more focused conversation, while a smaller κT means users discuss diverse topics.
",3.3 Mutually Informed User Preference and,[0],[0]
"Finally, softmax transformation is also applied to φTk , φ D d , φ
B , and τd, as done in McAuley and Leskovec (2013), with additional parameters ψTk , ψDd , ψ
B , and χd (as shown in Figure 2).",3.3 Mutually Informed User Preference and,[0],[0]
This is to ensure that the distributions φ∗∗ and τd are stochastic vectors.,3.3 Mutually Informed User Preference and,[0],[0]
"In doing so, these distributions can be learned via optimizing ψ∗∗ and χd, which take any value and thus ensure that the cost function in Eq. 1 is optimized without considering any parameter constraints.",3.3 Mutually Informed User Preference and,[0],[0]
"Our word generation process is displayed in Figure 2 and described as follows:
• Compute topic distribution θc by Eq. 6 •",3.4 Generative Process and Model Learning,[0],[0]
"For message m = 1 to Mc:
– Compute discourse distribution πuc,m by Eq. 7 – Draw topic assignment zc,m ∼Multi(θc) – Draw discourse mode dc,m ∼Multi(πuc,m) –",3.4 Generative Process and Model Learning,[0],[0]
"For word index n = 1 to Nc,m: ∗ Draw word type xc,m,n ∼Multi(τd)
∗",3.4 Generative Process and Model Learning,[0],[0]
"if xc,m,n == BACK:",3.4 Generative Process and Model Learning,[0],[0]
"Draw word wc,m,n ∼Multi(φB) ∗",3.4 Generative Process and Model Learning,[0],[0]
"if xc,m,n == DISC:",3.4 Generative Process and Model Learning,[0],[0]
"Draw word wc,m,n ∼Multi(φDdc,m) ∗",3.4 Generative Process and Model Learning,[0],[0]
"if xc,m,n == TOPIC:",3.4 Generative Process and Model Learning,[0],[0]
"Draw word wc,m,n ∼Multi(φTzc,m)
Parameter Learning.",3.4 Generative Process and Model Learning,[0],[0]
"For learning, we randomly initialize all learnable parameters and then alternate between the following two steps: Step 1.",3.4 Generative Process and Model Learning,[0],[0]
"Fix topic and discourse assignments z and d, and word type switcher x, then optimize the remaining parameters in Eq. 1 by L-BFGS (Nocedal, 1980):
Update a, b, γ∗, δ∗, κ∗, ψ∗, χ = argminL+ µ ·NLL(C |Θ) (8)
Step 2.",3.4 Generative Process and Model Learning,[0],[0]
"Sample topic and discourse assignments z and d at the message level and word type switcher x at the word level, using the distributions, computed according to parameters optimized in step 1:
Sample zc,m, dc,m, xc,m,n with probabilities p(zc,m = k) =",3.4 Generative Process and Model Learning,[0],[0]
"θc,k
p(dc,m = d) = πuc,m,d p(xc,m,n = BACK) = φ B wc,m,nτdc,m,BACK p(xc,m,n = DISC) = φ D dc,m,wc,m,nτdc,m,DISC p(xc,m,n = TOPIC) = φ T zc,m,wc,m,nτdc,m,TOPIC
(9)
Step 2 is analogous to Gibbs Sampling (Griffiths, 2002) in probabilistic graphical models, such as LDA (Blei et al., 2003).",3.4 Generative Process and Model Learning,[0],[0]
"However, distinguishing from previous models, the multinomial distributions in our models are not drawn from a Dirichlet prior.",3.4 Generative Process and Model Learning,[0],[0]
"Instead, they are computed based on the parameters learned in Step 1.
",3.4 Generative Process and Model Learning,[0],[0]
"Our learning process stops when the change of parameters is small (i.e., below a pre-specified
threshold).",3.4 Generative Process and Model Learning,[0],[0]
"Multiple restarts are tried, and similar results are achieved.",3.4 Generative Process and Model Learning,[0],[0]
Datasets.,4 Experimental Setup,[0],[0]
"We collected two microblog conversation datasets from Twitter for experiments3: one contains discussions about the U.S. presidential election (henceforth US Election), the other gathers conversations of diverse topics based on the tweets released by TREC 2011 microblog track (henceforth TREC)4.",4 Experimental Setup,[0],[0]
"US Election was collected from January to June of 2016 using Twitter’s Streaming API5 with a small set of political keywords.6 To recover conversations, Tweet Search API7 was used to retrieve messages with the “inreply-to” relations to collect tweets in a recursive way until full conversations were recovered.
",4 Experimental Setup,[0],[0]
Statistics of the datasets are shown in Table 1.,4 Experimental Setup,[0],[0]
Figure 3 displays the number of conversations individual users participated in.,4 Experimental Setup,[0],[0]
"As can be seen, most users are involved in only a few conversations.",4 Experimental Setup,[0],[0]
"Simply leveraging personal chat history will not produce good performance for conversation
3The datasets are available at http://www.ccs. neu.edu/home/luwang/
4 http://trec.nist.gov/data/tweets/ 5https://developer.twitter.com/
en/docs/tweets/filter-realtime/ api-reference/post-statuses-filter.html
6Keyword list: “trump”, “hillary”, “clinton”, “president”, “politics”, and “election.”
",4 Experimental Setup,[0],[0]
"7https://developer.twitter.com/en/ docs/tweets/search/api-reference/ get-saved_searches-show-id
recommendation.",4 Experimental Setup,[0],[0]
"In our experiments, we predict whether a user will engage in a conversation given the previous messages in that conversation and past conversations the user is involved.",4 Experimental Setup,[0],[0]
"For model training and testing, we divide conversations into three ordered segments, corresponding to training, development, and test sets at 75%, 12.5%, and 12.5%.8
Preprocessing and Hyperparameter Tuning.",4 Experimental Setup,[0],[0]
"For preprocessing, links, mentions (i.e., @username), and hashtags in tweets were replaced with generic tags of “URL”, “MENTION”, and “HASHTAG”.",4 Experimental Setup,[0],[0]
We then utilized the Twitter NLP tool9,4 Experimental Setup,[0],[0]
"(Gimpel et al., 2011; Owoputi et al., 2013) for tokenization and non-alphabetic token removal.",4 Experimental Setup,[0],[0]
We removed stop words and punctuations for all comparisons to ensure comparable performance.,4 Experimental Setup,[0],[0]
"We maintain a vocabulary with the 5,000 most frequent words.
",4 Experimental Setup,[0],[0]
"Our model parameters are tuned on the development set based on grid search, i.e. the parameters that give the lowest value for our objective are selected.",4 Experimental Setup,[0],[0]
"Specifically, the number of discourse modes (D) and topics (K) are tuned to be 10.",4 Experimental Setup,[0],[0]
"The trade-off parameter µ between user preference and corpus negative log-likelihood takes value of 0.1, and λ, the parameter for balancing topic and discourse, is set to 0.5.",4 Experimental Setup,[0],[0]
"Finally, the confidence parameter s takes a value of 200 to give higher weight for positive instances, i.e., a user replied to a conversation.
",4 Experimental Setup,[0],[0]
Evaluation Metrics.,4 Experimental Setup,[0],[0]
"Following prior work on social media post recommendation (Chen et al., 2012; Yan et al., 2012), we treat our task on conversation recommendation as a ranking problem.",4 Experimental Setup,[0],[0]
"Therefore, popular information retrieval evaluation metrics, including precision at K (P@K), mean average precision (MAP) (Manning et al., 2008), and normalized Discounted Cumulative Gain at K (nDCG@K) (Järvelin and Kekäläinen, 2002) are reported.",4 Experimental Setup,[0],[0]
The metrics are computed per user in the dataset and then averaged over all users.,4 Experimental Setup,[0],[0]
"The values range from 0.0 to 1.0, with higher values indicating better performance.
",4 Experimental Setup,[0],[0]
Baselines and Comparisons.,4 Experimental Setup,[0],[0]
"For comparison, we first consider three baselines: 1) ranking
8At least one turn per conversation is retained for training.",4 Experimental Setup,[0],[0]
"It is possible that one user only replies in either development set or test set, but it is rather infrequent.
",4 Experimental Setup,[0],[0]
"9http://www.cs.cmu.edu/˜ark/TweetNLP/
conversations randomly (RANDOM); 2) longer conversations (i.e., more words) ranked higher (LENGTH); 3) conversations with more distinct users ranked higher (POPULARITY).
",4 Experimental Setup,[0],[0]
"We further compare results with three established recommendation models: • OCCF: one-class Collaborative Filtering (Pan et al., 2008), which only considers users’ reply history without modeling content in conversations.",4 Experimental Setup,[0],[0]
• RSVM:,4 Experimental Setup,[0],[0]
"ranking SVM (Joachims, 2002), which ranks conversations for each user with the content and Twitter features as in Duan et al. (2010).",4 Experimental Setup,[0],[0]
"• CTR: messages in one conversation are aggregated into one post and a state-of-the art Collaborative Filtering-based post recommendation model is applied (Chen et al., 2012).
",4 Experimental Setup,[0],[0]
"Finally, we also adapt the “hidden factors as topics” (HFT) model proposed in McAuley and Leskovec (2013) (henceforth ADAPTED HFT).",4 Experimental Setup,[0],[0]
"Because the original model leverages the ratings for all product reviews and does not handle implicit user feedback well, we replace their user preference objective function with ours (Eq. 2).",4 Experimental Setup,[0],[0]
"In this section, we first discuss our main evaluation in Section 5.1.",5 Experimental Results,[0],[0]
"A case study and corresponding discussion are provided in Section 5.2 to provide further insights, which is followed by an analysis of the topics and discourse modes discovered by our model (Section 5.3).",5 Experimental Results,[0],[0]
We also examine our performance on first time replies (Section 5.4).,5 Experimental Results,[0],[0]
"Experimental results are displayed in Table 2, where our model yields statistically significantly better results than baselines and comparisons
(paired t-tests, p < 0.01).",5.1 Conversation Recommendation Results,[0],[0]
"For P@K, we only report P@1, because a significant amount of users participate only in 1 or 2 conversations.",5.1 Conversation Recommendation Results,[0],[0]
"For nDCG@K, different K values are experimented, which results in similar trend, so only nDCG@5 is reported.
",5.1 Conversation Recommendation Results,[0],[0]
"We find that the baselines that rank conversations with simple features (e.g., length or popularity) perform poorly.",5.1 Conversation Recommendation Results,[0],[0]
"This implies that generic algorithms that do not consider conversation content or user preference cannot produce reasonable recommendations.
",5.1 Conversation Recommendation Results,[0],[0]
"Although some non-baseline systems capture content in one way or another, only ADAPTED HFT and our model exploit latent topic models to better represent content in tweets, and outperform other methods.
",5.1 Conversation Recommendation Results,[0],[0]
"Compared to ADAPTED HFT, which only considers latent topics under a collaborative filtering framework, our model extracts both topics and discourse modes as latent variables, and shows superior performance on both datasets.",5.1 Conversation Recommendation Results,[0],[0]
"Our discourse variables go beyond topical content to capture social behaviors that affect user engagement, such as
arguments, question-asking, agreement, and other discourse modes.
",5.1 Conversation Recommendation Results,[0],[0]
Training with Varying Conversation History.,5.1 Conversation Recommendation Results,[0],[0]
"To test the model performance based different levels of user engagement history, we further experiment with varying the length of conversations for training.",5.1 Conversation Recommendation Results,[0],[0]
"Specifically, in addition to using 75% of conversation history, we also extract the first 25% and 50% of history as training.",5.1 Conversation Recommendation Results,[0],[0]
The rest of a conversation is separated equally for development and test.,5.1 Conversation Recommendation Results,[0],[0]
Figure 4 shows the MAP scores for US Election and TREC datasets.,5.1 Conversation Recommendation Results,[0],[0]
"The increasing MAP for all methods as the training history increases indicates that generally, conversation history is essential for recommendation.",5.1 Conversation Recommendation Results,[0],[0]
"Our model performs consistently better over different lengths of conversation histories.
",5.1 Conversation Recommendation Results,[0],[0]
Results for Varying Degree of Data Sparsity.,5.1 Conversation Recommendation Results,[0],[0]
"From Table 1 and Figure 3, we observe that most users in our datasets are involved in only a few conversations.",5.1 Conversation Recommendation Results,[0],[0]
"In order to study the effects of data sparsity on recommendation models, we examine in Figure 5 the MAP scores for users engaged in a varying number of conversations, as measured on the TREC dataset.",5.1 Conversation Recommendation Results,[0],[0]
The results on the US Election dataset have similar distributions.,5.1 Conversation Recommendation Results,[0],[0]
"As we see, the prediction results become worse for users involved in fewer conversations.",5.1 Conversation Recommendation Results,[0],[0]
This indicates that data sparsity serves as a challenge for all recommendation models.,5.1 Conversation Recommendation Results,[0],[0]
We also observe that our model performs consistently better than other models over different degrees of sparsity.,5.1 Conversation Recommendation Results,[0],[0]
"This implies that effectively capturing discourse structure in conversation context is useful to mitigating the effects of
data sparsity on conversation recommendation.",5.1 Conversation Recommendation Results,[0],[0]
Here we present a case study based on the sample conversations in Figure 1.,5.2 Case Study and Discussion,[0],[0]
"Recall that user U1 is interested in conversations about Sanders, and also prefers more argumentative discourse, and thus returns in conversation c2 but not c1.
",5.2 Case Study and Discussion,[0],[0]
"Table 3 shows the predicted scores for the two conversations from OCCF, ADAPTED HFT, and our model (as in Eq. 2).",5.2 Case Study and Discussion,[0],[0]
"Both ADAPTED HFT and our model more accurately recommend c2 over c1, with our model producing a slightly higher recommendation score for c2.
",5.2 Case Study and Discussion,[0],[0]
Table 4 shows the latent dimension values for the learned topics and discourse modes for this user and these two conversations.,5.2 Case Study and Discussion,[0],[0]
"Based on human inspection, topic 1 appears to contain words about Sanders, which is the main topic in conversation c2.",5.2 Case Study and Discussion,[0],[0]
"Topic 2 is about Clinton, which is a dominating topic in conversation c1.",5.2 Case Study and Discussion,[0],[0]
"Our model also picks up user interest in topic 1 (Sanders), and thus assigns γUu1,1 a high value.",5.2 Case Study and Discussion,[0],[0]
"For discourse modes, our model also generates a high score for “argument” discourse (labeled via human inspection) for both the user and c2.",5.2 Case Study and Discussion,[0],[0]
Ablation Study.,5.3 Further Analysis of Topic and Discourse,[0],[0]
"We have shown that joint modeling of topical content and discourse modes produces the superior performance for our model.
",5.3 Further Analysis of Topic and Discourse,[0],[0]
Here we provide an ablation study to examine the relative contributions of those two aspects by setting the trade-off parameter λ to 1.0 (topic only) or 0.0 (discourse only).,5.3 Further Analysis of Topic and Discourse,[0],[0]
"Table 5 shows that topics or discourse individually improve slightly upon the comparison ADAPTED HFT, but only jointly do they improve significantly upon it.
",5.3 Further Analysis of Topic and Discourse,[0],[0]
Topic Coherence.,5.3 Further Analysis of Topic and Discourse,[0],[0]
"To examine the quality of topics found by our model, we use the CV topic coherence score measured via the open-source toolkit Palmetto10, which has been shown to produce evaluation performance comparable to human judgment (Röder et al., 2015).",5.3 Further Analysis of Topic and Discourse,[0],[0]
"Our model achieves topic coherence scores of 0.343 and 0.376 on TREC and US Election datasets, compared to 0.338 and 0.371 for the topics from ADAPTED HFT.
",5.3 Further Analysis of Topic and Discourse,[0],[0]
Sample Discourse Modes.,5.3 Further Analysis of Topic and Discourse,[0],[0]
"While our topic word distributions are relatively unsurprising, of greater interest are the discourse mode word distributions.",5.3 Further Analysis of Topic and Discourse,[0],[0]
Table 6 shows a sample of discourse modes as labeled by human.,5.3 Further Analysis of Topic and Discourse,[0],[0]
"Although this is merely a qualitative human judgment at this point, there does appear to be a notable overlap in discourse modes between the two datasets even though they were learned separately.
",5.3 Further Analysis of Topic and Discourse,[0],[0]
10https://github.com/AKSW/Palmetto/,5.3 Further Analysis of Topic and Discourse,[0],[0]
"From a recommendation perspective, users may be interested in joining new conversations.",5.4 First Time Reply Results,[0],[0]
We thus compare each recommendation system for first time replies.,5.4 First Time Reply Results,[0],[0]
"For each user, we only evaluate for conversations where they are newcomers.",5.4 First Time Reply Results,[0],[0]
"Table 7 shows that, unsurprisingly, all systems perform poorly on this task, though our model performs slightly better.",5.4 First Time Reply Results,[0],[0]
"This suggests that other features, e.g., network structures or other discussion thread features, could usefully be included in future studies that target new conversations.",5.4 First Time Reply Results,[0],[0]
This paper has presented a framework for microblog conversation recommendation via jointly modeling topics and discourse modes.,6 Conclusion,[0],[0]
Experimental results show that our method can outperform competitive approaches that omit user discourse behaviors.,6 Conclusion,[0],[0]
Qualitative analysis shows that our joint model yields meaningful topics and discourse representations.,6 Conclusion,[0],[0]
This work is partly supported by Innovation and Technology Fund (ITF) Project,Acknowledgements,[0],[0]
"No. 6904333, General Research Fund (GRF) Project No. 14232816 (12183516), and National Science Foundation Grant IIS-1566382.",Acknowledgements,[0],[0]
"We thank Shuming Shi, Yan Song, and the three anonymous reviewers for the insightful suggestions on various aspects of this work.",Acknowledgements,[0],[0]
Millions of conversations are generated every day on social media platforms.,abstractText,[0],[0]
"With limited attention, it is challenging for users to select which discussions they would like to participate in.",abstractText,[0],[0]
Here we propose a new method for microblog conversation recommendation.,abstractText,[0],[0]
"While much prior work has focused on postlevel recommendation, we exploit both the conversational context, and user content and behavior preferences.",abstractText,[0],[0]
"We propose a statistical model that jointly captures: (1) topics for representing user interests and conversation content, and (2) discourse modes for describing user replying behavior and conversation dynamics.",abstractText,[0],[0]
Experimental results on two Twitter datasets demonstrate that our system outperforms methods that only model content without considering discourse.,abstractText,[0],[0]
Microblog Conversation Recommendation via Joint Modeling of Topics and Discourse,title,[0],[0]
"Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 102–112 Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics",text,[0],[0]
"One of the key advantages of word embeddings for natural language processing is that they enable generalization to words that are unseen in labeled training data, by embedding lexical features from large unlabeled datasets into a relatively low-dimensional Euclidean space.",1 Introduction,[0],[0]
"These low-dimensional embeddings are typically trained to capture distributional similarity, so that information can be shared among words that tend to appear in similar contexts.
",1 Introduction,[0],[0]
"However, it is not possible to enumerate the entire vocabulary of any language, and even large unlabeled datasets will miss terms that appear in later applications.",1 Introduction,[0],[0]
The issue of how to handle these out-of-vocabulary (OOV) words poses challenges for embedding-based methods.,1 Introduction,[0],[0]
"These challenges are particularly acute when working with lowresource languages, where even unlabeled data may be difficult to obtain at scale.",1 Introduction,[0],[0]
"A typical solution is to abandon hope, by assigning a single OOV embedding to all terms that do not appear in the unlabeled data.
",1 Introduction,[0],[0]
We approach this challenge from a quasigenerative perspective.,1 Introduction,[0],[0]
"Knowing nothing of a word except for its embedding and its written form, we attempt to learn the former from the latter.",1 Introduction,[0],[0]
"We train a recurrent neural network (RNN) on the character level with the embedding as the target, and use it later to predict vectors for OOV words in any downstream task.",1 Introduction,[0],[0]
"We call this model the MIMICK-RNN, for its ability to read a word’s spelling and mimick its distributional embedding.
",1 Introduction,[0],[0]
"Through nearest-neighbor analysis, we show that vectors learned via this method capture both word-shape features and lexical features.",1 Introduction,[0],[0]
"As a result, we obtain reasonable near-neighbors for OOV abbreviations, names, novel compounds, and orthographic errors.",1 Introduction,[0],[0]
"Quantitative evaluation on the Stanford RareWord dataset (Luong et al., 2013) provides more evidence that these character-based embeddings capture word similarity for rare and unseen words.
",1 Introduction,[0],[0]
"As an extrinsic evaluation, we conduct experiments on joint prediction of part-of-speech tags and morphosyntactic attributes for a diverse set of 23 languages, as provided in the Universal Dependencies dataset (De Marneffe et al., 2014).",1 Introduction,[0],[0]
"Our model shows significant improvement
102
across the board against a single UNK-embedding backoff method, and obtains competitive results against a supervised character-embedding model, which is trained end-to-end on the target task.",1 Introduction,[0],[0]
"In low-resource settings, our approach is particularly effective, and is complementary to supervised character embeddings trained from labeled data.",1 Introduction,[0],[0]
The MIMICK-RNN therefore provides a useful new tool for tagging tasks in settings where there is limited labeled data.,1 Introduction,[0],[0]
Models and code are available at www.github.com/ yuvalpinter/mimick .,1 Introduction,[0],[0]
Compositional models for embedding rare and unseen words.,2 Related Work,[0],[0]
"Several studies make use of morphological or orthographic information when training word embeddings, enabling the prediction of embeddings for unseen words based on their internal structure.",2 Related Work,[0],[0]
Botha and Blunsom (2014) compute word embeddings by summing over embeddings of the morphemes; Luong et al. (2013) construct a recursive neural network over each word’s morphological parse; Bhatia et al. (2016) use morpheme embeddings as a prior distribution over probabilistic word embeddings.,2 Related Work,[0],[0]
"While morphology-based approaches make use of meaningful linguistic substructures, they struggle with names and foreign language words, which include out-of-vocabulary morphemes.",2 Related Work,[0],[0]
"Character-based approaches avoid these problems: for example, Kim et al. (2016) train a recurrent neural network over words, whose embeddings are constructed by convolution over character embeddings; Wieting et al. (2016) learn embeddings of character ngrams, and then sum them into word embeddings.",2 Related Work,[0],[0]
"In all of these cases, the model for composing embeddings of subword units into word embeddings is learned by optimizing an objective over a large unlabeled corpus.",2 Related Work,[0],[0]
"In contrast, our approach is a post-processing step that can be applied to any set of word embeddings, regardless of how they were trained.",2 Related Work,[0],[0]
"This is similar to the “retrofitting” approach of Faruqui et al. (2015), but rather than smoothing embeddings over a graph, we learn a function to build embeddings compositionally.
",2 Related Work,[0],[0]
Supervised subword models.,2 Related Work,[0],[0]
Another class of methods learn task-specific character-based word embeddings within end-to-end supervised systems.,2 Related Work,[0],[0]
"For example, Santos and Zadrozny (2014) build word embeddings by convolution over char-
acters, and then perform part-of-speech (POS) tagging using a local classifier; the tagging objective drives the entire learning process.",2 Related Work,[0],[0]
"Ling et al. (2015) propose a multi-level long shortterm memory (LSTM; Hochreiter and Schmidhuber, 1997), in which word embeddings are built compositionally from an LSTM over characters, and then tagging is performed by an LSTM over words.",2 Related Work,[0],[0]
Plank et al. (2016) show that concatenating a character-level or bit-level LSTM network to a word representation helps immensely in POS tagging.,2 Related Work,[0],[0]
"Because these methods learn from labeled data, they can cover only as much of the lexicon as appears in their labeled training sets.",2 Related Work,[0],[0]
"As we show, they struggle in several settings: lowresource languages, where labeled training data is scarce; morphologically rich languages, where the number of morphemes is large, or where the mapping from form to meaning is complex; and in Chinese, where the number of characters is orders of magnitude larger than in non-logographic scripts.",2 Related Work,[0],[0]
"Furthermore, supervised subword models can be combined with MIMICK, offering additive improvements.
",2 Related Work,[0],[0]
Morphosyntactic attribute tagging.,2 Related Work,[0],[0]
"We evaluate our method on the task of tagging word tokens for their morphosyntactic attributes, such as gender, number, case, and tense.",2 Related Work,[0],[0]
"The task of morpho-syntactic tagging dates back at least to the mid 1990s (Oflazer and Kuruöz, 1994; Hajič and Hladká, 1998), and interest has been rejuvenated by the availability of large-scale multilingual morphosyntactic annotations through the Universal Dependencies (UD) corpus (De Marneffe et al., 2014).",2 Related Work,[0],[0]
"For example, Faruqui et al. (2016) propose a graph-based technique for propagating typelevel morphological information across a lexicon, improving token-level morphosyntactic tagging in 11 languages, using an SVM tagger.",2 Related Work,[0],[0]
"In contrast, we apply a neural sequence labeling approach, inspired by the POS tagger of Plank et al. (2016).",2 Related Work,[0],[0]
"We approach the problem of out-of-vocabulary (OOV) embeddings as a generation problem: regardless of how the original embeddings were created, we assume there is a generative wordformbased protocol for creating these embeddings.",3 MIMICK Word Embeddings,[0],[0]
"By training a model over the existing vocabulary, we can later use that model for predicting the embedding of an unseen word.
",3 MIMICK Word Embeddings,[0],[0]
"Formally: given a language L, a vocabulary V ⊆ L of size V , and a pre-trained embeddings table W ∈ RV×d where each word {wk}Vk=1 is assigned a vector ek of dimension d, our model is trained to find the function f :",3 MIMICK Word Embeddings,[0],[0]
L → Rd such that the projected function f |V approximates the assignments f(wk),3 MIMICK Word Embeddings,[0],[0]
≈ ek.,3 MIMICK Word Embeddings,[0],[0]
"Given such a model, a new word wk∗ ∈ L \ V can now be assigned an embedding ek∗ = f(wk∗).
",3 MIMICK Word Embeddings,[0],[0]
Our predictive function of choice is a Word Type Character Bi-LSTM.,3 MIMICK Word Embeddings,[0],[0]
"Given a word with character sequence w = {ci}n1 , a forward-LSTM and a backward-LSTM are run over the corresponding character embeddings sequence {e(c)i }n1 .",3 MIMICK Word Embeddings,[0],[0]
"Let hnf represent the final hidden vector for the forward-LSTM, and let h0b represent the final hidden vector for the backward-LSTM.",3 MIMICK Word Embeddings,[0],[0]
"The word embedding is computed by a multilayer perceptron:
(1)f(w) = OT · g(Th ·",3 MIMICK Word Embeddings,[0],[0]
"[hnf ; h0b ] + bh) + bT ,
where Th, bh and OT , bT are parameters of affine transformations, and g is a nonlinear elementwise function.",3 MIMICK Word Embeddings,[0],[0]
"The model is presented in Figure 1.
",3 MIMICK Word Embeddings,[0],[0]
The training objective is similar to that of Yin and Schütze (2016).,3 MIMICK Word Embeddings,[0],[0]
"We match the predicted embeddings f(wk) to the pre-trained word embeddings ewk , by minimizing the squared Euclidean distance,
(2)L = ‖f(wk)− ewk‖22 .
",3 MIMICK Word Embeddings,[0],[0]
"By backpropagating from this loss, it is possible to obtain local gradients with respect to the parameters of the LSTMs, the character embeddings, and the output model.",3 MIMICK Word Embeddings,[0.95099978333547],"['Recall that histories Λ record the choices of the algorithm, in addition to its observations.']"
"The ultimate output of the training phase is the character embeddings matrix C and the parameters of the neural network: M = {C,F,B,Th, bh,OT , bT }, where F,B are the forward and backward LSTM component parameters, respectively.",3 MIMICK Word Embeddings,[0],[0]
"The pretrained embeddings we use in our experiments are obtained from Polyglot (Al-Rfou et al., 2013), a multilingual word embedding effort.",3.1 MIMICK Polyglot Embeddings,[0],[0]
"Available for dozens of languages, each dataset contains 64-dimension embeddings for the 100,000 most frequent words in a language’s training corpus (of variable size), as well as an UNK embedding to be used for OOV words.",3.1 MIMICK Polyglot Embeddings,[0],[0]
"Even with this vocabulary size, querying words from respective UD corpora (train + dev + test) yields high
OOV rates: in at least half of the 23 languages in our experiments (see Section 5), 29.1% or more of the word types do not appear in the Polyglot vocabulary.",3.1 MIMICK Polyglot Embeddings,[0],[0]
"The token-level median rate is 9.2%.1
Applying our MIMICK algorithm to Polyglot embeddings, we obtain a prediction model for each of the 23 languages.",3.1 MIMICK Polyglot Embeddings,[0],[0]
"Based on preliminary testing on randomly selected held-out development sets of 1% from each Polyglot vocabulary (with error calculated as in Equation 2), we set the following hyper-parameters for the remainder of the experiments: character embedding dimension = 20; one LSTM layer with 50 hidden units; 60 training epochs with no dropout; nonlinearity function g =",3.1 MIMICK Polyglot Embeddings,[0],[0]
"tanh.2 We initialize character embeddings randomly, and use DyNet to implement the model (Neubig et al., 2017).
",3.1 MIMICK Polyglot Embeddings,[0],[0]
Nearest-neighbor examination.,3.1 MIMICK Polyglot Embeddings,[0],[0]
"As a preliminary sanity check for the validity of our protocol, we examined nearest-neighbor samples in languages for which speakers were available: English, Hebrew, Tamil, and Spanish.",3.1 MIMICK Polyglot Embeddings,[0],[0]
"Table 1 presents selected English OOV words with
1Some OOV counts, and resulting model performance, may be adversely affected by tokenization differences between Polyglot and UD.",3.1 MIMICK Polyglot Embeddings,[0],[0]
"Notably, some languages such as Spanish, Hebrew and Italian exhibit relational synthesis wherein words of separate grammatical phrases are joined into one form (e.g. Spanish del = de + el, ‘from the-masc.sg.’).",3.1 MIMICK Polyglot Embeddings,[0],[0]
"For these languages, the UD annotations adhere to the sub-token level, while Polyglot does not perform subtokenization.",3.1 MIMICK Polyglot Embeddings,[0],[0]
"As this is a real-world difficulty facing users of out-of-the-box embeddings, we do not patch it over in our implementations or evaluation.
",3.1 MIMICK Polyglot Embeddings,[0],[0]
"2Other settings, described below, were tuned on the supervised downstream tasks.
",3.1 MIMICK Polyglot Embeddings,[0],[0]
their nearest in-vocabulary Polyglot words computed by cosine similarity.,3.1 MIMICK Polyglot Embeddings,[0],[0]
"These examples demonstrate several properties: (a) word shape is learned well (acronyms, capitalizations, suffixes); (b) the model shows robustness to typos (e.g., developiong, corssing); (c) part-of-speech is learned across multiple suffixes (pesky – euphoric, ghastly); (d) word compounding is detected (e.g., lawnmower – bookmaker, postman); (e) semantics are not learned well (as is to be expected from the lack of context in training), but there are surprises (e.g., flatfish – slimy, watery).",3.1 MIMICK Polyglot Embeddings,[0.9528339475428265],"['(Tossou & Dimitrakakis, 2016) There is an - differentially private algorithm that obtains expected regret bounded by: O ( max ( lnT · (ln ln(T ) + ln(1/ )) , √ kT log T )) Thus, we can take to be as small as = O( ln 1.5 T√ kT ) while still having a regret bound of O( √ kT log T ), which is nearly optimal in the worst case (over instances) (Audibert & Bubeck, 2009).']"
"Table 2 presents examples from Hebrew that show learned properties can be extended to nominal morphosyntactic attributes (gender, number – first two examples) and even relational syntactic subword forms such as genetive markers (third example).",3.1 MIMICK Polyglot Embeddings,[0],[0]
Names are learned (fourth example) despite the lack of casing in the script.,3.1 MIMICK Polyglot Embeddings,[0],[0]
"Spanish examples exhibit wordshape and part-of-speech learning patterns with some loose semantics: for example, the plural adjective form prenatales is similar to other familyrelated plural adjectives such as patrimoniales and generacionales.",3.1 MIMICK Polyglot Embeddings,[0],[0]
"Tamil displays some semantic similarities as well: e.g. enjineer (‘engineer’) predicts similarity to other professional terms such as kalviyiyal (‘education’), thozhilnutpa (‘technical’), and iraanuva (‘military’).
",3.1 MIMICK Polyglot Embeddings,[0],[0]
Stanford RareWords.,3.1 MIMICK Polyglot Embeddings,[0],[0]
"The Stanford RareWord evaluation corpus (Luong et al., 2013) focuses on predicting word similarity between pairs involving low-frequency English words, predominantly ones with common morphological affixes.",3.1 MIMICK Polyglot Embeddings,[0],[0]
"As these words are unlikely to be above the cutoff threshold for standard word embedding models, they emphasize the performance on OOV words.
",3.1 MIMICK Polyglot Embeddings,[0],[0]
"For evaluation of our MIMICK model on the RareWord corpus, we trained the Variational Embeddings algorithm (VarEmbed; Bhatia et al., 2016) on a 20-million-token, 100,000- type Wikipedia corpus, obtaining 128-dimension
word embeddings for all words in the test corpus.",3.1 MIMICK Polyglot Embeddings,[0],[0]
"VarEmbed estimates a prior distribution over word embeddings, conditional on the morphological composition.",3.1 MIMICK Polyglot Embeddings,[0],[0]
"For in-vocabulary words, a posterior is estimated from unlabeled data; for outof-vocabulary words, the expected embedding can be obtained from the prior alone.",3.1 MIMICK Polyglot Embeddings,[0],[0]
"In addition, we compare to FastText (Bojanowski et al., 2016), a high-vocabulary, high-dimensionality embedding benchmark.
",3.1 MIMICK Polyglot Embeddings,[0],[0]
"The results, shown in Table 3, demonstrate that the MIMICK RNN recovers about half of the loss in performance incurred by the original Polyglot training model due to out-of-vocabulary words in the “All pairs” condition.",3.1 MIMICK Polyglot Embeddings,[0],[0]
MIMICK also outperforms VarEmbed.,3.1 MIMICK Polyglot Embeddings,[0],[0]
"FastText can be considered an upper bound: with a vocabulary that is 25 times larger than the other models, it was missing words from only 44 pairs on this data.",3.1 MIMICK Polyglot Embeddings,[0],[0]
"The Universal Dependencies (UD) scheme (De Marneffe et al., 2014) features a minimal set of 17 POS tags (Petrov et al., 2012) and supports tagging further language-specific features using attribute-specific inventories.",4 Joint Tagging of Parts-of-Speech and Morphosyntactic Attributes,[0],[0]
"For example, a verb in Turkish could be assigned a value for the evidentiality attribute, one which is absent from Danish.",4 Joint Tagging of Parts-of-Speech and Morphosyntactic Attributes,[0],[0]
"These additional morphosyntactic attributes are marked in the UD dataset as optional per-token attribute-value pairs.
",4 Joint Tagging of Parts-of-Speech and Morphosyntactic Attributes,[0],[0]
"Our approach for tagging morphosyntactic attributes is similar to the part-of-speech tagging model of Ling et al. (2015), who attach a projection layer to the output of a sentence-level bidirectional LSTM.",4 Joint Tagging of Parts-of-Speech and Morphosyntactic Attributes,[0],[0]
We extend this approach to morphosyntactic tagging by duplicating this projection layer for each attribute type.,4 Joint Tagging of Parts-of-Speech and Morphosyntactic Attributes,[0],[0]
"The input to our multilayer perceptron (MLP) projection network is the hidden state produced for each token in the sentence by an underlying LSTM, and the output is
attribute-specific probability distributions over the possible values for each attribute on each token in the sequence.",4 Joint Tagging of Parts-of-Speech and Morphosyntactic Attributes,[0],[0]
"Formally, for a given attribute a with possible values v ∈ Va, the tagging probability for the i’th word in a sentence is given by:
Pr(awi = v) =",4 Joint Tagging of Parts-of-Speech and Morphosyntactic Attributes,[0],[0]
"(Softmax(φ(hi)))v , (3)
with
(4)φ(hi) = OaW · tanh(Wah ·",4 Joint Tagging of Parts-of-Speech and Morphosyntactic Attributes,[0],[0]
"hi + bah) + baW ,
where hi is the i’th hidden state in the underlying LSTM, and φ(hi) is a two-layer feedforward neural network, with weights Wah and O a W .",4 Joint Tagging of Parts-of-Speech and Morphosyntactic Attributes,[0],[0]
We apply a softmax transformation to the output; the value at position v is then equal to the probability of attribute v applying to token wi.,4 Joint Tagging of Parts-of-Speech and Morphosyntactic Attributes,[0],[0]
"The input to the underlying LSTM is a sequence of word embeddings, which are initialized to the Polyglot vectors when possible, and to MIMICK vectors when necessary.",4 Joint Tagging of Parts-of-Speech and Morphosyntactic Attributes,[0],[0]
"Alternative initializations are considered in the evaluation, as described in Section 5.2.
",4 Joint Tagging of Parts-of-Speech and Morphosyntactic Attributes,[0],[0]
Each tagged attribute sequence (including POS tags) produces a loss equal to the sum of negative log probabilities of the true tags.,4 Joint Tagging of Parts-of-Speech and Morphosyntactic Attributes,[0],[0]
One way to combine these losses is to simply compute the sum loss.,4 Joint Tagging of Parts-of-Speech and Morphosyntactic Attributes,[0],[0]
"However, many languages have large differences in sparsity across morpho-syntactic attributes, as apparent from Table 4 (rightmost column).",4 Joint Tagging of Parts-of-Speech and Morphosyntactic Attributes,[0],[0]
"We therefore also compute a weighted sum
loss, in which each attribute is weighted by the proportion of training corpus tokens on which it is assigned a non-NONE value.",4 Joint Tagging of Parts-of-Speech and Morphosyntactic Attributes,[0],[0]
"Preliminary experiments on development set data were inconclusive across languages and training set sizes, and so we kept the simpler sum loss objective for the remainder of our study.",4 Joint Tagging of Parts-of-Speech and Morphosyntactic Attributes,[0],[0]
"In all cases, part-of-speech tagging was less accurate when learned jointly with morphosyntactic attributes.",4 Joint Tagging of Parts-of-Speech and Morphosyntactic Attributes,[0],[0]
This may be because the attribute loss acts as POS-unrelated “noise” affecting the common LSTM layer and the word embeddings.,4 Joint Tagging of Parts-of-Speech and Morphosyntactic Attributes,[0],[0]
The morphological complexity and compositionality of words varies greatly across languages.,5 Experimental Settings,[0],[0]
"While a morphologically-rich agglutinative language such as Hungarian contains words that carry many attributes as fully separable morphemes, a sentence in an analytic language such as Vietnamese may have not a single polymorphemic or inflected word in it.",5 Experimental Settings,[0],[0]
"To see whether this property is influential on our MIMICK model and its performance in the downstream tagging task, we select languages that comprise a sample of multiple morphological patterns.",5 Experimental Settings,[0],[0]
"Language family and script type are other potentially influential factors in an orthography-based approach such as ours, and so we vary along these parameters as well.",5 Experimental Settings,[0],[0]
"We also considered language selection recommendations from de Lhoneux and Nivre (2016) and Schluter and Agić (2017).
",5 Experimental Settings,[0],[0]
"As stated above, our approach is built on the Polyglot word embeddings.",5 Experimental Settings,[0],[0]
The intersection of the Polyglot embeddings and the UD dataset (version 1.4) yields 44 languages.,5 Experimental Settings,[0],[0]
"Of these, many are under-annotated for morphosyntactic attributes; we select twenty-three sufficiently-tagged languages, with the exception of Indonesian.3 Table 4 presents the selected languages and their typological properties.",5 Experimental Settings,[0],[0]
"As an additional proxy for mor-
3Vietnamese has no attributes by design; it is a pure analytic language.
",5 Experimental Settings,[0],[0]
"phological expressiveness, the rightmost column shows the proportion of UD tokens which are annotated with any morphosyntactic attribute.",5 Experimental Settings,[0],[0]
"As noted above, we use the UD datasets for testing our MIMICK algorithm on 23 languages4 with the supplied train/dev/test division.",5.1 Metrics,[0],[0]
"We measure partof-speech tagging by overall token-level accuracy.
",5.1 Metrics,[0],[0]
"For morphosyntactic attributes, there does not seem to be an agreed-upon metric for reporting performance.",5.1 Metrics,[0],[0]
Dzeroski et al. (2000) report pertag accuracies on a morphosyntactically tagged corpus of Slovene.,5.1 Metrics,[0],[0]
"Faruqui et al. (2016) report macro-averages of F1 scores of 11 languages from UD 1.1 for the various attributes (e.g., part-ofspeech, case, gender, tense); recall and precision were calculated for the full set of each attribute’s values, pooled together.5",5.1 Metrics,[0],[0]
Agić,5.1 Metrics,[0],[0]
"et al. (2013) report separately on parts-of-speech and morphosyntactic attribute accuracies in Serbian and Croatian, as well as precision, recall, and F1 scores per tag.",5.1 Metrics,[0],[0]
"Georgiev et al. (2012) report token-level accuracy for exact all-attribute tags (e.g. ‘Ncmsh’ for “Noun short masculine singular definite”) in Bulgarian, reaching a tagset of size 680.",5.1 Metrics,[0],[0]
Müller et al. (2013) do the same for six other languages.,5.1 Metrics,[0],[0]
"We report micro F1: each token’s value for each attribute is compared separately with the gold labeling, where a correct prediction is a matching non-NONE attribute/value assignment.",5.1 Metrics,[0],[0]
"Recall and
4When several datasets are available for a language, we use the unmarked corpus.
5Details were clarified in personal communication with the authors.
precision are calculated over the entire set, with F1 defined as their harmonic mean.",5.1 Metrics,[0],[0]
"We implement and test the following models:
No-Char.",5.2 Models,[0],[0]
"Word embeddings are initialized from Polyglot models, with unseen words assigned the Polyglot-supplied UNK vector.",5.2 Models,[0],[0]
"Following tuning experiments on all languages with cased script, we found it beneficial to first back off to the lowercased form for an OOV word if its embedding exists, and only otherwise assign UNK.
MIMICK.",5.2 Models,[0],[0]
"Word embeddings are initialized from Polyglot, with OOV embeddings inferred from a MIMICK model (Section 3) trained on the Polyglot embeddings.",5.2 Models,[0],[0]
"Unlike the No-Char case, backing off to lowercased embeddings before using the MIMICK output did not yield conclusive benefits and thus we report results for the more straightforward no-backoff implementation.
CHAR→TAG.",5.2 Models,[0],[0]
"Word embeddings are initialized from Polyglot as in the No-Char model (with lowercase backoff), and appended with the output of a character-level LSTM updated during training (Plank et al., 2016).",5.2 Models,[0],[0]
"This additional module causes a threefold increase in training time.
",5.2 Models,[0],[0]
Both.,5.2 Models,[0],[0]
"Word embeddings are initialized as in MIMICK, and appended with the CHAR→TAG LSTM.
",5.2 Models,[0],[0]
Other models.,5.2 Models,[0],[0]
"Several non-Polyglot embedding models were examined, all performed substantially worse than Polyglot.",5.2 Models,[0],[0]
"Two of these
are notable: a random-initialization baseline, and a model initialized from FastText embeddings (tested on English).",5.2 Models,[0],[0]
"FastText supplies 300-dimension embeddings for 2.51 million lowercase-only forms, and no UNK vector.6 Both of these embedding models were attempted with and without CHAR→TAG concatenation.",5.2 Models,[0],[0]
"Another model, initialized from only MIMICK output embeddings, performed well only on the language with smallest Polyglot training corpus (Latvian).",5.2 Models,[0],[0]
"A Polyglot model where OOVs were initialized using an averaged embedding of all Polyglot vectors, rather than the supplied UNK vector, performed worse than our No-Char baseline on a great majority of the languages.
",5.2 Models,[0],[0]
"Last, we do not employ type-based tagset restrictions.",5.2 Models,[0],[0]
All tag inventories are computed from the training sets and each tag selection is performed over the full set.,5.2 Models,[0],[0]
"Based on development set experiments, we set the following hyperparameters for all models on all languages: two LSTM layers of hidden size 128, MLP hidden layers of size equal to the number of each attribute’s possible values; momentum stochastic gradient descent with 0.01 learning rate; 40 training epochs (80 for 5K settings) with a dropout rate of 0.5.",5.3 Hyperparameters,[0],[0]
The CHAR→TAG models use 20-dimension character embeddings and a single hidden layer of size 128.,5.3 Hyperparameters,[0],[0]
We report performance in both low-resource and full-resource settings.,6 Results,[0],[0]
"Low-resource training sets were obtained by randomly sampling training sentences, without replacement, until a predefined token limit was reached.",6 Results,[0],[0]
We report the results on the full sets and on N = 5000 tokens in Table 5 (partof-speech tagging accuracy) and Table 6 (morphosyntactic attribute tagging micro-F1).,6 Results,[0],[0]
"Results for additional training set sizes are shown in Figure 2; space constraints prevent us from showing figures for all languages.
MIMICK as OOV initialization.",6 Results,[0],[0]
"In nearly all experimental settings on both tasks, across languages and training corpus sizes, the MIMICK embeddings significantly improve over the Polyglot UNK embedding for OOV tokens on both
6Vocabulary type-level coverage for the English UD corpus: 55.6% case-sensitive, 87.9% case-insensitive.
",6 Results,[0],[0]
POS and morphosyntactic tagging.,6 Results,[0],[0]
"For POS, the largest margins are in the Slavic languages (Russian, Czech, Bulgarian), where word order is relatively free and thus rich word representations are imperative.",6 Results,[0],[0]
"Chinese also exhibits impressive improvement across all settings, perhaps due to the large character inventory (> 12,000), for which a model such as MIMICK can learn well-informed embeddings using the large Polyglot vocabulary dataset, overcoming both word- and characterlevel sparsity in the UD",6 Results,[0],[0]
"corpus.7 In morphosyntactic tagging, gains are apparent for Slavic languages and Chinese, but also for agglutinative languages — especially Tamil and Turkish — where the stable morpheme representation makes it easy for subword modeling to provide a type-level signal.8 To examine the effects on Slavic and agglutinative languages in a more fine-grained view, we present results of multiple training-set size experiments for each model, averaged over five repetitions (with different corpus samples), in Figure 2.
MIMICK vs. CHAR→TAG.",6 Results,[0],[0]
"In several languages, the MIMICK algorithm fares better than the CHAR→TAG model on part-of-speech tagging in low-resource settings.",6 Results,[0],[0]
"Table 7 presents the POS tagging improvements that MIMICK achieves over the pre-trained Polyglot models, with and without CHAR→TAG concatenation, with 10,000 tokens of training data.",6 Results,[0],[0]
"We obtain statistically significant improvements in most languages, even when CHAR→TAG is included.",6 Results,[0],[0]
"These improvements are particularly substantial for test-set tokens outside the UD training set, as shown in the right two columns.",6 Results,[0],[0]
"While test set OOVs are a strength of the CHAR→TAG model (Plank et al., 2016), in many languages there are still considerable improvements to be obtained from the application of MIMICK initialization.",6 Results,[0],[0]
"This suggests that with limited training data, the end-to-end CHAR→TAG model is unable to learn a sufficiently accurate representational mapping from orthography.",6 Results,[0],[0]
"We present a straightforward algorithm to infer OOV word embedding vectors from pre-trained,
7Character coverage in Chinese Polyglot is surprisingly good: only eight characters from the UD dataset are unseen in Polyglot, across more than 10,000 unseen word types.
",7 Conclusion,[0],[0]
8Persian is officially classified as agglutinative but it is mostly so with respect to derivations.,7 Conclusion,[0],[0]
"Its word-level inflections are rare and usually fusional.
limited-vocabulary models, without need to access the originating corpus.",7 Conclusion,[0],[0]
"This method is particularly useful for low-resource languages and tasks with little labeled data available, and in fact is task-agnostic.",7 Conclusion,[0],[0]
"Our method improves performance over word-based models on annotated sequence-tagging tasks for a large variety of languages across dimensions of family, orthography, and morphology.",7 Conclusion,[0],[0]
"In addition, we present a BiLSTM approach for tagging morphosyntactic attributes at the token level.",7 Conclusion,[0],[0]
"In this paper, the MIMICK model was trained using characters as input, but future work may consider the use of other subword units, such as morphemes, phonemes, or even bitmap representations of ideographic characters (Costa-jussà et al., 2017).",7 Conclusion,[0],[0]
"We thank Umashanthi Pavalanathan, Sandeep Soni, Roi Reichart, and our anonymous reviewers for their valuable input.",8 Acknowledgments,[0],[0]
We thank Manaal Faruqui and Ryan McDonald for their help in understanding the metrics for morphosyntactic tagging.,8 Acknowledgments,[0],[0]
The project was supported by project HDTRA1-15-10019 from the Defense Threat Reduction Agency.,8 Acknowledgments,[0],[0]
"Word embeddings improve generalization over lexical features by placing each word in a lower-dimensional space, using distributional information obtained from unlabeled data.",abstractText,[0],[0]
"However, the effectiveness of word embeddings for downstream NLP tasks is limited by out-of-vocabulary (OOV) words, for which embeddings do not exist.",abstractText,[0],[0]
"In this paper, we present MIMICK, an approach to generating OOV word embeddings compositionally, by learning a function from spellings to distributional embeddings.",abstractText,[0],[0]
"Unlike prior work, MIMICK does not require re-training on the original word embedding corpus; instead, learning is performed at the type level.",abstractText,[0],[0]
Intrinsic and extrinsic evaluations demonstrate the power of this simple approach.,abstractText,[0],[0]
"On 23 languages, MIMICK improves performance over a word-based baseline for tagging part-of-speech and morphosyntactic attributes.",abstractText,[0],[0]
It is competitive with (and complementary to) a supervised characterbased model in low-resource settings.,abstractText,[0],[0]
Mimicking Word Embeddings using Subword RNNs,title,[0],[0]
The sheer number and variety of online social networks (OSN) today is staggering.,1. Introduction,[0],[0]
"Although the purpose and the shaping of these networks vary generously, the majority of them has one aspect in common: the value of most OSNs is in its user data and the information that one can infer from the data.",1. Introduction,[0],[0]
"This, unfortunately, results in a big incentive for culprits to intrude OSNs and manipulate their data.",1. Introduction,[0],[0]
"One popular method of intruding and attacking an OSN is referred to as Sybil attack, where the intruder creates a whole bunch of fake (Sybil) accounts that are all under the attacker’s control.",1. Introduction,[0],[0]
"The intruder’s influence over the OSN
1MathPlan, 10587 Berlin, Germany 2Machine Learning Group, Berlin Institute of Technology, 10587 Berlin, Germany 3Berlin Big Data Center 4Max Planck Society 5Korea University.",1. Introduction,[0],[0]
Correspondence to: János,1. Introduction,[0],[0]
Höner <,1. Introduction,[0],[0]
"janos.hoener@campus.tuberlin.de>, Nico Görnitz <nico.goernitz@tu-berlin.de>, KlausRobert Müller <klaus-robert.mueller@tu-berlin.de>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
is multiplied by the number of accounts created, which opens possibilities of manipulation typically for gaining some monetary advantage in the end.
",1. Introduction,[0],[0]
"The term, Sybil attack, was coined by Douceur (2002) who showed that this kind of attack will be always possible unless a trusted agency certifies identities.",1. Introduction,[0],[0]
"Unfortunately, this approach is orthogonal to how OSNs grow.",1. Introduction,[0],[0]
The threshold of registration must be as low as possible to attract as many new users as possible.,1. Introduction,[0],[0]
"On the other hand, Sybil attacks can damage the value of OSNs significantly, which has been proved by the fact that Facebook shares dropped in 2012 after the company revealed that a significant share of its network is made up by Sybil accounts (The Associated Press, 2012).
",1. Introduction,[0],[0]
"There exists a number of “classic” feature-based solutions (Stein et al., 2011; Cao et al., 2012; Stringhini et al., 2010; Yang et al., 2014).",1. Introduction,[0],[0]
"However, up until now, it remains an unsolved problem as those methods can be evaded by cleverly designed attacking schemes (Bilge et al., 2009; Boshmaf et al., 2011; Wagner et al., 2012; Lowd & Meek, 2005) and manual detection is too expensive, time consuming, and simply unfeasible in large OSNs (Cao et al., 2012).
",1. Introduction,[0],[0]
More recent graph-based Sybil detection methods assume that honest (non-Sybil) nodes form a strongly connected subgraph and attackers can establish a limited amount of edges which leads to a sparse cut between the honest subraph and the Sybil nodes.,1. Introduction,[0],[0]
"The majority of the graph-based methods define trusted nodes, which the defender is sure to be honest, and use random walks (Yu et al., 2010; Danezis, 2009; Cao et al., 2012) or other typical graph-based algorithms like breadth-first-search (Tran et al., 2011) and belief propagation (Gong et al., 2014) to convey trust from the trusted nodes.",1. Introduction,[0],[0]
A node is identified as Sybil if sufficient ammount of trust is not delivered to it.,1. Introduction,[0],[0]
"Among random-walk based approaches, SybilRank is known to be the state-ofthe-art, of which the performance is theoretically guaranteed (Cao et al., 2012).",1. Introduction,[0],[0]
"However, the theory holds only under unrealistic topological assumptions of the network.",1. Introduction,[0],[0]
"In this paper, we show that the same theoretical guarantee can be obtained under more realistic situations.
",1. Introduction,[0],[0]
We further dicuss the robustness of the random walk approach against adversarial strategies.,1. Introduction,[0],[0]
"To this end, we formally introduce adversarial settings for graph-based Sybil
detection and derive an optimal attacking strategy that is based on the exploitation of trust leaks.",1. Introduction,[0],[0]
"Based on our analysis, we propose a transductive Sybil ranking (TSR), an integrated approach capable of adjusting edge weights based on sampled trust leaks.",1. Introduction,[0],[0]
We empirically show good performance of TSR against the state-of-the-art baselines on a variety of attacking scenarios using artificially generated data as well as real-world Facebook data.,1. Introduction,[0],[0]
"We are given a graph G = (V,E) consisting of nodes V and pairwise edges E between nodes.",2. Preliminaries,[0],[0]
"We denote GS = (VS , ES) the Sybil sub-graph, GH = (VH , EH) the disjunct honest sub-graph, and VT ✓ VH our trusted (verified nonSybil nodes) random walk seed nodes.",2. Preliminaries,[0],[0]
EA is the set of edges connecting any node in GS and any node in GH .,2. Preliminaries,[0],[0]
"Sybil Rank is considered the state-of-the-art graph-based method to detect Sybil accounts as it outperformed all its contestants (Cao et al., 2012).",2. Preliminaries,[0],[0]
It is also based on random walks and operates solely on the topology of the graph.,2. Preliminaries,[0],[0]
"Sybil Rank starts from the initial distribution {p(i)0 2 [0, 1]}|V |i=1",2. Preliminaries,[0],[0]
"(without superscript refers to a vector containing all elements), in which “trust” is assigned to the known honest nodes VT :
p (i) 0",2. Preliminaries,[0],[0]
"=
( 1
|VT",2. Preliminaries,[0],[0]
"| if vi 2 VT , 0 otherwise.
(1)
Then, it “propagates” the trust via a short (k steps) random walk:
p > k",2. Preliminaries,[0],[0]
= p >,2. Preliminaries,[0],[0]
k,2. Preliminaries,[0],[0]
"1Q = · · · = p>0 Qk , (2)
where Q 2 R|V |⇥|V",2. Preliminaries,[0],[0]
"| is the transition matrix through the edges with Qi,j = ( P j0 1[(i, j 0 ) 2 E]) 1, if (i, j) 2 E, and else 0.",2. Preliminaries,[0],[0]
"It is known that the stationary distribution ⇡ ⌘ p1 is the normalized degree distribution (Behrends, 2000)
⇡ > = ⇣ deg(v1) Vol(V ) , . . .",2. Preliminaries,[0],[0]
", deg(v|V |) Vol(V ) ⌘ , (3)
where deg(v) is the degree of node v, i.e., the number of all incident edges of v, and Vol(V ) = P v2V deg(v) is the sum of the degrees for all nodes in V .",2. Preliminaries,[0],[0]
"SybilRank conpensates the effect of degrees, and use the degree-normalized probability
p (i) = p",2. Preliminaries,[0],[0]
"(i) k /⇡ (i) (4)
as the ranking score, where a high ranking indicates a high probability of being an honest node.
",2. Preliminaries,[0],[0]
"Essentially, SybilRank relies on the assumption that the total number of attacking edges is bounded.",2. Preliminaries,[0],[0]
"Under this assumption, only a small fraction of the trust is propagated
through the sparse cut between the honest network and the Sybil nodes during the short random walk, while ”trust” go through the ”non-trusted” honest nodes through the dense connections within the the honest subgraph.
",2. Preliminaries,[0],[0]
Boshmaf et al. (2016) developed Integro to cope with a larger number of attacking edges.,2. Preliminaries,[0],[0]
"To this end, Integro introduces weights on the edges to bias the random walk, where the weights are determined after its pre-processing step to detect victims.",2. Preliminaries,[0],[0]
Here a victim is defined as a node that established a connection to one of the Sybil nodes.,2. Preliminaries,[0],[0]
"The set of all victim nodes is defined by Vv = {v 2 Vh : 9(v, s) 2 EA}.",2. Preliminaries,[0],[0]
"After the detection step, Integro lowers the weights to all incident edges to the detected victims, which prevents the trust to propagate through victim nodes.",2. Preliminaries,[0],[0]
"As the victims form a natural border between the honest and the Sybil graph, this reduces the overall flow of trust into the Sybil graph.",2. Preliminaries,[0],[0]
Boshmaf et al. found that traditional feature-based classification methods yield good and robust detection of victims.,2. Preliminaries,[0],[0]
"A notable advantage against the feature-based Sybil detection is that, unlike Sybils, victims generally do not behave adversarial, as they don’t have any incentive to ”hide”.",2. Preliminaries,[0],[0]
"More Realistic Assumptions
Cao et al. (2012) gave a security guarantee for SybilRank.",3. SybilRank’s Security Guarantee Under,[0],[0]
Let g := |EA| be the number of attacking edges and n := |V | be the number of all nodes in the graph.,3. SybilRank’s Security Guarantee Under,[0],[0]
their theory relies on the notion of trust leaks.,3. SybilRank’s Security Guarantee Under,[0],[0]
Definition 1.,3. SybilRank’s Security Guarantee Under,[0],[0]
(Trust leaks) Let rk0 = P i2VH p (i) k0 be the trust that remains in the honest graph after k0 random walk steps.,3. SybilRank’s Security Guarantee Under,[0],[0]
We call l = Pk k0=1(rk0+1 rk0) the absolute trust leak.,3. SybilRank’s Security Guarantee Under,[0],[0]
"Assume that the attacking edges are created randomly, following a distribution ↵(EA).",3. SybilRank’s Security Guarantee Under,[0],[0]
We call CH(k 0 ),3. SybilRank’s Security Guarantee Under,[0],[0]
"= E↵(EA)[ rk0+1 rk0 rk0
] the expected relative trust leak.
",3. SybilRank’s Security Guarantee Under,[0],[0]
CH(k 0 ) is actually a constant with respect to k0 under reasonable assumptions on ↵(EA).,3. SybilRank’s Security Guarantee Under,[0],[0]
The following lemma has been proved: Lemma 1.,3. SybilRank’s Security Guarantee Under,[0],[0]
"(Cao et al., 2012) Assume that the graph G is created randomly, following the configuration model (Molloy & Reed, 1995).",3. SybilRank’s Security Guarantee Under,[0],[0]
"Then, the expected relative trust leak in each iteration is given by CH = gvol(VH) .
",3. SybilRank’s Security Guarantee Under,[0],[0]
This leads to a theoretical guarantee of SybilRank.,3. SybilRank’s Security Guarantee Under,[0],[0]
Theorem 1.,3. SybilRank’s Security Guarantee Under,[0],[0]
"(Cao et al., 2012) Assume that the graph G is created randomly, following the configuration model.",3. SybilRank’s Security Guarantee Under,[0],[0]
The total number of Sybils that are ranked higher than nonSybils by SybilRank is O(g log n).,3. SybilRank’s Security Guarantee Under,[0],[0]
"Theorem 1 implies good performance of SybilRank, but
it holds under the assumption that the attacking edges are created in the same process as the honest graph,1 which is not realistic.
",3. SybilRank’s Security Guarantee Under,[0],[0]
"Below, we show that the same guarantee is obtained under the following more realistic assumption: Assumption 1.",3. SybilRank’s Security Guarantee Under,[0],[0]
"The graph G is constructed by the following steps:
1.",3. SybilRank’s Security Guarantee Under,[0],[0]
"Honest graph GH construction: GH is connected, nonbipartite, and scale free, i.e., the degree distribution follows the power law distribution.
",3. SybilRank’s Security Guarantee Under,[0],[0]
2.,3. SybilRank’s Security Guarantee Under,[0],[0]
"Sybil graph GS construction: The topology of GS is arbitrary.
",3. SybilRank’s Security Guarantee Under,[0],[0]
3.,3. SybilRank’s Security Guarantee Under,[0],[0]
Attacking edges EA generation:,3. SybilRank’s Security Guarantee Under,[0],[0]
"The attacking edges are genarated on all possible edges EA ⇢ VS ⇥ VH between the honest and the Sybil subgraphs with equal propability.
",3. SybilRank’s Security Guarantee Under,[0],[0]
"Under Assumption 1, evaluating the expected trust leak is less straightforward.",3. SybilRank’s Security Guarantee Under,[0],[0]
"Nevertheless, we can show that it results in the same formal security guarantee stated in Theorem 1.
",3. SybilRank’s Security Guarantee Under,[0],[0]
"To properly compute the expected trust leak, the following random variables are defined.",3. SybilRank’s Security Guarantee Under,[0],[0]
"Xv counts the number of attacking edges incident to node v, Yv = ⇡(v)
",3. SybilRank’s Security Guarantee Under,[0],[0]
"Xv deg(v,GH)+Xv = ⇡(v) Xv deg(v,G) is the trust leak in node
v and Z = P
",3. SybilRank’s Security Guarantee Under,[0],[0]
v2VH Yv is the total trust leak.,3. SybilRank’s Security Guarantee Under,[0],[0]
Note that here ⇡(v) is the current amount of trust in node v and not the stationary distribution of the random walk.,3. SybilRank’s Security Guarantee Under,[0],[0]
This notation is used to avoid confusion with the probability mass function denoted by P .,3. SybilRank’s Security Guarantee Under,[0],[0]
"From Assumption 1 it follows that Xv is hypergeometrically distributed (Tuckwell, 1995) with the following parameters: the population size: N = |VH⇥VS |, successes: K = |{v}⇥ VS |, and the draws n = |EA|.",3. SybilRank’s Security Guarantee Under,[0],[0]
Let g := |EA| be the number of attacking edges.,3. SybilRank’s Security Guarantee Under,[0],[0]
"Moreover, let nH := |VH",3. SybilRank’s Security Guarantee Under,[0],[0]
| and nS,3. SybilRank’s Security Guarantee Under,[0],[0]
":= |VS | denote the number of honest nodes and Sybil nodes, respectively.
",3. SybilRank’s Security Guarantee Under,[0],[0]
"The probability mass function of Xv is given by P (Xv =
k) =
✓ K
k ◆✓ N K n k ◆ / ✓ N n",3. SybilRank’s Security Guarantee Under,[0],[0]
◆,3. SybilRank’s Security Guarantee Under,[0],[0]
"and according to Tuckwell
(1995), its expected value can be computed by E[Xv] = n
K N = |EA| |{v}⇥VS ||VH⇥VS | = |EA| |VH",3. SybilRank’s Security Guarantee Under,[0],[0]
"| = g nH
.",3. SybilRank’s Security Guarantee Under,[0],[0]
"The final goal is to compute the expected value of Z. The linearity of the expected value yields E[Z] =
P v2VH E[Yv] and for the
expected value of Yv we get
E[Yv] = ⇡(v)deg(v,G) P1 k=0 kP (Xv = k)
= ⇡(v) deg(v,G)E[Xv] = ⇡(v) deg(v,G) g nH .
",3. SybilRank’s Security Guarantee Under,[0],[0]
"1This assumption is not explicitly stated in Cao et al. (2012), but apparent from their derivation.
",3. SybilRank’s Security Guarantee Under,[0],[0]
"Using this result, the expected value of Z becomes E[Z]",3. SybilRank’s Security Guarantee Under,[0],[0]
"=P v2VH E[Yv] = g nH P v2VH ⇡(v) deg(v,G) , where the right hand side still contains a sum that needs to be evaluated individually for each node to compute its actual value.",3. SybilRank’s Security Guarantee Under,[0],[0]
"In order to “average out” this sum, we rely on the assumption that the honest nodes GH is power law-distributed (Barabási, 2009).",3. SybilRank’s Security Guarantee Under,[0],[0]
"To do this, a new random variable Dv is introduced which measures the degree of v. Then, the assumption results in the probability of a node having a degree of d being P (Dv = d) =",3. SybilRank’s Security Guarantee Under,[0],[0]
"d
⇣( ) , where ⇣ is the Riemann zeta function ⇣(s) := P1 n=0 n s (Barabási, 2009).
",3. SybilRank’s Security Guarantee Under,[0],[0]
"With this expression, it is possible to “average out” the exact topology of the graph by computing the expected value with respect to the newly defined random variable Dv:
E[Z] =",3. SybilRank’s Security Guarantee Under,[0],[0]
gnH P1 d=1 P v2VH ⇡(v) d P,3. SybilRank’s Security Guarantee Under,[0],[0]
(,3. SybilRank’s Security Guarantee Under,[0],[0]
"Dv = d)
= g nH P v2VH ⇡(v) P1 d=1 1 d d ⇣( )
= g nH P v2VH ⇡(v) ⇣( ) P1 d=1 d ( +1)
",3. SybilRank’s Security Guarantee Under,[0],[0]
= g nH ⇣( +1) ⇣,3. SybilRank’s Security Guarantee Under,[0],[0]
"( ) P v2VH ⇡(v).| {z }
Total trust in the honest graph
This yields the following lemma.",3. SybilRank’s Security Guarantee Under,[0],[0]
Lemma 2.,3. SybilRank’s Security Guarantee Under,[0],[0]
"Under Assumption 1 the expected relative trust leak in each iteration of the random walk is given by
˜ CH = g
nH ⇣( +1) ⇣( )| {z } =:e
where e < 1 is a constant that depends on the parameter of the assumed power law distribution for the degree distribution.
",3. SybilRank’s Security Guarantee Under,[0],[0]
"Although Lemma 2 gives a different expected relative trust leak from Lemma 1, the fact that the maximum number of connection for each node is bounded in every OSN and therefore O(nH) = O(vol(VH)) leads to the same asymptotic behavior as Theorem 2: Theorem 2.",3. SybilRank’s Security Guarantee Under,[0],[0]
"Under Assuption 1, the total number of Sybils that are ranked higher than non-Sybils by SybilRank is O(g log n).",3. SybilRank’s Security Guarantee Under,[0],[0]
"This result explicitly shows that, asymptotically, SybilRank’s security guarantee remains unchanged even under more realistic Assumption 1.",3. SybilRank’s Security Guarantee Under,[0],[0]
"In this section, we discuss adversarial strategies against graph-based Sybil detection methods.
",4. Adversarial Strategies,[0],[0]
"Attacker’s Action Although attackers in general can take variety of actions, we restricts their action to adding attacking edges.
",4. Adversarial Strategies,[0],[0]
Definition 2 (Attacking strategy).,4. Adversarial Strategies,[0],[0]
"Given an honest graph GH and a Sybil graph GS , an attacking strategy describes the set of attacking edges established by the intruder.
",4. Adversarial Strategies,[0],[0]
"The cost of action is measured by the number of attacking edges.
",4. Adversarial Strategies,[0],[0]
"Attacker’s Knowledge Generally, we focus on adversarial attacks against random walk based approaches.",4. Adversarial Strategies,[0],[0]
"That is, an attacker’s strategy for establishing edges from Sybil nodes to honest nodes in order to cloak an attacker’s Sybil sub-network.",4. Adversarial Strategies,[0],[0]
"For analysis, we assume different levels of knowledge that the attacker has on the defender’s strategy and information:
A.1 Strategy only.
",4. Adversarial Strategies,[0],[0]
"A.2 Strategy + topology.
",4. Adversarial Strategies,[0],[0]
"A.3 Strategy + topology + trusted nodes (positively labeled nodes).
",4. Adversarial Strategies,[0],[0]
"B.1 Strategy + topology + trusted nodes (positively labeled nodes) + untrusted nodes (negatively labeled nodes).
",4. Adversarial Strategies,[0],[0]
"Here, we divided the level of access to inside information for the attacker into two groups.",4. Adversarial Strategies,[0],[0]
"In group A (i.e., A.1, A.2, A.3) attackers are able to gather sophisticated information based on publicly available sources, whereas in group B (i.e., B.1) either some back-channel provides non-public information (e.g. defender marked Sybil nodes based on their analysis), or, the attackers are provided with all information visible to the defenders.
",4. Adversarial Strategies,[0],[0]
"Clearly, it is too hard, if not impossible, to have an out-ofthe-box solution for the setting described in group B and we therefore resort our analysis on the settings in group A.",4. Adversarial Strategies,[0],[0]
"In the first case (A.1), no efficient adversarial strategies for graph-based random walk approaches is possible.",4. Adversarial Strategies,[0],[0]
The attackers must build up sufficient attacking edges to trusted nodes in order to absorb enough trust.,4. Adversarial Strategies,[0],[0]
"In A.3 (and A.2 as a special case) on the other hand, the attacker gained enough information to guide the creation of attacking edges efficiently.",4. Adversarial Strategies,[0],[0]
This paper focuses on this most interesting situation.,4. Adversarial Strategies,[0],[0]
"More specifically, we assume the following: the intruder knows defender’s strategy (algorithm details), the topology of the honest graph, and the set of trusted nodes, i.e., she knows about GH = (VH , EH) and VT .",4. Adversarial Strategies,[0],[0]
Based on that knowledge the intruder can establish attacking edges to honest nodes of her choice with the goal to create an attacking scenario where the applied defense method fails.,4. Adversarial Strategies,[0],[0]
"Although the exact topology of the Sybil graph is not specified any further, for the following results it is assumed that it is designed in a way that suits the intruder well.
",4. Adversarial Strategies,[0],[0]
"Attacker’s Goal Attackers can have various final goals, e.g., spamming honest users to earn money, feeding wrong information to honest nodes, stealing nonpublic information, damaging countries/companies, etc.",4. Adversarial Strategies,[0],[0]
"Depending on the goal, the objective of the optimal strategy can differ.",4. Adversarial Strategies,[0],[0]
"We assume that attacker’s try to maximize their influence and hence, have an inherent need to increase the number of attacking edges.
",4. Adversarial Strategies,[0],[0]
"Random-walk based approaches such as SybilRank and Integro rely on the fact that the absolute trust leak l from the honest graph to the Sybil graph is small (i.e., below the amount needed to reach the stationary distribution within the Sybil sub-graph) which ensures low trust scores for the Sybil nodes.",4. Adversarial Strategies,[0],[0]
"However, if enough trust is being propagated to the Sybil graph, trust values will be close to the stationary distribution in the Sybil graph as well as in the honest graph.",4. Adversarial Strategies,[0],[0]
"Consequently, the degree-normalized ranking values will be similar to the ones in the honest graph, which makes Sybil nodes indistinguishable from honest nodes and therefore disables the detector.",4. Adversarial Strategies,[0],[0]
Definition 3 (Disabling Attacking Strategy).,4. Adversarial Strategies,[0],[0]
Let GH and GS be the honest graph and the Sybil graph.,4. Adversarial Strategies,[0],[0]
Let l : 2E !,4. Adversarial Strategies,[0],[0]
R be the absolute trust leak as a function of an attacking strategy.,4. Adversarial Strategies,[0],[0]
"Then, an attacking strategy EA ⇢ VH ⇥",4. Adversarial Strategies,[0],[0]
"VS is said to be disabling if
l(EA)",4. Adversarial Strategies,[0],[0]
"td, (5) where td is the disabling threshold, which depends on the topology of the Sybil graph and the detection algorithm.
",4. Adversarial Strategies,[0],[0]
"Surely, an attacker does not aim for just any disabling strategy but for the one that comes at the lowest cost.",4. Adversarial Strategies,[0],[0]
"As the cost of an attacking strategy is assumed to be increasing in the number of attacking edges, an optimal/minimal disabling strategy is given by the following definition.",4. Adversarial Strategies,[0],[0]
Definition 4 (Optimal Disabling Strategy).,4. Adversarial Strategies,[0],[0]
"An attacking strategy AE is said to be optimal if it is the solution to the following optimization problem:
min EA⇢VH⇥VS |EA| (6)
s. t. l(EA) td.
To solve this, the disabling threshold td and the trust leak function must be known to the attacker.",4. Adversarial Strategies,[0],[0]
"Ignoring the edge weights (which are unknown to the attacker) the amount of trust needed within the Sybil graph to reach the stationary distribution of the random walk is given by td =P
vi2VS ⇡i = vol(VS) vol(V ) .",4. Adversarial Strategies,[0],[0]
To exactly evaluate l(EA) the entire random walk needs to be simulated which is infeasible for the attacker without knowing its exact length and the edge weights.,4. Adversarial Strategies,[0],[0]
A useful estimate is to consider only the first iteration.,4. Adversarial Strategies,[0],[0]
"The computation of this value is feasible and the trust leak per attacking edge is by far the
largest in the first iteration because all the trust is concentrated in the relatively small subset of trusted nodes VT .",4. Adversarial Strategies,[0],[0]
"The trust leak in the first iteration ˜l(EA) is given by l(EA) = P v2VT (v) deg(v,GH)+(v)
, where (v) is the attacking degree (i.e., the number of attacking edges) of node v.",4. Adversarial Strategies,[0],[0]
This leads to a greedy strategy where the intruder iteratively adds those attacking edges which produce the largest increase in ˜l.,4. Adversarial Strategies,[0],[0]
In the following the term adversarial strategy/attacker refers to this greedy strategy.,4. Adversarial Strategies,[0],[0]
"In this section, we propose our new method and derive its efficient solver.",5. Proposed Method,[0],[0]
"Our method is specifically designed to cope with a large number of attacking edges by minimizing “trust leaks”, that is, minimizing a sampled trust leak by adjusting the edge weights—a missing mechanism for SybilRank and Integro.
",5. Proposed Method,[0],[0]
"Transductive Sybil Ranking Combining the approach of Backstrom & Leskovec (2011) and SybilRank (Cao et al., 2012), our proposed method, called transductive Sybil ranking (TSR), tries to leverage potential prior knowledge, negative labels, to bias a short random walk so that random walk methods work even with the existence of a large number of attacking edges.
",5. Proposed Method,[0],[0]
Assume that all nodes carry attributes and n  |V,5. Proposed Method,[0],[0]
"| nodes are additionally attached with label information, i.e., the defender knows a subset of nodes are honest, and another subset of nodes are sybil.",5. Proposed Method,[0],[0]
"More formally, the defender is given labeled nodes L := {(xi, yi) 2 X ⇥",5. Proposed Method,[0],[0]
"{+1, 1}}ni=1 and unlabeled nodes U := {xi 2 X}|V |i=n+1.",5. Proposed Method,[0],[0]
"Since only the honest nodes can be trusted, VT ✓ {vi 2 V ; yi = +1} holds.
",5. Proposed Method,[0],[0]
"We define an edge feature function u,v between nodes u and v as u,v : X ⇥ X !",5. Proposed Method,[0],[0]
Y .,5. Proposed Method,[0],[0]
"A corresponding parameterized, non-negative scoring function fw : Y !",5. Proposed Method,[0],[0]
"R+ is learned during training and applied as edge weight au,v = fw( u,v) in the weighted adjacency matrix Q 2 R|V |⇥|V",5. Proposed Method,[0],[0]
"|:
Qu,v =
( au,vP x au,x
if (u, v) 2 E, 0 otherwise.
(7)
",5. Proposed Method,[0],[0]
"Throughout our experiments, we restrict ourselves to the following differentiable edge feature function:
fw( u,v) =",5. Proposed Method,[0],[0]
"(1 exp( w> u,v))",5. Proposed Method,[0],[0]
1.,5. Proposed Method,[0],[0]
"(8) Once the transition matrix is fixed, The remaining procedure is the same as SybilRank.",5. Proposed Method,[0],[0]
"Namely, starting form the initial distribution (1), k-steps random walk (2) is applied with the transition matrix (7).",5. Proposed Method,[0],[0]
"After that, the degreenormalized ranking probability (4) is used for classification.",5. Proposed Method,[0],[0]
"However, we are also given negatively labeled nodes,
which are used to train the parameter w of the edge feature function (8), so that p(i) < p(j), 8 i, j 2 {1, . . .",5. Proposed Method,[0],[0]
", n} with yi = 1 and yj = +1.",5. Proposed Method,[0],[0]
"In the spirit of regularized risk minimization (Vapnik, 1999), this problem is formalized as follows:
Definition 5 (TSR optimization problem).",5. Proposed Method,[0],[0]
"TSR solves a quadratically regularized, non-convex optimization problem with generic loss-functions h :",5. Proposed Method,[0],[0]
"[0, 1]⇥{+1, 1} !",5. Proposed Method,[0],[0]
"R:
minimize w F (w) =
2
kwk2 + nX
i=1
h(p (i) (w), yi) .",5. Proposed Method,[0],[0]
"(9)
Using the notion of p(i)(w) visually indicates that node ranking probabilities p are (non-linearly) dependent on the parameter vector w.",5. Proposed Method,[0],[0]
"As for the choice of loss-functions, we examine the following:
• Wilcoxon-Mann-Whitney (WMW) loss (Yan et al., 2003).",5. Proposed Method,[0],[0]
"WMW maximizes the area under the ROC curve:
h(p, y) =
nX
j=1
1[y = +1^yj = 1] ⇣ 1 + exp p pjb ⌘ 1 .
",5. Proposed Method,[0],[0]
"• Smooth hinge-loss variant A smooth variant of the classical support vector machine hinge-loss with two additional parameters: a decision boundary b 2 R and a scaling parameter a 2 R:
h(p, y) =
8 ><
>: 1 2 y(ap b) if y(ap b)  0, 1 2 (1 y(ap b))2 if 0 < y(ap b)  1, 0 if 1 < y(ap b).
",5. Proposed Method,[0],[0]
"In this work, we focus on smooth, differentiable lossfunctions only, ensuring fast convergence to local optima via gradient-based methods, i.e., fast second-order methods (BFGS).",5. Proposed Method,[0],[0]
"A pivotal point is hence, to assess the gradient w.r.t.",5. Proposed Method,[0],[0]
"w.
Gradient Computation The remaining of this section is dedicated to the derivation of the gradient:
",5. Proposed Method,[0],[0]
"@F (w) @w = @ kwk2 @2w + Pn i @h(p(i)(w),yi) @w ,
where the loss-function h can be further split into @h(p(i)(w),yi)
@w = @h(p(i)(w),yi) @p(i)(w) @p(i)(w) @w .",5. Proposed Method,[0],[0]
"Since we con-
strained ourselves to differentiable loss-function h(p, y), the partial derivative w.r.t.",5. Proposed Method,[0],[0]
p can be calculated rather straightforward.,5. Proposed Method,[0],[0]
"More complicated is the evaluation of
@p(i)
",5. Proposed Method,[0],[0]
@w = @ @w p(i)k,5. Proposed Method,[0],[0]
⇡(i) =,5. Proposed Method,[0],[0]
✓ @p(i)k @w ⇡ (i) p(i)k @⇡ (i) @w ◆ ⇡ (i) 2 .,5. Proposed Method,[0],[0]
"(10)
The derivative of the i-th component of ⇡ is given by:
@⇡(i)
@w =
⇣ @deg⇤(vi) @w vol(V ) @vol(V )@w deg⇤(vi) ⌘ vol(V ) 2,
where @deg ⇤(vi) @w = P e2E vi2e @ae @w = P e2E vi2e @fw( e) @w and @vol(V )",5. Proposed Method,[0],[0]
@w = 2 P e2E @ae @w = 2 P e2E @fw( e) @w .,5. Proposed Method,[0],[0]
As fw is said to be differentiable the only part of Eq.,5. Proposed Method,[0],[0]
"(10) that remains is the Jacobian @pk/@w.
Theorem 3.",5. Proposed Method,[0],[0]
"The derivative @pk/@w for k 1 is given by:
@pk",5. Proposed Method,[0],[0]
@w = ✓ k 1P l=0 plQ k 1 l ◆ @Q @w .,5. Proposed Method,[0],[0]
"(11)
(the proof is given in Appendix A).",5. Proposed Method,[0],[0]
"The derivative of Q, defined in Eq.",5. Proposed Method,[0],[0]
"(7), is given by
@Quv @w =
8 <
:
@auv",5. Proposed Method,[0],[0]
@w P x aux auv P x @aux,5. Proposed Method,[0],[0]
"@w
( P x aux) 2",5. Proposed Method,[0],[0]
"if (u, v) 2 E, 0 otherwise.
",5. Proposed Method,[0],[0]
"This completes the computation of the gradient and enables the application of gradient-based methods, i.e., BFGS to find a (locally) optimal estimate ŵ.",5. Proposed Method,[0],[0]
"By using this estimate, TSR weights the whole graph, with which a short random walk is performed to obtain the final ranking p.
Robustness of TSR against Attacks By using the negative label information, our TSR, in principle, monitors “trust leak” through random walk, and adjusts the edge weights so that the leak is minimized.",5. Proposed Method,[0],[0]
"As a result, the weights tend to be lower on the attacking edges (to reduce the propagation), and higher on the Sybil edges (to boost the stationary distribution).",5. Proposed Method,[0],[0]
"Thus, we can expect that our TSR, which is an advanced integrated method, is more robust against attacks than the SybilRank and the two-step Integro approach.",5. Proposed Method,[0],[0]
"To assess the robustness of the proposed method and the baseline methods, we generate artificially network topology and edge and node attributes in order to have full control of the underlying ground truth.",6. Empirical Evaluation on Synthetic Data,[0],[0]
"We separately create two graphs, the honest and the Sybil graph.",6. Empirical Evaluation on Synthetic Data,[0],[0]
Both use the generation method proposed by Holme & Kim (2002) for scale free networks.,6. Empirical Evaluation on Synthetic Data,[0],[0]
Node features are generated randomly and correlated through dependency injection.,6. Empirical Evaluation on Synthetic Data,[0],[0]
"The edge features function u,v simply stacks node features of the two adjacent nodes xu",6. Empirical Evaluation on Synthetic Data,[0],[0]
and,6. Empirical Evaluation on Synthetic Data,[0],[0]
xv (see Appendix B for more details).,6. Empirical Evaluation on Synthetic Data,[0],[0]
"Connections between Sybil and honest graphs are established according to a random attacking strategy that iteratively adds attacking edges randomly, i.e., equally distributed on the set of all possible attacking edges VH ⇥",6. Empirical Evaluation on Synthetic Data,[0],[0]
"VS
or a adversarial attacking strategy that solves Problem (6) for optimal attacks.",6. Empirical Evaluation on Synthetic Data,[0],[0]
This strategy only chooses an honest node to be attacked next and the corresponding Sybil node is chosen randomly (equally distributed on the set of all Sybil nodes VS).,6. Empirical Evaluation on Synthetic Data,[0],[0]
"We test our method, TSR, using the proposed loss functions and compare against the stateof-the-art methods SybilRank and Integro.",6. Empirical Evaluation on Synthetic Data,[0],[0]
"As Integro depends on a preceding victim prediction, we simulated one that achieves highest possible rankings (ROC-AUC close to 1.0).2
Random Attacking Strategy We generated a sample network (|VH | = 200 and |VS | = 30) and select 15 honest nodes and 8 Sybil nodes randomly, which will be used as labeled examples for our TSR.",6. Empirical Evaluation on Synthetic Data,[0],[0]
The labeled honest nodes are also used as the set VT of trusted seeding nodes for the random walks in all methods.,6. Empirical Evaluation on Synthetic Data,[0],[0]
We evaluate the performance in terms of ROC-AUC-values for the computed ranking.,6. Empirical Evaluation on Synthetic Data,[0],[0]
This procedure was repeated 20 times for varying number of attacking edges (10-200 edges).,6. Empirical Evaluation on Synthetic Data,[0],[0]
Figure 1 shows ROC-AUC curves for all methods under the random attacking setting.,6. Empirical Evaluation on Synthetic Data,[0],[0]
"We can obsreve that our TSR, regardless of the choice of loss function, performs superior to the other methods.",6. Empirical Evaluation on Synthetic Data,[0],[0]
Integro’s accuracy deteriorates fast but still has an edge over SybilRank up to the point where the ROCAUC-value reaches 0.5.,6. Empirical Evaluation on Synthetic Data,[0],[0]
"After that SybilRank and Integro essentially perform similar.
",6. Empirical Evaluation on Synthetic Data,[0],[0]
"Adversarial Attacking Strategy For the adversarial setting, we ran the same benchmarks but this time attacking edges were added according to the adversarial attacking strategy.",6. Empirical Evaluation on Synthetic Data,[0],[0]
"Due to the much more aggressive setting, we varied the number of attacking edges from 1-40 and repeated this procedure 20 times to report averaged ROCAUC accuracies.",6. Empirical Evaluation on Synthetic Data,[0],[0]
The results are depicted in Figure 2.,6. Empirical Evaluation on Synthetic Data,[0],[0]
All choices of loss functions outperform SybilRank and Integro clearly.,6. Empirical Evaluation on Synthetic Data,[0],[0]
The results confirm our considerations that SybilRank’s performance drops fast and steep as soon as a certain amount of attacking edges is established.,6. Empirical Evaluation on Synthetic Data,[0],[0]
"Integro behaves more robust than SybilRank, but, ultimately, must resign after a few more attacking edges.",6. Empirical Evaluation on Synthetic Data,[0],[0]
"Again, our TSR is significantly more robust against adversarial attacks and can withstand higher number of attacking edges until its performance finally deteriorates.",6. Empirical Evaluation on Synthetic Data,[0],[0]
We also evaluated our method on a sample of the Facebook graph Leskovec & Mcauley collected from survey participants using the Facebook app.,7. Empirical Evaluation on Real-world Data,[0],[0]
"The dataset includes the topology (|V | = 4039 users and |E| = 88234 friend-
2SybiRank, Integro, and TSR rely on different information, and therefore, the fairness of comparison is not trivial.",7. Empirical Evaluation on Real-world Data,[0],[0]
"We discuss this issue in Appendix C.
ships) as well as node features for every node (see Table 1 for summary), Figure 3).",7. Empirical Evaluation on Real-world Data,[0],[0]
"Node features are comprised of obfuscated categorical features of users profiles including education, work, hometown, language, last name, etc.",7. Empirical Evaluation on Real-world Data,[0],[0]
"As with most of real world social graphs, the data exhibits strong multi-cluster structure, as seen in Figure 3 and Figure 4.",7. Empirical Evaluation on Real-world Data,[0],[0]
"These clusters pose additional challenges to the application of random walk-based methods as the trust propagation between two loosely inter-connected clusters is low (Cao et al., 2012; Boshmaf et al., 2016).",7. Empirical Evaluation on Real-world Data,[0],[0]
"Hence, trust seeds should be distributed among all clusters.",7. Empirical Evaluation on Real-world Data,[0],[0]
"Following SybilRank and Integro (Cao et al., 2012), we employ the Louvian clustering method (Blondel et al., 2008) first.
",7. Empirical Evaluation on Real-world Data,[0],[0]
"As common, the Sybil graph needs to be generated.",7. Empirical Evaluation on Real-world Data,[0],[0]
"For this purpose, a (small) subgraph was copied and declared as Sybil.",7. Empirical Evaluation on Real-world Data,[0],[0]
The attacking edges were created to link the honest and the Sybil graph following one of the attacking strategies (random or adversarial).,7. Empirical Evaluation on Real-world Data,[0],[0]
It was made sure that no Sybil node attacked one of the direct neighbors of its origin which is reasonable for most social graphs.,7. Empirical Evaluation on Real-world Data,[0],[0]
"Edge features
for TSR are as follows: the number of shared features (in total), the number of shared friends, and the number of shared features within specific categories.",7. Empirical Evaluation on Real-world Data,[0],[0]
"The other experimental setup is the same as the previous section.
",7. Empirical Evaluation on Real-world Data,[0],[0]
Random Attacks,7. Empirical Evaluation on Real-world Data,[0],[0]
The trusted nodes |VT,7. Empirical Evaluation on Real-world Data,[0],[0]
| = 50 were randomly distributed among all clusters and a small subset of Sybils |VD| = 30 was chosen as known Sybil nodes.,7. Empirical Evaluation on Real-world Data,[0],[0]
Attacking edges EA were established following the random attacking strategy ranging from |EA| = 1 to |EA| = 1400.,7. Empirical Evaluation on Real-world Data,[0],[0]
Experiments were repeated 10 times.,7. Empirical Evaluation on Real-world Data,[0],[0]
"Integro was run with
sarial attacking scenario on the Facebook graph.
",7. Empirical Evaluation on Real-world Data,[0],[0]
"two levels of accuracy in simulated victim detection, i.e., perfect (AUROC = 1) and almost perfect (AUROC = 0.9).",7. Empirical Evaluation on Real-world Data,[0],[0]
Figure 5 shows the AUROC-values.,7. Empirical Evaluation on Real-world Data,[0],[0]
The detection performance of SybilRank is the lowest and drops soon as attacking edges increase.,7. Empirical Evaluation on Real-world Data,[0],[0]
"Integro with the perfect victim detection outperforms the other methods, but with just a slight reduction in the victim detection accuracy (AUROC = 0.9), its performance drops significantly.",7. Empirical Evaluation on Real-world Data,[0],[0]
All versions of TSR perform almost on par with perfect version of Integro in the lower range of attacking edges (1—800).,7. Empirical Evaluation on Real-world Data,[0],[0]
"In the higher range (800—1400), the hinge loss drop fast to end up with a performance similar to Integro with the almost perfect victim detection.",7. Empirical Evaluation on Real-world Data,[0],[0]
"However, the variant that uses the WMW-loss does not show this performance drop and stays close to the upper-bound of Integro.
",7. Empirical Evaluation on Real-world Data,[0],[0]
Adversarial Attacks The number of adversarial attack edges ranged from |EA| = 1 to |EA| = 45.,7. Empirical Evaluation on Real-world Data,[0],[0]
"Figure 6 shows
the recorded average AUROC-values.",7. Empirical Evaluation on Real-world Data,[0],[0]
"Again, SybilRank’s performance drops the fastest and steepest and Integro is insignificantly better in this adversarial scenario.",7. Empirical Evaluation on Real-world Data,[0],[0]
Both variants of TSR performs better than the baselines.,7. Empirical Evaluation on Real-world Data,[0],[0]
"However, the WMW-loss variant performs only slightly better than SybilRank and Integro, while the hinge-loss variant keeps good performance even for a large number of attacking edges.",7. Empirical Evaluation on Real-world Data,[0],[0]
"As our future work, we will investigate which loss function should be chosen, depending on data and assumed attacker’s strategy.",7. Empirical Evaluation on Real-world Data,[0],[0]
"Overall, whereas SybilRank’s and Integro’s performance drops to an average AUROC-value below 0.5 at |EA| = 30, the hinge-loss variant of TSR still achieves an average value over 0.9 at the same amount of attacking edges.",7. Empirical Evaluation on Real-world Data,[0],[0]
"In this paper, we studied the problem of Sybil detection.",8. Conclusion & Outlook,[0],[0]
We first refined the security guarantees of random walk approaches towards more realistic assumptions.,8. Conclusion & Outlook,[0],[0]
"Then, we formalized and coined the adversarial setting and introduced optimal strategies for attackers.",8. Conclusion & Outlook,[0],[0]
"Further, we proposed a new method, transductive Sybil ranking (TSR), that leverages prior information, network topology as well as node and edge features.",8. Conclusion & Outlook,[0],[0]
"Unlike Integro, it is fused in a single optimization framework and can be solved efficiently by using gradient-based optimizer.",8. Conclusion & Outlook,[0],[0]
"In our empirical evaluation, we showed the advantages of our method and investigated the susceptibility of our method and baseline competitors to adversarial attacks.",8. Conclusion & Outlook,[0],[0]
"Further research will focus on the application of our method to real-world, large-scale OSNs.",8. Conclusion & Outlook,[0],[0]
"JH was supported by MathPlan GmbH and innoCampus, TU-Berlin.",9. Acknowledgments,[0],[0]
"SN, AB and KRM were supported by the German Ministry for Education and Research as Berlin Big Data Center BBDC, funding mark 01IS14013A. KRM thanks for the Institute for Information & Communications Technology Promotion (IITP) grant funded by the Korea government (No.2017-0-00451).",9. Acknowledgments,[0],[0]
NG was supported by BMBF ALICE II grant 01IB15001B.,9. Acknowledgments,[0],[0]
Sybil detection is a crucial task to protect online social networks (OSNs) against intruders who try to manipulate automatic services provided by OSNs to their customers.,abstractText,[0],[0]
"In this paper, we first discuss the robustness of graph-based Sybil detectors SybilRank and Integro and refine theoretically their security guarantees towards more realistic assumptions.",abstractText,[0],[0]
"After that, we formally introduce adversarial settings for the graph-based Sybil detection problem and derive a corresponding optimal attacking strategy by exploitation of trust leaks.",abstractText,[0],[0]
"Based on our analysis, we propose transductive Sybil ranking (TSR), a robust extension to SybilRank and Integro that directly minimizes trust leaks.",abstractText,[0],[0]
Our empirical evaluation shows significant advantages of TSR over stateof-the-art competitors on a variety of attacking scenarios on artificially generated data and realworld datasets.,abstractText,[0],[0]
Minimizing Trust Leaks for Robust Sybil Detection,title,[0],[0]
"Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1379–1388, Austin, Texas, November 1-5, 2016. c©2016 Association for Computational Linguistics
Deep inference on a large-scale knowledge base (KB) needs a mass of formulas, but it is almost impossible to create all formulas manually. Data-driven methods have been proposed to mine formulas from KBs automatically, where random sampling and approximate calculation are common techniques to handle big data. Among a series of methods, Random Walk is believed to be suitable for knowledge graph data. However, a pure random walk without goals still has a poor efficiency of mining useful formulas, and even introduces lots of noise which may mislead inference. Although several heuristic rules have been proposed to direct random walks, they do not work well due to the diversity of formulas. To this end, we propose a novel goaldirected inference formula mining algorithm, which directs random walks by the specific inference target at each step. The algorithm is more inclined to visit benefic structures to infer the target, so it can increase efficiency of random walks and avoid noise simultaneously. The experiments on both WordNet and Freebase prove that our approach is has a high efficiency and performs best on the task.",text,[0.9556397430310016],"['Similarly, sequential clinical trials may halt or re-allocate certain treatment groups due to preliminary results, and empirical scientists may initially try and test multiple hypotheses and multiple treatments, but then decide to gather more data in support of certain hypotheses and not others, based on the results of preliminary statistical tests.']"
"Recently, various knowledge bases (KBs), such as Freebase (Bollacker et al., 2008), WordNet (Miller, 1995), Yago (Hoffart et al., 2013), have been built, and researchers begin to explore how to make use of structural information to promote performances of several inference-based NLP applications, such as
text entailment, knowledge base completion, question and answering.",1 Introduction,[0],[0]
"Creating useful formulas is one of the most important steps in inference, and an accurate and high coverage formula set will bring a great promotion for an inference system.",1 Introduction,[0],[0]
"For example, Nationality(x, y) ∧ Nationality(z, y) ∧ Language(z, w)⇒ Language(x, w) is a high-quality formula, which means people with the same nationality probably speak the same language.",1 Introduction,[0],[0]
"However, it is a challenge to create formulas for open-domain KBs, where there are a great variety of relation types and it is impossible to construct a complete formula set by hand.
",1 Introduction,[0],[0]
"Several data-driven methods, such as Inductive Logic Programming (ILP) (Muggleton and De Raedt, 1994) and Markov Logic Network (MLN) (Richardson and Domingos, 2006), have been proposed to mine formulas automatically from KB data, which transform frequent sub-structures of KBs, e.g., paths or loops, into formulas.",1 Introduction,[0],[0]
"Figure 1.a shows a sub-graph extracted from Freebase, and the formula mentioned above about Language can be generated from the loop in Figure 1.d.",1 Introduction,[0],[0]
"However, the running time of these traditional probabilistic inference methods is unbearable over large-scale KBs.",1 Introduction,[0],[0]
"For example, MLN needs grounding for each candidate formula, i.e., it needs to enumerate all paths.",1 Introduction,[0],[0]
"Therefore, the computation complexity of MLN increases exponentially with the scale of a KB.
",1 Introduction,[0.9526464438282055],"[', PK , and with high probability or in expectation over the randomness of the algorithm and of the reward sampling.']"
"In order to handle large-scale KBs, the random walk is usually employed to replace enumerating all possible sub-structures.",1 Introduction,[0],[0]
"However, random walk is inefficient to find useful structures due to its completely randomized mechanism.",1 Introduction,[0],[0]
"For example in Fig-
1379
ure 1.b, the target path (yellow one) has a small probability to be visited, the reason is that the algorithm may select all the neighboring entity to transfer with an equal probability.",1 Introduction,[0],[0]
"This phenomenon is very common in KBs, e.g., each entity in Freebase has more than 30 neighbors in average, so there will be about 810,000 paths with length 4, and only several are useful.",1 Introduction,[0],[0]
"There have been two types of methods proposed to improve the efficiency of random walks, but they still meet serious problems, respectively.",1 Introduction,[0],[0]
1),1 Introduction,[0],[0]
Increasing rounds of random walks.,1 Introduction,[0],[0]
"More rounds of random walks will find more structures, but it will simultaneously introduce more noise and thus generate more false formulas.",1 Introduction,[0],[0]
"For example, the loop in Figure 1.c exists in Freebase, but it produces a false formula, Gender(x, y) ∧ Gender(z, y) ∧ Language(z, w)⇒ Language(x, w), which means people with the same gender speak the same language.",1 Introduction,[0],[0]
"This kind of structures frequently occur in KBs even the formulas are mined with a high confidence, because there are a lot of sparse structures in KBs which will lead to inaccurate confidence.",1 Introduction,[0],[0]
"According to our statistics, more than 90 percent of high-confidence formulas produced by random walk are noise.",1 Introduction,[0],[0]
2),1 Introduction,[0],[0]
Employing heuristic rules to direct random walks.,1 Introduction,[0],[0]
"This method directs random walks to find useful structures by rewriting the state transition probability matrix, but the artificial heuristic rules may only apply to a little part of formulas.",1 Introduction,[0],[0]
"For example, PRA (Lao and Cohen, 2010; Lao et al., 2011) assumes the more narrow distributions of elements in a formula are, the higher score the formula will obtain.",1 Introduction,[0],[0]
"However, formulas with high scores in PRA are not always true.",1 Introduction,[0],[0]
"For example, the formula in Figure 1.c has a high score in PRA, but it is not true.",1 Introduction,[0],[0]
"Oppositely, formulas with low scores in PRA are not always useless.",1 Introduction,[0],[0]
"For example, the formula, Father(x, y) ∧ Father(y, z) ⇒ Grandfather(x, t), has a low score when x and y both have several sons, but it obviously is the most effective to infer Grandfather.",1 Introduction,[0],[0]
"According to our investigations, the situations are common in KBs.",1 Introduction,[0],[0]
"In this paper, we propose a Goal-directed Random Walk algorithm to resolve the above problems.",1 Introduction,[0],[0]
The algorithm employs the specific inference target as the direction at each step in the random walk process.,1 Introduction,[0],[0]
"In more detail, to achieve such a goaldirected mechanism, at each step of random walk, the algorithm dynamically estimates the potentials for each neighbor by using the ultimate goal, and assigns higher probabilities to the neighbors with higher potentials.",1 Introduction,[0],[0]
"Therefore, the algorithm is more inclined to visit structures which are beneficial to infer
the target and avoid transferring to noise structures.",1 Introduction,[0],[0]
"For example in Figure 1, when the inference target is what language a person speaks, the algorithm is more inclined to walk along Nationality edge than Gender, because Nationality has greater potential than Gender to infer Language.",1 Introduction,[0],[0]
We build a real potential function based on low-rank distributional representations.,1 Introduction,[0],[0]
The reason of replacing symbols by distributional representations is that the distributional representations have less parameters and latent semantic relationship in them can contribute to estimate potentials more precisely.,1 Introduction,[0],[0]
"In summary, the contributions of this paper are as follows.",1 Introduction,[0],[0]
•,1 Introduction,[0],[0]
"Compared with the basic random walk, our approach direct random walks by the inference target, which increases efficiency of mining useful formulas and has a great capability of resisting noise.",1 Introduction,[0],[0]
•,1 Introduction,[0],[0]
"Compared with the heuristic methods, our approach can learn the strategy of random walk automatically and dynamically adjust the strategy for different inference targets, while the heuristic methods need to write heuristic rules by hand and follow the same rule all the time.",1 Introduction,[0],[0]
"• The experiments on link prediction task prove that our approach has a high efficiency on mining formulas and has a good performance on both WN18 and FB15K datasets.
",1 Introduction,[0],[0]
"The rest of this paper is structured as follows, Section 2 introduces the basic random walk for mining formulas.",1 Introduction,[0],[0]
Section 3 describes our approach in detail.,1 Introduction,[0],[0]
The experimental results and related discussions are shown in Section 4.,1 Introduction,[0],[0]
"Section 5 introduces some related works, and finally, Section 6 concludes this paper.",1 Introduction,[0],[0]
"Mining frequent patterns from source data is a problem that has a long history, and for different specific tasks, there are different types of source data and different definitions of pattern.",2.1 Frequent Pattern Mining,[0],[0]
"Mining formulas is more like frequent subgraph mining, which employs paths or loops as frequent patterns and mines them from a KB.",2.1 Frequent Pattern Mining,[0],[0]
"For each relation type R, the algorithm enumerates paths from entity H to entity T for each triplet R(H,T ).",2.1 Frequent Pattern Mining,[0],[0]
These paths are normalized to formulas by replacing entities to variables.,2.1 Frequent Pattern Mining,[0],[0]
"For example, the loop in Figure 1.d, National-
ity(Bob, America)",2.1 Frequent Pattern Mining,[0],[0]
"∧ Nationality(Stewart, America)",2.1 Frequent Pattern Mining,[0],[0]
"∧ Language(Bob, English) ⇒",2.1 Frequent Pattern Mining,[0],[0]
"Language(Stewart, English), can be normalized to the formula, Nationality(x, y) ∧ Nationality(z, y) ∧ Language(z, w) ⇒",2.1 Frequent Pattern Mining,[0],[0]
"Language(x, w).",2.1 Frequent Pattern Mining,[0],[0]
"Support and confidence are employed to estimate a formula, where the support value of a formula f : X ⇒ Y , noted as Sf , is defined as the proportion of paths in the KB which contains the body X , and the confidence value of X ⇒ Y , noted as Cf , is defined as the proportion of the paths that contains X which also meets X ⇒ Y .",2.1 Frequent Pattern Mining,[0],[0]
"Cf is calculated as follows,
Cf = Nf NX
(1)
",2.1 Frequent Pattern Mining,[0],[0]
whereNf is the total number of instantiated formula f and NX is the total number of instantiated X .,2.1 Frequent Pattern Mining,[0],[0]
Enumerating paths is a time consuming process and does not apply to large-scale KBs.,2.2 Random Walk on Knowledge Graph,[0],[0]
"Therefore, random walk on the graph is proposed to collect frequent paths instead of enumerating.",2.2 Random Walk on Knowledge Graph,[0],[0]
Random walk randomly chooses a neighbor to jump unlike enumerating which needs to search all neighbors.,2.2 Random Walk on Knowledge Graph,[0],[0]
"To estimate a formula f , the algorithm employs f ’s occurrence number during random walks N
′ f to approxi-
mate the total number Nf in Equation (1), and similarly employs N
′ X to approximate NX .",2.2 Random Walk on Knowledge Graph,[0],[0]
"Therefore,
f ’s confidence Cf can be approximatively estimated by N
′ f and N ′ X , noted as C ′ f .
",2.2 Random Walk on Knowledge Graph,[0],[0]
"Random walk maintains a state transition probability matrix P , and Pij means the probability of jumping from entity i to entity j. To make the confidence C
′",2.2 Random Walk on Knowledge Graph,[0],[0]
"f as close to the true confidence Cf as pos-
sible, the algorithm sets P as follows,
Pij = { 1/di, j ∈ Adj(i) 0, j /∈ Adj(i)",2.2 Random Walk on Knowledge Graph,[0],[0]
"(2)
where di is the out-degree of the entity i, Adj(i) is the set of adjacent entities of i, and ∑N j=1 Pij = 1.",2.2 Random Walk on Knowledge Graph,[0],[0]
Such a transition matrix means the algorithm may jump to all the neighboring entities with an equal probability.,2.2 Random Walk on Knowledge Graph,[0],[0]
"Such a random walk is independent from the inference target, so we call this type of random walk as a goalless random walk.",2.2 Random Walk on Knowledge Graph,[0],[0]
The goalless mechanism causes the inefficiency of mining useful structures.,2.2 Random Walk on Knowledge Graph,[0],[0]
"When we want to mine paths for R(H,T ), the algorithm cannot arrive at T from H
in the majority of rounds.",2.2 Random Walk on Knowledge Graph,[0],[0]
"Even though the algorithm recalls several paths for R(H,T ), some of them may generate noisy formulas for inferring R(H,T ).
",2.2 Random Walk on Knowledge Graph,[0],[0]
"To solve the above problem, several methods direct random walks by statically modifying P .",2.2 Random Walk on Knowledge Graph,[0],[0]
"For example, PRA sets Prij = P (j|i;r) |Ri| , P (j|i; r) = r(i,j) r(i,∗) , where P (j|i; r) is the probability of reaching node j from node i under the specific relation r, r(i, ∗) is the number of edges from i under r, and Ri is the number of relation types from i. Such a transition matrix implies the more narrow distributions of elements in a formula are, the higher score the formula will obtain, which can be viewed as the heuristic rule of PRA.",2.2 Random Walk on Knowledge Graph,[0],[0]
"We propose to use the inference target, ρ = R(H,T ), to direct random walks.",3.1 Goal-Directed Random Walk,[0],[0]
"When predicting ρ, our approach always directs random walks to find useful structures which may generate formulas to infer ρ.",3.1 Goal-Directed Random Walk,[0],[0]
"For different ρ, random walks are directed by modifying the transition matrix P in different ways.",3.1 Goal-Directed Random Walk,[0],[0]
"Our approach dynamically calculates Prij when jumping from entity i to entity j under relation r as follows,
",3.1 Goal-Directed Random Walk,[0],[0]
"Prij =    Φ(r(i, j), ρ)∑ k∈Adj(i) Φ(r(i, k), ρ) , j ∈ Adj(i)
0, j /∈ Adj(i)",3.1 Goal-Directed Random Walk,[0],[0]
"(3)
where Φ(r(i, j), ρ) is the r(i, j)’s potential which measures the potential contribution to infer ρ after walking to j.
Intuitively, if r(i, j) exits in a path from H to T and this path can generate a benefic formula to infer R(H,T ), the probability of jumping from i to j should larger and thus Φ(r(i, j), ρ) also should be larger.",3.1 Goal-Directed Random Walk,[0],[0]
"Reversely, if we cannot arrive at T within the maximal steps after jumping to j, or if the path produces a noisy formula leading to a wrong inference, Pij and Φ(r(i, j), ρ) should both be smaller.
",3.1 Goal-Directed Random Walk,[0],[0]
"To explicitly build a bridge between the potential Φ and the inference goal ρ, we maximize the likelihood of paths which can infer ρ.",3.1 Goal-Directed Random Walk,[0],[0]
"First, we recursively define the likelihood of a path from H to t
as PpHt = PpHs ·",3.1 Goal-Directed Random Walk,[0],[0]
"Prst , where Prst is defined in Equation (3).",3.1 Goal-Directed Random Walk,[0],[0]
"We then classify a path pHt into three separate categories: a) t = T and pHt can produce a benefic formula to infer R(H,T ); b) t 6=",3.1 Goal-Directed Random Walk,[0],[0]
T ; c) t = T but pHt may generate a noisy formula which misleads inference.,3.1 Goal-Directed Random Walk,[0],[0]
"Finally, we define the likelihood function as follows,
maxPP = ∏
pHt∈P P apHt(1− PpHt) b+c (4)
where P is all paths found in the process of performing random walks for R(H,T ), and t may be equal to T or not.",3.1 Goal-Directed Random Walk,[0],[0]
"a, b, c are three 0-1 variables corresponding to the above categories a), b), c).",3.1 Goal-Directed Random Walk,[0],[0]
"Only one in a, b, c can be 1 when PHt belongs to the corresponding category.",3.1 Goal-Directed Random Walk,[0],[0]
We then transform maximizing PP to minimizing Lrw = − logPP and employ SGD to train it.,3.1 Goal-Directed Random Walk,[0],[0]
"In practice, there is not a clear-cut boundary between a) and c), so we divide the loss into two parts:",3.1 Goal-Directed Random Walk,[0],[0]
Lrw = Ltrw + λL inf rw .,3.1 Goal-Directed Random Walk,[0],[0]
Ltrw is the loss of that t 6=,3.1 Goal-Directed Random Walk,[0],[0]
"T , and Linfrw is the loss of that pHT generates a noisy formula leading to a wrong inference.",3.1 Goal-Directed Random Walk,[0],[0]
λ is a super parameter to balance the two losses.,3.1 Goal-Directed Random Walk,[0],[0]
Ltrw and Linfrw have the same expression but are optimized in different stages.,3.1 Goal-Directed Random Walk,[0],[0]
"Ltrw can be optimized during random walks, while Linfrw should be optimized in the inference stage.",3.1 Goal-Directed Random Walk,[0],[0]
"We rewrite Lrw for a specific path p as follows,
Lrw(p) = −y logPp − (1− y) log (1− Pp) (5)
where y is the label of the path p and y = 1 if p is beneficial to infer ρ.",3.1 Goal-Directed Random Walk,[0],[0]
"To obtain the best Φ, we compute gradients of Lrw as follows,
∇Lrw(p) =",3.1 Goal-Directed Random Walk,[0],[0]
"(∇Lrw(r12),∇Lrw(r23), ...)
∇Lrw(rij)",3.1 Goal-Directed Random Walk,[0],[0]
"= ( ∂Lrw(rij) ∂Φrij , ∂Lrw(rij) ∂Φrik1 , ∂Lrw(rij) ∂Φrik2 , ...)
∂Lrw(rij)
",3.1 Goal-Directed Random Walk,[0],[0]
∂Φrij =,3.1 Goal-Directed Random Walk,[0],[0]
(Pp − y) · (1− Prij ),3.1 Goal-Directed Random Walk,[0],[0]
"Φrij · (1− Pp)
∂Lrw(rij) ∂Φrik",3.1 Goal-Directed Random Walk,[0],[0]
=,3.1 Goal-Directed Random Walk,[0],[0]
− (Pp − y) ·,3.1 Goal-Directed Random Walk,[0],[0]
"Prij
Φrij · (1− Pp) (6)
where ∇Lrw(rij) is the component of ∇Lrw(p) at rij .",3.1 Goal-Directed Random Walk,[0],[0]
"Φ(r(i,",3.1 Goal-Directed Random Walk,[0],[0]
"j), ρ) and Φ(r(i, k), ρ) are the potentials for all triplets r(i, j) ∈ p and r(i, k) /∈",3.1 Goal-Directed Random Walk,[0],[0]
"p, and rij is short for r(i, j).",3.1 Goal-Directed Random Walk,[0],[0]
"After iteratively updating Φrij and Φrik by the gradient of L t rw, the random walks can
be directed to find more paths fromH to T , and consequently it increases efficiency of the random walk.",3.1 Goal-Directed Random Walk,[0],[0]
"After updating Φrij and Φrik by the gradient ofL inf rw , random walk is more likely to find high-quality paths but not noise.",3.1 Goal-Directed Random Walk,[0],[0]
"Therefore, the goal-directed random walk increases efficiency of mining benefic formulas and has a great capability of resisting noise.",3.1 Goal-Directed Random Walk,[0],[0]
"The potential Φ(r(i, j), ρ) measures an implicit relationship between two triplets in the KB, so the total number of parameters is the square of the KB size.",3.2 Distributional Potential Function,[0],[0]
It is hard to precisely estimate all Φ because of the sparsity of training data.,3.2 Distributional Potential Function,[0],[0]
"To reduce the number of parameters, we represent each entity or relation in the KB as a low-rank numeric vector which is called embeddings (Bordes et al., 2013), and then we build a potential function Ψ on embeddings as Φ(r(i, j), ρ) = Ψ(Er(i,j), ER(H,T )), where Er(i,j) and ER(H,T ) are the embeddings of triplets.",3.2 Distributional Potential Function,[0],[0]
"In practice, we set Er(i,j) =",3.2 Distributional Potential Function,[0],[0]
"[Er, Ej ] and ER(H,T ) =",3.2 Distributional Potential Function,[0],[0]
"[ER, ET ] because Ei is the same for all triplets r(i, ∗), where [] is a concatenation operator.
",3.2 Distributional Potential Function,[0],[0]
"In the view of the neural network, our goaldirected mechanism is analogous to the attention mechanism.",3.2 Distributional Potential Function,[0],[0]
"At each step, the algorithm estimates attentions for each neighboring edges by Ψ. Therefore, there are several existing expressions of Ψ, e.g., the dot product (Sukhbaatar et al., 2015) and the single-layer perceptron (Bahdanau et al., 2015).",3.2 Distributional Potential Function,[0],[0]
"We will not compare different forms of Ψ, the detail comparison has been presented in the work (Luong et al., 2015).",3.2 Distributional Potential Function,[0],[0]
"We directly employ the simplest dot product for Ψ as follows,
Ψ(Er(i,j), ER(H,T ))",3.2 Distributional Potential Function,[0],[0]
"= σ(Er(i,j) · ER(H,T )) (7)
where σ is a nonlinear function and we set it as an exponential function.",3.2 Distributional Potential Function,[0],[0]
Ψ has no parameters beside KB embeddings which are updated during the training period.,3.2 Distributional Potential Function,[0],[0]
"To handle the dependence between goal-directed random walk and subsequent inference, we combine them into an integrated model and optimize them together.",3.3 Integrated Inference Model,[0],[0]
"To predict ρ = R(H,T ), the integrated model first collects formulas for R(H,T ), and then
Algorithm 1:",3.3 Integrated Inference Model,[0],[0]
"Train Integrated Inference Model
Input: KB, Ξ Output: Ψ, W , F 1: For ρ = R(H,T ) ∈ Ξ 2: Repeat ρ-directed Random Walk from H to t 3: Update Ψ by Ltrw 4: If t = T , then F = F ∩ fp 5: Calculate Linf and L inf rw by ρ 6: Update W by Linf 7: Update Ψ by Linfrw 8: Remove f ∈ F with little wf 9: Output Ψ, W , F
merges estimations of different formulas as features into a score function χ,
χ(ρ) =",3.3 Integrated Inference Model,[0],[0]
"∑
f∈Fρ δ(f) (8)
where Fρ is the formula set obtained by random walks for ρ, and δ(f) is an estimation of formula f .",3.3 Integrated Inference Model,[0],[0]
"The original frequent pattern mining algorithm employs formulas’ confidence as δ(f) directly, but it does not produce good results (Galárraga et al., 2013).",3.3 Integrated Inference Model,[0],[0]
"There are two ways to solve the problem: one is selecting another more suitable measure of f as δ(f) (Tan et al., 2002); the other is attaching a weight to each formula and learning weights with supervision, e.g., MLN (Richardson and Domingos, 2006) .",3.3 Integrated Inference Model,[0],[0]
We employ the latter method and set δ(f) =,3.3 Integrated Inference Model,[0],[0]
wf ·nf .,3.3 Integrated Inference Model,[0],[0]
"Finally, we employ a logistic regression classifier to predict R(H,T ), and the posterior probability of R(H,T ) is shown as follows,
P (ρ = y|χ) =",3.3 Integrated Inference Model,[0],[0]
"F(χ)y(1−F(χ))1−y
F(χ) = 1 1 + e−χ
(9)
where y is a 0-1 label of ρ.",3.3 Integrated Inference Model,[0],[0]
"Similar to Ltrw in Equation (5), we treat the negative logarithm of P (ρ = y|χ) as the loss of inference, Linf = − logP (ρ = y|χ), and turn to minimize it.",3.3 Integrated Inference Model,[0],[0]
"Moreover, the loss Linfrw of the above goal-directed random walk is influenced by the result of predicting R(H,T ), so Φrij and Φrik will be also updated.",3.3 Integrated Inference Model,[0],[0]
"Algorithm 1 shows the main process of training, where Ξ is the triplet set for training, Ψ is the potential function in Equation (7), F is the formula set, fp is
a formula generated from the path p, and H,T, t are entities in the KB.",3.3 Integrated Inference Model,[0],[0]
"To predict ρ = R(H,T ), the algorithm first performs multi rounds of random walks, and each random walk can find a path pHt (at line 2).",3.3 Integrated Inference Model,[0],[0]
"Then the algorithm decides to update Ψ by Ltrw based on whether t is T (at line 3), and adds the formula pf into the formula set when t = T (at line 4).",3.3 Integrated Inference Model,[0],[0]
"After random walks, the inference model predicts ρ, and computes Linf and L inf rw according to the prediction result (at line 5).",3.3 Integrated Inference Model,[0],[0]
"FinallyW and Ψ are updated by Linf and L inf rw (at line 6-7), respectively.",3.3 Integrated Inference Model,[0],[0]
"After training by all triplets in Ξ, the algorithm removes formulas with low weights from F (at line 8) and outputs the model (at line 9).",3.3 Integrated Inference Model,[0],[0]
"When we infer a new triplet by this model, the process is similar to Algorithm 1.",3.3 Integrated Inference Model,[0],[0]
We first compare our approach with several state-ofart methods on link prediction task to explore our approach’s overall ability of inference.,4 Experiments,[0],[0]
"Subsequently, we evaluate formulas mined by different random walk methods to explore whether the goal-directed mechanism can increase efficiency of mining useful structures.",4 Experiments,[0],[0]
"Finally, we dive deep into the formulas generated by our approach to analyze the characters of our approach.",4 Experiments,[0],[0]
"We conduct experiments on both WN18 and FB15K datasets which are subsets sampled from WordNet (Miller, 1995) and Freebase (Bollacker et al., 2008), respectively, and Table 1 shows the statistics of them.",4.1 Datasets and Evaluation Setup,[0],[0]
"For the link prediction task, we predict the missing h or t for a triplet r(h, t) in test set.",4.1 Datasets and Evaluation Setup,[0],[0]
"The detail evaluation method is that t in r(h, t) is replaced by all entities in the KB and methods need to rank the right answer at the top of the list, and so does h in r(h, t).",4.1 Datasets and Evaluation Setup,[0],[0]
"We report the mean of those true answer ranks and the Hits@10 under both ’raw’ and ’filter’ as TransE (Bordes et al., 2013) does, where Hits@10 is the proportion of correct entities ranked in the top 10.
sults on relation form of government in FB15K.",4.1 Datasets and Evaluation Setup,[0],[0]
We employ two types of baselines.,4.2 Baselines,[0],[0]
"One type is based on random walks including: a) the basic random walk algorithm whose state transition probability matrix is shown in Equation (2); b) PRA in (Lao et al., 2011) which is a typical heuristic random walk algorithm.",4.2 Baselines,[0],[0]
"The other type is based on KB embeddings including TransE (Bordes et al., 2013), Rescal (Nickel et al., 2011), TransH (Wang et al., 2014b), TransR",4.2 Baselines,[0],[0]
"(Lin et al., 2015b).",4.2 Baselines,[0],[0]
"These embedding-based methods have no explicit formulas, so we will not evaluate their performances on mining formulas.",4.2 Baselines,[0],[0]
We implement three random walk methods under a unified framework.,4.3 Settings,[0],[0]
"To predict r(h, ∗) quickly, we first select Top-K candidate instances, t1→K , by TransE as (Wei et al., 2015), and then the algorithm infers each r(h, ti) and ranks them by inference results.",4.3 Settings,[0],[0]
"We adjust parameters for our approach with the validate dataset, and the optimal configurations are set as follows.",4.3 Settings,[0],[0]
"The rounds of random walk is 10, learning rate is 0.0001, training epoch is 100, the size of candidate set is 500 for WN18 and 100 for FB15K, the embeddings have 50 dimensionalities for WN18 and 100 dimensionalities for FB15K, and the embeddings are initialized by TransE. For some relations, random walk truly finds no practicable formulas, so we employ TransE to improve per-
formance for these relations.",4.3 Settings,[0],[0]
"For embedding-based methods, we use reported results directly since the evaluation datasets are identical.",4.3 Settings,[0],[0]
"We show the results of link prediction for our approach and all baselines in Table 2 (* means the mean of ranks for random walk methods are evaluated in the Top-K subset), and we can obtain the following observations:
1)",4.4 Results on Link Prediction,[0],[0]
"Our approach achieves good performances on both WN18 and FB15K. On the FB15K, our approach outperforms all baselines.",4.4 Results on Link Prediction,[0],[0]
It indicates that our approach is effective for inference.,4.4 Results on Link Prediction,[0],[0]
"On the WN18, three random walk methods have similar performances.",4.4 Results on Link Prediction,[0],[0]
"The reason is that most entities in WN18 only have a small number of neighbors, so RW and PRA can also find useful structures in a few rounds.
2) For FB15K, the performances of RW and PRA are both poor and even worse than a part of embedding-based methods, but the performance of our approach is still the best.",4.4 Results on Link Prediction,[0],[0]
"The reason is that there are too many relation types in FB15K, so goalless random walks introduce lots of noise.",4.4 Results on Link Prediction,[0],[0]
"Oppositely, our approach has a great capability of resisting noise for the goal-directed mechanism.
3) RW and PRA have similar performances on both datasets, which indicates the heuristic rule of PRA does not apply to all relations and formulas.",4.4 Results on Link Prediction,[0],[0]
"To further explore whether the goal-directed mechanism can increase efficiency of mining paths, we compare the three random walk methods by the number of paths mined.",4.5 Paths Recall by Random Walks,[0],[0]
"For each triplet R(H,T )
in the training set, we perform 10 rounds of random walks fromH and record the number of times which arrive at T, noted as Arr@10.",4.5 Paths Recall by Random Walks,[0],[0]
We respectively select one relation type from WN18 and FB15K and show the comparison result in Figure 2.,4.5 Paths Recall by Random Walks,[0],[0]
"We can obtain the following observations:
1) With the increase of training epochs, Arr@10 of the goal-directed random walk first increases and then stays around a high value on both WN18 and FB15K, but the Arr@10 of RW and PRA always stay the same.",4.5 Paths Recall by Random Walks,[0],[0]
"This phenomenon indicates that the goal-directed random walk is a learnable model and can be trained to find more useful structures with epochs increasing, but RW and PRA are not.
2) RW and PRA always have similar Arr@10, which means PRA has not found more formulas.",4.5 Paths Recall by Random Walks,[0],[0]
This indicates that the heuristic rule of PRA is not always be beneficial to mining more structures for all relations.,4.5 Paths Recall by Random Walks,[0],[0]
"In Table 3, we show a small number of formulas mined by our approach from FB15K, and the formulas represent different types.",4.6 Example Formulas,[0],[0]
"Some formulas contain clear logic, e.g, Formula 1 means that if the writer x contributes a story to the film y and y is adapted from the book z, x is the writer of the book z.",4.6 Example Formulas,[0],[0]
"Some formulas have a high probability of being satisfied, e.g., Formula 3 means the wedding place probably is also the burial place for some people, and Formula 7 means the parent of the person x died of the disease and thus the person x has a high risk of suffering from the disease.",4.6 Example Formulas,[0],[0]
"Some formulas depend on synonyms, e.g., story by and works written have the similar meaning in Formula 2.",4.6 Example Formulas,[0],[0]
"However, there are still useless formulas, e.g, Formula 8 is useless be-
cause the body of the formula is same as the head.",4.6 Example Formulas,[0],[0]
"Such useless formula can be removed by a superrule, which is that the head of a formula cannot occur in its body.",4.6 Example Formulas,[0],[0]
"Our work has two aspects, which are related to mining formula automatically and inference on KBs, respectively.
",5 Related Work,[0],[0]
"Inductive Logic Programming (ILP) (Muggleton and De Raedt, 1994) and Association Rule Mining (ARM) (Agrawal et al., 1993) are both early works on mining formulas.",5 Related Work,[0],[0]
"FOIT (Quinlan, 1990) and SHERLOCK (Schoenmackers et al., 2010) are typical ILP systems, but the former one usually need a lot of negative facts and the latter one focuses on mining formulas from text.",5 Related Work,[0],[0]
"AMIE (Galárraga et al., 2013) is based on ARM and proposes a new measure for formulas instead of the confidence.",5 Related Work,[0],[0]
"Several structure learning algorithms (Kok and Domingos, 2005; Kok and Domingos, 2009; Kok and Domingos, 2010) based on Markov Logic Network (MLN) (Richardson and Domingos, 2006) can also learn first order logic formulas automatically, but they are too slow to run on large KBs.",5 Related Work,[0],[0]
"ProPPR (Wang et al., 2013; Wang et al., 2014a) performs structure learning by depth first searching on the knowledge graph, which is still not efficient enough to handle webscale KBs.",5 Related Work,[0],[0]
"PRA (Lao and Cohen, 2010; Lao et al., 2011) is a method based on random walks and employs heuristic rules to direct random walks.",5 Related Work,[0],[0]
"PRA is closely related to our approach, but unlike it, our approach dynamically calculates state transition prob-
abilities.",5 Related Work,[0],[0]
"Another method based on random walks (Wei et al., 2015) merges embedding similarities of candidates into the random walk as a priori, while our approach employs KB embeddings to calculate potentials for neighbors.
",5 Related Work,[0],[0]
"The majority of mining formula methods can perform inference on KBs, and besides them, a dozen methods based KB embeddings can also achieve the inference goal, and the typical ones of them are TransE (Bordes et al., 2013), Rescal (Nickel et al., 2011), TransH (Wang et al., 2014b), TransR",5 Related Work,[0],[0]
"(Lin et al., 2015b).",5 Related Work,[0],[0]
These embedding-based methods take advantage of the implicit relationship between elements of the KB and perform inference by calculating similarities.,5 Related Work,[0],[0]
"There are also methods which combine inference formulas and KB embeddings, such as PTransE (Lin et al., 2015a) and ProPPR+MF (Wang and Cohen, 2016).",5 Related Work,[0],[0]
"In this paper, we introduce a goal-directed random walk algorithm to increase efficiency of mining useful formulas and decrease noise simultaneously.",6 Conclusion and Future Works,[0],[0]
The approach employs the inference target as the direction at each steps in the random walk process and is more inclined to visit structures helpful to inference.,6 Conclusion and Future Works,[0],[0]
"In empirical studies, we show our approach achieves good performances on link prediction task over large-scale KBs.",6 Conclusion and Future Works,[0],[0]
"In the future, we are interested in exploring mining formulas directly in the distributional spaces which may resolve the sparsity of formulas.",6 Conclusion and Future Works,[0],[0]
"This work was supported by the Natural Science Foundation of China (No. 61533018), the National Basic Research Program of China (No. 2014CB340503) and the National Natural Science Foundation of China (No. 61272332).",7 Acknowledgments,[0],[0]
And this work was also supported by Google through focused research awards program.,7 Acknowledgments,[0],[0]
"Deep inference on a large-scale knowledge base (KB) needs a mass of formulas, but it is almost impossible to create all formulas manually.",abstractText,[0],[0]
"Data-driven methods have been proposed to mine formulas from KBs automatically, where random sampling and approximate calculation are common techniques to handle big data.",abstractText,[0],[0]
"Among a series of methods, Random Walk is believed to be suitable for knowledge graph data.",abstractText,[0],[0]
"However, a pure random walk without goals still has a poor efficiency of mining useful formulas, and even introduces lots of noise which may mislead inference.",abstractText,[0],[0]
"Although several heuristic rules have been proposed to direct random walks, they do not work well due to the diversity of formulas.",abstractText,[0],[0]
"To this end, we propose a novel goaldirected inference formula mining algorithm, which directs random walks by the specific inference target at each step.",abstractText,[0],[0]
"The algorithm is more inclined to visit benefic structures to infer the target, so it can increase efficiency of random walks and avoid noise simultaneously.",abstractText,[0],[0]
The experiments on both WordNet and Freebase prove that our approach is has a high efficiency and performs best on the task.,abstractText,[0],[0]
Mining Inference Formulas by Goal-Directed Random Walks,title,[0],[0]
"Proceedings of the SIGDIAL 2015 Conference, pages 22–31, Prague, Czech Republic, 2-4 September 2015. c©2015 Association for Computational Linguistics",text,[0],[0]
Physically situated dialogue differs from traditional human-computer dialogue in that interactions will make use of reference to a dialogue agent’s surroundings.,1 Introduction,[0],[0]
"Tasks may fail due to dependencies on specific environment configurations, such as when a robot’s path to a goal is blocked.",1 Introduction,[0],[0]
"People will often help; in navigation dialogues they tend to ask proactive, task-related questions instead of simply signaling communication failure (Skantze, 2005).",1 Introduction,[0],[0]
They supplement the agent’s representation of the environment and allow it to complete tasks.,1 Introduction,[0],[0]
The current study establishes an empirical basis for grounding in physically situated contexts.,1 Introduction,[0],[0]
"We had people provide recovery strategies for a robot in various situations.
",1 Introduction,[0],[0]
"The focus of this work is on recovery from situated grounding problems, a type of miscommunication that occurs when an agent fails to uniquely map a person’s instructions to its surroundings (Marge and Rudnicky, 2013).",1 Introduction,[0],[0]
"A referential ambiguity is where an instruction resolves to more than one possibility (e.g., “Search the room on the left” when there are multiple rooms on the agent’s left); an impossible-to-execute problem
fails to resolve to any action (e.g., same instruction but there are no rooms on the agent’s left).",1 Introduction,[0],[0]
"A common strategy evidenced in human-human corpora is for people to ask questions to recover from situated grounding problems (Tenbrink et al., 2010).
",1 Introduction,[0],[0]
"Dialogue divides into two levels: that of managing the actual dialogue—determining who has the floor, that an utterance was recognized, etc.—and",1 Introduction,[0],[0]
"the dialogue that serves the main joint activities that dialogue partners are carrying out, like a human-robot team exploring a new area (Bangerter and Clark, 2003).",1 Introduction,[0],[0]
"Most approaches to grounding in dialogue systems are managing the dialogue itself, making use of spoken language input as an indicator of understanding (e.g., (Bohus, 2007; Skantze, 2007)).",1 Introduction,[0],[0]
Situated grounding problems are associated with the main joint activities; to resolve them we believe that the recovery model must be extended to include planning and environment information.,1 Introduction,[0],[0]
"Flexible recovery strategies make this possible by enabling dialogue partners to coordinate their joint activities and accomplish tasks.
",1 Introduction,[0],[0]
We cast the problem space as one where the agent aims to select the most efficient recovery strategy that would resolve a user’s intended referent.,1 Introduction,[0],[0]
We expect that this efficiency is tied to the cognitive load it takes to produce clarifications.,1 Introduction,[0],[0]
Viethen and Dale (2006) suggest a similar prediction in their study comparing human and automatically generated referring expressions of objects and their properties.,1 Introduction,[0],[0]
"We sought to answer the following questions in this work: • How good are people at detecting situated
grounding problems?",1 Introduction,[0],[0]
• How do people organize recovery strategies?,1 Introduction,[0],[0]
"• When resolving ambiguity, which properties do
people use to differentiate referents?",1 Introduction,[0],[0]
"• When resolving impossible-to-execute instruc-
tions, do people use active or passive ways to get the conversation back on track?
",1 Introduction,[0],[0]
"22
We determined the most common recovery strategies for referential ambiguity and impossible-toexecute problems.",1 Introduction,[0],[0]
Several patterns emerged that suggest ways that people expect agents to recover.,1 Introduction,[0],[0]
Ultimately we intend for dialogue systems to use such strategies in physically situated contexts.,1 Introduction,[0],[0]
Researchers have long observed miscommunication and recovery in human-human dialogue corpora.,2 Related Work,[0],[0]
"The HCRC MapTask had a direction giverdirection follower pair navigate two dimensional schematics with slightly different maps (Anderson et al., 1991).",2 Related Work,[0],[0]
Carletta (1992) proposed several recovery strategies following an analysis of this corpus.,2 Related Work,[0],[0]
"The SCARE corpus collected human-human dialogues in a similar scenario where the direction follower was situated in a three-dimensional virtual environment (Stoia et al., 2008).
",2 Related Work,[0],[0]
"The current study follows up an initial proposal set of recovery strategies for physically situated domains (Marge and Rudnicky, 2011).",2 Related Work,[0],[0]
Others have also developed recovery strategies for situated dialogue.,2 Related Work,[0],[0]
Kruijff et al. (2006) developed a framework for a robot mapping an environment that employed conversational strategies as part of the grounding process.,2 Related Work,[0],[0]
"A similar study focused on resolving misunderstandings in the humanrobot domain using the Wizard-of-Oz methodology (Koulouri and Lauria, 2009).",2 Related Work,[0],[0]
"A body of work on referring expression generation uses object attributes to generate descriptions of referents (e.g., (Guhe and Bard, 2008; Garoufi and Koller, 2014)).",2 Related Work,[0],[0]
"Viethen and Dale (2006) compared human-authored referring expressions of objects to existing natural language generation algorithms and found them to have very different content.
",2 Related Work,[0],[0]
Crowdsourcing has been shown to provide useful dialogue data:,2 Related Work,[0],[0]
Manuvinakurike and DeVault (2015) used the technique to collect gameplaying conversations.,2 Related Work,[0],[0]
"Wang et al. (2012) and Mitchell et al. (2014) have used crowdsourced data for training, while others have used it in real time systems (Lasecki et al., 2013; Huang et al., 2014).",2 Related Work,[0],[0]
"In this study, participants came up with phrases that a search-and-rescue robot should say in response to an operator’s command.",3 Method,[0],[0]
"The participant’s task was to view scenes in a virtual envi-
ronment then formulate the robot’s response to an operator’s request.",3 Method,[0],[0]
"Participants listened to an operator’s verbal command then typed in a response.
",3 Method,[0],[0]
"Scenes displayed one of three situations: referential ambiguity (more than one possible action), impossible-to-execute (zero possible actions), and executable (one possible action).",3 Method,[0],[0]
The instructions showed some example problems.,3 Method,[0],[0]
All situations involved one operator and one robot.,3 Method,[0],[0]
"After instructions and a practice trial, participants viewed scenes in one of 10 different environments (see Figure 1).",3.1 Experiment Design,[0],[0]
"They would first watch a flyover video of the robot’s environment, then view a screen showing labels for all possible referable objects in the scene.",3.1 Experiment Design,[0],[0]
The participant would then watch the robot enter the first scene.,3.1 Experiment Design,[0],[0]
"The practice trial and instructions did not provide any examples of questions.
",3.1 Experiment Design,[0],[0]
The robot would stop and a spoken instruction from the operator would be heard.,3.1 Experiment Design,[0],[0]
The participant was free to replay the instruction multiple times.,3.1 Experiment Design,[0],[0]
They would then enter a response (say an acknowledgment or a question).,3.1 Experiment Design,[0],[0]
"Upon completion of the trial, the robot would move to a different scene, where the process was repeated.
",3.1 Experiment Design,[0],[0]
Only self-contained questions that would allow the operator to answer without follow-up were allowed.,3.1 Experiment Design,[0],[0]
Thus generic questions like “which one?” would not allow the operator to give the robot enough useful information to proceed.,3.1 Experiment Design,[0],[0]
"In the instructions, we suggested that participants include some detail about the environment in their ques-
tions.",3.1 Experiment Design,[0],[0]
Participants used a web form1 to view situations and provide responses.,3.1 Experiment Design,[0],[0]
"We recorded demographic information (gender, age, native language, native country) and time on task.",3.1 Experiment Design,[0],[0]
"The instructions had several attention checks (Paolacci et al., 2010) to ensure that participants were focusing on the task.
",3.1 Experiment Design,[0],[0]
We created fifty trials across ten environments.,3.1 Experiment Design,[0],[0]
Each environment had five trials that represented waypoints the robot was to reach.,3.1 Experiment Design,[0],[0]
Participants viewed five different environments (totaling twenty-five trials).,3.1 Experiment Design,[0],[0]
Each command from the remote operator to the robot was a route instruction in the robot navigation domain.,3.1 Experiment Design,[0],[0]
Trials were assembled in two groups and participants were assigned randomly to one (see Table 1).,3.1 Experiment Design,[0],[0]
Trial order was randomized according to a Latin Square.,3.1 Experiment Design,[0],[0]
"Scenes were of a 3D virtual environment at eye level, with the camera one to two meters behind the robot.",3.1.1 Scenes and Environments,[0],[0]
"Camera angle issues with environment objects caused this variation.
",3.1.1 Scenes and Environments,[0],[0]
Participants understood that the fictional operator was not co-located with the robot.,3.1.1 Scenes and Environments,[0],[0]
The USARSim robot simulation toolkit and the UnrealEd game map editor were used to create the environment.,3.1.1 Scenes and Environments,[0],[0]
"Cepstral’s SwiftTalker was used for the operator voice.
",3.1.1 Scenes and Environments,[0],[0]
"Of the fifty scenes, twenty-five (50%) had referential ambiguities, fifteen (30%) were impossible-to-execute, and ten (20%) were executable controls.",3.1.1 Scenes and Environments,[0],[0]
"The selection was weighted to referential ambiguity, as these were expected to produce greater variety in recovery strategies.",3.1.1 Scenes and Environments,[0],[0]
"We randomly assigned each of fifty trials a stimulus type according to this distribution, then divided the list into ten environments.",3.1.1 Scenes and Environments,[0],[0]
"The environments featured objects and doorways appropriate to the trial type, as well as waypoints.
1See http://goo.gl/forms/ZGpK3L1nPh for an example.
",3.1.1 Scenes and Environments,[0],[0]
"Referential Ambiguity We arranged the sources of information participants could use to describe referents, to enable analysis of the relationship between context and recovery strategies.",3.1.1 Scenes and Environments,[0],[0]
"The sources of information (i.e., “situated dimensions”) were: (1) intrinsic properties (either color or size), (2) history (objects that the robot already encountered), (3) egocentric proximity of the robot to candidate referents around it (the robot’s perspective is always taken), and (4) object proximity (proximity of candidate referents to other objects).",3.1.1 Scenes and Environments,[0],[0]
"Table 2 provides additional details.
",3.1.1 Scenes and Environments,[0],[0]
Scenes with referential ambiguity had up to four sources of information available.,3.1.1 Scenes and Environments,[0],[0]
"Information sources were evenly distributed across five trial types: one that included all four sources, and four that included all but one source of information (e.g., one division excluded using history information but did allow proximity, spatial, and object properties, one excluded proximity, etc.).
",3.1.1 Scenes and Environments,[0],[0]
Impossible-to-Execute The impossible-to-execute trials divided into two broad types.,3.1.1 Scenes and Environments,[0],[0]
Nine of the fifteen scenes were impossible because the operator’s command did not match to any referent in the environment.,3.1.1 Scenes and Environments,[0],[0]
"The other six scenes were impossible because a path to get to the matching referent was not possible.
",3.1.1 Scenes and Environments,[0],[0]
Executable Ten scenes were executable for the study and served as controls.,3.1.1 Scenes and Environments,[0],[0]
"The operator’s command mentioned existing, unambiguous referents.",3.1.1 Scenes and Environments,[0],[0]
Participants were aware of the robot’s capabilities before the start of the experiment.,3.1.2 Robot Capabilities,[0],[0]
The instructions said that the robot knew the locations of all objects in the environment and whether doors were closed or open.,3.1.2 Robot Capabilities,[0],[0]
"The robot also knew the color and size of objects in the environment (intrinsic properties), where objects were relative to the robot itself and to other objects (proximity), when objects were right, left, in front, and behind it (spatial terms), the room and hallway locations of objects (location), and the places it has been (history, the robot kept track of which objects it had visited).",3.1.2 Robot Capabilities,[0],[0]
The robot could not pass through closed doors.,3.1.2 Robot Capabilities,[0],[0]
"We made five hypotheses about the organization and content of participant responses to situated grounding problems:
• Hypothesis 1: Participants will have more difficulty detecting impossible-to-execute scenes than ambiguous ones.",3.2 Hypotheses,[0],[0]
"Determining a robot’s tasks to be impossible requires good situation awareness (Nielsen et al., 2007) (i.e., an understanding of surroundings with respect to correctly completing tasks).",3.2 Hypotheses,[0],[0]
"Detecting referential ambiguity requires understanding the operator’s command and visually inspecting the space (Spivey et al., 2002); detecting impossible commands also requires recalling the robot’s capabilities and noticing obstacles.",3.2 Hypotheses,[0],[0]
"Previous research has noted that remote teleoperators have trouble establishing good situation awareness of a robot’s surroundings (Casper and Murphy, 2003; Burke et al., 2004).",3.2 Hypotheses,[0],[0]
"Moreover, obstacles near a robot can be difficult to detect with a restricted view as in the current study (Alfano and Michel, 1990; Arthur, 2000).",3.2 Hypotheses,[0],[0]
•,3.2 Hypotheses,[0],[0]
"Hypotheses 2a and 2b: Responses will more commonly be single, self-contained questions instead of a scene description followed by a question (2a for scenes with referential ambiguity, 2b for scenes that were impossible-toexecute).",3.2 Hypotheses,[0],[0]
"This should reflect the principle of least effort (Clark, 1996), and follow from Carletta’s (1992) observations in a similar dataset.",3.2 Hypotheses,[0],[0]
•,3.2 Hypotheses,[0],[0]
Hypothesis 3: Responses will use the situated dimensions that require the least cognitive effort when disambiguating referents.,3.2 Hypotheses,[0],[0]
Viethen and Dale (2006) suggest that minimizing cognitive load for the speaker or listener would produce more human-like referring expressions.,3.2 Hypotheses,[0],[0]
"We predict that responses will mention visually salient features of the scene, such as color or size of referents, more than history or object proximity.",3.2 Hypotheses,[0],[0]
"Desimone and Duncan (1995) found that color and shape draw more attention than other
properties in visual search tasks when they are highly distinguishable.",3.2 Hypotheses,[0],[0]
•,3.2 Hypotheses,[0],[0]
"Hypothesis 4: In cases of referential ambiguity where two candidate referents are present, responses will confirm one referent in the form of a yes-no question more than presenting a list.",3.2 Hypotheses,[0],[0]
"Results from an analysis of task-oriented dialogue suggests that people are efficient when asking clarification questions (Rieser and Moore, 2005).",3.2 Hypotheses,[0],[0]
"Additionally, Clark’s least effort principle (Clark, 1996) suggests that clarifying one referent using a yes-no confirmation would require less effort than presenting a list in two ways: producing a shorter question and constraining the range of responses to expect.",3.2 Hypotheses,[0],[0]
•,3.2 Hypotheses,[0],[0]
"Hypothesis 5: For impossible-to-execute instructions, responses will most commonly be ways for the robot to proactively work with the operator’s instruction, in an effort to get the conversation back on track.",3.2 Hypotheses,[0],[0]
"The other possible technique, to simply declare that the problem is not possible, will be less common.",3.2 Hypotheses,[0],[0]
This is because participants will believe such a strategy will not align with the task goal of having the robot say something that will allow it to proceed with the task.,3.2 Hypotheses,[0],[0]
"Skantze found that in human-human navigation dialogues, people would prefer to look for alternative ways to proceed rather than simply express nonunderstanding (Skantze, 2005).",3.2 Hypotheses,[0],[0]
"The key independent variable in this study was the stimulus type that the participant viewed (i.e., referential ambiguity, impossible-to-execute, or executable).",3.3 Measures,[0],[0]
"Dependent variables were observational measurements, presented below.",3.3 Measures,[0],[0]
"We report Fleiss’ kappa score for inter-annotator agreement
between three native English speaking annotators on a subset of the data.
",3.3 Measures,[0],[0]
Correctness (κ = 0.77):,3.3 Measures,[0],[0]
"Whether participants correctly determined the situation as ambiguous, impossible, or executable.",3.3 Measures,[0],[0]
Annotators labeled correctness based on the content of participant responses.,3.3 Measures,[0],[0]
This measure assessed participant accuracy for detecting situated grounding problems.,3.3 Measures,[0],[0]
"Either correct or incorrect.
",3.3 Measures,[0],[0]
"Sentence type (κ = 0.82): Either declarative, interrogative, imperative, or exclamatory (Cowan, 2008).
",3.3 Measures,[0],[0]
Question type (κ = 0.92): Sentences that needed an answer from the operator.,3.3 Measures,[0],[0]
"The three types were yes-no questions, alternative questions (which presented a list of options and includes wh- questions that used sources from Table 2), and generic wh- questions (Cowan, 2008).
",3.3 Measures,[0],[0]
Situated dimensions in response (κ = 0.75):,3.3 Measures,[0],[0]
The capability (or capabilities) that the participant mentioned when providing a response.,3.3 Measures,[0],[0]
"The types were intrinsic (color or size), object proximity, egocentric proximity, and history.
",3.3 Measures,[0],[0]
"Projected belief (impossible-to-execute trials only, κ = 0.80):",3.3 Measures,[0],[0]
"The participant’s belief about the next task, given the current operator instruction (projected onto the robot).",3.3 Measures,[0],[0]
"The types were unknown (response indicates participant is unsure what to do next), ask for more (ask for more details), propose alternative (propose alternative object), ask for help (ask operator to physically manipulate environment), and off topic.",3.3 Measures,[0],[0]
We recruited 30 participants.,3.4 Participation,[0],[0]
"All participants completed the web form through the Amazon Mechanical Turk (MTurk) web portal2, all were located in the United States and had a task approval rate ≥95%.",3.4 Participation,[0],[0]
The group included 29 self-reported native English speakers born in the United States; 1 self-reported as a native Bangla speaker born in Bangladesh.,3.4 Participation,[0],[0]
The gender distribution was 15 male to 15 female.,3.4 Participation,[0],[0]
"Participants ranged in age from 22 to 52 (mean: 33 years, std. dev.: 7.7).",3.4 Participation,[0],[0]
They were paid between $1 and $2 for their participation.,3.4 Participation,[0],[0]
"We
2https://www.mturk.com
collected a total of 750 responses.",3.4 Participation,[0],[0]
We analyzed the measures by tabulating frequencies for each possible value.,4 Results,[0],[0]
Table 3 presents some example responses.,4 Results,[0],[0]
"In general, participants were good at detecting situated grounding problems.",4.1 Correctness,[0],[0]
"Out of 750 responses, 667 (89%) implied the correct scene type.",4.1 Correctness,[0],[0]
"We analyzed correctness across actual stimulus types (ambiguous, impossible-to-execute, executable) using a mixed-effects analysis of variance model3, with participant included as a random effect and trial group as a fixed effect.
",4.1 Correctness,[0],[0]
Hypothesis 1 predicted that participants will do better detecting scenes with referential ambiguity than those that were impossible-to-execute; the results support this hypothesis.,4.1 Correctness,[0],[0]
"Actual stimulus type had a significant main effect on correctness (F[2, 58] = 12.3, p < 0.001); trial group did not (F[1, 28] = 0.1, p = 0.72).",4.1 Correctness,[0],[0]
Participants had significantly worse performance detecting impossible-to-execute scenes compared to ambiguous ones (p< 0.001; Tukey HSD test).,4.1 Correctness,[0],[0]
"In fact, they were four times worse; of the impossible-toexecute scenes, participants failed to detect that 22% (50/225) of them were impossible, compared to 5% (17/375) of scenes with referential ambiguity.",4.1 Correctness,[0],[0]
"Of the 150 instructions that were executable, participants failed to detect 11% (16/150) of them as such.",4.1 Correctness,[0],[0]
"We analyzed the 358 responses where participants correctly detected referential ambiguity.
",4.2 Referential Ambiguity,[0],[0]
"3This approach computed standard least squares regression using reduced maximum likelihood (Harville, 1977).
",4.2 Referential Ambiguity,[0],[0]
"Hypothesis 2a predicted that participants would more commonly ask single, self-contained questions instead of describing the scene and asking a question.",4.2 Referential Ambiguity,[0],[0]
We assessed this by counting sentence types within a response.,4.2 Referential Ambiguity,[0],[0]
Responses that had both a declarative sentence and an interrogative would fit this case.,4.2 Referential Ambiguity,[0],[0]
The results confirmed this hypothesis.,4.2 Referential Ambiguity,[0],[0]
"Only 4.5% (16/358) of possible responses had a declarative and an interrogative.
",4.2 Referential Ambiguity,[0],[0]
Hypothesis 3 predicted that participants would use the situated dimensions that require the least cognitive effort when disambiguating referents.,4.2 Referential Ambiguity,[0],[0]
"More specifically, the most common mentions will be those that are visually apparent (intrinsic properties like color and size), while those that require more processing would have fewer mentions (history and to a lesser extent object proximity and egocentric proximity).",4.2 Referential Ambiguity,[0],[0]
"We measured this by tabulating mentions of situated dimensions in all 358 correct participant responses, summarized in Figure 2.",4.2 Referential Ambiguity,[0],[0]
Multiple dimensions could occur in a single response.,4.2 Referential Ambiguity,[0],[0]
The results support this hypothesis.,4.2 Referential Ambiguity,[0],[0]
"By far, across all ambiguous scenarios, the most mentioned dimension was an intrinsic property.",4.2 Referential Ambiguity,[0],[0]
"More than half of all situated dimensions used were intrinsic (59%, 242/410 total mentions).",4.2 Referential Ambiguity,[0],[0]
"This was followed by the dimensions that we hypothesize require more cognitive effort: egocentric proximity had 30% (125/410) of mentions, object proximity 9.5% (39/410), and history 1% (4/410).",4.2 Referential Ambiguity,[0],[0]
"Of the intrinsic dimensions mentioned, most were only color (61%, 148/242), followed by size (33%, 81/242), and using both (5%, 13/242).
",4.2 Referential Ambiguity,[0],[0]
Hypothesis 4 predicted that participants would ask yes-no confirmation questions in favor of presenting lists when disambiguating a referent with exactly two candidates.,4.2 Referential Ambiguity,[0],[0]
"The results suggest that the opposite is true; people strongly preferred to
list options, even when a confirmation question about one would have been sufficient.",4.2 Referential Ambiguity,[0],[0]
"Of the 285 responses that were correctly detected as ambiguous and were for scenes of exactly two possible referents, 74% (212/285) presented a list of options.",4.2 Referential Ambiguity,[0],[0]
Only 14% (39/285) asked yes-no confirmation questions.,4.2 Referential Ambiguity,[0],[0]
The remaining 34 questions (12%) were generic wh-questions.,4.2 Referential Ambiguity,[0],[0]
These results held in scenes where three options were present.,4.2 Referential Ambiguity,[0],[0]
"Overall 72% (259/358) presented a list of options, while 16% (58/358) asked generic wh-questions and 11% (41/358) asked yes-no confirmations.",4.2 Referential Ambiguity,[0],[0]
"We analyzed the 175 responses where participants correctly identified impossible-to-execute situations.
",4.3 Impossible-to-Execute,[0],[0]
Hypothesis 2b predicted that participants would more often only ask a question than also describe the scene.,4.3 Impossible-to-Execute,[0],[0]
Results confirmed this hypothesis.,4.3 Impossible-to-Execute,[0],[0]
"42% (73/175) of responses simply asked a question, while 22% (39/175) used only a declarative.",4.3 Impossible-to-Execute,[0],[0]
"More than a third included a declarative as well (36%, 63/175).",4.3 Impossible-to-Execute,[0],[0]
"The general organization to these was to declare the problem then ask a question about it (89%, 56/63).
",4.3 Impossible-to-Execute,[0],[0]
"Hypothesis 5 predicted that responses for impossible-to-execute instructions will more commonly be proactive and make suggestions, instead of simply declaring that an action was not possible.",4.3 Impossible-to-Execute,[0],[0]
"Table 4 summarizes the results, which confirmed this hypothesis.",4.3 Impossible-to-Execute,[0],[0]
The most common belief that participants had for the robot was to have it propose an alternative referent to the impossible one specified by the operator.,4.3 Impossible-to-Execute,[0],[0]
The next-most common was to have the robot simply express uncertainty about what to do next.,4.3 Impossible-to-Execute,[0],[0]
"Though this belief occurred in about a third of responses, the remaining responses were all proactive ways for the robot to get the conversation back on track (i.e., propose alternative, ask for more, and ask for help).",4.3 Impossible-to-Execute,[0],[0]
"The results largely support the hypotheses, with the exception of Hypothesis 4.",5 Discussion,[0],[0]
"They also provide information about how people expect robots to recover from situated grounding problems.
",5 Discussion,[0],[0]
"Correctness Participants had the most trouble detecting impossible-to-execute scenes, supporting Hypothesis 1.",5 Discussion,[0],[0]
"An error analysis of the 50 responses for this condition had participants responding as if the impossible scenes were possible (62%, 31/50).",5 Discussion,[0],[0]
"The lack of good situation awareness was a factor, which agrees with previous findings in the human-robot interaction literature (Casper and Murphy, 2003; Burke et al., 2004).",5 Discussion,[0],[0]
We found that participants had trouble with a specific scene where they confused the front and back of the robot (9 of the 31 impossibleexecutable responses were for this scene).,5 Discussion,[0],[0]
"Note that all scenes showed the robot entering the room with the same perspective, facing forward.
",5 Discussion,[0],[0]
"Referential Ambiguity Results for Hypothesis 2a showed that participants overwhelmingly asked only a single, self-contained question as opposed to first stating that there was an ambiguity.",5 Discussion,[0],[0]
"Participants also preferred to present a list of options, despite the number of possible candidates.",5 Discussion,[0],[0]
"This contradicted Hypothesis 4. Rieser and Moore (2005) found that in task-oriented human-human dialogues, clarification requests aim to be as efficient as possible; they are mostly partially formed.",5 Discussion,[0],[0]
The results in our study were not of real-time dialogue; we isolated specific parts of what participants believed to be human-computer dialogue.,5 Discussion,[0],[0]
"Moreover, Rieser and Moore were observing clarifications at Bangerter and Clark’s (2003) dialogue management level; we were observing them in service of the joint activity of navigating the robot.",5 Discussion,[0],[0]
"We believe that this difference resulted in participants using caution by disambiguating with lists.
",5 Discussion,[0],[0]
"These results suggest that dialogue systems should present detection of referential ambiguity implicitly, and as a list.",5 Discussion,[0],[0]
"Generic wh- questions (e.g., “which one?” without presenting a followon list) are less desirable because they don’t constrain what the user can say, and don’t provide any indication of what the dialogue system can understand.",5 Discussion,[0],[0]
"A list offers several benefits: it grounds awareness of surroundings, presents a fixed set of options to the user, and constrains the range of
linguistic responses.",5 Discussion,[0],[0]
"This could also extend to general ambiguity, as in when there are a list of matches to a query, but that is outside the scope of this work.",5 Discussion,[0],[0]
"Lists may be less useful as they grow in size; in our study they could not grow beyond three candidates.
",5 Discussion,[0],[0]
The data also supported Hypothesis 3.,5 Discussion,[0],[0]
Participants generally preferred to use situated dimensions that required less effort to describe.,5 Discussion,[0],[0]
"Intrinsic dimensions (color and size) had the greatest count, followed by egocentric proximity, object proximity, and finally using history.",5 Discussion,[0],[0]
"We attribute these results to the salient nature of intrinsic properties compared to ones that must be computed (i.e., egocentric and object proximity require spatial processing, while history requires thinking about previous exchanges).",5 Discussion,[0],[0]
This also speaks to a similar claim by Viethen and Dale (2006).,5 Discussion,[0],[0]
"Responses included color more than any other property, suggesting that an object’s color draws more visual attention than its size.",5 Discussion,[0],[0]
"Bright colors and big shapes stand out most in visual search tasks; we had more of the former than the latter (Desimone and Duncan, 1995).
",5 Discussion,[0],[0]
"For an ambiguous scene, participants appear to traverse a salience hierarchy (Hirst et al., 1994) whereby they select the most visually salient feature that also uniquely teases apart candidates.",5 Discussion,[0],[0]
"While the salience hierarchy varies depending on the current context of a referent, we anticipate such a hierarchy can be defined computationally.",5 Discussion,[0],[0]
"Others have proposed similar processes for referring expression generation (Van Der Sluis, 2005; Guhe and Bard, 2008).",5 Discussion,[0],[0]
One way to rank salience on the hierarchy could be predicted mental load; we speculate that this is a reason why history was barely mentioned to disambiguate.,5 Discussion,[0],[0]
"Another would be to model visual attention, which could explain why color was so dominant.
",5 Discussion,[0],[0]
"Note that only a few dimensions were “competing” at any given time, and their presence in the scenes was equal (save for history, which had slightly fewer due to task design constraints).",5 Discussion,[0],[0]
"Egocentric proximity, which uses spatial language to orient candidate referents relative to the robot, had a moderate presence.",5 Discussion,[0],[0]
"When intrinsic properties were unavailable in the scene, responses most often used this property.",5 Discussion,[0],[0]
"We found that sometimes participants would derive this property even if it wasn’t made prototypical in the scene (e.g., referring to a table as “left” when it was in front and
off to the left side of the robot).",5 Discussion,[0],[0]
This suggests that using egocentric proximity to disambiguate makes a good fallback strategy when nothing else works.,5 Discussion,[0],[0]
"Another situated dimension emerged from the responses, disambiguation by location (e.g., “Do you mean the box in this room or the other one?”).",5 Discussion,[0],[0]
"Though not frequent, it provides another useful technique to disambiguate when visually salient properties are not available.
",5 Discussion,[0],[0]
"Our findings differ from those of Carlson and Hill (2009) who found that salience is not as prominent as spatial relationships between a target (in the current study, this would be the robot) and other objects.",5 Discussion,[0],[0]
Our study did not direct participants to formulate spatial descriptions; they were free to compose responses.,5 Discussion,[0],[0]
"In addition, our work directly compares intrinsic properties for objects of the same broad type (e.g., disambiguation of a doors of different colors).",5 Discussion,[0],[0]
"Our findings suggest the opposite of Moratz et al. (2003), who found that when pointing out an object, describing its position may be better than describing its attributes in human-robot interactions.",5 Discussion,[0],[0]
"Their study only had one object type (cube) and did not vary color, size, or proximity to nearby objects.",5 Discussion,[0],[0]
"As a result, participants described objects using spatial terms.",5 Discussion,[0],[0]
"In our study, we explored variation of several attributes to determine participants’ preferences.
",5 Discussion,[0],[0]
Impossible-to-Execute Results supported Hypothesis 2b.,5 Discussion,[0],[0]
Most responses had a single sentence type.,5 Discussion,[0],[0]
"Although unanticipated, a useful strategy emerged: describe the problem that makes the scene impossible, then propose an alternative referent.",5 Discussion,[0],[0]
This type of strategy helped support Hypothesis 5.,5 Discussion,[0],[0]
"Responses for impossible scenes largely had the participant proactively presenting a way to move the task forward, similar to what Skantze (2005) observed in human-human dialogues.",5 Discussion,[0],[0]
This suggests that participants believed the robot should ask directed questions to recover.,5 Discussion,[0],[0]
These questions often took the form of posing alternative options.,5 Discussion,[0],[0]
We used the Amazon Mechanical Turk web portal to gather responses in this study.,5.1 Limitations,[0],[0]
"As such we could not control the participant environment when taking the study, but we did include attention checks.",5.1 Limitations,[0],[0]
"Participants did not interact with a
dialogue system.",5.1 Limitations,[0],[0]
Instead we isolated parts of the interaction that were instances of where the robot would have to say something in response to an instruction.,5.1 Limitations,[0],[0]
We asked participants to provide what they think the robot should say; there was no ongoing interaction.,5.1 Limitations,[0],[0]
"However, we maintained continuity by presenting videos of the robot navigating through the environment as participants completed the task.",5.1 Limitations,[0],[0]
"The robot was represented in a virtual environment, which prevents us from understanding if there are any influencing factors that may impact results if the robot were in physical form or co-present with the participant.",5.1 Limitations,[0],[0]
Recovery strategies allow situated agents like robots to recover from misunderstandings by using the human dialogue partner.,6 Conclusions,[0],[0]
We conducted a study that collected recovery strategies for physically situated dialogue with the goal of establishing an empirical basis for grounding in physically situated contexts.,6 Conclusions,[0],[0]
"We crowdsourced 750 written strategies across 30 participants and analyzed their situated properties and how they were organized.
",6 Conclusions,[0],[0]
We found that participants’ recovery strategies minimize cognitive effort and indicate a desire to successfully complete the task.,6 Conclusions,[0],[0]
"For disambiguation, there was a preference for strategies that use visually salient properties over ones that require additional mental processing, like spatial reasoning or memory recall.",6 Conclusions,[0],[0]
"For impossible-to-execute scenes, responses more often presented alternative referents than just noting non-understanding.",6 Conclusions,[0],[0]
"We should note that some differences between our findings and those of others may in part rest on differences in task and environment, though intrinsic variables such as mental effort will likely persist over different situations.
",6 Conclusions,[0],[0]
"In future work, we intend to use these data to model salience ranking in similar contexts.",6 Conclusions,[0],[0]
We will further assess the hypothesis that participants’ preferences in this study will enhance performance in a spoken dialogue system that deploys similar strategies.,6 Conclusions,[0],[0]
The authors thank Prasanna Kumar Muthukumar and Juneki Hong for helping to annotate recovery strategies.,Acknowledgments,[0],[0]
"We also thank Taylor Cassidy, Arthur William Evans, and the anonymous reviewers for their valuable comments.",Acknowledgments,[0],[0]
We describe an empirical study that crowdsourced human-authored recovery strategies for various problems encountered in physically situated dialogue.,abstractText,[0],[0]
The purpose was to investigate the strategies that people use in response to requests that are referentially ambiguous or impossible to execute.,abstractText,[0],[0]
"Results suggest a general preference for including specific kinds of visual information when disambiguating referents, and for volunteering alternative plans when the original instruction was not possible to carry out.",abstractText,[0],[0]
Miscommunication Recovery in Physically Situated Dialogue,title,[0],[0]
Feature selection is an important step in extracting interpretable patterns from data.,1. Introduction,[0],[0]
"It has numerous applications in a wide range of areas, including natural-language processing, genomics, and chemistry.",1. Introduction,[0],[0]
"Suppose that there are n or-
*These authors contributed equally and are listed alphabetically 1Department of Electrical Engineering, Stanford University, Stanford, California 2Department of Computer Science, Rice University, Houston, Texas 3Department of Electrical and Computer Engineering, Rice University, Houston, Texas.",1. Introduction,[0],[0]
"Correspondence to: Anshumali Shrivastava <anshumali@rice.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"dered pairs (Xi, yi)i∈[n], where Xi ∈ Rp are p-dimensional feature vectors, and yi ∈ R are scalar outputs.",1. Introduction,[0],[0]
"Feature selection aims to identify a small subset of features (coordinates of the p-dimensional feature vector) that best models the relationship between the data Xi and the output yi.
",1. Introduction,[0],[0]
A significant complication that is common in modern engineering and scientific applications is that the feature space p is ultra high-dimensional.,1. Introduction,[0],[0]
"For example, Weinberger introduced a dataset with 16 trillion (p = 1013) unique features (Weinberger et al., 2009).",1. Introduction,[0],[0]
A 16 trillion dimensional feature vector (of double 8 bytes) requires 128 terabytes of working memory.,1. Introduction,[0],[0]
Problems from modern genetics are even more challenging.,1. Introduction,[0],[0]
A particularly useful way to represent a long DNA sequence is by a feature vector that counts the occurrence frequency of all length-K sub-strings called K-mers.,1. Introduction,[0],[0]
"This representation plays an important role in large-scale regression problems in computational biology (Wood & Salzberg, 2014; Bray et al., 2015; Vervier et al., 2016; Aghazadeh et al., 2016).",1. Introduction,[0],[0]
"Typically, K is chosen to be larger than 12, and these strings are composed of all possible combinations of 16 characters ({A,T,C,G} in addition to 12 wild card characters).",1. Introduction,[0],[0]
"In this case, the feature vector dimension is p = 1612 = 248.",1. Introduction,[0],[0]
"A vector of size 248 single-precision variables requires approximately 1 petabyte of space!
",1. Introduction,[0],[0]
"For ultra large-scale feature selection problems, it is impossible to run standard explicit regularization-based methods like `1-regularization (Shalev-Shwartz & Tewari, 2011; Tan et al., 2014) or to select hyperparameters with a constrained amount of memory (Langford et al., 2009).",1. Introduction,[0],[0]
"This is not surprising, because these methods are not scalable in terms of memory and computational time (Duchi et al., 2008).",1. Introduction,[0],[0]
Another important operational concern is that most datasets represent features in the form of strings or tokens.,1. Introduction,[0],[0]
"For example, with DNA or n-gram datasets, features are represented by strings of characters.",1. Introduction,[0],[0]
"Even in click-through data (McMahan et al., 2013), features are indexed by textual tokens.",1. Introduction,[0],[0]
Observe that mapping each of these strings to a vector component requires maintaining a dictionary whose size equals the length of the feature vector.,1. Introduction,[0.9501601146676599],"['Above we’ve characterized a bandit algorithmA as gathering data adaptively using a sequence of selection functions ft, which map the observed history Λt ∈ Ht−1 to the index of the next arm pulled.']"
"As a result, one does not even have the capability to create a numerical exact vector representation of the features.
",1. Introduction,[0],[0]
"Typically, when faced with such large machine learning tasks, the practitioner chooses to do feature hashing (Weinberger et al., 2009).",1. Introduction,[0],[0]
Consider a 3-gram string “abc”.,1. Introduction,[0],[0]
"With feature hashing, one uses a lossy, random hash function h : strings → {0, 1, 2, . . .",1. Introduction,[0],[0]
", R} to map “abc” to a feature number h(abc) in the range {0, 1, 2, . .",1. Introduction,[0],[0]
.,1. Introduction,[0],[0]
", R}.",1. Introduction,[0],[0]
This is extremely convenient because it enables one to avoid creating a large look-up dictionary.,1. Introduction,[0],[0]
"Furthermore, this serves as a dimensionality reduction technique, reducing the problem dimension to R. Unfortunately, this convenience comes at a cost.",1. Introduction,[0],[0]
"Given that useful dimensionality reduction is strictly surjective (i.e., R < p), we lose the identity of the original features.",1. Introduction,[0],[0]
"This is not a viable option if one cares about both feature selection and interpretability.
",1. Introduction,[0],[0]
"One reason to remain hopeful is that in such highdimensional problems, the data vectors Xi are extremely sparse (Wood & Salzberg, 2014).",1. Introduction,[0],[0]
"For instance, the DNA sequence of an organism contains only a small fraction (at most the length of the DNA sequence) of p = 1612 features.",1. Introduction,[0],[0]
"The situation is similar whether we are predicting clickthrough rates of users on a website or if we seek n-gram representations of text documents (Mikolov et al., 2013).",1. Introduction,[0],[0]
"In practice, ultra high-dimensional data is almost always ultrasparse.",1. Introduction,[0],[0]
"Thus, loading a sparse data vector into memory is usually not a concern.",1. Introduction,[0],[0]
"The problem arises in the intermediate stages of traditional methods, where dense iterates need to be tracked in the main memory.",1. Introduction,[0],[0]
"One popular approach is to use greedy thresholding methods (Maleki, 2009; Mikolov et al., 2013; Jain et al., 2014; 2017) combined with stochastic gradient descent (SGD) to prevent the feature vector β from becoming too dense and blowing up in memory.",1. Introduction,[0],[0]
"In these methods, the intermediate iterates are regularized at each step, and a full gradient update is never stored nor computed (since this is memory and computation intensive).",1. Introduction,[0],[0]
"However, it is well known that greedy thresholding can be myopic and can result in poor convergence.",1. Introduction,[0],[0]
We clearly observe this phenomenon in our evaluations.,1. Introduction,[0],[0]
"See Section 5 for details.
",1. Introduction,[0],[0]
"In this paper we tackle the ultra large-scale feature selection problem, i.e., feature selection with billions or more dimensions.",1. Introduction,[0],[0]
"We propose a novel feature selection algorithm called MISSION, a Memory-efficient, Iterative Sketching algorithm for Sparse feature selectION.",1. Introduction,[0],[0]
"MISSION, that takes on all the concerns outlined above.",1. Introduction,[0],[0]
"MISSION matches the accuracy performance of existing large-scale machine learning frameworks like Vowpal Wabbit (VW) (Agarwal et al., 2014) on real-world datasets.",1. Introduction,[0],[0]
"However, in contrast to VW, MISSION can perform feature selection exceptionally well.",1. Introduction,[0],[0]
"Furthermore, MISSION significantly surpasses the performance of classical algorithms such as Iterative Hard Thresholding (IHT), which is currently the popular feature selection alternative concerning the problem sizes we consider.
",1. Introduction,[0],[0]
Contributions:,1. Introduction,[0],[0]
"In this work, we show that the two-decade old Count-Sketch data structure (Charikar et al., 2002) from the streaming algorithms literature is ideally suited for ultra large-scale feature selection.",1. Introduction,[0],[0]
The Count-Sketch data structure enables us to retain the convenience of feature hashing along with the identity of important features.,1. Introduction,[0],[0]
"Moreover, Count-Sketch can accumulate gradients updates over several iterations because of linear aggregation.",1. Introduction,[0],[0]
This aggregation eliminates the problem of myopia associated with existing greedy thresholding approaches.,1. Introduction,[0],[0]
"The aggregation phenomenon also extends to recent parallel works which employ count sketches in streaming domain (Tai et al., 2018).
",1. Introduction,[0],[0]
"In particular, we force the parameters (or feature vector) to reside in a memory-efficient Count-Sketch data structure.",1. Introduction,[0],[0]
SGD gradient updates are easily applied to the Count-Sketch.,1. Introduction,[0],[0]
"Instead of moving in the gradient direction and then greedily projecting into a subspace defined by the regularizer (e.g., in the case of LASSO-based methods), MISSION adds the gradient directly into the Count-Sketch data structure, where it aggregates with all the past updates.",1. Introduction,[0],[0]
See Fig. 1 for the schematic.,1. Introduction,[0],[0]
"At any point of time in the iteration, this data structure stores a compressed, randomized, and noisy sketch of the sum of all the gradient updates, while preserving the information of the heavy-hitters—the coordinates that accumulate the highest amount of energy.",1. Introduction,[0],[0]
"In order to find an estimate of the feature vector, MISSION queries the CountSketch.",1. Introduction,[0],[0]
"The Count-Sketch is used in conjunction with a top-k heap, which explicitly stores the features with the heaviest weights.",1. Introduction,[0],[0]
"Only the features in the top-k heap are considered active, and the rest are set to zero.",1. Introduction,[0],[0]
"However, a representation for every weight is stored, in compressed form, inside the Count-Sketch.
",1. Introduction,[0],[0]
"We demonstrate that MISSION surpasses the sparse recovery performance of classical algorithms such as Iterative Hard Thresholding (IHT), which is the only other method we could run at our scale.",1. Introduction,[0],[0]
"In addition, experiments suggest that the memory requirements of MISSION scale well with the dimensionality p of the problem.",1. Introduction,[0],[0]
"MISSION matches the
accuracy of existing large-scale machine learning frameworks like Vowpal Wabbit (VW) on real-world, large-scale datasets.",1. Introduction,[0],[0]
"Moreover, MISSION achieves comparable or even better accuracy while using significantly fewer features.",1. Introduction,[0],[0]
"In the streaming setting, we are given a high-dimensional vector β ∈",2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
Rp that is too costly to store in memory.,2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
We see only a very long sequence of updates over time.,2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
"The only information available at time t is of the form (i,∆), which means that coordinate i is incremented (or decremented) by the amount ∆. We are given a limited amount of storage, on the order of O(log p), which means that we can never store the entire sequence of updates.",2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
"Sketching algorithms aim to estimate the value of current item i, after any number of updates using only O(log p) memory.",2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
"Accurate estimation of heavy coordinates is desirable.
",2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
Count-Sketch is a popular algorithm for estimation in the streaming setting.,2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
"Count-Sketch keeps a matrix of counters (or bins) S of size d×w ∼ O(log p), where d andw are chosen based on the accuracy guarantees.",2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
"The algorithm uses d random hash functions hj for j ∈ {1, 2, ..., d} to map the vector’s components to bins w, hj : {1, 2, ..., p} → {1, 2, ..., w} Every component i of the vector is hashed to d different bins.",2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
"In particular, for any row j of sketch S, component i is hashed into bin S(j, hj(i)).",2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
"In addition to hj , Count-Sketch uses d random sign functions to map the components of the vectors randomly to {+1, −1}, i.e., si : {1, 2, ..., D} → {+1,−1}.",2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
"An illustration of this sketch data structure with three hash functions in shown inside Fig. 1.
",2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
The Count-Sketch supports two operations: UPDATE(item,2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
"i, increment ∆) and QUERY(item i).",2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
The UPDATE operation updates the sketch with any observed increment.,2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
"More formally, for an increment ∆ to an item i, the sketch is updated by adding sj(i)∆ to the cell S(j, hj(i))",2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
"∀j ∈ {1, 2, ..., d}.",2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
"The QUERY operation returns an estimate for component i, the median of all the d different associated counters.
",2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
"It has been shown that, for any sequence of streaming updates (addition or subtraction) to the vector β, Count-Sketch provides an unbiased estimate of any component i, β̂i such that the following holds with high probability,
βi",2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
− ||β||2 ≤ β̂i ≤,2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
βi + ||β||2.,2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
"(1)
It can be shown that the Eq. (1) is sufficient to achieve near-optimal guarantees for sparse recovery with the given space budget.",2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
"Furthermore, these guarantees also meet the best compressed sensing lower bounds in terms of the number of counters (or measurements) needed for sparse recovery (Indyk, 2013).",2. Review: Streaming Setting and the Count-Sketch Algorithm,[0],[0]
"Consider the feature selection problem in the ultra highdimensional setting: We are given the dataset (Xi, yi) for i ∈",3. Problem Formulation,[0],[0]
"[n] = {1, 2, . . .",3. Problem Formulation,[0],[0]
",",3. Problem Formulation,[0],[0]
"n},",3. Problem Formulation,[0],[0]
where Xi ∈,3. Problem Formulation,[0],[0]
Rp and yi ∈ R denote the ith measured and response variables.,3. Problem Formulation,[0],[0]
We are interested in finding the k-sparse (k non-zero entries) feature vector (or regressor),3. Problem Formulation,[0],[0]
β ∈,3. Problem Formulation,[0],[0]
"Rp from the optimization problem
min ‖β‖0=k
‖y −Xβ‖2, (2)
",3. Problem Formulation,[0],[0]
"where X = {X1,X2, . . .",3. Problem Formulation,[0],[0]
",Xn} and y =",3. Problem Formulation,[0],[0]
"[y1, y1, . . .",3. Problem Formulation,[0],[0]
", yn] denote the data matrix and response vector and the `0-norm ‖β‖0 counts the number of non-zero entries in β.
",3. Problem Formulation,[0],[0]
We are interested in solving the feature selection problem for ultra high-dimensional datasets where the number of features p is so large that a dense vector (or matrix) of size p cannot be stored explicitly in memory.,3. Problem Formulation,[0],[0]
"Among the menagerie of feature selection algorithms, the class of hard thresholding algorithms have the smallest memory footprint: Hard thresholding algorithms retain only the top-k values and indices of the entire feature vector using O(klog(p))",3.1. Hard Thresholding Algorithms,[0],[0]
"memory (Jain et al., 2014; Blumensath & Davies, 2009).",3.1. Hard Thresholding Algorithms,[0],[0]
"The iterative hard thresholding (IHT) algorithm generates the following iterates for the ith variable in an stochastic gradient descent (SGD) framework
βt+1",3.1. Hard Thresholding Algorithms,[0],[0]
← Hk(βt − 2λ,3.1. Hard Thresholding Algorithms,[0],[0]
"( yi −Xiβt )T Xi) (3)
The sparsity of the feature vector βt, enforced by the hard thresholding operator Hk, alleviates the need to store a vector of size O(p) in the memory in order to keep track of the changes of the features over the iterates.
",3.1. Hard Thresholding Algorithms,[0],[0]
"Unfortunately, because it only retains the top-k elements of β, the hard thresholding procedure greedily discards the information of the non top-k coordinates from the previous iteration.",3.1. Hard Thresholding Algorithms,[0],[0]
"In particular, it clips off coordinates that might add to the support set in later iterations.",3.1. Hard Thresholding Algorithms,[0],[0]
"This drastically affects the performance of hard thresholding algorithms in realworld scenarios where the design matrix X is not random, normalized, or well-conditioned.",3.1. Hard Thresholding Algorithms,[0],[0]
"In this regime, the gradient terms corresponding to the true support typically arrive in lagging order and are prematurely clipped in early iterations by Hk.",3.1. Hard Thresholding Algorithms,[0],[0]
"The effect of these lagging gradients is present even in the SGD framework, because the gradients are quite noisy, and only a small fraction of the energy of the true gradient is expressed in each iteration.",3.1. Hard Thresholding Algorithms,[0],[0]
"It is not difficult to see that these small energy, high noise signals can easily cause the greedy hard thresholding operator to make sub-optimal or incorrect decisions.",3.1. Hard Thresholding Algorithms,[0],[0]
"Ideally, we want to accumulate the gradients to get enough confidence in signal and to average out any noise.
",3.1. Hard Thresholding Algorithms,[0],[0]
"Algorithm 1 MISSION Initialize: β0 = 0, S (Count-Sketch), λ (Learning Rate) while not stopping criteria do
Find the gradient update gi = λ",3.1. Hard Thresholding Algorithms,[0],[0]
( 2 (yi −Xiβt) T Xi ),3.1. Hard Thresholding Algorithms,[0],[0]
Add the gradient update to the sketch gi → S Get the top-k heavy-hitters from the sketch βt+1,3.1. Hard Thresholding Algorithms,[0],[0]
"← S end while Return: The top-k heavy-hitters from the Count-Sketch
This aforementioned problem is in fact symptomatic of all other thresholding variants including the Iterative algorithm with inversion (ITI) (Maleki, 2009) and the Partial hard thresholding (PHT) algorithm (Jain et al., 2017).",3.1. Hard Thresholding Algorithms,[0],[0]
We now describe the MISSION algorithm.,4. The MISSION Algorithm,[0],[0]
"First, we initialize the Count-Sketch S and the feature vector βt=0 with zeros entries.",4. The MISSION Algorithm,[0],[0]
The Count-Sketch hashes a p-dimensional vector into O(log2p) buckets (Recall Fig. 1).,4. The MISSION Algorithm,[0],[0]
"We discuss this particular choice for the size of the Count-Sketch and the memory-accuracy trade offs of MISSION in Sections 5.3 and 6.1.
",4. The MISSION Algorithm,[0],[0]
"At iteration t, MISSION selects a random row Xi from the data matrix X and computes the stochastic gradient update term using the learning rate λ via gi = 2λ",4. The MISSION Algorithm,[0],[0]
(yi −Xiβt) T Xi i.e. the usual gradient update that minimizes the unconstrained quadratic loss ‖y−Xβ‖22.,4. The MISSION Algorithm,[0],[0]
The data vector Xi and the corresponding stochastic gradient term are sparse.,4. The MISSION Algorithm,[0],[0]
"We then add the non-zero entries of the stochastic gradient term {gij : ∀j gij > 0} to the Count-Sketch S. Next, MISSION queries the top-k values of the sketch to form βt+1.",4. The MISSION Algorithm,[0],[0]
We repeat the same procedure until convergence.,4. The MISSION Algorithm,[0],[0]
MISSION returns the top-k values of the Count-Sketch as the final output of the algorithm.,4. The MISSION Algorithm,[0],[0]
"The MISSION algorithm is detailed in Alg. 1. MISSION easily extends to other loss functions such as the hinge loss and logistic loss.
",4. The MISSION Algorithm,[0],[0]
MISSION is Different from Greedy Thresholding:,4. The MISSION Algorithm,[0],[0]
Denote the gradient vector update at any iteration t as ut.,4. The MISSION Algorithm,[0],[0]
"It is not difficult to see that starting with an all-zero vector β0, at any point of time t, the Count-Sketch state is equivalent to the sketch of the vector ∑t i=1",4. The MISSION Algorithm,[0],[0]
ut.,4. The MISSION Algorithm,[0],[0]
"In other words, the sketch aggregates the compressed aggregated vector.",4. The MISSION Algorithm,[0],[0]
"Thus, even if an individual SGD update is noisy and contains small signal energy, thresholding the Count-Sketch is based on the average update over time.",4. The MISSION Algorithm,[0],[0]
This averaging produces a robust signal that cancels out the noise.,4. The MISSION Algorithm,[0],[0]
"We can therefore expect MISSION to be superior over thresholding.
",4. The MISSION Algorithm,[0],[0]
"In the supplementary materials, we present initial theoretical results on the convergence of MISSION.",4. The MISSION Algorithm,[0],[0]
"Our results show
that, under certain assumptions, the full-gradient-descent version of MISSION converges geometrically to the true parameter β ∈",4. The MISSION Algorithm,[0],[0]
Rp up to some additive constants.,4. The MISSION Algorithm,[0],[0]
"The exploration of these assumptions and the extension to the SGD version of MISSION are exciting avenues for future work.
",4. The MISSION Algorithm,[0],[0]
"Feature Selection with the Ease of Feature Hashing: As argued earlier, the features are usually represented with strings, and we do not have the capability to map each string to a unique index in a vector without spendingO(p) memory.",4. The MISSION Algorithm,[0],[0]
"Feature hashing is convenient, because we can directly access every feature using hashes.",4. The MISSION Algorithm,[0],[0]
We can use any lossy hash function for strings.,4. The MISSION Algorithm,[0],[0]
MISSION only needs a few independent hash functions (3 in our Count-Sketch implementation) to access any component.,4. The MISSION Algorithm,[0],[0]
"The top-k estimation is done efficiently using a heap data structure of size k. Overall, we only access the data using efficient hash functions, which can be easily implemented in large-scale systems.",4. The MISSION Algorithm,[0],[0]
We designed a set of simulations to evaluate MISSION in a controlled setting.,5. Simulations,[0],[0]
"In contrast to the ultra large-scale, real-world experiments of Section 6, in the section the data matrices are drawn from a random Gaussian distribution and the ground truth features are known.",5. Simulations,[0],[0]
We first demonstrate the advantage of MISSION over greedy thresholding in feature selection.,5.1. Phase Transition,[0],[0]
"For this experiment, we modify MISSION slightly to find the root of the algorithmic advantage of MISSION: we replace the Count-Sketch with an “identity” sketch, or a sketch with a single hash function, h(i) = i.",5.1. Phase Transition,[0],[0]
"In doing so, we eliminate the complexity that Count-Sketch adds to the algorithm, so that the main difference between MISSION and IHT is that MISSION accumulates the gradients.",5.1. Phase Transition,[0],[0]
"To improve stability, we scale the non top-k elements of S by a factor γ ∈ (0, 1) that begins very near 1 and is gradually decreased until the algorithm converges.",5.1. Phase Transition,[0],[0]
"It is also possible to do this scaling in the CountSketch version of MISSION efficiently by exploiting the linearity of the sketch.
",5.1. Phase Transition,[0],[0]
Fig. 2 illustrates the empirical phase transition curves for sparse recovery using MISSION and the hard thresholding algorithms.,5.1. Phase Transition,[0],[0]
The phase transition curves show the points where the algorithm successfully recovers the features in > 50% of the random trails.,5.1. Phase Transition,[0],[0]
"MISSION shows a better phase transition curve compared to IHT by a considerable gap.
",5.1. Phase Transition,[0],[0]
Table 1.,5.1. Phase Transition,[0],[0]
Comparison of MISSION against hard thresholding algorithms in feature selection under adversarial effects.,5.1. Phase Transition,[0],[0]
We first report the percentage of instances in which the algorithms accurately find the solution (ACC) with no attenuation (α = 1) over 100 random trials.,5.1. Phase Transition,[0],[0]
"We then report the mean of the maximum level of attenuation α applied to the columns of design X before the algorithms fail to recover the support of β (over the trials that all algorithms can find the solution with α = 1).
",5.1. Phase Transition,[0],[0]
"(n, k) MISSION IHT ITI PHT",5.1. Phase Transition,[0],[0]
ACCα=1 α,5.1. Phase Transition,[0],[0]
ACCα=1 α,5.1. Phase Transition,[0],[0]
ACCα=1 α,5.1. Phase Transition,[0],[0]
"ACCα=1 α (100, 2) 100% 2.68 ± 0.37 100% 1.49 ± 0.33 91% 1.33 ± 0.23 64% 2.42 ± 0.87 (100, 3) 100% 2.52 ± 0.36 92% 1.36 ± 0.46 70% 1.15 ± 0.20 42% 2.05 ± 0.93 (100, 4) 100% 2.53 ± 0.23 72% 1.92 ± 0.91 37% 1.03 ± 0.09 39% 2.13 ± 1.07 (200, 5) 100% 4.07 ± 0.36 99",5.1. Phase Transition,[0],[0]
"% 2.34 ± 1.12 37% 1.15 ± 0.22 83% 2.75 ± 1.30 (200, 6) 100% 4.17 ± 0.24 97% 2.64 ± 1.14 23% 1.11 ± 0.12 73% 2.26 ± 1.33 (200, 7) 100% 4.07 ± 0.11 83% 1.64 ± 1.01 14% 1.11 ± 0.12 75% 3.39 ± 1.36
0.0 0.2 0.4 0.6 0.8 1.0
n/p
0.0
0.2
0.4
0.6
0.8
1.0
s/ n
MISSION IHT ITI",5.1. Phase Transition,[0],[0]
"PHT
Figure 2.",5.1. Phase Transition,[0],[0]
Empirical phase transition in recovering a binary feature vector β in p = 1000-dimensional space with a Gaussian data matrix X.,5.1. Phase Transition,[0],[0]
We illustrate the empirical 50% probability of success curves averaged over T = 20 trials.,5.1. Phase Transition,[0],[0]
MISSION outperforms the thresholding algorithms by a large margin.,5.1. Phase Transition,[0],[0]
"A major problem with the IHT algorithm, especially in largescale SGD settings, is with thresholding the coordinates with small gradients in the earlier iterations.",5.2. Lagging Gradient: Superiority of Count-Sketches over Greedy Thresholding,[0],[0]
"IHT misses these coordinates, since they become prominent only after the gradients accumulate with the progression of the algorithm.",5.2. Lagging Gradient: Superiority of Count-Sketches over Greedy Thresholding,[0],[0]
"The problem is amplified with noisy gradient updates such as SGD, which is unavoidable for large datasets.
",5.2. Lagging Gradient: Superiority of Count-Sketches over Greedy Thresholding,[0],[0]
This phenomenon occurs frequently in sparse recovery problems.,5.2. Lagging Gradient: Superiority of Count-Sketches over Greedy Thresholding,[0],[0]
"For example, when the coordinates that correspond to the columns of the data matrix with smaller energy lag in the iterations of gradient descent algorithm, IHT thresholds these lagging-gradient coordinates in first few iterations, and they never show up again in the support.",5.2. Lagging Gradient: Superiority of Count-Sketches over Greedy Thresholding,[0],[0]
"In contrast, MISSION retains a footprint of the gradients of all the previous iterations in the Count-Sketch.",5.2. Lagging Gradient: Superiority of Count-Sketches over Greedy Thresholding,[0],[0]
"When the total sum of the gradient of a coordinate becomes prominent, the coordinate joins the support after querying the top-k heavy hitters from the Count-Sketch.",5.2. Lagging Gradient: Superiority of Count-Sketches over Greedy Thresholding,[0],[0]
We illustrate this phenomena in sparse recovery using synthetic experiments.,5.2. Lagging Gradient: Superiority of Count-Sketches over Greedy Thresholding,[0],[0]
"We recover sparse vector β from its random linear measurements y = Xβ, where the energy of X is imbalanced across its columns.",5.2. Lagging Gradient: Superiority of Count-Sketches over Greedy Thresholding,[0],[0]
"In this case, the gradients corresponding to the
columns (coordinates) with smaller energy typically lag and are thresholded by IHT.
",5.2. Lagging Gradient: Superiority of Count-Sketches over Greedy Thresholding,[0],[0]
"To this end, we first construct a random Gaussian data matrix X ∈ R900×1000, pick a sparse vector β that is supported on an index set I , and then attenuate the energy of the columns of X supported by the indices in I by an attenuation factor of α = {1, 1.25, 1.5, 1.75, 2, . . .",5.2. Lagging Gradient: Superiority of Count-Sketches over Greedy Thresholding,[0],[0]
", 5}.",5.2. Lagging Gradient: Superiority of Count-Sketches over Greedy Thresholding,[0],[0]
Note that α = 1 implies that no attenuation is applied to the matrix.,5.2. Lagging Gradient: Superiority of Count-Sketches over Greedy Thresholding,[0],[0]
"In Table 1, we report the maximum attenuation level applied to a column of data matrix X before the algorithms fail to fully recover the support set I from y = βX.",5.2. Lagging Gradient: Superiority of Count-Sketches over Greedy Thresholding,[0],[0]
"We observe that MISSION is consistently and up to three times more robust against adversarial attenuation of the columns of the data matrix in various design settings.
",5.2. Lagging Gradient: Superiority of Count-Sketches over Greedy Thresholding,[0],[0]
The robustness of MISSION to the attenuation of the columns of X in sparse recovery task suggests that the Count-Sketch data structure enables gradient-based optimization methods such as IHT to store a footprint (or sketch) of all the gradients from the previous iterations and deliver them back when they become prominent.,5.2. Lagging Gradient: Superiority of Count-Sketches over Greedy Thresholding,[0],[0]
"in MISSION
In this section we demonstrate that the memory requirements of MISSION grows polylogarithmically in the dimension of the problem p.",5.3. Logarithmic Scaling of the Count-Sketch Memory,[0],[0]
We conduct a feature selection experiment with a data matrix X ∈ R100×p whose entries are drawn from i.i.d. random Gaussian distributions with zero mean and unit variance.,5.3. Logarithmic Scaling of the Count-Sketch Memory,[0],[0]
"We run MISSION and IHT to recover the feature vector β from the output vector y = Xβ, where the feature vector β is a k = 5-sparse vector with random support.",5.3. Logarithmic Scaling of the Count-Sketch Memory,[0],[0]
We repeat the same experiment 1000 times with different realizations for the sparse feature vector β and report the results in Fig. 3.,5.3. Logarithmic Scaling of the Count-Sketch Memory,[0],[0]
The left plot illustrates the feature selection accuracy of the algorithms as the dimension of the problem p grows.,5.3. Logarithmic Scaling of the Count-Sketch Memory,[0],[0]
"The right plot illustrates the minimum memory requirements of the algorithms to recover the features with 100% accuracy.
",5.3. Logarithmic Scaling of the Count-Sketch Memory,[0],[0]
The size of the Count-Sketch in MISSION scales only polylogarithmically with the dimension of the problem.,5.3. Logarithmic Scaling of the Count-Sketch Memory,[0],[0]
This is surprising since the aggregate gradient in a classical SGD framework becomes typically dense in early iterations and thus requires a memory of order O(p).,5.3. Logarithmic Scaling of the Count-Sketch Memory,[0],[0]
"MISSION, however, stores only the essential information of the features in the sketch using a poly-logarithmic sketch size.",5.3. Logarithmic Scaling of the Count-Sketch Memory,[0],[0]
Note that IHT sacrifices accuracy to achieve a small memory footprint.,5.3. Logarithmic Scaling of the Count-Sketch Memory,[0],[0]
At every iteration IHT eliminates all the information except for the top-k features.,5.3. Logarithmic Scaling of the Count-Sketch Memory,[0],[0]
"We observe that, using only a logarithmic factor more memory, MISSION has a significant advantage over IHT in recovering the ground truth features.",5.3. Logarithmic Scaling of the Count-Sketch Memory,[0],[0]
"All experiments were performed on a single machine, 2x Intel Xeon E5-2660 v4 processors (28 cores / 56 threads) with 512 GB of memory.",6. Experiments,[0],[0]
The code1 for training and running our randomized-hashing approach is available online.,6. Experiments,[0],[0]
"We designed the experiments to answer these questions:
1.",6. Experiments,[0],[0]
Does MISSION outperform IHT in terms of classification accuracy?,6. Experiments,[0],[0]
"In particular, how much does myopic thresholding affect IHT in practice?
2.",6. Experiments,[0],[0]
"How well does MISSION match the speed and accuracy of feature hashing (FH)?
3.",6. Experiments,[0],[0]
"How does changing the number of top-k features affect the accuracy and behaviour of the different methods?
4.",6. Experiments,[0],[0]
"What is the effect of changing the memory size of the Count-Sketch data structure on the classification accuracy of MISSION in read-world datasets?
5.",6. Experiments,[0],[0]
"Does MISSION scale well in comparison to the different methods on the ultra large-scale datasets (> 350 GB in size)?
1https://github.com/rdspring1/MISSION",6. Experiments,[0],[0]
"Datasets: We used four datasets in the experiments: 1) KDD2012, 2) RCV1, 3) Webspam–Trigram, 4) DNA2.",6.1. Large-scale Feature Extraction,[0],[0]
"The statistics of these datasets are summarized in Table 2.
",6.1. Large-scale Feature Extraction,[0],[0]
The DNA metagenomics dataset is a multi-class classification task where the model must classify 15 different bacteria species using DNA K-mers.,6.1. Large-scale Feature Extraction,[0],[0]
We sub-sampled the first 15 species from the original dataset containing 193 species.,6.1. Large-scale Feature Extraction,[0],[0]
We use all of the species in the DNA Metagenomics dataset for the large-scale experiments (See Section 6.2).,6.1. Large-scale Feature Extraction,[0],[0]
"Following standard procedures, each bacterial species is associated with a reference genome.",6.1. Large-scale Feature Extraction,[0],[0]
Fragments are sampled from the reference genome until each nucleotide is covered c times on average.,6.1. Large-scale Feature Extraction,[0],[0]
The fragments are then divided into K-mer sub-strings.,6.1. Large-scale Feature Extraction,[0],[0]
We used fragments of length 200 and K-mers of length 12.,6.1. Large-scale Feature Extraction,[0],[0]
"Each model was trained and tested with mean coverage c = {0.1, 1} respectively.",6.1. Large-scale Feature Extraction,[0],[0]
"For more details, see (Vervier et al., 2016).",6.1. Large-scale Feature Extraction,[0],[0]
"The feature extraction task is to find the DNA K-mers that best represent each bacteria class.
",6.1. Large-scale Feature Extraction,[0],[0]
"We implemented the following approaches to compare and contrast against our approach: For all methods, we used the logistic loss for binary classification and the cross-entropy loss for multi-class classification.
MISSION:",6.1. Large-scale Feature Extraction,[0],[0]
As described in Section 4.,6.1. Large-scale Feature Extraction,[0],[0]
"Iterative Hard Thresholding (IHT): An algorithm where, after each gradient update, a hard threshold is applied to the features.",6.1. Large-scale Feature Extraction,[0],[0]
"Only the top-k features are kept active, while the rest are set to zero.",6.1. Large-scale Feature Extraction,[0],[0]
"Since the features are strings or integers, we used a sorted heap to store and manipulate the top-k elements.",6.1. Large-scale Feature Extraction,[0],[0]
This was the only algorithm we could successfully run over the large datasets on our single machine.,6.1. Large-scale Feature Extraction,[0],[0]
Batch IHT: A modification to IHT that uses mini-batches such that the gradient sparsity is the same as the number of elements in the count-sketch.,6.1. Large-scale Feature Extraction,[0],[0]
We accumulate features and then sort and prune to find the top-k features.,6.1. Large-scale Feature Extraction,[0],[0]
"This accumulate, sort, prune process is repeated several times during training.",6.1. Large-scale Feature Extraction,[0],[0]
Note:,6.1. Large-scale Feature Extraction,[0],[0]
"This setup requires significantly more memory than MISSION, because it explicitly stores the feature strings.",6.1. Large-scale Feature Extraction,[0],[0]
The memory cost of maintaining a set of string features can be orders of magnitude more than the flat array used by MISSION.,6.1. Large-scale Feature Extraction,[0],[0]
"See Bloom Filters (Broder & Mitzenmacher, 2004) and related literature.",6.1. Large-scale Feature Extraction,[0],[0]
"This setup is not scalable to large-scale datasets.
",6.1. Large-scale Feature Extraction,[0],[0]
"2http://projects.cbio.mines-paristech.fr/ largescalemetagenomics/
Feature Hashing (FH): A standard machine learning algorithm for dimensionality reduction that reduces the memory cost associated with large datasets.",6.1. Large-scale Feature Extraction,[0],[0]
FH is not a feature selection algorithm and cannot identify important features.,6.1. Large-scale Feature Extraction,[0],[0]
"(Agarwal et al., 2014)
",6.1. Large-scale Feature Extraction,[0],[0]
Experimental Settings: The MISSION and IHT algorithms searched for the same number of top-k features.,6.1. Large-scale Feature Extraction,[0],[0]
"To ensure fair comparisons, the size of the Count-Sketch and the feature vector allocated for the FH model were equal.",6.1. Large-scale Feature Extraction,[0],[0]
The size of the MISSION and FH models were set to the nearest power of 2 greater than the number of features in the dataset.,6.1. Large-scale Feature Extraction,[0],[0]
"For all the experiments, the Count-Sketch data structure used 3 hash functions, and the model weights were divided equally among the hash arrays.",6.1. Large-scale Feature Extraction,[0],[0]
"For example, with the (Tiny) DNA metagenomics dataset, we allocated 24 bits or 16,777,216 weights for the FH model.",6.1. Large-scale Feature Extraction,[0],[0]
"Given 3 hash functions and 15 classes, roughly 372,827 elements were allocated for each class in the Count-Sketch.
MISSION, IHT, FH Comparison: Fig. 4 shows that MISSION surpasses IHT in classification accuracy in all four datasets, regardless of the number of features.",6.1. Large-scale Feature Extraction,[0],[0]
"In addition, MISSION closely matches FH, which is significant because FH is allowed to model a much larger set of features than MISSION or IHT.",6.1. Large-scale Feature Extraction,[0],[0]
"MISSION is 2–4× slower than FH, which is expected given that MISSION has the extra overhead of using a heap to track the top-k features.
MISSION’s accuracy rapidly rises with respect to the number of top-k features, while IHT’s accuracy plateaus and then grows slowly to match MISSION.",6.1. Large-scale Feature Extraction,[0],[0]
This observation corroborates our insight that the greedy nature of IHT hurts performance.,6.1. Large-scale Feature Extraction,[0],[0]
"When the number of top-k elements is small, the capacity of IHT is limited, so it picks the first set of features that provides good performance, ignoring the rest.",6.1. Large-scale Feature Extraction,[0],[0]
"On the other hand, MISSION decouples the memory from the top-k ranking, which is based on the aggregated gradients in the compressed sketch.",6.1. Large-scale Feature Extraction,[0],[0]
"By the linear property of the count-sketch, this ensures that the heavier entries occur in the top-k features with high probability.
",6.1. Large-scale Feature Extraction,[0],[0]
"Count-Sketch Memory Trade-Off: Fig. 5 shows how MISSION’s accuracy degrades gracefully, as the size of the Count-Sketch decreases.",6.1. Large-scale Feature Extraction,[0],[0]
"In this experiment, MISSION only used the top 500K features for classifying the Tiny DNA metagenomics dataset.",6.1. Large-scale Feature Extraction,[0],[0]
"When the top-k to Count-Sketch ratio is 1, then 500K weights were allocated for each class and hash array in the Count-Sketch data structure.",6.1. Large-scale Feature Extraction,[0],[0]
"The Batch IHT baseline was given 8,388,608 memory elements per class, enabling it to accumulate a significant number of features before thresholding to find the top-k features.",6.1. Large-scale Feature Extraction,[0],[0]
"This experiment shows that MISSION immediately outperforms IHT and Batch IHT, once the top-k to Count-Sketch ratio is 1:1.",6.1. Large-scale Feature Extraction,[0],[0]
"Thus, MISSION provides a unique memory-accuracy knob at any given value of top-k.",6.1. Large-scale Feature Extraction,[0],[0]
"Here we demonstrate that MISSION can extract features from three large-scale datasets: Criteo 1TB, Splice-Site, and DNA Metagenomics.
",6.2. Ultra Large-Scale Feature Selection,[0],[0]
Criteo 1TB: The Criteo 1TB3 dataset represents 24 days of click-through logs—23 days (training) + 1 day (testing).,6.2. Ultra Large-Scale Feature Selection,[0],[0]
The task for this dataset is click-through rate (CTR) prediction— How likely is a user to click an ad?,6.2. Ultra Large-Scale Feature Selection,[0],[0]
The dataset contains over 4 billion (training) and 175 million (testing) examples (2.5 TB of disk space).,6.2. Ultra Large-Scale Feature Selection,[0],[0]
The performance metric is Area Under the ROC Curve (AUC).,6.2. Ultra Large-Scale Feature Selection,[0],[0]
The VW baseline4 achieved 0.7570 AUC score.,6.2. Ultra Large-Scale Feature Selection,[0],[0]
"MISSION and IHT scored close to the VW baseline with 0.751 AUC using only the top 250K features.
",6.2. Ultra Large-Scale Feature Selection,[0],[0]
Splice-Site: The task for this dataset is to distinguish between true and fake splice sites using the local context around the splice site in-question.,6.2. Ultra Large-Scale Feature Selection,[0],[0]
"The dataset is highly skewed (few positive, many negative values), and so the performance metric is average precision (AP).",6.2. Ultra Large-Scale Feature Selection,[0],[0]
Average precision is the precision score averaged over all recall scores ranging from 0 to 1.,6.2. Ultra Large-Scale Feature Selection,[0],[0]
The dataset contains over 50 million (training) and 4.6 million (testing) examples (3.2 TB of disk space).,6.2. Ultra Large-Scale Feature Selection,[0],[0]
All the methods were trained for a single epoch with a learning rate of 0.5.,6.2. Ultra Large-Scale Feature Selection,[0],[0]
"MISSION, Batch IHT, and SGD IHT tracked the top 16,384 features.",6.2. Ultra Large-Scale Feature Selection,[0],[0]
"FH, MISSION, and Batch IHT used 786,432 extra memory elements.",6.2. Ultra Large-Scale Feature Selection,[0],[0]
MISSION significantly outperforms Batch IHT and SGD IHT by 2.3%.,6.2. Ultra Large-Scale Feature Selection,[0],[0]
"Also, unlike in Fig. 5, the extra memory did not help Batch IHT, since it performed the same as SGD IHT.",6.2. Ultra Large-Scale Feature Selection,[0],[0]
MISSION (17.5 hours) is 15% slower than FH (15 hours) in wall-clock running time.,6.2. Ultra Large-Scale Feature Selection,[0],[0]
DNA Metagenomics:,AP 0.522 0.510 0.498 0.498,[0],[0]
This experiment evaluates MISSION’s performance on a medium-sized metagenomics dataset.,AP 0.522 0.510 0.498 0.498,[0],[0]
"The parameters from the Tiny (15 species) dataset in Section 6.1 are shared with this experiment, except the
3https://www.kaggle.com/c/criteo-display-ad-challenge 4https://github.com/rambler-digital-solutions/
criteo-1tb-benchmark
DNA - Tiny (15 Species) - Top-K: 500K
number of species is increased to 193.",AP 0.522 0.510 0.498 0.498,[0],[0]
The size of a sample batch with mean coverage c = 1 increased from 7 GB (Tiny) to 68 GB (Medium).,AP 0.522 0.510 0.498 0.498,[0],[0]
Each round (mean coverage c = 0.25) contains 3.45 million examples and about 16.93 million unique non-zero features (p).,AP 0.522 0.510 0.498 0.498,[0],[0]
MISSION and IHT tracked the top 2.5 million features per class.,AP 0.522 0.510 0.498 0.498,[0],[0]
"The FH baseline used 231 weights, about 11.1 million weights per class, and we allocated the same amount of space for the Count-Sketch.",AP 0.522 0.510 0.498 0.498,[0],[0]
"Each model was trained on a dataset with coverage c = 5.
",AP 0.522 0.510 0.498 0.498,[0],[0]
"Fig. 6 shows the evolution of classification accuracy over time for MISSION, IHT, and the FH baseline.",AP 0.522 0.510 0.498 0.498,[0],[0]
"After 5 epochs, MISSION closely matches the FH baseline.",AP 0.522 0.510 0.498 0.498,[0],[0]
"Note: MISSION converges faster than IHT such that MISSION is 1–4 rounds ahead of IHT, with the gap gradually increasing over time.",AP 0.522 0.510 0.498 0.498,[0],[0]
"On average, the running time of MISSION is 1–2× slower than IHT.",AP 0.522 0.510 0.498 0.498,[0],[0]
"However, this experiment demonstrates that since MISSION converges faster, it actually needs less time to reach a certain accuracy level.",AP 0.522 0.510 0.498 0.498,[0],[0]
"Therefore, MISSION is effectively faster and more accurate than IHT.",AP 0.522 0.510 0.498 0.498,[0],[0]
"Scalability and Parallelism: IHT finds the top-k features after each gradient update, which requires sorting the features based on their weights before thresholding.",7. Implementation Details and Discussion,[0],[0]
"The speed of the sorting process is improved by using a heap data
DNA - Medium (193 Species) - Top-K: 2.5M
structure, but it is still costly per update.",7. Implementation Details and Discussion,[0],[0]
"MISSION also uses a heap to store its top-k elements, but it achieves the same accuracy as IHT with far fewer top-k elements because of the Count-Sketch.",7. Implementation Details and Discussion,[0],[0]
"(Recall Section 4)
",7. Implementation Details and Discussion,[0],[0]
Another suggested improvement for the top-k heap is to use lazy updates.,7. Implementation Details and Discussion,[0],[0]
"Updating the weight of a feature does not change its position in the heap very often, but still requires an O(log n) operation.",7. Implementation Details and Discussion,[0],[0]
"With lazy updates, the heap is updated only if it the change is significant.",7. Implementation Details and Discussion,[0],[0]
|xt,7. Implementation Details and Discussion,[0],[0]
"− x0| ≥ , i.e. the new weight at time t exceeds the original value by some threshold.",7. Implementation Details and Discussion,[0],[0]
This tweak significantly reduces the number of heap updates at the cost of slightly distorting the heap.,7. Implementation Details and Discussion,[0],[0]
"In this paper, we presented MISSION, a new framework for ultra large-scale feature selection which maintains an efficient, approximate representation for the features using a Count-Sketch data structure.",8. Conclusion and Future Work,[0],[0]
"MISSION retains the simplicity of feature hashing without sacrificing the interpretability of the features.
",8. Conclusion and Future Work,[0],[0]
"Going forward, we are interested in leveraging our MISSION framework to explore pairwise or higher-order interaction features.",8. Conclusion and Future Work,[0],[0]
"Interaction features are important for scientific discovery, e.g., in genomics (Basu et al., 2018), however, the exponential dimensionality growth of interactions has hindered further progress.",8. Conclusion and Future Work,[0],[0]
We believe MISSION will enable more scientific discoveries from big data in future.,8. Conclusion and Future Work,[0],[0]
"AAA, DL, GD, and RB were supported by the DOD Vannevar Bush Faculty Fellowship grant N00014-18-1-2047, NSF grant CCF-1527501, ARO grant W911NF-15-1-0316, AFOSR grant FA9550-14-1-0088, ONR grant N00014-17-12551, DARPA REVEAL grant HR0011-16-C-0028, and an ONR BRC grant for Randomized Numerical Linear Algebra.",Acknowledgements,[0],[0]
"RS and AS were supported by NSF-1652131, AFOSR-YIP FA9550-18-1-0152, and ONR BRC grant for Randomized Numerical Linear Algebra.",Acknowledgements,[0],[0]
The authors would also like to thank NVIDIA and Amazon for gifting computing resources.,Acknowledgements,[0],[0]
Feature selection is an important challenge in machine learning.,abstractText,[0],[0]
It plays a crucial role in the explainability of machine-driven decisions that are rapidly permeating throughout modern society.,abstractText,[0],[0]
"Unfortunately, the explosion in the size and dimensionality of real-world datasets poses a severe challenge to standard feature selection algorithms.",abstractText,[0],[0]
"Today, it is not uncommon for datasets to have billions of dimensions.",abstractText,[0],[0]
"At such scale, even storing the feature vector is impossible, causing most existing feature selection methods to fail.",abstractText,[0],[0]
"Workarounds like feature hashing, a standard approach to large-scale machine learning, helps with the computational feasibility, but at the cost of losing the interpretability of features.",abstractText,[0],[0]
"In this paper, we present MISSION, a novel framework for ultra large-scale feature selection that performs stochastic gradient descent while maintaining an efficient representation of the features in memory using a Count-Sketch data structure.",abstractText,[0],[0]
MISSION retains the simplicity of feature hashing without sacrificing the interpretability of the features while using only O(log p) working memory.,abstractText,[0],[0]
"We demonstrate that MISSION accurately and efficiently performs feature selection on real-world, large-scale datasets with billions of dimensions.",abstractText,[0],[0]
MISSION: Ultra Large-Scale Feature Selection using Count-Sketches,title,[0],[0]
Many modern data sets consist of data that is gathered adaptively: the choice of whether to collect more data points of a given type depends on the data already collected.,1. Introduction,[1.0],['Many modern data sets consist of data that is gathered adaptively: the choice of whether to collect more data points of a given type depends on the data already collected.']
"For example, it is common in industry to conduct “A/B” tests to make decisions about many things, including ad targeting, user interface design, and algorithmic modifications, and this A/B testing is often conducted using “bandit learning algorithms”",1. Introduction,[0.9622448913967341],"['For example, it is common in industry to conduct “A/B” tests to make decisions about many things, including ad targeting, user interface design, and algorithmic modifications, and this A/B testing is often conducted using “bandit learning algorithms” (Bubeck et al., 2012), which adaptively select treatments to show to users in an effort to find the best treatment as quickly as possible.']"
"(Bubeck et al., 2012), which adaptively select treatments to show to users in an effort to find the best treatment as quickly as possible.",1. Introduction,[0],[0]
"Similarly, sequen-
1Department of Statistics, The Wharton School, University of Pennsylvania 2Department of Computer Science, University of Pennsylvania.",1. Introduction,[0],[0]
Correspondence to: Seth Neel,1. Introduction,[0],[0]
"<sethneel93@gmail.com>, Aaron Roth <aaroth@cis.upenn.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"1This extended abstract is missing many details, proofs, and results that can be found in the full version (Neel & Roth, 2018).
",1. Introduction,[0],[0]
"tial clinical trials may halt or re-allocate certain treatment groups due to preliminary results, and empirical scientists may initially try and test multiple hypotheses and multiple treatments, but then decide to gather more data in support of certain hypotheses and not others, based on the results of preliminary statistical tests.
",1. Introduction,[0],[0]
"Unfortunately, as demonstrated by (Nie et al., 2017), the data that results from adaptive data gathering procedures will often exhibit substantial bias.",1. Introduction,[0],[0]
"As a result, subsequent analyses that are conducted on the data gathered by adaptive procedures will be prone to error, unless the bias is explicitly taken into account.",1. Introduction,[0],[0]
This can be difficult.,1. Introduction,[0],[0]
"(Nie et al., 2017) give a selective inference approach: in simple stochastic bandit settings, if the data was gathered by a specific stochastic algorithm that they design, they give an MCMC based procedure to perform maximum likelihood estimation to recover de-biased estimates of the underlying distribution means.",1. Introduction,[0],[0]
"In this paper, we give a related, but orthogonal approach whose simplicity allows for a substantial generalization beyond the simple stochastic bandits setting.",1. Introduction,[0],[0]
"We show that in very general settings, if the data is gathered by a differentially private procedure, then we can place strong bounds on the bias of the data gathered, without needing any additional de-biasing procedure.",1. Introduction,[0],[0]
"Via elementary techniques, this connection implies the existence of simple stochastic bandit algorithms with nearly optimal worst-case regret bounds, with very strong bias guarantees.",1. Introduction,[1.0],"['Via elementary techniques, this connection implies the existence of simple stochastic bandit algorithms with nearly optimal worst-case regret bounds, with very strong bias guarantees.']"
"By leveraging existing connections between differential privacy and adaptive data analysis (Dwork et al., 2015c; Bassily et al., 2016; Rogers et al., 2016), we can extend the generality of our approach to bound not just bias, but to correct for effects of adaptivity on arbitrary statistics of the gathered data.",1. Introduction,[0],[0]
"Since the data being gathered will generally be useful for some as yet unspecified scientific analysis, rather than just for the narrow problem of mean estimation, our technique allows for substantially broader possibilities compared to past approaches.",1. Introduction,[0],[0]
"This paper has three main contributions:
1.",1.1. Our Results,[1.0000000506417905],['This paper has three main contributions: 1.']
"Using elementary techniques, we provide explicit bounds on the bias of empirical arm means maintained by bandit algorithms in the simple stochastic
setting that make their selection decisions as a differentially private function of their observations.",1.1. Our Results,[0],[0]
"Together with existing differentially private algorithms for stochastic bandit problems, this yields an algorithm that obtains an essentially optimal worst-case regret bound, and guarantees minimal bias (on the order of O(1/ √ K · T )) for the empirical mean maintained for every arm.",1.1. Our Results,[1.0],"['Together with existing differentially private algorithms for stochastic bandit problems, this yields an algorithm that obtains an essentially optimal worst-case regret bound, and guarantees minimal bias (on the order of O(1/ √ K · T )) for the empirical mean maintained for every arm.']"
"In the full version (Neel & Roth, 2018), we also extend our results to the linear contextual bandit problem, proving new bounds for a private linear UCB algorithm along the way.
2.",1.1. Our Results,[0],[0]
"We then make a general observation, relating adaptive data gathering to an adaptive analysis of a fixed dataset (in which the choice of which query to pose to the dataset is adaptive).",1.1. Our Results,[0],[0]
This lets us apply the large existing literature connecting differential privacy to adaptive data analysis.,1.1. Our Results,[0],[0]
"In particular, it lets us apply the max-information bounds of (Dwork et al., 2015b; Rogers et al., 2016) to our adaptive data gathering setting.",1.1. Our Results,[0],[0]
"This allows us to give much more general guarantees about the data collected by differentially private collection procedures, that extend well beyond bias.",1.1. Our Results,[0],[0]
"For example, it lets us correct the p-values for arbitrary hypothesis tests run on the gathered data.
",1.1. Our Results,[0],[0]
3.,1.1. Our Results,[0],[0]
"Finally, we run a set of experiments that measure the bias incurred by the standard UCB algorithm in the stochastic bandit setting, contrast it with the low bias obtained by a private UCB algorithm, and show that there are settings of the privacy parameter that simultaneously can make bias statistically insignificant, while having competitive empirical regret with the non-private UCB algorithm.",1.1. Our Results,[0],[0]
We also demonstrate in the linear contextual bandit setting how failing to correct for adaptivity can lead to false discovery when applying t-tests for non-zero regression coefficients on an adaptively gathered dataset.,1.1. Our Results,[1.0],['We also demonstrate in the linear contextual bandit setting how failing to correct for adaptivity can lead to false discovery when applying t-tests for non-zero regression coefficients on an adaptively gathered dataset.']
This paper bridges two recent lines of work.,1.2. Related Work,[0],[0]
"Our starting point is two recent papers: (Villar et al., 2015) empirically demonstrate in the context of clinical trials that a variety of simple stochastic bandit algorithms produce biased sample mean estimates (Similar results have been empirically observed in the context of contextual bandits (Dimakopoulou et al., 2017)).",1.2. Related Work,[0],[0]
"(Nie et al., 2017) prove that simple stochastic bandit algorithms that exhibit two natural properties (satisfied by most commonly used algorithms, including UCB and Thompson Sampling) result in empirical means that exhibit negative bias.",1.2. Related Work,[0],[0]
"They then propose a heuristic algorithm which computes a maximum likelihood estimator for the sample means from the empirical means gathered by a modified UCB algorithm which adds Gumbel noise to
the decision statistics.",1.2. Related Work,[0],[0]
"(Deshpande et al., 2017) propose a debiasing procedure for ordinary least-squares estimates computed from adaptively gathered data that trades off bias for variance, and prove a central limit theorem for their method.",1.2. Related Work,[0],[0]
"In contrast, the methods we propose in this paper are quite different.",1.2. Related Work,[0],[0]
"Rather than giving an ex-post debiasing procedure, we show that if the data were gathered in a differentially private manner, no debiasing is necessary.",1.2. Related Work,[0],[0]
"The strength of our method is both in its simplicity and generality: rather than proving theorems specific to particular estimators, we give methods to correct the p-values for arbitrary hypothesis tests that might be run on the adaptively gathered data.
",1.2. Related Work,[0],[0]
"The second line of work is the recent literature on adaptive data analysis (Dwork et al., 2015c;b; Hardt & Ullman, 2014; Steinke & Ullman, 2015; Russo & Zou, 2016; Wang et al., 2016; Bassily et al., 2016; Hardt & Blum, 2015; Cummings et al., 2016; Feldman & Steinke, 2017a;b) which draws a connection between differential privacy (Dwork et al., 2006) and generalization guarantees for adaptively chosen statistics.",1.2. Related Work,[0],[0]
"The adaptivity in this setting is dual to the setting we study in the present paper: In the adaptive data analysis literature, the dataset itself is fixed, and the goal is to find techniques that can mitigate bias due to the adaptive selection of analyses.",1.2. Related Work,[0],[0]
"In contrast, here, we study a setting in which the data gathering procedure is itself adaptive, and can lead to bias even for a fixed set of statistics of interest.",1.2. Related Work,[0],[0]
"However, we show that adaptive data gathering can be re-cast as an adaptive data analysis procedure, and so the results from the adaptive data analysis literature can be ported over.",1.2. Related Work,[0],[0]
"In a simple stochastic bandit problem, there are K unknown distributions Pi over the unit interval [0,1], each with (unknown) mean µi.",2.1. Simple Stochastic Bandit Problems,[0],[0]
"Over a series of rounds t ∈ {1, . . .",2.1. Simple Stochastic Bandit Problems,[0],[0]
", T}, an algorithm A chooses an arm it ∈",2.1. Simple Stochastic Bandit Problems,[0],[0]
"[K], and observes a reward yit,t ∼ Pit .",2.1. Simple Stochastic Bandit Problems,[0],[0]
"Given a sequence of choices i1, . . .",2.1. Simple Stochastic Bandit Problems,[0],[0]
", iT , the pseudo-regret of an algorithm is defined to be:
Regret((P1, . . .",2.1. Simple Stochastic Bandit Problems,[0],[0]
", PK), i1, . . .",2.1. Simple Stochastic Bandit Problems,[0],[0]
", iT )",2.1. Simple Stochastic Bandit Problems,[0],[0]
= T ·max i µi − T∑ t=1,2.1. Simple Stochastic Bandit Problems,[0],[0]
"µit
We say that regret is bounded if we can put a bound on the quantity Regret((P1, . . .",2.1. Simple Stochastic Bandit Problems,[0],[0]
", PK), i1, . . .",2.1. Simple Stochastic Bandit Problems,[0],[0]
", iT ) in the worst case over the choice of distributions P1, . . .",2.1. Simple Stochastic Bandit Problems,[0],[0]
", PK , and with high probability or in expectation over the randomness of the algorithm and of the reward sampling.
",2.1. Simple Stochastic Bandit Problems,[0],[0]
"As an algorithm A interacts with a bandit problem, it generates a history Λ , which records the sequence of actions
taken and rewards observed thus far:",2.1. Simple Stochastic Bandit Problems,[0],[0]
"Λt = {(i`, yi`,`)} t−1 `=1.",2.1. Simple Stochastic Bandit Problems,[0],[0]
"We denote the space of histories of length T by HT = ([K]× R)T .
",2.1. Simple Stochastic Bandit Problems,[0],[0]
The definition of an algorithm A induces a sequence of T (possibly randomized) selection functions ft : Ht−1,2.1. Simple Stochastic Bandit Problems,[0],[0]
"→ [K], which map histories onto decisions of which arm to pull at each round.",2.1. Simple Stochastic Bandit Problems,[0],[0]
"In the contextual bandit problem, decisions are endowed with observable features.",2.2. Contextual Bandit Problems,[0],[0]
"Our algorithmic results in this paper focus on the linear contextual bandit problem, but our general connection between adaptive data gathering and differential privacy extends beyond the linear case.",2.2. Contextual Bandit Problems,[0],[0]
"For simplicity of exposition, we specialize to the linear case here.
",2.2. Contextual Bandit Problems,[0],[0]
"There are K arms i, each of which is associated with an unknown d-dimensional linear function represented by a vector of coefficients θi ∈ Rd with ||θi||2 ≤ 1.",2.2. Contextual Bandit Problems,[0],[0]
"In rounds t ∈ {1, . . .",2.2. Contextual Bandit Problems,[0],[0]
", T}, the algorithm is presented with a context xi,t ∈ Rd for each arm i with ||xi,t||2 ≤ 1, which may be selected by an adaptive adversary as a function of the past history of play.",2.2. Contextual Bandit Problems,[0],[0]
"We write xt to denote the set of all K contexts present at round t. As a function of these contexts, the algorithm then selects an arm it, and observes a reward yit,t. The rewards satisfy E [yi,t] = θi·xi,t and are bounded to lie in [0, 1].
",2.2. Contextual Bandit Problems,[0],[0]
"In the contextual setting, histories incorporate observed context information as well:",2.2. Contextual Bandit Problems,[0],[0]
"Λt = {(i`, x`, yi`,`)} t−1 `=1.
",2.2. Contextual Bandit Problems,[0],[0]
"Again, the definition of an algorithmA induces a sequence of T (possibly randomized) selection functions ft : Ht−1× Rd×K → [K], which now maps both a history and a set of contexts at round t to a choice of arm at round t.",2.2. Contextual Bandit Problems,[0],[0]
"Above we’ve characterized a bandit algorithmA as gathering data adaptively using a sequence of selection functions ft, which map the observed history",2.3. Data Gathering in the Query Model,[0],[0]
Λt ∈ Ht−1 to the index of the next arm pulled.,2.3. Data Gathering in the Query Model,[0],[0]
In this model only after the arm is chosen is a reward drawn from the appropriate distribution.,2.3. Data Gathering in the Query Model,[0],[0]
"Then the history is updated, and the process repeats.
",2.3. Data Gathering in the Query Model,[0],[0]
"In this section, we observe that whether the reward is drawn after the arm is “pulled,” or in advance, is a distinction without a difference.",2.3. Data Gathering in the Query Model,[1.0],"['In this section, we observe that whether the reward is drawn after the arm is “pulled,” or in advance, is a distinction without a difference.']"
"We cast this same interaction into the setting where an analyst asks an adaptively chosen sequence of queries to a fixed dataset, representing the arm rewards.",2.3. Data Gathering in the Query Model,[1.0],"['We cast this same interaction into the setting where an analyst asks an adaptively chosen sequence of queries to a fixed dataset, representing the arm rewards.']"
The process of running a bandit algorithm A up to time T can be formalized as the adaptive selection of T queries against a single database of size T - fixed in advance.,2.3. Data Gathering in the Query Model,[0],[0]
"The formalization consists of observing two things.
",2.3. Data Gathering in the Query Model,[0.9999999810861503],['The formalization consists of observing two things.']
"First, by the principle of deferred randomness, we can view any (simple or contextual) bandit algorithm as operating in a setting in the rewards available for every arm at every time step have been sampled before the start of the algorithm, rather than online as the algorithm makes its selections.",2.3. Data Gathering in the Query Model,[0],[0]
"Second, the choice of arm pulled at time t by the bandit algorithm can be viewed as the answer to an adaptively selected query against this fixed dataset of rewards.
",2.3. Data Gathering in the Query Model,[1.000000006602767],"['Second, the choice of arm pulled at time t by the bandit algorithm can be viewed as the answer to an adaptively selected query against this fixed dataset of rewards.']"
"Adaptive data analysis is formalized as an interaction in which a data analystA performs computations on a dataset D, observes the results, and then may choose the identity of the next computation to run as a function of previously computed results (Dwork et al., 2015c;a).",2.3. Data Gathering in the Query Model,[0],[0]
"A sequence of recent results shows that if the queries are differentially private in the dataset D, then they will not in general overfit D, in the sense that the distribution over results induced by computing q(D) will be “similar” to the distribution over results induced if q were run on a new dataset, freshly sampled from the same underlying distribution (Dwork et al., 2015c;a; Bassily et al., 2016; Dwork et al., 2015b; Rogers et al., 2016).",2.3. Data Gathering in the Query Model,[0],[0]
"We will be more precise about what these results say in Section 4.
",2.3. Data Gathering in the Query Model,[0],[0]
"Recall that histories Λ record the choices of the algorithm, in addition to its observations.",2.3. Data Gathering in the Query Model,[0],[0]
It will be helpful to introduce notation that separates out the choices of the algorithm from its observations.,2.3. Data Gathering in the Query Model,[0],[0]
"In the simple stochastic setting and the contextual setting, given a history",2.3. Data Gathering in the Query Model,[0],[0]
"Λt, an action history ΛAt =",2.3. Data Gathering in the Query Model,[0],[0]
"(i1, . . .",2.3. Data Gathering in the Query Model,[0],[0]
", it−1) ∈",2.3. Data Gathering in the Query Model,[0],[0]
"[K]t−1 denotes the portion of the history recording the actions of the algorithm.
",2.3. Data Gathering in the Query Model,[0],[0]
"In the simple stochastic setting, a bandit tableau is a T ×K matrix D ∈",2.3. Data Gathering in the Query Model,[0],[0]
"( [0, 1]K )T .",2.3. Data Gathering in the Query Model,[0],[0]
"Each row Dt of D is a vector of K real numbers, intuitively representing the rewards that would be available to a bandit algorithm at round t for each of the K arms.",2.3. Data Gathering in the Query Model,[0],[0]
"In the contextual setting, a bandit tableau is represented by a pair of T ×K matrices: D ∈",2.3. Data Gathering in the Query Model,[0],[0]
"( [0, 1]K
)T and C ∈ ( (Rd)K )T .",2.3. Data Gathering in the Query Model,[0],[0]
"Intuitively, C represents the contexts presented to a bandit algorithm",2.3. Data Gathering in the Query Model,[0],[0]
"A at each round: each row Ct corresponds to a set of K contexts, one for each arm.",2.3. Data Gathering in the Query Model,[0],[0]
"D again represents the rewards that would be available to the bandit algorithm at round t for each of the K arms.
",2.3. Data Gathering in the Query Model,[0],[0]
"We write Tab to denote a bandit tableau when the setting has not been specified: implicitly, in the simple stochastic case, Tab = D, and in the contextual case, Tab = (D,C).
",2.3. Data Gathering in the Query Model,[0],[0]
Given a bandit tableau and a bandit algorithm,2.3. Data Gathering in the Query Model,[0],[0]
"A, we have the following interaction:
We denote the subset of the reward tableau D corresponding to rewards that would have been revealed to a bandit algorithmA given action history ΛAt , by ΛAt (D).",2.3. Data Gathering in the Query Model,[0],[0]
"Concretely if ΛAt = (i1, . .",2.3. Data Gathering in the Query Model,[0],[0]
.,2.3. Data Gathering in the Query Model,[0],[0]
", it−1) then Λ A t (D) =",2.3. Data Gathering in the Query Model,[0],[0]
"{(i`, yi`,`)} t−1 `=1.",2.3. Data Gathering in the Query Model,[0],[0]
"Given a selection function ft and an action history ΛAt , de-
Interact Inputs: Time horizon T , bandit algorithm A, and bandit tableau Tab (D in the simple stochastic case, (D,C) in the contextual case)
1: for t = 1 to T do 2: (contextual case) ShowA contexts Ct,1, . . .",2.3. Data Gathering in the Query Model,[0],[0]
", Ct,K 3: Let A play action it 4: Show A reward Dt,it 5: end for 6: Return: (i1, . . .",2.3. Data Gathering in the Query Model,[0],[0]
", iT )
fine the query qΛAt as qΛAt (D) = ft(Λ A t (D)).
",2.3. Data Gathering in the Query Model,[0],[0]
We now define Algorithms Bandit and InteractQuery.,2.3. Data Gathering in the Query Model,[0],[0]
"Bandit is a standard contextual bandit algorithm defined by selection functions ft, and InteractQuery is the Interact routine that draws the rewards in advance, and at time t selects action it as the result of query qΛAt .",2.3. Data Gathering in the Query Model,[0],[0]
"With the above definitions in hand, it is straightforward to show that the two Algorithms are equivalent, in that they induce the same joint distribution on their outputs.",2.3. Data Gathering in the Query Model,[0],[0]
"In both algorithms for convenience we assume we are in the linear contextual setting, and we write ηit to denote the i.i.d. error distributions of the rewards, conditional on the contexts.
",2.3. Data Gathering in the Query Model,[0],[0]
"Bandit Inputs: T, k, {xit}, {θi}, ft,Λ0 = ∅
1: for t = 1, . . .",2.3. Data Gathering in the Query Model,[0],[0]
", T : do 2: Let it = ft(Λt−1) 3: Draw yit,t ∼ xit,t · θit + ηit 4: Update Λt = Λt−1 ∪ (it, yit,t) 5: end for 6: Return: ΛT
InteractQuery Inputs: T, k,D : Dit = θi · xit + ηit, ft
1: for t = 1, . . .",2.3. Data Gathering in the Query Model,[0],[0]
", T : do 2: Let qt = qΛAt−1 3: Let it = qt(D) 4: Update ΛAt = Λ",2.3. Data Gathering in the Query Model,[0],[0]
"A t−1 ∪ it 5: end for 6: Return: ΛAT
Claim 1.",2.3. Data Gathering in the Query Model,[0],[0]
"Let P1,t be the joint distribution induced by Algorithm Bandit on Λt at time t, and let P2,t be the joint distribution induced by Algorithm InteractQuery on Λt = Λ A t (D).",2.3. Data Gathering in the Query Model,[0],[0]
"Then ∀t P1,t = P2,t.
",2.3. Data Gathering in the Query Model,[0],[0]
"The upshot of this equivalence is that we can import existing results that hold in the setting in which the dataset
is fixed, and queries are adaptively chosen.",2.3. Data Gathering in the Query Model,[0],[0]
"There are a large collection of results of this form that apply when the queries are differentially private (Dwork et al., 2015c; Bassily et al., 2016; Rogers et al., 2016) which apply directly to our setting.",2.3. Data Gathering in the Query Model,[0],[0]
"In the next section we formally define differential privacy in the simple stochastic and contextual bandit setting, and leave the description of the more general transfer theorems to Section 4.",2.3. Data Gathering in the Query Model,[0],[0]
We will be interested in algorithms that are differentially private.,2.4. Differential Privacy,[0],[0]
"In the simple stochastic bandit setting, we will require differential privacy with respect to the rewards.",2.4. Differential Privacy,[0],[0]
"In the contextual bandit setting, we will also require differential privacy with respect to the rewards, but not necessarily with respect to the contexts.
",2.4. Differential Privacy,[0],[0]
"We now define the neighboring relation we need to define bandit differential privacy:
Definition 1.",2.4. Differential Privacy,[0],[0]
"In the simple stochastic setting, two bandit tableau’s D,D′ are reward neighbors if they differ in at most a single row: i.e. if there exists an index ` such that for all t 6=",2.4. Differential Privacy,[0],[0]
"`, Dt = D′t.
",2.4. Differential Privacy,[0],[0]
"In the contextual setting, two bandit tableau’s (D,C), (D′, C ′) are reward neighbors if C = C ′ and D and D′ differ in at most a single row: i.e. if there exists an index ` such that for all t 6=",2.4. Differential Privacy,[0.9945115310388741],"['In the contextual setting, two bandit tableau’s (D,C), (D′, C ′) are reward neighbors if C = C ′ and D and D′ differ in at most a single row: i.e. if there exists an index ` such that for all t 6= `, Dt = D′t.']"
"`, Dt = D′t.
",2.4. Differential Privacy,[0],[0]
"Note that changing a context does not result in a neighboring tableau: this neighboring relation will correspond to privacy for the rewards, but not for the contexts.",2.4. Differential Privacy,[0],[0]
Remark 1.,2.4. Differential Privacy,[0],[0]
"Note that we could have equivalently defined reward neighbors to be tableaus that differ in only a single entry, rather than in an entire row.",2.4. Differential Privacy,[0],[0]
"The distinction is unimportant in a bandit setting, because a bandit algorithm will be able to observe only a single entry in any particular row.
",2.4. Differential Privacy,[0],[0]
Definition 2.,2.4. Differential Privacy,[0],[0]
"A bandit algorithm A is ( , δ) reward differentially private if for every time horizon T and every pair of bandit tableau Tab,Tab′ that are reward neighbors, and every subset S ⊆",2.4. Differential Privacy,[0],[0]
"[K]T :
P [Interact(T,A,Tab) ∈ S] ≤
e P [ Interact(T,A,Tab′) ∈ S ]",2.4. Differential Privacy,[0],[0]
"+ δ
",2.4. Differential Privacy,[0],[0]
"If δ = 0, we say that A is -differentially private.",2.4. Differential Privacy,[0],[0]
We begin by showing that differentially private algorithms that operate in the stochastic bandit setting compute empirical means for their arms that are nearly unbiased.,3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"Together
with known differentially private algorithms for stochastic bandit problems, the result is an algorithm that obtains a nearly optimal (worst-case) regret guarantee while also guaranteeing that the collected data is nearly unbiased.",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0.9999999796402068],"['Together with known differentially private algorithms for stochastic bandit problems, the result is an algorithm that obtains a nearly optimal (worst-case) regret guarantee while also guaranteeing that the collected data is nearly unbiased.']"
"We could (and do) obtain these results by combining the reduction to answering adaptively selected queries given by Theorem 1 with the standard generalization theorems in adaptive data analysis (e.g. Corollary 2 in its most general form), but we first prove these de-biasing results from first principles to build intuition.
",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
Theorem 1.,3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"Let A be an ( , δ)-differentially private algorithm in the stochastic bandit setting.",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"Then, for all i ∈",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"[K], and all t, we have:∣∣∣E [Ŷ ti − µi]∣∣∣ ≤",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
(e − 1 + Tδ)µi Remark 2.,3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
Note that since µi ∈,3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"[0, 1], and for 1, e ≈ 1+ , this theorem bounds the bias by roughly +Tδ.",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0.9929898895450874],"['Note that since µi ∈ [0, 1], and for 1, e ≈ 1+ , this theorem bounds the bias by roughly +Tδ.']"
"Often, we will have δ = 0 and so the bias will be bounded by roughly .
",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
Proof.,3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
First we fix some notation.,3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"Fix any time horizon T , and let (ft)t∈[T ] be the sequence of selection functions induced by algorithm A. Let 1{ft(Λt)=i} be the indicator for the event that arm i is pulled at time t. We can write the random variable representing the sample mean of arm i at time T as
Ŷ Ti = T∑ t=1 1{ft(Λt)=i}∑T t′=1 1{ft′ (Λt′ )",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"=i} yit
where we recall that yi,t is the random variable representing the reward for arm",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"i at time t. Note that the numerator (ft(Λt) = i) is by definition independent of yi,t, but the denominator ( ∑T t′=1 1{ft′ (Λt′ )=i}) is not, because for t
′",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"> tΛt′ depends on yi,t.",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"It is this dependence that leads to bias in adaptive data gathering procedures, and that we must argue is mitigated by differential privacy.
",3. Privacy Reduces Bias in Stochastic Bandit Problems,[1.0000000153539441],"['It is this dependence that leads to bias in adaptive data gathering procedures, and that we must argue is mitigated by differential privacy.']"
We recall that the random variable NTi represents the number of times arm i is pulled through round T : NTi =∑T t′=1 1{ft′ (Λt′ ),3. Privacy Reduces Bias in Stochastic Bandit Problems,[0.9611933873334677],['We recall that the random variable NTi represents the number of times arm i is pulled through round T : NTi =∑T t′=1 1{ft′ (Λt′ )=i}.']
=i}.,3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"Using this notation, we write the sample mean of arm i at time T , as:
Ŷ Ti = T∑ t=1 1{ft(Λt)=i} NTi · yit
We can then calculate:
E[Ŷ ti ] = T∑ t=1 E[ 1{ft(Λt)=i} NTi yit]
= T∑ t=1 E yit∼Pi",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"[yit · E A [ 1{ft(Λt)=i} NTi |yit]]
where the first equality follows by the linearity of expectation, and the second follows by the law of iterated expectation.
",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
Our goal is to show that the conditioning in the inner expectation does not substantially change the value of the expectation.,3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"Specifically, we want to show that all t, and any value yit, we have
E[ 1{ft(Λt)=i}
Ni |yit] ≥ e− E[
1{ft(Λt)=i}
NTi ]",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"− δ
If we can show this, then we will have
E[Ŷ Ti ] ≥ (e− T∑ t=1 E[ 1{ft(Λt)=i} NTi ]",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"− Tδ) · µi
= (e− E[ NTi NTi ]",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"− Tδ) · µi = (e− − Tδ) · µi
which is what we want (The reverse inequality is symmetric).
",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
This is what we now show to complete the proof.,3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"Observe that for all t, i, the quantity 1{ft(Λt)=i}Ni can be derived as a post-processing of the sequence of choices (f1(Λ1), . . .",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
", fT (ΛT )), and is therefore differentially private in the observed reward sequence.",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"Observe also that the quantity 1{ft(Λt)=i}
NTi is bounded in [0, 1].",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"Hence (by a
lemma in the full version) for any pair of values yit, y′it, we have E[
1{ft(Λt)=i} NTi |yit] ≥ e− E[ 1{ft(Λt)=i} NTi |y′it]− δ.",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"All
that remains is to observe that there must exist some value y′it such that E[ 1{ft(Λt)=i} Ni |y′it] ≥ E[ 1{ft(Λt)=i} Ni ].",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"(Otherwise, this would contradict",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
Ey′it∼Pi,3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"[E[ 1{ft(Λt)=i} Ni |y′it]] = E[ 1{ft(Λt)=i}
NTi ])",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
.,3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"Fixing any such y′it implies that for all yit
E[ 1{ft(Λt)=i}
Ni |yit] ≥ e− E[
1{ft(Λt)=i}
NTi |y′i,t]− δ
≥ e− E[ 1{ft(Λt)=i}
NTi ]",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"− δ
as desired.",3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
The upper bound on the bias follows symmetrically.,3. Privacy Reduces Bias in Stochastic Bandit Problems,[0],[0]
"There are existing differentially private variants of the classic UCB algorithm ((Auer et al., 2002; Agrawal, 1995; Lai & Robbins, 1985)), which give a nearly optimal tradeoff between privacy and regret (Mishra & Thakurta, 2014; Tossou & Dimitrakakis, 2017; 2016).",3.1. A Private UCB Algorithm,[0],[0]
"For completeness, we give a simple version of a private UCB algorithm in the full version which we use in our experiments.",3.1. A Private UCB Algorithm,[0],[0]
"Here, we simply quote the relevant theorem, which is a consequence of a theorem in (Tossou & Dimitrakakis, 2016):
Theorem 2.",3.1. A Private UCB Algorithm,[0],[0]
"(Tossou & Dimitrakakis, 2016)",3.1. A Private UCB Algorithm,[0],[0]
"There is an - differentially private algorithm that obtains expected regret bounded by:
O ( max ( lnT · (ln ln(T ) + ln(1/ )) , √ kT log T ))
",3.1. A Private UCB Algorithm,[0],[0]
"Thus, we can take to be as small as = O( ln 1.5 T√ kT )
while still having a regret bound of O( √ kT log T ), which is nearly optimal in the worst case (over instances) (Audibert & Bubeck, 2009).
",3.1. A Private UCB Algorithm,[0],[0]
"Combining the above bound with Theorem 1, and letting =",3.1. A Private UCB Algorithm,[0],[0]
"O( ln
1.5 T√ kT ), we have:
Corollary 1.",3.1. A Private UCB Algorithm,[0],[0]
"There exists a simple stochastic bandit algorithm that simultaneously guarantees that the bias of the empirical average for each arm i is bounded by O(µi · ln
1.5 T√ kT
) and guarantees expected regret bounded by O( √ kT log T ).
",3.1. A Private UCB Algorithm,[0.9999999484864922],['There exists a simple stochastic bandit algorithm that simultaneously guarantees that the bias of the empirical average for each arm i is bounded by O(µi · ln 1.5 T√ kT ) and guarantees expected regret bounded by O( √ kT log T ).']
"Of course, other tradeoffs are possible using different values of .",3.1. A Private UCB Algorithm,[0],[0]
"For example, the algorithm of (Tossou & Dimitrakakis, 2016) obtains sub-linear regret so long as = ω( ln
2 T T ).",3.1. A Private UCB Algorithm,[1.0000000110415426],"['For example, the algorithm of (Tossou & Dimitrakakis, 2016) obtains sub-linear regret so long as = ω( ln 2 T T ).']"
"Thus, it is possible to obtain non-trivial regret while guaranteeing that the bias of the empirical means remains as low as polylog(T )/T .",3.1. A Private UCB Algorithm,[1.0],"['Thus, it is possible to obtain non-trivial regret while guaranteeing that the bias of the empirical means remains as low as polylog(T )/T .']"
"Up through this point, we have focused our attention on showing how the private collection of data mitigates the effect that adaptivity has on bias, in both the stochastic and (in the full version) contextual bandit problems.",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"In this section, we draw upon more powerful results from the adaptive data analysis literature to go substantially beyond bias: to correct the p-values of hypothesis tests applied to adaptively gathered data.",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"These p-value corrections follow from the connection between differential privacy and a quantity called max information, which controls the extent to which the dependence of selected test on the dataset can distort the statistical validity of the test (Dwork et al., 2015b; Rogers et al., 2016).",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"We briefly define max information, state the connection to differential privacy, and illustrate how max information bounds can be used to perform adaptive analyses in the private data gathering framework.
",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"Definition 3 (Max-Information (Dwork et al., 2015b).).",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"Let X,Z be jointly distributed random variables over domain (X ,Z).",4. Max Information & Arbitrary Hypothesis Tests,[1.0],"['Let X,Z be jointly distributed random variables over domain (X ,Z).']"
"Let X ⊗ Z denote the random variable that draws independent copies of X,Z according to their marginal distributions.",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"The β-approximate maxinformation between X,Z, denoted Iβ(X,Z), is defined
as:
Iβ(X,Z) = log sup O⊂(X×Z), P[(X,Z)∈O]>β",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
P,4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"[(X,Z) ∈ O]−",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
β P,4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
[X ⊗ Z ∈,4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"O]
",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"Following (Rogers et al., 2016), define a test statistic t : D → R, where D is the space of all datasets.",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"For D ∈ D, given an output a = t(D), the p-value associated with the test t on dataset D is p(a) =",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
PD∼P0,4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"[t(D) ≥ a], where P0 is the null hypothesis distribution.",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"Consider an algorithm A, mapping a dataset to a test statistic.",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"Definition 4 (Valid p-value Correction Function (Rogers et al., 2016).).",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
A function γ :,4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"[0, 1] → [0, 1] is a valid p-value correction function for A if the procedure:
1.",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"Select a test statistic t = A(D)
2.",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"Reject the null hypothesis if p(t(D)) ≤ γ(α)
has probability at most α of rejection, when D ∼ P0.
",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"Then the following theorem gives a valid p-value correction function when (D,A(D)) have bounded β-approximate max information.
",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"Theorem 3 ((Rogers et al., 2016).).",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"Let A be a datadependent algorithm for selecting a test statistics such that Iβ(X,A(X))",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
≤,4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
k.,4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"Then the following function γ is a valid p-value correction function for A: γ(α) = max(α−β
2k , 0)
",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"Finally, we can connect max information to differential privacy, which allows us to leverage private algorithms to perform arbitrary valid statistical tests.
",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"Theorem 4 (Theorem 20 from (Dwork et al., 2015b).).",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"Let A be an -differentially private algorithm, let P be an arbitrary product distribution over datasets of size n, and let D ∼ P .",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"Then for every β > 0:
Iβ(D,A(D)) ≤ log(e)( 2n/2 + √ n log(2/β)/2)
",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
Remark 3.,4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
We note that a hypothesis of this theorem is that the data is drawn from a product distribution.,4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"In the contextual bandit setting, this corresponds to rows in the bandit tableau being drawn from a product distribution.",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"This will be the case if contexts are drawn from a distribution at each round, and then rewards are generated as some fixed stochastic function of the contexts.",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"Note that contexts (and even rewards) can be correlated with one another within a round, so long as they are selected independently across rounds.
",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
We now formalize the process of running a hypothesis test against an adaptively collected dataset.,4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
A bandit algorithm A generates a history ΛT ∈ HT .,4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
Let the reward portion of the gathered dataset be denoted by DA.,4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"We define an adaptive test statistic selector as follows.
",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
Definition 5.,4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
Fix the reward portion of a bandit tableau D and bandit algorithmA.,4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"An adaptive test statistic selector is a function s from action histories to test statistics such that s(ΛAT ) is a real-valued function of the adaptively gathered dataset DA.
",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"Importantly, the selection of the test statistic s(ΛAT ) can depend on the sequence of arms pulled by A (and in the contextual setting, on all contexts observed), but not otherwise on the reward portion of the tableau D. For example, tA = s(Λ",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"A T ) could be the t-statistic corresponding to the null hypothesis that the arm i∗ which was pulled the great-
est number of times has mean µ: tA(DA) = ∑NT i∗ t=1 yi∗t−µ√
NT i∗
By virtue of Theorems 3 and 4, and our view of adaptive data gathering as adaptively selected queries, we get the following corollary:
Corollary 2.",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"Let A be an reward differentially private bandit algorithm, and let s be an adaptive test statistic selector.",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"Fix β > 0, and let γ(α) =
α
2log(e)( 2T/2+
√ T log(2/β)/2) , for α ∈",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"[0, 1].",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"Then for any adaptively selected statistic tA = s(ΛAT ), and any product distribution P corresponding to the null hypothesis for tA
PD∼P,A [p(tA(D))",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
≤ γ(α)],4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
"≤ α
If we set = O(1/ √ T ) in Corollary 2, then γ(α) = O(α)– i.e. a valid p-value correction that only scales α by a constant.",4. Max Information & Arbitrary Hypothesis Tests,[0],[0]
We first validate our theoretical bounds on bias in the simple stochastic bandit setting.,5. Experiments,[0],[0]
"As expected the standard UCB algorithm underestimates the mean at each arm, while the private UCB algorithm of (?) obtains very low bias.",5. Experiments,[0],[0]
"While using the suggested by the theory effectively reduces bias and achieves near optimal asymptotic regret, the resulting private algorithm only achieves non-trivial regret for large T due to large constants and logarithmic factors in our bounds.",5. Experiments,[0],[0]
"This motivates a heuristic choice of that provides no theoretical guarantees on bias reduction, but leads to regret that is comparable to the non-private UCB algorithm.",5. Experiments,[0],[0]
We find empirically that even with this large choice of we achieve an 8 fold reduction in bias relative to UCB.,5. Experiments,[0],[0]
"This is consistent with the observation that our guarantees hold in the worst-case, and suggests that there is room for improvement in our theoretical bounds — both improving constants in the worst-case bounds on bias and on regret, and for proving instance specific bounds.",5. Experiments,[0],[0]
"Finally, we show that in the linear contextual bandit setting collecting data adaptively with a linear UCB algorithm and then conducting t-tests for regression coefficients yields incorrect inference (absent a p-value correction).",5. Experiments,[0],[0]
"These findings
confirm the necessity of our methods when drawing conclusions from adaptively gathered data.",5. Experiments,[0],[0]
In our first stochastic bandit experiment we set K = 20 and T = 500.,5.1. Stochastic Multi-Armed Bandit,[0],[0]
"The K arm means are equally spaced between 0 and 1 with gap ∆ = .05, with µ0 = 1.",5.1. Stochastic Multi-Armed Bandit,[0],[0]
"We run UCB and -private UCB for T rounds with = .05, and after each run compute the difference between the sample mean at each arm and the true mean.",5.1. Stochastic Multi-Armed Bandit,[0],[0]
"We repeat this process 10, 000 times, averaging to obtain high confidence estimates of the bias at each arm.",5.1. Stochastic Multi-Armed Bandit,[0],[0]
"The average absolute bias over all arms for private UCB was .00176, with the bias for every arm being statistically indistinguishable from 0 at 95% confidence (see Figure 1 for confidence intervals) while the average absolute bias (over arms) for UCB was .0698, or over 40 times higher.",5.1. Stochastic Multi-Armed Bandit,[0],[0]
"The most biased arm had a measured bias of roughly 0.14, and except for the top 4 arms, the bias of each arm was statistically significant.",5.1. Stochastic Multi-Armed Bandit,[0],[0]
"It is worth noting that private UCB achieves bias significantly lower than the = .05 guaranteed by the theory, indicating that the theoretical bounds on bias obtained from differential privacy are conservative.",5.1. Stochastic Multi-Armed Bandit,[0],[0]
"Figures 1, 2 show the bias at each arm for private UCB vs. UCB, with 95% confidence intervals around the bias at each arm.",5.1. Stochastic Multi-Armed Bandit,[0],[0]
"Not only is the bias for private UCB an order of magnitude smaller on average, it does not exhibit the systemic negative bias evident in Figure 2.
",5.1. Stochastic Multi-Armed Bandit,[0],[0]
"Noting that the observed reduction in bias for = .05 exceeded that guaranteed by the theory, we run a second experiment withK = 5, T = 100000,∆ = .05, and = 400, averaging results over 1000 iterations.",5.1. Stochastic Multi-Armed Bandit,[0],[0]
Figure 5 shows that private UCB achieves sub-linear regret comparable with UCB.,5.1. Stochastic Multi-Armed Bandit,[0],[0]
"While = 400 provides no meaningful theoretical guarantee, the average absolute bias at each arm mean obtained by the private algorithm was .0015 (statistically indistinguishable from 0 at 95% confidence for each arm), while the non-private UCB algorithm obtained average bias .011, 7.5 times larger.",5.1. Stochastic Multi-Armed Bandit,[0],[0]
"The bias reduction for the arm with the smallest mean (for which the bias is the worst with the non private algorithm) was by more than a factor of 10.
",5.1. Stochastic Multi-Armed Bandit,[0],[0]
"Figures 3,4 show the bias at each arm for the private and non-private UCB algorithms together with 95% confidence intervals; again we observe a negative skew in the bias for UCB, consistent with the theory in (Nie et al., 2017).",5.1. Stochastic Multi-Armed Bandit,[0],[0]
Our second experiment confirms that adaptivity leads to bias in the linear contextual bandit setting in the context of hypothesis testing – and in particular can lead to false discovery in testing for non-zero regression coefficients.,5.2. Linear Contextual Bandits,[0],[0]
"The set up is as follows: for K = 5 arms, we observe rewards
yi,t ∼ N (θ′ixit, 1), where θi, xit ∈ R5, ||θi|| = ||xit|| = 1.",5.2. Linear Contextual Bandits,[0],[0]
"For each arm i, we set θi1 = 0.",5.2. Linear Contextual Bandits,[0],[0]
"Subject to these constraints, we pick the θ parameters uniformly at random (once per run), and select the contexts x uniformly at random (at each round).",5.2. Linear Contextual Bandits,[0],[0]
"We run a linear UCB algorithm (OFUL (?)) for T = 500 rounds, and identify the arm i∗ that has been selected most frequently.",5.2. Linear Contextual Bandits,[0],[0]
We then conduct a z-test for whether the first coordinate of θi∗ is equal to 0.,5.2. Linear Contextual Bandits,[0],[0]
"By construction the null hypothesis H0 : θi∗1 = 0 of the experiment is true, and absent adaptivity, the p-value should be distributed uniformly at random.",5.2. Linear Contextual Bandits,[0],[0]
"In particular, for any value of α the probability that the corresponding p-value is less than α is exactly α.",5.2. Linear Contextual Bandits,[0],[0]
"We record the observed p-value, and repeat the experiment 1000 times, displaying the histogram of observed p-values in Figure 6.",5.2. Linear Contextual Bandits,[0],[0]
"As expected, the adaptivity of the data gathering process leads the p-values to exhibit a strong downward skew.",5.2. Linear Contextual Bandits,[0],[0]
The dotted blue line demarcates α = .05.,5.2. Linear Contextual Bandits,[0],[0]
"Rather than probability .05 of falsely rejecting the null hypothesis at 95% confidence, we observe that 76% of the observed p-values fall below the .05 threshold.",5.2. Linear Contextual Bandits,[0],[0]
"This shows that a careful p-value correction in the style of Section 2.3 is essential even for simple testing of regression coefficients, lest bias lead to false discovery.",5.2. Linear Contextual Bandits,[0],[0]
"Data that is gathered adaptively — via bandit algorithms, for example — exhibits bias.",abstractText,[0],[0]
This is true both when gathering simple numeric valued data — the empirical means kept track of by stochastic bandit algorithms are biased downwards — and when gathering more complicated data — running hypothesis tests on complex data gathered via contextual bandit algorithms leads to false discovery.,abstractText,[0],[0]
"In this paper, we show that this problem is mitigated if the data collection procedure is differentially private.",abstractText,[0],[0]
"This lets us both bound the bias of simple numeric valued quantities (like the empirical means of stochastic bandit algorithms), and correct the p-values of hypothesis tests run on the adaptively gathered data.",abstractText,[0],[0]
"Moreover, there exist differentially private bandit algorithms with near optimal regret bounds: we apply existing theorems in the simple stochastic case, and give a new analysis for linear contextual bandits.",abstractText,[0],[0]
We complement our theoretical results with experiments validating our theory1.,abstractText,[0],[0]
Mitigating Bias in Adaptive Data Gathering via Differential Privacy,title,[0],[0]

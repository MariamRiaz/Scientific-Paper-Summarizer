0	20	Coreference resolution, identifying mentions that refer to the same entities, is an important NLP problem.
1	13	Resolving coreference is critical for many downstream applications, such as reading comprehension, translation, and text summarization.
4	13	For example, it is hard to identify the mention “he” between two entities “Tom” and “Jerry” because they have almost the same word embeddings.
6	40	The most popular one is OntoNotes, and recent work on coreference resolution (Clark and Manning, 2016a,b; Lee et al., 2017; Peters et al., 2018) evaluated their models on it.
7	21	Other datasets were rarely studied after OntoNotes was published.
8	75	Previous work (Sadat Moosavi and Strube, 2017) suggests that the overlap between training and test sets makes significant impact on the performance of current coreference resolvers.
9	68	In OntoNotes, which has relatively low training-test overlap, this impact is mixed together with the core challenges of coreference resolution.
11	14	It is hard to tell whether the algorithm can succeed if the currently low-frequency phrase “the wounded” has not been seen enough times in the training set.
12	20	From a machine learning perspective, high overlap is needed to ensure that the training and test datasets have similar statistics.
13	69	Another limitation of OntoNotes is that it only has annotations for non-singleton mentions, while singleton mentions are not annotated.
14	32	Most of the algorithms for coreference resolution have two steps: mention detection and mention clustering (Wiseman et al., 2016; Clark and Manning, 2016a,b).
15	30	The lack of singleton mention annotations makes training and evaluation of mention detectors more difficult.
16	31	To address both limitations of OntoNotes, we build a new dataset, PreCo.
17	18	To alleviate the negative impact of low training-test overlap, we restrict the data domain and collect a sufficient amount of data to achieve a relatively high training-test overlap.
18	41	Restricting the data domain is a common way to enable better studies of unsolved NLP tasks, such as language modeling (Hill et al., 2015) and visual question answering (Johnson et al., 2017).
19	17	We select our data from English reading comprehension tests for middle and high school Chinese students, which has several advantages.
22	26	This is similar to the vocabulary of a preschool English-speaking child (Wikipedia, 2018).
24	56	On the other hand, it is practical to collect enough data of this type from the Internet.
25	25	With 12.5M words, PreCo is about 10 times larger than OntoNotes.
26	17	Large scale datasets, e.g. ImageNet (Deng et al., 2009), SQuAD (Rajpurkar et al., 2016), have played an important role for driving computer vision and NLP forward.
27	147	We use the rate of out-of-vocabulary (OOV) words between training and test sets to measure their overlap.
30	149	We test a state-of-the-art system (Peters et al., 2018) on PreCo and get an F1 score of 81.5.
31	30	However, a modest human performance (87.9, which will be described in 4.1 ) is much higher, verifying there remain challenges.
32	28	To help training and evaluation of mention detection, we annotate singleton mentions in PreCo.
34	151	We show that in a state-of-the-art coreference resolution system (Peters et al., 2018), we can improve the model performance from 77.3 to 81.6 F1 on a training set of 2.5K PreCo documents by using an oracle mention detector, and the remaining gap of 18.4 F1 to the perfect 100 F1 can only be reduced by improving mention clustering.
35	20	This indicates that future work should concern more about mention clustering than mention detection.
36	16	The advantages of our proposed dataset over existing ones in coreference resolution can be summarized as follows: • Its OOV rate is about 1/3 of OntoNotes.
37	17	• It has about 10 times larger corpus size than OntoNotes.
38	32	• It has annotated singleton mentions.
62	21	We discuss the data collection and annotation in this section.

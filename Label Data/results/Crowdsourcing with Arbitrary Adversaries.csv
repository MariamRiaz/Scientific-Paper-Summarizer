0,1,label2,summary_sentences
"Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 2832–2838 Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics",text,[0],[0]
"Bidirectional Long Short-Term Memory (BLSTM) based models (Graves and Schmidhuber, 2005), along with word embeddings and character embeddings, have shown competitive performance on Part-of-Speech (POS) tagging given sufficient amount of training examples (Ling et al., 2015; Lample et al., 2016; Plank et al., 2016; Yang et al., 2017).
",1 Introduction,[0],[0]
"Given insufficient training examples, we can improve the POS tagging performance by cross-
lingual POS tagging, which exploits affluent POS tagging corpora from other source languages.",1 Introduction,[0],[0]
"This approach usually requires linguistic knowledge or resources about the relation between the source language and the target language such as parallel corpora (Täckström et al., 2013; Duong et al., 2013; Kim et al., 2015a; Zhang et al., 2016), morphological analyses (Hana et al., 2004), dictionaries (Wisniewski et al., 2014), and gaze features (Barrett et al., 2016).
",1 Introduction,[0],[0]
"Given no linguistic resources between the source language and the target language, transfer learning methods can be utilized instead.",1 Introduction,[0],[0]
"Transfer learning for cross-lingual cases is a type of transductive transfer learning, where the input domains of the source and the target are different (Pan and Yang, 2010) since each language has its own vocabulary space.",1 Introduction,[0],[0]
"When the input space is the same, lower layers of hierarchical models can be shared for knowledge transfer (Collobert et al., 2011; Kim et al., 2015b; Yang et al., 2017), but that approach is not directly applicable when the input spaces differ.
",1 Introduction,[0],[0]
Yang et al. (2017) used shared character embeddings for different languages as a cross-lingual transfer method while using different word embeddings for different languages.,1 Introduction,[0],[0]
"Although the approach showed improved performance on Named Entity Recognition, it is limited to character-level representation transfer and it is not applicable for knowledge transfer between languages without overlapped alphabets.
",1 Introduction,[0],[0]
"In this work, we introduce a cross-lingual transfer learning model for POS tagging requiring no cross-lingual resources, where knowledge transfer is made in the BLSTM layers on top of word embeddings and character embeddings.",1 Introduction,[0],[0]
"Inspired by Kim et al. (2016)’s multi-task slot-filling model, our model utilizes a common BLSTM for representing language-generic information, which al-
2832
lows knowledge transfer from other languages, and private BLSTMs for representing languagespecific information.",1 Introduction,[0],[0]
"The common BLSTM is additionally encouraged to be language-agnostic with language-adversarial training (Chen et al., 2016) so that the language-general representations to be more compatible among different languages.
",1 Introduction,[0],[0]
"Evaluating on POS datasets from 14 different target languages with English as the source language in the Universal Dependencies corpus 1.4 (Nivre et al., 2016), the proposed model showed significantly better performance when the source language and the target language are in the same language family, and competitive performance when the language families are different.",1 Introduction,[0],[0]
Cross-Lingual Training Figure 1 shows the overall architecture of the proposed model.,2 Model,[0],[0]
"The baseline POS tagging model is similar to Plank et al. (2016)’s model, and it corresponds to having only word+char embeddings, common BLSTM, and Softmax Output in Figure 1.",2 Model,[0],[0]
"Given an input
word sequence, a BLSTM is used for the character sequence of each word, where the outputs of the ends of the character sequences from the forward LSTM and the backward LSTM are concatenated to the word vector of the current word to supplement the word representation.",2 Model,[0],[0]
"These serve as an input to a BLSTM, and an output layer are used for POS tag prediction.
",2 Model,[0],[0]
"For the cross-lingual transfer learning, the character embedding, the BLSTM with the character embedding (Yang et al., 2017),1 and the common BLSTM are shared for all the given languages while word embeddings and private BLSTMs have different parameters for different languages.
",2 Model,[0],[0]
The outputs of the common BLSTM and the private BLSTM of the current language are summed to be used as the input to the softmax layer to predict the POS tags of given word sequences.,2 Model,[0],[0]
"The loss function of the POS tagging can be formulate as:
Lp = − S∑
i=1",2 Model,[0],[0]
"N∑ j=1 pi,j log (p̂i,j) , (1)
where S is the number of sentences in the current minibatch,N is the number of words in the current sentence, pi,j is the label of the j-th tag of the i-th sentence in the minibatch, and p̂i,j is the predicted tag.",2 Model,[0],[0]
"In addition to this main objective, two more objectives for improving the transfer learning are described in the following subsections.
",2 Model,[0],[0]
"Language-Adversarial Training We encourage the outputs of the common BLSTM to be language-agnostic by using language-adversarial training (Chen et al., 2016) inspired by domainadversarial training (Ganin et al., 2016; Bousmalis et al., 2016).",2 Model,[0],[0]
"First, we encode a BLSTM output sequence as a single vector using a CNN/MaxPool encoder, which is implemented the same as a CNN for text classification (Kim, 2014).",2 Model,[0],[0]
"The encoder is with three convolution filters whose sizes are 3, 4, and 5.",2 Model,[0],[0]
"For each filter, we pass the BLSTM output sequence as the input sequence and obtain a single vector from the filter output by using max pooling, and then tanh activation function is used for transforming the vector.",2 Model,[0],[0]
"Then, the vector outputs of the three filters are concatenated and forwarded to the language discriminator through the gradient reversal layer.",2 Model,[0],[0]
"The discriminator is implemented
1We also tried isolated character-level modules but the overall performance was worse.
as a fully-connected neural network with a single hidden layer, whose activation function is Leaky ReLU (Maas et al., 2013), where we multiply 0.2 to negative input values as the outputs.
",2 Model,[0],[0]
"Since the gradient reversal layer is below the language classifier, the gradients minimizing language classification errors are passed back with opposed sign to the sentence encoder, which adversarially encourages the sentence encoder to be language-agnostic.",2 Model,[0],[0]
"The loss function of the language classifier is formulated as:
La = − S∑
i=1
li log l̂i, (2)
where S is the number of sentences, li is the language of the i-th sentence, and l̂i is the softmax output of the tagging.",2 Model,[0],[0]
"Note that though the language classifier is optimized to minimize the language classification error, the gradient from the language classifier is negated so that the bottom layers are trained to be language-agnostic.
",2 Model,[0],[0]
"Bidirectional Language Modeling Rei (2017) showed the effectiveness of the bidirectional language modeling objective, where each time step of the forward LSTM outputs predicts the word of the next time step, and each of the backward LSTM outputs predicts the previous word.",2 Model,[0],[0]
"For example, if the current sentence is “I am happy”, the forward LSTM predicts “am happy <eos>” and the backward LSTM predicts “<bos> I am”.",2 Model,[0],[0]
"This objective encourages the BLSTM layers and the embedding layers to learn linguistically general-purpose representations, which are also useful for specific downstream tasks (Rei, 2017).",2 Model,[0],[0]
"We adopted the bidirectional language modeling objective, where the sum of the common BLSTM and the private BLSTM is used as the input to the language modeling module.",2 Model,[0],[0]
"It can be formulated as:
Ll = − S∑
i=1",2 Model,[0],[0]
N∑ j=1 log (P (wj+1|fj)),2 Model,[0],[0]
"+
log (P (wj−1|bj)) , (3)
where fj and bj represent the j-th outputs of the forward direction and the backward direction, respectively, given the output sum of the common BLSTM and the private BLSTM.
",2 Model,[0],[0]
"All the three loss functions are added to be optimized altogether as:
L = ws",2 Model,[0],[0]
"(Lp + λLa + λLl) , (4)
where λ is gradually increased from 0 to 1 as epoch increases so that the model is stably trained with auxiliary objectives (Ganin et al., 2016).",2 Model,[0],[0]
ws is used to give different weights to the source language and the target language.,2 Model,[0],[0]
"Since the source language has a larger train set and we are focusing on improving the performance of the target language, ws is set to 1 when training the target language.",2 Model,[0],[0]
"For the source language, instead, it is set as the size of the target train set divided by the size of the source train set.",2 Model,[0],[0]
"For the evaluation, we used the POS datasets from 14 different languages in Universal Dependencies corpus 1.4 (Nivre et al., 2016).",3 Experiments,[0],[0]
"We used English as the source language, which is with 12,543 training sentences.2",3 Experiments,[0],[0]
We chose datasets with 1k to 14k training sentences.,3 Experiments,[0],[0]
"The number of tag labels differs for each language from 15 to 18 though most of them are overlapped within the languages.
",3 Experiments,[0],[0]
"Table 1 shows the POS tagging accuracies of different transfer learning models when we limited the number of training sentences of the target languages to be the same as 1,280 for fair comparison among different languages.",3 Experiments,[0],[0]
The remainder training examples of the target languages are still used for both language-adversarial training and bidirectional language modeling since the objectives do not require tag labels.,3 Experiments,[0],[0]
Training with only the train sets in the target languages (c) showed 91.61% on average.,3 Experiments,[0],[0]
"When bidirectional language modeling objective is used (c, l), the accuracies were significantly increased to 92.82% on average.",3 Experiments,[0],[0]
"Therefore, we used the bidirectional language modeling for all the transfer learning evaluations.
",3 Experiments,[0],[0]
"With transfer learning, the three cases of using only the common BLSTM (c), using only the private BLSTMs (p), and using both (c, p) were evaluated.",3 Experiments,[0],[0]
"They showed better average accuracies than target only cases, but they showed mixed results.",3 Experiments,[0],[0]
"However, our proposed model (c, p, l + a), which utilizes both the common BLSTM with language-adversarial training and the private BLSTMs, showed the highest average score, 93.26%.",3 Experiments,[0],[0]
"For all the Germanic languages, where the source language also belongs to, the accuracies are significantly higher than those of
2The accuracies of English POS tagging are 94.01 and 94.33 for models without the bidirectional language modeling and with it, respectively.
",3 Experiments,[0],[0]
other transfer learning models.,3 Experiments,[0],[0]
"For the languages belonging to Slavic, Romance, or Indo-Iranian, our model shows competitive performance with the highest average accuracies among the compared models.",3 Experiments,[0],[0]
"Since languages in the same family are more likely to be similar and compatible, it is expected that the gain from the knowledge transfer to the languages in the same family to be higher than transferring to the languages in different families, which was shown in the results.",3 Experiments,[0],[0]
"This shows that utilizing both language-general representations that are encouraged to be more language-agnostic and language-specific representations effectively helps improve the POS tagging performance with transfer learning.
",3 Experiments,[0],[0]
Table 2 shows the results when using 320 taglabeled training sentences.,3 Experiments,[0],[0]
"In this case, transfer learning methods still show better accuracies than target-only approaches on average.",3 Experiments,[0],[0]
"However, the performance gain is weakened compared to using 1,280 labeled training sentences and there are some mixed results.",3 Experiments,[0],[0]
"In several cases, just utilizing private BLSTMs without the common BLSTM showed better accuracies than utilizing the common BLSTM.
",3 Experiments,[0],[0]
"When training with only 32 tag-labeled sentences, which is an extremely low-resourced setting, transfer learning methods still showed better accuracies than target-only methods on average.",3 Experiments,[0],[0]
"However, not using the common BLSTM
in transfer learning models showed better performance than using it on average.3",3 Experiments,[0],[0]
The main reason would be that we are not given a sufficient number of labeled training sentences to train both the common BLSTM and the private BLSTMs.,3 Experiments,[0],[0]
"In this case, just having private BLSTMs without the common BLSTM can show better performance.",3 Experiments,[0],[0]
"We also evaluated the opposite cases, which use all the tag-labeled training sentences in the target languages, and they showed mixed results.",3 Experiments,[0],[0]
"For example, the accuracy of German with the target only model is 93.31% while that of the proposed model is 93.04%.",3 Experiments,[0],[0]
"This is expected since transfer learning is effective when the target train set is small.
",3 Experiments,[0],[0]
An extension of this work is utilizing multiple languages as the source languages.,3 Experiments,[0],[0]
"Since we have four languages for each of Germanic, Slavic, and Romance language families, we evaluated the performance of those languages using the other languages in the same families as the source languages expecting that languages in the same language family are more likely to be helpful each other.",3 Experiments,[0],[0]
"For the efficiency, we performed multi-task learning for multiple languages rather than differentiating the targets from sources.",3 Experiments,[0],[0]
"When we tried to use 1,280, 320, and 32 tag-labeled training sentences for each language in the multi-source settings, the results showed noticeably better per-
3The results in detail are shown in the first authors dissertation Kim (2017).
formance than the results of using English as a single source language.",3 Experiments,[0],[0]
"Considering that utilizing 1,280*3=3,840, 320*3=960, or 32*3=96 tag labels from three other languages showed better results than using 12,543 English tag labels as the source, we can see that the knowledge transfer from multiple languages can be more helpful than that from single resource-rich source language.",3 Experiments,[0],[0]
"We also tried to use Wasserstein distance (Arjovsky et al., 2017) for the adversarial training in the multi-source settings, but there were no significant differences on average.4
Implementation Details All the models were optimized using ADAM (Kingma and Ba, 2015)5 with minibatch size 32 for total 100 epochs and we picked the parameters showing the best accuracy on the development set to report the score on the test set.",3 Experiments,[0],[0]
The dimensionalites of all the BLSTM related layers follow Plank et al. (2016)’s model.,3 Experiments,[0],[0]
Each word vector is 128 dimensional and each character vector is 100 dimensional.,3 Experiments,[0],[0]
"They are randomly initialized with Xavier initialization (Glorot and Bengio, 2010).",3 Experiments,[0],[0]
"For stable training, we use gradient clipping, where the threshold is set to 5.",3 Experiments,[0],[0]
"The dimensionality of each hidden output of LSTMs is 100, and the hidden outputs of both forward LSTM and backward LSTM are concatenated, thereby the output of each BLSTM for each time step is 200.",3 Experiments,[0],[0]
"Therefore, the input to the common BLSTM and the private BLSTM is 128+200=328
4The extended work in detail are shown in Kim (2017).",3 Experiments,[0],[0]
"5learning rate=0.001, β1 = 0.9, β2 = 0.999, = 1e− 8.
dimensional.",3 Experiments,[0],[0]
"The inputs and the outputs of the BLSTMs are regularized with dropout rate 0.5 (Pham et al., 2014).",3 Experiments,[0],[0]
"For the consistent dropout usages, we let the dropout masks to be identical for all the time steps of each sentence (Gal and Ghahramani, 2016).",3 Experiments,[0],[0]
"For all the BLSTMs, forget biases are initialized with 1 (Jozefowicz et al., 2015) and the other biases are initialized with 0.",3 Experiments,[0],[0]
"Each convolution filter output for the sentence encoding is 64 dimensional, and the three filter outputs are concatenated to represent each sentence with a 192 dimensional vector.",3 Experiments,[0],[0]
We introduced a cross-lingual transfer learning model for POS tagging which uses separate BLSTMs for language-general and languagespecific representations.,4 Conclusion,[0],[0]
"Evaluating on 14 different languages, including the source language improved tagging accuracies in almost all the cases.",4 Conclusion,[0],[0]
"Specifically, our model showed noticeably better performance when the source language and the target languages belong to the same language family, and competitively performed with the highest average accuracies for target languages in different families.",4 Conclusion,[0],[0]
We thank the anonymous reviewers for their helpful comments.,Acknowledgments,[0],[0]
All the experiments in this work were conducted with machines at Ohio Supercomputer Center (1987).,Acknowledgments,[0],[0]
Training a POS tagging model with crosslingual transfer learning usually requires linguistic knowledge and resources about the relation between the source language and the target language.,abstractText,[0],[0]
"In this paper, we introduce a cross-lingual transfer learning model for POS tagging without ancillary resources such as parallel corpora.",abstractText,[0],[0]
"The proposed cross-lingual model utilizes a common BLSTM that enables knowledge transfer from other languages, and private BLSTMs for language-specific representations.",abstractText,[0],[0]
The cross-lingual model is trained with language-adversarial training and bidirectional language modeling as auxiliary objectives to better represent language-general information while not losing the information about a specific target language.,abstractText,[0],[0]
"Evaluating on POS datasets from 14 languages in the Universal Dependencies corpus, we show that the proposed transfer learning model improves the POS tagging performance of the target languages without exploiting any linguistic knowledge between the source language and the target language.",abstractText,[0],[0]
Cross-Lingual Transfer Learning for POS Tagging without Cross-Lingual Resources,title,[0],[0]
"Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 998–1008, Baltimore, Maryland, USA, June 23-25 2014. c©2014 Association for Computational Linguistics",text,[0],[0]
"Discourse structure, logical flow of sentences, and context play a large part in ordering medical events based on temporal relations within a clinical narrative.",1 Introduction,[0],[0]
"However, cross-narrative temporal relation ordering is a challenging task as it is difficult to learn temporal relations among medical events which are not part of the logically coherent discourse of a single narrative.",1 Introduction,[0],[0]
"Resolving crossnarrative temporal relationships between medical events is essential to the task of generating an event timeline from across unstructured clinical narratives such as admission notes, radiology reports, history and physical reports and discharge summaries.",1 Introduction,[0],[0]
"Such a timeline has multiple applications in clinical trial recruitment (Luo et al., 2011), medical document summarization (Bramsen et al.,
2006, Reichert et al., 2010) and clinical decision making (Demner-Fushman et al., 2009).
",1 Introduction,[0],[0]
"Given multiple temporally ordered medical event sequences generated from each clinical narrative in a patient record, how can we combine the events to create a timeline across all the narratives?",1 Introduction,[0],[0]
"The tendency to copy-paste text and summarize past information in newly generated clinical narratives leads to multiple mentions of the same medical event across narratives (Cohen et al., 2013).",1 Introduction,[0],[0]
These cross-narrative coreferences act as important anchors for reasoning with information across narratives.,1 Introduction,[0],[0]
We leverage crossnarrative coreference information along with confident cross-narrative temporal relation predictions and learn to align and temporally order medical event sequences across longitudinal clinical narratives.,1 Introduction,[0],[0]
We model the problem as a sequence alignment task and propose solving this using two approaches.,1 Introduction,[0],[0]
"First, we use weighted finite state machines to represent medical events sequences, thus enabling composition and search to obtain the most probable combined sequence of medical events.",1 Introduction,[0],[0]
"As a contrast, we adapt dynamic programming algorithms (Needleman et al., 1970, Smith and Waterman, 1981) used to produce global and local alignments for aligning sequences of medical events across narratives.",1 Introduction,[0],[0]
"We also compare the proposed methods with an Integer Linear Programming (ILP) based method for timeline construction (Do et al., 2012).",1 Introduction,[0],[0]
"The cross-narrative coreference and temporal relation scores used in both these approaches are learned from a corpus of patient narratives from The Ohio State University Wexner Medical Center.
",1 Introduction,[0],[0]
The main contribution of this paper is a general framework that allows aligning multiple event sequences using cascaded weighted finite state transducers (WFSTs) with the help of efficient composition and decoding.,1 Introduction,[0],[0]
"Moreover, we demonstrate that this method can be used for more accurate multiple sequence alignment when compared to
998
dynamic programming or other ILP-based methods proposed in literature.",1 Introduction,[0],[0]
"In the areas of summarization and text-to-text generation, there has been prior work on several ordering strategies to order pieces of information extracted from different input documents (Barzilay et al., 2002, Lapata, 2003, Bollegala et al., 2010).",2 Related Work,[0],[0]
"In this paper, we focus on temporal ordering of information, as discussed next.
",2 Related Work,[0],[0]
"Recent state-of-the art research has focused on the problem of temporal relation learning within the same document, and in many cases within the same sentence (Mani et al., 2006, Verhagen et al., 2009, Lapata and Lascarides, 2011).",2 Related Work,[0],[0]
"Chambers and Jurafsky (2009) describe a process to induce a partially ordered set of events related by a common protagonist by using an unsupervised distributional method to learn relations between events sharing coreferring arguments, followed by temporal classification to induce partial order.",2 Related Work,[0],[0]
"The task was carried out on the Timebank newswire corpus, but was limited to an intra-document setting.",2 Related Work,[0],[0]
"More recently, (Do et al., 2012) proposed an ILP-based method to combine the outputs of an event-interval and an event-event classifier for timeline construction on the ACE 2005 corpus.",2 Related Work,[0],[0]
"However, this approach is also restricted to events within documents and requires annotations for event intervals.",2 Related Work,[0],[0]
We empirically compare our methods for timeline creation from longitudinal clinical narratives to such an ILP-based approach in Section 7.,2 Related Work,[0],[0]
"While a lot of this work has been done in the news domain, there is also some recent work in rule-based algorithms (Zhou et al., 2006) and machine learning (Roberts et al., 2008) applied to temporal relations between medical events in clinical text.",2 Related Work,[0],[0]
"Clinical narratives are written in a distinct sub-language with domain specific terminology and temporal characteristics, making them markedly different from newswire text.
",2 Related Work,[0],[0]
There is limited prior work in learning relations across documents.,2 Related Work,[0],[0]
"Ji and Grishman (2008) extended the one sense per discourse idea (Yarowsky, 1995) to multiple topically related documents and propagate consistent event arguments across sentences and documents.",2 Related Work,[0],[0]
Barzilay and McKeown (2005) propose a text-to-text generation technique for synthesizing common information across documents using sentence fusion.,2 Related Work,[0],[0]
"This involves multisequence dependency tree alignment to identify phrases conveying sim-
ilar information and statistical generation to combine common phrases into a sentence.",2 Related Work,[0],[0]
"Along with syntactic features, they combine knowledge from resources like WordNet to find similar sentences.",2 Related Work,[0],[0]
"In case of clinical narratives and medical event alignment, the objective is to identify a unique sequence of temporally ordered medical events from across longitudinal clinical data.
",2 Related Work,[0],[0]
"To the best of our knowledge, there is no prior work on cross-document alignment of event sequences.",2 Related Work,[0],[0]
"Multiple sequence alignment is a problem that arises in a variety of domains including gene/protein alignments in bioinformatics (Notredame, 2002), word alignments in machine translation (Kumar and Byrne, 2003), and sentence alignments for summarization (Lacatusu et al., 2004).",2 Related Work,[0],[0]
"Dynamic programming algorithms have been popularly leveraged to produce pairwise and global genetic alignments, where edit distance based metrics are used to compute the cost of insertions, deletions and substitutions.",2 Related Work,[0],[0]
"We use dynamic programming to compute the best alignment, given the temporal and coreference information between medical events across these sequences.",2 Related Work,[0],[0]
"More importantly, we propose a cascaded WFST-based framework for crossdocument temporal ordering of medical event sequences.",2 Related Work,[0],[0]
"Composition and search operations can be used to build a single transducer that integrates these components, directly mapping from input states to desired outputs, and obtain the best alignment (Mohri et al., 2000).",2 Related Work,[0],[0]
"In natural language processing, WFSTs have seen varied applications in machine translation (Kumar and Byrne, 2003), morphology (Sproat, 2006), named entity recognition (Krstev et al., 2011) and biological sequence alignment / generation (Whelan et al., 2010) among others.",2 Related Work,[0],[0]
We demonstrate that the WFST-based approach outperforms popularly used dynamic programming algorithms for multiple sequence alignment.,2 Related Work,[0],[0]
"Medical events are temporally-associated concepts in clinical text that describe a medical condition affecting the patient’s health, or procedures performed on a patient.",3 Problem Description,[0],[0]
We represent medical events by splitting each event into a start and a stop.,3 Problem Description,[0],[0]
"When there is insufficient information to discern the start or stop of an event, it is represented as a single concept.",3 Problem Description,[0],[0]
"If only the start is known then the stop is set to +∞, whereas when only the stop is known , the start is set to the date of birth of the
patient.1 Often, for chronic ailments like hypertension, we would only associate a start with the medical event and set the stop to +∞. The start of hypertension may be associated with the temporal expression history of in the narrative.",3 Problem Description,[0],[0]
"This, when considered along with the admission date, allows us to relatively order hypertension with respect to other medical events.",3 Problem Description,[0],[0]
"A medical event occurrence like chest pain may be associated with a start and a stop, where the start may be determined by the mention of “patient was complaining of chest pain yesterday” in the narrative text.",3 Problem Description,[0],[0]
"Further, the narrative may state that “he continued to have chest pain on admission, but currently he is chest pain free”; this may be used to infer the relative stop of chest pain.",3 Problem Description,[0],[0]
"Medical events may also be instantaneous, for e.g., injected with antibiotic.",3 Problem Description,[0],[0]
Such events are represented with the start and stop as being the same.,3 Problem Description,[0],[0]
Temporal relations exist between the start and stop of events as shown in Figure 1.,3 Problem Description,[0],[0]
"Learning temporal relations before, after and simultaneous between the medical event starts and stops corresponds to learning all of Allen’s temporal relations (Allen, 1981) between the medical events.",3 Problem Description,[0],[0]
"Following our previous work (Raghavan et al., 2012c), such a representation allows us to temporally order the event starts and stops within each clinical narrative by learning to rank them in relative order of time.",3 Problem Description,[0],[0]
"The problem definition is as follows:
1Patient date of birth, admission/ discharge date are usually available in the metadata associated with a clinical narrative.
",3 Problem Description,[0],[0]
Input: Sequences of temporally ordered medical event starts and stops.,3 Problem Description,[0],[0]
"This corresponds to N1, N2, and N3 in Figure 2.",3 Problem Description,[0],[0]
Each sequence corresponds to a clinical narrative.,3 Problem Description,[0],[0]
"The total number of sequences correspond to the number of clinical narratives for a patient.
",3 Problem Description,[0],[0]
Problem:,3 Problem Description,[0],[0]
"Combine medical events across these sequences to generate a timeline i.e., a single comprehensive sequence of medical events over all clinical narratives of the patient.
",3 Problem Description,[0],[0]
Expected Output:,3 Problem Description,[0],[0]
"In the example shown in Figure 2, the output would be as follows:",3 Problem Description,[0],[0]
"Timeline (N1, N2, N3)= {cocaine usestart < hypertensionstart = hypertensionstart < admission1 < chest painstart ∼ palpitationsstart < chest painstop < heart attackstart = myocardial infarctionstart <",3 Problem Description,[0],[0]
"admission2 < infectionstart < MRSAstart < admission3 < woundsstart}.
",3 Problem Description,[0],[0]
The goal of multiple sequence alignment is to find an alignment that maximizes some overall alignment score.,3 Problem Description,[0],[0]
"Thus, in order to align event sequences, we need to compute scores corresponding to cross-narrative medical event coreference resolution and cross-narrative temporal relations.",3 Problem Description,[0],[0]
"The first approach to learning a temporal ordering of medical events across all clinical narratives is to consider all pairs of events across all narratives and learn to classify them as sharing one of Allen’s temporal relations (Allen, 1981) using a single learning model.",4 Cross-Narrative Coreference Resolution and Temporal Relation Learning,[0],[0]
"Alternatively, a ranking ap-
proach, similar to the one used to generate intranarrative temporal ordering, can also be extended to the cross-narrative case.",4 Cross-Narrative Coreference Resolution and Temporal Relation Learning,[0],[0]
"However, the features related to narrative structure and relative and implicit temporal expressions used for temporal ordering within a clinical narrative may not be applicable across narratives.",4 Cross-Narrative Coreference Resolution and Temporal Relation Learning,[0],[0]
"For instance, a history and physical report may have sections like “past medical history”, “history of present illness”, “assessment and plan”, and a certain logical pattern to the flow of text within and across these sections.",4 Cross-Narrative Coreference Resolution and Temporal Relation Learning,[0],[0]
"Further, temporal cues like “thereafter”, “subsequently”, follow from the context around an event mention.",4 Cross-Narrative Coreference Resolution and Temporal Relation Learning,[0],[0]
"The absence of such features in the cross-narrative case does not allow such a model to generate accurate temporal relation predictions.
",4 Cross-Narrative Coreference Resolution and Temporal Relation Learning,[0],[0]
"Thus, for use in our sequence alignment models, we learn two independent classifiers for medical event coreference and temporal relation learning across narratives.",4 Cross-Narrative Coreference Resolution and Temporal Relation Learning,[0],[0]
We train a classifier to resolve cross-narrative coreferences by extracting semantic and temporal relatedness feature sets for each pair of medical concepts.,4 Cross-Narrative Coreference Resolution and Temporal Relation Learning,[0],[0]
"Extracting these feature sets helps us train a classifier to predict medical event coreferences (Raghavan et al., 2012a).",4 Cross-Narrative Coreference Resolution and Temporal Relation Learning,[0],[0]
"Another classifier is then trained to classify pairs of medical event starts and stops across narratives as sharing temporal relations {before, after, overlaps}.",4 Cross-Narrative Coreference Resolution and Temporal Relation Learning,[0],[0]
The learned cross-narrative coreference predictions can then be used along with confident temporal relation predictions to derive a joint probability to enable cross-narrative temporal ordering.,4 Cross-Narrative Coreference Resolution and Temporal Relation Learning,[0],[0]
Sequence alignment algorithms have been developed and popularly used in bioinformatics.,5 Narrative Sequence Alignment for Cross-narrative Temporal Ordering,[0],[0]
"However, multiple sequence alignment (MSA) has been shown to be NP complete (Wang and Jiang, 1994) and various heuristic algorithms have been proposed to solve this problem (Notredame, 2002).",5 Narrative Sequence Alignment for Cross-narrative Temporal Ordering,[0],[0]
"We propose a novel WFST-based representation that enables accurate decoding for MSA when compared to popularly used dynamic programming algorithms (Needleman et al., 1970, Smith and Waterman, 1981) or other state of the art methods (Do et al., 2012).
",5 Narrative Sequence Alignment for Cross-narrative Temporal Ordering,[0],[0]
"In the problem of aligning events across multiple narrative sequences, we want to align temporally ordered medical events corresponding to clinical narratives of a patient.",5 Narrative Sequence Alignment for Cross-narrative Temporal Ordering,[0],[0]
"Unlike problems in biological sequence alignment where the sym-
bols to be aligned across sequences are restricted to a fixed set, our symbol set is not fixed or certain because the symbols correspond to medical events in clinical narratives.",5 Narrative Sequence Alignment for Cross-narrative Temporal Ordering,[0],[0]
"Moreover, we cannot have fixed scores for symbol transformations since our transformations correspond to coreference and temporal relations between the medical events across sequences.",5 Narrative Sequence Alignment for Cross-narrative Temporal Ordering,[0],[0]
The computation of these scores is described next.,5 Narrative Sequence Alignment for Cross-narrative Temporal Ordering,[0],[0]
"Let us assume a, b are medical events in the first clinical narrative and have been temporally ordered so a < b.",5.1 Scoring Scheme,[0],[0]
"Similarly, x, y are medical events in the second clinical narrative such that x",5.1 Scoring Scheme,[0],[0]
< y.,5.1 Scoring Scheme,[0],[0]
"There exists a match or an alignment between a pair of medical events, across the sequences, in the following cases:
1.",5.1 Scoring Scheme,[0],[0]
"If the medical events are simultaneous and coreferring, denoted as a = x.
2.",5.1 Scoring Scheme,[0],[0]
"If the medical events are simultaneous and non-coreferring, denoted as a ∼ x.
3.",5.1 Scoring Scheme,[0],[0]
"If the a medical event from one sequence is before a medical event from another sequence, denoted as a < x.
4.",5.1 Scoring Scheme,[0],[0]
"If the a medical event from one sequence is after a medical event from another sequence, denoted as a > x.
We now illustrate how the scores for candidate aligned sequences are computed using the learned cross-narrative coreference and temporal probabilities for the following three scenarios:
• The medical events across sequences are simultaneous and corefer as illustrated in Figure 3.",5.1 Scoring Scheme,[0],[0]
"The joint score considers the probability of event temporal relations simultaneous conditioned on coreference.
",5.1 Scoring Scheme,[0],[0]
•,5.1 Scoring Scheme,[0],[0]
Some medical events across sequences are simultaneous but do not corefer as illustrated in Figure 4.,5.1 Scoring Scheme,[0],[0]
"Here, the joint score considers the joint probability of temporal relations simultaneous or before and no-coreference.
",5.1 Scoring Scheme,[0],[0]
•,5.1 Scoring Scheme,[0],[0]
The medical events across sequences are not simultaneous and do not corefer as illustrated in Figure 5.,5.1 Scoring Scheme,[0],[0]
"In this case, the joint score considers the probability of the temporal relation before and no coreference.
",5.1 Scoring Scheme,[0],[0]
"Thus, the coreference and temporal relation scores can be leveraged for aligning sequences of medical events.",5.1 Scoring Scheme,[0],[0]
"These scores are used in both the WFSTbased representation and decoding, as well as for dynamic programming.",5.1 Scoring Scheme,[0],[0]
"A weighted finite-state transducer (WFST) is an automaton in which each transition between states
is associated with an input symbol, an output symbol, and a weight (Mohri et al., 2005).",5.2 Alignment using a Weighted Finite State Representation,[0],[0]
WFSTs can be used to efficiently represent and combine sequences of medical events based coreference and temporal relation information.,5.2 Alignment using a Weighted Finite State Representation,[0],[0]
The WFST representation gives us the ability to talk about the global joint probability derived from coreference and temporal relation scores described in Section 5.1.,5.2 Alignment using a Weighted Finite State Representation,[0],[0]
It allows us to build a weighted lattice of sequences that can be searched for the most probable sequence of medical events from across all clinical narratives of a patient.,5.2 Alignment using a Weighted Finite State Representation,[0],[0]
"We use unweighted FSAs to represent the input described in Section 3, i.e. temporally ordered sequences of medical events corresponding to clinical narratives.",5.2 Alignment using a Weighted Finite State Representation,[0],[0]
"This corresponds to N1 and N2 in Figure 6.
",5.2 Alignment using a Weighted Finite State Representation,[0],[0]
"Based on whether we want to align the sequences purely based on coreference scores or both coreference and temporal relation scores, the arc weights for the WFST can be determined.",5.2 Alignment using a Weighted Finite State Representation,[0],[0]
M c12 is a WFST that maps input symbols from N1 to output symbols inN2 and is weighted by the probability of coreference or no-coreference between medical events across N1 and N2.,5.2 Alignment using a Weighted Finite State Representation,[0],[0]
The representation in WFST M c+t12 shown in Figure 7 allows us to align N1 and N2 based on both coreference as well as temporal relation probabilities.,5.2 Alignment using a Weighted Finite State Representation,[0],[0]
The WFST has transitions to accommodate insertion and deletion of medical events when combining the sequences.,5.2 Alignment using a Weighted Finite State Representation,[0],[0]
Deletions correspond to the case when an event in the first sequence does not map to any event in the second sequence; similarly insertions correspond to the case where an event in the second sequence does not map to any event in the first sequence.,5.2 Alignment using a Weighted Finite State Representation,[0],[0]
The WFST composition operation allows the outputs of one WFST to be fed to the inputs of a second WFST or FSA.,5.2 Alignment using a Weighted Finite State Representation,[0],[0]
"Thus, we build our final machine by composing the three sub-machines as,
D = N1 ◦M i12 ◦N2.",5.2 Alignment using a Weighted Finite State Representation,[0],[0]
(1) where i = c or i = c + t.,5.2 Alignment using a Weighted Finite State Representation,[0],[0]
This gives us a combined weighted graph by mapping the output symbols of the first medical event sequence to the input symbols of the second medical event sequence.,5.2 Alignment using a Weighted Finite State Representation,[0],[0]
"The scores on the decoding graph are derived from only the coreference probabilities if i = c and both coreference and temporal relation probabilities if i = c+ t.
In the medical event sequence alignment problem, we want to align multiple sequences of medical events that correspond to multiple clinical narratives of a patient.",5.2 Alignment using a Weighted Finite State Representation,[0],[0]
"Since we want to now combine
all narrative chains belonging to the same patient, the composition cascade to build the final combined sequence will be as,
Df = N1◦M i12◦N2◦M i23◦N3◦M i34...◦",5.2 Alignment using a Weighted Finite State Representation,[0],[0]
"Nn (2)
where i = c",5.2 Alignment using a Weighted Finite State Representation,[0],[0]
or i = c + t and n is the number of medical event sequences corresponding to clinical narratives for a patient.,5.2 Alignment using a Weighted Finite State Representation,[0],[0]
"During composition we retain intermediate paths like M i23 utilizing the ability to do lazy composition (Mohri and Pereira, 1998) in order to facilitate beam search through the multi-alignment.",5.2 Alignment using a Weighted Finite State Representation,[0],[0]
The best hypothesis corresponds to the highest scoring path which can be obtained using shortest path algorithms like Djikstra’s algorithm.,5.2 Alignment using a Weighted Finite State Representation,[0],[0]
"The best path corresponds to the best alignment across all medical event sequences based on the joint probability of cross-narrative medical event coreferences and temporal relations across the narrative sequences.
",5.2 Alignment using a Weighted Finite State Representation,[0],[0]
"The complexity of decoding increases exponentially with the number of narrative sequences in
the composition, and exact decoding becomes infeasible.",5.2 Alignment using a Weighted Finite State Representation,[0],[0]
"One solution to this problem is to do the alignment greedily pairwise, starting from the most recent medical event sequences, finding the best path, and iteratively moving on to the next sequence, and proceeding until the oldest medical event sequence.",5.2 Alignment using a Weighted Finite State Representation,[0],[0]
"The disadvantage of such a method is that it does not take into account constraints between medical events across multiple event sequences and may lead to a less accurate solution.
",5.2 Alignment using a Weighted Finite State Representation,[0],[0]
An alternative method is to use lazy composition to perform more efficient composition as it allows practical memory usage.,5.2 Alignment using a Weighted Finite State Representation,[0],[0]
"We also use beam search to make for an efficient approximation to the best-path computation (Mohri et al., 2005).",5.2 Alignment using a Weighted Finite State Representation,[0],[0]
This allows accommodating constraints from across multiple sequences and generates a more accurate best path.,5.2 Alignment using a Weighted Finite State Representation,[0],[0]
"Thus, this method generates more accurate alignments when we have more than two sequences to be aligned.
",5.2 Alignment using a Weighted Finite State Representation,[0],[0]
"For instance, instance say a, b ∈ N1, x, y ∈ N2, and m,",5.2 Alignment using a Weighted Finite State Representation,[0],[0]
"n ∈ N3 are temporally medical event sequences corresponding to narratives N1, N2 and N3.",5.2 Alignment using a Weighted Finite State Representation,[0],[0]
"Based on the learned pairwise temporal relations, if we have the following constraints a < x, m > x, m < a.",5.2 Alignment using a Weighted Finite State Representation,[0],[0]
"Aligning N1 and N2 greedily pairwise may give us the best combined sequence as a, x, b, y ∈ N12.",5.2 Alignment using a Weighted Finite State Representation,[0],[0]
"Now in aligning N12 with N3, we won’t be able to accommodate m > x",5.2 Alignment using a Weighted Finite State Representation,[0],[0]
and m < a.,5.2 Alignment using a Weighted Finite State Representation,[0],[0]
"However, performing a beam search over the composed WFST in equation 2 allows us to accommodate such constraints across multiple sequences.",5.2 Alignment using a Weighted Finite State Representation,[0],[0]
"The complexity of composing two transducers is O(V1V2D1(logD2 + M2)) where each edge from the first sequence matches every edge in the second sequence and Vi is the number of states, Di is the maximum out-degree and Mi maximum multiplicity for the ith FST (Mohri et al., 2005).
",5.2 Alignment using a Weighted Finite State Representation,[0],[0]
"We also use popular dynamic programming algorithms (Needleman et al., 1970, Smith and Waterman, 1981) for sequence alignment of medical events across narratives and compare it to the WFST-based representation and decoding.",5.2 Alignment using a Weighted Finite State Representation,[0],[0]
"As a contrast, we adapt two dynamic programming algorithms for sequence alignment: global alignment using the Needleman Wunsch algorithm (NW) (Needleman et al., 1970) and local alignment using the Smith-Waterman algorithm (SW) (Smith and Waterman, 1981).",5.3 Pairwise Alignment using Dynamic Programming,[0],[0]
NW allows us to align all events in one sequence with all events in another sequence.,5.3 Pairwise Alignment using Dynamic Programming,[0],[0]
A drawback of NW is that short and highly similar sequences maybe missed because they get overweighted by the rest of the sequence.,5.3 Pairwise Alignment using Dynamic Programming,[0],[0]
NW is suitable when the two sequences are of similar length with significant degree of similarity throughout.,5.3 Pairwise Alignment using Dynamic Programming,[0],[0]
"On the other hand, SW gives the longest sub-sequence pair that yields maximum degree of similarity between the two original sequences.",5.3 Pairwise Alignment using Dynamic Programming,[0],[0]
It does not force all events in a sequence to align with another sequence.,5.3 Pairwise Alignment using Dynamic Programming,[0],[0]
SW is useful in aligning sequences that differ in length and have short patches of similarity.,5.3 Pairwise Alignment using Dynamic Programming,[0],[0]
"The time complexity of these methods for sequences of length m and n are O(mn).
",5.3 Pairwise Alignment using Dynamic Programming,[0],[0]
The scoring scheme described earlier is used to update the scoring matrix for dynamic programming.,5.3 Pairwise Alignment using Dynamic Programming,[0],[0]
"In order to accommodate the temporal relations before and after, we insert a null symbol after every medical event in each sequence in the scoring matrix.",5.3 Pairwise Alignment using Dynamic Programming,[0],[0]
"A vertical or horizontal gap arises when cases 1, 2, 3 and 4 in Section 5.1 mentioned
above are not true.",5.3 Pairwise Alignment using Dynamic Programming,[0],[0]
"If the medical events are not simultaneous, not before or not after, the medical events will not align.",5.3 Pairwise Alignment using Dynamic Programming,[0],[0]
"Thus, the value of each cell in the scoring matrix is determined by computing the maximum score at each position C(i, j) as,
max{(C(i−1, j−1)+Sij), (C(i, j−1)+w), (C(i− 1, j) + w)} (3)
where, Sij = max{P (i = j), P (i < j), P (i > j)}, and w = max{(1",5.3 Pairwise Alignment using Dynamic Programming,[0],[0]
"− P (i = j)), (1 − P (i < j)), (1 − P (i > j))}.",5.3 Pairwise Alignment using Dynamic Programming,[0],[0]
"Here, C(i − 1, j − 1) corresponds to a match, whereas C(i, j − 1) and C(i − 1, j) correspond to a gaps in sequence one and two.
",5.3 Pairwise Alignment using Dynamic Programming,[0],[0]
"In case of the SW algorithm, the negative scoring matrix cells are set to zero, thus making the positively scoring local alignments visible.",5.3 Pairwise Alignment using Dynamic Programming,[0],[0]
"Backtracking starts at the highest scoring matrix cell and proceeds until a cell with score zero is encountered, yielding the highest scoring local alignment.
",5.3 Pairwise Alignment using Dynamic Programming,[0],[0]
The time and space complexity grows exponentially with the number of sequences to be aligned and finding the global optimum has been shown to be a NP-complete problem.,5.3 Pairwise Alignment using Dynamic Programming,[0],[0]
"The time complexity of aligning N sequences of length L is O(2NLN ) (Wang and Jiang, 1994).",5.3 Pairwise Alignment using Dynamic Programming,[0],[0]
"Thus, for MSA using dynamic programming, we use a heuristic method where we combine pairwise alignments iteratively starting with the latest narrative and progressing towards the oldest narrative.",5.3 Pairwise Alignment using Dynamic Programming,[0],[0]
Corpus Description.,6 Experiments and Evaluation,[0],[0]
The corpus consists of a dataset of clinical narratives obtained from the [redacted] medical center.,6 Experiments and Evaluation,[0],[0]
"The corpus has a total of 2060 patients, and 100704 clinical narratives.",6 Experiments and Evaluation,[0],[0]
"We gathered a gold standard set of seven patients (80 clinical narratives overall) with manual annotation of all medical events mentioned in the narratives, coreferences, and medical event sequence information.",6 Experiments and Evaluation,[0],[0]
"The annotation agreement across annotators is high, with 89.5% agreement corresponding to inter-annotator Cohen’s kappa statistic of 0.86 (Raghavan et al., 2012b).",6 Experiments and Evaluation,[0],[0]
"The types of clinical narratives included 27 discharge summaries, 30 history and physical reports, 15 radiology reports and 8 pathology reports.",6 Experiments and Evaluation,[0],[0]
The distribution of the number of medical event sequences and unique medical events across patients is shown in Table 1.,6 Experiments and Evaluation,[0],[0]
"The annotated dataset is used to crossvalidate and train our coreference and temporal relation learning models and to evaluate our crossnarrative medical event timeline.
",6 Experiments and Evaluation,[0],[0]
Evaluation Metric.,6 Experiments and Evaluation,[0],[0]
"For each patient and each method (WFST or dynamic programming), the output timeline to evaluate is the highest scoring candidate hypothesis derived as described above.",6 Experiments and Evaluation,[0],[0]
Accuracy of the timeline is calculated as the number of transformations required to obtain the reference sequence in the annotated gold-standard from the one generated by our system.,6 Experiments and Evaluation,[0],[0]
"Transformations are measured in terms of the minimum edit distance, insertions, deletions, and substitutions of medical events.
",6 Experiments and Evaluation,[0],[0]
Experiments and Results.,6 Experiments and Evaluation,[0],[0]
"We first temporally order medical events within each clinical narrative by learning to rank them in relative order of occurence as described in our previous work (Raghavan et al., 2012c).",6 Experiments and Evaluation,[0],[0]
The overall accuracy of ranking medical events using leave-one-out cross validation is 82.1%.,6 Experiments and Evaluation,[0],[0]
"The resulting medical event sequences serve as the input to the problem of crossnarrative sequence alignment.
",6 Experiments and Evaluation,[0],[0]
The cross-narrative coreference and temporal relation pairwise classification models described in Section 4 are trained using a Maximum entropy classifier.,6 Experiments and Evaluation,[0],[0]
The coreference resolution performs with 71.5% precision and 82.3% recall.,6 Experiments and Evaluation,[0],[0]
The temporal relation classifier performs with 60.2% precision and 76.3% recall.,6 Experiments and Evaluation,[0],[0]
"The learned pairwise coreference and temporal relation probabilities are now used to derive the score for the WFST and dynamic programming approaches.
WFST representation and decoding.",6 Experiments and Evaluation,[0],[0]
We build finite-state machines using the open source OpenFST,6 Experiments and Evaluation,[0],[0]
library.2,6 Experiments and Evaluation,[0],[0]
We use a tropical semi-ring weighted using the negative log-likelihood of the computed scores.,6 Experiments and Evaluation,[0],[0]
"OpenFST provides tools that can search for the highest scoring sequences accepted by the machine, and can sample from highscoring sequences probabilistically, by treating the
2www.openfst.org
scores of each transition within the machine as a negative log probability.",6 Experiments and Evaluation,[0],[0]
The decoding process to compute the most likely combined medical event sequence can be defined as searching for the best path in the combined graph representation (Equation 2).,6 Experiments and Evaluation,[0],[0]
The best path is the one that minimizes the total weight on a path (since the arcs are negative log probabilities).,6 Experiments and Evaluation,[0],[0]
"In searching for the best path, the beam size is set to 5.",6 Experiments and Evaluation,[0],[0]
"The accuracy of the WFST-based representation and beam search across all sequences using the coreference and temporal relation scores to obtain the combined aligned sequence is 78.9%.
",6 Experiments and Evaluation,[0],[0]
Dynamic Programming.,6 Experiments and Evaluation,[0],[0]
We use the NW and SW algorithms described in Section 5.3 to produce local and global alignments respectively.,6 Experiments and Evaluation,[0],[0]
We use the scoring scheme described in Section 5.1 to update the cost matrix for dynamic programming and implement the algorithms as described in Section 5.3.,6 Experiments and Evaluation,[0],[0]
The overall accuracy of sequence alignment with both coreference and temporal relation scores using NW is 68.7% whereas SW gives an accuracy of 72.1%.,6 Experiments and Evaluation,[0],[0]
"In case of aligning just two sequences, both methods yield the same results.",6 Experiments and Evaluation,[0],[0]
"The accuracy of cross-narrative MSA for each patient, for each method, using cross validation, is shown in Table 1.",6 Experiments and Evaluation,[0],[0]
Results indicate that the WFSTbased method outperforms the dynamic programming approach for multi-sequence alignment (statistical significance p<0.05).,6 Experiments and Evaluation,[0],[0]
"Morever, the results using both coreference and temporal realtion scores for alignment outperform using only coreference scores for alignment using all approaches.",6 Experiments and Evaluation,[0],[0]
This indicates that cross-narrative temporal relations are important for accurately aligning medical event sequences across narratives.,6 Experiments and Evaluation,[0],[0]
"We propose and evaluate different approaches to multiple sequence alignment of medical events.
",7 Discussion,[0],[0]
Approaches to multi-alignment.,7 Discussion,[0],[0]
We address the problem of aligning medical event sequences using a novel WFST-based framework and empirically demonstrate that it outperforms pairwise progressive alignment using dynamic programming.,7 Discussion,[0],[0]
"This is mainly because the WFST-based allows us to consider temporal constraints from across multiple sequences when performing the alignment.
",7 Discussion,[0],[0]
"Moreover, it also outperforms the integer linear programming (ILP) method for timeline construction proposed in (Do et al., 2012).",7 Discussion,[0],[0]
We implemented the proposed method that also allows combining the output of classifiers subject to some constraints.,7 Discussion,[0],[0]
We derive intervals from event starts and stops and learn two perceptron classifiers for classifying the temporal relations between events and assigning events to intervals.,7 Discussion,[0],[0]
The classifier probabilities are then used to solve the optimization problem using the lpsolve solver.3,7 Discussion,[0],[0]
We also use intra-document coreference information to resolve coreference before performing the global optimization.,7 Discussion,[0],[0]
"We observe that in case of MSA, the optimal solution using ILP is still intractable as the number of constraints increases exponentially with the number of sequences.",7 Discussion,[0],[0]
Aligning pairwise iteratively gives us an overall average accuracy of 68.2% similar to dynamic programming.,7 Discussion,[0],[0]
"While this is comparable to the dynamic programming performance, the WFST-based method significantly outperforms this in case of multialignments for cross-narrative temporal ordering.
",7 Discussion,[0],[0]
Performance and error analysis.,7 Discussion,[0],[0]
"We perform multi-alignments over medical event sequences for a patient, where each sequence corresponds to temporally ordered medical events in a clinical narrative generated using the ranking model described in (Raghavan et al., 2012c).",7 Discussion,[0],[0]
The accuracy of intra-narrative temporal ordering is 82.1%.,7 Discussion,[0],[0]
The errors in performing this intra-narrative ordering may propagate to the cross-narrative model resulting in reduced accuracy.,7 Discussion,[0],[0]
"This may be addressed by considering n-best temporally ordered medical event sequences, generated by the ranking process, and aligning the n-best sequences using the WFST-based framework.",7 Discussion,[0],[0]
"This could be feasible as, practically, the WFST-based method for multialignment takes only a few secs to align a pair of medical event sequences with average length 40.
",7 Discussion,[0],[0]
The accuracy of alignments across multiple medical event sequences is also affected by the error induced by the coreference and temporal relation scores.,7 Discussion,[0],[0]
"Often, insufficient temporal cues leads
3http://lpsolve.sourceforge.net/5.5/
to misclassification of events incorrectly as sharing the “simultaneous” temporal relation and often as coreferring.",7 Discussion,[0],[0]
This induces errors in the score calculation and hence the alignments.,7 Discussion,[0],[0]
"Better methods to address the challenging problem of crossdocument temporal relation learning, perhaps with the help of structured data from the patient record, could improve the accuracy of alignments.
",7 Discussion,[0],[0]
"There is no clear trend with respect to the number of medical events and narratives for a patient (Table 1.), and the alignment accuracy.",7 Discussion,[0],[0]
"In future work, it would be interesting to examine any such correlation and also study the scalability of the WFST-based method for sequence alignment on longer medical event sequences and a larger dataset of patients.",7 Discussion,[0],[0]
"Further, the WFST-based method may be used to model multi-alignment tasks in other speech and language problems as well.",7 Discussion,[0],[0]
We propose a novel framework for aligning medical event sequences across clinical narratives based on coreference and temporal relation information using cascaded WFSTs.,8 Conclusion,[0],[0]
FSTs provide a convenient and flexible framework to model sequences of temporally ordered medical events and compose them into a combined graph representation.,8 Conclusion,[0],[0]
Decoding this graph allows us to jointly maximize coreference as well as temporal relation probabilities to derive a timeline of the most likely temporal ordering of medical events.,8 Conclusion,[0],[0]
This approach to aligning multiple sequences of medical events significantly outperforms other approaches such as dynamic programming.,8 Conclusion,[0],[0]
"Moreover, we demonstrate the importance of learning temporal relations for the task timeline generation from across multiple clinical narratives by empirically proving that decoding using both coreference and temporal relation scores is far more accurate than decoding with only coreference scores.",8 Conclusion,[0],[0]
The project was supported by Award Number Grant R01LM011116 from the National Library of Medicine.,Acknowledgments,[0],[0]
The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Library of Medicine or the National Institutes of Health.,Acknowledgments,[0],[0]
The authors would like to thank Yanzhang He for his input on the WFST-based model.,Acknowledgments,[0],[0]
Cross-narrative temporal ordering of medical events is essential to the task of generating a comprehensive timeline over a patient’s history.,abstractText,[0],[0]
"We address the problem of aligning multiple medical event sequences, corresponding to different clinical narratives, comparing the following approaches: (1) A novel weighted finite state transducer representation of medical event sequences that enables composition and search for decoding, and (2) Dynamic programming with iterative pairwise alignment of multiple sequences using global and local alignment algorithms.",abstractText,[0],[0]
The cross-narrative coreference and temporal relation weights used in both these approaches are learned from a corpus of clinical narratives.,abstractText,[0],[0]
We present results using both approaches and observe that the finite state transducer approach performs performs significantly better than the dynamic programming one by 6.8% for the problem of multiple-sequence alignment.,abstractText,[0],[0]
Cross-narrative temporal ordering of medical events,title,[0],[0]
Relation extraction has made great strides in newswire and Web domains.,1 Introduction,[0],[0]
"Recently, there has
∗",1 Introduction,[0],[0]
"This research was conducted when the authors were at Microsoft Research.
been increasing interest in applying relation extraction to high-value domains such as biomedicine.",1 Introduction,[0],[0]
"The advent of $1000 human genome1 heralds the dawn of precision medicine, but progress in personalized cancer treatment has been hindered by the arduous task of interpreting genomic data using prior knowledge.",1 Introduction,[0],[0]
"For example, given a tumor sequence, a molecular tumor board needs to determine which genes and mutations are important, and what drugs are available to treat them.",1 Introduction,[0],[0]
"Already the research literature has a wealth of relevant knowledge, and it is growing at an astonishing rate.",1 Introduction,[0],[0]
"PubMed2, the online repository of biomedical articles, adds two new papers per minute, or one million each year.",1 Introduction,[0],[0]
"It is thus imperative to advance relation extraction for machine reading.
",1 Introduction,[0],[0]
"In the vast literature on relation extraction, past work focused primarily on binary relations in single sentences, limiting the available information.",1 Introduction,[0],[0]
"Consider the following example: “The deletion mutation on exon-19 of EGFR gene was present in 16 patients, while the L858E point mutation on exon-21 was noted in 10.",1 Introduction,[0],[0]
All patients were treated with gefitinib and showed a partial response.”.,1 Introduction,[0],[0]
"Collectively, the two sentences convey the fact that there is a ternary interaction between the three entities in bold, which is not expressed in either sentence alone.",1 Introduction,[0],[0]
"Namely, tumors with L858E mutation in EGFR gene can be treated with gefitinib.",1 Introduction,[0],[0]
Extracting such knowledge clearly requires moving beyond binary relations and single sentences.,1 Introduction,[0],[0]
N -ary relations and cross-sentence extraction have received relatively little attention in the past.,1 Introduction,[0],[0]
"Prior
1http://www.illumina.com/systems/ hiseq-x-sequencing-system.html
2https://www.ncbi.nlm.nih.gov/pubmed
ar X
iv :1
70 8.
03 74
3v 1
[ cs
.C",1 Introduction,[0],[0]
"L
] 1
2 A
ug 2
work on n-ary relation extraction focused on single sentences (Palmer et al., 2005; McDonald et al., 2005) or entity-centric attributes that can be extracted largely independently (Chinchor, 1998; Surdeanu and Heng, 2014).",1 Introduction,[0],[0]
"Prior work on cross-sentence extraction often used coreference to gain access to arguments in a different sentence (Gerber and Chai, 2010; Yoshikawa et al., 2011), without truly modeling inter-sentential relational patterns.",1 Introduction,[0],[0]
(See Section 7 for a more detailed discussion.),1 Introduction,[0],[0]
"A notable exception is Quirk and Poon (2017), which applied distant supervision to general cross-sentence relation extraction, but was limited to binary relations.
",1 Introduction,[0],[0]
"In this paper, we explore a general framework for cross-sentence n-ary relation extraction, based on graph long short-term memory networks (graph LSTMs).",1 Introduction,[0],[0]
"By adopting the graph formulation, our framework subsumes prior approaches based on chain or tree LSTMs, and can incorporate a rich set of linguistic analyses to aid relation extraction.",1 Introduction,[0],[0]
"Relation classification takes as input the entity representations learned from the entire text, and can be easily extended for arbitrary relation arity n. This approach also facilitates joint learning with kindred relations where the supervision signal is more abundant.
",1 Introduction,[0],[0]
We conducted extensive experiments on two important domains in precision medicine.,1 Introduction,[0],[0]
"In both distant supervision and supervised learning settings, graph LSTMs that encode rich linguistic knowledge outperformed other neural network variants, as well as a well-engineered feature-based classifier.",1 Introduction,[0],[0]
Multitask learning with sub-relations led to further improvement.,1 Introduction,[0],[0]
"Syntactic analysis conferred a significant benefit to the performance of graph LSTMs, especially when syntax accuracy was high.
",1 Introduction,[0],[0]
"In the molecular tumor board domain, PubMedscale extraction using distant supervision from a
small set of known interactions produced orders of magnitude more knowledge, and cross-sentence extraction tripled the yield compared to single-sentence extraction.",1 Introduction,[0],[0]
Manual evaluation verified that the accuracy is high despite the lack of annotated examples.,1 Introduction,[0],[0]
"Let e1, · · · , em be entity mentions in text T .",2 Cross-sentence n-ary relation extraction,[0],[0]
"Relation extraction can be formulated as a classification problem of determining whether a relation R holds for e1, · · · , em in T .",2 Cross-sentence n-ary relation extraction,[0],[0]
"For example, given a cancer patient with mutation v in gene g, a molecular tumor board seeks to find if this type of cancer would respond to drug d. Literature with such knowledge has been growing rapidly; we can help the tumor board by checking if the Respond relation holds for the (d, g, v) triple.
",2 Cross-sentence n-ary relation extraction,[0],[0]
"Traditional relation extraction methods focus on binary relations where all entities occur in the same sentence (i.e., m = 2 and T is a sentence), and cannot handle the aforementioned ternary relations.",2 Cross-sentence n-ary relation extraction,[0],[0]
"Moreover, as we focus on more complex relations and n increases, it becomes increasingly rare that the related entities will be contained entirely in a single sentence.",2 Cross-sentence n-ary relation extraction,[0],[0]
"In this paper, we generalize extraction to cross-sentence, n-ary relations, where m > 2 and T can contain multiple sentences.",2 Cross-sentence n-ary relation extraction,[0],[0]
"As will be shown in our experiments section, n-ary relations are crucial for high-value domains such as biomedicine, and expanding beyond the sentence boundary enables the extraction of more knowledge.
",2 Cross-sentence n-ary relation extraction,[0],[0]
"In the standard binary-relation setting, the dominant approaches are generally defined in terms of the shortest dependency path between the two entities in question, either by deriving rich features from the path or by modeling it using deep neural
networks.",2 Cross-sentence n-ary relation extraction,[0],[0]
"Generalizing this paradigm to the n-ary setting is challenging, as there are ( n 2 ) paths.",2 Cross-sentence n-ary relation extraction,[0],[0]
"One apparent solution is inspired by Davidsonian semantics: first, identify a single trigger phrase that signifies the whole relation, then reduce the n-ary relation to n binary relations between the trigger and an argument.",2 Cross-sentence n-ary relation extraction,[0],[0]
"However, challenges remain.",2 Cross-sentence n-ary relation extraction,[0],[0]
"It is often hard to specify a single trigger, as the relation is manifested by several words, often not contiguous.",2 Cross-sentence n-ary relation extraction,[0],[0]
"Moreover, it is expensive and time-consuming to annotate training examples, especially if triggers are required, as is evident in prior annotation efforts such as GENIA (Kim et al., 2009).",2 Cross-sentence n-ary relation extraction,[0],[0]
"The realistic and widely adopted paradigm is to leverage indirect supervision, such as distant supervision (Craven and Kumlien, 1999; Mintz et al., 2009), where triggers are not available.
",2 Cross-sentence n-ary relation extraction,[0],[0]
"Additionally, lexical and syntactic patterns signifying the relation will be sparse.",2 Cross-sentence n-ary relation extraction,[0],[0]
"To handle such sparsity, traditional feature-based approaches require extensive engineering and large data.",2 Cross-sentence n-ary relation extraction,[0],[0]
"Unfortunately, this challenge becomes much more severe in crosssentence extraction when the text spans multiple sentences.
",2 Cross-sentence n-ary relation extraction,[0],[0]
"To overcome these challenges, we explore a general relation extraction framework based on graph LSTMs.",2 Cross-sentence n-ary relation extraction,[0],[0]
"By learning a continuous representation for words and entities, LSTMs can handle sparsity effectively without requiring intense feature engineering.",2 Cross-sentence n-ary relation extraction,[0],[0]
"The graph formulation subsumes prior LSTM approaches based on chains or trees, and can incorporate rich linguistic analyses.
",2 Cross-sentence n-ary relation extraction,[0],[0]
This approach also opens up opportunities for joint learning with related relations.,2 Cross-sentence n-ary relation extraction,[0],[0]
"For example, the Response relation over d, g, v also implies a binary sub-relation over drug d and mutation v, with the gene underspecified.",2 Cross-sentence n-ary relation extraction,[0],[0]
"Even with distant supervision, the supervision signal for n-ary relations will likely be sparser than their binary sub-relations.",2 Cross-sentence n-ary relation extraction,[0],[0]
Our approach makes it very easy to use multi-task learning over both the n-ary relations and their sub-relations.,2 Cross-sentence n-ary relation extraction,[0],[0]
Learning a continuous representation can be effective for dealing with lexical and syntactic sparsity.,3 Graph LSTMs,[0],[0]
"For sequential data such as text, recurrent neural networks (RNNs) are quite popular.",3 Graph LSTMs,[0],[0]
"They resemble hidden
Markov models (HMMs), except that discrete hidden states are replaced with continuous vectors, and emission and transition probabilities with neural networks.",3 Graph LSTMs,[0],[0]
"Conventional RNNs with sigmoid units suffer from gradient diffusion or explosion, making training very difficult (Bengio et al., 1994; Pascanu et al., 2013).",3 Graph LSTMs,[0],[0]
"Long short-term memory (LSTMs) (Hochreiter and Schmidhuber, 1997) combats these problems by using a series of gates (input, forget and output) to avoid amplifying or suppressing gradients during backpropagation.",3 Graph LSTMs,[0],[0]
"Consequently, LSTMs are much more effective in capturing long-distance dependencies, and have been applied to a variety of NLP tasks.",3 Graph LSTMs,[0],[0]
"However, most approaches are based on linear chains and only explicitly model the linear context, which ignores a variety of linguistic analyses, such as syntactic and discourse dependencies.
",3 Graph LSTMs,[0],[0]
"In this section, we propose a general framework that generalizes LSTMs to graphs.",3 Graph LSTMs,[0],[0]
"While there is some prior work on learning tree LSTMs (Tai et al., 2015; Miwa and Bansal, 2016), to the best of our knowledge, graph LSTMs have not been applied to any NLP task yet.",3 Graph LSTMs,[0],[0]
Figure 2 shows the architecture of this approach.,3 Graph LSTMs,[0],[0]
The input layer is the word embedding of input text.,3 Graph LSTMs,[0],[0]
Next is the graph LSTM which learns a contextual representation for each word.,3 Graph LSTMs,[0],[0]
"For the entities in question, their contextual representations are concatenated and become the input to the relation classifiers.",3 Graph LSTMs,[0],[0]
"For a multi-word entity, we simply used the average of its word representations and leave the exploration of more sophisticated aggregation approaches to future work.",3 Graph LSTMs,[0],[0]
The layers are trained jointly with backpropagation.,3 Graph LSTMs,[0],[0]
"This framework is
agnostic to the choice of classifiers.",3 Graph LSTMs,[0],[0]
"Jointly designing classifiers with graph LSTMs would be interesting future work.
",3 Graph LSTMs,[0],[0]
At the core of the graph LSTM is a document graph that captures various dependencies among the input words.,3 Graph LSTMs,[0],[0]
"By choosing what dependencies to include in the document graph, graph LSTMs naturally subsumes linear-chain or tree LSTMs.
",3 Graph LSTMs,[0],[0]
"Compared to conventional LSTMs, the graph formulation presents new challenges.",3 Graph LSTMs,[0],[0]
"Due to potential cycles in the graph, a straightforward implementation of backpropagation might require many iterations to reach a fixed point.",3 Graph LSTMs,[0],[0]
"Moreover, in the presence of a potentially large number of edge types (adjacent-word, syntactic dependency, etc.), parametrization becomes a key problem.
",3 Graph LSTMs,[0],[0]
"In the remainder of this section, we first introduce the document graph and show how to conduct backpropagation in graph LSTMs.",3 Graph LSTMs,[0],[0]
We then discuss two strategies for parametrizing the recurrent units.,3 Graph LSTMs,[0],[0]
"Finally, we show how to conduct multi-task learning with this framework.",3 Graph LSTMs,[0],[0]
"To model various dependencies from linguistic analysis at our disposal, we follow Quirk and Poon (2017) and introduce a document graph to capture intra- and inter-sentential dependencies.",3.1 Document Graph,[0],[0]
"A document graph consists of nodes that represent words and edges that represent various dependencies such as linear context (adjacent words), syntactic dependencies, and discourse relations (Lee et al., 2013; Xue et al., 2015).",3.1 Document Graph,[0],[0]
"Figure 1 shows the document graph for our running example; this instance suggests that tumors with L858E mutation in EGFR gene responds to the drug gefitinib.
",3.1 Document Graph,[0],[0]
This document graph acts as the backbone upon which a graph LSTM is constructed.,3.1 Document Graph,[0],[0]
"If it con-
tains only edges between adjacent words, we recover linear-chain LSTMs.",3.1 Document Graph,[0],[0]
"Similarly, other prior LSTM approaches can be captured in this framework by restricting edges to those in the shortest dependency path or the parse tree.",3.1 Document Graph,[0],[0]
Conventional LSTMs are essentially very deep feedforward neural networks.,3.2 Backpropagation in Graph LSTMs,[0],[0]
"For example, a left-to-right linear LSTM has one hidden vector for each word.",3.2 Backpropagation in Graph LSTMs,[0],[0]
This vector is generated by a neural network (recurrent unit) that takes as input the embedding of the given word and the hidden vector of the previous word.,3.2 Backpropagation in Graph LSTMs,[0],[0]
"In discriminative learning, these hidden vectors then serve as input for the end classifiers, from which gradients are backpropagated through the whole network.
",3.2 Backpropagation in Graph LSTMs,[0],[0]
"Generalizing such a strategy to graphs with cycles typically requires unrolling recurrence for a number of steps (Scarselli et al., 2009; Li et al., 2016; Liang et al., 2016).",3.2 Backpropagation in Graph LSTMs,[0],[0]
"Essentially, a copy of the graph is created for each step that serves as input for the next.",3.2 Backpropagation in Graph LSTMs,[0],[0]
"The result is a feed-forward neural network through time, and backpropagation is conducted accordingly.
",3.2 Backpropagation in Graph LSTMs,[0],[0]
"In principle, we could adopt the same strategy.",3.2 Backpropagation in Graph LSTMs,[0],[0]
"Effectively, gradients are backpropagated in a manner similar to loopy belief propagation (LBP).",3.2 Backpropagation in Graph LSTMs,[0],[0]
"However, this makes learning much more expensive as each update step requires multiple iterations of backpropagation.",3.2 Backpropagation in Graph LSTMs,[0],[0]
"Moreover, loopy backpropagation could suffer from the same problems encountered to in LBP, such as oscillation or failure to converge.
",3.2 Backpropagation in Graph LSTMs,[0],[0]
"We observe that dependencies such as coreference and discourse relations are generally sparse, so the backbone of a document graph consists of the linear chain and the syntactic dependency tree.",3.2 Backpropagation in Graph LSTMs,[0],[0]
"As in belief propagation, such structures can be leveraged to make backpropagation more efficient by replac-
ing synchronous updates, as in the unrolling strategy, with asynchronous updates, as in linear-chain LSTMs.",3.2 Backpropagation in Graph LSTMs,[0],[0]
"This opens up opportunities for a variety of strategies in ordering backpropagation updates.
",3.2 Backpropagation in Graph LSTMs,[0],[0]
"In this paper, we adopt a simple strategy that performed quite well in preliminary experiments, and leave further exploration to future work.",3.2 Backpropagation in Graph LSTMs,[0],[0]
"Specifically, we partition the document graph into two directed acyclic graphs (DAGs).",3.2 Backpropagation in Graph LSTMs,[0],[0]
"One DAG contains the left-to-right linear chain, as well as other forwardpointing dependencies.",3.2 Backpropagation in Graph LSTMs,[0],[0]
The other DAG covers the right-to-left linear chain and the backward-pointing dependencies.,3.2 Backpropagation in Graph LSTMs,[0],[0]
Figure 3 illustrates this strategy.,3.2 Backpropagation in Graph LSTMs,[0],[0]
"Effectively, we partition the original graph into the forward pass (left-to-right), followed by the backward pass (right-to-left), and construct the LSTMs accordingly.",3.2 Backpropagation in Graph LSTMs,[0],[0]
"When the document graph only contains linear chain edges, the graph LSTMs is exactly a bi-directional LSTMs (BiLSTMs).",3.2 Backpropagation in Graph LSTMs,[0],[0]
"A standard LSTM unit consists of an input vector (word embedding), a memory cell and an output vector (contextual representation), as well as several gates.",3.3 The Basic Recurrent Propagation Unit,[0],[0]
"The input gate and output gate control the information flowing into and out of the cell, whereas the forget gate can optionally remove information from the recurrent connection to a precedent unit.
",3.3 The Basic Recurrent Propagation Unit,[0],[0]
"In linear-chain LSTMs, each unit contains only one forget gate, as it has only one direct precedent (i.e., the adjacent-word edge pointing to the previous word).",3.3 The Basic Recurrent Propagation Unit,[0],[0]
"In graph LSTMs, however, a unit may have several precedents, including connections to the same word via different edges.",3.3 The Basic Recurrent Propagation Unit,[0],[0]
"We thus introduce a forget gate for each precedent, similar to the approach taken by Tai et al. (2015) for tree LSTMs.
",3.3 The Basic Recurrent Propagation Unit,[0],[0]
"Encoding rich linguistic analysis introduces many distinct edge types besides word adjacency, such as syntactic dependencies, which opens up many possibilities for parametrization.",3.3 The Basic Recurrent Propagation Unit,[0],[0]
"This was not considered in prior syntax-aware LSTM approaches (Tai et al., 2015; Miwa and Bansal, 2016).",3.3 The Basic Recurrent Propagation Unit,[0],[0]
"In this paper, we explore two schemes that introduce more fined-grained parameters based on the edge types.
",3.3 The Basic Recurrent Propagation Unit,[0],[0]
Full Parametrization,3.3 The Basic Recurrent Propagation Unit,[0],[0]
"Our first proposal simply introduces a different set of parameters for each edge type, with computation specified below.
",3.3 The Basic Recurrent Propagation Unit,[0],[0]
"it = σ(Wixt + ∑
j∈P (t) U
m(t,j) i hj + bi)
ot = σ(Woxt + ∑
j∈P (t) Um(t,j)o hj + bo) c̃t = tanh(Wcxt + ∑
j∈P (t) Um(t,j)c hj + bc)
ftj = σ(Wfxt",3.3 The Basic Recurrent Propagation Unit,[0],[0]
+,3.3 The Basic Recurrent Propagation Unit,[0],[0]
"U m(t,j) f hj + bf )",3.3 The Basic Recurrent Propagation Unit,[0],[0]
ct = it c̃t,3.3 The Basic Recurrent Propagation Unit,[0],[0]
"+ ∑
j∈P (t) ftj",3.3 The Basic Recurrent Propagation Unit,[0],[0]
"cj
ht = ot tanh(ct)
",3.3 The Basic Recurrent Propagation Unit,[0],[0]
"As in standard chain LSTMs, xt is the input word vector for node t, ht is the hidden state vector for node t, W ’s are the input weight matrices, and b’s are the bias vectors.",3.3 The Basic Recurrent Propagation Unit,[0],[0]
"σ, tanh, and represent the sigmoid function, the hyperbolic tangent function, and the Hadamard product (pointwise multiplication), respectively.",3.3 The Basic Recurrent Propagation Unit,[0],[0]
The main differences lie in the recurrence terms.,3.3 The Basic Recurrent Propagation Unit,[0],[0]
"In graph LSTMs, a unit might have multiple predecessors (P (t)), for each of which (j) there is a forget gate ftj , and a typed weight matrix Um(t,j), where m(t, j) signifies the connection type between t and j. The input and output gates (it, ot) depend on all predecessors, whereas the forget gate (ftj) only depends on the predecessor with which the gate is associated.",3.3 The Basic Recurrent Propagation Unit,[0],[0]
"ct and c̃t represent intermediate computation results within the memory cell, which take into account the input and forget gates, and will be combined with output gate to produce the hidden representation ht.
",3.3 The Basic Recurrent Propagation Unit,[0],[0]
"Full parameterization is straightforward, but it requires a large number of parameters when there are many edge types.",3.3 The Basic Recurrent Propagation Unit,[0],[0]
"For example, there are dozens of syntactic edge types, each corresponding to a Stanford dependency label.",3.3 The Basic Recurrent Propagation Unit,[0],[0]
"As a result, in our experiments we resort to using only the coarse-grained types: word adjacency, syntactic dependency, etc.",3.3 The Basic Recurrent Propagation Unit,[0],[0]
"Next, we will consider a more fine-grained approach by learning an edge-type embedding.
",3.3 The Basic Recurrent Propagation Unit,[0],[0]
"Edge-Type Embedding To reduce the number of parameters and leverage potential correlation among fine-grained edge types, we learned a lowdimensional embedding of the edge types, and conducted an outer product of the predecessor’s hidden vector and the edge-type embedding to generate a “typed hidden representation”, which is a matrix.",3.3 The Basic Recurrent Propagation Unit,[0],[0]
"The new computation is as follows:
it = σ(Wixt + ∑
j∈P (t) Ui ×T (hj ⊗ ej) + bi)
ftj = σ(Wfxt +",3.3 The Basic Recurrent Propagation Unit,[0],[0]
Uf ×T (hj ⊗ ej) + bf ),3.3 The Basic Recurrent Propagation Unit,[0],[0]
"ot = σ(Woxt + ∑
j∈P (t)",3.3 The Basic Recurrent Propagation Unit,[0],[0]
"Uo ×T (hj ⊗ ej) + bo) c̃t = tanh(Wcxt + ∑
j∈P (t) Uc ×T (hj ⊗ ej) + bc) ct",3.3 The Basic Recurrent Propagation Unit,[0],[0]
"= it c̃t + ∑
j∈P (t) ftj cj
ht = ot tanh(ct)
",3.3 The Basic Recurrent Propagation Unit,[0],[0]
U ’s are now l ×,3.3 The Basic Recurrent Propagation Unit,[0],[0]
"l × d tensors (l is the dimension of the hidden vector and d is the dimension for edgetype embedding), and hj ⊗ ej is a tensor product that produces an l × d matrix.",3.3 The Basic Recurrent Propagation Unit,[0],[0]
×T denotes a tensor dot product defined as T ×T,3.3 The Basic Recurrent Propagation Unit,[0],[0]
"A = ∑ d(T:,:,d · A:,d), which produces an l-dimensional vector.",3.3 The Basic Recurrent Propagation Unit,[0],[0]
The edgetype embedding ej is jointly trained with the other parameters.,3.3 The Basic Recurrent Propagation Unit,[0],[0]
The main advantages of a graph formulation are its generality and flexibility.,3.4 Comparison with Prior LSTM Approaches,[0],[0]
"As seen in Section 3.1, linear-chain LSTMs are a special case when the document graph is the linear chain of adjacent words.",3.4 Comparison with Prior LSTM Approaches,[0],[0]
"Similarly, Tree LSTMs (Tai et al., 2015) are a special case when the document graph is the parse tree.
",3.4 Comparison with Prior LSTM Approaches,[0],[0]
"In graph LSTMs, the encoding of linguistic knowledge is factored from the backpropagation strategy (Section 3.2), making it much more flexible, including introducing cycles.",3.4 Comparison with Prior LSTM Approaches,[0],[0]
"For example, Miwa and Bansal (2016) conducted joint entity and binary relation extraction by stacking a LSTM for relation extraction on top of another LSTM for entity recognition.",3.4 Comparison with Prior LSTM Approaches,[0],[0]
"In graph LSTMs, the two can be combined seamlessly using a document graph comprising both the word-adjacency chain and the dependency path between the two entities.
",3.4 Comparison with Prior LSTM Approaches,[0],[0]
The document graph can also incorporate other linguistic information.,3.4 Comparison with Prior LSTM Approaches,[0],[0]
"For example, coreference and discourse parsing are intuitively relevant for cross-sentence relation extraction.",3.4 Comparison with Prior LSTM Approaches,[0],[0]
"Although existing systems have not yet been shown to improve crosssentence relation extraction (Quirk and Poon, 2017), it remains an important future direction to explore incorporating such analyses, especially after adapting them to the biomedical domains (Bell et al., 2016).",3.4 Comparison with Prior LSTM Approaches,[0],[0]
"Multi-task learning has been shown to be beneficial in training neural networks (Caruana, 1998; Collobert and Weston, 2008; Peng and Dredze, 2016).",3.5 Multi-task Learning with Sub-relations,[0],[0]
"By learning contextual entity representations, our framework makes it straightforward to conduct multi-task learning.",3.5 Multi-task Learning with Sub-relations,[0],[0]
The only change is to add a separate classifier for each related auxiliary relation.,3.5 Multi-task Learning with Sub-relations,[0],[0]
"All classifiers share the same graph LSTMs representation learner and word embeddings, and can potentially help each other by pooling their supervision signals.
",3.5 Multi-task Learning with Sub-relations,[0],[0]
"In the molecular tumor board domain, we applied this paradigm to joint learning of both the ternary relation (drug-gene-mutation) and its binary sub-relation (drug-mutation).",3.5 Multi-task Learning with Sub-relations,[0],[0]
Experiment results show that this provides significant gains in both tasks.,3.5 Multi-task Learning with Sub-relations,[0],[0]
"We implemented our methods using the Theano library (Theano Development Team, 2016).",4 Implementation Details,[0],[0]
We used logistic regression for our relation classifiers.,4 Implementation Details,[0],[0]
Hyper parameters were set based on preliminary experiments on a small development dataset.,4 Implementation Details,[0],[0]
Training was done using mini-batched stochastic gradient descent (SGD) with batch size 8.,4 Implementation Details,[0],[0]
"We used a learning rate of 0.02 and trained for at most 30 epochs, with early stopping based on development data (Caruana et al., 2001; Graves et al., 2013).",4 Implementation Details,[0],[0]
"The dimension for the hidden vectors in LSTM units was set to 150, and the dimension for the edge-type embedding was set to 3.",4 Implementation Details,[0],[0]
"The word embeddings were initialized with the publicly available 100-dimensional GloVe word vectors trained on 6 billion words from Wikipedia and web text3 (Pennington et al., 2014).",4 Implementation Details,[0],[0]
"Other model parameters were initialized with random samples drawn uniformly from the range [−1, 1].
",4 Implementation Details,[0],[0]
"In multi-task training, we alternated among all tasks, each time passing through all data for one task4, and updating the parameters accordingly.",4 Implementation Details,[0],[0]
"This was repeated for 30 epochs.
3http://nlp.stanford.edu/projects/glove/ 4However, drug-gene pairs have much more data, so we subsampled the instances down to the same size as the main n-ary relation task.",4 Implementation Details,[0],[0]
"Our main experiments focus on extracting ternary interactions over drugs, genes and mutations, which is important for molecular tumor boards.",5 Domain: Molecular Tumor Boards,[0],[0]
A druggene-mutation interaction is broadly construed as an association between the drug efficacy and the mutation in the given gene.,5 Domain: Molecular Tumor Boards,[0],[0]
There is no annotated dataset for this problem.,5 Domain: Molecular Tumor Boards,[0],[0]
"However, due to the importance of such knowledge, oncologists have been painstakingly curating known relations from reading papers.",5 Domain: Molecular Tumor Boards,[0],[0]
"Such a manual approach cannot keep up with the rapid growth of the research literature, and the coverage is generally sparse and not up to date.",5 Domain: Molecular Tumor Boards,[0],[0]
"However, the curated knowledge can be used for distant supervision.",5 Domain: Molecular Tumor Boards,[0],[0]
"We obtained biomedical literature from PubMed Central5, consisting of approximately one million fulltext articles as of 2015.",5.1 Datasets,[0],[0]
Note that only a fraction of papers contain knowledge about drug-gene-mutation interactions.,5.1 Datasets,[0],[0]
Extracting such knowledge from the vast body of biomedical papers is exactly the challenge.,5.1 Datasets,[0],[0]
"As we will see in later subsections, distant supervision enables us to generate a sizable training set from a small number of manually curated facts, and the learned model was able to extract orders of magnitude more facts.",5.1 Datasets,[0],[0]
"In future work, we will explore incorporating more known facts for distant supervision and extracting from more full-text articles.
",5.1 Datasets,[0],[0]
"We conducted tokenization, part-of-speech tagging, and syntactic parsing using SPLAT (Quirk et al., 2012), and obtained Stanford dependencies (de Marneffe et al., 2006) using Stanford CoreNLP",5.1 Datasets,[0],[0]
"(Manning et al., 2014).",5.1 Datasets,[0],[0]
"We used the entity taggers from Literome (Poon et al., 2014) to identify drug, gene and mutation mentions.
",5.1 Datasets,[0],[0]
"We used the Gene Drug Knowledge Database (GDKD) (Dienstmann et al., 2015) and the Clinical Interpretations of Variants In Cancer (CIVIC) knowledge base6 for distant supervision.",5.1 Datasets,[0],[0]
"The knowledge bases distinguish fine-grained interaction types, which we do not use in this paper.
",5.1 Datasets,[0],[0]
5http://www.ncbi.nlm.nih.gov/pmc/ 6http://civic.genome.wustl.edu,5.1 Datasets,[0],[0]
"After identifying drug, gene and mutation mentions in the text, co-occurring triples with known interactions were chosen as positive examples.",5.2 Distant Supervision,[0],[0]
"However, unlike the single-sentence setting in standard distant supervision, care must be taken in selecting the candidates.",5.2 Distant Supervision,[0],[0]
"Since the triples can reside in different sentences, an unrestricted selection of text spans would risk introducing many obviously wrong examples.",5.2 Distant Supervision,[0],[0]
"We thus followed Quirk and Poon (2017) in restricting the candidates to those occurring in a minimal span, i.e., we retain a candidate only if is no other co-occurrence of the same entities in an overlapping text span with a smaller number of consecutive sentences.",5.2 Distant Supervision,[0],[0]
"Furthermore, we avoid picking unlikely candidates where the triples are far apart in the document.",5.2 Distant Supervision,[0],[0]
"Specifically, we considered entity triples within K consecutive sentences, ignoring paragraph boundaries.",5.2 Distant Supervision,[0],[0]
K = 1 corresponds to the baseline of extraction within single sentences.,5.2 Distant Supervision,[0],[0]
"We explored K ≤ 3, which captured a large fraction of candidates without introducing many unlikely ones.
",5.2 Distant Supervision,[0],[0]
Only 59 distinct drug-gene-mutation triples from the knowledge bases were matched in the text.,5.2 Distant Supervision,[0],[0]
"Even from such a small set of unique triples, we obtained 3,462 ternary relation instances that can serve as positive examples.",5.2 Distant Supervision,[0],[0]
"For multi-task learning, we also considered drug-gene and drug-mutation sub-relations, which yielded 137,469 drug-gene and 3,192 drugmutation relation instances as positive examples.
",5.2 Distant Supervision,[0],[0]
"We generate negative examples by randomly sampling co-occurring entity triples without known interactions, subject to the same restrictions above.",5.2 Distant Supervision,[0],[0]
We sampled the same number as positive examples to obtain a balanced dataset7.,5.2 Distant Supervision,[0],[0]
"To compare the various models in our proposed framework, we conducted five-fold cross-validation, treating the positive and negative examples from distant supervision as gold annotation.",5.3 Automatic Evaluation,[0],[0]
"To avoid traintest contamination, all examples from a document were assigned to the same fold.",5.3 Automatic Evaluation,[0],[0]
"Since our datasets are balanced by construction, we simply report average test accuracy on held-out folds.",5.3 Automatic Evaluation,[0],[0]
"Obviously, the
7We will release the dataset at http://hanover.azurewebsites.net.
results could be noisy (e.g., entity triples not known to have an interaction might actually have one), but this evaluation is automatic and can quickly evaluate the impact of various design choices.
",5.3 Automatic Evaluation,[0],[0]
We evaluated two variants of graph LSTMs: “Graph LSTM-FULL” with full parametrization and “Graph LSTM-EMBED” with edge-type embedding.,5.3 Automatic Evaluation,[0],[0]
"We compared graph LSTMs with three strong baseline systems: a well-engineered feature-based classifier (Quirk and Poon, 2017), a convolutional neural network (CNN)",5.3 Automatic Evaluation,[0],[0]
"(Zeng et al., 2014; Santos et al., 2015; Wang et al., 2016), and a bi-directional LSTM (BiLSTM).",5.3 Automatic Evaluation,[0],[0]
"Following Wang et al. (2016), we used input attention for the CNN and a input window size of 5.",5.3 Automatic Evaluation,[0],[0]
Quirk and Poon (2017) only extracted binary relations.,5.3 Automatic Evaluation,[0],[0]
"We extended it to ternary relations by deriving features for each entity pair (with added annotation to signify the two entity types), and pooling the features
from all pairs.",5.3 Automatic Evaluation,[0],[0]
"For binary relation extraction, prior syntax-aware approaches are directly applicable.",5.3 Automatic Evaluation,[0],[0]
"So we also compared with a state-of-the-art tree LSTM system (Miwa and Bansal, 2016) and a BiLSTM on the shortest dependency path between the two entities (BiLSTM-Shortest-Path) (Xu et al., 2015b).
",5.3 Automatic Evaluation,[0],[0]
"Table 1 shows the results for cross-sentence, ternary relation extraction.",5.3 Automatic Evaluation,[0],[0]
"All neural-network based models outperformed the feature-based classifier, illustrating their advantage in handling sparse linguistic patterns without requiring intense feature engineering.",5.3 Automatic Evaluation,[0],[0]
"All LSTMs significantly outperformed CNN in the cross-sentence setting, verifying the importance in capturing long-distance dependencies.
",5.3 Automatic Evaluation,[0],[0]
"The two variants of graph LSTMs perform on par with each other, though Graph LSTM-FULL has a small advantage, suggesting that further exploration of parametrization schemes could be beneficial.",5.3 Automatic Evaluation,[0],[0]
"In particular, the edge-type embedding might improve by pretraining on unlabeled text with syntactic parses.
",5.3 Automatic Evaluation,[0],[0]
"Both graph variants significantly outperformed BiLSTMs (p < 0.05 by McNemar’s chi-square test), though the difference is small.",5.3 Automatic Evaluation,[0],[0]
This result is intriguing.,5.3 Automatic Evaluation,[0],[0]
"In Quirk and Poon (2017), the best system incorporated syntactic dependencies and outperformed the linear-chain variant (Base) by a large margin.",5.3 Automatic Evaluation,[0],[0]
"So why didn’t graph LSTMs make an equally substantial gain by modeling syntactic dependencies?
",5.3 Automatic Evaluation,[0],[0]
One reason is that linear-chain LSTMs can already captured some of the long-distance dependencies available in syntactic parses.,5.3 Automatic Evaluation,[0],[0]
"BiLSTMs substantially outperformed the feature-based classifier, even without explicit modeling of syntactic dependencies.",5.3 Automatic Evaluation,[0],[0]
"The gain cannot be entirely attributed to word embedding as LSTMs also outperformed CNNs.
",5.3 Automatic Evaluation,[0],[0]
Another reason is that syntactic parsing is less accurate in the biomedical domain.,5.3 Automatic Evaluation,[0],[0]
"Parse errors confuse the graph LSM learner, limiting the potential for gain.",5.3 Automatic Evaluation,[0],[0]
"In Section 6, we show supporting evidence in a domain when gold parses are available.
",5.3 Automatic Evaluation,[0],[0]
"We also reported accuracy on instances within single sentences, which exhibited a broadly similar set of trends.",5.3 Automatic Evaluation,[0],[0]
"Note that single-sentence and crosssentence accuracies are not directly comparable, as the test sets are different (one subsumes the other).
",5.3 Automatic Evaluation,[0],[0]
We conducted the same experiments on the binary sub-relation between drug-mutation pairs.,5.3 Automatic Evaluation,[0],[0]
"Table 2
shows the results, which are similar to the ternary case: Graph LSTM-FULL consistently performed the best for both single sentence and cross-sentence instances.",5.3 Automatic Evaluation,[0],[0]
"BiLSTMs on the shortest path substantially underperformed BiLSTMs or graph LSTMs, losing between 4-5 absolute points in accuracy, which could be attributed to the lower parsing quality in the biomedical domain.",5.3 Automatic Evaluation,[0],[0]
"Interestingly, the state-of-the-art tree LSTMs (Miwa and Bansal, 2016) also underperformed graph LSTMs, even though they encoded essentially the same linguistic structures (word adjacency and syntactic dependency).",5.3 Automatic Evaluation,[0],[0]
"We attributed the gain to the fact that Miwa and Bansal (2016) used separate LSTMs for the linear chain and the dependency tree, whereas graph LSTMs learned a single representation for both.
",5.3 Automatic Evaluation,[0],[0]
"To evaluate whether joint learning with subrelations can help, we conducted multi-task learning using Graph LSTM-FULL to jointly train extractors for both the ternary interaction and the drug-mutation, drug-gene sub-relations.",5.3 Automatic Evaluation,[0],[0]
Table 3 shows the results.,5.3 Automatic Evaluation,[0],[0]
Multi-task learning resulted in a significant gain for both the ternary interaction and the drug-mutation interaction.,5.3 Automatic Evaluation,[0],[0]
"Interestingly, the advantage of graph LSTMs over BiLSTMs is reduced with multi-task learning, suggesting that with more supervision signal, even linear-chain LSTMs can learn to capture long-range dependencies that are were made evident by parse features in graph LSTMs.",5.3 Automatic Evaluation,[0],[0]
"Note that there are many more instances for drug-gene interaction than others, so we only sampled a subset of comparable size.",5.3 Automatic Evaluation,[0],[0]
"Therefore, we do not evaluate the performance gain for drug-gene interaction, as in practice, one would simply learn from all available data, and the sub-sampled results are not competitive.
",5.3 Automatic Evaluation,[0],[0]
We included coreference and discourse relations in our document graph.,5.3 Automatic Evaluation,[0],[0]
"However, we didn’t observe any significant gains, similar to the observation in
Quirk and Poon (2017).",5.3 Automatic Evaluation,[0],[0]
We leave further exploration to future work.,5.3 Automatic Evaluation,[0],[0]
Our ultimate goal is to extract all knowledge from available text.,5.4 PubMed-Scale Extraction,[0],[0]
"We thus retrained our model using the best system from automatic evaluation (i.e., Graph LSTM-FULL) on all available data.",5.4 PubMed-Scale Extraction,[0],[0]
"The resulting model was then used to extract relations from all PubMed Central articles.
",5.4 PubMed-Scale Extraction,[0],[0]
Table 4 shows the number of candidates and extracted interactions.,5.4 PubMed-Scale Extraction,[0],[0]
"With as little as 59 unique druggene-mutation triples from the two databases8, we learned to extract orders of magnitude more unique interactions.",5.4 PubMed-Scale Extraction,[0],[0]
"The results also highlight the benefit of cross-sentence extraction, which yields 3 to 5 times more relations than single-sentence extraction.
",5.4 PubMed-Scale Extraction,[0],[0]
"Table 5 conducts a similar comparison on unique number of drugs, genes, and mutations.",5.4 PubMed-Scale Extraction,[0],[0]
"Again, machine reading covers far more unique entities, especially with cross-sentence extraction.",5.4 PubMed-Scale Extraction,[0],[0]
"Our automatic evaluations are useful for comparing competing approaches, but may not reflect the true classifier precision as the labels are noisy.",5.5 Manual Evaluation,[0],[0]
"Therefore, we randomly sampled extracted relation instances and asked three researchers knowledgeable in precision medicine to evaluate their correctness.",5.5 Manual Evaluation,[0],[0]
"For each instance, the annotators were presented with the provenance: sentences with the drug, gene, and mutation highlighted.",5.5 Manual Evaluation,[0],[0]
"The annotators determined in
8There are more in the databases, but these are the only ones for which we found matching instances in the text.",5.5 Manual Evaluation,[0],[0]
"In future work, we will explore various ways to increase the number, e.g., by matching underspecified drug classes to specific drugs.
",5.5 Manual Evaluation,[0],[0]
each case whether this instance implied that the given entities were related.,5.5 Manual Evaluation,[0],[0]
"Note that evaluation does not attempt to identify whether the relationships are true or replicated in follow-up papers; rather, it focuses on whether the relationships are entailed by the text.
",5.5 Manual Evaluation,[0],[0]
We focused our evaluation efforts on the crosssentence ternary-relation setting.,5.5 Manual Evaluation,[0],[0]
"We considered three probability thresholds: 0.9 for a high-precision but potentially low-recall setting, 0.5, and a random sample of all candidates.",5.5 Manual Evaluation,[0],[0]
"In each case, 150 instances were selected for a total of 450 annotations.",5.5 Manual Evaluation,[0],[0]
"A subset of 150 instances were reviewed by two annotators, and the inter-annotator agreement was 88%.
",5.5 Manual Evaluation,[0],[0]
"Table 6 shows that the classifier indeed filters out a large portion of potential candidates, with estimated instance accuracy of 64% at the threshold of 0.5, and 75% at 0.9.",5.5 Manual Evaluation,[0],[0]
"Interestingly, LSTMs are effective at screening out many entity mention errors, presumably because they include broad contextual features.",5.5 Manual Evaluation,[0],[0]
"We also conducted experiments on extracting genetic pathway interactions using the GENIA Event Extraction dataset (Kim et al., 2009).",6 Domain: Genetic Pathways,[0],[0]
"This dataset contains gold syntactic parses for the sentences, which offered a unique opportunity to investigate the impact of syntactic analysis on graph LSTMs.",6 Domain: Genetic Pathways,[0],[0]
"It also allowed us to test our framework in supervised learning.
",6 Domain: Genetic Pathways,[0],[0]
"The original shared task evaluated on complex, nested events for nine event types, many of which are unary relations (Kim et al., 2009).",6 Domain: Genetic Pathways,[0],[0]
"Following Poon et al. (2015), we focused on gene regulation and reduced it to binary-relation classification for headto-head comparison.",6 Domain: Genetic Pathways,[0],[0]
"We followed their experimental protocol by sub-sampling negative examples to be about three times of positive examples.
",6 Domain: Genetic Pathways,[0],[0]
"Since the dataset is not entirely balanced, we reported precision, recall, and F1.",6 Domain: Genetic Pathways,[0],[0]
We used our best performing graph LSTM from the previous experiments.,6 Domain: Genetic Pathways,[0],[0]
"By default, automatic parses were used in the document graphs, whereas in Graph LSTM (GOLD), gold parses were used instead.",6 Domain: Genetic Pathways,[0],[0]
Table 7 shows the results.,6 Domain: Genetic Pathways,[0],[0]
"Once again, despite the lack of intense feature engineering, linear-chain LSTMs performed on par with the feature-based classifier (Poon et al., 2015).",6 Domain: Genetic Pathways,[0],[0]
"Graph LSTMs exhibited a more commanding advantage over linear-chain LSTMs in this domain, substantially outperforming the latter (p < 0.01 by McNemar’s chi-square test).",6 Domain: Genetic Pathways,[0],[0]
"Most interestingly, graph LSTMs using gold parses significantly outperformed that using automatic parses, suggesting that encoding high-quality analysis is particularly beneficial.",6 Domain: Genetic Pathways,[0],[0]
Most work on relation extraction has been applied to binary relations of entities in a single sentence.,7 Related Work,[0],[0]
"We first review relevant work on the single-sentence bi-
nary relation extraction task, and then review related work on n-ary and cross-sentence relation extraction.
",7 Related Work,[0],[0]
"Binary relation extraction The traditional featurebased methods rely on carefully designed features to learn good models, and often integrate diverse sources of evidence such as word sequences and syntax context (Kambhatla, 2004; GuoDong et al., 2005; Boschee et al., 2005; Suchanek et al., 2006; Chan and Roth, 2010; Nguyen and Grishman, 2014).",7 Related Work,[0],[0]
"The kernel-based methods design various subsequence or tree kernels (Mooney and Bunescu, 2005; Bunescu and Mooney, 2005; Qian et al., 2008) to capture structured information.",7 Related Work,[0],[0]
"Recently, models based on neural networks have advanced the state of the art by automatically learning powerful feature representations (Xu et al., 2015a; Zhang et al., 2015; Santos et al., 2015; Xu et al., 2015b; Xu et al., 2016).
",7 Related Work,[0],[0]
"Most neural architectures resemble Figure 2, where there is a core representation learner (blue) that takes word embeddings as input and produces contextual entity representations.",7 Related Work,[0],[0]
Such representations are then taken by relation classifiers to produce the final predictions.,7 Related Work,[0],[0]
"Effectively representing sequences of words, both convolutional (Zeng et al., 2014; Wang et al., 2016; Santos et al., 2015) and RNN-based architectures (Zhang et al., 2015; Socher et al., 2012; Cai et al., 2016) have been successful.",7 Related Work,[0],[0]
Most of these have focused on modeling either the surface word sequences or the hierarchical syntactic structure.,7 Related Work,[0],[0]
"Miwa and Bansal (2016) proposed an architecture that benefits from both types of information, using a surface sequence layer, followed by a dependency-tree sequence layer.
",7 Related Work,[0],[0]
"N -ary relation extraction Early work on extracting relations between more than two arguments has been done in MUC-7, with a focus on fact/event extraction from news articles (Chinchor, 1998).",7 Related Work,[0],[0]
"Semantic role labeling in the Propbank (Palmer et al., 2005) or FrameNet (Baker et al., 1998) style are also instances of n-ary relation extraction, with extraction of events expressed in a single sentence.",7 Related Work,[0],[0]
"McDonald et al. (2005) extract n-ary relations in a biomedical domain, by first factoring the n-ary relation into pair-wise relations between all entity pairs, and then constructing maximal cliques of related entities.",7 Related Work,[0],[0]
"Recently, neural models have been applied to semantic role labeling (FitzGerald et al., 2015; Roth
and Lapata, 2016).",7 Related Work,[0],[0]
"These works learned neural representations by effectively decomposing the n-ary relation into binary relations between the predicate and each argument, by embedding the dependency path between each pair, or by combining features of the two using a feed-forward network.",7 Related Work,[0],[0]
"Although some re-ranking or joint inference models have been employed, the representations of the individual arguments do not influence each other.",7 Related Work,[0],[0]
"In contrast, we propose a neural architecture that jointly represents n entity mentions, taking into account long-distance dependencies and inter-sentential information.
",7 Related Work,[0],[0]
"Cross-sentence relation extraction Several relation extraction tasks have benefited from crosssentence extraction, including MUC fact and event extraction (Swampillai and Stevenson, 2011), record extraction from web pages (Wick et al., 2006), extraction of facts for biomedical domains (Yoshikawa et al., 2011), and extensions of semantic role labeling to cover implicit inter-sentential arguments (Gerber and Chai, 2010).",7 Related Work,[0],[0]
"These prior works have either relied on explicit co-reference annotation, or on the assumption that the whole document refers to a single coherent event, to simplify the problem and reduce the need for powerful representations of multi-sentential contexts of entity mentions.",7 Related Work,[0],[0]
"Recently, cross-sentence relation extraction models have been learned with distant supervision, and used integrated contextual evidence of diverse types without reliance on these assumptions (Quirk and Poon, 2017), but that work focused on binary relations only and explicitly engineered sparse indicator features.
",7 Related Work,[0],[0]
"Relation extraction using distant supervision Distant supervision has been applied to extraction of binary (Mintz et al., 2009; Poon et al., 2015) and n-ary (Reschke et al., 2014;",7 Related Work,[0],[0]
"Li et al., 2015) relations, traditionally using hand-engineered features.",7 Related Work,[0],[0]
"Neural architectures have recently been applied to distantly supervised extraction of binary relations (Zeng et al., 2015).",7 Related Work,[0],[0]
"Our work is the first to propose a neural architecture for n-ary relation extraction, where the representation of a tuple of entities is not decomposable into independent representations of the individual entities or entity pairs, and which integrates diverse information from multi-sentential context.",7 Related Work,[0],[0]
"To utilize training data more effectively, we show how multitask learning for component binary sub-relations can
improve performance.",7 Related Work,[0],[0]
"Our learned representation combines information sources within a single sentence in a more integrated and generalizable fashion than prior approaches, and can also improve performance on single-sentence binary relation extraction.",7 Related Work,[0],[0]
We explore a general framework for cross-sentence nary relation extraction based on graph LSTMs.,8 Conclusion,[0],[0]
The graph formulation subsumes linear-chain and tree LSTMs and makes it easy to incorporate rich linguistic analysis.,8 Conclusion,[0],[0]
"Experiments on biomedical domains showed that extraction beyond the sentence boundary produced far more knowledge, and encoding rich linguistic knowledge provided consistent gain.
",8 Conclusion,[0],[0]
"While there is much room to improve in both recall and precision, our results indicate that machine reading can already be useful in precision medicine.",8 Conclusion,[0],[0]
"In particular, automatically extracted facts (Section 5.4) can serve as candidates for manual curation.",8 Conclusion,[0],[0]
"Instead of scanning millions of articles to curate from scratch, human curators would just quickly vet thousands of extractions.",8 Conclusion,[0],[0]
The errors identified by curators offer direct supervision to the machine reading system for continuous improvement.,8 Conclusion,[0],[0]
"Therefore, the most important goal is to attain high recall and reasonable precision.",8 Conclusion,[0],[0]
"Our current models are already quite capable.
",8 Conclusion,[0],[0]
Future directions include: interactive learning with user feedback; improving discourse modeling in graph LSTMs; exploring other backpropagation strategies; joint learning with entity linking; applications to other domains.,8 Conclusion,[0],[0]
"We thank Daniel Fried and Ming-Wei Chang for useful discussions, as well as the anonymous reviewers and editor-in-chief Mark Johnson for their helpful comments.",Acknowledgements,[0],[0]
Past work in relation extraction has focused on binary relations in single sentences.,abstractText,[0],[0]
Recent NLP inroads in high-value domains have sparked interest in the more general setting of extracting n-ary relations that span multiple sentences.,abstractText,[0],[0]
"In this paper, we explore a general relation extraction framework based on graph long short-term memory networks (graph LSTMs) that can be easily extended to cross-sentence n-ary relation extraction.",abstractText,[0],[0]
"The graph formulation provides a unified way of exploring different LSTM approaches and incorporating various intra-sentential and intersentential dependencies, such as sequential, syntactic, and discourse relations.",abstractText,[0],[0]
"A robust contextual representation is learned for the entities, which serves as input to the relation classifier.",abstractText,[0],[0]
"This simplifies handling of relations with arbitrary arity, and enables multi-task learning with related relations.",abstractText,[0],[0]
"We evaluate this framework in two important precision medicine settings, demonstrating its effectiveness with both conventional supervised learning and distant supervision.",abstractText,[0],[0]
Cross-sentence extraction produced larger knowledge bases.,abstractText,[0],[0]
and multi-task learning significantly improved extraction accuracy.,abstractText,[0],[0]
A thorough analysis of various LSTM approaches yielded useful insight the impact of linguistic analysis on extraction accuracy.,abstractText,[0],[0]
Cross-Sentence N -ary Relation Extraction with Graph LSTMs,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 778–783 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
778",text,[0],[0]
"Stance classification is the task of automatically identifying users’ positions about a specific target from text (Mohammad et al., 2017).",1 Introduction,[0],[0]
"Table 1 shows an example of this task, where the stance of the sentence is recognized as favorable on the target climate change is concern.",1 Introduction,[0],[0]
"Traditionally, this task is approached by learning a target-specific classifier that is trained for prediction on the same target of interest (Hasan and Ng, 2013; Mohammad et al., 2016; Ebrahimi et al., 2016).",1 Introduction,[0],[0]
"This implies that a new classifier has to be built from scratch on a well-prepared set of ground-truth data whenever predictions are needed for an unseen target.
",1 Introduction,[0],[0]
"An alternative to this approach is to conduct a cross-target classification, where the classifier is adapted from different but related targets (Augenstein et al., 2016), which allows benefiting from the knowledge of existing targets.",1 Introduction,[0],[0]
"For example, in our project we are interested in online users’ stances on the approvals of particular mining projects in the country.",1 Introduction,[0],[0]
"It might be useful to start with a classifier that is adapted from a related target such as climate change is concern (presumably available and annotated), as in both cases
users could discuss the impacts from the targets to some common issues, such as the environment or communities.
",1 Introduction,[0],[0]
Cross-target stance classification is a more challenging task simply because the language models may not be compatible between different targets.,1 Introduction,[0],[0]
"However, for some targets that can be recognized as being related to the same and more general domains, it could be possible to generalize through certain aspects of the domains that reflect users’ major concerns.",1 Introduction,[0],[0]
"For example, from the following sentence, whose stance is against the approval of a mining project, “Environmentalists warn the $16 billion coal facility will damage the Great Barrier Reef”, it can be seen that both this sentence and the one in Table 1 mention the same aspect “reef destruction/damage”, which is closely related to the “environment” domain.
",1 Introduction,[0],[0]
"In this paper, we focus on cross-target stance classification and explore the limits of generalizing models between different but domain-related targets1.",1 Introduction,[0],[0]
"The basic idea is to learn a set of domainspecific aspects from a source target, and then apply them to prediction on a destination target.",1 Introduction,[0],[0]
"To this end, we propose CrossNet, a novel neural model that implements the above idea based on the self-attention mechanism.",1 Introduction,[0],[0]
"Our preliminary analysis shows that the proposed model can find useful domain-specific information from a stancebearing sentence and that the classification performance is improved in certain domains.
",1 Introduction,[0],[0]
"1In this work, the source target is chosen based on common sense.",1 Introduction,[0],[0]
Exploring more sophisticated source target selection methods will be our future work.,1 Introduction,[0],[0]
"In this section, we introduce the proposed model, CrossNet, for cross-target stance classification.",2 Model,[0],[0]
Figure 1 shows the architecture of CrossNet.,2 Model,[0],[0]
It consists of four layers from the Embedding Layer (bottom) to the Prediction Layer (top).,2 Model,[0],[0]
It works by taking a stance-bearing sentence and a target as input and yielding the predicted stance label as output.,2 Model,[0],[0]
"In the following, we present the implementation of each layer in CrossNet.",2 Model,[0],[0]
"There are two inputs in CrossNet: a stance-bearing sentence P and a descriptive target T (e.g, climate change is concern in Table 1).",2.1 Embedding Layer,[0],[0]
"We use word embeddings (Mikolov et al., 2013) to represent each word in the input as a dense vector.",2.1 Embedding Layer,[0],[0]
"The output of this layer are two sequences of vectors P = {p1, ...,p|P |} and T = {t1, ..., t|T |}, where p, t are word vectors.",2.1 Embedding Layer,[0],[0]
"In this layer, we encode the contextual information in the input sentence and target.",2.2 Context Encoding Layer,[0],[0]
"We use a bi-directional Long Short-Term Memory Network (BiLSTM) (Hochreiter and Schmidhuber, 1997) to capture the left and right contexts of each word in the input.",2.2 Context Encoding Layer,[0],[0]
"Moreover, to account for the impact of the target on stance inference, we borrow the idea of conditional encoding (Augenstein et al., 2016) to model the dependency of the sentence on the target.",2.2 Context Encoding Layer,[0],[0]
"Formally, we first use a BiLSTMT to encode the target:
",2.2 Context Encoding Layer,[0],[0]
[ −→ h Ti −→c,2.2 Context Encoding Layer,[0],[0]
"Ti ] = −−−−→ LSTMT (ti, −→ h Ti−1, −→c",2.2 Context Encoding Layer,[0],[0]
Ti−1),2.2 Context Encoding Layer,[0],[0]
"[ ←− h Ti ←−c Ti ] = ←−−−− LSTMT (ti, ←− h Ti+1, ←−c Ti+1)",2.2 Context Encoding Layer,[0],[0]
"(1)
where h ∈ Rh and c ∈",2.2 Context Encoding Layer,[0],[0]
Rh are the hidden state and cell state of LSTM.,2.2 Context Encoding Layer,[0],[0]
The symbol −→(←−) indicates the forward (backward) pass.,2.2 Context Encoding Layer,[0],[0]
"ti is the input word vector at time step i.
",2.2 Context Encoding Layer,[0],[0]
"Then, we learn a conditional encoding of the sentence P , by initializing BiLSTMP (a different BiLSTM) with the final states of BiLSTMT :
",2.2 Context Encoding Layer,[0],[0]
"[ −→ h P1 −→c P1 ] = −−−−→ LSTMP (p1, −→ h",2.2 Context Encoding Layer,[0],[0]
T|T,2.2 Context Encoding Layer,[0],[0]
"|, −→c T|T",2.2 Context Encoding Layer,[0],[0]
"|)
",2.2 Context Encoding Layer,[0],[0]
"[ ←− h P|P | ←−c P|P |] = ←−−−− LSTMP (p|P |, ←− h T1 , ←−c T1 )
(2)
It can be seen that the initialization is done by aligning the forward (backward) pass of the two BiLSTMs.",2.2 Context Encoding Layer,[0],[0]
"The output is a contextually-encoded sequence, HP = {hP1 , ...,hP|P |}, where h =",2.2 Context Encoding Layer,[0],[0]
[ −→ h ; ←− h ] ∈ R2h with [; ] as the vector concatenation operation.,2.2 Context Encoding Layer,[0],[0]
"In this layer, we implement the idea of discovering domain-specific aspects for cross-target stance inference.",2.3 Aspect Attention Layer,[0],[0]
"In particular, the key observation we make is that the domain aspects that reflect users’ major concerns are usually the core of understanding their stances, and could be mentioned by multiple users in a discussion.",2.3 Aspect Attention Layer,[0],[0]
"For example, we find that many users in our corpus mention the aspect “reef” to express their concerns about the impact of a mining project on the Great Barrier Reef.",2.3 Aspect Attention Layer,[0],[0]
"Based on this observation, the perception of the domain aspects can be boiled down to finding the sentence parts that not only carry the core idea of a stance-bearing sentence but also tend to be recurring in the corpus.
",2.3 Aspect Attention Layer,[0],[0]
"First, to capture the recurrences of the domain aspects, a simple way is to make every input sentence be consumed by this layer (see Figure 1), so that the layer parameters are shared across the corpus for being stimulated by all appearances of the domain aspects.
",2.3 Aspect Attention Layer,[0],[0]
"Then, we utilize self-attention to signal the core parts of a stance-bearing sentence.",2.3 Aspect Attention Layer,[0],[0]
"Self-attention is an attention mechanism for selecting specific parts of a sequence by relating its elements at different positions (Vaswani et al., 2017; Cheng et al., 2016).",2.3 Aspect Attention Layer,[0],[0]
"In our case, the self-attention process is based on the assumption that the core parts of a sentence are those that are compatible with the semantics of the entire sentence.",2.3 Aspect Attention Layer,[0],[0]
"To this end, we introduce a compatibility function to score the semantic compatibility between the encoded se-
quence HP and each of its hidden states hP :
ci = w > 2 σ(W1h P i + b1) + b2 (3)
where W1 ∈ Rd×2h, w2 ∈ Rd, b1 ∈ Rd, and b2 ∈ R are trainable parameters, and σ is the activation function.",2.3 Aspect Attention Layer,[0],[0]
Note that all the above parameters are shared by every hidden state in HP .,2.3 Aspect Attention Layer,[0],[0]
"Next, we compute the attention weight ai for each hPi based on its compatibility score via softmax operation:
ai = exp(ci)∑|P | j=1 exp(cj)
(4)
",2.3 Aspect Attention Layer,[0],[0]
"Finally, we can obtain the domain aspect encoded representation based on the attention weights:
AP = |P |∑ i=1",2.3 Aspect Attention Layer,[0],[0]
"aih P i (5)
where AP ∈ R2h is the domain aspect encoding for sentence P and also the output of this layer.",2.3 Aspect Attention Layer,[0],[0]
"We predict the stance label of the sentence based on its domain aspect encoding:
ŷ = softmax(MLP(AP ))",2.4 Prediction Layer,[0],[0]
"(6)
where we use a multilayer perceptron (MLP) to consume the domain aspect encoding AP and apply the softmax to get the predicted probability for each of the C classes, ŷ = {y1, ..., yC}.",2.4 Prediction Layer,[0],[0]
"For model training, we use multi-class crossentropy loss,
J (θ) =",2.5 Model Training,[0],[0]
− N∑ i C∑ j y,2.5 Model Training,[0],[0]
(i) j log ŷ,2.5 Model Training,[0],[0]
(i) j,2.5 Model Training,[0],[0]
"+ λ‖Θ‖ (7)
",2.5 Model Training,[0],[0]
whereN is the size of training set.,2.5 Model Training,[0],[0]
"y is the groundtruth label indicator for each class, and ŷ is the predicted probability.",2.5 Model Training,[0],[0]
λ is the coefficient for L2regularization.,2.5 Model Training,[0],[0]
Θ denotes the set of all trainable parameters in our model.,2.5 Model Training,[0],[0]
This section reports the results of quantitative and qualitative evaluations of the proposed model.,3 Experiments,[0],[0]
SemEval-2016:,3.1 Datasets,[0],[0]
the first dataset is from SemEval2016,3.1 Datasets,[0],[0]
"Task 6 on Twitter stance detection, which contains stance-bearing tweets on different targets.",3.1 Datasets,[0],[0]
"We use the following five targets for our experiments: Climate Change is Concern (CC), Feminist Movement (FM), Hillary Clinton (HC), Legalization of Abortion (LA), and Donald Trump (DT).",3.1 Datasets,[0],[0]
"The class labels are favor, against, and neither, and their distributions are shown in Table 2.",3.1 Datasets,[0],[0]
Tweets on an Australian mining project (AM): the second is our collection of tweets on a mining project in Australia obtained using Twitter API.,3.1 Datasets,[0],[0]
"It includes 220,067 tweets posted from January 2016 to June 2017 that contain the project name in the text.",3.1 Datasets,[0],[0]
"We remove all URL-only tweets and duplicate tweets, and obtain a set of 40,852 (unlabeled) tweets.",3.1 Datasets,[0],[0]
"Due to the lack of annotation, this dataset is only used for our qualitative evaluation.
",3.1 Datasets,[0],[0]
"To align with our scenario, the above targets can be categorized into three different domains: Women’s Rights (FM, LA), American Politics (HC, DT), and Environments (CC, AM).",3.1 Datasets,[0],[0]
We use F1-score to measure the classification performance.,3.2 Metric,[0],[0]
"Due to the imbalanced class distributions of the SemEval dataset, we compute both micro-averaged (large classes dominate) and macro-averaged (small classes dominate) F1scores (Manning et al., 2008), and use their average as the metric, i.e., F = 12(Fmicro + Fmacro).
",3.2 Metric,[0],[0]
"To evaluate the effectiveness of target adaptation, we use the metric transfer ratio (Glorot et al., 2011) to compare the cross-target and in-target performance of a model: Q = F (S,D)Fb(D,D) , where F (S,D) is the cross-target F1-score of a model trained on the source target S and tested on the destination target D, and Fb(D,D) is the in-target F1-score of a baseline model trained and tested on the same target D, which serves as the performance calibration for target adaptation.",3.2 Metric,[0],[0]
"The word embeddings are initialized with the pretrained 200d GloVe word vectors on the 27B Twitter corpus (Pennington et al., 2014), and fixed during training.",3.3 Training setup,[0],[0]
"The model is trained (90%) and validated (10%) on a source target, and tested on a destination target.",3.3 Training setup,[0],[0]
"The following model settings are selected based on a small grid search on the validation set: the LSTM hidden size of 60, the MLP layer size of 60, and dropout 0.1.",3.3 Training setup,[0],[0]
The L2-regularization coefficient λ in the loss is 0.01.,3.3 Training setup,[0],[0]
"ADAM (Kingma and Ba, 2014) is used as the optimizer, with a learning rate of 10−3.",3.3 Training setup,[0],[0]
Stratified 10-fold cross-validation is conducted to produce averaged results.,3.3 Training setup,[0],[0]
This section reports the results of our model and two baseline approaches on cross-target stance classification.,3.4 Classification Performance,[0],[0]
BiLSTM:,3.4 Classification Performance,[0],[0]
this is a base model for our task.,3.4 Classification Performance,[0],[0]
It has two BiLSTMs for encoding the sentence and target separately.,3.4 Classification Performance,[0],[0]
"Then, the concatenation of the resulting encodings is fed into the final Prediction Layer to generate predicted stance labels.",3.4 Classification Performance,[0],[0]
"In our evaluation, this model is treated as the baseline model for deriving the in-target performance calibration Fb(D,D).",3.4 Classification Performance,[0],[0]
"MITRE (Augenstein et al., 2016):",3.4 Classification Performance,[0],[0]
"this is the
best system in SemEval-2016 Task 6.",3.4 Classification Performance,[0],[0]
It utilizes the conditional encoding to learn a targetdependent representation for the input sentence.,3.4 Classification Performance,[0],[0]
"The conditional encoding is realized in the same way as the Context Encoding Layer does in our model, namely by using the hidden states of the target-encoding BiLSTM to initialize the sentence-encoding BiLSTM.
Table 3 shows the results (in-target and crosstarget) on the two domains: Women’s Rights and American Politics.",3.4 Classification Performance,[0],[0]
"First, it is observed that MITRE outperforms BiLSTM over all target configurations, suggesting that, compared to simple concatenation, the conditional encoding of the target information could be more helpful to capture the dependency of the sentence on the target.
",3.4 Classification Performance,[0],[0]
"Second, our model is shown to achieve better results than the two baselines in almost all cases (only slightly worse than MITRE on LA under the in-target setting, and the difference is not statistically significant), which implies that the aspect attention mechanism adopted in our model could benefit target-level generalization while it does not hurt the in-target performance.",3.4 Classification Performance,[0],[0]
"Moreover, by comparing the performance of our model under different target configurations, we see that the improvements brought by our model are more significant on the cross-target task than they are on the intarget task, with an average improvement of 6.6% (cross-target) vs. 3.0% (in-target) over MITRE in F1-score, which demonstrates a greater advantage of our model in the cross-target task.
",3.4 Classification Performance,[0],[0]
"Finally, according to the transfer ratio results, the general drop from the in-target to cross-target performance (26% averaged over all cases) could imply that while the target-independent information (i.e., the domain-specific aspects) is shown to benefit generalization, it could be important to also consider the information that is specific to the destination target for model building (which has not yet been explored in this work).",3.4 Classification Performance,[0],[0]
"To show that our model can select sentence parts that are related to domain aspects, we visualize the self-attention results on some tweet examples that are correctly classified by our model in Table 4.
",3.5 Visualization of Attention,[0],[0]
We can see that the most highlighted parts in each example are relevant to the respective domain.,3.5 Visualization of Attention,[0],[0]
"For example, “feminist”, “rights”, and “equality” are commonly used when talking about women’s rights, and “president” and “dreams” of-
ten appear in text about politics.",3.5 Visualization of Attention,[0],[0]
"It is also interesting to note that words that are specific to the destination target may not be captured by the model learned from the source target, such as “abortion” in sentence 1 and “trumps” in sentence 3.",3.5 Visualization of Attention,[0],[0]
"This makes sense because those words are rare in the source target corpus and thus not well noticed by the model.
",3.5 Visualization of Attention,[0],[0]
"Finally, for our project, we can see from the last two sentences that the model learned from climate change is concern is able to concentrate on words that are central to understanding the authors’ stances on the approval of the mining project, such as “reef”, “destroy”, “environmental”, and “disaster”.",3.5 Visualization of Attention,[0],[0]
"Overall, the above visualization demonstrates that our model could benefit stance inference across related targets through capturing domain-specific information.",3.5 Visualization of Attention,[0],[0]
"Finally, it is also possible to show the learned domain aspects by extracting all sentence parts in a corpus that are highly attended by our model.",3.6 Learned Domain-Specific Aspects,[0],[0]
Table 5 presents a number of samples from the intersections between the sets of highly-attended words on the respective targets in the three domains.,3.6 Learned Domain-Specific Aspects,[0],[0]
"Again, we see that these highly-attended words are specific to the respective domains.",3.6 Learned Domain-Specific Aspects,[0],[0]
"We
also notice that besides the domain-aspect words, our model can find words that carry sentiments as well, such as “great”, “crazy”, and “beautiful”, which contribute to stance prediction.",3.6 Learned Domain-Specific Aspects,[0],[0]
"In this work, we study cross-target stance classification and propose a novel self-attention neural model that can extract target-independent information for model generalization.",4 Conclusion and Future Work,[0],[0]
Experimental results show that the proposed model can perceive high-level domain-specific information in a sentence and achieves superior results over a number of baselines in certain domains.,4 Conclusion and Future Work,[0],[0]
"In the future, there are several ways of extending our model.
",4 Conclusion and Future Work,[0],[0]
"First, selecting the effective source targets to generalize from is crucial for achieving satisfying results on the destination targets.",4 Conclusion and Future Work,[0],[0]
"One possibility could be to learn certain correlations between target closeness and generalization performance, which could further be used for guiding the target selection process.",4 Conclusion and Future Work,[0],[0]
"Second, our current model for identifying users’ stances on mining projects only generalizes from one source target (i.e., Climate Change is Concern).",4 Conclusion and Future Work,[0],[0]
"However, a mining project in general could affect other aspects of our society such as community and economics.",4 Conclusion and Future Work,[0],[0]
It could be useful to also consider other related sources for knowledge transfer.,4 Conclusion and Future Work,[0],[0]
"Finally, it would be interesting to evaluate our model in a multilingual scenario (Taulé et al., 2017), in order to examine its generalization ability (whether it can attend to useful domain-specific information in a new language) and multilingual scope.",4 Conclusion and Future Work,[0],[0]
We thank all anonymous reviewers for their valuable comments.,Acknowledgments,[0],[0]
We would also like to thank Keith Vander Linden for his helpful comments on drafts of this paper.,Acknowledgments,[0],[0]
"In stance classification, the target on which the stance is made defines the boundary of the task, and a classifier is usually trained for prediction on the same target.",abstractText,[0],[0]
"In this work, we explore the potential for generalizing classifiers between different targets, and propose a neural model that can apply what has been learned from a source target to a destination target.",abstractText,[0],[0]
We show that our model can find useful information shared between relevant targets which improves generalization in certain scenarios.,abstractText,[0],[0]
Cross-Target Stance Classification with Self-Attention Networks,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3664–3674 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
3664",text,[0],[0]
Information retrieval and question answering are by now mature technologies that excel at answering factual queries on noncontroversial topics.,1 Introduction,[0],[0]
"However, they provide no specialized support for queries where there is no single canonical answer, as with topics that are controversial or opinion-based.",1 Introduction,[0],[0]
"For such queries, the user may need to carefully assess the stance, source, and supportability for each of the answers.",1 Introduction,[0],[0]
"These processes can be supported by argument mining (AM), a nascent area of natural language processing concerned with the automatic recognition and interpretation of arguments.",1 Introduction,[0],[0]
"In this paper, we apply AM to the task of argument search—that is, searching a large document collection for arguments relevant to a given topic.",1 Introduction,[0],[0]
"Searching for and classifying relevant arguments plays an important role in decision making (Svenson, 1979), legal reasoning (Wyner et al., 2010), and
the critical reading, writing, and summarization of persuasive texts (Kobayashi, 2009; Wingate, 2012).",1 Introduction,[0],[0]
"Automating the argument search process could ease much of the manual effort involved in these tasks, particularly if it can be made to robustly handle arguments from different text types and topics.",1 Introduction,[0],[0]
"But despite its obvious usefulness, this sort of argument search has attracted little attention in the research community.",1 Introduction,[0],[0]
"This may be due in part to the limitations of the underlying models and training resources, particularly as they relate to heterogeneous sources.",1 Introduction,[0],[0]
"That is, most current approaches to AM are designed for use with particular text types, faring poorly when applied to new data (Daxenberger et al., 2017).",1 Introduction,[0],[0]
"Indeed, as Habernal et al. (2014) observe, while there is a great diversity of perspectives on how arguments can be best characterized and modelled, there is no “one-size-fits-all” argumentation theory that applies to the variety of text sources found on the Web.",1 Introduction,[0],[0]
"To approach these challenges, we propose the novel task of topic-based sentential argument mining.",1 Introduction,[0],[0]
Our contributions are as follows: (1) We propose a new argument annotation scheme applicable to the information-seeking perspective of argument search.,1 Introduction,[0],[0]
"We show it to be general enough for use on heterogeneous data sources, and simple enough to be applied manually by untrained annotators at a reasonable cost.",1 Introduction,[0],[0]
"(2) We introduce a novel corpus of heterogeneous text types annotated with topic-based arguments.1 The corpus includes over 25,000 instances covering eight controversial topics.",1 Introduction,[0],[0]
This is the first known resource that can be used to evaluate the performance of argument mining methods across topics in heterogeneous sources.,1 Introduction,[0],[0]
"(3) We investigate different approaches for incorporating topic information into neural networks and
1https://www.ukp.tu-darmstadt.de/sent_am
show that including the topic vector into the i- and c-gates of the LSTM cell outperforms common attention-based approaches in two- and three-label cross-topic experiments.",1 Introduction,[0],[0]
(4) We further improve the performance of the modified LSTM cell by leveraging additional data for topic relevance in a multi-task learning setup.,1 Introduction,[0],[0]
"(5) In the more challenging setup of cross-topic experiments, we show that our models yield considerably better performance than common BiLSTM models when little data of the target topic is available.",1 Introduction,[0],[0]
"Most existing approaches treat argument mining at the discourse level, focusing on tasks such as segmenting argumentative discourse units (Ajjour et al., 2017; Goudas et al., 2014), classifying the function of argumentative discourse units (for example, as claims or premises) (Mochales-Palau and Moens, 2009; Stab and Gurevych, 2014), and recognizing argumentative discourse relations (Eger et al., 2017; Stab and Gurevych, 2017; Nguyen and Litman, 2016).",2 Related work,[0],[0]
"These discourse-level approaches address the identification of argumentative structures within a single document but do not consider relevance to externally defined topics.
",2 Related work,[0],[0]
"To date, there has been little research on the identification of topic-relevant arguments for argument search.",2 Related work,[0],[0]
Wachsmuth et al. (2017) present a generic argument search framework.,2 Related work,[0],[0]
"However, it relies on already-structured arguments from debate portals and is not yet able to retrieve arguments from arbitrary texts.",2 Related work,[0],[0]
"Levy et al. (2014) investigate the identification of topic-relevant claims, an approach that was later extended with evidence extraction to mine supporting statements for claims (Rinott et al., 2015).",2 Related work,[0],[0]
"However, both approaches are designed to mine arguments from Wikipedia articles; it is unclear whether their annotation scheme is applicable to other text types.",2 Related work,[0],[0]
"It is also uncertain that it can be easily and accurately applied by untrained annotators, since it requires unitizing (i.e., finding the boundaries of argument components at the token level).",2 Related work,[0],[0]
Hua and Wang (2017) identify sentences in cited documents that have been used by an editor to formulate an argument.,2 Related work,[0],[0]
"By contrast, we do not limit our approach to the identification of sentences related to a given argument, but rather focus on the retrieval of any argument relevant to a given topic.",2 Related work,[0],[0]
"The fact that we are concerned with retrieval of arguments also sets our work apart from
the discourse-agnostic stance detection task of Mohammad et al. (2016), which is concerned with the identification of sentences expressing support or opposition to a given topic, irrespective of whether those sentences contain supporting evidence (as opposed to mere statements of opinion).
",2 Related work,[0],[0]
"Cross-domain AM experiments have so far been conducted only for discourse-level tasks such as claim identification (Daxenberger et al., 2017), argumentative segment identification (Al-Khatib et al., 2016), and argumentative unit segmentation (Ajjour et al., 2017).",2 Related work,[0],[0]
"However, the discourse-level argumentation models these studies employ seem to be highly dependent on the text types for which they were designed; they do not work well when applied to other text types (Daxenberger et al., 2017).",2 Related work,[0],[0]
The crucial difference between our own work and prior cross-domain experiments is that we investigate AM from heterogeneous texts across different topics instead of studying specific discourse-level AM tasks across restricted text types of existing corpora.,2 Related work,[0],[0]
"There exists a great diversity in models of argumentation, which differ in their perspective, complexity, terminology, and intended applications (Bentahar et al., 2010).",3 Corpus creation,[0],[0]
"For the present study, we propose a model which, though simplistic, is nonetheless well-suited to the argument search scenario.",3 Corpus creation,[0],[0]
We define an argument as a span of text expressing evidence or reasoning that can be used to either support or oppose a given topic.,3 Corpus creation,[0],[0]
"An argument need not be “direct” or self-contained—it may presuppose some common or domain knowledge, or the application of commonsense reasoning—but it must be unambiguous in its orientation to the topic.",3 Corpus creation,[0],[0]
"A topic, in turn, is some matter of controversy for which there is an obvious polarity to the possible outcomes—that is, a question of being either for or against the use or adoption of something, the commitment to some course of action, etc.",3 Corpus creation,[0],[0]
"In some graph-based models of argumentation (Stab, 2017, Ch. 2), what we refer to as a topic would be part of a (major) claim expressing a positive or negative stance, and our arguments would be premises with supporting/attacking consequence relations to the claim.",3 Corpus creation,[0],[0]
"However, unlike these models, which are typically used to represent (potentially deep or complex) argument structures at the discourse level, ours is a flat model that considers arguments in isolation from their surrounding context.",3 Corpus creation,[0],[0]
"A great
advantage of this approach is that it allows annotators to classify text spans without having to read large amounts of context and without having to consider relations to other topics or arguments.",3 Corpus creation,[0],[0]
"In this work, we consider only those topics that can be concisely and implicitly expressed through keywords, and those arguments that consist of individual sentences.",3 Corpus creation,[0],[0]
"Some examples, drawn from our dataset, are shown in Table 1.",3 Corpus creation,[0],[0]
"Note that while the fourth example expresses opposition to the topic, under our definition it is properly classified as a non-argument because it is a mere statement of stance that provides no evidence or reasoning.
",3 Corpus creation,[0],[0]
Data.,3 Corpus creation,[0],[0]
For our experiments we gathered a large collection of manually annotated arguments that cover a variety of topics and that come from a variety of text types.,3 Corpus creation,[0],[0]
"We started by randomly selecting eight topics (see Table 2) from online lists of controversial topics.2 For each topic, we made a Google query for the topic name, removed results not archived by the Wayback Machine,3 and truncated the list to the top 50 results.",3 Corpus creation,[0],[0]
"This resulted in a set of persistent, topic-relevant, largely polemical Web documents representing a range of genres and text types, including news reports, editorials, blogs, debate forums, and encyclopedia articles.",3 Corpus creation,[0],[0]
"We preprocessed each document with Apache Tika (Mattmann and Zitting, 2011) to remove boilerplate text.",3 Corpus creation,[0],[0]
"We then used the Stanford CoreNLP tools (Manning et al., 2014) to perform tokenization, sentence segmentation, and part-ofspeech tagging on the remaining text, and removed all sentences without verbs or with less than three tokens.",3 Corpus creation,[0],[0]
"This left us with a raw dataset of 27,520 sentences (about 2,700 to 4,400 per topic).",3 Corpus creation,[0],[0]
"Annotators classified the sentences using a browser-based interface that presents a set of in2https://www.questia.com/library/ controversial-topics, https://www.procon.org/ 3https://web.archive.org/
structions, a topic, a list of sentences, and amultiplechoice form for specifying whether each sentence is a supporting argument, an opposing argument, or not an argument with respect to the topic.",3 Corpus creation,[0],[0]
"(In preliminary experiments, we presented annotators with a fourth option for sentences that are ambiguous or incomprehensible.",3 Corpus creation,[0],[0]
"However, we found that these constituted less than 1% of the distribution and so mapped all such answers to the “no argument” class.)
",3 Corpus creation,[0],[0]
Annotation experiments.,3 Corpus creation,[0],[0]
"We tested the applicability of our annotation scheme by untrained annotators by performing an experiment where we had a group of “expert” annotators and a group of untrained annotators classify the same set of sentences, and then compared the two groups’ classifications.",3 Corpus creation,[0],[0]
The data for this experiment consisted of 200 sentences randomly selected from each of our eight topics.,3 Corpus creation,[0],[0]
Our expert annotators were two graduatelevel language technology researchers who were fully briefed on the nature and purpose of the argument model.,3 Corpus creation,[0],[0]
Our untrained annotators were anonymous American workers from the Amazon Mechanical Turk (AMT) crowdsourcing platform.,3 Corpus creation,[0],[0]
"Each sentence was independently annotated by the two expert annotators and ten crowd workers.
",3 Corpus creation,[0],[0]
"Inter-annotator agreement for our two experts, as measured by Cohen’s κ, was 0.721; this exceeds the commonly used threshold of 0.7 for assuming the results are reliable (Carletta, 1996).",3 Corpus creation,[0],[0]
"We proceeded by having the two experts resolve their disagreements, resulting in a set of “expert” gold-standard annotations.",3 Corpus creation,[0],[0]
"Similar gold standards were produced for the crowd annotations by applying the MACE denoising tool (Hovy et al., 2013); we tested various thresholds (1.0, 0.9, and 0.8) to discard instances that could be confidently assigned a gold label.",3 Corpus creation,[0],[0]
We then calculated κ between the remaining instances in the expert and crowd gold standards.,3 Corpus creation,[0],[0]
"In order to
determine the relationship between inter-annotator agreement and the number of crowd workers, we performed this procedure with successively lower numbers of crowd workers, going from the original ten annotators per instance down to two.",3 Corpus creation,[0],[0]
The results are visualized in Fig. 1.,3 Corpus creation,[0],[0]
We found that using seven annotators and a MACE threshold of 0.9 results in κ = 0.723; this gives us similar reliability as with the expert annotators without sacrificing much coverage.,3 Corpus creation,[0],[0]
"Table 3 shows the κ and percentage agreement for this setup, as well as the agreement between our expert annotators, broken down by topic.",3 Corpus creation,[0],[0]
"We proceeded with annotating the remaining instances in our dataset using seven crowd workers each, paying a rate corresponding to the US federal minimum wage of $7.25/hour.",3 Corpus creation,[0],[0]
"Our total expenditure, including AMT processing fees, was $2,774.02.",3 Corpus creation,[0],[0]
"After MACE denoising, we were left with 25,492 gold-standard annotations.",3 Corpus creation,[0],[0]
Table 2 provides statistics on the size and class distribution of the final corpus.,3 Corpus creation,[0],[0]
"We are releasing the gold-standard annotations for this dataset, and code for retrieving
the original sentences from the Wayback Machine, under a Creative Commons licence.",3 Corpus creation,[0],[0]
We model the identification of arguments as a sentence-level classification task.,4 Approaches for identifying arguments,[0],[0]
"In particular, given a sentence ς with words u1, . . .",4 Approaches for identifying arguments,[0],[0]
",unς and a topic τ of words v1, . . .",4 Approaches for identifying arguments,[0],[0]
", vnτ (e.g., “gun control” or “school uniforms”), we aim to classify ς",4 Approaches for identifying arguments,[0],[0]
"as a “supporting argument” or “opposing argument” if it includes a relevant reason for supporting or opposing the τ , or as a “non-argument” if it does not include a reason or is not relevant to τ .",4 Approaches for identifying arguments,[0],[0]
We also investigate a two-label classification where we combine supporting and opposing arguments into a single category; this allows us to evaluate argument classification independent of stance.,4 Approaches for identifying arguments,[0],[0]
"We focus on the challenging task of cross-topic experiments, where one topic is withheld from the training data and used for testing.",4 Approaches for identifying arguments,[0],[0]
"Here, we denote scalars by italic lowercase letters (e.g., t), vector representations by italic bold lowercase letters (e.g., c), and matrices as italic bold uppercase letters (e.g.,W ).",4 Approaches for identifying arguments,[0],[0]
"Since arguments need to be relevant to the given topic, we posit that providing topic information to the learner results in a more robust prediction capability in cross-topic setups.",4.1 Integrating topic information,[0],[0]
"Below, we present two models that integrate the topic, one that uses an attention mechanism and another that includes the topic vector directly in the LSTM cell.
",4.1 Integrating topic information,[0],[0]
Outer-attention BiLSTM (outer-att).,4.1 Integrating topic information,[0],[0]
"To let the model learn which parts of the sentence are relevant (or irrelevant) to the given topic, we use an attentionbased neural network (Bahdanau et al., 2014) that learns an importance weighting of the input words depending on the given topic.",4.1 Integrating topic information,[0],[0]
"In particular, we adopt an outer-attention mechanism similar to the one proposed by Hermann et al. (2015), which has achieved state-of-the-art results in related tasks such as natural language inference and recognizing textual entailment (Rocktäschel et al., 2015; Wang and Jiang, 2016).",4.1 Integrating topic information,[0],[0]
"We combine the attention mechanism with a common BiLSTM model and, at time step t, determine the importance weighting for each hidden state h(t) as
m(t) = tanh(W hh(t)",4.1 Integrating topic information,[0],[0]
"+W pp) (1)
fattention(h(t),p) = exp(wTmm(t))∑ t exp(wTmm(t))
",4.1 Integrating topic information,[0],[0]
"(2)
whereW h,W p, andwm are trainable parameters of the attention mechanism and p is the average of all word embeddings of topic words v1, . .",4.1 Integrating topic information,[0],[0]
.,4.1 Integrating topic information,[0],[0]
", vnτ .",4.1 Integrating topic information,[0],[0]
"Using the importance weighting, we determine the final, weighted hidden output state s as
αt ∝ fattention(h(t),p) (3) s = n∑ t=1",4.1 Integrating topic information,[0],[0]
h(t)αt .,4.1 Integrating topic information,[0],[0]
"(4)
Finally, we feed s into a dense layer with a softmax activation function to get predictions for our twoor three-label setups.
",4.1 Integrating topic information,[0],[0]
Contextual BiLSTM (biclstm).,4.1 Integrating topic information,[0],[0]
"A more direct approach to integrating an argument’s topic is the contextual LSTM (CLSTM) architecture (Ghosh et al., 2016), where topic information is added as another term to all four gates of an LSTM cell.",4.1 Integrating topic information,[0],[0]
"We, however, hypothesize that topic information is more relevant at the i- and c-gates, the former because it has the biggest impact on how a new token is processed and the latter because it is closely linked
to how the sequence seen so far is to be interpreted and stored.",4.1 Integrating topic information,[0],[0]
"To this end, we experimented with severalmodifications to the original CLSTMsuch as removing peepholes—i.e., removing gates’ access to the cell state c",4.1 Integrating topic information,[0],[0]
"(Gers and Schmidhuber, 2000)— and removing topic information from one or more gates.",4.1 Integrating topic information,[0],[0]
"Empirical results on the validation set show that topic integration at the i- and c-gates only, and removal of all peephole connections, does indeed outperform the original CLSTM on our task by 1 percentage point.",4.1 Integrating topic information,[0],[0]
"Our modified CLSTM (Fig. 2) is defined as
i t = σ(W xi x t",4.1 Integrating topic information,[0],[0]
+,4.1 Integrating topic information,[0],[0]
"W hiht−1 + bi + Wpi p ) (5)
f t = σ(W x f x t",4.1 Integrating topic information,[0],[0]
+W h f ht−1 + b f ),4.1 Integrating topic information,[0],[0]
"(6) ct = f tct−1 + i tσc(W xc x t +W hcht−1
+bc + Wpc p ) (7)
ot = σ(W xox t",4.1 Integrating topic information,[0],[0]
+,4.1 Integrating topic information,[0],[0]
W hoht−1 + bo) (8) ht = otσc(ct ).,4.1 Integrating topic information,[0],[0]
"(9)
Here i , f , and o represent the input, forget, and output gates; c the cell memory; x t the embedded token of a sentence at timestep t; ht−1 the previous hidden state; and b the bias.",4.1 Integrating topic information,[0],[0]
σ,4.1 Integrating topic information,[0],[0]
"and σc are the activation and recurrent activation functions, respectively.",4.1 Integrating topic information,[0],[0]
The novel terms for topic integration are outlined.,4.1 Integrating topic information,[0],[0]
"We use this model bidirectionally, as we did with our BiLSTM network, and hence refer to it as biclstm.",4.1 Integrating topic information,[0],[0]
"As we want to classify arguments related to specific topics, leveraging information that supports the classifier in the decision of topic-relation is crucial.",4.2 Leveraging additional data,[0],[0]
The multi-task learning (mtl) and transfer learning (trl) models are able to make use of auxiliary data that can potentially improve the results on the main task.,4.2 Leveraging additional data,[0],[0]
"Thus, we extend our previously described models by integrating them into mtl and trl setups.",4.2 Leveraging additional data,[0],[0]
"We also choose to integrate two corpora
from which we expect to learn (a) topic-relevance and (b) the capability to distinguish between supporting and attacking arguments.",4.2 Leveraging additional data,[0],[0]
"The first corpus, DIP2016 (Habernal et al., 2016), consists of 49 queries from the educational domain and 100 documents for each query.",4.2 Leveraging additional data,[0],[0]
Each document has its sentences annotated for relevance (true/false) to the query.4,4.2 Leveraging additional data,[0],[0]
"The second corpus, from SemEval-2016 Task 6 (Mohammad et al., 2016), consists of around 5000 multi-sentence tweets, a corresponding topic (e.g., “atheism”), and the author’s stance on the topic (for/against/neither).
",4.2 Leveraging additional data,[0],[0]
"For our mtl and trl approaches, we consider every possible pairing of a model (biclstm, outer-att, and the bilstm baseline we introduce in §5) with an auxiliary corpus (DIP2016, SemEval).",4.2 Leveraging additional data,[0],[0]
"We formalize our datasets as Sk = {(xki ,pki , yki )|i = 0, . . .",4.2 Leveraging additional data,[0],[0]
", |Sk |}, where k can be either our main dataset or an auxiliary dataset, xki denotes a single sentence as a sequence of word embeddings and yki its corresponding label in k, and pki represents the corresponding averaged topic vector.
",4.2 Leveraging additional data,[0],[0]
Transfer learning (trl).,4.2 Leveraging additional data,[0],[0]
"For trl, we use the approach of parameter transfer (Pan andYang, 2010)— i.e., we do not modify the model used.",4.2 Leveraging additional data,[0],[0]
"Instead, we train the model twice: the first time, we train the model on the chosen auxiliary corpus, and the second time, we keep the trained model’s weights and train it with our own corpus.",4.2 Leveraging additional data,[0],[0]
"For the threelabel setting, we have to modify the transfer model slightly for the DIP2016 corpus, since it provides only two labels for each training sample.",4.2 Leveraging additional data,[0],[0]
"In this case, we simply add a layer with two neurons on top of the layer with three neurons for training with the DIP2016 corpus and remove it afterwards for training with our corpus.
4We only use 300K of the corpus’s 600K samples to ease hyperparameter tuning for our computation-heavy models.
",4.2 Leveraging additional data,[0],[0]
Multi-task learning (mtl).,4.2 Leveraging additional data,[0],[0]
"For mtl, we use a shared–private model (Liu et al., 2017), which showed promising results for text classification and word segmentation (Chen et al., 2017).",4.2 Leveraging additional data,[0],[0]
"(We also experimented with their adversarial approach to learn topic-invariant features, but abandoned this due to low scores.)",4.2 Leveraging additional data,[0],[0]
"The mtl base model consists of a private recurrent neural network (RNN) for both the auxiliary dataset and our dataset, plus a shared RNN that both datasets use (Fig. 3).",4.2 Leveraging additional data,[0],[0]
The last hidden states of the RNNs are concatenated and fed through a dense layer and a softmax activation function.,4.2 Leveraging additional data,[0],[0]
"The model is trained in an alternating fashion—i.e., after each epoch the loss for the other dataset is minimized until each dataset has run for the set number of epochs, where the last epoch is always executed on our dataset.",4.2 Leveraging additional data,[0],[0]
"At prediction time, only the private RNN trained on our dataset and the shared RNN are used.",4.2 Leveraging additional data,[0],[0]
"The core idea is that the shared RNN learns what is relevant for both tasks, while the private ones learn only the task-specific knowledge.
",4.2 Leveraging additional data,[0],[0]
"For the cases of mtl+bilstm+corpus, mtl+biclstm+ corpus, and mtl+outer-att+corpus, we simply switch the RNN with our bilstm, biclstm, and outer-att, respectively.",4.2 Leveraging additional data,[0],[0]
"For mtl+outer-att+corpus, we add the outer attention mechanism (see §4.1), modified for use with the mtl model, after each of the private RNNs, while additionally feeding it a second topic vector—the last hidden state of the shared RNN:
m(t) =",4.2 Leveraging additional data,[0],[0]
tanh(W rhr (t) +,4.2 Leveraging additional data,[0],[0]
W shs,4.2 Leveraging additional data,[0],[0]
"+W pp) (10) fattention(hr (t),hs,p) = exp(wTmm(t))∑ t exp(wTmm(t))",4.2 Leveraging additional data,[0],[0]
"(11)
",4.2 Leveraging additional data,[0],[0]
αt ∝,4.2 Leveraging additional data,[0],[0]
"fattention(hr (t),hs,p) (12)
s = n∑ t=1 hr (t)αt (13)
",4.2 Leveraging additional data,[0],[0]
"whereW r ,W s, andW p are trainable weight matrices, hr (t) is the hidden state of the private bilstm at timestep t, hs is the last hidden state of the shared model, and p is the average of all word embeddings of topic words v1, . . .",4.2 Leveraging additional data,[0],[0]
", vnτ .",4.2 Leveraging additional data,[0],[0]
"To evaluate the robustness of the models, we conduct cross-topic experiments to evaluate how well the models generalize to an unknown topic.",5 Evaluation,[0],[0]
"To this end, we combine training (70%) and validation
data (10%) of seven topics for training and parameter tuning, and use the test data (20%) of the eighth topic for testing.",5 Evaluation,[0],[0]
"For encoding the words of sentence ς and topic τ , we use 300-dimensional word embeddings trained on the Google News dataset by Mikolov et al. (2013).",5 Evaluation,[0],[0]
"To handle out-of-vocabulary words, we create separate random word vectors for each.5 Since reporting single performance scores is insufficient to compare non-deterministic learning approaches like neural networks (Reimers and Gurevych, 2017), we report all results as averages over ten runs with different random seeds.",5 Evaluation,[0],[0]
"As evaluation measures, we report the average macro F1, as well as the precision and the recall for the argument class (Parg, Rarg).",5 Evaluation,[0],[0]
"For the three-label approach, we split the precision and recall for predicting supporting (Parg+, Rarg+) and attacking arguments (Parg−, Rarg−).",5 Evaluation,[0],[0]
"As baselines, we use a simple bidirectional LSTM (Hochreiter and Schmidhuber, 1997), as well as a logistic regression model with lowercased unigram features, which has been shown to be a strong baseline for various other AM tasks (Daxenberger et al., 2017; Stab and Gurevych, 2017).",5 Evaluation,[0],[0]
"We refer to these models as bilstm and lr-uni, respectively.",5 Evaluation,[0],[0]
"All neural networks are trained using the Adam optimizer (Kingma and Ba, 2015) and cross-entropy loss function.",5 Evaluation,[0],[0]
"For finding the best model, we run each for ten epochs and take the best model based on the lowest validation loss.",5 Evaluation,[0],[0]
"In addition to that, we tune the hyperparameters of all
5Each dimension is set to a random number between −0.01 and 0.01.",5 Evaluation,[0],[0]
"Digits are mapped to the same random word vector.
neural networks (see Appendix A).",5 Evaluation,[0],[0]
"To accelerate training, we truncate sentences at 60 words.6",5 Evaluation,[0],[0]
Two-label setup.,5.1 Results,[0],[0]
The results in Table 4 show that all our models outperform the baselines for two-label prediction.7 F1 for biclstm improves by 3.5 percentage points over the bilstm baseline and by 5.6 over lr-uni.,5.1 Results,[0],[0]
A main reason for this proves to be the substantial increase in recall for our topic-integrating models—outer-att and especially biclstm—in comparison to our baselines.,5.1 Results,[0],[0]
These results show that knowledge of the argument’s topic has a strong impact on argument prediction capability.,5.1 Results,[0],[0]
"Further, we observe that integrating biclstm in a multi-task learning setup in order to draw knowledge about topic relevance from the DIP2016 corpus (mtl+biclstm+dip2016) improves F1 by an additional 2.5 percentage points.",5.1 Results,[0],[0]
"It achieves an F1 of 0.6662, which is 19.48 percentage points less than the human upper bound of 0.861.",5.1 Results,[0],[0]
"When using the SemEval corpus, which holds less task-relevant knowledge for our two-label approach, we are able to gain only 1 percentage point when integrating it into mtl+biclstm+corpus.
",5.1 Results,[0],[0]
"For the transfer learning models that integrate the topic (tr+biclstm+corpus and tr+outer-att+corpus), the parameter transfer is mostly ineffective.",5.1 Results,[0],[0]
"If no topic is provided (tr+bilstm+corpus), the transfer learning models are able to improve over the baseline bilstm.",5.1 Results,[0],[0]
"This shows that the parameter transfer
6Only 244 of our sentences (<1%) exceed this length.",5.1 Results,[0],[0]
"7Detailed results per topic are given in Appendix B.
itself can be of use, but confuses the model when combined with topic integration.
",5.1 Results,[0],[0]
"In general, we observe an overall lower score for trl models that use the DIP2016 corpus compared to those using the SemEval corpus.",5.1 Results,[0],[0]
"In contrast to the mtl model, for trl models all parameters are transferred to the main task, not just parameters that represent shared knowledge.",5.1 Results,[0],[0]
"Thus, we suspect the lower scores of the trl models with DIP2016 are due to overfitting on the vast number of samples which shape the parameters much more than the comparatively small SemEval corpus could.
",5.1 Results,[0],[0]
Three-label setup.,5.1 Results,[0],[0]
"For the three-label approach, we observe overall lower scores due to the additional difficulty in distinguishing supporting from opposing arguments.",5.1 Results,[0],[0]
"As already observed in the two-label setup, biclstm outperforms both the bilstm and lr-uni baselines; here, the former by 4.5 and the latter by 4.2 percentage points in F1.",5.1 Results,[0],[0]
"Again, this is caused by a substantial increase in recall and shows the impact that the available topic information has on the classifier’s predictive power.",5.1 Results,[0],[0]
"For transfer learning, we see similar results as for the two-label approach; both the DIP2016 and SemEval corpora have a generally negative impact when compared to the respective base models.",5.1 Results,[0],[0]
The SemEval corpus does not provide the knowledge required to distinguish supporting from attacking arguments.,5.1 Results,[0],[0]
"We conclude that the original purpose of the SemEval task, stance recognition, is too different from our own.",5.1 Results,[0],[0]
"But in multi-task learning, where only the shared parameters are taken, we observe slight improvements when using biclstm with DIP2016; this correlates with the same model in the two-label setup.",5.1 Results,[0],[0]
"To understand the errors of our best model, mtlbiclstm-dip, and the nature of this task, we manually analyzed 100 sentences randomly sampled from the false positive and false negative arguments of the three-label experiments (combining supporting and attacking arguments).",5.2 Error analysis,[0],[0]
"Among the false positives, we found 48 off-topic sentences that were wrongly classified as arguments.",5.2 Error analysis,[0],[0]
The 52 on-topic false positives consist of non-argumentative background information or mere opinions without evidence (as with the first and fourth examples of Table 1) and questions about the topic.,5.2 Error analysis,[0],[0]
"Among the false negatives, we found 65 arguments that did not explicitly refer to the topic but to related aspects that
depend on background knowledge.",5.2 Error analysis,[0],[0]
"For instance, the model fails to establish an argumentative link between the topic “gun control” and the Second Amendment to the US Constitution.",5.2 Error analysis,[0],[0]
"Lastly, we inspected arguments that are incorrectly classified as supporting and/or opposing a topic.",5.2 Error analysis,[0],[0]
We found several samples in which the term “against” is not correctly interpreted and the argument is classified as supporting a topic.,5.2 Error analysis,[0],[0]
"Similarly, for arguments incorrectly classified as attacking, we find various samples where the word “oppose” is used not to oppose the topic but to strengthen a supporting argument, as in “There is reason even for people who oppose the use of marijuana to support its legalization. . . ”",5.2 Error analysis,[0],[0]
"To evaluate the performance of the models in datascarce scenarios, we gradually add target topic data to the training data and analyze the model performance on the target test set.",5.3 Adapting to new topics,[0],[0]
"Figure 4 shows model performance (F1, Parg, and Rarg) on the “marijuana legalization” topicwhen adding different amounts of randomly sampled topic-specific data to the training data (x-axes).8",5.3 Adapting to new topics,[0],[0]
"As the results show, the models that integrate the topic achieve higher recall when adding target topic data to the training data.",5.3 Adapting to new topics,[0],[0]
"For bilstm, we observe a drastic difference when compared to the other models; the recall for arguments stays at around 30% and rises only when integrating more than 60% target topic data.",5.3 Adapting to new topics,[0],[0]
"In strong contrast, topic-integrating models retrieve a much higher number of actual arguments at target topic augmentation levels as low as 20%.",5.3 Adapting to new topics,[0],[0]
"Further, and equally important, this does not come at the cost of precision; on the contrary, the precision is mostly steady and slowly rising after around 20% of target topic integration, leading to an overall higher F1 for these models.",5.3 Adapting to new topics,[0],[0]
"Finally, in comparing F1 between topic-integrating models and bilstm, we conclude that the former need much less target topic data to substantially improve their score, making them more robust in situations of data scarcity.",5.3 Adapting to new topics,[0],[0]
We have presented a new approach for searching a document collection for arguments relevant to a given topic.,6 Conclusion,[0],[0]
"First, we introduced an annotation scheme suited to the information-seeking perspec-
8Each data point in the plot is the average score of ten runs with different random samples of target topic data.
",6 Conclusion,[0],[0]
tive of argument search and showed that it is cheaply but reliably applicable by untrained annotators to arbitrary Web texts.,6 Conclusion,[0],[0]
"Second, we presented a new corpus, including over 25,000 instances over eight topics, that allows for cross-topic experiments using heterogeneous text types.",6 Conclusion,[0],[0]
"Third, we conducted cross-topic experiments and showed that integrating topic information of arguments with our contextual BiLSTM leads to better generalization to unknown topics.",6 Conclusion,[0],[0]
"Fourth, by leveraging knowledge from similar datasets and integrating our contextual BiLSTM into a multi-task learning setup, we were able to gain an improvement over our strongest baseline of 5.9 percentage points in F1 in the two-label setup and 4.6 in the three-label setup.",6 Conclusion,[0],[0]
"Finally, by gradually adding target topic data to our training set, we showed that, when available, even small amounts of target topic data (20%) have a strong positive influence on the recall of arguments.
",6 Conclusion,[0],[0]
"In a separate, simultaneously written paper (Stab et al., 2018) we evaluate our models in real-world application scenarios by applying them to a large document collection and comparing the results to a manually produced gold standard.",6 Conclusion,[0],[0]
"An online argument search engine implementing our approach is now available for noncommercial use at https://www.argumentsearch.com/. Furthermore, we are experimenting with language adaptation and plan to extend the tool to the German language.",6 Conclusion,[0],[0]
Preliminary results are presented in Stahlhut (2018).,6 Conclusion,[0],[0]
We also intend to investigate methods for grouping similar arguments.,6 Conclusion,[0],[0]
This work has been supported by the German Federal Ministry of Education and Research (BMBF) under the promotional reference 03VP02540,Acknowledgements,[0],[0]
"(Ar-
gumenText) and the DFG-funded research training group “Adaptive Preparation of Information form Heterogeneous Sources” (AIPHES, GRK 1994/1).",Acknowledgements,[0],[0]
Argument mining is a core technology for automating argument search in large document collections.,abstractText,[0],[0]
"Despite its usefulness for this task, most current approaches are designed for use onlywith specific text types and fall short when applied to heterogeneous texts.",abstractText,[0],[0]
"In this paper, we propose a new sentential annotation scheme that is reliably applicable by crowd workers to arbitrary Web texts.",abstractText,[0],[0]
"We source annotations for over 25,000 instances covering eight controversial topics.",abstractText,[0],[0]
We show that integrating topic information into bidirectional long short-termmemory networks outperforms vanilla BiLSTMs by more than 3 percentage points in F1 in twoand three-label cross-topic settings.,abstractText,[0],[0]
We also show that these results can be further improved by leveraging additional data for topic relevance using multi-task learning.,abstractText,[0],[0]
Cross-topic Argument Mining from Heterogeneous Sources,title,[0],[0]
"Crowdsourcing is an omnipresent phenomenon: it has emerged as an integral part of the machine learning pipeline in recent years, and one reason for the great advances in deep learning is the presence of large data sets that have been labeled by the crowd (e.g., Deng et al., 2009; Krizhevsky, 2009).",1. Introduction,[0],[0]
"Crowdsourcing is also at the heart of peer grading systems (e.g., Alfaro & Shavlovsky, 2014), which help with rising enrollment at universities, and online rating systems (e.g., Liao et al., 2014), which many of us rely on when choosing the next restaurant, to provide just a few examples.
",1. Introduction,[0],[0]
A crowdsourcing scenario consists of a set of workers and a set of tasks that need to be solved.,1. Introduction,[0],[0]
A data curator utilizing crowdsourcing can aim at estimating various quantities of interest.,1. Introduction,[0],[0]
The first goal might be to estimate the true labels or answers for the tasks at hand.,1. Introduction,[0],[0]
"Typically, additional constraints are involved here such as a worker not being willing
1Department of Computer Science, Rutgers University, Piscataway Township, New Jersey, USA.",1. Introduction,[0],[0]
Correspondence to: Matthäus,1. Introduction,[0],[0]
"Kleindessner <matthaeus.kleindessner@rutgers.edu>, Pranjal Awasthi <pranjal.awasthi@rutgers.edu>.
Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
to solve too many tasks and the data curator wanting to get high-quality labels at a low price.",1. Introduction,[0],[0]
The canonical example of this case is the Amazon Mechanical TurkTM.,1. Introduction,[0],[0]
There one cannot track specific workers as they are fleeting.,1. Introduction,[0],[0]
"However, in scenarios such as peer grading or online rating systems, a second goal might be to estimate worker qualities, especially if workers can be reused at a later time.
",1. Introduction,[0],[0]
"In a seminal paper, Dawid & Skene (1979) proposed a formal model that involves worker quality parameters for crowdsourcing scenarios in the context of classification.",1. Introduction,[0],[0]
"The Dawid-Skene model has become a standard theoretical framework and has led to a flurry of research over the past few years (Liu et al., 2012; Raykar & Yu, 2012; Li et al., 2013; Gao et al., 2016; Zhang et al., 2016; Khetan et al., 2017), in particular in its special symmetric form usually referred to as one-coin model (Ghosh et al., 2011; Karger et al., 2011a;b; Dalvi et al., 2013; Gao & Zhou, 2013; Karger et al., 2014; Bonald & Combes, 2017; Ma et al., 2017).",1. Introduction,[0],[0]
"In its general form for binary classification problems, the DawidSkene model assumes that for each worker, the probability of providing the wrong label only depends on the true label of the task, but not on the task itself.",1. Introduction,[0],[0]
"Moreover, given the true label, the responses provided by different workers are independent.",1. Introduction,[0],[0]
"The one-coin model additionally assumes that for each worker, the probability of providing the wrong label is the same for both classes.",1. Introduction,[0],[0]
We will formally introduce the one-coin model in Section 2.,1. Introduction,[0],[0]
"A discussion of prior work work is provided in Section 5 and Appendix A.
The crucial limitation of the Dawid-Skene and one-coin model is the assumption that workers’ error probabilities are task-independent.",1. Introduction,[0],[0]
"In particular, this excludes the possibility of colluding adversaries (other than those that provide the wrong label all of the time), which might make these models a poor approximation of the real world encountered in such applications as peer grading or online rating.",1. Introduction,[0],[0]
"In this paper, we study a significant extension of the one-coin model that allows for arbitrary, highly colluding adversaries.",1. Introduction,[0],[0]
We provide an algorithm for estimating the workers’ error probabilities and prove that it asymptotically recovers the true error probabilities.,1. Introduction,[0],[0]
"Using our estimates of the error probabilities in weighted majority votes, we also provide strategies to estimate ground-truth labels of the tasks.",1. Introduction,[1.0],"['Using our estimates of the error probabilities in weighted majority votes, we also provide strategies to estimate ground-truth labels of the tasks.']"
Experiments on both synthetic and real data show that our approach clearly outperforms existing methods in the presence of adversaries.,1. Introduction,[0],[0]
"We first describe a general model for crowdsourcing with non-adaptive workers and binary classification tasks: there are n workers w1, . . .",2. Setup and problem formulation,[0.9918790788879925],"['We first describe a general model for crowdsourcing with non-adaptive workers and binary classification tasks: there are n workers w1, .']"
", wn and an i.i.d. sample of m tasklabel pairs ((xi, yi))mi=1 ∼",2. Setup and problem formulation,[0],[0]
"Dm, where D is a joint probability distribution over tasks x ∈ X and corresponding labels y ∈ {−1,+1}.",2. Setup and problem formulation,[0],[0]
"There is a variable gij ∈ {0, 1},",2. Setup and problem formulation,[0],[0]
i ∈,2. Setup and problem formulation,[0],[0]
"[m], j ∈",2. Setup and problem formulation,[0],[0]
"[n], indicating whether worker wj is presented with task xi (for k ∈ N, we use [k] to denote the set {1, . . .",2. Setup and problem formulation,[0],[0]
", k}).",2. Setup and problem formulation,[0],[0]
"If wj is presented with xi, that is gij = 1, wj provides an estimate wj(xi) ∈ {−1,+1} of the ground-truth label yi.",2. Setup and problem formulation,[1.0],"['If wj is presented with xi, that is gij = 1, wj provides an estimate wj(xi) ∈ {−1,+1} of the ground-truth label yi.']"
"Let A ∈ {−1, 0,+1}m×n be a matrix that stores all the responses collected from the workers: Aij = wj(xi) if gij = 1 and Aij = 0",2. Setup and problem formulation,[0],[0]
"if gij = 0.
",2. Setup and problem formulation,[0],[0]
We assume that each worker wj follows some (probabilistic or deterministic) strategy such that wj(xi) only depends on xi.,2. Setup and problem formulation,[0],[0]
"In particular, given xi, any two different workers’ responses wj(xi) and wk(xi) and the ground-truth label yi are independent.",2. Setup and problem formulation,[0],[0]
"Let εwj (x, y) ∈",2. Setup and problem formulation,[0],[0]
"[0, 1] be the conditional error probability that, given x and y, wj(x) does not equal y, that is
εwj (x, y)",2. Setup and problem formulation,[0],[0]
":= Prwj |(x,y)[wj(x) 6=",2. Setup and problem formulation,[0],[0]
"y | (x, y)].",2. Setup and problem formulation,[0],[0]
"(1)
Note that the unconditional probability of wj(x) being incorrect, before seeing x and y, is given by
Pr(x,y)∼D,wj [wj(x) 6=",2. Setup and problem formulation,[0],[0]
"y] = E(x,y)∼D[εwj (x, y)]",2. Setup and problem formulation,[0],[0]
"=: εwj .
",2. Setup and problem formulation,[0],[0]
"Now one may study the following questions:
(i)",2. Setup and problem formulation,[0],[0]
"Given only the matrix A, how can we estimate the ground-truth labels y1, . . .",2. Setup and problem formulation,[0],[0]
", ym?
(ii)",2. Setup and problem formulation,[0],[0]
"Given only the matrix A, how can we estimate the workers’ unconditional error probabilities εw1 , . . .",2. Setup and problem formulation,[0],[0]
", εwn?
(iii)",2. Setup and problem formulation,[0],[0]
"If we can choose gij (either in advance of collecting workers’ responses or adaptively while doing so), how should we choose it such that we can achieve (i) or (ii) with a minimum number of collected responses?
",2. Setup and problem formulation,[0],[0]
"In case of εwj (x, y) as defined in (1) being constant on X × {−1,+1}, that is εwj (x, y) ≡ εwj , for all j ∈",2. Setup and problem formulation,[0],[0]
"[n], our model boils down to what is usually referred to as the one-coin model (e.g., Szepesvari, 2015), for which (i) to (iii) have been studied extensively (see Section 5 and Appendix A for references and a detailed discussion).",2. Setup and problem formulation,[0],[0]
With this paper we initiate the study of a significant extension of the one-coin model.,2. Setup and problem formulation,[1.0],['With this paper we initiate the study of a significant extension of the one-coin model.']
"We will allow almost half of the workers to deviate from the one-coin model and for such a worker wj , the conditional error probability εwj (x, y) to be a completely arbitrary random variable.",2. Setup and problem formulation,[1.0],"['We will allow almost half of the workers to deviate from the one-coin model and for such a worker wj , the conditional error probability εwj (x, y) to be a completely arbitrary random variable.']"
"In other words, we will allow for arbitrary adversaries, for which not only error
probabilities can be high, but for which error probabilities can be arbitrarily correlated.",2. Setup and problem formulation,[0],[0]
We mainly study (ii) in this scenario.,2. Setup and problem formulation,[0],[0]
We then make use of existing results for the onecoin model to answer (i) satisfactorily for our purposes.,2. Setup and problem formulation,[0],[0]
"We do not deal with (iii), but instead assume that gij has been specified in advance.",2. Setup and problem formulation,[0],[0]
In this section we want to present the general outline of our approach.,3. General outline of our approach,[1.0],['In this section we want to present the general outline of our approach.']
"A key insight is that the unconditional probability of workers wj and wk being agreeing is given by
Pr(x,y)∼D,wj ,wk [wj(x) = wk(x)]",3. General outline of our approach,[0],[0]
"= 1− εwj − εwk+ 2εwjεwk + 2 Cov(x,y)∼D[εwj (x, y), εwk(x, y)].
(2)
Cov(x,y)∼D[εwj",3. General outline of our approach,[0],[0]
"(x, y), εwk(x, y)] denotes the covariance between random variables εwj",3. General outline of our approach,[0],[0]
"(x, y) and εwk(x, y), that is
Cov(x,y)∼D[εwj",3. General outline of our approach,[0],[0]
"(x, y), εwk(x, y)]",3. General outline of our approach,[0],[0]
"= E(x,y)∼D[(εwj (x, y)− εwj ) · (εwk(x, y)− εwk)].
",3. General outline of our approach,[0],[0]
"A proof of (2) can be found in Appendix B. The probability on the left-hand side of (2) can be easily estimated from A by the ratio of the number of tasks that wj and wk agreed on to the number of tasks they were both presented with:
Pr[wj(x) = wk(x)]",3. General outline of our approach,[0],[0]
≈ ∑m i=1,3. General outline of our approach,[0],[0]
"gijgik1{Aij = Aik}∑m
i=1",3. General outline of our approach,[0],[0]
"gijgik =: pjk.
(3)
",3. General outline of our approach,[0],[0]
"This suggests to solve the system of equations
1− εj",3. General outline of our approach,[0],[0]
"− εk + 2εjεk + 2cjk = pjk, 1 ≤ j < k ≤ n, (4)
in the unknowns εl, l ∈",3. General outline of our approach,[0],[0]
"[n], and cjk, 1 ≤ j",3. General outline of our approach,[0],[0]
"< k ≤ n, in order to obtain estimates of the workers’ unconditional error probabilities εw1 , . . .",3. General outline of our approach,[0],[0]
", εwn .",3. General outline of our approach,[0],[0]
"However, there is a catch: in general, the system (4) is not identifiable and has several solutions.",3. General outline of our approach,[0],[0]
We will assume that at least n2 + 2 of the workers follow the one-coin model and have error probabilities smaller than one half.,3. General outline of our approach,[1.0],['We will assume that at least n2 + 2 of the workers follow the one-coin model and have error probabilities smaller than one half.']
"A worker wj following the one-coin model implies
Cov(x,y)∼D[εwj",3. General outline of our approach,[0],[0]
"(x, y), εwk(x, y)] = 0, ∀k 6=",3. General outline of our approach,[0],[0]
"j, (5)
and hence under this assumption we can restrict the search for solutions of (4) to εl, l ∈",3. General outline of our approach,[0],[0]
"[n], and cjk, 1 ≤ j",3. General outline of our approach,[0],[0]
"< k ≤ n, with the property that1
∃L ⊆",3. General outline of our approach,[0],[0]
[n] with |L| ≥ n/2 + 2 such that ∀j ∈ L : (εj < 1/2,3. General outline of our approach,[0],[0]
∧,3. General outline of our approach,[0],[0]
[∀k 6= j : cjk = 0]) .,3. General outline of our approach,[0],[0]
"(6)
1Throughout the paper, we set cjk = ckj if",3. General outline of our approach,[0],[0]
j > k.,3. General outline of our approach,[0],[0]
"We also assume pjk = pkj .
",3. General outline of our approach,[0],[0]
"Note that we never assume to know which workers follow the one-coin model, which corresponds to using the existential quantifier for the set L in (6) rather than considering a “fixed” L. We can show that the system (4) has at most one solution with property (6).",3. General outline of our approach,[0],[0]
We also provide evidence that our assumption of n2 + 2 of the workers following the one-coin model and having error probabilities smaller than one half is a necessary condition for guaranteeing the identifiability of system (4).,3. General outline of our approach,[0],[0]
"If the workers satisfy our assumption and pjk on the right-hand side of (4) are actually true agreement probabilities, then εl = εwl and cjk = Cov[εwj",3. General outline of our approach,[0],[0]
"(x, y), εwk(x, y)] is the unique solution of (4) that satisfies (6).",3. General outline of our approach,[0],[0]
"But if pjk are not exactly true agreement probabilities, there might be no solution of (4) with property (6) at all.",3. General outline of our approach,[0],[0]
"We prove that if estimates pjk are not too bad, we can solve (4) together with (6) approximately, and our approximate solution is guaranteed to be close to true error probabilities εw1 , . . .",3. General outline of our approach,[0],[0]
", εwn and covariances Cov[εwj",3. General outline of our approach,[0],[0]
"(x, y), εwk(x, y)], j < k.",3. General outline of our approach,[0],[0]
This answers (ii) from Section 2 and is the main contribution of our paper: Main result.,3. General outline of our approach,[0],[0]
Assume that at least n2 + 2 of the workers follow the one-coin model and have error probabilities not greater than γTR < 12 .,3. General outline of our approach,[0],[0]
If |Pr[wj(x) = wk(x)],3. General outline of our approach,[0],[0]
"− pjk| ≤ β for all j 6= k and β sufficiently small, we can compute estimates ε̂w1 , . . .",3. General outline of our approach,[0],[0]
", ε̂wn of εw1 , . .",3. General outline of our approach,[0],[0]
.,3. General outline of our approach,[0],[0]
", εwn such that
|εwi",3. General outline of our approach,[0],[0]
"− ε̂wi | ≤ C(γTR) · β1/4.
",3. General outline of our approach,[0],[0]
"We answer (i) from Section 2 and provide two ways to predict ground-truth labels y1, . . .",3. General outline of our approach,[0],[0]
", ym by taking weighted majority votes over the responses provided by the workers.",3. General outline of our approach,[0],[0]
"In these majority votes, the weights depend on our estimates of true error probabilities εw1 , . . .",3. General outline of our approach,[0],[0]
", εwn .",3. General outline of our approach,[0],[0]
"If gij has been specified in advance, we have the following guarantee on the quality of the estimates pjk (see (3)):",4.1. Estimating agreement probabilities,[0],[0]
Lemma 1.,4.1. Estimating agreement probabilities,[0],[0]
Assume ∑m i=1,4.1. Estimating agreement probabilities,[0],[0]
"gijgik > 0, j 6= k.",4.1. Estimating agreement probabilities,[0],[0]
Let δ > 0,4.1. Estimating agreement probabilities,[0],[0]
"and
βjk",4.1. Estimating agreement probabilities,[0],[0]
"= min
{ 1, [ ln(2n2/δ)/ ( 2 ∑m
i=1",4.1. Estimating agreement probabilities,[0],[0]
"gijgik
)]1/2} .
",4.1. Estimating agreement probabilities,[0],[0]
"Then we have with probability at least 1− δ over the sample ((xi, yi))",4.1. Estimating agreement probabilities,[0],[0]
m i=1,4.1. Estimating agreement probabilities,[0],[0]
"and the randomness in workers’ strategies that
|Pr[wj(x) = wk(x)]− pjk| ≤ βjk, 1 ≤ j < k ≤",4.1. Estimating agreement probabilities,[0],[0]
"n.
Proof.",4.1. Estimating agreement probabilities,[0],[0]
A straightforward application of Hoeffding’s inequality and the union bound yields the result.,4.1. Estimating agreement probabilities,[0],[0]
"If all workers follow the one-coin model, that is εwj (x, y) ≡",4.2. Identifiability and approximate solution,[0],[0]
εwj for all j ∈,4.2. Identifiability and approximate solution,[0],[0]
"[n], we have
Cov(x,y)∼D[εwj",4.2. Identifiability and approximate solution,[0],[0]
"(x, y), εwk(x, y)]",4.2. Identifiability and approximate solution,[0],[0]
"= 0, 1 ≤ j < k ≤ n, and system (4) reduces to
1− εj − εk + 2εjεk = pjk, 1 ≤ j < k ≤ n, (7)
in the unknowns εl, l ∈",4.2. Identifiability and approximate solution,[0],[0]
[n].,4.2. Identifiability and approximate solution,[0],[0]
"It is well known that, in general, even (7) is not identifiable.",4.2. Identifiability and approximate solution,[0],[0]
"For example, if pjk = 1 for all 1 ≤ j < k ≤ n, there are the two solutions εl = 0, l ∈",4.2. Identifiability and approximate solution,[0],[0]
"[n], and εl = 1, l ∈",4.2. Identifiability and approximate solution,[0],[0]
"[n], corresponding to either all perfect or all completely erroneous workers.",4.2. Identifiability and approximate solution,[0],[0]
"On the other hand, the system (7) is identifiable if we assume that on average workers are better than random guessing, that is 1 n ∑n j=1 εwj < 1 2 , and there are at least three informative workers with εwj",4.2. Identifiability and approximate solution,[0],[0]
6= 12,4.2. Identifiability and approximate solution,[0],[0]
(,4.2. Identifiability and approximate solution,[0],[0]
"Bonald & Combes, 2017).
",4.2. Identifiability and approximate solution,[0],[0]
"Clearly, these two conditions do not guarantee identifiability of the general system (4).",4.2. Identifiability and approximate solution,[0],[0]
"The next lemma shows that even if we additionally assume half of the workers to follow the one-coin model, the system (4) is not identifiable.",4.2. Identifiability and approximate solution,[0],[0]
Here we only state an informal version of the lemma.,4.2. Identifiability and approximate solution,[0],[0]
"A detailed version and its proof can be found in Appendix B.
Lemma 2.",4.2. Identifiability and approximate solution,[0],[0]
"There exists an instance of the system (4), where n is even, that has two different solutions.",4.2. Identifiability and approximate solution,[0],[0]
"In both solutions, it holds that εl < 12 , l ∈",4.2. Identifiability and approximate solution,[0],[0]
[n].,4.2. Identifiability and approximate solution,[0],[0]
"Furthermore:
(a) In the first solution, cjk = 0 for all j ∈",4.2. Identifiability and approximate solution,[0],[0]
"[n2 ] and k 6= j, and εl is small",4.2. Identifiability and approximate solution,[0],[0]
if l ∈,4.2. Identifiability and approximate solution,[0],[0]
[n2 ] and,4.2. Identifiability and approximate solution,[0],[0]
big if l ∈,4.2. Identifiability and approximate solution,[0],[0]
[n] \,4.2. Identifiability and approximate solution,[0],[0]
[ n 2 ].,4.2. Identifiability and approximate solution,[0],[0]
"(b) In the second solution, cjk = 0 for all j ∈",4.2. Identifiability and approximate solution,[0],[0]
"[n]\ [n2 ] and k 6= j, and εl is small if l ∈",4.2. Identifiability and approximate solution,[0],[0]
[n] \,4.2. Identifiability and approximate solution,[0],[0]
"[n2 ] and big if l ∈ [ n 2 ].
We want to mention that a solution of (4) does not necessarily correspond to actual workers, that is given εl, l ∈",4.2. Identifiability and approximate solution,[0],[0]
"[n], and cjk, 1 ≤ j",4.2. Identifiability and approximate solution,[0],[0]
"< k ≤ n, there might be no collection of workers w1, . . .",4.2. Identifiability and approximate solution,[0],[0]
", wn such that εwl = εl and Cov[εwj",4.2. Identifiability and approximate solution,[0],[0]
"(x, y), εwk(x, y)] = cjk.",4.2. Identifiability and approximate solution,[0],[0]
"By the BhatiaDavis inequality (Bhatia & Davis, 2010) it holds that Var[εwj (x, y)] ≤ εwj − ε 2wj .",4.2. Identifiability and approximate solution,[0],[0]
"Hence, a necessary condition for a solution to correspond to actual workers is that |cjk| ≤ (εj−ε 2j )1/2(εk−ε 2k )1/2",4.2. Identifiability and approximate solution,[0],[0]
(in addition to εl ∈,4.2. Identifiability and approximate solution,[0],[0]
"[0, 1]).",4.2. Identifiability and approximate solution,[0],[0]
"The two solutions in Lemma 2 correspond to actual workers.
",4.2. Identifiability and approximate solution,[0],[0]
"From now on we assume that at least n2 + 2 workers follow the one-coin model and have error probabilities smaller than one half:2
Assumption A.",4.2. Identifiability and approximate solution,[0.9999999996638804],['From now on we assume that at least n2 + 2 workers follow the one-coin model and have error probabilities smaller than one half:2 Assumption A.']
There exists L ⊆,4.2. Identifiability and approximate solution,[0],[0]
"[n] with |L| ≥ n/2 + 2 such that for all j ∈ L, the worker wj follows the one-coin model with error probability εwj < 1/2.
",4.2. Identifiability and approximate solution,[0.9934388042469094],"['There exists L ⊆ [n] with |L| ≥ n/2 + 2 such that for all j ∈ L, the worker wj follows the one-coin model with error probability εwj < 1/2.']"
This corresponds to considering (4) together with the constraint (6).,4.2. Identifiability and approximate solution,[0],[0]
"The system (4) together with (6) is identifiable:
Proposition 1.",4.2. Identifiability and approximate solution,[0.999999971512992],['The system (4) together with (6) is identifiable: Proposition 1.']
"There exists at most one solution of system (4) that has property (6).
",4.2. Identifiability and approximate solution,[0],[0]
"2All results of Section 4.2 hold true if we assume, more generally, the existence of L ⊆",4.2. Identifiability and approximate solution,[0],[0]
"[n] with |L| ≥ n
2 + 2 such that (5)
together with εwj < 1 2 holds for all j ∈ L.
Proof.",4.2. Identifiability and approximate solution,[0],[0]
"Assuming there are two solutions (εS1l )l∈[n], (c S1jk )",4.2. Identifiability and approximate solution,[0],[0]
"1≤j<k≤n and (ε S2 l )l∈[n], (c S2 jk )1≤j<k≤n with L1 and L2 satisfying (6), there have to be pairwise different i1, i2, i3 ∈ L1 ∩ L2.",4.2. Identifiability and approximate solution,[0],[0]
"It is easy to see that (εS1i1 , ε S1 i2 , εS1i3 ) and (εS2i1 , ε S2 i2 , εS2i3 ) and consequently also all the other components of the two solutions have to coincide.",4.2. Identifiability and approximate solution,[0],[0]
"Details can be found in Appendix B.
If pjk at the right-hand side of (4) are true agreement probabilities, the true error probabilities εw1 , . . .",4.2. Identifiability and approximate solution,[0],[0]
", εwn and covariances Cov[εwj",4.2. Identifiability and approximate solution,[0],[0]
"(x, y), εwk(x, y)], j < k, make up the unique solution of (4) that satisfies (6), but if pjk are not exactly true agreement probabilities, there might be no solution of (4) that satisfies (6) at all.",4.2. Identifiability and approximate solution,[0],[0]
"Our goal is then to find a solution of (4) that satisfies (6) approximately and to show that our approximate solution has to be close to εw1 , . . .",4.2. Identifiability and approximate solution,[0.9954751384870008],"['Our goal is then to find a solution of (4) that satisfies (6) approximately and to show that our approximate solution has to be close to εw1 , .']"
", εwn and Cov[εwj",4.2. Identifiability and approximate solution,[0],[0]
"(x, y), εwk(x, y)], j < k.",4.2. Identifiability and approximate solution,[0],[0]
"As a first step towards this goal we need a generalization of Proposition 1:
Proposition 2.",4.2. Identifiability and approximate solution,[0],[0]
Let γ < 1/2 and ν < 1/8− γ/2 +,4.2. Identifiability and approximate solution,[0],[0]
γ2/2.,4.2. Identifiability and approximate solution,[0],[0]
"If there exist two solutions (εSil )l∈[n], (c Si jk )1≤j<k≤n, i ∈ {1, 2}, of system (4) (where pjk ∈",4.2. Identifiability and approximate solution,[0],[0]
"[0, 1]) with the property that εSil ∈",4.2. Identifiability and approximate solution,[0],[0]
"[0, 1], l ∈",4.2. Identifiability and approximate solution,[0],[0]
"[n], and
∃Li ⊆",4.2. Identifiability and approximate solution,[0],[0]
[n] with |Li| ≥ n/2 + 2 such that ∀j ∈ Li : ( εSij ≤,4.2. Identifiability and approximate solution,[0],[0]
γ,4.2. Identifiability and approximate solution,[0],[0]
∧,4.2. Identifiability and approximate solution,[0],[0]
[ ∀k 6=,4.2. Identifiability and approximate solution,[0],[0]
"j : |c Sijk | ≤ ν ]) , (8)
then∣∣εS1l − εS2l ∣∣ ≤ G(γ, ν)√ν, ∣∣c S1jk − c S2jk ∣∣ ≤ 3G(γ, ν)√ν for l ∈",4.2. Identifiability and approximate solution,[0],[0]
"[n], j < k, where G(γ, ν)→ G(γ)",4.2. Identifiability and approximate solution,[0],[0]
> 0,4.2. Identifiability and approximate solution,[0],[0]
"as ν → 0.
",4.2. Identifiability and approximate solution,[0],[0]
"The proof of Proposition 2, which provides an explicit expression for G(γ, ν), can be found in Appendix B.
In a next step, we assume that we are given pairwise different i1, i2, i3 ∈",4.2. Identifiability and approximate solution,[0],[0]
"[n] such that wi1 , wi2 , wi3 follow the onecoin model with εwi1 , εwi2 , εwi3 < 1/2.",4.2. Identifiability and approximate solution,[0],[0]
"In this case, assuming that estimates pjk are close to true agreement probabilities, we can construct a solution of (4) that is guaranteed to be close to the true error probabilities and covariances (and hence approximately satisfies (6)).",4.2. Identifiability and approximate solution,[1.0],"['In this case, assuming that estimates pjk are close to true agreement probabilities, we can construct a solution of (4) that is guaranteed to be close to the true error probabilities and covariances (and hence approximately satisfies (6)).']"
"This is made precise in the next lemma (its proof can be found in Appendix B).
",4.2. Identifiability and approximate solution,[0],[0]
Lemma 3.,4.2. Identifiability and approximate solution,[0],[0]
Let γTR < 1/2 and consider the system (4) with p TRjk ∈,4.2. Identifiability and approximate solution,[0],[0]
"[0, 1] as right-hand side.",4.2. Identifiability and approximate solution,[0],[0]
"Assume there exists a solution3 (εTRl )l∈[n], (c TR jk )1≤j<k≤n with the property that",4.2. Identifiability and approximate solution,[0],[0]
εTRl ∈,4.2. Identifiability and approximate solution,[0],[0]
"[0, 1] and
∃LTR ⊆",4.2. Identifiability and approximate solution,[0],[0]
[n] with |LTR| ≥ n/2 + 2 such that ∀j ∈ LTR : ( εTRj ≤ γTR,4.2. Identifiability and approximate solution,[0],[0]
∧,4.2. Identifiability and approximate solution,[0],[0]
[ ∀k 6=,4.2. Identifiability and approximate solution,[0],[0]
j :,4.2. Identifiability and approximate solution,[0],[0]
c TRjk = 0 ]) .,4.2. Identifiability and approximate solution,[0],[0]
"(9)
Now consider the system (4) with pjk ∈",4.2. Identifiability and approximate solution,[0],[0]
"[0, 1] as right-hand side.",4.2. Identifiability and approximate solution,[0],[0]
"Assume that |p TRjk − pjk| ≤ β for all j 6= k, where
3By Proposition 1, this solution is unique.
",4.2. Identifiability and approximate solution,[0],[0]
β satisfies β < 1/2− 2γTR + 2γ2TR.,4.2. Identifiability and approximate solution,[0],[0]
"Let i1, i2, i3 ∈",4.2. Identifiability and approximate solution,[0],[0]
"[n] be pairwise different and set
B := −2",4.2. Identifiability and approximate solution,[0],[0]
"+ 4pi1i3 , C := 1 + 2pi1i2pi2i3",4.2. Identifiability and approximate solution,[0],[0]
− pi1i2,4.2. Identifiability and approximate solution,[0],[0]
"− pi1i3 − pi2i3 ,
εRi2 := 1 2 − √ B + 4C 2 √ B , εSi2 := min(γTR,max(0, ε R i2))
(10)
and for all l 6= i2 and for all 1 ≤ j < k ≤ n
εRl := pi2l − 1 + εSi2
2εSi2 − 1 ,
εSl :=
{ min(γTR,max(0, ε R l ))",4.2. Identifiability and approximate solution,[0],[0]
"if l ∈ {i1, i3}
min(1,max(0, εRl ))",4.2. Identifiability and approximate solution,[0],[0]
"if l /∈ {i1, i3} ,
c Sjk := pjk − (1− εSj − εSk + 2εSj εSk )
2 .
(11)
",4.2. Identifiability and approximate solution,[0],[0]
"If all expressions are defined (i.e., B > 0, B + 4C ≥ 0 and εSi2 6= 1 2 ), then (ε S l )l∈[n], (c S jk)1≤j<k≤n is a solution of (4) with pjk as right-hand side.",4.2. Identifiability and approximate solution,[0.9939695224872139],"['(11) If all expressions are defined (i.e., B > 0, B + 4C ≥ 0 and εSi2 6= 1 2 ), then (ε S l )l∈[n], (c S jk)1≤j<k≤n is a solution of (4) with pjk as right-hand side.']"
"If i1, i2, i3 ∈ LTR, then all expressions are defined and∣∣εTRl",4.2. Identifiability and approximate solution,[0],[0]
"− εSl ∣∣ ≤ H(γTR, β)√β, l ∈",4.2. Identifiability and approximate solution,[0],[0]
"[n],∣∣c TRjk − c Sjk∣∣ ≤",4.2. Identifiability and approximate solution,[0],[0]
"3H(γTR, β)√β + β/2, j < k, (12) where H(γTR, β)→ H(γTR)",4.2. Identifiability and approximate solution,[0],[0]
> 0,4.2. Identifiability and approximate solution,[0],[0]
"as β → 0.
",4.2. Identifiability and approximate solution,[0],[0]
"In Lemma 3, for constructing the solution (εSl )l∈[n], (c Sjk)1≤j<k≤n as defined in (10) and (11) we need to know γTR < 1/2, which is an upper bound on the error probabilities of at least n2 + 2 workers that follow the one-coin model.",4.2. Identifiability and approximate solution,[0],[0]
"In practice, we might choose γTR depending on the difficulty of the tasks or simply set it conservatively, for example as γTR = 0.45.",4.2. Identifiability and approximate solution,[0],[0]
"If i1, i2, i3 ∈ LTR, then (12) implies that (εSl )l∈[n], (c S jk)1≤j<k≤n satisfies (8) with
γ = γTR +H(γTR, β) √ β, ν = 3H(γTR, β) √ β + β/2.
",4.2. Identifiability and approximate solution,[0],[0]
"(13)
If we know the value of β (using Lemma 1, we easily obtain an upper bound β that holds with high probability), we can compute these quantities.",4.2. Identifiability and approximate solution,[0],[0]
"This suggests the following strategy for obtaining estimates of εw1 , . . .",4.2. Identifiability and approximate solution,[0],[0]
", εwn and Cov[εwj",4.2. Identifiability and approximate solution,[0],[0]
"(x, y), εwk(x, y)], j < k: we sample pairwise different i1, i2, i3 ∈",4.2. Identifiability and approximate solution,[0],[0]
"[n] uniformly at random and construct (εSl )l∈[n], (c S jk)1≤j<k≤n as defined in (10) and (11).",4.2. Identifiability and approximate solution,[0],[0]
"If one of the expressions is not defined, we can immediately discard (i1, i2, i3).",4.2. Identifiability and approximate solution,[0],[0]
"Otherwise, we check whether (εSl )l∈[n], (c Sjk)1≤j<k≤n satisfies (8) with γ and ν as specified in (13).",4.2. Identifiability and approximate solution,[0],[0]
"If it does, since (εTRl )l∈[n], (c TR jk + (pjk− p TRjk )/2)1≤j<k≤n is a solution of (4) with pjk as right-hand side that satisfies
property (8) too, Proposition 2 guarantees that ∣∣εTRl",4.2. Identifiability and approximate solution,[0],[0]
"− εSl ∣∣ ≤√3H(γTR, β)√β",4.2. Identifiability and approximate solution,[0],[0]
"+ β2 · G ( γTR +H(γTR, β)",4.2. Identifiability and approximate solution,[0],[0]
"√ β, 3H(γTR, β)",4.2. Identifiability and approximate solution,[0],[0]
"√ β + β
2
) ∼ β1/4
(14)
for all l ∈",4.2. Identifiability and approximate solution,[0],[0]
"[n] and a similar bound on |c TRjk − c Sjk|, j < k.",4.2. Identifiability and approximate solution,[0],[0]
"If (εSl )l∈[n], (c S jk)1≤j<k≤n does not satisfy (8), we discard (i1, i2, i3) and start anew.",4.2. Identifiability and approximate solution,[0],[0]
"Note that under our Assumption A, the probability of choosing i1, i2, i3 such that i1, i2, i3 ∈ LTR is greater than 1/8.",4.2. Identifiability and approximate solution,[0],[0]
"In expectation we have to discard (i1, i2, i3) for not more than eight times before finding a solution that satisfies (8) and hence (14).
",4.2. Identifiability and approximate solution,[0],[0]
"Assuming that every worker is presented with every task, that is gij",4.2. Identifiability and approximate solution,[0],[0]
= 1,4.2. Identifiability and approximate solution,[0],[0]
for all i ∈,4.2. Identifiability and approximate solution,[0],[0]
[m] and j ∈,4.2. Identifiability and approximate solution,[0],[0]
"[n], it follows from Lemma 1 and (14) that m has to scale as ln(n2/δ)/ρ8 in order that the described strategy is guaranteed to yield, with probability at least 1 − δ, estimates εS1 , . . .",4.2. Identifiability and approximate solution,[0],[0]
", εSn satisfying |εTRl − εSl
∣∣ ≤ ρ,",4.2. Identifiability and approximate solution,[0],[0]
l ∈,4.2. Identifiability and approximate solution,[0],[0]
[n].,4.2. Identifiability and approximate solution,[0],[0]
"This is significantly larger than the rate m ∼ ln(n2/δ)/ρ2 required by the TE algorithm, which solves the estimation problem for the error probabilities in the one-coin model and is claimed to be minimax optimal (Bonald & Combes, 2017).",4.2. Identifiability and approximate solution,[0],[0]
"We suspect that our rate with its dependence on ρ−8 is not optimal and consider it to be an interesting follow-up question to study the minimax rate for our extension of the one-coin model.
",4.2. Identifiability and approximate solution,[0],[0]
"Although the convergence rate that we can guarantee for the described strategy is slow, we might still hope that the strategy performs better in practice.",4.2. Identifiability and approximate solution,[0],[0]
"However, there is an issue that we have to overcome.",4.2. Identifiability and approximate solution,[0],[0]
"Unless β is very small, γ and ν as specified in (13) are too big for being meaningful, that is any solution (εSl )l∈[n], (c S jk)1≤j<k≤n as defined in (10) and (11) will satisfy (8) with these values.",4.2. Identifiability and approximate solution,[0],[0]
"We will not discard any (i1, i2, i3), regardless of whether i1, i2, i3 ∈ LTR holds or not.",4.2. Identifiability and approximate solution,[0],[0]
"We deal with this issue by adapting the strategy as follows: let P ⊆ {(i1, i2, i3) : i1, i2, i3 ∈",4.2. Identifiability and approximate solution,[0],[0]
[n] pairwise different}.,4.2. Identifiability and approximate solution,[0],[0]
"For every p = (i1, i2, i3) ∈ P , we construct (εSl (p))l∈[n], (c Sjk(p))1≤j<k≤n as defined in (10) and (11).",4.2. Identifiability and approximate solution,[0],[0]
We set Qp =,4.2. Identifiability and approximate solution,[0],[0]
"[n] unless γ as specified in (13) is smaller than one, in which case we set Qp = {l ∈",4.2. Identifiability and approximate solution,[0],[0]
"[n] : εSl (p) ≤ γ} and discard any solution (εSl (p))l∈[n], (c S jk(p))1≤j<k≤n for which |Qp| < n2 + 2.",4.2. Identifiability and approximate solution,[0],[0]
Let ν,4.2. Identifiability and approximate solution,[0],[0]
p be the dn2 + 2e-th smallest element of {maxk∈[n]\{l} |c Slk (p)| : l ∈ Qp}.,4.2. Identifiability and approximate solution,[0],[0]
"Then we finally return the solution (εSl (p0))l∈[n], (c S jk(p0)))1≤j<k≤n for which νp is smallest, that is p0 = argminp ν",4.2. Identifiability and approximate solution,[0],[0]
"p.
",4.2. Identifiability and approximate solution,[0],[0]
"If γ is small enough, it follows from Proposition 2 that∣∣εTRl",4.2. Identifiability and approximate solution,[0],[0]
"− εSl (p0)∣∣ ≤√max{νp0 , β/2} · G ( γTR +H(γTR, β) √ β,max{νp0 , β/2} ) .",4.2. Identifiability and approximate solution,[0],[0]
"(15)
Note that if P contains at least one triple of indices i1, i2, i3 ∈ LTR, then νp0 ≤ 3H(γTR, β) √ β + β2 , so that the guarantee (15) is at least as good as (14).",4.2. Identifiability and approximate solution,[0],[0]
We also expect νp0 to be smaller the larger P is.,4.2. Identifiability and approximate solution,[0],[0]
"Hence, we should choose P as large as we can afford due to computational reasons, but in practice, there is one more aspect that we have to consider.",4.2. Identifiability and approximate solution,[0],[0]
"Depending on how gij has been chosen, there might be workers wj and wk that were presented with only a few common tasks or no common tasks at all.",4.2. Identifiability and approximate solution,[0],[0]
"In this case, the estimate pjk of the agreement probability between wj and wk is only poor and there is no uniform bound β on |p TRjk −pjk| (where p TRjk are true agreement probabilities).",4.2. Identifiability and approximate solution,[0],[0]
"We can deal with this aspect by choosing P in a way such that for all p ∈ P , all estimates pjk that are involved in the computation of (εSl (p))l∈[n] are somewhat reliable.",4.2. Identifiability and approximate solution,[0],[0]
We present a concrete implementation of this in Algorithm 1 below.,4.2. Identifiability and approximate solution,[0],[0]
"Once we have estimates ε̂w1 , . . .",4.3. Predicting ground-truth labels,[0],[0]
", ε̂wn of the true error probabilities εw1 , . . .",4.3. Predicting ground-truth labels,[0],[0]
", εwn , we predict ground-truth labels yi by taking a weighted majority vote over the responses collected for the task xi.",4.3. Predicting ground-truth labels,[0],[0]
"Our estimate for yi is given by
ŷi = sign {∑n
l=1 f(ε̂wl) ·Ail
} , (16)
where f :",4.3. Predicting ground-truth labels,[0],[0]
"[0, 1]→",4.3. Predicting ground-truth labels,[0],[0]
"[−∞,+∞].",4.3. Predicting ground-truth labels,[0],[0]
Ties are broken uniformly at random.,4.3. Predicting ground-truth labels,[0],[0]
"We consider two choices for the function f .
",4.3. Predicting ground-truth labels,[0],[0]
"It is well-known that if all workers follow the one-coin model with known error probabilities εw1 , . . .",4.3. Predicting ground-truth labels,[0],[0]
", εwn , groundtruth labels are balanced, that is Pr(x,y)∼D[y = +1] = Pr(x,y)∼D[y = −1], and gij are independent Bernoulli random variables with common success probability α > 0, then the optimal estimator for the ground-truth label yi is given by the weighted majority vote (16) with f(ε̂wl) replaced by f(εwl) =",4.3. Predicting ground-truth labels,[0],[0]
ln,4.3. Predicting ground-truth labels,[0],[0]
"((1− εwl)/εwl) (Nitzan & Paroush, 1982; Berend & Kontorovich, 2015; Bonald & Combes, 2017).",4.3. Predicting ground-truth labels,[0],[0]
"Hence, a common approach for the one-coin model is to first estimate the true error probabilities and then to estimate ground-truth labels by using the majority vote (16) with f(ε̂wl) = ln",4.3. Predicting ground-truth labels,[0],[0]
"((1− ε̂wl)/ε̂wl) (Bonald & Combes, 2017; Ma et al., 2017).",4.3. Predicting ground-truth labels,[0],[0]
"We propose to use the same majority vote, but restricted to answers from workers that we believe to follow the one-coin model.",4.3. Predicting ground-truth labels,[0],[0]
"Using the notation from Section 4.2, this means that we set f(ε̂wl) = ln ((1− ε̂wl)/ε̂wl) for l ∈ Qp0 with maxk∈[n]\{l} |c Slk (p0)| ≤ νp0 and f(ε̂wl) = 0 otherwise.
",4.3. Predicting ground-truth labels,[0],[0]
"Alternatively, we suggest to set f(ε̂wl) = 1 − 2ε̂wl for l ∈",4.3. Predicting ground-truth labels,[0],[0]
[n].,4.3. Predicting ground-truth labels,[0],[0]
With this choice of f we make use of the responses provided by all workers.,4.3. Predicting ground-truth labels,[0],[0]
"The same choice has been used for the one-coin model too (Dalvi et al., 2013).",4.3. Predicting ground-truth labels,[0],[0]
A third option would be to set f(ε̂wl) = 1− 2ε̂wl for l ∈ Qp0 with maxk∈[n]\{l} |c Slk (p0)| ≤ νp0 and f(ε̂wl) = 0,4.3. Predicting ground-truth labels,[0],[0]
"otherwise, but we do not consider this choice any further.",4.3. Predicting ground-truth labels,[0],[0]
"In the interests of clarity, we present our approach as self contained Algorithm 1.",4.4. Algorithm,[0],[0]
Choosing P as the set of triples such that involved pairs of workers have been provided with at least ten or three common tasks might seem somewhat arbitrary here.,4.4. Algorithm,[0],[0]
"Indeed, one could introduce two parameters to the algorithm instead.",4.4. Algorithm,[0],[0]
"Without optimizing for these parameters, we chose them as ten and three in all our experiments on real data, and hence we state Algorithm 1 as is.
",4.4. Algorithm,[0],[0]
"Our analysis best applies to the setting of a full matrix A (or variables gij that are independent Bernoulli random variables with common success probability, as it is assumed by Bonald & Combes, 2017, for example).",4.4. Algorithm,[0],[0]
"In this case, which we consider in our experiments on synthetic data, choosing P as stated in Algorithm 1 reduces to choosing P as the set of all triples of pairwise different indices.",4.4. Algorithm,[0],[0]
"If the number of workers n is small, this is the best one can do.",4.4. Algorithm,[1.0],"['If the number of workers n is small, this is the best one can do.']"
"If n is large, it is infeasible to choose P as the set of all triples though since the running time of Algorithm 1 is in O(n2(m + |P",4.4. Algorithm,[0],[0]
|)).,4.4. Algorithm,[0],[0]
"If n is large and A full, one should sample P uniformly at random.",4.4. Algorithm,[0],[0]
For |P | ≥ ln δ/ ln(7/8),4.4. Algorithm,[0],[0]
our error guarantee (14) holds with probability at least 1− δ then (compare with Section 4.2).,4.4. Algorithm,[0],[0]
We briefly survey related work here.,5. Related work,[0],[0]
A complete discussion can be found in Appendix A.,5. Related work,[0],[0]
"As discussed in Sections 1 and 2, in crowdsourcing one might be interested in estimating ground-truth labels and/or worker qualities given the response matrix A, but also in optimal task assignment.",5. Related work,[0],[0]
"In their seminal paper, Dawid & Skene (1979) proposed an EM based algorithm to address the first two goals.",5. Related work,[0],[0]
"Since then numerous works have followed addressing all three goals for the Dawid-Skene and one-coin model (Ghosh et al., 2011; Karger et al., 2011a;b; 2013; 2014; Dalvi et al., 2013; Gao & Zhou, 2013; Gao et al., 2016; Zhang et al., 2016; Bonald & Combes, 2017; Ma et al., 2017).",5. Related work,[0],[0]
"There have also been efforts to study generalizations of the Dawid-Skene model (Jaffe et al., 2016; Khetan & Oh, 2016; Shah et al., 2016) as well as to explicitly deal with adversaries (Raykar & Yu, 2012; Jagabathula et al., 2017).",5. Related work,[0],[0]
"However, none of the prior work can handle a number of arbitrary adversaries almost as large as the number of reliable workers as we do.",5. Related work,[0],[0]
"On both synthetic and real data, we compared our proposed Algorithm 1 to straightforward majority voting for predicting labels (referred to as Maj) and the following methods from the literature: the spectral algorithms by Ghosh et al. (2011) (GKM), Dalvi et al. (2013) (RoE and EoR) and Karger et al. (2013) (KOS), the two-stage procedure by
Algorithm 1",6. Experiments,[0],[0]
"Input: crowdsourced labels stored in A ∈ {−1, 0,+1}m×n, upper bound 0 < γTR < 12 on the error probabilities of dn2 + 2e workers that follow the one-coin model, confidence parameter 0",6. Experiments,[0],[0]
< δ < 1,6. Experiments,[0],[0]
"Output: estimates (εFl )l∈[n], (c Fjk )j<k, (ŷi)i∈[m] of error probabilities, covariances and ground-truth labels
I Estimating agreement probabilities set gij = 1{Aij 6= 0}, i ∈",6. Experiments,[0],[0]
"[m], j ∈",6. Experiments,[0],[0]
[n] set qjk = ∑m i=1,6. Experiments,[0],[0]
"gijgik, j, k ∈",6. Experiments,[0],[0]
"[n] set pjk as in (3), j, k ∈",6. Experiments,[0],[0]
"[n] (pjk = NaN if qjk = 0)
",6. Experiments,[0],[0]
I Estimating error probabilities and covariances set β =,6. Experiments,[0],[0]
"[ ln(2n2/δ)/ ( 2 minj,k∈[n] qjk )]1/2 ∈ (0,+Inf ] set γ as in (13)",6. Experiments,[0],[0]
if γ /∈,6. Experiments,[0],[0]
"[0, 1] then
set γ = 1 end if set P = { (i1, i2, i3) :",6. Experiments,[0],[0]
"i1, i2, i3 ∈",6. Experiments,[0],[0]
"[n] pairwise different
and qjk ≥ 10, j, k ∈ {i1, i2, i3}, and qi2j ≥ 3, j 6= i2 }
set νold = Inf, (εFl )l∈[n] = 0, (c F jk )1≤j<k≤n = 0, L = ∅ for (i1, i2,",6. Experiments,[0],[0]
"i3) ∈ P do if not all expressions in (10) or (11) are defined then
break end if compute (εSl )l∈[n], (c S jk)1≤j<k≤n as in (10) and (11) set Q = {l ∈",6. Experiments,[0],[0]
[n] : εSl ≤ γ} set ν = dn2 +,6. Experiments,[0],[0]
2e-th smallest element of {maxk∈[n]\{l} |c Slk,6. Experiments,[0],[0]
| : l ∈ Q} (ν = NaN ifQ = ∅) if |Q| ≥ n2 + 2 AND ν <,6. Experiments,[0],[0]
νold then set (εFl )l∈[n] =,6. Experiments,[0],[0]
"(ε S l )l∈[n], (c F jk )",6. Experiments,[0],[0]
j,6. Experiments,[0],[0]
"<k = (c S jk)j<k
set L = {l ∈ Q :",6. Experiments,[0],[0]
"maxk∈[n]\{l} |c Slk | ≤ ν} set νold = ν
end if end for
I Estimating ground-truth labels set f(ε̂wl) =",6. Experiments,[0],[0]
ln ((1− ε̂wl)/ε̂wl) ∈,6. Experiments,[0],[0]
"[−Inf,+Inf], l ∈ L,
and f(ε̂wl) = 0, l ∈",6. Experiments,[0],[0]
"[n] \ L (alternatively set f(ε̂wl) = 1− 2ε̂wl , l ∈",6. Experiments,[0],[0]
"[n]) set ŷi as in (16), i ∈",6. Experiments,[0],[0]
"[m]
Zhang et al. (2016) (S-EM1 and S-EM10, where we run one or ten iterations of the EM algorithm) and the recent method by Bonald & Combes (2017) (TE).",6. Experiments,[0],[0]
"We used the Matlab implementation of KOS, S-EM1 and S-EM10 made available by Zhang et al. (2016).",6. Experiments,[0],[0]
"In our implementations of the other methods, we adapted GKM, RoE and EoR as to assume that the average error of the workers is smaller than one half rather than assuming that the error of the first worker is.",6. Experiments,[0],[0]
"We always called Algorithm 1 with parameters γTR = 0.4 and δ = 0.1, which resulted in γ being set to 1
in the execution of the algorithm in all our experiments.",6. Experiments,[0],[0]
We refer to Algorithm 1 with the logarithmic weights in (16) as Alg. 1 and and with the linear weights as Alt-Alg. 1.,6. Experiments,[0],[0]
"In the following, all results are average results obtained from running an experiment for 100 times.",6. Experiments,[1.0],"['In the following, all results are average results obtained from running an experiment for 100 times.']"
"In our first experiment, we consider n = 50 workers and m = 5000 tasks with balanced ground-truth labels.",6.1. Synthetic data,[1.0],"['In our first experiment, we consider n = 50 workers and m = 5000 tasks with balanced ground-truth labels.']"
Every worker is presented with every task.,6.1. Synthetic data,[0],[0]
"For 0 ≤ t ≤ 25, we choose t workers at random.",6.1. Synthetic data,[0],[0]
"These workers are corrupted workers that all provide the same random response to every task, which is incorrect with error probability 0.5.",6.1. Synthetic data,[0],[0]
"The remaining n − t workers provide responses according to the one-coin model, where the error probability of each of these workers is 0.4.",6.1. Synthetic data,[0],[0]
Figure 1 shows the prediction error for estimating ground-truth labels and the estimation error for estimating error probabilities in both the maximum norm and the normalized 1-norm for the various methods as a function of t.,6.1. Synthetic data,[0],[0]
The prediction error is given by 1m ∑m i=1,6.1. Synthetic data,[0],[0]
1{yi 6= ŷi} for ground-truth labels yi and estimates ŷi and the estimation error is given by maxl∈[n] |εwl,6.1. Synthetic data,[0],[0]
− ε̂wl | or 1n,6.1. Synthetic data,[0],[0]
∑n l=1 |εwl − ε̂wl | for true error probabilities εwl and estimates ε̂wl .,6.1. Synthetic data,[0],[0]
"The methods Maj and KOS, by default, do not provide estimates of the workers’ error probabilities.",6.1. Synthetic data,[0],[0]
"We adapt these two methods in order to return estimates of the error probabilities too as follows: if the method returns label estimates ŷ1, . . .",6.1. Synthetic data,[0],[0]
", ŷm and worker wl provides responses A1l, . . .",6.1. Synthetic data,[0],[0]
", Aml 6= 0, then the method
returns 1m ∑m i=1",6.1. Synthetic data,[0],[0]
1{ŷi 6=,6.1. Synthetic data,[0],[0]
"Ail} as estimate ε̂wl of εwl .
",6.1. Synthetic data,[0],[0]
Our Algorithm 1 is the only method that can handle up to 23 = n2,6.1. Synthetic data,[0],[0]
− 2 corrupted workers (in accordance with our theoretical results).,6.1. Synthetic data,[0],[0]
Its estimation error is constant as the number of corrupted workers increases from 0 to 23.,6.1. Synthetic data,[0],[0]
"Its prediction error depends on which weights we use in (16): the prediction error of Alg. 1 is constant in this range too, the one of Alt-Alg. 1 is slightly increasing.",6.1. Synthetic data,[0],[0]
"If only a few workers are corrupted, Alt-Alg.1 performs better than Alg. 1, while it is the other way round if more than 13 workers are corrupted.",6.1. Synthetic data,[0],[0]
The methods from the literature predict ground-truth labels as badly as random guessing already in the presence of only six corrupted workers.,6.1. Synthetic data,[0],[0]
All these methods are outperformed by majority voting.,6.1. Synthetic data,[0],[0]
We do not have an explanation for the non-monotonic behavior of the estimation error of SEM10 in the maximum norm.,6.1. Synthetic data,[0],[0]
"In Appendix C we present similar experiments, in which the error probability of the workers following the one-coin model is smaller or the error probabilities of the corrupted workers are less correlated.",6.1. Synthetic data,[0],[0]
"Still, the overall picture there is the same.
",6.1. Synthetic data,[0],[0]
One might wonder whether one can combine the considered methods from the literature with one of the algorithms by Jagabathula et al. (2017) in order to first sort the corrupted workers out and then apply the method only to the remaining workers and their responses.,6.1. Synthetic data,[0],[0]
"However, those algorithms cannot deal with the corrupted workers considered in this experiment, which are perfectly colluding, at all.",6.1. Synthetic data,[0],[0]
"Even though provided with the correct number t of corrupted workers as input, when t ≥ 3, the soft-penalty algorithm by Jagabathula et al. (2017) was not able to identify any of the corrupted workers in any of the 100 runs of the experiment.
",6.1. Synthetic data,[0],[0]
"In our next experiment, we study the convergence rate of Algorithm 1.",6.1. Synthetic data,[0],[0]
"We consider n = 50 workers, out of which t = 23 are corrupted in the same way as above.",6.1. Synthetic data,[0],[0]
Figure 2 shows the prediction and estimation error of Algorithm 1 as a function of the number of tasks m varying from 5000 to 20000.,6.1. Synthetic data,[0],[0]
"The prediction error of Alg. 1 decreases only slightly as m increases, the prediction error of Alt-Alg. 1 decreases more significantly.",6.1. Synthetic data,[0],[0]
Most interesting is the decay of the estimation error.,6.1. Synthetic data,[0],[0]
"Apparently, in this experiment it
decreases at a rate ofm−1/2 rather than at a rate ofm−1/8 as suggested by our upper bound (compare with Section 4.2).",6.1. Synthetic data,[0],[0]
We performed experiments on six publicly available data sets that are are commonly used in the literature (cf.,6.2. Real data,[0],[0]
"Snow et al., 2008, Zhang et al., 2016, and Bonald & Combes, 2017).",6.2. Real data,[0],[0]
All six data sets come with ground truth labels for each task.,6.2. Real data,[0],[0]
"For most of the data sets the matrix A, which stores the collected responses, is highly sparse.",6.2. Real data,[0],[0]
"In order to reduce sparseness, we removed workers that provided fewer than 50 labels.",6.2. Real data,[0],[0]
"For two of the data sets, we merged classes in order to end up with binary classification problems in the same way as Bonald & Combes (2017) did (Dog: {0, 2} vs {1, 3}; Web: {0, 1, 2} vs {3, 4}).",6.2. Real data,[0],[0]
Table 2 in Appendix C provides the characteristic values of the data sets.,6.2. Real data,[0],[0]
Note that only for the Bird data set every worker provided a label for every task whereas for the other ones A is still rather sparse.,6.2. Real data,[0],[0]
Figure 5 in Appendix C shows for each data set a histogram of the error probabilities of the workers (computed over those tasks that a worker was presented with).,6.2. Real data,[0],[0]
"Figure 6 shows a heat map of the matrix (|Cov[εwj (x, y), εwk(x, y)]|)nj,k=1 (computed over those tasks that two workers were jointly presented with).
",6.2. Real data,[0],[0]
Table 1 shows the prediction error for the various methods and data sets.,6.2. Real data,[0],[0]
There is no method that performs best on all data sets.,6.2. Real data,[0],[0]
"Overall, S-EM10 seems to be the method of choice.",6.2. Real data,[0],[0]
"Our Algorithm 1 can compete with the other methods, and on four out of the six data sets, the prediction error of Alt-Alg. 1 is smaller or larger only by 0.01 than the prediction error of S-EM10.",6.2. Real data,[0],[0]
Alg. 1 performs slightly worse than Alt-Alg. 1.,6.2. Real data,[0],[0]
"The poor performance of our method on
the Bird data set might be explained by the fact that there the workers clearly deviate from our model: as Figure 6 shows, there are no n2 + 2 workers that follow the one-coin model.
",6.2. Real data,[0],[0]
We performed another experiments on these data sets by corrupting some of the workers (chosen at random).,6.2. Real data,[0],[0]
"Like in the experiments of Section 6.1, the corrupted workers provide the same random response to every task.",6.2. Real data,[0],[0]
Figure 3 shows the prediction errors for the various methods and the first three data sets as functions of the number of corrupted workers.,6.2. Real data,[0],[0]
"Similar plots for the other data sets are shown in Figure 7 in Appendix C. On none of the data sets, any method can handle more corrupted workers than Alt-Alg. 1.",6.2. Real data,[0],[0]
"In this work, we studied an extension of the well-known one-coin model for crowdsourcing that allows for colluding adversaries.",7. Discussion,[0],[0]
"Our results show that even if almost half of the workers are adversarial, one can consistently estimate the workers’ error probabilities with an efficient algorithm.
",7. Discussion,[0],[0]
"For future work, it would be interesting to relax the assumption that the reliable workers follow the one-coin model and to allow for task-dependent error probabilities also for them.",7. Discussion,[0],[0]
It would also be interesting to see whether our approach can be extended to multiclass classification problems.,7. Discussion,[1.0],['It would also be interesting to see whether our approach can be extended to multiclass classification problems.']
"Another direction concerns improving the sufficient rate m ∼ ρ−8 , which we obtained for our algorithm for recovering worker qualities up to error ρ.",7. Discussion,[1.0],"['Another direction concerns improving the sufficient rate m ∼ ρ−8 , which we obtained for our algorithm for recovering worker qualities up to error ρ.']"
"In the absence of adversaries one can achieve a rate m ∼ ρ−2, and we would like to understand whether this gap is inherent or an artifact of our algorithm/proof.",7. Discussion,[1.0],"['In the absence of adversaries one can achieve a rate m ∼ ρ−2, and we would like to understand whether this gap is inherent or an artifact of our algorithm/proof.']"
"Finally, we wonder about the role of adaptive task assignment in our extension of the one-coin model.",7. Discussion,[0],[0]
This research is supported by a Rutgers Research Council Grant and a Center for Discrete Mathematics and Theoretical Computer Science (DIMACS) postdoctoral fellowship.,Acknowledgements,[0],[0]
"Most existing works on crowdsourcing assume that the workers follow the Dawid-Skene model, or the one-coin model as its special case, where every worker makes mistakes independently of other workers and with the same error probability for every task.",abstractText,[0],[0]
We study a significant extension of this restricted model.,abstractText,[0],[0]
"We allow almost half of the workers to deviate from the one-coin model and for those workers, their probabilities of making an error to be task-dependent and to be arbitrarily correlated.",abstractText,[0],[0]
"In other words, we allow for arbitrary adversaries, for which not only error probabilities can be high, but which can also perfectly collude.",abstractText,[0],[0]
"In this adversarial scenario, we design an efficient algorithm to consistently estimate the workers’ error probabilities.",abstractText,[0],[0]
Crowdsourcing with Arbitrary Adversaries,title,[0],[0]

0	27	Natural Language Inference (NLI; a.k.a.
2	59	The goal of NLI is to identify the logical relationship (entailment, neutral, or contradiction) between a premise and a corresponding hypothesis.
5	14	† This work was conducted as part of an internship program at Philips Research.
7	12	Various deep learning models have been proposed that achieve successful results for this task (Gong et al., 2017; Wang et al., 2017; Chen et al., 2017; Yu and Munkhdalai, 2017a; Parikh et al., 2016; Zhao et al., 2016; Sha et al., 2016).
55	24	The proposed encoding mechanism yields a richer representation for both premise and hypothesis by taking the history of each other into account.
62	14	Next, for each word in either premise or hypothesis, the relevant semantics in the other sentence is extracted and composed according to eij .
76	30	But rather than passing just the dependent reading information to the next step, we feed both independent reading (p̄ and q̄) and dependent reading (p̂ and q̂) to a max pooling layer, which selects maximum values from each sequence of independent and dependent readings (p̄i and p̂i) as shown in Equations 10 and 11.
78	11	q̄, sq = BiLSTM(q, 0) p̂,− = BiLSTM(p, sq) (8) p̄, sp = BiLSTM(p, 0) q̂,− = BiLSTM(q, sp) (9) p̃ = MaxPooling(p̄, p̂) (10) q̃ = MaxPooling(q̄, q̂) (11) Here {p̄ ∈ Rn×2d, p̂ ∈ Rn×2d, sp} and {q̄ ∈ Rm×2d, q̂ ∈ Rm×2d, sq} are the independent reading sequences, dependent reading sequences, and BiLSTM final state of independent reading of p and q respectively.
82	12	Here, we feed the concatenation of U and V ([U, V ]) into a multilayer perceptron (MLP) classifier that includes a hidden layer with tanh activation and softmax output layer.
84	14	The Stanford Natural Language Inference (SNLI) dataset contains 570K human annotated sentence pairs.
85	16	The premises are drawn from the Flickr30k (Plummer et al., 2015) corpus, and then the hypotheses are manually composed for each relationship class (entailment, neutral, contradiction, and -).
87	17	We use the same data split as provided in Bowman et al. (2015) to report comparable results with other models.
96	19	Ensemble methods use multiple models to obtain better predictive performance.
97	31	Previous works typically utilize trivial ensemble strategies by either using majority votes or averaging the probability distributions over the same model with different initialization seeds (Wang et al., 2017; Gong et al., 2017).
98	28	By contrast, we use weighted averaging of the probability distributions where the weight of each model is learned through its performance on the SNLI development set.
128	30	Note that the difference between DR-BiLSTM and Chen et al. (2017) is statistically significant with a p-value of < 0.001 over the Chi-square test1.
129	12	To further improve the performance of NLI systems, researchers have built ensemble models.
130	46	Previously, ensemble systems obtained the best performance on SNLI with a huge margin.
141	29	We conducted an ablation study on our model to examine the importance and effect of each major component.
149	24	They illustrate the importance of our proposed dependent reading strategy which leads to significant improvement, specifically in the encoding stage.
150	12	We are convinced that the importance of dependent reading in the encoding stage originates from its ability to focus on more important and relevant aspects of the sentences due to its prior knowledge of the other sentence during the encoding procedure.
171	15	Table 4 can be divided into four major categories: 1) gold label data, 2) word overlap, 3) sentence length, and 4) occurrence of special words.
173	19	Moreover, DR-BiLSTM (Single) performs noticeably better than ESIM in most of the categories except “Entailment”, “High Overlap”, and “Long Sentence”, for which our model is not far behind (gaps of 0.2%, 0.5%, and 0.9%, respectively).
174	13	It is noteworthy that DR-BiLSTM (Single) performs better than ESIM in more frequent categories.
176	55	Our investigations indicate that ESIM generates somewhat uniform attention for most of the word pairs while our model could effectively attend to specific parts of the given sentences and provide more meaningful attention.
179	19	We show a sentence pair, where the premise is “Male in a blue jacket decides to lay the grass.”, and the hypothesis is “The guy in yellow is rolling on the grass.”, and its logical relationship is contradiction.
180	36	Figure 4 indicates the model’s ability in attending to critical pairs of words like <Male, guy>, <decides, rolling>, and <lay, rolling>.
181	90	Finally, high attention between {decides, lay} and {rolling}, and {Male} and {guy} leads the model to correctly classify the sentence pair as contradiction (for more samples with attention visualizations, see Section 4 in the supplementary material).
182	43	We propose a novel natural language inference model (DR-BiLSTM) that benefits from a dependent reading strategy and achieves the state-of-theart results on the SNLI dataset.
183	24	We also introduce a sophisticated ensemble strategy and illustrate its effectiveness through experimentation.

0	28	As scientific communities grow and evolve, new tasks, methods, and datasets are introduced and different methods are compared with each other.
2	38	To help researchers more quickly identify opportunities for new combinations of tasks, methods and data, it is important to design intelligent algorithms that can extract and organize scientific information from a large collection of documents.
3	77	Organizing scientific information into structured knowledge bases requires information extraction (IE) about scientific entities and their relationships.
4	60	However, the challenges associated with scientific IE are greater than for a general domain.
5	24	First, annotation of scientific text requires domain expertise which makes annotation costly and limits resources.
12	24	In this paper, we develop a unified learning model for extracting scientific entities, relations, and coreference resolution.
16	23	Different from a standard tagging system, our system enumerates all possible spans during decoding and can effectively detect overlapped spans.
17	35	It avoids cascading errors between tasks by jointly modeling all spans and span-span relations.
21	21	Human evaluation shows that propagating coreference can significantly improve the quality of the automatic constructed knowledge graph.
23	32	We create a dataset for scientific information extraction by jointly annotating scientific entities, relations, and coreference links.
43	85	Our dataset (called SCIERC) includes annotations for scientific entities, their relations, and coreference clusters for 500 scientific abstracts.
45	31	SCIERC extends previous datasets in scientific articles SemEval 2017 Task 10 (SemEval 17) (Augenstein et al., 2017) and SemEval 2018 Task 7 (SemEval 18) (Gábor et al., 2018) by extending entity types, relation types, relation coverage, and adding cross-sentence relations using coreference links.
79	48	The output structure R is a set of random variables indexed over pairs of spans (i, j) that belong to the same sentence: rij ∈ LR for i, j = 1, .
83	26	For efficient training and inference, we decompose P (E,R,C|D) assuming spans are conditionally independent given D: P (E,R,C | D) = P (E,R,C, S | D) (1) = N∏ i=1 P (ei | D)P (ci | D) N∏ j=1 P (rij | D), where the conditional probabilities of each random variable are independently normalized: P (ei = e | D) = exp(ΦE(e, si))∑ e′∈LE exp(ΦE(e ′, si)) (2) P (rij = r | D) = exp(ΦR(r, si, sj))∑ r′∈LR exp(ΦR(r ′, si, sj)) P (ci = j | D) = exp(ΦC(si, sj))∑ j′∈{1,...,i−1, } exp(ΦC(si, sj′)) , where ΦE denotes the unnormalized model score for an entity type e and a span si, ΦR denotes the score for a relation type r and span pairs si, sj , and ΦC denotes the score for a binary coreference link between si and sj .
89	34	For coreference resolution, we use the marginalized loss following Lee et al. (2017) since each mention can have multiple correct antecedents.
145	40	Results on SciERC Table 2 compares the result of our model with baselines on the three tasks: entity recognition (Table 2a), relation extraction (Table 2b), and coreference resolution (Table 2c).
149	47	For relation extraction, we observe more significant improvement with 13.1% relative improvement over E2E Rel and 7.4% improvement over E2E Rel with ELMO.
167	35	We provide qualitative analysis and human evaluations on the constructed knowledge graph.
168	28	Scientific trend analysis Figure 7 shows the historical trend analysis (from 1996 to 2016) of the most popular applications of the phrase neural network, selected according to the statistics of the extracted relation triples with the ‘Used-for’ relation type from speech, computer vision, and NLP conference papers.
170	29	In NLP, neural networks first gain popularity in language modeling and then extend to other tasks such as POS Tagging and Machine Translation.
171	53	In computer vision, the application of neural networks gains popularity in object recognition earlier (around 2010) than the other two more complex tasks of object detection and image segmentation (hardest and also the latest).
172	28	Knowledge Graph Evaluation Figure 8 shows the human evaluation of the constructed knowledge graph, comparing the quality of automatically generated knowledge graphs with and without the coreference links.
179	25	The precision of both systems is high (above 84% for both systems), but the system with coreference links has significantly higher recall.
191	43	A.1 Entity Category • Task: Applications, problems to solve, sys- tems to construct.
193	26	• Method: Methods , models, systems to use, or tools, components of a system, frameworks.
194	25	language model, CORENLP, POS parser, kernel method, etc.
195	35	• Evaluation Metric: Metrics, measures, or entities that can express quality of a system/method.
196	52	F1, BLEU, Precision, Recall, ROC curve, mean reciprocal rank, mean-squared error, robustness, time complexity, etc.
198	44	image data, speech data, stereo images, bilingual dictionary, paraphrased questions, CoNLL, Panntreebank, WordNet, Wikipedia, etc.
203	116	B always points to A for asymmetric relations • Used-for: B is used for A, B models A, A is trained on B, B exploits A, A is based on B. E.g.

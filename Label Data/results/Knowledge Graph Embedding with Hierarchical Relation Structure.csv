0,1,label2,summary_sentences
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 364–369 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
364",text,[0],[0]
"Semantic role labeling (SRL) captures predicateargument relations, such as “who did what to whom.”",1 Introduction,[0],[0]
"Recent high-performing SRL models (He et al., 2017; Marcheggiani et al., 2017; Tan et al., 2018) are BIO-taggers, labeling argument spans for a single predicate at a time (as shown in Figure 1).",1 Introduction,[0],[0]
"They are typically only evaluated with gold predicates, and must be pipelined with error-prone predicate identification models for deployment.
",1 Introduction,[0],[0]
We propose an end-to-end approach for predicting all the predicates and their argument spans in one forward pass.,1 Introduction,[0],[0]
"Our model builds on a recent coreference resolution model (Lee et al., 2017), by making central use of learned, contextualized span representations.",1 Introduction,[0],[0]
We use these representations to predict SRL graphs directly over text spans.,1 Introduction,[0],[0]
"Each edge is identified by independently predicting which role, if any, holds between every possible pair of text spans, while using aggressive beam
1Code and models: https://github.com/luheng/lsgn
pruning for efficiency.",1 Introduction,[0],[0]
"The final graph is simply the union of predicted SRL roles (edges) and their associated text spans (nodes).
",1 Introduction,[0],[0]
"Our span-graph formulation overcomes a key limitation of semi-markov and BIO-based models (Kong et al., 2016; Zhou and Xu, 2015; Yang and Mitchell, 2017; He et al., 2017; Tan et al., 2018): it can model overlapping spans across different predicates in the same output structure (see Figure 1).",1 Introduction,[0],[0]
"The span representations also generalize the token-level representations in BIObased models, letting the model dynamically decide which spans and roles to include, without using previously standard syntactic features (Punyakanok et al., 2008; FitzGerald et al., 2015).
",1 Introduction,[0],[0]
"To the best of our knowledge, this is the first span-based SRL model that does not assume that predicates are given.",1 Introduction,[0],[0]
"In this more realistic setting, where the predicate must be predicted, our model achieves state-of-the-art performance on PropBank.",1 Introduction,[0],[0]
"It also reinforces the strong performance of similar span embedding methods for coreference (Lee et al., 2017), suggesting that this style of models could be used for other span-span relation tasks, such as syntactic parsing (Stern et al., 2017), relation extraction (Miwa and Bansal, 2016), and QA-SRL (FitzGerald et al., 2018).",1 Introduction,[0],[0]
"We consider the space of possible predicates to be all the tokens in the input sentence, and the space of arguments to be all continuous spans.",2 Model,[0],[0]
"Our model decides what relation exists between each predicate-argument pair (including no relation).
",2 Model,[0],[0]
"Formally, given a sequence X = w1, . . .",2 Model,[0],[0]
", wn, we wish to predict a set of labeled predicateargument relations Y ⊆ P ×",2 Model,[0],[0]
"A × L, where P = {w1, . . .",2 Model,[0],[0]
", wn} is the set of all tokens (predicates), A = {(wi, . . .",2 Model,[0],[0]
", wj) | 1 ≤",2 Model,[0],[0]
"i ≤ j ≤ n} contains all the spans (arguments), and L is the space of semantic role labels, including a null label indicating no relation.",2 Model,[0],[0]
"The final SRL output would be all the non-empty relations {(p, a, l) ∈ Y",2 Model,[0],[0]
"| l 6= }.
",2 Model,[0],[0]
"We then define a set of random variables, where each random variable yp,a corresponds to a predicate p ∈ P and an argument a ∈ A, taking value from the discrete label space L.",2 Model,[0],[0]
"The random variables yp,a are conditionally independent of each other given the input X:
P (Y | X) = ∏
p∈P,a∈A P (yp,a | X) (1)
P (yp,a = l | X) = exp(φ(p, a, l))∑
l′∈L exp(φ(p, a, l′))
",2 Model,[0],[0]
"(2)
Where φ(p, a, l) is a scoring function for a possible (predicate, argument, label) combination.",2 Model,[0],[0]
"φ is decomposed into two unary scores on the predicate and the argument (defined in Section 3), as well as a label-specific score for the relation:
φ(p, a, l) = Φa(a) + Φp(p) +",2 Model,[0],[0]
"Φ (l) rel (a, p) (3)
",2 Model,[0],[0]
"The score for the null label is set to a constant: φ(p, a, ) = 0, similar to logistic regression.
",2 Model,[0],[0]
"Learning For each input X , we minimize the negative log likelihood of the gold structure Y ∗:
",2 Model,[0],[0]
J (X) =,2 Model,[0],[0]
"− logP (Y ∗ | X) (4)
Beam pruning As our model deals with O(n2) possible argument spans and O(n) possible predicates, it needs to consider O(n3|L|) possible relations, which is computationally impractical.",2 Model,[0],[0]
"To overcome this issue, we define two beams Ba and Bp for storing the candidate arguments and predicates, respectively.",2 Model,[0],[0]
The candidates in each beam are ranked by their unary score (Φa or Φp).,2 Model,[0],[0]
The sizes of the beams are limited by λan and λpn.,2 Model,[0],[0]
"Elements that fall out of the beam do not participate
in computing the edge factors Φ(l)rel , reducing the overall number of relational factors evaluated by the model to O(n2|L|).",2 Model,[0],[0]
"We also limit the maximum width of spans to a fixed number W (e.g. W = 30), further reducing the number of computed unary factors to O(n).",2 Model,[0],[0]
"Our model builds contextualized representations for argument spans a and predicate words p based on BiLSTM outputs (Figure 2) and uses feedforward networks to compute the factor scores in φ(p, a, l) described in Section 2 (Figure 3).
",3 Neural Architecture,[0],[0]
"Word-level contexts The bottom layer consists of pre-trained word embeddings concatenated with character-based representations, i.e. for each token wi, we have xi = [WORDEMB(wi); CHARCNN(wi)].",3 Neural Architecture,[0],[0]
"We then contextualize each xi using an m-layered bidirectional LSTM with highway connections (Zhang et al., 2016), which we denote as x̄i.
Argument and predicate representation We build contextualized representations for all candidate arguments a ∈ A and predicates p ∈ P .",3 Neural Architecture,[0],[0]
"The argument representation contains the following: end points from the BiLSTM outputs (x̄START(a), x̄END(a)), a soft head word xh(a), and embedded span width features f(a), similar to Lee et al. (2017).",3 Neural Architecture,[0],[0]
"The predicate representation is simply the BiLSTM output at the position INDEX(p).
",3 Neural Architecture,[0],[0]
"g(a) =[x̄START(a); x̄END(a); xh(a); f(a)] (5)
g(p) =x̄INDEX(p) (6)
The soft head representation xh(a) is an attention mechanism over word inputs x in the argument span, where the weights e(a) are computed via a linear layer over the BiLSTM outputs x̄.
xh(a) = xSTART(a):END(a)e(s) ᵀ (7) e(a)",3 Neural Architecture,[0],[0]
"= SOFTMAX(wᵀe x̄START(a):END(a)) (8)
xSTART(a):END(a) is a shorthand for stacking a list of vectors xt, where START(a) ≤ t ≤ END(a).
",3 Neural Architecture,[0],[0]
"Scoring The scoring functions Φ are implemented with feed-forward networks based on the predicate and argument representations g:
Φa(a) =w ᵀ a MLPa(g(a))",3 Neural Architecture,[0],[0]
(9) Φp(p),3 Neural Architecture,[0],[0]
"=w ᵀ pMLPp(g(p)) (10)
Φ (l) rel (a, p) =w (l)ᵀ r MLPr([g(a); g(p)]) (11)",3 Neural Architecture,[0],[0]
"We experiment on the CoNLL 2005 (Carreras and Màrquez, 2005) and CoNLL 2012 (OntoNotes 5.0, (Pradhan et al., 2013)) benchmarks, using two SRL setups: end-to-end and gold predicates.",4 Experiments,[0],[0]
"In the end-to-end setup, a system takes a tokenized sentence as input, and predicts all the predicates and their arguments.",4 Experiments,[0],[0]
"Systems are evaluated on the micro-averaged F1 for correctly predicting (predicate, argument span, label) tuples.",4 Experiments,[0],[0]
"For comparison with previous systems, we also report results with gold predicates, in which the complete set of predicates in the input sentence is given as well.",4 Experiments,[0],[0]
"Other experimental setups and hyperparameteres are listed in Appendix A.1.
ELMo embeddings To further improve performance, we also add ELMo word representations (Peters et al., 2018) to the BiLSTM input (in the +ELMo rows).",4 Experiments,[0],[0]
"Since the contextualized representations ELMo provides can be applied to most previous neural systems, the improvement is orthogonal to our contribution.",4 Experiments,[0],[0]
"In Table 1 and 2, we organize all the results into two categories: the comparable single model systems, and the mod-
els augmented with ELMo or ensembling (in the PoE rows).
",4 Experiments,[0],[0]
"End-to-end results As shown in Table 1,2 our joint model outperforms the previous best pipeline system (He et al., 2017) by an F1 difference of anywhere between 1.3 and 6.0 in every setting.",4 Experiments,[0],[0]
"The improvement is larger on the Brown test set, which is out-of-domain, and the CoNLL 2012 test set, which contains nominal predicates.",4 Experiments,[0],[0]
"On all datasets, our model is able to predict over 40% of the sentences completely correctly.
",4 Experiments,[0],[0]
"Results with gold predicates To compare with additional previous systems, we also conduct experiments with gold predicates by constraining our predicate beam to be gold predicates only.",4 Experiments,[0],[0]
"As shown in Table 2, our model significantly out-performs He et al. (2017), but falls short of Tan et al. (2018), a very recent attention-based (Vaswani et al., 2017)",4 Experiments,[0],[0]
BIO-tagging model that was developed concurrently with our work.,4 Experiments,[0],[0]
"By adding the contextualized ELMo representations, we are able to out-perform all previous systems, including Peters et al. (2018), which applies ELMo to the SRL model introduced in He et al. (2017).",4 Experiments,[0],[0]
Our model’s architecture differs significantly from previous BIO systems in terms of both input and decision space.,5 Analysis,[0],[0]
"To better understand our model’s strengths and weaknesses, we perform three analyses following Lee et al. (2017) and He et al. (2017), studying (1) the effectiveness of beam
2For the end-to-end setting on CoNLL 2012, we used a subset of the train/dev data from previous work due to noise in the dataset; the dev result is not directly comparable.",5 Analysis,[0],[0]
"See Appendix A.2 for detailed explanation.
",5 Analysis,[0],[0]
"pruning, (2) the ability to capture long-range dependencies, (3) agreement with syntactic spans, and (4) the ability to predict globally consistent SRL structures.",5 Analysis,[0],[0]
The analyses are performed on the development sets without using ELMo embeddings.,5 Analysis,[0],[0]
"3
Effectiveness of beam pruning Figure 4 shows the predicate and argument spans kept in the beam, sorted with their unary scores.",5 Analysis,[0],[0]
"Our model efficiently prunes unlikely argument spans and predicates, significantly reduces the number of edges it needs to consider.",5 Analysis,[0],[0]
Figure 5 shows the recall of predicate words on the CoNLL 2012 development set.,5 Analysis,[0],[0]
"By retaining λp = 0.4 predicates per word, we are able to keep over 99.7% argument-bearing predicates.",5 Analysis,[0],[0]
"Compared to having a part-of-speech tagger (POS:X in Figure 5), our joint beam pruning allowing the model to have a soft trade-off between efficiency and recall.4
Long-distance dependencies Figure 6 shows the performance breakdown by binned distance between arguments to the given predicates.",5 Analysis,[0],[0]
"Our model is better at accurately predicting arguments that are farther away from the predicates, even
3For comparability with prior work, analyses (2)-(4) are performed on the CoNLL 05 dev set with gold predicates.
",5 Analysis,[0],[0]
"4The predicate ID accuracy of our model is not comparable with that reported in He et al. (2017), since our model does not predict non-argument-bearing predicates.
",5 Analysis,[0],[0]
"compared to an ensemble model (He et al., 2017) that has a higher overall F1.",5 Analysis,[0],[0]
"This is very likely due to architectural differences; in a BIO tagger, predicate information passes through many LSTM timesteps before reaching a long-distance argument, whereas our architecture enables direct connections between all predicates-arguments pairs.
Agreement with syntax As mentioned in He et al. (2017), their BIO-based SRL system has good agreement with gold syntactic span boundaries (94.3%) but falls short of previous syntaxbased systems (Punyakanok et al., 2004).",5 Analysis,[0],[0]
"By directly modeling span information, our model achieves comparable syntactic agreement (95.0%) to Punyakanok et al. (2004) without explicitly modeling syntax.
",5 Analysis,[0],[0]
"Global consistency On the other hand, our model suffers from global consistency issues.",5 Analysis,[0],[0]
"For example, on the CoNLL 2005 test set, our model has lower complete-predicate accuracy (62.6%) than the BIO systems (He et al., 2017; Tan et al., 2018) (64.3%-66.4%).",5 Analysis,[0],[0]
"Table 3 shows its viola-
tions of global structural constraints5 compared to previous systems.",5 Analysis,[0],[0]
Our model made more constraint violations compared to previous systems.,5 Analysis,[0],[0]
"For example, our model predicts duplicate core arguments6 (shown in the U column in Table 3) more often than previous work.",5 Analysis,[0],[0]
"This is due to the fact that our model uses independent classifiers to label each predicate-argument pair, making it difficult for them to implicitly track the decisions made for several arguments with the same predicate.
",5 Analysis,[0],[0]
"The Ours+decode row in Table 3 shows SRL performance after enforcing the U-constraint using dynamic programming (Täckström et al., 2015) at decoding time.",5 Analysis,[0],[0]
"Constrained decoding at test time is effective at eliminating all the core-role inconsistencies (shown in the U-column), but did not bring significant gain on the end result (shown
5Punyakanok et al. (2008) described a list of global constraints for SRL systems, e.g., there can be at most one core argument of each type for each predicate.
6Arguments with labels ARG0,ARG1,. . .",5 Analysis,[0],[0]
",",5 Analysis,[0],[0]
"ARG5 and AA.
in SRL F1), which only evaluates the piece-wise predicate-argument structures.",5 Analysis,[0],[0]
"We proposed a new SRL model that is able to jointly predict all predicates and argument spans, generalized from a recent coreference system (Lee et al., 2017).",6 Conclusion and Future Work,[0],[0]
"Compared to previous BIO systems, our new model supports joint predicate identification and is able to incorporate span-level features.",6 Conclusion and Future Work,[0],[0]
"Empirically, the model does better at longrange dependencies and agreement with syntactic boundaries, but is weaker at global consistency, due to our strong independence assumption.
",6 Conclusion and Future Work,[0],[0]
"In the future, we could incorporate higher-order inference methods (Lee et al., 2018) to relax this assumption.",6 Conclusion and Future Work,[0],[0]
"It would also be interesting to combine our span-based architecture with the selfattention layers (Tan et al., 2018; Strubell et al., 2018) for more effective contextualization.",6 Conclusion and Future Work,[0],[0]
"This research was supported in part by the ARO (W911NF-16-1-0121), the NSF (IIS-1252835, IIS-1562364), a gift from Tencent, and an Allen Distinguished Investigator Award.",Acknowledgments,[0],[0]
"We thank Eunsol Choi, Dipanjan Das, Nicholas Fitzgerald, Ariel Holtzman, Julian Michael, Noah Smith, Swabha Swayamdipta, and our anonymous reviewers for helpful feedback.",Acknowledgments,[0],[0]
"Recent BIO-tagging-based neural semantic role labeling models are very high performing, but assume gold predicates as part of the input and cannot incorporate span-level features.",abstractText,[0],[0]
"We propose an endto-end approach for jointly predicting all predicates, arguments spans, and the relations between them.",abstractText,[0],[0]
"The model makes independent decisions about what relationship, if any, holds between every possible word-span pair, and learns contextualized span representations that provide rich, shared input features for each decision.",abstractText,[0],[0]
Experiments demonstrate that this approach sets a new state of the art on PropBank SRL without gold predicates.1,abstractText,[0],[0]
Jointly Predicting Predicates and Arguments in Neural Semantic Role Labeling,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 401–406 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
401",text,[0],[0]
"Neural NER trains a deep neural network for the NER task and has become quite popular as they minimize the need for hand-crafted features and, learn feature representations from the training data itself.",1 Introduction,[0],[0]
"Recently, multilingual learning has been shown to benefit Neural NER in a resource-rich language setting (Gillick et al., 2016; Yang et al., 2017).",1 Introduction,[0],[0]
Multilingual learning aims to improve the NER performance on the language under consideration (primary language) by adding training data from one or more assisting languages.,1 Introduction,[0],[0]
The neural network is trained on the combined data of the primary (DP ) and the assisting languages (DA).,1 Introduction,[0],[0]
"The neural network has a combination of languagedependent and language-independent layers, and, the network learns better cross-lingual features via these language-independent layers.
∗This work began when the second author was a research scholar at IIT Bombay
Existing approaches add all training sentences from the assisting language to the primary language and train the neural network on the combined data.",1 Introduction,[0],[0]
"However, data from assisting languages can introduce a drift in the tag distribution for named entities, since the common named entities from the two languages may have vastly divergent tag distributions.",1 Introduction,[0],[0]
"For example, the entity China appears in training split of Spanish (primary) and English (assisting) (Tjong Kim Sang, 2002; Tjong Kim Sang and De Meulder, 2003) with the corresponding tag frequencies, Spanish = { Loc : 20, Org : 49, Misc : 1 } and English = { Loc : 91, Org : 7 }.",1 Introduction,[0],[0]
"By adding English data to Spanish, the tag distribution of China is skewed towards Location entity in Spanish.",1 Introduction,[0],[0]
This leads to a drop in named entity recognition performance.,1 Introduction,[0],[0]
"In this work, we address this problem of drift in tag distribution owing to adding training data from a supporting language.
",1 Introduction,[0],[0]
"The problem is similar to the problem of data selection for domain adaptation of various NLP tasks, except that additional complexity is introduced due to the multilingual nature of the learning task.",1 Introduction,[0],[0]
"For domain adaptation in various NLP tasks, several approaches have been proposed to address drift in data distribution (Moore and Lewis, 2010; Axelrod et al., 2011; Ruder and Plank, 2017).",1 Introduction,[0],[0]
"For instance, in machine translation, sentences from out-of-domain data are selected based on a suitably defined metric (Moore and Lewis, 2010; Axelrod et al., 2011).",1 Introduction,[0],[0]
The metric attempts to capture similarity of the out-of-domain sentences with the in-domain data.,1 Introduction,[0],[0]
"Out-of-domain sentences most similar to the in-domain data are added.
",1 Introduction,[0],[0]
"Like the domain adaptation techniques summarized above, we propose to judiciously add sentences from the assisting language to the primary language data based on the divergence between the tag distributions of named entities in the train-
ing instances.",1 Introduction,[0],[0]
"Adding assisting language sentences with lower divergence reduces the possibility of entity drift enabling the multilingual model to learn better cross-lingual features.
",1 Introduction,[0],[0]
Following are the contributions of the paper: (a) We present a simple approach to select assisting language sentences based on symmetric KLDivergence of overlapping entities (b) We demonstrate the benefits of multilingual Neural NER on low-resource languages.,1 Introduction,[0],[0]
"We compare the proposed data selection approach with monolingual Neural NER system, and the multilingual Neural NER system trained using all assisting language sentences.",1 Introduction,[0],[0]
"To the best of our knowledge, ours is the first work for judiciously selecting a subset of sentences from an assisting language for multilingual Neural NER.",1 Introduction,[0],[0]
"For every assisting language sentence, we calculate the sentence score based on the average symmetric KL-Divergence score of overlapping entities present in that sentence.",2 Judicious Selection of Assisting Language Sentences,[0],[0]
"By overlapping entities, we mean entities whose surface form appears in both the languages’ training data.",2 Judicious Selection of Assisting Language Sentences,[0],[0]
"The symmetric KL-Divergence SKL(x), of a named entity x, is defined as follows,
SKL(x) =",2 Judicious Selection of Assisting Language Sentences,[0],[0]
[ KL( Pp(x) || Pa(x) ),2 Judicious Selection of Assisting Language Sentences,[0],[0]
+KL( Pa(x) ||,2 Judicious Selection of Assisting Language Sentences,[0],[0]
Pp(x) ) ] /2,2 Judicious Selection of Assisting Language Sentences,[0],[0]
"(1)
where Pp(x) and Pa(x) are the probability distributions for entity x in the primary (p) and the assisting (a) languages respectively.",2 Judicious Selection of Assisting Language Sentences,[0],[0]
"KL refers to the standard KL-Divergence score between the two probability distributions.
",2 Judicious Selection of Assisting Language Sentences,[0],[0]
KL-Divergence calculates the distance between the two probability distributions.,2 Judicious Selection of Assisting Language Sentences,[0],[0]
"Lower the KLDivergence score, higher is the tag agreement for an entity in both the languages thereby, reducing the possibility of entity drift in multilingual learning.",2 Judicious Selection of Assisting Language Sentences,[0],[0]
Assisting language sentences with the sentence score below a threshold value are added to the primary language data for multilingual learning.,2 Judicious Selection of Assisting Language Sentences,[0],[0]
"If an assisting language sentence contains no overlapping entities, the corresponding sentence score is zero resulting in its selection.
",2 Judicious Selection of Assisting Language Sentences,[0],[0]
"Network Architecture
Several deep learning models (Collobert et al., 2011; Ma and Hovy, 2016; Murthy and Bhattacharyya, 2016; Lample et al., 2016; Yang et al., 2017) have been proposed for monolingual NER in the literature.",2 Judicious Selection of Assisting Language Sentences,[0],[0]
"Apart from the model by Collobert et al. (2011), remaining approaches extract sub-word features using either Convolution Neural Networks (CNNs) or Bi-LSTMs.",2 Judicious Selection of Assisting Language Sentences,[0],[0]
The proposed data selection strategy for multilingual Neural NER can be used with any of the existing models.,2 Judicious Selection of Assisting Language Sentences,[0],[0]
"We choose the model by Murthy and Bhattacharyya (2016)1 in our experiments.
",2 Judicious Selection of Assisting Language Sentences,[0],[0]
"Multilingual Learning
We consider two parameter sharing configurations for multilingual learning (i) sub-word feature extractors shared across languages (Yang et al., 2017)",2 Judicious Selection of Assisting Language Sentences,[0],[0]
(Sub-word) (ii) the entire network trained in a language independent way (All).,2 Judicious Selection of Assisting Language Sentences,[0],[0]
"As Murthy and Bhattacharyya (2016) use CNNs to extract sub-word features, only the character-level CNNs are shared for the Sub-word configuration.
",2 Judicious Selection of Assisting Language Sentences,[0],[0]
1The code is available here: https://github.com/ murthyrudra/NeuralNER,2 Judicious Selection of Assisting Language Sentences,[0],[0]
In this section we list the datasets used and the network configurations used in our experiments.,3 Experimental Setup,[0],[0]
The Table 1 lists the datasets used in our experiments along with pre-trained word embeddings used and other dataset statistics.,3.1 Datasets,[0],[0]
"For German NER, we use ep-96-04-16.conll to create train and development splits, and use ep-96-04-15.conll as test split.",3.1 Datasets,[0],[0]
"As Italian has a different tag set compared to English, Spanish and Dutch, we do not share output layer for All configuration in multilingual experiments involving Italian.",3.1 Datasets,[0],[0]
"Even though the languages considered are resource-rich languages, we consider German and Italian as primary languages due to their relatively lower number of train tokens.",3.1 Datasets,[0],[0]
"The German NER data followed IO notation and for all experiments involving German, we converted other language data to IO notation.",3.1 Datasets,[0],[0]
"Similarly, the Italian NER data followed IOBES notation and for all experiments involving Italian, we converted other language data to IOBES notation.
",3.1 Datasets,[0],[0]
"For low-resource language setup, we consider the following Indian languages: Hindi, Marathi2, Bengali, Tamil and Malayalam.",3.1 Datasets,[0],[0]
Except for Hindi all are low-resource languages.,3.1 Datasets,[0],[0]
"We consider only Person, Location and Organization tags.",3.1 Datasets,[0],[0]
"Though the scripts of these languages are different, they share the same set of phonemes making script mapping across languages easier.",3.1 Datasets,[0],[0]
"We convert Tamil, Bengali and Malayalam data to the Devanagari script using the Indic NLP li-
2Data is available here: http://www.cfilt.iitb.",3.1 Datasets,[0],[0]
"ac.in/ner/annotated_corpus/
brary3 (Kunchukuttan et al., 2015)",3.1 Datasets,[0],[0]
"thereby, allowing sharing of sub-word features across the Indian languages.",3.1 Datasets,[0],[0]
"For Indian languages, the annotated data followed the IOB format.",3.1 Datasets,[0],[0]
"With the exception of English, Spanish and Dutch, remaining language datasets did not have official train and development splits provided.",3.2 Network Hyper-parameters,[0],[0]
We randomly select 70% of the train split for training the model and remaining as development split.,3.2 Network Hyper-parameters,[0],[0]
"The threshold for sentence score SKL, is selected based on cross-validation for every language pair.",3.2 Network Hyper-parameters,[0],[0]
The dimensions of the Bi-LSTM hidden layer are 200 and 400 for the monolingual and multilingual experiments respectively.,3.2 Network Hyper-parameters,[0],[0]
"We extract 20 features per convolution filter, with width varying from 1 to 9.",3.2 Network Hyper-parameters,[0],[0]
The initial learning rate is 0.4 and multiplied by 0.7 when validation error increases.,3.2 Network Hyper-parameters,[0],[0]
The training is stopped when the learning rate drops below 0.002.,3.2 Network Hyper-parameters,[0],[0]
"We assign a weight of 0.1 to assisting language sentences and oversample primary language sentences to match the assisting language sentence count in all multilingual experiments.
",3.2 Network Hyper-parameters,[0],[0]
"For European languages, we have performed hyper-parameter tuning for both the monolingual and multilingual learning (with all assisting language sentences) configurations.",3.2 Network Hyper-parameters,[0],[0]
The best hyperparameter values for the language pair involved were observed to be within similar range.,3.2 Network Hyper-parameters,[0],[0]
"Hence, we chose the same set of hyper-parameter values for all languages.
",3.2 Network Hyper-parameters,[0],[0]
3https://github.com/anoopkunchukuttan/ indic_nlp_library,3.2 Network Hyper-parameters,[0],[0]
We now present the results on both resource-rich and resource-poor languages.,4 Results,[0],[0]
Table 2 presents the results for German and Italian NER.,4.1 Resource-Rich Languages,[0],[0]
"We consistently observe improvements for German and Italian NER using our data selection strategy, irrespective of whether only subword features are shared (Sub-word) or the entire network (All) is shared across languages.
",4.1 Resource-Rich Languages,[0],[0]
Adding all Spanish/Dutch sentences to Italian data leads to drop in Italian NER performance when all layers are shared.,4.1 Resource-Rich Languages,[0],[0]
Label drift from overlapping entities is one of the reasons for the poor results.,4.1 Resource-Rich Languages,[0],[0]
This can be observed by comparing the histograms of English and Spanish sentences ranked by the SKL scores for Italian multilingual learning (Figure 1).,4.1 Resource-Rich Languages,[0],[0]
Most English sentences have lower SKL scores indicating higher tag agreement for overlapping entities and lower drift in tag distribution.,4.1 Resource-Rich Languages,[0],[0]
"Hence, adding all English sentences improves Italian NER accuracy.",4.1 Resource-Rich Languages,[0],[0]
"In contrast, most Spanish sentences have larger SKL
scores and adding these sentences adversely impacts Italian NER performance.",4.1 Resource-Rich Languages,[0],[0]
"By judiciously selecting assisting language sentences, we eliminate sentences which are responsible for drift occurring during multilingual learning.
",4.1 Resource-Rich Languages,[0],[0]
"To understand how overlapping entities impact the NER performance, we study the statistics of overlapping named entities between ItalianEnglish and Italian-Spanish pairs.",4.1 Resource-Rich Languages,[0],[0]
911 and 916 unique entities out of 4061 unique Italian entities appear in the English and Spanish data respectively.,4.1 Resource-Rich Languages,[0],[0]
We had hypothesized that entities with divergent tag distribution are responsible for hindering the performance in multilingual learning.,4.1 Resource-Rich Languages,[0],[0]
If we sort the common entities based on their SKL divergence value.,4.1 Resource-Rich Languages,[0],[0]
We observe that 484 out of 911 common entities in English and 535 out of 916 common entities in Spanish have an SKL score greater than 1.0. 162 out of 484 common entities in English-Italian data having SKL divergence value greater than 1.0 also appear more than 10 times in the English corpus.,4.1 Resource-Rich Languages,[0],[0]
"Similarly, 123 out of 535 common entities in Spanish-Italian data having SKL divergence value greater than 1.0 also appear more than 10 times in the Spanish corpus.",4.1 Resource-Rich Languages,[0],[0]
"However, these common 162 entities have a combined frequency of 12893 in English, meanwhile the 123 common entities have a combined frequency of 34945 in Spanish.",4.1 Resource-Rich Languages,[0],[0]
"To summarize, although the number of overlapping entities is comparable in English and Spanish sentences, entities with larger SKL divergence score appears more frequently in Spanish sentences compared to English sentences.",4.1 Resource-Rich Languages,[0],[0]
"As a consequence, adding all Spanish sentences leads to significant drop in Italian NER performance which is not the case when all English sentences are added.",4.1 Resource-Rich Languages,[0],[0]
"As Indian languages exhibit high lexical overlap (Kunchukuttan and Bhattacharyya, 2016) and syntactic relatedness (V Subbãrão, 2012), we share all layers of the network across languages.",4.2 Resource-Poor Languages,[0],[0]
Table 3 presents the results.,4.2 Resource-Poor Languages,[0],[0]
"Bengali, Malayalam, and Tamil (low-resource languages) benefits from our data selection strategy.",4.2 Resource-Poor Languages,[0],[0]
"Hindi and Marathi NER performance improves when the other is used as assisting language.
",4.2 Resource-Poor Languages,[0],[0]
"Bengali, Malayalam, and Tamil have weaker baselines compared to Hindi and Marathi, and are benefited from our approach irrespective of the assisting language chosen.",4.2 Resource-Poor Languages,[0],[0]
"However, Hindi and Marathi are not benefited from multilingual learning with Bengali, Malayalam and Tamil.",4.2 Resource-Poor Languages,[0],[0]
Malayalam and Tamil being morphologically rich have low entity overlap (surface level) with Hindi and Marathi.,4.2 Resource-Poor Languages,[0],[0]
"As a result, only 2-3% of Malayalam and Tamil sentences are eliminated from our approach, leading to no gains from multilingual learning.",4.2 Resource-Poor Languages,[0],[0]
Hindi and Marathi are negatively impacted by noisy Bengali data.,4.2 Resource-Poor Languages,[0],[0]
"Bengali has less training sentences compared to other languages and, choosing a low SKL threshold results in selecting very few Bengali sentences for multilingual learning.",4.2 Resource-Poor Languages,[0],[0]
"Here, we study the influence of SKL score threshold on the NER performance.",4.3 Influence of SKL Threshold,[0],[0]
We run experiments for Italian NER by adding Spanish training sentences and sharing all layers except for output layer across languages.,4.3 Influence of SKL Threshold,[0],[0]
"We vary the threshold value from 1.0 to 9.0 in steps of 1, and select sentences with score less than the threshold.",4.3 Influence of SKL Threshold,[0],[0]
"A threshold of 0.0 indicates monolingual training and threshold greater than 9.0 indicates all assist-
ing language sentences considered.",4.3 Influence of SKL Threshold,[0],[0]
The plot of Italian test F-Score against SKL score is shown in the Figure 2.,4.3 Influence of SKL Threshold,[0],[0]
Italian test F-Score increases initially as we add more and more Spanish sentences and then drops due to influence of drift becoming significant.,4.3 Influence of SKL Threshold,[0],[0]
"Finding the right SKL threshold is important, hence we use a validation set to tune the SKL threshold.",4.3 Influence of SKL Threshold,[0],[0]
"In this paper, we address the problem of divergence in tag distribution between primary and assisting languages for multilingual Neural NER.",5 Conclusion,[0],[0]
We show that filtering out the assisting language sentences exhibiting significant divergence in the tag distribution can improve NER accuracy.,5 Conclusion,[0],[0]
We propose to use the symmetric KL-Divergence metric to measure the tag distribution divergence.,5 Conclusion,[0],[0]
We observe consistent improvements in multilingual Neural NER performance using our data selection strategy.,5 Conclusion,[0],[0]
"The strategy shows benefits for extremely low resource primary languages too.
",5 Conclusion,[0],[0]
"This problem of drift in data distribution may not be unique to multilingual NER, and we plan to study the influence of data selection for multilingual learning on other NLP tasks like sentiment analysis, question answering, neural machine translation, etc.",5 Conclusion,[0],[0]
"We also plan to explore more metrics for multilingual learning, specifically for morphologically rich languages.",5 Conclusion,[0],[0]
"We thank Gajanan Rane and Geetanjali Rane for annotating the Marathi data, which was created as part of the CLIA project.",Acknowledgements,[0],[0]
Multilingual learning for Neural Named Entity Recognition (NNER) involves jointly training a neural network for multiple languages.,abstractText,[0],[0]
"Typically, the goal is improving the NER performance of one of the languages (the primary language) using the other assisting languages.",abstractText,[0],[0]
We show that the divergence in the tag distributions of the common named entities between the primary and assisting languages can reduce the effectiveness of multilingual learning.,abstractText,[0],[0]
"To alleviate this problem, we propose a metric based on symmetric KL divergence to filter out the highly divergent training instances in the assisting language.",abstractText,[0],[0]
"We empirically show that our data selection strategy improves NER performance in many languages, including those with very limited training data.",abstractText,[0],[0]
Judicious Selection of Training Data in Assisting Language for Multilingual Neural NER,title,[0],[0]
The key challenge of drug discovery is to find target molecules with desired chemical properties.,1. Introduction,[0],[0]
"Currently, this task takes years of development and exploration by expert chemists and pharmacologists.",1. Introduction,[0],[0]
Our ultimate goal is to automate this process.,1. Introduction,[0],[0]
"From a computational perspective, we decompose the challenge into two complementary subtasks: learning to represent molecules in a continuous manner that facilitates the prediction and optimization of their properties (encoding); and learning to map an optimized continuous representation back into a molecular graph with improved properties (decoding).",1. Introduction,[0],[0]
"While deep learning has been extensively investigated for molecular graph encoding (Duvenaud et al., 2015; Kearnes et al., 2016; Gilmer et al., 2017), the harder combinatorial task of molecular graph generation from latent representation remains under-explored.
",1. Introduction,[0],[0]
1MIT Computer Science & Artificial Intelligence Lab.,1. Introduction,[0],[0]
"Correspondence to: Wengong Jin <wengong@csail.mit.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"Prior work on drug design formulated the graph generation task as a string generation problem (Gómez-Bombarelli et al., 2016; Kusner et al., 2017) in an attempt to side-step direct generation of graphs.",1. Introduction,[0],[0]
"Specifically, these models start by generating SMILES (Weininger, 1988), a linear string notation used in chemistry to describe molecular structures.",1. Introduction,[0],[0]
"SMILES strings can be translated into graphs via deterministic mappings (e.g., using RDKit (Landrum, 2006)).",1. Introduction,[0],[0]
"However, this design has two critical limitations.",1. Introduction,[0],[0]
"First, the SMILES representation is not designed to capture molecular similarity.",1. Introduction,[0],[0]
"For instance, two molecules with similar chemical structures may be encoded into markedly different SMILES strings (e.g., Figure 1).",1. Introduction,[0],[0]
This prevents generative models like variational autoencoders from learning smooth molecular embeddings.,1. Introduction,[0],[0]
"Second, essential chemical properties such as molecule validity are easier to express on graphs rather than linear SMILES representations.",1. Introduction,[0],[0]
"We hypothesize that operating directly on graphs improves generative modeling of valid chemical structures.
",1. Introduction,[0],[0]
Our primary contribution is a new generative model of molecular graphs.,1. Introduction,[0],[0]
While one could imagine solving the problem in a standard manner – generating graphs node by node – the approach is not ideal for molecules.,1. Introduction,[0],[0]
"This is because creating molecules atom by atom would force the model to generate chemically invalid intermediaries (see, e.g., Figure 2), delaying validation until a complete graph is generated.",1. Introduction,[0],[0]
"Instead, we propose to generate molecular graphs in two phases by exploiting valid subgraphs as components.",1. Introduction,[0],[0]
"The overall generative approach, cast as a junction tree variational autoencoder, first generates a tree structured object (a junction tree) whose role is to represent the scaffold of subgraph components and their coarse relative arrangements.",1. Introduction,[0],[0]
The components are valid chemical substructures automatically extracted from the training set using tree decomposition and are used as building blocks.,1. Introduction,[0],[0]
"In the sec-
ond phase, the subgraphs (nodes in the tree) are assembled together into a coherent molecular graph.
",1. Introduction,[0],[0]
We evaluate our model on multiple tasks ranging from molecular generation to optimization of a given molecule according to desired properties.,1. Introduction,[0],[0]
"As baselines, we utilize state-of-the-art SMILES-based generation approaches (Kusner et al., 2017; Dai et al., 2018).",1. Introduction,[0],[0]
"We demonstrate that our model produces 100% valid molecules when sampled from a prior distribution, outperforming the top performing baseline by a significant margin.",1. Introduction,[0],[0]
"In addition, we show that our model excels in discovering molecules with desired properties, yielding a 30% relative gain over the baselines.",1. Introduction,[0],[0]
"Our approach extends the variational autoencoder (Kingma & Welling, 2013) to molecular graphs by introducing a suitable encoder and a matching decoder.",2. Junction Tree Variational Autoencoder,[0],[0]
"Deviating from previous work (Gómez-Bombarelli et al., 2016; Kusner et al., 2017), we interpret each molecule as having been built from subgraphs chosen out of a vocabulary of valid components.",2. Junction Tree Variational Autoencoder,[0],[0]
These components are used as building blocks both when encoding a molecule into a vector representation as well as when decoding latent vectors back into valid molecular graphs.,2. Junction Tree Variational Autoencoder,[0],[0]
"The key advantage of this view is that the decoder can realize a valid molecule piece by piece by utilizing the collection of valid components and how they interact, rather than trying to build the molecule atom by atom through chemically invalid intermediaries (Figure 2).",2. Junction Tree Variational Autoencoder,[0],[0]
"An aromatic bond, for example, is chemically invalid on its own unless the entire aromatic ring is present.",2. Junction Tree Variational Autoencoder,[0],[0]
"It would be therefore challenging to learn to build rings atom by atom rather than by introducing rings as part of the basic vocabulary.
",2. Junction Tree Variational Autoencoder,[0],[0]
"Our vocabulary of components, such as rings, bonds and individual atoms, is chosen to be large enough so that a given molecule can be covered by overlapping components or clusters of atoms.",2. Junction Tree Variational Autoencoder,[0],[0]
"The clusters serve the role analogous to cliques in graphical models, as they are expressive enough that a molecule can be covered by overlapping clusters without forming cluster cycles.",2. Junction Tree Variational Autoencoder,[0],[0]
"In this sense, the clusters serve as cliques in a (non-optimal) triangulation of the molecular graph.",2. Junction Tree Variational Autoencoder,[0],[0]
We form a junction tree of such clusters and use it as the tree representation of the molecule.,2. Junction Tree Variational Autoencoder,[0],[0]
"Since our choice of cliques is constrained a priori, we cannot guarantee that a junction tree exists with such clusters for an arbitrary
molecule.",2. Junction Tree Variational Autoencoder,[0],[0]
"However, our clusters are built on the basis of the molecules in the training set to ensure that a corresponding junction tree can be found.",2. Junction Tree Variational Autoencoder,[0],[0]
"Empirically, our clusters cover most of the molecules in the test set.
",2. Junction Tree Variational Autoencoder,[0],[0]
The original molecular graph and its associated junction tree offer two complementary representations of a molecule.,2. Junction Tree Variational Autoencoder,[0],[0]
We therefore encode the molecule into a two-part latent representation z,2. Junction Tree Variational Autoencoder,[0],[0]
=,2. Junction Tree Variational Autoencoder,[0],[0]
"[zT , zG] where zT encodes the tree structure and what the clusters are in the tree without fully capturing how exactly the clusters are mutually connected.",2. Junction Tree Variational Autoencoder,[0],[0]
zG encodes the graph to capture the fine-grained connectivity.,2. Junction Tree Variational Autoencoder,[0],[0]
Both parts are created by tree and graph encoders q(zT |T ) and q(zG|G).,2. Junction Tree Variational Autoencoder,[0],[0]
The latent representation is then decoded back into a molecular graph in two stages.,2. Junction Tree Variational Autoencoder,[0],[0]
"As illustrated in Figure 3, we first reproduce the junction tree using a tree decoder p(T |zT )",2. Junction Tree Variational Autoencoder,[0],[0]
based on the information in zT .,2. Junction Tree Variational Autoencoder,[0],[0]
"Second, we predict the fine grain connectivity between the clusters in the junction tree using a graph decoder p(G|T , zG) to realize the full molecular graph.",2. Junction Tree Variational Autoencoder,[0],[0]
"The junction tree approach allows us to maintain chemical feasibility during generation.
",2. Junction Tree Variational Autoencoder,[0],[0]
"Notation A molecular graph is defined as G = (V,E) where V is the set of atoms (vertices) and E the set of bonds (edges).",2. Junction Tree Variational Autoencoder,[0],[0]
Let N(x) be the neighbor of x. We denote sigmoid function as σ(·) and ReLU function as τ(·).,2. Junction Tree Variational Autoencoder,[0],[0]
"We use i, j, k for nodes in the tree and u, v, w for nodes in the graph.",2. Junction Tree Variational Autoencoder,[0],[0]
A tree decomposition maps a graph G into a junction tree by contracting certain vertices into a single node so that G becomes cycle-free.,2.1. Junction Tree,[0],[0]
"Formally, given a graph G, a junction tree TG = (V, E ,X ) is a connected labeled tree whose node set is V = {C1, · · · , Cn} and edge set is E .",2.1. Junction Tree,[0],[0]
"Each node or cluster Ci = (Vi, Ei) is an induced subgraph of G, satisfying the following constraints:
1.",2.1. Junction Tree,[0],[0]
"The union of all clusters equals G. That is, ⋃ i Vi = V
and ⋃ iEi = E.
2.",2.1. Junction Tree,[0],[0]
"Running intersection: For all clusters Ci, Cj and Ck, Vi ∩ Vj ⊆ Vk if Ck is on the path from Ci to Cj .
",2.1. Junction Tree,[0],[0]
"Viewing induced subgraphs as cluster labels, junction trees are labeled trees with label vocabulary X .",2.1. Junction Tree,[0],[0]
"By our molecule tree decomposition, X contains only cycles (rings) and single edges.",2.1. Junction Tree,[0],[0]
"Thus the vocabulary size is limited (|X | = 780 for a standard dataset with 250K molecules).
",2.1. Junction Tree,[0],[0]
"Tree Decomposition of Molecules Here we present our tree decomposition algorithm tailored for molecules, which finds its root in chemistry (Rarey & Dixon, 1998).",2.1. Junction Tree,[0],[0]
Our cluster vocabulary X includes chemical structures such as bonds and rings (Figure 3).,2.1. Junction Tree,[0],[0]
"Given a graphG, we first find all its simple cycles, and its edges not belonging to any cycles.",2.1. Junction Tree,[0],[0]
"Two simple rings are merged together if they have more than two overlapping atoms, as they constitute a specific structure called bridged compounds (Clayden et al., 2001).",2.1. Junction Tree,[0],[0]
Each of those cycles or edges is considered as a cluster.,2.1. Junction Tree,[0],[0]
"Next, a cluster graph is constructed by adding edges between all intersecting clusters.",2.1. Junction Tree,[0],[0]
"Finally, we select one of its spanning trees as the junction tree of G (Figure 3).",2.1. Junction Tree,[0],[0]
"As a result of ring merging, any two clusters in the junction tree have at most two atoms in common, facilitating efficient inference in the graph decoding phase.",2.1. Junction Tree,[0],[0]
The detailed procedure is described in the supplementary.,2.1. Junction Tree,[0],[0]
"We first encode the latent representation of G by a graph message passing network (Dai et al., 2016; Gilmer et al., 2017).",2.2. Graph Encoder,[0],[0]
"Each vertex v has a feature vector xv indicating the atom type, valence, and other properties.",2.2. Graph Encoder,[0],[0]
"Similarly, each edge (u, v) ∈ E has a feature vector xuv indicating its bond type, and two hidden vectors νuv and νvu denoting the message from u to v and vice versa.",2.2. Graph Encoder,[0],[0]
"Due to the loopy structure of the graph, messages are exchanged in a loopy belief propagation fashion:
ν(t)uv = τ(W",2.2. Graph Encoder,[0],[0]
"g 1xu +W g 2xuv +W g 3 ∑ w∈N(u)\v ν(t−1)wu ) (1)
where ν(t)uv is the message computed in t-th iteration, initialized with ν(0)uv = 0.",2.2. Graph Encoder,[0],[0]
"After T steps of iteration, we aggregate
those messages as the latent vector of each vertex, which captures its local graphical structure:
hu =",2.2. Graph Encoder,[0],[0]
"τ(U g 1xu + ∑ v∈N(u) Ug2ν (T ) vu ) (2)
",2.2. Graph Encoder,[0],[0]
The final graph representation is hG = ∑ i hi/|V |.,2.2. Graph Encoder,[0],[0]
The mean µG and log variance logσG of the variational posterior approximation are computed from hG with two separate affine layers.,2.2. Graph Encoder,[0],[0]
"zG is sampled from a Gaussian N (µG,σG).",2.2. Graph Encoder,[0],[0]
We similarly encode TG with a tree message passing network.,2.3. Tree Encoder,[0],[0]
Each cluster Ci is represented by a one-hot encoding xi representing its label type.,2.3. Tree Encoder,[0],[0]
"Each edge (Ci, Cj) is associated with two message vectors mij and mji.",2.3. Tree Encoder,[0],[0]
We pick an arbitrary leaf node as the root and propagate messages in two phases.,2.3. Tree Encoder,[0],[0]
"In the first bottom-up phase, messages are initiated from the leaf nodes and propagated iteratively towards root.",2.3. Tree Encoder,[0],[0]
"In the top-down phase, messages are propagated from the root to all the leaf nodes.",2.3. Tree Encoder,[0],[0]
"Message mij is updated as:
mij = GRU(xi, {mki}k∈N(i)\j) (3)
where GRU is a Gated Recurrent Unit (Chung et al., 2014; Li et al., 2015) adapted for tree message passing:
sij = ∑
k∈N(i)\j mki (4)
",2.3. Tree Encoder,[0],[0]
zij = σ(W zxi +U zsij + b z) (5) rki = σ(W rxi +U rmki + b r),2.3. Tree Encoder,[0],[0]
"(6)
m̃ij = tanh(Wxi +U ∑
k∈N(i)\j
rki mki) (7)
mij = (1− zij) sij + zij m̃ij (8)
The message passing follows the schedule where mij is computed only when all its precursors {mki | k ∈ N(i)\j} have been computed.",2.3. Tree Encoder,[0],[0]
"This architectural design is motivated by the belief propagation algorithm over trees and is thus different from the graph encoder.
",2.3. Tree Encoder,[0],[0]
"After the message passing, we obtain the latent representation of each node hi by aggregating its inward messages:
hi = τ(W oxi + ∑ k∈N(i) Uomki) (9)
",2.3. Tree Encoder,[0],[0]
"The final tree representation is hTG = hroot, which encodes a rooted tree (T , root).",2.3. Tree Encoder,[0],[0]
"Unlike the graph encoder, we do not apply node average pooling because it confuses the tree decoder which node to generate first.",2.3. Tree Encoder,[0],[0]
zTG is sampled in a similar way as in the graph encoder.,2.3. Tree Encoder,[0],[0]
"For simplicity, we abbreviate zTG as zT from now on.
",2.3. Tree Encoder,[0],[0]
This tree encoder plays two roles in our framework.,2.3. Tree Encoder,[0],[0]
"First, it is used to compute zT , which only requires the bottom-up phase of the network.",2.3. Tree Encoder,[0],[0]
"Second, after a tree T̂ is decoded
from zT , it is used to compute messages m̂ij over the entire T̂ , to provide essential contexts of every node during graph decoding.",2.3. Tree Encoder,[0],[0]
This requires both top-down and bottom-up phases.,2.3. Tree Encoder,[0],[0]
We will elaborate this in section 2.5.,2.3. Tree Encoder,[0],[0]
We decode a junction tree T from its encoding zT with a tree structured decoder.,2.4. Tree Decoder,[0],[0]
The tree is constructed in a top-down fashion by generating one node at a time.,2.4. Tree Decoder,[0],[0]
"As illustrated in Figure 4, our tree decoder traverses the entire tree from the root, and generates nodes in their depth-first order.",2.4. Tree Decoder,[0],[0]
"For every visited node, the decoder first makes a topological prediction: whether this node has children to be generated.",2.4. Tree Decoder,[0],[0]
"When a new child node is created, we predict its label and recurse this process.",2.4. Tree Decoder,[0],[0]
Recall that cluster labels represent subgraphs in a molecule.,2.4. Tree Decoder,[0],[0]
"The decoder backtracks when a node has no more children to generate.
",2.4. Tree Decoder,[0],[0]
"At each time step, a node receives information from other nodes in the current tree for making those predictions.",2.4. Tree Decoder,[0],[0]
The information is propagated through message vectors hij when trees are incrementally constructed.,2.4. Tree Decoder,[0],[0]
"Formally, let Ẽ = {(i1, j1), · · · , (im, jm)} be the edges traversed in a depth first traversal over T = (V, E), where m = 2|E| as each edge is traversed in both directions.",2.4. Tree Decoder,[0],[0]
The model visits node it at time t. Let Ẽt be the first t edges in Ẽ .,2.4. Tree Decoder,[0],[0]
"The message hit,jt is updated through previous messages:
hit,jt = GRU(xit , {hk,it}(k,it)∈Ẽt,k 6=jt) (10)
where GRU is the same recurrent unit as in the tree encoder.
",2.4. Tree Decoder,[0],[0]
"Topological Prediction When the model visits node it, it makes a binary prediction on whether it still has children to be generated.",2.4. Tree Decoder,[0],[0]
"We compute this probability by combining
Algorithm 1 Tree decoding at sampling time Require:",2.4. Tree Decoder,[0],[0]
"Latent representation zT
1: Initialize: Tree T̂ ← ∅ 2: function SampleTree(i, t) 3:",2.4. Tree Decoder,[0],[0]
Set Xi ← all cluster labels that are chemically compatible with node i and its current neighbors.,2.4. Tree Decoder,[0],[0]
4: Set dt ← expand with probability pt. .,2.4. Tree Decoder,[0],[0]
Eq.(11) 5:,2.4. Tree Decoder,[0],[0]
if dt = expand and Xi 6= ∅,2.4. Tree Decoder,[0],[0]
then 6: Create a node j and add it to tree T̂ .,2.4. Tree Decoder,[0],[0]
"7: Sample the label of node j from Xi .. Eq.(12) 8: SampleTree(j, t+ 1) 9: end if
10: end function
zT , node features xit and inward messages hk,it via a one hidden layer network followed by a sigmoid function:
pt = σ(u d ·τ(Wd1xit+Wd2zT +Wd3 ∑ (k,it)∈Ẽt hk,it) (11)
Label Prediction When a child node j is generated from its parent i, we predict its node label with
qj = softmax(Ulτ(Wl1zT",2.4. Tree Decoder,[0],[0]
+,2.4. Tree Decoder,[0],[0]
W l 2hij)),2.4. Tree Decoder,[0],[0]
"(12)
where qj is a distribution over label vocabulary X .",2.4. Tree Decoder,[0],[0]
"When j is a root node, its parent i is a virtual node and hij = 0.
",2.4. Tree Decoder,[0],[0]
Learning The tree decoder aims to maximize the likelihood p(T |zT ).,2.4. Tree Decoder,[0],[0]
"Let p̂t ∈ {0, 1} and q̂j be the ground truth topological and label values, the decoder minimizes the following cross entropy loss:1
Lc(T ) =",2.4. Tree Decoder,[0],[0]
"∑
t Ld(pt, p̂t)",2.4. Tree Decoder,[0],[0]
"+ ∑ j Ll(qj , q̂j) (13)
",2.4. Tree Decoder,[0],[0]
"Similar to sequence generation, during training we perform teacher forcing: after topological and label prediction at each step, we replace them with their ground truth so that the model makes predictions given correct histories.
",2.4. Tree Decoder,[0],[0]
Decoding & Feasibility Check Algorithm 1 shows how a tree is sampled from zT .,2.4. Tree Decoder,[0],[0]
The tree is constructed recursively guided by topological predictions without any external guidance used in training.,2.4. Tree Decoder,[0],[0]
"To ensure the sampled tree could be realized into a valid molecule, we define set Xi to be cluster labels that are chemically compatible with node i and its current neighbors.",2.4. Tree Decoder,[0],[0]
"When a child node j is generated from node i, we sample its label from Xi with a renormalized distribution qj over Xi by masking out invalid labels.",2.4. Tree Decoder,[0],[0]
"The final step of our model is to reproduce a molecular graph G that underlies the predicted junction tree T̂ = (V̂, Ê).
",2.5. Graph Decoder,[0],[0]
1The node ordering is not unique as the order within sibling nodes is ambiguous.,2.5. Graph Decoder,[0],[0]
"In this paper we train our model with one ordering and leave this issue for future work.
",2.5. Graph Decoder,[0],[0]
Note that this step is not deterministic since there are potentially many molecules that correspond to the same junction tree.,2.5. Graph Decoder,[0],[0]
The underlying degree of freedom pertains to how neighboring clusters Ci and Cj are attached to each other as subgraphs.,2.5. Graph Decoder,[0],[0]
"Our goal here is to assemble the subgraphs (nodes in the tree) together into the correct molecular graph.
",2.5. Graph Decoder,[0],[0]
Let G(T ) be the set of graphs whose junction tree is T .,2.5. Graph Decoder,[0],[0]
"Decoding graph Ĝ from T̂ = (V̂, Ê) is a structured prediction:
Ĝ = arg max G′∈G(T̂ )
",2.5. Graph Decoder,[0],[0]
"fa(G′) (14)
where fa is a scoring function over candidate graphs.",2.5. Graph Decoder,[0],[0]
We only consider scoring functions that decompose across the clusters and their neighbors.,2.5. Graph Decoder,[0],[0]
"In other words, each term in the scoring function depends only on how a cluster Ci is attached to its neighboring clusters",2.5. Graph Decoder,[0],[0]
"Cj , j ∈ NT̂ (i) in the tree T̂ .",2.5. Graph Decoder,[0],[0]
The problem of finding the highest scoring graph Ĝ – the assembly task – could be cast as a graphical model inference task in a model induced by the junction tree.,2.5. Graph Decoder,[0],[0]
"However, for efficiency reasons, we will assemble the molecular graph one neighborhood at a time, following the order in which the tree itself was decoded.",2.5. Graph Decoder,[0],[0]
"In other words, we start by sampling the assembly of the root and its neighbors according to their
scores.",2.5. Graph Decoder,[0],[0]
"Then we proceed to assemble the neighbors and their associated clusters (removing the degrees of freedom set by the root assembly), and so on.
",2.5. Graph Decoder,[0],[0]
It remains to be specified how each neighborhood realization is scored.,2.5. Graph Decoder,[0],[0]
"Let Gi be the subgraph resulting from a particular merging of cluster Ci in the tree with its neighbors Cj , j ∈ NT̂ (i).",2.5. Graph Decoder,[0],[0]
We score Gi as a candidate subgraph by first deriving a vector representation hGi and then using fai (Gi) = hGi · zG as the subgraph score.,2.5. Graph Decoder,[0],[0]
"To this end, let u, v specify atoms in the candidate subgraph Gi and let αv = i",2.5. Graph Decoder,[0],[0]
if v ∈ Ci and αv = j if v ∈,2.5. Graph Decoder,[0],[0]
Cj \ Ci.,2.5. Graph Decoder,[0],[0]
"The indices αv are used to mark the position of the atoms in the junction tree, and to retrieve messages m̂i,j summarizing the subtree under i along the edge (i, j) obtained by running the tree encoding algorithm.",2.5. Graph Decoder,[0],[0]
"The neural messages pertaining to the atoms and bonds in subgraph Gi are obtained and aggregated into hGi , similarly to the encoding step, but with different (learned) parameters:
µ(t)uv = τ(W a 1xu +W a 2xuv +W a 3µ̃ (t−1) uv ) (15)
µ̃(t−1)uv =
{∑ w∈N(u)\v µ (t−1) wu",2.5. Graph Decoder,[0],[0]
"αu = αv
m̂αu,αv + ∑ w∈N(u)\v µ",2.5. Graph Decoder,[0],[0]
(t−1) wu,2.5. Graph Decoder,[0],[0]
"αu 6= αv
The major difference from Eq.",2.5. Graph Decoder,[0],[0]
"(1) is that we augment the model with tree messages m̂αu,αv derived by running the tree encoder over the predicted tree T̂ .",2.5. Graph Decoder,[0],[0]
"m̂αu,αv provides a tree dependent positional context for bond (u, v) (illustrated as subtree A in Figure 5).
",2.5. Graph Decoder,[0],[0]
"Learning The graph decoder parameters are learned to maximize the log-likelihood of predicting correct subgraphs Gi of the ground true graph G at each tree node:
Lg(G)",2.5. Graph Decoder,[0],[0]
= ∑ i fa(Gi)− log ∑ G′i∈Gi exp(fa(G′i))  ,2.5. Graph Decoder,[0],[0]
"(16) where Gi is the set of possible candidate subgraphs at tree node i. During training, we again apply teacher forcing, i.e. we feed the graph decoder with ground truth trees as input.
",2.5. Graph Decoder,[0],[0]
Complexity,2.5. Graph Decoder,[0],[0]
"By our tree decomposition, any two clusters share at most two atoms, so we only need to merge at most two atoms or one bond.",2.5. Graph Decoder,[0],[0]
"By pruning chemically invalid subgraphs and merging isomorphic graphs, |Gi| ≈ 4 on average when tested on a standard ZINC drug dataset.",2.5. Graph Decoder,[0],[0]
"The computational complexity of JT-VAE is therefore linear in the number of clusters, scaling nicely to large graphs.",2.5. Graph Decoder,[0],[0]
Our evaluation efforts measure various aspects of molecular generation.,3. Experiments,[0],[0]
"The first two evaluations follow previously proposed tasks (Kusner et al., 2017).",3. Experiments,[0],[0]
"We also introduce a third task — constrained molecule optimization.
",3. Experiments,[0],[0]
"• Molecule reconstruction and validity We test the VAE models on the task of reconstructing input molecules from their latent representations, and decoding valid molecules when sampling from prior distribution.",3. Experiments,[0],[0]
(Section 3.1) •,3. Experiments,[0],[0]
"Bayesian optimization Moving beyond generating valid
molecules, we test how the model can produce novel molecules with desired properties.",3. Experiments,[0],[0]
"To this end, we perform Bayesian optimization in the latent space to search molecules with specified properties.",3. Experiments,[0],[0]
"(Section 3.2)
• Constrained molecule optimization The task is to modify given molecules to improve specified properties, while constraining the degree of deviation from the original molecule.",3. Experiments,[0],[0]
"This is a more realistic scenario in drug discovery, where development of new drugs usually starts with known molecules such as existing drugs (Besnard et al., 2012).",3. Experiments,[0],[0]
"Since it is a new task, we cannot compare to any existing baselines.",3. Experiments,[0],[0]
"(Section 3.3)
",3. Experiments,[0],[0]
"Below we describe the data, baselines and model configuration that are shared across the tasks.",3. Experiments,[0],[0]
"Additional setup details are provided in the task-specific sections.
",3. Experiments,[0],[0]
"Data We use the ZINC molecule dataset from Kusner et al. (2017) for our experiments, with the same training/testing split.",3. Experiments,[0],[0]
"It contains about 250K drug molecules extracted from the ZINC database (Sterling & Irwin, 2015).
",3. Experiments,[0],[0]
"Baselines We compare our approach with SMILES-based baselines: 1) Character VAE (CVAE) (Gómez-Bombarelli et al., 2016) which generates SMILES strings character by character; 2) Grammar VAE (GVAE) (Kusner et al., 2017) that generates SMILES following syntactic constraints given
by a context-free grammar; 3) Syntax-directed VAE (SDVAE) (Dai et al., 2018) that incorporates both syntactic and semantic constraints of SMILES via attribute grammar.",3. Experiments,[0],[0]
"For molecule generation task, we also compare with GraphVAE (Simonovsky & Komodakis, 2018) that directly generates atom labels and adjacency matrices of graphs.
",3. Experiments,[0],[0]
"Model Configuration To be comparable with the above baselines, we set the latent space dimension as 56, i.e., the tree and graph representation hT and hG have 28 dimensions each.",3. Experiments,[0],[0]
Full training details and model configurations are provided in the appendix.,3. Experiments,[0],[0]
Setup The first task is to reconstruct and sample molecules from latent space.,3.1. Molecule Reconstruction and Validity,[0],[0]
"Since both encoding and decoding process are stochastic, we estimate reconstruction accuracy by Monte Carlo method used in (Kusner et al., 2017):",3.1. Molecule Reconstruction and Validity,[0],[0]
Each molecule is encoded 10 times and each encoding is decoded 10 times.,3.1. Molecule Reconstruction and Validity,[0],[0]
"We report the portion of the 100 decoded molecules that are identical to the input molecule.
",3.1. Molecule Reconstruction and Validity,[0],[0]
"To compute validity, we sample 1000 latent vectors from the prior distribution N (0, I), and decode each of these vectors 100 times.",3.1. Molecule Reconstruction and Validity,[0],[0]
We report the percentage of decoded molecules that are chemically valid (checked by RDKit).,3.1. Molecule Reconstruction and Validity,[0],[0]
"For ablation study, we also report the validity of our model without validity check in decoding phase.
",3.1. Molecule Reconstruction and Validity,[0],[0]
"Results Table 1 shows that JT-VAE outperforms previous models in molecule reconstruction, and always pro-
duces valid molecules when sampled from prior distribution.",3.1. Molecule Reconstruction and Validity,[0],[0]
"When validity check is removed, our model could still generates 93.5% valid molecules.",3.1. Molecule Reconstruction and Validity,[0],[0]
This shows our method does not heavily rely on prior knowledge.,3.1. Molecule Reconstruction and Validity,[0],[0]
"As shown in Figure 6, the sampled molecules have non-trivial structures such as simple chains.",3.1. Molecule Reconstruction and Validity,[0],[0]
We further sampled 5000 molecules from prior and found they are all distinct from the training set.,3.1. Molecule Reconstruction and Validity,[0],[0]
"Thus our model is not a simple memorization.
",3.1. Molecule Reconstruction and Validity,[0],[0]
Analysis We qualitatively examine the latent space of JTVAE by visualizing the neighborhood of molecules.,3.1. Molecule Reconstruction and Validity,[0],[0]
"Given a molecule, we follow the method in Kusner et al. (2017) to construct a grid visualization of its neighborhood.",3.1. Molecule Reconstruction and Validity,[0],[0]
Figure 6 shows the local neighborhood of the same molecule visualized in Dai et al. (2018).,3.1. Molecule Reconstruction and Validity,[0],[0]
"In comparison, our neighborhood does not contain molecules with huge rings (with more than 7 atoms), which rarely occur in the dataset.",3.1. Molecule Reconstruction and Validity,[0],[0]
We also highlight two groups of closely resembling molecules that have identical tree structures but vary only in how clusters are attached together.,3.1. Molecule Reconstruction and Validity,[0],[0]
This demonstrates the smoothness of learned molecular embeddings.,3.1. Molecule Reconstruction and Validity,[0],[0]
Setup The second task is to produce novel molecules with desired properties.,3.2. Bayesian Optimization,[0],[0]
"Following (Kusner et al., 2017), our target chemical property y(·) is octanol-water partition coefficients (logP) penalized by the synthetic accessibility (SA) score and number of long cycles.2 To perform Bayesian optimization (BO), we first train a VAE and associate each molecule with a latent vector, given by the mean of the variational encoding distribution.",3.2. Bayesian Optimization,[0],[0]
"After the VAE is learned, we train a sparse Gaussian process (SGP) to predict y(m) given its latent representation.",3.2. Bayesian Optimization,[0],[0]
"Then we perform five iterations of batched BO using the expected improvement heuristic.
",3.2. Bayesian Optimization,[0],[0]
"For comparison, we report 1) the predictive performance of SGP trained on latent encodings learned by different VAEs, measured by log-likelihood (LL) and root mean square error (RMSE) with 10-fold cross validation.",3.2. Bayesian Optimization,[0],[0]
"2) The top-3 molecules found by BO under different models.
2y(m) = logP (m) − SA(m)",3.2. Bayesian Optimization,[0],[0]
"− cycle(m) where cycle(m) counts the number of rings that have more than six atoms.
",3.2. Bayesian Optimization,[0],[0]
"Results As shown in Table 2, JT-VAE finds molecules with significantly better scores than previous methods.",3.2. Bayesian Optimization,[0],[0]
Figure 7 lists the top-3 best molecules found by JT-VAE.,3.2. Bayesian Optimization,[0],[0]
"In fact, JT-VAE finds over 50 molecules with scores over 3.50 (the second best molecule proposed by SD-VAE).",3.2. Bayesian Optimization,[0],[0]
"Moreover, the SGP yields better predictive performance when trained on JT-VAE embeddings (Table 3).",3.2. Bayesian Optimization,[0],[0]
Setup The third task is to perform molecule optimization in a constrained scenario.,3.3. Constrained Optimization,[0],[0]
"Given a molecule m, the task is to find a different molecule m′ that has the highest property value with the molecular similarity sim(m,m′)",3.3. Constrained Optimization,[0],[0]
≥ δ for some threshold δ.,3.3. Constrained Optimization,[0],[0]
"We use Tanimoto similarity with Morgan fingerprint (Rogers & Hahn, 2010) as the similarity metric, and penalized logP coefficient as our target chemical property.",3.3. Constrained Optimization,[0],[0]
"For this task, we jointly train a property predictor F (parameterized by a feed-forward network) with JT-VAE to predict y(m) from the latent embedding of m. To optimize a molecule m, we start from its latent representation, and apply gradient ascent in the latent space to improve the predicted score F (·), similar to (Mueller et al., 2017).",3.3. Constrained Optimization,[0],[0]
"After applying K = 80 gradient steps, K molecules are decoded from resulting latent trajectories, and we report the molecule with the highest F (·) that satisfies the similarity constraint.",3.3. Constrained Optimization,[0],[0]
"A modification succeeds if one of the decoded molecules satisfies the constraint and is distinct from the original.
",3.3. Constrained Optimization,[0],[0]
"To provide the greatest challenge, we selected 800 molecules with the lowest property score y(·) from the test set.",3.3. Constrained Optimization,[0],[0]
"We report the success rate (how often a modification succeeds), and among success cases the average improvement y(m′)− y(m) and molecular similarity sim(m,m′) between the original and modified molecules m and m′.
Results Our results are summarized in Table 4.",3.3. Constrained Optimization,[0],[0]
"The unconstrained scenario (δ = 0) has the best average improvement, but often proposes dissimilar molecules.",3.3. Constrained Optimization,[0],[0]
"When we tighten the constraint to δ = 0.4, about 80% of the time our model finds similar molecules, with an average improvement 0.84.",3.3. Constrained Optimization,[0],[0]
This also demonstrates the smoothness of the learned latent space.,3.3. Constrained Optimization,[0],[0]
Figure 8 illustrates an effective modification resulting in a similar molecule with great improvement.,3.3. Constrained Optimization,[0],[0]
Molecule Generation Previous work on molecule generation mostly operates on SMILES strings.,4. Related Work,[0],[0]
GómezBombarelli,4. Related Work,[0],[0]
et al. (2016); Segler et al. (2017) built generative models of SMILES strings with recurrent decoders.,4. Related Work,[0],[0]
"Unfortunately, these models could generate invalid SMILES that do not result in any molecules.",4. Related Work,[0],[0]
"To remedy this issue, Kusner et al. (2017); Dai et al. (2018) complemented the decoder with syntactic and semantic constraints of SMILES by context free and attribute grammars, but these grammars do not fully capture chemical validity.",4. Related Work,[0],[0]
"Other techniques such as active learning (Janz et al., 2017) and reinforcement learning (Guimaraes et al., 2017) encourage the model to generate valid SMILES through additional training signal.",4. Related Work,[0],[0]
"Very recently, Simonovsky & Komodakis (2018) proposed to generate molecular graphs by predicting their adjacency matrices, and Li et al. (2018) generated molecules node by node.",4. Related Work,[0],[0]
"In comparison, our method enforces chemical validity and is more efficient due to the coarse-to-fine generation.
",4. Related Work,[0],[0]
Graph-structured Encoders,4. Related Work,[0],[0]
"The neural network formulation on graphs was first proposed by Gori et al. (2005); Scarselli et al. (2009), and later enhanced by Li et al. (2015) with gated recurrent units.",4. Related Work,[0],[0]
"For recurrent architectures over
graphs, Lei et al. (2017) designed Weisfeiler-Lehman kernel network inspired by graph kernels.",4. Related Work,[0],[0]
"Dai et al. (2016) considered a different architecture where graphs were viewed as latent variable graphical models, and derived their model from message passing algorithms.",4. Related Work,[0],[0]
"Our tree and graph encoder are closely related to this graphical model perspective, and to neural message passing networks (Gilmer et al., 2017).",4. Related Work,[0],[0]
"For convolutional architectures, Duvenaud et al. (2015) introduced a convolution-like propagation on molecular graphs, which was generalized to other domains by Niepert et al. (2016).",4. Related Work,[0],[0]
Bruna et al. (2013); Henaff et al. (2015) developed graph convolution in spectral domain via graph Laplacian.,4. Related Work,[0],[0]
"For applications, graph neural networks are used in semisupervised classification (Kipf & Welling, 2016), computer vision (Monti et al., 2016), and chemical domains (Kearnes et al., 2016; Schütt et al., 2017; Jin et al., 2017).
",4. Related Work,[0],[0]
Tree-structured Models,4. Related Work,[0],[0]
"Our tree encoder is related to recursive neural networks and tree-LSTM (Socher et al., 2013; Tai et al., 2015; Zhu et al., 2015).",4. Related Work,[0],[0]
These models encode tree structures where nodes in the tree are bottom-up transformed into vector representations.,4. Related Work,[0],[0]
"In contrast, our model propagates information both bottom-up and top-down.
",4. Related Work,[0],[0]
"On the decoding side, tree generation naturally arises in natural language parsing (Dyer et al., 2016; Kiperwasser & Goldberg, 2016).",4. Related Work,[0],[0]
"Different from our approach, natural language parsers have access to input words and only predict the topology of the tree.",4. Related Work,[0],[0]
"For general purpose tree generation, Vinyals et al. (2015); Aharoni & Goldberg (2017) applied recurrent networks to generate linearized version of trees, but their architectures were entirely sequence-based.",4. Related Work,[0],[0]
Dong & Lapata (2016); Alvarez-Melis & Jaakkola (2016) proposed tree-based architectures that construct trees top-down from the root.,4. Related Work,[0],[0]
"Our model is most closely related to Alvarez-Melis & Jaakkola (2016) that disentangles topological prediction from label prediction, but we generate nodes in a depth-first order and have additional steps that propagate information bottom-up.",4. Related Work,[0],[0]
"This forward-backward propagation also appears in Parisotto et al. (2016), but their model is node based whereas ours is based on message passing.",4. Related Work,[0],[0]
In this paper we present a junction tree variational autoencoder for generating molecular graphs.,5. Conclusion,[0],[0]
Our method significantly outperforms previous work in molecule generation and optimization.,5. Conclusion,[0],[0]
"For future work, we attempt to generalize our method for general low-treewidth graphs.",5. Conclusion,[0],[0]
"We thank Jonas Mueller, Chengtao Li, Tao Lei and MIT NLP Group for their helpful comments.",Acknowledgement,[0],[0]
This work was supported by the DARPA Make-It program under contract ARO W911NF-16-2-0023.,Acknowledgement,[0],[0]
We seek to automate the design of molecules based on specific chemical properties.,abstractText,[0],[0]
"In computational terms, this task involves continuous embedding and generation of molecular graphs.",abstractText,[0],[0]
"Our primary contribution is the direct realization of molecular graphs, a task previously approached by generating linear SMILES strings instead of graphs.",abstractText,[0],[0]
"Our junction tree variational autoencoder generates molecular graphs in two phases, by first generating a tree-structured scaffold over chemical substructures, and then combining them into a molecule with a graph message passing network.",abstractText,[0],[0]
This approach allows us to incrementally expand molecules while maintaining chemical validity at every step.,abstractText,[0],[0]
We evaluate our model on multiple tasks ranging from molecular generation to optimization.,abstractText,[0],[0]
"Across these tasks, our model outperforms previous state-of-the-art baselines by a significant margin.",abstractText,[0],[0]
Junction Tree Variational Autoencoder for Molecular Graph Generation,title,[0],[0]
"by using adaptively chosen pairwise comparisons. Our goal is to recover the ranking accurately but to sample the comparisons sparingly. If all comparison outcomes are consistent with the ranking, the optimal solution is to use an efficient sorting algorithm, such as Quicksort. But how do sorting algorithms behave if some comparison outcomes are inconsistent with the ranking? We give favorable guarantees for Quicksort for the popular Bradley–Terry model, under natural assumptions on the parameters. Furthermore, we empirically demonstrate that sorting algorithms lead to a very simple and effective active learning strategy: repeatedly sort the items. This strategy performs as well as state-of-the-art methods (and much better than random sampling) at a minuscule fraction of the computational cost.",text,[0],[0]
"The problem of recovering a ranking over n items from noisy outcomes of pairwise comparisons has attracted, in the last century, much research interest, driven by applications in sports (Elo, 1978), social sciences (Thurstone, 1927; Salganik & Levy, 2015) and—more recently—recommender systems (Houlsby et al., 2012).",1 Introduction,[0],[0]
"Whereas pairwise comparison models and related inference algorithms have been extensively studied, the issue of which pairwise comparisons to sample, also known as active learning, has received significantly less attention.",1 Introduction,[0],[0]
"To understand the potential benefits of adaptively selecting samples, consider the case where comparison outcomes are noiseless, i.e., consistent with a linear order on a set of n items.",1 Introduction,[0],[0]
"If pairs of items are selected at random, it is necessary to collect Ω(n2) comparisons to recover the ranking (Alon et al., 1994).",1 Introduction,[0],[0]
"In contrast, by using an efficient sorting algorithm, O(n log n) adaptively
1School of Computer and Communication Sciences, EPFL, Lausanne, Switzerland.",1 Introduction,[0],[0]
"Correspondence to: Lucas Maystre <lucas.maystre@epfl.ch>.
",1 Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1 Introduction,[0],[0]
"Copyright 2017 by the author(s).
chosen comparisons are sufficient.",1 Introduction,[0],[0]
"In this work, we demonstrate that sorting algorithms can also be helpful in the noisy setting, where some comparison outcomes are inconsistent with the ranking: despite errors, sorting algorithms tend to select informative samples.",1 Introduction,[0],[0]
"We focus on the Bradley–Terry (BT) model, a widely-used probabilistic model of comparison outcomes.",1 Introduction,[0],[0]
"In this model, each item is associated with a parameter on the real line, and the probability of observing an incorrect outcome decreases as the distance between the items’ parameters increases.
",1 Introduction,[0],[0]
"First, we study the output of a single execution of Quicksort when comparison outcomes are generated from a BT model, under the assumption that the distance between adjacent parameters is (stochastically) uniform across the ranking.",1 Introduction,[0],[0]
"We measure the quality of a ranking estimate by its displacement with respect to the ground truth, i.e., the sum of rank differences.",1 Introduction,[0],[0]
We show that Quicksort’s output is a good approximation to the ground-truth ranking: no method comparing every pair of items at most once can do better (up to constant factors).,1 Introduction,[0],[0]
"Furthermore, we show that by aggregating O(log5 n) independent runs of Quicksort, it is possible to recover the exact rank for all but a vanishing fraction of the items.",1 Introduction,[0],[0]
"These theoretical results suggest that adaptive sampling is able to bring a substantial acceleration to the learning process.
",1 Introduction,[0],[0]
"Second, we propose a practical active-learning (AL) strategy that consists of repeatedly sorting the items.",1 Introduction,[0],[0]
We evaluate our sorting-based method on three datasets and compare it to existing AL methods.,1 Introduction,[0],[0]
We observe that all the strategies that we consider lead to better ranking estimates noticeably faster than random sampling.,1 Introduction,[0],[0]
"However, most strategies are challenging to operate and computationally expensive, thus hindering wider adoption (Schein & Ungar, 2007).",1 Introduction,[0],[0]
"In this regard, sorting-based AL stands out, as a) it is computationally-speaking as inexpensive as random sampling, b) it is trivial to implement, and c)",1 Introduction,[0],[0]
it requires no tuning of hyperparameters.,1 Introduction,[0],[0]
"We consider n items that are represented by consecutive integers [n] = {1, . . .",1.1 Preliminaries and Notation,[0],[0]
", n}.",1.1 Preliminaries and Notation,[0],[0]
"Without loss of generality, we
assume that the items are ranked by increasing preference1, i.e., i < j means that j is (in expectation) preferred to i.",1.1 Preliminaries and Notation,[0],[0]
"When j is preferred to i as a result of a pairwise comparison, we denote the observation by i ≺ j.",1.1 Preliminaries and Notation,[0],[0]
"If i < j, we say that i ≺ j is a consistent outcome and j ≺ i an inconsistent (incorrect) outcome.",1.1 Preliminaries and Notation,[0],[0]
"In most of the paper, pairwise comparison outcomes follow a Bradley–Terry model with parameters θ = [ θ1 · · · θn ]
∈ Rn, denoted BT(θ).",1.1 Preliminaries and Notation,[0],[0]
"The parameters θ1 < · · · < θn represent the utilities of items 1, . . .",1.1 Preliminaries and Notation,[0],[0]
",",1.1 Preliminaries and Notation,[0],[0]
"n, and the probability of observing the outcome",1.1 Preliminaries and Notation,[0],[0]
"i ≺ j is
p(i ≺ j | θ) = 1
1 + exp[−(θj − θi)] .
",1.1 Preliminaries and Notation,[0],[0]
The probability of observing an inconsistent comparison decreases with the distance between the items.,1.1 Preliminaries and Notation,[0],[0]
"This captures the intuitive notion that some pairs of items are easy to compare and some are more difficult (Zermelo, 1928; Bradley & Terry, 1952).
",1.1 Preliminaries and Notation,[0],[0]
"A ranking σ is a function that maps an item to its rank, i.e., σ(i) = rank of item i.",1.1 Preliminaries and Notation,[0],[0]
"The (ground-truth) identity ranking is denoted by id, i.e. id(i) = i. To measure the quality of a ranking σ with respect to the ground-truth, we consider the displacement
∆(σ) =
n ∑
i=1
|σ(i)− i|,
also known as Spearman’s footrule distance.",1.1 Preliminaries and Notation,[0],[0]
"Another metric widely used in practice is the Kendall–Tau distance, defined as K(σ) =",1.1 Preliminaries and Notation,[0],[0]
"∑
i<j 1 {σ(i) > σ(j)}.",1.1 Preliminaries and Notation,[0],[0]
"Both metrics are equiv-
alent up to a factor of two2, such that bounds on ∆(σ) also hold for K(σ) up to constant factors.
",1.1 Preliminaries and Notation,[0],[0]
"Finally, we say that an event A holds with high probability if P [A] → 1 as n → ∞. For a random variable X and a sequence of numbers an, we say that X = O(an) with high probability if P",1.1 Preliminaries and Notation,[0],[0]
[|X| ≤ can]→,1.1 Preliminaries and Notation,[0],[0]
"1 as n→∞ for some constant c that does not depend on n.
Outline of the paper.",1.1 Preliminaries and Notation,[0],[0]
We begin by briefly reviewing related literature in Section 2.,1.1 Preliminaries and Notation,[0],[0]
"Next, in Section 3, we study the displacement of Quicksort’s output under noisy comparisons.",1.1 Preliminaries and Notation,[0],[0]
"In Section 4, we empirically evaluate several AL strategies on three datasets.",1.1 Preliminaries and Notation,[0],[0]
"Finally, we conclude in Section 5.",1.1 Preliminaries and Notation,[0],[0]
Passive setting.,2 Related Work,[0],[0]
"Recently, there have been a number of results on the sample complexity of the BT model, based on
1 This convention greatly simplifies the notation throughout the paper, but differs from that used in most of the preference learning literature.",2 Related Work,[0],[0]
"In our paper, the item with rank 1 is the worst.
2∆(σ)/2 ≤ K(σ)",2 Related Work,[0],[0]
"≤ ∆(σ) (Diaconis & Graham, 1977).
",2 Related Work,[0],[0]
"the assumption that all pairs of items are chosen before any comparison outcome is revealed (Negahban et al., 2012; Hajek et al., 2014; Rajkumar & Agarwal, 2014; Vojnovic & Yun, 2016).",2 Related Work,[0],[0]
"In general, these results reveal that choosing pairs of items uniformly at random is essentially optimal.",2 Related Work,[0],[0]
"Furthermore, they suggest that the ranking induced by the BT model cannot be recovered with less than Ω(n2) comparisons.",2 Related Work,[0],[0]
"Our work shows that by adaptively selecting pairs based on observed outcomes, we observe substantial gains.
",2 Related Work,[0],[0]
Active preference learning.,2 Related Work,[0],[0]
AL approaches for learning a ranking based on noisy comparison outcomes have been studied under various assumptions.,2 Related Work,[0],[0]
"Braverman & Mossel (2008) examine a model where outcomes of pairwise comparisons are flipped with a small, constant probability.",2 Related Work,[0],[0]
"Ailon (2012) considers an adversarial setting (comparison outcomes can be arbitrary) and investigates AL in the context of finding a ranking that minimizes the number of inconsistent outcomes, also known as the minimum feedback-arc set problem on tournaments (MFAST).",2 Related Work,[0],[0]
"These theoretical studies imply, in their respective settings, that O(n logk n) comparison outcomes are enough to recover a near-optimal ranking.",2 Related Work,[0],[0]
"Jamieson & Nowak (2011) propose an efficient active-ranking algorithm that is applicable if items can be embedded in Rd (e.g., using d features) and assuming that admissible rankings satisfy some geometric constraints.",2 Related Work,[0],[0]
Wang et al. (2014) study a collaborative preference-learning problem and show that a variant of uncertainty sampling (a well-known AL strategy) works well for their problem.,2 Related Work,[0],[0]
"In this work, we assume that we do not have access to item features and that comparison outcomes follow a single BT model.
",2 Related Work,[0],[0]
Bayesian methods.,2 Related Work,[0],[0]
"From a practical standpoint, Bayesian methods provide an effective way to select informative samples (MacKay, 1992).",2 Related Work,[0],[0]
"However, they can be difficult to scale if the number of items is large.",2 Related Work,[0],[0]
"Work on Bayesian active preference learning includes Chu & Ghahramani (2005), Houlsby et al. (2012), Salimans et al. (2012) and Chen et al. (2013).",2 Related Work,[0],[0]
"We compare our AL strategy to these methods in Section 4.
",2 Related Work,[0],[0]
Multi-armed bandit.,2 Related Work,[0],[0]
"The dueling bandit problem (Yue et al., 2009) is somewhat related to our work.",2 Related Work,[0],[0]
"In this problem, the goal is to identify the best item based on noisy comparison outcomes, using as few adaptively chosen samples as possible.",2 Related Work,[0],[0]
Two recent papers also extend the problem to that of recovering the entire ranking (instead of only the top element).,2 Related Work,[0],[0]
"The work of Szörényi et al. (2015) is the closest to ours, as it also uses the BT model.",2 Related Work,[0],[0]
"One of their results is similar to our Theorem 2: They show that a quasi-linear number of comparisons is sufficient to recover the true ranking, under some conditions on θ.",2 Related Work,[0],[0]
Heckel et al. (2016) investigate a non-parametric model and develop some theoretical guarantees.,2 Related Work,[0],[0]
"In contrast to these works, our paper studies practical
Algorithm 1 Quicksort
Require: set of items V 1: if |V | < 2 then return list(V ) ⊲",2 Related Work,[0],[0]
Terminating case.,2 Related Work,[0],[0]
"2: L← ∅, R← ∅ 3: p← element of V selected uniformly at random 4: for i ∈ V \ {p} do 5: if i ≺ p then ⊲",2 Related Work,[0],[0]
Pairwise comparison.,2 Related Work,[0],[0]
"6: L← L ∪ {i} 7: else
8: R← R ∪ {i}
9: return Quicksort(L) · p · Quicksort(R)
comparison budgets: we give theoretical guarantees for the output obtained from a single call to Quicksort, and in our experiments we never exceed ≈ 10 calls.
",2 Related Work,[0],[0]
Quicksort.,2 Related Work,[0],[0]
"The Quicksort algorithm (Hoare, 1962) is one of the most widely studied sorting procedures.",2 Related Work,[0],[0]
Quicksort has been shown to produce useful rankings beyond classic sorting problems.,2 Related Work,[0],[0]
"For example, Ailon et al. (2008) show that Quicksort produces (in expectation) a 3-approximation to the MFAST problem.",2 Related Work,[0],[0]
"Quicksort combined with BT comparison outcomes has also been proposed as a probabilistic ranking model (Ailon, 2008).",2 Related Work,[0],[0]
We take advantage of some of the properties of this ranking model in order to derive the theoretical results of Section 3.,2 Related Work,[0],[0]
"In this section, we begin by studying the behavior and output of Quicksort under inconsistent comparison outcomes, without any assumptions on the noise generating process.",3 Theoretical Results,[0],[0]
"Then, starting in Section 3.1, we focus on comparison outcomes generated by the BT model.",3 Theoretical Results,[0],[0]
"Due to limited space, most full proofs are deferred to the supplementary material (Section A).
",3 Theoretical Results,[0],[0]
Quicksort (Algorithm 1) is best described as a recursive procedure.,3 Theoretical Results,[0],[0]
"At each step of the recursion, a pivot item p is chosen uniformly at random (line 3).",3 Theoretical Results,[0],[0]
"Then, during the partition operation (lines 4–8), every other item is compared to p and added to the set L or R, depending on the outcome.",3 Theoretical Results,[0],[0]
"If all comparison outcomes are consistent, it is well-known that Quicksort terminates after sampling O(n log n) comparisons with high probability.",3 Theoretical Results,[0],[0]
What happens if we drop the consistency assumption?,3 Theoretical Results,[0],[0]
"The following two lemmas state that these key properties remain valid, no matter which (and how many) comparison outcomes are inconsistent.
",3 Theoretical Results,[0],[0]
Lemma 1.,3 Theoretical Results,[0],[0]
"Quicksort always terminates and samples each of the n(n−1)/2 possible comparisons at most once.
",3 Theoretical Results,[0],[0]
Proof.,3 Theoretical Results,[0],[0]
The proof is identical to the consistent setting.,3 Theoretical Results,[0],[0]
"Consider the state of L and R at the end of a partition operation.
",3 Theoretical Results,[0],[0]
"Because |L|+ |R| = |V |−1, the recursive calls are made on sets of items of strictly decreasing cardinality, and the algorithm terminates after a finite number of steps.",3 Theoretical Results,[0],[0]
"Furthermore, suppose that Quicksort samples an outcome for the pair (i, j).",3 Theoretical Results,[0],[0]
Then either i or j is the pivot in a partition operation.,3 Theoretical Results,[0],[0]
"In either case, the pivot is not included in the recursive calls, which ensures that (i, j) cannot be compared again.
",3 Theoretical Results,[0],[0]
Lemma 2.,3 Theoretical Results,[0],[0]
"Quicksort samples O(n log n) comparisons w.h.p.
",3 Theoretical Results,[0],[0]
Proof (sketch).,3 Theoretical Results,[0],[0]
"We follow a standard analysis of Quicksort (see, e.g., Dubhashi & Panconesi, 2009, Section 3.3.3).",3 Theoretical Results,[0],[0]
"With high probability, we choose a “good” pivot (i.e., one that results in a balanced partition) a constant fraction of the time.",3 Theoretical Results,[0],[0]
"In this case, the depth of the call tree is O(log n).",3 Theoretical Results,[0],[0]
"As there are at most n comparisons at each level of the call tree, we conclude that Quicksort uses O(n log n) comparisons in total.",3 Theoretical Results,[0],[0]
"With respect to the standard proof, we need some additional work to formalize the notion of “good” pivot to the setting where comparison outcomes are not consistent with a linear order.
",3 Theoretical Results,[0],[0]
"Lemma 2 complements Theorem 3 in Ailon & Mohri (2010), which states that Quicksort samples O(n log n) in expectation.",3 Theoretical Results,[0],[0]
These results might suggest that all properties of Quicksort carry over to the noisy setting.,3 Theoretical Results,[0],[0]
This is not the case.,3 Theoretical Results,[0],[0]
"For example, although Quicksort uses approximately 2n lnn comparisons on average in the noiseless setting (Sedgewick & Wayne, 2011), this number can be distinctly different with inconsistent comparison outcomes3.
Quicksort (and efficient sorting algorithms in general) infer most pairs of items’ relative position by transitivity and thus rely heavily on the consistency of comparison outcomes.",3 Theoretical Results,[0],[0]
"In the noisy case, it is therefore important to precisely understand the effect of an inconsistent outcome on the output of the algorithm; this effect extends beyond the pair of items whose comparison outcome was inconsistent.",3 Theoretical Results,[0],[0]
"For this purpose, the next Lemma bounds the displacement of Quicksort’s output as a function of the inconsistent outcomes.
",3 Theoretical Results,[0],[0]
Lemma 3.,3 Theoretical Results,[0],[0]
Let E be the set of pairs sampled by Quicksort and whose outcome is inconsistent with id. Let σ be the output.,3 Theoretical Results,[0],[0]
"Then,
∆(σ) ≤ 2 ∑
(i,j)∈E
|i− j|
Proof (sketch).",3 Theoretical Results,[0],[0]
"Consider the first partition operation, with pivot p, resulting in partitions L and R. Denote the errors
3E.g., if comparison outcomes are uniformly random, all items are “good” pivots w.h.p., and the average number of comparisons will be closer to n log
2 n on average, for large n.
made during this partition operation by E1.",3 Theoretical Results,[0],[0]
"We can show that the displacement is bounded by
∆(σ) ≤ ∆L(σ) + ∆R(σ) + 2 ∑
(i,j)∈E1
|i− j|,
where ∆L(σ) and ∆R(σ) represent the displacement of the ordering induced by σ on L and R, respectively.",3 Theoretical Results,[0],[0]
"In other words, the total displacement can be decomposed into a term that represents the “local” displacement due to the partition operation and into two terms that account for errors in the recursive calls.",3 Theoretical Results,[0],[0]
"We obtain the desired result by recursively bounding ∆L(σ) and ∆R(σ).
",3 Theoretical Results,[0],[0]
"Informally, Lemma 3 states that the displacement can be bounded by a sum of “local shifts” due to the inconsistent outcomes and that the price to pay for any information inferred by transitivity is bounded by a factor two.",3 Theoretical Results,[0],[0]
"Lemma 3 is a crucial component of our subsequent analysis of BT noise, and we believe that it can be useful in order to investigate Quicksort under a wide variety of other noise generating processes.",3 Theoretical Results,[0],[0]
"From here on, we assume that comparison outcomes are generated from BT(θ).",3.1 Displacement in the Poisson Model,[0],[0]
"Clearly, any results on the displacement of a ranking estimated from samples of a BT model will depend on θ; it is easy to construct a model instance for which it is arbitrarily hard to recover the ranking, by choosing parameters sufficiently close to each other.",3.1 Displacement in the Poisson Model,[0],[0]
Our approach is as follows.,3.1 Displacement in the Poisson Model,[0],[0]
"We postulate a family of distributions over θ, and we give bounds on the displacement that hold with high probability.
",3.1 Displacement in the Poisson Model,[0],[0]
"We suppose that comparison outcomes are (in expectation) uniformly noisy across the ranking: i.e., comparing two elements at the bottom is (a priori) as difficult as comparing two elements at the top or in the middle.",3.1 Displacement in the Poisson Model,[0],[0]
"This means that the probability distribution over parameters θ1, . . .",3.1 Displacement in the Poisson Model,[0],[0]
", θn results in (random) distances |θi+k−θi| that depend only on k. One such distribution arises if the parameters are drawn from a Poisson point process of rate λ.",3.1 Displacement in the Poisson Model,[0],[0]
"That is,
i.i.d.",3.1 Displacement in the Poisson Model,[0],[0]
"x1, . . .",3.1 Displacement in the Poisson Model,[0],[0]
", xn−1 ∼ Exp(λ), θi =
i−1 ∑
k=1
xk.",3.1 Displacement in the Poisson Model,[0],[0]
"(1)
The average distance between two items separated by k positions in the ordering is E",3.1 Displacement in the Poisson Model,[0],[0]
[θi+k,3.1 Displacement in the Poisson Model,[0],[0]
− θi] = k/λ.,3.1 Displacement in the Poisson Model,[0],[0]
"Although the distance between adjacent items is constant in expectation, we allow some parameters to be arbitrarily close4.",3.1 Displacement in the Poisson Model,[0],[0]
"The parameter λ controls the expected level of noise; a large λ is
4 In particular, the expected minimum distance between two items (i.e., the min of n exponential r.v.s) decreases as (nλ)−1 as n increases.
likely to result in a larger number of inconsistent outcomes.",3.1 Displacement in the Poisson Model,[0],[0]
"Although the precise choice of this Poisson model is driven by tractability concerns, in Section 3.2 we argue that it is essentially equivalent to choosing the parameters independently and uniformly at random in the interval",3.1 Displacement in the Poisson Model,[0],[0]
"[0, (n+1)/λ], when λ is fixed and n is large.",3.1 Displacement in the Poisson Model,[0],[0]
"We are now ready to state our main result.
",3.1 Displacement in the Poisson Model,[0],[0]
Theorem 1.,3.1 Displacement in the Poisson Model,[0],[0]
Let θ be sampled from a Poisson point process of rate λ.,3.1 Displacement in the Poisson Model,[0],[0]
Let σ be the output of Quicksort using comparison outcomes sampled from BT(θ).,3.1 Displacement in the Poisson Model,[0],[0]
"Then, w.h.p.,
∆(σ) = O(λ2n), (2)
max i |σ(i)− i| = O(λ log n).",3.1 Displacement in the Poisson Model,[0],[0]
"(3)
Proof (sketch).",3.1 Displacement in the Poisson Model,[0],[0]
"Let zij be the indicator random variable of the event “the comparison between i and j results in an error”, and let dij = |θi",3.1 Displacement in the Poisson Model,[0],[0]
− θj |.,3.1 Displacement in the Poisson Model,[0],[0]
"The distance dij is a sum of |i − j| exponential random variables, i.e., dij ∼ Gamma(|i− j|, λ), and we can show that
E",3.1 Displacement in the Poisson Model,[0],[0]
"[zij ] = E
[
1
1 + exp(dij)
]
≤ E",3.1 Displacement in the Poisson Model,[0],[0]
[exp(−dij)],3.1 Displacement in the Poisson Model,[0],[0]
"= (1 + 1/λ) −|i−j|.
Using Lemma 3 and the fact that every pair of items is compared at most once, we find
E [∆] ≤ 2 ∑
i<j
|i−",3.1 Displacement in the Poisson Model,[0],[0]
j|E,3.1 Displacement in the Poisson Model,[0],[0]
"[zij ]
≤ 2n
∞ ∑
k=0
k(1 + 1/λ)−k = 2nλ(λ+ 1).
",3.1 Displacement in the Poisson Model,[0],[0]
"The random variables {zij} are not unconditionally independent (they are independent when conditioned on θ) but, with some more work, we can show that Var [∆] = O(n).",3.1 Displacement in the Poisson Model,[0],[0]
"By using a Chebyshev bound, (2) follows.
",3.1 Displacement in the Poisson Model,[0],[0]
"In order to prove (3), we take advantage of a theorem due to Ailon (2008) which states that
P",3.1 Displacement in the Poisson Model,[0],[0]
[σ(i) < σ(j),3.1 Displacement in the Poisson Model,[0],[0]
"| θ] = p(i ≺ j | θ),
even if i and j were not directly compared with each other.",3.1 Displacement in the Poisson Model,[0],[0]
We use a Chernoff bound on dij to show that the relative order between any two items separated by at least O(λ log n) positions is correct with high probability.,3.1 Displacement in the Poisson Model,[0],[0]
"The second part of the claim follows easily.
",3.1 Displacement in the Poisson Model,[0],[0]
"Note that any method that compares each pair of items at most once results in a ranking estimate τ with displacement ∆(τ) = Ω(n) with high probability: As there is only a single (possibly inconsistent) comparison outcome between each pair of adjacent items, it is likely that a constant fraction of the items will be ranked incorrectly, resulting in a
Algorithm 2 Multisort
Require: set of items V , number of iterations m",3.1 Displacement in the Poisson Model,[0],[0]
"1: S ← ∅ 2: for k = 1, . . .",3.1 Displacement in the Poisson Model,[0],[0]
",m do 3: σ ← Quicksort(V ) 4: S ← S ∪ {σ}
5: return Copeland aggregation of S
displacement that grows linearly in n. Hence, our bound on ∆(σ) shows that Quicksort is order-optimal (in n).
",3.1 Displacement in the Poisson Model,[0],[0]
"In light of Theorem 1, a natural question to ask is as follows.",3.1 Displacement in the Poisson Model,[0],[0]
How many comparisons are needed in order to find the correct ranking?,3.1 Displacement in the Poisson Model,[0],[0]
"Clearly, finding the exact ranking is difficult: in fact, Ω(n) comparison outcomes are necessary to discriminate the closest pair of items reliably (see supplementary material, Section B).",3.1 Displacement in the Poisson Model,[0],[0]
"As such, we will focus on finding a ranking that matches the ground truth everywhere, except at a vanishing fraction of the items.
",3.1 Displacement in the Poisson Model,[0],[0]
"Multiple runs of Quicksort likely produce different outputs, because of the noisy comparison outcomes and because the algorithm itself is randomized (the pivot selection is random).",3.1 Displacement in the Poisson Model,[0],[0]
"By aggregating m independent outputs of Quicksort, is it possible to produce a better ranking estimate?",3.1 Displacement in the Poisson Model,[0],[0]
"Similarly to Szörényi et al. (2015), we combine the m outputs σ1, . . .",3.1 Displacement in the Poisson Model,[0],[0]
", σm into an aggregate ranking σ̂ using Copeland’s method.",3.1 Displacement in the Poisson Model,[0],[0]
"The method assigns, to each item, a score that corresponds to the number of items that it beats in a majority of the rankings, and it then ranks the items by increasing score (Copeland, 1951).",3.1 Displacement in the Poisson Model,[0],[0]
"We call the procedure Multisort and describe it in Algorithm 2.
Theorem 2.",3.1 Displacement in the Poisson Model,[0],[0]
Let θ be sampled from a Poisson point process of rate λ.,3.1 Displacement in the Poisson Model,[0],[0]
Let σ̂ be the output of Multisort using m = O(λ2 log5 n) and comparison outcomes sampled from BT(θ).,3.1 Displacement in the Poisson Model,[0],[0]
"Then, w.h.p.,
∆(σ̂) = o(λn).
",3.1 Displacement in the Poisson Model,[0],[0]
Proof (sketch).,3.1 Displacement in the Poisson Model,[0],[0]
"We use results on the order statistics of the distances x1, . . .",3.1 Displacement in the Poisson Model,[0],[0]
", xn−1 between successive items, as defined in (1), to partition the items into two disjoint subsets B and G. The set B contains a vanishing (1/ log2 n)-fraction of “bad” items that are difficult to order.",3.1 Displacement in the Poisson Model,[0],[0]
The set G is such that the smallest distance dij from any item,3.1 Displacement in the Poisson Model,[0],[0]
i ∈ G to any other item j ∈,3.1 Displacement in the Poisson Model,[0],[0]
[n] is bounded from below by c/(λ log2 n).,3.1 Displacement in the Poisson Model,[0],[0]
"We can show that with m = O(λ2 log5 n), for any i ∈ G and j ∈",3.1 Displacement in the Poisson Model,[0],[0]
[n] we have i < j ⇐⇒ σ(i) < σ(j) in a majority of the Quicksort outputs (with high probability).,3.1 Displacement in the Poisson Model,[0],[0]
This implies that σ̂(i),3.1 Displacement in the Poisson Model,[0],[0]
= i for all i ∈ G with high probability.,3.1 Displacement in the Poisson Model,[0],[0]
"Using (3) for items in B, we have
∆(σ̂) = |B| ·O(λ log n) = O(λn/ log n)
with high probability.
",3.1 Displacement in the Poisson Model,[0],[0]
Theorem 2 states that all but a vanishing fraction of items are correctly ranked using O(λ2n log6 n) comparisons.,3.1 Displacement in the Poisson Model,[0],[0]
"This result should be compared to the Ω(n2) comparisons needed if samples are selected uniformly at random.
",3.1 Displacement in the Poisson Model,[0],[0]
Empirical validation.,3.1 Displacement in the Poisson Model,[0],[0]
"In Figure 1, we illustrate the results of Theorems 1 and 2 by running simulations for increasing n and different values of λ.",3.1 Displacement in the Poisson Model,[0],[0]
"The bound on ∆(σ) is tight in n, but the dependence on λ appears to be linear rather than quadratic.",3.1 Displacement in the Poisson Model,[0],[0]
The bound on maxi|σ(i)− i| appears to be tight in n and λ.,3.1 Displacement in the Poisson Model,[0],[0]
"Finally, we compare the Copeland aggregation of m outputs of Quicksort with the ranking induced by the maximum-likelihood (ML) estimate, inferred from the outcomes of all the pairwise comparisons sampled by the m runs.",3.1 Displacement in the Poisson Model,[0],[0]
"Although the ranking induced by the ML estimate does not benefit from the guarantees of Theorem 2, it performs better in practice.",3.1 Displacement in the Poisson Model,[0],[0]
We will make use of this observation in Section 4.,3.1 Displacement in the Poisson Model,[0],[0]
A different (perhaps more natural) assumption on the parameters θ is to consider that they are drawn independently and uniformly at random over some interval.,3.2 Independent Uniformly-Distributed Parameters,[0],[0]
"That is,
i.i.d. θ̄1, . . .",3.2 Independent Uniformly-Distributed Parameters,[0],[0]
", θ̄n ∼ U(0, (n+ 1)/λ),
with θ1, . . .",3.2 Independent Uniformly-Distributed Parameters,[0],[0]
", θn the order statistics of θ̄, i.e., the random variables arranged in increasing order.",3.2 Independent Uniformly-Distributed Parameters,[0],[0]
"From some elementary results on the joint distribution of order statistics (see, e.g., Arnold et al., 2008), we see that
|θi+k",3.2 Independent Uniformly-Distributed Parameters,[0],[0]
"− θi| ∼ (n+ 1)/λ · Beta(k, n− k + 1),
i.e., a Beta random variable rescaled between 0 and (n + 1)/λ.",3.2 Independent Uniformly-Distributed Parameters,[0],[0]
"Letting fk,n(x) be the probability density of |θi+k",3.2 Independent Uniformly-Distributed Parameters,[0],[0]
"− θi|, we have, for any fixed k and λ,
fk,n(x) ∝",3.2 Independent Uniformly-Distributed Parameters,[0],[0]
"x k−1
[
1− λx
n+ 1
]n−k n→∞ −−−−→ xk−1e−λx.
",3.2 Independent Uniformly-Distributed Parameters,[0],[0]
"We recognize the functional form of the density of a Gamma(k, λ) distribution.",3.2 Independent Uniformly-Distributed Parameters,[0],[0]
"Hence, the Poisson model and the i.i.d. uniform model are essentially equivalent for fixed λ and large n, and we can expect the results developed in Section 3.1 to hold under this distribution as well.",3.2 Independent Uniformly-Distributed Parameters,[0],[0]
"In practice, the comparison budget for estimating a ranking from noisy data might typically be larger than that for a single call to Quicksort, and it might not exactly match the number of comparisons required to run a given number of calls to Quicksort to completion.",4 Experimental Results,[0],[0]
"Building upon the observations made at the end of Section 3.1, we suggest the following practical active-learning strategy: for a budget of
c pairwise comparisons, run the sorting procedure repeatedly until the budget is depleted (the last call might have to be truncated).",4 Experimental Results,[0],[0]
"Then, retain only the set of c comparison pairs and their outcomes and discard the rankings produced by the sorting procedure.",4 Experimental Results,[0],[0]
"The final ranking estimate is then induced from the ML estimate over the set of c comparison outcomes.
",4 Experimental Results,[0],[0]
"In this section, we demonstrate the effectiveness of this sampling strategy on synthetic and real-world data.",4 Experimental Results,[0],[0]
"In particular, we show that it is comparable to existing AL strategies at a minuscule fraction of the computational cost.",4 Experimental Results,[0],[0]
"To assess the relative merits of our sorting-based strategy, we consider three strategies that we believe are representative of the state of the art in active preference learning.
",4.1 Competing Sampling Strategies,[0],[0]
Uncertainty sampling.,4.1 Competing Sampling Strategies,[0],[0]
"Developed in the context of classification tasks, this popular active-learning heuristic suggests to greedily sample the point that lies closest to the decision boundary (Settles, 2012).",4.1 Competing Sampling Strategies,[0],[0]
"In the context of a ranking task, this corresponds to sampling the pair of items whose relative order is most uncertain.",4.1 Competing Sampling Strategies,[0],[0]
"After t observations, given an estimate of model parameters θt, the strategy selects the (t+1)-st pair uniformly at random in
argmin i 6=j
|θti − θ t j |.
",4.1 Competing Sampling Strategies,[0],[0]
This set can be computed in time O(n log n) by sorting the parameters.,4.1 Competing Sampling Strategies,[0],[0]
"The parameters themselves need to be estimated, e.g., using (penalized) ML inference that in practice can be the dominating cost.
",4.1 Competing Sampling Strategies,[0],[0]
Bayesian methods.,4.1 Competing Sampling Strategies,[0],[0]
"If we have access to a full posterior distribution qt(θ) instead of a point estimate θt, we can take advantage of the extra information on the uncertainty of the parameters to improve the selection strategy.",4.1 Competing Sampling Strategies,[0],[0]
"A principled approach to AL consists of sampling the point that
maximizes the expected information gain (MacKay, 1992).",4.1 Competing Sampling Strategies,[0],[0]
"That is, the pair of items at iteration t+ 1 is selected in
argmax i 6=j
H(qt)−E",4.1 Competing Sampling Strategies,[0],[0]
"[ H(qt+1) ] , (4)
where H(·) denotes the entropy function.",4.1 Competing Sampling Strategies,[0],[0]
A conceptually similar but slightly different selection strategy is given by Chen et al. (2013).,4.1 Competing Sampling Strategies,[0],[0]
"Letting qij be the marginal distribution of (θi, θj), the pair is selected in
argmax i 6=j
E",4.1 Competing Sampling Strategies,[0],[0]
"[ KL(qt+1ij ‖q t ij) ] , (5)
where KL(·) denotes the Kullback–Leibler divergence.",4.1 Competing Sampling Strategies,[0],[0]
"Computing the exact posterior is not analytically tractable for the BT model, but a Gaussian approximation can be found in time O(n3).",4.1 Competing Sampling Strategies,[0],[0]
Criteria (4) and (5) can be computed in constant time for each pair of items.,4.1 Competing Sampling Strategies,[0],[0]
"The dominating cost is again that of estimating θ (or, in this case, q(θ)).
",4.1 Competing Sampling Strategies,[0],[0]
"In addition to these existing AL strategies, we also include in our experiments a variation of our sorting-based strategy that uses Mergesort instead of Quicksort.",4.1 Competing Sampling Strategies,[0],[0]
"In the noiseless setting, Mergesort is known to use on average≈ 39 % fewer comparisons than Quicksort per run (Knuth, 1998), but it does not benefit from the theoretical guarantees developed in Section 3.",4.1 Competing Sampling Strategies,[0],[0]
"In this section, we briefly discuss the running time of the methods.",4.2 Running Time,[0],[0]
We implement ML and Bayesian approximate inference algorithms for the BT model as a Python library5.,4.2 Running Time,[0],[0]
"For ML inference, we find that the fastest running time is achieved by a truncated Newton algorithm (even for large n).",4.2 Running Time,[0],[0]
"For approximate Bayesian inference, we use a variant of the expectation-propagation algorithm outlined by Chu & Ghahramani (2005).",4.2 Running Time,[0],[0]
"All experiments are performed on
5See: http://lucas.maystre.ch/choix.
a server with a 12-core Xeon X5670 processor running at 2.93 GHz.",4.2 Running Time,[0],[0]
"Numerical computations take advantage of the Intel Math Kernel Library.
",4.2 Running Time,[0],[0]
We illustrate the running time of AL strategies as follows.,4.2 Running Time,[0],[0]
"For n ∈ {102, 103, 104}, we generate outcomes for n comparisons pairs chosen uniformly at random among n items.",4.2 Running Time,[0],[0]
"For each strategy, we then measure the time it takes to select the (n+1)-st pair of items adaptively.",4.2 Running Time,[0],[0]
The results are presented in Table 1.,4.2 Running Time,[0],[0]
"Note that these numbers are intended to be considered as orders of magnitude, rather than exact values, as they depend on the particular combination of software and hardware that we use.",4.2 Running Time,[0],[0]
The running time of the Bayesian AL strategies exceed 10 hours for n = 104 and the calls were stopped ahead of completion.,4.2 Running Time,[0],[0]
"Our sorting-based methods, like random sampling, are the only AL strategies whose running time is constant for increasing n",4.2 Running Time,[0],[0]
(and for increasing c).,4.2 Running Time,[0],[0]
"In fact, their running time is negligible in comparison to the other strategies, including uncertainty sampling.",4.2 Running Time,[0],[0]
"We now investigate three datasets and measure the displacement of rankings estimated from adaptively-chosen samples, as a function of the budget c. Note that in order to use uncertainty sampling and Bayesian methods, it is necessary to choose a regularization strength or prior variance in the inference step.",4.3 Empirical Evaluation,[0],[0]
"Different values can result in drastically different outcomes (in particular for uncertainty sampling) and, in practice, choosing a good value can be a significant challenge6.",4.3 Empirical Evaluation,[0],[0]
"In the following, we report results for the values that worked best a posteriori.
",4.3 Empirical Evaluation,[0],[0]
Synthetic dataset.,4.3 Empirical Evaluation,[0],[0]
We generate n i.i.d.,4.3 Empirical Evaluation,[0],[0]
"parameters θ1, . .",4.3 Empirical Evaluation,[0],[0]
.,4.3 Empirical Evaluation,[0],[0]
", θn uniformly in [0, (n + 1)/λ] and draw samples from BT(θ).",4.3 Empirical Evaluation,[0],[0]
The ground-truth ranking is the one induced by the parameters.,4.3 Empirical Evaluation,[0],[0]
Figure 2 presents results for n = 200 and λ,4.3 Empirical Evaluation,[0],[0]
"= 5 (plots for different values of λ are presented in the supplementary material, Section C, and are qualitatively
6Observe that our sorting-based approach is entirely parameterfree and is therefore not affected by this issue.
similar).",4.3 Empirical Evaluation,[0],[0]
"In comparison to random sampling, AL is very effective and results in significantly better ranking estimates for any given number of comparisons.",4.3 Empirical Evaluation,[0],[0]
"The two Bayesian methods, though being the most computationally expensive, perform the best for all values of c, but are nearly indistinguishable from uncertainty sampling.",4.3 Empirical Evaluation,[0],[0]
The two sorting-based strategies perform similarly (with a small edge for Mergesort).,4.3 Empirical Evaluation,[0],[0]
"They are slightly worse than the Bayesian methods but are still able to reap most of the benefits of active learning.
",4.3 Empirical Evaluation,[0],[0]
Sushi dataset.,4.3 Empirical Evaluation,[0],[0]
"Next, we consider a dataset of Sushi preferences (Kamishima & Akaho, 2009).",4.3 Empirical Evaluation,[0],[0]
"In this dataset, 5000 respondents give a strict ordering over 10 different types of sushi.",4.3 Empirical Evaluation,[0],[0]
These 10 sushi are chosen among a larger set of n = 100 items.,4.3 Empirical Evaluation,[0],[0]
"To suit our purposes, we decompose each 10-way partial ranking into pairwise comparisons, resulting in 225 000 comparison outcomes.",4.3 Empirical Evaluation,[0],[0]
"We use all comparisons to fit a BT model that induces a ground-truth ranking7.
",4.3 Empirical Evaluation,[0],[0]
"The comparisons are dense, and there is at least one comparison outcome for almost all pairs.",4.3 Empirical Evaluation,[0],[0]
"When an outcome for pair (i, j) is requested, we sample uniformly at random over all outcomes observed for this pair.",4.3 Empirical Evaluation,[0],[0]
"In the rare case where no outcome is available, we return i ≺ j with probability 1/2.",4.3 Empirical Evaluation,[0],[0]
"This enables us to compare sampling strategies in a realistic setting, where the assumptions of the BT model do not necessarily hold anymore.
",4.3 Empirical Evaluation,[0],[0]
Results are shown in Figure 3 (left).,4.3 Empirical Evaluation,[0],[0]
"Once again, active learning performs noticeably better than random sampling.",4.3 Empirical Evaluation,[0],[0]
"On this real-world dataset, the performance of our sorting-based strategies is indistinguishable from that of the Bayesian
7 The BT-induced ranking is almost the same as that obtained using the Copeland score.",4.3 Empirical Evaluation,[0],[0]
"The results are very similar if the Copeland aggregation is used as ground truth.
methods, after completing one entire call to the sorting procedure (slightly less than 1000 comparisons).",4.3 Empirical Evaluation,[0],[0]
"This result should be interpreted in light of the time needed to select all 104 pairs: a fraction of a second for sorting-based strategies, and several hours for the Bayesian methods.",4.3 Empirical Evaluation,[0],[0]
"Finally, we observe that the performance of uncertainty sampling progressively degrades as c increases.",4.3 Empirical Evaluation,[0],[0]
"A detailed analysis reveals that uncertainty sampling increasingly focuses on a small set of hard-to-discriminate pairs, symptomatic of a well-known issue (Settles, 2012).
GIFGIF dataset.",4.3 Empirical Evaluation,[0],[0]
GIFGIF8 is a project of the MIT Media Lab that aims at explaining the emotions communicated by a collection of animated GIF images.,4.3 Empirical Evaluation,[0],[0]
"Users of the website are shown a prompt with two images and a question, “Which better expresses x?” where x is one of 17 emotions.",4.3 Empirical Evaluation,[0],[0]
"The users can click on either image, or use a third option, neither.",4.3 Empirical Evaluation,[0],[0]
"To date, over three million comparison outcomes have been collected.",4.3 Empirical Evaluation,[0],[0]
"For the purpose of our experiment, we restrict ourselves to a single emotion, happiness; and we ignore outcomes that resulted in neither.",4.3 Empirical Evaluation,[0],[0]
"We consider 106 887 comparison outcomes over n = 6120 items—a significant increase in scale compared to the Sushi dataset.
",4.3 Empirical Evaluation,[0],[0]
"As the data, despite a relatively large number of comparisons, remains sparse (less than 20 comparisons per item on average), we proceed as follows.",4.3 Empirical Evaluation,[0],[0]
We fit a BT model by using all the available comparisons and use the induced ranking as ground truth.,4.3 Empirical Evaluation,[0],[0]
"We then generate new, synthetic comparison outcomes from the BT model.",4.3 Empirical Evaluation,[0],[0]
"In this sense, the experiment enables us to compare sampling strategies by using a large BT model with realistic parameters.",4.3 Empirical Evaluation,[0],[0]
"The large number of items makes uncertainty sampling and the two Bayesian
8See http://www.gif.gf/.",4.3 Empirical Evaluation,[0],[0]
"Data available at http:// lucas.maystre.ch/gifgif-data.
methods prohibitively expensive.",4.3 Empirical Evaluation,[0],[0]
"We try a simplified, computationally less expensive version of uncertainty sampling where, at every iteration, each item is compared to its two closest neighbors, but this heuristic fails spectacularly: The resulting displacement is over 5× larger than random sampling for c = 106, and is therefore not reported here (see supplementary material, Section C).
",4.3 Empirical Evaluation,[0],[0]
Figure 3 (right) compares the displacement of random sampling to that of the two sorting-based sampling strategies for increasing c.,4.3 Empirical Evaluation,[0],[0]
The adaptive sampling approaches perform systematically better.,4.3 Empirical Evaluation,[0],[0]
"After 106 comparisons, the displacement of random sampling is 14 % and 23 % larger than that of Quicksort and Mergesort, respectively.",4.3 Empirical Evaluation,[0],[0]
"Conversely, in order to reach any target displacement, Mergesort requires approximately 2× fewer comparisons than random sampling.",4.3 Empirical Evaluation,[0],[0]
"In this work, we demonstrate that active learning can substantively speed up the task of learning a ranking from noisy comparisons gains—both in theory and in practice.",5 Conclusion,[0],[0]
"With the advent of large-scale crowdsourced ranking surveys, exemplified by GIFGIF and wiki surveys (Salganik & Levy, 2015), there is a clear need for practical AL strategies.",5 Conclusion,[0],[0]
"However, existing methods are complex and computationally expensive to operate even for a reasonable number of items (a few thousands).",5 Conclusion,[0],[0]
"We show that a deceptively simple idea—repeatedly sorting the items—is able to bring in all the benefits of active learning, is trivial to implement, and is computationally no more expensive that random sampling.",5 Conclusion,[0],[0]
"Therefore, we believe that our method can be broadly useful for machine-learning practitioners interested in ranking problems.",5 Conclusion,[0],[0]
"We thank Holly Cogliati-Bauereis, Ksenia Konyushkova, Brunella Spinelli and the anonymous reviewers for careful proofreading and helpful comments.",Acknowledgments,[0],[0]
We address the problem of learning a ranking by using adaptively chosen pairwise comparisons.,abstractText,[0],[0]
Our goal is to recover the ranking accurately but to sample the comparisons sparingly.,abstractText,[0],[0]
"If all comparison outcomes are consistent with the ranking, the optimal solution is to use an efficient sorting algorithm, such as Quicksort.",abstractText,[0],[0]
But how do sorting algorithms behave if some comparison outcomes are inconsistent with the ranking?,abstractText,[0],[0]
"We give favorable guarantees for Quicksort for the popular Bradley–Terry model, under natural assumptions on the parameters.",abstractText,[0],[0]
"Furthermore, we empirically demonstrate that sorting algorithms lead to a very simple and effective active learning strategy: repeatedly sort the items.",abstractText,[0],[0]
This strategy performs as well as state-of-the-art methods (and much better than random sampling) at a minuscule fraction of the computational cost.,abstractText,[0],[0]
Just Sort It! A Simple and Effective Approach to Active Preference Learning,title,[0],[0]
K-means clustering is a classical clustering problems and has been studied for several decades.,1. Introduction,[0],[0]
The goal of K-Means clustering is to find a set of k cluster centers for a dataset such that the sum of squared distances of each point to its closest cluster center is minimized.,1. Introduction,[0],[0]
"While it is known that k-means clustering is an NP hard optimization problem even for k = 2 (Dasgupta, 2008), in practice a local search heuristic due to Lloyd (Lloyd, 1982) is widely used for solving K-means clustering problem.",1. Introduction,[0],[0]
"Lloyd’s iterative
1Department of Electrical Engineering & Computer Science, Wichita State University, KS, USA.",1. Introduction,[0],[0]
"Correspondence to: Kaushik Sinha <kaushik.sinha@wichita.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
algorithm begins with k arbitrary “cluster centers”, and in each iteration, each point is assigned to the nearest cluster center, and each cluster center is recomputed as the center of mass of all points assigned to it.",1. Introduction,[0],[0]
These last two steps are repeated until the process stabilizes.,1. Introduction,[0],[0]
"Lloyd’s algorithm for k-means clustering is known to be one of the top ten data mining tools of the last fifty years (Wu, 2008).
",1. Introduction,[0],[0]
"K-means clustering is typically performed on a data matrix A ∈ Rn×d, consisting of n data points each having d attributes/features and per iteration computational cost of Lloyd’s algorithm is O(nkd).",1. Introduction,[0],[0]
In recent years there has been a series of work towards reducing this computational cost and speeding up k-means clustering computation.,1. Introduction,[0],[0]
Most of these works can broadly be classified into three categories.,1. Introduction,[0],[0]
"In the first category, K-means clustering algorithm is accelerated by avoiding unnecessary distance calculations by applying various forms of triangular inequality and by keeping track of lower and upper bounds for distances between points and cluster centers (Elkan, 2003; Hamerly, 2010; Drake & Hamerly, 2012; Ding et al., 2015; Newling & Fleuret, 2016; Bottesch et al., 2016).",1. Introduction,[0],[0]
All these algorithms ensure the exact same clustering result that would have been obtained had one applied Lloyd’s heuristic from the same set of initial cluster centers without applying any distance inequality bounds.,1. Introduction,[0],[0]
"In the second category, various dimension reduction techniques are applied to data matrix A to reduce data dimensionality from d to d′ (d′ d), where d′ is independent of n and d, so that optimal k-means clustering solution of dimensionality reduced dataset A′ ∈",1. Introduction,[0],[0]
"Rn×d′ ensures an approximately optimal k-means clustering objective function of A. Most prominent among these is the random projection based dimensionality reduction technique that reduces data dimensionality from d to Ω(k/ 2) resulting in (1 + ) approximation of the optimal k-means objective function (Boutsidis et al., 2010; 2015; Cohen et al., 2015) and also from d to O(log(k)/ 2) resulting in (9 + ) approximation of the optimal k-means objective function (Cohen et al., 2015).",1. Introduction,[0],[0]
"Recently, (Liu et al., 2017) demonstrated the the random projection step can be performed by multiplying with a sparse matrix that yields the same (1 + ) approximation guarantee.",1. Introduction,[0],[0]
"Additionally, random feature selection method reduces data dimensionality from d to Ω(k log k/ 2) resulting in (1 + ) approximation of the optimal k-means objective function (Boutsidis et al.,
2015; Cohen et al., 2015).",1. Introduction,[0],[0]
"In the third category, a smaller subset of n data points called coresets, are constructed so that optimal weighted k-means clustering objective function performed on this coreset is (1 + ) approximation of the optimal k-means objective function performed on the original dataset (Feldman & Langberg, 2011; Feldman et al., 2013).",1. Introduction,[0],[0]
"In k-means clustering using Lloyd’s heuristic, a major computational bottleneck arises from Euclidean distance computation between each data point and k cluster centers in every iteration.",1. Introduction,[0],[0]
"For a data point a ∈ Rd and a cluster center µ ∈ Rd, the Euclidean distance can be represented as, ‖a",1. Introduction,[0],[0]
− µ‖2 = ‖a‖2 + ‖µ‖2,1. Introduction,[0],[0]
"− 2a>µ. Note that ‖a‖2 needs be computed for each data point only once over all iterations of Lloyd’s heuristics (and can be done off-line), ‖µ‖2 needs be computed once for each cluster center in each iteration, while the dot product needs to be computed for every possible data point, cluster center pair in every single iteration.",1. Introduction,[0],[0]
"In fact, the dot product between a cluster center µ and all n data points can be computed by a simple matrix-vector multiplication:",1. Introduction,[0],[0]
Aµ.,1. Introduction,[0],[0]
"If the data matrix A is significantly sparse (i.e., number of non-zero entries is reasonable small) the above matrix vector multiplication can be performed reasonably fast.",1. Introduction,[0],[0]
"A key question that is not addressed in the literature is, To what extent the data matrix A can be made sparse without significantly affecting optimal k-means clustering objective?",1. Introduction,[0],[0]
"In this paper we show that under mild conditions, we can randomly sparsify data matrix A to obtain a sparse data matrix Ã such that optimal k-means clustering solution of Ã yields an approximately optimal k-means clustering objective of A with high probability.",1. Introduction,[0],[0]
Note that such a sparsification scheme can be extremely useful in practice.,1. Introduction,[0],[0]
"If the original data matrix is reasonably dense, then such sparsification results in fast matrix-vector multiplication, thereby speeding up k-means clustering.",1. Introduction,[0],[0]
"However, it may seem at first that for many real world high dimensional datasets that are very sparse to begin with, such as text datasets represented in “bag of word” format, such sparsification scheme may not be useful.",1. Introduction,[0],[0]
"But, note that instead of directly working with high dimensional data, typically a random projection step is often applied first to reduce data dimensionality since it is known that optimal k-means clustering solution of this randomly projected dataset results in approximately optimal k-means clustering objective of the original high dimensional dataset (Boutsidis et al., 2010; 2015; Cohen et al., 2015; Liu et al., 2017).",1. Introduction,[0],[0]
"Unfortunately, such a random projection step results in a dense projected data matrix.",1. Introduction,[0],[0]
"Interestingly, our sparsification method can now be applied on this projected dense data matrix to reap further computational benefit in addition to the computational benefit already achieved by random projection step (see Figure 1).
",1. Introduction,[0],[0]
"To quantify the approximation factor as well as the level of sparsity of our proposed method, we use ideas from
(Achlioptas & Mcsherry, 2007) which establishes that random matrix sparsification approximately preserves low rank matrix structure with high probability and also ideas from (Cohen et al., 2015) which establishes to what extent an approximately optimal low rank matrix serves as a projection cost preserving sketch.",1. Introduction,[0],[0]
"To the best of our knowledge, this is the first result that quantifies how random matrix sparsification affects k-means clustering.",1. Introduction,[0],[0]
"In particular, we make the following contributions in this paper.
",1. Introduction,[0],[0]
"• We show that for any ∈ (0, 1), a dense data matrix A ∈ Rn×d can be randomly sparsified to yield a data matrix Ã ∈",1. Introduction,[0],[0]
"Rn×d, such that, Ã contains O(nk/ 9 + d log4 n) non-zero entries in expectation, and optimal k-means clustering solution of Ã results in (1 + ) approximation of optimal k-means objective of A with high probability.
",1. Introduction,[0],[0]
"• We show that for any ∈ (0, 1), a dense data matrix A ∈ Rn×d can be randomly sparsified to yield a data matrix Ã ∈",1. Introduction,[0],[0]
"Rn×d, such that, Ã contains O(nk/ 9 + d log4 n) non-zero entries in expectation, and any approximately optimal k-means clustering solution of Ã, having (1 + ) approximation of optimal k-means objective of Ã, results in (1 +O( )) approximation of optimal k-means objective of A with high probability.
",1. Introduction,[0],[0]
"• We present experimental results on three real world datasets to demonstrate effect of our proposed random sparsification scheme on k-means clustering solution.
",1. Introduction,[0],[0]
The rest of the paper is organized as follows.,1. Introduction,[0],[0]
In section 2 we present k-means clustering problem in matrix notation and introduce uniform and non-uniform sampling strategies for random matrix sparsification.,1. Introduction,[0],[0]
We propose an algorithm for k-means clustering using random matrix sparsification in section 3 and present its analysis in section 4.,1. Introduction,[0],[0]
Empirical evaluations are presented in section 5.,1. Introduction,[0],[0]
"Finally, we conclude and point out a few open questions in section 6.",1. Introduction,[0],[0]
We use bold lower case letters to denote vectors and bold upper case letters to denote matrices.,2.1. Notation and linear algebra basics,[0],[0]
"For any n and d, consider a matrix A ∈ Rn×d with rank r = rank(A).",2.1. Notation and linear algebra basics,[0],[0]
"Using singular value decomposition A can be written as A = UΣV>, where U ∈ Rn×r contains r left singular vectors u1,u2, . . .",2.1. Notation and linear algebra basics,[0],[0]
",ur ∈ Rn, V contains r right singular vectors v1,v2, . . .",2.1. Notation and linear algebra basics,[0],[0]
",vr ∈ Rd, and Σ ∈",2.1. Notation and linear algebra basics,[0],[0]
Rr×r is a positive diagonal matrix containing the singular values of A : σ1(A),2.1. Notation and linear algebra basics,[0],[0]
≥ σ2(A),2.1. Notation and linear algebra basics,[0],[0]
≥ · · · ≥ σr(A).,2.1. Notation and linear algebra basics,[0],[0]
A can also be written as A = ∑r i=1,2.1. Notation and linear algebra basics,[0],[0]
σi(A)uiv >,2.1. Notation and linear algebra basics,[0],[0]
i .,2.1. Notation and linear algebra basics,[0],[0]
"For any k ≤ r,
Ak = ∑k i=1",2.1. Notation and linear algebra basics,[0],[0]
σi(A)uiv >,2.1. Notation and linear algebra basics,[0],[0]
"i is the best rank k approximation to A for any unitarily invariant norm, including Frobenious
and spectral norm (Mirsky, 1960).",2.1. Notation and linear algebra basics,[0],[0]
Note that,2.1. Notation and linear algebra basics,[0],[0]
A = Ak + Ar−k,2.1. Notation and linear algebra basics,[0],[0]
where Ar−k =,2.1. Notation and linear algebra basics,[0],[0]
∑r,2.1. Notation and linear algebra basics,[0],[0]
i=k+1 σi(A)uiv >,2.1. Notation and linear algebra basics,[0],[0]
i .,2.1. Notation and linear algebra basics,[0],[0]
"Therefore, Ar−k = A−Ak.",2.1. Notation and linear algebra basics,[0],[0]
"Square Frobenious norm of A is given by ‖A‖2F = ∑ i,jA(i, j) 2 = trace(AA>)",2.1. Notation and linear algebra basics,[0],[0]
= ∑,2.1. Notation and linear algebra basics,[0],[0]
i σ 2,2.1. Notation and linear algebra basics,[0],[0]
i (A).,2.1. Notation and linear algebra basics,[0],[0]
The spectral norm of A is given by ‖A‖2 = σ1(A).,2.1. Notation and linear algebra basics,[0],[0]
Ak satisfies ‖A −Ak‖F =,2.1. Notation and linear algebra basics,[0],[0]
"minB,rank(B)=k ‖A",2.1. Notation and linear algebra basics,[0],[0]
"− B‖F and ‖A−Ak‖2 = minB,rank(B)=k ‖A−B‖2.",2.1. Notation and linear algebra basics,[0],[0]
"The objective of k-means clustering is to partition n data points in Rd, {a1, . . .",2.2. K-means clustering,[0],[0]
",an}, into k non-overlapping clusters C = {C1, . . .",2.2. K-means clustering,[0],[0]
", Ck} such that points that are close to each other belong to the same cluster and points that are far from each other belong to to different clusters.",2.2. K-means clustering,[0],[0]
"Let µi be the centroid of cluster Ci and for any data point ai, let C(ai) be the index of the cluster to which ai is assigned to.",2.2. K-means clustering,[0],[0]
"The goal of k-means clustering is to minimize the objective function
k∑ i=1",2.2. K-means clustering,[0],[0]
∑ aj∈Ci ‖aj −µi‖22,2.2. K-means clustering,[0],[0]
"= n∑ j=1 ‖aj −µC(aj)‖ 2 2 (1)
",2.2. K-means clustering,[0],[0]
"Let A ∈ Rn×d be a data matrix containing the n data points {a1, . . .",2.2. K-means clustering,[0],[0]
",an} as rows and for any clustering C, let XC ∈ Rn×k be the cluster indicator matrix, with XC(i, j) = 1/ √",2.2. K-means clustering,[0],[0]
"|Cj | if ai is assigned to Cj and XC(i, j) = 0",2.2. K-means clustering,[0],[0]
otherwise.,2.2. K-means clustering,[0],[0]
"The k-means objective function given in equation 1 can now be represented in the matrix notation as,
",2.2. K-means clustering,[0],[0]
"‖A−XCX>CA‖2F = n∑ j=1 ‖aj −µC(aj)‖ 2 2 (2)
",2.2. K-means clustering,[0],[0]
"By construction, the columns of XC have disjoint support and are orthonormal vectors and XCX>C is an orthogonal projection matrix of rank k.",2.2. K-means clustering,[0],[0]
Let S be the set of all possible rank k cluster projection matrices of the form,2.2. K-means clustering,[0],[0]
XCX>C .,2.2. K-means clustering,[0],[0]
"The objective of k-means clustering is to find an optimal clustering of A that minimizes the objective function in equation
2, that is, to find XCopt such that,
XCopt = argmin XCX>C ∈S
‖A−XCX>CA‖2F
As mentioned earlier, finding XCopt is an NP-hard problem.",2.2. K-means clustering,[0],[0]
"Any cluster indicator matrix Xγ is called an γapproximation for the k-means clustering problem (γ ≥ 1) for data matrix A if it satisfies,
‖A−XγX>γA‖2F ≤",2.2. K-means clustering,[0],[0]
γ min,2.2. K-means clustering,[0],[0]
XCX>C ∈S,2.2. K-means clustering,[0],[0]
"‖A−XCX>CA‖2F
= γ‖A−XCoptX>CoptA‖ 2 F",2.2. K-means clustering,[0],[0]
"Given a data matrix A ∈ Rn×d, the basic idea of random matrix sparsification is to randomly sparsify the entries of A to get a matrix Ã ∈ Rn×d such that Ã contains fewer nonzero entries compared to A. Such a sparse matrix Ã speeds up matrix-vector multiplication by decreasing the number of arithmetic operations.",2.3. Random matrix sparsification,[0],[0]
"Let us write Ã = A+N, where N ∈ Rn×d.",2.3. Random matrix sparsification,[0],[0]
"A fundamental result of random matrix theory is that, as long as N is a random matrix whose entries are zero mean, independent random variables with bounded variance, no low dimensional subspace accommodates N well, i.e., ‖Nm‖2 and ‖Nm‖F are small for small m. In fact, optimal rank m approximation to Ã approximates A nearly as well as Am as long as ‖Am‖ ‖Nm‖ (for both Frobenious and spectral norm) and the quantity ‖Nm‖ bounds the influence that N may exert on the optimal rank m approximation to Ã.",2.3. Random matrix sparsification,[0],[0]
"Next we describe a simple random uniform sampling scheme as well as a simple non-uniform sampling scheme for generating sparse Ã that were proposed in (Achlioptas & Mcsherry, 2007) along with bounds on ‖Nm‖.",2.3. Random matrix sparsification,[0],[0]
"In the following, we set b to be b = max(i,j) |A(i, j)|.",2.3. Random matrix sparsification,[0],[0]
"In random matrix sparsificaion using uniform sampling scheme, p fraction of entries of A are set to zero to obtain a sparse Ã.",2.3.1. UNIFORM SAMPLING SCHEME,[0],[0]
"In particular,
Ã(i, j) = { A(i, j)/p with probability p 0 otherwise
(3)
It was shown in (Achlioptas & Mcsherry, 2007) that as long as p is bounded from below, with high probability, ‖Nm‖ is bounded as shown below (a simplified version of a result from (Achlioptas & Mcsherry, 2007)).
",2.3.1. UNIFORM SAMPLING SCHEME,[0],[0]
Theorem 1.,2.3.1. UNIFORM SAMPLING SCHEME,[0],[0]
"[Theorem 2 of (Achlioptas & Mcsherry, 2007)]",2.3.1. UNIFORM SAMPLING SCHEME,[0],[0]
"For p ≥ (8 log n)4/n, let Ã be the random sparse matrix obtained by applying uniform sampling scheme (equation 3).",2.3.1. UNIFORM SAMPLING SCHEME,[0],[0]
"Then with probability at least (1 − 1/n19 log3 n), for any m ≤ min{n, d}, N satisfies ‖Nm‖2 ≤",2.3.1. UNIFORM SAMPLING SCHEME,[0],[0]
"4b √ n/p and
‖Nm‖F ≤",2.3.1. UNIFORM SAMPLING SCHEME,[0],[0]
4b,2.3.1. UNIFORM SAMPLING SCHEME,[0],[0]
√ mn/p.,2.3.1. UNIFORM SAMPLING SCHEME,[0],[0]
Random sparsification using uniform sampling can be improved by retaining entries with probability that depends on their magnitude.,2.3.2. NON-UNIFORM SAMPLING SCHEME,[0],[0]
"For any p > 0 define τij = p(A(i, j)/b)2
and let pij = max { τij , √ τij × (8 log n)4/n } .",2.3.2. NON-UNIFORM SAMPLING SCHEME,[0],[0]
"Then a
sparse Ã can be obtained from A using the following nonuniform sampling scheme.
",2.3.2. NON-UNIFORM SAMPLING SCHEME,[0],[0]
"Ã(i, j) = { A(i, j)/pij with probability pij 0",2.3.2. NON-UNIFORM SAMPLING SCHEME,[0],[0]
"otherwise (4)
Such non-uniform sampling scheme yields greater sparsification when entry magnitudes vary, without increasing error bound of Theorem 1.
",2.3.2. NON-UNIFORM SAMPLING SCHEME,[0],[0]
Theorem 2.,2.3.2. NON-UNIFORM SAMPLING SCHEME,[0],[0]
"[Theorem 3 of (Achlioptas & Mcsherry, 2007)] Let Ã be the random sparse matrix obtained by applying non-uniform sampling scheme (equation 4).",2.3.2. NON-UNIFORM SAMPLING SCHEME,[0],[0]
"Then with probability at least (1− 1/n19 log3 n), for any m ≤ min{n, d}, N satisfies ‖Nm‖2 ≤",2.3.2. NON-UNIFORM SAMPLING SCHEME,[0],[0]
4b √ n/p and ‖Nm‖F ≤ 4b √ mn/p.,2.3.2. NON-UNIFORM SAMPLING SCHEME,[0],[0]
most p(‖A‖F /b)2,"In addition, expected number of non-zero entries in Ã is at",[0],[0]
"+ d(8 log n)4.
","In addition, expected number of non-zero entries in Ã is at",[0],[0]
"For any s > 0, setting p = s(b/‖A‖F )2 in the above Theorem ensures that expected number of non-zero entries in Ã is at most s+ d(8 log n)4.","In addition, expected number of non-zero entries in Ã is at",[0],[0]
"While the goal of k-means clustering is to well approximate each row of A with its cluster center, as can be seen from equation 1, an equivalent formulation in equation 2 shows that the problem actually amounts to finding an optimal rank
Algorithm 1 K-means clustering using random sparsification Input : Data matrix A ∈ Rn×d, number of clusters k, a positive scalar p and a γ-approximation k-means algorithm.",3. An algorithm for k-means clustering using random matrix sparsification,[0],[0]
"Output : Cluster indicator matrix Xγ̃ determining a k partition of the rows of A.
1: Compute Ã using non-uniform sampling scheme (equation 4).",3. An algorithm for k-means clustering using random matrix sparsification,[0],[0]
2: Run the γ-approximation k-means algorithm on Ã to obtain Xγ̃ .,3. An algorithm for k-means clustering using random matrix sparsification,[0],[0]
"3: Return Xγ̃ .
",3. An algorithm for k-means clustering using random matrix sparsification,[0],[0]
"k subspace for approximating the columns of A. Moreover, the choice of subspace is constrained because it must be spanned by the columns of a cluster indicator matrix.",3. An algorithm for k-means clustering using random matrix sparsification,[0],[0]
"The random sampling schemes presented in the previous section yields a sparse Ã whose optimal rank m approximation Ãm approximates Am reasonably well for small m. For appropriate choice of m, if such Am approximates optimal rank k subspace for approximating the columns of A well, then a reasonable strategy for k-means clustering that will reduce number of arithmetic operations is to perform kmeans clustering on Ã, instead of A, and hope that optimal k-means clustering solution of Ã will be close to optimal kmeans clustering solution of A. We propose such a strategy in Algorithm 1.",3. An algorithm for k-means clustering using random matrix sparsification,[0],[0]
In the next section we present an analysis of this algorithm and prove that an optimal k-means clustering solution of Ã indeed results in an approximately optimal k-means objective of A.,3. An algorithm for k-means clustering using random matrix sparsification,[0],[0]
In this section we present an analysis of Algorithm 1.,4. Analysis of algorithm,[0],[0]
For all our results we have assumed that n,4. Analysis of algorithm,[0],[0]
≥,4. Analysis of algorithm,[0],[0]
d.,4. Analysis of algorithm,[0],[0]
"The main intuition for the technical part of the proof is that even though A and Ã look very different because of the enforced sparse structure, if their appropriate low-rank structures are similar, that is enough to argue that optimal k-means solution of Ã is close to optimal k-means solution of A. We use the notion of projection cost preserving sketch1 as a useful mathematical object for our proof.",4. Analysis of algorithm,[0],[0]
"If B is a rank k projection-cost preserving sketch for A with error 1, then it implies (can be easily shown) that optimal k-means solution of B is (1 + 1) optimal k-means solution of A (Cohen et al., 2015).",4. Analysis of algorithm,[0],[0]
"It turns out that for appropriate choice of m = m(k, 1), the best rankm approximation of A, namely Am, constructed by the m largest SVD structure form a rank k projection-cost preserving sketch for A with error 1.
1B ∈ Rn×d ′
is a rank k projection-cost preserving sketch of A ∈ Rn×d, with error 0 ≤ ≤ 1 if, for all rank k orthogonal projection matrices P ∈ Rn×n it holds",4. Analysis of algorithm,[0],[0]
that (1− )‖A−PA‖2F ≤,4. Analysis of algorithm,[0],[0]
‖B − PB‖2F + c ≤ (1 + ),4. Analysis of algorithm,[0],[0]
‖A,4. Analysis of algorithm,[0],[0]
"− PA‖2F for some fixed nonnegative constant c that may depend on A and B but is independent of P.
Similarly, Ãm is a rank k projection-cost preserving sketch for Ã.",4. Analysis of algorithm,[0],[0]
"We show that optimal k-means solution of Ã is close to optimal k-mean solution of A in two steps.
1.",4. Analysis of algorithm,[0],[0]
"First, we show the reverse direction of the implication of rank k projection-cost preserving sketch also holds.",4. Analysis of algorithm,[0],[0]
"In particular, we show that an optimal k-means solution of Ã is also (1 +O( 1)) optimal for Ãm.
2.",4. Analysis of algorithm,[0],[0]
Then we show that Ãm is also rank k projection-cost preserving sketch for A with a different error 2.,4. Analysis of algorithm,[0],[0]
"(this is where we quantify amount of sparsity to k-means error)
",4. Analysis of algorithm,[0],[0]
"Combining these two facts and properly choosing 1 and 2, we conclude that optimal k-means solution of Ã is (1 + )",4. Analysis of algorithm,[0],[0]
optimal k-means solution of A. We lay out the necessary details in the following subsections.,4. Analysis of algorithm,[0],[0]
"Ã and Ãm
We first show that close to optimal cluster indicator matrix obtained by solving k-means clustering problem on Ã yields a close to optimal k-means objective of Ãm.
",4.1. Relation between clustering objective functions of,[0],[0]
Lemma 1.,4.1. Relation between clustering objective functions of,[0],[0]
"For any 0 < ≤ 1/2, let m = dk/ e.",4.1. Relation between clustering objective functions of,[0],[0]
For any Ã ∈ Rn×d with rank r ≥ dk/,4.1. Relation between clustering objective functions of,[0],[0]
"e + k, let Ãm be its best rank m approximation.",4.1. Relation between clustering objective functions of,[0],[0]
"For any set S of rank k cluster projection matrices, let P̃∗ = argminP∈S ‖Ã",4.1. Relation between clustering objective functions of,[0],[0]
− PÃ‖2F and P̃∗m = argminP∈S ‖Ãm−PÃm‖2F .,4.1. Relation between clustering objective functions of,[0],[0]
"For any γ ≥ 1, if ‖Ã− P̂Ã‖2F ≤ γ‖Ã− P̃∗Ã‖2F , then, ‖Ãm− P̂Ãm‖2F ≤ γ‖Ãm",4.1. Relation between clustering objective functions of,[0],[0]
− P̃∗mÃm‖2F,4.1. Relation between clustering objective functions of,[0],[0]
+ (γ − 1)‖Ã − Ãm‖2F + ‖P̂(Ã − Ãm)‖2F .,4.1. Relation between clustering objective functions of,[0],[0]
"In particular, the following holds.
",4.1. Relation between clustering objective functions of,[0],[0]
(i),4.1. Relation between clustering objective functions of,[0],[0]
"If γ = 1, then, ‖Ãm − P̃∗Ãm‖2F ≤ (1 + 2 )‖Ãm",4.1. Relation between clustering objective functions of,[0],[0]
− P̃∗mÃm‖2.,4.1. Relation between clustering objective functions of,[0],[0]
(ii),4.1. Relation between clustering objective functions of,[0],[0]
"If γ = 1 + 1, for any 0 < 1 < 1 satisfying 1 ∑r i=m+1 σ 2 i (Ã) ≤ ∑m+k",4.1. Relation between clustering objective functions of,[0],[0]
"i=m+1 σ 2 i (Ã), then, ‖Ãm",4.1. Relation between clustering objective functions of,[0],[0]
− P̂Ãm‖2F ≤ (1 + 1 + 4 ),4.1. Relation between clustering objective functions of,[0],[0]
‖Ãm,4.1. Relation between clustering objective functions of,[0],[0]
"− P̃∗mÃm‖2.
",4.1. Relation between clustering objective functions of,[0],[0]
"Proof of the above lemma, which follows from repeated applications of linear algebra basics, choice of m, definition of P̂ and optimality of P̃∗, is long and technical and is differed to the supplementary material for better readability.",4.1. Relation between clustering objective functions of,[0],[0]
"Note that on the left hand side of the first inequality above (for γ = 1), we have used P̃∗ instead of P̂ since P̂ and P̃∗ are identical for γ",4.1. Relation between clustering objective functions of,[0],[0]
= 1.,4.1. Relation between clustering objective functions of,[0],[0]
Now we show that optimal cluster indicator matrix obtained by solving k-means clustering problem on Ãm results in close to optimal k-means objective of A. Let P∗,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"=
argminP∈S",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
‖A − PA‖2F and P̃∗m =,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
argminP∈S,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
‖Ãm,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
− PÃm‖2F .,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
Our goal is to show that ‖A−P̃∗mA‖2F is close to ‖A−P∗A‖2F .,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"In fact, we prove a stronger result showing that Ãm is a rank k projection cost preserving sketch2 of A.",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
We do this in multiple steps.,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"First we show that for small k, Ãm is approximately best rank m subspace of A. Next, we show that such an Ãm is a rank k projection cost preserving sketch for A, which in turn ensures the required guarantee.
",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
We start with the following lemma which is a consequence of Theorem 2.,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
Lemma 2.,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
Fix any m ≥ 1 and let 0 < 2,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
< 1/,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"√ m. Let Ã be a sparse matrix obtained using non-uniform random sampling scheme as in equation 4 with p = 16nb 2
22‖A‖2F .",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"Then Ã contains O ( n 22 + d(log n)4 ) non-zero entries in expectation and with probability at least (1− 1/n19 log3 n),
‖A− Ãm‖F ≤ ‖A−Am‖F + 3 √ 2m 1/4‖A‖F
We tailor the above result to show that under mild conditions Ãm approximates Am reasonably well.
",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
Lemma 3.,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"Fix any 3, where 0 < 3 < 1.",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
Let rank of A be ρ.,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
Fix any k that satisfies ∑k/ 3 i=1 σ,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
2 i (A) ≤ 12,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
∑ρ i=1,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
σ 2,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"i (A), and let m = dk/ 3e.",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"Let Ã be a sparse matrix obtained using non-uniform random sampling scheme as in equation 4 with p = O ( nb2k
93‖A‖2F
) .",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"Then Ã contains
O ( nk 93 + d(log n)4 ) non-zero entries in expectation and with probability at least (1− 1/n19 log3 n),
‖A− Ãm‖F ≤ (1 + 23)‖A−Am‖F
Next, we use a result from (Cohen et al., 2015) to show that if Ãm is close to best rank approximation of A, then Ãm is rank k projection cost preserving sketch for A.
Theorem 3.",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"[Theorem 9 of (Cohen et al., 2015)] Let m = dk/ 3e.",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"For any A ∈ Rn×d, 0 ≤ 4 ≤ 1 and any B ∈ Rn×d with rank(B) = m satisfying ‖A",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"− B‖2F ≤ (1 + 24)‖A−Am‖2F , the sketch B is a projection cost preserving sketch for A. Specifically, for all rank k orthogonal projections P,
(1− 2 4)‖A−PA‖2F ≤",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
‖B−PB‖2F,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
+ c ≤,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"(1 + 2 3 + 5 4)‖A−PA‖2F
where c is a non-negative scalar.
",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"From Lemma 3 we see that with high probability, ‖A − Ãm‖2F ≤ (1 + 2 23 + 43)‖A −Am‖2F = (1 + 3 23)‖A −
2If B is a rank k projection cost preserving sketch of A, then optimal k-means clustering solution of B results in approximately optimal k-means clustering objective of A (Cohen et al., 2015).
",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
Am‖2F .,4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
"Setting 4 = √
3 3 and B = Ãm, it follows from Theorem 3 that Ãm is a rank k projection cost preserving sketch of A.",4.2. Relation between clustering objective functions of Ãm and A,[0],[0]
We combine these results from previous two subsections to present the main result of this paper.,4.3. Main result,[0],[0]
Theorem 4.,4.3. Main result,[0],[0]
"Fix any , where 0 < < 1/4.",4.3. Main result,[0],[0]
Let rank of A be ρ.,4.3. Main result,[0],[0]
For any k that satisfies ∑k/ i=1,4.3. Main result,[0],[0]
σ,4.3. Main result,[0],[0]
2,4.3. Main result,[0],[0]
i (A) ≤ 1 2 ∑ρ i=1,4.3. Main result,[0],[0]
σ 2,4.3. Main result,[0],[0]
"i (A), and let m = dk/ e. Let Ã be a sparse matrix obtained using non-uniform random sampling scheme as in equation 4 with p = O ( nb2k
9‖A‖2F
) .",4.3. Main result,[0],[0]
"For any
set S of rank k cluster projection matrices, let P∗",4.3. Main result,[0],[0]
= argminP∈S,4.3. Main result,[0],[0]
"‖A−PA‖2F , P̃∗ = argminP∈S ‖Ã−PÃ‖2F and P̃∗m = argminP∈S",4.3. Main result,[0],[0]
‖Ãm,4.3. Main result,[0],[0]
− PÃm‖2F .,4.3. Main result,[0],[0]
"For any γ ≥ 1, if ‖Ã − P̂Ã‖2F ≤ γ‖Ã",4.3. Main result,[0],[0]
"− P̃∗Ã‖2F , then Ã contains O ( nk 9 + d(log n) 4 )
non-zero entries in expectation and with probability at least (1 − 1/n19 log3 n)",4.3. Main result,[0],[0]
"the following holds,
(i)",4.3. Main result,[0],[0]
"If γ = 1, then ‖A−P̂A‖2F ≤ (1+2 )(1+11 ) 1−4 ‖A−P ∗A‖2
(ii) If γ = 1 + 1, for any 0 < 1 < 1 satisfying 1 ∑r i=m+1 σ 2 i (Ã) ≤ ∑m+k",4.3. Main result,[0],[0]
"i=m+1 σ 2 i (Ã), then ‖A − P̂A‖2F ≤ (1+ 1+4 )(1+11 ) 1−4 ‖A−P ∗A‖2
Proof.",4.3. Main result,[0],[0]
Set 3 = .,4.3. Main result,[0],[0]
"Then from Lemma 3 we get, ‖A − Ãm‖2F ≤ (1 + 3 2)‖A −Am‖2F .",4.3. Main result,[0],[0]
"Now setting B = Ãm and 4 = √ 3 in Theorem 3, for any rank k orthogonal projection P we get, (1− 2 √
3 )‖A−PA‖2F ≤",4.3. Main result,[0],[0]
‖Ãm −PÃm‖2F + c ≤,4.3. Main result,[0],[0]
"(1 + 2 + 5 √ 3 )‖A−PA‖2F
or simplifying,
(1− 4 )‖A−PA‖2F ≤",4.3. Main result,[0],[0]
‖Ãm −PÃm‖2F + c ≤,4.3. Main result,[0],[0]
(1 + 11 )‖A−PA‖2F,4.3. Main result,[0],[0]
"(5)
Let γ1 = (1 + 2 ) if γ = 1 and γ1 = (1 + 1 + 4 ) if γ ≥ 1.",4.3. Main result,[0],[0]
Then from lemma 1 we get ‖Ãm,4.3. Main result,[0],[0]
− P̂Ãm‖2F ≤ γ1‖Ãm,4.3. Main result,[0],[0]
− P̃∗mÃm‖2.,4.3. Main result,[0],[0]
"Using this result and repeated application of Equation 5 we get,
‖A− P̂A‖2F
≤ 1 1− 4
{",4.3. Main result,[0],[0]
"‖Ãm − P̂Ãm‖2F + c } ≤ 1
1− 4
{ γ1‖Ãm − P̃∗mÃm‖2F + c } ≤ 1
1− 4
{ γ1‖Ãm −P∗Ãm‖2F + c } ≤ 1
1− 4 { γ1",4.3. Main result,[0],[0]
[ (1 + 11 ),4.3. Main result,[0],[0]
‖A−P∗A‖2F,4.3. Main result,[0],[0]
− c ],4.3. Main result,[0],[0]
"+ c }
≤",4.3. Main result,[0],[0]
γ1(1 + 11 ),4.3. Main result,[0],[0]
"1− 4 ‖A−P∗A‖2F
Substituting appropriate value of γ1 yields the result.
",4.3. Main result,[0],[0]
The above result (Theorem 4) is obtained by stitching together many intermediate results.,4.3. Main result,[0],[0]
"To make sure that everything works at the end, we have different ranges for in Lemma 1 and Theorem 4.
",4.3. Main result,[0],[0]
A simple consequence of the above theorem is the following result which ensures (1 + ′) approximation for any 0,4.3. Main result,[0],[0]
< ′,4.3. Main result,[0],[0]
"< 1.
",4.3. Main result,[0],[0]
Corollary 1.,4.3. Main result,[0],[0]
"Fix any ′, where 0 < ′",4.3. Main result,[0],[0]
< 1.,4.3. Main result,[0],[0]
Let rank of A be ρ.,4.3. Main result,[0],[0]
Let m = O(k/ ′) and fix any k that satisfies∑m i=1 σ,4.3. Main result,[0],[0]
2,4.3. Main result,[0],[0]
i (A) ≤ 12,4.3. Main result,[0],[0]
∑ρ i=1,4.3. Main result,[0],[0]
σ 2,4.3. Main result,[0],[0]
i (A).,4.3. Main result,[0],[0]
"Let Ã be a sparse matrix obtained using non-uniform random sampling scheme as in equation 4 with p = O ( nb2k
( ′)9‖A‖2F
) .",4.3. Main result,[0],[0]
"For any set S of rank
k cluster projection matrices, let P∗",4.3. Main result,[0],[0]
= argminP∈S ‖A− PA‖2F and P̃∗ = argminP∈S ‖Ã,4.3. Main result,[0],[0]
− PÃ‖2F .,4.3. Main result,[0],[0]
For any 1 ≤ γ ≤ 2 satisfying (γ − 1) ∑r,4.3. Main result,[0],[0]
"i=m+1 σ
2 i (Ã) ≤∑m+k
i=m+1 σ 2 i (Ã), if ‖Ã− P̂Ã‖2F ≤ γ‖Ã−",4.3. Main result,[0],[0]
"P̃∗Ã‖2F , then Ã contains O (
nk ( ′)9 + d(log n)
4 )
non-zero entries in ex-
pectation and with probability at least (1−1/n19 log3 n)",4.3. Main result,[0],[0]
"the following holds,
‖A− P̂A‖2F ≤",4.3. Main result,[0],[0]
γ(1 + ′)‖A−P∗A‖2,4.3. Main result,[0],[0]
"In this section we present empirical evaluation of our proposed algorithm on three real world datasets: USPS, RCV1 and TDT2.",5. Empirical evaluations,[0],[0]
"The USPS dataset (Hull, 1994) contains 9298 handwritten digit images, where each 16 × 16 image is represented by a feature vector of length 256.",5. Empirical evaluations,[0],[0]
"We seek to find k = 10 clusters, one for each of the ten digits.",5. Empirical evaluations,[0],[0]
"The RCV1 dataset (Lewis et al., 2004) is an archive of over 800, 000 manually categorized news articles recently made available by Reuters.",5. Empirical evaluations,[0],[0]
"We use a smaller subset of this dataset available from LIBSVM webpage (LIB) containing 15, 564 news articles from 53 categories.",5. Empirical evaluations,[0],[0]
"Each such news article is represented by a feature vector of length 47, 236.",5. Empirical evaluations,[0],[0]
"We seek to find k = 53 clusters, one for each news article category.",5. Empirical evaluations,[0],[0]
"The TDT2 dataset (Cieri et al., 1999) consists of 11201 text documents which are classified into 96 semantic categories.",5. Empirical evaluations,[0],[0]
"We use a smaller subset of this dataset available from Deng Cai’s webpage3 where those documents appearing in two or more categories are removed, and only the largest 30 categories are kept, resulting in 9, 394 documents in total.",5. Empirical evaluations,[0],[0]
"Each such document is represented by a feature vector of length 36, 771.",5. Empirical evaluations,[0],[0]
"We seek to find k = 30 clusters, one for each news article category.",5. Empirical evaluations,[0],[0]
"For USPS dataset, all (100%) data matrix entries are non-zero.",5. Empirical evaluations,[0],[0]
"However, for TDT2 dataset, only 0.35% entries of the 9394 × 36771 data matrix are
3http://www.cad.zju.edu.cn/home/dengcai/Data/TextData.html
non-zero, while for RCV1 dataset, only 0.14% entries of the 15564 × 47236 data matrix are non-zero.",5. Empirical evaluations,[0],[0]
Since these two later datasets are already very sparse we reduce data dimensionality to 1000 using random projection in both cases by multiplying original data matrices with a random projection matrix (of appropriate size) whose entries are standard i.i.d.,5. Empirical evaluations,[0],[0]
normals4.,5. Empirical evaluations,[0],[0]
"After this random projection step, resulting projected data matrices become dense matrices, each containing 100% non-zero entries.",5. Empirical evaluations,[0],[0]
"As we will demonstrate next, for these two dense projected matrices our proposed sparsification method finds k-means clustering solution without severely affecting cluster quality.
",5. Empirical evaluations,[0],[0]
"To apply Lloyd’s heuristic for k-means clustering we use Matlab’s kmeans function which, by default, uses kmeans++ algorithm (Arthur & Vassilvitskii, 2007) for cluster center initialization.",5. Empirical evaluations,[0],[0]
"We repeat this clustering 30 times, each time initializing cluster center using k-means++ and selecting the final clustering as the one with lowest k-means objective.",5. Empirical evaluations,[0],[0]
"We demonstrate the effect of random sparsification obtained by uniform and non-uniform sampling on k-means clustering by reporting the following quantities, (a) the ratio h1(q) = ‖A−XqX>q",5. Empirical evaluations,[0],[0]
A‖2F /‖A−XX,5. Empirical evaluations,[0],[0]
">A‖2F , (b) cluster quality h2(q), measured by normalized mutual information (with respect to ground truth cluster labels of A) of a sparse data matrix Ã whose q fracation of entries are non-zero, and (c) normalized objective function h3(q) =",5. Empirical evaluations,[0],[0]
‖A − XqX>q A‖2F /‖A‖2F,5. Empirical evaluations,[0],[0]
",",5. Empirical evaluations,[0],[0]
as we vary q.,5. Empirical evaluations,[0],[0]
"In the above description, Xq is the cluster indicator matrix obtained by running k-means on sparse data matrix Ã whose q fraction of entries are non-zero and X is the cluster indicator matrix obtained by running k-means on A.
For uniform sampling, p simply indicates that p fraction
4It has been shown (Cohen et al., 2015) that such dimensionality reduction introduces (1 + ) relative error to optimal k-means objective.",5. Empirical evaluations,[0],[0]
"We chose projected dimension to be 1000 since increasing it further did not increase normalized mutual information significantly.
of entries of Ã are non-zero (in expectation, when A is dense matrix).",5. Empirical evaluations,[0],[0]
"For non-uniform sampling, number of nonzero entries in Ã can only be guaranteed by Theorem 2, which typically holds for large n.",5. Empirical evaluations,[0],[0]
In our empirical evaluation we use a slightly different strategy for non-uniform sampling than what is presented in section 2.3.2.,5. Empirical evaluations,[0],[0]
"However, this modified strategy, in principle, is still similar to what is presented in section 2.3.2.",5. Empirical evaluations,[0],[0]
"For any fixed value of p, note that τij = p(A(i, j)/b)
2.",5. Empirical evaluations,[0],[0]
"Now, instead of using pij in terms of τij as given in section 2.3.2, we use,
pij = { τij if τij ≥ p× f√ τij × p× f",5. Empirical evaluations,[0],[0]
"otherwise
where, f > 1, is to be chosen later.",5. Empirical evaluations,[0],[0]
"Therefore, for τij < p×f , pij = √ τij × p× f = p×(|A(i, j)|/b)× √ f .",5. Empirical evaluations,[0],[0]
"The basic idea is still same as before, i.e., when τij is small, instead of setting pij ∝",5. Empirical evaluations,[0],[0]
"(A(i, j))2, we set pij ∝",5. Empirical evaluations,[0],[0]
"|A(i, j)|.",5. Empirical evaluations,[0],[0]
"Now consider the case when τij < p× f , for all i, j.",5. Empirical evaluations,[0],[0]
"The expected number of non-zero entries is ∑ i,j p ×",5. Empirical evaluations,[0],[0]
√ f ×,5. Empirical evaluations,[0],[0]
"(|A(i, j)|/b) = pnd×",5. Empirical evaluations,[0],[0]
"√ f×Avg(|A(i, j)|/b).",5. Empirical evaluations,[0],[0]
"Therefore, if we choose5 f = 1/(Avg(|A(i, j)|/b))2, expected number of non-zero entries in Ã is pnd.",5. Empirical evaluations,[0],[0]
"In general, when the condition τij < p× f does not hold for all i, j, the expected fraction will be even less since pij < p, for τij ≥ p× f .",5. Empirical evaluations,[0],[0]
"In our experimental setting, we set f = 1/(Avg(|A(i, j)|/b))2.",5. Empirical evaluations,[0],[0]
"This ensures for any p, non-uniform sampling results in at most p fraction of non-zero entries in Ã. In our experiments, we vary p from 0.01 to 1.0 in steps of 0.01 and for each value of p, the number of of non-zero entries in Ã obtained due to non-uniform sampling is denoted by q and is plotted in Figure 2 for all three datasets.",5. Empirical evaluations,[0],[0]
"Observe that for all values of p, q = p for uniform sampling and q ≤ p for non-uniform sampling.
",5. Empirical evaluations,[0],[0]
"Next, in Figure 3 we show how random sparsification affects k-means clustering quality with increasing q.",5. Empirical evaluations,[0],[0]
"As can be seen from Figure 3, with increasing q, h1(q) and h3(q) decrease, while h2(q) increases as one would expect.",5. Empirical evaluations,[0],[0]
"In fact, h1(q) decreases quickly towards its optimal value 1 and corresponding h2(q) value quickly increases towards optimal k-means normalized mutual information of A. The normalized k-means objective h3(q)",5. Empirical evaluations,[0],[0]
"also shows steady decrease with increasing q. As can be seen from Figure 3, for all three datasets, non-uniform sampling yields better k-means clustering performance compared to uniform sampling.",5. Empirical evaluations,[0],[0]
"This makes perfect sense since non-uniform sampling, unlike uniform sampling, enforces sparsity by retaining entries with probability that depends on their magnitude.",5. Empirical evaluations,[0],[0]
"In fact, for TDT2 and RCV1 datasets, non-uniform sampling results in significant improvement in k-means clustering performance compared to uniform sampling.
",5. Empirical evaluations,[0],[0]
"5Avg(|A(i, j)|) represents average over all entries |A(i, j)|.
USPS
TDT2
RCV1",5. Empirical evaluations,[0],[0]
In this paper we proposed a simple algorithm for k-means clustering using random matrix sparsification and presented its analysis.,6. Conclusion,[0],[0]
"We proved that under mild condition, for any ∈ (0, 1), a dense data matrix A ∈ Rn×d can be randomly sparsified to yield a data matrix Ã ∈ Rn×d containing O(nk/ 9 + d log4 n) non-zero entries in expectation, such that an (1+ )-approximate k-mean clustering solution of Ã results in (1 +O( ))-approximate clustering solution of A with high probability.",6. Conclusion,[0],[0]
"Empirical results on three real world datasets demonstrated that k-means clustering solution of Ã was indeed very close to k-means clustering solution of A. Moreover, sparsification obtained by non-uniform sampling resulted in better cluster quality compared to uniform sampling.",6. Conclusion,[0],[0]
Empirical results also seem to suggest that the O(1/ 9) dependence on the number of non-zero entries in Ã is possibly a bit loose.,6. Conclusion,[0],[0]
We conclude this paper with two possible open questions: (a) Is it possible to analytically provide a better estimate (by improving dependence on 1/ ) of the number of non-zero entries in the sparse matrix Ã that ensures (1 + ) approximation guarantee?,6. Conclusion,[0],[0]
"and, (b) Using different proof technique, is it possible to show that γ-approximate clustering solution of Ã will result in γ(1 + )-approximate solution of A as shown in Corollary 1, even for γ > 2?",6. Conclusion,[0],[0]
"In other words, is the restriction on γ
in Corollary 1 a limitation of the proof technique or does it indicate computational hardness of the problem?",6. Conclusion,[0],[0]
K-means clustering algorithm using Lloyd’s heuristic is one of the most commonly used tools in data mining and machine learning that shows promising performance.,abstractText,[0],[0]
"However, it suffers from a high computational cost resulting from pairwise Euclidean distance computations between data points and cluster centers in each iteration of Lloyd’s heuristic.",abstractText,[0],[0]
"Main contributing factor of this computational bottle neck is a matrix-vector multiplication step, where the matrix contains all the data points and the vector is a cluster center.",abstractText,[0],[0]
In this paper we show that we can randomly sparsify the original data matrix resulting in a sparse data matrix which can significantly speed up the above mentioned matrix vector multiplication step without significantly affecting cluster quality.,abstractText,[0],[0]
"In particular, we show that optimal k-means clustering solution of the sparse data matrix, obtained by applying random matrix sparsification, results in an approximately optimal k-means clustering objective of the original data matrix.",abstractText,[0],[0]
Our empirical studies on three real world datasets corroborate our theoretical findings and demonstrate that our proposed sparsification method can indeed achieve satisfactory clustering performance.,abstractText,[0],[0]
K-means clustering using random matrix sparsification,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 1470–1480 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics
We introduce KBGAN, an adversarial learning framework to improve the performances of a wide range of existing knowledge graph embedding models. Because knowledge graphs typically only contain positive facts, sampling useful negative training examples is a nontrivial task. Replacing the head or tail entity of a fact with a uniformly randomly selected entity is a conventional method for generating negative facts, but the majority of the generated negative facts can be easily discriminated from positive facts, and will contribute little towards the training. Inspired by generative adversarial networks (GANs), we use one knowledge graph embedding model as a negative sample generator to assist the training of our desired model, which acts as the discriminator in GANs. This framework is independent of the concrete form of generator and discriminator, and therefore can utilize a wide variety of knowledge graph embedding models as its building blocks. In experiments, we adversarially train two translation-based models, TRANSE and TRANSD, each with assistance from one of the two probability-based models, DISTMULT and COMPLEX. We evaluate the performances of KBGAN on the link prediction task, using three knowledge base completion datasets: FB15k-237, WN18 and WN18RR. Experimental results show that adversarial training substantially improves the performances of target embedding models under various settings.",text,[0],[0]
"Knowledge graph (Dong et al., 2014) is a powerful graph structure that can provide direct access of knowledge to users via various applications such as structured search, question answering, and intelligent virtual assistant.",1 Introduction,[0],[0]
"A common representation of knowledge graph beliefs is in the
form of a discrete relational triple such as LocatedIn(NewOrleans,Louisiana).
",1 Introduction,[0],[0]
A main challenge for using discrete representation of knowledge graph is the lack of capability of accessing the similarities among different entities and relations.,1 Introduction,[0],[0]
"Knowledge graph embedding (KGE) techniques (e.g., RESCAL (Nickel et al., 2011), TRANSE (Bordes et al., 2013), DISTMULT (Yang et al., 2015), and COMPLEX (Trouillon et al., 2016)) have been proposed in recent years to deal with the issue.",1 Introduction,[0],[0]
"The main idea is to represent the entities and relations in a vector space, and one can use machine learning technique to learn the continuous representation of the knowledge graph in the latent space.
",1 Introduction,[0],[0]
"However, even steady progress has been made in developing novel algorithms for knowledge graph embedding, there is still a common challenge in this line of research.",1 Introduction,[0],[0]
"For space efficiency, common knowledge graphs such as Freebase (Bollacker et al., 2008), Yago (Suchanek et al., 2007), and NELL (Mitchell et al., 2015) by default only stores beliefs, rather than disbeliefs.",1 Introduction,[0],[0]
"Therefore, when training the embedding models, there is only the natural presence of the positive examples.",1 Introduction,[0],[0]
"To use negative examples, a common method is to remove the correct tail entity, and randomly sample from a uniform distribution (Bordes et al., 2013).",1 Introduction,[0],[0]
"Unfortunately, this approach is not ideal, because the sampled entity could be completely unrelated to the head and the target relation, and thus the quality of randomly generated negative examples is often poor (e.g, LocatedIn(NewOrleans,BarackObama)).",1 Introduction,[0],[0]
"Other approach might leverage external ontological constraints such as entity types (Krompaß et al., 2015) to generate negative examples, but such resource does not always exist or accessible.
",1 Introduction,[0],[0]
"In this work, we provide a generic solution to improve the training of a wide range of knowl-
1470
edge graph embedding models.",1 Introduction,[0],[0]
"Inspired by the recent advances of generative adversarial deep models (Goodfellow et al., 2014), we propose a novel adversarial learning framework, namely, KBGAN, for generating better negative examples to train knowledge graph embedding models.",1 Introduction,[0],[0]
"More specifically, we consider probabilitybased, log-loss embedding models as the generator to supply better quality negative examples, and use distance-based, margin-loss embedding models as the discriminator to generate the final knowledge graph embeddings.",1 Introduction,[0],[0]
"Since the generator has a discrete generation step, we cannot directly use the gradient-based approach to backpropagate the errors.",1 Introduction,[0],[0]
"We then consider a onestep reinforcement learning setting, and use a variance-reduction REINFORCE method to achieve this goal.",1 Introduction,[0],[0]
"Empirically, we perform experiments on three common KGE datasets (FB15K-237, WN18 and WN18RR), and verify the adversarial learning approach with a set of KGE models.",1 Introduction,[0],[0]
"Our experiments show that across various settings, this adversarial learning mechanism can significantly improve the performance of some of the most commonly used translation based KGE methods.",1 Introduction,[0],[0]
"Our contributions are three-fold:
•",1 Introduction,[0],[0]
"We are the first to consider adversarial learning to generate useful negative training examples to improve knowledge graph embedding.
",1 Introduction,[0],[0]
•,1 Introduction,[0],[0]
"This adversarial learning framework applies to a wide range of KGE models, without the need of external ontologies constraints.
",1 Introduction,[0],[0]
• Our method shows consistent performance gains on three commonly used KGE datasets.,1 Introduction,[0],[0]
"A large number of knowledge graph embedding models, which represent entities and relations in a knowledge graph with vectors or matrices, have been proposed in recent years.",2.1 Knowledge Graph Embeddings,[0],[0]
"RESCAL (Nickel et al., 2011) is one of the earliest studies on matrix factorization based knowledge graph embedding models, using a bilinear form as score function.",2.1 Knowledge Graph Embeddings,[0],[0]
"TRANSE (Bordes et al., 2013) is the first model to introduce translation-based embedding.",2.1 Knowledge Graph Embeddings,[0],[0]
"Later variants, such as TRANSH (Wang et al., 2014), TRANSR (Lin et al., 2015) and TRANSD (Ji et al., 2015), extend TRANSE by projecting the embedding vectors of entities into various spaces.",2.1 Knowledge Graph Embeddings,[0],[0]
"DISTMULT (Yang et al., 2015) simplifies RESCAL by only using a diagonal matrix, and COMPLEX (Trouillon et al., 2016) extends DISTMULT into the complex number field.",2.1 Knowledge Graph Embeddings,[0],[0]
"(Nickel et al., 2015) is a comprehensive survey on these models.
",2.1 Knowledge Graph Embeddings,[0],[0]
Some of the more recent models achieve strong performances.,2.1 Knowledge Graph Embeddings,[0],[0]
"MANIFOLDE (Xiao et al., 2016) embeds a triple as a manifold rather than a point.",2.1 Knowledge Graph Embeddings,[0],[0]
"HOLE (Nickel et al., 2016) employs circular correlation to combine the two entities in a triple.",2.1 Knowledge Graph Embeddings,[0],[0]
"CONVE (Dettmers et al., 2017) uses a convolutional neural network as the score function.",2.1 Knowledge Graph Embeddings,[0],[0]
"However, most of these studies use uniform sampling to generate negative training examples (Bordes et al., 2013).",2.1 Knowledge Graph Embeddings,[0],[0]
"Because our framework is independent of the concrete form of models, all these models can be potentially incorporated into our framework, regardless of the complexity.",2.1 Knowledge Graph Embeddings,[0],[0]
"As a proof of principle, our work focuses on simpler models.",2.1 Knowledge Graph Embeddings,[0],[0]
Table 1 summarizes the score functions and dimensions of all models mentioned above.,2.1 Knowledge Graph Embeddings,[0],[0]
"Generative Adversarial Networks (GANs) (Goodfellow et al., 2014) was originally proposed for generating samples in a continuous space such as images.",2.2 Generative Adversarial Networks and its Variants,[0],[0]
"A GAN consists of two parts, the generator and the discriminator.",2.2 Generative Adversarial Networks and its Variants,[0],[0]
The generator accepts a noise input and outputs an image.,2.2 Generative Adversarial Networks and its Variants,[0],[0]
The discriminator is a classifier which classifies images as “true” (from the ground truth set) or “fake” (generated by the generator).,2.2 Generative Adversarial Networks and its Variants,[0],[0]
"When training a GAN, the generator and the discriminator play a minimax game, in which the generator tries to generate “real” images to deceive the discriminator, and the discriminator tries to tell them apart from ground truth images.",2.2 Generative Adversarial Networks and its Variants,[0],[0]
"GANs are also capable of generating samples satisfying certain requirements, such as conditional GAN (Mirza and Osindero, 2014).
",2.2 Generative Adversarial Networks and its Variants,[0],[0]
"It is not possible to use GANs in its original form for generating discrete samples like natural language sentences or knowledge graph triples, because the discrete sampling step prevents gradients from propagating back to the generator.",2.2 Generative Adversarial Networks and its Variants,[0],[0]
"SEQGAN (Yu et al., 2017) is one of the first successful solutions to this problem by using reinforcement learning—It trains the generator using policy gradient and other tricks.",2.2 Generative Adversarial Networks and its Variants,[0],[0]
"IRGAN (Wang et al., 2017) is a recent work which combines two categories of information retrieval models into a discrete GAN framework.",2.2 Generative Adversarial Networks and its Variants,[0],[0]
"Likewise, our framework relies on policy gradient to train the generator which provides discrete negative triples.
",2.2 Generative Adversarial Networks and its Variants,[0],[0]
The discriminator in a GAN is not necessarily a classifier.,2.2 Generative Adversarial Networks and its Variants,[0],[0]
"Wasserstein GAN or WGAN (Arjovsky et al., 2017) uses a regressor with clipped parameters as its discriminator, based on solid analysis about the mathematical nature of GANs.",2.2 Generative Adversarial Networks and its Variants,[0],[0]
"GOGAN (Juefei-Xu et al., 2017) further replaces the loss function in WGAN with marginal loss.",2.2 Generative Adversarial Networks and its Variants,[0],[0]
"Although originating from very different fields, the form of loss function in our framework turns out to be more closely related to the one in GOGAN.",2.2 Generative Adversarial Networks and its Variants,[0],[0]
"In this section, we first define two types of training objectives in knowledge graph embedding models to show how KBGAN can be applied.",3 Our Approaches,[0],[0]
"Then, we demonstrate a long overlooked problem about negative sampling which motivates us to propose KBGAN to address the problem.",3 Our Approaches,[0],[0]
"Finally, we dive into the mathematical, and algorithmic details of
KBGAN.",3 Our Approaches,[0],[0]
"For a given knowledge graph, let E be the set of entities, R be the set of relations, and T be the set of ground truth triples.",3.1 Types of Training Objectives,[0],[0]
"In general, a knowledge graph embedding (KGE) model can be formulated as a score function f(h, r, t), h, t ∈ E , r ∈ R which assigns a score to every possible triple in the knowledge graph.",3.1 Types of Training Objectives,[0],[0]
"The estimated likelihood of a triple to be true depends only on its score given by the score function.
",3.1 Types of Training Objectives,[0],[0]
"Different models formulate their score function based on different designs, and therefore interpret scores differently, which further lead to various training objectives.",3.1 Types of Training Objectives,[0],[0]
"Two common forms of training objectives are particularly of our interest: Marginal loss function is commonly used by a large group of models called translation-based models, whose score function models distance between points or vectors, such as TRANSE, TRANSH, TRANSR, TRANSD and so on.",3.1 Types of Training Objectives,[0],[0]
"In these models, smaller distance indicates a higher likelihood of truth, but only qualitatively.",3.1 Types of Training Objectives,[0],[0]
"The marginal loss function takes the following form:
Lm = ∑
(h,r,t)∈T [f(h, r, t)− f(h′, r, t′) +",3.1 Types of Training Objectives,[0],[0]
"γ]+ (1)
where γ is the margin, [·]+ = max(0, ·) is the hinge function, and (h′, r, t′) is a negative triple.",3.1 Types of Training Objectives,[0],[0]
"The negative triple is generated by replacing the head entity or the tail entity of a positive triple with a random entity in the knowledge graph, or formally (h′, r, t′) ∈ {(h′, r, t)|h′ ∈ E} ∪ {(h, r, t′)|t′ ∈ E}.",3.1 Types of Training Objectives,[0],[0]
Log-softmax loss function is commonly used by models whose score function has probabilistic interpretation.,3.1 Types of Training Objectives,[0],[0]
"Some notable examples are RESCAL, DISTMULT, COMPLEX.",3.1 Types of Training Objectives,[0],[0]
"Applying the softmax function on scores of a given set of triples gives the probability of a triple to be the best one among them: p(h, r, t) = exp f(h,r,t)∑
(h′,r,t′) exp f(h ′,r,t′) .",3.1 Types of Training Objectives,[0],[0]
"The loss
function is the negative log-likelihood of this probabilistic model:
",3.1 Types of Training Objectives,[0],[0]
"Ll = ∑
(h,r,t)∈T − log exp f(h, r, t)∑ exp f(h′, r, t′)
(h′, r, t′) ∈ {(h, r, t)} ∪Neg(h, r, t) (2) where Neg(h, r, t) ⊂ {(h′, r, t)|h′ ∈ E} ∪ {(h, r, t′)|t′ ∈ E} is a set of sampled corrupted triples.
",3.1 Types of Training Objectives,[0],[0]
"Other forms of loss functions exist, for example CONVE uses a triple-wise logistic function to model how likely the triple is true, but by far the two described above are the most common.",3.1 Types of Training Objectives,[0],[0]
"Also, softmax function gives an probabilistic distribution over a set of triples, which is necessary for a generator to sample from them.",3.1 Types of Training Objectives,[0],[0]
"Most previous KGE models use uniform negative sampling for generating negative triples, that is, replacing the head or tail entity of a positive triple with any of the entities in E , all with equal probability.",3.2 Weakness of Uniform Negative Sampling,[0],[0]
"Most of the negative triples generated in this way contribute little to learning an effective embedding, because they are too obviously false.
",3.2 Weakness of Uniform Negative Sampling,[0],[0]
"To demonstrate this issue, let us consider the following example.",3.2 Weakness of Uniform Negative Sampling,[0],[0]
"Suppose we have a ground truth triple LocatedIn(NewOrleans,Louisiana), and corrupt it by replacing its tail entity.",3.2 Weakness of Uniform Negative Sampling,[0],[0]
"First, we remove the tail entity, leaving LocatedIn(NewOrleans,?).",3.2 Weakness of Uniform Negative Sampling,[0],[0]
"Because the relation LocatedIn constraints types of its entities, “?” must be a geographical region.",3.2 Weakness of Uniform Negative Sampling,[0],[0]
"If we fill “?” with a random entity e ∈ E , the probability of e having a wrong type is very high, resulting in ridiculous triples like LocatedIn(NewOrleans,BarackObama) or LocatedIn(NewOrleans,StarTrek).",3.2 Weakness of Uniform Negative Sampling,[0],[0]
"Such triples are considered “too easy”, because they can be eliminated solely by types.",3.2 Weakness of Uniform Negative Sampling,[0],[0]
"In contrast, LocatedIn(NewOrleans,Florida) is a very useful negative triple, because it satisfies type constraints, but it cannot be proved wrong without detailed knowl-
edge of American geography.",3.2 Weakness of Uniform Negative Sampling,[0],[0]
"If a KGE model is fed with mostly “too easy” negative examples, it would probably only learn to represent types, not the underlying semantics.
",3.2 Weakness of Uniform Negative Sampling,[0],[0]
"The problem is less severe to models using logsoftmax loss function, because they typically samples tens or hundreds of negative triples for one positive triple in each iteration, and it is likely to have a few useful negatives among them.",3.2 Weakness of Uniform Negative Sampling,[0],[0]
"For instance, (Trouillon et al., 2016) found that a 100:1 negative-to-positive ratio results in the best performance for COMPLEX.",3.2 Weakness of Uniform Negative Sampling,[0],[0]
"However, for marginal loss function, whose negative-to-positive ratio is always 1:1, the low quality of uniformly sampled negatives can seriously damage their performance.",3.2 Weakness of Uniform Negative Sampling,[0],[0]
"Inspired by GANs, we propose an adversarial training framework named KBGAN which uses a KGE model with softmax probabilities to provide high-quality negative samples for the training of a KGE model whose training objective is marginal loss function.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"This framework is independent of the score functions of these two models, and therefore possesses some extent of universality.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Figure 1 illustrates the overall structure of KBGAN.
",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"In parallel to terminologies used in GAN literature, we will simply call these two models generator and discriminator respectively in the rest of this paper.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"We use softmax probabilistic models as the generator because they can adequately model the “sampling from a probability distribu-
Algorithm 1: The KBGAN algorithm Data: training set of positive fact triples T = {(h, r, t)}",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Input: Pre-trained generator G with parameters θG and score function fG(h, r, t), and pre-trained discriminator D with
parameters θD and score function fD(h, r, t)",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Output: Adversarially trained discriminator
1 b←− 0; // baseline for policy gradient 2 repeat 3 Sample a mini-batch of data Tbatch from T ; 4 GG ←− 0, GD ←− 0; // gradients of parameters of G and D 5 rsum ←− 0; // for calculating the baseline 6 for (h, r, t) ∈",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Tbatch do 7 Uniformly randomly sample Ns negative triples Neg(h, r, t) =",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"{(h′i, r, t′i)}i=1...",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
Ns ; 8 Obtain their probability of being generated: pi = exp fG(h ′,3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"i,r,t ′",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
i)∑Ns,3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"
",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"j=1 exp fG(h ′ j ,r,t ′ j)
;
9 Sample one negative triple (h′s, r, t′s) from Neg(h, r, t) according to {pi}i=1...",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
Ns .,3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Assume its probability to be ps;
10 GD ←− GD +∇θD",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"[fD(h, r, t)− fD(h′s, r, t′s) + γ]+; // accumulate gradients for D 11 r ←− −fD(h′s, r, t′s), rsum ←− rsum + r; // r is the reward 12 GG ←− GG",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
+ (r − b)∇θG log ps; // accumulate gradients for G 13 end 14 θG ←−,3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
θG,3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"+ ηGGG,",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"θD ←− θD − ηDGD; // update parameters 15 b← rsum/|Tbatch|; // update baseline 16 until convergence;
tion” process of discrete GANs, and we aim at improving discriminators based on marginal loss because they can benefit more from high-quality negative samples.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Note that a major difference between GAN and our work is that, the ultimate goal of our framework is to produce a good discriminator, whereas GANS are aimed at training a good generator.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"In addition, the discriminator here is not a classifier as it would be in most GANs.
",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Intuitively, the discriminator should assign a relatively small distance to a high-quality negative sample.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"In order to encourage the generator to generate useful negative samples, the objective of the generator is to minimize the distance given by discriminator for its generated triples.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"And just like the ordinary training process, the objective of the discriminator is to minimize the marginal loss between the positive triple and the generated negative triple.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"In an adversarial training setting, the generator and the discriminator are alternatively trained towards their respective objectives.
",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Suppose that the generator produces a probability distribution on negative triples pG(h
′, r, t′|h, r, t) given a positive triple (h, r, t), and generates negative triples (h′, r, t′) by sampling from this distribution.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Let fD(h, r, t) be the score function of the discriminator.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"The objective of the discriminator can be formulated as
minimizing the following marginal loss function:
LD = ∑
(h,r,t)∈T [fD(h, r, t)− fD(h′, r, t′) + γ]+
(h′, r, t′) ∼ pG(h′, r, t′|h, r, t) (3)
",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"The only difference between this loss function and Equation 1 is that it uses negative samples from the generator.
",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"The objective of the generator can be formulated as maximizing the following expectation of negative distances:
RG = ∑
(h,r,t)∈T E[−fD(h′, r, t′)]
(h′, r, t′) ∼ pG(h′, r, t′|h, r, t) (4)
RG involves a discrete sampling step, so we cannot find its gradient with simple differentiation.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"We use a simple special case of Policy Gradient Theorem1 (Sutton et al., 2000) to obtain the gradient of RG with respect to parameters of the generator:
∇GRG = ∑
(h,r,t)∈T E(h′,r,t′)∼pG(h′,r,t′|h,r,t)
",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"[−fD(h′, r, t′)∇G log pG(h′, r, t′|h, r, t)]
' ∑
(h,r,t)∈T
1
N
∑
(h′i,r,t ′",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"i)∼pG(h′,r,t′|h,r,t),i=1...",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"N
[−fD(h′, r, t′)∇G log pG(h′, r, t′|h, r, t)]",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"(5) 1A proof can be found in the supplementary material
where the second approximate equality means we approximate the expectation with sampling in practice.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Now we can calculate the gradient of RG and optimize it with gradient-based algorithms.
",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Policy Gradient Theorem arises from reinforcement learning (RL), so we would like to draw an analogy between our model and an RL model.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
The generator can be viewed as an agent which interacts with the environment by performing actions and improves itself by maximizing the reward returned from the environment in response of its actions.,3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Correspondingly, the discriminator can be viewed as the environment.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Using RL terminologies, (h, r, t) is the state (which determines what actions the actor can take), pG(h′, r, t′|h, r, t) is the policy (how the actor choose actions), (h′, r, t′) is the action, and −fD(h′, r, t′) is the reward.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"The method of optimizing RG described above is called REINFORCE (Williams, 1992) algorithm in RL.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Our model is a simple special case of RL, called one-step RL.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"In a typical RL setting, each action performed by the agent will change its state, and the agent will perform a series of actions (called an epoch) until it reaches certain states or the number of actions reaches a certain limit.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"However, in the analogy above, actions does not affect the state, and after each action we restart with another unrelated state, so each epoch consists of only one action.
",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"To reduce the variance of REINFORCE algorithm, it is common to subtract a baseline from the reward, which is an arbitrary number that only depends on the state, with-
out affecting the expectation of gradients.2 In our case, we replace −fD(h′, r, t′) with −fD(h′, r, t′)",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"− b(h, r, t) in the equation above to introduce the baseline.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"To avoid introducing new parameters, we simply let b be a constant, the average reward of the whole training set: b =∑
(h,r,t)∈T E(h′,r,t′)∼pG(h′,r,t′|h,r,t)[−fD(h′, r, t′)].",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"In practice, b is approximated by the mean of rewards of recently generated negative triples.
",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Let the generator’s score function to be fG(h, r, t), given a set of candidate negative triples Neg(h, r, t) ⊂ {(h′, r, t)|h′ ∈ E}∪{(h, r, t′)|t′ ∈ E}, the probability distribution pG is modeled as:
pG(h ′, r, t′|h, r, t)",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"= exp fG(h ′, r, t′)∑ exp fG(h∗, r, t∗) (h∗, r, t∗) ∈ Neg(h, r, t) (6) Ideally, Neg(h, r, t) should contain all possible negatives.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"However, knowledge graphs are usually highly incomplete, so the ”hardest” negative triples are very likely to be false negatives (true facts).",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"To address this issue, we instead generate Neg(h, r, t) by uniformly sampling of Ns entities (a small number compared to the number of all possible negatives) from E to replace h or t. Because in real-world knowledge graphs, true negatives are usually far more than false negatives, such set would be unlikely to contain any false negative, and the negative selected by the generator would likely be a true negative.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Using a small Neg(h, r, t) can also significantly reduce computational complexity.
",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Besides, we adopt the “bern” sampling technique (Wang et al., 2014) which replaces the “1” side in “1-to-N” and “N-to-1” relations with higher probability to further reduce false negatives.
",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
Algorithm 1 summarizes the whole adversarial training process.,3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Both the generator and the dis-
2A proof of such fact can also be found in the supplementary material
criminator require pre-training, which is the same as conventionally training a single KBE model with uniform negative sampling.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Formally speaking, one can pre-train the generator by minimizing the loss function defined in Equation (1), and pre-train the discriminator by minimizing the loss function defined in Equation (2).",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"Line 14 in the algorithm assumes that we are using the vanilla gradient descent as the optimization method, but obviously one can substitute it with any gradientbased optimization algorithm.",3.3 Generative Adversarial Training for Knowledge Graph Embedding Models,[0],[0]
"To evaluate our proposed framework, we test its performance for the link prediction task with different generators and discriminators.",4 Experiments,[0],[0]
"For the generator, we choose two classical probability-based KGE model, DISTMULT and COMPLEX, and for the discriminator, we also choose two classical translation-based KGE model, TRANSE and TRANSD, resulting in four possible combinations of generator and discriminator in total.",4 Experiments,[0],[0]
See Table 1 for a brief summary of these models.,4 Experiments,[0],[0]
"We use three common knowledge base completion datasets for our experiment: FB15k-237, WN18 and WN18RR. FB15k-237 is a subset of FB15k introduced by (Toutanova and Chen, 2015), which removed redundant relations in FB15k and greatly reduced the number of relations.",4.1.1 Datasets,[0],[0]
"Likewise, WN18RR is a subset of WN18 introduced by (Dettmers et al., 2017) which removes reversing relations and dramatically increases the difficulty of reasoning.",4.1.1 Datasets,[0],[0]
"Both FB15k and WN18 are first introduced by (Bordes et al., 2013) and have been commonly used in knowledge graph researches.",4.1.1 Datasets,[0],[0]
Statistics of datasets we used are shown in Table 3.,4.1.1 Datasets,[0],[0]
"Following previous works like (Yang et al., 2015) and (Trouillon et al., 2016), for each run, we report two common metrics, mean reciprocal ranking (MRR) and hits at 10 (H@10).",4.1.2 Evaluation Protocols,[0],[0]
"We only report scores under the filtered setting (Bordes et al., 2013), which removes all triples appeared in training, validating, and testing sets from candidate triples before obtaining the rank of the ground truth triple.",4.1.2 Evaluation Protocols,[0],[0]
"3 In the pre-training stage, we train every model to convergence for 1000 epochs, and divide every epoch into 100 mini-batches.",4.1.3 Implementation Details,[0],[0]
"To avoid overfitting, we adopt early stopping by evaluating MRR on the validation set every 50 epochs.",4.1.3 Implementation Details,[0],[0]
"We tried γ = 0.5, 1, 2, 3, 4, 5 and L1, L2 distances for TRANSE and TRANSD, and λ = 0.01, 0.1, 1, 10 for DISTMULT and COMPLEX, and determined the best hyperparameters listed on table 2, based on their performances on the validation set after pre-training.",4.1.3 Implementation Details,[0],[0]
"Due to limited computation resources, we deliberately limit the dimensions of embeddings to k = 50, similar to the one used in earlier works, to save time.",4.1.3 Implementation Details,[0],[0]
"We also apply certain constraints or regularizations to these models, which are mostly the same as those described in their original publications, and also listed on table 2.
",4.1.3 Implementation Details,[0],[0]
"In the adversarial training stage, we keep all the hyperparamters determined in the pre-training stage unchanged.",4.1.3 Implementation Details,[0],[0]
"The number of candidate negative triples, Ns, is set to 20 in all cases, which is proven to be optimal among the candidate set of {5, 10, 20, 30, 50}.",4.1.3 Implementation Details,[0],[0]
"We train for 5000 epochs, with 100 mini-batches for each epoch.",4.1.3 Implementation Details,[0],[0]
"We also use early stopping in adversarial training by evaluating MRR on the validation set every 100 epochs.
",4.1.3 Implementation Details,[0],[0]
"We use the self-adaptive optimization method Adam (Kingma and Ba, 2015) for all trainings, and always use the recommended default setting α = 0.001, β1 = 0.9, β2 = 0.999, = 10 −8.",4.1.3 Implementation Details,[0],[0]
Results of our experiments as well as baselines are shown in Table 4.,4.2 Results,[0],[0]
"All settings of adversarial training bring a pronounced improvement to the model, which indicates that our method is consistently effective in various cases.",4.2 Results,[0],[0]
"TRANSE performs slightly worse than TRANSD on FB15k-237 and WN18, but better on WN18RR.",4.2 Results,[0],[0]
"Using DISTMULT or COMPLEX as the generator does not affect performance greatly.
",4.2 Results,[0],[0]
"TRANSE and TRANSD enhanced by KBGAN can significantly beat their corresponding baseline implementations, and outperform stronger baselines in some cases.",4.2 Results,[0],[0]
"As a prototypical and proofof-principle experiment, we have never expected state-of-the-art results.",4.2 Results,[0],[0]
"Being simple models pro-
3The KBGAN source code is available at https:// github.com/cai-lw/KBGAN
posed several years ago, TRANSE and TRANSD has their limitations in expressiveness that are unlikely to be fully compensated by better training technique.",4.2 Results,[0],[0]
"In future researches, people may try employing more advanced models into KBGAN, and we believe it has the potential to become stateof-the-art.
",4.2 Results,[0],[0]
"To illustrate our training progress, we plot performances of the discriminator on validation set over epochs, which are displayed in Figure 2.",4.2 Results,[0],[0]
"As all these graphs show, our performances are always in increasing trends, converging to its max-
imum as training proceeds, which indicates that KBGAN is a robust GAN that can converge to good results in various settings, although GANs are wellknown for difficulty in convergence.",4.2 Results,[0],[0]
"Fluctuations in these graphs may seem more prominent than other KGE models, but is considered normal for an adversially trained model.",4.2 Results,[0],[0]
Note that in some cases the curve still tends to rise after 5000 epochs.,4.2 Results,[0],[0]
"We do not have sufficient computation resource to train for more epochs, but we believe that they will also eventually converge.",4.2 Results,[0],[0]
"To demonstrate that our approach does generate better negative samples, we list some examples of them in Table 5, using the KBGAN (TRANSE + DISTMULT) model and the WN18 dataset.",4.3 Case study,[0],[0]
"All hyperparameters are the same as those described in Section 4.1.3.
",4.3 Case study,[0],[0]
"Compared to uniform random negatives which are almost always totally unrelated, the generator generates more semantically related negative samples, which is different from type relatedness we used as example in Section 3.2, but also helps training.",4.3 Case study,[0],[0]
"In the first example, two of the five terms are physically related to the process of distilling liquids.",4.3 Case study,[0],[0]
"In the second example, three of the five entities are geographical objects.",4.3 Case study,[0],[0]
"In the third example, two of the five entities express the concept of “gather”.
",4.3 Case study,[0],[0]
"Because we deliberately limited the strength of generated negatives by using a small Ns as described in Section 3.3, the semantic relation is pretty weak, and there are still many unrelated entities.",4.3 Case study,[0],[0]
"However, empirical results (when selecting the optimal Ns) shows that such situation is more beneficial for training the discriminator than generating even stronger negatives.",4.3 Case study,[0],[0]
We propose a novel adversarial learning method for improving a wide range of knowledge graph embedding models—We designed a generatordiscriminator framework with dual KGE components.,5 Conclusions,[0],[0]
"Unlike random uniform sampling, the generator model generates higher quality negative examples, which allow the discriminator model to learn better.",5 Conclusions,[0],[0]
"To enable backpropagation of error, we introduced a one-step REINFORCE method to seamlessly integrate the two modules.",5 Conclusions,[0],[0]
"Experimentally, we tested the proposed ideas with four commonly used KGE models on three datasets, and the results showed that the adversarial learning framework brought consistent improvements to various KGE models under different settings.",5 Conclusions,[0],[0]
"We introduce KBGAN, an adversarial learning framework to improve the performances of a wide range of existing knowledge graph embedding models.",abstractText,[0],[0]
"Because knowledge graphs typically only contain positive facts, sampling useful negative training examples is a nontrivial task.",abstractText,[0],[0]
"Replacing the head or tail entity of a fact with a uniformly randomly selected entity is a conventional method for generating negative facts, but the majority of the generated negative facts can be easily discriminated from positive facts, and will contribute little towards the training.",abstractText,[0],[0]
"Inspired by generative adversarial networks (GANs), we use one knowledge graph embedding model as a negative sample generator to assist the training of our desired model, which acts as the discriminator in GANs.",abstractText,[0],[0]
"This framework is independent of the concrete form of generator and discriminator, and therefore can utilize a wide variety of knowledge graph embedding models as its building blocks.",abstractText,[0],[0]
"In experiments, we adversarially train two translation-based models, TRANSE and TRANSD, each with assistance from one of the two probability-based models, DISTMULT and COMPLEX.",abstractText,[0],[0]
"We evaluate the performances of KBGAN on the link prediction task, using three knowledge base completion datasets: FB15k-237, WN18 and WN18RR.",abstractText,[0],[0]
Experimental results show that adversarial training substantially improves the performances of target embedding models under various settings.,abstractText,[0],[0]
KBGAN: Adversarial Learning for Knowledge Graph Embeddings,title,[0],[0]
"Inference of parameters in a probabilistic model is an essential ingredient in model-based statistical approaches, both in the frequentist and Bayesian paradigms.",1. Introduction,[0],[0]
"Given a probabilistic model P (y|θ), which is a conditional distribution of observations y given a parameter θ, the aim is to make inference about the parameter θ∗ that generated an observed data y∗.",1. Introduction,[0],[0]
"When the model P (y|θ) admits a conditional density `(y|θ), such an inference can be made on the basis of evaluations of `(y∗|θ); this is the likelihood of y∗ as a function of θ.",1. Introduction,[0],[0]
"However, in modern scientific and engineering problems in which the model P (y|θ) is required to be sophisticated and complex, the likelihood function `(y∗|θ) might no longer be available.",1. Introduction,[0],[0]
"This may be because the density form of P (y|θ) is elusive, or the evaluation of the likelihood `(y∗|θ) is computationally very expensive.",1. Introduction,[0],[0]
"Such situations, in which `(y|θ) (or P (y|θ)) are referred to as intractable likelihood, make the inference problem quite challenging and are commonly found in the literature on
1NEC Corporation 2National Institute of Advanced Industrial Science and Technology 3Max Planck Institute for Intelligent Systems 4The Institute of Statistical Mathematics.",1. Introduction,[0],[0]
"Correspondence to: Takafumi Kajihara <t-kajihara@ct.jp.nec.com>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"population genetics (Pritchard et al., 1999) and dynamical systems (Toni et al., 2009), to name just two.
",1. Introduction,[0],[0]
"Approximate Bayesian Computation (ABC) is a class of computational methods for Bayesian inference with intractable likelihood (Tavaré et al., 1997; Pritchard et al., 1999; Beaumont et al., 2002) that is applicable as long as sampling from the model P (y|θ) is possible.",1. Introduction,[0],[0]
"Given a prior π(θ) on the parameter space, the basic ABC constructs a Monte Carlo approximation to the posterior Py∗(θ) ∝",1. Introduction,[0],[0]
"P (y∗|θ)π(θ) in the following way: i) sample pairs (yi, θi) of pseudo data yi and parameter θi from the joint distribution P (y|θ)π(θ), where i = 1, . . .",1. Introduction,[0],[0]
", n for some n ∈ N, ii) maintain only those parameters θi associated with yi that are “close enough” to the observed data y∗, and iii) regard them as samples from the posterior Py∗(θ).",1. Introduction,[0],[0]
"ABC has been extensively studied in statistics and machine learning; see, e.g., Del Moral et al. (2012); Fukumizu et al. (2013); Meeds and Welling (2014); Park et al. (2016); Mitrovic et al. (2016).
",1. Introduction,[0],[0]
"In this paper, we rather take the frequentist perspective, and deal with the problem of maximum likelihood estimation (MLE) with intractable likelihood.",1. Introduction,[0],[0]
"That is, we consider situations in which one believes that there is a “true” parameter θ∗ that generated the data y∗ and wishes to obtain a point estimate for it.",1. Introduction,[0],[0]
"This problem is also motivated by the following situations encountered in practice: 1) Consider a situation in which the model is computationally expensive (e.g., a state-space model) and one wants to perform prediction based on it.",1. Introduction,[0],[0]
"In this case fully Bayesian prediction would require simulation from each of sampled parameters, which might be quite costly.",1. Introduction,[0],[0]
"If one has a point estimate of the true parameter θ∗, then the computational cost can be drastically reduced.",1. Introduction,[0],[0]
2) Consider a situation in which one only has limited knowledge w.r.t. model parameters.,1. Introduction,[0],[0]
"In this case, it is generally difficult to specify an appropriate prior distribution over the parameter space, and thus the resulting posterior may not be reliable.1 Methods for point estimation with intractable likelihood have been reported in the literature, including the method of simulated-moments (McFadden, 1989), indirect inference (Gourieroux et al.,
1For point estimation, one may think of using the maximum a posterior (MAP) estimate, but it may again be unreliable (as for the posterior distribution itself), if the prior distribution cannot be specified appropriately.
1993), ABC-based MAP estimation (Rubio et al., 2013), noisy ABC-MLE (Dean et al., 2014; Yıldırım et al., 2015), an approach based on Bayesian optimization (Gutmann and Corander, 2016), and data-cloning ABC (Picchini and Anderson, 2017).",1. Introduction,[0],[0]
"We will discuss these existing approaches in Sec. 4.
",1. Introduction,[0],[0]
"Our contribution is in proposing a novel approach to point estimation with intractable likelihood on the basis of kernel mean embedding of distributions (Muandet et al., 2017), a framework for statistical inference using reproducing kernel Hilbert spaces.",1. Introduction,[0],[0]
"Specifically, our approach extends kernel ABC (Fukumizu et al., 2013; Nakagome et al., 2013), a method for ABC using kernel embedding of conditional distributions (Song et al., 2009; 2013), to point estimation with intractable likelihood.",1. Introduction,[0],[0]
"The novelty lies in combining kernel ABC with kernel herding (Chen et al., 2010), a deterministic sampling method similar to quasi-Monte Carlo (Dick et al., 2013), and in applying these two methods iteratively to the same observed data in a recursive way.",1. Introduction,[0],[0]
We term this approach kernel recursive ABC.,1. Introduction,[0],[0]
"A theoretical explanation will be provided for this approach, discussing how such recursion yields a point estimate for the true parameter.",1. Introduction,[0],[0]
"We also discuss that the combination of kernel ABC and kernel herding leads to robustness against misspecification of a prior for the true parameter; this is an advantage over existing methods, and will be demonstrated experimentally.
",1. Introduction,[0],[0]
This paper is organized as follows.,1. Introduction,[0],[0]
We briefly review kernel ABC and kernel herding in Sec. 2 and propose kernel recursive ABC in Sec. 3.,1. Introduction,[0],[0]
We report experimental results of comparisons with existing methods in Sec. 4.,1. Introduction,[0],[0]
"The experiments include parameter estimation for a real-world pedestrian flow simulator (Yamashita et al., 2010), which may be of independent interest as application.",1. Introduction,[0],[0]
"Kernel ABC is an algorithm that executes ABC in a reproducing kernel Hilbert space (RKHS) and produces a reliable solution even in moderately large dimensional problems (Fukumizu et al., 2013; Nakagome et al., 2013).",2.1. Kernel ABC,[0],[0]
"It is based on the framework of kernel mean embeddings, in which all probability measures are represented as elements in an RKHS (see Muandet et al. (2017) for a recent survey of this field).",2.1. Kernel ABC,[0],[0]
"Let Θ be a measurable space, k : Θ × Θ → R be a measurable positive definite kernel, and H be its RKHS.",2.1. Kernel ABC,[0],[0]
"In this framework, any probability measure P on Θ will be represented as a Bochner integral
µP",2.1. Kernel ABC,[0],[0]
":= ∫ Θ k(·, θ)dP (θ) ∈ H, (1)
which is called the kernel mean of P .",2.1. Kernel ABC,[0],[0]
"If the mapping P → µP is injective, in which case µP preserves all the
information in P , the kernel k is referred to as being characteristic (Fukumizu et al., 2008).",2.1. Kernel ABC,[0],[0]
"Characteristic kernels on Θ = Rd, for example, include Gaussian and Matérn kernels (Sriperumbudur et al., 2010).
",2.1. Kernel ABC,[0],[0]
Let Y be another measurable space and assume that an observed data y∗ ∈ Y is provided.,2.1. Kernel ABC,[0],[0]
(y∗ is often a set of sample points.),2.1. Kernel ABC,[0],[0]
"Given a conditional probability P (y|θ) and a prior π(θ), we wish to obtain the posterior distribution Py∗(θ) ∝",2.1. Kernel ABC,[0],[0]
P,2.1. Kernel ABC,[0],[0]
"(y∗|θ)π(θ).2 As in a standard ABC, kernel ABC achieves this by first generating pairs of pseudo data and parameter {(yi, θi)}ni=1 from the joint distribution P (y|θ)π(θ).",2.1. Kernel ABC,[0],[0]
"It then estimates the kernel mean of the posterior Py∗ , which we denote by
µPy∗ := ∫",2.1. Kernel ABC,[0],[0]
"Θ k(·, θ)dPy∗(θ) ∈ H.
",2.1. Kernel ABC,[0],[0]
"Given a measurable positive definite kernel kY on Y , the estimator is given by
µ̂Py∗ = n∑ i=1 wik(·, θi) ∈ H, (2)
",2.1. Kernel ABC,[0],[0]
"w := (w1, . . .",2.1. Kernel ABC,[0],[0]
", wn) T := (G+ nδI)−1k(y∗), (3)
where k(y∗)",2.1. Kernel ABC,[0],[0]
":= (kY(y1, y∗), . . .",2.1. Kernel ABC,[0],[0]
", kY(yn, y∗))T ∈",2.1. Kernel ABC,[0],[0]
"Rn, G := (kY(yi, yj)) n",2.1. Kernel ABC,[0],[0]
"i,j=1 ∈ Rn×n, δ > 0 is a regularization constant, and I ∈ Rn×n is an identity matrix.",2.1. Kernel ABC,[0],[0]
"The estimator (2) is essentially an (RKHS-valued) kernel ridge regression (Grünewälder et al., 2012):",2.1. Kernel ABC,[0],[0]
"Given training data {(yi, k(·, θi))}ni=1, the weights (3) provide an estimator for the mapping y∗ ⇒",2.1. Kernel ABC,[0],[0]
"k(·, θ∗).",2.1. Kernel ABC,[0],[0]
"For consistency and convergence results, which require δ → 0 as n→∞, we re refer to Fukumizu et al. (2013) and Muandet et al. (2017).",2.1. Kernel ABC,[0],[0]
"Kernel herding is a deterministic sampling technique based on the kernel mean representation of a distribution (Chen et al., 2010) and can be seen as a greedy approach to quasiMonte Carlo (Dick et al., 2013).",2.2. Kernel herding,[0],[0]
"Consider sampling from P using the kernel mean µP (1), and assume that one is able to evaluate function values of µP .",2.2. Kernel herding,[0],[0]
"Kernel herding greedily obtains sample points θ1, θ2, . . .",2.2. Kernel herding,[0],[0]
", θn by iterating the following steps: Defining h0 := µP ,
θt+1 = argmax θ∈Θ ht(θ), (4) ht+1 = ht + µP",2.2. Kernel herding,[0],[0]
"− k(·, θt+1) ∈ H, (5)
where t = 0, . . .",2.2. Kernel herding,[0],[0]
", n− 1.",2.2. Kernel herding,[0],[0]
"Chen et al. (2010) has shown that, if there exists a constant C > 0",2.2. Kernel herding,[0],[0]
"such that k(θ, θ) = C for all θ ∈ Θ, this procedure will be identical to the greedy
2There is abuse of notation here, as P (y|θ) does not denote a conditional density but a conditional distribution.
",2.2. Kernel herding,[0],[0]
Algorithm 1 Kernel Recursive ABC Input:,2.2. Kernel herding,[0],[0]
"A prior distribution π, an observed data y∗, a data generator P (y|θ), the number Niter of iterations, the number n of simulated pairs, a kernel k on Θ, a kernel kY on Y , and a regularization constant δ > 0",2.2. Kernel herding,[0],[0]
"Output: A point estimate θ́. for N = 1, ..., Niter do
if N = 1 then for i = 1, ..., n do
Sample θ1,i ∼ π(θ) i.i.d. end for
end if for i = 1, ..., n do
Generate yN,i ∼ P (·|θN,i) end for Compute G := (kY(yN,i, yN,i))ni,j=1 ∈ Rn×n and k(y) := (kY(yN,i, y
∗))ni=1 ∈",2.2. Kernel herding,[0],[0]
Rn.,2.2. Kernel herding,[0],[0]
"Calculate w = (w1, . . .",2.2. Kernel herding,[0],[0]
", wn)T ∈",2.2. Kernel herding,[0],[0]
Rn by Eq.(3).,2.2. Kernel herding,[0],[0]
"Construct a kernel mean estimate of the powered posterior µ̂PN := ∑n i=1 wik(·, θN,i)",2.2. Kernel herding,[0],[0]
"Sample {θN+1,t}nt=1 by performing kernel herding Eqs.(4) (5) with µP := µ̂PN .
",2.2. Kernel herding,[0],[0]
"end for Obtain a point estimate θ́ := θNiter+1,1
minimization of the maximum mean discrepancy (MMD) (Gretton et al., 2007; 2012):
n",2.2. Kernel herding,[0],[0]
:= ∥∥∥∥∥µP,2.2. Kernel herding,[0],[0]
"− 1n n∑ t=1 k(·, θt) ∥∥∥∥∥",2.2. Kernel herding,[0],[0]
"H , (6)
where ‖ · ‖H denotes the norm of H. That is, the points θ1, . . .",2.2. Kernel herding,[0],[0]
", θn are obtained so as to (greedily) minimize the distance εn between µP and the empirical kernel mean 1 n ∑n t=1",2.2. Kernel herding,[0],[0]
k,2.2. Kernel herding,[0],[0]
"(·, θt).",2.2. Kernel herding,[0],[0]
"The generated points θ1, . .",2.2. Kernel herding,[0],[0]
.,2.2. Kernel herding,[0],[0]
", θn are also called super-samples because they are more informative than those from random sampling; this is in the sense that error decreases at the rate n = O(n−1) if the RKHS is finite-dimensional (Bach et al., 2012), which is faster than the rate n = O(n−1/2) of random sampling (Smola et al., 2007).",2.2. Kernel herding,[0],[0]
"Convergence guarantees are also provided even when the optimization problem in (4) is solved approximately (Lacoste-Julien et al., 2015) and when the kernel mean µP is replaced by an empirical estimate µ̂P of the form (2) (Kanagawa et al., 2016b).",2.2. Kernel herding,[0],[0]
Note that the decay n → 0 of the error (6) as n→∞ implies the convergence of expectation 1 n,2.2. Kernel herding,[0],[0]
"∑n t=1 f(θt) → ∫ f(x)dP (x) for all functions f in the RKHSH and for functions f that can be approximated well by the RKHS functions (Kanagawa et al., 2016a).",2.2. Kernel herding,[0],[0]
"Our idea is to recursively apply Bayes’ rule to the same
observed data y∗ by using the posterior obtained in one iteration as a prior for the next iteration.",3. Proposed method,[0],[0]
"For this, let `(θ) := `(y∗|θ) be a likelihood function and π(θ) be a prior density, where θ ∈ Θ, with Θ being a measurable space.",3. Proposed method,[0],[0]
Consider the population setting in which no estimation procedure is involved.,3. Proposed method,[0],[0]
"After theN -th recursion, the posterior distribution becomes
pN (θ) :",3. Proposed method,[0],[0]
"= C −1 N π(θ)(`(θ)) N , (7)
where CN := ∫
Θ π(θ) (`(θ))
",3. Proposed method,[0],[0]
"N dθ is a normalization con-
stant.",3. Proposed method,[0],[0]
We refer here to this as a powered posterior.,3. Proposed method,[0],[0]
"If ` has a unique global maximum at θ∞ ∈ Θ and the support of π contains θ∞, one can show that pN converges weakly to the Dirac distribution δθ∞ at θ∞ under certain conditions (Lele et al., 2010).",3. Proposed method,[0],[0]
"In other words, the effect of the prior diminishes as the recursion proceeds, and the powered posterior degenerates at the maximum likelihood point, providing a method for MLE.",3. Proposed method,[0],[0]
"A similar idea has been discussed by Doucet et al. (2002); Lele et al. (2010) in the context of data augmentation and data cloning, in which one replicates the observed data y∗ multiple times and applies Bayes’ rule once; our approach is different, as we employ recursive applications of Bayes’ rule multiple times (this turns out to be beneficial in our approach, as is shown below).
",3. Proposed method,[0],[0]
"Based on the above idea, we propose to recursively applying kernel ABC (Sec. 2.1) and kernel herding (Sec. 2.2).",3. Proposed method,[0],[0]
"Specifically, the proposed method (Algorithm 1) iterates the following procedures: (i) At the N -th iteration, the kernel mean µPN := ∫ k(·, θ)pN (θ)dθ of the powered posterior (7) is estimated using simulated pairs {(θN,i, yN,i)}ni=1 via kernel ABC; (ii) from the estimate µ̂PN of µPN given in (i), new parameters {θN+1,i}ni=1 are generated via kernel herding, and new pseudo-data {yN+1,i}ni=1 are generated from the simulator P (yN+1,i|θN+1,i) in the N + 1-th iteration.",3. Proposed method,[0],[0]
"After iterating these procedures Niter times, point estimate θ́ for the true parameter is given as the first point θNiter+1,1 from kernel herding at the last iteration.
",3. Proposed method,[0],[0]
Auto-correction mechanism.,3. Proposed method,[0],[0]
"An interesting feature of the proposed approach is that, as experimentally indicated in Sec. 4.2, it is equipped with an auto-correction mechanism: If the parameters θN,1, . . .",3. Proposed method,[0],[0]
", θN,n",3. Proposed method,[0],[0]
at theN -th,3. Proposed method,[0],[0]
iteration,3. Proposed method,[0],[0]
"are far apart from the true parameter θ∗, then Algorithm 1 searches for the parameters θN+1,1, . . .",3. Proposed method,[0],[0]
", θN+1,n at the next iteration, so as to explore the parameter space Θ.",3. Proposed method,[0],[0]
"For instance, if the prior π(θ) is misspecified, meaning that the true parameter θ∗ is not contained in the support of π(θ), then the initial parameters θ1,1, . . .",3. Proposed method,[0],[0]
", θ1,n from π(θ) are likely to be apart from the true parameter θ∗.",3. Proposed method,[0],[0]
"The auto-correction mechanism makes the proposed method robust to such misspecification and makes it suitable for use in situations in which one lacks appropriate prior knowledge about the true parameter.
",3. Proposed method,[0],[0]
"To explain how this works, let us explicitly write down the procedure (4) (5) of kernel herding as used in Algorithm 1.
",3. Proposed method,[0],[0]
"Given that t (< n) points θN+1,1, . . .",3. Proposed method,[0],[0]
", θN+1,t have already been generated, the next point θN+1,t+1 is obtained as
θN+1,t+1 := (8)
argmax θ∈Θ n∑ i=1",3. Proposed method,[0],[0]
"wik(θ, θN,i)− 1 t+ 1",3. Proposed method,[0],[0]
t∑ i=1,3. Proposed method,[0],[0]
"k(θ, θN+1,i),
where the weights w1, . . .",3. Proposed method,[0],[0]
", wn are given as (3).",3. Proposed method,[0],[0]
"Assume that all the simulated parameters θN,1, . . .",3. Proposed method,[0],[0]
", θN,n at the N -th iteration are far apart from the true parameter θ∗:",3. Proposed method,[0],[0]
"If N = 1, these are the parameters sampled from the prior π(θ).",3. Proposed method,[0],[0]
"Then it is likely the resulting simulated data yN,1, . . .",3. Proposed method,[0],[0]
", yN,n are dissimilar to the observed data y∗.",3. Proposed method,[0],[0]
"In this case, each component of the vector k(y) := (kY(yN,i, y∗))ni=1 ∈",3. Proposed method,[0],[0]
"Rn becomes nearly 0, since kY(yN,i, y∗) quantifies the similarity between y∗ and yN,i. As a result, each of the weights w1, . .",3. Proposed method,[0],[0]
.,3. Proposed method,[0],[0]
", wn given by kernel ABC (3) also become nearly 0, and thus the first term on the right side in (8) will be ignorable.",3. Proposed method,[0],[0]
"The point θN+1,t+1 is then obtained so as to roughly maximize the second term − 1t+1 ∑t i=1",3. Proposed method,[0],[0]
"k(θN+1,t+1, θN+1,i), or, equivalently, so as
to minimize ∑t i=1",3. Proposed method,[0],[0]
"k(θN+1,t+1, θN+1,i).",3. Proposed method,[0],[0]
"Since the kernel k(θN+1,t+1, θN+1,i) measures the similarity between θN+1,t+1 and θN+1,i, the new point θN+1,t+1 is located apart from the points θN+1,1, . . .",3. Proposed method,[0],[0]
", θN+1,t generated so far.",3. Proposed method,[0],[0]
"In this way, the parameters θN+1,1, . . .",3. Proposed method,[0],[0]
", θN+1,n at theN+1th iteration are made to explore the parameter space Θ if parameters θN,1, . . .",3. Proposed method,[0],[0]
", θN,n at the N -th iteration are far apart from the true parameter θ∗.",3. Proposed method,[0],[0]
We provide here a theoretical basis for the proposed recursive approach.,3.1. Theoretical analysis,[0],[0]
"Since the consistency of kernel ABC and kernel herding have already been established in the literature (Fukumizu et al., 2013; Bach et al., 2012), we focus on convergence analysis in the population setting, that is, convergence analysis for the kernel mean of the powered posterior (7) and for the resulting point estimate.",3.1. Theoretical analysis,[0],[0]
We nevertheless note that convergence analysis of the overall procedure of Algorithm 1 remains an important topic for future research.,3.1. Theoretical analysis,[0],[0]
"All the proofs can be found in the Supplementary Materials.
",3.1. Theoretical analysis,[0],[0]
"Below, we let Θ be a Borel measurable set in Rd.",3.1. Theoretical analysis,[0],[0]
"Denote by PN the probability measure induced by the powered posterior density pN (7), and let µPN := ∫ k(·, θ)dPN (θ) ∈ H be its kernel mean, where k is a kernel on Θ and H is its RKHS.",3.1. Theoretical analysis,[0],[0]
We require the following assumption for the likelihood function ` and the prior π for theoretical analysis.,3.1. Theoretical analysis,[0],[0]
Assumption 1.,3.1. Theoretical analysis,[0],[0]
"(i) ` has a unique global maximum at θ∞ ∈ Θ, and π(θ∞) > 0; (ii) π is continuous at θ∞, ` has continuous second derivatives in the neighborhood of θ∞, and the Hessian of ` at θ∞ is strictly negative-definite.
",3.1. Theoretical analysis,[0],[0]
"Our first result below shows that, under Assumption 1, the
powered posterior PN (7) converges to the Dirac distribution δθ∞ in the RKHSH as N →∞; this provides a theoretical basis for recursively applying the kernel ABC.
",3.1. Theoretical analysis,[0],[0]
Proposition 1.,3.1. Theoretical analysis,[0],[0]
Let Θ ⊂ Rd be a Borel measurable set and k : Θ × Θ → R be a continuous bounded kernel.,3.1. Theoretical analysis,[0],[0]
"Under Assumption 1, we have limN→∞ ‖µPN",3.1. Theoretical analysis,[0],[0]
"− k(·, θ∞)‖H = 0.
Proposition 2 below provides a justification for the use of the first point of kernel herding (here this is θN",3.1. Theoretical analysis,[0],[0]
:= argminθ̃∈Θ ‖µPN,3.1. Theoretical analysis,[0],[0]
"− k(·, θ̃)‖H; see Sec. 2.2) as a point estimate of θ∞. To this end, we introduce the following assumption on the kernel, which is satisfied by, for example, Gaussian and Matérn kernels.
",3.1. Theoretical analysis,[0],[0]
Assumption 2.,3.1. Theoretical analysis,[0],[0]
(i),3.1. Theoretical analysis,[0],[0]
"There exists a constant C > 0 such that k(θ, θ) = C for all θ ∈ Θ. (ii)",3.1. Theoretical analysis,[0],[0]
"It holds that k(θ, θ′) < C for all θ, θ′ ∈ Θ with θ 6= θ′. Proposition 2.",3.1. Theoretical analysis,[0],[0]
"Let Θ ⊂ Rd be a compact set, and k : Θ × Θ → R be a continuous, bounded kernel.",3.1. Theoretical analysis,[0],[0]
Let θN,3.1. Theoretical analysis,[0],[0]
:,3.1. Theoretical analysis,[0],[0]
"= argminθ̃∈Θ
∥∥∥µPN − k(·, θ̃)∥∥∥H. If Assumptions 1 and 2 hold, then we have θN → θ∞ as N →∞.
We make a few remarks regarding Assumption 1.",3.1. Theoretical analysis,[0],[0]
"The assumption that ` has a unique global maximum is not satisfied if the model is singular, an example being mixture models: In this case there are multiple global maximums.",3.1. Theoretical analysis,[0],[0]
"However, our experiment in Sec. 4.5 shows that even for mixture models, the proposed method works reasonably well.",3.1. Theoretical analysis,[0],[0]
"This suggests that, in an empirical setting, a point estimate may converge to one of the global maximums.",3.1. Theoretical analysis,[0],[0]
"The assumption π(θ∞) > 0 will also not be satisfied if the support π does not contain θ∞, but the proposed method performs well even in this case (as shown in 4.2), possibly thanks to the auto-correction mechanism explained above.",3.1. Theoretical analysis,[0],[0]
We reserve further analysis of these properties for future work.,3.1. Theoretical analysis,[0],[0]
We have conducted a variety of experiments comparing the proposed method with existing approaches.,4. Experiments,[0],[0]
"We begin with a quick review of these approaches (Sec. 4.1), and report experimental results on point estimation with a misspecified prior (Sec. 4.2), population dynamics of the blowfly (Sec. 4.3), alpha stable distributions (Sec. 4.4), Gaussian mixture models with redundant components (Sec. 4.5), and a real-world pedestrian simulator (Sec. 4.6).",4. Experiments,[0],[0]
"K2-ABC (Park et al., 2016) is an ABC method that represents the empirical distributions of simulated and test observations as kernel means in an RKHS.",4.1. Existing approaches and experimental settings,[0],[0]
"For each of simulated parameters, the associated weight is calculated by using the RKHS distance between the kernel means (i.e., MMD), and the resulting weighted sample is treated as a posterior
distribution.",4.1. Existing approaches and experimental settings,[0],[0]
"Adaptive SMC-ABC (Del Moral et al., 2012) is a rejection-based approach based on sequential Monte Carlo, which sequentially updates the tolerance level and the associated proposal distribution in an adaptive manner.",4.1. Existing approaches and experimental settings,[0],[0]
This method is a state-of-the-art ABC approach.,4.1. Existing approaches and experimental settings,[0],[0]
"The approach by Gutmann and Corander (2016), which we refer to as Bayesian Optimization for simplicity, is a method for MLE with intractable likelihood based on Bayesian optimization (Brochu et al., 2010).",4.1. Existing approaches and experimental settings,[0],[0]
This method optimizes the parameters in a intractable model so as to minimize the discrepancy between the simulated and test observations.,4.1. Existing approaches and experimental settings,[0],[0]
"Note that comparison with this method in terms of computation time may not make sense (although we report them for purposes of completeness), as we used publicly available code3 for implementation.",4.1. Existing approaches and experimental settings,[0],[0]
"The method of simulated moments (MSM) (McFadden, 1989) optimizes the parameter in the model so that the resulting moments of simulated data match those of observe data.",4.1. Existing approaches and experimental settings,[0],[0]
"MSM may be seen a special case of indirect inference (Gourieroux et al., 1993), an approach studied in econometrics.4 Data-cloning ABC (ABC-DC) (Picchini and Anderson, 2017) is an approach combining ABC-MCMC (Marjoram et al., 2003) and Data Cloning (Lele et al., 2010), replicating observed data multiple times to achieve MLE with intractable likelihood.
",4.1. Existing approaches and experimental settings,[0],[0]
Experimental settings.,4.1. Existing approaches and experimental settings,[0],[0]
"Unless otherwise specified, the following settings were applied in the experiments.",4.1. Existing approaches and experimental settings,[0],[0]
"For all the methods that employed kernels, we used Gaussian kernels.",4.1. Existing approaches and experimental settings,[0],[0]
"The discrepancy between the simulated and observed data was measured by the energy distance (Székely and Rizzo, 2013), which is a standard metric for distributions in statistics and can be computed only from pairwise Euclidean distances between data points.",4.1. Existing approaches and experimental settings,[0],[0]
"Since the usual quadratic time estimator was too costly, we used a linear time estimator for computing the energy distance (see the Supplementary Materials for details).
",4.1. Existing approaches and experimental settings,[0],[0]
"For each method, unless otherwise specified, we determined the hyper-parameters on the basis of the cross-validationlike approach described in Park et al. (2016, Sec. 4).",4.1. Existing approaches and experimental settings,[0],[0]
"That is, to evaluate one configuration of hyper-parameters, we first used 75% of the observed data for point estimation and then computed the discrepancy between the rest of the observed data and the ones simulated from point estimates; after applying this procedure to all candidate configurations, the one with the lowest discrepancy was finally selected.",4.1. Existing approaches and experimental settings,[0],[0]
"The bandwidth of a Gaussian kernel was selected from candidate values, each of which is the median (of pairwise distances) multiplied by logarithmically equally spaced values between 2−4 and 24 (Takeuchi et al., 2006, Sec. 5.1.1).",4.1. Existing approaches and experimental settings,[0],[0]
"Regularization constants for the proposed method and kernel ABC, as well as the soft threshold for K2-ABC, were selected
3https://sheffieldml.github.io/GPyOpt/ 4MSM is a special case of indirect inference because the mo-
ments can be regarded as the parameters of an auxiliary model.
from logarithmically spaced values between 10−4 and 1.",4.1. Existing approaches and experimental settings,[0],[0]
"To compute MMD for K2-ABC, a linear time estimator (Gretton et al., 2012, Sec. 6) was used to reduce computational time, as the usual quadratic time estimator was too costly.",4.1. Existing approaches and experimental settings,[0],[0]
"For Adaptive SMC-ABC, the initial tolerance level was set as the median of pairwise distances between the observed and simulated data.",4.1. Existing approaches and experimental settings,[0],[0]
"For Bayesian Optimization, we used Expected Improvement as an acquisition function, and all the hyper-parameters were marginalized out following the approach of Snoek et al. (2012, Sec. 3.2).",4.1. Existing approaches and experimental settings,[0],[0]
"For MSM, the number of moments were selected from a range up to 30 by the cross-validation like approach.",4.1. Existing approaches and experimental settings,[0],[0]
"For ABC-DC, we employed, in particular, dynamic ABC-DC, which automatically adjusts its associated parameters.",4.1. Existing approaches and experimental settings,[0],[0]
"To obtain point estimates with kernel ABC and K2-ABC, we computed the means of the resulting posterior distributions.",4.1. Existing approaches and experimental settings,[0],[0]
"For Adaptive SMC-ABC, point estimates were obtained as posterior means as well as MAP estimates by applying the mean shift algorithm to posterior weighted samples (Fukunaga and Hostetler, 1975), the latter essentially being an approach suggested by Rubio et al. (2013).
",4.1. Existing approaches and experimental settings,[0],[0]
"The following abbreviations may be used for the sake of simplicity; kernel recursive ABC is referred to as KR-ABC, kernel ABC as K-ABC, adaptive SMC-ABC as SMC-ABC, Bayesian Optimization as BO, and Dynamic ABC-DC as ABC-DC.",4.1. Existing approaches and experimental settings,[0],[0]
"For our method, we also report results based on a half number of iterations, which we call KR-ABC (less).",4.1. Existing approaches and experimental settings,[0],[0]
"As a proof of concept regarding the auto-correction mechanism of the proposed method described in Sec.3, we have performed an experiment for when the prior distribution is severely misspecified (see the Supplementary Materials for an illustration).",4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
"The task is to estimate the mean vector of a 20-dimensional Gaussian distribution Normal(µ,Σ), where the true mean vector is µ := (10, 50, 90, 130, 180, 280, 390, 430, 520, 630, 1010, 1050, 1090, 1130, 1180, 1280, 1390, 1430, 1520, 1630)T ∈ R20.",4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
The covariance matrix Σ ∈ R20×20 is assumed to be known and is a diagonal matrix with all diagonal elements being 40.,4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
Test data y∗ consisted of 100 i.i.d.,4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
observations from this Gaussian distribution.,4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
"As a prior for the mean vector µ, we used the uniform distribution on [9× 106, 107]20, which is extremely misspecified.",4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
"For Bayesian optimization, the space to be explored was set as [0, 107]20.
",4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
"In this experiment, each pseudo data was made from 100 observations simulated with one parameter configuration.",4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
K2-ABC and K-ABC used 3000 pairs of a parameter and pseudo-data.,4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
"For the proposed method and SMC-ABC, we generated 100 pairs of a parameter and pseudo-data for the initial iteration, and then the iterations were repeated 30
times, resulting in a total of 3000 simulations.",4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
"For the proposed method, the bandwidth of the kernel kY on observed data was recomputed for each iteration, using the median heuristic.",4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
"For SMC-ABC, the parameter α ∈ (0, 1), which controls the trade-off between the speed of convergence and the accuracy of posterior approximation, was set to be 0.3, as we found this value to be the best in terms of the trade-off.
",4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
"For each method, we ran 30 independent trials, and the results in averages and standard deviations are shown in Table 1, where the parameter error is the mean (over 20 dimensions) of the absolute difference between the estimated and the true parameter values divided by the true value, and the data error is the energy distance between the true data and pseudo data simulated with the estimated parameter.",4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
"Surprisingly, the proposed method successfully approached the true parameter even when the prior was severely misspecified.",4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
"As discussed in Sec 3 and demonstrated in the Supplementary Materials, this would appear to be because of the use of kernel herding, which automatically widens the space to explore when simulated data is far apart from test data.",4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
"As expected, other methods were unable to approach the true parameter.",4.2. Multivariate Gaussian distribution with a severely misspecified prior,[0],[0]
"Following Park et al. (2016), we performed an experiment on parameter estimation with a dynamical system of blowfly populations (Wood, 2010), which is defined as
Nt+1 = PNt−τ exp (−Nt−τ/N0) et + Nt exp(−δ t),
where t = 1, . . .",4.3. Ecological dynamic systems: blowfly,[0],[0]
", T are time indices, Nt is the population at time t, et ∼ Gam( 1σ2pσ 2 p) and t ∼ Gam( 1σ2d , σ 2 d) are independent Gamma-distributed noise, and θ := (P ∈ N, N0 ∈ N,",4.3. Ecological dynamic systems: blowfly,[0],[0]
"σd ∈ R+, σp ∈",4.3. Ecological dynamic systems: blowfly,[0],[0]
"R+, τ",4.3. Ecological dynamic systems: blowfly,[0],[0]
"∈ N, δ ∈",4.3. Ecological dynamic systems: blowfly,[0],[0]
R+) are the parameters of the system.,4.3. Ecological dynamic systems: blowfly,[0],[0]
"The task is to estimate θ from observed values of N1, . . .",4.3. Ecological dynamic systems: blowfly,[0],[0]
", NT .",4.3. Ecological dynamic systems: blowfly,[0],[0]
"We set the true parameters as θ = (29, 260, 0.6, 0.3, 7, 0.2), and the time-length T for both the observed and pseudo data as T = 1000.",4.3. Ecological dynamic systems: blowfly,[0],[0]
"Following Park et al. (2016, Sec. 4), for each parameter we defined a Gaussian prior on its logarithm (see the Supplementary Materials for a definition).",4.3. Ecological dynamic systems: blowfly,[0],[0]
"In this experiment, for all methods we converted the observed and pseudo-data into histograms
with 1000 bins (i.e., we treated each data as a 1000 dim.",4.3. Ecological dynamic systems: blowfly,[0],[0]
"vector), as this produced better results.",4.3. Ecological dynamic systems: blowfly,[0],[0]
K2-ABC and K-ABC used 1300 pairs of a parameter and a pseudo-data item.,4.3. Ecological dynamic systems: blowfly,[0],[0]
"For the proposed method and SMC-ABC, we generated 100 pairs of a parameter and pseudo-data for the initial iteration, and the iterations were then repeated 13 times, resulting in total 1300 simulations.",4.3. Ecological dynamic systems: blowfly,[0],[0]
"For SMC-ABC, we set the parameter α ∈ (0, 1) to be 0.3, as in Sec. 4.2.
",4.3. Ecological dynamic systems: blowfly,[0],[0]
"For each method we performed 30 independent trials, and the results are summarized in Table 2.",4.3. Ecological dynamic systems: blowfly,[0],[0]
"The proposed method performed the best, even when the number of simulations was halved (i.e., KR-ABC (less)).",4.3. Ecological dynamic systems: blowfly,[0],[0]
"In addition to the competitive methods described earlier, we performed a comparison with the method called noisy ABC-MLE (Yıldırım et al., 2015).",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"This method assumes that sampling from the intractable model can be realized by deterministic mapping applied to a simple random variable, and that the gradient of the deterministic mapping is available.",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"This method can, then, only be applied to a limited class of generative models, though for such models it can perform well.",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"Although the main scope of this paper is on simulation models in which such gradient information is unavailable, we performed this experiment in order to see how the proposed method compared with this method without relying on the gradient information.
",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"We also considered parameter estimation with multivariate elliptically contoured alpha stable distributions (Nolan, 2013), which subsume heavy-tailed and skewed distributions and are popular for modeling financial data.",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"This family of distributions in general does not admit closedform expressions for density functions, which means they are “intractable” in the sense that the standard procedure for parameter estimation cannot be employed.",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"However, sampling of a random vector X ∈ Rd from this family is possible in the following way:
X := A1/2G + δ ∈ Rd, G ∼ Normal(0, Q),",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"A := τθ(U1, U2) ∈ R,
U1 ∼ Unif(−π/2, π/2), U2 ∼ Exp(1),
where Q ∈ Rd×d is positive definite, δ ∈ Rd, θ := (α, β, µ, σ) ∈ (0, 2] ×",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"[−1, 1] × R ×",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"[0,∞), τθ is a deterministic mapping whose concrete form is described in the Supplementary Materials, and Unif and Exp denote uniform and exponential distributions, respectively.
",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"We dealt with estimation of α := 1.3 and Q, while fixing the other parameters as δ := 0, β := 1, µ := 0, and σ",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
:= 1.,4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
We restricted Q to be a positive definite matrix such that all diagonal elements are the same and so are the off-diagonal elements.,4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
We defined true Q to be a matrix whose diagonal elements are 1.0 and off-diagonals are 0.2.,4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"Therefore the task was to estimate these three values (i.e., 1.3 for α, and 1.0 and 0.2 for Q).",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"We used Unif[0, 2] as a prior for α, and Unif[0, 5] as a prior for each of the diagonal and offdiagonal values of Q.
Figure 1 shows results for the averages of mean square errors in parameter estimation over 30 independent trials, with variation in the dimensionality d from 2 to 16.",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"For each method we sampled a total of 1400 pairs of a parameter and a pseudo-data item, and for iterative methods we used 100 pairs in each iteration.",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
Each pseudo-data (and observed-data) was made up of 1000 points.,4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"The noisy ABC-MLE exploited the gradient information in τθ, while the other methods did not.",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
The proposed method was competitive with BO and outperformed the other methods with the exception of the noisy ABC-MLE.,4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"Although the noisy ABC-MLE was accurate for lower-dimensionality (as expected), it exhibited a steep increase in errors for higher dimensionality.",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
"In contrast, the performance degradation of the proposed method was mild for higher dimensionality.",4.4. Multivariate elliptically contoured alpha stable distribution,[0],[0]
We consider here a parametric model in which there exist redundant parameters for expressing given data.,4.5. Gaussian mixture with redundant components,[0],[0]
"We are interested in whether point estimation with the proposed method results in elimination of the redundant parameters
when applied to such a model.",4.5. Gaussian mixture with redundant components,[0],[0]
"This was motivated by Yamazaki and Kaji (2013), who argued that, for mixture models, the use of a Dirichlet prior with a sufficiently small concentration parameter leads to elimination of unnecessary components.",4.5. Gaussian mixture with redundant components,[0],[0]
"We therefore focus on mixture models with redundant components.
",4.5. Gaussian mixture with redundant components,[0],[0]
"Specifically, we considered Gaussian mixture models.",4.5. Gaussian mixture with redundant components,[0],[0]
"We defined the true model as a two-component Gaussian mixture ∑2 i=1 φiNormal(µi, 20) of equal variances.",4.5. Gaussian mixture with redundant components,[0],[0]
"The task was to estimate the mixture coefficients (φ1, φ2, ) := (0.7, 0.3) and the associate means (µ1, µ2) := (110, 70), provided 3000 i.i.d. sample points from the model as observed data y∗. We employed an over-parametrized model for point estimation (i.e., no method used the knowledge that the truth consisted of 2 components), which is a fourcomponent Gaussian mixture ∑4 i=1 φiNormal(µi, 20).",4.5. Gaussian mixture with redundant components,[0],[0]
"We used a 4-dimensional Dirichlet distribution with equal concentration parameters 0.01 as a prior for the coefficients (φ1, . . .",4.5. Gaussian mixture with redundant components,[0],[0]
", φ4), and Normal(0, 100) as a prior for each of µ1, . . .",4.5. Gaussian mixture with redundant components,[0],[0]
", µ4.
",4.5. Gaussian mixture with redundant components,[0],[0]
"For each method, we generated a total of 1000 pairs of a parameter and pseudo-data, and for iterative methods, we made use of 100 pairs in each iteration, resulting in 10 iterations.",4.5. Gaussian mixture with redundant components,[0],[0]
Each pseudo-data consisted of 3000 simulated observations.,4.5. Gaussian mixture with redundant components,[0],[0]
"For all the methods, we converted each data item into a histogram of 300 bins and treated it as a 300 dim.",4.5. Gaussian mixture with redundant components,[0],[0]
vector since this resulted in better performances.,4.5. Gaussian mixture with redundant components,[0],[0]
"We set the parameter α ∈ (0, 1) of SMC-ABC to be 0.2, as this performed well in this experiment.
",4.5. Gaussian mixture with redundant components,[0],[0]
"We ran each algorithm 30 times, and the resulting average errors and standard deviations are shown in Table 3, where the φ error and µ error denote the errors for the coefficients and the means, respectively, as measured in terms of Euclidean distance.",4.5. Gaussian mixture with redundant components,[0],[0]
"More precisely, since any permutation of component labels will result in the same model, we first sorted the estimated parameters {(φi, µi)} so that φ1 ≥ · · · ≥ φ4, and we then measured the errors w.r.t.",4.5. Gaussian mixture with redundant components,[0],[0]
"the ground truth φ := (0.7, 0.3, 0, 0) and µ := (110, 70).",4.5. Gaussian mixture with redundant components,[0],[0]
"For the µ error, we computed the errors only for the estimated means µ1, µ2 associated with the two largest coefficients since there was no ground truth for the redundant components µ3, µ4.",4.5. Gaussian mixture with redundant components,[0],[0]
"Results show that the proposed KR-ABC performed best, indicating that the dominant components were successfully estimated.",4.5. Gaussian mixture with redundant components,[0],[0]
"Our final experiment was parameter estimation with CrowdWalk, a publicly available real-world simulator5 for the movements of pedestrians in a commercial district (Yamashita et al., 2010).",4.6. Real-world pedestrian simulator,[0],[0]
"It has been used to gain insights into pedestrian behavior at a variety of events and occurrences, such as fireworks festivals and evacuations after earthquakes.",4.6. Real-world pedestrian simulator,[0],[0]
"As this simulator is complicated and also computationally expensive, its likelihood function is intractable.
",4.6. Real-world pedestrian simulator,[0],[0]
"Using CrowdWalk, we simulated the movements of pedestrians in Ginza, a commercial district in Tokyo (see Supplementary Materials for an illustration).",4.6. Real-world pedestrian simulator,[0],[0]
"Specifically, we modeled pedestrians as a mixture of multiple groups, each of which has the following 6 parameters (below i denotes the index of a group): (1) θ(N)i ∈ N: the number of pedestrians in the group; (2) θ(T )",4.6. Real-world pedestrian simulator,[0],[0]
i ∈,4.6. Real-world pedestrian simulator,[0],[0]
R+:,4.6. Real-world pedestrian simulator,[0],[0]
"the time when the group starts to move; (3) θ(S)i ∈ R2: the starting location of the group (e.g., stations); (4) θ(G)i ∈ R2: the goal location of the group; (5) θ(P )",4.6. Real-world pedestrian simulator,[0],[0]
"i ∈ R2: the intermediate location(s) that the pedestrians in the group visit (e.g., stores); and (6) θ
(R)",4.6. Real-world pedestrian simulator,[0],[0]
i ∈,4.6. Real-world pedestrian simulator,[0],[0]
"R+: the time duration(s) of the pedestrians’ visit(s)
at the intermediate location(s).
",4.6. Real-world pedestrian simulator,[0],[0]
"In this experiment, we focused on estimation of the first two parameters θ(N)i , θ (T )",4.6. Real-world pedestrian simulator,[0],[0]
"i , and fixed the other parameters.",4.6. Real-world pedestrian simulator,[0],[0]
"We defined the true model as a mixture of 5 pedestrian groups, and set their parameters as (θ∗(N)1 , . . .",4.6. Real-world pedestrian simulator,[0],[0]
", θ ∗(N) 5 ) := (100, 100, 100, 100, 100) and (θ ∗(T ) 1 , . .",4.6. Real-world pedestrian simulator,[0],[0]
.,4.6. Real-world pedestrian simulator,[0],[0]
", θ ∗(T ) 5 ) := (30, 60, 90, 120, 150).",4.6. Real-world pedestrian simulator,[0],[0]
"As in Sec. 4.5, we used a redundant model of a mixture of 10 groups for parameter estimation.",4.6. Real-world pedestrian simulator,[0],[0]
"The goal was to detect the active 5 groups of the true model, without knowing that the truth consists of 5 groups.",4.6. Real-world pedestrian simulator,[0],[0]
"For simplicity, 5 (unknown) groups among the 10 candidate groups included the parameters of the true model other than θ∗(N)i , θ ∗(T ) i ; see the Supplementary Materials for details.
",4.6. Real-world pedestrian simulator,[0],[0]
We defined prior distributions as follows.,4.6. Real-world pedestrian simulator,[0],[0]
First we assumed the total number 500 of pedestrians to be known.,4.6. Real-world pedestrian simulator,[0],[0]
"The mixing coefficients of the mixture of 10 groups are given by (φ1, . . .",4.6. Real-world pedestrian simulator,[0],[0]
", φ10) =",4.6. Real-world pedestrian simulator,[0],[0]
"(θ (N) 1 , . . .",4.6. Real-world pedestrian simulator,[0],[0]
", θ (N) 10 )/500.",4.6. Real-world pedestrian simulator,[0],[0]
"Thus, rather than directly putting a prior on (θ(N)1 , . .",4.6. Real-world pedestrian simulator,[0],[0]
.,4.6. Real-world pedestrian simulator,[0],[0]
", θ (N) 10 ), we defined a prior on the mixing coefficients (φ1, . . .",4.6. Real-world pedestrian simulator,[0],[0]
", φ10).",4.6. Real-world pedestrian simulator,[0],[0]
"Specifically, we used a Dirichlet prior with a small concentration parameter, as in Sec. 4.5, in order to eliminate 5 redundant components:
(φ1, . . .",4.6. Real-world pedestrian simulator,[0],[0]
", φ10)",4.6. Real-world pedestrian simulator,[0],[0]
"∼ Dirichlet(α1, ..., α10), θ
(N)",4.6. Real-world pedestrian simulator,[0],[0]
"i := φi ∗ 500, (i = 1, . . .",4.6. Real-world pedestrian simulator,[0],[0]
", 10)
where α1 = · · · = α10 = 0.01 denote the concentration 5https://github.com/crest-cassia/CrowdWalk
parameters.",4.6. Real-world pedestrian simulator,[0],[0]
"For each of θ(T )1 , . . .",4.6. Real-world pedestrian simulator,[0],[0]
", θ (T ) 10 , we defined a broad uniform prior θ(T )i ∼ Unif(0, 480).
",4.6. Real-world pedestrian simulator,[0],[0]
"From the true model, we simulated 4200 time steps of pedestrian flow as observed data.",4.6. Real-world pedestrian simulator,[0],[0]
We made 5× 5 = 25 grids in a map of Ginza and computed a histogram of the corresponding 25 bins for each time step.,4.6. Real-world pedestrian simulator,[0],[0]
"Thus, observed data was made up of 4200 vectors in R25.",4.6. Real-world pedestrian simulator,[0],[0]
"In the same way, each method generated a total of 4200 vectors, and each iterative method made use of 200 vectors in each iteration, running 21 iterations in total.",4.6. Real-world pedestrian simulator,[0],[0]
"For SMC-ABC, we set the parameter α ∈ (0, 1) to be 0.2, as in the previous experiment.
",4.6. Real-world pedestrian simulator,[0],[0]
"We ran each method 20 times, and the resulting averages and standard deviations for errors are summarized in Table 4, where “θ(N) error” and “θ(T ) error” denote the errors of the corresponding estimated parameters, as measured in terms of Euclidean distance.",4.6. Real-world pedestrian simulator,[0],[0]
"These errors were computed in the same way as in Sec. 4.5 (e.g., the estimated parameters were sorted according to the magnitudes of the mixing coefficients).",4.6. Real-world pedestrian simulator,[0],[0]
"Results show that our method performed the best, confirming its effectiveness.",4.6. Real-world pedestrian simulator,[0],[0]
"In the Supplementary Materials, we also report the point estimates made using the proposed method, showing that the true parameters were estimated reasonably accurately.",4.6. Real-world pedestrian simulator,[0],[0]
We have proposed kernel recursive ABC for point estimation with intractable likelihood and have empirically investigated the effectiveness of this approach.,5. Summary and future work,[0],[0]
"While we have also provided theoretical analysis to a certain extent, there remain important theoretical topics, as discussed in Sec. 3.1, that we wish to reserve for future research.",5. Summary and future work,[0],[0]
"We thank the anonymous reviewers as well as Itaru Nishioka, Itsuki Noda, Takashi Washio, Shinji Ito, Wittawat Jitkrittum, and Marie Oshima for their helpful comments and support.",Acknowledgements,[0],[0]
We also thank Shuhei Mano for providing his code.,Acknowledgements,[0],[0]
MK has been supported by the European Research Council (StG Project PANAMA).,Acknowledgements,[0],[0]
KF has been supported by JSPS KAKENHI 26280009.,Acknowledgements,[0],[0]
We propose a novel approach to parameter estimation for simulator-based statistical models with intractable likelihood.,abstractText,[0],[0]
Our proposed method involves recursive application of kernel ABC and kernel herding to the same observed data.,abstractText,[0],[0]
"We provide a theoretical explanation regarding why the approach works, showing (for the population setting) that, under a certain assumption, point estimates obtained with this method converge to the true parameter, as recursion proceeds.",abstractText,[0],[0]
"We have conducted a variety of numerical experiments, including parameter estimation for a realworld pedestrian flow simulator, and show that in most cases our method outperforms existing approaches.",abstractText,[0],[0]
Kernel Recursive ABC: Point Estimation with Intractable Likelihood,title,[0],[0]
"1 Kernelized Support Tensor Train Machines Cong Chen, Kim Batselier, Wenjian Yu, Senior Member, IEEE, Ngai Wong, Senior Member, IEEE
Abstract—Tensor, a multi-dimensional data structure, has been exploited recently in the machine learning community. Traditional machine learning approaches are vector- or matrixbased, and cannot handle tensorial data directly. In this paper, we propose a tensor train (TT)-based kernel technique for the first time, and apply it to the conventional support vector machine (SVM) for image classification. Specifically, we propose a kernelized support tensor train machine that accepts tensorial input and preserves the intrinsic kernel property. The main contributions are threefold. First, we propose a TT-based feature mapping procedure that maintains the TT structure in the feature space. Second, we demonstrate two ways to construct the TTbased kernel function while considering consistency with the TT inner product and preservation of information. Third, we show that it is possible to apply different kernel functions on different data modes. In principle, our method tensorizes the standard SVM on its input structure and kernel mapping scheme. Extensive experiments are performed on real-world tensor data, which demonstrates the superiority of the proposed scheme under few-sample high-dimensional inputs.
I. INTRODUCTION
Many real-world data appear in matrix or tensor format. For example, a grayscale picture is a 2-way tensor (i.e. a matrix), a color image or a grayscale video is naturally a 3-way tensor, and a color video can be regarded as a 4- way tensor. In such circumstances, extending the vector-based machine learning algorithms to their tensorial format has recently attracted significant interest in the machine learning and data mining communities.For example, neighborhood preserving embedding (NPE) was extended to tensor neighborhood preserving embedding (TNPE) in [1], principal component analysis to multilinear principal component analysis (MPCA) in [2], support vector machines (SVMs) [3] to support tensor machines (STMs) in [4], and restricted Boltzmann machines to their tensorial formats in [5].
By reformulating the aforementioned machine learning algorithms into the tensorial framework, a huge performance improvement has been achieved. The main reasons for this improvement can be summarized as follows. Firstly, these tensorized algorithms can naturally utilize the multi-way structure of the original tensor data, which is believed to be useful in
This work is partially supported by the Hong Kong Research Grants Council under Project 17246416, the University Research Committee of The University of Hong Kong, Tsinghua University Initiative Scientific Research Program, and NSFC under grant No. 61872206.
Cong Chen is with the Department of Electrical and Electronic Engineering, The University of Hong Kong, Hong Kong. Email: chencong@eee.hku.hk.
Kim Batselier is with the Delft Center for Systems and Control, Delft University of Technology, Delft, Netherlands. Email: k.batselier@tudelft.nl.
Wenjian Yu is with BNRist, Department of Computer Science and Technology, Tsinghua University, Beijing 100084, China. Email: yuwj@tsinghua.edu.cn.
Ngai Wong is with the Department of Electrical and Electronic Engineering, The University of Hong Kong, Hong Kong. Email: nwong@eee.hku.hk.
many machine learning applications such as pattern recognition [6], image completion [7] and anomaly detection [8]. Secondly, vectorizing tensor data leads to high-dimensional vectors, which may cause overfitting especially when the training sample size is relatively small [9]. On the contrary, tensor-based approaches usually derive a more structural and robust model that commonly involves much fewer model parameters, which not only alleviates the overfitting problem, but also saves a lot of storage and computation resources [10], [11].
In this paper, we propose a kernelized support tensor train machine (K-STTM) to address few-sample image classification problems due to the fact that collecting labeled pictures is very expensive and time-consuming in many research areas. Specifically, we first employ the tensor train (TT) decomposition [12] to decompose the given tensor data so that a more compact and informative representation of it can be derived. Secondly, we define a TT-based feature mapping strategy to derive a high-dimensional TT in the feature space. This strategy enables us to apply different feature mappings on different data modes, which naturally provides a way to leverage the multi-modal nature of tensor structured data. Thirdly, we propose two ways to build the kernel matrix with the consideration of the consistency with the TT inner product and preservation of information. The constructed kernel matrix is then used by kernel machines to solve the image classification problems.
There are two main advantages from the proposed methods. On the one hand, the proposed methods are naturally nonlinear classifiers. It is common that real-life data are not linearly separable. However, most existing supervised tensor learning methods which employ tensor input are often based on a linear model and cannot deal with nonlinear classification problems. In that case, our proposed methods can handle nonlinear learning problems on tensor data better. On the other hand, conventional tensor-based kernel methods focus on flatting tensor data into matrices [13], [14], and thus can only preserve one-mode relationships within the tensor itself. However, our proposed approaches can capture and exploit multi-mode relationships, which commonly leads to more powerful and accurate models.
The superiority of our methods is validated through extensive experiments. It is observed that our methods achieve a much better performance than the linear supervised tensor learning methods, which indicates the importance of introducing kernel trick. Furthermore, our methods achieve a better classification performance when the input data are truly highdimensional. Applying different kernel functions on different data modes is also investigated and shows an obvious improvement compared with the baseline.
The rest of this paper is organized as follows. In Section II,
ar X
iv :2
00 1.
00 36
0v 1
[ cs
.L G
] 2
J an
2 02
0
2 we briefly review some related works in supervised tensor learning. Some useful notations and tensor arithmetic are further introduced in Section III. In Section IV, we formulate the proposed kernelized support tensor train machine (K-
STTM). Experiments are shown in Section V to validate the superiority of our methods. Lastly, we draw conclusions and propose some possible extended works in Section VI.",text,[0],[0]
"As one of the most typical supervised learning algorithms, SVM [3] has achieved an enormous success in pattern classification by minimizing the Vapnik-Chervonenkis dimensions and structural risk.",II. RELATED WORKS,[0],[0]
"However, a standard SVM can not deal with tensorial input directly.",II. RELATED WORKS,[0],[0]
The first work that extends SVM to handle tensorial input is [4].,II. RELATED WORKS,[0],[0]
"More precisely, a supervised tensor learning (STL) scheme was proposed to train a support tensor machine (STM), where the hyperplane parameters are modeled as a rank-1 tensor instead of a vector.",II. RELATED WORKS,[0],[0]
"For the parameter training, they employed the alternating projection optimization method.
",II. RELATED WORKS,[0],[0]
"Although STM is capable to classify tensorial data directly, the expressive power of a rank-1 weight tensor is limited, which often leads to a poor classification accuracy.",II. RELATED WORKS,[0],[0]
"To increase the model expression capacity, several works were proposed recently based on the STL scheme.",II. RELATED WORKS,[0],[0]
Ref.,II. RELATED WORKS,[0],[0]
"[15] employs a more general tensor structure, i.e., the canonical polyadic (CP) format, to replace the rank-1 weight tensor in STM.",II. RELATED WORKS,[0],[0]
"However, it is an NP-complete problem to determine the CP-rank.",II. RELATED WORKS,[0],[0]
"In [16], the STM is generalized to a support Tucker machine (STuM) by representing the weight parameter as a Tucker tensor.",II. RELATED WORKS,[0],[0]
"Nevertheless, the number of model parameters in STuM is exponentially large, which often leads to a large amount of storage and computation consumption.",II. RELATED WORKS,[0],[0]
"To overcome this, Ref.",II. RELATED WORKS,[0],[0]
"[17] proposed a support tensor train machine (STTM), which assumes the potential weight tensor format is a TT.",II. RELATED WORKS,[0],[0]
"By doing so, the corresponding optimization problem is more scalable and can be solved efficiently.",II. RELATED WORKS,[0],[0]
The aforementioned work are all based on the assumption that the given tensorial data are linearly separable.,II. RELATED WORKS,[0],[0]
"However, this is not the case in most real-world data.",II. RELATED WORKS,[0],[0]
"It is worth noting that though STTM sounds like the linear case of the proposed K-STTM, they are totally different when the linear kernel is applied on K-STTM.",II. RELATED WORKS,[0],[0]
"Specifically, K-STTM and STTM use two totally different schemes to train the corresponding model.",II. RELATED WORKS,[0],[0]
"For KSTTM, it first constructs the kernel matrix with the proposed TT-based kernel function, and then solves the standard SVM problem.",II. RELATED WORKS,[0],[0]
"However, in STTM, it assumes the parameter in the classification hyperplane can be modeled as a TT, and only updates one TT-core at a time by reformulating the training data.
",II. RELATED WORKS,[0],[0]
"To extend the linear tensorial classifiers to the nonlinear case, the authors in [18] proposed a nonlinear supervised learning scheme called dual structure-preserving kernels (DuSK).",II. RELATED WORKS,[0],[0]
"Specifically, based on the CP tensor structure, they define a corresponding kernel trick to map the CP format data into a higher-dimensional feature space.",II. RELATED WORKS,[0],[0]
"Through the introduction of the kernel trick, DuSK can achieve a higher classification
a a A A
Fig. 1: Graphical representation of a scalar a, vector a, matrix A, and third-order tensor A.
I1
I2 I4
I3 I5A B
Fig. 2: Index contraction between two 3-way tensors A and B.
accuracy.",II. RELATED WORKS,[0],[0]
"However, since DuSK is based on the CP decomposition, the NP-complete problem on the rank determination still exists.",II. RELATED WORKS,[0],[0]
"Moreover, through introducing a kernelized CP tensor factorization technique, the same research group in [18] further proposed the Multi-way Multi-level Kernel model [19] and kernelized support tensor machine model [20].",II. RELATED WORKS,[0],[0]
"Nevertheless, the CP-rank determination issue still exists since they are all based on the CP decomposition.
",II. RELATED WORKS,[0],[0]
"To avoid the above issues, we propose the K-STTM, which not only introduces the customized kernel function to handle nonlinear classification problems, but also achieves an efficient model training since the scalable TT format is employed.",II. RELATED WORKS,[0],[0]
"In this Section, we review some basic tensor notations and operations, together with the related tensor train decomposition method.",III. PRELIMINARIES,[0],[0]
Tensors in this paper are multi-dimensional arrays that generalize vectors (first-order tensors) and matrices (secondorder tensors) to higher orders.,A. Tensor basics,[0],[0]
"A dth-order or d-way tensor is denoted as A ∈ RI1×I2×···×Id and the element of A by A(i1, i2 . . .",A. Tensor basics,[0],[0]
", id), where 1≤ ik ≤ Ik, k = 1, 2, . . .",A. Tensor basics,[0],[0]
", d. The numbers I1, I2, . .",A. Tensor basics,[0],[0]
.,A. Tensor basics,[0],[0]
", Id are called the dimensions of the tensor A.",A. Tensor basics,[0],[0]
"We use boldface capital calligraphic letters A, B, . . .",A. Tensor basics,[0],[0]
"to denote tensors, boldface capital letters A, B, . . .",A. Tensor basics,[0],[0]
"to denote matrices, boldface letters a, b, . . .",A. Tensor basics,[0],[0]
"to denote vectors, and roman letters a, b, . . .",A. Tensor basics,[0],[0]
to denote scalars.,A. Tensor basics,[0],[0]
"An intuitive and useful graphical representation of scalars, vectors, matrices and tensors is depicted in Figure 1.",A. Tensor basics,[0],[0]
"The unconnected edges, also called free legs, are the indices of the tensor.",A. Tensor basics,[0],[0]
"Therefore scalars have no free legs, while a matrix has 2 free legs.",A. Tensor basics,[0],[0]
We will employ these graphical representations to visualize the tensor networks and operations in the following sections whenever possible and refer to [21] for more details.,A. Tensor basics,[0],[0]
"We now briefly introduce some important tensor operations.
",A. Tensor basics,[0],[0]
"Definition 1: (Tensor index contraction): A tensor index contraction is the sum over all possible values of the repeated indices in a set of tensors.
3 A(1) A(2) A(d)...",A. Tensor basics,[0],[0]
"R1 R2 R3 Rd Rd+1
I1 I2 Id
Fig. 3: Tensor train decomposition of a d-way tensor A into d 3-way tensors A(1),A(2) . . .",A. Tensor basics,[0],[0]
",A(d).
",A. Tensor basics,[0],[0]
"For example, the following contraction of two 3-way tensors A and B
C(i1, i2, i4, i5) = I3∑ i3=1 A(i1, i2, i3)B(i3, i4, i5),
over the i3 index produces a four-way tensor C. We also present the graphical representation of this contraction in Figure 2, where the summation over i3 is indicated by the connected edge.",A. Tensor basics,[0],[0]
"After this contraction, the tensor diagram contains four free legs indexed by i1, i2, i4, i5, respectively.
",A. Tensor basics,[0],[0]
"Definition 2: (Tensor inner product): For two tensors A,B ∈ RI1×I2×···×Id , their inner product 〈A,B〉 is defined as
〈A,B〉 = I1∑ i1=1 I2∑ i2=1 · · · Id∑ id=1 ai1,i2,··· ,idbi1,i2,··· ,id .
",A. Tensor basics,[0],[0]
"Definition 3: (Tensor Frobenius norm): The Frobenius norm of a tensor A ∈ RI1×I2×···×Id is defined as ||A||F =√ 〈A,A〉.",A. Tensor basics,[0],[0]
Here we briefly introduce the tensor train (TT) decomposition that will be utilized in the proposed K-STTM.,B. Tensor train decomposition,[0],[0]
"A TT decomposition [12] represents a d-way tensor A as d 3-way tensors A(1), A(2), . . .",B. Tensor train decomposition,[0],[0]
", A(d) such that a particular entry of A is written as the matrix product
A(i1, . . .",B. Tensor train decomposition,[0],[0]
", id) = A(1)(:, i1, :) · · ·A(d)(:, id, :), (1)
where A(k)(:, ik, :) is naturally a matrix since we fix the second index.",B. Tensor train decomposition,[0],[0]
"Each tensor A(k), k = 1, . . .",B. Tensor train decomposition,[0],[0]
", d, is called a TT-core and has dimensions Rk × Ik ×Rk+1.",B. Tensor train decomposition,[0],[0]
"Storage of a tensor as a TT therefore reduces from
∏d i=1",B. Tensor train decomposition,[0],[0]
Ri down,B. Tensor train decomposition,[0],[0]
"to∑d
i=1 RiIiRi+1.",B. Tensor train decomposition,[0],[0]
In order for the left-hand-side of (1) to be a scalar we require that R1 = Rd+1 = 1.,B. Tensor train decomposition,[0],[0]
The remaining Rk values are called the TT-ranks.,B. Tensor train decomposition,[0],[0]
"Figure 3 demonstrates how TT-decomposition decomposes a d-way tensor A, where the edges connecting the different circles indicate the matrixmatrix products of (1).",B. Tensor train decomposition,[0],[0]
"To simplify the statement, we define the notation TT (·), which means perform TT decomposition on a d-way tensor.",B. Tensor train decomposition,[0],[0]
"For example, TT (A) is the resulting TT after doing TT decomposition on the full tensor A, namely, A(1), A(2), · · · , A(d) are derived.
",B. Tensor train decomposition,[0],[0]
"Definition 4: (TT inner product): The inner product between two tensor trains TT (A) and TT (B) is denoted as 〈TT (A), TT (B)〉.",B. Tensor train decomposition,[0],[0]
The tensor network diagram of the inner product of two TTs is shown in Figure 4.,B. Tensor train decomposition,[0],[0]
"The lack of unconnected edges in Figure 4 implies that 〈TT (A), TT (B)〉 is a scalar.
A(1) A(2) A(d)
B(1) B(2) B(d)
...
...
",B. Tensor train decomposition,[0],[0]
Fig. 4: The inner product between two d-way tensor trains.,B. Tensor train decomposition,[0],[0]
"Since this work is based on traditional SVM, we therefore briefly review the main idea of an SVM.",C. Support vector machines,[0],[0]
"Assume we have a dataset D={xi, yi}Mi=1 of M labeled samples, where xi ∈ Rn are the vectorized data samples with labels yi ∈ {−1, 1}.",C. Support vector machines,[0],[0]
"The goal of an SVM is to find a discriminant hyperplane
f(x) = wTx + b (2)
that maximizes the margin between the two classes where w and b are the weight vector and bias, respectively.",C. Support vector machines,[0],[0]
"However, an SVM is very sensitive to noise since it requires all the training samples to meet the hard margin constraint.",C. Support vector machines,[0],[0]
"In that case, the trained model tends to overfit.",C. Support vector machines,[0],[0]
"To solve this, slack variables ξ1, . . .",C. Support vector machines,[0],[0]
", ξM are introduced to allow some certain samples to be misclassified, thus enhancing the robustness of the trained model.",C. Support vector machines,[0],[0]
"We can express the learning problem as a quadratic optimization problem
min w,b,ξ
1 2 ||w||2F + C M∑ i=1",C. Support vector machines,[0],[0]
"ξi
subject to yi(wTxi + b) ≥ 1− ξi, ξi ≥ 0, i = 1, . . .",C. Support vector machines,[0],[0]
",M. (3)
",C. Support vector machines,[0],[0]
The parameter C controls the trade-off between the size of the weight vector w and the size of the slack variables.,C. Support vector machines,[0],[0]
"It is more common to solve the dual problem of (3), especially when the feature size n is larger than the sample size M .",C. Support vector machines,[0],[0]
"The dual problem format of (3) is
min α1,α2,··· ,αM M∑ i=1",C. Support vector machines,[0],[0]
αi− 1 2 M∑,C. Support vector machines,[0],[0]
"i,j=1 αiαjyiyj〈xi,xj〉
subject to M∑ i=1",C. Support vector machines,[0],[0]
αiyi,C. Support vector machines,[0],[0]
"= 0,
0 ≤ αi ≤ C, i = 1, . . .",C. Support vector machines,[0],[0]
",M, (4)
where 〈xi,xj〉 represents the inner product between vector xi and xj and αi (i = 1, . . .",C. Support vector machines,[0],[0]
",M) are the Lagrange multipliers.
",C. Support vector machines,[0],[0]
"To solve a nonlinear classification problem with SVM, researchers further introduced the kernel trick that projects the original vectorial data onto a much higher-dimensional feature space through a nonlinear mapping function φ.",C. Support vector machines,[0],[0]
"In the feature space, the data generally become more (linearly) separable.",C. Support vector machines,[0],[0]
"By doing so, the optimization in (4) is transformed into
min α1,α2,··· ,αM M∑ i=1",C. Support vector machines,[0],[0]
αi− 1 2 M∑,C. Support vector machines,[0],[0]
"i,j=1 αiαjyiyj〈φ(xi), φ(xj)〉 (5)
4 with the same constraints as in (4).",C. Support vector machines,[0],[0]
"It turns out that it is possible to make the computation easier by replacing the inner product term 〈φ(xi), φ(xj)〉 with a kernel function k(xi,xj).",C. Support vector machines,[0],[0]
"In that case, the inner product in the high-dimensional feature space can be computed without the need to explicitly compute the mappings φ(xi), φ(xj).",C. Support vector machines,[0],[0]
"In this section, we first demonstrate the tensor-based kernel learning problem and then introduce the proposed K-STTM.",IV. KERNELIZED SUPPORT TENSOR TRAIN MACHINES,[0],[0]
"Given M tensorial training data and their labels, i.e., dataset D = {X i, yi}Mi=1, where X",A. Problem statement,[0],[0]
i ∈,A. Problem statement,[0],[0]
"RI1×I2×···×Id and yi ∈ {−1, 1}, we want to find a hyperplane
f(X ) = 〈W ,X 〉+ b",A. Problem statement,[0],[0]
(6) that separates the tensorial data into two classes.,A. Problem statement,[0],[0]
W is the hyperplane weight tensor with the same dimensions as X i and b is the bias.,A. Problem statement,[0],[0]
"Similar to the primal problem in SVM, we can derive the corresponding primal optimization problem for (6)
min W,b,ξ
1 2 ||W ||2F + C M∑ i=1",A. Problem statement,[0],[0]
"ξi
subject to yi(〈W ,X i〉+ b) ≥ 1− ξi, ξi ≥ 0, i = 1, . .",A. Problem statement,[0],[0]
.,A. Problem statement,[0],[0]
",M. (7)
",A. Problem statement,[0],[0]
"Following the scheme of the kernel trick for conventional SVMs, we introduce a nonlinear feature mapping function Φ(·).",A. Problem statement,[0],[0]
"Then, given a tensor X ∈ RI1×I2×···×Id , we assume it is mapped into the Hilbert space H by
Φ : X → Φ(X ) ∈ RH1×H2×···×Hd .",A. Problem statement,[0],[0]
(8) We need to mention that the dimension of projected tensor Φ(X ) can be infinite depending on the feature mapping function Φ(·).,A. Problem statement,[0],[0]
"The resulting Hilbert space is then called the tensor feature space and we can further develop the following model
min W,b,ξ
1 2 ||W ||2F + C M∑ i=1",A. Problem statement,[0],[0]
"ξi
subject to yi(〈W ,Φ(X i)〉+ b) ≥ 1− ξi, ξi ≥ 0, i = 1, . . .",A. Problem statement,[0],[0]
",M, (9)
with parameter tensor W ∈ RH1×H2×···×Hd .",A. Problem statement,[0],[0]
This model is naturally a linear classifier on the tensor feature space.,A. Problem statement,[0],[0]
"However, when we map the classifier back to the original data space, it is a nonlinear classifier.",A. Problem statement,[0],[0]
"To obtain the tensor-based kernel optimization model, we need to transfer model (9) into its dual, namely
min α1,α2,··· ,αM M∑ i=1",A. Problem statement,[0],[0]
αi− 1 2 M∑,A. Problem statement,[0],[0]
"i,j=1 αiαjyiyj〈Φ(X i),Φ(X j)〉
subject to M∑ i=1",A. Problem statement,[0],[0]
αiyi,A. Problem statement,[0],[0]
"= 0,
0 ≤ αi ≤ C, i = 1, . .",A. Problem statement,[0],[0]
.,A. Problem statement,[0],[0]
",M, (10)
where αi are the Lagrange multipliers.",A. Problem statement,[0],[0]
The key task we need to solve is to define a tensorial kernel function,A. Problem statement,[0],[0]
"K(X i,X j) that computes the inner product 〈Φ(X i),Φ(X j)〉 in the original data space instead of the feature space.",A. Problem statement,[0],[0]
"Although tensor is a natural structure for representing realworld data, there is no guarantee that such a representation works well for kernel learning.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"Instead of the full tensor, here we employ a TT for data representation due to the following reasons:
1) Real-life data often contain redundant information, which is not useful for kernel learning.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
The TT decomposition has proven to be efficient for removing the redundant information in the original data and provides a more compact data representation.,B. Customized kernel mapping schemes for TT-based data,[0],[0]
2),B. Customized kernel mapping schemes for TT-based data,[0],[0]
"Compared to the Tucker decomposition whose storage scales exponentially with the core tensor, a TT is more scalable (parameter number grows linearly with the tensor order d), which reduces the computation during kernel learning.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"3) Unlike the CP decomposition, determining the TT-rank is easily achieved through a series of singular value decompositions (TT-SVD [12] ).",B. Customized kernel mapping schemes for TT-based data,[0],[0]
This naturally leads to a faster data transformation to the TT format.,B. Customized kernel mapping schemes for TT-based data,[0],[0]
4),B. Customized kernel mapping schemes for TT-based data,[0],[0]
It is convenient to implement different operations on different tensor modes when data is in the TT format.,B. Customized kernel mapping schemes for TT-based data,[0],[0]
"Since a TT decomposition decomposes the original data into many TT cores, it is possible to apply different kernel functions on different TT cores for a better classification performance.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"Furthermore, we can emphasize the importance of different tensor modes by putting different weights on those TT cores during the kernel mapping.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"For example, a color image is a 3-way (pixel-pixel-color) tensor.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"The color mode can be treated differently with the two pixel modes since they contain different kinds of information, as will be exemplified later.
",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"In the following, we demonstrate the proposed TT-based feature mapping approach.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"Specifically, we map all fibers in each TT-core to the feature space, namely
Φ : X (i)(ri, :, ri+1)→ Φ(X (i)(ri, :, ri+1))",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"∈ RHi
1 ≤",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"ri ≤ Ri, i = 1, . . .",B. Customized kernel mapping schemes for TT-based data,[0],[0]
", d, (11)
where X (i) and Ri are the i-th TT-core and TT-rank of TT (X ), respectively.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"The fibers of each TT-core are naturally vectors, so the feature mapping works in the same way as for the conventional SVM.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"We then represent the resulting high-dimensional TT, which is in the tensor feature space, as Φ(TT (X ))",B. Customized kernel mapping schemes for TT-based data,[0],[0]
∈ RH1×H2×···×Hd .,B. Customized kernel mapping schemes for TT-based data,[0],[0]
We stress that Φ(TT (X )) is still in a TT format with the same TT-ranks as TT (X ).,B. Customized kernel mapping schemes for TT-based data,[0],[0]
"In this sense, the TT format data structure is preserved after the feature mapping.
",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"After mapping the TT format data into the TT-based highdimensional feature space, we then demonstrate the two proposed approaches for computing the inner product between two mapped TT format data using kernel function.
5 1) K-STTM-Prod:",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"The first method is called K-STTM-Prod since we implement consecutive multiplication operations on d fiber inner products, which is consistent with the result of an inner product between two TTs.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
Assuming Φ(TT (X )),B. Customized kernel mapping schemes for TT-based data,[0],[0]
and,B. Customized kernel mapping schemes for TT-based data,[0],[0]
"Φ(TT (Y)) ∈ RH1×H2×···×Hd with TT-ranks Ri and R̂i, i = 1, 2, . . .",B. Customized kernel mapping schemes for TT-based data,[0],[0]
", d, respectively, their inner product can be computed from
〈Φ(TT (X )),Φ(TT (Y))",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"〉 = R1∑ r1=1 · · · Rd∑ rd=1 R̂1∑ r̂1=1 · · · R̂d∑ r̂d=1
( d∏ i=1",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"〈Φ(X (i)(ri, :, ri+1)),Φ(Y(i)(r̂i, :, r̂i+1))〉).",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"(12)
We remark that (12) derives the exact same result as Figure 4 (assuming X = A and Y = B) when an identity feature mapping function Φ(·) is used, namely Φ(TT (X ))",B. Customized kernel mapping schemes for TT-based data,[0],[0]
=TT (X ).,B. Customized kernel mapping schemes for TT-based data,[0],[0]
"What is more, since each fiber of a mapped TT-core is naturally a vector, we have
〈Φ(X (i)(ri, :, ri+1)),Φ(Y(i)(r̂i, :, r̂i+1))",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"〉 = K(X (i)(ri, :, ri+1),Y(i)(r̂i, :, r̂i+1)), (13)
where K(·) can be any kernel function used for a standard SVM, such as a Gaussian RBF kernel, polynomial kernel, linear kernel etc.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"Combining (12) and (13), we obtain the corresponding TT-based kernel function
K(TT (X ), TT (Y))",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"= R1∑ r1=1 · · · Rd∑ rd=1 R̂1∑ r̂1=1 · · · R̂d∑ r̂d=1
( d∏ i=1",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"K(X (i)(ri, :, ri+1),Y(i)(r̂i, :, r̂i+1))).",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"(14)
As mentioned before, different kernel functions can be applied on different tensor modes i = 1, 2, . . .",B. Customized kernel mapping schemes for TT-based data,[0],[0]
", d. Therefore, the second line in (14) can be generalized to
( d∏ i=1",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"Ki(X (i)(ri, :, ri+1),Y(i)(r̂i, :, r̂i+1))).
",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"One possible application is in color image classification, where one could apply Gaussian RBF kernels K1 and K2 on its first two spatial modes, while choosing a linear or polynomial kernel K3 for the color mode.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"This will be investigated in the experiments.
2) K-STTM-Sum: The second method we propose to construct a TT kernel function is called K-STTM-Sum.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"Instead of implementing consecutive multiplication operations on d fiber inner products like in K-STTM-Prod, K-STTM-Sum performs consecutive addition operations on them.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
This idea is inspired by [22] which argues that the product of inner products can lead to the loss/misinterpretation of information.,B. Customized kernel mapping schemes for TT-based data,[0],[0]
"Take the linear kernel as an example, the inner product between two fibers of the same mode could be negative, which indicates a low similarity between those two fibers.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"However, by implementing consecutive multiplication operations on d fiber inner products, highly negative values could result in a large positive value.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"In that case, the overall similarity is high which is clearly unwanted.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"This situation also appears
when employing Gaussian RBF kernels.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"A nearly zero value would be assigned to two non-similar fibers, which could influence the final result significantly.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"To this end, we propose the K-STTM-Sum.",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"Similar to K-STTM-Prod, we can obtain the corresponding kernel function as
K(TT (X ), TT (Y))",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"= R1∑ r1=1 · · · Rd∑ rd=1 R̂1∑ r̂1=1 · · · R̂d∑ r̂d=1
( d∑ i=1",B. Customized kernel mapping schemes for TT-based data,[0],[0]
"Ki(X (i)(ri, :, ri+1),Y(i)(r̂i, :, r̂i+1))).",B. Customized kernel mapping schemes for TT-based data,[0],[0]
(15),B. Customized kernel mapping schemes for TT-based data,[0],[0]
"After defining the TT-based kernel function, we can then replace the term 〈Φ(X i),Φ(X j)〉 in (10) with (14) or (15), and derive our final kernel optimization problem based on the TT structure, namely,
min α1,α2,··· ,αM M∑ i=1",C. Kernel optimization problem,[0],[0]
αi− 1 2 M∑,C. Kernel optimization problem,[0],[0]
"i,j=1 αiαjyiyjK(TT",C. Kernel optimization problem,[0],[0]
"(X i), TT (X j))
subject to M∑ i=1",C. Kernel optimization problem,[0],[0]
αiyi,C. Kernel optimization problem,[0],[0]
"= 0,
0 ≤ αi ≤ C, i = 1, . . .",C. Kernel optimization problem,[0],[0]
",M. (16)
",C. Kernel optimization problem,[0],[0]
"After solving (16), we can get the unknown model parameters α1, α2, . . .",C. Kernel optimization problem,[0],[0]
", αM and the resulting decision function is then represented as
f(X )",C. Kernel optimization problem,[0],[0]
= sign( M∑ i=1,C. Kernel optimization problem,[0],[0]
αiyiK(TT,C. Kernel optimization problem,[0],[0]
"(X i), TT (X ))",C. Kernel optimization problem,[0],[0]
+ b).,C. Kernel optimization problem,[0],[0]
"(17)
Here we take the Gaussian RBF kernel as an example and summarize the training algorithm of the K-STTM-Prod/Sum as pseudo-code in Algorithm 1.",C. Kernel optimization problem,[0],[0]
An alternative for doing a grid search to find optimal hyperparameters would be crossvalidation.,C. Kernel optimization problem,[0],[0]
"Generalizing the binary classification to multiclassification can be easily achieved by utilizing a one-vs-one or one-vs-all strategy, namely, we can build several binary classifiers to do multi-class classification.",C. Kernel optimization problem,[0],[0]
"A key property of kernel function in standard SVM is that the resulting kernel matrix is positive semi-definite, which guarantees the mapped high-dimensional feature space is truly an inner product space.",D. Kernel validity,[0],[0]
"Therefore, we provide Theorem 1 to show the validity of K-STTM-Prod and K-STTM-Sum.
Theorem 1: Kernel functions K-STTM-Prod and K-STTMSum produce positive semi-definite kernel matrices.
",D. Kernel validity,[0],[0]
We provide the proof here.,D. Kernel validity,[0],[0]
1) Validity of K-STTM-Prod:,D. Kernel validity,[0],[0]
We first demonstrate the kernel function validity of K-STTM-Prod.,D. Kernel validity,[0],[0]
The goal is to show that the final kernel matrix constructed by (14) is positive semidefinite.,D. Kernel validity,[0],[0]
"In the actual implementation, it is extremely inefficient to use TT decomposition to decompose each tensorial sample one by one.",D. Kernel validity,[0],[0]
"The way we did it is by first stacking all
6 Algorithm 1 K-STTM-Prod/Sum Algorithm
Input: Training dataset {X i ∈ RI1×···×Id , yi ∈ {−1, 1}}Mi=1; Validation dataset {X j ∈ RI1×···×Id , yj ∈ {−1, 1}}Nj=1; The pre-set TT-ranks R1, R2, . . .",D. Kernel validity,[0],[0]
", Rd+1; The range of the performance trade-off parameter C and kernel width parameter σ, namely [Cmin, Cmax], and [σmin, σmax].",D. Kernel validity,[0],[0]
"Output: The Lagrange multipliers α1, α2, . . .",D. Kernel validity,[0],[0]
", αM ; The bias b.
1: Compute the TT approximation of training samples {X i}Mi=1 and validation set {X j}Nj=1 with the given TTranks using TT-SVD.",D. Kernel validity,[0],[0]
2: for C from Cmin to Cmax do 3: for σ from σmin to σmax do 4:,D. Kernel validity,[0],[0]
"Apply Gaussian RBF kernel on all the tensor modes,
and construct the kernel matrix according to (14) or (15), which are corresponding to K-STTM-Prod and K-STTM-Sum, respectively.
5: Solve (16) using the resulting kernel matrix.",D. Kernel validity,[0],[0]
6: Compute the classification accuracy on validation set.,D. Kernel validity,[0],[0]
"7: end for 8: end for 9: Find the best C and σ according to the classification
accuracy on validation set.",D. Kernel validity,[0],[0]
"10: Train the K-STTM with the best C and σ by imple-
menting step 4 and 5.",D. Kernel validity,[0],[0]
"Thus the the Lagrange multipliers α1, α2, . . .",D. Kernel validity,[0],[0]
", αM and the bias b are obtained.
",D. Kernel validity,[0],[0]
the d-way samples and then compute a TT decomposition on the resulting (d+ 1)-way tensor directly.,D. Kernel validity,[0],[0]
"By doing so, all TTbased training samples have the same TT-ranks.",D. Kernel validity,[0],[0]
"Also in the case where we compute the TT decomposition separately for each sample, we can still set the TT-ranks of all samples to be identical.",D. Kernel validity,[0],[0]
"That means Ri is equal to R̂i, i = 1, 2, . . .",D. Kernel validity,[0],[0]
", d for all the TT-based training samples.",D. Kernel validity,[0],[0]
We can then compute the final kernel matrix by doing R21×. .,D. Kernel validity,[0],[0]
.×R2d,D. Kernel validity,[0],[0]
"matrix summations, while each matrix in the summation procedure is computed by d times matrix Hadamard product.",D. Kernel validity,[0],[0]
"The matrix factors in the d times Hadamard product are valid kernel matrices since they are computed using the standard kernel function.
",D. Kernel validity,[0],[0]
"Through the above analysis, the goal now transforms into proving that the summation or Hadamard product between two positive semi-definite matrices A and B ∈ Rn×n still results in a positive semi-definite matrix.
",D. Kernel validity,[0],[0]
"For the summation case, we have{ uTAu ≥ 0, uTBu ≥ 0.
(18)
for every non-zero column vector u ∈ Rn.",D. Kernel validity,[0],[0]
"Obviously we can conclude that
uT (A+B)u ≥ 0, (19)
namely A + B is still positive semi-definite.",D. Kernel validity,[0],[0]
"For the Hadamard product case, we refer to the the Schur product theorem [23] and we can easily obtain
uT (A B)u ≥ 0, (20)
for every non-zero column vector u ∈",D. Kernel validity,[0],[0]
"Rn, where is the Hadamard product.",D. Kernel validity,[0],[0]
"Thus A B is still positive semi-definite.
",D. Kernel validity,[0],[0]
"Through the above analysis, we can conclude that by constraining the TT-based training samples to have identical TT-ranks, we can get a valid kernel matrix using K-STTMProd.
2) Validity of K-STTM-Sum: The proof for the validity of K-STTM-Sum is similar as it for K-STTM-Prod.",D. Kernel validity,[0],[0]
The difference between kernel functions (14) and (15) is that (15) only replaces the product with a summation.,D. Kernel validity,[0],[0]
"In that case, for K-STTM-Sum, the final kernel matrix is produced by the summation of a set of valid positive semi-definite matrices.",D. Kernel validity,[0],[0]
"Namely, we can still get a valid kernel matrix using K-STTMSum.",D. Kernel validity,[0],[0]
"Here we demonstrate the convergence analysis of our proposed methods and compare the storage and computation complexity with the standard SVM.
",E. Convergence and complexity,[0],[0]
"For the convergence analysis, it is same as it in standard SVM problem.",E. Convergence and complexity,[0],[0]
We already show the kernel validity of (14) and (15) in Theorem 1.,E. Convergence and complexity,[0],[0]
"With a valid kernel matrix, we can solve a quadratic programming problem to get the Lagrange multipliers αi and bias b, which is same as the procedure in standard SVM.",E. Convergence and complexity,[0],[0]
"Consequently, the convergence analysis is exactly same as it in standard SVM.
",E. Convergence and complexity,[0],[0]
"For the storage complexity analysis, the original tensorial sample storage is O(MId), where I is the maximum value of Ii, i = 1, 2, . . .",E. Convergence and complexity,[0],[0]
", d.",E. Convergence and complexity,[0],[0]
"After representing the original tensorial data as TTs, the data storage becomes to O(MdIR2), where R is the maximum TT-rank.",E. Convergence and complexity,[0],[0]
"This shows a great reduction especially when the data order d is large.
",E. Convergence and complexity,[0],[0]
"For the computation complexity, the overall result of KSTTM-Prod is the same as the result of K-STTM-Sum if we neglect those low-order polynomial terms.",E. Convergence and complexity,[0],[0]
This can be observed from (14) and (15).,E. Convergence and complexity,[0],[0]
The main computation costs are similar in those two equations.,E. Convergence and complexity,[0],[0]
Therefore we just analyze the K-STTM-Prod method.,E. Convergence and complexity,[0],[0]
"The computational complexity of constructing the kernel matrix in standard SVM is O(M2Id), where n is the maximum dimension of Ii, i = 1, 2, ...",E. Convergence and complexity,[0],[0]
"d. When applying the accelerating implementation of K-STTMProd, its kernel matrix computation complexity is O(dI2R4 + M2IdR 2 d), where I and R are the maximum values of Ii and Ri, i = 1, 2, ...",E. Convergence and complexity,[0],[0]
d,E. Convergence and complexity,[0],[0]
"− 1, respectively.",E. Convergence and complexity,[0],[0]
"Real-world data is commonly low-rank, so the TT-ranks Ri are generally small.",E. Convergence and complexity,[0],[0]
"Moreover, their dimensions Ii are very high.",E. Convergence and complexity,[0],[0]
That indicates our proposed method is more efficient than its vector counterpart since the computation complexity is reduced from exponential to polynomial.,E. Convergence and complexity,[0],[0]
"We evaluate the effectiveness of the two proposed schemes, K-STTM-Prod and K-STTM-Sum, on real-world tensorial datasets and contrast our methods with the following seven methods as a baseline.",V. EXPERIMENTS,[0],[0]
"• SVM: SVM [3] is one of the most widely used vector-
based method for classification.",V. EXPERIMENTS,[0],[0]
"What is more, the proposed K-STTM is a tensorial extension of SVM, so SVM
7 is selected as a baseline.",V. EXPERIMENTS,[0],[0]
"We employ the widely used convex optimization solver CVX∗ to solve the quadratic programming problem.
",V. EXPERIMENTS,[0],[0]
"• STM: STM [4] is the first method which extends SVM to the tensorial format, which employs alternating optimization scheme to update the weight tensors and outperforms kernel SVM in some tasks.",V. EXPERIMENTS,[0],[0]
• STuM:,V. EXPERIMENTS,[0],[0]
It is a kind of support tensor machine which is based on the Tucker decomposition [16].,V. EXPERIMENTS,[0],[0]
The training procedure is similar as the one in STM. •,V. EXPERIMENTS,[0],[0]
"STTM: STTM [17] assumes the weight tensor is a scalable tensor train, which enables STTM to deal with high-dimensional data classification.",V. EXPERIMENTS,[0],[0]
"STM, STuM, and STTM are all tensor-based linear classifiers.",V. EXPERIMENTS,[0],[0]
"In very small sample size problem, sometimes linear classifier are observed to achieve a better classification accuracy than nonlinear classifier [18] since a linear classifier is commonly less complex and more stable and can be better trained than nonlinear classifiers.",V. EXPERIMENTS,[0],[0]
• DuSK: DuSK is a kernelized support tensor machine using the CP decomposition [18].,V. EXPERIMENTS,[0],[0]
"Through introducing the kernel trick, it can deal with nonlinear classification tasks.",V. EXPERIMENTS,[0],[0]
• 3D CNN:,V. EXPERIMENTS,[0],[0]
CNN is one of the most powerful structure for image classification.,V. EXPERIMENTS,[0],[0]
The 3D CNN we employ here is an extension of the 2D version in [24].,V. EXPERIMENTS,[0],[0]
We replace the 2D convolutional kernels with 3D ones and keep other settings the same.,V. EXPERIMENTS,[0],[0]
"Though 3D CNN is a relatively simple CNN model, it has an advantage in dealing with small sample size problems since it can be trained better than the complicated CNN model.",V. EXPERIMENTS,[0],[0]
• TT Classifier:,V. EXPERIMENTS,[0],[0]
"As an updated tensor classification method, TT classifier [25] trains a TT as a polynomial classifier and achieves good results on tensorial image classification tasks.
",V. EXPERIMENTS,[0],[0]
"For simplicity, all of the kernel based methods, i.e., SVM, DuSK, and K-STTM, employ the Gaussian RBF kernel.",V. EXPERIMENTS,[0],[0]
"The optimal parameters, namely the performance trade-off parameter C, RBF kernel parameter σ, hidden layer size in 3D CNN, plus the corresponding tensor rank in STuM, STTM, DuSK, TT classifier and K-STTM, are determined through a grid search.",V. EXPERIMENTS,[0],[0]
The detail of the hyperparameter search schemes of all methods in all experiments are demonstrated in Appendix.,V. EXPERIMENTS,[0],[0]
"First, our proposed methods are compared with the above methods on the well-known MNIST dataset [26], which has a training set of 60k samples and a testing set of 10k samples.",A. MNIST,[0],[0]
"Each sample is a 28 × 28 grayscale image of a handwritten digit {0, . . .",A. MNIST,[0],[0]
", 9}.",A. MNIST,[0],[0]
"Although there are total 60k training samples, we care more about the small sample size problem.",A. MNIST,[0],[0]
"Thus for each class, we randomly choose 50 samples for model training and another 50 for validation.",A. MNIST,[0],[0]
All test samples in each class are used for checking the classification performance of each trained model.,A. MNIST,[0],[0]
"Since an SVM is naturally a binary classifier,
∗http://cvxr.com/cvx/
we randomly choose 10 digit pairs out of 45 to check the classification accuracy.
",A. MNIST,[0],[0]
Table I shows the classification results on different digit pairs.,A. MNIST,[0],[0]
"DuSK achieves the lowest accuracy among all the methods , which may be caused by the CP-rank searching: Finding a good CP-rank is an NP-complete problem, so DuSK may perform poorly if it fails to do so.",A. MNIST,[0],[0]
"Due to the naturally linearity of STM, STuM and STTM, they also can not achieve a good classification accuracy on real-world data.",A. MNIST,[0],[0]
"TT classifier even achieves a very poor classification performance on some digit pairs since it is naturally a polynomial classifier, whose classification power is limited.",A. MNIST,[0],[0]
We notice that the two proposed approaches K-STTM-Prod and K-STTM-Sum only achieve a slightly better accuracy than SVM and 3D CNN on some digit pairs.,A. MNIST,[0],[0]
The main reason that SVM and 3D CNN perform very well also is that MNIST is a relatively small dataset.,A. MNIST,[0],[0]
"The data dimension is 784 only, thus conventional SVM and 3D CNN do not encounter the curse of dimensionality and no overfitting occurs.",A. MNIST,[0],[0]
The advantage of tensorial methods are expected to be more apparent when the problem is truly high-dimensional.,A. MNIST,[0],[0]
"We therefore consider in the second experiment fMRI image data, whose dimensions are higher than 32k.
",A. MNIST,[0],[0]
We also investigate the influence of the TT-rank on the classification accuracy.,A. MNIST,[0],[0]
Figure 5 shows how the classification accuracy of K-STTM-Prod and K-STTM-Sum changes along with increasing TT-rank on two randomly selected digit pairs.,A. MNIST,[0],[0]
"We can observe that K-STTM with a small TT-rank can achieve a similar classification performance when it with high TT-rank, and the highest accuracies are all achieved when TTrank is around 5, which means we can select a relatively small TT-rank R to reduce the cost of kernel computation, while at the same time keep the classification performance.",A. MNIST,[0],[0]
This validates the computation complexity analysis in Section IV-E since the R and Rd in O(dI2R4 +M2IdR2d) are often small.,A. MNIST,[0],[0]
"As we mentioned in experiment V-A, tensorial method shows more apparent advantages on high-dimensional dataset.",B. fMRI datasets,[0],[0]
"Thus we consider two high-dimensional fMRI datasets, namely the StarPlus fMRI dataset† and the CMU Science 2008 fMRI dataset (CMU2008)",B. fMRI datasets,[0],[0]
[27] to evaluate the classification performance of different models.,B. fMRI datasets,[0],[0]
An fMRI image is essentially a 3-way tensor.,B. fMRI datasets,[0],[0]
"Figure 6 from [18] illustrates the tensorial structure of the fMRI image.
1) StarPlus fMRI dataset:",B. fMRI datasets,[0],[0]
"The fMRI images in StarPlus dataset are with dimensions 64 × 64 × 8 that contains 25 to 30 anatomically defined regions (called“Regions of Interest”, or ROIs).",B. fMRI datasets,[0],[0]
"To achieve a better classification accuracy, we only consider the following ROIs: ‘CALC’ ‘LIPL’ ‘LT’ ‘LTRIA’ ‘LOPER’ ‘LIPS’ ‘LDLPFC’.",B. fMRI datasets,[0],[0]
"After extracting those ROIs, we further normalize the data of each subject.",B. fMRI datasets,[0],[0]
StarPlus fMRI dataset contains the brain images of 6 human subjects.,B. fMRI datasets,[0],[0]
"The data of each human subject is partitioned into trials, and each subject has 40 effective trials.",B. fMRI datasets,[0],[0]
"Here we only use the first 4 seconds of each trial since the subject was shown one kind of
†http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-81/www/
8
TABLE",B. fMRI datasets,[0],[0]
I:,B. fMRI datasets,[0],[0]
"Classification accuracy of different methods for different MNIST digit pairs.
",B. fMRI datasets,[0],[0]
Digit pair SVM STM STuM STTM DuSK,B. fMRI datasets,[0],[0]
"3D CNN TT classiifer K-STTM-Prod K-STTM-Sum
{‘1’,‘2’} 98.15% 94.09% 97.96% 97.69% 89.16% 98.20% 73.93% 99.22% 99.27% {‘1’,‘7’} 97.73% 96.62% 97.87% 97.83% 80.95% 98.19% 96.99% 98.34% 98.20% {‘1’,‘8’} 96.49% 93.78% 95.92% 96.30% 87.63% 97.24% 84.48% 97.97% 98.06% {‘2’,‘4’} 98.36% 96.32% 97.46% 97.52% 77.26% 96.27% 93.45% 99.01% 98.61% {‘2’,‘7’} 96.41% 94.46% 95.58% 95.58% 81.26% 94.22% 94.22% 97.09% 96.95% {‘4’,‘6’} 97.16% 97.57% 97.47% 97.42% 78.66% 96.18% 93.71% 98.30% 97.74% {‘4’,‘9’} 89.50% 86.53% 90.65% 90.86% 68.46% 91.91% 59.12% 93.27% 91.77% {‘5’,‘6’} 96.00% 95.29% 95.24% 94.92% 75.78% 92.75% 88.16% 96.49% 96.76% {‘5’,‘8’} 86.92% 78.18% 91.47% 88.10% 70.69% 90.46% 63.56% 94.32% 91.59% {‘7’,‘8’} 94.46% 92.30% 95.85% 95.40% 75.97% 94.30% 94.46% 96.76% 96.16%
TABLE II:",B. fMRI datasets,[0],[0]
"Classification accuracy of different methods for different subjects in StarPlus fMRI datasets.
",B. fMRI datasets,[0],[0]
"Subject SVM STM STuM STTM DuSK 3D CNN TT classifier K-STTM-Prod K-STTM-Sum
04799 50.00%∗ 36.67% 35.83% 39.61% 47.50% 51.67% 57.50% 68.33% 66.67% 04820 50.00%∗ 43.33% 35.00% 45.83% 46.67% 44.16% 54.17% 70.00% 62.50% 04847 50.00%∗ 38.33% 17.50% 47.50% 53.33% 55.00% 61.67% 65.00% 65.00% 05675",B. fMRI datasets,[0],[0]
"50.00%∗ 37.50% 30.83% 35.00% 55.00% 47.50% 55.00% 60.00% 60.00% 05680 50.00%∗ 38.33% 39.17% 40.00% 64.17% 68.33% 60.83% 73.33% 75.00% 05710 50.00%∗ 40.00% 30.00% 43.33% 54.16% 47.50% 53.33% 59.17% 58.33% ∗ SVM classifies all test samples into one class since no good hyperparameter setting can be found by grid search.
",B. fMRI datasets,[0],[0]
Fig. 5: Classification accuracy of K-STTM-Prod and K-STTM-Sum with different TT-rank on two randomly selected digit pairs.,B. fMRI datasets,[0],[0]
"Top figure: digit pair ‘1’,‘2’; bottom figure: digit pair ‘5’,‘6’.
stimulus (sentence or picture) during the whole period.",B. fMRI datasets,[0],[0]
"The fMRI images were collected every 500 msec, thus we can utilize 8 fMRI images in each trial.",B. fMRI datasets,[0],[0]
"Overall, we have 320 fMRI images: one half of them were collected when the subject was shown a picture, the other half were collected when the subject was shown a sentence, while we randomly select 140 images for training, 60 for validation and the left for testing.
",B. fMRI datasets,[0],[0]
The classification results are listed in Table II.,B. fMRI datasets,[0],[0]
"Due to the very high-dimensional and sparse data, SVM fails to find a good hyperparameter setting thus can not do classification.",B. fMRI datasets,[0],[0]
"Since fMRI data are very complicated, those linear classifiers, namely STM, STuM and STTM, can not achieve an acceptable performance, and the classification accuracies of them are all
Fig. 6: fMRI images from [18].",B. fMRI datasets,[0],[0]
"(a) An illustration of a 3-way tensor (fMRI image), (b) Visualization of an fMRI image.
lower than 50%.",B. fMRI datasets,[0],[0]
The classification result of TT classifier is poor on several subjects.,B. fMRI datasets,[0],[0]
DuSK also performs poor on subjects ‘04799’ and ‘04820’.,B. fMRI datasets,[0],[0]
"Due to the small number of training samples and high-dimensional data size, the 3D CNN overfits and can not be well trained, while our proposed two methods still achieve the highest classification accuracy on all human subjects.
",B. fMRI datasets,[0],[0]
2) CMU2008:,B. fMRI datasets,[0],[0]
The second fMRI dataset we consider is CMU2008.,B. fMRI datasets,[0],[0]
It shows the brain activities associated with the meanings of nouns.,B. fMRI datasets,[0],[0]
"During the data collection period, the subjects were asked to view 60 different word-picture from 12 semantic categories.",B. fMRI datasets,[0],[0]
There are 5 pictures in each categories and each images is shown to the subject for 6 times.,B. fMRI datasets,[0],[0]
"Therefore, we can get 30 fMRI images for each semantic category, and each fMRI image is with dimensions 51 × 61 × 23.",B. fMRI datasets,[0],[0]
"In this experiment, we consider all the ROIs thus the classified fMRI images are relatively denser than the images we classified in the StarPlus example.",B. fMRI datasets,[0],[0]
"Considering the extremely small number of samples in each category, we therefore follow the experiment settings in [28] , which combines two similar categories into an integrated class.",B. fMRI datasets,[0],[0]
"Specifically, we combine categories
9
animal and insect as class Animals, and categories tool and furniture as class Tools.",B. fMRI datasets,[0],[0]
"By doing so, we have 60 samples in both Animals and Tools classes.",B. fMRI datasets,[0],[0]
"We separate the total 120 fMRI images as training, validation and testing sets, with 50, 20 and 50 images respectively.
",B. fMRI datasets,[0],[0]
Table III shows the binary classification results of different models.,B. fMRI datasets,[0],[0]
"We notice that SVM can perform classification on this dataset since we include all ROIs, which facilitates the hyperparameter searching procedure.",B. fMRI datasets,[0],[0]
"However, its classification accuracies on four subjects are lower than 50%.",B. fMRI datasets,[0],[0]
"The linear and polynomial model, namely STM, STuM, STTM, and TT classiifer, can only achieve an acceptable performance on a few subjects.",B. fMRI datasets,[0],[0]
"Due to the high-dimensional data size, DuSK fails to find a good CP-rank in acceptable time and can not achieve a good classification accuracy.",B. fMRI datasets,[0],[0]
3D CNN still performs poor due to the very few training samples and high-dimensional feature size.,B. fMRI datasets,[0],[0]
Our proposed two methods still achieve the best classification results on all subjects.,B. fMRI datasets,[0],[0]
"In this experiment, we use the CIFAR-10 dataset [29] to investigate the fourth claim in Section IV-B, namely, we can perform different kernel functions on different tensor modes.",C. CIFAR-10,[0],[0]
Here we demonstrate the effect on K-STTM-Prod only.,C. CIFAR-10,[0],[0]
We also randomly select ten class pairs to do binary classification.,C. CIFAR-10,[0],[0]
"Without overlap, 50 samples from the training set of each class are picked randomly for model training and validation respectively, while all the test samples of each class are used for testing.",C. CIFAR-10,[0],[0]
"Since each color image is naturally a threeway tensor (pixel-pixel-color), and the first two tensor modes are related to pixel intensity, we therefore utilize the same Gaussian RBF kernel for the first two tensor modes and try a different kernel (linear or polynomial) for the third mode.",C. CIFAR-10,[0],[0]
"The parameters c, d in the polynomial kernel k(x,y) = (xTy+c)d
were empirically set to c = 1 and d = 2.",C. CIFAR-10,[0],[0]
"The baseline case is when the Gaussian RBF kernel is applied to all tensor modes.
",C. CIFAR-10,[0],[0]
Table IV lists the classification results.,C. CIFAR-10,[0],[0]
We can observe that K-STTM-Prod still achieves the best accuracy on all class pairs.,C. CIFAR-10,[0],[0]
"And by applying a linear or polynomial kernel on the color mode, the classification accuracy of K-STTMProd outperforms the baseline case (RBF-RBF-RBF) on nine class pairs, which indicates the potential benefit of employing different kernel functions on different tensor modes when they contain different kind of information.",C. CIFAR-10,[0],[0]
"Since the data size of CIFAR-10 is also relatively small, we get a similar observation as the MNIST experiment, namely our method only achieves slightly better classification performance than SVM and 3D CNN on some class pairs.",C. CIFAR-10,[0],[0]
"Due to the constrained rank-one model setting, STM can not achieve an acceptable performance.",C. CIFAR-10,[0],[0]
"The other two linear classifiers, namely STuM and STTM still perform poor on most of the class pairs.",C. CIFAR-10,[0],[0]
The TT classifier has a similar performance as the STM in this experiment.,C. CIFAR-10,[0],[0]
This paper has proposed a tensor train (TT)-based kernel trick for the first time and devised a kernelized support tensor train machine (K-STTM).,VI. CONCLUSIONS AND FUTURE WORKS,[0],[0]
"Assuming a low-rank TT as the prior structure of multi-dimensional data, we first define a corresponding feature mapping scheme that keeps the TT structure in the feature space.",VI. CONCLUSIONS AND FUTURE WORKS,[0],[0]
"Furthermore, two kernel function construction schemes are proposed with consideration of consistency with the TT inner product and the preservation of information, respectively.",VI. CONCLUSIONS AND FUTURE WORKS,[0],[0]
The feasibility of applying different kernel mappings on the tensor modes with different characteristics is also investigated.,VI. CONCLUSIONS AND FUTURE WORKS,[0],[0]
"Experiments have demonstrated the superiority of K-STTM over conventional approaches for tensorial data in few-sample size problems.
",VI. CONCLUSIONS AND FUTURE WORKS,[0],[0]
"10
We further envision two future research directions based on the K-STTM framework.",VI. CONCLUSIONS AND FUTURE WORKS,[0],[0]
"Firstly, instead of constructing a kernel matrix in the K-STTM formula, we will consider building a kernel tensor.",VI. CONCLUSIONS AND FUTURE WORKS,[0],[0]
We believe that the kernel matrix constructed for each mode can contain different information.,VI. CONCLUSIONS AND FUTURE WORKS,[0],[0]
Simply multiplying or adding this information may not be the best solution.,VI. CONCLUSIONS AND FUTURE WORKS,[0],[0]
"Subsequently, we propose to stack this information into a 3-way kernel tensor and develop a better way to exploit information in each of the modes.",VI. CONCLUSIONS AND FUTURE WORKS,[0],[0]
"Secondly, we will embed the proposed kernel mapping trick into other kernel-based methods such as LSSVM [30], kernel PCA [31] etc., such that these methods can directly deal with tensorial data and achieve potentially better performance.",VI. CONCLUSIONS AND FUTURE WORKS,[0],[0]
"Tensor, a multi-dimensional data structure, has been exploited recently in the machine learning community.",abstractText,[0],[0]
"Traditional machine learning approaches are vectoror matrixbased, and cannot handle tensorial data directly.",abstractText,[0],[0]
"In this paper, we propose a tensor train (TT)-based kernel technique for the first time, and apply it to the conventional support vector machine (SVM) for image classification.",abstractText,[0],[0]
"Specifically, we propose a kernelized support tensor train machine that accepts tensorial input and preserves the intrinsic kernel property.",abstractText,[0],[0]
The main contributions are threefold.,abstractText,[0],[0]
"First, we propose a TT-based feature mapping procedure that maintains the TT structure in the feature space.",abstractText,[0],[0]
"Second, we demonstrate two ways to construct the TTbased kernel function while considering consistency with the TT inner product and preservation of information.",abstractText,[0],[0]
"Third, we show that it is possible to apply different kernel functions on different data modes.",abstractText,[0],[0]
"In principle, our method tensorizes the standard SVM on its input structure and kernel mapping scheme.",abstractText,[0],[0]
"Extensive experiments are performed on real-world tensor data, which demonstrates the superiority of the proposed scheme under few-sample high-dimensional inputs.",abstractText,[0],[0]
Kernelized Support Tensor Train Machines,title,[0],[0]
"Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1400–1409, Austin, Texas, November 1-5, 2016. c©2016 Association for Computational Linguistics
Directly reading documents and being able to answer questions from them is an unsolved challenge. To avoid its inherent difficulty, question answering (QA) has been directed towards using Knowledge Bases (KBs) instead, which has proven effective. Unfortunately KBs often suffer from being too restrictive, as the schema cannot support certain types of answers, and too sparse, e.g. Wikipedia contains much more information than Freebase. In this work we introduce a new method, Key-Value Memory Networks, that makes reading documents more viable by utilizing different encodings in the addressing and output stages of the memory read operation. To compare using KBs, information extraction or Wikipedia documents directly in a single framework we construct an analysis tool, WIKIMOVIES, a QA dataset that contains raw text alongside a preprocessed KB, in the domain of movies. Our method reduces the gap between all three settings. It also achieves state-of-the-art results on the existing WIKIQA benchmark.",text,[0],[0]
"Question answering (QA) has been a long standing research problem in natural language processing, with the first systems attempting to answer questions by directly reading documents (Voorhees and Tice, 2000).",1 Introduction,[0],[0]
"The development of large-scale Knowledge Bases (KBs) such as Freebase (Bollacker et al., 2008) helped organize information into structured forms, prompting recent progress to focus on answering questions by converting them into logical forms that
can be used to query such databases (Berant et al., 2013; Kwiatkowski et al., 2013; Fader et al., 2014).
",1 Introduction,[0],[0]
"Unfortunately, KBs have intrinsic limitations such as their inevitable incompleteness and fixed schemas that cannot support all varieties of answers.",1 Introduction,[0],[0]
"Since information extraction (IE) (Craven et al., 2000), intended to fill in missing information in KBs, is neither accurate nor reliable enough, collections of raw textual resources and documents such as Wikipedia will always contain more information.",1 Introduction,[0],[0]
"As a result, even if KBs can be satisfactory for closed-domain problems, they are unlikely to scale up to answer general questions on any topic.",1 Introduction,[0],[0]
"Starting from this observation, in this work we study the problem of answering by directly reading documents.
",1 Introduction,[0],[0]
"Retrieving answers directly from text is harder than from KBs because information is far less structured, is indirectly and ambiguously expressed, and is usually scattered across multiple documents.",1 Introduction,[0],[0]
This explains why using a satisfactory KB—typically only available in closed domains—is preferred over raw text.,1 Introduction,[0],[0]
"We postulate that before trying to provide answers that are not in KBs, document-based QA systems should first reach KB-based systems’ performance in such closed domains, where clear comparison and evaluation is possible.",1 Introduction,[0],[0]
"To this end, this paper introduces WIKIMOVIES, a new analysis tool that allows for measuring the performance of QA systems when the knowledge source is switched from a KB to unstructured documents.",1 Introduction,[0],[0]
"WIKIMOVIES contains ∼100k questions in the movie domain, and was designed to be answerable by using either a perfect KB (based on OMDb1), Wikipedia pages or an imper-
1http://www.omdbapi.com
1400
fect KB obtained through running an engineered IE pipeline on those pages.
",1 Introduction,[0],[0]
"To bridge the gap between using a KB and reading documents directly, we still lack appropriate machine learning algorithms.",1 Introduction,[0],[0]
"In this work we propose the Key-Value Memory Network (KV-MemNN), a new neural network architecture that generalizes the original Memory Network (Sukhbaatar et al., 2015) and can work with either knowledge source.",1 Introduction,[0],[0]
The KV-MemNN performs QA by first storing facts in a key-value structured memory before reasoning on them in order to predict an answer.,1 Introduction,[0],[0]
"The memory is designed so that the model learns to use keys to address relevant memories with respect to the question, whose corresponding values are subsequently returned.",1 Introduction,[0],[0]
"This structure allows the model to encode prior knowledge for the considered task and to leverage possibly complex transforms between keys and values, while still being trained using standard backpropagation via stochastic gradient descent.
",1 Introduction,[0],[0]
"Our experiments on WIKIMOVIES indicate that, thanks to its key-value memory, the KV-MemNN consistently outperforms the original Memory Network, and reduces the gap between answering from a human-annotated KB, from an automatically extracted KB or from directly reading Wikipedia.",1 Introduction,[0],[0]
"We confirm our findings on WIKIQA (Yang et al., 2015), another Wikipedia-based QA benchmark where no KB is available, where we demonstrate that KV-MemNN can reach state-of-the-art results— surpassing the most recent attention-based neural network models.",1 Introduction,[0],[0]
"Early QA systems were based on information retrieval and were designed to return snippets of text containing an answer (Voorhees and Tice, 2000; Banko et al., 2002), with limitations in terms of question complexity and response coverage.",2 Related Work,[0],[0]
"The creation of large-scale KBs (Auer et al., 2007; Bollacker et al., 2008) have led to the development of a new class of QA methods based on semantic parsing (Berant et al., 2013; Kwiatkowski et al., 2013; Fader et al., 2014; Yih et al., 2015) that can return precise answers to complicated compositional questions.",2 Related Work,[0],[0]
"Due to the sparsity of KB data, however, the main challenge shifts from finding answers to developing efficient information extraction methods to populate KBs auto-
matically (Craven et al., 2000; Carlson et al., 2010)— not an easy problem.
",2 Related Work,[0],[0]
"For this reason, recent initiatives are returning to the original setting of directly answering from text using datasets like TRECQA (Wang et al., 2007), which is based on classical TREC resources (Voorhees et al., 1999), and WIKIQA (Yang et al., 2015), which is extracted from Wikipedia.",2 Related Work,[0],[0]
"Both benchmarks are organized around the task of answer sentence selection, where a system must identify the sentence containing the correct answer in a collection of documents, but need not return the actual answer as a KB-based system would do.",2 Related Work,[0],[0]
"Unfortunately, these datasets are very small (hundreds of examples) and, because of their answer selection setting, do not offer the option to directly compare answering from a KB against answering from pure text.",2 Related Work,[0],[0]
"Using similar resources as the dialog dataset of Dodge et al. (2016), our new benchmark WIKIMOVIES addresses both deficiencies by providing a substantial corpus of questionanswer pairs that can be answered by either using a KB or a corresponding set of documents.
",2 Related Work,[0],[0]
"Even though standard pipeline QA systems like AskMR (Banko et al., 2002) have been recently revisited (Tsai et al., 2015), the best published results on TRECQA and WIKIQA have been obtained by either convolutional neural networks (Santos et al., 2016; Yin and Schütze, 2015; Wang et al., 2016) or recurrent neural networks (Miao et al., 2015)— both usually with attention mechanisms inspired by (Bahdanau et al., 2015).",2 Related Work,[0],[0]
"In this work, we introduce KV-MemNNs, a Memory Network model that operates a symbolic memory structured as (key, value) pairs.",2 Related Work,[0],[0]
Such structured memory is not employed in any existing attention-based neural network architecture for QA.,2 Related Work,[0],[0]
"As we will show, it gives the model greater flexibility for encoding knowledge sources and helps shrink the gap between directly reading documents and answering from a KB.",2 Related Work,[0],[0]
"The Key-Value Memory Network model is based on the Memory Network (MemNNs) model (Weston et al., 2015; Sukhbaatar et al., 2015) which has proven useful for a variety of document reading and question answering tasks: for reading children’s books and answering questions about them (Hill et al., 2016), for complex reasoning over sim-
ulated stories (Weston et al., 2016) and for utilizing KBs to answer questions (Bordes et al., 2015).
",3 Key-Value Memory Networks,[0],[0]
Key-value paired memories are a generalization of the way context (e.g. knowledge bases or documents to be read) are stored in memory.,3 Key-Value Memory Networks,[0],[0]
The lookup (addressing) stage is based on the key memory while the reading stage (giving the returned result) uses the value memory.,3 Key-Value Memory Networks,[0],[0]
This gives both (i) greater flexibility for the practitioner to encode prior knowledge about their task; and (ii) more effective power in the model via nontrivial transforms between key and value.,3 Key-Value Memory Networks,[0],[0]
"The key should be designed with features to help match it to the question, while the value should be designed with features to help match it to the response (answer).",3 Key-Value Memory Networks,[0],[0]
An important property of the model is that the entire model can be trained with key-value transforms while still using standard backpropagation via stochastic gradient descent.,3 Key-Value Memory Networks,[0],[0]
Our model is based on the end-to-end Memory Network architecture of Sukhbaatar et al. (2015).,3.1 Model Description,[0],[0]
"A high-level view of both models is as follows: one defines a memory, which is a possibly very large array of slots which can encode both long-term and short-term context.",3.1 Model Description,[0],[0]
"At test time one is given a query (e.g. the question in QA tasks), which is used to iteratively address and read from the memory (these iterations are also referred to as “hops”) looking for relevant information to answer the question.",3.1 Model Description,[0],[0]
"At each step, the collected information from the memory is cumulatively added to the original query to build context for the next round.",3.1 Model Description,[0],[0]
"At the last iteration, the final
retrieved context and the most recent query are combined as features to predict a response from a list of candidates.
",3.1 Model Description,[0],[0]
"Figure 1 illustrates the KV-MemNN model architecture.
",3.1 Model Description,[0],[0]
"In KV-MemNNs we define the memory slots as pairs of vectors (k1, v1) . . .",3.1 Model Description,[0],[0]
", (kM , vM ) and denote the question x.",3.1 Model Description,[0],[0]
"The addressing and reading of the memory involves three steps:
• Key Hashing: the question can be used to preselect a small subset of the possibly large array.",3.1 Model Description,[0],[0]
"This is done using an inverted index that finds a subset (kh1 , vh1), . . .",3.1 Model Description,[0],[0]
", (khN , vhN ) of memories of size N where the key shares at least one word with the question with frequency < F = 1000 (to ignore stop words), following Dodge et al. (2016).",3.1 Model Description,[0],[0]
"More sophisticated retrieval schemes could be used here, see e.g. Manning et al. (2008),
• Key Addressing: during addressing, each candidate memory is assigned a relevance probability by comparing the question to each key:
phi = Softmax(AΦX(x) ·AΦK(khi))
where Φ· are feature maps of dimension D, A is a d×D matrix and Softmax(zi) = ezi/ ∑ j e
zj .",3.1 Model Description,[0],[0]
"We discuss choices of feature map in Sec. 3.2.
",3.1 Model Description,[0],[0]
"• Value Reading: in the final reading step, the values of the memories are read by taking their weighted sum using the addressing probabilities,
and the vector o is returned:
o = ∑
i
phiAΦV (vhi) .
",3.1 Model Description,[0],[0]
The memory access process is conducted by the “controller” neural network using q = AΦX(x) as the query.,3.1 Model Description,[0],[0]
"After receiving the result o, the query is updated with q2 = R1(q + o) where R is a d × d matrix.",3.1 Model Description,[0],[0]
"The memory access is then repeated (specifically, only the addressing and reading steps, but not the hashing), using a different matrix",3.1 Model Description,[0],[0]
"Rj on each hop, j. The key addressing equation is transformed accordingly to use the updated query:
phi = Softmax(q > j+1AΦK(khi)) .
",3.1 Model Description,[0],[0]
The motivation for this is that new evidence can be combined into the query to focus on and retrieve more pertinent information in subsequent accesses.,3.1 Model Description,[0],[0]
"Finally, after a fixed number H hops, the resulting state of the controller is used to compute a final prediction over the possible outputs:
â = argmaxi=1,...,CSoftmax(q > H+1BΦY (yi))
where yi are the possible candidate outputs, e.g. all the entities in the KB, or all possible candidate answer sentences in the case of a dataset like WIKIQA (see Sec. 5.2).",3.1 Model Description,[0],[0]
The d×D matrix B can also be constrained to be identical to A.,3.1 Model Description,[0],[0]
"The whole network is trained end-to-end, and the model learns to perform the iterative accesses to output the desired target a by minimizing a standard cross-entropy loss between â and the correct answer a. Backpropagation and stochastic gradient descent are thus used to learn the matrices A,B and R1, . . .",3.1 Model Description,[0],[0]
", RH .
To obtain the standard End-To-End Memory Network of Sukhbaatar et al. (2015) one can simply set the key and value to be the same for all memories.",3.1 Model Description,[0],[0]
"Hashing was not used in that paper, but is important for computational efficiency for large memory sizes, as already shown in Dodge et al. (2016).",3.1 Model Description,[0],[0]
We will now go on to describe specific applications of key-value memories for the task of reading KBs or documents.,3.1 Model Description,[0],[0]
There are a variety of ways to employ key-value memories that can have important effects on overall performance.,3.2 Key-Value Memories,[0],[0]
"The ability to encode prior knowledge in
this way is an important component of KV-MemNNs, and we are free to define ΦX ,ΦY ,ΦK and ΦV for the query, answer, keys and values respectively.",3.2 Key-Value Memories,[0],[0]
"We now describe several possible variants of ΦK and ΦV that we tried in our experiments, for simplicity we kept ΦX and ΦY fixed as bag-of-words representations.
",3.2 Key-Value Memories,[0],[0]
KB Triple Knowledge base entries have a structure of triple “subject relation object” (see Table 1 for examples).,3.2 Key-Value Memories,[0],[0]
"The representation we consider is simple: the key is composed of the left-hand side entity (subject) and the relation, and the value is the right-hand side entity (object).",3.2 Key-Value Memories,[0],[0]
We double the KB and consider the reversed relation as well (e.g. we now have two triples “Blade Runner directed_by Ridley Scott” and “Ridley Scott !,3.2 Key-Value Memories,[0],[0]
directed_by Blade Runner” where !,3.2 Key-Value Memories,[0],[0]
directed_by is a different entry in the dictionary than directed_by).,3.2 Key-Value Memories,[0],[0]
Having the entry both ways round is important for answering different kinds of questions (“Who directed Blade Runner?” vs. “What did Ridley Scott direct?”).,3.2 Key-Value Memories,[0],[0]
"For a standard MemNN that does not have key-value pairs the whole triple has to be encoded into the same memory slot.
",3.2 Key-Value Memories,[0],[0]
Sentence Level,3.2 Key-Value Memories,[0],[0]
"For representing a document, one can split it up into sentences, with each memory slot encoding one sentence.",3.2 Key-Value Memories,[0],[0]
Both the key and the value encode the entire sentence as a bag-of-words.,3.2 Key-Value Memories,[0],[0]
"As the key and value are the same in this case, this is identical to a standard MemNN and this approach has been used in several papers (Weston et al., 2016; Dodge et al., 2016).
",3.2 Key-Value Memories,[0],[0]
Window Level Documents are split up into windows of W words; in our tasks we only include windows where the center word is an entity.,3.2 Key-Value Memories,[0],[0]
Windows are represented using bag-of-words.,3.2 Key-Value Memories,[0],[0]
"Window representations for MemNNs have been shown to work well previously (Hill et al., 2016).",3.2 Key-Value Memories,[0],[0]
"However, in Key-Value MemNNs we encode the key as the entire window, and the value as only the center word, which is not possible in the MemNN architecture.",3.2 Key-Value Memories,[0],[0]
"This makes sense because the entire window is more likely to be pertinent as a match for the question (as the key), whereas the entity at the center is more pertinent as a match for the answer (as the value).",3.2 Key-Value Memories,[0],[0]
"We will compare these approaches in our experiments.
",3.2 Key-Value Memories,[0],[0]
"Window + Center Encoding Instead of representing the window as a pure bag-of-words, thus mixing
the window center with the rest of the window, we can also encode them with different features.",3.2 Key-Value Memories,[0],[0]
"Here, we double the size, D, of the dictionary and encode the center of the window and the value using the second dictionary.",3.2 Key-Value Memories,[0],[0]
"This should help the model pick out the relevance of the window center (more related to the answer) as compared to the words either side of it (more related to the question).
",3.2 Key-Value Memories,[0],[0]
Window + Title,3.2 Key-Value Memories,[0],[0]
The title of a document is commonly the answer to a question that relates to the text it contains.,3.2 Key-Value Memories,[0],[0]
For example “What did Harrison Ford star in?” can be (partially) answered by the Wikipedia document with the title “Blade Runner”.,3.2 Key-Value Memories,[0],[0]
"For this reason, we also consider a representation where the key is the word window as before, but the value is the document title.",3.2 Key-Value Memories,[0],[0]
"We also keep all the standard (window, center) key-value pairs from the window-level representation as well, thus doubling the number of memory slots in comparison.",3.2 Key-Value Memories,[0],[0]
"To differentiate the two keys with different values we add an extra feature “_window_” or “_title_” to the key, depending on the value.",3.2 Key-Value Memories,[0],[0]
The “_title_” version also includes the actual movie title in the key.,3.2 Key-Value Memories,[0],[0]
This representation can be combined with center encoding.,3.2 Key-Value Memories,[0],[0]
Note that this representation is inherently specific to datasets in which there is an apparent or meaningful title for each document.,3.2 Key-Value Memories,[0],[0]
The WIKIMOVIES benchmark consists of questionanswer pairs in the domain of movies.,4 The WikiMovies Benchmark,[0],[0]
It was built with the following goals in mind: (i) machine learning techniques should have ample training examples for learning; and (ii) one can analyze easily the performance of different representations of knowledge and break down the results by question type.,4 The WikiMovies Benchmark,[0],[0]
The dataset can be downloaded from http://fb.ai/babi.,4 The WikiMovies Benchmark,[0],[0]
We construct three forms of knowledge representation: (i),4.1 Knowledge Representations,[0],[0]
Doc: raw Wikipedia documents consisting of the pages of the movies mentioned; (ii) KB: a classical graph-based KB consisting of entities and relations created from the Open Movie Database (OMDb) and MovieLens; and (iii) IE: information extraction performed on the Wikipedia pages to build a KB in a similar form as (ii).,4.1 Knowledge Representations,[0],[0]
"We take care to construct
QA pairs such that they are all potentially answerable from either the KB from (ii) or the original Wikipedia documents from (i) to eliminate data sparsity issues.",4.1 Knowledge Representations,[0],[0]
"However, it should be noted that the advantage of working from raw documents in real applications is that data sparsity is less of a concern than for a KB, while on the other hand the KB has the information already parsed in a form amenable to manipulation by machines.",4.1 Knowledge Representations,[0],[0]
"This dataset can help analyze what methods we need to close the gap between all three settings, and in particular what are the best methods for reading documents when a KB is not available.",4.1 Knowledge Representations,[0],[0]
"A sample of the dataset is shown in Table 1.
",4.1 Knowledge Representations,[0],[0]
Doc We selected a set of Wikipedia articles about movies by identifying a set of movies from OMDb2 that had an associated article by title match.,4.1 Knowledge Representations,[0],[0]
We keep the title and the first section (before the contents box) for each article.,4.1 Knowledge Representations,[0],[0]
"This gives∼17k documents (movies) which comprise the set of documents our models will read from in order to answer questions.
2 http://beforethecode.com/projects/omdb/download.aspx
KB",4.1 Knowledge Representations,[0],[0]
Our set of movies were also matched to the MovieLens dataset3.,4.1 Knowledge Representations,[0],[0]
"We built a KB using OMDb and MovieLens metadata with entries for each movie and nine different relation types: director, writer, actor, release year, language, genre, tags, IMDb rating and IMDb votes, with ∼10k related actors, ∼6k directors and∼43k entities in total.",4.1 Knowledge Representations,[0],[0]
The KB is stored as triples; see Table 1 for examples.,4.1 Knowledge Representations,[0],[0]
"IMDb ratings and votes are originally real-valued but are binned and converted to text (“unheard of”, “unknown”, “well known”, “highly watched”, “famous”).",4.1 Knowledge Representations,[0],[0]
"We finally only retain KB triples where the entities also appear in the Wikipedia articles4 to try to guarantee that all QA pairs will be equally answerable by either the KB or Wikipedia document sources.
",4.1 Knowledge Representations,[0],[0]
IE,4.1 Knowledge Representations,[0],[0]
"As an alternative to directly reading documents, we explore leveraging information extraction techniques to transform documents into a KB format.",4.1 Knowledge Representations,[0],[0]
An IE-KB representation has attractive properties such as more precise and compact expressions of facts and logical key-value pairings based on subjectverb-object groupings.,4.1 Knowledge Representations,[0],[0]
This can come at the cost of lower recall due to malformed or completely missing triplets.,4.1 Knowledge Representations,[0],[0]
For IE we use standard open-source software followed by some task-specific engineering to improve the results.,4.1 Knowledge Representations,[0],[0]
"We first employ coreference resolution via the Stanford NLP Toolkit (Manning et al., 2014) to reduce ambiguity by replacing pronominal (“he”, “it”) and nominal (“the film”) references with their representative entities.",4.1 Knowledge Representations,[0],[0]
"Next we use the SENNA semantic role labeling tool (Collobert et al., 2011) to uncover the grammatical structure of each sentence and pair verbs with their arguments.",4.1 Knowledge Representations,[0],[0]
"Each triplet is cleaned of words that are not recognized entities, and lemmatization is done to collapse different inflections of important task-specific verbs to one form (e.g. stars, starring, star→ starred).",4.1 Knowledge Representations,[0],[0]
"Finally, we append the movie title to each triple similar to the “Window + Title” representation of Sec. 3.2, which improved results.",4.1 Knowledge Representations,[0],[0]
"Within the dataset’s more than 100,000 questionanswer pairs, we distinguish 13 classes of question
3 http://grouplens.org/datasets/movielens/
4The dataset also includes the slightly larger version without this constraint.
",4.2 Question-Answer Pairs,[0],[0]
corresponding to different kinds of edges in our KB.,4.2 Question-Answer Pairs,[0],[0]
"They range in scope from specific—such as actor to movie: “What movies did Harrison Ford star in?” and movie to actors: “Who starred in Blade Runner?”—to more general, such as tag to movie: “Which films can be described by dystopian?”; see Table 4 for the full list.",4.2 Question-Answer Pairs,[0],[0]
"For some question there can be multiple correct answers.
",4.2 Question-Answer Pairs,[0],[0]
"Using SimpleQuestions (Bordes et al., 2015), an existing open-domain question answering dataset based on Freebase, we identified the subset of questions posed by human annotators that covered our question types.",4.2 Question-Answer Pairs,[0],[0]
We created our question set by substituting the entities in those questions with entities from all of our KB triples.,4.2 Question-Answer Pairs,[0],[0]
"For example, if the original question written by an annotator was “What movies did Harrison Ford star in?”, we created a pattern “What movies did [@actor] star in?”, which we substitute for any other actors in our set, and repeat this for all annotations.",4.2 Question-Answer Pairs,[0],[0]
"We split the questions into disjoint training, development and test sets with ∼96k, 10k and 10k examples, respectively.",4.2 Question-Answer Pairs,[0],[0]
The same question (even worded differently) cannot appear in both train and test sets.,4.2 Question-Answer Pairs,[0],[0]
"Note that this is much larger than most existing datasets; for example, the WIKIQA dataset (Yang et al., 2015) for which we also conduct experiments in Sec.",4.2 Question-Answer Pairs,[0],[0]
5.2 has only ∼1000 training pairs.,4.2 Question-Answer Pairs,[0],[0]
This section describes our experiments on WIKIMOVIES and WIKIQA.,5 Experiments,[0],[0]
We conducted experiments on the WIKIMOVIES dataset described in Sec. 4.,5.1 WikiMovies,[0],[0]
"Our main goal is to compare the performance of KB, IE and Wikipedia (Doc) sources when trying varying learning methods.",5.1 WikiMovies,[0],[0]
"We compare four approaches: (i) the QA system of Bordes et al. (2014) that performs well on existing datasets WebQuestions (Berant et al., 2013) and SimpleQuestions (Bordes et al., 2015) that use KBs only; (ii) supervised embeddings that do not make use of a KB at all but learn question-to-answer embeddings directly and hence act as a sanity check (Dodge et al., 2016); (iii) Memory Networks; and (iv) Key-Value Memory Networks.",5.1 WikiMovies,[0],[0]
"Performance is reported using the accuracy of the top hit (single answer) over all possible answers (all entities), i.e. the hits@1 metric measured in percent.",5.1 WikiMovies,[0],[0]
"In all cases hyperparameters are optimized on the development set, including the memory representations of Sec. 3.2 for MemNNs and KV-MemNNs.",5.1 WikiMovies,[0],[0]
"As MemNNs do not support key-value pairs, we concatenate key and value together when they differ instead.
",5.1 WikiMovies,[0],[0]
The main results are given in Table 2.,5.1 WikiMovies,[0],[0]
"The QA system of Bordes et al. (2014) outperforms Supervised Embeddings and Memory Networks for KB and IE-based KB representations, but is designed to work with a KB, not with documents (hence the N/A in that column).",5.1 WikiMovies,[0],[0]
"However, Key-Value Memory Networks outperform all other methods on all three data source types.",5.1 WikiMovies,[0],[0]
"Reading from Wikipedia documents directly (Doc) outperforms an IE-based KB (IE), which is an encouraging result towards automated machine reading though a gap to a humanannotated KB still remains (93.9 vs. 76.2).",5.1 WikiMovies,[0],[0]
The best memory representation for directly reading documents uses “Window-level + Center Encoding + Title” (W = 7 and H = 2); see Table 3 for a comparison of results for different representation types.,5.1 WikiMovies,[0],[0]
"Both center encoding and title features help the windowlevel representation, while sentence-level is inferior.
",5.1 WikiMovies,[0],[0]
QA Breakdown A breakdown by question type comparing the different data sources for KVMemNNs is given in Table 4.,5.1 WikiMovies,[0],[0]
"IE loses out especially
to Doc (and KB) on Writer, Director and Actor to Movie, perhaps because coreference is difficult in these cases – although it has other losses elsewhere too.",5.1 WikiMovies,[0],[0]
"Note that only 56% of subject-object pairs in IE match the triples in the original KB, so losses are expected.",5.1 WikiMovies,[0],[0]
"Doc loses out to KB particularly on Tag to Movie, Movie to Tags, Movie to Writer and Movie to Actors.",5.1 WikiMovies,[0],[0]
Tag questions are hard because they can reference more or less any word in the entire Wikipedia document; see Table 1.,5.1 WikiMovies,[0],[0]
"Movie to Writer/Actor are hard because there is likely only one or a few references to the answer across all documents, whereas for Writer/Actor to Movie there are more possible answers to find.
",5.1 WikiMovies,[0],[0]
"KB vs. Synthetic Document Analysis To further understand the difference between using a KB versus reading documents directly, we conducted an experiment where we constructed synthetic documents using the KB.",5.1 WikiMovies,[0],[0]
"For a given movie, we use a simple grammar to construct a synthetic “Wikipedia” doc-
ument based on the KB triples: for each relation type we have a set of template phrases (100 in total) used to generate the fact, e.g. “Blade Runner came out in 1982” for the entry BLADE RUNNER RELEASE_YEAR 1982.",5.1 WikiMovies,[0],[0]
"We can then parameterize the complexity of our synthetic documents: (i) using one template, or all of them; (ii) using conjunctions to combine facts into single sentences or not; and (iii) using coreference between sentences where we replace the movie name with “it”.5 The purpose of this experiment is to find which aspects are responsible for the gap in performance to a KB.",5.1 WikiMovies,[0],[0]
The results are given in Table 5.,5.1 WikiMovies,[0],[0]
"They indicate that some of the loss (93.9% for KB to 82.9% for One Template Sentence) in performance is due directly to representing in sentence form, making the subject, relation and object harder to extract.",5.1 WikiMovies,[0],[0]
Moving to a larger number of templates does not deteriorate performance much (80%).,5.1 WikiMovies,[0],[0]
The remaining performance drop seems to be split roughly equally between conjunctions (74%) and coreference (76%).,5.1 WikiMovies,[0],[0]
The hardest synthetic dataset combines these (All Templates + Conj.,5.1 WikiMovies,[0],[0]
+ Coref.),5.1 WikiMovies,[0],[0]
and is actually harder than using the real Wikipedia documents (72.5% vs. 76.2%).,5.1 WikiMovies,[0],[0]
"This is possibly because the amount of conjunctions and coreferences we make are artificially too high (50% and 80% of the time, respectively).",5.1 WikiMovies,[0],[0]
"WIKIQA (Yang et al., 2015) is an existing dataset for answer sentence selection using Wikipedia as the knowledge source.",5.2 WikiQA,[0],[0]
"The task is, given a question, to select the sentence coming from a Wikipedia document that best answers the question, where performance is measured using mean average preci-
5This data is also part of the WIKIMOVIES benchmark.
",5.2 WikiQA,[0],[0]
sion (MAP) and mean reciprocal rank (MRR) of the ranked set of answers.,5.2 WikiQA,[0],[0]
"The dataset uses a pre-built information retrieval step and hence provides a fixed set of candidate sentences per question, so systems do not have to consider ranking all of Wikipedia.",5.2 WikiQA,[0],[0]
"In contrast to WIKIMOVIES, the training set size is small (∼1000 examples) while the topic is much more broad (all of Wikipedia, rather than just movies) and the questions can only be answered by reading the documents, so no comparison to the use of KBs can be performed.",5.2 WikiQA,[0],[0]
"However, a wide range of methods have already been tried on WIKIQA, thus providing a useful benchmark to test if the same results found on WIKIMOVIES carry across to WIKIQA, in particular the performance of Key-Value Memory Networks.
",5.2 WikiQA,[0],[0]
"Due to the size of the training set, following many other works (Yang et al., 2015; Santos et al., 2016; Miao et al., 2015) we pre-trained the word vectors (matrices A and B which are constrained to be identical) before training KV-MemNNs.",5.2 WikiQA,[0],[0]
"We employed Supervised Embeddings (Dodge et al., 2016) for that goal, training on all of Wikipedia while treating the input as a random sentence and the target as the subsequent sentence.",5.2 WikiQA,[0],[0]
"We then trained KV-MemNNs with dropout regularization: we sample words from the question, memory representations and the answers, choosing the dropout rate using the development set.",5.2 WikiQA,[0],[0]
"Finally, again following other successful methods (Yin and Schütze, 2015), we combine our approach with exact matching word features between question and answers.",5.2 WikiQA,[0],[0]
Key hashing was not used as candidates were already pre-selected.,5.2 WikiQA,[0],[0]
"To represent the memories, we used the Window-Level representation (the best choice on the dev set was W = 7) as the key and the whole sentence as the value, as the value should match the answer which in this case is a sentence.",5.2 WikiQA,[0],[0]
"Additionally, in the representation all numbers in the text and the phrase “how many” in the question were replaced with the feature “_number_”.",5.2 WikiQA,[0],[0]
"The best choice of hops was also H = 2 for KV-MemNNs.
",5.2 WikiQA,[0],[0]
The results are given in Table 6.,5.2 WikiQA,[0],[0]
"Key-Value Memory Networks outperform a large set of other methods, although the results of the L.D.C. method of (Wang et al., 2016) are very similar.",5.2 WikiQA,[0],[0]
"Memory Networks, which cannot easily pair windows to sentences, perform much worse, highlighting the importance of key-value memories.",5.2 WikiQA,[0],[0]
"We studied the problem of directly reading documents in order to answer questions, concentrating our analysis on the gap between such direct methods and using human-annotated or automatically constructed KBs.",6 Conclusion,[0],[0]
"We presented a new model, Key-Value Memory Networks, which helps bridge this gap, outperforming several other methods across two datasets, WIKIMOVIES and WIKIQA.",6 Conclusion,[0],[0]
"However, some gap in performance still remains.",6 Conclusion,[0],[0]
WIKIMOVIES serves as an analysis tool to shed some light on the causes.,6 Conclusion,[0],[0]
"Future work should try to close this gap further.
",6 Conclusion,[0],[0]
Key-Value Memory Networks are versatile models for reading documents or KBs and answering questions about them—allowing to encode prior knowledge about the task at hand in the key and value memories.,6 Conclusion,[0],[0]
"These models could be applied to storing and reading memories for other tasks as well, and future work should try them in other domains, such as in a full dialog setting.",6 Conclusion,[0],[0]
Directly reading documents and being able to answer questions from them is an unsolved challenge.,abstractText,[0],[0]
"To avoid its inherent difficulty, question answering (QA) has been directed towards using Knowledge Bases (KBs) instead, which has proven effective.",abstractText,[0],[0]
"Unfortunately KBs often suffer from being too restrictive, as the schema cannot support certain types of answers, and too sparse, e.g. Wikipedia contains much more information than Freebase.",abstractText,[0],[0]
"In this work we introduce a new method, Key-Value Memory Networks, that makes reading documents more viable by utilizing different encodings in the addressing and output stages of the memory read operation.",abstractText,[0],[0]
"To compare using KBs, information extraction or Wikipedia documents directly in a single framework we construct an analysis tool, WIKIMOVIES, a QA dataset that contains raw text alongside a preprocessed KB, in the domain of movies.",abstractText,[0],[0]
Our method reduces the gap between all three settings.,abstractText,[0],[0]
It also achieves state-of-the-art results on the existing WIKIQA benchmark.,abstractText,[0],[0]
Key-Value Memory Networks for Directly Reading Documents,title,[0],[0]
"Proceedings of the SIGDIAL 2017 Conference, pages 37–49, Saarbrücken, Germany, 15-17 August 2017. c©2017 Association for Computational Linguistics",text,[0],[0]
"With the success of new speech-based humancomputer interfaces, there is a great need for effective task-oriented dialogue agents that can handle everyday tasks such as scheduling events and booking hotels.",1 Introduction,[0],[0]
Current commercial dialogue agents are often brittle pattern-matching systems which are unable to maintain the kind of flexible conversations that people desire.,1 Introduction,[0],[0]
"Neural dialogue agents present one of the most promising avenues for leveraging dialogue corpora to build statistical models directly from data by using powerful distributed representations (Bordes and Weston, 2016; Wen et al., 2016b; Dhingra et al., 2016).
",1 Introduction,[0],[0]
"While this work has been somewhat successful, these task-oriented neural dialogue models suffer from a number of problems: 1) They struggle to effectively reason over and incorporate knowledge base information while still preserving their endto-end trainability and 2)",1 Introduction,[0],[0]
"They often require explicitly modelling user dialogues with belief trackers and dialogue state information, which necessitates additional data annotation and also breaks differentiability.
",1 Introduction,[0],[0]
"To address some of the modelling issues in previous neural dialogue agents, we introduce a new architecture called the Key-Value Retrieval Network.",1 Introduction,[0],[0]
"This model augments existing recurrent network architectures with an attention-based key-value retrieval mechanism over the entries of a knowledge base, which is inspired by recent work on key-value memory networks (Miller et al., 2016).",1 Introduction,[0],[0]
"By doing so, it is able to learn how to extract useful information from a knowledge base directly from data in an end-to-end fashion, with-
37
out the need for explicit training of belief or intent trackers as is done in traditional task-oriented dialogue systems.",1 Introduction,[0],[0]
"The architecture has no dependence on the specifics of the data domain, learning how to appropriately incorporate world knowledge into its dialogue utterances via attention over the key-value entries of the underlying knowledge base.
",1 Introduction,[0],[0]
"In addition, we introduce and make publicly available a new corpus of 3,031 dialogues spanning three different domain types in the incar personal assistant space: calendar scheduling, weather information retrieval, and point-ofinterest navigation.",1 Introduction,[0],[0]
The dialogues are grounded through knowledge bases.,1 Introduction,[0],[0]
This makes them ideal for building dialogue architectures that seamlessly reason over world knowledge.,1 Introduction,[0],[0]
"The multi-domain nature of the dialogues in the corpus also makes this dataset an apt test bed for generalizability of modelling architectures.1
The main contributions of our work are therefore two-fold: 1) We introduce the Key-Value Retrieval Network, a highly performant neural taskoriented dialogue agent that is able to smoothly incorporate information from underlying knowledge bases through a novel key-value retrieval mechanism.",1 Introduction,[0],[0]
"Unlike other dialogue agents which only rely on prior dialogue history for generation (Kannan et al., 2016; Eric and Manning, 2017), our architecture is able to access and use database-style information, while still retaining the text generation advantages of recent neural models.",1 Introduction,[0],[0]
"By doing so, our model outperforms a competitive rulebased system and other baseline neural models on a number of automatic metrics as well as human evaluation.",1 Introduction,[0],[0]
2),1 Introduction,[0],[0]
We release a new publicly-available dialogue corpus across three distinct domains in the in-car personal assistant space that we hope will help further work on task-oriented dialogue agents.,1 Introduction,[0],[0]
"While recent neural dialogue models have explicitly modelled dialogue state through belief and user intent trackers (Wen et al., 2016b; Dhingra et al., 2016; Henderson et al., 2014b), we choose instead to rely on learned neural representations for implicit modelling of dialogue state, forming
1The data is available for download at https://nlp.stanford.edu/blog/a-new-multi-turn-multidomain-task-oriented-dialogue-dataset/
a truly end-to-end trainable system.",2 Key-Value Retrieval Networks,[0],[0]
Our model starts with an encoder-decoder sequence architecture and is further augmented with an attentionbased retrieval mechanism that effectively reasons over a key-value representation of the underlying knowledge base.,2 Key-Value Retrieval Networks,[0],[0]
We describe each component of our model in the subsequent sections.,2 Key-Value Retrieval Networks,[0],[0]
"Given a dialogue between a user (u) and a system (s), we represent the dialogue utterances as {(u1, s1), (u2, s2), . . .",2.1 Encoder,[0],[0]
", (uk, sk)} where k denotes the number of turns in the dialogue.",2.1 Encoder,[0],[0]
"At the ith turn of the dialogue, we encode the aggregated dialogue context composed of the tokens of (u1, s1, . . .",2.1 Encoder,[0],[0]
", si−1, ui).",2.1 Encoder,[0],[0]
"Letting x1, . . .",2.1 Encoder,[0],[0]
", xm denote these tokens, we first embed these tokens using a trained embedding function φemb that maps each token to a fixed-dimensional vector.",2.1 Encoder,[0],[0]
"These mappings are fed into the encoder to produce contextsensitive hidden representations h1, . . .",2.1 Encoder,[0],[0]
", hm, by repeatedly applying the recurrence:
hi = LSTM(φemb(xi), hi−1) (1)
where the recurrence uses a long-short-term memory unit, as described by (Hochreiter and Schmidhuber, 1997).",2.1 Encoder,[0],[0]
The vanilla sequence-to-sequence decoder predicts the tokens of the ith system response si by first computing decoder hidden states via the recurrent unit.,2.2 Decoder,[0],[0]
"We denote h̃1, . . .",2.2 Decoder,[0],[0]
", h̃n as the hidden states of the decoder and y1, . . .",2.2 Decoder,[0],[0]
", yn as the output tokens.",2.2 Decoder,[0],[0]
"We extend this decoder with an attentionbased model (Bahdanau et al., 2015; Luong et al., 2015a), where, at every time step t of the decoding, an attention score ati is computed for each hidden state hi of the encoder, using the attention mechanism of (Vinyals et al., 2015).",2.2 Decoder,[0],[0]
"Formally this attention can be described by the following equations:
uti = w T tanh(W2 tanh(W1[hi, h̃t])))",2.2 Decoder,[0],[0]
"(2) ati = Softmax(u t i) (3)
h̃′t = m∑
i=1
atihi (4)
",2.2 Decoder,[0],[0]
"ot = U [h̃t, h̃′t] (5) yt = Softmax(ot) (6)
where U , W1, W2, and w are trainable parameters of the model and ot represents the logits over the tokens of the output vocabulary V .",2.2 Decoder,[0],[0]
"In (2) above, the attention logit on hi is computed via a twolayer MLP function with a tanh nonlinearity at the intermediate layers.",2.2 Decoder,[0],[0]
"During training, the next token yt is predicted so as to maximize the loglikelihood of the correct output sequence given the input sequence.",2.2 Decoder,[0],[0]
"Recently, some neural task-oriented dialogue agents that query underlying knowledge bases (KBs) and extract relevant entities either do the following: 1) create and execute well-formatted API calls to the KB, operations which require intermediate supervision in the form of training slot trackers and which break differentiability (Wen et al., 2016b), or 2) softly attend to the KB and combine this probability distribution with belief trackers as state input for a reinforcement learning policy (Dhingra et al., 2016).",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"We choose to build off the latter approach as it fits nicely into the end-to-end trainable framework of sequenceto-sequence modelling, though we are in a supervised learning setting and we do away with explicit representations of belief trackers or dialogue state.
",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"For storing the KB of a given dialogue, we take inspiration from the work of (Miller et al., 2016) which found that a key-value structured memory allowed for efficient machine reading of documents.",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"We store every entry of our KB using a (subject, relation, object) representation.",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"In our representation a KB entry from the dialogue in Figure 1 such as (event=dinner, time=8pm, date=the 13th, party=Ana, agenda=“-”) would be normalized into four separate triples of the form (dinner, time, 8pm).",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
Every KB has at most 230 normalized triples.,2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"This formalism is similar to a neo-Davidsonian or RDF-style representation of events.
",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"Recent literature has shown that incorporating a copying mechanism into neural architectures improves performance on various sequenceto-sequence tasks (Jia and Liang, 2016; Gu et al., 2016; Ling et al., 2016; Gulcehre et al., 2016; Eric and Manning, 2017).",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"We build off this intuition in the following way: at every timestep of decoding, we take the decoder hidden state and compute an attention score with the key of each normalized
KB entry.",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"For our purposes, the key of an entry corresponds to the sum of the word embeddings of the subject (meeting) and relation (time).",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
The attention logits then become the logits of the value for that KB entry.,2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"For our KB attentions, we replace the embedding of the value with a canonicalized token representation.",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"For example, the value 5pm is replaced with the canonicalized representation meeting time.",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"At runtime, if we decode this canonicalized representation token, we convert it into the actual value of the KB entry (5pm in our running example) through a KB lookup.",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
Note that this means we are expanding our original output vocabulary to |V,2.3 Key-Value Knowledge Base Retrieval,[0],[0]
| + n,2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"where n is the number of separate canonical key representation KB entries.
",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"In particular, let kj denote the word embedding of the key of our j th normalized KB entry.",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
We can now formalize the decoding for our KB attentionbased retrieval.,2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"Assume that we have m distinct triples in our KB and that we are in the tth timestep of decoding:
utj = r T",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
tanh(W ′2,2.3 Key-Value Knowledge Base Retrieval,[0],[0]
tanh(W ′,2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"1[kj , h̃t])))",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"(7) ot = U [h̃t, h̃′t] + v̄ t (8) yt = Softmax(ot) (9)
where r, W ′1, and W ′2 are trainable parameters.",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"In (8) above, v̄t is a sparse vector with length |V",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
| + n.,2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"Within v̄t, the entry for the value embedding vj corresponding to the key kj is equal to the logit score utj on kj .",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"Hence, the m entries of v̄t corresponding to the values in the KB are non-zero, whereas the remaining entries corresponding to the original vocabulary tokens are 0.",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
This sparse vector contains our aggregated KB logit scores which we combine with the original logits to get a modified ot.,2.3 Key-Value Knowledge Base Retrieval,[0],[0]
We then select the argmax token as input to the next timestep.,2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"This description seeks to capture the intuition that in response to the query What time is my meeting, we want the model to put a high attention weight on the key representation for the (meeting, time, 5pm)",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"KB triple, which should then lead the model to favor outputting the value token at the given timestep.",2.3 Key-Value Knowledge Base Retrieval,[0],[0]
We provide a visualization of the KeyValue Retrieval Network in Figure 2.,2.3 Key-Value Knowledge Base Retrieval,[0],[0]
"In an effort to further work in multi-domain dialogue agents, we built a corpus of multi-turn
dialogues in three distinct domains: calendar scheduling, weather information retrieval, and point-of-interest navigation.","3 A Multi-Turn, Multi-Domain Dialogue Dataset",[0],[0]
"While these domains are different, they are all relevant to the overarching theme of tasks that users would expect of a sophisticated in-car personal assistant.","3 A Multi-Turn, Multi-Domain Dialogue Dataset",[0],[0]
"The data for the multi-turn dialogues was collected using a Wizard-of-Oz scheme inspired by that of (Wen et al., 2016b).",3.1 Data Collection,[0],[0]
"In our scheme, users had two potential modes they could play: Driver and Car Assistant.",3.1 Data Collection,[0],[0]
"In the Driver mode, users were presented with a task that listed certain information they were trying to extract from the Car Assistant as well as the dialogue history exchanged between Driver and Car Assistant up to that point.",3.1 Data Collection,[0],[0]
An example task presented could be: You want to find what the temperature is like in San Mateo over the next two days.,3.1 Data Collection,[0],[0]
"The Driver was then only responsible for contributing a single line of dialogue that appropriately continued the discourse given the prior dialogue history and the task definition.
",3.1 Data Collection,[0],[0]
"Tasks were randomly specified by selecting values (5pm, Saturday, San Francisco, etc.)",3.1 Data Collection,[0],[0]
"for three to five slots (time, date, location, etc.), de-
pending on the domain type.",3.1 Data Collection,[0],[0]
"Values specified for the slots were chosen according to a uniform distribution from a per-domain candidate set.
",3.1 Data Collection,[0],[0]
"In the Car Assistant mode, users were presented with the dialogue history exchanged up to that point in the running dialogue and a private knowledge base known only to the Car Assistant with information that could be useful for satisfying the Driver query.",3.1 Data Collection,[0],[0]
"Examples of knowledge bases could include a calendar of event information, a collection of weekly forecasts for nearby cities, or a collection of nearby points-of-interest with relevant information.",3.1 Data Collection,[0],[0]
The Car Assistant was then responsible for using this private information to provide a single utterance that progressed the user-directed dialogues.,3.1 Data Collection,[0],[0]
"The Car Assistant was also asked to fill in dialogue state information for mentioned slots and values in the dialogue history up to that point.
",3.1 Data Collection,[0],[0]
Each private knowledge base had six to seven distinct rows and five to seven attribute types.,3.1 Data Collection,[0],[0]
"The private knowledge bases used were generated by uniformly selecting a value for a given attribute type, where each attribute type had a variable number of candidate values.",3.1 Data Collection,[0],[0]
"Some knowledge bases intentionally lacked attributes to encourage diversity in discourse.
",3.1 Data Collection,[0],[0]
"During data collection, some of the dialogues
in the calendar scheduling domain did not explicitly require the use of a KB.",3.1 Data Collection,[0],[0]
"For example, in a task such as Set a meeting reminder at 3pm, we hoped to encourage dialogues that required the Car Assistant to execute a task while asking for Driver clarification on underspecified information.",3.1 Data Collection,[0],[0]
"Roughly half of the scheduling dialogues fell into this category.
",3.1 Data Collection,[0],[0]
"While specifying the attribute types and values in each task presented to the Driver allowed us to ground the subject of each dialogue with our desired entities, it would occasionally result in more mechanical discourse exchanges.",3.1 Data Collection,[0],[0]
"To encourage more naturalistic, unbiased utterances, we had users record themselves saying commands in response to underspecified visual depictions of an action a car assistant could perform.",3.1 Data Collection,[0],[0]
These commands were transcribed and then inserted as the first exchange in a given dialogue on behalf of the Driver.,3.1 Data Collection,[0],[0]
"Roughly ∼1,500 of the dialogues employed this transcribed audio command firstutterance technique.
",3.1 Data Collection,[0],[0]
241 unique workers from Amazon Mechanical Turk were anonymously recruited to use the interface we built over a period of about six days.,3.1 Data Collection,[0],[0]
Data statistics are provided in Table 1 and slot types and values are provided in Table 2.,3.1 Data Collection,[0],[0]
"A screenshot of the user-facing interfaces for the data collection, as well as a visual used to prompt user recorded commands, are provided in the supplementary material.",3.1 Data Collection,[0],[0]
Task-oriented agents for spoken dialogue systems have been the subject of extensive research effort.,4 Related Work,[0],[0]
"One line of work by (Young et al., 2013) has tackled the problem using partially observable Markov decision processes and reinforcement learning with carefully designed action spaces, though the number of distinct action states makes this approach often brittle and computationally intractable.
",4 Related Work,[0],[0]
"The recent successes of neural architectures on a number of traditional natural language processing subtasks (Bahdanau et al., 2015; Sutskever et al., 2014; Vinyals et al., 2015) have motivated investigation into dialogue agents that can effectively make use of distributed neural representations for dialogue state management, belief tracking, and response generation.",4 Related Work,[0],[0]
"Recent work by (Wen et al., 2016b) has built systems with modularly-connected representation, belief state, and generation components.",4 Related Work,[0],[0]
"These models learn to explicitly represent user intent through intermediate supervision, which breaks end-to-end trainability.",4 Related Work,[0],[0]
"Other work by (Bordes and Weston, 2016; Liu and Perez, 2016) stores dialogue context in a memory module and repeatedly queries and reasons about this context to select an adequate system response from a set of all candidate responses.
",4 Related Work,[0],[0]
"Another line of recent work has developed taskoriented models which are amenable to both supervised learning and reinforcement learning and are able to incorporate domain-specific knowledge via explicitly-provided features and model-output restrictions (Williams et al., 2017).",4 Related Work,[0],[0]
"Our model contrasts with these works in that training is done in a strictly supervised fashion via a per utterance token generative process, and the model does not need dialogue state trackers, relying instead on latent neural embeddings for accurate system response generation.
",4 Related Work,[0],[0]
"Research in task-oriented dialogue often struggles with a lack of standard, publicly available datasets.",4 Related Work,[0],[0]
"Several classical corpora have consisted of moderately-sized collections of dialogues related to travel-booking (Hemphill et al., 1990;
Bennett and Rudnicky, 2002).",4 Related Work,[0],[0]
"Another wellknown corpus is derived from a series of competitions on the task of dialogue-state tracking (Williams et al., 2013).",4 Related Work,[0],[0]
"While the competitions were designed to test systems for state tracking, recent work has chosen to repurpose this data by only using the transcripts of dialogues without state annotation for developing systems (Bordes and Weston, 2016; Williams et al., 2017).",4 Related Work,[0],[0]
"More recently, Maluuba has released a dataset of hotel and travel-booking dialogues collected in a Wizard-ofOz Scheme with elaborate semantic frames annotated (Asri et al., 2017).",4 Related Work,[0],[0]
This dataset aims to encourage research in non-linear decision-making processes that are present in task-oriented dialogues.,4 Related Work,[0],[0]
In this section we first introduce the details of the experiments and then present results from both automatic and human evaluation.,5 Experiments,[0],[0]
"For our experiments, we divided the dialogues into train/validation/test sets using a 0.8/0.1/0.1 data split and ensured that each domain type was equally represented in each of the splits.
",5.1 Details,[0],[0]
"To reduce lexical variability, in a pre-processing step, we map the variant surface expression of entities to a canonical form using named entity recognition and linking.",5.1 Details,[0],[0]
"For example, the surface form 20 Main Street is mapped to Pizza My Heart address.",5.1 Details,[0],[0]
"During inference, our model outputs the canonical forms of the entities, and so we realize their surface forms by running the system output through an inverse lexicon.",5.1 Details,[0],[0]
The inverse lexicon converts the entities back to their surface forms by sampling from a multinomial distribution with parameters of the distribution equal to the frequency count of a given surface form for an entity as observed in the training and validation data.,5.1 Details,[0],[0]
"Note that for the purposes of computing our evaluation metrics, we operate on the canonicalized forms, so that any non-deterministic variability in surface form realization does not affect the computed metrics.",5.1 Details,[0],[0]
"We trained using a cross-entropy loss and the Adam optimizer (Kingma and Ba, 2015) with learning rates sampled from the interval
[10−4, 10−3].",5.2 Hyperparameters,[0],[0]
"We applied dropout (Hinton et al., 2012) as a regularizer to the input and output of the LSTM.",5.2 Hyperparameters,[0],[0]
We also added an l2 regularization penalty on the weights of the model.,5.2 Hyperparameters,[0],[0]
"We identified hyperparameters by random search, evaluating on the held-out validation subset of the data.",5.2 Hyperparameters,[0],[0]
"Dropout keep rates were sampled from [0.8, 0.9] and the l2 coefficient was sampled from [3 · 10−6, 10−5].",5.2 Hyperparameters,[0],[0]
"We used word embeddings, hidden layer, and cell sizes with size 200.",5.2 Hyperparameters,[0],[0]
We applied gradient clipping with a clip-value of 10 to avoid gradient explosions during training.,5.2 Hyperparameters,[0],[0]
"The attention, output parameters, word embeddings, and LSTM weights were randomly initialized from a uniform unit-scaled distribution in the style of (Sussillo and Abbott, 2015).",5.2 Hyperparameters,[0],[0]
"We also added a bias of 1 to the LSTM cell forget gate in the style of (Pham et al., 2014).",5.2 Hyperparameters,[0],[0]
"We provide several baseline models for comparing performance of the Key-Value Retrieval Network:
• Rule-Based Model:",5.3 Baseline Models,[0],[0]
"This model is a traditional rule-based system with modular dialogue state trackers, KB query, and natural language generation components.",5.3 Baseline Models,[0],[0]
It first does an extensive domain-dependent keyword search in the user utterances to detect intent.,5.3 Baseline Models,[0],[0]
The user utterances are also provided to a lexicon to extract any entities mentioned.,5.3 Baseline Models,[0],[0]
"Collectively, this information forms the dialogue state up to a given point in the dialogue.",5.3 Baseline Models,[0],[0]
"This dialogue state is used to query the KB as appropriate, and the returned KB values are used to fill in predefined template system responses.
",5.3 Baseline Models,[0],[0]
"• Copy-Augmented Sequence-to-Sequence Network: This model is derived from the work of (Eric and Manning, 2017).",5.3 Baseline Models,[0],[0]
"It augments a sequence-to-sequence architecture with encoder attention, with an additional attention-based hard-copy mechanism over the KB entities mentioned in the encoder context.",5.3 Baseline Models,[0],[0]
This model does not explicitly incorporate information from the underlying KB and instead relies solely on dialogue history for system response generation.,5.3 Baseline Models,[0],[0]
"Unlike the best performing model of (Eric and Manning, 2017), we do not enhance the inputs to the encoder with additional entity type features, as we found that the
model performed worse on our data with this added mechanism.",5.3 Baseline Models,[0],[0]
"We choose this model for comparison as it is also end-to-end trainable and implicitly models dialogue state through learned neural representations, putting it in the same class of dialogue models as our key-value retrieval net.",5.3 Baseline Models,[0],[0]
This model has also been shown to be a competitive task-oriented dialogue baseline that can accurately interpret user input and act on this input through latent distributed representation.,5.3 Baseline Models,[0],[0]
We refer to this model as Copy Net in the results tables.,5.3 Baseline Models,[0],[0]
"Though prior work has shown that automatic evaluation metrics often correlate poorly with human assessments of dialogue agents (Liu et al., 2016), we report a number of automatic metrics in Table 3.",5.4.1 Metrics,[0],[0]
"These metrics are provided for coarse-grained evaluation of dialogue response quality:
• BLEU:",5.4.1 Metrics,[0],[0]
"We use the BLEU metric, commonly employed in evaluating machine translation systems (Papineni et al., 2002), which has also been used in past literature for evaluating dialogue systems both of the chatbot and task-oriented variety (Ritter et al., 2011; Li et al., 2016; Wen et al., 2016b).",5.4.1 Metrics,[0],[0]
"While work by (Liu et al., 2016) has demonstrated that ngram based evaluation metrics such as BLEU and METEOR do not correlate well with human performance on non-task-oriented dialogue datasets, recently (Sharma et al., 2017) have shown that these metrics can show comparatively stronger correlation with human assessment on task-oriented datasets.",5.4.1 Metrics,[0],[0]
"We, therefore, calculate average BLEU score over all responses generated by the system, and primarily report these scores to gauge our
model’s ability to accurately generate the language patterns seen in our data.
",5.4.1 Metrics,[0],[0]
• Entity F1: Each human Turker’s Car Assistant response in the test data defines a gold set of entities.,5.4.1 Metrics,[0],[0]
"To compute an entity F1, we micro-average over the entire set of system dialogue responses and use the entities in their canonicalized forms.",5.4.1 Metrics,[0],[0]
This metric evaluates the model’s ability to generate relevant entities from the underlying knowledge base and to capture the semantics of the userinitiated dialogue flow.,5.4.1 Metrics,[0],[0]
"Given that our test set contains dialogues from all three domains, we compute a per-domain entity F1 as well as an aggregated dataset entity F1.",5.4.1 Metrics,[0],[0]
"We note that other work on task-oriented dialogue by (Wen et al., 2016b; Henderson et al., 2014a) have reported the slot-tracking accuracy of their systems, which is a similar but perhaps more informative and fine-grained notion of a system’s ability to capture user semantics.",5.4.1 Metrics,[0],[0]
"Because our model does not have provisions for slot-tracking by design, we are unable to report such a metric and hence report our entity F1.",5.4.1 Metrics,[0],[0]
"We see that of our baseline models, Copy Net has the lowest aggregate entity F1 performance.",5.4.2 Results,[0],[0]
"Though it has the highest model entity F1 for the weather domain dialogues, it performs very poorly in the other domains, indicating its inability to generalize well to multiple dialogue domains and to accurately integrate relevant entities into its responses.",5.4.2 Results,[0],[0]
"Copy Net does, however, have the second highest BLEU score, which is not surprising given that the model is a powerful extension to the sequence-to-sequence modelling class, which is known to have very robust language modelling capabilities.
",5.4.2 Results,[0],[0]
"Our rule-based model has the lowest BLEU score, which is a consequence of the fact that the naturalness of the system output is very limited by the number of diverse and distinct response templates we manually provided.",5.4.2 Results,[0],[0]
This is a common issue with heuristic dialogue agents and one that could be partially alleviated through a larger collection of lexically rich response templates.,5.4.2 Results,[0],[0]
"However, the rule-based system has a very competitive aggregate entity F1.",5.4.2 Results,[0],[0]
"This is because it was designed to accurately parse the semantics of user utterances and query the underlying KB of the dialogue, through manually-provided heuristics.
",5.4.2 Results,[0],[0]
"As precursors to our key-value retrieval net, we first report results of a model that does not compute an attention over the KB (referred to as Attn.",5.4.2 Results,[0],[0]
Seq2Seq),5.4.2 Results,[0],[0]
"and show that without computing attention over the KB, the model performs poorly in entity F1 as its output is agnostic to the world state represented in the KB.",5.4.2 Results,[0],[0]
Note that this model is effectively a sequence-to-sequence model with encoder attention.,5.4.2 Results,[0],[0]
If we include an attention over the KB but do not compute an encoder attention (referred to as KV Retrieval Net no enc.,5.4.2 Results,[0],[0]
"attn.), the entity F1 increases drastically, showing that the model is able to incorporate relevant entities from the KB.",5.4.2 Results,[0],[0]
"Finally, we combine these two attention mechanisms to get our final key-value retrieval net.",5.4.2 Results,[0],[0]
"Our proposed key-value retrieval net has the highest modelling performance in BLEU, aggregate entity F1, and entity F1 for the scheduling and navigation domains.",5.4.2 Results,[0],[0]
It outperforms the rule-based aggregate entity F1 by 4.2% and outperforms the Copy Net BLEU score by 2.2 points as well as its entity F1 by 11%.,5.4.2 Results,[0],[0]
"These salient gains are noteworthy because our model is able to achieve them by learning its latent representationts directly from data, without the need for heuristics or manual labelling.
",5.4.2 Results,[0],[0]
We also report human performance on the provided metrics.,5.4.2 Results,[0],[0]
These scores were computed by taking the dialogues of the test set and having a second distinct batch of Amazon Mechanical Turk workers provide system responses given prior dialogue context.,5.4.2 Results,[0],[0]
"This, in effect, functions as an interannotator agreement score and sets a human upper bound on model performance.",5.4.2 Results,[0],[0]
"We see that there is a sizable gap between human performance on entity F1 and that of our key-value retrieval net (∼ 12.7%), though our model is on par with human performance in BLEU score.",5.4.2 Results,[0],[0]
"We randomly generated 120 distinct scenarios across the three dialogue domains, where a scenario is defined by an underlying KB as well as a user goal for the dialogue (e.g. find the nearest gas station, avoiding heavy traffic).",5.5 Human Evaluation,[0],[0]
"We then paired Amazon Mechanical Turkers with one of our systems in a real-time chat environment, where each Turker played the role of the Driver.",5.5 Human Evaluation,[0],[0]
"We evaluated the rule-based model, Copy Net, and key-value retrieval network on each of the 120 scenarios.",5.5 Human Evaluation,[0],[0]
"We also paired a Turker with another Turker for each of the scenarios, in order to get evaluations of human performance.",5.5 Human Evaluation,[0],[0]
"At the end of the chat, the Turker was asked to judge the quality of their partner according to fluency, cooperativeness, and humanlikeness on a scale from 1 to 5.",5.5 Human Evaluation,[0],[0]
The average scores per pairing are reported in Table 4.,5.5 Human Evaluation,[0],[0]
"In a separate experiment, we also had Turkers evaluate the outputs of the systems on 80 randomly selected dialogues from the test split of our dataset.",5.5 Human Evaluation,[0],[0]
"Those outputs were evaluated according to correctness, appropriateness, and humanlikeness of the responses, and the scores are reported in Table 5.
",5.5 Human Evaluation,[0],[0]
"We see that on real-time dialogues the key-value retrieval network outperforms the baseline models on all of the metrics, with especially sizeable performance gains over the Copy Net which is the only other recurrent neural model evaluated.",5.5 Human Evaluation,[0],[0]
"We also see that human performance on this assessment sets the upper bound on scores, as expected.",5.5 Human Evaluation,[0],[0]
"The results on human evaluation of test outputs show that the rule-based model provides the most correct system responses, the KV network provides the most appropriate responses, and the Copy Net gives the most humanlike responses by small margins.",5.5 Human Evaluation,[0],[0]
"We should note, however, that the second regime for human evaluation is more unrealistic because it involves providing a dialogue context that is directly sampled from our dataset, whereas the first regime of real-time dialogues measures the models’ abilities to adapt to new and noisier user input.",5.5 Human Evaluation,[0],[0]
"This suggests that the first set of results are more meaningful and representative for assessing overall model efficacy.
",5.5 Human Evaluation,[0],[0]
Examples of dialogues conducted between our model and Turkers are included in Figure 3.,5.5 Human Evaluation,[0],[0]
"Particularly noteworthy is our model’s ability to seamlessly integrate world information from the underlying KBs in the respective dialogues, while
still producing very naturalistic utterances.",5.5 Human Evaluation,[0],[0]
The model is able to do this effectively across multiple domains.,5.5 Human Evaluation,[0],[0]
"In this work, we have presented a novel neural task-oriented dialogue model that is able to sustain grounded discourse across a variety of domains by retrieving world knowledge represented in knowledge bases.",6 Conclusion and Future Work,[0],[0]
"It smoothly incorporates
this world knowledge into natural-sounding system responses in an end-to-end trainable fashion, without the need to explicitly model dialogue state.",6 Conclusion and Future Work,[0],[0]
Our model outperforms competitive heuristic and neural baselines on both automatic and human evaluation metrics.,6 Conclusion and Future Work,[0],[0]
"In addition, we have introduced a publicly available dialogue dataset across three domains in the in-car personal assistant space that we hope will help the data scarcity issue present in task-oriented dialogue research.
",6 Conclusion and Future Work,[0],[0]
Future work will address closing the margin between the Key-Value Retrieval Network and human performance on the various metrics.,6 Conclusion and Future Work,[0],[0]
This will include developing new methods for robust handling of joint KB attributes as well as usage of the KB that requires more pragmatic understanding of the world via notions such as temporal reasoning.,6 Conclusion and Future Work,[0],[0]
"The authors wish to thank He He, Peng Qi, Urvashi Khandelwal, and Reid Pryzant for their valuable feedback and insights.",Acknowledgments,[0],[0]
"We gratefully acknowledge the funding of the Ford Research and Innovation Center, under Grant No. 124344.",Acknowledgments,[0],[0]
Neural task-oriented dialogue systems often struggle to smoothly interface with a knowledge base.,abstractText,[0],[0]
"In this work, we seek to address this problem by proposing a new neural dialogue agent that is able to effectively sustain grounded, multi-domain discourse through a novel key-value retrieval mechanism.",abstractText,[0],[0]
The model is end-to-end differentiable and does not need to explicitly model dialogue state or belief trackers.,abstractText,[0],[0]
"We also release a new dataset of 3,031 dialogues that are grounded through underlying knowledge bases and span three distinct tasks in the in-car personal assistant space: calendar scheduling, weather information retrieval, and point-of-interest navigation.",abstractText,[0],[0]
Our architecture is simultaneously trained on data from all domains and significantly outperforms a competitive rulebased system and other existing neural dialogue architectures on the provided domains according to both automatic and human evaluation metrics.,abstractText,[0],[0]
Key-Value Retrieval Networks for Task-Oriented Dialogue,title,[0],[0]
Reasoning is a key concept in artificial intelligence.,1. Introduction,[0],[0]
"A host of applications such as search engines, question-answering systems, conversational dialogue systems, and social networks require reasoning over underlying structured knowledge.",1. Introduction,[0],[0]
Effective representation and learning over such knowledge has come to the fore as a very important task.,1. Introduction,[0],[0]
"In particular, Knowledge Graphs have gained much attention as an important model for studying complex multi-relational settings.",1. Introduction,[0],[0]
"Traditionally, knowledge graphs are considered to be static snapshot of multi-relational data.",1. Introduction,[0],[0]
"However, recent availability of large amount of event based interaction data that exhibits complex temporal dynamics in addition to its multi-relational nature has created the need for approaches that can characterize and reason over tempo-
1College of Computing, Georgia Institute of Technology.",1. Introduction,[0],[0]
Correspondence to:,1. Introduction,[0],[0]
"Rakshit Trivedi <rstrivedi@gatech.edu>, Le Song <lsong@cc.gatech.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
rally evolving systems.",1. Introduction,[0],[0]
"For instance, GDELT (Leetaru & Schrodt, 2013) and ICEWS (Boschee et al., 2017) are two popular event based data repository that contains evolving knowledge about entity interactions across the globe.
",1. Introduction,[0],[0]
"Thus traditional knowledge graphs need to be augmented into Temporal Knowledge Graphs, where facts occur, recur or evolve over time in these graphs, and each edge in the graphs have temporal information associated with it.",1. Introduction,[0],[0]
Figure 1 shows a subgraph snapshot of such temporal knowledge graph.,1. Introduction,[0],[0]
Static knowledge graphs suffer from incompleteness resulting in their limited reasoning ability.,1. Introduction,[0],[0]
Most work on static graphs have therefore focussed on advancing entity-relationship representation learning to infer missing facts based on available knowledge.,1. Introduction,[0],[0]
"But these methods lack ability to use rich temporal dynamics available in underlying data represented by temporal knowledge graphs.
",1. Introduction,[0],[0]
Effectively capturing temporal dependencies across facts in addition to the relational (structural) dependencies can help improve the understanding on behavior of entities and how they contribute to generation of facts over time.,1. Introduction,[0],[0]
"For example, one can precisely answer questions like:
• Object prediction.",1. Introduction,[0],[0]
"(Who) will Donald Trump mention next?
",1. Introduction,[0],[0]
• Subject prediction.,1. Introduction,[0],[0]
"(Which country) will provide material support to US next month?
",1. Introduction,[0],[0]
• Time prediction.,1. Introduction,[0],[0]
"(When) will Bob visit Burger King?
”People (entities) change over time and so do relationships.”",1. Introduction,[0],[0]
"When two entities forge a relationship, the newly formed edge drives their preferences and behavior.",1. Introduction,[0],[0]
"This change is effected by combination of their own historical factors (temporal evolution) and their compatibility with the historical factors of the other entity (mutual evolution).
",1. Introduction,[0],[0]
"For instance, if two countries have tense relationships, they are more likely to engage in conflicts.",1. Introduction,[0],[0]
"On the other hand, two countries forging an alliance are most likely to take confrontational stands against enemies of each other.",1. Introduction,[0],[0]
"Finally, time plays a vital role in this process.",1. Introduction,[0],[0]
A country that was once peaceful may not have same characteristics 10 years in future due to various facts (events) that may occur during that period.,1. Introduction,[0],[0]
Being able to capture this temporal and evolutionary effects can help us reason better about future relationship of an entity.,1. Introduction,[0],[0]
"We term this combined phenomenon of evolving entities and their dynamically changing relationships over time as “knowledge evolution”.
",1. Introduction,[0],[0]
"In this paper, we propose an elegant framework to model knowledge evolution and reason over complex non-linear interactions between entities in a multi-relational setting.",1. Introduction,[0],[0]
The key idea of our work is to model the occurrence of a fact as multidimensional temporal point process whose conditional intensity function is modulated by the relationship score for that fact.,1. Introduction,[0],[0]
The relationship score further depends on the dynamically evolving entity embeddings.,1. Introduction,[0],[0]
"Specifically, our work makes the following contributions:
• We propose a novel deep learning architecture that evolves over time based on availability of new facts.",1. Introduction,[0],[0]
"The dynamically evolving network will ingest the incoming new facts, learn from them and update the embeddings of involved entities based on their recent relationships and temporal behavior.",1. Introduction,[0],[0]
•,1. Introduction,[0],[0]
"Besides predicting the occurrence of a fact, our architecture has ability to predict time when the fact may potentially occur which is not possible by any prior relational learning approaches to the best of our knowledge.",1. Introduction,[0],[0]
•,1. Introduction,[0],[0]
Our model supports Open World Assumption as missing links are not considered to be false and may potentially occur in future.,1. Introduction,[0],[0]
It further supports prediction over unseen entities due to its novel dynamic embedding process.,1. Introduction,[0],[0]
•,1. Introduction,[0],[0]
The large-scale experiments on two real world datasets show that our framework has consistently and significantly better performance for link prediction than stateof-arts that do not account for temporal and evolving non-linear dynamics.,1. Introduction,[0],[0]
• Our work aims to introduce the use of powerful mathematical tool of temporal point process framework for temporal reasoning over dynamically evolving knowledge graphs.,1. Introduction,[0],[0]
It has potential to open a new research direction in reasoning over time for various multi-relational settings with underlying spatio-temporal dynamics.,1. Introduction,[0],[0]
"A temporal point process (Cox & Lewis, 2006) is a random process whose realization consists of a list of events localized in time, {ti} with ti ∈ R+.",2.1. Temporal Point Process,[0],[0]
"Equivalently, a given temporal point process can be represented as a counting process, N(t), which records the number of events before time t.
An important way to characterize temporal point processes is via the conditional intensity function λ(t), a stochastic model for the time of the next event given all the previous events.",2.1. Temporal Point Process,[0],[0]
"Formally, λ(t)dt is the conditional probability of observing an event in a small window [t, t+ dt) given the history T (t) := {tk|tk < t} up to t, i.e.,
λ(t)dt := P {event in [t, t+ dt)|T (t)} = E[dN(t)|T (t)]
(1)
where one typically assumes that only one event can happen in a small window of size dt, i.e., dN(t) ∈ {0, 1}.
",2.1. Temporal Point Process,[0],[0]
"From the survival analysis theory (Aalen et al., 2008), given the history T = {t1, . . .",2.1. Temporal Point Process,[0],[0]
", tn}, for any t > tn, we characterize the conditional probability that no event happens during [tn, t) as S(t|T ) =",2.1. Temporal Point Process,[0],[0]
exp ( − ∫ t tn λ(τ) dτ ) .,2.1. Temporal Point Process,[0],[0]
"Moreover, the conditional density that an event occurs at time t is defined as : f(t) = λ(t)S(t) (2)
The functional form of the intensity λ(t) is often designed to capture the phenomena of interests.",2.1. Temporal Point Process,[0],[0]
"Some Common forms include: Poisson Process, Hawkes processes (Hawkes, 1971), Self-Correcting Process (Isham & Westcott, 1979), Power Law and Rayleigh Process.
",2.1. Temporal Point Process,[0],[0]
"Rayleigh Process is a non-monotonic process and is welladapted to modeling fads, where event likelihood drops rapidly after rising to a peak.",2.1. Temporal Point Process,[0],[0]
"Its intensity function is λ(t) = α · (t), where α > 0 is the weight parameter, and the log survival function is logS(t|α) = −α · (t)2/2.",2.1. Temporal Point Process,[0],[0]
We define a Temporal Knowledge Graph (TKG) as a multirelational directed graph with timestamped edges between any pair of nodes.,2.2. Temporal Knowledge Graph representation,[0],[0]
"In a TKG, each edge between two nodes represent an event in the real world and edge type (relationship) represent the corresponding event type.",2.2. Temporal Knowledge Graph representation,[0],[0]
Further an edge may be available multiple times (recurrence).,2.2. Temporal Knowledge Graph representation,[0],[0]
We do not allow duplicate edges and self-loops in graph.,2.2. Temporal Knowledge Graph representation,[0],[0]
"Hence, all recurrent edges will have different time points and every edge will have distinct subject and object entities.
",2.2. Temporal Knowledge Graph representation,[0],[0]
"Given ne entities and nr relationships, we extend traditional triplet representation for knowledge graphs to introduce time dimension and represent each fact in TKG as a quadruplet (es, r, eo, t), where es, eo ∈ {1, . . .",2.2. Temporal Knowledge Graph representation,[0],[0]
", ne}, es 6= eo,
r ∈ {1, . . .",2.2. Temporal Knowledge Graph representation,[0],[0]
", nr}, t ∈",2.2. Temporal Knowledge Graph representation,[0],[0]
R+.,2.2. Temporal Knowledge Graph representation,[0],[0]
"It represents the creation of relationship edge r between subject entity es, and object entity eo at time t. The complete TKG can therefore be represented as an ne × ne",2.2. Temporal Knowledge Graph representation,[0],[0]
× nr × T - dimensional tensor where T is the total number of available time points.,2.2. Temporal Knowledge Graph representation,[0],[0]
"Consider a TKG comprising of N edges and denote the globally ordered set of corresponding N observed events as D = {(es, r, eo, t)n}Nn=1, where 0 ≤ t1 ≤ t2 . . .",2.2. Temporal Knowledge Graph representation,[0],[0]
≤ T .,2.2. Temporal Knowledge Graph representation,[0],[0]
We present our unified knowledge evolution framework (Know-Evolve) for reasoning over temporal knowledge graphs.,3. Evolutionary Knowledge Network,[0],[0]
"The reasoning power of Know-Evolve stems from the following three major components:
1.",3. Evolutionary Knowledge Network,[0],[0]
"A powerful mathematical tool of temporal point process that models occurrence of a fact.
2.",3. Evolutionary Knowledge Network,[0],[0]
"A bilinear relationship score that captures multirelational interactions between entities and modulates the intensity function of above point process.
",3. Evolutionary Knowledge Network,[0],[0]
3.,3. Evolutionary Knowledge Network,[0],[0]
A novel deep recurrent network that learns non-linearly and mutually evolving latent representations of entities based on their interactions with other entities in multirelational space over time.,3. Evolutionary Knowledge Network,[0],[0]
Large scale temporal knowledge graphs exhibit highly heterogeneous temporal patterns of events between entities.,3.1. Temporal Process,[0],[0]
Discrete epoch based methods to model such temporal behavior fail to capture the underlying intricate temporal dependencies.,3.1. Temporal Process,[0],[0]
"We therefore model time as a random variable and use temporal point process to model occurrence of fact.
",3.1. Temporal Process,[0],[0]
"More concretely, given a set of observed events O corresponding to a TKG, we construct a relationship-modulated multidimensional point process to model occurrence of these events.",3.1. Temporal Process,[0],[0]
"We characterize this point process with the following conditional intensity function:
λe s,eo r (t|t̄) = f(ge",3.1. Temporal Process,[0],[0]
"s,eo r (t̄))",3.1. Temporal Process,[0],[0]
"∗ (t− t̄) (3)
where t > t̄, t is the time of the current event and t̄ = max(te
s−, teo−) is the most recent time point when either subject or object entity was involved in an event before time t. Thus, λe s,eo
r (t|t̄) represents intensity of event involving triplet (es, r, ej) at time t given previous time point t̄ when either es or eo was involved in an event.",3.1. Temporal Process,[0],[0]
This modulates the intensity of current event based on most recent activity on either entities’ timeline and allows to capture scenarios like non-periodic events and previously unseen events.,3.1. Temporal Process,[0],[0]
f(·) = exp(·) ensures that intensity is positive and well defined.,3.1. Temporal Process,[0],[0]
"The first term in (3) modulates the intensity function by the relational compatibility score between the involved enti-
ties in that specific relationship.",3.2. Relational Score Function,[0],[0]
"Specifically, for an event (es, r, eo, t) ∈ D occurring at time t, the score term ges,eor is computed using a bilinear formulation as follows:
ge s,eo r (t) =",3.2. Relational Score Function,[0],[0]
v,3.2. Relational Score Function,[0],[0]
es(t−)T,3.2. Relational Score Function,[0],[0]
·,3.2. Relational Score Function,[0],[0]
"Rr · ve o (t−) (4)
where ve s , ve s ∈ Rd represent latent feature embeddings of entities appearing in subject and object position respectively.",3.2. Relational Score Function,[0],[0]
Rr ∈ Rd×d represents relationship weight matrix which attempts to capture interaction between two entities in the specific relationship space r.,3.2. Relational Score Function,[0],[0]
This matrix is unique for each relation in dataset and is learned during training.,3.2. Relational Score Function,[0],[0]
"t is time of current event and t− represent time point just before time t. ve s
(t−) and veo(t−), therefore represent most recently updated vector embeddings of subject and object entities respectively before time t. As these entity embeddings evolve and update over time, ge s,eo
r (t) is able to capture cumulative knowledge learned about the entities over the history of events that have affected their embeddings.",3.2. Relational Score Function,[0],[0]
We represent latent feature embedding of an entity e at time t with a low-dimensional vector ve(t).,3.3. Dynamically Evolving Entity Representations,[0],[0]
We add superscript s and o as shown in Eq.,3.3. Dynamically Evolving Entity Representations,[0],[0]
(4) to indicate if the embedding corresponds to entity in subject or object position respectively.,3.3. Dynamically Evolving Entity Representations,[0],[0]
"We also use relationship-specific low-dimensional representation for each relation type.
",3.3. Dynamically Evolving Entity Representations,[0],[0]
The latent representations of entities change over time as entities forge relationships with each other.,3.3. Dynamically Evolving Entity Representations,[0],[0]
We design novel deep recurrent neural network based update functions to capture mutually evolving and nonlinear dynamics of entities in their vector space representations.,3.3. Dynamically Evolving Entity Representations,[0],[0]
"We consider an event m = (es, r, eo, t)m ∈ D occurring at time t. Also, consider that event m is entity es’s p-th event while it is entity eo’s q-th event.",3.3. Dynamically Evolving Entity Representations,[0],[0]
"As entities participate in events in a heterogeneous pattern, it is less likely that p = q",3.3. Dynamically Evolving Entity Representations,[0],[0]
although not impossible.,3.3. Dynamically Evolving Entity Representations,[0],[0]
"Having observed this event, we update the embeddings of two involved entities as follows:
Subject Embedding:
ve s
(tp) = σ(W s t(tp − tp−1) +",3.3. Dynamically Evolving Entity Representations,[0],[0]
"Whh · he
s
(tp−))",3.3. Dynamically Evolving Entity Representations,[0],[0]
"he s (tp−) = σ(Wh · [ve s (tp−1)⊕ ve o (tp−)⊕ re s p−1])
(5)
Object Embedding:
ve o
(tq) = σ(W o t (tq − tq−1) +",3.3. Dynamically Evolving Entity Representations,[0],[0]
"Whh · he
o
(tq−))",3.3. Dynamically Evolving Entity Representations,[0],[0]
"he o (tq−) = σ(Wh · [ve o (tq−1)⊕ ve s (tq−)⊕ re o q−1])
(6)
where, ve s , ve o ∈ Rd.",3.3. Dynamically Evolving Entity Representations,[0],[0]
tp = tq = tm is the time of observed event.,3.3. Dynamically Evolving Entity Representations,[0],[0]
"For subject embedding update in Eq. (5), tp−1 is the time point of the previous event in which entity es was
involved.",3.3. Dynamically Evolving Entity Representations,[0],[0]
tp− is the timepoint just before time tp.,3.3. Dynamically Evolving Entity Representations,[0],[0]
"Hence, ve s
(tp−1) represents latest embedding for entity es that was updated after (p − 1)-th event for that entity.",3.3. Dynamically Evolving Entity Representations,[0],[0]
veo(tp−) represents latest embedding for entity eo that was updated any time just before tp = tm.,3.3. Dynamically Evolving Entity Representations,[0],[0]
"This accounts for the fact that entity eo may have been involved in some other event during the interval between current (p) and previous (p− 1) event of entity es. re s
p−1 ∈ Rc represent relationship embedding that corresponds to relationship type of the (p− 1)-th event of entity es.",3.3. Dynamically Evolving Entity Representations,[0],[0]
Note that the relationship vectors are static and do not evolve over time.,3.3. Dynamically Evolving Entity Representations,[0],[0]
"he s
(tp−)",3.3. Dynamically Evolving Entity Representations,[0],[0]
∈ Rd is the hidden layer.,3.3. Dynamically Evolving Entity Representations,[0],[0]
The semantics of notations apply similarly to object embedding update in Eq.,3.3. Dynamically Evolving Entity Representations,[0],[0]
"(6).
",3.3. Dynamically Evolving Entity Representations,[0],[0]
"Wst,W o t ∈ Rd×1, Whh ∈ Rd×l and Wh ∈ Rl×(2d+c) are weight parameters in network learned during training.",3.3. Dynamically Evolving Entity Representations,[0],[0]
"Wst,W o t captures variation in temporal drift for subject and object respectively.",3.3. Dynamically Evolving Entity Representations,[0],[0]
Whh is shared parameter that captures recurrent participation effect for each entity.,3.3. Dynamically Evolving Entity Representations,[0],[0]
Wh is a shared projection matrix applied to consider the compatibility of entities in their previous relationships.,3.3. Dynamically Evolving Entity Representations,[0],[0]
⊕ represent simple concatenation operator.,3.3. Dynamically Evolving Entity Representations,[0],[0]
σ(·) denotes nonlinear activation function (tanh in our case).,3.3. Dynamically Evolving Entity Representations,[0],[0]
"Our formulations use simple RNN units but it can be replaced with more expressive
units like LSTM or GRU in straightforward manner.",3.3. Dynamically Evolving Entity Representations,[0],[0]
"In our experiments, we choose d = l and d 6= c",3.3. Dynamically Evolving Entity Representations,[0],[0]
but they can be chosen differently.,3.3. Dynamically Evolving Entity Representations,[0],[0]
"Below we explain the rationales of our deep recurrent architecture that captures nonlinear evolutionary dynamics of entities over time.
",3.3. Dynamically Evolving Entity Representations,[0],[0]
"Reasoning Based on Structural Dependency: The hidden layer (he s
) reasons for an event by capturing the compatibility of most recent subject embedding with most recent object embedding in previous relationship of subject entity.",3.3. Dynamically Evolving Entity Representations,[0],[0]
"This accounts for the behavior that within a short period of time, entities tend to form relationships with other entities that have similar recent actions and goals.",3.3. Dynamically Evolving Entity Representations,[0],[0]
This layer thereby uses historical information of the two nodes involved in current event and the edges they both created before this event.,3.3. Dynamically Evolving Entity Representations,[0],[0]
"This holds symmetrically for hidden layer (he o ).
",3.3. Dynamically Evolving Entity Representations,[0],[0]
Reasoning based on Temporal Dependency: The recurrent layer uses hidden layer information to model the intertwined evolution of entity embeddings over time.,3.3. Dynamically Evolving Entity Representations,[0],[0]
"Specifically this layer has two main components:
• Drift over time:",3.3. Dynamically Evolving Entity Representations,[0],[0]
The first term captures the temporal difference between consecutive events on respective dimension of each entity.,3.3. Dynamically Evolving Entity Representations,[0],[0]
"This captures the external influences
that entities may have experienced between events and allows to smoothly drift their features over time.",3.3. Dynamically Evolving Entity Representations,[0],[0]
This term will not contribute anything in case when multiple events happen for an entity at same time point (e.g. within a day in our dataset).,3.3. Dynamically Evolving Entity Representations,[0],[0]
"While tp − tp−1 may exhibit high variation, the corresponding weight parameter will capture these variations and along with the second recurrent term, it will prevent ve s (tp) to collapse.
",3.3. Dynamically Evolving Entity Representations,[0],[0]
• Relation-specific Mutual Evolution: The latent features of both subject and object entities influence each other.,3.3. Dynamically Evolving Entity Representations,[0],[0]
"In multi-relational setting, this is further affected by the relationship they form.",3.3. Dynamically Evolving Entity Representations,[0],[0]
Recurrent update to entity embedding with the information from the hidden layer allows to capture the intricate non-linear and evolutionary dynamics of an entity with respect to itself and the other entity in a specific relationship space.,3.3. Dynamically Evolving Entity Representations,[0],[0]
"Figure (2) and Figure (3) shows the architecture of knowledge evolution framework and one step of our model.
",3.4. Understanding Unified View of Know-Evolve,[0],[0]
The updates to the entity representations in Eq. (5) and (6) are driven by the events involving those entities which makes the embeddings piecewise constant i.e. an entity embedding remains unchanged in the duration between two events involving that entity and updates only when an event happens on its dimension.,3.4. Understanding Unified View of Know-Evolve,[0],[0]
This is justifiable as an entity’s features may update only when it forges a relationship with other entity within the graph.,3.4. Understanding Unified View of Know-Evolve,[0],[0]
"Note that the first term in Eq. (5) and (6) already accounts for any external influences.
",3.4. Understanding Unified View of Know-Evolve,[0],[0]
"Having observed an event at time t, Know-Evolve considers it as an incoming fact that brings new knowledge about the entities involved in that event.",3.4. Understanding Unified View of Know-Evolve,[0],[0]
It computes the intensity of that event in Eq.,3.4. Understanding Unified View of Know-Evolve,[0],[0]
(3) which is based on relational compatibility score in Eq. (4) between most recent latent embeddings of involved entities.,3.4. Understanding Unified View of Know-Evolve,[0],[0]
"As these embeddings are piecewise constant, we use time interval term (t− t̄) in Eq.",3.4. Understanding Unified View of Know-Evolve,[0],[0]
(3) to make the overall intensity piecewise linear which is standard mathematical choice for efficient computation in point process framework.,3.4. Understanding Unified View of Know-Evolve,[0],[0]
This formulation naturally leads to Rayleigh distribution which models time interval between current event and most recent event on either entities’ dimension.,3.4. Understanding Unified View of Know-Evolve,[0],[0]
Rayleigh distribution has an added benefit of having a simple analytic form of likelihood which can be further used to find entity for which the likelihood reaches maximum value and thereby make precise entity predictions.,3.4. Understanding Unified View of Know-Evolve,[0],[0]
"The complete parameter space for the above model is: Ω = {{Ve}e=1:ne , {Rr}r=1:nr ,We,Wst,Wot ,Wh, Whh,Wr}.",4. Efficient Training Procedure,[0],[0]
"Although Know-Evolve gains expressive power from deep architecture, Table 4 (Appendix D) shows that the memory footprint of our model is comparable to
simpler relational models.",4. Efficient Training Procedure,[0],[0]
The intensity function in (3) allows to use maximum likelihood estimation over all the facts as our objective function.,4. Efficient Training Procedure,[0],[0]
"Concretely, given a collection of facts recorded in a temporal window [0, T ), we learn the model by minimizing the joint negative log likelihood of intensity function (Daley & Vere-Jones, 2007) written as:
L =",4. Efficient Training Procedure,[0],[0]
"− N∑ p=1 log ( λe s,eo r (tp|t̄p) )
︸ ︷︷ ︸ happened events
+ nr∑ r=1",4. Efficient Training Procedure,[0],[0]
"ne∑ es=1 ne∑ eo=1 ∫ T 0 λe s,eo
r (τ |τ̄) dτ︸ ︷︷ ︸ survival term
(7)
",4. Efficient Training Procedure,[0],[0]
The first term maximizes the probability of specific type of event between two entities; the second term penalizes non-presence of all possible types of events between all possible entity pairs in a given observation window.,4. Efficient Training Procedure,[0],[0]
We use Back Propagation Through Time (BPTT) algorithm to train our model.,4. Efficient Training Procedure,[0],[0]
"Previous techniques (Du et al., 2016; Hidasi et al., 2016) that use BPTT algorithm decompose data into independent sequences and train on mini-batches of those sequences.",4. Efficient Training Procedure,[0],[0]
But there exists intricate relational and temporal dependencies between data points in our setting which limits our ability to efficiently train by decomposing events into independent sequences.,4. Efficient Training Procedure,[0],[0]
"To address this challenge, we design an efficient Global BPTT algorithm (Algorithm 2, Appendix A) that creates mini-batches of events over global timeline in sliding window fashion and allows to capture dependencies across batches while retaining efficiency.
",4. Efficient Training Procedure,[0],[0]
Intractable Survival Term.,4. Efficient Training Procedure,[0],[0]
"To compute the second survival term in (7), since our intensity function is modulated by relation-specific parameter, for each relationship we need to compute survival probability over all pairs of entities.",4. Efficient Training Procedure,[0],[0]
"Next, given a relation r and entity pair (es, eo), we denote P(es,eo) as total number of events of type r involving either es or eo in window",4. Efficient Training Procedure,[0],[0]
"[T0, T ).",4. Efficient Training Procedure,[0],[0]
"As our intensity function is piecewise-linear, we can decompose the integration term − ∫ T T0 λe s,eo
r (τ |τ̄)dτ into multiple time intervals where intensity is constant:∫ T
T0
λe s,eo
r (τ |τ̄)dτ
= P(es,eo)−1∑ p=1 ∫ tp+1 tp λe s,eo r (τ |τ̄)dτ
= P(es,eo)−1∑ p=1 (t2p+1 − t2p) · exp(ve s (tp) T ·Rr · ve o (tp))
(8)
The integral calculations in (8) for all possible triplets requiresO(n2r) computations (n is number of entities and r is the number of relations).",4. Efficient Training Procedure,[0],[0]
"This is computationally intractable
Algorithm 1 Survival Loss Computation in mini-batch Input: Minibatch E , size s, Batch Entity List bl loss = 0.0 for p = 0 to s− 1 do
subj feat = Ep → ve s
(t−) obj feat = Ep → ve o
(t−) rel weight =",4. Efficient Training Procedure,[0],[0]
Ep → Rr t end =,4. Efficient Training Procedure,[0],[0]
"Ep → t subj surv = 0, obj surv = 0, total surv = 0 for i = 0 to bl.size do
obj other = bl[i] if obj other == Ep → es then
continue end if t̄ = max(te
s−, teo−) subj surv",4. Efficient Training Procedure,[0],[0]
+= (t end2 − t̄2) · exp(subj featT · rel weight ·,4. Efficient Training Procedure,[0],[0]
"obj other feat)
end for for j = 0 to bl.size do
subj other = bl[i] if subj other == Ep → eo then
continue end if t̄ = max(te
s−, teo−)",4. Efficient Training Procedure,[0],[0]
obj surv += (t end2,4. Efficient Training Procedure,[0],[0]
"− t̄2) · exp(subj other featT · rel weight · obj feat)
end for loss += subj",4. Efficient Training Procedure,[0],[0]
"surv + obj surv
end for
and also unnecessary.",4. Efficient Training Procedure,[0],[0]
Knowledge tensors are inherently sparse and hence it is plausible to approximate the survival loss in a stochastic setting.,4. Efficient Training Procedure,[0],[0]
"We take inspiration from techniques like noise contrastive (Gutmann & Hyvärinen, 2012) estimation and adopt a random sampling strategy to compute survival loss:",4. Efficient Training Procedure,[0],[0]
"Given a mini-batch of events, for each relation in the mini-batch, we compute dyadic survival term across all entities in that batch.",4. Efficient Training Procedure,[0],[0]
Algorithm 1 presents the survival loss computation procedure.,4. Efficient Training Procedure,[0],[0]
"While this procedure may randomly avoid penalizing some dimensions in a relationship, it still includes all dimensions that had events on them.",4. Efficient Training Procedure,[0],[0]
The computational complexity for this procedure will be O(2n′r′m) where m is size of mini-batch and n′ and r′ represent number of entities and relations in the mini-batch.,4. Efficient Training Procedure,[0],[0]
"We use two datasets: Global Database of Events, Language, and Tone (GDELT) (Leetaru & Schrodt, 2013) and Integrated Crisis Early Warning System (ICEWS) (Boschee et al., 2017) which has recently gained attention in learning community (Schein et al., 2016) as useful temporal KGs.",5.1. Temporal Knowledge Graph Data,[0],[0]
"GDELT data is collected from April 1, 2015 to Mar 31,
2016 (temporal granularity of 15 mins).",5.1. Temporal Knowledge Graph Data,[0],[0]
"ICEWS dataset is collected from Jan 1, 2014 to Dec 31, 2014 (temporal granularity of 24 hrs).",5.1. Temporal Knowledge Graph Data,[0],[0]
"Both datasets contain records of events that include two actors, action type and timestamp of event.",5.1. Temporal Knowledge Graph Data,[0],[0]
We use different hierarchy of actions in two datasets - (top level 20 relations for GDELT while last level 260 relations for ICEWS) - to test on variety of knowledge tensor configurations.,5.1. Temporal Knowledge Graph Data,[0],[0]
Note that this does not filter any record from the dataset.,5.1. Temporal Knowledge Graph Data,[0],[0]
"We process both datasets to remove any duplicate quadruples, any mono-actor events (i.e., we use only dyadic events), and self-loops.",5.1. Temporal Knowledge Graph Data,[0],[0]
We report our main results on full versions of each dataset.,5.1. Temporal Knowledge Graph Data,[0],[0]
We create smaller version of both datasets for exploration purposes.,5.1. Temporal Knowledge Graph Data,[0],[0]
Table 1 (Appendix B) provide statistics about the data and Table 2 (Appendix B) demonstrates the sparsity of knowledge tensor.,5.1. Temporal Knowledge Graph Data,[0],[0]
"We compare the performance of our method with following relational learning methods: RESCAL, Neural Tensor Network (NTN), Multiway Neural Network (ER-MLP), TransE and TransR.",5.2. Competitors,[0],[0]
"To the best of our knowledge, there are no existing relational learning approaches that can predict time for a new fact.",5.2. Competitors,[0],[0]
"Hence we devised two baseline methods for evaluating time prediction performance — (i) Multi-dimensional Hawkes process (MHP): We model dyadic entity interactions as multi-dimensional Hawkes process similar to (Du et al., 2015).",5.2. Competitors,[0],[0]
"Here, an entity pair constitutes a dimension and for each pair we collect sequence of events on its dimension and train and test on that sequence.",5.2. Competitors,[0],[0]
Relationship is not modeled in this setup.,5.2. Competitors,[0],[0]
"(ii) Recurrent Temporal Point Process (RTPP): We implement a simplified version of RMTPP (Du et al., 2016) where we do not predict the marker.",5.2. Competitors,[0],[0]
"For training, we concatenate static entity and relationship embeddings and augment the resulting vector with temporal feature.",5.2. Competitors,[0],[0]
This augmented unit is used as input to global RNN which produces output vector ht.,5.2. Competitors,[0],[0]
"During test time, for a given triplet, we use this vector ht to compute conditional intensity of the event given history which is further used to predict next event time.",5.2. Competitors,[0],[0]
Appendix C provides implementation details of our method and competitors.,5.2. Competitors,[0],[0]
"We report experimental results on two tasks: Link prediction and Time prediction.
",5.3. Evaluation Protocol,[0],[0]
Link prediction:,5.3. Evaluation Protocol,[0],[0]
"Given a test quadruplet (es, r, eo, t), we replace eo with all the entities in the dataset and compute the conditional density de s,eo
r = λ es,eo r (t)S es,eo
r (t) for the resulting quadruplets including the ground truth.",5.3. Evaluation Protocol,[0],[0]
We then sort all the quadruplets in the descending order of this density to rank the correct entity for object position.,5.3. Evaluation Protocol,[0],[0]
"We also conduct testing after applying the filtering techniques described in (Bordes et al., 2013) -",5.3. Evaluation Protocol,[0],[0]
"we only rank against the entities that do not generate a true triplet (seen in train) when it replaces
ground truth object.",5.3. Evaluation Protocol,[0],[0]
"We report Mean Absolute Rank (MAR), Standard Deviation for MAR and HITS@10 (correct entity in top 10 predictions) for both Raw and Filtered Versions.
",5.3. Evaluation Protocol,[0],[0]
"Time prediction: Give a test triplet (es, r, eo), we predict the expected value of next time the fact (es, r, eo) can occur.",5.3. Evaluation Protocol,[0],[0]
"This expectation is defined by: Ees,eor (t) =√
π
2 exp(ge s,eo r (t)) , where ge
s,eo
r (t) is computed using equa-
tion (4).",5.3. Evaluation Protocol,[0],[0]
"We report Mean Absolute Error (MAE) between the predicted time and true time in hours.
",5.3. Evaluation Protocol,[0],[0]
Sliding Window Evaluation.,5.3. Evaluation Protocol,[0],[0]
"As our work concentrates on temporal knowledge graphs, it is more interesting to see the performance of methods over time span of test set as compared to single rank value.",5.3. Evaluation Protocol,[0],[0]
This evaluation method can help to realize the effect of modeling temporal and evolutionary knowledge.,5.3. Evaluation Protocol,[0],[0]
We therefore partition our test set in 12 different slides and report results in each window.,5.3. Evaluation Protocol,[0],[0]
"For both datasets, each slide included 2 weeks of time.",5.3. Evaluation Protocol,[0],[0]
Link Prediction Results.,5.4. Quantitative Analysis,[0],[0]
"Figure (4, 5, 6) demonstrate link prediction performance comparison on both datasets.",5.4. Quantitative Analysis,[0],[0]
"Know-Evolve significantly and consistently outperforms all competitors in terms of prediction rank without any dete-
rioration over time.",5.4. Quantitative Analysis,[0],[0]
Neural Tensor Network’s second best performance compared to other baselines demonstrate its rich expressive power but it fails to capture the evolving dynamics of intricate dependencies over time.,5.4. Quantitative Analysis,[0],[0]
"This is further substantiated by its decreasing performance as we move test window further in time.
",5.4. Quantitative Analysis,[0],[0]
The second row represents deviation error for MAR across samples in a given test window.,5.4. Quantitative Analysis,[0],[0]
Our method achieves significantly low deviation error compared to competitors making it most stable.,5.4. Quantitative Analysis,[0],[0]
"Finally, high performance on HITS@10 metric demonstrates extensive discriminative ability of KnowEvolve.",5.4. Quantitative Analysis,[0],[0]
"For instance, GDELT has only 20 relations but 32M events where many entities interact with each other in multiple relationships.",5.4. Quantitative Analysis,[0],[0]
"In this complex setting, other methods depend only on static entity embeddings to perform prediction unlike our method which does effectively infers new knowledge using powerful evolutionary network and provides accurate prediction results.
",5.4. Quantitative Analysis,[0],[0]
Time Prediction Results.,5.4. Quantitative Analysis,[0],[0]
Figure 7 demonstrates that Know-Evolve performs significantly better than other point process based methods for predicting time.,5.4. Quantitative Analysis,[0],[0]
MHP uses a specific parametric form of the intensity function which limits its expressiveness.,5.4. Quantitative Analysis,[0],[0]
"Further, each entity pair interaction is modeled as an independent dimension and does not take
into account relational feature which fails to capture the intricate influence of different entities on each other.",5.4. Quantitative Analysis,[0],[0]
"On the other hand, RTPP uses relational features as part of input, but it sees all events globally and cannot model the intricate evolutionary dependencies on past events.",5.4. Quantitative Analysis,[0],[0]
"We observe that our method effectively captures such non-linear relational and temporal dynamics.
",5.4. Quantitative Analysis,[0],[0]
"In addition to the superior quantitative performance, we demonstrate the effectiveness of our method by providing extensive exploratory analysis in Appendix E.",5.4. Quantitative Analysis,[0],[0]
"In this section, we discuss relevant works in relational learning and temporal modeling techniques.",6. Related Work,[0],[0]
"Among various relational learning techniques, neural embedding models that focus on learning low-dimensional representations of entities and relations have shown stateof-the-art performance.",6.1. Relational Learning,[0],[0]
These methods compute a score for the fact based on different operations on these latent representations.,6.1. Relational Learning,[0],[0]
"Such models can be mainly categorized into two variants:
Compositional Models.",6.1. Relational Learning,[0],[0]
"RESCAL (Nickel et al., 2011) uses a relation specific weight matrix to explain triplets via pairwise interactions of latent features.",6.1. Relational Learning,[0],[0]
"Neural Tensor Network (NTN) (Socher et al., 2013) is more expressive model as it combines a standard NN layer with a bilinear tensor layer.",6.1. Relational Learning,[0],[0]
"(Dong et al., 2014) employs a concatenationprojection method to project entities and relations to lower dimensional space.",6.1. Relational Learning,[0],[0]
"Other sophisticated models include Holographic Embeddings (HoLE) (Nickel et al., 2016b) that employs circular correlation on entity embeddings and Neural Association Models (NAM) (Liu et al., 2016), a deep network used for probabilistic reasoning.
",6.1. Relational Learning,[0],[0]
Translation Based Models.,6.1. Relational Learning,[0],[0]
"(Bordes et al., 2011) uses two relation-specific matrices to project subject and object entities and computes L1 distance to score a fact between two entity vectors.",6.1. Relational Learning,[0],[0]
"(Bordes et al., 2013) proposed TransE model that computes score as a distance between relation-specific translations of entity embeddings.",6.1. Relational Learning,[0],[0]
"(Wang et al., 2014) improved",6.1. Relational Learning,[0],[0]
"TransE by allowing entities to have distributed representations on relation specific hyperplane where distance
between them is computed.",6.1. Relational Learning,[0],[0]
TransR,6.1. Relational Learning,[0],[0]
"(Lin et al., 2015) extends this model to use separate semantic spaces for entities and relations and does translation in the relationship space.
",6.1. Relational Learning,[0],[0]
"(Nickel et al., 2016a) and (Yang et al., 2015; Toutanova & Chen, 2015) contains comprehensive reviews and empirical comparison of relational learning techniques respectively.",6.1. Relational Learning,[0],[0]
All these methods consider knowledge graphs as static models and lack ability to capture temporally evolving dynamics.,6.1. Relational Learning,[0],[0]
"Temporal point processes have been shown as very effective tool to model various intricate temporal behaviors in networks (Yang & Zha, 2013; Farajtabar et al., 2014; 2015; Du et al., 2015; 2016; Wang et al., 2016a;b;c; 2017a;b).",6.2. Temporal Modeling,[0],[0]
"Recently, (Wang et al., 2016a; Dai et al., 2016b) proposed novel co-evolutionary feature embedding process that captures self-evolution and co-evolution dynamics of users and items interacting in a recommendation system.",6.2. Temporal Modeling,[0],[0]
"In relational setting, (Loglisci et al., 2015) proposed relational mining approach to discover changes in structure of dynamic network over time.",6.2. Temporal Modeling,[0],[0]
"(Loglisci & Malerba, 2017) proposes method to capture temporal autocorrelation in data to improve predictive performance.",6.2. Temporal Modeling,[0],[0]
"(Sharan & Neville, 2008) proposes summarization techniques to model evolving relational-temporal domains.",6.2. Temporal Modeling,[0],[0]
"Recently, (Esteban et al., 2016) proposed multiway neural network architecture for modeling event based relational graph.",6.2. Temporal Modeling,[0],[0]
The authors draw a synergistic relation between a static knowledge graph and an event set wherein the knowledge graph provide information about entities participating in events and new events in turn contribute to enhancement of knowledge graph.,6.2. Temporal Modeling,[0],[0]
They do not capture the evolving dynamics of entities and model time as discrete points which limits its capacity to model complex temporal dynamics.,6.2. Temporal Modeling,[0],[0]
"(Jiang et al., 2016) models dependence of relationship on time to facilitate time-aware link prediction but do not capture evolving entity dynamics.",6.2. Temporal Modeling,[0],[0]
We propose a novel deep evolutionary knowledge network that efficiently learns non-linearly evolving entity representations over time in multi-relational setting.,7. Conclusion,[0],[0]
Evolutionary dynamics of both subject and object entities are captured by deep recurrent architecture that models historical evolution of entity embeddings in a specific relationship space.,7. Conclusion,[0],[0]
The occurrence of a fact is then modeled by multivariate point process that captures temporal dependencies across facts.,7. Conclusion,[0],[0]
The superior performance and high scalability of our method on large real-world temporal knowledge graphs demonstrate the importance of supporting temporal reasoning in dynamically evolving relational systems.,7. Conclusion,[0],[0]
Our work establishes previously unexplored connection between relational processes and temporal point processes with a potential to open a new direction of research on reasoning over time.,7. Conclusion,[0],[0]
"This project was supported in part by NSF IIS-1218749, NIH BIGDATA 1R01GM108341, NSF CAREER IIS1350983,",Acknowledgement,[0],[0]
"NSF IIS-1639792 EAGER, ONR N00014-15-12340, NVIDIA, Intel and Amazon AWS.",Acknowledgement,[0],[0]
The availability of large scale event data with time stamps has given rise to dynamically evolving knowledge graphs that contain temporal information for each edge.,abstractText,[0],[0]
Reasoning over time in such dynamic knowledge graphs is not yet well understood.,abstractText,[0],[0]
"To this end, we present Know-Evolve, a novel deep evolutionary knowledge network that learns non-linearly evolving entity representations over time.",abstractText,[0],[0]
The occurrence of a fact (edge) is modeled as a multivariate point process whose intensity function is modulated by the score for that fact computed based on the learned entity embeddings.,abstractText,[0],[0]
We demonstrate significantly improved performance over various relational learning approaches on two large scale real-world datasets.,abstractText,[0],[0]
"Further, our method effectively predicts occurrence or recurrence time of a fact which is novel compared to prior reasoning approaches in multirelational setting.",abstractText,[0],[0]
Know-Evolve: Deep Temporal Reasoning for Dynamic Knowledge Graphs,title,[0],[0]
"Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2038–2043, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.",text,[0],[0]
"Large-scale knowledge bases (KB) like Freebase (Bollacker et al., 2008), Yago (Suchanek et al., 2007), NELL (Mitchell et al., 2015) can be useful in a variety of applications like natural language question answering, semantic search engines, etc.",1 Introduction,[0],[0]
These knowledge bases consist of millions of real world entities and relationships between them which are stored in the form of a directed graph where links represent relations and nodes represent the entities.,1 Introduction,[0],[0]
"Although such KBs contain millions of entities, they are still very sparse, i.e., they are missing a large number of relations between existing entities (West et al., 2014).
",1 Introduction,[0],[0]
Performing inference over the knowledge graph for predicting relations between two entities is one way of densifying the KB graph.,1 Introduction,[0],[0]
"For example,
from (Germany, playsinTournament, FIFA) and (FIFA, tournamentofSport, Soccer), we can infer (Germany, playsSport, Soccer).",1 Introduction,[0],[0]
"The Path Ranking Algorithm (PRA) (Lao and Cohen, 2010), (Lao et al., 2011) performs such an inference by learning inference rules over the knowledge graph.
",1 Introduction,[0],[0]
"If the knowledge graph is sparse, i.e., if there are a very few or no paths between source and target entities, then PRA is unable to predict the existence of a relation.",1 Introduction,[0],[0]
"To address this shortcoming, (Lao et al., 2012) augmented the knowledge graph with paths obtained from an external corpus.",1 Introduction,[0],[0]
The added paths consisted of unlexicalized dependency labels obtained from a dependency parsed external corpus.,1 Introduction,[0],[0]
"To improve the expressivity of the added paths, instead of the unlexicalized labels, (Gardner et al., 2013) augmented the KB graph with verbs (surface relations) from a corpus containing over 600 million Subject-Verb-Object (SVO) triples.",1 Introduction,[0],[0]
"These verbs act as edges that connect previously unconnected entities thereby increasing the connectivity of the KB graph which can potentially improve PRA performance.
",1 Introduction,[0],[0]
"However, naı̈vely adding these edges increases the feature sparsity which degrades the discriminative ability of the logistic regression classifier
2038
used in PRA.",1 Introduction,[0],[0]
"This can be addressed by adding latent relations obtained by clustering the surface relations, instead of directly adding the surface relations.",1 Introduction,[0],[0]
"This reduces feature sparsity and has been shown to improve PRA inference (Gardner et al., 2013) , (Gardner et al., 2014).
",1 Introduction,[0],[0]
In this article we propose a scheme for augmenting the KB using paths obtained by mining noun phrases that connect two SVO triples from an external corpus.,1 Introduction,[0],[0]
We term these noun phrases as bridging entities since they bridge two KB relations to form a path.,1 Introduction,[0],[0]
"This is different from the scheme in (Gardner et al., 2013) and (Gardner et al., 2014), which adds edges between KB nodes by mining surface relations from an external corpus.",1 Introduction,[0],[0]
"We search for such bridging entities in the corpus by performing a limited depth DFS (depth first search) on the corpus graph in an on-demand fashion.
",1 Introduction,[0],[0]
"We term this procedure as On-Demand Augmentation (ODA), because the search can be performed during test time in an on-demand manner.",1 Introduction,[0],[0]
"In contrast, the previous approaches of adding edges or embeddings to the KB (Gardner et al., 2013), and vector space random walk PRA (Gardner et al., 2014) are batch procedures.",1 Introduction,[0],[0]
"As we shall see in Section 4, due to a limited search space, on-demand augmentation is much faster compared to algorithms in (Gardner et al., 2013; Gardner et al., 2014).",1 Introduction,[0],[0]
"Furthermore, since edges are not added blindly, on-demand augmentation does not increase feature sparsity which is responsible for performance degradation.",1 Introduction,[0],[0]
"Our experiments suggest that ODA provides better performance than (Gardner et al., 2013) and nearly the same prediction performance as provided by (Gardner et al., 2014), but in both cases with the added advantage of faster running time and greater flexibility due to its online and on-demand nature.",1 Introduction,[0],[0]
The code along with the results can be obtained at https://github.com/malllabiisc/pra-oda.,1 Introduction,[0],[0]
"Using surface level relations and noun phrases for extracting meaningful relational facts is not a new idea (Hearst, 1992),(Brin, 1999), (Etzioni et al., 2004).",2 Related Work,[0],[0]
"However, none of them make use of Knowledge Bases for improving information extraction.
",2 Related Work,[0],[0]
"The Path Ranking Algorithm (PRA) first proposed in (Lao and Cohen, 2010) was used for per-
forming inference over a KB in (Lao et al., 2011).",2 Related Work,[0],[0]
"It was extended by (Lao et al., 2012), to improve the inference by augmenting the KB with syntactic information obtained from a dependency parsed corpus.",2 Related Work,[0],[0]
"Augmenting the KB for improving PRA inference using surface relations mined from an external corpus and using latent edge labels obtained by performing PCA on the surface relations was explored in (Gardner et al., 2013).",2 Related Work,[0],[0]
"Instead of hard mapping of surface relations to latent embeddings, (Gardner et al., 2014) perform a ‘soft’ mapping using vector space random walks.",2 Related Work,[0],[0]
"This allows the random walker to traverse an edge semantically similar to the current edge type more frequently than other edges.
",2 Related Work,[0],[0]
"Although, like others, we too use an external corpus to augment the KB, the crucial difference in our approach is that apart from adding surface relations, we also add bridging entities that enable us to create new paths in the KB.",2 Related Work,[0],[0]
"Furthermore, the procedure is targeted so that only paths that play a part in inferring the relations that are of interest are added.",2 Related Work,[0],[0]
"Thus, the number of paths added in this manner is much lower than the number of surface relations added using the procedure in (Gardner et al., 2013).",2 Related Work,[0],[0]
"As we shall see in Section 4, this results in a more effective algorithm with faster runtime.",2 Related Work,[0],[0]
"We first present a brief overview of the Path Ranking Algorithm (PRA) (Lao and Cohen, 2010).",3.1 Background: Path Ranking Algorithm (PRA),[0],[0]
The PRA uses paths as features for a logistic regression classifier which predicts if the given relation exists between a pair of entities.,3.1 Background: Path Ranking Algorithm (PRA),[0],[0]
"For a given pair of entities s and t, the path type connecting s to t form the feature vector.",3.1 Background: Path Ranking Algorithm (PRA),[0],[0]
A path types π is an ordered set of relations.,3.1 Background: Path Ranking Algorithm (PRA),[0],[0]
Paths with the same ordered relations but different intermediate or terminal entities belong to the same path type.,3.1 Background: Path Ranking Algorithm (PRA),[0],[0]
"For example, s1
v0−→ x1 v1−→ t1 and s2 v0−→ x2 v1−→ t2 belong to path type v0−→ v1−→.",3.1 Background: Path Ranking Algorithm (PRA),[0],[0]
"The value of a feature, is taken to be P (s → t;π), where P (s → t;π) is the probability of reaching t from s by traversing paths of type π.",3.1 Background: Path Ranking Algorithm (PRA),[0],[0]
PRA approximates these probabilities by running a random walk (RW) on the KB graph.,3.1 Background: Path Ranking Algorithm (PRA),[0],[0]
"Let F = {π1, π2, ..., πk} be the set of all path types.",3.1 Background: Path Ranking Algorithm (PRA),[0],[0]
"For predicting the existence of relation r between entities s and t, the logistic regression classifier outputs a score which is a measure of the
confidence that r exists between s and t. It does so by first assigning weights to the features in the training phase.",3.1 Background: Path Ranking Algorithm (PRA),[0],[0]
"The score is given by
S(s, t, r) = ∑ π∈F P (s→ t;π)× θrπ (1)
where θrπ is the weight learned by the logistic regression classifier during training specially for relation r and path type π.",3.1 Background: Path Ranking Algorithm (PRA),[0],[0]
"During the test phase, since targets are not available, the PRA gathers candidate targets by performing a random walk and then computes feature vectors and the score.",3.1 Background: Path Ranking Algorithm (PRA),[0],[0]
"PRA-SVO and PRA-VS are the systems proposed in (Gardner et al., 2013) and (Gardner et al., 2014) respectively, where the KB graph is augmented with edges mined from a large subject-verb-object (SVO) triple corpus.",3.2 PRA-SVO and PRA-VS,[0],[0]
"In these two systems, only new edges are added over the fixed set of nodes, and the augmentation happens in a batch, offline setting.",3.2 PRA-SVO and PRA-VS,[0],[0]
"In contrast, PRA-ODA, the method proposed in the paper, also expands the set of nodes through bridging entities, and performs the augmentation in an on-demand manner.",3.2 PRA-SVO and PRA-VS,[0],[0]
Training: Let s and t be any two KB entities and let s(n) and t(n) be their corresponding noun phrase representations or aliases.,3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"We search for bridging entities x1, x2, ..xn by performing limited depth first search (DFS) starting with sn such that we obtain a path s ALIAS−→ s(n) v0−→ x1 v1−→ ...
vn−1−→",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
xn vn−→ t(n) ALIAS−→,3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"t, where vi are verbs present in the corpus graph.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"This is done for all n ≤ dmax− 1, where dmax is the maximum depth of DFS.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
We add an ‘ALIAS’ edge between the KB entity and its noun phase representation.,3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"The usefulness of bridging entities is illustrated in Fig. 1.
",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"We mine bridging entities from a corpus containing over 600 million SVO triples which were obtained from the ClueWeb09 corpus (Callan et
al., 2009)",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"parsed using the MALT parser (Nivre et al., 2007).",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
We use Mongo DB to store the triples as an adjacency list.,3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"During training time, for any relation that is being inferred, both the source and its corresponding target entities are known.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
A limited depth DFS is performed for all depths less then dmax on the SVO graph with the aliases of subject entity acting as the starting points.,3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
Such aliases are available for the NELL and Freebase knowledge bases.,3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
The DFS is said to discover a path if the terminating entity of the path matches any alias of the target entity.,3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"We choose to use aliases to perform string match, since it is easy to change the softness of the match by simply adding more aliases.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
This is done for all training sourcetarget pairs.,3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"A few examples of added paths are shown in Table 1.
",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
The SVO graph is noisy since it is obtained by parsing the ClueWeb corpus which was obtained by scraping the web.,3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"To reduce noise, we add the top K most frequent discovered SVO path types, whereK is a tunable parameter.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
By SVO path type we refer to a set of ordered verbs mined from the SVO corpus.,3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"There is a possibility that the bridging entities, extracted from the corpus, may be present in the KB.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"If the bridging entity matches any alias, then it is treated as an alias to an existing KB entity.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"If not, then the bridging entity is added to the KB as a new entity.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
To avoid overfitting we add negative data to the training set.,3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"Furthermore, only high quality expressive bridging entities result in meaningful and discriminative paths.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"Although the quality of bridging entities depend on the corpus, low quality bridging entities can be filtered out by adding negative training data.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"Low quality bridging entities connect source target pairs from both positive and negative training sets, and hence are eliminated by the sparse logistic regression classifier.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"The negative dataset is generated using the closed world assumption by performing a random walk.
",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"After augmenting the KB, we run the training phase of the PRA algorithm to obtain the feature (path) weights computed by the logistic regression
classifier.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
Query Time:,3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
The set of target entities corresponding to a source entity and the relation being predicted is not available during query (test) time.,3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
We use all the entities included in the range of the relation being predicted as candidate target entities.,3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"For example, if the relation is riverFlowsThroughCity, the candidate target set would include entities in the KB that are cities.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"The DFS is now performed starting from source entities as during training, but this time only restricting to paths with positive weights learned during training.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"Any path (along with bridging entities) found during this search are added to the KB, and the PRA algorithm is now run over this augmented graph.",3.3 PRA On-Demand Augmentation (PRA-ODA),[0],[0]
"We used the implementation of PRA provided by the authors of (Gardner et al., 2014).",4 Experiments,[0],[0]
"For our experiments, we used the same 10 NELL relation data as used in (Gardner et al., 2014).",4 Experiments,[0],[0]
"The augmentation resulted in the addition of 1086 paths during training and 1430 paths during test time.
",4 Experiments,[0],[0]
"We split the NELL data into 60% training data, 15 % development data and 25% test data.",4 Experiments,[0],[0]
"Values for dmax, and K, the most frequent paths, were obtained by tuning on a development set for 4 relations (athleteplaysforsport,actorstarredinmovie,citylocatedincountry
and journalistwritesforpublication).",4 Experiments,[0],[0]
"The hyperparameter values dmax = 2, K = 10 reported the highest MRR and were used for the rest of the relations.",4 Experiments,[0],[0]
"For the L1 and L2 regularization parameters in the logistic regression classifier, we used the same values as used in (Gardner et al., 2013; Gardner et al., 2014), viz., L1 = 0.005, and L2 = 1.0.",4 Experiments,[0],[0]
"This is because the parameters were reported to be robust, and seemed to work well even when the knowledge base was augmented.
",4 Experiments,[0],[0]
"We compare the results (PRA-ODA) with the PRA algorithm executed on the NELL KB, NELL KB augmented with surface relations (PRA-SVO) (Gardner et al., 2013) and vector space random walk PRA (PRA-VS) (Gardner et al., 2014).",4 Experiments,[0],[0]
"The run times, i.e, the time taken to perform an entire experiment for PRA-SVO and PRA-VS includes the time taken to augment NELL KB with SVO edges.",4 Experiments,[0],[0]
The PRA-VS runtime also includes the time taken for generating embeddings to perform the vector space random walk.,4 Experiments,[0],[0]
"As can be seen from Table 2 and Table 3, our scheme, PRA-ODA, provides performance equivalent to PRA-VS with faster running time (speed up of 1.8).",4 Experiments,[0],[0]
"In addition to the time taken for the full SVO augmentation, PRA-VS takes additional time to generate embeddings (13 minutes) from the added verbs.",4 Experiments,[0],[0]
"We note that the batch augmentation in case of PRA-SVO and PRA-VS, and embedding computation in case of PRA-VS are all specific to the relations in the evaluation set, and hence can’t be ignored as a one-time offline cost.",4 Experiments,[0],[0]
"In other words, these costs are likely to increase as more relations (and their instances) are included during training and testing.",4 Experiments,[0],[0]
"Runtime gains with PRA-ODA are likely to be even more pronounced in such settings.
",4 Experiments,[0],[0]
An additional advantage of the proposed algorithm is that it can also be run on the top of any PRA based algorithm such as the PRA-SVO and PRA-VS.,4 Experiments,[0],[0]
"In this paper, we investigated the usefulness of adding paths to a Knowledge Base for improving its connectivity by mining bridging entities from an external corpus.",5 Conclusion,[0],[0]
"While previous KB augmentation methods focused only on augmentation using mined surface verbs while keeping the node set fixed, we extended these approaches by also adding bridging entities in an online fashion.",5 Conclusion,[0],[0]
We used a large corpus of 500 million web text corpus to mine these additional edges and bridging entities.,5 Conclusion,[0],[0]
"Through experiments on real-world datasets, we demonstrate that the proposed approach is not only comparable or better than other state-of-theart baselines, but more importantly provides faster overall runtime compared with the alternatives.",5 Conclusion,[0],[0]
This work is supported in part by a gift from Google.,Acknowledgment,[0],[0]
"Large-scale Knowledge Bases (such as NELL, Yago, Freebase, etc.) are often sparse, i.e., a large number of valid relations between existing entities are missing.",abstractText,[0],[0]
"Recent research have addressed this problem by augmenting the KB graph with additional edges mined from a large text corpus while keeping the set of nodes fixed, and then using the Path Ranking Algorithm (PRA) to perform KB inference over this augmented graph.",abstractText,[0],[0]
"In this paper, we extend this line of work by augmenting the KB graph not only with edges, but also with bridging entities, where both the edges and bridging entities are mined from a 500 million web text corpus.",abstractText,[0],[0]
"Through experiments on real-world datasets, we demonstrate the value of bridging entities in improving the performance and running time of PRA in the KB inference task.",abstractText,[0],[0]
Knowledge Base Inference using Bridging Entities,title,[0],[0]
"We consider the problem of completing a partial knowledge base (KB) containing facts about gener-
∗This work was done while the author was affiliated with the Allen Institute for Artificial Intelligence.
ics or common nouns, represented as a third-order tensor of (source, relation, target) triples, such as (butterfly, pollinate, flower) and (thermometer, measure, temperature).",1 Introduction,[0],[0]
Such facts capture common knowledge that humans have about the world.,1 Introduction,[0],[0]
They are arguably essential for intelligent agents with human-like conversational abilities as well as for specific applications such as question answering.,1 Introduction,[0],[0]
"We demonstrate that state-of-the-art KB completion methods perform poorly when faced with generics, while our strategies for incorporating external knowledge as well as obtaining additional annotations for rare entities provide the first successful solution to this challenging new task.
",1 Introduction,[0],[0]
"Since generics represent classes of similar individuals, the truth value yi of a generics triple xi = (s, r, t) depends on the quantification semantics one associates with s and t. Indeed, the semantics of generics statements can be ambiguous, even selfcontradictory, due to cultural norms.",1 Introduction,[0],[0]
"As Leslie (2008) points out, ‘ducks lay eggs’ is generally considered true while ‘ducks are female’, which is true for a broader set of ducks than the former statement, is generally considered false.
",1 Introduction,[0],[0]
"To avoid deep philosophical issues, we fix a particular mathematical semantics that is especially relevant for noisy facts derived automatically from text: associate s with a categorical quantification from {all, some, none} and associate t (implicitly) with some.",1 Introduction,[0],[0]
"For instance, “all butterflies pollinate (some) flower” and “some animals live in (some) forest”.",1 Introduction,[0],[0]
"When presenting such triples to humans, they are phrased as: is it true that all butterflies pollinate some flower?",1 Introduction,[0],[0]
"As a notational shortcut, we treat the quantification of s as the categorical label yi for the triple xi.",1 Introduction,[0],[0]
"For example, (butterfly, pollinate, flower)
197
Transactions of the Association for Computational Linguistics, vol. 6, pp.",1 Introduction,[0],[0]
"197–210, 2018.",1 Introduction,[0],[0]
Action Editor: Hinrich Schütze.,1 Introduction,[0],[0]
"Submission batch: 6/2017; Revision batch: 9/2017; Published 4/2018.
",1 Introduction,[0],[0]
c©2018 Association for Computational Linguistics.,1 Introduction,[0],[0]
"Distributed under a CC-BY 4.0 license.
is labeled all while (animal, live in, forest) is labeled some.",1 Introduction,[0],[0]
"Given a noisy KB of such labeled triples, the task is to infer more triples.
",1 Introduction,[0],[0]
"Tensor factorization and graph based methods have both been found to be very effective for expanding knowledge bases, but have focused on named entity KBs such as Freebase (Bollacker et al., 2008) involving relations with clear semantics such as liveIn and isACityIn, and disambiguated entities such as Barack Obama or Hawaii.",1 Introduction,[0],[0]
"Completing KBs that involve facts about generics, however, brings up new challenges, as evidenced by our empirical results when using existing methods.
",1 Introduction,[0],[0]
It has been observed that Horn clauses often reliably connect predicates in the named-entity setting.,1 Introduction,[0],[0]
"For instance, for any person x, city y, and country z, (x, liveIn, y) & (y, isACityIn, z) ⇒",1 Introduction,[0],[0]
"(x, liveIn, z).",1 Introduction,[0],[0]
"With generics, however, clear patterns or reliable first-order logic rules are rare, in part due to each generic representing a collection of individuals that often have similarities with respect to some relations and differences with respect to others.",1 Introduction,[0],[0]
"For instance, (x, liveIn, mountain) is true for many cats and caribou, but there is little tangible similarity between the two animals and it is unclear what, if anything, can be carried over from one to the other.",1 Introduction,[0],[0]
"On the other hand, if we take two animals that share a ‘parent’ in some taxonomy (e.g., reindeer and deer), then the likelihood of knowledge transfer increases.
",1 Introduction,[0],[0]
"We propose to make use of additional rich background knowledge complementing the information present in the KB itself, such as a taxonomic hierarchy of entities (available from sources such as WordNet (Miller, 1995)) and the corresponding entity types and relation schema.",1 Introduction,[0],[0]
"Our key insight is that, if used appropriately, taxonomic and schema information can be surprisingly effective in making tensor factorization methods vastly more effective for generics for deriving high precision facts.
",1 Introduction,[0],[0]
"Intuitively, for generics, many properties of interest are themselves generic (e.g., living in forests, as opposed to living in a specific forest) and tend to be shared by siblings in a taxonomy (e.g., finch, oriole, and hummingbird).",1 Introduction,[0],[0]
"In contrast, siblings of named entities (e.g., various people) often differ substantially in the properties we typically care about and model (e.g., who they are married to, where they live, etc.).",1 Introduction,[0],[0]
"Methods that use type information are
thus more promising for generics than for classical NLP tasks involving named entities.",1 Introduction,[0],[0]
"We propose three ways of using this information and empirically demonstrate the effectiveness of each on two variants of a KB of elementary level science facts (Dalvi et al., 2017).1
First, we observe that simply imposing schema consistency (Section 3.1) on derived facts can significantly boost state-of-the-art methods such as Holographic Embeddings (HolE) (Nickel et al., 2016b) from nearly no new facts at 80% precision to over 10,000 new facts, starting with a generics KB of a similar size.",1 Introduction,[0],[0]
"Other embedding methods, such as TransE (Bordes et al., 2013), RESCAL (Nickel et al., 2011), and SICTF (Nimishakavi et al., 2016) (which uses schema information as well), also produced no new facts at 80% precision.",1 Introduction,[0],[0]
"Graph-based completion methods did not scale to our densely connected tensors.2
Second, one can further boost performance by transferring knowledge up and down the taxonomic hierarchy, using the quantification semantics of generics (Section 3.2).",1 Introduction,[0],[0]
"We show that expanding the starting tensor this way before applying tensor factorization is complementary and results in a statistically significantly higher precision (86.4% as opposed to 82%) over new facts at the same yield.
",1 Introduction,[0],[0]
"Finally, we propose a novel limited-budget taxonomy guided active learning method to address the challenge of significant incompleteness in generics KBs, by quantifying uncertainty via siblings (Section 4).",1 Introduction,[0],[0]
"Dalvi et al. (2017) have observed that, when using information extraction methods, it is much harder to derive reliable facts about generics than about named entities.",1 Introduction,[0],[0]
"This makes generics KBs vastly incomplete, with no or very little information about certain entities such as caribou or oriole.
",1 Introduction,[0],[0]
1We are unaware of other large generics KBs.,1 Introduction,[0],[0]
"Our method does not employ rules or choices specific to this dataset and is expected to generalize to other generics KBs, as and when they become available.
2On the smaller Animals tensor (to be described later),",1 Introduction,[0],[0]
"PRA (Lao et al., 2011) generated very few high-precision facts after 30 hours.",1 Introduction,[0],[0]
"SFE (Gardner and Mitchell, 2015) was unable to finish training a classifier for any relation after a day, in part due to the high connectivity of generics like animal.",1 Introduction,[0],[0]
"On the other hand, HolE is trained in a couple of minutes even on the larger Science tensor, and can be made even faster using the method of Hayashi and Shimbo (2017).
",1 Introduction,[0],[0]
"Our active learning approach addresses the following question: Given a new entity3 ẽ and a budget B, what is a good set Q of B queries about ẽ to annotate (via humans) such that expanding the original tensor with Q helps a KB completion method infer many more high precision facts about ẽ?
We propose to define a correlation based measure of the uncertainty of each unannotated triple (i.e., a potential query) involving ẽ, based on how frequently the corresponding triple is true for ẽ’s siblings in the taxonomic hierarchy (Section 4.1).",1 Introduction,[0],[0]
"We then develop a submodular objective function, and a corresponding greedy (1 − 1/e)-approximation, to search for a small subset of triples to annotate that optimally balances diversity with coverage (Section 4.2).",1 Introduction,[0],[0]
We demonstrate that annotating this balanced subset makes tensor factorization derive substantially more new and interesting facts compared to several active learning baselines.,1 Introduction,[0],[0]
"For example, with a budget to annotate 100 queries about a new entity oriole, random queries lead to no new true facts at all (via annotation followed by tensor factorization), imposing schema consistency results in 83 new facts, and our proposed method ends up with 483 new facts.",1 Introduction,[0],[0]
"This demonstrates that well-designed intelligent queries can be substantially more effective in gathering facts about the new entity.
",1 Introduction,[0],[0]
"In summary, this work tackles, for the first time, the challenging task of knowledge completion for generics, by imposing consistency with external knowledge.",1 Introduction,[0],[0]
"Our efficient sibling-guided active learning approach addresses the paucity of facts about certain entities, successfully inferring a substantial number of new facts about them.",1 Introduction,[0],[0]
KB completion approaches fall into two main classes: graph-based methods and those employing low-dimensional embeddings via matrix or tensor factorization.,1.1 Related Work,[0],[0]
"The former uses graph traversal techniques to complete the KB, by learning which types of paths or transitions are indicative of which relation between the start and end points (Lao et al., 2011; Gardner and Mitchell, 2015).",1.1 Related Work,[0],[0]
"This class of solutions, unfortunately, does not scale well to
3Unless otherwise stated, we will henceforth use entity to refer to a singular common noun that represents a class or group of individuals, such as animal, hummingbird, forest, etc.
our setting (cf. Footnote 2).",1.1 Related Work,[0],[0]
"This appears due, at least in part, to different connectivity characteristics of generics tensors compared to named entity ones such as FB15k (Bordes et al., 2013).",1.1 Related Work,[0],[0]
"Advances in the latter set of methods have led to several embedding-based methods that are highly successful at KB completion for named entities (Nickel et al., 2011; Riedel et al., 2013; Dong et al., 2014; Trouillon et al., 2016; Nickel et al., 2016a).",1.1 Related Work,[0],[0]
"We compare against many of these, including variants of HolE, TransE, and RESCAL.
",1.1 Related Work,[0],[0]
"Recent work on incorporating entity type and relation schema in tensor factorization (Krompaß et al., 2014; Krompaß et al., 2015; Xie et al., 2016b) has focused on factual databases about named entities, which, as discussed earlier, have very different characteristics than generics tensors.",1.1 Related Work,[0],[0]
Nimishakavi et al. (2016) use entity type information as a matrix in the context of non-negative RESCAL for schema induction on medical research documents.,1.1 Related Work,[0],[0]
"As a byproduct, they complete missing entries in the tensor in a schema-compatible manner.",1.1 Related Work,[0],[0]
"We show that our proposal performs better on generics tensors than their method, SICTF.",1.1 Related Work,[0],[0]
"SICTF, in turn, is meant to be an improvement over the TRESCAL system of Chang et al. (2014), which also incorporates types in RESCAL in a similar manner.",1.1 Related Work,[0],[0]
"Recently, Schütze et al. (2017) proposed a neural model for fine-grained entity typing and for robustly using type information to improve relation extraction, but this is targeted for Freebase style named entities.
",1.1 Related Work,[0],[0]
"For schema-aware discriminative training of embeddings, Xie et al. (2016b) use a flexible ratio of negative samples from both schema consistent and schema inconsistent triples.",1.1 Related Work,[0],[0]
"Their combined ideas, however, do not improve upon vanilla HolE (one of our baselines) on the standard FB15k (Bordes et al., 2013) dataset.",1.1 Related Work,[0],[0]
"They also consider imposing hierarchical types for Freebase, as entities may have different meanings when they have different types— an issue that typically does not apply to generics KBs.",1.1 Related Work,[0],[0]
Komninos and Manandhar (2017) use type information along with additional textual evidence for knowledge base completion on the FB15k237 dataset.,1.1 Related Work,[0],[0]
"They learn embeddings for types, along with entities and relations, and show that this way of incorporating type information has a (small) contribution towards improving performance.",1.1 Related Work,[0],[0]
"Incorpo-
rating given first order logic rules has been explored for the simpler case of matrix factorization (Rocktaschel et al., 2015; Demeester et al., 2016).",1.1 Related Work,[0],[0]
"Existing first order logic rule extraction methods, however, struggle to find meaningful rules for generics, making this approach not yet viable in our setting.
",1.1 Related Work,[0],[0]
Xie et al. (2016a) consider inferring facts about a new entity ẽ given a ‘description’ of that entity.,1.1 Related Work,[0],[0]
"They use Convolutional Neural Networks (CNNs) to encode the description, deriving an embedding for ẽ. Such a description in our context would correspond to knowing some factual triples about ẽ, which is a restricted version of our active learning setting.
Krishnamurthy and Singh (2013) consider active learning for a particular kind of tensor decomposition, namely CP or Candecomp/Parafac decomposition into a low dimensional space.",1.1 Related Work,[0],[0]
They start with an empty tensor and look for the most informative slices and columns to fill completely to achieve optimal sample complexity.,1.1 Related Work,[0],[0]
"Their framework builds upon the incoherence assumption on the column space, which does not apply to generics KB.
Hegde and Talukdar (2015) use an entity-centric information extraction (IE) approach for obtaining new facts about entities of interest.",1.1 Related Work,[0],[0]
Narasimhan et al. (2016) use a reinforcement learning approach to issue search queries to acquire additional evidence for a candidate fact.,1.1 Related Work,[0],[0]
"Both of these works, and others along similar lines, are advanced IE techniques that operate via a search for new documents and extraction of facts from them.",1.1 Related Work,[0],[0]
"This is different from the KB completion task, where the only source of information is the starting KB and possibly some details about the involved entities and relations.",1.1 Related Work,[0],[0]
"We consider knowledge expressed in terms of (source, relation, target) triples, abbreviated as (s, r, t).",2 Tensors of Generics,[0],[0]
"Such a triple may refer to (subject, predicate, object) style facts commonly used in information extraction.",2 Tensors of Generics,[0],[0]
"Each source and target is an entity that is a generic noun, e.g., animals, habitats, or food items.",2 Tensors of Generics,[0],[0]
"Examples of relations include foundIn, eat, etc.",2 Tensors of Generics,[0],[0]
"As mentioned earlier, with each generics triple (s, r, t), we associate a categorical truth value q ∈",2 Tensors of Generics,[0],[0]
"{all, some, none}, defining the quantification semantics “q s r (some) t”.",2 Tensors of Generics,[0],[0]
"For instance, “some an-
imals live in (some) forest” and “all dogs eat (some) bone”.",2 Tensors of Generics,[0],[0]
"Given a set K of such triples with annotated truth values, the task is to predict additional triples K ′",2 Tensors of Generics,[0],[0]
"that are also likely to be true.
",2 Tensors of Generics,[0],[0]
"In addition to a list of triples, we assume access to background information in the form of entity types and the corresponding relation schema, as well as a taxonomic hierarchy.4 Let ET denote the set of possible entity types.",2 Tensors of Generics,[0],[0]
"For each relation r, the relation schema imposes a type constraint on the entities that may appear as its source or target.",2 Tensors of Generics,[0],[0]
"Specifically, using [`] to denote the set {1, 2, . . .",2 Tensors of Generics,[0],[0]
", `}, the schema for r is a collection Sr = {(D(i)r ,R(i)r ) ⊆ ET × ET",2 Tensors of Generics,[0],[0]
| i ∈,2 Tensors of Generics,[0],[0]
"[`]} of domain-range pairs with the following property: the truth value of (s, r, t) is none whenever for every",2 Tensors of Generics,[0],[0]
i ∈,2 Tensors of Generics,[0],[0]
[`] it is the case that s /∈,2 Tensors of Generics,[0],[0]
D(i)r or t /∈,2 Tensors of Generics,[0],[0]
R(i)r .,2 Tensors of Generics,[0],[0]
"For example, the relation foundIn may be associated with the schema SfoundIn = {(animal, location), (insect, animal), (plant, habitat), . . .",2 Tensors of Generics,[0],[0]
}.,2 Tensors of Generics,[0],[0]
"Similarly, the taxonomic hierarchy defines a partial order H over all entities that captures the “isa” relation, with direct links such as isa(dog, mammal) or isa(gerbil, rodent).",2 Tensors of Generics,[0],[0]
"We use this information to extract “siblings” of a given entity, i.e., entities that share a common parent (this may be easily generalized to any common ancestor).",2 Tensors of Generics,[0],[0]
We begin with an overview of tensor factorization for KB completion for generics.,3 Guided Knowledge Completion,[0],[0]
"Let (s, r, t) be a generics triple associated with a categorical quantification label q ∈ {all, some, none}.",3 Guided Knowledge Completion,[0],[0]
"For example, ((cat, havePart, whiskers), all), ((cat, liveIn, homes), some), and ((cat, eat, bear), none).",3 Guided Knowledge Completion,[0],[0]
Predicting such labels is thus a multi-class classification problem.,3 Guided Knowledge Completion,[0],[0]
"Given a set K of labeled triples, the goal of tensor factorization is to learn a low-dimensional embedding h for each entity and relation such that some function f of h best captures the given labels.",3 Guided Knowledge Completion,[0],[0]
"Given a new triple, we can then use f and the learned h to predict the probability of each label for it.",3 Guided Knowledge Completion,[0],[0]
"K often contains only “positive” triples, i.e., those with label all or some.",3 Guided Knowledge Completion,[0],[0]
"A common step in discriminative training for h is thus negative sampling, i.e., generating additional triples that (are expected to) have
4We do not assume that the schema or taxonomy is perfect, and instead rely on these only for heuristic guidance.
",3 Guided Knowledge Completion,[0],[0]
label none.,3 Guided Knowledge Completion,[0],[0]
"With [m] denoting the set {1, 2, . . .",3 Guided Knowledge Completion,[0],[0]
",m} as before, let K = {(xi, yi),",3 Guided Knowledge Completion,[0],[0]
i ∈,3 Guided Knowledge Completion,[0],[0]
[m]} be a set of triples,3 Guided Knowledge Completion,[0],[0]
"xi = (si, ri, ti) and corresponding labels",3 Guided Knowledge Completion,[0],[0]
"yi ∈ {1, 2, 3} equivalent to categorical quantification label qi ∈ {all, some, none}.",3 Guided Knowledge Completion,[0],[0]
"We learn entity and relation embeddings Θ that minimize the multinomial logistic loss defined as:
min Θ
m∑
i=1
3∑
k=1
−1{yi = k} log Pr(yi = k | xi,Θ)
=",3 Guided Knowledge Completion,[0],[0]
"min Θ
m∑
i=1
3∑
k=1
−1{yi = k} log σ(yi f(hr, hs, ht))
(1)
where hr, hs, ht ∈ Rd denote the learned embeddings (latent vectors) for s, r, t, respectively, and σ(·) is the sigmoid function defined as σ(z) =
1 1+exp(−z) .
",3 Guided Knowledge Completion,[0],[0]
"If the all categorical label for generics is unavailable,5 we can simplify the label space to {some, none}, modeled as yi ∈ {±1}, and reduce the model to binary classification:
min Θ
m∑
i=1
log [1 + exp",3 Guided Knowledge Completion,[0],[0]
"[−yi f(hr, hs, ht)]] .",3 Guided Knowledge Completion,[0],[0]
"(2)
We remark that while this generics task with only two labels appears superficially similar to the standard KB completion task for named entities, the underlying challenges and solutions are different.",3 Guided Knowledge Completion,[0],[0]
"For instance, the approach of using taxonomic information (as opposed to just entity types) as a guide is uniquely suited to generics KBs; the reason being that a generic entity refers to a set of individuals, with a natural subset/superset relation forming a taxonomy, whereas in standard KBs an entity refers to one specific individual.",3 Guided Knowledge Completion,[0],[0]
"This prevents taxonomy based rules from providing useful information for standard KBs, while our results demonstrate their high value when reasoning with generics.",3 Guided Knowledge Completion,[0],[0]
"Differences like this lead to differences in what is successful in each setting and what is not.
",3 Guided Knowledge Completion,[0],[0]
"5This happens to be the case for current generics KBs, but is expected to change with increasing interest in the research community.",3 Guided Knowledge Completion,[0],[0]
"A step in this direction is a recent version of the Aristo Tuple KB, http://allenai.org/data/aristo-tuple-kb, which includes most as a quantification label, in addition to some.
",3 Guided Knowledge Completion,[0],[0]
"While all our proposed schemes are embedding oblivious, for concreteness, we describe and evaluate them for the Holographic Embedding or HolE (Nickel et al., 2016b) which models the label probability as:
f(hr, hs, ht) = h > r",3 Guided Knowledge Completion,[0],[0]
"(hs ◦ ht) (3)
where ◦ : Rd × Rd → Rd denotes circular correlation defined as:
[a ◦ b]k = d−1∑
i=0
aib(i+k) mod d .",3 Guided Knowledge Completion,[0],[0]
"(4)
Intuitively, the k-th dimension of circular correlation captures how related a is to b when the dimensions of the latter are shifted (circularly, via the mod operation) by k.",3 Guided Knowledge Completion,[0],[0]
In particular [a ◦ b]0 is simply the dot product of a and b.,3 Guided Knowledge Completion,[0],[0]
As can be deduced from Eqns.,3 Guided Knowledge Completion,[0],[0]
"(3)-(4), this model resembles circular convolution, but can capture, to some extent, relations that are asymmetric among the source and target entities.",3 Guided Knowledge Completion,[0],[0]
This is because [a ◦ b] is not the same as [b ◦a] but is rather “flipped” ([a◦b]k = [b◦a]d−k).,3 Guided Knowledge Completion,[0],[0]
"If we consider the d × d matrix Mab of element-wise relationships between a and b, the HolE embedding of a relation r between a and b defines a weighted sum of circular anti-diagonals of Mab.
",3 Guided Knowledge Completion,[0],[0]
"Circular correlation can be computed using the fast Fourier transform (FFT), making HolE quite efficient in practice.",3 Guided Knowledge Completion,[0],[0]
"Hayashi and Shimbo (2017) recently showed that HolE and complex embeddings (Trouillon et al., 2016), which is another stateof-the-art method for KB completion, are equivalent and differ only in terms of constraints on initial values.",3 Guided Knowledge Completion,[0],[0]
"Further, they proposed a linear time computation for HolE by staying fully within the frequency domain of FFT.",3 Guided Knowledge Completion,[0],[0]
"As described earlier, relation schema Sr imposes a restriction on sources and targets that may occur with a relation r.",3.1 Incorporating Types and Relation Schema (ITRS),[0],[0]
We can incorporate this knowledge both at training and at test times.,3.1 Incorporating Types and Relation Schema (ITRS),[0],[0]
Doing this at test time simply translates to relabeling schemainconsistent predicted triples as none.,3.1 Incorporating Types and Relation Schema (ITRS),[0],[0]
"Incorporating this knowledge at training time can be done as a constraint on the random negative samples that
the method generates to complement the given, typically positive, triples for training.
",3.1 Incorporating Types and Relation Schema (ITRS),[0],[0]
"In general, the ratio of random negative samples from the entire tensor T and random negative samples from the schema consistent portion T ′ of T is a parameter that should be tuned such that the resulting negative samples mimic the true distribution of labels.",3.1 Incorporating Types and Relation Schema (ITRS),[0],[0]
It is worth noting that whether the locally closed world assumption (LCWA) holds or not plays an important role in determining this ratio.,3.1 Incorporating Types and Relation Schema (ITRS),[0],[0]
"However, the idea of mixing the two kinds of negative samples has been used in the literature without considering the nature of the dataset, resulting in some seemingly contradicting empirical results on the optimal ratio (Li et al., 2016; Xie et al., 2016b; Shi and Weninger, 2017; Xie et al., 2017).",3.1 Incorporating Types and Relation Schema (ITRS),[0],[0]
"As discussed later, we found sampling from T to work best on our datasets.",3.1 Incorporating Types and Relation Schema (ITRS),[0],[0]
"It is challenging to come up with complex Horn or first order logic rules for generics, as each entity represents a class of individuals that may not all behave identically.",3.2 Incorporating Entity Taxonomy (IET),[0],[0]
"However, we can derive simple yet highly effective rules based on categorical quantification labels, leveraging the fact that entities come from different levels in a taxonomy hierarchy.
",3.2 Incorporating Entity Taxonomy (IET),[0],[0]
Let p be the parent entity for entity set {ci}.,3.2 Incorporating Entity Taxonomy (IET),[0],[0]
"Note that ci itself is a generic, that is, a class of individuals rather than a single individual.",3.2 Incorporating Entity Taxonomy (IET),[0],[0]
"This allows one to make meaningful existential statements such as: if a property holds for all or most members of even one class ci, then it holds for some (reasonable number of) members of its parent class p.",3.2 Incorporating Entity Taxonomy (IET),[0],[0]
"We use the following rules:6
((p, rj , tj), all)⇒ ∀i ((ci, rj , tj), all) ∀i ((ci, rj , tj), all)⇒ ((p, ej , tj), all) ∃i",3.2 Incorporating Entity Taxonomy (IET),[0],[0]
"((ci, rj , tj), all)⇒ ((p, ej , tj), some)
∃i",3.2 Incorporating Entity Taxonomy (IET),[0],[0]
"((ci, rj , tj), some)⇒ ((p, ej , tj), some)
",3.2 Incorporating Entity Taxonomy (IET),[0],[0]
"We apply these rules to address sparsity of generics tensors, making tensor factorization more robust.",3.2 Incorporating Entity Taxonomy (IET),[0],[0]
"Specifically, given initial triples K, we use applicable rules to derive additional triples K ′, perform
6The last rule may not be appropriate for KBs where some may refer to the extreme case of a single individual.",3.2 Incorporating Entity Taxonomy (IET),[0],[0]
"This is not the case for the KBs we use for our evaluation.
tensor factorization on K ∪K ′, and then revisit the triples in K ′ using their predicted label probabilities.",3.2 Incorporating Entity Taxonomy (IET),[0],[0]
"Note that this approach allows us to be robust to taxonomic errors: instead of assuming each triple in K ′ is true, we use this only as a prior and let tensor factorization determine the final prediction based on global patterns it finds.",3.2 Incorporating Entity Taxonomy (IET),[0],[0]
"To address the incomplete nature of generics KBs, we consider rare entities for which we have very few facts, or new entities which are present in the taxonomy but for which we have no facts in the KB.",4 Active Learning for New or Rare Entities,[0],[0]
"The goal is to use tensor factorization to generate high quality facts about such entities.
",4 Active Learning for New or Rare Entities,[0],[0]
"For instance, consider the task of inferring facts about oriole, where all we know is that it is a bird.",4 Active Learning for New or Rare Entities,[0],[0]
"We assume a restricted budget on the number of facts we can query (for human annotation) about oriole, using which we would like to predict many more high-quality facts about it.
",4 Active Learning for New or Rare Entities,[0],[0]
"Given a fixed query budget B, what is the optimal set of queries we should generate for human annotation about a new or rare entity ẽ for this task?",4 Active Learning for New or Rare Entities,[0],[0]
We view this as an active learning problem and propose a two-step algorithm.,4 Active Learning for New or Rare Entities,[0],[0]
"First, we use taxonomy guided uncertainty sampling to propose a list L to potentially query.",4 Active Learning for New or Rare Entities,[0],[0]
"Next, we describe a submodular objective function and a corresponding linear time algorithm to choose an optimal subset L̂ ⊆ L satisfying |L̂| = B. We then use L̂ for human annotation, append the result to the original KB, and perform tensor factorization to predict additional new facts about ẽ. For notational simplicity and without loss of generality, throughout this section, we consider the case where ẽ appears as the source entity in the triple; the ideas apply equally when ẽ appears as the target entity in the triple.",4 Active Learning for New or Rare Entities,[0],[0]
We now discuss the active learning and specifically uncertainty sampling method we use to propose a list of triples to query.,4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"Uncertainty sampling considers the uncertainty for each possible triple (ẽ, ri, ei), defined as how far away from 0.5 the conditional probability is of this fact, given the facts we already
know from the KB (Settles, 2012).",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
The question is how to model this conditional probability.,4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"A simple baseline is to consider Random queries, i.e., r, e are selected randomly from the list of relations and entities in the tensor, respectively.
",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"To infer information about ẽ, we propose the following approximation for the conditional probability of a new fact about ẽ given the KB.",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"Let Ẽẽ = {e | corr(ẽ, e) > 0} be the set of entities that are correlated with ẽ, Ω = {((ei, ri, e′i), yi)",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"| ei ∈ Ẽẽ} be the set of known facts about such entities, and yi be the label for the triple (ei, ri, e′i).",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"We have:
Pr(f(hri , hẽ, he′i)) ' 1 |Ω| ∑
ei∈Ẽẽ
corr(ẽ, ei) yi.",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"(5)
However, in practice, we cannot measure corr(ẽ, ei) for every entry in the KB as we do not have complete information about ẽ. One simple idea is to consider that every entity is correlated with ẽ: corr(ẽ, ei) = 1 ∀ei ∈ E.",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"We will refer to this as Schema Consistent query proposal as this relates to summing over all possible (hence schema consistent) facts.
",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"Since we have access to taxonomy information, we can do a more precise, Sibling Guided, approximation.7",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"We propose the following approximation for corr(ẽ, ei) for ei ∈ E:
corr(ẽ, ei) =",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
{ 1 if ei ∈ sibling(ẽ) 0,4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
otherwise .,4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"(6)
Eqns.",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"(5) and (6) can be used to infer uncertain triples: if every sibling of ẽ has relationship r with an entity e′, we can infer for “free” that this is the case for ẽ as well.",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"On the other hand, when siblings disagree in this respect, there is more uncertainty about (ẽ, r, e′)",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"(according to (5) and (6)), making this triple a good candidate to query.",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"In our example of oriole, the siblings are the birds that exist in the tensor, e.g., hummingbird, finch, woodpecker, etc.",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"All of them (eat, insect) and hence we infer this for oriole.",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"But there is no agreement on (appearIn, farm) and hence this is added to the query list.
",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
7One may also define corr based on entity similarity in a distributional space.,4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
One challenge here is that such similarity generally doesn’t preserve types.,4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"For example, dog may cooccur more often with and thus be “closer” to bone or barking in a distributional space, than to siblings such as cat or other pet animals, which are more helpful in our setting.
",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"Algorithm 1: Active Learning for Query Proposal
input new entity ẽ, KB, taxonomy, lower bound κM on agreement, lower bound τL on uncertainty, upper bound τU on uncertainty
1: extract list Sẽ of sibling(ẽ) using taxonomy 2: for each ei ∈ Sẽ, add all facts about ei to Ω 3: for (ẽ, ri, e′i) ∈ Ω do 4: use (5)-(6) to estimate Pr(f(hri , hẽ, he′i)) 5",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
: if p ≥ κM,4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"then add (ẽ, ri, e′i) to M 6: if τL ≤ p ≤ τU then add (ẽ, ri, e′i) to L
output L, M
Algorithm 1 formalizes this process.",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"Setting some upper (τU ) and lower (τL) bounds on the conditional probability (Eqn. (5)) which quantifies the uncertainty, we reach a set L = {(ẽ, ri, ei), i ∈",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
I} of triples to query.,4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
Using another high threshold κM,4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"> τU , we also infer the set M = {(ẽ, rj , ej), j ∈ J} of triples that a large majority of siblings agree upon, and hence ẽ is expected to agree with as well.",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
Triples whose conditional probability estimate is between κM and τU are considered neither certain enough to include in M nor uncertain enough to justify adding to L for human annotation in hopes of learning from it.,4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"Similarly, triples with a conditional probability estimate lower than τL are discarded.",4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
The output of Algorithm 1 is the list L to query and the list M to add directly to the knowledge base.,4.1 Knowledge Guided Uncertainty Quantification,[0],[0]
"Given the list L as above (Algorithm 1), which we can write in short as L = {(ri, ei), i ∈",4.2 Efficient Subset Selection,[0],[0]
"I}, the problem is to find the “best” subset L̂. A baseline for such a selection is to choose the top k queries.",4.2 Efficient Subset Selection,[0],[0]
"We will refer to this as TK subset selection.
",4.2 Efficient Subset Selection,[0],[0]
"Viewing subset selection as a combinatorial problem, we devise an objective F that models several natural properties of this subset.",4.2 Efficient Subset Selection,[0],[0]
"We then prove that F is submodular, that is, the marginal gain inF(L) obtained by adding one more item to L decreases as L grows.8",4.2 Efficient Subset Selection,[0],[0]
"Importantly, this implies that there is a simple known greedy algorithm that can efficiently compute a worst-case (1 − 1/e)-approximation of
8Formally, for L′′ ⊆ L′",4.2 Efficient Subset Selection,[0],[0]
"⊆ L and for l = (rl, el) ∈",4.2 Efficient Subset Selection,[0],[0]
"L \ L′, we have F(L′′ ∪ l)−F(L′′) ≥ F(L′ ∪ l)−F(L′).
",4.2 Efficient Subset Selection,[0],[0]
"the global optimum of F (Nemhauser et al., 1978).",4.2 Efficient Subset Selection,[0],[0]
"We refer to this as SM subset selection.
",4.2 Efficient Subset Selection,[0],[0]
"Since queried samples will eventually be fed into tensor factorization, we would like L̂ to cover entities (for the other argument of the triple) and relations as much as possible.",4.2 Efficient Subset Selection,[0],[0]
"In addition, we would like L̂ to be diverse, i.e., prioritize relations and entities that are more varied.9",4.2 Efficient Subset Selection,[0],[0]
"At the same time, we would also want to minimize redundancy, i.e., avoid choosing relations (entities) that are too similar.",4.2 Efficient Subset Selection,[0],[0]
"Let F(L̂, R
L̂ , E L̂ ) denote our objective, where R L̂ , E L̂
is the set of relations and entities in L̂, respectively.",4.2 Efficient Subset Selection,[0],[0]
"We decompose it as:
F(L̂, R L̂ , E L̂ ) = wCC(L̂, RL̂, EL̂) (7)
+ wDD(L̂, RL̂, EL̂)− wRR(L̂, RL̂, EL̂)
where the terms in RHS correspond to coverage, diversity, and redundancy, respectively, and wC , wD, wR are the corresponding non-negative weights.",4.2 Efficient Subset Selection,[0],[0]
"Next, we propose functional forms for these terms.",4.2 Efficient Subset Selection,[0],[0]
"Note that any function that captures the described properties can be used instead, as long as the objective remains submodular.
",4.2 Efficient Subset Selection,[0],[0]
"Let R and E denote the set of relations and entities in the KB, respectively.",4.2 Efficient Subset Selection,[0],[0]
"The coverage simply captures the fraction of entity and relations that we have included in L̂:
C(L̂, R L̂ , E L̂ ) = |R",4.2 Efficient Subset Selection,[0],[0]
L̂ | |R| + |E,4.2 Efficient Subset Selection,[0],[0]
"L̂ | |E| .
",4.2 Efficient Subset Selection,[0],[0]
"The diversity for L̂ is the sum of the diversity measure of the entities and relations included in the set:
D(L̂, R L̂ , E L̂ ) =
∑
(r,e)∈L̂
",4.2 Efficient Subset Selection,[0],[0]
"[Vr + Ve] ,
Vr = |ESr |+",4.2 Efficient Subset Selection,[0],[0]
|ETr,4.2 Efficient Subset Selection,[0],[0]
"| |E| , Ve = |Re|+ |ESe | |R|+ |E| .
",4.2 Efficient Subset Selection,[0],[0]
"Here Vr and Ve represent the diversity measure of relation r and entity e, respectively.",4.2 Efficient Subset Selection,[0],[0]
"We use ESr , ETr to denote the set of sources and targets that appear
9This agrees with the sampling method of Chen et al. (2014) for factorizing coherent matrices with missing values, which chooses samples with probability proportional to their local coherence.
",4.2 Efficient Subset Selection,[0],[0]
Algorithm 2:,4.2 Efficient Subset Selection,[0],[0]
"Query Subset Selection input KB, budget B, query list L from Alg. 1.
1: ∀(r, e) ∈ L, compute the diversity measure Vr, Ve 2: L̂← ∅ 3: for j = 1 to B do 4: ∀l ∈ L \ L̂ : G(l) = F(L̂ ∪ l)−F(L̂), for F in (7) 5:",4.2 Efficient Subset Selection,[0],[0]
"Select l∗ = arg max
L\L̂ G(l) 6: Add l∗ to L̂
output L̂
for relation r in the KB, Re as the set of relations in the KB that have e as their target, and ESe as the set of entities that appear as the first entity when e is the second entity of the triple in the KB.",4.2 Efficient Subset Selection,[0],[0]
"The diversity measure for each relation r is defined as the ratio of the number of entities that appear in the KB as its source or target, over the total number of entities.",4.2 Efficient Subset Selection,[0],[0]
"Similarly, for an entity e, its diversity is defined as the ratio of the number of relations involving e plus the number of source entities that co-occur with e in a relation, over the total number of relations and entities.",4.2 Efficient Subset Selection,[0],[0]
"Note that the diversity measure is an intrinsic characteristic of each entity and relationship, dictated by the KB and independent of the set L, and can thus be computed in advance.
",4.2 Efficient Subset Selection,[0],[0]
"As described above, redundancy is a measure of similarity between relations(entities) in L̂. Tensor factorization yields an embedding for each relation(entity) given the facts they participated in.",4.2 Efficient Subset Selection,[0],[0]
"Therefore, the learned embeddings are one of the best options for capturing similarities.",4.2 Efficient Subset Selection,[0],[0]
"Let he (and hr) denote the learned embedding for entity e (and relation r, resp.).",4.2 Efficient Subset Selection,[0],[0]
"We define
R(L̂, R L̂ , E L̂ ) =
∑
r1,r2∈L̂
‖hr1",4.2 Efficient Subset Selection,[0],[0]
"− hr2‖
+ ∑
e1,e2∈L̂
‖he1 − he2‖.
This completes the definition of all pieces of our objective function, F , from Eqn.",4.2 Efficient Subset Selection,[0],[0]
(7).,4.2 Efficient Subset Selection,[0],[0]
"In Algorithm 2, we present our efficient greedy method to select a subset of L that approximately optimizes F .
",4.2 Efficient Subset Selection,[0],[0]
"Despite being a greedy approach that simply adds the currently most valuable single query to L̂ and
repeats, the submodular nature of F , which we will prove shortly, guarantees that Algorithm 2 provides an approximation that, even in the worse case, is no worse than a factor of 1 − 1/e from the (unknown) true optimum of F .",4.2 Efficient Subset Selection,[0],[0]
This is formalized in the following theorem.,4.2 Efficient Subset Selection,[0],[0]
"Since addition preserves submodularity and the weights wC , wD, wR are non-negative, we will show that each of the three terms in F is submodular.
",4.2 Efficient Subset Selection,[0],[0]
Theorem 1.,4.2 Efficient Subset Selection,[0],[0]
"Given a tensor KB, a budget B, and a candidate query list L, the quality F(L̂, R
L̂ , E L̂ )
of the output L̂ of Algorithm 2 is a (1 − 1/e)approximation of the global optimum of F .",4.2 Efficient Subset Selection,[0],[0]
Proof.,4.2 Efficient Subset Selection,[0],[0]
"In order to prove the result, it suffices to show that F(L̂, R
L̂ , E L̂ ) in Equation (7) is submod-
ular (Nemhauser et al., 1978).",4.2 Efficient Subset Selection,[0],[0]
"To this end, we show that for L′′ ⊆ L′ ⊆ L and for l = (rl, el) ∈",4.2 Efficient Subset Selection,[0],[0]
"L \ L′,
F(L′′ ∪ l)−F(L′′) ≥ F(L′ ∪ l)−F(L′).
",4.2 Efficient Subset Selection,[0],[0]
"Since addition preserves submodularity and the weights wC , wD, wR are non-negative, it suffices to show that each term in F is submodular.
",4.2 Efficient Subset Selection,[0],[0]
"First, consider the coverage term, C(L̂, R L̂ , E L̂ ).
",4.2 Efficient Subset Selection,[0],[0]
"In order to prove that it is submodular, we verify:
(|RL′′∪l| − |RL′′ |)",4.2 Efficient Subset Selection,[0],[0]
|R| ≥ (|RL′∪l| − |RL′ |),4.2 Efficient Subset Selection,[0],[0]
"|R| , (|EL′′∪l| − |EL′′",4.2 Efficient Subset Selection,[0],[0]
|),4.2 Efficient Subset Selection,[0],[0]
"|E| ≥ (|EL′∪l| − |EL′ |) |E| .
",4.2 Efficient Subset Selection,[0],[0]
"Note that for the numerators of each of the above lines, the difference can be either +1 or 0.",4.2 Efficient Subset Selection,[0],[0]
"Since L′′ ⊂ L′, LHS is, by definition, never less than RHS and the inequalities holds.
",4.2 Efficient Subset Selection,[0],[0]
"Next, consider the diversity term, D(L̂, R L̂ , E L̂ ).",4.2 Efficient Subset Selection,[0],[0]
The above argument directly applies here as well.,4.2 Efficient Subset Selection,[0],[0]
"Finally, consider the redundancy term.",4.2 Efficient Subset Selection,[0],[0]
"In order to show that −R(L̂, R L̂ , E L̂ ) is submodular, note that when taking the difference between R(L′′ ∪ l) and R(L′′) the terms that correspond to both entities (or both relations) being in L′′ cancel out.",4.2 Efficient Subset Selection,[0],[0]
The same holds forR(L′ ∪ l)−R(L′).,4.2 Efficient Subset Selection,[0],[0]
"We thus have: R(L′′ ∪ l)−R(L′′) =
∑
rl∈l,r2∈L′′ ‖hr1",4.2 Efficient Subset Selection,[0],[0]
"− hr2‖+
∑
el∈l,e2∈L′′ ‖he1",4.2 Efficient Subset Selection,[0],[0]
"− he2‖
R(L′ ∪ l)−R(L′) = ∑
rl∈l,r2∈L′",4.2 Efficient Subset Selection,[0],[0]
‖hr1,4.2 Efficient Subset Selection,[0],[0]
"− hr2‖+
∑
el∈l,e2∈L′ ‖he1 − he2‖.
Since L′′ ⊆ L′ and norms are non-negative,
R(L′′ ∪ l)−R(L′′) ≤ R(L′ ∪ l)−R(L′).
",4.2 Efficient Subset Selection,[0],[0]
"The reverse inequality holds for the negation of both sides, proving that −R(L̂, R
L̂ , E L̂ ) is submodular.
",4.2 Efficient Subset Selection,[0],[0]
Combining the three items concludes the proof.,4.2 Efficient Subset Selection,[0],[0]
We will complement this theoretical guarantee in the experiments section (cf. Table 3) by empirically comparing the performance of our query proposal and subset selection methods with baselines.,4.2 Efficient Subset Selection,[0],[0]
"We begin with a description of the datasets and the general setup, then evaluate the effectiveness of our guided KB completion approach, and end with an evaluation of our active learning method.10",5 Experiments,[0],[0]
"To assess the quality of our guided KB completion method, we consider the only large existing knowledge bases about generics that we are aware of:
1.",5.1 Dataset and Setup,[0],[0]
"A Science tensor containing facts about various scientific activities, entities (e.g., animals, instruments, body parts), units, locations, occupations, etc.",5.1 Dataset and Setup,[0],[0]
"(Dalvi et al., 2017).11",5.1 Dataset and Setup,[0],[0]
This starting tensor has a precision of about 80% and acts as a valuable resource for challenging tasks such as question answering.,5.1 Dataset and Setup,[0],[0]
"Our goal is to start with this tensor and infer more scientific facts at a similar or higher level of precision.
",5.1 Dataset and Setup,[0],[0]
2.,5.1 Dataset and Setup,[0],[0]
An Animals sub,5.1 Dataset and Setup,[0],[0]
"-tensor of the Science tensor, which focuses on facts about animals and also has a similar starting precision.",5.1 Dataset and Setup,[0],[0]
"Again, the goal is to infer more facts about animals.
",5.1 Dataset and Setup,[0],[0]
The mainstream approach for KB completion is to focus on entities that are mentioned sufficiently often.,5.1 Dataset and Setup,[0],[0]
"For instance, the commonly used FB15K dataset guarantees that every entity appears at least 100 times.",5.1 Dataset and Setup,[0],[0]
"As a milder version of this, we focus on the subset of the starting tensors where every entity appears at least 20 times.",5.1 Dataset and Setup,[0],[0]
"The resulting statistics of the tensors we use here are shown in Table 1.
10Data and code available from the authors.",5.1 Dataset and Setup,[0],[0]
"11Aristo Tuple KB v0, http://allenai.org/data/aristo-tuple-kb.
",5.1 Dataset and Setup,[0],[0]
"This data, which is the only one we are aware of with generics, does not include ((s, r, t), all) style triples.",5.1 Dataset and Setup,[0],[0]
We therefore use the objective function in Eqn.,5.1 Dataset and Setup,[0],[0]
(2) rather than the multi-class one in Eqn. (1).,5.1 Dataset and Setup,[0],[0]
"Despite this limitation of the dataset and its superficial similarity to the binary classification task underlying standard (non-generics) KB completion, our results reveal that extending a generics KB is surprisingly difficult for existing methods.
",5.1 Dataset and Setup,[0],[0]
"Dalvi et al. (2017) use a pipeline consisting of Open IE (Banko et al., 2007) extractions, aggregation, and clean up via crowd-sourcing to generate the Science tensor.",5.1 Dataset and Setup,[0],[0]
"These facts come with a relevant WordNet (Miller, 1995) based taxonomy, entity types (derived from WordNet ‘synsets’), and relation schema.",5.1 Dataset and Setup,[0],[0]
"Our method capitalizes on this additional information12 to perform high quality knowledge completion.
",5.1 Dataset and Setup,[0],[0]
Our evaluation metric is the accuracy of the top k triples generated by various KB completion methods.,5.1 Dataset and Setup,[0],[0]
"We also visualize entire precision-recall curves, where possible.",5.1 Dataset and Setup,[0],[0]
"While this metric requires human annotation and is thus more cumbersome than fullyautomatic metrics, it is arguably more suitable for evaluating generative tasks with a massive output space, such as KB completion.",5.1 Dataset and Setup,[0],[0]
"In this setting, evaluation against a relatively small held out test set can be misleading—a method may be highly accurate at generating thousands of valid and useful triples even if it does not necessarily classify specific held out instances accurately.",5.1 Dataset and Setup,[0],[0]
"While measures such MAP and MRR have been used in the past to alleviate this, they provide only a partial solution to the inherent difficulty of evaluating generative systems.",5.1 Dataset and Setup,[0],[0]
"Annotation-efficient evaluation methods have recently been proposed to address this challenge (Sabharwal and Sedghi, 2017).
",5.1 Dataset and Setup,[0],[0]
"12In order to limit potential error propagation, we collapse the taxonomy to the top two levels in our experiments.",5.1 Dataset and Setup,[0],[0]
"We first compare our method (Section 3) with existing KB completion techniques on the Animals tensor, and then demonstrate that its effectiveness carries over scalably to the larger Science tensor as well.",5.2 Guided KB Completion,[0],[0]
"In what follows, T denotes the tensor under consideration.
",5.2 Guided KB Completion,[0],[0]
"We examine two alternatives for generating negative samples: given a triple (s, r, t) ∈ T , replace s with (1) any entity s′ or (2) an entity s′ of the same type as s.",5.2 Guided KB Completion,[0],[0]
"The resulting perturbed triple (s′, r, t) is then treated as a negative sample if it is not present in T .",5.2 Guided KB Completion,[0],[0]
"We also considered a weighted combination of (1) and (2), and found random sampling to be the most reliable on our datasets.",5.2 Guided KB Completion,[0],[0]
"This complies with the commonly used LCWA assumption not being applicable to these tensors.
",5.2 Guided KB Completion,[0],[0]
"As baselines, we consider extensions of three state-of-the-art embedding-based KB completion methods: HolE, TransE, and RESCAL.",5.2 Guided KB Completion,[0],[0]
"As mentioned earlier, two leading graph-based methods, SFE and PRA, did not scale well.",5.2 Guided KB Completion,[0],[0]
Both vanilla TransE and RESCAL resulted in poor performance; we thus report numbers only for their extensions.,5.2 Guided KB Completion,[0],[0]
"Specifically, we consider 3 baselines: (1) HolE, (2) TransE+Schema, and (3) SICTF which extends
RESCAL and incorporates schema.",5.2 Guided KB Completion,[0],[0]
Figure 1 shows the resulting precision-yield curves for the predictions made by each method on the Animals dataset containing 10.6K facts.,5.2 Guided KB Completion,[0],[0]
"Specifically, for each method, we rank the predictions based on the method’s assigned score and compute the precision of the top k predictions for varying k.",5.2 Guided KB Completion,[0],[0]
"As expected, we observe a generally decreasing trend as k increases.",5.2 Guided KB Completion,[0],[0]
TransE+ITRS gave a precision of only around 10% and is omitted from the plot.,5.2 Guided KB Completion,[0],[0]
"We make two observations:
First, deriving new facts for these generics tensors at a high precision is challenging!",5.2 Guided KB Completion,[0],[0]
"Specifically, none of the baseline methods (black and pink curves), which represent state of the art for named-entity tensors, achieve a yield of more than 10% of T (i.e., 1K predictions) even at a precision of just 60%.
",5.2 Guided KB Completion,[0],[0]
"Second, external information, if used appropriately, can be surprisingly powerful in this setting.",5.2 Guided KB Completion,[0],[0]
"Specifically, simply incorporating relation schema (ITRS, blue curve) allows HolE-based completion to double the size of the starting tensor T by producing over 10K new triples at a precision of 82%.",5.2 Guided KB Completion,[0],[0]
"Further, incorporating entity taxonomy (IET, green
curve) to address tensor sparsity results in the same yield at a statistically significantly higher precision of 86.4%.
",5.2 Guided KB Completion,[0],[0]
"It turns out that not only does our method result in substantially improved PR curves, it also generates qualitatively more interesting and useful generic facts about the world than previous methods.",5.2 Guided KB Completion,[0],[0]
"We illustrate this in Table 2, which lists the top 20 predictions made by various approaches.",5.2 Guided KB Completion,[0],[0]
"The triples shown in red are false predictions (e.g., (penguin, has part, tooth), (grass, graze in, man), (caterpillar, turn into, bird)) or uninteresting ones (e.g., (water, is known as, water)).",5.2 Guided KB Completion,[0],[0]
"As we see, a vast majority of the top 20 predictions made by both vanilla HolE and SICTF fall into these categories.",5.2 Guided KB Completion,[0],[0]
"On the other hand, our method, HolE+ITRS+IET, predicts 19 true tripes out of the top 20, including interesting scientific facts that were evidently missing from the starting tensor, such as (salmon, thrive in, water), (fish, swim in, ocean) and (insect, destroy, tree).
",5.2 Guided KB Completion,[0],[0]
"Finally, we evaluate our proposal on the entire Science dataset with 66.6K facts.",5.2 Guided KB Completion,[0],[0]
"Since graph-based methods did not scale well to the much smaller Animals dataset and other methods performed substan-
tially worse there, we focus here on the scalability and prediction quality of our method.",5.2 Guided KB Completion,[0],[0]
"We found that HolE+ITRS+IET scales well to this high dimension, doubling the number of facts by adding 66K new facts at 74% precision.",5.2 Guided KB Completion,[0],[0]
"Although the Science tensor is 1,000 times larger than the Animals tensor, the method took only 10x longer to run (3 minutes on Animals tensor vs. 56 minutes on Science tensor, using a 2.8GHz, 16GB Macbook Pro).",5.2 Guided KB Completion,[0],[0]
"With additional improvements such as parallelization, it is easily possible to further scale the method up to substantially larger tensors.",5.2 Guided KB Completion,[0],[0]
"To assess the quality of our active learning mechanism (Section 4), we consider predicting facts about a new entity ẽ that is not in the Animals tensor.",5.3 Active Learning for New Entities,[0],[0]
"For illustration, we choose ẽ from the Science tensor vocabulary while ensuring that it is present in the WordNet taxonomy.
",5.3 Active Learning for New Entities,[0],[0]
The setup is as follows.,5.3 Active Learning for New Entities,[0],[0]
"We first use a query generation mechanism (Random, Schema Consistent, or Sibling Guided; cf. Section 4.1) to propose an ordered list L of facts about ẽ to annotate.",5.3 Active Learning for New Entities,[0],[0]
"Next, we perform subset selection (Top k or TK, Submodular or SM; cf. Section 4.2) on L to identify a subset L̂ of up to 100 most promising queries.",5.3 Active Learning for New Entities,[0],[0]
"These are then annotated and the true ones fed into tensor factorization as additional input to infer further new facts about ẽ.
In Table 3, we assess the quality of L̂ in two ways, when |L̂| = 100: how many true facts does L̂ have and how many overall new facts does this annotation produce about ẽ. Figure 2 provides a complementary view, focusing on the overall number of new facts inferred as |L̂| increases.",5.3 Active Learning for New Entities,[0],[0]
"While these illus-
trative numbers are for a representative new entity, reindeer, the overall trend and order of numbers remained the same for other new entities we experimented with.
",5.3 Active Learning for New Entities,[0],[0]
We mention some highlights from Table 3.,5.3 Active Learning for New Entities,[0],[0]
"First, not surprisingly, randomly choosing triples about ẽ to annotate is ineffective.",5.3 Active Learning for New Entities,[0],[0]
"Second, choosing schema consistent triples results in 73 true triples (out of 100) but these facts help tensor factorization very little, resulting in only 10 additional new triples about ẽ.",5.3 Active Learning for New Entities,[0],[0]
"Our proposed sibling guided querying mechanism results not only in nearly all 100 facts being true along with 17 true facts inferred from sibling agreement (set M in Alg. 1), but also, combined with submodular subset selection for balancing diversity with coverage (Alg. 2), ultimately results in 483 new
facts about ẽ. These facts cover interesting new information such as (reindeer, eat, fruit), (wolf, chase, reindeer), and (reindeer, provide, fur).
",5.3 Active Learning for New Entities,[0],[0]
"Finally, the plot in Figure 2 demonstrates that the qualitative trends remain the same, irrespective of the number |L̂| of queries annotated.",5.3 Active Learning for New Entities,[0],[0]
"Overall, our sibling guided queries with submodular subset selection (green triangles, top-most curve) ultimately results in 5.8 times more new facts about ẽ than a non-trivial, uncertainly based, schema consistent baseline (black stars, 3rd curve from the top).",5.3 Active Learning for New Entities,[0],[0]
This attests to the efficacy of the method on this challenging problem and dataset.,5.3 Active Learning for New Entities,[0],[0]
"This work explores KB completion for a new class of problems, namely completing generics KBs, which is an essential step for including general world knowledge in intelligent machines.",6 Conclusion,[0],[0]
The differences between generics and much studied named entity KBs make existing techniques either not scale well or produce facts at an undesirably low precision out of the box.,6 Conclusion,[0],[0]
We demonstrate that incorporating entity taxonomy and relation schema appropriately can be highly effective for generics KBs.,6 Conclusion,[0],[0]
"Further, to address scarcity of facts about certain entities in such KBs, we present a novel active learning approach using sibling guided uncertainty estimation along with submodular subset selection.",6 Conclusion,[0],[0]
"The proposed techniques substantially outperform various baselines, setting a new state of the art for this challenging class of completion problems.
",6 Conclusion,[0],[0]
Our method is applicable to KBs that have an associated entity taxonomy and relation schema.,6 Conclusion,[0],[0]
It is expected to be successful when information from siblings can be used to guide what is likely to be true and what is a good candidate to query for a given entity.,6 Conclusion,[0],[0]
"We focus on KBs of generics where such information is available and—as we show—is highly valuable for effective KB completion.
",6 Conclusion,[0],[0]
Why does our use of types work substantially better in our setting than the use of types in various baselines?,6 Conclusion,[0],[0]
One hypothesis is the following.,6 Conclusion,[0],[0]
The use of complicated models requires substantial data and information.,6 Conclusion,[0],[0]
"In our KB, the information appears so sparse and incomplete that using types in complicated ways is not productive.",6 Conclusion,[0],[0]
"Our proposal instead
attempts to use type information only to gently enhance the signal and reduce noise, before performing tensor decomposition.",6 Conclusion,[0],[0]
"We hope this work will trigger further exploration of knowledge bases with generics, a key aspect of machine intelligence.",6 Conclusion,[0],[0]
"The authors would like to thank Peter Clark for fruitful discussions, valuable feedback, and crowdsourcing annotations; Matt Gardner for constructive comments and assessing graph-based completion methods on our datasets; and Udai Saini and Partha Talukdar for evaluating their CNTF approach on our datasets.",Acknowledgments,[0],[0]
"Given a knowledge base or KB containing (noisy) facts about common nouns or generics, such as “all trees produce oxygen” or “some animals live in forests”, we consider the problem of inferring additional such facts at a precision similar to that of the starting KB.",abstractText,[0],[0]
"Such KBs capture general knowledge about the world, and are crucial for various applications such as question answering.",abstractText,[0],[0]
"Different from commonly studied named entity KBs such as Freebase, generics KBs involve quantification, have more complex underlying regularities, tend to be more incomplete, and violate the commonly used locally closed world assumption (LCWA).",abstractText,[0],[0]
"We show that existing KB completion methods struggle with this new task, and present the first approach that is successful.",abstractText,[0],[0]
"Our results demonstrate that external information, such as relation schemas and entity taxonomies, if used appropriately, can be a surprisingly powerful tool in this setting.",abstractText,[0],[0]
"First, our simple yet effective knowledge guided tensor factorization approach achieves state-of-the-art results on two generics KBs (80% precise) for science, doubling their size at 74%-86% precision.",abstractText,[0],[0]
"Second, our novel taxonomy guided, submodular, active learning method for collecting annotations about rare entities (e.g., oriole, a bird) is 6x more effective at inferring further new facts about them than multiple active learning baselines.",abstractText,[0],[0]
Knowledge Completion for Generics using Guided Tensor Factorization,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3198–3207 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
3198",text,[0],[0]
"Knowledge Graphs (KGs) are extremely useful resources for many AI-related applications, such as question answering, information retrieval and query expansion.",1 Introduction,[1.0],"['Knowledge Graphs (KGs) are extremely useful resources for many AI-related applications, such as question answering, information retrieval and query expansion.']"
"Indeed, KGs are multi-relational directed graphs composed of entities as nodes and relations as edges.",1 Introduction,[1.0],"['Indeed, KGs are multi-relational directed graphs composed of entities as nodes and relations as edges.']"
"They represent information about real-world entities and relations in the form of knowledge triples, which is denoted as (h, r, t), where h and t correspond to the head and tail entities and r denotes the relation between them, e.g., (Donald Trump, presidentOf, USA).",1 Introduction,[1.0],"['They represent information about real-world entities and relations in the form of knowledge triples, which is denoted as (h, r, t), where h and t correspond to the head and tail entities and r denotes the relation between them, e.g., (Donald Trump, presidentOf, USA).']"
"Large
scale, collaboratively created KGs , such as Freebase (Bollacker et al., 2008), WordNet (Miller, 1994), Yago (Suchanek et al., 2007), Gene Ontology (Sherlock, 2009), NELL (Carlson et al., 2010) and Google’s KG1, have recently become available.",1 Introduction,[0.9999999965209584],"['Large scale, collaboratively created KGs , such as Freebase (Bollacker et al., 2008), WordNet (Miller, 1994), Yago (Suchanek et al., 2007), Gene Ontology (Sherlock, 2009), NELL (Carlson et al., 2010) and Google’s KG1, have recently become available.']"
"However, despite the impressively large sizes, the coverage of most existing KGs are far from complete.",1 Introduction,[0],[0]
"This has motivated research in knowledge base completion task, which includes KGE methods aiming to embed entities and relations in KGs into low-dimensional embeddings.
",1 Introduction,[1.0000000688895925],"['This has motivated research in knowledge base completion task, which includes KGE methods aiming to embed entities and relations in KGs into low-dimensional embeddings.']"
"In the literature, there are a number of studies about KGE models.",1 Introduction,[1.0],"['In the literature, there are a number of studies about KGE models.']"
"These models embed entities and relations into latent vectors and complete KGs based on these vectors, such as TransE (Bordes et al., 2013), TransH (Wang et al., 2014) and TransR",1 Introduction,[0],[0]
"(Lin et al., 2015b).",1 Introduction,[0],[0]
"However, most of the existing works simply embed relations into vectors.",1 Introduction,[0],[0]
Less efforts have been made for investigating the rich information from the relation structure.,1 Introduction,[0],[0]
"Indeed, in this research, we define a three-layer hierarchical relation structure (HRS), which can be conformed by relation clusters, relations and subrelations in KGs.
",1 Introduction,[0],[0]
• Relation clusters: Semantically similar relations are often observed in Large-scales KGs.,1 Introduction,[1.0],['• Relation clusters: Semantically similar relations are often observed in Large-scales KGs.']
"For example, the relation ’producerOf’ and ’directorOf’ may be semantically related if both of them describe a relation between a person and a film.",1 Introduction,[1.0],"['For example, the relation ’producerOf’ and ’directorOf’ may be semantically related if both of them describe a relation between a person and a film.']"
These semantically similar relations can make up relation clusters.,1 Introduction,[0],[0]
"We believe the information from semantically similar relations is of great value, and relations in the same group can be trained in a collective way to facilitate the knowledge sharing when learning the embeddings of related relations.
",1 Introduction,[0],[0]
"• Relations: A relation connects the head and 1https://www.google.com/intl/es419/insidesearch/features/ search/knowledge.html
tail entities in a knowledge triple, denoted as (h, r, t), where h and t correspond to the head and tail entities and r denotes the relation between them.
",1 Introduction,[0],[0]
• Sub-relations: There are relations that have multiple semantic meanings and can be split into several sub-relations.,1 Introduction,[0],[0]
"For example, the relation partOf has at least two semantics: location-related as (New Y ork, partOf , USA) and composition-related as (monitor, partOf , television).",1 Introduction,[1.0],"['For example, the relation partOf has at least two semantics: location-related as (New Y ork, partOf , USA) and composition-related as (monitor, partOf , television).']"
"We believe the subrelations can give fine-grained descriptions for each relation.
",1 Introduction,[0],[0]
"The relation clusters, relations and sub-relations correspond to the top, middle and bottom layer of the three-layer HRS.
",1 Introduction,[0],[0]
"In this paper, we extend state-of-the-art models TransE (Bordes et al., 2013), TransH (Wang et al., 2014) and DistMult (Yang et al., 2015) to learn knowledge representations by leveraging the rich information from the HRS.",1 Introduction,[0],[0]
"Moreover, the same technique can easily be used to extend other stateof-the-art models and utilize the HRS information.",1 Introduction,[0],[0]
"In the proposed models, for each knowledge triple (h, r, t), the embedding of r is the sum of three embedding vectors, which correspond to the three layers of the HRS respectively and therefore, the information from the HRS is leveraged.",1 Introduction,[0],[0]
"Particularly, instead of using additional information like text or paths, our model simply use the knowledge triples in KGs and the rich information from the HRS.",1 Introduction,[0],[0]
"Extensive experiments on popular benchmark data sets demonstrate the effectiveness of our models.
",1 Introduction,[0],[0]
"In summary, we highlight our key contributions as follows,
1.",1 Introduction,[1.0000000261539257],"['In summary, we highlight our key contributions as follows, 1.']"
"We propose a technique by making use of the HRS information to conduct the KGE task, and extend three state-of-the-art models to utilize this technique.",1 Introduction,[0],[0]
"The technique can be easily applied to other KGE models.
",1 Introduction,[0],[0]
2.,1 Introduction,[0],[0]
"Our proposed models don’t use additional information like text or paths, instead, we only use the knowledge triples in KGs and take advantage of the rich information from the HRS.
3.",1 Introduction,[0],[0]
"We evaluate our models on popular benchmark data sets, and the results show that our
extended models achieve substantial improvements against the original models as well as other state-of-the-art baselines.",1 Introduction,[0],[0]
We extend three popular KGE models by leveraging the HRS information in this study.,2 Preliminaries and Related Work,[0],[0]
"Therefore, in this section, we first introduce the three existing models TransE (Bordes et al., 2013), TransH (Wang et al., 2014) and DistMult (Yang et al., 2015) in detail.",2 Preliminaries and Related Work,[0],[0]
"Then, we further summarize other state-of-the-art models on the topic of KGE.",2 Preliminaries and Related Work,[0],[0]
"Recently, a number of KGE models have been proposed.","2.1 TransE, TransH and DistMult",[0],[0]
"These methods learn low-dimensional vector representations for entities and relations (Bordes et al., 2013; Wang et al., 2014; Lin et al., 2015b).
","2.1 TransE, TransH and DistMult",[0],[0]
"TransE (Bordes et al., 2013) is one of the most widely used model, which views relations as translations from a head entity to a tail entity on the same low-dimensional hyperplane, i.e, h + r","2.1 TransE, TransH and DistMult",[0],[0]
"≈ t when (h, r, t) holds.","2.1 TransE, TransH and DistMult",[0],[0]
This indicates that t should be the nearest neighbor of h+ r.,"2.1 TransE, TransH and DistMult",[0],[0]
"In this case, the score function of TransE is defined as
fr(h, t) = ‖h+ r− t‖Ln , (1)
which can be measured by L1 or L2 norm.","2.1 TransE, TransH and DistMult",[0],[0]
"Positive triples are supposed to have lower scores than negative ones.
","2.1 TransE, TransH and DistMult",[0],[0]
"TransH (Wang et al., 2014) introduces a mechanism of projecting entities into relation-specific hyperplanes that enables different roles of an entity in different relations.","2.1 TransE, TransH and DistMult",[0],[0]
TransH models the relation as a vector r on a hyperplane wr and assumes that h⊥ +,"2.1 TransE, TransH and DistMult",[0],[0]
"r ≈ t⊥ when (h, r, t) holds, where h⊥ and t⊥ are the projection of h and t in the relationspecific hyperplane.","2.1 TransE, TransH and DistMult",[0],[0]
"The score function of TransH is defined as
fr(h, t) = ‖h⊥ + r− t⊥‖22 , (2)
","2.1 TransE, TransH and DistMult",[0],[0]
"where h⊥ = h−w>r hwr, t⊥ = t−w>r twr and ‖wr‖2 = 1.","2.1 TransE, TransH and DistMult",[0],[0]
"Like triples in TransE, positive triples in TransH should have lower scores than negative ones.
","2.1 TransE, TransH and DistMult",[0],[0]
"DistMult (Yang et al., 2015) adopts a bilinear score function to compute the scores given (h, r, t) triples.","2.1 TransE, TransH and DistMult",[0],[0]
"The score function is defined as
fr(h, t) =","2.1 TransE, TransH and DistMult",[0],[0]
"hMrt, (3)
where Mr is a relation-specific diagonal matrix, which represents the characteristics of a relation.","2.1 TransE, TransH and DistMult",[0],[0]
"Different from TransE and TransH, positive triples should have larger scores than negative ones.","2.1 TransE, TransH and DistMult",[0],[0]
"Besides TransE, TransH and DistMult, there are also many models on the topic of KGE. TransR",2.2 Other KGE Models,[0],[0]
"(Lin et al., 2015b) embeds entities and relations into separate entity space and relationspecific spaces.",2.2 Other KGE Models,[0],[0]
"ComplEx (Welbl et al., 2016) extends DistMult to embed entities and relations into complex vectors instead of real-valued ones.",2.2 Other KGE Models,[0],[0]
"HolE (Nickel et al., 2016) employs circular correlations to create compositional representations.",2.2 Other KGE Models,[0],[0]
"ProjE (Shi and Weninger, 2017) adopts a twolayer network to embed entities and relations.",2.2 Other KGE Models,[0],[0]
"Other KGE models also try to embeds entities and relations in various ways, such as Unstructured Model (Bordes et al., 2012a, 2014), Structured Embedding (Bordes et al., 2012b), Single Layer Model (Socher et al., 2013), Semantic Matching Energy (Bordes et al., 2012a, 2014), NTN Model (Socher et al., 2013), etc.
",2.2 Other KGE Models,[0],[0]
Many efforts have been devoted to building models using additional information like paths or text.,2.2 Other KGE Models,[0],[0]
"For instance, PTransE (Lin et al., 2015a) and R-GCN (Schlichtkrull et al., 2017) use paths as additional information, while DKRL (Xie et al., 2016) and SSP (Xiao et al., 2017) adopt text to assist the embedding task.
",2.2 Other KGE Models,[0],[0]
Some KGE works focus on making use of the information from relations.,2.2 Other KGE Models,[0],[0]
"CTransR (Lin et al., 2015b), TransD",2.2 Other KGE Models,[0],[0]
"(Ji et al., 2015) and TransG",2.2 Other KGE Models,[0],[0]
"(Xiao et al., 2016) try to find fine-grained representations for each relation.",2.2 Other KGE Models,[0],[0]
"However, these works didn’t utilize the information from semantically similar relations and the HRS is also not exploited.",2.2 Other KGE Models,[0],[0]
"Different from the above studies, we believe semantically similar relations can make up relation clusters, and some relations may have multiple semantic meanings and can be split into fine-grained subrelations.",2.2 Other KGE Models,[0],[0]
"In this paper, we take advantage of the three-layer HRS and conduct the KGE task by extending three widely used models.",2.2 Other KGE Models,[0],[0]
"In this section, we provide the technical details of how to extend existing KGE models by leveraging the HRS information.",3 Methodology,[0],[0]
We first formally define the HRS and its integration with existing models.,3 Methodology,[0],[0]
"Then
we introduce the new loss functions of extended models TransE-HRS, TransH-HRS and DistMultHRS.",3 Methodology,[0],[0]
"Finally, two variants of the HRS models and implementation details are provided.",3 Methodology,[0],[0]
"Given a KG G = {(h, r, t)} ⊆ E × R× E , where E and R are the entity (node) set and relation (edge) set respectively.",3.1 Hierarchical Relation Structure,[0],[0]
We believe the relations in KGs can make up relation clusters as well as be split into fine-grained sub-relations.,3.1 Hierarchical Relation Structure,[0],[0]
"On the one hand, large scale KGs always have semantically related relations.",3.1 Hierarchical Relation Structure,[0],[0]
The information from semantically similar relations is of great value and these relations should be trained in a collective way.,3.1 Hierarchical Relation Structure,[0],[0]
"In this way, meaningful associations among related relations can be utilized and less frequent relations can be enriched with more training data.",3.1 Hierarchical Relation Structure,[0],[0]
"On the other hand, some relations may have multiple semantic meanings and can be split into several subrelations, which can provide fine-grained descriptions for each relation.",3.1 Hierarchical Relation Structure,[0],[0]
"In general, relations in KGs conform to a three-layer HRS, as shown in Figure 1.",3.1 Hierarchical Relation Structure,[1.0],"['In general, relations in KGs conform to a three-layer HRS, as shown in Figure 1.']"
"The HRS include a relation cluster layer, a relation layer and a sub-relation layer, which are denoted in yellow, green and blue in Figure 1 respectively.
",3.1 Hierarchical Relation Structure,[0],[0]
"For a triple (h, r, t) in the HRS model, the embedding of r is comprised of three parts: the relation cluster embedding rc, relation-specific embedding r′ and sub-relation embedding rs, which is denotes as
r = rc + r ′ + rs.",3.1 Hierarchical Relation Structure,[1.0000000351322855],"['For a triple (h, r, t) in the HRS model, the embedding of r is comprised of three parts: the relation cluster embedding rc, relation-specific embedding r′ and sub-relation embedding rs, which is denotes as r = rc + r ′ + rs.']"
"(4)
",3.1 Hierarchical Relation Structure,[0],[0]
"According to the above equation, the embedding of each relation can leverage the information from the three-layer HRS.",3.1 Hierarchical Relation Structure,[0],[0]
"The relation clusters and subrelations are determined by k-means algorithm based on the results of TransE:
• Relation clusters.",3.1 Hierarchical Relation Structure,[1.0000000474653814],['The relation clusters and subrelations are determined by k-means algorithm based on the results of TransE: • Relation clusters.']
"We first run TransE on a given data set and obtain the embeddings of relations r1, r2, r3, ..., r|R|, where |R| is the number of relations.",3.1 Hierarchical Relation Structure,[0],[0]
"Then, the k-means algorithm is applied on these embeddings.",3.1 Hierarchical Relation Structure,[0],[0]
"In this way, we get relation clusters C1, C2, C3, ..., C|C|, where C is the set of relation clusters.",3.1 Hierarchical Relation Structure,[0],[0]
"Previous studies have shown that the embeddings of semantically similar relations locate near each other in the latent space (Yang et al., 2015).",3.1 Hierarchical Relation Structure,[0],[0]
"In this way, we are able to find relation clusters composed of semantically related relations.
",3.1 Hierarchical Relation Structure,[0],[0]
• Sub-relations.,3.1 Hierarchical Relation Structure,[0],[0]
TransE assumes that t − h,3.1 Hierarchical Relation Structure,[0],[0]
"≈ r when (h, r, t) holds.",3.1 Hierarchical Relation Structure,[0],[0]
"For each triple (h, r, t), we define that r̂ = t−h, where h and t are obtained from the results of TransE. For each relation, we collect all the r̂ and adopt the k-means algorithm to cluster these vectors into several groups Sr1 , Sr2 , Sr3 , ..., Srnr , where nr is the number of subrelations for",3.1 Hierarchical Relation Structure,[0],[0]
relation r.,3.1 Hierarchical Relation Structure,[0],[0]
Each group corresponds to a fine-grained sub-relation.,3.1 Hierarchical Relation Structure,[0],[0]
"The loss of the extended HRS model is comprised of two parts, as is shown in Equation (5),
LTotal =",3.2 Loss Function,[0],[0]
"LOrig + LHRS , (5)
where LOrig is the loss function of the original model, while LHRS is the loss function for the HRS information.
",3.2 Loss Function,[0],[0]
"We know that TransE, TransH and DistMult all adopt a margin-based ranking loss.",3.2 Loss Function,[0],[0]
"Taking TransE as an example, the loss function of TransE for the first part LOrig is shown as Equation (6),
LOrig = |C|∑ c=1 ∑ r∈Cc ∑ (h,r,t)∈4r ∑ (h′,r,t′)∈4′r",3.2 Loss Function,[0],[0]
"[γ + fr(h, t)
",3.2 Loss Function,[0],[0]
"− fr(h′, t′)]+, (6)
where [x]+ = max(0, x), 4r denotes the set of positive triples for relation r and 4′r = {(h′, r, t)|h′ ∈ E}∪{(h, r, t′)|t′ ∈ E} is the set of negative ones for relation r. γ is the margin separating the positive triples from the negative ones.",3.2 Loss Function,[0],[0]
"fr(h, t) is the score function as shown in Equation (7),
fr(h, t) = ∥∥h+",3.2 Loss Function,[0],[0]
rc + r′ + rs,3.2 Loss Function,[0],[0]
"− t∥∥Ln , (7)
which can be measured by L1 or L2 norm.",3.2 Loss Function,[0],[0]
"Positive triples are supposed to have lower scores than negative ones.
",3.2 Loss Function,[0],[0]
"The second part, LHRS , is composed of three regularized terms, which is shown in Equation (8),
LHRS = λ1 ∑ rc∈C ‖rc‖22 + λ2 ∑ r′∈R ∥∥r′∥∥2 2
+ λ3 ∑ rs∈S ‖rs‖22 , (8)
where C = {C1, C2, ..., C|C|} is the set of relation clusters, S = {Sr1 , Sr2 , Sr3 , ..., Srnr |r ∈ R} is the set of fine-grained sub-relations, nr is the number of sub-relations for relation r. λ1, λ2 and λ3 are trade-off parameters.",3.2 Loss Function,[0],[0]
"Large value of λ1 will result in the separate training of each relation, while large value of λ2 will lead to all relations in the same relation cluster sharing the same embedding vector.",3.2 Loss Function,[0],[0]
"λ3 should be larger than λ1 and λ2 to restrict rs to be a small value, i.e., the sub-relations from the same relation should be close.",3.2 Loss Function,[0],[0]
"Additionally, we introduce two variants of the HRS model: the top-middle model and the middle-bottom model.",3.3 Variants of the HRS Model and Implementation details,[0],[0]
The top-middle model only uses the HRS by leveraging the information from the top to the middle layer.,3.3 Variants of the HRS Model and Implementation details,[0],[0]
"For this model, the relation embedding and the loss for HRS is defined as Equation (9) and (10).
",3.3 Variants of the HRS Model and Implementation details,[0],[0]
"r = rc + r ′, (9)
",3.3 Variants of the HRS Model and Implementation details,[0],[0]
LHRS = λ1 ∑ rc∈C ‖rc‖22 + λ2 ∑ r′∈R ∥∥r′∥∥2 2 .,3.3 Variants of the HRS Model and Implementation details,[0],[0]
"(10)
While the middle-bottom model only utilizes the information from the middle to the bottom layer.",3.3 Variants of the HRS Model and Implementation details,[0],[0]
"The relation embedding and HRS loss are defined as Equation (11) and (12).
",3.3 Variants of the HRS Model and Implementation details,[0],[0]
"r = r′ + rs, (11)
",3.3 Variants of the HRS Model and Implementation details,[0],[0]
LHRS = λ2 ∑ r′∈R ∥∥r′∥∥2 2 + λ3 ∑ rs∈S ‖rs‖22 .,3.3 Variants of the HRS Model and Implementation details,[0],[0]
"(12)
",3.3 Variants of the HRS Model and Implementation details,[0],[0]
"The learning process of the extended models is carried out by using the Adam (Kingma and Ba, 2014) optimizer.",3.3 Variants of the HRS Model and Implementation details,[0],[0]
"For the extended models of TransE, all the entity and relation embedding parameters are initialized with a uniform distribution U [ − 6√
k , 6√ k
] following TransE, where k
is the dimension of the embedding space.",3.3 Variants of the HRS Model and Implementation details,[0],[0]
"For the extended models of TransH and DistMult, we initialize these parameters with the results of TransE. For the relation cluster embeddings and sub-relation embeddings, we initialize all the parameters with the value of zero.",3.3 Variants of the HRS Model and Implementation details,[0],[0]
"In this research, we evaluate the performances of our extended models on popular benchmarks FB15k (Bordes et al., 2013), FB15k237 (Toutanova and Chen, 2015), FB13(Socher et al., 2013), WN18 (Bordes et al., 2013) and WN11 (Socher et al., 2013).",4.1 Data Sets,[0],[0]
"FB15k, FB15k237 and FB13 are extracted from Freebase (Bollacker et al., 2008), which provides general facts of the world.",4.1 Data Sets,[0],[0]
"WN18 and WN11 are obtained from WordNet (Miller, 1994), which provides semantic knowledge of words.",4.1 Data Sets,[0],[0]
"FB15k-237 and WN18 are used for the task of link prediction, FB13 and WN11 are used for the triple classification task, while FB15k is used for both tasks.",4.1 Data Sets,[1.0],"['FB15k-237 and WN18 are used for the task of link prediction, FB13 and WN11 are used for the triple classification task, while FB15k is used for both tasks.']"
The statistics of the five data sets are summarized in Table 1.,4.1 Data Sets,[1.0],['The statistics of the five data sets are summarized in Table 1.']
"To demonstrate the effectiveness of our models, we compare results with the following baselines.
",4.2 Baselines,[0],[0]
•,4.2 Baselines,[0],[0]
"TransE (Bordes et al., 2013): one of the most widely used KGE models.
",4.2 Baselines,[0],[0]
"• TransH (Wang et al., 2014): a KGE model which adopts relation-specific hyperplanes to lay entities and relations.
",4.2 Baselines,[0],[0]
"• DistMult (Yang et al., 2015): a state of the art model which uses a bilinear score function to compute scores of knowledge triples.
",4.2 Baselines,[0],[0]
"• CTransR (Lin et al., 2015b): a pioneering KGE model which exploits fine-grained sub-relations for each relation.
• TransD",4.2 Baselines,[0],[0]
"(Ji et al., 2015): an improvement of CTransR, which embeds KGs using dynamic mapping matrices.
• TransG",4.2 Baselines,[0],[0]
"(Xiao et al., 2016): the first generative KGE model that uses a non-parametric bayesian model to embed KGs.",4.2 Baselines,[0],[0]
"Link prediction, a.k.a. knowledge graph completion, aims to fill the missing values into incomplete knowledge triples.",4.3 Link Prediction,[0],[0]
"More formally, the goal of link prediction is to predict either the head entity in a given query (?, r, t) or the tail entity in a given query (h, r, ?).",4.3 Link Prediction,[0],[0]
All the parameters are set by some preliminary test.,4.3.1 Experimental Settings,[0],[0]
"For TransE-HRS, TransE-top-middle and TransE-middle-bottom, λ1, λ2, λ3 and the margin γ are set as λ1 = 1e",4.3.1 Experimental Settings,[0],[0]
"− 5, λ2 = 1e",4.3.1 Experimental Settings,[0],[0]
"− 4, λ3 = 1e−3, γ = 2.",4.3.1 Experimental Settings,[0],[0]
"For the extended models of TransH, we set the parameters as λ1 = 1e",4.3.1 Experimental Settings,[0],[0]
"− 5, λ2 = 1e",4.3.1 Experimental Settings,[0],[0]
"− 5, λ3 = 1e",4.3.1 Experimental Settings,[0],[0]
"− 3, γ = 1.",4.3.1 Experimental Settings,[0],[0]
"For the extended models of DistMult, the parameters are set as λ1 = 1e",4.3.1 Experimental Settings,[0],[0]
"− 5, λ2 = 1e",4.3.1 Experimental Settings,[0],[0]
"− 4, λ3 = 1e",4.3.1 Experimental Settings,[0],[0]
"− 3, γ = 1.",4.3.1 Experimental Settings,[0],[0]
"For all the above models, the learning rate ς , batch size b and embedding size k are set as ς = 1e",4.3.1 Experimental Settings,[0],[0]
"− 3, b = 4096, k = 100.",4.3.1 Experimental Settings,[0],[0]
The L1 norm is adopted by the score function of TransE and its extended models.,4.3.1 Experimental Settings,[0],[0]
"The number of relation clusters are set as 300, 120 and 10 for FB15k, FB15k-237 and WN18 respectively.",4.3.1 Experimental Settings,[0],[0]
"For all the data sets, we generate 3 subrelations for relations that have more than 500 occurrences in the training set.",4.3.1 Experimental Settings,[0],[0]
"For all the extended models and baselines, we produce negative triples following the “bern” sampling strategy which was introduced in TransH (Wang et al., 2014).",4.3.1 Experimental Settings,[0],[0]
"For baselines TransE, TransH and DistMult, the embedding parameters of entities and relations are initialized the same way as the extended models for a fair comparison.
",4.3.1 Experimental Settings,[0],[0]
"In the test phase, we replace the head and tail entities with all the entities in KG in turn for each triple in the test set.",4.3.1 Experimental Settings,[0],[0]
Then we compute a score for each corrupted triple.,4.3.1 Experimental Settings,[0],[0]
"Note that for each corrupted
triple (h′, r, t′), the sub-relation is determined by t′ − h′, i.e., the k-means model is adopted to assign t′−h′ to a specific sub-relation of r. We rank all the candidate entities according to the scores.",4.3.1 Experimental Settings,[0],[0]
"Specifically, positive candidates are supposed to precede negative ones.",4.3.1 Experimental Settings,[0],[0]
"Finally, the rank of the correct entity is stored.",4.3.1 Experimental Settings,[0],[0]
"We compare our models with baselines using the following metrics: (1) Mean Rank (MR, the mean of all the predicted ranks); (2) Mean Reciprocal Rank (MRR, the mean of all the reciprocals of predicted ranks); (3) Hits@n",4.3.1 Experimental Settings,[0],[0]
"(Hn, the proportion of ranks not larger than n).",4.3.1 Experimental Settings,[0],[0]
Lower values of MR and larger values of MRR and Hn indicate better performance.,4.3.1 Experimental Settings,[0],[0]
"All the results are reported in the “filtered” setting (Bordes et al., 2013).",4.3.1 Experimental Settings,[0],[0]
Evaluation results are shown in Table 2.,4.3.2 Experimental Results,[0],[0]
We divide all the results into 4 groups.,4.3.2 Experimental Results,[0],[0]
"The second, third and forth group are results of TransE, TransH, DistMult and their extended models respectively, while the first group are results of other state-ofthe-art competitors.",4.3.2 Experimental Results,[0],[0]
Results in bold font are the best results in the group and the underlined results denote the best results in the column.,4.3.2 Experimental Results,[0],[0]
"From Table 1, we have the following findings: (1) Our extended models outperform the original models, which indicates that the information learned from the HRS is valuable; (2) For WN18, the results from ‘top-middle’ models of TransE, TransH and DistMult are worse than the original models, and HRS models can’t outperform middle-bottom ones.",4.3.2 Experimental Results,[0],[0]
We conjecture the reason lies as follows: WN18 has only 18 relations and the semantic correlation among relations is small.,4.3.2 Experimental Results,[0],[0]
"In this case, the information learned from the top to the middle layer of the HRS may lead to worse results since for each relation, even though the information learned from semantically similar relations are useful, the information learned from unrelated relations may damage the results.",4.3.2 Experimental Results,[1.0],"['In this case, the information learned from the top to the middle layer of the HRS may lead to worse results since for each relation, even though the information learned from semantically similar relations are useful, the information learned from unrelated relations may damage the results.']"
"The results indicate that HRS models are especially useful for KGs with dense semantic distributions over relations; (3) For WN18, TransE-middle-bottom and DistMult-middle-bottom achieve the best results on MRR, Hits@10, Hits@3 and Hits@1 while failing to get the best results on MR in the same group.",4.3.2 Experimental Results,[0],[0]
"Further analysis shows that in the results of TransE-middle-bottom, 56 test triples get ranks more than 10000, leading to more than 110 MR loss.",4.3.2 Experimental Results,[0],[0]
"While in the results of DistMult-middle-
bottom, there exist 37 test triples whose ranks are more than 7000, which would lead to about 50 MR loss.",4.3.2 Experimental Results,[0],[0]
"Indeed, MR is sensitive to these high ranks, which lead to worse results on the metric of MR; (4) From all the results, based on the good basic model DistMult, the extended models of DistMult can achieve the best performance compared with other state-of-the-art baselines CTransR, TransD and TransG.
We also provide some case studies on relation clusters and sub-relations.",4.3.2 Experimental Results,[0],[0]
Table 3 shows some relation clusters of FB15k.,4.3.2 Experimental Results,[0],[0]
"Cluster 1 to 3 are Olympics-related, basketball-related and software-related relations respectively.",4.3.2 Experimental Results,[0],[0]
From Table 3 we can see that semantically related relations can join the same cluster.,4.3.2 Experimental Results,[0],[0]
"Table 4 shows some (head, tail) pairs for the sub-relations of ‘/educational institution/education/degree’.",4.3.2 Experimental Results,[0],[0]
"Sub-relation 1 to 3 are about the degree of Doctor, Master and Bachelor respectively.",4.3.2 Experimental Results,[0],[0]
"Table 5 gives some (head, tail) pairs for the sub-relations of ’/music/artist/genre’.",4.3.2 Experimental Results,[0],[0]
Sub-relation 1 and 2 are about rock music and pop music respectively while subcluster 3 is about other kinds of music.,4.3.2 Experimental Results,[0],[0]
"From Table 4 and 5, we can see that different sub-relations give fine-grained descriptions for each relation.",4.3.2 Experimental Results,[0],[0]
"In this section, we study the performance affected by the number of relation clusters N1 as well as the number of sub-relations for each relation N2.",4.3.3 Parameter Study,[1.0],"['In this section, we study the performance affected by the number of relation clusters N1 as well as the number of sub-relations for each relation N2.']"
The results in Figure 2 and 3 clearly show that there exists an optimal value of N1 and N2 for each dataset.,4.3.3 Parameter Study,[1.0],['The results in Figure 2 and 3 clearly show that there exists an optimal value of N1 and N2 for each dataset.']
All three models keep achieving better results as we increase the number of clusters from 0 to the optimal value.,4.3.3 Parameter Study,[0],[0]
"Then, after N1 and N2 exceed the optimal point, the performance starts falling down.",4.3.3 Parameter Study,[0],[0]
The reason lies as: (1) Smaller value of N1 leads to large-sized relation clusters.,4.3.3 Parameter Study,[0],[0]
Some unrelated relations may join in the same large-sized cluster and degrade the performance of our models.,4.3.3 Parameter Study,[0],[0]
"Larger value of N1 leads to small-sized relation clusters, thus less information can be leveraged by each relation, leading to the unsatisfying performance; (2) Smaller value of N2 can’t provide sufficient representations for each relation and degrade the performance of our models.",4.3.3 Parameter Study,[0],[0]
Larger value ofN2 may lead to lacking of training data for each sub-relation and also result in the unsatisfying performance.,4.3.3 Parameter Study,[0],[0]
"In order to testify the discriminative capability of our models, we conduct a triple classification task aiming to predict the label (True or False) of a given triple (h, r, t).",4.4 Triple Classification,[1.0],"['In order to testify the discriminative capability of our models, we conduct a triple classification task aiming to predict the label (True or False) of a given triple (h, r, t).']"
"In this paper, we use three datasets WN11, FB13 and FB15k to evaluate our models.",4.4.1 Experimental Settings,[1.0],"['In this paper, we use three datasets WN11, FB13 and FB15k to evaluate our models.']"
"The data sets WN11 and FB13 released by NTN (Socher et al., 2013) already have negative triples.",4.4.1 Experimental Settings,[0],[0]
"The test set of FB15k only contains correct triples, which re-
quires us to construct negative triples.",4.4.1 Experimental Settings,[0],[0]
"In this study, we construct negative triples following the same setting used for FB13 (Socher et al., 2013).",4.4.1 Experimental Settings,[0],[0]
"For the extended models of TransE, λ1, λ2, λ3 and γ are set as λ1 = 1e−5, λ2 = 1e−5, λ3 = 1e−3 and γ = 4.",4.4.1 Experimental Settings,[0],[0]
"For the extended models of TransH, we set λ1 = 1e",4.4.1 Experimental Settings,[0],[0]
"− 5, λ2 = 1e",4.4.1 Experimental Settings,[0],[0]
"− 4, λ3 = 1e",4.4.1 Experimental Settings,[0],[0]
− 3 and γ = 5.,4.4.1 Experimental Settings,[0],[0]
"While for the extended models of DistMult, parameters are set as λ1 = 1e",4.4.1 Experimental Settings,[0],[0]
"− 5, λ2 = 1e− 4, λ3 = 1e− 2 and γ = 4.",4.4.1 Experimental Settings,[0],[0]
"For WN11 and FB13, we generate 2 sub-relations for each relation.",4.4.1 Experimental Settings,[0],[0]
"For FB15k, we generate 3 sub-relations for
relations that have more than 500 occurrences in the training set.",4.4.1 Experimental Settings,[0],[0]
Other parameters are set as introduced in Section 4.3.1.,4.4.1 Experimental Settings,[0],[0]
"We follow the same decision process as NTN (Socher et al., 2013): for TransE and TransH, a triple is predicted to be positive if fr(h, t) is below a threshold, while for DistMult, a triple is regarded as a positive one if fr(h, t) is above a threshold; otherwise negative.",4.4.1 Experimental Settings,[0],[0]
The thresholds are determined on the validation set.,4.4.1 Experimental Settings,[0],[0]
We adopt accuracy as our evaluation metric.,4.4.1 Experimental Settings,[0],[0]
"Finally, the evaluation results in Table 6 lead to the following findings: (1) Our models outperform other baselines on WN11 and FB15k, and obtain comparable results with baselines on FB13, which validate the effectiveness of our models; (2) The extended models TransE-HRS, TransH-HRS and DistMult-HRS achieve substantial improvements against the original models.",4.4.2 Experimental Results,[0],[0]
"On WN11, TransE-
HRS outperforms TransE with a margin as large as 10.9%.",4.4.2 Experimental Results,[0],[0]
These improvements indicates the technique of utilizing the HRS information is capable to be extended to different KGE models.,4.4.2 Experimental Results,[0],[0]
"Figure 4
shows the classification accuracy of different relations on WN11.",4.4.2 Experimental Results,[0],[0]
"We can see that extended models significantly improve the original models in each relation classification task, which again validate the effectiveness of our models.",4.4.2 Experimental Results,[1.0],"['We can see that extended models significantly improve the original models in each relation classification task, which again validate the effectiveness of our models.']"
"In this paper, we found that relations in KGs conform to a three-layer HRS.",5 Conclusion,[0],[0]
"This HRS model provides a critical capacity for embedding entities and relations, and along this line we extended three state-of-the-art models to leverage the HRS information.",5 Conclusion,[0],[0]
The technique we used can be easily applied to extend other KGE models.,5 Conclusion,[1.0],['The technique we used can be easily applied to extend other KGE models.']
"Moreover, our proposed models don’t need additional information like text or paths, instead, we made full use of the knowledge triples in KGs and the rich information from the HRS.",5 Conclusion,[0],[0]
We evaluate our model on the link prediction task and triple classification task.,5 Conclusion,[0],[0]
"The results show that our extended models achieve substantial improvements against the original models as well as other baseline competitors.
",5 Conclusion,[1.0000000361039936],['The results show that our extended models achieve substantial improvements against the original models as well as other baseline competitors.']
"In the future, we will utilize more sophisticated models to leverage the HRS information, e.g, (1) utilize the embeddings of the three layers in a more sophisticated way instead of sum them together;
(2) determine the number of relation clusters and sub-relations automatically instead of manually.",5 Conclusion,[0.9999999693777183],"['In the future, we will utilize more sophisticated models to leverage the HRS information, e.g, (1) utilize the embeddings of the three layers in a more sophisticated way instead of sum them together; (2) determine the number of relation clusters and sub-relations automatically instead of manually.']"
"The research work is supported by the National Key Research and Development Program of China under Grant No. 2018YFB1004300, the National Natural Science Foundation of China under Grant No. 61773361, 61473273, 91546122, Guangdong provincial science and technology plan projects under Grant No. 2015 B010109005, the Project of Youth Innovation Promotion Association CAS under Grant No. 2017146.",Acknowledgements,[0],[0]
This work is also partly supported by the funding of WeChat cooperation project.,Acknowledgements,[0],[0]
"We thank Bo Chen, Leyu Lin, Cheng Niu, Xiaohu Cheng for their constructive advices.",Acknowledgements,[0],[0]
"The rapid development of knowledge graphs (KGs), such as Freebase and WordNet, has changed the paradigm for AI-related applications.",abstractText,[0],[0]
"However, even though these KGs are impressively large, most of them are suffering from incompleteness, which leads to performance degradation of AI applications.",abstractText,[0],[0]
Most existing researches are focusing on knowledge graph embedding (KGE) models.,abstractText,[0],[0]
"Nevertheless, those models simply embed entities and relations into latent vectors without leveraging the rich information from the relation structure.",abstractText,[0],[0]
"Indeed, relations in KGs conform to a three-layer hierarchical relation structure (HRS), i.e., semantically similar relations can make up relation clusters and some relations can be further split into several fine-grained sub-relations.",abstractText,[0],[0]
"Relation clusters, relations and sub-relations can fit in the top, the middle and the bottom layer of three-layer HRS respectively.",abstractText,[0],[0]
"To this end, in this paper, we extend existing KGE models TransE, TransH and DistMult, to learn knowledge representations by leveraging the information from the HRS.",abstractText,[0],[0]
"Particularly, our approach is capable to extend other KGE models.",abstractText,[0],[0]
"Finally, the experiment results clearly validate the effectiveness of the proposed approach against baselines.",abstractText,[0],[0]
Knowledge Graph Embedding with Hierarchical Relation Structure,title,[0],[0]

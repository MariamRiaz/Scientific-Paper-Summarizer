23	32	We define the LSTM units at each time step t to be a collection of vectors in Rd: an input gate it, a forget gate ft, an output gate ot, a memory cell ct and a hidden state ht.
24	5	d is the number of the LSTM units.
25	8	The elements of the gating vectors it, ft and ot are in [0, 1].
28	15	The update of each LSTM unit can be written precisely as follows: ht = LSTM(ht−1,xt, θp).
30	9	(1-3), and θp represents all the parameters of LSTM.
35	5	L(ŷ, y) = − N∑ i=1 C∑ j=1 yji log(ŷ j i ), (6) where yji is the ground-truth label; ŷ j i is prediction probabilities, and C is the class number.
36	6	softmax Lmtask LSTM softmax Lntask xm xn (a) Fully Shared Model (FS-MTL)
38	4	To facilitate this, we give some explanation for notations used in this paper.
39	14	Formally, we refer to Dk as a dataset with Nk samples for task k. Specifically, Dk = {(xki , yki )}Nki=1 (7) where xki and y k i denote a sentence and corresponding label for task k.
47	18	This model ignores the fact that some features are task-dependent.
49	5	Shared-Private Model (SP-MTL) As shown in Figure 2b, the shared-private model introduces two feature spaces for each task: one is used to store task-dependent features, the other is used to capture task-invariant features.
50	12	Accordingly, we can see each task is assigned a private LSTM layer and shared LSTM layer.
51	8	Formally, for any sentence in task k, we can compute its shared representation skt and task-specific representation h k t as follows: skt = LSTM(xt, s k t−1, θs), (8) hkt = LSTM(xt,h m t−1, θk) (9) where LSTM(., θ) is defined as Eq.
57	14	Thus, some useful sharable features could be ignored in shared-private model, and the shared feature space is also vulnerable to contamination by some taskspecific information.
59	29	To address this problem, we introduce adversarial training into multi-task framework as shown in Figure 3 (ASPMTL).
60	21	Adversarial networks have recently surfaced and are first used for generative model (Goodfellow et al., 2014).
61	4	The goal is to learn a generative distribution pG(x) that matches the real data distribution Pdata(x) Specifically, GAN learns a generative network G and discriminative model D, in which G generates samples from the generator distribution pG(x).
63	31	This min-max game can be optimized by the following risk: φ = min G max D ( Ex∼Pdata [logD(x)] + Ez∼p(z)[log(1−D(G(z)))] ) (11) While originally proposed for generating random samples, adversarial network can be used as a general tool to measure equivalence between distributions (Taigman et al., 2016).
65	63	Motivated by theory on domain adaptation (Ben-David et al., 2010, 2007; Bousmalis et al., 2016) that a transferable feature is one for which an algorithm cannot learn to identify the domain of origin of the input observation.
66	14	Inspired by adversarial networks (Goodfellow et al., 2014), we proposed an adversarial sharedprivate model for multi-task learning, in which a shared recurrent neural layer is working adversarially towards a learnable multi-layer perceptron, preventing it from making an accurate prediction about the types of tasks.
68	4	Task Discriminator Discriminator is used to map the shared representation of sentences into a probability distribution, estimating what kinds of tasks the encoded sentence comes from.
69	23	D(skT , θD) = softmax(b+Us k T ) (12) where U ∈ Rd×d is a learnable parameter and b ∈ Rd is a bias.
72	6	The original loss of adversarial network is limited since it can only be used in binary situation.
75	6	At the same time, the discriminator tries its best to make a correct classification on the type of task.
76	27	After the training phase, the shared feature extractor and task discriminator reach a point at which both cannot improve and the discriminator is unable to differentiate among all the tasks.
77	26	Semi-supervised Learning Multi-task Learning We notice that the LAdv requires only the input sentence x and does not require the corresponding label y, which makes it possible to combine our model with semi-supervised learning.
81	35	Motivated by recently work(Jia et al., 2010; Salzmann et al., 2010; Bousmalis et al., 2016) on shared-private latent space analysis, we introduce orthogonality constraints, which penalize redundant latent representations and encourages the shared and private extractors to encode different aspects of the inputs.
82	7	After exploring many optional methods, we find below loss is optimal, which is used by Bousmalis et al. (2016) and achieve a better performance: Ldiff = K∑ k=1 ∥∥∥Sk>Hk ∥∥∥ 2 F , (14) where ‖ · ‖2F is the squared Frobenius norm.
84	4	The final loss function of our model can be written as: L = LTask + λLAdv + γLDiff (15) where λ and γ are hyper-parameter.
85	4	The networks are trained with backpropagation and this minimax optimization becomes possible via the use of a gradient reversal layer (Ganin and Lempitsky, 2015).

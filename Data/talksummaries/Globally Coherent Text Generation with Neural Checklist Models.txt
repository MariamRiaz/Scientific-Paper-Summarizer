0	73	Recurrent neural network (RNN) architectures have proven to be well suited for many natural language generation tasks (Mikolov et al., 2010; Mikolov et al., 2011; Sordoni et al., 2015; Xu et al., 2015; Wen et al., 2015; Mei et al., 2016).
1	78	Previous neural generation models typically generate locally coherent language that is on topic; however, overall they can miss information that should have been introduced or introduce duplicated or superfluous content.
2	54	These errors are particularly common in situations where there are multiple distinct sources of input or the length of the output text is sufficiently long.
3	42	In this paper, we present a new recurrent neural model that maintains coherence while improv- ing coverage by globally tracking what has been said and what is still left to be said in complete texts.
4	81	For example, consider the challenge of generating a cooking recipe, where the title and ingredient list are provided as inputs and the system must generate a complete text that describes how to produce the desired dish.
5	40	Existing RNN models may lose track of which ingredients have already been mentioned, especially during the generation of a long recipe with many ingredients.
8	28	More specifically, our neural checklist model generates a natural language description for achieving a goal, such as generating a recipe for a particular dish, while using a new checklist mechanism to keep track of an agenda of items that should be mentioned, such as a list of ingredients (see Fig.
39	31	At a high level, our model uses a recurrent neural network (RNN) language model that encodes the goal as a bag-of-words and then generates output text token by token.
50	76	To generate the output token probability distribution (see “Generate output” box in Fig.
52	121	The output hidden state is the linear interpolation of (1) content cgrut from a Gated Recurrent Unit (GRU) language model, (2) an encoding cnewt generated from the new agenda item reference model (Sec.
57	125	1 example, fnewt is high in the first row when new ingredient references “tomatoes” and “onion” are generated; fusedt is high when the reference back to “tomatoes” is made in the second row, and fgrut is high the rest of the time.
58	150	To generate these weights, our model uses a threeway probabilistic classifier, ref -type(ht), to determine whether the hidden state of the GRU ht will generate non-agenda tokens, new agenda item references, or used item references.
59	38	ref -type(ht) generates a probability distribution ft ∈ R3 as ft = ref -type(ht) = softmax(βSht), where S ∈ R3×k is a trained projection matrix and β is a temperature hyper-parameter.
72	36	cnewt is computed using an attention model that generates a learned soft alignment αnewt ∈ RL between the hidden state ht and the rows of Enewt (i.e., available items).
95	25	We use mini-batch stochastic gradient descent, and back-propagate through the goal, agenda, and text embeddings.
140	25	We also present a nearest neighbor baseline (NN) that simply copies over an existing recipe text based on the input similarity computed using cosine similarity over the title and the ingredient list.
143	25	Our neural checklist model is labeled Checklist.
165	30	Human evaluation Because neither BLEU nor METEOR is suitable for evaluating generated text in terms of their adherence to the provided goal and the agenda, we also report human evaluation using Amazon Mechanical Turk.
166	26	We evaluate the generated recipes on (1) grammaticality, (2) how well the recipe adheres to the provided ingredient list, and (3) how well the generated recipe accomplishes the desired dish.
171	36	Perhaps surprisingly, both the Attention and EncDec baselines and the Checklist model beat the true recipes in terms of having better grammar.
172	27	This can partly be attributed to noise in the parsing of the true recipes, and partly because the neural models tend to generate shorter, simpler texts.
173	34	3 shows the counts of the most used vocabulary tokens in the true dev set recipes compared to the recipes generated by EncDec and Checklist+.
180	53	The EncDec model is much more likely to both use incorrect ingredients and to introduce ingredients more than once (e.g., “baking power” and “salt” in the bottom example are not in the ingredient list, and “milk” in the top example is duplicated).
182	70	The Checklist+ recipes generate the correct dishes to an extent: for example, the top recipe makes a casserole but does not cook the ingredients together before baking and mixes in biscuits instead of putting them on top.
184	55	Figure 3 shows our results on the hotel and restaurant dialogue system generation tasks.
186	87	For both domains, the checklist model achieved the highest BLEU-4 and METEOR scores, but both neural systems performed very well.
187	192	The power of our model is in generating long texts, but this experiment shows that our model can generalize well to other tasks with different kinds of agenda items and goals.
189	75	Future work includes incorporating referring expressions for sets or compositions of agenda items (e.g., “vegetables”).
190	70	The neural checklist model is sensitive to hyperparameter initialization, which should be investigated in future work.
191	86	The neural checklist model can also be adapted to handle multiple checklists, such as checklists over composite entities created over the course of a recipe (see Kiddon (2016) for an initial proposal).

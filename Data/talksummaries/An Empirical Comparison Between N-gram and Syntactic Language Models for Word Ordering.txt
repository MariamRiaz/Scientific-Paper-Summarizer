6	221	In this paper, we make an empirical comparison between syntactic and N-gram language models on the task of word ordering (Wan et al., 2009; Zhang and Clark, 2011a; De Gispert et al., 2014), which is to order a set of input words into a grammatical and fluent sentence.
7	24	The task can be regarded as an abstract language modeling problem, although methods have been explored extending it for tree linearization (Zhang, 2013), broader text generation (Song et al., 2014) and machine translation (Zhang et al., 2014).
8	23	We choose the model of Liu et al.(2015) as the syntactic language model.
13	52	We try to answer the following research questions by comparing the syntactic model and the Ngram model using the same search algorithm.
14	34	â€¢ What is the influence of automaticallyparsed training data on the performance of syntactic models.
15	29	Because manual syntactic annotations are relatively limited and highly expensive, it is necessary to use large-scale automatically-parsed sentences for training syntactic language models.
16	28	As a result, the syntactic structures that a word ordering system learns can be inaccurate.
20	38	N-gram language models can be trained efficiently over large numbers of raw sentences.
50	25	The feature templates essentially represents a syntactic language model.
61	28	For training data, we use the Wall Street Journal (WSJ) sections 1-22 of the Penn Treebank (Marcus et al., 1993), and the Agence France-Presse (AFP) and Xinhua News Agency (XIN) subsets of the English Giga Word Fifth Edition (Parker et al., 2011).
90	42	We train the syntactic models on the WSJ training parsing data with different accuracies.
95	27	On the other hand, the influence is not huge, the BLEU scores decrease by 1.0 points as the parsing accuracy decreases from 88.10% to 57.31%
102	17	On the other hand, when the training data scale increases, syntactic models can become much slower to train compared with Ngram models.
106	27	The WPB test data is used to measure indomain performance, and the SANCL blog data is used to measure cross-domain performance.
110	85	The grey dot in each figure shows the performance of the syntactic model trained on the gold WSJ training data, and evaluated on the same WPB and SANCL test data sets.
111	26	A comparison between the grey dots and the dashed lines shows that the syntactic model trained on the WSJ data perform better than the syntactic model trained on similar amounts of AFP data.
116	30	Figure 5 shows the BLEU of the two systems under different amounts of training time.
118	27	On the other hand, the N-gram model can be trained using all the WSJ, AFP, XIN training sentences, which are 53 millions, within 103.2 seconds.
120	38	As can be seen from the figure, the syntactic model is much slower to train.
130	19	The results are measured by binning sentences according to their lengths, so that each bin contains about the same number of sentences.
131	45	As shown by the figure, the N-gram model performs better on short sentences (less than 8 tokens), and the syntactic model performs better on longer sentences.
141	25	The syntactic model performs better in most constituent labels.
149	25	7 Combining the syntactic and N-gram models The results above show the respective error characteristics of each model, which are complimentary.
151	18	7.1 N-gram language model feature We integrate the two types of models by using N-gram language model probabilities as features in the syntactic model.
172	24	The influ- ence of parsing accuracies has relatively small impact on the syntactic language model trained on automatically-parsed data, which enables scaling up of training data for syntactic language models.
175	24	On the other hand, the two models lead to different error distributions in word ordering.
176	29	As a result, we combined the advantages of both systems by integrating a syntactic model trained with relatively small data and an N-gram model trained with relatively large data.
177	45	The resulting model gives better performance than both single models and achieves the best reported scores in a standard benchmark for word ordering.
178	30	We release our code under GPL at https:// github.com/SUTDNLP/ZGen.
179	74	Future work includes application of the system on text-to-text problem such as machine translation.

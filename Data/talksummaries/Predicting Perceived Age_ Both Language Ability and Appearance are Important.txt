0	43	Co-located, face-to-face spoken dialogue is the primary and basic setting where humans learn their first language (Fillmore, 1981) partly because dialogue participants (i.e., caregiver and child) can denote objects in their shared environment which is an important developmental step in child language acquisition (McCune, 2008).
1	40	This setting motivates human-robot interaction tasks where robots acquire semantic meanings of words, and where part of the semantic representation of those words is grounded (Harnad, 1990) somehow in the physical world (e.g., the semantics of the word red is grounded in perception of color vision).
3	48	However, humans who interact with robots often assign anthropomorphic characteristics to robots depending on how they perceive those robots; for example stereotypical gender (Eyssel and Hegel, 2012), social categorizations (Eyssel and Kuchenbrandt, 2012) stereotypical roles (Tay et al., 2014), as well as intelligence, interpretability, and sympathy (Novikova et al., 2017).
4	53	This has implications for the kinds of tasks that we ask our robots to do and the settings in which robots perform those tasks, including tasks where language grounding and acquisition is either a direct or indirect goal.
5	36	It is important not to assume that humans will perceive the robot in the “correct” way; rather, the age and academic level appropriateness needs to be monitored, particularly in a grounding and first-language acquisition task.
7	68	Certainly, enough functional systems exist that show how language can be acquired in many ways.
10	28	We hypothesize in this paper that how a robot looks and acts will not only affect how humans perceive that robot’s intelligence, but it will also affect how humans perceive that robot’s age and academic level.
12	46	We show through an experiment that human perception of robots, particularly in how they perceive the robots’ intelligence, age, and academic level, is due to how the robot appears, but also due to how the robot uses speech to interact.
26	25	The robots did not move during the experiments, though they were clearly activated (e.g., the KOBUKI had a small light and COZMO’s eyes were visible and moved at random intervals, which is the default setting).
27	26	Figure 1 shows the KOBUKI and COZMO robots as seen by the participants.
29	26	We chose a spoken dialogue system (SDS) as one of the “robots” because we wanted to explore how participants perceive a system that is unembodied in direct comparison to embodied systems.
32	36	In the high setting, the following responses were possible: sure; okay; yeah; oh; I see; uh huh; (where the robot repeats a word spoken by the participant) and any combination of those responses in a single uttered response; and for the low setting, the following responses were possible: yes; okay; uh; (where the robot repeats a word spoken by the participant).
39	23	The participant was then given three colored pentomino puzzle tiles and a sheet of paper with three goal shapes (example in Figure 2), each composed from the corresponding tiles.
48	62	The following aspects of the experiment were randomly assigned to each participant: the order of robot presentation, the puzzle tiles and corresponding goal shapes for each robot, the language setting (i.e., high or low) which remained the same for all three robot interactions for each participant, and for KOBUKI and SDS the adult voice (either Joey or Joanna).
52	29	We automatically transcribed the speech using the Google Speech API (we manually checked an accented female voice which achieved an estimated WER of 30.0) and segmented transcriptions into sentences after 1 second of detected silence, which is a longer pause duration than the average pause duration for adult-adult conversation (though adults tend to take longer pauses when interacting with children (DePaulo and Coleman, 1986)).
54	35	We also collected 58 questionnaires (we had to remove several because they were missing data; i.e., some participants did not answer some of the questionnaire questions), one for each robot interaction, from each participant.
58	65	We used the Microsoft Emotion API for processing these images to calculate an average distribution over 8 possible emotion categories for each image: happiness, sadness, surprise, anger, fear, contempt, disgust, and neutral.
61	174	Linguistic Features Using the automatically transcribed text, we follow directly from Novikova et al. (2017) to derive several linguistic measures, with the exception that we did not derive dialoguerelated features because, though our robots were engaging in a kind of dialogue with the participants, they weren’t taking the floor in a dialogue turn; i.e., our robots were only providing feedback to signal either phonetic receipt or semantic understanding (low and high settings, respectively).
62	37	We used the Lexical Complexity Analyser (Lu, 2009, 2012), which yields several measures, two of which we leverage here: lexical diversity (LD) and the mean segmented type-token ratio (MSTTR), both of which measure diversity of tokens; the latter averaging the diversity over segments of a given length (for all measures, higher values denote more respective diversity and sophistication in the measured text).
66	57	The D-Level scale counts utterances belonging to one of 8 levels (Levels 0- 7), where lower levels such as 0-1 include simple or incomplete sentences; the higher the level, the more complex the syntactic structure.
95	83	Overall, participants assigned low age and academic level to all robots when they produced feedback that did not signal semantic understanding (i.e., the low setting).
99	34	There is more to the F0 correlations: F0 in the low setting correlates with conscious, in the high setting correlates with natural and human-like, and in the COZMO robot setting with lifelike.
101	71	Lexical diversity correlates with sadness and contempt, which indicates that participants use more diverse language (i.e., they continue speaking) when they are frustrated with the interaction (Stubbe, 1998); particularly in the high setting when they expect more from the robots.
132	32	Though the data is sparse, these classifiers give us useful information: a robot can use these classifiers to determine if they are perceived as an adult by human dialogue partners, and, more importantly for our purposes, as a preschool aged child, which is the age range in which we are interested for language acquisition tasks.
142	53	This confirms the work of Novikova et al. (2017) that linguistic features are a good predictor of interpretability.
143	41	In this paper, we have investigated how human dialogue partners perceive the age and academic level of three robotic systems, two of which were embodied (albeit not particularly anthropomorphically), and one unembodied spoken dialogue system.
144	60	We collected data from participants as they interacted with the three robotic systems then derived prosodic, emotional, and linguistic features from that participant data, and found that those features correlate with certain age and academic perceptions of those robots, as well as a number of other subjective measures from the Godspeed Questionnaire.
145	33	This work confirms what previous work has shown: that humans tend to perceive robots differently depending on different factors; in our case, varying the look and spo- ken reposes determined how the human participants perceived the age and academic levels, as well as intelligence, likability, and interpretability of those robots.
146	52	We were then able to use these features to automatically predict perceived age (i.e., adult or minor), perceived academic level (i.e., preschool or above) and perceived intelligence, likability, and interpretabilitiy.
149	33	The work presented here shows that those interacting with a robot like COZMO will more likely treat COZMO as a learning child instead of as an adult.

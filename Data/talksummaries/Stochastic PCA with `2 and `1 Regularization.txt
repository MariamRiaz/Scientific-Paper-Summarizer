0	32	Principal component analysis (PCA), a ubiquitous procedure in scientific analysis, can be posed as the following learning problem: given a zero-mean random vector x ∈ Rd with some (unknown) distribution D, find the k-dimensional subspace that captures the maximal mass of the distribution.
1	9	If we represent a subspace by an orthogonal basis matrix U ∈ Rd×k that spans the subspace, then PCA returns the subspace that maximizes the variance in data projected onto the subspace, i.e. E[‖U>x‖2], among all k-dimensional subspaces of Rd.
2	36	Formally, we can write PCA as the following stochastic optimization problem: min U∈Rd×k − E[‖U>x‖2] subject to U>U = Ik .
7	12	Furthermore, given access to the distribution D only through a sample {xi}ni=1 ∼ Dn drawn independently from D, the sample average approximation (SAA, or equivalently empirical risk minimization) approach to learning the maximal variance subspace amounts to finding the top-k eigenvectors of the empirical covariance matrix, Ĉ := 1n ∑n i=1 xix > i .
8	16	An alternative computationally attractive approach to solving Problem 1 is based on stochastic approximation (SA) algorithms that attempt to directly minimize the objective given access to a first order oracle.
10	20	Such first order methods for solving Problem 1 have received a lot of attention in recent years (Arora et al., 2012; 2013; Balsubramani et al., 2013; Mitliagkas et al., 2013; Shamir, 2016; Allen-Zhu & Li, 2017; Jain et al., 2016; Balcan et al., 2016).
12	22	Rather than directly solve the nonconvex problem, one can consider a convex relaxation of the equivalent formulation in Problem 2.
13	33	Following Arora et al. (2013), we take the convex hull of the constraint set in Problem 2 to obtain the following convex program: min M∈Rd×d − E[x>Mx] subject to Tr (M) = k, 0 M I .
14	30	(4) Stochastic gradient descent on Problem 4 yields the following update, also referred to as matrix stochastic gradient (MSG) in (Arora et al., 2013): Mt+1 ←P(Mt + ηtxtx>t ), (5) where P(·) is the projection operator onto the feasible set of Problem 4 with respect to the Frobenius norm.
15	18	Assuming the fourth moment of the distribution is bounded by a constant, the standard analysis of (Shamir & Zhang, 2013) yields the following guarantee for MSG: E[x>M∗x]− E[x>M̄x] = O ( log T√ T ) , where M∗ is the optimal solution to the PCA Problem 2 and M̄ = rounding(MT+1) is a rank-k projection matrix obtained using randomized rounding (Warmuth & Kuzmin, 2008) of the final iterate of MSG.
16	42	Compared to Oja’s algorithm, MSG has two major drawbacks: first, Oja’s algorithm achieves a faster Õ( 1T ) rate of convergence, and second, Oja’s algorithm is computationally efficient since at each iteration it only keeps a d × k orthogonal matrix, while rank of the projection matrix Mt in MSG can possibly grow at each iteration.
17	7	More generally, methods based on convex relaxation are usually hard to scale to large problems due to both statistical inefficiency and higher computational cost.
21	16	Thus, a natural question to ask is if the suboptimal guarantees on statistical and computational efficiency of methods based on convex relaxation are artifacts of analysis.
40	8	PCA with `2-regularization In this section, we study how adding a strongly convex regularizer to the linear PCA objective in Problem 4 changes the optimization problem and if we can leverage strong convexity of the resulting objective to guarantee a faster convergence rate without changing the optimum.
47	19	Before giving formal results, we make a few remarks summarizing the key observations.
48	9	Fast rate: The objective in Problem 6 is λ-strongly convex.
51	54	Our analysis shows that if there exists an eigengap at k in the spectrum of the covariance matrix, i.e. if gk = λk(C)− λk+1(C) > 0, then for λ < gk, the global optimum of the regularized PCA problem is a global optimum for the original problem, even when there is no eigengap at k – we refer to such values of the regularization parameter as admissible; see Section 2.1 for more details.
56	17	This rank-one eigenupdate requires O(k3t + dk 2 t ) time and O(dkt) space where kt = rank(Mt); this computational trick is well-known in literature (Arora et al., 2013).
70	22	Let p and q be respectively the largest index smaller than k and the smallest index larger than k, at which C has an eigengap: p := max {i : i ∈ {0, .
77	10	As can be seen in the bottom row, all points on the left edge are equally good in terms of the objective.
79	27	Convergence Analysis of `2-RMSG Our main result of this section bounds the sub-optimality of the output of Algorithm 1, for admissible values of the regularization parameter λ, in terms of the distance from the optimal subspace, M∗.
81	9	Then, for any admissible value of λ, after T iterations of Algorithm 1 starting at M1 = 0, with step-size sequence ηt = 1λt , we have that E[ ∥∥M̃−M∗∥∥2F ] ≤ 16(1 + λ √ k)2 λ2T , (8) where M∗ is an optimum of Problem 4, M̃ is the output after rounding the final iterate to a rank-k matrix, and the expectation is with respect to the distribution D. Minimax Optimality: Theorem 2.4 guarantees that the iterates of Algorithm 1 converge to the optimal projection matrix in Frobenius norm.
90	8	In order to overcome this computational barrier, which appears to be a natural artifact of convex relaxations, we consider regularizing the PCA objective with an `1 penalty.
102	7	KKT first-order optimality condition on Problem 10 gives λk(C) = µ − γk + ωk + β, where γk, ωk, β ≥ 0 are Lagrange multipliers associated with the constraints λk(M) ≥ 0, λk(M) ≤ 1 and Tr M ≤ k. If µ > λk(C), and since β, ωk ≥ 0, it should hold that γk > 0.
108	7	The result above shows that for sufficiently small admissible µ, `1-RMSG converges at the same rate as MSG, i.e. O( log T√ T ).
110	22	We show formally that the `1 regularization prevents the rank of `1-RMSG iterates from growing too large.
125	11	Again, we should be judicious in our choice of the regularization parameters µ and λ so as to ensure that the regularized problem has the same optimum as the original problem; the following result provides a sufficient condition.
129	17	We conclude this section by noting that it is straightforward to adapt Theorem 2.4 to get a faster O( 1 ) iteration complexity for `2,1-RMSG, as long as we choose learning rate ηt = O( 1 t ).
130	42	Also, one can show rank-control as in Theorem 3.5, under the learning rate ηt = O( 1√t ).
134	15	We provide empirical results for our proposed algorithms `2-RMSG, `1-RMSG, and `2,1-RMSG, compared to vanilla MSG, Oja’s algorithm, and Follow The Leader (FTL) algorithm, on both synthetic and real datasets.

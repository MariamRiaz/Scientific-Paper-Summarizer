0	29	Detection problems, aiming to identify occurrences of specific kinds of information (e.g., events, relations, or entities) in documents, are fundamental and widespread in information extraction (IE).
3	37	Recently, a number of researches have employed neural network models to solve detection problems, and have achieved significant improvement in many tasks, such as event detection (Chen et al., 2015; Nguyen and Grishman, 2015), relation detection (Zeng et al., 2014; Santos et al., 2015) and named entity recognition (Huang et al., 2015; Chiu and Nichols, 2015; Lample et al., 2016).
4	25	These methods usually regard detection problems as standard classification tasks, with several positive classes for targets to detect and one negative class for irrelevant (background) instances.
9	18	First, positive instances are commonly sparsely distributed in detection tasks.
11	18	Furthermore, detection tasks are commonly evaluated using F-measure on positive classes, rather than accuracy or F-measure on all classes.
14	31	This is because minimizing cross-entropy loss function corresponds to maximize the accuracy of neural networks on all training instances, rather than Fmeasure on positive classes.
26	27	Based on the above framework, we propose adaptive scaling, a dynamic cost-sensitive learning algorithm which adaptively scales costs of instances of different classes with above quantified importance during the training procedure, and thus can make the optimization criteria consistent with the evaluation metric.
29	29	Generally, the main contributions of this paper are: • We propose a marginal utility based framework for detection model optimization, which can dynamically quantify instance importance to different evaluation metrics.
66	43	Formally, we derive marginal positive utility MU(TP ) and marginal negative utility MU(TN) by computing the partial derivative of the evaluation metric with respect to TP and TN respectively.
70	22	First, MUFβ (TP ) and MUFβ (TN) is no longer equal, indicating that the importance of positive/negative instances to F-measure are different.
72	23	In this section, we describe how to incorporate the above importance measures into the training procedure of neural networks, so that it can dynamically adjust weights of positive and negative instances regarding to F-measure.
74	20	Then wβ(θ) can be computed as the ratio of marginal negative utility MUFβ (TN(θ)) to the marginal positive utility MUFβ (TP (θ)), where TP (θ) and TN(θ) are TP and TN on training data with respect to θ-parameterized model: wβ(θ) = MUFβ (TN(θ)) MUFβ (TP (θ)) = TP (θ) β2P +N − TN(θ) + PE (11) Then at each iteration of the model optimization (i.e., each step of gradient descending), we want the model to take next update step proportional to the gradient of the wβ-scaled cross-entropy loss function LAS(θ) at the current point: LAS(θ) =− ∑ (xi,yi)∈P log p(yi|xi; θ) − ∑ (xi,yi)∈N wβ(θ) · log p(yi|xi; θ) (12) Consequently, based on the contributions that correctly predicting one more instances of each class bringing to F-measure, the training procedure dynamically adjusts its attention between positive and negative instances.
80	28	This indicates that the training procedure should pay more attention to positive instances if the empirical distribution inclines more severely towards negative class, which is identical to conventional practice that we should deemphasize more on negative instances if the positive sparsity problem is more severe (Japkowicz and Stephen, 2002).
81	16	Besides, wβ(θ) highly depends on TP and TN , which is identical to previous conclusion that the best cost factors are related to the convergence ability of models (Parambath et al., 2014).
87	17	Besides, if the accuracy of positive class is close to zero, F-measure will also be close to zero no matter how high the accuracy on negative class is, i.e., correctly predicting negative instances can result in little F-measure increment.
92	21	During model convergence, easy negative instances can be correctly classified at the very beginning of training and its loss (negative log probability) will reduce very quickly.
93	17	This is analogical to removing easy negative instances out of the training procedure and the hard negative instances remaining become more balanced proportional to positive instances.
97	28	This is identical to practice in sampling heuristics that models should attach more attention to negative instances and sub-sample more of them if evaluation metrics incline more to precision than recall.
103	43	Specifically, let PB = {(xi, yi)P B i=1} denotes PB positive instances andNB = {(xi, yi)N B i=1} is NB negative instances in the batch, we estimate TP (θ) and TN(θ) as: TPB(θ) = ∑ (xi,yi)∈PB p(yi|xi; θ) (14) TNB(θ) = ∑ (xi,yi)∈NB p(yi|xi; θ) (15) Then we can compute the estimator ŵβ(θ) for wβ(θ) as: ŵβ(θ) = TPB(θ) β2PB +NB − TNB(θ) (16) where ŵβ(θ) is computed using only the instances in a batch, which makes it can be directly applied as a plug-in of conventional batch-based neural network optimization algorithm where the loss of negative instances in batch are scaled by ŵβ(θ).
114	28	We compared our method with following baselines upon above-mentioned two models: 1) Vanilla models (Vanilla), which used the original cross-entropy loss function without any additional treatment for class inequality problem.
117	39	3) Static scaling (Scaling), which scales loss of negative instances with a constant.
132	22	Even down-weighting the loss assigned to well-classified examples can alleviate the positive sparsity problem by deemphasizing easy negative instances during optimization, Focal Loss cannot achieve competitive performance because it does not distinguish between different classes.
147	25	In all groups of experiments, the performances of our adaptive scaling algorithm are with a smaller fluctuation.
159	36	Furthermore, adaptive scaling with β = 1 achieved the best performance on F1 measure.
160	49	This further demonstrates that wβ derived from our marginal utility framework is a good and adaptive estimator for the relative importance of the negative class to positive classes of Fβ measure.
176	68	This paper proposes adaptive scaling algorithm for detection tasks, which can deal with its positive sparsity problem and directly optimize F-measure by adaptively scaling the influence of negative instances in loss function.
177	24	Based on the marginal utility theory framework, our method leads to more effective, stable and transferable optimization of neural networks without introducing additional hyper-parameters.
178	25	Experiments on event detection verified the effectiveness and stability of our adaptive scaling algorithm.
179	161	The divergence between loss functions and evaluation metrics is common in NLP and machine learning.
180	216	In the future we want to apply our marginal utility based framework to other metrics, such as Mean Average Precision (MAP).

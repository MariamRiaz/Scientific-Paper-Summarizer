6	40	Therefore, it is beneficial to provide MT confidence estimation, to help the translators to decide whether to accept MT proposals, making minor modifications on MT proposals when the quality is high or translating from scratching when the quality is low.
9	102	HTER is an ideal quality measurement for MT post editing since the reference is obtained from human correction of the MT output.
10	78	Document-specific MT model is an MT model that is specifically built for the given input document.
41	31	The document-specific system is built based on sub-sampling: from the parallel corpora we select sentence pairs that are the most similar to the sentences from the input document, then build the MT system with the sub-sampled sentence pairs.
48	27	Altogether the decoder incorporates 17 features with weights estimated by PRO (Hopkins and May, 2011) in the decoding process, and achieves state-of-the-art translation performance in various Arabic-English translation evaluations (NIST MT2008, GALE and BOLT projects).
57	76	• Source sentence syntactic features, including the number of noun phrases, verb phrases, adjective phrases, adverb phrases, as inspired by (Green et al., 2013).
59	28	• The maximum length of source phrases in the final translation, since longer matching source phrase indicates better coverage of the input sentence with possibly better translations.
84	25	However this is not helpful for the human translators, because that means they have to translate every sentence from scratch, and consequently there is no productivity gain from MT post-editing.
85	40	If we only use the 17 decoding features, it improves the classification accuracy by 9% on the training set, but only 2% on the test set.
89	34	Combining both the decoding features and the external features, we observed the best accuracy on both the training and test set.
92	23	We experiment with several classifiers: linear regression model, decision tree based regression model and SVM model.
93	33	With the same training and test data set up, we predict the TER for each sentence in the test set, and compute the correlation coefficient (r) and root mean square error (RMSE).
94	50	Our experiments show that the decision tree-based regression model obtains the highest correlation coefficients (0.53) and lowest RMSE (0.23) in both the training and test sets.
96	19	The above QE regression model is trained on a portion of the sentences from the input document, and evaluated on the remaining sentences from the same document.
97	19	One would like to know whether the trained model can achieve consistent TER prediction accuracy on other documents.
102	57	The source side of the QE training data Sq is combined with the input document Sd for MT system training data subsampling.
103	24	Once the document-specific MT system is trained, we use it to translate both the input document and the source QE training data, obtaining the translation Td and Tq .
126	42	We compare these two QE models on three documents, LZA, RTW and WC7, measuring r and RMSE for each QE model.
136	30	We evaluate the TER of MT outputs with and without the adaptive QE training on the same three documents.
140	26	We apply the proposed adaptive QE model to large scale English-to-Japanese MT Post-Editing project on 36 documents with 562K words.
141	165	Each English sentence can be categorized into 3 classes: • Exact Match (EM): the source sentence is completely covered in the bilingual training corpora thus the corresponding target sentence is returned as the translation; • Fuzzy Match (FM): the source sentence is similar to some sentence in the training data (similarity measured by string editing distance), the corresponding fuzzy match target sentence (FM proposal) as well as the MT translation output (MT proposal) are returned for human translators to select and correct; • No Proposal (NP): there is no close match source sentences in the training data (the FM similarity score of 70% is used as the threshold), therefore only the MT output is returned.
153	34	We also measure the translator’s productivity gain for MT proposals with different confidence labels.
156	32	We choose the overall productivity of NP0 as the base unit 1, where there is no proposal presents and the translator has to translate the segments from scratch.
158	72	Table 6 and 7 also show the productivity gain on sentences with High, Medium and Low labels from FM and NP categories.
159	46	Again, the productivity gain is consistent with the confidence labels from the adaptive QE model’s prediction.
162	23	In this paper we proposed a method to adaptively train a quality estimation model for documentspecific MT post editing.
163	104	With the 26 proposed features derived from decoding process and source sentence syntactic analysis, the proposed QE model achieved better TER prediction, higher correlation with human correction of MT output and higher F-score in finding good translations.
164	51	The proposed adaptive QE model is deployed to a large scale English-to-Japanese MT post editing project, showing strong correlation with human preference and leading to about 10% gain in human translator productivity.
168	147	Another option is to select the sentence pairs from the MT system subsampled training data, which is more similar to the input document thus the trained QE model could be a better match to the input document.
170	28	The model consistency is no longer guaranteed, and the QE training data must be removed from the MT system training data to avoid data contamination.

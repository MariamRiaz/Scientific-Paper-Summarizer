1	24	It has attracted huge attention in both academic and industrial communities due to its widespread applications, such like recommendation (Zhang et al., 2014) and social media mining (Chambers et al., 2015).
4	30	In this new form, a potential customer asks question(s) about the target product/service while other experienced user(s) can provide answer(s).
7	21	More importantly, because answer providers are randomly picked from the users who already purchased the target item, this new form of review can be more reliable and trustful.
9	21	However, because of the significant differences between QA-style and classical reviews, existing review mining algorithms, e.g., text-based sentiment analysis/classification, should not be di- rectly applied to this new kind of QA-style data.
18	25	In order to address these problems, a more appropriate approach is to segment both the question and answer text into some parallel sentences, and then construct the [Q-sentence, A-sentence] units in each QA text pair to detect in-depth sentiment information.
19	21	Second, although the main sentiment polarity is usually expressed from the answer text, the question text could also carry important sentiment tips to predict the sentiment polarity of a QA text pair.
20	17	For instance, in Figure 1, we could hardly estimate the sentiment polarity solely based on Answer 2.
25	15	Therefore, a well-behaved network approach should consider the importance degrees of different [Q-sentence, A-sentence] units for predicting the sentiment polarity of a QA text pair.
29	15	Second, we propose a hierarchical matching network model to address the challenges of QA-style sentiment classification.
33	18	Experimental results show that the proposed approach significantly outperforms several strong baselines for QA-style sentiment classification.
61	25	One contains the guidelines which aim to distinguish the categories of neutral and nonneutral, i.e., (a) A QA text pair in which the question and the answer do not match is annotated as a neutral sample.
97	21	We then construct [Q-sentence, A-sentence] units by pairing one sentence in the question text and one sentence in the answer text, and we obtain N*M [Q-sentence, A-sentence] units at last.
104	18	Figure 3 depicts the detail architecture of QA bidirectional matching mechanism.
105	20	Specifically, we first calculate the bidirectional pair-wise matching matrix by using the fol- lowing formula: D[i,j] = (HQi) > · (HAj ) (3) where D[i,j] ∈ RNi×Mj denotes the bidirectional matching matrix for the [SQi , SAj ] unit.
109	46	After computing the Answer-to-Question attention weight vector, we can get the Answer-to-Question matching vector V r[i,j] ∈ R d′ as follows: V r[i,j] = (HQi) · α r [i,j] (6) • Question-to-Answer Attention: Simultaneously, we employ column-wise operations to calculate the attention weight vector αc[i,j] as follows: U c[i,j] = tanh(Wc ·D[i,j]) (7) αc[i,j] = softmax(w > c · U c[i,j]) (8) where αc[i,j] ∈ R Mj is the Question-to-Answer attention weight vector regarding the importance degrees of all words in A-sentence SAj , Wc ∈ Rd′×Ni and wc ∈ Rd ′ are weight matrices.
111	22	Through the QA bidirectional matching layer, informative bidirectional matching vectors are generated to pinpoint the sentiment matching information in each [Q-sentence, A-sentence] unit.
137	16	• Evaluation Metric: The performance is evaluated using standard Accuracy and Macro-F1.
150	16	Table 2 summarizes the experimental results of all the approaches above, and we can find that: (1) All LSTM-based approaches are superior to SVM, indicating the effectiveness of neural network for this task.
152	17	(3) When only employing QA bidirectional matching mechanism, Bidirectional-Match QA, which takes the sentence segmentation strategy, consistently outperforms Bidirectional-Match (without sentence segmentation) in all domains.
153	15	It confirms our hypothesis that sentence segmentation helps to extract the sentiment matching information between the question and answer.
154	31	(4) When comparing to QA unidirectional matching mechanism, Bidirectional-Match QA, which employs QA bidirectional matching mechanism, performs better than AtoQMatch and QtoA-Match.
155	20	It confirms our hypothesis that both the question and answer information contribute to sentiment polarity of the QA text pair.
157	44	It verifies the advantages of both QA bidirectional matching mechanism and selfmatching attention mechanism for this task.
171	22	This is a unique challenge for QA-style sentiment mining, and traditional sentiment classification approaches can hardly address this problem.
172	20	(2) The proposed approach (HMN) performs better than other approaches when dealing with conflict instances, as shown in E10.
176	35	From Figure 4, we can see that the QA bidirectional matching layer always assigns reasonable attention weights to words in each [Q-sentence, Asentence] unit which makes sentence from question and sentence from answer match correctly.
179	34	The dataset is shared to encourage other scholars to investigate this interesting problem.
180	17	Moreover, we propose a hierarchical matching neural network model to enable QA bidirectional matching mechanism and self-matching attention mechanism for this task.
181	32	Empirical studies show that the proposed approach significantly outperforms other strong baseline approaches in all the test domains for QA-style sentiment classification.
182	64	In the future, we would like to investigate some other network structures to explore deeper information in each QA text pair.

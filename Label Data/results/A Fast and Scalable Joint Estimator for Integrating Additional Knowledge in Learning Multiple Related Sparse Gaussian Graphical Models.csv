0,1,label2,summary_sentences
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 1938–1947 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
1938",text,[0],[0]
"The explicit modeling of morphology has been shown to improve a number of tasks (Seeker and Çetinoglu, 2015; Luong et al., 2013).",1 Introduction,[0],[0]
"In a large number of the world’s languages, many words are composed through morphological operations on subword units.",1 Introduction,[0],[0]
"Some languages are rich in inflectional morphology, characterized by syntactic transformations like pluralization.",1 Introduction,[0],[0]
"Similarly, languages like English are rich in derivational morphology, where the semantics of words are composed from
∗These authors contributed equally; listed alphabetically.
smaller parts.",1 Introduction,[0],[0]
"The AGENT derivational transformation, for example, answers the question, what is the word for ‘someone who runs’?",1 Introduction,[0],[0]
"with the answer, a runner.1 Here, AGENT is spelled out as suffixing -ner onto the root verb run.
",1 Introduction,[0],[0]
We tackle the task of derived word generation.,1 Introduction,[0],[0]
"In this task, a root word x and a derivational transformation t are given to the learner.",1 Introduction,[0],[0]
"The learner’s job is to produce the result of the transformation on the root word, called the derived word y. Table 1 gives examples of these transformations.
",1 Introduction,[0],[0]
"Previous approaches to derived word generation model the task as a character-level sequenceto-sequence (seq2seq) problem (Cotterell et al., 2017b).",1 Introduction,[0],[0]
"The letters from the root word and some encoding of the transformation are given as input to a neural encoder, and the decoder is trained to produce the derived word, one letter at a time.",1 Introduction,[0],[0]
"We identify the following problems with these approaches:
First, because these models are unconstrained, they can generate sequences of characters that do
1We use the verb run as a demonstrative example; the transformation can be applied to most verbs.
",1 Introduction,[0],[0]
not form actual words.,1 Introduction,[0],[0]
"We argue that requiring the model to generate a known word is a reasonable constraint in the special case of English derivational morphology, and doing so avoids a large number of common errors.
",1 Introduction,[0],[0]
"Second, sequence-based models can only generalize string manipulations (such as “add -ment”) if they appear frequently in the training data.",1 Introduction,[0],[0]
"Because of this, they are unable to generate derived words that do not follow typical patterns, such as generating truth as the nominative derivation of true.",1 Introduction,[0],[0]
We propose to learn a function for each transformation in a low dimensional vector space that corresponds to mapping from representations of the root word to the derived word.,1 Introduction,[0],[0]
"This eliminates the reliance on orthographic information, unlike related approaches to distributional semantics, which operate at the suffix level (Gupta et al., 2017).
",1 Introduction,[0],[0]
"We contribute an aggregation model of derived word generation that produces hypotheses independently from two separate learned models: one from a seq2seq model with only orthographic information, and one from a feed-forward network using only distributional semantic information in the form of pretrained word vectors.",1 Introduction,[0],[0]
The model learns to choose between the hypotheses according to the relative confidence of each.,1 Introduction,[0],[0]
This system can be interpreted as learning to decide between positing an orthographically regular form or a semantically salient word.,1 Introduction,[0],[0]
"See Figure 1 for a diagram of our model.
",1 Introduction,[0],[0]
"We show that this model helps with two open problems with current state-of-the-art seq2seq derived word generation systems, suffix ambiguity and orthographic irregularity (Section 2).",1 Introduction,[0],[0]
"We also
improve the accuracy of seq2seq-only derived word systems by adding external information through constrained decoding and hypothesis rescoring.",1 Introduction,[0],[0]
"These methods provide orthogonal gains to our main contribution.
",1 Introduction,[0],[0]
"We evaluate models in two categories: open vocabulary models that can generate novel words unattested in a preset vocabulary, and closedvocabulary models, which cannot.",1 Introduction,[0],[0]
Our best openvocabulary and closed-vocabulary models demonstrate 22% and 37% relative error reductions over the current state of the art.,1 Introduction,[0],[0]
Derivational transformations generate novel words that are semantically composed from the root word and the transformation.,2 Background: Derivational Morphology,[0],[0]
"We identify two unsolved problems in derived word transformation, each of which we address in Sections 3 and 4.
",2 Background: Derivational Morphology,[0],[0]
"First, many plausible choices of suffix for a single pair of root word and transformation.",2 Background: Derivational Morphology,[0],[0]
"For example, for the verb ground, the RESULT transformation could plausibly take as many forms as2
(ground, RESULT)→ grounding (ground, RESULT)→ *groundation (ground, RESULT)→ *groundment (ground, RESULT)→ *groundal
However, only one is correct, even though each suffix appears often in the RESULT transformation of other words.",2 Background: Derivational Morphology,[0],[0]
"We will refer to this problem as “suffix ambiguity.”
",2 Background: Derivational Morphology,[0],[0]
"Second, many derived words seem to lack a generalizable orthographic relationship to their root words.",2 Background: Derivational Morphology,[0],[0]
"For example, the RESULT of the verb speak is speech.",2 Background: Derivational Morphology,[0],[0]
"It is unlikely, given an orthographically similar verb creak, that the RESULT be creech instead of, say, creaking.",2 Background: Derivational Morphology,[0],[0]
Seq2seq models must grapple with the problem of derived words that are the result of unlikely or potentially unseen string transformations.,2 Background: Derivational Morphology,[0],[0]
We refer to this problem as “orthographic irregularity.”,2 Background: Derivational Morphology,[0],[0]
"In this section, we introduce the prior state-of-theart model, which serves as our baseline system.",3 Sequence Models and Corpus Knowledge,[0],[0]
"Then we build on top of this system by incorporating a dictionary constraint and rescoring the
2The * indicates a non-word.
model’s hypotheses with token frequency information to address the suffix ambiguity problem.",3 Sequence Models and Corpus Knowledge,[0],[0]
We begin by formalizing the problem and defining some notation.,3.1 Baseline Architecture,[0],[0]
"For source word x = x1, x2, . . .",3.1 Baseline Architecture,[0],[0]
"xm, a derivational transformation t, and target word y = y1, y2, . . .",3.1 Baseline Architecture,[0],[0]
"yn, our goal is to learn some function from the pair (x, t) to y. Here, xi and yj are the ith and jth characters of the input strings x and y.",3.1 Baseline Architecture,[0],[0]
"We will sometimes use x1:i to denote x1, x2, . . .",3.1 Baseline Architecture,[0],[0]
"xi, and similarly for y1:j .
",3.1 Baseline Architecture,[0],[0]
"The current state-of-the-art model for derivedform generation approaches this problem by learning a character-level encoder-decoder neural network with an attention mechanism (Cotterell et al., 2017b; Bahdanau et al., 2014).
",3.1 Baseline Architecture,[0],[0]
"The input to the bidirectional LSTM encoder (Hochreiter and Schmidhuber, 1997; Graves and Schmidhuber, 2005) is the sequence #, x1, x2, . . .",3.1 Baseline Architecture,[0],[0]
"xm, #, t, where # is a special symbol to denote the start and end of a word, and the encoding of the derivational transformation t is concatenated to the input characters.",3.1 Baseline Architecture,[0],[0]
The model is trained to minimize the cross entropy of the training data.,3.1 Baseline Architecture,[0],[0]
"We refer to our reimplementation of this model as SEQ.
",3.1 Baseline Architecture,[0],[0]
"For a more detailed treatment of neural sequenceto-sequence models with attention, we direct the reader to Luong et al. (2015).",3.1 Baseline Architecture,[0],[0]
The suffix ambiguity problem poses challenges for models which rely exclusively on input characters for information.,3.2 Dictionary Constraint,[0],[0]
"As previously demonstrated, words derived via the same transformation may take different suffixes, and it is hard to select among them based on character information alone.",3.2 Dictionary Constraint,[0],[0]
"Here, we describe a process for restricting our inference procedure to only generate known English words, which we call a dictionary constraint.",3.2 Dictionary Constraint,[0],[0]
"We believe that for English morphology, a large enough corpus will contain the vast majority of derived forms, so while this approach is somewhat restricting, it removes a significant amount of ambiguity from the problem.
",3.2 Dictionary Constraint,[0],[0]
"To describe how we implemented this dictionary constraint, it is useful first to discuss how decoding in a seq2seq model is equivalent to solving a shortest path problem.",3.2 Dictionary Constraint,[0],[0]
"The notation is specific to our model, but the argument is applicable to seq2seq models in general.
",3.2 Dictionary Constraint,[0],[0]
"The goal of decoding is to find the most probable structure ŷ conditioned on some observation x and transformation t. That is, the problem is to solve
ŷ =",3.2 Dictionary Constraint,[0],[0]
"argmax y∈Y
p(y | x, t) (1)
= argmin y∈Y − log p(y | x, t) (2)
where Y is the set of valid structures.",3.2 Dictionary Constraint,[0],[0]
"Sequential models have a natural ordering y = y1, y2, . . .",3.2 Dictionary Constraint,[0],[0]
"yn over which − log p(y | x, t) can be decomposed
− log p(y | x, t) = n∑
t=1
− log p(yt | y1:t−1,x, t)
(3)",3.2 Dictionary Constraint,[0],[0]
Solving Equation 2 can be viewed as solving a shortest path problem from a special starting state to a special ending state via some path which uniquely represents y.,3.2 Dictionary Constraint,[0],[0]
Each vertex in the graph represents some sequence y1,3.2 Dictionary Constraint,[0],[0]
":i, and the weight of the edge from y1:i to y1:i+1 is given by
− log p(yi+1 | y1:i−1,x, t) (4)
",3.2 Dictionary Constraint,[0],[0]
The weight of the path from the start state to the end state via the unique path that describes y is exactly equal to Equation 3.,3.2 Dictionary Constraint,[0],[0]
"When the vocabulary size is too large, the exact shortest path is intractable, and approximate search methods, such as beam search, are used instead.
",3.2 Dictionary Constraint,[0],[0]
"In derived word generation, Y is an infinite set of strings.",3.2 Dictionary Constraint,[0],[0]
"Since Y is unrestricted, almost all of the strings in Y are not valid words.",3.2 Dictionary Constraint,[0],[0]
"Given a dictionary YD, the search space is restricted to only those words in the dictionary by searching over the trie induced from YD, which is a subgraph of the unrestricted graph.",3.2 Dictionary Constraint,[0],[0]
"By limiting the search space to YD, the decoder is guaranteed to generate some known word.",3.2 Dictionary Constraint,[0],[0]
Models which use this dictionaryconstrained inference procedure will be labeled with +DICT.,3.2 Dictionary Constraint,[0],[0]
"Algorithm 1 has the pseudocode for our decoding procedure.
",3.2 Dictionary Constraint,[0],[0]
We discuss specific details of the search procedure and interesting observations of the search space in Section 6.,3.2 Dictionary Constraint,[0],[0]
Section 5.2 describes how we obtained the dictionary of valid words.,3.2 Dictionary Constraint,[0],[0]
"We also consider the inclusion of explicit word frequency information to help solve suffix ambiguity, using the intuition that “real” derived words
are likely to be frequently attested.",3.3 Word Frequency Knowledge through Rescoring,[0],[0]
"This permits a high-recall, potentially noisy dictionary.
",3.3 Word Frequency Knowledge through Rescoring,[0],[0]
"We are motivated by very high top-10 accuracy compared to top-1 accuracy, even among dictionary-constrained models.",3.3 Word Frequency Knowledge through Rescoring,[0],[0]
"By rescoring the hypotheses of a model using word frequency (a word-global signal) as a feature, attempt to recover a portion of this top-10 accuracy.
",3.3 Word Frequency Knowledge through Rescoring,[0],[0]
"When a model has been trained, we query it for its top-10 most likely hypotheses.",3.3 Word Frequency Knowledge through Rescoring,[0],[0]
The union of all hypotheses for a subset of the training observations forms the training set for a classifier that learns to predict whether a hypothesis generated by the model is correct.,3.3 Word Frequency Knowledge through Rescoring,[0],[0]
"Each hypothesis is labelled with its correctness, a value in {±1}.",3.3 Word Frequency Knowledge through Rescoring,[0],[0]
"We train a simple combination of two scores: the seq2seq model score for the hypothesis, and the log of the word frequency of the hypothesis.
",3.3 Word Frequency Knowledge through Rescoring,[0],[0]
"To permit a nonlinear combination of word frequency and model score, we train a small multilayer perceptron with the model score and the frequency of a derived word hypothesis as features.
",3.3 Word Frequency Knowledge through Rescoring,[0],[0]
"At testing time, the 10 hypotheses generated by a single seq2seq model for a single observation are rescored.",3.3 Word Frequency Knowledge through Rescoring,[0],[0]
"The new model top-1 hypothesis, then, is the argmax over the 10 hypotheses according to the rescorer.",3.3 Word Frequency Knowledge through Rescoring,[0],[0]
"In this way, we are able to incorporate word-global information, e.g. word frequency, that is ill-suited for incorporation at each character prediction step of the seq2seq model.",3.3 Word Frequency Knowledge through Rescoring,[0],[0]
We label models that are rescored in this way +FREQ.,3.3 Word Frequency Knowledge through Rescoring,[0],[0]
"So far, we have presented models that learn derivational transformations as orthographic operations.",4 Distributional Models,[0],[0]
"Such models struggle by construction with the orthographic irregularity problem, as they are trained to generalize orthographic information.",4 Distributional Models,[0],[0]
"However, the semantic relationships between root words and derived words are the same even when the orthography is dissimilar.",4 Distributional Models,[0],[0]
"It is salient, for example, that irregular word speech is related to its root speak in about the same way as how exploration is related to the word explore.
",4 Distributional Models,[0],[0]
"We model distributional transformations as functions in dense distributional word embedding spaces, crucially learning a function per derivational transformation, not per suffix pair.",4 Distributional Models,[0],[0]
"In this way, we aim to explicitly model the semantic transformation, not the othographic information.",4 Distributional Models,[0],[0]
"For all source words x and all target words y, we look up static distributional embeddings vx, vy ∈ Rd.",4.1 Feed-forward derivational transformations,[0],[0]
"For each derivational transformation t, we learn a function ft : Rd → Rd that maps vx to vy.",4.1 Feed-forward derivational transformations,[0],[0]
"ft is parametrized as two-layer perceptron, trained using a squared loss,
L = bTb (5) b =",4.1 Feed-forward derivational transformations,[0],[0]
"ft(vx)− vy (6)
We perform inference by nearest neighbor search in the embedding space.",4.1 Feed-forward derivational transformations,[0],[0]
"This inference strategy requires a subset of strings for our embedding dictionary, YV .
",4.1 Feed-forward derivational transformations,[0],[0]
"Upon receiving (x, t) at test time, we compute ft(vx) and find the most similar embeddings in YV .",4.1 Feed-forward derivational transformations,[0],[0]
"Specifically, we find the top-k most similar embeddings, and take the most similar derived word that starts with the same 4 letters as the root word, and is not identical to it.",4.1 Feed-forward derivational transformations,[0],[0]
"This heuristic filters out highly implausible hypotheses.
",4.1 Feed-forward derivational transformations,[0],[0]
"We use the single-word subset of the Google News vectors (Mikolov et al., 2013) as YV , so the size of the vocabulary is 929k words.",4.1 Feed-forward derivational transformations,[0],[0]
The seq2seq and distributional models we have presented learn with disjoint information to solve separate problems.,4.2 SEQ and DIST Aggregation,[0],[0]
"We leverage this intuition to build a model that chooses, for each observation, whether to generate according to orthographic information via the SEQ model, or produce a potentially irregular form via the DIST model.
",4.2 SEQ and DIST Aggregation,[0],[0]
"To train this model, we use a held-out portion of the training set, and filter it to only observations for which exactly one of the two models produces the correct derived form.",4.2 SEQ and DIST Aggregation,[0],[0]
"Finally, we make the strong assumption that the probability of a derived form being generated correctly according to 1 model as opposed to the other is dependent only on the unnormalized model score from each.",4.2 SEQ and DIST Aggregation,[0],[0]
"We model this as a logistic regression (t is omitted for clarity):
P (·|yD,yS,x) = softmax(We [DIST(yD|x); SEQ(yS|x)]",4.2 SEQ and DIST Aggregation,[0],[0]
"+ be)
where We and be are learned parameters, yD and yS are the hypotheses of the distributional and seq2seq models, and DIST(·) and SEQ(·) are the models’ likelihood functions.",4.2 SEQ and DIST Aggregation,[0],[0]
We denote this aggregate AGGR in our results.,4.2 SEQ and DIST Aggregation,[0],[0]
In this section we describe the derivational morphology dataset used in our experiments and how we collected the dictionary and token frequencies used in the dictionary constraint and rescorer.,5 Datasets,[0],[0]
"In our experiments, we use the derived word generation derivational morphology dataset released in Cotterell et al. (2017b).",5.1 Derivational Morphology,[0],[0]
"The dataset, derived from NomBank (Meyers et al., 2004) , consists of 4,222 training, 905 validation, and 905 test triples of the form (x, t,y).",5.1 Derivational Morphology,[0],[0]
"The transformations are from the following categories: ADVERB (ADJ→ ADV), RESULT (V→ N), AGENT (V→ N), and NOMINAL (ADJ→ N).",5.1 Derivational Morphology,[0],[0]
Examples from the dataset can be found in Table 1.,5.1 Derivational Morphology,[0],[0]
"The dictionary and token frequency statistics used in the dictionary constraint and frequency reranking come from the Google Books NGram corpus (Michel et al., 2011).",5.2 Dictionary and Token Frequency Statistics,[0],[0]
"The unigram frequency counts were aggregated across years, and any tokens which appear fewer than approximately 2,000 times, do not end in a known possible suffix, or contain a character outside of our vocabulary were removed.
",5.2 Dictionary and Token Frequency Statistics,[0],[0]
"The frequency threshold was determined using development data, optimizing for high recall.",5.2 Dictionary and Token Frequency Statistics,[0],[0]
We collect a set of known suffixes from the training data by removing the longest common prefix between the source and target words from the target word.,5.2 Dictionary and Token Frequency Statistics,[0],[0]
"The result is a dictionary with frequency information for around 360k words, which covers 98% of the target words in the training data.3",5.2 Dictionary and Token Frequency Statistics,[0],[0]
"In many sequence models where the vocabulary size is large, exact inference by finding the true shortest path in the graph discussed in Section 3.2 is intractable.",6 Inference Procedure Discussion,[0],[0]
"As a result, approximate inference techniques such as beam search are often used, or the size of the search space is reduced, for example, by using a Markov assumption.",6 Inference Procedure Discussion,[0],[0]
"We, however, observed that exact inference via a shortest path algorithm is not only tractable in our model, but
3 The remaining 2% is mostly words with hyphens or mistakes in the dataset.
only slightly more expensive than greedy search and significantly less expensive than beam search.
",6 Inference Procedure Discussion,[0],[0]
"To quantify this claim, we measured the accuracy and number of states explored by greedy search, beam search, and shortest path with and without a dictionary constraint on the development data.",6 Inference Procedure Discussion,[0],[0]
Table 2 shows the results averaged over 30 runs.,6 Inference Procedure Discussion,[0],[0]
"As expected, beam search and shortest path have higher accuracies than greedy search and explore more of the search space.",6 Inference Procedure Discussion,[0],[0]
"Surprisingly, beam search and shortest path have nearly identical accuracies, but shortest path explores significantly fewer hypotheses.
",6 Inference Procedure Discussion,[0],[0]
At least two factors contribute to the tractability of exact search in our model.,6 Inference Procedure Discussion,[0],[0]
"First, our characterlevel sequence model has a vocabulary size of 63, which is significantly smaller than token-level models, in which a vocabulary of 50k words is not uncommon.",6 Inference Procedure Discussion,[0],[0]
"The search space of sequence models is dependent upon the size of the vocabulary, so the model’s search space is dramatically smaller than for a token-level model.
",6 Inference Procedure Discussion,[0],[0]
"Second, the inherent structure of the task makes it easy to eliminate large subgraphs of the search space.",6 Inference Procedure Discussion,[0],[0]
"The first several characters of the input word and output word are almost always the same, so the model assigns very low probability to any sequence with different starting characters than the input.",6 Inference Procedure Discussion,[0],[0]
"Then, the rest of the search procedure is dedicated to deciding between suffixes.",6 Inference Procedure Discussion,[0],[0]
"Any suffix which does not appear frequently in the training data receives a low score, leaving the search to decide between a handful of possible options.",6 Inference Procedure Discussion,[0],[0]
The result is that the learned probability distribution is very spiked; it puts very high probability on just a few output sequences.,6 Inference Procedure Discussion,[0],[0]
"It is empirically true that the top few most probable sequences have significantly higher scores than the next most probable sequences, which supports this hypothesis.
",6 Inference Procedure Discussion,[0],[0]
"In our subsequent experiments, we decode using
Algorithm 1 The decoding procedure uses a shortest-path algorithm to find the most probable output sequence.",6 Inference Procedure Discussion,[0],[0]
"The dictionary constraint is (optionally) implemented on line 9 by only considering prefixes that are contained in some trie T .
1: procedure DECODE(x, t, V , T ) 2: H ← Heap() 3: H .insert(0, #) 4: while H is not empty",6 Inference Procedure Discussion,[0],[0]
do 5: y← H .remove() 6: if y is a complete word then return y 7: for y ∈ V do 8: y′,6 Inference Procedure Discussion,[0],[0]
"← y + y 9: if y′ ∈ T then
10: s← FORWARD(x, t,y′) 11: H .insert(s, y′)
exact inference by running a shortest path algorithm (see Algorithm 1).",6 Inference Procedure Discussion,[0],[0]
"For reranking models, instead of typically using a beam of size k, we use the top k most probable sequences.",6 Inference Procedure Discussion,[0],[0]
"In all of our experiments, we use the training, development, and testing splits provided by Cotterell et al. (2017b) and average over 30 random restarts.",7 Results,[0],[0]
"Table 3 displays the accuracies and average edit distances on the test set of each of the systems presented in this work and the state-of-the-art model from Cotterell et al. (2017b).
",7 Results,[0],[0]
"First, we observed that SEQ outperforms the results reported in Cotterell et al. (2017b) by a large margin, despite the fact that the model architectures are the same.",7 Results,[0],[0]
"We attribute this difference to better hyperparameter settings and improved learning rate annealing.
",7 Results,[0],[0]
"Then, it is clear that the accuracy of the distributional model, DIST, is significantly lower than any seq2seq model.",7 Results,[0],[0]
"We believe the orthographyinformed models perform better because most observations in the dataset are orthographically regular, providing low-hanging fruit.
",7 Results,[0],[0]
"Open-vocabulary models Our open-vocabulary aggregation model AGGR improves performance by 3.8 points accuracy over SEQ, indicating that the sequence models and the distributional model are contributing complementary signals.",7 Results,[0],[0]
"AGGR is an open-vocabulary model like Cotterell et al. (2017b) and improves upon it by 6.3 points, making it our best comparable model.",7 Results,[0],[0]
"We provide an in-
depth analysis of the strengths of SEQ and DIST in Section 7.1.
",7 Results,[0],[0]
Closed-vocabulary models We now consider closed-vocabulary models that improve upon the seq2seq model in AGGR.,7 Results,[0],[0]
"First, we see that restricting the decoder to only generate known words is extremely useful, with SEQ+DICT improving over SEQ by 6.2 points.",7 Results,[0],[0]
"Qualitatively, we note that this constraint helps solve the suffix ambiguity problem, since orthographically plausible incorrect hypotheses are pruned as non-words.",7 Results,[0],[0]
See Table 6 for examples of this phenomenon.,7 Results,[0],[0]
"Additionally, we observe that the dictionary-constrained model outperforms the unconstrained model according to top-10 accuracy (see Table 5).
",7 Results,[0],[0]
"Rescoring (+FREQ) provides further improvement of 0.8 points, showing that the decoding dictionary constraint provides a higher-quality beam that still has room for top-1 improvement.",7 Results,[0],[0]
"All together, AGGR+FREQ+DICT provides a 4.4 point improvement over the best open-vocabulary model, AGGR.",7 Results,[0],[0]
"This shows the disambiguating power of assuming a closed vocabulary.
",7 Results,[0],[0]
Edit Distance One interesting side effect of the dictionary constraint appears when comparing AGGR+FREQ with and without the dictionary constraint.,7 Results,[0],[0]
"Although the accuracy of the dictionaryconstrained model is better, the average edit distance is worse.",7 Results,[0],[0]
"The unconstrained model is free to put invalid words which are orthographically similar to the target word in its top-k, however the constrained model can only choose valid words.",7 Results,[0],[0]
"This means it is easier for the unconstrained model to generate words which have a low edit distance to the ground truth, whereas the constrained model
can only do that if such a word exists.",7 Results,[0],[0]
"The result is a more accurate, yet more orthographically diverse, set of hypotheses.
",7 Results,[0],[0]
"Results by Transformation Next, we compare our best open vocabulary and closed vocabulary models to previous work across each derivational transformation.",7 Results,[0],[0]
"These results are in Table 4.
",7 Results,[0],[0]
"The largest improvement over the baseline system is for NOMINAL transformations, in which the AGGR has a 49% reduction in error.",7 Results,[0],[0]
We attribute most of this gain to the difficulty of this particular transformation.,7 Results,[0],[0]
"NOMINAL is challenging because there are several plausible endings (e.g. -ity, -ness, -ence) which occur at roughly the same rate.",7 Results,[0],[0]
"Additionally, NOMINAL examples are the least frequent transformation in the dataset, so it is challenging for a sequential model to learn to generalize.",7 Results,[0],[0]
"The distributional model, which does not rely on suffix information, does not have this same weakness, so the aggregation AGGR model has better results.
",7 Results,[0],[0]
"The performance of AGGR+FREQ+DICT is worse than AGGR, however.",7 Results,[0],[0]
"This is surprising because, in all other transformations, adding dictionary information improves the accuracies.",7 Results,[0],[0]
"We believe this is due to the ambiguity of the ground truth: Many root words have seemingly multiple plausible nominal transformations, such as rigid → {rigidness, rigidity} and equivalent → {equivalence, equivalency}.",7 Results,[0],[0]
"The dictionary constraint produces a better set of hypotheses to rescore, as demonstrated in Table 5.",7 Results,[0],[0]
"Therefore, the dictionary-constrained model is likely to have more of these ambiguous cases, which makes the task more difficult.",7 Results,[0],[0]
In this subsection we explore why AGGR improves consistently over SEQ even though it maintains an open vocabulary.,7.1 Strengths of SEQ and DIST,[0],[0]
"We have argued that DIST is able to correctly produce derived words that are
orthographically irregular or infrequent in the training data.",7.1 Strengths of SEQ and DIST,[0],[0]
"Figure 2 quantifies this phenomenon, analyzing the difference in accuracy between the two models, and plotting this in relationship to the frequency of the suffix in the training data.",7.1 Strengths of SEQ and DIST,[0],[0]
"The plot shows that SEQ excels at generating derived words ending in -ly, -ion, and other suffixes that appeared frequently in the training data.",7.1 Strengths of SEQ and DIST,[0],[0]
"DIST’s improvements over SEQ are generally much less frequent in the training data, or as in the case of -ment, are less frequent than other suffixes for the same transformation (like -ion.)",7.1 Strengths of SEQ and DIST,[0],[0]
"By producing derived words whose suffixes show up rarely in the training data, DIST helps solve the orthographic irregularity problem.",7.1 Strengths of SEQ and DIST,[0],[0]
"There has been much work on the related task of inflected word generation (Durrett and DeNero,
2013; Rastogi et al., 2016; Hulden et al., 2014).",8 Prior Work,[0],[0]
"It is a structurally similar task to ours, but does not have the same difficulty of challenges (Cotterell et al., 2017a,b), which we have addressed in our work.",8 Prior Work,[0],[0]
The paradigm completion for derivational morphology dataset we use in this work was introduced in Cotterell et al. (2017b).,8 Prior Work,[0],[0]
"They apply the model that won the 2016 SIGMORPHON shared task on inflectional morphology to derivational morphology (Kann and Schütze, 2016; Cotterell et al., 2016).",8 Prior Work,[0],[0]
"We use this as our baseline.
",8 Prior Work,[0],[0]
Our implementation of the dictionary constraint is an example of a special constraint which can be directly incorporated into the inference algorithm at little additional cost.,8 Prior Work,[0],[0]
"Roth and Yih (2004, 2007) propose a general inference procedure that naturally incorporates constraints through recasting inference as solving an integer linear program.
Beam or hypothesis rescoring to incorporate an expensive or non-decomposable signal into search has a history in machine translation (Huang and Chiang, 2007).",8 Prior Work,[0],[0]
"In inflectional morphology, Nicolai et al. (2015) use this idea to rerank hypotheses using orthographic features and Faruqui et al. (2016) use a character-level language model.",8 Prior Work,[0],[0]
"Our approach is similar to Faruqui et al. (2016) in that we use statistics from a raw corpus, but at the token level.
",8 Prior Work,[0],[0]
There have been several attempts to use distributional information in morphological generation and analysis.,8 Prior Work,[0],[0]
"Soricut and Och (2015) collect pairs of words related by any morphological change in an unsupervised manner, then select a vector offset which best explains their observations.",8 Prior Work,[0],[0]
"There has been subsequent work exploring the vector offset method, finding it unsuccessful in captur-
ing derivational transformations (Gladkova et al., 2016).",8 Prior Work,[0],[0]
"However, we use more expressive, nonlinear functions to model derivational transformations and report positive results.",8 Prior Work,[0],[0]
Gupta et al. (2017) then learn a linear transformation per orthographic rule to solve a word analogy task.,8 Prior Work,[0],[0]
"Our distributional model learns a function per derivational transformation, not per orthographic rule, which allows it to generalize to unseen orthography.",8 Prior Work,[0],[0]
"Our models are implemented in Python using the DyNet deep learning library (Neubig et al., 2017).",9 Implementation Details,[0],[0]
"The code is freely available for download.4
Sequence Model The sequence-to-sequence model uses character embeddings of size 20, which are shared across the encoder and decoder, with a vocabulary size of 63.",9 Implementation Details,[0],[0]
"The hidden states of the LSTMs are of size 40.
",9 Implementation Details,[0],[0]
"For training, we use Adam with an initial learning rate of 0.005, a batch size of 5, and train for a maximum of 30 epochs.",9 Implementation Details,[0],[0]
"If after one epoch of the training data, the loss on the validation set does not decrease, we anneal the learning rate by half and revert to the previous best model.
",9 Implementation Details,[0],[0]
"During decoding, we find the top 1 most probable sequence as discussed in Section 6 unless rescoring is used, in which we use the top 10.
",9 Implementation Details,[0],[0]
Rescorer The rescorer is a 1-hidden-layer perceptron with a tanh nonlinearity and 4 hidden units.,9 Implementation Details,[0],[0]
"It is trained for a maximum of 5 epochs.
",9 Implementation Details,[0],[0]
Distributional Model,9 Implementation Details,[0],[0]
"The DIST model is a 1- hidden-layer perceptron with a tanh nonlinearity
4https://github.com/danieldeutsch/ acl2018
and 100 hidden units.",9 Implementation Details,[0],[0]
It is trained for a maximum of 25 epochs.,9 Implementation Details,[0],[0]
"In this work, we present a novel aggregation model for derived word generation.",10 Conclusion,[0],[0]
This model learns to choose between the predictions of orthographicallyand distributionally-informed models.,10 Conclusion,[0],[0]
"This ameliorates suffix ambiguity and orthographic irregularity, the salient problems of the generation task.",10 Conclusion,[0],[0]
"Concurrently, we show that derivational transformations can be usefully modeled as nonlinear functions on distributional word embeddings.",10 Conclusion,[0],[0]
"The distributional and orthographic models aggregated contribute orthogonal information to the aggregate, as shown by substantial improvements over state-of-the-art results, and qualitative analysis.",10 Conclusion,[0],[0]
Two ways of incorporating corpus knowledge – constrained decoding and rescoring – demonstrate further improvements to our main contribution.,10 Conclusion,[0],[0]
"We would like to thank Shyam Upadhyay, Jordan Kodner, and Ryan Cotterell for insightful discussions about derivational morphology.",Acknowledgements,[0],[0]
"We would also like to thank our anonymous reviewers for helpful feedback on clarity and presentation.
",Acknowledgements,[0],[0]
This work was supported by Contract HR001115-2-0025 with the US Defense Advanced Research Projects Agency (DARPA).,Acknowledgements,[0],[0]
"Approved for Public Release, Distribution Unlimited.",Acknowledgements,[0],[0]
The views expressed are those of the authors and do not reflect the official policy or position of the Department of Defense or the U.S. Government.,Acknowledgements,[0],[0]
"Modeling derivational morphology to generate words with particular semantics is useful in many text generation tasks, such as machine translation or abstractive question answering.",abstractText,[0],[0]
"In this work, we tackle the task of derived word generation.",abstractText,[0],[0]
"That is, given the word “run,” we attempt to generate the word “runner” for “someone who runs.”",abstractText,[0],[0]
We identify two key problems in generating derived words from root words and transformations: suffix ambiguity and orthographic irregularity.,abstractText,[0],[0]
We contribute a novel aggregation model of derived word generation that learns derivational transformations both as orthographic functions using sequence-to-sequence models and as functions in distributional word embedding space.,abstractText,[0],[0]
"Our best open-vocabulary model, which can generate novel words, and our best closed-vocabulary model, show 22% and 37% relative error reductions over current state-of-the-art systems on the same dataset.",abstractText,[0],[0]
A Distributional and Orthographic Aggregation Model for English Derivational Morphology,title,[0],[0]
"One of the simplest Markov chain Monte Carlo (MCMC) methods is Langevin dynamics (Grenander & Miller, 1994; Robert & Casella, 2004, Sec. 7.8.5) where one repeats gradient steps with injected Gaussian noise.",1. Introduction,[0],[0]
"Namely, one iterates
z z + ✏ 2 rz log p(z) + p ✏⌘, (1)
where ⌘ is sampled from a standard Gaussian distribution and ✏ is a step-size that may decay over time.",1. Introduction,[0],[0]
"To get exact samples, a Metropolis-Hastings rejection step should be used.",1. Introduction,[0],[0]
"However, as the step-size ✏ becomes smaller, the acceptance probability goes to one, and so this can be disregarded.",1. Introduction,[0],[0]
"In the Bayesian inference setting, z denotes unknown parameters and p(z) represents a posterior over
1College of Computing and Information Sciences, University of Massachusetts, Amherst, USA.",1. Introduction,[0],[0]
"Correspondence to: Justin Domke <domke@cs.umass.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
them.",1. Introduction,[0],[0]
Computing p(z) thus requires a full pass over the dataset.,1. Introduction,[0],[0]
"The idea of Stochastic Gradient Langevin Dynamics (Welling & Teh, 2011) is to get an unbiased estimate of the gradient of log p(z) by approximating the posterior using a minibatch.",1. Introduction,[0],[0]
"Since the gradient term is multiplied by ✏, the variance of its error has order ✏2, while the variance of p ✏⌘ has order ✏.",1. Introduction,[0],[0]
"Thus, with a small step ✏, the injected noise dominates, meaning one can might expect these to have a stationary distribution close to the target p(z).
",1. Introduction,[0],[0]
The idea of variational inference is to posit a simple family of distributions qw(z) and then optimize w to minimize the KL-divergence from qw(z) to the target p(z).,1. Introduction,[0],[0]
"(In a Bayesian setting, this is equivalent to maximizing the evidence lower bound.)",1. Introduction,[0],[0]
"If one were to use plain gradient ascent to perform this optimization, this leads to the iterate of
w w + ✏ 2 rwEqw(Z)[log",1. Introduction,[0],[0]
"p(Z) log qw(Z)], (2)
where the gradient step ✏ is divided by two for convenience, and may again decay over time.",1. Introduction,[0],[0]
"In practice, doing gradient ascent like this has two difficulties.",1. Introduction,[0],[0]
"First, in the Bayesian inference setting, computing log p(z) requires a full pass over the data.",1. Introduction,[0],[0]
This can be approximated without bias using a minibatch.,1. Introduction,[0],[0]
The second difficulty stems from the expectation of log p(z) with respect to qw(z) in Eq. 2.,1. Introduction,[0],[0]
The gradient of this expectation can be approximated in different ways using samples from qw(Z) (Section 3.2).,1. Introduction,[0],[0]
"Since this gives unbiased estimates of the gradient, stochastic optimization methods, such as stochastic gradient descent, will converge to a local optima when the step-size becomes small.
",1. Introduction,[0],[0]
"Intuitively, both MCMC and variational methods can be thought of as trying to find a high-probability region of log p(z), with different strategies to encourage entropy to get coverage of the distribution.",1. Introduction,[0],[0]
"In MCMC, entropy is created by randomness in the Markov chain, while in variational methods the KL-divergence directly measures the entropy of the variational distribution.",1. Introduction,[0],[0]
It is natural to think that hybrid methods might employ fractions of these two strategies.,1. Introduction,[0],[0]
This paper does so by defining a distribution over the parameters w of the approximating family q(z|w).,1. Introduction,[0],[0]
"This distribution q(w) is designed to minimize a bound on the KL-divergence of the resulting marginal distribution
q(z) to the target p(z).",1. Introduction,[0],[0]
"Intuitively, when defining q(w), there are two ways to encourage entropy, namely to give higher density to vectors w where q(Z|w) has high entropy or to encourage entropy over w itself.
",1. Introduction,[0],[0]
"Given a distribution q(w, z) and a target distribution p(z), this paper uses two bounds on the marginal divergence Dtrue = KL (q(Z)kp(Z)) .",1. Introduction,[0],[0]
"First, one can upper-bound by the conditional divergence D0 = KL (q(Z|W )kp(Z)).",1. Introduction,[0],[0]
"Second, one can “adjoin” some distribution p(w|z) to p(z), and bound Dtrue by the joint divergence D1 = KL (q(W,Z)kp(W,Z)).",1. Introduction,[0],[0]
"This paper takes a convex combination of these two bounds, i.e. uses the family of bounds D = (1 )D0 + D1 .",1. Introduction,[0],[0]
"For any between 0 and 1, the distribution q(w) is derived that minimizes this bound for fixed p and a fixed approximating family q(z|w) (Theorem 3).",1. Introduction,[0],[0]
"Then, one can sample from this distribution over w by (stochastic) Langevin dynamics.",1. Introduction,[0],[0]
"This turns out to lead to the iterate
w w +",1. Introduction,[0],[0]
"✏ 2
rw ⇣ Eqw [log p(Z) + ( 1) log qw(Z)]
+ log r(w) ⌘",1. Introduction,[0],[0]
"+ p ✏ ⌘, (3)
where r(w) is related to the adjoining distribution p(w|z) and may be thought of as a “base measure” 1 over the space of w. Of course, exactly computing this gradient is intractable in general, but the same strategies used for variational inference can be used to efficiently compute an un-
1To see why r is necessary, consider a reparameterization of w.",1. Introduction,[0],[0]
"In order for the marginal distribution q(z) to stay the same, the density of the base measure must be transformed corresponding to the reparameterization.",1. Introduction,[0],[0]
"Put another way, without r(w), the results of inference would depend on the parameterization of w, even with an arbitrarily small step-size.
biased estimate.
",1. Introduction,[0],[0]
"It can be shown that as ! 0, the solution concentrates in the optima of the variational optimization, and thus the sampling algorithm reduces to gradient ascent on the variational objective.",1. Introduction,[0],[0]
"Meanwhile, as will be discussed in Sections 2.3 and 5 it is best to make r a function of such that w with high entropy have less density when approaches 1.",1. Introduction,[0],[0]
"When this is true, then as ! 1, only w indexing highly concentrated distributions over z retain density, and so sampling from q(w) is essentially just a reparameterization of sampling from p(z), and the algorithm reduces to Langevin dynamics.
",1. Introduction,[0],[0]
"Thus, for the extreme cases of = 0 and = 1, this algorithm reduces to variational inference and Langevin dynamics, respectively.",1. Introduction,[0],[0]
"Informally, at these extremes, the algorithm is “fast but approximate” and “slow but accurate”.",1. Introduction,[0],[0]
"In the intermediate range, the algorithm exhibits new behavior with a fine-grained trade-off between speed and accuracy.",1. Introduction,[0],[0]
"Thus, this approach gives a smooth continuum of algorithms with different priorities of speed and accuracy.",1. Introduction,[0],[0]
This paper uses three notational conventions that are not universal.,1.1. Notation,[0],[0]
"First, the conditional probability q(z|w) will alternatively be written as qw(z) when convenient.",1.1. Notation,[0],[0]
"Second, A ' B indicates that A and B have the same expected value or (if A is a constant) that B is an unbiased estimator of A. Finally, upper and lower-cases indicate what terms are random variables in a KL-divergence.",1.1. Notation,[0],[0]
"So, KL (q(Z|w)kp(Z|w)) = Eq(Z|w) log (q(Z|w)/p(Z|w)) is the divergence between q(z|w) and p(z|w) for a fixed w, while KL (q(Z|W )kp(Z|W ))",1.1. Notation,[0],[0]
"=
Eq(W,Z) log (q(Z|W )/p(Z|W )) is a standard conditional divergence.",1.1. Notation,[0],[0]
"This section derives a few results from an information theoretic viewpoint, without any particular regard for form of the target distribution, or how one might sample from it.",2. Information Theoretic Results,[0],[0]
Proofs are given in the appendix.,2. Information Theoretic Results,[0],[0]
Let p(z) be the target distribution.,2.1. Preliminaries,[0],[0]
"For simplicity, z is treated here as a continuous variable, although the results in this section remain true if it is discrete.",2.1. Preliminaries,[0],[0]
"There is some fixed set of conditional distributions q(z|w), which may also be written as qw(z).",2.1. Preliminaries,[0],[0]
"In principle, one might like to know how to set q(w) such that the resulting marginal distribution over z, is close to p(z), as measured by the KLdivergence,
Dtrue = KL (q(Z)kp(Z))",2.1. Preliminaries,[0],[0]
"= Eq(Z) log q(Z)
p(Z) .",2.1. Preliminaries,[0],[0]
"(4)
This quantity is difficult to control directly, since the marginal q(z) typically cannot be evaluated in closed form.",2.1. Preliminaries,[0],[0]
"One bound comes from the conditional KL-divergence, as stated in the following Lemma.
",2.1. Preliminaries,[0],[0]
Lemma 1.,2.1. Preliminaries,[0],[0]
"The divergence from q(z) to p(z) is
KL (q(Z)kp(Z))",2.1. Preliminaries,[0],[0]
"= KL (q(Z|W )kp(Z))| {z } D0 Iq[W,Z],
(5) where D0 = Eq(W,Z) log (q(Z|W )/p(Z)) is the conditional divergence and Iq = KL (q(Z,W )kq(Z)q(W ))",2.1. Preliminaries,[0],[0]
"denotes mutual information under q.
A second bound comes from adjoining some distribution p(w|z) to p(z).",2.1. Preliminaries,[0],[0]
"Then, the following lemma is essentially just a re-statement of the chain rule for the KL-divergence (Cover & Thomas, 2006, Thm. 2.5.3).
",2.1. Preliminaries,[0],[0]
Lemma 2.,2.1. Preliminaries,[0],[0]
"The KL-divergence between q(z) and p(z) can be written as
KL(q(Z)kp(Z)))",2.1. Preliminaries,[0],[0]
"= KL (q(W,Z)kp(W,Z))| {z } D1
KL (q(W |Z)kp(W |Z)) .",2.1. Preliminaries,[0],[0]
"(6)
Since the mutual information in Eq. 5 and the conditional divergence on the right of Eq. 6 are both non-negative, both D0 and D1 are upper-bounds on Dtrue.",2.1. Preliminaries,[0],[0]
"Note that if p(w|z) = q(w), then D1 = D0, and so Lemma 1 follows from Lemma 2.",2.1. Preliminaries,[0],[0]
"This paper is based on convex combination of D0 and D1 , parameterized by some 2 [0, 1], namely
D = (1 )D0 + D1.",2.2. Divergence Bound and its Minimizer,[0],[0]
"(7)
Since D0 and D1 are upper-bounds, so is D .",2.2. Divergence Bound and its Minimizer,[0],[0]
"The following theorem gives the distribution q(w) to minimize D .
Theorem 3.",2.2. Divergence Bound and its Minimizer,[0],[0]
"For fixed values of and p(w|z), the distribution q(w) that minimizes D is
q⇤(w) = exp s(w) A) (8)
A = log
Z
w exp s(w)
s(w) = log p(w) KL (q(Z|w)kp(Z|w))
",2.2. Divergence Bound and its Minimizer,[0],[0]
"1 1 KL (q(Z|w)kp(Z)) .
",2.2. Divergence Bound and its Minimizer,[0],[0]
"Moreover, at q⇤, the objective value is D⇤ = A.
Since A is an upper-bound on the KLdivergence, A must be non-positive.",2.2. Divergence Bound and its Minimizer,[0],[0]
"This can also be seen directly, since it can be written as A = log R w p(w) exp( KL (q(Z|w)kp(Z|w))
1 1 KL (q(Z|w)kp(Z))), and the inner diver-
gences as well as 1 1 are non-negative.
",2.2. Divergence Bound and its Minimizer,[0],[0]
"To understand the connection of this bound to variational inference and MCMC, one can look at behavior where = 0 or where = 1.",2.2. Divergence Bound and its Minimizer,[0],[0]
"For the former case, one obtains a result closely related to the solution to the variational inference problem.",2.2. Divergence Bound and its Minimizer,[0],[0]
Remark 4.,2.2. Divergence Bound and its Minimizer,[0],[0]
In the limit where ! 0,2.2. Divergence Bound and its Minimizer,[0],[0]
"the divergence bound at the optimal q⇤ becomes
lim !0",2.2. Divergence Bound and its Minimizer,[0],[0]
D⇤ = infw KL (q(Z|w)kp(Z)) .,2.2. Divergence Bound and its Minimizer,[0],[0]
"(9)
Similarly, when ! 0, q⇤(w) concentrates at the minimizer(s) of this divergence.",2.2. Divergence Bound and its Minimizer,[0],[0]
"(Formally, with multiple global optima with the same divergence, q(w) will concentrate equally around all minimizers.)
",2.2. Divergence Bound and its Minimizer,[0],[0]
"For the case where = 1 , it is easy to see that
D⇤1 = log Z
w p(w) exp ( KL (q(Z|w)kp(Z|w))) ,
(10) which will be zero if p(w) is only supported on w where the divergence between q(z|w) and p(z|w) is zero.",2.2. Divergence Bound and its Minimizer,[0],[0]
"This may initially seem like a strange condition, given that p(w) results from both the target distribution p(z) and the adjoined distribution p(w|z).",2.2. Divergence Bound and its Minimizer,[0],[0]
"However, the next section gives more specifics.
2.3.",2.2. Divergence Bound and its Minimizer,[0],[0]
"Specific Form for p(w|z)
",2.2. Divergence Bound and its Minimizer,[0],[0]
The results in the previous section were written without without considering the specific form of p(w|z).,2.2. Divergence Bound and its Minimizer,[0],[0]
"This paper takes the approach of defining
p(w|z)",2.2. Divergence Bound and its Minimizer,[0],[0]
"= r(w)q(z|w) rz , (11)
where r(w) is a possibly improper distribution over w and rz = R w r(w)q(z|w) is a normalizer.",2.2. Divergence Bound and its Minimizer,[0],[0]
"Note that p(w|z) is still well-defined as long as the integral defining rz exists.
",2.2. Divergence Bound and its Minimizer,[0],[0]
"Here, we assume for convenience that rz is a constant, not depending on z. Enforcing rz to be constant essentially means choosing r(w) in such a way that it doesn’t “favor” any z over any other since if q(w) / r(w) then q(z) is uniform over z. Lemma 5.",2.2. Divergence Bound and its Minimizer,[0],[0]
If p(w|z),2.2. Divergence Bound and its Minimizer,[0],[0]
=,2.2. Divergence Bound and its Minimizer,[0],[0]
"r(w)q(z|w)/rz and rz is a constant, then the solution in Thm. 3 holds with
s(w) = log r(w)",2.2. Divergence Bound and its Minimizer,[0],[0]
log rz +,2.2. Divergence Bound and its Minimizer,[0],[0]
Eqw(Z)[ 1 log p(Z) + (1 1) log qw(Z)].,2.2. Divergence Bound and its Minimizer,[0],[0]
"(12)
This gives a distribution over q(w) that can be written in various equivalent ways, such as
q⇤(w) / r(w) exp 1E(w) + ( 1 1)H(w) (13)
=r(w) exp H(w) 1KL (qw(Z)kp(Z))
",2.2. Divergence Bound and its Minimizer,[0],[0]
=r(w) exp1/ E qw(Z),2.2. Divergence Bound and its Minimizer,[0],[0]
[log p(Z),2.2. Divergence Bound and its Minimizer,[0],[0]
"+ ( 1) log qw(Z)] ,
where H(w) = Eqw(Z)[log qw(Z)] is the entropy of qw and E(w) = Eqw(z)[log p(Z)].
",2.2. Divergence Bound and its Minimizer,[0],[0]
"Here, r(w) plays a role similar to a base density in an exponential family.",2.2. Divergence Bound and its Minimizer,[0],[0]
"If one simply used r(w) = 1, then p(w|z) may not be well-defined.",2.2. Divergence Bound and its Minimizer,[0],[0]
"Further, without a base density, the marginal q(z) would depend on the particular parameterization of w. To see this, take single parameter w, and imagine re-parameterizing so the negative reals are “squashed” by a factor of two.",2.2. Divergence Bound and its Minimizer,[0],[0]
The base density must increase by a factor of two for the negative reals to compensate in order to leave the marginal q(z) unchanged under the reparameterization.,2.2. Divergence Bound and its Minimizer,[0],[0]
Adjoining p(w|z) to p(z),2.4. Latent variables in variational inference,[0],[0]
"to define D1 above is strongly related to auxiliary random variables (Agakov & Barber, 2004) explored in variational inference to increase the representative power of q, e.g. by including latent stochastic transition operators (Salimans et al., 2015), random Gaussian process mappings (Tran et al., 2016), or hierarchical variables (Ranganath et al., 2016).",2.4. Latent variables in variational inference,[0],[0]
"Imagine doing variational inference with q✓(z, w), where now w is auxiliary
and the goal is to set ✓ so that q✓(z) ⇡ p(z).",2.4. Latent variables in variational inference,[0],[0]
"Since w must be integrated out, the entropy of z under q is typically intractable, but can be bounded by augmenting p with some distribution p(w|z) and then optimizing the joint KLdivergence over z and w, similarly to Lemma 2.",2.4. Latent variables in variational inference,[0],[0]
Note two differences.,2.4. Latent variables in variational inference,[0],[0]
"First, here the distribution over w is mathematically derived to minimize the bound, while previous work numerically optimizes ✓ at run-time.",2.4. Latent variables in variational inference,[0],[0]
"Second, previous work also optimizes parameters of the distribution p(w|z) to further improve the bound, while here it is left fixed (for each ) for simplicity (Sec. 5).",2.4. Latent variables in variational inference,[0],[0]
Future work might explore optimizing p(w|z) at run-time in the current paper’s framework.,2.4. Latent variables in variational inference,[0],[0]
This section considers algorithms to sample from the distribution defined by Eq. 13.,3. Bayesian Inference,[0],[0]
"Probabilistic inference can be used in various settings, but for concreteness the rest of this paper will focus on Bayesian inference.",3. Bayesian Inference,[0],[0]
"To fix notation, suppose a set of N inputs xi with corresponding outputs yi.",3. Bayesian Inference,[0],[0]
"(In a generative setting, xi would be empty.)",3. Bayesian Inference,[0],[0]
"Then, if z is a vector of parameters, the posterior distribution over z is, up to a constant
log p(z) = log p0(z)",3. Bayesian Inference,[0],[0]
"+ NX
i=1
log p(yi|xi, z) +",3. Bayesian Inference,[0],[0]
"C, (14)
where p0(z) is the prior, and p(yi|xi, z) is the likelihood for the i-th datum.",3. Bayesian Inference,[0],[0]
The goal of probabilistic inference is to be able to evaluate expectations with respect to p(z).,3. Bayesian Inference,[0],[0]
The goal of MCMC methods is to obtain samples from the target distribution p(z).,3.1. Langevin Dynamics,[0],[0]
Langevin dynamics sample by an extremely simple process of repeating gradient steps of log(z) with injected Gaussian noise.,3.1. Langevin Dynamics,[0],[0]
"Specifically, the iterate is
z z + ✏ 2 r log p(z) + p ✏⌘, (15)
where ⌘ is sampled from a standard Multivariate Gaussian distribution and ✏ is a step-size that may decay over time.",3.1. Langevin Dynamics,[0],[0]
"If Langevin dynamics are used as a proposal for a MetropolisHastings sampler, it can be shown that correct acceptance ratio is
exp s(z0) s(z) +",3.1. Langevin Dynamics,[0],[0]
"✏
8 krs(z)k2 ✏ 8 krs(z0)k2
+
1
2
(z z0) · (rs(z) +rs(z0)) , (16)
where s(z) = log p(z) up to a constant factor, and z0 is the proposed point from Eq. 15.",3.1. Langevin Dynamics,[0],[0]
"It is easy to see that as ✏ becomes small, this acceptance ratio will go to one, and so one can disregard the acceptance step with some bias in the results determined by the step size.
",3.1. Langevin Dynamics,[0],[0]
"Langevin dynamics explore the space of z through a random walk, and thus are likely to be slower than alternatives such as Hamiltonian Monte Carlo when used as an exact method (Neal, 2010, Section 5.2).",3.1. Langevin Dynamics,[0],[0]
The main practical advantage of Langevin dynamics comes from the case where the number of data N is large.,3.1. Langevin Dynamics,[0],[0]
"In that case, one can use a minibatch of M elements and approximate r log p(z) as
r log p(z) '",3.1. Langevin Dynamics,[0],[0]
"r log p0(z)+ N
M
X
i2minibatch r log p(yi|xi, z).
",3.1. Langevin Dynamics,[0],[0]
"(17)
Thus, Stochastic Gradient Langevin Dynamics, avoid a full pass through the dataset in each iteration, and so can scale to large datasets.",3.1. Langevin Dynamics,[0],[0]
Though Eq. 17 is an unbiased estimate of the gradient of log p(z) this still adds a bias to the stationary distribution of the the chain.,3.1. Langevin Dynamics,[0],[0]
"(See (Mandt et al., 2016) for an analysis.)",3.1. Langevin Dynamics,[0],[0]
"In the limit of a small step-size, the variance of the noise due to stochastic estimation of the gradient of log p(z) will be of order ✏2 while the variance of the injected noise is of order ✏, meaning the latter dominates (Welling & Teh, 2011; Teh et al., 2016).",3.1. Langevin Dynamics,[0],[0]
"The goal of variational inference is to maximize
L(w) =",3.2. Stochastic Gradient Variational Inference,[0],[0]
"Eqw(Z)[log p(Z) log qw(Z)], (18)
equivalent to minimizing the KL divergence between qw(z) and p(z).",3.2. Stochastic Gradient Variational Inference,[0],[0]
"If it were possible to exactly compute L, this could be maximized (to a local optima) by a simple gradient iteration like
w w + ✏ 2 rwL(w).",3.2. Stochastic Gradient Variational Inference,[0],[0]
"(19)
While in some cases with specific p and q, one can derive exact updates of L (Ghahramani & Beal, 2000) in general one cannot exactly evaluate the expectation over Z in L. One line of approach to this (Ranganath et al., 2014; Salimans & Knowles, 2014) is to write the gradient as rL = Eqw(Z)[(log qw(Z) log p(Z))r log qw(Z)], and estimate this by drawing samples from qw(z).",3.2. Stochastic Gradient Variational Inference,[0],[0]
"This experimentally seems to result in gradients with large variance, but this can be reduced by two strategies.",3.2. Stochastic Gradient Variational Inference,[0],[0]
"Firstly, one can use control variates, based on either Taylor expansion (Paisley et al., 2012) or the fact that the expected value of rw log qw(Z) is zero.",3.2. Stochastic Gradient Variational Inference,[0],[0]
"Secondly, since log p(z) is often a sum of terms defined on subsets of variables, one can RaoBlackwellize by integrating out other variables.",3.2. Stochastic Gradient Variational Inference,[0],[0]
"This approach only needs to be able to compute log p(z)– no other access, even to the gradient of p, is needed.",3.2. Stochastic Gradient Variational Inference,[0],[0]
"Another line of approach to variational inference is based on the “reparameterization trick” (Kingma & Welling,
2014; Rezende et al., 2014; Titsias & Lázaro-Gredilla, 2014), known in the stochastic approximation literature as a “pathwise” derivative (Kushner & Yin, 2003, Sec. 2.5.1).",3.2.1. REPARAMETERIZATION TRICK,[0],[0]
"Suppose that there is a deterministic mapping zr,w from parameters w and random numbers r (from some fixed standard distribution) such that zr,w ⇠ qw(z).",3.2.1. REPARAMETERIZATION TRICK,[0],[0]
"Then, we could equivalently write
L(w) = ER[log",3.2.1. REPARAMETERIZATION TRICK,[0],[0]
"p(zR,w)]",3.2.1. REPARAMETERIZATION TRICK,[0],[0]
+H(w).,3.2.1. REPARAMETERIZATION TRICK,[0],[0]
"(20)
where H(w) = Eqw(Z) log qw(Z) denotes the entropy.",3.2.1. REPARAMETERIZATION TRICK,[0],[0]
The advantage of Eq. 20,3.2.1. REPARAMETERIZATION TRICK,[0],[0]
"this is that the expectation is not a function of w, and so if computing the gradient of L, the gradient moves inside the expectation.",3.2.1. REPARAMETERIZATION TRICK,[0],[0]
"Then, provided zr,w is differentiable with respect to w, an unbiased estimate of the gradient of L is available as
rwL(w) '",3.2.1. REPARAMETERIZATION TRICK,[0],[0]
"rw log p(zr,w) +rwH(w).",3.2.1. REPARAMETERIZATION TRICK,[0],[0]
"(21)
If H(w) cannot be integrated in closed-form an alternative estimator based on
L(w) = ER[log",3.2.1. REPARAMETERIZATION TRICK,[0],[0]
"p(zR,w) log qw(zR,w)]",3.2.1. REPARAMETERIZATION TRICK,[0],[0]
"(22)
is possible, and in some circumstances this can even have lower variance (Roeder et al., 2016).
",3.2.1. REPARAMETERIZATION TRICK,[0],[0]
"Computing the gradient of log p(zr,w) with respect to w amounts to computing the derivative of log p(z) with respect to z multiplied by the Jacobian dzTr,w/dw.",3.2.1. REPARAMETERIZATION TRICK,[0],[0]
"For simple distributions like Gaussians zr,w this is easy to do analytically (Section 5).",3.2.1. REPARAMETERIZATION TRICK,[0],[0]
"Alternatively, this can all be done efficiently by automatic differentiation, (Kucukelbir et al., 2017)",3.2.1. REPARAMETERIZATION TRICK,[0],[0]
"the approach used here.
",3.2.1. REPARAMETERIZATION TRICK,[0],[0]
"As with Langevin dynamics, with a large dataset, log p(z) can be approximated by taking a sum over a minibatch.",3.2.1. REPARAMETERIZATION TRICK,[0],[0]
The most obious approach to this would be to choose a single vector r and use it throughout the minibatch.,3.2.1. REPARAMETERIZATION TRICK,[0],[0]
"However, variance can often be reduced by the “local reparameterization trick” (Kingma et al., 2015) in which a different random vector ri is drawn for each datum in the minibatch.",3.2.1. REPARAMETERIZATION TRICK,[0],[0]
"Intuitively, the motivation is that if i and j are two data in the minibatch then log p(yi|xi, zr,w) should be less correlated with log p(yj |xj , zr0,w) when a different random vector r0 is used for the second datum (consider the limiting case where all data are identical).",3.2.1. REPARAMETERIZATION TRICK,[0],[0]
"Then, one can write the approximation as
rwL(w) ' 1
M
X
i2minibatch
⇣ rw log p0(zri,w)
+Nrw log p(yi|xi, zri,w) rw log qw(zri,w) ⌘ .",3.2.1. REPARAMETERIZATION TRICK,[0],[0]
"(23)
Note that the approximation on the right-hand side depends both on the choice of the minibatch and on the random vectors ri, one chosen per element of the minibatch.",3.2.1. REPARAMETERIZATION TRICK,[0],[0]
An algorithm that interpolates between the methods in the previous section results from applying Langevin dynamics to the distribution over w defined by Thm. 3,4. Hybrid Dynamics,[0],[0]
"If the adjoining distribution p(w|z) is chosen as in in Sec. 2.3 with some r (w) that depends on , then define
L(w) = log",4. Hybrid Dynamics,[0],[0]
"r (w) + Eqw(Z)[log p(z) + ( 1) log q(z|w)], (24)
which is times the form of s(w) derived in 5, with the constant term of log rz dropped.",4. Hybrid Dynamics,[0],[0]
"Applying Langevin Dynamics2 to this results in the iteration
w w + ✏ 2
rL(w)",4. Hybrid Dynamics,[0],[0]
"+ p ✏ ⌘, (25)
where again ✏ is a step-size that may decrease over time and ⌘ is sampled from a standard Gaussian distribution.
",4. Hybrid Dynamics,[0],[0]
"This paper uses a closed-form for the entropy H(w) = Eqw(Z) log qw(Z), and so uses the gradient estimator
rL(w) ' r log r (w) + (1 )rH(w) + Eqw(Z)[log p(z) + ( 1) log q(z|w)].",4. Hybrid Dynamics,[0],[0]
(26),4. Hybrid Dynamics,[0],[0]
"The following experiments use the simplest common variational distribution for qw(Z), namely a fully-factorized Gaussian distribution.",5. Specifics For Gaussians,[0],[0]
"To make w unconstrained, let w = (µ, ⌫) where µ is a vector of mean components and the standard deviation of the i-th dimension is i = 10⌫i .",5. Specifics For Gaussians,[0],[0]
"To sample from this distribution given a vector r, one can simply take zr,w = µ + r where is element-wise product.",5. Specifics For Gaussians,[0],[0]
"The entropy of qw(Z) is, up to constant factors H(w)",5. Specifics For Gaussians,[0],[0]
= P i ⌫,5. Specifics For Gaussians,[0],[0]
"i ln 10.
",5. Specifics For Gaussians,[0],[0]
It remains to set the base density.,5. Specifics For Gaussians,[0],[0]
These experiments used an improper prior r (w) / Q,5. Specifics For Gaussians,[0],[0]
"i N (⌫i|u , 1) that is uniform over µ with a Gaussian prior on ⌫ with a fixed variance of 1 and a mean u .",5. Specifics For Gaussians,[0],[0]
"Since this is uniform over µ, rz is a constant.",5. Specifics For Gaussians,[0],[0]
The value u was calculated to numerically optimize the divergence bound D⇤ for a one-dimensional standard Gaussian p(z).,5. Specifics For Gaussians,[0],[0]
"Since D⇤ = A at the solution (Theorem 3), for any given and u , D⇤ can be evaluated by symbolically integrating out µ and then numerically integrating over ⌫.",5. Specifics For Gaussians,[0],[0]
"The values used in these experiments are below, with linear interpolation used for any other .
",5. Specifics For Gaussians,[0],[0]
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 u -.33 -.472 -.631 -.792,5. Specifics For Gaussians,[0],[0]
"-.953 -1.11 -1.29 -1.49 -1.74 -2.10 -10
2For some step-size ✏0, the Langevin dynamics would immediately be w w + (✏0/2)rs(w) + p ✏0⌘.",5. Specifics For Gaussians,[0],[0]
"If we define ✏ = ✏0, then this results in the given form since ✏0rs(w) =",5. Specifics For Gaussians,[0],[0]
"(✏/ )rs(w) = ✏rL(w).
",5. Specifics For Gaussians,[0],[0]
"Theoretically, it’s easy to show that as ! 1, D⇤ is minimized (with a minimum of zero) by u ! 1, meaning that after one iteration, ⌫ = 1, and henceforth, zr,w = µ.",5. Specifics For Gaussians,[0],[0]
"Thus, Eq. 25 is equivalent to Langevin dynamics as in Eq. 15.",5. Specifics For Gaussians,[0],[0]
"However, using u = 10, r(w) (a prior centered on a standard deviation of = 10 10) is practically equivalent and is more useful to guide linear interpolation.",5. Specifics For Gaussians,[0],[0]
"Meanwhile, when ! 0, the algorithm is independent of r(w), though the optimal value of u ⇡ .33 is correct for small .
",5. Specifics For Gaussians,[0],[0]
The above choice of r (w) is quite arbitrary.,5. Specifics For Gaussians,[0],[0]
"It is possible that other choices could be better, though performance was surprisingly insensitive in practice.",5. Specifics For Gaussians,[0],[0]
With large datasets log p(z) dominates log r(w) just as likelihoods dominate Bayesian priors.,5. Specifics For Gaussians,[0],[0]
"Calling on inspiration from recent work in variational inference, it might also be useful to optimize p(w|z) at runtime (Section 2.4).",5. Specifics For Gaussians,[0],[0]
There does not appear to be a single standard performance measure to evaluate approximate inference algorithms.,6. Experiments,[0],[0]
"For Bayesian inference, test-set accuracy or likelihood are sometimes used, but these measures have high variance due to the dataset, and conflate evaluation of the inference method with evaluation of the model it is running on.",6. Experiments,[0],[0]
"(An inference method with poor coverage of p(z) can have higher accuracy than a perfect sampler due to model mis-specification or dataset peculiarities.)
",6. Experiments,[0],[0]
"For a more fine-grained measure of inference performance, this paper uses the Maximum Mean Discrepancy (MMD) measure (Gretton et al., 2006; 2012).",6. Experiments,[0],[0]
MMD is essentially the empirical difference of the means of two samples in some feature space.,6. Experiments,[0],[0]
"We first draw a sample from p(z) by exhaustively running a traditional MCMC algorithm (Stan (Team, 2016), based on a variant of Hamil-
tonian Monte Carlo (Hoffman & Gelman, 2014)) for a large number of iterations, and compare this to the results of approximate inference.",6. Experiments,[0],[0]
"Since we have large samples, and want to compute the online performance at all iterations, a finite-dimensional feature space must be used to avoid the quadratic complexity of computing MMD using an arbitrary kernel.",6. Experiments,[0],[0]
"For two-dimensional problems, it was beneficial to use random Fourier features (Rahimi & Recht, 2007) to approximate the radial-basis function kernel k(x, y) = exp",6. Experiments,[0],[0]
( kx yk2).,6. Experiments,[0],[0]
"For higher dimensions, the original feature space was sufficiently discriminative.
",6. Experiments,[0],[0]
Approximate inference gives a sequence of vectors wt.,6. Experiments,[0],[0]
"For each time-step, a set of 100 samples At are drawn from q(z|wt).",6. Experiments,[0],[0]
"Then, the MMD between A1[A2[ · · ·At and the sample from exhaustive MCMC can be computed for all t in linear time.",6. Experiments,[0],[0]
"A disadvantage of this approach is the need for exhaustive MCMC for comparison, which by definition eludes the large-scale cases that motivate Langevin dynamics and stochastic variational inference.",6. Experiments,[0],[0]
However this gives a more fine-grained view of performance.,6. Experiments,[0],[0]
"For a first demonstration, the algorithm was applied to a set of toy 2-dimensional distributions, with various values of .",6.1. Toy Distributions,[0],[0]
"A few results are shown in Fig. 1, with more in
the appendix.",6.1. Toy Distributions,[0],[0]
"While the algorithm displays the expected trade-offs between speed and accuracy for different (Fig. 2), the results fairly uninteresting as all curves cross near the same time/MMD point where = 0 (variational inference) and = 1 (MCMC) meet.",6.1. Toy Distributions,[0],[0]
"So, for any given amount of time, either variational inference or MCMC are nearoptimal, and so intermediate do not much expand the “Pareto frontier” on these problems, although one might prefer an intermediate since the crossover horizon is not known in advance.",6.1. Toy Distributions,[0],[0]
"Next, the algorithm was applied to binary logistic regression with several standard datasets, using a minibatch size of 25, a different random vector r for each element in the minibatch, and a standard multivariate Laplace distribution as a prior.",6.2. Bayesian Logistic Regression,[0],[0]
"Simply picking a single value or schedule for the step ✏ is unsatisfactory, as the best schedule for a given problem, length of time, and value of varies.",6.2. Bayesian Logistic Regression,[0],[0]
"To give a fair comparison, inference was run for with a range of constant ✏ varying by factors of two from 23/N to 2 2/N .",6.2. Bayesian Logistic Regression,[0],[0]
This spans the range from large enough to often diverge to below optimal even after 106 iterations.,6.2. Bayesian Logistic Regression,[0],[0]
"Then, for each time, the best value of ✏ was retrospectively chosen (with performance averaged over repetitions before this choice).",6.2. Bayesian Logistic Regression,[0],[0]
"It is likely that decaying step-size schedules would perform
better, but this was not pursued since it would reduce transparency of the results.
",6.2. Bayesian Logistic Regression,[0],[0]
"The mean errors after 100 repetitions are shown in Fig. 4, while samples are compared to the ground truth for ionosphere in Fig. 3.",6.2. Bayesian Logistic Regression,[0],[0]
"This confirms the basic ideas of the algorithm, namely that it smoothly interpolates between the two previous algorithms without introducing any new behavior.",6.2. Bayesian Logistic Regression,[0],[0]
The main experimental finding is that there is usually a large range of time horizons for which an intermediate setting of performs better than either of the previous existing algorithms.,6.2. Bayesian Logistic Regression,[0],[0]
"This suggests that, say, someone who has a time budget slightly larger than that needed for variational inference could benefit from running the algorithm with a small value of for a slightly larger time.",6.2. Bayesian Logistic Regression,[0],[0]
This is in contrast to the toy two-dimensional examples where for almost all time horizons either = 0 or = 1 was optimal.,6.2. Bayesian Logistic Regression,[0],[0]
This paper has two contributions.,7. Discussion,[0],[0]
"First, a distribution over variational parameters is derived to minimize a bound on the marginal divergence to a target distribution.",7. Discussion,[0],[0]
"Secondly, this is used to derive an algorithm that interpolates between Langevin dynamics and stochastic variational inference.",7. Discussion,[0],[0]
"The Bayesian logistic regression experiments show that the intermediate values of this algorithm are useful in the sense that there are several orders of magnitude of time horizons where an intermediate algorithm performs better than either Langevin dynamics or variational inference.
",7. Discussion,[0],[0]
Many improvements to stochastic Langevin dynamics and variational inference have been proposed beyond the simple algorithms used here.,7. Discussion,[0],[0]
"For Langevin dynamics, Welling & Teh (2011) and Li et al. (2016) suggest adding a preconditioner, Patterson & Teh (2013) propose Riemannian Langevin Dynamics, and Dubey et al. (2016) propose to make use of the finite sum structure in a Bayesian posterior p(z) by incorporating techniques for incremental optimization.",7. Discussion,[0],[0]
"For stochastic variational inference, Hoffman et al.
(2013) propose to use the natural gradient, Mandt & Blei (2014) propose using smoothed gradients, and Sakaya & Klami (2016) propose a strategy of re-using previous gradient computations.",7. Discussion,[0],[0]
"It would be interesting to consider using these ideas with the hybrid algorithm, which could give insight into the relationship between the two different methods.
",7. Discussion,[0],[0]
There is other work based on combining the advantages of variational inference and MCMC.,7. Discussion,[0],[0]
"Stochastic Gradient Fisher Scoring (Ahn et al., 2012) interpolates between Langevin dynamics and a Gaussian approximation of the target.",7. Discussion,[0],[0]
"However, this approximation is based on the Bayesian central limit theorem and so will not be the same in general as the optimal variational distribution, even when a Gaussian is used as the variational family.",7. Discussion,[0],[0]
"Another line of research is that of interpreting the path of a MCMC algorithm as a variational distribution, and then fitting parameters to tighten a variational bound (Salimans et al., 2015; Rezende & Mohammed, 2015).",7. Discussion,[0],[0]
"While motivationally quite similar, the contribution of this paper is orthogonal, in that one could conceivably use these same ideas to define the variational family qw(z) used in this paper.",7. Discussion,[0],[0]
This would result in a somewhat unusual method that runs MCMC over the parameters of variational family of distributions that are themselves defined in terms of a (different) MCMC algorithm.,7. Discussion,[0],[0]
Two popular classes of methods for approximate inference are Markov chain Monte Carlo (MCMC) and variational inference.,abstractText,[0],[0]
"MCMC tends to be accurate if run for a long enough time, while variational inference tends to give better approximations at shorter time horizons.",abstractText,[0],[0]
"However, the amount of time needed for MCMC to exceed the performance of variational methods can be quite high, motivating more fine-grained tradeoffs.",abstractText,[0],[0]
"This paper derives a distribution over variational parameters, designed to minimize a bound on the divergence between the resulting marginal distribution and the target, and gives an example of how to sample from this distribution in a way that interpolates between the behavior of existing methods based on Langevin dynamics and stochastic gradient variational inference (SGVI).",abstractText,[0],[0]
A Divergence Bound for Hybrids of MCMC and Variational Inference and an Application to Langevin Dynamics and SGVI,title,[0],[0]
"Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2388–2397, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.",text,[0],[0]
"Many complex speech and natural language processing (NLP) pipelines such as Automatic Speech Recognition (ASR) and Statistical Machine Translation (SMT) systems store alternative hypotheses produced at various stages of processing as weighted acyclic automata, also known as lattices.",1 Introduction,[0],[0]
Each lattice stores a large number of hypotheses along with the raw system scores assigned to them.,1 Introduction,[0],[0]
"While single-best hypothesis is
typically what is desired at the end of the processing, it is often beneficial to consider a large number of weighted hypotheses at earlier stages of the pipeline to hedge against errors introduced by various subcomponents.",1 Introduction,[0],[0]
"Standard ASR and SMT techniques like discriminative training, rescoring with complex models and Minimum Bayes-Risk (MBR) decoding rely on lattices to represent intermediate system hypotheses that will be further processed to improve models or system output.",1 Introduction,[0],[0]
"For instance, lattice based MBR decoding has been shown to give moderate yet consistent gains in performance over conventional MAP decoding in a number of speech and NLP applications including ASR (Goel and Byrne, 2000) and SMT (Tromble et al., 2008; Blackwood et al., 2010; de Gispert et al., 2013).
",1 Introduction,[0],[0]
Most lattice-based techniques employed by speech and NLP systems make use of posterior quantities computed from probabilistic lattices.,1 Introduction,[0],[0]
"In this paper, we are interested in two such posterior quantities: i) n",1 Introduction,[0],[0]
"-gram expected count, the expected number of occurrences of a particular n-gram in a lattice, and ii) n-gram posterior probability, the total probability of accepting paths that include a particular n-gram.",1 Introduction,[0],[0]
"Expected counts have applications in the estimation of language model statistics from probabilistic input such as ASR lattices (Allauzen et al., 2003) and the estimation term frequencies from spoken corpora while posterior probabilities come up in MBR decoding of SMT lattices (Tromble et al., 2008), relevance ranking of spoken utterances and the estimation of document frequencies from spoken corpora (Karakos et al., 2011; Can and Narayanan, 2013).
",1 Introduction,[0],[0]
"The expected count c(x|A) of n-gram x given lattice A is defined as
c(x|A) = ∑ y∈Σ∗ #y(x)p(y|A) (1)
where #y(x) is the number of occurrences of n-
2388
gram x in hypothesis y and p(y|A) is the posterior probability of hypothesis y given lattice A.",1 Introduction,[0],[0]
"Similarly, the posterior probability p(x|A) of n-gram x given lattice A is defined as
p(x|A) = ∑ y∈Σ∗ 1y(x)p(y|A) (2)
where 1y(x) is an indicator function taking the value 1 when hypothesis y includes n-gram x and 0 otherwise.",1 Introduction,[0],[0]
"While it is straightforward to compute these posterior quantities from weighted nbest lists by examining each hypothesis separately and keeping a separate accumulator for each observed n-gram type, it is infeasible to do the same with lattices due to the sheer number of hypotheses stored.",1 Introduction,[0],[0]
"There are efficient algorithms in literature (Allauzen et al., 2003; Allauzen et al., 2004) for computing n-gram expected counts from weighted automata that rely on weighted finite state transducer operations to reduce the computation to a sum over n-gram occurrences eliminating the need for an explicit sum over accepting paths.",1 Introduction,[0],[0]
"The rather innocent looking difference between Equations 1 and 2, #y(x) vs. 1y(x), makes it hard to develop similar algorithms for computing n-gram posteriors from weighted automata since the summation of probabilities has to be carried out over paths rather than n-gram occurrences (Blackwood et al., 2010; de Gispert et al., 2013).
",1 Introduction,[0],[0]
"The problem of computing n-gram posteriors from lattices has been addressed by a number of recent works (Tromble et al., 2008; Allauzen et al., 2010; Blackwood et al., 2010; de Gispert et al., 2013) in the context of lattice-based MBR for SMT.",1 Introduction,[0],[0]
"In these works, it has been reported that the time required for lattice MBR decoding is dominated by the time required for computing n-gram posteriors.",1 Introduction,[0],[0]
"Our interest in computing n-gram posteriors from lattices stems from its potential applications in spoken content retrieval (Chelba et al., 2008; Karakos et al., 2011; Can and Narayanan, 2013).",1 Introduction,[0],[0]
Computation of document frequency statistics from spoken corpora relies on estimating ngram posteriors from ASR lattices.,1 Introduction,[0],[0]
"In this context, a spoken document is simply a collection of ASR lattices.",1 Introduction,[0],[0]
"The n-grams of interest can be word, syllable, morph or phoneme sequences.",1 Introduction,[0],[0]
"Unlike in the case of lattice-based MBR for SMT where the n-grams of interest are relatively short – typically up to 4-grams –, the n-grams we are interested in
are in many instances relatively long sequences of subword units.
",1 Introduction,[0],[0]
"In this paper, we present an efficient algorithm for computing the posterior probabilities of all ngrams in a lattice and constructing a minimal deterministic weighted finite-state automaton associating each n-gram with its posterior for efficient storage and retrieval.",1 Introduction,[0],[0]
"Our n-gram posterior computation algorithm builds upon the custom forward procedure described in (de Gispert et al., 2013) and introduces a number of refinements to significantly improve the time and space requirements:
•",1 Introduction,[0],[0]
"The custom forward procedure described in (de Gispert et al., 2013) computes unigram posteriors from an input lattice.",1 Introduction,[0],[0]
Higher order n-gram posteriors are computed by first transducing the input lattice to an n-gram lattice using an order mapping transducer and then running the custom forward procedure on this higher order lattice.,1 Introduction,[0],[0]
We reformulate the custom forward procedure as a dynamic programming algorithm that computes posteriors for successively longer n-grams and reuses the forward scores computed for the previous order.,1 Introduction,[0],[0]
"This reformulation subsumes the transduction of input lattices to n-gram lattices and obviates the need for constructing and applying order mapping transducers.
",1 Introduction,[0],[0]
"• Comparing Eq. 1 with Eq. 2, we can observe that posterior probability and expected count are equivalent for an n-gram that do not repeat on any path of the input lattice.",1 Introduction,[0],[0]
The key idea behind our algorithm is to limit the costly posterior computation to only those ngrams that can potentially repeat on some path of the input lattice.,1 Introduction,[0],[0]
We keep track of repeating n-grams of order n and use a simple impossibility argument to significantly reduce the number of n-grams of order n + 1 for which posterior computation will be performed.,1 Introduction,[0],[0]
The posteriors for the remaining n-grams are replaced with expected counts.,1 Introduction,[0],[0]
"This filtering of n-grams introduces a slight bookkeeping overhead but in return dramatically reduces the runtime and memory requirements for long n-grams.
",1 Introduction,[0],[0]
• We store the posteriors for n-grams that can potentially repeat on some path of the input lattice in a weighted prefix tree that we construct on the fly.,1 Introduction,[0],[0]
"Once that is done, we com-
pute the expected counts for all n-grams in the input lattice and represent them as a minimal deterministic weighted finite-state automaton, known as a factor automaton (Allauzen et al., 2004; Mohri et al., 2007), using the approach described in (Allauzen et al., 2004).",1 Introduction,[0],[0]
Finally we use general weighted automata algorithms to merge the weighted factor automaton representing expected counts with the weighted prefix tree representing posteriors to obtain a weighted factor automaton representing posteriors that can be used for efficient storage and retrieval.,1 Introduction,[0],[0]
"This section introduces the definitions and notation related to weighted finite state automata and transducers (Mohri, 2009).",2 Preliminaries,[0],[0]
Definition 1,2.1 Semirings,[0],[0]
"A semiring is a 5-tuple (K,⊕,⊗, 0, 1) where (K,⊕, 0) is a commutative monoid, (K,⊗, 1) is a monoid, ⊗ distributes over ⊕ and 0 is an annihilator for ⊗.
Table 1 lists common semirings.",2.1 Semirings,[0],[0]
"In speech and language processing, two semirings are of particular importance.",2.1 Semirings,[0],[0]
The log semiring is isomorphic to the probability semiring via the negative-log morphism and can be used to combine probabilities in the log domain.,2.1 Semirings,[0],[0]
"The tropical semiring, provides the algebraic structure necessary for shortest-path algorithms and can be derived from the log semiring using the Viterbi approximation.",2.1 Semirings,[0],[0]
Definition 2 A weighted finite-state automaton (WFSA),2.2 Weighted Finite-State Automata,[0],[0]
"A over a semiring (K,⊕,⊗, 0, 1) is a 7- tuple",2.2 Weighted Finite-State Automata,[0],[0]
"A = (Σ, Q, I, F,E, λ, ρ) where: Σ is the finite input alphabet; Q is a finite set of states; I, F ⊆ Q are respectively the set of initial and
final states;",2.2 Weighted Finite-State Automata,[0],[0]
E ⊆ Q ×,2.2 Weighted Finite-State Automata,[0],[0]
"(Σ ∪ {ε}) × K × Q is a finite set of arcs; λ : I → K, ρ : F → K are respectively the initial and final weight functions.
",2.2 Weighted Finite-State Automata,[0],[0]
"Given an arc e ∈ E, we denote by i[e] its input label, w[e] its weight, s[e] its source or origin state and t[e] its target or destination state.",2.2 Weighted Finite-State Automata,[0],[0]
"A path π = e1 · · · ek is an element ofE∗ with consecutive arcs satisfying t[ei−1] = s[ei], i = 2, . . .",2.2 Weighted Finite-State Automata,[0],[0]
", k. We extend t and s to paths by setting t[π] = s[ek] and s[π] = t[e1].",2.2 Weighted Finite-State Automata,[0],[0]
The labeling and the weight functions can also be extended to paths by defining i[π] = i[e1] . . .,2.2 Weighted Finite-State Automata,[0],[0]
i[ek] and w[π] = w[e1] ⊗ . . .,2.2 Weighted Finite-State Automata,[0],[0]
⊗ w[ek].,2.2 Weighted Finite-State Automata,[0],[0]
"We denote by Π(q, q′) the set of paths from q to q′ and by Π(q, x, q′) the set of paths from q to q′ with input string x ∈",2.2 Weighted Finite-State Automata,[0],[0]
"Σ∗. These definitions can also be extended to subsets S, S′ ⊆ Q, e.g.
Π(S, x, S′) =",2.2 Weighted Finite-State Automata,[0],[0]
"⋃
q∈S,q′∈S′ Π(q, x, q′).
",2.2 Weighted Finite-State Automata,[0],[0]
"An accepting path in an automaton A is a path in Π(I, F ).",2.2 Weighted Finite-State Automata,[0],[0]
A string x is accepted byA if there exists an accepting path π labeled with,2.2 Weighted Finite-State Automata,[0],[0]
x. A is deterministic if it has at most one initial state and at any state no two outgoing transitions share the same input label.,2.2 Weighted Finite-State Automata,[0],[0]
"The weight associated by an automaton A to a string x ∈ Σ∗ is given by
JAK(x) = ⊕ π∈Π(I,x,F ) λ(s[π])⊗ w[π]⊗ ρ(t[π])
and JAK(x) , 0 when Π(I, x, F ) = ∅.",2.2 Weighted Finite-State Automata,[0],[0]
"A weighted automatonA defined over the probability semiring (R+,+,×, 0, 1) is said to be probabilistic if for any state q ∈ Q, the sum of the weights of all cycles at q, ⊕π∈Π(q,q)w[π], is well-defined and in R+ and ∑ x∈Σ∗JAK(x) = 1.",2.2 Weighted Finite-State Automata,[0],[0]
"We denote by Φn the n-gram mapping transducer (Blackwood et al., 2010; de Gispert et al., 2013)
of order n.",2.3 N-gram Mapping Transducer,[0],[0]
"This transducer maps label sequences to n-gram sequences of order n. Φn is similar in form to the weighted finite-state transducer representation of a backoff n-gram language model (Allauzen et al., 2003).",2.3 N-gram Mapping Transducer,[0],[0]
"We denote by An the ngram lattice of order n obtained by composing lattice A with Φn, projecting the resulting transducer onto its output labels, i.e. n-grams, to obtain an automaton, removing ε-transitions, determinizing and minimizing (Mohri, 2009).",2.3 N-gram Mapping Transducer,[0],[0]
An is a compact lattice of n-gram sequences of order n consistent with the labels and scores of lattice A.,2.3 N-gram Mapping Transducer,[0],[0]
An typically has more states than A due to the association of distinct n-gram histories with states.,2.3 N-gram Mapping Transducer,[0],[0]
Definition 3,2.4 Factor Automata,[0],[0]
"Given two strings x, y ∈ Σ∗, x is a factor (substring) of y",2.4 Factor Automata,[0],[0]
"if y = uxv for some u, v ∈ Σ∗. More generally, x is a factor of a language L ⊆ Σ∗",2.4 Factor Automata,[0],[0]
if x is a factor of some string y ∈,2.4 Factor Automata,[0],[0]
L.,2.4 Factor Automata,[0],[0]
The factor automaton S(y) of a string y is the minimal deterministic finite-state automaton recognizing exactly the set of factors of y.,2.4 Factor Automata,[0],[0]
"The factor automaton S(A) of an automaton A is the minimal deterministic finite-state automaton recognizing exactly the set of factors of A, that is the set of factors of the strings accepted by A.
Factor automaton (Mohri et al., 2007) is an efficient and compact data structure for representing a full index of a set of strings, i.e. an automaton.",2.4 Factor Automata,[0],[0]
It can be used to determine if a string x is a factor in time linear in its length O(|x|).,2.4 Factor Automata,[0],[0]
"By associating a weight with each factor, we can generalize the factor automaton structure to weighted automata and use it for efficient storage and retrieval of n-gram posteriors and expected counts.",2.4 Factor Automata,[0],[0]
"In this section we present an efficient algorithm based on the n-gram posterior computation algorithm described in (de Gispert et al., 2013) for computing the posterior probabilities of all ngrams in a lattice and constructing a weighted factor automaton for efficient storage and retrieval of these posteriors.",3 Computation of N-gram Posteriors,[0],[0]
We assume that the input lattice is an ε-free acyclic probabilistic automaton.,3 Computation of N-gram Posteriors,[0],[0]
"If that is not the case, we can use general weighted automata ε-removal and weight-pushing algorithms (Mohri, 2009) to preprocess the input automaton.
",3 Computation of N-gram Posteriors,[0],[0]
"Algorithm 1 reproduces the original algorithm of (de Gispert et al., 2013) in our no-
tation.",3 Computation of N-gram Posteriors,[0],[0]
"Each iteration of the outermost loop starting at line 1 computes posterior probabilities of all unigrams in the n-gram lattice An = (Σn, Qn, In, Fn, En, λn, ρn), or equivalently all n-grams of order n in the lattice A.",3 Computation of N-gram Posteriors,[0],[0]
"The inner loop starting at line 6 is essentially a custom forward procedure computing not only the standard forward probabilities α[q], the marginal probability of paths that lead to state q,
α[q] = ⊕
π ∈Π(I,q) λ(s[π])⊗ w[π] (3)
= ⊕ e∈E t[e] = q α[s[e]]⊗ w[e] (4)
but also the label specific forward probabilities α̃[q][x], the marginal probability of paths that lead to state q and include label x.
α̃[q][x] = ⊕
π ∈Π(I,q) ∃u,v ∈Σ∗: i[π] =uxv
λ(s[π])⊗ w[π] (5)
= ⊕ e∈E t[e] = q
i[e] =x
α[s[e]]⊗ w[e]
⊕ ⊕ e∈E t[e] = q
i[e] 6=x
α̃[s[e]][x]⊗ w[e] (6)
Just like in the case of the standard forward algorithm, visiting states in topological order ensures that forward probabilities associated with a state has already been computed when that state is visited.",3 Computation of N-gram Posteriors,[0],[0]
"At each state s, the algorithm examines each arc e = (s, x, w, q) and updates the forward probabilities for state q in accordance with the recursions in Equations 4 and 6 by propagating the forward probabilities computed for s (lines 8-12).",3 Computation of N-gram Posteriors,[0],[0]
"The conditional on line 11 ensures that the label specific forward probability α̃[s][y] is propagated to state q only if label y is different from label x, the label on the current arc.",3 Computation of N-gram Posteriors,[0],[0]
"In other words, if a label y repeats on some path π leading to state q, then π contributes to α̃[q][y] only once.",3 Computation of N-gram Posteriors,[0],[0]
This is exactly what is required by the indicator function in Equation 2 when computing unigram posteriors.,3 Computation of N-gram Posteriors,[0],[0]
"Whenever a final state is processed, the posterior probability accumulator for each label observed on paths reaching that state is updated by multiplying the label specific forward probability and the final weight associated with that state
Algorithm 1 Compute N-gram Posteriors 1 for n← 1, . . .",3 Computation of N-gram Posteriors,[0],[0]
", N do 2 An←Min(Det(RmEps(ProjOut(A ◦",3 Computation of N-gram Posteriors,[0],[0]
Φn)))),3 Computation of N-gram Posteriors,[0],[0]
"3 α[q]← λn(q), ∀ state q ∈",3 Computation of N-gram Posteriors,[0],[0]
"Qn 4 α̃[q][x]← 0, ∀ state q ∈ Qn, ∀ label x ∈",3 Computation of N-gram Posteriors,[0],[0]
"Σn 5 p(x|A)← 0, ∀ label x ∈",3 Computation of N-gram Posteriors,[0],[0]
Σn 6 for each state s ∈,3 Computation of N-gram Posteriors,[0],[0]
Qn do .,3 Computation of N-gram Posteriors,[0],[0]
"In topological order 7 for each arc (s, x, w, q) ∈ En do 8 α[q]← α[q]⊕ α[s]⊗ w 9 α̃[q][x]← α̃[q][x]⊕ α[s]⊗ w
10 for each label y ∈ α̃[s] do 11 if y 66= x then 12 α̃[q][y]← α̃[q][y]⊕ α̃[s][y]⊗",3 Computation of N-gram Posteriors,[0],[0]
"w 13 if s ∈ Fn then 14 for each label x ∈ α̃[s] do 15 p(x|A)← p(x|A)⊕ α̃[s][x]⊗ ρn(s) 16 P ←Min(ConstructPrefixTree(p))
and adding the resulting value to the accumulator (lines 13-15).",3 Computation of N-gram Posteriors,[0],[0]
"It should be noted that this algorithm is a form of marginalization (de Gispert et al., 2013), rather than a counting procedure, due to the conditional on line 11.",3 Computation of N-gram Posteriors,[0],[0]
"If that conditional were to be removed, this algorithm would compute n-gram expected counts instead of posterior probabilities.
",3 Computation of N-gram Posteriors,[0],[0]
The key idea behind our algorithm is to restrict the computation of posteriors to only those n-grams that may potentially repeat on some path of the input lattice and exploit the equivalence of expected counts and posterior probabilities for the remaining n-grams.,3 Computation of N-gram Posteriors,[0],[0]
It is possible to extend Algorithm 1 to implement this restriction by keeping track of repeating n-grams of order n and replacing the output labels of appropriate arcs in Φn+1 with ε labels.,3 Computation of N-gram Posteriors,[0],[0]
Alternatively we can reformulate Algorithm 1 as in Algorithm 2.,3 Computation of N-gram Posteriors,[0],[0]
In this formulation we compute n-gram posteriors directly on the input lattice A without constructing the n-gram lattice An.,3 Computation of N-gram Posteriors,[0],[0]
We explicitly associate states in the original lattice with distinct n-gram histories which is implicitly done in Algorithm 1 by constructing the n-gram lattice An.,3 Computation of N-gram Posteriors,[0],[0]
This explicit association lets us reuse forward probabilities computed at order n while computing the forward probabilities at order n + 1.,3 Computation of N-gram Posteriors,[0],[0]
"Further, we can directly restrict the n-grams for which posterior computation will be performed.
",3 Computation of N-gram Posteriors,[0],[0]
"In Algorithm 2, ά[n][q][h] represents the his-
tory specific forward probability of state q, the marginal probability of paths that lead to state q and include length n string h as a suffix.
ά[n][q][h] = ⊕
π ∈Π(I,q) ∃ z",3 Computation of N-gram Posteriors,[0],[0]
"∈Σ∗: i[π] = zh
λ(s[π])⊗ w[π] (7)
= ⊕ e∈E t[e] = q
g ∈ ά[n−1][s[e]] gi[e] =h
ά[n− 1][s[e]][g]⊗ w[e]
(8)
ά[n][q][h] is the analogue of α[q] in Algorithm 1.",3 Computation of N-gram Posteriors,[0],[0]
It splits the forward probability of state q,3 Computation of N-gram Posteriors,[0],[0]
"(Equation 3), among length n suffixes (or histories) of paths that lead to state q. We can interpret ά[n][q][h] as the forward probability of state (q, h) in the n-gram lattice An+1.",3 Computation of N-gram Posteriors,[0],[0]
"Here (q, h) ∈ Qn+1 denotes the unique state corresponding to state q in the original lattice A and state h in the mapping transducer Φn+1.",3 Computation of N-gram Posteriors,[0],[0]
"α̂[q][h][x] represents the history and n-gram specific forward probability of state q, the marginal probability of paths that lead to state q, include length n − 1 string h as a suffix and
Algorithm 2 Compute N-gram Posteriors (Reformulation) 1",3 Computation of N-gram Posteriors,[0],[0]
"R[0]← {ε} 2 ά[0][q][ε]← α[q], ∀ state q ∈ Q 3 for n← 1, . . .",3 Computation of N-gram Posteriors,[0],[0]
", N do 4 R[n]← ∅ 5 ά[n][q][x]← 0, ∀ state q ∈ Q, ∀ ngram x ∈",3 Computation of N-gram Posteriors,[0],[0]
"Σn 6 α̂[q][h][x]← 0, ∀ state q ∈ Q, ∀ history h ∈ Σn−1, ∀ ngram x ∈",3 Computation of N-gram Posteriors,[0],[0]
"Σn 7 p(x|A)← 0, ∀ ngram x ∈",3 Computation of N-gram Posteriors,[0],[0]
Σn 8 for each state s ∈ Q do .,3 Computation of N-gram Posteriors,[0],[0]
"In topological order 9 for each history g ∈ ά[n− 1][s] where g ∈ R[n− 1] do
10 for each arc (s, i, w, q) ∈ E",3 Computation of N-gram Posteriors,[0],[0]
do 11 x←,3 Computation of N-gram Posteriors,[0],[0]
gi .,3 Computation of N-gram Posteriors,[0],[0]
Concatenate history and label 12 h←,3 Computation of N-gram Posteriors,[0],[0]
x[1 : n] .,3 Computation of N-gram Posteriors,[0],[0]
Drop first label 13 if h ∈ R[n− 1] then 14 ά[n][q][x]← ά[n][q][x]⊕ ά[n− 1][s][g]⊗ w 15 α̂[q][h][x]← α̂[q][h][x]⊕ ά[n−,3 Computation of N-gram Posteriors,[0],[0]
1][s][g]⊗ w 16 for each ngram y ∈ α̂[s][g] do 17 if y 66= x then 18 α̂[q][h][y]← α̂[q][h][y]⊕ α̂[s][g][y]⊗,3 Computation of N-gram Posteriors,[0],[0]
w 19 else 20 R[n]← R[n] ∪ {y} 21 if s ∈ F then 22 for each history g ∈ α̂[s] do 23 for each ngram x ∈ α̂[s][g] do 24 p(x|A)← p(x|A)⊕ α̂[s][g][x]⊗ ρ(s),3 Computation of N-gram Posteriors,[0],[0]
"25 P ′← ConstructPrefixTree(p) 26 C ← ComputeExpectedCounts(A,N) 27 P ←Min(Det(RmEps((C",3 Computation of N-gram Posteriors,[0],[0]
"− RmWeight(P ′))⊕ P ′)))
",3 Computation of N-gram Posteriors,[0],[0]
"include n-gram x as a substring.
α̂[q][h][x] = ⊕
π ∈Π(I,q) ∃ z",3 Computation of N-gram Posteriors,[0],[0]
"∈Σ∗: i[π] = zh ∃u,v ∈Σ∗: i[π] =uxv
λ(s[π])⊗ w[π]
(9) = ⊕ e∈E t[e] = q
g ∈ ά[|h|][s[e]] gi[e] =x
ά[|h|][s[e]][g]⊗ w[e]
⊕ ⊕ e∈E t[e] = q
g ∈ α̂[s[e]] gi[e] 6=x
α̂[s[e]][g][x]⊗",3 Computation of N-gram Posteriors,[0],[0]
"w[e]
(10)
α̂[q][h][x] is the analogue of α̃[q][x] in Algorithm 1.",3 Computation of N-gram Posteriors,[0],[0]
"R[n] represents the set of n-grams of order n
that repeat on some path of A. We start by defining R[0] , {ε}, i.e. the only repeating n-gram of order 0 is the empty string ε, and computing ά[0][q][ε] ≡ α[q] using the standard forward algorithm.",3 Computation of N-gram Posteriors,[0],[0]
Each iteration of the outermost loop starting at line 3 computes posterior probabilities of all n-grams of order n directly on the lattice A.,3 Computation of N-gram Posteriors,[0],[0]
"At iteration n, we visit the states in topological order and examine each length n−1 history g associated with s, the state we are in.",3 Computation of N-gram Posteriors,[0],[0]
"For each history g, we go over the set of arcs leaving state s, construct the current n-gram x by concatenating g with the current arc label i (line 11), construct the length n−1 history h of the target state q (line 12), and update the forward probabilities for the target state history pair (q, h) in accordance with the recursions in Equations 8 and 10 by propagating the forward probabilities computed for the state history pair (s, g) (lines 14-18).",3 Computation of N-gram Posteriors,[0],[0]
"Whenever a final state is processed, the posterior probability accumulator for
each n-gram of order n observed on paths reaching that state is updated by multiplying the n-gram specific forward probability and the final weight associated with that state and adding the resulting value to the accumulator (lines 21-24).
",3 Computation of N-gram Posteriors,[0],[0]
We track repeating n-grams of order n to restrict the costly posterior computation operation to only those n-grams of order n+ 1 that can potentially repeat on some path of the input lattice.,3 Computation of N-gram Posteriors,[0],[0]
"The conditional on line 17 checks if any of the n-grams observed on paths reaching state history pair (s, g) is the same as the current n-gram x, and if so adds it to the set of repeating n-grams.",3 Computation of N-gram Posteriors,[0],[0]
"At each iteration n, we check if the current length n",3 Computation of N-gram Posteriors,[0],[0]
"− 1 history g of the state we are in is in R[n − 1], the set of repeating n-grams of order n−1 (line 9).",3 Computation of N-gram Posteriors,[0],[0]
"If it is not, then no n-gram x = gi can repeat on some path of A since that would require g to repeat as well.",3 Computation of N-gram Posteriors,[0],[0]
"If g is inR[n−1], then for each arc e = (s, i, w, q) we check if the length n− 1 history h",3 Computation of N-gram Posteriors,[0],[0]
=,3 Computation of N-gram Posteriors,[0],[0]
g[1 : n− 1]i of the next state q is in R[n − 1] (line 13).,3 Computation of N-gram Posteriors,[0],[0]
"If it is not, then the n-gram x = g[0]h can not repeat either.
",3 Computation of N-gram Posteriors,[0],[0]
We keep the posteriors p(x|A) for n-grams that can potentially repeat on some path of the input lattice in a deterministic WFSA P ′ that we construct on the fly.,3 Computation of N-gram Posteriors,[0],[0]
"P ′ is a prefix tree where each path π corresponds to an n-gram posterior, i.e. i[π] = x =⇒ w[π] = ρ(t[π])",3 Computation of N-gram Posteriors,[0],[0]
= p(x|A).,3 Computation of N-gram Posteriors,[0],[0]
"Once the computation of posteriors for possibly repeating n-grams is finished, we use the algorithm described in (Allauzen et al., 2004) to construct a weighted factor automaton C mapping all n-grams observed in A to their expected counts, i.e. ∀π in C, i[π] = x =⇒ w[π] = c(x|A).",3 Computation of N-gram Posteriors,[0],[0]
"We use P ′ and C to construct another weighted factor automaton P mapping all n-grams observed in A to their posterior probabilities, i.e. ∀π in P , i[π] = x =⇒ w[π] = p(x|A).",3 Computation of N-gram Posteriors,[0],[0]
First we remove the n-grams accepted by P ′,3 Computation of N-gram Posteriors,[0],[0]
"from C using the difference operation (Mohri, 2009),
C ′ = C − RmWeight(P ′) then take the union of the remaining automaton C ′ and P ′, and finally optimize the result by removing ε-transitions, determinizing and minimizing
P = Min(Det(RmEps(C ′ ⊕ P ′))).",3 Computation of N-gram Posteriors,[0],[0]
"In this section we provide experiments comparing the performance of Algorithm 2 with Algorithm 1
as well as a baseline algorithm based on the approach of (Tromble et al., 2008).",4 Experiments and Discussion,[0],[0]
"All algorithms were implemented in C++ using the OpenFst Library (Allauzen et al., 2007).",4 Experiments and Discussion,[0],[0]
Algorithm 1 implementation is a thin wrapper around the reference implementation.,4 Experiments and Discussion,[0],[0]
"All experiments were conducted on the 88K ASR lattices (total size: #states + #arcs = 33M, disk size: 481MB) generated from the training subset of the IARPA Babel Turkish language pack, which includes 80 hours of conversational telephone speech.",4 Experiments and Discussion,[0],[0]
"Lattices were generated with a speaker dependent DNN ASR system that was trained on the same data set using IBM’s Attila toolkit (Soltau et al., 2010).",4 Experiments and Discussion,[0],[0]
"All lattices were pruned to a logarithmic beam width of 5.
",4 Experiments and Discussion,[0],[0]
"Figure 1 gives a scatter plot of the posterior probability computation time vs. the number of lattice n-grams (up to 5-grams) where each point
represents one of the 88K lattices in our data set.",4 Experiments and Discussion,[0],[0]
"Similarly, Figure 2 gives a scatter plot of the maximum memory used by the program (maximum resident set size) during the computation of posteriors vs. the number of lattice n-grams (up to 5-grams).",4 Experiments and Discussion,[0],[0]
"Algorithm 2 requires significantly less resources, particularly in the case of larger lattices with a large number of unique n-grams.
",4 Experiments and Discussion,[0],[0]
"To better understand the runtime characteristics of Algorithms 1 and 2, we conducted a small experiment where we randomly selected 100 lattices (total size: #states + #arcs = 81K, disk size: 1.2MB) from our data set and analyzed the relation between the runtime and the maximum ngram length N .",4 Experiments and Discussion,[0],[0]
"Table 2 gives a runtime comparison between the baseline posterior computation algorithm described in (Tromble et al., 2008), Algorithm 1, Algorithm 2 and the expected count computation algorithm of (Allauzen et al., 2004).",4 Experiments and Discussion,[0],[0]
The baseline method computes posteriors separately for each n-gram by intersecting the lattice with an automaton accepting only the paths including that n-gram and computing the total weight of the resulting automaton in log semiring.,4 Experiments and Discussion,[0],[0]
Runtime complexities of the baseline method and Algorithm 1 are exponential in N due to the explicit enumeration of n-grams and we can clearly see this trend in the 3rd and 4th rows of Table 2.,4 Experiments and Discussion,[0],[0]
"Algorithm 2 (5th row) takes advantage of the WFSA based expected count computation algorithm (6th row) to do most of the work for long n-grams, hence does not suffer from the same exponential growth.",4 Experiments and Discussion,[0],[0]
Notice the drops in the runtimes of Algorithm 2 and the WFSA based expected count computation algorithm when all n-grams are included into the computation regardless of their length.,4 Experiments and Discussion,[0],[0]
These drops are due to the expected count computation algorithm that processes all n-grams simultaneously using WFSA operations.,4 Experiments and Discussion,[0],[0]
"Limiting the maximum n-gram length requires pruning long ngrams, which in general can increase the sizes of
intermediate WFSAs used in computation and result in longer runtimes as well as larger outputs.
",4 Experiments and Discussion,[0],[0]
"When there is no limit on the maximum n-gram length, the output of Algorithm 2 is a weighted factor automaton mapping each factor to its posterior.",4 Experiments and Discussion,[0],[0]
Table 3 compares the construction and storage requirements for posterior factor automata with similar factor automata structures.,4 Experiments and Discussion,[0],[0]
"We use the approach described in (Allauzen et al., 2004) for constructing both the unweighted and the expected count factor automata.",4 Experiments and Discussion,[0],[0]
We construct the unweighted factor automata by first removing the weights on the input lattices and then applying the determinization operation on the tropical semiring so that path weights are not added together.,4 Experiments and Discussion,[0],[0]
The storage requirements of the posterior factor automata produced by Algorithm 2 is similar to those of the expected count factor automata.,4 Experiments and Discussion,[0],[0]
"Unweighted factor automata, on the other hand, are significantly more compact than their weighted counterparts even though they accept the same set of strings.",4 Experiments and Discussion,[0],[0]
This difference in size is due to accommodating path weights which in general can significantly impact the effectiveness of automata determinization and minimization.,4 Experiments and Discussion,[0],[0]
"Efficient computation of n-gram expected counts from weighted automata was first addressed in (Allauzen et al., 2003) in the context of estimating n-gram language model statistics from ASR lattices.",5 Related Work,[0],[0]
"Expected counts for all n-grams of interest observed in the input automaton are computed by composing the input with a simple counting transducer, projecting on the output side, and removing ε-transitions.",5 Related Work,[0],[0]
The weight associated by the resulting WFSA to each n-gram it accepts is simply the expected count of that n-gram in the input automaton.,5 Related Work,[0],[0]
"Construction of such an automaton for all substrings (factors) of the input automaton was later explored in (Allauzen et al., 2004) in the con-
text of building an index for spoken utterance retrieval (SUR) (Saraclar and Sproat, 2004).",5 Related Work,[0],[0]
This is the approach used for constructing the weighted factor automaton C in Algorithm 2.,5 Related Work,[0],[0]
"While expected count works well in practice for ranking spoken utterances containing a query term, posterior probability is in theory a better metric for this task.",5 Related Work,[0],[0]
"The weighted factor automaton P produced by Algorithm 2 can be used to construct an SUR index weighted with posterior probabilities.
",5 Related Work,[0],[0]
"The problem of computing n-gram posteriors from lattices was first addressed in (Tromble et al., 2008) in the context of lattice-based MBR for SMT.",5 Related Work,[0],[0]
This is the baseline approach used in our experiments and it consists of building a separate FSA for each n-gram of interest and intersecting this automaton with the input lattice to discard those paths that do not include that n-gram and summing up the weights of remaining paths.,5 Related Work,[0],[0]
The fundamental shortcoming of this approach is that it requires separate intersection and shortest distance computations for each n-gram.,5 Related Work,[0],[0]
"This shortcoming was first tackled in (Allauzen et al., 2010) by introducing a counting transducer for simultaneous computation of posteriors for all n-grams of order n in a lattice.",5 Related Work,[0],[0]
This transducer works well for unigrams since there is a relatively small number of unique unigrams in a lattice.,5 Related Work,[0],[0]
"However, it is less efficient for n-grams of higher orders.",5 Related Work,[0],[0]
"This inefficiency was later addressed in (Blackwood et al., 2010) by employing n-gram mapping transducers to transduce the input lattices to n-gram lattices of order n and computing unigram posteriors on the higher order lattices.",5 Related Work,[0],[0]
"Algorithm 1 was described in (de Gispert et al., 2013) as a fast alternative to counting transducers.",5 Related Work,[0],[0]
"It is a lattice specialization of a more general algorithm for computing n-gram posteriors from a hypergraph in a single inside pass (DeNero et al., 2010).",5 Related Work,[0],[0]
"While this algorithm works really well for relatively short n-grams, its time and space requirements scale exponentially with the maximum n-gram length.",5 Related Work,[0],[0]
"Algorithm 2 builds upon this algorithm by exploiting the equiv-
alence of expected counts and posteriors for nonrepeating n-grams and eliminating the costly posterior computation operation for most n-grams in the input lattice.",5 Related Work,[0],[0]
We have described an efficient algorithm for computing n-gram posteriors from an input lattice and constructing an efficient and compact data structure for storing and retrieving them.,6 Conclusion,[0],[0]
The runtime and memory requirements of the proposed algorithm grow linearly with the length of the n-grams as opposed to the exponential growth observed with the original algorithm we are building upon.,6 Conclusion,[0],[0]
This is achieved by limiting the posterior computation to only those n-grams that may repeat on some path of the input lattice and using the relatively cheaper expected count computation algorithm for the rest.,6 Conclusion,[0],[0]
This filtering of n-grams introduces a slight bookkeeping overhead over the baseline algorithm but in return dramatically reduces the runtime and memory requirements for long n-grams.,6 Conclusion,[0],[0]
The authors would like to thank Cyril Allauzen and Graeme W. Blackwood for helpful discussions.,Acknowledgments,[0],[0]
This work uses IARPA-babel105b-v0.4 Turkish full language pack from the IARPA Babel Program language collection and is supported by the Intelligence Advanced Research Projects Activity (IARPA) via Department of Defense U.S. Army Research Laboratory (DoD/ARL) contract number W911NF-12-C-0012.,Acknowledgments,[0],[0]
The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright annotation thereon.,Acknowledgments,[0],[0]
"Disclaimer: The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of IARPA, DoD/ARL, or the U.S. Government.",Acknowledgments,[0],[0]
Efficient computation of n-gram posterior probabilities from lattices has applications in lattice-based minimum Bayes-risk decoding in statistical machine translation and the estimation of expected document frequencies from spoken corpora.,abstractText,[0],[0]
"In this paper, we present an algorithm for computing the posterior probabilities of all ngrams in a lattice and constructing a minimal deterministic weighted finite-state automaton associating each n-gram with its posterior for efficient storage and retrieval.",abstractText,[0],[0]
"Our algorithm builds upon the best known algorithm in literature for computing ngram posteriors from lattices and leverages the following observations to significantly improve the time and space requirements: i) the n-grams for which the posteriors will be computed typically comprises all n-grams in the lattice up to a certain length, ii) posterior is equivalent to expected count for an n-gram that do not repeat on any path, iii) there are efficient algorithms for computing",abstractText,[0],[0]
n-gram expected counts from lattices.,abstractText,[0],[0]
We present experimental results comparing our algorithm with the best known algorithm in literature as well as a baseline algorithm based on weighted finite-state automata operations.,abstractText,[0],[0]
A Dynamic Programming Algorithm for Computing N-gram Posteriors from Lattices,title,[0],[0]
"We consider the problem of including additional knowledge in estimating sparse Gaussian graphical models (sGGMs) from aggregated samples, arising often in bioinformatics and neuroimaging applications. Previous joint sGGM estimators either fail to use existing knowledge or cannot scale-up to many tasks (large K) under a highdimensional (large p) situation. In this paper, we propose a novel Joint Elementary Estimator incorporating additional Knowledge (JEEK) to infer multiple related sparse Gaussian Graphical models from large-scale heterogeneous data. Using domain knowledge as weights, we design a novel hybrid norm as the minimization objective to enforce the superposition of two weighted sparsity constraints, one on the shared interactions and the other on the task-specific structural patterns. This enables JEEK to elegantly consider various forms of existing knowledge based on the domain at hand and avoid the need to design knowledgespecific optimization. JEEK is solved through a fast and entry-wise parallelizable solution that largely improves the computational efficiency of the state-of-the-art O(p5K4) to O(p2K4). We conduct a rigorous statistical analysis showing that JEEK achieves the same convergence rate O(log(Kp)/ntot) as the state-of-the-art estimators that are much harder to compute. Empirically, on multiple synthetic datasets and two real-world data, JEEK outperforms the speed of the state-ofarts significantly while achieving the same level of prediction accuracy.
1Department of Computer Science, University of Virginia, http://www.jointnets.org/ . Correspondence to: Beilun Wang <bw4mw@virginia.edu>, Yanjun Qi <yanjun@virginia.edu>.
Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).",text,[0],[0]
Technology revolutions in the past decade have collected large-scale heterogeneous samples from many scientific domains.,1 Introduction,[0],[0]
"For instance, genomic technologies have delivered petabytes of molecular measurements across more than hundreds of types of cells and tissues from national projects like ENCODE (Consortium et al., 2012) and TCGA (Network et al., 2011).",1 Introduction,[0],[0]
"Neuroimaging technologies have generated petabytes of functional magnetic resonance imaging (fMRI) datasets across thousands of human subjects (shared publicly through projects like openfMRI (Poldrack et al., 2013).",1 Introduction,[0],[0]
"Given such data, understanding and quantifying variable graphs from heterogeneous samples about multiple contexts is a fundamental analysis task.
",1 Introduction,[0],[0]
"Such variable graphs can significantly simplify networkdriven studies about diseases (Ideker & Krogan, 2012), can help understand the neural characteristics underlying clinical disorders (Uddin et al., 2013) and can allow for understanding genetic or neural pathways and systems.",1 Introduction,[0],[0]
"The number of contexts (denoted as K) that those applications need to consider grows extremely fast, ranging from tens (e.g., cancer types in TCGA (Network et al., 2011)) to thousands (e.g., number of subjects in openfMRI (Poldrack et al., 2013)).",1 Introduction,[0],[0]
"The number of variables (denoted as p) ranges from hundreds (e.g., number of brain regions) to tens of thousands (e.g., number of human genes).
",1 Introduction,[0],[0]
"The above data analysis problem can be formulated as jointly estimating K conditional dependency graphs G(1), G(2), . . .",1 Introduction,[0],[0]
", G(K) on a single set of p variables based on heterogeneous samples accumulated from K distinct contexts.",1 Introduction,[0],[0]
"For homogeneous data samples from a given i-th context, one typical approach is the sparse Gaussian Graphical Model (sGGM) (Lauritzen, 1996; Yuan & Lin, 2007).",1 Introduction,[0],[0]
"sGGM assumes samples are independently and identically drawn from Np(µ(i),Σ(i)), a multivariate Gaussian distribution with mean vector µ(i) and covariance matrix Σ(i).",1 Introduction,[0],[0]
"The graph structure G(i) is encoded by the sparsity pattern of the inverse covariance matrix, also named precision matrix, Ω(i).",1 Introduction,[0],[0]
Ω(i),1 Introduction,[0],[0]
:= (Σ(i))−1. Ω(i)jk = 0,1 Introduction,[0],[0]
"if and only if in G(i) an edge does not connect j-th node and k-th node (i.e., conditional independent).",1 Introduction,[0],[0]
"sGGM imposes an `1 penalty on the parameter Ω(i) to achieve a consistent estimation
under high-dimensional situations.",1 Introduction,[0],[0]
"When handling heterogeneous data samples, rather than estimating sGGM of each condition separately, a multi-task formulation that jointly estimatesK different but related sGGMs can lead to a better generalization(Caruana, 1997).
",1 Introduction,[0],[0]
"Previous studies for joint estimation of multiple sGGMs roughly fall into four categories: (Danaher et al., 2013; Mohan et al., 2013; Chiquet et al., 2011; Honorio & Samaras, 2010; Guo et al., 2011; Zhang & Wang, 2012; Zhang & Schneider, 2010; Zhu et al., 2014): (1) The first group seeks to optimize a sparsity regularized data likelihood function plus an extra penalty functionR′ to enforce structural similarity among multiple estimated networks.",1 Introduction,[0],[0]
"Joint graphical lasso (JGL) (Danaher et al., 2013) proposed an alternating direction method of multipliers (ADMM) based optimization algorithm to work with two regularization functions (`1 + R′).",1 Introduction,[0],[0]
(2) The second category tries to recover the support of Ω(i) using sparsity penalized regressions in a column by column fashion.,1 Introduction,[0],[0]
"Recently (Monti et al., 2015) proposed to learn population and subject-specific brain connectivity networks via a so-called “Mixed Neighborhood Selection” (MSN) method in this category.",1 Introduction,[0],[0]
(3) The third type of methods seeks to minimize the joint sparsity of the target precision matrices under matrix inversion constraints.,1 Introduction,[0],[0]
"One recent study, named SIMULE (Shared and Individual parts of MULtiple graphs Explicitly) (Wang et al., 2017b), automatically infers both specific edge patterns that are unique to each context and shared interactions preserved among all the contexts (i.e. by modeling each precision matrix as Ω(i) = Ω(i)I + ΩS) via the constrained `1 minimization.",1 Introduction,[0],[0]
"Following the CLIME estimator (Pang et al., 2014), the constrained `1 convex formulation can also be solved column by column via linear programming.",1 Introduction,[0],[0]
"However, all three categories of aforementioned estimators are difficult to scale up when the dimension p or the number of tasks K are large because they cannot avoid expensive steps like SVD (Danaher et al., 2013) for JGL, linear programming for SIMULE or running multiple iterations of p expensive penalized regressions in MNS.",1 Introduction,[0],[0]
"(4) The last category extends the so-called ”Elementary Estimator” graphical model (EE-GM) formulation (Yang et al., 2014b) to revise JGL’s penalized likelihood into a constrained convex program that minimizes (`1 + R′).",1 Introduction,[0],[0]
"One proposed estimator FASJEM (Wang et al., 2017a) is solved in an entry-wise manner and group-entry-wise manner that largely outperforms the speed of its JGL counterparts.",1 Introduction,[0],[0]
"More details of the related works are in Section (5).
",1 Introduction,[0],[0]
One significant caveat of state-of-the-art joint sGGM estimators is the fact that little attention has been paid to incorporating existing knowledge of the nodes or knowledge of the relationships among nodes in the models.,1 Introduction,[0],[0]
"In addition to the samples themselves, additional information is widely available in real-world applications.",1 Introduction,[0],[0]
"In fact, incorporating the
knowledge is of great scientific interest.",1 Introduction,[0],[0]
"A prime example is when estimating the functional brain connectivity networks among brain regions based on fMRI samples, the spatial position of the regions are readily available.",1 Introduction,[0],[0]
"Neuroscientists have gathered considerable knowledge regarding the spatial and anatomical evidence underlying brain connectivity (e.g., short edges and certain anatomical regions are more likely to be connected (Watts & Strogatz, 1998)).",1 Introduction,[0],[0]
Another important example is the problem of identifying gene-gene interactions from patients’ gene expression profiles across multiple cancer types.,1 Introduction,[0],[0]
Learning the statistical dependencies among genes from such heterogeneous datasets can help to understand how such dependencies vary from normal to abnormal and help to discover contributing markers that influence or cause the diseases.,1 Introduction,[0],[0]
"Besides the patient samples, state-ofthe-art bio-databases like HPRD (Prasad et al., 2009) have collected a significant amount of information about direct physical interactions among corresponding proteins, regulatory gene pairs or signaling relationships collected from high-qualify bio-experiments.
",1 Introduction,[0],[0]
"Although being strong evidence of structural patterns we aim to discover, this type of information has rarely been considered in the joint sGGM formulation of such samples.",1 Introduction,[0],[0]
"To the authors’ best knowledge, only one study named as WSIMULE tried to extend the constrained `1 minimization in SIMULE into weighted `1 for considering spatial information of brain regions in the joint discovery of heterogeneous neural connectivity graphs (Singh et al., 2017).",1 Introduction,[0],[0]
"This method was designed just for the neuroimaging samples and has O(p5K4) time cost, making it not scalable for large-scale settings (more details in Section 3).
",1 Introduction,[0],[0]
This paper aims to fill this gap by adding additional knowledge most effectively into scalable and fast joint sGGM estimations.,1 Introduction,[0],[0]
"We propose a novel model, namely Joint Elementary Estimator incorporating additional Knowledge (JEEK), that presents a principled and scalable strategy to include additional knowledge when estimating multiple related sGGMs jointly.",1 Introduction,[0],[0]
"Briefly speaking, this paper makes the following contributions:
• Novel approach: JEEK presents a new way of integrating additional knowledge in learning multi-task sGGMs in a scalable way.",1 Introduction,[0],[0]
(Section 3) •,1 Introduction,[0],[0]
Fast optimization: We optimize JEEK through an entrywise and group-entry-wise manner that can dramatically improve the time complexity to O(p2K4).,1 Introduction,[0],[0]
(Section 3.4) •,1 Introduction,[0],[0]
Convergence rate: We theoretically prove the convergence rate of JEEK asO(log(Kp)/ntot).,1 Introduction,[0],[0]
This rate shows the benefit of joint estimation and achieves the same convergence rate as the state-of-the-art that are much harder to compute.,1 Introduction,[0],[0]
"(Section 4) • Evaluation: We evaluate JEEK using several synthetic datasets and two real-world data, one from neuroscience and one from genomics.",1 Introduction,[0],[0]
"It outperforms state-of-the-art
baselines significantly regarding the speed.",1 Introduction,[0],[0]
"(Section 6)
JEEK provides the flexibility of using (K + 1) different weight matrices representing the extra knowledge.",1 Introduction,[0],[0]
"We try to showcase a few possible designs of the weight matrices in Section S:5, including (but not limited to):
• Spatial or anatomy knowledge about brain regions; • Knowledge of known co-hub nodes or perturbed nodes;",1 Introduction,[0],[0]
"• Known group information about nodes, such as genes
belonging to the same biological pathway or cellular location; • Using existing known edges as the knowledge, like the known protein interaction databases for discovering gene networks (a semi-supervised setting for such estimations).
",1 Introduction,[0],[0]
"We sincerely believe the scalability and flexibility provided by JEEK can make structure learning of joint sGGM feasible in many real-world tasks.
",1 Introduction,[0],[0]
"Att: Due to space limitations, we have put details of certain contents (e.g., proofs) in the appendix.",1 Introduction,[0],[0]
Notations with “S:” as the prefix in the numbering mean the corresponding contents are in the appendix.,1 Introduction,[0],[0]
"For example, full proofs are in Section (S:3).
",1 Introduction,[0],[0]
Notations: math notations we use are described in Section (S:1).,1 Introduction,[0],[0]
ntot = K∑ i=1,1 Introduction,[0],[0]
ni is the total number of data samples.,1 Introduction,[0],[0]
"Sparse Gaussian graphical model (sGGM):The classic formulation of estimating sparse Gaussian Graphical model (Yuan & Lin, 2007) from a single given condition (single sGGM) is the “graphical lasso” estimator (GLasso) (Yuan & Lin, 2007; Banerjee et al., 2008).",2 Background,[0],[0]
"It solves the following `1 penalized maximum likelihood estimation (MLE) problem:
argmin Ω>0
− log det(Ω)+ < Ω, Σ̂ > +λn||Ω||1 (2.1)
M-Estimator with Decomposable Regularizer in High-Dimensional Situations:",2 Background,[0],[0]
"Recently the seminal study (Negahban et al., 2009) proposed a unified framework for highdimensional analysis of the following general formulation: M-estimators with decomposable regularizers:
argmin θ L(θ) + λnR(θ) (2.2)
where R(·) represents a decomposable regularization function and L(·) represents a loss function (e.g., the negative log-likelihood function in sGGM L(Ω) =",2 Background,[0],[0]
− log det(Ω)+ <,2 Background,[0],[0]
"Ω, Σ̂ >).",2 Background,[0],[0]
"Here λn > 0 is the tuning parameter.
",2 Background,[0],[0]
"Elementary Estimators (EE): Using the analysis framework from (Negahban et al., 2009), recent studies (Yang
et al., 2014a;b;c) propose a new category of estimators named “Elementary estimator” (EE) with the following general formulation:
argmin θ R(θ) subject to:R∗(θ − θ̂n) ≤ λn (2.3)
",2 Background,[0],[0]
"WhereR∗(·) is the dual norm ofR(·),
R∗(v) := sup u6=0
< u, v >
R(u) = sup R(u)≤1",2 Background,[0],[0]
"< u, v > .",2 Background,[0],[0]
"(2.4)
",2 Background,[0],[0]
The solution of Eq.,2 Background,[0],[0]
(2.3) achieves the near optimal convergence rate as Eq.,2 Background,[0],[0]
(2.2) when satisfying certain conditions.,2 Background,[0],[0]
"R(·) represents a decomposable regularization function (e.g., `1-norm) andR∗(·) is the dual norm ofR(·) (e.g., `∞-norm is the dual norm of `1-norm).",2 Background,[0],[0]
"λn is a regularization parameter.
",2 Background,[0],[0]
The basic motivation of Eq.,2 Background,[0],[0]
"(2.3) is to build simpler and possibly fast estimators, that yet come with statistical guarantees that are nonetheless comparable to regularized MLE. θ̂n needs to be carefully constructed, well-defined and closedform for the purpose of simpler computations.",2 Background,[0],[0]
The formulation defined by Eq.,2 Background,[0],[0]
(2.3) is to ensure its solution having the desired structure defined by R(·).,2 Background,[0],[0]
"For cases of highdimensional estimation of linear regression models, θ̂n can be the classical ridge estimator that itself is closed-form and with strong statistical convergence guarantees in highdimensional situations.
",2 Background,[0],[0]
"EE-sGGM:(Yang et al., 2014b) proposed elementary estimators for graphical models (GM) of exponential families, in which θ̂n represents so-called proxy of backward mapping for the target GM (more details in Section S:4).",2 Background,[0],[0]
"The key idea (summarized in the upper row of Figure 1) is to investigate the vanilla MLE and where it breaks down for estimating a graphical model of exponential families in the case of high-dimensions (Yang et al., 2014b).",2 Background,[0],[0]
Essentially the vanilla graphical model MLE can be expressed as a backward mapping that computes the model parameters from some given moments in an exponential family distribution.,2 Background,[0],[0]
"For instance, in the case of learning Gaussian GM (GGM) with vanilla MLE, the backward mapping is Σ̂−1 that estimates Ω from the sample covariance matrix (moment) Σ̂.",2 Background,[0],[0]
"We introduce the details of backward mapping in Section S:4.
",2 Background,[0],[0]
"However, even though this backward mapping has a simple closed form for GGM, the backward mapping is normally not well-defined in high-dimensional settings.",2 Background,[0],[0]
"When given the sample covariance Σ̂, we cannot just compute the vanilla MLE solution as [Σ̂]−1 for GGM since Σ̂ is rankdeficient when p >",2 Background,[0],[0]
n.,2 Background,[0],[0]
"Therefore Yang et al. (Yang et al., 2014b) used carefully constructed proxy backward maps as θ̂n =",2 Background,[0],[0]
[Tv(Σ̂)] −1,2 Background,[0],[0]
"that is both available in closed-form, and
well-defined in high-dimensional settings for GGMs.",2 Background,[0],[0]
We introduce the details of [Tv(Σ̂)]−1 and its statistical property in Section S:4.,2 Background,[0],[0]
Now,2 Background,[0],[0]
Eq.,2 Background,[0],[0]
"(2.3) becomes the following closed-form estimator for learning sparse Gaussian graphical models (Yang et al., 2014b):
argmin Ω ||Ω||1,,off
",2 Background,[0],[0]
subject to:||Ω−,2 Background,[0],[0]
"[Tv(Σ̂)]−1||∞,off ≤ λn (2.5)
Eq. (2.5) is a special case of Eq.",2 Background,[0],[0]
"(2.3), in whichR(·) is the off-diagonal `1-norm and the precision matrix Ω is the θ we search for.",2 Background,[0],[0]
"When R(·) is the `1-norm, the solution of Eq.",2 Background,[0],[0]
(2.3) (and Eq. (2.5)) just needs to perform entry-wise thresholding operations on θ̂n to ensure the desired sparsity structure of its final solution.,2 Background,[0],[0]
"In applications of Gaussian graphical models, we typically have more information than just the data samples themselves.",3 Proposed Method: JEEK,[0],[0]
"This paper aims to propose a simple, scalable and theoretically-guaranteed joint estimator for estimating multiple sGGMs with additional knowledge in large-scale situations.",3 Proposed Method: JEEK,[1.0],"['This paper aims to propose a simple, scalable and theoretically-guaranteed joint estimator for estimating multiple sGGMs with additional knowledge in large-scale situations.']"
"We first propose to jointly estimate multiple related sGGMs from K data blocks using the following formulation:
argmin Ω(1),Ω(2),...,Ω(K) K∑ i=1 L(Ω(i))",3.1 A Joint EE (JEE) Formulation,[0],[0]
"+ λnR(Ω(1),Ω(2), . .",3.1 A Joint EE (JEE) Formulation,[0],[0]
.,3.1 A Joint EE (JEE) Formulation,[0],[0]
",Ω(K))
(3.1)
where Ω(i) denotes the precision matrix for i-th task.",3.1 A Joint EE (JEE) Formulation,[0],[0]
L(Ω) =,3.1 A Joint EE (JEE) Formulation,[0],[0]
− log det(Ω)+ <,3.1 A Joint EE (JEE) Formulation,[0],[0]
"Ω, Σ̂ > describes the negative log-likelihood function in sGGM. Ω(i) 0 means that Ω(i) needs to be a positive definite matrix.",3.1 A Joint EE (JEE) Formulation,[0],[0]
"R(·) represents a decomposable regularization function enforcing sparsity and structure assumptions (details in Section (3.2)).
",3.1 A Joint EE (JEE) Formulation,[0],[0]
"For ease of notation, we denote that Ωtot = (Ω(1),Ω(2), . . .",3.1 A Joint EE (JEE) Formulation,[0],[0]
",Ω(K))",3.1 A Joint EE (JEE) Formulation,[0],[0]
"and Σtot = (Σ(1),Σ(2), . . .",3.1 A Joint EE (JEE) Formulation,[0],[0]
",Σ(K)).
",3.1 A Joint EE (JEE) Formulation,[0],[0]
Ωtot and Σtot are both p,3.1 A Joint EE (JEE) Formulation,[0],[0]
"× Kp matrices (i.e., Kp2 parameters to estimate).",3.1 A Joint EE (JEE) Formulation,[0],[0]
"Now define an inverse function as inv(Atot) := (A(1) −1 , A(2) −1 , . . .",3.1 A Joint EE (JEE) Formulation,[0],[0]
", A(K) −1 ), where Atot is a given p ×Kp matrix with the same structure as Σtot.",3.1 A Joint EE (JEE) Formulation,[0],[0]
Then we rewrite Eq.,3.1 A Joint EE (JEE) Formulation,[0],[0]
"(3.1) into the following form:
argmin Ωtot
L(Ωtot) + λnR(Ωtot) (3.2)
Now connecting Eq. (3.2) to Eq. (2.2) and Eq. (2.3), we propose the following joint elementary estimator (JEE) for learning multiple sGGMs:
argmin Ωtot
R(Ωtot)
subject to: R∗(Ωtot − Ω̂totntot) ≤ λn (3.3)
",3.1 A Joint EE (JEE) Formulation,[0],[0]
The fundamental component in Eq.,3.1 A Joint EE (JEE) Formulation,[0],[0]
(2.3) for the single context sGGM was to use a well-defined proxy function to approximate the vanilla MLE solution (named as the backward mapping for exponential family distributions),3.1 A Joint EE (JEE) Formulation,[0],[0]
"(Yang et al., 2014b).",3.1 A Joint EE (JEE) Formulation,[0],[0]
The proposed proxy θ̂n =,3.1 A Joint EE (JEE) Formulation,[0],[0]
[Tv(Σ̂)]−1 is both well-defined under high-dimensional situations and also has a simple closed-form.,3.1 A Joint EE (JEE) Formulation,[0],[0]
"Following a similar idea, when learning multiple sGGMs, we propose to use inv(Tv(Σ̂tot)) for Ω̂totntot and get the following joint elementary estimator:
argmin Ωtot
R(Ωtot)
",3.1 A Joint EE (JEE) Formulation,[0],[0]
Subject to: R∗(Ωtot − inv(Tv(Σ̂tot))),3.1 A Joint EE (JEE) Formulation,[0],[0]
≤ λn (3.4),3.1 A Joint EE (JEE) Formulation,[0],[0]
The main goal of this paper is to design a principled strategy to incorporate existing knowledge (other than samples or structured assumptions) into the multi-sGGM formulation.,3.2 Knowledge as Weight (KW-Norm),[0],[0]
"We consider two factors in such a design:
(1) When learning multiple sGGMs jointly from real-world applications, it is often of great scientific interests to model and learn context-specific graph variations explicitly, because such variations can “fingerprint” important markers in domains like cognition (Ideker & Krogan, 2012) or pathology (Kelly et al., 2012).",3.2 Knowledge as Weight (KW-Norm),[0],[0]
Therefore we design to share parameters between different contexts.,3.2 Knowledge as Weight (KW-Norm),[0],[0]
"Mathematically, we model Ω(i) as two parts:
Ω(i) =",3.2 Knowledge as Weight (KW-Norm),[0],[0]
"Ω (i) I + ΩS (3.5)
where Ω(i)I is the individual precision matrix for context i and ΩS is the shared precision matrix between contexts.",3.2 Knowledge as Weight (KW-Norm),[0],[0]
"Again, for ease of notation we denote ΩtotI = (Ω
(1) I ,Ω (2) I , . . .",3.2 Knowledge as Weight (KW-Norm),[0],[0]
",Ω (K) I ) and Ω tot S = (ΩS ,ΩS , . . .",3.2 Knowledge as Weight (KW-Norm),[0],[0]
",ΩS).
(2) We represent additional knowledge as positive weight matrices from Rp×p.",3.2 Knowledge as Weight (KW-Norm),[0],[0]
"More specifically, we represent
the knowledge of the task-specific graph as weight matrix {W (i)} and WS representing existing knowledge of the shared network.",3.2 Knowledge as Weight (KW-Norm),[0],[0]
The positive matrix-based representation is a powerful and flexible strategy that can describe many possible forms of existing knowledge.,3.2 Knowledge as Weight (KW-Norm),[0],[0]
"In Section (S:5), we provide a few different designs of {W (i)} and WS for real-world applications.",3.2 Knowledge as Weight (KW-Norm),[0],[0]
"In total, we have weight matrices {W (1)I ,W (2) I , . . .",3.2 Knowledge as Weight (KW-Norm),[0],[0]
",W (K) I ,WS} to represent additional knowledge.",3.2 Knowledge as Weight (KW-Norm),[0],[0]
"To simplify notations, we denote W totI = (W (1) I ,W (2), . . .",3.2 Knowledge as Weight (KW-Norm),[0],[0]
",W (K) I ) and W tot S = (WS ,WS , . . .",3.2 Knowledge as Weight (KW-Norm),[0],[0]
",WS).
",3.2 Knowledge as Weight (KW-Norm),[0],[0]
"Now we propose the following knowledge as weight norm (kw-norm) combining the above two:
R(Ωtot) = ||W totI ◦ ΩtotI ||1 + ||W",3.2 Knowledge as Weight (KW-Norm),[0],[0]
"totS ◦ ΩtotS ||1 (3.6)
",3.2 Knowledge as Weight (KW-Norm),[0],[0]
Here the Hadamard product ◦ is the element-wise product between two matrices i.e. [A ◦B]ij = AijBij .,3.2 Knowledge as Weight (KW-Norm),[0],[0]
"The kw-norm( Eq. (3.6)) has the following three properties:
• (i) kw-norm is a norm function if and only if any entries in W totI and W tot S do not equal to 0.",3.2 Knowledge as Weight (KW-Norm),[0],[0]
• (ii),3.2 Knowledge as Weight (KW-Norm),[0],[0]
"If the condition in (i) holds, kw-norm is a decomposable norm.",3.2 Knowledge as Weight (KW-Norm),[0],[0]
• (iii),3.2 Knowledge as Weight (KW-Norm),[0],[0]
"If the condition in (i) holds, the dual norm of kwnorm isR∗(u) = max(||W totI ◦ u||∞, ||W totS ◦ u||∞).
",3.2 Knowledge as Weight (KW-Norm),[0],[0]
Section S:3.1 provides proofs of the above claims.,3.2 Knowledge as Weight (KW-Norm),[0],[0]
"Plugging Eq. (3.6) to Eq. (3.4), we obtain the following formulation of JEEK for learning multiple related sGGMs from heterogereous samples:
argmin ΩtotI ,Ω tot S
||W totI ◦ ΩtotI ||1 + ||W",3.3 JEE with Knowledge (JEEK),[0],[0]
"totS ◦ ΩtotS ||
Subject to: ||W totI ◦ (Ωtot − inv(Tv(Σ̂tot)))||∞ ≤ λn ||W totS ◦",3.3 JEE with Knowledge (JEEK),[0],[0]
(Ωtot − inv(Tv(Σ̂tot)))||∞ ≤ λn Ωtot = ΩtotS + Ω,3.3 JEE with Knowledge (JEEK),[0],[0]
"tot I
(3.7)
",3.3 JEE with Knowledge (JEEK),[0],[0]
"In Section 4, we theoretically prove that the statistical convergence rate of JEEK achieves the same sharp convergence rate as the state-of-the-art estimators for multi-task sGGMs.",3.3 JEE with Knowledge (JEEK),[0],[0]
"Our proofs are inspired by the unified framework of the high-dimensional statistics (Negahban et al., 2009).",3.3 JEE with Knowledge (JEEK),[0],[0]
A huge computational advantage of JEEK (Eq. (3.7)) is that it can be decomposed into p × p independent small linear programming problems.,3.4 Solution of JEEK:,[0],[0]
"To simplify notations, we denote Ω(i)I j,k (the {j, k}-th entry of Ω (i))",3.4 Solution of JEEK:,[0],[0]
as ai.,3.4 Solution of JEEK:,[0],[0]
"Similarly
Algorithm 1.",3.4 Solution of JEEK:,[0],[0]
"Joint Elementary Estimator with additional knowledge (JEEK) for Multi-task sGGMs Input: Data sample matrix X(i) ( i = 1 toK), regularization hyperparameter λn, Knowledge weight matrices {W (i)I ,WS} and LP(.)",3.4 Solution of JEEK:,[1.0],"['Joint Elementary Estimator with additional knowledge (JEEK) for Multi-task sGGMs Input: Data sample matrix X(i) ( i = 1 toK), regularization hyperparameter λn, Knowledge weight matrices {W (i)I ,WS} and LP(.)']"
(a linear programming solver),3.4 Solution of JEEK:,[0],[0]
"Output: {Ω(i)} ( i = 1 toK)
1: for i = 1 toK do 2: Initialize Σ̂(i) = 1ni−1 ∑ni",3.4 Solution of JEEK:,[0],[0]
"s=1(X (i) s, −µ̂ (i))(X(i)s, −µ̂ (i))T (the sample
covariance matrix of X(i))",3.4 Solution of JEEK:,[0],[0]
3: Initialize Ω(i) = 0p×p,3.4 Solution of JEEK:,[0],[0]
4: Calculate the proxy backward mapping [Tv(Σ̂(i))]−1 5: end for 6: for j = 1 to p do 7: for k = 1 to j do 8: ci =,3.4 Solution of JEEK:,[0],[0]
"[Tv(Σ̂(i))]−1j,k 9: wi = W (i)j,k 10: ws = WSj,k 11: ai, b = LP(wi, ws, ci, λn) where i = 1, . . .",3.4 Solution of JEEK:,[0],[0]
", K and LP(.) solves Eq.",3.4 Solution of JEEK:,[0],[0]
"(3.8) 12: for i = 1 toK do 13: Ω(i)j,k = Ω(i)k,j = ai + b 14: Ω(i)I j,k = ai 15: ΩSj,k = b 16: end for 17: end for 18: end for
we denote ΩSj,k as b and [Tv(Σ̂(i))",3.4 Solution of JEEK:,[0],[0]
] −1,3.4 Solution of JEEK:,[0],[0]
"j,k be ci.",3.4 Solution of JEEK:,[0],[0]
"Similarly we denote W (i)j,k = wi and W S j,k = ws. ”",3.4 Solution of JEEK:,[0],[0]
"A group of entries” means a set of parameters {a1, . . .",3.4 Solution of JEEK:,[0],[0]
", aK , b} for certain j, k.",3.4 Solution of JEEK:,[0],[0]
"In order to estimate {a1, . . .",3.4 Solution of JEEK:,[0],[0]
", aK , b}, JEEK (Eq. (3.7)) can be decomposed into the following formulation for a certain j, k :
argmin ai,b ∑",3.4 Solution of JEEK:,[0],[0]
"i |wiai|+K|wsb|
Subject to: |ai + b− ci| ≤",3.4 Solution of JEEK:,[0],[0]
"λn
min(wi, ws) ,
i = 1, . .",3.4 Solution of JEEK:,[0],[0]
.,3.4 Solution of JEEK:,[0],[0]
",K
(3.8)
Eq. (3.8) can be easily converted into a linear programming form of Eq.",3.4 Solution of JEEK:,[0],[0]
(S:1–1),3.4 Solution of JEEK:,[0],[0]
with only K + 1 variables.,3.4 Solution of JEEK:,[0],[0]
The time complexity of Eq.,3.4 Solution of JEEK:,[0],[0]
(3.8) is O(K4).,3.4 Solution of JEEK:,[0],[0]
Considering JEEK has a total p(p,3.4 Solution of JEEK:,[0],[0]
"− 1)/2 of such subproblems to solve, the computational complexity of JEEK (Eq. (3.7)) is therefore O(p2K4).",3.4 Solution of JEEK:,[0],[0]
We summarize the optimization algorithm of JEEK in Algorithm 1 (details in Section (S:1.2)).,3.4 Solution of JEEK:,[0],[0]
KW-Norm:We presented the three properties of kw-norm in Section 3.2.,4 Theoretical Analysis,[0],[0]
"The proofs of these three properties are included in Section (S:3.1).
",4 Theoretical Analysis,[0],[0]
"Theoretical error bounds of Proxy Backward Mapping: (Yang et al., 2014b) proved that when (p ≥ n), the proxy backward mapping [Tv(Σ̂)]−1 used by EE-sGGM achieves the sharp convergence rate to its truth (i.e., by proving
||Tv(Σ̂))−1",4 Theoretical Analysis,[0],[0]
− Σ∗−1||∞ = O( √ log p n )).,4 Theoretical Analysis,[0],[0]
"The proof was extended from the previous study (Rothman et al., 2009) that
devised Tv(Σ̂) for estimating covariance matrix consistently in high-dimensional situations.",4 Theoretical Analysis,[0],[0]
See detailed proofs in Section S:4.3.,4 Theoretical Analysis,[0],[0]
"To derive the statistical error bound of JEEK, we need to assume that inv(Tv(Σ̂tot)) are well-defined.",4 Theoretical Analysis,[0],[0]
"This is ensured by assuming that the true Ω(i) ∗ satisfy the conditions defined in Section (S:3.1).
",4 Theoretical Analysis,[0],[0]
"Theoretical error bounds of JEEK:We now use the highdimensional analysis framework from (Negahban et al., 2009), three properties of kw-norm, and error bounds of backward mapping from (Rothman et al., 2009; Yang et al., 2014b) to derive the statistical convergence rates of JEEK.",4 Theoretical Analysis,[0],[0]
"Detailed proofs of the following theorems are in Section 4 .
",4 Theoretical Analysis,[0],[0]
"Before providing the theorem, we need to define the structural assumption, the IS-Sparsity, we assume for the parameter truth.",4 Theoretical Analysis,[0],[0]
(IS-Sparsity): The ’true’ parameter of Ωtot∗ can be decomposed into two clear structures–{ΩtotI ∗ and ΩtotS ∗}.,4 Theoretical Analysis,[0],[0]
"ΩtotI ∗ is exactly sparse with ki non-zero entries indexed by a support set SI and ΩtotS ∗ is exactly sparse with ks
non-zero entries indexed by a support set SS .",4 Theoretical Analysis,[0],[0]
SI,4 Theoretical Analysis,[0],[0]
"⋂ SS = ∅.
All other elements equal to 0 (in (SI ⋃ SS) c).
",4 Theoretical Analysis,[0],[0]
Theorem 4.1.,4 Theoretical Analysis,[0],[0]
Consider Ωtot whose true parameter Ωtot∗ satisfies the (IS-Sparsity) assumption.,4 Theoretical Analysis,[1.0],['Consider Ωtot whose true parameter Ωtot∗ satisfies the (IS-Sparsity) assumption.']
Suppose we compute the solution of Eq. (3.7) with a bounded λn such that λn ≥ max(||W totI ◦,4 Theoretical Analysis,[0],[0]
"(Ωtot
∗− inv(Tv(Σ̂tot)))||∞, ||W totS ◦",4 Theoretical Analysis,[0],[0]
"(Ωtot
∗ − inv(Tv(Σ̂tot)))||∞), then the estimated solution Ω̂tot satisfies the following error bounds:
||Ω̂tot",4 Theoretical Analysis,[0],[0]
− Ωtot∗||F ≤ 4,4 Theoretical Analysis,[0],[0]
√ ki + ksλn max(||W,4 Theoretical Analysis,[0],[0]
totI ◦,4 Theoretical Analysis,[0],[0]
"(Ω̂tot − Ωtot ∗ )||∞, ||W totS ◦ (Ω̂tot − Ωtot
∗||∞) ≤ 2λn
||W totI ◦ (Ω̂totI − ΩtotI ∗ )||1 + ||W",4 Theoretical Analysis,[0],[0]
totS ◦,4 Theoretical Analysis,[0],[0]
"(Ω̂totS − ΩtotS ∗ )||1
≤ 8(ki + ks)λn",4 Theoretical Analysis,[0],[0]
"(4.1)
Proof.",4 Theoretical Analysis,[0],[0]
"See detailed proof in Section S:3.2
Theorem (4.1) provides a general bound for any selection of λn.",4 Theoretical Analysis,[0],[0]
"The bound of λn is controlled by the distance between Ωtot
∗ and inv(Tv(Σ̂tot)).",4 Theoretical Analysis,[0],[0]
We then extend Theorem (4.1) to derive the statistical convergence rate of JEEK.,4 Theoretical Analysis,[0],[0]
This gives us the following corollary: Corollary 4.2.,4 Theoretical Analysis,[0],[0]
"Suppose the high-dimensional setting, i.e., p > max(ni).",4 Theoretical Analysis,[0],[0]
Let v := a √ log(Kp) ntot .,4 Theoretical Analysis,[0],[0]
"Then for
λn := 8κ1a κ2 √ log(Kp) ntot
and ntot > c logKp, with a probability of at least 1− 2C1 exp(−C2Kp log(Kp)), the estimated optimal solution Ω̂tot has the following error bound:
||Ω̂tot−Ωtot∗||F
≤ 16κ1amax j,k (W totI j,k,W tot S j,k)
κ2
√ (ki + ks) log(Kp)
",4 Theoretical Analysis,[0],[0]
"ntot (4.2)
where a, c, κ1 and κ2 are constants.
",4 Theoretical Analysis,[0],[0]
Proof.,4 Theoretical Analysis,[0],[0]
See detailed proof in Section S:3.2.2 (especially from Eq.,4 Theoretical Analysis,[0],[0]
(S:3–11) to Eq.,4 Theoretical Analysis,[0],[0]
"(S:3–19)).
",4 Theoretical Analysis,[0],[0]
Bayesian View of JEEK:,4 Theoretical Analysis,[0],[0]
In Section (S:2) we provide a direct Bayesian interpretation of JEEK through the perspective of hierarchical Bayesian modeling.,4 Theoretical Analysis,[0],[0]
Our hierarchical Bayesian interpretation nicely explains the assumptions we make in JEEK.,4 Theoretical Analysis,[0],[0]
JEEK is closely related to a few state-of-the-art studies summarized in Table 1.,5 Connecting to Relevant Studies,[0],[0]
"We compare the time complexity and functional properties of JEEK versus these studies.
NAK: (Bu & Lederer, 2017)For the single task sGGM, one recent study (Bu & Lederer, 2017) (following ideas from (Shimamura et al., 2007)) proposed to integrating Additional Knowledge (NAK)into estimation of graphical models through a weighted Neighbourhood selection formulation (NAK) as: β̂j = argmin
β,βj=0
1 2 ||X j−Xβ||22 + ||rj ◦β||1.
NAK is designed for estimating brain connectivity networks from homogeneous samples and incorporate distance knowledge as weight vectors.",5 Connecting to Relevant Studies,[0],[0]
1,5 Connecting to Relevant Studies,[0],[0]
"In experiments, we compare JEEK to NAK (by running NAK R package K times) on multiple synthetic datasets of simulated samples about brain regions.",5 Connecting to Relevant Studies,[0],[0]
"The data simulation strategy was suggested by (Bu & Lederer, 2017).",5 Connecting to Relevant Studies,[0],[0]
"Same as the NAK (Bu & Lederer, 2017), we use the spatial distance among brain regions as additional knowledge in JEEK.
",5 Connecting to Relevant Studies,[0],[0]
"W-SIMULE: (Singh et al., 2017)Like JEEK, one recent study (Singh et al., 2017) of multi-sGGMs (following ideas from (Wang et al., 2017b)) also assumed that Ω(i) = Ω
(i)",5 Connecting to Relevant Studies,[0],[0]
"I + ΩS and incorporated spatial distance knowl-
edge in their convex formulation for joint discovery of heterogeneous neural connectivity graphs.",5 Connecting to Relevant Studies,[0],[0]
"This study, with name W-SIMULE (Weighted model for Shared and Individual parts of MULtiple graphs Explicitly) uses a weighted constrained `1 minimization:
argmin Ω (i) I ,ΩS
∑ i ||W ◦ Ω(i)I ||1 + K||W ◦ ΩS ||1 (5.1)
",5 Connecting to Relevant Studies,[0],[0]
"Subject to: ||Σ(i)(Ω(i)I + ΩS)− I||∞ ≤ λn, i = 1, . . .",5 Connecting to Relevant Studies,[0],[0]
", K
1Here β̂j indicates the sparsity of j-th column of a single Ω̂. Namely, β̂jk = 0 if and only if Ω̂k,j = 0.",5 Connecting to Relevant Studies,[0],[0]
"rj is a weight vector as the additional knowledge The NAK formulation can be solved by a classic Lasso solver like glmnet.
",5 Connecting to Relevant Studies,[0],[0]
W-SIMULE simply includes the additional knowledge as a weight matrix W .,5 Connecting to Relevant Studies,[0],[0]
"2
Different from W-SIMULE, JEEK separates the knowledge of individual context and the shared using different weight matrices.",5 Connecting to Relevant Studies,[0],[0]
"While W-SIMULE also minimizes a weighted `1 norm, its constraint optimization term is entirely different from JEEK.",5 Connecting to Relevant Studies,[0],[0]
The formulation difference makes the optimization of JEEK much faster and more scalable than WSIMULE (Section (6)).,5 Connecting to Relevant Studies,[0],[0]
"We have provided a complete theoretical analysis of error bounds of JEEK, while W-SIMULE provided no theoretical results.",5 Connecting to Relevant Studies,[0],[0]
"Empirically, we compare JEEK with W-SIMULE R package from (Singh et al., 2017) in the experiments.
",5 Connecting to Relevant Studies,[0],[0]
"JGL: (Danaher et al., 2013): Regularized MLE based multi-sGGMs Studies mostly follow the so called joint graphical lasso (JGL) formulation as Eq.",5 Connecting to Relevant Studies,[1.0],"['JGL: (Danaher et al., 2013): Regularized MLE based multi-sGGMs Studies mostly follow the so called joint graphical lasso (JGL) formulation as Eq.']"
"(5.2):
argmin Ω(i) 0 K∑ i=1",5 Connecting to Relevant Studies,[0],[0]
(−L(Ω(i)),5 Connecting to Relevant Studies,[0],[0]
+ λn K∑ i=1,5 Connecting to Relevant Studies,[0],[0]
"||Ω(i)||1
",5 Connecting to Relevant Studies,[0],[0]
+ λ ′,5 Connecting to Relevant Studies,[0],[0]
nR ′,5 Connecting to Relevant Studies,[0],[0]
"(Ω (1) ,Ω (2) , . . .",5 Connecting to Relevant Studies,[0],[0]
",Ω (K) )
(5.2)
R′(·) is the second penalty function for enforcing some structural assumption of group property among the multiple graphs.",5 Connecting to Relevant Studies,[0],[0]
One caveat of JGL is that R′(·) cannot model explicit additional knowledge.,5 Connecting to Relevant Studies,[0],[0]
"For instance,it can not incorporate the information of a few known hub nodes shared by the contexts.",5 Connecting to Relevant Studies,[0],[0]
"In experiments, we compare JEEK to JGLco-hub and JGL-perturb-hub toolbox provided by (Mohan et al., 2013).
",5 Connecting to Relevant Studies,[0],[0]
"FASJEM: (Wang et al., 2017a)",5 Connecting to Relevant Studies,[0],[0]
One very recent study extended JGL using so-called Elementary superpositionstructured moment estimator formulation as Eq.,5 Connecting to Relevant Studies,[0],[0]
"(5.3):
argmin Ωtot
||Ωtot||1 + R′(Ωtot)
s.t.||Ωtot",5 Connecting to Relevant Studies,[0],[0]
− inv(Tv(Σ̂tot))||∞ ≤ λn R′∗(Ωtot − inv(Tv(Σ̂tot))),5 Connecting to Relevant Studies,[0],[0]
≤,5 Connecting to Relevant Studies,[0],[0]
"λn
(5.3)
",5 Connecting to Relevant Studies,[0],[0]
FASJEM is much faster and more scalable than the JGL estimators.,5 Connecting to Relevant Studies,[0],[0]
However like JGL estimators it can not model additional knowledge and its optimization needs to be carefully re-designed for differentR′(·).,5 Connecting to Relevant Studies,[0],[0]
"3
2It can be solved by any linear programming solver and can be column-wise paralleled.",5 Connecting to Relevant Studies,[0],[0]
"However, it is very slow when p > 200 due to the expensive computation cost O(K4p5).
",5 Connecting to Relevant Studies,[0],[0]
3FASJEM extends JGL into multiple independent group-entry wise optimization just like JEEK.,5 Connecting to Relevant Studies,[0],[0]
"HereR
′∗(·) is the dual norm of R′(·).",5 Connecting to Relevant Studies,[0],[0]
"Because (Wang et al., 2017a) only designs the optimization of two cases (group,2 and group,inf), we can not use it as a baseline.
",5 Connecting to Relevant Studies,[0],[0]
Both NAK and W-SIMULE only explored the formulation for estimating neural connectivity graphs using spatial information as additional knowledge.,5 Connecting to Relevant Studies,[0],[0]
"Differently our experiments (Section (6)) extend the weight-as-knowledge formulation on weights as distance, as shared hub knowledge, as perturbed hub knowledge, and as nodes’ grouping information (e.g., multiple genes are known to be in the same pathway).",5 Connecting to Relevant Studies,[0],[0]
This has largely extends the previous studies in showing the real-world adaptivity of the proposed formulation.,5 Connecting to Relevant Studies,[1.0],['This has largely extends the previous studies in showing the real-world adaptivity of the proposed formulation.']
JEEK elegantly formulates existing knowledge based on the problem at hand and avoid the need to design knowledge-specific optimization.,5 Connecting to Relevant Studies,[1.0],['JEEK elegantly formulates existing knowledge based on the problem at hand and avoid the need to design knowledge-specific optimization.']
"We empirically evaluate JEEK and baselines on four types of datasets, including two groups of synthetic data, one realworld fMRI dataset for brain connectivity estimation and one real-world genomics dataset for estimating interaction among regulatory genes (results in Section (6.2)).",6 Experiments,[0],[0]
"In order to incorporating various types of knowledge, we provide five different designs of the weight matrices in Section S:5.",6 Experiments,[0],[0]
"Details of experimental setup, metrics and hyper-parameter tuning are included in Section (S:6.1).",6 Experiments,[0],[0]
Baselines used in our experiments have been explained in details by Section (5).,6 Experiments,[1.0],['Baselines used in our experiments have been explained in details by Section (5).']
"We also use JEEK with no additional knowledge (JEEKNK) as a baseline.
",6 Experiments,[0],[0]
JEEK is available as the R package ’jeek’ in CRAN.,6 Experiments,[1.0],['JEEK is available as the R package ’jeek’ in CRAN.']
"Inspired the JGL-co-hub and JGL-perturb-hub toolbox (JGL-node) provided by (Mohan et al., 2013), we empirically show JEEK’s ability to model known co-hub or perturbed-hub nodes as knowledge when estimating multiple sGGMs.",6.1 Experiment: Simulated Samples with Known Hubs as Knowledge,[0],[0]
"We generate multiple simulated Gaussian datasets through the random graph model (Rothman et al., 2008) to simulate both the co-hub and perturbed-hub graph structures (details in S:7.1).",6.1 Experiment: Simulated Samples with Known Hubs as Knowledge,[0],[0]
"We use JGL-node package, W-SIMULE and JEEK-NK as baselines for this set of experiments.",6.1 Experiment: Simulated Samples with Known Hubs as Knowledge,[0],[0]
"The weights in {W totI ,W totS } are designed using the strategy proposed in Section (S:5).
",6.1 Experiment: Simulated Samples with Known Hubs as Knowledge,[0],[0]
We use AUC score (to reflect the consistency and variance of a method’s performance when varying its important hyperparameter) and computational time cost to compare JEEK with baselines.,6.1 Experiment: Simulated Samples with Known Hubs as Knowledge,[0],[0]
"We compare all methods on many simulated cases by varying p from the set {100, 200, 300, 400, 500}",6.1 Experiment: Simulated Samples with Known Hubs as Knowledge,[0],[0]
"and the number of tasks K from the set {2, 3, 4}.",100 200 300 400 500,[0],[0]
"In Figure 2 and Figure S:1(a)(b), JEEK consistently achieves higher AUC-scores than the baselines JGL, JEEK-NK and W-SIMULE for all cases.",100 200 300 400 500,[0],[0]
JEEK is more than 10 times faster than the baselines on average.,100 200 300 400 500,[0],[0]
"In Figure 2, for each p > 300 case (with n = p/2), W-SIMULE takes more than one month and JGL takes more than one day.",100 200 300 400 500,[0],[0]
Therefore we can not show them with p > 300.,100 200 300 400 500,[0],[0]
"Next, we apply JEEK and the baselines on one real-world biomedical data about gene expression profiles across two different cell types.",6.2 Experiment: Gene Interaction Network from Real-World Genomics Data,[1.0],"['Next, we apply JEEK and the baselines on one real-world biomedical data about gene expression profiles across two different cell types.']"
We explored two different types of knowledge: (1) Known edges and (2) Known group about genes.,6.2 Experiment: Gene Interaction Network from Real-World Genomics Data,[0],[0]
Figure S:1(c) shows that JEEK has lower time cost and recovers more interactions than baselines (higher number of matched edges to the existing bio-databases.).,6.2 Experiment: Gene Interaction Network from Real-World Genomics Data,[0],[0]
More results are in Appendix Section (S:7.2) and the design of weight matrices for this case is in Section (S:5).,6.2 Experiment: Gene Interaction Network from Real-World Genomics Data,[1.0],['More results are in Appendix Section (S:7.2) and the design of weight matrices for this case is in Section (S:5).']
"Following (Bu & Lederer, 2017), we use one known Euclidean distance between human brain regions as additional knowledge W and use it to generate multiple simulated datasets (details in Section S:7.3).",6.3 Experiment: Simulated Data about Brain Connectivity with Distance as Knowledge,[0],[0]
"We compare JEEK with the baselines regarding (a) Scalability (computational time cost), and (b) effectiveness (F1-score, because NAK package does not allow AUC calculation).",6.3 Experiment: Simulated Data about Brain Connectivity with Distance as Knowledge,[0],[0]
"For each simulation case, the computation time for each estimator is the summation of a method’s execution time over all values of λn.",6.3 Experiment: Simulated Data about Brain Connectivity with Distance as Knowledge,[1.0],"['For each simulation case, the computation time for each estimator is the summation of a method’s execution time over all values of λn.']"
Figure S:2(a)(b) show clearly that JEEK outperforms its baselines.,6.3 Experiment: Simulated Data about Brain Connectivity with Distance as Knowledge,[0],[0]
JEEK has a consistently higher F1-Score and is almost 6 times faster than W-SIMULE in the high dimensional case.,6.3 Experiment: Simulated Data about Brain Connectivity with Distance as Knowledge,[0],[0]
"JEEK performs better than JEEK-NK, confirming the advantage of integrating additional distance knowledge.",6.3 Experiment: Simulated Data about Brain Connectivity with Distance as Knowledge,[0],[0]
"While NAK is fast, its F1-Score is nearly 0 and hence, not useful for multi-sGGM structure learning.",6.3 Experiment: Simulated Data about Brain Connectivity with Distance as Knowledge,[0],[0]
"We evaluate JEEK and relevant baselines for a classification task on one real-world publicly available resting-state fMRI dataset: ABIDE(Di Martino et al., 2014).",6.4 Experiment: Functional Connectivity Estimation from Real-World Brain fMRI Data,[0],[0]
"The ABIDE data aims to understand human brain connectivity and how it reflects neural disorders (Van Essen et al., 2013).",6.4 Experiment: Functional Connectivity Estimation from Real-World Brain fMRI Data,[1.0],"['The ABIDE data aims to understand human brain connectivity and how it reflects neural disorders (Van Essen et al., 2013).']"
"ABIDE includes two groups of human subjects: autism and control, and therefore we formulate it as K = 2 graph estimation.",6.4 Experiment: Functional Connectivity Estimation from Real-World Brain fMRI Data,[1.0],"['ABIDE includes two groups of human subjects: autism and control, and therefore we formulate it as K = 2 graph estimation.']"
We utilize the spatial distance between human brain regions as additional knowledge for estimating functional connectivity edges among brain regions.,6.4 Experiment: Functional Connectivity Estimation from Real-World Brain fMRI Data,[0],[0]
We use Linear Discriminant Analysis (LDA) for a downstream classification task aiming to assess the ability of a graph estimator to learn the differential patterns of the connectome structures.,6.4 Experiment: Functional Connectivity Estimation from Real-World Brain fMRI Data,[0],[0]
"(Details of the ABIDE dataset, baselines, design of the additional knowledge W matrix, cross-validation and LDA classification method are in Section (S:7.4).)
",6.4 Experiment: Functional Connectivity Estimation from Real-World Brain fMRI Data,[0],[0]
"Figure S:2(c) compares JEEK and three baselines: JEEKNK, W-SIMULE and W-SIMULE with no additional knowledge (W-SIMULE-NK).",6.4 Experiment: Functional Connectivity Estimation from Real-World Brain fMRI Data,[1.0],"['Figure S:2(c) compares JEEK and three baselines: JEEKNK, W-SIMULE and W-SIMULE with no additional knowledge (W-SIMULE-NK).']"
"JEEK yields a classification accuracy of 58.62% for distinguishing the autism subjects versus the control subjects, clearly outperforming JEEK-NK and W-SIMULE-NK.",6.4 Experiment: Functional Connectivity Estimation from Real-World Brain fMRI Data,[0],[0]
"JEEK is roughly 7 times faster than the W-SIMULE estimators, locating at the top left region in Figure S:2(c) (higher classification accuracy and lower time cost).",6.4 Experiment: Functional Connectivity Estimation from Real-World Brain fMRI Data,[1.0],"['JEEK is roughly 7 times faster than the W-SIMULE estimators, locating at the top left region in Figure S:2(c) (higher classification accuracy and lower time cost).']"
We also experimented with variations of theW matrix and found the classification results are fairly robust to the variations of W (Section (S:7.4)).,6.4 Experiment: Functional Connectivity Estimation from Real-World Brain fMRI Data,[1.0],['We also experimented with variations of theW matrix and found the classification results are fairly robust to the variations of W (Section (S:7.4)).']
"We propose a novel method, JEEK, to incorporate additional knowledge in estimating multi-sGGMs.",7 Conclusions,[1.0],"['We propose a novel method, JEEK, to incorporate additional knowledge in estimating multi-sGGMs.']"
JEEK achieves the same asymptotic convergence rate as the state-of-the-art.,7 Conclusions,[1.0],['JEEK achieves the same asymptotic convergence rate as the state-of-the-art.']
"Our experiments has showcased using weights for describing pairwise knowledge among brain regions, for shared hub knowledge, for perturbed hub knowledge, for describing group information among nodes (e.g., genes known to be in the same pathway), and for using known interaction edges as the knowledge.",7 Conclusions,[1.0],"['Our experiments has showcased using weights for describing pairwise knowledge among brain regions, for shared hub knowledge, for perturbed hub knowledge, for describing group information among nodes (e.g., genes known to be in the same pathway), and for using known interaction edges as the knowledge.']"
"We consider the problem of including additional knowledge in estimating sparse Gaussian graphical models (sGGMs) from aggregated samples, arising often in bioinformatics and neuroimaging applications.",abstractText,[0],[0]
Previous joint sGGM estimators either fail to use existing knowledge or cannot scale-up to many tasks (large K) under a highdimensional (large p) situation.,abstractText,[0],[0]
"In this paper, we propose a novel Joint Elementary Estimator incorporating additional Knowledge (JEEK) to infer multiple related sparse Gaussian Graphical models from large-scale heterogeneous data.",abstractText,[0],[0]
"Using domain knowledge as weights, we design a novel hybrid norm as the minimization objective to enforce the superposition of two weighted sparsity constraints, one on the shared interactions and the other on the task-specific structural patterns.",abstractText,[0],[0]
This enables JEEK to elegantly consider various forms of existing knowledge based on the domain at hand and avoid the need to design knowledgespecific optimization.,abstractText,[0],[0]
JEEK is solved through a fast and entry-wise parallelizable solution that largely improves the computational efficiency of the state-of-the-art O(pK) to O(pK).,abstractText,[0],[0]
We conduct a rigorous statistical analysis showing that JEEK achieves the same convergence rate O(log(Kp)/ntot) as the state-of-the-art estimators that are much harder to compute.,abstractText,[0],[0]
"Empirically, on multiple synthetic datasets and two real-world data, JEEK outperforms the speed of the state-ofarts significantly while achieving the same level of prediction accuracy.",abstractText,[0],[0]
"Department of Computer Science, University of Virginia, http://www.jointnets.org/ .",abstractText,[0],[0]
"Correspondence to: Beilun Wang <bw4mw@virginia.edu>, Yanjun Qi <yanjun@virginia.edu>.",abstractText,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",abstractText,[0],[0]
Copyright 2018 by the author(s).,abstractText,[0],[0]
A Fast and Scalable Joint Estimator for Integrating Additional Knowledge in Learning Multiple Related Sparse Gaussian Graphical Models,title,[0],[0]

0	18	Single-document summarization methods can be divided into two categories: extractive and abstractive.
1	82	Extractive summarization systems form summaries by selecting and copying text snippets from the document, while abstractive methods aim to generate concise summaries with paraphrasing.
2	21	This work is primarily concerned with extractive summarization.
3	69	Though abstractive summarization methods have made strides in recent years, extractive techniques are still very attractive as they are simpler, faster, and more reliably yield semantically and grammatically correct sentences.
4	20	Many extractive summarizers work by selecting sentences from the input document (Luhn, 1958; Mihalcea and Tarau, 2004; Wong et al., 2008; Kågebäck et al., 2014; Yin and Pei, 2015; Cao et al., 2015; Yasunaga et al., 2017).
6	45	Recurrent neural networks may be trained with stochastic gradient ascent to maximize the likelihood of a set of ground-truth binary label sequences (Cheng and Lapata, 2016; Nallapati et al., 2017).
8	19	First, it suffers from exposure bias, a form of mismatch between training and testing data distributions which can hurt performance (Ranzato et al., 2015; Bahdanau et al., 2017; Paulus et al., 2018).
16	30	The first issue can be resolved to a degree using either a cumbersome maximum likelihood-based pre-training step (using heuristically-generated labels) (Wu and Hu, 2018), or placing a hard upper limit on the number of sentences selected.
17	20	The second issue is more problematic, as it is inherent to the sequential binary labeling setting.
23	98	An affinity is a real number in [0, 1] which quantifies the model’s propensity for including a sentence in the summary.
25	35	BANDITSUM is free to process the document as a whole before yielding affinities, which permits affinities for different sentences in the document to depend on one another in arbitrary ways.
27	37	The contributions of our work are as follows: • We propose a theoretically grounded method, based on the contextual bandit formalism, for training neural network-based extractive summarizers with reinforcement learning.
28	47	Based on this training method, we propose the BANDITSUM system for extractive summarization.
29	17	• We perform experiments demonstrating that BANDITSUM obtains state-of-the-art performance on a number of datasets and requires significantly fewer update steps than competing approaches.
61	18	Our goal is to find parameters θ which cause pθ(·|d) to assign high probability to index sequences that induce extractive summaries that a human reader would judge to be of high-quality.
73	65	This proceeds by repeatedly normalizing the set of affinities corresponding to sentences that have not yet been selected, thereby obtaining a probability distribution over unselected sentences, and sampling from that distribution to obtain a new sentence to include.
83	26	Using a baseline r, our sample-based estimate of∇θJ(θ) becomes: 1 B B∑ i=1 ∇θ log pθ(ib|d)(R(ib, a)− r) (6) It can be shown that the introduction of r does not bias the gradient estimator and can significantly reduce its variance if chosen appropriately (Sutton et al., 2000).
85	20	We choose an approach known as self-critical reinforcement learning, in which the test-time performance of the current model is used as the baseline (Ranzato et al., 2015; Rennie et al., 2017; Paulus et al., 2018).
87	29	This baseline has the intuitively satisfying property of only increasing the probability of a sampled label sequence when the summary it induces is better than what would be obtained by greedy decoding.
103	16	Three datasets are used for our experiments: the CNN, the Daily Mail, and combined CNN/Daily Mail (Hermann et al., 2015; Nallapati et al., 2016).
106	26	The models are evaluated based on ROUGE (Lin, 2004).
149	20	It is interesting to observe that, even though BANDITSUM does not have an explicit redundancy avoidance mechanism, it actually outperforms the other systems on non-redundancy.
164	21	We conjecture that the contextual bandit (CB) setting is a more suitable framework for modeling extractive summarization than the sequential binary labeling setting, especially in the cases when good summary sentences appear later in the document.
174	17	Starting with random initializations without supervised pre-training, we train each model ten times for 100 epochs and plot the learning curve of the average ROUGE-F1 score computed based on the trained model in Figure 2.
175	19	We can clearly see that BANDITSUM finds a better solution more quickly than RNES and RNES3 on both datasets.
176	17	Moreover, it displays a significantly speed-up in the exploration and finds the best solution when good summary sentences appeared later in the document (Dlate).
177	23	In this work, we presented a contextual bandit learning framework, BANDITSUM , for extractive summarization, based on neural networks and reinforcement learning algorithms.
178	29	BANDITSUM does not require sentence-level extractive labels and optimizes ROUGE scores between summaries generated by the model and abstractive reference summaries.
179	56	Empirical results show that our method performs better than or comparable to state-of-the-art extractive summarization models which must be pre-trained on extractive labels, and converges using significantly fewer update steps than competing approaches.
180	17	In future work, we will explore the direction of adding an extra coherence reward (Wu and Hu, 2018) to improve the quality of extracted summaries in terms of sentence discourse relation.

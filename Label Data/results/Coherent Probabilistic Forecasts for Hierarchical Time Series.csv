0,1,label2,summary_sentences
"Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 908–916, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.",text,[0],[0]
Neural networks have proven to be highly effective at many tasks in natural language.,1 Introduction,[0],[0]
"For example, neural language models and joint language/translation models improve machine translation quality significantly (Vaswani et al., 2013; Devlin et al., 2014).",1 Introduction,[0],[0]
"However, neural networks can be complicated to design and train well.",1 Introduction,[0],[0]
"Many decisions need to be made, and performance can be highly dependent on making them correctly.",1 Introduction,[0],[0]
"Yet the optimal settings are non-obvious and can be laborious to find, often requiring an extensive grid search involving numerous experiments.
",1 Introduction,[0],[0]
"In this paper, we focus on the choice of the sizes of hidden layers.",1 Introduction,[0],[0]
"We introduce a method for automatically pruning out hidden layer units, by adding a sparsity-inducing regularizer that encourages units to deactivate if not needed, so that
they can be removed from the network.",1 Introduction,[0],[0]
"Thus, after training with more units than necessary, a network is produced that has hidden layers correctly sized, saving both time and memory when actually putting the network to use.
",1 Introduction,[0],[0]
"Using a neural n-gram language model (Bengio et al., 2003), we are able to show that our novel auto-sizing method is able to learn models that are smaller than models trained without the method, while maintaining nearly the same perplexity.",1 Introduction,[0],[0]
"The method has only a single hyperparameter to adjust (as opposed to adjusting the sizes of each of the hidden layers), and we find that the same setting works consistently well across different training data sizes, vocabulary sizes, and n-gram sizes.",1 Introduction,[0],[0]
"In addition, we show that incorporating these models into a machine translation decoder still results in large BLEU point improvements.",1 Introduction,[0],[0]
The result is that fewer experiments are needed to obtain models that perform well and are correctly sized.,1 Introduction,[0],[0]
Language models are often used in natural language processing tasks involving generation of text.,2 Background,[0],[0]
"For instance, in machine translation, the language model helps to output fluent translations, and in speech recognition, the language model helps to disambiguate among possible utterances.
",2 Background,[0],[0]
"Current language models are usually n-gram models, which look at the previous (n− 1) words to predict the nth word in a sequence, based on (smoothed) counts of n-grams collected from training data.",2 Background,[0],[0]
"These models are simple but very effective in improving the performance of natural language systems.
",2 Background,[0],[0]
"However, n-gram models suffer from some limitations, such as data sparsity and memory usage.",2 Background,[0],[0]
"As an alternative, researchers have begun exploring the use of neural networks for language modeling.",2 Background,[0],[0]
"For modeling n-grams, the most common approach is the feedforward network of Bengio et
908
al. (2003), shown in Figure 1.",2 Background,[0],[0]
"Each node represents a unit or “neuron,” which has a real valued activation.",2 Background,[0],[0]
The units are organized into real-vector valued layers.,2 Background,[0],[0]
The activations at each layer are computed as follows.,2 Background,[0],[0]
(We assume n = 3; the generalization is easy.),2 Background,[0],[0]
"The two preceding words, w1, w2, are mapped into lowerdimensional word embeddings,
x1",2 Background,[0],[0]
= A:w1 x2 =,2 Background,[0],[0]
"A:w2
then passed through two hidden layers,
y = f(B1x1 +",2 Background,[0],[0]
B2x2 + b) z,2 Background,[0],[0]
"= f(Cy + c)
where f is an elementwise nonlinear activation (or transfer) function.",2 Background,[0],[0]
"Commonly used activation functions are the hyperbolic tangent, logistic function, and rectified linear units, to name a few.",2 Background,[0],[0]
"Finally, the result is mapped via a softmax to an output probability distribution,
P (wn | w1 · · ·wn−1) ∝",2 Background,[0],[0]
exp([Dz + d]wn).,2 Background,[0],[0]
"The parameters of the model are A, B1, B2, b, C, c, D, and d, which are learned by minimizing the negative log-likelihood of the the training data using stochastic gradient descent (also known as backpropagation) or variants.
",2 Background,[0],[0]
"Vaswani et al. (2013) showed that this model, with some improvements, can be used effectively during decoding in machine translation.",2 Background,[0],[0]
"In this paper, we use and extend their implementation.",2 Background,[0],[0]
Our method is focused on the challenge of choosing the number of units in the hidden layers of a feed-forward neural network.,3 Methods,[0],[0]
"The networks used for different tasks require different numbers of units, and the layers in a single network also require different numbers of units.",3 Methods,[0],[0]
"Choosing too few units can impair the performance of the network, and choosing too many units can lead to overfitting.",3 Methods,[0],[0]
"It can also slow down computations with the network, which can be a major concern for many applications such as integrating neural language models into a machine translation decoder.
",3 Methods,[0],[0]
Our method starts out with a large number of units in each layer and then jointly trains the network while pruning out individual units when possible.,3 Methods,[0],[0]
"The goal is to end up with a trained network
that also has the optimal number of units in each layer.
",3 Methods,[0],[0]
We do this by adding a regularizer to the objective function.,3 Methods,[0],[0]
"For simplicity, consider a single layer without bias, y = f(Wx).",3 Methods,[0],[0]
Let L(W) be the negative log-likelihood of the model.,3 Methods,[0],[0]
"Instead of minimizing L(W) alone, we want to minimize L(W)",3 Methods,[0],[0]
"+ λR(W), where R(W) is a convex regularizer.",3 Methods,[0],[0]
"The `1 norm, R(W) = ‖W‖1 =∑
i,j |Wij |, is a common choice for pushing parameters to zero, which can be useful for preventing overfitting and reducing model size.",3 Methods,[0],[0]
"However, we are interested not only in reducing the number of parameters but the number of units.",3 Methods,[0],[0]
"To do this, we need a different regularizer.
",3 Methods,[0],[0]
"We assume activation functions that satisfy f(0) = 0, such as the hyperbolic tangent or rectified linear unit (f(x) = max{0, x}).",3 Methods,[0],[0]
"Then, if we push the incoming weights of a unit yi to zero, that is, Wij = 0 for all j (as well as the bias, if any: bi = 0), then yi = f(0) = 0 is independent of the previous layers and contributes nothing to subsequent layers.",3 Methods,[0],[0]
So the unit can be removed without affecting the network at all.,3 Methods,[0],[0]
"Therefore, we need a regularizer that pushes all the incoming connection weights to a unit together towards zero.
",3 Methods,[0],[0]
"Here, we experiment with two, the `2,1 norm and the `∞,1 norm.1 The `2,1 norm on a ma-
1In the notation `p,q , the subscript p corresponds to the norm over each group of parameters, and q corresponds to the norm over the group norms.",3 Methods,[0],[0]
"Contrary to more common usage, in this paper, the groups are rows, not columns.
",3 Methods,[0],[0]
"trix W is
R(W) =",3 Methods,[0],[0]
∑ i ‖Wi:‖2 = ∑ i ∑ j W 2ij  12 .,3 Methods,[0],[0]
"(1) (If there are biases bi, they should be included as well.)",3 Methods,[0],[0]
"This puts equal pressure on each row, but within each row, the larger values contribute more, and therefore there is more pressure on larger values towards zero.",3 Methods,[0],[0]
"The `∞,1 norm is
R(W) =",3 Methods,[0],[0]
∑ i ‖Wi:‖∞ = ∑ i max j |Wij |.,3 Methods,[0],[0]
"(2)
Again, this puts equal pressure on each row, but within each row, only the maximum value (or values) matter, and therefore the pressure towards zero is entirely on the maximum value(s).
",3 Methods,[0],[0]
Figure 2 visualizes the sparsity-inducing behavior of the two regularizers on a single row.,3 Methods,[0],[0]
Both have a sharp tip at the origin that encourages all the parameters in a row to become exactly zero.,3 Methods,[0],[0]
"However, this also means that sparsity-inducing regularizers are not differentiable at zero, making gradient-based optimization methods trickier to apply.",4 Optimization,[0],[0]
"The methods we use are discussed in detail elsewhere (Duchi et al., 2008; Duchi and Singer, 2009); in this section, we include a short description of these methods for completeness.",4 Optimization,[0],[0]
"Most work on learning with regularizers, including this work, can be thought of as instances of the proximal gradient method (Parikh and Boyd, 2014).",4.1 Proximal gradient method,[0],[0]
"Our objective function can be split into two parts, a convex and differentiable part (L) and a
convex but non-differentiable part (λR).",4.1 Proximal gradient method,[0],[0]
"In proximal gradient descent, we alternate between improving L alone and λR alone.",4.1 Proximal gradient method,[0],[0]
Let u be the parameter values from the previous iteration.,4.1 Proximal gradient method,[0],[0]
"We compute new parameter values w using:
v← u− η∇L(u) (3)
w← arg max w",4.1 Proximal gradient method,[0],[0]
( 1 2η ‖w − v‖2 + λR(w) ),4.1 Proximal gradient method,[0],[0]
"(4)
and repeat until convergence.",4.1 Proximal gradient method,[0],[0]
The first update is just a standard gradient descent update on L; the second is known as the proximal operator for λR and in many cases has a closed-form solution.,4.1 Proximal gradient method,[0],[0]
"In the rest of this section, we provide some justification for this method, and in Sections 4.2 and 4.3 we show how to compute the proximal operator for the `2 and `∞ norms.
",4.1 Proximal gradient method,[0],[0]
We can think of the gradient descent update (3) on L as follows.,4.1 Proximal gradient method,[0],[0]
"Approximate L around u by the tangent plane,
L̄(v) = L(u) +∇L(u)(v − u) (5)
and move v to minimize L̄, but don’t move it too far from u; that is, minimize
F (v) = 1",4.1 Proximal gradient method,[0],[0]
2η ‖v,4.1 Proximal gradient method,[0],[0]
"− u‖2 + L̄(v).
",4.1 Proximal gradient method,[0],[0]
"Setting partial derivatives to zero, we get
∂F ∂v = 1 η
(v − u) +∇L(u) = 0 v = u− η∇L(u).
",4.1 Proximal gradient method,[0],[0]
"By a similar strategy, we can derive the second step (4).",4.1 Proximal gradient method,[0],[0]
"Again we want to move w to minimize the objective function, but don’t want to move it too far from u; that is, we want to minimize:
G(w) = 1 2η ‖w",4.1 Proximal gradient method,[0],[0]
"− u‖2 + L̄(w) + λR(w).
",4.1 Proximal gradient method,[0],[0]
Note that we have not approximated R by a tangent plane.,4.1 Proximal gradient method,[0],[0]
We can simplify this by substituting in (3).,4.1 Proximal gradient method,[0],[0]
"The first term becomes
1 2η ‖w",4.1 Proximal gradient method,[0],[0]
− u‖2 = 1 2η ‖w,4.1 Proximal gradient method,[0],[0]
"− v − η∇L(u)‖2
= 1 2η ‖w − v‖2 −∇L(u)(w − v)
+ η
2 ‖∇L(u)‖2
and the second term becomes
L̄(w) = L(u) +∇L(u)(w − u) = L(u) +∇L(u)(w",4.1 Proximal gradient method,[0],[0]
"− v − η∇L(u)).
",4.1 Proximal gradient method,[0],[0]
"The ∇L(u)(w − v) terms cancel out, and we can ignore terms not involving w, giving
G(w) = 1 2η ‖w",4.1 Proximal gradient method,[0],[0]
"− v‖2 + λR(w) + const.
which is minimized by the update (4).",4.1 Proximal gradient method,[0],[0]
"Thus, we have split the optimization step into two easier steps: first, do the update for L (3), then do the update for λR (4).",4.1 Proximal gradient method,[0],[0]
The latter can often be done exactly (without approximating R by a tangent plane).,4.1 Proximal gradient method,[0],[0]
"We show next how to do this for the `2 and `∞ norms.
4.2 `2 and `2,1 regularization Since the `2,1 norm on matrices (1) is separable into the `2 norm of each row, we can treat each row separately.",4.1 Proximal gradient method,[0],[0]
"Thus, for simplicity, assume that we have a single row and want to minimize
G(w) = 1 2η ‖w − v‖2 +",4.1 Proximal gradient method,[0],[0]
"λ‖w‖+ const.
",4.1 Proximal gradient method,[0],[0]
"The minimum is either at w = 0 (the tip of the cone) or where the partial derivatives are zero (Figure 3):
∂G ∂w = 1 η (w − v) + λ w‖w‖",4.1 Proximal gradient method,[0],[0]
"= 0.
",4.1 Proximal gradient method,[0],[0]
"Clearly, w and v must have the same direction and differ only in magnitude, that is, w = α v‖v‖ .",4.1 Proximal gradient method,[0],[0]
"Substituting this into the above equation, we get the solution
α = ‖v‖",4.1 Proximal gradient method,[0],[0]
− ηλ.,4.1 Proximal gradient method,[0],[0]
"Therefore the update is
w = α v ‖v‖
α = max(0, ‖v‖ − ηλ).",4.1 Proximal gradient method,[0],[0]
"As above, since the `∞,1 norm on matrices (2) is separable into the `∞ norm of each row, we can treat each row separately; thus, we want to minimize
G(w) = 1 2η ‖w − v‖2 + λmax j |xj |+ const.
","4.3 `∞ and `∞,1 regularization",[0],[0]
"Intuitively, the solution can be characterized as: Decrease all of the maximal |xj | until the total decrease reaches ηλ or all the xj are zero.","4.3 `∞ and `∞,1 regularization",[0],[0]
"See Figure 4.
","4.3 `∞ and `∞,1 regularization",[0],[0]
"If we pre-sort the |xj | in nonincreasing order, it’s easy to see how to compute this: for ρ = 1, . . .","4.3 `∞ and `∞,1 regularization",[0],[0]
", n, see if there is a value ξ ≤ xρ","4.3 `∞ and `∞,1 regularization",[0],[0]
"such that decreasing all the x1, . . .","4.3 `∞ and `∞,1 regularization",[0],[0]
", xρ to ξ amounts to a total decrease of ηλ.","4.3 `∞ and `∞,1 regularization",[0],[0]
"The largest ρ for which this is possible gives the correct solution.
","4.3 `∞ and `∞,1 regularization",[0],[0]
"But this situation seems similar to another optimization problem, projection onto the `1-ball, which Duchi et al. (2008) solve in linear time without pre-sorting.","4.3 `∞ and `∞,1 regularization",[0],[0]
"In fact, the two problems can be solved by nearly identical algorithms, because they are convex conjugates of each other (Duchi and Singer, 2009; Bach et al., 2012).","4.3 `∞ and `∞,1 regularization",[0],[0]
"Intuitively, the `1 projection of v is exactly what is cut out by the `∞ proximal operator, and vice versa (Figure 4).
","4.3 `∞ and `∞,1 regularization",[0],[0]
Duchi et al.’s algorithm modified for the present problem is shown as Algorithm 1.,"4.3 `∞ and `∞,1 regularization",[0],[0]
It partitions the xj about a pivot element (line 6) and tests whether it and the elements to its left can be decreased to a value ξ such that the total decrease is δ (line 8).,"4.3 `∞ and `∞,1 regularization",[0],[0]
"If so, it recursively searches the right side; if not, the
left side.","4.3 `∞ and `∞,1 regularization",[0],[0]
"At the conclusion of the algorithm, ρ is set to the largest value that passes the test (line 13), and finally the new xj are computed (line 16) – the only difference from Duchi et al.’s algorithm.
","4.3 `∞ and `∞,1 regularization",[0],[0]
This algorithm is asymptotically faster than that of Quattoni et al. (2009).,"4.3 `∞ and `∞,1 regularization",[0],[0]
"They reformulate `∞,1 regularization as a constrained optimization problem (in which the `∞,1 norm is bounded by µ) and provide a solution inO(n log n) time.","4.3 `∞ and `∞,1 regularization",[0],[0]
"The method shown here is simpler and faster because it can work on each row separately.
","4.3 `∞ and `∞,1 regularization",[0],[0]
"Algorithm 1 Linear-time algorithm for the proximal operator of the `∞ norm.
1: procedure UPDATE(w, δ) 2: lo, hi← 1, n 3: s← 0 4:","4.3 `∞ and `∞,1 regularization",[0],[0]
"while lo ≤ hi do 5: select md randomly from lo, . . .","4.3 `∞ and `∞,1 regularization",[0],[0]
", hi 6: ρ← PARTITION(w, lo,md, hi) 7: ξ ← 1ρ","4.3 `∞ and `∞,1 regularization",[0],[0]
"( s+ ∑ρ i=lo |xi| − δ
) 8: if ξ ≤ |xρ| then 9: s← s+∑ρi=lo |xi|
10: lo← ρ+ 1 11: else 12: hi← ρ− 1 13: ρ← hi 14: ξ ← 1ρ (s− δ) 15: for i← 1, . . .","4.3 `∞ and `∞,1 regularization",[0],[0]
", n","4.3 `∞ and `∞,1 regularization",[0],[0]
"do 16: xi ← min(max(xi,−ξ), ξ) 17: procedure PARTITION(w, lo,md, hi) 18: swap xlo and xmd 19: i← lo + 1 20: for j ← lo + 1, . . .","4.3 `∞ and `∞,1 regularization",[0],[0]
", hi do 21: if xj ≥ xlo then 22: swap xi and xj 23: i← i+ 1 24: swap xlo and xi−1 25: return i− 1","4.3 `∞ and `∞,1 regularization",[0],[0]
"We evaluate our model using the open-source NPLM toolkit released by Vaswani et al. (2013), extending it to use the additional regularizers as described in this paper.2 We use a vocabulary size of 100k and word embeddings with 50 dimensions.",5 Experiments,[0],[0]
"We use two hidden layers of rectified linear units (Nair and Hinton, 2010).
",5 Experiments,[0],[0]
"2These extensions have been contributed to the NPLM project.
",5 Experiments,[0],[0]
"We train neural language models (LMs) on two natural language corpora, Europarl v7 English and the AFP portion of English Gigaword 5.",5 Experiments,[0],[0]
"After tokenization, Europarl has 56M tokens and Gigaword AFP has 870M tokens.",5 Experiments,[0],[0]
"For both corpora, we hold out a validation set of 5,000 tokens.",5 Experiments,[0],[0]
"We train each model for 10 iterations over the training data.
",5 Experiments,[0],[0]
Our experiments break down into three parts.,5 Experiments,[0],[0]
"First, we look at the impact of our pruning method on perplexity of a held-out validation set, across a variety of settings.",5 Experiments,[0],[0]
"Second, we take a closer look at how the model evolves through the training process.",5 Experiments,[0],[0]
"Finally, we explore the downstream impact of our method on a statistical phrase-based machine translation system.",5 Experiments,[0],[0]
"We first look at the impact that the `∞,1 regularizer has on the perplexity of our validation set.",5.1 Evaluating perplexity and network size,[0],[0]
The main results are shown in Table 1.,5.1 Evaluating perplexity and network size,[0],[0]
"For λ ≤ 0.01, the regularizer seems to have little impact: no hidden units are pruned, and perplexity is also not affected.",5.1 Evaluating perplexity and network size,[0],[0]
"For λ = 1, on the other hand, most hidden units are pruned – apparently too many, since perplexity is worse.",5.1 Evaluating perplexity and network size,[0],[0]
"But for λ = 0.1, we see that we are able to prune out many hidden units: up to half of the first layer, with little impact on perplexity.",5.1 Evaluating perplexity and network size,[0],[0]
"We found this to be consistent across all our experiments, varying n-gram size, initial hidden layer size, and vocabulary size.
",5.1 Evaluating perplexity and network size,[0],[0]
Table 2 shows the same information for 5-gram models trained on the larger Gigaword AFP corpus.,5.1 Evaluating perplexity and network size,[0],[0]
"These numbers look very similar to those on Europarl: again λ = 0.1 works best, and, counter to expectation, even the final number of units is similar.
",5.1 Evaluating perplexity and network size,[0],[0]
"Table 3 shows the result of varying the vocabulary size: again λ = 0.1 works best, and, although it is not shown in the table, we also found that the final number of units did not depend strongly on the vocabulary size.
",5.1 Evaluating perplexity and network size,[0],[0]
"Table 4 shows results using the `2,1 norm (Europarl corpus, 5-grams, 100k vocabulary).",5.1 Evaluating perplexity and network size,[0],[0]
"Since this is a different regularizer, there isn’t any reason to expect that λ behaves the same way, and indeed, a smaller value of λ seems to work best.",5.1 Evaluating perplexity and network size,[0],[0]
We also studied the evolution of the network over the training process to gain some insights into how the method works.,5.2 A closer look at training,[0],[0]
"The first question we want to
answer is whether the method is simply removing units, or converging on an optimal number of units.",5.2 A closer look at training,[0],[0]
"Figure 5 suggests that it is a little of both: if we start with too many units (900 or 1000), the method converges to the same number regardless of how many extra units there were initially.",5.2 A closer look at training,[0],[0]
"But if we start with a smaller number of units, the method still prunes away about 50 units.
",5.2 A closer look at training,[0],[0]
"Next, we look at the behavior over time of different regularization strengths λ.",5.2 A closer look at training,[0],[0]
"We found that not only does λ = 1 prune out too many units, it does so at the very first iteration (Figure 6, above), perhaps prematurely.",5.2 A closer look at training,[0],[0]
"By contrast, the λ = 0.1 run prunes out units gradually.",5.2 A closer look at training,[0],[0]
"By plotting these curves together with perplexity (Figure 6, below), we can see that the λ = 0.1 run is fitting the model and pruning it at the same time, which seems preferable to fitting without any pruning (λ =
0.01) or pruning first and then fitting (λ = 1).",5.2 A closer look at training,[0],[0]
"We can also visualize the weight matrix itself over time (Figure 7), for λ = 0.1.",5.2 A closer look at training,[0],[0]
"It is striking that although this setting fits the model and prunes it at the same time, as argued above, by the first iteration it already seems to have decided roughly how many units it will eventually prune.",5.2 A closer look at training,[0],[0]
We also looked at the impact of our method on statistical machine translation systems.,5.3 Evaluating on machine translation,[0],[0]
"We used the Moses toolkit (Koehn et al., 2007) to build a phrase based machine translation system with a traditional 5-gram LM trained on the target side of our bitext.",5.3 Evaluating on machine translation,[0],[0]
We augmented this system with neural LMs trained on the Europarl data and the Gigaword AFP data.,5.3 Evaluating on machine translation,[0],[0]
"Based on the results from the perplexity experiments, we looked at models both built with a λ = 0.1 regularizer, and without regularization (λ = 0).
",5.3 Evaluating on machine translation,[0],[0]
We built our system using the newscommentary dataset v8.,5.3 Evaluating on machine translation,[0],[0]
We tuned our model using newstest13 and evaluated using newstest14.,5.3 Evaluating on machine translation,[0],[0]
"After standard cleaning and tokenization, there were 155k parallel sentences in the newscommentary dataset, and 3,000 sentences each for the tuning and test sets.
",5.3 Evaluating on machine translation,[0],[0]
"Table 5 shows that the addition of a neural LM helps substantially over the baseline, with improvements of up to 2 BLEU.",5.3 Evaluating on machine translation,[0],[0]
"Using the Europarl model, the BLEU scores obtained without and with regularization were not significantly different (p ≥ 0.05), consistent with the negligible perplexity difference between these models.",5.3 Evaluating on machine translation,[0],[0]
"On the Gigaword AFP model, regularization did decrease the BLEU score by 0.3, consistent with the small perplexity increase of the regularized model.",5.3 Evaluating on machine translation,[0],[0]
"The decrease is statistically significant, but small compared with the overall benefit of adding a neural LM.",5.3 Evaluating on machine translation,[0],[0]
Researchers have been exploring the use of neural networks for language modeling for a long time.,6 Related Work,[0],[0]
Schmidhuber and Heil (1996) proposed a character n-gram model using neural networks which they used for text compression.,6 Related Work,[0],[0]
"Xu and Rudnicky (2000) proposed a word-based probability model using a softmax output layer trained using cross-entropy, but only for bigrams.",6 Related Work,[0],[0]
Bengio et al. (2003) defined a probabilistic word n-gram model and demonstrated improvements over conventional smoothed language models.,6 Related Work,[0],[0]
Mnih and Teh (2012) sped up training of log-bilinear language models through the use of noise-contrastive estimation (NCE).,6 Related Work,[0],[0]
"Vaswani et al. (2013) also used NCE to train the architecture of Bengio et al. (2003), and were able to integrate a largevocabulary language model directly into a machine translation decoder.",6 Related Work,[0],[0]
"Baltescu et al. (2014) describe a similar model, with extensions like a hierarchical softmax (based on Brown clustering) and direct n-gram features.
",6 Related Work,[0],[0]
"Beyond feed-forward neural network language models, researchers have explored using more complicated neural network architectures.",6 Related Work,[0],[0]
"RNNLM is an open-source implementation of a language model using recurrent neural networks (RNN) where connections between units can form directed cycles (Mikolov et al., 2011).",6 Related Work,[0],[0]
Sundermeyer et al. (2015) use the long-short term memory (LSTM) neural architecture to show a perplexity improvement over the RNNLM toolkit.,6 Related Work,[0],[0]
"In future work, we plan on exploring how our method could improve these more complicated neural models as well.
",6 Related Work,[0],[0]
Automatically limiting the size of neural networks is an old idea.,6 Related Work,[0],[0]
"The “Optimal Brain Damage” (OBD) technique (LeCun et al., 1989) computes a saliency based on the second derivative of the objective function with respect to each parameter.",6 Related Work,[0],[0]
"The parameters are then sorted by saliency, and the lowest-saliency parameters are pruned.",6 Related Work,[0],[0]
"The pruning process is separate from the training process, whereas regularization performs training and pruning simultaneously.",6 Related Work,[0],[0]
"Regularization in neural networks is also an old idea; for example, Nowland and Hinton (1992) mention both `22 and `0 regularization.",6 Related Work,[0],[0]
"Our method develops on this idea by using a mixed norm to prune units, rather than parameters.
",6 Related Work,[0],[0]
"Srivastava et al. introduce a method called dropout in which units are directly deactivated at random during training (Srivastava et al., 2014), which induces sparsity in the hidden unit activations.",6 Related Work,[0],[0]
"However, at the end of training, all units are reactivated, as the goal of dropout is to reduce overfitting, not to reduce network size.",6 Related Work,[0],[0]
"Thus, dropout and our method seem to be complementary.",6 Related Work,[0],[0]
"We have presented a method for auto-sizing a neural network during training by removing units using a `∞,1 regularizer.",7 Conclusion,[0],[0]
"This regularizer drives a unit’s input weights as a group down to zero, allowing the unit to be pruned.",7 Conclusion,[0],[0]
"We can thus prune units out of our network during training with minimal impact to held-out perplexity or downstream performance of a machine translation system.
",7 Conclusion,[0],[0]
"Our results showed empirically that the choice
of a regularization coefficient of 0.1 was robust to initial configuration parameters of initial network size, vocabulary size, n-gram order, and training corpus.",7 Conclusion,[0],[0]
"Furthermore, imposing a single regularizer on the objective function can tune all of the hidden layers of a network with one setting.",7 Conclusion,[0],[0]
"This reduces the need to conduct expensive, multi-dimensional grid searches in order to determine optimal sizes.
",7 Conclusion,[0],[0]
We have demonstrated the power and efficacy of this method on a feed-forward neural network for language modeling though experiments on perplexity and machine translation.,7 Conclusion,[0],[0]
"However, this method is general enough that it should be applicable to other domains, both inside natural language processing and outside.",7 Conclusion,[0],[0]
"As neural models become more pervasive in natural language processing, the ability to auto-size networks for fast experimentation and quick exploration will become increasingly important.",7 Conclusion,[0],[0]
"We would like to thank Tomer Levinboim, Antonios Anastasopoulos, and Ashish Vaswani for their helpful discussions, as well as the reviewers for their assistance and feedback.",Acknowledgments,[0],[0]
Neural networks have been shown to improve performance across a range of natural-language tasks.,abstractText,[0],[0]
"However, designing and training them can be complicated.",abstractText,[0],[0]
"Frequently, researchers resort to repeated experimentation to pick optimal settings.",abstractText,[0],[0]
"In this paper, we address the issue of choosing the correct number of units in hidden layers.",abstractText,[0],[0]
"We introduce a method for automatically adjusting network size by pruning out hidden units through `∞,1 and `2,1 regularization.",abstractText,[0],[0]
We apply this method to language modeling and demonstrate its ability to correctly choose the number of hidden units while maintaining perplexity.,abstractText,[0],[0]
We also include these models in a machine translation decoder and show that these smaller neural models maintain the significant improvements of their unpruned versions.,abstractText,[0],[0]
Auto-Sizing Neural Networks: With Applications to n-gram Language Models,title,[0],[0]
"There has been a staggering increase in progress on generative modeling in recent years, built largely upon fundamental advances such as generative adversarial networks (Goodfellow et al., 2014), variational inference (Kingma & Welling, 2013), and autoregressive density estimation (van den Oord et al., 2016c).",1. Introduction,[0],[0]
"These have led to breakthroughs in state-ofthe-art generation of natural images (Karras et al., 2017) and audio (van den Oord et al., 2016a), and even been used for unsupervised learning of disentangled representations (Higgins et al., 2017; Chen et al., 2016).",1. Introduction,[0],[0]
"These domains often have real-valued distributions with underlying metrics; that is, there is a domain-specific notion of similarity between data points.",1. Introduction,[0],[0]
"This similarity is ignored by the predominant work-horse of generative modeling, the Kullback-Leibler (KL) divergence.",1. Introduction,[0],[0]
"Progress is now being made towards algorithms that optimize with respect to these underlying metrics (Arjovsky et al., 2017; Bousquet et al., 2017).
",1. Introduction,[0],[0]
"*Equal contribution 1DeepMind, London, UK.",1. Introduction,[0],[0]
"Correspondence to: Georg Ostrovski <ostrovski@google.com>, Will Dabney <wdabney@google.com>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"In this paper, we present a novel approach to generative modeling, that, while strikingly different from existing methods, is grounded in the well-understood statistical methods of quantile regression.",1. Introduction,[0],[0]
"Unlike the majority of recent work, we approach generative modeling without the use of the KL divergence, and without explicitly approximating a likelihood model.",1. Introduction,[0],[0]
"Like GANs, in this way we produce an implicitly defined model, but unlike GANs our optimization procedure is inherently stable and lacks degenerate solutions which cause loss of diversity and mode collapse.
",1. Introduction,[0],[0]
"Much of the recent research on GANs has been focused on improving stability (Radford et al., 2015; Arjovsky et al., 2017; Daskalakis et al., 2017) and sample diversity (Gulrajani et al., 2017; Salimans et al., 2016; 2018).",1. Introduction,[0],[0]
"By stark contrast, methods such as PixelCNN (van den Oord et al., 2016b) readily produce high diversity, but due to their use of KL divergence are unable to make reasonable trade-offs between likelihood and perceptual similarity (Theis et al., 2015; Bellemare et al., 2017; Bousquet et al., 2017).
",1. Introduction,[0],[0]
"Our proposed method, autoregressive implicit quantile networks (AIQN), combines the benefits of both: a loss function that respects the underlying metric of the data leading to improved perceptual quality, and a stable optimization process leading to highly diverse samples.",1. Introduction,[0],[0]
"While there has been an increasing tendency towards complex architectures (Chen et al., 2017; Salimans et al., 2017) and multiple objective loss functions to overcome these challenges, AIQN is conceptually simple and does not rely on any special architecture or optimization techniques.",1. Introduction,[0],[0]
"Empirically it proves to be robust to hyperparameter variations and easy to optimize.
",1. Introduction,[0],[0]
"Our work is motivated by the recent advances achieved by reframing GANs in terms of optimal transport, leading to the Wasserstein GAN algorithm (Arjovsky et al., 2017), as well as work towards understanding the relationship between optimal transport and both GANs and VAEs (Bousquet et al., 2017).",1. Introduction,[0],[0]
"In agreement with these results, we focus on loss functions grounded in perceptually meaningful metrics.",1. Introduction,[0],[0]
"We build upon recent work in distributional reinforcement learning (Dabney et al., 2018a), which has begun to bridge the gap between approaches in reinforcement learning and unsupervised learning.",1. Introduction,[0],[0]
"Towards a practical algorithm we base our experimental results on Gated PixelCNN (van den Oord et al., 2016b), and show that using AIQN significantly im-
proves objective performance on CIFAR-10 and ImageNet 32x32 in terms of Fréchet Inception Distance (FID) and Inception score, as well as subjective perceptual quality in image samples and inpainting.",1. Introduction,[0],[0]
"We begin by establishing some notation, before turning to a review of three of the most prevalent methods for generative modeling.",2. Background,[0],[0]
"Calligraphic letters (e.g.X ) denote sets or spaces, capital letters (e.g. X) denote random variables, and lower case letters (e.g. x) indicate values.",2. Background,[0],[0]
"A probability distribution with random variable X ∈ X is denoted pX ∈P(X ), its cumulative distribution function (c.d.f.)",2. Background,[0],[0]
"FX , and inverse c.d.f. or quantile function QX = F−1X .",2. Background,[0],[0]
When probability distributions or quantile functions are parameterized by some θ,2. Background,[0],[0]
"we will write pθ or Qθ recognizing that here we do not view θ as a random variable.
",2. Background,[0],[0]
"Perhaps the simplest way to approach generative modeling of a random variableX ∈ X is by fixing some discretization ofX into n separate values, say x1, . . .",2. Background,[0],[0]
", xn ∈ X , and parameterize the approximate distribution with pθ(xi) ∝",2. Background,[0],[0]
exp(θi).,2. Background,[0],[0]
"This type of categorical parameterization is widely used, only slightly less commonly when X does not lend itself naturally to such a partitioning.",2. Background,[0],[0]
"Typically, the parameters θ are optimized to minimize the Kullback-Leibler (KL) divergence between observed values of X and the model pθ, θ∗ = arg minθDKL(pX‖pθ).",2. Background,[0],[0]
"However, this is only tractable whenX is a small discrete set or at best low-dimensional.",2. Background,[0],[0]
A common method for extending a generative model or density estimator to multivariate distributions is to factor the density as a product of scalarvalued conditional distributions.,2. Background,[0],[0]
"Let X = (X1, . . .",2. Background,[0],[0]
", Xn), then for any permutation of the dimensions σ :",2. Background,[0],[0]
"Nn → Nn,
pX(x) =",2. Background,[0],[0]
"n∏ i=1 pXσ(i)(xσ(i)|xσ(1), . . .",2. Background,[0],[0]
", xσ(i−1)).",2. Background,[0],[0]
"(1)
When the conditional density is modeled by a simple (e.g. Gaussian) base distribution, the ordering of the dimensions can be crucial (Papamakarios et al., 2017).",2. Background,[0],[0]
"However, it is common practice to choose an arbitrary ordering and rely upon a more powerful conditional model to avoid these problems.",2. Background,[0],[0]
"This class of models includes PixelRNN and PixelCNN (van den Oord et al., 2016c;b), MAF (Papamakarios et al., 2017), MADE (Germain et al., 2015), and many others.",2. Background,[0],[0]
"Fundamentally, all these approaches use the KL divergence as their loss function.
",2. Background,[0],[0]
"Another class of methods, generally known as latent variable methods, can bypass the need for autoregressive models using a different modeling assumption.",2. Background,[0],[0]
"Specifically, consider the Variational Autoencoder (VAE) (Kingma & Welling, 2013; Rezende et al., 2014), which represents
pθ as the marginalization over a latent random variable Z ∈ Z .",2. Background,[0],[0]
"The VAE is trained to maximize an approximate lower bound of the log-likelihood of the observations:
log pθ(x) ≥ −DKL(qθ(z|x)‖p(z))",2. Background,[0],[0]
+,2. Background,[0],[0]
E,2. Background,[0],[0]
"[log pθ(x|z)] .
",2. Background,[0],[0]
"Although VAEs are straightforward to implement and optimize, and effective at capturing structure in highdimensional spaces, they often miss fine-grained detail, resulting in blurry images.
",2. Background,[0],[0]
"Generative Adversarial Networks (GANs) (Goodfellow et al., 2014) pose the problem of learning a generative model as a two-player zero-sum game between a discriminator D, attempting to distinguish between x ∼ pX (real data) and x ∼ pθ (generated data), and a generator G, attempting to generate data indistinguishable from real data.",2. Background,[0],[0]
"The generator is an implicit latent variable model that reparameterizes samples, typically from an isotropic Gaussian distribution, into values in X .",2. Background,[0],[0]
"The original formulation of GANs,
arg min G sup D",2. Background,[0],[0]
[ E X log(D(X)),2. Background,[0],[0]
"+ E Z log(1−D(G(Z))) ] ,
can be seen as minimizing a lower-bound on the JensenShannon divergence (Goodfellow et al., 2014; Bousquet et al., 2017).",2. Background,[0],[0]
"That is, even in the case of GANs we are often minimizing functions of the KL divergence1.
",2. Background,[0],[0]
"Many recent advances have come from principled combinations of these three fundamental methods (Makhzani et al., 2015; Dumoulin et al., 2016; Rosca et al., 2017).",2. Background,[0],[0]
"A common perspective in generative modeling is that the choice of model should encode existing metric assumptions about the domain, combined with a generic likelihoodfocused loss such as the KL divergence.",2.1. Distance Metrics and Loss Functions,[0],[0]
"Under this view, the KL’s general applicability and robust optimization properties make it a natural choice, and most implementations of the methods we reviewed in the previous section attempt to, at least indirectly, minimize a version of the KL.
",2.1. Distance Metrics and Loss Functions,[0],[0]
"On the other hand, as every model inevitably makes tradeoffs when constrained by capacity or limited training, it is desirable for its optimization goal to incentivize trade-offs prioritizing approximately correct solutions, when the data space is endowed with a metric supporting a meaningful (albeit potentially subjective) notion of approximation.",2.1. Distance Metrics and Loss Functions,[0],[0]
"It has been argued (Theis et al., 2015; Bousquet et al., 2017; Arjovsky et al., 2017; Bellemare et al., 2017) that the KL may not always be appropriate from this perspective, by making sub-optimal trade-offs between likelihood and similarity.
",2.1. Distance Metrics and Loss Functions,[0],[0]
"1The Jensen-Shannon divergence is the sum of KLs between distributions P,Q and their uniform mixture M = 0.5(P +Q): JSD(P ||Q)",2.1. Distance Metrics and Loss Functions,[0],[0]
"= 0.5(DKL(P ||M) +DKL(Q||M)).
",2.1. Distance Metrics and Loss Functions,[0],[0]
"Indeed, many limitations of existing models can be traced back to the use of KL, and the resulting trade-offs in approximate solutions it implies.",2.1. Distance Metrics and Loss Functions,[0],[0]
"For instance, its use appears to play a central role in one of the primary failure modes of VAEs, that of blurry samples.",2.1. Distance Metrics and Loss Functions,[0],[0]
"Zhao et al. (2017) argue that the Gaussian posterior pθ(x|z) implies an overly simple model, which, when unable to perfectly fit the data, is forced to average (thus creating blur), and is not incentivized by the KL towards an alternative notion of approximate solution.",2.1. Distance Metrics and Loss Functions,[0],[0]
"Theis et al. (2015) emphasized that an improvement of log-likelihood does not necessarily translate to higher perceptual quality, and that the KL loss is more likely to produce atypical samples than some other training criteria.
",2.1. Distance Metrics and Loss Functions,[0],[0]
"We offer an alternative perspective: a good model should encode assumptions about the data distribution, whereas a good loss should encode the notion of similarity, that is, the underlying metric on the data space.",2.1. Distance Metrics and Loss Functions,[0],[0]
"From this point of view, the KL corresponds to an actual absence of explicit underlying metric, with complete focus on probability.
",2.1. Distance Metrics and Loss Functions,[0],[0]
"The optimal transport metrics Wc, for underlying metric c(x, x′), and in particular the p-Wasserstein distance, when c is an Lp metric, have frequently been proposed as being well-suited replacements to KL (Bousquet et al., 2017; Genevay et al., 2017).",2.1. Distance Metrics and Loss Functions,[0],[0]
"Briefly, the advantages are (1) avoidance of mode collapse (no need to choose between spreading over modes or collapsing to a single mode as in KL), and (2) the ability to trade off errors and incentivize approximations that respect the underlying metric.
",2.1. Distance Metrics and Loss Functions,[0],[0]
"Recently, Arjovsky et al. (2017) introduced the Wasserstein
GAN, reposing the two-player game as the estimation of the gradient of the 1-Wasserstein distance between the data and generator distributions.",2.1. Distance Metrics and Loss Functions,[0],[0]
"They reframe this in terms of the dual form of the 1-Wasserstein, with the critic estimating a function f which maximally separates the two distributions.",2.1. Distance Metrics and Loss Functions,[0],[0]
"While this is an exciting line of work, it still faces limitations when the critic solution is approximate, i.e. when f∗ is not found before each update.",2.1. Distance Metrics and Loss Functions,[0],[0]
"In this case, due to insufficient training of the critic (Bellemare et al., 2017) or limitations of the function approximator, the gradient direction produced can be arbitrarily bad (Bousquet et al., 2017).
",2.1. Distance Metrics and Loss Functions,[0],[0]
"Thus, we are left with the question of how to minimize a distribution loss respecting an underlying metric.",2.1. Distance Metrics and Loss Functions,[0],[0]
"Recent work in distributional reinforcement learning has proposed the use of quantile regression as a method for minimizing the 1-Wasserstein in the univariate case when approximating using a mixture of Dirac functions (Dabney et al., 2018b).",2.1. Distance Metrics and Loss Functions,[0],[0]
"In this section, we review quantile regression as a method for estimating the quantile function of a distribution at specific points, i.e. its inverse cumulative distribution function.",2.2. Quantile Regression,[0],[0]
"This leads to recent work on approximating a distribution by a neural network approximation of its quantile function, acting as a reparameterization of a random sample from the uniform distribution.
",2.2. Quantile Regression,[0],[0]
"The quantile regression loss (Koenker & Hallock, 2001) for a quantile at τ ∈",2.2. Quantile Regression,[0],[0]
"[0, 1] and error u (positive for underestimation and negative for overestimation) is given by ρτ (u) =",2.2. Quantile Regression,[0],[0]
(τ − I{u ≤,2.2. Quantile Regression,[0],[0]
0})u.,2.2. Quantile Regression,[0],[0]
It is an asymmetric loss function penalizing underestimation by weight τ and overestimation by weight 1,2.2. Quantile Regression,[0],[0]
− τ .,2.2. Quantile Regression,[0],[0]
"For a given scalar distribution Z with c.d.f. FZ and a quantile τ , the inverse c.d.f. q = F−1Z (τ) minimizes the expected quantile regression loss Ez∼Z",2.2. Quantile Regression,[0],[0]
[ρτ (z − q)].,2.2. Quantile Regression,[0],[0]
Using this loss allows one to train a neural network to approximate a scalar distribution represented by its inverse c.d.f.,2.2. Quantile Regression,[0],[0]
"For this, the network can output a fixed grid of quantiles (Dabney et al., 2018b), with the respective quantile regression losses being applied to each output independently.",2.2. Quantile Regression,[0],[0]
"A more effective approach is to provide the desired quantile τ as an additional input to the network, and train it to output the corresponding value of F−1Z (τ).",2.2. Quantile Regression,[0],[0]
"The implicit quantile network (IQN) model (Dabney et al., 2018a) reparameterizes a sample τ ∼ U([0, 1]) through a deterministic function to produce samples from the underlying data distribution.",2.2. Quantile Regression,[0],[0]
These two methods can be seen to belong to the top-right and bottom-right categories in Figure 1.,2.2. Quantile Regression,[0],[0]
"An IQN Qθ can be trained by stochastic gradient descent on the quantile regression loss, with u = z −Qθ(τ) and training samples (z, τ) drawn from z ∼ Z and τ ∼ U([0, 1]).
",2.2. Quantile Regression,[0],[0]
"One drawback to the quantile regression loss is that gradients do not scale with the magnitude of the error, but instead with the sign of the error and the quantile weight τ .",2.2. Quantile Regression,[0],[0]
This increases gradient variance and can negatively impact the final model’s sample quality.,2.2. Quantile Regression,[0],[0]
"Increasing the batch size, and thus averaging over more values of τ , would have the effect of lowering this variance.",2.2. Quantile Regression,[0],[0]
"Alternatively, we can smooth the gradients as the model converges by allowing errors, under some threshold κ, to be scaled with their magnitude, reverting to an expectile loss.",2.2. Quantile Regression,[0],[0]
"This results in the Huber quantile loss (Huber, 1964; Dabney et al., 2018b):
ρκτ (u) =
{ |τ−I{u≤0}| 2κ u
2, if |u| ≤ κ, |τ −",2.2. Quantile Regression,[0],[0]
I{u ≤ 0}|(|u|,2.2. Quantile Regression,[0],[0]
"− 12κ), otherwise.",2.2. Quantile Regression,[0],[0]
(2),2.2. Quantile Regression,[0],[0]
"Let X = (X1, . . .",3. Autoregressive Implicit Quantiles,[0],[0]
", Xn) ∈",3. Autoregressive Implicit Quantiles,[0],[0]
X1 × · · · × Xn = X be an ndimensional random variable.,3. Autoregressive Implicit Quantiles,[0],[0]
"We begin by analyzing the effect of two naive applications of IQN to modeling the distribution of X .
",3. Autoregressive Implicit Quantiles,[0],[0]
"First, suppose we use the same quantile target, τ ∈",3. Autoregressive Implicit Quantiles,[0],[0]
"[0, 1], for every output dimension.",3. Autoregressive Implicit Quantiles,[0],[0]
"The only modification to IQN would be to output n dimensions instead of 1, the loss being applied to each output dimension independently.",3. Autoregressive Implicit Quantiles,[0],[0]
This is equivalent to assuming that the dimensions of X are comonotonic.,3. Autoregressive Implicit Quantiles,[0],[0]
"Two random variables are comonotonic if and only if they can be expressed as nondecreasing (deterministic) functions of a single random variable (Dhaene et al., 2006).",3. Autoregressive Implicit Quantiles,[0],[0]
Thus a joint quantile function for a comonotonic X can be written as F−1X (τ) =,3. Autoregressive Implicit Quantiles,[0],[0]
"(F−1X1 (τ), F −1 X2
(τ), . . .",3. Autoregressive Implicit Quantiles,[0],[0]
", F−1Xn(τ)).",3. Autoregressive Implicit Quantiles,[0],[0]
"While there are many interesting uses for comonotonic random variables, we believe this assumption is too strong to be useful more broadly.
",3. Autoregressive Implicit Quantiles,[0],[0]
"Second, one could use a separate value τi ∈",3. Autoregressive Implicit Quantiles,[0],[0]
"[0, 1] for each Xi, with the IQN being unchanged from the first case.",3. Autoregressive Implicit Quantiles,[0],[0]
This corresponds to making an independence assumption on the dimensions of X .,3. Autoregressive Implicit Quantiles,[0],[0]
"Again we would expect this to be an unreasonably restrictive modeling assumption for many domains, such as the case of natural images.
",3. Autoregressive Implicit Quantiles,[0],[0]
"Now, we turn to our proposed approach of extending IQN to multivariate distributions.",3. Autoregressive Implicit Quantiles,[0],[0]
We fix an ordering of the n dimensions.,3. Autoregressive Implicit Quantiles,[0],[0]
"If the density function pX is expressed as a product of conditional likelihoods, as in Equation 1, then the joint c.d.f. can be written as
FX(x) = P(X1 ≤",3. Autoregressive Implicit Quantiles,[0],[0]
"x1, . .",3. Autoregressive Implicit Quantiles,[0],[0]
.,3. Autoregressive Implicit Quantiles,[0],[0]
", Xn ≤ xn),
",3. Autoregressive Implicit Quantiles,[0],[0]
= n∏ i=1,3. Autoregressive Implicit Quantiles,[0],[0]
"FXi|Xi−1,...,X1(xi).
",3. Autoregressive Implicit Quantiles,[0],[0]
"Furthermore, for τjoint = ∏n i=1 τi, we can write the jointquantile function of X as
F−1X (τjoint) =",3. Autoregressive Implicit Quantiles,[0],[0]
"(F −1 X1 (τ1), . . .",3. Autoregressive Implicit Quantiles,[0],[0]
", F −1 Xn|Xn−1,...(τn)).
",3. Autoregressive Implicit Quantiles,[0],[0]
"This approach has been used previously by Koenker & Xiao (2006), who introduced a quantile autoregression model for quantile regression on time-series.
",3. Autoregressive Implicit Quantiles,[0],[0]
We propose to extend IQN to an autoregressive model of the above conditional form of a joint-quantile function.,3. Autoregressive Implicit Quantiles,[0],[0]
"Denoting X1:i = X1 × · · · × Xi, let X̃ := ⋃n i=0 X1:i be the space of ‘partial’ data points.",3. Autoregressive Implicit Quantiles,[0],[0]
We can define the autoregressive IQN as a deterministic functionQθ :,3. Autoregressive Implicit Quantiles,[0],[0]
X̃ ×,3. Autoregressive Implicit Quantiles,[0],[0]
"[0, 1]n → X̃ , mapping partial samples x̃ ∈ X̃ and quantile targets τi ∈",3. Autoregressive Implicit Quantiles,[0],[0]
"[0, 1] to estimates of F−1X .",3. Autoregressive Implicit Quantiles,[0],[0]
We can then train Qθ using a quantile regression loss (Equation 2).,3. Autoregressive Implicit Quantiles,[0],[0]
"For generation, one can iterate x1:i = Qθ(x1:i−1, τi), on a sequence of growing partial samples2 x1:i−1 and independently sampled τi ∼ U([0, 1]), for i = 1, . . .",3. Autoregressive Implicit Quantiles,[0],[0]
", n, to finally obtain a sample x = x1:n.",3. Autoregressive Implicit Quantiles,[0],[0]
"As previously mentioned, for the restricted model class of a uniform mixture of Diracs, quantile regression can be shown to minimize the 1-Wasserstein metric (Dabney et al., 2018b).",3.1. Quantile Regression and the Wasserstein,[0],[0]
"We extend this analysis for the case of arbitrary approximate quantile functions, and find that quantile regression minimizes a closely related divergence which we call quantile divergence, defined, for any distributions P and Q, as
q(P,Q) := ∫ 1 0",3.1. Quantile Regression and the Wasserstein,[0],[0]
[∫ F−1Q (τ),3.1. Quantile Regression and the Wasserstein,[0],[0]
"F−1P (τ) (FP (x)− τ)dx ] dτ.
",3.1. Quantile Regression and the Wasserstein,[0],[0]
"Indeed, the expected quantile loss of any parameterized quantile function Q̄θ equals, up to a constant, the quantile divergence between P and the distribution Qθ implicitly defined by Q̄θ:
E τ∼U([0,1])",3.1. Quantile Regression and the Wasserstein,[0],[0]
[ E z∼P [ρτ (z − Q̄θ(τ))],3.1. Quantile Regression and the Wasserstein,[0],[0]
"] = q(P,Qθ) + h(P ),
where h(P ) does not depend on Qθ.",3.1. Quantile Regression and the Wasserstein,[0],[0]
"Thus quantile regression minimizes the quantile divergence q(P,Qθ) and the sample gradient ∇θρτ (z − Q̄θ(τ))",3.1. Quantile Regression and the Wasserstein,[0],[0]
"(for τ ∼ U([0, 1]) and z ∼ P ) is an unbiased estimate of ∇θq(P,Qθ).",3.1. Quantile Regression and the Wasserstein,[0],[0]
See Appendix for proofs.,3.1. Quantile Regression and the Wasserstein,[0],[0]
"Although IQN does not directly model the log-likelihood of the data distribution, observe that we can still query the implied density at a point (Jones, 1992):
∂
∂τ F−1X (τ) =
1
pX(F −1 X (τ))
.
",3.2. Quantile Density Function,[0],[0]
"Indeed, this quantity, known as the sparsity function (Tukey, 1965) or the quantile-density function (Parzen, 1979) plays
2Throughout we understand x0 = x1:0 ∈ X1:0 to denote the ‘empty tuple’, and the function Qθ to map this to a single unconditional sample x1 = x1:1 = Qθ(x0, τ1).
",3.2. Quantile Density Function,[0],[0]
"a central role in the analysis of quantile regression models (Koenker, 1994).",3.2. Quantile Density Function,[0],[0]
"A common approach involves choosing a bandwidth parameter h and estimating this quantity through finite-differences around the value of interest as (F−1X (τ+h)−F−1X (τ−h))/2h (Siddiqui, 1960).",3.2. Quantile Density Function,[0],[0]
"However, as we have the full quantile function, the quantile-density function can be computed exactly using a single step of back-propagation to compute ∂F
−1(τ) ∂τ .",3.2. Quantile Density Function,[0],[0]
"As this only allows
querying the density given the value of τ , application to general likelihoods would require finding the value of τ that produces the closest approximation to the query point x.",3.2. Quantile Density Function,[0],[0]
"Though arguably too inefficient for training, this could potentially be used to interrogate the model.",3.2. Quantile Density Function,[0],[0]
"To test our proposed method, which is architecturally compatible with many generative model approaches, we wanted to compare and contrast IQN, that is quantile regression and quantile reparameterization, with a method trained with an explicit parameterization to minimize KL divergence.",4. PixelIQN,[0],[0]
"A natural choice for this was PixelCNN, specifically we build upon the Gated PixelCNN of van den Oord et al. (2016b).
",4. PixelIQN,[0],[0]
"The Gated PixelCNN takes as input an image x ∼ X , sampled from the training distribution at training time, and potentially all zeros or partially generated at generation time, as well as a location-dependent context s.",4. PixelIQN,[0],[0]
"The model consists of a number of residual layer blocks, whose structure is chosen to allow each output pixel to be a function of all preceding input pixels (in a raster-scan order).",4. PixelIQN,[0],[0]
"At its core, each layer block computes two gated activations of the form
y = tanh(Wk,f ∗ x+ Vk,f ∗ s) σ(Wk,g ∗ x+",4. PixelIQN,[0],[0]
"Vk,g ∗ s), with k the layer index, ∗ denoting convolution, and Vk,f and Vk,g being 1 × 1 convolution kernels.",4. PixelIQN,[0],[0]
"See Figure 2 for a full schematic depiction of a Gated PixelCNN layer
block.",4. PixelIQN,[0],[0]
"After a number of such layer blocks, the PixelCNN produces a final output layer with shape (n, n, 3, 256), with a softmax across the final dimension, corresponding to the approximate conditional likelihood for the value of each pixel-channel.",4. PixelIQN,[0],[0]
"That is, the conditional likelihood is the product of these individual autoregressive models,
p(x|s) = 3n2∏ i=1",4. PixelIQN,[0],[0]
"p(xi|x1, . . .",4. PixelIQN,[0],[0]
", xi−1, si).
",4. PixelIQN,[0],[0]
"Typically the location-dependent conditioning term was used to condition on class labels, but here, we will use it to condition on the sample point3 τ ∈",4. PixelIQN,[0],[0]
"[0, 1]3n2 .",4. PixelIQN,[0],[0]
"Thus, in addition to the input image x we input, in place of s, the sample points τ = (τ1, . . .",4. PixelIQN,[0],[0]
", τ3n2) to be reparameterized, with each τi ∼ U([0, 1]).",4. PixelIQN,[0],[0]
"Finally, our network outputs only the full sample image of shape (n, n, 3), without the need for an additional softmax layer.",4. PixelIQN,[0],[0]
Note that the number of τ values generated exactly corresponds to the number of random draws from softmax distributions in the original PixelCNN.,4. PixelIQN,[0],[0]
"We are simply changing the role of the randomness, from a draw at the output to a part of the input.
",4. PixelIQN,[0],[0]
"Architecturally, our proposed model, PixelIQN, is exactly the network given by van den Oord et al. (2016b), with the one exception that we output only a single value per pixel-channel and do not require the softmax activations.
",4. PixelIQN,[0],[0]
"In PixelCNN training is done by passing the training image through the network, and training each output softmax distribution using the KL divergence between the training image and the approximate distribution,∑
i
DKL(δxi , p(·|x1, . . .",4. PixelIQN,[0],[0]
", xi−1)).
",4. PixelIQN,[0],[0]
"For PixelIQN, the input is the training image x and a sample point τ ∼ U([0, 1]3n2).",4. PixelIQN,[0],[0]
"The output values Qx(τ) ∈ R3n 2 are interpreted as the approximate quantile function at τ , Qx(τ)i = QX(τi|xi−1, . . .), trained with a single step of quantile regression towards the observed sample",4. PixelIQN,[0],[0]
"x:∑
i
",4. PixelIQN,[0],[0]
"ρκτi(xi −QX(τi|xi−1, . .",4. PixelIQN,[0],[0]
.)).,4. PixelIQN,[0],[0]
"We begin by demonstrating PixelIQN on CIFAR-10 (Krizhevsky & Hinton, 2009).",4.1. CIFAR-10,[0],[0]
"For comparison, we train both a baseline Gated PixelCNN and a PixelIQN.",4.1. CIFAR-10,[0],[0]
"Both models correspond to the 15-layer network variant in (van den Oord et al., 2016b), see Appendix for detailed hyperparameters and training procedure.",4.1. CIFAR-10,[0],[0]
"The two methods have substantially different loss functions, so we performed a
3Conditioning on labels remains possible (see Section 4.2).
hyperparameter search using a short training run, with the same number (500) of hyperparameter configurations evaluated for both models.",4.1. CIFAR-10,[0],[0]
"For all results, we report full training runs using the best found hyperparameters in each case.",4.1. CIFAR-10,[0],[0]
"The evaluation metric used for the hyperparameter search was the Fréchet Inception Distance (FID) (Heusel et al., 2017), see Appendix for details.",4.1. CIFAR-10,[0],[0]
"In addition to FID, we report Inception score (Salimans et al., 2016) for both models.
",4.1. CIFAR-10,[0],[0]
Figure 4 (left) shows Inception score and FID for both models evaluated at several points throughout training.,4.1. CIFAR-10,[0],[0]
"The fully trained PixelCNN achieves an Inception score and FID of 4.6 and 65.9 respectively, while PixelIQN substantially outperforms it with an Inception score of 5.3 and FID of 49.5.",4.1. CIFAR-10,[0],[0]
"This also compares favorably with e.g. WGAN (Arjovsky et al., 2017), which reaches an Inception score of 3.8.",4.1. CIFAR-10,[0],[0]
"For subjective evaluations, we give samples from both models in Figure 3.",4.1. CIFAR-10,[0],[0]
Samples coming from PixelIQN are much more visually coherent.,4.1. CIFAR-10,[0],[0]
"Of note, the PixelIQN model achieves
a performance level comparable to that of the fully trained PixelCNN with only about one third the number of training updates (and about one third of the wall-clock time).",4.1. CIFAR-10,[0],[0]
"Next, we turn to the small ImageNet dataset (Russakovsky et al., 2015), first used for generative modeling in the PixelRNN work (van den Oord et al., 2016c).",4.2. ImageNet 32x32,[0],[0]
"Again, we evaluate using FID and Inception score.",4.2. ImageNet 32x32,[0],[0]
"For this much harder dataset, we base our PixelCNN and PixelIQN models on the larger 20-layer variant used in (van den Oord et al., 2016b).",4.2. ImageNet 32x32,[0],[0]
"Due to substantially longer training time for this model, we did not perform additional hyperparameter tuning, and mostly used the same hyperparameter values as in the previous sections for both models; details can be found in the Appendix.
",4.2. ImageNet 32x32,[0],[0]
Figure 4 shows Inception score and FID throughout training of PixelCNN and PixelIQN.,4.2. ImageNet 32x32,[0],[0]
"Again, PixelIQN substan-
tially outperforms the baseline in terms of final performance and sample complexity.",4.2. ImageNet 32x32,[0],[0]
"For final scores and a comparison to state-of-the-art GAN models, see Table 1.",4.2. ImageNet 32x32,[0],[0]
Figure 5 shows random (non-cherry-picked) samples from both models.,4.2. ImageNet 32x32,[0],[0]
"Compared to PixelCNN, PixelIQN samples appear to have superior quality with more global consistency and less ‘high-frequency noise’.
",4.2. ImageNet 32x32,[0],[0]
"In Figure 6, we show the inpainting performance of PixelIQN, by fixing the top half of a validation set image as input and sampling repeatedly from the model to generate different completions.",4.2. ImageNet 32x32,[0],[0]
We note that the model consistently generates plausible completions with significant diversity between different completion samples for the same input image.,4.2. ImageNet 32x32,[0],[0]
"Meanwhile, WGAN-GP has been seen to produce deterministic completions (Bellemare et al., 2017).
",4.2. ImageNet 32x32,[0],[0]
"Following (van den Oord et al., 2016b), we also trained a class-conditional PixelIQN variant, providing to the model the one-hot class label corresponding to a training image (in addition to a τ sample).",4.2. ImageNet 32x32,[0],[0]
"Samples from a class-conditional model can be expected to have higher visual quality, as the class label provides log2(1000)",4.2. ImageNet 32x32,[0],[0]
"≈ 10 bits of information, see Figure 7.",4.2. ImageNet 32x32,[0],[0]
"As seen in Figure 4 and Table 1, class conditioning also further improves Inception score and FID.",4.2. ImageNet 32x32,[0],[0]
"To generate each sample for the computation of these scores, we sample one of 1000 class labels randomly, then generate an image conditioned on this label via the trained model.
",4.2. ImageNet 32x32,[0],[0]
"Finally, motivated by the very long training time for the large PixelCNN model (approximately 1 day per 100K training steps, on 16 NVIDIA Tesla P100 GPUs), we also trained smaller 15-layer versions of the models (same as the ones used on CIFAR-10) on the small ImageNet dataset.",4.2. ImageNet 32x32,[0],[0]
"For comparison, these take approximately 12 hours for 100K training steps on a single P100 GPU, or less than 3 hours on 8 P100 GPUs.",4.2. ImageNet 32x32,[0],[0]
"As expected, little PixelCNN, while suitable
for the CIFAR-10 dataset, fails to achieve competitive scores on the ImageNet dataset, achieving Inception score 5.1 and FID 66.4.",4.2. ImageNet 32x32,[0],[0]
"Astonishingly, little PixelIQN on this dataset reaches Inception score 7.3 and FID 38.5, see Figure 4 (right).",4.2. ImageNet 32x32,[0],[0]
"It thereby not only outperforms the little PixelCNN, but also the larger 20-layer version!",4.2. ImageNet 32x32,[0],[0]
"This strongly supports the hypothesis that PixelCNN, and potentially many other models, are constrained not only by their model capacity, but crucially also by the sub-optimal trade-offs made by their log-likelihood training criterion, failing to align with perceptual or evaluation metrics.",4.2. ImageNet 32x32,[0],[0]
Most existing generative models for images belong to one of two classes.,5. Discussion and Conclusions,[0],[0]
"The first are likelihood-based models, trained with an elementwise KL reconstruction loss, which,
while perceptually meaningless, provides robust optimization properties and high sample diversity.",5. Discussion and Conclusions,[0],[0]
"The second are GANs, trained based on a discriminator loss, typically better aligned with a perceptual metric and enabling the generator to produce realistic, globally consistent samples.",5. Discussion and Conclusions,[0],[0]
"Their advantages come at the cost of a harder optimization problem, high parameter sensitivity, and most importantly, a tendency to collapse modes of the data distribution.
",5. Discussion and Conclusions,[0],[0]
"AIQNs are a new, fundamentally different, technique for generative modeling.",5. Discussion and Conclusions,[0],[0]
"By using a quantile regression loss instead of KL divergence, they combine some of the best properties of the two model classes.",5. Discussion and Conclusions,[0],[0]
"By their nature, they preserve modes of the learned distribution, while producing perceptually appealing high-quality samples.",5. Discussion and Conclusions,[0],[0]
The inevitable approximation trade-offs a generative model makes when constrained by capacity or insufficient training can vary significantly depending on the loss used.,5. Discussion and Conclusions,[0],[0]
"We argue that the proposed quantile regression loss aligns more effectively with a given metric and therefore makes subjectively more advantageous trade-offs.
",5. Discussion and Conclusions,[0],[0]
Devising methods for quantile regression over multidimensional outputs is an active area of research.,5. Discussion and Conclusions,[0],[0]
"New methods are continuing to be investigated (Carlier et al., 2016; Hallin & Miroslav, 2016), and a promising direction for future work is to find ways to use these to replace autoregressive models.",5. Discussion and Conclusions,[0],[0]
"One approach to reducing the computational burden of such models is to apply AIQN to the latent dimensions
of a VAE.",5. Discussion and Conclusions,[0],[0]
"Similar in spirit to Rosca et al. (2017), this would use the VAE to reduce the dimensionality of the problem and the AIQN to sample from the true latent distribution.",5. Discussion and Conclusions,[0],[0]
"In the Appendix we give preliminary results using such an technique, on CelebA 64× 64 (Liu et al., 2015).",5. Discussion and Conclusions,[0],[0]
"We have shown that IQN, computationally cheap and technically simple, can be readily applied to existing architectures, PixelCNN and VAE (Appendix), improving robustness and sampling quality of the underlying model.",5. Discussion and Conclusions,[0],[0]
"We demonstrated that PixelIQN produces more realistic, globally coherent samples, and improves Inception score and FID.
",5. Discussion and Conclusions,[0],[0]
We further point out that many recent advances in generative models could be easily combined with our proposed method.,5. Discussion and Conclusions,[0],[0]
"Recent algorithmic improvements to GANs such as mini-batch discrimination and progressive growing (Salimans et al., 2016; Karras et al., 2017), while not strictly necessary in our work, could be applied to further improve performance.",5. Discussion and Conclusions,[0],[0]
"PixelCNN++ (Salimans et al., 2017) is an architectural improvement of PixelCNN, with several beneficial modifications supported by experimental evidence.",5. Discussion and Conclusions,[0],[0]
"Although we have built upon the original Gated PixelCNN in this work, we believe all of these modifications to be compatible with our work, except for the use of a mixture of logistics in place of PixelCNN’s softmax.",5. Discussion and Conclusions,[0],[0]
"As we have entirely replaced this model component, this change does not map onto our model.",5. Discussion and Conclusions,[0],[0]
"Of note, the motivation behind this change closely mirrors our own, in looking for a loss that respects the underlying metric between examples.",5. Discussion and Conclusions,[0],[0]
"The recent PixelSNAIL model (Chen et al., 2017) achieves stateof-the-art modeling performance by enhancing PixelCNN with ELU nonlinearities, modified block structure, and an attention mechanism.",5. Discussion and Conclusions,[0],[0]
"Again, all of these are fully compatible with our work and should improve results further.
",5. Discussion and Conclusions,[0],[0]
"Finally, the implicit quantile formulation lifts a number of architectural restrictions of previous generative models.",5. Discussion and Conclusions,[0],[0]
"Most importantly, the reparameterization as an inverse c.d.f. allows to learn distributions over continuous ranges without pre-specified boundaries or quantization.",5. Discussion and Conclusions,[0],[0]
"This enables modeling continuous-valued variables, for example for generation of sound (van den Oord et al., 2016a), opening multiple interesting avenues for further investigation.",5. Discussion and Conclusions,[0],[0]
We would like to acknowledge the important role many of our colleagues at DeepMind played for this work.,Acknowledgements,[0],[0]
"We especially thank Aäron van den Oord and Sander Dieleman for invaluable advice on the PixelCNN model; Ivo Danihelka and Danilo J. Rezende for careful reading and insightful comments on an earlier version of the paper; Igor Babuschkin, Alexandre Galashov, Dominik Grewe, Jacob Menick, and Mihaela Rosca for technical help.",Acknowledgements,[0],[0]
"We introduce autoregressive implicit quantile networks (AIQN), a fundamentally different approach to generative modeling than those commonly used, that implicitly captures the distribution using quantile regression.",abstractText,[0],[0]
"AIQN is able to achieve superior perceptual quality and improvements in evaluation metrics, without incurring a loss of sample diversity.",abstractText,[0],[0]
The method can be applied to many existing models and architectures.,abstractText,[0],[0]
"In this work we extend the PixelCNN model with AIQN and demonstrate results on CIFAR-10 and ImageNet using Inception score, FID, non-cherrypicked samples, and inpainting results.",abstractText,[0],[0]
We consistently observe that AIQN yields a highly stable algorithm that improves perceptual quality while maintaining a highly diverse distribution.,abstractText,[0],[0]
Autoregressive Quantile Networks for Generative Modeling,title,[0],[0]
"There has been a staggering increase in progress on generative modeling in recent years, built largely upon fundamental advances such as generative adversarial networks (Goodfellow et al., 2014), variational inference (Kingma & Welling, 2013), and autoregressive density estimation (van den Oord et al., 2016c).",1. Introduction,[0],[0]
"These have led to breakthroughs in state-ofthe-art generation of natural images (Karras et al., 2017) and audio (van den Oord et al., 2016a), and even been used for unsupervised learning of disentangled representations (Higgins et al., 2017; Chen et al., 2016).",1. Introduction,[0],[0]
"These domains often have real-valued distributions with underlying metrics; that is, there is a domain-specific notion of similarity between data points.",1. Introduction,[0],[0]
"This similarity is ignored by the predominant work-horse of generative modeling, the Kullback-Leibler (KL) divergence.",1. Introduction,[0],[0]
"Progress is now being made towards algorithms that optimize with respect to these underlying metrics (Arjovsky et al., 2017; Bousquet et al., 2017).
",1. Introduction,[0],[0]
"*Equal contribution 1DeepMind, London, UK.",1. Introduction,[0],[0]
"Correspondence to: Georg Ostrovski <ostrovski@google.com>, Will Dabney <wdabney@google.com>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"In this paper, we present a novel approach to generative modeling, that, while strikingly different from existing methods, is grounded in the well-understood statistical methods of quantile regression.",1. Introduction,[0],[0]
"Unlike the majority of recent work, we approach generative modeling without the use of the KL divergence, and without explicitly approximating a likelihood model.",1. Introduction,[0],[0]
"Like GANs, in this way we produce an implicitly defined model, but unlike GANs our optimization procedure is inherently stable and lacks degenerate solutions which cause loss of diversity and mode collapse.
",1. Introduction,[0],[0]
"Much of the recent research on GANs has been focused on improving stability (Radford et al., 2015; Arjovsky et al., 2017; Daskalakis et al., 2017) and sample diversity (Gulrajani et al., 2017; Salimans et al., 2016; 2018).",1. Introduction,[0],[0]
"By stark contrast, methods such as PixelCNN (van den Oord et al., 2016b) readily produce high diversity, but due to their use of KL divergence are unable to make reasonable trade-offs between likelihood and perceptual similarity (Theis et al., 2015; Bellemare et al., 2017; Bousquet et al., 2017).
",1. Introduction,[0],[0]
"Our proposed method, autoregressive implicit quantile networks (AIQN), combines the benefits of both: a loss function that respects the underlying metric of the data leading to improved perceptual quality, and a stable optimization process leading to highly diverse samples.",1. Introduction,[0],[0]
"While there has been an increasing tendency towards complex architectures (Chen et al., 2017; Salimans et al., 2017) and multiple objective loss functions to overcome these challenges, AIQN is conceptually simple and does not rely on any special architecture or optimization techniques.",1. Introduction,[0],[0]
"Empirically it proves to be robust to hyperparameter variations and easy to optimize.
",1. Introduction,[0],[0]
"Our work is motivated by the recent advances achieved by reframing GANs in terms of optimal transport, leading to the Wasserstein GAN algorithm (Arjovsky et al., 2017), as well as work towards understanding the relationship between optimal transport and both GANs and VAEs (Bousquet et al., 2017).",1. Introduction,[0],[0]
"In agreement with these results, we focus on loss functions grounded in perceptually meaningful metrics.",1. Introduction,[0],[0]
"We build upon recent work in distributional reinforcement learning (Dabney et al., 2018a), which has begun to bridge the gap between approaches in reinforcement learning and unsupervised learning.",1. Introduction,[0],[0]
"Towards a practical algorithm we base our experimental results on Gated PixelCNN (van den Oord et al., 2016b), and show that using AIQN significantly im-
proves objective performance on CIFAR-10 and ImageNet 32x32 in terms of Fréchet Inception Distance (FID) and Inception score, as well as subjective perceptual quality in image samples and inpainting.",1. Introduction,[0],[0]
"We begin by establishing some notation, before turning to a review of three of the most prevalent methods for generative modeling.",2. Background,[0],[0]
"Calligraphic letters (e.g.X ) denote sets or spaces, capital letters (e.g. X) denote random variables, and lower case letters (e.g. x) indicate values.",2. Background,[0],[0]
"A probability distribution with random variable X ∈ X is denoted pX ∈P(X ), its cumulative distribution function (c.d.f.)",2. Background,[0],[0]
"FX , and inverse c.d.f. or quantile function QX = F−1X .",2. Background,[0],[0]
When probability distributions or quantile functions are parameterized by some θ,2. Background,[0],[0]
"we will write pθ or Qθ recognizing that here we do not view θ as a random variable.
",2. Background,[0],[0]
"Perhaps the simplest way to approach generative modeling of a random variableX ∈ X is by fixing some discretization ofX into n separate values, say x1, . . .",2. Background,[0],[0]
", xn ∈ X , and parameterize the approximate distribution with pθ(xi) ∝",2. Background,[0],[0]
exp(θi).,2. Background,[0],[0]
"This type of categorical parameterization is widely used, only slightly less commonly when X does not lend itself naturally to such a partitioning.",2. Background,[0],[0]
"Typically, the parameters θ are optimized to minimize the Kullback-Leibler (KL) divergence between observed values of X and the model pθ, θ∗ = arg minθDKL(pX‖pθ).",2. Background,[0],[0]
"However, this is only tractable whenX is a small discrete set or at best low-dimensional.",2. Background,[0],[0]
A common method for extending a generative model or density estimator to multivariate distributions is to factor the density as a product of scalarvalued conditional distributions.,2. Background,[0],[0]
"Let X = (X1, . . .",2. Background,[0],[0]
", Xn), then for any permutation of the dimensions σ :",2. Background,[0],[0]
"Nn → Nn,
pX(x) =",2. Background,[0],[0]
"n∏ i=1 pXσ(i)(xσ(i)|xσ(1), . . .",2. Background,[0],[0]
", xσ(i−1)).",2. Background,[0],[0]
"(1)
When the conditional density is modeled by a simple (e.g. Gaussian) base distribution, the ordering of the dimensions can be crucial (Papamakarios et al., 2017).",2. Background,[0],[0]
"However, it is common practice to choose an arbitrary ordering and rely upon a more powerful conditional model to avoid these problems.",2. Background,[0],[0]
"This class of models includes PixelRNN and PixelCNN (van den Oord et al., 2016c;b), MAF (Papamakarios et al., 2017), MADE (Germain et al., 2015), and many others.",2. Background,[0],[0]
"Fundamentally, all these approaches use the KL divergence as their loss function.
",2. Background,[0],[0]
"Another class of methods, generally known as latent variable methods, can bypass the need for autoregressive models using a different modeling assumption.",2. Background,[0],[0]
"Specifically, consider the Variational Autoencoder (VAE) (Kingma & Welling, 2013; Rezende et al., 2014), which represents
pθ as the marginalization over a latent random variable Z ∈ Z .",2. Background,[0],[0]
"The VAE is trained to maximize an approximate lower bound of the log-likelihood of the observations:
log pθ(x) ≥ −DKL(qθ(z|x)‖p(z))",2. Background,[0],[0]
+,2. Background,[0],[0]
E,2. Background,[0],[0]
"[log pθ(x|z)] .
",2. Background,[0],[0]
"Although VAEs are straightforward to implement and optimize, and effective at capturing structure in highdimensional spaces, they often miss fine-grained detail, resulting in blurry images.
",2. Background,[0],[0]
"Generative Adversarial Networks (GANs) (Goodfellow et al., 2014) pose the problem of learning a generative model as a two-player zero-sum game between a discriminator D, attempting to distinguish between x ∼ pX (real data) and x ∼ pθ (generated data), and a generator G, attempting to generate data indistinguishable from real data.",2. Background,[0],[0]
"The generator is an implicit latent variable model that reparameterizes samples, typically from an isotropic Gaussian distribution, into values in X .",2. Background,[0],[0]
"The original formulation of GANs,
arg min G sup D",2. Background,[0],[0]
[ E X log(D(X)),2. Background,[0],[0]
"+ E Z log(1−D(G(Z))) ] ,
can be seen as minimizing a lower-bound on the JensenShannon divergence (Goodfellow et al., 2014; Bousquet et al., 2017).",2. Background,[0],[0]
"That is, even in the case of GANs we are often minimizing functions of the KL divergence1.
",2. Background,[0],[0]
"Many recent advances have come from principled combinations of these three fundamental methods (Makhzani et al., 2015; Dumoulin et al., 2016; Rosca et al., 2017).",2. Background,[0],[0]
"A common perspective in generative modeling is that the choice of model should encode existing metric assumptions about the domain, combined with a generic likelihoodfocused loss such as the KL divergence.",2.1. Distance Metrics and Loss Functions,[0],[0]
"Under this view, the KL’s general applicability and robust optimization properties make it a natural choice, and most implementations of the methods we reviewed in the previous section attempt to, at least indirectly, minimize a version of the KL.
",2.1. Distance Metrics and Loss Functions,[0],[0]
"On the other hand, as every model inevitably makes tradeoffs when constrained by capacity or limited training, it is desirable for its optimization goal to incentivize trade-offs prioritizing approximately correct solutions, when the data space is endowed with a metric supporting a meaningful (albeit potentially subjective) notion of approximation.",2.1. Distance Metrics and Loss Functions,[0],[0]
"It has been argued (Theis et al., 2015; Bousquet et al., 2017; Arjovsky et al., 2017; Bellemare et al., 2017) that the KL may not always be appropriate from this perspective, by making sub-optimal trade-offs between likelihood and similarity.
",2.1. Distance Metrics and Loss Functions,[0],[0]
"1The Jensen-Shannon divergence is the sum of KLs between distributions P,Q and their uniform mixture M = 0.5(P +Q): JSD(P ||Q)",2.1. Distance Metrics and Loss Functions,[0],[0]
"= 0.5(DKL(P ||M) +DKL(Q||M)).
",2.1. Distance Metrics and Loss Functions,[0],[0]
"Indeed, many limitations of existing models can be traced back to the use of KL, and the resulting trade-offs in approximate solutions it implies.",2.1. Distance Metrics and Loss Functions,[0],[0]
"For instance, its use appears to play a central role in one of the primary failure modes of VAEs, that of blurry samples.",2.1. Distance Metrics and Loss Functions,[0],[0]
"Zhao et al. (2017) argue that the Gaussian posterior pθ(x|z) implies an overly simple model, which, when unable to perfectly fit the data, is forced to average (thus creating blur), and is not incentivized by the KL towards an alternative notion of approximate solution.",2.1. Distance Metrics and Loss Functions,[0],[0]
"Theis et al. (2015) emphasized that an improvement of log-likelihood does not necessarily translate to higher perceptual quality, and that the KL loss is more likely to produce atypical samples than some other training criteria.
",2.1. Distance Metrics and Loss Functions,[0],[0]
"We offer an alternative perspective: a good model should encode assumptions about the data distribution, whereas a good loss should encode the notion of similarity, that is, the underlying metric on the data space.",2.1. Distance Metrics and Loss Functions,[0],[0]
"From this point of view, the KL corresponds to an actual absence of explicit underlying metric, with complete focus on probability.
",2.1. Distance Metrics and Loss Functions,[0],[0]
"The optimal transport metrics Wc, for underlying metric c(x, x′), and in particular the p-Wasserstein distance, when c is an Lp metric, have frequently been proposed as being well-suited replacements to KL (Bousquet et al., 2017; Genevay et al., 2017).",2.1. Distance Metrics and Loss Functions,[0],[0]
"Briefly, the advantages are (1) avoidance of mode collapse (no need to choose between spreading over modes or collapsing to a single mode as in KL), and (2) the ability to trade off errors and incentivize approximations that respect the underlying metric.
",2.1. Distance Metrics and Loss Functions,[0],[0]
"Recently, Arjovsky et al. (2017) introduced the Wasserstein
GAN, reposing the two-player game as the estimation of the gradient of the 1-Wasserstein distance between the data and generator distributions.",2.1. Distance Metrics and Loss Functions,[0],[0]
"They reframe this in terms of the dual form of the 1-Wasserstein, with the critic estimating a function f which maximally separates the two distributions.",2.1. Distance Metrics and Loss Functions,[0],[0]
"While this is an exciting line of work, it still faces limitations when the critic solution is approximate, i.e. when f∗ is not found before each update.",2.1. Distance Metrics and Loss Functions,[0],[0]
"In this case, due to insufficient training of the critic (Bellemare et al., 2017) or limitations of the function approximator, the gradient direction produced can be arbitrarily bad (Bousquet et al., 2017).
",2.1. Distance Metrics and Loss Functions,[0],[0]
"Thus, we are left with the question of how to minimize a distribution loss respecting an underlying metric.",2.1. Distance Metrics and Loss Functions,[0],[0]
"Recent work in distributional reinforcement learning has proposed the use of quantile regression as a method for minimizing the 1-Wasserstein in the univariate case when approximating using a mixture of Dirac functions (Dabney et al., 2018b).",2.1. Distance Metrics and Loss Functions,[0],[0]
"In this section, we review quantile regression as a method for estimating the quantile function of a distribution at specific points, i.e. its inverse cumulative distribution function.",2.2. Quantile Regression,[0],[0]
"This leads to recent work on approximating a distribution by a neural network approximation of its quantile function, acting as a reparameterization of a random sample from the uniform distribution.
",2.2. Quantile Regression,[0],[0]
"The quantile regression loss (Koenker & Hallock, 2001) for a quantile at τ ∈",2.2. Quantile Regression,[0],[0]
"[0, 1] and error u (positive for underestimation and negative for overestimation) is given by ρτ (u) =",2.2. Quantile Regression,[0],[0]
(τ − I{u ≤,2.2. Quantile Regression,[0],[0]
0})u.,2.2. Quantile Regression,[0],[0]
It is an asymmetric loss function penalizing underestimation by weight τ and overestimation by weight 1,2.2. Quantile Regression,[0],[0]
− τ .,2.2. Quantile Regression,[0],[0]
"For a given scalar distribution Z with c.d.f. FZ and a quantile τ , the inverse c.d.f. q = F−1Z (τ) minimizes the expected quantile regression loss Ez∼Z",2.2. Quantile Regression,[0],[0]
[ρτ (z − q)].,2.2. Quantile Regression,[0],[0]
Using this loss allows one to train a neural network to approximate a scalar distribution represented by its inverse c.d.f.,2.2. Quantile Regression,[0],[0]
"For this, the network can output a fixed grid of quantiles (Dabney et al., 2018b), with the respective quantile regression losses being applied to each output independently.",2.2. Quantile Regression,[0],[0]
"A more effective approach is to provide the desired quantile τ as an additional input to the network, and train it to output the corresponding value of F−1Z (τ).",2.2. Quantile Regression,[0],[0]
"The implicit quantile network (IQN) model (Dabney et al., 2018a) reparameterizes a sample τ ∼ U([0, 1]) through a deterministic function to produce samples from the underlying data distribution.",2.2. Quantile Regression,[0],[0]
These two methods can be seen to belong to the top-right and bottom-right categories in Figure 1.,2.2. Quantile Regression,[0],[0]
"An IQN Qθ can be trained by stochastic gradient descent on the quantile regression loss, with u = z −Qθ(τ) and training samples (z, τ) drawn from z ∼ Z and τ ∼ U([0, 1]).
",2.2. Quantile Regression,[0],[0]
"One drawback to the quantile regression loss is that gradients do not scale with the magnitude of the error, but instead with the sign of the error and the quantile weight τ .",2.2. Quantile Regression,[0],[0]
This increases gradient variance and can negatively impact the final model’s sample quality.,2.2. Quantile Regression,[0],[0]
"Increasing the batch size, and thus averaging over more values of τ , would have the effect of lowering this variance.",2.2. Quantile Regression,[0],[0]
"Alternatively, we can smooth the gradients as the model converges by allowing errors, under some threshold κ, to be scaled with their magnitude, reverting to an expectile loss.",2.2. Quantile Regression,[0],[0]
"This results in the Huber quantile loss (Huber, 1964; Dabney et al., 2018b):
ρκτ (u) =
{ |τ−I{u≤0}| 2κ u
2, if |u| ≤ κ, |τ −",2.2. Quantile Regression,[0],[0]
I{u ≤ 0}|(|u|,2.2. Quantile Regression,[0],[0]
"− 12κ), otherwise.",2.2. Quantile Regression,[0],[0]
(2),2.2. Quantile Regression,[0],[0]
"Let X = (X1, . . .",3. Autoregressive Implicit Quantiles,[0],[0]
", Xn) ∈",3. Autoregressive Implicit Quantiles,[0],[0]
X1 × · · · × Xn = X be an ndimensional random variable.,3. Autoregressive Implicit Quantiles,[0],[0]
"We begin by analyzing the effect of two naive applications of IQN to modeling the distribution of X .
",3. Autoregressive Implicit Quantiles,[0],[0]
"First, suppose we use the same quantile target, τ ∈",3. Autoregressive Implicit Quantiles,[0],[0]
"[0, 1], for every output dimension.",3. Autoregressive Implicit Quantiles,[0],[0]
"The only modification to IQN would be to output n dimensions instead of 1, the loss being applied to each output dimension independently.",3. Autoregressive Implicit Quantiles,[0],[0]
This is equivalent to assuming that the dimensions of X are comonotonic.,3. Autoregressive Implicit Quantiles,[0],[0]
"Two random variables are comonotonic if and only if they can be expressed as nondecreasing (deterministic) functions of a single random variable (Dhaene et al., 2006).",3. Autoregressive Implicit Quantiles,[0],[0]
Thus a joint quantile function for a comonotonic X can be written as F−1X (τ) =,3. Autoregressive Implicit Quantiles,[0],[0]
"(F−1X1 (τ), F −1 X2
(τ), . . .",3. Autoregressive Implicit Quantiles,[0],[0]
", F−1Xn(τ)).",3. Autoregressive Implicit Quantiles,[0],[0]
"While there are many interesting uses for comonotonic random variables, we believe this assumption is too strong to be useful more broadly.
",3. Autoregressive Implicit Quantiles,[0],[0]
"Second, one could use a separate value τi ∈",3. Autoregressive Implicit Quantiles,[0],[0]
"[0, 1] for each Xi, with the IQN being unchanged from the first case.",3. Autoregressive Implicit Quantiles,[0],[0]
This corresponds to making an independence assumption on the dimensions of X .,3. Autoregressive Implicit Quantiles,[0],[0]
"Again we would expect this to be an unreasonably restrictive modeling assumption for many domains, such as the case of natural images.
",3. Autoregressive Implicit Quantiles,[0],[0]
"Now, we turn to our proposed approach of extending IQN to multivariate distributions.",3. Autoregressive Implicit Quantiles,[0],[0]
We fix an ordering of the n dimensions.,3. Autoregressive Implicit Quantiles,[0],[0]
"If the density function pX is expressed as a product of conditional likelihoods, as in Equation 1, then the joint c.d.f. can be written as
FX(x) = P(X1 ≤",3. Autoregressive Implicit Quantiles,[0],[0]
"x1, . .",3. Autoregressive Implicit Quantiles,[0],[0]
.,3. Autoregressive Implicit Quantiles,[0],[0]
", Xn ≤ xn),
",3. Autoregressive Implicit Quantiles,[0],[0]
= n∏ i=1,3. Autoregressive Implicit Quantiles,[0],[0]
"FXi|Xi−1,...,X1(xi).
",3. Autoregressive Implicit Quantiles,[0],[0]
"Furthermore, for τjoint = ∏n i=1 τi, we can write the jointquantile function of X as
F−1X (τjoint) =",3. Autoregressive Implicit Quantiles,[0],[0]
"(F −1 X1 (τ1), . . .",3. Autoregressive Implicit Quantiles,[0],[0]
", F −1 Xn|Xn−1,...(τn)).
",3. Autoregressive Implicit Quantiles,[0],[0]
"This approach has been used previously by Koenker & Xiao (2006), who introduced a quantile autoregression model for quantile regression on time-series.
",3. Autoregressive Implicit Quantiles,[0],[0]
We propose to extend IQN to an autoregressive model of the above conditional form of a joint-quantile function.,3. Autoregressive Implicit Quantiles,[0],[0]
"Denoting X1:i = X1 × · · · × Xi, let X̃ := ⋃n i=0 X1:i be the space of ‘partial’ data points.",3. Autoregressive Implicit Quantiles,[0],[0]
We can define the autoregressive IQN as a deterministic functionQθ :,3. Autoregressive Implicit Quantiles,[0],[0]
X̃ ×,3. Autoregressive Implicit Quantiles,[0],[0]
"[0, 1]n → X̃ , mapping partial samples x̃ ∈ X̃ and quantile targets τi ∈",3. Autoregressive Implicit Quantiles,[0],[0]
"[0, 1] to estimates of F−1X .",3. Autoregressive Implicit Quantiles,[0],[0]
We can then train Qθ using a quantile regression loss (Equation 2).,3. Autoregressive Implicit Quantiles,[0],[0]
"For generation, one can iterate x1:i = Qθ(x1:i−1, τi), on a sequence of growing partial samples2 x1:i−1 and independently sampled τi ∼ U([0, 1]), for i = 1, . . .",3. Autoregressive Implicit Quantiles,[0],[0]
", n, to finally obtain a sample x = x1:n.",3. Autoregressive Implicit Quantiles,[0],[0]
"As previously mentioned, for the restricted model class of a uniform mixture of Diracs, quantile regression can be shown to minimize the 1-Wasserstein metric (Dabney et al., 2018b).",3.1. Quantile Regression and the Wasserstein,[0],[0]
"We extend this analysis for the case of arbitrary approximate quantile functions, and find that quantile regression minimizes a closely related divergence which we call quantile divergence, defined, for any distributions P and Q, as
q(P,Q) := ∫ 1 0",3.1. Quantile Regression and the Wasserstein,[0],[0]
[∫ F−1Q (τ),3.1. Quantile Regression and the Wasserstein,[0],[0]
"F−1P (τ) (FP (x)− τ)dx ] dτ.
",3.1. Quantile Regression and the Wasserstein,[0],[0]
"Indeed, the expected quantile loss of any parameterized quantile function Q̄θ equals, up to a constant, the quantile divergence between P and the distribution Qθ implicitly defined by Q̄θ:
E τ∼U([0,1])",3.1. Quantile Regression and the Wasserstein,[0],[0]
[ E z∼P [ρτ (z − Q̄θ(τ))],3.1. Quantile Regression and the Wasserstein,[0],[0]
"] = q(P,Qθ) + h(P ),
where h(P ) does not depend on Qθ.",3.1. Quantile Regression and the Wasserstein,[0],[0]
"Thus quantile regression minimizes the quantile divergence q(P,Qθ) and the sample gradient ∇θρτ (z − Q̄θ(τ))",3.1. Quantile Regression and the Wasserstein,[0],[0]
"(for τ ∼ U([0, 1]) and z ∼ P ) is an unbiased estimate of ∇θq(P,Qθ).",3.1. Quantile Regression and the Wasserstein,[0],[0]
See Appendix for proofs.,3.1. Quantile Regression and the Wasserstein,[0],[0]
"Although IQN does not directly model the log-likelihood of the data distribution, observe that we can still query the implied density at a point (Jones, 1992):
∂
∂τ F−1X (τ) =
1
pX(F −1 X (τ))
.
",3.2. Quantile Density Function,[0],[0]
"Indeed, this quantity, known as the sparsity function (Tukey, 1965) or the quantile-density function (Parzen, 1979) plays
2Throughout we understand x0 = x1:0 ∈ X1:0 to denote the ‘empty tuple’, and the function Qθ to map this to a single unconditional sample x1 = x1:1 = Qθ(x0, τ1).
",3.2. Quantile Density Function,[0],[0]
"a central role in the analysis of quantile regression models (Koenker, 1994).",3.2. Quantile Density Function,[0],[0]
"A common approach involves choosing a bandwidth parameter h and estimating this quantity through finite-differences around the value of interest as (F−1X (τ+h)−F−1X (τ−h))/2h (Siddiqui, 1960).",3.2. Quantile Density Function,[0],[0]
"However, as we have the full quantile function, the quantile-density function can be computed exactly using a single step of back-propagation to compute ∂F
−1(τ) ∂τ .",3.2. Quantile Density Function,[0],[0]
"As this only allows
querying the density given the value of τ , application to general likelihoods would require finding the value of τ that produces the closest approximation to the query point x.",3.2. Quantile Density Function,[0],[0]
"Though arguably too inefficient for training, this could potentially be used to interrogate the model.",3.2. Quantile Density Function,[0],[0]
"To test our proposed method, which is architecturally compatible with many generative model approaches, we wanted to compare and contrast IQN, that is quantile regression and quantile reparameterization, with a method trained with an explicit parameterization to minimize KL divergence.",4. PixelIQN,[0],[0]
"A natural choice for this was PixelCNN, specifically we build upon the Gated PixelCNN of van den Oord et al. (2016b).
",4. PixelIQN,[0],[0]
"The Gated PixelCNN takes as input an image x ∼ X , sampled from the training distribution at training time, and potentially all zeros or partially generated at generation time, as well as a location-dependent context s.",4. PixelIQN,[0],[0]
"The model consists of a number of residual layer blocks, whose structure is chosen to allow each output pixel to be a function of all preceding input pixels (in a raster-scan order).",4. PixelIQN,[0],[0]
"At its core, each layer block computes two gated activations of the form
y = tanh(Wk,f ∗ x+ Vk,f ∗ s) σ(Wk,g ∗ x+",4. PixelIQN,[0],[0]
"Vk,g ∗ s), with k the layer index, ∗ denoting convolution, and Vk,f and Vk,g being 1 × 1 convolution kernels.",4. PixelIQN,[0],[0]
"See Figure 2 for a full schematic depiction of a Gated PixelCNN layer
block.",4. PixelIQN,[0],[0]
"After a number of such layer blocks, the PixelCNN produces a final output layer with shape (n, n, 3, 256), with a softmax across the final dimension, corresponding to the approximate conditional likelihood for the value of each pixel-channel.",4. PixelIQN,[0],[0]
"That is, the conditional likelihood is the product of these individual autoregressive models,
p(x|s) = 3n2∏ i=1",4. PixelIQN,[0],[0]
"p(xi|x1, . . .",4. PixelIQN,[0],[0]
", xi−1, si).
",4. PixelIQN,[0],[0]
"Typically the location-dependent conditioning term was used to condition on class labels, but here, we will use it to condition on the sample point3 τ ∈",4. PixelIQN,[0],[0]
"[0, 1]3n2 .",4. PixelIQN,[0],[0]
"Thus, in addition to the input image x we input, in place of s, the sample points τ = (τ1, . . .",4. PixelIQN,[0],[0]
", τ3n2) to be reparameterized, with each τi ∼ U([0, 1]).",4. PixelIQN,[0],[0]
"Finally, our network outputs only the full sample image of shape (n, n, 3), without the need for an additional softmax layer.",4. PixelIQN,[0],[0]
Note that the number of τ values generated exactly corresponds to the number of random draws from softmax distributions in the original PixelCNN.,4. PixelIQN,[0],[0]
"We are simply changing the role of the randomness, from a draw at the output to a part of the input.
",4. PixelIQN,[0],[0]
"Architecturally, our proposed model, PixelIQN, is exactly the network given by van den Oord et al. (2016b), with the one exception that we output only a single value per pixel-channel and do not require the softmax activations.
",4. PixelIQN,[0],[0]
"In PixelCNN training is done by passing the training image through the network, and training each output softmax distribution using the KL divergence between the training image and the approximate distribution,∑
i
DKL(δxi , p(·|x1, . . .",4. PixelIQN,[0],[0]
", xi−1)).
",4. PixelIQN,[0],[0]
"For PixelIQN, the input is the training image x and a sample point τ ∼ U([0, 1]3n2).",4. PixelIQN,[0],[0]
"The output values Qx(τ) ∈ R3n 2 are interpreted as the approximate quantile function at τ , Qx(τ)i = QX(τi|xi−1, . . .), trained with a single step of quantile regression towards the observed sample",4. PixelIQN,[0],[0]
"x:∑
i
",4. PixelIQN,[0],[0]
"ρκτi(xi −QX(τi|xi−1, . .",4. PixelIQN,[0],[0]
.)).,4. PixelIQN,[0],[0]
"We begin by demonstrating PixelIQN on CIFAR-10 (Krizhevsky & Hinton, 2009).",4.1. CIFAR-10,[0],[0]
"For comparison, we train both a baseline Gated PixelCNN and a PixelIQN.",4.1. CIFAR-10,[0],[0]
"Both models correspond to the 15-layer network variant in (van den Oord et al., 2016b), see Appendix for detailed hyperparameters and training procedure.",4.1. CIFAR-10,[0],[0]
"The two methods have substantially different loss functions, so we performed a
3Conditioning on labels remains possible (see Section 4.2).
hyperparameter search using a short training run, with the same number (500) of hyperparameter configurations evaluated for both models.",4.1. CIFAR-10,[0],[0]
"For all results, we report full training runs using the best found hyperparameters in each case.",4.1. CIFAR-10,[0],[0]
"The evaluation metric used for the hyperparameter search was the Fréchet Inception Distance (FID) (Heusel et al., 2017), see Appendix for details.",4.1. CIFAR-10,[0],[0]
"In addition to FID, we report Inception score (Salimans et al., 2016) for both models.
",4.1. CIFAR-10,[0],[0]
Figure 4 (left) shows Inception score and FID for both models evaluated at several points throughout training.,4.1. CIFAR-10,[0],[0]
"The fully trained PixelCNN achieves an Inception score and FID of 4.6 and 65.9 respectively, while PixelIQN substantially outperforms it with an Inception score of 5.3 and FID of 49.5.",4.1. CIFAR-10,[0],[0]
"This also compares favorably with e.g. WGAN (Arjovsky et al., 2017), which reaches an Inception score of 3.8.",4.1. CIFAR-10,[0],[0]
"For subjective evaluations, we give samples from both models in Figure 3.",4.1. CIFAR-10,[0],[0]
Samples coming from PixelIQN are much more visually coherent.,4.1. CIFAR-10,[0],[0]
"Of note, the PixelIQN model achieves
a performance level comparable to that of the fully trained PixelCNN with only about one third the number of training updates (and about one third of the wall-clock time).",4.1. CIFAR-10,[0],[0]
"Next, we turn to the small ImageNet dataset (Russakovsky et al., 2015), first used for generative modeling in the PixelRNN work (van den Oord et al., 2016c).",4.2. ImageNet 32x32,[0],[0]
"Again, we evaluate using FID and Inception score.",4.2. ImageNet 32x32,[0],[0]
"For this much harder dataset, we base our PixelCNN and PixelIQN models on the larger 20-layer variant used in (van den Oord et al., 2016b).",4.2. ImageNet 32x32,[0],[0]
"Due to substantially longer training time for this model, we did not perform additional hyperparameter tuning, and mostly used the same hyperparameter values as in the previous sections for both models; details can be found in the Appendix.
",4.2. ImageNet 32x32,[0],[0]
Figure 4 shows Inception score and FID throughout training of PixelCNN and PixelIQN.,4.2. ImageNet 32x32,[0],[0]
"Again, PixelIQN substan-
tially outperforms the baseline in terms of final performance and sample complexity.",4.2. ImageNet 32x32,[0],[0]
"For final scores and a comparison to state-of-the-art GAN models, see Table 1.",4.2. ImageNet 32x32,[0],[0]
Figure 5 shows random (non-cherry-picked) samples from both models.,4.2. ImageNet 32x32,[0],[0]
"Compared to PixelCNN, PixelIQN samples appear to have superior quality with more global consistency and less ‘high-frequency noise’.
",4.2. ImageNet 32x32,[0],[0]
"In Figure 6, we show the inpainting performance of PixelIQN, by fixing the top half of a validation set image as input and sampling repeatedly from the model to generate different completions.",4.2. ImageNet 32x32,[0],[0]
We note that the model consistently generates plausible completions with significant diversity between different completion samples for the same input image.,4.2. ImageNet 32x32,[0],[0]
"Meanwhile, WGAN-GP has been seen to produce deterministic completions (Bellemare et al., 2017).
",4.2. ImageNet 32x32,[0],[0]
"Following (van den Oord et al., 2016b), we also trained a class-conditional PixelIQN variant, providing to the model the one-hot class label corresponding to a training image (in addition to a τ sample).",4.2. ImageNet 32x32,[0],[0]
"Samples from a class-conditional model can be expected to have higher visual quality, as the class label provides log2(1000)",4.2. ImageNet 32x32,[0],[0]
"≈ 10 bits of information, see Figure 7.",4.2. ImageNet 32x32,[0],[0]
"As seen in Figure 4 and Table 1, class conditioning also further improves Inception score and FID.",4.2. ImageNet 32x32,[0],[0]
"To generate each sample for the computation of these scores, we sample one of 1000 class labels randomly, then generate an image conditioned on this label via the trained model.
",4.2. ImageNet 32x32,[0],[0]
"Finally, motivated by the very long training time for the large PixelCNN model (approximately 1 day per 100K training steps, on 16 NVIDIA Tesla P100 GPUs), we also trained smaller 15-layer versions of the models (same as the ones used on CIFAR-10) on the small ImageNet dataset.",4.2. ImageNet 32x32,[0],[0]
"For comparison, these take approximately 12 hours for 100K training steps on a single P100 GPU, or less than 3 hours on 8 P100 GPUs.",4.2. ImageNet 32x32,[0],[0]
"As expected, little PixelCNN, while suitable
for the CIFAR-10 dataset, fails to achieve competitive scores on the ImageNet dataset, achieving Inception score 5.1 and FID 66.4.",4.2. ImageNet 32x32,[0],[0]
"Astonishingly, little PixelIQN on this dataset reaches Inception score 7.3 and FID 38.5, see Figure 4 (right).",4.2. ImageNet 32x32,[0],[0]
"It thereby not only outperforms the little PixelCNN, but also the larger 20-layer version!",4.2. ImageNet 32x32,[0],[0]
"This strongly supports the hypothesis that PixelCNN, and potentially many other models, are constrained not only by their model capacity, but crucially also by the sub-optimal trade-offs made by their log-likelihood training criterion, failing to align with perceptual or evaluation metrics.",4.2. ImageNet 32x32,[0],[0]
Most existing generative models for images belong to one of two classes.,5. Discussion and Conclusions,[0],[0]
"The first are likelihood-based models, trained with an elementwise KL reconstruction loss, which,
while perceptually meaningless, provides robust optimization properties and high sample diversity.",5. Discussion and Conclusions,[0],[0]
"The second are GANs, trained based on a discriminator loss, typically better aligned with a perceptual metric and enabling the generator to produce realistic, globally consistent samples.",5. Discussion and Conclusions,[0],[0]
"Their advantages come at the cost of a harder optimization problem, high parameter sensitivity, and most importantly, a tendency to collapse modes of the data distribution.
",5. Discussion and Conclusions,[0],[0]
"AIQNs are a new, fundamentally different, technique for generative modeling.",5. Discussion and Conclusions,[0],[0]
"By using a quantile regression loss instead of KL divergence, they combine some of the best properties of the two model classes.",5. Discussion and Conclusions,[0],[0]
"By their nature, they preserve modes of the learned distribution, while producing perceptually appealing high-quality samples.",5. Discussion and Conclusions,[0],[0]
The inevitable approximation trade-offs a generative model makes when constrained by capacity or insufficient training can vary significantly depending on the loss used.,5. Discussion and Conclusions,[0],[0]
"We argue that the proposed quantile regression loss aligns more effectively with a given metric and therefore makes subjectively more advantageous trade-offs.
",5. Discussion and Conclusions,[0],[0]
Devising methods for quantile regression over multidimensional outputs is an active area of research.,5. Discussion and Conclusions,[0],[0]
"New methods are continuing to be investigated (Carlier et al., 2016; Hallin & Miroslav, 2016), and a promising direction for future work is to find ways to use these to replace autoregressive models.",5. Discussion and Conclusions,[0],[0]
"One approach to reducing the computational burden of such models is to apply AIQN to the latent dimensions
of a VAE.",5. Discussion and Conclusions,[0],[0]
"Similar in spirit to Rosca et al. (2017), this would use the VAE to reduce the dimensionality of the problem and the AIQN to sample from the true latent distribution.",5. Discussion and Conclusions,[0],[0]
"In the Appendix we give preliminary results using such an technique, on CelebA 64× 64 (Liu et al., 2015).",5. Discussion and Conclusions,[0],[0]
"We have shown that IQN, computationally cheap and technically simple, can be readily applied to existing architectures, PixelCNN and VAE (Appendix), improving robustness and sampling quality of the underlying model.",5. Discussion and Conclusions,[0],[0]
"We demonstrated that PixelIQN produces more realistic, globally coherent samples, and improves Inception score and FID.
",5. Discussion and Conclusions,[0],[0]
We further point out that many recent advances in generative models could be easily combined with our proposed method.,5. Discussion and Conclusions,[0],[0]
"Recent algorithmic improvements to GANs such as mini-batch discrimination and progressive growing (Salimans et al., 2016; Karras et al., 2017), while not strictly necessary in our work, could be applied to further improve performance.",5. Discussion and Conclusions,[0],[0]
"PixelCNN++ (Salimans et al., 2017) is an architectural improvement of PixelCNN, with several beneficial modifications supported by experimental evidence.",5. Discussion and Conclusions,[0],[0]
"Although we have built upon the original Gated PixelCNN in this work, we believe all of these modifications to be compatible with our work, except for the use of a mixture of logistics in place of PixelCNN’s softmax.",5. Discussion and Conclusions,[0],[0]
"As we have entirely replaced this model component, this change does not map onto our model.",5. Discussion and Conclusions,[0],[0]
"Of note, the motivation behind this change closely mirrors our own, in looking for a loss that respects the underlying metric between examples.",5. Discussion and Conclusions,[0],[0]
"The recent PixelSNAIL model (Chen et al., 2017) achieves stateof-the-art modeling performance by enhancing PixelCNN with ELU nonlinearities, modified block structure, and an attention mechanism.",5. Discussion and Conclusions,[0],[0]
"Again, all of these are fully compatible with our work and should improve results further.
",5. Discussion and Conclusions,[0],[0]
"Finally, the implicit quantile formulation lifts a number of architectural restrictions of previous generative models.",5. Discussion and Conclusions,[0],[0]
"Most importantly, the reparameterization as an inverse c.d.f. allows to learn distributions over continuous ranges without pre-specified boundaries or quantization.",5. Discussion and Conclusions,[0],[0]
"This enables modeling continuous-valued variables, for example for generation of sound (van den Oord et al., 2016a), opening multiple interesting avenues for further investigation.",5. Discussion and Conclusions,[0],[0]
We would like to acknowledge the important role many of our colleagues at DeepMind played for this work.,Acknowledgements,[0],[0]
"We especially thank Aäron van den Oord and Sander Dieleman for invaluable advice on the PixelCNN model; Ivo Danihelka and Danilo J. Rezende for careful reading and insightful comments on an earlier version of the paper; Igor Babuschkin, Alexandre Galashov, Dominik Grewe, Jacob Menick, and Mihaela Rosca for technical help.",Acknowledgements,[0],[0]
"We introduce autoregressive implicit quantile networks (AIQN), a fundamentally different approach to generative modeling than those commonly used, that implicitly captures the distribution using quantile regression.",abstractText,[0],[0]
"AIQN is able to achieve superior perceptual quality and improvements in evaluation metrics, without incurring a loss of sample diversity.",abstractText,[0],[0]
The method can be applied to many existing models and architectures.,abstractText,[0],[0]
"In this work we extend the PixelCNN model with AIQN and demonstrate results on CIFAR-10 and ImageNet using Inception score, FID, non-cherrypicked samples, and inpainting results.",abstractText,[0],[0]
We consistently observe that AIQN yields a highly stable algorithm that improves perceptual quality while maintaining a highly diverse distribution.,abstractText,[0],[0]
Autoregressive Quantile Networks for Generative Modeling,title,[0],[0]
"We study the problem of attributing the prediction of a deep network to its input features.
",1. Motivation and Summary of Results,[0],[0]
Definition 1.,1. Motivation and Summary of Results,[0],[0]
"Formally, suppose we have a function F :",1. Motivation and Summary of Results,[0],[0]
"Rn → [0, 1] that represents a deep network, and an input x = (x1, . . .",1. Motivation and Summary of Results,[0],[0]
", xn) ∈ Rn.",1. Motivation and Summary of Results,[0],[0]
"An attribution of the prediction at input x relative to a baseline input x′ is a vector AF (x, x
′) =",1. Motivation and Summary of Results,[0],[0]
"(a1, . . .",1. Motivation and Summary of Results,[0],[0]
", an) ∈ Rn where ai is the contribution of xi to the prediction F (x).
",1. Motivation and Summary of Results,[0],[0]
"For instance, in an object recognition network, an attribution method could tell us which pixels of the image were responsible for a certain label being picked (see Figure 2).",1. Motivation and Summary of Results,[0],[0]
"The attribution problem was previously studied by various papers (Baehrens et al., 2010; Simonyan et al., 2013;
",1. Motivation and Summary of Results,[0],[0]
"*Equal contribution 1Google Inc., Mountain View, USA.",1. Motivation and Summary of Results,[0],[0]
Correspondence to: Mukund Sundararajan <mukunds@google.com,1. Motivation and Summary of Results,[0],[0]
">, Ankur Taly <ataly@google.com>.
",1. Motivation and Summary of Results,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Motivation and Summary of Results,[0],[0]
"Copyright 2017 by the author(s).
",1. Motivation and Summary of Results,[0],[0]
"Shrikumar et al., 2016; Binder et al., 2016; Springenberg et al., 2014).
",1. Motivation and Summary of Results,[0],[0]
"The intention of these works is to understand the inputoutput behavior of the deep network, which gives us the ability to improve it.",1. Motivation and Summary of Results,[0],[0]
"Such understandability is critical to all computer programs, including machine learning models.",1. Motivation and Summary of Results,[0],[0]
There are also other applications of attribution.,1. Motivation and Summary of Results,[0],[0]
They could be used within a product driven by machine learning to provide a rationale for the recommendation.,1. Motivation and Summary of Results,[0],[0]
"For instance, a deep network that predicts a condition based on imaging could help inform the doctor of the part of the image that resulted in the recommendation.",1. Motivation and Summary of Results,[0],[0]
This could help the doctor understand the strengths and weaknesses of a model and compensate for it.,1. Motivation and Summary of Results,[0],[0]
We give such an example in Section 6.2.,1. Motivation and Summary of Results,[0],[0]
Attributions could also be used by developers in an exploratory sense.,1. Motivation and Summary of Results,[0],[0]
"For instance, we could use a deep network to extract insights that could be then used in a rulebased system.",1. Motivation and Summary of Results,[0],[0]
"In Section 6.3, we give such an example.
",1. Motivation and Summary of Results,[0],[0]
A significant challenge in designing an attribution technique is that they are hard to evaluate empirically.,1. Motivation and Summary of Results,[0],[0]
"As we discuss in Section 4, it is hard to tease apart errors that stem from the misbehavior of the model versus the misbehavior of the attribution method.",1. Motivation and Summary of Results,[0],[0]
"To compensate for this shortcoming, we take an axiomatic approach.",1. Motivation and Summary of Results,[0],[0]
In Section 2 we identify two axioms that every attribution method must satisfy.,1. Motivation and Summary of Results,[0],[0]
Unfortunately most previous methods do not satisfy one of these two axioms.,1. Motivation and Summary of Results,[0],[0]
"In Section 3, we use the axioms to identify a new method, called integrated gradients.
",1. Motivation and Summary of Results,[0],[0]
"Unlike previously proposed methods, integrated gradients do not need any instrumentation of the network, and can be computed easily using a few calls to the gradient operation, allowing even novice practitioners to easily apply the technique.
",1. Motivation and Summary of Results,[0],[0]
"In Section 6, we demonstrate the ease of applicability over several deep networks, including two images networks, two text processing networks, and a chemistry network.",1. Motivation and Summary of Results,[0],[0]
"These applications demonstrate the use of our technique in either improving our understanding of the network, performing debugging, performing rule extraction, or aiding an end user in understanding the network’s prediction.
",1. Motivation and Summary of Results,[0],[0]
Remark 1.,1. Motivation and Summary of Results,[0],[0]
Let us briefly examine the need for the baseline in the definition of the attribution problem.,1. Motivation and Summary of Results,[0],[0]
"A common way for humans to perform attribution relies on counter-
ar X
iv :1
70 3.
01 36
5v 2
[ cs
.L",1. Motivation and Summary of Results,[0],[0]
"G
] 1
3 Ju
n 20
17
factual intuition.",1. Motivation and Summary of Results,[0],[0]
When we assign blame to a certain cause we implicitly consider the absence of the cause as a baseline for comparing outcomes.,1. Motivation and Summary of Results,[0],[0]
"In a deep network, we model the absence using a single baseline input.",1. Motivation and Summary of Results,[0],[0]
"For most deep networks, a natural baseline exists in the input space where the prediction is neutral.",1. Motivation and Summary of Results,[0],[0]
"For instance, in object recognition networks, it is the black image.",1. Motivation and Summary of Results,[0],[0]
"The need for a baseline has also been pointed out by prior work on attribution (Shrikumar et al., 2016; Binder et al., 2016).",1. Motivation and Summary of Results,[0],[0]
We now discuss two axioms (desirable characteristics) for attribution methods.,2. Two Fundamental Axioms,[0],[0]
We find that other feature attribution methods in literature break at least one of the two axioms.,2. Two Fundamental Axioms,[0],[0]
"These methods include DeepLift (Shrikumar et al., 2016; 2017), Layer-wise relevance propagation (LRP) (Binder et al., 2016), Deconvolutional networks (Zeiler & Fergus, 2014), and Guided back-propagation (Springenberg et al., 2014).",2. Two Fundamental Axioms,[0],[0]
"As we will see in Section 3, these axioms will also guide the design of our method.
Gradients.",2. Two Fundamental Axioms,[0],[0]
"For linear models, ML practitioners regularly inspect the products of the model coefficients and the feature values in order to debug predictions.",2. Two Fundamental Axioms,[0],[0]
"Gradients (of the output with respect to the input) is a natural analog of the model coefficients for a deep network, and therefore the product of the gradient and feature values is a reasonable starting point for an attribution method (Baehrens et al., 2010; Simonyan et al., 2013); see the third column of Figure 2 for examples.",2. Two Fundamental Axioms,[0],[0]
"The problem with gradients is that they break sensitivity, a property that all attribution methods should satisfy.",2. Two Fundamental Axioms,[0],[0]
An attribution method satisfies Sensitivity(a),2.1. Axiom: Sensitivity(a),[0],[0]
if for every input and baseline that differ in one feature but have different predictions then the differing feature should be given a non-zero attribution.,2.1. Axiom: Sensitivity(a),[0],[0]
"(Later in the paper, we will have a part (b) to this definition.)
",2.1. Axiom: Sensitivity(a),[0],[0]
Gradients violate Sensitivity(a):,2.1. Axiom: Sensitivity(a),[0],[0]
"For a concrete example, consider a one variable, one ReLU network, f(x) = 1 − ReLU(1−x).",2.1. Axiom: Sensitivity(a),[0],[0]
Suppose the baseline is x = 0 and the input is x = 2.,2.1. Axiom: Sensitivity(a),[0],[0]
"The function changes from 0 to 1, but because f becomes flat at x = 1, the gradient method gives attribution of 0 to x. Intuitively, gradients break Sensitivity because the prediction function may flatten at the input and thus have zero gradient despite the function value at the input being different from that at the baseline.",2.1. Axiom: Sensitivity(a),[0],[0]
"This phenomenon has been reported in previous work (Shrikumar et al., 2016).
",2.1. Axiom: Sensitivity(a),[0],[0]
"Practically, the lack of sensitivity causes gradients to focus on irrelevant features (see the “fireboat” example in Fig-
ure 2).
",2.1. Axiom: Sensitivity(a),[0],[0]
Other back-propagation based approaches.,2.1. Axiom: Sensitivity(a),[0],[0]
A second set of approaches involve back-propagating the final prediction score through each layer of the network down to the individual features.,2.1. Axiom: Sensitivity(a),[0],[0]
"These include DeepLift, Layer-wise relevance propagation (LRP), Deconvolutional networks (DeConvNets), and Guided back-propagation.",2.1. Axiom: Sensitivity(a),[0],[0]
"These methods differ in the specific backpropagation logic for various activation functions (e.g., ReLU, MaxPool, etc.).
",2.1. Axiom: Sensitivity(a),[0],[0]
"Unfortunately, Deconvolution networks (DeConvNets), and Guided back-propagation violate Sensitivity(a).",2.1. Axiom: Sensitivity(a),[0],[0]
This is because these methods back-propogate through a ReLU node only if the ReLU is turned on at the input.,2.1. Axiom: Sensitivity(a),[0],[0]
"This makes the method similar to gradients, in that, the attribution is zero for features with zero gradient at the input despite a non-zero gradient at the baseline.",2.1. Axiom: Sensitivity(a),[0],[0]
"We defer the specific counterexamples to Appendix B.
Methods like DeepLift and LRP tackle the Sensitivity issue by employing a baseline, and in some sense try to compute “discrete gradients” instead of (instantaeneous) gradients at the input.",2.1. Axiom: Sensitivity(a),[0],[0]
(The two methods differ in the specifics of how they compute the discrete gradient).,2.1. Axiom: Sensitivity(a),[0],[0]
"But the idea is that a large, discrete step will avoid flat regions, avoiding a breakage of sensitivity.",2.1. Axiom: Sensitivity(a),[0],[0]
"Unfortunately, these methods violate a different requirement on attribution methods.",2.1. Axiom: Sensitivity(a),[0],[0]
"Two networks are functionally equivalent if their outputs are equal for all inputs, despite having very different implementations.",2.2. Axiom: Implementation Invariance,[0],[0]
"Attribution methods should satisfy Implementation Invariance, i.e., the attributions are always identical for two functionally equivalent networks.",2.2. Axiom: Implementation Invariance,[0],[0]
"To motivate this, notice that attribution can be colloquially defined as assigning the blame (or credit) for the output to the input features.",2.2. Axiom: Implementation Invariance,[0],[0]
"Such a definition does not refer to implementation details.
",2.2. Axiom: Implementation Invariance,[0],[0]
"We now discuss intuition for why DeepLift and LRP break Implementation Invariance; a concrete example is provided in Appendix B.
First, notice that gradients are invariant to implementation.",2.2. Axiom: Implementation Invariance,[0],[0]
"In fact, the chain-rule for gradients ∂f∂g = ∂f ∂h · ∂h ∂g is essentially about implementation invariance.",2.2. Axiom: Implementation Invariance,[0],[0]
"To see this, think of g and f as the input and output of a system, and h being some implementation detail of the system.",2.2. Axiom: Implementation Invariance,[0],[0]
"The gradient of output f to input g can be computed either directly by ∂f∂g , ignoring the intermediate function h (implementation detail), or by invoking the chain rule via h.",2.2. Axiom: Implementation Invariance,[0],[0]
"This is exactly how backpropagation works.
",2.2. Axiom: Implementation Invariance,[0],[0]
Methods like LRP and DeepLift replace gradients with discrete gradients and still use a modified form of backpropagation to compose discrete gradients into attributions.,2.2. Axiom: Implementation Invariance,[0],[0]
"Un-
fortunately, the chain rule does not hold for discrete gradients in general.",2.2. Axiom: Implementation Invariance,[0],[0]
Formally f(x1)−f(x0)g(x1)−g(x0) 6=,2.2. Axiom: Implementation Invariance,[0],[0]
"f(x1)−f(x0) h(x1)−h(x0) · h(x1)−h(x0) g(x1)−g(x0) , and therefore these methods fail to satisfy implementation invariance.
",2.2. Axiom: Implementation Invariance,[0],[0]
"If an attribution method fails to satisfy Implementation Invariance, the attributions are potentially sensitive to unimportant aspects of the models.",2.2. Axiom: Implementation Invariance,[0],[0]
"For instance, if the network architecture has more degrees of freedom than needed to represent a function then there may be two sets of values for the network parameters that lead to the same function.",2.2. Axiom: Implementation Invariance,[0],[0]
"The training procedure can converge at either set of values depending on the initializtion or for other reasons, but the underlying network function would remain the same.",2.2. Axiom: Implementation Invariance,[0],[0]
It is undesirable that attributions differ for such reasons.,2.2. Axiom: Implementation Invariance,[0],[0]
We are now ready to describe our technique.,3. Our Method: Integrated Gradients,[0],[0]
"Intuitively, our technique combines the Implementation Invariance of Gradients along with the Sensitivity of techniques like LRP or DeepLift.
",3. Our Method: Integrated Gradients,[0],[0]
"Formally, suppose we have a function F :",3. Our Method: Integrated Gradients,[0],[0]
"Rn → [0, 1] that represents a deep network.",3. Our Method: Integrated Gradients,[0],[0]
"Specifically, let x ∈",3. Our Method: Integrated Gradients,[0],[0]
"Rn be the input at hand, and x′ ∈ Rn be the baseline input.",3. Our Method: Integrated Gradients,[0],[0]
"For image networks, the baseline could be the black image, while for text models it could be the zero embedding vector.
",3. Our Method: Integrated Gradients,[0],[0]
"We consider the straightline path (in Rn) from the baseline x′ to the input x, and compute the gradients at all points along the path.",3. Our Method: Integrated Gradients,[0],[0]
Integrated gradients are obtained by cumulating these gradients.,3. Our Method: Integrated Gradients,[0],[0]
"Specifically, integrated gradients are defined as the path intergral of the gradients along the straightline path from the baseline x′ to the input x.
The integrated gradient along the ith dimension for an input x and baseline x′ is defined as follows.",3. Our Method: Integrated Gradients,[0],[0]
"Here, ∂F (x)∂xi is the gradient of F (x) along the ith dimension.
",3. Our Method: Integrated Gradients,[0],[0]
IntegratedGradsi(x) ::= (xi−x ′,3. Our Method: Integrated Gradients,[0],[0]
i)× ∫ 1 α=0 ∂F (x′+α×(x−x′)),3. Our Method: Integrated Gradients,[0],[0]
"∂xi dα
(1)",3. Our Method: Integrated Gradients,[0],[0]
Axiom: Completeness.,3. Our Method: Integrated Gradients,[0],[0]
"Integrated gradients satisfy an
axiom called completeness that the attributions add up to the difference between the output of F at the input x and the baseline x′.",3. Our Method: Integrated Gradients,[0],[0]
This axiom is identified as being desirable by Deeplift and LRP.,3. Our Method: Integrated Gradients,[0],[0]
"It is a sanity check that the attribution method is somewhat comprehensive in its accounting, a property that is clearly desirable if the networks score is used in a numeric sense, and not just to pick the top label, for e.g., a model estimating insurance premiums from credit features of individuals.
",3. Our Method: Integrated Gradients,[0],[0]
"This is formalized by the proposition below, which instantiates the fundamental theorem of calculus for path integrals.
",3. Our Method: Integrated Gradients,[0],[0]
Proposition 1.,3. Our Method: Integrated Gradients,[0],[0]
"If F : Rn → R is differentiable almost everywhere 1 then
Σni=1IntegratedGradsi(x)",3. Our Method: Integrated Gradients,[0],[0]
"= F (x)− F (x′)
",3. Our Method: Integrated Gradients,[0],[0]
"For most deep networks, it is possible to choose a baseline such that the prediction at the baseline is near zero (F (x′)",3. Our Method: Integrated Gradients,[0],[0]
≈ 0).,3. Our Method: Integrated Gradients,[0],[0]
"(For image models, the black image baseline indeed satisfies this property.)",3. Our Method: Integrated Gradients,[0],[0]
"In such cases, there is an intepretation of the resulting attributions that ignores the baseline and amounts to distributing the output to the individual input features.
",3. Our Method: Integrated Gradients,[0],[0]
Remark 2.,3. Our Method: Integrated Gradients,[0],[0]
Integrated gradients satisfies Sensivity(a) because Completeness implies Sensivity(a) and is thus a strengthening of the Sensitivity(a) axiom.,3. Our Method: Integrated Gradients,[0],[0]
"This is because Sensitivity(a) refers to a case where the baseline and the input differ only in one variable, for which Completeness asserts that the difference in the two output values is equal to the attribution to this variable.",3. Our Method: Integrated Gradients,[0],[0]
Attributions generated by integrated gradients satisfy Implementation Invariance since they are based only on the gradients of the function represented by the network.,3. Our Method: Integrated Gradients,[0],[0]
Prior literature has relied on empirically evaluating the attribution technique.,4. Uniqueness of Integrated Gradients,[0],[0]
"For instance, in the context of an object recognition task, (Samek et al., 2015) suggests that we select the top k pixels by attribution and randomly vary their intensities and then measure the drop in score.",4. Uniqueness of Integrated Gradients,[0],[0]
"If the attribution method is good, then the drop in score should be large.",4. Uniqueness of Integrated Gradients,[0],[0]
"However, the images resulting from pixel perturbation could be unnatural, and it could be that the scores drop simply because the network has never seen anything like it in training.",4. Uniqueness of Integrated Gradients,[0],[0]
"(This is less of a concern with linear or logistic models where the simplicity of the model ensures that ablating a feature does not cause strange interactions.)
",4. Uniqueness of Integrated Gradients,[0],[0]
"A different evaluation technique considers images with human-drawn bounding boxes around objects, and computes the percentage of pixel attribution inside the box.",4. Uniqueness of Integrated Gradients,[0],[0]
"While for most objects, one would expect the pixels located on the object to be most important for the prediction, in some cases the context in which the object occurs may also contribute to the prediction.",4. Uniqueness of Integrated Gradients,[0],[0]
"The cabbage butterfly image from Figure 2 is a good example of this where the pixels on the leaf are also surfaced by the integrated gradients.
",4. Uniqueness of Integrated Gradients,[0],[0]
"Roughly, we found that every empirical evaluation technique we could think of could not differentiate between ar-
1Formally, this means the function F is continuous everywhere and the partial derivative of F along each input dimension satisfies Lebesgue’s integrability condition, i.e., the set of discontinuous points has measure zero.",4. Uniqueness of Integrated Gradients,[0],[0]
"Deep networks built out of Sigmoids, ReLUs, and pooling operators satisfy this condition.
tifacts that stem from perturbing the data, a misbehaving model, and a misbehaving attribution method.",4. Uniqueness of Integrated Gradients,[0],[0]
This was why we turned to an axiomatic approach in designing a good attribution method (Section 2).,4. Uniqueness of Integrated Gradients,[0],[0]
"While our method satisfies Sensitivity and Implementation Invariance, it certainly isn’t the unique method to do so.
",4. Uniqueness of Integrated Gradients,[0],[0]
We now justify the selection of the integrated gradients method in two steps.,4. Uniqueness of Integrated Gradients,[0],[0]
"First, we identify a class of methods called Path methods that generalize integrated gradients.",4. Uniqueness of Integrated Gradients,[0],[0]
We discuss that path methods are the only methods to satisfy certain desirable axioms.,4. Uniqueness of Integrated Gradients,[0],[0]
"Second, we argue why integrated gradients is somehow canonical among the different path methods.",4. Uniqueness of Integrated Gradients,[0],[0]
Integrated gradients aggregate the gradients along the inputs that fall on the straightline between the baseline and the input.,4.1. Path Methods,[0],[0]
"There are many other (non-straightline) paths that monotonically interpolate between the two points, and each such path will yield a different attribution method.",4.1. Path Methods,[0],[0]
"For instance, consider the simple case when the input is two dimensional.",4.1. Path Methods,[0],[0]
"Figure 1 has examples of three paths, each of which corresponds to a different attribution method.
",4.1. Path Methods,[0],[0]
"Formally, let γ = (γ1, . . .",4.1. Path Methods,[0],[0]
", γn) :",4.1. Path Methods,[0],[0]
"[0, 1] → Rn be a smooth function specifying a path in Rn from the baseline x′ to the input x, i.e., γ(0)",4.1. Path Methods,[0],[0]
"= x′ and γ(1) = x.
Given a path function γ, path integrated gradients are obtained by integrating the gradients along the path γ(α) for α ∈",4.1. Path Methods,[0],[0]
"[0, 1].",4.1. Path Methods,[0],[0]
"Formally, path integrated gradients along the ith dimension for an input x is defined as follows.
",4.1. Path Methods,[0],[0]
PathIntegratedGradsγi (x) ::= ∫ 1 α=0 ∂F (γ(α)) ∂γi(α) ∂γi(α) ∂α,4.1. Path Methods,[0],[0]
"dα
(2) where ∂F (x)∂xi is the gradient of F along the i
th dimension at x.
Attribution methods based on path integrated gradients are
collectively known as path methods.",4.1. Path Methods,[0],[0]
Notice that integrated gradients is a path method for the straightline path specified γ(α) = x′ + α× (x− x′) for α ∈,4.1. Path Methods,[0],[0]
"[0, 1].",4.1. Path Methods,[0],[0]
Remark 3.,4.1. Path Methods,[0],[0]
All path methods satisfy Implementation Invariance.,4.1. Path Methods,[0],[0]
"This follows from the fact that they are defined using the underlying gradients, which do not depend on the implementation.",4.1. Path Methods,[0],[0]
"They also satisfy Completeness (the proof is similar to that of Proposition 1) and Sensitvity(a) which is implied by Completeness (see Remark 2).
",4.1. Path Methods,[0],[0]
"More interestingly, path methods are the only methods that satisfy certain desirable axioms.",4.1. Path Methods,[0],[0]
"(For formal definitions of the axioms and proof of Proposition 2, see Friedman (Friedman, 2004).)
",4.1. Path Methods,[0],[0]
Axiom: Sensitivity(b).,4.1. Path Methods,[0],[0]
"(called Dummy in (Friedman, 2004))",4.1. Path Methods,[0],[0]
"If the function implemented by the deep network does not depend (mathematically) on some variable, then the attribution to that variable is always zero.
",4.1. Path Methods,[0],[0]
This is a natural complement to the definition of Sensitivity(a) from Section 2.,4.1. Path Methods,[0],[0]
"This definition captures desired insensitivity of the attributions.
",4.1. Path Methods,[0],[0]
Axiom: Linearity.,4.1. Path Methods,[0],[0]
"Suppose that we linearly composed two deep networks modeled by the functions f1 and f2 to form a third network that models the function a×f1+b×f2, i.e., a linear combination of the two networks.",4.1. Path Methods,[0],[0]
Then we’d like the attributions for a× f1 + b× f2 to be the weighted sum of the attributions for f1 and f2 with weights a and b respectively.,4.1. Path Methods,[0],[0]
"Intuitively, we would like the attributions to preserve any linearity within the network.",4.1. Path Methods,[0],[0]
Proposition 2.,4.1. Path Methods,[0],[0]
"(Theorem 1 (Friedman, 2004))",4.1. Path Methods,[0],[0]
"Path methods are the only attribution methods that always satisfy Implementation Invariance, Sensitivity(b), Linearity, and Completeness.",4.1. Path Methods,[0],[0]
Remark 4.,4.1. Path Methods,[0],[0]
"We note that these path integrated gradients have been used within the cost-sharing literature in economics where the function models the cost of a project as a function of the demands of various participants, and the attributions correspond to cost-shares.",4.1. Path Methods,[0],[0]
"Integrated gradients correspond to a cost-sharing method called AumannShapley (Aumann & Shapley, 1974).",4.1. Path Methods,[0],[0]
Proposition 2 holds for our attribution problem because mathematically the cost-sharing problem corresponds to the attribution problem with the benchmark fixed at the zero vector.,4.1. Path Methods,[0],[0]
(Implementation Invariance is implicit in the cost-sharing literature as the cost functions are considered directly in their mathematical form.),4.1. Path Methods,[0],[0]
"In this section, we formalize why the straightline path chosen by integrated gradients is canonical.",4.2. Integrated Gradients is Symmetry-Preserving,[0],[0]
"First, observe that it is the simplest path that one can define mathematically.
",4.2. Integrated Gradients is Symmetry-Preserving,[0],[0]
"Second, a natural property for attribution methods is to preserve symmetry, in the following sense.
",4.2. Integrated Gradients is Symmetry-Preserving,[0],[0]
Symmetry-Preserving.,4.2. Integrated Gradients is Symmetry-Preserving,[0],[0]
Two input variables are symmetric w.r.t.,4.2. Integrated Gradients is Symmetry-Preserving,[0],[0]
a function if swapping them does not change the function.,4.2. Integrated Gradients is Symmetry-Preserving,[0],[0]
"For instance, x and y are symmetric w.r.t.",4.2. Integrated Gradients is Symmetry-Preserving,[0],[0]
F,4.2. Integrated Gradients is Symmetry-Preserving,[0],[0]
"if and only if F (x, y) = F (y, x) for all values of x and y.",4.2. Integrated Gradients is Symmetry-Preserving,[0],[0]
"An attribution method is symmetry preserving, if for all inputs that have identical values for symmetric variables and baselines that have identical values for symmetric variables, the symmetric variables receive identical attributions.
",4.2. Integrated Gradients is Symmetry-Preserving,[0],[0]
"E.g., consider the logistic model Sigmoid(x1 + x2 + . . . ).",4.2. Integrated Gradients is Symmetry-Preserving,[0],[0]
x1 and x2 are symmetric variables for this model.,4.2. Integrated Gradients is Symmetry-Preserving,[0],[0]
"For an input where x1 = x2 = 1 (say) and baseline where x1 = x2 = 0 (say), a symmetry preserving method must offer identical attributions to x1 and x2.
",4.2. Integrated Gradients is Symmetry-Preserving,[0],[0]
"It seems natural to ask for symmetry-preserving attribution methods because if two variables play the exact same role in the network (i.e., they are symmetric and have the same values in the baseline and the input) then they ought to receive the same attrbiution.
",4.2. Integrated Gradients is Symmetry-Preserving,[0],[0]
Theorem 1.,4.2. Integrated Gradients is Symmetry-Preserving,[0],[0]
"Integrated gradients is the unique path method that is symmetry-preserving.
",4.2. Integrated Gradients is Symmetry-Preserving,[0],[0]
"The proof is provided in Appendix A.
Remark 5.",4.2. Integrated Gradients is Symmetry-Preserving,[0],[0]
"If we allow averaging over the attributions from multiple paths, then are other methods that satisfy all the axioms in Theorem 1.",4.2. Integrated Gradients is Symmetry-Preserving,[0],[0]
"In particular, there is the method by Shapley-Shubik (Shapley & Shubik, 1971) from the cost sharing literature, and used by (Lundberg & Lee, 2016; Datta et al., 2016) to compute feature attributions (though they were not studying deep networks).",4.2. Integrated Gradients is Symmetry-Preserving,[0],[0]
"In this method, the attribution is the average of those from n!",4.2. Integrated Gradients is Symmetry-Preserving,[0],[0]
extremal paths; here n is the number of features.,4.2. Integrated Gradients is Symmetry-Preserving,[0],[0]
"Here each such path considers an ordering of the input features, and sequentially changes the input feature from its value at the baseline to its value at the input.",4.2. Integrated Gradients is Symmetry-Preserving,[0],[0]
This method yields attributions that are different from integrated gradients.,4.2. Integrated Gradients is Symmetry-Preserving,[0],[0]
"If the function of interest is min(x1, x2), the baseline is x1 = x2 = 0, and the input is x1 = 1, x2 = 3, then integrated gradients attributes the change in the function value entirely to the critical variable x1, whereas Shapley-Shubik assigns attributions of 1/2 each; it seems somewhat subjective to prefer one result over the other.
",4.2. Integrated Gradients is Symmetry-Preserving,[0],[0]
"We also envision other issues with applying Shapley-Shubik to deep networks: It is computationally expensive; in an object recognition network that takes an 100X100 image as input, n is 10000, and n!",4.2. Integrated Gradients is Symmetry-Preserving,[0],[0]
is a gigantic number.,4.2. Integrated Gradients is Symmetry-Preserving,[0],[0]
"Even if one samples few paths randomly, evaluating the attributions for a single path takes n calls to the deep network.",4.2. Integrated Gradients is Symmetry-Preserving,[0],[0]
"In contrast, integrated gradients is able to operate with 20 to 300 calls.",4.2. Integrated Gradients is Symmetry-Preserving,[0],[0]
"Further, the Shapley-Shubik computation visit
inputs that are combinations of the input and the baseline.",4.2. Integrated Gradients is Symmetry-Preserving,[0],[0]
It is possible that some of these combinations are very different from anything seen during training.,4.2. Integrated Gradients is Symmetry-Preserving,[0],[0]
We speculate that this could lead to attribution artifacts.,4.2. Integrated Gradients is Symmetry-Preserving,[0],[0]
Selecting a Benchmark.,5. Applying Integrated Gradients,[0],[0]
A key step in applying integrated gradients is to select a good baseline.,5. Applying Integrated Gradients,[0],[0]
"We recommend that developers check that the baseline has a near-zero score— as discussed in Section 3, this allows us to interpret the attributions as a function of the input.",5. Applying Integrated Gradients,[0],[0]
But there is more to a good baseline:,5. Applying Integrated Gradients,[0],[0]
"For instance, for an object recogntion network it is possible to create an adversarial example that has a zero score for a given input label (say elephant), by applying a tiny, carefully-designed perturbation to an image with a very different label (say microscope) (cf.",5. Applying Integrated Gradients,[0],[0]
"(Goodfellow et al., 2015)).",5. Applying Integrated Gradients,[0],[0]
The attributions can then include undesirable artifacts of this adversarially constructed baseline.,5. Applying Integrated Gradients,[0],[0]
"So we would additionally like the baseline to convey a complete absence of signal, so that the features that are apparent from the attributions are properties only of the input, and not of the baseline.",5. Applying Integrated Gradients,[0],[0]
"For instance, in an object recognition network, a black image signifies the absence of objects.",5. Applying Integrated Gradients,[0],[0]
The black image isn’t unique in this sense—an image consisting of noise has the same property.,5. Applying Integrated Gradients,[0],[0]
"However, using black as a baseline may result in cleaner visualizations of “edge” features.",5. Applying Integrated Gradients,[0],[0]
"For text based networks, we have found that the allzero input embedding vector is a good baseline.",5. Applying Integrated Gradients,[0],[0]
"The action of training causes unimportant words tend to have small norms, and so, in the limit, unimportance corresponds to the all-zero baseline.",5. Applying Integrated Gradients,[0],[0]
"Notice that the black image corresponds to a valid input to an object recognition network, and is also intuitively what we humans would consider absence of signal.",5. Applying Integrated Gradients,[0],[0]
"In contrast, the all-zero input vector for a text network does not correspond to a valid input; it nevertheless works for the mathematical reason described above.
",5. Applying Integrated Gradients,[0],[0]
Computing Integrated Gradients.,5. Applying Integrated Gradients,[0],[0]
The integral of integrated gradients can be efficiently approximated via a summation.,5. Applying Integrated Gradients,[0],[0]
"We simply sum the gradients at points occurring at sufficiently small intervals along the straightline path from the baseline x′ to the input x.
IntegratedGradsapproxi (x) ::=
(xi − x′i)× Σmk=1 ∂F (x′+ k",5. Applying Integrated Gradients,[0],[0]
m×(x−x ′))),5. Applying Integrated Gradients,[0],[0]
"∂xi × 1m
(3)
",5. Applying Integrated Gradients,[0],[0]
Here m is the number of steps in the Riemman approximation of the integral.,5. Applying Integrated Gradients,[0],[0]
Notice that the approximation simply involves computing the gradient in a for loop which should be straightforward and efficient in most deep learning frameworks.,5. Applying Integrated Gradients,[0],[0]
"For instance, in TensorFlow, it amounts to calling tf.gradients in a loop over the set of inputs (i.e., x′ + km × (x − x ′) for k = 1, . . .",5. Applying Integrated Gradients,[0],[0]
",m), which
could also be batched.",5. Applying Integrated Gradients,[0],[0]
"In practice, we find that somewhere between 20 and 300 steps are enough to approximate the integral (within 5%); we recommend that developers check that the attributions approximately adds up to the difference beween the score at the input and that at the baseline (cf. Proposition 1), and if not increase the step-size m.",5. Applying Integrated Gradients,[0],[0]
The integrated gradients technique is applicable to a variety of deep networks.,6. Applications,[0],[0]
"Here, we apply it to two image models, two natural language models, and a chemistry model.",6. Applications,[0],[0]
"We study feature attribution in an object recognition network built using the GoogleNet architecture (Szegedy et al., 2014) and trained over the ImageNet object recognition dataset (Russakovsky et al., 2015).",6.1. An Object Recognition Network,[0],[0]
We use the integrated gradients method to study pixel importance in predictions made by this network.,6.1. An Object Recognition Network,[0],[0]
The gradients are computed for the output of the highest-scoring class with respect to pixel of the input image.,6.1. An Object Recognition Network,[0],[0]
"The baseline input is the black image, i.e., all pixel intensities are zero.
",6.1. An Object Recognition Network,[0],[0]
Integrated gradients can be visualized by aggregating them along the color channel and scaling the pixels in the actual image by them.,6.1. An Object Recognition Network,[0],[0]
Figure 2 shows visualizations for a bunch of images2.,6.1. An Object Recognition Network,[0],[0]
"For comparison, it also presents the corresponding visualization obtained from the product of the image with the gradients at the actual image.",6.1. An Object Recognition Network,[0],[0]
Notice that integrated gradients are better at reflecting distinctive features of the input image.,6.1. An Object Recognition Network,[0],[0]
Diabetic retinopathy (DR) is a complication of the diabetes that affects the eyes.,6.2. Diabetic Retinopathy Prediction,[0],[0]
"Recently, a deep network (Gulshan et al., 2016) has been proposed to predict the severity grade for DR in retinal fundus images.",6.2. Diabetic Retinopathy Prediction,[0],[0]
"The model has good predictive accuracy on various validation datasets.
",6.2. Diabetic Retinopathy Prediction,[0],[0]
"We use integrated gradients to study feature importance for this network; like in the object recognition case, the baseline is the black image.",6.2. Diabetic Retinopathy Prediction,[0],[0]
"Feature importance explanations are important for this network as retina specialists may use it to build trust in the network’s predictions, decide the grade for borderline cases, and obtain insights for further testing and screening.
",6.2. Diabetic Retinopathy Prediction,[0],[0]
Figure 3 shows a visualization of integrated gradients for a retinal fundus image.,6.2. Diabetic Retinopathy Prediction,[0],[0]
The visualization method is a bit different from that used in Figure 2.,6.2. Diabetic Retinopathy Prediction,[0],[0]
"We aggregate integrated gradients along the color channel and overlay them on the
2More examples can be found at https://github.com/ ankurtaly/Attributions
actual image in gray scale with positive attribtutions along the green channel and negative attributions along the red channel.",6.2. Diabetic Retinopathy Prediction,[0],[0]
Notice that integrated gradients are localized to a few pixels that seem to be lesions in the retina.,6.2. Diabetic Retinopathy Prediction,[0],[0]
The interior of the lesions receive a negative attribution while the periphery receives a positive attribution indicating that the network focusses on the boundary of the lesion.,6.2. Diabetic Retinopathy Prediction,[0],[0]
Automatically answering natural language questions (over semi-structured data) is an important problem in artificial intelligence (AI).,6.3. Question Classification,[0],[0]
"A common approach is to semantically parse the question to its logical form (Liang, 2016) using a set of human-authored grammar rules.",6.3. Question Classification,[0],[0]
An alternative approach is to machine learn an end-to-end model provided there is enough training data.,6.3. Question Classification,[0],[0]
An interesting question is whether one could peek inside machine learnt models to derive new rules.,6.3. Question Classification,[0],[0]
"We explore this direction for a sub-problem of semantic parsing, called question classification, using the method of integrated gradients.
",6.3. Question Classification,[0],[0]
The goal of question classification is to identify the type of answer it is seeking.,6.3. Question Classification,[0],[0]
"For instance, is the quesiton seeking a yes/no answer, or is it seeking a date?",6.3. Question Classification,[0],[0]
"Rules for solving this problem look for trigger phrases in the question, for e.g., a “when” in the beginning indicates a date seeking question.",6.3. Question Classification,[0],[0]
"We train a model for question classification using the the text categorization architecture proposed by (Kim, 2014) over the WikiTableQuestions dataset (Pasupat & Liang, 2015).",6.3. Question Classification,[0],[0]
We use integrated gradients to attribute predictions down to the question terms in order to identify new trigger phrases for answer type.,6.3. Question Classification,[0],[0]
"The baseline input is the all zero embedding vector.
",6.3. Question Classification,[0],[0]
Figure 4 lists a few questions with constituent terms highlighted based on their attribution.,6.3. Question Classification,[0],[0]
"Notice that the attributions largely agree with commonly used rules, for e.g., “how many” indicates a numeric seeking question.",6.3. Question Classification,[0],[0]
"In addition, attributions help identify novel question classification rules, for e.g., questions containing “total number” are seeking numeric answers.",6.3. Question Classification,[0],[0]
"Attributions also point out undesirable correlations, for e.g., “charles” is used as trigger for a yes/no question.",6.3. Question Classification,[0],[0]
"We applied our technique to a complex, LSTM-based Neural Machine Translation System (Wu et al., 2016).",6.4. Neural Machine Translation,[0],[0]
We attribute the output probability of every output token (in form of wordpieces) to the input tokens.,6.4. Neural Machine Translation,[0],[0]
Such attributions “align” the output sentence with the input sentence.,6.4. Neural Machine Translation,[0],[0]
"For
baseline, we zero out the embeddings of all tokens except the start and end markers.",6.4. Neural Machine Translation,[0],[0]
Figure 5 shows an example of such an attribution-based alignments.,6.4. Neural Machine Translation,[0],[0]
We observed that the results make intuitive sense.,6.4. Neural Machine Translation,[0],[0]
"E.g. “und” is mostly attributed to “and”, and “morgen” is mostly attributed to “morning”.",6.4. Neural Machine Translation,[0],[0]
We use 100 − 1000 steps (cf. Section 5) in the integrated gradient approximation; we need this because the network is highly nonlinear.,6.4. Neural Machine Translation,[0],[0]
"We apply integrated gradients to a network performing Ligand-Based Virtual Screening which is the problem of predicting whether an input molecule is active against a certain target (e.g., protein or enzyme).",6.5. Chemistry Models,[0],[0]
"In particular, we consider a network based on the molecular graph convolution architecture proposed by (Kearnes et al., 2016).
",6.5. Chemistry Models,[0],[0]
The network requires an input molecule to be encoded by hand as a set of atom and atom-pair features describing the molecule as an undirected graph.,6.5. Chemistry Models,[0],[0]
"Atoms are featurized using a one-hot encoding specifying the atom type (e.g., C, O, S, etc.), and atom-pairs are featurized by specifying either the type of bond (e.g., single, double, triple, etc.) between the atoms, or the graph distance between them.",6.5. Chemistry Models,[0],[0]
"The baseline input is obtained zeroing out the feature vectors for atom and atom-pairs.
",6.5. Chemistry Models,[0],[0]
We visualize integrated gradients as heatmaps over the the atom and atom-pair features with the heatmap intensity depicting the strength of the contribution.,6.5. Chemistry Models,[0],[0]
Figure 6 shows the visualization for a specific molecule.,6.5. Chemistry Models,[0],[0]
"Since integrated gradients add up to the final prediction score (see Proposition 1), the magnitudes can be use for accounting the contributions of each feature.",6.5. Chemistry Models,[0],[0]
"For instance, for the molecule in the figure, atom-pairs that have a bond between them cumulatively contribute to 46% of the prediction score, while all other pairs cumulatively contribute to only −3%.
",6.5. Chemistry Models,[0],[0]
Identifying Degenerate Features.,6.5. Chemistry Models,[0],[0]
"We now discuss how attributions helped us spot an anomaly in the W1N2 architecture in (Kearnes et al., 2016).",6.5. Chemistry Models,[0],[0]
"On applying the integrated gradients method to this network, we found that several atoms in the same molecule received identical attribution despite being bonded to different atoms.",6.5. Chemistry Models,[0],[0]
"This is surprising as one would expect two atoms with different neighborhoods to be treated differently by the network.
",6.5. Chemistry Models,[0],[0]
"On investigating the problem further, in the network architecture, the atoms and atom-pair features were not fully convolved.",6.5. Chemistry Models,[0],[0]
"This caused all atoms that have the same atom type, and same number of bonds of each type to contribute identically to the network.",6.5. Chemistry Models,[0],[0]
We already covered closely related work on attribution in Section 2.,7. Other Related work,[0],[0]
We mention other related work.,7. Other Related work,[0],[0]
"Over the last few years, there has been a vast amount work on demystifying the inner workings of deep networks.",7. Other Related work,[0],[0]
"Most of this work has been on networks trained on computer vision tasks, and deals with understanding what a specific neuron computes (Erhan et al., 2009; Le, 2013) and interpreting the representations captured by neurons during a prediction (Mahendran & Vedaldi, 2015; Dosovitskiy & Brox, 2015; Yosinski et al., 2015).",7. Other Related work,[0],[0]
"In contrast, we focus on understanding the network’s behavior on a specific input in terms of the base level input features.",7. Other Related work,[0],[0]
"Our technique quantifies the importance of each feature in the prediction.
",7. Other Related work,[0],[0]
"One approach to the attribution problem proposed first by (Ribeiro et al., 2016a;b), is to locally approximate the behavior of the network in the vicinity of the input being explained with a simpler, more interpretable model.",7. Other Related work,[0],[0]
An appealing aspect of this approach is that it is completely agnostic to the implementation of the network and satisfies implemenation invariance.,7. Other Related work,[0],[0]
"However, this approach does not guarantee sensitivity.",7. Other Related work,[0],[0]
"There is no guarantee that the local region explored escapes the “flat” section of the pre-
diction function in the sense of Section 2.",7. Other Related work,[0],[0]
The other issue is that the method is expensive to implement for networks with “dense” input like image networks as one needs to explore a local region of size proportional to the number of pixels and train a model for this space.,7. Other Related work,[0],[0]
"In contrast, our technique works with a few calls to the gradient operation.
",7. Other Related work,[0],[0]
"Attention mechanisms (Bahdanau et al., 2014) have gained popularity recently.",7. Other Related work,[0],[0]
"One may think that attention could be used a proxy for attributions, but this has issues.",7. Other Related work,[0],[0]
"For instance, in a LSTM that also employs attention, there are many ways for an input token to influence an output token: the memory cell, the recurrent state, and “attention”.",7. Other Related work,[0],[0]
Focussing only an attention ignores the other modes of influence and results in an incomplete picture.,7. Other Related work,[0],[0]
The primary contribution of this paper is a method called integrated gradients that attributes the prediction of a deep network to its inputs.,8. Conclusion,[0],[0]
"It can be implemented using a few calls to the gradients operator, can be applied to a variety of deep networks, and has a strong theoretical justification.
",8. Conclusion,[0],[0]
A secondary contribution of this paper is to clarify desirable features of an attribution method using an axiomatic framework inspired by cost-sharing literature from economics.,8. Conclusion,[0],[0]
"Without the axiomatic approach it is hard to tell whether the attribution method is affected by data artifacts, network’s artifacts or artifacts of the method.",8. Conclusion,[0],[0]
"The axiomatic approach rules out artifacts of the last type.
",8. Conclusion,[0],[0]
"While our and other works have made some progress on understanding the relative importance of input features in a deep network, we have not addressed the interactions between the input features or the logic employed by the network.",8. Conclusion,[0],[0]
So there remain many unanswered questions in terms of debugging the I/O behavior of a deep network.,8. Conclusion,[0],[0]
"We would like to thank Samy Bengio, Kedar Dhamdhere, Scott Lundberg, Amir Najmi, Kevin McCurley, Patrick Riley, Christian Szegedy, Diane Tang for their feedback.",ACKNOWLEDGMENTS,[0],[0]
We would like to thank Daniel Smilkov and Federico Allocati for identifying bugs in our descriptions.,ACKNOWLEDGMENTS,[0],[0]
"We would like to thank our anonymous reviewers for identifying bugs, and their suggestions to improve presentation.",ACKNOWLEDGMENTS,[0],[0]
Proof.,A. Proof of Theorem 1,[0],[0]
Consider a non-straightline path γ :,A. Proof of Theorem 1,[0],[0]
"[0, 1] → Rn from baseline to input.",A. Proof of Theorem 1,[0],[0]
"W.l.o.g., there exists t0 ∈",A. Proof of Theorem 1,[0],[0]
"[0, 1] such that for two dimensions i, j, γi(t0) > γj(t0).",A. Proof of Theorem 1,[0],[0]
"Let (t1, t2) be the maximum real open interval containing t0 such that γi(t) > γj(t) for all t in (t1, t2), and let a = γi(t1) = γj(t1), and b = γi(t2) = γj(t2).",A. Proof of Theorem 1,[0],[0]
Define function f,A. Proof of Theorem 1,[0],[0]
: x ∈,A. Proof of Theorem 1,[0],[0]
"[0, 1]n → R as 0 if min(xi, xj) ≤ a, as (b − a)2 if max(xi, xj) ≥ b, and as (xi − a)(xj − a) otherwise.",A. Proof of Theorem 1,[0],[0]
"Next we compute the attributions of f at x = 〈1, . . .",A. Proof of Theorem 1,[0],[0]
", 1〉n with baseline x′ = 〈0, . . .",A. Proof of Theorem 1,[0],[0]
", 0〉n.",A. Proof of Theorem 1,[0],[0]
"Note that xi and xj are symmetric, and should get identical attributions.",A. Proof of Theorem 1,[0],[0]
For t /∈,A. Proof of Theorem 1,[0],[0]
"[t1, t2], the function is a constant, and the attribution of f is zero to all variables, while for t ∈ (t1, t2), the integrand of attribution of f is γj(t)",A. Proof of Theorem 1,[0],[0]
"− a to xi, and γi(t)",A. Proof of Theorem 1,[0],[0]
"− a to xj , where the latter is always strictly larger by our choice of the interval.",A. Proof of Theorem 1,[0],[0]
"Integrating, it follows that xj gets a larger attribution than xi, contradiction.",A. Proof of Theorem 1,[0],[0]
"We show that the methods DeepLift and Layer-wise relevance propagation (LRP) break the implementation invariance axiom, and the Deconvolution and Guided backpropagation methods break the sensitivity axiom.
",B. Attribution Counter-Examples,[0],[0]
"Figure 7 provides an example of two equivalent networks
f(x1, x2) and g(x1, x2) for which DeepLift and LRP yield different attributions.
",B. Attribution Counter-Examples,[0],[0]
"First, observe that the networks f and g are of the form f(x1, x2) =",B. Attribution Counter-Examples,[0],[0]
"ReLU(h(x1, x2)) and f(x1, x2) = ReLU(k(x1, x2))",B. Attribution Counter-Examples,[0],[0]
"3, where
h(x1, x2) =",B. Attribution Counter-Examples,[0],[0]
"ReLU(x1)− 1− ReLU(x2) k(x1, x2)",B. Attribution Counter-Examples,[0],[0]
"= ReLU(x1 − 1)− ReLU(x2)
",B. Attribution Counter-Examples,[0],[0]
Note that h and k are not equivalent.,B. Attribution Counter-Examples,[0],[0]
They have different values whenever x1 < 1.,B. Attribution Counter-Examples,[0],[0]
But f and g are equivalent.,B. Attribution Counter-Examples,[0],[0]
"To prove this, suppose for contradiction that f and g are different for some x1, x2.",B. Attribution Counter-Examples,[0],[0]
Then it must be the case that ReLU(x1)− 1 6= ReLU(x1 − 1).,B. Attribution Counter-Examples,[0],[0]
"This happens only when x1 < 1, which implies that f(x1, x2) = g(x1, x2) = 0.
",B. Attribution Counter-Examples,[0],[0]
Now we leverage the above example to show that Deconvolution and Guided back-propagation break sensitivity.,B. Attribution Counter-Examples,[0],[0]
"Consider the network f(x1, x2) from Figure 7.",B. Attribution Counter-Examples,[0],[0]
"For a fixed value of x1 greater than 1, the output decreases linearly as x2 increases from 0 to x1 − 1.",B. Attribution Counter-Examples,[0],[0]
"Yet, for all inputs, Deconvolutional networks and Guided back-propagation results in zero attribution for x2.",B. Attribution Counter-Examples,[0],[0]
"This happens because for all inputs the back-propagated signal received at the node ReLU(x2) is negative and is therefore not back-propagated through the ReLU operation (per the rules of deconvolution and guided back-propagation; see (Springenberg et al., 2014) for details).",B. Attribution Counter-Examples,[0],[0]
"As a result, the feature x2 receives zero
3 ReLU(x) is defined as max(x, 0).
",B. Attribution Counter-Examples,[0],[0]
attribution despite the network’s output being sensitive to it.,B. Attribution Counter-Examples,[0],[0]
"We study the problem of attributing the prediction of a deep network to its input features, a problem previously studied by several other works.",abstractText,[0],[0]
We identify two fundamental axioms— Sensitivity and Implementation Invariance that attribution methods ought to satisfy.,abstractText,[0],[0]
"We show that they are not satisfied by most known attribution methods, which we consider to be a fundamental weakness of those methods.",abstractText,[0],[0]
We use the axioms to guide the design of a new attribution method called Integrated Gradients.,abstractText,[0],[0]
Our method requires no modification to the original network and is extremely simple to implement; it just needs a few calls to the standard gradient operator.,abstractText,[0],[0]
"We apply this method to a couple of image models, a couple of text models and a chemistry model, demonstrating its ability to debug networks, to extract rules from a network, and to enable users to engage with models better.",abstractText,[0],[0]
1.,abstractText,[0],[0]
Motivation and Summary of Results We study the problem of attributing the prediction of a deep network to its input features.,abstractText,[0],[0]
Definition 1.,abstractText,[0],[0]
"Formally, suppose we have a function F :",abstractText,[0],[0]
R,abstractText,[0],[0]
→,abstractText,[0],[0]
"[0, 1] that represents a deep network, and an input x =",abstractText,[0],[0]
"(x1, . . .",abstractText,[0],[0]
", xn) ∈",abstractText,[0],[0]
R.,abstractText,[0],[0]
"An attribution of the prediction at input x relative to a baseline input x′ is a vector AF (x, x ′) =",abstractText,[0],[0]
"(a1, . . .",abstractText,[0],[0]
", an) ∈ R where ai is the contribution of xi to the prediction F (x).",abstractText,[0],[0]
"For instance, in an object recognition network, an attribution method could tell us which pixels of the image were responsible for a certain label being picked (see Figure 2).",abstractText,[0],[0]
"The attribution problem was previously studied by various papers (Baehrens et al., 2010; Simonyan et al., 2013; Equal contribution Google Inc., Mountain View, USA.",abstractText,[0],[0]
Correspondence to: Mukund Sundararajan <mukunds@google.com,abstractText,[0],[0]
">, Ankur Taly <ataly@google.com>.",abstractText,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",abstractText,[0],[0]
Copyright 2017 by the author(s).,abstractText,[0],[0]
"Shrikumar et al., 2016; Binder et al., 2016; Springenberg et al., 2014).",abstractText,[0],[0]
"The intention of these works is to understand the inputoutput behavior of the deep network, which gives us the ability to improve it.",abstractText,[0],[0]
"Such understandability is critical to all computer programs, including machine learning models.",abstractText,[0],[0]
There are also other applications of attribution.,abstractText,[0],[0]
They could be used within a product driven by machine learning to provide a rationale for the recommendation.,abstractText,[0],[0]
"For instance, a deep network that predicts a condition based on imaging could help inform the doctor of the part of the image that resulted in the recommendation.",abstractText,[0],[0]
This could help the doctor understand the strengths and weaknesses of a model and compensate for it.,abstractText,[0],[0]
We give such an example in Section 6.2.,abstractText,[0],[0]
Attributions could also be used by developers in an exploratory sense.,abstractText,[0],[0]
"For instance, we could use a deep network to extract insights that could be then used in a rulebased system.",abstractText,[0],[0]
"In Section 6.3, we give such an example.",abstractText,[0],[0]
A significant challenge in designing an attribution technique is that they are hard to evaluate empirically.,abstractText,[0],[0]
"As we discuss in Section 4, it is hard to tease apart errors that stem from the misbehavior of the model versus the misbehavior of the attribution method.",abstractText,[0],[0]
"To compensate for this shortcoming, we take an axiomatic approach.",abstractText,[0],[0]
In Section 2 we identify two axioms that every attribution method must satisfy.,abstractText,[0],[0]
Unfortunately most previous methods do not satisfy one of these two axioms.,abstractText,[0],[0]
"In Section 3, we use the axioms to identify a new method, called integrated gradients.",abstractText,[0],[0]
"Unlike previously proposed methods, integrated gradients do not need any instrumentation of the network, and can be computed easily using a few calls to the gradient operation, allowing even novice practitioners to easily apply the technique.",abstractText,[0],[0]
"In Section 6, we demonstrate the ease of applicability over several deep networks, including two images networks, two text processing networks, and a chemistry network.",abstractText,[0],[0]
"These applications demonstrate the use of our technique in either improving our understanding of the network, performing debugging, performing rule extraction, or aiding an end user in understanding the network’s prediction.",abstractText,[0],[0]
Remark 1.,abstractText,[0],[0]
Let us briefly examine the need for the baseline in the definition of the attribution problem.,abstractText,[0],[0]
A common way for humans to perform attribution relies on counterar X iv :1 70 3.,abstractText,[0],[0]
01,abstractText,[0],[0]
36 5v 2,abstractText,[0],[0]
[ cs .L G ] 1 3 Ju n 20 17 Axiomatic Attribution for Deep Networks factual intuition.,abstractText,[0],[0]
When we assign blame to a certain cause we implicitly consider the absence of the cause as a baseline for comparing outcomes.,abstractText,[0],[0]
"In a deep network, we model the absence using a single baseline input.",abstractText,[0],[0]
"For most deep networks, a natural baseline exists in the input space where the prediction is neutral.",abstractText,[0],[0]
"For instance, in object recognition networks, it is the black image.",abstractText,[0],[0]
"The need for a baseline has also been pointed out by prior work on attribution (Shrikumar et al., 2016; Binder et al., 2016).",abstractText,[0],[0]
2.,abstractText,[0],[0]
Two Fundamental Axioms We now discuss two axioms (desirable characteristics) for attribution methods.,abstractText,[0],[0]
We find that other feature attribution methods in literature break at least one of the two axioms.,abstractText,[0],[0]
"These methods include DeepLift (Shrikumar et al., 2016; 2017), Layer-wise relevance propagation (LRP) (Binder et al., 2016), Deconvolutional networks (Zeiler & Fergus, 2014), and Guided back-propagation (Springenberg et al., 2014).",abstractText,[0],[0]
"As we will see in Section 3, these axioms will also guide the design of our method.",abstractText,[0],[0]
Gradients.,abstractText,[0],[0]
"For linear models, ML practitioners regularly inspect the products of the model coefficients and the feature values in order to debug predictions.",abstractText,[0],[0]
"Gradients (of the output with respect to the input) is a natural analog of the model coefficients for a deep network, and therefore the product of the gradient and feature values is a reasonable starting point for an attribution method (Baehrens et al., 2010; Simonyan et al., 2013); see the third column of Figure 2 for examples.",abstractText,[0],[0]
"The problem with gradients is that they break sensitivity, a property that all attribution methods should satisfy.",abstractText,[0],[0]
2.1.,abstractText,[0],[0]
Axiom: Sensitivity(a),abstractText,[0],[0]
An attribution method satisfies Sensitivity(a),abstractText,[0],[0]
if for every input and baseline that differ in one feature but have different predictions then the differing feature should be given a non-zero attribution.,abstractText,[0],[0]
"(Later in the paper, we will have a part (b) to this definition.)",abstractText,[0],[0]
Gradients violate Sensitivity(a):,abstractText,[0],[0]
"For a concrete example, consider a one variable, one ReLU network, f(x) = 1 − ReLU(1−x).",abstractText,[0],[0]
Suppose the baseline is x = 0 and the input is x = 2.,abstractText,[0],[0]
"The function changes from 0 to 1, but because f becomes flat at x = 1, the gradient method gives attribution of 0 to x. Intuitively, gradients break Sensitivity because the prediction function may flatten at the input and thus have zero gradient despite the function value at the input being different from that at the baseline.",abstractText,[0],[0]
"This phenomenon has been reported in previous work (Shrikumar et al., 2016).",abstractText,[0],[0]
"Practically, the lack of sensitivity causes gradients to focus on irrelevant features (see the “fireboat” example in Figure 2).",abstractText,[0],[0]
Other back-propagation based approaches.,abstractText,[0],[0]
A second set of approaches involve back-propagating the final prediction score through each layer of the network down to the individual features.,abstractText,[0],[0]
"These include DeepLift, Layer-wise relevance propagation (LRP), Deconvolutional networks (DeConvNets), and Guided back-propagation.",abstractText,[0],[0]
"These methods differ in the specific backpropagation logic for various activation functions (e.g., ReLU, MaxPool, etc.).",abstractText,[0],[0]
"Unfortunately, Deconvolution networks (DeConvNets), and Guided back-propagation violate Sensitivity(a).",abstractText,[0],[0]
This is because these methods back-propogate through a ReLU node only if the ReLU is turned on at the input.,abstractText,[0],[0]
"This makes the method similar to gradients, in that, the attribution is zero for features with zero gradient at the input despite a non-zero gradient at the baseline.",abstractText,[0],[0]
"We defer the specific counterexamples to Appendix B. Methods like DeepLift and LRP tackle the Sensitivity issue by employing a baseline, and in some sense try to compute “discrete gradients” instead of (instantaeneous) gradients at the input.",abstractText,[0],[0]
(The two methods differ in the specifics of how they compute the discrete gradient).,abstractText,[0],[0]
"But the idea is that a large, discrete step will avoid flat regions, avoiding a breakage of sensitivity.",abstractText,[0],[0]
"Unfortunately, these methods violate a different requirement on attribution methods.",abstractText,[0],[0]
2.2.,abstractText,[0],[0]
"Axiom: Implementation Invariance Two networks are functionally equivalent if their outputs are equal for all inputs, despite having very different implementations.",abstractText,[0],[0]
"Attribution methods should satisfy Implementation Invariance, i.e., the attributions are always identical for two functionally equivalent networks.",abstractText,[0],[0]
"To motivate this, notice that attribution can be colloquially defined as assigning the blame (or credit) for the output to the input features.",abstractText,[0],[0]
Such a definition does not refer to implementation details.,abstractText,[0],[0]
"We now discuss intuition for why DeepLift and LRP break Implementation Invariance; a concrete example is provided in Appendix B. First, notice that gradients are invariant to implementation.",abstractText,[0],[0]
"In fact, the chain-rule for gradients ∂f ∂g = ∂f ∂h · ∂h ∂g is essentially about implementation invariance.",abstractText,[0],[0]
"To see this, think of g and f as the input and output of a system, and h being some implementation detail of the system.",abstractText,[0],[0]
"The gradient of output f to input g can be computed either directly by ∂f ∂g , ignoring the intermediate function h (implementation detail), or by invoking the chain rule via h.",abstractText,[0],[0]
This is exactly how backpropagation works.,abstractText,[0],[0]
Methods like LRP and DeepLift replace gradients with discrete gradients and still use a modified form of backpropagation to compose discrete gradients into attributions.,abstractText,[0],[0]
"UnAxiomatic Attribution for Deep Networks fortunately, the chain rule does not hold for discrete gradients in general.",abstractText,[0],[0]
Formally f(x1)−f(x0) g(x1)−g(x0) 6=,abstractText,[0],[0]
"f(x1)−f(x0) h(x1)−h(x0) · h(x1)−h(x0) g(x1)−g(x0) , and therefore these methods fail to satisfy implementation invariance.",abstractText,[0],[0]
"If an attribution method fails to satisfy Implementation Invariance, the attributions are potentially sensitive to unimportant aspects of the models.",abstractText,[0],[0]
"For instance, if the network architecture has more degrees of freedom than needed to represent a function then there may be two sets of values for the network parameters that lead to the same function.",abstractText,[0],[0]
"The training procedure can converge at either set of values depending on the initializtion or for other reasons, but the underlying network function would remain the same.",abstractText,[0],[0]
It is undesirable that attributions differ for such reasons.,abstractText,[0],[0]
3.,abstractText,[0],[0]
Our Method: Integrated Gradients We are now ready to describe our technique.,abstractText,[0],[0]
"Intuitively, our technique combines the Implementation Invariance of Gradients along with the Sensitivity of techniques like LRP or DeepLift.",abstractText,[0],[0]
"Formally, suppose we have a function F : R",abstractText,[0],[0]
→,abstractText,[0],[0]
"[0, 1] that represents a deep network.",abstractText,[0],[0]
"Specifically, let x ∈ R be the input at hand, and x′ ∈ R be the baseline input.",abstractText,[0],[0]
"For image networks, the baseline could be the black image, while for text models it could be the zero embedding vector.",abstractText,[0],[0]
"We consider the straightline path (in R) from the baseline x′ to the input x, and compute the gradients at all points along the path.",abstractText,[0],[0]
Integrated gradients are obtained by cumulating these gradients.,abstractText,[0],[0]
"Specifically, integrated gradients are defined as the path intergral of the gradients along the straightline path from the baseline x′ to the input x.",abstractText,[0],[0]
The integrated gradient along the i dimension for an input x and baseline x′ is defined as follows.,abstractText,[0],[0]
"Here, ∂F (x) ∂xi is the gradient of F (x) along the i dimension.",abstractText,[0],[0]
IntegratedGradsi(x) ::= (xi−x ′,abstractText,[0],[0]
i)× ∫ 1 α=0 ∂F (x′+α×(x−x′)),abstractText,[0],[0]
Axiomatic Attribution for Deep Networks,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 1863–1873 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
1863
We experiment on two structured NLP pipelines: syntactic-then-semantic dependency parsing, and semantic parsing followed by sentiment classification. We show that training with SPIGOT leads to a larger improvement on the downstream task than a modularly-trained pipeline, the straight-through estimator, and structured attention, reaching a new state of the art on semantic dependency parsing.",text,[0],[0]
Learning methods for natural language processing are increasingly dominated by end-to-end differentiable functions that can be trained using gradient-based optimization.,1 Introduction,[0],[0]
"Yet traditional NLP often assumed modular stages of processing that formed a pipeline; e.g., text was tokenized, then tagged with parts of speech, then parsed into a
phrase-structure or dependency tree, then semantically analyzed.",1 Introduction,[0],[0]
"Pipelines, which make “hard” (i.e., discrete) decisions at each stage, appear to be incompatible with neural learning, leading many researchers to abandon earlier-stage processing.
",1 Introduction,[0],[0]
"Inspired by findings that continue to see benefit from various kinds of linguistic or domain-specific preprocessing (He et al., 2017; Oepen et al., 2017; Ji and Smith, 2017), we argue that pipelines can be treated as layers in neural architectures for NLP tasks.",1 Introduction,[0],[0]
"Several solutions are readily available: • Reinforcement learning (most notably the
REINFORCE algorithm; Williams, 1992), and structured attention (SA; Kim et al., 2017).",1 Introduction,[0],[0]
These methods replace argmax with a sampling or marginalization operation.,1 Introduction,[0],[0]
"We note two potential downsides of these approaches: (i) not all argmax-able operations have corresponding sampling or marginalization methods that are efficient, and (ii) inspection of intermediate outputs, which could benefit error analysis and system improvement, is more straightforward for hard decisions than for posteriors.",1 Introduction,[0],[0]
"• The straight-through estimator (STE; Hin-
ton, 2012) treats discrete decisions as if they were differentiable and simply passes through gradients.",1 Introduction,[0],[0]
"While fast and surprisingly effective, it ignores constraints on the argmax problem, such as the requirement that every word has exactly one syntactic parent.",1 Introduction,[0],[0]
"We will find, experimentally, that the quality of intermediate representations degrades substantially under STE.
",1 Introduction,[0],[0]
"This paper introduces a new method, the structured projection of intermediate gradients optimization technique (SPIGOT; §2), which defines a proxy for the gradient of a loss function with respect to the input to argmax.",1 Introduction,[0],[0]
"Unlike STE’s gradient proxy, SPIGOT aims to respect the constraints
in the argmax problem.",1 Introduction,[0],[0]
"SPIGOT can be applied with any intermediate layer that is expressible as a constrained maximization problem, and whose feasible set can be projected onto.",1 Introduction,[0],[0]
"We show empirically that SPIGOT works even when the maximization and the projection are done approximately.
",1 Introduction,[0],[0]
"We offer two concrete architectures that employ structured argmax as an intermediate layer: semantic parsing with syntactic parsing in the middle, and sentiment analysis with semantic parsing in the middle (§3).",1 Introduction,[0],[0]
"These architectures are trained using a joint objective, with one part using data for the intermediate task, and the other using data for the end task.",1 Introduction,[0],[0]
"The datasets are not assumed to overlap at all, but the parameters for the intermediate task are affected by both parts of the training data.
",1 Introduction,[0],[0]
"Our experiments (§4) show that our architecture improves over a state-of-the-art semantic dependency parser, and that SPIGOT offers stronger performance than a pipeline, SA, and STE.",1 Introduction,[0],[0]
"On sentiment classification, we show that semantic parsing offers improvement over a BiLSTM, more so with SPIGOT than with alternatives.",1 Introduction,[0],[0]
Our analysis considers how the behavior of the intermediate parser is affected by the end task (§5).,1 Introduction,[0],[0]
Our code is open-source and available at https:// github.com/Noahs-ARK/SPIGOT.,1 Introduction,[0],[0]
Our aim is to allow a (structured) argmax layer in a neural network to be treated almost like any other differentiable function.,2 Method,[0],[0]
"This would allow us to place, for example, a syntactic parser in the middle of a neural network, so that the forward calculation simply calls the parser and passes the parse tree to the next layer, which might derive syntactic features for the next stage of processing.
",2 Method,[0],[0]
"The challenge is in the backward computation, which is key to learning with standard gradientbased methods.",2 Method,[0],[0]
"When its output is discrete as we assume here, argmax is a piecewise constant function.",2 Method,[0],[0]
"At every point, its gradient is either zero or undefined.",2 Method,[0],[0]
"So instead of using the true gradient, we will introduce a proxy for the gradient of the loss function with respect to the inputs to argmax, allowing backpropagation to proceed through the argmax layer.",2 Method,[0],[0]
Our proxy is designed as an improvement to earlier methods (discussed below) that completely ignore constraints on the argmax operation.,2 Method,[0],[0]
"It accomplishes this through a projec-
tion of the gradients.",2 Method,[0],[0]
"We first lay out notation, and then briefly review max-decoding and its relaxation (§2.1).",2 Method,[0],[0]
"We define SPIGOT in §2.2, and show how to use it to backpropagate through NLP pipelines in §2.3.
Notation.",2 Method,[0],[0]
"Our discussion centers around two tasks: a structured intermediate task followed by an end task, where the latter considers the outputs of the former (e.g., syntactic-then-semantic parsing).",2 Method,[0],[0]
"Inputs are denoted as x, and end task outputs as y. We use z to denote intermediate structures derived from x. We will often refer to the intermediate task as “decoding”, in the structured prediction sense.",2 Method,[0],[0]
"It seeks an output ẑ = argmaxz∈Z S from the feasible set Z , maximizing a (learned, parameterized) scoring function S for the structured intermediate task.",2 Method,[0],[0]
"L denotes the loss of the end task, which may or may not also involve structured predictions.",2 Method,[0],[0]
We use ∆k−1 = {p ∈,2 Method,[0],[0]
"Rk | 1>p = 1,p ≥ 0} to denote the (k − 1)-dimensional simplex.",2 Method,[0],[0]
"We denote the domain of binary variables as B = {0, 1}, and the unit interval as U =",2 Method,[0],[0]
"[0, 1].",2 Method,[0],[0]
"By projection of a vector v onto a set A, we mean the closest point in A to v, measured by Euclidean distance: projA(v) = argminv′∈A ‖v′ − v‖2.",2 Method,[0],[0]
"Decoding problems are typically decomposed into a collection of “parts”, such as arcs in a dependency tree or graph.",2.1 Relaxed Decoding,[0],[0]
"In such a setup, each element of z, zi, corresponds to one possible part, and zi takes a boolean value to indicate whether the part is included in the output structure.",2.1 Relaxed Decoding,[0],[0]
"The scoring function S is assumed to decompose into a vector s(x) of part-local, input-specific scores:
ẑ = argmax z∈Z S(x, z) =",2.1 Relaxed Decoding,[0],[0]
"argmax z∈Z
z>s(x) (1)
In the following, we drop s’s dependence on x for clarity.
",2.1 Relaxed Decoding,[0],[0]
"In many NLP problems, the output space Z can be specified by linear constraints (Roth and Yih, 2004):
",2.1 Relaxed Decoding,[0],[0]
A [ z ψ ],2.1 Relaxed Decoding,[0],[0]
"≤ b, (2)
where ψ are auxiliary variables (also scoped by argmax), together with integer constraints (typically, each zi ∈ B).
",2.1 Relaxed Decoding,[0],[0]
"The problem in Equation 1 can be NP-complete in general, so the {0, 1} constraints are often relaxed to [0, 1] to make decoding tractable (Martins et al., 2009).",2.1 Relaxed Decoding,[0],[0]
"Then the discrete combinatorial problem over Z is transformed into the optimization of a linear objective over a convex polytope P={p ∈ Rd |Ap≤b}, which is solvable in polynomial time (Bertsimas and Tsitsiklis, 1997).",2.1 Relaxed Decoding,[0],[0]
"This is not necessary in some cases, where the argmax can be solved exactly with dynamic programming.",2.1 Relaxed Decoding,[0],[0]
"We now view structured argmax as an activation function that takes a vector of input-specific partscores s and outputs a solution ẑ. For backpropagation, to calculate gradients for parameters of s, the chain rule defines:
∇sL = J ∇ẑL, (3) where the Jacobian matrix J = ∂ẑ∂s contains the derivative of each element of ẑ with respect to each element of s. Unfortunately, argmax is a piecewise constant function, so its Jacobian is either zero (almost everywhere) or undefined (in the case of ties).
",2.2 From STE to SPIGOT,[0],[0]
"One solution, taken in structured attention, is to replace the argmax with marginal inference and a softmax function, so that ẑ encodes probability distributions over parts (Kim et al., 2017; Liu and Lapata, 2018).",2.2 From STE to SPIGOT,[0],[0]
"As discussed in §1, there are two reasons to avoid this modification.",2.2 From STE to SPIGOT,[0],[0]
"Softmax can only be used when marginal inference is feasible, by sum-product algorithms for example (Eisner, 2016; Friesen and Domingos, 2016); in general marginal inference can be #P-complete.",2.2 From STE to SPIGOT,[0],[0]
"Further, a soft intermediate layer will be less amenable to inspection by anyone wishing to understand and improve the model.
",2.2 From STE to SPIGOT,[0],[0]
"In another line of work, argmax is augmented with a strongly-convex penalty on the solutions (Martins and Astudillo, 2016; Amos and Kolter, 2017; Niculae and Blondel, 2017; Niculae et al., 2018; Mensch and Blondel, 2018).",2.2 From STE to SPIGOT,[0],[0]
"However, their approaches require solving a relaxation even when exact decoding is tractable.",2.2 From STE to SPIGOT,[0],[0]
"Also, the penalty will bias the solutions found by the decoder, which may be an undesirable conflation of computational and modeling concerns.
",2.2 From STE to SPIGOT,[0],[0]
"A simpler solution is the STE method (Hinton, 2012), which replaces the Jacobian matrix in Equation 3 by the identity matrix.",2.2 From STE to SPIGOT,[0],[0]
"This method has been demonstrated to work well when used to “backpropagate” through hard threshold functions (Bengio et al., 2013; Friesen and Domingos, 2018) and categorical random variables (Jang et al., 2016; Choi et al., 2017).
",2.2 From STE to SPIGOT,[0],[0]
"Consider for a moment what we would do if ẑ were a vector of parameters, rather than intermediate predictions.",2.2 From STE to SPIGOT,[0],[0]
"In this case, we are seeking points in Z that minimize L; denote that set of minimizers by Z∗. Given ∇ẑL and step size η, we would update ẑ to be ẑ",2.2 From STE to SPIGOT,[0],[0]
"− η∇ẑL. This update, however, might not return a value in the feasible set Z , or even (if we are using a linear relaxation) the relaxed set P .
",2.2 From STE to SPIGOT,[0],[0]
SPIGOT therefore introduces a projection step that aims to keep the “updated” ẑ in the feasible set.,2.2 From STE to SPIGOT,[0],[0]
"Of course, we do not directly update ẑ; we continue backpropagation through s and onward to the parameters.",2.2 From STE to SPIGOT,[0],[0]
"But the projection step nonetheless alters the parameter updates in the way that our proxy for “∇sL” is defined.
",2.2 From STE to SPIGOT,[0],[0]
"The procedure is defined as follows:
p̂ = ẑ− η∇ẑL, (4a)",2.2 From STE to SPIGOT,[0],[0]
"z̃ = projP(p̂), (4b) ∇sL , ẑ−",2.2 From STE to SPIGOT,[0],[0]
"z̃. (4c)
",2.2 From STE to SPIGOT,[0],[0]
"First, the method makes an “update” to ẑ as if it contained parameters (Equation 4a), letting p̂ denote the new value.",2.2 From STE to SPIGOT,[0],[0]
"Next, p̂ is projected back onto the (relaxed) feasible set (Equation 4b), yielding a feasible new value z̃.",2.2 From STE to SPIGOT,[0],[0]
"Finally, the gradients with respect to s are computed by Equation 4c.
",2.2 From STE to SPIGOT,[0],[0]
"Due to the convexity of P , the projected point z̃ will always be unique, and is guaranteed to be no farther than p̂ from any point in Z∗ (Luenberger and Ye, 2015).1 Compared to STE, SPIGOT in-
1Note that this property follows from P’s convexity, and we do not assume the convexity of L.
volves a projection and limits ∇sL to a smaller space to satisfy constraints.",2.2 From STE to SPIGOT,[0],[0]
"See Figure 1 for an illustration.
",2.2 From STE to SPIGOT,[0],[0]
"When efficient exact solutions (such as dynamic programming) are available, they can be used.",2.2 From STE to SPIGOT,[0],[0]
"Yet, we note that SPIGOT does not assume the argmax operation is solved exactly.",2.2 From STE to SPIGOT,[0],[0]
"Using SPIGOT, we now devise an algorithm to “backpropagate” through NLP pipelines.",2.3 Backpropagation through Pipelines,[0],[0]
"In these pipelines, an intermediate task’s output is fed into an end task for use as features.",2.3 Backpropagation through Pipelines,[0],[0]
"The parameters of the complete model are divided into two parts: denote the parameters of the intermediate task model byφ (used to calculate s), and those in the end task model as θ.2 As introduced earlier, the end-task loss function to be minimized is L, which depends on both φ and θ.
Algorithm 1 describes the forward and backward computations.",2.3 Backpropagation through Pipelines,[0],[0]
"It takes an end task training pair 〈x,y〉, along with the intermediate task’s feasible set Z , which is determined by x. It first runs the intermediate model and decodes to get intermediate structure ẑ, just as in a standard pipeline.",2.3 Backpropagation through Pipelines,[0],[0]
"Then forward propagation is continued into the end-task model to compute loss L, using ẑ to define input features.",2.3 Backpropagation through Pipelines,[0],[0]
"Backpropagation in the endtask model computes ∇θL and ∇ẑL, and ∇sL is then constructed using Equations 4.",2.3 Backpropagation through Pipelines,[0],[0]
"Backpropagation then continues into the intermediate model, computing∇φL.
Due to its flexibility, SPIGOT is applicable to many training scenarios.",2.3 Backpropagation through Pipelines,[0],[0]
"When there is no 〈x, z〉 training data for the intermediate task, SPIGOT can be used to induce latent structures for the end-task (Yogatama et al., 2017; Kim et al., 2017; Choi et al., 2017, inter alia).",2.3 Backpropagation through Pipelines,[0],[0]
"When intermediate-task training data is available, one can use SPIGOT to adopt joint learning by minimizing an interpolation of L (on end-task data 〈x,y〉) and an intermediate-task loss function L̃ (on intermediate task data 〈x, z〉).",2.3 Backpropagation through Pipelines,[0],[0]
This is the setting in our experiments; note that we do not assume any overlap in the training examples for the two tasks.,2.3 Backpropagation through Pipelines,[0],[0]
"In this section we discuss how to compute approximate projections for the two intermediate tasks
2Nothing prohibits tying across pre-argmax parameters and post-argmax parameters; this separation is notationally convenient but not at all necessary.
",3 Solving the Projections,[0],[0]
"Algorithm 1 Forward and backward computation with SPIGOT. 1: procedure SPIGOT(x,y,Z) 2: Construct A, b such that Z = {p ∈",3 Solving the Projections,[0],[0]
Zd | Ap ≤ b} 3: P ← {p ∈ Rd | Ap ≤ b} .,3 Solving the Projections,[0],[0]
Relaxation 4: Forwardprop and compute sφ(x) 5: ẑ← argmaxz∈Z z>sφ(x) .,3 Solving the Projections,[0],[0]
"Intermediate decoding 6: Forwardprop and compute L given x, y, and ẑ 7: Backprop and compute∇θL and∇ẑL 8: z̃← projP(ẑ− η∇ẑL) .",3 Solving the Projections,[0],[0]
"Projection 9: ∇sL← ẑ− z̃ 10: Backprop and compute∇φL 11: end procedure
considered in this work, arc-factored unlabeled dependency parsing and first-order semantic dependency parsing.
",3 Solving the Projections,[0],[0]
"In early experiments we observe that for both tasks, projecting with respect to all constraints of their original formulations using a generic quadratic program solver was prohibitively slow.",3 Solving the Projections,[0],[0]
"Therefore, we construct relaxed polytopes by considering only a subset of the constraints.3",3 Solving the Projections,[0],[0]
"The projection then decomposes into a series of singly constrained quadratic programs (QP), each of which can be efficiently solved in linear time.
",3 Solving the Projections,[0],[0]
The two approximate projections discussed here are used in backpropagation only.,3 Solving the Projections,[0],[0]
"In the forward pass, we solve the decoding problem using the models’ original decoding algorithms.
",3 Solving the Projections,[0],[0]
Arc-factored unlabeled dependency parsing.,3 Solving the Projections,[0],[0]
"For unlabeled dependency trees, we impose [0, 1] constraints and single-headedness constraints.4
Formally, given a length-n input sentence, excluding self-loops, an arc-factored parser considers d = n(n − 1) candidate arcs.",3 Solving the Projections,[0],[0]
"Let i→j denote an arc from the ith token to the jth, and σ(i→j) denote its index.",3 Solving the Projections,[0],[0]
"We construct the relaxed feasible set by:
PDEP = p ∈",3 Solving the Projections,[0],[0]
Ud ∣∣∣∣∣∣ ∑,3 Solving the Projections,[0],[0]
i 6=j pσ(i→j) =,3 Solving the Projections,[0],[0]
"1,∀j  , (5) i.e., we consider each token j individually, and force single-headedness by constraining the number of arcs incoming to j to sum to 1.",3 Solving the Projections,[0],[0]
"Algorithm 2 summarizes the procedure to project onto PDEP.
",3 Solving the Projections,[0],[0]
"3A parallel work introduces an active-set algorithm to solve the same class of quadratic programs (Niculae et al., 2018).",3 Solving the Projections,[0],[0]
"It might be an efficient approach to solve the projections in Equation 4b, which we leave to future work.
4",3 Solving the Projections,[0],[0]
"It requires O(n2) auxiliary variables and O(n3) additional constraints to ensure well-formed tree structures (Martins et al., 2013).
",3 Solving the Projections,[0],[0]
"Line 3 forms a singly constrained QP, and can be solved in O(n) time (Brucker, 1984).
",3 Solving the Projections,[0],[0]
Algorithm 2 Projection onto the relaxed polytope PDEP for dependency tree structures.,3 Solving the Projections,[0],[0]
"Let bold σ(·→j) denote the index set of arcs incoming to j. For a vector v, we use vσ(·→j) to denote vector [vk]k∈σ(·→j).
1: procedure DEPPROJ(p̂) 2: for j = 1, 2, . . .",3 Solving the Projections,[0],[0]
", n",3 Solving the Projections,[0],[0]
"do 3: z̃σ(·→j) ← proj∆n−2 ( p̂σ(·→j) ) 4: end for 5: return z̃ 6: end procedure
First-order semantic dependency parsing.",3 Solving the Projections,[0],[0]
"Semantic dependency parsing uses labeled bilexical dependencies to represent sentence-level semantics (Oepen et al., 2014, 2015, 2016).",3 Solving the Projections,[0],[0]
"Each dependency is represented by a labeled directed arc from a head token to a modifier token, where the arc label encodes broadly applicable semantic relations.",3 Solving the Projections,[0],[0]
"Figure 2 diagrams a semantic graph from the DELPH-IN MRS-derived dependencies (DM), together with a syntactic tree.
",3 Solving the Projections,[0],[0]
"We use a state-of-the-art semantic dependency parser (Peng et al., 2017) that considers three types of parts: heads, unlabeled arcs, and labeled arcs.",3 Solving the Projections,[0],[0]
Let σ(i `→ j) denote the index of the arc from i to j with semantic role `.,3 Solving the Projections,[0],[0]
"In addition to [0, 1] constraints, we constrain that the predictions for labeled arcs sum to the prediction of their associated unlabeled arc:
PSDP { p ∈ Ud ∣∣∣∣∣∑ ` p σ(i `→j) = pσ(i→j), ∀i 6= j } .
(6)
",3 Solving the Projections,[0],[0]
This ensures that exactly one label is predicted if and only if its arc is present.,3 Solving the Projections,[0],[0]
The projection onto PSDP can be solved similarly to Algorithm 2.,3 Solving the Projections,[0],[0]
We drop the determinism constraint imposed by Peng et al. (2017) in the backward computation.,3 Solving the Projections,[0],[0]
"We empirically evaluate our method with two sets of experiments: using syntactic tree structures in semantic dependency parsing, and using semantic dependency graphs in sentiment classification.",4 Experiments,[0],[0]
"In this experiment we consider an intermediate syntactic parsing task, followed by seman-
… became dismayed at
poss arg1
arg2
’sG-2 connections arrested traffickersto drug
arg2 compound
root
arg2 arg1 arg2
tic dependency parsing as the end task.",4.1 Syntactic-then-Semantic Parsing,[0],[0]
"We first briefly review the neural network architectures for the two models (§4.1.1), and then introduce the datasets (§4.1.2) and baselines (§4.1.3).",4.1 Syntactic-then-Semantic Parsing,[0],[0]
Syntactic dependency parser.,4.1.1 Architectures,[0],[0]
"For intermediate syntactic dependencies, we use the unlabeled arc-factored parser of Kiperwasser and Goldberg (2016).",4.1.1 Architectures,[0],[0]
"It uses bidirectional LSTMs (BiLSTM) to encode the input, followed by a multilayerperceptron (MLP) to score each potential dependency.",4.1.1 Architectures,[0],[0]
"One notable modification is that we replace their use of Chu-Liu/Edmonds’ algorithm (Chu and Liu, 1965; Edmonds, 1967) with the Eisner algorithm (Eisner, 1996, 2000), since our dataset is in English and mostly projective.
",4.1.1 Architectures,[0],[0]
Semantic dependency parser.,4.1.1 Architectures,[0],[0]
We use the basic model of Peng et al. (2017) (denoted as NEURBOPARSER) as the end model.,4.1.1 Architectures,[0],[0]
"It is a first-order parser, and uses local factors for heads, unlabeled arcs, and labeled arcs.",4.1.1 Architectures,[0],[0]
NEURBOPARSER does not use syntax.,4.1.1 Architectures,[0],[0]
"It first encodes an input sentence with a two-layer BiLSTM, and then computes part scores with two-layer tanh-MLPs.",4.1.1 Architectures,[0],[0]
"Inference is conducted with AD3 (Martins et al., 2015).",4.1.1 Architectures,[0],[0]
"To add syntactic features to NEURBOPARSER, we concatenate a token’s contextualized representation to that of its syntactic head, predicted by the intermediate parser.",4.1.1 Architectures,[0],[0]
"Formally, given length-n input sentence, we first run a BiLSTM.",4.1.1 Architectures,[0],[0]
We use the concatenation of the two hidden representations hj =,4.1.1 Architectures,[0],[0]
[ −→ h j ; ←−,4.1.1 Architectures,[0],[0]
h j ] at each position j as the contextualized token representations.,4.1.1 Architectures,[0],[0]
"We then concatenate
hj with the representation of its head hHEAD(j) by
h̃j =",4.1.1 Architectures,[0],[0]
[hj ;hHEAD(j)],4.1.1 Architectures,[0],[0]
= hj ;∑ i 6=j ẑσ(i→j),4.1.1 Architectures,[0],[0]
"hi  , (7)
where ẑ ∈ Bn(n−1) is a binary encoding of the tree structure predicted by by the intermediate parser.",4.1.1 Architectures,[0],[0]
We then use h̃j anywhere hj would have been used in NEURBOPARSER.,4.1.1 Architectures,[0],[0]
"In backpropagation, we compute ∇ẑL with an automatic differentiation toolkit (DyNet; Neubig et al., 2017).
",4.1.1 Architectures,[0],[0]
"We note that this approach can be generalized to convolutional neural networks over graphs (Mou et al., 2015; Duvenaud et al., 2015; Kipf and Welling, 2017, inter alia), recurrent neural networks along paths (Xu et al., 2015; Roth and Lapata, 2016, inter alia) or dependency trees (Tai et al., 2015).",4.1.1 Architectures,[0],[0]
"We choose to use concatenations to control the model’s complexity, and thus to better understand which parts of the model work.
",4.1.1 Architectures,[0],[0]
"We refer the readers to Kiperwasser and Goldberg (2016) and Peng et al. (2017) for further details of the parsing models.
",4.1.1 Architectures,[0],[0]
Training procedure.,4.1.1 Architectures,[0],[0]
"Following previous work, we minimize structured hinge loss (Tsochantaridis et al., 2004) for both models.",4.1.1 Architectures,[0],[0]
"We jointly train both models from scratch, by randomly sampling an instance from the union of their training data at each step.",4.1.1 Architectures,[0],[0]
"In order to isolate the effect of backpropagation, we do not share any parameters between the two models.5 Implementation details are summarized in the supplementary materials.",4.1.1 Architectures,[0],[0]
"• For semantic dependencies, we use the
English dataset from SemEval 2015 Task 18 (Oepen et al., 2015).",4.1.2 Datasets,[0],[0]
"Among the three formalisms provided by the shared task, we consider DELPH-IN MRS-derived dependencies (DM) and Prague Semantic Dependencies (PSD).6 It includes §00–19 of the WSJ corpus as training data, §20 and §21 for development and in-domain test data, resulting in a 33,961/1,692/1,410 train/dev./test split, and
5 Parameter sharing has proved successful in many related tasks (Collobert and Weston, 2008; Søgaard and Goldberg, 2016; Ammar et al., 2016; Swayamdipta et al., 2016, 2017, inter alia), and could be easily combined with our approach.
",4.1.2 Datasets,[0],[0]
"6We drop the third (PAS) because its structure is highly predictable from parts-of-speech, making it less interesting.
",4.1.2 Datasets,[0],[0]
"1,849 out-of-domain test instances from the Brown corpus.7 •",4.1.2 Datasets,[0],[0]
"For syntactic dependencies, we use the Stanford Dependency (de Marneffe and Manning, 2008) conversion of the the Penn Treebank WSJ portion (Marcus et al., 1993).",4.1.2 Datasets,[0],[0]
"To avoid data leak, we depart from standard split and use §20 and §21 as development and test data, and the remaining sections as training data.",4.1.2 Datasets,[0],[0]
"The number of training/dev./test instances is 40,265/2,012/1,671.",4.1.2 Datasets,[0],[0]
We compare to the following baselines: • A pipelined system (PIPELINE).,4.1.3 Baselines,[0],[0]
"The pre-
trained parser achieves 92.9 test unlabeled attachment score (UAS).8
7The organizers remove, e.g., instances with cyclic graphs, and thus only a subset of the WSJ corpus is included.",4.1.3 Baselines,[0],[0]
"See Oepen et al. (2015) for details.
",4.1.3 Baselines,[0],[0]
8 Note that this number is not comparable to the parsing literature due to the different split.,4.1.3 Baselines,[0],[0]
"As a sanity check, we found in preliminary experiments that the same parser archi-
• Structured attention networks (SA; Kim et al., 2017).",4.1.3 Baselines,[0],[0]
"We use the inside-outside algorithm (Baker, 1979) to populate z with arcs’ marginal probabilities, use log-loss as the objective in training the intermediate parser.",4.1.3 Baselines,[0],[0]
"• The straight-through estimator (STE; Hinton,
2012), introduced in §2.2.",4.1.3 Baselines,[0],[0]
Table 1 compares the semantic dependency parsing performance of SPIGOT to all five baselines.,4.1.4 Empirical Results,[0],[0]
"FREDA3 (Peng et al., 2017) is a state-of-the-art variant of NEURBOPARSER that is trained using multitask learning to jointly predict three different semantic dependency graph formalisms.",4.1.4 Empirical Results,[0],[0]
"Like the basic NEURBOPARSER model that we build from, FREDA3 does not use any syntax.",4.1.4 Empirical Results,[0],[0]
"Strong DM performance is achieved in a more recent work by using joint learning and an ensemble (Peng et al., 2018), which is beyond fair comparisons to the models discussed here.
",4.1.4 Empirical Results,[0],[0]
We found that using syntactic information improves semantic parsing performance: using pipelined syntactic head features brings 0.5– 1.4% absolute labeled F1 improvement to NEURBOPARSER.,4.1.4 Empirical Results,[0],[0]
"Such improvements are smaller compared to previous works, where dependency path and syntactic relation features are included (Almeida and Martins, 2015; Ribeyre et al., 2015; Zhang et al., 2016), indicating the potential to get better performance by using more syntactic information, which we leave to future work.
",4.1.4 Empirical Results,[0],[0]
Both STE and SPIGOT use hard syntactic features.,4.1.4 Empirical Results,[0],[0]
"By allowing backpropation into the intermediate syntactic parser, they both consistently outperform PIPELINE.",4.1.4 Empirical Results,[0],[0]
"On the other hand, when marginal syntactic tree structures are used, SA outperforms PIPELINE only on the out-of-domain PSD test set, and improvements under other cases are not observed.
",4.1.4 Empirical Results,[0],[0]
"Compared to STE, SPIGOT outperforms STE on DM by more than 0.3% absolute labeled F1, both in-domain and out-of-domain.",4.1.4 Empirical Results,[0],[0]
"For PSD, SPIGOT achieves similar performance to STE on in-domain test set, but has a 0.5% absolute labeled F1 improvement on out-of-domain data, where syntactic parsing is less accurate.
",4.1.4 Empirical Results,[0],[0]
"tecture achieves 93.5 UAS when trained and evaluated with the standard split, close to the results reported by Kiperwasser and Goldberg (2016).",4.1.4 Empirical Results,[0],[0]
Our second experiment uses semantic dependency graphs to improve sentiment classification performance.,4.2 Semantic Dependencies for Sentiment Classification,[0],[0]
"We are not aware of any efficient algorithm that solves marginal inference for semantic dependency graphs under determinism constraints, so we do not include a comparison to SA.",4.2 Semantic Dependencies for Sentiment Classification,[0],[0]
"Here we use NEURBOPARSER as the intermediate model, as described in §4.1.1, but with no syntactic enhancements.
",4.2.1 Architectures,[0],[0]
Sentiment classifier.,4.2.1 Architectures,[0],[0]
We first introduce a baseline that does not use any structural information.,4.2.1 Architectures,[0],[0]
"It learns a one-layer BiLSTM to encode the input sentence, and then feeds the sum of all hidden states into a two-layer ReLU-MLP.
",4.2.1 Architectures,[0],[0]
"To use semantic dependency features, we concatenate a word’s BiLSTM-encoded representation to the averaged representation of its heads, together with the corresponding semantic roles, similarly to that in Equation 7.9 Then the concatenation is fed into an affine transformation followed by a ReLU activation.",4.2.1 Architectures,[0],[0]
"The rest of the model is kept the same as the BiLSTM baseline.
",4.2.1 Architectures,[0],[0]
Training procedure.,4.2.1 Architectures,[0],[0]
"We use structured hinge loss to train the semantic dependency parser, and log-loss for the sentiment classifier.",4.2.1 Architectures,[0],[0]
"Due to the discrepancy in the training data size of the two tasks (33K vs. 7K), we pre-train a semantic dependency parser, and then adopt joint training together with the classifier.",4.2.1 Architectures,[0],[0]
"In the joint training stage, we randomly sample 20% of the semantic dependency training instances each epoch.",4.2.1 Architectures,[0],[0]
Implementations are detailed in the supplementary materials.,4.2.1 Architectures,[0],[0]
"For semantic dependencies, we use the DM dataset introduced in §4.1.2.
We consider a binary classification task using the Stanford Sentiment Treebank (Socher et al., 2013).",4.2.2 Datasets,[0],[0]
It consists of roughly 10K movie review sentences from Rotten Tomatoes.,4.2.2 Datasets,[0],[0]
"The full dataset includes a rating on a scale from 1 to 5 for each constituent (including the full sentences), resulting in more than 200K instances.",4.2.2 Datasets,[0],[0]
"Following previous work (Iyyer et al., 2015), we only use full-sentence
9In a well-formed semantic dependency graph, a token may have multiple heads.",4.2.2 Datasets,[0],[0]
"Therefore we use average instead of the sum in Equation 7.
instances, with neutral instances excluded (3s) and the remaining four rating levels converted to binary “positive” or “negative” labels.",4.2.2 Datasets,[0],[0]
"This results in a 6,920/872/1,821 train/dev./test split.",4.2.2 Datasets,[0],[0]
Table 2 compares our SPIGOT method to three baselines.,4.2.3 Empirical Results,[0],[0]
"Pipelined semantic dependency predictions brings 0.9% absolute improvement in classification accuracy, and SPIGOT outperforms all baselines.",4.2.3 Empirical Results,[0],[0]
In this task STE achieves slightly worse performance than a fixed pre-trained PIPELINE.,4.2.3 Empirical Results,[0],[0]
We examine here how the intermediate model is affected by the end-task training signal.,5 Analysis,[0],[0]
"Is the endtask signal able to “overrule” intermediate predictions?
",5 Analysis,[0],[0]
We use the syntactic-then-semantic parsing model (§4.1) as a case study.,5 Analysis,[0],[0]
Table 3 compares a pipelined system to one jointly trained using SPIGOT.,5 Analysis,[0],[0]
"We consider the development set instances where both syntactic and semantic annotations are available, and partition them based on whether the two systems’ syntactic predictions agree (SAME), or not (DIFF).",5 Analysis,[0],[0]
"The second group includes sentences with much lower syntactic parsing accuracy (91.3 vs. 97.4 UAS), and SPIGOT further reduces this to 89.6.",5 Analysis,[0],[0]
"Even though these changes hurt syntactic parsing accuracy, they lead to a 1.1% absolute gain in labeled F1 for semantic parsing.",5 Analysis,[0],[0]
"Furthermore, SPIGOT has an overall less detrimental effect on the intermediate parser than STE: using SPIGOT, intermediate dev. parsing UAS drops to 92.5 from the 92.9 pipelined performance, while STE reduces it to 91.8.
",5 Analysis,[0],[0]
We then take a detailed look and categorize the changes in intermediate trees by their correlations with the semantic graphs.,5 Analysis,[0],[0]
"Specifically, when a modifier m’s head is changed from h to h′ in the
tree, we consider three cases: (a) h′ is a head of m in the semantic graph; (b) h′ is a modifier of m in the semantic graph; (c) h is the modifier of m in the semantic graph.",5 Analysis,[0],[0]
The first two reflect modifications to the syntactic parse that rearrange semantically linked words to be neighbors.,5 Analysis,[0],[0]
"Under (c), the semantic parser removes a syntactic dependency that reverses the direction of a semantic dependency.",5 Analysis,[0],[0]
"These cases account for 17.6%, 10.9%, and 12.8%, respectively (41.2% combined) of the total changes.",5 Analysis,[0],[0]
"Making these changes, of course, is complicated, since they often require other modifications to maintain well-formedness of the tree.",5 Analysis,[0],[0]
Figure 2 gives an example.,5 Analysis,[0],[0]
Joint learning in NLP pipelines.,6 Related Work,[0],[0]
"To avoid cascading errors, much effort has been devoted to joint decoding in NLP pipelines (Habash and Rambow, 2005; Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008; Lewis et al., 2015; Zhang et al., 2015, inter alia).",6 Related Work,[0],[0]
"However, joint inference can sometimes be prohibitively expensive.",6 Related Work,[0],[0]
"Recent advances in representation learning facilitate exploration in the joint learning of multiple tasks by sharing parameters (Collobert and Weston, 2008; Blitzer et al., 2006; Finkel and Manning, 2010; Zhang and Weiss, 2016; Hashimoto et al., 2017, inter alia).
",6 Related Work,[0],[0]
Differentiable optimization.,6 Related Work,[0],[0]
"Gould et al. (2016) review the generic approaches to differentiation in bi-level optimization (Bard, 2010; Kunisch and Pock, 2013).",6 Related Work,[0],[0]
Amos and Kolter (2017) extend their efforts to a class of subdifferentiable quadratic programs.,6 Related Work,[0],[0]
"However, they both require that the intermediate objective has an invertible Hessian, limiting their application
in NLP.",6 Related Work,[0],[0]
"In another line of work, the steps of a gradient-based optimization procedure are unrolled into a single computation graph (Stoyanov et al., 2011; Domke, 2012; Goodfellow et al., 2013; Brakel et al., 2013).",6 Related Work,[0],[0]
This comes at a high computational cost due to the second-order derivative computation during backpropagation.,6 Related Work,[0],[0]
"Moreover, constrained optimization problems (like many NLP problems) often require projection steps within the procedure, which can be difficult to differentiate through (Belanger and McCallum, 2016; Belanger et al., 2017).",6 Related Work,[0],[0]
"We presented SPIGOT, a novel approach to backpropagating through neural network architectures that include discrete structured decisions in intermediate layers.",7 Conclusion,[0],[0]
"SPIGOT devises a proxy for the gradients with respect to argmax’s inputs, employing a projection that aims to respect the constraints in the intermediate task.",7 Conclusion,[0],[0]
"We empirically evaluate our method with two architectures: a semantic parser with an intermediate syntactic parser, and a sentiment classifier with an intermediate semantic parser.",7 Conclusion,[0],[0]
"Experiments show that SPIGOT achieves stronger performance than baselines under both settings, and outperforms stateof-the-art systems on semantic dependency parsing.",7 Conclusion,[0],[0]
Our implementation is available at https: //github.com/Noahs-ARK/SPIGOT.,7 Conclusion,[0],[0]
"We thank the ARK, Julian Michael, Minjoon Seo, Eunsol Choi, and Maxwell Forbes for their helpful comments on an earlier version of this work, and the anonymous reviewers for their valuable feedback.",Acknowledgments,[0],[0]
This work was supported in part by NSF grant IIS-1562364.,Acknowledgments,[0],[0]
"We introduce the structured projection of intermediate gradients optimization technique (SPIGOT), a new method for backpropagating through neural networks that include hard-decision structured predictions (e.g., parsing) in intermediate layers.",abstractText,[0],[0]
"SPIGOT requires no marginal inference, unlike structured attention networks (Kim et al., 2017) and some reinforcement learning-inspired solutions (Yogatama et al., 2017).",abstractText,[0],[0]
"Like socalled straight-through estimators (Hinton, 2012), SPIGOT defines gradient-like quantities associated with intermediate nondifferentiable operations, allowing backpropagation before and after them; SPIGOT’s proxy aims to ensure that, after a parameter update, the intermediate structure will remain well-formed.",abstractText,[0],[0]
"We experiment on two structured NLP pipelines: syntactic-then-semantic dependency parsing, and semantic parsing followed by sentiment classification.",abstractText,[0],[0]
"We show that training with SPIGOT leads to a larger improvement on the downstream task than a modularly-trained pipeline, the straight-through estimator, and structured attention, reaching a new state of the art on semantic dependency parsing.",abstractText,[0],[0]
Backpropagating through Structured Argmax using a SPIGOT,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 153–161 New Orleans, Louisiana, June 1 - 6, 2018. c©2017 Association for Computational Linguistics",text,[0],[0]
"Natural language understanding (NLU) is a key component of dialog systems for commercial personal digital assistants (PDAs) such as Amazon Alexa, Google Home, Microsoft Cortana and Apple Siri.",1 Introduction,[0],[0]
"The task of the NLU component is to map input user utterances into a semantic frame consisting of domain, intent and slots (Kurata et al., 2016).",1 Introduction,[0],[0]
"The semantic frame is used by the dialog manager for state tracking and action selection.
",1 Introduction,[0],[0]
"Slot tagging can be formulated as a sequence classification task where each input word in the user utterance must be classified as belonging to one of the slot types in a predefined schema (Sarikaya et al., 2016).",1 Introduction,[0],[0]
"In a standard NLU architecture, each new domain defines a new domainspecific schema for its slots.",1 Introduction,[0],[0]
"Figure 1 shows examples of annotated queries from three different domains relevant to a typical commercial digital
assistant.",1 Introduction,[0],[0]
"Since the schemas for different domains can vary, the usual strategy is to train a separate slot tagging model for each new domain.",1 Introduction,[0],[0]
"However, the number of domains increases rapidly as the PDAs are required to support new scenarios and training a separate slot tagging model for each new domain becomes prohibitively expensive in terms of annotation costs.
",1 Introduction,[0],[0]
"Even though different domains have different slot tagging schemas, some classes of slots appear across a number of domains, as suggested by the examples in Figure 1.",1 Introduction,[0],[0]
"Both travel and flight status have date and time related slots, and all three domains have the location slot.",1 Introduction,[0],[0]
Reusing annotated data for these common slots would allow us to train models with better accuracy using less data.,1 Introduction,[0],[0]
"However, since both the input distribution and the label distribution are different across domains, we must use domain adaptation methods to train on the joint data (Daume, 2007; Kim et al.,
153
2016c; Blitzer et al., 2006).",1 Introduction,[0],[0]
"In this data-driven adaptation approach, we build a repository of annotated data containing date, time, location and other reusable slots.",1 Introduction,[0],[0]
We then combine relevant data from the reusable repository with the domain specific data during model training.,1 Introduction,[0],[0]
"Figure 2(a) shows an example of this architecture where reusable date/time data is used for training travel domain.
",1 Introduction,[0],[0]
"A drawback of the data-driven adaptation approach is that as the repository of data for reusable slots grows, the training time for new domains increases.",1 Introduction,[0],[0]
"The training data for a new domain might be in the hundreds of samples, while the training data for the reusable slots might contain hundreds of thousands of samples.",1 Introduction,[0],[0]
"This increase in training time makes iterative refinement difficult in the initial design of new domains, which is when the ability to deploy new models quickly is crucial.
",1 Introduction,[0],[0]
"An alternative strategy is to use model-driven adaptation approaches (Kim et al., 2017b) as shown in Figure 2(b).",1 Introduction,[0],[0]
"Here, instead of retraining on the data for the reusable slots, we train “expert” models for these slots, and use the output of these models directly when training new domains.",1 Introduction,[0],[0]
"Using model-driven adaptation ensures that model training time is proportional to the data size of new
target domains, as opposed to the large data size for reusable slots, allowing for faster training.
",1 Introduction,[0],[0]
"In this paper, we present a model-driven adaptation approach for slot tagging called Bag of Experts (BoE).",1 Introduction,[0],[0]
"In Section 2, we first describe how this approach can be applied to two popular machine learning methods used for slot tagging: Long Short Term Memory (LSTM) and Conditional Random Fields (CRF) models.",1 Introduction,[0],[0]
"We then describe a dataset of 10 target domains and 2 reusable domains that we’ve collected for use in a commercial digital assistant, in Section 3.",1 Introduction,[0],[0]
"Using this data, we conduct experiments comparing the BoE models with their non-expert counterparts, and show that BoE models can lead to significant F1-score improvements.",1 Introduction,[0],[0]
The experimental setup is described in Section 4.1 and the results are discussed in Section 4.3.,1 Introduction,[0],[0]
This is followed by a survey of related work in Section 5 and the conclusion in Section 6.,1 Introduction,[0],[0]
"We first describe our LSTM and CRF models for slot tagging, followed by their BoE variants: LSTM-BoE and CRF-BoE. Tensorflow (Abadi et al., 2015) was used for implementing the LSTM models, while a custom C++ implementation was
used for the CRF models.",2 Approaches,[0],[0]
"For our LSTM model, we follow a standard bidirectional LSTM architecture (Huang et al., 2015; Ma and Hovy, 2016; Lample et al., 2016).",2.1 LSTM,[0],[0]
Let w1...,2.1 LSTM,[0],[0]
wn denote the input word sequence.,2.1 LSTM,[0],[0]
"For every input word wi, let fCi and b C i be the outputs of the forward and backward character level LSTMs respectively, and let mi be the word embedding (initialized either randomly or with pretrained embeddings).",2.1 LSTM,[0],[0]
"The input to the word level LSTMs, gi, is the concatenation of these three vectors:
gi =",2.1 LSTM,[0],[0]
"[f C i ; b C i ;mi]
where both fCi , b C i ∈",2.1 LSTM,[0],[0]
R25 and mi has the same dimensions as the pre-trained embeddings.,2.1 LSTM,[0],[0]
"The forward and backward word level LSTMs take gi as input and produce fWi and b W i , which are then concatenated to produce hi:
hi =",2.1 LSTM,[0],[0]
"[f W i , b W i ]
",2.1 LSTM,[0],[0]
"where fWi , b W i ∈ R100, making hi ∈ R200.",2.1 LSTM,[0],[0]
hi is then input to a dense feed forward layer with a softmax activation to predict the label probabilities for each word.,2.1 LSTM,[0],[0]
"We train using stochastic gradient descent with Adam (Kingma and Ba, 2015).",2.1 LSTM,[0],[0]
"To avoid overfitting, we also use dropout on top of mi and hi layers, with a default dropout keep probability of 0.8.",2.1 LSTM,[0],[0]
"We experiment with some variations
of this default LSTM architecture, the results are described in Section 4.2.",2.1 LSTM,[0],[0]
We now describe the LSTM Bag of Experts (LSTM-BoE) architecture.,2.2 LSTM-BoE,[0],[0]
Let e1...,2.2 LSTM-BoE,[0],[0]
ek ∈ E be the set of reusable expert domains.,2.2 LSTM-BoE,[0],[0]
"For each expert ej , we train a separate LSTM with the architecture described in Section 2.1.",2.2 LSTM-BoE,[0],[0]
"Let heji be the bi-directional word LSTM output for expert ej on word wi.
",2.2 LSTM-BoE,[0],[0]
"When training on a target domain, for each word wi, we first compute the character level LSTMs fCi , b C i similarly to Section 2.1.",2.2 LSTM-BoE,[0],[0]
"We then compute a BoE representation for this word as:
hE = ∑
ei∈E h ej",2.2 LSTM-BoE,[0],[0]
"i
The input to the word level LSTM for word wi in the target domain is now a concatenation of the character level LSTM outputs (fCi , b C i ), the word embedding mi, and hE :
gi =",2.2 LSTM-BoE,[0],[0]
[f C i ; b C i ;mi;h,2.2 LSTM-BoE,[0],[0]
"E ]
gi is then input to the word level LSTM for the target domain to produce hi in the same way as Section 2.1.",2.2 LSTM-BoE,[0],[0]
"This architecture is similar to the one presented in (Kim et al., 2017b), with the exception that in their architecture, hE is concatenated with the word level LSTM output hi for the target
domain.",2.2 LSTM-BoE,[0],[0]
"In our architecture, we add hE before the word-level LSTM in order to capture long-range dependencies of label prediction for a word on expert predictions for context words.",2.2 LSTM-BoE,[0],[0]
"Conditional Random Fields (CRF) are a popular family of models that have been proven to work well in a variety of sequence tagging NLP applications (Lafferty et al., 2001).",2.3 CRF,[0],[0]
"For our experiments, we use a standard linear-chain CRF architecture with n-gram and context features.
",2.3 CRF,[0],[0]
"In particular, for each token, we use unigram, bigram and trigram features, along with previous and next unigrams, bigrams, and trigrams for context length of up to 3 words.",2.3 CRF,[0],[0]
"We also use a skip bigram feature created by concatenating the current unigram and skip-one unigram.
",2.3 CRF,[0],[0]
We train our CRF using stochastic gradient descent with L1 regularization to prevent overfitting.,2.3 CRF,[0],[0]
"The L1 coefficient was set to 0.1 and we use a learning rate of 0.1 with exponential decay for learning rate scheduling (Tsuruoka et al., 2009).",2.3 CRF,[0],[0]
"Similar to the LSTM-BoE model, we first train a CRF model cj for each of the reusable expert domains ej ∈ E. When training on a target domain, for every query word wi, a one-hot label vector",2.4 CRF-BoE,[0],[0]
l j,2.4 CRF-BoE,[0],[0]
i is emitted by each expert CRF model cj .,2.4 CRF-BoE,[0],[0]
"The length of the label vector lji is the number of labels in the expert domain, with the value corresponding to the label predicted by cj for word wi set to 1, and values for all other labels set to 0.",2.4 CRF-BoE,[0],[0]
"For each word, the label vectors for all the expert CRF models are concatenated and provided as features for the target domain CRF training, along with the n-gram features.",2.4 CRF-BoE,[0],[0]
We built a dataset of 10 target domains for experimentation.,3.1 Target Domains,[0],[0]
Table 1 shows the list of domains as well as some statistics and example utterances.,3.1 Target Domains,[0],[0]
"We treated these as new domains - that is, we do not have real interaction data with users for these domains.",3.1 Target Domains,[0],[0]
"The annotated data is therefore prepared in two steps.
",3.1 Target Domains,[0],[0]
"First, utterances are obtained using crowdsourcing, where workers are provided with prompts for different intents of a domain and asked to generate
natural language utterances corresponding to those intents.",3.1 Target Domains,[0],[0]
"Next, the generated utterances are annotated by a different set of crowd workers, using the slot schema for each domain.",3.1 Target Domains,[0],[0]
"Inter-annotator agreement as well as manual inspection are used to ensure data quality in both stages.
",3.1 Target Domains,[0],[0]
The amount of data collected varies for each domain based on its complexity and business priority.,3.1 Target Domains,[0],[0]
Dataset size statistics for the data used in our experiments are presented in section 4.1.,3.1 Target Domains,[0],[0]
"Test and dev data are sampled at 10% of the total annotated data, with stratified sampling used in order to preserve the distribution of the intents.",3.1 Target Domains,[0],[0]
We experiment with two domains containing reusable slots: timex and location.,3.2 Reusable Domains,[0],[0]
"The timex domain consists of utterances containing the slots date, time and duration.",3.2 Reusable Domains,[0],[0]
"The location domain consists of utterances containing location, location type and place name slots.",3.2 Reusable Domains,[0],[0]
"Both of these types of slots appear in more than 20 of a set of 40 domains developed for use in our commercial personal assistant, making them ideal candidates for reuse.1
1Several other candidate reusable domains exist, including: the name domain containing the slot contact name; the number domain containing the slots rating, quantity and price; and the reference domain containing the slots ordinal (whose values include “first”, “second” or “third”) and order ref (with values such as “before” or “after”).",3.2 Reusable Domains,[0],[0]
"All of these slots appear in more than 25% of the available domains.
",3.2 Reusable Domains,[0],[0]
Data for these domains was sampled from the input utterances from our commercial digital assistant.,3.2 Reusable Domains,[0],[0]
Each reusable domain contains about a million utterances.,3.2 Reusable Domains,[0],[0]
There is no overlap between utterances in the target domains used for our experiments and utterances in the reusable domains.,3.2 Reusable Domains,[0],[0]
"The data for the reusable domains is sampled from other domains available to the digital assistant, not including our target domains.
",3.2 Reusable Domains,[0],[0]
Grouping the reusable slots into domains in this way provides additional opportunities for a commercial system: the trained reusable domain models can be used in other related products which need to identify time and location related entities.,3.2 Reusable Domains,[0],[0]
Models trained on the timex and location data have F1-scores of 96% and 89% respectively on test data from their respective domains.,3.2 Reusable Domains,[0],[0]
We want to verify if BoE models can improve slot tagging performance by using the information from reusable domains.,4.1 Experimental Setup,[0],[0]
"To simulate the low data scenario for the initial model training, we create three training datasets by sampling 2000, 1000 and 500 training examples from every domain.",4.1 Experimental Setup,[0],[0]
"We use stratified sampling to maintain the input distribution of the intents across the three training datasets.
",4.1 Experimental Setup,[0],[0]
"For each training dataset, we train the four models as described in Section 2 and compute the precision, recall and F1-score on the test data.",4.1 Experimental Setup,[0],[0]
Fixed seeds are used when training all models to make the results reproducible.,4.1 Experimental Setup,[0],[0]
"Table 3 summarizes these results, with only F1-scores reported to save space.",4.1 Experimental Setup,[0],[0]
We describe these results in Section 4.3.,4.1 Experimental Setup,[0],[0]
"Using the dev data set for the 10 domains, we experimented with using different pretrained embeddings, dropout probabilities and a CRF output layer in our LSTM architecture.",4.2 LSTM architecture variants,[0],[0]
The results are summarized in Table 2.,4.2 LSTM architecture variants,[0],[0]
"For each of the 10 domains, we trained using each variant with 10 different seeds, and computed the mean F1-score for each domain.",4.2 LSTM architecture variants,[0],[0]
"For comparing two variants, we computed the mean difference in the F1-scores over the 10 domains and its p-value.
",4.2 LSTM architecture variants,[0],[0]
"We tried word level Glove embeddings of 100, 200 and 300 dimensions as well as 500- dimensional word embeddings trained over the ut-
terances from our commercial PDA logs.",4.2 LSTM architecture variants,[0],[0]
"Both 100 and 200 dimensional Glove embeddings led to statistically significant improvements, but the word embeddings trained over our logs led to the biggest improvement.",4.2 LSTM architecture variants,[0],[0]
"We also tried using a CRF output layer (Lample et al., 2016) and different values of dropout keep probability, but none of them gave statistically significant improvements over the default model.",4.2 LSTM architecture variants,[0],[0]
"Based on this, we used PDA trained 500-dimensional word embeddings for our final experiments on test data.",4.2 LSTM architecture variants,[0],[0]
Table 3(a) shows the F1-scores obtained by the different methods for the training data set of 2000 training instances for each of the 10 domains.,4.3 Results and Discussion,[0],[0]
LSTM based models in general perform better than the CRF based models.,4.3 Results and Discussion,[0],[0]
The LSTM models have a statistically significant average improvement of 3.14 absolute F1-score over the CRF models.,4.3 Results and Discussion,[0],[0]
"The better performance of LSTM over CRF can be explained by the LSTM being able to use information over longer contexts to make predictions, while the CRF model is limited to at most the previous and next 3 words.
",4.3 Results and Discussion,[0],[0]
The results in Table 3(a) also show that both the CRF-BoE and LSTM-BoE outperform the basic CRF and LSTM models.,4.3 Results and Discussion,[0],[0]
LSTM-BoE has a statistically significant mean improvement of 1.92 points over LSTM.,4.3 Results and Discussion,[0],[0]
"CRF-BoE also shows an average improvement of 2.19 points over the CRF model, but the results are not statistically significant.",4.3 Results and Discussion,[0],[0]
"Looking at results for individual domains, the highest improvement for BoE models are seen for transportation and travel.",4.3 Results and Discussion,[0],[0]
"This can be explained by these domains having a high frequency of timex and location slots, as shown in Table 4.
",4.3 Results and Discussion,[0],[0]
"The shopping model shows a regression for BoE models, and a reason could be the low frequency of expert slots (Table 4).",4.3 Results and Discussion,[0],[0]
"However, low frequency of expert slots does not always mean that BoE methods can’t help, as shown by the improvement in the purchase domain.",4.3 Results and Discussion,[0],[0]
"Finally, for sports, social network and deals domains, the LSTM-BoE improves over LSTM, while CRFBoE does not improve over CRF.",4.3 Results and Discussion,[0],[0]
"Our hypothesis is that given the query patterns for these domains, the dense vector output used by LSTM-BoE is able to transfer some information, while the categorical label output used by CRF-BoE is not.
",4.3 Results and Discussion,[0],[0]
"Table 3(b) shows the results with 500 and 1000
training data instances.",4.3 Results and Discussion,[0],[0]
Note that the improvements are even higher for the experiments with smaller training data.,4.3 Results and Discussion,[0],[0]
"In particular, LSTM-BoE shows an improvement of 4.63 in absolute F1score over LSTM when training with 500 instances.",4.3 Results and Discussion,[0],[0]
"Thus, as we reduce the amount of training data in the target domain, the performance improvement from BoE models is even higher.
",4.3 Results and Discussion,[0],[0]
"As an example, in the purchase domain, the LSTM-BoE model achieves an F1-score of 70.66% with only 500 training instances, while even with 2000 training instances the CRF model achieves an F1-score of only 66.24%.",4.3 Results and Discussion,[0],[0]
Thus the LSTM-BoE model achieves better F1-score with only one-fourth the training data.,4.3 Results and Discussion,[0],[0]
"Similarly, for flight status, travel, and transportation domains, the LSTM-BoE model gets better performance with 500 training instances, compared to a CRF model with 2000 training instances.",4.3 Results and Discussion,[0],[0]
"The LSTMBoE architecture, therefore, allows us to reuse the domain experts to produce better performing mod-
els with much lower data annotation costs.",4.3 Results and Discussion,[0],[0]
"As the target domain training data increases, the contribution due to domain experts goes down, but more experimentation is needed to establish the threshold at which it is no longer useful to add experts.",4.3 Results and Discussion,[0],[0]
"Early methods for slot-tagging used rule-based approaches (Ward and Issar, 1994).",5 Related Work,[0],[0]
"Much of the later work on supervised learning focused on CRFs, for example (Sarikaya et al., 2016), or neural networks (Deoras and Sarikaya, 2013; Yao et al., 2013; Liu et al., 2015; Celikyilmaz and HakkaniTur, 2015).",5 Related Work,[0],[0]
"Unsupervised (or weakly-supervised) methods also were used for NLU tasks, primarily leveraging search query click logs (Hakkani-Tur et al., 2011a,b, 2013) and knowledge graphs (Tur et al., 2012; Heck and Hakkani-Tur, 2012; Heck et al., 2013); hybrid methods, for example as described in (Kim et al., 2015a; Celikyilmaz et al., 2015; Chen et al., 2016), also exist.",5 Related Work,[0],[0]
"Our approach
in this paper is a purely supervised one.",5 Related Work,[0],[0]
"Transfer learning is a vast area of research, with too many publications for an exhaustive list.",5 Related Work,[0],[0]
We discuss some of the recent work most relevant to our methods.,5 Related Work,[0],[0]
"In (Kim et al., 2015b), the slot labels from across different domains are mapped into a shared space using Canonical Correlation Analysis (CCA) and automatically-induced embeddings over the label space.",5 Related Work,[0],[0]
"These label representations allow mapping of label types between different domains, which makes it possible to apply standard data-driven domain adaptation approaches (Daume, 2007).",5 Related Work,[0],[0]
"They also introduce a model-driven adaptation technique based on training a hidden unit CRF (HUCRF) on the source domain, which is then used to initialize the training for the target domain.",5 Related Work,[0],[0]
"The limitation of this approach is that only one source domain can be used, while multiple experts can be used in the proposed BoE approach.
",5 Related Work,[0],[0]
"(Kim et al., 2016a) build a single, universal slot tagging model, and constrain the decoding process to subsets of slots for various domains; this process assumes that a mapping of slot tags in the new domain to the ones in the universal slot model has already been generated.",5 Related Work,[0],[0]
"A related work by (Kim et al., 2016b) directly predicts the required schema prior to performing the constrained decoding.",5 Related Work,[0],[0]
"These approaches are attractive because only one universal model needs to be trained, but do not work in cases when a new domain contains a mixture of new and existing slots.",5 Related Work,[0],[0]
"Our approach allows transfer of partial knowledge in such cases.
",5 Related Work,[0],[0]
"(Kim et al., 2016c) uses a neural version of the approach first described in (Daume, 2007), by using existing annotated data in a variety of domains
to adapt the slot tag models of new domains where the tag space is partly shared.",5 Related Work,[0],[0]
"The drawback of such data-driven domain adaptation is the increase in training time as more experts are added.
",5 Related Work,[0],[0]
"An expert-based adaptation, similar to the techniques applied in this paper, was first described in (Kim et al., 2017b).",5 Related Work,[0],[0]
"(Jaech et al., 2016) use multitask learning, training a bidirectional LSTM with character-level embeddings, trained jointly to produce slot tags for a number of travel-related domains.",5 Related Work,[0],[0]
"Finally, (Kim et al., 2017a) frame the problem of temporal shift in data of a single domain (and the related problem of bootstrapping a new domain with imperfectly-matched synthetic data) as one of domain adaptation, applying adversarial training approaches.
",5 Related Work,[0],[0]
A number of researchers also investigated bootstrapping NLU systems using zero-shot learning.,5 Related Work,[0],[0]
"(Dauphin et al., 2014; Kumar et al., 2017) both investigated domain classification; most relevant to us is the work by (Bapna et al., 2017), who studied full semantic frame tagging using zero-shot learning, by projecting the tags into a shared embedding space, similar to work done by (Kim et al., 2015b).",5 Related Work,[0],[0]
We experimented with Bag of Experts (BoE) architectures for CRF and LSTM based slot tagging models.,6 Conclusion,[0],[0]
Our experimental results over a set of 10 domains show that BoE architectures are able to use the information from reusable expert models to perform significantly better than their nonexpert counterparts.,6 Conclusion,[0],[0]
"In particular, the LSTM-BoE model shows a statistically significant improvement of 1.92% over the LSTM model on average when training with 2000 instances.",6 Conclusion,[0],[0]
"When training with 500 instances, the improvement of LSTM-BoE model over LSTM is even higher at 4.63%.",6 Conclusion,[0],[0]
"For multiple domains, an LSTM-BoE model trained on only 500 instances is able to outperform a baseline CRF model trained over 4 times the data.",6 Conclusion,[0],[0]
"Thus, the BoE approach produces high performing models for slot tagging at much lower annotation costs.",6 Conclusion,[0],[0]
We would like to thank Ahmed El Kholy for his comments and feedback on an earlier version of this paper.,Acknowledgments,[0],[0]
"Also, thanks to Kyle Williams and Zhaleh Feizollahi for their help with code and data collection.",Acknowledgments,[0],[0]
"Slot tagging, the task of detecting entities in input user utterances, is a key component of natural language understanding systems for personal digital assistants.",abstractText,[0],[0]
"Since each new domain requires a different set of slots, the annotation costs for labeling data for training slot tagging models increases rapidly as the number of domains grow.",abstractText,[0],[0]
"To tackle this, we describe Bag of Experts (BoE) architectures for model reuse for both LSTM and CRF based models.",abstractText,[0],[0]
"Extensive experimentation over a dataset of 10 domains drawn from data relevant to our commercial personal digital assistant shows that our BoE models outperform the baseline models with a statistically significant average margin of 5.06% in absolute F1score when training with 2000 instances per domain, and achieve an even higher improvement of 12.16% when only 25% of the training data is used.",abstractText,[0],[0]
Bag of Experts Architectures for Model Reuse in Conversational Language Understanding,title,[0],[0]
The stochastic multi-armed bandit (MAB) problem is a prominent framework for capturing the explorationexploitation tradeoff in online decision making and experiment design.,1. Introduction,[0],[0]
"The MAB problem proceeds in discrete sequential rounds, where in each round, the player pulls one
1 Department of Mathematics and Statistics, Lancaster University, Lancaster, UK 2 Department of Industrial Engineering and Operations Research, Columbia University, New York, NY, USA 3 DeepMind, London, UK 4 Department of Computing Science, University of Alberta, Edmonton, AB, Canada.",1. Introduction,[0],[0]
Correspondence to:,1. Introduction,[0],[0]
"Ciara Pike-Burke <ciara.pikeburke@gmail.com>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
of the K possible arms.",1. Introduction,[0],[0]
"In the classic stochastic MAB setting, the player immediately observes stochastic feedback from the pulled arm in the form of a ‘reward’ which can be used to improve the decisions in subsequent rounds.",1. Introduction,[0],[0]
One of the main application areas of MABs is in online advertising.,1. Introduction,[0],[0]
"Here, the arms correspond to adverts, and the feedback would correspond to conversions, that is users buying a product after seeing an advert.",1. Introduction,[0],[0]
"However, in practice, these conversions may not necessarily happen immediately after the advert is shown, and it may not always be possible to assign the credit of a sale to a particular showing of an advert.",1. Introduction,[0],[0]
"A similar challenge is encountered in many other applications, e.g., in personalized treatment planning, where the effect of a treatment on a patient’s health may be delayed, and it may be difficult to determine which out of several past treatments caused the change in the patient’s health; or, in content design applications, where the effects of multiple changes in the website design on website traffic and footfall may be delayed and difficult to distinguish.
",1. Introduction,[0],[0]
"In this paper, we propose a new bandit model to handle online problems with such ‘delayed, aggregated and anonymous’ feedback.",1. Introduction,[0],[0]
"In our model, a player interacts with an environment ofK actions (or arms) in a sequential fashion.",1. Introduction,[0],[0]
At each time step the player selects an action which leads to a reward generated at random from the underlying reward distribution.,1. Introduction,[0],[0]
"At the same time, a nonnegative random integer-valued delay is also generated i.i.d.",1. Introduction,[0],[0]
from an underlying delay distribution.,1. Introduction,[0],[0]
Denoting this delay by τ ≥ 0,1. Introduction,[0],[0]
"and the index of the current round by t, the reward generated in round t will arrive at the end of the (t + τ)th round.",1. Introduction,[0],[0]
"At the end of each round, the player observes only the sum of all the rewards that arrive in that round.",1. Introduction,[0],[0]
"Crucially, the player does not know which of the past plays have contributed to this aggregated reward.",1. Introduction,[0],[0]
"We call this problem multi-armed bandits with delayed, aggregated anonymous feedback (MABDAAF).",1. Introduction,[0],[0]
"As in the standard MAB problem, in MABDAAF, the goal is to maximize the cumulative reward from T plays of the bandit, or equivalently to minimize the regret.",1. Introduction,[0],[0]
"The regret is the total difference between the reward of the optimal action and the actions taken.
",1. Introduction,[0],[0]
"If the delays are all zero, the MABDAAF problem reduces to the standard (stochastic) MAB problem, which has been studied considerably (e.g., Thompson, 1933; Lai & Robbins, 1985; Auer et al., 2002; Bubeck & Cesa-Bianchi,
2012).",1. Introduction,[0],[0]
"Compared to the MAB problem, the job of the player in our problem appears to be significantly more difficult since the player has to deal with (i) that some feedback from the previous pulls may be missing due to the delays, and (ii) that the feedback takes the form of the sum of an unknown number of rewards of unknown origin.
",1. Introduction,[0],[0]
"An easier problem is when the observations are delayed, but they are non-aggregated and non-anonymous: that is, the player has to only deal with challenge (i) and not (ii).",1. Introduction,[0],[0]
"Here, the player receives delayed feedback in the shape of action-reward pairs that inform the player of both the individual reward and which action generated it.",1. Introduction,[0],[0]
"This problem, which we shall call the (non-anonymous) delayed feedback bandit problem, has been studied by Joulani et al. (2013), and later followed up by Mandel et al. (2015) (for bounded delays).",1. Introduction,[0],[0]
"Remarkably, they show that compared to the standard (non-delayed) stochastic MAB setting, the regret will increase only additively by a factor that scales with the expected delay.",1. Introduction,[0],[0]
"For delay distributions with a finite expected delay, E[τ ], the worst case regret scales with O( √ KT log T + KE[τ ]).",1. Introduction,[0],[0]
"Hence, the price to pay for the delay in receiving the observations is negligible.",1. Introduction,[0],[0]
"QPM-D of Joulani et al. (2013) and SBD of Mandel et al. (2015) place received rewards into queues for each arm, taking one whenever a base bandit algorithm suggests playing the arm.",1. Introduction,[0],[0]
"Throughout, we take UCB1 (Auer et al., 2002) as the base algorithm in QPM-D. Joulani et al. (2013) also present a direct modification of the UCB1 algorithm.",1. Introduction,[0],[0]
All of these algorithms achieve the stated regret.,1. Introduction,[0],[0]
"None of them require any knowledge of the delay distributions, but they all rely heavily upon the non-anonymous nature of the observations.
",1. Introduction,[0],[0]
"While these results are encouraging, the assumption that the rewards are observed individually in a non-anonymous fashion is limiting for most practical applications with delays (e.g., recall the applications discussed earlier).",1. Introduction,[0],[0]
How big is the price to be paid for receiving only aggregated anonymous feedback?,1. Introduction,[0],[0]
Our main result is to prove that essentially there is no extra price to be paid provided that the value of the expected delay (or a bound on it) is available.,1. Introduction,[0],[0]
"In particular, this means that detailed knowledge of which action led to a particular delayed reward can be replaced by the much weaker requirement that the expected delay, or a bound on it, is known.",1. Introduction,[0],[0]
"Fig. 1 summarizes the relationship between the non-delayed, the delayed and the new problem
by showing the leading terms of the regret.",1. Introduction,[0],[0]
"In all cases, the dominant term is √ KT .",1. Introduction,[0],[0]
"Hence, asymptotically, the delayed, aggregated anonymous feedback problem is no more difficult than the standard multi-armed bandit problem.",1. Introduction,[0],[0]
We now consider what sort of algorithm will be able to achieve the aforementioned results for the MABDAAF problem.,1.1. Our Techniques and Results,[0],[0]
"Since the player only observes delayed, aggregated anonymous rewards, the first problem we face is how to even estimate the mean reward of individual actions.",1.1. Our Techniques and Results,[0],[0]
"Due to the delays and anonymity, it appears that to be able to estimate the mean reward of an action, the player wants to have played it consecutively for long stretches.",1.1. Our Techniques and Results,[0],[0]
"Indeed, if the stretches are sufficiently long compared to the mean delay, the observations received during the stretch will mostly consist of rewards of the action played in that stretch.",1.1. Our Techniques and Results,[0],[0]
"This naturally leads to considering algorithms that switch actions rarely and this is indeed the basis of our approach.
",1.1. Our Techniques and Results,[0],[0]
"Several popular MAB algorithms are based on choosing the action with the largest upper confidence bound (UCB) in each round (e.g., Auer et al., 2002; Cappé et al., 2013).",1.1. Our Techniques and Results,[0],[0]
UCB-style algorithms tend to switch arms frequently and will only play the optimal arm for long stretches if a unique optimal arm exists.,1.1. Our Techniques and Results,[0],[0]
"Therefore, for MABDAAF, we will consider alternative algorithms where arm-switching is more tightly controlled.",1.1. Our Techniques and Results,[0],[0]
The design of such algorithms goes back at least to the work of Agrawal et al. (1988) where the problem of bandits with switching costs was studied.,1.1. Our Techniques and Results,[0],[0]
The general idea of these rarely switching algorithms is to gradually eliminate suboptimal arms by playing arms in phases and comparing each arm’s upper confidence bound to the lower confidence bound of a leading arm at the end of each phase.,1.1. Our Techniques and Results,[0],[0]
"Generally, this sort of rarely switching algorithm switches arms onlyO(log T ) times.",1.1. Our Techniques and Results,[0],[0]
"We base our approach on one such algorithm, the so-called Improved UCB1 algorithm of Auer & Ortner (2010).
",1.1. Our Techniques and Results,[0],[0]
Using a rarely switching algorithm alone will not be sufficient for MABDAAF.,1.1. Our Techniques and Results,[0],[0]
"The remaining problem, and where the bulk of our contribution lies, is to construct appropri-
1The adjective “Improved” indicates that the algorithm improves upon the regret bounds achieved by UCB1.",1.1. Our Techniques and Results,[0],[0]
The improvement replaces log(T )/∆j,1.1. Our Techniques and Results,[0],[0]
by log(T∆2j )/∆j,1.1. Our Techniques and Results,[0],[0]
"in the regret bound.
ate confidence bounds and adjust the length of the periods of playing each arm to account for the delayed, aggregated anonymous feedback.",1.1. Our Techniques and Results,[0],[0]
"In particular, in the confidence bounds attention must be paid to fine details: it turns out that unless the variance of the observations is dealt with, there is a blow-up by a multiplicative factor of K. We avoid this by an improved analysis involving Freedman’s inequality (Freedman, 1975).",1.1. Our Techniques and Results,[0],[0]
"Further, to handle the dependencies between the number of plays of each arm and the past rewards, we combine Doob’s optimal skipping theorem (Doob, 1953) and Azuma-Hoeffding inequalities.",1.1. Our Techniques and Results,[0],[0]
Using a rarely switching algorithm for MABDAAF means we must also consider the dependencies between the elimination of arms in one phase and the corruption of observations in the next phase (ie. past plays can influence both whether an arm is still active and the corruption of its next plays).,1.1. Our Techniques and Results,[0],[0]
"We deal with this through careful algorithmic design.
",1.1. Our Techniques and Results,[0],[0]
"Using the above, we provide an algorithm that achieves worst case regret of O( √ KT logK + KE[τ ] log T ) using only knowledge of the expected delay, E[τ ].",1.1. Our Techniques and Results,[0],[0]
We then show that this regret can be improved by using a more careful martingale argument that exploits the fact that our algorithm is designed to remove most of the dependence between the corruption of future observations and elimination of arms.,1.1. Our Techniques and Results,[0],[0]
"Particularly, if the delays are bounded with known bound 0 ≤",1.1. Our Techniques and Results,[0],[0]
"d ≤ √ T/K, we can recover worst case regret ofO( √ KT logK+KE[τ ]), matching that of Joulani et al. (2013).",1.1. Our Techniques and Results,[0],[0]
"If the delays are unbounded but have known variance V(τ), we show that the problem independent regret can be reduced to O( √ KT logK +KE[τ ] +KV(τ)).",1.1. Our Techniques and Results,[0],[0]
We have already discussed several of the most relevant works to our own.,1.2. Related Work,[0],[0]
"However, there has also been other work looking at different flavors of the bandit problem with delayed (non-anonymous) feedback.",1.2. Related Work,[0],[0]
"For example, Neu et al. (2010) and Cesa-Bianchi et al. (2016) consider nonstochastic bandits with fixed constant delays; Dudik et al. (2011) look at stochastic contextual bandits with a constant delay and Desautels et al. (2014) consider Gaussian Process bandits with a bounded stochastic delay.",1.2. Related Work,[0],[0]
The general observation that delay causes an additive regret penalty in stochastic bandits and a multiplicative one in adversarial bandits is made in Joulani et al. (2013).,1.2. Related Work,[0],[0]
The empirical performance of K-armed stochastic bandit algorithms in delayed settings was investigated in Chapelle & Li (2011).,1.2. Related Work,[0],[0]
A further related problem is the ‘batched bandit’ problem studied by Perchet et al. (2016).,1.2. Related Work,[0],[0]
Here the player must fix a set of time points at which to collect feedback on all plays leading up to that point.,1.2. Related Work,[0],[0]
"Vernade et al. (2017) consider delayed Bernoulli bandits where some observations could also be censored (e.g., no conversion is ever actually observed if the delay exceeds some threshold) but require
complete knowledge of the delay distribution.",1.2. Related Work,[0],[0]
"Crucially, here and in all the aforementioned works, the feedback is always assumed to take the form of arm-reward pairs and knowledge of the assignment of rewards to arms underpins the suggested algorithms, rendering them unsuitable for MABDAAF.",1.2. Related Work,[0],[0]
"To the best of our knowledge, ours is the first work to develop algorithms to deal with delayed, aggregated anonymous feedback in the bandit setting.",1.2. Related Work,[0],[0]
The reminder of this paper is organized as follows: In the next section (Section 2) we give the formal problem definition.,1.3. Organization,[0],[0]
We present our algorithm in Section 3.,1.3. Organization,[0],[0]
"In Section 4, we discuss the performance of our algorithm under various delay assumptions; known expectation, bounded support with known bound and expectation, and known variance and expectation.",1.3. Organization,[0],[0]
This is followed by a numerical illustration of our results in Section 5.,1.3. Organization,[0],[0]
We conclude in Section 6.,1.3. Organization,[0],[0]
There are K > 1 actions or arms in the set A. Each action j ∈,2. Problem Definition,[0],[0]
A is associated with a reward distribution ζj and a delay distribution δj .,2. Problem Definition,[0],[0]
"The reward distribution is supported in [0, 1] and the delay distribution is supported on N .=",2. Problem Definition,[0],[0]
"{0, 1, . . .",2. Problem Definition,[0],[0]
}.,2. Problem Definition,[0],[0]
"We denote by µj the mean of ζj , µ∗ = µj∗ = maxj µj and define ∆j = µ∗ − µj to be the reward gap, that is the expected loss of reward each time action j is chosen instead of an optimal action.",2. Problem Definition,[0],[0]
"Let (Rl,j , τl,j)l∈N,j∈A be an infinite array of random variables defined on the probability space (Ω,Σ, P ) which are mutually independent.",2. Problem Definition,[0],[0]
"Further, Rl,j follows the distribution ζj and τl,j follows the distribution δj .",2. Problem Definition,[0],[0]
"The meaning of these random variables is that if the player plays action j at time l, a payoff of Rl,j will be added to the aggregated feedback that the player receives at the end of the (l + τl,j)th play.",2. Problem Definition,[0],[0]
"Formally, if Jl ∈ A denotes the action chosen by the player at time l = 1, 2, . . .",2. Problem Definition,[0],[0]
", then the observation received at the end of the tth play is
Xt = t∑ l=1",2. Problem Definition,[0],[0]
K∑ j=1,2. Problem Definition,[0],[0]
"Rl,j × I{l + τl,j = t, Jl = j}.
",2. Problem Definition,[0],[0]
"For the remainder, we will consider i.i.d. delays across arms.",2. Problem Definition,[0],[0]
"We also assume discrete delay distributions, although most results hold for continuous delays by redefining the event {τl,j = t− l} as {t− l− 1 < τl,j ≤ t− l} in Xt.",2. Problem Definition,[0],[0]
"In our analysis, we will sum over stochastic index sets.",2. Problem Definition,[0],[0]
For a stochastic index set I and random variables {Zn}n∈N we denote such sums as ∑ t∈I Zt .,2. Problem Definition,[0],[0]
= ∑ t∈N I{t ∈,2. Problem Definition,[0],[0]
"I} × Zt.
",2. Problem Definition,[0],[0]
Regret definition,2. Problem Definition,[0],[0]
"In most bandit problems, the regret is the cumulative loss due to not playing an optimal action.
",2. Problem Definition,[0],[0]
"In the case of delayed feedback, there are several possible ways to define the regret.",2. Problem Definition,[0],[0]
One option is to consider only the loss of the rewards received before horizon T (as in Vernade et al. (2017)).,2. Problem Definition,[0],[0]
"However, we will not use this definition.",2. Problem Definition,[0],[0]
"Instead, as in Joulani et al. (2013), we consider the loss of all generated rewards and define the (pseudo-)regret by
RT = T∑ t=1",2. Problem Definition,[0],[0]
(µ∗ − µJt) = Tµ∗,2. Problem Definition,[0],[0]
"− T∑ t=1 µJt .
",2. Problem Definition,[0],[0]
This includes the rewards received after the horizon T and does not penalize large delays as long as an optimal action is taken.,2. Problem Definition,[0],[0]
"This definition is natural since, in practice, the player should eventually receive all outstanding reward.
",2. Problem Definition,[0],[0]
"Lai & Robbins (1985) showed that the regret of any algorithm for the standard MAB problem must satisfy,
lim inf T→∞",2. Problem Definition,[0],[0]
"E[RT ] log(T )
",2. Problem Definition,[0],[0]
"≥ ∑
j:∆j>0
∆j",2. Problem Definition,[0],[0]
"KL(ζj , ζ∗) , (1)
where KL(ζj , ζ∗) is the KL-divergence between the reward distributions of arm j and an optimal arm.",2. Problem Definition,[0],[0]
Theorem 4 of Vernade et al. (2017) shows that the lower bound in (1) also holds for delayed feedback bandits with no censoring and their alternative definition of regret.,2. Problem Definition,[0],[0]
We therefore suspect (1) should hold for MABDAAF.,2. Problem Definition,[0],[0]
"However, due to the specific problem structure, finding a lower bound for MABDAAF is non-trivial and remains an open problem.
",2. Problem Definition,[0],[0]
"Assumptions on delay distribution For our algorithm for MABDAAF, we need some assumptions on the delay distribution.",2. Problem Definition,[0],[0]
"We assume that the expected delay, E[τ ], is bounded and known.",2. Problem Definition,[0],[0]
"This quantity is used in the algorithm.
",2. Problem Definition,[0],[0]
Assumption 1,2. Problem Definition,[0],[0]
"The expected delay E[τ ] is bounded and known to the algorithm.
",2. Problem Definition,[0],[0]
"We then show that under some further mild assumptions on the delay, we can obtain better algorithms with even more efficient regret guarantees.",2. Problem Definition,[0],[0]
"We consider two settings: delay distributions with bounded support, and bounded variance.
",2. Problem Definition,[0],[0]
Assumption 2 (Bounded support),2. Problem Definition,[0],[0]
There exists some constant d > 0 known to the algorithm,2. Problem Definition,[0],[0]
"such that the support of the delay distribution is bounded by d.
Assumption 3 (Bounded variance)",2. Problem Definition,[0],[0]
"The variance, V(τ), of the delay is bounded and known to the algorithm.
",2. Problem Definition,[0],[0]
In fact the known expected value and known variance assumption can be replaced by a ‘known upper bound’ on the expected value and variance respectively.,2. Problem Definition,[0],[0]
"However, for simplicity, in the remaining, we use E[τ ] and V(τ) directly.",2. Problem Definition,[0],[0]
The next sections provide algorithms and regret analysis for different combinations of the above assumptions.,2. Problem Definition,[0],[0]
Our algorithm is a phase-based elimination algorithm based on the Improved UCB algorithm by Auer & Ortner (2010).,3. Our Algorithm,[0],[0]
The general structure is as follows.,3. Our Algorithm,[0],[0]
"In each phase, each arm is played multiple times consecutively.",3. Our Algorithm,[0],[0]
"At the end of the phase, the observations received are used to update mean estimates, and any arm with an estimated mean below the best estimated mean by a gap larger than a ‘separation gap tolerance’ is eliminated.",3. Our Algorithm,[0],[0]
"This separation tolerance is decreased exponentially over phases, so that it is very small in later phases, eliminating all but the best arm(s) with high probability.",3. Our Algorithm,[0],[0]
"An alternative formulation of the algorithm is that at the end of a phase, any arm with an upper confidence bound lower than the best lower confidence bound is eliminated.",3. Our Algorithm,[0],[0]
"These confidence bounds are computed so that with high probability they are more (less) than the true mean, but within the separation gap tolerance.",3. Our Algorithm,[0],[0]
The phase lengths are then carefully chosen to ensure that the confidence bounds hold.,3. Our Algorithm,[0],[0]
"Here we assume that the horizon T is known, but we expect that this can be relaxed as in Auer & Ortner (2010).
",3. Our Algorithm,[0],[0]
"Algorithm overview Our algorithm, ODAAF, is given in Algorithm 1.",3. Our Algorithm,[0],[0]
"It operates in phases m = 1, 2, . .",3. Our Algorithm,[0],[0]
..,3. Our Algorithm,[0],[0]
"Define Am to be the set of active arms in phase m. The algorithm takes parameter nm which defines the number of samples of each active arm required by the end of phase m.
In Step 1 of phase m of the algorithm, each active arm j is played repeatedly for nm − nm−1 steps.",3. Our Algorithm,[0],[0]
We record all timesteps where arm j was played in the first m phases (excluding bridge periods) in the set Tj(m).,3. Our Algorithm,[0],[0]
The active arms are played in any arbitrary but fixed order.,3. Our Algorithm,[0],[0]
"In Step 2, the nm observations from timesteps in Tj(m) are averaged to obtain a new estimate X̄m,j of µj .",3. Our Algorithm,[0],[0]
"Arm j is eliminated if X̄m,j is further than ∆̃m from maxj′∈Am X̄m,j′ .
",3. Our Algorithm,[0],[0]
A further nuance in the algorithm structure is the ‘bridge period’ (see Figure 2).,3. Our Algorithm,[0],[0]
The algorithm picks an active arm j ∈ Am+1 to play in this bridge period for nm − nm−1 steps.,3. Our Algorithm,[0],[0]
"The observations received during the bridge period are discarded, and not used for computing confidence intervals.",3. Our Algorithm,[0],[0]
The significance of the bridge period is that it breaks the dependence between confidence intervals calculated in phasem and the delayed payoffs seeping into phasem+1.,3. Our Algorithm,[0],[0]
Without the bridge period this dependence would impair the validity of our confidence intervals.,3. Our Algorithm,[0],[0]
"However, we suspect that, in practice, it may be possible to remove it.
",3. Our Algorithm,[0],[0]
Choice of nm A key element of our algorithm design is the careful choice of nm.,3. Our Algorithm,[0],[0]
"Since nm determines the number of times each active (possibly suboptimal) arm is played, it clearly has an impact on the regret.",3. Our Algorithm,[0],[0]
"Furthermore, nm needs to be chosen so that the confidence bounds on the estimation error hold with given probability.",3. Our Algorithm,[0],[0]
"The main chal-
Algorithm 1 Optimism for Delayed, Aggregated Anonymous Feedback (ODAAF)",3. Our Algorithm,[0],[0]
"Input: A set of arms, A; a horizon, T ; choice of nm for
each phase m = 1, 2, . .",3. Our Algorithm,[0],[0]
..,3. Our Algorithm,[0],[0]
"Initialization: Set ∆̃1 = 1/2 (tolerance), the set of active
arms A1 = A. Let Ti(1) =",3. Our Algorithm,[0],[0]
"∅, i ∈",3. Our Algorithm,[0],[0]
"A, m = 1 (phase index), t = 1 (round index) while t ≤ T do
Step 1: Play arms.",3. Our Algorithm,[0],[0]
"for j ∈ Am do
Let Tj(m) =",3. Our Algorithm,[0],[0]
"Tj(m− 1) while |Tj(m)| ≤ nm and t ≤ T do
Play arm j, receive Xt.",3. Our Algorithm,[0],[0]
Add t to Tj(m).,3. Our Algorithm,[0],[0]
Increment t by 1. end while end for Step 2: Eliminate sub-optimal arms.,3. Our Algorithm,[0],[0]
"For every arm in j ∈ Am, compute X̄m,j as the average of observations at time steps t ∈ Tj(m).",3. Our Algorithm,[0],[0]
"That is,
X̄m,j = 1 |Tj(m)| ∑
t∈Tj(m)
",3. Our Algorithm,[0],[0]
"Xt .
",3. Our Algorithm,[0],[0]
"Construct Am+1 by eliminating actions j ∈ Am with
X̄m,j +",3. Our Algorithm,[0],[0]
"∆̃m < max j′∈Am X̄m,j′ .
",3. Our Algorithm,[0],[0]
Step 3:,3. Our Algorithm,[0],[0]
"Decrease Tolerance.
",3. Our Algorithm,[0],[0]
Set ∆̃m+1 = ∆̃m2 .,3. Our Algorithm,[0],[0]
Step 4: Bridge period.,3. Our Algorithm,[0],[0]
Pick an arm j ∈ Am+1 and play it νm = nm − nm−1 times while incrementing t ≤ T .,3. Our Algorithm,[0],[0]
Discard all observations from this period.,3. Our Algorithm,[0],[0]
Do not add t to Tj(m).,3. Our Algorithm,[0],[0]
"Increment phase index m.
end while
lenge is developing these confidence bounds from delayed, aggregated anonymous feedback.",3. Our Algorithm,[0],[0]
"Handling this form of feedback involves a credit assignment problem of deciding which samples can be used for a given arm’s mean estimation, since each sample is an aggregate of rewards from multiple previously played arms.",3. Our Algorithm,[0],[0]
This credit assignment problem would be hopeless in a passive learning setting without further information on how the samples were generated.,3. Our Algorithm,[0],[0]
"Our algorithm utilizes the power of active learning to design the phases in such a way that the feedback can be effectively ‘decensored’ without losing too many samples.
",3. Our Algorithm,[0],[0]
"A naive approach to defining the confidence bounds for delays bounded by a constant d ≥ 0 would be to observe that,∣∣∣∣ ∑
t∈Tj(m)\Tj(m−1)
",3. Our Algorithm,[0],[0]
Xt,3. Our Algorithm,[0],[0]
"− ∑
t∈Tj(m)\Tj(m−1)
Rt,j ∣∣∣∣ ≤ d,
since all rewards are in [0, 1].",3. Our Algorithm,[0],[0]
"Then we could use Hoeffding’s inequality to boundRt,Jt (see Appendix F) and select
nm = C1 log(T ∆̃
2 m)
∆̃2m + C2md ∆̃m
for some constants C1, C2.",3. Our Algorithm,[0],[0]
This corresponds to worst case regret of O( √ KT logK + K log(T )d).,3. Our Algorithm,[0],[0]
"For d E[τ ] and large T , this is significantly worse than that of Joulani et al. (2013).",3. Our Algorithm,[0],[0]
"In Section 4, we show that, surprisingly, it is possible to recover the same rate of regret as Joulani et al. (2013), but this requires a significantly more nuanced argument to get tighter confidence bounds and smaller nm.",3. Our Algorithm,[0],[0]
"In the next section, we describe this improved choice of nm for every phase m ∈ N and its implications on the regret, for each of the three cases mentioned previously: (i) Known and bounded expected delay (Assumption 1), (ii) Bounded delay with known bound and expected value (Assumptions 1 and 2), (iii) Delay with known and bounded variance and expectation (Assumptions 1 and 3).",3. Our Algorithm,[0],[0]
"In this section, we specify the choice of parameters nm and provide regret guarantees for Algorithm 1 for each of the three previously mentioned cases.",4. Regret Analysis,[0],[0]
"First, we consider the setting with the weakest assumption on delay distribution: we only assume that the expected delay, E[τ ], is bounded and known.",4.1. Known and Bounded Expected Delay,[0],[0]
No assumption on the support or variance of the delay distribution is made.,4.1. Known and Bounded Expected Delay,[0],[0]
"The regret analysis for this setting will not use the bridge period, so Step 4 of the algorithm could be omitted in this case.
",4.1. Known and Bounded Expected Delay,[0],[0]
"Choice of nm Here, we use Algorithm 1 with
nm = C1 log(T ∆̃
2 m) ∆̃2m + C2mE[τ ] ∆̃m (2)
for some large enough constants C1, C2.",4.1. Known and Bounded Expected Delay,[0],[0]
"The exact value of nm is given in Equation (14) in Appendix B.
Estimation of error bounds We bound the error between X̄m,j and µj by ∆̃m/2.",4.1. Known and Bounded Expected Delay,[0],[0]
"In order to do this we first bound the corruption of the observations received during timesteps Tj(m) due to delays.
",4.1. Known and Bounded Expected Delay,[0],[0]
Fix a phase m and arm j ∈ Am.,4.1. Known and Bounded Expected Delay,[0],[0]
Then the observations Xt in the period t ∈ Tj(m),4.1. Known and Bounded Expected Delay,[0],[0]
"\ Tj(m− 1) are composed of two types of rewards: a subset of rewards from plays of arm j in this period, and delayed rewards from some of the plays before this period.",4.1. Known and Bounded Expected Delay,[0],[0]
The expected value of observations from this period would be (nm − nm−1)µj but for the rewards entering and leaving this period due to delay.,4.1. Known and Bounded Expected Delay,[0],[0]
"Since the reward is bounded by 1, a simple observation is that expected discrepancy between the sum of observations in this period and the quantity (nm − nm−1)µj is bounded by the expected delay E[τ",4.1. Known and Bounded Expected Delay,[0],[0]
"],
E  ∑ t∈Tj(m)\Tj(m−1)",4.1. Known and Bounded Expected Delay,[0],[0]
(Xt − µj)  ≤ E[τ ].,4.1. Known and Bounded Expected Delay,[0],[0]
"(3) Summing this over phases ` = 1, . .",4.1. Known and Bounded Expected Delay,[0],[0]
".m gives a bound
|E[X̄m,j ]",4.1. Known and Bounded Expected Delay,[0],[0]
− µj | ≤ mE[τ ] |Tj(m)| = mE[τ ] nm .,4.1. Known and Bounded Expected Delay,[0],[0]
"(4)
Note that given the choice of nm in (2), the above is smaller than ∆̃m/2, when large enough constants are used.",4.1. Known and Bounded Expected Delay,[0],[0]
"Using this, along with concentration inequalities and the choice of nm from (2), we can obtain the following high probability bound.",4.1. Known and Bounded Expected Delay,[0],[0]
"A detailed proof is provided in Appendix B.1.
",4.1. Known and Bounded Expected Delay,[0],[0]
Lemma 1,4.1. Known and Bounded Expected Delay,[0],[0]
"Under Assumption 1 and the choice of nm given by (2), the estimates X̄m,j constructed by Algorithm 1 satisfy the following: For every fixed arm j and phase m, with probability 1− 3
T ∆̃2m , either j /∈",4.1. Known and Bounded Expected Delay,[0],[0]
"Am, or:
X̄m,j − µj ≤",4.1. Known and Bounded Expected Delay,[0],[0]
"∆̃m/2 .
",4.1. Known and Bounded Expected Delay,[0],[0]
"Regret bounds Using Lemma 1, we derive the following regret bounds in the current setting.
",4.1. Known and Bounded Expected Delay,[0],[0]
Theorem 2,4.1. Known and Bounded Expected Delay,[0],[0]
"Under Assumption 1, the expected regret of Algorithm 1 is upper bounded as
E[RT ] ≤ K∑ j=1 j 6=j∗ O ( log(T∆2j ) ∆j + log(1/∆j)E[τ ] ) .",4.1. Known and Bounded Expected Delay,[0],[0]
"(5)
Proof: Given Lemma 1, the proof of Theorem 2 closely follows the analysis of the Improved UCB algorithm of Auer & Ortner (2010).",4.1. Known and Bounded Expected Delay,[0],[0]
"Lemma 1 and the elimination condition in Algorithm 1 ensure that, with high probability, any suboptimal arm j will be eliminated by phase mj = log(1/∆j), thus incurring regret at most nmj∆j",4.1. Known and Bounded Expected Delay,[0],[0]
"We then substitute in nmj from (2), and sum over all suboptimal arms.",4.1. Known and Bounded Expected Delay,[0],[0]
A detailed proof is in Appendix B.2.,4.1. Known and Bounded Expected Delay,[0],[0]
"As in Auer & Ortner (2010), we avoid a union bound over all arms (which would result in an extra logK) by (i) reasoning about the regret of each arm individually, and (ii) bounding the regret resulting
from erroneously eliminating the optimal arm by carefully controlling the probability it is eliminated in each phase.
",4.1. Known and Bounded Expected Delay,[0],[0]
"Considering the worst-case values of ∆j (roughly √ K/T ), we obtain the following problem independent bound.
",4.1. Known and Bounded Expected Delay,[0],[0]
"Corollary 3 For any problem instance satisfying Assumption 1, the expected regret of Algorithm 1 satisfies
E[RT ] ≤",4.1. Known and Bounded Expected Delay,[0],[0]
O( √ KT log(K) +KE[τ ] log(T )).,4.1. Known and Bounded Expected Delay,[0],[0]
"If the delay is bounded by some constant d ≥ 0 and a single arm is played repeatedly for long enough, we can restrict the number of arms corrupting the observation",4.2. Delay with Bounded Support,[0],[0]
Xt at a given time t.,4.2. Delay with Bounded Support,[0],[0]
"In fact, if each arm j is played consecutively for more than d rounds, then at any time t ∈ Tj(m), the observation Xt will be composed of the rewards from at most two arms: the current arm j, and previous arm j′. Further, from the elimination condition, with high probability, arm j′ will have been eliminated if it is clearly suboptimal.",4.2. Delay with Bounded Support,[0],[0]
We can then recursively use the confidence bounds for arms j and j′ from the previous phase to bound |µj,4.2. Delay with Bounded Support,[0],[0]
− µj′ |.,4.2. Delay with Bounded Support,[0],[0]
"Below, we formalize this intuition to obtain a tighter bound on |X̄m,j − µj",4.2. Delay with Bounded Support,[0],[0]
|,4.2. Delay with Bounded Support,[0],[0]
"for every arm j and phase m, when each active arm is played a specified number of times per phase.
",4.2. Delay with Bounded Support,[0],[0]
"Choice of nm Here, we define,
nm = C1 log(T ∆̃
2 m) ∆̃2m + C2E[τ ]",4.2. Delay with Bounded Support,[0],[0]
"∆̃m (6)
+",4.2. Delay with Bounded Support,[0],[0]
"min { md, C3 log(T ∆̃ 2 m)
∆̃2m + C4mE[τ ] ∆̃m } for some large enough constants C1, C2, C3, C4 (see Appendix C, Equation (18) for the exact values).",4.2. Delay with Bounded Support,[0],[0]
"This choice of nm means that for large d, we essentially revert back to the choice of nm from (2) for the unbounded case, and we gain nothing by using the bound on the delay.",4.2. Delay with Bounded Support,[0],[0]
"However, if d is not large, the choice of nm in (6) is smaller than (2) since the second term now scales with E[τ ] rather than mE[τ ].
",4.2. Delay with Bounded Support,[0],[0]
"Estimation of error bounds In this setting, by the elimination condition and bounded delays, the expectation of each reward entering Tj(m) will be within ∆̃m−1 of µj , with high probability.",4.2. Delay with Bounded Support,[0],[0]
"Then, using knowledge of the upper bound of the support of τ , we can obtain a tighter bound and get an error bound similar to Lemma 1 with the smaller value of nm in (6).",4.2. Delay with Bounded Support,[0],[0]
We prove the following proposition.,4.2. Delay with Bounded Support,[0],[0]
"Since ∆̃m = 2−m, this is considerably tighter than (3).
",4.2. Delay with Bounded Support,[0],[0]
Proposition 4,4.2. Delay with Bounded Support,[0],[0]
"Assume ni − ni−1 ≥ d for phases i = 1, . . .",4.2. Delay with Bounded Support,[0],[0]
",m. Define Em−1 as the event that all arms j ∈",4.2. Delay with Bounded Support,[0],[0]
"Am satisfy error bounds |X̄m−1,j − µj | ≤ ∆̃m−1/2.",4.2. Delay with Bounded Support,[0],[0]
"Then, for
every arm j ∈",4.2. Delay with Bounded Support,[0],[0]
"Am,
E  ∑ t∈Tj(m)\Tj(m−1)",4.2. Delay with Bounded Support,[0],[0]
(Xt − µj) ∣∣∣∣Em−1  ≤ ∆̃m−1E[τ ].,4.2. Delay with Bounded Support,[0],[0]
Proof: (Sketch).,4.2. Delay with Bounded Support,[0],[0]
Consider a fixed arm j ∈ Am.,4.2. Delay with Bounded Support,[0],[0]
The expected value of the sum of observations Xt for t ∈ Tj(m),4.2. Delay with Bounded Support,[0],[0]
\ Tj(m− 1) would be (nm − nm−1)µj were it not for some rewards entering and leaving this period due to the delays.,4.2. Delay with Bounded Support,[0],[0]
"Because of the i.i.d. assumption on the delay, in expectation, the number of rewards leaving the period is roughly the same as the number of rewards entering this period, i.e., E[τ ].",4.2. Delay with Bounded Support,[0],[0]
(Conditioning on Em−1 does not effect this due to the bridge period).,4.2. Delay with Bounded Support,[0],[0]
"Since nm − nm−1 ≥ d, the reward coming into the period Tj(m)\Tj(m−1) can only be from the previous arm j′. All rewards leaving the period are from arm j. Therefore the expected difference between rewards entering and leaving the period is (µj − µj′)E[τ ].",4.2. Delay with Bounded Support,[0],[0]
"Then, if µj is close to µj′ , the total reward leaving the period is compensated by total reward entering.",4.2. Delay with Bounded Support,[0],[0]
"Due to the bridge period, even when j is the first arm played in phase m, j′ ∈ Am, so it was not eliminated in phase m − 1.",4.2. Delay with Bounded Support,[0],[0]
"By the elimination condition in Algorithm 1, if the error bounds |X̄m−1,j−µj | ≤ ∆̃m−1/2 are satisfied for all arms in Am, then |µj",4.2. Delay with Bounded Support,[0],[0]
− µj′ | ≤ ∆̃m−1.,4.2. Delay with Bounded Support,[0],[0]
"This gives the result.
",4.2. Delay with Bounded Support,[0],[0]
"Repeatedly using Proposition 4 we get,
m∑ i=1",4.2. Delay with Bounded Support,[0],[0]
E  ∑ t∈Tj(i)\Tj(i−1) (Xt − µj) ∣∣∣∣Ei−1  ≤ 2E[τ ] since ∑m i=1,4.2. Delay with Bounded Support,[0],[0]
"∆̃i−1 = ∑m−1 i=0 2
−i ≤ 2.",4.2. Delay with Bounded Support,[0],[0]
"Then, observe that P(ECi ) is small.",4.2. Delay with Bounded Support,[0],[0]
This bound is an improvement of a factor of m compared to (4).,4.2. Delay with Bounded Support,[0],[0]
"For the regret analysis, we derive a high probability version of the above result.",4.2. Delay with Bounded Support,[0],[0]
"Using this, and the choice of nm ≥ Ω ( log(T ∆̃2m)
",4.2. Delay with Bounded Support,[0],[0]
"∆̃2m + E[τ ] ∆̃m
) from (6), for
large enough constants, we derive the following lemma.",4.2. Delay with Bounded Support,[0],[0]
"A detailed proof is given in Appendix C.1.
",4.2. Delay with Bounded Support,[0],[0]
Lemma 5,4.2. Delay with Bounded Support,[0],[0]
"Under Assumptions 1 of known expected delay and 2 of bounded delays, and choice of nm given in (6), the estimates X̄m,j obtained by Algorithm 1 satisfy the following: For any arm j and phase m, with probability at least 1− 12
T ∆̃2m , either j /∈",4.2. Delay with Bounded Support,[0],[0]
"Am or
X̄m,j − µj ≤ ∆̃m/2.
",4.2. Delay with Bounded Support,[0],[0]
"Regret bounds We now give regret bounds for this case.
",4.2. Delay with Bounded Support,[0],[0]
Theorem 6,4.2. Delay with Bounded Support,[0],[0]
"Under Assumption 1 and bounded delay Assumption 2, the expected regret of Algorithm 1 satisfies
E[RT ]",4.2. Delay with Bounded Support,[0],[0]
"≤ K∑
j=1;j 6=j∗ O
( log(T∆2j )
∆j + E[τ",4.2. Delay with Bounded Support,[0],[0]
"]
+ min { d, log(T∆2j )
",4.2. Delay with Bounded Support,[0],[0]
"∆j + log(
1
∆j )",4.2. Delay with Bounded Support,[0],[0]
"E[τ ]
}) .
",4.2. Delay with Bounded Support,[0],[0]
Proof: (Sketch).,4.2. Delay with Bounded Support,[0],[0]
"Given Lemma 5, the proof is similar to that of Theorem 2.",4.2. Delay with Bounded Support,[0],[0]
"The full proof is in Appendix C.2.
",4.2. Delay with Bounded Support,[0],[0]
"Then, if d ≤ √
T logK K + E[τ ], we get the following
problem independent regret bound which matches that of Joulani et al. (2013).
",4.2. Delay with Bounded Support,[0],[0]
Corollary 7 For any problem instance satisfying Assumptions 1 and 2 with d ≤,4.2. Delay with Bounded Support,[0],[0]
"√ T logK K +E[τ ], the expected regret of Algorithm 1 satisfies
E[RT ] ≤",4.2. Delay with Bounded Support,[0],[0]
O( √ KT log(K) +KE[τ ]).,4.2. Delay with Bounded Support,[0],[0]
"If the delay is unbounded but well behaved in the sense that we know (a bound on) the variance, then we can obtain similar regret bounds to the bounded delay case.",4.3. Delay with Bounded Variance,[0],[0]
"Intuitively, delays from the previous phase will only corrupt observations in the current phase if their delays exceed the length of the bridge period.",4.3. Delay with Bounded Variance,[0],[0]
"We control this by using the bound on the variance to bound the tails of the delay distributions.
",4.3. Delay with Bounded Variance,[0],[0]
"Choice of nm Let V(τ) be the known variance (or bound on the variance) of the delay, as in Assumption 3.",4.3. Delay with Bounded Variance,[0],[0]
"Then, we use Algorithm 1 with the following value of nm,
nm = C1 log(T ∆̃2m)
∆̃2m + C2 E[τ ] + V(τ) ∆̃m
(7)
for some large enough constants C1, C2.",4.3. Delay with Bounded Variance,[0],[0]
"The exact value of nm is given in Appendix D, Equation (25).
",4.3. Delay with Bounded Variance,[0],[0]
"Regret bounds We get the following instance specific and problem independent regret bound in this case.
",4.3. Delay with Bounded Variance,[0],[0]
Theorem 8,4.3. Delay with Bounded Variance,[0],[0]
"Under Assumption 1 and Assumption 3 of known (bound on) the expectation and variance of the delay, and choice of nm from (7), the expected regret of Algorithm 1 can be upper bounded by,
E[RT ]",4.3. Delay with Bounded Variance,[0],[0]
"≤ K∑
j=1:µj 6=µ∗ O
( log(T∆2j )
∆j + E[τ ] + V(τ)
) .
",4.3. Delay with Bounded Variance,[0],[0]
Proof: (Sketch).,4.3. Delay with Bounded Variance,[0],[0]
See Appendix D.2.,4.3. Delay with Bounded Variance,[0],[0]
"We use Chebychev’s inequality to get a result similar to Lemma 5 and then use a similar argument to the bounded delay case.
",4.3. Delay with Bounded Variance,[0],[0]
"Corollary 9 For any problem instance satisfying Assumptions 1 and 3, the expected regret of Algorithm 1 satisfies
E[RT ] ≤",4.3. Delay with Bounded Variance,[0],[0]
"O( √ KT log(K) +KE[τ ] +KV(τ)).
",4.3. Delay with Bounded Variance,[0],[0]
"Remark If E[τ ] ≥ 1, then the delay penalty can be reduced to O(KE[τ ] +KV(τ)/E[τ ]) (see Appendix D).
",4.3. Delay with Bounded Variance,[0],[0]
"Thus, it is sufficient to know a bound on variance to obtain regret bounds similar to those in bounded delay case.",4.3. Delay with Bounded Variance,[0],[0]
Note that this approach is not possible just using knowledge of the expected delay since we cannot guarantee that the reward entering phase i is from an arm active in phase i− 1.,4.3. Delay with Bounded Variance,[0],[0]
"We compared the performance of our algorithm (under different assumptions) to QPM-D (Joulani et al., 2013) in various experimental settings.",5. Experimental Results,[0],[0]
"In these experiments, our aim was to investigate the effect of the delay on the performance of the algorithms.",5. Experimental Results,[0],[0]
"In order to focus on this, we used a simple setup of two arms with Bernoulli rewards and µ = (0.5, 0.6).",5. Experimental Results,[0],[0]
"In every experiment, we ran each algorithm to horizon T = 250000 and used UCB1 (Auer et al., 2002) as the base algorithm in QPM-D. The regret was averaged over 200 replications.",5. Experimental Results,[0],[0]
"For ease of reading, we define ODAAF to be our algorithm using only knowledge of the expected delay, with nm defined as in (2) and run without a bridge period, and ODAAF-B and ODAAF-V to be the versions of Algorithm 1 that use a bridge period and information on the bounded support and the finite variance of the delay to define nm as in (6) and (7) respectively.
",5. Experimental Results,[0],[0]
We tested the algorithms with different delay distributions.,5. Experimental Results,[0],[0]
"In the first case, we considered bounded delay distributions whereas in the second case, the delays were unbounded.",5. Experimental Results,[0],[0]
"In Fig. 3a, we plotted the ratios of the regret of ODAAF and ODAAF-B (with knowledge of d, the delay bound) to the regret of QPM-D. We see that in all cases the ratios converge to a constant.",5. Experimental Results,[0],[0]
"This shows that the regret of our algorithm is essentially of the same order as that of QPM-D. Our algorithm predetermines the number of times to play each active arm per phase (the randomness appears in whether an arm is active), so the jumps in the regret are it changing arm.",5. Experimental Results,[0],[0]
"This occurs at the same points in all replications.
",5. Experimental Results,[0],[0]
Fig.,5. Experimental Results,[0],[0]
3b shows a similar story for unbounded delays with mean E[τ ],5. Experimental Results,[0],[0]
= 50 (where N+ denotes the the half normal distribution).,5. Experimental Results,[0],[0]
The ratios of the regret of ODAAF and ODAAF-V (with knowledge of the delay variance) to the regret of QPM-D again converge to constants.,5. Experimental Results,[0],[0]
"Note that in this case, these constants, and the location of the jumps, vary with the delay distribution and V(τ).",5. Experimental Results,[0],[0]
"When the variance of the delay is small, it can be seen that using the variance information leads to improved performance.",5. Experimental Results,[0],[0]
"However, for exponential delays where V(τ) = E[τ ]2, the large variance causes nm to be large and so the suboptimal arm is played more, increasing the regret.",5. Experimental Results,[0],[0]
"In this case ODAAF-V had only just eliminated the suboptimal arm at time T .
",5. Experimental Results,[0],[0]
It can also be illustrated experimentally that the regret of our algorithms and that of QPM-D all increase linearly in E[τ ].,5. Experimental Results,[0],[0]
This is shown in Appendix E. We also provide an experimental comparison to Vernade et al. (2017) in Appendix E.,5. Experimental Results,[0],[0]
"We have studied an extension of the multi-armed bandit problem to bandits with delayed, aggregated anonymous feedback.",6. Conclusion,[0],[0]
"Here, a sum of observations is received after some stochastic delay and we do not learn which arms contributed to each observation.",6. Conclusion,[0],[0]
"In this more difficult setting, we have proven that, surprisingly, it is possible to develop an algorithm that performs comparably to those for the simpler delayed feedback bandits problem, where the assignment of rewards to plays is known.",6. Conclusion,[0],[0]
"Particularly, using only knowledge of the expected delay, our algorithm matches the worst case regret of Joulani et al. (2013) up to a logarithmic factor.",6. Conclusion,[0],[0]
"This logarithmic factors can be removed using an improved analysis and slightly more information about the delay; if the delay is bounded, we achieve the same worst case regret as Joulani et al. (2013), and for unbounded delays with known finite variance, we have an extra additive V(τ) term.",6. Conclusion,[0],[0]
We supported these claims experimentally.,6. Conclusion,[0],[0]
"Note that while our algorithm matches the order of regret of QPM-D, the constants are worse.",6. Conclusion,[0],[0]
"Hence, it is an open problem to find algorithms with better constants.",6. Conclusion,[0],[0]
CPB would like to thank the EPSRC funded EP/L015692/1 STOR-i centre for doctoral training and Sparx.,Acknowledgments,[0],[0]
We would like to thank the reviewers for their helpful comments.,Acknowledgments,[0],[0]
"We study a variant of the stochastic K-armed bandit problem, which we call “bandits with delayed, aggregated anonymous feedback”.",abstractText,[0],[0]
"In this problem, when the player pulls an arm, a reward is generated, however it is not immediately observed.",abstractText,[0],[0]
"Instead, at the end of each round the player observes only the sum of a number of previously generated rewards which happen to arrive in the given round.",abstractText,[0],[0]
"The rewards are stochastically delayed and due to the aggregated nature of the observations, the information of which arm led to a particular reward is lost.",abstractText,[0],[0]
"The question is what is the cost of the information loss due to this delayed, aggregated anonymous feedback?",abstractText,[0],[0]
"Previous works have studied bandits with stochastic, non-anonymous delays and found that the regret increases only by an additive factor relating to the expected delay.",abstractText,[0],[0]
"In this paper, we show that this additive regret increase can be maintained in the harder delayed, aggregated anonymous feedback setting when the expected delay (or a bound on it) is known.",abstractText,[0],[0]
"We provide an algorithm that matches the worst case regret of the non-anonymous problem exactly when the delays are bounded, and up to logarithmic factors or an additive variance term for unbounded delays.",abstractText,[0],[0]
"Bandits with Delayed, Aggregated Anonymous Feedback",title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3739–3748 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
3739",text,[0],[0]
Single-document summarization methods can be divided into two categories: extractive and abstractive.,1 Introduction,[0],[0]
"Extractive summarization systems form summaries by selecting and copying text snippets from the document, while abstractive methods aim to generate concise summaries with paraphrasing.",1 Introduction,[0],[0]
"This work is primarily concerned with extractive
∗Equal contribution.
summarization.",1 Introduction,[0],[0]
"Though abstractive summarization methods have made strides in recent years, extractive techniques are still very attractive as they are simpler, faster, and more reliably yield semantically and grammatically correct sentences.
",1 Introduction,[0],[0]
"Many extractive summarizers work by selecting sentences from the input document (Luhn, 1958; Mihalcea and Tarau, 2004; Wong et al., 2008; Kågebäck et al., 2014; Yin and Pei, 2015; Cao et al., 2015; Yasunaga et al., 2017).",1 Introduction,[0],[0]
"Furthermore, a growing trend is to frame this sentence selection process as a sequential binary labeling problem, where binary inclusion/exclusion labels are chosen for sentences one at a time, starting from the beginning of the document, and decisions about later sentences may be conditioned on decisions about earlier sentences.",1 Introduction,[0],[0]
"Recurrent neural networks may be trained with stochastic gradient ascent to maximize the likelihood of a set of ground-truth binary label sequences (Cheng and Lapata, 2016; Nallapati et al., 2017).",1 Introduction,[0],[0]
"However, this approach has two well-recognized disadvantages.",1 Introduction,[0],[0]
"First, it suffers from exposure bias, a form of mismatch between training and testing data distributions which can hurt performance (Ranzato et al., 2015; Bahdanau et al., 2017; Paulus et al., 2018).",1 Introduction,[0],[0]
"Second, extractive labels must be generated by a heuristic, as summarization datasets do not generally include ground-truth extractive labels; the ultimate performance of models trained on such labels is thus fundamentally limited by the quality of the heuristic.
",1 Introduction,[0],[0]
"An alternative to maximum likelihood training
is to use reinforcement learning to train the model to directly maximize a measure of summary quality, such as the ROUGE score between the generated summary and a ground-truth abstractive summary (Wu and Hu, 2018).",1 Introduction,[0],[0]
"This approach has become popular because it avoids exposure bias, and directly optimizes a measure of summary quality.",1 Introduction,[0],[0]
"However, it also has a number of downsides.",1 Introduction,[0],[0]
"For one, the search space is quite large: for a document of length T , there are 2T possible extractive summaries.",1 Introduction,[0],[0]
This makes the exploration problem faced by the reinforcement learning algorithm during training very difficult.,1 Introduction,[0],[0]
"Another issue is that due to the sequential nature of selection, the model is inherently biased in favor of selecting earlier sentences over later ones, a phenomenon which we demonstrate empirically in Section 7.",1 Introduction,[0],[0]
"The first issue can be resolved to a degree using either a cumbersome maximum likelihood-based pre-training step (using heuristically-generated labels) (Wu and Hu, 2018), or placing a hard upper limit on the number of sentences selected.",1 Introduction,[0],[0]
"The second issue is more problematic, as it is inherent to the sequential binary labeling setting.
",1 Introduction,[0],[0]
"In the current work, we introduce BANDITSUM, a novel method for training neural network-based extractive summarizers with reinforcement learning.",1 Introduction,[0],[0]
"This method does away with the sequential binary labeling setting, instead formulating extractive summarization as a contextual bandit.",1 Introduction,[0],[0]
"This move greatly reduces the size of the space that must be explored, removes the need to perform supervised pre-training, and prevents systematically privileging earlier sentences over later ones.",1 Introduction,[0],[0]
"Although the strong performance of Lead-3 indicates that good sentences often occur early in the source article, we show in Sections 6 and 7 that the contextual bandit setting greatly improves model performance when good sentences occur late without sacrificing performance when good sentences occur early.
",1 Introduction,[0],[0]
"Under this reformulation, BANDITSUM takes the document as input and outputs an affinity for each of the sentences therein.",1 Introduction,[0],[0]
"An affinity is a real number in [0, 1] which quantifies the model’s propensity for including a sentence in the summary.",1 Introduction,[0],[0]
These affinities are then used in a process of repeated sampling-without-replacement which does not privilege earlier sentences over later ones.,1 Introduction,[0],[0]
"BANDITSUM is free to process the document as a whole before yielding affinities, which permits
affinities for different sentences in the document to depend on one another in arbitrary ways.",1 Introduction,[0],[0]
"In our technical section, we show how to apply policy gradient reinforcement learning methods to this setting.
",1 Introduction,[0],[0]
"The contributions of our work are as follows:
• We propose a theoretically grounded method, based on the contextual bandit formalism, for training neural network-based extractive summarizers with reinforcement learning.",1 Introduction,[0],[0]
"Based on this training method, we propose the BANDITSUM system for extractive summarization.
",1 Introduction,[0],[0]
"• We perform experiments demonstrating that BANDITSUM obtains state-of-the-art performance on a number of datasets and requires significantly fewer update steps than competing approaches.
",1 Introduction,[0],[0]
"• We perform human evaluations showing that in the eyes of human judges, summaries created by BANDITSUM are less redundant and of higher overall quality than summaries created by competing approaches.
",1 Introduction,[0],[0]
"• We provide evidence, in the form of experiments in which models are trained on subsets of the data, that the improved performance of BANDITSUM over competitors stems in part from better handling of summary-worthy sentences that come near the end of the document (see Section 7).",1 Introduction,[0],[0]
Extractive summarization has been widely studied in the past.,2 Related Work,[0],[0]
"Recently, neural network-based methods have been gaining popularity over classical methods (Luhn, 1958; Gong and Liu, 2001; Conroy and O’leary, 2001; Mihalcea and Tarau, 2004; Wong et al., 2008), as they have demonstrated stronger performance on large corpora.",2 Related Work,[0],[0]
Central to the neural network-based models is the encoderdecoder structure.,2 Related Work,[0],[0]
"These models typically use either a convolution neural network (Kalchbrenner et al., 2014; Kim, 2014; Yin and Pei, 2015; Cao et al., 2015), a recurrent neural network (Chung et al., 2014; Cheng and Lapata, 2016; Nallapati et al., 2017), or a combination of the two (Narayan et al., 2018; Wu and Hu, 2018) to create sentence and document representations, using word embeddings (Mikolov et al., 2013; Pennington et al.,
2014) to represent words at the input level.",2 Related Work,[0],[0]
"These vectors are then fed into a decoder network to generate the output summary.
",2 Related Work,[0],[0]
"The use of reinforcement learning (RL) in extractive summarization was first explored by Ryang and Abekawa (2012), who proposed to use the TD(λ) algorithm to learn a value function for sentence selection.",2 Related Work,[0],[0]
Rioux et al. (2014) improved this framework by replacing the learning agent with another TD(λ) algorithm.,2 Related Work,[0],[0]
"However, the performance of their methods was limited by the use of shallow function approximators, which required performing a fresh round of reinforcement learning for every new document to be summarized.",2 Related Work,[0],[0]
"The more recent work of Paulus et al. (2018) and Wu and Hu (2018) use reinforcement learning in a sequential labeling setting to train abstractive and extractive summarizers, respectively, while Chen and Bansal (2018) combines both approaches, applying abstractive summarization to a set of sentences extracted by a pointer network (Vinyals et al., 2015) trained via REINFORCE.",2 Related Work,[0],[0]
"However, pre-training with a maximum likelihood objective is required in all of these models.
",2 Related Work,[0],[0]
The two works most similar to ours are Yao et al. (2018) and Narayan et al. (2018).,2 Related Work,[0],[0]
"Yao et al. (2018) recently proposed an extractive summarization approach based on deep Q learning, a type of reinforcement learning.",2 Related Work,[0],[0]
"However, their approach is extremely computationally intensive (a minimum of 10 days before convergence), and was unable to achieve ROUGE scores better than the best maximum likelihood-based approach.",2 Related Work,[0],[0]
"Narayan et al. (2018) uses a cascade of filters in order to arrive at a set of candidate extractive summaries, which we can regard as an approximation of the true action space.",2 Related Work,[0],[0]
They then use an approximation of a policy gradient method to train their neural network to select summaries from this approximated action space.,2 Related Work,[0],[0]
"In contrast, BANDITSUM samples directly from the true action space, and uses exact policy gradient parameter updates.",2 Related Work,[0],[0]
Our approach formulates extractive summarization as a contextual bandit which we then train an agent to solve using policy gradient reinforcement learning.,3 Extractive Summarization as a Contextual Bandit,[0],[0]
"A bandit is a decision-making formalization in which an agent repeatedly chooses one of several actions, and receives a reward based on
this choice.",3 Extractive Summarization as a Contextual Bandit,[0],[0]
"The agent’s goal is to quickly learn which action yields the most favorable distribution over rewards, and choose that action as often as possible.",3 Extractive Summarization as a Contextual Bandit,[0],[0]
"In a contextual bandit, at each trial, a context is sampled and shown to the agent, after which the agent selects an action and receives a reward; importantly, the rewards yielded by the actions may depend on the sampled context.",3 Extractive Summarization as a Contextual Bandit,[0],[0]
The agent must quickly learn which actions are favorable in which contexts.,3 Extractive Summarization as a Contextual Bandit,[0],[0]
"Contextual bandits are a subset of Markov Decision Processes in which every episode has length one.
",3 Extractive Summarization as a Contextual Bandit,[0],[0]
Extractive summarization may be regarded as a contextual bandit as follows.,3 Extractive Summarization as a Contextual Bandit,[0],[0]
"Each document is a context, and each ordered subset of a document’s sentences is a different action.",3 Extractive Summarization as a Contextual Bandit,[0],[0]
"Formally, assume that each context is a document d consisting of sentences s = (s1, . . .",3 Extractive Summarization as a Contextual Bandit,[0],[0]
", sNd), and that each action is a length-M sequence of unique sentence indices",3 Extractive Summarization as a Contextual Bandit,[0],[0]
"i = (i1, . . .",3 Extractive Summarization as a Contextual Bandit,[0],[0]
", iM ) where it ∈ {1, . . .",3 Extractive Summarization as a Contextual Bandit,[0],[0]
", Nd}, it 6=",3 Extractive Summarization as a Contextual Bandit,[0],[0]
"it′ for t 6= t′, and M is an integer hyper-parameter.",3 Extractive Summarization as a Contextual Bandit,[0],[0]
"For each i, the extractive summary induced by i is given by (si1 , . . .",3 Extractive Summarization as a Contextual Bandit,[0],[0]
", siM ).",3 Extractive Summarization as a Contextual Bandit,[0],[0]
"An action i taken in context d is given a reward R(i, a), where a is the gold-standard abstractive summary that is paired with document d, andR is a scalar reward function quantifying the degree of match between a and the summary induced by i.
A policy for extractive summarization is a neural network pθ(·|d), parameterized by a vector θ, which, for each input document d, yields a probability distribution over index sequences.",3 Extractive Summarization as a Contextual Bandit,[0],[0]
Our goal is to find parameters θ which cause pθ(·|d) to assign high probability to index sequences that induce extractive summaries that a human reader would judge to be of high-quality.,3 Extractive Summarization as a Contextual Bandit,[0],[0]
"We achieve this by maximizing the following objective function with respect to parameters θ:
J(θ) =",3 Extractive Summarization as a Contextual Bandit,[0],[0]
"E [R(i, a)] (1)
where the expectation is taken over documents d paired with gold-standard abstractive summaries a, as well as over index sequences i generated according to pθ(·|d).",3 Extractive Summarization as a Contextual Bandit,[0],[0]
"Ideally, we would like to maximize (1) using gradient ascent.",3.1 Policy Gradient Reinforcement Learning,[0],[0]
"However, the required gradient cannot be obtained using usual techniques (e.g. simple backpropagation) because i must be discretely sampled in order to compute R(i, a).
",3.1 Policy Gradient Reinforcement Learning,[0],[0]
"Fortunately, we can use the likelihood ratio gradient estimator from reinforcement learning and stochastic optimization (Williams, 1992; Sutton et al., 2000), which tells us that the gradient of this function can be computed as:
∇θJ(θ) = E",3.1 Policy Gradient Reinforcement Learning,[0],[0]
"[∇θ log pθ(i|d)R(i, a)]",3.1 Policy Gradient Reinforcement Learning,[0],[0]
"(2)
where the expectation is taken over the same variables as (1).
",3.1 Policy Gradient Reinforcement Learning,[0],[0]
"Since we typically do not know the exact document distribution and thus cannot evaluate the expected value in (2), we instead estimate it by sampling.",3.1 Policy Gradient Reinforcement Learning,[0],[0]
"We found that we obtained the best performance when, for each update, we first sample one document/summary pair (d, a), then sample B index sequences i1, . . .",3.1 Policy Gradient Reinforcement Learning,[0],[0]
", iB from pθ(·|d), and finally take the empirical average:
∇θJ(θ)",3.1 Policy Gradient Reinforcement Learning,[0],[0]
"≈ 1
B B∑ b=1",3.1 Policy Gradient Reinforcement Learning,[0],[0]
"∇θ log pθ(ib|d)R(ib, a) (3)
",3.1 Policy Gradient Reinforcement Learning,[0],[0]
"This overall learning algorithm can be regarded as an instance of the REINFORCE policy gradient algorithm (Williams, 1992).",3.1 Policy Gradient Reinforcement Learning,[0],[0]
There are many possible choices for the structure of pθ(·|d); we opt for one that avoids privileging early sentences over later ones.,3.2 Structure of pθ(·|d),[0],[0]
"We first decompose pθ(·|d) into two parts: πθ, a deterministic function which contains all the network’s parameters, and µ, a probability distribution parameterized by the output of πθ.",3.2 Structure of pθ(·|d),[0],[0]
"Concretely:
pθ(·|d) = µ(·|πθ(d)) (4)
",3.2 Structure of pθ(·|d),[0],[0]
"Given an input document d, πθ outputs a realvalued vector of sentence affinities whose length is equal to the number of sentences in the document (i.e. πθ(d) ∈ RNd) and whose elements fall in the range [0, 1].",3.2 Structure of pθ(·|d),[0],[0]
"The t-th entry π(d)t may be roughly interpreted as the network’s propensity to include sentence st in the summary of d.
",3.2 Structure of pθ(·|d),[0],[0]
"Given sentence affinities πθ(d), µ implements a process of repeated sampling-withoutreplacement.",3.2 Structure of pθ(·|d),[0],[0]
"This proceeds by repeatedly normalizing the set of affinities corresponding to sentences that have not yet been selected, thereby obtaining a probability distribution over unselected sentences, and sampling from that distribution to obtain a new sentence to include.",3.2 Structure of pθ(·|d),[0],[0]
"This normalizeand-sample step is repeated M times, yielding M unique sentences to include in the summary.
",3.2 Structure of pθ(·|d),[0],[0]
"At each step of sampling-without-replacement, we also include a small probability of sampling uniformly from all remaining sentences.",3.2 Structure of pθ(·|d),[0],[0]
"This is used to achieve adequate exploration during training, and is similar to the -greedy technique from reinforcement learning.
",3.2 Structure of pθ(·|d),[0],[0]
"Under this sampling scheme, we have the following expression for pθ(i|d):
M∏ j=1
(
Nd − j + 1 + (1− )π(d)ij z(d)− ∑j−1",3.2 Structure of pθ(·|d),[0],[0]
"k=1 π(d)ik
) (5)
where z(d) = ∑
t π(d)t.",3.2 Structure of pθ(·|d),[0],[0]
"For index sequences that have length different from M , or that contain duplicate indices, we have pθ(i|d) = 0.",3.2 Structure of pθ(·|d),[0],[0]
"Using this expression, it is straightforward to use automatic differentiation software to compute ∇θ log pθ(i|d), which is required for the gradient estimate in (3).",3.2 Structure of pθ(·|d),[0],[0]
"Our sample-based gradient estimate can have high variance, which can slow the learning.",3.3 Baseline for Variance Reduction,[0],[0]
"One potential cause of this high variance can be seen by inspecting (3), and noting that it basically acts to change the probability of a sampled index sequence to an extent determined by the reward R(i, a).",3.3 Baseline for Variance Reduction,[0],[0]
"However, since ROUGE scores are always positive, the probability of every sampled index sequence is increased, whereas intuitively, we would prefer to decrease the probability of sequences that receive a comparatively low reward, even if it is positive.",3.3 Baseline for Variance Reduction,[0],[0]
"This can be remedied by the introduction of a so-called baseline which is subtracted from all rewards.
",3.3 Baseline for Variance Reduction,[0],[0]
"Using a baseline r, our sample-based estimate of∇θJ(θ) becomes:
1
B B∑ i=1",3.3 Baseline for Variance Reduction,[0],[0]
"∇θ log pθ(ib|d)(R(ib, a)− r) (6)
",3.3 Baseline for Variance Reduction,[0],[0]
"It can be shown that the introduction of r does not bias the gradient estimator and can significantly reduce its variance if chosen appropriately (Sutton et al., 2000).
",3.3 Baseline for Variance Reduction,[0],[0]
"There are several possibilities for the baseline, including the long-term average reward and the average reward across different samples for one document-summary pair.",3.3 Baseline for Variance Reduction,[0],[0]
"We choose an approach known as self-critical reinforcement learning, in which the test-time performance of the current model is used as the baseline (Ranzato et al., 2015;
Rennie et al., 2017; Paulus et al., 2018).",3.3 Baseline for Variance Reduction,[0],[0]
"More concretely, after sampling the document-summary pair (d, a), we greedily generate an index sequence using the current parameters θ:
igreedy =",3.3 Baseline for Variance Reduction,[0],[0]
argmax,3.3 Baseline for Variance Reduction,[0],[0]
"i
pθ(i|d) (7)
and calculate the baseline for the current update as r = R(igreedy, a).",3.3 Baseline for Variance Reduction,[0],[0]
This baseline has the intuitively satisfying property of only increasing the probability of a sampled label sequence when the summary it induces is better than what would be obtained by greedy decoding.,3.3 Baseline for Variance Reduction,[0],[0]
"A final consideration is a concrete choice for the reward function R(i, a).",3.4 Reward Function,[0],[0]
"Throughout this work we use:
R(i, a) = 1
3 (ROUGE-1f (i, a) +
ROUGE-2f (i, a) +",3.4 Reward Function,[0],[0]
"ROUGE-Lf (i, a)).",3.4 Reward Function,[0],[0]
"(8)
The above reward function optimizes the average of all the ROUGE variants (Lin, 2004) while balancing precision and recall.",3.4 Reward Function,[0],[0]
"In this section, we discuss the concrete instantiations of the neural network πθ that we use in our experiments.",4 Model,[0],[0]
"We break πθ up into two components: a document encoder fθ1, which outputs a sequence of sentence feature vectors (h1, . . .",4 Model,[0],[0]
", hNd) and a decoder gθ2 which yields sentence affinities:
h1, . . .",4 Model,[0],[0]
", hNd = fθ1(d) (9)
πθ(d) = gθ2(h1, . . .",4 Model,[0],[0]
", hNd) (10)
Encoder.",4 Model,[0],[0]
"Features for each sentence in isolation are first obtained by applying a word-level Bidirectional Recurrent Neural Network (BiRNN) to the embeddings for the words in the sentence, and averaging the hidden states over words.",4 Model,[0],[0]
A separate sentence-level BiRNN is then used to obtain a representations hi for each sentence in the context of the document.,4 Model,[0],[0]
Decoder.,4 Model,[0],[0]
"A multi-layer perceptron is used to map from the representation ht of each sentence through a final sigmoid unit to yield sentence affinities πθ(d).
",4 Model,[0],[0]
"The use of a bidirectional recurrent network in the encoder is crucial, as it allows the network to
process the document as a whole, yielding representations for each sentence that take all other sentences into account.",4 Model,[0],[0]
"This procedure is necessary to deal with some aspects of summary quality such as redundancy (avoiding the inclusion of multiple sentences with similar meaning), which requires the affinities for different sentences to depend on one another.",4 Model,[0],[0]
"For example, to avoid redundancy, if the affinity for some sentence is high, then sentences which express similar meaning should have low affinities.",4 Model,[0],[0]
"In this section, we discuss the setup of our experiments.",5 Experiments,[0],[0]
We first discuss the corpora that we used and our evaluation methodology.,5 Experiments,[0],[0]
"We then discuss the baseline methods against which we compared, and conclude with a detailed overview of the settings of the model parameters.",5 Experiments,[0],[0]
"Three datasets are used for our experiments: the CNN, the Daily Mail, and combined CNN/Daily Mail (Hermann et al., 2015; Nallapati et al., 2016).",5.1 Corpora,[0],[0]
"We use the standard split of Hermann et al. (2015) for training, validating, and testing and the same setting without anonymization on the three corpus as See et al. (2017).",5.1 Corpora,[0],[0]
"The Daily Mail corpus has 196,557 training documents, 12,147 validation documents and 10,397 test documents; while the CNN corpus has 90,266/1,220/1,093 documents, respectively.",5.1 Corpora,[0],[0]
"The models are evaluated based on ROUGE (Lin, 2004).",5.2 Evaluation,[0],[0]
We obtain our ROUGE scores using the standard pyrouge package1 for the test set evaluation and a faster python implementation of the ROUGE metric2 for training and evaluating on the validation set.,5.2 Evaluation,[0],[0]
"We report the F1 scores of ROUGE1, ROUGE-2, and ROUGE-L, which compute the uniform, bigram, and longest common subsequence overlapping with the reference summaries.",5.2 Evaluation,[0],[0]
"We compare BANDITSUM with other extractive methods including: the Lead-3 model, SummaRuNNer (Nallapati et al., 2017), Refresh
1https://pypi.python.org/pypi/pyrouge/ 0.1.3
2We use the modified version based on https:// github.com/pltrdy/rouge
(Narayan et al., 2018), RNES (Wu and Hu, 2018), DQN (Yao et al., 2018), and NN-SE (Cheng and Lapata, 2016).",5.3 Baselines,[0],[0]
The Lead-3 model simply produces the leading three sentences of the document as the summary.,5.3 Baselines,[0],[0]
"We use 100-dimensional Glove embeddings (Pennington et al., 2014) as our embedding initialization.",5.4 Model Settings,[0],[0]
"We do not limit the sentence length, nor the maximum number of sentences per document.",5.4 Model Settings,[0],[0]
"We use one-layer BiLSTM for word-level RNN, and two-layers BiLSTM for sentence-level RNN.",5.4 Model Settings,[0],[0]
The hidden state dimension is 200 for each direction on all LSTMs.,5.4 Model Settings,[0],[0]
"For the decoder, we use a feedforward network with one hidden layer of dimension 100.
",5.4 Model Settings,[0],[0]
"During training, we use Adam (Kingma and Ba, 2015) as the optimizer with the learning rate of 5e−5, beta parameters (0, 0.999), and a weight decay of 1e−6, to maximize the objective function defined in equation (1).",5.4 Model Settings,[0],[0]
We employ gradient clipping of 1 to regularize our model.,5.4 Model Settings,[0],[0]
"At each iteration, we sample B = 20 times to estimate the gradient defined in equation 3.",5.4 Model Settings,[0],[0]
"For our system, the reported performance is obtained within two epochs of training 3.
",5.4 Model Settings,[0],[0]
"At the test time, we pick sentences sorted by the predicted probabilities until the length limit is reached.",5.4 Model Settings,[0],[0]
The full-length ROUGE F1 score is used as the evaluation metric.,5.4 Model Settings,[0],[0]
"For M , the number of sentences selected per summary, we use a value of 3, based on our validation results as well as on the settings described in Nallapati et al. (2017).",5.4 Model Settings,[0],[0]
"In this section, we present quantitative results from the ROUGE evaluation and qualitative results based on human evaluation.",6 Experiment Results,[0],[0]
"In addition, we demonstrate the stability of our RL model by comparing the validation curve of BANDITSUM with SummaRuNNer (Nallapati et al., 2017) trained with a maximum likelihood objective.",6 Experiment Results,[0],[0]
"We present the results of comparing BANDITSUM to several baseline algorithms4 on the CNN/Daily
3Our code can be found at https://github.com/ yuedongP/summarization_RL
4 Due to different pre-processing methods and different numbers of selected sentences, several papers report different Lead scores (Narayan et al., 2018; See et al., 2017).",6.1 Rouge Evaluation,[0],[0]
"We use
Mail corpus in Tables 1 and 2.",6.1 Rouge Evaluation,[0],[0]
"Compared to other extractive summarization systems, BANDITSUM achieves performance that is significantly better than two RL-based approaches, Refresh (Narayan et al., 2018) and DQN (Yao et al., 2018), as well as SummaRuNNer, the state-of-the-art maximum liklihood-based extractive summarizer (Nallapati et al., 2017).",6.1 Rouge Evaluation,[0],[0]
"BANDITSUM performs a little better than RNES (Wu and Hu, 2018) in terms of ROUGE-1 and slightly worse in terms of ROUGE2.",6.1 Rouge Evaluation,[0],[0]
"However, RNES requires pre-training with the maximum likelihood objective on heuristicallygenerated extractive labels; in contrast, BANDITSUM is very light-weight and converges significantly faster.",6.1 Rouge Evaluation,[0],[0]
"We discuss the advantage of framing the extractive summarization based on the contextual bandit (BANDITSUM) over the sequential binary labeling setting (RNES) in the discussion Section 7.
",6.1 Rouge Evaluation,[0],[0]
"We also noticed that different choices for the policy gradient baseline (see Section 3.3) in BANDITSUM affect learning speed, but do not significantly affect asymptotic performance.",6.1 Rouge Evaluation,[0],[0]
"Models trained with an average reward baseline learned most quickly, while models trained with three different baselines (greedy, average reward in a
the test set provided by Narayan et al. (2018).",6.1 Rouge Evaluation,[0],[0]
"Since their Lead score is a combination of Lead-3 for CNN and Lead4 for Daily Mail, we recompute the Lead-3 scores for both CNN and Daily Mail with the preprocessing steps used in See et al. (2017).",6.1 Rouge Evaluation,[0],[0]
"Additionally, our results are not directly comparable to results based on the anonymized dataset used by Nallapati et al. (2017).
batch, average global reward) all perform roughly the same after training for one epoch.",6.1 Rouge Evaluation,[0],[0]
Models trained without a baseline were found to underperform other baseline choices by about 2 points of ROUGE score on average.,6.1 Rouge Evaluation,[0],[0]
We also conduct a qualitative evaluation to understand the effects of the improvements introduced in BANDITSUM on human judgments of the generated summaries.,6.2 Human Evaluation,[0],[0]
"To assess the effect of training with RL rather than maximum likelihood, in the first set of human evaluations we compare BANDITSUM with the state-of-the-art maximum likelihood-based model SummaRuNNer.",6.2 Human Evaluation,[0],[0]
"To evaluate the importance of using an exact, rather than approximate, policy gradient to optimize ROUGE scores, we perform another human evaluation comparing BANDITSUM and Refresh, an RL-based method that uses the an approximation of the policy gradient.
",6.2 Human Evaluation,[0],[0]
We follow a human evaluation protocol similar to the one used in Wu and Hu (2018).,6.2 Human Evaluation,[0],[0]
"Given a set of N documents, we ask K volunteers to evaluate the summaries extracted by both systems.",6.2 Human Evaluation,[0],[0]
"For each document, a reference summary, and a pair of randomly ordered extractive summaries (one generated by each of the two models) is presented to the volunteers.",6.2 Human Evaluation,[0],[0]
"They are asked to compare and rank the extracted summaries along three dimensions: overall, coverage, and non-redundancy.
",6.2 Human Evaluation,[0],[0]
"To compare with SummaRuNNer, we randomly sample 57 documents from the test set of Daily-
Mail and ask 5 volunteers to evaluate the extracted summaries.",6.2 Human Evaluation,[0],[0]
"While comparing with Refresh, we use the 20 documents (10 CNN and 10 DailyMail) provided by Narayan et al. (2018) to 4 volunteers.",6.2 Human Evaluation,[0],[0]
Tables 3 and 4 show the results of human evaluation in these two settings.,6.2 Human Evaluation,[0],[0]
BANDITSUM is shown to be better than Refresh and SummaRuNNer in terms of overall quality and nonredundancy.,6.2 Human Evaluation,[0],[0]
"These results indicate that the use of the true policy gradient, rather than the approximation used by Refresh, improves overall quality.",6.2 Human Evaluation,[0],[0]
"It is interesting to observe that, even though BANDITSUM does not have an explicit redundancy avoidance mechanism, it actually outperforms the other systems on non-redundancy.",6.2 Human Evaluation,[0],[0]
Reinforcement learning methods are known for sometimes being unstable during training.,6.3 Learning Curve,[0],[0]
"However, this seems to be less of a problem for BANDITSUM, perhaps because it is formulated as a contextual bandit rather than a sequential labeling problem.",6.3 Learning Curve,[0],[0]
"We show this by comparing the validation curves generated by BANDITSUM and the state-of-the-art maximum likelihood-based model – SummaRuNNer (Nallapati et al., 2017) (Figure 1).
",6.3 Learning Curve,[0],[0]
"From Figure 1, we observe that BANDITSUM converges significantly more quickly to good results than SummaRuNNer.",6.3 Learning Curve,[0],[0]
"Moreover, there is less variance in the performance of BANDITSUM.
",6.3 Learning Curve,[0],[0]
One possible reason is that extractive summarization does not have well-defined supervised labels.,6.3 Learning Curve,[0],[0]
There exists a mismatch between the provided labels and human-generated abstractive summaries.,6.3 Learning Curve,[0],[0]
"Hence, the gradient, computed from the maximum likelihood loss function, is not optimizing the evaluation metric of interest.",6.3 Learning Curve,[0],[0]
"Another important message is that both models are still far from the estimated upper bound5, which shows that there is still significant room for improvement.",6.3 Learning Curve,[0],[0]
"On CNN/Daily mail dataset, our model’s timeper-epoch is about 25.5 hours on a TITAN Xp.",6.4 Run Time,[0],[0]
"We trained the model for 3 epochs, which took about 76 hours in total.",6.4 Run Time,[0],[0]
"For comparison, DQN took about 10 days to train on a GTX 1080 (Yao et al., 2018).",6.4 Run Time,[0],[0]
"Refresh took about 12 hours on a single GPU to train (Narayan et al., 2018).",6.4 Run Time,[0],[0]
Note that this figure does not take into account the significant time required by Refresh for pre-computing ROUGE scores.,6.4 Run Time,[0],[0]
"We conjecture that the contextual bandit (CB) setting is a more suitable framework for modeling extractive summarization than the sequential binary labeling setting, especially in the cases when good summary sentences appear later in the document.",7 Discussion: Contextual Bandit Setting Vs. Sequential Full RL Labeling,[0],[0]
"The intuition behind this is that models based on the sequential labeling setting are affected by the order of the decisions, which biases towards selecting sentences that appear earlier in the document.",7 Discussion: Contextual Bandit Setting Vs. Sequential Full RL Labeling,[0],[0]
"By contrast, our CB-based RL model has more flexibility and freedom to explore the search space, as it samples the sentences without replacement based on the affinity scores.",7 Discussion: Contextual Bandit Setting Vs. Sequential Full RL Labeling,[0],[0]
"Note that although we do not explicitly make the selection decisions in a sequential fashion, the sequential information about dependencies between sentences is implicitly embedded in the affinity scores, which are produced by bidirectional RNNs.
",7 Discussion: Contextual Bandit Setting Vs. Sequential Full RL Labeling,[0],[0]
"We provide empirical evidence for this conjecture by comparing BANDITSUM to the sequential RL model proposed by Wu and Hu (2018) (Figure 2) on two subsets of the data: one with good
5The supervised labels for the upper bound estimation are obtained using the heuristic described in Nallapati et al. (2017).
summary sentences appearing early in the article, while the other contains articles where good summary sentences appear late.",7 Discussion: Contextual Bandit Setting Vs. Sequential Full RL Labeling,[0],[0]
"Specifically, we construct two evaluation datasets by selecting the first 50 documents (Dearly, i.e., best summary occurs early) and the last 50 documents (Dlate, i.e., best summary occurs late) from a sample of 1000 documents that is ordered by the average extractive label index idx.",7 Discussion: Contextual Bandit Setting Vs. Sequential Full RL Labeling,[0],[0]
"Given an article with n sentences indexed from 1, . . .",7 Discussion: Contextual Bandit Setting Vs. Sequential Full RL Labeling,[0],[0]
", n and a greedy extractive labels set with three sentences (i, j, k)6, the average index for the extractive label is computed by idx= (i+ j + k)/3n.
",7 Discussion: Contextual Bandit Setting Vs. Sequential Full RL Labeling,[0],[0]
"Given these two subsets of the data, three different models (BANDITSUM, RNES and RNES3) are trained and evaluated on each of the two datasets without extractive labels.",7 Discussion: Contextual Bandit Setting Vs. Sequential Full RL Labeling,[0],[0]
"Since the original sequential RL model (RNES) is unstable without supervised pre-training, we propose the RNES3 model that is limited to select no more then three sentences.",7 Discussion: Contextual Bandit Setting Vs. Sequential Full RL Labeling,[0],[0]
"Starting with random initializations without supervised pre-training, we train each model ten times for 100 epochs and plot the learning curve of the average ROUGE-F1 score computed based on the trained model in Figure 2.",7 Discussion: Contextual Bandit Setting Vs. Sequential Full RL Labeling,[0],[0]
"We can clearly see that BANDITSUM finds a better so-
6For each document, a length-3 extractive summary with near-optimal ROUGE score is selected following the heuristic proposed by Nallapati et al. (2017).
lution more quickly than RNES and RNES3 on both datasets.",7 Discussion: Contextual Bandit Setting Vs. Sequential Full RL Labeling,[0],[0]
"Moreover, it displays a significantly speed-up in the exploration and finds the best solution when good summary sentences appeared later in the document (Dlate).",7 Discussion: Contextual Bandit Setting Vs. Sequential Full RL Labeling,[0],[0]
"In this work, we presented a contextual bandit learning framework, BANDITSUM , for extractive summarization, based on neural networks and reinforcement learning algorithms.",8 Conclusion,[0],[0]
BANDITSUM does not require sentence-level extractive labels and optimizes ROUGE scores between summaries generated by the model and abstractive reference summaries.,8 Conclusion,[0],[0]
"Empirical results show that our method performs better than or comparable to state-of-the-art extractive summarization models which must be pre-trained on extractive labels, and converges using significantly fewer update steps than competing approaches.",8 Conclusion,[0],[0]
"In future work, we will explore the direction of adding an extra coherence reward (Wu and Hu, 2018) to improve the quality of extracted summaries in terms of sentence discourse relation.",8 Conclusion,[0],[0]
The research was supported in part by Natural Sciences and Engineering Research Council of Canada (NSERC).,Acknowledgements,[0],[0]
The authors would like to thank Compute Canada for providing the computational resources.,Acknowledgements,[0],[0]
"In this work, we propose a novel method for training neural networks to perform singledocument extractive summarization without heuristically-generated extractive labels.",abstractText,[0],[0]
"We call our approach BANDITSUM as it treats extractive summarization as a contextual bandit (CB) problem, where the model receives a document to summarize (the context), and chooses a sequence of sentences to include in the summary (the action).",abstractText,[0],[0]
A policy gradient reinforcement learning algorithm is used to train the model to select sequences of sentences that maximize ROUGE score.,abstractText,[0],[0]
"We perform a series of experiments demonstrating that BANDITSUM is able to achieve ROUGE scores that are better than or comparable to the state-of-the-art for extractive summarization, and converges using significantly fewer update steps than competing approaches.",abstractText,[0],[0]
"In addition, we show empirically that BANDITSUM performs significantly better than competing approaches when good summary sentences appear late in the source document.",abstractText,[0],[0]
BANDITSUM: Extractive Summarization as a Contextual Bandit,title,[0],[0]
The advancement of modern society is driven by the development of Integrated Circuits (IC).,1. Introduction,[0],[0]
"Unlike the digital circuits where the design flow is already highly automated, the automation of analog circuit design is still a challenging problem.
",1. Introduction,[0],[0]
"Traditionally, the design parameters of analog circuits like widths and lengths of transistors are manually calculated by designers with their experience and the understanding of the design specifications.",1. Introduction,[0],[0]
"However, due to the progress
1State Key Lab of ASIC and System, School of Microelectronics, Fudan University, Shanghai, China 2Department of Electrical Engineering, University of Texas at Dallas, Richardson, TX, U.S.A. Correspondence to: Fan Yang <yangfan@fudan.edu.cn>, Xuan Zeng <xzeng@fudan.edu.cn>.
Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"of IC manufacture technology forecasted by Moore’s law, the circuit devices become more and more complicated, and the parasitic effect of the circuits can no longer be ignored.",1. Introduction,[0],[0]
"On the other hand, the demands for high-performance, lowpower analog circuits are increasing.",1. Introduction,[0],[0]
It is much more difficult to meet the performance and time-to-market requirements with manual circuit design.,1. Introduction,[0],[0]
"Automated analog circuit design has thus attracted much research interest in the past decade (Rutenbar et al., 2007).
",1. Introduction,[0],[0]
The analog circuit design automation problems can be formulated as optimization problems.,1. Introduction,[0],[0]
"The aim is to find the optimal design parameters that provide the best circuit performance, which can be represented by a figure of merit (FOM) real-valued function.",1. Introduction,[0],[0]
"Prior works about analog circuit optimization include offline model-based approaches (Colleran et al., 2003; Daems et al., 2003; Wang et al., 2014) and simulation-based approaches.",1. Introduction,[0],[0]
The offline model-based methods try to build global models of the FOM via manual calculation or regression with simulated data and then optimize the cheap-to-evaluate models.,1. Introduction,[0],[0]
The problem with this approach is that the accurate models are usually hard to get.,1. Introduction,[0],[0]
"For example, in Wang et al. (2014), 100,000 randomly simulated points are used to train a sparse polynomial model for an amplifier circuit with ten design parameters.
",1. Introduction,[0],[0]
"Simulation-based methods, instead, treat the performances of the circuits as black-box functions.",1. Introduction,[0],[0]
The performances are obtained from circuit simulations.,1. Introduction,[0],[0]
Global optimization algorithms are directly applied to the black-box functions.,1. Introduction,[0],[0]
"For simulation-based circuit optimization methods, metaheuristic algorithms (Phelps et al., 2000; Liu et al., 2009) are widely used.",1. Introduction,[0],[0]
"Although these algorithms can explore the whole design space, they have relatively low convergence rate.",1. Introduction,[0],[0]
"When the circuit simulation takes a long time, both model-based and simulation-based approaches can be very time-consuming.
",1. Introduction,[0],[0]
"In recent years, the Gaussian process (GP) (Rasmussen, 2006) model has been introduced for the automated design of analog circuits to reduce the required number of circuit simulations.",1. Introduction,[0],[0]
"In Liu et al. (2014), GP is combined with differential evolution algorithm.",1. Introduction,[0],[0]
"Recently, Bayesian optimization (BO) (Shahriari et al., 2016) algorithm has also been applied for analog circuit optimization.",1. Introduction,[0],[0]
"In Lyu et al. (2017),
Bayesian optimization algorithm is firstly introduced for the single- and multi-objective optimization of general analog circuits and has shown to be much more efficient compared with other simulation-based approaches.",1. Introduction,[0],[0]
"In Wang et al. (2017), Bayesian optimization algorithm is combined with adaptive Monte-Carlo sampling to optimize the yield of analog circuits and static random-access memory (SRAM).
",1. Introduction,[0],[0]
Bayesian optimization algorithm is a well-studied algorithm and has demonstrated to be promising for the automated design of analog circuits.,1. Introduction,[0],[0]
"However, the standard Bayesian optimization algorithm is sequential.",1. Introduction,[0],[0]
It chooses only one point at each iteration by optimizing the acquisition function.,1. Introduction,[0],[0]
It is often desirable to select a batch of points at each iteration.,1. Introduction,[0],[0]
"The sequential property of Bayesian optimization limits its further applications in multi-core computer systems.
",1. Introduction,[0],[0]
Bayesian optimization algorithm has been extended to enable batch selection.,1. Introduction,[0],[0]
"Some prior works, like the qEI (Chevalier & Ginsbourger, 2013), qKG (Wu & Frazier, 2016) and parallel predictive entropy search (PPES) (Shah & Ghahramani, 2015) approaches, consider to search for the optimal batch selection for a specific acquisition function.",1. Introduction,[0],[0]
"These methods usually involve some approximations or MonteCarlo sampling, and thus scale poorly as the batch size increases.",1. Introduction,[0],[0]
"Other works, including the simulation matching (SM) (Azimi et al., 2010) method, the batch-UCB (BUCB, BLCB for minimization problems) (Desautels et al., 2014) method, the parallel UCB with pure exploration (GP-UCBPE) (Contal et al., 2013) method, and the local penalization (LP) (González et al., 2016) method, adopted the greedy strategies that select individual points until the batch is filled.
",1. Introduction,[0],[0]
All the batch Bayesian optimization algorithms mentioned above choose to use single acquisition function.,1. Introduction,[0],[0]
"And except for the SM method (Azimi et al., 2010) and LP method (González et al., 2016) which can use arbitrary acquisition function, other parallelization methods rely on a specific acquisition function.",1. Introduction,[0],[0]
"The UCB acquisition function must be used for BUCB and GP-UCB-PE, and the knowledge gradient (KG) acquisition function must be used for the qKG algorithm.",1. Introduction,[0],[0]
"As is stated in Hoffman et al. (2011), no single acquisition function can always outperform other acquisition functions.",1. Introduction,[0],[0]
"Relying on one acquisition function may result in poor performance.
",1. Introduction,[0],[0]
"In this paper, we propose to parallelize Bayesian optimization algorithm via the Multi-objective ACquisition Ensemble (MACE).",1. Introduction,[0],[0]
The proposed MACE method exploits the disagreement between different acquisition functions to enable batch selection.,1. Introduction,[0],[0]
"At each iteration, after the GP model is updated, multiple acquisition functions are selected.",1. Introduction,[0],[0]
We then perform multi-objective optimization to find the Pareto front (PF) of the acquisition functions.,1. Introduction,[0],[0]
The PF represents the best trade-off between these acquisition functions.,1. Introduction,[0],[0]
"When batch
evaluations are possible, we can sample multiple points on the PF to accelerate the optimization.
",1. Introduction,[0],[0]
"The MACE algorithm is tested using several analytical benchmark functions and two real-world analog circuits, including an operational amplifier with ten design parameters and a class-E power amplifier with twelve design parameters.",1. Introduction,[0],[0]
"The BLCB method (Desautels et al., 2014), local penalization method with expected improvement acquisition function (EI-LP) (González et al., 2016), qEI (Chevalier & Ginsbourger, 2013) and qKG (Wu & Frazier, 2016) methods are compared with MACE.",1. Introduction,[0],[0]
The proposed MACE method achieved competitive performance when compared with the state-of-the-art algorithms listed in the paper.,1. Introduction,[0],[0]
"In this section, we will present the problem formulation of analog circuit optimization, and review the background of Gaussian process regression and Bayesian optimization.",2. Background,[0],[0]
"When designing integrated circuits, the designers have to decide what circuit topology to use and then set the corrsponding design parameters.",2.1. Problem Formulation,[0],[0]
"In this work, we handle the scenarios where the topology of the analog circuit is fixed.",2.1. Problem Formulation,[0],[0]
"This is practical as there are usually a lot of classical topologies for a given design task, so unlike digital circuits, choosing appropriate topology is relatively easy.
",2.1. Problem Formulation,[0],[0]
"Once the circuit topology is fixed, the designer has to choose the appropriate design parameters according to the specifications and the circuit device model.",2.1. Problem Formulation,[0],[0]
What we want to do is automatically searching for the optimal design parameters.,2.1. Problem Formulation,[0],[0]
"This problem can then be formulated as a bound-constrained black-box optimization problem:
minimize FOM(x), (1)
where x ∈ D is the vector of design variables, FOM(x) is the objective constructed from the design specifications, the FOM(x) can be deterministric or noisy depending on the design specifications.",2.1. Problem Formulation,[0],[0]
"Given the design parameters x, the FOM value can be obtained by commercial circuit simulators like HSPICE or Spectre.",2.1. Problem Formulation,[0],[0]
"The objective function FOM(x) in (1) can be approximated by Gaussian process (GP) model (Rasmussen, 2006).",2.2. Gaussian Process Regression,[0],[0]
The GP model is the most commonly used model for Bayesian optimization.,2.2. Gaussian Process Regression,[0],[0]
The advantage of GP is that it provides a well-calibrated uncertainty of prediction.,2.2. Gaussian Process Regression,[0],[0]
"GP is characterized by a mean function m(x) and a covariance function k(x,x′).",2.2. Gaussian Process Regression,[0],[0]
"In this work, we use squared-exponential ARD kernel (Rasmussen, 2006), and a constant mean function
m(x) = µ0 for all our experiments.",2.2. Gaussian Process Regression,[0],[0]
"By default, we assume the objective function evaluations are influenced by i.i.d. noise t ∼ N(0, σ2n) and set the noise level σ2n as a hyperparameter.",2.2. Gaussian Process Regression,[0],[0]
"The introduction of the i.i.d noise also helps to improve the numerical stability.
",2.2. Gaussian Process Regression,[0],[0]
"Denote the training set as {X,y} where X = {x1, . . .",2.2. Gaussian Process Regression,[0],[0]
",xN} and y = {y1, . .",2.2. Gaussian Process Regression,[0],[0]
.,2.2. Gaussian Process Regression,[0],[0]
", yN}, given a new data point x, the prediction of f(x) is not a scalar value, but a predictive distribution
f(x) ∼ N(µ(x), σ2(x)), (2)
where µ(x) and σ2(x) can be expressed as
µ(x) = µ0 + k(x, X)[K +",2.2. Gaussian Process Regression,[0],[0]
σ 2 nI] −1(y,2.2. Gaussian Process Regression,[0],[0]
"− µ0) σ2(x) = k(x,x)− k(x, X)[K + σ2nI]−1k(X,x),
(3)",2.2. Gaussian Process Regression,[0],[0]
"where k(x, X) = (k(x,x1), . .",2.2. Gaussian Process Regression,[0],[0]
.,2.2. Gaussian Process Regression,[0],[0]
", k(x,xN ))",2.2. Gaussian Process Regression,[0],[0]
"T and k(X,x) = k(x, X)T .",2.2. Gaussian Process Regression,[0],[0]
"The µ(x) can be viewed as the prediction of the function value, while the σ2(x) is a measure of uncertainty of the prediction.",2.2. Gaussian Process Regression,[0],[0]
"Bayesian optimization (Shahriari et al., 2016) was proposed for the optimization of expensive black-box functions.",2.3. Bayesian Optimization,[0],[0]
"It consists of two essential ingredients, i.e., the probabilistic surrogate models and the acquisition functions.",2.3. Bayesian Optimization,[0],[0]
The probabilistic surrogate models provide predictions with uncertainties.,2.3. Bayesian Optimization,[0],[0]
The acquisition functions make use of the predictive distribution to explore the state space.,2.3. Bayesian Optimization,[0],[0]
"The procedure of Bayesian optimization is summarized in Algorithm 1.
",2.3. Bayesian Optimization,[0],[0]
"Algorithm 1 Bayesian Optimization Require: Number of initial sampling points Ninit, number
of iterations Niter 1: Randomly sample Ninit points in the design space 2:",2.3. Bayesian Optimization,[0],[0]
"Construct initial GP model 3: for t = 1, 2, . . .",2.3. Bayesian Optimization,[0],[0]
", Niter do 4: Construct the acquisition function 5: Find xt that optimizes the acquisition function 6: Sample yt = f(xt) 7: Update probabilistic surrogate model 8: end for 9: Return best f(x) recorded during iterations
In Bayesian optimization described in Algorithm 1, the acquisition function is used to balance the exploration and exploitation during the optimization.",2.3. Bayesian Optimization,[0],[0]
The acquisition function considers both the predictive value and the uncertainty.,2.3. Bayesian Optimization,[0],[0]
There are a lot of existing acquisition functions.,2.3. Bayesian Optimization,[0],[0]
"Examples include the lower confidence bound (LCB), the probability of improvement (PI), and the expected improvement (EI).
",2.3. Bayesian Optimization,[0],[0]
"The LCB function is defined as follows:
LCB(x) = µ(x)− κσ(x), (4)
where the µ(x) and the σ(x) are the predictive value and uncertainty of GP defined in (3), κ is a parameter that balances the exploitation and exploration.
",2.3. Bayesian Optimization,[0],[0]
"Following the suggestion of (Srinivas et al., 2010; Brochu et al., 2010), the κ in (4) is defined as:
κ = √ ντt τt",2.3. Bayesian Optimization,[0],[0]
"= 2 log(t d/2+2π2/3δ),
(5)
where t is the number of current iteration, ν and δ are two user-defined parameters.",2.3. Bayesian Optimization,[0],[0]
"We fix ν = 0.5 and δ = 0.05 in this paper for the proposed MACE algorithm and our implementation of the BLCB algorithm.
",2.3. Bayesian Optimization,[0],[0]
"The PI and EI functions are defined as
PI(x) = Φ(λ) EI(x) = σ(x)(λΦ(λ) + φ(λ))",2.3. Bayesian Optimization,[0],[0]
λ,2.3. Bayesian Optimization,[0],[0]
= τ,2.3. Bayesian Optimization,[0],[0]
− ξ,2.3. Bayesian Optimization,[0],[0]
"− µ(x)
σ(x) ,
(6)
where τ is the current best value objective value, and ξ is a small positive jitter to improvement the ability of exploration.",2.3. Bayesian Optimization,[0],[0]
The Φ(.) and φ(.) functions are the CDF and PDF functions of normal distribution.,2.3. Bayesian Optimization,[0],[0]
"In our implementation of the MACE algorithm, we fix ξ = 1e-3.
",2.3. Bayesian Optimization,[0],[0]
"There are also other acquisition functions, like the knowledge gradient (Scott et al., 2011) function, predictive entropy search (Hernández-Lobato et al., 2014), and the max-value entropy search(Wang & Jegelka, 2017).",2.3. Bayesian Optimization,[0],[0]
"A portfolio of several acquisition functions is also possible (Hoffman et al., 2011).",2.3. Bayesian Optimization,[0],[0]
We will present the proposed batch Bayesian optimization algorithm in this section.,3. Proposed Batch Bayesian Optimization Algorithm,[0],[0]
"Unlike single-objective optimization, there are multiple objectives to optimize in multi-objective optimization problems(Marler & Arora, 2004).",3.1. Multi-objective Optimization,[0],[0]
"The multi-objective optimization problem is formulated as
minimize f1(x), . . .",3.1. Multi-objective Optimization,[0],[0]
", fm(x).",3.1. Multi-objective Optimization,[0],[0]
"(7)
The multiple objectives to be optimized can be conflicting so that it is usually impossible to find a single solution that is the optimum of all objectives.",3.1. Multi-objective Optimization,[0],[0]
"The goal of multi-objective optimization algorithms is to approximate the Pareto front of
the objectives.",3.1. Multi-objective Optimization,[0],[0]
A solution x1 is said to dominate x2 if ∀i ∈ {1 . .,3.1. Multi-objective Optimization,[0],[0]
".m}, fi(x1) ≤ fi(x2) and ∃j ∈ {1 . .",3.1. Multi-objective Optimization,[0],[0]
".m}, fj(x1) < fj(x2).",3.1. Multi-objective Optimization,[0],[0]
A design is Pareto-optimal if it is not dominated by any other point in the design space and dominates at least one point.,3.1. Multi-objective Optimization,[0],[0]
"The whole set of the Pareto-optimal points in the design space is called the Pareto set, and the set of Pareto-optimal points in the objective space is called the Pareto front.",3.1. Multi-objective Optimization,[0],[0]
"It is often unlikely to get the whole Pareto front as there might be infinite points on the Paret front, multi-objective optimization algorithms try to find a set of evenly distributed solutions that approximate the true Pareto front.
",3.1. Multi-objective Optimization,[0],[0]
"There exist many mature multi-objective optimization algorithms, like the non-dominated sorting based genetic algorithm (NSGA-II) (Deb et al., 2002), and the multiobjective evolutionary algorithm based on decomposition (MOEA/D) (Zhang & Li, 2007).",3.1. Multi-objective Optimization,[0],[0]
"In this paper, the multi-objective optimization based on differential evolution (DEMO) (Robič & Filipič, 2005) is used to solve multiobjective optimization problems, but other multi-objective optimization algorithms can also be applied.",3.1. Multi-objective Optimization,[0],[0]
"Each acquisition function represents a unique selection strategy, different acquisition functions may not agree with each other about where to sample the next point.",3.2. Batch Bayesian Optimization via Multi-objective Acquisition Function Ensemble,[0],[0]
"For example, the value of LCB function always decreases as the σ(x) increases.",3.2. Batch Bayesian Optimization via Multi-objective Acquisition Function Ensemble,[0],[0]
"However, for the PI function, when σ(x) increases, the value of PI would decrease when µ(x) < τ , and increase when µ(x) > τ .",3.2. Batch Bayesian Optimization via Multi-objective Acquisition Function Ensemble,[0],[0]
"For the EI function, if the function is noiseless, the values of EI function at already sampled points would always be worse than the EI values at any
unsampled locations, while this property does not hold for the LCB function.
",3.2. Batch Bayesian Optimization via Multi-objective Acquisition Function Ensemble,[0],[0]
"Algorithm 2 Multi-objective Acquisition Ensemble Algorithm Require: Number of initial sampling points Ninit, number
of iterations Niter, batch size B. 1: Randomly sample Ninit points in the design space 2:",3.2. Batch Bayesian Optimization via Multi-objective Acquisition Function Ensemble,[0],[0]
"Construct initial GP model 3: for t = 1, 2, . . .",3.2. Batch Bayesian Optimization via Multi-objective Acquisition Function Ensemble,[0],[0]
", Niter do 4: Construct the LCB, EI and PI functions according to (4) and (6) 5: Find the Pareto front of LCB, EI, PI functions using the DEMO algorithm 6: Randomly sample B points x1, . . .",3.2. Batch Bayesian Optimization via Multi-objective Acquisition Function Ensemble,[0],[0]
",xB from the Pareto-optimal points 7: Evaluate x1, . . .",3.2. Batch Bayesian Optimization via Multi-objective Acquisition Function Ensemble,[0],[0]
",xB to get y1 = f(x1), . . .",3.2. Batch Bayesian Optimization via Multi-objective Acquisition Function Ensemble,[0],[0]
", yB = f(xB) 8: Update the GP model 9: end for
10: Return best f(x) recorded during iterations
With multi-objective optimization, the best trade-off between acquisition functions can be captured by the Pareto front of these acquisition functions.",3.2. Batch Bayesian Optimization via Multi-objective Acquisition Function Ensemble,[0],[0]
"We can then sample on the Pareto front to obtain multiple candidate points for the objective function evaluations.
",3.2. Batch Bayesian Optimization via Multi-objective Acquisition Function Ensemble,[0],[0]
The proposed MACE algorithm is described in Algorithm 2.,3.2. Batch Bayesian Optimization via Multi-objective Acquisition Function Ensemble,[0],[0]
"In the proposed MACE algorithm, the LCB, EI, and PI acquisition functions are selected.",3.2. Batch Bayesian Optimization via Multi-objective Acquisition Function Ensemble,[0],[0]
Other acquisition functions like KG and PES can also be incorporated into the MACE framework.,3.2. Batch Bayesian Optimization via Multi-objective Acquisition Function Ensemble,[0],[0]
"In each iteration, the following multi-objective
optimization problem is constructed:
minimize LCB(x), − EI(x), − PI(x).",3.2. Batch Bayesian Optimization via Multi-objective Acquisition Function Ensemble,[0],[0]
"(8)
Then the DEMO multi-objective optimization algorithm (Robič & Filipič, 2005) is applied to solve the multiobjective problem in (8).",3.2. Batch Bayesian Optimization via Multi-objective Acquisition Function Ensemble,[0],[0]
"Once the Pareto front of LCB, EI and PI is obtained, the candidate points are then randomly sampled from the Pareto front.
",3.2. Batch Bayesian Optimization via Multi-objective Acquisition Function Ensemble,[0],[0]
"In Figure 1, we illustrate the proposed MACE algorithm using an example of a real-world amplifier circuit.",3.2. Batch Bayesian Optimization via Multi-objective Acquisition Function Ensemble,[0],[0]
"The optimization objective is to maximize the phase margin (PM) of the amplifier, so the FOM is defined as FOM(x) = −PM(x).",3.2. Batch Bayesian Optimization via Multi-objective Acquisition Function Ensemble,[0],[0]
The width of one of its transistor is the design variable.,3.2. Batch Bayesian Optimization via Multi-objective Acquisition Function Ensemble,[0],[0]
We sweep the width of the transistor and perform HSPICE simulations to get the FOM values.,3.2. Batch Bayesian Optimization via Multi-objective Acquisition Function Ensemble,[0],[0]
The curve of FOM values is plotted in Figure 1(a) (the blue line).,3.2. Batch Bayesian Optimization via Multi-objective Acquisition Function Ensemble,[0],[0]
Several points are randomly sampled from the FOM curve to train the GP model.,3.2. Batch Bayesian Optimization via Multi-objective Acquisition Function Ensemble,[0],[0]
"The LCB, EI, PI functions and the Pareto front of the acquisition functions are plotted in Figure 1(b).",3.2. Batch Bayesian Optimization via Multi-objective Acquisition Function Ensemble,[0],[0]
"We can see from Figure 1(b) that the optimal locations of the three acquisition functions are different, while their best trade-off is captured by the Pareto front.",3.2. Batch Bayesian Optimization via Multi-objective Acquisition Function Ensemble,[0],[0]
The Pareto set that represents the best trade-off between the three acquisition functions is the interval,3.2. Batch Bayesian Optimization via Multi-objective Acquisition Function Ensemble,[0],[0]
"[43, 50.4], as plotted in Figure 1(a).",3.2. Batch Bayesian Optimization via Multi-objective Acquisition Function Ensemble,[0],[0]
The candidate points for the next batch of evaluations are randomly sampled from the Pareto set.,3.2. Batch Bayesian Optimization via Multi-objective Acquisition Function Ensemble,[0],[0]
The proposed MACE algorithm1 was tested using eight benchmark functions and two real-world analog circuits.,4. Experimental Results,[0],[0]
"Four state-of-the-art parallel Bayesian optimization methods were compared, including the BLCB algorithm (Desautels et al., 2014), the local penalization method with EI acquisition function (EI-LP) (González et al., 2016), the qEI and qKG methods (Chevalier & Ginsbourger, 2013; Wu & Frazier, 2016).",4. Experimental Results,[0],[0]
"2
For the MACE, BLCB, and EI-LP method, the ARD squared-exponential kernel is used and the GP models are fitted by maximum likelihood estimations (MLE); for the qKG and qEI methods, the ARD Matern52 kernels are used, and the GP hyperparameters are integrated via MCMC sampling.",4. Experimental Results,[0],[0]
"The Matern52 kernel and MCMC integration are the default strategies of the qKG and qEI implementations and it is unclear in the documentation about how to change the GP settings.
",4. Experimental Results,[0],[0]
1Available at https://github.com/Alaya-in-Matrix/MACE 2We implemented the BLCB algorithm as the available open source implementations only allow discrete input.,4. Experimental Results,[0],[0]
"For the EI-LP method, the code is downloaded from https://github.com/SheffieldML/GPyOpt.",4. Experimental Results,[0],[0]
The code for qEI and qKG is downloaded from https://github.com/wujian16/CornellMOE.,4. Experimental Results,[0],[0]
"We tested the MACE algorithm and other parallel BO methods using eight commonly used benchmark functions, as summarized in Table 1.
",4.1. Benchmark Problems,[0],[0]
"For all functions except the two 10D functions, we set the number of initial random sampling to Ninit = 20 and the number of iterations toNiter = 45.",4.1. Benchmark Problems,[0],[0]
"Batch size is set toB = 4, the total number of function evaluations is Ninit +B × Niter.",4.1. Benchmark Problems,[0],[0]
"For the 10D Ackley and 10D Rosenbrock functions, we set Ninit = 100 and Niter = 175.",4.1. Benchmark Problems,[0],[0]
"The experiments were repeated ten times to average the random fluctuations.
",4.1. Benchmark Problems,[0],[0]
We also ran the MACE algorithm in sequential mode and compared with the EI and LCB acquisition functions.,4.1. Benchmark Problems,[0],[0]
"The sequential EI and LCB based Bayesian optimization are implemented by setting the batch size B = 1 for EI-LP and BLCB respectively.
",4.1. Benchmark Problems,[0],[0]
"The mean convergence plots of the tested algorithms on the benchmark functions are given in Figure 2, the statistics of the final regrets are listed in Table 2.",4.1. Benchmark Problems,[0],[0]
"As can be seen in Figure 2 and Table 2, when running in sequential mode, the MACE algorithm is competitive with the LCB and EI acquisition functions.",4.1. Benchmark Problems,[0],[0]
"The sequential MACE (MACE-1) algorithm gave better performances than the sequential EI (EI-1) and sequential LCB (LCB-1) algorithms in the Eggholder, Branin, Hartmann6, Ackley10, and Rosenbrock10 functions.",4.1. Benchmark Problems,[0],[0]
"Also, the parallel MACE (MACE-4) gave the best performances among all the tested algorithms for six out of the eight benchmark functions, and has shown dramatic speedup compared to the sequential MACE.",4.1. Benchmark Problems,[0],[0]
"We also performed additional experiments with varied batch sizes, the detail of those experimental results can be seen in the supplementary materials.",4.1. Benchmark Problems,[0],[0]
"We report the time spent on the ten-dimensional Rosenbrock function optimization with B = 4 as a measure of the algorithm overhead, for the ten-dimensional Rosenbrock function, it took MACE about 11 hours to finish all the Niter = 175 iterations, the BLCB algorithm took about five hours, for the EI-LP algorithm, it took only one hour to finish the optimization.",4.1. Benchmark Problems,[0],[0]
"The overheads for qEI and qKG are much larger, it took more than two days for qKG and qEI to
finish the optimization of the ten-dimensional Rosenbrock function.",4.1. Benchmark Problems,[0],[0]
"The operational amplifier (Wang et al., 2014) shown in Figure 3 is used to test Bayesian optimization algorithms.",4.2. Operational Amplifier,[0],[0]
The circuit is designed using the 180nm process.,4.2. Operational Amplifier,[0],[0]
"It has 10 design parameters, including the lengths and widths of transistors, the resistance of the resistors and the capacitance of the capacitors.",4.2. Operational Amplifier,[0],[0]
"The circuit is simulated using the commercial HSPICE circuit simulator.
",4.2. Operational Amplifier,[0],[0]
"We want to maximize the gain, unit gain frequency (UGF) and the phase margin (PM) for this amplifier.",4.2. Operational Amplifier,[0],[0]
"The Figure of Merit FOM is constructed as
FOM = −1.2× gain − 10×UGF − 1.6× PM .
",4.2. Operational Amplifier,[0],[0]
"For this circuit, we compared the MACE algorithm with the BLCB and EI-LP algorithms.",4.2. Operational Amplifier,[0],[0]
"The qKG and qEI are not compared as the computation of qEI and qKG acquisition functions become very slow for the ten-dimensional functions.
",4.2. Operational Amplifier,[0],[0]
We run the algorithms in sequential mode and batch mode.,4.2. Operational Amplifier,[0],[0]
"For the batch mode, the batch size is set to B = 4.",4.2. Operational Amplifier,[0],[0]
"The number of initial random sampling is set to Ninit = 100, and the number of iterations is set to Niter = 100.
",4.2. Operational Amplifier,[0],[0]
The mean convergence plot for the sequential and batch runs are given in Figure 4.,4.2. Operational Amplifier,[0],[0]
The mean and standard deviation of the final optimized FOM values are listed in Table 3.,4.2. Operational Amplifier,[0],[0]
"As can be seen, on average, the batch MACE algorithm had the fastest convergence rate compared with the sequential MACE algorithm and other parallel algorithms.",4.2. Operational Amplifier,[0],[0]
"It should also be noted that the final optimized FOM values given by MACE-4 have very small deviation (0.105) compared with other algorithms.
",4.2. Operational Amplifier,[0],[0]
Table 2.,4.2. Operational Amplifier,[0],[0]
"Statistics of the regrets of the benchmark functions
Eggholder Branin Alpine1 Hartmann6
MACE-1 87.65±75.83 1.05e-5±1.31e-5 2.66305±1.05844 0.0646869±0.0621189 LCB-1 153.9±112.8 6.86e-5±1.13e-4 5.66812±1.76973 0.125565±0.122684 EI-1",4.2. Operational Amplifier,[0],[0]
172.8±132.2 1.62e-2±1.63e-2 2.46061±1.56079 0.110561±0.146809,4.2. Operational Amplifier,[0],[0]
MACE-4,4.2. Operational Amplifier,[0],[0]
46.38±40.89 4.62e-6±6.64e-6 0.903805±0.835209 0.0275738±0.052254 BLCB-4 56.86±35.91 4.32e-5±6.33e-5 1.8843±0.938873 0.06447±0.0621176 EI-LP-4 44.68±56.45,4.2. Operational Amplifier,[0],[0]
"2.11e-2±1.84e-2 1.0059±0.456865 0.0540446±0.0558557 qKG-4 106.4±67.64 2.65e-1±2.70e-1 3.01513±1.13414 0.47134±0.18939 qEI-4 72.13±52.08 3.29e-4±1.14e-3 2.7074±1.05145 0.186088±0.116323
Ackley2 Rosenbrock2 Ackley10",4.2. Operational Amplifier,[0],[0]
"Rosenbrock10
MACE-1 1.71474±1.12154 0.026173±0.051189 3.1348±0.447874 499.697±300.899 LCB-1 1.624±0.926437 0.0201124±0.0205367 3.14797±0.519164 517.944±288.955 EI-1 1.0136±0.985858",4.2. Operational Amplifier,[0],[0]
13.5508±9.52734 18.8006±0.652136 1367.08±637.507 MACE-4 1.07906±0.886466 0.00095416±0.00093729 2.56439±0.535488 158.116±50.0024 BLCB-4 1.40051±1.02849 0.00191986±0.00180895 3.27543±0.735501 406.819±127.351 EI-LP-4 0.284265±0.24634 2.73645±2.05923,4.2. Operational Amplifier,[0],[0]
18.2682±0.608564 721.351±327.365 qKG-4 5.59394±1.80595 5.03976±3.72014 18.197±0.764103 705.112±412.762,4.2. Operational Amplifier,[0],[0]
qEI-4 2.87373±1.02405 10.1881±15.0432,4.2. Operational Amplifier,[0],[0]
"18.3686±0.501869 655.208±340.954
Vin
C0
C1
Vdd1=2.5V
Vg
Vdd2=1.8V
M4
M3
M2
M1
L3 C2
C3
Vout
RLC1
L1
Cc
R0
R1
L2
Figure 5.",4.2. Operational Amplifier,[0],[0]
Schematic of the power amplifier,4.2. Operational Amplifier,[0],[0]
The class-E power amplifier shown in Figure 5 is used to test Bayesian optimization algorithms.,4.3. Class-E Power Amplifier,[0],[0]
"The circuit is designed using the 180nm process with 12 design parameters, the circuit is simulated by the commercial HSPICE circuit simulator to get its performances.
",4.3. Class-E Power Amplifier,[0],[0]
"For this power amplifier, we aim to maximize the power added efficiency (PAE) and the output power (Pout), the Figure of Merit FOM is constructed as
FOM = −3× PAE − Pout .
",4.3. Class-E Power Amplifier,[0],[0]
"The MACE, BLCB, and EI-LP algorithms were tested in both sequential and batch modes.",4.3. Class-E Power Amplifier,[0],[0]
The number of initial sampling is Ninit = 100.,4.3. Class-E Power Amplifier,[0],[0]
"The number of iterations is
Niter = 100.",4.3. Class-E Power Amplifier,[0],[0]
The batch size is set to B = 4.,4.3. Class-E Power Amplifier,[0],[0]
"The total number of HSPICE simulations is 500 for each batch run and 200 for each sequential run.
",4.3. Class-E Power Amplifier,[0],[0]
The optimization results of the class-E power amplifier are given in Figure 6 and Table 4.,4.3. Class-E Power Amplifier,[0],[0]
We can see that the MACE outperformed the BLCB and EI-LP in both sequential and batch mode.,4.3. Class-E Power Amplifier,[0],[0]
"For the batch runs, the MACE converges fastest among the three algorithms, while the sequential MACE (MACE-1) has comparable performance as the batch EI-LP (EI-LP-4) method.",4.3. Class-E Power Amplifier,[0],[0]
"In this paper, a batch Bayesian optimization algorithm is proposed for the automation of analog circuit design.",5. Conclusion,[0],[0]
The parallelization is achieved via the multi-objective ensemble of acquisition functions.,5. Conclusion,[0],[0]
"In each iteration, the candidate points are sampled from the Pareto front of multiple acquisition functions.",5. Conclusion,[0],[0]
"We compared the proposed MACE algorithm using analytical benchmark functions and real-world circuits, it is shown that the MACE algorithm is competitive compared with the state-of-the-art methods listed in the paper.",5. Conclusion,[0],[0]
"This research was supported partly by the National Major Science and Technology Special Project of China (2017ZX01028101-003), partly by National Key Research and Development Program of China 2016YFB0201304, partly by National Natural Science Foundation of China (NSFC) research projects 61774045, 61574044, 61474026, 61574046, 61674042, and 61628402 and partly by the Recruitment Program of Global Experts (the Thousand Talents Plan).",Acknowledgements,[0],[0]
Bayesian optimization methods are promising for the optimization of black-box functions that are expensive to evaluate.,abstractText,[0],[0]
"In this paper, a novel batch Bayesian optimization approach is proposed.",abstractText,[0],[0]
The parallelization is realized via a multi-objective ensemble of multiple acquisition functions.,abstractText,[0],[0]
"In each iteration, the multi-objective optimization of the multiple acquisition functions is performed to search for the Pareto front of the acquisition functions.",abstractText,[0],[0]
The batch of inputs are then selected from the Pareto front.,abstractText,[0],[0]
The Pareto front represents the best trade-off between the multiple acquisition functions.,abstractText,[0],[0]
Such a policy for batch Bayesian optimization can significantly improve the efficiency of optimization.,abstractText,[0],[0]
The proposed method is compared with several state-of-the-art batch Bayesian optimization algorithms using analytical benchmark functions and real-world analog integrated circuits.,abstractText,[0],[0]
The experimental results show that the proposed method is competitive compared with the state-of-the-art algorithms.,abstractText,[0],[0]
Batch Bayesian Optimization via Multi-objective Acquisition Ensemble for Automated Analog Circuit Design,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 1853–1862 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
1853",text,[0],[0]
"Representing words using dense and real-valued vectors, aka word embeddings, has become the cornerstone for many natural language processing (NLP) tasks, such as document classification (Sebastiani, 2002), parsing (Huang et al., 2012), discourse relation recognition (Lei et al., 2017) and named entity recognition (Turian et al., 2010).",1 Introduction,[0],[0]
"Word embeddings can be learned by optimizing that words occurring in similar contexts have similar embeddings, i.e. the well-known distributional hypothesis (Harris, 1954).",1 Introduction,[0],[0]
"A representative method is skip-gram (SG) (Mikolov et al., 2013a,b), which realizes the hypothesis using a
∗The first two authors contributed equally to this paper and share the first-authorship.
",1 Introduction,[0],[0]
shallow neural network model.,1 Introduction,[0],[0]
"The other family of methods is count-based, such as GloVe (Pennington et al., 2014) and LexVec (Salle et al., 2016a,b), which exploit low-rank models such as matrix factorization (MF) to learn embeddings by reconstructing the word co-occurrence statistics.
",1 Introduction,[0],[0]
"By far, most state-of-the-art embedding methods rely on SGD and negative sampling for optimization.",1 Introduction,[0],[0]
"However, the performance of SGD is highly sensitive to the sampling distribution and the number of negative samples (Chen et al., 2018; Yuan et al., 2016), as shown in Figure 1.",1 Introduction,[0],[0]
"Essentially, sampling is biased, making it difficult to converge to the same loss with all examples, regardless of how many update steps have been taken.",1 Introduction,[0],[0]
"Moreover, SGD exhibits dramatic fluctuation and suffers from overshooting on local minimums (Ruder, 2016).",1 Introduction,[0],[0]
"These drawbacks of SGD can be attributed to its one-sample learning scheme, which updates parameters based on one training sample in each step.
",1 Introduction,[0],[0]
"To address the above-mentioned limitations of SGD, a natural solution is to perform exact (full) batch learning.",1 Introduction,[0],[0]
"In contrast to SGD, batch learning does not involve any sampling procedure and computes the gradient over all training samples.",1 Introduction,[0],[0]
"As such, it can easily converge to a better optimum in a more stable way.",1 Introduction,[0],[0]
"Nevertheless, a well-known
difficulty in applying full batch learning lies in the expensive computational cost for large-scale data.",1 Introduction,[0],[0]
"Taking the word embedding learning as an example, if the vocabulary size is |V |, then evaluating the loss function and computing the full gradient takes O(|V |2k) time, where k is the embedding size.",1 Introduction,[0],[0]
"This high complexity is unaffordable in practice, since |V |2 can easily reach billion level or even higher.
",1 Introduction,[0],[0]
"In this paper, we introduce AllVec, an exact and efficient word embedding method based on full batch learning.",1 Introduction,[0],[0]
"To address the efficiency challenge in learning from all training samples, we devise a regression-based loss function for word embedding, which allows fast optimization with memorization strategies.",1 Introduction,[0],[0]
"Specifically, the acceleration is achieved by reformulating the expensive loss over all negative samples using a partition and a decouple operation.",1 Introduction,[0],[0]
"By decoupling and caching the bottleneck terms, we succeed to use all samples for each parameter update in a manageable time complexity which is mainly determined by the positive samples.",1 Introduction,[0],[0]
"The main contributions of this work are summarized as follows:
• We present a fine-grained weighted least square loss for learning word embeddings.",1 Introduction,[0],[0]
"Unlike GloVe, it explicitly accounts for all negative samples and reweights them with a frequency-aware strategy.
",1 Introduction,[0],[0]
• We propose an efficient and exact optimization algorithm based on full batch gradient optimization.,1 Introduction,[0],[0]
"It has a comparable time complexity with SGD, but being more effective and stable due to the consideration of all samples in each parameter update.
",1 Introduction,[0],[0]
"• We perform extensive experiments on several benchmark datasets and tasks to demonstrate the effectiveness, efficiency, and convergence property of our AllVec method.",1 Introduction,[0],[0]
"Mikolov et al. (2013a,b) proposed the skip-gram model to learn word embeddings.",2.1 Skip-gram with Negative Sampling,[0],[0]
"SG formulates the problem as a predictive task, aiming at predicting the proper context c for a target word w within a local window.",2.1 Skip-gram with Negative Sampling,[0],[0]
"To speed up the training process, it applies the negative sampling (Mikolov et al., 2013b) to approximate the full softmax.",2.1 Skip-gram with Negative Sampling,[0],[0]
"That is,
each positive (w, c) pair is trained with n randomly sampled negative pairs (w,wi).",2.1 Skip-gram with Negative Sampling,[0],[0]
"The sampled loss function of SG is defined as
LSGwc =log σ(UwŨ T c )+ n∑ i=1",2.1 Skip-gram with Negative Sampling,[0],[0]
"Ewi∼Pn(w) log σ(−UwŨ T wi)
where Uw and Ũc denote the k-dimensional embedding vectors for word w and context c. Pn(w) is the distribution from which negative context wi is sampled.
",2.1 Skip-gram with Negative Sampling,[0],[0]
"Plenty of research has been done based on SG, such as the use of prior knowledge from another source (Kumar and Araki, 2016; Liu et al., 2015a; Bollegala et al., 2016), incorporating word type information (Cao and Lu, 2017; Niu et al., 2017), character level n-gram models (Bojanowski et al., 2016; Joulin et al., 2016) and jointly learning with topic models like LDA (Shi et al., 2017; Liu et al., 2015b).",2.1 Skip-gram with Negative Sampling,[0],[0]
Mikolov et al. (2013b) showed that the unigram distribution raised to the 3/4th power as Pn(w) significantly outperformed both the unigram and the uniform distribution.,2.2 Importance of the Sampling Distribution,[0],[0]
This suggests that the sampling distribution (of negative words) has a great impact on the embedding quality.,2.2 Importance of the Sampling Distribution,[0],[0]
"Furthermore, Chen et al. (2018) and Guo et al. (2018) recently found that replacing the original sampler with adaptive samplers could result in better performance.",2.2 Importance of the Sampling Distribution,[0],[0]
The adaptive samplers are used to find more informative negative examples during the training process.,2.2 Importance of the Sampling Distribution,[0],[0]
"Compared with the original word-frequency based sampler, adaptive samplers adapt to both the target word and the current state of the model.",2.2 Importance of the Sampling Distribution,[0],[0]
They also showed that the finegrained samplers not only speeded up the convergence but also significantly improved the embedding quality.,2.2 Importance of the Sampling Distribution,[0],[0]
"Similar observations were also found in other fields like collaborative filtering (Yuan et al., 2016).",2.2 Importance of the Sampling Distribution,[0],[0]
"While being effective, it is proven that negative sampling is a biased approximation and does not converges to the same loss as the full softmax — regardless of how many update steps have been taken (Bengio and Senécal, 2008; Blanc and Rendle, 2017).",2.2 Importance of the Sampling Distribution,[0],[0]
"Another line of research is the count-based embedding, such as GloVe (Pennington et al., 2014).",2.3 Count-based Embedding Methods,[0],[0]
"GloVe performs a biased MF on the word-context co-occurrence statistics, which is a common ap-
proach in the field of collaborative filtering (Koren, 2008).",2.3 Count-based Embedding Methods,[0],[0]
"However, GloVe only formulates the loss on positive entries of the co-occurrence matrix, meaning that negative signals about wordcontext co-occurrence are discarded.",2.3 Count-based Embedding Methods,[0],[0]
"A remedy solution is LexVec (Salle et al., 2016a,b) which integrates negative sampling into MF.",2.3 Count-based Embedding Methods,[0],[0]
"Some other methods (Li et al., 2015; Stratos et al., 2015; Ailem et al., 2017) also use MF to approximate the word-context co-occurrence statistics.",2.3 Count-based Embedding Methods,[0],[0]
"Although predictive models and count-based models seem different at first glance, Levy and Goldberg (2014) proved that SG with negative sampling is implicitly factorizing a shifted pointwise mutual information (PMI) matrix, which means that the two families of embedding models resemble each other to a certain degree.
",2.3 Count-based Embedding Methods,[0],[0]
Our proposed method departs from all above methods by using the full batch gradient optimizer to learn from all (positive and negative) samples.,2.3 Count-based Embedding Methods,[0],[0]
We propose a fast learning algorithm to show that such batch learning is not “heavy” even with tens of billions of training examples.,2.3 Count-based Embedding Methods,[0],[0]
"In this work, we adopt the regression loss that is commonly used in count-based models (Pennington et al., 2014; Stratos et al., 2015; Ailem et al., 2017) to perform matrix factorization on word cooccurrence statistics.",3 AllVec Loss,[0],[0]
"As highlighted, to retain the modeling fidelity, AllVec eschews using any sampling but optimizes the loss on all positive and negative word-context pairs.
",3 AllVec Loss,[0],[0]
"Given a word w and a symmetric window of win contexts, the set of positive contexts can be obtained by sliding through the corpus.",3 AllVec Loss,[0],[0]
"Let c denote a specific context, Mwc be the number of cooccurred (w, c) pairs in the corpus within the window.",3 AllVec Loss,[0],[0]
"Mwc=0 means that the pair (w, c) has never been observed, i.e. the negative signal.",3 AllVec Loss,[0],[0]
"rwc is the association coefficient between w and c, which is calculated from Mwc.",3 AllVec Loss,[0],[0]
"Specifically, we use r+wc to denote the ground truth value for positive (w, c) pairs and a constant value r−(e.g., 0 or -1) for negative ones since there is no interaction between w and c in negative pairs.",3 AllVec Loss,[0],[0]
"Finally, with all positive and negative pairs considered, a regular loss function can be given as Eq.(1), where V is the vocabulary and S is the set of positive pairs.",3 AllVec Loss,[0],[0]
"α+wc and α−wc represent the weight for positive and negative
(w, c) pairs, respectively.",3 AllVec Loss,[0],[0]
"L = ∑
(w,c)∈S α+wc(r + wc − UwŨTc )2︸ ︷︷ ︸
LP + ∑ (w,c)∈(V×V )",3 AllVec Loss,[0],[0]
"\S
α−wc(r − − UwŨTc )2︸ ︷︷ ︸
LN
(1)
When it comes to r+wc, there are several choices.",3 AllVec Loss,[0],[0]
"For example, GloVe applies the log of Mwc with bias terms for w and c. However, research from Levy and Goldberg (2014) showed that the SG model with negative sampling implicitly factorizes a shifted PMI matrix.",3 AllVec Loss,[0],[0]
"The PMI value for a (w, c) pair can be defined as
PMIwc = log P (w, c)
P (w)P (c) = log MwcM∗∗ Mw∗M∗c",3 AllVec Loss,[0],[0]
"(2)
where ‘*’ denotes the summation of all corresponding indexes (e.g., Mw∗= ∑ c∈V Mwc).",3 AllVec Loss,[0],[0]
"Inspired by this connection, we set r+wc as the positive point-wise mutual information (PPMI) which has been commonly used in the NLP literature (Stratos et al., 2015; Levy and Goldberg, 2014).",3 AllVec Loss,[0],[0]
"Sepcifically, PPMI is the positive version of PMI by setting the negative values to zero.",3 AllVec Loss,[0],[0]
"Finally, r+wc is defined as
r+wc = PPMIwc = max(PMIwc, 0) (3)",3 AllVec Loss,[0],[0]
"Regarding α+wc, we follow the design in GloVe, where it is defined as
α+wc =
{ (Mwc/xmax) ρ",3.1 Weighting Strategies,[0],[0]
"Mwc < xmax
1 Mwc ≥ xmax (4)
",3.1 Weighting Strategies,[0],[0]
"As for the weight for negative instances α−wc, considering that there is no interaction between w and negative c, we set α−wc as α − c (or α − w), which means that the weight is determined by the word itself rather than the word-context interaction.",3.1 Weighting Strategies,[0],[0]
Note that either α−wc = α − c or α − wc = α,3.1 Weighting Strategies,[0],[0]
− w does not influence the complexity of AllVec learning algorithm described in the next section.,3.1 Weighting Strategies,[0],[0]
"The design of α−c is inspired by the frequency-based oversampling scheme in skip-gram and missing data reweighting in recommendation (He et al., 2016).",3.1 Weighting Strategies,[0],[0]
The intuition is that a word with high frequency is more likely to be a true negative context word if there is no observed word-context interactions.,3.1 Weighting Strategies,[0],[0]
"Hence, to effectively differentiate the positive and negative examples, we assign a higher weight for the negative examples that have a higher word fre-
quency, and a smaller weight for infrequent words.",3.1 Weighting Strategies,[0],[0]
"Formally, α−wc is defined as
α−wc = α − c = α0 M δ∗c∑",3.1 Weighting Strategies,[0],[0]
"c∈V M δ ∗c
(5)
where α0 can be seen as a global weight to control the overall importance of negative samples.",3.1 Weighting Strategies,[0],[0]
α0 = 0 means that no negative information is utilized in the training.,3.1 Weighting Strategies,[0],[0]
The exponent δ is used for smoothing the weights.,3.1 Weighting Strategies,[0],[0]
"Specially, δ = 0 means a uniform weight for all negative examples and δ = 1 means that no smoothing is applied.",3.1 Weighting Strategies,[0],[0]
"Once specifying the loss function, the main challenge is how to perform an efficient optimization for Eq.(1).",4 Fast Batch Gradient Optimization,[0],[0]
"In the following, we develop a fast batch gradient optimization algorithm that is based on a partition reformulation for the loss and a decouple operation for the inner product.",4 Fast Batch Gradient Optimization,[0],[0]
"As can be seen, the major computational cost in Eq.(1) lies in the term LN , because the size of (V×V ) \S is very huge, which typically contains over billions of negative examples.",4.1 Loss Partition,[0],[0]
"To this end, we show our first key design that separates the loss of negative samples into the difference between the loss on all samples and that on positive samples1.",4.1 Loss Partition,[0],[0]
"The loss partition serves as the prerequisite for the efficient computation of full batch gradients.
",4.1 Loss Partition,[0],[0]
"LN= ∑ w∈V ∑ c∈V α−c (r −−UwŨTc )2− ∑ (w,c)∈S α−c (r −− UwŨTc )2 (6)
By replacing LN in Eq.(1) with Eq.(6), we can obtain a new loss function with a more clear structure.",4.1 Loss Partition,[0],[0]
We further simplify the loss function by merging the terms on positive examples.,4.1 Loss Partition,[0],[0]
"Finally, we achieve a reformulated loss
L = ∑ w∈V ∑ c∈V α−c (r −−UwŨTc ) 2
︸ ︷︷ ︸ LA
+ ∑
(w,c)∈S
(α+wc − α−c )(∆− UwŨTc ) 2
︸ ︷︷ ︸ L
P ′
+C (7)
where ∆ =",4.1 Loss Partition,[0],[0]
(α+wcr + wc − α−c r−)/(α+wc − α−c ).,4.1 Loss Partition,[0],[0]
It can be seen that the new loss function consists of two components: the loss LA on the whole V ×V training examples and LP ′ on positive examples.,4.1 Loss Partition,[0],[0]
"The major computation now lies in LA which has
1The idea here is similar to that used in (He et al., 2016; Li et al., 2016) for a different problem.
",4.1 Loss Partition,[0],[0]
a time complexity of O(k|V |2).,4.1 Loss Partition,[0],[0]
"In the following, we show how to reduce the huge volume of computation by a simple mathematical decouple.",4.1 Loss Partition,[0],[0]
"To clearly show the decouple operation, we rewrite LA as L̃A by omitting the constant term α−c (r
−)2.",4.2 Decouple,[0],[0]
"Note that uwd and ũcd denote the d-th element in Uw and Ũc, respectively.
",4.2 Decouple,[0],[0]
"L̃A = ∑ w∈V ∑ c∈V α−c k∑ d=0 uwdũcd k∑ d′=0 uwd′ ũcd′
− 2r− ∑ w∈V ∑ c∈V α−c k∑",4.2 Decouple,[0],[0]
"d=0 uwdũcd
(8)
Now we show our second key design that is based on a decouple manipulation for the inner product operation.",4.2 Decouple,[0],[0]
"Interestingly, we observe that the summation operator and elements in Uw and Ũc can be rearranged by the commutative property (Dai et al., 2007), as shown below.
",4.2 Decouple,[0],[0]
L̃A = k∑ d=0 k∑ d′=0 ∑ w∈V uwduwd′,4.2 Decouple,[0],[0]
"∑ c∈V α−c ũcdũcd′
− 2r− k∑
d=0 ∑ w∈V uwd ∑ c∈V α−c ũcd
(9)
",4.2 Decouple,[0],[0]
"An important feature in Eq.(9) is that the original inner product terms are disappeared, while in the new equation ∑ c∈V α",4.2 Decouple,[0],[0]
− c ũcdũcd′ and ∑ c∈V α,4.2 Decouple,[0],[0]
− c ũcd are “constant” values relative to uwduwd′ and uwd respectively.,4.2 Decouple,[0],[0]
This means that they can be pre-calculated before training in each iteration.,4.2 Decouple,[0],[0]
"Specifically, we define pwdd′ , p c",4.2 Decouple,[0],[0]
"dd′ , q w d and q c d as the pre-calculated terms
pwdd′",4.2 Decouple,[0],[0]
=,4.2 Decouple,[0],[0]
∑,4.2 Decouple,[0],[0]
"w∈V uwduwd′ q w d = ∑ w∈V uwd
pcdd′ = ∑ c∈V α−c ũcdũcd′ q c",4.2 Decouple,[0],[0]
d = ∑ c∈V α−c ũcd (10),4.2 Decouple,[0],[0]
Then the computation of L̃A can be simplified to∑k d=0 ∑k d′=0 p w dd′p,4.2 Decouple,[0],[0]
c,4.2 Decouple,[0],[0]
dd′,4.2 Decouple,[0],[0]
"− 2r−qwd qcd.
",4.2 Decouple,[0],[0]
"It can be seen that the time complexity to compute all pwdd′ is O(|V |k2), and similarly, O(|V |k2) for pcdd′ andO(|V |k) for qwd and qcd.",4.2 Decouple,[0],[0]
"With all terms pre-calculated before each iteration, the time complexity of computing L̃A is justO(k2).",4.2 Decouple,[0],[0]
"As a result, the total time complexity of computing LA is decreased toO(2|V |k2+2|V |k+k2)",4.2 Decouple,[0],[0]
"≈ O(2|V |k2), which is much smaller than the originalO(k|V |2).",4.2 Decouple,[0],[0]
"Moreover, it’s worth noting that our efficient computation for L̃A is strictly equal to its original value, which means AllVec does not introduce any approximation in evaluating the loss function.
",4.2 Decouple,[0],[0]
"Finally, we can derive the batch gradients for
uwd and ũcd as ∂L
∂uwd = k∑ d′=0 uwd′p c dd′",4.2 Decouple,[0],[0]
"− ∑ c∈I+w Λ · ũcd − r−qcd
∂L
∂ũcd = k∑ d′=0 ũcd′p w dd′α",4.2 Decouple,[0],[0]
"− c− ∑ w∈I+c Λ · uwd − r−α−c qwd (11) where I+w denotes the set of positive contexts for w, I+c denotes the set of positive words for c and Λ = (α+wc−α−c )(∆−UwŨTc ).",4.2 Decouple,[0],[0]
"Algorithm 1 shows the training procedure of AllVec.
",4.2 Decouple,[0],[0]
"Algorithm 1 AllVec learning Input: corpus Γ, win, α0, δ, iter, learning rate η Output: embedding matrices U and Ũ
1: Build vocabulary V from Γ 2:",4.2 Decouple,[0],[0]
"Obtain all positive (w, c) and Mwc from Γ 3: Compute all r+wc, α + wc and α − c 4: Initialize U and Ũ 5: for i = 1, ..., iter do 6: for d ∈ {0, .., k} do 7: Compute and store qcd .O(|V |k) 8: for d′ ∈ {0, .., k} do 9: Compute and store pcdd′ .O(|V",4.2 Decouple,[0],[0]
"|k 2) 10: end for 11: end for 12: for w ∈ V do 13: Compute Λ .O(|S|k) 14: for d ∈ {0, .., k} do 15: Update uwd .O(|S|k + |V |k2) 16: end for 17: end for 18: Repeat 6-17 for ũcd .O(2|S|k+2|V |k2) 19: end for",4.2 Decouple,[0],[0]
"In the following, we show that AllVec can achieve the same time complexity with negative sampling based SGD methods.
",4.3 Time Complexity Analysis,[0],[0]
"Given the sample size n, the total time complexity for SG is O((n + 1)|S|k), where n + 1 denotes n negative samples and 1 positive example.",4.3 Time Complexity Analysis,[0],[0]
"Regarding the complexity of AllVec, we can see that the overall complexity of Algorithm 1 is O(4|S|k + 4|V |k2).
",4.3 Time Complexity Analysis,[0],[0]
"For the ease of discussion, we denote c as the average number of positive contexts for a word in the training corpus, i.e. |S| = c|V | (c ≥ 1000 in most cases).",4.3 Time Complexity Analysis,[0],[0]
"We then obtain the ratio
4|S|k + 4|V |k2
(n+ 1)|S|k =
4
n+ 1 (1 +
k c ) (12)
where k is typically set from 100 to 300 (Mikolov et al., 2013a; Pennington et al., 2014), resulting in k ≤ c.",4.3 Time Complexity Analysis,[0],[0]
"Hence, we can give the lower and upper bound for the ratio:
4
n+1",4.3 Time Complexity Analysis,[0],[0]
"<
",4.3 Time Complexity Analysis,[0],[0]
"4|S|k+4|V |k2
(n+1)|S|k = 4 n+1 (1+ k c )≤ 8 n+1",4.3 Time Complexity Analysis,[0],[0]
"(13)
",4.3 Time Complexity Analysis,[0],[0]
The above analysis suggests that the complexity of AllVec is same as that of SGD with negative sample size between 3 and 7.,4.3 Time Complexity Analysis,[0],[0]
"In fact, considering that c is much larger than k in most datasets, the major cost of AllVec comes from the part 4|S|k (see Section 5.4 for details), which is linear with respect to the number of positive samples.",4.3 Time Complexity Analysis,[0],[0]
"We conduct experiments on three popular evaluation tasks, namely word analogy (Mikolov et al., 2013a), word similarity (Faruqui and Dyer, 2014) and QVEC (Tsvetkov et al., 2015).
",5 Experiments,[0],[0]
Word analogy task.,5 Experiments,[0],[0]
"The task aims to answer questions like, “a is to b as c is to ?”.",5 Experiments,[0],[0]
"We adopt the Google testbed2 which contains 19, 544 such questions in two categories: semantic and syntactic.",5 Experiments,[0],[0]
"The semantic questions are usually analogies about people or locations, like “king is to man as queen is to ?”, while the syntactic questions focus on forms or tenses, e.g., “swimming is to swim as running to ?”.
",5 Experiments,[0],[0]
Word similarity tasks.,5 Experiments,[0],[0]
"We perform evaluation on six datasets, including MEN (Bruni et al., 2012), MC (Miller and Charles, 1991), RW (Luong et al., 2013), RG (Rubenstein and Goodenough, 1965), WS-353 Similarity (WSim) and Relatedness (WRel) (Finkelstein et al., 2001).",5 Experiments,[0],[0]
"We compute the spearman rank correlation between the similarity scores calculated based on the trained embeddings and human labeled scores.
QVEC.",5 Experiments,[0],[0]
QVEC is an intrinsic evaluation metric of word embeddings based on the alignment to features extracted from manually crafted lexical resources.,5 Experiments,[0],[0]
"QVEC has shown strong correlation with the performance of embeddings in several semantic tasks (Tsvetkov et al., 2015).
",5 Experiments,[0],[0]
"We compare AllVec with the following word embedding methods.
",5 Experiments,[0],[0]
"• SG: This is the original skip-gram model with SGD and negative sampling (Mikolov et al., 2013a,b).",5 Experiments,[0],[0]
"• SGA: This is the skip-gram model with an
adaptive sampler (Chen et al., 2018).",5 Experiments,[0],[0]
"2https://code.google.com/archive/p/word2vec/
For all baselines, we use the original implementation released by the authors.",5 Experiments,[0],[0]
"We evaluate the performance of AllVec on four real-world corpora, namely Text83, NewsIR4, Wiki-sub and Wiki-all.",5.1 Datasets and Experimental Setup,[0],[0]
Wiki-sub is a subset of 2017 Wikipedia dump5.,5.1 Datasets and Experimental Setup,[0],[0]
"All corpora have been pre-processed by a standard pipeline (i.e. removing non-textual elements, lowercasing and tokenization).",5.1 Datasets and Experimental Setup,[0],[0]
"Table 1 summarizes the statistics of these corpora.
",5.1 Datasets and Experimental Setup,[0],[0]
"To obtain Mwc for positive (w, c) pairs, we follow GloVe where word pairs that are xwords apart contribute 1/x to Mwc.",5.1 Datasets and Experimental Setup,[0],[0]
The window size is set as win = 8.,5.1 Datasets and Experimental Setup,[0],[0]
"Regarding α+wc, we set xmax = 100 and ρ = 0.75.",5.1 Datasets and Experimental Setup,[0],[0]
"For a fair comparison, the embedding size k is set as 200 for all models and corpora.",5.1 Datasets and Experimental Setup,[0],[0]
"AllVec can be easily trained by AdaGrad (Zeiler, 2012) like GloVe or Newton-like (Bayer et al., 2017; Bradley et al., 2011) second order methods.",5.1 Datasets and Experimental Setup,[0],[0]
"For models based on negative sampling (i.e. SG, SGA and LexVec), the sample size is set as n = 25 for Text8, n = 10 for NewsIR and n = 5 for Wiki-sub and Wiki-all.",5.1 Datasets and Experimental Setup,[0],[0]
The setting is also suggested by Mikolov et al. (2013b).,5.1 Datasets and Experimental Setup,[0],[0]
Other detailed hyper-parameters are reported in Table 2.,5.1 Datasets and Experimental Setup,[0],[0]
We present results on the word analogy task in Table 2.,5.2 Accuracy Comparison,[0],[0]
"As shown, AllVec achieves the highest total accuracy (Tot.) in all corpora, particu-
3http://mattmahoney.net/dc/text8.zip 4http://research.signalmedia.co/newsir16/signal-
dataset.html 5https://dumps.wikimedia.org/enwiki/
larly in smaller corpora (Text8 and NewsIR).",5.2 Accuracy Comparison,[0],[0]
"The reason is that in smaller corpora the number of positive (w, c) pairs is very limited, thus making use of negative examples will bring more benefits.",5.2 Accuracy Comparison,[0],[0]
"Similar reason also explains the poor accuracy of GloVe in Text8, because GloVe does not consider negative samples.",5.2 Accuracy Comparison,[0],[0]
"Even in the very large corpus (Wiki-all), ignoring negative samples still results in sub-optimal performance.
",5.2 Accuracy Comparison,[0],[0]
"Our results also show that SGA achieves better performance than SG, which demonstrates the importance of a good sampling strategy.",5.2 Accuracy Comparison,[0],[0]
"However, regardless what sampler (except the full softmax sampling) is utilized and how many updates are taken, sampling is still a biased approach.",5.2 Accuracy Comparison,[0],[0]
"AllVec achieves the best performance because it is trained on the whole batch data for each parameter update rather than a fraction of sampled data.
",5.2 Accuracy Comparison,[0],[0]
Another interesting observation is AllVec performs better in semantic tasks in general.,5.2 Accuracy Comparison,[0],[0]
"The reason is that our model utilizes global co-occurrence statistics, which capture more semantic signals than syntactic signals.",5.2 Accuracy Comparison,[0],[0]
"While both AllVec and GloVe use global contexts, AllVec performs much better than GloVe in syntactic tasks.",5.2 Accuracy Comparison,[0],[0]
"We argue that the main reason is because AllVec can distill useful signals from negative examples, while GloVe simply ignores all negative information.",5.2 Accuracy Comparison,[0],[0]
"By contrast, local-window based methods, such as SG and SGA, are more effective to capture local sentence features, resulting in good performance on syntactic analogies.",5.2 Accuracy Comparison,[0],[0]
"However, Rekabsaz et al. (2017) argues that these local-window based methods may suffer from the topic shifting issue.
",5.2 Accuracy Comparison,[0],[0]
Table 3 and Table 4 provide results in the word similarity and QVEC tasks.,5.2 Accuracy Comparison,[0],[0]
"We can see that AllVec achieves the best performance in most tasks, which admits the advantage of batch learning with all samples.",5.2 Accuracy Comparison,[0],[0]
"Interestingly, although GloVe performs well in semantic analogy tasks, it shows extremely worse results in word similarity and QVEC.",5.2 Accuracy Comparison,[0],[0]
The reason shall be the same as that it performs poorly in syntactic tasks.,5.2 Accuracy Comparison,[0],[0]
"In this subsection, we investigate the impact of the proposed weighting scheme for negative (context) words.",5.3 Impact of α−c,[0],[0]
We show the performance change of word analogy tasks on NewsIR in Figure 2 by tuning α0 and δ.,5.3 Impact of α−c,[0],[0]
"Results in other corpora show similar trends thus are omitted due to space limitation.
",5.3 Impact of α−c,[0],[0]
"Table 2: Results (“Tot.” denotes total accuracy) on the word analogy task.
",5.3 Impact of α−c,[0],[0]
"Corpus Text8 NewsIR
para.",5.3 Impact of α−c,[0],[0]
Sem.,5.3 Impact of α−c,[0],[0]
Syn.,5.3 Impact of α−c,[0],[0]
Tot.,5.3 Impact of α−c,[0],[0]
para.,5.3 Impact of α−c,[0],[0]
Sem.,5.3 Impact of α−c,[0],[0]
Syn.,5.3 Impact of α−c,[0],[0]
"Tot.
SG 1e-4 8 25 47.51 32.26 38.60 1e-5 10 10 70.81 47.48 58.10 SGA 6e-3 - - 48.10 33.78 39.74 6e-3 - - 71.74 48.71 59.20 GloVe 10 15 1 45.11 26.89 34.47 50 8 1 78.79 41.58 58.52 LexVec 1e-4 25 - 51.87 31.78 40.14 1e-5 10 - 76.11 39.09 55.95 AllVec 350 0.75 - 56.66 32.42 42.50 100 0.8 - 78.47 48.33 61.57
Wiki-sub Wiki-all
SG 1e-5 10 5 72.05 55.88 63.24 1e-5 10 5 73.91 61.91 67.37 SGA 6e-3 - - 73.93 56.10 63.81 6e-3 - - 75.11 61.94 67.92 GloVe 100 8 1 77.22 53.16 64.13 100 8 1 77.38 58.94 67.33 LexVec 1e-5 5 - 75.95 52.78 63.33 1e-5 5 - 76.31 56.83 65.48 AllVec 100 0.75 - 76.66 54.72 64.75 50 0.75 - 77.64 60.96 68.52
The parameter columns (para.)",5.3 Impact of α−c,[0],[0]
for each model are given from left to right as follows.,5.3 Impact of α−c,[0],[0]
"SG: subsampling of frequent words, window size and the number of negative samples; SGA: λ (Chen et al., 2018) that controls the distribution of the rank, the other parameters are the same with SG; GloVe:",5.3 Impact of α−c,[0],[0]
"xmax, window size and symmetric window; LexVec: subsampling of frequent words and the number of negative samples; AllVec: the negative weight α0 and δ.",5.3 Impact of α−c,[0],[0]
"Boldface denotes the highest total accuracy.
",5.3 Impact of α−c,[0],[0]
Figure 2(a) shows the impact of the overall weight α0 by setting δ as 0.75 (inspired by the setting of skip-gram).,5.3 Impact of α−c,[0],[0]
"Clearly, we observe that all results (including semantic, syntactic and total accuracy) have been greatly improved when α0 increases from 0 to a larger value.",5.3 Impact of α−c,[0],[0]
"As mentioned before, α0 = 0 means that no negative information is considered.",5.3 Impact of α−c,[0],[0]
This observation verifies that negative samples are very important for learning good embeddings.,5.3 Impact of α−c,[0],[0]
It also helps to explain why GloVe performs poorly on syntactic tasks.,5.3 Impact of α−c,[0],[0]
"In addition, we find that in all corpora the optimal results are usually obtained when α0 falls in the range of 50 to 400.",5.3 Impact of α−c,[0],[0]
"For example, in the NewIR corpus as shown, AllVec achieves the best performance when α0 = 100.",5.3 Impact of α−c,[0],[0]
Figure 2(b) shows the impact of δ with α0 = 100.,5.3 Impact of α−c,[0],[0]
"As mentioned before, δ = 0 denotes a uniform value for all negative words and δ = 1 denotes that no smoothing is applied to word frequency.",5.3 Impact of α−c,[0],[0]
We can see that the total accuracy is only around 55% when δ = 0.,5.3 Impact of α−c,[0],[0]
"By increasing its value, the performance is gradually improved, achieving the highest score when δ is around 0.8.",5.3 Impact of α−c,[0],[0]
Further increase of δ will degrade the total accuracy.,5.3 Impact of α−c,[0],[0]
This analysis demonstrates the effectiveness of the proposed negative weighting scheme.,5.3 Impact of α−c,[0],[0]
Figure 3(a) compares the convergence between AllVec and GloVe on NewsIR.,5.4 Convergence Rate and Runtime,[0],[0]
"Clearly, AllVec ex-
hibits a more stable convergence due to its full batch learning.",5.4 Convergence Rate and Runtime,[0],[0]
"In contrast, GloVe has a more dramatic fluctuation because of the one-sample learning scheme.",5.4 Convergence Rate and Runtime,[0],[0]
Figure 3(b) shows the relationship between the embedding size k and runtime on NewsIR.,5.4 Convergence Rate and Runtime,[0],[0]
"Although the analysis in Section 4.3 demonstrates that the time complexity of AllVec is O(4|S|k + 4|V |k2), the actual runtime shows a near linear relationship with k.",5.4 Convergence Rate and Runtime,[0],[0]
"This is because 4|V |k2/4|S|k = k/c, where c generally ranges from 1000 ∼ 6000 and k is set from 200 to 300 in practice.",5.4 Convergence Rate and Runtime,[0],[0]
"The above ratio explains the fact that 4|S|k dominates the complexity, which is linear
with k and |S|.",5.4 Convergence Rate and Runtime,[0],[0]
We also compare the overall runtime of AllVec and SG on NewsIR and show the results in Table 5.,5.4 Convergence Rate and Runtime,[0],[0]
"As can be seen, the runtime of AllVec falls in the range of SG-3 and SG-7 in a single iteration, which confirms the theoretical analysis in Section 4.3.",5.4 Convergence Rate and Runtime,[0],[0]
"In contrast with SG, AllVec needs more iterations to converge.",5.4 Convergence Rate and Runtime,[0],[0]
"The reason is that each parameter in SG is updated many times during each iteration, although only one training example is used in each update.",5.4 Convergence Rate and Runtime,[0],[0]
"Despite this, the total run time of AllVec is still in a feasible range.",5.4 Convergence Rate and Runtime,[0],[0]
"Assuming the convergence is measured by the number of parameter updates, our AllVec yields a much faster convergence rate than the one-sample SG method.
",5.4 Convergence Rate and Runtime,[0],[0]
"In practice, the runtime of our model in each iteration can be further reduced by increasing the number of parallel workers.",5.4 Convergence Rate and Runtime,[0],[0]
"Although baseline methods like SG and GloVe can also be parallelized, the stochastic gradient steps in these methods unnecessarily influence each other as there is no exact way to separate these updates for different workers.",5.4 Convergence Rate and Runtime,[0],[0]
"In other words, the parallelization of SGD is not well suited to a large number of work-
ers.",5.4 Convergence Rate and Runtime,[0],[0]
"In contrast, the parameter updates in AllVec are completely independent of each other, therefore AllVec does not have the update collision issue.",5.4 Convergence Rate and Runtime,[0],[0]
"This means we can achieve the embarrassing parallelization by simply separating the updates by words; that is, letting different workers update the model parameters for disjoint sets of words.",5.4 Convergence Rate and Runtime,[0],[0]
"As such, AllVec can provide a near linear scaling without any approximation since there is no potential conflicts between updates.",5.4 Convergence Rate and Runtime,[0],[0]
"In this paper, we presented AllVec, an efficient batch learning based word embedding model that is capable to leverage all positive and negative training examples without any sampling and approximation.",6 Conclusion,[0],[0]
"In contrast with models based on SGD and negative sampling, AllVec shows more stable convergence and better embedding quality by the all-sample optimization.",6 Conclusion,[0],[0]
"Besides, both theoretical analysis and experiments demonstrate that AllVec achieves the same time complexity with the classic SGD models.",6 Conclusion,[0],[0]
"In future, we will extend
our proposed all-sample learning scheme to deep learning methods, which are more expressive than the shallow embedding model.",6 Conclusion,[0],[0]
"Moreover, we will integrate prior knowledge, such as the words that are synonyms and antonyms, into the word embedding process.",6 Conclusion,[0],[0]
"Lastly, we are interested in exploring the recent adversarial learning techniques to enhance the robustness of word embeddings.
",6 Conclusion,[0],[0]
Acknowledgements.,6 Conclusion,[0],[0]
"This research is supported by the National Research Foundation, Prime Minister’s Office, Singapore under its IRC@SG Funding Initiative.",6 Conclusion,[0],[0]
Joemon M.Jose and Xiangnan,6 Conclusion,[0],[0]
He are corresponding authors.,6 Conclusion,[0],[0]
Stochastic Gradient Descent (SGD) with negative sampling is the most prevalent approach to learn word representations.,abstractText,[0],[0]
"However, it is known that sampling methods are biased especially when the sampling distribution deviates from the true data distribution.",abstractText,[0],[0]
"Besides, SGD suffers from dramatic fluctuation due to the onesample learning scheme.",abstractText,[0],[0]
"In this work, we propose AllVec that uses batch gradient learning to generate word representations from all training samples.",abstractText,[0],[0]
"Remarkably, the time complexity of AllVec remains at the same level as SGD, being determined by the number of positive samples rather than all samples.",abstractText,[0],[0]
We evaluate AllVec on several benchmark tasks.,abstractText,[0],[0]
"Experiments show that AllVec outperforms samplingbased SGD methods with comparable efficiency, especially for small training corpora.",abstractText,[0],[0]
Batch IS NOT Heavy: Learning Word Representations From All Samples,title,[0],[0]
Optimization is one of the fundamental pillars of modern machine learning.,1. Introduction,[0],[0]
"Considering that most modern machine learning methods involve the solution of some optimization problem, it is not surprising that many recent breakthroughs in this area have been on the back of more effective techniques for optimization.",1. Introduction,[0],[0]
"A case in point is deep learning, whose rise has been mirrored by the development of numerous techniques like batch normalization.
",1. Introduction,[0],[0]
"While modern algorithms have been shown to be very
*Equal contribution 1Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Massachusetts, USA 2DeepMind, London, UK.",1. Introduction,[0],[0]
"Correspondence to: Zi Wang <ziw@csail.mit.edu>, Chengtao Li <ctli@mit.edu>, Stefanie Jegelka <stefje@csail.mit.edu>, Pushmeet Kohli <pushmeet@google.com>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
effective for convex optimization problems defined over continuous domains, the same cannot be stated for nonconvex optimization, which has generally been dominated by stochastic techniques.",1. Introduction,[0],[0]
"During the last decade, Bayesian optimization has emerged as a popular approach for optimizing black-box functions.",1. Introduction,[0],[0]
"However, its applicability is limited to low-dimensional problems because of computational and statistical challenges that arise from optimization in high-dimensional settings.
",1. Introduction,[0],[0]
"In the past, these two problems have been addressed by assuming a simpler underlying structure of the black-box function.",1. Introduction,[0],[0]
"For instance, Djolonga et al. (2013) assume that the function being optimized has a low-dimensional effective subspace, and learn this subspace via low-rank matrix recovery.",1. Introduction,[0],[0]
"Similarly, Kandasamy et al. (2015) assume additive structure of the function where different constituent functions operate on disjoint low-dimensional subspaces.",1. Introduction,[0],[0]
The subspace decomposition can be partially optimized by searching possible decompositions and choosing the one with the highest GP marginal likelihood (treating the decomposition as a hyper-parameter of the GP).,1. Introduction,[0],[0]
"Fully optimizing the decomposition is, however, intractable.",1. Introduction,[0],[0]
"Li et al. (2016) extended (Kandasamy et al., 2015) to functions with a projected-additive structure, and approximate the projective matrix via projection pursuit with the assumption that the projected subspaces have the same and known dimensions.",1. Introduction,[0],[0]
The aforementioned approaches share the computational challenge of learning the groups of decomposed subspaces without assuming the dimensions of the subspaces are known.,1. Introduction,[0],[0]
"Both (Kandasamy et al., 2015) and subsequently (Li et al., 2016) adapt the decomposition by maximizing the GP marginal likelihood every certain number of iterations.",1. Introduction,[0],[0]
"However, such maximization is computationally intractable due to the combinatorial nature of the partitions of the feature space, which forces prior work to adopt randomized search heuristics.
",1. Introduction,[0],[0]
"In this paper, we develop a new formulation of Bayesian optimization specialized for high dimensions.",1. Introduction,[0],[0]
"One of the key contributions of this work is a new formulation that interprets prior work on high-dimensional Bayesian optimization (HDBO) through the lens of structured kernels, and places a prior on the kernel structure.",1. Introduction,[0],[0]
"Thereby, our
formulation enables simultaneous learning of the decomposition of the function domain.
",1. Introduction,[0],[0]
Prior work on latent decomposition of the feature space considers the setting where exploration/evaluation is performed once at a time.,1. Introduction,[0],[0]
"This approach makes Bayesian optimization time-consuming for problems where a large number of function evaluations need to be made, which is the case for high dimensional problems.",1. Introduction,[0],[0]
"To overcome this restriction, we extend our approach to a batched version that allows multiple function evaluations to be performed in parallel (Desautels et al., 2014; González et al., 2016; Kathuria et al., 2016).",1. Introduction,[0],[0]
"Our second contribution is an approach to select the batch of evaluations for structured kernel learning-based HDBO.
",1. Introduction,[0],[0]
Other Related Work.,1. Introduction,[0],[0]
"In the past half century, a series of different acquisition functions was developed for sequential BO in relatively low dimensions (Kushner, 1964; Moc̆kus, 1974; Srinivas et al., 2012; Hennig & Schuler, 2012; Hernández-Lobato et al., 2014; Kawaguchi et al., 2015; Wang et al., 2016a; Kawaguchi et al., 2016; Wang & Jegelka, 2017).",1. Introduction,[0],[0]
"More recent developments address high dimensional BO by making assumptions on the latent structure of the function to be optimized, such as lowdimensional structure (Wang et al., 2016b; Djolonga et al., 2013) or additive structure of the function (Li et al., 2016; Kandasamy et al., 2015).",1. Introduction,[0],[0]
"Duvenaud et al. (2013) explicitly search over kernel structures.
",1. Introduction,[0],[0]
"While the aforementioned methods are sequential in nature, the growth of computing power has motivated settings where at once a batch of points is selected for observation (Contal et al., 2013; Desautels et al., 2014; González et al., 2016; Snoek et al., 2012; Wang et al., 2017).",1. Introduction,[0],[0]
"For example, the UCB-PE algorithm (Contal et al., 2013) exploits that the posterior variance of a Gaussian Process is independent of the function mean.",1. Introduction,[0],[0]
"It greedily selects points with the highest posterior variance, and is able to update the variances without observations in between selections.",1. Introduction,[0],[0]
"Similarly, B-UCB (Desautels et al., 2014) greedily chooses points with the highest UCB score computed via the out-dated function mean but up-to-date function variances.",1. Introduction,[0],[0]
"However, these methods may be too greedy in their selection, resulting in points that lie far from an optimum.",1. Introduction,[0],[0]
"More recently, Kathuria et al. (2016) tries to resolve this issue by sampling the batch via a diversity-promoting distribution for better randomized exploration, while Wang et al. (2017) quantifies the goodness of the batch with a submodular surrogate function that trades off quality and diversity.",1. Introduction,[0],[0]
Let f : X → R be an unknown function and we aim to optimize it over a compact set X ⊆ RD.,2. Background,[0],[0]
"Within as few
function evaluations as possible, we want to find
f(x∗) = max x∈X f(x).
",2. Background,[0],[0]
"Following (Kandasamy et al., 2015), we assume a latent decomposition of the feature dimensions [D] = {1, . . .",2. Background,[0],[0]
", D} into disjoint subspaces, namely, ⋃M m=1Am = [D] and Ai ∩ Aj = ∅ for all i 6= j, i, j ∈",2. Background,[0],[0]
[D].,2. Background,[0],[0]
"Further, f can be decomposed into the following additive form:
f(x) = ∑
m∈[M ]
fm(x Am).
",2. Background,[0],[0]
"To make the problem tractable, we assume that each fm is drawn independently from GP(0, k(m)) for all m ∈",2. Background,[0],[0]
[M ].,2. Background,[0],[0]
"The resulting f will also be a sample from a GP: f ∼ GP(µ, k), where the priors are µ(x) = ∑ m∈[M ] µm(x",2. Background,[0],[0]
"Am)
and k(x, x′) = ∑ m∈[M ] k (m)(xAm , x′ Am).",2. Background,[0],[0]
"Let Dn = {(xt, yt)}nt=1 be the data we observed from f , where yt ∼ N (f(xt), σ).",2. Background,[0],[0]
"The log data likelihood for Dn is
log p(Dn|{k(m), Am}m∈[M ]) (2.1)
",2. Background,[0],[0]
= −1 2 (yT(Kn + σ,2. Background,[0],[0]
2I)−1y + log |Kn + σ2I|+ n,2. Background,[0],[0]
"log 2π)
",2. Background,[0],[0]
where Kn =,2. Background,[0],[0]
"[∑M m=1 k (m)(xAmi , x Am j ) ]",2. Background,[0],[0]
"i≤n,j≤n is the gram matrix associated with Dn, and y =",2. Background,[0],[0]
[yt]t≤n are the concatenated observed function values.,2. Background,[0],[0]
"Conditioned on the observations Dn, we can infer the posterior mean and covariance function of the function component f (m) to be
µ(m)n (x Am) =",2. Background,[0],[0]
"k(m)n (x Am)T(Kn + σ 2I)−1y,
k(m)n (x Am , x′ Am) = k(m)(xAm , x′ Am)
",2. Background,[0],[0]
− k(m)n (xAm)T(Kn + σ2I)−1k(m)n,2. Background,[0],[0]
"(x′ Am),
where k(m)n (xAm) =",2. Background,[0],[0]
"[k(m)(xAmt , x Am)]t≤n.
",2. Background,[0],[0]
"We use regret to evaluate the BO algorithms, both in the sequential and the batch selection case.",2. Background,[0],[0]
"For the sequential selection, let r̃t = maxx∈X f(x) − f(xt) denote the immediate regret at iteration t. We are interested in both the averaged cumulative regret RT = 1T ∑ t r̃t and the simple regret rT = mint≤T r̃t for a total number of T iterations.",2. Background,[0],[0]
"For batch evaluations, r̃t = maxx∈X ,b∈[B] f(x) − f(xt,b) denotes the immediate regret obtained by the batch at iteration t. The averaged cumulative regret of the batch setting is RT = 1T ∑ t r̃t, and the simple regret rT = mint≤T r̃t.",2. Background,[0],[0]
"We use the averaged cumulative regret in the bandit setting, where each evaluation of the function incurs a cost.",2. Background,[0],[0]
"If we simply want to optimize the function, we use the simple regret to capture the minimum gap between the best point found and the global optimum of the black-box function f .",2. Background,[0],[0]
Note that the averaged cumulative regret upper bounds the simple regret.,2. Background,[0],[0]
We take a Bayesian view on the task of learning the latent structure of the GP kernel.,3. Learning Additive Kernel Structure,[0],[0]
The decomposition of the input space X will be learned simultaneously with optimization as more and more data is observed.,3. Learning Additive Kernel Structure,[0],[0]
Our generative model draws mixing proportions θ ∼ DIR(α).,3. Learning Additive Kernel Structure,[0],[0]
Each dimension j is assigned to one out of M groups via the decomposition assignment variable zj ∼ MULTI(θ).,3. Learning Additive Kernel Structure,[0],[0]
"The objective function is then f(x) = ∑M m=1 fm(x
Am), where Am = {j : zj = m} is the set of support dimensions for function fm, and each fm is drawn from a Gaussian Process.",3. Learning Additive Kernel Structure,[0],[0]
"Finally, given an input x, we observe y ∼ N (f(x), σ).",3. Learning Additive Kernel Structure,[0],[0]
"Figure 1 illustrates the corresponding graphical model.
",3. Learning Additive Kernel Structure,[0],[0]
"Given the observed data Dn = {(xt, yt)}nt=1, we obtain a posterior distribution over possible decompositions z (and mixing proportions θ) that we will include later in the BO process:
p(z, θ | Dn;α) ∝",3. Learning Additive Kernel Structure,[0],[0]
p(Dn |,3. Learning Additive Kernel Structure,[0],[0]
z)p(z,3. Learning Additive Kernel Structure,[0],[0]
"| θ)p(θ;α).
",3. Learning Additive Kernel Structure,[0],[0]
"Marginalizing over θ yields the posterior distribution of the decomposition assignment
p(z | Dn;α) ∝",3. Learning Additive Kernel Structure,[0],[0]
p(Dn,3. Learning Additive Kernel Structure,[0],[0]
| z) ∫,3. Learning Additive Kernel Structure,[0],[0]
p(z | θ)p(θ;α),3. Learning Additive Kernel Structure,[0],[0]
"dθ
∝ p(Dn",3. Learning Additive Kernel Structure,[0],[0]
| z),3. Learning Additive Kernel Structure,[0],[0]
"Γ( ∑ m αm)
Γ(D + ∑ m αm)",3. Learning Additive Kernel Structure,[0],[0]
∏,3. Learning Additive Kernel Structure,[0],[0]
"m Γ(|Am|+ αm) Γ(αm)
where p(Dn|z) is the data likelihood (2.1) for the additive GP given a fixed structure defined by",3. Learning Additive Kernel Structure,[0],[0]
"z. We learn the posterior distribution for z via Gibbs sampling, choose the decomposition among the samples that achieves the highest data likelihood, and then proceed with BO.",3. Learning Additive Kernel Structure,[0],[0]
"The Gibbs sampler repeatedly draws coordinate assignments zj according to
p(zj = m | z¬j ,Dn; α) ∝ p(Dn",3. Learning Additive Kernel Structure,[0],[0]
| z)p(zj | z¬j) ∝,3. Learning Additive Kernel Structure,[0],[0]
"p(Dn | z)(|Am|+ αm) ∝ eφm ,
where
φm = − 1
2 yT(K(zj=m)n + σ",3. Learning Additive Kernel Structure,[0],[0]
"2I)−1y
− 1 2 log |K(zj=m)n + σ2I|+ log(|Am|+ αm)
and K(zj=m)n is the gram matrix associated with the observations Dn by setting zj = m. We can use the Gumbel trick to efficiently sample from this categorical distribution.",3. Learning Additive Kernel Structure,[0],[0]
"Namely, we sample a vector of i.i.d standard Gumbel variables ωi of length M , and then choose the sampled decomposition assignment zj = arg maxi≤M φi + ωi.
",3. Learning Additive Kernel Structure,[0],[0]
"With a Dirichlet process, we could make the model nonparametric and the number M of possible groups in the decomposition infinite.",3. Learning Additive Kernel Structure,[0],[0]
"Given that we have a fixed number of input dimension D, we set M = D in practice.",3. Learning Additive Kernel Structure,[0],[0]
"In real-world applications where function evaluations translate into time-intensive experiments, the typical sequential exploration strategy – observe one function value, update the model, then select the next observation – is undesirable.",4. Diverse Batch Sampling,[0],[0]
"Batched Bayesian Optimization (BBO) (Azimi et al., 2010; Contal et al., 2013; Kathuria et al., 2016) instead selects a batch of B observations to be made in parallel, then the model is updated with all simultaneously.
",4. Diverse Batch Sampling,[0],[0]
"Extending this scenario to high dimensions, two questions arise: (1) the acquisition function is expensive to optimize and (2), by itself, does not sufficiently account for exploration.",4. Diverse Batch Sampling,[0],[0]
The additive kernel structure improves efficiency for (1).,4. Diverse Batch Sampling,[0],[0]
"For batch selection (2), we need an efficient strategy that enourages observations that are both informative and non-redundant.",4. Diverse Batch Sampling,[0],[0]
"Recent work (Contal et al., 2013; Kathuria et al., 2016) selects a point that maximizes the acquisition function, and adds additional batch points via a diversity criterion.",4. Diverse Batch Sampling,[0],[0]
"In high dimensions, this diverse selection becomes expensive.",4. Diverse Batch Sampling,[0],[0]
"For example, if each dimension has a finite number of possible values1, the cost of sampling batch points via a Determinantal Point Process (DPP), as proposed in (Kathuria et al., 2016), grows exponentially with the number of dimensions.",4. Diverse Batch Sampling,[0],[0]
"The same obstacle arises with the approach by Contal et al. (2013), where points are selected greedily.",4. Diverse Batch Sampling,[0],[0]
"Thus, naı̈ve adoptions of these approaches in our setting would result in intractable algorithms.",4. Diverse Batch Sampling,[0],[0]
"Instead, we propose a general approach that explicitly takes advantage of the structured kernel to enable relevant, non-redundant high-dimensional batch selection.
",4. Diverse Batch Sampling,[0],[0]
We describe our approach for a single decomposition sampled from the posterior; it extends to a distribution of decompositions by sampling a set of decompositions from the posterior and then sampling points for each decomposition individually.,4. Diverse Batch Sampling,[0],[0]
"Given a decomposition z, we define a separate Determinantal Point Process (DPP) on each group of Am dimensions.",4. Diverse Batch Sampling,[0],[0]
"A set S of points in the subspace R|Am| is sampled with probability proportional to det(K(m)n (S)),
1While we use this discrete categorical domain to illustrate the batch setting, our proposed method is general and is applicable to continuous box-constrained domains.
where K(m)n is the posterior covariance matrix of the mth group given n observations, and K(S) is the submatrix of K with rows and columns indexed by S. Assuming the group sizes are upper-bounded by some constant, sampling from each such DPP individually implies an exponential speedup compared to using the full kernel.
",4. Diverse Batch Sampling,[0],[0]
Sampling vs. Greedy Maximization The determinant det(K (m) n,4. Diverse Batch Sampling,[0],[0]
"(S)) measures diversity, and hence the DPP assigns higher probability to diverse subsets S. An alternative to sampling is to directly maximize the determinant.",4. Diverse Batch Sampling,[0],[0]
"While this is NP-hard, a greedy strategy gives an approximate solution, and is used in (Kathuria et al., 2016), and in (Contal et al., 2013) as Pure Exploration (PE).",4. Diverse Batch Sampling,[0],[0]
We too test this strategy in the experiments.,4. Diverse Batch Sampling,[0],[0]
"In the beginning, if the GP is not approximating the function well, then greedy may perform no better than a stochastic combination of coordinates, as we observe in Fig. 6.
",4. Diverse Batch Sampling,[0],[0]
Sample Combination Now we have chosen a diverse subset Xm = {x(m)i }i∈[B−1],4. Diverse Batch Sampling,[0],[0]
⊂,4. Diverse Batch Sampling,[0],[0]
R|Am| of size (B − 1) for each group Am.,4. Diverse Batch Sampling,[0],[0]
We need to combine these subspace points to obtain B − 1 final batch query points in RD.,4. Diverse Batch Sampling,[0],[0]
"A simple way to combine samples from each group is to do it randomly without replacement, i.e., we sample one x (m) i from each Xm uniformly randomly without replacement, and combine the parts, one for each m ∈",4. Diverse Batch Sampling,[0],[0]
"[M ], to get one sample in RD.",4. Diverse Batch Sampling,[0],[0]
We repeat this procedure until we have (B − 1) points.,4. Diverse Batch Sampling,[0],[0]
"This retains diversity across the batch of samples, since the samples are diverse within each group of features.
",4. Diverse Batch Sampling,[0],[0]
"Besides this random combination, we can also combine samples greedily.",4. Diverse Batch Sampling,[0],[0]
We define a quality function ψ(m)t for each group m ∈,4. Diverse Batch Sampling,[0],[0]
"[M ] at time t, and combine samples to maximize this quality function.",4. Diverse Batch Sampling,[0],[0]
"Concretely, for the first point, we combine the maximizers x(m)∗ = arg maxx(m)∈Xm ψ",4. Diverse Batch Sampling,[0],[0]
"(m) t (x
(m)) from each group.",4. Diverse Batch Sampling,[0],[0]
"We remove those used parts, Xm ← Xm\{x(m)∗ }, and repeat the procedure until we have (B − 1) samples.",4. Diverse Batch Sampling,[0],[0]
"In each iteration, the sample achieving the highest quality score gets selected, while diversity is retained.
",4. Diverse Batch Sampling,[0],[0]
"Both selection strategies can be combined with a wide range of existing quality and acquisition functions.
",4. Diverse Batch Sampling,[0],[0]
"Add-UCB-DPP-BBO We illustrate the above framework with GP-UCB (Srinivas et al., 2012) as both the acquisition and quality functions.",4. Diverse Batch Sampling,[0],[0]
The Upper Confidence Bound (f (m)t ) + and Lower Confidence Bound (f (m)t ),4. Diverse Batch Sampling,[0],[0]
"− with parameter βt for group m at time t are
(f (m) t )",4. Diverse Batch Sampling,[0],[0]
+(x) = µ (m) t−1(x) +,4. Diverse Batch Sampling,[0],[0]
β 1/2 t σ,4. Diverse Batch Sampling,[0],[0]
"(m) t (x); (4.1)
(f (m) t ) −(x) = µ (m) t−1(x)− β 1/2 t σ",4. Diverse Batch Sampling,[0],[0]
"(m) t (x),
and combine the expected value µ(m)t−1(x) of f (m) t with the uncertainty β1/2t σ (m) t (x).",4. Diverse Batch Sampling,[0],[0]
"We set both the acquisition function and quality function ψ(m)t to be (f (m) t )
+ for group m at time t.
To ensure that we select points with high acquisition function values, we follow (Contal et al., 2013; Kathuria et al., 2016) and define a relevance region R(m)t for each group m as
R(m)t = {x ∈",4. Diverse Batch Sampling,[0],[0]
"Xm |
µ (m) t−1(x) + 2 √ β (m) t+1σ",4. Diverse Batch Sampling,[0],[0]
(m) t−1(x) ≥ (y (m) t ),4. Diverse Batch Sampling,[0],[0]
"• } ,
where (y(m)t ) • = maxx(m)∈Xm(f (m) t ) −(x(m)).",4. Diverse Batch Sampling,[0],[0]
We then use R(m)t as the ground set to sample with PE/DPP.,4. Diverse Batch Sampling,[0],[0]
The full algorithm is shown in the appendix.,4. Diverse Batch Sampling,[0],[0]
"We empirically evaluate our approach in two parts: First, we verify the effectiveness of using our Gibbs sampling algorithm to learn the additive structure of the unknown function, and then we test our batch BO for high dimensional problems with the Gibbs sampler.",5. Empirical Results,[0],[0]
Our code is available at https://github.com/zi-w/ Structural-Kernel-Learning-for-HDBBO.,5. Empirical Results,[0],[0]
We first probe the effectiveness of using the Gibbs sampling method described in Section 3 to learn the decomposition of the input space.,5.1. Effectiveness of Decomposition Learning,[0],[0]
"More details of the experiments including sensitivity analysis for α can be found in the appendix.
",5.1. Effectiveness of Decomposition Learning,[0],[0]
"Recovering Decompositions First, we sample test functions from a known additive Gaussian Process prior with zero-mean and isotropic Gaussian kernel with bandwidth = 0.1 and scale = 5 for each function component.",5.1. Effectiveness of Decomposition Learning,[0],[0]
"For D = 2, 5, 10, 20, 50, 100 input dimensions, we randomly sample decomposition settings that have at least two groups in the decomposition and at most 3 dimensions in each group.
",5.1. Effectiveness of Decomposition Learning,[0],[0]
"We set the burn-in period to be 50 iterations, and the total number of iterations for Gibbs sampling to be 100.",5.1. Effectiveness of Decomposition Learning,[0],[0]
"In Tables 1 and 2, we show two quantities that are closely related
to the learned empirical posterior of the decompositions with different numbers of randomly sampled observed data points (N ).",5.1. Effectiveness of Decomposition Learning,[0],[0]
"Table 1 shows the probability of two dimensions being correctly grouped together by Gibbs sampling in each iteration of Gibbs sampling after the burn-in period, namely, ( ∑ i<j≤D 1zgi≡z g j∧zi≡zj )/",5.1. Effectiveness of Decomposition Learning,[0],[0]
( ∑ i<j≤D 1zi≡zj ).,5.1. Effectiveness of Decomposition Learning,[0],[0]
"Table 2 reports the probability of two dimensions being correctly separated in each iteration of Gibbs sampling after the burn-in period, namely, ( ∑ i<j≤D 1zgi 6=z g j∧zi 6=zj )/",5.1. Effectiveness of Decomposition Learning,[0],[0]
( ∑ i<j≤D 1zi 6=zj ).,5.1. Effectiveness of Decomposition Learning,[0],[0]
"The results show that the more data we observe, the more accurate the learned decompositions are.",5.1. Effectiveness of Decomposition Learning,[0],[0]
They also suggest that the Gibbs sampling procedure can converge to the ground truth decomposition with enough data for relatively small numbers of dimensions.,5.1. Effectiveness of Decomposition Learning,[0],[0]
"The higher the dimension, the more data we need to recover the true decomposition.
",5.1. Effectiveness of Decomposition Learning,[0],[0]
"Effectiveness of Learning Decompositions for Bayesian Optimization To verify the effectiveness of the learned decomposition for Bayesian optimization, we tested on 2, 10, 20 and 50 dimensional functions sampled from a zero-mean Add-GP with randomly sampled decomposi-
tion settings (at least two groups, at most 3 dimensions in each group) and isotropic Gaussian kernel with bandwidth = 0.1 and scale = 5.",5.1. Effectiveness of Decomposition Learning,[0],[0]
Each experiment was repeated 50 times.,5.1. Effectiveness of Decomposition Learning,[0],[0]
An example of a 2-dimensional function component is shown in the appendix.,5.1. Effectiveness of Decomposition Learning,[0],[0]
"For Add-GPUCB, we used β(m)t = |Am| log 2t for lower dimensions (D = 2, 5, 10), and β(m)t = |Am| log 2t/5 for higher dimensions (D = 20, 30, 50).",5.1. Effectiveness of Decomposition Learning,[0],[0]
"We show parts of the results on averaged cumulative regret and simple regret in Fig. 2, and the rest in the appendix.",5.1. Effectiveness of Decomposition Learning,[0],[0]
"We compare Add-GP-UCB with known additive structure (Known), no partitions (NP), fully partitioned with one dimension for each group (FP)
and the following methods of learning the decomposition: Gibbs sampling (Gibbs), randomly sampling the same number of decompositions sampled by Gibbs and select the one with the highest data likelihood (PL-1), randomly sampling 5 decompositions and selecting the one with the highest data likelihood (PL-2).",5.1. Effectiveness of Decomposition Learning,[0],[0]
"For the latter two learning methods are referred to as “partial learning” in (Kandasamy et al., 2015).",5.1. Effectiveness of Decomposition Learning,[0],[0]
The learning of the decomposition is done every 50 iterations.,5.1. Effectiveness of Decomposition Learning,[0],[0]
"Fig. 3 shows the improvement of learning decompositions with Gibbs over optimizing without partitions (NP).
",5.1. Effectiveness of Decomposition Learning,[0],[0]
"Overall, the results show that Gibbs outperforms both of the partial learning methods, and for higher dimensions, Gibbs is sometimes even better than Known.",5.1. Effectiveness of Decomposition Learning,[0],[0]
"Interestingly, similar results can be found in Fig. 3 (c) of (Kandasamy et al., 2015), where different decompositions than the ground truth may give better simple regret.",5.1. Effectiveness of Decomposition Learning,[0],[0]
"We conjecture that this is because Gibbs is able to explore more than Known, for two reasons:
1.",5.1. Effectiveness of Decomposition Learning,[0],[0]
"Empirically, Gibbs changes the decompositions across iterations, especially in the beginning.",5.1. Effectiveness of Decomposition Learning,[0],[0]
"With fluctuating partitions, even exploitation leads to moving around, because the supposedly “good” points are influenced by the partition.",5.1. Effectiveness of Decomposition Learning,[0],[0]
"The result is an implicit “exploration” effect that is absent with a fixed partition.
",5.1. Effectiveness of Decomposition Learning,[0],[0]
2.,5.1. Effectiveness of Decomposition Learning,[0],[0]
Gibbs sometimes merges “true” parts into larger parts.,5.1. Effectiveness of Decomposition Learning,[0],[0]
"The parameter βt in UCB depends on the size of the part, |Am|(log 2t)/5 (as in (Kandasamy et al., 2015)).",5.1. Effectiveness of Decomposition Learning,[0],[0]
"Larger parts hence lead to larger βt and hence more exploration.
",5.1. Effectiveness of Decomposition Learning,[0],[0]
"Of course, more exploration is not always better, but Gibbs was able to find a good balance between exploration and exploitation, which leads to better performance.",5.1. Effectiveness of Decomposition Learning,[0],[0]
Our preliminary experiments indicate that one solution to ensure that the ground truth decomposition produces the best result is to tune βt.,5.1. Effectiveness of Decomposition Learning,[0],[0]
"Hyperparameter selection (such as choosing βt) for BO is, however, very challenging and an active topic of research (e.g. (Wang et al., 2016a)).
",5.1. Effectiveness of Decomposition Learning,[0],[0]
"Next, we test the decomposition learning algorithm on a real-world function, which returns the distance between a designated goal location and two objects being pushed by two robot hands, whose trajectory is determined by 14 parameters specifying the location, rotation, velocity, moving direction etc.",5.1. Effectiveness of Decomposition Learning,[0],[0]
"This function is implemented with a physics engine, the Box2D simulator (Catto, 2011).",5.1. Effectiveness of Decomposition Learning,[0],[0]
We use add-GP-UCB with different ways of setting the additive structure to tune the parameters for the robot hand so as to push the object closer to the goal.,5.1. Effectiveness of Decomposition Learning,[0],[0]
The regrets are shown in Fig. 4.,5.1. Effectiveness of Decomposition Learning,[0],[0]
"We observe that the performance of learning the decomposition with Gibbs dominates all existing
alternatives including partial learning.",5.1. Effectiveness of Decomposition Learning,[0],[0]
"Since the function we tested here is composed of the distance to two objects, there could be some underlying additive structure for this function in certain regions of the input space, e.g. when the two robots hands are relatively distant from each other so that one of the hands only impacts one of the objects.",5.1. Effectiveness of Decomposition Learning,[0],[0]
"Hence, it is possible for Gibbs to learn a good underlying additive structure and perform effective BO with the structures it learned.",5.1. Effectiveness of Decomposition Learning,[0],[0]
"Next, we probe the effectiveness of batch BO in high dimensions.",5.2. Diverse Batch Sampling,[0],[0]
"In particular, we compare variants of the AddUCB-DPP-BBO approach outlined in Section 4, and a baseline:
• Rand:",5.2. Diverse Batch Sampling,[0],[0]
"All batch points are chosen uniformly at random from X .
• Batch-UCB-*: *∈ {PE,DPP}.",5.2. Diverse Batch Sampling,[0],[0]
All acquisition functions are UCB (Eq. 4.1).,5.2. Diverse Batch Sampling,[0],[0]
Exploration is done via PE or DPP with posterior covariance kernels for each group.,5.2. Diverse Batch Sampling,[0],[0]
"Combination is via sampling without replacement.
",5.2. Diverse Batch Sampling,[0],[0]
"• *-Fnc: *∈ {Batch-UCB-PE,Batch-UCB-DPP}.",5.2. Diverse Batch Sampling,[0],[0]
"All quality functions are also UCB’s, and combination is done by maximizing the quality functions.
",5.2. Diverse Batch Sampling,[0],[0]
"A direct application of existing batch selection methods is very inefficient in the high-dimensional settings where they differ more, algorithmically, from our approach that ex-
ploits decompositions.",5.2. Diverse Batch Sampling,[0],[0]
"Hence, we only compare to uniform sampling as a baseline.
",5.2. Diverse Batch Sampling,[0],[0]
"Effectiveness We tested on 2, 10, 20 and 50-dimensional functions sampled the same way as in Section 5.1; we assume the ground-truth decomposition of the feature space is known.",5.2. Diverse Batch Sampling,[0],[0]
"Since Rand performs the worst, we show relative averaged cumulative regret and simple regret of all methods compared to Rand in Fig. 5.",5.2. Diverse Batch Sampling,[0],[0]
Results for absolute values of regrets are shown in the appendix.,5.2. Diverse Batch Sampling,[0],[0]
Each experiment was repeated for 20 times.,5.2. Diverse Batch Sampling,[0],[0]
"For all experiments, we set βmt = |Am| log 2t and B = 10.",5.2. Diverse Batch Sampling,[0],[0]
"All diverse batch sampling methods perform comparably well and far better than Rand, although there exist slight differences.",5.2. Diverse Batch Sampling,[0],[0]
"While in lower dimensions (D ∈ {2, 10}), Batch-UCB-PE-Fnc performs among the best, in higher dimensions (D ∈ {20, 50}), Batch-UCB-DPP-Fnc performs better than (or comparable to) all other variants.",5.2. Diverse Batch Sampling,[0],[0]
"We will see a larger performance gap in later real-world experiments, showing that biasing the combination towards higher quality functions while retaining diversity across the batch of samples provides a better exploration-exploitation trade-off.
",5.2. Diverse Batch Sampling,[0],[0]
"For a real-data experiment, we tested the diverse batch sampling algorithms for BBO on the Walker function which returns the walking speed of a three-link planar bipedal walker implemented in Matlab (Westervelt et al., 2007).",5.2. Diverse Batch Sampling,[0],[0]
"We tune 25 parameters that may influence the walking speed, including 3 sets of 8 parameters for the ODE solver and 1 parameter specifying the initial velocity of the stance leg.",5.2. Diverse Batch Sampling,[0],[0]
"We discretize each dimension into 40 points, resulting in a function domain of |X | = 4025.",5.2. Diverse Batch Sampling,[0],[0]
This size is very inefficient for existing batch sampling techniques.,5.2. Diverse Batch Sampling,[0],[0]
We learn the additive structure via Gibbs sampling and sample batches of size B = 5.,5.2. Diverse Batch Sampling,[0],[0]
"To further improve efficiency, we limit the maximum size of each group to 2.",5.2. Diverse Batch Sampling,[0],[0]
The regrets for all methods are shown in Fig. 6.,5.2. Diverse Batch Sampling,[0],[0]
"Again, all diverse batch sampling methods outperform Rand by a large gap.",5.2. Diverse Batch Sampling,[0],[0]
"Moreover, Batch-UCB-DPP-Fnc is a bit better than other variants, suggesting that a selection by quality functions is useful.
",5.2. Diverse Batch Sampling,[0],[0]
"Batch Sizes Finally, we show how the batch size B affects the performance of the proposed methods.",5.2. Diverse Batch Sampling,[0],[0]
"We test the algorithms on the 14-dimensional Robot dataset with B ∈ {5, 10}.",5.2. Diverse Batch Sampling,[0],[0]
The regrets are shown in Fig. 4.,5.2. Diverse Batch Sampling,[0],[0]
"With larger batches, the differences between the batch selection approaches become more pronounced.",5.2. Diverse Batch Sampling,[0],[0]
"In both settings, Batch-UCB-DPP-Fnc performs a bit better than other variants, in particular with larger batch sizes.",5.2. Diverse Batch Sampling,[0],[0]
"In this paper, we propose two novel solutions for high dimensional BO: inferring latent structure, and combining it with batch Bayesian Optimization.",6. Conclusion,[0],[0]
"The experimental results demonstrate that the proposed techniques are effective at optimizing high-dimensional black-box functions.
",6. Conclusion,[0],[0]
"Moreover, their gain over existing methods increases as the dimensionality of the input grows.",6. Conclusion,[0],[0]
We believe that these results have the potential to enable the increased use of Bayesian optimization for challenging black-box optimization problems in machine learning that typically involve a large number of parameters.,6. Conclusion,[0],[0]
"We gratefully acknowledge support from NSF CAREER award 1553284, NSF grants 1420927 and 1523767, from ONR grant N00014-14-1-0486, and from ARO grant W911NF1410433.",Acknowledgements,[0],[0]
We thank MIT Supercloud and the Lincoln Laboratory Supercomputing Center for providing computational resources.,Acknowledgements,[0],[0]
"Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of our sponsors.",Acknowledgements,[0],[0]
Optimization of high-dimensional black-box functions is an extremely challenging problem.,abstractText,[0],[0]
"While Bayesian optimization has emerged as a popular approach for optimizing black-box functions, its applicability has been limited to low-dimensional problems due to its computational and statistical challenges arising from high-dimensional settings.",abstractText,[0],[0]
"In this paper, we propose to tackle these challenges by (1) assuming a latent additive structure in the function and inferring it properly for more efficient and effective BO, and (2) performing multiple evaluations in parallel to reduce the number of iterations required by the method.",abstractText,[0],[0]
Our novel approach learns the latent structure with Gibbs sampling and constructs batched queries using determinantal point processes.,abstractText,[0],[0]
Experimental validations on both synthetic and real-world functions demonstrate that the proposed method outperforms the existing state-of-the-art approaches.,abstractText,[0],[0]
Batched High-dimensional Bayesian Optimization via Structural Kernel Learning,title,[0],[0]
"Boolean matrix factorisation aims to decompose a binary data matrix into an approximate Boolean product of two low rank, binary matrices: one containing meaningful patterns, the other quantifying how the observations can be expressed as a combination of these patterns. We introduce the OrMachine, a probabilistic generative model for Boolean matrix factorisation and derive a Metropolised Gibbs sampler that facilitates efficient parallel posterior inference. On real world and simulated data, our method outperforms all currently existing approaches for Boolean matrix factorisation and completion. This is the first method to provide full posterior inference for Boolean Matrix factorisation which is relevant in applications, e.g. for controlling false positive rates in collaborative filtering and, crucially, improves the interpretability of the inferred patterns. The proposed algorithm scales to large datasets as we demonstrate by analysing single cell gene expression data in 1.3 million mouse brain cells across 11 thousand genes on commodity hardware.",text,[0],[0]
"Boolean matrix factorisation (BooMF) can infer interpretable decompositions of a binary data matrix X ∈ {0, 1}N×D into a pair of low-rank, binary matrices Z ∈ {0, 1}N×L and U ∈ {0, 1}D×L.",1. Introduction,[0],[0]
"The data generating process is based on the Boolean product, a special case of matrix product between binary matrices where all values
1Department of Statistics, University of Oxford, UK 2Nuffield Department of Medicine, University of Oxford, UK 3Department of Informatics, Athens University of Economics and Business, Greece 4Centre for Computational Biology, Institute of Cancer and Genomic Sciences, University of Birmingham, UK.",1. Introduction,[0],[0]
"Correspondence to: Tammo Rukat <tammo.rukat@stats.ox.ac.uk>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
n=0 n=1 n=2,1. Introduction,[0],[0]
"n=3 n=4 n=5 n=6 n=7 n=8 n=9
N=10 observation of size D=17x10
' l=0",1. Introduction,[0],[0]
l=1,1. Introduction,[0],[0]
"l=2
l=3 l=4",1. Introduction,[0],[0]
"l=5
Codes u
⊗
0 1 2 3 4 5 6 7 8 9 n
5
4
3
2
1
0
l
0.0
0.2
0.4
0.6
0.8
1.0 Latent representations z
Figure 1.",1. Introduction,[0],[0]
The observed images are 10 digits from 0 to 9 as they are traditionally represented in calculators.,1. Introduction,[0],[0]
"The data is factorised into matrices of rank 6, which is not sufficient for full error-free reconstruction.",1. Introduction,[0],[0]
"Every digit, except 7, can be constructed by Boolean combination of the inferred codes.",1. Introduction,[0],[0]
The OrMachine infers a posterior mean probability of 50% for using code l = 5 in constructing a 7.,1. Introduction,[0],[0]
Note that there exist other equally valid solutions to this problem with 6 latent dimensions.,1. Introduction,[0],[0]
The pixels represent posterior means.,1. Introduction,[0],[0]
"Codes and observations are arranged to 10×17 images for interpretation.
larger than zero are set to one, i.e.
xnd",1. Introduction,[0],[0]
= L∨ l=1 znl ∧ uld .,1. Introduction,[0],[0]
"(1)
Here, ∨ and∧ encode the Boolean disjunction and conjunction, respectively.",1. Introduction,[0],[0]
BooMF provides a framework for learning from binary data where the inferred codes U provide a basis and the indicator variables Z encode the presence or absence of these codes.,1. Introduction,[0],[0]
This representation is illustrated in the calculator digits example in Fig. 1.,1. Introduction,[0],[0]
"We can think of BooMF as binary factor analysis or as clustering with joint assignments, where each observation is assigned to a subset of L cluster centroids or codes.",1. Introduction,[0],[0]
The L-dimensional indicators provide a compact representation of which codes are allocated to each observation.,1. Introduction,[0],[0]
As stated in Eq.,1. Introduction,[0],[0]
"(1), a feature xnd takes a value of one if it equals one in any of the assigned codes.
",1. Introduction,[0],[0]
"BooMF has many real-world applications ranging from topic modelling (Blei, 2012) to collaborating filtering (Su
& Khoshgoftaar, 2009) and computer vision (LázaroGredilla et al., 2016).",1. Introduction,[0],[0]
"In this paper, we introduce the OrMachine, a Bayesian approach to BooMF, and fit the model using a fast and scalable Metropolised Gibbs sampling algorithm.",1. Introduction,[0],[0]
"On simulated and real-world data, our method is shown to significantly outperform the current state-of-theart message passing approaches for learning BooMF models.",1. Introduction,[0],[0]
"Moreover, we consider a challenging application in the analysis of high-throughput single cell genomics data.",1. Introduction,[0],[0]
BooMF is used to identify latent gene signatures (codes) that correspond to key cellular pathways or biological processes from large gene expression datasets consisting of 1.3 million cells across 11 thousand genes.,1. Introduction,[0],[0]
"Genes are expressed if one or more relevant biological processes are active, a property which is naturally modelled by the Boolean OR operation.",1. Introduction,[0],[0]
We also introduce a multi-layered extensions of Bayesian BooMF that can capture hierarchical dependencies in the latent representations.,1. Introduction,[0],[0]
There has been a sustained interest in BooMF and related methods of which we will give a brief review.,2. Related Work,[0],[0]
"The Discrete Basis Problem (Miettinen et al., 2006) provides a greedy heuristic algorithm to solve BooMF without recourse to an underlying probabilistic model.",2. Related Work,[0],[0]
"It is based on association rule mining (Agrawal et al., 1994) and has more recently been extended to automatically select the optimal dimensionality of the latent space based on the minimum description length principle (Miettinen & Vreeken, 2014).",2. Related Work,[0],[0]
"In contrast, multi assignment clustering for Boolean data (Streich et al., 2009) leverages on a probabilistic model for BooMF, adding a further global noise source to the generative process.",2. Related Work,[0],[0]
Point estimates are inferred by deterministic annealing.,2. Related Work,[0],[0]
"Similarly, Wood et al. (2012) develop a probabilistic model to infer hidden causes.",2. Related Work,[0],[0]
"In contrast to the Boolean OR, the likelihood of an observation increases with the number of active hidden codes.",2. Related Work,[0],[0]
They use an Indian Buffet process prior over the latent space and a Gibbs sampler to infer the distribution over the unbounded number of hidden causes.,2. Related Work,[0],[0]
"A more expressive model for matrix factorisation with binary latent variables is introcued by (Meeds et al., 2007), who combine binary interactions with continous weights.",2. Related Work,[0],[0]
A similar approach to ours is the work by Ravanbakhsh et al. (2016).,2. Related Work,[0],[0]
The authors tackle BooMF using a probabilistic graphical model and derive a message passing algorithm to perform MAP inference.,2. Related Work,[0],[0]
Their method is shown to have state-of-the-art performance for BooMF and completion.,2. Related Work,[0],[0]
It therefore serves us as baseline benchmark in these tasks.,2. Related Work,[0],[0]
The message passing approach has recently been employed by Lázaro-Gredilla et al. (2016) in a hierarchical network combined with pooling layers to infer the building blocks of binary images.,2. Related Work,[0],[0]
The OrMachine is a probabilistic generative model for Boolean matrix factorisation.,3.1. Model Formulation,[0],[0]
"A matrix of N binary observations xn ∈ {0, 1}D is generated from a discrete mixture of L binary codes ul ∈ {0, 1}D. Binary latent variables znl denote whether or not code l is used in generating a particular observation xn.",3.1. Model Formulation,[0],[0]
"The probability for a data point xnd to be one is greater than 1/2 if the corresponding codes and latent variables in at least one latent dimension both equal one; conversely, if there exists no dimension where codes and latent variables both equal one, the probability for the data point to be one is less than 1/2.",3.1. Model Formulation,[0],[0]
"The exact magnitude of this probability is inferred from the data and, for later notational convenience, is parametrised as the logistic sigmoid of a global dispersion parameter σ(λ) =",3.1. Model Formulation,[0],[0]
"(1+e−λ)−1, with λ ∈ R+.",3.1. Model Formulation,[0],[0]
"Next, we give a full description of the likelihood and prior distributions used in the OrM.
The likelihood function is factorised across the N observations and D features with each factor given by
p(xnd|u, z, λ) = { σ(λ); if x=min(1,uTd zn) 1−σ(λ); if x 6=min(1,uTd zn) (2)
= σ",3.1. Model Formulation,[0],[0]
"[ λx̃nd ( 1− 2
∏ l (1− znluld)
)] .
(3)
",3.1. Model Formulation,[0],[0]
"Tilde denotes the {0, 1} → {−1, 1} mapping so that for any binary variable x ∈ {0, 1}, x̃ = 2x − 1.",3.1. Model Formulation,[0],[0]
The expression inside the parentheses of Eq.,3.1. Model Formulation,[0],[0]
"(3) encodes the OR operation and evaluates to 1 if znl = uld = 1 for at least one l, and to −1 otherwise.",3.1. Model Formulation,[0],[0]
"The dispersion parameter controls the noise in the generative process, i.e. as λ→∞, all probabilities tend to 0 or 1 and the model describes a deterministic Boolean matrix product.",3.1. Model Formulation,[0],[0]
Note that the likelihood can be computed efficiently from Eq. (3) as we describe in detail in the next section.,3.1. Model Formulation,[0],[0]
We further assume independent Bernoulli priors for all variables uld and znl.,3.1. Model Formulation,[0],[0]
Such priors allow us to promote denseness or sparsity in codes and latent variables.,3.1. Model Formulation,[0],[0]
Notice that the designation of U as codes and Z as latent variables is not necessary since these matrices appear in a symmetric manner.,3.1. Model Formulation,[0],[0]
"If we transpose the matrix of observations X , then codes and latent variables merely swap roles.
",3.1. Model Formulation,[0],[0]
"Finally, we do not place a prior on the dispersion parameter λ, but maximise it using an EM-type algorithm described below.",3.1. Model Formulation,[0],[0]
"The full joint distribution of all data and random variables is given by p(X,U ,Z|λ) = p(X|U ,Z, λ)p(U)p(Z).
",3.2. Fast Posterior Inference,[0],[0]
"The full conditional for znl (and analogous for uld) is
p(znl| ·)",3.2. Fast Posterior Inference,[0],[0]
"=
σ [ λz̃nl ∑ d x̃nduld ∏ l′ 6=l (1−znl′ul′d)+logit(p(znl)) ] .",3.2. Fast Posterior Inference,[0],[0]
"(4)
We give a detailed derivation in the supplement.",3.2. Fast Posterior Inference,[0],[0]
"Notice that the independent Bernoulli prior enters the expression as additive term inside the sigmoid function that vanishes for the uninformative Bernoulli prior p(z) = 1/2.
",3.2. Fast Posterior Inference,[0],[0]
The form of Eq.,3.2. Fast Posterior Inference,[0],[0]
(4) allows for computationally efficient evaluation of the conditionals.,3.2. Fast Posterior Inference,[0],[0]
"The underlying principle is that once certain conditions are met, the result of the full conditional is known without considering the remainder of a variable’s Markov blanket.",3.2. Fast Posterior Inference,[0],[0]
"For instance, when computing updates for znl, terms in the sum over d necessarily evaluate to zero if one of the following conditions is met: (i) uld = 0 or (ii) znl′ul′d",3.2. Fast Posterior Inference,[0],[0]
= 1 for some l′ 6=,3.2. Fast Posterior Inference,[0],[0]
"l. This leads to Algorithm 1 for fast evaluation of the conditionals.
",3.2. Fast Posterior Inference,[0],[0]
"Algorithm 1 Computation of the full conditional of znl accumulator = 0 for d in 1, . . .",3.2. Fast Posterior Inference,[0],[0]
", D do
if uld = 0 then continue (next iteration over d) end if for l′ in 1, . . .",3.2. Fast Posterior Inference,[0],[0]
", L do
if l′",3.2. Fast Posterior Inference,[0],[0]
6=,3.2. Fast Posterior Inference,[0],[0]
"l and znl′ = 1 and ul′d = 1 then continue (next iteration over d)
end if end for accumulator = accumulator +",3.2. Fast Posterior Inference,[0],[0]
"x̃nd
end for p(znl| ·)",3.2. Fast Posterior Inference,[0],[0]
= σ,3.2. Fast Posterior Inference,[0],[0]
"(λ · z̃nl · accumulator)
To infer the posterior distribution over all variables uld and znl we could iteratively sample from the above conditionals using standard Gibbs sampling.",3.2. Fast Posterior Inference,[0],[0]
In practice we use a modification of this procedure which is referred to as Metropolised Gibbs sampler and was proposed by Liu (1996).,3.2. Fast Posterior Inference,[0],[0]
"We always propose to flip the current state, leading to a Hastings acceptance probability of p(z| ·)/(1−p(z|",3.2. Fast Posterior Inference,[0],[0]
·)),3.2. Fast Posterior Inference,[0],[0]
.,3.2. Fast Posterior Inference,[0],[0]
"This is guaranteed to yield lower variance Monte Carlo estimates (Peskun, 1973).
",3.2. Fast Posterior Inference,[0],[0]
"After every sweep through all variables, the dispersion parameter λ is updated to maximise the likelihood akin to the M-step of a Monte Carlo EM algorithm.",3.2. Fast Posterior Inference,[0],[0]
"Specifically, given the current values of the codes U and latent variables Z we can compute how many observations xnd are correctly predicted by the model, as
P = ∑ n,d",3.2. Fast Posterior Inference,[0],[0]
I,3.2. Fast Posterior Inference,[0],[0]
[ xnd = 1− ∏,3.2. Fast Posterior Inference,[0],[0]
l (1− znluld) ] .,3.2. Fast Posterior Inference,[0],[0]
"This allows us to
Algorithm 2 Sampling from the OrMachine for i in 1, . . .",3.2. Fast Posterior Inference,[0],[0]
",max-iters do
for n in 1, . . .",3.2. Fast Posterior Inference,[0],[0]
",N (in parallel) do for l in 1, . . .",3.2. Fast Posterior Inference,[0],[0]
",L do
Compute p(znl| ·) following Algorithm 1 Flip znl with probability [p(znl| ·)−1−1]−1
end for end for for d in 1, . . .",3.2. Fast Posterior Inference,[0],[0]
", d (in parallel) do
for l in 1, . . .",3.2. Fast Posterior Inference,[0],[0]
",L do Compute p(uld| ·) following Algorithm 1 Flip uld with probability [p(uld| ·)−1−1]−1
end for end for Set λ to its MLE according to Eq.",3.2. Fast Posterior Inference,[0],[0]
"(5).
end for
rewrite the likelihood as σ(λ)Pσ(−λ)ND−P which can be subsequently maximised with respect to λ to yield the update
σ(λ̂) = P
ND .",3.2. Fast Posterior Inference,[0],[0]
"(5)
The alternation between sampling (U ,Z) and updating the dispersion parameter is carried out until convergence; see Algorithm 2 for all steps of this procedure.",3.2. Fast Posterior Inference,[0],[0]
"We can handle unobserved data, by marginalising the likelihood over the missing observations.",3.3. Dealing with Missing Data,[0],[0]
"More precisely, if X = (Xobs,Xmis) is the decomposition of the full matrix into the observed part Xobs and the missing part Xmis, after marginalisation, the initial likelihood p(X|U ,Z, λ) simplifies to p(Xobs|U ,Z, λ).",3.3. Dealing with Missing Data,[0],[0]
"Then, a naı̈ve implementation could be based on indexing the observed components inside matrix X and modifying the inference procedure so that the posterior conditionals of znl and uld involve only sums over observed elements.",3.3. Dealing with Missing Data,[0],[0]
"A simpler, equivalent implementation, which we follow in our experiments, is to represent the data as x̃nd ∈ {−1, 0, 1} where missing observations are encoded as zeros, each contributing the constant factor σ(0) = 1/2 to the full likelihood, so that p(X|U ,Z, λ) = C p(Xobs|U ,Z, λ), where C is a constant.",3.3. Dealing with Missing Data,[0],[0]
"Thus, the missing values do not contribute to the posterior over U and Z which is also clear from the form of the full conditionals in Eq.",3.3. Dealing with Missing Data,[0],[0]
(4) that depend on a sum weighted by xnds.,3.3. Dealing with Missing Data,[0],[0]
"For the update of the dispersion parameter in Eq. (5)), we need to subtract the number of all missing observations in the denominator.",3.3. Dealing with Missing Data,[0],[0]
The dispersion now indicates the fraction of correct prediction in the observed data.,3.3. Dealing with Missing Data,[0],[0]
"Following this inference procedure, we can impute missing data based on a Monte Carlo estimate of
the predictive distribution of some unobserved xnd as
1
S S∑ s=1",3.3. Dealing with Missing Data,[0],[0]
"p(xnd|U (s),Z(s), λ̂) , (6)
where each (U (s),Z(s)) is a posterior sample.",3.3. Dealing with Missing Data,[0],[0]
"A much faster approximation of the predictive distribution is obtained by p(xnd|Û , Ẑ, λ̂), where we simply plug the posterior mean estimates for (U ,Z) into the predictive distribution.",3.3. Dealing with Missing Data,[0],[0]
"For the simulated data in Section 4.2, we find both methods to perform equally well and therefore follow the second, faster approach for all remaining experiments.",3.3. Dealing with Missing Data,[0],[0]
BooMF learns patterns of correlation in the data.,3.4. Multi-Layer OrMachine,[0],[0]
"In analogy to multi-layer neural networks, we can build a hierarchy of correlations by applying another layer of factorisation to the factor matrix Z. This is reminiscent of the idea of deep exponential families, as introduced by Ranganath et al. (2015).",3.4. Multi-Layer OrMachine,[0],[0]
"The ability to learn features at different levels of abstraction is commonly cited as an explanation for the success that deep neural networks have across many domains of application (Lin & Tegmark, 2016; Bengio et al., 2013).",3.4. Multi-Layer OrMachine,[0],[0]
"In the present setting, with stochasticity at every step of the generative process and posterior inference, we are able to infer meaningful and interpretable hierarchies of abstraction.
",3.4. Multi-Layer OrMachine,[0],[0]
"To give an example, we determine the optimal multi-layer architecture for representing the calculator digit toy dataset as introduced in Fig. 1.",3.4. Multi-Layer OrMachine,[0],[0]
We observe 50 digits and consider 70% of the data points randomly as unobserved.,3.4. Multi-Layer OrMachine,[0],[0]
"We then
train multi-layer OrMachines with various depths and layer widths, iterating through the individual layers during 200 iterations of burn-in.",3.4. Multi-Layer OrMachine,[0],[0]
We then draw 200 samples from each consecutive layer with the remaining layers held fixed to their MAP estimate.,3.4. Multi-Layer OrMachine,[0],[0]
"In order to enforce distributed representations, we choose independent Bernoulli sparsity priors for the codes: p(uld) =",3.4. Multi-Layer OrMachine,[0],[0]
"[0.01, 0.05, 0.2] for each layer, respectively.",3.4. Multi-Layer OrMachine,[0],[0]
"Superior performance in reconstructing the unobserved data is achieved by a 3-hidden layer architecture with hidden layers of size L1 = 7, L2 = 4, L3 = 2.",3.4. Multi-Layer OrMachine,[0],[0]
This 3-layer model reduces the reconstruction error from 1.4% to 0.4% compared to the single-layer model with width L = 7.,3.4. Multi-Layer OrMachine,[0],[0]
Maximum likelihood estimates of the dispersion for the three layers are λ̂ =,3.4. Multi-Layer OrMachine,[0],[0]
"[1.0, 0.93, 0.8].",3.4. Multi-Layer OrMachine,[0],[0]
"The first layer infers the seven bars that compose all digits, the following layer infers dominant groupings of these bars, and so on.",3.4. Multi-Layer OrMachine,[0],[0]
"In Fig. 2, we plot the probabilities that each prototype induces in the observation layer.",3.4. Multi-Layer OrMachine,[0],[0]
"They are given by the means of the posterior predictive as described in the the previous section, conditioned on the one-hot activations of zn with znl ∈ {0, 1} and ∑ l znl = 1.",3.4. Multi-Layer OrMachine,[0],[0]
"Alongside, we depict the average posterior mean of the corresponding representations for each digit in the training data.",3.4. Multi-Layer OrMachine,[0],[0]
This example illustrates that the multi-layer OrMachine infers interpretable higherorder correlations and is able to exploit them to achieve significant improvements in missing data imputation.,3.4. Multi-Layer OrMachine,[0],[0]
The algorithm is implemented in Python with the core sampling routines in compiled Cython.,3.5. Practical Implementation and Speed,[0],[0]
Code is avaialble on GitHub1.,3.5. Practical Implementation and Speed,[0],[0]
"Binary data is represented as {−1, 1} with missing data encoded as 0.",3.5. Practical Implementation and Speed,[0],[0]
This economical representation of data and variables as integer types simplifies computations considerably.,3.5. Practical Implementation and Speed,[0],[0]
"Algorithm 1 is implemented in parallel across the observations [n] = {1, . . .",3.5. Practical Implementation and Speed,[0],[0]
", N} and conversely updates for uld are implemented in parallel across all features [d] = {1, . . .",3.5. Practical Implementation and Speed,[0],[0]
", D}.",3.5. Practical Implementation and Speed,[0],[0]
The computation time scales linearly in each dimension.,3.5. Practical Implementation and Speed,[0],[0]
A single sweep through high-resolution calculator digits toy dataset with ND = 1.7 × 106 data points and L = 7 latent dimensions takes approximately 1 second on a desktop computer.,3.5. Practical Implementation and Speed,[0],[0]
A single sweep through the approximately 1.4× 1010 data points presented in the biological example in Section 5.2 with L = 2 latent dimensions takes approximately 5 minutes executed on 24 computing cores.,3.5. Practical Implementation and Speed,[0],[0]
For all examples presented here 100 iterations suffice for the algorithm to converge to a (local) posterior mode.,3.5. Practical Implementation and Speed,[0],[0]
"In this section, we probe the performance of the OrMachine (OrM) at random matrix factorisation and completion
1https://github.com/TammoR/OrMachine/
tasks.",4. Experiments on Simulated Data,[0],[0]
"Message passing (MP) has been shown to compare favourably with other state-of-the-art methods for BooMF that we introduced in Section 2 (Ravanbakhsh et al., 2016).",4. Experiments on Simulated Data,[0],[0]
It therefore is the focus of our comparison.,4. Experiments on Simulated Data,[0],[0]
"The following settings for MP and the OrM are used throughout our experiments, unless mentioned otherwise.",4. Experiments on Simulated Data,[0],[0]
"For MP, we use the Python implementation provided by the authors.",4. Experiments on Simulated Data,[0],[0]
"We also proceed with their choice of hyper-parameters, as experimentation with different learning rates and maximum number of iterations did not lead to any improvements.",4. Experiments on Simulated Data,[0],[0]
"For both methods, we set the priors p(u) and p(z) to the factor matrices’ expected value based on the density of the product matrix in an Empirical-Bayes fashion.",4. Experiments on Simulated Data,[0],[0]
"The only exception is MP in the matrix completion task, where uniform priors, as used by Ravanbakhsh et al. (2016), lead to slightly better performance.",4. Experiments on Simulated Data,[0],[0]
"For the OrM, we initialise the parameters uniformly at random and draw 100 iterations after 100 samples of burn-in.",4. Experiments on Simulated Data,[0],[0]
Note that around 10–100 sampling steps are usually sufficient for convergence.,4. Experiments on Simulated Data,[0],[0]
"We generate a quadratic matrix X ∈ {0, 1}N×N of rank L by taking the Boolean product of two random N × L factor matrices.",4.1. Random Matrix Factorisation,[0],[0]
The Boolean product X of two rank L binary matrices that are sampled i.i.d. from a Bernoulli distribution with parameter p has an expected value of E(X),4.1. Random Matrix Factorisation,[0],[0]
"= 1− (1− p2)L. Since we generally prefer X to be neither sparse nor dense, we fix its expected density to 1/2, unless stated otherwise.",4.1. Random Matrix Factorisation,[0],[0]
This ensures that a simple bias toward zeroes or ones in either method is not met with reward.,4.1. Random Matrix Factorisation,[0],[0]
Bits in the data are flipped at random with probabilities ranging from 5% to 50%.,4.1. Random Matrix Factorisation,[0],[0]
Factor matrices of the correct underlying dimension are inferred and the data is reconstructed from the inferred factorisation.,4.1. Random Matrix Factorisation,[0],[0]
"An example of the task is shown in Fig. 3.
",4.1. Random Matrix Factorisation,[0],[0]
"Results for the reconstruction error, defined as the fraction of misclassified data points, are depicted in Fig. 4.",4.1. Random Matrix Factorisation,[0],[0]
All experiments were repeated 10 times with error bars denoting standard deviations.,4.1. Random Matrix Factorisation,[0],[0]
"The OrM outperforms MP under all conditions, except when both methods infer equally errorfree reconstructions.",4.1. Random Matrix Factorisation,[0],[0]
"Fig. 4 (top) reproduces the experi-
mental settings of Fig. 2 in Ravanbakhsh et al. (2016).",4.1. Random Matrix Factorisation,[0],[0]
We find that the OrMachine enables virtually perfect reconstruction of a 1000 × 1000 matrix of rank L = 5 for up to 35% bit flip probability.,4.1. Random Matrix Factorisation,[0],[0]
"Notably, MP performs worse for smaller noise levels.",4.1. Random Matrix Factorisation,[0],[0]
It was hypothesised by Ravanbakhsh et al. (2016) that symmetry breaking at higher noise levels helps message passage to converge to a better solution.,4.1. Random Matrix Factorisation,[0],[0]
Fig. 4 (middle) demonstrates the consistently improved performance of the OrMachine for a more challenging example of 100 × 100 matrices of rank 7.,4.1. Random Matrix Factorisation,[0],[0]
"The reconstruction performance of both methods is similar for lower noise levels, while the OrMachine consistently out-
performs MP for larger noise levels.",4.1. Random Matrix Factorisation,[0],[0]
"For biased data with E[xnd] = 0.7 in Fig. 4 (bottom), we observe a similar pattern with a larger performance gap for higher noise levels.",4.1. Random Matrix Factorisation,[0],[0]
"Even for a bit flip-probability of 50% the OrMachine retains a reconstruction error of approximately 30%, which is achieved by levering the bias in the data.
",4.1. Random Matrix Factorisation,[0],[0]
"Fig. 4 (middle) also shows the reconstruction error on the observed data, indicating that MP overfits the data more than the OrM for larger noise levels.",4.1. Random Matrix Factorisation,[0],[0]
This may contribute to the improved performance of the OrMachine.,4.1. Random Matrix Factorisation,[0],[0]
"We further investigate the problem of matrix completion or collaborative filtering, where bits of the data matrix are unobserved and reconstructed from the inferred factor matrices.",4.2. Random Matrix Completion,[0],[0]
"Following the procedure outlined in Section 4.1, we generate random matrices of rank 5 and size 250 × 250.",4.2. Random Matrix Completion,[0],[0]
"We only observe a random subset of the data, ranging from 0.5% and 3.5%.",4.2. Random Matrix Completion,[0],[0]
The missing data is reconstructed from the inferred factor matrices.,4.2. Random Matrix Completion,[0],[0]
"As shown in Fig. 5, the OrMachine outperforms message passing throughout.",4.2. Random Matrix Completion,[0],[0]
"The plot indicates means and standard deviations from 10 repetitions of each experiment.
",4.2. Random Matrix Completion,[0],[0]
"Notably, the OrMachine does not only provide a MAP estimate, but also an estimate of the posterior probability for each unobserved data point xnd.",4.2. Random Matrix Completion,[0],[0]
Fig. 5 (bottom) shows an estimate of the density of the posterior means for the correctly and incorrectly completed data points.,4.2. Random Matrix Completion,[0],[0]
"The distribution of incorrect predictions peaks around a probability of 1/2, indicating that the OrMachine’s uncertainty about
its reconstruction provides further useful information about the missing data.",4.2. Random Matrix Completion,[0],[0]
"For instance, this information can be used to control for false positives or false negatives, simply by setting a threshold for the posterior mean.",4.2. Random Matrix Completion,[0],[0]
We investigate the OrMachine’s performance for collaborative filtering on a real-world dataset.,5.1. MovieLens Matrix Completion,[0],[0]
"The MovieLens-1M dataset2 contains 106 integer film ratings from 1 to 5 from 6000 users for 4000 films, i.e. 1/24 of the possible ratings are available.",5.1. MovieLens Matrix Completion,[0],[0]
"Similarly, the MovieLens 100k dataset contains 943 users and 1682 films.",5.1. MovieLens Matrix Completion,[0],[0]
"Following Ravanbakhsh et al. (2016), we binarise the data taking the global mean as threshold.",5.1. MovieLens Matrix Completion,[0],[0]
"We observe only a fraction of the available data, varying from 1% to 95%, and reconstruct the remaining available data following the procedure in Section 4.2 with L = 2 latent dimensions.",5.1. MovieLens Matrix Completion,[0],[0]
Reconstruction accuracies are given as fractions of correctly reconstructed unobserved ratings in Table 1.,5.1. MovieLens Matrix Completion,[0],[0]
The given values are means from 10 randomly initialised runs of each algorithm.,5.1. MovieLens Matrix Completion,[0],[0]
The corresponding standard deviations are always smaller than 0.2%.,5.1. MovieLens Matrix Completion,[0],[0]
"The OrMachine is more accurate than message passing in all cases, except for the 1M dataset with 95% available ratings.",5.1. MovieLens Matrix Completion,[0],[0]
The OrMachine’s advantage is particularly significant if only little data is observed.,5.1. MovieLens Matrix Completion,[0],[0]
"Increasing the latent dimension L to values of 3 or 4 yields no consistent improvement, while a further increase is met with diminishing
2The MovieLens dataset is available online: https:// grouplens.org/datasets/movielens/.
returns.",5.1. MovieLens Matrix Completion,[0],[0]
We achieve the best within-sample performance for a two-layer OrMachine with different architectures performing best for different amounts of observed data.,5.1. MovieLens Matrix Completion,[0],[0]
An OrMachine with two hidden layers of sizes 4 and 2 respectively yields the best average performance.,5.1. MovieLens Matrix Completion,[0],[0]
"As indicated in Table 1, it provides better results throughout but exceeds the performance of the shallow OrMachine rarely by more than 1%.",5.1. MovieLens Matrix Completion,[0],[0]
"This indicates that there is not much higher order structure in the data, which is unsurprising given the sparsity of the observations and the low dimensionality of the first hidden layer.
",5.1. MovieLens Matrix Completion,[0],[0]
We illustrate a further advantage of full posterior inference for collaborative filtering.,5.1. MovieLens Matrix Completion,[0],[0]
We can choose a threshold for how likely we want a certain prediction to take a certain value and trade off false with true positives.,5.1. MovieLens Matrix Completion,[0],[0]
"A corresponding ROC curve for the MovieLens 100k dataset, where 10% of the available data was observed, is shown in Fig. 6.",5.1. MovieLens Matrix Completion,[0],[0]
"Single-cell RNA expression analysis is a revolutionary experimental technique that facilitates the measurement of gene expression on the level of a single cell (Blainey & Quake, 2014).",5.2. Explorative Analysis of Single Cell Gene Expression Profiles,[0],[0]
"In recent years this has led to the discovery of new cell types and to a better understanding of tissue heterogeneity (Trapnell, 2015).",5.2. Explorative Analysis of Single Cell Gene Expression Profiles,[0],[0]
"The latter is particularly relevant in cancer research where it helps to understand the cellular composition of a tumour and its relationship to disease progression and treatment (Patel et al., 2014).",5.2. Explorative Analysis of Single Cell Gene Expression Profiles,[0],[0]
Here we apply the OrMachine to binarised gene expression profiles of about 1.3 million cells for about 28 thousand genes per cell.,5.2. Explorative Analysis of Single Cell Gene Expression Profiles,[0],[0]
"Cell specimens were obtained from cortex, hip-
pocampus and subventricular zone of E18 (embryonic day 18) mice; the data is publicly available3.",5.2. Explorative Analysis of Single Cell Gene Expression Profiles,[0],[0]
Only 7% of the data points are non-zero.,5.2. Explorative Analysis of Single Cell Gene Expression Profiles,[0],[0]
"We set all non-zero expression levels to one, retaining the essential information of whether or not a particular gene is expressed.",5.2. Explorative Analysis of Single Cell Gene Expression Profiles,[0],[0]
We remove genes that are expressed in fewer than 1% of cells with roughly 11 thousand genes remaining.,5.2. Explorative Analysis of Single Cell Gene Expression Profiles,[0],[0]
This leaves us with approximately 1.4×1010 data points.,5.2. Explorative Analysis of Single Cell Gene Expression Profiles,[0],[0]
"We apply the OrMachine for latent dimensions L = 2, . . .",5.2. Explorative Analysis of Single Cell Gene Expression Profiles,[0],[0]
", 10.",5.2. Explorative Analysis of Single Cell Gene Expression Profiles,[0],[0]
"The algorithm converges to a posterior mode after 10–20 iteration, taking roughly an hour on a 4-core desktop computer and 10–30 minutes on a cluster with 24 cores.",5.2. Explorative Analysis of Single Cell Gene Expression Profiles,[0],[0]
"We draw 125 samples and discard the first 25 as burn-in.
",5.2. Explorative Analysis of Single Cell Gene Expression Profiles,[0],[0]
"Factorisations with different latent dimensionality form hierarchies of representations, where features that appear together in codes for lower dimensions are progressively split apart when moving to a higher dimensional latent space.",5.2. Explorative Analysis of Single Cell Gene Expression Profiles,[0],[0]
We illustrate this approach to analysing the inferred factorisations on calculator digits in Fig. 7.,5.2. Explorative Analysis of Single Cell Gene Expression Profiles,[0],[0]
Each row corresponds to an independently trained OrMachine with the dimensionality L increasing from 3 to 7.,5.2. Explorative Analysis of Single Cell Gene Expression Profiles,[0],[0]
We observe denser patterns dividing up consecutively until only the seven constituent bars remain.,5.2. Explorative Analysis of Single Cell Gene Expression Profiles,[0],[0]
"This is a form of hierarchical clustering that, in contrast to traditional methods, does not impose any hierarchical structure on the model.",5.2. Explorative Analysis of Single Cell Gene Expression Profiles,[0],[0]
"We perform the same analysis on the single cell gene expression data with the results for both, gene patterns and specimen patterns shown in Fig. 8.",5.2. Explorative Analysis of Single Cell Gene Expression Profiles,[0],[0]
This Figure should be interpreted in analogy to Fig. 7.,5.2. Explorative Analysis of Single Cell Gene Expression Profiles,[0],[0]
"Furthermore, we run a gene set enrichment analysis for the genes that are unique to each inferred code, looking for associated biological states.",5.2. Explorative Analysis of Single Cell Gene Expression Profiles,[0],[0]
"This
3https://support.10xgenomics.com
is done using the Enrichr analysis tool (Chen et al., 2013) and a mouse gene atlas (Su et al., 2004).",5.2. Explorative Analysis of Single Cell Gene Expression Profiles,[0],[0]
"Biological states are denoted above each code, together with the logarithm to base 10 of their adjusted p-value.",5.2. Explorative Analysis of Single Cell Gene Expression Profiles,[0],[0]
"Increasing the latent dimensionality leads to a more distributed representation with subtler, biologically plausible patterns.",5.2. Explorative Analysis of Single Cell Gene Expression Profiles,[0],[0]
The columns in Fig. 8 are ordered to emphasise the hierarchical structure.,5.2. Explorative Analysis of Single Cell Gene Expression Profiles,[0],[0]
"E.g., in the first column for L = 5 and second column for L = 6, a gene set with significant overlap to two biological processes (olfactory bulb and hippocampus) splits into two gene sets each corresponding to one of the two processes.",5.2. Explorative Analysis of Single Cell Gene Expression Profiles,[0],[0]
"In the assignment of cells to these sets (Fig. 8B), this is associated with an increase in posterior uncertainty as to which cell expresses this property.",5.2. Explorative Analysis of Single Cell Gene Expression Profiles,[0],[0]
The significance levels of the associated biological processes drop from p-values on the order of 10−3 to p-values on the order of 1.,5.2. Explorative Analysis of Single Cell Gene Expression Profiles,[0],[0]
"In addition, typical genes for each of the biological states are annotated (Lopez-Bendito et al., 2007; Zheng et al., 2008; Demyanenko et al., 2010; Upadhya et al., 2011; Raman et al., 2013).",5.2. Explorative Analysis of Single Cell Gene Expression Profiles,[0],[0]
This examples illustrates the OrMachine’s ability to scale posterior inference to massive datasets.,5.2. Explorative Analysis of Single Cell Gene Expression Profiles,[0],[0]
"It enables the
discovery of readily interpretable patterns, representations and hierarchies, all of which are biologically plausible.",5.2. Explorative Analysis of Single Cell Gene Expression Profiles,[0],[0]
"We have developed the OrMachine, a probabilistic model for Boolean matrix factorisation.",6. Conclusion,[0],[0]
The extremely efficient Metropolised Gibbs sampler outperforms state-of-the-art methods in matrix factorisation and completion.,6. Conclusion,[0],[0]
"It is the first method that infers posterior distributions for Boolean matrix factorisation, a property which is highly relevant in practical applications where full uncertainty quantification matters.",6. Conclusion,[0],[0]
"Despite full posterior inference, the proposed method scales to very large datasets.",6. Conclusion,[0],[0]
We have shown that tens of billions of data points can be handled on commodity hardware.,6. Conclusion,[0],[0]
The OrMachine can readily accommodate missing data and prior knowledge.,6. Conclusion,[0],[0]
"Layers of OrMachines can be stacked, akin to deep belief networks, inferring representations at different levels of abstraction.",6. Conclusion,[0],[0]
This leads to improved reconstruction performance on simulated and real world data.,6. Conclusion,[0],[0]
"Boolean matrix factorisation aims to decompose a binary data matrix into an approximate Boolean product of two low rank, binary matrices: one containing meaningful patterns, the other quantifying how the observations can be expressed as a combination of these patterns.",abstractText,[0],[0]
"We introduce the OrMachine, a probabilistic generative model for Boolean matrix factorisation and derive a Metropolised Gibbs sampler that facilitates efficient parallel posterior inference.",abstractText,[0],[0]
"On real world and simulated data, our method outperforms all currently existing approaches for Boolean matrix factorisation and completion.",abstractText,[0],[0]
"This is the first method to provide full posterior inference for Boolean Matrix factorisation which is relevant in applications, e.g. for controlling false positive rates in collaborative filtering and, crucially, improves the interpretability of the inferred patterns.",abstractText,[0],[0]
The proposed algorithm scales to large datasets as we demonstrate by analysing single cell gene expression data in 1.3 million mouse brain cells across 11 thousand genes on commodity hardware.,abstractText,[0],[0]
Bayesian Boolean Matrix Factorisation,title,[0],[0]
"In statistical applications, random graphs serve as Bayesian models for network data, that is, data consisting of objects and the observed linkages between them.",1. Introduction,[0],[0]
"Here we will focus on models for random simple graphs (that is, graphs with edges that take binary values), which are appropriate for applications where we observe either the presence or
1Pohang University of Science and Technology, Pohang, South Korea 2University of Cambridge, Cambridge, UK 3Uber AI Labs, San Francisco, CA, USA 4Hong Kong University of Science and Technology, Hong Kong.",1. Introduction,[0],[0]
Correspondence to:,1. Introduction,[0],[0]
"Juho Lee <stonecold@postech.ac.kr>, Seungjin Choi <seungjin@postech.ac.kr>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
absence of links between objects in the network.",1. Introduction,[0],[0]
"For example, in social networks, nodes may represent individuals and a link (i.e., a nonzero value of an edge) could represent friendship.",1. Introduction,[0],[0]
"In a protein-protein interaction network, nodes may represent proteins and links could represent an observed physical or chemical interaction between proteins.",1. Introduction,[0],[0]
"Many domains involving network data (including social and protein-protein interaction networks) have been shown to exhibit power law, i.e., heavy-tailed, degree distributions (Barabási & Albert, 1999).",1. Introduction,[0],[0]
"Models for random graphs with power law degree distributions, also called scale-free random graphs, have therefore become one of the most actively studied areas of graph theory and network science (Bollobás et al., 2001; Albert & Barabási, 2002; Dorogovtsev & Mendes, 2002).",1. Introduction,[0],[0]
"In this paper we present a model for simple, scale-free random graphs, which we apply as a probabilistic model for several network datasets.
",1. Introduction,[0],[0]
"The model we present in this paper is a special case of the generalized random graph defined by Britton et al. (2006), and studied further by van der Hofstad (2016, Ch. 6), which outlines a framework for defining scale-free random graphs, but does not provide practical constructions, much less algorithms for performing statistical inference on the model components given data.",1. Introduction,[0],[0]
"Here we provide one such practical construction, along with a variational inference routine (Jordan et al., 1999) for efficient posterior inference.",1. Introduction,[0],[0]
"What’s more, our construction readily generalizes to include the structure of latent factors/clusters, as captured by the popular stochastic blockmodels (Nowicki & Snijders, 2001; Airoldi et al., 2009), while maintaining power law behavior in the graph.
",1. Introduction,[0],[0]
"Applying Bayesian inference algorithms on network datasets is a challenge because likelihood computations, in general, scale with the number of edges in the graph, which is O(n2) in a network with n nodes.",1. Introduction,[0],[0]
"To help overcome these difficulties, we follow Hoffman et al. (2013) and develop a stochastic variational inference algorithm in which we approximate many likelihood computations on only subsets of the data, called minibatches.",1. Introduction,[0],[0]
"In the case of a network dataset, the minibatches are comprised of subsets of edges in the graph.
",1. Introduction,[0],[0]
"We apply this inference procedure to several network
datasets that are commonly observed to possess power law structure.",1. Introduction,[0],[0]
Our experiments show that accurately capturing this power law structure improves performance on tasks predicting missing edges in the networks.,1. Introduction,[0],[0]
"We represent a simple graph with n nodes by an adjacency matrix X := (Xi,j)i,j≤n, where Xi,j = 1 if there is a link between nodes i and j and Xi,j = 0 otherwise.",2. Bayesian models for simple graphs,[0],[0]
"Here we will only consider undirected graphs, in which case X represents a symmetric matrix.",2. Bayesian models for simple graphs,[0],[0]
"Furthermore, we do not allow self links, so the diagonal entries in X are meaningless.",2. Bayesian models for simple graphs,[0],[0]
"Most probabilistic models for simple graphs take the entries in X to be conditionally independent Bernoulli random variables; in particular, for every i, j ≤ n, let pi,j be the (random) probability of a link between nodes i and j, and let Xi,j | pi,j ∼ Bernoulli(pi,j).",2. Bayesian models for simple graphs,[0],[0]
"For every simple graph x := (xi,j)i,j≤n, we may then write the likelihood for the parameters p := (pi,j)i,j≥1 given X as
P (X = x | p) =",2. Bayesian models for simple graphs,[0],[0]
"∏
i<j≤n
p xi,j i,j (1− pi,j) 1−xi,j , (1)
where in our case it should be clear that the product is only over i, j ≤ n",2. Bayesian models for simple graphs,[0],[0]
such that i < j and i 6=,2. Bayesian models for simple graphs,[0],[0]
"j. Random simple graphs date back to the Erdös–Rényi model, which may be reviewed, along with the more general theory of random graphs, in the text by Bollobás (1998).",2. Bayesian models for simple graphs,[0],[0]
A random graph is called scale-free when the fraction of nodes in the network having k connections to other nodes behaves like k−τ for large values of k and some exponent τ > 1.,2. Bayesian models for simple graphs,[0],[0]
"More precisely, let Dn,i := ∑ j 6=iXi,j denote the (random) degree of node i, for every i ≤ n.",2. Bayesian models for simple graphs,[0],[0]
"Then X is (asymptotically) scale-free when, for every node i ≤ n,
P{Dn,i = k} ∼ ck−τ , as n→∞, (2)
for some constant c > 0, a power law exponent τ",2. Bayesian models for simple graphs,[0],[0]
"> 1, and k sufficiently large.",2. Bayesian models for simple graphs,[0],[0]
"Here the notation A ∼ B denotes that the ratio A/B → 1 in the specified limit.
",2. Bayesian models for simple graphs,[0],[0]
"In order to model scale-free random graphs, Britton et al. (2006) suggested reparameterizing the model in Eq.",2. Bayesian models for simple graphs,[0],[0]
"(1) by a sequence of odds ratios ri,j := pi,j/(1 − pi,j), for every i < j ≤ n, which factorize as ri,j = UiUj , for some U := (U1, . . .",2. Bayesian models for simple graphs,[0],[0]
", Un).",2. Bayesian models for simple graphs,[0],[0]
"The node-specific factors Ui are then modeled as Ui := Wi/ √ L for some sequence of nonnegative random variables W := (W1, . . .",2. Bayesian models for simple graphs,[0],[0]
",Wn) and where L := ∑n i=1Wi.",2. Bayesian models for simple graphs,[0],[0]
"In a series of results, (Britton et al., 2006, Thms.",2. Bayesian models for simple graphs,[0],[0]
"3.1 & 3.2) and (van der Hofstad, 2016, Cor. 6.11 & Thm.",2. Bayesian models for simple graphs,[0],[0]
"6.13) assert conditions on the random variablesW so that the limiting distribution of the degrees Dn,i is a mixed Poisson distribution.",2. Bayesian models for simple graphs,[0],[0]
"We will further detail these previous results in Section 4.
",2. Bayesian models for simple graphs,[0],[0]
"The distribution of Wi is interpreted here as a prior distribution for the degree Dn,i of node i, and if its distribution has heavy tails, then so will the distribution of Dn,i. Conversely, if the distribution of Wi does not have heavy tails, then neither will the distribution of the degrees Dn,i.",2. Bayesian models for simple graphs,[0],[0]
"We explore this alternative in Section 7.
",2. Bayesian models for simple graphs,[0],[0]
"Previous authors did not suggest any particular choices for the distribution of Wi, and so we elect to model them with BFRY random variables (Bertoin et al., 2006; Devroye & James, 2014), which have a heavy-tailed distribution and have recently played a role in the construction of several power law models in Bayesian statistics.",2. Bayesian models for simple graphs,[0],[0]
"Other heavy tailed distributions, such as those exhibited by log normal random variables, may also be used to model the Wi, and these options may be explored.",2. Bayesian models for simple graphs,[0],[0]
"One benefit of the BFRY distribution is that the thickness of its tails, and thus the power law behavior of the resulting graph, may be straightforwardly controlled by the discount parameter α.",2. Bayesian models for simple graphs,[0],[0]
"Consider the model from the previous section, parameterized by the odds ratios r := (ri,j : i < j ≤ n).",3. A generalized random graph,[0],[0]
"Define
G(r) := ∏
i<j≤n
(1 + ri,j) = ∏
i<j≤n
(1 + UiUj), (3)
and note that the conditional likelihood in Eq.",3. A generalized random graph,[0],[0]
"(1) may be rewritten in terms of the degrees Dn,i as
P (X = x | r) =",3. A generalized random graph,[0],[0]
"G(r)−1 ∏
i<j≤n
(UiUj) xi,j (4)
= G(r)−1 ∏ i≤n U Dn,i i .",3. A generalized random graph,[0],[0]
"(5)
The random simple graphX is called a generalized random graph, and we will henceforth write X | r ∼ GRG(n, r).
",3. A generalized random graph,[0],[0]
"Let α ∈ (0, 1), which we call the discount parameter, and let C1, C2, . . .",3. A generalized random graph,[0],[0]
"be a sequence of positive values satisfying
lim n→∞ Cn =∞ and lim n→∞ Cαn/n = 0.",3. A generalized random graph,[0],[0]
"(6)
Let the weights W1, . . .",3. A generalized random graph,[0],[0]
",Wn be i.i.d.",3. A generalized random graph,[0],[0]
"with density
fn(w) ∝ w−α−1(1− e−w)1{0≤w≤Cn}.",3. A generalized random graph,[0],[0]
"(7)
(These are truncated BFRY random variables and will be discussed, along with a method for simulation, in Section 3.1.)",3. A generalized random graph,[0],[0]
Then the corresponding generalized random graph has an (asymptotic) power law degree distribution with power law exponent τ,3. A generalized random graph,[0],[0]
= 1,3. A generalized random graph,[0],[0]
+ α.,3. A generalized random graph,[0],[0]
"We summarize this construction in the following theorem:
Theorem 3.1.",3. A generalized random graph,[0],[0]
"For every n, let W1, . . .",3. A generalized random graph,[0],[0]
",Wn be i.i.d.",3. A generalized random graph,[0],[0]
"with density fn and let (Dn,i)i≤n be the degrees of the generalized random graph X | r ∼ GRG(n, r), where
r := (ri,j)i<j≤n is the sequence of odds ratios
ri,j = WiWj/L, i < j ≤ n, (8)
and L := ∑ iWi.",3. A generalized random graph,[0],[0]
"Then the following hold:
1.",3. A generalized random graph,[0],[0]
"For y 1, P{Dn,i = y} ∼ cy−1−α, for every node i and for some constant c, as n→∞. 2.",3. A generalized random graph,[0],[0]
"For any m, the collection Dn,1, . . .",3. A generalized random graph,[0],[0]
", Dn,m are asymptotically independent, as n→∞.
This construction is closely related to the model described by van der Hofstad (2016, Thm. 6.13), and the proof of Theorem 3.1, which is provided in the supplementary material, follows analogously to the results by Britton et al. (2006, Thms.",3. A generalized random graph,[0],[0]
3.1 & 3.2),3. A generalized random graph,[0],[0]
.,3. A generalized random graph,[0],[0]
Note that the power law exponent τ,3. A generalized random graph,[0],[0]
= 1 + α of the graph (as described by Eq.,3. A generalized random graph,[0],[0]
"(2)) is determined by the parameter α ∈ (0, 1), and takes values in (1, 2).",3. A generalized random graph,[0],[0]
"While power law exponents in (2, 3) has often been suggested in the past, it has more recently been shown that exponents within the (1, 2) range of our model is more appropriate in many domains (van der Hofstad, 2016, Ch. 1); (Crane & Dempsey, 2015).",3. A generalized random graph,[0],[0]
"A random variable W with density function fn given by Eq. (7) is a ratio of gamma and beta random variables, upper truncated at Cn.",3.1. Truncated BFRY random variables,[0],[0]
"In particular let
g ∼ gamma(1− α, 1) and b ∼ beta(α, 1), (9)
be independent, then the ratio Z := g/b has density p(z) ∝ z−α−1(1",3.1. Truncated BFRY random variables,[0],[0]
"− e−z) on (0,∞)",3.1. Truncated BFRY random variables,[0],[0]
"(by construction), which is known as the Bertoin-Fujita-Roynette-Yor (BFRY) distribution (Bertoin et al., 2006; Devroye & James, 2014) and has been used in the construction of power law models in some recent applications in machine learning (James et al., 2015; Lee et al., 2016).",3.1. Truncated BFRY random variables,[0],[0]
"The random variable W is then
obtained by upper truncating the random variable Z at Cn.",3.1. Truncated BFRY random variables,[0],[0]
By our requirements on the sequence Cn (c.f. Eq.,3.1. Truncated BFRY random variables,[0],[0]
"(6)), the density function fn of W approaches the density function of the BFRY random variable Z as n→∞, that is,
lim n→∞
fn(w) = α
Γ(1− α) w−α−1(1− e−w), (10)
which is heavy-tailed with infinite moments.",3.1. Truncated BFRY random variables,[0],[0]
It is straightforward to simulate these truncated BFRY random variables by repeatedly simulating g and b as in Eq.,3.1. Truncated BFRY random variables,[0],[0]
"(9), accepting W := g/b as a sample when W < Cn.
",3.1. Truncated BFRY random variables,[0],[0]
"The truncation of W at Cn produces a random variable with finite mean (for n < ∞), which is essential when constructing the generalized random graph and motivates the construction by van der Hofstad (2016, Thm. 6.13) alluded to earlier; see Section 4.",3.1. Truncated BFRY random variables,[0],[0]
"For simplicity, one could take Cn = n, but the flexibility to set this parameter allows us to control other properties of the model.",3.1. Truncated BFRY random variables,[0],[0]
"For example, in the next section we show how to vary this truncation level to control the sparsity of the graph.",3.1. Truncated BFRY random variables,[0],[0]
"The discount parameter α ∈ (0, 1) controls the power law behavior of the graph, where decreasing α results in heavier tails in the degree distribution of the nodes in the graph.",3.2. Controlling power law and sparsity in the graph,[0],[0]
We can visualize this behavior by simulating graphs at different values of α.,3.2. Controlling power law and sparsity in the graph,[0],[0]
"In Section 3, we set Cn = n and show the number of nodes of varying degrees in two simulated graphs, one with α = 0.2 and one with α = 0.8.
",3.2. Controlling power law and sparsity in the graph,[0],[0]
"The degree distribution of the nodes in a graph of course affects the sparsity of the graph; to characterize this relationship, we can upper bound the expected number of links in the graph as follows:
Theorem 3.2.",3.2. Controlling power law and sparsity in the graph,[0],[0]
Let En be the number of positive edges in the graph.,3.2. Controlling power law and sparsity in the graph,[0],[0]
"Then E[En] = O(nC1−αn ).
",3.2. Controlling power law and sparsity in the graph,[0],[0]
The derivation of this result is provided in the supplementary material.,3.2. Controlling power law and sparsity in the graph,[0],[0]
"While varying α can thus control the sparsity of the graph in addition to the power law behavior, we often want to decouple these behaviors, in which case we could parameterize the truncation level as Cn = nβ , for some sparsity parameter β > 0.",3.2. Controlling power law and sparsity in the graph,[0],[0]
"Note the restriction α < min{1, 1/β} must be enforced in order to ensure that the conditions in Eq.",3.2. Controlling power law and sparsity in the graph,[0],[0]
(6) are satisfied.,3.2. Controlling power law and sparsity in the graph,[0],[0]
"In this case, the bound in Theorem 3.2 becomes E[En] = O(n1+β(1−α)).",3.2. Controlling power law and sparsity in the graph,[0],[0]
"The interpretation here is that increasing the upper bound Cn increases the likelihood that any particular node will link to others, but does not affect the (asymptotic) power law characterized by Theorem 3.1.",3.2. Controlling power law and sparsity in the graph,[0],[0]
"In Section 3.2, we display the average number of positive edges in graphs that were simulated with fixed α = 0.3 and varying values of the sparsity parameter β.",3.2. Controlling power law and sparsity in the graph,[0],[0]
"We note that in simulations, we encountered numerical issues in β > 1.4 regimes.",3.2. Controlling power law and sparsity in the graph,[0],[0]
"Referring to the construction for generalized random graphs in Section 2, Britton et al. (2006, Thm. 3.1) shows that when the weights Wi have finite first and second moments, then the limiting distribution of the degree Dn,i is a mixed Poisson distribution.",4. Related work,[0],[0]
"Most such distributions are light-tailed, however, in which case the degrees will not exhibit power law behavior.",4. Related work,[0],[0]
"Britton et al. (2006, Thm. 3.2) therefore provides an alternative construction in which Wi may have infinite moments (so that it may exhibit a heavy tail), which results in a graph with a power law exponent of τ = 2.",4. Related work,[0],[0]
"Finally, van der Hofstad (2016, Thm. 6.13) suggests yet another construction where the Wi are upper truncated to be of order o(n), where n is the number of nodes in the graph.",4. Related work,[0],[0]
"The resulting random variables therefore have finite moments, yet exhibit a heavy tail, and the resulting random graph has a heavy tailed degree distribution with an arbitrary power law exponent.",4. Related work,[0],[0]
"None of these results suggest a particular choice for the distribution of Wi, however, and so we have elected to use BFRY random variables (which are heavy tailed) that are upper truncated (so that they have finite moments).",4. Related work,[0],[0]
We note that the requirements on our truncation level (c.f. Eq.,4. Related work,[0],[0]
"(6)) is less strict than the o(n) criterion of the van der Hofstad (2016, Thm.",4. Related work,[0],[0]
"6.13) construction.
",4. Related work,[0],[0]
"The reader may consult the surveys by Bollobás & Riordan (2003); Albert & Barabási (2002); Dorogovtsev & Mendes (2002) for a background on scale-free random graphs, which is too large to review here.",4. Related work,[0],[0]
"While these models are numerous, the following recent pieces of work in the Bayesian statistics and machine learning communities may be of interest to the reader: Caron & Fox (2014); Veitch & Roy (2015); Crane & Dempsey (2016); Cai & Broderick (2015).",4. Related work,[0],[0]
"This collection of work discusses power law degree distributions, albeit in some cases in multi-graphs
(i.e., graphs with nonnegative integer-valued edges) and in some cases the power law behavior is not characterized, only numerically observed in simulations.",4. Related work,[0],[0]
"Many of these models can be seen to invoke their power law properties from the Pitman–Yor process (Pitman & Yor, 1997) (or related stochastic processes), where the extent of this behavior is controlled by the discount parameter α ∈ (0, 1) of the Pitman–Yor model, which, like the BFRY distribution, is related to a stable subordinator of index α.",4. Related work,[0],[0]
Latent factor models for relational data assume that a set of latent clusters underlie the network.,5. Incorporating latent factors,[0],[0]
"For example, in a social network, the latent factors could be the unobserved hobbies or interests of individuals, which determine the observed friendships in the network.",5. Incorporating latent factors,[0],[0]
"Bayesian models for latent factors in relational data are widespread, with some of the most popular based on stochastic blockmodels, where models for unsupervised learning, or clustering, are used to infer the latent factors (Nowicki & Snijders, 2001; Kemp et al., 2006; Airoldi et al., 2009; Miller et al., 2009).",5. Incorporating latent factors,[0],[0]
"In this section, we present extensions of the generalized random graph that incorporate latent factors by scaling the odds ratios, while maintaining their power law degree distribution.
",5. Incorporating latent factors,[0],[0]
"We will first provide a general result showing how to incorporate random scaling variables into the model, followed by specific examples that model these scaling variables with latent clusters.",5. Incorporating latent factors,[0],[0]
"Let the odds ratios in the generalized random graph be given by ri,j = Ai,jUiUj for some Ai,j ≥ 0.",5. Incorporating latent factors,[0],[0]
"Note that pi,j → 1 as Ai,j → ∞ and pi,j → 0 as Ai,j → 0, and so the edge-specific weight Ai,j simply scales the link probability.",5. Incorporating latent factors,[0],[0]
"The random graph X | r ∼ GRG(n, r) then has the likelihood
P (X = x | r) =",5. Incorporating latent factors,[0],[0]
"G(r)−1 ∏
i<j≤n
A xi,j i,j ∏ i≤n U Dn,i i , (11)
where the normalization term G(r) in Eq.",5. Incorporating latent factors,[0],[0]
"(3) is now
G(r) := ∏
i<j≤n
(1 +Ai,jUiUj) (12)
= ∑ x ∏",5. Incorporating latent factors,[0],[0]
"i<j≤n A xi,j i,j ∏ i≤n U Dn,i i , (13)
where the final equality follows simply because∑ x P (X = x | r) = 1.",5. Incorporating latent factors,[0],[0]
"So constructed, the odds ratios r will influence the link probabilities in the generalized random graph, but will not affect the power law behavior of the degree distributions (under some assumptions on the random variables Ai,j).",5. Incorporating latent factors,[0],[0]
"We summarize this construction in the following theorem, the proof for which is provided in the supplementary material:
Theorem 5.1.",5. Incorporating latent factors,[0],[0]
Let (Wi)i≤n be i.i.d. random variables with density function fn(w) (in Eq. (7)).,5. Incorporating latent factors,[0],[0]
"Let (Ai,j)i<j≤n be a collection of uniformly bounded random variables, where, for every i ≤ n, the collection (Ai,j)j>i is exchangeable.",5. Incorporating latent factors,[0],[0]
"Let (Dn,i)i≤n be the degrees of the random graph X | r ∼ GRG(n, r), where r := (ri,j)i<j≤n is the sequence of odds ratios
ri,j = Ai,jWiWj/L, i < j ≤ n, (14) and where L := ∑ iWi.",5. Incorporating latent factors,[0],[0]
"Then the degrees (Dn,i)i≤n satisfy statements (1) and (2) in Theorem 3.1.
",5. Incorporating latent factors,[0],[0]
"For example, we may construct stochastic blockmodels, such as those introduced by Nowicki & Snijders (2001), as follows: For every i ≤ n, let Zi be a random variable taking values in {1, . . .",5. Incorporating latent factors,[0],[0]
",K}, indicating which one (and only one) of K different factors to associate with node i.",5. Incorporating latent factors,[0],[0]
"We want the latent cluster assignments for two nodes i and j to influence their link probability, which we could capture with a set of parameters θk,`, for k, ` = 1, . . .",5. Incorporating latent factors,[0],[0]
",K. Then the parameter θZi,Zj could represent, or influence, the probability of a link between nodes i and j. Taking a Bayesian approach, the indicator variables Zi may be modeled with a Dirichlet-categorical conjugate distribution and their values may be inferred via probabilistic inference.",5. Incorporating latent factors,[0],[0]
"An example of such a model could be summarized as follows: Let
Zi ∼ categorical(π), i ≤ n, (15) π ∼ Dirichlet(c/K), where c > 0, (16)
θ`,k ∼ gamma(aθ, bθ), `, k ≤ K, (17) Ai,j = θZi,Zj , i < j ≤ n, (18)
and construct the random graph X as in Theorem 5.1.",5. Incorporating latent factors,[0],[0]
"Kemp et al. (2006) developed a nonparametric extension of a similar model that in a sense takes the limit K → ∞, allowing an appropriate number of clusters to be automatically inferred from the data.",5. Incorporating latent factors,[0],[0]
"In this case, the marginal law of the indicator variables Z1, . . .",5. Incorporating latent factors,[0],[0]
", Zn is given by a Chinese restaurant process (with concentration parameter c).
",5. Incorporating latent factors,[0],[0]
"Several generalizations of the stochastic blockmodel allow the clusters underlying the network to overlap, leading to mixed membership stochastic blockmodels (Airoldi et al., 2009) or the related latent feature relational models (Miller et al., 2009).",5. Incorporating latent factors,[0],[0]
"To capture this structure, we may generalize the indicators Zi to now represent a binary K-vector with entry Zi,k = 1 indicating node i is associated with cluster k, now called a feature, and Zi,k = 0 otherwise.",5. Incorporating latent factors,[0],[0]
"One example of such a model could be summarized as follows:
Zi,k ∼ Bernoulli(pk), i ≤ n, k ≤ K, (19) pk ∼ beta(c, cγ/K), k ≤ K, and c, γ > 0, (20) θ`,k ∼ gamma(aθ, bθ), `, k = 1, 2, . . .",5. Incorporating latent factors,[0],[0]
", (21)
Ai,j = ∑ k,` θk,`Zi,kZj,`, i < j ≤ n, (22)
and construct the random graph X as in Theorem 5.1.",5. Incorporating latent factors,[0],[0]
"Miller et al. (2009) derived a nonparametric extension of this model that in a sense takes the limit K →∞, in which case the marginal law of the vectors Z1, . . .",5. Incorporating latent factors,[0],[0]
", Zn is that of an Indian buffet process (with mass parameter γ and concentration parameter c)",5. Incorporating latent factors,[0],[0]
"(Ghahramani et al., 2007).",5. Incorporating latent factors,[0],[0]
"We derive a variational Bayesian inference algorithm (Jordan et al., 1999) that approximates the (optimal state of the) posterior distribution of the model components, given a network dataset.",6. Variational inference,[0],[0]
"We approximate the required gradients in this procedure with stochastic gradient ascent (Bottou, 2010; Hoffman et al., 2013), computed on minibatches (i.e., subsets) of edges in the graph.",6. Variational inference,[0],[0]
"In variational inference, we approximate the posterior distribution on the latent variables W := (W1, . . .",6.1. The variational lower bound,[0],[0]
",Wn) with a variational distribution q(W ; θ), the parameters θ of which are fit to maximize the following lower bound on the marginal likelihood
log p(X) ≥ Eq(W ;θ) [ log
p(X |W ;α)p(W ;α) q(W ; θ)
] , (23)
where p(X | W ) is the likelihood function computed as in Eq.",6.1. The variational lower bound,[0],[0]
"(5), and p(W ;α) is the prior on W represented by the density function in Eq.",6.1. The variational lower bound,[0],[0]
(7).,6.1. The variational lower bound,[0],[0]
"The (non random) discount parameter α is inferred by corresponding gradient ascent updates maximizing the likelihood of the model, which is described in Section 6.4.",6.1. The variational lower bound,[0],[0]
We specify a mean field variational distribution q(W ; θ) =∏n i=1 q(Wi; θi).,6.1. The variational lower bound,[0],[0]
"We considered several approximations for the marginals q(Wi; θi) including truncated BFRY and truncated gamma distributions, however, in our experiments we found that the following rectified gamma distribution performed well:
Wi =q min{W ′i , Cn}, (24) W ′i ∼ gamma(θi,shp, θi,rte), (25)
independently for every i ≤ n, where θi,shp and θi,rte denote the shape and rate parameters of the gamma distribution, respectively, and the notation =q emphasizes that this formula holds under the variational distribution q.",6.1. The variational lower bound,[0],[0]
We maximize the lower bound on the right hand side of Eq.,6.2. Stochastic gradient ascent,[0],[0]
"(23) by stochastic gradient ascent, where on the t-th step of the algorithm, we make the following updates to the
parameters in parallel
θ (t+1) i ← θ (t)",6.2. Stochastic gradient ascent,[0],[0]
"i + ρt∇θiEq(W ;θ(t))[L(X,W ; θ (t))",6.2. Stochastic gradient ascent,[0],[0]
"], (26)
",6.2. Stochastic gradient ascent,[0],[0]
"for i ≤ n and some sequence (ρt)t≥1 of positive numbers satisfying the Robbins–Monro criterion (Robbins & Monro, 1951) ∑ t ρt =∞ and ∑ t ρ",6.2. Stochastic gradient ascent,[0],[0]
2,6.2. Stochastic gradient ascent,[0],[0]
"t <∞, and where
L(X,W ; θ) := log p(X,W ;α)− log q(W ; θ) (27)
= ∑
(i,j)∈E log p(Xi,j |W ) + n∑ i=1",6.2. Stochastic gradient ascent,[0],[0]
"log p(Wi;α)
",6.2. Stochastic gradient ascent,[0],[0]
− n∑ i=1,6.2. Stochastic gradient ascent,[0],[0]
"log q(Wi; θi), (28)
where E denotes the observed edges (both links and nonlinks) in the dataset.",6.2. Stochastic gradient ascent,[0],[0]
"We cannot evaluate the expectation (with respect to the rectified gamma distributions q(W ; θ)) analytically, and so we elect to use a particular Monte Carlo approximation of this gradient detailed by Knowles (2015), which was developed for gamma variational distributions and easily applies to the rectified gamma case.
",6.2. Stochastic gradient ascent,[0],[0]
"Briefly, for every i ≤ n, create the collection of S Monte Carlo samples from the variational distribution as follows: Independently for s ≤ S, let z (s) i ∼ Uniform(0, 1), and set W (s) i = ψ(z (s) i ; θi), where ψ(z; θ) :",6.2. Stochastic gradient ascent,[0],[0]
"= min{F−1θ (z), Cn} and F −1 θ",6.2. Stochastic gradient ascent,[0],[0]
(x) is the inverse of the cumulative distribution function for a gamma random variable.,6.2. Stochastic gradient ascent,[0],[0]
"For convenience, we recall that
Fa,b(x) = ∫ x 0 ba Γ(a) ta−1e−btdt. (29)
",6.2. Stochastic gradient ascent,[0],[0]
"For every k ≤ n, the gradient with respect to the parameters θk is then approximated by
∇θkEq(W ;θ)[L(X,W ; θ)]
≈ 1 S ∑ s ∇WkL(X,W (s); θ)∇θkψ(z (s) k ; θk), (30)
where W (s) := (W (s)1 , . . .",6.2. Stochastic gradient ascent,[0],[0]
",W (s) n ).",6.2. Stochastic gradient ascent,[0],[0]
"This estimator is unbiased and has low enough variance that often a single sample suffices for the approximation (Salimans & Knowles, 2013; Kingma & Welling, 2014).",6.2. Stochastic gradient ascent,[0],[0]
The gradient of ψ is nonzero only when {F−1θk (z (s) k ),6.2. Stochastic gradient ascent,[0],[0]
"< Cn}, in which case we may immediately obtain the partial derivative with respect to the rate parameter; in particular, we have
∇θk,rteψ(z (s) k ; θk) =
{ z (s) k
θk,rte , if F−1θk (z (s) k )",6.2. Stochastic gradient ascent,[0],[0]
"< Cn,
0, otherwise.",6.2. Stochastic gradient ascent,[0],[0]
"(31)
",6.2. Stochastic gradient ascent,[0],[0]
"The partial derivative with respect to the shape parameter ∇θk,shpψ(z (s) k ; θk) does not have a closed form solution and must be approximated.",6.2. Stochastic gradient ascent,[0],[0]
"Different approximation routines are suggested by Knowles (2015) for different regimes of the shape parameter θk,shp, and we found these approximations to be accurate and efficient in our experiments.",6.2. Stochastic gradient ascent,[0],[0]
"Computing the n required gradients in Eq. (26) may be done in parallel, and this computation, whether performed analytically or with automatic differentiation methods, scales with the number of edges in the graph.",6.3. Minibatches of edges in the graph,[0],[0]
"This can be prohibitive for many network datasets, and we therefore introduce a further approximation where this gradient is evaluated on subsets (a.k.a. minibatches) of the dataset, a technique from stochastic gradient ascent (Bottou, 2010) adopted in the context of variational Bayesian inference by Hoffman et al. (2013).",6.3. Minibatches of edges in the graph,[0],[0]
"In the case of a network dataset, we may select minibatches that are subsets of the observed edges in the graph.",6.3. Minibatches of edges in the graph,[0],[0]
"In particular, write the gradient of Eq.",6.3. Minibatches of edges in the graph,[0],[0]
(28) with respect to the variable Wk (which is required by Eq. (30)),6.3. Minibatches of edges in the graph,[0],[0]
"as
∇WkL(W (s); θ) = ∑
(i,j)∈E
g(i,j)(X,W (s); k), (32)
where g(i,j)(X,W ; k) := ∇Wk",6.3. Minibatches of edges in the graph,[0],[0]
"[log p(Xi,j | W ) + |E|−1 log p(W ;α)− |E|−1 log q(W ; θ)] is the gradient that ignores all but one edge of the graph.",6.3. Minibatches of edges in the graph,[0],[0]
"We may therefore compute the unbiased estimate of this gradient
∇WkL(W",6.3. Minibatches of edges in the graph,[0],[0]
"(s); θ) ≈ |E| |B| ∑ (i,j)∈B g(i,j)(X,W (s); k), (33)
on a minibatch B ⊆ E of the observed edges.",6.3. Minibatches of edges in the graph,[0],[0]
"Without good prior knowledge of how to set the discount parameter α and the sparsity parameter β controlling the power law and sparsity behaviors of the graph, respectively, we infer their values from the data.",6.4. Inference on the parameters α and β,[0],[0]
"First consider the discount parameter, which we infer with gradient ascent.",6.4. Inference on the parameters α and β,[0],[0]
"After every update to the latent variables W , we fix them to their mean under the distribution q, i.e., Ŵ := (Ŵ1, . . .",6.4. Inference on the parameters α and β,[0],[0]
", Ŵn) where Ŵi = Eq(Wi;θi)[Wi], and take a step in the direction of the gradient
∇α log p(Ŵ ;α) = n∑ i=1",6.4. Inference on the parameters α and β,[0],[0]
"∇α log p(Ŵi;α) (34)
= n∑ i=1",6.4. Inference on the parameters α and β,[0],[0]
"[ −∇αZα,β Zα,β − log(Ŵi) ] , (35)
which is straightforward to derive from the density function in Eq. (7), and where the normalization term
Zα,β := ∫ Cn 0 w−α−1(1− e−w) dw (36)
is a function of α and β, if we let Cn = nβ as suggested in Section 3.2.",6.4. Inference on the parameters α and β,[0],[0]
"We do not have a closed form solution for
α = 0.3 BFRY -57323.19 ± 91.62 -57675.72",6.4. Inference on the parameters α and β,[0],[0]
"± 31.71 Gamma -71341.90 ± 116.82 -71841.66 ± 47.38
α = 0.5 BFRY -21077.62 ± 79.64 -21289.75 ±",6.4. Inference on the parameters α and β,[0],[0]
34.23 Gamma -24430.38 ± 73.06 -24701.06 ±,6.4. Inference on the parameters α and β,[0],[0]
"11.31
α = 0.7 BFRY -7894.67 ± 41.84 -8027.42 ± 51.08 Gamma -8511.48 ± 22.45 -8601.50 ± 15.42
this term when Cn < ∞, and, unfortunately, inference on model parameters where the likelihood is difficult to evaluate is a challenging problem; for example, see the approaches taken by Murray et al. (2006) on such problems, which those authors call doubly intractable distributions.",6.4. Inference on the parameters α and β,[0],[0]
"Accurate inference for α is important in our model, because it controls the power law behavior of the graph.",6.4. Inference on the parameters α and β,[0],[0]
"In our experiments, we approximate the gradient in Eq.",6.4. Inference on the parameters α and β,[0],[0]
"(35) for (fixed β) by approximating Zα,β (via Eq. (36)) and ∇αZα,β = ∫ Cn 0 −w−α−1(1 − e−w) logw dw, with line integrals.",6.4. Inference on the parameters α and β,[0],[0]
"In the Section 7, we demonstrate that this approximation works well in various regimes of α, with slight overestimation for moderate values.
",6.4. Inference on the parameters α and β,[0],[0]
"Similar approaches to infer β may be derived with finite difference approximations; we did not find these approaches successful in our experiments, however, and so we instead select β by cross validation.",6.4. Inference on the parameters α and β,[0],[0]
"We first demonstrate how the inference procedure in Section 6.4 can correctly differentiate between various regimes
of α.",7. Experiments,[0],[0]
"We ran an experiment where for each value α ∈ {0.1, 0.3, 0.5, 0.7}, we simulated 10 datasets from the model with n = 1, 000 nodes, while fixing β = 1.0.",7. Experiments,[0],[0]
"For each simulated dataset, we ran an instance of the inference routine with α randomly initialized.",7. Experiments,[0],[0]
"In Fig. 3, we show the trace plots of alpha during each instance of the inference routine.",7. Experiments,[0],[0]
"For comparison, the true values of α are also shown as horizontal dashed lines.",7. Experiments,[0],[0]
"We can see that the inference routine can correctly distinguish between these different regimes of α, with slight overestimation in the moderate α regime.",7. Experiments,[0],[0]
"Interestingly, despite random initializations of α ∈ (0, 1), the algorithm always immediately inflates α to around 0.9, and then slowly decreases this value during inference, regardless of what value of α generated the data.
",7. Experiments,[0],[0]
We next demonstrate that accurately capturing power law structures in datasets will improve predictive performance.,7. Experiments,[0],[0]
"While fixing β = 1.0, we simulate three network datasets with 5,000 nodes from our model with discount parameters α = 0.3, 0.5, and 0.7, respectively, which therefore exhibit increasingly lighter-tailed degree distributions.",7. Experiments,[0],[0]
"The generated graphs have 117,300, 32,925, and 9,460 links, respectively.",7. Experiments,[0],[0]
"To establish a baseline model that does not exhibit power law degree distributions but is otherwise comparable to our model, we implement the generalized random graph where the node-specific weights are constructed from the gamma random variables Wi ∼ gamma(θ, 1), for some positive parameter θ, i.i.d. for every node i ≤",7. Experiments,[0],[0]
n. Note that the parameter θ controls the sparsity of the generated graph; larger values of θ imply denser graphs.,7. Experiments,[0],[0]
"It follows analogously to Theorem 5.1 that
P{Dn,i = k} ∼ kθ−1
2k+θ , (37)
for k 1, as n → ∞.",7. Experiments,[0],[0]
"This model therefore does not exhibit power law behavior, as desired.",7. Experiments,[0],[0]
"We refer to this model as “Gamma” and the power law graph model as “BFRY”.
",7. Experiments,[0],[0]
"We ran an experiment holding out 20% of the edges in the
simulated graphs as test sets, training the two models on the remaining 80% of the edges.",7. Experiments,[0],[0]
"We used a mini-batch size of 5,000 edges (note that the training dataset corresponds to almost 10 million observed edges).",7. Experiments,[0],[0]
"We ran each inference procedure for 20,000 steps of stochastic gradient ascent updates, using Adam (Kingma & Ba, 2015) to adjust the learning rates at each step.",7. Experiments,[0],[0]
"We repeated each experiment 5 times, each time holding out a different test set and using a different random initialization.",7. Experiments,[0],[0]
"Again, for this experiment we fixed β = 1.",7. Experiments,[0],[0]
"In Table 1 we report a mean loglikelihood metric for the test datasets, where the metric for each run is obtained by averaging the test log-likelihoods across the states for the last 4,000 steps of the inference procedure; the displayed intervals are at ±1 standard deviation about the metric, from across the 5 repeats.",7. Experiments,[0],[0]
"We also report a max log-likelihood metric, which simply records the maximum test log-likelihood across the last 4,000 steps of the inference procedure, instead of the average.",7. Experiments,[0],[0]
"The best performing method is highlighted in bold (which in each case was the BFRY model).
",7. Experiments,[0],[0]
"In each case, we see that the BFRY model achieves higher test log-likelihood metrics than the Gamma model, as expected, implying that accurately capturing a power law degree distribution improves predictive performance (when power law behavior is truly present in the network).",7. Experiments,[0],[0]
"In Table 3, we report the inferred values for α, which were reasonably accurate, though we see slight overestimation for some regimes, as seen in the demonstration earlier.",7. Experiments,[0],[0]
"For the baseline Gamma model, we optimized the hyperparameter θ using gradient ascent maximizing the evidence lower bound of the model",7. Experiments,[0],[0]
"(c.f. Eq. (23)), and the inferred values are also reported in Table 3.
",7. Experiments,[0],[0]
"Next, we ran similar experiments on the following network datasets, each of which are expected to exhibit power law degree distributions:
• ‘USTop500Airports’: 500 nodes, 2,980 links • ‘openflights’: 7,976 nodes, 15,243 links • ‘polblogs’: 1,490 nodes, 9,517 links • ‘Facebook107’: 1,034 nodes, 26,749 links
Where appropriate, we saved only the upper triangular parts of the adjacency matrices.",7. Experiments,[0],[0]
"The ‘USTop500Airports’ dataset contains the (undirected, unweighted) flight connections between the 500 busiest US airports.",7. Experiments,[0],[0]
"The similar,
though much larger, ‘openflights’ dataset contains the flight connections between non-US airports.",7. Experiments,[0],[0]
"Scale-free networks have been proposed for such traffic networks, detailed for these datasets by Colizza et al. (2007).",7. Experiments,[0],[0]
"The ‘polblogs’ dataset contains the links between political blogs (judged by hyperlinks between the front webpages of the blogs) in the period leading up to the 2004 US presidential election, which is observed to exhibit power law degree distributions by Adamic & Glance (2005).",7. Experiments,[0],[0]
"The ‘Facebook107’ dataset contains “friendships” between users of a Facebook app, collected by Leskovec & McAuley (2012); social networks are widely studied for their power law degree distributions.
",7. Experiments,[0],[0]
"For both the Gamma and BFRY models, we ran our variational inference procedure for 20,000 steps on each dataset.",7. Experiments,[0],[0]
"As before, we repeated the experiment 5 times for each network, each time holding out a different 20% of the edges in the network as a testing set.",7. Experiments,[0],[0]
"We selected the value of β from among the grid {0.6, 0.9, 1.0, 1.2, 1.4} with 5-fold cross validation on the training set.",7. Experiments,[0],[0]
"We set the minibatch size to be equal to the number of nodes in the graph; for example, we used minibatches of 1,490 edges for the polblog dataset.",7. Experiments,[0],[0]
"The evaluation metrics on the test datasets are summarized in Table 2, and the inferred hyperparameter values are reported in Table 3.",7. Experiments,[0],[0]
"We see that the BFRY model once again outperforms the Gamma baseline model, according to the test log-likelihood metrics.
",7. Experiments,[0],[0]
Probabilistic inference on α by the BFRY model provides some of the most interesting analyses here.,7. Experiments,[0],[0]
"With α ≈ 0.00 (underflowing our machine’s precision), the Facebook107 social network has the degree distribution with the heaviest tails, followed by the USTop500Airports traffic network with α ≈ 0.23, the polblog citation network with α ≈ 0.64, and the openflights network has the lightest tailed degree distribution with α ≈ 0.67.",7. Experiments,[0],[0]
"Future work could focus on implementing the latent factor modeling generalizations presented in Section 5, which are natural assumptions in many domains where networks are expected to exhibit power law degree distributions.",8. Future work,[0],[0]
"Alternative approaches to inference on the sparsity parameter β should also be explored, since controlling the sparsity in the graph was important for good predictive performance.",8. Future work,[0],[0]
The authors thank Remco van der Hofstad for helpful advice and anonymous reviewers for helpful feedback.,Acknowledgements,[0],[0]
"J. Lee and S. Choi were partly supported by an Institute for Information & Communications Technology Promotion (IITP) grant, funded by the Korean government (MSIP) (No.20140-00147, Basic Software Research in Human-level Lifelong Machine Learning (Machine Learning Center)) and Naver, Inc.",Acknowledgements,[0],[0]
"C. Heaukulani undertook this work in part while a visiting researcher at the Hong Kong University of Science and Technology, who along with L. F. James was funded by grant rgc-hkust 601712 of the Hong Kong Special Administrative Region.",Acknowledgements,[0],[0]
"We present a model for random simple graphs with power law (i.e., heavy-tailed) degree distributions.",abstractText,[0],[0]
"To attain this behavior, the edge probabilities in the graph are constructed from Bertoin–Fujita–Roynette–Yor (BFRY) random variables, which have been recently utilized in Bayesian statistics for the construction of power law models in several applications.",abstractText,[0],[0]
"Our construction readily extends to capture the structure of latent factors, similarly to stochastic blockmodels, while maintaining its power law degree distribution.",abstractText,[0],[0]
"The BFRY random variables are well approximated by gamma random variables in a variational Bayesian inference routine, which we apply to several network datasets for which power law degree distributions are a natural assumption.",abstractText,[0],[0]
"By learning the parameters of the BFRY distribution via probabilistic inference, we are able to automatically select the appropriate power law behavior from the data.",abstractText,[0],[0]
"In order to further scale our inference procedure, we adopt stochastic gradient ascent routines where the gradients are computed on minibatches (i.e., subsets) of the edges in the graph.",abstractText,[0],[0]
Bayesian inference on random simple graphs with power law degree distributions,title,[0],[0]
A classical estimation problem in many scientific inquiries is the well-studied change point detection problem where one tries to estimate when some properties of a sequence of random variables changes.,1. Introduction,[0],[0]
"This local property is of prime importance in many learning tasks such as signal segmentation (Abou-Elailah et al., 2016; Kim et al., 2009), change point detection in comparative genomics for early cancer diagnosis (Lai et al., 2005), and modeling and forecasting of changes in financial data (Lavielle & TeyssiÃĺre, 2006; Spokoiny, 2009).
",1. Introduction,[0],[0]
"For other applications, one needs more than this local answer and is interested in a more general overview of the time series where for instance earlier data samples behave like new ones creating a clustering effect.",1. Introduction,[0],[0]
"Examples of this are found in: electricity market data, where prices
1KTH Royal Institute of Technology, Stockholm, Sweden.",1. Introduction,[0],[0]
"Correspondence to: Othmane Mazhar <othmane@kth.se>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
might have different behavior corresponding to different price regimes that might reappear depending on some triggering events; signal partitioning with some parts of the signal sharing similar properties; and speech segmentation with different alternating sources.",1. Introduction,[0],[0]
"Generally speaking, it is of interest in these situations to determine not only the changes but also the clusters for a more precise description of the inhomogeneous time series.
",1. Introduction,[0],[0]
Parametric models for solving the change point detection problem have been proposed in Cleynen & Lebarbier (2014) and Rigaill et al. (2012).,1. Introduction,[0],[0]
"However, in dealing with the change point and clustering problem we would naturally require that our solution does not assume any knowledge of the number of changes nor the actual number of clusters, as these numbers would evolve over time, so we expect new changes in the process to happen and new clusters to form as N , the number of samples, grows.",1. Introduction,[0],[0]
"Thus, any practical procedure should be able to estimate these numbers and also have adaptive guarantees with respect to how fast these numbers grow.",1. Introduction,[0],[0]
"Similar setups for change point detection have been the subject of study by Harchaoui & Cappé (2007), Arlot et al. (2016) and Garreau & Arlot (2017) who use characteristic kernels for detecting changes in the distribution, while from a computational standpoint a more effective implementation has been proposed by Celisse et al. (2017).",1. Introduction,[0],[0]
"In this study, we will restrict ourselves to an iid (independent and identically distributed) Gaussian sequence model of the data with known variance, noting that the same study can be done using kernels and that the algorithm we develop can be effectively implemented using the same procedure as in (Celisse et al., 2017), as explained later in the paper.
",1. Introduction,[0],[0]
"Two other related lines of research, but which we do not explore here, are on-line algorithms for segmentation and L1-regularized segmentation.",1. Introduction,[0],[0]
"We refer the reader to (Tartakovsky et al., 2014) for an extensive review of on-line algorithms.",1. Introduction,[0],[0]
Data segmentation using the L1-penalty was introduced by Rudin et al. (1992).,1. Introduction,[0],[0]
"The one-dimensional case, corresponding to the Fussed LASSO, has been studied in (Tibshirani et al., 2005) and (Rennie & Dobson, 1969) and an efficient algorithm has been proposed by Arnold & Tibshirani (2016).",1. Introduction,[0],[0]
"More recent results can be found in (Dalalyan et al., 2017) for the one-dimensional case and (Hütter & Rigollet, 2016) for two-dimensional case.
",1. Introduction,[0],[0]
"Main contribution: The generalized setting of change point detection while clustering the segments for sequences
of data points does not seem to have been previously studied.",1. Introduction,[0],[0]
"In this work, we propose a two-pass dynamic programming algorithm for selecting an adequate model from a collection of candidate models.",1. Introduction,[0],[0]
We motivate the choice of the algorithm computationally by showing that it runs in O(N2D,1. Introduction,[0],[0]
"+ D4) time (where D is an upper bound on the number of change points), statistically by showing that it can be seen as an approximation of a computationally hard MAP optimization problem for which we can derive an oracle inequality that guarantees low sample complexity, consistency and adaptivity, and practically by testing the model on simulation data.
",1. Introduction,[0],[0]
Structure of the paper: In Section 2 we formulate the problem as one of nonparametric model selection from a family of models over all partitions of the data set.,1. Introduction,[0],[0]
"After some preliminaries and notations are given in Section 3, we propose in Section 4 a two-pass dynamic programming algorithm as a computationally effective relaxation of the optimization criterion and analyze its computational cost.",1. Introduction,[0],[0]
"We then put the model selection problem in a Bayesian framework in Section 5, and use a Laplace-type approximation to derive as optimization criterion the maximum a-posteriori probability.",1. Introduction,[0],[0]
"In Section 6 we derive an oracle inequality for the criterion that our algorithm is approximating, and study its properties.",1. Introduction,[0],[0]
Experimental results showing that the clusters and segments can be effectively estimated are presented in Section 7 using simulation data.,1. Introduction,[0],[0]
"Let Y be a measurable space and Y1, Y2, . . .",2. Problem formulation,[0],[0]
", YN ∈ Y denote random variables with distributions PYi .",2. Problem formulation,[0],[0]
Our goal is on one hand to detect changes in the sequence of distribution measures (PYi) N i=1,2. Problem formulation,[0],[0]
and on the other hand to cluster the data points coming from the same process.,2. Problem formulation,[0],[0]
"Hence we put random variables between two consecutive changes in the same segment, and we think of random variables of the same segment or different segments as belonging to the same cluster if they are the realization of the same process.
",2. Problem formulation,[0],[0]
"One important case both in theory and in practice is the uniform constant design model were the Yis depend on deterministic variables uniformly spaced on a grid Xi = i for i ∈ J1, NK := {1, . . .",2. Problem formulation,[0],[0]
", N} through a regression function f∗ with an additive iid random noise ( i)Ni=1.",2. Problem formulation,[0],[0]
"Taking the distribution of the i’s as N (0, σ2) with known variance, we end up with the following Gaussian sequence model:
Yi = f ∗",2. Problem formulation,[0],[0]
"i + i, for i ∈ J1, NK.",2. Problem formulation,[0],[0]
"(1)
Here we are placed in a regression setting of the form Y = f∗+ , where Y =",2. Problem formulation,[0],[0]
"[Y1 · · · YN ]T , f∗ =",2. Problem formulation,[0],[0]
"[f∗1 · · · f∗N ]T and = [ 1 · · · N ]T ∼ N (0, σ2IN ), and we are interested in estimating f∗ as a piecewise constant function that takes limited number of values.
",2. Problem formulation,[0],[0]
"We emphasize that it is unlikely that the data correspond exactly to a piecewise constant function plus independent
random Gaussian noise and that we are in this low dimensional hidden structure exactly, yet there might exist a good sparse linear approximation.",2. Problem formulation,[0],[0]
"Hence our search is not for an exact model, rather we are trying to select the best model in a collection of candidates, as we explain in the next section.",2. Problem formulation,[0],[0]
"We would like to perform dimensionality reduction by exploiting the hidden structure on the data sequence Y1, Y2, . . .",3. Preliminaries and notation,[0],[0]
", YN .",3. Preliminaries and notation,[0],[0]
To do this we split it into different segments while also putting the segments sharing the same mean into the same cluster.,3. Preliminaries and notation,[0],[0]
Hence if we knew the clusters our problem reduces to fitting a constant to a set of observations over each cluster.,3. Preliminaries and notation,[0],[0]
"Observe that if f∗ is constant over parts of J1, NK, then it determines a clustering of Y1, Y2, . . .",3. Preliminaries and notation,[0],[0]
", YN over the values where it is constant.",3. Preliminaries and notation,[0],[0]
"Hence, we can think about the problem as, first determining the clustering of the Y1, Y2, . . .",3. Preliminaries and notation,[0],[0]
", YN which would result in a partition π of J1, NK, and then choosing the best value of f̂ over each part as our estimate.",3. Preliminaries and notation,[0],[0]
"So f∗ belong to the subspace Fπ: subspace of functions that are constant over the parts of the partition π.
To formalize this, let M be an index set over the collection of partitions ΠN of J1, NK; given m ∈ M, denote by Fm the subspace of functions that are constant over the parts of πm.",3. Preliminaries and notation,[0],[0]
"Our goal is two-fold: find m̂ as the index estimate of Fm̂, the subspace where the estimate of f∗ lives, and from Fm̂ compute f̂m̂ as our estimate.",3. Preliminaries and notation,[0],[0]
We represent a partition π as an unordered collection of its subsets π = {,3. Preliminaries and notation,[0],[0]
"[1], [2], . . .",3. Preliminaries and notation,[0],[0]
", [|π|]} with [k] being the kth-equivalent class, -part or -cluster, and |π| the cardinality of the partition.",3. Preliminaries and notation,[0],[0]
Every part [k] can be seen as the union of segments [k] = {,3. Preliminaries and notation,[0],[0]
"[k1], [k2], . . .",3. Preliminaries and notation,[0],[0]
",",3. Preliminaries and notation,[0],[0]
[k|[k]|]} where (ki) |[k]| i=1 is the collection of maximal intervals in [k] that we call segments of the kth-cluster.,3. Preliminaries and notation,[0],[0]
The last element in each segment [ki] is called a change point.,3. Preliminaries and notation,[0],[0]
We define d′m := |πm|−1 = dim(Fm)−1 as the clustering dimension.,3. Preliminaries and notation,[0],[0]
Even though this choice might create some confusion it will be consistent the notations used in the proofs of sections 5 and 6.,3. Preliminaries and notation,[0],[0]
Also we define d′′m = |πm|0 := |∪ d′m+1 k=1,3. Preliminaries and notation,[0],[0]
"[k]| as the change point dimension.
",3. Preliminaries and notation,[0],[0]
"To link partitions to subspaces let el := (0, . . .",3. Preliminaries and notation,[0],[0]
", 1, . . .",3. Preliminaries and notation,[0],[0]
", 0) be the lth-component of the standard orthonormal basis of RN , and define for a subset A of J1, NK the vector 1A :=∑ l∈A el.",3. Preliminaries and notation,[0],[0]
"For [k], the k
th cluster of πm, with a slight abuse of notation we define 1[k] := ∑|[k]| i=1 eki , and observe that Fm = span{1[k] : k ∈ πm}, which is consistent with the definition of the clustering dimension d′m := |πm| − 1 = dim(Fm)− 1.
We define 〈f∗〉 := span{f∗}, S1 ⊕ S2 as the direct sum of the two vector space S1 and S2, and S1 S2 as their direct difference.",3. Preliminaries and notation,[0],[0]
"PS denotes the (orthogonal) projection operator onto the subspace S. We also define the partitions inclusion as m1 ⊂ m2 if Fm1 ⊂ Fm2 , or equivalently if
πm2 is finer than πm1 .",3. Preliminaries and notation,[0],[0]
Example 1.,3. Preliminaries and notation,[0],[0]
"Consider the signal f∗ of Figure 1, whose partition is
π = {[1]; [2];",3. Preliminaries and notation,[0],[0]
"[3]; [4]; [5]},
where
[1] = J615, 678K ∪ J821, 926K ∪ J1019, 1211K ∪ J1753, 2000K [2] = J1, 100K ∪ J679, 820K ∪ J1212, 1280K [3] = J101, 214K ∪ J505, 614K ∪ J926, 1018K ∪ J1281, 1600K [4] = J215, 504K [5] = J1601, 1752K.
Hence, d′π = 4 and d ′′",3. Preliminaries and notation,[0],[0]
"π = 12 for this signal.
",3. Preliminaries and notation,[0],[0]
"We also denote by CNk the binomial coefficient that gives the number of ways, disregarding order, that k objects can be chosen from among N objects.",3. Preliminaries and notation,[0],[0]
"This is given by
CNk := N !
k!(N − k)! .",3. Preliminaries and notation,[0],[0]
"(2)
The Stirling numbers of the second kind, S(N, k), correspond to the number of ways to partition a set of N objects into k non-empty subsets, or, similarly, to the number of different equivalence relations with precisely k equivalence classes that can be defined on an set of N elements.
",3. Preliminaries and notation,[0],[0]
"We are precisely interested in the case where the element set is J1, NK and the distance between every two elements in each equivalence class is at least 2; we denote the number of such equivalent classes by S2(N, k).",3. Preliminaries and notation,[0],[0]
"S(N, k) and S2(N, k) satisfy the following recurrence relations:
S(N, k) = S(N − 1, k − 1) + kS(N",3. Preliminaries and notation,[0],[0]
"− 1, k), N > k, S2(N, k) = S(N",3. Preliminaries and notation,[0],[0]
"− 1, k − 1), N, k > 2. (3)
",3. Preliminaries and notation,[0],[0]
"For the proofs of these results, we refer the reader to (Graham et al., 1988) and (Mohr & Porter, 2009).",3. Preliminaries and notation,[0],[0]
"To solve the change point and clustering problem, a natural approach is to consider the minimization of a criterion of the form,
Crit(m) = ‖y",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
− f̂m‖22 + σ2K pen(m).,4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"(4)
Uniqueness, continuity and stability properties of similar criterion have been studied in (O. et al.), we restrict to a penalty term pen(d′m, d ′′ m) := pen(m) depending only on d′ and d′′ and a multiplicative tuning parameter K. Indeed, as we shall see the penalty can be chosen such that the minimizer f̂m̂ of (4) behaves like an approximation to a maximum a-posteriori estimator (MAP), and also, the average expected risk 1NE[‖f̂m̂−",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"f
∗‖22]→ 0",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"for a large class of signals f∗, namely, those corresponding to models with d′ 6 d′′ = o(N/ lnN), i.e., f∗ is a consistent estimator for those signals.",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"The specific form of pen(m) will be derived in the next section, based on an oracle inequality that will guarantee consistency and adaptivity of our estimator.
",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"Although the estimator f̂m̂ enjoys good statistical properties, from a computational stand it would involve the exploration ofM.",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"The setM is identified with the collection of all the partitions of J1, NK, whose number asymptotically behaves like O(NeN/ lnN), rendering the minimization of the criterion (4) computationally challenging.",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"A way to bypass this issue for the change point only detection problem is via dynamic programming (Harchaoui & Cappé, 2007); this approach works in this simplified setup since there is a natural ordering for exploring the subproblems, which does not hold here.",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"To overcome this, we will relax the criterion in such a way to create a subproblem ordering and thus derive a computationally feasible approximation.",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"The proposed new method is outlined in Algorithm 1.
",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"Let ȳ[k] := ( ∑ i∈[k] Yi)/|[k]|, the average of the elements of Y in the [k]-th part.",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"Notice that, given πm := {[1]; [2]; . . .",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"; [d′m − 1]}, we have
PFm Y = d′m−1∑ k=1 〈Y,1[k]〉 ‖1[k]‖2 1[k] = d′m−1∑ k=1 ȳ[k]1[k].
",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"The minimization of criterion (4) can then be equivalently written as
min m∈M Crit(m)
=",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"min m∈M
{‖y",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"− PFm Y ‖22 + σ2K pen(d′m, d′′m)}
= min 06d′
6d′′6D  min|m|=d′ |m|0=d′′ ‖y",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"− PFm Y ‖22 + σ2K pen(d′, d′′)  ,
Algorithm 1 Two-Pass Dynamic Programming Algorithm input data points (yi)Ni=1, maximum number of changes D and
penalty strength K. 1:
ȳ[k,l] :=
∑l i=k Yi k",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"− l + 1
R[k,l] := l∑",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"i=k (yi − ȳ[k,l])2, 1 6 k 6 l 6 N.
2: for d = 1 to D do 3: use the dynamic programming recurrence in (9) and a
backtracking step to compute
Cd(N) := min |m̄|=d
‖Y − PFm̄ Y ‖ 2, (5)
m̃d ∈ arg min |m̄|=d ‖Y − PFm̄ Y ‖ 2.
4: end for 5: for d = 1 to D do 6: m̃d =: {0 6 i1 < i2 < · · ·",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"< id < N}
(αk) d k=0 := (ik+1 − ik)d0, (i0 = 0, id+1 = N).
7: sort (ȳ[1,i1], ȳ[i1+1,i2], . . .",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
", ȳ[id+1,N ]).",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
8: ( ȳ(k) ),4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"d k=0 := ordered sequence of (ȳ[ik+1,ik+1])",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"d k=0
(α(k))",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
d k=0 := corresponding permuted (αk) d k=0,4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"according to permutation φd.
9: ȳ(k,l) := ∑l i=k α(i)ȳ(i)∑l−1 i=k α(i) and R̄[k,l] := ∑l i=k α(i)(ȳ(i) −
ȳ(k,l)) 2, 1 6 k 6 l 6 d.
10: for δ = 1 to d do 11: use the dynamic programming recurrence in (10) and a
backtracking step to compute
G(d,δ) := min m∈Mȳm̃,δ
‖PFm̄ Y − PFm PFm̄ Y ‖ 2, (6)
˜̃m(d,δ) ∈ arg min m∈Mȳm̃δ ‖PFm̄",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"Y − PFm PFm̄ Y ‖ 2.
12: end for 13: end for 14: B(d,δ) := Cd+G(d,δ) +σ2K pen((d, δ)), 1 6 δ 6 d 6 D. 15: (d̂, δ̂) := arg min
16δ6d6D B(d,δ).
16: reconstruct m(d̂,δ̂) from m̃d̂ and ˜̃m(d̂,δ̂).",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"output value of criterion Crit(m(d̂,δ̂))",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"= B(d̂,δ̂) and selected
model for change points and clusters m(d̂,δ̂).
",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
where D is a reasonable upper bound on the number of change points.,4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"As we shall see later, from a statistical point of view there is no need to explore all possible values of d′ and d′′, since the statistical guarantees only hold in a regime where d′ 6 d′′ = o(N/ lnN).
",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"We define πm̄ to be the partition having as elements all the segments of πm and instead of computing the minimum exactly we will take a greedy step by defining
m̃ := arg min |m̄|=d′′
‖Y − PFm̄ Y ‖2
and defining Mm̃,d′ := {m ∈ M : m ⊂ m̃, |m| = d′}, which can be identified with the collection of all partitions of J1, d′′K into d′ sets.",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"We restrict further this collection to partitions π satisfying what we call the clustering property, which states that if I1, I2 and I are segments in some (possibly different) parts of π, then
{I1, I2 ∈",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
[k] ȳI1 6,4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
ȳI 6 ȳI2 ⇒,4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
I ∈,4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"[k]. (7)
",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"This sub-collection will be denoted asMȳm̃,d′ .",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"Simply put, this property says that the partitions considered are those that respect the ordering of (ȳ[ik+1,ik+1])",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"d′′
k=0, since if two segments I1, I2 belong to [k], and the segment I satisfies ȳI1 6",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"ȳI 6 ȳI2 , then it should also be in cluster [k].
",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"This leads to the following upper bound, whose detailed derivation is given in appendix B:
min m∈M Crit(m) 6 min 06d′′6D { min |m|=d′′ ‖Y − PFm",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
Y,4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"‖2
+ min 06d′6d′′
m∈Mȳm̃,d′′
‖PFm̃ Y",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
− PFm PFm̃,4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"Y ‖2
+ σ2K pen(d′, d′′) } .
",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"Therefore, we can define the following relaxation for the minimization of the criterion in (4):
Critr(d ′′) := min |m|=d′′ ‖Y − PFm",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
Y,4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"‖2
+ min 06d′6d′′
m∈Mȳm̃,d′′
{ ‖PFm̃ Y",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
− PFm PFm̃,4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"Y ‖2
+ σ2K pen(d′m, d ′′ m)
} .",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"(8)
and our algorithm computes min 06d′′6D
Critr(d ′′) and returns
m(d̂,δ̂).",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"From this last definition we observe that
min m∈M Crit(m) 6 Crit(m(d̂,δ̂))",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"= min06d′′6D Critr(d
′′).
",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"Thus, obtainingm(d̂,δ̂) ensures making progress toward the minimization of Crit(m).",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"The Two-Pass Dynamic Programming Algorithm 1 is aimed at doing this by computing the value of the minimum in (8) and returning a solution m̂ = m(d̂,δ̂) in the following way:
Details of Main Steps in Algorithm 1
• Step 3: It computes Cd(n) defined in (9) for all d and n to obtain Cd(N) for all d ∈ J1, NK.",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"It does so by using a dynamic programming algorithm that computes recursively for all 2 6 d 6 D and d 6 n 6 N the following recurrence, similar to the one in Hawkins (1976):
C1(n)",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
":= R[1,n] (9)
Cd(n) := min i∈Jd,nK
{Cd−1(i− 1) +R[i,n]}, d > 2.
•",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"Step 7: For all values of d, it sorts the obtained segments according to their levels to yield ( ȳ(k) )",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"d 0 , and it keeps track
of the segments’ sizes as (αk)dk=0 = (ik+1 − ik)d0 .
",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
• Step 11: It runs a modified dynamic programming recurrence on ( ȳ(k) ),4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"d 0
that uses weights according to the sizes (α(k)) d 0 .",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"It does so using the following recurrence for all 1 6 δ 6 t 6 d:
G(t,1)",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
":= R̄[1,t], (10)
G(t,δ) := min i∈Jδ,tK
{G(i−1,δ−1) + R̄[i,t]}, δ > 2.
• Step 15: It computes the minimum in (8) and finds for which model it is attained by solving the minimization problem:
(d̂, δ̂) := arg min 16δ6d6D B(d,δ).
",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"• Step 16: It finally reconstructs m(d̂,δ̂) from m̃d̂ and ˜̃m(d̂,δ̂) using the permutation φ(d̂).
",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"This algorithm can be thought of as an efficient way to compute the relaxation in (8), based on solving the change point detection problem in (5) using the dynamic programming recurrence of (9), followed by a solving a clustering problem in (6) using the dynamic programming recurrence of (10).
",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
The next theorem shows that Algorithm 1 correctly solves the minimization problem in (8) and explicits its time and space complexity.,4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
Theorem 4.1.,4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"Let (yi)Ni=1 ⊂ R, D ∈ N and K > 0.",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"Then,
• for all 1 6 d 6 D,
m̃d ∈ arg min |m̄|=d ‖Y − PFm̄ Y ‖2,
• for all 1 6 δ 6 d 6 D,
˜̃m(d,δ) ∈ arg",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
min,4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
m∈Mȳm̃δ ‖PFm̄,4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
Y − PFm PFm̄,4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"Y ‖2.
",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"Furthermore, Algorithm 1 correctly solves the minimization problem in (8), with time and space complexity O(N3 +D4) and O(N2 +D3), respectively.
",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
Proof.,4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"See Appendix B.
The time and space complexity can be improved to O(N2D",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
+,4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"D4) and O(DN +D3), respectively.",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
We refer the reader to the discussion after the proof in Appendix B for the derivation of this result.,4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
In this way we obtain a computationally feasible algorithm that finds the minimum in (8) and returns an approximation to the criterion in (4).,4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"In the next section, we will motivate the use of Algorithm 1 from a statistical point of view by showing that the minimization of criterion (4) can be viewed as an approximate maximum a-posteriori estimator.",4. Two-pass dynamic programming for change point detection and clustering,[0],[0]
"In this part, we provide a derivation of the optimization criterion in (4).",5. Model selection criterion for change point detection and clustering,[0],[0]
"We start by proposing a Bayesian model selection scheme, which is later inverted to arrive at an integral form of the maximum a-posteriori probability (MAP) estimator.",5. Model selection criterion for change point detection and clustering,[0],[0]
"Then we use a Laplace approximation to derive turn the MAP into an optimization problem of the desired form.
",5. Model selection criterion for change point detection and clustering,[0],[0]
Here we show that the proposed selection criterion in (4) follows naturally from a Bayesian reasoning.,5. Model selection criterion for change point detection and clustering,[0],[0]
"For this, we model the data as being the outcome of the following sampling model.",5. Model selection criterion for change point detection and clustering,[0],[0]
The observation Y is generated from a multivariate Gaussian of mean F and variance σ2IN as described by (1).,5. Model selection criterion for change point detection and clustering,[0],[0]
"For the random variable F , given that it belongs to a subspace Fm, we choose an absolutely continuous measure Ld′m with respect to λd′m , the Lebesgue measure on Rd′m+1, such that dLd′m = lf/mdλd ′",5. Model selection criterion for change point detection and clustering,[0],[0]
"m+1 =
d′m+1∏ k=1 (lfk/mdλ) with lf1/m = · · · = lfd′m+1/m. Later we will see that the choice lf/m will not matter in comparison to the order of approximation, nevertheless we would like it to be a bounded continuous prior satisfying some additional conditions given in Lemma 2, even though we might be chosen as an improper prior.",5. Model selection criterion for change point detection and clustering,[0],[0]
"On the family of models M we impose a categorical distribution measure PM as prior, with a weight pm for model m. Thus, we obtain the following sampling model for the data1:
Y/F ∼ N (F, σ2IN ) F/m ∼ Ld ′ m (11)
m ∼ PM = Categorical((pm)m∈M).
",5. Model selection criterion for change point detection and clustering,[0],[0]
"Since Y , F and m are now random variables, it makes sense to compute µm/Y , the posterior distribution of m
1Here and in the sequel, the dependence of pm and PM on the number of samples N is omitted, for simplicity of notation.
",5. Model selection criterion for change point detection and clustering,[0],[0]
"given Y , and maximize it, to arrive at a MAP estimate of m given bellow.
pm/",5. Model selection criterion for change point detection and clustering,[0],[0]
"Y =
pm ∫ f∈Fm φN",5. Model selection criterion for change point detection and clustering,[0],[0]
"( Y − f σ ) lf/m(f)df
∑ m′∈M pm′ ∫ f ′∈Fm φN",5. Model selection criterion for change point detection and clustering,[0],[0]
"( Y − f ′ σ ) lf/m′(f ′)df ′ .
(12)
",5. Model selection criterion for change point detection and clustering,[0],[0]
"For the complete derivation of the formula in 12 we refer you to appendix B.
Starting from the a-posteriori distribution (12) we can derive an approximation for the MAP as follows:
pm/Y ∝ pm ∫",5. Model selection criterion for change point detection and clustering,[0],[0]
f∈Fm φN,5. Model selection criterion for change point detection and clustering,[0],[0]
"( Y − f σ ) lf/m(f)df
= pm",5. Model selection criterion for change point detection and clustering,[0],[0]
"d′m+1∏ k=1
1
(2πσ2) |[k]| 2
(13)
· ∫ R exp ( − ‖y[k]",5. Model selection criterion for change point detection and clustering,[0],[0]
− fk1[k]‖22 2σ2 ),5. Model selection criterion for change point detection and clustering,[0],[0]
"lfk/m(fk)dfk.
",5. Model selection criterion for change point detection and clustering,[0],[0]
In the last step of (13) we define y[k] as the vector obtained from the entries of y corresponding to cluster [k].,5. Model selection criterion for change point detection and clustering,[0],[0]
To obtain an approximation of the MAP estimate as a solution of a criterion of the form (4) we need the result of lemma 2 stated and proved in Appendix C using a Laplace approximation type of argument.,5. Model selection criterion for change point detection and clustering,[0],[0]
"We then obtain the following upper bound for the MAP for all K > 1 :
CritMAP(m) 6 ‖y",5. Model selection criterion for change point detection and clustering,[0],[0]
"− PFm y‖22
2σ2
+K ( ln 1
pm +
1 2 (d′m + 1) ln N
d′m
) +O(d′m).",5. Model selection criterion for change point detection and clustering,[0],[0]
"(14)
The complete derivation of (14) can be found in Appendix C.",5. Model selection criterion for change point detection and clustering,[0],[0]
"Now we define our approximate MAP criterion as:
Crit(m) = ‖y",5. Model selection criterion for change point detection and clustering,[0],[0]
"− PFm y‖22 + σ2K pen(m),
pen(m) =",5. Model selection criterion for change point detection and clustering,[0],[0]
"( 2 ln 1
pm + (d′m + 1)",5. Model selection criterion for change point detection and clustering,[0],[0]
"ln
N
d′m
) .",5. Model selection criterion for change point detection and clustering,[0],[0]
"(15)
In the next section, we finish the specification of the penalty term by providing the probabilities pm over the space of models.",5. Model selection criterion for change point detection and clustering,[0],[0]
"To do so we will exhibit an oracle inequality satisfied by the estimator that minimizes (4), and choose a probability mass function (pm) that gives a reasonable upper bound on the expected quadratic risk defined below.",5. Model selection criterion for change point detection and clustering,[0],[0]
The standard way of assessing the performance of a statistical algorithm is by comparing its performance to a reasonable oracle.,6. Oracle inequality and upper bound for the risk,[0],[0]
"For this we use as a measure of performance
of an estimator f̂ the expected quadratic risk:
Rn(f̂) =",6. Oracle inequality and upper bound for the risk,[0],[0]
E[‖f̂,6. Oracle inequality and upper bound for the risk,[0],[0]
"− f∗‖22].
In the case of the change point detection and clustering problem, the comparison should be non-asymptotic, reflecting our lack of knowledge about both the clustering dimension and the change point dimension.",6. Oracle inequality and upper bound for the risk,[0],[0]
"For this we state below a non-asymptotic oracle inequality for Crit(m) using an oracle with remainder of the form:
inf m∈M {Rn(PFm y) + om(1)}.
",6. Oracle inequality and upper bound for the risk,[0],[0]
"This type of oracle has access to f∗ and chooses the m that minimizes the risk criterion up to a remainder term.
",6. Oracle inequality and upper bound for the risk,[0],[0]
To derive this we finish the specification of Crit(m) by providing an appropriate prior pm.,6. Oracle inequality and upper bound for the risk,[0],[0]
The intuition behind our choice is the following.,6. Oracle inequality and upper bound for the risk,[0],[0]
Defining r̂m = ‖y,6. Oracle inequality and upper bound for the risk,[0],[0]
− f̂m‖22 and pen(m) = 2σ2,6. Oracle inequality and upper bound for the risk,[0],[0]
ln 1pm + σ 2(d′m + 1),6. Oracle inequality and upper bound for the risk,[0],[0]
"ln N d′m
we see that the criterion (15) is of the form:
Crit(m)",6. Oracle inequality and upper bound for the risk,[0],[0]
"= r̂m + pen(m).
",6. Oracle inequality and upper bound for the risk,[0],[0]
The number of models in the family M having the same values of d′m and d ′′ m grows exponentially with those dimensions.,6. Oracle inequality and upper bound for the risk,[0],[0]
"Thus for fix d′m and d ′′ m we might find a model with low r̂m just because of randomness since some of them will deviate largely from their means, which would correspond to an over-fitting case, this was the problem of case with the traditional AIC type of estimators.",6. Oracle inequality and upper bound for the risk,[0],[0]
"Therefore, we need to penalize models of high dimensions more by taking into account the number of models with same dimensions.",6. Oracle inequality and upper bound for the risk,[0],[0]
On the other hand we want this penalty to be as small as possible this way we give more importance to the fitting term r̂m.,6. Oracle inequality and upper bound for the risk,[0],[0]
"In particular we would prefer the term 2σ2 ln 1pm to stay close to σ
2(d′+1)",6. Oracle inequality and upper bound for the risk,[0],[0]
ln Nd′ at least for values of d′m close to d ′′ m.,6. Oracle inequality and upper bound for the risk,[0],[0]
"Our choice for pm, useful inequalities and a complete discussion of the role of pm as a prior and tuning parameter for the risk can be found in Appendix D. From Lemmas 3 and 4, the following oracle inequality can be derived for f̂m̂:
Theorem 6.1 (Oracle inequality for f̂m̂).",6. Oracle inequality and upper bound for the risk,[0],[0]
"With M restricted to models such that ed′m 6 N and for the choice of K = 3a, pm as in 3, pen(m) as in 15 and m̂ ∈ M corresponding to
m̂ ∈ arg min",6. Oracle inequality and upper bound for the risk,[0],[0]
m∈M ‖y,6. Oracle inequality and upper bound for the risk,[0],[0]
"− f̂m‖22 + σ2K pen(m), (16)
We obtain for all a > 1,
Ef∗",6. Oracle inequality and upper bound for the risk,[0],[0]
"[‖PFm̂ Y − f∗‖2] 6
arg min m∈M
{ a
a− 1 Ef∗",6. Oracle inequality and upper bound for the risk,[0],[0]
"[‖PFm Y − f∗‖2]
+ a2σ2
a− 1
( 7 + 3(d′m + 1) ln N
d′m + 6 ln
1
pm
)} .",6. Oracle inequality and upper bound for the risk,[0],[0]
"(17)
Proof.",6. Oracle inequality and upper bound for the risk,[0],[0]
"See Appendix D.
By investigating the oracle inequality, one notices that for an optimal choice of a one has to make a trade-off between the performance of the oracle part and the bias part of the inequality.",6. Oracle inequality and upper bound for the risk,[0],[0]
In general this trade-off is not possible to optimize since the value of the oracle part is not available to us and depends on the variance of the noise.,6. Oracle inequality and upper bound for the risk,[0],[0]
"In practice, one can use the SLOPE heuristic introduced in Lebarbier (2002) and described in Baudry et al. (2012) and in (Arlot & Massart, 2009).",6. Oracle inequality and upper bound for the risk,[0],[0]
"In our case, the value of the tuning parameter can be chosen independently of the variance of the noise and we can use the value of a for which we know that our estimator f̂m̂ will perform well.
",6. Oracle inequality and upper bound for the risk,[0],[0]
Corollary 6.1.,6. Oracle inequality and upper bound for the risk,[0],[0]
"For the set of models described in 6.1 with f∗ ∈ Fm∗ the following properties hold:
• Adaptation and Risk Upper bound: The following adaptive upper bound in terms of d′m∗ and d ′′ m∗ holds
for a = 2:
Ef∗",6. Oracle inequality and upper bound for the risk,[0],[0]
"[‖PFm̂ Y − f ∗‖2] 6 4σ2 ( 7 + 3(d′m∗ + 1) ln N
d′m∗
+ 6 ( d′m∗ ln[d ′′ m∗e 13 6 ] + d′′m∗ ln[d ′ m∗e 2] + d′′m∗ ln N
d′′m∗
)) .
",6. Oracle inequality and upper bound for the risk,[0],[0]
• Consistency:,6. Oracle inequality and upper bound for the risk,[0],[0]
"If d′′m∗ = o(N/ lnN), then limN→∞N −1Ef∗",6. Oracle inequality and upper bound for the risk,[0],[0]
"[‖f̂m̂ − f∗‖2] = 0.
",6. Oracle inequality and upper bound for the risk,[0],[0]
Proof.,6. Oracle inequality and upper bound for the risk,[0],[0]
"See Appendix D.
We notice that the consistency condition d′′m∗ = o(N/ lnN) is within the restriction on the models in theorem 6.1, hence there is no loss of generality of having only models with ed′m 6 N in M since for other models we cannot guarantee convergent mean square risk anyway.",6. Oracle inequality and upper bound for the risk,[0],[0]
"In the special case d′m∗ = d ′′ m∗ , i.e when the change point and clustering problem reduces to a change point only problem, Kernel methods have comparable accuracy (Celisse et al., 2017).",6. Oracle inequality and upper bound for the risk,[0],[0]
"The interesting case is when the numbers are different, we gain a logarithmic factor in accuracy with almost the same computational cost.",6. Oracle inequality and upper bound for the risk,[0],[0]
"In the next section, we validate these theoretical guarantees by a series of tests on simulated data to get a sense of how tight the oracle inequality is, which signals are difficult to estimate and how the algorithm behaves in practice.",6. Oracle inequality and upper bound for the risk,[0],[0]
Consider first an experiment based data generated randomly according to the setup of (1) with the same change points of Example 1.,7. Experimental results,[0],[0]
"This is considered to be an easy case since d′m∗ = 4 < d ′′ m∗ = 12 N = 2000, which is within the range of signals for which the consistency result of Corollary 6.1 holds.
",7. Experimental results,[0],[0]
"The experiments in Figure 2 show that the algorithm is quite robust to the level of noise as measured by the signalto-noise ratio S/N = magnitude of smallest jump in f ∗
σ2 .",7. Experimental results,[0],[0]
"We observe that the difference between the ground truth f∗ and f̂m̂ is quite small even for small S/N levels such as S/N = 0.5 and the change point locations do not vary appreciably; in fact, for this experiment, S/N = 0.3 seems to be the limiting case for which the algorithm performs well, and for lower values the risk upper-bound in Corollary 6.1 becomes loose when σ increases.",7. Experimental results,[0],[0]
"Also, we note that an S/N of 0.5 is quite low for this kind of problems.",7. Experimental results,[0],[0]
"In particular, algorithms relying on the L1-penalty such as Fussed LASSO do not achieve this kind of performance on the simpler task of change point only detection, while on the other hand, they are more computational efficient (Xin et al., 2014).
",7. Experimental results,[0],[0]
"Figure 3 illustrates a difficult case, where we reduced the number of observation by segment by scaling down the signal f∗ to a support of size N = 500.",7. Experimental results,[0],[0]
"Now we are outside of the useful regime of Corollary 6.1 and we notice that the second segment J15, 53K is wider than what it should since the first change point at 25 was detected at 14; also the segment J206, 237K belongs to cluster [4] while it is actually in cluster",7. Experimental results,[0],[0]
[3] in the original signal f∗.,7. Experimental results,[0],[0]
"Nevertheless we can observe an interesting property for segment J324, 346K, namely, that the end point 346 does not correspond to any real change point, yet this segment belongs to the optimal solution of the 1st dynamic programming pass.",7. Experimental results,[0],[0]
"On the other hand the 2nd dynamic programming pass puts it in the same cluster [3] as J347, 399K, turning them into one single segment of cluster [3].",7. Experimental results,[0],[0]
"This behavior actually is the norm for the algorithm, where false changes are often detected in difficult signals in the 1st
dynamic programming pass but are removed after the 2nd pass.",7. Experimental results,[0],[0]
"These kinds of false discoveries are actually one of the weaknesses of many change point only detection algorithms like Fussed LASSO, and they have been studied in (Levy-leduc & Harchaoui, 2008), (Rinaldo, 2009) and (Rojas & Wahlberg, 2014).",7. Experimental results,[0],[0]
"In the last experiment,
we run Algorithm 1 300 times with the parameter values d′m∗ = 4 < d ′′ m∗ = 12 N = 2000 and signal-to-noise ratio S/N = 1; Figure 4 summarizes the results.",7. Experimental results,[0],[0]
"In the top histogram we notice that the algorithm successfully detects the change points most of the time; in fact, the achieved accuracy was number of change points correctly detectednumber of change points detected ≈ 0.8528.",7. Experimental results,[0],[0]
"The
middle histogram shows the placement of estimated clusters and the true values of the clusters; we observe that the true values lie in a small neighborhood of the estimated values for every cluster.",7. Experimental results,[0],[0]
"In the bottom histogram we observe that the theoretical upper bound on the average mean square error –in this case 12.1575– found in Corollary 6.1 is very conservative and most of the 300 estimates –given by ‖f̂m̂−f
∗‖2 N – are significantly smaller.",7. Experimental results,[0],[0]
"In this work, we considered a novel problem related to change point detection where we have to address the simultaneous task of segmenting and clustering the observed signal.",8. Conclusions,[0],[0]
Our approach has been to view this problem as a non-parametric model selection problem on the set of all possible partitions.,8. Conclusions,[0],[0]
"We derived for this the computationally tractable Algorithm 1, that computes a relaxation of the penalized minimization of criterion (4), and we justified it from a statistical standpoint by showing that this minimization can be viewed as an approximate MAP.",8. Conclusions,[0],[0]
This approximate MAP estimate enjoys the properties of being adaptive and consistent in the sense of Corollary 6.1.,8. Conclusions,[0],[0]
"We finally justified the use of Algorithm 1 by simulation data that shows some useful properties of the resulting estimate and validates the theoretical guarantees.
",8. Conclusions,[0],[0]
"One extension of this work concerns developing a more complete analysis of Algorithm 1, to obtain consistency results on the number and locations of the change points and clusters.",8. Conclusions,[0],[0]
"Another possible extension relates to the use of Algorithm 1 in the non-scalar case; this was already explored for change point only detection in (Arlot et al., 2016) through the use of characteristic kernels (Sriperumbudur et al., 2011).",8. Conclusions,[0],[0]
"We believe that the same approach can be adopted here except that we cannot perform the sorting step; this can be overcome using a Kernel clustering algorithm (Filipponea et al., 2008) or a spectral version of it (Schölkopf et al., 1998) for the second stage.",8. Conclusions,[0],[0]
"Finally, the remark after Figure 3 hints to the possibility of using a combined algorithm starting with the sparse solution of Fussed LASSO and running the 2nd dynamic programming pass of our algorithm as a way to boost the performance of Fussed LASSO to get rid of false discoveries.",8. Conclusions,[0],[0]
"This would be still computationally attractive according to the comment after Theorem 4.1, since the solution of Fussed LASSO has a small number of changes.",8. Conclusions,[0],[0]
We address a generalization of change point detection with the purpose of detecting the change locations and the levels of clusters of a piecewise constant signal.,abstractText,[0],[0]
Our approach is to model it as a nonparametric penalized least square model selection on a family of models indexed over the collection of partitions of the design points and propose a computationally efficient algorithm to approximately solve it.,abstractText,[0],[0]
"Statistically, minimizing such a penalized criterion yields an approximation to the maximum a-posteriori probability (MAP) estimator.",abstractText,[0],[0]
The criterion is then analyzed and an oracle inequality is derived using a Gaussian concentration inequality.,abstractText,[0],[0]
"The oracle inequality is used to derive on one hand conditions for consistency and on the other hand an adaptive upper bound on the expected square risk of the estimator, which statistically motivates our approximation.",abstractText,[0],[0]
"Finally, we apply our algorithm to simulated data to experimentally validate the statistical guarantees and illustrate its behavior.",abstractText,[0],[0]
Bayesian Model Selection for Change Point Detection and Clustering,title,[0],[0]
"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 1029–1039 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics
https://doi.org/10.18653/v1/P17-1095",text,[0],[0]
Dictionaries and gazetteers are useful in many natural language processing tasks.,1 Introduction,[0],[0]
These lexical resources may be derived from freely available sources (such as Wikidata and Wiktionary) or constructed for a particular domain.,1 Introduction,[0],[0]
"Lexical resources are typically used to complement existing annotations for a given task (Ando and Zhang, 2005; Collobert et al., 2011).",1 Introduction,[0],[0]
"In this paper, we focus instead on low-resource settings where task annotations are unavailable or scarce.",1 Introduction,[0],[0]
"Specifically, we use lexical resources to guide part-of-speech induction (§4) and to bootstrap named-entity recognizers in low-resource languages (§5).
",1 Introduction,[0],[0]
"Given their success, it is perhaps surprising that incorporating gazetteers or dictionaries into dis-
criminative models (e.g. conditional random fields) may sometimes hurt performance.",1 Introduction,[0],[0]
"This phenomena is called weight under-training, in which lexical features—which detect whether a name is listed in the dictionary or gazetteer—are given excessive weight at the expense of other useful features such as spelling features that would generalize to unlisted names (Smith et al., 2005; Sutton et al., 2006; Smith and Osborne, 2006).",1 Introduction,[0],[0]
"Furthermore, discriminative training with lexical features requires sufficient annotated training data, which poses challenges for the unsupervised and low-resource settings we consider here.
",1 Introduction,[0],[0]
Our observation is that Bayesian modeling provides a principled solution.,1 Introduction,[0],[0]
The lexicon is itself a dataset that was generated by some process.,1 Introduction,[0],[0]
"Practically, this means that lexicon entries (words or phrases) may be treated as additional observations.",1 Introduction,[0],[0]
"As a result, these entries provide information about how names are spelled.",1 Introduction,[0],[0]
"The presence of the lexicon therefore now improves training of the spelling features, rather than competing with the spelling features to help explain the labeled corpus.
",1 Introduction,[0],[0]
A downside is that generative models are typically less feature-rich than their globally normalized discriminative counterparts (e.g. conditional random fields).,1 Introduction,[0],[0]
In designing our approach—the hierarchical sequence memoizer (HSM)—we aim to be reasonably expressive while retaining practically useful inference algorithms.,1 Introduction,[0],[0]
We propose a Bayesian nonparametric model to serve as a generative distribution responsible for both lexicon and corpus data.,1 Introduction,[0],[0]
"The proposed model memoizes previously used lexical entries (words or phrases) but backs off to a character-level distribution when generating novel types (Teh, 2006; Mochihashi et al., 2009).",1 Introduction,[0],[0]
We propose an efficient inference algorithm for the proposed model using particle Gibbs sampling (§3).,1 Introduction,[0],[0]
"Our code is available at https://github.com/noa/bayesner.
1029",1 Introduction,[0],[0]
Our goal is to fit a model that can automatically annotate text.,2 Model,[0],[0]
We observe a supervised or unsupervised training corpus.,2 Model,[0],[0]
"For each label y in the annotation scheme, we also observe a lexicon of strings of type y.",2 Model,[0],[0]
"For example, in our tagging task (§4), a dictionary provides us with a list of words for each part-of-speech tag y.",2 Model,[0],[0]
(These lists need not be disjoint.),2 Model,[0],[0]
"For named-entity recognition (NER, §5), we use a list of words or phrases for each named-entity type y (PER, LOC, ORG, etc.).1",2 Model,[0],[0]
"We may treat the lexicon for type y, of size my, as having been produced by a set of my IID draws from an unknown distribution Py over the words or named entities of type y.",2.1 Modeling the lexicon,[0],[0]
It therefore provides some evidence about Py.,2.1 Modeling the lexicon,[0],[0]
We will later assume that Py is also used when generating mentions of these words or entities in text.,2.1 Modeling the lexicon,[0],[0]
"Thanks to this sharing of Py, if x = Washington is listed in the gazetteer of locations (y = LOC), we can draw the same conclusions as if we had seen a LOC-labeled instance of Washington in a supervised corpus.
",2.1 Modeling the lexicon,[0],[0]
"Generalizing this a bit, we may suppose that one observation of string x in the lexicon is equivalent to c labeled tokens of x in a corpus, where the constant c > 0 is known as a pseudocount.",2.1 Modeling the lexicon,[0],[0]
"In other words, observing a lexicon of my distinct types {x1, . .",2.1 Modeling the lexicon,[0],[0]
.,2.1 Modeling the lexicon,[0],[0]
", xmy} is equivalent to observing a labeled pseudocorpus of cmy tokens.",2.1 Modeling the lexicon,[0],[0]
"Notice that given such an observation, the prior probability of any candidate distribution Py is reweighted by the likelihood (cmy)!(c!)my · (Py(x1)Py(x2) · · ·Py(xmy))c.",2.1 Modeling the lexicon,[0],[0]
"Therefore, this choice of Py can have relatively high posterior probability only to the extent that it assigns high probability to all of the lexicon types.",2.1 Modeling the lexicon,[0],[0]
"We employ the above model because it has reasonable qualitative behavior and because computationally, it allows us to condition on observed lexicons as easily as we condition on observed corpora.",2.2 Discussion,[0],[0]
"However, we caution that as a generative model of the lexicon, it is deficient, in the sense that it
1Dictionaries and knowledge bases provide more information than we use in this paper.",2.2 Discussion,[0],[0]
"For instance, Wikidata also provides a wealth of attributes and other metadata for each entity s. In principle, this additional information could also be helpful in estimating Py(s); we leave this intriguing possibility for future work.
",2.2 Discussion,[0],[0]
allocates probability mass to events that cannot actually correspond to any lexicon.,2.2 Discussion,[0],[0]
"After all, drawing cmy IID tokens from Py is highly unlikely to result in exactly c tokens of each of my different types, and yet a run of our system will always assume that precisely this happened to produce each observed lexicon!",2.2 Discussion,[0],[0]
"To avoid the deficiency, one could assume that the lexicon was generated by rejection sampling: that is, the gazetteer author repeatedly drew samples of size cmy from Py until one was obtained that had this property, and then returned the set of distinct types in that sample as the lexicon for y.",2.2 Discussion,[0],[0]
But this is hardly a realistic description of how gazetteers are actually constructed.,2.2 Discussion,[0],[0]
"Rather, one imagines that the gazetteer author simply harvested a lexicon of frequent types from Py or from a corpus of tokens generated from Py.",2.2 Discussion,[0],[0]
"For example, a much better generative story is that the lexicon was constructed as the first my distinct types to appear ≥ c times in an unbounded sequence of IID draws from Py.",2.2 Discussion,[0],[0]
"When c = 1, this is equivalent to modeling the lexicon as my draws without replacement from Py.2 Unfortunately, draws without replacement are no longer IID or exchangeable: order matters.",2.2 Discussion,[0],[0]
"It would therefore become difficult to condition inference and learning on an observed lexicon, because we would need to explicitly sum or sample over the possibilities for the latent sequence of tokens (or stick segments).",2.2 Discussion,[0],[0]
"We therefore adopt the simpler deficient model.
",2.2 Discussion,[0],[0]
"A version of our lexicon model (with c = 1) was previously used by Dreyer and Eisner (2011, Appendix C), who observed a list of verb paradigm types rather than word or entity-name types.",2.2 Discussion,[0],[0]
"We assume a priori that Py was drawn from a Pitman-Yor process (PYP) (Pitman and Yor, 1997).",2.3 Prior distribution over Py,[0],[0]
Both the lexicon and the ordinary corpus are observations that provide information about Py.,2.3 Prior distribution over Py,[0],[0]
"The PYP is defined by three parameters: a concentration parameter α, a discount parameter d, and a base distribution Hy.",2.3 Prior distribution over Py,[0],[0]
"In our case, Hy is a distribution over X = Σ∗, the set of possible strings over a finite character alphabet",2.3 Prior distribution over Py,[0],[0]
"Σ.
For example, HLOC is used to choose new place names, so it describes what place names tend to
2If we assume that Py was drawn from a Pitman-Yor process prior (as in §2.3) using the stick-breaking method (Pitman, 1996), it is also equivalent to modeling the lexicon as the set of labels of the first my stick segments (which tend to have high probability).
look like in the language.",2.3 Prior distribution over Py,[0],[0]
"The draw PLOC ∼ PYP(d, α,HLOC) is an “adapted” version of HLOC.",2.3 Prior distribution over Py,[0],[0]
It is PLOC that determines how often each name is mentioned in text (and whether it is mentioned in the lexicon).,2.3 Prior distribution over Py,[0],[0]
"Some names such as Washington that are merely plausible under HLOC are far more frequent under PLOC, presumably because they were chosen as the names of actual, significant places.",2.3 Prior distribution over Py,[0],[0]
"These place names were randomly drawn from HLOC as part of the procedure for drawing Py.
",2.3 Prior distribution over Py,[0],[0]
"The expected value of Py is H (i.e., H is the mean of the PYP distribution), but if α and d are small, then a typical draw of Py will be rather different from H , with much of the probability mass falling on a subset of the strings.
",2.3 Prior distribution over Py,[0],[0]
"At training or test time, when deciding whether to label a corpus token of x = Washington as a place or person, we will be interested in the relative values of PLOC(x) and PPER(x).",2.3 Prior distribution over Py,[0],[0]
"In practice, we do not have to represent the unknown infinite object Py, but can integrate over its possible values.",2.3 Prior distribution over Py,[0],[0]
"When Py ∼ PYP(d, α,Hy), then a sequence of draws X1, X2, . . .",2.3 Prior distribution over Py,[0],[0]
"∼ Py is distributed according to a Chinese restaurant process, via
Py(Xi+1 = x",2.3 Prior distribution over Py,[0],[0]
"| X1, . . .",2.3 Prior distribution over Py,[0],[0]
", Xi) (1)
",2.3 Prior distribution over Py,[0],[0]
"= customers(x)− d · tables(x)
α+",2.3 Prior distribution over Py,[0],[0]
"i
+ α+ d ·∑x′ tables(x′)
α+ i Hy(x)
where customers(x) ≤ i is the number of times that x appeared among X1, . . .",2.3 Prior distribution over Py,[0],[0]
", Xi, and tables(x) ≤ customers(x) is the number of those times that x was drawn from Hy (where each Py(Xi | · · · ) defined by (1) is interpreted as a mixture distribution that sometimes uses Hy).",2.3 Prior distribution over Py,[0],[0]
"By fitting Hy on corpus and lexicon data, we learn what place names or noun strings tend to look like in the language.",2.4 Form of the base distribution Hy,[0],[0]
"By simultaneously fitting Py, we learn which ones are commonly mentioned.",2.4 Form of the base distribution Hy,[0],[0]
"Recall that under our model, tokens are drawn from Py but the underlying types are drawn fromHy, e.g.,Hy is responsible for (at least) the first token of each type.
",2.4 Form of the base distribution Hy,[0],[0]
"A simple choice for Hy is a Markov process that emits characters in Σ ∪ {$}, where $ is a distinguished stop symbol that indicates the end of the string.",2.4 Form of the base distribution Hy,[0],[0]
"Thus, the probability of producing $ controls the typical string length under Hy.
We use a more sophisticated model of strings—a sequence memoizer (SM), which is a (hierarchical) Bayesian treatment of variable-order Markov modeling (Wood et al., 2009).",2.4 Form of the base distribution Hy,[0],[0]
"The SM allows dependence on an unbounded history, and the probability of a given sequence (string) can be found efficiently much as in equation (1).
",2.4 Form of the base distribution Hy,[0],[0]
"Given a string x = a1 · · · aJ ∈ Σ∗, the SM assigns a probability to it via
Hy(a1:J) =",2.4 Form of the base distribution Hy,[0],[0]
"( J∏
j=1
Hy(aj |",2.4 Form of the base distribution Hy,[0],[0]
a1:,2.4 Form of the base distribution Hy,[0],[0]
j−1) ),2.4 Form of the base distribution Hy,[0],[0]
"Hy($ | a1:J)
=",2.4 Form of the base distribution Hy,[0],[0]
"( J∏
j=1
Hy,a1:j−1(aj) )",2.4 Form of the base distribution Hy,[0],[0]
"Hy,a1:J ($) (2)
where Hy,u(a) denotes the conditional probability of character a given the left context u ∈ Σ∗. Each Hy,u is a distribution over Σ, defined recursively as
Hy, ∼ PYP(d , α ,UΣ) (3) Hy,u ∼ PYP(d|u|, α|u|, Hy,σ(u))
where is the empty sequence, UΣ is the uniform distribution over Σ ∪ {$}, and σ(u) drops the first symbol from u.",2.4 Form of the base distribution Hy,[0],[0]
"The discount and concentration parameters (d|u|, α|u|) are associated with the lengths of the contexts |u|, and should generally be larger for longer (more specific) contexts, implying stronger backoff from those contexts.3
Our inference procedure is largely indifferent to the form of Hy, so the SM is not the only option.",2.4 Form of the base distribution Hy,[0],[0]
"It would be possible to inject more assumptions into Hy, for instance via structured priors for morphology or a grammar of name structure.",2.4 Form of the base distribution Hy,[0],[0]
"Another possibility is to use a parametric model such as a neural language model (e.g., Jozefowicz et al. (2016)), although this would require an inner-loop of gradient optimization.",2.4 Form of the base distribution Hy,[0],[0]
We now turn to modeling the corpus.,2.5 Modeling the sequence of tags y,[0],[0]
We assume that each sentence is generated via a sequence of latent labels y = y1:T ∈ Y∗.4,2.5 Modeling the sequence of tags y,[0],[0]
"The observations
3We fix these hyperparameters using the values suggested in (Wood et al., 2009; Gasthaus and Teh, 2010), which we find to be quite robust in practice.",2.5 Modeling the sequence of tags y,[0],[0]
"One could also resample their values (Blunsom and Cohn, 2010); we experimented with this but did not observe any consistent advantage to doing so in our setting.
",2.5 Modeling the sequence of tags y,[0],[0]
"4The label sequence is terminated by a distinguished endof-sequence label, again written as $.
",2.5 Modeling the sequence of tags y,[0],[0]
x1:T are then generated conditioned on the label sequence via the corresponding Py distribution (defined in §2.3).,2.5 Modeling the sequence of tags y,[0],[0]
"All observations with the same label y are drawn from the same Py, and thus this subsequence of observations is distributed according to the Chinese restaurant process (1).
",2.5 Modeling the sequence of tags y,[0],[0]
We model y using another sequence memoizer model.,2.5 Modeling the sequence of tags y,[0],[0]
"This is similar to other hierarchical Bayesian models of latent sequences (Goldwater and Griffiths, 2007; Blunsom and Cohn, 2010), but again, it does not limit the Markov order (the number of preceding labels that are conditioned on).",2.5 Modeling the sequence of tags y,[0],[0]
"Thus, the probability of a sequence of latent types is computed in the same way as the base distribution in §2.4, that is,
p(y1:T ) := ( T∏
t=1
Gy1:t−1(yt) ) Gy1",2.5 Modeling the sequence of tags y,[0],[0]
":T ($) (4)
where Gv(y) denotes the conditional probability of latent label y ∈ Y given the left context v ∈ Y∗.",2.5 Modeling the sequence of tags y,[0],[0]
"Each Gv is a distribution over Y , defined recursively as
G ∼ PYP(d , α ,UY) (5) Gv ∼ PYP(d|v|, α|v|, Gσ(v))
",2.5 Modeling the sequence of tags y,[0],[0]
The probability of transitioning to label yt depends on the assignments of all previous labels y1 . . .,2.5 Modeling the sequence of tags y,[0],[0]
"yt−1.
",2.5 Modeling the sequence of tags y,[0],[0]
"For part-of-speech induction, each label yt is the part-of-speech associated with the corresponding word xt.",2.5 Modeling the sequence of tags y,[0],[0]
"For named-entity recognition, we say that each word token is labeled with a named entity type (LOC, PER, . . . ),5 or with itself if it is not a named entity but rather a “context word.”",2.5 Modeling the sequence of tags y,[0],[0]
"For example, the word token xt",2.5 Modeling the sequence of tags y,[0],[0]
"= Washington could have been emitted from the label yt = LOC, or from yt = PER, or from yt = Washington itself (in which case p(xt | yt) = 1).",2.5 Modeling the sequence of tags y,[0],[0]
"This uses a much larger set of labels Y than in the traditional setup where all context words are emitted from the same latent label type O. Of course, most labels are impossible at most positions (e.g., yt cannot be Washington unless xt = Washington).",2.5 Modeling the sequence of tags y,[0],[0]
This scheme makes our generative model sensitive to specific contexts (which is accomplished in discriminative NER systems by contextual features).,2.5 Modeling the sequence of tags y,[0],[0]
"For example, the SM for y can learn that spoke to PER yesterday is a common 4-gram
5In §3.2, we will generalize this labeling scheme to allow multi-word named entities such as New York.
in the label sequence y, and thus we are more likely to label Washington as a person if x = . .",2.5 Modeling the sequence of tags y,[0],[0]
.spoke,2.5 Modeling the sequence of tags y,[0],[0]
to Washington,2.5 Modeling the sequence of tags y,[0],[0]
yesterday .,2.5 Modeling the sequence of tags y,[0],[0]
.,2.5 Modeling the sequence of tags y,[0],[0]
"..
",2.5 Modeling the sequence of tags y,[0],[0]
"We need one change to make this work, since now Y must include not only the standard NER labels Y ′ = {PER, LOC, ORG, GPE} but also words like Washington.",2.5 Modeling the sequence of tags y,[0],[0]
"Indeed, now Y = Y ′ ∪ Σ∗.",2.5 Modeling the sequence of tags y,[0],[0]
"But no uniform distribution exists over the infinite set Σ∗, so how should we replace the base distribution UY over labels in equation (5)?",2.5 Modeling the sequence of tags y,[0],[0]
"Answer: To draw from the new base distribution, sample y ∼ UY ′ ∪{CONTEXT}.",2.5 Modeling the sequence of tags y,[0],[0]
"If y = CONTEXT, however, then “expand” it by resampling y ∼ HCONTEXT.",2.5 Modeling the sequence of tags y,[0],[0]
"Here HCONTEXT is the base distribution over spellings of context words, and is learned just like the other Hy distributions in §2.4.",2.5 Modeling the sequence of tags y,[0],[0]
"Taking Y to be a random variable, we are interested in the posterior distribution p(Y = y | x) over label sequences y given the emitted word sequence",3.1 Sequential sampler,[0],[0]
x.,3.1 Sequential sampler,[0],[0]
"Our model does not admit an efficient dynamic programming algorithm, owing to the dependencies introduced among the Yt when we marginalize over the unknown G and P distributions that govern transitions and emissions, respectively.",3.1 Sequential sampler,[0],[0]
"In contrast to tagging with a hidden Markov model tagging, the distribution of each label Yt depends on all previous labels y1:t−1, for two reasons: ¬ The transition distribution p(Yt = y | y1:t−1) has unbounded dependence because of the PYP prior (4).  ",3.1 Sequential sampler,[0],[0]
"The emission distribution p(xt | Yt = y) depends on the emissions observed from any earlier tokens of y, because of the Chinese restaurant process (1).",3.1 Sequential sampler,[0],[0]
"When  is the only complication, block Metropolis-Hastings samplers have proven effective (Johnson et al., 2007).",3.1 Sequential sampler,[0],[0]
"However, this approach uses dynamic programming to sample from a proposal distribution efficiently, which ¬ precludes in our case.",3.1 Sequential sampler,[0],[0]
"Instead, we use sequential Monte Carlo (SMC)—sometimes called particle filtering—as a proposal distribution.",3.1 Sequential sampler,[0],[0]
"Particle filtering is typically used in online settings, including word segmentation (Borschinger and Johnson, 2011), to make decisions before all of x has been observed.",3.1 Sequential sampler,[0],[0]
"However, we are interested in the inference (or smoothing) problem that conditions on all of x (Dubbin and Blunsom, 2012; Tripuraneni et al., 2015).
",3.1 Sequential sampler,[0],[0]
"SMC employs a proposal distribution q(y | x)
whose definition decomposes as follows:
q(y1",3.1 Sequential sampler,[0],[0]
| x1),3.1 Sequential sampler,[0],[0]
"T∏
t=2
q(yt | y1:t−1,x1:t) (6)
for T = |x|.",3.1 Sequential sampler,[0],[0]
"To sample a sequence of latent labels, first sample an initial label y1 from q1, then proceed incrementally by sampling yt from qt(· | y1:t−1,x1:t) for t = 2, . . .",3.1 Sequential sampler,[0],[0]
", T .",3.1 Sequential sampler,[0],[0]
"The final sampled sequence y is called a particle, and is given an unnormalized importance weight of w̃ = w̃T · p($",3.1 Sequential sampler,[0],[0]
"| y1:T ) where w̃T was built up via
w̃t := w̃t−1 · p(y1:t,x1:t)
p(y1:t−1,x1:t−1) q(yt",3.1 Sequential sampler,[0],[0]
"| y1:t−1,x1:t) (7)
",3.1 Sequential sampler,[0],[0]
The SMC procedure consists of generating a system of M weighted particles whose unnormalized importance weights w̃(m) : 1 ≤ m ≤ M are normalized into w(m),3.1 Sequential sampler,[0],[0]
:= w̃(m)/ ∑M m=1,3.1 Sequential sampler,[0],[0]
"w̃
(m).",3.1 Sequential sampler,[0],[0]
"As M → ∞, SMC provides a consistent estimate of the marginal likelihood p(x) as 1M ∑M m=1 w̃
(m), and samples from the weighted particle system are distributed as samples from the desired posterior p(y | x) (Doucet and Johansen, 2009).",3.1 Sequential sampler,[0],[0]
Particle Gibbs.,3.1 Sequential sampler,[0],[0]
"We employ SMC as a kernel in an MCMC sampler (Andrieu et al., 2010).",3.1 Sequential sampler,[0],[0]
"In particular, we use a block Gibbs sampler in which we iteratively resample the hidden labeling y of a sentence x conditioned on the current labelings for all other sentences in the corpus.",3.1 Sequential sampler,[0],[0]
"In this context, the algorithm is called conditional SMC since one particle is always fixed to the previous sampler state for the sentence being resampled, which ensures that the MCMC procedure is ergodic.",3.1 Sequential sampler,[0],[0]
"At a high level, this procedure is analogous to other Gibbs samplers (e.g. for topic models), except that the conditional SMC (CSMC) kernel uses auxiliary variables (particles) in order to generate the new block variable assignments.",3.1 Sequential sampler,[0],[0]
The procedure is outlined in Algorithm 1.,3.1 Sequential sampler,[0],[0]
"Given a previous latent state assignment y′1:T and observations x1:T , the CSMC kernel produces a new latent state assignment via M auxiliary particles where one particle is fixed to the previous assignment.",3.1 Sequential sampler,[0],[0]
"For ergodicity, M ≥ 2, where larger values of M may improve mixing rate at the expense of increased computation per step.
",3.1 Sequential sampler,[0],[0]
Proposal distribution.,3.1 Sequential sampler,[0],[0]
The choice of proposal distribution q is crucial to the performance of SMC methods.,3.1 Sequential sampler,[0],[0]
"In the case of continuous latent variables,
it is common to propose yt from the transition probability p(Yt | y1:t−1) because this distribution usually has a simple form that permits efficient sampling.",3.1 Sequential sampler,[0],[0]
"However, it is possible to do better in the case of discrete latent variables.",3.1 Sequential sampler,[0],[0]
"The optimal proposal distribution is the one which minimizes the variance of the importance weights, and is given by
q(yt | y1:t−1,x1:t)",3.1 Sequential sampler,[0],[0]
":= p(yt | y1:t−1,x1:t) (8)
= p(yt | y1:t−1)p(xt | yt)
p(xt | y1:t−1)
where
p(xt | y1:t−1)= ∑
yt∈Y p(yt | y1:t−1)p(xt | yt) (9)
Substituting this expression in equation (7) and simplifying yields the incremental weight update:
w̃t := w̃t−1 · p(xt | y1:t−1) (10)
Resampling.",3.1 Sequential sampler,[0],[0]
"In filtering applications, it is common to use resampling operations to prevent weight degeneracy.",3.1 Sequential sampler,[0],[0]
We do not find resampling necessary here for three reasons.,3.1 Sequential sampler,[0],[0]
"First, note that we resample hidden label sequences that are only as long as the number of words in a given sentence.",3.1 Sequential sampler,[0],[0]
"Second, we use a proposal which minimizes the variance of the weights.",3.1 Sequential sampler,[0],[0]
"Finally, we use SMC as a kernel embedded in an MCMC sampler; asymptotically, this procedure yields samples from the desired posterior regardless of degeneracy (which only affects the mixing rate).",3.1 Sequential sampler,[0],[0]
"Practically speaking, one can diagnose the need for resampling via the effective sample size (ESS) of the particle system:
ESS := 1
∑M m=1(w̃",3.1 Sequential sampler,[0],[0]
"(m))2 =
( ∑M
m=1w (m))2
∑M m=1(w",3.1 Sequential sampler,[0],[0]
"(m))2
In our experiments, we find that ESS remains high (a significant fraction of M ) even for long sentences, suggesting that resampling is not necessary to enable mixing of the the Gibbs sampler.
",3.1 Sequential sampler,[0],[0]
Decoding.,3.1 Sequential sampler,[0],[0]
"In order to obtain a single latent variable assignment for evaluation purposes, we simply take the state of the Markov chain after a fixed number of iterations of particle Gibbs.",3.1 Sequential sampler,[0],[0]
"In principle, one could collect many samples during particle Gibbs and use them to perform minimum Bayes risk decoding under a given loss function.",3.1 Sequential sampler,[0],[0]
"However, this approach is somewhat slower and did not appear to improve performance in preliminary experiments
Algorithm 1 Conditional SMC 1: procedure CSMC(x1:T , y′1:T , M ) 2:",3.1 Sequential sampler,[0],[0]
Draw y(m)1 (eqn.,3.1 Sequential sampler,[0],[0]
8) for m ∈,3.1 Sequential sampler,[0],[0]
"[1,M − 1] 3: Set y(M)1 = y ′ 1
4: Set w̃(m)1 (eqn. 10) for m ∈",3.1 Sequential sampler,[0],[0]
"[1,M ] 5: for t",3.1 Sequential sampler,[0],[0]
= 2 to T do 6: Draw y(m)t (eqn.,3.1 Sequential sampler,[0],[0]
8) for m ∈,3.1 Sequential sampler,[0],[0]
"[1,M −1] 7: Set yMt = y ′ t 8: Set w̃(m)t (eqn. 10) for m ∈",3.1 Sequential sampler,[0],[0]
"[1,M ] 9: Set w̃(m) = w̃(m)T",3.1 Sequential sampler,[0],[0]
p($|y1:T ) for m ∈,3.1 Sequential sampler,[0],[0]
"[1,M ]
10: Draw index k where p(k = m) ∝",3.1 Sequential sampler,[0],[0]
w̃(m) 11: return y(k)1:T,3.1 Sequential sampler,[0],[0]
We now present an sampler for settings such as NER where each latent label emits a segment consisting of 1 or more words.,3.2 Segmental sampler,[0],[0]
"We make use of the same transition distribution p(yt | y1:t−1), which determines the probability of a label in a given context, and an emission distribution p(xt | yt) (namely Pyt); these are assumed to be drawn from hierarchical Pitman-Yor processes described in §2.5 and §2.1, respectively.",3.2 Segmental sampler,[0],[0]
"To allow the xt to be a multi-word string, we simply augment the character set with a distinguished space symbol ∈ Σ that separates words within a string.",3.2 Segmental sampler,[0],[0]
"For instance, New York would be generated as the 9-symbol sequence New York$.
Although the model emits New York all at once, we still formulate our inference procedure as a particle filter that proposes one tag for each word.",3.2 Segmental sampler,[0],[0]
"Thus, for a given segment label type y, we allow two tag types for its words:
• I-y corresponds to a non-final word in a segment of type y (in effect, a word with a following attached).",3.2 Segmental sampler,[0],[0]
•,3.2 Segmental sampler,[0],[0]
"E-y corresponds to the final word in a segment
of type y.
For instance, x1:2 = New York would be annotated as a location segment by defining y1:2 = I-LOC E-LOC.",3.2 Segmental sampler,[0],[0]
"This says that y1:2 has jointly emitted x1:2, an event with prior probability PLOC(New York).",3.2 Segmental sampler,[0],[0]
Each word that is not part of a named entity is considered to be a singleword segment.,3.2 Segmental sampler,[0],[0]
"For example, if the next word were x3 = hosted then it should be tagged with y3 = hosted as in §2.5, in which case x3 was emitted with probability 1.
",3.2 Segmental sampler,[0],[0]
"To adapt the sampler described in §3.1 for the segmental case, we need only to define the transition and emission probabilities used in equation (8) and its denominator (9).
",3.2 Segmental sampler,[0],[0]
"For the transition probabilities, we want to model the sequence of segment labels.",3.2 Segmental sampler,[0],[0]
"If yt−1 is an I- tag, we take p(yt | y1:t−1) = 1 , since then yt merely continues an existing segment.",3.2 Segmental sampler,[0],[0]
"Otherwise yt starts a new segment, and we take p(yt | y1:t−1) = 1 to be defined by the PYP’s probability Gy1:t−1(yt) as usual, but where we interpret the subscript y1:t−1 to refer to the possibly shorter sequence of segment labels implied by those t− 1 tags.
",3.2 Segmental sampler,[0],[0]
"For the emission probabilities, if yt has the form I-y or E-y, then its associated emission probability no longer has the form p(xt | yt), since the choice of xt also depends on any words emitted earlier in the segment.",3.2 Segmental sampler,[0],[0]
Let s ≤ t be the starting position of the segment that contains t.,3.2 Segmental sampler,[0],[0]
"If yt = E-y, then the emission probability is proportional to Py(xs xs+1 . . .",3.2 Segmental sampler,[0],[0]
xt).,3.2 Segmental sampler,[0],[0]
If yt = I-y then the emission probability is proportional to the prefix probability ∑ x Py(x) where x ranges over all strings in Σ∗,3.2 Segmental sampler,[0],[0]
that have xs xs+1 . . .,3.2 Segmental sampler,[0],[0]
xt,3.2 Segmental sampler,[0],[0]
as a proper prefix.,3.2 Segmental sampler,[0],[0]
"Prefix probabilities in Hy are easy to compute because Hy has the form of a language model, and prefix probabilities in Py are therefore also easy to compute (using a prefix tree for efficiency).
",3.2 Segmental sampler,[0],[0]
This concludes the description of the segmental sampler.,3.2 Segmental sampler,[0],[0]
Note that the particle Gibbs procedure is unchanged.,3.2 Segmental sampler,[0],[0]
"Automatically inducing parts-of-speech from raw text is a challenging problem (Goldwater et al., 2005).",4 Inducing parts-of-speech with type-level supervision,[0],[0]
"Our focus here is on the easier problem of type-supervised part-of-speech induction, in which (partial) dictionaries are used to guide inference (Garrette and Baldridge, 2012; Li et al., 2012).",4 Inducing parts-of-speech with type-level supervision,[0],[0]
"Conditioned on the unlabeled corpus and dictionary, we use the MCMC procedure described in §3.1 to impute the latent parts-of-speech.
",4 Inducing parts-of-speech with type-level supervision,[0],[0]
"Since dictionaries are freely available for hundreds of languages,6 we see this as a mild additional requirement in practice over the purely unsupervised setting.
",4 Inducing parts-of-speech with type-level supervision,[0],[0]
"In prior work, dictionaries have been used as constraints on possible parts-of-speech: words appearing in the dictionary take one of their known parts-
6https://www.wiktionary.org/
of-speech.",4 Inducing parts-of-speech with type-level supervision,[0],[0]
"In our setting, however, the dictionaries are not constraints but evidence.",4 Inducing parts-of-speech with type-level supervision,[0],[0]
"If monthly is listed in (only) the adjective lexicon, this tells us that PADJ sometimes generates monthly and therefore that HADJ may also tend to generate other words that end with -ly.",4 Inducing parts-of-speech with type-level supervision,[0],[0]
"However, for us, PADV(monthly) > 0",4 Inducing parts-of-speech with type-level supervision,[0],[0]
"as well, allowing us to still correctly treat monthly as a possible adverb if we later encounter it in a training or test corpus.",4 Inducing parts-of-speech with type-level supervision,[0],[0]
"We follow the experimental procedure described in Li et al. (2012), and use their released code and data to compare to their best model: a second-order maximum entropy Markov model parametrized with log-linear features (SHMM-ME).",4.1 Experiments,[0],[0]
"This model uses hand-crafted features designed to distinguish between different parts-of-speech, and it has special handling for rare words.",4.1 Experiments,[0],[0]
"This approach is surprisingly effective and outperforms alternate approaches such as cross-lingual transfer (Das and Petrov, 2011).",4.1 Experiments,[0],[0]
"However, it also has limitations, since words that do not appear in the dictionary will be unconstrained, and spurious or incorrect lexical entries may lead to propagation of errors.
",4.1 Experiments,[0],[0]
"The lexicons are taken from the Wiktionary project; their size and coverage are documented by (Li et al., 2012).",4.1 Experiments,[0],[0]
We evaluate our model on multi-lingual data released as part of the CoNLL 2007 and CoNLL-X shared tasks.,4.1 Experiments,[0],[0]
"In particular, we use the same set of languages as Li et al. (2012).7 For our method, we impute the parts-of-speech by running particle Gibbs for 100 epochs, where one epoch consists of resampling the states for a each sentence in the corpus.",4.1 Experiments,[0],[0]
"The final sampler state is then taken as a 1-best tagging of the unlabeled data.
",4.1 Experiments,[0],[0]
Results.,4.1 Experiments,[0],[0]
The results are reported in Table 1.,4.1 Experiments,[0],[0]
"We find that our hierarchical sequence memoizer (HSM) matches or exceeds the performance of the baseline (SHMM-ME) for nearly all the tested languages, particularly for morphologically rich languages such as German where the spelling distributions Hy may capture regularities.",4.1 Experiments,[0],[0]
"It is interesting to note that our model performs worse relative to the baseline for English; one possible explanation is that the baseline uses hand-engineered features whereas ours does not, and these features may have been tuned using English data for validation.
",4.1 Experiments,[0],[0]
7With the exception of Dutch.,4.1 Experiments,[0],[0]
"Unlike the other CoNLL languages, Dutch includes phrases, and the procedure by which these were split into tokens was not fully documented.
",4.1 Experiments,[0],[0]
Our generative model is supposed to exploit lexicons well.,4.1 Experiments,[0],[0]
"To see what is lost from using a generative model, we also compared with Li et al. (2012) on standard supervised tagging without any lexicons.",4.1 Experiments,[0],[0]
"Even here our generative model is very competive, losing only on English and Swedish.",4.1 Experiments,[0],[0]
Name lists and dictionaries are useful for NER particularly when in-domain annotations are scarce.,5 Boostrapping NER with type-level supervision,[0],[0]
"However, with little annotated data, discriminative training may be unable to reliably estimate lexical feature weights and may overfit.",5 Boostrapping NER with type-level supervision,[0],[0]
"In this section, we are interested in evaluating our proposed Bayesian model in the context of low-resource NER.",5 Boostrapping NER with type-level supervision,[0],[0]
"Most languages do not have corpora annotated for parts-of-speech, named-entities, syntactic parses, or other linguistic annotations.",5.1 Data,[0],[0]
"Therefore, rapidly deploying natural language technologies in a new language may be challenging.",5.1 Data,[0],[0]
"In the context of facilitating relief responses in emergencies such as natural disasters, the DARPA LORELEI (Low Resource Languages for Emergent Incidents) program has sponsored the development and release of representative “language packs” for Turkish and Uzbek with more languages planned (Strassel and Tracey, 2016).",5.1 Data,[0],[0]
"We use the named-entity annotations as part of these language packs which include persons, locations, organizations, and geo-political entities, in order to explore bootstrapping named-entity recognition from small amounts of data.",5.1 Data,[0],[0]
"We consider two types of data: ¬ in-context annotations, where sentences are fully annotated for named-entities, and  lexical resources.
",5.1 Data,[0],[0]
The LORELEI language packs lack adequate indomain lexical resources for our purposes.,5.1 Data,[0],[0]
"Therefore, we simulate in-domain lexical resources by holding out portions of the annotated development data and deriving dictionaries and name lists from them.",5.1 Data,[0],[0]
"For each label y ∈ {PER, LOC, ORG, GPE, CONTEXT}, our lexicon for y lists all distinct y-labeled strings that appear in the held-out data.",5.1 Data,[0],[0]
This setup ensures that the labels associated with lexicon entries correspond to the annotation guidelines used in the data we use for evaluation.,5.1 Data,[0],[0]
"It avoids possible problems that might arise when leveraging noisy out-of-domain knowledge bases, which we may explore in future.",5.1 Data,[0],[0]
In this section we report supervised NER experiments on two low-resource languages: Turkish and Uzbek.,5.2 Evaluation,[0],[0]
We vary both the amount of supervision as well as the size of the lexical resources.,5.2 Evaluation,[0],[0]
A challenge when evaluating the performance of a model with small amounts of training data is that there may be high-variance in the results.,5.2 Evaluation,[0],[0]
"In order to have more confidence in our results, we perform bootstrap resampling experiments in which the training set, evaluation set, and lexical resources are randomized across several replications of the same experiment (for each of the data conditions).",5.2 Evaluation,[0],[0]
"We use 10 replications for each of the data conditions reported in Figures 1–2, and report both the mean performance and 95% confidence intervals.
Baseline.",5.2 Evaluation,[0],[0]
"We use the Stanford NER system with a standard set of language-independent features (Finkel et al., 2005).8.",5.2 Evaluation,[0],[0]
This model is a conditional random field (CRF) with feature templates which include character n-grams as well as word shape features.,5.2 Evaluation,[0],[0]
"Crucially, we also incorporate lexical features.",5.2 Evaluation,[0],[0]
"The CRF parameters are regularized using an L1 penalty and optimized via Orthant-wise limited-memory quasi-Newton optimization (Andrew and Gao, 2007).",5.2 Evaluation,[0],[0]
"For both our proposed method and the discriminative baseline, we use a fixed set of hyperparameters (i.e. we do not use a separate validation set for tuning each data condition).",5.2 Evaluation,[0],[0]
"In order to make a fair comparison to the CRF, we use our sampler for forward inference only, without resampling on the test data.
Results.",5.2 Evaluation,[0],[0]
We show learning curves as a function of supervised training corpus size.,5.2 Evaluation,[0],[0]
Figure 1 shows that our generative model strongly beats the baseline in this low-data regime.,5.2 Evaluation,[0],[0]
"In particular, when there is little annotated training data, our proposed generative model can compensate by exploiting the lexicon, while the discriminative baseline scores terribly.",5.2 Evaluation,[0],[0]
"The performance gap decreases with larger
8We also experimented with neural models, but found that the CRF outperformed them in low-data conditions.
supervised corpora, which is consistent with prior results comparing generative and discriminative training (Ng and Jordan, 2002).
",5.2 Evaluation,[0],[0]
"In Figure 2, we show the effect of the lexicon’s size: as expected, larger lexicons are better.",5.2 Evaluation,[0],[0]
"The generative approach significantly outperforms the discriminative baseline at any lexicon size, although its advantage drops for smaller lexicons or larger training corpora.
",5.2 Evaluation,[0],[0]
"In Figure 1 we found that increasing the pseudocount c consistently decreases performance, so we used c = 1 in our other experiments.9",5.2 Evaluation,[0],[0]
This paper has described a generative model for low-resource sequence labeling and segmentation tasks using lexical resources.,6 Conclusion,[0],[0]
Experiments in semisupervised and low-resource settings have demonstrated its applicability to part-of-speech induction and low-resource named-entity recognition.,6 Conclusion,[0],[0]
There are many potential avenues for future work.,6 Conclusion,[0],[0]
Our model may be useful in the context of active learning where efficient re-estimation and performance in low-data conditions are important.,6 Conclusion,[0],[0]
"It would also be interesting to explore more expressive parameterizations, such recurrent neural networks for Hy.",6 Conclusion,[0],[0]
"In the space of neural methods, differentiable memory (Santoro et al., 2016) may be more flexible than the PYP prior, while retaining the ability of the model to cache strings observed in the gazetteer.",6 Conclusion,[0],[0]
"This work was supported by the JHU Human Language Technology Center of Excellence, DARPA LORELEI, and NSF grant IIS-1423276.",Acknowledgments,[0],[0]
"Thanks to Jay Feldman for early discussions.
",Acknowledgments,[0],[0]
9Why?,Acknowledgments,[0],[0]
"Even a pseudocount of c = 1 is enough to ensure that Py(s) Hy(s), since the prior probability Hy(s) is rather small for most strings in the lexicon.",Acknowledgments,[0],[0]
"Indeed, perhaps c < 1 would have increased performance, particularly if the lexicon reflects out-of-domain data.",Acknowledgments,[0],[0]
"This could be arranged, in effect, by using a hierarchical Bayesian model in which the lexicon and corpus emissions are not drawn from the identical distribution Py but only from similar (coupled) distributions.",Acknowledgments,[0],[0]
Lexical resources such as dictionaries and gazetteers are often used as auxiliary data for tasks such as part-of-speech induction and named-entity recognition.,abstractText,[0],[0]
"However, discriminative training with lexical features requires annotated data to reliably estimate the lexical feature weights and may result in overfitting the lexical features at the expense of features which generalize better.",abstractText,[0],[0]
"In this paper, we investigate a more robust approach: we stipulate that the lexicon is the result of an assumed generative process.",abstractText,[0],[0]
"Practically, this means that we may treat the lexical resources as observations under the proposed generative model.",abstractText,[0],[0]
The lexical resources provide training data for the generative model without requiring separate data to estimate lexical feature weights.,abstractText,[0],[0]
We evaluate the proposed approach in two settings: part-of-speech induction and lowresource named-entity recognition.,abstractText,[0],[0]
Bayesian Modeling of Lexical Resources for Low-Resource Settings,title,[0],[0]
"Flexible and computationally efficient models for streaming data are required in many machine learning applications, and in this paper we propose a new class of models for these situations.",1. Introduction,[0],[0]
"Specifically, we are interested in models suitable for domains that exhibit changes in the underlying generative process (Gama et al., 2014).",1. Introduction,[0],[0]
"We envision a situation, where one receives batches of data at discrete points in time.",1. Introduction,[0],[0]
"As each new batch arrives, we want to glean information from the new data, while also retaining relevant information from the historical observations.
",1. Introduction,[0],[0]
"Our modelling is inspired by previous works on Bayesian recursive estimation (Özkan et al., 2013; Kárnỳ, 2014), power priors (Ibrahim & Chen, 2000) and exponential for-
1Department of Mathematics, Unversity of Almerı́a, Almerı́a, Spain 2Department of Computer and Information Science, Norwegian University of Science and Technology, Trondheim, Norway 3Department of Computer Science, Aalborg University, Aalborg, Denmark 4Hugin",1. Introduction,[0],[0]
"Expert A/S, Aalborg, Denmark.",1. Introduction,[0],[0]
Correspondence to: Andrés,1. Introduction,[0],[0]
Masegosa,1. Introduction,[0],[0]
"<andresmasegosa@ual.es>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
getting approaches (Honkela & Valpola, 2003).",1. Introduction,[0],[0]
"However, all of these methods were developed for slowly changing processes, where the rate of change anticipated by the model is controlled by a quantity that must be set manually.",1. Introduction,[0],[0]
"Our solution, on the other hand, can accommodate both gradual and abrupt concept drift by continuously assessing the similarity between new and historic data using a fully Bayesian paradigm.
",1. Introduction,[0],[0]
"Building Bayesian models for data streams raises computational problems, as data may arrive with high velocity and is unbounded in size.",1. Introduction,[0],[0]
We therefore develop an approximate variational inference technique based on a novel lower-bound of the data likelihood function.,1. Introduction,[0],[0]
"The appropriateness of the approach is investigated through experiments using both synthetic and real-life data, giving encouraging results.",1. Introduction,[0],[0]
The proposed methods are released as part of an open-source toolbox for scalable probabilistic machine learning (http://www.amidsttoolbox.com),1. Introduction,[0],[0]
"(Masegosa et al., 2017; 2016b; Cabañas et al., 2016).",1. Introduction,[0],[0]
In this paper we focus on conjugate exponential Bayesian network models for performing Bayesian learning on streaming data.,2. Preliminaries,[0],[0]
"To simplify the presentation, we shall initially focus on the model structure shown in Figure 1 (a).",2. Preliminaries,[0],[0]
This model includes the observed data x = xi=1,2. Preliminaries,[0],[0]
":N , global hidden variables (or parameters) β = β1:M , a set of local hidden variables z = z1:N , and a vector of fixed (hyper) parameters denoted by α.",2. Preliminaries,[0],[0]
"Notice how the dynamics of the process is not included in the model of Figure 1 (a); the model will be set in the context of data streams in Section 4, where we extend it to incorporate explicit dynamics over the (global) parameters to capture concept drift.
",2. Preliminaries,[0],[0]
"With the conditional distributions in the model belonging to the exponential family, we have that all distributions are of the following form
ln p(Y |pa(Y ))",2. Preliminaries,[0],[0]
= lnhY + ηY,2. Preliminaries,[0],[0]
(pa(Y )),2. Preliminaries,[0],[0]
"T tY (Y )− aY (ηY (pa(Y ))),
where pa(Y ) denotes the parents of Y in the directed acyclic graph of the induced Bayesian network model.",2. Preliminaries,[0],[0]
"The scalar functions hY and aY (·) are the base measure and
the log-normalizer, respectively; the vector functions ηY (·) and tY (·) are the natural parameters and the sufficient statistics vectors, respectively.",2. Preliminaries,[0],[0]
"The subscript Y means that the associated functional forms may be different for the different factors of the model, but we may remove the subscript when clear from the context.",2. Preliminaries,[0],[0]
"By also requiring that the distributions are conjugate, we have that the posterior distribution for each variable in the model has the same functional form as its prior distribution.",2. Preliminaries,[0],[0]
"Consequently, learning (i.e. conditioning the model on observations) only changes the values of the parameters of the model, and not the functional form of the distributions.
",2. Preliminaries,[0],[0]
"Variational inference is a deterministic technique for finding tractable posterior distributions, denoted by q, which approximates the Bayesian posterior, p(β, z|x), that is often intractable to compute.",2. Preliminaries,[0],[0]
"More specifically, by letting Q be a set of possible approximations of this posterior, variational inference solves the following optimization problem for any model in the conjugate exponential family:
min q(β,z)∈Q
KL(q(β, z)|p(β, z|x)), (1)
where KL denotes the Kullback-Leibler divergence between two probability distributions.
",2. Preliminaries,[0],[0]
In the mean field variational approach the approximation familyQ is assumed to fully factorize.,2. Preliminaries,[0],[0]
"Extending the notation of Hoffman et al. (2013), we have that
q(β, z|λ,φ) = M∏ k=1 q(βk|λk) N∏ i=1",2. Preliminaries,[0],[0]
"J∏ j=1 q(zi,j |φi,j),
where J is the number of local hidden variables, which is assumed fixed for all i = 1, . . .",2. Preliminaries,[0],[0]
", N .",2. Preliminaries,[0],[0]
"The parameterizations of the variational distributions are made explicit, in that λ parameterize the variational distribution of β, while φ has the same role for the variational distribution of z.
To solve the minimization problem in Equation (1), the
variational approach exploits the transformation
lnP (x) = L(λ,φ|x,αu) + KL(q(β, z|λ,φ)|p(β, z|x)), (2) where L(·|·) is a lower bound of lnP (x) since KL is nonnegative.",2. Preliminaries,[0],[0]
x,2. Preliminaries,[0],[0]
"and αu are introduced in L’s notation to make explicit the function’s dependency on x, the data sample, and αu, the natural parameters of the prior over β.",2. Preliminaries,[0],[0]
"As lnP (x) is constant, minimizing the KL term is equivalent to maximizing the lower bound.",2. Preliminaries,[0],[0]
"Variational methods maximize this lower bound by applying a coordinate ascent that iteratively updates the individual variational distributions while holding the others fixed (Winn & Bishop, 2005).",2. Preliminaries,[0],[0]
"The key advantage of having a conjugate exponential model is that the gradients of theL function can be always computed in closed form (Winn & Bishop, 2005).",2. Preliminaries,[0],[0]
"Bayesian inference on streaming data has been widely studied (Ahmed et al., 2011; Doucet et al., 2000; Yao et al., 2009).",3. Related Work,[0],[0]
"In the context of variational inference, there are two main approaches.",3. Related Work,[0],[0]
Ghahramani & Attias (2000); Broderick et al. (2013) propose recursive Bayesian updating of the variational approximation.,3. Related Work,[0],[0]
"The streaming variational Bayes (SVB) algorithm (Broderick et al., 2013) is the most known approach of this category.",3. Related Work,[0],[0]
"Alternatively, one could cast the inference problem as a stochastic optimization problem.",3. Related Work,[0],[0]
"Stochastic variational inference (SVI) (Hoffman et al., 2013) and the closely related population variational Bayes (PVB) (McInerney et al., 2015) are prominent examples from this group.",3. Related Work,[0],[0]
"SVI assumes the existence of a fixed data set observed in a sequential manner, and in particular that this data set has a known finite size.",3. Related Work,[0],[0]
This is unrealistic when modeling data streams.,3. Related Work,[0],[0]
"PVB addresses this problem by using the frequentist notion of a population distribution, F, which is assumed to generate the data stream by repeatedly sampling M data points at the time.",3. Related Work,[0],[0]
"M parameterizes the size of the population, and helps control the variance of the population posterior.",3. Related Work,[0],[0]
"Unfortunately, M must be specified by the user.",3. Related Work,[0],[0]
"No clear rule exists regarding how to set it, and McInerney et al. (2015) show that its optimal value may differ from one data stream to another.
",3. Related Work,[0],[0]
"The problem of Bayesian modeling of non-stationary data streams (i.e., with concept drift (Gama et al., 2014)) is not addressed by SVB, as it assumes data exchangeability.",3. Related Work,[0],[0]
"An online variational inference method, which exponentially forgets the variational parameters associated with old data, was proposed by Honkela & Valpola (2003).",3. Related Work,[0],[0]
"The so-called power prior approach (Ibrahim & Chen, 2000) is also based on an exponential forgetting mechanisms, and has nice theoretical properties (Ibrahim et al., 2003).",3. Related Work,[0],[0]
"Nevertheless, both approaches rely on a hyper-parameter determining forgetting, which has to be set manually.",3. Related Work,[0],[0]
"PVB can
also adapt to concept drift, because the variance of the variational posterior never decreases below a given threshold indirectly controlled by M , but again, the hyper-parameter has to be set manually.
",3. Related Work,[0],[0]
A time series based modeling approach for concept drift using implicit transition models was pursued by Özkan et al. (2013); Kárnỳ (2014).,3. Related Work,[0],[0]
"Unfortunately, the implicit transition model depends on a hyper-parameter determining the forgetting-factor, which has to be manually set.",3. Related Work,[0],[0]
"In this paper we build on this approach, adapt it to variational settings, and place a hierarchical prior on its forgetting parameter.",3. Related Work,[0],[0]
This greatly improves the flexibility and accuracy of the resulting model when making inferences over drifting data streams.,3. Related Work,[0],[0]
In this section we extend the model in Figure 1 (a) to also account for the dynamics of the data stream being modeled.,4. Hierarchical Power Priors,[0],[0]
"We shall here assume that only the parameters β in Figure 1 (a) are time-varying, which we will indicate with the subscript t, i.e., βt.",4. Hierarchical Power Priors,[0],[0]
First we briefly describe the approach on which the proposed model is based.,4. Hierarchical Power Priors,[0],[0]
"Afterwards, we introduce the hierarchical power prior and detail a variational inference procedure for this model class.",4. Hierarchical Power Priors,[0],[0]
"In order to extend the model in Figure 1 (a) to data streams, we may introduce a transition model p(βt|βt−1) to explicitly model the evolution of the parameters over time, enabling the estimation of the predictive density at time t:
p(βt|x1:t−1) = ∫",4.1. Power Priors as Implicit Transition Models,[0],[0]
"p(βt|βt−1)p(βt−1|x1:t−1)dβt−1.
(3) However, this approach introduces two problems.",4.1. Power Priors as Implicit Transition Models,[0],[0]
"First of all, in non-stationary domains we may not have a single transition model or the transition model may be unknown.",4.1. Power Priors as Implicit Transition Models,[0],[0]
"Secondly, if we seek to position the model within the conjugate exponential family in order to be able to compute the gradients of L in closed-form, we need to ensure that the distribution family for βt is its own conjugate distribution, thereby severely limiting model expressivity (we can, e.g., not assign a Dirichlet distribution to βt).
",4.1. Power Priors as Implicit Transition Models,[0],[0]
"Rather than explicitly modeling the evolution of the βt parameters as in Equation (3), we instead follow the approach of Kárnỳ (2014) and Özkan et al. (2013) who define the time evolution model implicitly by constraining the maximum KL divergence over consecutive parameter distributions.",4.1. Power Priors as Implicit Transition Models,[0],[0]
"Specifically, by defining
pδ(βt|x1:t−1) = ∫",4.1. Power Priors as Implicit Transition Models,[0],[0]
"δ(βt − βt−1)p(βt−1|x1:t−1)dβt−1
(4)
one can restrict the space of possible distributions p(βt|x1:t−1), supported by an unknown transition model, by the constraint
KL(p(βt|x1:t−1), pδ(βt|x1:t−1)) ≤ κ.",4.1. Power Priors as Implicit Transition Models,[0],[0]
"(5)
Kárnỳ (2014) and Özkan et al. (2013) seek to approximate p(βt|x1:t−1) by the distribution p̂(βt|x1:t−1) having maximum entropy under the constraint in (5); for continuous distributions the maximum entropy can be formulated relative to an uninformative prior density pu(βt), which corresponds to the Kullbach-Leibler divergence between the two distributions.",4.1. Power Priors as Implicit Transition Models,[0],[0]
"This approach ensures that we will not underestimate the uncertainty in the parameter distribution and the particular solution being sought takes the form
p̂(βt|x1:t−1, ρt) ∝",4.1. Power Priors as Implicit Transition Models,[0],[0]
"pδ(βt|x1:t−1)ρtpu(βt)(1−ρt), (6)
",4.1. Power Priors as Implicit Transition Models,[0],[0]
"where 0 ≤ ρt ≤ 1 is indirectly defined by (5) which in turn depends on the user defined parameter κ.
",4.1. Power Priors as Implicit Transition Models,[0],[0]
"In our streaming data setting we follow assumed density filtering (Lauritzen, 1992) and the SVB approach (Broderick et al., 2013) and employ the approximation p(βt−1|x1:t−1)",4.1. Power Priors as Implicit Transition Models,[0],[0]
"≈ q(βt−1|λt−1), where q(βt−1|λt−1) is the variational distribution calculated in the previous time step.",4.1. Power Priors as Implicit Transition Models,[0],[0]
"Using this approximation in (3) and (4), we can express pδ in terms of λt−1 in which case (6) becomes
p̂(βt|λt−1, ρt) ∝ pδ(βt|λt−1)ρtpu(βt)(1−ρt), (7)
which we use as the prior density for time step t. Now, if pu(βt) belong to the same family as q(βt−1|λt−1), then p̂(βt|λt−1, ρt) will stay within the same family and have natural parameters ρtλt−1+(1−ρt)αu, where αu are the natural parameters of pu(βt).",4.1. Power Priors as Implicit Transition Models,[0],[0]
"Thus, under this approach, the transitioned posterior remains within the same exponential family, so we can enjoy the full flexibility of the conjugate exponential family (i.e. computing gradients of the L function in closed form), an option that would not be available if one were to explicitly specify a transition model as in Equation (3).
",4.1. Power Priors as Implicit Transition Models,[0],[0]
"So, at each time step, we simply have to solve the following variational problem, where only the prior changes with respect to the original SVB approach,
arg max λt,φt L(λt,φt|xt, ρtλt−1 + (1− ρt)αu).
",4.1. Power Priors as Implicit Transition Models,[0],[0]
"As stated in the following lemma, this approach coincides with the so-called power priors approach (Ibrahim & Chen, 2000), a term that we will also adopt in the following.
",4.1. Power Priors as Implicit Transition Models,[0],[0]
Lemma 1.,4.1. Power Priors as Implicit Transition Models,[0],[0]
"The Bayesian updating scheme described by Figure 1 (b) and Equation 6, but with ρt fixed to a constant value, is equivalent to the recursive application of
the Bayesian updating scheme of power priors (Ibrahim & Chen, 2000).",4.1. Power Priors as Implicit Transition Models,[0],[0]
"This scheme is expressed as follows:
p(β|x1,x0, ρ) ∝ p(x1|β)p(x0|β)ρp(β),
where x0 and x1 is the observation at time 0 (historical observation) and time 1 (current observation), respectively.
",4.1. Power Priors as Implicit Transition Models,[0],[0]
Proof sketch.,4.1. Power Priors as Implicit Transition Models,[0],[0]
"Translate the recursive Bayesian updating approach of power priors into an equivalent two time slice model, where β0 is given a prior distribution p and p(β1|β0) is a Dirac delta function.",4.1. Power Priors as Implicit Transition Models,[0],[0]
"The distribution p(β1|x0,x1, ρ) in this model is equivalent to p(β|x1,x0, ρ), which, in turn, is equivalent (up to proportionality) to p(x1|β1)p̂(β1|x0, ρt).",4.1. Power Priors as Implicit Transition Models,[0],[0]
"Note that the last p̂ term can alternatively be expressed as p̂(β1|x0, ρt) ∝ pδ(β1|x0)ρp(β1)1−ρ ∝ pδ(x0|β1)ρp(β1).
",4.1. Power Priors as Implicit Transition Models,[0],[0]
"The perspective provided by Lemma 1 introduces a well known result of power priors, which is also applicable in the current context (see the discussion after Theorem 1 in (Ibrahim et al., 2003)): “the power prior is an optimal prior to use and in fact minimizes the convex combination of KL divergences between two extremes: one in which no historical data is used and the other in which the historical data and current data are given equal weight.”",4.1. Power Priors as Implicit Transition Models,[0],[0]
"As noted in (Olesen et al., 1992; Özkan et al., 2013), this schema works as a moving window with exponential forgetting of past data, where the effective number of samples or, more technically, the so-called equivalent sample size of the posterior (Heckerman et al., 1995), converges to,
lim t→∞ ESSt = |xt| 1− ρ
(8)
if the size of the data batches is constant1.
",4.1. Power Priors as Implicit Transition Models,[0],[0]
For the experimental results reported in Section 5 we shall refer to the method outlined above as SVB with power priors (SVB-PP).,4.1. Power Priors as Implicit Transition Models,[0],[0]
"In the approach taken by Özkan et al. (2013) (and, by extension, SVB-PP), the forgetting factor ρt is user-defined.",4.2. The Hierarchical Power Prior Model,[0],[0]
"In this paper, we instead pursue a (hierarchical) Bayesian approach and introduce a prior distribution over ρt allowing the distribution over ρt (and thereby the forgetting mechanism) to adapt to the data stream.
",4.2. The Hierarchical Power Prior Model,[0],[0]
"As we shall see below, in order to support a variational updating scheme we need to restrict the prior distribution over ρt, effectively limiting the choice of prior distribution to
1For instance, the ESS of a Beta distribution is equal to the sum of the components of λt and, in turn, equal to the number of data samples seen so far plus the prior’s pseudo-samples.
",4.2. The Hierarchical Power Prior Model,[0],[0]
"either an exponential distribution or a normal distribution with fixed variance, both of which should be truncated to the interval",4.2. The Hierarchical Power Prior Model,[0],[0]
"[0, 1].",4.2. The Hierarchical Power Prior Model,[0],[0]
"Unless explicitly stated otherwise, we shall for now assume a truncated exponential distribution with natural parameter γ as prior distribution over ρt:
p(ρt|γ) = γ exp(−γρt) 1− exp(−γ) .",4.2. The Hierarchical Power Prior Model,[0],[0]
"(9)
The resulting model can be illustrated as in Figure 1 (b).",4.2. The Hierarchical Power Prior Model,[0],[0]
We shall refer to models of this type as hierarchical power prior (HPP) models.,4.2. The Hierarchical Power Prior Model,[0],[0]
"For updating the model distributions we pursue a variational approach, where we seek to maximize the evidence lower bound L in Equation (2) for time step t. However, since the model in Figure 1 (b) does not define a conjugate exponential distribution due to the introduction of p(ρt) we cannot maximize L directly.",4.3. Variational Updating,[0],[0]
"Instead we will derive a (double) lower bound L̂ (L̂ ≤ L) and use this lower bound as a proxy for the updating rules for the variational posteriors.
",4.3. Variational Updating,[0],[0]
"First of all, by instantiating the lower bound LHPP (λt,φt, ωt|xt,λt−1) in Equation (2) for the HPP model we obtain
LHPP (λt,φt, ωt|xt,λt−1) = Eq[ln p(xt,Zt|βt)]",4.3. Variational Updating,[0],[0]
"+ Eq[ln p̂(βt|λt−1, ρt)]",4.3. Variational Updating,[0],[0]
+ Eq[p(ρt|γ)]− Eq[ln q(Zt|φt)],4.3. Variational Updating,[0],[0]
"− Eq[q(βt|λt)]− Eq[q(ρt|ωt)], (10)
where ωt is the variational parameter for the variational distribution for ρt; as we shall see later, ωt is a scalar and is therefore not shown in boldface.",4.3. Variational Updating,[0],[0]
"For ease of presentation we shall sometimes drop from LHPP (λt,φt, ωt|xt,λt−1) the subscript as well as the explicit specification of the parameters when these is otherwise clear from the context.
",4.3. Variational Updating,[0],[0]
We now define L̂HPP,4.3. Variational Updating,[0],[0]
"(λt,φt, ωt|xt,λt−1)",4.3. Variational Updating,[0],[0]
"as
L̂HPP (λt,φt, ωt|xt,λt−1) = Eq[ln p(xt,Zt|βt)]",4.3. Variational Updating,[0],[0]
+ Eq[ρt]Eq[ln pδ(βt|λt−1)],4.3. Variational Updating,[0],[0]
+ (1− Eq[ρt])Eq[ln pu(βt)],4.3. Variational Updating,[0],[0]
+ Eq[p(ρt|γ)]− Eq[ln q(Zt|φt)],4.3. Variational Updating,[0],[0]
"− Eq[q(βt|λt)]− Eq[q(ρt|ωt)], (11)
which provide a lower bound for L. Theorem 1. L̂HPP gives a lower bound for LHPP :
L̂HPP",4.3. Variational Updating,[0],[0]
"(λt,φt, ωt|xt,λt−1) ≤ LHPP (λt,φt, ωt|xt,λt−1).
",4.3. Variational Updating,[0],[0]
Proof sketch.,4.3. Variational Updating,[0],[0]
The inequality derives by using Equation (12) and observing that ag(ρtλt−1,4.3. Variational Updating,[0],[0]
+ (1 − ρt)αu) ≤ ρtag(λt−1),4.3. Variational Updating,[0],[0]
"+ (1− ρt)ag(αu) because the log-normalizer
ag is always a convex function (Wainwright et al., 2008)",4.3. Variational Updating,[0],[0]
.,4.3. Variational Updating,[0],[0]
"Full details are given in the supplementary material.
",4.3. Variational Updating,[0],[0]
"Rather than seeking to maximize L we will instead maximize L̂. The gap between the two bounds is determined only by the log-normalizer of p̂(βt|λt−1, ρt):
L̂ − L = Eq[ρtag(λt−1)",4.3. Variational Updating,[0],[0]
+ (1− ρt)ag(αu) + ag(ρtλt−1,4.3. Variational Updating,[0],[0]
"+ (1− ρt)αu)]
(12)
",4.3. Variational Updating,[0],[0]
"Thus, maximizing L̂ wrt.",4.3. Variational Updating,[0],[0]
"the variational parameters λt and φ also maxmizes L. By the same observation, we also have that the (natural) gradients are consistent relative to the two bounds:
Corollary 1.
",4.3. Variational Updating,[0],[0]
"∇̂λtL = ∇̂λtL̂ ∇̂φtL = ∇̂φtL̂ .
",4.3. Variational Updating,[0],[0]
Proof.,4.3. Variational Updating,[0],[0]
"Follows immediately from Equation (12) because the difference does not depend of λt and φt.
",4.3. Variational Updating,[0],[0]
"Thus, updating the variational parametersλt andφt in HPP models can be done as for regular conjugate exponential models of the form in Figure 1.
",4.3. Variational Updating,[0],[0]
"In order to update ωt we rely on L̂, which we can maximize using the natural gradient wrt.",4.3. Variational Updating,[0],[0]
"ωt (Sato, 2001) and which can be calculated in closed form for a restricted distribution family for ρt.
",4.3. Variational Updating,[0],[0]
Lemma 2.,4.3. Variational Updating,[0],[0]
"Assuming that the sufficient statistics function for ρt is the identity function, t(ρt) = ρt, then we have
∇̂ωtL̂ =KL(q(βt|λt), pu(βt))",4.3. Variational Updating,[0],[0]
"− KL(q(βt|λt), pδ(βt|λt−1))",4.3. Variational Updating,[0],[0]
"+ γ − ωt (13)
",4.3. Variational Updating,[0],[0]
Proof sketch.,4.3. Variational Updating,[0],[0]
Based on a straightforward algebraic derivation of the gradient using standard properties of the exponential family.,4.3. Variational Updating,[0],[0]
"Full details are given in the supplementary material.
",4.3. Variational Updating,[0],[0]
"Note that the truncated exponential distribution (see Equation (9)) satisfies the restriction expressed in Lemma 2, and also note that the variational posterior q(ρt|ωt) will be a truncated exponential density too.
",4.3. Variational Updating,[0],[0]
"On the other hand, observe that the form of the natural gradient of ωt have an intuitive semantic interpretation, which also extends to the coordinate ascent variational message passing framework (Winn & Bishop, 2005) as shown by Masegosa et al. (2016a).",4.3. Variational Updating,[0],[0]
"Specifically, using the constant γ as a threshold, we see that if the uninformed prior pu(βt) provides a better fit to the variational posterior at time t than the variational parameters λt from the previous time step (KL(q(βt|λt), pu(βt))",4.3. Variational Updating,[0],[0]
"+
γ < KL(q(βt|λt), pδ(βt|λt−1))), then we will get a negative value for ωt when performing coordinate ascent using Equation (13).",4.3. Variational Updating,[0],[0]
This in turn implies that Eq[ρ] < 0.5 because Eq[ρ] = 1/(1 − e−ωt),4.3. Variational Updating,[0],[0]
"− 1/ωt (plotted in Figure 2), which means that we have a higher degree of forgetting for past data.",4.3. Variational Updating,[0],[0]
If ωt > 0 then Eq[ρ] > 0.5 and less past data is forgotten.,4.3. Variational Updating,[0],[0]
Figure 2 graphically illustrates this trade-off.,4.3. Variational Updating,[0],[0]
"The HPP model can immediately be extended to include multiple power priors ρ(i)t , one for each global parameter βi.",4.4. The Multiple Hierarchical Power Prior Model,[0],[0]
In this model the ρ (i) t ’s are pair-wise independent.,4.4. The Multiple Hierarchical Power Prior Model,[0],[0]
"The latter ensures that optimizing the L̂ can be performed as above, since the variational distribution for each ρ(i)t can be updated independently of the other variational distributions over ρ(j)t , for j 6= i.",4.4. The Multiple Hierarchical Power Prior Model,[0],[0]
"This extended model allows local model substructures to have different forgetting mechanisms, thereby extending the expressivity of the model.",4.4. The Multiple Hierarchical Power Prior Model,[0],[0]
We shall refer to this extended model as a multiple hierarchical power prior (MHPP) model.,4.4. The Multiple Hierarchical Power Prior Model,[0],[0]
"In this section we will evaluate the following methods:
• Streaming variational Bayes (SVB).",5.1. Experimental Set-up,[0],[0]
"• Four versions of Population Variational Bayes
(PVB)2: Population-size M equal to the average size of each data-batch, or M equal to a fixed value (M = 1000 in Section 5.2 and M = 10 000 in Section 5.3).",5.1. Experimental Set-up,[0],[0]
Learning-rate ν = 0.1 or ν = 0.01.,5.1. Experimental Set-up,[0],[0]
• Two versions of SVB-PP: ρ = 0.9 or ρ = 0.99.,5.1. Experimental Set-up,[0],[0]
"• Two versions of SVB-HPP: A single shared ρ (de-
noted SVB-HPP) or separate ρ(i) parameters (SVBMHPP).
",5.1. Experimental Set-up,[0],[0]
"The underlying variational engine is the VMP algorithm (Winn & Bishop, 2005) for all models; VMP was termi-
2We do not compare with SVI, because SVI is a special case of PVB when M is equal to the total size of the stream.
nated after 100 iterations or if the relative increase in the lower bound fell below 0.01%.",5.1. Experimental Set-up,[0],[0]
"All priors were uninformative, using either flat Gaussians, flat Gamma priors or uniform Dirichlet priors.",5.1. Experimental Set-up,[0],[0]
We set γ = 0.1 for the HPP priors.,5.1. Experimental Set-up,[0],[0]
Variational parameters were randomly initialized using the same seed for all methods.,5.1. Experimental Set-up,[0],[0]
"First, we illustrate the behavior of the different approaches in a controlled experimental setting: We produced an artificial data stream by generating 100 samples (i.e., |xt| = 100) from a Binomial distribution at each time step.",5.2. Evaluation using an Artificial Data Set,[0],[0]
"We artificially introduce concept drift by changing the parameter p of the Binomial distribution: p = 0.2 for the first 30 time steps, then p = 0.5 for the following 30 time steps, and finally p = 0.8 for the last 40 time steps.",5.2. Evaluation using an Artificial Data Set,[0],[0]
"The data stream was modelled using a Beta-Binomial model.
",5.2. Evaluation using an Artificial Data Set,[0],[0]
Parameter Estimation: Figure 3 shows the evolution of Eq[βt] for the different methods.,5.2. Evaluation using an Artificial Data Set,[0],[0]
"We recognize that SVB simply generates a running average of the data, as it is not able to adapt to the concept drift.",5.2. Evaluation using an Artificial Data Set,[0],[0]
"The results from PVB depend heavily on the learning rate ν, where the higher learning rate, which results in the more aggressive forgetting, works better in this example.",5.2. Evaluation using an Artificial Data Set,[0],[0]
"Recall, though, that ν needs to be hand-tuned to achieve an optimal performance.",5.2. Evaluation using an Artificial Data Set,[0],[0]
"As expected, the choice of M does not have an impact, because the present model has no local hidden variables (cf. Section 3).",5.2. Evaluation using an Artificial Data Set,[0],[0]
"SVB-PP produces results almost identical to PVB when ρ matches the learning rate of PVB (i.e., ρ = 1 − ν).",5.2. Evaluation using an Artificial Data Set,[0],[0]
"Finally, SVB-HPP provides the best results, almost mirroring the true model.
",5.2. Evaluation using an Artificial Data Set,[0],[0]
"Equivalent Sample Size (ESS): Figure 4 (left) gives the evolution of the equivalent sample size, ESSt, for the different methods 3.",5.2. Evaluation using an Artificial Data Set,[0],[0]
The ESS of PVB is always given by the constant M .,5.2. Evaluation using an Artificial Data Set,[0],[0]
"For SVB, the ESS monotonically increases as more data is seen, while SVB-PP exhibits convergence to the limiting value computed in Equation (8).",5.2. Evaluation using an Artificial Data Set,[0],[0]
A different behaviour is observed for SVB-HPP:,5.2. Evaluation using an Artificial Data Set,[0],[0]
"It is automatically ad-
3For this model, ESS is simply computed by summing up the components of the λt defining the Beta posterior.
justed.",5.2. Evaluation using an Artificial Data Set,[0],[0]
Notice that the values for this model is to be read off the alternative y-axis.,5.2. Evaluation using an Artificial Data Set,[0],[0]
"We can detect the the concept drift, by identifying where the ESS rapidly declines.
",5.2. Evaluation using an Artificial Data Set,[0],[0]
Evolution of Expected Forgetting factor: In Figure 4 (right) the series denoted “E[ρ]−100” shows the evolution of Eq[ρt] for the artificial data set.,5.2. Evaluation using an Artificial Data Set,[0],[0]
Notice how the model clearly identifies abrupt concept drift at time steps t = 30 and t = 60.,5.2. Evaluation using an Artificial Data Set,[0],[0]
The series denoted “E[ρ],5.2. Evaluation using an Artificial Data Set,[0],[0]
− 1000” illustrates the evolution of the parameter when we increase the batch size to 1000 samples.,5.2. Evaluation using an Artificial Data Set,[0],[0]
We recognize a more confident assessment about the absence of concept drift as more data is made available.,5.2. Evaluation using an Artificial Data Set,[0],[0]
"For this evaluation we consider three real data sets from different domains:
Electricity Market (Harries, 1999):",5.3.1. DATA AND MODELS,[0],[0]
The data set describes the electricity market of two Australian states.,5.3.1. DATA AND MODELS,[0],[0]
"It contains 45312 instances of 6 attributes, including a class label comparing the change of the electricity price related to a moving average of the last 24 hours.",5.3.1. DATA AND MODELS,[0],[0]
"Each instance in the data set represents 30 minutes of trading; during our analysis we created batches such that xt contains all information associated with month t.
The data is analyzed using a Bayesian linear regression model.",5.3.1. DATA AND MODELS,[0],[0]
The binary class label is assumed to follow a Gaussian distribution in order to fit within the conjugate model class.,5.3.1. DATA AND MODELS,[0],[0]
"Similarly, the marginal densities of the predictive attributes are also assumed to be Gaussian.",5.3.1. DATA AND MODELS,[0],[0]
"The regression coefficients are given Gaussian prior distributions, and the variance is given a Gamma prior.",5.3.1. DATA AND MODELS,[0],[0]
"Note that the overall distribution does not fall inside the conditional conjugate exponential family (Hoffman et al., 2013), hence PVB cannot be applied here, because lower-bound’s gradient cannot be computed in closed-form.
",5.3.1. DATA AND MODELS,[0],[0]
"GPS (Zheng et al., 2008; 2009; 2010):",5.3.1. DATA AND MODELS,[0],[0]
"This data set contains 17 621 GPS trajectories (time-stamped x and y coordinates), totalling more than 4.5 million observations.",5.3.1. DATA AND MODELS,[0],[0]
To reduce the data-size we kept only one out of every ten measurements.,5.3.1. DATA AND MODELS,[0],[0]
"We grouped the data so that xt contains all data collected during hour t of the day, giving a total of 24 batches of this stream.
",5.3.1. DATA AND MODELS,[0],[0]
"Here we employ a model with one independent Gaussian mixture model per day of the week, each mixture with 5 components.",5.3.1. DATA AND MODELS,[0],[0]
"This enables us to track changes in the users’ profiles across hours of the day, and also to monitor how the changes are affected by the day of the week.
",5.3.1. DATA AND MODELS,[0],[0]
"Finance (reference withheld): The data contains monthly aggregated information about the financial profile of
around 50 000 customers over 62 (non-consecutive) months.",5.3.1. DATA AND MODELS,[0],[0]
"Three attributes were extracted per customer, in addition to a class-label telling whether or not the customer will default within the next 24 months.
",5.3.1. DATA AND MODELS,[0],[0]
"We fit a naı̈ve Bayes model to this data set, where the distribution at the leaf-nodes is 5-component mixture of Gaussians distribution.",5.3.1. DATA AND MODELS,[0],[0]
"The distribution over the mixture node is shared by all the attributes, but not between the two classes of customers.
",5.3.1. DATA AND MODELS,[0],[0]
"A detailed description of all the models, including their structure and their variational families, is given at the supplementary material.",5.3.1. DATA AND MODELS,[0],[0]
"To evaluate the different methods discussed, we look at the test marginal log-likelihood (TMLL).",5.3.2. EVALUATION AND DISCUSSION,[0],[0]
"Specifically, each data batch is randomly split in a train data set, xt, and a test data set, x̃t, containing two thirds and one third of the data batch, respectively.",5.3.2. EVALUATION AND DISCUSSION,[0],[0]
"Then, TMLLt is computed as TMLLt = 1|x̃t| ∫ p(x̃t, zt|βt)p(βt|xt)dztdβt.",5.3.2. EVALUATION AND DISCUSSION,[0],[0]
Figure 5 (left) shows for each method the difference between its TMLLt and that obtained by SVB (which is considered the baseline method).,5.3.2. EVALUATION AND DISCUSSION,[0],[0]
"To improve readability, we only plot the results of the best performing method inside each group of methods.",5.3.2. EVALUATION AND DISCUSSION,[0],[0]
The right-hand side of Figure 5 shows the development of Eq[ρt] over time for SVB-HPP and SVB-MHPP.,5.3.2. EVALUATION AND DISCUSSION,[0],[0]
"For SVB-HPP we only have one ρt-parameter, and its value is given by the solid line.",5.3.2. EVALUATION AND DISCUSSION,[0],[0]
SVB-MHPP utilizes one ρ(i) for each variational parameter.4,5.3.2. EVALUATION AND DISCUSSION,[0],[0]
"In this case, we plot Eq[ρ(i)t ] at each point in time to indicate the variability between the different estimates throughout the series.",5.3.2. EVALUATION AND DISCUSSION,[0],[0]
"Finally, we compute each method’s aggregated test marginal log-likelihood measure ∑T t=1 TMLLt, and report these values in Table 1.
",5.3.2. EVALUATION AND DISCUSSION,[0],[0]
"For the electricity data set, we can see that the two proposed methods (SVB-HPP and SVB-MHPP) perform best.",5.3.2. EVALUATION AND DISCUSSION,[0],[0]
"All models are comparable during the first nine months, which is a period where our models detect no or very limited con-
4The numbers of variational parameters are 14, 78 and 33 for the Electricity, GPS and Financial model, respectively.
",5.3.2. EVALUATION AND DISCUSSION,[0],[0]
cept drift (cf. top right plot or Figure 5).,5.3.2. EVALUATION AND DISCUSSION,[0],[0]
"However, after this period, both SVB-HPP and SVB-MHPP detects substantial drift, and is able to adapt better than the other methods, which appear unable to adjust to the complex concept drift structure in the latter part of the data.",5.3.2. EVALUATION AND DISCUSSION,[0],[0]
"SVB-HPP and SVB-MHPP continue to behave at a similar level, mainly because when drift happens it typically includes a high proportion of the parameters of the model.
",5.3.2. EVALUATION AND DISCUSSION,[0],[0]
"For the GPS data set, we can observe how the SVB-MHPP is superior to the rest of the methods, particularly towards the end of the series.",5.3.2. EVALUATION AND DISCUSSION,[0],[0]
"When looking at Figure 5 (middle right panel), we can see that a significative proportion of the model parameters are drifting (i.e., Eq[ρ(i)t ]",5.3.2. EVALUATION AND DISCUSSION,[0],[0]
≤ 0.05),5.3.2. EVALUATION AND DISCUSSION,[0],[0]
"at all times, while another proportion of the parameters show a quite stable behavior (ρ-values above 0.9)",5.3.2. EVALUATION AND DISCUSSION,[0],[0]
.,5.3.2. EVALUATION AND DISCUSSION,[0],[0]
"This complex pattern is not captured well by SVB-HPP, which ends up assuming no concept drift after the initial time-step.
",5.3.2. EVALUATION AND DISCUSSION,[0],[0]
The financial data set shows a different behavior.,5.3.2. EVALUATION AND DISCUSSION,[0],[0]
"During the first months, SVB-MHPP slightly outperforms the rest of the approaches, but after month 30, SVB-PP with ρ = 0.9 is superior, with SVB-MHPP second.",5.3.2. EVALUATION AND DISCUSSION,[0],[0]
"Looking at the E[ρ(i)t ]-values of SVB-MHPP, we observe that there is significant concept drift in some of the parameters over the first few months.",5.3.2. EVALUATION AND DISCUSSION,[0],[0]
"However, only a few parameters exhibit noteworthy drift after the first third of the sequence.",5.3.2. EVALUATION AND DISCUSSION,[0],[0]
"Apparently, the simple SVB-PP approach has the upper hand when the drift is constant and fairly limited, at least when the optimal forgetting factor ρ has been identified.
",5.3.2. EVALUATION AND DISCUSSION,[0],[0]
"We conclude this section by highlighting that the performance of SVB-PP and PVB depend heavily on the hyperparameters of the model, cf. Table 1.",5.3.2. EVALUATION AND DISCUSSION,[0],[0]
"As an example, consider SVB-PP for the financial data set.",5.3.2. EVALUATION AND DISCUSSION,[0],[0]
"While it was the best overall with ρ = 0.9, it is inferior to SVB-MHPP if ρ = 0.99.",5.3.2. EVALUATION AND DISCUSSION,[0],[0]
"Similarly, PVB’s performance is sensitive both to ν (see in particular the results for the GPS data) and M (financial data).",5.3.2. EVALUATION AND DISCUSSION,[0],[0]
"These hyper-parameters are hard to fix, as their optimal values depend on data characteristics (see Broderick et al. (2013); McInerney et al. (2015) for similar conclusions).",5.3.2. EVALUATION AND DISCUSSION,[0],[0]
We therefore believe that the fully Bayesian formulation is an important strong point of our approach.,5.3.2. EVALUATION AND DISCUSSION,[0],[0]
"We have introduced a new class of Bayesian models for streaming data, able to capture changes in the underlying generative process.",6. Conclusions and Future Work,[0],[0]
"Unlike existing solutions to this problem, aimed at modeling slowly changing processes, our proposal is able to handle both abrupt and gradual concept drift following a Bayesian approach.",6. Conclusions and Future Work,[0],[0]
The new model accounts for the dynamics of the data stream by assuming that only the global parameters evolve over time.,6. Conclusions and Future Work,[0],[0]
"We intro-
duce the so-called hierarchical power priors, where a prior on the learning rate is given allowing it to adapt to the data stream.",6. Conclusions and Future Work,[0],[0]
"We have addressed the complexity of the underlying inference tasks by developing an approximate variational inference scheme that optimizes a novel lower bound of the likelihood function.
",6. Conclusions and Future Work,[0],[0]
As future work we aim to provide a sound approach to semantically characterize concept drift by inspecting the E[ρ(i)t ] values provided by SVB-MHPP.,6. Conclusions and Future Work,[0],[0]
This work was partly carried out as part of the AMIDST project.,Acknowledgements,[0],[0]
"AMIDST has received funding from the European Union’s Seventh Framework Programme for research, technological development and demonstration under grant agreement no 619209.",Acknowledgements,[0],[0]
"Furthermore, this research has been partly funded by the Spanish Ministry of Economy and Competitiveness, through projects TIN2015-74368JIN, TIN2013-46638-C3-1-P, TIN2016-77902-C3-3-P and by ERDF funds.",Acknowledgements,[0],[0]
Making inferences from data streams is a pervasive problem in many modern data analysis applications.,abstractText,[0],[0]
"But it requires to address the problem of continuous model updating, and adapt to changes or drifts in the underlying data generating distribution.",abstractText,[0],[0]
"In this paper, we approach these problems from a Bayesian perspective covering general conjugate exponential models.",abstractText,[0],[0]
Our proposal makes use of non-conjugate hierarchical priors to explicitly model temporal changes of the model parameters.,abstractText,[0],[0]
We also derive a novel variational inference scheme which overcomes the use of non-conjugate priors while maintaining the computational efficiency of variational methods over conjugate models.,abstractText,[0],[0]
The approach is validated on three real data sets over three latent variable models.,abstractText,[0],[0]
Bayesian Models of Data Streams with Hierarchical Power Priors,title,[0],[0]
"Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2100–2105, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.",text,[0],[0]
NLP researchers and practitioners spend a considerable amount of time comparing machine-learned models of text that differ in relatively uninteresting ways.,1 Introduction,[0],[0]
"For example, in categorizing texts, should the “bag of words” include bigrams, and is tf-idf weighting a good idea?",1 Introduction,[0],[0]
"In learning word embeddings, distributional similarity approaches have been shown to perform competitively with neural network models when the hyperparameters (e.g., context window, subsampling rate, smoothing constant) are carefully tuned (Levy et al., 2015).",1 Introduction,[0],[0]
"These choices matter experimentally, often leading to big differences in performance, with little consistency across tasks and datasets in which combination of choices works best.",1 Introduction,[0],[0]
"Unfortunately, these differences tell us little about language or the problems that machine learners are supposed to solve.
",1 Introduction,[0],[0]
"We propose that these decisions can be automated in a similar way to hyperparameter selection (e.g., choosing the strength of a ridge or lasso regularizer).",1 Introduction,[0],[0]
"Given a particular text dataset and classification task, we show a technique for optimizing over the space of representational choices, along
with other “nuisances” that interact with these decisions, like hyperparameter selection.",1 Introduction,[0],[0]
"For example, using higher-order n-grams means more features and a need for stronger regularization and more training iterations.",1 Introduction,[0],[0]
"Generally, these decisions about instance representation are made by humans, heuristically; our work seeks to automate them, not unlike Daelemans et al. (2003), who proposed to use genetic algorithms to optimize representational choices.
",1 Introduction,[0],[0]
"Our technique instantiates sequential modelbased optimization (SMBO; Hutter et al., 2011).",1 Introduction,[0],[0]
"SMBO and other Bayesian optimization approaches have been shown to work well for hyperparameter tuning (Bergstra et al., 2011; Hoffman et al., 2011; Snoek et al., 2012).",1 Introduction,[0],[0]
"Though popular in computer vision (Bergstra et al., 2013), these techniques have received little attention in NLP.
",1 Introduction,[0],[0]
We apply it to logistic regression on a range of topic and sentiment classification tasks.,1 Introduction,[0],[0]
"Consistently, our method finds representational choices that perform better than linear baselines previously reported in the literature, and that, in some cases, are competitive with more sophisticated non-linear models trained using neural networks.",1 Introduction,[0],[0]
"Let the training data consist of a collection of pairs dtrain = 〈〈d.i1, d.o1〉, . . .",2 Problem Formulation and Notation,[0],[0]
", 〈d.in, d.on〉〉, where each input d.i ∈ I is a text document and each output",2 Problem Formulation and Notation,[0],[0]
d.o ∈,2 Problem Formulation and Notation,[0],[0]
"O, the output space.",2 Problem Formulation and Notation,[0],[0]
"The overall training goal is to maximize a performance function f (e.g., classification accuracy, log-likelihood, F1 score, etc.) of a machine-learned model, on a held-out dataset, ddev ∈ (I× O)n′ .
",2 Problem Formulation and Notation,[0],[0]
"Classification proceeds in three steps: first, x : I → RN maps each input to a vector representation.",2 Problem Formulation and Notation,[0],[0]
"Second, a predictive model (typically, its parameters) is learned from the inputs (now transformed into vectors) and outputs:",2 Problem Formulation and Notation,[0],[0]
L : (RN × O)n,2 Problem Formulation and Notation,[0],[0]
→ (RN → O).,2 Problem Formulation and Notation,[0],[0]
"Finally, the resulting classifier c :",2 Problem Formulation and Notation,[0],[0]
I → O is fixed as L(dtrain) ◦,2 Problem Formulation and Notation,[0],[0]
"x (i.e., the composition of the representation function with
2100
the learned mapping).",2 Problem Formulation and Notation,[0],[0]
Here we consider linear classifiers of the form c(d.i) = arg maxo∈O,2 Problem Formulation and Notation,[0],[0]
"w>o x(d.i), where the parameters wo ∈ RN , for each output o, are learned using logistic regression on the training data.",2 Problem Formulation and Notation,[0],[0]
We let w denote the concatenation of all wo.,2 Problem Formulation and Notation,[0],[0]
Hence the parameters can be understood as a function of the training data and the representation function x.,2 Problem Formulation and Notation,[0],[0]
"The performance function f , in turn, is a function of the held-out data ddev and x—also w and dtrain , through x.",2 Problem Formulation and Notation,[0],[0]
"For simplicity, we will write “f(x)” when the rest are clear from context.
",2 Problem Formulation and Notation,[0],[0]
"Typically, x is fixed by the model designer, perhaps after some experimentation, and learning focuses on selecting the parameters w. For logistic regression and many other linear models, this training step reduces to convex optimization in N |O| dimensions—a solvable problem that is costly for large datasets and/or large output spaces.",2 Problem Formulation and Notation,[0],[0]
"In seeking to maximize f with respect to x, we do not wish to carry out training any more times than necessary.
",2 Problem Formulation and Notation,[0],[0]
Choosing x can be understood as a problem of selecting hyperparameter values.,2 Problem Formulation and Notation,[0],[0]
"We therefore turn to Bayesian optimization, a family of techniques that can be used to select hyperparameter values intelligently when solving for parameters (w) is costly.",2 Problem Formulation and Notation,[0],[0]
"Our approach is based on sequential model-based optimization (SMBO; Hutter et al., 2011).",3 Bayesian Optimization,[0],[0]
It iteratively chooses representation functions x.,3 Bayesian Optimization,[0],[0]
"On each round, it makes this choice through a probabilistic model of f , then evaluates f—we call this a “trial.”",3 Bayesian Optimization,[0],[0]
"As in any iterative search algorithm, the goal is to balance exploration of options for x with exploitation of previously-explored options, so that a good choice is found in a small number of trials.
",3 Bayesian Optimization,[0],[0]
"More concretely, in the tth trial, xt is selected using an acquisition function A and a “surrogate” probabilistic model pt.",3 Bayesian Optimization,[0],[0]
"Second, f is evaluated given xt—an expensive operation which involves training to learn parameters w and assessing performance on the held-out data.",3 Bayesian Optimization,[0],[0]
"Third, the surrogate model is updated.",3 Bayesian Optimization,[0],[0]
"See Algorithm 1; details on A and pt follow.
",3 Bayesian Optimization,[0],[0]
Acquisition Function.,3 Bayesian Optimization,[0],[0]
"A good acquisition function returns high values for x when either the value f(x) is predicted to be high, or the uncertainty about f(x)’s value is high; balancing between these is the classic tradeoff between exploitation
Algorithm 1",3 Bayesian Optimization,[0],[0]
"SMBO algorithm Input: number of trials T , target function f p1 = initial surrogate model Initialize y∗
for t = 1 to T do xt ← arg maxx A(x; pt, y∗) yt",3 Bayesian Optimization,[0],[0]
← evaluate f(xt),3 Bayesian Optimization,[0],[0]
"Update y∗
Estimate pt given x1:t and y1:",3 Bayesian Optimization,[0],[0]
"t end for
and exploration.",3 Bayesian Optimization,[0],[0]
"We use a criterion called Expected Improvement (EI; Jones, 2001),1 which is the expectation (under the current surrogate model pt) that f(x) = y will exceed f(x∗) = y∗:
A(x; pt, y∗) = ∫ ∞ −∞ max(y",3 Bayesian Optimization,[0],[0]
"− y∗, 0)pt(y",3 Bayesian Optimization,[0],[0]
"| x)dy
where x∗ is chosen depending on the surrogate model, discussed below.",3 Bayesian Optimization,[0],[0]
"(For now, think of it as a strongly-performing “benchmark” discovered in earlier iterations.)",3 Bayesian Optimization,[0],[0]
"Other options for the acquisition function include maximum probability of improvement (Jones, 2001), minimum conditional entropy (Villemonteix et al., 2009), Gaussian process upper confidence bound (Srinivas et al., 2010), or a combination of them (Hoffman et al., 2011).
",3 Bayesian Optimization,[0],[0]
Surrogate Model.,3 Bayesian Optimization,[0],[0]
"As a surrogate model, we use a tree-structured Parzen estimator (TPE; Bergstra et al., 2011).2",3 Bayesian Optimization,[0],[0]
This is a nonparametric approach to density estimation.,3 Bayesian Optimization,[0],[0]
"We seek to estimate pt(y | x) where y = f(x), the performance function that is expensive to compute exactly.",3 Bayesian Optimization,[0],[0]
"The TPE approach
seeks pt(y | x) ∝",3 Bayesian Optimization,[0],[0]
"pt(y) · { p<t (x), if y<y ∗
p≥t (x), if y≥y∗ , where
p<t and p ≥ t are densities estimated using observations from previous trials that are less than and greater than y∗, respectively.",3 Bayesian Optimization,[0],[0]
"In TPE, y∗ is defined as some quantile of the observed y from previous trials; we use 15-quantiles.
",3 Bayesian Optimization,[0],[0]
"As shown by Bergstra et al. (2011), the Expected Improvement in TPE can be written as:
1EI is the most widely used acquisition function that has been shown to work well on a range of tasks.
",3 Bayesian Optimization,[0],[0]
"2Another common approach to the surrogate is the Gaussian process (Rasmussen and Williams, 2006; Hoffman et al., 2011; Snoek et al., 2012).",3 Bayesian Optimization,[0],[0]
"Like Bergstra et al. (2011), our preliminary experiments found the TPE to perform favorably.",3 Bayesian Optimization,[0],[0]
"Further TPE’s tree-structured configuration space is advantageous, because it allows nested definitions of hyperparameters, which we exploit in our experiments (e.g., only allows bigrams to be chosen if unigrams are also chosen).
",3 Bayesian Optimization,[0],[0]
"A(x; pt, y∗) ∝",3 Bayesian Optimization,[0],[0]
"( γ + p < t (x)
p≥t (x) (1− γ)
)−1 , where
γ = pt(y < y∗), fixed at 0.15 by definition of y∗ (above).",3 Bayesian Optimization,[0],[0]
"Here, we prefer x with high probability under p≥t (x) and low probability under p < t (x).",3 Bayesian Optimization,[0],[0]
"To maximize this quantity, we draw many candidates according to p≥t (x) and evaluate them according to p<t (x)/p ≥ t (x).",3 Bayesian Optimization,[0],[0]
Note that p(y) does not need to be given an explicit form.,3 Bayesian Optimization,[0],[0]
"To compute p<t (x) and p≥t (x), we associate each hyperparameter with a node in the graphical model and multiply individual probabilities at every node—see Bergstra et al. (2011) for details.",3 Bayesian Optimization,[0],[0]
We fix L to logistic regression.,4 Experiments,[0],[0]
"We optimize text representation based on the types of n-grams used, the type of weighting scheme, and the removal of stopwords; we also optimize the regularizer and training convergence criterion, which interact with the representation.",4 Experiments,[0],[0]
"See Table 1 for a complete list.
",4 Experiments,[0],[0]
"Note that even with this limited number of options, the number of possible combinations is huge,3 so exhaustive search is computationally expensive.",4 Experiments,[0],[0]
"In all our experiments for all datasets, we limit ourselves to 30 trials per dataset.",4 Experiments,[0],[0]
"The only preprocessing we applied was downcasing.
",4 Experiments,[0],[0]
We always use a development set to evaluate f(x) during learning and report the final result on an unseen test set.,4 Experiments,[0],[0]
"We summarize the hyperparameters selected by our method, and the accuracies achieved (on test data) in Table 5.",4 Experiments,[0],[0]
We discuss comparisons to baselines for each dataset in turn.,4 Experiments,[0],[0]
"For each of our datasets, we select supervised, nonensemble classification methods from previous literature as baselines.",4 Experiments,[0],[0]
"In each case, we emphasize comparisons with the best-published linear method
3It is actually infinite since the reg. strength and conv.",4 Experiments,[0],[0]
"tolerance are continuous values, but we could discretize them.
",4 Experiments,[0],[0]
(often an SVM with a linear kernel with representation selected by experts) and the best-published method overall.,4 Experiments,[0],[0]
"In the following, “SVM” always means “linear SVM.”",4 Experiments,[0],[0]
"All methods were trained and evaluated on the same training/testing splits as baselines; in cases where standard development sets were not available, we used a random 20% of the training data as a development set.
",4 Experiments,[0],[0]
"Stanford sentiment treebank (Socher et al., 2013)—Table 2.",4 Experiments,[0],[0]
A sentence-level sentiment analysis dataset of rottentomatoes.com movie reviews: http://nlp.stanford.edu/sentiment.,4 Experiments,[0],[0]
We use the binary classification task where the goal is to predict whether a review is positive or negative (no neutral).,4 Experiments,[0],[0]
"Our logistic regression model outperforms the baseline SVM reported by Socher et al. (2013), who used only unigrams but did not specify the weighting scheme for their SVM baseline.",4 Experiments,[0],[0]
"While our result is still below the state-of-the-art based on the the recursive neural tensor networks (Socher et al., 2013) and the paragraph vector (Le and Mikolov, 2014), we show that logistic regression is comparable with recursive and matrix-vector neural networks (Socher et al., 2011; Socher et al., 2012).
",4 Experiments,[0],[0]
"Amazon electronics (McAuley and Leskovec, 2013)—Table 3.",4 Experiments,[0],[0]
A binary sentiment analysis dataset of Amazon electronics product reviews: http://riejohnson.com/cnn data.html.,4 Experiments,[0],[0]
"The bestperforming methods on this dataset are based on convolutional neural networks (Johnson and Zhang, 2015).4 Our method is on par with the secondbest of these, outperforming all of the reported feed-forward neural networks and SVM variants Johnson and Zhang used as baselines.",4 Experiments,[0],[0]
"They varied
4These are convolutional neural networks with a rectifier activation function, trained under `2 regularization with stochastic gradient descent.",4 Experiments,[0],[0]
"The authors also consider an extension based on parallel CNN that we do not include here.
",4 Experiments,[0],[0]
"the representations, and used log term frequency and normalization to unit vectors as the weighting scheme, after finding that this outperformed term frequency.",4 Experiments,[0],[0]
"Our method achieved the best performance with binary weighting, which they did not consider.
",4 Experiments,[0],[0]
"IMDB movie reviews (Maas et al., 2011)— Table 3.",4 Experiments,[0],[0]
A binary sentiment analysis dataset of highly polar IMDB movie reviews: http://ai.stanford.edu/~amaas/data/sentiment.,4 Experiments,[0],[0]
"The results parallel those for Amazon electronics; our method comes close to convolutional neural networks (Johnson and Zhang, 2015), which are state-of-the-art.5 It outperforms SVMs and feed-forward neural networks, the restricted Boltzmann machine approach presented by Dahl et al. (2012), and compressive feature learning (Paskov et al., 2013).6
Congressional vote (Thomas et al., 2006)—Table 4.",4 Experiments,[0],[0]
A dataset of transcripts from the U.S. Congressional debates: http://www.cs.cornell.edu/~ainur/sle-data.html.,4 Experiments,[0],[0]
"Similar to previous work (Thomas et al., 2006; Bansal et al., 2008; Yessenalina et al., 2010), we consider the task to predict the vote (“yea” or “nay”) for the speaker of each speech segment (speaker-based speech-segment classification).",4 Experiments,[0],[0]
"Our method outperforms the best results of Yessenalina et al. (2010), which use a multi-level structured
5As noted, semi-supervised and ensemble methods are excluded for a fair comparison.
",4 Experiments,[0],[0]
"6This approach is based on minimum description length, using unlabeled data to select a set of higher-order n-grams to use as features.
model based on a latent-variable SVM.",4 Experiments,[0],[0]
We show comparisons to two weaker baselines as well.,4 Experiments,[0],[0]
20 Newsgroups is a benchmark topic classification dataset: http://qwone.com/~jason/20Newsgroups.,"20 Newsgroups (Lang, 1995) all topics—Table 6.",[0],[0]
There are 20 topics in this dataset.,"20 Newsgroups (Lang, 1995) all topics—Table 6.",[0],[0]
"Our method outperforms state-of-the-art methods including the distributed structured output model (Srikumar and Manning, 2014).7 The strong logistic regression baseline from Paskov et al. (2013) uses all 5-grams, heuristic normalization, and elastic net regularization; our method found that unigrams and bigrams, with binary weighting and `2 penalty, achieved far better results.
20 Newsgroups: talk.religion.misc vs. alt.atheism and comp.graphics vs. comp.windows.x.","20 Newsgroups (Lang, 1995) all topics—Table 6.",[0],[0]
We derived three additional topic classification tasks from the 20N dataset.,"20 Newsgroups (Lang, 1995) all topics—Table 6.",[0],[0]
The first and second tasks are talk.religion.misc vs. alt.atheism (test size = 686) and comp.graphics vs. comp.windows.x (test size = 942).,"20 Newsgroups (Lang, 1995) all topics—Table 6.",[0],[0]
"Wang and Manning (2012) report a bigram naı̈ve Bayes model achieving 85.1% and 91.2% on these tasks, respectively (best single model results).8 Our
7This method was designed for structured prediction, but Srikumar and Manning (2014) also applied it to classification.","20 Newsgroups (Lang, 1995) all topics—Table 6.",[0],[0]
It attempts to learn a distributed representation for features and for labels.,"20 Newsgroups (Lang, 1995) all topics—Table 6.",[0],[0]
"The authors used unigrams and did not discuss the weighting scheme.
","20 Newsgroups (Lang, 1995) all topics—Table 6.",[0],[0]
"8They also report a naı̈ve Bayes/SVM ensemble achieving 87.9% and 91.2%.
method achieves 86.3% and 92.1% using slightly different representations (see Table 5).","20 Newsgroups (Lang, 1995) all topics—Table 6.",[0],[0]
"The last task is to classify related science documents into four science topics (sci.crypt, sci.electronics, sci.space, sci.med; test size = 1, 899).","20 Newsgroups (Lang, 1995) all topics—Table 6.",[0],[0]
We were not able to find previous results that are comparable to ours on this task; we include our result (95.82%) to enable further comparisons in the future.,"20 Newsgroups (Lang, 1995) all topics—Table 6.",[0],[0]
Optimized representations.,5 Discussion,[0],[0]
"For each task, the chosen representation is different.",5 Discussion,[0],[0]
"Out of all possible choices in our experiments (Table 1), each of them is used by at least one of the datsets (Table 5).",5 Discussion,[0],[0]
"For example, on the Congress vote dataset, we only need to use bigrams, whereas on the Amazon electronics dataset we need to use {1, 2, 3}-grams.",5 Discussion,[0],[0]
"The binary weighting scheme works well for most of the datasets, except the sentence-level sentiment analysis task, where the tf-idf weighting scheme was selected.",5 Discussion,[0],[0]
`2 regularization was best in all cases but one.,5 Discussion,[0],[0]
"We do not believe that an NLP expert would be likely to make these particular choices, except through the same kind of trial-and-error process our method automates efficiently.
",5 Discussion,[0],[0]
Number of trials.,5 Discussion,[0],[0]
We ran 30 trials for each dataset in our experiments.,5 Discussion,[0],[0]
Figure 1 shows each trial accuracy and the best accuracy on development data as we increase the number of trials for two datasets.,5 Discussion,[0],[0]
"We can see that 30 trials are generally enough for the model to obtain good results, although the search space is large.
",5 Discussion,[0],[0]
Transfer learning and multitask setting.,5 Discussion,[0],[0]
We treat each dataset independently and create a separate model for each of them.,5 Discussion,[0],[0]
"It is also possible to learn from previous datasets (i.e., transfer learning) or to learn from all datasets simultaneously (i.e., multitask learning) to improve performance.",5 Discussion,[0],[0]
"This has the potential to reduce the number of trials
required even further.",5 Discussion,[0],[0]
"See Bardenet et al. (2013), Swersky et al. (2013), and Yogatama and Mann (2014) for more about how to perform Bayesian optimization in these settings.
",5 Discussion,[0],[0]
Beyond supervised learning.,5 Discussion,[0],[0]
Our framework could also be extended to unsupervised and semisupervised models.,5 Discussion,[0],[0]
"For example, in document clustering (e.g., k-means), we also need to construct representations for documents.",5 Discussion,[0],[0]
Log-likelihood might serve as a performance function.,5 Discussion,[0],[0]
A range of random initializations might be considered.,5 Discussion,[0],[0]
Investigation of this approach for nonconvex problems is an exciting area for future work.,5 Discussion,[0],[0]
We used Bayesian optimization to optimize choices about text representations for various categorization problems.,6 Conclusion,[0],[0]
Our technique identifies settings for a standard linear model (logistic regression) that are competitive with far more sophisticated methods on topic classification and sentiment analysis.,6 Conclusion,[0],[0]
We thank several reviewers for their helpful feedback.,Acknowledgments,[0],[0]
This work was supported by the Defense Advanced Research Projects Agency through grant FA87501420244 and computing resources provided by Amazon.,Acknowledgments,[0],[0]
This research was completed while NAS was at CMU.,Acknowledgments,[0],[0]
"When applying machine learning to problems in NLP, there are many choices to make about how to represent input texts.",abstractText,[0],[0]
"They can have a big effect on performance, but they are often uninteresting to researchers or practitioners who simply need a module that performs well.",abstractText,[0],[0]
"We apply sequential model-based optimization over this space of choices and show that it makes standard linear models competitive with more sophisticated, expensive state-ofthe-art methods based on latent variables or neural networks on various topic classification and sentiment analysis problems.",abstractText,[0],[0]
Our approach is a first step towards black-box NLP systems that work with raw text and do not require manual tuning.,abstractText,[0],[0]
Bayesian Optimization of Text Representations,title,[0],[0]
"In recent years, Bayesian optimization has gained a growing attention from machine learning experts in, both, academia and industry (Shahriari et al., 2016).",1. Introduction,[0],[0]
"It takes the widespread application of machine learning to the next level of sophistication as it enables to automatically fine-tune hyperparameters (Snoek et al., 2012), whether they are parametrizing data pre-processors, models or the learning algorithms.",1. Introduction,[0],[0]
"Finetuning is essential to obtain state-of-the-art performance
1Amazon, Berlin, Germany.",1. Introduction,[0],[0]
"2Amazon, Cambridge, United Kingdom.",1. Introduction,[0],[0]
"Correspondence to: Rodolphe Jenatton <jenatton@amazon.de>, Cedric Archambeau <cedrica@amazon.de>, Javier Gonzalez <gojav@amazon.co.uk>, Matthias Seeger <matthias@amazon.de>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
with complex machine learning models, such as deep neural networks.",1. Introduction,[0],[0]
"Historically, this vital step has been done, either manually, or via regular or random grid search, which can consume vast amounts of human expert time and are wasteful of computing resources.",1. Introduction,[0],[0]
"Hence, one of the main benefits of Bayesian optimization is that it removes this burden from the shoulders of the practitioners, who can then focus their attention on more rewarding value-adding tasks.
",1. Introduction,[0],[0]
"To set the stage, our goal is to solve a global optimization problem:
min x∈X f(x),
where X is the optimization domain and f is a black-box function, typically continuous and multimodal.",1. Introduction,[0],[0]
We further assume that querying f is costly.,1. Introduction,[0],[0]
"For example, f may be the outcome of a physical experiment or require a large amount of computation.",1. Introduction,[0],[0]
"The latter arises when f corresponds to a model selection score for a machine learning model trained on a possibly large dataset.
",1. Introduction,[0],[0]
"The protocol for sequential Bayesian optimization proceeds as follows (Mockus et al., 1978; Shahriari et al., 2016).",1. Introduction,[0],[0]
"Given n noisy evaluations yi ≈ f(xi), i ∈ {1, . . .",1. Introduction,[0],[0]
",",1. Introduction,[0],[0]
"n}, a surrogate probabilistic model of f is maintained.",1. Introduction,[0],[0]
Our goal is to find a global optimum of f by querying it as few times as possible.,1. Introduction,[0],[0]
The location xn+1 is chosen by maximizing an acquisition function which performs an explorationexploitation trade-off.,1. Introduction,[0],[0]
"A common choice for the surrogate model is a Gaussian process (GP) (Rasmussen & Williams, 2006).",1. Introduction,[0],[0]
"For a GP surrogate model, common acquisition functions can be tractably computed and optimized via gradientbased optimization algorithms.",1. Introduction,[0],[0]
"While existing Bayesian optimization approaches mitigate the high evaluation cost of f , they suffer from the curse of dimensionality when facing a high-dimensional space X .
",1. Introduction,[0],[0]
"In this paper, we introduce a novel methodology able to exploit a given tree-shaped dependency structure on X by transferring information between overlapping paths.",1. Introduction,[0],[0]
"By constructing a surrogate model tailored to the structure, we can reduce the number of evaluations of commonly used acquisition functions.",1. Introduction,[0],[0]
"The same structure also allows us to take acquisition decisions more efficiently, thus speeding up the search of candidates.
",1. Introduction,[0],[0]
Tree-based dependencies occur often in practice.,1. Introduction,[0],[0]
"For exam-
ple, faced with a classification problem, we may want to simultaneously search over many different machine learning models, each coming with their own hyperparameters.",1. Introduction,[0],[0]
"Some configurations may also share parameters (e.g., logistic regression with `2 and `1 penalty may share the learning rate).",1. Introduction,[0],[0]
"These choices could be encoded in a decision tree, where inner nodes select between different models and hyperparameters populate leaf nodes.",1. Introduction,[0],[0]
"Another example arises when having to decide on a deep neural network architecture: the size of a layer, choice of activation function, or dropout fraction may depend on the number of layers (Bengio, 2009).",1. Introduction,[0],[0]
"A baseline approach to Bayesian optimization in this setting is to ignore the structure of X and, as a result, choose a GP with covariance kernel K(x,x′) defined over the joint input space.",1.1. Baselines and Related Work,[0],[0]
"When comparing a pair of points, all coordinates are taken into account.",1.1. Baselines and Related Work,[0],[0]
"While easy to run in existing Bayesian optimization toolboxes, this approach can be highly inefficient.",1.1. Baselines and Related Work,[0],[0]
"Not only do we encounter a cost of O(n3) after n acquisitions due to the global nature of the GP, but we also suffer from the curse of dimensionality when searching over X .",1.1. Baselines and Related Work,[0],[0]
"Several authors attempted to design covariance functions that are aware of the structure: Duvenaud et al. (2011) consider kernels with an additive structure, while Swersky et al. (2014a); Hutter & Osborne (2013) introduce the Arc-kernel.",1.1. Baselines and Related Work,[0],[0]
"However, the cost remains O(n3).
",1.1. Baselines and Related Work,[0],[0]
"Another idea is to consider an independent GP for every valid subset of hyperparameters, as proposed by Bergstra et al. (2011).",1.1. Baselines and Related Work,[0],[0]
This approach corresponds to having an independent GP per leaf in the dependency tree.,1.1. Baselines and Related Work,[0],[0]
"It scales as O( ∑ p n 3 p), where np is the number of evaluations at leaf
node p and ∑ p np = n.",1.1. Baselines and Related Work,[0],[0]
"However, it lacks a mechanism for information sharing across the leaves.",1.1. Baselines and Related Work,[0],[0]
"As we will show, information sharing can be beneficial in order to cut down on the number of evaluations.",1.1. Baselines and Related Work,[0],[0]
"Moreover, the independent approach requires a sizable number of evaluations at each leaf, which can be problematic when there are many leafs.
",1.1. Baselines and Related Work,[0],[0]
"Tree-structured dependencies can also be dealt with by assigning default values to coordinates of x which do not fall into the leaf node under consideration, using a Random Forest model to make this choice (Hutter et al., 2011).",1.1. Baselines and Related Work,[0],[0]
"This strategy is implemented in the SMAC library.
",1.1. Baselines and Related Work,[0],[0]
"Finally, Zhang et al. (2016) proposed a dedicated approach to tune data analytic pipelines, via a two-layer Bayesian optimization framework.",1.1. Baselines and Related Work,[0],[0]
"Their method first uses a parametric model to select some promising algorithms, whose hyperparameters are then refined by a nonparametric model.",1.1. Baselines and Related Work,[0],[0]
"First, we introduce a novel Bayesian optimization methodology able to leverage conditional dependencies between hyperparameters.",1.2. Contributions,[0],[0]
"To this end, we build a tree-structured surrogate model, with separate GPs at the leaf nodes, and random linear (or constant) functions at the inner nodes.",1.2. Contributions,[0],[0]
"This allows us to transfer information between leafs that share nodes on their respective paths, which enables us in turn to efficiently search the space X .",1.2. Contributions,[0],[0]
"Yet, we also retain the beneficial scaling of the independent approach (Bergstra et al., 2011).",1.2. Contributions,[0],[0]
"To our knowledge, no prior published work satisfied these two aspects.",1.2. Contributions,[0],[0]
"The Arc-kernel allows for information sharing, but comes with O(n3) computations.",1.2. Contributions,[0],[0]
"Hutter et al. (2011) rely on Random Forests to represent correlations, but no particular sharing mechanism exists.
",1.2. Contributions,[0],[0]
"Second, we introduce a novel acquisition function which is also able to exploit the tree structure and relies on the expected improvement (Mockus et al., 1978).",1.2. Contributions,[0],[0]
The acquisition operates in two steps.,1.2. Contributions,[0],[0]
"We first select the most promising leaf node to score, effectively restricting our attention to a portion of X .",1.2. Contributions,[0],[0]
We then optimize over all possible anchor points in this portion of space.,1.2. Contributions,[0],[0]
This can result in a drastic reduction in the number of surrogate functions to optimize over.,1.2. Contributions,[0],[0]
"In comparison, the independent baseline requires to score every anchor point of every leaf in the tree at each iteration.
",1.2. Contributions,[0],[0]
The paper is organized as follows.,1.2. Contributions,[0],[0]
"In Section 2, we detail our surrogate GP model and inference computations.",1.2. Contributions,[0],[0]
"In Section 3, we show how the model structure gives rise to efficient acquisition optimization.",1.2. Contributions,[0],[0]
"For a range of experiments on simulated and real data, we report in Section 4 favorable comparisons with existing alternatives.",1.2. Contributions,[0],[0]
We conclude with possible extensions in Section 5.,1.2. Contributions,[0],[0]
"We assume that the hyperparameters exhibit conditional dependencies, which can be modeled with decision tree T .",2. Tree-structured semi-parametric Gaussian process regression model,[0],[0]
"The set of inner nodes V is indexed by v ∈ {1, . . .",2. Tree-structured semi-parametric Gaussian process regression model,[0],[0]
", V }; each v has a decision variable and a weight variable cv.",2. Tree-structured semi-parametric Gaussian process regression model,[0],[0]
"The set of leaf nodes P is indexed by p ∈ {1, . . .",2. Tree-structured semi-parametric Gaussian process regression model,[0],[0]
", P}.",2. Tree-structured semi-parametric Gaussian process regression model,[0],[0]
"Equivalently, p indexes (unique) paths from the root to a leaf.
",2. Tree-structured semi-parametric Gaussian process regression model,[0],[0]
"Further, let Dn = {(xi, yi)}ni=1 be the set of observations.",2. Tree-structured semi-parametric Gaussian process regression model,[0],[0]
We introduce a set of auxiliary variables {pi | pi ∈ P}ni=1 that indicate the leaf to which observation i is associated and let np= |{i | pi=p}|.,2. Tree-structured semi-parametric Gaussian process regression model,[0],[0]
Note that xi∈Xpi since the input domain may vary from one leaf to another.,2. Tree-structured semi-parametric Gaussian process regression model,[0],[0]
"We consider a surrogate model that associates with leaf p a latent function gp with GP prior, whose mean function and covariance kernel are bp and Kp(x,x′).",2.1. Model with Random Inner Node Parameters,[0],[0]
We impose a zero-mean Gaussian prior over the weight vector c =,2.1. Model with Random Inner Node Parameters,[0],[0]
"[c1, . .",2.1. Model with Random Inner Node Parameters,[0],[0]
.,2.1. Model with Random Inner Node Parameters,[0],[0]
", cV ] T .
",2.1. Model with Random Inner Node Parameters,[0],[0]
"The resulting generative model is given by
c ∼ N (0,Σc), gp(·) ∼ GP ( bp,Kp ) ,
yi|pi, {gp(xi)}Pp=1, c ∼ N (gpi(xi) + z>pic, σ 2).",2.1. Model with Random Inner Node Parameters,[0],[0]
"(1)
where Σc, {bp}Pp=1 and σ2 are the prior covariance, the scalar offsets and the noise variance.",2.1. Model with Random Inner Node Parameters,[0],[0]
"Vector zp∈ {0, 1}V is a binary mask that activates the weights of the inner node decision variables on the path to leaf node p.",2.1. Model with Random Inner Node Parameters,[0],[0]
"In other words, (zp)v = 1 iff v lies on the path from the root to p.",2.1. Model with Random Inner Node Parameters,[0],[0]
"The prior covariance Σc will be diagonal in our experiments.
",2.1. Model with Random Inner Node Parameters,[0],[0]
"When c=0, model (1) boils down to assuming P independent GPs.",2.1. Model with Random Inner Node Parameters,[0],[0]
"While inference only scales as O( ∑ p n 3 p) in this case, information is not transferred between overlapping paths.",2.1. Model with Random Inner Node Parameters,[0],[0]
"Introducing the weight vector c allows us to couple inference for such paths, while keeping the favorable scaling and better exploring the optimization space (see Section 4).
",2.1. Model with Random Inner Node Parameters,[0],[0]
"Next, we show how to perform efficient inference in this model and give an interpretation of the induced kernel when computing the marginal likelihood.",2.1. Model with Random Inner Node Parameters,[0],[0]
Posterior inference over the surrogate models {gp(·)} and the random weights c is needed to compute the acquisition functions (see Section 3).,2.1. Model with Random Inner Node Parameters,[0],[0]
"Before starting, we need some notation.",2.2. Posterior Inference,[0],[0]
Let y ∈,2.2. Posterior Inference,[0],[0]
Rn be the vector of all observations and g ∈,2.2. Posterior Inference,[0],[0]
Rn the vector of latent function values at {xi}ni=1.,2.2. Posterior Inference,[0],[0]
"Further, let Ip = {i | pi = p}, noting that np = |Ip|.",2.2. Posterior Inference,[0],[0]
"We partition the data accordingly, so that yp =",2.2. Posterior Inference,[0],[0]
"[yi]i∈Ip , and similarly gp = [gp(xi)]i∈Ip .",2.2. Posterior Inference,[0],[0]
"Also, we define the matrix Zp = zp1>np ∈ R
V×np , where 1np =",2.2. Posterior Inference,[0],[0]
"[1] ∈ Rnp , and the vector bp = bp1np ∈ Rnp .
",2.2. Posterior Inference,[0],[0]
"The joint distribution P (y,g, c) of our model is given by P (c) ∏ pN (gp; bp,Kp)N (yp; gp + Z > p c, σ 2Inp), (2)
where Kp = [Kp(xi,xj)]i,j∈Ip are kernel matrices, with the prior P (c) = N (c; 0,Σc).",2.2. Posterior Inference,[0],[0]
"Our goal is to obtain the posterior process P (gp(·)|c,yp) and the posterior distribution P (c|y).
",2.2. Posterior Inference,[0],[0]
"We can directly read off the posterior over the latent functions and parameters after rewriting the joint distribution into the following form (see Section 2 of the Appendix for details):
P (y)P (c|y)",2.2. Posterior Inference,[0],[0]
"∏ pP (gp|c,yp).
",2.2. Posterior Inference,[0],[0]
"First, we obtain the posterior GP over the latent functions:
gp(·)|c,yp ∼ GP ( mp(·), Sp(·, ·) ) ,
where mp(x) =",2.2. Posterior Inference,[0],[0]
kp(x)>M−1p (yp − Z>p c,2.2. Posterior Inference,[0],[0]
"− bp) + bp, Sp(x,x
′)",2.2. Posterior Inference,[0],[0]
"= Kp(x,x′)",2.2. Posterior Inference,[0],[0]
"− kp(x)>M−1p kp(x′) and Mp = Kp + σ 2Inp .
",2.2. Posterior Inference,[0],[0]
"Next, we obtain the posterior for the weights c:
c|y",2.2. Posterior Inference,[0],[0]
"∼ N (Λ−1c fc,Λ −1 c ),
where fc = ∑ p ZpM −1",2.2. Posterior Inference,[0],[0]
p (yp − bp) and Λc = Σ −1,2.2. Posterior Inference,[0],[0]
"c +∑
p ZpM −1",2.2. Posterior Inference,[0],[0]
"p Z > p .
",2.2. Posterior Inference,[0],[0]
"In the sequel, we compute expressions such as M−1p and log |Mp| by using the Cholesky decomposition Mp = LpL > p .",2.2. Posterior Inference,[0],[0]
"Similarly, the expressions depending on Λc are computed using its Cholesky decomposition.",2.2. Posterior Inference,[0],[0]
"As shown in Section 2 of the Appendix, we can derive the expression for the log-marginal likelihood logP (y) in closed form:
logP (y) = ∑ p logN (yp; Z>p c + bp,Mp)
+ logN (c;",2.3. Marginal Likelihood and Its Interpretation,[0],[0]
"0,Σc)− logP (c|y), (3)
",2.3. Marginal Likelihood and Its Interpretation,[0],[0]
"The p-dependent terms require computing the Cholesky decompositions of all Mp ∈ Rnp×np , whereas the final term needs the Cholesky decomposition of Λc ∈ RV×V .",2.3. Marginal Likelihood and Its Interpretation,[0],[0]
"Therefore, logP (y) can be computed in O(V 3 + ∑ p n 3 p).",2.3. Marginal Likelihood and Its Interpretation,[0],[0]
"Note that this computation is required for optimizing the hyperparameters of the GPs.
",2.3. Marginal Likelihood and Its Interpretation,[0],[0]
We can also obtain an interesting interpretation for the induced kernel of the marginal likelihood by computing it in a different way.,2.3. Marginal Likelihood and Its Interpretation,[0],[0]
Let Z =,2.3. Marginal Likelihood and Its Interpretation,[0],[0]
"[Zp] ∈ RV×n, b =",2.3. Marginal Likelihood and Its Interpretation,[0],[0]
[bp] ∈,2.3. Marginal Likelihood and Its Interpretation,[0],[0]
Rn and Kblock ∈ Rn×n the block-diagonal matrix with blocks Kp.,2.3. Marginal Likelihood and Its Interpretation,[0],[0]
"With these notations, it can be shown that P (yp|c) = N (yp|Z>p c + bp,Mp).",2.3. Marginal Likelihood and Its Interpretation,[0],[0]
"Integrating out c leads to
P (y) = N",2.3. Marginal Likelihood and Its Interpretation,[0],[0]
"( b,Z>ΣcZ + K block + σ2I ) .",2.3. Marginal Likelihood and Its Interpretation,[0],[0]
"(4)
If we further assume that Σc = σ2cIV , then
Z>ΣcZ = [ σ2cZ > p Zp′ ]",2.3. Marginal Likelihood and Its Interpretation,[0],[0]
"p,p′ = [ σ2c (z > p zp′)1np1 > np′",2.3. Marginal Likelihood and Its Interpretation,[0],[0]
],2.3. Marginal Likelihood and Its Interpretation,[0],[0]
"p,p′ .
",2.3. Marginal Likelihood and Its Interpretation,[0],[0]
"Hence, the diagonal blocks are proportional to z>p zp, which is the length of path p, and the off-diagonal blocks are proportional to z>p zp′ , which is the path overlap length between p and p′. The resulting kernel is thus the intersection kernel (see Shawe-Taylor & Cristianini (2004), Section 9.5).",2.3. Marginal Likelihood and Its Interpretation,[0],[0]
We have so far associated a random scalar cv with each inner node.,2.4. Model with Random Linear Inner Node Functions,[0],[0]
"More generally, we can use linear functions c>v rv, where cv is a weight vector and rv∈Rdv is a feature vector.",2.4. Model with Random Linear Inner Node Functions,[0],[0]
"The special case above is obtained with dv=1 and rv=[1].
",2.4. Model with Random Linear Inner Node Functions,[0],[0]
We collect the weight vectors in c =,2.4. Model with Random Linear Inner Node Functions,[0],[0]
"[cv] ∈ Rd, where d = ∑ v dv.",2.4. Model with Random Linear Inner Node Functions,[0],[0]
Let Vp ⊆ V be the set of inner nodes on the path from the root to leaf p.,2.4. Model with Random Linear Inner Node Functions,[0],[0]
"Concatenating the rv’s, we define the induced feature vector zp =",2.4. Model with Random Linear Inner Node Functions,[0],[0]
"[rv]v∈Vp such that
c>zp = ∑ v∈Vp c > v rv.
",2.4. Model with Random Linear Inner Node Functions,[0],[0]
"Hence, the dataset we collect during the optimization is now the extended set Dn = {(xi, yi, pi, zpi =[rv,i]v∈Vpi )} n i=1.",2.4. Model with Random Linear Inner Node Functions,[0],[0]
"It is easy to see that all our results above transfer to this more general case, if only we redefine
Zp =",2.4. Model with Random Linear Inner Node Functions,[0],[0]
[zpi ]i∈Ip =,2.4. Model with Random Linear Inner Node Functions,[0],[0]
"[rv,i]i∈Ip,v∈Vpi ∈ R d×np .
",2.4. Model with Random Linear Inner Node Functions,[0],[0]
"Except for an increased dimensionality d > V of the weight vector c, the extension with random linear inner node functions is not more difficult to implement or run.
",2.4. Model with Random Linear Inner Node Functions,[0],[0]
"In Section 4, we will use rv to encode both numerical (i.e., dv = 1) and categorical parameters (via one-hot representations, so that dv equals the number of categories).",2.4. Model with Random Linear Inner Node Functions,[0],[0]
"In our deep learning use case, parameters such as the learning rate, the number of units and the type of activation functions are encoded via the rv’s (see Figure 3, bottom).",2.4. Model with Random Linear Inner Node Functions,[0],[0]
We will refer to the parameter associated with rv as a shared parameter since it is shared across all the leaves whose paths contain v.,2.4. Model with Random Linear Inner Node Functions,[0],[0]
"Bayesian optimization generally proceeds by discretizing the search space X into a set of anchor points, for example by using quasi-random sequences (Sobol, 1967).",3. Acquisition Functions,[0],[0]
"We then maximize an acquisition function starting from the most promising anchor point(s), typically with a numerical solver like L-BFGS (Nocedal & Wright, 2006).",3. Acquisition Functions,[0],[0]
Acquisition functions are defined in terms of expectations over the surrogate model posterior.,3. Acquisition Functions,[0],[0]
"Frequently used choices include Thompson sampling (Thompson, 1933), probability of improvement (PI) (Kushner, 1964), expected improvement (EI) (Mockus et al., 1978), or GP-UCB (Srinivas et al., 2010).",3. Acquisition Functions,[0],[0]
We will focus on EI in the sequel as it has been shown to perform better than PI.,3. Acquisition Functions,[0],[0]
"Our initial experiments also showed that Thompson sampling was not performing well.
",3. Acquisition Functions,[0],[0]
The naive approach of globally optimizing EI over anchor points does not scale well with a high-dimensional X .,3. Acquisition Functions,[0],[0]
"In the previous section, we specified a tree-structured model for the (random) surrogate function, with which the evaluation of an acquisition function at some x ∈ X is sped up.",3. Acquisition Functions,[0],[0]
"In this section, we show how the model structure can also be exploited in order to speed up the optimization itself.",3. Acquisition Functions,[0],[0]
The acquisition function α(x|Dn) plays a critical role in Bayesian Optimization as it selects anchor points by performing an exploration-exploitation trade-off.,3.1. Acquisition Strategies,[0],[0]
The key question that concerns us is whether we can leverage the explicit structure in high-dimensional structured space in order to make the search more efficient.,3.1. Acquisition Strategies,[0],[0]
"The naive approach ignores structure in the search space, using a surrogate model based on a global kernel, like the one proposed by Swersky et al. (2014a).",3.1. Acquisition Strategies,[0],[0]
"While the design of a kernel that incorporate structure is non-trivial, it is not explicitly used to guide the search and the cost of evaluations still scales as O(n3).
",3.1. Acquisition Strategies,[0],[0]
"As noted above, we can speed up evaluations to O( ∑ p n 3 p) by adopting an independent model, which corresponds to our tree model with c = 0, so that the surrogate models {gp(·)}Pp=1 can be learnt and queried independently from each other.",3.1. Acquisition Strategies,[0],[0]
"With this approach, the search decouples across the leaf nodes and can be parallelized accordingly.",3.1. Acquisition Strategies,[0],[0]
"However, if acquisitions are done sequentially, then all leafs have to be searched in order to find the overall best candidate.",3.1. Acquisition Strategies,[0],[0]
"The independent model also fails to represent dependencies between the leaf nodes, so that a larger total number of evaluations may be required to reach a good solution.
",3.1. Acquisition Strategies,[0],[0]
"Given our tree-structured surrogate model, we can improve on both the naive and the independent approach.",3.1. Acquisition Strategies,[0],[0]
"The acquisition function becomes α(x, p|Dn), p being the leaf node where x is evaluated.",3.1. Acquisition Strategies,[0],[0]
"For our model, α(x, p|Dn) can be evaluated in O(V 3 + ∑ p n 3 p), which is often much cheaper than O(n3) required in the naive approach, and is comparable to O( ∑ p n 3 p) for independent.",3.1. Acquisition Strategies,[0],[0]
"We could maximize α(x, p|Dn) separately at each leaf p, and then pick the best candidate across leaf nodes:
(x?, p?) ∈ arg max p∈P,x∈Xp α(x, p|Dn).
",3.1. Acquisition Strategies,[0],[0]
"In practice, the set of leaf nodes P can become large, in which case the requirement to search in every leaf node can be costly.",3.1. Acquisition Strategies,[0],[0]
We propose to further exploit the tree structure of our surrogate model in order to speed up the optimization.,3.1. Acquisition Strategies,[0],[0]
"Namely, our model implies a path acquisition function α(p|Dn).",3.1. Acquisition Strategies,[0],[0]
"Based on this, we select p? and x?",3.1. Acquisition Strategies,[0],[0]
"in two steps:
p? = arg max p∈P α(p|Dn), x? ∈ arg max x∈Xp? α(x, p?|Dn).
",3.1. Acquisition Strategies,[0],[0]
This strategy can greatly speed up the optimization.,3.1. Acquisition Strategies,[0],[0]
"There are obvious intermediates, such as searching in a subset of top-ranked leafs p, which we defer for future work.",3.1. Acquisition Strategies,[0],[0]
"Given our surrogate model, the EI acquisition function is: α(x, p|Dn) = E {",3.2. Two-step Expected Improvement,[0],[0]
[ymin − gp(x)−,3.2. Two-step Expected Improvement,[0],[0]
"z>p c]+ } , (5)
Table 1.",3.2. Two-step Expected Improvement,[0],[0]
Comparison of different surrogate models and acquisition strategies (see text for details).,3.2. Two-step Expected Improvement,[0],[0]
"Here,M(X ) is the complexity of optimizing a surrogate function over the space X .",3.2. Two-step Expected Improvement,[0],[0]
"p? is the path selected by tree, and Xp? is the corresponding leaf domain.
",3.2. Two-step Expected Improvement,[0],[0]
sharing?,3.2. Two-step Expected Improvement,[0],[0]
"complexity independent × O
(∑
p n 3 p · M(Xp)
)
",3.2. Two-step Expected Improvement,[0],[0]
"naive X O ( ( ∑
p np) 3 · M
( P× ∏ pXp ))",3.2. Two-step Expected Improvement,[0],[0]
tree X O ( V 3 + n3p? ·,3.2. Two-step Expected Improvement,[0],[0]
"M(Xp?)
)",3.2. Two-step Expected Improvement,[0],[0]
"where [u]+ = max{u, 0}, and ymin is the best evaluation so far (across all leafs).",3.2. Two-step Expected Improvement,[0],[0]
The expectation is computed with respect to the posterior of gp(x) + z,3.2. Two-step Expected Improvement,[0],[0]
">p c, which is a GP with mean and covariance functions respectively given by
m̃p(x) = kp(x) >",3.2. Two-step Expected Improvement,[0],[0]
M−1p (yp − bp) + tp(x)>Λ −1,3.2. Two-step Expected Improvement,[0],[0]
"c fc + bp,
S̃p(x,x ′)",3.2. Two-step Expected Improvement,[0],[0]
=,3.2. Two-step Expected Improvement,[0],[0]
"Sp(x,x ′) + tp(x) >Λ−1c tp(x ′),
where tp(x) = zp",3.2. Two-step Expected Improvement,[0],[0]
− ZpM−1p kp(x).,3.2. Two-step Expected Improvement,[0],[0]
"We can analytically compute (5), leading to
α(x, p|Dn) = σ̃p(x) (ξΦ(ξ) +N (ξ; 0, 1)) ,
where σ̃p(x) = {S̃p(x,x)}1/2, ξ = m̃p(x)−yminσ̃p(x) and Φ(ξ) is the CDF of a standard Gaussian.
",3.2. Two-step Expected Improvement,[0],[0]
"As noted above, we could optimize α(x, p|Dn) at all leaves and pick the overall winner.",3.2. Two-step Expected Improvement,[0],[0]
"Instead, we propose a two-step approach, based on a path EI acquisition function:
α(p|Dn) = E {",3.2. Two-step Expected Improvement,[0],[0]
"[ymin − bp − z>p c]+ } , (6)
where the expectation is taken with respect to z",3.2. Two-step Expected Improvement,[0],[0]
>p c + bp ∼ N,3.2. Two-step Expected Improvement,[0],[0]
(z>p Λ −1,3.2. Two-step Expected Improvement,[0],[0]
"c fc + bp, z > p Λ −1 c zp).",3.2. Two-step Expected Improvement,[0],[0]
"We first select the path p? = arg maxp α(p|Dn), then find x? by maximizing α(x, p?|Dn) at leaf p?",3.2. Two-step Expected Improvement,[0],[0]
only.,3.2. Two-step Expected Improvement,[0],[0]
Our tree acquisition strategy is related to the naive and independent ones in Table 1.,3.2. Two-step Expected Improvement,[0],[0]
"Interestingly, tree can be faster than independent overall.",3.2. Two-step Expected Improvement,[0],[0]
"Finally, (6) is easily extended to the case where we have random linear functions at the inner nodes by considering the augmented induced variable zp =",3.2. Two-step Expected Improvement,[0],[0]
[rv]v∈Vp (see Section 2.4 for details).,3.2. Two-step Expected Improvement,[0],[0]
"In particular, the resulting optimization of (6) is carried out jointly over p and zp =",3.2. Two-step Expected Improvement,[0],[0]
[rv]v∈Vp .,3.2. Two-step Expected Improvement,[0],[0]
"In this section, we conduct two sets of experiments.",4. Experiments,[0],[0]
"First, we focus on optimizing synthetic functions designed to have tree-structured conditional relationships.",4. Experiments,[0],[0]
"We then consider the tuning of a multi-layer perceptron for binary classification, which we evaluate over a large number of datasets.
",4. Experiments,[0],[0]
"Throughout the experiments, we use the following acronyms to refer to the different competing methods: tree is our proposed approach, independent is a baseline that consider an independent GP for every leaf, arc corresponds
to (Swersky et al., 2014a), smac refers to (Hutter et al., 2011) and gp-baseline is a standard GP-based Bayesian optimization solver taken from (GPyOpt, 2016).",4. Experiments,[0],[0]
"For tree, independent and gp-baseline, we use 5/2 Matérn kernels.",4. Experiments,[0],[0]
"marginal is another baseline obtained by replacing the kernel of gp-baseline by that stemming from the marginal (4), where c is viewed as a nuisance variable and integrated out.",4. Experiments,[0],[0]
"Finally, random is standard random search (Bergstra & Bengio, 2012).
",4. Experiments,[0],[0]
"Unless otherwise specified, all the results displayed in this section correspond to the means and twice the standard errors computed over 25 random replications.",4. Experiments,[0],[0]
"Also, in order to minimize the initialization bias, all methods (except smac1) start from the same set of random candidates; there is one random candidate drawn per conditional path.",4. Experiments,[0],[0]
Our implementation is in Python and we ran the experiments on a fleet of Amazon AWS c4.8xlarge machines.,4. Experiments,[0],[0]
"The functions we consider are defined over binary trees: Each inner node, including the root, corresponds to a binary variable.",4.1. Synthetic Tree-structured Functions,[0],[0]
A path in this tree thus represents successive binary decisions.,4.1. Synthetic Tree-structured Functions,[0],[0]
The leaves contain univariate quadratic functions that are shifted by different constant terms.,4.1. Synthetic Tree-structured Functions,[0],[0]
We give an example of such a function in Figure 1.,4.1. Synthetic Tree-structured Functions,[0],[0]
"In the sequel, we study the two functions from Figure 1 (referred to as small balanced), in addition to a higher-dimensional version of those, with a depth of 4 and 8 leaves whose constant shifts are {a× 0.1}8a=1 (referred to as large balanced).",4.1. Synthetic Tree-structured Functions,[0],[0]
"In the supplementary material, we provide further results based
1We use https://github.com/sfalkner/pySMAC.",4.1. Synthetic Tree-structured Functions,[0],[0]
"To the best of our knowledge, we cannot specify the starting point.
on unbalanced binary trees of increasing sizes, for which similar conclusions hold.",4.1. Synthetic Tree-structured Functions,[0],[0]
"All the non-shared continuous variables xj’s are defined in [−1, 1], while the shared ones are in [0, 1].",4.1. Synthetic Tree-structured Functions,[0],[0]
"The best function value will thus always be 0.1.
",4.1. Synthetic Tree-structured Functions,[0],[0]
"Those functions encode conditional relationships since given a path p and its leaf `p, all the binary variables outside of the path p and all the continuous variables defined in the leaves `′ 6=",4.1. Synthetic Tree-structured Functions,[0],[0]
`p are irrelevant.,4.1. Synthetic Tree-structured Functions,[0],[0]
We report in Figure 2 the optimization results for the different competing methods.,4.1. Synthetic Tree-structured Functions,[0],[0]
"We make the following observations:
Approaches blind to structure perform poorly: The results show that, both gp-baseline and random, which cannot use the conditional structure, do not fare well.",4.1. Synthetic Tree-structured Functions,[0],[0]
"As expected, the performance gap widens as the trees get deeper.
",4.1. Synthetic Tree-structured Functions,[0],[0]
"Independent vs. tree vs. arc: independent, tree and arc represent 3 ways of increasingly incorporating conditional structure.",4.1. Synthetic Tree-structured Functions,[0],[0]
"Indeed, independent takes into account the tree structure but does not allow for any sharing of information across different paths, arc defines a joint kernel over the union of all the leaves, while tree makes intermediate modeling assumptions.",4.1. Synthetic Tree-structured Functions,[0],[0]
"We can observe that, thanks to its joint nature, arc tends to perform well initially, but it is quickly overtaken by tree and later also by independent that lags behind because of the absence of sharing, but catches up once sufficient observations were collected.",4.1. Synthetic Tree-structured Functions,[0],[0]
"Also, as the dimension of the optimization space gets larger, the performance of independent worsens, while that of tree is barely affected (we do observe the same scalability with respect to the dimension on unbalanced binary trees, as reported in the supplementary material).",4.1. Synthetic Tree-structured Functions,[0],[0]
"At this juncture, we would also like to emphasize that while independent catches up with tree in some cases, it is more wasteful of resources as it requires to score every leaf at each iteration unlike tree (see also Table 1).
",4.1. Synthetic Tree-structured Functions,[0],[0]
"Importance of exploiting the latent variables c: It is interesting to observe that marginal, which considers c to be a nuisance variable and integrates it out, performs significantly worse than tree.",4.1. Synthetic Tree-structured Functions,[0],[0]
"Note that marginal cannot de facto be applied in presence of shared variables, which explains why it does not appear in the right panels of Figure 1.
",4.1. Synthetic Tree-structured Functions,[0],[0]
"Approach not based on GPs: smac is known to be stateof-the-art for optimization tasks in presence of conditional relationships (Eggensperger et al., 2013).",4.1. Synthetic Tree-structured Functions,[0],[0]
"In particular, it is known to work better than GP-based approaches, especially when the dimension gets large.",4.1. Synthetic Tree-structured Functions,[0],[0]
"We observe in our experiments (e.g., for large balanced, 7 categorical and 10 continuous parameters, 2 of which being shared) that smac does not reach good solutions on these synthetic tasks.",4.1. Synthetic Tree-structured Functions,[0],[0]
We now focus our attention on the tuning of a multilayer perceptron (MLP) for binary classification.,4.2. Multi-layer Perceptron Tuning,[0],[0]
The setting we consider is reminiscent of that proposed by Swersky et al. (2014a).,4.2. Multi-layer Perceptron Tuning,[0],[0]
"We optimize for the number of hidden layers in {0, 1, 2, 3, 4}, the number of units per layer in {1, 2, . . .",4.2. Multi-layer Perceptron Tuning,[0],[0]
", 30} (provided the corresponding layer is activated), the choice of the activation function in {identity, logistic, tanh, relu}, which we constrain to be identical across all layers, the amount of `2 regularization in [10−6, 10−1], the learning rate in [10−5, 10−1] of the underlying Adam solver (Kingma & Ba, 2014), the tolerance in [10−5, 10−2] of the solver (based on relative decrease), and the type of data pre-processing, which can be unit `2-norm observation-wise normalization, `∞-norm feature-wise normalization, mean/standarddeviation feature-wise whitening or no normalization at all.
",4.2. Multi-layer Perceptron Tuning,[0],[0]
"The optimization task can be specified in various ways, resulting in different topologies for the trees of conditional relationships.",4.2. Multi-layer Perceptron Tuning,[0],[0]
We consider the two instantiations of conditional relationships illustrated in Figure 3.,4.2. Multi-layer Perceptron Tuning,[0],[0]
"The first one has all the variables duplicated (top tree), which is similar to how independent proceeds.",4.2. Multi-layer Perceptron Tuning,[0],[0]
The second one consists in having most of the variables shared (bottom tree).,4.2. Multi-layer Perceptron Tuning,[0],[0]
"Note that in the two settings, we have one regularization parameter λk per number k of hidden layer(s) of the network.",4.2. Multi-layer Perceptron Tuning,[0],[0]
"We do
so to account for the fact that the λk’s regularize matrices of different dimensions.",4.2. Multi-layer Perceptron Tuning,[0],[0]
"In between those two extreme settings, we could consider intermediate modeling assumptions (e.g., a learning rate ηlinear for the case with no hidden layers and a shared learning rate ηnon-linear otherwise).
",4.2. Multi-layer Perceptron Tuning,[0],[0]
"To provide a robust evaluation of the different competing methods, we consider a subset of the datasets from the Libsvm repository (Chang & Lin, 2011).",4.2. Multi-layer Perceptron Tuning,[0],[0]
"More specifically, we consider all the datasets whose number of features is smaller than 106, which results in 45 data sets.",4.2. Multi-layer Perceptron Tuning,[0],[0]
"In absence of pre-defined default train-test split, we took a random 80%−20% split.",4.2. Multi-layer Perceptron Tuning,[0],[0]
"To limit the overall computational burden, we cap the training and test set sizes to a maximum of respectively 103 and 104 instances (randomly selected when the subsampling applies).",4.2. Multi-layer Perceptron Tuning,[0],[0]
"Note that this subsampling step is not related to a computational limitation of our approach, but is a practical consideration only modifying the properties of the black-box function we optimize.",4.2. Multi-layer Perceptron Tuning,[0],[0]
"We use the MLP implementation of scikit-learn (Pedregosa et al., 2011)
and we add a CPU-time constraint of 5 minutes to each evaluation, beyond which the worst classification error 1.0 is returned.",4.2. Multi-layer Perceptron Tuning,[0],[0]
"Under this constraint, the total computational time of the experiment was roughly 100 CPU days.
",4.2. Multi-layer Perceptron Tuning,[0],[0]
We run all the methods for 85 iterations and initialize them with one random choice for each of the 5 conditional paths.,4.2. Multi-layer Perceptron Tuning,[0],[0]
We aggregate the average classification errors per dataset by displaying the average rank of each method as a function of the number of iterations.,4.2. Multi-layer Perceptron Tuning,[0],[0]
"We say that the rank of a method is equal to i if it performs the ith best (see, e.g., Bardenet et al. (2013); Feurer et al. (2015)).",4.2. Multi-layer Perceptron Tuning,[0],[0]
"We can draw the following conclusions:
Effect of z>p c without shared variables: The top panel in Figure 4 compares independent with tree-based method when it is defined on the independent topology shown in Figure 3(top).",4.2. Multi-layer Perceptron Tuning,[0],[0]
"Since there are no shared variables in the inner nodes, the sharing mechanism of tree only
happens via the term z>p c",4.2. Multi-layer Perceptron Tuning,[0],[0]
which contributes to the mean.,4.2. Multi-layer Perceptron Tuning,[0],[0]
"As expected, sharing results in tree makes faster progress towards the optimum.",4.2. Multi-layer Perceptron Tuning,[0],[0]
"However, when more observations are collected, independent outperforms tree because it better explores all the leafs (though, at a higher computational cost; see Table 1).",4.2. Multi-layer Perceptron Tuning,[0],[0]
"We next show how we can additionally benefit from sharing parameters at inner nodes.
",4.2. Multi-layer Perceptron Tuning,[0],[0]
Shared topology: The lower panel in Figure 4 compares all the methods using the shared topology shown in Figure 3(bottom).,4.2. Multi-layer Perceptron Tuning,[0],[0]
"We found that arc, gp-baseline, random and smac all benefitted from running with the shared topology.",4.2. Multi-layer Perceptron Tuning,[0],[0]
"The results show that tree not only greatly improves upon all other GP-based approaches, but also converges faster than smac that finally reaches the same level of performance after about 75 iterations.",4.2. Multi-layer Perceptron Tuning,[0],[0]
"We can observe that a standard GP-based technique that is blind to the conditional structure, like gp-baseline, performs poorly.",4.2. Multi-layer Perceptron Tuning,[0],[0]
"Of independent interest is the comparison of arc with smac, which was not reported by Swersky et al. (2014a).",4.2. Multi-layer Perceptron Tuning,[0],[0]
"Finally, it is worth emphasizing that tree obtains good results while only modeling shared variables at the inner nodes in a linear fashion.",4.2. Multi-layer Perceptron Tuning,[0],[0]
"This conclusion is in agreement with the recent observations from (Zhang et al., 2016) where linear models lead to good results in the context of the optimization of data analytic pipelines.",4.2. Multi-layer Perceptron Tuning,[0],[0]
"Next, we discuss an extension to model the shared variables non-linearly.",4.2. Multi-layer Perceptron Tuning,[0],[0]
The approach we have introduced in Section 2.4 can easily be extended to account for non-linearities through the use of basis expansions.,4.3. Nonlinear Extensions,[0],[0]
"More specifically, we focus on the use of random Fourier features (Rahimi et al., 2007) that proved successful for large-scale kernel methods (Lu et al., 2014).",4.3. Nonlinear Extensions,[0],[0]
"Combining basis expansion with linear models for Bayesian optimization is by no means new (see (Shahriari et al., 2016) and references therein).",4.3. Nonlinear Extensions,[0],[0]
"We also follow this methodology since it naturally fits our proposed semi-parametric model.
",4.3. Nonlinear Extensions,[0],[0]
"In the supplementary material, we report results on synthetic tree-structured functions where the objectives at the leaves depend now quadratically on the shared variables and on the MLP tuning task.",4.3. Nonlinear Extensions,[0],[0]
"In a nutshell, on the synthetic functions with linearly-dependent shared variables, tree-nonlinear converges slower than the linear version tree, which might be due to the fact that c is of higher dimensionality.",4.3. Nonlinear Extensions,[0],[0]
"Moreover, in presence of quadratically-dependent shared variables, we observe that tree fails to model adequately the non-linearities, while tree-nonlinear, as expected, can.",4.3. Nonlinear Extensions,[0],[0]
"As for the MLP task, we notice that the non-linear extension of tree tends to perform worse than its linear counterpart.",4.3. Nonlinear Extensions,[0],[0]
"The black-box functions typically encountered in machine learning rely on incremental learning procedures, such as the application of (stochastic) gradient descent over several epochs.",5. Concluding Remarks,[0],[0]
"A recent line of work has been focusing on leveraging this property to speed up Bayesian optimization (Swersky et al., 2013; 2014b; Domhan et al., 2014; Li et al., 2016; Klein et al., 2016).",5. Concluding Remarks,[0],[0]
"In particular, Li et al. (2016) and Klein et al. (2016) have reported state-of-the-art results with methods based respectively on bandits and GPs, exploiting a dynamic subsampling of the training sets.
",5. Concluding Remarks,[0],[0]
The goal of our work is orthogonal to this idea and consists instead in efficiently encoding conditional relationships with GPs.,5. Concluding Remarks,[0],[0]
"We next outline ways of combining our work with the aforementioned subsampling idea:
Combination with Klein et al. (2016): The proposal of Klein et al. (2016) uses some contextual variable (also referred to as environmental variable) to encode the subsampling rate of the training set.",5. Concluding Remarks,[0],[0]
Let us denote it by β ∈,5. Concluding Remarks,[0],[0]
"[0, 1].",5. Concluding Remarks,[0],[0]
"Klein et al. (2016) define the following joint kernel:
K((x, β), (x′, β′))",5. Concluding Remarks,[0],[0]
"= K0(x,x′) · Kcontext(β, β′).
",5. Concluding Remarks,[0],[0]
"The optimization is then driven by a cost-normalized acquisition function maxβ′,x α(x, β = 1|Dn)/cost(x, β′) where both x and β are sought to perform well on the final task of interest where no subsampling is applied (i.e., β = 1).
",5. Concluding Remarks,[0],[0]
"Looking at our case, we could easily replace our kernel Kp by K̃p((x, β), (x′, β′)) , Kp(x,x′) · Kcontext(β, β′).",5. Concluding Remarks,[0],[0]
"To apply the two-step procedure, we could normalize (6) by a cost following a separate model (1) where the contextual variable β would be a shared variables at the root.",5. Concluding Remarks,[0],[0]
"Formally, we could consider a joint path/subsampling selection criterion:
(p?, β?)",5. Concluding Remarks,[0],[0]
"∈ arg max p∈P,β′∈[0,1]
E {",5. Concluding Remarks,[0],[0]
"[ymin − bp − zp(β = 1)>c]+ }
E { zp(β′)>ccost } , where zp(β) refers to the feature representation of the path p with context variable β.
Combination with Li et al. (2016): The approach of Li et al. (2016) is based on successive halving procedures where a pool containing initially many models is progressively refined and trimmed.",5. Concluding Remarks,[0],[0]
"The output of their theoreticallyjustifed algorithm, named hyperband, can be seen as triplets Hn , {(xi, yi, βi)}ni=1",5. Concluding Remarks,[0],[0]
"representing all the tested configurations xi along with their corresponding evaluations yi and subsampling rates βi.
",5. Concluding Remarks,[0],[0]
A natural approach to leverage hyperband is therefore to useHn to warm-start our context-aware extension with kernel K̃p while fixing β = 1.,5. Concluding Remarks,[0],[0]
"In other words, our approach would be used to refine the smart and computationallyefficient initialization provided by hyperband.",5. Concluding Remarks,[0],[0]
Bayesian optimization has been successfully used to optimize complex black-box functions whose evaluations are expensive.,abstractText,[0],[0]
"In many applications, like in deep learning and predictive analytics, the optimization domain is itself complex and structured.",abstractText,[0],[0]
"In this work, we focus on use cases where this domain exhibits a known dependency structure.",abstractText,[0],[0]
The benefit of leveraging this structure is twofold: we explore the search space more efficiently and posterior inference scales more favorably with the number of observations than Gaussian Process-based approaches published in the literature.,abstractText,[0],[0]
We introduce a novel surrogate model for Bayesian optimization which combines independent Gaussian Processes with a linear model that encodes a tree-based dependency structure and can transfer information between overlapping decision sequences.,abstractText,[0],[0]
We also design a specialized two-step acquisition function that explores the search space more effectively.,abstractText,[0],[0]
Our experiments on synthetic tree-structured objectives and on the tuning of feedforward neural networks show that our method compares favorably with competing approaches.,abstractText,[0],[0]
Bayesian Optimization with Tree-structured Dependencies,title,[0],[0]
"Probabilistic numerics (Hennig et al., 2015) proposes approaching problems of numerical analysis from the point of view of statistics.",1. Introduction,[0],[0]
"In particular, Bayesian probabilistic numerical methods approach this problem from a Bayesian point of view, and can provide posterior distributions on the solutions of numerical problems (e.g. in the case of this paper, the solution of some integral).",1. Introduction,[0],[0]
These posterior distributions represent our epistemic uncertainty about these quantities of interest.,1. Introduction,[0],[0]
"In the case of quadrature rules, the uncertainty is due to the fact that we only have a finite number of
*Equal contribution 1Department of Mathematics, Imperial College London 2Department of Statistics, University of Warwick 3The Alan Turing Institute for Data Science and AI.",1. Introduction,[0],[0]
"Correspondence to: François-Xavier Briol <f-x.briol@warwick.ac.uk>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
function evaluations and therefore are uncertaint about the value of the integral.",1. Introduction,[0],[0]
"The notion of Bayesian probabilistic numerical method was independently introduced by several authors (Larkin, 1972; Kadane & Wasilkowski, 1985; Diaconis, 1988; O’Hagan, 1992), but only recently formalised by (Cockayne et al., 2017).
",1. Introduction,[0],[0]
"Apart from the uncertainty quantification property described above, these methods have several other advantages over “classical” (i.e. non-Bayesian) numerical methods (although some of the classical and Bayesian methods coincide (Diaconis, 1988)).",1. Introduction,[0],[0]
"First of all, they allow the user to formulate all of its prior knowledge in the form of a prior, making all of the assumptions of the numerical scheme explicit.",1. Introduction,[0],[0]
"Second of all, they can allow for coherent propagation of numerical uncertainties through chains of computation; see (Cockayne et al., 2017; Oates et al., 2017a).
",1. Introduction,[0],[0]
"However, one property which has not been studied so far is the possibility of jointly inferring several quantities of interest.",1. Introduction,[0],[0]
"In this paper, we study the problem of numerically integrating a sequence of functions f1, . . .",1. Introduction,[0],[0]
", fD (which are correlated to one another) with respect to some probability measure Π, and hence propose to build a model for joint inference of ∫ f1dΠ, . . .",1. Introduction,[0],[0]
", ∫ fDdΠ. Such a joint model allows for better finite-sample performance, and can also lead to more refined posterior distributions on each of the individual integrals.
",1. Introduction,[0],[0]
"To tackle this problem, we extend the well-known Bayesian quadrature (O’Hagan, 1991) algorithm and study the performance of the proposed methodology from a theoretical and experimental point of view.",1. Introduction,[0],[0]
"In particular, we provide asymptotic convergence results for the marginal posterior variance on each of the integrals, both in the case of a well specified and misspecified prior.",1. Introduction,[0],[0]
"We also demonstrate the performance of our algorithm on some toy problems from the engineering literature on multi-fidelity models, and on a challenging problem from the field of computer graphics.",1. Introduction,[0],[0]
"Bayesian Quadrature Let (X ,B,Π) be a probability space and consider some function f :",2. Methodology,[0],[0]
"X → R where X ⊆ Rp, p ∈",2. Methodology,[0],[0]
N+.,2. Methodology,[0],[0]
"The classical problem of numerical
integration is concerned with approximating the integral:
Π[f ]",2. Methodology,[0],[0]
:,2. Methodology,[0],[0]
"= ∫ X f(x)Π(dx),
where we assume ∫ X f
2(x)Π(dx)",2. Methodology,[0],[0]
<,2. Methodology,[0],[0]
"∞. Under fairly general conditions on f , one can show that an optimal algorithm (in terms of worst-case integration error in some function space) takes the form of a quadrature (or cubature) rule Π̂[f ] = ∑N i=1 wif(xi) for some weights {wi}Ni=1 ∈ R and samples {xi}Ni=1 ∈ X (see (Bakhvalov, 1971)).",2. Methodology,[0],[0]
"These are also sometimes denoted in vectorised form as Π[f ] = w>f(X) where w = (w1, . . .",2. Methodology,[0],[0]
", wN )>, X =",2. Methodology,[0],[0]
"(x1, . . .",2. Methodology,[0],[0]
",xN )
> and f(X) = (f(x1), . . .",2. Methodology,[0],[0]
", f(xN ))",2. Methodology,[0],[0]
>.,2. Methodology,[0],[0]
The notation Π̂[f ] is motivated by the fact that we can see this object as an exact integral with respect to a discrete measure Π̂ = ∑N i=1,2. Methodology,[0],[0]
"wiδxi , where δxi denotes the Dirac delta measure taking value 1 at xi and 0 otherwise.",2. Methodology,[0],[0]
"Many popular numerical integration methods take this form, including Newton–Cotes rules, Gaussian quadrature, Monte Carlo methods and sparse grids.
",2. Methodology,[0],[0]
"Let (Ω,F ,P) be another probability space.",2. Methodology,[0],[0]
"Bayesian quadrature (BQ), introduced by (O’Hagan, 1991), proposes to approach the problem of numerical integration by first formulating a prior stochastic model g : X × Ω → R for the integrand f (where ∀ω ∈ Ω, g(·, ω) represents a realisation of g).",2. Methodology,[0],[0]
"This prior model is then conditioned on the vector of observations f(X) to obtain a posterior model for f , which is then pushed forward through the integral operator to give a posterior on Π[f ].
",2. Methodology,[0],[0]
"A popular choice of prior is a Gaussian Process (GP) GP(m, k) with m : X → R denoting the mean function (i.e. m(x) =",2. Methodology,[0],[0]
"Eω[g(x, ω)]), and c :",2. Methodology,[0],[0]
"X × X → R denoting the covariance function/kernel (i.e. c(x,x′) = Eω[(g(x, ω)−m(x))(g(x′, ω)−m(x′))]).",2. Methodology,[0],[0]
Let us assume that m = 0,2. Methodology,[0],[0]
(this can be done without loss of generality since the domain can be re-parametrized to be centred at 0).,2. Methodology,[0],[0]
"After conditioning on X , we have a new Gaussian process gN with mean and covariance:
mN (x) = c(x,X)c(X,X) −1f(X),
cN (x,x ′)",2. Methodology,[0],[0]
"= c(x,x′)− c(x,X)c(X,X)−1c(X,x′),
for all x,x′ ∈ X .",2. Methodology,[0],[0]
"Here, c(X,X) is the Gram matrix with entries (c(X,X))ij = c(xi,xj) and c(x,X) = (c(x,x1), . . .",2. Methodology,[0],[0]
", c(x,xN ))",2. Methodology,[0],[0]
"whilst c(X,x) = c(x,X)> .",2. Methodology,[0],[0]
"The push-forward of this posterior through the integral operator is a Gaussian distribution with mean and variance:
E",2. Methodology,[0],[0]
"[Π[gN ]] = Π[c(·,X)]c(X,X)−1f(X), V [Π[gN",2. Methodology,[0],[0]
]] = ΠΠ̄,2. Methodology,[0],[0]
"[c]−Π[c(·,X)]c(X,X)−1Π̄[c(X, ·)],
where Π[c(·,X)]",2. Methodology,[0],[0]
"= (Π[c(·,x1)], . . .",2. Methodology,[0],[0]
",Π[c(·,xN )]).",2. Methodology,[0],[0]
"These expression can be obtained in closed-form if the kernel mean Π[c(·,x)]",2. Methodology,[0],[0]
"= ∫ X c(x ′,x)Π(dx′) (also called
the representer of integration) and initial error ΠΠ̄[c] =∫ X×X c(x,x
′)Π(dx)Π(dx′) can be obtained in closed form (here Π̄ indicates that the integral is taken with respect to the second argument).
",2. Methodology,[0],[0]
"The choice of covariance function c can be used to encode prior beliefs about the function f , such as smoothness or periodicity, and is very important to obtain good performance in practice.",2. Methodology,[0],[0]
"A popular example is the family of Matérn kernels
cα(x,x ′) = λ2
21−α
Γ(α)
(√ 2α ‖x− x′‖22
σ2 )α ×",2. Methodology,[0],[0]
"Jα (√ 2α ‖x− x′‖22
σ2
) , (1)
for σ, λ > 0 where Jα is the Bessel function of the second kind and α > 0 gives the smoothness of the kernel.",2. Methodology,[0],[0]
"On X = Rp, this will give an RKHS normequivalent to the Sobolev space Wα2 (Rd)1.",2. Methodology,[0],[0]
"Examples of infinitely smooth kernels include the squared-exponential kernel c(x,x′) = exp(−‖x− x′‖22/σ2) where σ > 0, the multi-quadric kernel c(x,x′) =",2. Methodology,[0],[0]
"(−1)dβe(σ2+‖x−x′‖22)β for β, σ > 0, β 6∈ N and the inverse multi-quadric kernel c(x,x′) = (σ2 + ‖x− x′‖22)−β for β, σ > 0.
",2. Methodology,[0],[0]
"In practice, numerical inversion can be challenging since the Gram matrix tends to be nearly singular, and so one may wish to regularise the matrix using a Tikhonov penalty.",2. Methodology,[0],[0]
"The inverses above can also potentially render the computation of the BQ estimator computationally expensive (up to O(N3) cost in the most general settings), although this can be alleviated in specific cases (Karvonen & Särkkä, 2017b).",2. Methodology,[0],[0]
"Even if this is not the case, the additional cost can be worthwhile regardless since the method has been shown to attain fast convergence rates (Briol et al., 2015a;b; Kanagawa et al., 2016; 2017; Bach, 2017) when the target integrand and the kernel used are smooth.
",2. Methodology,[0],[0]
"Recent research directions in BQ include efficient sampling algorithms (for the point set X) to improve the performance of the method (Rasmussen & Ghahramani, 2002; Huszar & Duvenaud, 2012; Gunter et al., 2014; Briol et al., 2015a; Karvonen & Särkkä, 2017a; Briol et al., 2017), asymptotic convergence results (Briol et al., 2015a;b; Kanagawa et al., 2016; Bach, 2017) and equivalence of BQ with known quadrature rules for certain choices of point sets and kernels (Sarkka et al., 2016; Karvonen & Särkkä, 2017a).",2. Methodology,[0],[0]
"Furthermore, there has also been a wide range of new applications, including to other numerical methods in optimization, linear algebra and functional approximation (Kersting & Hennig, 2016; Fitzsimons et al., 2017), inference in complex computer models
1We say that two norms ‖ · ‖1 and ‖ · ‖2 on a vector space are norm-equivalent if and only if ∃C1, C2 > 0",2. Methodology,[0],[0]
"such that C1‖ · ‖2 ≤ ‖ · ‖1 ≤ C2‖ · ‖2.
(Oates et al., 2017c), and problems in econometrics (Oettershagen, 2017) and computer graphics (Brouillat et al., 2009; Marques et al., 2013; Briol et al., 2015b).
",2. Methodology,[0],[0]
"Although other stochastic processes could of course be used (Cockayne et al., 2017), GPs are popular due to their conjugacy properties, and the terminology Bayesian quadrature usually refers to this case.",2. Methodology,[0],[0]
"Note that other names for BQ with GP priors include Gaussian-process quadrature (Sarkka et al., 2016) or kernel quadrature (Bach, 2017; Briol et al., 2017; Kanagawa et al., 2017).",2. Methodology,[0],[0]
"In fact, a well-known alternative view of the posterior mean provided by BQ is that of an optimally-weighted quadrature rule in a reproducing kernel Hilbert spaces (RKHS) in the classical worst-case setting (Ritter, 2000).",2. Methodology,[0],[0]
"Let Hk be an RKHS with inner product and norm denoted 〈·, ·〉k and ‖·‖k respectively; i.e. a Hilbert space with an associated symmetric and positive definite reproducing kernel k :",2. Methodology,[0],[0]
"X × X → R such that f(x) = 〈f, k(·,x)〉k (see (Berlinet & Thomas-Agnan, 2004) for a detailed study).",2. Methodology,[0],[0]
"Suppose that our integrand f ∈ Hk and that ∫ X k(x,x)Π(dx) <",2. Methodology,[0],[0]
"∞. In that case, using the Cauchy–Schwarz inequality, the integration error can be decomposed as:∣∣∣Π[f ]",2. Methodology,[0],[0]
− Π̂[f ]∣∣∣ ≤ ‖f‖k ∥∥∥Π,2. Methodology,[0],[0]
"[k(·,x)]− Π̂",2. Methodology,[0],[0]
"[k(·,x)]∥∥∥
k .
",2. Methodology,[0],[0]
"The corresponding worst-case error over the unit ball of the spaceHk is given by:
e ( Hk, Π̂,X )",2. Methodology,[0],[0]
= sup ‖f‖k≤1 ∣∣∣Π[f,2. Methodology,[0],[0]
]− Π̂[f ]∣∣∣ = ∥∥∥Π,2. Methodology,[0],[0]
"[k(·,x)]− Π̂",2. Methodology,[0],[0]
"[k(·,x)]∥∥∥
k = ( w>k(X,X)w − 2Π[k(·,X)]>w + ΠΠ̄[k] )",2. Methodology,[0],[0]
"1 2 .
",2. Methodology,[0],[0]
"This final expression can be minimised in closed form over w ∈ RN to show that the optimal quadrature rule has weights w = Π[k(·,X)]k(X,X)−1.",2. Methodology,[0],[0]
"This corresponds exactly to the weights for the BQ posterior mean if we take our prior on f to be a GP(0, k), whilst the worst-case error can be shown to correspond to the posterior variance squared.",2. Methodology,[0],[0]
"The BQ estimator with prior GP(0, c) is therefore optimal in the classical worst-case sense for the RKHSHc.
",2. Methodology,[0],[0]
Multi-output Bayesian Quadrature We now extend the set-up of our problem.,2. Methodology,[0],[0]
"Suppose we have a sequence of probability spaces (Xd,Bd,Πd) and functions fd :",2. Methodology,[0],[0]
"Xd → R for which we are interested in numerically computing integrals of the form Πd[fd] for d = 1, . . .",2. Methodology,[0],[0]
", D.",2. Methodology,[0],[0]
"In many applications where we are faced with this type of problem, we also have prior knowledge about correlations between the individual fd.",2. Methodology,[0],[0]
"However, this information is often ignored and the integrals are approximated individually.",2. Methodology,[0],[0]
"This is not a principled approach from a Bayesian point of
view since it means we are not conditioning on all available information.",2. Methodology,[0],[0]
"In this section, we extend the BQ algorithm to solve this problem by building a joint model of f1, . . .",2. Methodology,[0],[0]
", fD in order to obtain a joint posterior on the integrals Π1[f1], . . .",2. Methodology,[0],[0]
",ΠD[fD].
",2. Methodology,[0],[0]
"For notational convenience, we will restrict ourselves to the case where all of the input domains are identical and denoted X , all of the probability measures are identical and denoted Π, and the input sets X = {Xd}Dd=1 consist of N points",2. Methodology,[0],[0]
"Xd = (xd,1, . . .",2. Methodology,[0],[0]
",xd,N ) per output function fd (note the setup can be made more general if necessary).",2. Methodology,[0],[0]
We re-frame the integration problem as that of integrating some vector-valued function f : X,2. Methodology,[0],[0]
"→ RD such that f(x) = (f1(x), . . .",2. Methodology,[0],[0]
", fD(x))
",2. Methodology,[0],[0]
">; i.e. we want to estimate Π[f ] = (Π[f1], . . .",2. Methodology,[0],[0]
",Π[fD])
>.",2. Methodology,[0],[0]
"In this multiple-integral setting, we can have generalised quadrature rules of the form:
Π̂[fd] = D∑ d′=1 N∑ i=1",2. Methodology,[0],[0]
"(Wi)dd′fd′(xd′,i)
where Wi ∈ RD×D are weight matrices and (Wi)dd′ gives the influence of the value of fd′ at xd′,i on the estimate of Π[fd].",2. Methodology,[0],[0]
"The quadrature rule for f can be re-written in compact form as Π̂[f ] = W>f(X) for some weight matrix W ∈ RND×D (a concatenation of {Wi}Ni=1) and function-evaluations vector f(X) = (f1(x1,1), . . .",2. Methodology,[0],[0]
", f1(x1,N ), . . .",2. Methodology,[0],[0]
", fD(xD,1), . . .",2. Methodology,[0],[0]
", fD(xD,N ))",2. Methodology,[0],[0]
">.
",2. Methodology,[0],[0]
"These generalised quadrature rules encompass popular Monte Carlo methods such as control variates or functionals (Glasserman, 2004; Oates et al., 2017b), multilevel Monte Carlo (Giles, 2015) and multi-fidelity Monte Carlo (Peherstorfer et al., 2016b).",2. Methodology,[0],[0]
"However, it is important to point out that these methods can only deal with very specific relations between integrands, usually requiring ( ∫ X (fd(x)−fd′(x)) 2Π(dx))",2. Methodology,[0],[0]
"1 2 to be small for all pairs of integrands fd, fd′ .",2. Methodology,[0],[0]
"Our method will be able to make use of much more complex relations.
",2. Methodology,[0],[0]
"We propose to approach this problem using an extended version of BQ, where we impose a prior g : X × Ω→ RD which is a GP(0,C) on the extended space (this is often called a multi-output GP or co-kriging model (Alvarez et al., 2012))",2. Methodology,[0],[0]
"where now C is matrix-valued and (C(x,x′))dd′ = Eω∼P[gd(x, ω)gd′(x′, ω)",2. Methodology,[0],[0]
].,2. Methodology,[0],[0]
"In this case, after conditioning on X , we have a GP gN with vectorvalued mean mN :",2. Methodology,[0],[0]
"X → RD and matrix-valued covariance CN : X × X → RD×D:
mN (x) = C(x,X)C(X,X) −1f(X),
CN (x,x ′) = C(x,x′)−C(x,X)C(X,X)−1C(X,x′),
for C(x,X) = (C(x,x1), . . .",2. Methodology,[0],[0]
", C(x,xN ))",2. Methodology,[0],[0]
"∈ RD×ND and Gram matrix C(X,X) ∈",2. Methodology,[0],[0]
"RND×ND is:
C(X,X) =  (C(X1,X1))1,1 . . .",2. Methodology,[0],[0]
"(C(X1,XD))1,D (C(X2,X1))2,1 ... (C(X2,XD))2,D
... ... ...",2. Methodology,[0],[0]
"(C(XD,X1))D,1 . . .",2. Methodology,[0],[0]
"(C(XD,XD))D,D
 ,
where C(Xd,Xd′)d,d′ is an N × N matrix.",2. Methodology,[0],[0]
"The posterior on the value of the integral vector Π[f ] can also be obtained whenever the kernel mean Π[C(·,x)] and initial error ΠΠ̄",2. Methodology,[0],[0]
"[C] are available in closed form, which is potentially a restrictive condition.",2. Methodology,[0],[0]
"The authors of (Briol et al., 2015b) give a table of closed-form expressions of these quantities for popular kernels in the uni-output case, and we envision the same type of table being necessary for future extensions of multi-output BQ.",2. Methodology,[0],[0]
"Alternatively, (Oates et al., 2017b; 2016) proposed a kernel which is tailored to the target probability measure Π and which could also be extended to the multi-output case.
",2. Methodology,[0],[0]
Proposition 1.,2. Methodology,[0],[0]
"Consider multi-output Bayesian Quadrature with a GP(0,C) prior on f = (f1, . . .",2. Methodology,[0],[0]
", fD)>.",2. Methodology,[0],[0]
"The posterior distribution on Π[f ] is a D-dimensional Gaussian distribution with mean and covariance matrix:
E",2. Methodology,[0],[0]
"[Π[gN ]] = Π[C(·,X)]C(X,X)−1f(X), V [Π[gN ]] = ΠΠ̄",2. Methodology,[0],[0]
"[C]−Π[C(·,X)]C(X,X)−1Π̄[C(X, ·)].
",2. Methodology,[0],[0]
"All proofs can be found in Appendix B. In this case, we clearly end up with a generalised quadrature rule with weight matrix: W BQ = (Π [C(·,X)]C(X,X)−1)",2. Methodology,[0],[0]
>,2. Methodology,[0],[0]
∈,2. Methodology,[0],[0]
"RND×D. In general, the computational cost for computing the posterior mean and variance is now of orderO(N3D3).",2. Methodology,[0],[0]
"However, several choices of kernels can reduce this cost significantly, and it is also possible to obtain sparse GP approximations; see e.g. (Álvarez & Lawrence, 2011).
",2. Methodology,[0],[0]
The choice of kernel C is of course once again of great importance since it encodes prior knowledge about each of the integrand and their correlation structure and should be made based on the application considered.,2. Methodology,[0],[0]
"We also remark that matrix valued kernels C can be described in term of some scalar-valued kernel r on the extended space X×{1, . . .",2. Methodology,[0],[0]
", D} as (C(x,x′))dd′ =",2. Methodology,[0],[0]
"r((x, d), (x′, d′)).",2. Methodology,[0],[0]
"We now present two choices of covariance functions which are popular in the literature and will be used in this paper:
• The separable kernel is of the form
C(x,x′) = Bc(x,x′),
whereB ∈ RD×D is symmetric and positive definite, and c :",2. Methodology,[0],[0]
X × X → R is a scalar-valued reproducing kernel.,2. Methodology,[0],[0]
"This treats the kernel as the product of two scalar-valued reproducing kernels, one defined on X
and the other on {1, . . .",2. Methodology,[0],[0]
", D}.",2. Methodology,[0],[0]
A particular case of interest is the linear model of coregionalization (LMC) where the matrix is of the form (B)dd′ = ∑R i=1,2. Methodology,[0],[0]
a i da,2. Methodology,[0],[0]
i d′ for some aid ∈ R.,2. Methodology,[0],[0]
"This type of kernel can lead to a lower computational cost of orderO(N3 +D3) when evaluating all fd on the same input set and using tensor product formulations (see Appendix C).
",2. Methodology,[0],[0]
•,2. Methodology,[0],[0]
"The process convolution kernel (Ver Hoef & Barry, 1998; Higdon, 2002; Alvarez et al., 2012) models the individual functions f1, . . .",2. Methodology,[0],[0]
", fD",2. Methodology,[0],[0]
as blurred transformations of R ∈ N+ underlying functions.,2. Methodology,[0],[0]
"It is given by:
(C(x,x′))d,d′ = cd,d′(x,x ′) + cwd(x,x ′)δd,d′ ,
where δdd′ = 1 if d = d′ and 0 else.",2. Methodology,[0],[0]
"Here there are two parts of the kernel, first cd,d′ : X × X → R defined as:
cd,d′(x,x ′)",2. Methodology,[0],[0]
= R∑ i=1,2. Methodology,[0],[0]
∫,2. Methodology,[0],[0]
"X Gid(x− z)×∫
X Gid′(x ′",2. Methodology,[0],[0]
"− z′)ci(z, z′)dz′dz,
and cwd : X ×X → R representing covariance inherent to the dth function and Gid : X → R is a blurring kernel2 which is a continuous function either having compact support or being square integrable.",2. Methodology,[0],[0]
"Notice that taking Gid(x− z) = aidδ(x− z) (where δ(·) represents a Dirac function) gives back the LMC case.
",2. Methodology,[0],[0]
"Note that it is also common to combine kernels, by summing them (i.e. C(x,x′) = ∑Q q=1Cq(x,x
′))",2. Methodology,[0],[0]
in order to obtain more flexible models.,2. Methodology,[0],[0]
"The kernel means and initial error, as well as other details for implementation are provided in Appendix C.",2. Methodology,[0],[0]
"In this section, we begin by exploring properties of multioutput BQ with GP(0,C) prior as an optimally-weighted quadrature algorithm in vector-valued RKHSHC .
",3. Theoretical results,[0],[0]
"Let HK be a vector-valued RKHS with norm and inner product denoted ‖ · ‖K and 〈·, ·〉K respectively.",3. Theoretical results,[0],[0]
"These spaces were extensively studied in (Pedrick, 1957; Micchelli & Pontil, 2005; Carmeli et al., 2006; 2010; De Vito et al., 2013), and generalise the notion of RKHS to vectorvalued functions.",3. Theoretical results,[0],[0]
"In the multi-output case, there is also a one-to-one correspondance between the RKHS HK and the kernel K. Theorem 3.1 in (Micchelli & Pontil, 2005) shows that the minimizer of the variational problem:
min h∈HK
{ ‖h‖2K : h : X → RD,h(xi) = f(xi) ∀xi ∈X } 2Note that the term “blurring kernel” does not mean the func-
tion is a reproducing kernel.
takes the form of the multi-output posterior GP mean mN obtained after conditioning a GP(0,K) on some data set X .",3. Theoretical results,[0],[0]
"We can therefore extend a well-known result from the uni-output case to show that Π̂BQ[fd] is an optimally weighted quadrature rule for all fd in terms of their worstcase integration error, denoted:
e(HC , Π̂,X, d)",3. Theoretical results,[0],[0]
:= sup ‖f‖C≤1 ∣∣∣Π[fd]− Π̂[fd]∣∣∣ .,3. Theoretical results,[0],[0]
(2) Proposition 2 (Optimally weighted quadrature rule in HC).,3. Theoretical results,[0],[0]
"For a fixed point set X , denote by Π̂[f ] = W>f(X) any quadrature rule for the vector-valued function f = (f1, . . .",3. Theoretical results,[0],[0]
", fD) and by Π̂BQ[f ]",3. Theoretical results,[0],[0]
"= W>BQf(X) the BQ rule with GP(0,C) prior.",3. Theoretical results,[0],[0]
"Then, ∀d = 1, . . .",3. Theoretical results,[0],[0]
", D:
WBQ = arg min W∈RND×D
e(HC , Π̂,X, d).
",3. Theoretical results,[0],[0]
"In specific cases, it is also possible to characterise the rate of convergence of the worst-case error for each element fd.",3. Theoretical results,[0],[0]
"This is for example the case with the separable kernel introduced in Sec. 2, as will be demonstrated in the Theorem 1 below.",3. Theoretical results,[0],[0]
"First, we introduce some technical definitions which will be required for the statement of the theorem.
",3. Theoretical results,[0],[0]
We say that a domain X ⊂,3. Theoretical results,[0],[0]
"Rp satisfies an interior cone condition if there exists an angle θ ∈ (0, π2 ) and a radius r > 0",3. Theoretical results,[0],[0]
"such that ∀x ∈ X , a unit vector ξ(x) exists such that the cone {x + λy : y ∈ Rp, ‖y‖2 = 1,y>ξ(x) ≥ cos θ, λ ∈",3. Theoretical results,[0],[0]
"[0, r]} is a subset of X .
",3. Theoretical results,[0],[0]
"For a point setX , we call hX,X :=",3. Theoretical results,[0],[0]
supx∈X infxj∈X,3. Theoretical results,[0],[0]
"‖x− xj‖2 the fill distance, qX := 12 minj 6=k ‖xj−xk‖2",3. Theoretical results,[0],[0]
"the separation radius and ρX,X := hX,X /qX the mesh ratio.",3. Theoretical results,[0],[0]
"We will assume we evaluate all integrands on the same point setX which satisfies either of these assumptions:
(A1) X consists of independently and identically distributed (IID) samples from some probability measure Π′ which admits a density π′ > 0",3. Theoretical results,[0],[0]
"on X .
(A2) X is a quasi-uniform grid on X ⊂",3. Theoretical results,[0],[0]
"Rp (i.e. satisfies hX,X ≤ C1N− 1 p for some C1 > 0) and satisfies
hX,X ≤ C2qX,X for some C2 > 0.
",3. Theoretical results,[0],[0]
"Examples of point sets satisfying (A2) include uniform grid points in some hypercube.
",3. Theoretical results,[0],[0]
Theorem 1 (Convergence rate for BQ with separable kernel).,3. Theoretical results,[0],[0]
Suppose we want to approximate Π[f ] for some f : X,3. Theoretical results,[0],[0]
"→ RD and Π̂BQ[f ] is the multi-output BQ rule with the kernel C(x,x′) = Bc(x,x′) for some positive definite B ∈ RD×D and scalar-valued",3. Theoretical results,[0],[0]
kernel c :,3. Theoretical results,[0],[0]
"X × X → R. Then, ∀d = 1, . . .",3. Theoretical results,[0],[0]
", D, we have:
e(HC , Π̂BQ,X, d) =",3. Theoretical results,[0],[0]
"O ( e(Hc, Π̂BQ,X) ) .
",3. Theoretical results,[0],[0]
"In particular, assume that X ⊂",3. Theoretical results,[0],[0]
Rp satisfies an interior cone condition with Lipschitz boundary3 and X satisfies assumption (A1) or (A2).,3. Theoretical results,[0],[0]
"Then, the following rates hold:
• IfHc is norm-equivalent to an RKHS with Matérn kernel of smoothness α > p2 , we have ∀d = 1, . . .",3. Theoretical results,[0],[0]
", D:
e(HC , Π̂BQ,X, d) =",3. Theoretical results,[0],[0]
"O ( N− α p+ ) ,
for > 0 arbitrarily small.
",3. Theoretical results,[0],[0]
"• If Hc is norm-equivalent to the RKHS with squaredexponential, multiquadric or inverse multiquadric kernel, we have ∀d = 1, . . .",3. Theoretical results,[0],[0]
", D:
e(HC , Π̂BQ,X, d) =",3. Theoretical results,[0],[0]
"O ( exp ( −C1N 1 p− )) ,
for someC1 > 0 and for some > 0 arbitrarily small.
",3. Theoretical results,[0],[0]
Proposition 3 (Convergence rate for sum of kernels).,3. Theoretical results,[0],[0]
"Suppose that C(x,x′) = ∑Q q=1Cq(x,x ′).",3. Theoretical results,[0],[0]
"Then:
e(HC , Π̂BQ,X, d) = arg max q∈{1,...,Q}
O",3. Theoretical results,[0],[0]
"( e(HCq , Π̂BQ,X, d) ) .
",3. Theoretical results,[0],[0]
"We clarify that the notation with is common in the numerical integration literature, and is used to hide powers of log n terms since these do not have a significant influence on the asymptotic convergence rate.
",3. Theoretical results,[0],[0]
"It is interesting to note that the rate of convergence for multi-output BQ is the same as that of uni-output BQ (Briol et al., 2015b).",3. Theoretical results,[0],[0]
"This can be explained intuitively by the fact that, when adding a new integrand, we can only gain by a constant factor since we always evaluate the functions at the same input points.",3. Theoretical results,[0],[0]
"In fact the proof of Thm. 1 provides an expression for this improvement factor (in terms of WCE) for any integrand fd, and this depends explicitly on its correlation with the other functions: | ∑D i,j=1(B
−1)ijBidBjd|.",3. Theoretical results,[0],[0]
"From a practitioner’s viewpoint, this can clearly be used to balance the value of using several integrands with the additional computational cost incurred by using multi-output BQ.
",3. Theoretical results,[0],[0]
We now give a result in the misspecified setting when the function f is assumed to be smoother than it is.,3. Theoretical results,[0],[0]
"In this case, it is still possible to recover the optimal convergence rate:
Theorem 2 (Misspecified Convergence Result for Separable Kernel).",3. Theoretical results,[0],[0]
Let cα be a kernel norm-equivalent to a Matérn kernel of smoothness α on some domain X with Lipschitz boundary and satisfying an interior cone condition.,3. Theoretical results,[0],[0]
"Consider the BQ rule Π̂BQ[f ] corresponding to a separable kernel Cα(x, x′) = Bcα(x, x′) with X satisfying
3Formally defined in Appendix A for completeness.
",3. Theoretical results,[0],[0]
Figure 1.,3. Theoretical results,[0],[0]
"Multi-fidelity modelling: Plot of the Step function (top), Forrester function (bottom) for the low fidelity (left) and high fidelity (right).",3. Theoretical results,[0],[0]
"Each plot gives the true function (blue) and their unit-output (dashed, red), LMC-based multi-output (dashed, yellow) and PC-based multi-output (dotted purple) approximations.
",3. Theoretical results,[0],[0]
"(A2), and suppose that f ∈ HCβ where p 2 ≤ β ≤ α.",3. Theoretical results,[0],[0]
"Then, ∀d = 1, . . .",3. Theoretical results,[0],[0]
", D:∣∣∣Π[fd]−",3. Theoretical results,[0],[0]
"Π̂BQ[fd]∣∣∣ = O (N− βp+ ) , for some > 0.
",3. Theoretical results,[0],[0]
This last theorem demonstrate that the method is rate adaptive as long as we choose a kernel which is too smooth.,3. Theoretical results,[0],[0]
"However, it also demonstrates a drawback of the separable kernels: if one of the integrands is rough but all other are smooth, then the worst-case error could potentially converge slowly for all of them.
",3. Theoretical results,[0],[0]
"Finally, we note that studying the method in other information complexity settings than the worst-case would also be interesting.",3. Theoretical results,[0],[0]
"For example, it is trivial to show that the method above satisfies the definition of Bayesian probabilistic numerical method of (Cockayne et al., 2017) (Def. 2.5).",3. Theoretical results,[0],[0]
"Furthermore, optimality conditions for this method could also be obtained in a game-theoretic setting (in terms of a two-player mixed strategies game) by extending the theory on gamblets by (Owhadi & Scovel, 2017).",3. Theoretical results,[0],[0]
"Multi-fidelity modelling Consider some function f high : X → R representing some complex engineering model of interest, which we would like to use for some task such as statistical inference or optimization.",4. Applications,[0],[0]
"These models usually require the simulation of underlying physical systems, which can make each evaluation prohibitively expensive and will therefore limit N to the order of tens or hundreds.",4. Applications,[0],[0]
"To tackle this issue, multi-fidelity modelling proposes to build cheap, but less accurate, alternatives f low1 , . . .",4. Applications,[0],[0]
", f low",4. Applications,[0],[0]
"D−1 :
Model BQ LMC-BQ PC-BQ
Step (l) 0.02 (0.22) 0.02 (0.21) 0.02 (0.52)",4. Applications,[0],[0]
Step (h) 0.41 (0.03) 0.09 (0.09) 0.04 (0.15) For.,4. Applications,[0],[0]
(l) 0.08 (4.91) 0.08 (4.95) 0.07 (33.95) For.,4. Applications,[0],[0]
"(h) 3.96 (3.98) 2.86 (27.01) 1.06 (63.80)
",4. Applications,[0],[0]
"X → R to f high, and use the cheaper models in order to accelerate computation for the task of interest.",4. Applications,[0],[0]
"This can be done using surrogate models (e.g. support vector machines, GPs or neural networks), projection-based models (Krylov subspace or reduced basis methods) or models where the underlying physics is simplified; see (Peherstorfer et al., 2016a) for an overview.
",4. Applications,[0],[0]
"In this section, we consider the problem of numerical integration in such a multi-fidelity setup.",4. Applications,[0],[0]
"Note that two related methods for Monte Carlo estimation are the multi-fidelity Monte Carlo estimator (Peherstorfer et al., 2016a) and the multilevel Monte Carlo of (Giles, 2015), both of which are based on control variate identities.
",4. Applications,[0],[0]
"We approach this problem with multi-output BQ on the vector-valued function f = (f high, f low1 , . . .",4. Applications,[0],[0]
", f low D−1)
>.",4. Applications,[0],[0]
"Note that multi-output Gaussian processes were already proposed for multi-fidelity modelling in (Perdikaris et al., 2016; Parussini et al., 2017), and we extend their methodologies to the task of numerical integration.",4. Applications,[0],[0]
"We consider two toy problems from this literature (Raissi & Karniadakis, 2016) to highlight some of the advantages and disadvantages of our methodology
1.",4. Applications,[0],[0]
A step function on X =,4. Applications,[0],[0]
"[0, 2]:
f low1 (x) = { 0, x ≤ 1 1, x > 1 f high(x) = { −1, x ≤ 1 2, x > 1
2.",4. Applications,[0],[0]
The Forrester function with Jump on X =,4. Applications,[0],[0]
"[0, 1]:
f low1 (x) =
{ (3x−1)2 sin(12x−4)
4 + 10(x− 1), x ≤ 1 2
3 + (3x−1) 2 sin(12x−4)
4 + 10(x− 1), x > 1 2
f high(x) =
{ 2f low(x)− 20(x− 1), x ≤ 12
4 + 2f low(x)− 20(x− 1), x > 12
The functions and conditioned GPs are given in Fig. 1, whilst the uni-output and multi-output BQ estimates for integration of these functions against a uniform measure Π
are given in the table in Fig. 2.",4. Applications,[0],[0]
"In both cases, 20 equidistant points are used, with point number 4, 10, 11, 14 and 17 used to evaluate the high fidelity model and the others used for the low fidelity model.",4. Applications,[0],[0]
The choice of kernel hyperparameters is made by maximising the marginal likelihood (often called empirical Bayes).,4. Applications,[0],[0]
"Further details, and an additional test function can be found in Appendix D.2.
",4. Applications,[0],[0]
Note that both of these problems are challenging for several reasons.,4. Applications,[0],[0]
"Firstly, due to their discontinuity, the integrands are not in the RKHS HC corresponding to the kernel C used in multi-output BQ.",4. Applications,[0],[0]
"In particular, the problems are misspecified in the sense that the true function is not in the support of the prior.",4. Applications,[0],[0]
"It is therefore difficult to interpret the posterior distribution on Π[f ], and we end up with credible intervals which are too wide.",4. Applications,[0],[0]
This is for example illustrated in the values of the posterior variance for the high-fidelity Forrester function.,4. Applications,[0],[0]
"Secondly, in each case, the high and low-fidelity models are defined on different scales and so require tuning of several kernel hyper-parameters.",4. Applications,[0],[0]
"This can of course make it challenging for multi-output BQ since the number of function evaluations N is small and empirical Bayes will tend to be inefficient in those cases.
",4. Applications,[0],[0]
"However, despite these two issues, it is interesting to note that both of the multi-output BQ methods manage to significantly outperform uni-output BQ in terms of point estimate, as the sharing of information allows the multi-output models to better represent the main trends in the functions.",4. Applications,[0],[0]
"Furthermore, the multi-output BQ does not suffer from the issues of overconfident posterior credible intervals present in uni-output BQ; contrast for example the posterior variances for the high-fidelity step function.
",4. Applications,[0],[0]
"Global illumination In this section, we apply multioutput BQ to a challenging numerical integration problem from the field of computer graphics, known as global illumination.",4. Applications,[0],[0]
"BQ was previously applied to this problem in several papers (Brouillat et al., 2009; Marques et al., 2013; Briol et al., 2015b), but we propose to extend these results using multi-output BQ.
",4. Applications,[0],[0]
Global illumination is a problem which occurs when trying to obtain realistic representation of light interactions for the design of virtual environments (e.g. a video game).,4. Applications,[0],[0]
"One model of the amount of light coming from an object towards the camera (representing the current viewpoint on this environment) is given by the following equation:
L0(ω0) = Le(ω0) + ∫ S2 Li(ωi)ρ(ωi, ω0)[ωi · n]+dΠ(ωi).
",4. Applications,[0],[0]
"where [x]+ = max(0, x).",4. Applications,[0],[0]
"The function L0 : S2 → R evaluated at ω0 is called the outgoing radiance in direction ω0 (the angle of the outgoing light from the object normal n), Le(ω0) : S2 → R is the amount of light emitted by
the object, and Li : S2 → R evaluated at ωi is the amount of light reflected by the object (which originated from an angle ωi from the object’s normal n).",4. Applications,[0],[0]
"Here, S2 = {x = (x1, x2, x3) ∈ R3 : ‖x‖2 = 1} and ρ(ωi, ω0) :",4. Applications,[0],[0]
"S2 × S2 → R is called the bidirectional reflectance distribution and represents the proportion of light being reflected.
",4. Applications,[0],[0]
"We follow (Briol et al., 2015b) and consider the problem as Π[hω0 ]",4. Applications,[0],[0]
"= ∫ S2 h
ω0(ωi)Π(dωi) where Π is the uniform measure on S2, and hω0(ωi) = Li(ωi)ρ(ωi, ω0)[ωi · ω0]+ is a function which can be evaluated by making a call to an environment map (which we consider to be a black box).",4. Applications,[0],[0]
"One scenario which is common in these type of problems is to look at an object from different angles ω0, with the camera moving.",4. Applications,[0],[0]
"In this case, it is reasonable to assume that the different integrands hω0 will be very similar when the difference in the angle ω0 is small, and it is therefore natural to consider jointly estimating their integrals.",4. Applications,[0],[0]
"In the experiments we consider five integrands fi = hω i 0 for i = 1, . . .",4. Applications,[0],[0]
", 5 where ω10 , . .",4. Applications,[0],[0]
.,4. Applications,[0],[0]
", ω 5 0 are on a great circle of the sphere at intervals determined by an angle of 0.005π.
",4. Applications,[0],[0]
We therefore consider two-output and five-output BQ with independent and identically distributed (Monte Carlo) samples X from the uniform measure,4. Applications,[0],[0]
"Π. We propose to use a separable kernel with scalar-valued RKHS Hc being a Sobolev space of smoothness 32 over S
2 and has kernel c(x,x′) = 83",4. Applications,[0],[0]
− ‖x,4. Applications,[0],[0]
"− x
′‖22.",4. Applications,[0],[0]
"For the matrix B representing the covariance between outputs, we propose to make this covariance proportional to the difference in angle at which the camera looks at the object.",4. Applications,[0],[0]
In particular we choose (B)ij = exp(ω i 0 · ω,4. Applications,[0],[0]
j 0,4. Applications,[0],[0]
"− 1) for simplicity, but this could be generalised to include a lengthscale and amplitude hyperparameter to be learnt together with the hyperparameters of the scalar-valued kernel c.
The GP means for the one-output and five-output cases are given in Fig. 3, and we can clearly notice a significant improvement in approximation accuracy with the larger number of outputs.",4. Applications,[0],[0]
Results for integration error are given in Fig. 4.,4. Applications,[0],[0]
"As noticed, the integration error (for a fixed number of evaluationsN of each integrand) is significantly reduced by increasing the number of outputs D. The individual posterior variances for this problem (see Appendix D.3 Fig. 10) are also smaller, reflecting the fact that our uncertainty is reduced due to use of observations from other integrands.
",4. Applications,[0],[0]
"In fact, a small extension of Thm. 1 (combined with the rate for the scalar-valued kernel in (Briol et al., 2015b)) allows us to obtain an asymptotic convergence rate for the posterior variance on each integral Π[fd]: Corollary 1.",4. Applications,[0],[0]
LetX be the sphere S2 andX be IID uniform points onX .,4. Applications,[0],[0]
AssumeC is a separable kernel with c defined above.,4. Applications,[0],[0]
"Then e(HC , Π̂BQ,X, d) = OP ( N− 3 4 ) .
",4. Applications,[0],[0]
"The same rate with improved rate constant was observed
in (Briol et al., 2015b) when using QMC point sets, and similar gains could be obtained in this multi-output case.
",4. Applications,[0],[0]
We note that there a significant potential further gains for the use of multi-output BQ in this setting.,4. Applications,[0],[0]
"Similar integration problems need to be computed for three colors in every pixel of an image, and for every image in a video.",4. Applications,[0],[0]
This is challenging computationally and limits the use of Monte Carlo methods to a few dozen points.,4. Applications,[0],[0]
Designing specific matrix-valued kernels could provide enormous gains since we end up with thousands of correlated integrands.,4. Applications,[0],[0]
"Furthermore, the weights only depend on the choice of kernel and not on function values, so that all of the weights could be pre-computed off-line to be later used in real-time.",4. Applications,[0],[0]
We have proposed an extension of Bayesian Quadrature to the case where we are interested in numerically computing the integral of several functions which are related.,5. Conclusion,[0],[0]
In particular we have proposed a new algorithm based on jointly modelling the integrands with a Gaussian prior.,5. Conclusion,[0],[0]
"Then, we provided a theoretical study of the rate of convergence for the case where the kernel is separable and illustrated the potential of our methodology on applications in multi-fidelity
modelling and computer graphics.",5. Conclusion,[0],[0]
"Our main contribution however, has been to highlight the natural extension of Bayesian probabilistic numerical methods to the joint estimation of the solution of several numerical problems (in this case, numerical integration problems).
",5. Conclusion,[0],[0]
There are several possible extensions of multi-output BQ which we reserve for future work.,5. Conclusion,[0],[0]
One important question remaining is that of the choice of sampling distribution.,5. Conclusion,[0],[0]
"In the uni-output case, it is well known that obtaining an optimal sampling distribution with respect to the Vn[Π[f ]] is intractable in most cases.",5. Conclusion,[0],[0]
"(Briol et al., 2017) proposed an algorithm to approach such a distribution, and (Kanagawa et al., 2017) provided conditions on the point sets to guarantee fast convergence.",5. Conclusion,[0],[0]
"In the multi-output case, the problem is even more complex due to the interaction between the different integration problems.",5. Conclusion,[0],[0]
"However, the literature on the design of experiments for co-kriging/multi-output GPs may be of interest, and the use of more advanced sampling distributions will certainly provide significant gains.",5. Conclusion,[0],[0]
"The authors are grateful to Alessandro Barp, Aretha Teckentrup, Chris Oates and Motonobu Kanagawa for helpful discussions.",Acknowledgements,[0],[0]
"FXB was supported by the EPSRC grants [EP/L016710/1, EP/R018413/1, EP/N510129/1].",Acknowledgements,[0],[0]
"MG was supported by the EPSRC grants [EP/J016934/3, EP/K034154/1, EP/P020720/1, EP/R018413/1, EP/N510129/1], an EPSRC Established Career Fellowship, the EU grant [EU/259348] and the
Lloyds Register Foundation Programme on Data-Centric Engineering.",Acknowledgements,[0],[0]
The authors would like to thank the Isaac Newton Institute for Mathematical Sciences for support and hospitality during the programme on “Uncertainty Quantification for Complex Systems: Theory and Methodologies”.,Acknowledgements,[0],[0]
This work was supported by EPSRC grant no [EP/K032208/1].,Acknowledgements,[0],[0]
"Finally, this material was also based upon work partially supported by the National Science Foundation under Grant DMS-1127914 to the Statistical and Applied Mathematical Sciences Institute.",Acknowledgements,[0],[0]
Bayesian probabilistic numerical methods are a set of tools providing posterior distributions on the output of numerical methods.,abstractText,[0],[0]
The use of these methods is usually motivated by the fact that they can represent our uncertainty due to incomplete/finite information about the continuous mathematical problem being approximated.,abstractText,[0],[0]
"In this paper, we demonstrate that this paradigm can provide additional advantages, such as the possibility of transferring information between several numerical methods.",abstractText,[0],[0]
"This allows users to represent uncertainty in a more faithful manner and, as a by-product, provide increased numerical efficiency.",abstractText,[0],[0]
We propose the first such numerical method by extending the well-known Bayesian quadrature algorithm to the case where we are interested in computing the integral of several related functions.,abstractText,[0],[0]
"We then prove convergence rates for the method in the well-specified and misspecified cases, and demonstrate its efficiency in the context of multi-fidelity models for complex engineering systems and a problem of global illumination in computer graphics.",abstractText,[0],[0]
Bayesian Quadrature for Multiple Related Integrals,title,[0],[0]
Deep learning has dramatically advanced the state of the art in a number of domains.,1. Introduction,[0],[0]
"Despite their unprecedented discriminative power, deep networks are prone to make mistakes.",1. Introduction,[0],[0]
"Nevertheless, they can already be found in settings where errors carry serious repercussions such as autonomous vehicles (Chen et al., 2016) and high frequency trading.",1. Introduction,[0],[0]
"We can soon expect automated systems to screen for various types of cancer (Esteva et al., 2017; Shen, 2017) and diagnose biopsies (Djuric et al., 2017).",1. Introduction,[0],[0]
"As autonomous systems based on deep learning are increasingly deployed in settings with the potential to cause physical or economic harm, we need to develop a better understanding of when we can be confident in the estimates produced by deep networks, and when we should be less certain.
",1. Introduction,[0],[0]
Standard deep learning techniques used for supervised learning lack methods to account for uncertainty in the model.,1. Introduction,[0],[0]
"This can be problematic when the network encounters conditions it was not exposed to during training,
* Co-first authorship 1School of Electrical Engineering and Computer Science, KTH Royal Institute of Technology, Stockholm, Sweden 2Current address: Electronic Arts, SEED, Stockholm, Sweden.",1. Introduction,[0],[0]
This work was carried out at Budbee AB.,1. Introduction,[0],[0]
3Science for Life Laboratory.,1. Introduction,[0],[0]
"Correspondence to: Kevin Smith <ksmith@kth.se>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"or if the network is confronted with adversarial examples (Goodfellow et al., 2014).",1. Introduction,[0],[0]
"When exposed to data outside the distribution it was trained on, the network is forced to extrapolate, which can lead to unpredictable behavior.
",1. Introduction,[0],[0]
"If the network can provide information about its uncertainty in addition to its point estimate, disaster may be avoided.",1. Introduction,[0],[0]
"In this work, we focus on estimating such predictive uncertainties in deep networks (Figure 1).
",1. Introduction,[0],[0]
"The Bayesian approach provides a theoretical framework for modeling uncertainty (Ghahramani, 2015), which has prompted several attempts to extend neural networks (NN) into a Bayesian setting.",1. Introduction,[0],[0]
"Most notably, Bayesian neural networks (BNNs) have been studied since the 1990’s (Neal, 2012), but do not scale well and struggle to compete with modern deep learning architectures.",1. Introduction,[0],[0]
"Recently, (Gal & Ghahramani, 2015) developed a practical solution to obtain uncertainty estimates by casting dropout training in conventional deep networks as a Bayesian approximation of a Gaussian Process (its correspondence to a general approximate Bayesian model was shown in (Gal, 2016)).",1. Introduction,[0],[0]
"They showed that any network trained with dropout is an approximate Bayesian model, and uncertainty estimates can be obtained by computing the variance on multiple predictions with different dropout masks.
",1. Introduction,[0],[0]
"The inference in this technique, called Monte Carlo Dropout (MCDO), has an attractive quality: it can be applied to any pre-trained networks with dropout layers.",1. Introduction,[0],[0]
Uncertainty estimates come (nearly) for free.,1. Introduction,[0],[0]
"However, not all architectures use dropout, and most modern networks have adopted other regularization techniques.",1. Introduction,[0],[0]
"Batch normalization (BN), in particular, has become widespread thanks to its ability to stabilize learning with improved generalization (Ioffe & Szegedy, 2015).
",1. Introduction,[0],[0]
An interesting aspect of BN is that the mini-batch statistics used for training each iteration depend on randomly selected batch members.,1. Introduction,[0],[0]
"We exploit this stochasticity and show that training using batch normalization, like dropout, can be cast as an approximate Bayesian inference.",1. Introduction,[0],[0]
We demonstrate how this finding allows us to make meaningful estimates of the model uncertainty in a technique we call Monte Carlo Batch Normalization (MCBN) (Figure 1).,1. Introduction,[0],[0]
"The method we propose can be applied to any network using standard batch normalization.
",1. Introduction,[0],[0]
"We validate our approach by empirical experiments on a variety of datasets and tasks, including regression and image classification.",1. Introduction,[0],[0]
"We measure uncertainty quality relative to a baseline of fixed uncertainty, and show that MCBN outperforms the baseline on nearly all datasets with strong statistical significance.",1. Introduction,[0],[0]
We also show that the uncertainty quality of MCBN is on par with other recent approximate Bayesian networks.,1. Introduction,[0],[0]
"Bayesian models provide a natural framework for modeling uncertainty, and several approaches have been developed to adapt NNs to Bayesian reasoning.",2. Related Work,[0],[0]
A common approach is to place a prior distribution (often a Gaussian) over each parameter.,2. Related Work,[0],[0]
"The resulting model corresponds to a Gaussian process for infinite parameters (Neal, 1995), and a Bayesian NN (MacKay, 1992) for a finite number of parameters.",2. Related Work,[0],[0]
"Inference in BNNs is difficult however (Gal, 2016), so focus has thus shifted to techniques that approximate the posterior, approximate BNNs.",2. Related Work,[0],[0]
"Methods based on variational inference (VI) typically rely on a fully factorized approximate distribution (Kingma & Welling, 2014; Hinton & Van Camp, 1993), but often do not scale.",2. Related Work,[0],[0]
"To alleviate these difficulties, (Graves, 2011) proposed a model using sampling methods to estimate a factorized posterior.",2. Related Work,[0],[0]
"Probabilistic backpropagation (PBP), estimates a factorized posterior via expectation propagation (HernándezLobato & Adams, 2015).
",2. Related Work,[0],[0]
"Using several strategies to address scaling issues, Deep
Gaussian Processes show superior performance in terms of RMSE and uncertainty quality compared to state-of-the-art approximate BNNs (Bui et al., 2016)1.",2. Related Work,[0],[0]
"Another recent approach to Bayesian learning, Bayesian hypernetworks, use a NN to learn a distribution of parameters over another network (Krueger et al., 2017).",2. Related Work,[0],[0]
"Multiplicative Normalizing Flows for variational Bayesian networks (MNF) (Louizos & Welling, 2017) is a recent model that formulates a posterior dependent on auxiliary variables.",2. Related Work,[0],[0]
"MNF achieves a highly flexible posterior by the application of normalizing flows to the auxiliary variables.
",2. Related Work,[0],[0]
"Although these recent techniques address some of the difficulties with approximate BNNs, they all require modifications to the architecture or the way networks are trained, as well as specialized knowledge from practitioners.",2. Related Work,[0],[0]
"Recently, (Gal & Ghahramani, 2015) showed that a network trained with dropout implicitly performs the VI objective.",2. Related Work,[0],[0]
Therefore any network trained with dropout can be treated as an approximate Bayesian model by making multiple predictions through the network while sampling different dropout masks for each prediction.,2. Related Work,[0],[0]
The mean and variance of the predictions are used in the estimation of the mean and variance of the predictive distribution 2.,2. Related Work,[0],[0]
"In the following, we introduce Bayesian models and a variational approximation using Kullback-Leibler (KL) divergence following (Gal, 2016).",3. Method,[0],[0]
We continue by showing that a batch normalized deep network can be seen as an approximate Bayesian model.,3. Method,[0],[0]
"Employing theoretical insights and empirical analysis, we study the induced prior on the parameters when using batch normalization.",3. Method,[0],[0]
"Finally, we describe the procedure for estimating the uncertainty of a batch normalized network’s output.3",3. Method,[0],[0]
"We assume a finite training set D = {(xi,yi)}i=1:N where each (xi,yi) is a sample-label pair.",3.1. Bayesian Modeling,[0],[0]
"Using D, we are interested in learning an inference function fω(x,y) with parameters ω.",3.1. Bayesian Modeling,[0],[0]
"In deterministic models, the estimated label ŷ is obtained as follows:
ŷ = arg max y fω(x,y)
",3.1. Bayesian Modeling,[0],[0]
"In probabilistic models we let fω(x,y) = p(y|x,ω).",3.1. Bayesian Modeling,[0],[0]
"In Bayesian modeling, in contrast to finding a point estimate
1By uncertainty quality, we refer to predictive probability distributions as measured by PLL and CRPS.
2This technique is referred to as “MC Dropout” in the original work, though we refer to it here as MCDO.
",3.1. Bayesian Modeling,[0],[0]
"3While the method applies to FC or Conv layers, the induced prior from weight decay (Section 3.3) is studied for FC layers.
of the model parameters, the idea is to estimate an (approximate) posterior distribution of the model parameters p(ω|D) to be used for probabilistic prediction:
p(y|x,D) = ∫ fω(x,y)p(ω|D)dω
The predicted label, ŷ, can then be accordingly obtained by sampling p(y|x,D) or taking its maxima.
",3.1. Bayesian Modeling,[0],[0]
"Variational Approximation In approximate Bayesian modeling, a common approach is to learn a parameterized approximating distribution qθ(ω) that minimizes KL(qθ(ω)||p(ω|D)); the Kullback-Leibler divergence of the true posterior w.r.t.",3.1. Bayesian Modeling,[0],[0]
its approximation.,3.1. Bayesian Modeling,[0],[0]
"Minimizing this KL divergence is equivalent to the following minimization while being free of the data term p(D) 4:
LVA(θ) :",3.1. Bayesian Modeling,[0],[0]
"=− N∑ i=1 ∫ qθ(ω) ln fω(xi,yi)dω
+ KL(qθ(ω)||p(ω))
",3.1. Bayesian Modeling,[0],[0]
"During optimization, we want to take the derivative of the expected likelihood w.r.t.",3.1. Bayesian Modeling,[0],[0]
the learnable parameters θ.,3.1. Bayesian Modeling,[0],[0]
"We use the same MC estimate as in (Gal, 2016) (explained in Appendix Section 1.1), such that one realized ω̂i is taken for each sample i 5.",3.1. Bayesian Modeling,[0],[0]
"Optimizing over mini-batches of size M , the approximated objective becomes:
L̂VA(θ) :",3.1. Bayesian Modeling,[0],[0]
"= − N
M M∑ i=1",3.1. Bayesian Modeling,[0],[0]
"ln fω̂i(xi,yi) + KL(qθ(ω)||p(ω))",3.1. Bayesian Modeling,[0],[0]
"(1)
The first term is the data likelihood and the second term is the divergence of the prior w.r.t.",3.1. Bayesian Modeling,[0],[0]
the approximated posterior.,3.1. Bayesian Modeling,[0],[0]
"We now describe the optimization procedure of a deep network with batch normalization and draw the resemblance to the approximate Bayesian modeling in Eq (1).
",3.2. Batch Normalized Deep Nets as Bayesian Modeling,[0],[0]
"The inference function of a feed-forward deep network with L layers can be described as:
fω(x) = W La(WL−1...a(W2a(W1x))
4Achieved by constructing the Evidence Lower Bound, called ELBO, and assuming i.i.d. observation noise; details can be found in Appendix Section 1.1.
",3.2. Batch Normalized Deep Nets as Bayesian Modeling,[0],[0]
"5While a MC integration using a single sample is a weak approximation, in an iterative optimization for θ several samples will be taken over time.
",3.2. Batch Normalized Deep Nets as Bayesian Modeling,[0],[0]
"where a(.) is an element-wise nonlinearity function and Wl is the weight vector at layer l. Furthermore, we denote the input to layer l as xl with x1 = x",3.2. Batch Normalized Deep Nets as Bayesian Modeling,[0],[0]
and we then set hl = Wlxl.,3.2. Batch Normalized Deep Nets as Bayesian Modeling,[0],[0]
Parenthesized super-index for matrices (e.g. W(j)) and vectors (e.g. x(j)) indicates jth row and element respectively.,3.2. Batch Normalized Deep Nets as Bayesian Modeling,[0],[0]
"Super-index u refers to a specific unit at layer l, (e.g. Wu = Wl,(j), hu = hl,(j)).",3.2. Batch Normalized Deep Nets as Bayesian Modeling,[0],[0]
"6
Batch Normalization Each layer of a deep network is constructed by several linear units whose parameters are the rows of the weight matrix W. Batch normalization is a unit-wise operation proposed in (Ioffe & Szegedy, 2015) to standardize the distribution of each unit’s input.",3.2. Batch Normalized Deep Nets as Bayesian Modeling,[0],[0]
"For FC layers, it converts a unit’s input hu in the following way:
ĥu = hu",3.2. Batch Normalized Deep Nets as Bayesian Modeling,[0],[0]
"− E[hu]√
Var[hu]
where the expectations are computed over the training set during evaluation, and mini-batch during training (in deep networks, the weight matrices are often optimized using back-propagated errors calculated on mini-batches of data)7.",3.2. Batch Normalized Deep Nets as Bayesian Modeling,[0],[0]
"Therefore, during training, the estimated mean and variance on the mini-batch B is used, which we denote by µB and σB respectively.",3.2. Batch Normalized Deep Nets as Bayesian Modeling,[0],[0]
"This makes the inference at training time for a sample x a stochastic process, varying based on other samples in the mini-batch.
",3.2. Batch Normalized Deep Nets as Bayesian Modeling,[0],[0]
"Loss Function and Optimization Training deep networks with mini-batch optimization involves a (regularized) risk minimization with the following form:
LRR(ω) :",3.2. Batch Normalized Deep Nets as Bayesian Modeling,[0],[0]
"= 1
M M∑ i=1",3.2. Batch Normalized Deep Nets as Bayesian Modeling,[0],[0]
"l(ŷi,yi) + Ω(ω)
where the first term is the empirical loss on the training data and the second term is a regularization penalty acting as a prior on model parameters ω.",3.2. Batch Normalized Deep Nets as Bayesian Modeling,[0],[0]
If the loss l is cross-entropy for classification or sum-of-squares for regression problems (assuming i.i.d.,3.2. Batch Normalized Deep Nets as Bayesian Modeling,[0],[0]
"Gaussian noise on labels), the first term is equivalent to minimizing the negative log-likelihood:
LRR(ω) := − 1
Mτ M∑ i=1",3.2. Batch Normalized Deep Nets as Bayesian Modeling,[0],[0]
"ln fω(xi,yi) + Ω(ω)
6For a (softmax) classification network, fω(x) is a vector with fω(x,y) = fω(x)
(y), for regression networks with i.i.d.",3.2. Batch Normalized Deep Nets as Bayesian Modeling,[0],[0]
"Gaussian noise we have fω(x,y) = N (fω(x), τ−1I).
",3.2. Batch Normalized Deep Nets as Bayesian Modeling,[0],[0]
"7It also learns an affine transformation for each unit with parameters γ and β, omitted for brevity: x̂(j)affine = γ (j)x̂(j) + β(j).
with τ = 1 for classification.",3.2. Batch Normalized Deep Nets as Bayesian Modeling,[0],[0]
"In a network with batch normalization, the model parameters include {W1:L,γ1:L,β1:L,µ1:LB ,σ1:LB }.",3.2. Batch Normalized Deep Nets as Bayesian Modeling,[0],[0]
"If we decouple the learnable parameters θ = {W1:L,γ1:L,β1:L} from the stochastic parameters ω = {µ1:LB ,σ1:LB }, we get the following objective at each step of the mini-batch optimization:
LRR(θ) := − 1
Mτ M∑ i=1",3.2. Batch Normalized Deep Nets as Bayesian Modeling,[0],[0]
"ln f{θ,ω̂i}(xi,yi) + Ω(θ) (2)
where ω̂i is the means and variances for sample i’s minibatch at a certain training step.",3.2. Batch Normalized Deep Nets as Bayesian Modeling,[0],[0]
Note that while ω̂i formally needs to be i.i.d.,3.2. Batch Normalized Deep Nets as Bayesian Modeling,[0],[0]
"for each training example, a batch normalized network samples the stochastic parameters once per training step (mini-batch).",3.2. Batch Normalized Deep Nets as Bayesian Modeling,[0],[0]
"For a large number of epochs, however, the distribution of sampled batch members for a given training example converges to the i.i.d. case.
",3.2. Batch Normalized Deep Nets as Bayesian Modeling,[0],[0]
"In a batch normalized network, qθ(ω) corresponds to the joint distribution of the weights, induced by the randomness of the normalization parameters µ1:LB ,σ 1:L B , as implied by the repeated sampling from D during training.",3.2. Batch Normalized Deep Nets as Bayesian Modeling,[0],[0]
"This is an approximation of the true posterior, where we have restricted the posterior to lie within the domain of our parametric network and source of randomness.",3.2. Batch Normalized Deep Nets as Bayesian Modeling,[0],[0]
"With that, we can estimate the uncertainty of predictions from a trained batch normalized network using the inherent stochasticity of BN (Section 3.4).",3.2. Batch Normalized Deep Nets as Bayesian Modeling,[0],[0]
Equivalence between the VA and BN training procedures requires ∂∂θ of Eq.,3.3. Prior p(ω),[0],[0]
(1) and Eq. (2) to be equivalent up to a scaling factor.,3.3. Prior p(ω),[0],[0]
This is the case if ∂∂θKL(qθ(ω)||p(ω)),3.3. Prior p(ω),[0],[0]
"= Nτ ∂∂θΩ(θ).
",3.3. Prior p(ω),[0],[0]
"To reconcile this condition, one option is to let the prior p(ω) imply the regularization term Ω(θ).",3.3. Prior p(ω),[0],[0]
Eq. (1) reveals that the contribution of KL(qθ(ω)||p(ω)) to the optimization objective is inversely scaled with N .,3.3. Prior p(ω),[0],[0]
"For BN, this corresponds to a model with a small Ω(θ) when N is large.",3.3. Prior p(ω),[0],[0]
"In the limit as N →∞, the optimization objectives of Eq.",3.3. Prior p(ω),[0],[0]
"(1) and Eq. (2) become identical with no regularization.8
Another option is to let some Ω(θ) imply p(ω).",3.3. Prior p(ω),[0],[0]
"In Appendix Section 1.4 we explore this with L2-regularization, also called weight decay (Ω(θ) = λ ∑ l=1:L ||W l||2).",3.3. Prior p(ω),[0],[0]
"We find that unlike in MCDO (Gal, 2016), some simplifying
8To prove the existence and find an expression of KL(qθ(ω)||p(ω)), in Appendix Section 1.3 we find that BN approximately induces Gaussian distributions over BN units’ means and standard deviations, centered around the population values given by D. We assume a factorized distribution and Gaussian priors, and find the corresponding KL(qθ(ω)||p(ω)) components in Appendix Section 1.4 Eq.",3.3. Prior p(ω),[0],[0]
(7).,3.3. Prior p(ω),[0],[0]
"These could be used to construct a custom Ω(θ) for any Gaussian choice of p(ω).
assumptions are necessary to reconcile the VA and BN objectives with weight decay: no scale and shift applied to BN layers, uncorrelated units in each layer, BN applied on all layers, and large N and M .",3.3. Prior p(ω),[0],[0]
"Given these conditions:
p(µuB) = N (µµ,p, σµ,p) p(σuB) = N (µσ,p, σσ,p)
where µµ,p = 0, σµ,p →∞, µσ,p = 0 and σσ,p → 12Nτλl .
",3.3. Prior p(ω),[0],[0]
This corresponds to a wide and narrow distribution on BN units’ means and std.,3.3. Prior p(ω),[0],[0]
"devs respectively, where N accounts for the narrowness of the prior.",3.3. Prior p(ω),[0],[0]
"Due to its popularity in deep learning, our experiments in Section 4 are performed with weight decay.",3.3. Prior p(ω),[0],[0]
"In the absence of the true posterior, we rely on the approximate posterior to express an approximate predictive distribution:
p∗(y|x,D) := ∫ fω(x,y)qθ(ω)dω
Following (Gal, 2016)",3.4. Predictive Uncertainty in Batch Normalized Deep Nets,[0],[0]
"we estimate the first (for regression and classification) and second (for regression) moments of the predictive distribution empirically (see Appendix Section 1.5 for details):
Ep∗",3.4. Predictive Uncertainty in Batch Normalized Deep Nets,[0],[0]
"[y] ≈ 1
T T∑ i=1",3.4. Predictive Uncertainty in Batch Normalized Deep Nets,[0],[0]
"fω̂i(x)
Covp∗",3.4. Predictive Uncertainty in Batch Normalized Deep Nets,[0],[0]
"[y] ≈ τ−1I + 1
T T∑ i=1",3.4. Predictive Uncertainty in Batch Normalized Deep Nets,[0],[0]
"fω̂i(x) ᵀfω̂i(x)
",3.4. Predictive Uncertainty in Batch Normalized Deep Nets,[0],[0]
− Ep∗,3.4. Predictive Uncertainty in Batch Normalized Deep Nets,[0],[0]
"[y]ᵀEp∗ [y]
where each ω̂i corresponds to sampling the net’s stochastic parameters ω = {µ1:LB ,σ1:LB } the same way as during training.",3.4. Predictive Uncertainty in Batch Normalized Deep Nets,[0],[0]
"Sampling ω̂i therefore involves sampling a batch B from the training set and updating the parameters in the BN units, just as if we were taking a training step with B. From a VA perspective, training the network amounted to minimizing KL(qθ(ω)||p(ω|D))",3.4. Predictive Uncertainty in Batch Normalized Deep Nets,[0],[0]
wrt θ.,3.4. Predictive Uncertainty in Batch Normalized Deep Nets,[0],[0]
"Sampling ω̂i from the training set, and keeping the size of B consistent with the mini-batch size used during training, ensures that qθ(ω) during inference remains identical to the approximate posterior optimized during training.
",3.4. Predictive Uncertainty in Batch Normalized Deep Nets,[0],[0]
"The network is trained just as a regular BN network, but instead of replacing ω = {µ1:LB ,σ1:LB } with population values from D for inference, we update these parameters stochastically, once for each forward pass.9 Pseudocode for estimating predictive mean and variance is given in Algorithm 1.
9As an alternative to using the training set D to sample ω̂i,
",3.4. Predictive Uncertainty in Batch Normalized Deep Nets,[0],[0]
"Algorithm 1 MCBN Algorithm Input: sample x, number of inferences T , batchsize b Output: mean prediction ŷ, predictive uncertainty σ2
1: y = {} 2: loop for T iterations 3: B ∼ D // mini batch 4: ω̂ = {µB ,σB} // mini batch mean and variance 5: y = y ∪ fω̂(x) 6: end loop 7: ŷ = E[y] 8: σ2 = Cov[y] + τ−1I // for regression",3.4. Predictive Uncertainty in Batch Normalized Deep Nets,[0],[0]
We assess the uncertainty quality of MCBN quantitatively and qualitatively.,4. Experiments and Results,[0],[0]
"Our quantitative analysis relies on CIFAR10 for image classification and eight standard regression datasets, listed in Appendix Table 1.",4. Experiments and Results,[0],[0]
"Publicly available from the UCI Machine Learning Repository (University of California, 2017) and Delve (Ghahramani, 1996), these datasets have been used to benchmark comparative models in recent related literature (see (Hernández-Lobato & Adams, 2015), (Gal & Ghahramani, 2015), (Bui et al., 2016) and (Li & Gal, 2017)).",4. Experiments and Results,[0],[0]
"We report results using standard metrics, and also propose useful upper and lower bounds to normalize these metrics for an easier interpretation in Section 4.2.
",4. Experiments and Results,[0],[0]
"Our qualitative results include the toy dataset in Figure 1 in the style of (Karpathy, 2015), a new visualization of uncertainty quality that plots test errors sorted by predicted variance (Figure 2 and Appendix), and image segmentation results (Figure 2 and Appendix).",4. Experiments and Results,[0],[0]
"We evaluate uncertainty quality based on two standard metrics, described below: Predictive Log Likelihood (PLL) and Continuous Ranked Probability Score (CRPS).",4.1. Metrics,[0],[0]
"To improve the interpretability of the metrics, we propose to normalize them by upper and lower bounds.
",4.1. Metrics,[0],[0]
Predictive Log Likelihood (PLL),4.1. Metrics,[0],[0]
"Predictive Log Likelihood is widely accepted as the main uncertainty quality metric for regression (Hernández-Lobato & Adams, 2015; Gal & Ghahramani, 2015; Bui et al., 2016; Li & Gal, 2017).",4.1. Metrics,[0],[0]
A key property of PLL is that it makes no assumptions about the form of the distribution.,4.1. Metrics,[0],[0]
"The measure is defined for a probabilistic model fω(x) and a single observation
we could sample from the implied qθ(ω) as modeled in the Appendix.",4.1. Metrics,[0],[0]
This would alleviate having to store D for use during prediction.,4.1. Metrics,[0],[0]
"In our experiments we used D to sample ω̂i however, and leave the evaluation of the modeled qθ(ω) for future research.
",4.1. Metrics,[0],[0]
"(yi,xi) as:
PLL(fω(x), (yi,xi))",4.1. Metrics,[0],[0]
"= log p(yi|fω(xi))
where p(yi|fω(xi))",4.1. Metrics,[0],[0]
"is the model’s predicted PDF evaluated at yi, given the input xi.",4.1. Metrics,[0],[0]
A more detailed description is given in the Appendix Section 1.5.,4.1. Metrics,[0],[0]
The metric is unbounded and maximized by a perfect prediction (mode at yi) with no variance.,4.1. Metrics,[0],[0]
"As the predictive mode moves away from yi, increasing the variance tends to increase PLL (by maximizing probability mass at yi).",4.1. Metrics,[0],[0]
"While PLL is an elegant measure, it has been criticized for allowing outliers to have an overly negative effect on the score (Selten, 1998).
",4.1. Metrics,[0],[0]
Continuous Ranked Probability Score (CRPS) Continuous Ranked Probability Score is a measure that takes the full predicted PDF into account with less sensitivity to outliers.,4.1. Metrics,[0],[0]
A prediction with low variance that is slightly offset from the true observation will receive a higher score form CRPS than PLL.,4.1. Metrics,[0],[0]
"In order for CRPS to be analytically tractable, we need to assume a Gaussian unimodal predictive distribution.",4.1. Metrics,[0],[0]
"CRPS is defined as
CRPS(fω(xi), (yi, xi))",4.1. Metrics,[0],[0]
= ∫ ∞ −∞,4.1. Metrics,[0],[0]
( F (y)− 1(y ≥ yi) ),4.1. Metrics,[0],[0]
"2 dy
where F (y) is the predictive CDF, and 1(y ≥ yi) = 1 if y ≥ yi and 0 otherwise (for univariate distributions) (Gneiting & Raftery, 2007).",4.1. Metrics,[0],[0]
CRPS is interpreted as the sum of the squared area between the CDF and 0 where y < yi and between the CDF and 1 where y ≥ yi.,4.1. Metrics,[0],[0]
A perfect prediction with no variance yields a CRPS of 0; for all other cases the value is larger.,4.1. Metrics,[0],[0]
CRPS has no upper bound.,4.1. Metrics,[0],[0]
It is difficult to interpret the quality of uncertainty from raw PLL and CRPS values.,4.2. Benchmark models and normalized metrics,[0],[0]
We propose to normalize the metrics between useful lower and upper bounds.,4.2. Benchmark models and normalized metrics,[0],[0]
The normalized measures estimate the performance of an uncertainty model between the trivial solution (constant uncertainty) and optimal uncertainty for each prediction.,4.2. Benchmark models and normalized metrics,[0],[0]
"For the lower bound, we define a baseline that predicts constant variance regardless of input.",4.2. Benchmark models and normalized metrics,[0],[0]
The variance is set to a fixed value that optimizes CRPS on validation data.,4.2. Benchmark models and normalized metrics,[0],[0]
We call this model Constant Uncertainty BN (CUBN).,4.2. Benchmark models and normalized metrics,[0],[0]
"It reflects our best guess of constant variance on test data – thus, any improvement in uncertainty quality over CUBN indicates a sensible estimate of uncertainty.",4.2. Benchmark models and normalized metrics,[0],[0]
"We similarly define a baseline for dropout, Constant Uncertainty Dropout (CUDO).",4.2. Benchmark models and normalized metrics,[0],[0]
"The modeling of variance (uncertainty) by MCBN and CUBN are visualized in Figure 1.
",4.2. Benchmark models and normalized metrics,[0],[0]
An upper bound on uncertainty performance can also be defined for a probabilistic model f with respect to CRPS or PLL.,4.2. Benchmark models and normalized metrics,[0],[0]
"For each observation (yi, xi), a value
for the predictive variance Ti can be chosen that maximizes PLL or minimizes CRPS10.",4.2. Benchmark models and normalized metrics,[0],[0]
"Using CUBN as a lower bound and the optimized CRPS score as the upper bound, uncertainty estimates can be normalized between these bounds (1 indicating optimal performance, and 0 indicating same performance as fixed uncertainty).",4.2. Benchmark models and normalized metrics,[0],[0]
"We call this normalized measure CRPS =
CRPS(f,(yi,xi))−CRPS(fCU ,(yi,xi)) minT CRPS(f,(yi,xi))−CRPS(fCU ,(yi,xi)) × 100, and the PLL analogue PLL = PLL(f,(yi,xi))−PLL(fCU ,(yi,xi))maxT PLL(f,(yi,xi))−PLL(fCU ,(yi,xi))×100.",4.2. Benchmark models and normalized metrics,[0],[0]
"Our evaluation compares MCBN to MCDO (Gal & Ghahramani, 2015) and MNF (Louizos & Welling, 2017) using the datasets and metrics described above.",4.3. Test setup,[0],[0]
"Our setup is similar to (Hernández-Lobato & Adams, 2015), which was also followed by (Gal & Ghahramani, 2015).",4.3. Test setup,[0],[0]
"However, our comparison implements a different hyperparameter selection, allows for a larger range of dropout rates, and uses larger networks with two hidden layers.
",4.3. Test setup,[0],[0]
"For the regression task, all models share a similar architecture: two hidden layers with 50 units each, and ReLU activations, with the exception of Protein Tertiary Structure dataset (100 units per hidden layer).",4.3. Test setup,[0],[0]
Inputs and outputs were normalized during training.,4.3. Test setup,[0],[0]
Results were averaged over five random splits of 20% test and 80% training and cross-validation (CV) data.,4.3. Test setup,[0],[0]
"For each split, 5-fold CV by grid search with a RMSE minimization objective was used to find training hyperparameters and optimal n.o. epochs, out of a maximum of 2000.",4.3. Test setup,[0],[0]
"For BN-based models, the hyperparameter grid consisted of a weight decay factor ranging from 0.1 to 1−15 by a log 10 scale, and a batch size range from 32 to 1024 by a log 2 scale.",4.3. Test setup,[0],[0]
"For DO-based models, the hyperparameter grid consisted of the same weight decay range, and dropout probabilities in {0.2, 0.1, 0.05, 0.01, 0.005, 0.001}.",4.3. Test setup,[0],[0]
DO-based models used a batch size of 32 in all evaluations.,4.3. Test setup,[0],[0]
"For MNF11, the n.o. epochs was optimized, the batch size was set to 100, and early stopping test performed each epoch (compared to every 20th for MCBN, MCDO).
",4.3. Test setup,[0],[0]
"For MCBN and MCDO, the model with optimal training hyperparameters was used to optimize τ numerically.",4.3. Test setup,[0],[0]
"This optimization was made in terms of average CV CRPS for MCBN, CUBN, MCDO, and CUDO respectively.
",4.3. Test setup,[0],[0]
Estimates for the predictive distribution were obtained by taking T = 500 stochastic forward passes through the network.,4.3. Test setup,[0],[0]
"For each split, test set evaluation was done 5 times with different seeds.",4.3. Test setup,[0],[0]
"Implementation was done in TensorFlow with the Adam optimizer and a learning rate of 0.001.
",4.3. Test setup,[0],[0]
"10Ti can be found analytically for PLL, but must be found numerically for CRPS.
",4.3. Test setup,[0],[0]
"11Where we used an adapted version of the authors’ code.
",4.3. Test setup,[0],[0]
"For the image classification test we use CIFAR10 (Krizhevsky & Hinton, 2009) which includes 10 object classes with 5,000 and 1,000 images in the training and test sets, respectively.",4.3. Test setup,[0],[0]
Images are 32x32 RGB format.,4.3. Test setup,[0],[0]
"We trained a ResNet32 architecture with a batch size of 32, learning rate of 0.1, weight decay of 0.0002, leaky ReLU slope of 0.1, and 5 residual units.",4.3. Test setup,[0],[0]
"SGD with momentum was used as the optimizer.
",4.3. Test setup,[0],[0]
Code for reproducing our experiments is available at https://github.com/icml-mcbn/mcbn.,4.3. Test setup,[0],[0]
The regression experiment comparing uncertainty quality is summarized in Table 1.,4.4. Test results,[0],[0]
"We report CRPS and PLL, expressed as a percentage, which reflects how close the model is to the upper bound, and check to see if the model significantly exceeds the lower bound using a one sample t-test (significance level is indicated by *’s).",4.4. Test results,[0],[0]
"Further details are provided in Appendix Section 1.7.
",4.4. Test results,[0],[0]
"In Figure 2 (left), we present a novel visualization of uncertainty quality for regression problems.",4.4. Test results,[0],[0]
Data are sorted by estimated uncertainty in the x-axis.,4.4. Test results,[0],[0]
"Grey dots show the errors in model predictions, and the shaded areas show the model uncertainty.",4.4. Test results,[0],[0]
A running mean of the errors appears as a gray line.,4.4. Test results,[0],[0]
"If uncertainty estimation is working well, a correlation should exist between the mean error (gray line) and uncertainty (shaded area).",4.4. Test results,[0],[0]
"This indicates that the uncertainty estimation recognizes samples with larger (or smaller) potential for predictive errors.
",4.4. Test results,[0],[0]
We applied MCBN on the image classification task of CIFAR10.,4.4. Test results,[0],[0]
The baseline in this case is the softmax distribution using the moving average for BN units.,4.4. Test results,[0],[0]
Log likelihood (PLL) is the metric used to compare with the baseline.,4.4. Test results,[0],[0]
"The baseline achieves a PLL of -0.32 on the test set, while MCBN obtains a PLL of -0.28.",4.4. Test results,[0],[0]
Table 2 shows the performance of MCBN when using different number of stochastic forward passes (the MCBN batchsize is fixed to the training batch size at 32).,4.4. Test results,[0],[0]
"PLL improves as the number of the stochastic passes increases, until it is significantly better than the softmax baseline.
",4.4. Test results,[0],[0]
"To demonstrate how model uncertainty can be obtained from an existing network with minimal effort, we applied MCBN to an image segmentation task using Bayesian SegNet with the main CamVid and PASCAL-VOC models in (Kendall et al., 2015).",4.4. Test results,[0],[0]
We simply ran multiple forward passes with different mini-batches randomly taken from the train set.,4.4. Test results,[0],[0]
The models obtained from the online model zoo have BN blocks after each layer.,4.4. Test results,[0],[0]
We recalculate mean and variance for the first 2 blocks only and use the training statistics for the rest of the blocks.,4.4. Test results,[0],[0]
"Mini-batches of size 10 and 36 were used for CamVid and VOC respectively
due to memory limits.",4.4. Test results,[0],[0]
"The results in Figure 2 (right) were obtained from 20 stochastic forward passes, showing high uncertainty near object boundaries.",4.4. Test results,[0],[0]
"The VOC results are more appealing because of larger mini-batches.
",4.4. Test results,[0],[0]
We provide additional experimental results in the Appendix.,4.4. Test results,[0],[0]
Appendix Tables 2 and 3 show the mean CRPS and PLL values from the regression experiment.,4.4. Test results,[0],[0]
Table 4 provides the raw CRPS and PLL scores.,4.4. Test results,[0],[0]
In Table 5 we provide RMSE results of the MCBN and MCDO networks in comparison with non-stochastic BN and DO networks.,4.4. Test results,[0],[0]
These results indicate that the procedure of multiple forward passes in MCBN and MCDO show slight improvements in the predictive accuracy compared to their nonBayesian counterparts.,4.4. Test results,[0],[0]
"In Tables 6 and 7, we investigate the effect of varying batch size while keeping other hyperparameters fixed.",4.4. Test results,[0],[0]
"We see that performance deteriorates with small batch sizes (≤16), a known issue of BN (Ioffe, 2017).",4.4. Test results,[0],[0]
"Similarly, results varying the number of stochastic forward passes T is reported in Tables 8 and 9.",4.4. Test results,[0],[0]
"While performance benefits from large T , in some cases T = 50 (i.e. 1/10 of T in the main evaluation) performs well.",4.4. Test results,[0],[0]
Uncertainty-error plots for all the datasets are provided in the Appendix.,4.4. Test results,[0],[0]
"The results presented in Tables 1-2 and Appendix Tables 2-9 indicate that MCBN generates meaningful uncertainty
estimates that correlate with actual errors in the model’s prediction.",5. Discussion,[0],[0]
"In Table 1, we show statistically significant improvements over CUBN in the majority of the datasets, both in terms of CRPS and PLL.",5. Discussion,[0],[0]
The visualizations in Figure 2 and in the Appendix Figures 2-3 show correlations between the estimated model uncertainty and errors of the network’s predictions.,5. Discussion,[0],[0]
"We perform the same experiments using MCDO and MNF, and find that MCBN generally performs on par with both methods.",5. Discussion,[0],[0]
"Looking closer, MCBN outperforms MCDO and MNF in more cases than not, measured by CRPS.",5. Discussion,[0],[0]
"However, care must be used.",5. Discussion,[0],[0]
"The learned parameters are different, leading to different predictive means and confounding direct comparison.
",5. Discussion,[0],[0]
The results on the Yacht Hydrodynamics dataset seem contradictory.,5. Discussion,[0],[0]
"The CRPS score for MCBN are extremely negative, while the PLL score is extremely positive.",5. Discussion,[0],[0]
The opposite trend is observed for MCDO.,5. Discussion,[0],[0]
"To add to the puzzle, the visualization in Figure 2 depicts an extremely promising uncertainty estimation that models the predictive errors with high fidelity.",5. Discussion,[0],[0]
"We hypothesize that this strange behavior is due to the small size of the data set, which only contains 60 test samples, or due to the Gaussian assumption of CRPS.",5. Discussion,[0],[0]
"There is also a large variability in the model’s accuracy on this dataset, which further confounds the measurements for such limited data.
",5. Discussion,[0],[0]
"One might criticize the overall quality of uncertainty estimates observed in all the models we tested, due to the magnitude of CRPS and PLL in Table 1.",5. Discussion,[0],[0]
The scores rarely exceed 10% improvement over the lower bound.,5. Discussion,[0],[0]
"However, we caution that these measures should be taken in context.",5. Discussion,[0],[0]
"The upper bound is very difficult to achieve in practice – it is optimized for each test sample individually – and the lower bound is a quite reasonable estimate.
",5. Discussion,[0],[0]
"The study of MCBN sensitivity to batch size revealed that a certain batch size is required for the best performance, dependent on the data.",5. Discussion,[0],[0]
"When doing inference on a GPU, large
batch sizes may cause memory issues for cases where the input is large and the network has a large number of parameters, as is common for state-of-the-art image classification networks.",5. Discussion,[0],[0]
"However, there are various workarounds to this problem.",5. Discussion,[0],[0]
"One can store BN statistics, instead of batches, to reduce memory issues.",5. Discussion,[0],[0]
"Furthermore, we can use the Gaussian estimate of the BN statistics as discussed previously, which makes memory and computation extremely efficient.",5. Discussion,[0],[0]
"In this work, we have shown that training a deep network using batch normalization is equivalent to approximate inference in Bayesian models.",6. Conclusion,[0],[0]
"We show evidence that the uncertainty estimates from MCBN correlate with actual errors in the model’s prediction, and are useful for practical
tasks such as regression, image classification, and image segmentation.",6. Conclusion,[0],[0]
"Our experiments show that MCBN yields a significant improvement over the optimized constant uncertainty baseline, on par with MCDO and MNF.",6. Conclusion,[0],[0]
"Our evaluation also suggests new normalized metrics based on useful upper and lower bounds, and a new visualization which provides an intuitive explanation of uncertainty quality.
",6. Conclusion,[0],[0]
"Finally, it should be noted that over the past few years, batch normalization has become an integral part of most – if not all – cutting edge deep networks.",6. Conclusion,[0],[0]
We have shown that it is possible to obtain meaningful uncertainty estimates from existing models without modifying the network or the training procedure.,6. Conclusion,[0],[0]
"With a few lines of code, robust uncertainty estimates can be obtained by computing the variance of multiple stochastic forward passes through an existing network.",6. Conclusion,[0],[0]
We show that training a deep network using batch normalization is equivalent to approximate inference in Bayesian models.,abstractText,[0],[0]
"We further demonstrate that this finding allows us to make meaningful estimates of the model uncertainty using conventional architectures, without modifications to the network or the training procedure.",abstractText,[0],[0]
Our approach is thoroughly validated by measuring the quality of uncertainty in a series of empirical experiments on different tasks.,abstractText,[0],[0]
"It outperforms baselines with strong statistical significance, and displays competitive performance with recent Bayesian approaches.",abstractText,[0],[0]
Bayesian Uncertainty Estimation for Batch Normalized Deep Networks,title,[0],[0]
"Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 64–74, Denver, Colorado, May 31 – June 5, 2015. c©2015 Association for Computational Linguistics",text,[0],[0]
"For the majority of the state-of-the-art parsers that routinely reach ninety percent performance plateau in capturing tree structures, the question of what next crucially arises.",1 Introduction,[0],[0]
"Indeed, it has long been thought that the bottleneck preventing the advent of accurate syntax-to-semantic interfaces lies in the quality of the preceding phase of analysis: the better the parse, the better the output.",1 Introduction,[0],[0]
"The truth is that most of the structures used to train current parsing models are degraded versions of a more informative data set: the Wall Street journal section of the Penn treebank (PTB, (Marcus et al., 1993)) which is often stripped of its richer set of annotations (i.e. traces and functional labels are removed), while, for reasons of efficiency and availability, projective dependency trees are often given preference over richer graph structures (Nivre and Nilsson, 2005; Sagae
and Tsujii, 2008).",1 Introduction,[0],[0]
"This led to the emergence of surface syntax-based parsers (Charniak, 2000; Nivre, 2003; Petrov et al., 2006) whose output cannot by themselves be used to extract full-fledged predicateargument structures.",1 Introduction,[0],[0]
"For example, control verb constructions, it-cleft structures, argument sharing in ellipsis coordination, etc. are among the phenomena requiring a graph to be properly accounted for.",1 Introduction,[0],[0]
The dichotomy between what can usually be parsed with high accuracy and what lies in the deeper syntactic description has initiated a line of research devoted to closing the gap between surface syntax and richer structures.,1 Introduction,[0],[0]
"For most of the previous decade, the term deep syntax was used for rich parsing models built upon enriched versions of a constituency treebank, either with added HPSG or LFG annotation or CCG (almost) full rewrites (Miyao and Tsujii, 2005; Cahill et al., 2004; Hockenmaier, 2003).",1 Introduction,[0],[0]
"Its use now spreads by misnomer to models that provide more abstract structures, capable of generalizing classical functional labels to more semantic (in a logical view) arguments, potentially capable of neutralizing diathesis distinctions and of providing accurate predicate-argument structures.",1 Introduction,[0],[0]
"Although the building of syntax-to-semantic interface seems inextricably linked to an efficient parsing stage, inspirational works on semantic role labelling (Toutanova et al., 2005) and more recently on broad coverage semantic parsing (Du et al., 2014) that provide stateof-the-art results without relying on surface syntax, lead us to question the usefulness of syntactic parses for predicate-argument structure parsing.
",1 Introduction,[0],[0]
"In this study, we investigate the impact of syntactic features on a transition-based graph parser by testing on two treebanks.",1 Introduction,[0],[0]
"We take advantage of the recent release for the SemEval 2014 shared task on semantic dependency parsing, by Oepen et
64
al. (2014) of two semantic-based treebanks, derived from two HPSG resources, the DeepBank (DM, (Flickinger et al., 2012)) and the Enju’s predicate argument structure (PAS, (Miyao and Tsujii, 2005)), to investigate the impact of syntactic features on a transition-based graph parser.",1 Introduction,[0],[0]
Our results show that surface syntactic features significantly improve the parsing of predicate-argument structures.,1 Introduction,[0],[0]
"More specifically, we show that adding syntactic context improves the recognition of long distance dependencies and elliptical constructions.",1 Introduction,[0],[0]
"We finally discuss the usefulness of our approach, when applied on a second-order model based on dual decomposition (Martins and Almeida, 2014), showing that our use of syntactic features enhances this model accuracy and provides state-of-the-art performance.",1 Introduction,[0],[0]
"DeepBank Corpus Semantic dependency graphs in the DM Corpus are the result of a two-step simplification of the underspecified logical-form meaning representations, based on Minimal Recursion Semantic (MRS, (Copestake et al., 1995; Copestake et al., 2005)), derived from the manually annotated DeepBank treebank (Flickinger et al., 2012).",2 Deep Syntax and Underspecified Semantic Corpora,[0],[0]
"First, Oepen and Lønning (2006) define a conversion from original MRS formulae to variable-free Elementary Dependency Structures (EDS), which (a) maps each predication in the MRS logical-form meaning representation to a node in a dependency graph and (b) transforms argument relations represented by shared logical variables into directed dependency links between graph nodes.",2 Deep Syntax and Underspecified Semantic Corpora,[0],[0]
"Then, in a second conversion step, the EDS graphs are further reduced into strict bi-lexical form, i.e. a set of directed, binary dependency relations holding exclusively between lexical units (Ivanova et al., 2012).",2 Deep Syntax and Underspecified Semantic Corpora,[0],[0]
"Even though both conversion steps are, by design, lossy, DM semantic dependency graphs present a true subset of the information encoded in the full, original MRS data set.
",2 Deep Syntax and Underspecified Semantic Corpora,[0],[0]
"Predicate-Argument Structure Corpus Enju Predicate-Argument Structures (PAS Corpus) are derived from the automatic HPSG-style annotation of the Penn Treebank (Miyao and Tsujii, 2004) that was primarily used for the development of the Enju parsing system (Miyao and Tsujii, 2005).",2 Deep Syntax and Underspecified Semantic Corpora,[0],[0]
"The
PAS data set is an extraction of predicate-argument structures from the Enju HPSG treebank and contains word-to-word semantic dependencies.",2 Deep Syntax and Underspecified Semantic Corpora,[0],[0]
"Each dependency type is made of two elements: a coarse part-of-speech of the head predicate dependent (e.g. verb and adjective), and the argument (e.g. ARG1 and ARG2).
",2 Deep Syntax and Underspecified Semantic Corpora,[0],[0]
"Although both are derived from HSPG resources (a hand-crafted grammar for DM, a treebank-based one for PAS), they differ in their core linguistic choices (functional heads vs lexical heads, coordination scheme, etc.) leading to different views of the predicate argument structure for the same sentence (Ivanova et al., 2012).",2 Deep Syntax and Underspecified Semantic Corpora,[0],[0]
"Thus, even though both corpora may appear to contain a similar number of dependency labels, as shown in Table 1, their annotation schemes depict a deeply divergent linguistic reality exposed by two very different distributions.",2 Deep Syntax and Underspecified Semantic Corpora,[0],[0]
"In DM, 9 labels account for almost 95% of all dependencies whereas a label set twice as large covers the same percentage for PAS, as shown in Table 2.",2 Deep Syntax and Underspecified Semantic Corpora,[0],[0]
"Furthermore, semantically empty elements are widespread in the DeepBank (around 21.5%), compared to a low rate of 4.3% in PAS.",2 Deep Syntax and Underspecified Semantic Corpora,[0],[0]
"In other words, the latter is somewhat more dense and consequently more syntactic.",2 Deep Syntax and Underspecified Semantic Corpora,[0],[0]
"This is due to the fact that PAS integrates markers for infinitives, auxiliaries, and most punctuation marks into its graphs, whereas DM considers them as semantically void.",2 Deep Syntax and Underspecified Semantic Corpora,[0],[0]
DM corpus is clearly heading toward more semantic analysis while the PAS corpus aims at providing a more abstract deep syntax analysis than regular surface syntax trees.,2 Deep Syntax and Underspecified Semantic Corpora,[0],[0]
Both treebanks are used in their bilexical dependency formats.,2 Deep Syntax and Underspecified Semantic Corpora,[0],[0]
"Shift-reduce transition-based parsers essentially rely on configurations formed of a stack and a buffer, with stack transitions used to move from a configuration to the next one, until reaching a final configuration.",3 Transition-based Graphs Parsing,[0],[0]
"Following Kübler et al. (2009), we define a configuration by c = (σ, β,A) where σ denotes a stack of words wi, β a buffer of words, and A a set of dependency arcs of the form (wi, r, wj), with wi the head, wj the dependent, and r a label in some set R. As shown in Figure 1, besides the usual shift and reduce transitions (lR & rR) of the arc-standard strategy, we introduced the new left and right attach (lA & rA) transitions for adding new dependencies (while keeping the dependent on the stack) and a pop0 transition to remove a word from the stack after attachment of its dependents.",3 Transition-based Graphs Parsing,[0],[0]
"All the transitions that add an edge must also satisfy the condition that the newly created edge does not introduce a cycle or
multiple edges between the same pair of nodes.",3 Transition-based Graphs Parsing,[0],[0]
"It is to be noted that the pop0 action may also be used to remove words with no heads.
",3 Transition-based Graphs Parsing,[0],[0]
"We base our work on the the DAG parser of Sagae and Tsujii (2008) (henceforth S&T) which we extended with the set of actions displayed above (Figure 1) to cope with partially connected planar graphs, and we gave it the ability to take advantage of an extended set of features.",3 Transition-based Graphs Parsing,[0],[0]
"Finally, for efficiency reasons (memory consumption and speed), we replaced the original Maxent model with an averaged structured perceptron (Freund and Schapire, 1999; Collins, 2002).",3 Transition-based Graphs Parsing,[0],[0]
We define Wordβi (resp.,4.1 Baseline Features,[0],[0]
Lemmaβi and POSβi) as the word (resp.,4.1 Baseline Features,[0],[0]
lemma and part-of-speech) at position i in the queue.,4.1 Baseline Features,[0],[0]
"The same goes for σi, which is the position i in the stack.",4.1 Baseline Features,[0],[0]
"Let di,j be the distance between Wordσi and Wordσj .",4.1 Baseline Features,[0],[0]
"We also define d′i,j , the distance between Wordβi and Wordσj .",4.1 Baseline Features,[0],[0]
"In addition, we define leftPOSσi (resp. leftLabelσi)",4.1 Baseline Features,[0],[0]
the part-of-speech (resp.,4.1 Baseline Features,[0],[0]
"the label if any) of the word immediately to the left of σi, and the same goes for rightPOSσi (resp.",4.1 Baseline Features,[0],[0]
rightLabelσi).,4.1 Baseline Features,[0],[0]
"Finally, a is the previous action predicted by the parser.",4.1 Baseline Features,[0],[0]
Table 3 lists our baseline features.,4.1 Baseline Features,[0],[0]
"Xσi, σj , σk means that we use Xσi, Xσj , Xσk as unigram features as well as bigram and trigram features.",4.1 Baseline Features,[0],[0]
"We combined the previous features with different types of syntactic features (constituents and dependencies), our intuition being that syntax and semantic are interdependent, and that syntactic features should therefore help predicate-argument parsing.",4.2 Syntactic Features,[0],[0]
"In fact, we considered that the low density of syntactic information (compared to regular dependency treebanks) would be counterbalanced by
adding more context.",4.2 Syntactic Features,[0],[0]
"We considered the following pieces of information in particular.
",4.2 Syntactic Features,[0],[0]
Constituent Tree Fragments These consist of fragments of syntactic trees predicted by the Petrov et al. (2006) parser in a 10-way jackknife setting.,4.2 Syntactic Features,[0],[0]
"They can be used as enhanced POS or as features.
",4.2 Syntactic Features,[0],[0]
Spinal Elementary Trees,4.2 Syntactic Features,[0],[0]
"A full set of parses was reconstructed from the tree fragments using a slightly tweaked version of the CONLL 2009 shared task processing tools (Hajič et al., 2009).",4.2 Syntactic Features,[0],[0]
"We then extracted a spine grammar (Seddah, 2010) using the head percolation table of the Bikel (2002) parser, slightly modified to avoid certain determiners being marked as heads in certain configurations.",4.2 Syntactic Features,[0],[0]
"The resulting spines were assigned in a deterministic way (red part in Figure 2).
",4.2 Syntactic Features,[0],[0]
"Predicted MATE Dependency Labels These consist of the dependency labels predicted by the MATE parser (Bohnet, 2010), trained on a Stanford surface dependency version of the Penn Treebank.",4.2 Syntactic Features,[0],[0]
We combined the labels with a distance δ =,4.2 Syntactic Features,[0],[0]
t − h where t is the token position and h the head position (brown labels and δ in Figure 2).,4.2 Syntactic Features,[0],[0]
"In addition, we expanded these features with the part-of-speech of the head of a given token (HPOS).",4.2 Syntactic Features,[0],[0]
"The idea is to evaluate the informativeness of more abstract syntactic features since a <LABEL,HPOS> pair can be seen as generalizing many constituent subtrees.
",4.2 Syntactic Features,[0],[0]
Constituent Head Paths.,4.2 Syntactic Features,[0],[0]
"Inspired by Björkelund et al. (2013), we used MATE dependencies to extract the shortest path between a token and its lexical head and included the path length w (in terms of traversed nodes) as a feature (blue part in Figure 2).",4.2 Syntactic Features,[0],[0]
The global idea is to use the phrase-based features to provide different kinds of syntactic context and the dependency-based features to provide generalisations over the functional label governing a token.,4.2 Syntactic Features,[0],[0]
"The spines are seen as deterministic supertags, bringing a vertical context.
",4.2 Syntactic Features,[0],[0]
"We report, in Table 4, the counts for each syntactic feature on each set.",4.2 Syntactic Features,[0],[0]
Experimental Setup Both DM and PAS treebanks consist of texts from the PTB and which were either automatically derived from the original annotations or annotated with a hand-crafted grammar (see above).,5 Experiments,[0],[0]
"We use them in their bi-lexical dependency format, aligned at the token level as provided by Oepen et al. (2014)1.",5 Experiments,[0],[0]
"The following split is used: sections 00-19 for training, 20 for the dev. set and 21 for test2.",5 Experiments,[0],[0]
"All predicted parses are evaluated against the gold standard with labeled precision, recall and f-measure metrics.
",5 Experiments,[0],[0]
"Results Our experiments are based on the evaluation of the combinations of the 4 main types of syntactic features described in section 4: tree fragments (BKY), predicted mate dependencies (BN) and their extension with POS heads (BN(HPOS)), spinal elementary trees (SPINES) and head paths (PATHS).
",5 Experiments,[0],[0]
The results are shown in Tables 5 and 6.,5 Experiments,[0],[0]
All improvements from the baseline are significant with a p-value p < 0.05.,5 Experiments,[0],[0]
"There was no significant difference of the same p value between our two best mod-
1This alignment entailed the removal of all unparsed sentences.
",5 Experiments,[0],[0]
"2We used the same unusual split as in (Oepen et al., 2014) to be able to conduct meaningful comparisons with others.
",5 Experiments,[0],[0]
els for each of the treebanks.,5 Experiments,[0],[0]
"3
As expected from the rapid overview of our datasets exposed earlier in section 2, the use of each single feature alone increases the performance over the baseline by 0.5 points for the BN feature in DM to 1.44 for PATHS, and by 1.10 for the SPINES to 1.85 for the PATHS features in PAS.",5 Experiments,[0],[0]
"Looking at the conjunction of two classes in the DM table, it seems that dependency-based features benefit from the extra context brought by constituents features, reaching an increase of 2.21 points for BKY+BN(HPOS).",5 Experiments,[0],[0]
"Interestingly, the maximum gain is brought by the addition of topologically different phrase-based features such as SPINES (+2.80, inherently vertical) or BKY (+2.76, often wider) to the previous best.",5 Experiments,[0],[0]
"Regarding PAS, similar trends can be observed, although the gains are more distributed.",5 Experiments,[0],[0]
"As opposed to DM where the conjunction of more features led to inferior results, here using a four-features class provides the second best improvement (ALL(HPOS) = BKY+BN(HPOS)+SPINES+PATHS), +2.82) while removing the SPINES slightly increases the score (+2.92).",5 Experiments,[0],[0]
"In fact, adding too many features to the model slightly degrades our scores, at least with regard to DM which has a larger label set than PAS.
Results show that syntactic information improves our parser performances.",5 Experiments,[0],[0]
"As each feature represents one unique piece of information, they benefit from being combined in order to provide more structural information.",5 Experiments,[0],[0]
"Following Mcdonald and Nivre (2007), we conducted an error analysis based on the two best models and the baseline for each corpus.",6 Results Analysis,[0],[0]
"As shown in section 5, syntactic features greatly improve semantic parsing.",6 Results Analysis,[0],[0]
"However, it is interesting to explore more precisely what kind of syntactic information boosts or penalizes our predictions.",6 Results Analysis,[0],[0]
"We consider, among other factors, the impact in terms of distance between the head and the dependent (edge length) and the labels.",6 Results Analysis,[0],[0]
"We also explore several linguistic phenomena well known to be difficult to recover.
",6 Results Analysis,[0],[0]
"3We tested the statistical significance between our best models and the baseline with the paired bootstrap test (BergKirkpatrick et al., 2012).",6 Results Analysis,[0],[0]
"In Figures 3(a) and 4(a), we detail the scores for the five most frequent labels.
",6.1 Breakdown by Labels,[0],[0]
"As observed in the charts, the scores are higher for the most frequent labels on both corpora, especially when dealing with verbal arguments.",6.1 Breakdown by Labels,[0],[0]
"There are also two interesting cases for DM: the predictions of _and_c and ARG3 edges show an improvement by at least 5 points (Figures 3(b) & 4(b)), showing that the recovery of coordination structures and the disambiguation of less frequent or more distant arguments is achieved by adding non-local features.",6.1 Breakdown by Labels,[0],[0]
Longer sentences are notoriously difficult to parse for most parsing models.,6.2 Length Factor,[0],[0]
"Figures 3(c) and 4(c) show the F1-measure of our models with respect to sentence length (in bins of size 10: 1-10, 11-20, etc.)",6.2 Length Factor,[0],[0]
"for the DM and PAS corpora.
",6.2 Length Factor,[0],[0]
It is worth noting that we greatly improve the scores for longer sentences.,6.2 Length Factor,[0],[0]
"The use of paths and of the output of a graph-based parser (Bohnet, 2010) favors the capture of complex dependencies and enhances the learning of these constructions for our local transition-based parser.",6.2 Length Factor,[0],[0]
"However, we also observe that the features are not able to completely stop the loss of F1-score for longer sentences.",6.2 Length Factor,[0],[0]
"The slopes of the curves in the different charts show the same trend: the longer the sentence, the lower the score.",6.2 Length Factor,[0],[0]
"We now center our analysis on long-distance dependencies (LDDs), by focusing our attention on edges length, i.e. the distance between two words linked by an edge.",6.3 Linguistic Factors,[0],[0]
"We will then concentrate on subject ellipsis, in a treatment of LDDs more similar to the linguistic definition of Cahill et al. (2004).
",6.3 Linguistic Factors,[0],[0]
Long-distance Dependencies (LDDs),6.3 Linguistic Factors,[0],[0]
"For many systems, LDDs are difficult to recover because they are generally under-represented in the training corpus and the constructions involved in LDDs often require deep linguistic knowledge to be recovered.",6.3 Linguistic Factors,[0],[0]
"In
Figure 7, we report the distribution of long-distance dependencies by bins of size 5 up to 40.",6.3 Linguistic Factors,[0],[0]
They only account for 15% of all the dependencies in both corpora.,6.3 Linguistic Factors,[0],[0]
The longest dependencies consist of the first and second arguments of the verb as well as coordination links.,6.3 Linguistic Factors,[0],[0]
"In the case of elided coordination structures, we have long-distance dependencies when two coordinated verbs share the same first or second argument, which explains the distribution of lengths.
BINS 5-10 11-15 16-20 21-25 26-40
DM 2907 734 329 141 92 PAS 3705 1007 408 175 127
Table 7: Number of LDDs edges (dev. set).
",6.3 Linguistic Factors,[0],[0]
"As outlined in Figures 3(d) and 4(d), we can see that without structural information such as spines, surfacic dependencies or paths, the longest dependencies have low F1-scores.",6.3 Linguistic Factors,[0],[0]
"When using these features, our models tend to perform better, with a gain of up to 25 points for high-dependency lengths (bins between 16-20 and 21-25).
",6.3 Linguistic Factors,[0],[0]
"In Table 8, we show the global improvement when considering edge lengths between 5 and 40.",6.3 Linguistic Factors,[0],[0]
"For both corpora, the improvement is the same (around 9 points), showing that structural information is the key to better predictions.",6.3 Linguistic Factors,[0],[0]
"Looking into this improvement more closely, we found that PATHS combined with BN tend to be crucial, whereas SPINES
may sometimes penalize the models.",6.3 Linguistic Factors,[0],[0]
"Even though, BN+SPINES+PATHS is the best model for DM, a spine is only a partial projection which lacks attachment information.",6.3 Linguistic Factors,[0],[0]
"Spines alone only therefore provide a local context and are unable to cope well with LDDs.
",6.3 Linguistic Factors,[0],[0]
Coordination Structures We now focus on structures with subject ellipsis.,6.3 Linguistic Factors,[0],[0]
"We extracted them by using a simple graph pattern, i.e. two verbs with a shared ARG1 and a coordination dependency.
",6.3 Linguistic Factors,[0],[0]
Our best models’ scores are displayed in Tables 9.,6.3 Linguistic Factors,[0],[0]
"Once again, our models improve the F1 score, but not in the same proportion.",6.3 Linguistic Factors,[0],[0]
DM considers the conjunction as a semantically empty word and attaches an edge _and_c between the two verbs to mark the coordination.,6.3 Linguistic Factors,[0],[0]
"Consequently this edge is more difficult to predict, because it is less informative, our baseline model relying on tokens, lemmas and POS.
",6.3 Linguistic Factors,[0],[0]
We note that the difference in the number of evaluated dependencies in both corpora comes from an annotation scheme divergence between PAS and DM regarding subject ellipsis.,6.3 Linguistic Factors,[0],[0]
"DM opts for coordinate structures with a chain of dependencies rooted at the first conjunct, the coordinating conjunctions being therefore semantically empty.",6.3 Linguistic Factors,[0],[0]
"In PAS, the final coordinating conjunction and each coordinating conjunction is a two-place predicate, taking left and right conjuncts as its arguments.
",6.3 Linguistic Factors,[0],[0]
"The gain of 6.30 points for DM (Table 9(a), resp.",6.3 Linguistic Factors,[0],[0]
"+3 for PAS) indicates that, when an annotation scheme is designed to have many semantically empty words, using syntactic information tends to enhance the parser accuracy.",6.3 Linguistic Factors,[0],[0]
"This gives a clear insight into what type of information is required to
parse semantic graphs: the greater the distance between the head and the dependent, the larger the context needed to disambiguate the attachments.",6.3 Linguistic Factors,[0],[0]
"PAS DM
Overlap +2.87 +2.67",6.4 Ruling out the Structural Factor Bias,[0],[0]
"Rest +2.70 +2.74 It may argued that the improvement we noticed could stem from a potentially strong overlap between surface trees and predicate-argument structures, both in terms of edges and labels.",6.4 Ruling out the Structural Factor Bias,[0],[0]
"In fact, the conversion from surfacic parses into predicate-argument structures requires a large amount of edges relabeling (for instance, when nsubj is relabeled to ARG1).",6.4 Ruling out the Structural Factor Bias,[0],[0]
We tested this hypothesis by computing the number of common edges between MATE predictions and DM and PAS.,6.4 Ruling out the Structural Factor Bias,[0],[0]
The overlap corresponds to about 22% of all edges in PAS and 27% in DM.,6.4 Ruling out the Structural Factor Bias,[0],[0]
"Although important, it does not represent the majority of dependencies in our corpora, because most of edges are not present in surface predictions.",6.4 Ruling out the Structural Factor Bias,[0],[0]
We evaluated the improvement of the overlap as well as for the rest.,6.4 Ruling out the Structural Factor Bias,[0],[0]
Results show that our best models perform roughly the same on both sets.,6.4 Ruling out the Structural Factor Bias,[0],[0]
"Interestingly, as opposed to PAS’s model, DM’s model performs better on the non-overlap part.",6.4 Ruling out the Structural Factor Bias,[0],[0]
"This suggests that the use of PTB-based features is somehow not optimal when applied on a none PTB-based treebank, such as DM which comes from a handcrafted grammar.",6.4 Ruling out the Structural Factor Bias,[0],[0]
"Our point was to prove that providing more syntactic context, in the form of phrased-based tree fragments and surface dependencies, helps transition-
based parsers to predict predicate-argument structures, especially for LDDs.",7 Discussion,[0],[0]
"Yet, compared to stateof-the-art systems, our results built on the S&T parser score lower than the top performers (Table 10).",7 Discussion,[0],[0]
"However, we are currently extending a more advanced lattice-aware transition-based parser (DSR) with beams (Villemonte De La Clergerie, 2013) that takes advantage of cutting-edge techniques (dynamic programming, averaged perceptron with early updates, etc. following (Goldberg et al., 2013; Huang et al., 2012)) 4, which proves effective by reaching the state-of-the-art on PAS, outperforming Thomson et al. (2014) and second to the model of Martins and Almeida (2014).",7 Discussion,[0],[0]
"5
The point here is that using the same syntactic features as our base system exhibits the same improvement over a now much stronger baseline.",7 Discussion,[0],[0]
"We can conjecture that the ambiguities added by the relative scarcity of the deep annotations is efficiently handled by a more complete exploration of the search space, made possible by beam optimization.
",7 Discussion,[0],[0]
"We can also wonder whether the lower improvement brought to DM parsing by the PTB-based syntactic features does not come from the fact that the DM corpus and the PTB have divergent annotation
4It uses a different set of transitions, notably pop actions instead of left and right reduce, and a swap that allow limited amount of non-planarity.",7 Discussion,[0],[0]
"Such a set raises issues with beams (several paths leading to a same item, final items reached with paths of various lengths, . . . ), overcome by adding a ’noop’ action only applied on final items to balance path lengths.
",7 Discussion,[0],[0]
"5Leaving aside the multiple (19) ensemble models of Du et al. (2014), because of the impracticability of the approach.
schemes.",7 Discussion,[0],[0]
"In that aspect, PTB syntactic features may add some noise to the learning process, because they give more weight to conflicting decisions that led to correct structures in one but not in the other scheme.
",7 Discussion,[0],[0]
"By using features which, to a certain extent, (i) extend the domain of locality available at a given node and (ii) generalize some structural and functional contexts otherwise unavailable, we tried to overcome the main issue of transition-based parsers: they remain local in the sense that they lack a global view of the whole sentence.
",7 Discussion,[0],[0]
"Impact Beyond Transition-based Parser Of course, it can be argued that improving over a somewhat weak baseline is of limited interest.",7 Discussion,[0],[0]
Our point was to investigate how the direct parsing of relatively sparse graph structures would benefit from the inclusion of more context via the use of topologically different syntactic pieces of information.,7 Discussion,[0],[0]
"However in that work, we mostly focused on transition based-parsing, which raises the question of the impact of our feature-set on a much more powerful and state-of-the-art model such as the TURBOSEMANTICPARSER developed by Martins and Almeida (2014).
",7 Discussion,[0],[0]
"To this end, we extended the T.PARSER so that it could cope with our syntactic features and studied the interaction of our best feature set with second order features (i.e. grand-parents and co-parents).",7 Discussion,[0],[0]
Results in Table 11 show that the gain brought by adding syntactic features (+2.14 on DM over the baseline) is higher than the sole use of second order ones (+1.09).,7 Discussion,[0],[0]
"Furthermore, the gain brought by
the second-order features is reduced by half when used jointly with our feature set (+1.09 vs +0.57 with them).",7 Discussion,[0],[0]
"However, although we could assess that the need of second order models is thus alleviated, the conjunction of both types of features still improves the parser performance by an overall gain of 1.62 points on DM (1.18 on PAS), suggesting that both feature sets contribute to different types of “structures”.",7 Discussion,[0],[0]
"In short, the use of syntactic features is also relevant with a strong baseline, as they provide a global view to graph-based models, establishing a new state-of-the-art on these corpora.
",7 Discussion,[0],[0]
"Baseline = arc-factored + siblings
Related Work A growing interest for semantic parsing has emerged over the past few years, with the availability of resources such as PropBank and NomBank (Palmer et al., 2005; Meyers et al., 2004) built on top of the Penn Treebank.",7 Discussion,[0],[0]
"The shallow semantic annotations they provide were among the targets of successful shared tasks on semantic role labeling (Surdeanu et al., 2008; Carreras and Màrquez, 2005).",7 Discussion,[0],[0]
"Actually, the conjoint use of such annotations with surface syntax dependencies bears some resemblance with predicate-argument structure parsing like we presented here.",7 Discussion,[0],[0]
"However, they diverge in that Propbank/Nombank annotations
do not form connected graphs by themselves, as they only cover argument identification and nominal predicates.",7 Discussion,[0],[0]
"The range of phenomena they describe is also limited, compared to a full predicate-argument analysis as provided by DM and PAS (Oepen et al., 2014).",7 Discussion,[0],[0]
"More importantly, as pointed out by Yi et al. (2007), being verb-specific, Propbank’s roles do not generalize well beyond the ARG0 argument (i.e. the subject/agent role) leading to inconsistencies.",7 Discussion,[0],[0]
"However, the advent of such semantic-based resources have ignited a fruitful line of research, of which the use of heterogeneous sources of information to boost parsing performance has been investigated over the past decade (Chen and Rambow, 2003; Tsuruoka et al., 2004) with a strong regain of interest raised by the work of Moschitti et al. (2008), Henderson et al. (2008), Sagae (2009).",7 Discussion,[0],[0]
We described the use and combination of several kinds of syntactic features to improve predicateargument parsing.,8 Conclusion,[0],[0]
"To do so, we tested our approach of injecting surface-syntax features by thoroughly evaluating their impact on one transitionbased graph parser, then validating on two more efficient parsers, over two deep syntax and semantic treebanks.",8 Conclusion,[0],[0]
"Results of the syntax-enhanced semantic parsers exhibit a constant improvement, regardless of the annotation scheme and the parser used.",8 Conclusion,[0],[0]
The question is now to establish whether will this be verified in other semantic data sets?,8 Conclusion,[0],[0]
"From the parsing of deep syntax treebanks a la Meaning Text Theory (Ballesteros et al., 2014), to Framenet semantic parsing (Das et al., 2014) or data-driven approaches closer to ours (Flanigan et al., 2014), it is difficult to know which models will predominate from this bubbling field and what kind of semantic data sets will benefit the most from syntax.",8 Conclusion,[0],[0]
We would like to thank Kenji Sagae and André F. T. Martins for making their parsers available and for kindly answering our questions.,Acknowledgements,[0],[0]
We also thank our anonymous reviewers for their comments.,Acknowledgements,[0],[0]
"This work was partly funded by the Program ""Investissements d’avenir"" managed by Agence Nationale de la Recherche ANR-10-LABX-0083 (Labex EFL).",Acknowledgements,[0],[0]
Parsing full-fledged predicate-argument structures in a deep syntax framework requires graphs to be predicted.,abstractText,[0],[0]
"Using the DeepBank (Flickinger et al., 2012) and the PredicateArgument Structure treebank (Miyao and Tsujii, 2005) as a test field, we show how transition-based parsers, extended to handle connected graphs, benefit from the use of topologically different syntactic features such as dependencies, tree fragments, spines or syntactic paths, bringing a much needed context to the parsing models, improving notably over long distance dependencies and elided coordinate structures.",abstractText,[0],[0]
"By confirming this positive impact on an accurate 2nd-order graphbased parser (Martins and Almeida, 2014), we establish a new state-of-the-art on these data sets.",abstractText,[0],[0]
Because Syntax Does Matter: Improving Predicate-Argument Structures Parsing with Syntactic Features,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 386–396 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics",text,[0],[0]
"Human reasoning is lazy and biased but it perfectly serves its purpose in the argumentative context (Mercier and Sperber, 2017).",1 Introduction,[0],[0]
"When challenged by genuine back-and-forth argumentation, humans do better in both generating and evaluating arguments (Mercier and Sperber, 2011).",1 Introduction,[0],[0]
"The dialogical perspective on argumentation has been reflected in argumentation theory prominently by the pragma-dialectic model of argumentation (van Eemeren and Grootendorst, 1992).",1 Introduction,[0],[0]
"Not only sketches this theory an ideal normative model of argumentation but also distinguishes the wrong argumentative moves, fallacies (van Eemeren and Grootendorst, 1987).",1 Introduction,[0],[0]
"Among the plethora of prototypical fallacies, notwithstanding the controversy of most taxonomies (Boudry et al., 2015), ad hominem argument is perhaps the most famous one.",1 Introduction,[0],[0]
"Arguing against the person is considered faulty, yet is prevalent in online and offline discourse.1
1According to ‘Godwin’s law’ known from the internet pop-culture (https://en.wikipedia.org/wiki/
Although the ad hominem fallacy has been known since Aristotle, surprisingly there are very few empirical works investigating its properties.",1 Introduction,[0],[0]
"While Sahlane (2012) analyzed ad hominem and other fallacies in several hundred newspaper editorials, others usually only rely on few examples, as observed by de Wijze (2002).",1 Introduction,[0],[0]
"As Macagno (2013) concludes, ad hominem arguments should be considered as multifaceted and complex strategies, involving not a simple argument, but several combined tactics.",1 Introduction,[0],[0]
"However, such research, to the best of our knowledge, does not exist.",1 Introduction,[0],[0]
"Very little is known not only about the feasibility of ad hominem theories in practical applications (the NLP perspective) but also about the dynamics and triggers of ad hominem (the theoretical counterpart).
",1 Introduction,[0],[0]
"This paper investigates the research gap at three levels of increasing discourse complexity: ad hominem in isolation, direct ad hominem without dialogical exchange, and ad hominem in large inter-personal discourse context.",1 Introduction,[0],[0]
We asked the following research questions.,1 Introduction,[0],[0]
"First, what qualitative and quantative properties do ad hominem arguments have in Web debates and how does that reflect the common theoretical view (RQ1)?",1 Introduction,[0],[0]
"Second, how much of the debate context do we need for recognizing ad hominem by humans and machine learning systems (RQ2)?",1 Introduction,[0],[0]
"And finally, what are the actual triggers of ad hominem arguments and can we predict whether the discussion is going to end up with one (RQ3)?
",1 Introduction,[0],[0]
"We tackle these questions by leveraging Webbased argumentation data (Change my View on Reddit), performing several large-scale annotation studies, and creating a new dataset.",1 Introduction,[0],[0]
"We experiment with various neural architectures and ex-
Godwin’s_law), if a discussion goes on long enough, sooner or later someone will compare someone or something to Adolf Hitler.
386
trapolate the trained models to validate our working hypotheses.",1 Introduction,[0],[0]
"Furthermore, we propose a list of potential linguistic and rhetorical triggers of ad hominem based on interpreting parameters of trained neural models.2",1 Introduction,[0],[0]
This article thus presents the first NLP work on multi-faceted ad hominem fallacies in genuine dialogical argumentation.,1 Introduction,[0],[0]
We also release the data and the source code to the research community.3,1 Introduction,[0],[0]
"The prevalent view on argumentation emphasizes its pragmatic goals, such as persuasion and groupbased deliberation (van Eemeren et al., 2014), although numerous works have dealt with argument as product, that is, treating a single argument and its properties in isolation (Toulmin, 1958; Habernal and Gurevych, 2017).",2 Theoretical background and related work,[0],[0]
"Yet the social role of argumentation and its alleged responsibility for the very skill of human reasoning explained from the evolutionary perspective (Mercier and Sperber, 2017) provide convincing reasons to treat argumentation as an inherently dialogical tool.
",2 Theoretical background and related work,[0],[0]
"The observation that some arguments are in fact ‘deceptions in disguise’ was made already by Aristotle (Aristotle and Kennedy (translator), 1991), for which the term fallacy has been adopted.",2 Theoretical background and related work,[0],[0]
"Leaving the controversial typology of fallacies aside (Hamblin, 1970; van Eemeren and Grootendorst, 1987; Boudry et al., 2015), the ad hominem argument is addressed in most theories.",2 Theoretical background and related work,[0],[0]
"Ad hominem argumentation relies on the strategy of attacking the opponent and some feature of the opponent’s character instead of the counterarguments (Tindale, 2007).",2 Theoretical background and related work,[0],[0]
"With few exceptions, the following five sub-types of ad hominem are prevalent in the literature: abusive ad hominem (a pure attack on the character of the opponent), tu quoque ad hominem (essentially analogous to the “He did it first” defense of a three-year-old in a sandbox), circumstantial ad hominem (the “practice what you preach” attack and accusation of hypocrisy), bias ad hominem (the attacked opponent has a hidden agenda), and guilt by association (associating the opponent with somebody with a low credibility) (Schiappa and Nordin,
2An attempt to address the plea for thinking about problems, cognitive science, and the details of human language (Manning, 2015).
",2 Theoretical background and related work,[0],[0]
"3https://github.com/UKPLab/ naacl2018-before-name-calling-habernal-et-al
2013; Macagno, 2013; Walton, 2007; Hansen, 2017; Woods, 2008).",2 Theoretical background and related work,[0],[0]
"We omit examples here as these provided in theoretical works or textbooks are usually artificial, as already criticized by (de Wijze, 2002) or (Boudry et al., 2015).
",2 Theoretical background and related work,[0],[0]
"The topic of fallacies, which might be considered as sub-topic of argumentation quality, has recently been investigated also in the NLP field.",2 Theoretical background and related work,[0],[0]
"Existing works are, however, limited to the monological view (Wachsmuth et al., 2017; Habernal and Gurevych, 2016b,a; Stab and Gurevych, 2017) or they focus primarily on learning fallacy recognition by humans (Habernal et al., 2017, 2018a).",2 Theoretical background and related work,[0],[0]
Another related NLP sub-field includes abusive language and personal attacks in general.,2 Theoretical background and related work,[0],[0]
Wulczyn et al. (2017) investigated whether or not Wikipedia talk page comments are personal attacks and annotated 38k instances resulting in a highly skewed distribution (only 0.9% were actual attacks).,2 Theoretical background and related work,[0],[0]
"Regarding the participants’ perspective, Jain et al. (2014) examined principal roles in 80 discussions from the Wikipedia:",2 Theoretical background and related work,[0],[0]
"Article for Deletion pages (focusing on stubbornness or ignoredness, among others) and found several typical roles, including ‘rebels’, ‘voices’, or ‘idiots’.",2 Theoretical background and related work,[0],[0]
"In contrast to our data under investigation (Change My View debates), Wikipedia talk pages do not adhere to strict argumentation rules with manual moderation and have a different pragmatic purpose.
",2 Theoretical background and related work,[0],[0]
Reddit as a source platform has also been used in other relevant works.,2 Theoretical background and related work,[0],[0]
Saleem et al. (2016) detected hateful speech on Reddit by exploiting particular sub-communities to automatically obtain training data.,2 Theoretical background and related work,[0],[0]
Wang et al. (2016) experimented with an unsupervised neural model to cluster social roles on sub-reddits dedicated to computer games.,2 Theoretical background and related work,[0],[0]
Zhang et al. (2017) proposed a set of nine comment-level dialogue act categories and annotated 9k threads with 100k comments and built a CRF classifier for dialogue act labeling.,2 Theoretical background and related work,[0],[0]
"Unlike these works which were not related to argumentation, Tan et al. (2016) examined persuasion strategies on Change My View using word overlap features.",2 Theoretical background and related work,[0],[0]
"In contrast to our work, they focused solely on the successful strategies with delta-awarded posts.",2 Theoretical background and related work,[0],[0]
"Using the same dataset, Musi (2017) recently studied concession in argumentation.",2 Theoretical background and related work,[0],[0]
"Change My View (CMV) is an online ‘place to post an opinion you accept [...] in an effort to un-
derstand other perspectives on the issue’, in other words an online platform for ‘good-faith’ argumentation hosted on Reddit.4 A user posts a submission (also called original post(er); OP) and other participants provide arguments to change the OP’s view, forming a typical tree-form Web discussion.",3 Data,[0],[0]
A special feature of CMV is that the OP acknowledges convincing arguments by giving a delta point (∆).,3 Data,[0],[0]
"Unlike the vast majority of internet discussion forums, CMV enforces obeying strict rules (such as no ‘low effort’ posts, or accusing of being unwilling to change view) whose violation results into deleting the comment by moderators.",3 Data,[0],[0]
"These formal requirements of an ideal debate with the notion of violating rules correspond to incorrect moves in critical discussion in the normative pragma-dialectic theory (van Eemeren and Grootendorst, 1987).",3 Data,[0],[0]
"Thus, violating the rule of ‘not being rude or hostile’ is equivalent to committing ad hominem fallacy.",3 Data,[0],[0]
"For our experiments, we scraped, in cooperation with Reddit, the complete CMV including the content of the deleted comments so we could fully reconstruct the fallacious discussions, relying on the rule violation labels provided by the moderators.",3 Data,[0],[0]
"The dataset contains ≈ 2M posts in 32k submissions, forming 780k unique threads.
",3 Data,[0],[0]
We will set up the stage for further experiments by providing several quantitative statistics we performed on the dataset.,3 Data,[0],[0]
Only 0.2% posts in CMV are ad hominem arguments.,3 Data,[0],[0]
This contrasts with a typical online discussion: Coe et al. (2014) found 19.5% of comments under online news articles to be incivil.,3 Data,[0],[0]
"Most threads contain only a single ad hominem argument (3,396 threads; there are 3,866 ad hominem arguments in total in CMV); only 35 threads contain more than three ad hominem arguments.",3 Data,[0],[0]
"In 48.6% of threads containing a single ad hominem, the ad hominem argument is the very last comment.",3 Data,[0],[0]
"This corresponds to the popular belief that if one is out of arguments, they start attacking and the discussion is over.",3 Data,[0],[0]
This trend is also shown in Figure 1 which displays the relative position of the first ad hominem argument in a thread.,3 Data,[0],[0]
"Replying to ad hominem with another ad hominem happens only in 15% of the cases; this speaks for the attempts of CMV participants to keep up with the standards of a rather rational discussion.
",3 Data,[0],[0]
"Regarding ad hominem authors, about 66% of
4https://www.reddit.com/r/changemyview/
them start attacking ‘out of blue’, without any previous interaction in the thread.",3 Data,[0],[0]
"On the other hand, 11% ad hominem authors write at least one ‘normal’ argument in the thread (we found one outlier who committed ad hominem after writing 57 normal arguments in the thread).",3 Data,[0],[0]
"Only in 20% cases, the ad hominem thread is an interplay between the original poster and another participant.",3 Data,[0],[0]
It means that there are usually more people involved in an ad hominem thread.,3 Data,[0],[0]
"Unfortunately, sometimes the OP herself also commits ad hominem (12%).
",3 Data,[0],[0]
We also investigated the relation between the presence of ad hominem arguments and the submission topic.,3 Data,[0],[0]
"While most submissions are accompanied by only one or two ad hominem arguments (75% of submissions), there are also extremes with over 50 ad hominem arguments.",3 Data,[0],[0]
"Manual analysis revealed that these extremes deal with religion, sexuality/gender, U.S. politics (mostly Trump), racism in the U.S., and veganism.",3 Data,[0],[0]
We will elaborate on that later in Section 4.2.,3 Data,[0],[0]
The experimental part is divided into three parts according to the increasing level of discourse complexity.,4 Experiments,[0],[0]
"We first experiment with ad hominem in isolation in section 4.1, then with direct ad hominem replies to original posts without dialogical exchange in section 4.2, and finally with ad hominem in a larger inter-personal discourse context in section 4.3.",4 Experiments,[0],[0]
The first experimental set-up examines ad hominem arguments in Change my view regardless of its dialogical context.,4.1 Ad hominem without context in CMV,[0],[0]
Ad hominem arguments labeled by the CMV moderators come with no warranty.,4.1.1 Data verification,[0],[0]
"To verify their reliability, we conducted the following annotation studies.",4.1.1 Data verification,[0],[0]
"First, we needed to estimate parameters of crowdsourcing and its reliability.",4.1.1 Data verification,[0],[0]
"We sampled 100 random arguments from CMV without context: positive candidates were the reported ad hominem arguments, whereas negative candidates were sampled from comments that either violate other argumentation rules or have a delta label.",4.1.1 Data verification,[0],[0]
"To ensure the maximal content similarity of these two groups, for each positive instance the semantically closest negative instance was selected.5 We then experimented with different numbers of Amazon Mechanical Turk workers and various thresholds of the MACE gold label estimator (Hovy et al., 2013); comparing two groups of six workers each and 0.9 threshold yielded almost perfect interannotator agreement (0.79 Cohen’s κ).",4.1.1 Data verification,[0],[0]
"We then used this setting (six workers, 0.9 MACE threshold) to annotate another 452 random arguments sampled in the same way as above.
",4.1.1 Data verification,[0],[0]
Crowdsourced ‘gold’ labels were then compared to the original CMV labels (balanced binary task: positive instances (ad hominem) and negative instances) reaching accuracy of 0.878.,4.1.1 Data verification,[0],[0]
This means that the ad hominem labels from CMV moderators are quite reliable.,4.1.1 Data verification,[0],[0]
Manual error analysis of disagreements revealed 11 missing ad hominem labels.,4.1.1 Data verification,[0],[0]
These were not spotted by the moderators but were annotated as such by crowd workers.,4.1.1 Data verification,[0],[0]
"We sampled a larger balanced set of positive instances (ad hominem) and negative instances using the same methodology as in section 4.1.1, resulting in 7,242 instances, and casted the task of recognition of ad hominem arguments as a binary supervised task.",4.1.2 Recognizing ad hominem arguments,[0],[0]
"We trained two neural classifiers, namely a 2-stacked bi-directional LSTM network (Graves and Schmidhuber, 2005), and a convolutional network (Kim, 2014), and evaluated them using 10-fold cross validation.",4.1.2 Recognizing ad hominem arguments,[0],[0]
"Throughout the paper we use pre-trained word2vec word embeddings (Mikolov et al., 2013).",4.1.2 Recognizing ad hominem arguments,[0],[0]
"Detailed hyperpa-
5Similarity was computed using a cosine similarity of average embedding vectors multiplied by the argument length difference to minimize length-related artifacts.",4.1.2 Recognizing ad hominem arguments,[0],[0]
"The sample was balanced with roughly 50% positive and 50% negative instances.
",4.1.2 Recognizing ad hominem arguments,[0],[0]
rameters are described in the source codes (link provided in section 1).,4.1.2 Recognizing ad hominem arguments,[0],[0]
"As results in Table 1 show, the task of recognizing ad hominem arguments is feasible and almost achieves the human upper bound performance.",4.1.2 Recognizing ad hominem arguments,[0],[0]
"While binary classification of ad hominem as presented above might be sufficient for the purpose of red-flagging arguments, theories provide us with a much finer granularity (recall the typology in section 2).",4.1.3 Typology of ad hominem,[0],[0]
"To validate whether this typology is empirically relevant, we executed an annotation experiment to classify ad hominem arguments into the provided five types (plus ‘other’ if none applies).",4.1.3 Typology of ad hominem,[0],[0]
We sampled 200 ad hominem arguments from threads in which interlocution happens only between two persons and which end up with ad hominem.,4.1.3 Typology of ad hominem,[0],[0]
The Mechanical Turk workers were shown this last ad hominem argument as well as the preceding one.,4.1.3 Typology of ad hominem,[0],[0]
Each instance was annotated by 16 workers to achieve a stable distribution of labels as suggested by Aroyo and Welty (2015).,4.1.3 Typology of ad hominem,[0],[0]
"While 41% arguments were categorized as abusive, other categories (tu quoque, circumstantial, and guilt by association) were found to be rather ambiguous with very subtle differences.",4.1.3 Typology of ad hominem,[0],[0]
"In particular, we observed a very low percentage agreement on these categories and a label distribution spiked around two or more categories.",4.1.3 Typology of ad hominem,[0],[0]
After a manual inspection we concluded that (1) the theoretical typology does not account for longer ad hominem arguments that mix up different attacks and that (2) there are actual phenomena in ad hominem arguments not covered by theoretical categories.,4.1.3 Typology of ad hominem,[0],[0]
"These observations reflect those of Macagno (2013, p. 399) about ad hominem moves as multifaceted strategies.
",4.1.3 Typology of ad hominem,[0],[0]
We thus propose a list of phenomena typical to ad hominem arguments in CMV based on our empirical study.,4.1.3 Typology of ad hominem,[0],[0]
"For this purpose, we follow up with another annotation experiment on 400 arguments, with seven workers per instance.6 The goal was
6Here we decided on seven workers per item by relying on other span annotation experiments done in a similar setup (Habernal et al., 2018b).
to annotate a text span which made the argument an ad hominem; a single argument could contain several spans.",4.1.3 Typology of ad hominem,[0],[0]
We estimated the gold spans using MACE and performed a manual post-analysis by designing a typology of causes of ad hominem together with their frequency of occurrence.,4.1.3 Typology of ad hominem,[0],[0]
The results and examples are summarized in Table 2.,4.1.3 Typology of ad hominem,[0],[0]
The data verification annotation study (section 4.1.1) has two direct consequences.,4.1.4 Results and interpretation,[0],[0]
"First, the high κ score (0.79) answers RQ2: for recognizing ad hominem argument, no previous context is necessary.",4.1.4 Results and interpretation,[0],[0]
"Second, we still found 5% overlooked ad hominem arguments in CMV thus a moderationfacilitating tool might come handy; this can be served by the well-performing CNN model (0.810 accuracy; section 4.1.2).
",4.1.4 Results and interpretation,[0],[0]
"The existing theoretical typology of ad hominem arguments, as presented for example in most textbooks, provides only a very simplified view.",4.1.4 Results and interpretation,[0],[0]
"On the one hand, some of the categories which we found in the empirical labeling study (section 4.1.3) do map to their corresponding counterparts (such as the vulgar insults).",4.1.4 Results and interpretation,[0],[0]
"On the other hand, some ad hominem insults typical to online argumentation (illiteracy insults, condescension) are not present in studies on ad hominem.",4.1.4 Results and interpretation,[0],[0]
"Hence, we claim that any potential typology of ad hominem arguments should be multinomial rather than categorical, as we found multiple different spans in a single argument.",4.1.4 Results and interpretation,[0],[0]
"In the following section, we increase the complexity of the studied discourse by taking the original post into account.",4.2 Triggers of first level ad hominem,[0],[0]
We already showed that ad hominem arguments are usually preceded by a discussion between the interlocutors.,4.2.1 Annotation study,[0],[0]
"However, 897 submissions (original posts; OPs) have at least one intermediate ad hominem (in other words, the original post is directly attacked).",4.2.1 Annotation study,[0],[0]
We were thus interested in what triggers these first-level ad hominem arguments.,4.2.1 Annotation study,[0],[0]
"We hypothesize two causes: (1) the controversy of the OP, similarly to some related works on news comments (Coe et al., 2014) and (2) the reasonableness of the OP (whether the topic is reasonable to argue about).",4.2.1 Annotation study,[0],[0]
"We model both features on a three-point scale, namely controversy: 1 = ‘not re-
ally controversial’, 2 = ‘somehow controversial’, 3 = ‘very controversial’ and reasonableness: 1 = ‘quite stupid’, 2 = ‘neutral’, 3 = ‘quite reasonable’.7
We sampled two groups of OPs: those which had some ad hominem arguments in any of its threads but no delta (ad hominem group) and those without ad hominem but some deltas (Delta group).",4.2.1 Annotation study,[0],[0]
"In total, 1,800 balanced instances were annotated by five workers and the resulting value was averaged for each item.8
Statistical analysis of the annotated 1,800 OPs revealed that ad hominem arguments are associated with more controversial OPs (mean controversy 1.23) while delta-awarded arguments with less controversial OPs (mean controversy 1.06; K-S test;9 statistics 0.13, P-value: 7.97× 10−7).",4.2.1 Annotation study,[0],[0]
"On the other hand, reasonableness does not seem to play such a role.",4.2.1 Annotation study,[0],[0]
"The difference between ad hominem in reasonable OPs (mean 1.20) and delta in reasonable OPs (mean 1.11) is not that statistically strong; (K-S test statistics: 0.07, P-value: 0.02).",4.2.1 Annotation study,[0],[0]
We further built a regression model for predicting controversy and reasonableness of the OPs.,4.2.2 Regression model for predicting controversy and reasonableness,[0],[0]
Along with Bi-LSTM and CNN networks (same models as in 4.1.2) we also developed a neural model that integrates CNN with topic distribution (CNN+LDA).,4.2.2 Regression model for predicting controversy and reasonableness,[0],[0]
The motivation for a topicincorporating model was based on our earlier observations presented in section 3.,4.2.2 Regression model for predicting controversy and reasonableness,[0],[0]
"In particular, we trained an LDA topic model (k = 50) (Blei et al., 2003) on the heldout OPs and during training/testing, we merged the estimated topic distribution vector with the output layer after convolution and pooling.",4.2.2 Regression model for predicting controversy and reasonableness,[0],[0]
"We performed 10-fold cross validation on the 1,800 annotated OPs and got reasonable performance for controversy prediction (ρ
7Examples of not really controversial: ”I Don’t Think Monty",4.2.2 Regression model for predicting controversy and reasonableness,[0],[0]
"Python is Funny”, very controversial: ”Blacks are generally intellectual inferior to the other major races”, quite stupid: ”Burritos are better than sandwiches”, and quite reasonable: ”Nations whose leadership is based upon religion are fundamentally backwards”.
",4.2.2 Regression model for predicting controversy and reasonableness,[0],[0]
"8A pilot crowd sourcing annotation with 5 + 5 workers showed a fair reliability for controversy (Spearman’s ρ 0.804) and medium reliability for reasonableness (Spearman’s ρ 0.646).
",4.2.2 Regression model for predicting controversy and reasonableness,[0],[0]
"9Kolmogorov-Smirnov (K-S) test is a non-parametric test without any assumptions about the underlying probability distribution.
0.569) and medium performance for reasonableness prediction (ρ 0.385), respectively; both using the CNN+LDA model (see Table 3).
",4.2.2 Regression model for predicting controversy and reasonableness,[0],[0]
"We then used the trained model and extrapolated on all held-out OPs (1,267 ad hominem and 10,861 delta OPs, respectively).",4.2.2 Regression model for predicting controversy and reasonableness,[0],[0]
"The analysis again showed that ad hominem arguments tend to be found under more controversial OPs whereas delta arguments in the less controversial ones (KS test statistics: 0.14, P-value: 1 × 10−18).",4.2.2 Regression model for predicting controversy and reasonableness,[0],[0]
"For reasonableness, the rather low performance of the predictor does not allow us draw any conclusions on the extrapolated data.",4.2.2 Regression model for predicting controversy and reasonableness,[0],[0]
Controversy of the original post is immediately heating up the debate participants and correlates with a higher number of direct ad hominem responses.,4.2.3 Results and interpretation,[0],[0]
"This corresponds to observations made in comments in newswire where ‘weightier’ topics tended to stir incivility (Coe et al., 2014).",4.2.3 Results and interpretation,[0],[0]
"On the other hand, ‘stupidity’ (or ‘reasonableness’) does not seem to play any significant role.",4.2.3 Results and interpretation,[0],[0]
The CNN+LDA model for predicting controversy (ρ 0.569) might come handy for signaling potentially ‘heated’ discussions.,4.2.3 Results and interpretation,[0],[0]
"In this section, we focus on the dialogical aspect of CMV debates and dynamics of ad hominem fallacies.",4.3 Before calling names,[0],[0]
"Although ad hominem arguments appear in many forms (Section 4.1.3), we treat all ad hominem arguments equal in the following experiments.",4.3 Before calling names,[0],[0]
"So far we explored what makes an ad hominem argument and whether debated topic influences the
number of intermediate attacks.",4.3.1 Data sampling,[0],[0]
"However, possible causes of the argumentative dynamics that ends up with an ad hominem argument remain an open question, which has been addressed in neither argumentation theory nor in cognitive psychology, to the best of our knowledge.",4.3.1 Data sampling,[0],[0]
"We thus cast an explanation of triggers and dynamics of ad hominem discussions as a supervised machine learning problem and draw theoretical insights by a retrospective interpretation of the learned models.
",4.3.1 Data sampling,[0],[0]
We sample positive instances by taking three contextual arguments preceding the ad hominem argument from threads which are an interplay between two persons.,4.3.1 Data sampling,[0],[0]
Negative samples are drawn similarly from threads in which the argument is awarded with ∆ as shown in Figure 2.10 Each instance consists of the three concatenated arguments delimited by a special OOV token.,4.3.1 Data sampling,[0],[0]
"This resulted in 2,582 balanced training instances.",4.3.1 Data sampling,[0],[0]
"The alleged lack of interpretability of neural networks has motivated several lines of approaches, such as layer-wise relevance propagation (Arras et al., 2017) or representation erasure (Li et al., 2016), both on sentiment analysis.",4.3.2 Neural models,[0],[0]
"As our task at hand deals with multi-party discourse that presumably involves temporal relations important for the learned representation, we opted for a state-of-theart self-attentive LSTM model.",4.3.2 Neural models,[0],[0]
"In particular, we re-implemented the Structured Self-Attentive Embedding Neural Network (SSAE-NN) (Lin et al., 2017) which learns an embedding matrix representation of the input using attention weights.",4.3.2 Neural models,[0],[0]
"To make the attention even more interpretable, we replaced the final non-linear MLP layers with a single linear classifier (softmax).",4.3.2 Neural models,[0],[0]
"By summing over one dimension of the attention embedding matrix, each word from the input sequence gets associated
10To ensure as much content similarity as possible, we used the same similarity sampling as in section 4.1.1.
with a single attention weight that gives us insights into the classifier’s ‘features’ (still indirectly, as the true representation is a matrix; see the original paper).11 The learning objective is to recognize whether the thread ends up in an ad hominem argument or a delta point.",4.3.2 Neural models,[0],[0]
"We trained the model in 10-fold cross-validation and although our goal is not to achieve the best performance but rather to gain insight, we also tested a CNN model (accuracy 0.7095) which performed slightly worse than the SSAE-NN model (accuracy 0.7208).",4.3.2 Neural models,[0],[0]
"During testing the model, we projected attention weights to the original texts as heat maps and manually analyzed 191 true positives (ad hominem threads recognized correctly), as well as 77 false positives (ad hominem threads misclassified as delta) and 84 false negatives (delta as ad hominem), in total about 120k tokens.",4.3.3 Results and interpretation,[0],[0]
"The full output is available in the supplementary materials, we use IDs as a reference in the following text.
",4.3.3 Results and interpretation,[0],[0]
"In the following analysis, we solely relied on the weights of words or phrases learned by the attention model, see an example in Figure 3.",4.3.3 Results and interpretation,[0],[0]
"Based on our observations, we summarize several linguistic and argumentative phenomena with examples most likely responsible for ad hominem threads in Table 4.
",4.3.3 Results and interpretation,[0],[0]
The identified phenomena have few interesting properties in common.,4.3.3 Results and interpretation,[0],[0]
"First, they all are topic-independent rhetorical devices (except for the loaded keywords at the bottom).",4.3.3 Results and interpretation,[0],[0]
"Second, many of them deal with meta-level argumentation, i.e., arguing about argumentation (such as missing support or fallacy accusations).",4.3.3 Results and interpretation,[0],[0]
"Third, most of them do not contain profanity (in contrast to the actual ad hominem arguments of which a third are vulgar insults; cf. Table 2).",4.3.3 Results and interpretation,[0],[0]
"And finally, all of them should be easy to avoid.
",4.3.3 Results and interpretation,[0],[0]
"Misleading ‘features’ False positives revealed properties that misled the network to classify delta threads as ad hominem threads.
",4.3.3 Results and interpretation,[0],[0]
"• These include topic words (such as racism, blacks, slave, abortion) which reflects the implicit bias in the data.
",4.3.3 Results and interpretation,[0],[0]
"• Actual interest mixed with indifference in 11We also experimented with regularizing the attention matrix as the authors proposed, but it resulted in worse performance.
",4.3.3 Results and interpretation,[0],[0]
"sarcasm is also problematic (185(-2) “That’s a very interesting ...”).
",4.3.3 Results and interpretation,[0],[0]
"• Another problematic phenomena is also expressed disagreement (678(-2) “overheated rhetoric”, 203(-2)",4.3.3 Results and interpretation,[0],[0]
"“But I suppose this argument is ...”, 230(-2)",4.3.3 Results and interpretation,[0],[0]
"“But I don’t think it’s quite ...”, 938(-1)",4.3.3 Results and interpretation,[0],[0]
"“I disagree too, however ...”).
",4.3.3 Results and interpretation,[0],[0]
"False negatives were caused basically by presence of many ‘informative’ content words (980 unemployment, quarterly publication, inflation data, 474 actual publications, this experiment, biological ailments, medical doctorate, 1214 graduate degree, education, health insurance) and misinterpreted sarcasm (285(-1)",4.3.3 Results and interpretation,[0],[0]
“Also this is a cute analogy”).,4.3.3 Results and interpretation,[0],[0]
"In this article, we investigated ad hominem argumentation on three levels of discourse complexity.",5 Conclusion,[0],[0]
"We looked into qualitative and quantative properties of ad hominem arguments, crowdsourced labeled data, experimented with models for prediction (0.810 accuracy; 4.1.2), and proposed an updated typology of ad hominem properties (4.1.3).",5 Conclusion,[0],[0]
We then looked into the dynamics of argumentation to examine the relation between the quality of the original post and immediate ad hominem arguments (4.2).,5 Conclusion,[0],[0]
"Finally, we exploited the learned representation of Self-Attentive Embedding Neural Network to search for features triggering ad hominem in one-to-one discussions.",5 Conclusion,[0],[0]
"We found several categories of rhetorical devices as well as misleading features (4.3.3).
",5 Conclusion,[0],[0]
There are several points that deserve further investigation.,5 Conclusion,[0],[0]
"First, we have ignored metainformation of the debate participants, such as their overall activity (i.e., whether they are spammers or trolls).",5 Conclusion,[0],[0]
"Second, the proposed typology of ad hominem causes has not yet been post-verified empirically.",5 Conclusion,[0],[0]
"Third, we expect that personality traits of the participants (BIG5) may also play a significant role in the argumentative exchange.",5 Conclusion,[0],[0]
"We leave these points for future work.
",5 Conclusion,[0],[0]
"We believe that our findings will help gain better understanding of, and hopefully keep restraining from, ad hominem fallacies in good-faith discussions.",5 Conclusion,[0],[0]
"This work has been supported by the ArguAna Project GU 798/20-1 (DFG), and by the DFGfunded research training group “Adaptive Preparation of Information form Heterogeneous Sources” (AIPHES, GRK 1994/1).",Acknowledgments,[0],[0]
Arguing without committing a fallacy is one of the main requirements of an ideal debate.,abstractText,[0],[0]
"But even when debating rules are strictly enforced and fallacious arguments punished, arguers often lapse into attacking the opponent by an ad hominem argument.",abstractText,[0],[0]
"As existing research lacks solid empirical investigation of the typology of ad hominem arguments as well as their potential causes, this paper fills this gap by (1) performing several large-scale annotation studies, (2) experimenting with various neural architectures and validating our working hypotheses, such as controversy or reasonableness, and (3) providing linguistic insights into triggers of ad hominem using explainable neural network architectures.",abstractText,[0],[0]
Before Name-calling: Dynamics and Triggers of Ad Hominem Fallacies in Web Argumentation,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 1975–1985 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics",text,[0],[0]
"The task of Natural Language Inference (NLI)1 has received a lot of attention and has elicited models which have achieved impressive results on the Stanford NLI (SNLI) dataset (Bowman et al., 2015).",1 Introduction,[0],[0]
"Such results are impressive due to the linguistic knowledge required to solve the task (LoBue and Yates, 2011; Maccartney, 2009).",1 Introduction,[0],[0]
"However, the ever-growing complexity of these models inhibits a full understanding of the phenomena that they capture.
",1 Introduction,[0],[0]
"1Also known as Recognizing Textual Entailment.
",1 Introduction,[0],[0]
"As a consequence, evaluating these models purely on test set performance may not yield enough insight into the complete repertoire of abilities learned and any possible abnormal behaviors (Kummerfeld et al., 2012; Sammons et al., 2010).",1 Introduction,[0],[0]
"A similar case can be observed in models from other domains; take as an example an image classifier that predicts based on the image’s background rather than on the target object (Zhao et al., 2017; Ribeiro et al., 2016), or a classifier used in social contexts that predicts a label based on racial attributes (Crawford and Calo, 2016).",1 Introduction,[0],[0]
"In both examples, the models exploit a bias (an undesired pattern hidden in the dataset) to enhance accuracy.",1 Introduction,[0],[0]
"In such cases, the models may appear to be robust to new and even challenging test instances; however, this behavior may be due to spurious factors, such as biases.",1 Introduction,[0],[0]
"Assessing to what extent the models are robust to these contingencies just by looking at test accuracy is, therefore, difficult.
",1 Introduction,[0],[0]
"In this work we aim to study how certain factors affect the robustness of three pre-trained NLI models (a conditional encoder, the DAM model (Parikh et al., 2016), and the ESIM model (Chen et al., 2017)).",1 Introduction,[0],[0]
"We call these target factors insensitivity (not recognizing a new instance), polarity (a word-pair bias), and unseen pairs (recognizing the semantic relation of new word pairs).",1 Introduction,[0],[0]
"We became aware of these factors based on an exploration of the models’ behavior, and we hypothesize that these factors systematically influence the behavior of the models.
",1 Introduction,[0],[0]
"In order to systematically test if the above factors affect robustness, we propose a set of challenging instances for the models: We sample a set of instances from SNLI data, we apply a transformation on this set that yields a new set of instances, and we test both how well the models
1975
classify these new instances and whether the target factors influence the models’ behavior.",1 Introduction,[0],[0]
"The transformation (swapping a pair of words between premise and hypothesis sentences) is intended to yield both easy and difficult instances to challenge the models, but easy for a human to annotate them.
",1 Introduction,[0],[0]
"We draw motivation to study the robustness of NLI models from previous work on evaluating complex models (Isabelle et al., 2017; White et al., 2017).",1 Introduction,[0],[0]
"Furthermore, we base our approach on the discipline of behavioral science which provides methodologies for analyzing how certain factors influence the behavior of subjects under study (Epling and Pierce, 1986).
",1 Introduction,[0],[0]
We aim to answer the research questions: How robust is the predictive behavior of the pre-trained models under our transformation to input data?,1 Introduction,[0],[0]
"Do the target factors (insensitivity, polarity, and unseen pairs) influence the prediction of the models?",1 Introduction,[0],[0]
"Are these factors common across models?
",1 Introduction,[0],[0]
"Our results show that the models are robust mainly where the semantics of the new instances do not change significantly with respect to the sampled instances and thus the class labels remain unaltered; i.e., the models are insensitive to our transformation to input data.",1 Introduction,[0],[0]
"However, when the class labels change, the models significantly drop accuracy.",1 Introduction,[0],[0]
"In addition, the models exploit a bias, polarity, to stay robust when facing new instances.",1 Introduction,[0],[0]
"We also find that the models are able to cope with unseen word pairs under a hypernym relation, but not with those under an antonym relation, suggesting their inability to learn a symmetric relation.",1 Introduction,[0],[0]
"Previous works in ML and NLP have analyzed different aspects of complex models using a variety of approaches; for example, understanding input-output relationships by approximating the local or global behavior of the model using an interpretable model (Ribeiro et al., 2016; Craven and Shavlik, 1996), or analyzing the output of the model under lesions of its internal mechanism (Li et al., 2016).",2.1 Analysis of Complex Models,[0],[0]
"Another line of work has analyzed the robustness of NLP models both via controlled experiments to complement the information from the test set accuracy and test abilities of the models (Isabelle et al., 2017; B. Hashemi and Hwa, 2016; White et al., 2017) and via adversarial instances to expose weaknesses (Jia and Liang, 2017).",2.1 Analysis of Complex Models,[0],[0]
"In addi-
tion, work has been done to uncover and diminish gender biases in datasets captured by structured prediction models (Zhao et al., 2017) and word embeddings (Bolukbasi et al., 2016).",2.1 Analysis of Complex Models,[0],[0]
"However, to the best of our knowledge, there is no previous work to study the robustness of NLI models while analyzing factors affecting their predictions.",2.1 Analysis of Complex Models,[0],[0]
"Previous work on behavioral science has focused on understanding how environmental factors influence behaviors in both human (Soman, 2001) and animal (Mench, 1998) subjects with the objective of predicting behavioral patterns or analyzing environmental conditions.",2.2 Behavior Analysis,[0],[0]
"This methodology also helps to identify and understand abnormal behaviour by collecting behavioral data without the need to reach any internal component of the subject (Birkett and Newton-Fisher, 2011).
",2.2 Behavior Analysis,[0],[0]
"We base our approach in the discipline of behavioral science since some of our research questions and objectives align to those from this discipline; in addition, its methodology to study how factors effect on the subjects’ behavior provides statistical guarantees.",2.2 Behavior Analysis,[0],[0]
"NLI, or RTE, is the task of inferring whether a natural language sentence (hypothesis) is entailed by another natural language sentence (premise) (Maccartney, 2009; Dagan et al., 2009; Dagan and Glickman, 2004).",3.1 Natural Language Inference,[0],[0]
"More formally, given a pair of natural language sentences i = (premise, hypothesis), a model classifies the type of relation such sentences fall in from three possible classes, entailment, where the hypothesis is necessarily true given the premise, neutral, where the hypothesis may be true given the premise, and contradiction, where the hypothesis is necessarily false given the premise.",3.1 Natural Language Inference,[0],[0]
"Solving this task is challenging since it requires linguistic and semantic knowledge, such as co-reference, hypernymy, and antonymy (LoBue and Yates, 2011), as well as pragmatic knowledge and informal reasoning (Maccartney, 2009).",3.1 Natural Language Inference,[0],[0]
Behavior analysis seeks to account for the role that factors (independent variables) play in the behavior (dependent variable) of subjects.,3.2 Behavior Analysis,[0],[0]
"Testing for
the influence of a factor on the subject’s behavior can be done via statistical tests: A null hypothesis states no association between a target factor and behavior, whereas the alternative hypothesis states an association (McDonald, 2014).",3.2 Behavior Analysis,[0],[0]
"The Stanford NLI dataset (Bowman et al., 2015) was created with the purpose of training deep neural models while providing human-annotated data.",4.1 SNLI Dataset,[0],[0]
"Each instance was created by providing a premise sentence, harvested from a pre-existing dataset, to a crowdsource worker who was instructed to produce three hypothesis sentences, one for each NLI class (entailment, neutral, contradiction).",4.1 SNLI Dataset,[0],[0]
This process yielded a balanced dataset containing around 570K instances.,4.1 SNLI Dataset,[0],[0]
"Conditional Encoder We use two bidirectional LSTMs; the first LSTM encodes the premise sentence into a fixed-size vector embedding by sequentially reading on a word basis, while the second LSTM encodes the hypothesis sentence conditioned on the representation of the premise sentence.",4.2 Models,[0],[0]
At the final layer we used a softmax over the class labels on top of a 3-layer MLP.,4.2 Models,[0],[0]
"All embeddings, of dimensionality d = 100, were randomly initialized and learned during training.",4.2 Models,[0],[0]
"Accuracy on SNLI’s dev set is 0.782.
",4.2 Models,[0],[0]
"Decomposable Attention Model DAM (Parikh et al., 2016) consists of 2-layer multilayerperceptrons (MLPs) factorized in a 3-step process.",4.2 Models,[0],[0]
"First, a soft-alignment matrix is created for all the words in both the premise and hypothesis.",4.2 Models,[0],[0]
"Then, each word of the premise is paired with the softalignment representation of the hypothesis sentence and fed into an MLP, and similarly for each word in the hypothesis with the soft-alignment of the premise.",4.2 Models,[0],[0]
"The resulting representations are then aggregated where the vector representations of the premise are summed up and the same for those of the hypothesis; the new representations are then fed to an MLP, followed by a linear layer and a softmax whose output is a class label.",4.2 Models,[0],[0]
We use d = 300 dimensional GloVe embeddings (not updated at training time).,4.2 Models,[0],[0]
All layers use the ReLU function.,4.2 Models,[0],[0]
"Accuracy on SNLI’s dev set is 0.854.
",4.2 Models,[0],[0]
"Enhanced Sequential Information Model ESIM (Chen et al., 2017) performs inference in three stages.",4.2 Models,[0],[0]
"First, Input Encoding uses BiLSTMs to produce representations of each word in its context within premise or hypothesis.",4.2 Models,[0],[0]
"Then, Local Inference Modelling constructs new word representations for each hypothesis (premise) by summing over the BiLSTM hidden states for the premise (hypothesis) words using weights from a soft attention matrix.",4.2 Models,[0],[0]
"Additionally, these representations are enhanced with element-wise products and differences of the original hidden states vectors and the new attention based vectors.",4.2 Models,[0],[0]
"Finally, Inference Composition uses a BiLSTM, average and max pooling and an MLP output layer to produce predicted labels.",4.2 Models,[0],[0]
Accuracy on SNLI’s dev set is 0.882.,4.2 Models,[0],[0]
"We test our main hypothesis (Section 1) by perturbing instances in a controlled, simple, and meaningful way.",5 Methods,[0],[0]
"This alteration, at the instance level, yields new sets of instances which range from easy (the semantics and the label of the new instance are the same to those of the original instance) to challenging (both semantics and label of the new instance change with respect to those of the original instance), but all of them remain easy to annotate for a human.
",5 Methods,[0],[0]
"To examine how the models generalize from seen instances to transformed instances, we sample our original instances from the SNLI training set, which we refer to as control instances from now on.",5 Methods,[0],[0]
"We then produce new instances which differ either minimally from the control instances, by changing only a single word in the premise and hypothesis, or more substantially, by copying the same sentence structure into the premise and hypothesis with a single word changed.",5 Methods,[0],[0]
"In this way, we produce instances that contain only words seen at training time, within sentence structures also seen at training time.",5 Methods,[0],[0]
"Thus, our evaluation sets are as in-domain as possible, and control for factors associated with novel sentential contexts and vocabulary.",5 Methods,[0],[0]
"We first sample an instance from the SNLI dataset according to a given criterion, namely we look for a specific word pair in the instance; then, we apply our transformation over the word pair.",5.1 Basic Procedure and Statistical Analyses,[0],[0]
"This pro-
cedure generates a new instance.",5.1 Basic Procedure and Statistical Analyses,[0],[0]
"After that, the models label the new instance, and we statistically analyze which target factors influenced the models to respond in such a way via chi-square (McNemar’s, independence, and homogeneity) tests (McDonald, 2014; Alpaydin, 2010).",5.1 Basic Procedure and Statistical Analyses,[0],[0]
When the sample size is too small we apply Yate’s correction or a Fisher test.,5.1 Basic Procedure and Statistical Analyses,[0],[0]
"We use the StatsModels (Seabold and Perktold, 2010) and SciPy (Oliphant, 2007) packages.",5.1 Basic Procedure and Statistical Analyses,[0],[0]
"The level of significance is p < 0.0001, unless otherwise stated.2 This procedure is applied in four experiments, where we study the effect of different word pairs (hypernym, hyponym, and antonyms) and the effect of two types of context words surrounding the word pairs which we refer to as in situ and ex situ (explained in Section 5.3).",5.1 Basic Procedure and Statistical Analyses,[0],[0]
"Given a set of word pairs of the form W = (w1, w2), where w1 and w2 hold under a semantic relation s ∈ {antonymy, hypernymy, hyponymy}, we look through the training set for instances ik = (pk, hk), where pk and hk are premise and hypothesis sentences, respectively, such that w1 ∈ pk and w2 ∈ hk.",5.2 Transformation and Word Pairs,[0],[0]
"For each instance ik we apply transformation T : we swap w1 with w2; this transformation yields an instance im = (pm, hm) where w2 ∈ pm, w1 ∈ hm and w1 /∈",5.2 Transformation and Word Pairs,[0],[0]
"pm, w2 /∈",5.2 Transformation and Word Pairs,[0],[0]
"hm.3
",5.2 Transformation and Word Pairs,[0],[0]
"An example of transformation T on a contradiction instance ik is the following:
(1) pk :",5.2 Transformation and Word Pairs,[0],[0]
A soccer game occurring at sunset.,5.2 Transformation and Word Pairs,[0],[0]
hk :,5.2 Transformation and Word Pairs,[0],[0]
"A basketball game is occurring at sunrise.
",5.2 Transformation and Word Pairs,[0],[0]
"Where the word pair (sunset , sunrise) are antonyms.",5.2 Transformation and Word Pairs,[0],[0]
"After applying transformation T , we obtain the new contradiction instance",5.2 Transformation and Word Pairs,[0],[0]
"im:
(2) pm :",5.2 Transformation and Word Pairs,[0],[0]
A soccer game occurring at sunrise.,5.2 Transformation and Word Pairs,[0],[0]
hm :,5.2 Transformation and Word Pairs,[0],[0]
"A basketball game is occurring at sunset.
",5.2 Transformation and Word Pairs,[0],[0]
"Consider now the following instance il (class label entailment):
(3) pl :",5.2 Transformation and Word Pairs,[0],[0]
A little girl hugs her brother on a footbridge in a forest.,5.2 Transformation and Word Pairs,[0],[0]
hl :,5.2 Transformation and Word Pairs,[0],[0]
"A pair of siblings are on a bridge.
",5.2 Transformation and Word Pairs,[0],[0]
2We apply a Bonferroni correction.,5.2 Transformation and Word Pairs,[0],[0]
"3If a word w1 or w2 appears more than once, we replace
all the appearances with its corresponding pair, w2 or w1.
",5.2 Transformation and Word Pairs,[0],[0]
"If we now apply transformation T on the hypernym word pair (footbridge, bridge) we derive the new instance in (class neutral):
(4) pn :",5.2 Transformation and Word Pairs,[0],[0]
A little girl hugs her brother on a bridge in a forest.,5.2 Transformation and Word Pairs,[0],[0]
"hn : A pair of siblings are on a footbridge.
",5.2 Transformation and Word Pairs,[0],[0]
"Since swapping word pairs under hypernymy or hyponymy relations may yield a different class label for the new instance, we manually annotate all the instances in the new sample, discarding those that are semantically incoherent.",5.2 Transformation and Word Pairs,[0],[0]
"We consider two types of sentential context for the word pairs, namely in situ and ex situ.",5.3 Experimental Conditions,[0],[0]
"Examples of instances under the in situ condition are Examples 1, 2, 3, and 4 in Section 5.2.",5.3 Experimental Conditions,[0],[0]
The name in situ refers to the fact that we analyze the effect of the transformation T within the original context of the premise and hypothesis sentences.,5.3 Experimental Conditions,[0],[0]
"This allows to control for confounding factors, such as sentence length and order of the context words.
",5.3 Experimental Conditions,[0],[0]
We also consider an ex situ condition in which we remove the word pair from the original premise and hypothesis and analyze the effect of the transformation T within a simplified sentential context which is the same in premise and hypothesis.,5.3 Experimental Conditions,[0],[0]
"Specifically, we randomly select either the premise or hypothesis context from the original instance and copy it into both positions.",5.3 Experimental Conditions,[0],[0]
"In this way, we obtain a sentence pair where the only difference between the premise and hypothesis is the word pair, which allows us to isolate the effect of this pair from its interaction with the surrounding context; this condition thus allows to control for context words.",5.3 Experimental Conditions,[0],[0]
"This process yields a new set of instances, which we refer to as E.
An example of an ex situ instance can be constructed from Example 1 (Section 5.2).",5.3 Experimental Conditions,[0],[0]
"If the premise sentence is selected, then after performing the procedure described above, the following sentence pair ek is generated:
(5) pk :",5.3 Experimental Conditions,[0],[0]
A soccer game occurring at sunset.,5.3 Experimental Conditions,[0],[0]
hk :,5.3 Experimental Conditions,[0],[0]
"A soccer game occurring at sunrise.
",5.3 Experimental Conditions,[0],[0]
"Given a sample E, we apply the transformation T in order to generate a transformed sample ET where the word pairs are swapped, similar to the procedure applied in Section 5.2 on SNLI control instances in order to generate their transformed instances counterpart.",5.3 Experimental Conditions,[0],[0]
"In the latter case, we say that
given a sample of control instances I we generate a transformed sample IT .
",5.3 Experimental Conditions,[0],[0]
"As an example of obtaining a transformed ex situ instance, we apply T to (sunset , sunrise) in Example 5 to obtain the new instance",5.3 Experimental Conditions,[0],[0]
"em:
(6) pm :",5.3 Experimental Conditions,[0],[0]
A soccer game occurring at sunrise.,5.3 Experimental Conditions,[0],[0]
hm :,5.3 Experimental Conditions,[0],[0]
"A soccer game occurring at sunset.
",5.3 Experimental Conditions,[0],[0]
"We note that for both conditions, in situ and ex situ, the same word pairs are swapped, so the differences are the surrounding context words and the factors being controlled.",5.3 Experimental Conditions,[0],[0]
In each experiment we use two sets of instances in order to measure the robustness of the models and analyze our target factors: 1),5.4 Test Sets,[0],[0]
The control instances where the target word pair is in its original position and 2) the transformed instances generated after applying transformation T .,5.4 Test Sets,[0],[0]
The name of each set corresponds with the experimental setting it is used in.,5.4 Test Sets,[0],[0]
"Samples used in in situ experiments are named as I , and E for ex situ.",5.4 Test Sets,[0],[0]
Subscripts distinguish both the type of word pairs (A for antonyms and H for hypernym/hyponym) and the type of set (control or transformed).,5.4 Test Sets,[0],[0]
"For example, IA refers to the control in situ set whose instances contain antonym word pairs, whereas ETH refers to the ex situ transformed test set containing hypernym/hyponym swapped word pairs.
",5.4 Test Sets,[0],[0]
"We clarify: a) the sets IA and IH are sampled from the SNLI dataset; b) transformed test sets are
generated from control sets containing control instances; c) we refer to the sets EA and EH as control test sets because the target word pairs are in their original position, and we apply T on them in order to obtain the transformed samples ETA and ETH , respectively.
",5.4 Test Sets,[0],[0]
"Details about the sets: In order to build set IA, we sample only contradiction instances (instances in EA are also contradictions).",5.4 Test Sets,[0],[0]
"We use the antonym word pairs from (Mohammad et al., 2013) to yield the sets ITA1 and ETA, which also only contain contradictions since the relation of antonymy is symmetric.4 We build two more sets, ITA2 and ITA3 (explained in Section 6.1).",5.4 Test Sets,[0],[0]
"Sets IH , EH , ITH , and ETH contain instances with any class label.",5.4 Test Sets,[0],[0]
"In order to generate sets ITH and ETH , we use the hypernym word pairs from (Baroni et al., 2012).",5.4 Test Sets,[0],[0]
We manually annotate these transformed sets and discard incoherent instances.,5.4 Test Sets,[0],[0]
"We describe the three target factors that we hypothesize that affect the models’ response.
",5.5 Factors Under Study,[0],[0]
Insensitivity is the name we give to the tendency of a model to predict the original label on a transformed instance that is similar to a control instance.,5.5 Factors Under Study,[0],[0]
"Thus a model would be insensitive if, for example, it incorrectly predicts the same class label for both the control instance in Example 3
4The word pair (sunset , sunrise) holds in an antonymy relation regardless of the position of the words in premise and hypothesis sentences.
and the transformed instance in Example 4 just because they closely resemble each other.",5.5 Factors Under Study,[0],[0]
A simple measure of the impact of this effect is to look at the accuracy on the subset of instances in which the gold label was changed by the transformation.,5.5 Factors Under Study,[0],[0]
"We show this effect by statistically correlating the rate of correct predictions with changes in the labels predicted.
",5.5 Factors Under Study,[0],[0]
Unseen Word Pairs are another factor we can use to evaluate robustness.,5.5 Factors Under Study,[0],[0]
"In this case, we are interested in the subset of transformed instances where the swapped word pair is now in an order within premise and hypothesis that was unseen in the training data.",5.5 Factors Under Study,[0],[0]
"An example is Example 2 which contains the unseen word pair (sunrise, sunset); i.e., no instance in the training set contains the word sunrise in the premise and the word sunset in the hypothesis.",5.5 Factors Under Study,[0],[0]
Poor performance on this subset reflects an inability to exploit the symmetry (antonym pairs) or anti-symmetry (hypernym pairs) of the word pairs involved.,5.5 Factors Under Study,[0],[0]
"We show models’ abilities to cope with unseen pairs by statistically associating proportions of instances containing unseen pairs with incorrect predictions rates.
",5.5 Factors Under Study,[0],[0]
Polarity is the name we give to the association between a word pair and the most frequent class it is found in across training instances.,5.5 Factors Under Study,[0],[0]
"For example, we associate the word pair (sunset , sunrise) with polarity contradiction because it mainly appears on training instances with label contradiction.",5.5 Factors Under Study,[0],[0]
"We define four main categories of polarity: neutral, contradiction, entailment, and none for unseen word pairs.5 Accuracy on the subset of instances where polarity and gold label disagree is an indicator of the extent to which a model is influenced by this factor.",5.5 Factors Under Study,[0],[0]
"For example, a model incorrectly predicting label entailment for the instance in Example 4 (class neutral) based on the polarity of class entailment of its word pair (bridge, footbridge) indicates that the model is influenced by this factor.",5.5 Factors Under Study,[0],[0]
We show this influence by statistically correlating labels predicted with polarities.,5.5 Factors Under Study,[0],[0]
Table 1 presents the performance of the models across the different test sets.,6 Experiments and Results,[0],[0]
"In general, DAM and ESIM seem to be more robust than CE, with
5We also define categories when a word pair appears the same number of times in two classes, such as entailmentneutral, though these cases are rare.
",6 Experiments and Results,[0],[0]
the latter’s accuracy degrading to essentially random performance on the most challenging subsets.,6 Experiments and Results,[0],[0]
"However, this general trend is reversed in a single row of the table.",6 Experiments and Results,[0],[0]
"On ETH , ESIM shows a comparable performance to CE.",6 Experiments and Results,[0],[0]
"And on Subset 3 of IH , DAM appears to rely on a bias (polarity) in the same way as CE.",6 Experiments and Results,[0],[0]
"Overall, all models are affected by the three target factors, dropping performance up to 0.25, 0.20, and 0.28 for ESIM, DAM, CE, respectively, just by virtue of our simple transformation of swapping words.",6 Experiments and Results,[0],[0]
"Situ Instances
In this experiment we use sets IA and ITA1 .",6.1 Experiment 1: Swapping Antonyms in In,[0],[0]
"Swapping antonyms seems to have no effect on the overall performance of the DAM model on ITA1 when compared to IA, and little effect on ESIM.",6.1 Experiment 1: Swapping Antonyms in In,[0],[0]
Thus these two models appear to be robust to this transformation.,6.1 Experiment 1: Swapping Antonyms in In,[0],[0]
"Nonetheless, further analysis will not support the conclusion that both models have learned that antonymy is symmetric, and we will show that this seemingly robust behavior is due to confounding factors and not due to inference abilities.",6.1 Experiment 1: Swapping Antonyms in In,[0],[0]
"Accuracy scores of CE model seem to reveal that it is much less robust to the antonym swap, with performance significantly dropping by roughly 10.5% according to a McNemar’s test.
",6.1 Experiment 1: Swapping Antonyms in In,[0],[0]
"Insensitivity Because instances in ITA1 are contradiction, we perform a proxy experiment to understand the models’ sensitivity.",6.1 Experiment 1: Swapping Antonyms in In,[0],[0]
"From IA, we substitute one of the antonyms in each word pair (in each instance) with a hyponym, hypernym, or synonym6 of the other.",6.1 Experiment 1: Swapping Antonyms in In,[0],[0]
"Doing this on both the premise and hypothesis yields two new samples, ITA2 and ITA3 , which we manually annotate.
",6.1 Experiment 1: Swapping Antonyms in In,[0],[0]
"Examples of control (Example 7) and transformed (Example 8) instances are given below, showing the replacement of young, in the hypothesis, with aged, a synonym of elderly from the premise.",6.1 Experiment 1: Swapping Antonyms in In,[0],[0]
This transformation changes gold-label from contradiction to neutral.,6.1 Experiment 1: Swapping Antonyms in In,[0],[0]
"Approximately, half the sample yields such changes in gold-label.
",6.1 Experiment 1: Swapping Antonyms in In,[0],[0]
(7) pk : An elderly woman sitting on a bench.,6.1 Experiment 1: Swapping Antonyms in In,[0],[0]
hk :,6.1 Experiment 1: Swapping Antonyms in In,[0],[0]
"A young mother sits down.
",6.1 Experiment 1: Swapping Antonyms in In,[0],[0]
(8) pm : An elderly woman sitting on a bench.,6.1 Experiment 1: Swapping Antonyms in In,[0],[0]
hm :,6.1 Experiment 1: Swapping Antonyms in In,[0],[0]
"An aged mother sits down.
",6.1 Experiment 1: Swapping Antonyms in In,[0],[0]
"6We manually select these from WordNet such that it appears at least t = 10 times in the training set on either the premise sentences or the hypothesis sentences.
",6.1 Experiment 1: Swapping Antonyms in In,[0],[0]
"This transformation leads to a considerable drop in overall performance for all models when accuracy scores on sets ITA2 and ITA3 are compared to the accuracy on the control instances in IA: up to 0.175 (CE), 0.201 (DAM), and 0.24 (ESIM) points (Table 1).",6.1 Experiment 1: Swapping Antonyms in In,[0],[0]
"To test if insensitivity to the transformation is associated with these behaviors, we measure accuracy only on those instances that changed gold-label (Subset 1 from the sets ITA2 and ITA3 ), where we see a further reduction in performance for all models.",6.1 Experiment 1: Swapping Antonyms in In,[0],[0]
"2-way tests of independence provide strong evidence for the insensitivity of the models (CE: χ2(1) = 73.33, DAM: χ2(1)",6.1 Experiment 1: Swapping Antonyms in In,[0],[0]
"= 108.30, ESIM: χ2(1) = 175.34).
",6.1 Experiment 1: Swapping Antonyms in In,[0],[0]
Table 2 shows the case for ESIM: most of its incorrect predictions are due to predicting the same label on both control and transformed instances when these two type of instances have different gold labels.,6.1 Experiment 1: Swapping Antonyms in In,[0],[0]
"Paradoxically, this effect works in the models’ favour in the antonym swapping case (ITA1 ) because all the gold-labels remain as contradiction.",6.1 Experiment 1: Swapping Antonyms in In,[0],[0]
"Thus ignoring the transformation will avoid any loss in performance.
",6.1 Experiment 1: Swapping Antonyms in In,[0],[0]
Unseen Word Pairs The results in the column Subset 2 of ITA1 (Table 1) suggest that performance on unseen word pairs is weak.,6.1 Experiment 1: Swapping Antonyms in In,[0],[0]
"However, only 40 instances within ITA1 contain unseen antonym pairs; thus the impact of this result may be limited.",6.1 Experiment 1: Swapping Antonyms in In,[0],[0]
2-way tests of homogeneity show that the difference in accuracy of predictions in instances containing seen or unseen word pairs is nonetheless significant for all models (CE: χ2(1),6.1 Experiment 1: Swapping Antonyms in In,[0],[0]
"= 19.46, DAM: χ2(1) = 74.16, ESIM: χ2(1) = 39.33).",6.1 Experiment 1: Swapping Antonyms in In,[0],[0]
"In other words, the models struggle to recognize the reversed antonym pairs, even though they were all seen in their original order at training time.",6.1 Experiment 1: Swapping Antonyms in In,[0],[0]
"This effect can be seen, for example, in the contingency table for DAM in Table 3.
",6.1 Experiment 1: Swapping Antonyms in In,[0],[0]
Polarity Only 11% of the instances in the transformed sample ITA1 contain word pairs that have polarity other than contradiction.,6.1 Experiment 1: Swapping Antonyms in In,[0],[0]
"Thus, a model
relying only on this factor could achieve an accuracy of 89%.",6.1 Experiment 1: Swapping Antonyms in In,[0],[0]
We investigate if the predicted labels on instances in ITA1 are associated with the polarity of the transformed word pair.,6.1 Experiment 1: Swapping Antonyms in In,[0],[0]
"For all models, independence tests are highly significant (CE: χ2(6)",6.1 Experiment 1: Swapping Antonyms in In,[0],[0]
"= 30.69, DAM: χ2(6) = 101.26, ESIM: χ2(6) = 64.40).",6.1 Experiment 1: Swapping Antonyms in In,[0],[0]
Table 4 shows that the predictions of DAM change according to the polarity of the word pairs.,6.1 Experiment 1: Swapping Antonyms in In,[0],[0]
"For example, when the polarity is contradiction, around 98.5% of the predictions are contradictions; however, this figure changes when the polarity is neutral where the rate of correct predictions (contradictions) fall to 80.7%, and a more dramatic fall is observed when the word pairs are unseen (polarity none) where only 50% of the predictions are correct.",6.1 Experiment 1: Swapping Antonyms in In,[0],[0]
"This is strong evidence that the models learned to rely on polarity.
",6.1 Experiment 1: Swapping Antonyms in In,[0],[0]
"We note that a model with perfect accuracy on ITA1 , would lead to a statistic that does not reject the null hypothesis, showing in this case that the predictions are independent of polarity.",6.1 Experiment 1: Swapping Antonyms in In,[0],[0]
"Ex Situ Instances
",6.2 Experiment 2: Swapping Antonyms in,[0],[0]
"In this experiment, we use samples EA and ETA.",6.2 Experiment 2: Swapping Antonyms in,[0],[0]
"Swapping antonyms has little effect on the performance of all models, where the biggest drop comes from DAM (0.029 points).",6.2 Experiment 2: Swapping Antonyms in,[0],[0]
"However, the CE model performs quite poorly at both samples (0.508 and 0.48 accuracy points on EA and ETA);
this drop in performance, with respect to the in situ condition, suggests that the repeated sentence context is too different from the structure of the training instances for the CE model to generalize effectively.
",6.2 Experiment 2: Swapping Antonyms in,[0],[0]
"In this condition, we refrain from analyzing the effect of insensitivity, since doing so would require a transformation similar to that in the in situ condition, which might add an extra layer of change and the results may turn difficult to interpret.
",6.2 Experiment 2: Swapping Antonyms in,[0],[0]
Unseen Word Pairs Accuracy scores strongly suggest that the models are weak at dealing with unseen antonym pairs (Subset 2 of ETA in Table 1); drops in performance on this subset range from 0.315 up to 0.429 points across the three models.,6.2 Experiment 2: Swapping Antonyms in,[0],[0]
"Tests of homogeneity show strong evidence of this weakness for all models (CE: χ2(1) = 15.91, DAM: χ2(1)",6.2 Experiment 2: Swapping Antonyms in,[0],[0]
"= 59.17, ESIM: χ2(1) = 44.72).",6.2 Experiment 2: Swapping Antonyms in,[0],[0]
"Comparing results on this subset with those of Subset 2 in ITA1 , we notice that ESIM and DAM keep similar behavior, but CE seems to be strongly affected by this context type.
",6.2 Experiment 2: Swapping Antonyms in,[0],[0]
"Polarity All models perform poorly in the subset of instances where polarity disagrees with gold label of the instance (Subset 3 of ETA), showing that the models’ behavior rely on this bias.",6.2 Experiment 2: Swapping Antonyms in,[0],[0]
"These results are highly significant (CE: χ2(6) = 34.37, DAM: χ2(6) = 136.99, ESIM: χ2(6) = 103.47).",6.2 Experiment 2: Swapping Antonyms in,[0],[0]
This is further evidence that the models get confused with a simple reversal of an antonym pair.,6.2 Experiment 2: Swapping Antonyms in,[0],[0]
"Hyponyms in In Situ Instances
We now study the effect on the robustness of the systems when we swap hypernym and hyponym word pairs in in situ instances.",6.3 Experiment 3: Swapping Hypernyms and,[0],[0]
"Whole sample accuracy scores in Table 1 significantly drop, according to McNemar’s tests, by 0.25 (ESIM), 0.285 (CE), and 0.128 (DAM) points when we compare scores on control instances (IH ) with those on transformed instances (ITH ).",6.3 Experiment 3: Swapping Hypernyms and,[0],[0]
"We investigate the role of our target factors on these behaviors.
",6.3 Experiment 3: Swapping Hypernyms and,[0],[0]
Insensitivity Around 42% of the instances in ITH (Subset 1) have different gold label from those in IH .,6.3 Experiment 3: Swapping Hypernyms and,[0],[0]
"On these instances, the models’ results are severely impaired: CE and ESIM models’ performances drop to close-to-random (0.271 and 0.315), while DAM decreases by 0.18 points.",6.3 Experiment 3: Swapping Hypernyms and,[0],[0]
"All models’ errors on this subset are strongly as-
sociated with failure to change the predicted class (CE:χ2(1)",6.3 Experiment 3: Swapping Hypernyms and,[0],[0]
"= 90.73, DAM:χ2(1) = 101.52, ESIM:χ2(1) = 150.92).",6.3 Experiment 3: Swapping Hypernyms and,[0],[0]
"In contrast to the case in Experiment 1, insensitivity acts in detriment of the models’ robustness when gold labels change after the transformation.
",6.3 Experiment 3: Swapping Hypernyms and,[0],[0]
Unseen Word Pairs,6.3 Experiment 3: Swapping Hypernyms and,[0],[0]
"Whereas model performance was significantly worse on unseen antonym pairs, this effect is not obvious on the hyponymhypernym results (Subset 2 of ITH ).",6.3 Experiment 3: Swapping Hypernyms and,[0],[0]
"In fact, all models have a slightly higher accuracy on this subset than overall.",6.3 Experiment 3: Swapping Hypernyms and,[0],[0]
"Homogeneity tests find no evidence of an association between unseen word pairs and incorrect predictions for any model (CE:χ2(1) = 0.00036, p = 0.98, DAM:χ2(1) = 0.98, p = 0.32, ESIM:χ2(1) = 0.178, p = 0.67).",6.3 Experiment 3: Swapping Hypernyms and,[0],[0]
This effect may be explained by the models exploiting information from word embeddings.,6.3 Experiment 3: Swapping Hypernyms and,[0],[0]
"It has been shown that word embeddings are able to capture hypernymy (Sanchez and Riedel, 2017); thus the models may use this information to generalize to unseen hypernym pairs.
",6.3 Experiment 3: Swapping Hypernyms and,[0],[0]
"Polarity We find very strong evidence for an association between polarity and class label predicted on sample IH for all models (CE:χ2(10) = 168.40, DAM:χ2(10) = 182.76, ESIM:χ2(10) = 157.76).",6.3 Experiment 3: Swapping Hypernyms and,[0],[0]
"However, for sample ITH , only DAM keeps this strong correlation (χ2(14) = 47.71).",6.3 Experiment 3: Swapping Hypernyms and,[0],[0]
"In the case of CE, we find weak evidence in favour of this correlation on instances of ITH (χ2(14) = 25.27, p = 0.03).",6.3 Experiment 3: Swapping Hypernyms and,[0],[0]
"For ESIM we find no evidence of correlation (χ2(14) = 22.72, p = 0.06), thus we do not reject the null hypothesis.",6.3 Experiment 3: Swapping Hypernyms and,[0],[0]
"Polarity’s influence can be observed in Subset 3 of IH (Table 1), where we observe a drop in accuracy for instances whose gold labels do not match the polarity of the word pairs, compared to the accuracy of the whole sample; this means that when the models have polarity as a cue, they improve performance.",6.3 Experiment 3: Swapping Hypernyms and,[0],[0]
"Hyponyms in Ex Situ Instances
All models’ performance significantly drop (p < 0.01) after our transformation by 0.208 (CE), 0.061 (DAM) and 0.195 (ESIM) points, where performance of ESIM is comparable to that of CE on both samples, EH and ETH .",6.4 Experiment 4: Swapping Hypernyms and,[0],[0]
"Compared to the in situ condition, DAM’s performance improves, opposite to CE’s and ESIM’s behavior.
",6.4 Experiment 4: Swapping Hypernyms and,[0],[0]
"Insensitivity The drop in performance described above can be partially explained by insensitivity to changes in gold label, since around 93% of the instances in ETH changed gold-label with respect to EH .",6.4 Experiment 4: Swapping Hypernyms and,[0],[0]
We find strong statistical evidence for this hypothesis (CE:χ2(1) =,6.4 Experiment 4: Swapping Hypernyms and,[0],[0]
"175.19, DAM:χ2(1) = 158.62, ESIM:χ2(1) = 252.27).",6.4 Experiment 4: Swapping Hypernyms and,[0],[0]
"However, in the case of DAM, this factor seems to play a small role on its behavior as seen when we compare accuracy on Subset 1 with that of the whole transformed sample.
",6.4 Experiment 4: Swapping Hypernyms and,[0],[0]
"Insensitivity seems to have a bigger influence on the models when the transformed instances are closer to the training set: Accuracy scores on Subset 1 from ITH are smaller than those on Subset 1 from ETH .
",6.4 Experiment 4: Swapping Hypernyms and,[0],[0]
"Unseen Word Pairs Similar to the in situ condition, our homogeneity tests show no evidence for incorrect predictions being due to unseen word pairs (CE:χ2(1) = 0.35, p = 0.55, DAM:χ2(1) = 2.43, p = 0.11, ESIM:χ2(1) = 0.183, p = 0.66).",6.4 Experiment 4: Swapping Hypernyms and,[0],[0]
"We posit the same explanation as before: Models may use hypernymy information contained in the embeddings.
",6.4 Experiment 4: Swapping Hypernyms and,[0],[0]
"Polarity We find statistically high correlation of the models’ predictions with the polarity of the word pairs in the instances from both samples, EH (CE:χ2(10) = 261.77, DAM:χ2(10) = 312.67, ESIM:χ2(10) = 176.38) and ETH (CE:χ2(14) = 56.52, DAM:χ2(14) = 258.09, ESIM:χ2(10) = 105.70).",6.4 Experiment 4: Swapping Hypernyms and,[0],[0]
"This evidence indicates that all models use, to some extent, the polarity as a feature for predicting class labels.",6.4 Experiment 4: Swapping Hypernyms and,[0],[0]
"Although all three models achieve strong results on the original SNLI development set (CE: 0.782, DAM: 0.854, ESIM: 0.882), each model exhibits particular weaknesses on the transformed training instances.",7 Discussion and Conclusions,[0],[0]
"Notably, all perform poorly on ITH instances in which the gold label is changed, with ESIM and CE performing below the level of chance.",7 Discussion and Conclusions,[0],[0]
"Thus, on these instances, the models tend to predict the label of the original unaltered training instance and inference in this case is similar to nearest-neighbour prediction.
",7 Discussion and Conclusions,[0],[0]
"On the other hand, much better performance is obtained for the DAM and ESIM models on ITH instances containing unseen word pairs, indicating these models have learned to infer hyper-
nym/hyponym relations from information in the pre-trained word embeddings.",7 Discussion and Conclusions,[0],[0]
"In contrast, performance on the unseen word pairs in ITA1 and ETA suggests that inferring antonymy from the embeddings is more difficult.
",7 Discussion and Conclusions,[0],[0]
Weak performance is seen again on the EA and ETA instances where the polarity of the antonym pair is not consistent with the gold label.,7 Discussion and Conclusions,[0],[0]
"For these cases, the only difference between premise and hypothesis is the antonym pair, and the models tend to fall back on predicting the most frequent gold label seen for that word pair.
",7 Discussion and Conclusions,[0],[0]
One result that remains anomalous is the overall performance of the ESIM model on the whole ETH sample.,7 Discussion and Conclusions,[0],[0]
"While this sample contains unseen word pairs and instances in which the gold label changes or is inconsistent with polarity, these effects do not by themselves explain the poor performance overall.",7 Discussion and Conclusions,[0],[0]
"Neither is this weakness explained by the ex situ structure, in which premise and hypothesis differ by only one word, as performance on the control ex situ sample, EH , is much stronger.",7 Discussion and Conclusions,[0],[0]
"The effect, then, appears to be due to an interaction of the ex situ structure in combination with the transformation.
",7 Discussion and Conclusions,[0],[0]
"In the present work, we have limited ourselves to examining single influences independently.",7 Discussion and Conclusions,[0],[0]
"However, there are undoubtedly manifold interactions contributing to model performance.",7 Discussion and Conclusions,[0],[0]
"In fact, the complexities of these models (LSTMs, attention mechanisms and MLPs) are specifically intended to capture the interactions between the words in the premise and hypothesis.",7 Discussion and Conclusions,[0],[0]
Further work is required to understand what these interactions are and how they contribute to performance.,7 Discussion and Conclusions,[0],[0]
Fully uncovering these factors in current NLI datasets is a pre-requisite for the construction of more effective resources in the future.,7 Discussion and Conclusions,[0],[0]
"We thank Raul Ortiz Pulido and Erick Sanchez Carmona for insightful discussions, Pasquale Minervini for providing the implementations of DAM and ESIM, Pontus Stenetorp for providing valuable feedback on the manuscript, and Johannes Welbl for insightful comments.",Acknowledgments,[0],[0]
The first author was recipient of a scholarship from CONACYT.,Acknowledgments,[0],[0]
This work was supported by an Allen Distinguished Investigator Award and the EU H2020 SUMMA project (grant agreement number 688139).,Acknowledgments,[0],[0]
"Natural Language Inference is a challenging task that has received substantial attention, and state-of-the-art models now achieve impressive test set performance in the form of accuracy scores.",abstractText,[0],[0]
"Here, we go beyond this single evaluation metric to examine robustness to semantically-valid alterations to the input data.",abstractText,[0],[0]
"We identify three factors insensitivity, polarity and unseen pairs and compare their impact on three SNLI models under a variety of conditions.",abstractText,[0],[0]
Our results demonstrate a number of strengths and weaknesses in the models’ ability to generalise to new in-domain instances.,abstractText,[0],[0]
"In particular, while strong performance is possible on unseen hypernyms, unseen antonyms are more challenging for all the models.",abstractText,[0],[0]
"More generally, the models suffer from an insensitivity to certain small but semantically significant alterations, and are also often influenced by simple statistical correlations between words and training labels.",abstractText,[0],[0]
"Overall, we show that evaluations of NLI models can benefit from studying the influence of factors intrinsic to the models or found in the dataset used.",abstractText,[0],[0]
Behavior Analysis of NLI Models: Uncovering the Influence of Three Factors on Robustness,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 431–441 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics",text,[0],[0]
"Multimodal information processing tasks such as image captioning (Farhadi et al., 2010; Ordonez et al., 2011; Xu et al., 2015) and visual question answering (Visual QA) (Antol et al., 2015) have
∗Equal contributions
gained a lot of attention recently.",1 Introduction,[0],[0]
"A number of significant advances in learning algorithms have been made, along with the development of nearly two dozens of datasets in this very active research domain.",1 Introduction,[0],[0]
"Among those datasets, popular ones include MSCOCO (Lin et al., 2014; Chen et al., 2015), Visual Genome (Krishna et al., 2017), VQA (Antol et al., 2015), and several others.",1 Introduction,[0],[0]
"The overarching objective is that a learning machine needs to go beyond understanding different modalities of information separately (such as image recognition alone) and to learn how to correlate them in order to perform well on those tasks.
",1 Introduction,[0],[0]
"431
To evaluate the progress on those complex and more AI-like tasks is however a challenging topic.",1 Introduction,[0],[0]
"For tasks involving language generation, developing an automatic evaluation metric is itself an open problem (Anderson et al., 2016; Kilickaya et al., 2017; Liu et al., 2016; Kafle and Kanan, 2017b).",1 Introduction,[0],[0]
"Thus, many efforts have concentrated on tasks such as multiple-choice Visual QA (Antol et al., 2015; Zhu et al., 2016; Jabri et al., 2016) or selecting the best caption (Hodosh et al., 2013; Hodosh and Hockenmaier, 2016; Ding et al., 2016; Lin and Parikh, 2016), where the selection accuracy is a natural evaluation metric.
",1 Introduction,[0],[0]
"In this paper, we study how to design highquality multiple choices for the Visual QA task.",1 Introduction,[0],[0]
"In this task, the machine (or the human annotator) is presented with an image, a question and a list of candidate answers.",1 Introduction,[0],[0]
"The goal is to select the correct answer through a consistent understanding of the image, the question and each of the candidate answers.",1 Introduction,[0],[0]
"As in any multiple-choice based tests (such as GRE), designing what should be presented as negative answers — we refer them as decoys — is as important as deciding the questions to ask.",1 Introduction,[0],[0]
"We all have had the experience of exploiting the elimination strategy: This question is easy — none of the three answers could be right so the remaining one must be correct!
",1 Introduction,[0],[0]
"While a clever strategy for taking exams, such “shortcuts” prevent us from studying faithfully how different learning algorithms comprehend the meanings in images and languages (e.g., the quality of the embeddings of both images and languages in a semantic space).",1 Introduction,[0],[0]
"It has been noted that machines can achieve very high accuracies of selecting the correct answer without the visual input (i.e., the image), the question, or both (Jabri et al., 2016; Antol et al., 2015).",1 Introduction,[0],[0]
"Clearly, the learning algorithms have overfit on incidental statistics in the datasets.",1 Introduction,[0],[0]
"For instance, if the decoy answers have rarely been used as the correct answers (to any questions), then the machine can rule out a decoy answer with a binary classifier that determines whether the answers are in the set of the correct answers — note that this classifier does not need to examine the image and it just needs to memorize the list of the correct answers in the training dataset.",1 Introduction,[0],[0]
"See Fig. 1 for an example, and Sect.",1 Introduction,[0],[0]
"3 for more and detailed analysis.
",1 Introduction,[0],[0]
We focus on minimizing the impacts of exploiting such shortcuts.,1 Introduction,[0],[0]
"We suggest a set of principles
for creating decoy answers.",1 Introduction,[0],[0]
"In light of the amount of human efforts in curating existing datasets for the Visual QA task, we propose two procedures that revise those datasets such that the decoy answers are better designed.",1 Introduction,[0],[0]
"In contrast to some earlier works, the procedures are fully automatic and do not incur additional human annotator efforts.",1 Introduction,[0],[0]
"We apply the procedures to revise both Visual7W (Zhu et al., 2016) and VQA (Antol et al., 2015).",1 Introduction,[0],[0]
"Additionally, we create new multiplechoice based datasets from COCOQA (Ren et al., 2015) and the recently released VQA2 (Goyal et al., 2017) and Visual Genome datasets (Krishna et al., 2017).",1 Introduction,[0],[0]
"The one based on Visual Genome becomes the largest multiple-choice dataset for the Visual QA task, with more than one million image-question-candidate answers triplets.
",1 Introduction,[0],[0]
We conduct extensive empirical and human studies to demonstrate the effectiveness of our procedures in creating high-quality datasets for the Visual QA task.,1 Introduction,[0],[0]
"In particular, we show that machines need to use all three information (image, questions and answers) to perform well — any missing information induces a large drop in performance.",1 Introduction,[0],[0]
"Furthermore, we show that humans dominate machines in the task.",1 Introduction,[0],[0]
"However, given the revised datasets are likely reflecting the true gap between the human and the machine understanding of multimodal information, we expect that advances in learning algorithms likely focus more on the task itself instead of overfitting to the idiosyncrasies in the datasets.
",1 Introduction,[0],[0]
The rest of the paper is organized as follows.,1 Introduction,[0],[0]
In Sect.,1 Introduction,[0],[0]
"2, we describe related work.",1 Introduction,[0],[0]
In Sect.,1 Introduction,[0],[0]
"3, we analyze and discuss the design deficiencies in existing datasets.",1 Introduction,[0],[0]
In Sect.,1 Introduction,[0],[0]
"4, we describe our automatic procedures for remedying those deficiencies.",1 Introduction,[0],[0]
In Sect. 5 we conduct experiments and analysis.,1 Introduction,[0],[0]
We conclude the paper in Sect.,1 Introduction,[0],[0]
6.,1 Introduction,[0],[0]
Wu et al. (2017) and Kafle and Kanan (2017b) provide recent overviews of the status quo of the Visual QA task.,2 Related Work,[0],[0]
There are about two dozens of datasets for the task.,2 Related Work,[0],[0]
"Most of them use real-world images, while some are based on synthetic ones.",2 Related Work,[0],[0]
"Usually, for each image, multiple questions and their corresponding answers are generated.",2 Related Work,[0],[0]
"This can be achieved either by human annotators, or with an automatic procedure that uses captions or question templates and detailed image annota-
tions.",2 Related Work,[0],[0]
"We concentrate on 3 datasets: VQA (Antol et al., 2015), Visual7W (Zhu et al., 2016), and Visual Genome (Krishna et al., 2017).",2 Related Work,[0],[0]
"All of them use images from MSCOCO (Lin et al., 2014).
",2 Related Work,[0],[0]
"Besides the pairs of questions and correct answers, VQA, Visual7W, and visual Madlibs (Yu et al., 2015) provide decoy answers for each pair so that the task can be evaluated in multiple-choice selection accuracy.",2 Related Work,[0],[0]
"What decoy answers to use is the focus of our work.
",2 Related Work,[0],[0]
"In VQA, the decoys consist of human-generated plausible answers as well as high-frequency and random answers from the datasets.",2 Related Work,[0],[0]
"In Visual7W, the decoys are all human-generated plausible ones.",2 Related Work,[0],[0]
"Note that, humans generate those decoys by only looking at the questions and the correct answers but not the images.",2 Related Work,[0],[0]
"Thus, the decoys might be unrelated to the corresponding images.",2 Related Work,[0],[0]
"A learning algorithm can potentially examine the image alone and be able to identify the correct answer.
",2 Related Work,[0],[0]
"In visual Madlibs, the questions are generated with a limited set of question templates and the detailed annotations (e.g., objects) of the images.",2 Related Work,[0],[0]
"Thus, similarly, a learning model can examine the image alone and deduce the correct answer.
",2 Related Work,[0],[0]
"We propose automatic procedures to revise VQA and Visual7W (and to create new datasets based on COCOQA (Ren et al., 2015), VQA2 (Goyal et al., 2017), and Visual Genome) such that the decoy generation is carefully orchestrated to prevent learning algorithms from exploiting the shortcuts in the datasets by overfitting on incidental statistics.",2 Related Work,[0],[0]
"In particular, our design goal is that a learning machine needs to understand all the 3 components of an image-question-candidate answers triplet in order to make the right choice — ignoring either one or two components will result in drastic degradation in performance.
",2 Related Work,[0],[0]
"Our work is inspired by the experiments in (Jabri et al., 2016) where they observe that machines without looking at images or questions can still perform well on the Visual QA task.",2 Related Work,[0],[0]
"Others have also reported similar issues (Goyal et al., 2017; Zhang et al., 2016; Johnson et al., 2017; Agrawal et al., 2016; Kafle and Kanan, 2017a; Agrawal et al., 2018), though not in the multiplechoice setting.",2 Related Work,[0],[0]
"Our work extends theirs by providing more detailed analysis as well as automatic procedures to remedy those design deficiencies.
",2 Related Work,[0],[0]
"Besides Visual QA, VisDial (Das et al., 2017) and Ding et al. (2016) also propose automatic
ways to generate decoys for the tasks of multiplechoice visual captioning and dialog, respectively.
",2 Related Work,[0],[0]
"Recently, Lin and Parikh (2017) study active learning for Visual QA: i.e., how to select informative image-question pairs (for acquiring annotations) or image-question-answer triplets for machines to “learn” from.",2 Related Work,[0],[0]
"On the other hand, our work further focuses on designing better datasets for “evaluating” a machine.",2 Related Work,[0],[0]
"In this section, we examine in detail the dataset Visual7W (Zhu et al., 2016), a popular choice for the Visual QA task.",3 Analysis of Decoy Answers’ Effects,[0],[0]
"We demonstrate how the deficiencies in designing decoy questions impact the performance of learning algorithms.
",3 Analysis of Decoy Answers’ Effects,[0],[0]
"In multiple-choice Visual QA datasets, a training or test example is a triplet that consists of an image I, a question Q, and a candidate answer set A.",3 Analysis of Decoy Answers’ Effects,[0],[0]
"The set A contains a target T (the correct answer) and K decoys (incorrect answers) denoted by D. An IQA triplet is thus {I,Q,A = {T,D1, · · · ,DK}}.",3 Analysis of Decoy Answers’ Effects,[0],[0]
We use C to denote either the target or a decoy.,3 Analysis of Decoy Answers’ Effects,[0],[0]
We investigate how well a learning algorithm can perform when supplied with different modalities of information.,3.1 Visual QA models,[0],[0]
"We concentrate on the one hiddenlayer MLP model proposed in (Jabri et al., 2016), which has achieved state-of-the-art results on the dataset Visual7W.",3.1 Visual QA models,[0],[0]
"The model computes a scoring function f(c, i)
f(c, i) = σ(U",3.1 Visual QA models,[0],[0]
"max(0,W g(c, i))",3.1 Visual QA models,[0],[0]
"+ b) (1)
over a candidate answer c and the multimodal information i, where g is the joint feature of (c, i) and σ(x) = 1/(1 + exp(−x)).",3.1 Visual QA models,[0],[0]
"The information i can be null, the image (I) alone, the question (Q) alone, or the combination of both (I+Q).
",3.1 Visual QA models,[0],[0]
"Given an IQA triplet, we use the penultimate layer of ResNet-200 (He et al., 2016) as visual features to represent I and the average WORD2VEC embeddings (Mikolov et al., 2013) as text features to represent Q and C. To form the joint feature g(c, i), we just concatenate the features together.",3.1 Visual QA models,[0],[0]
The candidate c ∈,3.1 Visual QA models,[0],[0]
"A that has the highest f(c, i) score in prediction is selected as the model output.
",3.1 Visual QA models,[0],[0]
"We use the standard training, validation, and test splits of Visual7W, where each contains 69,817, 28,020, and 42,031 examples respectively.
",3.1 Visual QA models,[0],[0]
Each question has 4 candidate answers.,3.1 Visual QA models,[0],[0]
"The parameters of f(c, i) are learned by minimizing the binary logistic loss of predicting whether or not a candidate c is the target of an IQA triplet.",3.1 Visual QA models,[0],[0]
Details are in Sect.,3.1 Visual QA models,[0],[0]
5 and the Supplementary Material.,3.1 Visual QA models,[0],[0]
"Machines find shortcuts Table 1 summarizes the performance of the learning models, together with the human studies we performed on a subset of 1,000 triplets (c.f. Sect.",3.2 Analysis results,[0],[0]
5 for details).,3.2 Analysis results,[0],[0]
"There are a few interesting observations.
",3.2 Analysis results,[0],[0]
"First, in the row of “A” where only the candidate answers (and whether they are right or wrong) are used to train a learning model, the model performs significantly better than random guessing and humans (52.9% vs. 25%) — humans will deem each of the answers equally likely without looking at both the image and the question!",3.2 Analysis results,[0],[0]
"Note that in this case, the information i in eq. (1) contains nothing.",3.2 Analysis results,[0],[0]
The model learns the specific statistics of the candidate answers in the dataset and exploits those.,3.2 Analysis results,[0],[0]
"Adding the information about the image (i.e., the row of “I+A”), the machine improves significantly and gets close to the performance when all information is used (62.4% vs. 65.7%).",3.2 Analysis results,[0],[0]
There is a weaker correlation between the question and the answers as “Q+A” improves over “A” only modestly.,3.2 Analysis results,[0],[0]
This is expected.,3.2 Analysis results,[0],[0]
"In the Visual7W dataset, the decoys are generated by human annotators as plausible answers to the questions without being shown the images — thus, many decoy answers do not have visual groundings.",3.2 Analysis results,[0],[0]
"For instance, a question of “what animal is running?” elicits equally likely answers such as “dog”, “tiger”, “lion”, or “cat”, while an image of a dog running in the park will immediately rule out all 3 but the “dog”, see Fig. 1 for a similar example.",3.2 Analysis results,[0],[0]
"Thus, the performance of “I+A” implies that many IQA triplets can be solved by object, attribute or concept detection on the image, without understanding the questions.",3.2 Analysis results,[0],[0]
This is indeed the case also for humans — humans can achieve 75.3% by considering “I+A” and not “Q”.,3.2 Analysis results,[0],[0]
"Note that the difference between ma-
chine and human on “I+A” are likely due to their difference in understanding visual information.
",3.2 Analysis results,[0],[0]
"Note that human improves significantly from “I+A” to “I+Q+A” with “Q” added, while the machine does so only marginally.",3.2 Analysis results,[0],[0]
The difference can be attributed to the difference in understanding the question and correlating with the answers between the two.,3.2 Analysis results,[0],[0]
"Since each image corresponds to multiple questions or have multiple objects, solely relying on the image itself will not work well in principle.",3.2 Analysis results,[0],[0]
"Such difference clearly indicates that in the Visual QA model, the language component is weak as the model cannot fully exploit the information in “Q”, making a smaller relative improvement 5.3% (from 62.4% to 65.7%) where humans improved relatively 17.4%.
",3.2 Analysis results,[0],[0]
"Shortcuts are due to design deficiencies We probe deeper on how the decoy answers have impacted the performance of learning models.
",3.2 Analysis results,[0],[0]
"As explained above, the decoys are drawn from all plausible answers to a question, irrespective of whether they are visually grounded or not.",3.2 Analysis results,[0],[0]
"We have also discovered that the targets (i.e., correct answers) are infrequently used as decoys.
",3.2 Analysis results,[0],[0]
"Specifically, among the 69,817 training samples, there are 19,503 unique correct answers and each one of them is used about 3.6 times as correct answers to a question.",3.2 Analysis results,[0],[0]
"However, among all the 69, 817× 3 ≈ 210K decoys, each correct answer appears 7.2 times on average, far below a chance level of 10.7 times (210K÷19, 503 ≈ 10.7).",3.2 Analysis results,[0],[0]
This disparity exists in the test samples too.,3.2 Analysis results,[0],[0]
"Consequently, the following rule, computing each answer’s likelihood of being correct,
P (correct|C) = { 0.5, if C is never seen in training,
# times C as target # times C as target+(# times C as decoys)/K , otherwise,
(2)
should perform well.",3.2 Analysis results,[0],[0]
"Essentially, it measures how unbiased C is used as the target and the decoys.",3.2 Analysis results,[0],[0]
"Indeed, it attains an accuracy of 48.73% on the test data, far better than the random guess and is close to the learning model using the answers’ information only (the “A” row in Table 1).
",3.2 Analysis results,[0],[0]
"Good rules for designing decoys Based on our analysis, we summarize the following guidance rules to design decoys: (1) Question only Unresolvable (QoU).",3.2 Analysis results,[0],[0]
"The decoys need to be equally
plausible to the question.",3.2 Analysis results,[0],[0]
"Otherwise, machines can rely on the correlation between the question and candidate answers to tell the target from decoys, even without the images.",3.2 Analysis results,[0],[0]
Note that this is a principle that is being followed by most datasets.,3.2 Analysis results,[0],[0]
(2) Neutrality.,3.2 Analysis results,[0],[0]
The decoys answers should be equally likely used as the correct answers.,3.2 Analysis results,[0],[0]
(3) Image only Unresolvable (IoU).,3.2 Analysis results,[0],[0]
The decoys need to be plausible to the image.,3.2 Analysis results,[0],[0]
"That is, they should appear in the image, or there exist questions so that the decoys can be treated as targets to the image.",3.2 Analysis results,[0],[0]
"Otherwise, Visual QA can be resolved by objects, attributes, or concepts detection in images, even without the questions.
",3.2 Analysis results,[0],[0]
"Ideally, each decoy in an IQA triplet should meet the three principles.",3.2 Analysis results,[0],[0]
Neutrality is comparably easier to achieve by reusing terms in the whole set of targets as decoys.,3.2 Analysis results,[0],[0]
"On the contrary, a decoy may hardly meet QoU and IoU simultaneously1.",3.2 Analysis results,[0],[0]
"However, as long as all decoys of an IQA triplet meet Neutrality and some meet QoU and others meet IoU, the triplet as a whole still achieves the three principles — a machine ignoring either images or questions will likely perform poorly.",3.2 Analysis results,[0],[0]
"In this section, we describe our approaches of remedying design deficiencies in the existing datasets for the Visual QA task.",4 Creating Better Visual QA Datasets,[0],[0]
We introduce two automatic and widely-applicable procedures to create new decoys that can prevent learning models from exploiting incident statistics in the datasets.,4 Creating Better Visual QA Datasets,[0],[0]
"Main ideas Our procedures operate on a dataset that already contains image-question-target (IQT) triplets, i.e., we do not assume it has decoys already.",4.1 Methods,[0],[0]
"For instance, we have used our procedures to create a multiple-choice dataset from the Visual Genome dataset which has no decoy.",4.1 Methods,[0],[0]
"We assume that each image in the dataset is coupled with “multiple” QT pairs, which is the case in nearly all the existing datasets.",4.1 Methods,[0],[0]
"Given an IQT triplet (I, Q, T), we create two sets of decoy answers.
",4.1 Methods,[0],[0]
• QoU-decoys.,4.1 Methods,[0],[0]
"We search among all other triplets that have similar questions to Q. The targets of those triplets are then collected as the decoys for T. As the targets to similar questions are likely 1E.g., in Fig 1, for the question “What vehicle is pictured?”, the only answer that meets both principles is “train”, which is the correct answer instead of being a decoy.
plausible for the question Q, QoU-decoys likely follow the rules of Neutrality and Question only Unresolvable (QoU).",4.1 Methods,[0],[0]
"We compute the average WORD2VEC (Mikolov et al., 2013) to represent a question, and use the cosine similarity to measure the similarity between questions.
",4.1 Methods,[0],[0]
• IoU-decoys.,4.1 Methods,[0],[0]
"We collect the targets from other triplets of the same image to be the decoys for T. The resulting decoys thus definitely follow the rules of Neutrality and Image only Unresolvable (IoU).
",4.1 Methods,[0],[0]
"We then combine the triplet (I, Q, T) with QoUdecoys and IoU-decoys to form an IQA triplet as a training or test sample.
",4.1 Methods,[0],[0]
"Resolving ambiguous decoys One potential drawback of automatically selected decoys is that they may be semantically similar, ambiguous, or rephrased terms to the target (Zhu et al., 2016).",4.1 Methods,[0],[0]
We utilize two filtering steps to alleviate it.,4.1 Methods,[0],[0]
"First, we perform string matching between a decoy and the target, deleting those decoys that contain or are covered by the target (e.g., “daytime” vs. “during the daytime” and “ponytail” vs. “pony tail”).
",4.1 Methods,[0],[0]
"Secondly, we utilize the WordNet hierarchy and the Wu-Palmer (WUP) score (Wu and Palmer, 1994) to eliminate semantically similar decoys.",4.1 Methods,[0],[0]
"The WUP score measures how similar two word senses are (in the range of [0, 1]), based on the depth of them in the taxonomy and that of their least common subsumer.",4.1 Methods,[0],[0]
"We compute the similarity of two strings according to the WUP scores in a similar manner to (Malinowski and Fritz, 2014), in which the WUP score is used to evaluate Visual QA performance.",4.1 Methods,[0],[0]
We eliminate decoys that have higher WUP-based similarity to the target.,4.1 Methods,[0],[0]
"We use the NLTK toolkit (Bird et al., 2009) to compute the similarity.",4.1 Methods,[0],[0]
"See the Supplementary Material for more details.
",4.1 Methods,[0],[0]
"Other details For QoU-decoys, we sort and keep for each triplet the top N (e.g., 10,000) similar triplets from the entire dataset according to the question similarity.",4.1 Methods,[0],[0]
"Then for each triplet, we compute the WUP-based similarity of each potential decoy to the target successively, and accept those with similarity below 0.9 until we have K decoys.",4.1 Methods,[0],[0]
"We choose 0.9 according to (Malinowski and Fritz, 2014).",4.1 Methods,[0],[0]
We also perform such a check among selected decoys to ensure they are not very similar to each other.,4.1 Methods,[0],[0]
"For IoU-decoys, the potential decoys are sorted randomly.",4.1 Methods,[0],[0]
"The WUP-based
similarity with a threshold of 0.9 is then applied to remove ambiguous decoys.",4.1 Methods,[0],[0]
"Several authors have noticed the design deficiencies in the existing databases and have proposed “fixes” (Antol et al., 2015; Yu et al., 2015; Zhu et al., 2016; Das et al., 2017).",4.2 Comparison to other datasets,[0],[0]
No dataset has used a procedure to generate IoU-decoys.,4.2 Comparison to other datasets,[0],[0]
"We empirically show that how the IoU-decoys significantly remedy the design deficiencies in the datasets.
",4.2 Comparison to other datasets,[0],[0]
Several previous efforts have generated decoys that are similar in spirit to our QoU-decoys.,4.2 Comparison to other datasets,[0],[0]
"Yu et al. (2015), Das et al. (2017), and Ding et al. (2016) automatically find decoys from similar questions or captions based on question templates and annotated objects, tri-grams and GLOVE embeddings (Pennington et al., 2014), and paragraph vectors (Le and Mikolov, 2014) and linguistic surface similarity, respectively.",4.2 Comparison to other datasets,[0],[0]
"The later two are for different tasks from Visual QA, and only Ding et al. (2016) consider removing semantically ambiguous decoys like ours.",4.2 Comparison to other datasets,[0],[0]
"Antol et al. (2015) and Zhu et al. (2016) ask humans to create decoys, given the questions and targets.",4.2 Comparison to other datasets,[0],[0]
"As shown earlier, such decoys may disobey the rule of Neutrality.
",4.2 Comparison to other datasets,[0],[0]
"Goyal et al. (2017) augment the VQA dataset (Antol et al., 2015) (by human efforts) with additional IQT triplets to eliminate the shortcuts (language prior) in the open-ended setting.",4.2 Comparison to other datasets,[0],[0]
Their effort is complementary to ours on the multiplechoice setting.,4.2 Comparison to other datasets,[0],[0]
"Note that an extended task of Visual QA, visual dialog (Das et al., 2017), also adopts the latter setting.",4.2 Comparison to other datasets,[0],[0]
We examine our automatic procedures for creating decoys on five datasets.,5.1 Dataset,[0],[0]
"Table 2 summarizes the characteristics of the three datasets we focus on.
",5.1 Dataset,[0],[0]
"VQA Real (Antol et al., 2015)",5.1 Dataset,[0],[0]
"The dataset uses images from MSCOCO (Lin et al., 2014) under the same training/validation/testing splits to construct IQA triplets.",5.1 Dataset,[0],[0]
"Totally 614,163 IQA triplets are generated for 204,721 images.",5.1 Dataset,[0],[0]
"Each question has 18 candidate answers: in general 3 decoys are human-generated, 4 are randomly sampled, and 10 are randomly sampled frequent-occurring targets.",5.1 Dataset,[0],[0]
"As the test set does not indicate the targets, our studies focus on the training and validation sets.
",5.1 Dataset,[0],[0]
"Visual7W Telling (Visual7W) (Zhu et al., 2016)",5.1 Dataset,[0],[0]
"The dataset uses 47,300 images from MSCOCO (Lin et al., 2014) and contains 139,868 IQA triplets.",5.1 Dataset,[0],[0]
"Each has 3 decoys generated by humans.
",5.1 Dataset,[0],[0]
"Visual Genome (VG) (Krishna et al., 2017)",5.1 Dataset,[0],[0]
"The dataset uses 101,174 images from MSCOCO (Lin et al., 2014) and contains 1,445,322 IQT triplets.",5.1 Dataset,[0],[0]
No decoys are provided.,5.1 Dataset,[0],[0]
Human annotators are asked to write diverse pairs of questions and answers freely about an image or with respect to some regions of it.,5.1 Dataset,[0],[0]
On average an image is coupled with 14 question-answer pairs.,5.1 Dataset,[0],[0]
We divide the dataset into non-overlapping 50%/20%/30% for training/validation/testing.,5.1 Dataset,[0],[0]
"Additionally, we partition such that each portion is a “superset” of the corresponding one in Visual7W, respectively.
",5.1 Dataset,[0],[0]
"VQA2 (Goyal et al., 2017) and COCOQA (Ren et al., 2015)",5.1 Dataset,[0],[0]
"We describe the datasets and experimental results in the Supplementary Material.
",5.1 Dataset,[0],[0]
"Creating decoys We create 3 QoU-decoys and 3 IoU-decoys for every IQT triplet in each dataset, following the steps in Sect.",5.1 Dataset,[0],[0]
4.1.,5.1 Dataset,[0],[0]
"In the cases that we cannot find 3 decoys, we include random ones from the original set of decoys for VQA and Visual7W; for other datasets, we randomly include those from the top 10 frequently-occurring targets.",5.1 Dataset,[0],[0]
Visual QA models We utilize the MLP models mentioned in Sect.,5.2 Setup,[0],[0]
3 for all the experiments.,5.2 Setup,[0],[0]
"We denote MLP-A, MLP-QA, MLP-IA, MLPIQA",5.2 Setup,[0],[0]
"as the models using A (Answers only), Q+A (Question plus Answers), I+A (Image plus Answers), and I+Q+A (Image, Question and Answers) for multimodal information, respectively.",5.2 Setup,[0],[0]
"The hidden-layer has 8,192 neurons.",5.2 Setup,[0],[0]
"We use a 200-layer ResNet (He et al., 2016) to compute visual features which are 2,048-dimensional.",5.2 Setup,[0],[0]
"The ResNet is pre-trained on ImageNet (Russakovsky et al., 2015).",5.2 Setup,[0],[0]
"The WORD2VEC feature (Mikolov et al., 2013) for questions and answers are 300- dimensional, pre-trained on Google News2.",5.2 Setup,[0],[0]
"The
2We experiment on using different features in the Supplementary Material.
parameters of the MLP models are learned by minimizing the binary logistic loss of predicting whether or not a candidate answer is the target of the corresponding IQA triplet.",5.2 Setup,[0],[0]
"Please see the Supplementary Material for details on optimization.
",5.2 Setup,[0],[0]
"We further experiment with a variant of the spatial memory network (denoted as Attention) (Xu and Saenko, 2016) and the HieCoAtt model (Lu et al., 2016) adjusted for the multiple-choice setting.",5.2 Setup,[0],[0]
Both models utilize the attention mechanism.,5.2 Setup,[0],[0]
"Details are listed in the Supplementary Material.
",5.2 Setup,[0],[0]
"Evaluation metric For VQA and VQA2, we follow their protocols by comparing the picked answer to 10 human-generated targets.",5.2 Setup,[0],[0]
The accuracy is computed based on the number of exactly matched targets (divided by 3 and clipped at 1).,5.2 Setup,[0],[0]
"For others, we compute the accuracy of picking the target from multiple choices.
",5.2 Setup,[0],[0]
"Decoy sets to compare For each dataset, we derive several variants: (1) Orig: the original decoys from the datasets, (2)",5.2 Setup,[0],[0]
QoU:,5.2 Setup,[0],[0]
"Orig replaced with ones selected by our QoU-decoys generating procedure, (3) IoU:",5.2 Setup,[0],[0]
"Orig replaced with ones selected by our IoU-decoys generating procedure, (4) QoU +IoU:",5.2 Setup,[0],[0]
"Orig replaced with ones combining QoU and IoU, (5) All: combining Orig, QoU, and IoU.
User studies Automatic decoy generation may lead to ambiguous decoys as mentioned in Sect.",5.2 Setup,[0],[0]
"4 and (Zhu et al., 2016).",5.2 Setup,[0],[0]
We conduct a user study via Amazon Mechanic Turk (AMT) to test humans’ performance on the datasets after they are remedied by our automatic procedures.,5.2 Setup,[0],[0]
"We select 1,000 IQA triplets from each dataset.",5.2 Setup,[0],[0]
Each triplet is answered by three workers and in total 169 workers get involved.,5.2 Setup,[0],[0]
The total cost is $215 — the rate for every 20 triplets is $0.25.,5.2 Setup,[0],[0]
We report the average human performance and compare it to the learning models’.,5.2 Setup,[0],[0]
See the Supplementary Material for more details.,5.2 Setup,[0],[0]
"The performances of learning models and humans on the 3 datasets are reported in Table 3, 4, and 53.
",5.3 Results,[0],[0]
"3We note that in Table 3, the 4.3% drop of the human performance on IoU +QoU, compared to Orig, is likely due to that IoU",5.3 Results,[0],[0]
+QoU has more candidates (7 per question).,5.3 Results,[0],[0]
"Besides, the human performance on qaVG cannot be directly compared to that on the other datasets, since the questions on qaVG tend to focus on local image regions and are considered harder.
",5.3 Results,[0],[0]
"Effectiveness of new decoys A better set of decoys will force learning models to integrate all 3 pieces of information — images, questions and answers — to make the correct selection from multiple-choices.",5.3 Results,[0],[0]
"In particular, they should prevent learning algorithms from exploiting shortcuts such that partial information is sufficient for performing well on the Visual QA task.
",5.3 Results,[0],[0]
Table 3 clearly indicates that those goals have been achieved.,5.3 Results,[0],[0]
"With the Orig decoys, the relatively small gain from MLP-IA to MLP-IQA suggests that the question information can be ignored to attain good performance.",5.3 Results,[0],[0]
"However, with the IoU-decoys which require questions to help to resolve (as image itself is inadequate to resolve), the gain is substantial (from 27.3% to 84.1%).",5.3 Results,[0],[0]
"Likewise, with the QoU-decoys (question itself is not adequate to resolve), including images information improves from 40.7% (MLP-QA) substantially to 57.6% (MLP-IQA).",5.3 Results,[0],[0]
"Note that with the Orig decoys, this gain is smaller (58.2% vs. 65.7%).
",5.3 Results,[0],[0]
"It is expected that MLP-IA matches better QoUdecoys but not IoU-decoys, and MLP-QA is the other way around.",5.3 Results,[0],[0]
Thus it is natural to combine these two decoys.,5.3 Results,[0],[0]
What is particularly appealing is that MLP-IQA improves noticeably over models learned with partial information on the combined IoU,5.3 Results,[0],[0]
+QoU-decoys (and “All” decoys4).,5.3 Results,[0],[0]
"Furthermore, using answer information only (MLP-A) attains about the chance-level accuracy.
",5.3 Results,[0],[0]
"On the VQA dataset (Table 4), the same observations hold, though to a lesser degree.",5.3 Results,[0],[0]
"On any of the IoU or QoU columns, we observe substan-
4We note that the decoys in Orig are not trivial, which can be seen from the gap between All and IoU +QoU.",5.3 Results,[0],[0]
"Our main concern on Orig is that for those questions that machines can accurately answer, they mostly rely on only partial information.",5.3 Results,[0],[0]
This will thus hinder designing machines to fully comprehend and reason from multimodal information.,5.3 Results,[0],[0]
"We further experiment on random decoys, which can achieve Neutrality but not the other two principles, to demonstrate the effectiveness of our methods in the Supplementary Material.
tial gains when the complementary information is added to the model (such as MLP-IA to MLPIQA).",5.3 Results,[0],[0]
"All these improvements are much more visible than those observed on the original decoy sets.
",5.3 Results,[0],[0]
"Combining both Table 3 and 4, we notice that the improvements from MLP-QA to MLP-IQA tend to be lower when facing IoU-decoys.",5.3 Results,[0],[0]
This is also expected as it is difficult to have decoys that are simultaneously both IoU and QoU — such answers tend to be the target answers.,5.3 Results,[0],[0]
"Nonetheless, we deem this as a future direction to explore.
",5.3 Results,[0],[0]
"Differences across datasets Contrasting Visual7W to VQA (on the column IoU +QoU), we notice that Visual7W tends to have bigger improvements in general.",5.3 Results,[0],[0]
"This is due to the fact that VQA has many questions with “Yes” or “No” as the targets — the only valid decoy to the target “Yes” is “No”, and vice versa.",5.3 Results,[0],[0]
"As such decoys are already captured by Orig of VQA (‘Yes” and “No” are both top frequently-occurring targets), adding other decoy answers will not make any noticeable improvement.",5.3 Results,[0],[0]
"In Supplementary Material, however, we show that once we remove such questions/answers pairs, the degree of improvements increases substantially.
",5.3 Results,[0],[0]
"Comparison on Visual QA models As presented in Table 3 and 4, MLP-IQA is on par with or even outperforms Attention and HieCoAtt on the Orig decoys, showing how the shortcuts make
it difficult to compare different models.",5.3 Results,[0],[0]
"By eliminating the shortcuts (i.e., on the combined IoU +QoU-decoys), the advantage of using sophisticated models becomes obvious (Attention outperforms MLP-IQA by 3% in Table 4), indicating the importance to design advanced models for achieving human-level performance on Visual QA.
",5.3 Results,[0],[0]
"For completeness, we include the results on the Visual Genome dataset in Table 5.",5.3 Results,[0],[0]
"This dataset has no “Orig” decoys, and we have created a multiplechoice based dataset qaVG from it for the task — it has over 1 million triplets, the largest dataset on this task to our knowledge.",5.3 Results,[0],[0]
"On the combined IoU +QoU-decoys, we again clearly see that machines need to use all the information to succeed.
",5.3 Results,[0],[0]
"With qaVG, we also investigate whether it can help improve the multiple-choice performances on the other two datasets.",5.3 Results,[0],[0]
We use the MLP-IQA trained on qaVG with both IoU and QoU decoys to initialize the models for the Visual7W and VQA datasets.,5.3 Results,[0],[0]
"We report the accuracies before and after fine-tuning, together with the best results learned solely on those two datasets.",5.3 Results,[0],[0]
"As shown in Table 6, fine-tuning largely improves the performance, justifying the finding by Fukui et al. (2016).",5.3 Results,[0],[0]
"In Fig. 2, we present examples of image-questiontarget triplets from V7W, VQA, and VG, together with our IoU-decoys (A, B, C) and QoU-decoys (D, E, F).",5.4 Qualitative Results,[0],[0]
G is the target.,5.4 Qualitative Results,[0],[0]
The predictions by the corresponding MLP-IQA are also included.,5.4 Qualitative Results,[0],[0]
"Ignoring information from images or questions makes it extremely challenging to answer the triplet correctly, even for humans.
",5.4 Qualitative Results,[0],[0]
"Our automatic procedures do fail at some triplets, resulting in ambiguous decoys to the targets.",5.4 Qualitative Results,[0],[0]
See Fig. 3 for examples.,5.4 Qualitative Results,[0],[0]
"We categorized those failure cases into two situations.
",5.4 Qualitative Results,[0],[0]
• Our filtering steps in Sect.,5.4 Qualitative Results,[0],[0]
"4 fail, as observed in the top example.",5.4 Qualitative Results,[0],[0]
"The WUP-based similarity re-
lies on the WordNet hierarchy.",5.4 Qualitative Results,[0],[0]
"For some semantically similar words like “lady” and “woman”, the similarity is only 0.632, much lower than that of 0.857 between “cat” and “dog”.",5.4 Qualitative Results,[0],[0]
"This issue can be alleviated by considering alternative semantic measures by WORD2VEC or by those used in (Das et al., 2017; Ding et al., 2016) for searching similar questions.
",5.4 Qualitative Results,[0],[0]
• The question is ambiguous to answer.,5.4 Qualitative Results,[0],[0]
"In the bottom example in Fig. 3, both candidates D and F seem valid as a target.",5.4 Qualitative Results,[0],[0]
Another representative case is when asked about the background of a image.,5.4 Qualitative Results,[0],[0]
"In images that contain sky and mountains in the distance, both terms can be valid.",5.4 Qualitative Results,[0],[0]
We perform detailed analysis on existing datasets for multiple-choice Visual QA.,6 Conclusion,[0],[0]
We found that the design of decoys can inadvertently provide “shortcuts” for machines to exploit to perform well on the task.,6 Conclusion,[0],[0]
"We describe several principles of constructing good decoys and propose automatic pro-
cedures to remedy existing datasets and create new ones.",6 Conclusion,[0],[0]
We conduct extensive empirical studies to demonstrate the effectiveness of our methods in creating better Visual QA datasets.,6 Conclusion,[0],[0]
The remedied datasets and the newly created ones are released and available at http://www.teds. usc.edu/website_vqa/.,6 Conclusion,[0],[0]
"This work is partially supported by USC Graduate Fellowship, NSF IIS-1065243, 1451412, 1513966/1632803, 1208500, CCF-1139148, a Google Research Award, an Alfred.",Acknowledgments,[0],[0]
P. Sloan Research Fellowship and ARO# W911NF-12-1-0241 and W911NF-15-1-0484.,Acknowledgments,[0],[0]
"Visual question answering (Visual QA) has attracted a lot of attention lately, seen essentially as a form of (visual) Turing test that artificial intelligence should strive to achieve.",abstractText,[0],[0]
"In this paper, we study a crucial component of this task: how can we design good datasets for the task?",abstractText,[0],[0]
We focus on the design of multiplechoice based datasets where the learner has to select the right answer from a set of candidate ones including the target (i.e. the correct one) and the decoys (i.e. the incorrect ones).,abstractText,[0],[0]
"Through careful analysis of the results attained by state-of-the-art learning models and human annotators on existing datasets, we show that the design of the decoy answers has a significant impact on how and what the learning models learn from the datasets.",abstractText,[0],[0]
"In particular, the resulting learner can ignore the visual information, the question, or both while still doing well on the task.",abstractText,[0],[0]
"Inspired by this, we propose automatic procedures to remedy such design deficiencies.",abstractText,[0],[0]
"We apply the procedures to re-construct decoy answers for two popular Visual QA datasets as well as to create a new Visual QA dataset from the Visual Genome project, resulting in the largest dataset for this task.",abstractText,[0],[0]
Extensive empirical studies show that the design deficiencies have been alleviated in the remedied datasets and the performance on them is likely a more faithful indicator of the difference among learning models.,abstractText,[0],[0]
The datasets are released and publicly available via http://www.teds. usc.edu/website_vqa/.,abstractText,[0],[0]
Being Negative but Constructively: Lessons Learnt from Creating Better Visual Question Answering Datasets,title,[0],[0]
Robust statistics was founded in the seminal works of [Tuk60] and [Hub64].,1 Introduction,[0],[0]
"The overarching motto is that any model (especially a parametric one) is only approximately valid, and that any estimator designed for a particular distribution that is to be used in practice must also be stable in the presence of model misspecification.",1 Introduction,[0],[0]
"The standard setup is to assume that the samples we are given come from a nice distribution, but that an adversary has the power to arbitrarily corrupt a constant fraction of the observed data.",1 Introduction,[0],[0]
"After several decades of work, the robust statistics community has discovered a myriad of estimators that are provably robust.",1 Introduction,[0],[0]
"An important feature of this line of work is that it can tolerate a constant fraction of corruptions independent of the dimension and that there are estimators for both the location (e.g., the mean) and scale (e.g., the covariance).",1 Introduction,[0],[0]
"See [HR09] and [HRRS86] for further background.
",1 Introduction,[0],[0]
"It turns out that there are vast gaps in our understanding of robustness, when computational considerations are taken into account.",1 Introduction,[0],[0]
"In one dimension, robustness and computational efficiency are in perfect
∗A version of this paper appeared in ICML 2017",1 Introduction,[0],[0]
"[DKK+17]. †Supported by NSF CAREER Award CCF-1652862, a Sloan Research Fellowship, and a Google Faculty Research Award.",1 Introduction,[0],[0]
"‡Supported by NSF CCF-1551875, CCF-1617730, CCF-1650733, and ONR N00014-12-1-0999.",1 Introduction,[0],[0]
§Supported by NSF CAREER Award CCF-1553288 and a Sloan Research Fellowship.,1 Introduction,[0],[0]
"¶Supported by NSF CAREER Award CCF-1453261, a Google Faculty Research Award, and an NSF Fellowship.",1 Introduction,[0],[0]
"‖Supported by NSF CAREER Award CCF-1453261, a grant from the MIT NEC Corporation, and a Google Faculty Research
Award.",1 Introduction,[0],[0]
"∗∗Research supported by a USC startup grant.
",1 Introduction,[0],[0]
Authors are in alphabetical order.,1 Introduction,[0],[0]
"Code of our implementation is available at https://github.com/hoonose/robust-filter.
",1 Introduction,[0],[0]
"ar X
iv :1
70 3.
00 89
3v 4
[ cs
.L",1 Introduction,[0],[0]
"G
] 1
3 M
harmony.",1 Introduction,[0],[0]
"The empirical mean and empirical variance are not robust, because a single corruption can arbitrarily bias these estimates, but alternatives such as the median and the interquartile range are straightforward to compute and are provably robust.
",1 Introduction,[0],[0]
"But in high dimensions, there is a striking tension between robustness and computational efficiency.",1 Introduction,[0],[0]
Let us consider estimators for location.,1 Introduction,[0],[0]
The Tukey median [Tuk60] is a natural generalization of the onedimensional median to high-dimensions.,1 Introduction,[0],[0]
"It is known that it behaves well (i.e., it needs few samples) when estimating the mean for various symmetric distributions [DG92, CGR16].",1 Introduction,[0],[0]
"However, it is hard to compute in general [JP78, AK95] and the many heuristics for computing it degrade badly in the quality of their approximation as the dimension scales [CEM+93, Cha04, MS10].",1 Introduction,[0],[0]
The same issues plague estimators for scale.,1 Introduction,[0],[0]
"The minimum volume ellipsoid [Rou85] is a natural generalization of the one-dimensional interquartile range and is provably robust in high-dimensions, but is also hard to compute.",1 Introduction,[0],[0]
"And once again, heuristics for computing it [VAR09, RS98] work poorly in high dimensions.
",1 Introduction,[0],[0]
The fact that robustness in high dimensions seems to come at such a steep price has long been a point of consternation within robust statistics.,1 Introduction,[0],[0]
"In a 1997 retrospective on the development of robust statistics [Hub97], Huber laments:
“It is one thing to design a theoretical algorithm whose purpose is to prove [large fractions of corruptions can be tolerated] and quite another thing to design a practical version that can be used not merely on small, but also on medium sized regression problems, with a 2000 by 50 matrix or so.",1 Introduction,[0],[0]
"This last requirement would seem to exclude all of the recently proposed [techniques].”
",1 Introduction,[0],[0]
"The goal of this paper is to answer Huber’s call to action and design estimators for both the mean and covariance that are highly practical, provably robust, and work in high-dimensions.",1 Introduction,[0],[0]
"Such estimators make the promise of robust statistics – estimators that work in high-dimensions and guarantee that their output has not been heavily biased by some small set of noisy samples – much closer to a reality.
",1 Introduction,[0],[0]
"First, we make some remarks to dispel some common misconceptions.",1 Introduction,[0],[0]
"There has been a considerable amount of recent work on robust principal component analysis, much of it making use of semidefinite programming.",1 Introduction,[0],[0]
"Some of these works can tolerate a constant fraction of corruptions [CLMW11], however require that the locations of the corruptions are evenly spread throughout the dataset so that no individual sample is entirely corrupted.",1 Introduction,[0],[0]
"In contrast, the usual models in robust statistics are quite rigid in what they require and they do this for good reason.",1 Introduction,[0],[0]
"A common scenario that is used to motivate robust statistical methods is if two studies are mixed together, and one subpopulation does not fit the model.",1 Introduction,[0],[0]
"Then one wants estimators that work without assuming anything at all about these outliers.
",1 Introduction,[0],[0]
There have also been semidefinite programming methods proposed for robust principal component analysis with outliers [XCS10].,1 Introduction,[0],[0]
"These methods assume that the uncorrupted matrix is rank r and that the fraction of outliers is at most 1/r, which again degrades badly as the rank of the matrix increases.",1 Introduction,[0],[0]
"Moreover, any method that uses semidefinite programming will have difficulty scaling to the sizes of the problems we consider here.",1 Introduction,[0],[0]
For sake of comparison – even with state-of-the-art interior point methods – it is not currently feasible to solve the types of semidefinite programs that have been proposed when the matrices have dimension larger than a hundred.,1 Introduction,[0],[0]
Recent works in theoretical computer science have sought to circumvent the usual difficulties of designing efficient and robust algorithms by instead working in a generative model.,1.1 Robustness in a Generative Model,[0],[0]
"The starting point for our paper is the work of [DKK+16] who gave an efficient algorithm for the problem of agnostically learning a Gaussian:
Given a polynomial number of samples from a high-dimensional Gaussian N (µ,Σ), where an adversary has arbitrarily corrupted an ε-fraction, find a set of parameters N ′(µ̂, Σ̂) that satisfy dTV (N ,N ′) ≤",1.1 Robustness in a Generative Model,[0],[0]
"Õ(ε)∗.
Total variation distance is the natural metric to use to measure closeness of the parameters, since a (1− ε)-fraction of the observed samples came from a Gaussian.",1.1 Robustness in a Generative Model,[0],[0]
"[DKK+16] gave an algorithm for the above ∗We use the notation Õ(·) to hide factors which are polylogarithmic in the argument – in particular, we note that this bound does not depend on the dimension.
problem (note that the guarantees are dimension independent), whose running time and sample complexity are polynomial in the dimension d and 1/ε.",1.1 Robustness in a Generative Model,[0],[0]
"[LRV16] independently gave an algorithm for the unknown mean case that achieves dTV (N ,N ′) ≤ Õ(ε √
log d), and in the unknown covariance case achieves guarantees in a weaker metric that is not affine invariant.",1.1 Robustness in a Generative Model,[0],[0]
"A crucial feature is that both algorithms work even when the moments of the underlying distribution satisfy certain conditions, and thus are not necessarily brittle to the modeling assumption that the inliers come from a Gaussian distribution.
",1.1 Robustness in a Generative Model,[0],[0]
A more conceptual way to view such work is as a proof-of-concept that the Tukey median and minimum volume ellipsoid can be computed efficiently in a natural family of distributional models.,1.1 Robustness in a Generative Model,[0],[0]
"This follows because not only would these be good estimates for the mean and covariance in the above model, but in fact any estimates that are good must also be close to them.",1.1 Robustness in a Generative Model,[0],[0]
"Thus, these works fit into the emerging research direction of circumventing worst-case lower bounds by going beyond worst-case analysis.
",1.1 Robustness in a Generative Model,[0],[0]
"Since the dissemination of the aforementioned works [DKK+16, LRV16], there has been a flurry of research activity on computationally efficient robust estimation in a variety of high-dimensional settings [DKS16, DKS17, CSV17, DKK+17, Li17, DBS17, BDLS17, SCV18, DKK+18], including studying graphical distributional models [DKS16], understanding the computation-robustness tradeoff for statistical query algorithms [DKS17], tolerating much more noise by allowing the algorithm to output a list of candidate hypotheses [CSV17], and developing robust algorithms under sparsity assumptions",1.1 Robustness in a Generative Model,[0],[0]
"[Li17, DBS17, BDLS17], where the number of samples is sublinear in the dimension.",1.1 Robustness in a Generative Model,[0],[0]
Our goal in this work is to show that high-dimensional robust estimation can be highly practical.,1.2 Our Results,[0],[0]
"However, there are two major obstacles to achieving this.",1.2 Our Results,[0],[0]
"First, the sample complexity and running time of the algorithms in [DKK+16] is prohibitively large for high-dimensional applications.",1.2 Our Results,[0],[0]
"We just would not be able to store as many samples as we would need, in order to compute accurate estimates, in high-dimensional applications.
",1.2 Our Results,[0],[0]
Our first main contribution is to show essentially tight bounds on the sample complexity of the filtering based algorithm of [DKK+16].,1.2 Our Results,[0],[0]
"Roughly speaking, we accomplish this with a new definition of the good set which plugs into the existing analysis in a straightforward manner and shows that it is possible to estimate the mean with Õ(d/ε2) samples (when the covariance is known) and the covariance with Õ(d2/ε2) samples.",1.2 Our Results,[0],[0]
"Both of these bounds are information-theoretically optimal, up to logarithmic factors.
",1.2 Our Results,[0],[0]
Our second main contribution is to vastly improve the fraction of adversarial corruptions that can be tolerated in applications.,1.2 Our Results,[0],[0]
"The fraction of errors that the algorithms of [DKK+16] can tolerate is indeed a constant that is independent of the dimension, but it is very small both in theory and in practice.",1.2 Our Results,[0],[0]
This is due to the fact that many of the steps in the algorithm are overly conservative.,1.2 Our Results,[0],[0]
"In fact, we found that a naive implementation of the algorithm did not remove any outliers in many realistic scenarios.",1.2 Our Results,[0],[0]
We combat this by giving new ways to empirically tune the threshold for where to remove points from the sample set.,1.2 Our Results,[0],[0]
"These optimizations dramatically improve the empirical performance.
",1.2 Our Results,[0],[0]
"Finally, we show that the same bounds on the error guarantee continue to work even when the underlying distribution is sub-Gaussian.",1.2 Our Results,[0],[0]
This theoretically confirms that the robustness guarantees of such algorithms are in fact not overly brittle to the distributional assumptions.,1.2 Our Results,[0],[0]
"In fact, the filtering algorithm of [DKK+16] is easily shown to be robust under much weaker distributional assumptions, while retaining near-optimal sample and error guarantees.",1.2 Our Results,[0],[0]
"As an example, we show that it yields a near sample-optimal efficient estimator for robustly estimating the mean of a distribution, under the assumption that its covariance is bounded.",1.2 Our Results,[0],[0]
"Even in this regime, the filtering algorithm guarantees optimal error, up to a constant factor.",1.2 Our Results,[0],[0]
"Furthermore we empirically corroborate this finding by showing that the algorithm works well on real world data, as we describe below.
",1.2 Our Results,[0],[0]
Now we come to the task of testing out our algorithms.,1.2 Our Results,[0],[0]
"To the best of our knowledge, there have been no experimental evaluations of the performance of the myriad of approaches to robust estimation.",1.2 Our Results,[0],[0]
"It remains mostly a mystery which ones perform well in high-dimensions, and which do not.",1.2 Our Results,[0],[0]
"To test out our algorithms, we design a synthetic experiment where a (1 − ε)-fraction of the samples come from a Gaussian and the rest are noise and sampled from another distribution (in many cases, Bernoulli).",1.2 Our Results,[0],[0]
"This gives us a baseline to compare how well various algorithms recover µ and Σ, and how their performance degrades based on the dimension.",1.2 Our Results,[0],[0]
"Our plots show a predictable and yet striking phenomenon: All earlier approaches have error
rates that scale polynomially with the dimension and ours is a constant that is almost indistinguishable from the error that comes from sample noise alone.",1.2 Our Results,[0],[0]
"Moreover, our algorithms are able to scale to hundreds of dimensions.
",1.2 Our Results,[0],[0]
But are algorithms for agnostically learning a Gaussian unduly sensitive to the distributional assumptions they make?,1.2 Our Results,[0],[0]
We are able to give an intriguing visual demonstration of our techniques on real data.,1.2 Our Results,[0],[0]
The famous study of [NJB+08] showed that performing principal component analysis on a matrix of genetic data recovers a map of Europe.,1.2 Our Results,[0],[0]
"More precisely, the top two singular vectors define a projection into the plane and when the groups of individuals are color-coded with where they are from, we recover familiar country boundaries that corresponds to the map of Europe.",1.2 Our Results,[0],[0]
The conclusion from their study was that genes mirror geography.,1.2 Our Results,[0],[0]
"Given that one of the most important applications of robust estimation ought to be in exploratory data analysis, we ask: To what extent can we recover the map of Europe in the presence of noise?",1.2 Our Results,[0],[0]
"We show that when a small number of corrupted samples are added to the dataset, the picture becomes entirely distorted (and this continues to hold even for many other methods that have been proposed).",1.2 Our Results,[0],[0]
"In contrast, when we run our algorithm, we are able to once again recover the map of Europe.",1.2 Our Results,[0],[0]
"Thus, even when some fraction of the data has been corrupted (e.g., medical studies were pooled together even though the subpopulations studied were different), it is still possible to perform principal component analysis and recover qualitatively similar conclusions as if there were no noise at all!",1.2 Our Results,[0],[0]
Notation.,2 Formal Framework,[0],[0]
"For a vector v, we will let ‖v‖2 denote its Euclidean norm.",2 Formal Framework,[0],[0]
"If M is a matrix, we will let ‖M‖2 denote its spectral norm and ‖M‖F denote its Frobenius norm.",2 Formal Framework,[0],[0]
"We will write X ∈u S to denote that X is drawn from the empirical distribution defined by S.
Robust Estimation.",2 Formal Framework,[0],[0]
"We consider the following powerful model of robust estimation that generalizes many other existing models, including Huber’s contamination model:
Definition 2.1.",2 Formal Framework,[0],[0]
"Given ε > 0 and a distribution family D, the adversary operates as follows:",2 Formal Framework,[0],[0]
"The algorithm specifies some number of samples m. The adversary generates m samples X1, X2, . . .",2 Formal Framework,[0],[0]
",",2 Formal Framework,[0],[0]
Xm from some (unknown) D ∈ D.,2 Formal Framework,[0],[0]
It then draws m′ from an appropriate distribution.,2 Formal Framework,[0],[0]
"This distribution is allowed to depend on X1, X2, . . .",2 Formal Framework,[0],[0]
", Xm, but when marginalized over the m samples satisfies m
′",2 Formal Framework,[0],[0]
"∼ Bin(ε,m).",2 Formal Framework,[0],[0]
"The adversary is allowed to inspect the samples, removes m′ of them, and replaces them with arbitrary points.",2 Formal Framework,[0],[0]
"The set of m points is then given to the algorithm.
",2 Formal Framework,[0],[0]
"In summary, the adversary is allowed to inspect the samples before corrupting them, both by adding corrupted points and deleting uncorrupted points.",2 Formal Framework,[0],[0]
"In contrast, in Huber’s model the adversary is oblivious to the samples and is only allowed to add corrupted points.
",2 Formal Framework,[0],[0]
We remark that there are no computational restrictions on the adversary.,2 Formal Framework,[0],[0]
The goal is to return the parameters of a distribution D̂ in D that are close to the true parameters in an appropriate metric.,2 Formal Framework,[0],[0]
"For the case of the mean, our metric will be the Euclidean distance.",2 Formal Framework,[0],[0]
"For the covariance, we will use the Mahalanobis distance, i.e., ‖Σ−1/2Σ̂Σ−1/2",2 Formal Framework,[0],[0]
− I‖F .,2 Formal Framework,[0],[0]
"This is a strong affine invariant distance that implies corresponding bounds in total variation distance.
",2 Formal Framework,[0],[0]
"We will use the following terminology:
Definition 2.2.",2 Formal Framework,[0],[0]
We say that a set of samples is ε-corrupted if it is generated by the process described in Definition 2.1.,2 Formal Framework,[0],[0]
"In this section, we present near sample-optimal efficient robust estimators for the mean and the covariance of high-dimensional distributions under various structural assumptions of varying strength.",3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
"Our estimators rely on the filtering technique introduced in [DKK+16].
",3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
"We note that [DKK+16] gave two algorithmic techniques: the first one was a spectral technique to iteratively remove outliers from the dataset (filtering), and the second one was a soft-outlier removal method relying on convex programming.",3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
"The filtering technique seemed amenable to practical implementation (as
it only uses simple eigenvalue computations), but the corresponding sample complexity bounds given in [DKK+16] are polynomially worse than the information-theoretic minimum.",3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
"On the other hand, the convex programming technique of [DKK+16] achieved better sample complexity bounds (e.g., near sample-optimal for robust mean estimation), but relied on the ellipsoid method, which seemed to preclude a practically efficient implementation.
",3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
"In this work, we achieve the best of both worlds: we provide a more careful analysis of the filter technique that yields sample-optimal bounds (up to logarithmic factors) for both the mean and the covariance.",3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
"Moreover, we show that the filtering technique easily extends to much weaker distributional assumptions (e.g., under bounded second moments).",3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
"Roughly speaking, the filtering technique follows a general iterative recipe: (1) via spectral methods, find some univariate test which is violated by the corrupted points, (2) find some concrete tail bound violated by the corrupted set of points, and (3) throw away all points which violate this tail bound.
",3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
We start with sub-gaussian distributions.,3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
Recall that if P is sub-gaussian on Rd with mean vector µ and parameter ν,3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
"> 0,",3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
then for any unit vector v ∈,3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
Rd,3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
we have that PrX∼P,3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
"[|v · (X − µ)| ≥ t] ≤ exp(−t2/2ν).
",3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
Theorem 3.1.,3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
"Let G be a sub-gaussian distribution on Rd with parameter ν = Θ(1), mean µG, covariance matrix I, and ε > 0.",3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
Let S be an ε-corrupted set of samples from G of size Ω((d/ε2) poly log(d/ε)).,3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
"There exists an efficient algorithm that, on input S and ε > 0, returns a mean vector µ̂ so that with probability at least 9/10 we have ‖µ̂− µG‖2 = O(ε √ log(1/ε)).
",3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
[DKK+16] gave algorithms for robustly estimating the mean of a Gaussian distribution with known covariance and for robustly estimating the mean of a binary product distribution.,3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
The main motivation for considering these specific distribution families is that robustly estimating the mean within Euclidean distance immediately implies total variation distance bounds for these families.,3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
The above theorem establishes that these guarantees hold in a more general setting with near sample-optimal bounds.,3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
"Under a bounded second moment assumption, we show:
Theorem 3.2.",3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
Let P be a distribution on Rd with unknown mean vector µP and unknown covariance matrix ΣP σ2I. Let S be an ε-corrupted set of samples from P of size Θ((d/ε) log d).,3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
"There exists an efficient algorithm that, on input S and ε > 0, with probability 9/10 outputs µ̂ with ‖µ̂− µP ‖2 ≤ O( √ εσ).
",3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
A similar result on mean estimation under bounded second moments was concurrently shown in [SCV18].,3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
"The sample size above is optimal, up to a logarithmic factor, and the error guarantee is easily seen to be the best possible up to a constant factor.",3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
The main difference between the filtering algorithm establishing the above theorem and the filtering algorithm for the sub-gaussian case is how we choose the threshold for the filter.,3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
"Instead of looking for a violation of a concentration inequality, here we will choose a threshold at random.",3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
"In this case, randomly choosing a threshold weighted towards higher thresholds suffices to throw out more corrupted samples than uncorrupted samples in expectation.",3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
"Although it is possible to reject many good samples this way, we show that the algorithm still only rejects a total of O(ε) samples with high probability.
",3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
"Finally, for robustly estimating the covariance of a Gaussian distribution, we have:
Theorem 3.3.",3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
"Let G ∼ N (0,Σ) be a Gaussian in d dimensions, and let ε > 0.",3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
Let S be an ε-corrupted set of samples from G of size Ω((d2/ε2) poly log(d/ε)).,3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
"There exists an efficient algorithm that, given S and ε, returns the parameters of a Gaussian distribution G′ ∼ N (0, Σ̂) so that with probability at least 9/10, it holds ‖I − Σ−1/2Σ̂Σ−1/2‖F = O(ε log(1/ε)).
",3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
We now provide a high-level description of the main ingredient which yields these improved sample complexity bounds.,3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
"The initial analysis of [DKK+16] established sample complexity bounds which were suboptimal by polynomial factors because it insisted that the set of good samples (i.e., before the corruption) satisfied very tight tail bounds.",3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
"To some degree such bounds are necessary, as when we perform our filtering procedure, we need to ensure that not too many good samples are thrown away.",3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
"However, the old analysis required that fairly strong tail bounds hold uniformly.",3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
"The idea for the improvement is as follows: If the errors are sufficient to cause the variance of some polynomial p (linear in the unknown mean case or quadratic in the unknown covariance case) to increase by more than ε, it must be the case that for some T , roughly an ε/T 2 fraction of samples are error points with |p(x)| > T .",3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
"As long as we can ensure that less than an
ε/T 2 fraction of our good sample points have |p(x)| > T , this will suffice for our filtering procedure to work.",3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
"For small values of T , these are much weaker tail bounds than were needed previously and can be achieved with a smaller number of samples.",3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
"For large values of T , these tail bounds are comparable to those used in previous work [DKK+16] , but in such cases we can take advantage of the fact that |p(G)| > T only with very small probability, again allowing us to reduce the sample complexity.",3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
The details are deferred to Appendix A.,3 Nearly Sample-Optimal Efficient Robust Learning,[0],[0]
We now describe the filtering technique more rigorously.,4 Filtering,[0],[0]
We also describe some additional heuristics we found useful in practice.,4 Filtering,[0],[0]
We first consider mean estimation.,4.1 Robust Mean Estimation,[0],[0]
The algorithms which achieve Theorems 3.1 and 3.2 both follow the general recipe in Algorithm 1.,4.1 Robust Mean Estimation,[0],[0]
"We must specify three parameter functions:
• Thres(ε) is a threshold function—we terminate if the covariance has spectral norm bounded by Thres(ε).
",4.1 Robust Mean Estimation,[0],[0]
"• Tail(T, d, ε, δ, τ) is an univariate tail bound, which would only be violated by a τ fraction of points if they were uncorrupted, but is violated by many more of the current set of points.
",4.1 Robust Mean Estimation,[0],[0]
"• δ(ε, s) is a slack function, which we require for technical reasons.
",4.1 Robust Mean Estimation,[0],[0]
"Given these objects, our filter is fairly easy to state: first, we compute the empirical covariance.",4.1 Robust Mean Estimation,[0],[0]
"Then, we check if the spectral norm of the empirical covariance exceeds Thres(ε).",4.1 Robust Mean Estimation,[0],[0]
"If it does not, we output the empirical mean with the current set of data points.",4.1 Robust Mean Estimation,[0],[0]
"Otherwise, we project onto the top eigenvector of the empirical covariance, and throw away all points which violate Tail(T, d, ε, δ, τ), for some choice of slack function δ.
",4.1 Robust Mean Estimation,[0],[0]
"Algorithm 1 Filter-based algorithm template for robust mean estimation
1: Input: An ε-corrupted set of samples S, Thres(ε),Tail(T, d, ε, δ, τ), δ(ε, s) 2: Compute the sample mean µS ′",4.1 Robust Mean Estimation,[0],[0]
"= EX∈uS′ [X] 3: Compute the sample covariance matrix Σ 4: Compute approximations for the largest absolute eigenvalue of Σ, λ∗ := ‖Σ‖2, and the associated unit
eigenvector v∗. 5: if ‖Σ‖2 ≤ Thres(ε) then 6: return µS ′ .",4.1 Robust Mean Estimation,[0],[0]
"7: Let δ = δ(ε, ‖Σ‖2).",4.1 Robust Mean Estimation,[0],[0]
8: Find T > 0,4.1 Robust Mean Estimation,[0],[0]
"such that
Pr X∈uS′
[ |v∗ · (X − µS ′ )",4.1 Robust Mean Estimation,[0],[0]
| > T,4.1 Robust Mean Estimation,[0],[0]
+ δ,4.1 Robust Mean Estimation,[0],[0]
"] > Tail(T, d, ε, δ, τ).
9: return {x ∈ S′ : |v∗ · (x− µS′)| ≤ T + δ}.
",4.1 Robust Mean Estimation,[0],[0]
"Sub-gaussian case To concretely instantiate this algorithm for the subgaussian case, we take Thres(ε)",4.1 Robust Mean Estimation,[0],[0]
"= O(ε log 1/ε), δ(ε, s) = 3 √ ε(s− 1), and
Tail(T, d, ε, δ, τ) = 8 exp(−T 2/2ν)",4.1 Robust Mean Estimation,[0],[0]
"+ 8 ε T 2 log(d log(d/ετ)) ,
where ν is the subgaussian parameter.",4.1 Robust Mean Estimation,[0],[0]
"See Section A.1 for details.
",4.1 Robust Mean Estimation,[0],[0]
"Second moment case To concretely instantiate this algorithm for the second moment case, we take Thres(ε)",4.1 Robust Mean Estimation,[0],[0]
"= 9,",4.1 Robust Mean Estimation,[0],[0]
"δ = 0, and we take Tail to be a random rescaling of the largest deviation in the data set, in the direction v∗.",4.1 Robust Mean Estimation,[0],[0]
See Section A.2 for details.,4.1 Robust Mean Estimation,[0],[0]
"Our algorithm for robust covariance follows the exact recipe outlined above, with one key difference—we check for deviations in the empirical fourth moment tensor.",4.2 Robust Covariance Estimation,[0],[0]
"Intuitively, just as in the robust mean setting, we used degree-2 information to detect outliers for the mean (the degree-1 moment), here we use degree-4 information to detect outliers for the covariance (the degree-2 moment).
",4.2 Robust Covariance Estimation,[0],[0]
"More concretely, this corresponds to finding a normalized degree-2 polynomial whose empirical variance is too large.",4.2 Robust Covariance Estimation,[0],[0]
"By then filtering along this polynomial, with an appropriate choice of Thres(ε), δ(ε, s), and Tail, we achieve the desired bounds.",4.2 Robust Covariance Estimation,[0],[0]
See Section A.3 for the formal pseudocode and more details.,4.2 Robust Covariance Estimation,[0],[0]
"In the algorithms described above for robust mean estimation, after projecting onto one dimension, we center the points at the empirical mean along this direction.",4.3 Better Univariate Tests,[0],[0]
"This is theoretically sufficient, however, introduces additional constant factors since the empirical mean along this direction may be corrupted.",4.3 Better Univariate Tests,[0],[0]
"Instead, one can use a robust estimate for the mean in one direction.",4.3 Better Univariate Tests,[0],[0]
"Namely, it is well known that the median is a provably robust estimator for the mean for symmetric distributions [HR09, HRRS86], and under certain models it is in fact optimal in terms of its resilience to noise [DKW56, Mas90, Che98, DK14, DKK+17].",4.3 Better Univariate Tests,[0],[0]
"By centering the points at the median instead of the mean, we are able to achieve better error in practice.",4.3 Better Univariate Tests,[0],[0]
"In our empirical evaluation, we found that it was important to find an appropriate choice of Tail, to achieve good error rates, especially for robust covariance estimation.",4.4 Adaptive Tail Bounding,[0],[0]
"Concretely, in this setting, our tail bound is given by
Tail(T, d, ε, δ, τ) = C1 exp(−C2T ) +",4.4 Adaptive Tail Bounding,[0],[0]
"Tail2(T, d, ε, δ, τ) ,
for some function Tail2, and constants C1, C2.",4.4 Adaptive Tail Bounding,[0],[0]
"We found that for reasonable settings, the term that dominated was always the first term on the RHS, and that Tail2 is less significant.",4.4 Adaptive Tail Bounding,[0],[0]
"Thus, we focused on optimizing the first term.
",4.4 Adaptive Tail Bounding,[0],[0]
"We found that depending on the setting, it was useful to change the constant C2.",4.4 Adaptive Tail Bounding,[0],[0]
"In particular, in low dimensions, we could be more stringent, and enforce a stronger tail bound (which corresponds to a higher C2), but in higher dimensions, we must be more lax with the tail bound.",4.4 Adaptive Tail Bounding,[0],[0]
"To do this in a principled manner, we introduced a heuristic we call adaptive tail bounding.",4.4 Adaptive Tail Bounding,[0],[0]
Our goal is to find a choice of C2 which throws away roughly an ε-fraction of points.,4.4 Adaptive Tail Bounding,[0],[0]
The heuristic is fairly simple: we start with some initial guess for C2.,4.4 Adaptive Tail Bounding,[0],[0]
We then run our filter with this C2.,4.4 Adaptive Tail Bounding,[0],[0]
"If we throw away too many data points, we increase our C2, and retry.",4.4 Adaptive Tail Bounding,[0],[0]
"If we throw away too few, then we decrease our C2 and retry.",4.4 Adaptive Tail Bounding,[0],[0]
"Since increasing C2 strictly decreases the number of points thrown away, and vice versa, we binary search over our choice of C2 until we reach something close to our target accuracy.",4.4 Adaptive Tail Bounding,[0],[0]
"In our current implementation, we stop when the fraction of points we throw away is between ε/2 and 3ε/2, or if we’ve binary searched for too long.",4.4 Adaptive Tail Bounding,[0],[0]
"We found that this heuristic drastically improves our accuracy, and allows our algorithm to scale fairly smoothly from low to high dimension.",4.4 Adaptive Tail Bounding,[0],[0]
We performed an empirical evaluation of the above algorithms on synthetic and real data sets with and without synthetic noise.,5 Experiments,[0],[0]
All experiments were done on a laptop computer with a 2.7 GHz Intel Core i5 CPU and 8 GB of RAM.,5 Experiments,[0],[0]
"The focus of this evaluation was on statistical accuracy, not time efficiency.",5 Experiments,[0],[0]
"In this measure, our algorithm performs the best of all algorithms we tried.",5 Experiments,[0],[0]
"In all synthetic trials, our algorithm consistently had the smallest error.",5 Experiments,[0],[0]
"In fact, in some of the synthetic benchmarks, our error was orders of magnitude better than any other algorithms.",5 Experiments,[0],[0]
"In the semi-synthetic benchmark, our algorithm also (arguably) performs the best, though there is no way to tell for sure, since there is no ground truth.",5 Experiments,[0],[0]
"We also note that despite not optimizing our code for runtime, the runtime of our algorithm is always comparable, and in many cases, better than the alternatives which provided comparable error.",5 Experiments,[0],[0]
Code of our implementation is available at https://github.com/hoonose/robust-filter.,5 Experiments,[0],[0]
Experiments with synthetic data allow us to verify the error guarantees and the sample complexity rates proven in Section 3 for unknown mean and unknown covariance.,5.1 Synthetic Data,[0],[0]
"In both cases, the experiments validate the accuracy and usefulness of our algorithm, almost exactly matching the best rate without noise.
",5.1 Synthetic Data,[0],[0]
Unknown mean The results of our synthetic mean experiment are shown in Figure 1.,5.1 Synthetic Data,[0],[0]
"In the synthetic mean experiment, we set ε = 0.1, and for dimension d =",5.1 Synthetic Data,[0],[0]
"[100, 150, . .",5.1 Synthetic Data,[0],[0]
.,5.1 Synthetic Data,[0],[0]
", 400], we generate n = 10dε2 samples, where a (1 − ε)-fraction come from N (µ, I), and an ε fraction come from a noise distribution.",5.1 Synthetic Data,[0],[0]
Our goal is to produce an estimator which minimizes the `2 error the estimator has to the truth.,5.1 Synthetic Data,[0],[0]
"As a baseline, we compute the error that is achieved by only the uncorrupted sample points.",5.1 Synthetic Data,[0],[0]
"This error will be used as the gold standard for comparison, since in the presence of error, this is roughly the best one could do even if all the noise points were identified exactly.†
On this data, we compared the performance of our Filter algorithm to that of (1) the empirical mean of all the points, (2) a trivial pruning procedure, (3) the geometric median of the data, (4) a RANSAC-based mean estimation algorithm, and (5) a recently proposed robust estimator for the mean due to [LRV16], which we will call LRVMean.",5.1 Synthetic Data,[0],[0]
"For (5), we use the implementation available in their Github.‡ In Figure 1, the x-axis indicates the dimension of the experiment, and the y-axis measures the `2 error of our estimated mean minus the `2 error of the empirical mean of the true samples from the Gaussian, i.e., the excess error induced over the sampling error.
",5.1 Synthetic Data,[0],[0]
"We tried various noise distributions, and found that the same qualitative pattern arose for all of them.",5.1 Synthetic Data,[0],[0]
"In the reported experiment, our noise distribution was a mixture of two binary product distributions, where one had a couple of large coordinates (see Section B.1 for a detailed description).",5.1 Synthetic Data,[0],[0]
"For all (nontrivial) error distributions we tried, we observed that indeed the empirical mean, pruning, geometric median, and RANSAC all have error which diverges as d grows, as the theory predicts.",5.1 Synthetic Data,[0],[0]
"On the other hand, both our algorithm and LRVMean have markedly smaller error as a function of dimension.",5.1 Synthetic Data,[0],[0]
"Indeed, our algorithm’s error is almost identical to that of the empirical mean of the uncorrupted sample points.
",5.1 Synthetic Data,[0],[0]
Unknown covariance The results of our synthetic covariance experiment are shown in Figure 2.,5.1 Synthetic Data,[0],[0]
Our setup is similar to that for the synthetic mean.,5.1 Synthetic Data,[0],[0]
"Since both our algorithm and LRVCov require access to fourth moment objects, we ran into issues with limited memory on machines.",5.1 Synthetic Data,[0],[0]
"Thus, we could not perform experiments at as high a dimension as for the unknown mean setting, and we could not use as many samples.",5.1 Synthetic Data,[0],[0]
"We set ε = 0.05, and for dimension d =",5.1 Synthetic Data,[0],[0]
"[10, 20, . .",5.1 Synthetic Data,[0],[0]
.,5.1 Synthetic Data,[0],[0]
", 100], we generate n = 0.5dε2 samples, where a (1 − ε)-fraction come from N (0,Σ), and an ε fraction come from a noise distribution.",5.1 Synthetic Data,[0],[0]
"We measure distance in the natural affine invariant way, namely, the Mahalanobis distance induced by Σ to the identity: err(Σ̂) = ‖Σ−1/2Σ̂Σ−1/2−",5.1 Synthetic Data,[0],[0]
I‖F .,5.1 Synthetic Data,[0],[0]
"As explained above, this is the right affine-invariant metric for this problem.",5.1 Synthetic Data,[0],[0]
"As before, we use the empirical error of only the uncorrupted data points as a benchmark.
",5.1 Synthetic Data,[0],[0]
"On this corrupted data, we compared the performance of our Filter algorithm to that of (1) the empirical covariance of all the points, (2) a trivial pruning procedure, (3) a RANSAC-based minimal volume ellipsoid (MVE) algorithm, and (5) a recently proposed robust estimator for the covariance due to [LRV16], which we will call LRVCov.",5.1 Synthetic Data,[0],[0]
"For (5), we again obtained the implementation from their Github repository.
",5.1 Synthetic Data,[0],[0]
We tried various choices of Σ and noise distribution.,5.1 Synthetic Data,[0],[0]
Figure 2 shows two choices of Σ and noise.,5.1 Synthetic Data,[0],[0]
"Again, the x-axis indicates the dimension of the experiment and the y-axis indicates the estimator’s excess Mahalanobis error over the sampling error.",5.1 Synthetic Data,[0],[0]
"In the left figure, we set Σ = I, and our noise points are simply all located at the all-zeros vector.",5.1 Synthetic Data,[0],[0]
"In the right figure, we set Σ = I + 10e1e T 1 , where e1 is the first basis vector, and our noise distribution is a somewhat more complicated distribution, which is similarly spiked, but in a different, random, direction.",5.1 Synthetic Data,[0],[0]
We formally define this distribution in Section B.1.,5.1 Synthetic Data,[0],[0]
"For all choices of Σ and noise we tried, the qualitative behavior of our algorithm and LRVCov was unchanged.",5.1 Synthetic Data,[0],[0]
"Namely, we seem to match the empirical error without noise up to a very small slack, for all dimensions.",5.1 Synthetic Data,[0],[0]
"On the other hand, the performance of empirical mean, pruning, and RANSAC varies widely with the noise distribution.",5.1 Synthetic Data,[0],[0]
"The performance of all these algorithms degrades substantially with dimension, and their error gets worse as we increase the skew of the underlying data.",5.1 Synthetic Data,[0],[0]
"The performance of LRVCov is the most similar to ours, but again is worse by a large
†We note that it is possible that an estimator may achieve slightly better error than this baseline.",5.1 Synthetic Data,[0],[0]
"‡https://github.com/kal2000/AgnosticMean\AndCovarianceCode
constant factor.",5.1 Synthetic Data,[0],[0]
"In particular, our excess risk was on the order of 10−4 for large d, for both experiments, whereas the excess risk achieved by LRVCov was in all cases a constant between 0.1 and 2.
",5.1 Synthetic Data,[0],[0]
Discussion These experiments demonstrate that our statistical guarantees are in fact quite strong.,5.1 Synthetic Data,[0],[0]
"In particular, since our excess error is almost zero (and orders of magnitude smaller than other approaches), this suggests that our sample complexity is indeed close to optimal, since we match the rate without noise, and that the constants and logarithmic factors in the theoretical recovery guarantee are often small or non-existent.",5.1 Synthetic Data,[0],[0]
"To demonstrate the efficacy of our method on real data, we revisit the famous study of [NJB+08].",5.2 Semi-synthetic Data,[0],[0]
"In this study, the authors investigated data collected as part of the Population Reference Sample (POPRES) project.",5.2 Semi-synthetic Data,[0],[0]
This dataset consists of the genotyping of thousands of individuals using the Affymetrix 500K single nucleotide polymorphism (SNP) chip.,5.2 Semi-synthetic Data,[0],[0]
"The authors pruned the dataset to obtain the genetic data of over 1387 European individuals, annotated by their country of origin.",5.2 Semi-synthetic Data,[0],[0]
"Using principal components analysis, they produce a two-dimensional summary of the genetic variation, which bears a striking resemblance to the map of Europe.
",5.2 Semi-synthetic Data,[0],[0]
Our experimental setup is as follows.,5.2 Semi-synthetic Data,[0],[0]
"While the original dataset is very high dimensional, we use a 20 dimensional version of the dataset as found in the authors’ GitHub§.",5.2 Semi-synthetic Data,[0],[0]
"We first randomly rotate the data, as then 20 dimensional data was diagonalized, and the high dimensional data does not follow such structure.",5.2 Semi-synthetic Data,[0],[0]
We then add an additional ε1−ε fraction of points (so that they make up an ε-fraction of the final points).,5.2 Semi-synthetic Data,[0],[0]
"These added points were discrete points, following a simple product distribution (see Section B.1 for full details).",5.2 Semi-synthetic Data,[0],[0]
"We used a number of methods to obtain a covariance matrix for this dataset, and we projected the data onto the top two singular vectors of this matrix.",5.2 Semi-synthetic Data,[0],[0]
"In Figure 3, we show the results when we compare our techniques to pruning.",5.2 Semi-synthetic Data,[0],[0]
"In particular, our output was able to more or less reproduce the map of Europe, whereas pruning fails to.",5.2 Semi-synthetic Data,[0],[0]
"In Section B.2, we also compare our result with a number of other techniques, including those we tested against in the unknown covariance experiments, and other robust PCA techniques.",5.2 Semi-synthetic Data,[0],[0]
"The only alternative algorithm which was able to produce meaningful output was LRVCov, which produced output that was similar to ours, but which produced a map which was somewhat more skewed.",5.2 Semi-synthetic Data,[0],[0]
"We believe that our algorithm produces the best picture.
",5.2 Semi-synthetic Data,[0],[0]
"In Figure 3, we also display the actual points which were output by our algorithm’s Filter.",5.2 Semi-synthetic Data,[0],[0]
"While it manages to remove most of the noise points, it also seems to remove some of the true data points, particularly those from Eastern Europe and Turkey.",5.2 Semi-synthetic Data,[0],[0]
"We attribute this to a lack of samples from these regions, and thus one could consider them as outliers to a dataset consisting of Western European individuals.",5.2 Semi-synthetic Data,[0],[0]
"For instance, Turkey had 4 data points, so it seems quite reasonable that any robust algorithm would naturally consider these points outliers.
",5.2 Semi-synthetic Data,[0],[0]
"Discussion We view our experiments as a proof of concept demonstration that our techniques can be useful in real world exploratory data analysis tasks, particularly those in high-dimensions.",5.2 Semi-synthetic Data,[0],[0]
"Our experiments reveal that a minimal amount of noise can completely disrupt a data analyst’s ability to notice an interesting phenomenon, thus limiting us to only very well-curated data sets.",5.2 Semi-synthetic Data,[0],[0]
"But with robust methods, this noise does not interfere with scientific discovery, and we can still recover interesting patterns which otherwise would have been obscured by noise.",5.2 Semi-synthetic Data,[0],[0]
We would like to thank Simon Du and Lili Su for helpful comments on a previous version of this work.,Acknowledgments,[0],[0]
"A.1 Robust Mean Estimation for Sub-Gaussian Distributions
In this section, we use our filter technique to give a near sample-optimal computationally efficient algorithm to robustly estimate the mean of a sub-gaussian density with a known covariance matrix, thus proving Theorem 3.1.
",A Omitted Details from Section 3,[0],[0]
"We emphasize that the algorithm and its analysis is essentially identical to the filtering algorithm given in Section 8.1 of [DKK+16] for the case of a Gaussian N (µ, I).",A Omitted Details from Section 3,[0],[0]
The only difference is a weaker definition of the “good set of samples” (Definition A.4) and a simple concentration argument (Lemma A.5) showing that a random set of uncorrupted samples of the appropriate size is good with high probability.,A Omitted Details from Section 3,[0],[0]
"Given these, the analysis of this subsection follows straightforwardly from the analysis in Section 8.1 of [DKK+16] by plugging in the modified parameters.",A Omitted Details from Section 3,[0],[0]
"For the sake of completeness, we provide the details below.
",A Omitted Details from Section 3,[0],[0]
"We start by formally defining sub-gaussian distributions:
Definition A.1.",A Omitted Details from Section 3,[0],[0]
"A distribution P on R with mean µ, is sub-gaussian with parameter ν",A Omitted Details from Section 3,[0],[0]
> 0,A Omitted Details from Section 3,[0],[0]
"if
EX∼P [exp(λ(X − µ))] ≤ exp(νλ2/2)
for all λ ∈ R.",A Omitted Details from Section 3,[0],[0]
A distribution P on Rd with mean vector µ is sub-gaussian with parameter ν,A Omitted Details from Section 3,[0],[0]
"> 0, if for all unit vectors v, the one-dimensional random variable v ·X, X ∼ P , is sub-gaussian with parameter ν.
",A Omitted Details from Section 3,[0],[0]
"We will use the following simple fact about the concentration of sub-gaussian random variables:
Fact A.2.",A Omitted Details from Section 3,[0],[0]
If P is sub-gaussian on Rd with mean vector µ and parameter ν,A Omitted Details from Section 3,[0],[0]
"> 0,",A Omitted Details from Section 3,[0],[0]
then for any unit vector v ∈,A Omitted Details from Section 3,[0],[0]
Rd,A Omitted Details from Section 3,[0],[0]
we have that PrX∼P,A Omitted Details from Section 3,[0],[0]
[|v · (X − µ)| ≥,A Omitted Details from Section 3,[0],[0]
T ] ≤,A Omitted Details from Section 3,[0],[0]
"exp(−T 2/2ν).
",A Omitted Details from Section 3,[0],[0]
"The following theorem is a high probability version of Theorem 3.1:
Theorem A.3.",A Omitted Details from Section 3,[0],[0]
"Let G be a sub-gaussian distribution on Rd with parameter ν = Θ(1), mean µG, covariance matrix I, and ε, τ > 0.",A Omitted Details from Section 3,[0],[0]
Let S′ be an ε-corrupted set of samples from G of size Ω((d/ε2) poly log(d/ετ)).,A Omitted Details from Section 3,[0],[0]
"There exists an efficient algorithm that, on input S′ and ε > 0, returns a mean vector µ̂ so that with probability at least 1− τ",A Omitted Details from Section 3,[0],[0]
we have ‖µ̂− µG‖2 = O(ε √ log(1/ε)).,A Omitted Details from Section 3,[0],[0]
Notation.,A Omitted Details from Section 3,[0],[0]
We will denote µS =,A Omitted Details from Section 3,[0],[0]
"1|S| ∑ X∈S X and MS = 1 |S| ∑ X∈S(X−µG)(X−µG)T for the sample mean and modified sample covariance matrix of the set S.
We start by defining our modified notion of good sample, i.e, a set of conditions on the uncorrupted set of samples under which our algorithm will succeed.
",A Omitted Details from Section 3,[0],[0]
Definition A.4.,A Omitted Details from Section 3,[0],[0]
"Let G be an identity covariance sub-gaussian in d dimensions with mean µG and covariance matrix I and ε, τ > 0.",A Omitted Details from Section 3,[0],[0]
"We say that a multiset S of elements in Rd is (ε, τ)-good with respect to G if the following conditions are satisfied:
(i)",A Omitted Details from Section 3,[0],[0]
For all x ∈ S we have ‖x− µG‖2 ≤,A Omitted Details from Section 3,[0],[0]
"O( √ d log(|S|/τ)).
",A Omitted Details from Section 3,[0],[0]
(ii) For every affine function L : Rd → R such that L(x) = v · (x − µG),A Omitted Details from Section 3,[0],[0]
"− T , ‖v‖2 = 1, we have that |PrX∈uS",A Omitted Details from Section 3,[0],[0]
[L(X) ≥ 0]− PrX∼G[L(X) ≥ 0]| ≤,A Omitted Details from Section 3,[0],[0]
εT 2,A Omitted Details from Section 3,[0],[0]
"log(d log( dετ )) .
",A Omitted Details from Section 3,[0],[0]
"(iii) We have that ‖µS − µG‖2 ≤ ε.
(iv) We have that ‖MS − I‖2 ≤ ε.
",A Omitted Details from Section 3,[0],[0]
"We show in the following subsection that a sufficiently large set of independent samples from G is (ε, τ)good",A Omitted Details from Section 3,[0],[0]
(with respect to G) with high probability.,A Omitted Details from Section 3,[0],[0]
"Specifically, we prove:
Lemma A.5.",A Omitted Details from Section 3,[0],[0]
"Let G be sub-gaussian distribution with parameter ν = Θ(1) and with identity covariance, and ε, τ > 0.",A Omitted Details from Section 3,[0],[0]
If the multiset S is obtained by taking Ω((d/ε2) poly log(d/ετ)),A Omitted Details from Section 3,[0],[0]
"independent samples from G, it is (ε, τ)-good with respect to G with probability at least 1− τ.
",A Omitted Details from Section 3,[0],[0]
"We require the following definition that quantifies the extent to which a multiset has been corrupted:
Definition A.6.",A Omitted Details from Section 3,[0],[0]
"Given finite multisets S and S′ we let ∆(S, S′) be the size of the symmetric difference of S and S′ divided by the cardinality of S.
The starting point of our algorithm will be a simple NaivePrune routine (Section 4.3.1 of [DKK+16]) that removes obvious outliers, i.e., points which are far from the mean.",A Omitted Details from Section 3,[0],[0]
"Then, we iterate the algorithm whose performance guarantee is given by the following:
Proposition A.7.",A Omitted Details from Section 3,[0],[0]
"Let G be a sub-gaussian distribution on Rd with parameter ν = Θ(1), mean µG, covariance matrix I, ε > 0 be sufficiently small and τ > 0.",A Omitted Details from Section 3,[0],[0]
"Let S be an (ε, τ)-good set with respect to G. Let S′ be any multiset with ∆(S, S′) ≤ 2ε and for any x, y ∈ S′, ‖x",A Omitted Details from Section 3,[0],[0]
− y‖2 ≤,A Omitted Details from Section 3,[0],[0]
O( √ d log(d/ετ)).,A Omitted Details from Section 3,[0],[0]
"There exists a polynomial time algorithm Filter-Sub-Gaussian-Unknown-Mean that, given S′ and ε > 0, returns one of the following:
(i) A mean vector µ̂ such that ‖µ̂− µG‖2 = O(ε √ log(1/ε)).
",A Omitted Details from Section 3,[0],[0]
"(ii) A multiset S′′ ⊆ S′ such that ∆(S, S′′) ≤ ∆(S, S′)− ε/α, where α def= d log(d/ετ) log(d log( dετ )).
",A Omitted Details from Section 3,[0],[0]
"We start by showing how Theorem A.3 follows easily from Proposition A.7.
",A Omitted Details from Section 3,[0],[0]
Proof of Theorem A.3.,A Omitted Details from Section 3,[0],[0]
"By the definition of ∆(S, S′), since S′ has been obtained from S by corrupting an ε-fraction of the points in S, we have that ∆(S, S′) ≤ 2ε.",A Omitted Details from Section 3,[0],[0]
"By Lemma A.5, the set S of uncorrupted samples is (ε, τ)-good with respect to G with probability at least 1− τ.",A Omitted Details from Section 3,[0],[0]
"We henceforth condition on this event.
",A Omitted Details from Section 3,[0],[0]
"Since S is (ε, τ)-good, all x ∈ S have ‖x− µG‖2 ≤",A Omitted Details from Section 3,[0],[0]
O( √ d log |S|/τ).,A Omitted Details from Section 3,[0],[0]
"Thus, the NaivePrune procedure does not remove from S′ any member of S. Hence, its output, S′′, has ∆(S, S′′) ≤ ∆(S, S′) and for any x ∈ S′′, there is a y ∈ S with ‖x",A Omitted Details from Section 3,[0],[0]
− y‖2 ≤,A Omitted Details from Section 3,[0],[0]
O( √ d log |S|/τ).,A Omitted Details from Section 3,[0],[0]
"By the triangle inequality, for any x, z ∈ S′′,
‖x− z‖2 ≤ O( √ d log |S|/τ)",A Omitted Details from Section 3,[0],[0]
"= O( √ d log(d/ετ)).
",A Omitted Details from Section 3,[0],[0]
"Then, we iteratively apply the Filter-Sub-Gaussian-Unknown-Mean procedure of Proposition A.7 until it terminates returning a mean vector µ with ‖µ̂− µG‖2 = O(ε √ log(1/ε)).",A Omitted Details from Section 3,[0],[0]
We claim that we need at most O(α) iterations for this to happen.,A Omitted Details from Section 3,[0],[0]
"Indeed, the sequence of iterations results in a sequence of sets S′i, so that ∆(S, S′i) ≤ ∆(S, S′)− i · ε/α.",A Omitted Details from Section 3,[0],[0]
"Thus, if we do not output the empirical mean in the first 2α iterations, in the next iteration there are no outliers left and the algorithm terminates outputting the sample mean of the remaining set.
",A Omitted Details from Section 3,[0],[0]
"A.1.1 Algorithm Filter-Sub-Gaussian-Unknown-Mean: Proof of Proposition A.7
In this subsection, we describe the efficient algorithm establishing Proposition A.7 and prove its correctness.",A Omitted Details from Section 3,[0],[0]
Our algorithm calculates the empirical mean vector µS ′,A Omitted Details from Section 3,[0],[0]
and,A Omitted Details from Section 3,[0],[0]
"empirical covariance matrix Σ. If the matrix Σ has no large eigenvalues, it returns µS ′ .",A Omitted Details from Section 3,[0],[0]
"Otherwise, it uses the eigenvector v∗ corresponding to the maximum magnitude eigenvalue of Σ and the mean vector µS ′
to define a filter.",A Omitted Details from Section 3,[0],[0]
"Our efficient filtering procedure is presented in detailed pseudocode below.
",A Omitted Details from Section 3,[0],[0]
"A.1.2 Proof of Correctness of Filter-Sub-Gaussian-Unknown-Mean
By definition, there exist disjoint multisets L,E, of points in Rd, where L ⊂ S, such that S′ = (S \ L) ∪ E. With this notation, we can write ∆(S, S′) = |L|+|E||S| .",A Omitted Details from Section 3,[0],[0]
"Our assumption ∆(S, S
′) ≤",A Omitted Details from Section 3,[0],[0]
"2ε is equivalent to |L|+|E| ≤ 2ε · |S|, and the definition of S′ directly implies that (1− 2ε)|S| ≤ |S′| ≤ (1 + 2ε)|S|.",A Omitted Details from Section 3,[0],[0]
"Throughout the proof, we assume that ε is a sufficiently small constant.
",A Omitted Details from Section 3,[0],[0]
"We define µG, µS , µS ′ , µL, and µE to be the means of G,S, S′, L, and E, respectively.",A Omitted Details from Section 3,[0],[0]
"Our analysis will make essential use of the following matrices:
• MS′ denotes EX∈uS′",A Omitted Details from Section 3,[0],[0]
[(X − µG)(X,A Omitted Details from Section 3,[0],[0]
"− µG)T ],
• MS denotes EX∈uS",A Omitted Details from Section 3,[0],[0]
[(X − µG)(X,A Omitted Details from Section 3,[0],[0]
"− µG)T ],
• ML denotes EX∈uL[(X − µG)(X",A Omitted Details from Section 3,[0],[0]
"− µG)T ], and
Algorithm 2 Filter algorithm for a sub-gaussian with unknown mean and identity covariance
1: procedure Filter-Sub-Gaussian-Unknown-Mean(S′, ε, τ) input: A multiset S′ such that there exists an (ε, τ)-good S with ∆(S, S′) ≤",A Omitted Details from Section 3,[0],[0]
2ε output: Multiset S′′ or mean vector µ̂ satisfying Proposition A.7 2: Compute the sample mean µS ′,A Omitted Details from Section 3,[0],[0]
"= EX∈uS′ [X] and the sample covariance matrix Σ , i.e., Σ =
(Σi,j)1≤i,j≤d with Σi,j = EX∈uS′ [(Xi − µS ′",A Omitted Details from Section 3,[0],[0]
"i )(Xj − µS ′
j )].",A Omitted Details from Section 3,[0],[0]
3: Compute approximations for the largest absolute eigenvalue of Σ,A Omitted Details from Section 3,[0],[0]
"− I, λ∗ := ‖Σ − I‖2, and the
associated unit eigenvector v∗. 4: if ‖Σ− I‖2 ≤ O(ε log(1/ε)), then return µS ′ .
",A Omitted Details from Section 3,[0],[0]
5: Let δ := 3 √ ε‖Σ− I‖2.,A Omitted Details from Section 3,[0],[0]
Find T > 0,A Omitted Details from Section 3,[0],[0]
"such that
Pr X∈uS′
[ |v∗ · (X − µS ′ )",A Omitted Details from Section 3,[0],[0]
| > T,A Omitted Details from Section 3,[0],[0]
+ δ,A Omitted Details from Section 3,[0],[0]
],A Omitted Details from Section 3,[0],[0]
> 8 exp(−T 2/2ν),A Omitted Details from Section 3,[0],[0]
"+ 8 ε
T 2 log ( d log( dετ ) ) .",A Omitted Details from Section 3,[0],[0]
"6: return the multiset S′′ = {x ∈ S′ : |v∗ · (x− µS′)| ≤ T + δ}.
",A Omitted Details from Section 3,[0],[0]
• ME denotes EX∈uE,A Omitted Details from Section 3,[0],[0]
[(X − µG)(X,A Omitted Details from Section 3,[0],[0]
"− µG)T ].
",A Omitted Details from Section 3,[0],[0]
Our analysis will hinge on proving the important claim that Σ− I is approximately (|E|/|S′|)ME .,A Omitted Details from Section 3,[0],[0]
This means two things for us.,A Omitted Details from Section 3,[0],[0]
"First, it means that if the positive errors align in some direction (causing ME to have a large eigenvalue), there will be a large eigenvalue in Σ− I. Second, it says that any large eigenvalue of Σ",A Omitted Details from Section 3,[0],[0]
"− I will correspond to an eigenvalue of ME , which will give an explicit direction in which many error points are far from the empirical mean.
",A Omitted Details from Section 3,[0],[0]
Useful Structural Lemmas.,A Omitted Details from Section 3,[0],[0]
"We begin by noting that we have concentration bounds on G and therefore, on S due to its goodness.
",A Omitted Details from Section 3,[0],[0]
Fact A.8.,A Omitted Details from Section 3,[0],[0]
"Let w ∈ Rd be any unit vector, then for any T > 0, PrX∼G",A Omitted Details from Section 3,[0],[0]
"[ |w · (X − µG)| > T ] ≤ 2 exp(−T 2/2ν)
and PrX∈uS [ |w · (X − µG)|",A Omitted Details from Section 3,[0],[0]
>,A Omitted Details from Section 3,[0],[0]
T,A Omitted Details from Section 3,[0],[0]
],A Omitted Details from Section 3,[0],[0]
≤ 2 exp(−T 2/2ν),A Omitted Details from Section 3,[0],[0]
"+ ε
T 2 log(d log( dετ )) .
",A Omitted Details from Section 3,[0],[0]
Proof.,A Omitted Details from Section 3,[0],[0]
"The first line is Fact A.2, and the former follows from it using the goodness of S.
By using the above fact, we obtain the following simple claim:
Claim A.9.",A Omitted Details from Section 3,[0],[0]
"Let w ∈ Rd be any unit vector, then for any T > 0, we have that:
Pr X∼G
[|w · (X − µS ′ )",A Omitted Details from Section 3,[0],[0]
| > T + ‖µS ′,A Omitted Details from Section 3,[0],[0]
"− µG‖2] ≤ 2 exp(−T 2/2ν).
and Pr
X∈uS",A Omitted Details from Section 3,[0],[0]
"[|w · (X − µS
′ )",A Omitted Details from Section 3,[0],[0]
| > T + ‖µS ′,A Omitted Details from Section 3,[0],[0]
− µG‖2] ≤ 2 exp(−T 2/2ν),A Omitted Details from Section 3,[0],[0]
"+
ε T 2 log ( d log( dετ ) ) .",A Omitted Details from Section 3,[0],[0]
Proof.,A Omitted Details from Section 3,[0],[0]
"This follows from Fact A.8 upon noting that |w · (X−µS′)| > T +‖µS′−µG‖2 only if |w · (X−µG)| > T .
",A Omitted Details from Section 3,[0],[0]
"We can use the above facts to prove concentration bounds for L. In particular, we have the following lemma:
Lemma A.10.",A Omitted Details from Section 3,[0],[0]
We have that ‖ML‖2 =,A Omitted Details from Section 3,[0],[0]
"O (log(|S|/|L|) + ε|S|/|L|).
",A Omitted Details from Section 3,[0],[0]
Proof.,A Omitted Details from Section 3,[0],[0]
"Since L ⊆ S, for any x ∈ Rd, we have that
|S| ·",A Omitted Details from Section 3,[0],[0]
Pr X∈uS (X = x) ≥ |L| ·,A Omitted Details from Section 3,[0],[0]
Pr X∈uL (X = x) .,A Omitted Details from Section 3,[0],[0]
"(1)
Since ML is a symmetric matrix, we have ‖ML‖2 = max‖v‖2=1 |vTMLv|.",A Omitted Details from Section 3,[0],[0]
"So, to bound ‖ML‖2 it suffices to bound |vTMLv| for unit vectors v.",A Omitted Details from Section 3,[0],[0]
"By definition of ML, for any v ∈",A Omitted Details from Section 3,[0],[0]
Rd,A Omitted Details from Section 3,[0],[0]
"we have that
|vTMLv| = EX∈uL[|v · (X − µG)|2].
",A Omitted Details from Section 3,[0],[0]
"For unit vectors v, the RHS is bounded from above as follows:
",A Omitted Details from Section 3,[0],[0]
EX∈uL [ |v · (X − µG)|2 ] = 2 ∫ ∞ 0,A Omitted Details from Section 3,[0],[0]
Pr X∈uL,A Omitted Details from Section 3,[0],[0]
[ |v · (X − µG)| > T ],A Omitted Details from Section 3,[0],[0]
"TdT
= 2 ∫ O(√d",A Omitted Details from Section 3,[0],[0]
log(d/ετ)) 0,A Omitted Details from Section 3,[0],[0]
Pr X∈uL,A Omitted Details from Section 3,[0],[0]
"[|v · (X − µG)| > T ]TdT
≤ 2 ∫ O(√d log(d/ετ))
0
min { 1, |S| |L| ·",A Omitted Details from Section 3,[0],[0]
"Pr X∈uS [ |v · (X − µG)| > T ]} TdT
∫ 4√ν log(|S|/|L|)
0
TdT
+ (|S|/|L|) ∫ O(√d",A Omitted Details from Section 3,[0],[0]
"log(d/ετ))
",A Omitted Details from Section 3,[0],[0]
4 √ ν,A Omitted Details from Section 3,[0],[0]
"log(|S|/|L|)
( exp(−T 2/2ν)",A Omitted Details from Section 3,[0],[0]
"+ ε
T 2 log ( d log( dετ ) ))",A Omitted Details from Section 3,[0],[0]
"TdT log(|S|/|L|) + ε · |S|/|L| ,
where the second line follows from the fact that ‖v‖2 = 1, L ⊂ S, and S satisfies condition (i) of Definition A.4",A Omitted Details from Section 3,[0],[0]
"; the third line follows from (1); and the fourth line follows from Fact A.8.
",A Omitted Details from Section 3,[0],[0]
"As a corollary, we can relate the matrices MS′ and ME , in spectral norm:
Corollary A.11.",A Omitted Details from Section 3,[0],[0]
We have that MS′,A Omitted Details from Section 3,[0],[0]
"− I = (|E|/|S′|)ME + O(ε log(1/ε)), where the O(ε log(1/ε)) term denotes a matrix of spectral norm O(ε log(1/ε)).
",A Omitted Details from Section 3,[0],[0]
Proof.,A Omitted Details from Section 3,[0],[0]
"By definition, we have that |S′|MS′ =",A Omitted Details from Section 3,[0],[0]
|S|MS − |L|ML + |E|ME .,A Omitted Details from Section 3,[0],[0]
"Thus, we can write
MS′ =",A Omitted Details from Section 3,[0],[0]
(,A Omitted Details from Section 3,[0],[0]
|S|/|S′|)MS − (|L|/|S′|)ML + (|E|/|S′|)ME = I +O(ε) +O(ε log(1/ε)),A Omitted Details from Section 3,[0],[0]
"+ (|E|/|S′|)ME ,
where the second line uses the fact that 1 − 2ε ≤ |S|/|S′| ≤ 1 + 2ε, the goodness of S (condition (iv) in Definition A.4), and Lemma A.10.",A Omitted Details from Section 3,[0],[0]
"Specifically, Lemma A.10 implies that (|L|/|S′|)‖ML‖2 = O(ε log(1/ε)).",A Omitted Details from Section 3,[0],[0]
"Therefore, we have that
MS′ = I + (|E|/|S′|)ME +O(ε log(1/ε)) ,
as desired.
",A Omitted Details from Section 3,[0],[0]
"We now establish a similarly useful bound on the difference between the mean vectors:
Lemma A.12.",A Omitted Details from Section 3,[0],[0]
We have that µS ′,A Omitted Details from Section 3,[0],[0]
"− µG = (|E|/|S′|)(µE − µG) +O(ε √ log(1/ε)), where the O(ε √ log(1/ε))
term denotes a vector with `2-norm at most O(ε √ log(1/ε)).
",A Omitted Details from Section 3,[0],[0]
Proof.,A Omitted Details from Section 3,[0],[0]
"By definition, we have that
|S′|(µS ′",A Omitted Details from Section 3,[0],[0]
− µG) = |S|(µS − µG)− |L|(µL − µG) + |E|(µE,A Omitted Details from Section 3,[0],[0]
"− µG).
",A Omitted Details from Section 3,[0],[0]
"Since S is a good set, by condition (iii) of Definition A.4, we have ‖µS−µG‖2 = O(ε).",A Omitted Details from Section 3,[0],[0]
"Since 1−2ε ≤ |S|/|S′| ≤ 1 + 2ε, it follows that (|S|/|S′|)‖µS − µG‖2 = O(ε).",A Omitted Details from Section 3,[0],[0]
"Using the valid inequality ‖ML‖2 ≥ ‖µL − µG‖22 and Lemma A.10, we obtain that ‖µL − µG‖2 ≤",A Omitted Details from Section 3,[0],[0]
O (√ log(|S|/|L|) +,A Omitted Details from Section 3,[0],[0]
√ ε|S|/|L| ) .,A Omitted Details from Section 3,[0],[0]
"Therefore,
(|L|/|S′|)‖µL − µG‖2 ≤",A Omitted Details from Section 3,[0],[0]
O ( (|L|/|S|) √ log(|S|/|L|) + √ ε|L|/|S| ) =,A Omitted Details from Section 3,[0],[0]
O(ε √ log(1/ε)),A Omitted Details from Section 3,[0],[0]
".
",A Omitted Details from Section 3,[0],[0]
"In summary, µS ′",A Omitted Details from Section 3,[0],[0]
"− µG = (|E|/|S′|)(µE − µG) +O(ε √ log(1/ε)) ,
as desired.",A Omitted Details from Section 3,[0],[0]
"This completes the proof of the lemma.
",A Omitted Details from Section 3,[0],[0]
"By combining the above, we can conclude that Σ−I is approximately proportional to ME .",A Omitted Details from Section 3,[0],[0]
"More formally, we obtain the following corollary:
Corollary A.13.",A Omitted Details from Section 3,[0],[0]
We have Σ− I = (|E|/|S′|)ME +O(ε log(1/ε)),A Omitted Details from Section 3,[0],[0]
"+O(|E|/|S′|)2‖ME‖2, where the additive terms denote matrices of appropriately bounded spectral norm.
",A Omitted Details from Section 3,[0],[0]
Proof.,A Omitted Details from Section 3,[0],[0]
"By definition, we can write Σ",A Omitted Details from Section 3,[0],[0]
− I =,A Omitted Details from Section 3,[0],[0]
MS′,A Omitted Details from Section 3,[0],[0]
− I − (µS ′,A Omitted Details from Section 3,[0],[0]
− µG)(µS′ − µG)T .,A Omitted Details from Section 3,[0],[0]
"Using Corollary A.11 and Lemma A.12, we obtain:
Σ− I = (|E|/|S′|)ME +O(ε log(1/ε))",A Omitted Details from Section 3,[0],[0]
+O((|E|/|S′|)2‖µE − µG‖22),A Omitted Details from Section 3,[0],[0]
+O(ε2 log(1/ε)) = (|E|/|S′|)ME +O(ε log(1/ε)),A Omitted Details from Section 3,[0],[0]
"+O(|E|/|S′|)2‖ME‖2 ,
where the second line follows from the valid inequality ‖ME‖2 ≥ ‖µE −µG‖22.",A Omitted Details from Section 3,[0],[0]
"This completes the proof.
",A Omitted Details from Section 3,[0],[0]
Case of Small Spectral Norm.,A Omitted Details from Section 3,[0],[0]
We are now ready to analyze the case that the mean vector µS ′ is returned by the algorithm in Step 4.,A Omitted Details from Section 3,[0],[0]
"In this case, we have that λ∗ def = ‖Σ − I‖2 = O(ε log(1/ε)).",A Omitted Details from Section 3,[0],[0]
"Hence, Corollary A.13 yields that (|E|/|S′|)‖ME‖2 ≤",A Omitted Details from Section 3,[0],[0]
λ∗,A Omitted Details from Section 3,[0],[0]
+O(ε log(1/ε)),A Omitted Details from Section 3,[0],[0]
"+O(|E|/|S′|)2‖ME‖2 ,
which in turns implies that (|E|/|S′|)‖ME‖2 = O(ε log(1/ε)) .
",A Omitted Details from Section 3,[0],[0]
"On the other hand, since ‖ME‖2 ≥ ‖µE − µG‖22, Lemma A.12 gives that
‖µS ′",A Omitted Details from Section 3,[0],[0]
− µG‖2 ≤ (|E|/|S′|) √ ‖ME‖2 +O(ε √ log(1/ε)),A Omitted Details from Section 3,[0],[0]
"= O(ε √ log(1/ε)).
",A Omitted Details from Section 3,[0],[0]
"This proves part (i) of Proposition A.7.
",A Omitted Details from Section 3,[0],[0]
Case of Large Spectral Norm.,A Omitted Details from Section 3,[0],[0]
"We next show the correctness of the algorithm when it returns a filter in Step 5.
",A Omitted Details from Section 3,[0],[0]
We start by proving that if λ∗ def = ‖Σ,A Omitted Details from Section 3,[0],[0]
"− I‖2 > Cε log(1/ε), for a sufficiently large universal constant C, then a value T satisfying the condition in Step 5 exists.",A Omitted Details from Section 3,[0],[0]
We first note that that ‖ME‖2 is appropriately large.,A Omitted Details from Section 3,[0],[0]
"Indeed, by Corollary A.13 and the assumption that λ∗ >",A Omitted Details from Section 3,[0],[0]
Cε log(1/ε),A Omitted Details from Section 3,[0],[0]
"we deduce that
(|E|/|S′|)‖ME‖2 = Ω(λ∗) .",A Omitted Details from Section 3,[0],[0]
"(2)
Moreover, using the inequality ‖ME‖2 ≥ ‖µE − µG‖22 and Lemma A.12 as above, we get that
‖µS ′",A Omitted Details from Section 3,[0],[0]
"− µG‖2 ≤ (|E|/|S′|) √ ‖ME‖2 +O(ε √ log(1/ε)) ≤ δ/2 , (3)
where we used the fact that δ def = √ ελ∗ > C ′ε √ log(1/ε).
",A Omitted Details from Section 3,[0],[0]
Suppose for the sake of contradiction that for all T > 0,A Omitted Details from Section 3,[0],[0]
"we have that
Pr X∈uS′
[ |v∗ · (X − µS ′ )",A Omitted Details from Section 3,[0],[0]
| > T,A Omitted Details from Section 3,[0],[0]
+ δ,A Omitted Details from Section 3,[0],[0]
],A Omitted Details from Section 3,[0],[0]
≤ 8 exp(−T 2/2ν),A Omitted Details from Section 3,[0],[0]
"+ 8 ε
T 2 log ( d log( dετ ) ) .",A Omitted Details from Section 3,[0],[0]
"Using (3), we obtain that for all T > 0",A Omitted Details from Section 3,[0],[0]
"we have that
Pr X∈uS′
[ |v∗ · (X − µG)| > T + δ/2 ] ≤ 8 exp(−T 2/2ν)",A Omitted Details from Section 3,[0],[0]
"+ 8 ε
T 2 log ( d log( dετ ) ) .",A Omitted Details from Section 3,[0],[0]
"(4) Since E ⊆ S′, for all x ∈ Rd we have that |S′|PrX∈uS′ [X = x] ≥",A Omitted Details from Section 3,[0],[0]
|E|PrY ∈uE,A Omitted Details from Section 3,[0],[0]
[Y = x].,A Omitted Details from Section 3,[0],[0]
"This fact combined with (4) implies that for all T > 0
Pr X∈uE
[ |v∗ · (X − µG)| > T + δ/2 ] (|S′|/|E|) ( exp(−T 2/2ν)",A Omitted Details from Section 3,[0],[0]
+,A Omitted Details from Section 3,[0],[0]
"ε
T 2 log ( d log( dετ )
)) .",A Omitted Details from Section 3,[0],[0]
"(5)
We now have the following sequence of inequalities: ‖ME‖2 = EX∈uE [ |v∗ · (X − µG)|2 ] = 2 ∫ ∞ 0",A Omitted Details from Section 3,[0],[0]
Pr X∈uE [ |v∗ · (X − µG)| > T ],A Omitted Details from Section 3,[0],[0]
"TdT
= 2 ∫ O(√d",A Omitted Details from Section 3,[0],[0]
log(d/ετ)) 0,A Omitted Details from Section 3,[0],[0]
Pr X∈uE [ |v∗ · (X − µG)| > T ],A Omitted Details from Section 3,[0],[0]
"TdT
≤ 2 ∫ O(√d log(d/ετ))
0
min { 1, |S′| |E| · Pr X∈uS′ [ |v∗ · (X − µG)| > T ]} TdT
∫ 4√ν log(|S′|/|E|)+δ
0
",A Omitted Details from Section 3,[0],[0]
TdT + (|S′|/|E|) ∫ O(√d,A Omitted Details from Section 3,[0],[0]
"log(d/ετ))
4 √ ν",A Omitted Details from Section 3,[0],[0]
"log(|S′|/|E|)+δ
( exp(−T 2/2ν)",A Omitted Details from Section 3,[0],[0]
"+ ε
T 2 log ( d log( dετ ) ))",A Omitted Details from Section 3,[0],[0]
TdT log(|S′|/|E|),A Omitted Details from Section 3,[0],[0]
+,A Omitted Details from Section 3,[0],[0]
"δ2 +O(1) + ε · |S′|/|E| log(|S′|/|E|) + ελ∗ + ε · |S′|/|E| .
",A Omitted Details from Section 3,[0],[0]
"Rearranging the above, we get that
(|E|/|S′|)‖ME‖2 (|E|/|S′|) log(|S′|/|E|)",A Omitted Details from Section 3,[0],[0]
"+ (|E|/|S′|)ελ∗ + ε = O(ε log(1/ε) + ε2λ∗).
",A Omitted Details from Section 3,[0],[0]
"Combined with (2), we obtain λ∗ = O(ε log(1/ε)), which is a contradiction if C is sufficiently large.",A Omitted Details from Section 3,[0],[0]
"Therefore, it must be the case that for some value of T the condition in Step 5 is satisfied.
",A Omitted Details from Section 3,[0],[0]
"The following claim completes the proof:
Claim A.14.",A Omitted Details from Section 3,[0],[0]
Fix α def = d log(d/ετ) log(d log( dετ )).,A Omitted Details from Section 3,[0],[0]
"We have that ∆(S, S ′′) ≤ ∆(S, S′)− 2ε/α .",A Omitted Details from Section 3,[0],[0]
Proof.,A Omitted Details from Section 3,[0],[0]
"Recall that S′ = (S \L)∪E, with E and L disjoint multisets such that L ⊂ S.",A Omitted Details from Section 3,[0],[0]
"We can similarly write S′′ = (S \ L′) ∪ E′, with L′ ⊇ L and E′ ⊂ E.",A Omitted Details from Section 3,[0],[0]
"Since
∆(S, S′)−∆(S, S′′) = |E",A Omitted Details from Section 3,[0],[0]
"\ E ′| − |L′ \ L| |S| ,
it suffices to show that |E",A Omitted Details from Section 3,[0],[0]
\E′| ≥ |L′ \L|+ ε|S|/α.,A Omitted Details from Section 3,[0],[0]
"Note that |L′ \L| is the number of points rejected by the filter that lie in S ∩ S′. Note that the fraction of elements of S that are removed to produce S′′ (i.e., satisfy |v∗ · (x − µS′)| > T + δ) is at most 2 exp(−T 2/2ν)",A Omitted Details from Section 3,[0],[0]
+ ε/α.,A Omitted Details from Section 3,[0],[0]
"This follows from Claim A.9 and the fact that T = O( √ d log(d/ετ)).
",A Omitted Details from Section 3,[0],[0]
"Hence, it holds that |L′ \ L| ≤ (2 exp(−T 2/2ν) + ε/α)|S|.",A Omitted Details from Section 3,[0],[0]
"On the other hand, Step 5 of the algorithm ensures that the fraction of elements of S′ that are rejected by the filter is at least 8 exp(−T 2/2ν) + 8ε/α).",A Omitted Details from Section 3,[0],[0]
Note that |E,A Omitted Details from Section 3,[0],[0]
\ E′| is the number of points rejected by the filter that lie in S′ \,A Omitted Details from Section 3,[0],[0]
"S. Therefore, we can write:
|E",A Omitted Details from Section 3,[0],[0]
"\ E′| ≥ (8 exp(−T 2/2ν) + 8ε/α)|S′| − (2 exp(−T 2/2ν) + ε/α)|S| ≥ (8 exp(−T 2/2ν) + 8ε/α)|S|/2− (2 exp(−T 2/2ν) + ε/α)|S| ≥ (2 exp(−T 2/2ν) + 3ε/α)|S| ≥ |L′ \ L|+ 2ε|S|/α ,
where the second line uses the fact that |S′| ≥ |S|/2 and the last line uses the fact that |L′ \ L|/|S| ≤ 2 exp(−T 2/2ν)",A Omitted Details from Section 3,[0],[0]
+ ε/α.,A Omitted Details from Section 3,[0],[0]
"Noting that log(d/ετ) ≥ 1, this completes the proof of the claim.
",A Omitted Details from Section 3,[0],[0]
"A.1.3 Proof of Lemma A.5
Proof.",A Omitted Details from Section 3,[0],[0]
"Let N = Ω((d/ε2) poly log(d/ετ)) be the number of samples drawn from G. For (i), the probability that a coordinate of a sample is at least √ 2ν log(Nd/3τ) is at most τ/3dN by Fact A.2.",A Omitted Details from Section 3,[0],[0]
"By a union bound,
the probability that all coordinates of all samples are smaller than √
2ν log(Nd/3τ) is at least 1 − τ/3.",A Omitted Details from Section 3,[0],[0]
"In this case, ‖x‖2 ≤ √ 2νd log(Nd/3τ) =",A Omitted Details from Section 3,[0],[0]
"O( √ dν log(Nν/τ)).
",A Omitted Details from Section 3,[0],[0]
"After translating by µG, we note that (iii) follows immediately from Lemmas 4.3 of [DKK+16] and (iv) follows from Theorem 5.50 of [Ver10], as long as N = Ω(ν4d log(1/τ)/ε2), with probability at least 1− τ/3.",A Omitted Details from Section 3,[0],[0]
"It remains to show that, conditioned on (i), (ii) holds with probability at least 1− τ/3.
",A Omitted Details from Section 3,[0],[0]
"To simplify some expressions, let δ := ε/(log(d log d/ετ)) and R = C √ d log(|S|/τ).",A Omitted Details from Section 3,[0],[0]
We need to show that for all unit vectors v and all 0 ≤ T ≤,A Omitted Details from Section 3,[0],[0]
R that∣∣∣∣ PrX∈uS[|v · (X − µG)| > T ],A Omitted Details from Section 3,[0],[0]
− PrX∼G[|v · (X − µG) > T ≥ 0] ∣∣∣∣ ≤ δT 2 .,A Omitted Details from Section 3,[0],[0]
"(6)
Firstly, we show that for all unit vectors v and T > 0∣∣∣∣",A Omitted Details from Section 3,[0],[0]
PrX∈uS[|v · (X − µG)| > T,A Omitted Details from Section 3,[0],[0]
],A Omitted Details from Section 3,[0],[0]
− PrX∼G[|v · (X − µG)| > T ≥ 0],A Omitted Details from Section 3,[0],[0]
"∣∣∣∣ ≤ δ10ν ln(1/δ)
with probability at least 1 − τ/6.",A Omitted Details from Section 3,[0],[0]
"Since the VC-dimension of the set of all halfspaces is d + 1, this follows from the VC inequality [DL01], since we have more than Ω(d/(δ/(10ν log(1/δ))2) samples.",A Omitted Details from Section 3,[0],[0]
We thus only need to consider the case,A Omitted Details from Section 3,[0],[0]
"when T ≥ √ 10ν ln(1/δ).
",A Omitted Details from Section 3,[0],[0]
Lemma A.15.,A Omitted Details from Section 3,[0],[0]
"For any fixed unit vector v and T > √
10ν ln(1/δ), except with probability exp(−Nδ/(6Cν)), we have that
Pr X∈uS",A Omitted Details from Section 3,[0],[0]
"[|v · (X − µG)| > T ] ≤ δ CT 2 ,
where C = 8.
",A Omitted Details from Section 3,[0],[0]
Proof.,A Omitted Details from Section 3,[0],[0]
Let E be the event that |v · (X − µG)| > T .,A Omitted Details from Section 3,[0],[0]
"Since G is sub-gaussian, Fact A.2 yields that PrG[E] =",A Omitted Details from Section 3,[0],[0]
PrY∼G[|v · (X − µG)| > T,A Omitted Details from Section 3,[0],[0]
] ≤ exp(−T 2/(2ν)).,A Omitted Details from Section 3,[0],[0]
"Note that, thanks to our assumption on T , we have that T ≤",A Omitted Details from Section 3,[0],[0]
"exp(T 2/(4ν))/2C, and therefore T 2 PrG[E] ≤",A Omitted Details from Section 3,[0],[0]
"exp(−T 2/(4ν))/2C ≤ δ/2C.
Consider ES [exp(t2/(3ν) ·",A Omitted Details from Section 3,[0],[0]
N PrS,A Omitted Details from Section 3,[0],[0]
[E])].,A Omitted Details from Section 3,[0],[0]
Each individual sample Xi for 1 ≤,A Omitted Details from Section 3,[0],[0]
"i ≤ N , is an independent copy of Y ∼ G, and hence:
ES [ exp ( T 2
3ν ·N Pr S",A Omitted Details from Section 3,[0],[0]
"[E]
)]",A Omitted Details from Section 3,[0],[0]
"= ES [ exp ( T 2
3ν ) · n∑ i=1 1Xi∈E) ]
= N∏ i=1",A Omitted Details from Section 3,[0],[0]
"EXi
[ exp ( T 2
3ν ) · n∑ i=1 1Xi∈E) ]
= ( exp ( T 2
3ν )",A Omitted Details from Section 3,[0],[0]
Pr G,A Omitted Details from Section 3,[0],[0]
"[G] + 1 )N (a)
≤ ( exp ( T 2
6ν
)",A Omitted Details from Section 3,[0],[0]
"+ 1 )N (b) ≤ (1 + δ5/3)N
(c) ≤ exp(Nδ5/3) ,
where (a) follows from sub-gaussianity, (b) follows from our choice of T , and (c) comes from the fact that 1 + x ≤ ex for all x.
Hence, by Markov’s inequality, we have
Pr [ Pr S [E] ≥ δ CT 2 ]",A Omitted Details from Section 3,[0],[0]
≤ exp,A Omitted Details from Section 3,[0],[0]
( Nδ5/3 − δN 3C ) = exp(Nδ(δ2/3,A Omitted Details from Section 3,[0],[0]
"− 1/(3C))) .
",A Omitted Details from Section 3,[0],[0]
"Thus, if δ is a sufficiently small constant and C is sufficiently large, this yields the desired bound.
",A Omitted Details from Section 3,[0],[0]
Now let C be a 1/2-cover in Euclidean distance for the set of unit vectors of size 2O(d).,A Omitted Details from Section 3,[0],[0]
"By a union bound, for all v′ ∈ C and T ′ a power of 2 between √ 4ν ln(1/δ) and R, we have that
Pr X∈uS",A Omitted Details from Section 3,[0],[0]
"[|v′ · (X − µG)| > T ′] ≤ δ 8T 2
except with probability
2O(d) log(R) exp(−Nδ/6Cν) = exp (O(d) + log logR−Nδ/6Cν) ≤ τ/6 .
",A Omitted Details from Section 3,[0],[0]
"However, for any unit vector v and √
4ν ln(1/δ) ≤ T ≤ R, there is a v′ ∈ C and such a T ′ such that for all x ∈ Rd, we have |v · (X − µG)| ≥ |v′ · (X − µG)|/2, and so |v′ · (",A Omitted Details from Section 3,[0],[0]
X − µG)|,A Omitted Details from Section 3,[0],[0]
>,A Omitted Details from Section 3,[0],[0]
2T ′ implies |v′ · (X − µG)| >,A Omitted Details from Section 3,[0],[0]
"T.
Then, by a union bound, (6) holds simultaneously for all unit vectors v and all 0 ≤ T ≤ R, with probability a least 1− τ/3.",A Omitted Details from Section 3,[0],[0]
"This completes the proof.
",A Omitted Details from Section 3,[0],[0]
"A.2 Robust Mean Estimation Under Second Moment Assumptions
In this section, we use our filtering technique to give a near sample-optimal computationally efficient algorithm to robustly estimate the mean of a density with a second moment assumption.",A Omitted Details from Section 3,[0],[0]
"We show:
Theorem A.16.",A Omitted Details from Section 3,[0],[0]
Let P be a distribution on Rd with unknown mean vector µP and unknown covariance matrix ΣP I.,A Omitted Details from Section 3,[0],[0]
Let S be an ε-corrupted set of samples from P of size Θ((d/ε) log d).,A Omitted Details from Section 3,[0],[0]
"Then there exists an algorithm that given S, with probability 2/3, outputs µ̂ with ‖µ̂− µP ‖2 ≤ O( √ ε) in time poly(d/ε).
",A Omitted Details from Section 3,[0],[0]
"Note that Theorem 3.2 follows straightforwardly from the above (divide every sample by σ, run the algorithm of Theorem A.16, and multiply its output by σ).
",A Omitted Details from Section 3,[0],[0]
"As usual in our filtering framework, the algorithm will iteratively look at the top eigenvalue and eigenvector of the sample covariance matrix and return the sample mean if this eigenvalue is small (Algorithm 3).",A Omitted Details from Section 3,[0],[0]
The main difference between this and the filter algorithm for the sub-gaussian case is how we choose the threshold for the filter.,A Omitted Details from Section 3,[0],[0]
"Instead of looking for a violation of a concentration inequality, here we will choose a threshold at random (with a bias towards higher thresholds).",A Omitted Details from Section 3,[0],[0]
"The reason is that, in this setting, the variance in the direction we look for a filter in needs to be a constant multiple larger – instead of the typical Ω̃(ε) relative for the sub-gaussian case.",A Omitted Details from Section 3,[0],[0]
"Therefore, randomly choosing a threshold weighted towards higher thresholds suffices to throw out more corrupted samples than uncorrupted samples in expectation.",A Omitted Details from Section 3,[0],[0]
"Although it is possible to reject many good samples this way, the algorithm still only rejects a total of O(ε) samples with high probability.
",A Omitted Details from Section 3,[0],[0]
We would like our good set of samples to have mean close to that of P and bounded variance in all directions.,A Omitted Details from Section 3,[0],[0]
"This motivates the following definition:
Definition A.17.",A Omitted Details from Section 3,[0],[0]
"We call a set S ε-good for a distribution P with mean µP and covariance ΣP I if the mean µS and covariance ΣS of S satisfy ‖µS − µP ‖2 ≤ √ ε and ‖ΣS‖2 ≤ 2.
",A Omitted Details from Section 3,[0],[0]
"However, since we have no assumptions about higher moments, it may be be possible for outliers to affect our sample covariance too much.",A Omitted Details from Section 3,[0],[0]
"Fortunately, such outliers have small probability and do not contribute too much to the mean, so we will later reclassify them as errors.
",A Omitted Details from Section 3,[0],[0]
Lemma A.18.,A Omitted Details from Section 3,[0],[0]
Let S be N = Θ((d/ε) log d) samples drawn from P .,A Omitted Details from Section 3,[0],[0]
"Then, with probability at least 9/10, a random X ∈u S satisfies
(i) ‖ES",A Omitted Details from Section 3,[0],[0]
"[X]− µP ‖2 ≤ √ ε/3,
(ii)",A Omitted Details from Section 3,[0],[0]
"PrS [ ‖X − µP ‖2 ≥ 80 √ d/ε ] ≤ ε/160,
(iii) ∥∥∥ES",A Omitted Details from Section 3,[0],[0]
"[(X − µP ) · 1‖X−µP ‖2≤80√d/ε]∥∥∥2 ≤ √ε/3, and
(iv) ∥∥∥ES",A Omitted Details from Section 3,[0],[0]
"[(X − µP )(X − µP )T · 1‖X−µP ‖2≤80√d/ε]∥∥∥2 ≤ 3/2.
",A Omitted Details from Section 3,[0],[0]
Proof.,A Omitted Details from Section 3,[0],[0]
"For (i), note that ES [‖E[X]− µP ‖22] = ∑ i ES",A Omitted Details from Section 3,[0],[0]
[(E[X]i − µPi )2] ≤,A Omitted Details from Section 3,[0],[0]
"d/N ≤ ε/360 ,
and so by Markov’s inequality, with probability at least 39/40, we have ‖E[X]− µP ‖22 ≤ ε/9.
",A Omitted Details from Section 3,[0],[0]
"For (ii), similarly to (i), note that E[‖Y − µP ‖22] = ∑ i E",A Omitted Details from Section 3,[0],[0]
[ (Yi − µPi )2 ] ≤,A Omitted Details from Section 3,[0],[0]
"d ,
for Y ∼ P .",A Omitted Details from Section 3,[0],[0]
"By Markov’s inequality, Pr[‖Y − µP ‖2 ≥ 80 √ d/ε] ≤ ε/160 with probability at least 39/40.
",A Omitted Details from Section 3,[0],[0]
"For (iii), let ν = EX∼P",A Omitted Details from Section 3,[0],[0]
[X · 1‖X−µP ‖2≤80 √ d/ε ] be the true mean of the distribution when we condition on the event,A Omitted Details from Section 3,[0],[0]
that ‖X − µP ‖2 ≤ 80 √ d/ε.,A Omitted Details from Section 3,[0],[0]
"By the same argument as (i), we know that∥∥∥EX∈uS",A Omitted Details from Section 3,[0],[0]
[X · 1‖X−µP ‖2≤80√d/ε]− ν∥∥∥2 ≤,A Omitted Details from Section 3,[0],[0]
"√ε/9 ,
with probability at least 39/40.",A Omitted Details from Section 3,[0],[0]
Thus it suffices to show that ∥∥∥ν − µP ·,A Omitted Details from Section 3,[0],[0]
1‖X−µP ‖2≤80√d/ε∥∥∥2 ≤ √ε/10.,A Omitted Details from Section 3,[0],[0]
"To do so, it suffices to show that for all unit vectors v ∈ Rd, we have∣∣∣〈v, ν",A Omitted Details from Section 3,[0],[0]
− µP · 1‖X−µP ‖2≤80√d/ε〉∣∣∣ <,A Omitted Details from Section 3,[0],[0]
√ε/10 .,A Omitted Details from Section 3,[0],[0]
"Observe that for any such v, we have〈
v, µP · 1‖X−µP ‖2≤80 √ d/ε",A Omitted Details from Section 3,[0],[0]
"− ν 〉 = EX∼P [〈 v,X − µP 〉 · 1‖X−µP ‖2≤80 √ d/ε ]",A Omitted Details from Section 3,[0],[0]
"(a)
≤ √
EX∼P",A Omitted Details from Section 3,[0],[0]
"[〈v,X − µP 〉2]",A Omitted Details from Section 3,[0],[0]
"Pr X∼P
[",A Omitted Details from Section 3,[0],[0]
"‖X − µP ‖2 ≥ 80 √ d/ε]
(b) = √ vTΣP v ·",A Omitted Details from Section 3,[0],[0]
"Pr
X∼P
[ ‖X − µP ‖2 ≥ 80 √ d/ε ]
(c) ≤",A Omitted Details from Section 3,[0],[0]
"√ ε/10 ,
where (a) follows from Cauchy-Schwarz, and (b) follows from the definition of the covariance, and (c) follows from the assumption that ΣP I and from Markov’s inequality.
",A Omitted Details from Section 3,[0],[0]
"For (iv), we require the following Matrix Chernoff bound:
Lemma A.19 (Part of Theorem 5.1.1 of [T+15]).",A Omitted Details from Section 3,[0],[0]
Consider a sequence of d×d positive semi-definite random matrices Xk with ‖Xk‖2 ≤,A Omitted Details from Section 3,[0],[0]
L for all k. Let µmax = ‖ ∑,A Omitted Details from Section 3,[0],[0]
k E[Xk]‖2.,A Omitted Details from Section 3,[0],[0]
"Then, for θ > 0,
E [∥∥∥∥∥∑ k Xk ∥∥∥∥∥ 2 ] ≤ (eθ − 1)µmax/θ + L log(d)/θ ,
and for any δ > 0,
Pr [∥∥∥∥∥∑ k Xk ∥∥∥∥∥ 2 ≥ (1 + δ)µmax ] ≤ d(eδ/(1 + δ)1+δ)µ max/L .
",A Omitted Details from Section 3,[0],[0]
We apply this lemma with Xk = (xk − µP ),A Omitted Details from Section 3,[0],[0]
(xk − µP )T 1‖xk−µP,A Omitted Details from Section 3,[0],[0]
"‖2≤80 √ d/ε for {x1, . . .",A Omitted Details from Section 3,[0],[0]
", xN}",A Omitted Details from Section 3,[0],[0]
= S. Note that ‖Xk‖2 ≤ (80)2d/ε = L and that µmax ≤,A Omitted Details from Section 3,[0],[0]
N‖ΣP,A Omitted Details from Section 3,[0],[0]
"‖2 ≤ N .
",A Omitted Details from Section 3,[0],[0]
Suppose that µmax ≤ N/80.,A Omitted Details from Section 3,[0],[0]
"Then, taking θ = 1, we have
E[ ∥∥∥∥∥∑ k Xk ∥∥∥∥∥ 2 ] ≤ (e− 1)N/80 +O(d log(d)/ε) .
",A Omitted Details from Section 3,[0],[0]
"By Markov’s inequality, except with probability 39/40, we have ‖ ∑ kXk‖2 ≤",A Omitted Details from Section 3,[0],[0]
N +,A Omitted Details from Section 3,[0],[0]
"O(d log(d)/ε) ≤ 3N/2, for N a sufficiently high multiple of d log(d)/ε.",A Omitted Details from Section 3,[0],[0]
"Suppose that µmax ≥ N/80, then we take δ = 1/2 and obtain
Pr [∥∥∥∥∥∑ k Xk ∥∥∥∥∥ 2 ≥ 3µmax2 ] ≤",A Omitted Details from Section 3,[0],[0]
"d(e3/2/(5/2)3/2)Nε/20d .
",A Omitted Details from Section 3,[0],[0]
"For N a sufficiently high multiple of d log(d)/ε, we get that Pr[‖ ∑ kXk‖2 ≥ 3µ
max/2] ≤ 1/40.",A Omitted Details from Section 3,[0],[0]
"Since µmax ≤ N , we have with probability at least 39/40, ‖ ∑ kXk‖2 ≤ 3N/2.
",A Omitted Details from Section 3,[0],[0]
Noting that ‖ ∑ kXk‖2 /N,A Omitted Details from Section 3,[0],[0]
=,A Omitted Details from Section 3,[0],[0]
"‖E[1‖X−µP ‖2≤80 √ d/ε
(X − µP )(X − µP )",A Omitted Details from Section 3,[0],[0]
"T ]‖2, we obtain (iv).",A Omitted Details from Section 3,[0],[0]
"By a union bound, (i)-(iv) all hold simultaneously with probability at least 9/10.
",A Omitted Details from Section 3,[0],[0]
"Now we can get a 2ε-corrupted good set from an ε-corrupted set of samples satisfying Lemma A.18, by reclassifying outliers as errors:
Lemma A.20.",A Omitted Details from Section 3,[0],[0]
"Let S = R ∪E \L, where R is a set of N = Θ(d log d/ε) samples drawn from P and E and L are disjoint sets with |E|, |L| ≤ ε.",A Omitted Details from Section 3,[0],[0]
"Then, with probability 9/10, we can also write S = G ∪ E′ \",A Omitted Details from Section 3,[0],[0]
"L′, where G ⊆ R is ε-good, L′ ⊆ L and E′ ⊆ E′ has |E′| ≤ 2ε|S|.",A Omitted Details from Section 3,[0],[0]
Proof.,A Omitted Details from Section 3,[0],[0]
Let G = {x ∈ R : ‖x‖2 ≤ 80 √ d/ε}.,A Omitted Details from Section 3,[0],[0]
Condition on the event that R satisfies Lemma A.18.,A Omitted Details from Section 3,[0],[0]
"By Lemma A.18, this occurs with probability at least 9/10.",A Omitted Details from Section 3,[0],[0]
"Since R satisfies (ii) of Lemma A.18, |G|",A Omitted Details from Section 3,[0],[0]
− |R| ≤ ε|R|/160 ≤ ε|S|.,A Omitted Details from Section 3,[0],[0]
"Thus, E′ = E ∪ (R \ G) has |E′| ≤ 3ε/2.",A Omitted Details from Section 3,[0],[0]
"Note that (iv) of Lemma A.18 for R in terms of G is exactly |G|‖ΣG‖2/|R| ≤ 3/2, and so ‖ΣG‖2 ≤ 3|R|/(2|G|) ≤ 2.
",A Omitted Details from Section 3,[0],[0]
It remains to check that ‖µG,A Omitted Details from Section 3,[0],[0]
− µP ‖2 ≤ √ ε.,A Omitted Details from Section 3,[0],[0]
"We have∥∥|G| · µG − |G| · µP∥∥
2 = |R| ·",A Omitted Details from Section 3,[0],[0]
∥∥∥EX∼uR,A Omitted Details from Section 3,[0],[0]
[(X − µP ) · 1‖X−µP ‖2≤80√d/ε]∥∥∥2 ≤,A Omitted Details from Section 3,[0],[0]
"|R| · √ ε/3 ,
where the last line follows from (iii) of Lemma A.18.",A Omitted Details from Section 3,[0],[0]
"Since we argued above that |R|/|G| ≥ 2/3, dividing this expression by |G| yields the desired claim.
",A Omitted Details from Section 3,[0],[0]
"Algorithm 3 Filter under second moment assumptions
1: function FilterUnder2ndMoment(S) 2: Compute µS , ΣS , the mean and covariance matrix of S. 3: Find the eigenvector v∗ with highest eigenvalue λ∗ of ΣS .",A Omitted Details from Section 3,[0],[0]
"4: if λ∗ ≤ 9 then 5: return µS 6: else 7: Draw Z from the distribution on [0, 1] with probability density function 2x. 8: Let T = Z max{|v∗ · x− µS",A Omitted Details from Section 3,[0],[0]
| : x ∈ S}.,A Omitted Details from Section 3,[0],[0]
"9: Return the set S′ = {x ∈ S : |v∗ · (X − µS)| < T}.
",A Omitted Details from Section 3,[0],[0]
An iteration of FilterUnder2ndMoment may throw out more samples from G than corrupted samples.,A Omitted Details from Section 3,[0],[0]
"However, in expectation, we throw out many more corrupted samples than from the good set:
Proposition A.21.",A Omitted Details from Section 3,[0],[0]
"If we run FilterUnder2ndMoment on a set S = G ∪ E \ L for some ε-good set G and disjoint E,L with |E| ≤ 2ε|S|, |L| ≤ 9ε|S|, then either it returns µS with ‖µS − µP ‖2 ≤ O( √ ε), or else it returns a set S′ ⊂",A Omitted Details from Section 3,[0],[0]
S with S′ = G ∪ E′ \,A Omitted Details from Section 3,[0],[0]
L′ for disjoint E′ and L′.,A Omitted Details from Section 3,[0],[0]
In the latter case we have EZ [|E′|+ 2|L′|],A Omitted Details from Section 3,[0],[0]
"≤ |E|+ 2|L|.
",A Omitted Details from Section 3,[0],[0]
"For D ∈ {G,E,L, S}, let µD be the mean of D and MD be the matrix EX∈uD[(X − µS)(X",A Omitted Details from Section 3,[0],[0]
− µS)T ].,A Omitted Details from Section 3,[0],[0]
Lemma A.22.,A Omitted Details from Section 3,[0],[0]
"If G is an ε-good set with x ≤ 40 √ d/ε for x ∈ S ∪G, then ‖MG‖2 ≤ 2‖µG − µS‖22 + 2 .
",A Omitted Details from Section 3,[0],[0]
Proof.,A Omitted Details from Section 3,[0],[0]
"For any unit vector v, we have
vTMGv = EX∈uG[(v · (X − µS))2] = EX∈uG[(v · (X − µG) + v · (µP − µG))2] = vTΣGv +",A Omitted Details from Section 3,[0],[0]
"(v · (µG − µS))2
≤ 2 + 2‖µG − µS‖22 .
",A Omitted Details from Section 3,[0],[0]
Lemma A.23.,A Omitted Details from Section 3,[0],[0]
We have that |L|‖ML‖2 ≤ 2|G|(1 + ‖µG,A Omitted Details from Section 3,[0],[0]
"− µS‖22) .
",A Omitted Details from Section 3,[0],[0]
Proof.,A Omitted Details from Section 3,[0],[0]
"Since L ⊆ G, for any unit vector v, we have
|L|vTMLv = |L|EX∈uL[(v · (X − µS))2] ≤ |G|EX∈uG[(v · (X − µS))2] ≤ 2|G|(1 + ‖µG",A Omitted Details from Section 3,[0],[0]
"− µS‖22) .
",A Omitted Details from Section 3,[0],[0]
Lemma A.24.,A Omitted Details from Section 3,[0],[0]
‖µG,A Omitted Details from Section 3,[0],[0]
"− µS‖2 ≤ √ 2ε‖MS‖2 + 12 √ ε.
",A Omitted Details from Section 3,[0],[0]
Proof.,A Omitted Details from Section 3,[0],[0]
We have that |E|ME ≤,A Omitted Details from Section 3,[0],[0]
|S|MS +,A Omitted Details from Section 3,[0],[0]
"|L|ML and so
|E|‖ME‖2 ≤ |S|‖MS‖2 +",A Omitted Details from Section 3,[0],[0]
2|G|(1 + ‖µG,A Omitted Details from Section 3,[0],[0]
"− µS‖22) .
",A Omitted Details from Section 3,[0],[0]
"By Cauchy Schwarz, we have that ‖ME‖2 ≥ ‖µE − µS‖22, and so√ |E|‖µE",A Omitted Details from Section 3,[0],[0]
− µS‖2 ≤ √ |S|‖MS‖2 +,A Omitted Details from Section 3,[0],[0]
2|G|(1 + ‖µG,A Omitted Details from Section 3,[0],[0]
"− µS‖22) .
",A Omitted Details from Section 3,[0],[0]
"By Cauchy-Schwarz and Lemma A.23, we have that√ |L|‖µL − µS‖2 ≤ √ |L|‖ML‖2 ≤",A Omitted Details from Section 3,[0],[0]
√ 2|G|(1 + ‖µG,A Omitted Details from Section 3,[0],[0]
"− µS‖22) .
",A Omitted Details from Section 3,[0],[0]
"Since |S|µS = |G|µG + |E|µE − |L|µL and |S| = |G|+ |E| − |L|, we get
|G|(µG",A Omitted Details from Section 3,[0],[0]
− µS),A Omitted Details from Section 3,[0],[0]
= |E|(µE,A Omitted Details from Section 3,[0],[0]
− µS)− |L|(µE,A Omitted Details from Section 3,[0],[0]
"− µS) .
",A Omitted Details from Section 3,[0],[0]
"Substituting into this, we obtain |G|‖µG − µS‖2 ≤ √ |E||S|‖MS‖2 + 2|E||G|(1 +",A Omitted Details from Section 3,[0],[0]
‖µG,A Omitted Details from Section 3,[0],[0]
− µS‖22) + √ 2|L||G|(1 + ‖µG,A Omitted Details from Section 3,[0],[0]
− µS‖22) .,A Omitted Details from Section 3,[0],[0]
"Since for x, y > 0, √ x+ y ≤",A Omitted Details from Section 3,[0],[0]
"√ x+ √ y, we have
|G|‖µG − µS‖2 ≤ √ |E||S|‖MS‖2 +",A Omitted Details from Section 3,[0],[0]
(,A Omitted Details from Section 3,[0],[0]
"√ 2|E||G|+ √ 2|L||G|)(1 + ‖µG − µS‖2) .
",A Omitted Details from Section 3,[0],[0]
"Since ||G| − |S|| ≤ ε|S| and |E| ≤ 2ε|S|, |L| ≤ 9ε|S|, we have
‖µG",A Omitted Details from Section 3,[0],[0]
− µS‖2 ≤ √ 2ε‖MS‖2 + (6 √ ε)(1 + ‖µG,A Omitted Details from Section 3,[0],[0]
"− µS‖2) .
",A Omitted Details from Section 3,[0],[0]
Moving the ‖µG,A Omitted Details from Section 3,[0],[0]
"− µS‖2 terms to the LHS, using 6 √ ε ≤ 1/2, gives
‖µG",A Omitted Details from Section 3,[0],[0]
"− µS‖2 ≤ √ 2ε‖MS‖2 + 12 √ ε .
",A Omitted Details from Section 3,[0],[0]
"Since λ∗ = ‖MS‖2, the correctness if we return the empirical mean is immediate.
",A Omitted Details from Section 3,[0],[0]
Corollary A.25.,A Omitted Details from Section 3,[0],[0]
"If λ∗ ≤ 9, we have that ‖µG",A Omitted Details from Section 3,[0],[0]
"− µS‖2 = O( √ ε).
",A Omitted Details from Section 3,[0],[0]
"From now on, we assume λ∗ > 9.",A Omitted Details from Section 3,[0],[0]
In this case we have ‖µG − µS‖22 ≤ O(ελ∗).,A Omitted Details from Section 3,[0],[0]
"Using Lemma A.22, we have
‖MG‖2 ≤ 2 +O(ελ∗) ≤ 2 + λ∗/5
for sufficiently small ε.",A Omitted Details from Section 3,[0],[0]
"Thus, we have that
v∗TMSv ∗ ≥ 4v∗TMGv∗ .",A Omitted Details from Section 3,[0],[0]
"(7)
Now we can show that in expectation, we throw out many more corrupted points from E than from G\L:
Lemma A.26.",A Omitted Details from Section 3,[0],[0]
"Let S′ = G∪E′ \L′ for disjoint E′, L′ be the set of samples returned by the iteration.",A Omitted Details from Section 3,[0],[0]
"Then we have EZ [|E′|+ 2|L′|] ≤ |E|+ 2|L|.
Proof.",A Omitted Details from Section 3,[0],[0]
Let a = maxx∈S |v∗ · x− µS,A Omitted Details from Section 3,[0],[0]
|.,A Omitted Details from Section 3,[0],[0]
"Firstly, we look at the expected number of samples we reject:
EZ",A Omitted Details from Section 3,[0],[0]
"[|S′|]− |S| = EZ [ |S| Pr
X∈uS",A Omitted Details from Section 3,[0],[0]
"[|X − µS | ≥ aZ] ] = |S|
∫ 1 0",A Omitted Details from Section 3,[0],[0]
"Pr X∈uS [ |v∗ · (X − µS)| ≥ ax ] 2xdx
= |S| ∫ a
0
Pr X∈uS
[ |v∗ · (X − µS)| ≥ T ] (2T/a)dT
= |S|EX∈uS",A Omitted Details from Section 3,[0],[0]
"[ (v∗ · (X − µS))2 ] /a = (|S|/a) · v∗TMSv∗ .
",A Omitted Details from Section 3,[0],[0]
"Next, we look at the expected number of false positive samples we reject, i.e., those in L′ \",A Omitted Details from Section 3,[0],[0]
"L.
EZ",A Omitted Details from Section 3,[0],[0]
[|L′|]− |L| = EZ [ (|G| − |L|),A Omitted Details from Section 3,[0],[0]
"Pr
X∈uG\L
[ |X − µS",A Omitted Details from Section 3,[0],[0]
| ≥ T ]] ≤,A Omitted Details from Section 3,[0],[0]
"EZ [ |G| Pr
X∈uG [|v∗ · (X − µS)| ≥ aZ]",A Omitted Details from Section 3,[0],[0]
"] = |G|
∫ 1 0",A Omitted Details from Section 3,[0],[0]
"Pr X∈uG [|v∗ · (X − µS)| ≥ ax]2x dx
= |G| ∫ a
0
Pr X∈uG
[|v∗ · (X − µS)| ≥ T ](2T/a) dT
≤ |G| ∫ ∞
0
Pr X∈uG
[|v∗ · (X − µS)| ≥ T ](2T/a) dT
= |G|EX∈uG [ (v∗ · (X − µS))2 ] /a = (|G|/a) ·",A Omitted Details from Section 3,[0],[0]
"v∗TMGv∗ .
",A Omitted Details from Section 3,[0],[0]
"Using (7), we have |S|v∗TMSv∗ ≥ 4|G|v∗TMGv∗ and so",A Omitted Details from Section 3,[0],[0]
EZ [S′] − S ≥ 3(EZ,A Omitted Details from Section 3,[0],[0]
[L′],A Omitted Details from Section 3,[0],[0]
− L).,A Omitted Details from Section 3,[0],[0]
Now consider that |S′| = |G|+,A Omitted Details from Section 3,[0],[0]
|E′| − |L′| = |S| − |E|+ |E′|+ |L|,A Omitted Details from Section 3,[0],[0]
"− |L′|, and thus |S′| − |S| =",A Omitted Details from Section 3,[0],[0]
|E| − |E′|+ |L′|,A Omitted Details from Section 3,[0],[0]
− |L|.,A Omitted Details from Section 3,[0],[0]
This yields that |E| − EZ [|E′|] ≥ 2(EZ,A Omitted Details from Section 3,[0],[0]
"[L′]− L), which can be rearranged to EZ [|E′|+ 2|L′|]",A Omitted Details from Section 3,[0],[0]
"≤ |E|+ 2|L|.
",A Omitted Details from Section 3,[0],[0]
Proof of Proposition A.21.,A Omitted Details from Section 3,[0],[0]
"If λ∗ ≤ 9, then we return the mean in Step 5, and by Corollary A.25, ‖µS−µP ‖2 ≤ O( √ ε).
",A Omitted Details from Section 3,[0],[0]
"If λ∗ > 9, then we return S′. Since at least one element of S has |v∗ ·X| = maxx∈S |v∗ ·X|, whatever value of Z is drawn, we still remove at least one element, and so have S′ ⊂ S. By Lemma A.26, we have EZ [|E′|+ 2|L′|]",A Omitted Details from Section 3,[0],[0]
"≤ |E|+ 2|L|.
",A Omitted Details from Section 3,[0],[0]
Proof of Theorem A.16.,A Omitted Details from Section 3,[0],[0]
"Our input is a set S of N = Θ((d/ε) log d) ε-corrupted samples so that with probability 9/10, S is a 2ε-corrupted set of ε-good samples for P by Lemmas A.18 and A.20.",A Omitted Details from Section 3,[0],[0]
We have a set S = G ∪ E′ \,A Omitted Details from Section 3,[0],[0]
"L, where G′ is an ε-good set, |E| ≤ 2ε, and |L| ≤ ε.",A Omitted Details from Section 3,[0],[0]
"Then, we iteratively apply FilterUnder2ndMoment until it outputs an approximation to the mean.",A Omitted Details from Section 3,[0],[0]
"Since each iteration removes a sample, this must happen within N iterations.",A Omitted Details from Section 3,[0],[0]
"The algorithm takes at most poly(N, d) = poly(d, 1/ε) time.
",A Omitted Details from Section 3,[0],[0]
"As long as we can show that the conditions of Proposition A.21 hold in each iteration, it ensures that ‖µS − µP ‖2 ≤ O( √ ε).",A Omitted Details from Section 3,[0],[0]
"However, the condition that |L| ≤ 9ε|S| need not hold in general.",A Omitted Details from Section 3,[0],[0]
"Although in expectation we reject many more samples in E than G, it is possible that we are unlucky and reject many samples in G, which could make L large in the next iteration.",A Omitted Details from Section 3,[0],[0]
"Thus, we need a bound on the probability that we ever have |L| > 9ε.
",A Omitted Details from Section 3,[0],[0]
We analyze the following procedure: We iteratively run FilterUnder2ndMoment starting with a set Si ∪ Ei \ Li of samples with S0 = S and producing a set Si+1 = G ∪ Ei+1,A Omitted Details from Section 3,[0],[0]
\,A Omitted Details from Section 3,[0],[0]
Li+1.,A Omitted Details from Section 3,[0],[0]
We stop if we output an approximation to the mean or if |Li+1| ≥ 13ε|S|.,A Omitted Details from Section 3,[0],[0]
"Since we do now always satisfy the conditions of Proposition A.21, this gives that EZ",A Omitted Details from Section 3,[0],[0]
[|Ei+1|+ |Li+1|],A Omitted Details from Section 3,[0],[0]
= |Ei|+ 2|Li|.,A Omitted Details from Section 3,[0],[0]
"This expectation is conditioned on the
state of the algorithm after previous iterations, which is determined by Si.",A Omitted Details from Section 3,[0],[0]
"Thus, if we consider the random variables Xi = |Ei| + 2|Li|, then we have E[Xi+1|Si] ≤",A Omitted Details from Section 3,[0],[0]
"Xi, i.e., the sequence Xi is a sub-martingale with respect to Xi.",A Omitted Details from Section 3,[0],[0]
"Using the convention that Si+1 = Si, if we stop in less than i iterations, and recalling that we always stop in N iterations, the algorithm fails if and only if |LN",A Omitted Details from Section 3,[0],[0]
| > 9ε|S|.,A Omitted Details from Section 3,[0],[0]
"By a simple induction or standard results on sub-martingales, we have E[XN ] ≤ X0.",A Omitted Details from Section 3,[0],[0]
Now X0 = |E0|+ 2|L0| ≤ 3ε|S|.,A Omitted Details from Section 3,[0],[0]
"Thus, E[XN ] ≤ 3ε|S|.",A Omitted Details from Section 3,[0],[0]
"By Markov’s inequality, except with probability 1/6, we have XN ≤ 18ε|S|.",A Omitted Details from Section 3,[0],[0]
"In this case, |LN | ≤ XN/2 ≤ 9ε|S|.",A Omitted Details from Section 3,[0],[0]
"Therefore, the probability that we ever have |Li| > 9ε is at most 1/6.
",A Omitted Details from Section 3,[0],[0]
"By a union bound, the probability that the uncorrupted samples satisfy Lemma A.18 and Proposition A.21 applies to every iteration is at least 9/10−1/6 ≥ 2/3.",A Omitted Details from Section 3,[0],[0]
"Thus, with at least 2/3 probability, the algorithm outputs a vector µ̂ with ‖µ̂− µP",A Omitted Details from Section 3,[0],[0]
‖2 ≤,A Omitted Details from Section 3,[0],[0]
"O( √ ε).
",A Omitted Details from Section 3,[0],[0]
"A.3 Robust Covariance Estimation
In this subsection, we give a near sample-optimal efficient robust estimator for the covariance of a zero-mean Gaussian density, thus proving Theorem 3.3.",A Omitted Details from Section 3,[0],[0]
Our algorithm is essentially identical to the filtering algorithm given in Section 8.2 of [DKK+16].,A Omitted Details from Section 3,[0],[0]
As in Section A.1 the only difference is a weaker definition of the “good set of samples” (Definition A.27) and a concentration argument (Lemma A.28) showing that a random set of uncorrupted samples of the appropriate size is good with high probability.,A Omitted Details from Section 3,[0],[0]
"Given these, the analysis of this subsection follows straightforwardly from the analysis in Section 8.2 of [DKK+16] by plugging in the modified parameters.
",A Omitted Details from Section 3,[0],[0]
"The algorithm Filter-Gaussian-Unknown-Covariance to robustly estimate the covariance of a mean 0 Gaussian in [DKK+16] is as follows:
Algorithm 4 Filter algorithm for a Gaussian with unknown covariance matrix.
1: procedure Filter-Gaussian-Unknown-Covariance(S′, ε, τ) input: A multiset S′ such that there exists an (ε, τ)-good set S with ∆(S, S′)",A Omitted Details from Section 3,[0],[0]
"≤ 2ε output: Either a set S′′ with ∆(S, S′′) < ∆(S, S′) or the parameters of a Gaussian G′ with dTV (G,G
′) = O(ε log(1/ε)).
",A Omitted Details from Section 3,[0],[0]
Let C > 0 be a sufficiently large universal constant.,A Omitted Details from Section 3,[0],[0]
2: Let Σ′ be the matrix EX∈uS′ [XXT ] and let G′ be the mean,A Omitted Details from Section 3,[0],[0]
0 Gaussian with covariance matrix Σ′. 3: if there is any x ∈ S′,A Omitted Details from Section 3,[0],[0]
so that xT,A Omitted Details from Section 3,[0],[0]
(Σ′)−1x ≥ Cd log(|S′|/τ) then 4: return S′′ = S′ − {x : xT,A Omitted Details from Section 3,[0],[0]
(Σ′)−1x ≥ Cd log(|S′|/τ)}.,A Omitted Details from Section 3,[0],[0]
"5: Compute an approximate eigendecomposition of Σ′ and use it to compute Σ′−1/2 6: Let x(1), . . .",A Omitted Details from Section 3,[0],[0]
", x(|S′|) be the elements of S ′. 7:",A Omitted Details from Section 3,[0],[0]
"For i = 1, . . .",A Omitted Details from Section 3,[0],[0]
", |S′|, let y(i) = Σ′−1/2x(i) and z(i) = y⊗2(i) .",A Omitted Details from Section 3,[0],[0]
8: Let TS′ = −I[I[T + (1/|S′|) ∑|S′| i=1,A Omitted Details from Section 3,[0],[0]
z(i)z,A Omitted Details from Section 3,[0],[0]
"T (i).
",A Omitted Details from Section 3,[0],[0]
"9: Approximate the top eigenvalue λ∗ and corresponding unit eigenvector v∗ of TS′ .. 10: Let p∗(x) = 1√
2 ((Σ′−1/2x)T v∗](Σ′−1/2x)− tr(v∗]))
11: if λ∗ ≤ (1 + Cε log2(1/ε))QG′(p∗) then 12: return G′ 13: Let µ be the median value of p∗(X) over X ∈ S′. 14: Find a T ≥ C ′",A Omitted Details from Section 3,[0],[0]
"so that
Pr X∈uS′
(|p∗(X)− µ| ≥ T + 4/3) ≥ Tail(T, d, ε, τ)
15: return S′′ = {X ∈ S′ : |p∗(X)− µ| < T}.
",A Omitted Details from Section 3,[0],[0]
"In [DKK+16], we take Tail(T, d, ε, τ) = 12 exp(−T ) + 3ε/(d",A Omitted Details from Section 3,[0],[0]
"log(N/τ))2, where N = Θ((d log(d/ετ))6/ε2) is the number of samples we took there.
",A Omitted Details from Section 3,[0],[0]
"To get a near sample-optimal algorithms, we will need a weaker definition of a good set.",A Omitted Details from Section 3,[0],[0]
"To use this, we will need to weaken the tail bound in the algorithm to Tail(T, d, ε, τ) = ε/(T 2 log2(T )), when T ≥ 10 log(1/ε).",A Omitted Details from Section 3,[0],[0]
"For T ≤ 10 log(1/ε), we take Tail(T, d, ε, τ) = 1",A Omitted Details from Section 3,[0],[0]
so that we always choose T ≥ 10 log(1/ε).,A Omitted Details from Section 3,[0],[0]
"It is easy to show
that the integrals of this tail bound used in the proofs of Lemma 8.19 and Claim 8.22 of [DKK+16] have similar bounds.",A Omitted Details from Section 3,[0],[0]
"Thus, our analysis here will sketch that these tail bounds hold for a set of Ω(d2 log5(d/ετ)/ε2) samples from the Guassian.
",A Omitted Details from Section 3,[0],[0]
"Firstly, we state the new, weaker, definition of a good set:
Definition A.27.",A Omitted Details from Section 3,[0],[0]
Let G be a Gaussian in Rd with mean 0 and covariance Σ.,A Omitted Details from Section 3,[0],[0]
Let ε > 0 be sufficiently small.,A Omitted Details from Section 3,[0],[0]
"We say that a multiset S of points in Rd is ε-good with respect to G if the following hold:
1.",A Omitted Details from Section 3,[0],[0]
"For all x ∈ S, xTΣ−1x < d+O( √ d log(d/ε)).
2.",A Omitted Details from Section 3,[0],[0]
We have that ‖Σ−1/2Cov(S)Σ−1/2,A Omitted Details from Section 3,[0],[0]
"− I‖F = O(ε).
",A Omitted Details from Section 3,[0],[0]
3.,A Omitted Details from Section 3,[0],[0]
"For all even degree-2 polynomials p, we have that Var(p(S)) = Var(p(G))(1 +O(ε)).
4.",A Omitted Details from Section 3,[0],[0]
For p an even degree-2 polynomial with E[p(G)] = 0 and Var(p(G)),A Omitted Details from Section 3,[0],[0]
"= 1, and for any T > 10 log(1/ε) we have that
Pr x∈uS
(|p(x)| > T ) ≤ ε/(T 2 log2(T )).
",A Omitted Details from Section 3,[0],[0]
It is easy to see that the algorithm and analysis of [DKK+16] can be pushed through using the above weaker definition.,A Omitted Details from Section 3,[0],[0]
"That is, if S is a good set, then G can be recovered to Õ(ε) error from an ε-corrupted version of S. Our main task will be to show that random sets of the appropriate size are good with high probability.
",A Omitted Details from Section 3,[0],[0]
Proposition A.28.,A Omitted Details from Section 3,[0],[0]
Let N be a sufficiently large constant multiple of d2 log5(d/ε)/ε2.,A Omitted Details from Section 3,[0],[0]
"Then a set S of N independent samples from G is ε-good with respect to G with high probability.
",A Omitted Details from Section 3,[0],[0]
Proof.,A Omitted Details from Section 3,[0],[0]
"First, note that it suffices to prove this when G = N(0, I).",A Omitted Details from Section 3,[0],[0]
Condition 1 follows by standard concentration bounds on ‖x‖22.,A Omitted Details from Section 3,[0],[0]
Condition 2 follows by estimating the entry-wise error between Cov(S) and I. Condition 3 is slightly more involved.,A Omitted Details from Section 3,[0],[0]
"Let {pi} be an orthonormal basis for the set of even, degree-2, mean-0 polynomials with respect to G. Define the matrix Mi,j = Ex∈uS",A Omitted Details from Section 3,[0],[0]
"[pi(x)pj(x)]− δi,j .",A Omitted Details from Section 3,[0],[0]
This condition is equivalent to ‖M‖2 = O(ε).,A Omitted Details from Section 3,[0],[0]
"Thus, it suffices to show that for every v with ‖v‖2 = 1 that vTMv = O(ε).",A Omitted Details from Section 3,[0],[0]
It actually suffices to consider a cover of such v’s.,A Omitted Details from Section 3,[0],[0]
"Note that this cover will be of size 2O(d
2).",A Omitted Details from Section 3,[0],[0]
"For each v, let pv = ∑ i vipi.",A Omitted Details from Section 3,[0],[0]
We need to show that Var(pv(S)),A Omitted Details from Section 3,[0],[0]
= 1 + O(ε).,A Omitted Details from Section 3,[0],[0]
"We can show this happens with probability 1− 2−Ω(d2), and thus it holds for all v in our cover by a union bound.",A Omitted Details from Section 3,[0],[0]
Condition 4 is substantially the most difficult of these conditions to prove.,A Omitted Details from Section 3,[0],[0]
"Naively, we would want to find a cover of all possible p and all possible T , and bound the probability that the desired condition fails.",A Omitted Details from Section 3,[0],[0]
"Unfortunately, the best a priori bound on Pr(|p(G)| > T ) are on the order of exp(−T ).",A Omitted Details from Section 3,[0],[0]
"As our cover would need to be of size 2d 2
or so, to make this work with T = d, we would require on the order of d3 samples in order to make this argument work.
",A Omitted Details from Section 3,[0],[0]
"However, we will note that this argument is sufficient to cover the case of T < 10 log(1/ε) log2(d/ε).",A Omitted Details from Section 3,[0],[0]
"Fortunately, most such polynomials p satisfy much better tail bounds.",A Omitted Details from Section 3,[0],[0]
"Note that any even, mean zero
polynomial p can be written in the form p(x) = xTAx−tr(A) for some matrix A.",A Omitted Details from Section 3,[0],[0]
We call A the associated matrix to p.,A Omitted Details from Section 3,[0],[0]
"We note by the Hanson-Wright inequality that Pr(|p(G)| > T ) = exp(−Ω(min((T/‖A‖F )2, T/‖A‖2))).",A Omitted Details from Section 3,[0],[0]
"Therefore, the tail bounds above are only as bad as described when A has a single large eigenvalue.",A Omitted Details from Section 3,[0],[0]
"To take advantage of this, we will need to break p into parts based on the size of its eigenvalues.",A Omitted Details from Section 3,[0],[0]
"We begin with a definition:
Definition A.29.",A Omitted Details from Section 3,[0],[0]
"Let Pk be the set of even, mean-0, degree-2 polynomials, so that the associated matrix A satisfies:
1.",A Omitted Details from Section 3,[0],[0]
rank(A) ≤,A Omitted Details from Section 3,[0],[0]
k 2.,A Omitted Details from Section 3,[0],[0]
‖A‖2 ≤ 1/,A Omitted Details from Section 3,[0],[0]
"√ k.
Note that for p ∈",A Omitted Details from Section 3,[0],[0]
Pk,A Omitted Details from Section 3,[0],[0]
"that |p(x)| ≤ |x|2/ √ k + √ k. Importantly, any polynomial can be written in terms of these sets.
",A Omitted Details from Section 3,[0],[0]
Lemma A.30.,A Omitted Details from Section 3,[0],[0]
"Let p be an even, degree-2 polynomial with E[p(G)] = 0,Var(p(G))",A Omitted Details from Section 3,[0],[0]
= 1.,A Omitted Details from Section 3,[0],[0]
"Then if t = blog2(d)c, it is possible to write p = 2(p1 + p2 + . .",A Omitted Details from Section 3,[0],[0]
.+,A Omitted Details from Section 3,[0],[0]
"p2t + pd) where pk ∈ Pk.
",A Omitted Details from Section 3,[0],[0]
Proof.,A Omitted Details from Section 3,[0],[0]
Let A be the associated matrix to p.,A Omitted Details from Section 3,[0],[0]
Note that ‖A‖F = Var p = 1.,A Omitted Details from Section 3,[0],[0]
Let Ak be the matrix corresponding to the top k eigenvalues of A.,A Omitted Details from Section 3,[0],[0]
"We now let p1 be the polynomial associated to A1/2, p2 be associated to (A2 − A1)/2, p4 be associated to (A4 − A2)/2, and so on.",A Omitted Details from Section 3,[0],[0]
It is clear that p = 2(p1 + p2 + . . .,A Omitted Details from Section 3,[0],[0]
+,A Omitted Details from Section 3,[0],[0]
p2t + pd).,A Omitted Details from Section 3,[0],[0]
It is also clear that the matrix associated to pk has rank at most k.,A Omitted Details from Section 3,[0],[0]
"If the matrix associated to pk had an eigenvalue more than 1/ √ k, it would need to be the case that the k/2nd largest eigenvalue of A had size at least 2/ √ k.",A Omitted Details from Section 3,[0],[0]
"This is impossible since the sum of the squares of the eigenvalues of A is at most 1.
",A Omitted Details from Section 3,[0],[0]
"This completes our proof.
",A Omitted Details from Section 3,[0],[0]
"We will also need covers of each of these sets Pk.
Lemma A.31.",A Omitted Details from Section 3,[0],[0]
"For each k, there exists a set Ck ⊂ Pk so that
1.",A Omitted Details from Section 3,[0],[0]
For each p ∈,A Omitted Details from Section 3,[0],[0]
"Pk there exists a q ∈ Ck so that ‖p(G)− q(G)‖2 ≤ (ε/d)2.
2.",A Omitted Details from Section 3,[0],[0]
|Ck| = 2O(dk log(d/ε)).,A Omitted Details from Section 3,[0],[0]
Proof.,A Omitted Details from Section 3,[0],[0]
We note that any such p is associated to a matrix A of the form A = ∑k i=1,A Omitted Details from Section 3,[0],[0]
"λiviv T i , for λi ∈",A Omitted Details from Section 3,[0],[0]
"[0, 1/ √ k] and vi orthonormal.",A Omitted Details from Section 3,[0],[0]
It suffices to let q correspond to the matrix A ′ = ∑k i=1,A Omitted Details from Section 3,[0],[0]
µiwiw T i for with |λi−µi| < (ε/d)3 and |vi − wi| <,A Omitted Details from Section 3,[0],[0]
(ε/d)3 for all i.,A Omitted Details from Section 3,[0],[0]
It is easy to let µi and wi range over covers of the interval and the sphere with appropriate errors.,A Omitted Details from Section 3,[0],[0]
This gives a set of possible q’s of size 2O(dk log(d/ε)) as desired.,A Omitted Details from Section 3,[0],[0]
"Unfortunately, some of these q will not be in Pk as they will have eigenvalues that are too large.",A Omitted Details from Section 3,[0],[0]
"However, this is easily fixed by replacing each such q by the closest element of Pk.",A Omitted Details from Section 3,[0],[0]
"This completes our proof.
",A Omitted Details from Section 3,[0],[0]
"We next will show that these covers are sufficient to express any polynomial.
",A Omitted Details from Section 3,[0],[0]
Lemma A.32.,A Omitted Details from Section 3,[0],[0]
Let p be an even degree-2 polynomial with E[p(G)],A Omitted Details from Section 3,[0],[0]
= 0 and Var(p(G)),A Omitted Details from Section 3,[0],[0]
= 1.,A Omitted Details from Section 3,[0],[0]
"It is possible to write p as a sum of O(log(d)) elements of some Ck plus another polynomial of L2 norm at most ε/d.
Proof.",A Omitted Details from Section 3,[0],[0]
"Combining the above two lemmas we have that any such p can be written as
p = (q1 + p1) + (q2 + p2) + . . .",A Omitted Details from Section 3,[0],[0]
(q2t + p2t),A Omitted Details from Section 3,[0],[0]
+ (,A Omitted Details from Section 3,[0],[0]
qd + pd) = q1 + q2 + . .,A Omitted Details from Section 3,[0],[0]
.+ q 2t +,A Omitted Details from Section 3,[0],[0]
"qd + p′ ,
where qk above is in Ck and ‖pk(G)‖2 < (ε/d)2.",A Omitted Details from Section 3,[0],[0]
"Thus, p′ = p1 + p2 + . . .",A Omitted Details from Section 3,[0],[0]
+,A Omitted Details from Section 3,[0],[0]
p2t + pd has ‖p′(G)‖2 ≤ (ε/d).,A Omitted Details from Section 3,[0],[0]
"This completes the proof.
",A Omitted Details from Section 3,[0],[0]
"The key observation now is that if |p(x)| ≥ T for ‖x‖2 ≤ √ d/ε, then writing p = q1 +q2 +q4 + . .",A Omitted Details from Section 3,[0],[0]
.+qd+p ′,A Omitted Details from Section 3,[0],[0]
"as above, it must be the case that |qk(x)| >",A Omitted Details from Section 3,[0],[0]
(T−1)/(2 log(d)),A Omitted Details from Section 3,[0],[0]
"for some k. Therefore, to prove our main result, it suffices to show that, with high probability over the choice of S, for any T ≥ 10 log(1/ε) log2(d/ε) and any q ∈ Ck for some k, that Prx∈uS(|q(x)| >",A Omitted Details from Section 3,[0],[0]
T/(2 log(d))),A Omitted Details from Section 3,[0],[0]
"< ε/(2T 2 log
2(T ) log(d)).",A Omitted Details from Section 3,[0],[0]
"Equivalently, it suffices to show that for T ≥ 10 log(1/ε) log(d/ε) it holds Prx∈uS(|q(x)| >",A Omitted Details from Section 3,[0],[0]
T/(2 log(d))),A Omitted Details from Section 3,[0],[0]
"< ε/(2T 2 log
2(T ) log2(d)).",A Omitted Details from Section 3,[0],[0]
"Note that this holds automatically for T > (d/ε), as p(x) cannot possibly be that large for ‖x‖2 ≤ √ d/ε.",A Omitted Details from Section 3,[0],[0]
"Furthermore, note that losing a constant factor in the probability, it suffices to show this only for T a power of 2.
",A Omitted Details from Section 3,[0],[0]
"Therefore, it suffices to show for every k ≤ d, every q ∈ Ck and every d/ √ kε T log(1/ε) log(d/ε)
that with probability at least 1 − 2−Ω(dk log(d/ε)) over the choice of S we have that Prx∈uS(|q(x)| > T ) ε/(T 2 log4(d/ε)).",A Omitted Details from Section 3,[0],[0]
"However, by the Hanson-Wright inequality, we have that
Pr(|q(G)| > T ) = exp(−Ω(min(T 2, T √ k)))",A Omitted Details from Section 3,[0],[0]
"< (ε/(T 2 log4(d/ε)))2 .
",A Omitted Details from Section 3,[0],[0]
"Therefore, by Chernoff bounds, the probability that more than a ε/(T 2 log4(d/ε))-fraction of the elements of S satisfy this property is at most
exp(−Ω(min(T 2, T √ k))|S|ε/(T 2 log4(d/ε)))",A Omitted Details from Section 3,[0],[0]
"= exp(−Ω(|S|ε/(log4(d/ε)) min(1, √ k/T )))
",A Omitted Details from Section 3,[0],[0]
≤ exp(−Ω(|S|ε2/(log4(d/ε))k/d)),A Omitted Details from Section 3,[0],[0]
"≤ exp(−Ω(dk log(d/ε))) ,
as desired.",A Omitted Details from Section 3,[0],[0]
This completes our proof.,A Omitted Details from Section 3,[0],[0]
"B.1 Full description of the distributions for experiments
Here we formally describe the distributions we used in our experiments.",B Omitted Details from Section 5,[0],[0]
"In all settings, our goal was to find noise distributions so that noise points were not “obvious” outliers, in the sense that there is no obvious pointwise pruning process which could throw away the noise points, which still gave the algorithms we tested the most difficulty.",B Omitted Details from Section 5,[0],[0]
"We again remark that while other algorithms had varying performances depending on the noise distribution, it seemed that the performance of ours was more or less unaffected by it.
",B Omitted Details from Section 5,[0],[0]
"Distribution for the synthetic mean experiment Our uncorrupted points were generated by N (µ, I), where µ is the all-ones vector.",B Omitted Details from Section 5,[0],[0]
"Our noise distribution is given as
N = 1
2 Π1 +
1 2 Π2 ,
where Π1 is the product distribution over the hypercube where every coordinate is 0 or 1 with probability 1/2, and Π2 is a product distribution where the first coordinate is ether 0 or 12 with equal probability, the second coordinate is −2 or 0 with equal probability, and all remaining coordinates are zero.
",B Omitted Details from Section 5,[0],[0]
"Distribution for the synthetic covariance experiment For the isotropic synthetic covariance experiment, our uncorrupted points were generated by N (0, I), and the noise points were all zeros.",B Omitted Details from Section 5,[0],[0]
"For the skewed synthetic covariance experiment, our uncorrupted points were generated by N (0, I + 100e1eT1 ), where e1 is the first unit vector, and our noise points were generated as follows: we took a fixed random rotation of points of the form Yi ∼ Π, where Π is a product distribution whose first d/2 coordinates are each uniformly selected from {−0.5, 0, 0.5}, and whose next d/2−1 coordinates are each 0.8×Ai, where for each coordinate",B Omitted Details from Section 5,[0],[0]
"i, Ai is an independent random integer between −2 and 2, and whose last coordinate is a uniformly random integer between [−100, 100].
",B Omitted Details from Section 5,[0],[0]
"Setup for the semi-synthetic geographic experiment We took the 20 dimensional data from [NJB+08], which was diagonalized, and randomly rotated it.",B Omitted Details from Section 5,[0],[0]
"This was to simulate the higher dimensional case, since the singular vectors that [NJB+08] obtained did not seem to be sparse or analytically sparse.",B Omitted Details from Section 5,[0],[0]
"Our noise was distributed as Π, where Π is a product distribution whose first d/2 coordinates are each uniformly random integers between 0 and 2 and whose last d/2 coordinates are each uniformly randomly either 2 or 3, all scaled by a factor of 1/24.
",B Omitted Details from Section 5,[0],[0]
"B.2 Comparison with other robust PCA methods on semi-synthetic data
In addition to comparing our results with simple pruning techniques, as we did in Figure 3 in the main text, we also compared our algorithm with implementations of other robust PCA techniques from the literature with accessible implementations.",B Omitted Details from Section 5,[0],[0]
"In particular, we compared our technique with RANSAC-based techniques, LRVCov, two SDPs ([CLMW11, XCS10]) for variants of robust PCA, and an algorithm proposed by [CLMW11] to speed up their SDP based on alternating descent.",B Omitted Details from Section 5,[0],[0]
"For the SDPs, since black box methods were too slow to run on the full data set (as [CLMW11] mentions, black-box solvers for the SDPs are impractical above perhaps 100 data points), we subsample the data, and run the SDP on the subsampled data.",B Omitted Details from Section 5,[0],[0]
"For each of these methods, we ran the algorithm on the true data points plus noise, where the noise was generated as described above.",B Omitted Details from Section 5,[0],[0]
"We then take the estimate of the covariance it outputs, and project the data points onto the top two singular values of this matrix, and plot the results in Figure 4.
",B Omitted Details from Section 5,[0],[0]
Similar results occurred for most noise patterns we tried.,B Omitted Details from Section 5,[0],[0]
"We found that only our algorithm and LRVCov were able to reasonably reconstruct Europe, in the presence of this noise.",B Omitted Details from Section 5,[0],[0]
"It is hard to judge qualitatively which of the two maps generated is preferable, but it seems that ours stretches the picture somewhat less than LRVCov.",B Omitted Details from Section 5,[0],[0]
Robust estimation is much more challenging in high dimensions than it is in one dimension: Most techniques either lead to intractable optimization problems or estimators that can tolerate only a tiny fraction of errors.,abstractText,[0],[0]
"Recent work in theoretical computer science has shown that, in appropriate distributional models, it is possible to robustly estimate the mean and covariance with polynomial time algorithms that can tolerate a constant fraction of corruptions, independent of the dimension.",abstractText,[0],[0]
"However, the sample and time complexity of these algorithms is prohibitively large for high-dimensional applications.",abstractText,[0],[0]
"In this work, we address both of these issues by establishing sample complexity bounds that are optimal, up to logarithmic factors, as well as giving various refinements that allow the algorithms to tolerate a much larger fraction of corruptions.",abstractText,[0],[0]
"Finally, we show on both synthetic and real data that our algorithms have state-of-the-art performance and suddenly make high-dimensional robust estimation a realistic possibility.",abstractText,[0],[0]
Being Robust (in High Dimensions) Can Be Practical∗,title,[0],[0]
"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 729–740 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics
https://doi.org/10.18653/v1/P17-1068
Automatic political preference prediction from social media posts has to date proven successful only in distinguishing between publicly declared liberals and conservatives in the US. This study examines users’ political ideology using a sevenpoint scale which enables us to identify politically moderate and neutral users – groups which are of particular interest to political scientists and pollsters. Using a novel data set with political ideology labels self-reported through surveys, our goal is two-fold: a) to characterize the political groups of users through language use on Twitter; b) to build a fine-grained model that predicts political ideology of unseen users. Our results identify differences in both political leaning and engagement and the extent to which each group tweets using political keywords. Finally, we demonstrate how to improve ideology prediction accuracy by exploiting the relationships between the user groups.",text,[0],[0]
Social media is used by people to share their opinions and views.,1 Introduction,[0],[0]
"Unsurprisingly, an important part of the population shares opinions and news related to politics or causes they support, thus offering strong cues about their political preferences and ideologies.",1 Introduction,[0],[0]
"In addition, political membership is also predictable purely from one’s interests or demographics — it is much more likely for a religious person to be conservative or for a younger person to lean liberal (Ellis and Stimson, 2012).
",1 Introduction,[0],[0]
"∗ Work carried out during a research visit at the University of Pennsylvania
User trait prediction from text is based on the assumption that language use reflects a user’s demographics, psychological states or preferences.",1 Introduction,[0],[0]
"Applications include prediction of age (Rao et al., 2010; Flekova et al., 2016b), gender (Burger et al., 2011; Sap et al., 2014), personality (Schwartz et al., 2013; Preoţiuc-Pietro et al., 2016), socioeconomic status (Preoţiuc-Pietro et al., 2015a,b; Liu et al., 2016c), popularity (Lampos et al., 2014) or location (Cheng et al., 2010).
",1 Introduction,[0],[0]
"Research on predicting political orientation has focused on methodological improvements (Pennacchiotti and Popescu, 2011) and used data sets with publicly stated dichotomous political orientation labels due to their easy accessibility (Sylwester and Purver, 2015).",1 Introduction,[0],[0]
"However, these data sets are not representative samples of the entire population (Cohen and Ruths, 2013) and do not accurately reflect the variety of political attitudes and engagement (Kam et al., 2007).
",1 Introduction,[0],[0]
"For example, we expect users who state their political affiliation in their profile description, tweet with partisan hashtags or appear in public party lists to use social media as a means of popularizing and supporting their political beliefs (BarberASa, 2015).",1 Introduction,[0],[0]
Many users may choose not to publicly post about their political preference for various social goals or perhaps this preference may not be strong or representative enough to be disclosed online.,1 Introduction,[0],[0]
Dichotomous political preference also ignores users who do not have a political ideology.,1 Introduction,[0],[0]
"All of these types of users are very important for researchers aiming to understand group preferences, traits or moral values (Lewis and Reiley, 2014; Hersh, 2015).
",1 Introduction,[0],[0]
"The most common political ideology spectrum in the US is the conservative – liberal (Ellis and Stimson, 2012).",1 Introduction,[0],[0]
"We collect a novel data set of Twitter users mapped to this seven-point spectrum which allows us to:
729
1.",1 Introduction,[0],[0]
Uncover the differences in language use between ideological groups; 2.,1 Introduction,[0],[0]
Develop a user-level political ideology prediction algorithm that classifies all levels of engagement and leverages the structure in the political ideology spectrum.,1 Introduction,[0],[0]
"First, using a broad range of language features
including unigrams, word clusters and emotions, we study the linguistic differences between the two ideologically extreme groups, the two ideologically moderate groups and between both extremes and moderates in order to provide insight into the content they post on Twitter.",1 Introduction,[0],[0]
"In addition, we examine the extent to which the ideological groups in our data set post about politics and compare it to a data set obtained similarly to previous work.
",1 Introduction,[0],[0]
"In prediction experiments, we show how accurately we can distinguish between opposing ideological groups in various scenarios and that previous binary political orientation prediction has been oversimplified.",1 Introduction,[0],[0]
"Then, we measure the extent to which we can predict the two dimensions of political leaning and engagement.",1 Introduction,[0],[0]
"Finally, we build an ideology classifier in a multi-task learning setup that leverages the relationships between groups.1",1 Introduction,[0],[0]
"Automatically inferring user traits from their online footprints is a prolific topic of research, enabled by the increasing availability of user generated data and advances in machine learning.",2 Related Work,[0],[0]
"Beyond its research oriented goals, user profiling has important industry applications in online marketing, personalization or large-scale audience profiling.",2 Related Work,[0],[0]
"To this end, researchers have used a wide range of types of online footprints, including video (Subramanian et al., 2013), audio (Alam and Riccardi, 2014), text (Preoţiuc-Pietro et al., 2015a), profile images (Liu et al., 2016a), social data (Van Der Heide et al., 2012; Hall et al., 2014), social networks (Perozzi and Skiena, 2015; Rout et al., 2013), payment data (Wang et al., 2016) and endorsements (Kosinski et al., 2013).
",2 Related Work,[0],[0]
"Political orientation prediction has been studied in two related, albeit crucially different scenarios, as also identified in (Zafar et al., 2016).",2 Related Work,[0],[0]
"First, researchers aimed to identify and quantify orientation of words (Monroe et al., 2008), hashtags (Weber et al., 2013) or documents (Iyyer et al., 2014),
1Data is available at http://www.preotiuc.ro
or to detect bias (Yano et al., 2010) or impartiality (Zafar et al., 2016) at a document level.
",2 Related Work,[0],[0]
"Our study belongs to the second category, where political orientation is inferred at a user-level.",2 Related Work,[0],[0]
"All previous studies study labeling US conservatives vs. liberals using either text (Rao et al., 2010), social network connections (Zamal et al., 2012), platform-specific features (Conover et al., 2011) or a combination of these (Pennacchiotti and Popescu, 2011; Volkova et al., 2014), with very high reported accuracies of up to 94.9% (Conover et al., 2011).
",2 Related Work,[0],[0]
"However, all previous work on predicting userlevel political preferences are limited to a binary prediction between liberal/democrat and conservative/republican, disregarding any nuances in political ideology.",2 Related Work,[0],[0]
"In addition, as the focus of the studies is more on the methodological or interpretation aspects of the problem, another downside is that the user labels were obtained in simple, albeit biased ways.",2 Related Work,[0],[0]
"These include users who explicitly state their political orientation on user lists of party supporters (Zamal et al., 2012; Pennacchiotti and Popescu, 2011), supporting partisan causes (Rao et al., 2010), by following political figures (Volkova et al., 2014) or party accounts (Sylwester and Purver, 2015) or that retweet partisan hashtags (Conover et al., 2011).",2 Related Work,[0],[0]
"As also identified in (Cohen and Ruths, 2013) and further confirmed later in this study, these data sets are biased: most people do not clearly state their political preference online – fewer than 5% according to Priante et al. (2016) – and those that state their preference are very likely to be political activists.",2 Related Work,[0],[0]
Cohen and Ruths (2013) demonstrated that predictive accuracy of classifiers is significantly lower when confronted with users that do not explicitly mention their political orientation.,2 Related Work,[0],[0]
"Despite this, their study is limited because in their hardest classification task, they use crowdsourced political orientation labels, which may not correspond to reality and suffer from biases (Flekova et al., 2016a; Carpenter et al., 2016).",2 Related Work,[0],[0]
"Further, they still only look at predicting binary political orientation.",2 Related Work,[0],[0]
"To date, no other research on this topic has taken into account these findings.",2 Related Work,[0],[0]
"The main data set used in this study consists of 3,938 users recruited through the Qualtrics platform (D1).",3 Data Set,[0],[0]
"Each participant was compensated
with 3 USD for 15 minutes of their time.",3 Data Set,[0],[0]
"All participants first answered the same demographic questions (including political ideology), then were directed to one of four sets of psychological questionnaires unrelated to the political ideology question.",3 Data Set,[0],[0]
"They were asked to self-report their political ideology on a seven point scale: Very conservative (1), Conservative (2), Moderately conservative (3), Moderate (4), Moderately liberal (5), Liberal (6), Very liberal (7).",3 Data Set,[0],[0]
"In addition, participants had the option of choosing Apathetic and Other, which have ambiguous fits on the conservative – liberal spectrum and were removed from our analysis (399 users).",3 Data Set,[0],[0]
"We also asked participants to self-report their gender (2322 female, 1205 male, 12 other) and age.",3 Data Set,[0],[0]
Participants were all from the US in order to limit the impact of cultural and political factors.,3 Data Set,[0],[0]
"The political ideology distribution in our sample is presented in Figure 1.
",3 Data Set,[0],[0]
"We asked users their Twitter handle and downloaded their most recent 3,200 tweets, leading to a total of 4,833,133 tweets.",3 Data Set,[0],[0]
"Before adding users to our 3,938 user data set, we performed the following checks to ensure that the Twitter handle was the user’s own: 1) after compensation, users were if they were truthful in reporting their handle and if not, we removed their data from analysis; 2) we manually examined all handles marked as verified by Twitter or that had over 2000 followers and eliminated them if they were celebrities or corporate/news accounts, as these were unlikely the users who participated in the survey.",3 Data Set,[0],[0]
"This study received approval from the Institutional Review Board (IRB) of the University of Pennsylvania.
",3 Data Set,[0],[0]
"In addition, to facilitate comparison to previous work, we also use a data set of 13,651 users with overt political orientation (D2).",3 Data Set,[0],[0]
"We selected popular political figures unambiguously associated with US liberal politics (@SenSanders,
@JoeBiden, @CoryBooker, @JohnKerry) or US conservative politics (@marcorubio, @tedcruz, @RandPaul, @RealBenCarson).",3 Data Set,[0],[0]
Liberals in our set (Nl = 7417) had to follow on Twitter all of the liberal political figures and none of the conservative figures.,3 Data Set,[0],[0]
"Likewise, conservative users (Nc = 6234) had to follow all of the conservative figures and no liberal figures.",3 Data Set,[0],[0]
"We downloaded up to 3,200 of each user’s most recent tweets, leading to a total of 25,493,407 tweets.",3 Data Set,[0],[0]
All tweets were downloaded around 10 August 2016.,3 Data Set,[0],[0]
"In our analysis, we use a broad range of linguistic features described below.",4 Features,[0],[0]
"Unigrams We use the bag-of-words representation to reduce each user’s posting history to a normalised frequency distribution over the vocabulary consisting of all words used by at least 10% of the users (6,060 words).",4 Features,[0],[0]
LIWC Traditional psychological studies use a dictionary-based approach to representing text.,4 Features,[0],[0]
"The most popular method is based on Linguistic Inquiry and Word Count (LIWC) (Pennebaker et al., 2001), and automatically counts word frequencies for 64 different categories manually constructed based on psychological theory.",4 Features,[0],[0]
"These include different parts-of-speech, topical categories and emotions.",4 Features,[0],[0]
Each user is thereby represented as a frequency distribution over these categories.,4 Features,[0],[0]
Word2Vec Topics,4 Features,[0],[0]
"An alternative to LIWC is to use automatically generated word clusters i.e., groups of words that are semantically and/or syntactically similar.",4 Features,[0],[0]
"The clusters help reducing the feature space and provides additional interpretability.
",4 Features,[0],[0]
"To create these groups of words, we use an automatic method that leverages word co-occurrence patterns in large corpora by making use of the distributional hypothesis: similar words tend to cooccur in similar contexts (Harris, 1954).",4 Features,[0],[0]
"Based on co-occurrence statistics, each word is represented as a low dimensional vector of numbers with words closer in this space being more similar (Deerwester et al., 1990).",4 Features,[0],[0]
"We use the method from (Preoţiuc-Pietro et al., 2015a) to compute topics using word2vec similarity (Mikolov et al., 2013a,b) and spectral clustering (Shi and Malik, 2000; von Luxburg, 2007) of different sizes (from 30 to 2000).",4 Features,[0],[0]
"We have tried other alternatives to building clusters: using other word similarities to
generate clusters – such as NPMI (Lampos et al., 2014) or GloVe (Pennington et al., 2014) as proposed in (Preoţiuc-Pietro et al., 2015a) – or using standard topic modelling approached to create soft clusters of words e.g., Latent Dirichlet Allocation (Blei et al., 2003).",4 Features,[0],[0]
"For brevity, we present experiments with the best performing feature set containing 500 Word2Vec clusters.",4 Features,[0],[0]
We aggregate all the words posted in a users’ tweets and represent each user as a distribution of the fraction of words belonging to each cluster.,4 Features,[0],[0]
Sentiment & Emotions We hypothesise that different political ideologies differ in the type and amount of emotions the users express through their posts.,4 Features,[0],[0]
"The most studied model of discrete emotions is the Ekman model (Ekman, 1992; Strapparava and Mihalcea, 2008; Strapparava et al., 2004) which posits the existence of six basic emotions: anger, disgust, fear, joy, sadness and surprise.",4 Features,[0],[0]
"We automatically quantify these emotions from our Twitter data set using a publicly available crowd-sourcing derived lexicon of words associated with any of the six emotions, as well as general positive and negative sentiment (Mohammad and Turney, 2010, 2013).",4 Features,[0],[0]
"Using these lexicons, we assign a predicted emotion to each message and then average across all users’ posts to obtain user level emotion expression scores.",4 Features,[0],[0]
"Political Terms In order to select unigrams pertaining to politics, we assigned the most frequent 12,000 unigrams in our data set to three categories: • Political words: mentions of political terms
(234);",4 Features,[0],[0]
"• Political NEs: mentions of politician proper
names out of the political terms (39); • Media NEs: mentions of political media
sources and pundits out of the political terms (20).
",4 Features,[0],[0]
This coding was initially performed by a research assistant studying political science with good knowledge of US politics and were further filtered and checked by one of the authors.,4 Features,[0],[0]
"First, we explore the relationships between language use and political ideological groups within each feature set and pairs of opposing user groups.",5 Analysis,[0],[0]
"To illustrate differences between ideological groups we compare the two political extremes (Very Conservative – Very Liberal) and the political moderates (Moderate Conservative – Moderate
Liberal).",5 Analysis,[0],[0]
"We further compare outright moderates with a group combining the two political extremes to study if we can uncover differences in political engagement and extremity, regardless of the conservative–liberal leaning.
",5 Analysis,[0],[0]
We use univariate partial linear correlations with age and gender as co-variates to factor out the influence of basic demographics.,5 Analysis,[0],[0]
"For example, in D1, users who reported themselves as very conservative are older and more likely males (µage = 35.1, pctmale = 44%) than the data average (µage = 31.2, pctmale = 35%).",5 Analysis,[0],[0]
"Additionally, prior to combining the two ideologically extreme groups, we sub-sampled the larger class (Very Liberal) to match the smaller class (Very Conservative) in age and gender.",5 Analysis,[0],[0]
"In the later prediction experiments, we do not perform matching, as this represents useful signal for classification (Ellis and Stimson, 2012).",5 Analysis,[0],[0]
Results with unigrams are presented in Figure 2 and with the other features in Table 1.,5 Analysis,[0],[0]
These are selected using standard statistical significance tests.,5 Analysis,[0],[0]
The comparison between the extreme categories reveals the largest number of significant differences.,5.1 Very Conservatives vs. Very Liberals,[0],[0]
"The unigrams and Word2Vec clusters specific to conservatives are dominated by religion specific terms (‘praying’, ‘god’, W2V485, W2V-018, W2V-099, L-RELIG), confirming a well-documented relationship (Gelman, 2009) and words describing family relationships (‘uncle’, ‘son’, L-FAMILY), another conservative value (Lakoff, 1997).",5.1 Very Conservatives vs. Very Liberals,[0],[0]
"The emphasis on religious terms among conservatives is consistent with the claim that many Americans associate ‘conservative’ with ‘religious’ (Ellis and Stimson, 2012).",5.1 Very Conservatives vs. Very Liberals,[0],[0]
"Extreme liberals show a tendency to use more adjectives (W2V-075, W2V-110), adverbs (L-ADVERB), conjunctions (L-CONJ) and comparisons (L-COMPARE) which indicate more nuanced and complex posts.",5.1 Very Conservatives vs. Very Liberals,[0],[0]
"Extreme conservatives post tweets higher in all positive emotions than liberals (L-POSEMO, Emot-Joy, EmotPositive), confirming a previously hypothesised relationship (Napier and Jost, 2008).",5.1 Very Conservatives vs. Very Liberals,[0],[0]
"However, extreme liberals are not associated with posting negative emotions either, only using words that reflect more anxiety (L-ANX), which is related to neuroticism in which the liberals are higher (Gerber et al., 2010).
",5.1 Very Conservatives vs. Very Liberals,[0],[0]
"Political term analysis reveals the partisan terms
employed by both sides.",5.1 Very Conservatives vs. Very Liberals,[0],[0]
"For example, conservatives retweet or mention politicians such as Donald Trump or Ted Cruz, while liberals mention
Barack Obama.",5.1 Very Conservatives vs. Very Liberals,[0],[0]
"Extreme conservatives also reference known partisan conservative media sources (@foxnews, @yahoonews) and hashtags (#pjnet,
#tcot), while extreme liberals focus on issues (‘gay’, ‘racism’, ‘feminism’, ‘transgender’).",5.1 Very Conservatives vs. Very Liberals,[0],[0]
"This perhaps reflects the desire for conservatives on Twitter to identify like-minded individuals, as extreme conservatives are a minority on the platform.",5.1 Very Conservatives vs. Very Liberals,[0],[0]
"Liberals, by contrast, use the platform to discuss and popularize their causes.",5.1 Very Conservatives vs. Very Liberals,[0],[0]
Comparing the two sides of moderate users reveals a slightly more nuanced view of the two ideologies.,5.2 Moderate Conservatives vs. Moderate Liberals,[0],[0]
"While moderate conservatives still make heavy use of religious terms and express positive emotions (Emot-Joy, L-DRIVES), they also use affiliative language (L-AFFILIATION) and plural pronouns (L-WE).",5.2 Moderate Conservatives vs. Moderate Liberals,[0],[0]
Moderate liberals are identified by very different features compared to their more extreme counterparts.,5.2 Moderate Conservatives vs. Moderate Liberals,[0],[0]
"Most striking is the use of swear and sex words (L-SEXUAL, L-ANGER, W2V-316), also highlighted by Sylwester and Purver (2015).",5.2 Moderate Conservatives vs. Moderate Liberals,[0],[0]
"Two word clusters relating to British culture (W2V-458) and art (W2V373) reflect that liberals are more inclined towards arts (Dollinger, 2007).",5.2 Moderate Conservatives vs. Moderate Liberals,[0],[0]
"Statistically significant political terms are very few compared to the previous comparison, probably due to their lower overall usage, which we further investigate later.",5.2 Moderate Conservatives vs. Moderate Liberals,[0],[0]
"Our final comparison looks at outright moderates compared to the two extreme groups combined, as we hypothesise the existence of a difference in overall political engagement.",5.3 Moderates vs. Extremists,[0],[0]
"Moderates are not characterized by many features besides a topic of casual words (W2V-098), indicating the heterogeneity of this group of users.",5.3 Moderates vs. Extremists,[0],[0]
"However, regardless of their orientation, the ideological extremists stand out from moderates.",5.3 Moderates vs. Extremists,[0],[0]
"They use words and word clusters related to political actors (W2V-309), issues (W2V-237) and laws (W2V296, W2V-288).",5.3 Moderates vs. Extremists,[0],[0]
LIWC analysis uncovers differences in article use (L-ARTICLE) or power words (L-POWER) specific of political tweets.,5.3 Moderates vs. Extremists,[0],[0]
"The overall sentiment of these users is negative (Emot-Fear, Emot-Disgust, Emot-Sadness, L-DEATH) compared to moderates.",5.3 Moderates vs. Extremists,[0],[0]
"This reveals – combined with the finding from the first comparison – that while extreme conservatives are overall more positive than liberals, both groups share negative expression.",5.3 Moderates vs. Extremists,[0],[0]
"Political terms are almost all significantly correlated with the extreme ideological groups,
confirming the existence of a difference in political engagement which we study in detail next.",5.3 Moderates vs. Extremists,[0],[0]
Figure 3 presents the use of the three types of political terms across the 7 ideological groups in D1 and the two political groups from D2.,5.4 Political Terms,[0],[0]
"We notice the following: • D2 has a huge skew towards political words,
with an average of more than three times more political terms across all three categories than our extreme classes from D1; • Within the groups in D1, we observe an almost
perfectly symmetrical U-shape across all three types of political terms, confirming our hypothesis about political engagement; • The difference between 1–2/6–7 is larger than
2–3/5–6.",5.4 Political Terms,[0],[0]
"The extreme liberals and conservatives are disproportionately political, and have the potential to give Twitter’s political discussions an unrepresentative, extremist hue (Fiorina, 1999).",5.4 Political Terms,[0],[0]
"It is also possible, however, that characterizing one as an extreme liberal or conservative indicates as much about her level of political engagement as it does about her placement on a left-right scale (Converse, 1964; Broockman, 2016).",5.4 Political Terms,[0],[0]
In this section we build predictive models of political ideology and compare them to data sets obtained using previous work.,6 Prediction,[0],[0]
"First, we experiment with classifying between conservatives and liberals across various levels of political engagement in D1 and between the two polarized groups in D2.",6.1 Cross-Group Prediction,[0],[0]
"We use logistic regression classification to compare three setups in Table 2 with results measured with ROC AUC as the classes are slightly inbalanced: • 10-fold cross-validation where training is per-
formed on the same task as the testing (principal diagonal); • A train–test setup where training is performed
on one task (presented in rows) and testing is performed on another (presented in columns); • A domain adaptation setup (results in brack-
ets) where on each of the 10 folds, the 9 training folds (presented in rows) are supplemented with all the data from a different task (presented in columns) using the EasyAdapt algorithm (Daumé III, 2007) as a proof on concept on the effects of using additional distantly supervised data.",6.1 Cross-Group Prediction,[0],[0]
Data pooling lead to worse results than EasyAdapt.,6.1 Cross-Group Prediction,[0],[0]
"Each of the three tasks from D1 have a similar number of training samples, hence we do not expect that data set size has any effects in comparing the results across tasks.
",6.1 Cross-Group Prediction,[0],[0]
"The results with both sets of features show that: • Prediction performance is much higher for D2
than for D1, with the more extreme groups in D1 being easier to predict than the moderate groups.",6.1 Cross-Group Prediction,[0],[0]
"This confirms that the very high accuracies reported by previous research are an artifact of user label collection and that on regular users, the expected accuracy is much lower (Cohen and Ruths, 2013).",6.1 Cross-Group Prediction,[0],[0]
"We further show that, as the level of political engagement decreases, the classification problem becomes even harder; • The model trained on D2 and Word2Vec word
clusters performs significantly worse on D1 tasks even if the training data is over 10 times larger.",6.1 Cross-Group Prediction,[0],[0]
"When using political words, the D2 trained classifier performs relatively well on all tasks from D1; • Overall, using political words as features per-
forms better than Word2Vec clusters in the binary classification tasks; • Domain adaptation helps in the majority of
cases, leading to improvements of up to .03 in AUC (predicting 2v6 supplemented with 3v5 data).",6.1 Cross-Group Prediction,[0],[0]
"Political leaning (Conservative – Liberal, excluding the Moderate group) can be considered an ordinal variable and the prediction problem framed as one of regression.",6.2 Political Leaning and Engagement Prediction,[0],[0]
"In addition to the political leaning prediction, based on analysis and previous prediction results, we hypothesize the existence of a separate dimension of political engagement regardless of the partisan side.",6.2 Political Leaning and Engagement Prediction,[0],[0]
"Thus, we merge users from classes 3–5, 2–6, 1–7 and create a variable with four values, where the lowest value is represented by moderate users (4) and the highest value is represented by either very conservative (1) or very liberal (7) users.
",6.2 Political Leaning and Engagement Prediction,[0],[0]
"We use a linear regression algorithm with an Elastic Net regularizer (Zou and Hastie, 2005) as implemented in ScikitLearn (Pedregosa et al., 2011).",6.2 Political Leaning and Engagement Prediction,[0],[0]
"To evaluate our results, we split our data into 10 stratified folds and performed crossvalidation on one held-out fold at a time.",6.2 Political Leaning and Engagement Prediction,[0],[0]
For all our methods we tune the parameters of our models on a separate validation fold.,6.2 Political Leaning and Engagement Prediction,[0],[0]
The overall performance is assessed using Pearson correlation between the set of predicted values and the userreported score.,6.2 Political Leaning and Engagement Prediction,[0],[0]
"Results are presented in Table 3.
",6.2 Political Leaning and Engagement Prediction,[0],[0]
"The same patterns hold when evaluating the results with Root Mean Squared Error (RMSE).
",6.2 Political Leaning and Engagement Prediction,[0],[0]
"The results show that both dimensions can be predicted well above chance, with political leaning being easier to predict than engagement.",6.2 Political Leaning and Engagement Prediction,[0],[0]
"Word2Vec clusters obtain the highest predictive accuracy for political leaning, even though they did not perform as well in the previous classification tasks.",6.2 Political Leaning and Engagement Prediction,[0],[0]
"For political engagement, political terms and Word2Vec clusters obtain similar predictive accuracy.",6.2 Political Leaning and Engagement Prediction,[0],[0]
"This result is expected based on the results from Figure 3, which showed how political term usage varies across groups, and how it is especially dependent on political engagement.",6.2 Political Leaning and Engagement Prediction,[0],[0]
"While political terms are very effective at distinguishing between two opposing political groups, they can not discriminate as well between levels of engagement within the same ideological orientation.",6.2 Political Leaning and Engagement Prediction,[0],[0]
Combining all classifiers’ predictions in a linear ensemble obtains best results when compared to each individual category.,6.2 Political Leaning and Engagement Prediction,[0],[0]
"In our previous experiments, we uncovered that certain relationships exist between the seven groups.",6.3 Encoding Class Structure,[0],[0]
"For example, extreme conservatives and liberals both demonstrate strong political engagement.",6.3 Encoding Class Structure,[0],[0]
"Therefore, this class structure can be exploited to improve classification performance.",6.3 Encoding Class Structure,[0],[0]
"To this end, we deploy the sparse graph regularized approach (Argyriou et al., 2007; Zhou et al., 2011) to encode the structure of the seven classes as a graph regularizer in a logistic regression framework.
",6.3 Encoding Class Structure,[0],[0]
"In particular, we employed a multi-task learning paradigm, where each task is a one-vs-all classification.",6.3 Encoding Class Structure,[0],[0]
"Multi-task learning (MTL) is a learning paradigm that jointly learns multiple related
tasks and can achieve better generalization performance than learning each task individually, especially when presented with insufficient training samples (Liu et al., 2015, 2016b,d).",6.3 Encoding Class Structure,[0],[0]
The group structure is encoded into a matrix R which codes the groups which are considered similar.,6.3 Encoding Class Structure,[0],[0]
"The objective of the sparse graph regularized multi-task learning problem is:
min W,c
τ∑
t=1
N∑
i=1
log(1 + exp(−Yt,i(WTi,tXt,i + ct)))
",6.3 Encoding Class Structure,[0],[0]
+,6.3 Encoding Class Structure,[0],[0]
γ‖WR‖2F +,6.3 Encoding Class Structure,[0],[0]
"λ‖W‖1,
where τ is the number of tasks, |N | the number of samples, X the feature matrix, Y the outcome matrix, Wi,t and ct is the model for task t and R is the structure matrix.
",6.3 Encoding Class Structure,[0],[0]
"We define three R matrices: (1) codes that groups with similar political engagement are similar (i.e. 1–7, 2–6, 3–5); (2) codes that groups from each ideological side are similar (i.e. 1–2, 1–3, 2–3, 5–6, 5–7, 6–7); (3) learnt from the data.",6.3 Encoding Class Structure,[0],[0]
Results are presented in Table 4.,6.3 Encoding Class Structure,[0],[0]
"Regular logistic regression performs slightly better than the majority class baseline, which demonstrates that the 7- class classification is a very hard problem although most miss-classifications are within one ideology point.",6.3 Encoding Class Structure,[0],[0]
"The graph regularization (GR) improves the classification performance over logistic regression (LR) in all cases, with political leaning based matrix (GR–Leaning) obtaining 2% in accuracy higher than the political engagement one (GR– Engagement) and the learnt matrix (GR–Learnt) obtaining best results.",6.3 Encoding Class Structure,[0],[0]
This study analyzed user-level political ideology through Twitter posts.,7 Conclusions,[0],[0]
"In contrast to previous work, we made use of a novel data set where finegrained user political ideology labels are obtained through surveys as opposed to binary self-reports.",7 Conclusions,[0],[0]
"We showed that users in our data set are far less
likely to post about politics and real-world finegrained political ideology prediction is harder and more nuanced than previously reported.",7 Conclusions,[0],[0]
"We analyzed language differences between the ideological groups and uncovered a dimension of political engagement separate from political leaning.
",7 Conclusions,[0],[0]
"Our work has implications for pollsters or marketers, who are most interested to identify and persuade moderate users.",7 Conclusions,[0],[0]
"With respect to political conclusions, researchers commonly conceptualize ideology as a single, left-right dimension similar to what we observe in the U.S. Congress (Ansolabehere et al., 2008; Bafumi and Herron, 2010).",7 Conclusions,[0],[0]
"Our results suggest a different direction: self-reported political extremity is more an indication of political engagement than of ideological self-placement (Abramowitz, 2010).",7 Conclusions,[0],[0]
"In fact, only self-reported extremists appear to devote much of their Twitter activity to politics at all.
",7 Conclusions,[0],[0]
"While our study focused solely on text posted by the user, follow-up work can use other modalities such as images or social network analysis to improve prediction performance.",7 Conclusions,[0],[0]
"In addition, our work on user-level modeling can be integrated with work on message-level political bias to study how this is revealed across users with various levels of engagement.",7 Conclusions,[0],[0]
"Another direction of future study will look at political ideology prediction in other countries and cultures, where ideology has different or multiple dimensions.",7 Conclusions,[0],[0]
"The authors acknowledge the support of the Templeton Religion Trust, grant TRT-0048.",Acknowledgments,[0],[0]
We wish to thank Prof. David S. Rosenblum for supporting the research visit of Ye Liu.,Acknowledgments,[0],[0]
Automatic political preference prediction from social media posts has to date proven successful only in distinguishing between publicly declared liberals and conservatives in the US.,abstractText,[0],[0]
This study examines users’ political ideology using a sevenpoint scale which enables us to identify politically moderate and neutral users – groups which are of particular interest to political scientists and pollsters.,abstractText,[0],[0]
"Using a novel data set with political ideology labels self-reported through surveys, our goal is two-fold: a) to characterize the political groups of users through language use on Twitter; b) to build a fine-grained model that predicts political ideology of unseen users.",abstractText,[0],[0]
Our results identify differences in both political leaning and engagement and the extent to which each group tweets using political keywords.,abstractText,[0],[0]
"Finally, we demonstrate how to improve ideology prediction accuracy by exploiting the relationships between the user groups.",abstractText,[0],[0]
Beyond Binary Labels: Political Ideology Prediction of Twitter Users,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3602–3611 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
3602",text,[0],[0]
"Neural machine translation (NMT) has attracted much research attention in recent years (Bahdanau et al., 2014; Shen et al., 2018; Song et al., 2018; Xia et al., 2018; He et al., 2016; Wu et al., 2017, 2018).",1 Introduction,[0],[0]
"The major approach to the task typically leverages an encoder-decoder framework (Cho et al., 2014; Sutskever et al., 2014) and the decoder usually generates the target tokens one by one from left to right autoregressively, in which the generation of a target token is conditioned on previously generated target tokens.
",1 Introduction,[0],[0]
"It has been observed that for an NMT model with left-to-right decoding, the right part words in
∗Authors contribute equally to this work.
",1 Introduction,[0],[0]
"its translation results are usually worse than the left part words in terms of accuracy (Zhang et al., 2018; Bengio et al., 2015; Ranzato et al., 2015; Hassan et al., 2018; Liu et al., 2016b,a).",1 Introduction,[0],[0]
This phenomenon is referred to as accuracy drop in this paper.,1 Introduction,[0],[0]
"A straightforward explanation to accuracy drop is error propagation: If a word is mistakenly predicted during inference, the error will be propagated and the future words conditioned on this one will be impacted.",1 Introduction,[0],[0]
"Different methods have been proposed to address the problem of accuracy drop (Liu et al., 2016a,b; Hassan et al., 2018).
",1 Introduction,[0],[0]
"Instead of solving the problem, in this paper, we aim to deeply understand the causes of the problem.",1 Introduction,[0],[0]
"In particular, we want to answer the following two questions:
• Is error propagation the main cause of accuracy drop?
",1 Introduction,[0],[0]
"• Are there any other causes leading to accuracy drop?
",1 Introduction,[0],[0]
"To answer these two questions, we conduct a series of experiments to analyze the problem.
",1 Introduction,[0],[0]
"First, we train NMT models separately using left-to-right and right-to-left decoding (Sennrich et al., 2016; Liu et al., 2016b; He et al., 2017; Gao et al., 2018) on several language pairs (i.e., German to English, English to German, and English to Chinese).",1 Introduction,[0],[0]
"If error propagation is the main cause of accuracy drop, then the right part words in the translation results generated by right-toleft NMT models should be more accurate than the left part words.",1 Introduction,[0],[0]
"However, we observe the opposite phenomenon that the accuracy of the right part words of the translated sentences in both leftto-right and right-to-left models is lower than that of the left part, which contradicts with error propagation.",1 Introduction,[0],[0]
"This shows that error propagation alone cannot well explain the accuracy drop and even
suggests that error propagation may not exist or matter.
",1 Introduction,[0],[0]
"Second, to further investigate the influence of error propagation on accuracy drop, we conduct a set of experiments with teacher forcing (Williams and Zipser, 1989) during inference, in which we feed the ground-truth preceding words to predict the next target word.",1 Introduction,[0],[0]
Teacher forcing eliminates exposure bias as well as error propagation in inference.,1 Introduction,[0],[0]
"The results verify the existence of error propagation, since the later part (the right part in left-to-right decoding and the left part in right-toleft decoding) of the translation results get more accuracy improvement with teacher forcing, regardless of the decoding direction.",1 Introduction,[0],[0]
"Meanwhile, the accuracy of the right part is still lower than that of the left part with teacher forcing, which demonstrates that there must be some other causes apart from error propagation leading to accuracy drop.
",1 Introduction,[0],[0]
"Third, inspired by linguistics, we find that the concept of branching (Berg et al., 2011; Payne, 2006) can help to explain the problem.",1 Introduction,[0],[0]
We conduct the third set of experiments to study the correlation between language branching and accuracy drop.,1 Introduction,[0],[0]
"We find that if a target language is right branching such as English, the accuracy of the left part words is usually higher than that of the right part words, no matter for left-to-right or right-toleft NMT models, while for a left-branching target language such as Japanese, the accuracy of the left part words is usually lower than that of the right part, no matter for which models.",1 Introduction,[0],[0]
"The intuitive explanation is that a right-branching language has a clearer structure pattern (easier to predict) in the left part of sentence than that in the right part, since the main subject of the sentence is usually put in the left part.",1 Introduction,[0],[0]
We calculate two statistics to verify this assumption: n-gram statistics (including n-gram frequency and conditional probabilities) and dependency parsing statistics.,1 Introduction,[0],[0]
"For rightbranching languages, we found higher n-gram frequency/conditional probabilities as well as more dependencies in the left part compared with that in the right part.",1 Introduction,[0],[0]
"The opposite results are also found in left-branching languages.
",1 Introduction,[0],[0]
"We summarize our findings as follows.
",1 Introduction,[0],[0]
"• Through empirical analyses, we find that the influence of error propagation is overstated in the literature, which may misguide the future research.",1 Introduction,[0],[0]
"Error propagation alone cannot fully explain the accuracy drop in the left or
right part of sentence.
",1 Introduction,[0],[0]
"• We find the branching in linguistics well correlates with accuracy drop in the left or right part of sentence and the corresponding analysis on n-gram and dependency parsing statistics well explain this phenomenon.
",1 Introduction,[0],[0]
Our studies show that linguistics can be very helpful to understand existing machine learning models and build better models for language related tasks.,1 Introduction,[0],[0]
We hope that our work can bring some insights to the research on neural machine translation.,1 Introduction,[0],[0]
We believe that our findings can help us to design better translation models.,1 Introduction,[0],[0]
"For example, the finding on language branching suggests us to use left-to-right NMT models for right-branching languages such as English and right-to-right NMT models for left-branching languages such as Japanese.",1 Introduction,[0],[0]
"Exposure bias and error propagation are two different concepts but often mentioned together in literature (Bengio et al., 2015; Shen et al., 2016; Ranzato et al., 2015; Liu et al., 2016b,a; Zhang et al., 2018; Hassan et al., 2018).",2.1 Exposure Bias and Error Propagation,[0],[0]
Exposure bias refers to the fact that the sequence generation model is usually trained with teacher-forcing while generates the sequence autoaggressviely during inference.,2.1 Exposure Bias and Error Propagation,[0],[0]
"This discrepancy between training and inference can yield errors that accumulate quickly along the generated sequence, which is known as error propagation (Bengio et al., 2015; Shen et al., 2016; Ranzato et al., 2015).
",2.1 Exposure Bias and Error Propagation,[0],[0]
"Bengio et al. (2015) propose the scheduled sampling method to eliminate the exposure bias and the resulting error propagation, which achieves promising performance on sequence generation tasks such as image captioning.",2.1 Exposure Bias and Error Propagation,[0],[0]
Shen et al. (2016); Ranzato et al. (2015) improve the basic maximum likelihood estimation (MLE) with reinforcement learning or minimum risk training and aim to address the limitation of MLE training and exposure bias problem.,2.1 Exposure Bias and Error Propagation,[0],[0]
"(Liu et al., 2016b,a; Zhang et al., 2018; Hassan et al., 2018) mainly ascribe accuracy drop (the accuracy of right part words is worse than that in the left part in most cases) to error propagation and
propose different methods to solve this problem.",2.2 Tackling Accuracy Drop,[0],[0]
"Liu et al. (2016b,a); Hassan et al. (2018) use agreement regularization between the left-to-right and right-to-left models to achieve better performance.",2.2 Tackling Accuracy Drop,[0],[0]
"Zhang et al. (2018) and (Hassan et al., 2018) propose to use two-pass decoding to refine the generated sequence to yield better quality.
",2.2 Tackling Accuracy Drop,[0],[0]
All these works focus on error propagation and accuracy drop.,2.2 Tackling Accuracy Drop,[0],[0]
"To our knowledge, there is no deep study about other causes of accuracy drop.",2.2 Tackling Accuracy Drop,[0],[0]
"In this paper, we aim to conduct such a study.",2.2 Tackling Accuracy Drop,[0],[0]
"Our study shows that accuracy drop is not only caused by error propagation, but also the characteristics of language itself.",2.2 Tackling Accuracy Drop,[0],[0]
"A left-to-right NMT model feeds target tokens one by one from left to right in training and generate target tokens one by one from left to right during inference, while a right-to-left NMT model trains and generates token in the reverse direction.",3.1 Error Propagation is Not the Only Cause,[0],[0]
"Intuitively, if error propagation is the root cause of accuracy drop, then a right-to-left NMT model will generate translations with better right half accuracy than the left half.",3.1 Error Propagation is Not the Only Cause,[0],[0]
"In this section, we study the results of both left-to-right and right-to-left NMT models to analyze the relationship between error propagation and accuracy drop.
",3.1 Error Propagation is Not the Only Cause,[0],[0]
"We conduct experiments on three translation tasks with different language pairs, which include: IWSLT 2014 German-English (De-En), WMT 2014 English-German (En-De) and WMT 2017 English-Chinese (En-Zh).",3.1 Error Propagation is Not the Only Cause,[0],[0]
"We choose the state-ofthe-art NMT model Transformer (Vaswani et al., 2017) as the basic model structure and train two separate models with left-to-right and right-toleft decoding on each language pair.",3.1 Error Propagation is Not the Only Cause,[0],[0]
More details about the datasets and model descriptions can be found in supplementary materials (section A.1 and A.2).,3.1 Error Propagation is Not the Only Cause,[0],[0]
We evenly split each generated sentence into the left half and the right half with same number of words1.,3.1 Error Propagation is Not the Only Cause,[0],[0]
"Then for both the left and right half, we compute their accuracy with respect to the reference target sentence, in terms of BLEU score (Pa-
11) For most of the sentences, the last word of the sentence is period which is easy to decode.",3.1 Error Propagation is Not the Only Cause,[0],[0]
"To make a fair comparison, we simply remove the last period before dividing the translation sentence.",3.1 Error Propagation is Not the Only Cause,[0],[0]
2),3.1 Error Propagation is Not the Only Cause,[0],[0]
"For sentence with an odd number of words, we simply remove the word in the middle position to make the left half and right half have the same number of words.
",3.1 Error Propagation is Not the Only Cause,[0],[0]
"pineni et al., 2002) 2.",3.1 Error Propagation is Not the Only Cause,[0],[0]
We first report the BLEU scores of the full translation results (without split) in Table 1.,3.1 Error Propagation is Not the Only Cause,[0],[0]
"As can be seen, the accuracy of the model is comparable to state-of-the-art results (Vaswani et al., 2017; Wang et al., 2017, 2018).",3.1 Error Propagation is Not the Only Cause,[0],[0]
Afterwards we report the BLEU scores of the left half and the right half in Table 2.,3.1 Error Propagation is Not the Only Cause,[0],[0]
"We have several observations.
",3.1 Error Propagation is Not the Only Cause,[0],[0]
"• When translating from left-to-right, the BLEU score of the left half is higher than the right half on all the three tasks, which is consistent with previous observation and is able to be explained via error propagation.
",3.1 Error Propagation is Not the Only Cause,[0],[0]
"• When translating from right-to-left, the accuracy of the left half (in this way it’s the later part of the generated sentence) is still higher than the right half.",3.1 Error Propagation is Not the Only Cause,[0],[0]
"Such an observation is contradictory to the previous analyses between error propagation and accuracy drop, which regard that accumulated error brought by exposure bias will deteriorate the quality in later part of translation (i.e., the left half).
",3.1 Error Propagation is Not the Only Cause,[0],[0]
"The inconsistent observation above suggests that error propagation is not the only cause of accuracy drop that there are other factors beyond er-
2We use the multi-bleu.perl script https: //github.com/moses-smt/mosesdecoder/ scripts/generic/multi-bleu.perl.",3.1 Error Propagation is Not the Only Cause,[0],[0]
"When computing BLEU score of the left or right half, the reference is the full reference sentence.
",3.1 Error Propagation is Not the Only Cause,[0],[0]
ror propagation for accuracy drop.,3.1 Error Propagation is Not the Only Cause,[0],[0]
It even challenges the existence of error propagation: does error propagation really exist?,3.1 Error Propagation is Not the Only Cause,[0],[0]
In the next section we try to answer this question through teacher forcing experiments.,3.1 Error Propagation is Not the Only Cause,[0],[0]
"Teacher forcing (Williams and Zipser, 1989) in sequence generation means that when training a sequence generation model, we feed the previous ground-truth tokens as inputs to predict the next target word.",3.2 The Influence of Error Propagation,[0],[0]
"Here we apply teacher forcing in the inference phase of NMT: to generate the next word ŷi, we input the preceding ground-truth words y<i rather than the previously generated words ŷ<i, which largely alleviates the effect of error propagation, since there will be no error propagated from the previously generated words.
",3.2 The Influence of Error Propagation,[0],[0]
"Same as last section, we evaluate the quality of the left and right half of the translation results generated by both the left-to-right and right-toleft models.",3.2 The Influence of Error Propagation,[0],[0]
The results are summarized in Table 3.,3.2 The Influence of Error Propagation,[0],[0]
"For comparison, we also include the BLEU scores of normal translation (without teacher forcing).",3.2 The Influence of Error Propagation,[0],[0]
"We have several findings from Table 3 as follows:
• Exposure bias exists.",3.2 The Influence of Error Propagation,[0],[0]
"The accuracy of both left and right half tokens in the normal translation is lower than that in teacher forcing, which feeds the ground-truth tokens as inputs.",3.2 The Influence of Error Propagation,[0],[0]
"This demonstrates that feeding the previously generated tokens (which might be in-
correct) in inference indeed hurts translation accuracy.
",3.2 The Influence of Error Propagation,[0],[0]
• Error propagation does exist.,3.2 The Influence of Error Propagation,[0],[0]
We find the error is accumulated along the sequential generation of the sentence.,3.2 The Influence of Error Propagation,[0],[0]
"Taking En-Zh and the left-to-right NMT model as an example, the BLEU score improvement of the right half (the second half of the generation) of teacher forcing over normal translation is 2.64, which is much larger than the accuracy improvement of the left half (the first half of the generation): 1.70.",3.2 The Influence of Error Propagation,[0],[0]
"Similarly, for En-Zh with the right-to-left NMT model, the BLEU score improvement of the left half (the second half of the generation) of teacher forcing over normal translation is 2.82, which is much larger than the accuracy improvement of the right half (the first half of the generation): 1.77.
",3.2 The Influence of Error Propagation,[0],[0]
• Other causes exist.,3.2 The Influence of Error Propagation,[0],[0]
"Taking En-De translation with the left-to-right model as an example, the accuracy of the left half (9.43) is higher than that of the right half (8.36) when there is no error propagation with teacher forcing.",3.2 The Influence of Error Propagation,[0],[0]
Similar results can be found in other language pairs and models.,3.2 The Influence of Error Propagation,[0],[0]
"This suggests that there must be some other causes leading to accuracy drop, which will be studied in the next section.",3.2 The Influence of Error Propagation,[0],[0]
Section 3.1 and 3.2 together show that error propagation has influence on but is not the only cause of accuracy drop.,4 Language Branching Matters,[0],[0]
"We hypothesize that the language itself, i.e., its characteristics, may explain the phenomenon of accuracy drop.
",4 Language Branching Matters,[0],[0]
Watanabe and Sumita (2002) finds that leftto-right decoding performs better for JapaneseEnglish translation while right-to-left decoding performs better for English-Japanese translation.,4 Language Branching Matters,[0],[0]
We conduct the same analysis settings as in Section 3.1 and 3.2 on English-Japanese (En-Jp) translation dataset.,4 Language Branching Matters,[0],[0]
"More details about this dataset and model descriptions can be found in supplementary materials (section A.1 and A.2).
",4 Language Branching Matters,[0],[0]
Table 4 shows the BLEU score on the En-Jp test set.,4 Language Branching Matters,[0],[0]
"It can be observed that regardless of decoding direction (i.e., from left-to-right or from right-toleft) and with or without teacher forcing, the accuracy of the right half is always higher than that in the left half.",4 Language Branching Matters,[0],[0]
"This observation on Japanese is
opposite to English, German and Chinese in Section 3.1 and 3.2, and motivates us to investigate the differences between these languages.
",4 Language Branching Matters,[0],[0]
"We find that a linguistics concept, the branching, can differentiate Japanese from other languages such as English/German.",4 Language Branching Matters,[0],[0]
"Branching refers to the shape of the parse trees that represent the structure of sentences (Berg et al., 2011; Payne, 2006).",4 Language Branching Matters,[0],[0]
"Usually, right-branching sentences are head-initial, which means the main subject of the sentence is described first, and is followed by a sequence of modifiers that provide additional information about the subject.",4 Language Branching Matters,[0],[0]
"On the contrary, left-branching sentences are head-final that putting such modifiers to the left of the sentence (Payne, 2006).
",4 Language Branching Matters,[0],[0]
"English is a typical right-branching language, while Japanese is almost fully leftbranching (Wikipedia, 2018).",4 Language Branching Matters,[0],[0]
The two languages demonstrate the opposite phenomenon of accuracy drop as shown in previous studies.,4 Language Branching Matters,[0],[0]
"When we say a language is typical left/right-branching, we mean most of the sentences in this language follows the left/right-branching structure.",4 Language Branching Matters,[0],[0]
"While being predominantly right-branching, German is less conclusively so than English.",4 Language Branching Matters,[0],[0]
"Chinese features a mixture of head-final and head-initial structures, with the noun phrases are head-final while the strict head/complement ordering sentences are headinitial as right-branching (Wikipedia, 2018), but less conclusively than German.
",4 Language Branching Matters,[0],[0]
We believe the language branching is a main cause of accuracy drop.,4 Language Branching Matters,[0],[0]
"Intuitively, the main subject of a right-branching sentence is described first (in the left part) and is followed by additional modifiers (in the right part) (Berg et al., 2011).",4 Language Branching Matters,[0],[0]
"Therefore, the left half of a right-branching sentence is more likely to possess a clearer structure pattern and thus lead to higher generation accuracy than in the right part, since the main subject is usually simpler and clearer than the modifiers that providing additional information about the subjec-
t. In next section, we will verify this intuition this assumption from a statistical perspective.",4 Language Branching Matters,[0],[0]
"As previous work (Arpit et al., 2017) shows, neural networks are easy to learn and memorize simple patterns but difficult to make a correct prediction on noise examples.",5 Correlation between Language Branching and Accuracy Drop,[0],[0]
"In this section, we study different branching languages from two aspects, including the n-gram statistics of a target language, which has been used as a kind of characterization of hardness of learning (Bengio et al., 2009), and the dependency statistics in parse trees.",5 Correlation between Language Branching and Accuracy Drop,[0],[0]
We show that these statistics well correlate with the accuracy drop between the left half and the right half of translation results.,5 Correlation between Language Branching and Accuracy Drop,[0],[0]
"Intuitively speaking, if a pattern occurs frequently and deterministically, it is easy to be learned by neural networks.",5.1 N-gram Statistics,[0],[0]
"By comparing the general statistics on the n-gram frequency and n-gram conditional probability of the left and right half tokens, we link the language branching to accuracy drop.
",5.1 N-gram Statistics,[0],[0]
"Denote a bilingual dataset D = {(xi, yi}, i = 1, · · · ,M , where each yi is a sequence of words yi = {y1i , · · · , y Ti i }, Ti is the length of yi.",5.1 N-gram Statistics,[0],[0]
"F li,n and P li,n denote the average n-gram frequency and n-gram conditional probability of the left half of yi 3, i.e.,
F li,n = 1
Ti/2− n + 1 Ti/2−n+1∑ j=1 F (yji , ..., y j+n−1 i ),
P li,n = 1
Ti/2− n + 1 Ti/2−n+1∑ j=1 P (yj+n−1i |y j i , ..., y j+n−2 i ),
(1)
where F (.)",5.1 N-gram Statistics,[0],[0]
and P (.) are the n-gram frequency and n-gram conditional probability calculated from the training dataset.,5.1 N-gram Statistics,[0],[0]
"Similarly, F ri,n and P r i,n denote the n-gram frequency and n-gram conditional probability of the right half.
",5.1 N-gram Statistics,[0],[0]
We calculate the average n-gram frequencies F ln and F rn of the left half and right half over all the target sentences in the training set.,5.1 N-gram Statistics,[0],[0]
We also calculate the average n-gram conditional probabilities P ln and P r n,5.1 N-gram Statistics,[0],[0]
"over all the training sentences to compare the uncertainty of phrases in the left half and
3Again, we assume Ti is an even number.",5.1 N-gram Statistics,[0],[0]
"If not, we simply remove the middle word of yi, as done in Section 3.1.
right half.
",5.1 N-gram Statistics,[0],[0]
"F ln = 1
M M∑ i=1",5.1 N-gram Statistics,[0],[0]
"F li,n, F r n = 1 M M∑ i=1",5.1 N-gram Statistics,[0],[0]
"F ri,n,
P ln = 1
M M∑ i=1",5.1 N-gram Statistics,[0],[0]
"P li,n, P r n = 1 M M∑ i=1",5.1 N-gram Statistics,[0],[0]
"P ri,n.
(2)
We also calculate the ratio of the sentences that the frequency/conditional probability of left half is bigger/smaller than that in the right half, denoted as RF",5.1 N-gram Statistics,[0],[0]
l>rn /RF,5.1 N-gram Statistics,[0],[0]
l<r n and RP l>r n,5.1 N-gram Statistics,[0],[0]
/RP,5.1 N-gram Statistics,[0],[0]
"l<r n :
RF l>rn = 1
M M∑ i=1",5.1 N-gram Statistics,[0],[0]
"1{F li,n > F ri,n},
RF l<rn = 1
M M∑ i=1",5.1 N-gram Statistics,[0],[0]
"1{F li,n < F ri,n},
RP l>rn = 1
M M∑ i=1",5.1 N-gram Statistics,[0],[0]
"1{P li,n > P ri,n},
RP l<rn = 1
M M∑ i=1",5.1 N-gram Statistics,[0],[0]
"1{P li,n < P ri,n}.
(3)
",5.1 N-gram Statistics,[0],[0]
We choose n = 2 and 3 to calculate the metrics in Equation 2 and 3 on different translation datasets.,5.1 N-gram Statistics,[0],[0]
"The numbers are listed in Table 5 and 6.
",5.1 N-gram Statistics,[0],[0]
"We can see the 2/3-gram frequency as well as the conditional probability of the left half is higher than that of the right half for right-branching languages including English, German and Chinese in De-En, En-De and En-Zh translation datasets.",5.1 N-gram Statistics,[0],[0]
"For left-branching language Japanese, the result is opposite.",5.1 N-gram Statistics,[0],[0]
"The n-gram frequency and conditional probability statistics are consistent with our observations on accuracy drop in left/rightbranching languages and verify our hypothesis: right-branching languages have clearer patterns in left part (with larger n-gram frequency as well as the conditional probability) and consequently leads to higher translation accuracy in the left part than the right part; left-branching languages are opposite.
",5.1 N-gram Statistics,[0],[0]
We further visualize how the accuracy drop (between the left half and right half of the translations) correlates with the gap of n-gram statistics in the left and right part.,5.1 N-gram Statistics,[0],[0]
"The accuracy drop (e.g., BLEU score) of left/right half is taken from the teacherforcing with left-to-right decoding in Table 3, and the n-gram gap is taken from the ∆ in the last row of Table 5 and 6.",5.1 N-gram Statistics,[0],[0]
Figure 1 shows strong correlation between accuracy drop and the gap of n-gram statistics:,5.1 N-gram Statistics,[0],[0]
"As the gap of n-gram statistics increases from negative values to positive values, the accuracy drop also increases from negative to positive.
",5.1 N-gram Statistics,[0],[0]
"n represent the ra-
tio that the n-gram frequency of left half of sentences are bigger/smaller than that of the right half. ∆",5.1 N-gram Statistics,[0],[0]
= RF l>rn − RF l<rn .,5.1 N-gram Statistics,[0],[0]
Note that the sum of RF,5.1 N-gram Statistics,[0],[0]
l>rn and RF,5.1 N-gram Statistics,[0],[0]
l<rn is less than 1 since sentence with less than 4 words does not contribute to the n-gram statistics.,5.1 N-gram Statistics,[0],[0]
"In this subsection, we study language branching from the perspective of dependency structure.",5.2 Dependency Statistics,[0],[0]
"We hypothesize that if the left/right half of sentence contains more dependencies between its intra words, this half should be easier to predict, leading to higher accuracy.",5.2 Dependency Statistics,[0],[0]
"Here we analyze the English sentence in De-En translation and Japanese sentence in En-Jp translation, since English is fully right-branching and Japanese is fully left-branching as introduced before.
",5.2 Dependency Statistics,[0],[0]
"For English parsing, we utilize the wellacknowledged Standford Parser4 to parse the sentences.",5.2 Dependency Statistics,[0],[0]
"After obtaining the parsing results, we split the sentence into left and right half, and separately count the numbers of dependencies in each half5.",5.2 Dependency Statistics,[0],[0]
"For Japanese, we leverage the open-source toolkit J.DepP6 to parse the sentence, and then count the number of dependencies of each half.
",5.2 Dependency Statistics,[0],[0]
We provide the results in Table 7.,5.2 Dependency Statistics,[0],[0]
"As can be observed, for English sentences, the left-half words depend more on each other than the right-half words, while for the Japanese sentences, the righthalf words have more dependencies.",5.2 Dependency Statistics,[0],[0]
"This observation is consistent with our observations on accu-
4https://nlp.stanford.edu/software/ lex-parser.shtml
5For simplicity, we just count the number of dependency, without considering dependency types.",5.2 Dependency Statistics,[0],[0]
"The detailed parsing formats can be found in the supplementary material (Section A.3).
",5.2 Dependency Statistics,[0],[0]
"6http://www.tkl.iis.u-tokyo.ac.jp/ ˜ynaga/jdepp/
racy drop, and can well explain the high accuracy of left part in English translation and right part in Japanese translation.",5.2 Dependency Statistics,[0],[0]
We have analyzed the accuracy drop problem from the view of error propagation and language itself in previous sections.,6 Extended Analyses and Discussions,[0],[0]
"In this section, we further provide extended analyses and several discussions to give a more clear understanding of the accuracy drop problem.",6 Extended Analyses and Discussions,[0],[0]
"The previous analyses are based on four languages, three right-branching (En, De, Zh) and one left-branching language (Jp).",6.1 More Languages on Left-Branching,[0],[0]
"To avoid the experimental bias and randomness, we provide one more translation task, English-Turkish (EnTr) translation7, as Turkish is a left-branching language.",6.1 More Languages on Left-Branching,[0],[0]
"We simply calculate the BLEU score of the left/right half in left-to-right and right-to-left
7The detailed dataset and model description can be found in supplementary material (section A.1 and section A.2).
decodings, as in Section 3.1 and 3.2.",6.1 More Languages on Left-Branching,[0],[0]
The result is provided in Table 8.,6.1 More Languages on Left-Branching,[0],[0]
"For the leftto-right decoding, the accuracy of the left half is higher than that of the right half in the normal translation.",6.1 More Languages on Left-Branching,[0],[0]
"However, the accuracy of the right half becomes higher with teacher forcing translation.",6.1 More Languages on Left-Branching,[0],[0]
This demonstrates that English-Turkish translation performs similar to English-Japanese translation as the accuracy of right half is higher than that of the left half.,6.1 More Languages on Left-Branching,[0],[0]
"But different from what we observed in Japanese, Turkish shows the opposite phenomenon: the influence of language branching is weaker than error propagation.",6.1 More Languages on Left-Branching,[0],[0]
One may wonder whether the results in the paper are biased towards a certain model structure as we use Transformer on all the above analyses.,6.2 Other Model Structures,[0],[0]
"To address such concerns, we conduct an additional experiment on De-En translation task with RNN (GRU)-based model8.",6.2 Other Model Structures,[0],[0]
The results are shown in Table 9 and the observations are consistent with what we observed on Transformer.,6.2 Other Model Structures,[0],[0]
"The accuracy of the left half of the De-En translation sentence is always higher than the right half, in both the leftto-right and right-to-left decodings.",6.2 Other Model Structures,[0],[0]
"We conduct experimental analysis on abstractive summarization, which is also a sequence generation task.",6.3 Other Sequence Generation Tasks,[0],[0]
The goal of the task is to recap a long news sentence into a short summary.,6.3 Other Sequence Generation Tasks,[0],[0]
"We use Gigaword dataset which contains 3.8M training pairs,
8The detailed setting for GRU based RNN model can be found in supplementary material (section A.2).
",6.3 Other Sequence Generation Tasks,[0],[0]
"190k validation and 2k test pairs of English sentence, and train an RNN-based model for sentence summarization.",6.3 Other Sequence Generation Tasks,[0],[0]
"The accuracy is measured by the commonly used metric ROUGE F1 score and are reported in Table 10.
",6.3 Other Sequence Generation Tasks,[0],[0]
We observe the same phenomenon as in translation tasks.,6.3 Other Sequence Generation Tasks,[0],[0]
"The accuracy of the left half is always better than the right half, no matter in left-to-right or right-to-left decoding, since the target language English is a right-branching language.",6.3 Other Sequence Generation Tasks,[0],[0]
"In this work, we studied the problem of accuracy drop between the left half and the right half of the results generated by neural machine translation models.",7 Conclusion,[0],[0]
We found the influence of error propagation is overstated in literature and error propagation alone cannot explain accuracy drop.,7 Conclusion,[0],[0]
We showed that language branching well correlates to the accuracy drop problem and the evidences on n-gram statistics as well as the dependency statistics well support this correlation.,7 Conclusion,[0],[0]
"Our discoveries suggest that left-to-right NMT models fit better for right-branching languages (e.g., English) and right-to-left NMT models fit better for leftbranching languages (e.g., Japanese).
",7 Conclusion,[0],[0]
"For future works, we will study more left/rightbranching languages as well as other languages that have no obvious branching characteristics.",7 Conclusion,[0],[0]
"We will also investigate how language branching influences other natural language tasks, especially for neural networks based models.",7 Conclusion,[0],[0]
Neural machine translation usually adopts autoregressive models and suffers from exposure bias as well as the consequent error propagation problem.,abstractText,[0],[0]
"Many previous works have discussed the relationship between error propagation and the accuracy drop (i.e., the left part of the translated sentence is often better than its right part in left-to-right decoding models) problem.",abstractText,[0],[0]
"In this paper, we conduct a series of analyses to deeply understand this problem and get several interesting findings.",abstractText,[0],[0]
"(1) The role of error propagation on accuracy drop is overstated in the literature, although it indeed contributes to the accuracy drop problem.",abstractText,[0],[0]
"(2) Characteristics of a language play a more important role in causing the accuracy drop: the left part of the translation result in a right-branching language (e.g., English) is more likely to be more accurate than its right part, while the right part is more accurate for a left-branching language (e.g., Japanese).",abstractText,[0],[0]
"Our discoveries are confirmed on different model structures including Transformer and RNN, and in other sequence generation tasks such as text summarization.",abstractText,[0],[0]
Beyond Error Propagation in Neural Machine Translation: Characteristics of Language Also Matter,title,[0],[0]
"Tremendous power of convolutional neural networks (CNNs) have been well demonstrated in a wide variety of computer vision applications, from image classification (Simonyan & Zisserman, 2015) and object detection (Ren et al., 2015) to image segmentation (Long et al., 2015).",1. Introduction,[0],[0]
"Meanwhile, there is a recent consensus that there are
1Key Laboratory of Machine Perception (MOE) and Cooperative Medianet Innovation Center, School of EECS, Peking University, Beijing 100871, P.R. China.",1. Introduction,[0],[0]
"2UBTech Sydney AI Institute, School of IT, FEIT, The University of Sydney, Darlington, NSW 2008, Australia.",1. Introduction,[0],[0]
"Correspondence to: Yunhe Wang <wangyunhe@pku.edu.cn>, Chang Xu <c.xu@sydney.edu.au>, Chao Xu <xuchao@cis.pku.edu.cn>, Dacheng Tao <dacheng.tao@sydney.edu.au>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
significant redundancy in most of existing convolutional neural networks.,1. Introduction,[0],[0]
"For instance, the ResNet-50 (He et al., 2015) with some 50 convolutional layers needs over 95MB memory for storage and over 3.8 × 109 times of floating number multiplications for calculating each image, and after discarding more than 75% of its weights, the network still works as usual (Wang et al., 2016).
",1. Introduction,[0],[0]
"Admittedly, a heavy neural network is extremely difficult to train and to use in mobile terminal apps due to the limited memory and computational resource.",1. Introduction,[0],[0]
"Lots of methods have been developed to reduce the amount of parameters in CNNs (Liu et al., 2015) to obtain a considerable compression ratio.",1. Introduction,[0],[0]
"(Han et al., 2015) discarded subtle weights in a pre-trained network and constructed a sparse neural network with less computational complexity.",1. Introduction,[0],[0]
"Subsequently, (Wang et al., 2016) further studied the redundancy on all weights and their underlying connections in the DCT frequency domain, which achieves higher compression and speed-up ratios.",1. Introduction,[0],[0]
"(Wen et al., 2016) excavated subtle connections in different aspects and (Figurnov et al., 2016) refined the conventional convolution neurons as locally connection on the input data in order to reduce the computational cost.",1. Introduction,[0],[0]
"In addition, there are a variety of techniques for compressing convolution filters, e.g., pruning (Han et al., 2016; Hu et al., 2016; Li et al., 2016), quantization and binarization (Arora et al., 2014; Rastegari et al., 2016; Courbariaux & Bengio, 2016), matrix approximation (Cheng et al., 2015), and matrix decomposition (Denton et al., 2014).
",1. Introduction,[0],[0]
"Although these methods obtained promising performance to reduce the storage of convolution filters, the memory usage introduced by filters is still huge in the stage of online inference.",1. Introduction,[0],[0]
"This is because except convolution filters, we have to store feature maps (output data) of different layers for the subsequent processes, e.g., over 97MB memory is required for storing feature maps of one single image when running a ResNet-50 (He et al., 2015) without batch normalization layers, and a batch consisting of 32 instances consumes some 3.2GB GPU memory.",1. Introduction,[0],[0]
"However, existing compression methods tend to directly compress the filters in one step and rarely consider the significant demand of feature maps on the storage and computational cost.
",1. Introduction,[0],[0]
"In a CNN, the size of a convolution filter is usually much
smaller than the number of filters in a convolutional layer.",1. Introduction,[0],[0]
"Given a convolutional layer with 1024 filters of size 3× 3, any 3×3 patch in the input data will be mapped into a 1024- dimensional space R9 → R1024.",1. Introduction,[0],[0]
"The size of the space to describe this small patch has broken up more than 100 folds, which leads to the redundancy of the feature map.",1. Introduction,[0],[0]
We are therefore motivated to discover the intrinsic representations of the redundant feature maps via dimensionality reduction.,1. Introduction,[0],[0]
Circulant matrix is employed to formulate the feature map transformation considering its low space complexity and high mapping speed.,1. Introduction,[0],[0]
"Based on the obtained compact feature maps, we re-formulate the convolution filters to establish its connections with the input data.",1. Introduction,[0],[0]
"In summary, the proposed approach makes the following contributions: • We propose to excavate the intrinsic information and
decrease the redundancy in feature maps derived from a large number of filters in each layer, and then the network architecture is upgraded to produce a new compact network with fewer filters but the similar discriminativeness.",1. Introduction,[0],[0]
• We devise to learn a circulant matrix for projection which is exactly a diagonal matrix in the Fourier domain and thus yields a high speed for training and low complexity for mapping.,1. Introduction,[0],[0]
"• Experiments demonstrate that, compared to the original heavy network, the learned portable counterpart network achieves a comparable accuracy, but has significantly lower memory usage and computational cost.",1. Introduction,[0],[0]
"Here we will first introduce some preliminaries of CNNs and then develop feature map dimensionality reduction method.
",2. Feature Map Dimensionality Reduction,[0],[0]
"For a convolutional layer L in a pre-trained convolution neural network N whose input data and output feature maps are X ∈ RH×W×c and Y ∈ RH′×W ′×d, respectively, where H , W , H ′, W ′ are widths and heights of X and Y , c is the channel number (i.e., the number of convolution filters in the previous layer) and d is the number of convolution filters in this layer.",2. Feature Map Dimensionality Reduction,[0],[0]
"These convolution filters can be denoted as a tensor, i.e., F ∈ Rs1×s2×c×d, where s1 and s2 are the width and the height of filters, respectively.",2. Feature Map Dimensionality Reduction,[0],[0]
"Taking the neural network as a powerful feature extractor, the convolutional layer then becomes a mapping from the patch x ∈ Rs1×s2 to feature map y ∈ Rd×1.
",2. Feature Map Dimensionality Reduction,[0],[0]
"Generally, d is much larger than s = s1× s2, e.g., d = 256 and s = 1 in the second layer in ResNet-50, and there are even some layers with d > 2000.",2. Feature Map Dimensionality Reduction,[0],[0]
"Admittedly, using such a long d-dimensional vector to represent a s1 × s2 area is heavy and redundant.",2. Feature Map Dimensionality Reduction,[0],[0]
"To decrease the storage and com-
putation cost of the feature map, we attempt to discover the compact representations of the feature maps.",2. Feature Map Dimensionality Reduction,[0],[0]
"Many sophisticated methods such as locally linear embedding (LLE, (Roweis & Saul, 2000)), principle component analysis (PCA, (Wold et al., 1987; Pan & Jiashi, 2017)), isometric feature mapping (Isomap, (Tenenbaum et al., 2000)), locality preserving projection (LLP, (He & Niyogi, 2004)), and other excellent dimensionality methods (Pan et al., 2016; Xu et al., 2014), can be applied for dimensionality reduction.",2. Feature Map Dimensionality Reduction,[0],[0]
"Low-dimensional representations produced by these methods can inherit intrinsic information of original high-dimensional data, so that the performance of the transformed features can be maintained, and enhanced in some cases.",2. Feature Map Dimensionality Reduction,[0],[0]
"We thus proceed to develop an exclusive feature map dimensionality reduction method for the deep network compression problem.
",2. Feature Map Dimensionality Reduction,[0],[0]
Dividing X into q = H ′,2. Feature Map Dimensionality Reduction,[0],[0]
"× W ′ patches and vectorizing them, we have X =",2. Feature Map Dimensionality Reduction,[0],[0]
"[vec(x1), ..., vec(xq)] ∈ Rsc×q .",2. Feature Map Dimensionality Reduction,[0],[0]
"Accordingly, we reformulate feature maps and convolution filters as Y =",2. Feature Map Dimensionality Reduction,[0],[0]
"[vec(Y1), ..., vec(Yd)] ∈ Rq×d and F = [vec(F1), ..., vec(Fd)]",2. Feature Map Dimensionality Reduction,[0],[0]
"∈ Rsc×d, respectively.",2. Feature Map Dimensionality Reduction,[0],[0]
"Thus, the conventional convolution operation of the given layer L can be rewritten as:
Y = XTF, (1)
where the i-th column in Y corresponds to the convolution responses of all patches through the i-th filter in F. Note that, when we consider the entire dataset, q should be additionally multiplied by the number of samples which is an extreme large number.",2. Feature Map Dimensionality Reduction,[0],[0]
The most compact representation of a CNN should have no correlation between feature maps derived from different convolution filters.,2. Feature Map Dimensionality Reduction,[0],[0]
"In other words, feature maps from different filters should be independent of each other as far as possible.",2. Feature Map Dimensionality Reduction,[0],[0]
"The independence (or redundancy) in Y can be measured by
Θ(Y) = ||YTY ◦ (1− I)||2F , (2)
where || · ||F is the Frobenius norm for matrices, 1 is a full one matrix, ◦ is the element-wise product, and I is an identity matrix.",2. Feature Map Dimensionality Reduction,[0],[0]
"Denote the reduced feature maps as Ỹ = φ(Y) ∈ Rq×d̃, where d̃ ≤ d and φ(·) can be either a linear (Wold et al., 1987) or non-linear transformation (Roweis & Saul, 2000).",2. Feature Map Dimensionality Reduction,[0],[0]
"However, since there are numerous training samples in real word image datasets (e.g., ImageNet (Russakovsky et al., 2015)), computational complexities of the nonlinear transformation will be great.",2. Feature Map Dimensionality Reduction,[0],[0]
"We thus use the linear transformation instead, i.e., Ỹ = φ(Y) =",2. Feature Map Dimensionality Reduction,[0],[0]
"YPT , where P ∈ Rd̃×d is the projection matrix.",2. Feature Map Dimensionality Reduction,[0],[0]
An optimal transformation should generate the new representations which occupy more information of the original input and have less internal correlation.,2. Feature Map Dimensionality Reduction,[0],[0]
"Based on the measurement in Fcn. 2, the optimal projection P can be solved
by minimizing the following function:
min P,c ||PYTYPT − C||2F , s.t. C = diag(c), (3)
where C = diag(c) is a diagonal matrix, whose functionality is equal to the identity matrix in Fcn. 2.
",2. Feature Map Dimensionality Reduction,[0],[0]
Deep neural network enjoys great popularity due to its excellent capability of learning effective features for examples.,2. Feature Map Dimensionality Reduction,[0],[0]
"An optimal projection should thus not only remove redundancy between feature maps, but also preserve the discriminability of these features.",2. Feature Map Dimensionality Reduction,[0],[0]
"If images from different categories are well separated from each other in the feature space, classifiers will more easily accomplish the classification task.",2. Feature Map Dimensionality Reduction,[0],[0]
"To maintain the accuracy of the original network and its representation capability, we propose to preserve the distances between feature maps and form the following objective function for seeking the compact feature maps:
min P,c ||PYTYPT − C||2F + λ||D(Ỹ)−D(Y)||
s.t. Ỹ = YPT , C = diag(c), (4)
where D(Y) = D ∈ Rq×q and Dij is the Euclidean distance between the i-th column and the j-th column of Y.",2. Feature Map Dimensionality Reduction,[0],[0]
The above section has proposed a feature map dimensionality reduction model.,3. Optimal Feature Map Learning,[0],[0]
"However, calculating the distance matrix D = D(·) is inefficient and memory consuming since the column length of Y corresponds to the number of training samples and is rather large in practice.",3. Optimal Feature Map Learning,[0],[0]
"For example, there are over 1.2×106 images in the ILSVRC-2012 dataset and there are up to 4096 filters of a network layer.",3. Optimal Feature Map Learning,[0],[0]
"The size ofD will be larger than 4×109, which is inconvenient for distance calculation.",3. Optimal Feature Map Learning,[0],[0]
"In this section, we will propose an alternative feature map dimensionality reduction approach, which consists of two steps: distance preservation and sparse approximation.
",3. Optimal Feature Map Learning,[0],[0]
"In fact, distances between feature maps can be easily preserved if P is orthogonal, i.e., PPT = I, where I is an identity matrix with size",3. Optimal Feature Map Learning,[0],[0]
d × d.,3. Optimal Feature Map Learning,[0],[0]
"For any two feature maps y1, y2,∈ Rd, we have ||y1PT ||2 = ||y1||2 and ||y1PT",3. Optimal Feature Map Learning,[0],[0]
− y2PT ||22 = ||y1 − y2||22.,3. Optimal Feature Map Learning,[0],[0]
"We thus reformulate Fcn. 4 as
min P ||PYTYPT − C||2F ,
s.t. C = diag(c), PPT = I. (5)
",3. Optimal Feature Map Learning,[0],[0]
"The orthogonal transformation P learned by Fcn. 5 is able to extract the intrinsic representation and preserve distances between feature maps, but the dimensionality has not been reduced since P is a square matrix.",3. Optimal Feature Map Learning,[0],[0]
"Hence at the second
stage, we propose to use a sparse matrix to approximate the representation generated by P ,
min Ỹ
1 2 ||Ỹ −YPT ||2F",3. Optimal Feature Map Learning,[0],[0]
"+ λ||Ỹ||2,1, (6)
",3. Optimal Feature Map Learning,[0],[0]
"where ||Ỹ||2,1 = ∑ i ||Ỹi|| and Ỹi is the i-th column in Ỹ. || · ||2,1 is `2,1-norm which is a widely used regularization (Nie et al., 2010; Liu et al., 2010) for removing useless columns in Ỹ and the closed form solution of Fcn. 6 is
Ỹi =
{ ||ui||−λ ||ui|| ui, if λ < ||ui||
0, otherwise (7)
where ui = YPTi and Pi is the i-th column in P .",3. Optimal Feature Map Learning,[0],[0]
"Zero columns in Ỹ can be discarded to achieve the lowdimensional representations.
",3. Optimal Feature Map Learning,[0],[0]
"By combining Fcn. 6 and Fcn. 5, we can obtain a unified model as follow
min P,c ||PYTYPT − C||2F + β||c||1
s.t. C = diag(c), PPT = I, (8)
where || · ||1 is the `1 norm to make c sparse, so that some small valued columns in Ỹ = YPT will be discarded.",3. Optimal Feature Map Learning,[0],[0]
"β is a weight parameter which controls the sparsity of Ỹ and implicitly influence the resulting dimensionality of the new feature map of this layer.
",3. Optimal Feature Map Learning,[0],[0]
"Considering there are d × d variables in P and d can be up to 4096, Fcn. 8 cannot be efficiently optimized w.r.t.",3. Optimal Feature Map Learning,[0],[0]
P .,3. Optimal Feature Map Learning,[0],[0]
"Since each frequency coefficient corresponds to a Fourier base with different textures, circulant matrices have complex internal structures and strong diversity thus can be utilized for approximating huge matrices (Cheng et al., 2015).",3. Optimal Feature Map Learning,[0],[0]
"We therefore propose using a circulant matrix (Gray, 2006; Henriques et al., 2015; 2014) to formulate P , which then only has d variables in the Fourier frequency domain.",3. Optimal Feature Map Learning,[0],[0]
"We propose the following model to learn the projection for generating the compact low-dimensional feature maps:
min p,c ||PYTYPT − C||2F + α||PPT",3. Optimal Feature Map Learning,[0],[0]
"− I||2F + β||c||1,
s.t. P = circ(p), C = diag(c), (9)
where α is the weight for relaxing the equality constrain in Fcn. 5, and P = circ(p) is a circulant matrix.",3. Optimal Feature Map Learning,[0],[0]
"For the d×1 vector p = (p1, ..., pd)T , we can refer to it as the base sample, and the cyclic shift operator can be defined as:
circ(p)",3. Optimal Feature Map Learning,[0],[0]
:=  p1 pd . . .,3. Optimal Feature Map Learning,[0],[0]
p3 p2 p2 p1 pd p3 ...,3. Optimal Feature Map Learning,[0],[0]
p2 p1 . . .,3. Optimal Feature Map Learning,[0],[0]
"...
",3. Optimal Feature Map Learning,[0],[0]
pd−1 . . . . . .,3. Optimal Feature Map Learning,[0],[0]
"pd
pd pd−1 . . .",3. Optimal Feature Map Learning,[0],[0]
"p2 p1
 .",3. Optimal Feature Map Learning,[0],[0]
"(10)
Given the fact that all circulant matrices are made diagonal by the discrete Fourier transform (DFT (Bracewell, 1965)), P and PT can be expressed as
P = 1
d SH diag(p̂) S, PT =
1 d S diag(p̂) SH , (11)
where S is the DFT transform matrix which is constant, the DFT is a linear transform, and SHS = dI. p̂ is the frequency representation of p, i.e.,
p̂ = F(p)",3. Optimal Feature Map Learning,[0],[0]
"= Sp, (12)
and its inverse discrete Fourier transform (IDFT) is p = F−1(p̂) = 1dS
H(p̂).",3. Optimal Feature Map Learning,[0],[0]
"In following illustrations, we will use a hat ˆ to denote the DFT frequency representations.
",3. Optimal Feature Map Learning,[0],[0]
Since any two bases in S are orthogonal thus it can hold the Euclidean distance between any two vectors.,3. Optimal Feature Map Learning,[0],[0]
"For any two d-dimensional samples in Y we have
||SyT1 ||22 = 1
d ||y1||22,
||SyT1 − SyT2 ||22 = 1
d ||y1 − y2||22.
(13)
",3. Optimal Feature Map Learning,[0],[0]
"In addition, the most elegant property of the circulant matrix is that the projection in the original domain is equivalent to vector element wise product in the Fourier domain (Oppenheim et al., 1999), which is beneficial for significantly decreasing the computational complexity, i.e.,
F(PyT ) = F(p) ◦ F(y)T , F(yPT ) = F(y) ◦ F(p)T ,
(14)
",3. Optimal Feature Map Learning,[0],[0]
where ◦ denotes the element wise product.,3. Optimal Feature Map Learning,[0],[0]
"Since DFT and IDFT can be efficiently computed in O(d log d) with the fast Fourier transform (FFT, (Bracewell, 1965)), the projection for generating low-dimensional feature maps is only O(d log d), compared with the O(d2) complexity of the original dense matrix multiplication.",3. Optimal Feature Map Learning,[0],[0]
"Considering the efficient computation over circulant matrix in the frequency domain, we propose to use the frequency optimizing approach to obtain the optimal feature maps representation Ỹ = YPT .",3. Optimal Feature Map Learning,[0],[0]
"We optimize Fcn. 9 by alternatively fixing p and c, and leave the optimization details in the supplementary materials for the limited page length.
",3. Optimal Feature Map Learning,[0],[0]
"Given the optimal p̂ and c, the transformation for reducing the dimensionality of feature maps can be written as
P = 1
d diag(c̄)SH P̂S, (15)
where c̄i = 0, if ci = 0, and c̃i = 1, otherwise, the transformation P in Fcn. 9 is a row sparse matrix, and the rows with all zeros can be discarded to reformulate a compact transformation matrix Pd̃ with d̃ rows according to c̄.
Therefore the feature map matrix Y can be transformed as Ỹ = YPT
d̃ .",3. Optimal Feature Map Learning,[0],[0]
"This projection is exactly a linear transform,
if we only take one convolutional layer into consideration, i.e., the input data matrix X is fixed, we can explicitly include the filter matrix F into the dimensionality reduction procedure, i.e.,
Ỹ = YPT d̃ = XFTPT d̃ = XF̃T .",3. Optimal Feature Map Learning,[0],[0]
"(16)
Hence, we can also directly reduce the number of convolution filters after obtaining the optimal projection matrix Pd̃. Fixing the filter size as s1×s2×c, we can reconstruct convolutional layers with smaller filters F̃ ∈",3. Optimal Feature Map Learning,[0],[0]
Rs1×s2×d̃.,3. Optimal Feature Map Learning,[0],[0]
"Based on the above analysis, we have the following proposition:
Proposition 1.",3. Optimal Feature Map Learning,[0],[0]
"Given a convolutional layer L with d filters, i.e., its feature map dimensionality is d. For the ddimensional feature of any sample through L, the proposed method for solving its low-dimensional embedding has space complexity O(d), and time complexity O(d log d).",3. Optimal Feature Map Learning,[0],[0]
Section 3 proposes an effective approach for learning compact feature maps of a given convolutional layer.,4. CNN Layer Reconstruction,[0],[0]
"In the online inference, it is impossible to first calculate the original high-dimensional feature maps, and then project them into the low-dimensional space.",4. CNN Layer Reconstruction,[0],[0]
"To conserve the online computation resource, we thus aim to establish the mapping directly from the input data to the compact feature map.
",4. CNN Layer Reconstruction,[0],[0]
"The dimensionality of the feature map for the i-th convolutional layer Li has been reduced by Fcn. 16, and the number of convolution filters of Li has also been reduced from d to d̃ (where d̃ d).",4. CNN Layer Reconstruction,[0],[0]
"For the following convolutional layer L(i+1), the size of the input data X̃ has becomesH×W×d̃ and we have X̃ ∈ Rsd̃×q , which leads original filters can no longer be used for calculating.",4. CNN Layer Reconstruction,[0],[0]
"Thus, we propose minimizing the following function for reconstructing convolution filters of this layer:
min F̃ ||Ỹ",4. CNN Layer Reconstruction,[0],[0]
− X̃T F̃||2F,4. CNN Layer Reconstruction,[0],[0]
"+ γ||F̃||2F , (17)
where Ỹ is the compact feature maps of L(i+1) after applying Fcn. 16 and γ is a weight parameter for balancing the two terms.",4. CNN Layer Reconstruction,[0],[0]
"Note that the second term can be regarded as a weight decay regularization in the training of neural networks (Krizhevsky et al., 2012).",4. CNN Layer Reconstruction,[0],[0]
"Fcn. 17 can be efficiently solved by the following closed form solution:
F̃ = (X̃X̃T + γI)−1X̃Ỹ, (18)
where I is an identity matrix.",4. CNN Layer Reconstruction,[0],[0]
"However, when the scale of the dataset is enormous, we cannot construct the two huge matrices X̃ and Ỹ through all instances in the dataset.",4. CNN Layer Reconstruction,[0],[0]
"The
Algorithm 1 CNN Layer Reconstruction Method.",4. CNN Layer Reconstruction,[0],[0]
"Input: A pre-trained convolutional neural network N learned
through a dataset X with k convolutional layers: L1, ...,Lk, weight parameter γ, learning rate η. 1: Calculate feature maps of each layer by using the original network: {Y1, ...Yk} ← N (X ); 2: for i = 1 to k",4. CNN Layer Reconstruction,[0],[0]
"− 1 do 3: Learn the projection Pi by solving Fcn. 9; 4: Calculate new feature maps: Ỹi ← YiPTi ; 5: end for 6: Keep feature maps of the k-th layer: Ỹk ← Yk; 7: Construct a new network Ñ according to {Ỹ1, ...Ỹk} and
initialize convolution filters {F̃1, ...F̃k} by random values from the standard normal distribution;
8: repeat 9: Randomly select a batch Xj from X ;
10: for i = 1 to k do 11: Generate input data X̃i of Li exploiting Ñ ; 12: Estimate the new filter matrix (Fcn. 20):",4. CNN Layer Reconstruction,[0],[0]
"F̃i ← F̃i − η∂L(F̃i)/∂F̃i; 13: Convert F̃i into filter data and fill it in Ñ ; 14: end for 15: until Convergence; Output: The new convolutional neural network Ñ .
mini-batch strategy is adopted for updating F̃ iteratively.",4. CNN Layer Reconstruction,[0],[0]
"The loss function of F̃ can be directly formulated as
L(F̃) = Tr(F̃T X̃T X̃F̃)
",4. CNN Layer Reconstruction,[0],[0]
− 2Tr(F̃T X̃Ỹ) +,4. CNN Layer Reconstruction,[0],[0]
"γTr(F̃T F̃), (19)
and the gradient of L(F̃) is
∂L(F̃)
",4. CNN Layer Reconstruction,[0],[0]
"∂F̃ = 2X̃X̃T F̃− 2X̃Ỹ + 2γF̃. (20)
",4. CNN Layer Reconstruction,[0],[0]
"By using stochastic gradient descent (SGD), F̃ can be updated as
F̃ = F̃− η ∂L(F̃) ∂F̃ , (21)
where η is the learning rate.
",4. CNN Layer Reconstruction,[0],[0]
It is worth mentioning that input data of the first layer of the original network N and feature map of the last layer (closely related to the number of classification labels) are kept unchanged.,4. CNN Layer Reconstruction,[0],[0]
"As for other intermediate convolutional layers and fully connected layers, we can generate compact feature maps Ỹ from the original feature maps",4. CNN Layer Reconstruction,[0],[0]
"Y. Then, calculate the input data X̃ using the compressed network Ñ and estimate the filter matrix F̃. The detailed filters updating procedure can be found in Alg. 1.
",4. CNN Layer Reconstruction,[0],[0]
"According to Proposition 1, for a d-dimensional feature, the complexity of the proposed feature map dimensionality reduction method with the help of circulant matrix is only O(d log d).",4. CNN Layer Reconstruction,[0],[0]
"Compared to O(d2) of other traditional linear projection methods, the proposed scheme is of great benefit
for conducting experiments on large scale datasets.",4. CNN Layer Reconstruction,[0],[0]
"Moreover, since we only need to store a d-dimensional vector for one layer, the proposed method also have an obvious advantage on the space complexity for learning a portable version of neural networks with a larger number of layers (e.g., ResNet (He et al., 2015)).
",4. CNN Layer Reconstruction,[0],[0]
Discussion.,4. CNN Layer Reconstruction,[0],[0]
There are some works investigating the intrinsic information of feature maps in the original neural network to learn a new thinner and deeper neural network.,4. CNN Layer Reconstruction,[0],[0]
"(Hinton et al., 2015) first built a thinner neural network and then made its feature map of the fully connected layer similar to that of the original pre-trained networks, thus enhanced the accuracy of the new network.",4. CNN Layer Reconstruction,[0],[0]
"(Romero et al., 2015) further extended this work to a general model which minimizes the difference between the feature map of an arbitrary layer in the smaller network and the feature map of a given layer in the original network, yields a thinner and deeper network with some accuracy decline.
",4. CNN Layer Reconstruction,[0],[0]
"The difference between these methods and the proposed method is two-fold: (i) These methods rebuild a new student network with less parameters while the proposed method outputs a compact CNN based on the original network itself, which inherits the well-designed architectures; (ii)",4. CNN Layer Reconstruction,[0],[0]
"The performance of the newly learned student network will be declined, since it is only influenced by the information from one or several layers of the teacher network.",4. CNN Layer Reconstruction,[0],[0]
"By contrast, the proposed method excavates redundancy in feature maps of every layer and preserves the distances between examples to guarantee the accuracy of the CNN.",4. CNN Layer Reconstruction,[0],[0]
A novel dimensionality reduction method for learning a portable neural network has been proposed in Alg. 1.,5. Analysis on Compression Performance,[0],[0]
"Compared with the original heavy networkN , the new network Ñ has the same depth but less convolution filters per layer.",5. Analysis on Compression Performance,[0],[0]
"In this section, we will further analyze the memory usage and computation cost of Ñ and calculate the compression ratio and speed-up ratio theoretically.
",5. Analysis on Compression Performance,[0],[0]
Speed-up ratio.,5. Analysis on Compression Performance,[0],[0]
Consider the i-th convolutional layerLi in the original networkN with its output feature map and convolution filters are,5. Analysis on Compression Performance,[0],[0]
Yi ∈ RH ′,5. Analysis on Compression Performance,[0],[0]
i×W ′,5. Analysis on Compression Performance,[0],[0]
"i×di and F ∈ Rs2i×ci×di , respectively.",5. Analysis on Compression Performance,[0],[0]
We only discuss square filters and the conclusion can be straightforwardly extended to non-square filters as well.,5. Analysis on Compression Performance,[0],[0]
"Wherein, ci = di−1 is the channel number of filters in Li and d0 = 3",5. Analysis on Compression Performance,[0],[0]
(RGB color images).,5. Analysis on Compression Performance,[0],[0]
The feature map and convolution filters in the corresponding layer L̃i in the learned compact network are Yi ∈ RH ′,5. Analysis on Compression Performance,[0],[0]
i×W ′,5. Analysis on Compression Performance,[0],[0]
"i×d̃i and F ∈ Rs2i×c̃i×d̃i , respectively.",5. Analysis on Compression Performance,[0],[0]
"Generally, weights and feature maps are stored in 32-bit floating values whose multiplications are much more expensive than additions.",5. Analysis on Compression Performance,[0],[0]
"Complexities of other auxiliary layers (e.g., pooling, Relu, etc..)
have been discarded since they only account for a subtle proportion of the overall complexity.",5. Analysis on Compression Performance,[0],[0]
"Hence, considering the major multiplications, the speed-up ratio of the compact network for this layer compared with the original network is
rs = s2i di−1diH ′ iW ′",5. Analysis on Compression Performance,[0],[0]
"i
s2i d̃i−1d̃iH ′",5. Analysis on Compression Performance,[0],[0]
iW ′,5. Analysis on Compression Performance,[0],[0]
"i
= di−1di
d̃i−1d̃i .",5. Analysis on Compression Performance,[0],[0]
"(22)
",5. Analysis on Compression Performance,[0],[0]
It is obvious that the speed-up ratio for one convolutional layer relates to numbers of filters in this layer and the previous layer.,5. Analysis on Compression Performance,[0],[0]
"Thus, if we only keep 1/2 filters per layer, the speed-up ratio will be increased to 4×.
Compression ratio.",5. Analysis on Compression Performance,[0],[0]
"The online memory can be divided into two major parts, feature maps of different layers and filters of convolutional layers.",5. Analysis on Compression Performance,[0],[0]
"Although we can remove feature maps of a layer after it has already been used for calculating the following layer, the the memory allocation and release will increase the time consumption.",5. Analysis on Compression Performance,[0],[0]
"Moreover, if a layer is connected with several other convolutional layers, we have to store feature maps of previous layers when doing online inference (e.g., the second convolutional layer and the fifth convolutional layer will be combined in ResNet-50 (He et al., 2015), and we have to preserve these feature maps before merging them).",5. Analysis on Compression Performance,[0],[0]
"For a given convolutional layer Li, the compression ratio of the proposed method is
rc = s2i di−1di + diH ′ iW ′",5. Analysis on Compression Performance,[0],[0]
"i
s2i d̃i−1d̃i + d̃iH ′",5. Analysis on Compression Performance,[0],[0]
iW ′,5. Analysis on Compression Performance,[0],[0]
"i
, (23)
which is simultaneously affected by the current layer and the pervious layer.",5. Analysis on Compression Performance,[0],[0]
"Meanwhile, the memory for storing feature maps of other layers, such as pooling layers and Relu layers, will be reduced.",5. Analysis on Compression Performance,[0],[0]
We will further illustrate the detailed compression ratio and speed-up ratio of the proposed method in the following section experimentally.,5. Analysis on Compression Performance,[0],[0]
Baselines and Models.,6. Experiments,[0],[0]
"Several effective approaches for compressing deep neural networks were selected for comparison: SVD (Denton et al., 2014), XNOR-Net (Rastegari
et al., 2016), Pruning (Han et al., 2016), Perforation (Figurnov et al., 2016), and CNNpack (Wang et al., 2016), and we denoted the proposed method as RedCNN.",6. Experiments,[0],[0]
"The evaluation was conducted on the MNIST and ILSVRC2012 datasets (Russakovsky et al., 2015).",6. Experiments,[0],[0]
"We first tested the performance of the proposed method and analyzed impacts of parameters on the MNIST dataset using LeNet (LeCun et al., 1998), then compared the proposed method with two benchmark CNNs (VGGNet-16 (Simonyan & Zisserman, 2015) and ResNet-50 (He et al., 2015)) on the ILSVRC 2012 dataset (Russakovsky et al., 2015) which has more than 1 million nature images.",6. Experiments,[0],[0]
"All methods were implemented using MatConvNet (Vedaldi & Lenc, 2015) and ran on NVIDIA K40 cards.",6. Experiments,[0],[0]
"Filters and data in CNNs were stored and calculated as 32 bit floating-point values.
",6. Experiments,[0],[0]
Impact of parameters.,6. Experiments,[0],[0]
The hyper-parameter γ in the proposed reconstruction method (Alg. 1) controls the weight decay regularization and makes weights in new convolution filters not too large.,6. Experiments,[0],[0]
We set γ as 0.0005 empirically.,6. Experiments,[0],[0]
"In addition, the proposed dimensionality method (Fcn. 9) has two hyper-parameters, i.e., α and β.",6. Experiments,[0],[0]
"We first tested their impact on the network accuracy by conducting an experiment using a LeNet for classifying the MNIST dataset (Vedaldi & Lenc, 2015), where the network has four convolutional layers of size 5×5×1×20, 5×5×20×50, 4×4×50×500, and 1×1×500×10, respectively, and its accuracy is 99.2%.",6. Experiments,[0],[0]
"α is used for enforcing the projection matrix P to be orthogonal and is set to be 1.5, experimentally.",6. Experiments,[0],[0]
"β is directly related to the sparsity of P , and it effects compression and speed-up ratios of the proposed method.",6. Experiments,[0],[0]
"Although a larger β will produce a smaller network, it also leads to a larger distortion on the Euclidean distances between samples.",6. Experiments,[0],[0]
"To have a clear illustration, we reported the compression performance by ranging different β, as shown in Fig. 1.
",6. Experiments,[0],[0]
"From Fig. 1 (a), we found that the compact network reconstructed by using Alg. 1 can also hold a considerable accuracy (e.g., 78% when β = 0.06), which demonstrates that the proposed method can preserve the intrinsic information of the original CNN.",6. Experiments,[0],[0]
"Moreover, the accuracy decline can be rebounded (98.9% when β = 0.06) after fine-tuning as
shown in Fig. 1 (b).",6. Experiments,[0],[0]
"However, a network that was directly trained with such a small architecture can only achieve a 92.8% accuracy.",6. Experiments,[0],[0]
"In addition, although the impact of β is sensitive but monotonous, a larger β enhances compression and speed-up ratios simultaneously, but decreases the accuracy of CNNs as well.",6. Experiments,[0],[0]
The value of β can be easily adjusted according to the demand and restrictions of devices.,6. Experiments,[0],[0]
"In our experiments, we set β = 0.06 which provides the best trade-off between compression performance and accuracy, i.e., rc = 11.3×, rs = 8.7×, with 99.16% accuracy.",6. Experiments,[0],[0]
"In this case, the layers in the compact convolution network is of the size 5×5×1×5, 5×5×5×20, 4×4×20×96, and 1×1×96×10, respectively.",6. Experiments,[0],[0]
The resulting compact network only occupies around 130KB memory.,6. Experiments,[0],[0]
"The MATLAB file of the compressed network and the demo code can be found in https://github.com/YunheWang/RedCNN.
",6. Experiments,[0],[0]
Deep Neural Networks Compression on ISLVRC-2012.,6. Experiments,[0],[0]
"We next employed the proposed RedCNN for CNN compression on the ImageNet ILSVRC-2012 dataset (Russakovsky et al., 2015), which contains over 1.2M training images and 50k validation images.",6. Experiments,[0],[0]
"We evaluated the compression performance on three widely used models: AlexNet (Krizhevsky et al., 2012), which has more than 61M parameters and a top-5 accuracy of 80.8%; VGGNet16 (Simonyan & Zisserman, 2015), which has over 138M parameters and a top-5 accuracy of 90.1%; and ResNet50 (He et al., 2015) which has more than 150 layers with 54 convolutional layers, and a top-5 accuracy of 92.9%.",6. Experiments,[0],[0]
"It is worth mentioning that there are considerable filters in the ResNet-50, and thus the network has less redundancy and it is hard for further compression.",6. Experiments,[0],[0]
"We first begin our experiment with the AlexNet dataset, and the detailed experimental results were shown in Tab. 1.
",6. Experiments,[0],[0]
"From Tab. 1, we found that the proposed method achieved a 5.1× compression ratio and a 4.3× speed-up ratio for AlexNet.",6. Experiments,[0],[0]
"Then, we reported the compression result of VGGNet-16 in Tab. 2.
",6. Experiments,[0],[0]
"It can be seen from Tab. 2, we obtained a 6.19× compression ratio and a 9.63× speed-up ratio on VGGNet-16.",6. Experiments,[0],[0]
"In addition, the compression ratio and the speed-up ratio on ResNet-50 are 4.14× and 5.82×, respectively.",6. Experiments,[0],[0]
"Note that the compression ratio we reported here is calculated by
Fcn. 23, which contains both convolution filters and feature maps.",6. Experiments,[0],[0]
"More compression results of these three CNN models can be found in the supplementary material.
",6. Experiments,[0],[0]
Comparison with state-of-the-art methods.,6. Experiments,[0],[0]
Tab. 3 details the compression results of the proposed method and several state-of-the-art methods on three benchmark deep CNN models.,6. Experiments,[0],[0]
"Since comparison methods do not change the number of filters of the original neural network, feature map compression ratios of these methods are both equal to 1.",6. Experiments,[0],[0]
"Thus, we reported the compression ratio of filters rc1 and feature maps rc2 separately for a fair comparison.",6. Experiments,[0],[0]
"For a convolutional neural network with layers, its compression ratios is calculated as
rc1 =
∑p i=1 s
2 i di−1di∑p
i=1 s 2 i d̃i−1d̃i
, rc2",6. Experiments,[0],[0]
"=
∑p i=1",6. Experiments,[0],[0]
"diH
′ iW ′",6. Experiments,[0],[0]
"i∑p
i=1",6. Experiments,[0],[0]
d̃iH ′,6. Experiments,[0],[0]
iW ′,6. Experiments,[0],[0]
"i
.",6. Experiments,[0],[0]
"(24)
Tab. 3 also shows the cost of various models for processing one image, i.e., storage of filters, memory usage of feature maps, and multiplications for calculating convolutions.",6. Experiments,[0],[0]
"It is obvious that feature maps accounting a considerable proportion of memory usage of the whole network, and the proposed RedCNN can provide significant compression ratios rc2 on every network.",6. Experiments,[0],[0]
"Although we can remove the feature map of a layer after calculation for saving memory, frequently allocating and releasing is also time consuming.
",6. Experiments,[0],[0]
"It can be seen from Tab. 3, RedCNN clearly achieves the best performance in terms of both the speed-up ratio (rs) and the feature map compression ratio (rc1 ).",6. Experiments,[0],[0]
"In addition, convolution filter compression ratios of the proposed method is lower than those of pruning (Han et al., 2016) and CNNpack (Wang et al., 2016).",6. Experiments,[0],[0]
"These two comparison methods employed quantization approaches (i.e., onedimensional k-means clustering), and thus 32-bit floating values can be converted into about 8-bit values without af-
fecting the accuracy of the original network.",6. Experiments,[0],[0]
"If we adopt this similar strategy, the convolution filter compression ratio rc1 of the proposed scheme can be further multiplied a factor of around 4×, e.g., we can obtain an almost 17.4× filter compression ratio on ResNet-50 model, which is superior to all the other comparison methods.",6. Experiments,[0],[0]
"However, 8-bit (or other unconventional format) value cannot be directly used in generic devices (e.g., GPU cards, mobile phones), and thus we did not try them in the experiments of this paper.",6. Experiments,[0],[0]
"In summary, the proposed RedCNN can achieve considerable compression and speed-up ratios, which can make existing deep models portable.
",6. Experiments,[0],[0]
Runtime.,6. Experiments,[0],[0]
"In fact, most of comparison methods cannot significantly accelerate the deep network for various additional operations.",6. Experiments,[0],[0]
"For example, (Han et al., 2016) needs to decode the CSR data before testing, which slows down the online inference and will not achieve the comparable compression and speed-up ratios with those of the proposed algorithm in practice.",6. Experiments,[0],[0]
"Since the proposed compression method directly re-configures the network into a more compact form, and does not require other additional support for realizing the network speed-up, the runtime of the compressed models for processing images will be reduced significantly.",6. Experiments,[0],[0]
"To explicitly demonstrate the superiority of the proposed method, we compared runtimes for recognizing images by benchmark CNN models before and after applying the proposed method, and showed the experimental results in Tab. 4.
",6. Experiments,[0],[0]
"We found that runtimes of these models after compression
were significantly reduced.",6. Experiments,[0],[0]
"The results are extremely encouraging, e.g., the compressed ResNet can recognize over 500 images per second.",6. Experiments,[0],[0]
"This efficiency can also be inherited into the fine-tuning process, therefore, the compressed networks can be quickly adjusted when applied them to a new dataset.",6. Experiments,[0],[0]
"In addition, the practical speed-up ratios of runtimes were slightly lower than the corresponding theoretical speed-up ratios rs due to the costs incurred by data transmission, pooling, padding, etc..",6. Experiments,[0],[0]
"Note that, the runtime reported here is a bit higher than that in (Vedaldi & Lenc, 2015), due to different configurations and hardware environments.",6. Experiments,[0],[0]
Compression methods for learning portable CNNs are urgently required so that neural networks can be used on mobile devices.,7. Conclusions and Discussions,[0],[0]
"Besides convolution filters, the storage of feature maps also accounts for a larger proportion of the online memory usage, we thus no longer search useless connections or weights of filters.",7. Conclusions and Discussions,[0],[0]
"In this paper, we present a feature map dimensionality reduction method by excavating and removing redundancy in feature maps generated by different filters.",7. Conclusions and Discussions,[0],[0]
"Although the portable network learned by our approach has significantly fewer parameters, its feature maps can also preserve intrinsic information of the original network.",7. Conclusions and Discussions,[0],[0]
Experiments conducted on benchmark datasets and models show that the proposed method can achieve considerable compression ratio and speed-up ratios simultaneously without affecting the classification accuracy of the original CNN.,7. Conclusions and Discussions,[0],[0]
"In addition, the compressed network generated by exploiting the proposed method is still a regular CNN with 32-bit float values which does not have any decoding or other procedures for online inference.",7. Conclusions and Discussions,[0],[0]
"We thank supports of NSFC 61375026 and 2015BAF15B00, and ARC Projects: FT-130101457, DP-140102164, LP-150100671.",Acknowledgements,[0],[0]
"Convolutional neural networks (CNNs) have shown extraordinary performance in a number of applications, but they are usually of heavy design for the accuracy reason.",abstractText,[0],[0]
"Beyond compressing the filters in CNNs, this paper focuses on the redundancy in the feature maps derived from the large number of filters in a layer.",abstractText,[0],[0]
We propose to extract intrinsic representation of the feature maps and preserve the discriminability of the features.,abstractText,[0],[0]
"Circulant matrix is employed to formulate the feature map transformation, which only requires O(d log d) computation complexity to embed a d-dimensional feature map.",abstractText,[0],[0]
"The filter is then reconfigured to establish the mapping from original input to the new compact feature map, and the resulting network can preserve intrinsic information of the original network with significantly fewer parameters, which not only decreases the online memory for launching CNN but also accelerates the computation speed.",abstractText,[0],[0]
Experiments on benchmark image datasets demonstrate the superiority of the proposed algorithm over state-ofthe-art methods.,abstractText,[0],[0]
Beyond Filters: Compact Feature Map for Portable Deep Model,title,[0],[0]
"Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 2204–2214, Austin, Texas, November 1-5, 2016. c©2016 Association for Computational Linguistics
We develop a novel bi-directional attention model for dependency parsing, which learns to agree on headword predictions from the forward and backward parsing directions. The parsing procedure for each direction is formulated as sequentially querying the memory component that stores continuous headword embeddings. The proposed parser makes use of soft headword embeddings, allowing the model to implicitly capture high-order parsing history without dramatically increasing the computational complexity. We conduct experiments on English, Chinese, and 12 other languages from the CoNLL 2006 shared task, showing that the proposed model achieves state-of-the-art unlabeled attachment scores on 6 languages.1",text,[0],[0]
"Recently, several neural network models have been developed for efficiently accessing long-term memory and discovering dependencies in sequential data.",1 Introduction,[0],[0]
"The memory network framework has been studied in the context of question answering and language modeling (Weston et al., 2015; Sukhbaatar et al., 2015), whereas the neural attention model under the encoder-decoder framework has been applied to machine translation (Bahdanau et al., 2015) and constituency parsing (Vinyals et al., 2015b).",1 Introduction,[0],[0]
"Both frameworks learn the latent alignment between the source and target sequences, and the mechanism of
1Our software and models are available at https:// github.com/hao-cheng/biattdp.
attention over the encoder can be viewed as a soft operation on the memory.",1 Introduction,[0],[0]
"Although already used in the encoder for capturing global context information (Bahdanau et al., 2015), the bi-directional recurrent neural network (RNN) has yet to be employed in the decoder.",1 Introduction,[0],[0]
"Bi-directional decoding is expected to be advantageous over the previously developed uni-directional counterpart, because the former exploits richer contextual information.",1 Introduction,[0],[0]
"Intuitively, we can use two separate uni-directional RNNs where each one constructs its respective attended encoder context vectors for computing RNN hidden states.",1 Introduction,[0],[0]
"However, the drawback of this approach is that the decoder would often produce different alignments resulting in discrepancies for the forward and backward directions.",1 Introduction,[0],[0]
"In this paper, we design a training objective function to enforce attention agreement between both directions, inspired by the alignmentby-agreement idea from Liang et al. (2006).",1 Introduction,[0],[0]
"Specifically, we develop a dependency parser (BiAtt-DP) using a bi-directional attention model based on the memory network.",1 Introduction,[0],[0]
"Given that the golden alignment is observed for dependency parsing in the training stage, we further derive a simple and interpretable approximation for the agreement objective, which makes a natural connection between the latent and observed alignment cases.
",1 Introduction,[0],[0]
The proposed BiAtt-DP parses a sentence in a linear order via sequentially querying the memory component that stores continuous embeddings for all headwords.,1 Introduction,[0],[0]
"In other words, we consider all possible arcs during the parsing.",1 Introduction,[0],[0]
"This formulation is adopted by graph-based parsers such as the MSTParser (McDonald et al., 2005).",1 Introduction,[0],[0]
"The consideration
2204
of all possible arcs makes the proposed BiAtt-DP different from many recently developed neural dependency parsers (Chen and Manning, 2014; Weiss et al., 2015; Alberti et al., 2015; Dyer et al., 2015; Ballesteros et al., 2015), which use a transitionbased algorithm by modeling the parsing procedure as a sequence of actions on buffers.",1 Introduction,[0],[0]
"Moreover, unlike most graph-based parsers which may suffer from high computational complexity when utilizing high-order parsing history (McDonald and Pereira, 2006), the proposed BiAtt-DP can implicitly inject such information into the model while keeping the computational complexity in the order of O(n2) for a sentence with n words.",1 Introduction,[0],[0]
"This is achieved by feeding the RNN in the query component with a soft headword embedding, which is computed as the probability-weighted sum of all headword embeddings in the memory component.
",1 Introduction,[0],[0]
"To the best of our knowledge, this is the first attempt to apply memory network models to graphbased dependency parsing.",1 Introduction,[0],[0]
"Moreover, it is the first extension of neural attention models from unidirection to multi-direction by enforcing agreement on alignments.",1 Introduction,[0],[0]
"Experiments on English, Chinese, and 12 languages from the CoNLL 2006 shared task show the BiAtt-DP can achieve competitive parsing accuracy with several state-of-the-art parsers.",1 Introduction,[0],[0]
"Furthermore, our model achieves the highest unlabeled attachment score (UAS) on Chinese, Czech, Dutch, German, Spanish and Turkish.",1 Introduction,[0],[0]
"The proposed parser first encodes each word in a sentence by continuous embeddings using a bidirectional RNN, and then performs two types of operations, i.e. 1) headword predictions based on bidirectional parsing history and 2) the relation prediction conditioned on the current modifier and its predicted headword both in the embedding space.",2 A MemNet-based Dependency Parser,[0],[0]
"In the following, we first present how the token embeddings are constructed.",2 A MemNet-based Dependency Parser,[0],[0]
"Then, the key components of the proposed parser, i.e. the memory component and the query component, are discussed in detail.",2 A MemNet-based Dependency Parser,[0],[0]
"Lastly, we describe the parsing algorithm using a bidirectional attention model with agreement.",2 A MemNet-based Dependency Parser,[0],[0]
"In the proposed BiAtt-DP, the memory and query components share the same token embeddings.",2.1 Token Embeddings,[0],[0]
"We use the notion of additive token embedding as in (Botha and Blunsom, 2014) to utilize the available information about the token, e.g., its word form, lemma, part-of-speech (POS) tag, and morphological features.",2.1 Token Embeddings,[0],[0]
"Specifically, the token embedding is computed as
Eformeformi + E poseposi + E lemmaelemmai + · · · ,
where ei’s are one-hot encoding vectors for the ith word, and E’s are parameters to be learned that store the continuous embeddings for corresponding feature.",2.1 Token Embeddings,[0],[0]
"Note those one-hot encoding vectors have different dimensions, depending on individual vocabulary sizes, and all E’s have the same first dimension but different second dimension.",2.1 Token Embeddings,[0],[0]
The additive token embeddings allow us to easily integrate a variety of information.,2.1 Token Embeddings,[0],[0]
"Moreover, we only need to make a single decision on the dimensionality of the token embedding, rather than a combination of decisions on word embeddings and POS tag embeddings as in concatenated token embeddings used by Chen and Manning (2014), Dyer et al. (2015) and Weiss et al. (2015).",2.1 Token Embeddings,[0],[0]
"It reduces the number of model parameters to be tuned, especially when lots of different features are used.",2.1 Token Embeddings,[0],[0]
"In our experiments, the word form and fine-grained POS tag are always used, whereas other features are used depending on their availability in the dataset.",2.1 Token Embeddings,[0],[0]
"All singleton words, lemmas, and POS tags are replaced by special tokens.
",2.1 Token Embeddings,[0],[0]
"The additive token embeddings are transformed into another space before they are used by the memory and query components, i.e.
xi = LReL",2.1 Token Embeddings,[0],[0]
"[ P ( Eformeformi + · · · )] ,
where P is the projection matrix and is shared by the memory and query components as well.",2.1 Token Embeddings,[0],[0]
"The activation function of this projection layer is the leaky rectified linear (LReL) function (Mass et al., 2013) with 0.1 as the slope of the negative part.",2.1 Token Embeddings,[0],[0]
"In the remaining part of the paper, we refer to xi ∈",2.1 Token Embeddings,[0],[0]
"Rp as the token embedding for word at position i. Note the subscript i is substituted by j and t for the memory and query components, respectively.",2.1 Token Embeddings,[0],[0]
"As shown in Figure 1, the proposed BiAtt-DP has three components, i.e. a memory component, a leftto-right query component, and a right-to-left query component.",2.2 Components,[0],[0]
"Given a sentence of length n, the parser first uses a bi-directional RNN to construct n + 1 headword embeddings, m0,m1, . . .",2.2 Components,[0],[0]
",mn ∈ Re, with m0 reserved for the ROOT symbol.",2.2 Components,[0],[0]
Each query component is an uni-directional attention model.,2.2 Components,[0],[0]
"In a query component, a sequence of n modifier embeddings q1, . . .",2.2 Components,[0],[0]
",qn ∈ Rd are constructed recursively by conditioning on all headword embeddings.",2.2 Components,[0],[0]
"To address the vanishing gradient issue in RNNs, we use the gated recurrent unit (GRU) proposed by Cho et al. (2014), where an update gate and a reset gate are employed to control the information flow.",2.2 Components,[0],[0]
"We replace the hyperbolic tangent function in GRU with the LReL function, which is faster to compute and achieves better parsing accuracy in our preliminary studies.",2.2 Components,[0],[0]
"In the following, we refer to headword and modifier embeddings as memory and query vectors, respectively.
",2.2 Components,[0],[0]
Memory Component: The proposed BiAtt-DP uses a bi-directional RNN to obtain the memory vectors.,2.2 Components,[0],[0]
"At time step j, the current hidden state vector hlj ∈ Re/2 (or hrj ∈ Re/2) is computed as a non-linear transformation based on the current input vector xj and the previous hidden state vector hlj−1 (or h r j+1), i.e. h l j = GRU(h l j−1,xj) (or hrj = GRU(h r j+1,xj)).",2.2 Components,[0],[0]
"Ideally, the recursive nature of the RNN allows it to capture all context information from one-side, and a bi-directional RNN can thus capture context information from both sides.",2.2 Components,[0],[0]
We concatenate the hidden layers of the left-to-right RNN and the right-to-left RNN for the word at position j as the memory vector mj =,2.2 Components,[0],[0]
[ hlj ;h r j ] .,2.2 Components,[0],[0]
"These memory vectors are expected to encode the words and their context information in the headword space.
",2.2 Components,[0],[0]
Query Component:,2.2 Components,[0],[0]
"For each query component, we use a single-directional RNN with GRU to obtain the query vectors qj’s, which are the hidden state vectors of the RNN.",2.2 Components,[0],[0]
"Each qt is used to query the memory component, returning association scores st,j’s between the word at position t and the head-
word at position j for j ∈ {0, · · · , n}, i.e.
st,j = v",2.2 Components,[0],[0]
"Tφ (Cmj + Dqt) , (1)
",2.2 Components,[0],[0]
"where φ(·) is the element-wise hyperbolic tangent function, and C ∈ Rh×e, D ∈ Rh×d and v ∈",2.2 Components,[0],[0]
Rh are model parameters.,2.2 Components,[0],[0]
"Then, we can obtain probabilities (aka attention weights), at,0, · · · , at,n, over all headwords in the sentence by normalizing st,j’s, using a softmax function
at = softmax(st).",2.2 Components,[0],[0]
"(2)
The soft headword embedding is then defined as m̃t = ∑n j=1 at,jmj .",2.2 Components,[0],[0]
"At each time step t, the
RNN takes the soft headword embedding m̃lt−1 or m̃rt+1 as the input, in addition to the token embedding xt.",2.2 Components,[0],[0]
"Formally, for the forward case, the qt can be computed as qt = GRU (qt−1, [m̃t;xt]).",2.2 Components,[0],[0]
"Although the RNN is able to capture long-span context information to some extent, the local context may very easily dominate the hidden state.",2.2 Components,[0],[0]
"Therefore, this additional soft headword embedding allows the model to access long-span context information in a different channel.",2.2 Components,[0],[0]
"On the other hand, by recursively feeding both the query vector and the soft headword embedding into the RNN, the model implicitly captures high-order parsing history information, which can potentially improve the parsing accuracy (Yamada and Matsumoto, 2003; McDonald and Pereira, 2006).",2.2 Components,[0],[0]
"However, for a graph-based dependency parser, utilizing parsing history features is computationally expensive.",2.2 Components,[0],[0]
"For example, an k-th order MSTParser (McDonald and Pereira, 2006) has O(nk+1) complexity for a sentence of n words.",2.2 Components,[0],[0]
"In contrast, the BiAtt-DP implicitly captures high-order parsing history while keeping the complexity in the order of O(n2), i.e. for each direction.",2.2 Components,[0],[0]
"we compute n(n+1) pair-wise probabilities at,j for t = 1, · · · , n and j = 0, · · · , n.
In this paper, we choose to use soft headword embeddings rather than making hard decisions on headwords.",2.2 Components,[0],[0]
"In the latter case, beam search may potentially improve the parsing accuracy at the cost of higher computational complexity, i.e. O(Bn2) with a beam width of B. When using soft headword embeddings, there is no need to perform beam search.",2.2 Components,[0],[0]
"Moreover, it is straightforward to incorporate parsing history from both directions by using two query components at the cost of O(2n2), which cannot be easily achieved when using beam search.",2.2 Components,[0],[0]
The parsing decision can be made directly based on attention weights from the two query components or further rescored by the maximum spanning tree (MST) search algorithm.,2.2 Components,[0],[0]
"For the bi-directional attention model, the underlying probability distributions alt and a r t may not agree with each other.",2.3 Parsing by Attention with Agreement,[0],[0]
"In order to encourage the agreement, we use the mathematically convenient metric, i.e. the squared Hellinger distance H2 ( alt||art ) , for quantifying the distance between these two distri-
butions.",2.3 Parsing by Attention with Agreement,[0],[0]
"For dependency parsing, when the golden alignment is known during training, we can derive an upper bound on the latent agreement objective as
H2(alt,a r t ) ≤ 2 √ D(gt||alt)",2.3 Parsing by Attention with Agreement,[0],[0]
"+D(gt||art ),
where D(·||·) is the KL-divergence.",2.3 Parsing by Attention with Agreement,[0],[0]
"The complete derivation is provided in the Appendix A. During optimization, we can safely drop the constant scaler and the square root operation in the upper bound, leading to the following loss function
D(gt||alt)",2.3 Parsing by Attention with Agreement,[0],[0]
"+D(gt||art ) = 2D(gt||alt art ), (3)
where indicates element-wise multiplication.",2.3 Parsing by Attention with Agreement,[0],[0]
"The resulting loss function is equivalent to the crossentropy loss, which is widely adopted for training neural networks.
",2.3 Parsing by Attention with Agreement,[0],[0]
"As we can see, the loss function (3) tries to minimize the distance between the golden alignment and the intersection of the two directional attention alignments at every time step.",2.3 Parsing by Attention with Agreement,[0],[0]
"Therefore, during inference, the headword prediction for the word at time step t can be obtained as
argmax j
log alt,j + log a r t,j ,
seeking for agreement between both query components.",2.3 Parsing by Attention with Agreement,[0],[0]
"This parsing procedure is also similar to the exhaustive left-to-right modifier-first search algorithm described in (Covington, 2001), but it is enhanced by an additional right-to-left search with the agreement enforcement.",2.3 Parsing by Attention with Agreement,[0],[0]
"Alternatively, we can treat (log alt,j + log a r t,j) as a score of the corresponding arc and then search for the MST to form a dependency parse tree, as proposed in (McDonald et al., 2005).",2.3 Parsing by Attention with Agreement,[0],[0]
"The MST search is achieved via the ChuLiu-Edmonds algorithm (Chu and Liu, 1965; Edmonds, 1967), which can be implemented in O(n2) for dense graphs according to Tarjan (1977).",2.3 Parsing by Attention with Agreement,[0],[0]
"In practice, the MST search slows down the parsing speed by 6–10%.",2.3 Parsing by Attention with Agreement,[0],[0]
"However, it forces the parser to produce a valid tree, and we observe a slight improvement on parsing accuracy in most cases.
",2.3 Parsing by Attention with Agreement,[0],[0]
"After obtaining each modifier and its soft header embeddings, we use a single-layer perceptron to predict the head-modifier relation, i.e.
yt = softmax ( U [ m̃lt; m̃ r t ] +",2.3 Parsing by Attention with Agreement,[0],[0]
"W [ qlt; q r t ]) , (4)
",2.3 Parsing by Attention with Agreement,[0],[0]
"where yt,1, · · · , yt,m are the probabilities of m possible relations, and U ∈ Rm×2e and W ∈ Rm×2d are model parameters.",2.3 Parsing by Attention with Agreement,[0],[0]
"For the t-th word (modifier) wt in a sentence of length n, let H lt and H r t denote random variables representing the predicted headword from forward (left-to-right) and backward (right-to-left) parsing directions, respectively.",3 Model Learning,[0],[0]
Also let Rt denote the random variable representing the dependency relation for wt.,3 Model Learning,[0],[0]
"The joint probability of headword and relation predictions can be written as
P (R1:n, H l 1:n, H r 1:n|w1:n)
= n∏
t=1
P (Rt|w1:n)P (H lt |w1:n)P (Hrt |w1:n)
= n∏
t=1
ylt,Rt · alt,Hlt · a r t,Hrt
(5)
where at each time step we assume head-modifier relations and headwords from both directions are independent with each other when conditioned on the global knowledge of the whole sentence.",3 Model Learning,[0],[0]
"Note that the long-span context and high-order parsing history information are injected when we model P (H lt |w1:n), P (Hrt |w1:n) and P (Rt|w1:n), as discussed in Section 2.2.
",3 Model Learning,[0],[0]
"As discussed in Section 2.3, the model can be trained by encouraging attention agreement between two query components.",3 Model Learning,[0],[0]
"From (5), we observe that it is equivalent to maximizing the log-likelihood of the golden dependency tree (or minimizing the crossentropy) for each training sentence, i.e.
n∑
t=1
( log yt,relationt + log a l t,headt + log a r t,headt ) ,
where at,j and yt,r are defined in (2) and (4), respectively, and relationt and headt are golden relation and headword labels, respectively.",3 Model Learning,[0],[0]
"The gradients are computed via the back-propagation algorithm (Rumelhart et al., 1986).",3 Model Learning,[0],[0]
"Errors of yt come from the arc labels, whereas there are two source of errors for at, one from the headword labels and the other back-propagated from errors of yt.",3 Model Learning,[0],[0]
"We use stochastic gradient descent with the Adam algorithm proposed in (Kingma and Ba, 2015).",3 Model Learning,[0],[0]
"The
learning rate is halved at each iteration once the loglikelihood of the dev set decreases.",3 Model Learning,[0],[0]
The whole training procedure terminates when the log-likelihood decreases for the second time.,3 Model Learning,[0],[0]
"All learning parameters except bias terms are initialized randomly according to the Gaussian distribution N (0, 10−2).",3 Model Learning,[0],[0]
"In our experiments, we tune the initial learning rate with a step size of 0.0002, and choose the best one based on the log-likelihood on the dev set at the first epoch.",3 Model Learning,[0],[0]
"Empirically, the selected initial learning rates fall in the range of [0.0004, 0.0010] for hidden layer size [128, 320], and tend to be larger when using a smaller hidden layer size, i.e. [0.0016, 0.0034] for hidden layer size around 80.",3 Model Learning,[0],[0]
The training data are randomly shuffled at every epoch.,3 Model Learning,[0],[0]
"In this section, we present the parsing accuracy of the proposed BiAtt-DP on 14 languages.",4 Experiments,[0],[0]
"We report both UAS and labeled attachment score (LAS), obtained by the CoNLL-X eval.pl script2 which ignores punctuation symbols.",4 Experiments,[0],[0]
"The headword predictions are made through the MST search, which slightly improves both UAS and LAS (less than 0.3% absolutely).",4 Experiments,[0],[0]
"Overall, the proposed BiAtt-DP achieves competitive parsing accuracy on all languages as state-of-the-art parsers, and obtains better UAS in 6 languages.",4 Experiments,[0],[0]
We also show the impact of using POS tags and pre-trained word embeddings.,4 Experiments,[0],[0]
"Moreover, different variants of the full model are compared in this section.",4 Experiments,[0],[0]
"We work on the English Treebank-3 (PTB) dataset (Marcus et al., 1999), the Chinese Treebank-5.1 (CTB) dataset (Palmer et al., 2005), and 12 other languages from the CoNLL 2006 shared task (Buchholz and Marsi, 2006).",4.1 Data,[0],[0]
"For PTB and CTB datasets, we use exactly the same setup as in (Chen and Manning, 2014; Dyer et al., 2015).",4.1 Data,[0],[0]
"Specifically, we convert the English and Chinese data using the Stanford parser v3.3.0 (de Marneffe et al., 2006) and the Penn2Malt tool (Zhang and Clark, 2008), respectively.
",4.1 Data,[0],[0]
"For English, POS tags are obtained using the Stanford POS tagger v3.3.0 (Toutanova et al., 2003),
2http://ilk.uvt.nl/conll/software.html
whereas for Chinese, we use gold segmentation and POS tags.",4.1 Data,[0],[0]
"When constructing the token embeddings for English and Chinese, both the word form and the POS tag are used.",4.1 Data,[0],[0]
"We also initialize Eform by pretrained word embeddings3.
",4.1 Data,[0],[0]
"For the 12 other languages, we randomly hold out 5% of the training data as the dev set.",4.1 Data,[0],[0]
"In addition to the word form and find-grained POS tags, we use extra features such as lemmas, coarse-grained POS tags, and morphemes when they are available in the dataset.",4.1 Data,[0],[0]
No pre-trained word embeddings are used for these 12 languages.,4.1 Data,[0],[0]
The hidden layer size is kept the same across all RNNs in the proposed BiAtt-DP.,4.2 Model Configurations,[0],[0]
We also require the dimension of the token embeddings to be the same as the hidden layer size.,4.2 Model Configurations,[0],[0]
"Note that we concatenate the hidden layers of two RNNs for constructing mj , and thus we have e = 2d.",4.2 Model Configurations,[0],[0]
"The weight matrices C and D respectively project vectors mj and qt to the same dimension h, which is equivalent to d. For English and Chinese, since the dimension of pretrained word embeddings are 300, we use 300 × h as the dimension of embedding parameters E’s.",4.2 Model Configurations,[0],[0]
"For the 12 other languages, we use square matrices for the embedding parameters E’s.",4.2 Model Configurations,[0],[0]
"For all languages, We tune the hidden layer size and choose one according to UAS on the dev set.",4.2 Model Configurations,[0],[0]
"The selected hidden layer sizes for these languages are: 368 (English), 114 (Chinese), 128 (Arabic), 160 (Bulgarian), 224 (Czech), 176 (Danish), 220 (Dutch), 200 (German), 128 (Japanese), 168 (Portuguese), 128 (Slovene), 144 (Spanish), 176 (Swedish), and 128 (Turkish).",4.2 Model Configurations,[0],[0]
We first compare our parser with state-of-the-art neural transition-based dependency parsers on PTB and CTB.,4.3 Results,[0],[0]
"For English, we also compare with stateof-the-art graph-based dependency parsers.",4.3 Results,[0],[0]
"The results are shown in Table 1 and Table 2, respectively.",4.3 Results,[0],[0]
It can be seen that the BiAtt-DP outperforms all other graph-based parsers on PTB.,4.3 Results,[0],[0]
"Compared with
3For English, we use the dependency-based word embeddings at https://goo.gl/tWke3I (Levy and Goldberg, 2014).",4.3 Results,[0],[0]
"For Chinese, we pre-train 192-dimension skip-gram embeddings (Mikolov et al., 2013) on Chinese Gigawords (Graff et al., 2005).
",4.3 Results,[0],[0]
"the transition-based parsers, it achieves better accuracy than Chen and Manning (2014), which uses a feed-forward neural network, and Dyer et al. (2015), which uses three stack LSTM networks.",4.3 Results,[0],[0]
"Compared with the integrated parsing and tagging models, the BiAtt-DP outperforms Bohnet and Nivre (2012) but has a small gap to Alberti et al. (2015).",4.3 Results,[0],[0]
"On CTB, it achieves best UAS and similar LAS.",4.3 Results,[0],[0]
"This may be caused by that the relation vocabulary size is relatively smaller than the average sentence length, which biases the joint objective to be more sensitive to UAS.",4.3 Results,[0],[0]
"The parsing speed is around 50–60 sents/sec measured on a desktop with Intel Core i7 CPU @ 3.33GHz using single thread.
",4.3 Results,[0],[0]
"Next, in Table 3 we show the parsing accuracy of the proposed BiAtt-DP on 12 languages in the CoNLL 2006 shared task, including comparison with state-of-the-art parsers.",4.3 Results,[0],[0]
"Specifically, we show UAS of the 3rd-order RBGParser as reported in (Lei et al., 2014) since it also uses low-dimensional continuous embeddings.",4.3 Results,[0],[0]
"However, there are several major differences between the RBGParser and the BiAtt-DP.",4.3 Results,[0],[0]
"First, in (Lei et al., 2014), the lowdimensional continuous embeddings are derived
from low-rank tensors.",4.3 Results,[0],[0]
"Second, the RBGParser uses combined scoring of arcs by including traditional features from the MSTParser (McDonald and Pereira, 2006) /",4.3 Results,[0],[0]
"TurboParser (Martins et al., 2013).",4.3 Results,[0],[0]
"Third, the RBGParser employs a third-order parsing algorithm based on (Zhang et al., 2014), although it also implements a first-order parsing algorithm, which achieves lower UAS in general.",4.3 Results,[0],[0]
"In Table 3, we show that the proposed BiAtt-DP outperforms the RBGParser in most languages except Japanese, Slovene, and Swedish.
",4.3 Results,[0],[0]
It can be observed from Table 3 that the BiAttDP has highly competitive parsing accuracy as stateof-the-art parsers.,4.3 Results,[0],[0]
"Moreover, it achieves best UAS for 5 out of 12 languages.",4.3 Results,[0],[0]
"For the remaining seven languages, the UAS gaps between the BiAtt-DP and state-of-the-art parsers are within 1.0%, except Swedish.",4.3 Results,[0],[0]
"An arguably fair comparison for the BiAttDP is the MSTParser (McDonald and Pereira, 2006), since the BiAtt-DP replaces the scoring function for arcs but uses exactly the same search algorithm.",4.3 Results,[0],[0]
"Due to the space limit, we refer readers to (Lei et al., 2014) for results of the MSTParsers (also shown in Appendix B).",4.3 Results,[0],[0]
"The BiAtt-DP consistently outperforms both parser by up to 5% absolute UAS score.
",4.3 Results,[0],[0]
"Finally, following (Pitler and McDonald, 2015), we also analyze the performance of the BiAtt-DP on both crossed and uncrossed arcs.",4.3 Results,[0],[0]
"Since the BiAtt-
DP uses a graph-based non-projective parsing algorithm, it is interesting to evaluate the performance on crossed arcs, which result in the non-projectivity of the dependency tree.",4.3 Results,[0],[0]
"The last three columns of Table 3 show the recall of crossed arcs, that of uncrossed arcs, and the percentage of crossed arcs in the test set.",4.3 Results,[0],[0]
"Pitler and McDonald (2015) reported numbers on the same data for Dutch, German, Portuguese, and Slovene as in this paper.",4.3 Results,[0],[0]
"For these four languages, the BiAtt-DP achieves better UAS than that reported in (Pitler and McDonald, 2015).",4.3 Results,[0],[0]
"More importantly, we observe that the improvement on recall of crossed arcs (around 10–18% absolutely) is much more significant than that of uncrossed arcs (around 1–3% absolutely), which indicates the effectiveness of the BiAtt-DP in parsing languages with non-projective trees.",4.3 Results,[0],[0]
"Here we try to study the impact of using pre-trained word embeddings, POS tags, as well as the bidirectional query components on our model.",4.4 Ablative Study,[0],[0]
"First of all, we start from our best model (Model 1 in Table 4) on English, which uses 300 as the token embedding dimension and 368 as the hidden layer size.",4.4 Ablative Study,[0],[0]
"We keep those model parameter dimensions unchanged and analyze different factors by comparing the parsing accuracy on PTB dev set.
",4.4 Ablative Study,[0],[0]
The results are summarized in Table 4.,4.4 Ablative Study,[0],[0]
"Comparing Models 1–3, it can be observed that without using pre-trained word embeddings, both UAS and LAS drop by 0.6%, and without using POS tags in token embeddings, the numbers further drop by 1.6% in UAS and around 2.6% in LAS.",4.4 Ablative Study,[0],[0]
"In terms of query components, using single query component (Models 4–5) degrades UAS by 0.7–0.9% and LAS by around 1.0%, compared with Model 2.",4.4 Ablative Study,[0],[0]
"For Model 6, the soft headword embedding is only used for arc label predictions but not fed into the next hidden state, which is around 0.3% worse than Model 2.",4.4 Ablative Study,[0],[0]
This supports the hypothesis about the usefulness of the parsing history information.,4.4 Ablative Study,[0],[0]
We also implement a variant of Model 6 which produces one at instead two by using both qlt and q r t in (1).,4.4 Ablative Study,[0],[0]
"It gets 92.44% UAS and 89.26% LAS, indicating that naively applying a bi-directional RNN may not be enough.",4.4 Ablative Study,[0],[0]
"Neural Dependency Parsing: Recently developed neural dependency parsers are mostly transition-based models, which read words sequentially from a buffer into a stack and incrementally build a parse tree by predicting a sequence of transitions (Yamada and Matsumoto, 2003; Nivre, 2003; Nivre, 2004).",5 Related Work,[0],[0]
"A feed-forward neural network is used in (Chen and Manning, 2014), where they represent the current state with 18 selected elements such as the top words on the stack and buffer.",5 Related Work,[0],[0]
"Each element is encoded by concatenated embeddings of words, POS tags, and arc labels.",5 Related Work,[0],[0]
"Their dependency parser achieves improvement
on both accuracy and parsing speed.",5 Related Work,[0],[0]
Weiss et al. (2015) improve the parser using semi-supervised structured learning and unlabeled data.,5 Related Work,[0],[0]
"The model is extended to integrate parsing and tagging in (Alberti et al., 2015).",5 Related Work,[0],[0]
"On the other hand, Dyer et al. (2015) develop the stack LSTM architecture, which uses three LSTMs to respectively model the sequences of buffer states, stack states, and actions.",5 Related Work,[0],[0]
"Unlike the transition-based formulation, the proposed BiAtt-DP directly predicts the headword and the dependency relation at each time step.",5 Related Work,[0],[0]
"Specifically, there is no explicit representation of actions or headwords in our model.",5 Related Work,[0],[0]
"The model learns to retrieve the most relevant information from the input memory to make decisions on headwords and head-modifier relations.
",5 Related Work,[0],[0]
Graph-based Dependency Parsing:,5 Related Work,[0],[0]
"In addition to the transition-based parsers, another line of research in dependency parsing uses graph-based models.",5 Related Work,[0],[0]
Graph-based parser usually build a dependency tree from a directed graph and learns to scoring the possible arcs.,5 Related Work,[0],[0]
"Due to this nature, nonprojective parsing can be done straightforwardly by most graph-based dependency parsers.",5 Related Work,[0],[0]
"The MSTParser (McDonald et al., 2005) and the TurboParser (Martins et al., 2010) are two examples of graphbased parsers.",5 Related Work,[0],[0]
"The MSTParser formulates the parsing as searching for the MST, whereas the TurboParser performs approximate variational inference over a factor graph.",5 Related Work,[0],[0]
"The RBGParser proposed in (Lei et al., 2014) can also be viewed as a graph-based parser, which scores arcs using low-dimensional continuous features derived from low-rank tensors as well as features used by MSTParser/TurboParser.",5 Related Work,[0],[0]
"It also employs a sampler-based algorithm for parsing (Zhang et al., 2014).
",5 Related Work,[0],[0]
"Neural Attention Model: The proposed BiAttDP is closely related to the memory network (Sukhbaatar et al., 2015) for question answering, as well as the neural attention models for machine translation (Bahdanau et al., 2015) and constituency parsing (Vinyals et al., 2015b).",5 Related Work,[0],[0]
The way we query the memory component and obtain the soft headword embeddings is essentially the attention mechanism.,5 Related Work,[0],[0]
"However, different from the above studies where the alignment information is latent, in dependency parsing, the arc between the modifier and
headword is known during training.",5 Related Work,[0],[0]
"Thus, we can utilize these labels for attention weights.",5 Related Work,[0],[0]
"The similar idea is employed by the pointer network in (Vinyals et al., 2015a), which is used to solve three different combinatorial optimization problems.",5 Related Work,[0],[0]
"In this paper, we develop a bi-directional attention model by encouraging agreement between the latent attention alignments.",6 Conclusion,[0],[0]
"Through a simple and interpretable approximation, we make the connection between latent and observed alignments for training the model.",6 Conclusion,[0],[0]
We apply the bi-directional attention model incorporating the agreement objective during training to the proposed memory-network-based dependency parser.,6 Conclusion,[0],[0]
"The resulting parser is able to implicitly capture the high-order parsing history without suffering from issue of high computational complexity for graph-based dependency parsing.
",6 Conclusion,[0],[0]
We have carried out empirical studies over 14 languages.,6 Conclusion,[0],[0]
The parsing accuracy of the proposed model is highly competitive with state-of-the-art dependency parsers.,6 Conclusion,[0],[0]
"For English, the proposed BiAttDP outperforms all graph-based parsers.",6 Conclusion,[0],[0]
"It also achieves state-of-the-art performance in 6 languages in terms of UAS, demonstrating the effectiveness of the proposed mechanism of bi-directional attention with agreement and its use in dependency parsing.
",6 Conclusion,[0],[0]
"A Upper Bound on H2(p,q)
",6 Conclusion,[0],[0]
"Here, we use the following definition of squared Hellinger distance for countable space
H2(p,q) = 1
2
∑
i
( √ pi − √ qi) 2
where p,q ∈ ∆k are two k-simplexes.",6 Conclusion,[0],[0]
"Introducing g ∈ ∆k, the squared Hellinger distance can be upper bounded as
H2(p,q) ≤ √ 2H(p,q) (6)
≤",6 Conclusion,[0],[0]
√ 2,6 Conclusion,[0],[0]
"[H(p,g)",6 Conclusion,[0],[0]
"+H(q,g)]",6 Conclusion,[0],[0]
"(7) ≤ 2 √ H2(p,g) +H2(q,g) (8)
where (6), (7) and (8) follow the inequalities between the `1-norm and the `2-norm, the triangle
inequality defined for a metric, and the CauchySchwarz’s inequality, respectively.",6 Conclusion,[0],[0]
"Using the relationship between the KL-divergence and the squared Hellinger distance, (8) can be further bounded by
2 √ D(g||p)",6 Conclusion,[0],[0]
+D(g||q).,6 Conclusion,[0],[0]
"We develop a novel bi-directional attention model for dependency parsing, which learns to agree on headword predictions from the forward and backward parsing directions.",abstractText,[0],[0]
The parsing procedure for each direction is formulated as sequentially querying the memory component that stores continuous headword embeddings.,abstractText,[0],[0]
"The proposed parser makes use of soft headword embeddings, allowing the model to implicitly capture high-order parsing history without dramatically increasing the computational complexity.",abstractText,[0],[0]
"We conduct experiments on English, Chinese, and 12 other languages from the CoNLL 2006 shared task, showing that the proposed model achieves state-of-the-art unlabeled attachment scores on 6 languages.1",abstractText,[0],[0]
Bi-directional Attention with Agreement for Dependency Parsing,title,[0],[0]
"Learning from time-series data is of paramount importance for prediction, anomaly detection, classification, and other critical tasks that appear in business and society.",1. Introduction,[0],[0]
Various models of time-series have been studied in the literature to better learn from time-series data.,1. Introduction,[0],[0]
"These include vector autoregressive (VAR) models (Lütkepohl, 2005), hidden Markov models (HMM) (Baum & Petrie, 1966), and recurrent neural networks (RNN) (Rumelhart et al., 1986), including long short term memory (LSTM) (Hochreiter & Schmidhuber, 1997) and echo state networks (ESN) (Jaeger & Haas, 2004).",1. Introduction,[0],[0]
"With these models of time-series, one seeks to learn the relation between past values and future values.
",1. Introduction,[0],[0]
"In some of these models of time-series, hidden units (or latent variables) play essential roles in taking into account long term dependency or non-linearity in time-series.",1. Introduction,[0],[0]
"Hid-
1IBM Research - Tokyo, Tokyo, Japan.",1. Introduction,[0],[0]
"Correspondence to: Takayuki Osogami <osogami@jp.ibm.com>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"den units, however, make it difficult to learn the parameters of those models.",1. Introduction,[0],[0]
"For example, the Baum-Welch algorithm (Baum & Petrie, 1966) learns the parameters of an HMM by iteration of expectation and maximization (i.e., an EM algorithm).",1. Introduction,[0],[0]
"An RNN, including LSTM, is trained via back propagation through time (Rumelhart et al., 1986).",1. Introduction,[0],[0]
"These algorithms are time-consuming and do not necessarily find optimal values of the parameters.
",1. Introduction,[0],[0]
This difficulty in learning a model with hidden units partly stems from the fact that the values of hidden units can only be reliably estimated after observing future values of target time-series.,1. Introduction,[0],[0]
It then requires iteration or back propagation to learn the relation between the hidden values and preceding values.,1. Introduction,[0],[0]
"An ESN, on the other hand, gives up learning the hard-to-learn parameters between hidden values and preceding (visible or hidden) values and set those parameters randomly.",1. Introduction,[0],[0]
"The ESN only learns the relation between visible values and preceding (hidden) values (Jaeger & Haas, 2004).
",1. Introduction,[0],[0]
We study a model of time-series whose parameters can be represented as a matrix M or a set of such matrices.,1. Introduction,[0],[0]
"An element Mi,j of the matrix may, for example, represent the weight between a past value of a unit i and a future value of a unit j. In a VAR model, each matrix corresponds to the coefficients for a particular lag.",1. Introduction,[0],[0]
"In an RNN, a matrix corresponds to the weight between hidden units.",1. Introduction,[0],[0]
"We consider a situation where it is hard to estimate an appropriate value of Mi,j for some of the units j ∈ H (in particular, H may denote the set of hidden units).
",1. Introduction,[0],[0]
"We propose a method of training a time-series model with hidden units in a bidirectional manner, one from the past and the other from the future.",1. Introduction,[0],[0]
"From a time-series model with parameter M, we construct a backward model, whose parameters are represented by the transposed matrix M> or a set of such transposed matrices.",1. Introduction,[0],[0]
"The (i, j)-th element of M> is Mj,i, which represents the weight between a preceding value of a unit j and a succeeding value of a unit i.",1. Introduction,[0],[0]
Our key idea is to let the preceding value represent a future value and the succeeding value represent a past value in the backward model.,1. Introduction,[0],[0]
"Then an intuitive meaning of Mj,i in the backward model matches that in the original (forward) model.",1. Introduction,[0],[0]
We use a common matrix M both in the forward model and in the backward model.,1. Introduction,[0],[0]
"Namely, the parameters are shared between the two models.
",1. Introduction,[0],[0]
"The two models have an identical structure and trained in an identical manner with a stochastic gradient method (Bottou, 2009) except that we train the forward model using timeseries in a standard (forward) manner and the backward model using the time-series from the future to the past.",1. Introduction,[0],[0]
We alternately train the forward model to learn M and the backward model to learn M>.,1. Introduction,[0],[0]
An advantage of our bidirectional training is that the elements of M that are hard to estimate differ between when we train the forward model and when we train the backward model.,1. Introduction,[0],[0]
"For the forward model, it is hard to estimate Mi,j for j ∈ H (i.e., M:,H).",1. Introduction,[0],[0]
"For the backward model, it is hard to estimate Mj,i for j ∈ H (i.e., MH,: = (M
>):,H).",1. Introduction,[0],[0]
"Although MH,H is hard to estimate for both models, the other elements of M can be reliably estimated in either of the two models.",1. Introduction,[0],[0]
"This idea of bidirectional training for learning time-series models with hidden units constitutes our first contribution.
",1. Introduction,[0],[0]
"Here, we extend a Dynamic Boltzmann Machine (DyBM) to incorporate hidden units and apply bidirectional training to learn its parameters.",1. Introduction,[0],[0]
The DyBM has been proposed by Osogami & Otsuka (2015a;b) and subsequently studied by Dasgupta et al. (2016); Dasgupta & Osogami (2017); Kajino (2017).,1. Introduction,[0],[0]
The prior work on the DyBM does not consider hidden units but instead uses various features of past values to capture the long term dependency in time-series.,1. Introduction,[0],[0]
"For example, Dasgupta & Osogami (2017) use an ESN to create nonlinear features of past values.",1. Introduction,[0],[0]
"In our context, these features are fed into visible units of a DyBM.",1. Introduction,[0],[0]
"In particular, what features of past values are used is determined randomly without learning.",1. Introduction,[0],[0]
Our analysis of the DyBM with hidden units illuminates the difficulty of learning some of its parameters.,1. Introduction,[0],[0]
"With bidirectional learning, we seek to learn the weight from the past visible values to the future hidden values, which corresponds to learning what features of past values are effective for prediction.",1. Introduction,[0],[0]
"The DyBM with hidden units and its analysis constitute our second contribution.
",1. Introduction,[0],[0]
We validate the effectiveness of bidirectional training and the hidden units in DyBMs through numerical experiments using synthetic and real time-series.,1. Introduction,[0],[0]
We will show that the DyBM with hidden units can be trained more effectively with bidirectional training and reduces the predictive error by up to 90 %.,1. Introduction,[0],[0]
"Our bidirectional training is related to but different from bidirectional recurrent neural networks (BRNN) (Schuster & Paliwal, 1997; Baldi et al., 1999), including bidirectional LSTM (Graves & Schmidhuber, 2005; Chen & Chaudhari, 2005).",1.1. Related Work,[0],[0]
"Similar to our bidirectional training, a BRNN trains both a forward model and a backward model.",1.1. Related Work,[0],[0]
"These two models, however, do not share parameters, contrary to our bidirectional training.",1.1. Related Work,[0],[0]
"In fact, motivation and purpose of the
BRNN are quite different from ours.",1.1. Related Work,[0],[0]
The BRNN uses both the sequence from the past and the sequence from the future to better estimate missing values.,1.1. Related Work,[0],[0]
The BRNN thus needs both of the two sequences for learning and for prediction.,1.1. Related Work,[0],[0]
"On the other hand, our bidirectional training uses both a forward sequence and a backward sequence at the time of learning, but the trained model uses only the sequence from the past to predict future unseen values.",1.1. Related Work,[0],[0]
"Namely, our bidirectional training is used to learn a model for predicting future values from past values, while the BRNN is used for estimating missing values from past and future values.
",1.1. Related Work,[0],[0]
Our bidirectional training is also related to but different from Forward Backward Lasso Granger (FBLG) by Cheng et al. (2014).,1.1. Related Work,[0],[0]
"In FBLG, forward and backward VAR models are estimated with Lasso, and an averaged model is used to infer the Granger causality.",1.1. Related Work,[0],[0]
"The VAR models in FBLG do not have hidden units, while our bidirectional training is motivated by the need for training time-series models with hidden units.",1.1. Related Work,[0],[0]
"Winkler et al. (2016) also study a backward VAR in the context of the Granger causality but do not consider hidden units.
",1.1. Related Work,[0],[0]
"Another related work is structure learning of a VAR model (Bahadori et al., 2013) or a simpler linear dynamical system (Jalali & Sanghavi, 2012) that takes into account the existence of unobserved (or latent) variables.",1.1. Related Work,[0],[0]
"However, their goal is to reliably estimate the structure of the relation between observable variables by taking into account the unobserved variables.",1.1. Related Work,[0],[0]
"This is in contrast to the purpose of our bidirectional training, which aims at learning the relation between visible units and hidden units.",1.1. Related Work,[0],[0]
We study a particularly structured Boltzmann machine for time-series (see Figure 1).,2. DyBM with Hidden Units,[0],[0]
"Corresponding to a segment of a time-series of length T + 1, the Boltzmann machine in Figure 1 has T + 1 layers in the horizontal (temporal) direction.",2. DyBM with Hidden Units,[0],[0]
Each layer corresponds to a time t−δ for 0 ≤ δ ≤ T .,2. DyBM with Hidden Units,[0],[0]
"Each layer has two parts, hidden and visible.",2. DyBM with Hidden Units,[0],[0]
The visible part x[t−δ] at the δ-th layer represents the values of the timeseries at time t − δ.,2. DyBM with Hidden Units,[0],[0]
The hidden part h[t−δ] represents the values of hidden units at time t,2. DyBM with Hidden Units,[0],[0]
− δ.,2. DyBM with Hidden Units,[0],[0]
"Here, units within each layer do not have connections to each other.",2. DyBM with Hidden Units,[0],[0]
We let x[<t] ≡,2. DyBM with Hidden Units,[0],[0]
"(x[s])t−T≤s<t and define h[<t] analogously.
",2. DyBM with Hidden Units,[0],[0]
"The Boltzmann machine in Figure 1 has bias parameter b and weight parameter (U, V, W, Z).",2. DyBM with Hidden Units,[0],[0]
"Let θ ≡ (V,W,b) be the parameters connected to visible units x[t] (from the units in the past, x[s] or h[s] for s < t) and φ ≡ (U,Z).",2. DyBM with Hidden Units,[0],[0]
"The energy of this Boltzmann machine is given as follows:
Eθ,φ(x",2. DyBM with Hidden Units,[0],[0]
"[t],h[t]|x[<t],h[<t])
= Eθ(x",2. DyBM with Hidden Units,[0],[0]
"[t]|x[<t],h[<t]) +",2. DyBM with Hidden Units,[0],[0]
"Eφ(h[t]|x[<t],h[<t]), (1)
where we define
Eθ(x",2. DyBM with Hidden Units,[0],[0]
"[t]|x[<t],h[<t]) (2)
= −b>x[t] − T∑ δ=1 (x[t−δ])>W[δ] x[t] − T∑ δ=1 (h[t−δ])>V[δ] x[t]
and define Eφ(h[t]|x[<t],h[<t]) from (2) by letting W ← U, V← Z, b← 0, and x[t] ← h[h].
Similar to the DyBM in Osogami & Otsuka (2015a), we study the case where W ≡ (W[δ])1≤δ≤T and other matrices have the following parametric forms for δ ≥ d:
W[δ] = λδ−dW[d], V[δ] = λδ−dV[d], (3)
Z[δ] = λδ−d Z[d], U[δ] = λδ−dU[d], (4)
where λ is a decay rate satisfying 0 ≤ λ < 1.",2. DyBM with Hidden Units,[0],[0]
"Then, in the limit of T → ∞, the energy in (2) can be represented as follows (and Eφ(h[t]|x[<t],h[<t]) has an analogous limit shown in (37) of the supplementary material):
",2. DyBM with Hidden Units,[0],[0]
Eθ(x,2. DyBM with Hidden Units,[0],[0]
"[t]|x[<t],h[<t])
= −b>x[t] − d−1∑ δ=1 (x[t−δ])>W[δ] x[t]",2. DyBM with Hidden Units,[0],[0]
"− d−1∑ δ=1 (h[t−δ])>V[δ] x[t]
− (α[t−1])>W[d] x[t] − (β[t−1])>V[d] x[t], (5)
where α[t−1] is referred to as an eligibility trace in Osogami & Otsuka (2015a) and defined as follows (here, we define an eligibility trace β[t−1] for the hidden part analogously): α[t−1] ≡ ∞∑ δ=d λδ−d x[t−δ], β[t−1] ≡ ∞∑ δ=d λδ−d h[t−δ].",2. DyBM with Hidden Units,[0],[0]
"(6)
The energy in (5) gives the conditional probability distribution over x[t] given x[<t] and h[<t].",2. DyBM with Hidden Units,[0],[0]
"For binary-valued time-series, we have
pθ(x",2. DyBM with Hidden Units,[0],[0]
"[t]|x[<t],h[<t]) = 1
Z exp(−Eθ(x[t]|x[<t],h[<t]))",2. DyBM with Hidden Units,[0],[0]
"(7)
for any binary vector x[t], where Z is the normalization factor for the probabilities to sum up to one.",2. DyBM with Hidden Units,[0],[0]
"Due to the structure in Figure 1, the values in x[t] = (x[t]i )i=1,2,... are conditionally independent of each other given x[<t] and h[<t], so that we can represent
pθ(x",2. DyBM with Hidden Units,[0],[0]
"[t]|x[<t],h[<t]) = ∏ i=1,2,... pθ,i(x [t] i |x",2. DyBM with Hidden Units,[0],[0]
"[<t],h[<t]), (8)
where the conditional probability pi(x",2. DyBM with Hidden Units,[0],[0]
"[t] i |x[<t],h[<t]) is defined with the energy associated with unit i (see Osogami & Otsuka (2015a)).",2. DyBM with Hidden Units,[0],[0]
"For real-valued time-series, one can define the conditional density pi(x [t] i |x[<t],h[<t]) with a Gaussian distribution whose mean is given from the energy associated with unit i (Dasgupta & Osogami, 2017; Osogami, 2016).",2. DyBM with Hidden Units,[0],[0]
Conditional distributions can be defined analogously for h[t] (see (40)–(42) and (51) in the supplementary material).,2. DyBM with Hidden Units,[0],[0]
"Here, we derive a learning rule for θ.",3. Training a DyBM with Hidden Units,[0],[0]
"We will also see that φ cannot be trained in an analogous manner.
",3. Training a DyBM with Hidden Units,[0],[0]
"Our DyBM with binary hidden units gives the probability of a time-series, x ≡ (x[t])t=`,...,u, by
pθ,φ(x) = ∑ h̃ pφ(h̃|x) u∏ t=` pθ(x",3. Training a DyBM with Hidden Units,[0],[0]
"[t]|x[<t], h̃[<t]) (9)
where ∑
h̃ denotes the summation over all of the possible values of hidden units from time t = ` to t = u, and
pφ(h̃|x) ≡",3. Training a DyBM with Hidden Units,[0],[0]
u∏ s=` pφ(h̃,3. Training a DyBM with Hidden Units,[0],[0]
"[s]|x[<s], h̃[<s]), (10)
",3. Training a DyBM with Hidden Units,[0],[0]
"where pφ(h̃[s]|x[<s], h̃[<s]) is defined analogously to (7)– (8) and provided in (36) of the supplementary material, and we arbitrarily define x[s] = 0 and h̃[s] = 0 for s < `.
We seek to maximize the log likelihood of a given x by maximizing a lower bound given by Jensen’s inequality:
log pθ,φ(x) = log (∑
h̃
pφ(h̃|x) u∏ t=` pθ(x [t]|x[<t], h̃[<t]) )",3. Training a DyBM with Hidden Units,[0],[0]
"(11)
≥ ∑ h̃ pφ(h̃|x) log ( u∏ t=` pθ(x [t]|x[<t], h̃[<t]) )",3. Training a DyBM with Hidden Units,[0],[0]
"(12)
= ∑ h̃ pφ(h̃|x) u∑ t=` log pθ(x",3. Training a DyBM with Hidden Units,[0],[0]
"[t]|x[<t], h̃[<t]) (13)
= u∑ t=` ∑ h̃[<t]",3. Training a DyBM with Hidden Units,[0],[0]
pφ(h̃,3. Training a DyBM with Hidden Units,[0],[0]
"[<t]|x[<t−1]) log pθ(x[t]|x[<t], h̃[<t])
≡",3. Training a DyBM with Hidden Units,[0],[0]
"Lθ,φ(x), (14)
where the summation with respect to h̃[<t] is over all of the possible values of h̃[s] for s ≤ t− 1, and
pφ(h̃",3. Training a DyBM with Hidden Units,[0],[0]
[<t]|x[<t−1]) ≡,3. Training a DyBM with Hidden Units,[0],[0]
t−1∏ s=` pφ(h̃,3. Training a DyBM with Hidden Units,[0],[0]
"[s]|x[<s], h̃[<s]).",3. Training a DyBM with Hidden Units,[0],[0]
"(15)
The gradient of the lower bound with respect to θ is:
∇θLθ,φ(x) (16)
= u∑ t=` ∑ h̃[<t] pφ(h̃",3. Training a DyBM with Hidden Units,[0],[0]
"[<t]|x[<t−1])∇θ log pθ(x[t]|x[<t], h̃[<t]).
",3. Training a DyBM with Hidden Units,[0],[0]
"The right-hand side of (16) is a summation of expected gradients, which suggests a method of stochastic gradient.",3. Training a DyBM with Hidden Units,[0],[0]
"Namely, at each step t, we sample h[t−1] according to pφ(h",3. Training a DyBM with Hidden Units,[0],[0]
"[t−1]|x[<t−1],h[<t−1]) and update θ on the basis of
∇θ log pθ(x[t]|x[<t],h[<t]).",3. Training a DyBM with Hidden Units,[0],[0]
"(17)
",3. Training a DyBM with Hidden Units,[0],[0]
"This learning rule is equivalent to the one for the model where all of the units are visible, except that the values for the hidden units are given by sampled values.
",3. Training a DyBM with Hidden Units,[0],[0]
"Therefore, the learning rule for θ follows directly from Osogami & Otsuka (2015a):
b← b+ η (x[t]",3. Training a DyBM with Hidden Units,[0],[0]
− 〈X[t]〉θ) (18) W[d] ←W[d] + ηα[t−1] (x[t] − 〈X[t]〉θ)> (19) V[d] ← V[d] + η β[t−1] (x[t] − 〈X[t]〉θ)> (20) W[δ] ←W[δ] + η x[t−δ] (x[t],3. Training a DyBM with Hidden Units,[0],[0]
− 〈X[t]〉θ)> (21) V[δ] ← V[δ] + η h[t−δ] (x[t] − 〈X[t]〉θ)>,3. Training a DyBM with Hidden Units,[0],[0]
"(22)
for 1 ≤ δ <",3. Training a DyBM with Hidden Units,[0],[0]
"d, where 〈X[t]〉θ denotes the expected values of x[t] with respect to pθ in (7).
",3. Training a DyBM with Hidden Units,[0],[0]
"Now we take the gradient of Lθ,φ(x) with respect to φ:
∇φLθ,φ(x) (23)
= u∑ t=` ∑ h̃[<t] ∇φpφ(h̃[<t]|x[<t−1]) log pθ(x[t]|x[<t], h̃[<t]),
where
∇φpφ(h̃[<t]|x[<t−1])
= ∇φ t−1∏ s=` pφ(h̃",3. Training a DyBM with Hidden Units,[0],[0]
"[s]|x[<s], h̃[<s]) (24)
= t−1∑ s=` ∇φ log pφ(h̃[s]|x[<s], h̃[<s])",3. Training a DyBM with Hidden Units,[0],[0]
t−1∏ s′=` pφ(h̃,3. Training a DyBM with Hidden Units,[0],[0]
"[s′]|x[<s ′], h̃[<s ′])
= pφ(h̃",3. Training a DyBM with Hidden Units,[0],[0]
"[<t]|x[<t−1]) t−1∑ s=` ∇φ log pφ(h̃[s]|x[<s], h̃[<s]).",3. Training a DyBM with Hidden Units,[0],[0]
"(25)
Plugging (25) into the right-hand side of (23), we obtain
∇φLθ,φ(x)
= u∑ t=` ∑ h̃[<t] pφ(h̃",3. Training a DyBM with Hidden Units,[0],[0]
"[<t]|x[<t−1]) log pθ(x[t]|x[<t], h̃[<t])
t−1∑ s=` ∇φ log pφ(h̃[s]|x[<s], h̃[<s]).",3. Training a DyBM with Hidden Units,[0],[0]
"(26)
Similar to (16), the expression of (26) suggests a method of stochastic gradient: at each time t, we sample h[t−1] according to pφ(h[t−1]|x[<t−1],h[<t−1]) and update φ on the basis of the following stochastic gradient:
log pθ(x",3. Training a DyBM with Hidden Units,[0],[0]
"[t]|x[<t],h[<t])Gt−1, (27)
where
Gt−1 ≡ t−1∑ s=` ∇φ log pφ(h[s]|x[<s],h[<s]).",3. Training a DyBM with Hidden Units,[0],[0]
"(28)
Computation of (26) involves mainly two interrelated inefficiencies.",3. Training a DyBM with Hidden Units,[0],[0]
"First, although (26) can be approximately computed using sampled hidden values h̃[<t] in the same way as (16), the samples cannot be reused after updating φ because it was sampled from the distribution with the previous parameter.",3. Training a DyBM with Hidden Units,[0],[0]
"Second, since each summand of Gt−1 is dependent on φ, Gt−1 also has to be recomputed after each update.",3. Training a DyBM with Hidden Units,[0],[0]
"Thus, the computational complexity of (27) grows linearly with respect to the length of the time-series (i.e., t− `), in contrast to (17), whose complexity is independent of that length.",3. Training a DyBM with Hidden Units,[0],[0]
"One could approximately compute (28) recursively:
",3. Training a DyBM with Hidden Units,[0],[0]
"Gt ← γ Gt−1 + (1− γ)∇φ log pφ(h[t]|x[<t],h[<t]), (29)
",3. Training a DyBM with Hidden Units,[0],[0]
where γ ∈,3. Training a DyBM with Hidden Units,[0],[0]
"[0, 1) is a discount factor.",3. Training a DyBM with Hidden Units,[0],[0]
"The recursive update rule with γ < 1 puts exponentially small weight γt−s on ∇φ log pφ(h[s]|x[<s],h[<s]) computed with an old value of φ (i.e., s t).",3. Training a DyBM with Hidden Units,[0],[0]
"This recursively computed Gt is related to the momentum in gradient descent (Qian, 1999).",3. Training a DyBM with Hidden Units,[0],[0]
"See the supplementary material for specific learning rules suggested by (27)–(29).
",3. Training a DyBM with Hidden Units,[0],[0]
"Observe in (26) that ∇φLθ,φ(x) consists of the products of log pθ(x[t]|x[<t],h[<t]) and ∇φ log pφ(h[s]|x[<s],h[<s]) for s < t.",3. Training a DyBM with Hidden Units,[0],[0]
"Without the dependency on log pθ(x
[t]|x[<t],h[<t]), the parameter φ is updated in a way that h[s] is more likely to be generated (i.e., the learning rule would be equivalent to that for visible units).",3. Training a DyBM with Hidden Units,[0],[0]
"Such an update rule is undesirable, because h[s] has been sampled and is not necessarily what we want to sample again.",3. Training a DyBM with Hidden Units,[0],[0]
"The dependency on log pθ(x[t]|x[<t],h[<t]) suggests that φ is updated by a large amount if the sampled h[s] happens to make the future values, x[t] for t > s, likely.",3. Training a DyBM with Hidden Units,[0],[0]
"Intuitively, weighting ∇φ log pφ(h[s]|x[<s],h[<s]) by log pθ(x[t]|x[<t],h[<t]) for t > s is inevitable, because whether the particular values of hidden units are good for the purpose of predicting future values will only be known after seeing future values.",3. Training a DyBM with Hidden Units,[0],[0]
"Because the stochastic gradient for φ requires approximations that are not needed for θ, we might not be able to learn appropriate values of φ as effectively as θ.",4. Learning with Reversed Time-series,[0],[0]
"This motivates us to consider a backward DyBM in Figure 2, which has a common set of parameters, (θ, φ), as the forward DyBM in Figure 1 but defines the conditional distribution for time-series from the future.",4. Learning with Reversed Time-series,[0],[0]
"Specifically, the energy of the backward DyBM is represented analogously to (1) with the superscript",4. Learning with Reversed Time-series,[0],[0]
"[< t] replaced by [> t], where we define
Eθ(x",4. Learning with Reversed Time-series,[0],[0]
"[t]|x[>t],h[>t]) = −b>x[t] − T∑ δ=1 (x[t+δ])>(W[δ])>x[t]
− T∑ δ=1 (x[t+δ])>(U[δ])>h[t] (30)
and Eφ(h[t]|x[>t],h[>t]) is defined from (30) by letting W ← V, U ← Z, b ← 0, and x[t] ← h[t].",4. Learning with Reversed Time-series,[0],[0]
"Similar to the forward DyBM, we assume that the weight has the parametric form of (4) and let T →∞.
Namely, the backward DyBM is obtained from the forward DyBM by the following changes: W ← W>, Z ← Z>, U← V>, and V← U>.",4. Learning with Reversed Time-series,[0],[0]
"The other difference between (2) and (30) is the sign of δ, but this is because the backward DyBM deals with time-series from the future.
",4. Learning with Reversed Time-series,[0],[0]
"Because the backward DyBM has the structure that is equivalent to that of the forward DyBM, it can be trained in
the same manner as the forward DyBM but using timeseries from the future.",4. Learning with Reversed Time-series,[0],[0]
"Specifically, θ′ ≡ (U>,W>,b) in the backward DyBM is optimized analogously to θ in the forward DyBM.",4. Learning with Reversed Time-series,[0],[0]
"Likewise, φ′ ≡",4. Learning with Reversed Time-series,[0],[0]
"(V>,Z>) is optimized analogously to φ.",4. Learning with Reversed Time-series,[0],[0]
"Recall that φ and φ′ are relatively hard to optimize, and θ and θ′ are relatively easy to optimize.
",4. Learning with Reversed Time-series,[0],[0]
"Our key observation is that the parameter U, which is in φ and is relatively hard to optimize in the forward DyBM, is in θ′ and is relatively easy to optimize in the backward DyBM.",4. Learning with Reversed Time-series,[0],[0]
"By training both the forward DyBM and the backward DyBM, we expect to effectively find appropriate values of θ and θ′.
Consider a stochastic process X(t) whose distribution is given by a forward DyBM.",4. Learning with Reversed Time-series,[0],[0]
We remark that the distribution of the stochastic process X(−t) that is defined by reversing X(t) is generally different from what the corresponding backward DyBM gives unless the DyBMs have no hidden units.,4. Learning with Reversed Time-series,[0],[0]
"The exact distribution of X(−t) needs to be given by marginalizing out the past values (i.e., succeeding values for the backward process).",4. Learning with Reversed Time-series,[0],[0]
"Despite this discrepancy, we expect that bidirectional training is effective because of intuitive correspondence between the forward DyBM and the backward DyBM.",4. Learning with Reversed Time-series,[0],[0]
"In particular, W [δ]i,j in both DyBMs represent the strength of the correlation between the past value of unit i and the future value of unit j, where the time is separated by δ.",4. Learning with Reversed Time-series,[0],[0]
"A recommendation is, however, to perform backward training more moderately than forward training.",4. Learning with Reversed Time-series,[0],[0]
We will show an example of a specific procedure in the next section.,4. Learning with Reversed Time-series,[0],[0]
We now demonstrate the effectiveness of bidirectional training through numerical experiments in two settings.,5. Numerical Experiments,[0],[0]
The purpose of the first setting is to study whether bidirectional learning of the DyBM with hidden units can indeed learn to predict what cannot be done without bidirectional learning or hidden units.,5. Numerical Experiments,[0],[0]
We use a synthetic dataset that is designed specifically for this purpose.,5. Numerical Experiments,[0],[0]
"In the second setting, we study the effectiveness of bidirectional learning and hidden units on real datasets.",5. Numerical Experiments,[0],[0]
"We use the two datasets that have been used in Dasgupta & Osogami (2017) as well as a 391 dimensional time-series, which is substantially larger than the eight or lower dimensional time-series that are used in the other experiments.",5. Numerical Experiments,[0],[0]
The experiments are carried out with a Python implementation on workstations having 48-64 GB memory and 2.6-4.0 GHz CPU.,5. Numerical Experiments,[0],[0]
"For each dataset, we train a DyBM with or without hidden units.",5.1. Specific Learning Algorithms to Evaluate,[0],[0]
"Because all of the datasets are real valued, visible units are Gaussian and give predictions by (5) with x[t] omit-
Algorithm 1 Specific steps of bidirectional learning evaluated in experiments T :",5.1. Specific Learning Algorithms to Evaluate,[0],[0]
"The total number of iterations T0: The number of iterations of bidirectional learning F : The relative frequency of forward learning for t = 1 to T do
if t < T0 and t mod F + 1 = 0",5.1. Specific Learning Algorithms to Evaluate,[0],[0]
"then Backward learning to update (U,W,b) else Forward learning to update (V,W,b)
end if end for
ted (see (52) in the supplementary material).",5.1. Specific Learning Algorithms to Evaluate,[0],[0]
"To reduce the variability in the experiments, we use the expected value for the output of a hidden unit instead of sampling a binary value.",5.1. Specific Learning Algorithms to Evaluate,[0],[0]
"By the law of large numbers, the use of expected value corresponds to having an infinitely many binary hidden units that are conditionally independent and identically distributed (i.i.d.)",5.1. Specific Learning Algorithms to Evaluate,[0],[0]
given the internal state of the DyBM.,5.1. Specific Learning Algorithms to Evaluate,[0],[0]
"See also (Sutskever et al., 2008; Sutskever & Hinton, 2007) for the related use of the expected values for hidden units.
",5.1. Specific Learning Algorithms to Evaluate,[0],[0]
A DyBM with hidden unit is trained bidirectionally or only with forward learning.,5.1. Specific Learning Algorithms to Evaluate,[0],[0]
A DyBM without hidden units is trained only with forward learning.,5.1. Specific Learning Algorithms to Evaluate,[0],[0]
"While bidirectional learning has several design choices, here we evaluate the specific algorithm shown in Algorithm 1.",5.1. Specific Learning Algorithms to Evaluate,[0],[0]
"In particular, we perform bidirectional learning for the first T0 iterations, where the backward training is apply every F +1 steps.",5.1. Specific Learning Algorithms to Evaluate,[0],[0]
"For the rest of T − T0 iterations, we perform forward learning only.",5.1. Specific Learning Algorithms to Evaluate,[0],[0]
Throughout we set F = 2.,5.1. Specific Learning Algorithms to Evaluate,[0],[0]
Note that Z is fixed with its initial values throughout learning.,5.1. Specific Learning Algorithms to Evaluate,[0],[0]
Here we do not update U in forward learning and V in backward learning.,5.1. Specific Learning Algorithms to Evaluate,[0],[0]
"This is partly because the learning rule of (27)-(28) has no effect when we use the expected values in hidden units.
",5.1. Specific Learning Algorithms to Evaluate,[0],[0]
"Before applying Algorithm 1, the bias b is initialized to zero, and the weight (U, V, W, Z) is initialized with i.i.d. normal random variable with mean 0 and standard deviation of 0.01 (Hinton, 2012) except the following two changes.",5.1. Specific Learning Algorithms to Evaluate,[0],[0]
"First, we set the mean of W[1] as an identity matrix for real datasets, because using the previous value for prediction is clearly beneficial for these datasets.",5.1. Specific Learning Algorithms to Evaluate,[0],[0]
"Second, we use the small standard deviation of 0.001 for the large dataset of 391 dimensions for faster convergence.",5.1. Specific Learning Algorithms to Evaluate,[0],[0]
"The learning rate is adjusted according to AdaGrad (Duchi et al., 2011), where the the initial learning rate is optimized as we discuss in the following.
",5.1. Specific Learning Algorithms to Evaluate,[0],[0]
"Throughout the experiments, we set the decay rate of the eligibility traces in (6) to zero: α[t−1] = x[t−d] and β[t−1] = h[t−d].",5.1. Specific Learning Algorithms to Evaluate,[0],[0]
The delay d and the number of hidden units are varied for each dataset.,5.1. Specific Learning Algorithms to Evaluate,[0],[0]
"We first demonstrate the effectiveness of our bidirectional training in a synthetic setting of learning a one-dimensional noisy sawtooth wave, which is generated according to
x[t] = t C −",5.2. Synthetic Data,[0],[0]
⌊ t C ⌋,5.2. Synthetic Data,[0],[0]
+,5.2. Synthetic Data,[0],[0]
"εt, for t = 0, 1, . . .",5.2. Synthetic Data,[0],[0]
"(31)
where C is the period of the noisy sawtooth wave, and εt is an i.i.d. normal random variable, whose mean is fixed at 0 and standard deviation at 0.01.",5.2. Synthetic Data,[0],[0]
"The noisy sawtooth wave has large discontinuity at the end of each period, which makes hidden units essential for learning.
",5.2. Synthetic Data,[0],[0]
Here we train a DyBM with one hidden unit or no hidden units.,5.2. Synthetic Data,[0],[0]
"Throughout, the delay is set d = 4, and the learning rate is initialized to η = 1.0.",5.2. Synthetic Data,[0],[0]
"Bidirectional learning is continued for T0 = T/2 iterations, where T is varied depending on C. In each iteration, we use one period of the noisy sawtooth wave and update the parameters with stochastic gradients.
",5.2. Synthetic Data,[0],[0]
Figure 3(a) and (c) show how learning progresses over iterations.,5.2. Synthetic Data,[0],[0]
The period of the noisy sawtooth wave is C = 6 in (a) and C = 8 in (c).,5.2. Synthetic Data,[0],[0]
"Training is continued for T = 1, 000 iterations for C = 6 and T = 30, 000 iterations for C = 8.",5.2. Synthetic Data,[0],[0]
"In every F + 1 iterations, we let the DyBM predict the one-step-ahead value for each of the C steps of one period during forward learning.",5.2. Synthetic Data,[0],[0]
We evaluate the root mean squared error (RMSE) of one-step-ahead predictions against true values.,5.2. Synthetic Data,[0],[0]
"For clarity, the RMSE curves are smoothed with a Gaussian filter with window size of 50.
",5.2. Synthetic Data,[0],[0]
"In the figure, the solid curves show the results with the bidirectionally trained DyBMs (Bidirectional).",5.2. Synthetic Data,[0],[0]
"As a baseline, we also train the DyBM only with forward training and show the results with dashed curves (Baseline).",5.2. Synthetic Data,[0],[0]
The dotted curves show the results with the DyBM with no hidden units (No hidden).,5.2. Synthetic Data,[0],[0]
The comparison suggests that Bidirectional can substantially (by a factor of 10) improve the predictive accuracy over Baseline.,5.2. Synthetic Data,[0],[0]
Notice also that the hidden unit can hurt the predictive accuracy without bidirectional training.,5.2. Synthetic Data,[0],[0]
"No hidden often exhibits lower RMSE than Baseline.
",5.2. Synthetic Data,[0],[0]
"In Figure 3(c), the reduction of the RMSE accelerates at T0 iterations, after which bidirectional learning is no longer performed.",5.2. Synthetic Data,[0],[0]
"This suggests that, after learning appropriate values of U (namely, what features should be used for prediction) via bidirectional learning, it is better to optimally learn (V,W,b) given the learned values of U. Namely, although bidirectional learning help learn appropriate values of U, it does not necessarily optimize all of the parameters of the DyBM.",5.2. Synthetic Data,[0],[0]
"Recall also the discussion at the end of Section 4 that the backward DyBM is not exactly the same as the time-reversed DyBM.
",5.2. Synthetic Data,[0],[0]
"Figure 3(b) and (d) show the values predicted by bidirection-
ally trained DyBMs (black curves) and the corresponding target values (red curves).",5.2. Synthetic Data,[0],[0]
"For clarity, we use a noiseless sawtooth wave as the target by letting εt = 0 in (31).",5.2. Synthetic Data,[0],[0]
"Observe that the bidirectionally trained DyBM well predicts the next value of the sawtooth wave, substantially better than the baseline (or the DyBM with no hidden unit).",5.2. Synthetic Data,[0],[0]
"In particular, the bidirectionally trained DyBM can well predict the sharp drop at the end of each period.",5.2. Synthetic Data,[0],[0]
"This is in contrast to the baseline, whose prediction is rather smoothed out over the period.",5.2. Synthetic Data,[0],[0]
"Next, we demonstrate the effectiveness of bidirectional training on three real datasets, including the two datasets used in Dasgupta & Osogami (2017).",5.3. Real Data,[0],[0]
"The first dataset is the monthly sunspot number1, which we will refer to as Sunspot.",5.3. Real Data,[0],[0]
"This time-series has one dimension and 2,820 steps (corresponding to January 1749 to December 1983).",5.3. Real Data,[0],[0]
"The second dataset is the weekly retail gasoline and diesel prices2, which we will refer to as Price.",5.3. Real Data,[0],[0]
"This time-series has eight dimensions (corresponding to eight locations in the US) and 1,223 steps (corresponding to April 5th, 1993 to September 5th, 2016).",5.3. Real Data,[0],[0]
"Following Dasgupta & Osogami (2017), the first 67 % of each time-series is used for training, and the remaining 33 % is used for test.",5.3. Real Data,[0],[0]
See Dasgupta & Osogami (2017) for further details about the first two datasets.,5.3. Real Data,[0],[0]
"The third dataset is the NOAA Global Surface Temperature3, which consists of a real valued time-series of 1,635 steps (t = 1, . . .",5.3. Real Data,[0],[0]
", 1635)",5.3. Real Data,[0],[0]
with 391 dimensions.,5.3. Real Data,[0],[0]
"We use the first 80 % of the time-series for training and the remaining 20 % for test.
",5.3. Real Data,[0],[0]
"We normalize the values of each dataset in a way that the
1https://datamarket.com/data/set/22t4/ 2https://www.eia.gov/dnav/pet/pet_pri_
gnd_a_epm0_pte_dpgal_w.htm 3V4.00 of Air Temperature (air.mon.anom.nc) from https://www.esrl.noaa.gov/psd/data/gridded/ data.noaaglobaltemp.html
values in a training data are in [0,1] for each dimension.",5.3. Real Data,[0],[0]
"Notice that this normalization differs from that in (Dasgupta & Osogami, 2017), where the values in training or test data are in [0,1] for each dimension.",5.3. Real Data,[0],[0]
"However, the use of test data for normalization is less appropriate.",5.3. Real Data,[0],[0]
"This difference in normalization has no effect on the Price dataset, but the results on the Sunspot dataset need to be renormalized to be compared against those in (Dasgupta & Osogami, 2017).
",5.3. Real Data,[0],[0]
Here we train a DyBM with four hidden units or no hidden units.,5.3. Real Data,[0],[0]
"In each iteration, we use the whole training data (except the first d steps for forward learning and the last d steps for backward learning, which are used only to update the internal state of the DyBM) once and update the parameters with stochastic gradients.
",5.3. Real Data,[0],[0]
We find that the speed of convergence is sensitive to the initial learning rate.,5.3. Real Data,[0],[0]
"Here, we choose the initial learning rate from {20, 2−1, 2−2, . . .}.",5.3. Real Data,[0],[0]
"Specifically, we choose 2−k with the smallest k such that the training RMSE after the initial T/100 iterations is smaller than that with 2−(k+1).",5.3. Real Data,[0],[0]
"Because the training RMSE tends to decrease with k up to a point and then increases with k, we usually choose the initial learning rate that minimizes the training RMSE after those initial iterations.
",5.3. Real Data,[0],[0]
Figure 4 shows the RMSE of one-step-ahead prediction with respect to the test data after every F + 1 iterations of training.,5.3. Real Data,[0],[0]
"We show the results where the delay is set d = 30 for Sunspot, d = 3 for Price, and d = 2 for Temperature.",5.3. Real Data,[0],[0]
"However, we have also run experiments with d ∈ {20, 40} for Sunspot and d ∈ {2, 4} for Price and have found that these do not improve the accuracy for any of the three methods.",5.3. Real Data,[0],[0]
"For the large dataset of Temperature, we have been able to perform limited experiments due to its relatively heavy computational requirements.",5.3. Real Data,[0],[0]
"Again, we compare Bidirectional against Baseline and No hidden.",5.3. Real Data,[0],[0]
"However, we now vary T0 ∈ {T/4, T/2, T}, so that each figure has three solid curves.",5.3. Real Data,[0],[0]
"The range of the vertical axis is chosen in a way that the upper limit corresponds to the RMSE with a naı̈ve
prediction of using the preceding values as prediction.
",5.3. Real Data,[0],[0]
"For the Sunspot dataset (a), we find that Bidirectional does not improve upon Baseline, although having hidden units (Bidirectional and Baseline) can make the RMSE lower than No hidden.",5.3. Real Data,[0],[0]
"This means that the randomly set values of U is effective, and bidirectional learning does not find better values of U. After 1,000 iterations, however, Bidirectional with T0 = T/4 or T0 = T/2 achieves the RMSE that is essentially indistinguishable from that with Baseline.",5.3. Real Data,[0],[0]
"The best RMSE achieved by the Baseline is 0.0698, which corresponds to 0.0657 when the dataset is normalized in the way of (Dasgupta & Osogami, 2017) and is lower than 0.0734 reported in (Dasgupta & Osogami, 2017).
",5.3. Real Data,[0],[0]
"For Price (b) and Temperature (c), Bidirectional improves upon Baseline particularly when the bidirectional learning is stopped after T0 < T iterations.",5.3. Real Data,[0],[0]
"Bidirectional reduces the RMSE more slowly than Baseline or No hidden but eventually outperforms the others, and the reduction of the RMSE can be accelerated by stopping the bidirectional training after T0 < T iterations.",5.3. Real Data,[0],[0]
"In particular, the best RMSE achieved by Bidirectional with T0 = T/4 is 0.0399, which is lower than 0.0564 reported in (Dasgupta & Osogami, 2017).",5.3. Real Data,[0],[0]
"In addition, while Baseline and No hidden (namely, forward learning only) starts overfitting to training data and increases the RMSE with respect to the test data after some iterations, bidirectional training appears to avoid such overfit.",5.3. Real Data,[0],[0]
We have proposed bidirectional training for time-series models with hidden units.,6. Conclusion,[0],[0]
"Namely, we consider two models that have a common set of parameters, where one model is trained with forward time-series and the other with backward time-series.",6. Conclusion,[0],[0]
Our key idea is that some of the parameters that are difficult to learn in one model can be effectively learned in the other model.,6. Conclusion,[0],[0]
"Numerical experiments suggest that bidirectional training has the additional effect of
avoiding overfit to training data.
",6. Conclusion,[0],[0]
"The DyBM with hidden units analyzed in Sections 2–4 is new, and its analysis has two highlights, which have led to proposing bidirectional training.",6. Conclusion,[0],[0]
The first highlight is that the learning rule for V (hidden-to-visible weight) in (20)–(22) becomes equivalent to those for W (visible-tovisible weight) in (20)–(22) when the lower bound (14) is maximized.,6. Conclusion,[0],[0]
"The second highlight is that we cannot learn the weight to hidden units (φ = (U,Z)) in the same way as the weight to visible units (θ = (V,W,b)) due to the form of the gradient in (27).
",6. Conclusion,[0],[0]
"Although we have demonstrated the effectiveness of bidirectional training in specific cases, its capabilities are not fully explored.",6. Conclusion,[0],[0]
Bidirectional training has many design choices that need further study.,6. Conclusion,[0],[0]
"For example, one might want to use the gradients in (27)-(28), possibly with the approximation in (29), to update (U,Z) in forward learning and (V,Z) in backward learning.",6. Conclusion,[0],[0]
It would also be interesting to apply bidirectional training to other time-series models having parameters that represent the dependency between hidden values at one time and visible values at another time.,6. Conclusion,[0],[0]
"In addition to DyBM and VAR with hidden units, these include Spiking Boltzmann Machine (Hinton & Brown, 1999) and Conditional Restricted Boltzmann Machine (Taylor et al., 2007).",6. Conclusion,[0],[0]
"Because bidirectional training is largely complementary to other techniques for learning time-series, it would be interesting to investigate how bidirectional training improves performance when it is combined with these other techniques.",6. Conclusion,[0],[0]
We expect that this work opens up a line of research on more effective methods of bidirectional training.,6. Conclusion,[0],[0]
"This work was supported by JST CREST Grant Number JPMJCR1304, Japan.",Acknowledgments,[0],[0]
Hidden units can play essential roles in modeling time-series having long-term dependency or nonlinearity but make it difficult to learn associated parameters.,abstractText,[0],[0]
"Here we propose a way to learn such a time-series model by training a backward model for the time-reversed time-series, where the backward model has a common set of parameters as the original (forward) model.",abstractText,[0],[0]
"Our key observation is that only a subset of the parameters is hard to learn, and that subset is complementary between the forward model and the backward model.",abstractText,[0],[0]
"By training both of the two models, we can effectively learn the values of the parameters that are hard to learn if only either of the two models is trained.",abstractText,[0],[0]
We apply bidirectional learning to a dynamic Boltzmann machine extended with hidden units.,abstractText,[0],[0]
Numerical experiments with synthetic and real datasets clearly demonstrate advantages of bidirectional learning.,abstractText,[0],[0]
Bidirectional Learning for Time-series Models with Hidden Units,title,[0],[0]
"While in standard supervised learning problems we seek the best hypothesis in a given space and with a given learning algorithm, in hyperparameter optimization (HO) and metalearning (ML) we seek a configuration so that the optimized learning algorithm will produce a model that generalizes well to new data.",1. Introduction,[0],[0]
"The search space in ML often incorporates choices associated with the hypothesis space and the features of the learning algorithm itself (e.g., how optimization of the training loss is performed).",1. Introduction,[0],[0]
"Under this common perspective, both HO and ML essentially boil down to nesting two search problems: at the inner level we seek a good
1Computational Statistics and Machine Learning, Istituto Italiano di Tecnologia, Genoa, Italy 2Department of Computer Science, University College London, London, UK 3Department of Information Engineering, Università degli Studi di Firenze, Florence, Italy.",1. Introduction,[0],[0]
"Correspondence to: Luca Franceschi <luca.franceschi@iit.it>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
hypothesis (as in standard supervised learning) while at the outer level we seek a good configuration (including a good hypothesis space) where the inner search takes place.",1. Introduction,[0],[0]
"Surprisingly, the literature on ML has little overlap with the literature on HO and in this paper we present a unified framework encompassing both of them.
",1. Introduction,[0],[0]
"Classic approaches to HO (see e.g. Hutter et al., 2015, for a survey) have been only able to manage a relatively small number of hyperparameters, from a few dozens using random search (Bergstra and Bengio, 2012) to a few hundreds using Bayesian or model-based approaches (Bergstra et al., 2013; Snoek et al., 2012).",1. Introduction,[0],[0]
"Recent gradient-based techniques for HO, however, have significantly increased the number of hyperparameters that can be optimized (Domke, 2012; Maclaurin et al., 2015; Pedregosa, 2016; Franceschi et al., 2017) and it is now possible to tune as hyperparameters entire weight vectors associated with a neural network layer.",1. Introduction,[0],[0]
"In this way, it becomes feasible to design models that possibly have more hyperparameters than parameters.",1. Introduction,[0],[0]
"Such an approach is well suited for ML, since parameters are learned from a small dataset, whereas hyperparameters leverage multiple available datasets.
",1. Introduction,[0],[0]
HO and ML only differ substantially in terms of the experimental settings in which they are evaluated.,1. Introduction,[0],[0]
"While in HO the available data is associated with a single task and split into a training set (used to tune the parameters) and a validation set (used to tune the hyperparameters), in ML we are often interested in the so-called few-shot learning setting where data comes in the form of short episodes (small datasets with few examples per class) sampled from a common probability distribution over supervised tasks.
",1. Introduction,[0],[0]
"Early work on ML dates back at least to the 1990’s (Schmidhuber, 1992; Baxter, 1995; Thrun and Pratt, 1998) but this research area has received considerable attention in the last few years, mainly driven by the need in real-life and industrial scenarios for learning quickly a vast multitude of tasks.",1. Introduction,[0],[0]
"These tasks, or episodes, may appear and evolve continuously over time and may only contain few examples (Lake et al., 2017).",1. Introduction,[0],[0]
Different strategies have emerged to tackle ML.,1. Introduction,[0],[0]
"Although they do overlap in some aspects, it is possible to identify at least four of them.",1. Introduction,[0],[0]
"The metric strategy attempts to use training episodes to construct embeddings such that examples of the same class are mapped into similar repre-
sentations.",1. Introduction,[0],[0]
"It has been instantiated in several variants that involve non-parametric (or instance-based) predictors (Koch et al., 2015; Vinyals et al., 2016; Snell et al., 2017).",1. Introduction,[0],[0]
"In the related memorization strategy, the meta-learner learns to store and retrieve data points representations in memory.",1. Introduction,[0],[0]
"It can be implemented either using recurrent networks (Santoro et al., 2016) or temporal convolutions (Mishra et al., 2018).",1. Introduction,[0],[0]
"The use of an attention mechanism (Vaswani et al., 2017) is crucial both in (Vinyals et al., 2016) and in (Mishra et al., 2018).",1. Introduction,[0],[0]
"The initialization strategy (Ravi and Larochelle, 2017; Finn et al., 2017) uses training episodes to infer a good initial value for the model’s parameters so that new tasks can be learned quickly by fine tuning.",1. Introduction,[0],[0]
"The optimization strategy (Andrychowicz et al., 2016; Ravi and Larochelle, 2017; Wichrowska et al., 2017) forges an optimization algorithm that will find it easier to learn on novel related tasks.
",1. Introduction,[0],[0]
"A main contribution of this paper is a unified view of HO and ML within the natural mathematical framework of bilevel programming, where an outer optimization problem is solved subject to the optimality of an inner optimization problem.",1. Introduction,[0],[0]
In HO the outer problem involves hyperparameters while the inner problem is usually the minimization of an empirical loss.,1. Introduction,[0],[0]
In ML the outer problem could involve a shared representation among tasks while the inner problem could concern classifiers for individual tasks.,1. Introduction,[0],[0]
"Bilevel programming (Bard, 2013) has been suggested before in machine learning in the context of kernel methods and support vector machines (Keerthi et al., 2007; Kunapuli et al., 2008), multitask learning (Flamary et al., 2014), and more recently HO (Pedregosa, 2016), but never in the context of ML.",1. Introduction,[0],[0]
"The resulting framework outlined in Sec. 2 encompasses some existing approaches to ML, in particular those based on the initialization and the optimization strategies.
",1. Introduction,[0],[0]
A technical difficulty arises when the solution to the inner problem cannot be written analytically (for example this happens when using the log-loss for training neural networks) and one needs to resort to iterative optimization approaches.,1. Introduction,[0],[0]
"As a second contribution, we provide in Sec.",1. Introduction,[0],[0]
3 sufficient conditions that guarantee good approximation properties.,1. Introduction,[0],[0]
"We observe that these conditions are reasonable and apply
to concrete problems relevant to applications.
",1. Introduction,[0],[0]
"In Sec. 4, by taking inspiration on early work on representation learning in the context of multi-task and meta-learning (Baxter, 1995; Caruana, 1998), we instantiate the framework for ML in a simple way treating the weights of the last layer of a neural network as the inner variables and the remaining weights, which parametrize the representation mapping, as the outer variables.",1. Introduction,[0],[0]
"As shown in Sec. 5, the resulting ML algorithm performs well in practice, outperforming most of the existing strategies on MiniImagenet.",1. Introduction,[0],[0]
"In this paper, we consider bilevel optimization problems (see e.g. Colson et al., 2007) of the form
min{f(λ) : λ ∈ Λ}, (1)
where function f : Λ→ R is defined at λ ∈ Λ as
f(λ) = inf{E(wλ, λ) : wλ ∈ arg min u∈Rd Lλ(u)}.",2. A bilevel optimization framework,[0],[0]
"(2)
We call E : Rd × Λ→ R the outer objective and, for every λ ∈ Λ, we call Lλ : Rd → R the inner objective.",2. A bilevel optimization framework,[0],[0]
Note that {Lλ : λ ∈ Λ} is a class of objective functions parameterized by λ.,2. A bilevel optimization framework,[0],[0]
"Specific instances of this problem include HO and ML, which we discuss next.",2. A bilevel optimization framework,[0],[0]
"Table 1 outlines the links among bilevel programming, HO and ML.",2. A bilevel optimization framework,[0],[0]
"In the context of hyperparameter optimization, we are interested in minimizing the validation error of a model gw : X",2.1. Hyperparameter Optimization,[0],[0]
"→ Y parameterized by a vector w, with respect to a vector of hyperparameters λ.",2.1. Hyperparameter Optimization,[0],[0]
"For example, we may consider representation or regularization hyperparameters that control the hypothesis space or penalties, respectively.",2.1. Hyperparameter Optimization,[0],[0]
"In this setting, a prototypical choice for the inner objective is the regularized empirical error
Lλ(w) = ∑
(x,y)∈Dtr
`(gw(x), y) + Ωλ(w),
where Dtr = {(xi, yi)}ni=1 is a set of input/output points, ` is a prescribed loss function, and Ωλ a regularizer parameterized by λ.",2.1. Hyperparameter Optimization,[0],[0]
"The outer objective represents a proxy for the generalization error of gw, and it may be given by the average loss on a validation set Dval
E(w, λ) = ∑
(x,y)∈Dval
`(gw(x), y).
or, in more generality, by a cross-validation error, as detailed in Appendix B. Note that in this setting, the outer objective E does not depend explicitly on the hyperparameters λ,
Error
since in HO λ is instrumental in finding a good model gw, which is our final goal.",2.1. Hyperparameter Optimization,[0],[0]
"As a more specific example, consider linear models, gw(x) = 〈w, x〉, let ` be the square loss and let Ωλ(w) = λ‖w‖2, in which case the inner objective is ridge regression (Tikhonov regularization) and the bilevel problem optimizes over the regularization parameter the validation error of ridge regression.",2.1. Hyperparameter Optimization,[0],[0]
"In meta-learning (ML) the inner and outer objectives are computed by averaging a training and a validation error over multiple tasks, respectively.",2.2. Meta-Learning,[0],[0]
The goal is to produce a learning algorithm that will work well on novel tasks1.,2.2. Meta-Learning,[0],[0]
"For this purpose, we have available a meta-training set D = {Dj = Djtr ∪ D j val}Nj=1, which is a collection of datasets, sampled from a meta-distribution P .",2.2. Meta-Learning,[0],[0]
"Each dataset Dj = {(xji , y j i )}",2.2. Meta-Learning,[0],[0]
nj i=1,2.2. Meta-Learning,[0],[0]
"with (x j i , y j i ) ∈",2.2. Meta-Learning,[0],[0]
X,2.2. Meta-Learning,[0],[0]
×,2.2. Meta-Learning,[0],[0]
Yj is linked to a specific task.,2.2. Meta-Learning,[0],[0]
Note that the output space is task dependent (e.g. a multi-class classification problem with variable number of classes).,2.2. Meta-Learning,[0],[0]
"The model for each task is a function gwj ,λ : X → Yj , identified by a parameter vectors wj and hyperparameters λ.",2.2. Meta-Learning,[0],[0]
A key point here is that λ is shared between the tasks.,2.2. Meta-Learning,[0],[0]
"With this notation the inner and outer objectives are
Lλ(w) =",2.2. Meta-Learning,[0],[0]
"N∑ j=1 Lj(wj , λ,Djtr), (3)
E(w, λ) = N∑ j=1 Lj(wj , λ,Djval) (4)
respectively.",2.2. Meta-Learning,[0],[0]
"The loss Lj(wj , λ, S) represents the empirical error of the pair (wj , λ) on a set of examples S. Note that the
1The ML problem is also related to multitask learning, however in ML the goal is to extrapolate from the given tasks.
inner and outer losses for task j use different train/validation splits of the corresponding dataset Dj .",2.2. Meta-Learning,[0],[0]
"Furthermore, unlike in HO, in ML the final goal is to find a good λ and the wj are now instrumental.
",2.2. Meta-Learning,[0],[0]
The cartoon in Figure 1 illustrates ML as a bilevel problem.,2.2. Meta-Learning,[0],[0]
The parameter λ indexes an hypothesis space within which the inner objective is minimized.,2.2. Meta-Learning,[0],[0]
"A particular example, detailed in Sec. 4, is to choose the model gw,λ = 〈w, hλ(x)〉, in which case λ parameterizes a feature mapping.",2.2. Meta-Learning,[0],[0]
"Yet another choice would be to consider gwj ,λ(x) =",2.2. Meta-Learning,[0],[0]
"〈w + λ, x〉, in which case λ represents a common model around which task specific models are to be found (see e.g. Evgeniou et al., 2005; Finn et al., 2017; Khosla et al., 2012; Kuzborskij et al., 2013, and reference therein).",2.2. Meta-Learning,[0],[0]
We now discuss a general approach to solve Problem (1)-(2) when the hyperparameter vector λ is real-valued.,2.3. Gradient-Based Approach,[0],[0]
To simplify our discussion let us assume that the inner objective has a unique minimizer wλ.,2.3. Gradient-Based Approach,[0],[0]
"Even in this simplified scenario, Problem (1)-(2) remains challenging to solve.",2.3. Gradient-Based Approach,[0],[0]
"Indeed, in general there is no closed form expression wλ, so it is not possible to directly optimize the outer objective function.",2.3. Gradient-Based Approach,[0],[0]
While a possible strategy (implicit differentiation) is to apply the implicit function theorem to∇Lλ = 0,2.3. Gradient-Based Approach,[0],[0]
"(Pedregosa, 2016; Koh and Liang, 2017; Beirami et al., 2017), another compelling approach is to replace the inner problem with a dynamical system.",2.3. Gradient-Based Approach,[0],[0]
"This point, discussed in (Domke, 2012; Maclaurin et al., 2015; Franceschi et al., 2017), is developed further in this paper.
",2.3. Gradient-Based Approach,[0],[0]
"Specifically, we let [T ] = {1, . . .",2.3. Gradient-Based Approach,[0],[0]
", T} where T is a prescribed positive integer and consider the following approximation of Problem (1)-(2)
min λ fT (λ)",2.3. Gradient-Based Approach,[0],[0]
"= E(wT,λ, λ), (5)
where E is a smooth scalar function, and2
w0,λ = Φ0(λ), wt,λ = Φt(wt−1,λ, λ), t ∈",2.3. Gradient-Based Approach,[0],[0]
"[T ], (6)
with Φ0 :",2.3. Gradient-Based Approach,[0],[0]
"Rm → Rd a smooth initialization mapping and, for every t ∈",2.3. Gradient-Based Approach,[0],[0]
"[T ], Φt : Rd × Rm → Rd a smooth mapping that represents the operation performed by the t-th step of an optimization algorithm.",2.3. Gradient-Based Approach,[0],[0]
"For example, the optimization dynamics could be gradient descent: Φt(wt, λ) =",2.3. Gradient-Based Approach,[0],[0]
"wt − ηt∇Lλ(·) where (ηt)t∈[T ] is a sequence of steps sizes.
",2.3. Gradient-Based Approach,[0],[0]
"The approximation of the bilevel problem (1)-(2) by the procedure (5)-(6) raises the issue of the quality of this approximation and we return to this issue in the next section.
",2.3. Gradient-Based Approach,[0],[0]
"2In general, the algorithm used to minimize the inner objective may involve auxiliary variables, e.g., velocities when using gradient descent with momentum, so w should be intended as a larger vector containing both model parameters and auxiliary variables.
",2.3. Gradient-Based Approach,[0],[0]
"However, it also suggests to consider the inner dynamics as a form of approximate empirical error minimization (e.g. early stopping) which is valid in its own right.",2.3. Gradient-Based Approach,[0],[0]
From this perspective – conversely to the implicit differentiation strategy – it is possible to include among the components of λ variables which are associated with the optimization algorithm itself.,2.3. Gradient-Based Approach,[0],[0]
"For example, λ may include the step sizes or momentum factors if the dynamics",2.3. Gradient-Based Approach,[0],[0]
Φt in Eq.,2.3. Gradient-Based Approach,[0],[0]
"(6) is gradient descent with momentum; in (Andrychowicz et al., 2016; Wichrowska et al., 2017)",2.3. Gradient-Based Approach,[0],[0]
"the mapping Φt is implemented as a recurrent neural network, while (Finn et al., 2017) focus on the initialization mapping by letting Φ0(λ) =",2.3. Gradient-Based Approach,[0],[0]
"λ.
",2.3. Gradient-Based Approach,[0],[0]
"A major advantage of this reformulation is that it makes it possible to compute efficiently the gradient of fT , which we call hypergradient, either in time or in memory (Maclaurin et al., 2015; Franceschi et al., 2017), by making use of reverse or forward mode algorithmic differentiation (Griewank and Walther, 2008; Baydin et al., 2017).",2.3. Gradient-Based Approach,[0],[0]
"This allows us to optimize a number of hyperparameters of the same order of that of parameters, a situation which arise in ML.",2.3. Gradient-Based Approach,[0],[0]
"In this section, we provide results about the existence of solutions of Problem (1)-(2) and the approximation properties of Procedure (5)-(6) with respect to the original bilevel problem.",3. Exact and Approximate Bilevel Programming,[0],[0]
"Proofs of these results are provided in the supplementary material.
",3. Exact and Approximate Bilevel Programming,[0],[0]
"Procedure (5)-(6), though related to the bilevel problem (1)-(2), may not be, in general, a good approximation of it.",3. Exact and Approximate Bilevel Programming,[0],[0]
"Indeed, making the assumptions (which sound perfectly reasonable) that, for every λ ∈ Λ, wT,λ → wλ for some wλ ∈ arg maxLλ, and that E(·, λ) is continuous, one can only assert that limT→∞ fT (λ) = E(wλ, λ) ≥ f(λ).",3. Exact and Approximate Bilevel Programming,[0],[0]
"This is because the optimization dynamics converge to some minimizer of the inner objective Lλ, but not necessarily to the one that also minimizes the function E. This is illustrated in Figure 2.",3. Exact and Approximate Bilevel Programming,[0],[0]
"The situation is, however, different if the inner problem admits a unique minimizer for every λ ∈",3. Exact and Approximate Bilevel Programming,[0],[0]
Λ.,3. Exact and Approximate Bilevel Programming,[0],[0]
"Indeed in this case, it is possible to show that the set of minimizers of the approximate problems converge, as T → +∞ and in an appropriate sense, to the set of minimizers of the bilevel problem.",3. Exact and Approximate Bilevel Programming,[0],[0]
"More precisely, we make the following assumptions:
(i) Λ is a compact subset of Rm;
(ii) E : Rd × Λ→ R is jointly continuous;
(iii) the map (w, λ) 7→ Lλ(w) is jointly continuous and such that arg minLλ is a singleton for every λ ∈ Λ;
(iv) wλ = arg minLλ remains bounded as λ varies in Λ.
Then, problem (1)-(2) becomes
min λ∈Λ f(λ) = E(wλ, λ), wλ = argminuLλ(u).",3. Exact and Approximate Bilevel Programming,[0],[0]
"(7)
Under the above assumptions, in the following we give results about the existence of solutions of problem (7) and the (variational) convergence of the approximate problems (5)-(6) towards problem (7) — relating the minima as well as the set of minimizers.",3. Exact and Approximate Bilevel Programming,[0],[0]
"In this respect we note that, since both f and fT are nonconvex, argmin fT and argmin f are in general nonsingleton, so an appropriate definition of set convergence is required.
",3. Exact and Approximate Bilevel Programming,[0],[0]
Theorem 3.1 (Existence).,3. Exact and Approximate Bilevel Programming,[0],[0]
Under Assumptions (i)-(iv) problem (7) admits solutions.,3. Exact and Approximate Bilevel Programming,[0],[0]
"Proof See Appendix A.
The result below follows from general facts on the stability of minimizers in optimization problems (Dontchev and Zolezzi, 1993).
",3. Exact and Approximate Bilevel Programming,[0],[0]
Theorem 3.2 (Convergence).,3. Exact and Approximate Bilevel Programming,[0],[0]
"In addition to Assumptions (i)-(iv), suppose that:
(v) E(·, λ) is uniformly Lipschitz continuous; (vi) The iterates (wT,λ)T∈N converge uniformly to wλ on
Λ as T → +∞. Then
(a) inf fT → inf f , (b) argmin fT → argmin f , meaning that, for every
(λT )T∈N such that λT ∈ argmin fT , we have that:
- (λT )T∈N admits a convergent subsequence; - for every subsequence (λKT )T∈N such that λKT → λ̄, we have λ̄ ∈ argmin f .
",3. Exact and Approximate Bilevel Programming,[0],[0]
"Proof See Appendix A.
We stress that assumptions (i)-(vi) are very natural and satisfied by many problems of practical interests.",3. Exact and Approximate Bilevel Programming,[0],[0]
"Thus, the above results provide full theoretical justification to the proposed approximate procedure (5)-(6).",3. Exact and Approximate Bilevel Programming,[0],[0]
"The following remark discusses assumption (vi), while the subsequent example will be relevant to the experiments in Sec. 5.
",3. Exact and Approximate Bilevel Programming,[0],[0]
Algorithm 1.,3. Exact and Approximate Bilevel Programming,[0],[0]
"Reverse-HG for Hyper-representation Input: λ, current values of the hyperparameter, T number of iteration of GD, η ground learning rate, B minibatch of episodes from D Output: Gradient of meta-training error w.r.t.",3. Exact and Approximate Bilevel Programming,[0],[0]
"λ on B for j = 1 to |B| do
wj0",3. Exact and Approximate Bilevel Programming,[0],[0]
"= 0 for t = 1 to T do
wjt ← wt−1",3. Exact and Approximate Bilevel Programming,[0],[0]
"− η∇wLj(w j t−1, λ,D j tr)
αjT",3. Exact and Approximate Bilevel Programming,[0],[0]
"← ∇wLj(w j T , λ,Dval)",3. Exact and Approximate Bilevel Programming,[0],[0]
"pj ← ∇λLj(wjT , λ,Dval) for t = T − 1 downto 0",3. Exact and Approximate Bilevel Programming,[0],[0]
"do
pj ← pj − αjt+1η∇λ∇wLj(w j t , λ,D j tr) αjt ← α j t+1",3. Exact and Approximate Bilevel Programming,[0],[0]
"[ I − η∇w∇wLj(wjt , λ,D j tr) ] return ∑ j p j
Remark 3.3.",3. Exact and Approximate Bilevel Programming,[0],[0]
"If Lλ is strongly convex, then many gradientbased algorithms (e.g., standard and accelerated gradient descent) yield linear convergence of the iterates wT,λ’s.",3. Exact and Approximate Bilevel Programming,[0],[0]
"Moreover, in such cases, the rate of linear convergence is of type (νλ − µλ)/(νλ + µλ), where νλ and µλ are the Lipschitz constant of the gradient and the modulus of strong convexity of Lλ respectively.",3. Exact and Approximate Bilevel Programming,[0],[0]
"So, this rate can be uniformly bounded from above by ρ ∈ ]0, 1[, provided that supλ∈Λ νλ <",3. Exact and Approximate Bilevel Programming,[0],[0]
+∞,3. Exact and Approximate Bilevel Programming,[0],[0]
and infλ∈Λ,3. Exact and Approximate Bilevel Programming,[0],[0]
µλ > 0.,3. Exact and Approximate Bilevel Programming,[0],[0]
"Thus, in these cases wT,λ converges uniformly to wλ on Λ (at a linear rate).
",3. Exact and Approximate Bilevel Programming,[0],[0]
Example 3.4.,3. Exact and Approximate Bilevel Programming,[0],[0]
"Let us consider the following form of the inner objective:
LH(w) = ‖y −XHw‖2",3. Exact and Approximate Bilevel Programming,[0],[0]
"+ ρ‖w‖2, (8)
where ρ > 0 is a fixed regularization parameter and H ∈ Rd×d is the hyperparameter, representing a linear feature map.",3. Exact and Approximate Bilevel Programming,[0],[0]
"LH is strongly convex, with modulus µ = ρ > 0",3. Exact and Approximate Bilevel Programming,[0],[0]
"(independent on the hyperparameter H), and Lipschitz smooth with constant νH = 2‖(XH)>XH+ρI‖, which is bounded from above, if H ranges in a bounded set of square matrices.",3. Exact and Approximate Bilevel Programming,[0],[0]
In this case assumptions (i)-(vi) are satisfied.,3. Exact and Approximate Bilevel Programming,[0],[0]
"In this section, we instantiate the bilevel programming approach for ML outlined in Sec. 2.2 in the case of deep learning where representation layers are shared across episodes.",4. Learning Hyper-Representations,[0],[0]
Finding good data representations is a centerpiece in machine learning.,4. Learning Hyper-Representations,[0],[0]
"Classical approaches (Baxter, 1995; Caruana, 1998) learn both the weights of the representation mapping and those of the ground classifiers jointly on the same data.",4. Learning Hyper-Representations,[0],[0]
"Here we follow the bilevel approach and split each dataset/episode in training and validation sets.
",4. Learning Hyper-Representations,[0],[0]
"Our method involves the learning of a cross-task intermedi-
ate representation hλ :",4. Learning Hyper-Representations,[0],[0]
X → Rk (parametrized by a vector λ) on top of which task specific models gj :,4. Learning Hyper-Representations,[0],[0]
Rk → Yj (parametrized by vectors wj) are trained.,4. Learning Hyper-Representations,[0],[0]
The final ground model for task j is thus given by gj ◦,4. Learning Hyper-Representations,[0],[0]
"h. To find λ, we solve Problem (1)-(2) with inner and outer objectives as in Eqs.",4. Learning Hyper-Representations,[0],[0]
"(3) and (4), respectively.",4. Learning Hyper-Representations,[0],[0]
"Since, in general, this problem cannot be solved exactly, we instantiate the approximation scheme in Eqs.",4. Learning Hyper-Representations,[0],[0]
"(5)-(6) as follows:
min λ fT (λ) = N∑ j=1 Lj(wjT , λ,D j val) (9)
wjt = w j",4. Learning Hyper-Representations,[0],[0]
"t−1−η∇wLj(w j t−1, λ,D j tr), t, j ∈",4. Learning Hyper-Representations,[0],[0]
"[T ], [N ].",4. Learning Hyper-Representations,[0],[0]
"(10)
Starting from an initial value, the weights of the task-specific models are learned by T iterations of gradient descent.",4. Learning Hyper-Representations,[0],[0]
"The gradient of fT can be computed efficiently in time by making use of an extended reverse-hypergradient procedure (Franceschi et al., 2017) which we present in Algorithm 1.",4. Learning Hyper-Representations,[0],[0]
"Since, in general, the number of episodes in a meta-training set is large, we compute a stochastic approximation of the gradient of fT by sampling a mini-batch of episodes.",4. Learning Hyper-Representations,[0],[0]
"At test time, given a new episode D̄, the representation h is kept fixed, and all the examples in D̄ are used to tune the weights w̄ of the episode-specific model ḡ.
Like other initialization and optimization strategies for ML, our method does not require lookups in a support set as the memorization and metric strategies do (Santoro et al., 2016; Vinyals et al., 2016; Mishra et al., 2018).",4. Learning Hyper-Representations,[0],[0]
"Unlike (Andrychowicz et al., 2016; Ravi and Larochelle, 2017) we do not tune the optimization algorithm, which in our case is plain empirical loss minimization by gradient descent, and rather focus on the hypothesis space.",4. Learning Hyper-Representations,[0],[0]
"Unlike (Finn et al., 2017), that aims at maximizing sensitivity of new task losses to the model parameters, we aim at maximizing the generalization to novel examples during training episodes, with respect to λ.",4. Learning Hyper-Representations,[0],[0]
"Our assumptions about the structure of the model are slightly stronger than in (Finn et al., 2017) but still mild, namely that some (hyper)parameters define the representation and the remaining parameters define the classification function.",4. Learning Hyper-Representations,[0],[0]
"In (Munkhdalai and Yu, 2017)",4. Learning Hyper-Representations,[0],[0]
"the meta-knowledge is distributed among fast and slow weights and an external memory; our approach is more direct, since the meta-knowledge is solely distilled by λ.",4. Learning Hyper-Representations,[0],[0]
"A further advantage of our method is that, if the episode-specific models are linear (e.g. logistic regressors) and each loss Lj is strongly convex in w, the theoretical guarantees of Theorem 3.2 apply (see Remark 3.3).",4. Learning Hyper-Representations,[0],[0]
These assumptions are satisfied in the experiments reported in the next section.,4. Learning Hyper-Representations,[0],[0]
The aim of the following experiments is threefold.,5. Experiments,[0],[0]
"First, we investigate the impact of the number of iterations of the optimization dynamics on the quality of the solution on a
simple multiclass classification problem.",5. Experiments,[0],[0]
"Second, we test our hyper-representation method in the context of few-shot learning on two benchmark datasets.",5. Experiments,[0],[0]
"Finally, we constrast the bilevel ML approach against classical approaches to learn shared representations 3.",5. Experiments,[0],[0]
"Motivated by the theoretical findings of Sec. 3, we empirically investigate how solving the inner problem approximately (i.e. using small T ) affects convergence, generalization performances, and running time.",5.1. The Effect of T,[0],[0]
"We focus in particular on the linear feature map described in Example 3.4, which allows us to compare the approximated solution against the closed-form analytical solution given by
wH =",5.1. The Effect of T,[0],[0]
"[(XH) TXH + ρI]−1(XH)TY.
",5.1. The Effect of T,[0],[0]
"In this setting, the bilevel problem reduces to a (non-convex) optimization problem in H .
",5.1. The Effect of T,[0],[0]
"We use a subset of 100 classes extracted from Omniglot dataset (Lake et al., 2017) to construct a HO problem aimed at tuning H .",5.1. The Effect of T,[0],[0]
"A training set Dtr and a validation set Dval, each consisting of three randomly drawn examples per class, were sampled to form the HO problem.",5.1. The Effect of T,[0],[0]
"A third set Dtest, consisting of fifteen examples per class, was used for testing.",5.1. The Effect of T,[0],[0]
"Instead of using raw images as input, we employ feature vectors x ∈ R256 computed by the convolutional network trained on one-shot five-ways ML setting as described in Sec.",5.1. The Effect of T,[0],[0]
"5.2.
",5.1. The Effect of T,[0],[0]
"For the approximate problems we compute the hypergradient using Algorithm 1, where it is intended that B = {(Dtr, Dval)}.",5.1. The Effect of T,[0],[0]
Figure 3 shows the values of functions f and fT (see Eqs.,5.1. The Effect of T,[0],[0]
"(1) and (5), respectively) during the optimization of H .",5.1. The Effect of T,[0],[0]
"As T increases, the solution of the approximate
3The code for reproducing the experiments, based on the package FAR-HO (https://bit.ly/far-ho), is available at https://bit.ly/hyper-repr
problem approaches the true bilevel solution.",5.1. The Effect of T,[0],[0]
"However, performing a small number of gradient descent steps for solving the inner problem acts as implicit regularizer.",5.1. The Effect of T,[0],[0]
"As it is evident from Figure 4, the generalization error is better when T is smaller than the value yielding the best approximation of the inner solution.",5.1. The Effect of T,[0],[0]
"This is to be expected since, in this setting, the dimensions of parameters and hyperparameters are of the same order, leading to a concrete possibility of overfitting the outer objective (validation error).",5.1. The Effect of T,[0],[0]
"An appropriate, problem dependent, choice of T may help avoiding this issue (see also Appendix C).",5.1. The Effect of T,[0],[0]
"As T increases, the number of hyperiterations required to reach the maximum test accuracy decreases, further suggesting that there is an interplay between the number of iterations used to solve the inner and the outer objective.",5.1. The Effect of T,[0],[0]
"Finally, the running time of Algorithm 1, is linear in T and the size of w and independent of the size of H (see also Table 2), making it even more appealing to reduce the number of iterations.",5.1. The Effect of T,[0],[0]
"We now turn our attention to learning-to-learn, precisely to few-shot supervised learning, implementing the ML strategy outlined in Sec. 4 on two different benchmark datasets:
• OMNIGLOT (Lake et al., 2015), a dataset that contains examples of 1623 different handwritten characters from 50 alphabets.",5.2. Few-shot Learning,[0],[0]
"We downsample the images to 28× 28.
• MINIIMAGENET (Vinyals et al., 2016), a subset of ImageNet (Deng et al., 2009), that contains 60000 downsampled images from 100 different classes.
",5.2. Few-shot Learning,[0],[0]
"Following the experimental protocol used in a number of recent works, we build a meta-training set D, from which we sample datasets to solve Problem (9)-(10), a meta-validation
set V for tuning ML hyperparameters, and finally a metatest set T which is used to estimate accuracy.",5.2. Few-shot Learning,[0],[0]
"Operationally, each meta-dataset consists of a pool of samples belonging to different (non-overlapping between separate meta-dataset) classes, which can be combined to form ground classification datasets Dj = Djtr ∪ D j val with 5 or 20 classes (for Omniglot).",5.2. Few-shot Learning,[0],[0]
The Djtr’s contain 1 or 5 examples per class which are used to fit wj (see Eq. 10).,5.2. Few-shot Learning,[0],[0]
"The Djval’s, containing 15 examples per class, is used either to compute fT (λ) (see Eq. (9)) and its (stochastic) gradient if Dj ∈ D or to provide a generalization score if Dj comes from either V or T .",5.2. Few-shot Learning,[0],[0]
"For MiniImagenet we use the same split and images proposed in (Ravi and Larochelle, 2017), while for Omniglot we use the protocol defined by (Santoro et al., 2016).
",5.2. Few-shot Learning,[0],[0]
As ground classifiers we use multinomial logistic regressors and as task losses `j we employ cross-entropy.,5.2. Few-shot Learning,[0],[0]
"The inner problems, being strongly convex, admit unique minimizers, yet require numerical computation of the solutions.",5.2. Few-shot Learning,[0],[0]
"We initialize ground models parameters wj to 0 and, according to the observation in Sec. 5.1, we perform T gradient descent steps, where T is treated as a ML hyperparameter that has to be validated.",5.2. Few-shot Learning,[0],[0]
Figure 6 shows an example of meta-validation of T for one-shot learning on MiniImagenet.,5.2. Few-shot Learning,[0],[0]
"We compute a stochastic approximation of∇fT (λ) with Algorithm 1 and use Adam with decaying learning rate to optimize λ.
",5.2. Few-shot Learning,[0],[0]
"Regarding the specific implementation of the representation mapping h, we employ for Omniglot a four-layers convolutional neural network with strided convolutions and 64 filters per layer as in (Vinyals et al., 2016) and other successive works.",5.2. Few-shot Learning,[0],[0]
"For MiniImagenet we tried two different architectures:
• C4L, a four-layers convolutional neural network with maxpooling and 32 filters per layer;
• RN: a residual network (He et al., 2016) built of four residual blocks followed by two convolutional layers.
",5.2. Few-shot Learning,[0],[0]
"The first network architecture has been proposed in (Ravi and Larochelle, 2017) and then used in (Finn et al., 2017), while a similar residual network architecture has been employed in a more recent work (Mishra et al., 2018).",5.2. Few-shot Learning,[0],[0]
"Further details on the architectures of h, as well as other ML hyperparameters, are specified in the supplementary material.",5.2. Few-shot Learning,[0],[0]
"We report our results, using RN for MiniImagenet, in Table 3, alongside scores from various recently proposed methods for comparison.
",5.2. Few-shot Learning,[0],[0]
"The proposed method achieves competitive results highlighting the relative importance of learning a task independent representation, on the top of which logistic classifiers trained with very few samples generalize well.",5.2. Few-shot Learning,[0],[0]
"Moreover, utilizing more expressive models such as residual network as representation mappings, is beneficial for our proposed strategy and, unlike other methods, does not result in overfitting
of the outer objective, as reported in (Mishra et al., 2018).",5.2. Few-shot Learning,[0],[0]
"Indeed, compared to C4L, RN achieves a relative improvement of 6.5% on one-shot and 4.2% on five-shot.",5.2. Few-shot Learning,[0],[0]
"Figure 5 provides a visual example of the goodness of the learned representation, showing that MiniImagenet examples (the first from meta-training, the second from the meta-testing sets) from similar classes (different dog breeds) are mapped near each other by h and, conversely, samples from dissimilar classes are mapped afar.",5.2. Few-shot Learning,[0],[0]
"In this section, we show the benefits of learning a representation within the proposed bilevel framework compared to other possible approaches that involve an explicit factorization of a classifier as gj ◦",5.3. On Variants of Representation Learning Methods,[0],[0]
h.,5.3. On Variants of Representation Learning Methods,[0],[0]
The representation mapping h is either pretrained or learned with different meta-learning algorithms.,5.3. On Variants of Representation Learning Methods,[0],[0]
We focus on the problem of one-shot learning on MiniImagenet and we use C4L as architecture for the representation mapping.,5.3. On Variants of Representation Learning Methods,[0],[0]
"In all the experiments the ground models gj are multinomial logistic regressor as in Sec. 5.2, tuned with 5 steps of gradient descent.",5.3. On Variants of Representation Learning Methods,[0],[0]
"We ran the following experiments:
• Multiclass: the mapping h : X → R64 is given by the
linear outputs before the softmax operation of a network4 pretrained on the totality of examples contained in the training meta-dataset (600 examples for each of the 64 classes).",5.3. On Variants of Representation Learning Methods,[0],[0]
"In this setting, we found that using the second last layer or the output after the softmax yields worst results;
• Bilevel-train: we use a bilevel approach but, unlike in Sec. 4, we optimize the parameter vector λ of the representation mapping by minimizing the loss on the training sets of each episode.",5.3. On Variants of Representation Learning Methods,[0],[0]
"The hypergradient is still computed with Algorithm 1, albeit we set Djval = D j tr for each training episodes;
• Approx and Approx-train: we consider an approximation of the hypergradient ∇fT",5.3. On Variants of Representation Learning Methods,[0],[0]
(λ) by disregarding the optimization dynamics of the inner objectives (i.e. we set ∇λwjT = 0).,5.3. On Variants of Representation Learning Methods,[0],[0]
"In Approx-train we just use the training sets;
• Classic: as in (Baxter, 1995), we learn h by jointly optimize f̂(λ,w1, . . .",5.3. On Variants of Representation Learning Methods,[0],[0]
", wN ) = ∑N j=1 L
j(wj , λ,Djtr) and treat the problem as standard multitask learning, with the exception that we evaluate f̂ on mini-batches of 4 episodes, randomly sampled every 5 gradient descent iterations.
",5.3. On Variants of Representation Learning Methods,[0],[0]
"In settings where we do not use the validation sets, we let the training sets of each episode contain 16 examples per class.",5.3. On Variants of Representation Learning Methods,[0],[0]
Using training episodes with just one example per class resulted in performances just above random chance.,5.3. On Variants of Representation Learning Methods,[0],[0]
"While the first experiment constitutes a standard baseline, the others have the specific aim of assessing (i) the importance of splitting episodes of meta-training set into training and validation and (ii) the importance of computing the hypergradient of the approximate bilevel problem with Algorithm 1.",5.3. On Variants of Representation Learning Methods,[0],[0]
The results reported in Table 4 suggest that both the training/validation splitting and the full computation of the hypergradient constitute key factors for learning a good representation in a meta-learning context.,5.3. On Variants of Representation Learning Methods,[0],[0]
"On the other side, using pretrained representations, especially in a low-dimensional space, turns out to be a rather effective baseline.",5.3. On Variants of Representation Learning Methods,[0],[0]
"One possible explanation is that, in this context,
4The network is similar to C4L but has 64 filters per layer.
",5.3. On Variants of Representation Learning Methods,[0],[0]
some classes in the training and testing meta-datasets are rather similar (e.g. various dog breeds) and thus ground classifiers can leverage on very specific representations.,5.3. On Variants of Representation Learning Methods,[0],[0]
We have shown that both HO and ML can be formulated in terms of bilevel programming and solved with an iterative approach.,6. Conclusions,[0],[0]
"When the inner problem has a unique solution (e.g. is strongly convex), our theoretical results show that the iterative approach has convergence guarantees, a result that is interesting in its own right.",6. Conclusions,[0],[0]
"In the case of ML, by adapting classical strategies (Baxter, 1995) to the bilevel framework with training/validation splitting, we present a method for learning hyper-representations which is experimentally effective and supported by our theoretical guarantees.
",6. Conclusions,[0],[0]
"Our framework encompasses recently proposed methods for meta-learning, such as learning to optimize, but also suggests different design patterns for the inner learning algorithm which could be interesting to explore in future work.",6. Conclusions,[0],[0]
"The resulting inner problems may not satisfy the assumptions of our convergence analysis, raising the need for further theoretical investigations.",6. Conclusions,[0],[0]
An additional future direction of research is the study of the statistical properties of bilevel strategies where outer objectives are based on the generalization ability of the inner model to new (validation) data.,6. Conclusions,[0],[0]
"Ideas from (Maurer et al., 2016; Denevi et al., 2018) may be useful in this direction.",6. Conclusions,[0],[0]
We introduce a framework based on bilevel programming that unifies gradient-based hyperparameter optimization and meta-learning.,abstractText,[0],[0]
We show that an approximate version of the bilevel problem can be solved by taking into explicit account the optimization dynamics for the inner objective.,abstractText,[0],[0]
"Depending on the specific setting, the outer variables take either the meaning of hyperparameters in a supervised learning problem or parameters of a meta-learner.",abstractText,[0],[0]
We provide sufficient conditions under which solutions of the approximate problem converge to those of the exact problem.,abstractText,[0],[0]
We instantiate our approach for meta-learning in the case of deep learning where representation layers are treated as hyperparameters shared across a set of training episodes.,abstractText,[0],[0]
"In experiments, we confirm our theoretical findings, present encouraging results for few-shot learning and contrast the bilevel approach against classical approaches for learning-to-learn.",abstractText,[0],[0]
Bilevel Programming for Hyperparameter Optimization and Meta-Learning,title,[0],[0]
"Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2398–2408, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.",text,[0],[0]
"Many model components of competitive statistical machine translation (SMT) systems are based on rather simplistic definitions with little linguistic grounding, which includes the definitions of phrase pairs, lexicalized reordering, and n-gram language models.",1 Introduction,[0],[0]
"However, earlier work has also shown that statistical MT can benefit from additional linguistically motivated models.",1 Introduction,[0],[0]
"Most prominent among the linguistically motivated approaches are syntax-based MT systems which take into account the syntactic structure of sentences through CKY decoding and categorial labels (Zollmann and Venugopal, 2006; Shen et al., 2008).",1 Introduction,[0],[0]
"On the other hand, the commonly used phrase-based SMT approaches can also reap some of the benefits of using syntactic information by
integrating linguistic components addressing specific phenomena, such as Cherry (2008), Carpuat et al. (2010), Crego and Yvon (2010), Ge (2010), Xiang et al. (2011), Lerner and Petrov (2013), Garmash and Monz (2014).
",1 Introduction,[0],[0]
This paper is a contribution to the existing body of work on how syntactically motivated models help translation performance.,1 Introduction,[0],[0]
"We work with the phrase-based SMT (PBSMT) (Koehn et al., 2003) framework as the baseline system.",1 Introduction,[0],[0]
Our choice is motivated by the fact that PBSMT is a conceptually simple and therefore flexible framework.,1 Introduction,[0],[0]
It is typically quite straightforward to integrate an additional model into the system.,1 Introduction,[0],[0]
"Also, PBSMT is the most widely used framework in the SMT research community, which ensures comparability of our results to other people’s work on the topic.
",1 Introduction,[0],[0]
There is a variety of ways syntax can be used in a PBSMT model.,1 Introduction,[0],[0]
Typically a syntactic representation of a source sentence is used to define constraints on the order in which the decoder translates it.,1 Introduction,[0],[0]
"For example, Cherry (2008) defines soft constraints based on the notion of syntactic cohesion (Section 2).",1 Introduction,[0],[0]
Ge (2010) captures reordering patterns by defining soft constraints based on the currently translated word’s POS tag and the words structurally related to it.,1 Introduction,[0],[0]
"On the other hand, target syntax is more challenging to use in PBSMT, since a target-side syntactic model does not have access to the whole target sentence at decoding.",1 Introduction,[0],[0]
"Post and Gildea (2008) is one of the few targetside syntactic approaches applicable to PBSMT, but it has been shown not to improve translation.",1 Introduction,[0],[0]
Their approach uses a target side parser as a language model: one of the reasons why it fails is that a parser assumes its input to be grammatical and chooses the most likely parse for it.,1 Introduction,[0],[0]
"What we are interested in during translation is how gram-
2398
matical the target sentence actually is.",1 Introduction,[0],[0]
"In addition to reordering constraints, source syntax can be used for target-side language modeling.",1 Introduction,[0],[0]
A target side string can be encoded with source-syntactic building blocks and then scored as to how well-formed it is.,1 Introduction,[0],[0]
"Crego and Yvon (2010), Niehues et al. (2011), Garmash and Monz (2014) model target sequences as strings of tokens built from the target POS tag and the POS tags of the source words related to it through alignment and the source parse.",1 Introduction,[0],[0]
"In this paper, we define a target-side syntactic language model that takes structural constraints from the source sentence, but uses the words from the target side (as ‘building blocks’).",1 Introduction,[0],[0]
"We do it by adapting an existing monolingual model of Chelba and Jelinek (2000), structured language models, to the bilingual setting.",1 Introduction,[0],[0]
"Our contributions can be summarized as follows:
• we propose a novel method to adapt monolingual structured language models (Chelba and Jelinek, 2000)",1 Introduction,[0],[0]
"(Section 3) to a PBSMT system (Section 4), which does not require an external on-the-fly parser, but only uses the given source-side syntactic analysis to infer structural relations between target words;
• building on the existing literature, we propose a set of deterministic rules that incrementally build up a parse of a target translation hypothesis based on the source parse (Section 4);
• we evaluate our models in a series of rescoring experiments and achieve statistically significant improvements of up to 0.7 BLEU for Chinese-English (Section 5).
",1 Introduction,[0],[0]
"Before describing the models, we motivate our method with a common assumption about crosslingual correspondence (Section 2).",1 Introduction,[0],[0]
"Before we apply the syntactic model introduced in Section 3 to the bilingual setting (Section 4), we first explain two widely used assumptions about syntactic correspondence across languages.
",2 Direct correspondence assumption and syntactic cohesion in SMT,[0],[0]
We take a dependency tree to be a syntactic representation of a sentence and reason about other syntactic assumptions and models in its terms.,2 Direct correspondence assumption and syntactic cohesion in SMT,[0],[0]
"In this work, we choose a dependency structure over a constituency structure because the former
is more primitive.1 A dependency parse D is a dependency tree analysis of a sentence W , and we will think of it as a relation between words of W , such that D(w, v) if w is a parent (head) of v (v being a child/modifier).",2 Direct correspondence assumption and syntactic cohesion in SMT,[0],[0]
"D can be generalized to D∗ which is an relation between words that are connected by a continuous path in a dependency tree (i.e. D∗(w, v) if D(w, v) or if ∃u s.t. D(w, u) ∧ D∗(u, v)).",2 Direct correspondence assumption and syntactic cohesion in SMT,[0],[0]
We assume unlabeled dependency trees.,2 Direct correspondence assumption and syntactic cohesion in SMT,[0],[0]
"Finally, we make a projectivity assumption, which is supported by empirical data in many languages (Kuhlmann and Nivre, 2006; Havelka, 2007), and makes a model computationally less expensive.",2 Direct correspondence assumption and syntactic cohesion in SMT,[0],[0]
"A dependency parse D of a sentence W = w1, . . .",2 Direct correspondence assumption and syntactic cohesion in SMT,[0],[0]
", wn is projective, if for every word pair wi, wj ∈ W s.t",2 Direct correspondence assumption and syntactic cohesion in SMT,[0],[0]
". D(wi, wj) it holds that every wk ∈ W s.t.",2 Direct correspondence assumption and syntactic cohesion in SMT,[0],[0]
i <,2 Direct correspondence assumption and syntactic cohesion in SMT,[0],[0]
k < j or j < k,2 Direct correspondence assumption and syntactic cohesion in SMT,[0],[0]
"< i is a descendant of wi, i.e., D∗(wi, wk); see Figure 1.
",2 Direct correspondence assumption and syntactic cohesion in SMT,[0],[0]
"Most NLP models that address the interaction of two or more languages are based (explicitly or implicitly) on the direct correspondence assumption (DCA) (Hwa et al., 2002).",2 Direct correspondence assumption and syntactic cohesion in SMT,[0],[0]
It states that close translation equivalents in different languages have the same dependency structure.,2 Direct correspondence assumption and syntactic cohesion in SMT,[0],[0]
"This is grounded linguistically, as translation equivalence implies semantic equivalence and therefore thematic relations are preserved (Hwa et al., 2002).",2 Direct correspondence assumption and syntactic cohesion in SMT,[0],[0]
"Thus dependency relations are preserved, as they are defined based on thematic relations between words.",2 Direct correspondence assumption and syntactic cohesion in SMT,[0],[0]
"On the other hand, there is plenty empirical evidence supporting the violation of DCA under certain conditions (Hwa et al., 2002).",2 Direct correspondence assumption and syntactic cohesion in SMT,[0],[0]
"For instance, even semantically very close sentences in different languages may have a different number of
1A dependency parse (a dependency tree analysis of a sentence) is more primitive because every constituency parse can be formalized as a projective dependency parse with labeled relations, but not vice versa (Osborne, 2008).
words.",2 Direct correspondence assumption and syntactic cohesion in SMT,[0],[0]
"Syntactic divergence increases if the two languages are typologically different.
",2 Direct correspondence assumption and syntactic cohesion in SMT,[0],[0]
"Even though DCA only holds up to a certain level of precision, it is widely used in NLP.",2 Direct correspondence assumption and syntactic cohesion in SMT,[0],[0]
"There are models of cross-lingual transfer that define syntactic structure of one language by conditioning it on the structure of semantically equivalent sentences in another language (Naseem et al., 2012).",2 Direct correspondence assumption and syntactic cohesion in SMT,[0],[0]
DCA has also been used in SMT.,2 Direct correspondence assumption and syntactic cohesion in SMT,[0],[0]
"In particular, syntax-based SMT is built implicitly around this assumption (Wu, 1997; Yamada and Knight, 2001).",2 Direct correspondence assumption and syntactic cohesion in SMT,[0],[0]
"In Quirk and Menezes (2006) DCA is explicitly implemented by defining a translation model in terms of treelet pairs where target-side treelets are produced by projecting source dependencies via word alignments.
",2 Direct correspondence assumption and syntactic cohesion in SMT,[0],[0]
"Closely related to DCA is the notion of syntactic cohesion of translation (Fox, 2002; Cherry, 2008).",2 Direct correspondence assumption and syntactic cohesion in SMT,[0],[0]
This is a constraint that does not allow for non-projective reordering:,2 Direct correspondence assumption and syntactic cohesion in SMT,[0],[0]
"Given a source parse DS , a translation W is cohesive if all translated target words wi, wj do not have any word wk between them such that there is a source subtree sub in DS such that some parts of it are translated by wi andwj but not bywk (Figure 2).",2 Direct correspondence assumption and syntactic cohesion in SMT,[0],[0]
Cherry (2008) and Bach et al. (2009) define a set of soft constraints based on the syntactic cohesion assumption which are applicable to PBSMT decoding.,2 Direct correspondence assumption and syntactic cohesion in SMT,[0],[0]
"They only require phrase applications, and not necessarily individual target words, to conform to the cohesion principle.",2 Direct correspondence assumption and syntactic cohesion in SMT,[0],[0]
"For example, if we imagine a situation where a subtree as in Figure 2(b) is translated as a whole with one phrase application (and not word by word), then it does not violate the cohesion principle, although it is internally
uncohesive.",2 Direct correspondence assumption and syntactic cohesion in SMT,[0],[0]
"Both our approach and Cherry (2008) implement the idea of conforming the target translation to the source syntactic structure, but in different ways.",2 Direct correspondence assumption and syntactic cohesion in SMT,[0],[0]
Approaches like Cherry (2008) define principles that constrain the decoder in order to produce better translations.,2 Direct correspondence assumption and syntactic cohesion in SMT,[0],[0]
Our goal is to have a model that allows for a more direct way of evaluation of how well-formed the target translation is.,2 Direct correspondence assumption and syntactic cohesion in SMT,[0],[0]
In Section 5 we compare translation performance of the two approaches.,2 Direct correspondence assumption and syntactic cohesion in SMT,[0],[0]
"As discussed in Sections 1 and 2, we would like to test how much a PBSMT can benefit from an additional syntax-based LM.",3 Structured language models,[0],[0]
"In this section, we describe a syntactic language model, structured LM (SLM) (Chelba and Jelinek, 2000), that we extend to a bilingual setting and apply to SMT in Section 4.",3 Structured language models,[0],[0]
"SLMs have been applied in SMT before (Yamada and Knight, 2001; Yu et al., 2014), but as we show in Section 4, we provide a much simpler method to integrate it into the system.",3 Structured language models,[0],[0]
"While a SLM is not the only syntactically defined LM, it is one of the few that models sentence generation sequentially.",3 Structured language models,[0],[0]
"And due to the way the decoding procedure of PBSMT is defined, it is natural and straightforward to use models whose score can be computed sequentially.",3 Structured language models,[0],[0]
"Other syntactic language models define sentence generation hierarchically (Shen et al., 2008; Sennrich, 2015), which complicates their integration into a PBSMT system.
",3 Structured language models,[0],[0]
The linguistic intuition behind SLMs is that the structural children of a word do not essentially change its distributional properties but just provide additional specification.,3 Structured language models,[0],[0]
In Figure 3(a),3 Structured language models,[0],[0]
the word president has two modifiers: the and former and it follows yesterday (an adjunct) and precedes met (a predicate).,3 Structured language models,[0],[0]
This ordering is correct in English.,3 Structured language models,[0],[0]
"If instead its modifier was a or an entire relative clause, it would not make it incorrect.
",3 Structured language models,[0],[0]
"To capture this observation, (Chelba and Jelinek, 2000) propose a language model where each word wi of a sentence W is predicted by an ordered subset of the words preceding wi.",3 Structured language models,[0],[0]
This conditioning subset is selected based on the syntactic properties of the preceding sequence Wi−1: the strong predictors are kept and the weak ones are left out.,3 Structured language models,[0],[0]
The strong predictors are the set of exposed heads.,3 Structured language models,[0],[0]
"Given a subsequence Wi−1 and its associated parseDi−1, exposed heads are the roots of all the disconnected subtrees inDi−1.",3 Structured language models,[0],[0]
"Note that
a parseDi−1 is not necessarily fully connected and thus a word can have multiple conditioning words.
",3 Structured language models,[0],[0]
"For an example, consider again Figure 3(a).",3 Structured language models,[0],[0]
"In a left-to-right scenario, when met is generated, a regular n-gram LM conditions it on yesterday the former president, while a SLM conditions it on yesterday president, since these two words are the exposed heads with respect to met (Figure 3(b)).",3 Structured language models,[0],[0]
The words the and former are modifiers of president and they get filtered out.,3 Structured language models,[0],[0]
"Thus we obtain a less specific conditioning history, which may lead to the resulting model being less sparse.",3 Structured language models,[0],[0]
"Another potential benefit is that SLMs can capture longdistance reordering: If president had as its modifier a relative clause (Figure 3(c)) then a simple n-gram LM would be conditioned on days before (assuming n = 3), while an SLM would condition met on yesterday president.
",3 Structured language models,[0],[0]
"Summarizing the ideas of words being conditioned on a structurally defined subset of the preceding sentence, Chelba and Jelinek (2000) formalize the generation process of W as follows:2 Each new word wi is conditioned on a
2The original model by (Chelba and Jelinek, 2000) is defined in terms of a lexicalized constituency grammar, but as
sequence of exposed heads Expos(W,D).",3 Structured language models,[0],[0]
"Then a tag ti is predicted, and the parse Di−i of Wi−1 is extended to Di incorporating wi and ti (where Wi−1 is the prefix of W preceding wi): p(W,D) = |W |∏ i=1",3 Structured language models,[0],[0]
"p(wi|Expos(Wi−1, Di−1))
· p(ti|wi, Expos(Wi−1, Di−1)) ·",3 Structured language models,[0],[0]
"p(Di|wi, ti, Expos(Wi−1, Di−1)).
",3 Structured language models,[0],[0]
"(1)
They use a shift-reduce parser with reduce-left, reduce-right, and shift operations.",3 Structured language models,[0],[0]
"In this section, we combine the direct correspondence assumption (Section 2) and SLMs (Section 3), and define bilingual structured language models (BiSLMs) for PBSMT.",4 Bilingual structured language models,[0],[0]
Structured LMs have been successfully applied in SMT before.,4 Bilingual structured language models,[0],[0]
"Yamada and Knight (2001) use SLMs in a stringto-tree SMT system where a derivation of a targetside parse tree is part of the decoding algorithm, and target syntactic representations are obtained ‘for free’.",4 Bilingual structured language models,[0],[0]
"Yu et al. (2014) use an on-the-fly shiftreduce parser to build an incremental target parse.
",4 Bilingual structured language models,[0],[0]
The approaches sketched above rely on resources that a standard PBSMT system does not have access to by default.,4 Bilingual structured language models,[0],[0]
"Phrase-based decoders do not provide us with a parse of the target sentence, and inferring the parse of a target string with an external parser is computationally expensive and potentially unreliable (see Section 1).",4 Bilingual structured language models,[0],[0]
Our main insight is that in a bilingual setting one does not need an additional probabilistic target parsing model.,4 Bilingual structured language models,[0],[0]
"We assume that the source parse is given (precomputed) and that the DCA (Section 2) holds, and project the parse deterministically onto the target side via word alignments3.",4 Bilingual structured language models,[0],[0]
"We obtain the following equation:
p(T |S,DS) = |T |∏ i=1",4 Bilingual structured language models,[0],[0]
"p(ti| Expos(Ti−1,
ProjP(DS , S, Ti−1)))",4 Bilingual structured language models,[0],[0]
",
(2)
where T is a target sentence, Ti−1 is the sequence in T preceding the i-th target word ti, S is a
we discussed in Section 2, constituency parses can be transformed into dependency parses.
",4 Bilingual structured language models,[0],[0]
"3Phrase-internal word alignments are stored in the phrase table and are available at decoding time, see Section 4.4.
source sentence,DS is a source dependency parse, and ProjP is a function that returns a partial target parse DT i−1 by projecting DS onto Ti−1.",4 Bilingual structured language models,[0],[0]
"In words, at each time step iwe predict the next word ti conditioned on the exposed heads of the partial parse of Ti−1 projected from the source side.",4 Bilingual structured language models,[0],[0]
"We limit Expos to returning the four preceding exposed heads.4 Because the function ProjP is deterministic and because we do not have to predict tags for words, Equation 2 is simpler than Equation 1.
",4 Bilingual structured language models,[0],[0]
We first illustrate Equation 2 with an example in Figure 4.,4 Bilingual structured language models,[0],[0]
"Since word alignment is monotonic in Figure 4(a), it is straightforward to project the source dependencies onto the target side.",4 Bilingual structured language models,[0],[0]
"We aim to imitate a monolingual parser in the way we build up our projected parse: Reduce operations should be invoked whenever both of the subtrees involved in the operation are complete, i.e., are not expected to have any more modifiers (Section 4.2).",4 Bilingual structured language models,[0],[0]
"For example, when the target word likes is produced its exposed heads are said and he (Figure 4(b)), since Putin is a modifier of said.",4 Bilingual structured language models,[0],[0]
"Likewise, the exposed heads for women are said likes all Russian (Figure 4(c)).
",4 Bilingual structured language models,[0],[0]
"In what follows we discuss how to define ProjP. Compared to projection approaches like (Quirk
4As written above, we choose the dependency structures over the lexicalized constituency ones because the latter can be mapped to the former.",4 Bilingual structured language models,[0],[0]
"It is thus more likely that a projected dependency tree is still be a well-formed parse, than a projected constituency tree.",4 Bilingual structured language models,[0],[0]
"We decided to work with structural models that are more flexible, but one may also define BiSLM in terms of the more constraining constituency trees and see if the such model has better generalization power.
and Menezes, 2006), we would like our model to project a source parse incrementally, allowing it to be used in a PBSMT decoder.",4 Bilingual structured language models,[0],[0]
"We think of ProjP as a function that computes the output in two stages: first, it infers from the source parse the dependency relations between target words (Section 4.1), second, it decides how to parse the target sequence, i.e. in which order to assign these dependencies (Section 4.2).",4 Bilingual structured language models,[0],[0]
"Additionally, in Section 4.3 we propose to use additional labelings of target words, and in Section 4.4 we describe some important implementation details.",4 Bilingual structured language models,[0],[0]
Adoption of DCA (Section 2) allows to build up a target dependency tree from a source tree by projecting the latter through word alignments.,4.1 Dependency graph projection,[0],[0]
"The definition of DCA can be rephrased as requiring a one-to-one correspondence map between words of a sentence pair, allowing one to unambiguously map dependencies:",4.1 Dependency graph projection,[0],[0]
"Given a source parse, if t1 is the head of t2, then map(t1) is the head of map(t2).",4.1 Dependency graph projection,[0],[0]
"The correspondence relation that we have in PBSMT is the word alignment align: in the most general case, it is a many-to-many correspondence, and the straightforward projection described above can lead to incorrect dependency structures.",4.1 Dependency graph projection,[0],[0]
"To overcome these problems, we describe a simple ordered set of projection rules, based on the ones specified by (Quirk and Menezes, 2006) (and we point out if otherwise).
",4.1 Dependency graph projection,[0],[0]
The general idea behind this set of rules is to extract a one-to-one function align1−1 from source words to target words from align and use it to project source dependencies as described in the paragraph above (R1 below).,4.1 Dependency graph projection,[0],[0]
We then use additional rules (R2-R4 below) for the target words that are not in align1−1.,4.1 Dependency graph projection,[0],[0]
"Given a source sentence S with a parse DS , a target sentence T and word alignment align, align1−1 is extracted as follows:",4.1 Dependency graph projection,[0],[0]
"For all ti ∈ T with multiple aligned source words {si1 , si2 , ...} only align1−1(si1) = ti (only leftmost source word is kept, the links from the rest of the source words are removed5).",4.1 Dependency graph projection,[0],[0]
"For all si ∈ S with aligned target words {ti1 , ti2 , ...} keep the link only for the leftmost aligned target word: align1−1(si) = ti1 .",4.1 Dependency graph projection,[0],[0]
"For example, in Figure 5(b)",4.1 Dependency graph projection,[0],[0]
"the link between f0 and e1 is not in align1−1, and in Figure 5(c) the link between f1 and e0 is removed (and the arc from f2 to f1 is not projected).
",4.1 Dependency graph projection,[0],[0]
"5This is an ad-hoc solution, other heuristics could be used.
",4.1 Dependency graph projection,[0],[0]
The following rules should be applied in order (as else-if conditions).,4.1 Dependency graph projection,[0],[0]
"Given a source sentence S with a parse DS , a target sentence T and word alignment align between them, ti ∈ T is a head of tj ∈ T (i.e. DT (ti, tj)): (R1) if there are sk, sl ∈ S s.t.",4.1 Dependency graph projection,[0],[0]
"DS(sk, sl) and align1−1(sk) = ti and align1−1(sl) = tj ; see Figures 5(a)-5(c); (R2) if ∃s ∈ S s.t.",4.1 Dependency graph projection,[0],[0]
"align1−1(s) = ti and (s, tj) ∈ align.",4.1 Dependency graph projection,[0],[0]
"This rule deals with one-to-many alignments; see Figure 5(d); (R3a) if ∃sk s.t. align1−1(sk) = ti and ∃sl s.t. (sl, tj) ∈ align and and DS(sl, sk), and ti linearly precedes tj .",4.1 Dependency graph projection,[0],[0]
"In words: if two target words are in align1−1 but do not get connected via R1, find a source word aligned to the second target word that may get them connected; see Figure 5(e); (R3b) same as R3a, but in case tj precedes ti (i.e., find an additional source word aligned to the first target word; see Figure 5(f)).6 (R4)",4.1 Dependency graph projection,[0],[0]
"In case ¬∃s (s, tj) ∈ align (tj is unaligned), we consider two strategies: We simplify the rule of Quirk and Menezes (2006) (dealing with the same situation) by adjoining it to the immediately preceding head.",4.1 Dependency graph projection,[0],[0]
"We also consider a strategy whereby the word remains unconnected to any word in the sentence; see Figure 5(g).
6R3a and R3b differ from the rules proposed in Quirk and Menezes (2006) dealing with the same situation, since we had to adapt it to the left-to-right parsing scenario.",4.1 Dependency graph projection,[0],[0]
"Given an inference procedure for dependency relations between target words (Section 4.1), one can specify in which order the corresponding dependency arcs are assigned to the target sentence.",4.2 BiSLM parsing procedure,[0],[0]
"We define an incremental parsing procedure in terms of three operations: shift, left-reduce, and right-reduce.",4.2 BiSLM parsing procedure,[0],[0]
The operations are applied as soon as the sufficient conditions hold: We specify the conditions using the following structural properties.,4.2 BiSLM parsing procedure,[0],[0]
A target subtree is source-complete if all the descendants of align−11−1(root(sub)),4.2 BiSLM parsing procedure,[0],[0]
(source correspondent of the root of the current subtree) (Section 4.1) have been translated and reduced.,4.2 BiSLM parsing procedure,[0],[0]
A target subtree is complete if it is source-complete and all the target words that are its children through non-projected arcs (through R2 or R4 in Section 4.1) have been translated and reduced.,4.2 BiSLM parsing procedure,[0],[0]
The bilingual parsing operations and the sufficient conditions for them are defined as follows:,4.2 BiSLM parsing procedure,[0],[0]
Shift: after the word is produced it is shifted onto the stack as an elementary subtree.,4.2 BiSLM parsing procedure,[0],[0]
"Left-reduce: if a disconnected subtree subi and a disconnected subtree subi−1 immediately preceding it are both complete and DT (root(subi), root(subi−1)), adjoin subi−1 to subi so that root(subi−1) is a modifier of root(subi).",4.2 BiSLM parsing procedure,[0],[0]
"Right-reduce: analogous to left-reduce, but DT (root(subi−1), root(subi)).
",4.2 BiSLM parsing procedure,[0],[0]
In the case of non-cohesive translation the resulting target dependencies are non-projective.,4.2 BiSLM parsing procedure,[0],[0]
Our definition of left- and right-reduce only produces projective parses.,4.2 BiSLM parsing procedure,[0],[0]
"For a non-cohesive translation, certain subtrees will never be sourcecomplete and will never be reduced; see Figure 6(a).",4.2 BiSLM parsing procedure,[0],[0]
"Note that this is not a disadvantage
of our model.",4.2 BiSLM parsing procedure,[0],[0]
"Cherry (2008) simply assumes that non-cohesive reordering should be penalized, and our model is able to learn this pattern.",4.2 BiSLM parsing procedure,[0],[0]
"We also consider an alternative to incorporating noncohesive alignments by relaxing the definition of completeness for subtrees: A projected subtree sub is weakly source-complete if all descendants of all source word(s) which are aligned to the root of sub have been translated and, only if the definition of reduce applies, reduced; see Figure 6(b).",4.2 BiSLM parsing procedure,[0],[0]
"One of the problems with SLMs in general is that at time steps i and j the sets of exposed heads for ti and tj can differ in size, which may imply different predictive power.",4.3 Syntactic labeling of tokens,[0],[0]
"To this end, we add an additional detail to our model: Each time a reduction occurs, we label the root of the subtree to which another subtree has been adjoined, thus making the conditioning history more specific.",4.3 Syntactic labeling of tokens,[0],[0]
"We use the following labelings: Reduction labeling: if a subtree is adjoint to sub from the left, then label root(sub) with LR.",4.3 Syntactic labeling of tokens,[0],[0]
"If it is adjoint from the right, then label it with RR.",4.3 Syntactic labeling of tokens,[0],[0]
"Reduction POS-labeling: same as in simple reduction labeling, but add the POS tag of the root of the reduced subtree to the label.",4.3 Syntactic labeling of tokens,[0],[0]
"To use BiSLM during decoding, one needs access to phrase-internal alignments and target POS tags.",4.4 Implementation and training,[0],[0]
"We store phrase-internal alignments and targetside POS annotations of each phrase in the phrase table, based on the most frequent internal alignment during training and the most likely targetside POS labeling t̂ given the phrase pair: t̂ = arg maxt̄ p(t̄|ē, f̄).",4.4 Implementation and training,[0],[0]
"We train BiSLMs on the parallel training data (Section 5.1) and use the Stanford dependency parser (Chang et al., 2009) for Chinese and and the Stanford constituency parser (Green and Manning, 2010) for Arabic7.",4.4 Implementation and training,[0],[0]
"POStagging of the training data is produced with the Stanford POS-tagger (Toutanova et al., 2003).",4.4 Implementation and training,[0],[0]
"We learn a 5-gram model using SRILM (Stolcke et al., 2011) with modified Kneser-Ney smoothing.",4.4 Implementation and training,[0],[0]
"To evaluate the effectiveness of BiSLMs for PBSMT, we performed rescoring experiments for
7We extract dependency parses from its output based on Collins (1999)
Arabic-English and Chinese-English.",5 Experiments,[0],[0]
We compare the resulting 1-best translation lists with an output of the baseline system and the baseline augmented with soft cohesion constraints from Bach et al. (2009).,5 Experiments,[0],[0]
This section provides information about our baseline system.,5.1 Experimental setup,[0],[0]
Word-alignment is produced with GIZA++,5.1 Experimental setup,[0],[0]
"(Och and Ney, 2003).",5.1 Experimental setup,[0],[0]
"We use an inhouse implementation of a PBSMT system similar to Moses (Koehn et al., 2007).",5.1 Experimental setup,[0],[0]
"Our baseline has all standard PBSMT features including language model, lexical weighting, and lexicalized reordering.",5.1 Experimental setup,[0],[0]
The distortion limit is set to 5.,5.1 Experimental setup,[0],[0]
A 5-gram LM is trained on the English Gigaword corpus (1.6B tokens) using SRILM with modified Kneser-Ney smoothing and linear interpolation.,5.1 Experimental setup,[0],[0]
"Information about the training data for the Arabic-English and Chinese-English systems is in Table 3.8 Feature weights are tuned using pairwise ranking optimization (Hopkins and May, 2011) on the MT04 benchmark (for both language pairs).",5.1 Experimental setup,[0],[0]
"For testing, we use MT08 and MT09 for Arabic, and MT06 and MT08 for Chinese.",5.1 Experimental setup,[0],[0]
"We use case-insensitive BLEU (Papineni et al., 2002) as evaluation metric.",5.1 Experimental setup,[0],[0]
"Approximate randomization (Noreen, 1989; Riezler and Maxwell, 2005) is used to detect statistically significant differences.",5.1 Experimental setup,[0],[0]
"As a comparison model, we implemented six features from Cherry (2008) and Bach et al. (2009)9 and added them to the log-linear interpolation used 8The standard LDC corpora were used for training.",5.2 Baseline and comparison systems,[0],[0]
"9Exhaustive and non-exhaustive interruption check, exhaustive and non-exhaustive interruption count, verb- and noun-dominated subtree interruption count.
by the baseline system.",5.2 Baseline and comparison systems,[0],[0]
"Since these features are binary or count-based, we cannot use them directly in rescoring.",5.2 Baseline and comparison systems,[0],[0]
For that reason we integrated the features into the decoder and tuned the corresponding weights.,5.2 Baseline and comparison systems,[0],[0]
"The results for Chinese-English and Arabic-English translation experiments are presented in Table 1 and 2, respectively.",5.2 Baseline and comparison systems,[0],[0]
We see that adding the cohesion constraints does not improve performance.,5.2 Baseline and comparison systems,[0],[0]
"This finding is different from, for example, Feng et al. (2010), where they get improvement for Chinese-English: however, we note that their training set is smaller than ours, and their baseline is weaker as it does not contain lexicalized distortion models.",5.2 Baseline and comparison systems,[0],[0]
Rescoring with BiSLMs is performed as follows: For the test runs of the baseline system we compute the n = 1000 best translation hypotheses for each source sentence and extract their derivations (sequence of phrase pair applications).,5.3 Rescoring experiments,[0],[0]
Each phrase pair in our implementation is associated with a unique phrase-internal alignment and target POS-sequence.,5.3 Rescoring experiments,[0],[0]
We fully reconstruct wordalignment for each pair of a source sentence and its translation hypothesis.,5.3 Rescoring experiments,[0],[0]
We project a precomputed source parse onto the target side and compute representations of the target sentence to be computed by a BiSLM.,5.3 Rescoring experiments,[0],[0]
"For each hypothesis, we take its BiSLM score and its score assigned by the baseline system and compute the final score as a weighted sum of the original baseline score and a length-normalized BiSLM score10, where the weight λ is empirically set to 0.3:
λ · scoreBiSLM lengthHypothesis + (1− λ) · scoreBaseline (3)",5.3 Rescoring experiments,[0],[0]
"Our main focus here is Chinese-English, since it has more instances of longer-distance reordering, at which syntax-based models are typically good.
",5.3.1 Chinese-English,[0],[0]
"10Normalization is needed to ensure comparability of scores for translation hypotheses of different lengths, since longer translation hypotheses will have lower scores.
",5.3.1 Chinese-English,[0],[0]
SLMs by design are good at capturing longerdistance dependencies.,5.3.1 Chinese-English,[0],[0]
We try out several variations of BiSLM.,5.3.1 Chinese-English,[0],[0]
"First, we test whether to use a strong or weak definition of a complete subtree (Section 4.2).",5.3.1 Chinese-English,[0],[0]
"Second, we investigate whether to adjoin unaligned target words to a preceding head (Section 4.1; unalign-adjoin+/-).",5.3.1 Chinese-English,[0],[0]
"Third, we compare several target-side labeling methods (Section 4.3): plain (just target words), reduce (LR or RR) or reduce-POS (LR POS or RR POS, where POS is the tag of the root of the reduced subtree).",5.3.1 Chinese-English,[0],[0]
"The rescoring results are presented in Table 4.
",5.3.1 Chinese-English,[0],[0]
The results show statistically significant improvement over the baseline of up to 0.7 BLEU (for all of the employed BiSLM variants except one).,5.3.1 Chinese-English,[0],[0]
The rescoring experiments also demonstrate the tendency of the unalign-adjoin- feature value to produce higher scores than unalign-adjoin+.,5.3.1 Chinese-English,[0],[0]
But the other two distinguishing features do not have an effect on BLEU scores.,5.3.1 Chinese-English,[0],[0]
"As future work, we are interested in examining if these features produce the same distribution of scores when a BiSLM is fully integrated into the decoder.",5.3.1 Chinese-English,[0],[0]
We also rescore the n-best lists for the output of the Arabic-English baseline system and results are shown in Table 5.,5.3.2 Arabic-English,[0],[0]
"Arabic and English are typologically very different, but the range of reordering is much smaller than for Chinese-English.",5.3.2 Arabic-English,[0],[0]
"We expect reordering-related models to have lesser effect on Arabic as compared to Chinese (Carpuat et al., 2010).",5.3.2 Arabic-English,[0],[0]
Experimental results on ArabicEnglish could indicate what kind of translation aspect benefits from BiSLMs.,5.3.2 Arabic-English,[0],[0]
"We see that for Arabic-English, just as for the cohesion constraint, BiSLM have little effect on BLEU scores, or even decrease them.",5.3.2 Arabic-English,[0],[0]
This is a weak indication that BiSLMs are better at capturing reordering aspects.,5.3.2 Arabic-English,[0],[0]
"As for the varying features defining different BiSLM versions, we again see little effect of the labeling type or subtree completeness definition.",5.3.2 Arabic-English,[0],[0]
"On the other hand, we see the opposite pattern for the unalign-adjoin feature, where unalign-adjoin+ is preferred.
",5.3.2 Arabic-English,[0],[0]
"To gain further insight into the different effect of BiSLM on the two language pairs, we evaluated our experimental output against a reorderingsensitive metric LRscore (Birch et al., 2010).",5.3.2 Arabic-English,[0],[0]
We use the version of LRscore which is an average of the inverse Kendall’s Tau distance and the Hamming distance.,5.3.2 Arabic-English,[0],[0]
In order to compute alignments for test sets which are needed to compute the score we concatenated the parallel text with an additional 250K lines of parallel text from the training data to ensure better generalization of the alignment algorithm (GIZA++).,5.3.2 Arabic-English,[0],[0]
"The LRscores of the baseline are compared to the best performing BiSLM system with respect to BLEU, for each of the language pair.",5.3.2 Arabic-English,[0],[0]
"The results are provided in Tables 6 and 7.
",5.3.2 Arabic-English,[0],[0]
"As expected, the scores for Chinese-English are much lower than for Arabic-English, which is consistent with the observation reordering is more difficult for Chinese-English.",5.3.2 Arabic-English,[0],[0]
BiSLM yields larger improvements for Chinese-English suggesting that the proposed model helps addressing difficult reordering problems.,5.3.2 Arabic-English,[0],[0]
While there are also small improvements for Arabic-English the they may be too small to be detectable by BLEU.,5.3.2 Arabic-English,[0],[0]
In this paper we proposed a novel way to adapt structured language models to phrase-based SMT.,6 Conclusions,[0],[0]
Our method requires minimal changes to the PBSMT pipeline.,6 Conclusions,[0],[0]
"We tried a number of variations of our model and evaluated them in rescoring experiments, resulting in statistically significant improvement for Chinese-English.",6 Conclusions,[0],[0]
The model is based on the idea of syntactic transfer (DCA; Section 2) and the positive result indicates its ability to capture syntactic patterns across languages.,6 Conclusions,[0],[0]
"For Arabic-English, we did not observe any improvements, suggesting that our models indeed mainly improve reordering aspects.",6 Conclusions,[0],[0]
Improvements in rescoring are a positive indication that our model may be a strong feature during decoding.,6 Conclusions,[0],[0]
"As future work, we will fully integrate our model into a PBSMT decoder and evaluate it on other language pairs with different reordering distributions.",6 Conclusions,[0],[0]
We thank the reviewers for their useful comments.,Acknowledgments,[0],[0]
This research was funded in part by the Netherlands Organization for Scientific Research (NWO) under project numbers 639.022.213 and 612.001.218.,Acknowledgments,[0],[0]
"This paper describes a novel target-side syntactic language model for phrase-based statistical machine translation, bilingual structured language model.",abstractText,[0],[0]
"Our approach represents a new way to adapt structured language models (Chelba and Jelinek, 2000) to statistical machine translation, and a first attempt to adapt them to phrasebased statistical machine translation.",abstractText,[0],[0]
We propose a number of variations of the bilingual structured language model and evaluate them in a series of rescoring experiments.,abstractText,[0],[0]
"Rescoring of 1000-best translation lists produces statistically significant improvements of up to 0.7 BLEU over a strong baseline for Chinese-English, but does not yield improvements for ArabicEnglish.",abstractText,[0],[0]
Bilingual Structured Language Models for Statistical Machine Translation,title,[0],[0]
"Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 2306–2312, Austin, Texas, November 1-5, 2016. c©2016 Association for Computational Linguistics",text,[0],[0]
"Discovering the discourse relation between two sentences is crucial to understanding the meaning of a coherent text, and also beneficial to many downstream NLP applications, such as question answering and machine translation.",1 Introduction,[0],[0]
Implicit discourse relation recognition (DRRimp) remains a challenging task due to the absence of strong surface clues like discourse connectives (e.g. but).,1 Introduction,[0],[0]
"Most work resorts to large amounts of manually designed features (Soricut and Marcu, 2003; Pitler et al., 2009; Lin et al., 2009; Louis et al., 2010; Rutherford and Xue, 2014), or distributed features learned via neural network models (Braud and Denis, 2015; Zhang et al., 2015; Ji and Eisenstein, 2015).",1 Introduction,[0],[0]
"The above methods usually suffer from limited labeled data.
",1 Introduction,[0],[0]
"Marcu and Echihabi (2002) attempt to create labeled implicit data automatically by removing connectives from explicit instances, as additional training data.",1 Introduction,[0],[0]
"These data are usually called as syn-
∗Corresponding author.
",1 Introduction,[0],[0]
thetic implicit data (hereafter SynData).,1 Introduction,[0],[0]
"However, Sporleder and Lascarides (2008) argue that SynData has two drawbacks: 1) meaning shifts in some cases when removing connectives, and 2) a different word distribution with the real implicit data.",1 Introduction,[0],[0]
They also show that using SynData directly degrades the performance.,1 Introduction,[0],[0]
"Recent work seeks to derive valuable information from SynData while filtering noise, via domain adaptation (Braud and Denis, 2014; Ji et al., 2015), classifying connectives (Rutherford and Xue, 2015) or multi-task learning (Lan et al., 2013; Liu et al., 2016), and shows promising results.
",1 Introduction,[0],[0]
"Different from previous work, we propose to construct bilingually-constrained synthetic implicit data (called BiSynData) for DRRimp, which can alleviate the drawbacks of SynData.",1 Introduction,[0],[0]
Our method is inspired by the findings that a discourse instance expressed implicitly in one language may be expressed explicitly in another.,1 Introduction,[0],[0]
"For example, Zhou and Xue
2306
(2012) show that the connectives in Chinese omit much more frequently than those in English with about 82.0% vs. 54.5%.",1 Introduction,[0],[0]
Li et al. (2014a) further argue that there are about 23.3% implicit/explicit mismatchs between Chinese/English instances.,1 Introduction,[0],[0]
"As illustrated in Figure 1, a Chinese implicit instance where the connective ´ is absent, is translated into an English explicit one with the connective but.",1 Introduction,[0],[0]
"Intuitively, the Chinese instance is a real implicit one which can be signaled by but.",1 Introduction,[0],[0]
"Hence, it could potentially serve as additional training data for the Chinese DRRimp, avoiding the different word distribution problem of SynData.",1 Introduction,[0],[0]
"Meanwhile, for the English explicit instance, it is very likely that removing but would not lose any information since its Chinese counterpart ´ can be omitted.",1 Introduction,[0],[0]
"Therefore it could be used for the English DRRimp, alleviating the meaning shift problem of SynData.
We extract our BiSynData from a ChineseEnglish sentence-aligned corpus (Section 2).",1 Introduction,[0],[0]
Then we design a multi-task neural network model to incorporate the BiSynData (Section 3).,1 Introduction,[0],[0]
"Experimental results, on both the English PDTB (Prasad et al., 2008) and Chinese CDTB (Li et al., 2014b), show that BiSynData is more effective than SynData used in previous work (Section 4).",1 Introduction,[0],[0]
"Finally, we review the related work (Section 5) and draw conclusions (Section 6).",1 Introduction,[0],[0]
"Formally, given a Chinese-English sentence pair (Sch, Sen), we try to find an English explicit instance (Arg1en, Arg2en, Connen) in Sen1, and a Chinese implicit instance (Arg1ch, Arg2ch) in Sch, where (Arg1en, Arg2en, Connen) is the translation of (Arg1ch, Arg2ch).",2 BiSynData,[0],[0]
"In most cases, discourse relations should be preserved during translating, so the connective Connen is potentially a strong indicator of the discourse relation between not only Arg1en and Arg2en, but also Arg1ch and Arg2ch.",2 BiSynData,[0],[0]
"Therefore, we can construct two synthetic implicit instances labeled by Connen, denoted as 〈(Arg1en, Arg2en), Connen〉 and 〈(Arg1ch, Arg2ch), Connen〉, respectively.",2 BiSynData,[0],[0]
"We refer to these synthetic instances as BiSynData be-
1In our experiments, we use the pdtb-parser toolkit (Lin et al., 2014) to identify English explicit instances.
cause they are constructed according to the bilingual implicit/explicit mismatch.
",2 BiSynData,[0],[0]
"In our experiments, we extract our BiSynData from a combined corpus (FBIS and HongKong Law), with about 2.38 million Chinese-English sentence pairs.",2 BiSynData,[0],[0]
"We generate 30,032 synthetic English instances and the same number of Chinese instances, with 80 connectives, as our BiSynData.",2 BiSynData,[0],[0]
"Table 1 lists the top 10 most frequent connectives in our BiSynData, which are roughly consistent with the statistics of Chinese/English implicit/explicit mismatches in (Li et al., 2014a).",2 BiSynData,[0],[0]
"According to connectives and their related relations in the PDTB, in most cases, and and also indicate the Expansion relation, if and because the Contigency relation, before the Temporal relation, and but the Comparison relation.",2 BiSynData,[0],[0]
"Connectives as, when, while and since are ambiguous.",2 BiSynData,[0],[0]
"For example, while can indicate the Comparison or Temporal relation.",2 BiSynData,[0],[0]
"Overall, our constructed BiSynData covers all four main discourse relations defined in the PDTB.
",2 BiSynData,[0],[0]
"With our BiSynData, we define two connective classification tasks: 1) given (Arg1en, Arg2en) to predict the connective Connen, and 2) given (Arg1ch, Arg2ch) to predict Connen.",2 BiSynData,[0],[0]
"We incorporate the first task to help the English DRRimp, and the second for the Chinese DRRimp.",2 BiSynData,[0],[0]
It is worthy to note that we use English connectives themselves as classification labels rather than mapping them to relations in both tasks.,2 BiSynData,[0],[0]
"We design a Multi-task Neural Network Model (denoted as MTN ), which incorporates a connective classification task on BiSynData (auxiliary task) to benefit DRRimp (main task).",3 Multi-Task Neural Network Model,[0],[0]
"In general, the more related two tasks are, the more powerful a multi-task learning method will be.",3 Multi-Task Neural Network Model,[0],[0]
"In the current problem, the
2307
two tasks are essentially the same, just with different output labels.",3 Multi-Task Neural Network Model,[0],[0]
"Therefore, as illustrated in Figure 2, MTN shares parameters in all feature layers (L1-L3) and uses two separate classifiers in the classifier layer (L4).",3 Multi-Task Neural Network Model,[0],[0]
"For each task, given an instance (Arg1, Arg2), MTN simply averages embeddings of words to represent arguments, as vArg1 and vArg2 .",3 Multi-Task Neural Network Model,[0],[0]
These two vectors are then concatenated and transformed through two non-linear hidden layers.,3 Multi-Task Neural Network Model,[0],[0]
"Finally, the corresponding softmax layer is used to perform classification.
",3 Multi-Task Neural Network Model,[0],[0]
MTN ignores the word order in arguments and uses two hidden layers to capture the interactions between two arguments.,3 Multi-Task Neural Network Model,[0],[0]
"The idea behind MTN is borrowed from (Iyyer et al., 2015), where a deep averaging network achieves close to the state-ofthe-art performance on text classification.",3 Multi-Task Neural Network Model,[0],[0]
"Though MTN is simple, it is easy to train and efficient on both memory and computational cost.",3 Multi-Task Neural Network Model,[0],[0]
"In addition, the simplicity of MTN allows us to focus on measuring the quality of BiSynData.
",3 Multi-Task Neural Network Model,[0],[0]
"We use the cross-entropy loss function and minibatch AdaGrad (Duchi et al., 2011) to optimize parameters.",3 Multi-Task Neural Network Model,[0],[0]
Pre-trained word embeddings are fixed.,3 Multi-Task Neural Network Model,[0],[0]
We find that fine-tuning word embeddings during training leads to severe overfitting in our experiments.,3 Multi-Task Neural Network Model,[0],[0]
"Following Liu et al. (2016), we alternately use two tasks to train the model, one task per epoch.",3 Multi-Task Neural Network Model,[0],[0]
"For tasks on both the PDTB and CDTB, we use the same hyper-parameters.",3 Multi-Task Neural Network Model,[0],[0]
The dimension of word embedding is 100.,3 Multi-Task Neural Network Model,[0],[0]
"We set the size of L2 to 200, and L3 to 100.",3 Multi-Task Neural Network Model,[0],[0]
ReLU is used as the non-linear function.,3 Multi-Task Neural Network Model,[0],[0]
"Different learning rates 0.005 and 0.001 are used in the main and auxiliary tasks, respectively.",3 Multi-Task Neural Network Model,[0],[0]
"To avoid overfitting, we randomly drop out 20% words
in each argument following Iyyer et al. (2015).",3 Multi-Task Neural Network Model,[0],[0]
All hyper-parameters are tuned on the development set.,3 Multi-Task Neural Network Model,[0],[0]
We evaluate our method on both the English PDTB and Chinese CDTB data sets.,4 Experiments,[0],[0]
"We tokenize English data and segment Chinese data using the Stanford CoreNLP toolkit (Manning et al., 2014).",4 Experiments,[0],[0]
"The English/Chinese Gigaword corpus (3rd edition) is used to train the English/Chinese word embeddings via word2vec (Mikolov et al., 2013), respectively.",4 Experiments,[0],[0]
"Due to the skewed class distribution of test data (see Section 4.1), we use the macro-averaged F1 for performance evaluation.",4 Experiments,[0],[0]
"Following Rutherford and Xue (2015), we perform a 4-way classification on the top-level discourse relations: Temporal (Temp), Comparison (Comp), Contigency (Cont) and Expansion (Expa).",4.1 On the PDTB,[0],[0]
"Sections 2-20 are used as training set, sections 0-1 as development set and sections 21-22 as test set.",4.1 On the PDTB,[0],[0]
"The training/test set contains 582/55 instances for Temp, 1855/145 for Comp, 3235/273 for Cont and 6673/538 for Expa.",4.1 On the PDTB,[0],[0]
"The top 20 most frequent connectives in our BiSynData are considered in the auxiliary task, with 28,013 synthetic English instances in total.
",4.1 On the PDTB,[0],[0]
"Table 2 shows the results of MTN combining our BiSynData (denoted as MTNbi) on the PDTB.
2308
STN means we train MTN with only the main task.",4.1 On the PDTB,[0],[0]
"On the macro F1, MTNbi gains an improvement of 4.17% over STN .",4.1 On the PDTB,[0],[0]
The improvement is significant under one-tailed t-test (p<0.05).,4.1 On the PDTB,[0],[0]
"A closer look into the results shows that MTNbi performs better across all relations, on the precision, recall and F1 score, except a little drop on the recall of Cont.",4.1 On the PDTB,[0],[0]
The reason for the recall drop of Cont is not clear.,4.1 On the PDTB,[0],[0]
"The greatest improvement is observed on Comp, up to 6.36% F1 score.",4.1 On the PDTB,[0],[0]
"The possible reason is that only while is ambiguous about Comp and Temp, while as, when and since are all ambiguous about Temp and Cont, among top 10 connectives in our BiSynData.",4.1 On the PDTB,[0],[0]
Meanwhile the amount of labeled data for Comp is relatively small.,4.1 On the PDTB,[0],[0]
"Overall, using BiSynData under our multi-task model achieves significant improvements on the English DRRimp.",4.1 On the PDTB,[0],[0]
"We believe the reasons for the improvements are twofold: 1) the added synthetic English instances from our BiSynData can alleviate the meaning shift problem, and 2) a multi-task learning method is helpful for addressing the different word distribution problem between implicit and explicit data.
",4.1 On the PDTB,[0],[0]
"Considering some of the English connectives (e.g., while) are highly ambiguous, we compare our method with ones that uses only unambiguous connectives.",4.1 On the PDTB,[0],[0]
"Specifically, we first discard as, when, while and since in top 20 connectives, and get 22,999 synthetic instances.",4.1 On the PDTB,[0],[0]
"Then, we leverage these instances in two different ways: 1) using them in our multi-task model as above, and 2) using them as additional training data directly after mapping unambiguous connectives into relations.",4.1 On the PDTB,[0],[0]
Both methods using only unambiguous connectives do not achieve better performance.,4.1 On the PDTB,[0],[0]
"One possible reason is that these synthetic instances become more unbalanced after discarding ones with ambiguous connectives.
",4.1 On the PDTB,[0],[0]
We also compare MTNbi with recent systems using additional training data.,4.1 On the PDTB,[0],[0]
"Rutherford and Xue (2015) select explicit instances that are similar to the implicit ones via connective classification, to enrich the training data.",4.1 On the PDTB,[0],[0]
"Liu et al. (2016) use a multi-task model with three auxiliary tasks: 1) conn: connective classification on explicit instances, 2) exp: relation classification on the labeled explicit instances in the PDTB, and 3) rst: relation classification on the labeled RST corpus (William and Thompson,
1988), which defines different discourse relations with that in the PDTB.",4.1 On the PDTB,[0],[0]
The results are shown in Table 3.,4.1 On the PDTB,[0],[0]
"Although Liu et al. (2016) achieve the stateof-the-art performance (Line 5), they use two additional labeled corpora.",4.1 On the PDTB,[0],[0]
"We can find that MTNbi (Line 6) yields better results than those systems incorporating SynData (Line 1, 2 and 3), or even the labeled RST (Line 4).",4.1 On the PDTB,[0],[0]
These results confirm that BiSynData can indeed alleviate the disadvantages of SynData effectively.,4.1 On the PDTB,[0],[0]
"Four top-level relations are defined in the CDTB, including Transition (Tran), Causality (Caus), Explanation (Expl) and Coordination (Coor).",4.2 On the CDTB,[0],[0]
"We use instances in the first 50 documents as test set, second 50 documents as development set and remaining 400 documents as training set.",4.2 On the CDTB,[0],[0]
We conduct a 3-way classification because of only 39 instances for Tran.,4.2 On the CDTB,[0],[0]
"The training/test set contains 682/95 instances for Caus, 1143/126 for Expl and 2300/347 for Coor.",4.2 On the CDTB,[0],[0]
"The top 20 most frequent connectives (excluding and)2 in our BiSynData are considered in the auxiliary task, with 13,899 synthetic Chinese instances in total.",4.2 On the CDTB,[0],[0]
The results are shown in Table 4.,4.2 On the CDTB,[0],[0]
"Compared with STN , MTNbi raises the macro F1 from 55.44% to 58.28%.",4.2 On the CDTB,[0],[0]
The improvement is significant under one-tailed t-test (p<0.05).,4.2 On the CDTB,[0],[0]
"Therefore, BiSynData is also helpful for the Chinese DRRimp.
",4.2 On the CDTB,[0],[0]
"Because of no reported results on the CDTB, we use MTN with two different auxiliary tasks as baselines: 1) exp: relation classification on the labeled
2Including and degrades the performance slightly.",4.2 On the CDTB,[0],[0]
"A possible reason is that and can be related to both the Expl and Coor relations in the CDTB, and instances marked by and account for about half of our BiSynData.
2309
explicit instances in the CDTB, including 466 instances for Caus, 201 for Expl and 974 for Coor.",4.2 On the CDTB,[0],[0]
2) conn: connective classification on explicit instances from the Xinhua part of the Chinese Gigaword corpus.,4.2 On the CDTB,[0],[0]
"We collect explicit instances with the top 20 most frequent Chinese connectives and sample 20,000 instances for the experiment.",4.2 On the CDTB,[0],[0]
Both exp and conn can be considered as tasks on SynData.,4.2 On the CDTB,[0],[0]
"The results in Table 5 show that MTN incorporating BiSynData (Line 3) performs better than using SynData (Line 1 and 2), for the task on the CDTB.",4.2 On the CDTB,[0],[0]
One line of research related to DRRimp tries to take advantage of explicit discourse data.,5 Related Work,[0],[0]
Zhou et al. (2010) predict the absent connectives based on a language model.,5 Related Work,[0],[0]
Using these predicted connectives as features is proven to be helpful.,5 Related Work,[0],[0]
"Biran and McKeown (2013) aggregate word-pair features that are collected around the same connectives, which can effectively alleviate the feature sparsity problem.",5 Related Work,[0],[0]
"More recently, Braud and Denis (2014) and Ji et al. (2015) consider explicit data from a different domain, and use domain adaptation methods to explore the effect of them.",5 Related Work,[0],[0]
"Rutherford and Xue (2015) propose to gather weakly labeled data from explicit instances via connective classification, which are
used as additional training data directly.",5 Related Work,[0],[0]
Lan et al. (2013) and Liu et al. (2016) combine explicit and implicit data using multi-task learning models and gain improvements.,5 Related Work,[0],[0]
"Different from all the above work, we construct additional training data from a bilingual corpus.
",5 Related Work,[0],[0]
Multi-task neural networks have been successfully used for many NLP tasks.,5 Related Work,[0],[0]
"For example, Collobert et al. (2011) jointly train models for the Partof-Speech tagging, chunking, named entity recognition and semantic role labeling using convolutional network.",5 Related Work,[0],[0]
Liu et al. (2015) successfully combine the tasks of query classification and ranking for web search using a deep multi-task neural network.,5 Related Work,[0],[0]
"Luong et al. (2016) explore multi-task sequence to sequence learning for constituency parsing, image caption generation and machine translation.",5 Related Work,[0],[0]
"In this paper, we introduce bilingually-constrained synthetic implicit data (BiSynData), which are generated based on the bilingual implicit/explicit mismatch, into implicit discourse relation recognition for the first time.",6 Conclusion,[0],[0]
"On both the PDTB and CDTB, using BiSynData as the auxiliary task significantly improves the performance of the main task.",6 Conclusion,[0],[0]
We also show that BiSynData is more beneficial than the synthetic implicit data typically used in previous work.,6 Conclusion,[0],[0]
"Since the lack of labeled data is a major challenge for implicit discourse relation classification, our proposed BiSynData can enrich the training data and then benefit future work.",6 Conclusion,[0],[0]
We would like to thank all the reviewers for their constructive and helpful suggestions on this paper.,Acknowledgments,[0],[0]
"This work is partially supported by the Natural Science Foundation of China (Grant Nos. 61573294, 61303082, 61672440), the Ph.D. Programs Foundation of Ministry of Education of China (Grant No. 20130121110040), the Fund of Research Project of Tibet Autonomous Region of China (Grant No. Z2014A18G2-13), and the Natural Science Foundation of Fujian Province (Grant No. 2016J05161).
2310",Acknowledgments,[0],[0]
"To alleviate the shortage of labeled data, we propose to use bilingually-constrained synthetic implicit data for implicit discourse relation recognition.",abstractText,[0],[0]
These data are extracted from a bilingual sentence-aligned corpus according to the implicit/explicit mismatch between different languages.,abstractText,[0],[0]
"Incorporating these data via a multi-task neural network model achieves significant improvements over baselines, on both the English PDTB and Chinese CDTB data sets.",abstractText,[0],[0]
Bilingually-constrained Synthetic Data for Implicit Discourse Relation Recognition,title,[0],[0]
"Binary classification, with the goal of predicting a binary response given input features, is perhaps the classical problem in machine learning, with wide ranging applications.",1. Introduction,[0],[0]
"A key ingredient in binary classification is a performance measure, that quantifies how well a given classifier fits the data.",1. Introduction,[0],[0]
"While the performance measure of accuracy has been the predominant focus of both theory and practice, it has severe limitations in many practical settings, such as imbal-
1University of Texas at Austin, Austin, Texas, USA 2University of Illinois at Urbana-Champaign, Champaign, Illinois, USA 3Carnegie Mellon University, Pittsburgh, Pennsylvania, USA.",1. Introduction,[0],[0]
"Correspondence to: Bowei Yan <boweiy@utexas.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"anced classes, and where different types of errors made by the classifier have different costs (Gu et al., 2009; Wallace et al., 2011).",1. Introduction,[0],[0]
"Accordingly, practitioners in applied machine learning settings such as information retrieval and medical diagnosis have developed complex performance metrics that capture important trade-offs between different types of errors; we have collated a few instances in Table 1.",1. Introduction,[0],[0]
"A key complication with many complex classification performance metrics, such as the F-measure (Manning et al., 2008) and Harmonic Mean (Kennedy et al., 2009), is that they cannot be decomposed into the sum or average of individual losses on each sample.",1. Introduction,[0],[0]
"Even the simple performance measure of precision — the fraction of correct positive predictions, among the set of positive predictions — is not a sum of individual losses on each sample.",1. Introduction,[0],[0]
"Thus, the standard theoretical and practical treatments of supervised learning, such as standard empirical risk minimization that minimizes the empirical expectation of a loss evaluated on a single random example, are not applicable.
",1. Introduction,[0],[0]
This practical reality has motivated research into effective and efficient algorithms tailored to complex nondecomposable performance measures.,1. Introduction,[0],[0]
"One class of approaches extend standard empirical risk minimization to this non-decomposable setting, which often relies on strong assumptions on either the form of the classifiers, such as requiring linear classifiers (Narasimhan et al., 2015a), or restricted to specific performance measures such as F-measure (Parambath et al., 2015).",1. Introduction,[0],[0]
"An alternative approach is the plug-in estimator, where we first derive the form of the Bayes optimal classifier, estimate the statistical quantities associated with the Bayes optimal classifier, and finally “plug-in” the sample estimates of the population quantities to then obtain the overall estimate of the Bayes optimal classifier.",1. Introduction,[0],[0]
"In particular, for many complex performance metrics, the Bayes optimal classifier is simply a thresholding of the conditional probability of the positive class (Koyejo et al., 2014; Narasimhan et al., 2014), so that the plug-in estimator requires (a) an estimate of the conditional probability, and (b) the associated threshold.",1. Introduction,[0],[0]
"Plug-in methods have been of particular interest in non-parametric functional estimation as they typically require weaker assumptions on the function class and are often easy to implement.
",1. Introduction,[0],[0]
"In this paper, we seek to advance our understanding and practice of binary classification under complex non-
decomposable performance measures.",1. Introduction,[0],[0]
"We show that for a very broad class of performance measures, encompassing a large set of performance measures used in practice, the Bayes optimal classifier is simply a thresholding of the conditional probability of the response.",1. Introduction,[0],[0]
"Towards this general result, we identify two key properties that a performance measure could satisfy.",1. Introduction,[0],[0]
"The first is what we call a “Karmic” property that loosely has the performance measure be more sensitive to an increase in true positives and true negatives, and a decrease in false positives and false negatives.",1. Introduction,[0],[0]
"The second is a more technical property we call threshold-quasiconcavity, which in turn ensures the performance measure is well-behaved around an optimal threshold.",1. Introduction,[0],[0]
"As we show these properties are satisfied by performance metrics used in practice, and in particular, these conditions are milder than existing results that restrict either the structural form of the performance measures, or impose strong shape constraints such as particular monotonicities.
",1. Introduction,[0],[0]
"Our general result has two main consequences, which we investigate further: one algorithmic, and the other for the analysis of classification error for general performance measures.",1. Introduction,[0],[0]
"As the algorithmic consequence, we leverage the derived form of the Bayes optimal classifier, and some additional general assumptions on the performance measures, to provide a tractable algorithm to estimate the threshold, which coupled with an estimator of the conditional probability, provides a tractable “plug-in estimator” of the Bayes optimal classifier.",1. Introduction,[0],[0]
"Towards the statistical analysis consequence, we provide an analysis of the excess classification error, but with respect to general non-decomposable performance measures, of the general class of plugin-estimators for our class of Bayes optimal classifiers.",1. Introduction,[0],[0]
"Our analysis of classification error rates for such plug-in classifiers depend on three natural quantities: the rate of convergence for the conditional probability estimate, the rate of convergence for the threshold estimate, and a measurement of noise in the data.",1. Introduction,[0],[0]
"For the last part, we extend margin or low-noise assumptions for binary classification with the accuracy performance measure to complex performance measures.",1. Introduction,[0],[0]
"Low noise assumptions, proposed by Mammen et al. (1999) in the context of the accuracy performance measure, bounds the noise level in the neighborhood of the Bayes optimal threshold i.e. 12 for standard classification.",1. Introduction,[0],[0]
"Under such a low-noise assumption, Audibert et al. (2007) derive fast convergence rates for plug-in classification rules based on the smoothness of the conditional probability function.",1. Introduction,[0],[0]
Similar margin assumptions have also been introduced for density level set estimation by Polonik (1995).,1. Introduction,[0],[0]
"We provide a natural extension of such a low-noise assumption, under which we provide explicit rates of convergence of classification error with respect to complex performance measures.",1. Introduction,[0],[0]
"We provide corollaries for both parametric and non-parametric instances of our general class of plugin-classifiers.
",1. Introduction,[0],[0]
The rest of the paper is organized as below.,1. Introduction,[0],[0]
In Section 2 we introduce the problem and relevant notations.,1. Introduction,[0],[0]
The characterization and properties of Bayes optimal classifier are derived in Section 3.,1. Introduction,[0],[0]
"We discuss the algorithm for estimating the plug-in estimator in Section 4, and present the statistical convergence guarantee in Section 5.",1. Introduction,[0],[0]
"Applications of the derived rate for two special cases, Gaussian generative model and β-Hölder class conditional probability are presented in Section 6 where explicit convergence rates are provided.",1. Introduction,[0],[0]
We conclude the paper in Section 7.,1. Introduction,[0],[0]
Detailed proofs are deferred to the supplementary materials.,1. Introduction,[0],[0]
Binary classification entails predicting a binary label Y ∈ {±1} associated with a feature vector X ∈ X ⊂ Rd.,2. Problem Setup and Preliminaries,[0],[0]
Such a a function mapping f : X 7→ {±1} from the feature space X to the labels {±1} is called a binary classifier.,2. Problem Setup and Preliminaries,[0],[0]
Let Θ = {f : X → {±1}} denote a set of binary classifiers.,2. Problem Setup and Preliminaries,[0],[0]
"We assume (X,Y ) has distribution P ∈ P , and let η(x) := P(Y = 1|X = x) denote the conditional probability of the label Y given feature vector x.
A key quantity is the confusion matrix, that consists of four population quantities: true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN).",2. Problem Setup and Preliminaries,[0],[0]
Definition 2.1 (Confusion Matrix).,2. Problem Setup and Preliminaries,[0],[0]
"For any classifier f : Rd 7→ {±1}, its confusion matrix is defined as C(f,P) :=",2. Problem Setup and Preliminaries,[0],[0]
"[TP(f,P),FP(f,P),FN(f,P),TN(f,P)] ∈",2. Problem Setup and Preliminaries,[0],[0]
"[0, 1]4, where:
TP(f,P) =",2. Problem Setup and Preliminaries,[0],[0]
"P(Y = +1, f(X) = +1), FP(f,P) = P(Y = −1, f(X) = +1), FN(f,P) =",2. Problem Setup and Preliminaries,[0],[0]
"P(Y = +1, f(X) = −1), TN(f,P) = P(Y = −1, f(X) = −1).
",2. Problem Setup and Preliminaries,[0],[0]
"(1)
Another key ingredient is the utility or performance measure U : Θ×P",2. Problem Setup and Preliminaries,[0],[0]
"→ R, that measures the performance of a classifier.",2. Problem Setup and Preliminaries,[0],[0]
"In this paper, we focus on complex binary classification performance measures that can be expressed as a function of the confusion matrix.",2. Problem Setup and Preliminaries,[0],[0]
"Formally, U(f,P) = G(C(f,P)).",2. Problem Setup and Preliminaries,[0],[0]
"When it is clear from context, we will drop the dependency of the distribution P in C and U .",2. Problem Setup and Preliminaries,[0],[0]
The confusion-matrix functions G corresponding to popular performance measures are listed in Table 1.,2. Problem Setup and Preliminaries,[0],[0]
"Given the performance measure U , we are interested in the corresponding Bayes optimal classifier:
f∗ = arg max f∈Θ U(f,P).",2. Problem Setup and Preliminaries,[0],[0]
"(2)
Given any candidate classifier f , we are then interested in the excess risk U(f∗,P)− U(f,P), which is the utility gap between a given classifier f and the corresponding Bayes optimal.",2. Problem Setup and Preliminaries,[0],[0]
Assumption 1 (Karmic Performance Measure).,2. Problem Setup and Preliminaries,[0],[0]
"The confusion-matrix function G corresponding to the performance measure U is Lipschitz continuous, and satisfies the
Table 1.",2. Problem Setup and Preliminaries,[0],[0]
Examples of evaluation metrics.,2. Problem Setup and Preliminaries,[0],[0]
"Notation: TPR = TPTP+FN ;TNR = TN TN+FP .
",2. Problem Setup and Preliminaries,[0],[0]
"METRIC DEFINITION REFERENCE G(C)
ACCURACY TP + TN (1, 0, 0, 1)C ARITHMETIC MEAN (AM) (TPR + TNR)/2 MENON ET AL.",2. Problem Setup and Preliminaries,[0],[0]
"(2013) ( C1
C1+C3 + C4 C2+C4 )/2
YOUDEN’S INDEX TPR + TNR − 1 YOUDEN (1950) C1 C1+C3 + C4 C2+C4 − 1 Fβ (1+β2)TP (1+β2)TP+β2FN+FP VAN RIJSBERGEN (1974) (1+β2,0,0,0)C (1+β2,1,β2)C LINEAR-FRACTIONAL a1TP+a2FP+a3FN+a4TN b1TP+b2FP+b3FN+b4TN KOYEJO ET AL.",2. Problem Setup and Preliminaries,[0],[0]
(2014) a TC bTC G-MEAN √ TPR · TNR DASKALAKI ET AL.,2. Problem Setup and Preliminaries,[0],[0]
"(2006) √
C1C4 (C1+C3)(C2+C4) Q-MEAN 1− √
(1−TPR)2+(1−TNR)2 2 KUBAT ET AL.",2. Problem Setup and Preliminaries,[0],[0]
"(1997) 1−
√ (
C3 C1+C3 )2+( C2 C2+C4 )2
2
H-MEAN 2 1/TPR+1/TNR KENNEDY ET AL.",2. Problem Setup and Preliminaries,[0],[0]
"(2009) 2
/( C1+C3
C1 + C2+C4 C4 ) condition that ∇G(C)T (1,−1,−1, 1)T ≥ CB , for some constant CB > 0.
",2. Problem Setup and Preliminaries,[0],[0]
"We term performance measures that satisfy the condition ∇G(C)T (1,−1,−1, 1)T ≥ CB as “Karmic measures”, since it guarantees a lower bound on the sensitivity of the performance measure in the direction of increasing true positives and true negatives, and decreasing false positives and false negatives.",2. Problem Setup and Preliminaries,[0],[0]
"While our Karmic assumption slightly weakens the existing monotonicity assumption used in literature, it is worth pointing out that the analysis in (Narasimhan et al., 2014) requires not only monotonicity but also additional assumptions (Assumption B in (Narasimhan et al., 2014)).",2. Problem Setup and Preliminaries,[0],[0]
"Assumption B assumes the existence and uniqueness of an optimal threshold, which turns out to be non-trivial to check.",2. Problem Setup and Preliminaries,[0],[0]
"Our analysis on the threshold-quasi-concavity closes this gap.
",2. Problem Setup and Preliminaries,[0],[0]
"Assumption 1 is satisfied if G is strictly monotonically increasing with respect to TP,TN and decreasing with respect to FP,FN.",2. Problem Setup and Preliminaries,[0],[0]
"Such an assumption is natural in that one would typically prefer a classifier with higher TP for fixed TN and vice versa (Narasimhan et al., 2015b).",2. Problem Setup and Preliminaries,[0],[0]
"This condition is satisfied by most metrics in common use e.g. for the F1 measure, ∇G(C)T (1,−1,−1, 1)T = 4(FP+FN)(2TP+FP+FN)2 is strictly positive as long as the data is not fully separable.",2. Problem Setup and Preliminaries,[0],[0]
Representation of the Bayes Optimal Classifier.,2.1. Related Work,[0],[0]
"The Bayes optimal classifier under the accuracy metric is classically known to be a thresholding of the conditional probability of the response, with the threshold of 1/2 (see e.g. Devroye et al. (2013)).",2.1. Related Work,[0],[0]
This property of Bayes optimal classifier having the thresholded form is called the probability thresholding principle for binary classification by Lewis (1995).,2.1. Related Work,[0],[0]
"Prior work has also shown that the thresholding principle, with a metric dependent threshold, for more complex specific measures such as F-measure (Jansche, 2007;
Zhao et al., 2013), Arithmetic Mean (AM) (Menon et al., 2013), linear-fractional performance metrics (Koyejo et al., 2014), and monotonic concave metrics (Narasimhan et al., 2015a).
",2.1. Related Work,[0],[0]
Plug-in Classifiers for Complex Metrics.,2.1. Related Work,[0],[0]
"For Bayes optimal classifiers that have thresholded form, a line of work has devised plug-in classifiers that then estimate the threshold, and the conditional probability of response.",2.1. Related Work,[0],[0]
"For the AM metric, Menon et al. (2013) show that the threshold is simply the proportion of the positive class.",2.1. Related Work,[0],[0]
"For linear fractional functions, Koyejo et al. (2014) provide an implicit characterization of the optimal threshold, but the solution of which in turn requires the knowledge of the optimal classifier, which is unknown in practice.",2.1. Related Work,[0],[0]
"As a practical estimator, Koyejo et al. (2014) propose an exhaustive search for the threshold over all data samples, and show that the resulting algorithm is consistent, but for which non-asymptotic convergence rates are not known.",2.1. Related Work,[0],[0]
"Narasimhan et al. (2014) also note the importance of estimating the optimal threshold, but do not provide practical algorithms.",2.1. Related Work,[0],[0]
"As we show in Section 3, the empirical risk as a function of the threshold is in general neither convex nor concave.",2.1. Related Work,[0],[0]
"Hence, care must be taken to construct an optimization algorithm that guarantees convergence to the true threshold.
",2.1. Related Work,[0],[0]
Estimators designed for specific Utility Functions.,2.1. Related Work,[0],[0]
"Perhaps the most studied non-decomposable performance metric is the F-measure (Nan et al., 2012; Joachims, 2005; Zhao et al., 2013), with wide use in information retrieval and related areas, and for which researchers have developed tailored estimators (Nan et al., 2012; Joachims, 2005) as well as risk bounds for these estimators (Zhao et al., 2013).",2.1. Related Work,[0],[0]
"For instance, Busa-Fekete et al. (2015) propose a scalable online F-measure estimator for large-scale datasets, with a root finding algorithm for the threshold update which exploits special properties of the F-measure.",2.1. Related Work,[0],[0]
"Similarly, for the
Arithmetic Mean (AM) measure, Menon et al. (2013) design a consistent optimization scheme, based on a balanced classification-calibrated surrogate to AM.",2.1. Related Work,[0],[0]
"Unfortunately, these techniques are not easily extended to general complex performance metrics.
",2.1. Related Work,[0],[0]
Algorithms for General Classification Measures.,2.1. Related Work,[0],[0]
"Joachims (2005) poses the classification problem as a structured prediction problem, and for linear classifiers, propose a structural SVM solver, but for which neither consistency nor explicit convergence rates are known.",2.1. Related Work,[0],[0]
"Kar et al. (2014) proposes an online gradient descent algorithm which requires function classes that satisfy a uniform convergence property, which is difficult to verify apriori.",2.1. Related Work,[0],[0]
"Along similar lines, Narasimhan et al. (2015a) propose a stochastic gradient method, that involves a linearization of classification metric.",2.1. Related Work,[0],[0]
"Their proposed approach depends strongly on the assumption of a linear (or kernelized) classifier, and it is not obvious that the procedure can be extended to more complex non-linear function classes.",2.1. Related Work,[0],[0]
"In this section, we characterize the Bayes-optimal classifier for the broad class of Karmic performance measures, that satisfy Assumption 1.",3. The Bayes Optimal Classifier Revisited,[0],[0]
"We then show that with one additional assumption, we call threshold-quasi-concavity, the optimal threshold can be guaranteed to be unique.",3. The Bayes Optimal Classifier Revisited,[0],[0]
"This result will be crucial for the design and analysis of our computationally efficient threshold finding procedure in Section 4.
",3. The Bayes Optimal Classifier Revisited,[0],[0]
Denote µ as the measure corresponding to the marginal distribution of X .,3. The Bayes Optimal Classifier Revisited,[0],[0]
"The utility is Frechét differentiable, whose Frechét derivative of U may be computed as:
[∇U(f)]x =∇G(C(f))T ·",3. The Bayes Optimal Classifier Revisited,[0],[0]
"[∇C(f)]x
= 1
2
( ∇G(C)T (1,−1,−1, 1)T η(x)
−∇G(C)T (0,−1, 0, 1)T ) dµ(x)
From the Karmic measure Assumption 1, we know that ∇G(C)T (1,−1,−1, 1)T > 0.",3. The Bayes Optimal Classifier Revisited,[0],[0]
"We define the “Bayes critical set” of G(f,P) for any f ∈ F as the set of instances where the utility has zero derivative:
A3(f)",3. The Bayes Optimal Classifier Revisited,[0],[0]
"=
{ x : η(x) = ∇G(C)T (0,−1, 0, 1)T
∇G(C)T (1,−1,−1, 1)T
} .
",3. The Bayes Optimal Classifier Revisited,[0],[0]
"For notational simplicity, we have omitted the dependency of gi on C(f).",3. The Bayes Optimal Classifier Revisited,[0],[0]
"Similarly, we will use A∗3 := A3(f
∗) to denote the Bayes critical set.
",3. The Bayes Optimal Classifier Revisited,[0],[0]
"In this paper we focus on distributions where the critical set of G(f, P ) satisfies P(A3(f))",3. The Bayes Optimal Classifier Revisited,[0],[0]
= 0.,3. The Bayes Optimal Classifier Revisited,[0],[0]
"For instance, this is true for any distribution that satisfies the following assumption.
",3. The Bayes Optimal Classifier Revisited,[0],[0]
Assumption 2 (η-continuity).,3. The Bayes Optimal Classifier Revisited,[0],[0]
Let ν denote the probability measure that is associated with random variable Z = η(X),3. The Bayes Optimal Classifier Revisited,[0],[0]
= P,3. The Bayes Optimal Classifier Revisited,[0],[0]
(,3. The Bayes Optimal Classifier Revisited,[0],[0]
"Y = 1|X), then ν is absolutely continuous with respect to µ.",3. The Bayes Optimal Classifier Revisited,[0],[0]
"Furthermore, the density of η(X), denoted by pη(·), has full support on [0, 1], and is bounded everywhere.
",3. The Bayes Optimal Classifier Revisited,[0],[0]
"Absolute-continuity guarantees the existence of the density of Z. Armed with the above assumption on the conditional probability of the response, we can then characterize the Bayes optimal classifier as follows.
",3. The Bayes Optimal Classifier Revisited,[0],[0]
Theorem 3.1 (Bayes Optimal Classifier as a Thresholding Function).,3. The Bayes Optimal Classifier Revisited,[0],[0]
"Suppose that U is a performance measure that satisfies Assumption 1, and that η(X) satisfies Assumption 2.",3. The Bayes Optimal Classifier Revisited,[0],[0]
Let f∗ be the Bayes classifier with respect to U and C∗ be its confusion matrix.,3. The Bayes Optimal Classifier Revisited,[0],[0]
"Then, for all x ∈ (A∗3)c,
f∗(x) = sign ( η(x)− ∇G(C ∗)T (0,−1, 0, 1)T
∇G(C∗)T (1,−1,−1, 1)T
) .
(3)
Threshold of Bayes optimal classifier For some performance measures, the optimal threshold reduces to an absolute constant; for instance it has the value of 1/2 for the accuracy measure U(f,P) = TP + TN",3. The Bayes Optimal Classifier Revisited,[0],[0]
"(see e.g. (Devroye et al., 2013)).",3. The Bayes Optimal Classifier Revisited,[0],[0]
"In the general case however, the optimal threshold δ∗ is a solution of the fixed point equation:
(∇G(C∗)T (0,−1, 0, 1)T )/(∇G(C∗)T",3. The Bayes Optimal Classifier Revisited,[0],[0]
"(1,−1,−1, 1)T ) = δ∗,
which is fixed point equation due to the dependency of C∗
on the threshold δ∗.",3. The Bayes Optimal Classifier Revisited,[0],[0]
"Theorem 3.1 guarantees the existence of a solution to the above fixed point equation, but not its uniqueness.",3. The Bayes Optimal Classifier Revisited,[0],[0]
"As we will show in Section 5, uniqueness can be achieved with some additional regularity assumptions.
",3. The Bayes Optimal Classifier Revisited,[0],[0]
"We note that Theorem 3.1 only imposes a weak Karmic assumption on the performance measure, which as as stated in Section 2, is more general than even a simple strictly monotonicity assumption.",3. The Bayes Optimal Classifier Revisited,[0],[0]
"In particular, it generalizes prior work such as (Koyejo et al., 2014; Menon et al., 2013), that impose more stringent assumptions (linear or linear fractional form of the measures, or strong monotonicity conditions).
",3. The Bayes Optimal Classifier Revisited,[0],[0]
We next briefly discuss why the critical set is crucial.,3. The Bayes Optimal Classifier Revisited,[0],[0]
"Consider for instance the example studied in Narasimhan et al. (2014): with domain X = {x1, x2, x3}, a corresponding probability mass function (0.25, 0.5, 0.25), and the conditional probability η = (0.49, 0.5, 0.51).",3. The Bayes Optimal Classifier Revisited,[0],[0]
"Narasimhan et al. (2014) show that for this setting, and for the case of the Hmean measure, there exist at least two deterministic Bayes optima: (−1, 1,−1) and (1,−1, 1)}, which can be seen to not have a thresholded form i.e. it cannot be expressed as a (signed) thresholding of the conditional probability.",3. The Bayes Optimal Classifier Revisited,[0],[0]
"Our analysis reveals why this is the case.
",3. The Bayes Optimal Classifier Revisited,[0],[0]
"From the threshold expression in (3) from Theorem 3.1, the optimal threshold can be computed explicitly as ∇G(C∗)T (0,−1,0,1)T ∇G(C∗)T (1,−1,−1,1)T = 1 2 .",3. The Bayes Optimal Classifier Revisited,[0],[0]
"Thus, the Bayes critical set A∗3 = {x : η(x) = 12} = {x2} has measure P (X ∈ A3) = P (X = x2) = 1 2 > 0.",3. The Bayes Optimal Classifier Revisited,[0],[0]
It is clear that the Bayes optimal classifier may not take a thresholded form on the Bayes critical set.,3. The Bayes Optimal Classifier Revisited,[0],[0]
"We are interested in characterizing mild conditions on the performance measure under which the fixed point equation characterizing the Bayes optimal threshold has a unique solution, under which case P (A∗3) = 0 (guaranteed by the η-continuity Assumption 2).
",3.1. Uniqueness of the Bayes Optimal Threshold.,[0],[0]
"The performance measure restricted to classifiers that are threshold functions of the conditional probability, can be rewritten as a function of the conditional probability η and the threshold δ.
",3.1. Uniqueness of the Bayes Optimal Threshold.,[0],[0]
Definition 3.1.,3.1. Uniqueness of the Bayes Optimal Threshold.,[0],[0]
"We define Vη(δ,P) :",3.1. Uniqueness of the Bayes Optimal Threshold.,[0],[0]
"= U(fη,δ,P) as the performance measure of any threshold classifier fη,δ(x) = sign (η(x)− δ).",3.1. Uniqueness of the Bayes Optimal Threshold.,[0],[0]
"Its arguments are the threshold δ, and distribution P, while the subscript η notes its dependence on the conditional probability η.
",3.1. Uniqueness of the Bayes Optimal Threshold.,[0],[0]
"We next introduce the definition of quasi-concavity, and the assumption of V being strictly quasi-concave.",3.1. Uniqueness of the Bayes Optimal Threshold.,[0],[0]
Definition 3.2.,3.1. Uniqueness of the Bayes Optimal Threshold.,[0],[0]
"A function f : X → R is said to be quasiconcave if ∀x, y ∈ X , such that f(x) ≤ f(y), it follows that 〈∇f(x), y − x〉 ≥ 0.",3.1. Uniqueness of the Bayes Optimal Threshold.,[0],[0]
"We further say that f is strictly quasiconcave if it is quasi-concave and its gradient only vanishes at the global optimum, i.e., f(y) < maxx∈X f(x)⇒ ‖∇f(y)‖ > 0.",3.1. Uniqueness of the Bayes Optimal Threshold.,[0],[0]
"Quasi-concave functions have super level sets are convex sets, and moreover by definition are unimodal i.e. have a unique maximal point.
",3.1. Uniqueness of the Bayes Optimal Threshold.,[0],[0]
Assumption 3.,3.1. Uniqueness of the Bayes Optimal Threshold.,[0],[0]
(Threshold-Quasi-Concavity),3.1. Uniqueness of the Bayes Optimal Threshold.,[0],[0]
"The threshold-classifier performance measure Vη(δ,P) is strictly quasi-concave for δ ∈",3.1. Uniqueness of the Bayes Optimal Threshold.,[0],[0]
"[0, 1].
Assumption 3 seems abstract, but it entails that the performance measure is well-behaved as a function of the threshold.",3.1. Uniqueness of the Bayes Optimal Threshold.,[0],[0]
"Moreover, it can be easily shown to hold for performance measures in practical use.",3.1. Uniqueness of the Bayes Optimal Threshold.,[0],[0]
"We provide a proposition that shows that the assumption is satisfied for two important classes of performance measures: linear-fractional functions and concave functions.
",3.1. Uniqueness of the Bayes Optimal Threshold.,[0],[0]
Proposition 3.1.,3.1. Uniqueness of the Bayes Optimal Threshold.,[0],[0]
"If Assumptions 1, 2 hold, and either: (a) G is twice continuously differentiable and concave, or (b) G is a linear fractional function G(C) = a
TC bTC with |bTC| > 0.",3.1. Uniqueness of the Bayes Optimal Threshold.,[0],[0]
"Then Vη(δ,P) is strictly quasi-concave.",3.1. Uniqueness of the Bayes Optimal Threshold.,[0],[0]
Theorem 3.2.,3.1. Uniqueness of the Bayes Optimal Threshold.,[0],[0]
"Under Assumption 3, the fixed-point equa-
tion:
δ = ∇G(C(fδ),P)T (0,−1, 0, 1)T
∇G(C(fδ),P)T (1,−1,−1, 1)T , (4)
where fδ(x) = sign (η(x)− δ), has a unique fixed point δ∗ ∈ (0, 1).",3.1. Uniqueness of the Bayes Optimal Threshold.,[0],[0]
"Hence the threshold in Theorem 3.1 is uniquely defined.
",3.1. Uniqueness of the Bayes Optimal Threshold.,[0],[0]
"Theorems 3.1 and 3.2 have two key consequences: first, we can use the representation to design plugin-estimators of the Bayes optimal classifier; second, it facilitates the statistical analysis for rates of convergence.",3.1. Uniqueness of the Bayes Optimal Threshold.,[0],[0]
We will discuss each of these two consequences in the following sections.,3.1. Uniqueness of the Bayes Optimal Threshold.,[0],[0]
"Theorem 3.1 shows that for Karmic performance measures, the Bayes optimal classifiers has the thresholded form as in Eq.",4. Algorithmic Consequence: Estimation of the Threshold,[0],[0]
"(3), and moreover under the threshold-quasi-concavity Assumption 3, this threshold is unique.",4. Algorithmic Consequence: Estimation of the Threshold,[0],[0]
"An immediate algorithmic consequence of this is to focus on plug-in classifiers that separately estimate the conditional probability, and the threshold.",4. Algorithmic Consequence: Estimation of the Threshold,[0],[0]
We present this plugin-classifier template in Algorithm 1.,4. Algorithmic Consequence: Estimation of the Threshold,[0],[0]
"The template needs: (a) an estimator for conditional probability density η(x), and (b) an estimator for the threshold.",4. Algorithmic Consequence: Estimation of the Threshold,[0],[0]
"For the convenience of analysis, we divide the set of samples into two independent subsets: the conditional probability estimator is estimated using one subset, and the threshold is estimated using the other.",4. Algorithmic Consequence: Estimation of the Threshold,[0],[0]
"In the coming subsec-
Algorithm 1 Two-step Plug-in Classifier for General Metrics
1: Input: Training sample {Xi, Yi}ni=1, utility measure U , conditional probability estimator η̂, stepsize α.",4. Algorithmic Consequence: Estimation of the Threshold,[0],[0]
"2: Randomly split the training sample into two subsets {X(1)i , Y (1) i } n1 i=1",4. Algorithmic Consequence: Estimation of the Threshold,[0],[0]
"and {X (2) i , Y (2) i } n2 i=1",4. Algorithmic Consequence: Estimation of the Threshold,[0],[0]
;,4. Algorithmic Consequence: Estimation of the Threshold,[0],[0]
"3: Estimate η̂ on {X(1)i , Y (1) i } n1 i=1; 4: Estimate δ̂ with {X(2)i , Y (2) i };
5: Output: f̂(x) = sign ( η̂ − δ̂ ) .
tions we discuss how to estimate the conditional probability and the threshold respectively.",4. Algorithmic Consequence: Estimation of the Threshold,[0],[0]
"The estimation of the conditional probability of the response plays a crucial role in the success of Algorithm 1, but we emphasize that it is not the focus of our paper.",4.1. Estimation of Conditional Probability Function,[0],[0]
"In particular, this is a well studied problem, and numerous methods have been proposed for both parametric and non-parametric model assumptions on the conditional probability function.
",4.1. Estimation of Conditional Probability Function,[0],[0]
"In this section we briefly discuss some common estimators, and defer additional details to Section 6.
Parametric methods.",4.1. Estimation of Conditional Probability Function,[0],[0]
"In a classical paper, Ng and Jordan (2002) compares two models of classification: one can either estimate P (Y ) and P (X|Y ) first, then get the conditional probability by Bayes rule (generative model approach); or directly estimate P (Y |X) (discriminative model approach).",4.1. Estimation of Conditional Probability Function,[0],[0]
The two approaches can also be related.,4.1. Estimation of Conditional Probability Function,[0],[0]
"In particular, if PθY (X|Y ) belongs to exponential family, we have
PθY (X|Y ) = h(x) exp (〈θY , φ(X)〉 −A(θY )) ,
where φ(X) is the set of sufficient statistics, θY is the vector of the true canonical parameters, and A(θ) is the logpartition function.",4.1. Estimation of Conditional Probability Function,[0],[0]
"Using Bayes rule, we then have:
P (Y = 1|X) = 1 1 + exp (−〈θ1 − θ0, φ(X)〉+ c∗)
where c∗ = A(θ0) − A(θ1).",4.1. Estimation of Conditional Probability Function,[0],[0]
"The conditional distribution can be seen to follow a logistic regression model, with the generative model sufficient statistics as the features, and the difference of the generative model parameters serving as the parameters of the discriminative model.",4.1. Estimation of Conditional Probability Function,[0],[0]
A natural class of estimators for either the generative or discriminative models is based on Maximum likelihood Estimation (MLE).,4.1. Estimation of Conditional Probability Function,[0],[0]
"In Section 6, we derive the rate of convergence for the special case where the generative distributions are Gaussians with same covariances for both classes.
",4.1. Estimation of Conditional Probability Function,[0],[0]
Non-parametric methods.,4.1. Estimation of Conditional Probability Function,[0],[0]
"One can also estimate η(x) = P (Y = 1|X) non-parametrically, where a common model assumption is some form of smoothness on η(x).",4.1. Estimation of Conditional Probability Function,[0],[0]
"One popular class of smooth functions is the following.
",4.1. Estimation of Conditional Probability Function,[0],[0]
Definition 4.1 (β-Hölder class).,4.1. Estimation of Conditional Probability Function,[0],[0]
"Let β > 0, denote bβc the maximal integer that is strictly less than β.",4.1. Estimation of Conditional Probability Function,[0],[0]
"For x ∈ X and any bβc-times continuously differentiable real-valued function η on X , we denote by ηx its Taylor polynomial of degree bβc at point x,
ηx(x ′) = ∑",4.1. Estimation of Conditional Probability Function,[0],[0]
s≤bβc (x′ − x)s s!,4.1. Estimation of Conditional Probability Function,[0],[0]
"Dsη(x).
",4.1. Estimation of Conditional Probability Function,[0],[0]
"β-Hölder class is defined as the functions that satisfy, for ∀x, x′ ∈ X ,
|ηx(x)− ηx(x′)| ≤ Cβ‖x− x′‖β .
",4.1. Estimation of Conditional Probability Function,[0],[0]
"In particular, when 0 ≤ β < 1, we have |η(x)− η(x′)| ≤ Cβ‖x− x′‖β",4.1. Estimation of Conditional Probability Function,[0],[0]
"where β > 0.
",4.1. Estimation of Conditional Probability Function,[0],[0]
"We can then estimate η(x) from this family of smooth functions via locally polynomial estimators (Audibert et al., 2007), or kernel (conditional) density estimators (Jiang, 2017) with a properly chosen bandwidth.",4.1. Estimation of Conditional Probability Function,[0],[0]
"When Vη is quasi-concave, a key consequence is that its gradient with respect to the threshold suffices to provide ascent direction information.",4.2. Estimation of the Threshold,[0],[0]
"We leverage this consequence, and summarize a simple binary search algorithm based on the sign of V ′η(δ,P) in Algorithm 2.
",4.2. Estimation of the Threshold,[0],[0]
Algorithm 2 Binary search for the optimal threshold 1:,4.2. Estimation of the Threshold,[0],[0]
"Input: Training sample {Xi, Yi}ni=1, utility measure U , conditional probability estimator η̂, tolerance 0.
2: δ` = 0; δr = 1; 3: while |δ` − δr| ≥ 0 do 4: Evaluate s = sign ( V ′η̂(δ,Pn) ) ; 5: if s ≥ 0",4.2. Estimation of the Threshold,[0],[0]
"then 6: δ` = δ`+δr 2 ; 7: else 8: δr = δ`+δr 2 ;
9: end if 10: end while 11: Output:",4.2. Estimation of the Threshold,[0],[0]
"δ`+δr2 .
",4.2. Estimation of the Threshold,[0],[0]
"In the next section, we then analyze the rates of convergence for the excess generalization error of the plug-in classifier learned from Algorithm 1, and with threshold estimated via Algorithm 2.",4.2. Estimation of the Threshold,[0],[0]
We next analyze the convergence rate of the excess utility.,5. Statistical Analysis Consequence: Rates of Convergence,[0],[0]
"As we will show, the rates of convergence depend on three quantities: the noise level of the data distribution, the convergence rate of the conditional probability function, and the convergence rate of the threshold.",5. Statistical Analysis Consequence: Rates of Convergence,[0],[0]
"We start by introducing some assumptions.
",5. Statistical Analysis Consequence: Rates of Convergence,[0],[0]
We assume that the estimator of the conditional probability of response satisfies the following condition.,5. Statistical Analysis Consequence: Rates of Convergence,[0],[0]
Assumption 4.,5. Statistical Analysis Consequence: Rates of Convergence,[0],[0]
"Let Sn denote a sample set of size n, and ηSn denote the conditional probability estimator learnt from Sn.",5. Statistical Analysis Consequence: Rates of Convergence,[0],[0]
"Then, for some absolute constants c1, c2 > 0, the conditional probability estimator satisfies the following condition:
sup Sn
P (|ηSn(x)− η(x)| ≥ )",5. Statistical Analysis Consequence: Rates of Convergence,[0],[0]
≤,5. Statistical Analysis Consequence: Rates of Convergence,[0],[0]
"c1 exp(−c2 an 2) a.e.
",5. Statistical Analysis Consequence: Rates of Convergence,[0],[0]
"The convergence rate also depends on the noise in the training labels, which is typically captured via the probability mass near the Bayes optimal threshold.",5. Statistical Analysis Consequence: Rates of Convergence,[0],[0]
"Here we generalize the classical margin assumption (sometimes also called low noise assumption) of Audibert et al. (2007), developed for the accuracy metric, to the case where the optimal threshold is not a fixed constant 12 :
Assumption 5.",5. Statistical Analysis Consequence: Rates of Convergence,[0],[0]
For some functionC0(δ∗) > 0,5. Statistical Analysis Consequence: Rates of Convergence,[0],[0]
"that depends on the threshold δ∗, there exists an α ≥ 0 such that
PX(0 < |η(X)−",5. Statistical Analysis Consequence: Rates of Convergence,[0],[0]
δ∗| ≤ t) ≤,5. Statistical Analysis Consequence: Rates of Convergence,[0],[0]
"C0(δ∗) tα.
",5. Statistical Analysis Consequence: Rates of Convergence,[0],[0]
The assumption characterizes the behavior of the regression function in the vicinity of the optimal threshold δ∗.,5. Statistical Analysis Consequence: Rates of Convergence,[0],[0]
"The case α = 0 bounds the probability by a constant potentially larger than one, and is trivially satisfied.",5. Statistical Analysis Consequence: Rates of Convergence,[0],[0]
"The other extreme case α =∞ is most advantageous for classification, since in this case the regression function η is bounded away from the threshold.
",5. Statistical Analysis Consequence: Rates of Convergence,[0],[0]
"In cases where the threshold is not an absolute constant (such as 1/2), it has to be estimated from data.",5. Statistical Analysis Consequence: Rates of Convergence,[0],[0]
"We make the following assumption on its convergence rate.
",5. Statistical Analysis Consequence: Rates of Convergence,[0],[0]
Assumption 6.,5. Statistical Analysis Consequence: Rates of Convergence,[0],[0]
"Given a conditional probability estimate η̂ learned from an independent data source, the estimator δ̂n of the threshold, from a sample set of size n, satisfies the following condition, for some absolute constant c3 > 0",5. Statistical Analysis Consequence: Rates of Convergence,[0],[0]
":
P (∣∣∣U(sign (η̂ − δ∗))− U(sign(η̂",5. Statistical Analysis Consequence: Rates of Convergence,[0],[0]
− δ̂))∣∣∣ ≥ b−1n ),5. Statistical Analysis Consequence: Rates of Convergence,[0],[0]
"≤ n−c3 .
",5. Statistical Analysis Consequence: Rates of Convergence,[0],[0]
"Note that Assumption 6 allows the rate bn to in turn depend on η̂, or more specifically, EX |η(X)− η̂(X)|.",5. Statistical Analysis Consequence: Rates of Convergence,[0],[0]
"Moreover, it does not necessarily require that δ̂ converge to δ∗, only that their corresponding utility function values be close.
",5. Statistical Analysis Consequence: Rates of Convergence,[0],[0]
"Armed with these largely notational assumptions, we can now provide the rate for the overall data-splitting two-step plug-in classifier described in Algorithm 1:
Theorem 5.1.",5. Statistical Analysis Consequence: Rates of Convergence,[0],[0]
"Suppose Assumption 1 and 2 hold, and further that Assumptions 4 and 6 hold for some η̂ and δ̂. Let U∗ = U(sign (η − δ∗) ,P) be the Bayes optimal utility.",5. Statistical Analysis Consequence: Rates of Convergence,[0],[0]
"If we split the data as n1 = n2 = n2 , then with probability greater than 1− n−c4 :
U∗ − U ( sign ( η̂ − δ̂ ) ,P )",5. Statistical Analysis Consequence: Rates of Convergence,[0],[0]
≤,5. Statistical Analysis Consequence: Rates of Convergence,[0],[0]
"c5 max { a − 1+α2 n , b −1 n } .
where c4, c5 > 0 are absolute constants.",5. Statistical Analysis Consequence: Rates of Convergence,[0],[0]
"We provide a detailed proof of the theorem in the Appendix, but provide brief vignettes via some key lemmas that also provide some additional insight into the statistical analysis.",5.1. Key Lemmas,[0],[0]
A key tool when analyzing traditional binary classification is to turn the excess risk into an expectation of the absolute deviation of conditional probability from the threshold 12 .,5.1. Key Lemmas,[0],[0]
"We show in the following lemma that a similar result holds with general optimal threshold:
Lemma 5.1.",5.1. Key Lemmas,[0],[0]
"Let Cn and C∗ be the vectorized confusion matrices associated with fn = sign (ηn − δ∗)
and f∗ = sign (η − δ∗) respectively, where δ∗ is the threshold for the Bayes optimal classifier.",5.1. Key Lemmas,[0],[0]
"Denote CG := ∇G(C∗)T (1,−1,−1, 1), and CH := maxf ‖∇2G(C(f))‖op, where ‖ · ‖op refers to the operator norm of a matrix.",5.1. Key Lemmas,[0],[0]
"If for some constant c6, an ≥ c6 ( CH
CG min{δ∗,1−δ∗}
)2 , then
G(C∗)− G(Cn)",5.1. Key Lemmas,[0],[0]
"≥ 1
2 CGE[|η − δ∗|1(fn 6= f∗)],
G(C∗)− G(Cn) ≤ 3
2 CGE[|η − δ∗|1(fn 6= f∗)].
",5.1. Key Lemmas,[0],[0]
This lemma thus helps us control the excess utility via the error of the conditional probability estimator η̂ − η.,5.1. Key Lemmas,[0],[0]
"Armed with this result, and additionally using Assumption 4 on the convergence rate of the conditional probability estimator, we can then show that the excess utility converges at the rate O(a− 1+α 2 n ):
Lemma 5.2.",5.1. Key Lemmas,[0],[0]
"Suppose that Assumptions 4 and 5 are satisfied, and that the Bayes optimal classifier is f∗ = sign (η − δ∗).",5.1. Key Lemmas,[0],[0]
"Then there exists a constant c7 > 0 which depend on G and C(f∗), such that U(sign (η − δ∗))− U(sign (ηn − δ∗)) ≤ c7a − 1+α2 n .
",5.1. Key Lemmas,[0],[0]
Lemma 5.2 describes the classification error rate when the optimal threshold is known.,5.1. Key Lemmas,[0],[0]
Stitching this together with Assumption 6 on the convergence rate of the threshold estimator can then be shown to yield the statement of Theorem 5.1.,5.1. Key Lemmas,[0],[0]
"Algorithm 2
",5.2. Risk Bound for the Plugin Classifier from,[0],[0]
"Prior work on threshold estimation for plug-in classifiers have ranged over brute-force search (Koyejo et al., 2014) with no rates of convergence, level-set based methods (Parambath et al., 2015) for the specific class of linear fractional metrics, and Frank-Wolfe based methods (Narasimhan et al., 2015b) for the specific class of concave performance metrics.",5.2. Risk Bound for the Plugin Classifier from,[0],[0]
"However these estimators, in addition to focus on specific performance metrics, are only able to achieve a convergence rate of O(max{E‖η̂(X)",5.2. Risk Bound for the Plugin Classifier from,[0],[0]
"− η(X)‖1, 1/ √ n}).",5.2. Risk Bound for the Plugin Classifier from,[0],[0]
"This entails that even if when the conditional probability estimator has a fast convergence rate, the final convergence rate for these estimators will still be bounded by O(1/ √ n).",5.2. Risk Bound for the Plugin Classifier from,[0],[0]
"In this section we show that our simple threshold search procedure in Algorithm 2 achieves a fast O(1/n) or O(1/an) rate of convergence by leveraging our analysis from Section 3.
",5.2. Risk Bound for the Plugin Classifier from,[0],[0]
Lemma 5.3.,5.2. Risk Bound for the Plugin Classifier from,[0],[0]
"Assume that Assumptions 1, 2, 5 hold, and that the confusion-matrix function G corresponding to the performance measure U satisfies the same conditions as in Proposition 3.1.",5.2. Risk Bound for the Plugin Classifier from,[0],[0]
"Let δ̂ denote the output of Algorithm 2 with sample size n and tolerance τ = lognn , and η̂ denote
a conditional probability estimator satisfying Assumption 4 obtained on an independent sample set of size n. Denoting ñ = min{n, an}, we then have that the rate bn in Assumption 6 satisfies: bn = log ññ .
",5.2. Risk Bound for the Plugin Classifier from,[0],[0]
"An immediate corollary then gives the excess risk for the plug-in classifier.
",5.2. Risk Bound for the Plugin Classifier from,[0],[0]
Corollary 5.1.,5.2. Risk Bound for the Plugin Classifier from,[0],[0]
Suppose Assumption 3 holds.,5.2. Risk Bound for the Plugin Classifier from,[0],[0]
"If τ = logn n , n1 = n2 = n 2 , then there exist constants c8, c9 > 0, such that with probability at least 1−min{n, an}−c8 ,
U(f∗,P)− U(f̂ ,P) ≤ c9 max { log n
n , log an an , a − 1+α2 n
} .",5.2. Risk Bound for the Plugin Classifier from,[0],[0]
"In this section, we analyze two special cases where we can achieve explicit rate of convergence for the conditional probability estimation.",6. Explicit Rates for Specific Conditional Probability Models,[0],[0]
"For the first example, we consider the Gaussian generative model.",6. Explicit Rates for Specific Conditional Probability Models,[0],[0]
We will show that the rate of convergence for the excess utility obtained in Theorem 5.1 is O( lognn ) in this case.,6. Explicit Rates for Specific Conditional Probability Models,[0],[0]
The second example is for nonparametric kernel estimators when the conditional probability function satisfies certain smoothness assumption.,6. Explicit Rates for Specific Conditional Probability Models,[0],[0]
"Consider two Gaussian distributions with the same variance, without loss of generality we assume the covariance matrix is identity Id for both classes.",6.1. Gaussian Generative Model,[0],[0]
"We define an asymmetric mixture of two Gaussians indexed by the centers and mixing weights.
",6.1. Gaussian Generative Model,[0],[0]
"Pµ,κ :",6.1. Gaussian Generative Model,[0],[0]
"P (Y = 1) = κ, P (Y = 0) = 1− κ, X|Y = 1 ∼ N (µ
2 , Id
) , X|Y = 0 ∼ N ( −µ
2 , Id
) .",6.1. Gaussian Generative Model,[0],[0]
"(5)
As stated in Section 4, we can compute the conditional probability and show that it can be fitted with a logistic regression model.",6.1. Gaussian Generative Model,[0],[0]
"Next we present results related to the key quantities in Theorem 5.1: an and α.
",6.1. Gaussian Generative Model,[0],[0]
Lemma 6.1.,6.1. Gaussian Generative Model,[0],[0]
Model defined in Eq.,6.1. Gaussian Generative Model,[0],[0]
"(5) with maximum likelihood estimator satisfies Assumption 4 with an = n.
The following lemma specifies the margin assumption parameter for the above model.
",6.1. Gaussian Generative Model,[0],[0]
Lemma 6.2.,6.1. Gaussian Generative Model,[0],[0]
The Gaussian generative model defined as in Eq.,6.1. Gaussian Generative Model,[0],[0]
"(5), satisfies Assumption 5 with α = 1.
",6.1. Gaussian Generative Model,[0],[0]
"Combining this result with Theorem 5.1 gives us the following corollary.
",6.1. Gaussian Generative Model,[0],[0]
Corollary 6.1.,6.1. Gaussian Generative Model,[0],[0]
"Assume Assumptions 1-5 hold, P is generated from Eq.",6.1. Gaussian Generative Model,[0],[0]
(5).,6.1. Gaussian Generative Model,[0],[0]
"Let f̂ be the output of Algorithm 1 with
η̂ estimated by MLE of logistic regression.",6.1. Gaussian Generative Model,[0],[0]
"We have with probability tending to 1, U(f∗,P)−U(f̂ ,P) =",6.1. Gaussian Generative Model,[0],[0]
"O ( logn n ) .
",6.1. Gaussian Generative Model,[0],[0]
"For Gaussian generative models, fast rates of O( 1n ) are only known for 0-1 loss (Li et al., 2015).",6.1. Gaussian Generative Model,[0],[0]
"The logarithm factor can be further removed under 0-1 loss, or other cases when the threshold is known, as one can apply Lemma 5.2 with α = 1 and get exactly the same rate as in Li et al. (2015).",6.1. Gaussian Generative Model,[0],[0]
"Corollary 6.1 generalizes this result for a much broader class of utility functions, when the threshold is unknown and estimated from data.",6.1. Gaussian Generative Model,[0],[0]
"When the conditional probability function belongs to the β-Hölder class as defined in Definition 4.1, we have the following lemma on the convergence rates of ηn.
Lemma 6.3.",6.2. β-Hölder Densities,[0],[0]
"For β-Hölder conditional probability functions, there exists estimators such that Assumption 4 holds with an = n 2β 2β+d .
",6.2. β-Hölder Densities,[0],[0]
"Examples of such estimators include locally polynomial estimators (Audibert et al., 2007), or kernel (conditional) density estimators (Jiang, 2017).",6.2. β-Hölder Densities,[0],[0]
"Combined with Theorem 5.1 we have the following corollary.
",6.2. β-Hölder Densities,[0],[0]
Corollary 6.2.,6.2. β-Hölder Densities,[0],[0]
Assume Assumptions 1-5 hold and P be a distribution where P (Y = 1|X) belongs to β-Hölder class.,6.2. β-Hölder Densities,[0],[0]
"With locally polynomial estimators (Audibert et al., 2007) or kernel (conditional) density estimators (Jiang, 2017), we have: U(f∗,P)− U(f̂) =",6.2. β-Hölder Densities,[0],[0]
"O ( n− (min{α,1}+1)β 2β+d ) .
",6.2. β-Hölder Densities,[0],[0]
"The convergence rate obtained in Corollary 6.2 is faster than O( 1√
n )",6.2. β-Hölder Densities,[0],[0]
"if β > max{ d2α , d 2}.",6.2. β-Hölder Densities,[0],[0]
"It is worth pointing out that the fast rate is obtained via a trade-off between the parameter α and β: to have a very smooth conditional probability function η, i.e., a large value of β, it cannot deviate from the critical level very abruptly, hence α has to be small.",6.2. β-Hölder Densities,[0],[0]
We study Bayes optimal classification for general performance metrics.,7. Conclusion,[0],[0]
"We derive the form of the Bayes optimal classifier, provide practical algorithms to estimate this Bayes optimal classifier, and provide novel analysis of classification error with respect to general performance metrics, and in particular show our estimators are not only consistent but have fast rates of convergence.",7. Conclusion,[0],[0]
"We also provide corollaries of our general results for some special cases, such as when the inputs are drawn from a Gaussian mixture generative models, or when the conditional probability function lies in a Hölder space, explicitly proving fast rates under mild regularity conditions.",7. Conclusion,[0],[0]
"P.R. acknowledges the support of NSF via IIS-1149803, IIS-1664720, DMS-1264033, and PNC via the PNC Center for Financial Services Innovation.",Acknowledgements,[0],[0]
"Complex performance measures, beyond the popular measure of accuracy, are increasingly being used in the context of binary classification.",abstractText,[0],[0]
"These complex performance measures are typically not even decomposable, that is, the loss evaluated on a batch of samples cannot typically be expressed as a sum or average of losses evaluated at individual samples, which in turn requires new theoretical and methodological developments beyond standard treatments of supervised learning.",abstractText,[0],[0]
"In this paper, we advance this understanding of binary classification for complex performance measures by identifying two key properties: a so-called Karmic property, and a more technical threshold-quasiconcavity property, which we show is milder than existing structural assumptions imposed on performance measures.",abstractText,[0],[0]
"Under these properties, we show that the Bayes optimal classifier is a threshold function of the conditional probability of positive class.",abstractText,[0],[0]
"We then leverage this result to come up with a computationally practical plug-in classifier, via a novel threshold estimator, and further, provide a novel statistical analysis of classification error with respect to complex performance measures.",abstractText,[0],[0]
"Binary Classification with Karmic, Threshold-Quasi-Concave Metrics",title,[0],[0]
Decision Trees as well as ensemble methods that use them (e.g. Random Forests and Gradient Boosted Trees) are among the most popular methods for classification tasks.,1. Introduction,[0],[0]
"It is widely known that decision trees, specially small ones, are easy to interpret while ensemble methods usually yield to more stable/accurate classifications.
",1. Introduction,[0],[0]
"When building a decision tree, in each node, one needs to address two problems: which attribute shall be used for branching, and how to split the chosen attribute, i.e., which values of the attribute go to each branch.",1. Introduction,[0],[0]
"For the first problem we refer the reader to (Hothorn et al., 2006; Nowozin, 2012).",1. Introduction,[0],[0]
"Here we consider the latter, which is a well-studied problem (Breiman et al., 1984; Nadas et al., 1991; Chou, 1991; Burshtein et al., 1992; Coppersmith et al., 1999; Elomaa & Rousu, 2004).",1. Introduction,[0],[0]
"More specifically, we focus on nominal attributes (i.e. finite set of possible values with no additional structure such as order).
",1. Introduction,[0],[0]
"*Equal contribution 1Departamento de Informática, PUCRIO, Brazil.",1. Introduction,[0],[0]
"Correspondence to: Eduardo Laber <eduardo.laber1@gmail.com>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
An important design choice is whether to use multiway splits or binary splits.,1. Introduction,[0],[0]
"One possibility is splitting a nominal attribute with n distinct values into n branches, one for each value.",1. Introduction,[0],[0]
"When n is large, this option may lead to a severe data fragmentation, which makes the classification task harder and increases the risk of data overfit since we may have only a few examples associated with each branch.",1. Introduction,[0],[0]
Note that any decision tree obtained via multiway splits can be simulated by a decision tree that only uses binary splits.,1. Introduction,[0],[0]
"Thus, we focus our study on binary splits.
",1. Introduction,[0],[0]
"The standard approach for deciding the split is to search for ‘pure’ partitions of the set of examples, that is, partitions in which each branch is very homogeneous with respect to the class distribution of its examples.",1. Introduction,[0],[0]
"To measure how impure each branch is, impurity measures are often employed.",1. Introduction,[0],[0]
"An impurity measure maps a vector u = (u1, . . .",1. Introduction,[0],[0]
", uk), counting how many examples of each class we have in a node (branch), into a non-negative scalar 1.",1. Introduction,[0],[0]
"Arguably, two of the most classical impurity measures are the Gini impurity
iGini(u) = k∑ i=1",1. Introduction,[0],[0]
ui ‖u‖1,1. Introduction,[0],[0]
"( 1− ui ‖u‖1 ) ,
which is used in the CART package (Breiman et al., 1984), and the Entropy impurity
iEntr(u) =",1. Introduction,[0],[0]
"− k∑
i=1
ui ‖u‖1 log ( ui ‖u‖1 ) ,
that, along with its variants, is used in the C4.5 decision tree inducer (Quinlan, 1992).",1. Introduction,[0],[0]
"Given an attribute and an impurity measure, the goal is then to find a binary split (L∗, R∗) for the attribute values that induces a binary partition of the set of examples with minimum weighted impurity, where the weights are given by the number of examples that lie into each of the two branches.
",1. Introduction,[0],[0]
"For classification tasks with only two classes, Breiman et al. (Breiman et al., 1984) proposed an algorithm that finds a partition with minimum weighted impurity in O(n log n) time for a family of impurity measures that include both Gini and Entropy.",1. Introduction,[0],[0]
"For nominal attributes with a small number of distinct values n, the best partition can be found in O(2n)
1In the original definition an impurity measure maps a vector of probabilities into a non-negative scalar.
time by an exhaustive search.",1. Introduction,[0],[0]
"However, when k > 2 and n is large (e.g. states of a country, letters of the alphabet, breed of an animal), these methods are not effective.",1. Introduction,[0],[0]
"Thus, heuristics are commonly used (Nadas et al., 1991; Chou, 1991; Mehta et al., 1996; Coppersmith et al., 1999; Loh, 2009).",1. Introduction,[0],[0]
"Despite the importance of this problem, little is known about its computational complexity and the quality (approximation guarantee) of its heuristics.",1. Introduction,[0],[0]
"Therefore, our goal here is contributing to fill this gap.",1. Introduction,[0],[0]
"Given an impurity measure i (e.g. iGini), define I as I(v) = ‖v‖1 · i(v) for all vectors v. This scaled impurity I is called frequency-weighted impurity measure in (Coppersmith et al., 1999) and will be used to formalize our problem.
",1.1. Problem Description,[0],[0]
"Consider a nominal attribute A that may take n possible values a1, . . .",1.1. Problem Description,[0],[0]
", an.",1.1. Problem Description,[0],[0]
The `-ary Partition with Minimum Weighted Impurity Problem (`-PMWIP) can be described abstractly as follows.,1.1. Problem Description,[0],[0]
We are given a collection of n vectors V ⊂,1.1. Problem Description,[0],[0]
"Rk, where the ith coordinate of the jth vector counts the number of examples in class i for which the attribute A has value aj .",1.1. Problem Description,[0],[0]
We are also given a scaled impurity measure I .,1.1. Problem Description,[0],[0]
"The goal is to partition V into ` disjoint groups of vectors V1, . . .",1.1. Problem Description,[0],[0]
", V` so as to minimize the sum of the weighted impurities ∑̀
m=1
I ( ∑ v∈Vm v ) .
",1.1. Problem Description,[0],[0]
We focus on binary partitions (2-PMWIP) and on a broad class of impurity measures that includes both Gini and Entropy.,1.1. Problem Description,[0],[0]
"These impurities have the form
I(v) = ‖v‖1
( k∑
i=1
f",1.1. Problem Description,[0],[0]
( vi ‖v‖1 )),1.1. Problem Description,[0],[0]
",
where f is a strictly concave function that satisfies a certain property related to its curvature.",1.1. Problem Description,[0],[0]
The formal definition of this class is postponed to Section 2.1.,1.1. Problem Description,[0],[0]
In this paper we propose new splitting procedures that provably achieve near-optimal impurity.,1.2. Our Results,[0],[0]
"Our starting point is one of the results presented in (Burshtein et al., 1992; Coppersmith et al., 1999) that states that for every instance of 2-PMWIP, where the impurity I satisfies certain conditions, there exists an optimal binary partition that is induced by a homogeneous hyperplane in Rk.",1.2. Our Results,[0],[0]
"Building upon this result we prove that an optimal binary partition can be obtained by a non-homogeneous hyperplane whose normal direction belongs to the box [0, 1]k.",1.2. Our Results,[0],[0]
"Then, motivated by this observation, we propose and analyze two methods that belong to a family of algorithms that search for binary partitions with
reduced impurity by considering hyperplanes in Rk whose normal lie in the hypercube {0, 1}k.
",1.2. Our Results,[0],[0]
"Our first algorithm, the Hypercube Cover (HcC for short), is closely related with the well established Twoing method proposed in (Breiman et al., 1984).",1.2. Our Results,[0],[0]
We prove that HcC has a 2-approximation for every impurity measure in our class.,1.2. Our Results,[0],[0]
"A drawback of this method, however, is its running time proportional to 2k.",1.2. Our Results,[0],[0]
"Given this limitation, we present LargestClassAlone (LCA for short), a simple algorithm that runs in O(nk + n log n) time and provides a (3 + √ 3)-approximation for every impurity measure in our class.",1.2. Our Results,[0],[0]
This material is covered in Section 3.,1.2. Our Results,[0],[0]
"Furthermore, in Section 4, we show that the approximation ratio of LCA for Gini and Entropy impurities is indeed much better, being at most 2 for the former and at most 3 for the latter.",1.2. Our Results,[0],[0]
"We also show that, unless P = NP , it is not possible to find the partition with minimum impurity in polynomial time, even for the Entropy impurity.
",1.2. Our Results,[0],[0]
"To complement our theoretical findings, in Section 5 we present a set of experiments where we compare the proposed methods with PCext and SLIQext, the two splitting methods that obtained the best results in the study reported in (Coppersmith et al., 1999).",1.2. Our Results,[0],[0]
"Our experiments provide evidence that both methods proposed in this paper are interesting candidates to be used in splitting nominal attributes with many values during decision tree/ random forest induction: HcC is preferable when the number of classes is small and LCA is a good alternative when speed is an issue.
",1.2. Our Results,[0],[0]
We believe that our set of results contributes to improving the current knowledge on a classical and still relevant problem for both the Machine Learning and Data Mining communities.,1.2. Our Results,[0],[0]
"There have been theoretical investigations on methods to compute the best split efficiently (Breiman et al., 1984; Chou, 1991; Burshtein et al., 1992; Coppersmith et al., 1999; Kurkoski & Yagi, 2014).",1.3. Related Work,[0],[0]
"As mentioned above, for the 2- class problem, Breiman et.",1.3. Related Work,[0],[0]
"al. (Breiman et al., 1984) presented a simple algorithm that finds the best binary partition in O(n log n) time for impurity measures in a certain class that includes both Gini and Entropy.",1.3. Related Work,[0],[0]
"The correctness of this algorithm relies on a theorem, also proved in (Breiman et al., 1984), which is generalized for k > 2 classes and multiway partitions in (Chou, 1991; Burshtein et al., 1992; Coppersmith et al., 1999).",1.3. Related Work,[0],[0]
"Basically, these theorems provide necessary conditions for partitions with minimum impurity and can be used to restrict the set of partitions that need to be considered, as in the family of algorithms we study here.",1.3. Related Work,[0],[0]
"However, despite their usefulness, these conditions do not yield a method that has running time polynomial on n and k.
Some heuristics for computing suboptimal partitions are available in the literature (Breiman et al., 1984; Nadas et al., 1991; Mehta et al., 1996; Coppersmith et al., 1999; Loh, 2009).",1.3. Related Work,[0],[0]
For none of them approximation guarantees are available.,1.3. Related Work,[0],[0]
"The conclusion of the experiments reported in (Coppersmith et al., 1999) is that PCext, one of the methods proposed in that paper, overcomes Flip Flop (Nadas et al., 1991) and SLIQ (Mehta et al., 1996) in terms of running time and the impurity of the partitions found.
",1.3. Related Work,[0],[0]
"Recently, motivated by applications on signal processing (e.g. construction of polar codes (Tal & Vardy, 2013)), the problem of computing the quantization of the output of a Discrete Memoryless Channel (DMC) that provides the maximum mutual information with the DMC’s input has attracted a considerable attention in the Information Theory community (Tal & Vardy, 2013; Kurkoski & Yagi, 2014; Kartowsky & Tal, 2017; Pereg & Tal, 2017; Nazer et al., 2017).",1.3. Related Work,[0],[0]
"Kurkoski and Yagi (Kurkoski & Yagi, 2014) observed that this problem is equivalent to `-PMWIP when the impurity measure is the Entropy, and proved that it can be solved in polynomial time when k = 2.",1.3. Related Work,[0],[0]
"In (Gülcü et al., 2016; Nazer et al., 2017; Pereg & Tal, 2017; Kartowsky & Tal, 2017), upper and lower bounds on the difference between the entropy impurity of the n-ary partition and the optimal `-ary partition are proved.",1.3. Related Work,[0],[0]
These bounds do not imply constant approximations for the problem we consider here.,1.3. Related Work,[0],[0]
We start defining some notations employed throughout the paper.,2. Preliminaries,[0],[0]
"An input for 2-PMWIP is a pair (V, I), where V is a collection of non-null vectors in Rk with non-negative integer coordinates and I is a scaled impurity measure.",2. Preliminaries,[0],[0]
We assume that the vector ∑ v∈V v has no zero coordinates for otherwise we would have an instance with less than k classes.,2. Preliminaries,[0],[0]
"For a set of vectors L, the impurity I(L) of L is given by I( ∑ v∈L v).",2. Preliminaries,[0],[0]
"The impurity of a binary partition (L,R) of the set V is then I(L) + I(R).",2. Preliminaries,[0],[0]
"We use optI(V ) to denote the minimum possible impurity for a binary partition of V and, whenever the context is clear, we omit I from optI(V ).",2. Preliminaries,[0],[0]
"We say that a partition (L
∗, R∗) is optimal for input (V, I) iff I(L∗)",2. Preliminaries,[0],[0]
"+ I(R∗) = optI(V ).
",2. Preliminaries,[0],[0]
We use bold face to denote vectors.,2. Preliminaries,[0],[0]
"Given two vectors u = (u1, . . .",2. Preliminaries,[0],[0]
", uk) and v = (v1, . . .",2. Preliminaries,[0],[0]
", vk) we use u · v to denote their inner product and u ◦ v = (u1v1, . . .",2. Preliminaries,[0],[0]
", ukvk) to denote their component-wise (Hadamard) product.",2. Preliminaries,[0],[0]
"We use 0 and 1 to denote the vectors in Rk with all coordinates equal to 0 and 1, respectively.",2. Preliminaries,[0],[0]
For a non-null vector v ∈ Rk+ we use π(v) = v/‖v‖1 to denote the vector obtained by normalizing v w.r.t.,2. Preliminaries,[0],[0]
to the `1 norm.,2. Preliminaries,[0],[0]
"We use [m] to denote the set of the first m positive integers.
",2. Preliminaries,[0],[0]
Due to space constraints we omit most of the proofs.,2. Preliminaries,[0],[0]
"However, all of the them can be found in the full version available in the supplementary material.",2. Preliminaries,[0],[0]
"We are interested in the class C of scaled impurity measures I that satisfy
I(u) =",2.1. Impurity Measures,[0],[0]
‖u‖1 dim(u)∑ i=1,2.1. Impurity Measures,[0],[0]
"f ( ui ‖u‖1 ) , (P0)
where dim(u) is the dimension of vector u and f : R→ R is a function satisfying the following conditions:
1.",2.1. Impurity Measures,[0],[0]
"f(0) = f(1) = 0 (P1)
2.",2.1. Impurity Measures,[0],[0]
"f is strictly concave in the interval [0,1] (P2)
3.",2.1. Impurity Measures,[0],[0]
"For all 0 < p ≤ q ≤ 1
f(p) ≤ p q · f(q) + q · f
( p
q
) .",2.1. Impurity Measures,[0],[0]
"(P3)
Impurity measures satisfying conditions (P0)-(P2) are called frequency-weighted impurity measures with concave functions (Coppersmith et al., 1999).",2.1. Impurity Measures,[0],[0]
"These impurities measures are superadditive.
",2.1. Impurity Measures,[0],[0]
"Lemma 2.1 (Lemma 1 in (Coppersmith et al., 1999)).",2.1. Impurity Measures,[0],[0]
"If I satisfies (P0)-(P2) then for every vectors uL and uR in Rk+, we have I(uL + uR) ≥ I(uL) + I(uR).
",2.1. Impurity Measures,[0],[0]
"Although property (P3) is not particularly intuitive it can be shown that if a simple constraint (xf ′′(x) is non-increasing in [0,1]) is imposed on the second derivative f ′′ of f then (P3) is also satisfied.
",2.1. Impurity Measures,[0],[0]
"From (Coppersmith et al., 1999)",2.1. Impurity Measures,[0],[0]
we know that both IGini and IEntr satisfy (P0)-(P2).,2.1. Impurity Measures,[0],[0]
"It is not difficult to verify that they also satisfy (P3).
",2.1. Impurity Measures,[0],[0]
Lemma 2.2.,2.1. Impurity Measures,[0],[0]
"The Gini measure IGini and the Entropy measure IEntr belong to C.
The last lemma of this subsection shows that the impurity measures of our class satisfy a subsystem property.",2.1. Impurity Measures,[0],[0]
"It will be used in our analysis to relate the impurity of partitions for instances with k classes with the impurity of partitions for instances with 2 classes.
",2.1. Impurity Measures,[0],[0]
Lemma 2.3 (Subsystem Property).,2.1. Impurity Measures,[0],[0]
"Let I be an impurity measure in C. Then, for every u ∈ Rk+ and every d ∈",2.1. Impurity Measures,[0],[0]
"[0, 1]k,
I(u) ≤",2.1. Impurity Measures,[0],[0]
"I ( (u · d,u · (1− d)) )",2.1. Impurity Measures,[0],[0]
"+
I(u ◦ d) +",2.1. Impurity Measures,[0],[0]
I(u ◦,2.1. Impurity Measures,[0],[0]
"(1− d))
",2.1. Impurity Measures,[0],[0]
Proof’s sketch.,2.1. Impurity Measures,[0],[0]
"Note that by the definition of I , the desired inequality is invariant to scaling u; thus, we assume without loss of generality that ‖u‖1 = 1.",2.1. Impurity Measures,[0],[0]
"The left-hand side of the inequality is then ∑ i f(ui).
",2.1. Impurity Measures,[0],[0]
The result is then obtained by applying the following steps: (i) The subadditivity of f is used to obtain f(ui) ≤ f(diui) + f((1,2.1. Impurity Measures,[0],[0]
"− di)ui); (ii) Property (P3) is used, with p = diui and q = d · u, to upper bound f(diui); (iii) The same property is used with p = (1−di)ui and q = (1−d)·u to upper bound f(ui(1− di)) and (iv) The upper bound on f(ui) derived in the previous steps is added over all i to get the right-hand side of the desired inequality.",2.1. Impurity Measures,[0],[0]
We end our section of preliminaries presenting two results that give necessary conditions for optimal partitions.,2.2. Necessary conditions for optimal partitions,[0],[0]
"The first one, proved in (Breiman et al., 1984), yields to an O(n log n) time algorithm for 2-PMWIP when the number of classes k is 2.",2.2. Necessary conditions for optimal partitions,[0],[0]
"The second one works for 2-PMWIP, with arbitrary k, and it is a reduced version of a more general theorem that also works for `-ary partitions (Burshtein et al., 1992; Coppersmith et al., 1999).",2.2. Necessary conditions for optimal partitions,[0],[0]
Both results are stated using our notation.,2.2. Necessary conditions for optimal partitions,[0],[0]
"Theorem 2.4 (Theorem 4.5 of (Breiman et al., 1984)).",2.2. Necessary conditions for optimal partitions,[0],[0]
Let I be an impurity measure satisfying properties (P0)-(P2) and let V2 ⊆ R2+.,2.2. Necessary conditions for optimal partitions,[0],[0]
"Moreover, for every v = (v1, v2) ∈ V2 let r(v) = v1/‖v‖1.",2.2. Necessary conditions for optimal partitions,[0],[0]
"Furthermore, let Pj be the set containing the first j vectors of V2 when those are sorted with respect to r().",2.2. Necessary conditions for optimal partitions,[0],[0]
"Then (Pj , V2 \Pj), for some j ∈",2.2. Necessary conditions for optimal partitions,[0],[0]
"[n− 1], is an optimal partition for the instance (V2, I).",2.2. Necessary conditions for optimal partitions,[0],[0]
"Lemma 2.5 (Hyperplanes Lemma (Burshtein et al., 1992; Coppersmith et al., 1999)).",2.2. Necessary conditions for optimal partitions,[0],[0]
Let I be an impurity measure satisfying properties (P0)-(P2).,2.2. Necessary conditions for optimal partitions,[0],[0]
"If (L∗, R∗) is an optimal partition for an instance (V, I), then there is a vector d∗ ∈",2.2. Necessary conditions for optimal partitions,[0],[0]
Rk such that d∗·π(v) < 0,2.2. Necessary conditions for optimal partitions,[0],[0]
for every v ∈ L∗ and d∗·π(v) > 0,2.2. Necessary conditions for optimal partitions,[0],[0]
for every v ∈ R∗.,2.2. Necessary conditions for optimal partitions,[0],[0]
In this section we present approximation algorithms for finding binary partitions with reduced impurity.,3. Constant Approximations for Impurity Measures in C,[0],[0]
"We first analyze a general hyperplane-based procedure, and later specialize it to obtain different approximation algorithms.",3. Constant Approximations for Impurity Measures in C,[0],[0]
A direct consequence of the Hyperplanes Lemma (Lemma 2.5) above is that the search of the optimal partition can be reduced to the search of a direction in Rk.,3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"In fact, it is easy to see that we can normalize these directions to be in [0, 1]k, at the expense of working with non-homogeneous hyperplanes, as it is shown in the next proposition.
",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
Proposition 3.1.,3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"Let (L∗, R∗) be an optimal partition for input (V, I) and let d∗ ∈",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
Rk be such that d∗ · π(v) < 0 for every v in L∗ and d∗ · π(v) > 0,3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"for every v in R∗.
Then, there is a direction d ∈",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"[0, 1]k and a constant C such that d · π(v) < C for every v in L∗ and d · π(v) > C for every v in R∗.
The previous observation motivates the definition of a family of algorithms indexed by a direction d ∈",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"[0, 1]k.",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"The algorithm Bd searches for a partition with reduced impurity by considering all the n − 1 partitions of the input set V induced by the hyperplanes with normal d (Algorithm 1).
",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"Algorithm 1 Bd (V : collection of vectors, I: impurity measure)
1: For each v in V let r(v)",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"= (d · v)/‖v‖1 2: Rank the vectors in V according to r(v) 3: for j = 1, . . .",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
", n− 1 do 4:",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"Pj ← subset of V containing the j vectors with the largest value of r(·) 5: Evaluate the impurity of partition (Pj , V \ Pj) 6: end for 7: Return the partition (Pj∗ , V \ Pj∗) with the smallest
impurity found in the loop
We present a general analysis of the quality of solution produced by algorithm Bd when d ∈ {0, 1}k.",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"More specifically, we prove the following theorem:
Theorem 3.2.",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"Let I(Bd) be the impurity of the partition returned by Bd for an instance (V, I).",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"Then, for every direction d ∈ {0, 1}k we have
I(Bd) opt(V ) ≤ 1 + I(u ◦ d) + I(u ◦ (1− d))",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"mind′∈{0,1}k {I(u ◦ d′) + I(u ◦",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"(1− d′))}
(1)
",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
The bound given by this theorem is the basis for the approximation algorithms obtained in the next subsections since it motivates the use of a direction d such that I(u ◦ d) +,3.1. Analysis of a general hyperplane-based procedure,[0],[0]
I(u ◦,3.1. Analysis of a general hyperplane-based procedure,[0],[0]
(1− d)) is minimized.,3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"The remainder of this section is dedicated to prove Theorem 3.2.
",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"One of the key ideas of the proof is to establish a relation between the impurity of the partition obtained by Bd for the k-class instance (V, I) and the optimal impurity for the 2-class instance obtained by collapsing all the classes corresponding to the coordinates of d with value 0 into one “super class”, and all classes corresponding to the coordinates of d with value 1 into another super class.",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"Recall that each vector v ∈ V ⊆ Rk+, which corresponds to an attribute value, counts in its coordinates the number of examples of each of the k classes with the given attribute value.",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"Then, in the collapsed 2-class instance, this vector count becomes
simply ( ∑ i:di=1 vi, ∑ i:di=0 vi) = (v · d,v · (1 − d)).",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"Thus, define the operation collapsed : Rk+ → R2+ that maps v 7→ (v · d,v · (1 − d)).",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"Moreover, for a set of vectors S, define collapsed(S) as the set obtained applying collapsed() to each vector of S. Therefore, from a k-class instance (V, I) and a direction d ∈ {0, 1}k, we obtain the collapsed 2-class instance (collapsed(V ), I).
",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"The main motivation for looking at 2-class instances is that we know from Theorem 2.4 that an optimal partition can be obtained by sweeping the vectors according to some order, which is very similar to what algorithm Bd is doing.",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"To make this connection precise, let Ad be the algorithm obtained by modifying Line 5 of Bd so that the impurity of the binary partition (collapsed(Pj), collapsed(V",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"\ Pj)) is evaluated, rather than the impurity of (Pj , V \ Pj).",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"The following proposition states that the impurity Bd is at most that of Ad and that essentially the latter solves optimally the collapsed 2-class instance.
",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
Proposition 3.3.,3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"Let (L,R) be the partition returned by Ad for the k-class instance (V, I) and let I(Ad) be the impurity of (L,R).",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"Then: (i) I(Bd) ≤ I(Ad) and (ii) (collapsed(L), collapsed(R)) is an optimal partition for the 2-class instance (collapsed(V ), I).
",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"Given the first item of the above proposition, to prove Theorem 3.2, it suffices to upper bound the impurity of the partition (L,R) returned by Ad.",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"To simplify the notation, let u = ∑ v∈V v, uL = ∑ v∈L v, and uR = ∑ v∈R v. Also, for a direction d in {0, 1}k let d̄",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"= 1 − d. The impurity of the partition (L,R) constructed by Ad is
I(Ad) = I(uL) + I(uR).
",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
From the Subsystem Property (Lemma 2.3) we get I(Ad) ≤,3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"I ( (d · uL, d̄ · uL) )",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"+ I(d ◦ uL) + I(d̄ ◦ uL)
+ I ( (d · uR, d̄ · uR) )",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"+ I(d ◦ uR) + I(d̄ ◦ uR)
= opt(collapsed(V ))",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
+ I(d ◦ uL) + I(d̄ ◦ uL)+ I(d ◦ uR),3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"+ I(d̄ ◦ uR), (2)
where the last identity follows from the item (ii) of Proposition 3.3 because (d · uL, d̄ · uL) = ∑ v∈collapsed(L) v and
(d · uR, d̄ · uR) = ∑
v∈collapsed(R)",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"v.
Now we need to upper bound the last four terms in the RHS of the equation (2).",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
Using the superadditivity of I (Lemma 2.1),3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"we have
I(Ad) ≤ opt(collapsed(V ))",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"+ I(d ◦ u) + I(d̄ ◦ u) (3)
Now we devise lower bounds on opt(V ).",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"The first lower bound captures the intuitive fact that the impurity in the multi-class problem is at least as large as that in the collapsed 2-class problem.
",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
Lemma 3.4.,3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"For any input V and d ∈ {0, 1}k, we have opt(V ) ≥ opt(collapsed(V )).
",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"For our second lower bound, we consider the relaxed problem where each example corresponds to a distinct attribute value and the full class distribution is equal to that of V .",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"Formally, from the original instance (V, I) we consider the instance (V ′, I), where V ′ contains ui copies of the standard basis vector ei for i = 1, . . .",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
", k.
Let opt(V ′) be the optimal solution to this relaxed problem.",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"It is clear that opt(V ′) ≤ opt(V ), since any partition for the collection V can be realized in the collection V ′.
It follows from Lemma 2.5 that in the optimal partition of V ′ all vectors associated with the same class (standard basis vectors) end up on the same side of the partition.",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"Thus, the optimal solution for instance (V ′, I) corresponds to a partition of the set of classes, and so
opt(V ) ≥ opt(V ′) =",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"min
d′∈{0,1}k {I(u ◦ d′) + I(u ◦",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"(1− d′))} .
",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"Thus, by using the upper bound given by equation (3), the lower bound given by Lemma 3.4 and the previous inequality we obtain that the RHS of inequality (1) is an upper bound on the approximation ratio of algorithm Ad.",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"This bound together with the first item of Proposition 3.3 establish Theorem 3.2.
3.2.",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"The Hypercube Cover procedure
The HcC method simply returns the best Bd among all possible directions d ∈ {0, 1}k, hence it equals Bd′ for d′ satisfying
I(Bd′) =",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"min d∈{0,1}k I(Bd).
",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"To find d′, the algorithm examines all the 2k binary vectors in {0, 1}k.
",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"Given the general analysis provided by Theorem 3.2, it follows directly that HcC has the following approximation guarantee.",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
Theorem 3.5.,3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"HcC is a 2-approximation algorithm for every impurity measure in C.
We shall mention that HcC is closely related with the Twoing method proposed in (Breiman et al., 1984).",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"In fact, Twoing considers all 2k possibilities of grouping the k classes into 2 super classes and, for each possibility, optimally solves the 2-class problem; the best partition w.r.t.",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
the 2-class problem is then returned.,3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"In our notation, Twoing executes algorithm Ad, rather than Bd, for all directions d ∈ {0, 1}k and returns the partition, among the 2k generated, with minimum impurity with respect to the collapsed problem.
",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"It is also interesting to note that in (Breiman et al., 1984)",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"it was proved that if Twoing considers the Gini impurity for solving its 2-class problems then it finds a partition of attribute values that optimizes a specific objective function for the k-class problem that is significantly different from IGini.
3.3.",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
LargestClassAlone: an O(nk + n log,3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"n)-time constant approximation
A limitation of HcC is its running time, which is exponential on the number of classes k.",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"To address this issue, we show that a simple algorithm with O(nk+n log n) running time has a constant approximation for our class of impurity measures.
",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"Recall that we are using u to denote ∑
v∈V v.",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"Given u, let i∗ be the index of the coordinate corresponding to the largest value in u, that is, ui∗ ≥ ui for all i. Moreover, let ei∗ be the direction where all coordinates are 0 but coordinated i∗ whose value is 1.",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
We use LargestClassAlone (LCA for short) to denote the algorithm Bei∗ .,3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"The next result, which also relies on Theorem 3.2, shows that LCA has a constant approximation for our class.",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
Theorem 3.6.,3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"LCA is an (3 + √
3)−approximation for every impurity measure in the class C.",3.1. Analysis of a general hyperplane-based procedure,[0],[0]
"Here we show that we can obtain better approximations, with polynomial running time on n and k, when we focus on specific impurity measures.",4. Improved Approximations for Gini and Entropy,[0],[0]
"We consider both Gini and Entropy.
",4. Improved Approximations for Gini and Entropy,[0],[0]
The key idea for the improvement is to characterize the direction that minimizes the denominator of the upper bound on the approximation ration given by Theorem 3.2.,4. Improved Approximations for Gini and Entropy,[0],[0]
"It will be interesting to observe how Gini and Entropy behave significantly different in this sense, with the latter favoring balanced partition.",4. Improved Approximations for Gini and Entropy,[0],[0]
We prove that LCA is a 2-approximation algorithm for IGini.,4.1. Gini,[0],[0]
"To achieve this goal we show that, when I = IGini, ei∗ is a direction that minimizes the expression I(u ◦ d′)",4.1. Gini,[0],[0]
+ I(u ◦,4.1. Gini,[0],[0]
"(1 − d′)) that appears on the denominator of the righthand side of inequality (1).
",4.1. Gini,[0],[0]
Lemma 4.1.,4.1. Gini,[0],[0]
"The direction ei∗ satisfies
IGini(u ◦ ei∗)",4.1. Gini,[0],[0]
+,4.1. Gini,[0],[0]
IGini(u ◦ (1− ei∗)),4.1. Gini,[0],[0]
=,4.1. Gini,[0],[0]
"min
d∈{0,1}k {IGini(u ◦ d) +",4.1. Gini,[0],[0]
"IGini(u ◦ (1− d))}.
",4.1. Gini,[0],[0]
"A direct consequence of the previous lemma and Theorem 3.2 is that LCA gives a 2-approximation for IGini.
Theorem 4.2.",4.1. Gini,[0],[0]
"LCA is a 2-approximation for the Gini impurity measure.
",4.1. Gini,[0],[0]
A natural question is whether the analysis is tight.,4.1. Gini,[0],[0]
"The instance V = {(x, 0, 0), (0, x, 0), (c, 0, c)}, x >> c > 0, shows that this is the case for algorithm Aei∗ .",4.1. Gini,[0],[0]
For LCA (which is Bei∗ ) we are not aware whether the approximation is tight or not.,4.1. Gini,[0],[0]
The worst example we know has impurity 4/3 larger than the optimal one.,4.1. Gini,[0],[0]
"In this section we show that, for the Entropy impurity, LCA achieves an approximation ratio better than the one given by Theorem 3.6.
",4.2. Entropy,[0],[0]
"Let us define the balance of a direction d in {0, 1}k with respect to u as min{u ·d,u · (1−d)}.",4.2. Entropy,[0],[0]
"The next lemma implies that the most balanced direction with respect to u is the one that minimizes the denominator on the approximation ratio given by inequality (1).
",4.2. Entropy,[0],[0]
Lemma 4.3.,4.2. Entropy,[0],[0]
"Let d and d′ be directions in {0, 1}k.",4.2. Entropy,[0],[0]
"Then,
IEnt(u ◦",4.2. Entropy,[0],[0]
d) +,4.2. Entropy,[0],[0]
IEnt(u ◦,4.2. Entropy,[0],[0]
(1− d)),4.2. Entropy,[0],[0]
<,4.2. Entropy,[0],[0]
IEnt(u ◦ d′),4.2. Entropy,[0],[0]
+ IEnt(u ◦,4.2. Entropy,[0],[0]
"(1− d′)) (4)
if and only if d is more balanced than d′ with respect to u, that is, min{d ·u, (1−d) ·u} > min{d′ ·u, (1−d′) ·u}.
",4.2. Entropy,[0],[0]
"Let d∗ be the most balanced direction in {0, 1}k with respect to u.",4.2. Entropy,[0],[0]
The previous result together with Theorem 3.2 guarantee that algorithm Bd∗,4.2. Entropy,[0],[0]
is a 2-approximation for the Entropy impurity.,4.2. Entropy,[0],[0]
"The direction d∗ can be constructed in O(k ∑ v∈V ‖v‖1) time using an algorithm for the subset sum problem (Cormen et al., 1998).
",4.2. Entropy,[0],[0]
Theorem 4.4.,4.2. Entropy,[0],[0]
"There exists a 2-approximation algorithm for the entropy impurity measure that runs inO(k ∑ v∈V ‖v‖1) time.
",4.2. Entropy,[0],[0]
"For LCA we manage to prove the following bound.
",4.2. Entropy,[0],[0]
Theorem 4.5.,4.2. Entropy,[0],[0]
"LCA is a 3-approximation for the Entropy impurity measure.
",4.2. Entropy,[0],[0]
"Given Lemma 4.3, a straightforward reduction from PARTITION problem shows that 2-PMWIP is NP-hard even when I is the Entropy measure.
",4.2. Entropy,[0],[0]
Theorem 4.6.,4.2. Entropy,[0],[0]
"The 2-PMWIP for the Entropy impurity measure is NP-Hard.
",4.2. Entropy,[0],[0]
The complexity of the problem for the case where I is the scaled Gini impurity measure remains open.,4.2. Entropy,[0],[0]
To complement our theoretical study we report a number of experiments with the methods proposed/analyzed in the previous sections.,5. Experiments,[0],[0]
"Our first set of experiments is very similar to the set presented in (Coppersmith et al., 1999) except for a few details.",5.1. Evaluation of Splits Impurity,[0],[0]
"All experiments are Monte Carlo simulations with 10,000 runs, each using a randomly-generated contingency table for the given number of values n and classes k.",5.1. Evaluation of Splits Impurity,[0],[0]
By a contingency table we mean a matrix where each row corresponds to a distinct vector of the input V .,5.1. Evaluation of Splits Impurity,[0],[0]
"Each table was created by uniformly picking a number in {0, . . .",5.1. Evaluation of Splits Impurity,[0],[0]
", 7} for each entry.",5.1. Evaluation of Splits Impurity,[0],[0]
"This guarantees a substantial probability of a row/column having some zero frequencies, which is common in practice.",5.1. Evaluation of Splits Impurity,[0],[0]
"Differing from (Coppersmith et al., 1999), if all the entries corresponding to a value or a class are zero, we re-generate the contingency table, since otherwise the number of actual values and classes would not match n and k.
We compared the following splitting methods: HcC, LCA, SLIQext and PCext.",5.1. Evaluation of Splits Impurity,[0],[0]
"SLIQext is a variant, presented in (Coppersmith et al., 1999), of the SLIQ method proposed in (Mehta et al., 1996).",5.1. Evaluation of Splits Impurity,[0],[0]
"It starts with the partition (V, ∅) and then it greedily moves, from the ’left’ to the ’right’ partition, the vector that yields to the partition with minimum impurity until the the partition (∅, V ) is reached; the best partition found in this process is returned.",5.1. Evaluation of Splits Impurity,[0],[0]
"PCext is a method proposed in (Coppersmith et al., 1999) that defines the partition for the vectors in V by using a hyperplane in Rk whose normal direction is the principal direction of a certain contingency table associated with the instance.",5.1. Evaluation of Splits Impurity,[0],[0]
"According to the experiments reported in (Coppersmith et al., 1999), PCext and SLIQext outperformed other available methods, such as the Flip Flop method (Nadas et al., 1991), in terms of the impurity of the partitions found.
",5.1. Evaluation of Splits Impurity,[0],[0]
"Table 1 and 2 show, for different values of n and k, the percentage of times each method is at least as good as the other competitors for Gini and Entropy, respectively.",5.1. Evaluation of Splits Impurity,[0],[0]
"We only show results for k ≤ 9 because, for larger values of k, HcC becomes non-practical due to its running time.",5.1. Evaluation of Splits Impurity,[0],[0]
"Furthermore, we do not present results for small values of n because, in this case, the optimal partition can be found reasonably quick through an exhaustive search, hence there is no motivation for heuristics.
",5.1. Evaluation of Splits Impurity,[0],[0]
"In general, we observe an advantage of HcC for both the impurity measures, being much more evident for Entropy impurity.",5.1. Evaluation of Splits Impurity,[0],[0]
We also observe that LCA presents the worst results.,5.1. Evaluation of Splits Impurity,[0],[0]
"Additional experiments where we set the maximum possible value in the contingency table to 2 and 15, rather than to 7, presented similar behavior.
",5.1. Evaluation of Splits Impurity,[0],[0]
It is also interesting to observe how far the impurity of the partition generated by a splitting method may be with respect to the best partition found by the other methods.,5.1. Evaluation of Splits Impurity,[0],[0]
"To measure this distance, let us define the relative excess (in percentage) of a partition P w.r.t.",5.1. Evaluation of Splits Impurity,[0],[0]
a partition Q as 100 × (I(P )/I(Q)− 1).,5.1. Evaluation of Splits Impurity,[0],[0]
"The maximum relative excess observed for the partitions generated by HcC, with respect to the partitions generated by the other methods, was 2% and 1.9% for Gini and Entropy, respectively.",5.1. Evaluation of Splits Impurity,[0],[0]
"For SLIQext, the maximum relative excess observed was 9.4% for Gini and 14% for Entropy.",5.1. Evaluation of Splits Impurity,[0],[0]
"For PCext, we observed 3.7% for Gini and 21.6% for Entropy.",5.1. Evaluation of Splits Impurity,[0],[0]
"Finally, for LCA, we had 22.3% for Gini and 43.6% for Entropy.",5.1. Evaluation of Splits Impurity,[0],[0]
"These numbers suggest that the risk of finding a ‘bad’ partition is smaller when HcC is used, specially for the Entropy impurity.
",5.1. Evaluation of Splits Impurity,[0],[0]
Table 3 presents a comparison between the running time of the 4 methods for each configuration of n and k.,5.1. Evaluation of Splits Impurity,[0],[0]
"The numbers are relative to the running time of LCA, which is the fastest of them.",5.1. Evaluation of Splits Impurity,[0],[0]
"Among the other three methods, PCext ob-
tained the best results.",5.1. Evaluation of Splits Impurity,[0],[0]
"As expected, HcC is very competitive for small values of k and it becomes less competitive when k grows.",5.1. Evaluation of Splits Impurity,[0],[0]
"For the slowest configuration, n = 50 and k = 9, HcC took, in average, 0.38 seconds.",5.1. Evaluation of Splits Impurity,[0],[0]
We can also observe that SLIQext becomes less competitive as n grows.,5.1. Evaluation of Splits Impurity,[0],[0]
All the experiments were executed on a PC Intel i7-6500U CPU with 2.5GHz and 8GB of RAM.,5.1. Evaluation of Splits Impurity,[0],[0]
The algorithms were implemented in Python 3 using numpy and and are available in https://github.com/felipeamp/icml-2018.,5.1. Evaluation of Splits Impurity,[0],[0]
We also carried out a set of experiments to evaluate how the methods behave when they are used in decision tree induction.,5.2. Decision tree induction,[0],[0]
"Here we just present a summary of these experiments – a more complete complete description can be found in the supplementary material.
",5.2. Decision tree induction,[0],[0]
We employed 11 datasets in total.,5.2. Decision tree induction,[0],[0]
"Eight of them are from the UCI repository: Mushroom, KDD98, Adult, Nursery, Covertype, Cars, Contraceptive and Poker (Lichman, 2013).",5.2. Decision tree induction,[0],[0]
Two others are available in Kaggle: San Francisco Crime and Shelter Animal Outcome (SF-OpenData; AustinAnimal-Center).,5.2. Decision tree induction,[0],[0]
"The last dataset was created by translating texts from the Reuters database (Lichman, 2013) into phonemes, using the CMU pronouncing dictionary (CMU).",5.2. Decision tree induction,[0],[0]
"We shall note that these datasets were also used in (Laber & de A. Mello Pereira, 2018) where methods for splitting nominal attributes that do not rely on impurity measures are proposed.
",5.2. Decision tree induction,[0],[0]
We chose these datasets because they have at least 1000 samples and they either contain multi-valued attributes or attributes that can be naturally aggregated to produce multivalued attributes.,5.2. Decision tree induction,[0],[0]
"For datasets Cars, CoverType, Nursery and Contraceptive we add new nominal attributes that were obtained by aggregating some of the original ones.",5.2. Decision tree induction,[0],[0]
"Additional details are given in the supplementary material.
",5.2. Decision tree induction,[0],[0]
In this second set of experiments we build decision trees with depth at most 16.,5.2. Decision tree induction,[0],[0]
"We employed a 95% one-tailed
paired t-student test to compare the accuracy attained by the methods over 20 3-fold stratified cross-validations.",5.2. Decision tree induction,[0],[0]
Table 4 shows how LCA and HcC compare with each of the other methods with regards to the number of datasets in which they had statistically better/worse accuracy.,5.2. Decision tree induction,[0],[0]
"As an example, the entry associated with Entropy/PCExt in the top Table 4 shows that out of the 11 datasets, for the Entropy impurity, LCA was statistically better in 4 datasets while PCExt was better in none.
",5.2. Decision tree induction,[0],[0]
"Given the results on the previous section, we were not expecting a strong performance from LCA.",5.2. Decision tree induction,[0],[0]
"However, to our surprise, LCA was quite competitive, performing better than some of the other methods in these datasets, specially for the Entropy impurity measure.",5.2. Decision tree induction,[0],[0]
"HcC, as expected, had a good performance.",5.2. Decision tree induction,[0],[0]
"These results suggest that LCA is also an interesting alternative, specially when speed is an issue.",5.2. Decision tree induction,[0],[0]
In this paper we proved that the 2-PMWIP is NP-Hard and we devised algorithms with constant approximation guarantee for it.,6. Final Remarks,[0],[0]
"Furthermore, we reported experiments that suggest that our methods proposed are good candidates to be used in splitting nominal attributes with many values during decision tree/random forest induction.",6. Final Remarks,[0],[0]
"HcC has the advantage of generating partitions with lower impurity than other available methods while LCA has the advantage of being very fast.
",6. Final Remarks,[0],[0]
Some interesting questions remain open.,6. Final Remarks,[0],[0]
"The main one concerns the existence of a FPTAS for 2-PMWIP, that is, an algorithm that for every > 0 obtains an approximation (1+ ) with running time polynomial on n and 1/ .",6. Final Remarks,[0],[0]
"Another interesting question regards the existence of algorithms with provably approximation for the L-PMWIP, the most general problem where the values of an attribute have to be partitioned into at most L groups.",6. Final Remarks,[0],[0]
The problem of splitting attributes is one of the main steps in the construction of decision trees.,abstractText,[0],[0]
"In order to decide the best split, impurity measures such as Entropy and Gini are widely used.",abstractText,[0],[0]
"In practice, decision-tree inducers use heuristics for finding splits with small impurity when they consider nominal attributes with a large number of distinct values.",abstractText,[0],[0]
"However, there are no known guarantees for the quality of the splits obtained by these heuristics.",abstractText,[0],[0]
"To fill this gap, we propose two new splitting procedures that provably achieve nearoptimal impurity.",abstractText,[0],[0]
We also report experiments that provide evidence that the proposed methods are interesting candidates to be employed in splitting nominal attributes with many values during decision tree/random forest induction.,abstractText,[0],[0]
Binary Partitions with Approximate Minimum Impurity,title,[0],[0]
"Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 665–675, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.
Knowledge Base Population (KBP) tasks, such as slot filling, show the particular importance of entity-oriented automatic relevant document acquisition. Rich, diverse and reliable relevant documents satisfy the fundamental requirement that a KBP system explores the nature of an entity. Towards the bottleneck problem between comprehensiveness and definiteness of acquisition, we propose a collaborative archiving method. In particular we introduce topic modeling methodologies into entity biography profiling, so as to build a bridge between fuzzy and exact matching. On one side, we employ the topics in a small-scale high-quality relevant documents (i.e., exact matching results) to summarize the life slices of a target entity (i.e., biography), and on the other side, we use the biography as a reliable reference material to detect new truly relevant documents from a large-scale partially complete pseudo-feedback (i.e., fuzzy matching results). We leverage the archiving method to enhance slot filling systems. Experiments on KBP corpus show significant improvement over stateof-the-art.",text,[0],[0]
Entity archiving is an entity-oriented document retrieval task.,1 Introduction,[0],[0]
"Towards a target entity of a specific type, such as the ones discussed in this paper, a person or an organization, the goal of entity archiving is to search and collect all relevant documents from large-scale data sets under limited prior knowledge of the entity.",1 Introduction,[0],[0]
"We limit our study to the regular English entity archiving, in which the prior knowledge contains the com-
monly used full name (formatted by English entity naming criteria) along with a gold-standard reference document, such as a news story on President “George W. Bush”.
",1 Introduction,[0],[0]
Entity archiving plays a fundamental role in KBP tasks.,1 Introduction,[0],[0]
It narrows down the range of the data source for knowledge discovery to small-scale closely related documents.,1 Introduction,[0],[0]
"Such documents, on one hand, contain informative content on a target entity, which is extremely favorable for background knowledge extraction.",1 Introduction,[0],[0]
"On the other hand, the documents provide definitive evidence for verifying the claimed identity of the entity.
",1 Introduction,[0],[0]
"As for KBP slot filling and verification tasks (Surdeanu and Ji, 2014), the archived relevant documents to an entity provide sufficient contexts (provenances) of the concrete instances (fillers) of the entity attributes (slots).",1 Introduction,[0],[0]
"See Figure 1, in which both the provenances support filler extraction, meanwhile the provenance 1 additionally provides the evidence to verify the fillers (e.g., is episcopalism the true religion of Bush?).
",1 Introduction,[0],[0]
"The main challenges of entity archiving are as
665
follows: 1) it is difficult to retrieve all relevant documents through exact matching at the level of entity name, because an entity can be mentioned in various forms, such as alternate names and abbreviations; 2) in contrast, fuzzy matching introduces a large amount of noise into retrieval results (see the examples in Figure 1), although it is capable of recalling an overwhelming majority of relevant documents; 3) inadequate prior knowledge makes it difficult to generate a full profile of an entity; 4) although pseudo-feedback is helpful to enrich the prior knowledge, traditional entity profiling (e.g., bag-of-words) methods establish vague boundaries among different life slices of an entity.",1 Introduction,[0],[0]
"For example, they are incapable of distinguishing the slice of the “Church Scientologist in Sea Organization” of Mark Fisher 1 from the freelance career as the “Corporate liaison to Miscavige”.",1 Introduction,[0],[0]
"As a result it is difficult to enhance the independent effects of different slices on the entity-document relevance determination.
",1 Introduction,[0],[0]
"To solve these problems, we propose a collaborative entity archiving (CEA) method.",1 Introduction,[0],[0]
"It employs the exact-matching based document retrieval to obtain a few high-quality reference documents, and leverages fuzzy matching for high-speed acquisition of adequate candidate documents (section 3).",1 Introduction,[0],[0]
"In addition, CEA uses the reference documents as prior knowledge to model the topic-level biography of an entity, and identifies the truly relevant documents from the candidates based on biography-document relevance (section 4).",1 Introduction,[0],[0]
Experiments show that CEA has substantial advantages over traditional retrieval methods (section 5.1).,1 Introduction,[0],[0]
We apply CEA to state-of-the-art slot filling systems.,1 Introduction,[0],[0]
Experimental results show that CEA provides consistent gains (section 5.2).,1 Introduction,[0],[0]
 Entity Search One research topic similar to entity archiving is entity search.,2 Related Work,[0],[0]
"Entity search aims to seek, collect, and rank entities associated with specific information needs (Balog et al, 2011).",2 Related Work,[0],[0]
"The TREC Enterprise track featured an expert finding task (Balog et al, 2008a): given a topic, return a ranked list of experts on the topic.",2 Related Work,[0],[0]
"In response to this problem, there have been considerable efforts on content based retrieval models, as well as feature
1 Mark Fisher: a PERSON query name in Slot Filing evaluation of 2014, ID=SF14_ENG_031
selection, such as proximity (Petkova and Croft, 2007), document priors (Hu et al, 2006; Zhu et al, 2010), expert-document associations (Balog and De-Rijke, 2008) and external evidence (Serdyukov and Hiemstra, 2008).
",2 Related Work,[0],[0]
"Since INEX was launched in 2002, which is an entity ranking task specific to structured data and multimedia (Demartini et al, 2010), structured features have been widely used in entity search, such as the most recent studies on Wikipedia links and categories (Vercoustre et al, 2008; Zhu et al, 2008; Jiang et al, 2009; Weerkamp et al, 2009; Kaptein and Kamps, 2009; Balog et al, 2011) and web link structure (Balog et al, 2008b; You et al, 2011; Blanco et al, 2011; Neumayer et al, 2012; Bron et al, 2013).",2 Related Work,[0],[0]
"
 ",2 Related Work,[0],[0]
"Slot Filling The goal of slot filling is to seek and extract the concrete instances (fillers) specific to multiple entity attributes (slots) from a large-scale textual data set (Ji et al., 2010 and 2011; Surdeanu, 2013; Surdeanu and Ji, 2014).",2 Related Work,[0],[0]
"The quality of the fillers largely depends on the performance of entity archiving and information extraction.
",2 Related Work,[0],[0]
"Related studies on archiving mainly employed traditional retrieval techniques, including query expansion and string matching (Ji and Grishman, 2011).",2 Related Work,[0],[0]
"A few studies involved document ranking and prioritizing by using probability model (Byrne and Dunnion, 2010; Roth et al, 2014) and statistical language model (Chrupala et al, 2010).
",2 Related Work,[0],[0]
"For filler extraction, great efforts were made to generate effective patterns and structure perceptrons by supervised learning and reasoning (Chen et al, 2010; Grishman and Min, 2010; Gao et al, 2010; Surdeanu et al, 2011; Louis et al, 2011; Kisiel et al, 2013).",2 Related Work,[0],[0]
"And effective feature selection and distant-supervision based classifiers have been explored (Lehmann et al, 2010; Artiles et al, 2011; Sun et al, 2011; Roth and Klakow, 2013; Roth et al, 2014).",2 Related Work,[0],[0]
"Recently active learning (Angeli et al, 2014), truth-finding (Yu et al, 2014) as well, scanning (Yu et al., 2015) and ensemble learning (Viswanathan et al., 2015) were introduced to this field.
 ",2 Related Work,[0],[0]
"Brief Summary In all, entity search concentrates on the analysis of a single specific aspect of an entity, which is of interest or related to a domain.",2 Related Work,[0],[0]
"In the expert finding task, only academic careers of person entities (potential experts) are of concern in entity-document relevance determination.",2 Related Work,[0],[0]
"By contrast, for the sake of comprehensive understanding of an entity, entity archiving necessarily
takes multiple and diverse aspects into account, such as a person’s career, family, religion, sociality, academics, etc.",2 Related Work,[0],[0]
"Due to the difference in goals, entity search techniques cannot be used directly to solve entity archiving problems.
",2 Related Work,[0],[0]
The performance of conventional retrieval techniques was generally limited due to the lack of precise modeling of the characteristics of an entity.,2 Related Work,[0],[0]
Sparse prior knowledge and absence of effective profiling methods cause difficulties in characterizing the entity.,2 Related Work,[0],[0]
"The rest of the paper will be about knowledge acquisition and partition, as well as the collaborative method, along with a topic-level biographical profiling method.",2 Related Work,[0],[0]
We use string matching based retrieval methods to acquire relevant documents.,3 Prior Knowledge Acquisition,[0],[0]
It is worth considering that the acquired documents are not straightforwardly defined as the final entity archiving results.,3 Prior Knowledge Acquisition,[0],[0]
"As we will show in this section, some of them are reliable, while others are full of noise.",3 Prior Knowledge Acquisition,[0],[0]
"Instead, we regard them as the prerequisite knowledge for a coarse-to-fine processing.
",3 Prior Knowledge Acquisition,[0],[0]
"In the retrieval phase, a query Q is formulated as the full name of the target entity, while a document D is represented as a string of words.",3 Prior Knowledge Acquisition,[0],[0]
D is determined to be relevant only if it contains some words that match,3 Prior Knowledge Acquisition,[0],[0]
Q. Accordingly we name such words as entity mentions.,3 Prior Knowledge Acquisition,[0],[0]
Both Q and D are preprocessed by tokenization and stop-word filtering.,3 Prior Knowledge Acquisition,[0],[0]
Other commonly used preprocessing steps (stemming and lemmatization) are disabled because they may cause confusion between entity mentions and common words.,3 Prior Knowledge Acquisition,[0],[0]
"Table 1 shows the examples where the underlined words in <1> denotes an entity mention but <2> does not.
",3 Prior Knowledge Acquisition,[0],[0]
"We employ two matching methods for the rel-
evance determination: exact and fuzzy matching.
Exact matching (EM) requires that a sequence of successive words in D exactly matches Q. By EM, entity archiving regards a full entity name
as an indivisible word-order-fixed unit.",3 Prior Knowledge Acquisition,[0],[0]
"Accordingly it only acquires the documents which contain the entity mentions in the form of completely-preserved full name.
",3 Prior Knowledge Acquisition,[0],[0]
"Fuzzy matching (FM) relaxes the conditions to a large extent, allowing Q to be split into nonadjacent words.",3 Prior Knowledge Acquisition,[0],[0]
"In particular, it supports the change in word order as well as partial match.",3 Prior Knowledge Acquisition,[0],[0]
"By FM, entity archiving is able to retrieve documents that contain the entity mentions in the form of separated, pruned and/or reordered names.",3 Prior Knowledge Acquisition,[0],[0]
"Table 2 shows some examples of using these matching methods, where the mark “•” denotes the available methods for a certain form of entity mention.
",3 Prior Knowledge Acquisition,[0],[0]
Mark Fisher (PER) <,3 Prior Knowledge Acquisition,[0],[0]
"ID: SF14_ENG_031 >
Mark Fisher, Sea Org member.",3 Prior Knowledge Acquisition,[0],[0]
"(exact)
",3 Prior Knowledge Acquisition,[0],[0]
"Availability: EM (•) FM (•)
Mark, husband of Julie Fisher.",3 Prior Knowledge Acquisition,[0],[0]
(separation),3 Prior Knowledge Acquisition,[0],[0]
"Fisher had been Miscavige’s aide for 7 years.(pruning) Fisher’s first name, Mark, is impressive due to his inconceivable career change.",3 Prior Knowledge Acquisition,[0],[0]
"(reordering)
Availability: EM ( ) FM (•)
",3 Prior Knowledge Acquisition,[0],[0]
Table 2:,3 Prior Knowledge Acquisition,[0],[0]
"Examples of string matching results
EM and FM have substantially different advantages and disadvantages in entity archiving.",3 Prior Knowledge Acquisition,[0],[0]
"Table 3 shows the performance of EM and FM based entity archiving on KBP corpus (Surdeanu, 2013).",3 Prior Knowledge Acquisition,[0],[0]
We will introduce the corpus in details in Section 5.,3 Prior Knowledge Acquisition,[0],[0]
EM yields precise archiving results because the constraint conditions are helpful to reduce uncertainty in string matching.,3 Prior Knowledge Acquisition,[0],[0]
"In contrast FM-based archiving is able to match entity name mentions with various forms, and thus it achieves higher recall.
",3 Prior Knowledge Acquisition,[0],[0]
"However FM generally introduces much noise,
namely those mistakenly retrieved irrelevant documents.",3 Prior Knowledge Acquisition,[0],[0]
The documents are recalled because some pseudo entity mentions they contain can easily satisfy the constraints of fuzzy matching.,3 Prior Knowledge Acquisition,[0],[0]
See examples of the pseudo mentions in Table 4.,3 Prior Knowledge Acquisition,[0],[0]
"As a result, FM yields a very low precision score.
",3 Prior Knowledge Acquisition,[0],[0]
Undoubtedly it is helpful for global optimization of entity archiving to make full use of the advantages of EM and FM.,3 Prior Knowledge Acquisition,[0],[0]
"In view of the abovementioned investigation, we partition the string matching results into two parts, exact and fuzzy ones, which are used as reliable prior knowledge (named reference source) and unrefined prior knowledge (candidate source) respectively.",3 Prior Knowledge Acquisition,[0],[0]
"Most documents in the reference are truly related to the target entity but the scale is not big (see Recall of EM in Table 3), while the candidate is full of both true answers and noise (see Precision and Recall of FM in Table 3), respectively.",3 Prior Knowledge Acquisition,[0],[0]
"As we will show in the next section, the final archiving results are generated by synthesizing the sources in a collaborative coarse-to-fine way.",3 Prior Knowledge Acquisition,[0],[0]
We propose a Collaborative Entity Archiving approach (CEA for short).,4 Collaborative Entity Archiving (CEA),[0],[0]
CEA synthesizes the reference source and candidate source in a collaborative manner (section 4.1) through a biography-document relevance determination method (section 4.2 and 4.3).,4 Collaborative Entity Archiving (CEA),[0],[0]
"In addition, CEA involves mention disambiguation and query expansion in pre-processing to optimize the quality of both sources (section 4.4)",4 Collaborative Entity Archiving (CEA),[0],[0]
"CEA models the biography of an entity by using the topics in the reference source, in which, each topic serves as the description of a slice of life of the target entity (life slice for short), as shown in Figure 2.",4.1 Overall Framework of CEA,[0],[0]
"The Life slice means an episode in the whole story of the entity, which may represent an event, state or scenario at a certain moment, such as a person’s birth or an organization’s establishment.
",4.1 Overall Framework of CEA,[0],[0]
"CEA pulls out a document from the candidate source, one by one, and measures the biographydocument relevance at the topic level.",4.1 Overall Framework of CEA,[0],[0]
"By using a relevance threshold as the discrimination factor, CEA either preserves the document if it is rele-
vant, or filters otherwise.",4.1 Overall Framework of CEA,[0],[0]
"Meanwhile, CEA adds the newly found relevant documents to the reference source, and updates the biography by reshaping life slices (i.e., topics).",4.1 Overall Framework of CEA,[0],[0]
"CEA iteratively goes through the process of biography formulation, biography-document relevance measurement and determination until a condition is satisfied.",4.1 Overall Framework of CEA,[0],[0]
Finally CEA selects all the preserved documents in the reference source as the final output.,4.1 Overall Framework of CEA,[0],[0]
Figure 2 shows the framework.,4.1 Overall Framework of CEA,[0],[0]
"We design a generative approach to estimate the biography-document relevance r, which calculates the conditional probability that a candidate document D generates the biography B:
 ( | )r P B D (1)
",4.2 Biography-Document Relevance Models,[0],[0]
"In total we leverage three probabilistic models
for modeling B and D, including relevance model, topic model and context-level topic model.",4.2 Biography-Document Relevance Models,[0],[0]
"Then we introduce Hellinger Distance (Lindsay, 1994) into relevance measurement.
 ",4.2 Biography-Document Relevance Models,[0],[0]
"Relevance Model (RM) Generally, Relevance Model (RM) (Huang and Croft, 2009) refers to the probability distribution over all words conditioned on their occurrences in a set of previously-known relevant documents (or high-quality pseudo-relevant documents), i.e., , ( | )w V P w R  , where V is the vocabulary, R is the document set, and P(w|R) can be estimated by TF-IDF.",4.2 Biography-Document Relevance Models,[0],[0]
RM is often used in combination with Document Model (DM).,4.2 Biography-Document Relevance Models,[0],[0]
"Similar to RM, DM refers to the probability distribution over words in a particular document, i.e., , ( | )w V P w D  .",4.2 Biography-Document Relevance Models,[0],[0]
The relevance between R and D is normally determined by the agreement of RM and DM.,4.2 Biography-Document Relevance Models,[0],[0]
"The agreement can be estimated with Hellinger Distance between the models:
2 ( | ) ( ( | ) ( | ))
w V
H RM DM P w R P w D

  (2)
RM is a widely-used probabilistic model for information retrieval.",4.2 Biography-Document Relevance Models,[0],[0]
"It determines the relevance of a document to an object in accordance with homogeneousness in content between the document and the relevant documents of the object.
",4.2 Biography-Document Relevance Models,[0],[0]
"For an entity, in our case, we generate RM on the reference source, and regard it as the probabilistic model of a macro-level all-embracing biography B over the prior knowledge R. For a candidate document D, the biography-document relevance r is measured with Hellinger Distance between RM and DM: P(B|D)=H(RM|DM).",4.2 Biography-Document Relevance Models,[0],[0]
"We
will demonstrate the effect of RM heavily relies on the quality of reference source in experiments.
 ",4.2 Biography-Document Relevance Models,[0],[0]
"Topic Model (TM) Empirically, RM is coarse-grained.",4.2 Biography-Document Relevance Models,[0],[0]
"It mixes up different, separate and incoherent life slices of an entity.",4.2 Biography-Document Relevance Models,[0],[0]
"A more serious problem is that RM assigns uneven weights to life slices, giving excessive weights to the words about the popular slices, but low or even zeroth weights to the unpopular ones.",4.2 Biography-Document Relevance Models,[0],[0]
"A popular slice is defined as the slice of greater concern, which is normally frequently mentioned in the reference source, such as the slice of “the career of George W. Bush as the President” (high weight) versus “his childhood” (low weight).",4.2 Biography-Document Relevance Models,[0],[0]
"As a result, the RM based biography-document relevance is only helpful to identify and recall the documents relevant to the popular slices but not to the unpopular ones.
",4.2 Biography-Document Relevance Models,[0],[0]
"As a modification, we employ Topic Model (TM) for biography modeling.",4.2 Biography-Document Relevance Models,[0],[0]
We define a topic in the reference source as an independent finegrained representation for a microscopic life slice.,4.2 Biography-Document Relevance Models,[0],[0]
Accordingly we treat the biography as a bucket of topics.,4.2 Biography-Document Relevance Models,[0],[0]
"We leverage Latent Dirichlet Allocation (LDA) (Blei et al, 2003; Wei and Croft, 2006) for topic discovery and modeling in the reference source.",4.2 Biography-Document Relevance Models,[0],[0]
"A topic is modeled as a probability distribution over all words in lexicon conditioned on the association of the words with the topic, denoted as w V  , P(w|tR), in which tR refers to a topic in the reference source, representing a life slice s. Table 5 shows partial topic models (slices) in the reference source of Mark Fisher, where the highlighted probability values by a box reveal the words that well characterize a topic (slice).",4.2 Biography-Document Relevance Models,[0],[0]
"In the same way, we survey the topics tC in the candidate source, modeled as w V  , P(w|tC).",4.2 Biography-Document Relevance Models,[0],[0]
"It is worth noting that those topics (tC) may represent anything, namely the slices of the target entity or namesakes, related or unrelated events, etc.",4.2 Biography-Document Relevance Models,[0],[0]
"It means they are full of noise.
",4.2 Biography-Document Relevance Models,[0],[0]
"In practice, given a target entity, its reference source (exact matching results) is a subset of the candidate source (fuzzy matching results).",4.2 Biography-Document Relevance Models,[0],[0]
"We picked the reference source out of the candidate to parse topics independently, forming the set of tR. Meanwhile, we parse topics in the candidate source to form the set of tC. Benefitting from the separate treatment, some of the truly related topics (tR) to the entity (correct slices) can be collected along with less noise.",4.2 Biography-Document Relevance Models,[0],[0]
"Using the topics as references, we detect the relevant documents in the candidate source in terms of the topic-level biography-document relevance P(B|D).
",4.2 Biography-Document Relevance Models,[0],[0]
"Given a document D in the candidate source, we transform P(B|D) into the combination of topic-document relevance of all topics in the reference source.",4.2 Biography-Document Relevance Models,[0],[0]
"We measure the topic-document relevance with the conditional probability P(tR|D) that the topic tR occurs in the document D. Accordingly, P(B|D) is estimated by:
( | ) ( | )
log( ) log ( | )
R
R
R
t
R
t
r P B D P t D
r P t D
 


 (3)
where, we incorporate the log likelihood into the numerical calculation for the sake of nonzero joint probability.
",4.2 Biography-Document Relevance Models,[0],[0]
"Due to the separate topic modeling procedures for the reference and candidate sources, the probability P(tR|D) ̶ a topic tR in the reference source occurs in a candidate document D ̶ cannot be obtained directly.",4.2 Biography-Document Relevance Models,[0],[0]
"To solve the problem, we introduce the joint probability of topic-topic relevance between topics (tR) in reference and topics (tC) in candidate (see the mode in Figure 2) into the probability calculation:
, ( | ) ( | ) ( | )
C C
R R R R C C
t T
t T P t D P t t P t D

    (4)
where TR is the set of all topics in the reference source while TC is the candidate.",4.2 Biography-Document Relevance Models,[0],[0]
"The topic-topic relevance P(tR|tC) is approximated by Hellinger distance estimation between the topic models of tR and tC. As a whole, we measure the biographydocument relevance as:
2
log( ) log ( | ) ( | )
log ( | ) ( | )
",4.2 Biography-Document Relevance Models,[0],[0]
"log ( | ) ( | )
log( ( | ) ( | ))",4.2 Biography-Document Relevance Models,[0],[0]
"( | )
R R C C
R R C C
R R C C
R R C C
R C C
t T t T
R C C
t T t T
R C C
t T t T
R C C
t T t T w V
r P t t P t D
P t t P t D
H t t P t D
P w t P w t P t D
 
 
 
  



 
 
 
 
  
(5)
",4.2 Biography-Document Relevance Models,[0],[0]
"We employ the toolkit GibbsLDA++ 2 in topic modeling, which is an implementation of LDA using Gibbs sampling (Porteous et al, 2008).",4.2 Biography-Document Relevance Models,[0],[0]
GibbsLDA++ makes it easy to parse the topics in a document set as well as estimate topic models P(w|t).,4.2 Biography-Document Relevance Models,[0],[0]
"Besides, GibbsLDA++ offers the probability over topics in generating a specific document, facilitating the estimation of P(tC|D) in equation (5).",4.2 Biography-Document Relevance Models,[0],[0]
"Table 6 shows the operating parameters what we set in experiments, where the ones {α, β} were set as the default values while the iterative number num is an empirical value.
",4.2 Biography-Document Relevance Models,[0],[0]
The necessary precondition for GibbsLDA++ in topic partition is to define the number Nt of potential topics in a set of documents.,4.2 Biography-Document Relevance Models,[0],[0]
"We execute the Hierarchical Dirichlet Processes (Teh et al, 2005), abbr., HDP, to predict Nt.",4.2 Biography-Document Relevance Models,[0],[0]
"HDP is similar to current hierarchical information organization methods, such as the hierarchical clustering (Kummamuru et al, 2004), unsupervised and coarse-to-fine grained.",4.2 Biography-Document Relevance Models,[0],[0]
"Hence HDP is useful in exploring the basic rules of topic partition in an automatic way, such as number and granularity.",4.2 Biography-Document Relevance Models,[0],[0]
"We employ HDP to estimate the number (Nt) of all possible topics in reference source and candidate separately, acquiring two Nt for each target entity, one per source.
 ",4.2 Biography-Document Relevance Models,[0],[0]
Context-level Topic Model (CTM),4.2 Biography-Document Relevance Models,[0],[0]
"In consideration of the reliability of contexts in representing closely-related life slices to the entity, we use the contexts around entity mentions to improve the slice-oriented topic modeling.
",4.2 Biography-Document Relevance Models,[0],[0]
A context consists of the words co-occurring with an entity mention in a radius-fixed text span or syntactic or dependent structure (see instructions in Table 7).,4.2 Biography-Document Relevance Models,[0],[0]
"Given a target entity, the entity mention in the reference source is its full name.",4.2 Biography-Document Relevance Models,[0],[0]
"The union of all contexts in the source defines the vocabulary VR that most probably represent
2 http://gibbslda.sourceforge.net/
the slices of the entity.",4.2 Biography-Document Relevance Models,[0],[0]
"In the candidate source, on the contrary, the entity mention can be a reordered, separated or pruned entity name, as well as abbreviation or alias, such as GWB (abbr.) and Dubya (alias) of George W. Bush.",4.2 Biography-Document Relevance Models,[0],[0]
"Different from the cases in reference, the vocabulary VC obtained from the contexts in candidate are closely related to diverse entities or other objects with the same name (see Table 2&4).
",4.2 Biography-Document Relevance Models,[0],[0]
"CTM measures the biography-document relevance in the same way with TM, estimating the topic-level P(B|D) by equation (5).",4.2 Biography-Document Relevance Models,[0],[0]
The only difference lies in the available words in topic model P(w|t).,4.2 Biography-Document Relevance Models,[0],[0]
"For the ones not included in VR and VC, CTM assigns a weight zero in topic model no matter what GibbsLDA++ does.",4.2 Biography-Document Relevance Models,[0],[0]
"For each target entity, CEA measures the biography-document relevance for all documents in the candidate source.",4.3 Unsupervised Threshold Estimation,[0],[0]
"In the light of the relevance scores, CEA ranks the documents and sets a clear threshold θ to cut off the long tail in the ranking list, in other words, filtering the documents that have a relevance score lower than θ.",4.3 Unsupervised Threshold Estimation,[0],[0]
"The preserved documents will be added to the reference source for both biography reformulation and archiving result output.
",4.3 Unsupervised Threshold Estimation,[0],[0]
"We estimate the threshold by learning density distribution of documents over relevance scores (Arampatzis et al, 2009).",4.3 Unsupervised Threshold Estimation,[0],[0]
Density means the number of documents that have similar relevance scores.,4.3 Unsupervised Threshold Estimation,[0],[0]
The distribution is produced by densities within all interval ranges of relevance score.,4.3 Unsupervised Threshold Estimation,[0],[0]
"Our empirical findings show that the density distribution fits a mixture of two Gaussians, where the highly relevant documents and the irrelevant ones distribute in two separate Gaussian peaks respectively.",4.3 Unsupervised Threshold Estimation,[0],[0]
"Accordingly we define the threshold as the range of relevance score at the extreme point between the peaks, as shown in Figure 3.
",4.3 Unsupervised Threshold Estimation,[0],[0]
"In order to detect the extreme point, we firstly use a cubic polynomial function to approximate
the density distribution.",4.3 Unsupervised Threshold Estimation,[0],[0]
"Second, we go through the integral solution of the function in every finegrained interval range of relevance score (interval is set as max(r)/100).",4.3 Unsupervised Threshold Estimation,[0],[0]
We finally detect the extremum between peaks.,4.3 Unsupervised Threshold Estimation,[0],[0]
"The threshold is initialized during runtime exclusively for each target entity, without training.",4.3 Unsupervised Threshold Estimation,[0],[0]
It is re-estimated every time when the biography is reformulated.,4.3 Unsupervised Threshold Estimation,[0],[0]
CEA identifies relevant documents in candidate source and moves them to reference.,4.4 Termination Criterion for Iteration,[0],[0]
"Then CEA reshapes statistical models (RM, TM or CTM) over the updated sources.",4.4 Termination Criterion for Iteration,[0],[0]
"In terms of the reformed models, CEA starts a new round of relevance determination, data movement, and statistical modeling.",4.4 Termination Criterion for Iteration,[0],[0]
"CEA keeps it going until meeting any of the following termination criterions:
 T1: No more new topic occurs in the reference source (Nt doesn’t change).  ",4.4 Termination Criterion for Iteration,[0],[0]
T2:,4.4 Termination Criterion for Iteration,[0],[0]
"The number of the documents in Peak1 (Figure 3) begins to increase continuously.
",4.4 Termination Criterion for Iteration,[0],[0]
T2 is triggered if T1 loses its efficacy.,4.4 Termination Criterion for Iteration,[0],[0]
"The in-
validation happens when some general slices (i.e., general topics) are mistakenly introduced into the reference source, causing large-scale irrelevant document to be recalled and moved to reference.",4.4 Termination Criterion for Iteration,[0],[0]
"It will dramatically increase the number (Nt) of topics in a long term in the iterative procedure, driving CEA to capture more irrelevant documents.",4.4 Termination Criterion for Iteration,[0],[0]
Thus Peak1 will be enlarged continuously.,4.4 Termination Criterion for Iteration,[0],[0]
"However, if as expected, Peak1 should be narrowed with increasing the iteration times because:
 Fewer new related slices appear.  ",4.4 Termination Criterion for Iteration,[0],[0]
"The number of documents related to the
slices is less than that in previous iterations.",4.4 Termination Criterion for Iteration,[0],[0]
"In the preprocessing phase, we improve the precision of EM because higher-quality EM results can offer more reliable reference documents for biography modeling.",4.5 Optimization of EM and FM,[0],[0]
"In addition, we expand queries for FM to recall a larger number of relevant documents.",4.5 Optimization of EM and FM,[0],[0]
"It is helpful to minimize the loss of relevant documents before proceeding to CEA.
",4.5 Optimization of EM and FM,[0],[0]
"To improve EM, we focus on identifying the common words that completely match the full name of the target entity.",4.5 Optimization of EM and FM,[0],[0]
"The words normally are elusive and easily treated as a correct entity name, called deceptive name, see that in (1).
",4.5 Optimization of EM and FM,[0],[0]
"(1) Countrywide Financial <ORG> True: Countrywide Financial Corporation.
",4.5 Optimization of EM and FM,[0],[0]
"Deceptive: Bank of America purchased the failing countrywide financial for $4.1 billion.
",4.5 Optimization of EM and FM,[0],[0]
"To reduce EM errors caused by deceptive names, we use name tagging (Miller et al, 2004) to distinguish deceptive names and true names.",4.5 Optimization of EM and FM,[0],[0]
"Further, we filter the documents that are mistakenly retrieved based on the match between a deceptive name and the full-entity-name based query Q.
We leverage an Alternate Name Table (ANT) for query expansion.",4.5 Optimization of EM and FM,[0],[0]
ANT is a mapping table between entity name and alternate name.,4.5 Optimization of EM and FM,[0],[0]
"An alternate name is either generated according to the naming conventions (Burman et al, 2011), such as abbreviation, suffixation and revivification.",4.5 Optimization of EM and FM,[0],[0]
"Some alternative names were extracted from knowledge base through redirect links (Nia et al, 2014), such as nicknames in Wikipedia dumps.",4.5 Optimization of EM and FM,[0],[0]
"For an entity, we reformulate query Q by the combination of the pre-assigned full entity name and all possible alternate names in ANT, see (2).
",4.5 Optimization of EM and FM,[0],[0]
"(2) Initial Q: Countrywide Financial Corporation.
",4.5 Optimization of EM and FM,[0],[0]
"Expanded: Countrywide Financial+Corporation
+Corp. +Company +Co. +Ltd. +Co Ltd. +CFC.
",4.5 Optimization of EM and FM,[0],[0]
"We use the expanded query for FM to increase the number of relevant documents in the candidate source, regardless of whether or not it will introduce a larger scale of new noises.",4.5 Optimization of EM and FM,[0],[0]
We evaluate our methods on KBP 2013 corpus.,5 Experiments,[0],[0]
"The corpus contains 2.1M texts collected from web pages, newswires and discussion forums.",5 Experiments,[0],[0]
"From this corpus, a slot filling system is required to find fillers for 41 types of slots that represent the attributes of the target entities.",5 Experiments,[0],[0]
"There are 25 slot types of person and 16 slot types of organization, such as a Person’s birth date and an Organization’s founder (Ji et al., 2010 and 2011).
",5 Experiments,[0],[0]
"KBP 2013 includes 100 target entities and ground-truth fillers and provenances, where the ground-truth data was obtained by manual verification and annotation on the pool of system outputs.",5 Experiments,[0],[0]
"The provenances contain the IDs of documents relevant to target entities and fine-grained text spans which illustrate the eligibility of fillers.
",5 Experiments,[0],[0]
"In total there are 1,851 gold standard relevant documents available for the evaluation of entity archiving.",5 Experiments,[0],[0]
However the data is far from enough because it only covers a small portion of all relevant documents in the pool.,5 Experiments,[0],[0]
"Most are excluded since KBP annotators ignore relevant documents in which there isn’t any filler for the assigned slots or, although exists, the fillers were inexactly identified by Slot Filling systems.",5 Experiments,[0],[0]
"Therefore, we manually went over the pool and extracted 4,405 relevant documents as our ground-truth.",5 Experiments,[0],[0]
"We evaluate the entity archiving methods by micro and macro Precision (P), Recall (R) and F metrics.",5.1 Archiving Results and Analysis,[0],[0]
"Table 8 shows the main results.
 ",5.1 Archiving Results and Analysis,[0],[0]
"Overall Archiving Results Overall, the proposed CEA methods perform much better than the string matching based entity archiving methods (i.e., EM and FM).
",5.1 Archiving Results and Analysis,[0],[0]
"In addition the methods outperform a randomsampling based CEA (baseline), which randomly selects a certain number of documents (candidates) from the candidate source to combine with reference source straightforwardly (for final archiving results generation).",5.1 Archiving Results and Analysis,[0],[0]
"The sampling number is set to be the same as the number of candidates eventually archived by RM-based CEA.
cates after optimization)
",5.1 Archiving Results and Analysis,[0],[0]
Table 9 shows the number of candidates archived from the candidate source by all kinds of CEA methods.,5.1 Archiving Results and Analysis,[0],[0]
"It demonstrates that the biography-based CEAs yield higher precision (Table 8) after introducing the same or smaller number of candidates in the reference source, revealing the positive effect of biography modeling on entity-oriented document relevance determination.
 ",5.1 Archiving Results and Analysis,[0],[0]
Reliability versus Comprehensiveness CEA achieves higher precision by using the optimized EM results as reference source.,5.1 Archiving Results and Analysis,[0],[0]
It demonstrates the importance of reliable prior knowledge for entity understanding as well as detecting relevant documents.,5.1 Archiving Results and Analysis,[0],[0]
"However, the reference source causes lower recall scores of all CEA methods.",5.1 Archiving Results and Analysis,[0],[0]
The reason lies in reduction of prior knowledge.,5.1 Archiving Results and Analysis,[0],[0]
"As shown in Table 8, the re-
fined reference source (i.e., optimized EM results) covers only 24.6% of all relevant documents, which is far less than the coverage before optimization (nearly 40%).
",5.1 Archiving Results and Analysis,[0],[0]
"The reduced prior knowledge provides fewer available life slices of an entity for constructing an informative biography, inevitably resulting in missing some relevant documents.",5.1 Archiving Results and Analysis,[0],[0]
"In order to confirm this, we regard the 41 KBP slot types as some readily-made visible life slices, and use the manual annotations of the slot fillers to verify whether a life slice appears in a relevant document.",5.1 Archiving Results and Analysis,[0],[0]
"For example, the filler “Corporate liaison of the slot Title reveals the slice of freelance career of Mark Fisher.",5.1 Archiving Results and Analysis,[0],[0]
Then we figure out the coverage rate of life slices for both the original reference source and,5.1 Archiving Results and Analysis,[0],[0]
"the refined.
Figure 4 exhibits the coverage rates for 5 most frequently occurred life slices.",5.1 Archiving Results and Analysis,[0],[0]
"The coverage rate is calculated by the number of reference sources that contain a specific life slice versus 100, i.e., the number of reference sources for the 100 KBP entities (one per entity).",5.1 Archiving Results and Analysis,[0],[0]
"It can be found that the refined reference sources miss lots of life slices.
",5.1 Archiving Results and Analysis,[0],[0]
"Figure 4: Coverage rates of life slices (for top 5)
 ",5.1 Archiving Results and Analysis,[0],[0]
Comparison among Biography Models RM is biased towards the popular life slices in biography modeling.,5.1 Archiving Results and Analysis,[0],[0]
"The reasons are as following: 1) RM gives greater weights to the highfrequency words, and 2) popular slices are of much greater public interest and hence frequently mentioned in relevant documents.",5.1 Archiving Results and Analysis,[0],[0]
"However, some entities not only share similar names but similar popular slices, such as the religious vocation of different church scientologists.",5.1 Archiving Results and Analysis,[0],[0]
"Therefore
RM is extremely likely to acquire the documents related to the namesakes if they have similar popular background as the target entity, causing a greater loss of precision.
",5.1 Archiving Results and Analysis,[0],[0]
"Table 10 shows the top highly-weighted words in RM for the target Mark Fisher (a church scientologist), along with 2 namesakes who occur most frequently in the incorrect archiving results.
",5.1 Archiving Results and Analysis,[0],[0]
"By contrast, TM independently represents different life slices and combines the effects of the slices on biography-document relevance determination, evenly and exhaustively.",5.1 Archiving Results and Analysis,[0],[0]
Comprehensive and unbiased measurement of every known life slices is helpful in disambiguating entities that have similar backgrounds (definitely not the same in all).,5.1 Archiving Results and Analysis,[0],[0]
"As a result, TM improves the precision.",5.1 Archiving Results and Analysis,[0],[0]
And the context-based TM goes further.,5.1 Archiving Results and Analysis,[0],[0]
"We apply our entity archiving methods to two top-ranked slot filling systems in the evaluation of KBP 2013, including LSV (Roth and Klakow, 2013) and Blender (Yu et al 2013).
",5.2 Slot Filling Results and Analysis,[0],[0]
The LSV incorporates a string matching based entity archiving and a SVM classifier based filler extraction.,5.2 Slot Filling Results and Analysis,[0],[0]
"LSV’s archiving model expands queries by using suffixes and Wikipedia anchor texts, and uses mutual information based relevance measure in document ranking and filtering.
",5.2 Slot Filling Results and Analysis,[0],[0]
Blender employs a hybrid retrieval model for archiving relevant documents.,5.2 Slot Filling Results and Analysis,[0],[0]
It combines Boolean and VSM models and expands query by an alternate name table similar to ours.,5.2 Slot Filling Results and Analysis,[0],[0]
"For filler extraction, Blender implements truth finding over conflicting claims from multiple rule-based extraction systems.
",5.2 Slot Filling Results and Analysis,[0],[0]
"Table 11 shows entity archiving performances
of LSV and Blender (Macro-Average P, R and F).",5.2 Slot Filling Results and Analysis,[0],[0]
All CEA methods perform better than the both.,5.2 Slot Filling Results and Analysis,[0],[0]
"With the aim to optimize provenances of fillers, we modify the slot filling systems by substituting their archiving methods with ours.",5.2 Slot Filling Results and Analysis,[0],[0]
"Table 12 exhibits the performance gains after replacement.
",5.2 Slot Filling Results and Analysis,[0],[0]
Both LSV and Blender achieve significant gains.,5.2 Slot Filling Results and Analysis,[0],[0]
The most interesting finding is on the different performance gains.,5.2 Slot Filling Results and Analysis,[0],[0]
"It should reveal the fact that the well-supervised classification based filler extraction of LSV has a better capability of noise resistance, while by contrast, the truthfinding in Blender is capable of identifying valid fillers if the quality of archiving results is high, otherwise easily makes mistake.",5.2 Slot Filling Results and Analysis,[0],[0]
"We doubt that it is easy to maintain the stability of current entity-oriented knowledge acquisition methods, including ours, in dealing with ordinary entities.",6 Conclusion,[0],[0]
"Most target entities now in use for the evaluation are made to stand as “out of the ordinary”, such as well-known enterprises, celebrities or domain experts.",6 Conclusion,[0],[0]
"As a result, a corpus contains abundant relevant documents of the entities but less about the little-known namesakes.",6 Conclusion,[0],[0]
"It greatly reduces the interference of namesakes and thus the difficulty of the task.
",6 Conclusion,[0],[0]
"In future work, we will make the task critical for success by employing the little known namesakes as targets.",6 Conclusion,[0],[0]
"In addition to verifying the robustness of the CEA method, we will work on the relationship among entities (ACE entity relation types, Doddington et al, 2004) and related events (e.g., causal, temporal and sub-event relations), by which to build graph-based biography.",6 Conclusion,[0],[0]
"This work was supported by the U.S. DARPA DEFT Program No. FA8750-13-2-0041, ARL NS-CTA No.",7 Acknowledgment,[0],[0]
"W911NF-09-2-0053, NSF CAREER Award IIS-1523198, AFRL DREAM project, gift awards from IBM, Google, Disney and Bosch.",7 Acknowledgment,[0],[0]
It was also supported by Natural Science Foundation of China (NSFC),7 Acknowledgment,[0],[0]
No.,7 Acknowledgment,[0],[0]
"K111818713, K111818612.",7 Acknowledgment,[0],[0]
"The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the U.S. and CHN Governments.",7 Acknowledgment,[0],[0]
The U.S. and CHN Governments are authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation here on.,7 Acknowledgment,[0],[0]
"Knowledge Base Population (KBP) tasks, such as slot filling, show the particular importance of entity-oriented automatic relevant document acquisition.",abstractText,[0],[0]
"Rich, diverse and reliable relevant documents satisfy the fundamental requirement that a KBP system explores the nature of an entity.",abstractText,[0],[0]
"Towards the bottleneck problem between comprehensiveness and definiteness of acquisition, we propose a collaborative archiving method.",abstractText,[0],[0]
"In particular we introduce topic modeling methodologies into entity biography profiling, so as to build a bridge between fuzzy and exact matching.",abstractText,[0],[0]
"On one side, we employ the topics in a small-scale high-quality relevant documents (i.e., exact matching results) to summarize the life slices of a target entity (i.e., biography), and on the other side, we use the biography as a reliable reference material to detect new truly relevant documents from a large-scale partially complete pseudo-feedback (i.e., fuzzy matching results).",abstractText,[0],[0]
We leverage the archiving method to enhance slot filling systems.,abstractText,[0],[0]
Experiments on KBP corpus show significant improvement over stateof-the-art.,abstractText,[0],[0]
Biography-Dependent Collaborative Entity Archiving for Slot Filling,title,[0],[0]
"A stochastic differential equation (SDE) defines a diffusion process, which evolves randomly over time, by describing its instantaneous behaviour.",1. Introduction,[0],[0]
"As such, SDEs are powerful modelling tools used extensively in fields such as econometrics (Black & Scholes, 1973; Eraker, 2001), biology (Gillespie, 2000; Golightly & Wilkinson, 2011), physics (van Kampen, 2007) and epidemiology (Fuchs, 2013).
",1. Introduction,[0],[0]
It is only possible to work with analytic solutions to SDEs in special cases.,1. Introduction,[0],[0]
"Therefore it is common to use a numerical approximation, such as the Euler-Maruyama scheme.",1. Introduction,[0],[0]
"Here the diffusion process is defined only on a grid of time points, and the transition density between successive diffusion states is approximated as Gaussian.",1. Introduction,[0],[0]
"The approximation
*Equal contribution 1School of Mathematics, Statistics and Physics, Newcastle University, Newcastle, UK 2School of Computing, Newcastle University, Newcastle, UK.",1. Introduction,[0],[0]
Correspondence to: Tom Ryder <,1. Introduction,[0],[0]
"t.ryder2@newcastle.ac.uk>, Dennis Prangle <dennis.prangle@newcastle.ac.uk>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
error involved converges to zero as the grid becomes finer.
",1. Introduction,[0],[0]
"Even under discretisation, statistical inference for SDEs observed at discrete times is challenging.",1. Introduction,[0],[0]
"The difficulty is that, along with unknown parameters θ in the description of the SDE, there is an unknown latent path of the diffusion process,",1. Introduction,[0],[0]
"x. An inference method must somehow deal with these high dimensional, highly structured latent variables.
",1. Introduction,[0],[0]
Our proposed method uses recent advances in variational inference to jointly infer θ and x. We introduce a flexible family of approximations to the posterior distribution and select the member closest to the true posterior.,1. Introduction,[0],[0]
"We use a standard mean-field approximation for the θ posterior, and introduce a novel recurrent neural network (RNN) approximation for the posterior of x conditional on θ.",1. Introduction,[0],[0]
"The RNN learns how to supply Gaussian state transitions between successive time points which closely match those for the intractable conditioned diffusion process.
",1. Introduction,[0],[0]
Our black-box variational inference method is a simple and fast way to produce approximate inference for any SDE system.,1. Introduction,[0],[0]
"We illustrate our method on Lotka-Volterra and epidemic examples, achieving accurate parameter estimates in just a few hours under default tuning choices.",1. Introduction,[0],[0]
"Although our parameter posteriors are over-concentrated, as in most variational methods, our approximation of the conditioned diffusion process is close to the true posterior.",1. Introduction,[0],[0]
"In comparison, existing Markov chain Monte Carlo (MCMC) methods (see Section 1.1) require more tuning choices and can take days to run (Whitaker et al., 2017a).",1. Introduction,[0],[0]
"Variational inference Several authors have looked at variational inference for SDEs (Archambeau et al., 2008) or related problems such as Markov jump processes (Ruttor et al., 2010) and state space models (Archer et al., 2016; Quiroz et al., 2018).",1.1. Related Work,[0],[0]
The novelty of our approach is to use: (1) stochastic optimisation rather than variational calculus; (2) a RNN-based variational approximation for the latent states instead of a mean-field or multivariate Gaussian approach.,1.1. Related Work,[0],[0]
"We expect (2) is especially relevant to sparsely observed SDEs, where the latent states between observations may have a particularly complex dependency structure.
",1.1. Related Work,[0],[0]
"Another approach (Moreno et al., 2016) is to perform vari-
ational inference for the parameters only, using latent variables drawn from their prior in the ELBO estimate.",1.1. Related Work,[0],[0]
Such latent states are typically a poor match to the observed data and so make a negligible contribution to the ELBO.,1.1. Related Work,[0],[0]
"To deal with the problem, close matches are upweighted.",1.1. Related Work,[0],[0]
"Our approach avoids this extra approximation by instead learning the posterior distribution of the latent variables.
",1.1. Related Work,[0],[0]
"Our method can also be related to recent work on normalising flows as variational approximations (Rezende & Mohamed, 2015).",1.1. Related Work,[0],[0]
"As in that work, our variational approximation can be viewed as transforming a N(0, I) sample vector by successive linear transformations to an approximate posterior sample (of the diffusion states in our case).",1.1. Related Work,[0],[0]
"Our work uses SDE theory to select simple and cheap transformations which produce a particularly good approximation.
Monte Carlo A popular approach in the Monte Carlo literature on SDEs is to introduce a bridge construct: an approximation to the discretised diffusion process conditional on the parameters and observations at a single time, derived using probability theory and various simplifying approximations.",1.1. Related Work,[0],[0]
The goal is to produce a path bridging between two observation times.,1.1. Related Work,[0],[0]
Combining successive bridges forms a complete diffusion path.,1.1. Related Work,[0],[0]
Bridge constructs can be used to produce proposals within Monte Carlo algorithms such as MCMC (see e.g. Roberts & Stramer 2001; Golightly & Wilkinson 2008; Fuchs 2013; van der Meulen et al. 2017).,1.1. Related Work,[0],[0]
"However, designing a bridge construct with desirable features for a particular problem is a challenging and time consuming tuning choice.",1.1. Related Work,[0],[0]
(Some particularly difficult regimes for bridge constructs are discussed in Section 5.),1.1. Related Work,[0],[0]
"From this point of view, our contribution is to use machine learning to effectively automate the design of a bridge construct.
",1.1. Related Work,[0],[0]
"Another Monte Carlo approach is to perform approximate inference based on low dimensional summary statistics of the observations (Picchini, 2014).",1.1. Related Work,[0],[0]
"This results in a loss of information, which our approach avoids.",1.1. Related Work,[0],[0]
"Consider an Itô process {Xt, t ≥ 0} satisfying the SDE
dXt = α(Xt, θ)dt+ √ β(Xt, θ)dWt, X0 = x0.",2. Stochastic Differential Equations,[0],[0]
"(1)
Here Xt is a p-dimensional vector of random variables, α is a p-dimensional drift vector, β is a p× p positive definite diffusion matrix (with √ β representing a matrix square root) and Wt is a p-vector of standard and uncorrelated Brownian motion processes.",2. Stochastic Differential Equations,[0],[0]
"The drift and diffusion depend on θ = (θ1, θ2, ..., θc)
′, a vector of unknown parameters (which may also include the initial condition x0).
",2. Stochastic Differential Equations,[0],[0]
"We assume that α(·) and β(·) are sufficiently regular that (1) has a weak non-explosive solution (Øksendal, 2003).",2. Stochastic Differential Equations,[0],[0]
"In
this case, (1) defines a diffusion process.",2. Stochastic Differential Equations,[0],[0]
"Such processes are always Markovian (i.e. memoryless).
",2. Stochastic Differential Equations,[0],[0]
We further assume partial noisy observations of the latent process.,2. Stochastic Differential Equations,[0],[0]
"Suppose that there are d + 1 observation times t0, t1, . . .",2. Stochastic Differential Equations,[0],[0]
", td = T .",2. Stochastic Differential Equations,[0],[0]
"In the simplest case, these times are equally spaced, separated by a time-step of ∆t.",2. Stochastic Differential Equations,[0],[0]
"Let ytj be a vector of p0 observations at time tj , for some p0 ≤ p.",2. Stochastic Differential Equations,[0],[0]
"Following Golightly & Wilkinson (2008), among others, we assume that
ytj = F ′Xtj + ωtj , ωtj indep∼ N(0,Σ), (2)
where F is a constant p×p0 matrix, and Σ is a p0×p0 matrix which may be assumed known or the object of inference.",2. Stochastic Differential Equations,[0],[0]
"For the latter case Σ should be a specified function of θ.
",2. Stochastic Differential Equations,[0],[0]
"Upon choosing a prior density p(θ), Bayesian inference proceeds via the parameter posterior p(θ|y), or alternatively the joint posterior p(θ, x|y).
",2. Stochastic Differential Equations,[0],[0]
Discretisation Few SDEs permit analytical solutions to (1) and instead it is common to use an approximation based on time discretisation.,2. Stochastic Differential Equations,[0],[0]
We therefore introduce intermediate time-points between observation times.,2. Stochastic Differential Equations,[0],[0]
"For concreteness, we present our methods for the case of equally spaced observations with t0 = 0.",2. Stochastic Differential Equations,[0],[0]
"(It is easy to adapt them to alternative specifications of time points, such as those required by irregularly-spaced observation times.)",2. Stochastic Differential Equations,[0],[0]
"We introduce k − 1 time-points between successive observations, giving a regular grid of times τi = i∆τ for i = 0, 1, 2, . . .",2. Stochastic Differential Equations,[0],[0]
",m = dk, with time-step ∆τ = ∆t/k. Note that i = 0, k, 2k, . . .",2. Stochastic Differential Equations,[0],[0]
", dk give the observation times.",2. Stochastic Differential Equations,[0],[0]
"The role of k is to ensure the discretisation can be made arbitrarily accurate, at the expense of increased computational cost.
",2. Stochastic Differential Equations,[0],[0]
"We work with the simplest discretisation, the EulerMaruyama scheme, in which transition densities between states at successive times are approximated as Gaussian
p ( xτi+1 |xτi , θ ) = ϕ",2. Stochastic Differential Equations,[0],[0]
( xτi+1,2. Stochastic Differential Equations,[0],[0]
"− xτi ; α(xτi , θ)∆τ, β(xτi , θ)∆τ ) ,
(3)
where ϕ(·;µ, S) is the Gaussian density with mean µ and variance matrix S. A generative expression of this is
xτi+1 = xτi + α(xτi , θ)∆τ + √ β(xτi , θ)∆τ zi+1, (4)
where zi+1 is an independent N(0, Ip) realisation.
",2. Stochastic Differential Equations,[0],[0]
Discretisation is not guaranteed to preserve properties of the underlying SDE.,2. Stochastic Differential Equations,[0],[0]
An issue which is particularly relevant later is positivity.,2. Stochastic Differential Equations,[0],[0]
"In many SDEs, such as population models, it is guaranteed that some components of Xt are always positive.",2. Stochastic Differential Equations,[0],[0]
"However, in (4) xτi+1 is sampled from a Gaussian, which has unbounded support.",2. Stochastic Differential Equations,[0],[0]
"Consequently, there is a non-zero probability of sampling negative values.",2. Stochastic Differential Equations,[0],[0]
"This is problematic
as the drift or diffusion function may be poorly behaved or undefined for such input.",2. Stochastic Differential Equations,[0],[0]
"A simple solution to this problem is the use of a reflecting boundary (Skorokhod, 1961), for example by projecting invalid xτi+1 values back to the valid region (Dangerfield et al., 2012).
",2. Stochastic Differential Equations,[0],[0]
Posterior,2. Stochastic Differential Equations,[0],[0]
"The joint posterior under the Euler-Maruyama discretisation is
p(θ, x|y) ∝",2. Stochastic Differential Equations,[0],[0]
"p(θ)p(x|θ)p(y|x, θ), (5)
p(x|θ) = m−1∏ i=0 ϕ",2. Stochastic Differential Equations,[0],[0]
( xτi+1,2. Stochastic Differential Equations,[0],[0]
"− xτi ; α(xτi , θ)∆τ,
β(xτi , θ)∆τ ) (6)
p(y|x, θ) = d∏ i=0 ϕ",2. Stochastic Differential Equations,[0],[0]
"(yti ;F ′xti ,Σ) .",2. Stochastic Differential Equations,[0],[0]
"(7)
In principle Monte Carlo algorithms can sample from (5).",2. Stochastic Differential Equations,[0],[0]
"However this is difficult in practice due to its high dimension and complex dependency structure.
",2. Stochastic Differential Equations,[0],[0]
"Conditioned processes Consider the process defined by conditioning (1) on an initial state, x0 and an exactly observed future state, xt1 .",2. Stochastic Differential Equations,[0],[0]
"This conditioned process itself satisfies an SDE (see e.g. Rogers & Williams, 2013) with drift and diffusion
α̂(xt, θ) = α(xt, θ) + β(xt, θ)∇xt log π (xt1 |xt, θ) , (8)
β̂(xt, θ) = β(xt, θ), (9)
where π (xt1 |xt, θ) is the transition density of the unconditioned process.",2. Stochastic Differential Equations,[0],[0]
"While this is intractable in most cases, the result motivates our choice of variational approximation later.
",2. Stochastic Differential Equations,[0],[0]
In some simple situations a discretised approximation of this conditioned process can be derived (see e.g. Papaspiliopoulos et al. 2013) in which the diffusion matrix is scaled down as the observation time is approached.,2. Stochastic Differential Equations,[0],[0]
"Intuitively this is appealing: conditioned paths converge towards the observation, so nearby random deviations are smaller in scale.",2. Stochastic Differential Equations,[0],[0]
"This motivates us to use a variational approximation in which the diffusion matrix is not constrained to follow (9), and instead is allowed to shrink.",2. Stochastic Differential Equations,[0],[0]
Suppose we have a likelihood p(y|θ) for parameters θ under observations y.,3. Approximate Bayesian Inference,[0],[0]
Given a prior density p(θ),3. Approximate Bayesian Inference,[0],[0]
we wish to infer the posterior density p(θ|y) = p(θ)p(y|θ)/p(y).,3. Approximate Bayesian Inference,[0],[0]
"It is typically possible to numerically evaluate the unnormalised posterior p(θ, y) = p(θ)p(y|θ).",3. Approximate Bayesian Inference,[0],[0]
"Estimating the normalising constant p(y) = ∫ p(θ, y)dθ, known as the evidence, is useful for Bayesian model selection.",3. Approximate Bayesian Inference,[0],[0]
"Variational inference (VI) (see e.g. Blei et al., 2017) introduces a family of approximations to the posterior indexed by φ, q(θ;φ).",3.1. Variational Inference,[0],[0]
Optimisation is then used to find φ minimising the Kullback-Leibler divergence KL(q(θ;φ)||p(θ|y)).,3.1. Variational Inference,[0],[0]
"This is equivalent to maximising the ELBO (evidence lower bound) (Jordan et al., 1999),
Eθ∼q(·;φ)[log p(θ, y)− log q(θ;φ)].",3.1. Variational Inference,[0],[0]
"(10)
The optimal q(θ;φ) is an approximation to the posterior distribution.",3.1. Variational Inference,[0],[0]
"This is typically overconcentrated, unless the approximating family is rich enough to allow particularly close matches to the posterior.
",3.1. Variational Inference,[0],[0]
"The optimisation required by VI can be performed efficiently using the reparameterisation trick (Kingma & Welling, 2014; Rezende et al., 2014; Titsias & Lázaro-Gredilla, 2014).",3.1. Variational Inference,[0],[0]
"This requires expressing θ ∼ q(·;φ) as a non-centred parameterisation (Papaspiliopoulos et al., 2003).",3.1. Variational Inference,[0],[0]
"That is, writing θ as the output of an invertible deterministic function g( , φ) for some random variable with a fixed distribution.",3.1. Variational Inference,[0],[0]
"Then the ELBO can be written as
L(φ) = E",3.1. Variational Inference,[0],[0]
"[log p(θ, y)− log q(θ;φ)], (11)
with an unbiased Monte-Carlo estimate
L̂(φ) = 1 n n∑ i=1",3.1. Variational Inference,[0],[0]
"[log p(θ(i), y)− log q(θ(i);φ)], (12)
where θ(i)",3.1. Variational Inference,[0],[0]
"= g( (i), φ) and (1), . . .",3.1. Variational Inference,[0],[0]
", (n) are independent samples.",3.1. Variational Inference,[0],[0]
"Assuming L̂ is differentiable with respect to φ, the gradient of (12) can be calculated using automatic differentiation, and the resulting unbiased estimator of∇L(φ) used in stochastic gradient descent or similar algorithms.",3.1. Variational Inference,[0],[0]
"When variational inference outputs a good match to the posterior distribution, importance sampling (IS) (see e.g. Robert, 2004) can correct remaining inaccuracies and provide near-exact posterior inference.",3.2. Importance Sampling,[0],[0]
"In more detail, select an importance density q(θ) which can easily be sampled from, and satisfies supp q(θ) ⊇ supp p(θ|y).",3.2. Importance Sampling,[0],[0]
"IS samples θ(1), θ(2), . . .",3.2. Importance Sampling,[0],[0]
", θ(N) from q and calculates weights wi = p(θ
(i), y)/q(θ(i)).",3.2. Importance Sampling,[0],[0]
"Then, for any function h, an estimate of Eθ∼p(·|y)[h(θ)] is
N∑ i=1",3.2. Importance Sampling,[0],[0]
h(θ(i))wi / N∑ i=1,3.2. Importance Sampling,[0],[0]
wi.,3.2. Importance Sampling,[0],[0]
"(13)
",3.2. Importance Sampling,[0],[0]
"This is consistent for large N , but in practice q should approximate the posterior for accurate estimation at a feasible cost.",3.2. Importance Sampling,[0],[0]
Also note that N−1 ∑N i=1,3.2. Importance Sampling,[0],[0]
"wi is an unbiased and consistent estimate of the evidence.
",3.2. Importance Sampling,[0],[0]
A diagnostic for the quality of IS results is the effective sample size (ESS).,3.2. Importance Sampling,[0],[0]
"This is defined as
Neff =",3.2. Importance Sampling,[0],[0]
( N∑ i=1,3.2. Importance Sampling,[0],[0]
wi )2/ N∑ i=1,3.2. Importance Sampling,[0],[0]
w2i .,3.2. Importance Sampling,[0],[0]
"(14)
",3.2. Importance Sampling,[0],[0]
"For most functions h, the variance of (13) approximately equals that of an idealised Monte Carlo estimate based on Neff independent samples from p(θ|y) (Liu, 1996).",3.2. Importance Sampling,[0],[0]
"In practice we will use a variational approximation as the importance density, and the ESS to assess whether this is sufficiently good to produce accurate estimates.",3.2. Importance Sampling,[0],[0]
"However, ESS values can be an unstable for poor importance densities (Vehtari et al., 2017) so later we also consider other problemspecific evidence for the quality of our results.",3.2. Importance Sampling,[0],[0]
"Our variational approximation to the posterior (5) is
q(θ, x;φ) = q(θ;φθ)q(x|θ;φx).",4. Variational Inference for SDEs,[0],[0]
"(15)
These factors represent approximations to p(θ|y) and p(x|θ, y) respectively, which are described below.",4. Variational Inference for SDEs,[0],[0]
Here φθ,4. Variational Inference for SDEs,[0],[0]
"and φx are the variational parameters for the two factors, and φ is the collection of all variational parameters.",4. Variational Inference for SDEs,[0],[0]
"Note our eventual choice of q(x|θ;φx) depends on several features of the data and model (see list in Section 4.5), but we suppress this in our notation for simplicity.",4. Variational Inference for SDEs,[0],[0]
"For q(θ;φθ) we use the mean-field Gaussian approximation
q(θ;φθ) = c∏ i=1 ϕ(θi;µi, s 2 i ), (16)
with φθ = (µ1, . . .",4.1. Approximate Parameter Posterior,[0],[0]
", µc, s1, . . .",4.1. Approximate Parameter Posterior,[0],[0]
", sc).",4.1. Approximate Parameter Posterior,[0],[0]
Hence the components of θ are independent Gaussians.,4.1. Approximate Parameter Posterior,[0],[0]
"To express θ using a noncentred parameterisation, we write
θ = gθ( 1, φθ) = S 1 + µ. (17)
where ∼ N(0, Ic), S = diag(s1, . . .",4.1. Approximate Parameter Posterior,[0],[0]
", sc) and µ = (µ1, . . .",4.1. Approximate Parameter Posterior,[0],[0]
", µc).
",4.1. Approximate Parameter Posterior,[0],[0]
It may be necessary to transform θ to an alternative parameterisation ϑ,4.1. Approximate Parameter Posterior,[0],[0]
"so that a Gaussian approximation is appropriate e.g. log-transforming parameters constrained to be positive.
",4.1. Approximate Parameter Posterior,[0],[0]
"Mean-field approximations are imperfect, often producing underdispersed estimates of the posterior (see e.g. Blei et al., 2017), and more sophisticated approximations (e.g. Rezende & Mohamed, 2015) could be used here instead.",4.1. Approximate Parameter Posterior,[0],[0]
However mean-field approximations suffice to give good parameter estimation in our examples.,4.1. Approximate Parameter Posterior,[0],[0]
"Motivated by the result that a diffusion process conditioned on an exact observation is itself an SDE (see Section 2), we base q(x|θ;φx) upon a discretised diffusion.",4.2. Approximate Conditioned Diffusion Process,[0],[0]
"A generative definition is
xτi+1",4.2. Approximate Conditioned Diffusion Process,[0],[0]
= h,4.2. Approximate Conditioned Diffusion Process,[0],[0]
"( xτi + α̃(xτi , y, θ, τi;φx)∆τ
+ √ β̃(xτi , y, θ, τi;φx)∆τzi+1 ) ,
(18)
where α̃ and β̃ are drift and diffusion functions.",4.2. Approximate Conditioned Diffusion Process,[0],[0]
Taking h as the identity function gives a discretised diffusion process.,4.2. Approximate Conditioned Diffusion Process,[0],[0]
"However often we use h to impose positivity constraints on some components of x – see Section 4.3.
",4.2. Approximate Conditioned Diffusion Process,[0],[0]
"The resulting variational density q(x|θ;φx) is
m−1∏ i=0 ϕ",4.2. Approximate Conditioned Diffusion Process,[0],[0]
( xτi+1,4.2. Approximate Conditioned Diffusion Process,[0],[0]
"− xτi ; α̃(xτi , y, θ, τi;φx)∆τ,
β̃(xτi , y, θ, τi;φx)∆τ ) |det Ji|.
(19)
where Ji is the Jacobian matrix associated with the transformation h in (18).",4.2. Approximate Conditioned Diffusion Process,[0],[0]
"To express x with a non-centred parameterisation, let 2 ∼ N(0, Ipm) be the flattened vector of (z1, z2, . . .",4.2. Approximate Conditioned Diffusion Process,[0],[0]
", zm) realisations.",4.2. Approximate Conditioned Diffusion Process,[0],[0]
Then apply (18) repeatedly.,4.2. Approximate Conditioned Diffusion Process,[0],[0]
"Let the outcome be represented by the function
x = gx( 2, θ, φx).",4.2. Approximate Conditioned Diffusion Process,[0],[0]
"(20)
We use a neural network, with parameters φx, to serve as our functions α̃ and β̃.",4.2. Approximate Conditioned Diffusion Process,[0],[0]
At time τi it acts as follows.,4.2. Approximate Conditioned Diffusion Process,[0],[0]
"The network’s input is several features (described in Section 4.5) computed from: the current diffusion state xτi , the observations y, the parameters θ and the current time τi.",4.2. Approximate Conditioned Diffusion Process,[0],[0]
"The network outputs a drift vector and diffusion matrix (see Section 4.5 for details of the latter), which are used to sample xτi+1 from (18).",4.2. Approximate Conditioned Diffusion Process,[0],[0]
This state forms part of the neural network input at time τi+1.,4.2. Approximate Conditioned Diffusion Process,[0],[0]
So the network just discussed forms a cell of an overall recurrent neural network (RNN) structure for q(x|θ;φx).,4.2. Approximate Conditioned Diffusion Process,[0],[0]
"Note that long-term memory features are not required as we wish to produce a diffusion process, which is memoryless.",4.2. Approximate Conditioned Diffusion Process,[0],[0]
"In practice, we take h in (18) to be a function which applies the identity function to unconstrained components of the diffusion state, and the function softplus(z) = log(1 + ez) to components with positivity constraints.",4.3. Ensuring Positivity,[0],[0]
This function produces strictly positive outputs while having little effect on positive inputs above 2.,4.3. Ensuring Positivity,[0],[0]
"The latter property means our variational approximation usually remains similar to a discretised
diffusion process.",4.3. Ensuring Positivity,[0],[0]
"Alternative transformations could be used if state values below 2 were believed to be common, potentially with tuning parameters so a suitable shape could be learned.",4.3. Ensuring Positivity,[0],[0]
"However, this was not necessary for our examples.
",4.3. Ensuring Positivity,[0],[0]
Preliminary work found this transformation approach to enforcing positivity was much easier to implement in the variational framework than reflection methods.,4.3. Ensuring Positivity,[0],[0]
It can be interpreted as constraining the variational approximation based on prior beliefs about positivity of diffusion paths.,4.3. Ensuring Positivity,[0],[0]
Our overall inference algorithm is given in Algorithm 1.,4.4. Algorithm,[0],[0]
"This aims to maximise the ELBO
L(φ) = Eθ,x∼q(·;φ) [ log
p(θ)p(x|θ)p(y|x, θ) q(θ;φθ)q(x|θ;φx)
] , (21)
by differentiating the Monte Carlo estimate
L̂(φ) = 1 n n∑ i=1",4.4. Algorithm,[0],[0]
"log p(θ(i))p(x(i)|θ(i))p(y|x(i), θ(i))",4.4. Algorithm,[0],[0]
"q ( θ(i);φθ ) q ( x(i)|θ(i);φx
) , (22)",4.4. Algorithm,[0],[0]
"where θ(i) = gθ( (i) 1 , φθ) and x (i) = gx( (i) 2 , θ (i), φx).
",4.4. Algorithm,[0],[0]
Algorithm 1 Black-box variational inference for SDEs Initialise φ0 and k = 0.,4.4. Algorithm,[0],[0]
"loop
Sample (i)1 , (i) 2 for 1 ≤",4.4. Algorithm,[0],[0]
i ≤ n. Calculate ∇L̂(φk) using automatic differentiation of (22).,4.4. Algorithm,[0],[0]
"Calculate φk+1 using stochastic gradient descent, or a similar algorithm, and increment k.
end loop",4.4. Algorithm,[0],[0]
"Our RNN cell input at time τi, with tj ≤ τi < tj+1, is:
• The parameters θ. •",4.5. Implementation Details,[0],[0]
"The most recent latent state, xτi−1 .",4.5. Implementation Details,[0],[0]
"• The time until the next observation, tj+1",4.5. Implementation Details,[0],[0]
− τi.,4.5. Implementation Details,[0],[0]
"• The next observation time, tj+1.",4.5. Implementation Details,[0],[0]
•,4.5. Implementation Details,[0],[0]
"The difference between the next observation and what
the mean observation would be at the most recent latent state, ytj+1 − F ′xτi−1 .
",4.5. Implementation Details,[0],[0]
"Exploratory work showed that the RNN produces a much better approximation of the conditioned process with these features as input rather than simply xτi , y, θ and τi.
",4.5. Implementation Details,[0],[0]
"Our RNN cell outputs a vector α̃ and the coefficients of a lower-triangular matrix, M .",4.5. Implementation Details,[0],[0]
"In order to return a Cholesky factor of β̃, the diagonal elements of M are transformed
using the softplus function to ensure positivity.",4.5. Implementation Details,[0],[0]
"We also regularise to avoid β̃ matrices with very small determinants.
",4.5. Implementation Details,[0],[0]
Algorithm 1 requires automatic differentiation of (22).,4.5. Implementation Details,[0],[0]
This can be achieved using the standard tool-kit of backpropagation after rolling-out the RNN i.e. stacking m copies of the RNN cell to form a deep feed-forward network.,4.5. Implementation Details,[0],[0]
"The canonical challenge in training such networks, known as the exploding-gradient problem (Bengio et al., 1994), often necessitates the use of gradient clipping to control for numerical instability.",4.5. Implementation Details,[0],[0]
"We follow Pascanu et al. (2013) and perform gradient clipping using the L1 norm.
",4.5. Implementation Details,[0],[0]
"To initialise φ0 in Algorithm 1, we select φθ",4.5. Implementation Details,[0],[0]
so the margins of the variational approximation are based on those of the parameter priors.,4.5. Implementation Details,[0],[0]
Standard choices from the neural network literature – random Gaussian weights and constant biases – are used for φx.,4.5. Implementation Details,[0],[0]
We implement our method for two examples: (1) analysing synthetic data from a Lotka-Volterra SDE; (2) analysing real data from an SDE model of a susceptible-infectiousremoved (SIR) epidemic.,5. Experiments,[0],[0]
Our experiments include challenging regimes such as: (A) low-variance observations; (B) conditioned diffusions with non-linear dynamics; (C) unobserved time series; (D) widely spaced observation times; (E) data which is highly unlikely under the unconditioned model.,5. Experiments,[0],[0]
"Many of these violate the assumptions used by existing diffusion bridge constructs (Whitaker et al., 2017b).
",5. Experiments,[0],[0]
In all our experiments below similar tuning choices worked well.,5. Experiments,[0],[0]
We use batch size n = 50 in (22).,5. Experiments,[0],[0]
Our RNN cell has four hidden layers each with 20 hidden units and rectifiedlinear activation.,5. Experiments,[0],[0]
"We implement our algorithms in Tensorflow using the Adam optimiser (Kingma & Ba, 2015) and report results using an 8-core CPU.",5. Experiments,[0],[0]
The code is available at https://github.com/Tom-Ryder/VIforSDEs.,5. Experiments,[0],[0]
"Lotka-Volterra models describe simple predator-prey population dynamics combining three types of event: prey reproduction, predation (in which prey are consumed and predators have the resources to reproduce) and predator death.",5.1. Lotka-Volterra,[0],[0]
"A SDE Lotka-Volterra model (for derivation see e.g. Golightly & Wilkinson, 2011) is defined by
α(Xt, θ) = ( θ1Ut − θ2UtVt θ2UtVt − θ3Vt ) , (23)
β(Xt, θ) = ( θ1Ut + θ2UtVt −θ2UtVt −θ2UtVt θ3Vt + θ2UtVt ) , (24)
where Xt = (Ut, Vt)′ represents the populations of prey and predators at time t. The parameters θ = (θ1, θ2, θ3) ′ control the rates of the three events described above.
",5.1. Lotka-Volterra,[0],[0]
"In the experiments below, we use discretisation time step ∆τ = 0.1 and observation variance Σ = I , which is small relative to the typical population sizes (see e.g. Figure 1.)
",5.1. Lotka-Volterra,[0],[0]
"A single observation time with known parameters We begin with the case of a single observation time and known parameter values, where we follow Boys et al. (2008) by taking θ = (0.5, 0.0025, 0.3)′ and x0 = (71, 79)′. This setting solely investigates our ability to learn x, without uncertainty in θ: essentially the same problem as creating a bridge construct (described in Section 1.1.)
",5.1. Lotka-Volterra,[0],[0]
"We consider four different observations at time t = 10, listed in Table 1.",5.1. Lotka-Volterra,[0],[0]
"For each example we train our variational approximation until convergence (assessed manually throughout this paper), which takes roughly 20 minutes for the first 3 examples, and 90 minutes for the last.",5.1. Lotka-Volterra,[0],[0]
"We then perform importance sampling using 500,000 samples from the fitted approximation.",5.1. Lotka-Volterra,[0],[0]
Table 1 shows the resulting ESS values.,5.1. Lotka-Volterra,[0],[0]
"The first 3 rows in the table are typical observations under the model given our θ, while the final row represents highly unlikely observations (double those in the previous row).",5.1. Lotka-Volterra,[0],[0]
"Figure 1 shows fitted diffusion paths for this case.
",5.1. Lotka-Volterra,[0],[0]
This example contains several challenging features: all those listed at the start of Section 5 except (C).,5.1. Lotka-Volterra,[0],[0]
"While these features make it hard to use existing bridge constructs, our variational method produces a close approximation to the true posterior, as illustrated by the high ESS values.
",5.1. Lotka-Volterra,[0],[0]
"The case of highly unlikely observations takes longer to train and receives a lower ESS, reflecting that a more complicated diffusion path must be learned here.",5.1. Lotka-Volterra,[0],[0]
"(To check this we found that a simpler RNN cell suffices for good performance in the other examples but not this one.)
",5.1. Lotka-Volterra,[0],[0]
"Multiple observation times with known parameters We now extend the previous example to multiple observation times, t = 0, 10, 20, 30, 40.",5.1. Lotka-Volterra,[0],[0]
"We analyse synthetic data, produced using the parameters specified previously (including observation noise with Σ = I).",5.1. Lotka-Volterra,[0],[0]
"Here convergence takes 6 hours, and importance sampling with 500,000 samples produces an ESS of 96,812.",5.1. Lotka-Volterra,[0],[0]
"The resulting diffusion
paths are not shown as they are very similar visually to the next example (see Figure 2).
",5.1. Lotka-Volterra,[0],[0]
"This example shows that our method learns the conditioned process well even when there are several observation times.
",5.1. Lotka-Volterra,[0],[0]
Multiple observation times with unknown parameters We now analyse the same synthetic data with unknown θ parameters.,5.1. Lotka-Volterra,[0],[0]
"As these must take positive values, we work with the log-transformed parameters ϑ and assume they have independent N(0, 32) priors.",5.1. Lotka-Volterra,[0],[0]
"Our results are shown after transforming back to the original parameterisation.
",5.1. Lotka-Volterra,[0],[0]
"Convergence takes 2 hours, and importance sampling with 500,000 iterations produces an ESS of 635.4.",5.1. Lotka-Volterra,[0],[0]
Figure 2 shows 50 diffusion paths sampled from the fitted variational approximation.,5.1. Lotka-Volterra,[0],[0]
"Figure 3 shows two estimates of the marginal parameter posteriors: the variational inference output, and a kernel density estimate based on importance sampling results.
",5.1. Lotka-Volterra,[0],[0]
The estimated posteriors give accurate estimates of the true parameter values.,5.1. Lotka-Volterra,[0],[0]
"However, the low ESS here shows that both estimates of the parameter posteriors are imperfect approximations (also illustrated by the variational posterior estimates appearing overconcentrated compared to the importance sampling results.)",5.1. Lotka-Volterra,[0],[0]
"Achieving good point estimates but imperfect posteriors is typical for variational inference (Blei et al., 2017).",5.1. Lotka-Volterra,[0],[0]
"An SIR epidemic model (Andersson & Britton, 2000) describes the spread of an infectious disease.",5.2. Epidemic Model,[0],[0]
"The population is
split into those susceptible (S), infectious (I) and removed (R).",5.2. Epidemic Model,[0],[0]
"Two types of event take place: susceptibles can be infected by the infectious, and the infectious eventually become removed.",5.2. Epidemic Model,[0],[0]
Constant population size is assumed.,5.2. Epidemic Model,[0],[0]
"Hence only the S and I population sizes need to be modelled.
",5.2. Epidemic Model,[0],[0]
"An SIR epidemic model using SDEs is defined by
α(Xt, θ) =
( −θ1StIt
θ1StIt",5.2. Epidemic Model,[0],[0]
"− θ2It,
) (25)
β(Xt, θ) =",5.2. Epidemic Model,[0],[0]
( θ1StIt −θ1StIt −θ1StIt,5.2. Epidemic Model,[0],[0]
"θ1StIt + θ2It ) , (26)
where Xt = (St, It)′ is the state of the system at time t, θ1 is an infection parameter and θ2 is a removal parameter.",5.2. Epidemic Model,[0],[0]
"For a detailed derivation see Fuchs (2013).
",5.2. Epidemic Model,[0],[0]
"Our data is taken from an outbreak of influenza at a boys boarding school in 1978 (Jackson et al., 2013).",5.2. Epidemic Model,[0],[0]
Influenza was introduced to the population by a student returning from holiday in Hong Kong.,5.2. Epidemic Model,[0],[0]
"Of the 763 boys at the school, 512 were infected within 14 days.",5.2. Epidemic Model,[0],[0]
Hence we assume x0 =,5.2. Epidemic Model,[0],[0]
"(762, 1)
′. Observations of the number infectious are provided daily by those students confined to bed.",5.2. Epidemic Model,[0],[0]
"We
assume Gaussian observation error with unknown variance σ2.",5.2. Epidemic Model,[0],[0]
"Our analyses use a discretisation time step of ∆τ = 0.1.
",5.2. Epidemic Model,[0],[0]
We also consider an alternative model with a time-varying infection parameter.,5.2. Epidemic Model,[0],[0]
"Here we let ϑ1 = log θ1 follow an Ornstein-Uhlenbeck process
dϑt,1 = θ3 (θ4 − ϑt,1)",5.2. Epidemic Model,[0],[0]
"dt+ θ5dWt, (27)
where θ3, θ4 and θ5 are the mean-reversion rate, process mean and volatility, respectively, and θt,1 is the infection parameter at time t. Previous related work has focused on ODE epidemic models with time-varying parameters following SDEs (Dureau et al., 2013; Del Moral & Murray, 2015).",5.2. Epidemic Model,[0],[0]
"In contrast, our approach can easily be applied to a full SDE system.
",5.2. Epidemic Model,[0],[0]
Time-invariant infection parameter,5.2. Epidemic Model,[0],[0]
"We infer the logtransformed parameters ϑ = (log θ1, log θ2, log σ2)′ under independent N(0, 32) priors.",5.2. Epidemic Model,[0],[0]
"Our results are shown after transforming back to the original parameterisation.
",5.2. Epidemic Model,[0],[0]
"Convergence takes 2.5 hours, and importance sampling with 500,000 iterations produces an ESS of 718.2.",5.2. Epidemic Model,[0],[0]
"Figure 4 shows two estimates of the marginal parameter posteriors: variational inference output, and a kernel density estimate based on importance sampling results.",5.2. Epidemic Model,[0],[0]
"Figure 6 shows 50 diffusion paths sampled from the variational approximation.
",5.2. Epidemic Model,[0],[0]
The small ESS indicates there is some approximation error.,5.2. Epidemic Model,[0],[0]
"However, the marginal posteriors for θ1 and θ2 are very similar to those from the MCMC analysis of Fuchs (2013, pg 293), despite some modelling differences (that analysis fixed σ2 = 0 and used exponential priors for θ1 and θ2).
",5.2. Epidemic Model,[0],[0]
"Time-variant infection parameter We infer the logtransformed parameters ϑ = (log θ0,1, log θ2, log θ3, log θ4, log θ5, log σ
2)′ under independent N(0, 32) priors.",5.2. Epidemic Model,[0],[0]
"Results are shown after transforming back to the original parameterisation.
",5.2. Epidemic Model,[0],[0]
"Convergence now takes 3 hours, and 500,000 iterations of importance sampling produces an ESS of 256.1.",5.2. Epidemic Model,[0],[0]
"Figure 5 shows estimates of the marginal parameter posteriors, using variational inference and importance sampling outputs as before.",5.2. Epidemic Model,[0],[0]
Figures 7 (SIR) and 8 (Ornstein-Uhlenbeck) show 50 diffusion paths sampled from the variational approximation.,5.2. Epidemic Model,[0],[0]
"Again the low ESS indicates some approximation error.
",5.2. Epidemic Model,[0],[0]
"Model comparison The two models produce visually similar diffusion paths, but close inspection shows some differences.",5.2. Epidemic Model,[0],[0]
The time-invariant model paths for It appear smooth but slightly miss some of the observation points.,5.2. Epidemic Model,[0],[0]
The time-variant model paths for It are less smooth and more accurately capture the shape of the data.,5.2. Epidemic Model,[0],[0]
"Correspondingly, the time-varying model infers a smaller σ2 value.",5.2. Epidemic Model,[0],[0]
"The most obvious difference in It paths occurs for the t = 7, 8, 9
observations, shown in the zoomed-in inset of Figures 6 and 7.",5.2. Epidemic Model,[0],[0]
"Figure 8 shows that shortly before this the time-variant θ1 values become constrained to smaller values.
",5.2. Epidemic Model,[0],[0]
"Although the time-varying model appears to fit the data better, this is at the cost of increased model complexity, and could simply reflect overfitting.",5.2. Epidemic Model,[0],[0]
A better estimate of the parameter posteriors would allow formal model comparison based on importance sampling evidence estimates.,5.2. Epidemic Model,[0],[0]
"We provide a black-box variational approach to inference for SDES which is simple, practical and fast (relative to existing methods).",6. Conclusion,[0],[0]
This performs inference for a broad class of SDEs with minimal tuning requirements.,6. Conclusion,[0],[0]
Empirical investigation shows we obtain close matches to the posterior of the conditioned diffusion paths.,6. Conclusion,[0],[0]
"Approximate parameter inference is also possible, with our results recovering known parameters for synthetic data (Section 5.1), and previous results for real data (Section 5.2), using only a few hours of computation for a desktop PC.",6. Conclusion,[0],[0]
"An interesting future direction is develop choices of q(x|θ;φx) more efficent than standard RNNs, to further reduce computing time and enable real-time applications of this methodology.",6. Conclusion,[0],[0]
"Tom Ryder is supported by the Engineering and Physical Sciences Research Council, Centre for Doctoral Training in Cloud Computing for Big Data (grant number EP/L015358/1).
",Acknowledgements,[0],[0]
We acknowledge with thanks an NVIDIA academic GPU grant for this project.,Acknowledgements,[0],[0]
Parameter inference for stochastic differential equations is challenging due to the presence of a latent diffusion process.,abstractText,[0],[0]
"Working with an EulerMaruyama discretisation for the diffusion, we use variational inference to jointly learn the parameters and the diffusion paths.",abstractText,[0],[0]
"We use a standard mean-field variational approximation of the parameter posterior, and introduce a recurrent neural network to approximate the posterior for the diffusion paths conditional on the parameters.",abstractText,[0],[0]
This neural network learns how to provide Gaussian state transitions which bridge between observations as the conditioned diffusion process does.,abstractText,[0],[0]
The resulting black-box inference method can be applied to any SDE system with light tuning requirements.,abstractText,[0],[0]
"We illustrate the method on a LotkaVolterra system and an epidemic model, producing accurate parameter estimates in a few hours.",abstractText,[0],[0]
Black-Box Variational Inference for Stochastic Differential Equations,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 383–389 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
383",text,[0],[0]
"Author profiling is the task of discovering latent user attributes disclosed through text, such as gender, age, personality, income, location and occupation (Rao et al., 2010; Burger et al., 2011; Feng et al., 2012; Jurgens, 2013; Bamman et al., 2014; Plank and Hovy, 2015; Flekova et al., 2016).",1 Introduction,[0],[0]
"It is of interest to several applications including personalized machine translation, forensics, and marketing (Mirkin et al., 2015; Rangel et al., 2015).
",1 Introduction,[0],[0]
"Early approaches to gender prediction (Koppel et al., 2002; Schler et al., 2006, e.g.) are inspired by pioneering work on authorship attribution (Mosteller and Wallace, 1964).",1 Introduction,[0],[0]
Such stylometric models typically rely on carefully handselected sets of content-independent features to capture style beyond topic.,1 Introduction,[0],[0]
"Recently, open vocabulary approaches (Schwartz et al., 2013), where the entire linguistic production of an author is used, yielded substantial performance gains in on-
line user-attribute prediction (Nguyen et al., 2014; Preoţiuc-Pietro et al., 2015; Emmery et al., 2017).",1 Introduction,[0],[0]
"Indeed, the best performing gender prediction models exploit chiefly lexical information (Rangel et al., 2017; Basile et al., 2017).
",1 Introduction,[0],[0]
"Relying heavily on the lexicon though has its limitations, as it results in models with limited portability.",1 Introduction,[0],[0]
"Moreover, performance might be overly optimistic due to topic bias (Sarawgi et al., 2011).",1 Introduction,[0],[0]
"Recent work on cross-lingual author profiling has proposed the use of solely language-independent features (Ljubešić et al., 2017), e.g., specific textual elements (percentage of emojis, URLs, etc) and users’ meta-data/network (number of followers, etc), but this information is not always available.
",1 Introduction,[0],[0]
"We propose a novel approach where the actual text is still used, but bleached out and transformed into more abstract, and potentially better transferable features.",1 Introduction,[0],[0]
One could view this as a method in between the open vocabulary strategy and the stylometric approach.,1 Introduction,[0],[0]
"It has the advantage of fading out content in favor of more shallow patterns still based on the original text, without introducing additional processing such as part-of-speech tagging.",1 Introduction,[0],[0]
"In particular, we investigate to what extent gender prediction can rely on generic non-lexical features (RQ1), and how predictive such models are when transferred to other languages (RQ2).",1 Introduction,[0],[0]
"We also glean insights from human judgments, and investigate how well people can perform cross-lingual gender prediction (RQ3).",1 Introduction,[0],[0]
"We focus on gender prediction for Twitter, motivated by data availability.
",1 Introduction,[0],[0]
Contributions In this work,1 Introduction,[0],[0]
i),1 Introduction,[0],[0]
"we are the first to study cross-lingual gender prediction without relying on users’ meta-data; ii) we propose a novel simple abstract feature representation which is surprisingly effective; and iii) we gauge human ability to perform cross-lingual gender detection, an angle of analysis which has not been studied thus far.",1 Introduction,[0],[0]
"Can we recover the gender of an author from bleached text, i.e., transformed text were the raw lexical strings are converted into abstract features?",2 Profiling with Abstract Features,[0],[0]
"We investigate this question by building a series of predictive models to infer the gender of a Twitter user, in absence of additional user-specific metadata.",2 Profiling with Abstract Features,[0],[0]
"Our approach can be seen as taking advantage of elements from a data-driven open-vocabulary approach, while trying to capture gender-specific style in text beyond topic.
",2 Profiling with Abstract Features,[0],[0]
"To represent utterances in a more language agnostic way, we propose to simply transform the text into alternative textual representations, which deviate from the lexical form to allow for abstraction.",2 Profiling with Abstract Features,[0],[0]
"We propose the following transformations, exemplified in Table 1.",2 Profiling with Abstract Features,[0],[0]
"They are mostly motivated by intuition and inspired by prior work, like the use of shape features from NER and parsing (Petrov and Klein, 2007; Schnabel and Schütze, 2014;",2 Profiling with Abstract Features,[0],[0]
"Plank et al., 2016; Limsopatham and Collier, 2016):
• Frequency",2 Profiling with Abstract Features,[0],[0]
"Each word is presented as its binned frequency in the training data; bins are sized by orders of magnitude.
",2 Profiling with Abstract Features,[0],[0]
"• Length Number of characters (prefixed by 0 to avoid collision with the next transformation).
",2 Profiling with Abstract Features,[0],[0]
"• PunctC Merges all consecutive alphanumeric characters to one ‘W’ and leaves all other characters as they are (C for conservative).
",2 Profiling with Abstract Features,[0],[0]
• PunctA,2 Profiling with Abstract Features,[0],[0]
"Generalization of PunctC (A for aggressive), converting different types of punctuation to classes: emoticons1 to ‘E’ and emojis2 to ‘J’, other punctuation to ‘P’.
",2 Profiling with Abstract Features,[0],[0]
•,2 Profiling with Abstract Features,[0],[0]
"Shape Transforms uppercase characters to ‘U’, lowercase characters to ‘L’, digits to ‘D’ and all other characters to ‘X’.",2 Profiling with Abstract Features,[0],[0]
"Repetitions
1Using the NLTK tokenizer http://www.nltk.org/ _modules/nltk/tokenize/casual.html
2https://pypi.python.org/pypi/emoji/
of transformed characters are condensed to a maximum of 2 for greater generalization.
",2 Profiling with Abstract Features,[0],[0]
• Vowel-Consonant,2 Profiling with Abstract Features,[0],[0]
"To approximate vowels, while being able to generalize over (IndoEuropean) languages, we convert any of the ‘aeiou’ characters to ‘V’, other alphabetic character to ‘C’, and all other characters to ‘O’.
",2 Profiling with Abstract Features,[0],[0]
•,2 Profiling with Abstract Features,[0],[0]
AllAbs A combination (concatenation) of all previously described features.,2 Profiling with Abstract Features,[0],[0]
"In order to test whether abstract features are effective and transfer across languages, we set up experiments for gender prediction comparing lexicalized and bleached models for both in- and cross-language experiments.",3 Experiments,[0],[0]
"We compare them to a model using multilingual embeddings (Ruder, 2017).",3 Experiments,[0],[0]
"Finally, we elicit human judgments both within language and across language.",3 Experiments,[0],[0]
"The latter is to check whether a person with no prior knowledge of (the lexicon of) a given language can predict the gender of a user, and how that compares to an in-language setup and the machine.",3 Experiments,[0],[0]
"If humans can predict gender cross-lingually, they are likely to rely on aspects beyond lexical information.
",3 Experiments,[0],[0]
"Data We obtain data from the TWISTY corpus (Verhoeven et al., 2016), a multi-lingual collection of Twitter users, for the languages with 500+ users, namely Dutch, French, Portuguese, and Spanish.",3 Experiments,[0],[0]
"We complement them with English, using data from a predecessor of TWISTY (Plank and Hovy, 2015).",3 Experiments,[0],[0]
All datasets contain manually annotated gender information.,3 Experiments,[0],[0]
"To simplify interpretation for the cross-language experiments, we balance gender in all datasets by downsampling to the minority class.",3 Experiments,[0],[0]
The datasets’ final sizes are given in Table 2.,3 Experiments,[0],[0]
"We use 200 tweets per user, as done by previous work (Verhoeven et al., 2016).",3 Experiments,[0],[0]
"We leave the data untokenized to exclude any languagedependent processing, because original tokenization could preserve some signal.",3 Experiments,[0],[0]
Apart from mapping usernames to ‘USER’ and urls to ‘URL’ we do not perform any further data pre-processing.,3 Experiments,[0],[0]
"We use the scikit-learn (Pedregosa et al., 2011) implementation of a linear SVM with default parameters (e.g., L2 regularization).",3.1 Lexical vs Bleached Models,[0],[0]
We use 10-fold cross validation for all in-language experiments.,3.1 Lexical vs Bleached Models,[0],[0]
"For the cross-lingual experiments, we train
on all available source language data and test on all target language data.
",3.1 Lexical vs Bleached Models,[0],[0]
"For the lexicalized experiments, we adopt the features from the best performing system at the latest PAN evaluation campaign3",3.1 Lexical vs Bleached Models,[0],[0]
"(Basile et al., 2017) (word 1-2 grams and character 3-6 grams).
",3.1 Lexical vs Bleached Models,[0],[0]
"For the multilingual embeddings model we use the mean embedding representation from the system of (Plank, 2017) and add max, std and coverage features.",3.1 Lexical vs Bleached Models,[0],[0]
"We create multilingual embeddings by projecting monolingual embeddings to a single multilingual space for all five languages using a recently proposed SVD-based projection method with a pseudo-dictionary (Smith et al., 2017).",3.1 Lexical vs Bleached Models,[0],[0]
"The monolingual embeddings are trained on large amounts of in-house Twitter data (as much data as we had access to, i.e., ranging from 30M tweets for French to 1,500M tweets in Dutch, with a word type coverage between 63 and 77%).",3.1 Lexical vs Bleached Models,[0],[0]
This results in an embedding space with a vocabulary size of 16M word types.,3.1 Lexical vs Bleached Models,[0],[0]
"All code is available at https:// github.com/bplank/bleaching-text.
",3.1 Lexical vs Bleached Models,[0],[0]
"For the bleached experiments, we ran models with each feature set separately.",3.1 Lexical vs Bleached Models,[0],[0]
"In this paper, we report results for the model where all features are combined, as it proved to be the most robust across languages.",3.1 Lexical vs Bleached Models,[0],[0]
"We tuned the n-gram size of this model through in-language cross-validation, finding that n = 5 performs best.
",3.1 Lexical vs Bleached Models,[0],[0]
"When testing across languages, we report accuracy for two setups: average accuracy over each single-language model (AVG), and accuracy obtained when training on the concatenation of all languages but the target one (ALL).",3.1 Lexical vs Bleached Models,[0],[0]
The latter setting is also used for the embeddings model.,3.1 Lexical vs Bleached Models,[0],[0]
"We report accuracy for all experiments.
3http://pan.webis.de
Results and Analysis Table 2 shows results for both the cross-language and in-language experiments in the lexical and abstract-feature setting.
",3.1 Lexical vs Bleached Models,[0],[0]
"Within language, the lexical features unsurprisingly work the best, achieving an average accuracy of 80.5% over all languages.",3.1 Lexical vs Bleached Models,[0],[0]
"The abstract features lose some information and score on average 11.8% lower, still beating the majority baseline (50%) by a large margin (68.7%).",3.1 Lexical vs Bleached Models,[0],[0]
"If we go across language, the lexical approaches break down (overall to 53.7% for LEX AVG/56.3% for ALL), except for Portuguese and Spanish, thanks to their similarities (see Table 3 for pair-wise results).",3.1 Lexical vs Bleached Models,[0],[0]
"The closelyrelated-language effect is also observed when training on all languages, as scores go up when the classifier has access to the related language.",3.1 Lexical vs Bleached Models,[0],[0]
The same holds for the multilingual embeddings model.,3.1 Lexical vs Bleached Models,[0],[0]
"On average it reaches an accuracy of 59.8%.
",3.1 Lexical vs Bleached Models,[0],[0]
"The closeness effect for Portuguese and Spanish can also be observed in language-to-language experiments, where scores for ES7→PT and PT 7→ES are the highest.",3.1 Lexical vs Bleached Models,[0],[0]
"Results for the lexical models are generally lower on English, which might be due to smaller amounts of data (see first column in Table 2 providing number of users per language).
",3.1 Lexical vs Bleached Models,[0],[0]
"The abstract features fare surprisingly well and
work a lot better across languages.",3.1 Lexical vs Bleached Models,[0],[0]
"The performance is on average 6% higher across all languages (57.9% for AVG, 63.9% for ALL) in comparison to their lexicalized counterparts, where ABS ALL results in the overall best model.",3.1 Lexical vs Bleached Models,[0],[0]
"For Spanish, the multilingual embedding model clearly outperforms ABS.",3.1 Lexical vs Bleached Models,[0],[0]
"However, the approach requires large Twitterspecific embeddings.4
For our ABS model, if we investigate predictive features over all languages, cf",3.1 Lexical vs Bleached Models,[0],[0]
". Table 4, we can see that the use of an emoji (like ) and shape-based features are predictive of female users.",3.1 Lexical vs Bleached Models,[0],[0]
"Quotes, question marks and length features, for example, appear to be more predictive of male users.",3.1 Lexical vs Bleached Models,[0],[0]
"We experimented with three different conditions, one within language and two across language.",3.2 Human Evaluation,[0],[0]
"For the latter, we set up an experiment where native speakers of Dutch were presented with tweets written in Portuguese and were asked to guess the poster’s gender.",3.2 Human Evaluation,[0],[0]
"In the other experiment, we asked speakers of French to identify the gender of the writer when reading Dutch tweets.",3.2 Human Evaluation,[0],[0]
"In both cases, the participants declared to have no prior knowledge of the target language.",3.2 Human Evaluation,[0],[0]
"For the in-language experiment, we asked Dutch speakers to identify the gender of a user writing Dutch tweets.",3.2 Human Evaluation,[0],[0]
"The
4We tested the approach with more generic (from Wikipedia) but smaller (in terms of vocabulary size) Polyglot embeddings resulting in inferior multilingual embeddings for our task.
",3.2 Human Evaluation,[0],[0]
Dutch speakers who participated in the two experiments are distinct individuals.,3.2 Human Evaluation,[0],[0]
Participants were informed of the experiment’s goal.,3.2 Human Evaluation,[0],[0]
"Their identity is anonymized in the data.
",3.2 Human Evaluation,[0],[0]
"We selected a random sample of 200 users from the Dutch and Portuguese data, preserving a 50/50 gender distribution.",3.2 Human Evaluation,[0],[0]
Each user was represented by twenty tweets.,3.2 Human Evaluation,[0],[0]
The answer key (F/M) order was randomized.,3.2 Human Evaluation,[0],[0]
"For each of the three experiments we had six judges, balanced for gender, and obtained three annotations per target user.
Results and Analysis Inter-annotator agreement for the tasks was measured via Fleiss kappa (n = 3, N = 200), and was higher for the in-language experiment (K = 0.40) than for the cross-language tasks (NL 7→PT: K = 0.25; FR 7→NL: K = 0.28).",3.2 Human Evaluation,[0],[0]
"Table 5 shows accuracy against the gold labels, comparing humans (average accuracy over three annotators) to lexical and bleached models on the exact same subset of 200 users.",3.2 Human Evaluation,[0],[0]
"Systems were tested under two different conditions regarding the number of tweets per user for the target language: machine and human saw the exact same twenty tweets, or the full set of tweets (200) per user, as done during training (Section 3.1).
",3.2 Human Evaluation,[0],[0]
"First of all, our results indicate that in-language performance of humans is 70.5%, which is quite in line with the findings of Flekova et al. (2016), who report an accuracy of 75% on English.",3.2 Human Evaluation,[0],[0]
"Within language, lexicalized models are superior to humans if exposed to enough information (200 tweets setup).",3.2 Human Evaluation,[0],[0]
"One explanation for this might lie in an observation by Flekova et al. (2016), according to which people tend to rely too much on stereotypical lexical indicators when assigning gender to the poster of a tweet, while machines model less evident patterns.",3.2 Human Evaluation,[0],[0]
"Lexicalized models are also superior to the bleached ones, as already seen on the full datasets (Table 2).
",3.2 Human Evaluation,[0],[0]
We can also observe that the amount of information available to represent a user influences system’s performance.,3.2 Human Evaluation,[0],[0]
"Training on 200 tweets per
user, but testing on 20 tweets only, decreases performance by 12 percentage points.",3.2 Human Evaluation,[0],[0]
"This is likely due to the fact that inputs are sparser, especially since the bleached model is trained on 5-grams.5 The bleached model, when given 200 tweets per user, yields a performance that is slightly higher than human accuracy.
",3.2 Human Evaluation,[0],[0]
"In the cross-language setting, the picture is very different.",3.2 Human Evaluation,[0],[0]
"Here, human performance is superior to the lexicalized models, independently of the amount of tweets per user at testing time.",3.2 Human Evaluation,[0],[0]
"This seems to indicate that if humans cannot rely on the lexicon, they might be exploiting some other signal when guessing the gender of a user who tweets in a language unknown to them.",3.2 Human Evaluation,[0],[0]
"Interestingly, the bleached models, which rely on non-lexical features, not only outperform the lexicalized ones in the cross-language experiments, but also neatly match the human scores.",3.2 Human Evaluation,[0],[0]
Most existing work on gender prediction exploits shallow lexical information based on the linguistic production of the users.,4 Related Work,[0],[0]
"Few studies investigate deeper syntactic information (Koppel et al., 2002; Feng et al., 2012) or non-linguistic input, e.g., language-independent clues such as visual (Alowibdi et al., 2013) or network information (Jurgens, 2013; Plank and Hovy, 2015; Ljubešić et al., 2017).",4 Related Work,[0],[0]
A related angle is cross-genre profiling.,4 Related Work,[0],[0]
"In both settings lexical models have limited portability due to their bias towards the language/genre they have been trained on (Rangel et al., 2016; Busger op Vollenbroek et al., 2016; Medvedeva et al., 2017).
",4 Related Work,[0],[0]
"Lexical bias has been shown to affect inlanguage human gender prediction, too.",4 Related Work,[0],[0]
"Flekova et al. (2016) found that people tend to rely too much on stereotypical lexical indicators, while Nguyen et al. (2014) show that more than 10% of the Twitter users do actually not employ words that the crowd associates with their biological sex.",4 Related Work,[0],[0]
Our features abstract away from such lexical cues while retaining predictive signal.,4 Related Work,[0],[0]
"Bleaching text into abstract features is surprisingly effective for predicting gender, though lexical infor-
5We experimented with training on 20 tweets rather than 200, and with different n-gram sizes (e.g., 1–4).",5 Conclusions,[0],[0]
"Despite slightly better results, we decided to use the trained models as they were to employ the same settings across all experiments (200 tweets per users, n = 5), with no further tuning.
mation is still more useful within language (RQ1).",5 Conclusions,[0],[0]
"However, models based on lexical clues fail when transferred to other languages, or require large amounts of unlabeled data from a similar domain as our experiments with the multilingual embedding model indicate.",5 Conclusions,[0],[0]
"Instead, our bleached models clearly capture some signal beyond the lexicon, and perform well in a cross-lingual setting (RQ2).",5 Conclusions,[0],[0]
We are well aware that we are testing our crosslanguage bleached models in the context of closely related languages.,5 Conclusions,[0],[0]
"While some features (such as PunctA, or Frequency) might carry over to genetically more distant languages, other features (such as Vowels and Shape) would probably be meaningless.",5 Conclusions,[0],[0]
"Future work on this will require a sensible setting from a language typology perspective for choosing and testing adequate features.
",5 Conclusions,[0],[0]
"In our novel study on human proficiency for cross-lingual gender prediction, we discovered that people are also abstracting away from the lexicon.",5 Conclusions,[0],[0]
"Indeed, we observe that they are able to detect gender by looking at tweets in a language they do not know (RQ3) with an accuracy of 60% on average.",5 Conclusions,[0],[0]
We would like to thank the three anonymous reviewers and our colleagues for their useful feedback on earlier versions of this paper.,Acknowledgments,[0],[0]
"Furthermore, we are grateful to Chloé Braud for helping with the French human evaluation part.",Acknowledgments,[0],[0]
We would like to thank all of our human participants.,Acknowledgments,[0],[0]
"Gender prediction has typically focused on lexical and social network features, yielding good performance, but making systems highly language-, topic-, and platformdependent.",abstractText,[0],[0]
"Cross-lingual embeddings circumvent some of these limitations, but capture gender-specific style less.",abstractText,[0],[0]
"We propose an alternative: bleaching text, i.e., transforming lexical strings into more abstract features.",abstractText,[0],[0]
This study provides evidence that such features allow for better transfer across languages.,abstractText,[0],[0]
"Moreover, we present a first study on the ability of humans to perform cross-lingual gender prediction.",abstractText,[0],[0]
"We find that human predictive power proves similar to that of our bleached models, and both perform better than lexical models.",abstractText,[0],[0]
Bleaching Text: Abstract Features for Cross-lingual Gender Prediction,title,[0],[0]
"Concerns are rising that machine learning systems which make or support important decisions affecting individuals— such as car insurance pricing, résumé filtering or recidivism prediction—might illegally or unfairly discriminate against certain subgroups of the population (Schreurs et al., 2008; Calders & Žliobaitė, 2012; Barocas & Selbst, 2016).",1. Introduction,[0],[0]
"The growing field of fair learning seeks to formalize relevant requirements, and through altering parts of the algorithmic decision-making pipeline, to detect and mitigate potential discrimination (Friedler et al., 2016).
",1. Introduction,[0],[0]
"Most legally-problematic discrimination centers on differences based on sensitive attributes, such as gender or race (Barocas & Selbst, 2016).",1. Introduction,[0],[0]
"The first type, disparate treatment (or direct discrimination), occurs if individuals are treated differently according to their sensitive attributes (with all others equal).",1. Introduction,[0],[0]
"To avoid disparate treatment, one should not inquire about individuals’ sensitive attributes.",1. Introduction,[0],[0]
"While
1Max Planck Institute for Intelligent Systems 2University of Cambridge 3The Alan Turing Institute 4University of Warwick 5University College London 6Max Planck Institute for Software Systems.",1. Introduction,[0],[0]
"Correspondence to: Niki Kilbertus <niki.kilbertus@tuebingen.mpg.de>.
Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"this has some intuitive appeal and justification (Grgić-Hlača et al., 2018), a significant concern is that sensitive attributes may often be accurately predicted (“reconstructed”) from non-sensitive features (Dwork et al., 2012).",1. Introduction,[0],[0]
"This motivates measures to deal with the second type of discrimination.
",1. Introduction,[0],[0]
Disparate impact (or indirect discrimination) occurs when the outcomes of decisions disproportionately benefit or hurt individuals from subgroups with particular sensitive attribute settings without appropriate justification.,1. Introduction,[0],[0]
"For example, firms deploying car insurance telematics devices (Handel et al., 2014) build up high dimensional pictures of driving behavior which might easily proxy for sensitive attributes even when they are omitted.",1. Introduction,[0],[0]
"Much recent work in fair learning has focused on approaches to avoiding various notions of disparate impact (Feldman et al., 2015; Hardt et al., 2016; Zafar et al., 2017c).
",1. Introduction,[0],[0]
"In order to check and enforce such requirements, the modeler must have access to the sensitive attributes for individuals in the training data—however, this may be undesirable for several reasons (Žliobaitė & Custers, 2016).",1. Introduction,[0],[0]
"First, individuals are unlikely to want to entrust sensitive attributes to modelers in all application domains.",1. Introduction,[0],[0]
"Where applications have clear discriminatory potential, it is understandable that individuals may be wary of providing sensitive attributes to modelers who might exploit them to negative effect, especially with no guarantee that a fair model will indeed be learned and deployed.",1. Introduction,[0],[0]
"Even if certain modelers themselves were trusted, the wide provision of sensitive data creates heightened privacy risks in the event of a data breach.
",1. Introduction,[0],[0]
"Further, legal barriers may limit collection and processing of sensitive personal data.",1. Introduction,[0],[0]
"A timely example is the EU’s General Data Protection Regulation (GDPR), which contains heightened prerequisites for the collection and processing of some sensitive attributes.",1. Introduction,[0],[0]
"Unlike other data, modelers cannot justify using sensitive characteristics in fair learning with their “legitimate interests”—and instead will often need explicit, freely given consent (Veale & Edwards, 2018).
",1. Introduction,[0],[0]
One way to address these concerns was recently proposed by Veale & Binns (2017).,1. Introduction,[0],[0]
"The idea is to involve a highly trusted third party, and may work well in some cases.",1. Introduction,[0],[0]
"However, there are significant potential difficulties: individuals must disclose their sensitive attributes to the third party (even if an individual trusts the party, she may have concerns that
the data may somehow be obtained or hacked by others, e.g., Graham, 2017); and the modeler must disclose their model to the third party, which may be incompatible with their intellectual property or other business concerns.
Contribution.",1. Introduction,[0],[0]
We propose an approach to detect and mitigate disparate impact without disclosing readable access to sensitive attributes.,1. Introduction,[0],[0]
"This reflects the notion that decisions should be blind to an individual’s status—depicted in courtrooms by a blindfolded Lady Justice holding balanced scales (Bennett Capers, 2012).",1. Introduction,[0],[0]
We assume the existence of a regulator with fairness aims (such as a data protection authority or anti-discrimination agency).,1. Introduction,[0],[0]
"With recent methods from secure multi-party computation (MPC), we enable auditable fair learning while ensuring that both individuals’ sensitive attributes and the modeler’s model remain private to all other parties—including the regulator.",1. Introduction,[0],[0]
"Desirable fairness and accountability applications we enable include:
1.",1. Introduction,[0],[0]
Fairness certification.,1. Introduction,[0],[0]
"Given a model and a dataset of individuals, check that the model satisfies a given fairness constraint (we consider several notions from the literature, see Section 2.2); if yes, generate a certificate.
2.",1. Introduction,[0],[0]
Fair model training.,1. Introduction,[0],[0]
"Given a dataset of individuals, learn a model guaranteed and certified to be fair.
3.",1. Introduction,[0],[0]
Decision verification.,1. Introduction,[0],[0]
"A malicious modeler might go through fair model training, but then use a different model in practice.",1. Introduction,[0],[0]
"To address such accountability concerns (Kroll et al., 2016), we efficiently provide for an individual to challenge a received outcome, verifying that it matches the outcome from the previously certified model.
",1. Introduction,[0],[0]
We rely on recent theoretical developments in MPC (see Section 3) which we extend to admit linear constraints in order to enforce fairness requirements.,1. Introduction,[0],[0]
These extensions may be of independent interest.,1. Introduction,[0],[0]
"We demonstrate the realworld efficacy of our methods, and shall make our code publicly available.",1. Introduction,[0],[0]
Here we formalize our setup and requirements.,2. Fairness and Privacy Requirements,[0],[0]
"We assume three categories of participants: a modeler M, a regulator REG, and users U1, . . .",2.1. Assumptions and Incentives,[0],[0]
",Un.",2.1. Assumptions and Incentives,[0],[0]
"For each user, we consider a vector of sensitive features (or attributes, we use the terms interchangeably) zi ∈ Z (e.g., ethnicity or gender) which might be a source of discrimination, and a vector of non-sensitive features xi ∈ X (discrete or real).",2.1. Assumptions and Incentives,[0],[0]
"Additionally, each user has a non-sensitive feature yi ∈ Y which the modeler M would like to predict—the label (e.g., loan default).",2.1. Assumptions and Incentives,[0],[0]
"In line with current work in fair learning, we
assume that all zi and yi attributes are binary, though our MPC approach could be extended to multi-label settings.",2.1. Assumptions and Incentives,[0],[0]
"The source of societal concern is that sensitive attributes zi are potentially correlated with xi or yi.
",2.1. Assumptions and Incentives,[0],[0]
"Modeler M wishes to train a model fθ : X → Y , which accurately maps features xi to labels yi, in a supervised fashion.",2.1. Assumptions and Incentives,[0],[0]
We assume M needs to keep the model private for intellectual property or other business reasons.,2.1. Assumptions and Incentives,[0],[0]
"The model fθ does not use sensitive information zi as input to prevent disparate treatment (direct discrimination).
",2.1. Assumptions and Incentives,[0],[0]
"For each user Ui, M observes or is provided xi, yi.",2.1. Assumptions and Incentives,[0],[0]
The sensitive information in zi is required to ensure fθ meets a given disparate impact fairness condition F (see Section 2.2).,2.1. Assumptions and Incentives,[0],[0]
"While each user Ui wants fθ to meet F, they also wish to keep zi private from all other parties.",2.1. Assumptions and Incentives,[0],[0]
"The regulator REG aims to ensure that M deploys only models that meet fairness condition F. It has no incentive to collude with M (if collusion were a concern, more sophisticated cryptographic protocols would be required).",2.1. Assumptions and Incentives,[0],[0]
"Further, the modeler M might be legally obliged to demonstrate to the regulator REG that their model meets fairness condition F before it can be publicly deployed.",2.1. Assumptions and Incentives,[0],[0]
"As part of this, REG also has a positive duty to enable the training of fair models.
",2.1. Assumptions and Incentives,[0],[0]
"In Section 2.3, we define and address three fundamental problems in our setup: certification, training, and verification.",2.1. Assumptions and Incentives,[0],[0]
"For each problem, we present its functional goal and its privacy requirements.",2.1. Assumptions and Incentives,[0],[0]
"We refer to D = {(xi, yi)}ni=1 and Z = {zi}ni=1 as the non-sensitive and sensitive data, respectively.",2.1. Assumptions and Incentives,[0],[0]
"In Section 2.2, we first provide necessary background on various notions of fairness that have been explored in the fair learning literature.",2.1. Assumptions and Incentives,[0],[0]
"In large part, works that formalize fairness in machine learning do so by balancing a certain condition between groups of people with different sensitive attributes, z versus z′. Several possible conditions have been proposed.",2.2. Fairness Criteria,[0],[0]
"Popular choices include (where y ∈ {0, 1} and ŷ is the prediction of a machine learning model):
P (ŷ = y | z) = P (ŷ = y | z′) (acc) (1) P (ŷ = y | z, y = 1) = P (ŷ = y | z′, y = 1) (TPR) (2) P (ŷ = y | z, y = 0) = P (ŷ = y | z′, y = 0) (TNR) (3) P (ŷ = y | z, ŷ",2.2. Fairness Criteria,[0],[0]
"= 1) = P (ŷ = y | z′, ŷ = 1) (PPV) (4) P (ŷ = y | z, ŷ = 0) = P (ŷ = y | z′, ŷ = 0) (NPV) (5)
P (ŷ = 1 | z) = P (ŷ = 1 | z′) (AR) (6) Respectively, these consider equality of: (1) accuracy, (2) true positive rate, (3) true negative rate, (4) positive predicted value, (5) negative predicted value, or (6) acceptance rate.",2.2. Fairness Criteria,[0],[0]
"Works which use these or related notions include (Hardt et al., 2016; Zafar et al., 2017c;a;b).
",2.2. Fairness Criteria,[0],[0]
In this work we focus on a variant of eq.,2.2. Fairness Criteria,[0],[0]
"(6), formulated as a constrained optimization problem by Zafar et al. (2017c) mimicking the p%-rule (Biddle, 2006): for any binary protected attribute z ∈ {0, 1}, it aims to achieve
min { P (ŷ = 1 | z = 1) P (ŷ = 1 | z = 0) , P (ŷ = 1 | z = 0) P (ŷ = 1 | z = 1) } ≥ p 100 .",2.2. Fairness Criteria,[0],[0]
"(7)
We believe that in future work, a similar MPC approach could also be used for conditions (1), (2) or (3)—i.e., all the other measures which, to our knowledge, have been addressed with efficient standard (non-private) methods.",2.2. Fairness Criteria,[0],[0]
Fairness certification.,"2.3. Certification, Training, and Verification",[0],[0]
"Given a notion of fairness F, the modeler M would like to work with the regulator REG to obtain a certificate that model fθ is fair.","2.3. Certification, Training, and Verification",[0],[0]
"To do so, we propose that users send their non-sensitive data D to REG; and send encrypted versions of their sensitive data Z to both M and REG.","2.3. Certification, Training, and Verification",[0],[0]
Neither M nor REG can read the sensitive data.,"2.3. Certification, Training, and Verification",[0],[0]
"However, we can design a secure protocol between M and REG (described in Section 3) to certify if the model is fair.","2.3. Certification, Training, and Verification",[0],[0]
"This setup is shown in Figure 1 (Left).
","2.3. Certification, Training, and Verification",[0],[0]
"While both REG and M learn the outcome of the certification, we require the following privacy constraints: (C1) privacy of sensitive user data: no one other than Ui ever learns zi in the clear, (C2) model secrecy: only M learns fθ in the clear, and (C3) minimal disclosure of D to REG: only REG learns D in the clear.
","2.3. Certification, Training, and Verification",[0],[0]
Fair model training.,"2.3. Certification, Training, and Verification",[0],[0]
How can a modeler M learn a fair model without access to users’ sensitive data Z?,"2.3. Certification, Training, and Verification",[0],[0]
We propose to solve this by having users send their non-sensitive data D to M and to distribute encryptions of their sensitive data to M and REG as in certification.,"2.3. Certification, Training, and Verification",[0],[0]
We shall describe a secure MPC protocol between M and REG to train a fair model fθ privately.,"2.3. Certification, Training, and Verification",[0],[0]
"This setup is shown in Figure 1 (Center).
","2.3. Certification, Training, and Verification",[0],[0]
"Privacy constraints: (C1) privacy of sensitive user data, (C2) model secrecy, and (C3) minimal disclosure of D to M.
Decision verification.","2.3. Certification, Training, and Verification",[0],[0]
Assume that a malicious M has had model fθ successfully certified by REG as above.,"2.3. Certification, Training, and Verification",[0],[0]
It then swaps fθ for another potentially unfair model fθ′ in the real world.,"2.3. Certification, Training, and Verification",[0],[0]
"When a user receives a decision ŷ, e.g., her mortgage is denied, she can then challenge that decision by asking REG for a verification V .","2.3. Certification, Training, and Verification",[0],[0]
"The verification involves M and REG, and consists of verifying that fθ′(x) = fθ(x), where x is the user’s non-sensitive data.","2.3. Certification, Training, and Verification",[0],[0]
"This ensures that the user would have been subject to the same result with the certified model fθ, even if fθ′ 6= fθ and fθ′ is not fair.","2.3. Certification, Training, and Verification",[0],[0]
"Hence, while there is no simple technical way to prevent a malicious M from deploying an unfair model, it will get
caught if a user challenges a decision that would differ under fθ.","2.3. Certification, Training, and Verification",[0],[0]
"This setup is shown in Figure 1 (Right).
","2.3. Certification, Training, and Verification",[0],[0]
"Privacy constraint: While REG and the user learn the outcome of the verification, we require (C1) privacy of sensitive user data, and (C2) model secrecy.","2.3. Certification, Training, and Verification",[0],[0]
We use a regulator for several reasons.,2.4. Design Choices,[0],[0]
"Given fair learning is of most benefit to vulnerable individuals, we do not wish to deter adoption with high individual burdens.",2.4. Design Choices,[0],[0]
"While MPC could be carried out without the involvement of a regulator, using all users as parties, this comes at a significantly greater computational cost.",2.4. Design Choices,[0],[0]
"With current methods, taking that approach would be unrealistic given the size of the user-base in many domains of concern, and would furthermore require all users to be online simultaneously.",2.4. Design Choices,[0],[0]
"Introducing a regulator removes these barriers and leaves users’ computational burden at a minimum level, with envisaged applications practical with only their web browsers.
",2.4. Design Choices,[0],[0]
"In cases where users are uncomfortable sharing D with either REG or M, it is trivial to extend all three tasks such that all of xi, yi, zi remain private throughout, with the computation cost increasing only by a factor of 2.",2.4. Design Choices,[0],[0]
"This extension would sometimes be desirable as it restricts the view of M to the final model, prohibiting inferences about Z when D is known.",2.4. Design Choices,[0],[0]
"However, this setup hinders exploratory data analysis by the modeler which might promote robust model-building, and, in the case of verification, validation by the regulator that user-provided data is correct.",2.4. Design Choices,[0],[0]
Our proposed solution to these three problems is to use Multi-Party Computation (MPC).,3. Our Solution,[0],[0]
"Before we describe how it can be applied to fair learning, we first present the basic principles of MPC, as well as its limitations particularly in the context of machine learning applications.",3. Our Solution,[0],[0]
"Multi-Party Computation protocols allow two parties P1 andP2 holding secret values x1 and x2 to evaluate an agreedupon function f , via y = f(x1, x2) in a way in which the parties (either both or one of them) learn only y.",3.1. MPC for Machine Learning,[0],[0]
"For example, if f(x1, x2)",3.1. MPC for Machine Learning,[0],[0]
"= I(x1 < x2), then the parties would learn which of their values is bigger, but nothing else.1 This corresponds to the well-known Yao’s millionaires problem: two millionaires want to conclude who is richer without disclosing their wealth to each other.",3.1. MPC for Machine Learning,[0],[0]
"The problem was introduced by Andrew Yao in 1982, and kicked off the area of multi-party computation in cryptography.
",3.1. MPC for Machine Learning,[0],[0]
"1The function I is 1 if its argument is true and 0 otherwise.
",3.1. MPC for Machine Learning,[0],[0]
"In our setting—instead of a simple comparison as in the millionaires problem—f will be either (i) a procedure to check the fairness of a model and certify it, (ii) a machine learning training procedure with fairness constraints, or (iii) a model evaluation to verify a decision.",3.1. MPC for Machine Learning,[0],[0]
The two parties involved in our computation are the modeler M and the regulator REG.,3.1. MPC for Machine Learning,[0],[0]
"The inputs depend on the case (see Figure 1).
",3.1. MPC for Machine Learning,[0],[0]
"As generic solutions do not yet scale to real-world data analysis tasks, one typically has to tailor custom protocols to the desired functionality.",3.1. MPC for Machine Learning,[0],[0]
"This approach has been followed successfully for a variety of machine learning tasks such as logistic and linear regression (Nikolaenko et al., 2013b; Gascón et al., 2017; Mohassel & Zhang, 2017), neural network training (Mohassel & Zhang, 2017) and evaluation (Juvekar et al., 2018; Liu et al., 2017), matrix factorization (Nikolaenko et al., 2013a), and principal component analysis (Al-Rubaie et al., 2017).",3.1. MPC for Machine Learning,[0],[0]
In the next section we review challenges beyond scalability issues that arise when implementing machine learning algorithms in MPC.,3.1. MPC for Machine Learning,[0],[0]
MPC protocols can be classified into two groups depending on whether the target function is represented as either a Boolean or arithmetic circuit.,3.2. Challenges in Multi-Party Machine Learning,[0],[0]
"All protocols proceed by having the parties jointly evaluate the circuit, processing it gate by gate while keeping intermediate values hidden from both parties by means of a secret sharing scheme.",3.2. Challenges in Multi-Party Machine Learning,[0],[0]
"While representing functions as circuits can be done without losing expressiveness, it means certain operations are impractical.",3.2. Challenges in Multi-Party Machine Learning,[0],[0]
"In particular, algorithms that execute different branches depending on the input data will explode in size when implemented as circuits, and in some cases lose their run time guarantees (e.g., consider binary search).
",3.2. Challenges in Multi-Party Machine Learning,[0],[0]
"Crucially, this applies to floating-point arithmetic.",3.2. Challenges in Multi-Party Machine Learning,[0],[0]
"While
this is work in progress, state-of-the-art MPC floating-point arithmetic implementations take more than 15 milliseconds to multiply two 64 bit numbers (Demmler et al., 2015a,
Table 4), which is prohibitive for our applications.",3.2. Challenges in Multi-Party Machine Learning,[0],[0]
"Hence, machine learning MPC protocols are limited to fixed-point arithmetic.",3.2. Challenges in Multi-Party Machine Learning,[0],[0]
Overcoming this limitation is a key challenge for the field.,3.2. Challenges in Multi-Party Machine Learning,[0],[0]
"Another necessity for the feasibility of MPC is to approximate non-linear functions such as the sigmoid, ideally by (piecewise) linear functions.",3.2. Challenges in Multi-Party Machine Learning,[0],[0]
Input sharing.,3.3. Our MPC Protocols,[0],[0]
"To implement the functionality from Figure 1, we first need a secure procedure for the users to secret share a sensitive value, for example her race, with the modeler M and the regulator REG.",3.3. Our MPC Protocols,[0],[0]
We use additive secret sharing.,3.3. Our MPC Protocols,[0],[0]
A value z is represented in a finite domain Zq—we use q = 264.,3.3. Our MPC Protocols,[0],[0]
"To share z, the user samples a value r from Zq uniformly at random, and sends z − r to M and r to REG.",3.3. Our MPC Protocols,[0],[0]
"While z can be reconstructed (and subsequently operated on) inside the MPC computation by means of a simple addition, each share on its own does not reveal anything z",3.3. Our MPC Protocols,[0],[0]
(other than that it is in Zq).,3.3. Our MPC Protocols,[0],[0]
"One can think of arithmetic sharing as a “distributed one-time pad”.
",3.3. Our MPC Protocols,[0],[0]
"In Figure 1, we now reinterpret the key held by REG and the encrypted z by M, as their corresponding shares of the sensitive attributes and denote them by 〈z〉1 and 〈z〉2 respectively.",3.3. Our MPC Protocols,[0],[0]
"The idea of privately outsourcing computation to two non-colluding parties in this way is recurrent in MPC, and often referred to as the two-server model (Mohassel & Zhang, 2017; Gascón et al., 2017; Nikolaenko et al., 2013b; Al-Rubaie et al., 2017).
",3.3. Our MPC Protocols,[0],[0]
Signing and checking a model.,3.3. Our MPC Protocols,[0],[0]
"Note that certification and verification partly correspond to sub-procedures of the fair training task: during training we check the fairness
constraint F, and repeatedly evaluate partial models on the training dataset (using gradient descent).",3.3. Our MPC Protocols,[0],[0]
"Hence, certification and verification do not add technical difficulties over training, which is described in detail in Section 4.",3.3. Our MPC Protocols,[0],[0]
"However, for verification, we still need to “sign” the model, i.e., REG should obtain a signature s(θ) as a result of model certification, see Figure 1 (Left).",3.3. Our MPC Protocols,[0],[0]
"This signature is used to check in the verification phase, whether a given model θ′ from M satisfies s(θ′) = s(θ) for a certified fair model θ (in which case θ = θ′ with high probability).",3.3. Our MPC Protocols,[0],[0]
"Moreover, we need to preserve the secrecy of the model, i.e., REG should not be able to recover θ from s(θ).",3.3. Our MPC Protocols,[0],[0]
"These properties, given that the space of models is large, calls for a cryptographic hash function, such as SHA-256.
",3.3. Our MPC Protocols,[0],[0]
"Additionally, in our functionality, the hash of θ should be computed inside MPC, to hide θ from REG.",3.3. Our MPC Protocols,[0],[0]
"Fortunately, cryptographic hashes such as SHA-256 are a common benchmark functionality in MPC, and their execution is highly optimized.",3.3. Our MPC Protocols,[0],[0]
"More concretely, the overhead of computing s(θ), which needs to be done both for certification and verification is of the order of fractions of a second (Keller et al., 2013, Figure 14).",3.3. Our MPC Protocols,[0],[0]
"While cryptographic hash functions have various applications in MPC, we believe the application to machine learning model certification is novel.
",3.3. Our MPC Protocols,[0],[0]
"Hence, certification is implemented in MPC as a check that θ satisfies the criterion F, followed by the computation of s(θ).",3.3. Our MPC Protocols,[0],[0]
"On the other hand, for verification, the MPC protocol first computes the signature of the model provided by M, and then proceeds with a prediction as long as the computed signature matches the one obtained by REG in the verification phase.",3.3. Our MPC Protocols,[0],[0]
"An alternative solution is possible based on symmetric encryption under a shared key, as highly efficient MPC implementations of block ciphers such as AES are available (Keller et al., 2017).
",3.3. Our MPC Protocols,[0],[0]
Fair training.,3.3. Our MPC Protocols,[0],[0]
"To realize the fair training functionality from the previous section, we follow closely the techniques recently introduced by Mohassel & Zhang (2017).",3.3. Our MPC Protocols,[0],[0]
"Specifically, we extend their custom MPC protocol for logistic regression to additionally handle linear constraints.",3.3. Our MPC Protocols,[0],[0]
"This extension may be of independent interest, and has applications for privacy-preserving machine learning beyond fairness.",3.3. Our MPC Protocols,[0],[0]
"The concrete technical difficulties in achieving this goal, and how to overcome them, are presented in the next section.",3.3. Our MPC Protocols,[0],[0]
"The formal privacy guarantees of our fair training protocol are stated in the following proposition.
",3.3. Our MPC Protocols,[0],[0]
Proposition 1.,3.3. Our MPC Protocols,[0],[0]
"For non-colluding M and REG, our protocol implements the fair model training functionality satisfying constraints (C1)-(C3) in Section 2.3 in the presence of a semi-honest adversary.
",3.3. Our MPC Protocols,[0],[0]
"The proof holds in the random oracle model, as a standard simulation argument combining several MPC primitives
(Mohassel & Zhang, 2017; Gascón et al., 2017).",3.3. Our MPC Protocols,[0],[0]
"It leverages security of arithmetic sharing, garbled circuits, and oblivious transfer protocols in the semi-honest model (Goldreich et al., 1987).",3.3. Our MPC Protocols,[0],[0]
"A general introduction to MPC, as well as a description of the relevant techniques from (Mohassel & Zhang, 2017) used in our protocol, can be found in Section A in the appendix.",3.3. Our MPC Protocols,[0],[0]
We now present our tailored approaches for learning and evaluating fair models with encrypted sensitive attributes.,4. Technical Challenges of Fair Training,[0],[0]
"We do this via the following contributions:
•",4. Technical Challenges of Fair Training,[0],[0]
"We argue that current optimization techniques for fair learning algorithms are unstable for fixed-point data, which is required by our MPC techniques.",4. Technical Challenges of Fair Training,[0],[0]
"• We describe optimization schemes that are well-suited
for learning over fixed-point number representations.",4. Technical Challenges of Fair Training,[0],[0]
"• We combine tricks to approximate non-linear functions
with specialized operations to make fixed-point arithmetic feasible and avoid over- and under-flows.
",4. Technical Challenges of Fair Training,[0],[0]
"The optimization problem at hand is to learn a classifier θ subject to a (often convex) fairness constraint F(θ):
min θ
n∑
i=1
`θ(xi, yi) subject to F(θ) ≤ 0 , (8)
where `θ is a loss term (the logistic loss in this work).",4. Technical Challenges of Fair Training,[0],[0]
"We collect user data from U1, . . .",4. Technical Challenges of Fair Training,[0],[0]
",Un into matrices X ∈ Rn×d,Z ∈ {0, 1}n×p and a label vector y ∈ {0, 1}n.",4. Technical Challenges of Fair Training,[0],[0]
"Zafar et al. (2017c) use a convex approximation of the p%rule, see eq. (7), for linear classifiers to derive the constraint:
F(θ) = 1
n |Ẑ>Xθ|",4. Technical Challenges of Fair Training,[0],[0]
"− c , (9)
where Ẑ is the matrix of all ẑi := zi",4. Technical Challenges of Fair Training,[0],[0]
− z̄ and c ∈,4. Technical Challenges of Fair Training,[0],[0]
Rd is a constant vector corresponding to the tightness of the fairness constraint.,4. Technical Challenges of Fair Training,[0],[0]
"Here, z̄ is the mean of all inputs zi.",4. Technical Challenges of Fair Training,[0],[0]
"With A := 1/nẐ>X, the p% constraint reads F(θ) = |Aθ|",4. Technical Challenges of Fair Training,[0],[0]
"− c, where the absolute value is taken element-wise.",4. Technical Challenges of Fair Training,[0],[0]
"To solve the optimization problem in eq. (8), with the fairness function F in eq. (9), Zafar et al. (2017c) use Sequential Least Squares Programming (SLSQP).",4.1. Current Techniques,[0],[0]
This technique works by reformulating eq.,4.1. Current Techniques,[0],[0]
(8) as a sequence of Quadratic Programs (QPs).,4.1. Current Techniques,[0],[0]
"After solving each QP, their algorithm uses the Han-Powell method, a quasi-Newton method that iteratively approximates the Hessian H of the objective function via the update
Ht+1 = Ht + l∆l > ∆
θ>∆l∆ − Htθ∆θ
> ∆Ht
θ>∆Htθ∆ ,
where l∆ = l(θt+1,λt+1)",4.1. Current Techniques,[0],[0]
"− l(θt,λt) and l(θt,λt) =∑n i=1",4.1. Current Techniques,[0],[0]
"`θt(xi, yi) + λ
>F(θt) is the Lagrangian of eq.",4.1. Current Techniques,[0],[0]
(8).,4.1. Current Techniques,[0],[0]
"Finally, θ∆ = θt+1 − θt.",4.1. Current Techniques,[0],[0]
There are two issues with this approach from an MPC perspective.,4.1. Current Techniques,[0],[0]
"First, solving a sequence of QPs is prohibitively time-consuming in MPC.",4.1. Current Techniques,[0],[0]
"Second, while the above HanPowell update performs well on floating-point data, the two divisions by non-constant, non-integer numbers easily underflow or overflow with fixed-point numbers.",4.1. Current Techniques,[0],[0]
"Instead, to solve the optimization problem in eq.",4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
"(8), we perform stochastic gradient descent and experiment with the following techniques to incorporate the constraints.
",4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
Lagrangian multipliers.,4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
"Here we minimize
L := 1 n
n∑
i=1
`BCEθ (xi, yi) + λ",4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
">max{F(θ),0} ,
using stochastic gradient descent, i.e., alternating updates θ ← θ − ηθ∇θL and λ ← max{λ + ηλ∇λL,0}, where ηθ, ηλ are the learning rates.
",4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
Projected gradient descent.,4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
"For this method, consider specifically the p%-rule based notion F(θ) = |Aθ|",4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
"− c. We first define Â as the matrix consisting of the rows of A for which F(θ) > 0, i.e., where the constraint is active.",4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
"In each step, we project the computed gradient of the binary-crossentropy loss LBCE—either of a single example or averaged over a minibatch—back into the constraint set, i.e.,
θ ← θ − ηθ(Idd − Â>(ÂÂ>)−1Â)∇θ`BCEθ .",4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
"(10)
Interior point log barrier (Boyd & Vandenberghe, 2004).",4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
We can approximate eq.,4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
"(8) for the p%-rule constraint F(θ) = |Aθ|−c by: minimize∑ni=1 `BCEθ (xi, yi)− 1 t ∑p j=1 ( log(a>j θ + cj) + log(−a>j θ + cj) ) , where aj is the jth row of A.",4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
The parameter t trades off the approximation of the true objective (I−(u) = 0 for u ≤ 0 and I−(u) =∞ for u > 0) and the smoothness of the objective function.,4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
"Throughout training t is increased, allowing the solution to move closer to the boundary.",4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
"As the gradient of the objective has a simple closed form representation, we can perform regular (stochastic) gradient descent.
",4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
"After extensive experiments (see Section 5) we found the Lagrangian multipliers technique to work best, both in yielding high accuracies, reliably staying within the constraints and being robust to hyperparameter changes such as learning rates or the batch size.",4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
"For a proof of concept, in Section 5 we focus on the p%-rule, i.e., eq. (9).",4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
Note that the gradients for eq. (2) and eq.,4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
"(3) take a similarly simple form, i.e., balancing the true positive or true negative rates (corresponding to equal opportunity or equal odds) is simple to implement
for the Lagrangian multiplier technique, but harder for projected gradient descent.",4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
"However, these fairness notions are more expensive as we have to compute Z>X for each update step, instead of pre-computing it once at the beginning of training, see Algorithm 1 in the appendix.",4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
"We could speed up the computation again by evaluating the constraint only on the current minibatch for each update, in which case we risk violating the fairness constraint.
",4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
MPC-friendliness.,4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
"For eq. (9), we can compute the gradient updates in all three methods with elementary linear algebra operations (matrix multiplications) and a single evaluation of the logistic function.",4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
"While MPC is well suited for linear operations, most nonlinear functions are prohibitively expensive to evaluate in an MPC framework.",4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
Hence we tried two piecewise linear approximations for σ(x).,4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
"The first was recently suggested for machine learning in an MPC context (Mohassel & Zhang, 2017) and is simply constant 0 and 1 for x < −0.5 and x > 0.5 respectively, and linear in between.",4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
The second uses the optimal first order Chebychev polynomial on each interval,4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
"[x, x + 1] for x ∈ {−5,−4, . . .",4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
", 4}, and is constant 0 or 1 outside of [−5, 5] (Faiedh et al., 2001).",4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
"While it is more accurate, we only report results for the simpler first approximation, as it yielded equal or better results in all our experiments.
",4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
"As the largest number that can be represented in fixed-point format with m integer and m fractional bits is roughly 2m + 1, overflow becomes a common problem.",4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
"Since we whiten the features X column-wise, we need to be careful whenever we add roughly 2m numbers or more, because we cannot even represent numbers greater than 2m. In particular, the minibatch size has to be smaller than this limit.",4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
"For large n, the multiplication Z>X in the fairness function F for the p%-rule is particularly problematic.
",4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
"Hence, we split both factors into blocks of size b × b with b < 2m and normalize the result of each blocked matrix multiplication by b before adding up the blocks.",4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
We then multiply the sum by b/n > 2−m.,4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
"As long as b, b/n (and thus also n/b) can be represented with sufficient precision, which is the case in all our experiments, this procedure avoids under- and overflow.",4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
Note that we require the sample size n to be a multiple of b.,4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
"In practice, we have to either discard or duplicate part of the data.",4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
"Since the latter may introduce bias, we recommend subsampling.",4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
Once we have (an approximation of),4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
"A ∈ Rp×d, we resort to normal matrix multiplication, as typically p, d .",4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
"100, see Table 1.
Division is prohibitively expensive in MPC.",4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
"Hence, we set the minibatch size to a power of two, which allows us to use fast bit shifts for divisions when averaging over minibatches.",4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
"To exploit the same trick when averaging over/across blocks in the blocked matrix multiplication, we choose n as the largest possible power of two, see Table 1.
",4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
Algorithm 1 in Section B in the appendix describes the computations M and REG have to run for fair model training using the Lagrangian multiplier technique and the p%-rule from eq.,4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
(9).,4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
We implicitly assume all computations are performed jointly on additively shared secrets.,4.2. Fixed-Point-Friendly Optimization Techniques,[0],[0]
The root cause for most technical difficulties pointed out in the previous section is the necessity to work with fixed-point numbers and the high computational cost of MPC.,5. Experiments,[0],[0]
"Hence, major concerns are loss of precision and infeasible running times.",5. Experiments,[0],[0]
"In this section, we show how to overcome both doubts and that fair training, certification and verification are feasible for realistic datasets.",5. Experiments,[0],[0]
We work with two separate code bases.,5.1. Experimental Setup and Datasets,[0],[0]
"Our Python code does not implement MPC, to be able to flexibly switch between floating and fixed-point numbers as well as exact non-linear functions and their approximations.",5.1. Experimental Setup and Datasets,[0],[0]
We use it mostly for validation and empirical guidance in our design choices.,5.1. Experimental Setup and Datasets,[0],[0]
"The full MPC protocol is implemented in C++ on top of the Obliv-C garbled circuits framework (Zahur & Evans, 2015a) and the Absentminded Crypto Kit (lib).",5.1. Experimental Setup and Datasets,[0],[0]
This is done as described in Section 3 for the Lagrangian multiplier technique (see Section A in the appendix for more details).,5.1. Experimental Setup and Datasets,[0],[0]
It accurately mirrors the computations performed by the first implementation on encrypted data.2,5.1. Experimental Setup and Datasets,[0],[0]
"Except for the timing results in Table 1, all comparisons with floatingpoint numbers or non-linearities were done with the versatile Python implementation.",5.1. Experimental Setup and Datasets,[0],[0]
"Details about parameters and the algorithm can be found in Section B in the appendix.
",5.1. Experimental Setup and Datasets,[0],[0]
"We consider 5 real world datasets, namely the adult (Adult), German credit (German), and bank market (Bank) datasets from the UCI machine learning repository (Lichman, 2013), the stop, question and frisk 2012 dataset (SQF),3 and the COMPAS dataset (Angwin et al., 2016) (COMPAS).",5.1. Experimental Setup and Datasets,[0],[0]
"For practical purposes (see Section 4), we subsample 2i examples from each dataset with the largest possible i, see Table 1.",5.1. Experimental Setup and Datasets,[0],[0]
"Moreover, we also run on synthetic data, generated
2Code is available at https://github.com/ nikikilbertus/blind-justice
3https://perma.cc/6CSM-N7AQ
as described by Zafar et al. (2017c, Section 4.1), as it allows us to control the correlation between the sensitive attributes and the class labels.",5.1. Experimental Setup and Datasets,[0],[0]
It is thus well suited to observe how different optimization techniques handle the fairness-accuracy trade off.,5.1. Experimental Setup and Datasets,[0],[0]
For comparison we use the SLSQP approach described in Section 4.1 as a baseline.,5.1. Experimental Setup and Datasets,[0],[0]
"We run all methods for a range of constraint values in [10−4, 100] and a corresponding range for SLSQP.
",5.1. Experimental Setup and Datasets,[0],[0]
"In the plots in this section, discontinuations of lines indicate failed experiments.",5.1. Experimental Setup and Datasets,[0],[0]
"The most common reasons are overflow and underflow for fixed-point numbers, and instability due to exploding gradients.",5.1. Experimental Setup and Datasets,[0],[0]
Plots and analyses for the remaining datasets can be found in Section C in the appendix.,5.1. Experimental Setup and Datasets,[0],[0]
First we evaluate which of the three optimization techniques works best in practice.,5.2. Comparing Optimization Techniques,[0],[0]
Figure 2 shows the test set accuracy over the constraint value.,5.2. Comparing Optimization Techniques,[0],[0]
"By design, the synthetic dataset exhibits a clear trade-off between accuracy and fairness.",5.2. Comparing Optimization Techniques,[0],[0]
"The Lagrange technique closely follows the (dotted) baseline from (Zafar et al., 2017c), whereas iplb performs slightly worse (and fails for small c).",5.2. Comparing Optimization Techniques,[0],[0]
"Even though the projected gradient method formally satisfies the proxy constraint for the p% rule, it does so by merely shrinking the parameter vector θ, which is why it also fails for small c.",5.2. Comparing Optimization Techniques,[0],[0]
"We analyze this behavior in more detail in Section C in the appendix.
",5.2. Comparing Optimization Techniques,[0],[0]
"The COMPAS dataset is the most challenging as it contains 7 sensitive attributes, one of which has only 10 positive instances in the training set.",5.2. Comparing Optimization Techniques,[0],[0]
"Since we enforce the fairness constraint individually for each sensitive attribute (we randomly picked one for visualization), the classifier tends to collapse to negative predictions.",5.2. Comparing Optimization Techniques,[0],[0]
"All three methods maintain close to optimal accuracy in the unconstrained region, but collapse more quickly than SLSQP.",5.2. Comparing Optimization Techniques,[0],[0]
This example shows that the p%-rule proxy itself needs careful interpretation when applied to multiple sensitive attributes simultaneously and that our SGD based approach seems particularly prone to collapse in such a scenario.,5.2. Comparing Optimization Techniques,[0],[0]
On the Bank dataset accuracy increases for iplb and Lagrange when the constraint becomes active as c decreases until they match the baseline.,5.2. Comparing Optimization Techniques,[0],[0]
Determining the cause of this—perhaps unintuitive—behavior requires further investigation.,5.2. Comparing Optimization Techniques,[0],[0]
We currently suspect the constraint to act as a regularizer.,5.2. Comparing Optimization Techniques,[0],[0]
"The projected gradient method is unreliable on the Bank dataset.
",5.2. Comparing Optimization Techniques,[0],[0]
"Empirically, the Lagrangian multiplier technique is most robust with maximal deviations of accuracy from SLSQP of < 4% across the 6 datasets and all constraint values.",5.2. Comparing Optimization Techniques,[0],[0]
We substantiate this claim in Section C of the appendix.,5.2. Comparing Optimization Techniques,[0],[0]
For the rest of this section we only report results for Lagrangian multipliers.,5.2. Comparing Optimization Techniques,[0],[0]
Figure 2 also shows that using a piecewise linear approximation as described in Section 4 for the logistic function does not spoil performance.,5.2. Comparing Optimization Techniques,[0],[0]
Figure 3 shows how the fractions of users with positive outcomes in the two groups (z = 0 is continuous and z = 1 is dashed) are gradually balanced as we decrease the fairness constraint c. These plots can be interpreted as the degree to which disparate impact is mitigated as the constraint is tightened.,"5.3. Fair Training, Certification and Verification",[0],[0]
The effect is most pronounced for the synthetic dataset by construction.,"5.3. Fair Training, Certification and Verification",[0],[0]
"As discussed above, the collapse for the COMPAS dataset occurs faster than for SLSQP due to the constraints from multiple sensitive attributes.","5.3. Fair Training, Certification and Verification",[0],[0]
"In the Bank dataset, for large c—before the constraint becomes active—the fractions of positive outcomes for z = 1 differ, which is related to the slightly suboptimal accuracy at large c that needs further investigation.","5.3. Fair Training, Certification and Verification",[0],[0]
"However, as the constraint becomes active, the fractions are balanced at a similar rate as the baseline.","5.3. Fair Training, Certification and Verification",[0],[0]
"Overall, our Lagrangian multiplier technique with fixed point numbers and piecewise linear approximations of non-linearities robustly manages to satisfy the p%-rule proxy at similar rates as the baseline with only minor losses in accuracy on all but the challenging COMPAS dataset.
","5.3. Fair Training, Certification and Verification",[0],[0]
In Table 1 we show the online running times of 10 training epochs on a laptop computer.,"5.3. Fair Training, Certification and Verification",[0],[0]
"While training takes several orders of magnitudes longer than a non-MPC implementation, our approach still remains feasible and realistic.","5.3. Fair Training, Certification and Verification",[0],[0]
"We use the one time offline precomputation of multiplication triples described and timed in Mohassel & Zhang (2017,
Table 2).","5.3. Fair Training, Certification and Verification",[0],[0]
"As pointed out in Section 3, certification of a trained model requires checking whether F(θ) > 0.","5.3. Fair Training, Certification and Verification",[0],[0]
"We already perform this check at least once for each gradient
update during training.","5.3. Fair Training, Certification and Verification",[0],[0]
"It only takes a negligible fraction of the computation time, see Table 1.","5.3. Fair Training, Certification and Verification",[0],[0]
"Similarly, the operations required for certification stay well below one second.
","5.3. Fair Training, Certification and Verification",[0],[0]
Discussion.,"5.3. Fair Training, Certification and Verification",[0],[0]
"In this section, we have demonstrated the practicability of private and fair model training, certification and verification using MPC as described in Figure 1.","5.3. Fair Training, Certification and Verification",[0],[0]
"Using the methods and tricks introduced in Section 4, we can overcome accuracy as well as over- and underflow concerns due to fixed-point numbers.","5.3. Fair Training, Certification and Verification",[0],[0]
Offline precomputation combined with a fast C++ implementation yield viable running times for reasonably large datasets on a laptop computer.,"5.3. Fair Training, Certification and Verification",[0],[0]
"Real world fair learning has suffered from a dilemma: in order to enforce fairness, sensitive attributes must be examined; yet in many situations, users may feel uncomfortable in revealing these attributes, or modelers may be legally restricted in collecting and utilizing them.",6. Conclusion,[0],[0]
"By introducing recent methods from MPC, and extending them to handle linear constraints as required for various notions of fairness, we have demonstrated that it is practical on real-world datasets to: (i) certify and sign a model as fair; (ii) learn a fair model; and (iii) verify that a fair-certified model has indeed been used; all while maintaining cryptographic privacy of all users’ sensitive attributes.",6. Conclusion,[0],[0]
"Connecting concerns in privacy, algorithmic fairness and accountability, our proposal empowers regulators to provide better oversight, modelers to develop fair and private models, and users to retain control over data they consider highly sensitive.",6. Conclusion,[0],[0]
"The authors would like to thank Chris Russell and Phillipp Schoppmann for useful discussions and help with the implementation, as well as the anonymous reviewers for helpful comments.",Acknowledgments,[0],[0]
AG and MK were supported by The Alan Turing Institute under the EPSRC grant EP/N510129/1.,Acknowledgments,[0],[0]
MV was supported by EPSRC grant EP/M507970/1.,Acknowledgments,[0],[0]
"AW acknowledges support from the David MacKay Newton research fellowship at Darwin College, The Alan Turing Institute under EPSRC grant EP/N510129/1 & TU/B/000074, and the Leverhulme Trust via the CFI.",Acknowledgments,[0],[0]
Recent work has explored how to train machine learning models which do not discriminate against any subgroup of the population as determined by sensitive attributes such as gender or race.,abstractText,[0],[0]
"To avoid disparate treatment, sensitive attributes should not be considered.",abstractText,[0],[0]
"On the other hand, in order to avoid disparate impact, sensitive attributes must be examined—e.g., in order to learn a fair model, or to check if a given model is fair.",abstractText,[0],[0]
We introduce methods from secure multi-party computation which allow us to avoid both.,abstractText,[0],[0]
"By encrypting sensitive attributes, we show how an outcomebased fair model may be learned, checked, or have its outputs verified and held to account, without users revealing their sensitive attributes.",abstractText,[0],[0]
Blind Justice: Fairness with Encrypted Sensitive Attributes,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 1516–1527 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics",text,[0],[0]
"A core step in statistical data-to-text generation concerns learning correspondences between structured data representations (e.g., facts in a database) and paired texts (Barzilay and Lapata, 2005; Kim and Mooney, 2010; Liang et al., 2009).",1 Introduction,[0],[0]
"These correspondences describe how data representations are expressed in natural language (content realisation) but also indicate which subset of the data is verbalised in the text (content selection).
",1 Introduction,[0],[0]
"Although content selection is traditionally performed by domain experts, recent advances in generation using neural networks (Bahdanau et al., 2015; Ranzato et al., 2016) have led to the use of large scale datasets containing loosely related data and text pairs.",1 Introduction,[0],[0]
"A prime example are online data sources like DBPedia (Auer et al., 2007) and Wikipedia and their associated texts which
1Our code and data are available at https://github.com/EdinburghNLP/wikigen.
are often independently edited.",1 Introduction,[0],[0]
Another example are sports databases and related textual resources.,1 Introduction,[0],[0]
"Wiseman et al. (2017) recently define a generation task relating statistics of basketball games with commentaries and a blog written by fans.
",1 Introduction,[0],[0]
"In this paper, we focus on short text generation from such loosely aligned data-text resources.",1 Introduction,[0],[0]
We work with the biographical subset of the DBPedia and Wikipedia resources where the data corresponds to DBPedia facts and texts are Wikipedia abstracts about people.,1 Introduction,[0],[0]
"Figure 1 shows an example for the film-maker Robert Flaherty, the Wikipedia infobox, and the corresponding abstract.",1 Introduction,[0],[0]
We wish to bootstrap a data-to-text generator that learns to verbalise properties about an entity from a loosely related example text.,1 Introduction,[0],[0]
"Given the set of properties in Figure (1a) and the related text in Figure (1b), we want to learn verbalisations for those properties that are mentioned in the text and produce a short description like the one in Figure (1c).
",1 Introduction,[0],[0]
"In common with previous work (Mei et al., 2016; Lebret et al., 2016; Wiseman et al., 2017)",1 Introduction,[0],[0]
"our model draws on insights from neural machine translation (Bahdanau et al., 2015; Sutskever et al., 2014) using an encoder-decoder architecture as its backbone.",1 Introduction,[0],[0]
"Lebret et al. (2016) introduce the task of generating biographies from Wikipedia data, however they focus on single sentence generation.",1 Introduction,[0],[0]
"We generalize the task to multi-sentence text, and highlight the limitations of the standard attention mechanism which is often used as a proxy for content selection.",1 Introduction,[0],[0]
"When exposed to sub-sequences that do not correspond to any facts in the input, the soft attention mechanism will still try to justify the sequence and somehow distribute the attention weights over the input representation (Ghader and Monz, 2017).",1 Introduction,[0],[0]
"The decoder will still memorise high frequency sub-sequences in spite of these not being supported by any facts in the input.
",1 Introduction,[0],[0]
"We propose to alleviate these shortcom-
1516
ings via a specific content selection mechanism based on multi-instance learning (MIL; Keeler and Rumelhart, 1992) which automatically discovers correspondences, namely alignments, between data and text pairs.",1 Introduction,[0],[0]
These alignments are then used to modify the generation function during training.,1 Introduction,[0],[0]
"We experiment with two frameworks that allow to incorporate alignment information, namely multi-task learning (MTL; Caruana, 1993) and reinforcement learning (RL; Williams, 1992).",1 Introduction,[0],[0]
In both cases we define novel objective functions using the learnt alignments.,1 Introduction,[0],[0]
"Experimental results using automatic and human-based evaluation show that models trained with content-specific objectives improve upon vanilla encoder-decoder architectures which rely solely on soft attention.
",1 Introduction,[0],[0]
The remainder of this paper is organised as follows.,1 Introduction,[0],[0]
We discuss related work in Section 2 and describe the MIL-based content selection approach in Section 3.,1 Introduction,[0],[0]
We explain how the generator is trained in Section 4 and present evaluation experiments in Section 5.,1 Introduction,[0],[0]
Section 7 concludes the paper.,1 Introduction,[0],[0]
Previous attempts to exploit loosely aligned data and text corpora have mostly focused on extracting verbalisation spans for data units.,2 Related Work,[0],[0]
"Most approaches work in two stages: initially, data units are aligned with sentences from related corpora using some heuristics and subsequently extra content is discarded in order to retain only text spans verbalising the data.",2 Related Work,[0],[0]
"Belz and Kow (2010) obtain verbalisation spans using a measure of strength of association between data units and words, Walter et al. (2013) extract textual patterns from paths in dependency trees while Mrabet et al. (2016) rely on crowd-sourcing.",2 Related Work,[0],[0]
"Perez-Beltrachini and Gardent (2016) learn shared representations for data units and sentences reduced to subject-
predicate-object triples with the aim of extracting verbalisations for knowledge base properties.",2 Related Work,[0],[0]
"Our work takes a step further, we not only induce datato-text alignments but also learn generators that produce short texts verbalising a set of facts.
",2 Related Work,[0],[0]
Our work is closest to recent neural network models which learn generators from independently edited data and text resources.,2 Related Work,[0],[0]
"Most previous work (Lebret et al., 2016; Chisholm et al., 2017; Sha et al., 2017; Liu et al., 2017) targets the generation of single sentence biographies from Wikipedia infoboxes, while Wiseman et al. (2017) generate game summary documents from a database of basketball games where the input is always the same set of table fields.",2 Related Work,[0],[0]
"In contrast, in our scenario, the input data varies from one entity (e.g., athlete) to another (e.g., scientist) and properties might be present or not due to data incompleteness.",2 Related Work,[0],[0]
"Moreover, our generator is enhanced with a content selection mechanism based on multi-instance learning.",2 Related Work,[0],[0]
"MIL-based techniques have been previously applied to a variety of problems including image retrieval (Maron and Ratan, 1998; Zhang et al., 2002), object detection (Carbonetto et al., 2008; Cour et al., 2011), text classification (Andrews and Hofmann, 2004), image captioning (Wu et al., 2015; Karpathy and Fei-Fei, 2015), paraphrase detection (Xu et al., 2014), and information extraction (Hoffmann et al., 2011).",2 Related Work,[0],[0]
"The application of MIL to content selection is novel to our knowledge.
",2 Related Work,[0],[0]
We show how to incorporate content selection into encoder-decoder architectures following training regimes based on multi-task learning and reinforcement learning.,2 Related Work,[0],[0]
Multi-task learning aims to improve a main task by incorporating joint learning of one or more related auxiliary tasks.,2 Related Work,[0],[0]
"It has been applied with success to a variety of sequence-prediction tasks focus-
ing mostly on morphosyntax.",2 Related Work,[0],[0]
"Examples include chunking, tagging (Collobert et al., 2011; Søgaard and Goldberg, 2016; Bjerva et al., 2016; Plank, 2016), name error detection (Cheng et al., 2015), and machine translation (Luong et al., 2016).",2 Related Work,[0],[0]
"Reinforcement learning (Williams, 1992) has also seen popularity as a means of training neural networks to directly optimize a taskspecific metric (Ranzato et al., 2016) or to inject task-specific knowledge (Zhang and Lapata, 2017).",2 Related Work,[0],[0]
We are not aware of any work that compares the two training methods directly.,2 Related Work,[0],[0]
"Furthermore, our reinforcement learning-based algorithm differs from previous text generation approaches (Ranzato et al., 2016; Zhang and Lapata, 2017) in that it is applied to documents rather than individual sentences.",2 Related Work,[0],[0]
"We consider loosely coupled data and text pairs where the data component is a set P of propertyvalues {p1 : v1, · · · , p|P | : v|P |} and the related text T is a sequence of sentences (s1, · · · ,s|T |).",3 Bidirectional Content Selection,[0],[0]
We define a mention span τ as a (possibly discontinuous) subsequence of T containing one or several words that verbalise one or more property-value from P .,3 Bidirectional Content Selection,[0],[0]
"For instance, in Figure 1, the mention span “married to Frances H. Flaherty” verbalises the property-value {Spouse(s) :",3 Bidirectional Content Selection,[0],[0]
"Frances Johnson Hubbard}.
",3 Bidirectional Content Selection,[0],[0]
"In traditional supervised data to text generation tasks, data units (e.g., pi : vi in our particular setting) are either covered by some mention span τ j or do not have any mention span at all in T .",3 Bidirectional Content Selection,[0],[0]
The latter is a case of content selection where the generator will learn which properties to ignore when generating text from such data.,3 Bidirectional Content Selection,[0],[0]
"In this work, we consider text components which are independently edited, and will unavoidably contain unaligned spans, i.e., text segments which do not correspond to any property-value in P .",3 Bidirectional Content Selection,[0],[0]
The phrase “from 1914” in the text in Figure (1b) is such an example.,3 Bidirectional Content Selection,[0],[0]
"Similarly, the last sentence, talks about Frances’ awards and nominations and this information is not supported by the properties either.
",3 Bidirectional Content Selection,[0],[0]
Our model checks content in both directions; it identifies which properties have a corresponding text span (data selection) and also foregrounds (un)aligned text spans (text selection).,3 Bidirectional Content Selection,[0],[0]
"This knowledge is then used to discourage the generator from producing text not supported by facts in the prop-
erty set P .",3 Bidirectional Content Selection,[0],[0]
"We view a property set P and its loosely coupled text T as a coarse level, imperfect alignment.",3 Bidirectional Content Selection,[0],[0]
"From this alignment signal, we want to discover a set of finer grained alignments indicating which mention spans in T align to which properties in P .",3 Bidirectional Content Selection,[0],[0]
"For each pair (P ,T ), we learn an alignment set A(P ,T ) which contains property-value word pairs.",3 Bidirectional Content Selection,[0],[0]
"For example, for the properties spouse and died in Figure 1, we would like to derive the alignments in Table 1.
",3 Bidirectional Content Selection,[0],[0]
"We formulate the task of discovering finergrained word alignments as a multi-instance learning problem (Keeler and Rumelhart, 1992).",3 Bidirectional Content Selection,[0],[0]
We assume that words from the text are positive labels for some property-values but we do not know which ones.,3 Bidirectional Content Selection,[0],[0]
"For each data-text pair (P ,T ), we derive |T | pairs of the form (P ,s) where |T | is the number of sentences in T .",3 Bidirectional Content Selection,[0],[0]
We encode property sets P and sentences s into a common multimodal h-dimensional embedding space.,3 Bidirectional Content Selection,[0],[0]
"While doing this, we discover finer grained alignments between words and property-values.",3 Bidirectional Content Selection,[0],[0]
"The intuition is that by learning a high similarity score for a property set P and sentence pair s, we will also learn the contribution of individual elements (i.e., words and property-values) to the overall similarity score.",3 Bidirectional Content Selection,[0],[0]
We will then use this individual contribution as a measure of word and property-value alignment.,3 Bidirectional Content Selection,[0],[0]
"More concretely, we assume the pair is aligned (or unaligned) if this individual score is above (or below) a given threshold.",3 Bidirectional Content Selection,[0],[0]
"Across examples like the one shown in Figure (1a-b), we expect the model to learn an alignment between the text span
“married to Frances H. Flaherty” and the propertyvalue {spouse : Frances Johnson Hubbard}.
",3 Bidirectional Content Selection,[0],[0]
"In what follows we describe how we encode (P ,s) pairs and define the similarity function.
",3 Bidirectional Content Selection,[0],[0]
"Property Set Encoder As there is no fixed order among the property-value pairs p : v in P , we individually encode each one of them.",3 Bidirectional Content Selection,[0],[0]
"Furthermore, both properties p and values v may consist of short phrases.",3 Bidirectional Content Selection,[0],[0]
"For instance, the property cause o f death and value cerebral thrombosis in Figure 1.",3 Bidirectional Content Selection,[0],[0]
"We
therefore consider property-value pairs as concatenated sequences pv and use a bidirectional Long Short-Term Memory Network (LSTM; Hochreiter and Schmidhuber, 1997) network for their encoding.",3 Bidirectional Content Selection,[0],[0]
Note that the same network is used for all pairs.,3 Bidirectional Content Selection,[0],[0]
"Each property-value pair is encoded into a vector representation:
pi = biLSTMdenc(pvi) (1)
which is the output of the recurrent network at the final time step.",3 Bidirectional Content Selection,[0],[0]
"We use addition to combine the forward and backward outputs and generate encoding {p1, · · · ,p|P |} for P .",3 Bidirectional Content Selection,[0],[0]
"Sentence Encoder We also use a biLSTM to obtain a representation for the sentence s = w1, · · · ,w|s|.",3 Bidirectional Content Selection,[0],[0]
"Each word wt is represented by the output of the forward and backward networks at time step t. A word at position t is represented by the concatenation of the forward and backward outputs of the networks at time step t :
wt = biLSTMsenc(wt)",3 Bidirectional Content Selection,[0],[0]
"(2)
and each sentence is encoded as a sequence of vectors (w1, · · · ,w|s|).",3 Bidirectional Content Selection,[0],[0]
Alignment Objective,3 Bidirectional Content Selection,[0],[0]
"Our learning objective seeks to maximise the similarity score between property set P and a sentence s (Karpathy and Fei-Fei, 2015).",3 Bidirectional Content Selection,[0],[0]
This similarity score is in turn defined on top of the similarity scores among property-values in P and words in s. Equation (3) defines this similarity function using the dot product.,3 Bidirectional Content Selection,[0],[0]
"The function seeks to align each word to the best scoring property-value:
SP s = |s| ∑ t=1",3 Bidirectional Content Selection,[0],[0]
"maxi∈{1,...,|P |} pi • wt (3)
",3 Bidirectional Content Selection,[0],[0]
Equation (4) defines our objective which encourages related properties P and sentences s to have higher similarity than other P ′ 6=,3 Bidirectional Content Selection,[0],[0]
"P and s′ 6= s:
LCA = max(0,SP s −SP s ′ +1) +max(0,SP s −SP ′s +1)
(4)",3 Bidirectional Content Selection,[0],[0]
In this section we describe the base generation architecture and explain two alternative ways of using the alignments to guide the training of the model.,4 Generator Training,[0],[0]
"One approach follows multi-task training where the generator learns to output a sequence of words but also to predict alignment labels for
each word.",4 Generator Training,[0],[0]
The second approach relies on reinforcement learning for adjusting the probability distribution of word sequences learnt by a standard word prediction training algorithm.,4 Generator Training,[0],[0]
"We follow a standard attention based encoderdecoder architecture for our generator (Bahdanau et al., 2015; Luong et al., 2015).",4.1 Encoder-Decoder Base Generator,[0],[0]
"Given a set of properties X as input, the model learns to predict an output word sequence Y which is a verbalisation of (part of) the input.",4.1 Encoder-Decoder Base Generator,[0],[0]
"More precisely, the generation of sequence Y is conditioned on input X :
P(Y |X) = |Y | ∏ t=1",4.1 Encoder-Decoder Base Generator,[0],[0]
"P(yt |y1:t−1,X) (5)
",4.1 Encoder-Decoder Base Generator,[0],[0]
The encoder module constitutes an intermediate representation of the input.,4.1 Encoder-Decoder Base Generator,[0],[0]
"For this, we use the property-set encoder described in Section 3 which outputs vector representations {p1, · · · ,p|X |} for a set of property-value pairs.",4.1 Encoder-Decoder Base Generator,[0],[0]
"The decoder uses an LSTM and a soft attention mechanism (Luong et al., 2015) to generate one word yt at a time conditioned on the previous output words and a context vector ct dynamically created: P(yt+1|y1:t ,X) =",4.1 Encoder-Decoder Base Generator,[0],[0]
"so f tmax(g(ht ,ct))",4.1 Encoder-Decoder Base Generator,[0],[0]
"(6) where g(·) is a neural network with one hidden layer parametrised by Wo ∈ R|V |×d , |V",4.1 Encoder-Decoder Base Generator,[0],[0]
"| is the output vocabulary size and d the hidden unit dimension, over ht and ct composed as follows:
g(ht ,ct) =",4.1 Encoder-Decoder Base Generator,[0],[0]
"Wo tanh(Wc[ct ;ht ]) (7)
where Wc ∈ Rd×2d .",4.1 Encoder-Decoder Base Generator,[0],[0]
ht is the hidden state of the LSTM decoder which summarises y1:,4.1 Encoder-Decoder Base Generator,[0],[0]
"t :
ht = LSTM(yt ,ht−1) (8)
The dynamic context vector ct is the weighted sum of the hidden states of the input property set (Equation (9)); and the weights αti are determined by a dot product attention mechanism:
ct = |X",4.1 Encoder-Decoder Base Generator,[0],[0]
| ∑ i=1,4.1 Encoder-Decoder Base Generator,[0],[0]
"αti pi (9)
αti = exp(ht • pi)
∑i ′",4.1 Encoder-Decoder Base Generator,[0],[0]
"exp(ht • pi ′) (10)
We initialise the decoder with the averaged sum of the encoded input representations (Vinyals et al., 2016).",4.1 Encoder-Decoder Base Generator,[0],[0]
"The model is trained to optimize negative log likelihood:
LwNLL =− |Y | ∑ t=1",4.1 Encoder-Decoder Base Generator,[0],[0]
"logP(yt |y1:t−1,X) (11)
We extend this architecture to multi-sentence texts in a way similar to Wiseman et al. (2017).",4.1 Encoder-Decoder Base Generator,[0],[0]
"We view the abstract as a single sequence, i.e., all sentences are concatenated.",4.1 Encoder-Decoder Base Generator,[0],[0]
"When training, we cut the abstracts in blocks of equal size and perform forward backward iterations for each block (this includes the back-propagation through the encoder).",4.1 Encoder-Decoder Base Generator,[0],[0]
"From one block iteration to the next, we initialise the decoder with the last state of the previous block.",4.1 Encoder-Decoder Base Generator,[0],[0]
The block size is a hyperparameter tuned experimentally on the development set.,4.1 Encoder-Decoder Base Generator,[0],[0]
The generation of the output sequence is conditioned on the previous words and the input.,4.2 Predicting Alignment Labels,[0],[0]
"However, when certain sequences are very common, the language modelling conditional probability will prevail over the input conditioning.",4.2 Predicting Alignment Labels,[0],[0]
"For instance, the phrase from 1914 in our running example is very common in contexts that talk about periods of marriage or club membership, and as a result, the language model will output this phrase often, even in cases where there are no supporting facts in the input.",4.2 Predicting Alignment Labels,[0],[0]
"The intuition behind multi-task training (Caruana, 1993) is that it will smooth the probabilities of frequent sequences when trying to simultaneously predict alignment labels.
",4.2 Predicting Alignment Labels,[0],[0]
"Using the set of alignments obtained by our content selection model, we associate each word in the training data with a binary label at indicating whether it aligns with some property in the input set.",4.2 Predicting Alignment Labels,[0],[0]
"Our auxiliary task is to predict at given the sequence of previously predicted words and input X :
P(at+1|y1:t ,X) =",4.2 Predicting Alignment Labels,[0],[0]
"sigmoid(g′(ht ,ct))",4.2 Predicting Alignment Labels,[0],[0]
"(12)
g′(ht ,ct) = va • tanh(Wc[ct ;ht ]) (13)
where va ∈ Rd and the other operands are as defined in Equation (7).",4.2 Predicting Alignment Labels,[0],[0]
"We optimise the following auxiliary objective function:
Laln =− |Y | ∑ t=1 logP(at |y1:t−1,X) (14)
and the combined multi-task objective is the weighted sum of both word prediction and alignment prediction losses:
LMT L = λLwNLL +(1−λ)Laln (15)
where λ controls how much model training will focus on each task.",4.2 Predicting Alignment Labels,[0],[0]
"As we will explain in Section 5, we can anneal this value during training in favour of one objective or the other.",4.2 Predicting Alignment Labels,[0],[0]
"Although the multi-task approach aims to smooth the target distribution, the training process is still driven by the imperfect target text.",4.3 Reinforcement Learning Training,[0],[0]
"In other words, at each time step t the algorithm feeds the previous word wt−1 of the target text and evaluates the prediction against the target wt .
",4.3 Reinforcement Learning Training,[0],[0]
"Alternatively, we propose a training approach based on reinforcement learning (Williams 1992) which allows us to define an objective function that does not fully rely on the target text but rather on a revised version of it.",4.3 Reinforcement Learning Training,[0],[0]
"In our case, the set of alignments obtained by our content selection model provides a revision for the target text.",4.3 Reinforcement Learning Training,[0],[0]
"The advantages of reinforcement learning are twofold: (a) it allows to exploit additional task-specific knowledge (Zhang and Lapata, 2017) during training, and (b) enables the exploration of other word sequences through sampling.",4.3 Reinforcement Learning Training,[0],[0]
"Our setting differs from previous applications of RL (Ranzato et al., 2016; Zhang and Lapata, 2017) in that the reward function is not computed on the target text but rather on its alignments with the input.
",4.3 Reinforcement Learning Training,[0],[0]
The encoder-decoder model is viewed as an agent whose action space is defined by the set of words in the target vocabulary.,4.3 Reinforcement Learning Training,[0],[0]
"At each time step, the encoder-decoder takes action ŷt with policy Pπ(ŷt |ŷ1:t−1,X) defined by the probability in Equation (6).",4.3 Reinforcement Learning Training,[0],[0]
"The agent terminates when it emits the End Of Sequence (EOS) token, at which point the sequence of all actions taken yields the output sequence Ŷ = (ŷ1, · · · , ŷ|Ŷ |).",4.3 Reinforcement Learning Training,[0],[0]
This sequence in our task is a short text describing the properties of a given entity.,4.3 Reinforcement Learning Training,[0],[0]
"After producing the sequence of actions Ŷ , the agent receives a reward r(Ŷ ) and the policy is updated according to this reward.
",4.3 Reinforcement Learning Training,[0],[0]
Reward Function,4.3 Reinforcement Learning Training,[0],[0]
"We define the reward function r(Ŷ ) on the alignment set A(X ,Y ).",4.3 Reinforcement Learning Training,[0],[0]
"If the output action sequence Ŷ is precise with respect to the set of alignments A(X ,Y ), the agent will receive a high reward.",4.3 Reinforcement Learning Training,[0],[0]
"Concretely, we define r(Ŷ ) as follows:
r(Ŷ ) = γpr rpr(Ŷ )",4.3 Reinforcement Learning Training,[0],[0]
"(16)
where γpr adjusts the reward value rpr which is the unigram precision of the predicted sequence Ŷ and the set of words in A(X ,Y ).
",4.3 Reinforcement Learning Training,[0],[0]
Training Algorithm,4.3 Reinforcement Learning Training,[0],[0]
"We use the REINFORCE algorithm (Williams, 1992) to learn an agent that maximises the reward function.",4.3 Reinforcement Learning Training,[0],[0]
"As this is a gradient descent method, the training loss of a sequence
is defined as the negative expected reward:
LRL =−E(ŷ1,··· ,ŷ|Ŷ |) ∼ Pπ(·|X)[r(ŷ1, · · · , ŷ|Ŷ |)]
where Pπ is the agent’s policy, i.e., the word distribution produced by the encoder-decoder model (Equation (6)) and r(·) is the reward function as defined in Equation (16).",4.3 Reinforcement Learning Training,[0],[0]
"The gradient of LRL is given by:
∇LRL ≈ |Ŷ | ∑ t=1 ∇ logPπ(ŷt",4.3 Reinforcement Learning Training,[0],[0]
"|ŷ1:t−1,X)[r(ŷ1:|Ŷ |)−bt ]
where bt is a baseline linear regression model used to reduce the variance of the gradients during training.",4.3 Reinforcement Learning Training,[0],[0]
bt predicts the future reward and is trained by minimizing mean squared error.,4.3 Reinforcement Learning Training,[0],[0]
"The input to this predictor is the agent hidden state ht , however we do not back-propagate the error to ht .",4.3 Reinforcement Learning Training,[0],[0]
"We refer the interested reader to Williams (1992) and Ranzato et al. (2016) for more details.
",4.3 Reinforcement Learning Training,[0],[0]
"Document Level Curriculum Learning Rather than starting from a state given by a random policy, we initialise the agent with a policy learnt by pretraining with the negative log-likelihood objective (Ranzato et al., 2016; Zhang and Lapata, 2017).",4.3 Reinforcement Learning Training,[0],[0]
The reinforcement learning objective is applied gradually in combination with the log-likelihood objective on each target block subsequence.,4.3 Reinforcement Learning Training,[0],[0]
Recall from Section 4.1 that our document is segmented into blocks of equal size during training which we denote as MAXBLOCK.,4.3 Reinforcement Learning Training,[0],[0]
"When training begins, only the last ℧ tokens are predicted by the agent while for the first (MAXBLOCK −℧) we still use the negative log-likelihood objective.",4.3 Reinforcement Learning Training,[0],[0]
The number of tokens ℧ predicted by the agent is incremented by ℧ units every 2 epochs.,4.3 Reinforcement Learning Training,[0],[0]
We set ℧ = 3 and the training ends when (MAXBLOCK−℧) = 0.,4.3 Reinforcement Learning Training,[0],[0]
"Since we evaluate the model’s predictions at the block level, the reward function is also evaluated at the block level.",4.3 Reinforcement Learning Training,[0],[0]
"Data We evaluated our model on a dataset collated from WIKIBIO (Lebret et al., 2016), a corpus of 728,321 biography articles (their first paragraph) and their infoboxes sampled from the English Wikipedia.",5 Experimental Setup,[0],[0]
We adapted the original dataset in three ways.,5 Experimental Setup,[0],[0]
"Firstly, we make use of the entire abstract rather than first sentence.",5 Experimental Setup,[0],[0]
"Secondly, we reduced the dataset to examples with a rich set of properties and multi-sentential text.",5 Experimental Setup,[0],[0]
"We eliminated examples with less than six property-value
pairs and abstracts consisting of one sentence.",5 Experimental Setup,[0],[0]
We also placed a minimum restriction of 23 words in the length of the abstract.,5 Experimental Setup,[0],[0]
We considered abstracts up to a maximum of 12 sentences and property sets with a maximum of 50 property-value pairs.,5 Experimental Setup,[0],[0]
"Finally, we associated each abstract with the set of DBPedia properties p : v corresponding to the abstract’s main entity.",5 Experimental Setup,[0],[0]
"As entity classification is available in DBPedia for most entities, we concatenate class information c (whenever available) with the property value, i.e., p : vc.",5 Experimental Setup,[0],[0]
"In Figure 1, the property value spouse : FrancesH.Flaherty is extended with class information from the DBPedia ontology to spouse : FrancesH.FlahertyPerson.
",5 Experimental Setup,[0],[0]
Pre-processing Numeric date formats were converted to a surface form with month names.,5 Experimental Setup,[0],[0]
Numerical expressions were delexicalised using different tokens created with the property name and position of the delexicalised token on the value sequence.,5 Experimental Setup,[0],[0]
"For instance, given the property-value for birth date in Figure (1a), the first sentence in the abstract (Figure (1b)) becomes “ Robert Joseph Flaherty, (February DLX birth date 2, DLX birth date 4 – July . . .",5 Experimental Setup,[0],[0]
”.,5 Experimental Setup,[0],[0]
Years and numbers in the text not found in the values of the property set were replaced with tokens YEAR and NUMERIC.2,5 Experimental Setup,[0],[0]
"In a second phase, when creating the input and output vocabularies, V I and V O respectively, we delexicalised words w which were absent from the output vocabulary but were attested in the input vocabulary.",5 Experimental Setup,[0],[0]
"Again, we created tokens based on the property name and the position of the word in the value sequence.",5 Experimental Setup,[0],[0]
Words not in V O or V I were replaced with the symbol UNK.,5 Experimental Setup,[0],[0]
Vocabulary sizes were limited to |V,5 Experimental Setup,[0],[0]
I | = 50k and |V O| = 50k for the alignment model and |V O| = 20k for the generator.,5 Experimental Setup,[0],[0]
We discarded examples where the text contained more than three UNKs (for the content aligner) and five UNKs (for the generator); or more than two UNKs in the property-value (for generation).,5 Experimental Setup,[0],[0]
"Finally, we added the empty relation to the property sets.
",5 Experimental Setup,[0],[0]
Table 2 summarises the dataset statistics for the generator.,5 Experimental Setup,[0],[0]
"We report the number of abstracts in the dataset (size), the average number of sentences and tokens in the abstracts, and the average number of properties and sentence length in tokens
2We exploit these tokens to further adjust the score of the reward function given by Equation (16).",5 Experimental Setup,[0],[0]
"Each time the predicted output contains some of these symbols we decrease the reward score by κ which we empirically set to 0.025 .
",5 Experimental Setup,[0],[0]
(sent.len).,5 Experimental Setup,[0],[0]
"For the content aligner (cf. Section 3), each sentence constitutes a training instance, and as a result the sizes of the train and development sets are 796,446 and 153,096, respectively.
",5 Experimental Setup,[0],[0]
Training Configuration,5 Experimental Setup,[0],[0]
We adjusted all models’ hyperparameters according to their performance on the development set.,5 Experimental Setup,[0],[0]
"The encoders for both content selection and generation models were initialised with GloVe (Pennington et al., 2014) pre-trained vectors.",5 Experimental Setup,[0],[0]
The input and hidden unit dimension was set to 200 for content selection and 100 for generation.,5 Experimental Setup,[0],[0]
"In all models, we used encoder biLSTMs and decoder LSTM (regularised with a dropout rate of 0.3 (Zaremba et al., 2014)) with one layer.",5 Experimental Setup,[0],[0]
"Content selection and generation models (base encoder-decoder and MTL) were trained for 20 epochs with the ADAM optimiser (Kingma and Ba, 2014) using a learning rate of 0.001.",5 Experimental Setup,[0],[0]
The reinforcement learning model was initialised with the base encoder-decoder model and trained for 35 additional epochs with stochastic gradient descent and a fixed learning rate of 0.001.,5 Experimental Setup,[0],[0]
"Block sizes were set to 40 (base), 60 (MTL) and 50 (RL).",5 Experimental Setup,[0],[0]
"Weights for the MTL objective were also tuned experimentally; we set λ = 0.1 for the first four epochs (training focuses on alignment prediction) and switched to λ = 0.9 for the remaining epochs.
",5 Experimental Setup,[0],[0]
Content Alignment We optimized content alignment on the development set against manual alignments.,5 Experimental Setup,[0],[0]
"Specifically, two annotators aligned 132 sentences to their infoboxes.",5 Experimental Setup,[0],[0]
"We used the Yawat annotation tool (Germann, 2008) and followed the alignment guidelines (and evaluation metrics) used in Cohn et al. (2008).",5 Experimental Setup,[0],[0]
"The inter-annotator agreement using macro-averaged f-score was 0.72 (we treated one annotator as the reference and the other one as hypothetical system output).
",5 Experimental Setup,[0],[0]
"Alignment sets were extracted from the model’s output (cf. Section 3) by optimizing the threshold avg(sim) + a ∗ std(sim) where sim denotes the similarity between the set of property values and words, and a is empirically set to 0.75; avg
and std are the mean and standard deviation of sim scores across the development set.",5 Experimental Setup,[0],[0]
Each word was aligned to a property-value if their similarity exceeded a threshold of 0.22.,5 Experimental Setup,[0],[0]
"Our best content alignment model (Content-Aligner) obtained an fscore of 0.36 on the development set.
",5 Experimental Setup,[0],[0]
We also compared our Content-Aligner against a baseline based on pre-trained word embeddings (EmbeddingsBL).,5 Experimental Setup,[0],[0]
"For each pair (P ,s) we computed the dot product between words in s and properties in P (properties were represented by the the averaged sum of their words’ vectors).",5 Experimental Setup,[0],[0]
Words were aligned to property-values if their similarity exceeded a threshold of 0.4.,5 Experimental Setup,[0],[0]
EmbeddingsBL,5 Experimental Setup,[0],[0]
obtained an f-score of 0.057 against the manual alignments.,5 Experimental Setup,[0],[0]
"Finally, we compared the performance of the Content-Aligner at the level of property set P and sentence s similarity by comparing the average ranking position of correct pairs among 14 distractors, namely rank@15.",5 Experimental Setup,[0],[0]
"The Content-Aligner obtained a rank of 1.31, while the EmbeddingsBL model had a rank of 7.99 (lower is better).",5 Experimental Setup,[0],[0]
"We compared the performance of an encoderdecoder model trained with the standard negative log-likelihood method (ED), against a model trained with multi-task learning (EDMTL) and reinforcement learning (EDRL).",6 Results,[0],[0]
"We also included a template baseline system (Templ) in our evaluation experiments.
",6 Results,[0],[0]
The template generator used hand-written rules to realise property-value pairs.,6 Results,[0],[0]
"As an approximation for content selection, we obtained the 50 more frequent property names from the training set and manually defined content ordering rules with the following criteria.",6 Results,[0],[0]
"We ordered personal life properties (e.g., birth date or occupation) based on their most common order of mention in the Wikipedia abstracts.",6 Results,[0],[0]
"Profession dependent properties (e.g., position or genre), were assigned an equal ordering but posterior to the personal properties.",6 Results,[0],[0]
We manually lexicalised properties into single sentence templates to be concatenated to produce the final text.,6 Results,[0],[0]
The template for the property position and example verbalisation for the property-value position : de f ender of the entity zanetti are “[NAME] played as [POSITION].”,6 Results,[0],[0]
and “ Zanetti played as defender.”,6 Results,[0],[0]
"respectively.
",6 Results,[0],[0]
"Automatic Evaluation Table 3 shows the results of automatic evaluation using BLEU-4
(Papineni et al., 2002) against the noisy Wikipedia abstracts.",6 Results,[0],[0]
"Considering these as a gold standard is, however, not entirely satisfactory for two reasons.",6 Results,[0],[0]
"Firstly, our models generate considerably shorter text and will be penalized for not generating text they were not supposed to generate in the first place.",6 Results,[0],[0]
"Secondly, the model might try to reproduce what is in the imperfect reference but not supported by the input properties and as a result will be rewarded when it should not.",6 Results,[0],[0]
"To alleviate this, we crowd-sourced using AMT a revised version of 200 randomly selected abstracts from the test set.
",6 Results,[0],[0]
Crowdworkers were shown a Wikipedia infobox with the accompanying abstract and were asked to adjust the text to the content present in the infobox.,6 Results,[0],[0]
Annotators were instructed to delete spans which did not have supporting facts and rewrite the remaining parts into a well-formed text.,6 Results,[0],[0]
We collected three revised versions for each abstract.,6 Results,[0],[0]
"Inter-annotator agreement was 81.64 measured as the mean pairwise BLEU-4 amongst AMT workers.
",6 Results,[0],[0]
Automatic evaluation results against the revised abstracts are also shown in Table 3.,6 Results,[0],[0]
"As can be seen, all encoder-decoder based models have a significant advantage over Templ when evaluating against both types of abstracts.",6 Results,[0],[0]
The model enabled with the multi-task learning content selection mechanism brings an improvement of 1.29 BLEU-4 over a vanilla encoder-decoder model.,6 Results,[0],[0]
Performance of the RL trained model is inferior and close to the ED model.,6 Results,[0],[0]
"We discuss the reasons for this discrepancy shortly.
",6 Results,[0],[0]
"To provide a rough comparison with the results reported in Lebret et al. (2016), we also computed BLEU-4 on the first sentence of the text generated by our system.3 Recall that their model generates the first sentence of the abstract, whereas we out-
3We post-processed system output with Stanford CoreNLP",6 Results,[0],[0]
"(Manning et al., 2014) to extract the first sentence.
put multi-sentence text.",6 Results,[0],[0]
"Using the first sentence in the Wikipedia abstract as reference, we obtained a score of 37.29% (ED), 38.42% (EDMTL) and 38.1% (EDRL) which compare favourably with their best performing model (34.7%±0.36).
",6 Results,[0],[0]
Human-Based Evaluation,6 Results,[0],[0]
We further examined differences among systems in a human-based evaluation study.,6 Results,[0],[0]
"Using AMT, we elicited 3 judgements for the same 200 infobox-abstract pairs we used in the abstract revision study.",6 Results,[0],[0]
"We compared the output of the templates, the three neural generators and also included one of the human edited abstracts as a gold standard (reference).",6 Results,[0],[0]
"For each test case, we showed crowdworkers the Wikipedia infobox and five short texts in random order.",6 Results,[0],[0]
The annotators were asked to rank each of the texts according to the following criteria: (1) Is the text faithful to the content of the table?,6 Results,[0],[0]
and (2) Is the text overall comprehensible and fluent?,6 Results,[0],[0]
Ties were allowed only when texts were identical strings.,6 Results,[0],[0]
"Table 5 presents examples of the texts (and properties) crowdworkers saw.
",6 Results,[0],[0]
"Table 4 shows, proportionally, how often crowdworkers ranked each system, first, second, and so on.",6 Results,[0],[0]
"Unsurprisingly, the human authored gold text is considered best (and ranked first 47% of the time).",6 Results,[0],[0]
"EDMTL is mostly ranked second and third best, followed closely by EDRL.",6 Results,[0],[0]
The vanilla encoder-decoder system ED is mostly forth and Templ is fifth.,6 Results,[0],[0]
"As shown in the last column of the table (Rank), the ranking of EDMTL is overall slightly better than EDRL.",6 Results,[0],[0]
We further converted the ranks to ratings on a scale of 1 to 5 (assigning ratings 5. .,6 Results,[0],[0]
.1,6 Results,[0],[0]
to rank placements 1. .,6 Results,[0],[0]
.5),6 Results,[0],[0]
.,6 Results,[0],[0]
This allowed us to perform Analysis of Variance (ANOVA) which revealed a reliable effect of system type.,6 Results,[0],[0]
Post-hoc Tukey tests showed that all systems were significantly worse than RevAbs and significantly better than Templ (p < 0.05).,6 Results,[0],[0]
"EDMTL is not significantly better than EDRL but is significantly (p < 0.05) different from ED.
",6 Results,[0],[0]
Discussion,6 Results,[0],[0]
"The texts generated by EDRL are shorter compared to the other two neural systems
which might affect BLEU-4 scores and also the ratings provided by the annotators.",6 Results,[0],[0]
"As shown in Table 5 (entity dorsey burnette), EDRL drops information pertaining to dates or chooses to just verbalise birth place information.",6 Results,[0],[0]
"In some cases, this is preferable to hallucinating incorrect facts; however, in other cases outputs with more information are rated more favourably.",6 Results,[0],[0]
"Overall, EDMTL seems to be more detail oriented and faithful to the facts included in the infobox (see dorsey burnette, aaron moores, or kirill moryganov).",6 Results,[0],[0]
"The template system manages in some specific configurations to verbalise appropriate facts (indrani bose), however, it often fails to verbalise infrequent properties (aaron moores) or focuses on properties which are very frequent in the knowledge base but are rarely found in the abstracts (kirill moryganov).",6 Results,[0],[0]
"In this paper we focused on the task of bootstrapping generators from large-scale datasets consisting of DBPedia facts and related Wikipedia biog-
raphy abstracts.",7 Conclusions,[0],[0]
"We proposed to equip standard encoder-decoder models with an additional content selection mechanism based on multi-instance learning and developed two training regimes, one based on multi-task learning and the other on reinforcement learning.",7 Conclusions,[0],[0]
"Overall, we find that the proposed content selection mechanism improves the accuracy and fluency of the generated texts.",7 Conclusions,[0],[0]
"In the future, it would be interesting to investigate a more sophisticated representation of the input (Vinyals et al., 2016).",7 Conclusions,[0],[0]
"It would also make sense for the model to decode hierarchically, taking sequences of words and sentences into account (Zhang and Lapata, 2014; Lebret et al., 2015).",7 Conclusions,[0],[0]
We thank the NAACL reviewers for their constructive feedback.,Acknowledgments,[0],[0]
"We also thank Xingxing Zhang, Li Dong and Stefanos Angelidis for useful discussions about implementation details.",Acknowledgments,[0],[0]
We gratefully acknowledge the financial support of the European Research Council (award number 681760).,Acknowledgments,[0],[0]
"A core step in statistical data-to-text generation concerns learning correspondences between structured data representations (e.g., facts in a database) and associated texts.",abstractText,[0],[0]
"In this paper we aim to bootstrap generators from large scale datasets where the data (e.g., DBPedia facts) and related texts (e.g., Wikipedia abstracts) are loosely aligned.",abstractText,[0],[0]
We tackle this challenging task by introducing a special-purpose content selection mechanism.1,abstractText,[0],[0]
We use multi-instance learning to automatically discover correspondences between data and text pairs and show how these can be used to enhance the content signal while training an encoder-decoder architecture.,abstractText,[0],[0]
Experimental results demonstrate that models trained with content-specific objectives improve upon a vanilla encoder-decoder which solely relies on soft attention.,abstractText,[0],[0]
Bootstrapping Generators from Noisy Data,title,[0],[0]
"Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1084–1093, Baltimore, Maryland, USA, June 23-25 2014. c©2014 Association for Computational Linguistics
This approach learns role assignment in filler-gap constructions in a manner consistent with current developmental findings and is extremely robust to initialization variance. Additionally, this model is shown to be able to account for a characteristic error made by learners during this period (A and B gorped interpreted as A gorped B).",text,[0],[0]
"The phenomenon of filler-gap, where the argument of a predicate appears outside its canonical position in the phrase structure (e.g. [the apple]i that the boy ate ti or [what]i did the boy eat ti), has long been an object of study for syntacticians (Ross, 1967) due to its apparent processing complexity.",1 Introduction,[0],[0]
"Such complexity is due, in part, to the arbitrary length of the dependency between a filler and its gap (e.g. [the apple]i that Mary said the boy ate ti).
",1 Introduction,[0],[0]
"Recent studies indicate that comprehension of filler-gap constructions begins around 15 months (Seidl et al., 2003; Gagliardi et al., 2014).",1 Introduction,[0],[0]
"This finding raises the question of how such a complex phenomenon could be acquired so early since children at that age do not yet have a very advanced grasp of language (e.g. ditransitives do not seem to be generalized until at least 31 months; Goldberg et al. 2004, Bello 2012).",1 Introduction,[0],[0]
"This work shows that filler-gap comprehension in English may be
acquired through learning word orderings rather than relying on hierarchical syntactic knowledge.
",1 Introduction,[0],[0]
This work describes a cognitive model of the developmental timecourse of filler-gap comprehension with the goal of setting a lower bound on the modeling assumptions necessary for an ideal learner to display filler-gap comprehension.,1 Introduction,[0],[0]
"In particular, the model described in this paper takes chunked child-directed speech as input and learns orderings over semantic roles.",1 Introduction,[0],[0]
"These orderings then permit the model to successfully resolve filler-gap dependencies.1 Further, the model presented here is also shown to initially reflect an idiosyncratic role assignment error observed in development (e.g. A and B kradded interpreted as A kradded B ; Gertner and Fisher, 2012), though after training, the model is able to avoid the error.",1 Introduction,[0],[0]
"As such, this work may be said to model a learner from 15 months to between 25 and 30 months.
",1 Introduction,[0],[0]
"1This model does not explicitly learn gap positions, but rather assigns thematic roles to arguments based on where those arguments are expected to manifest.",1 Introduction,[0],[0]
"This approach to filler-gap comprehension is supported by findings that show people do not actually link fillers to gap positions but instead link the filler to a verb with missing arguments (Pickering and Barry, 1991)
1084",1 Introduction,[0],[0]
The developmental timeline during which children acquire the ability to process filler-gap constructions is not well-understood.,2 Background,[0],[0]
"Language comprehension precedes production, and the developmental literature on the acquisition of filler-gap constructions is sparsely populated due to difficulties in designing experiments to test filler-gap comprehension in preverbal infants.",2 Background,[0],[0]
"Older studies typically looked at verbal children and the mistakes they make to gain insight into the acquisition process (de Villiers and Roeper, 1995).
",2 Background,[0],[0]
"Recent studies, however, indicate that fillergap comprehension likely begins earlier than production (Seidl et al., 2003; Gagliardi and Lidz, 2010; Gagliardi et al., 2014).",2 Background,[0],[0]
"Therefore, studies of verbal children are probably actually testing the acquisition of production mechanisms (planning, motor skills, greater facility with lexical access, etc) rather than the acquisition of fillergap.",2 Background,[0],[0]
"Note that these may be related since fillergap could introduce greater processing load which could overwhelm the child’s fragile production capacity (Phillips, 2010).
",2 Background,[0],[0]
Seidl et al. (2003) showed that children are able to process wh-extractions from subject position (e.g. [who]i ti ate pie) as young as 15 months while similar extractions from object position (e.g. [what]i did the boy eat ti) remain unparseable until around 20 months of age.2 This line of investigation has been reopened and expanded by Gagliardi et al. (2014) whose results suggest that the experimental methodology employed by Seidl et al. (2003) was flawed in that it presumed infants have ideal performance mechanisms.,2 Background,[0],[0]
"By providing more trials of each condition and controlling for the pragmatic felicity of test statements, Gagliardi et al. (2014) provide evidence that 15-month old infants can process wh-extractions from both subject and object positions.",2 Background,[0],[0]
"Object extractions are more difficult to comprehend than subject extractions, however, perhaps due to additional processing load in object extractions (Gibson, 1998; Phillips, 2010).",2 Background,[0],[0]
"Similarly, Gagliardi and Lidz (2010) show that relativized extractions with a wh-relativizer (e.g. find [the boy]i who ti ate the apple) are easier to comprehend than relativized extractions with that as the relativizer (e.g. find [the boy]i that ti ate the apple).
",2 Background,[0],[0]
Yuan et al. (2012) demonstrate that 19-month olds use their knowledge of nouns to learn both verbs and their associated argument structure.,2 Background,[0],[0]
"In
2Since the wh-phrase is in the same (or a very similar) position as the original subject when the wh-phrase takes subject position, it is not clear that these constructions are true extractions (Culicover, 2013), however, this paper will continue to refer to them as such for ease of exposition.
",2 Background,[0],[0]
"their study, infants were shown video of a person talking on a phone using a nonce verb with either one or two nouns (e.g. Mary kradded Susan).",2 Background,[0],[0]
"Under the assumption that infants look longer at things that correspond to their understanding of a prompt, the infants were then shown two images that potentially depicted the described action – one picture where two actors acted independently (reflecting an intransitive proposition) and one picture where one actor acted on the other (reflecting a transitive proposition).3 Even though the infants had no extralinguistic knowledge about the verb, they consistently treated the verb as transitive if two nouns were present and intransitive if only one noun was present.
",2 Background,[0],[0]
"Similarly, Gertner and Fisher (2012) show that intransitive phrases with conjoined subjects (e.g. John and Mary gorped) are given a transitive interpretation (i.e. John gorped Mary) at 21 months (henceforth termed ‘1-1 role bias’), though this effect is no longer present at 25 months (Naigles, 1990).",2 Background,[0],[0]
This finding suggests both that learners will ignore canonical structure in favor of using all possible arguments and that children have a bias to assign a unique semantic role to each argument.,2 Background,[0],[0]
"It is important to note, however, that crosslinguistically children do not seem to generalize beyond two arguments until after at least 31 months of age (Goldberg et al., 2004; Bello, 2012), so a predicate occurring with three nouns would still likely be interpreted as merely transitive rather than ditransitive.
",2 Background,[0],[0]
"Computational modeling provides a way to test the computational level of processing (Marr, 1982).",2 Background,[0],[0]
"That is, given the input (child-directed speech, adult-directed speech, and environmental experiences), it is possible to probe the computational processes that result in the observed output.",2 Background,[0],[0]
"However, previous computational models of grammar induction (Klein and Manning, 2004), including infant grammar induction (Kwiatkowski et al., 2012), have not addressed filler-gap comprehension.4
The closest work to that presented here is the work on BabySRL (Connor et al., 2008; Connor et al., 2009; Connor et al., 2010).",2 Background,[0],[0]
BabySRL is a computational model of semantic role acquistion using a similar set of assumptions to the current work.,2 Background,[0],[0]
"BabySRL learns weights over ordering constraints (e.g. preverbal, second noun, etc.) to acquire semantic role labelling while still exhibiting 1-1 role bias.",2 Background,[0],[0]
"However, no analysis has evaluated the abil-
3There were two actors in each image to avoid biasing the infants to look at the image with more actors.
",2 Background,[0],[0]
"4As one reviewer notes, Joshi et al. (1990) and subsequent work show that filler-gap phenomena can be formally captured by mildly context-sensitive grammar formalisms; these have the virtue of scaling up to adult grammar, but due to their complexity, do not seem to have been described as models of early acquisition.
",2 Background,[0],[0]
ity of BabySRL to acquire filler-gap constructions.,2 Background,[0],[0]
Further comparison to BabySRL may be found in Section 6.,2 Background,[0],[0]
The present work restricts itself to acquiring fillergap comprehension in English.,3 Assumptions,[0],[0]
"The model presented here learns a single, non-recursive ordering for the semantic roles in each sentence relative to the verb since several studies have suggested that early child grammars may consist of simple linear grammars that are dictated by semantic roles (Diessel and Tomasello, 2001; Jackendoff and Wittenberg, in press).",3 Assumptions,[0],[0]
"This work assumes learners can already identify nouns and verbs, which is supported by Shi et al. (1999) who show that children at an extremely young age can distinguish between content and function words and by Waxman and Booth (2001) who show that children can distinguish between different types of content words.",3 Assumptions,[0],[0]
"Further, since Waxman and Booth (2001) demonstrate that, by 14 months, children are able to distinguish nouns from modifiers, this work assumes learners can already chunk nouns and access the nominal head.",3 Assumptions,[0],[0]
"To handle recursion, this work assumes that children treat the final verb in each sentence as the main verb (implicitly assuming sentence segmentation), which ideally assigns roles to each of the nouns in the sentence.
",3 Assumptions,[0],[0]
"Due to the findings of Yuan et al. (2012), this work adopts a ‘syntactic bootstrapping’ theory of acquisition (Gleitman, 1990), where structural properties (e.g. number of nouns) inform the learner about semantic properties of a predicate (e.g. how many semantic roles it confers).",3 Assumptions,[0],[0]
"Since infants infer the number of semantic roles, this work further assumes they already have expectations about where these roles tend to be realized in sentences, if they appear.",3 Assumptions,[0],[0]
"These positions may correspond to different semantic roles for different predicates (e.g. the subject of run and of melt); however, the role for predicates with a single argument is usually assigned to the noun that precedes the verb while a second argument is usually assigned after the verb.",3 Assumptions,[0],[0]
"The semantic properties of these roles may be learned lexically for each predicate, but that is beyond the scope of this work.",3 Assumptions,[0],[0]
"Therefore, this work uses syntactic and semantic roles interchangeably (e.g. subject and agent).
",3 Assumptions,[0],[0]
"Finally, following the finding by Gertner and Fisher (2012) that children interpret intransitives with conjoined subjects as transitives, this work assumes that semantic roles have a one-to-one correspondence with nouns in a sentence (similarly used as a soft constraint in the semantic role labelling work of Titov and Klementiev, 2012).",3 Assumptions,[0],[0]
The model represents the preferred locations of semantic roles relative to the verb as distributions over real numbers.,4 Model,[0],[0]
"This idea is adapted from Boersma (1997) who uses it to learn constraint rankings in optimality theory.
",4 Model,[0],[0]
"In this work, the final (main) verb is placed at position 0; words (and chunks) before the verb are given progressively more negative positions, and words after the verb are given progressively more positive positions (see Table 1).",4 Model,[0],[0]
"Learner expectations of where an argument will appear relative to the verb are modelled as two-component Gaussian mixtures: one mixture of Gaussians (GS·) corresponds to the subject argument, another (GO·) corresponds to the object argument.",4 Model,[0],[0]
"There is no mixture for a third argument since children do not generalize beyond two arguments until later in development (Goldberg et al., 2004; Bello, 2012).
",4 Model,[0],[0]
"One component of each mixture learns to represent the canonical position for the argument (G·C) while the other (G·N ) represents some alternate, non-canonical position such as the filler position in filler-gap constructions.",4 Model,[0],[0]
"To reflect the fact that learners have had 15 months of exposure to their language before acquiring filler-gap, the mixture is initialized so that there is a stronger probability associated with the canonical Gaussian than with the non-canonical Gaussian of each mixture.5 Finally, the one-to-one role bias is explicitly encoded such that the model cannot use a label that has already been used elsewhere in the sentence.
",4 Model,[0],[0]
"5Akhtar (1999) finds that learners may not have strong expectations of canonical argument positions until four years of age, but the results of the current study are extremely robust to changes in initialization, as discussed in Section 7 of this paper, so this assumption is mostly adopted for ease of exposition.
",4 Model,[0],[0]
"Thus, the initial model conditions (see Figure 2) are most likely to realize an SVO ordering, although it is possible to obtain SOV (by sampling a negative number from the blue curve) or even OSV (by also sampling the red curve very close to 0).",4 Model,[0],[0]
"The model is most likely to hypothesize a preverbal object when it has already assigned the subject role to something and, in addition, there is no postverbal noun competing for the object label.",4 Model,[0],[0]
"In other words, the model infers that an object extraction may have occurred if there is a ‘missing’ postverbal argument.
",4 Model,[0],[0]
"Finally, the probability of a given sequence is the product of the label probabilities for the component argument positions (e.g. GSC generating an argument at position -2, etc).",4 Model,[0],[0]
"Since many sentences have more than two nouns, the model is allowed to skip nouns by multiplying a penalty term (Φ) into the product for each skipped noun; the cost is set at 0.00001 for this study, though see Section 7 for a discussion of the constraints on this parameter.",4 Model,[0],[0]
"See Table 2 for initialization parameters and Figure 2 for a visual representation of the initial expectations of the model.
",4 Model,[0],[0]
This work uses a model with 2-component mixtures for both subjects and objects (termed the symmetric model).,4 Model,[0],[0]
"This formulation achieves the best fit to the training data according to the Bayesian Information Criterion (BIC).6 However, follow-up experiments find that the non-canonical subject Gaussian only improves the likelihood of the data by erroneously modeling postverbal nouns in imperative statements.",4 Model,[0],[0]
"The lack of a canonical subject in English imperatives allows the model to improve the likelihood of the data by using the non-canonical subject Gaussian to capture ficti-
6The BIC rewards improved log-likelihood but penalizes increased model complexity.
tious postverbal arguments.",4 Model,[0],[0]
"When imperatives are filtered out of the training corpus, the symmetric model obtains a worse BIC fit than a model that lacks the non-canonical subject Gaussian.",4 Model,[0],[0]
"Therefore, if one makes the assumption that imperatives are prosodically-marked for learners (e.g. the learner is the implicit subject), the best model is one that lacks a non-canonical subject.7",4 Model,[0],[0]
"The remainder of this paper assumes a symmetric model to demonstrate what happens if such an assumption is not made; for the evaluations described in this paper, the results are similar in either case.
",4 Model,[0],[0]
"This model differs from other non-recursive computational models of grammar induction (e.g. Goldwater and Griffiths, 2007) since it is not based on Hidden Markov Models.",4 Model,[0],[0]
"Instead, it determines the best ordering for the sentence as a whole.",4 Model,[0],[0]
"This approach bears some similarity to a Generalized Mallows model (Chen et al., 2009), but the current formulation was chosen due to being independently posited as cognitively plausible (Boersma, 1997).
",4 Model,[0],[0]
"Figure 2 (Right) shows the converged, final state of the model.",4 Model,[0],[0]
"The model expects the first argument (usually agent) to be assigned preverbally and expects the second (say, patient) to be assigned postverbally; however, there is now a larger chance that the second argument will appear preverbally.",4 Model,[0],[0]
"The model in this work is trained using transcribed child-directed speech (CDS) from the BabySRL portions (Connor et al., 2008) of CHILDES (MacWhinney, 2000).",5 Evaluation,[0],[0]
"Chunking is performed us-
7This finding suggests that a Dirichlet Process or other means of dynamically determining the number of components in each mixture would converge to a model that lacks non-canonical subjects if imperative filtering were employed.
ing a basic noun-chunker from NLTK (Bird et al., 2009).",5 Evaluation,[0],[0]
"Based on an initial analysis of chunker performance, yes is hand-corrected to not be a noun.",5 Evaluation,[0],[0]
"Poor chunker perfomance is likely due to a mismatch in chunker training and testing domains (Wall Street Journal text vs transcribed speech), but chunking noise may be a good estimation of learner uncertainty, so the remaining text is left uncorrected.",5 Evaluation,[0],[0]
"All noun phrase chunks are then replaced with their final noun (presumed the head) to approximate the ability of children to distinguish nouns from modifiers (Waxman and Booth, 2001).",5 Evaluation,[0],[0]
"Finally, for each sentence, the model assigns sentence positions to each word with the final verb at zero.
",5 Evaluation,[0],[0]
Viterbi Expectation-Maximization is performed over each sentence in the corpus to infer the parameters of the model.,5 Evaluation,[0],[0]
"During the Expectation step, the model uses the current Gaussian parameters to label the nouns in each sentence with argument roles.",5 Evaluation,[0],[0]
"Since the model is not lexicalized, these roles correspond to the semantic roles most commonly associated with subject and object.",5 Evaluation,[0],[0]
"The model then chooses the best label sequence for each sentence.
",5 Evaluation,[0],[0]
These newly labelled sentences are used during the Maximization step to determine the Gaussian parameters that maximize the likelihood of that labelling.,5 Evaluation,[0],[0]
The mean of each Gaussian is updated to the mean position of the words it labels.,5 Evaluation,[0],[0]
"Similarly, the standard deviation of each Gaussian is updated with the standard deviation of the positions it labels.",5 Evaluation,[0],[0]
A learning rate of 0.3 is used to prevent large parameter jumps.,5 Evaluation,[0],[0]
"The prior probability of each Gaussian is updated as the ratio of that Gaussian’s labellings to the total number of labellings from that mixture in the corpus:
πρθ = | Gρθ | | Gρ· | (1)
where ρ ∈ {S,O} and θ ∈ {C,N}.",5 Evaluation,[0],[0]
"Best results seem to be obtained when the skippenalty is loosened by an order of magnitude dur-
ing testing.",5 Evaluation,[0],[0]
"Essentially, this forces the model to tightly adhere to the perceived argument structure during training to learn more rigid parameters, but the model is allowed more leeway to skip arguments it has less confidence in during testing.",5 Evaluation,[0],[0]
"Convergence (see Figure 2) tends to occur after four iterations but can take up to ten iterations depending on the initial parameters.
",5 Evaluation,[0],[0]
"Since the model is unsupervised, it is trained on a given corpus (e.g. Eve) before being tested on the role annotations of that same corpus.",5 Evaluation,[0],[0]
"The Eve corpus was used for development purposes,8 and the Adam data was used only for testing.
",5 Evaluation,[0],[0]
"For testing, this study uses the semantic role annotations in the BabySRL corpus.",5 Evaluation,[0],[0]
"These annotations were obtained by automatically semantic role labelling portions of CHILDES with the system of Punyakanok et al. (2008) before roughly hand-correcting them (Connor et al., 2008).",5 Evaluation,[0],[0]
"The BabySRL corpus is annotated with 5 different roles, but the model described in this paper only uses 2 roles.",5 Evaluation,[0],[0]
"Therefore, overall accuracy results (see Table 3) are presented both for the raw BabySRL corpus and for a collapsed BabySRL corpus where all non-agent roles are collapsed into a single role (denoted by a subscript c in all tables).
",5 Evaluation,[0],[0]
"Since children do not generalize above two arguments during the modelled age range (Goldberg et al., 2004; Bello, 2012), the collapsed numbers more closely reflect the performance of a learner at this age than the raw numbers.",5 Evaluation,[0],[0]
The increase in accuracy obtained from collapsing non-agent arguments indicates that children may initially generalize incorrectly to some verbs and would need to learn lexically-specific role assignments (e.g. double-object constructions of give).,5 Evaluation,[0],[0]
"Since the current work is interested in general filler-gap comprehension at this age, including over unknown verbs, the remaining analyses in this paper con-
8This is included for transparency, though the initial parameters have very little bearing on the final results as stated in Section 7, so the danger of overfitting to development data is very slight.
sider performance when non-agent arguments are collapsed.9
Next, a filler-gap version of the BabySRL corpus is created using a coarse filtering process: the new corpus is comprised of all sentences where an associated object precedes the final verb and all sentences where the relevant subject is not immediately followed by the final verb (see Table 4).",5 Evaluation,[0],[0]
"For these filler-gap evaluations, the model is trained on the full version of the corpus in question (e.g. Eve) before being tested on the filler-gap subset of that corpus.",5 Evaluation,[0],[0]
"The overall results of the filler-gap evaluation (see Table 4) indicate that the model improves significantly at parsing filler-gap constructions after training.
",5 Evaluation,[0],[0]
"The performance of the model on roleassignment in filler-gap constructions may be analyzed further in terms of how the model performs on subject-extractions compared with object-extractions and in terms of how the model performs on that-relatives compared with whrelatives (see Table 5).
",5 Evaluation,[0],[0]
The model actually performs worse at subjectextractions after training than before training.,5 Evaluation,[0],[0]
"This is unsurprising because, prior to training, subjects have little-to-no competition for preverbal role assignments; after training, there is a preverbal extracted object category, which the model can erroneously use.",5 Evaluation,[0],[0]
"This slight, though significant in Eve, deficit is counter-balanced by a very substantial and significant improvement in objectextraction labelling accuracy.
",5 Evaluation,[0],[0]
"Similarly, training confers a large and significant improvement for role assignment in wh-relative constructions, but it yields less of an improvement for that-relative constructions.",5 Evaluation,[0],[0]
"This difference mimics a finding observed in the developmental literature where children seem slower to acquire comprehension of that-relatives than of whrelatives (Gagliardi and Lidz, 2010).
9Though performance is slightly worse when arguments are not collapsed, all the same patterns emerge.",5 Evaluation,[0],[0]
"The acquisition of semantic role labelling (SRL) by the BabySRL model (Connor et al., 2008; Connor et al., 2009; Connor et al., 2010) bears many similarities to the current work and is, to our knowledge, the only comparable line of inquiry to the current one.",6 Comparison to BabySRL,[0],[0]
"The primary function of BabySRL is to model the acquisition of semantic role labelling while making an idiosyncratic error which infants also make (Gertner and Fisher, 2012), the 1-1 role bias error (John and Mary gorped interpreted as John gorped Mary).",6 Comparison to BabySRL,[0],[0]
"Similar to the model presented in this paper, BabySRL is based on simple ordering features such as argument position relative to the verb and argument position relative to the other arguments.
",6 Comparison to BabySRL,[0],[0]
"This section will demonstrate that the model in this paper initially reflects 1-1 role bias comparably to BabySRL, though it progresses beyond this bias after training.10 Further, the model in this paper is able to reflect the concurrent acquisition of fillergap whereas BabySRL does not seem well-suited to such a task.",6 Comparison to BabySRL,[0],[0]
"Finally, BabySRL performs undesirably in intransitive settings whereas the model in this paper does not.
",6 Comparison to BabySRL,[0],[0]
"Connor et al. (2008) demonstrate that a supervised perceptron classifier, based on positional features and trained on the silver role label annotations of the BabySRL corpus, manifests 1-1 role bias errors.",6 Comparison to BabySRL,[0],[0]
"Follow-up studies show that supervision may be lessened (Connor et al., 2009) or removed (Connor et al., 2010) and BabySRL will still reflect a substantial 1-1 role bias.
",6 Comparison to BabySRL,[0],[0]
Connor et al. (2008) and Connor et al. (2009) run direct analyses of how frequently their models make 1-1 role bias errors.,6 Comparison to BabySRL,[0],[0]
"A comparable evaluation may be run on the current model by generating 1000 sentences with a structure of NNV and reporting how many times the model chooses a subject-first labelling (see Table 6).11
10All evaluations in this section are preceded by training on the chunked Eve corpus.
",6 Comparison to BabySRL,[0],[0]
"11While Table 6 analyzes erroneous labellings of NNV structure, the ‘Obj’ column of Table 5 (Left)
",6 Comparison to BabySRL,[0],[0]
The results of Connor et al. (2008) and Connor et al. (2009) depend on whether BabySRL uses argument-argument relative position as a feature or argument-verb relative position as a feature (there is no combined model).,6 Comparison to BabySRL,[0],[0]
"Further, the model presented here from Connor et al. (2009) has a unique argument constraint, similar to the model in this paper, in order to make comparison as direct as possible.
",6 Comparison to BabySRL,[0],[0]
"The 1-1 role bias error rate (before training) of the model presented in this paper is comparable to that of Connor et al. (2008) and Connor et al. (2009), which shows that the current model provides comparable developmental modeling benefits to the BabySRL models.",6 Comparison to BabySRL,[0],[0]
"Further, similar to real children (see Figure 1) the model presented in this paper develops beyond this error by the end of its training,12 whereas the BabySRL models still make this error after training.
",6 Comparison to BabySRL,[0],[0]
Connor et al. (2010) look at how frequently their model correctly labels the agent in transitive and intransitive sentences with unknown verbs (to demonstrate that it exhibits an agent-first bias).,6 Comparison to BabySRL,[0],[0]
"This evaluation can be replicated for the current study by generating 1,000 sentences with the transitive form of NVN and a further 1,000 sentences with the intransitive form of NV (see Table 7).
",6 Comparison to BabySRL,[0],[0]
"Since Connor et al. (2010) investigate the effects
shows model accuracy on NNV structures.",6 Comparison to BabySRL,[0],[0]
"12It is important to note that the unique argument constraint prevents the current model from actually getting the correct, conjoined-subject parse, but it no longer exhibits agent-first bias, an important step for acquiring passives, which occurs between 3 and 4 years (Thatcher et al., 2008).
of different initial lexicons, this evaluation compares against the resulting BabySRL from each initializer: they initially seed their part-of-speech tagger with either the 10 or 365 most frequent nouns in the corpus or they dispense with the tagger and use gold part-of-speech tags.
",6 Comparison to BabySRL,[0],[0]
"As with subject extraction, the model in this paper gets less accurate after training because of the newly minted extracted object category that can be mistakenly used in these canonical settings.",6 Comparison to BabySRL,[0],[0]
"While the model of Connor et al. (2010) outperforms the model presented here when in a transitive setting, their model does much worse in an intransitive setting.",6 Comparison to BabySRL,[0],[0]
"The difference in transitive settings stems from increased lexicalization, as is apparent from their results alone; the model presented here initially performs close to their weakly lexicalized model, though training impedes agentprediction accuracy due to an increased probability of non-canonical objects.
",6 Comparison to BabySRL,[0],[0]
"For the intransitive case, however, whereas the model presented in this paper is generally able to successfully label the lone noun as the subject, the model of Connor et al. (2010) chooses to label lone nouns as objects about 40% of the time.",6 Comparison to BabySRL,[0],[0]
"This likely stems from their model’s reliance on argumentargument relative position as a feature; when there is no additional argument to use for reference, the model’s accuracy decreases.",6 Comparison to BabySRL,[0],[0]
"This is borne out by their model (not shown in Table 7) that omits the argument-argument relative position feature and solely relies on verb-argument position, which achieves up to 70% accuracy in intransitive settings.",6 Comparison to BabySRL,[0],[0]
"Even in that case, however, BabySRL still chooses to label lone nouns as objects 30% of the time.",6 Comparison to BabySRL,[0],[0]
"The fact that intransitive sentences are more common than transitive sentences in both the Eve and Adam sections of the BabySRL corpus suggests that learners should be more likely to assign
correct roles in an intransitive setting, which is not reflected in the BabySRL results.
",6 Comparison to BabySRL,[0],[0]
The overall reason for the different results between the current work and BabySRL is that BabySRL relies on positional features that measure the relative position of two individual elements (e.g. where a given noun is relative to the verb).,6 Comparison to BabySRL,[0],[0]
"Since the model in this paper operates over global orderings, it implicitly takes into account the positions of other nouns as it models argument position relative to the verb; object and subject are in competition as labels for preverbal nouns, so a preverbal object is usually only assigned once a subject has already been detected.
",6 Comparison to BabySRL,[0],[0]
"Further, while BabySRL consistently reflects 1- 1 role bias (corresponding to a pre 25-month old learner), it also learns to productively label five roles, which developmental studies have shown does not take place until at least 31 months (Goldberg et al., 2004; Bello, 2012).",6 Comparison to BabySRL,[0],[0]
"Finally, it does not seem likely that BabySRL could be easily extended to capture filler-gap acquisition.",6 Comparison to BabySRL,[0],[0]
"The argumentverb position features impede acquisition of fillergap by classifying preverbal arguments as agents, and the argument-argument position features inhibit accurate labelling in intransitive settings and result in an agent-first bias which would tend to label extracted objects as agents.",6 Comparison to BabySRL,[0],[0]
"In fact, these observations suggest that any linear classifier which relies on positioning features will have difficulties modeling filler-gap acquisition.
",6 Comparison to BabySRL,[0],[0]
"In sum, the unlexicalized model presented in this paper is able to achieve greater labelling accuracy than the lexicalized BabySRL models in intransitive settings, though this model does perform slightly worse in the less common transitive setting.",6 Comparison to BabySRL,[0],[0]
"Further, the unsupervised model in this paper initially reflects developmental 1-1 role bias as well as the supervised BabySRL models, and it is able to progress beyond this bias.",6 Comparison to BabySRL,[0],[0]
"Finally, unlike BabySRL, the model presented here provides a cognitive model of the acquisition of filler-gap comprehension, which BabySRL does not seem wellsuited to model.",6 Comparison to BabySRL,[0],[0]
"This paper has presented a simple cognitive model of filler-gap acquisition, which is able to capture several findings from developmental psychology.",7 Discussion,[0],[0]
"Training significantly improves role labelling in the case of object-extractions, which improves the overall accuracy of the model.",7 Discussion,[0],[0]
This boost is accompanied by a slight decrease in labelling accuracy in subject-extraction settings.,7 Discussion,[0],[0]
"The asymmetric ease of subject versus object comprehension is well-documented in both children and adults (Gibson, 1998), and while training improves the model’s ability to process object-extractions,
there is still a gap between object-extraction and subject-extraction comprehension even after training.
",7 Discussion,[0],[0]
"Further, the model exhibits better comprehension of wh-relatives than that-relatives similar to children (Gagliardi and Lidz, 2010).",7 Discussion,[0],[0]
This could also be an area where a lexicalized model could do better.,7 Discussion,[0],[0]
"As Gagliardi and Lidz (2010) point out, whereas wh-relatives such as who or which always signify a filler-gap construction, that can occur for many different reasons (demonstrative, determiner, complementizer, etc) and so is a much weaker filler-gap cue.",7 Discussion,[0],[0]
"A lexical model could potentially pick up on clues which could indicate when that is a relativizer or simply improve on its comprehension of wh-relatives even more.
",7 Discussion,[0],[0]
It is interesting to note that the cuurent model does not make use of that as a cue at all and yet is still slower at acquiring that-relatives than wh-relatives.,7 Discussion,[0],[0]
"This fact suggests that the findings of Gagliardi and Lidz (2010) may be partially explained by a frequency effect: perhaps the input to children is simply biased such that wh-relatives are much more common than that-relatives (as shown in Table 5).
",7 Discussion,[0],[0]
"This model also initially reflects the 1-1 role bias observed in children (Gertner and Fisher, 2012) as well as previous models (Connor et al., 2008; Connor et al., 2009; Connor et al., 2010) without sacrificing accuracy in canonical intransitive settings.
",7 Discussion,[0],[0]
"Finally, this model is extremely robust to different initializations.",7 Discussion,[0],[0]
"The canonical Gaussian expectations can begin far from the verb (±3) or close to the verb (±0.1), and the standard deviations of the distributions and the skip-penalty can vary widely; the model always converges to give comparable results to those presented here.",7 Discussion,[0],[0]
The only constraint on the initial parameters is that the probability of the extracted object occurring preverbally must exceed the skip-penalty (i.e. extraction must be possible).,7 Discussion,[0],[0]
"In short, this paper describes a simple, robust cognitive model of the development of a learner between 15 months until somewhere between 25- and 30-months old (since 1-1 role bias is no longer present but no more than two arguments are being generalized).
",7 Discussion,[0],[0]
"In future, it would be interesting to incorporate lexicalization into the model presented in this paper, as this feature seems likely to bridge the gap between this model and BabySRL in transitive settings.",7 Discussion,[0],[0]
"Lexicalization should also help further distinguish modifiers from arguments and improve the overall accuracy of the model.
",7 Discussion,[0],[0]
It would also be interesting to investigate how well this model generalizes to languages besides English.,7 Discussion,[0],[0]
"Since the model is able to use the verb position as a semi-permeable boundary between canonical subjects and objects, it may not work as
well in verb-final languages, and thus makes the prediction that filler-gap comprehension may be acquired later in development in such languages due to a greater reliance on hierarchical syntax.
",7 Discussion,[0],[0]
"Ordering is one of the definining characteristics of a language that must be acquired by learners (e.g. SVO vs SOV), and this work shows that filler-gap comprehension can be acquired as a byproduct of learning orderings rather than having to resort to higher-order syntax.",7 Discussion,[0],[0]
"Note that this model cannot capture the constraints on filler-gap usage which require a hierarchical grammar (e.g. subjacency), but such knowledge is really only needed for successful production of filler-gap constructions, which occurs much later (around 5 years; de Villiers and Roeper, 1995).",7 Discussion,[0],[0]
"Further, the kind of ordering system proposed in this paper may form an initial basis for learning such grammars (Jackendoff and Wittenberg, in press).",7 Discussion,[0],[0]
"Thanks to Peter Culicover, William Schuler, Laura Wagner, and the attendees of the OSU 2013 Fall Linguistics Colloquium Fest for feedback on this work.",8 Acknowledgements,[0],[0]
This work was partially funded by an OSU Dept. of Linguistics Targeted Investment for Excellence (TIE) grant for collaborative interdisciplinary projects conducted during the academic year 2012-13.,8 Acknowledgements,[0],[0]
Analyses of filler-gap dependencies usually involve complex syntactic rules or heuristics; however recent results suggest that filler-gap comprehension begins earlier than seemingly simpler constructions such as ditransitives or passives.,abstractText,[0],[0]
"Therefore, this work models filler-gap acquisition as a byproduct of learning word orderings (e.g. SVO vs OSV), which must be done at a very young age anyway in order to extract meaning from language.",abstractText,[0],[0]
"Specifically, this model, trained on part-of-speech tags, represents the preferred locations of semantic roles relative to a verb as Gaussian mixtures over real numbers.",abstractText,[0],[0]
This approach learns role assignment in filler-gap constructions in a manner consistent with current developmental findings and is extremely robust to initialization variance.,abstractText,[0],[0]
"Additionally, this model is shown to be able to account for a characteristic error made by learners during this period (A and B gorped interpreted as A gorped B).",abstractText,[0],[0]
Bootstrapping into Filler-Gap: An Acquisition Story,title,[0],[0]
"We have seen an unprecedented success of DNNs in computer vision, speech, and other domains (Krizhevsky et al., 2012; Ciresan et al., 2012; Goodfellow et al., 2013; Hinton et al., 2012).",1. Introduction,[0],[0]
"While the popular networks such as AlexNet (Krizhevsky et al., 2012), GoogleNet (Szegedy et al., 2015), and residual networks (He et al., 2016) have shown record beating performance on various image recognition tasks, empirical results still govern the design of network architecture in terms of depth and activation functions.",1. Introduction,[0],[0]
Two important considerations that are part of most successful architectures are greater depth and the use of PWL activation functions such as rectified linear units (ReLUs).,1. Introduction,[0],[0]
"This large gap between practice and theory has driven
*Equal contribution 1Carnegie Mellon University, Pittsburgh, USA 2The University of Utah, Salt Lake City, USA.",1. Introduction,[0],[0]
"Correspondence to: Thiago Serra <tserraaz@alumni.cmu.edu>, Christian Tjandraatmadja <ctjandra@alumni.cmu.edu>, Srikumar Ramalingam <srikumar@cs.utah.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"researchers toward mathematical modeling of the expressive power of DNNs (Cybenko, 1989; Anthony & Bartlett, 1999; Pascanu et al., 2014; Montúfar et al., 2014; Bianchini & Scarselli, 2014; Eldan & Shamir, 2016; Telgarsky, 2015; Mhaskar et al., 2016; Raghu et al., 2017; Montúfar, 2017).
",1. Introduction,[0],[0]
The expressiveness of DNNs can be studied by transforming one network to another with different number of layers or activation functions.,1. Introduction,[0],[0]
"While any continuous function can be modeled using a single hidden layer of sigmoid activation functions (Cybenko, 1989), shallow networks require exponentially more neurons to model functions that can be modeled using much smaller deeper networks (Delalleau & Bengio, 2011).",1. Introduction,[0],[0]
"There are a wide variety of activation functions, which come with different modeling capabilities, such as threshold (f(z) =",1. Introduction,[0],[0]
"(z > 0)), logistic (f(z) = 1/(1 + exp(−e))), ReLU (f(z) = max{0, z}), and maxout (f(z1, z2, . . .",1. Introduction,[0],[0]
", zk) = max{z1, z2, . . .",1. Introduction,[0],[0]
", zk}).",1. Introduction,[0],[0]
"It has been shown that sigmoid networks are more expressive than similar-sized threshold networks (Maass et al., 1994), and ReLU networks are more expressive than similar-sized
threshold networks (Pan & Srikumar, 2016).
",1. Introduction,[0],[0]
"The complexity or expressiveness of neural networks belonging to the family of PWL functions can also be analyzed by looking at how the network can partition the input space to an exponential number of linear response regions (Pascanu et al., 2014; Montúfar et al., 2014).",1. Introduction,[0],[0]
The basic idea of a PWL function is simple: we can divide the input space into several regions and we have individual linear functions for each of these regions.,1. Introduction,[0],[0]
"Functions partitioning the input space to a larger number of linear regions are considered to be more complex, or in other words, possess better representational power.",1. Introduction,[0],[0]
"In the case of ReLUs, it has been shown that some deep networks separate their input space into exponentially more linear response regions than their shallow counterparts despite using the same number of activation functions (Pascanu et al., 2014).",1. Introduction,[0],[0]
The results were later extended and improved.,1. Introduction,[0],[0]
"In particular, Montúfar et al. (2014) show upper and lower bounds on the maximal number of linear regions for a ReLU DNN and a single layer maxout network, and a lower bound for a maxout DNN.",1. Introduction,[0],[0]
"Furthermore, Raghu et al. (2017) and Montúfar (2017) improve the upper bound for a ReLU DNN.",1. Introduction,[0],[0]
This upper bound asymptotically matches the lower bound from Montúfar et al. (2014) when the number of layers and input dimension are constant and all layers have the same width.,1. Introduction,[0],[0]
"Finally, Arora et al. (2018) improve the lower bound by providing a family of ReLU DNNs with an exponential number of regions for fixed size and depth.
",1. Introduction,[0],[0]
"Main Contributions
This paper directly improves on the results of Montúfar et al. (Pascanu et al., 2014; Montúfar et al., 2014; Montúfar, 2017), Raghu et al. (2017), and Arora et al. (2018).",1. Introduction,[0],[0]
"Fig. 1 highlights the main contributions, and the following list summarizes all the contributions:
• We achieve tighter upper and lower bounds on the maximal number of linear regions of the PWL function corresponding to a DNN that employs ReLUs as shown in Fig. 1.",1. Introduction,[0],[0]
"As a special case, we present the exact maximal number of regions when the input dimension is one.",1. Introduction,[0],[0]
We additionally provide the first upper bound for multi-layer maxout networks.,1. Introduction,[0],[0]
"(See Sections 3 and 4).
",1. Introduction,[0],[0]
"• We show for ReLUs that the exact maximal number of linear regions of shallow networks is larger than that of deep networks if the input dimension exceeds the number of neurons, a result that could not be inferred from bounds in prior work.",1. Introduction,[0],[0]
"(See Figure 5).
",1. Introduction,[0],[0]
• We use a mixed-integer linear formulation to show that counting linear regions is indeed possible.,1. Introduction,[0],[0]
"For
the first time, we show the exact number of linear regions for a sample of DNNs as shown in Fig. 1.",1. Introduction,[0],[0]
This new capability can be used to evaluate the tightness of the bounds and potentially to analyze the correlation between accuracy and the number of linear regions.,1. Introduction,[0],[0]
(See Sections 5 and 6).,1. Introduction,[0],[0]
"Let us assume that a feedforward neural network, which is studied in this paper, has n0 input variables given by x = {x1, x2, . . .",2. Notations and Background,[0],[0]
", xn0}, and m output variables given by y = {y1, y2, . . .",2. Notations and Background,[0],[0]
", ym}.",2. Notations and Background,[0],[0]
"Each hidden layer l = {1, 2, . . .",2. Notations and Background,[0],[0]
", L} has nl hidden neurons whose activations are given by hl = {hl1, hl2, . . .",2. Notations and Background,[0],[0]
", hlnl}.",2. Notations and Background,[0],[0]
"Let W
l be the nl × nl−1 matrix where each row corresponds to the weights of a neuron of layer l. Let bl be the bias vector used to obtain the activation functions of neurons in layer l.",2. Notations and Background,[0],[0]
"Based on the ReLU(x) = max{0, x} activation function, the activations of the hidden neurons and the outputs are given below:
h1 = max{0,W 1x + b1} hl = max{0,W",2. Notations and Background,[0],[0]
lhl−1,2. Notations and Background,[0],[0]
"+ bl} y = WL+1hL
As considered in Pascanu et al. (2014), the output layer is a linear layer that computes the linear combination of the activations from the previous layer without any ReLUs.
",2. Notations and Background,[0],[0]
We can treat the DNN as a piecewise linear (PWL) function F : Rn0 → Rm that maps the input x in Rn0 to y in Rm.,2. Notations and Background,[0],[0]
"We define linear regions based on activation patterns.
",2. Notations and Background,[0],[0]
"Activation Pattern: Let us consider an input vector x = {x1, . . .",2. Notations and Background,[0],[0]
", xn0}.",2. Notations and Background,[0],[0]
"For every layer l we define an activation set Sl ⊆ {1, . . .",2. Notations and Background,[0],[0]
", nl} such that e ∈ Sl if and only if the ReLU e is active, i.e. hle > 0.",2. Notations and Background,[0],[0]
"We aggregate these activation sets into S = (S1, . . .",2. Notations and Background,[0],[0]
", Sl), which we call an activation pattern.",2. Notations and Background,[0],[0]
"In this work, we may consider activation patterns up to a layer",2. Notations and Background,[0],[0]
l ≤,2. Notations and Background,[0],[0]
"L. Activation patterns were previously defined in terms of strings (Raghu et al., 2017; Montúfar, 2017).",2. Notations and Background,[0],[0]
"We say that an input x corresponds to an activation pattern S if feeding x to the DNN results in the activations in S.
We define linear regions as follows.1
Definition 1.",2. Notations and Background,[0],[0]
"Given a PWL function F : Rn0 → Rm represented by a DNN, a linear region is the set of inputs that correspond to a same activation pattern in the DNN.
",2. Notations and Background,[0],[0]
"1There is a subtly different definition of linear region in the literature (Pascanu et al., 2014; Montúfar et al., 2014), as follows.",2. Notations and Background,[0],[0]
"Given a PWL function F , a linear region is a maximal connected subset of the input space on which F is linear.",2. Notations and Background,[0],[0]
"The two definitions are essentially the same, except in a few degenerate cases.",2. Notations and Background,[0],[0]
"There could be scenarios where two different activation patterns may correspond to two adjacent regions with the same linear function, in which case this definition considers them as a single one.",2. Notations and Background,[0],[0]
"However, the bounds derived in this paper are valid for both definitions.
",2. Notations and Background,[0],[0]
"In this paper, we interchangeably refer to S as an activation pattern or a region for convenience.
",2. Notations and Background,[0],[0]
"In Figure 2 we show a simple ReLU DNN with two inputs {x1, x2} and 3 layers.",2. Notations and Background,[0],[0]
"The activation units {a, b, c, d, e, f} on these layers can be thought of as hyperplanes that each divide the space in two.",2. Notations and Background,[0],[0]
"On one side of the hyperplane, the unit outputs a positive value.",2. Notations and Background,[0],[0]
"For all points on the other side of the hyperplane including itself, the unit outputs 0.
",2. Notations and Background,[0],[0]
One may wonder: into how many linear regions do n hyperplanes split a space?,2. Notations and Background,[0],[0]
"Zaslavsky (1975) shows that an arrangement of n hyperplanes divides a d-dimensional space into at most ∑d s=0 ( n s ) regions, a bound that is attained when they are in general position.",2. Notations and Background,[0],[0]
The term general position basically means that a small perturbation of the hyperplanes does not change the number of regions.,2. Notations and Background,[0],[0]
"This corresponds to the exact maximal number of regions of a single layer DNN with n ReLUs and input dimension d.
In Figures 2(b)–(c), we provide a visualization of how ReLUs partition the input space.",2. Notations and Background,[0],[0]
"Figure 2(c) shows the hyperplanes corresponding to the ReLUs at layers l = 1, 2, and 3, from top to bottom.",2. Notations and Background,[0],[0]
Figure 2(b) considers these same hyperplanes in the input space x.,2. Notations and Background,[0],[0]
"If we consider only the first-layer hyperplanes, the 2D input space is partitioned into 4 regions, as per Zaslavsky (1975) (( 2 0 )",2. Notations and Background,[0],[0]
+ ( 2 1 ) +,2. Notations and Background,[0],[0]
( 2 2 ) = 4 ) .,2. Notations and Background,[0],[0]
The regions are further partitioned as we consider additional layers.,2. Notations and Background,[0],[0]
"Subsequent hyperplanes are affected by the transformations applied in the earlier layers.
",2. Notations and Background,[0],[0]
Figure 2 also highlights that activation boundaries behave like hyperplanes when inside a region and may bend whenever they intersect with a boundary from a previous layer.,2. Notations and Background,[0],[0]
This has also been pointed out by Raghu et al. (2017).,2. Notations and Background,[0],[0]
"In particular, they cannot appear twice in the same region as they are defined by a single hyperplane if we fix the region.",2. Notations and Background,[0],[0]
"Moreover, these boundaries do not need to be connected, as illustrated in Figure 3.",2. Notations and Background,[0],[0]
"Montúfar et al. (2014) derive an upper bound of 2N for N units, which can be obtained by mapping linear regions to activation patterns.",3. Tighter Bounds for Rectifier Networks,[0],[0]
"Raghu et al. (2017) improve this result by deriving an asymptotic upper bound of O(nLn0) to the maximal number of regions, assuming nl = n for all layers l and n0 = O(1).",3. Tighter Bounds for Rectifier Networks,[0],[0]
Montúfar (2017) further tightens the upper bound to ∏L l=1 ∑dl j=0,3. Tighter Bounds for Rectifier Networks,[0],[0]
"( nl j ) , where dl = min{n0, n1, . . .",3. Tighter Bounds for Rectifier Networks,[0],[0]
", nl}.",3. Tighter Bounds for Rectifier Networks,[0],[0]
"Moreover, Montúfar et al. (2014) prove a lower bound of(∏L−1 l=1 bnl/n0cn0 )∑n0 j=0",3. Tighter Bounds for Rectifier Networks,[0],[0]
"( nL j ) when n ≥ n0, or asymptotically Ω((n/n0)(L−1)n0nn0).",3. Tighter Bounds for Rectifier Networks,[0],[0]
Arora et al. (2018) present a lower bound of 2 ∑n0−1 j=0,3. Tighter Bounds for Rectifier Networks,[0],[0]
( m−1 j ) wL−1,3. Tighter Bounds for Rectifier Networks,[0],[0]
"where 2m = n1 and w = nl for all l = 2, . . .",3. Tighter Bounds for Rectifier Networks,[0],[0]
", L. We derive both upper and lower bounds that improve upon these previous results.",3. Tighter Bounds for Rectifier Networks,[0],[0]
"In this section, we prove the following upper bound on the number of regions.
",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
Theorem 1.,3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"Consider a deep rectifier network with L layers, nl rectified linear units at each layer l, and an input of dimension n0.",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"The maximal number of regions of this
neural network is at most
∑ (j1,...,jL)∈J L∏ l=1 ( nl jl )
where J = {(j1, . . .",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
", jL) ∈ ZL : 0 ≤",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"jl ≤ min{n0, n1 − j1, . . .",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
", nl−1 − jl−1, nl} ∀l = 1, . . .",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
", L}.",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"This bound is tight when L = 1.
",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"Note that this is a stronger upper bound than the one that appeared in Montúfar (2017), which can be derived from this bound by relaxing the terms nl",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
− jl to nl and factoring the expression.,3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"When n0 = O(1) and all layers have the same width n, we have the same best known asymptotic bound O(nLn0) first presented in Raghu et al. (2017).
",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"Two insights can be extracted from the above expression:
1.",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
Bottleneck effect.,3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"The bound is sensitive to the positioning of layers that are small relative to the others, a property we call the bottleneck effect.",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"If we subtract a neuron from one of two layers with the same width, choosing the one closer to the input layer will lead to a larger (or equal) decrease in the bound.",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"This occurs because each index jl is essentially limited by the widths of the current and previous layers, n0, n1, . . .",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
", nl.",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"In other words, smaller widths in the first few layers of the network imply a bottleneck on the bound.
",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"The following proposition illustrates this bottleneck effect of the bound for the 2-layer case (see Appendix A for the proof).
",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
Proposition 2.,3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"Consider a 2-layer network with widths n1, n2 and input dimension n0 > max{n1, n2}.",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"Then moving a neuron from the first layer to the second layer strictly decreases the bound.
",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
Figure 4 illustrates this behavior.,3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"For the solid line, we keep the total size of the network the same but shift from a small-to-large network (i.e., smaller width near the input layer and larger width near the output layer) to a large-to-small network in terms of width.",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
We see that the bound monotonically increases as we reduce the bottleneck.,3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"If we add a layer of constant width at the end, represented by the dashed line, the bound decreases when the layers before the last become too small and create a bottleneck for the last layer.
",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"While this is a property of the upper bound rather than of the exact maximal number of regions, we observe in Section 6 that empirical results for the number of regions of a trained network exhibit a behavior that resembles the bound as the width of the layers vary.",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"Moreover, this bottleneck effect appears at a more fundamental level.",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"For example, having a first layer of size
one forces all hyperplanes corresponding to subsequent layers to be parallel to each other in the input space, reflecting the fact that we have compressed all information into a single value.",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"More generally, the smaller a layer is, the more linearly dependent the hyperplanes from subsequent layers will be, which results in fewer regions.",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"Further in this section, we formalize this in terms of dimension and show that the dimension of the image of a region is limited by the widths of earlier layers, which is used to prove Theorem 1.
2.",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
Deep vs shallow for large input dimensions.,3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"In several applications such as imaging, the input dimension can be very large.",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"Montúfar et al. (2014) show that if the input dimension n0 is constant, then the number of regions of deep networks is asymptotically larger than that of shallow (single-layer) networks.",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"We complement this picture by establishing that if the input dimension is large, then shallow networks can attain more regions than deep networks.
",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"More precisely, we compare a deep network with L layers of equal width n and a shallow network with one layer of width Ln.",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"Denote the exact maximal number of regions byR(n0, n1, . . .",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
", nL), where n0 is the input dimension and n1, . . .",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
", nL are the widths of layers 1 through L of the network.
",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
Corollary 3.,3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"Let L ≥ 2, n ≥ 1, and n0 ≥ Ln.",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"Then
R(n0, n, . . .",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
", n︸ ︷︷ ︸ L times )",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"< R(n0, Ln)
",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"Moreover, limL→∞ R(n0,n,...,n)",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"R(n0,Ln) = 0.
",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"This is a consequence of Theorem 1 (see Appendix A for the proof).
",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
Figure 5 (a) illustrates this behavior.,3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"As we increase the number of layers while keeping the total size of the network constant, the bound plateaus at a value lower than the exact maximal number of regions for shallow networks.",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"Moreover, the number of layers that yields the highest bound decreases as we increase the input dimension n0.",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"Hence, for a given number of units and n0, there is a particular depth maximizing the bound.
",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"This property cannot be inferred from upper bounds derived in prior work: previous bounds for a network with L layers of size n are no smaller than R(n0, Ln) for a sufficiently large n0.",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"Figure 5 (b) shows the behavior of the previous best known bound.
",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
We remark that asymptotically both deep and shallow networks can attain exponentially many regions when the input dimension is sufficiently large.,3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"More precisely, for a DNN with the same width n per layer, the maximal number of linear regions is Ω(2 2 3Ln) when n0 ≥ n/3 (see Appendix B).
",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
We now build towards the proof of Theorem 1.,3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"For a given activation set Sl and a matrix W with nl rows, let σSl(W ) be the operation that zeroes out the rows of W that are inactive according to Sl.",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
This represents the effect of the ReLUs.,3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"We say that a region is at layer l if it corresponds to an activation pattern (S1, . . .",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
", Sl) up to layer l. For a region S at layer l",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"− 1, define W̄ lS",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
":= W l σSl−1(W l−1) · · ·σS1(W 1).
",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"Each region S at layer l − 1 may be partitioned by a set of hyperplanes defined by the neurons of layer l. When viewed in the input space, these hyperplanes are the rows of W̄",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
lSx+ b = 0,3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
for some b.,3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"To verify this, note that, if we recursively substitute out the hidden variables hl−1, . . .",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
", h1 from the original hyperplane W lhl−1 + bl = 0 following S , the resulting weight matrix applied to x is W̄ lS .
",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"A central element in the proof of Theorem 1 is the dimension of the image of a linear region S under the DNN function hl up to a layer l, which we denote by dim(hl(S)).",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"For a fixed region S at layer l, that function is linear, and thus the dimension equals to the rank of the coefficient matrix.",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"Therefore, dim(hl(S))",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
= rank(σSl(W l) · · ·σS1(W 1)).,3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
This can be interpreted as the dimension of the space corresponding to S that the hyperplanes defined by W l+1hl + bl+1,3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
= 0,3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
effectively partitions.,3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"A key observation is that, once this dimension falls to a certain value, the regions contained in S at subsequent layers cannot recover to a higher dimension.
",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
Zaslavsky (1975) showed that the maximal number of regions in Rd induced by an arrangement of m hyperplanes is at most ∑d j=0,3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
( m j ) .,3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"Moreover, this value is attained if
and only if the hyperplanes are in general position.",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"The lemma below tightens this bound for a special case where the hyperplanes may not be in general position.
",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
Lemma 4.,3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
Consider m hyperplanes in Rd defined by the rows of Wx+ b = 0.,3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
Then the number of regions induced by the hyperplanes is at most ∑rank(W ) j=0,3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"( m j ) .
",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
The proof is given in Appendix C. Its key idea is that it suffices to count regions within the row space of W .,3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"The next lemma brings Lemma 4 into our context.
",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
Lemma 5.,3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"The number of regions induced by the nl neurons at layer l within a certain region S is at most∑min{nl,dim(hl−1(S))}
j=0
( nl j ) .
",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
Proof.,3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
The hyperplanes in a region S of the input space are given by the rows of W̄ lSx + b,3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
= 0,3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
for some b.,3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"By definition, the rank of W̄ lS is upper bounded by min{rank(W l), rank(σSl−1(W l−1) · · ·σS1(W 1))} = min{rank(W l),dim(hl−1(S))}.",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"That is, rank(W̄ lS)",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"≤ min{nl,dim(hl−1(S))}, and we apply Lemma 4.
",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"In the next lemma, we show that the dimension of the image of a region S can be bounded recursively in terms of the dimension of the image of the region containing S and the number of activated neurons defining S. Lemma 6.",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
Let S be a region at layer l and S ′ be the region at layer l,3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
− 1 that contains it.,3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"Then dim(hl(S)) ≤ min{|Sl|,dim(hl−1(S ′))}.
",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
Proof.,3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
dim(hl(S)),3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
= rank(σSl(W l) · · ·σS1(W 1)) ≤,3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"min{rank(σSl(W l)), rank(σSl−1(W l−1) · · ·σS1(W 1))",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"≤ min{|Sl|,dim(hl−1(S ′))}.",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"The last inequality comes from zeroed out rows not counting towards the matrix rank.
",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"We now have the ingredients to prove Theorem 1.
",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
Proof of Theorem 1.,3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"As illustrated in Figure 2, the partitioning can be regarded as a sequential process: at each layer, we partition the regions obtained from the previous layer.",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"When viewed in the input space, each region S obtained at layer l−1 is potentially partitioned by nl hyperplanes given by the rows of W̄",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
lSx+ b = 0 for some bias b.,3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"Some hyperplanes may fall outside the interior of S and have no effect.
",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"With this process in mind, we recursively bound the number of subregions within a region.",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"More precisely, we construct a recurrence R(l, d) to upper bound the maximal number of regions attainable from partitioning a region with image of dimension d using units from layers l, l+1, . . .",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
", L.",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"The base case is given by Lemma 5: R(L, d) = ∑min{nL,d} j=0",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
( nL j ) .,3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"Based on Lemma 6, the recurrence groups together regions with same activation set size |Sl|, as follows: R(l, d) =∑nl
j=0Nnl,d,jR(l + 1,min{j, d}) for all l = 1, . . .",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
", L− 1.
",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"Here, Nnl,d,j represents the maximum number of regions with |Sl| = j from partitioning a space of dimension d with nl hyperplanes.",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"We bound this value next.
",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"For each j, there are at most ( nl j ) regions with |Sl| = j, as they can be viewed as subsets of nl neurons of size j. In total, Lemma 5 states that there are at most ∑min{nl,d} j=0",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"( nl j
) regions.",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"If we allow these regions to have the highest |Sl| possible, for each j from 0 to min{nl, d} we have at most(
nl nl−j )",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
=,3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
( nl j ) regions with |Sl| = nl,3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"− j.
Therefore, we can write the recurrence as
R(l, d) =  min{nl,d}∑ j=0",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"( nl j ) R(l + 1,min{nl",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"− j, d})",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"if 1 ≤ l ≤ L− 1, min{nL,d}∑
j=0
( nL j ) if l = L.
The recurrence R(1, n0) can be unpacked to
min{n1,d1}∑ j1=0 ( n1 j1 )min{n2,d2}∑ j2=0 ( n2 j2 ) · · · min{nL,dL}∑ jL=0 ( nL jL )
where dl = min{n0, n1 − j1, . . .",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
", nl−1 − jl−1}.",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"This can be made more compact, resulting in the final expression.",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"The bound is tight when L = 1 since it becomes∑min{n0,n1} j=0",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"( n1 j ) , which is the maximal number of regions of a single-layer network.
",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"As a side note, Theorem 1 can be further tightened if the weight matrices are known to have small rank.",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"The bound from Lemma 5 can be rewritten as ∑min{rank(W l),dim(hl−1(S))}
j=0
( nl j ) if we do not relax
rank(W",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
l) to nl in the proof.,3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"The term rank(W l) follows through the proof of Theorem 1 and the index set J in the theorem becomes {(j1, . . .",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
", jL) ∈ ZL : 0 ≤",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"jl ≤ min{n0, n1 − j1, . . .",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
", nl−1 − jl−1, rank(W l)} ∀l ≥ 1}.
",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
A key insight from Lemmas 5 and 6 is that the dimensions of the images of the regions are non-increasing as we move through the layers partitioning them.,3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"In other words, if at any layer the dimension of the image of a region becomes small, then that region will not be able to be further partitioned into a large number of regions.",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"For instance, if the dimension of the image of a region falls to zero, then that region will never be further partitioned.",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"This suggests that if we want to have many regions, we need to keep dimensions high.",3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
We use this idea in the next section to construct a DNN with many regions.,3.1. An Upper Bound on the Number of Linear Regions,[0],[0]
"If the input dimension n0 is equal to 1 and nl = n for all layers l, the upper bound presented in the previous section reduces to (n + 1)L.",3.2. The Case of Dimension One,[0],[0]
"On the other hand, the lower bound given by Montúfar et al. (2014) becomes nL−1(n+ 1).",3.2. The Case of Dimension One,[0],[0]
It is then natural to ask: are either of these bounds tight?,3.2. The Case of Dimension One,[0],[0]
"The answer is that the upper bound is tight in the case of n0 = 1, assuming there are sufficiently many neurons.
",3.2. The Case of Dimension One,[0],[0]
Theorem 7.,3.2. The Case of Dimension One,[0],[0]
"Consider a deep rectifier network with L layers, nl ≥ 3 rectified linear units at each layer l, and an input of dimension 1.",3.2. The Case of Dimension One,[0],[0]
"The maximal number of regions of this neural network is exactly ∏L l=1(nl + 1).
",3.2. The Case of Dimension One,[0],[0]
"The expression above is a simplified form of the upper bound from Theorem 1 in the case n0 = 1.
",3.2. The Case of Dimension One,[0],[0]
"The proof of this theorem in Appendix D has a construction with n+1 regions that replicate themselves as we add layers, instead of n as in Montúfar et al. (2014).",3.2. The Case of Dimension One,[0],[0]
"That is motivated by an insight from the previous section: in order to obtain more regions, we want the dimension of the image of every region to be as large as possible.",3.2. The Case of Dimension One,[0],[0]
"When n0 = 1, we want all regions to have images with dimension one.",3.2. The Case of Dimension One,[0],[0]
This intuition leads to a new construction with one additional region that can be replicated with other strategies.,3.2. The Case of Dimension One,[0],[0]
"Both the lower bounds from Montúfar et al. (2014) and from Arora et al. (2018) can be slightly improved, since their approaches are based on extending a 1-dimensional construction similar to the one in Section 3.2.",3.3. Lower Bounds on the Maximal Number of Linear Regions,[0],[0]
"We do both since they are not directly comparable: the former bound is in terms of the number of neurons in each layer and the latter is in terms of the total size of the network.
",3.3. Lower Bounds on the Maximal Number of Linear Regions,[0],[0]
Theorem 8.,3.3. Lower Bounds on the Maximal Number of Linear Regions,[0],[0]
"The maximal number of linear regions induced by a rectifier network with n0 input units and L hidden layers with nl ≥ 3n0 for all l is lower bounded by (∏L−1
l=1 (⌊ nl n0 ⌋",3.3. Lower Bounds on the Maximal Number of Linear Regions,[0],[0]
+ 1 )n0)∑n0 j=0,3.3. Lower Bounds on the Maximal Number of Linear Regions,[0],[0]
"( nL j ) .
",3.3. Lower Bounds on the Maximal Number of Linear Regions,[0],[0]
"The proof of this theorem is in Appendix E. For comparison, the differences between the lower bound theorem (Theorem 5) from Montúfar et al. (2014) and the above theorem is the replacement of the condition nl ≥ n0 by the more restrictive nl ≥ 3n0, and of bnl/n0c by bnl/n0c+ 1.",3.3. Lower Bounds on the Maximal Number of Linear Regions,[0],[0]
Theorem 9.,3.3. Lower Bounds on the Maximal Number of Linear Regions,[0],[0]
"For any m ≥ 1 and w ≥ 2, there exists a rectifier network with n0 input units and L hidden layers of size 2m + w(L",3.3. Lower Bounds on the Maximal Number of Linear Regions,[0],[0]
− 1) that has 2 ∑n0−1 j=0,3.3. Lower Bounds on the Maximal Number of Linear Regions,[0],[0]
"( m−1 j ) (w + 1)L−1 linear regions.
",3.3. Lower Bounds on the Maximal Number of Linear Regions,[0],[0]
The proof of this theorem is in Appendix F. The differences between Theorem 2.11(i) from Arora et al. (2018) and the above theorem is the replacement of w by w + 1.,3.3. Lower Bounds on the Maximal Number of Linear Regions,[0],[0]
"They
construct a 2m-width layer with many regions and use a one-dimensional construction for the remaining layers.",3.3. Lower Bounds on the Maximal Number of Linear Regions,[0],[0]
We now consider a deep neural network composed of maxout units.,4. An Upper Bound on the Number of Linear Regions for Maxout Networks,[0],[0]
"Given weights W lj for j = 1, . . .",4. An Upper Bound on the Number of Linear Regions for Maxout Networks,[0],[0]
", k, the output of a rank-k maxout layer l is given by
hl = max{W l1hl−1 + bl1, . . .",4. An Upper Bound on the Number of Linear Regions for Maxout Networks,[0],[0]
",W lkhl−1 + blk}
",4. An Upper Bound on the Number of Linear Regions for Maxout Networks,[0],[0]
"In terms of bounding number of regions, a major difference between the next result for maxout units and the previous one for ReLUs is that dimensionality plays less of a role, since neurons may no longer have an inactive state with zero output.",4. An Upper Bound on the Number of Linear Regions for Maxout Networks,[0],[0]
"Nevertheless, using techniques similar to the ones from Section 3.1, the following theorem can be shown (see Appendix G for the proof).
",4. An Upper Bound on the Number of Linear Regions for Maxout Networks,[0],[0]
Theorem 10.,4. An Upper Bound on the Number of Linear Regions for Maxout Networks,[0],[0]
"Consider a deep neural network withL layers, nl rank-k maxout units at each layer l, and an input of dimension n0.",4. An Upper Bound on the Number of Linear Regions for Maxout Networks,[0],[0]
"The maximal number of regions is at most
L∏ l=1 dl∑ j=0",4. An Upper Bound on the Number of Linear Regions for Maxout Networks,[0],[0]
"(k(k−1) 2 nl j )
where dl = min{n0, n1, . . .",4. An Upper Bound on the Number of Linear Regions for Maxout Networks,[0],[0]
", nl}.
",4. An Upper Bound on the Number of Linear Regions for Maxout Networks,[0],[0]
"Asymptotically, if nl = n for all l = 1, . . .",4. An Upper Bound on the Number of Linear Regions for Maxout Networks,[0],[0]
", L, n ≥ n0, and n0 = O(1), then the maximal number of regions is at most O((k2n)Ln0).",4. An Upper Bound on the Number of Linear Regions for Maxout Networks,[0],[0]
"If the input space x ∈ Rn0 is bounded by minimum and maximum values along each dimension, or else if x corresponds to a polytope more generally, then we can define a mixed-integer linear formulation mapping polyhedral regions of x to the output space y.",5. Exact Counting of Linear Regions,[0],[0]
"The assumption that x is bounded and polyhedral is natural in most applications, where each value xi has known lower and upper bounds (e.g., the value can vary from 0 to 1 for image pixels).",5. Exact Counting of Linear Regions,[0],[0]
"Among other things, we can use this formulation to count the number of linear regions.
",5. Exact Counting of Linear Regions,[0],[0]
"In the formulation that follows, we use continuous variables to represent the input x, which we can also denote as h0, the output of each neuron i in layer l as hli, and the output y as hL+1.",5. Exact Counting of Linear Regions,[0],[0]
"To simplify the representation, we lift this formulation to a space that also contains the output of a complementary set of neurons, each of which is active when the corresponding neuron is not.",5. Exact Counting of Linear Regions,[0],[0]
"Namely, for each neuron i in layer",5. Exact Counting of Linear Regions,[0],[0]
l we also have a variable h,5. Exact Counting of Linear Regions,[0],[0]
"l
i := max{0,−W lihl−1− bli}.",5. Exact Counting of Linear Regions,[0],[0]
"We use binary variables of the form zli to denote if each
neuron i in layer l is active or else if the complement is.",5. Exact Counting of Linear Regions,[0],[0]
"Finally, we assume M to be a sufficiently large constant.
",5. Exact Counting of Linear Regions,[0],[0]
"For a given neuron i in layer l, the following set of constraints maps the input to the output:
W lih l−1 + bli",5. Exact Counting of Linear Regions,[0],[0]
= h,5. Exact Counting of Linear Regions,[0],[0]
l i,5. Exact Counting of Linear Regions,[0],[0]
"− h
l i (1)
",5. Exact Counting of Linear Regions,[0],[0]
"hli ≤Mzli (2)
",5. Exact Counting of Linear Regions,[0],[0]
h,5. Exact Counting of Linear Regions,[0],[0]
"l
i ≤M(1− zli) (3) hli",5. Exact Counting of Linear Regions,[0],[0]
"≥ 0 (4)
h",5. Exact Counting of Linear Regions,[0],[0]
"l
i ≥ 0 (5) zli ∈ {0, 1} (6)
Theorem 11.",5. Exact Counting of Linear Regions,[0],[0]
"Provided that |W lihl−1 + bli| ≤ M for any possible value of hl−1, a formulation with the set of constraints (1)–(6) for each neuron of a rectifier network is such that a feasible solution with a fixed value for x yields the output y of the neural network.
",5. Exact Counting of Linear Regions,[0],[0]
Proof.,5. Exact Counting of Linear Regions,[0],[0]
It suffices to prove that the constraints for each neuron map the input to the output in the same way that the neural network would.,5. Exact Counting of Linear Regions,[0],[0]
"If W lih
l−1 + bli > 0, it follows that",5. Exact Counting of Linear Regions,[0],[0]
hli,5. Exact Counting of Linear Regions,[0],[0]
− h,5. Exact Counting of Linear Regions,[0],[0]
"l
i > 0",5. Exact Counting of Linear Regions,[0],[0]
according to (1).,5. Exact Counting of Linear Regions,[0],[0]
"Since both variables are non-negative due to (4) and (5) whereas one is non-positive due to (2), (3), and (6), then zli = 1 and hli = max { 0,W lih l−1 + bli } .",5. Exact Counting of Linear Regions,[0],[0]
"If W lih l−1 + bli < 0, then it similarly follows that hli",5. Exact Counting of Linear Regions,[0],[0]
− h,5. Exact Counting of Linear Regions,[0],[0]
"l i < 0, z",5. Exact Counting of Linear Regions,[0],[0]
"l i = 0, and thus",5. Exact Counting of Linear Regions,[0],[0]
"h l i = min { 0,W lih l−1 + bli } .",5. Exact Counting of Linear Regions,[0],[0]
"If W lih l−1 + bli = 0, then either hli = 0 or h l
i = 0 due to constraints (4) to (6) whereas (1) implies that h",5. Exact Counting of Linear Regions,[0],[0]
"l
i = 0 or h",5. Exact Counting of Linear Regions,[0],[0]
"l i = 0, respectively.",5. Exact Counting of Linear Regions,[0],[0]
"In this case,
the value of zli is arbitrary but irrelevant.
",5. Exact Counting of Linear Regions,[0],[0]
"A systematic method to count integer solutions is the onetree approach (Danna et al., 2007), which resumes the search after an optimal solution has been found using the same branch-and-bound tree.",5. Exact Counting of Linear Regions,[0],[0]
This method also allows for counting feasible solutions within a threshold of the optimal value.,5. Exact Counting of Linear Regions,[0],[0]
"Note that in constraints (1)–(6), the variables zli can be either 0 or 1 when they lie on the activation boundary, whereas we want to consider a neuron active only when its output is strictly positive.",5. Exact Counting of Linear Regions,[0],[0]
This discrepancy may cause doublecounting when activation boundaries overlap.,5. Exact Counting of Linear Regions,[0],[0]
"We can address that by defining an objective function that maximizes the minimum output f of an active neuron, which is positive in the non-degenerate cases that we want to count.",5. Exact Counting of Linear Regions,[0],[0]
"We state this formulation for rectifier networks as follows:
max f
s.t. (1)–(6) ∀",5. Exact Counting of Linear Regions,[0],[0]
neuron i in layer l (P) f ≤,5. Exact Counting of Linear Regions,[0],[0]
hli +,5. Exact Counting of Linear Regions,[0],[0]
(1− zli)M ∀ neuron i in layer l x ∈,5. Exact Counting of Linear Regions,[0],[0]
"X
A discusssion on the choice for the M constants can be found in Appendix H. In addition, we discuss the mixedrepresentability of DNNs in Appendix I, the theory for unrestricted inputs in Appendix J, and a mixed-integer formulation for maxout networks in Appendix K, respectively.",5. Exact Counting of Linear Regions,[0],[0]
"We perform an experiment to count linear regions of smallsized networks with ReLU activation units on the MNIST benchmark dataset (LeCun et al., 1998).",6. Experiments,[0],[0]
"In this experiment, we train rectifier networks with two hidden layers summing up to 22 neurons.",6. Experiments,[0],[0]
"We train 10 networks for each configuration for 20 epochs or training steps, and we count all linear regions within 0 ≤ x ≤ 1.",6. Experiments,[0],[0]
The counting code is written in C++ (gcc 4.8.4) using CPLEX Studio 12.8 as a solver and ran in Ubuntu 14.04.4 on a machine with 40 Intel(R),6. Experiments,[0],[0]
Xeon(R) CPU E5-2640 v4 @ 2.40GHz processors and 132 GB of RAM.,6. Experiments,[0],[0]
"The runtimes for counting different configuration can be found in Appendix L.
Figure 1 shows the average, minimum, and maximum number of linear regions for each configuration of these networks.",6. Experiments,[0],[0]
"The plot also contains the corresponding upper bounds for each configuration from Theorem 1 and those from Montúfar et al. (2014) and Montúfar (2017), which are the first and the tightest bounds from prior work respectively.",6. Experiments,[0],[0]
"Note that upper bound from Theorem 1 is tighter.
",6. Experiments,[0],[0]
"Figure 6 shows how the number of regions for each trained DNN compares with Cross-Entropy (CE) error on training set, and Misclassification Rate (MR) on testing set.",6. Experiments,[0],[0]
"If an intermediate layer in a network has only 1 or 2 neurons, it is natural to expect very high training and test errors.",6. Experiments,[0],[0]
We discard such DNNs with a layer of small width in Figure 7.,6. Experiments,[0],[0]
Our ReLU upper bound indicates that small widths in early layers cause a bottleneck effect on the number of regions.,7. Discussion,[0],[0]
"If
we reduce the width of an early layer, the dimension of the image of the linear regions become irrecoverably smaller throughout the network and the regions will not be able to be partitioned as much.",7. Discussion,[0],[0]
This intuition allows us to develop a 1-dimensional construction with the maximal number of regions by eliminating a zero-dimensional bottleneck.,7. Discussion,[0],[0]
"In our experiment, we validate the bottleneck effect by observing that the actual number of linear regions is asymmetric when one layer is increased and another decreased in size.
",7. Discussion,[0],[0]
An unexpected consequence of one of our results is that shallow networks can attain more linear regions when the input dimensions exceed the number of neurons.,7. Discussion,[0],[0]
"This complements prior work, which has not considered large input dimensions, a common case in practice.
",7. Discussion,[0],[0]
We also observe in Figure 5 that the depth that maximizes the upper bound from Theorem 1 increases with the number of units and decreases with the size of the input.,7. Discussion,[0],[0]
"It would be interesting to investigate if this also happens with respect to the actual number of regions, in which case the depth could be chosen according to those parameters.
",7. Discussion,[0],[0]
"However, it would be possible that DNNs configurations with large number of linear regions do not generalize well if there are so many regions that each training point can be singled out in a different region, in particular if regions with similar labels are unlikely to be compositionally related.
",7. Discussion,[0],[0]
"Nevertheless, we have initial evidence that training and classification accuracies relate to the number of regions for configurations where no layer is too small, hence suggesting that the number of regions can be a metric for comparing similar DNN configurations.",7. Discussion,[0],[0]
"However, in the cases where one layer is too small, we have also observed that the number of regions can be large and do not reflect the capacity of the DNN.",7. Discussion,[0],[0]
"We hypothesize that the presence of low dimensionality negatively affects the accuracy of the network, even when the number of regions is large because of other layers.",7. Discussion,[0],[0]
This indicates that potentially more insights could be gained from investigating the shape of linear regions.,7. Discussion,[0],[0]
We thank the anonymous reviewers for useful suggestions.,Acknowledgements,[0],[0]
We investigate the complexity of deep neural networks (DNN) that represent piecewise linear (PWL) functions.,abstractText,[0],[0]
"In particular, we study the number of linear regions, i.e. pieces, that a PWL function represented by a DNN can attain, both theoretically and empirically.",abstractText,[0],[0]
"We present (i) tighter upper and lower bounds for the maximum number of linear regions on rectifier networks, which are exact for inputs of dimension one; (ii) a first upper bound for multi-layer maxout networks; and (iii) a first method to perform exact enumeration or counting of the number of regions by modeling the DNN with a mixed-integer linear formulation.",abstractText,[0],[0]
These bounds come from leveraging the dimension of the space defining each linear region.,abstractText,[0],[0]
The results also indicate that a deep rectifier network can only have more linear regions than every shallow counterpart with same number of neurons if that number exceeds the dimension of the input.,abstractText,[0],[0]
Bounding and Counting Linear Regions of Deep Neural Networks,title,[0],[0]
"It is well-known that sufficiently large multi-layer feedforward networks can approximate any function with desired accuracy (Hornik et al., 1989).",1. Introduction,[0],[0]
An important problem then is to determine the smallest neural network for a given task and accuracy.,1. Introduction,[0],[0]
"The standard guideline is the approximation power (variously known as expressiveness) of the network which quantifies the size of the neural network, typically in terms of depth and width, in order to approximate a class of functions within a given error.",1. Introduction,[0],[0]
"In particular, several works provided evidence that deeper networks perform better than shallow ones, given a fixed number of hidden units (Bianchini & Scarselli, 2014; Delalleau & Bengio, 2011; Liang & Srikant, 2017; Mhaskar et al., 2016; Pascanu et al., 2014; Telgarsky, 2015; 2016; Yarotsky, 2017).1
",1. Introduction,[0],[0]
"A popular activation function is the rectified linear unit (ReLU), partly because of its low complexity when coupled with backpropagation training (Krizhevsky et al., 2012).",1. Introduction,[0],[0]
"It has, therefore, become of interest to determine the power of neural networks with ReLU’s and, more generally, with piecewise linear activation functions.
",1. Introduction,[0],[0]
"1Department of Electrical Engineering, Sharif University of Technology, Iran 2Department of Communications and Electronics, Telecom ParisTech, France.",1. Introduction,[0],[0]
"Correspondence to: Mohammad Mehrabi <mohamadmehrabi4@gmail.com>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"1For a nice counterexample see (Lu et al., 2017).
",1. Introduction,[0],[0]
Determining the capacity of a neural networks with a piecewise linear activation function typically involves two steps.,1. Introduction,[0],[0]
"First, evaluate the number of linear pieces (or break points) that the network can produce and, second, tie this number to the approximation error.",1. Introduction,[0],[0]
"The works (Montufar et al., 2014; Pascanu et al., 2014) recently showed that a linear increase in depth results in an exponential growth in the number of linear pieces as opposed to width which results only in a polynomial growth.",1. Introduction,[0],[0]
"Accordingly, the approximation capacity exhibits a similar tradeoff between depth and width.",1. Introduction,[0],[0]
"For related works with respect to classification error see (Telgarsky, 2015; 2016) and with respect to function approximation error see (Liang & Srikant, 2017; Mhaskar et al., 2016; Yarotsky, 2017).
",1. Introduction,[0],[0]
"In this paper we consider general feedforward neural networks with piecewise linear activation functions and establish bounds on the size of the network in terms of the approximation error, the depth d, the width, and the dimension of the input space to approximate a given function.",1. Introduction,[0],[0]
"We first establish an improved upper bound on the number of break points that such a network can produce which is a multiplicative factor dd smaller than the currently best known from (Yarotsky, 2017).",1. Introduction,[0],[0]
"This upper bound is obtained by investigating neuron state transitions as introduced in (Raghu et al., 2017).",1. Introduction,[0],[0]
"Combining this upper bound with lower bounds in terms of error and dimension, we obtain necessary conditions on the depth, width, error, and dimension for a neural network to approximate a given function.",1. Introduction,[0],[0]
"These bounds significantly improve on the corresponding state-of-the-art bounds for certain classes of functions (Theorems 1,2 and Corollaries 1,2,3).
",1. Introduction,[0],[0]
The second contribution of the paper (Theorem 3) is an upper bound on the difference of two neural networks with identical weights but different activation functions.,1. Introduction,[0],[0]
"This problem is related to “activation function simulation” investigated in (DasGupta & Schnitger, 1993) which leverages network topology to compensate a change in activation function.
",1. Introduction,[0],[0]
The paper is organized as follows.,1. Introduction,[0],[0]
In Section 2 we briefly introduce the setup.,1. Introduction,[0],[0]
In Section 3 we present the main results which are then compared with the corresponding ones in the recent literature in Section 4.,1. Introduction,[0],[0]
"Finally, Section 5 contains the proofs.",1. Introduction,[0],[0]
"Throughout the paper R denotes a compact convex set in Rn, n ≥ 1, and Fσ denotes the set of feedforward neural networks with input R, output R, and activation function σ : R → R. Feedforward here refers to the fact that the neural network contains no cycles; connections are allowed between non-neighbouring layers.",2. Preliminaries,[0],[0]
It is assumed that σ is a piecewise linear (not necessarily continuous) function with t ≥ 1 linear pieces.,2. Preliminaries,[0],[0]
"The set of all such activation functions is denoted by Σt.
",2. Preliminaries,[0],[0]
"A neural network f ∈ Fσ consists of a set of input units If , a set of hidden units Hf that operate according to σ, non-zero weights representing connections, and a single output unit which just weight-sums its inputs.",2. Preliminaries,[0],[0]
"To simplify the notation we use f to represent both a neural network and the function that it represents.
",2. Preliminaries,[0],[0]
"For instance, in the neural network shown in Fig. 1, we have If = {x1, x2, x3} andHf = {uij , ∀i, j}.",2. Preliminaries,[0],[0]
Definition 1 (Depth and width).,2. Preliminaries,[0],[0]
"Given a neural network f ∈ Fσ, the depth of a hidden unit h ∈ Hf , denoted as df (h), is the length of the longest path from any i ∈",2. Preliminaries,[0],[0]
"If to h. The depth of f is
df def = max { df (h) ∣∣h ∈ Hf}.",2. Preliminaries,[0],[0]
"The set of hidden units with depth i is
Hif def = { h ∈ Hf ∣∣df (h) = i}.",2. Preliminaries,[0],[0]
"The width of the network is
ωf def = |Hf | df def = ∑df i=1",2. Preliminaries,[0],[0]
"ωi df
(1)
where ωi def = |Hif |.
",2. Preliminaries,[0],[0]
"For instance, in Fig. 1, the hidden unit u23 can be reached by inputs x1 and x3, by following the paths x1 → u23, x3 → u11 → u23, or x3 → u12 → u23.",2. Preliminaries,[0],[0]
"Therefore, df (u23) = 2.",2. Preliminaries,[0],[0]
"The hidden units of maximum depth are u31, u32, and u33 and hence df = 3,H3f = {u31, u32, u33} and ωf = 8/3.
",2. Preliminaries,[0],[0]
The following simple inequality is frequently used in the paper.,2. Preliminaries,[0],[0]
Lemma 1.,2. Preliminaries,[0],[0]
"For any t ≥ 1, df ≥ 1, and |Hf | ≥ 1
((t− 1)ωf + 1)df ≤ t|Hf",2. Preliminaries,[0],[0]
"|.
",2. Preliminaries,[0],[0]
Proof.,2. Preliminaries,[0],[0]
"Set ωf = |Hf | df
and observe that( (t− 1) |Hf |
df + 1 )",2. Preliminaries,[0],[0]
"df is a non-decreasing function of df and that df ≤ |Hf |.
",2. Preliminaries,[0],[0]
Definition 2 (Affine ε-approximation).,2. Preliminaries,[0],[0]
Function f ∈,2. Preliminaries,[0],[0]
Fσ is an affine ε-approximation of a function g : R → R,2. Preliminaries,[0],[0]
"if
sup x∈R |f(x)− g(x)| ≤ ε.
",2. Preliminaries,[0],[0]
Definition 3 (Break point).,2. Preliminaries,[0],[0]
"Given (x,y) ∈ R2, function f : R → R admits a break point at α0 ∈ (0, 1) relative to the segment [x,y] if the first order derivative of f((1− α)x + αy) does not exist at α = α0.",2. Preliminaries,[0],[0]
"The total number of break points of f on the (open) segment ]x,y[ is denoted by Bx→y(f).",2. Preliminaries,[0],[0]
"Finally, we let B̄x→y(f) def = Bx→y(f) + 1.
",2. Preliminaries,[0],[0]
Since f is piecewise linear B̄x→y(f) simply counts the number of linear pieces that f produces as the input ranges from x to y.,2. Preliminaries,[0],[0]
"Theorems 1,2 and Corollaries 2,3 provide bounds on the size of a neural network to approximate a given function.",3. Main Results,[0],[0]
"These bounds are expressed in terms of the approximation error and width and depth of the network, but hold irrespectively of the weights.",3. Main Results,[0],[0]
"Recall that connections are allowed between non-neighboring layers.
",3. Main Results,[0],[0]
"As a notational convention we use C2(R) to denote the set of functionsR → R whose second order partial derivatives are continuous over R̊ (the interior ofR).
",3. Main Results,[0],[0]
Theorem 1.,3. Main Results,[0],[0]
"Let f ∈ Fσ, σ",3. Main Results,[0],[0]
"∈ Σt, be an ε-approximation of a function g ∈ C2(R) and let x,y ∈",3. Main Results,[0],[0]
"R. Then,
( (t− 1)ωf + 1 )",3. Main Results,[0],[0]
"df ≥ B̄x→y(f) (2)
≥ ||x− y||2 4 √ ε ·Ψ(g,x,y), (3)
where
Ψ(g,x,y) def = √ inf
0≤α≤1
( max { 0, γ(α)δ(α) }) , (4)
γ(α) def = min { |α1(α)|, |α2(α)| } ,
δ(α) def = sign ( α1(α)α2(α) ) ,
and where α1(α) and α2(α) are the largest and smallest eigenvalues of the hessian matrix ∇2g ( (1 − α)x + αy ) , respectively.
",3. Main Results,[0],[0]
"Maximizing the right-hand side of (3) over x,y and using Lemma 1 we obtain:
Corollary 1.",3. Main Results,[0],[0]
"Under the assumptions of Theorem 1 we have
|Hf | ≥ logt
( sup
(x,y)∈R2
{ ||x− y||2 4 √ ε ·Ψ(g,x,y) }) .
",3. Main Results,[0],[0]
A function g : R → R that is twice differentiable is said to be strongly convex with parameter µ if ∇2g(x) µI for all x ∈ R̊.,3. Main Results,[0],[0]
Corollary 2.,3. Main Results,[0],[0]
"Let f ∈ Fσ, σ",3. Main Results,[0],[0]
"∈ Σt, be an ε-approximation of a function g ∈ C2(R)",3. Main Results,[0],[0]
that is strongly convex with parameter µ > 0.,3. Main Results,[0],[0]
"Then,
|Hf | ≥ 1
2 logt (µ · (diam(R))2 16ε ) ,
where diam(R) def= sup
(x,y)∈R ||x− y||2.
Proof.",3. Main Results,[0],[0]
"By strong convexity Ψ(g,x,y) ≥ √µ.",3. Main Results,[0],[0]
"The result then follows from Theorem 1 and Lemma 1.
",3. Main Results,[0],[0]
"As an example, consider g(x) = x · x over [0, 1]n.",3. Main Results,[0],[0]
"The Hessian matrix is 2In×n and from Corollary 2 we get
|Hf | ≥ log2 (√ n
8ε
) .
",3. Main Results,[0],[0]
Corollary 3.,3. Main Results,[0],[0]
Let R =,3. Main Results,[0],[0]
"[0, 1]n.",3. Main Results,[0],[0]
"Let f ∈ Fσ, σ ∈ Σ2,2 be an ε-approximation of a function g ∈ C2(R) such that ∇g(x) 0 for any x ∈ R̊.",3. Main Results,[0],[0]
"Then,
|Hf | ≥ q(g)dfε − 12df (5)
where q(g) > 0 is a constant that only depends on g.
Proof of Corollary 3.",3. Main Results,[0],[0]
From Theorem 1 we get(Hf df + 1 ),3. Main Results,[0],[0]
"df ≥ c(g)√ ε ,
2Recall that Σ2 includes ReLU’s.
where c(g) > 0 is some strictly positive constant, since the Hessian of g is positive definite everywhere over R̊.",3. Main Results,[0],[0]
"Since Hf/df ≥ 1 the above inequality implies(
2 |Hf | df
)df ≥ c√
ε .
",3. Main Results,[0],[0]
"Since 12c 1 df ≥ q where q = 12 min(c, 1), the above inequality yields the desired result.
",3. Main Results,[0],[0]
Theorem 2.,3. Main Results,[0],[0]
Let R =,3. Main Results,[0],[0]
"[0, 1]n.",3. Main Results,[0],[0]
"Let f ∈ Fσ, σ",3. Main Results,[0],[0]
"∈ Σt, be an ε-approximation of a function g : R → R such that |DJ(g)(x)| ≤ δ for any x ∈",3. Main Results,[0],[0]
"[0, 1]n and any multi-index3 J such that |J | = 3.",3. Main Results,[0],[0]
"Then,
( (t−1)ωf+1 )df ≥ √√√√( max x∈[0,1]n ∣∣∆(g)(x)∣∣n−1",3. Main Results,[0],[0]
"− δn 32)+ 16ε , (6) where
∆(g)(x) = n∑ k=1 d2g dx2k , (7)
is the Laplacian of g and where a+ = max(a, 0).
",3. Main Results,[0],[0]
"For instance, approximating
g(x1, x2) = 10x 2 1 + x 2 1x 2 2 + 10x 2 2
over [0, 1]2 requires logt ( 0.82√ ε ) hidden units—combine Theorem 2 with Lemma 1.
",3. Main Results,[0],[0]
"Whether it is Theorem 1 or Theorem 2 which provides a better approximation bound depends on g. For instance, for g1(x1, x2) = 20x 2 1 − 2x22 + x21x22",3. Main Results,[0],[0]
Theorem 1 gives a trivial (zero) lower bound since the two eigenvalues of the Hessian matrix ∇2(g1) have always different signs.,3. Main Results,[0],[0]
"Theorem 2 instead gives 0.737√
ε .",3. Main Results,[0],[0]
"On the other hand, for g2(x1, x2) =
10x21 + 10x 2 2 + x 2 1x 2 2 Theorem 1 gives 1.37√ ε as lower bound while Theorem 2 gives 0.82√
ε .
",3. Main Results,[0],[0]
The next theorem quantifies the effect of a change of activation function on the output of the neural network.,3. Main Results,[0],[0]
"Here, the activation functions need not be piece-wise affine.
",3. Main Results,[0],[0]
Theorem 3.,3. Main Results,[0],[0]
Let f1 ∈ Fσ1 and f2 ∈ Fσ2 be two neural networks with identical architectures and weights.,3. Main Results,[0],[0]
"Suppose that σ1 is a δ-Lipschitz continuous function and suppose that the weights belong to some bounded interval [−A,+A], A > 0.",3. Main Results,[0],[0]
"Then,
||f1−f2||∞ ≤ ||σ1",3. Main Results,[0],[0]
"− σ2||∞
δ
(( δ ·A·ωf+1 )df −1 ) .",3. Main Results,[0],[0]
"(8)
3E.g., for J = (2, 1) we have DJ(g(x1, x2))",3. Main Results,[0],[0]
"= ∂ 3g
∂2x1∂x2 .
",3. Main Results,[0],[0]
"A slightly weaker version of (8) is
||f1 − f2||∞ ≤ ||σ1",3. Main Results,[0],[0]
"− σ2||∞
L
(( L2 · ωf + 1 )df − 1 ) ,
where L = max{A, δ} denotes the Lipschitz-bound defined in (DasGupta & Schnitger, 1993).
",3. Main Results,[0],[0]
"As an illustration of Theorem 3 consider a feedforward neural network f1 with 100 hidden units, a maximum depth of 5, and the sigmoid as activation function.",3. Main Results,[0],[0]
"Suppose the weights belong to interval [−1, 1].",3. Main Results,[0],[0]
"Replacing the sigmoid with a 32-bit quantized function results in an error of at most 0.0001—which can readily be obtained from Theorem 3 with δ = 14 , A = 1, ||σ1 − σ2||∞ = 2 −32.",3. Main Results,[0],[0]
Consider first the inequality (2).,4. Comparison with Previous Works,[0],[0]
"Restricting attention to neural networks with d hidden layers, at most ω units per layer, and where connections are allowed only between neighbouring layers, this inequality gives
B̄x→y(f) ≤",4. Comparison with Previous Works,[0],[0]
( (t− 1)ω + 1 )d .,4. Comparison with Previous Works,[0],[0]
"(9)
This is to be compared with the previously best known bound (Lemma 3.2 in (Telgarsky, 2016))
2(2(t− 1)ω)d
which is larger by a multiplicative factor that is exponential in d whenever ω > 1, t ≥ 2.",4. Comparison with Previous Works,[0],[0]
"For n = 1, Lemma 2.1 in (Telgarsky, 2015) gives (tω)d which still differs from (9) by a multiplicative factor that is exponential is d for ω > 1, t ≥ 2.
",4. Comparison with Previous Works,[0],[0]
"For general feedforward neural networks the previously best known bound (see Lemma 4 of (Yarotsky, 2017)) was
B̄x→y(f) ≤ ( t · ω · df )df which is a multiplicative factor df df larger than (2).
",4. Comparison with Previous Works,[0],[0]
Now consider the approximation power of neural networks in terms of number of hidden units required to approximate a given function within a given error.,4. Comparison with Previous Works,[0],[0]
"Theorem 11 in (Liang & Srikant, 2017) states that to approximate a function [0, 1]n → R, assumed to be differentiable and strongly convex with parameter µ, with a neural network f requires
|Hf | ≥ 1
2 log2 ( µ 16ε ) ,
regardless of the dimension n. Corollary 2 improves this bound to
1 2 log2 (µ · n 16ε )
which incorporates dimension as well—albeit the dependency on dimension is arguably small.
",4. Comparison with Previous Works,[0],[0]
"Corollary 3 provides a lower bound for ReLU types of networks in terms of the error, the depth, and a constant term which only depends on g. This bound can be compared with the bound of Theorem 6 in (Yarotsky, 2017) which is of order − 12df .4",4. Comparison with Previous Works,[0],[0]
"Hence, Corollary 3 provides a linear (in df ) improvement which is particularly relevant in the deep regime where df = Ω(log(1/ε)).",4. Comparison with Previous Works,[0],[0]
"Table 1 summarizes the above discussion.
",4. Comparison with Previous Works,[0],[0]
To the best of our knowledge Theorem 3 is the first result to bound the effect of a change in the activation function for given network topology and weights.,4. Comparison with Previous Works,[0],[0]
"Noteworthy perhaps, this bound is essentially universal in the weights since it only depends on their range.
",4. Comparison with Previous Works,[0],[0]
"Finally, compared to the cited papers it should perhaps be stressed that the proofs here (see next section) are relatively elementary—e.g., they do not hinge on VC dimension analysis—and hold true for general feedforward networks.",4. Comparison with Previous Works,[0],[0]
We first establish a few lemmas to prove Proposition 1 which will provide an upper bound on the number of break points.,5. Analysis,[0],[0]
Then we establish Propositions 2 and 3 which will give lower bounds on the number of break points in terms of the approximation error.,5. Analysis,[0],[0]
Combining these propositions will give Theorems 1 and 2.,5. Analysis,[0],[0]
"Finally, we prove Theorem 3.
",5. Analysis,[0],[0]
Definition 4 (Intermediate set of units).,5. Analysis,[0],[0]
"Given f ∈ Fσ and 4Theorem 6 of (Yarotsky, 2017) provides a bound of the form q − 1
2df where q is a constant that depends on both g and df .",5. Analysis,[0],[0]
"However, a close inspection of the proof of this theorem reveals that q depends only on g.
U ⊆ Hf we define the set of hidden units that lie on a path between the input and U as
in(U) def=",5. Analysis,[0],[0]
{ v ∈,5. Analysis,[0],[0]
Hf\U|∃i ∈,5. Analysis,[0],[0]
"If , u ∈ U s.t. v ∈",5. Analysis,[0],[0]
"(i→ u) } where (i→ u) denotes the set of intermediate hidden nodes on the path from i to u.
For instance, in Fig. 1 we have
in({u32}) = {u11, u12, u21, u23}.
",5. Analysis,[0],[0]
"The following lemma follows from the above definition.
",5. Analysis,[0],[0]
Lemma 2.,5. Analysis,[0],[0]
"Given U ⊆ Hf we have
in(in(U) = ∅
and in(u) ⊆ (U ∪ in(U))
for any u ∈ U .",5. Analysis,[0],[0]
Definition 5 (State).,5. Analysis,[0],[0]
"Any σ ∈ Σt partitions the real line (its input) into t intervals I1, I2, ...,",5. Analysis,[0],[0]
It such that on each of these intervals σ is affine.,5. Analysis,[0],[0]
"The state of a unit with activation function σ is defined to be s ∈ {1, 2, . . .",5. Analysis,[0],[0]
", t} if its input belongs to Is.",5. Analysis,[0],[0]
"By extension, the state of U ⊆ Hf is defined to be the vector of length |U| whose components are the state of each unit in U .
",5. Analysis,[0],[0]
"The following definition is inspired by the notion of pattern transition introduced in (Raghu et al., 2017):
Definition 6 (Transition).",5. Analysis,[0],[0]
"Let f ∈ Fσ , U ⊆ Hf and x,y ∈ R. Let zα = (1 − α)x + αy be a parametrization of the line segment [x,y] as α goes from 0 to 1.",5. Analysis,[0],[0]
"We say that the state of U experiences a transition at point zα∗ for some α∗ ∈ (0, 1] if the state vector of U changes at zα∗ while the state vector of in(U) does not change at zα∗ .",5. Analysis,[0],[0]
The number of state transitions of U on the segment,5. Analysis,[0],[0]
"[x,y], denoted by Nx→y(U), is defined to be the number of state transitions of U as the input changes from x to y on zα.",5. Analysis,[0],[0]
"If in(U) = ∅, then Nx→y(U) is defined to be the number of state transitions of U as the input changes from x to y.
Note that if the state vectors of both U and in(U) change atα, Nx→y(U) does not change at that α.",5. Analysis,[0],[0]
"For example, consider the neural network f in Fig. 1.",5. Analysis,[0],[0]
"Suppose that U = {u11, u12} and suppose that the state of u11 and u12 changes exactly once along segment zα for some x and y, respectively at α1 and α2.",5. Analysis,[0],[0]
Then Nx→y({u11}) = 1 and Nx→y({u12}) = 1.,5. Analysis,[0],[0]
"If α1 = α2, Nx→y(U) = 1, otherwise Nx→y(U) = 2.",5. Analysis,[0],[0]
"If U ′ = {u21, u22, u23}, and the state of each of u21, u22 and u23 changes exactly once at either α1 or α2, then Nx→y(U ′) = 0 since the state vector of in(U ′)",5. Analysis,[0],[0]
"= U has also changed at both α1 and α2.
",5. Analysis,[0],[0]
Lemma 3.,5. Analysis,[0],[0]
"Given f ∈ Fσ and U1,U2 ⊆ Hf such that in(U2) = ∅ and in(U1)",5. Analysis,[0],[0]
"⊆ U2, we have
Nx→y ( U1 ∪ U2 ) ≤ Nx→y",5. Analysis,[0],[0]
( U1 ) +Nx→y,5. Analysis,[0],[0]
"( U2 ) .
",5. Analysis,[0],[0]
Proof.,5. Analysis,[0],[0]
Suppose Nx→y ( U1 ∪ U2 ) increases by one at α = α∗.,5. Analysis,[0],[0]
"If U2 undergoes a state transition at α∗ then, because in(U2) = ∅, we have that Nx→y ( U2 )
also increases by one at α∗. Instead, if no state change happens in U2 at α∗ then, due to the state change of U1∪U2 at α∗, the state of U1 must change as well at α∗. Since in(U1) ⊆ U2 and no change in the state of U2 is observed at α∗ we have that Nx→y ( U1 ) necessarily increases by one at α∗.
Lemma 4.",5. Analysis,[0],[0]
"Given f ∈ Fσ and U1,U2 ⊆ Hf such that U1 ⊆ U2 and in(U2) =",5. Analysis,[0],[0]
"∅ we have
Nx→y ( U1 ) ≤",5. Analysis,[0],[0]
Nx→y,5. Analysis,[0],[0]
"( U2 ) .
",5. Analysis,[0],[0]
Proof.,5. Analysis,[0],[0]
"Suppose Nx→y ( U1 )
increases by one at α∗. Since U1 ⊆ U2 the state of U2 changes as well at α∗. Since in(U2) = ∅",5. Analysis,[0],[0]
"we deduce that Nx→y ( U2 )
increases at α∗ by one, thereby concluding the proof.
",5. Analysis,[0],[0]
Lemma 5.,5. Analysis,[0],[0]
"Given f ∈ Fσ , for any U ⊆ Hf we have
Nx→y(U) ≤ ∑ u∈U Nx→y(u).
",5. Analysis,[0],[0]
Proof.,5. Analysis,[0],[0]
Suppose that Nx→y(U) increases by one at α∗. Let V ⊆ U be the set of units that experience a transition at α∗. Since we have a transition in the state of U at α∗ we have V 6= ∅.,5. Analysis,[0],[0]
"Now, because the neural network is cycle-free,5 there exists some v ∈ V such that in(v) ∩ V = ∅.",5. Analysis,[0],[0]
We claim that the state of in(v) has not changed at α∗. To prove this note that by Lemma 2 we have in(v) ⊆ in(U)∪U and since in(v) ∩ V = ∅,5. Analysis,[0],[0]
we deduce that in(v) ⊆ (in(U) ∪ U\V).,5. Analysis,[0],[0]
On the other hand neither U\V nor in(U) has a transition at α∗.,5. Analysis,[0],[0]
This implies that in(v) has no transition at α∗ and therefore Nx→y(v) increases by one at α∗.,5. Analysis,[0],[0]
"This concludes the proof since v ∈ U .
",5. Analysis,[0],[0]
Lemma 6.,5. Analysis,[0],[0]
"Given f ∈ Fσ , for any u ∈",5. Analysis,[0],[0]
"Hf we have
Nx→y(u) ≤ (t− 1) ( Nx→y(in(u))",5. Analysis,[0],[0]
"+ 1 ) .
",5. Analysis,[0],[0]
Proof.,5. Analysis,[0],[0]
"To establish the lemma we show that between transitions of in(u) there are at most t− 1 transitions of u.
5Recall that throughout the paper neural networks are feedforward.
",5. Analysis,[0],[0]
"Suppose, by way of contradiction, that at least t transitions in the state of u happen while in(u) experiences no change.",5. Analysis,[0],[0]
"Then there exists an increasing sequence of real numbers α1, ..., αt+1 from interval [0, 1] and an increasing set of integers k1, k2, ..., kt+1 from S = {1, 2, ..., t}, with ki 6= ki+1, such that for particular w ∈",5. Analysis,[0],[0]
"Rn and b ∈ R we have
xi def = (1− αi)x + αiy
w · xi + b ∈ Iki where Ii is defined in Definition 5.",5. Analysis,[0],[0]
Since |S| = t there exists i < j such that ki = kj .,5. Analysis,[0],[0]
Now since ki 6= ki+1,5. Analysis,[0],[0]
we deduce that j 6=,5. Analysis,[0],[0]
i + 1 and therefore j >,5. Analysis,[0],[0]
i + 1.,5. Analysis,[0],[0]
But w · xi+1,5. Analysis,[0],[0]
+ b lies between w · xi + b and w · xj,5. Analysis,[0],[0]
"+ b since the sequence α1, α2, ..., αt+1 is increasing.",5. Analysis,[0],[0]
"Since w ·xj+b and w ·xi+b belong to Iki , by the connectedness property of the set Ii we deduce that that w · xi+1 + b ∈ Ii.",5. Analysis,[0],[0]
"Therefore, we get ki = ki+1",5. Analysis,[0],[0]
"= kj , a contradiction.
",5. Analysis,[0],[0]
Since a break point of f ∈ Fσ necessarily implies a change in the state of the units we get: Lemma 7.,5. Analysis,[0],[0]
"Given (x,y) ∈ R2 and f ∈ Fσ we have
Bx→y(f) ≤",5. Analysis,[0],[0]
"Nx→y(Hf ).
",5. Analysis,[0],[0]
Propositions 1 and 2 establish inequalities (2) and (3) of Theorem 1.,5. Analysis,[0],[0]
Proposition 1.,5. Analysis,[0],[0]
"Given f ∈ Fσ ,",5. Analysis,[0],[0]
"σ ∈ Σt, we have
Bx→y(f) ≤",5. Analysis,[0],[0]
"(( t− 1 ) ωf + 1 )df − 1. (10)
Proof of Proposition 1.",5. Analysis,[0],[0]
Fix f ∈ Fσ where σ ∈,5. Analysis,[0],[0]
Σt.,5. Analysis,[0],[0]
"Referring to Definition 1, consider the partition
∪di=1Hif ofHf according to unit depth where d = df .
",5. Analysis,[0],[0]
Fix u ∈,5. Analysis,[0],[0]
"Hi+1f , 0 ≤",5. Analysis,[0],[0]
i < d.,5. Analysis,[0],[0]
"From the definitions of in(u) andHif we get
in(u) ⊆ i⋃
j=1
Hjf (11)
in ( Hi+1f ) ⊆ i⋃ j=1 Hjf
in ( i⋃ j=1 Hjf ) = ∅.
Applying Lemma 3 with U1 = Hi+1f and U2 = i⋃
j=1
Hjf we
get
Nx→y( i+1⋃ j=1 Hjf )",5. Analysis,[0],[0]
"≤ Nx→y( i⋃ j=1 Hjf ) +Nx→y(H i+1 f ).
",5. Analysis,[0],[0]
"From Lemma 5
Nx→y( i+1⋃ j=1 Hjf ) ≤ Nx→y( i⋃ j=1 Hjf ) + ∑
u∈Hi+1f
Nx→y(u)
and applying Lemma 6 to the previous inequality
Nx→y(",5. Analysis,[0],[0]
"i+1⋃ j=1 Hjf ) ≤ Nx→y( i⋃ j=1 Hjf )
+ ∑
u∈Hi+1f
( t− 1 )( Nx→y ( in(u) )",5. Analysis,[0],[0]
"+ 1 ) .
",5. Analysis,[0],[0]
"Then, using (11) and Lemma 4 we get
Nx→y( i+1⋃ j=1 Hjf )
≤",5. Analysis,[0],[0]
"Nx→y( i⋃
j=1
Hjf ) + ∑
u∈Hi+1f
( t− 1 )( Nx→y ( i⋃ j=1 Hjf ) + 1 )
= ( ωi+1(t− 1) + 1 ) Nx→y( i⋃ j=1 Hjf ) + ωi+1(t− 1).
(12)
",5. Analysis,[0],[0]
For u ∈,5. Analysis,[0],[0]
H1f,5. Analysis,[0],[0]
we have in(u) =,5. Analysis,[0],[0]
∅ and according to Lemma 6 we deduce that Nx→y(H1f ) ≤,5. Analysis,[0],[0]
(t− 1)ω1.,5. Analysis,[0],[0]
"With this initial condition and the recursive relation in (12) we get
Nx→y( d⋃ j=1 Hjf )
≤ d∑ j=1 ( ∏ 1≤α1<α2<...<αj≤d ωα1ωα2 · · ·ωαj ( t− 1 )j) ≤ d∑ j=1 ((d j )( ωf (t− 1) )j) =",5. Analysis,[0],[0]
( ωf (t− 1) + 1 )d,5. Analysis,[0],[0]
"− 1
with ωf as width of f .",5. Analysis,[0],[0]
"Finally, apply Lemma 7 to obtain
Bx→y(f) ≤",5. Analysis,[0],[0]
"(( t− 1 ) ωf + 1 )df − 1.
",5. Analysis,[0],[0]
Proposition 2.,5. Analysis,[0],[0]
Let R be a convex region in Rn.,5. Analysis,[0],[0]
For any affine ε-approximation f : R → R of a function g ∈ C2(R),5. Analysis,[0],[0]
"we have
Bx→y(f) ≥ ||x− y||2
4 √ ε ·Ψ(g,x,y)− 1 (13)
where Ψ(g,x,y) is defined in (4).
",5. Analysis,[0],[0]
Proof of Proposition 2.,5. Analysis,[0],[0]
"We partition R into convex subregionsRi, such that in each subregion f(x) is an affine function.",5. Analysis,[0],[0]
These convex subregions partition a segment,5. Analysis,[0],[0]
"[x,y] into sub-segments with end points { x0,x1, ...,xs } , where
x0 = x,xs = y and s = Bx→y(f)+1.",5. Analysis,[0],[0]
"In the sub-segment i ∈ {0, 1, ..., s− 1},
f(x) = pi.x + qi, x ∈",5. Analysis,[0],[0]
"[xi,xi+1], (14)
for some pi and qi.",5. Analysis,[0],[0]
Let xi(r) =,5. Analysis,[0],[0]
"(1 − r)xi + rxi+1, r ∈",5. Analysis,[0],[0]
"[0, 1], and define
fi(r) = (1− r)g(xi) + rg(xi+1), hi(r)",5. Analysis,[0],[0]
"= g ( xi(r) ) ,
li(r) = f(x(r)).
",5. Analysis,[0],[0]
"From the definition of ε-approximation, ||hi(r)−li(r)||∞ ≤ ε.",5. Analysis,[0],[0]
"Thus
||fi(r)−hi(r)||∞ ≤ ||fi(r)−",5. Analysis,[0],[0]
li(r)||∞ + ||li(r)−,5. Analysis,[0],[0]
"hi(r)||∞ (a) ≤ max { |fi(0)− li(0)|, |fi(1)− li(1)| } + ε
≤ 2ε, (15)
where ||k(r)||∞ = sup 0≤r≤1 k(r) and step (a) follows because fi(r) and li(r) are both line segments and the maximum distance between them is achieved at end points.
",5. Analysis,[0],[0]
"As h(r) on (0, 1) is differentiable so there exists r∗i ∈ (0, 1) such that h′i(r ∗ i ) = hi(1) − hi(0).",5. Analysis,[0],[0]
Consider x∗i = (1 − r∗i )xi + r ∗ i xi+1.,5. Analysis,[0],[0]
"From (15) we obtain
|(1− r∗i ) ( g(xi)− g(xi+1) )",5. Analysis,[0],[0]
"− g(x∗i ) + g(xi+1)| ≤ 2ε,
|r∗i ( g(xi+1)− g(xi) )",5. Analysis,[0],[0]
"+ g(xi)− g(x∗i )| ≤ 2ε.
",5. Analysis,[0],[0]
"Then, from the definition of r∗i we have
|(r∗i − 1)∇g(x∗i ).(xi+1",5. Analysis,[0],[0]
− xi)− g(x∗i ) +,5. Analysis,[0],[0]
"g(xi+1)| ≤ 2ε (16)
|r∗i∇g(x∗i ).(xi+1",5. Analysis,[0],[0]
− xi)− g(x∗i ) +,5. Analysis,[0],[0]
g(xi)| ≤,5. Analysis,[0],[0]
2ε.,5. Analysis,[0],[0]
"(17) Since g ∈ C2(R) a Taylor expansion of g(xi) and g(xi+1) around x∗i gives
g(xi)",5. Analysis,[0],[0]
= g(x ∗,5. Analysis,[0],[0]
i ),5. Analysis,[0],[0]
− r∗i∇g ( x∗i ) .(xi+1,5. Analysis,[0],[0]
"− xi)
+ r∗i 2
2 (xi+1",5. Analysis,[0],[0]
"− xi)T∇2g
( xi(αi) )",5. Analysis,[0],[0]
"(xi+1 − xi),
g(xi+1) =",5. Analysis,[0],[0]
g(x ∗,5. Analysis,[0],[0]
i ),5. Analysis,[0],[0]
+ (1− r∗i )∇g,5. Analysis,[0],[0]
( x∗i ) .(xi+1,5. Analysis,[0],[0]
"− xi)
+ (1− r∗i ) 2
2 (xi+1",5. Analysis,[0],[0]
"− xi)T∇2g
( xi(βi) )",5. Analysis,[0],[0]
"(xi+1 − xi),
where 0 ≤ αi ≤ r∗i ≤ βi ≤ 1.
",5. Analysis,[0],[0]
"Substituting the above relations in inequalities (16) and (17) we get
|(1− r∗i ) 2 (xi+1",5. Analysis,[0],[0]
− xi)T∇2g ( xi(βi) ),5. Analysis,[0],[0]
(xi+1,5. Analysis,[0],[0]
− xi)| ≤,5. Analysis,[0],[0]
"4ε,
(18)
|r∗i 2(xi+1",5. Analysis,[0],[0]
− xi)T∇2g,5. Analysis,[0],[0]
( xi(αi) ),5. Analysis,[0],[0]
(xi+1 − xi)| ≤,5. Analysis,[0],[0]
4ε.,5. Analysis,[0],[0]
"(19)
Use the Rayleigh quotient and the definitions of θ(α), γ(α) to obtain
| (xi+1",5. Analysis,[0],[0]
"− xi)T∇2g
( xi(αi) )",5. Analysis,[0],[0]
"(xi+1 − xi)
(xi+1",5. Analysis,[0],[0]
"− xi)T (xi+1 − xi) |
≥ inf 0≤α≤1
( max { 0, θ(α)γ(α) }) .
",5. Analysis,[0],[0]
"Combining the above inequality with (18) and (19) and the fact that r∗i 2 + (1− r∗i )2 ≥ 12 we get
||xi+1",5. Analysis,[0],[0]
"− xi||22. inf 0≤α≤1
( max { 0, θ(α)γ(α) }) ≤ 16ε.
",5. Analysis,[0],[0]
"Accordingly, s−1∑ i=0 ( ||xi+1 − xi||2 4 √ ε .",5. Analysis,[0],[0]
"√ inf 0≤α≤1 ( max { 0, θ(α)γ(α) }))",5. Analysis,[0],[0]
"≤ s,
which gives
Bx→y(f) ≥ ||x− y||2
4 √ ε Ψ(g,x,y)− 1.
",5. Analysis,[0],[0]
Proposition 3.,5. Analysis,[0],[0]
"Let g : [0, 1]n → R be such that DJ(g)(x) ≤ δ for any x ∈",5. Analysis,[0],[0]
"[0, 1]n and any multi-index J such that |J | = 3.",5. Analysis,[0],[0]
"Then, for any affine ε-approximation f
Bx→y(f) ≥
√√√√( max x∈[0,1]n ∣∣∆(g)(x)∣∣ ·",5. Analysis,[0],[0]
n−1,5. Analysis,[0],[0]
− δ · n 32)+ 16ε,5. Analysis,[0],[0]
"− 1
for any x,y ∈",5. Analysis,[0],[0]
"[0, 1]n, where ∆ denotes the Laplace operator (7).
",5. Analysis,[0],[0]
Proof of Proposition 3.,5. Analysis,[0],[0]
"Define
z def = arg max x∈R ρ ( ∇2g(x) ) where ρ(·) denotes the spectral radius.",5. Analysis,[0],[0]
"Let u be a normalized eigenvector corresponding to an eigenvalue λ where |λ| = ρ ( ∇2g(z) ) , i.e.,
∇2g(z)u = λu, ||u|| = 1. (20)
Consider any segment [x,y] in R in the direction of u, i.e., such that x− y = u.",5. Analysis,[0],[0]
"The convex subregions of f , defined in the proof of Proposition 2, divide this segment into sub-segments with end points {x0,x1, ...,xs} where x0 = x,xs = y and s = Bx→y(f) + 1.",5. Analysis,[0],[0]
"Using the same
analysis as in the proof of Proposition 2, from (14)–(19) we obtain (18) and (19).",5. Analysis,[0],[0]
"On the other hand, note that
|(xi+1",5. Analysis,[0],[0]
− xi)T∇2g ( xi(αi) ),5. Analysis,[0],[0]
"(xi+1 − xi)|
≥ |(xi+1 − xi)T∇2g ( z ) (xi+1",5. Analysis,[0],[0]
"− xi)|
− |(xi+1",5. Analysis,[0],[0]
− xi)T ( ∇2g ( xi(αi) ),5. Analysis,[0],[0]
−∇2,5. Analysis,[0],[0]
g ( z )),5. Analysis,[0],[0]
"(xi+1 − xi)|
= |λ| · ||xi+1",5. Analysis,[0],[0]
− xi||2,5. Analysis,[0],[0]
− ∣∣tr{(∇2g(xi(αi))−∇2g(z))(xi+1 − xi)(xi+1,5. Analysis,[0],[0]
"− xi)T}∣∣
(a) ≥ |λ| · ||xi+1",5. Analysis,[0],[0]
− xi||2 − ∣∣∣∣∇2g(xi(αi))−∇2g(z)∣∣∣∣F∣∣∣∣(xi+1 − xi)(xi+1,5. Analysis,[0],[0]
− xi)T ∣∣∣∣F = |λ| · ||xi+1,5. Analysis,[0],[0]
"− xi||2
− ∣∣∣∣∇2g(xi(αi))−∇2g(z)∣∣∣∣F||xi+1 − xi||2
= ||xi+1",5. Analysis,[0],[0]
− xi||2 · ( |λ| − nδ · ||z − xi(αi)|| ),5. Analysis,[0],[0]
≥ ||xi+1,5. Analysis,[0],[0]
"− xi||2 · ( |λ| − δ · n 32 ) ,
where in step (a) we used the inequality∣∣∣tr(AB)∣∣∣ ≤ ||A||F ||B||F , || · ||F stands for Frobenius norm.
",5. Analysis,[0],[0]
"Combining the above relation with (18), (19) and the fact that r∗i 2 + (1− r∗i )2 ≥ 12 we get
16ε ≥ ||xi+1",5. Analysis,[0],[0]
"− xi||2 · ( |λ| − δ · n 32 ) ,
which gives
4 √ ε · ( Bx→y(f) + 1 ) ≥ ||x− y|| · √( |λ| − δ · n 32 )+ .
",5. Analysis,[0],[0]
"Finally, rewriting the above inequality we get
Bx→y(f) ≥ 1 4 √ ε · √( |λ| − δ · n 32 )+",5. Analysis,[0],[0]
"− 1.
",5. Analysis,[0],[0]
Since |λ| = ρ ( ∇2g(z) ),5. Analysis,[0],[0]
"= max x∈[0,1]n ρ ( ∇2g(x) ) and
|∆(g)(x)| = |tr(∇2g(x))| ≤ ρ(∇2g(x)) · n,
we obtain the desired result.
",5. Analysis,[0],[0]
"Proofs of Theorems 1 and 2
Propositions 1 and 2 give Theorem 1 and Propositions 1 and 3 give Theorem 2.
",5. Analysis,[0],[0]
"Proof of Theorem 3
Given a neural network f we use o to denote the output unit, w(u, v) to denote the weight of two connected units u and
v, and b(u) to denote the bias of unit u. Furthermore, given u ∈",5. Analysis,[0],[0]
"Hf and x ∈ R let fu1 (x) denote the output of unit u when the input to f1 is x, and similarly for f2(x).",5. Analysis,[0],[0]
"Finally, define the maximum change in hidden layer i as
εi(x) def = max
u∈Hif
{ |fu1 (x)− fu2 (x)| } .
",5. Analysis,[0],[0]
Fix 1 ≤,5. Analysis,[0],[0]
i ≤,5. Analysis,[0],[0]
df,5. Analysis,[0],[0]
− 1 and v ∈,5. Analysis,[0],[0]
Hi+1f .,5. Analysis,[0],[0]
"Then,∣∣fv1 (x)− fv2 (x)∣∣ =
∣∣∣∣∣σ1( ∑ u∈
i⋃ j=1 Hjf
w(u, v) ·",5. Analysis,[0],[0]
"fu1 (x) + b(v) )
",5. Analysis,[0],[0]
"− σ2 ( ∑ u∈
i⋃ j=1 Hjf
w(u, v) ·",5. Analysis,[0],[0]
"fu2 (x) + b(v) )∣∣∣∣∣
≤",5. Analysis,[0],[0]
"ε+ δ · ( ∑ u∈
i⋃ j=1 Hjf
|w(u, v)| · ∣∣fu1",5. Analysis,[0],[0]
"(x)− fu2 (x)∣∣)
≤ ε+ δA · ( i∑ j=1 ∑ u∈Hjf ∣∣fu1 (x)− fu2 (x)∣∣)
≤ ε+ δA · ( i∑ j=1 ωjεj(x) )
where the first inequality holds since σ1 is δ-Lipschitz and assuming that ||σ1−σ2||∞ ≤ ε.",5. Analysis,[0],[0]
"Hence we get the recursion between εi’s
εi+1(x) ≤ ε+ δA · ( i∑ j=1 ωjεj(x) )
(21)
for 1 ≤",5. Analysis,[0],[0]
i ≤,5. Analysis,[0],[0]
df,5. Analysis,[0],[0]
− 1.,5. Analysis,[0],[0]
"Now, since ε1(x) ≤",5. Analysis,[0],[0]
∣∣σ1(x)− σ2(x)∣∣ we get ε1(x) ≤ ε.,5. Analysis,[0],[0]
"From this initial condition and (21)
εi+1(x) ≤",5. Analysis,[0],[0]
ε(1 + δAω1)(1,5. Analysis,[0],[0]
+ δAω2) · · · (1 + δAωi).,5. Analysis,[0],[0]
"(22)
On the other hand we have |f1(x)− f2(x)| = ∣∣∣ ∑ u∈
df⋃ j=1 Hjf
w(u, o) · ( fu1 (x)− fu2 (x) )∣∣∣ ≤",5. Analysis,[0],[0]
"A ( ε1(x)ω1 + ε2(x)ω2 + ...+ εd(x)ωdf
) and from (22) we finally get
|f1(x)− f2(x)|
≤ ε δ
( (1 + δAω1)(1 + δAω2)...",5. Analysis,[0],[0]
(1 + δAωdf ),5. Analysis,[0],[0]
− 1 ) ≤ ||σ1,5. Analysis,[0],[0]
"− σ2||∞
δ
(( δ ·A · ωf + 1 )df − 1 ) which gives the desired result.",5. Analysis,[0],[0]
The approximation power of general feedforward neural networks with piecewise linear activation functions is investigated.,abstractText,[0],[0]
"First, lower bounds on the size of a network are established in terms of the approximation error and network depth and width.",abstractText,[0],[0]
"These bounds improve upon stateof-the-art bounds for certain classes of functions, such as strongly convex functions.",abstractText,[0],[0]
"Second, an upper bound is established on the difference of two neural networks with identical weights but different activation functions.",abstractText,[0],[0]
Bounds on the Approximation Power of Feedforward Neural Networks,title,[0],[0]
"showed that momentum can be used to accelerate the rate of convergence for block GaussSeidel in the setting where a fixed partitioning of the coordinates is chosen ahead of time. We show that this setting is too restrictive, constructing instances where breaking locality by running non-accelerated Gauss-Seidel with randomly sampled coordinates substantially outperforms accelerated Gauss-Seidel with any fixed partitioning. Motivated by this finding, we analyze the accelerated block Gauss-Seidel algorithm in the random coordinate sampling setting. Our analysis captures the benefit of acceleration with a new data-dependent parameter which is well behaved when the matrix subblocks are well-conditioned. Empirically, we show that accelerated Gauss-Seidel with random coordinate sampling provides speedups for large scale machine learning tasks when compared to non-accelerated Gauss-Seidel and the classical conjugate-gradient algorithm.",text,[0],[0]
The randomized Gauss-Seidel method is a commonly used iterative algorithm to compute the solution of an n× n linear system Ax = b by updating a single coordinate at a time in a randomized order.,1. Introduction,[0],[0]
"While this approach is known to converge linearly to the true solution when A is positive definite (see e.g. (Leventhal & Lewis, 2010)), in practice it is often more efficient to update a small block of coordinates at a time due to the effects of cache locality.
",1. Introduction,[0],[0]
"In extending randomized Gauss-Seidel to the block setting, a natural question that arises is how one should sample the next block.",1. Introduction,[0],[0]
"At one extreme a fixed partition of the coordi-
1UC Berkeley, Berkeley, California, USA 2Rensselaer Polytechnic Institute, Troy, New York, USA.",1. Introduction,[0],[0]
"Correspondence to: Stephen Tu <stephent@berkeley.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
nates is chosen ahead of time.,1. Introduction,[0],[0]
"The algorithm is restricted to randomly selecting blocks from this fixed partitioning, thus favoring data locality.",1. Introduction,[0],[0]
"At the other extreme we break locality by sampling a new set of random coordinates to form a block at every iteration.
",1. Introduction,[0],[0]
"Theoretically, the fixed partition case is well understood both for Gauss-Seidel (Qu et al., 2015; Gower & Richtárik, 2015) and its Nesterov accelerated variant (Nesterov & Stich, 2016).",1. Introduction,[0],[0]
"More specifically, at most O(µ−1part log(1/ε))",1. Introduction,[0],[0]
"iterations of Gauss-Seidel are sufficient to reach a solution with at most ε error, where µpart is a quantity which measures how well the A matrix is preconditioned by the block diagonal matrix containing the sub-blocks corresponding to the fixed partitioning.",1. Introduction,[0],[0]
"When acceleration is used, Nesterov and Stich (2016) show that the rate improves to O (√
n",1. Introduction,[0],[0]
"pµ −1 part log(1/ε)
)
, where p is the partition size.
",1. Introduction,[0],[0]
"For the random coordinate selection model, the existing literature is less complete.",1. Introduction,[0],[0]
"While it is known (Qu et al., 2015; Gower & Richtárik, 2015) that the iteration complexity with random coordinate section is O(µ−1rand log(1/ε)) for an ε error solution, µrand is another instance dependent quantity which is not directly comparable to µpart.",1. Introduction,[0],[0]
"Hence it is not obvious how much better, if at all, one expects random coordinate selection to perform compared to fixed partitioning.
",1. Introduction,[0],[0]
"Our first contribution in this paper is to show that, when compared to the random coordinate selection model, the fixed partition model can perform very poorly in terms of iteration complexity to reach a pre-specified error.",1. Introduction,[0],[0]
"Specifically, we present a family of instances (similar to the matrices recently studied by Lee and Wright (2016)) where nonaccelerated Gauss-Seidel with random coordinate selection performs arbitrarily faster than both non-accelerated and even accelerated Gauss-Seidel, using any fixed partition.",1. Introduction,[0],[0]
"Our result thus shows the importance of the sampling strategy and that acceleration cannot make up for a poor choice of sampling distribution.
",1. Introduction,[0],[0]
This finding motivates us to further study the benefits of acceleration under the random coordinate selection model.,1. Introduction,[0],[0]
"Interestingly, the benefits are more nuanced under this model.",1. Introduction,[0],[0]
"We show that acceleration improves the rate from
O(µ−1rand log(1/ε)) to O
(
√
νµ−1rand log(1/ε)
)
, where ν is
a new instance dependent quantity that satisfies ν ≤ µ−1rand.",1. Introduction,[0],[0]
"We derive a bound on ν which suggests that if the subblocks of A are all well conditioned, then acceleration can provide substantial speedups.",1. Introduction,[0],[0]
"We note that this is merely a sufficient condition, and our experiments suggest that our bound is conservative.
",1. Introduction,[0],[0]
"In the process of deriving our results, we also develop a general proof framework for randomized accelerated methods based on Wilson et al. (2016) which avoids the use of estimate sequences in favor of an explicit Lyapunov function.",1. Introduction,[0],[0]
"Using our proof framework we are able to recover recent results (Nesterov & Stich, 2016; Allen-Zhu et al., 2016) on accelerated coordinate descent.",1. Introduction,[0],[0]
"Furthermore, our proof framework allows us to immediately transfer our results on Gauss-Seidel over to the randomized accelerated Kaczmarz algorithm, extending a recent result by Liu and Wright (2016) on updating a single constraint at a time to the block case.
",1. Introduction,[0],[0]
"Finally, we empirically demonstrate that despite its theoretical nuances, accelerated Gauss-Seidel using random coordinate selection can provide significant speedups in practical applications over Gauss-Seidel with fixed partition sampling, as well as the classical conjugate-gradient (CG) algorithm.",1. Introduction,[0],[0]
"As an example, for a kernel ridge regression (KRR) task in machine learning on the augmented CIFAR10 dataset (n = 250, 000), acceleration with random coordinate sampling performs up to 1.5× faster than acceleration with a fixed partitioning to reach an error tolerance of 10−2, with the gap substantially widening for smaller error tolerances.",1. Introduction,[0],[0]
"Furthermore, it performs over 3.5× faster than conjugate-gradient on the same task.",1. Introduction,[0],[0]
"We assume that we are given an n × n matrix A which is positive definite, and an n dimensional response vector b. We also fix an integer p which denotes a block size.",2. Background,[0],[0]
"Under the assumption of A being positive definite, the function f(x) = 12x
TAx−",2. Background,[0],[0]
xTb is strongly convex and smooth.,2. Background,[0],[0]
"Recent analysis of Gauss-Seidel (Gower & Richtárik, 2015) proceeds by noting the connection between Gauss-Seidel and (block) coordinate descent on f .",2. Background,[0],[0]
This is the point of view we will take in this paper.,2. Background,[0],[0]
"We first describe the sketching framework of (Qu et al., 2015; Gower & Richtárik, 2015) and show how it yields rates on Gauss-Seidel when blocks are chosen via a fixed partition or randomly at every iteration.",2.1. Existing rates for randomized block Gauss-Seidel,[0],[0]
"While we will only focus on the special case when the sketch matrix represents column sampling, the sketching framework allows us to provide a unified analysis of both cases.
",2.1. Existing rates for randomized block Gauss-Seidel,[0],[0]
"To be more precise, let D be a distribution over Rn×p, and let Sk ∼ D be drawn iid from D. If we perform block coordinate descent by minimizing f along the range of Sk, then the randomized block Gauss-Seidel update is given by
xk+1 = xk − Sk(STkASk)†STk",2.1. Existing rates for randomized block Gauss-Seidel,[0],[0]
(,2.1. Existing rates for randomized block Gauss-Seidel,[0],[0]
Axk − b) .,2.1. Existing rates for randomized block Gauss-Seidel,[0],[0]
"(1)
Column sampling.",2.1. Existing rates for randomized block Gauss-Seidel,[0],[0]
"Every index set J ⊆ 2[n] with |J | = p induces a sketching matrix S(J) = (eJ(1), ..., eJ(p)) where ei denotes the i-th standard basis vector in R n, and J(1), ..., J(p) is any ordering of the elements of J .",2.1. Existing rates for randomized block Gauss-Seidel,[0],[0]
"By equipping different probability measures on 2[n], one can easily describe fixed partition sampling as well as random coordinate sampling (and many other sampling schemes).",2.1. Existing rates for randomized block Gauss-Seidel,[0],[0]
"The former puts uniform mass on the index sets J1, ..., Jn/p, whereas the latter puts uniform mass on all ( n p ) index sets of size p.",2.1. Existing rates for randomized block Gauss-Seidel,[0],[0]
"Furthermore, in the sketching framework there is no limitation to use a uniform distribution, nor is there any limitation to use a fixed p for every iteration.",2.1. Existing rates for randomized block Gauss-Seidel,[0],[0]
"For this paper, however, we will restrict our attention to these cases.
",2.1. Existing rates for randomized block Gauss-Seidel,[0],[0]
Existing rates.,2.1. Existing rates for randomized block Gauss-Seidel,[0],[0]
"Under the assumptions stated above, (Qu et al., 2015; Gower & Richtárik, 2015) show that for every k ≥ 0, the sequence (1) satisfies E[‖xk − x∗‖A] ≤ (1− µ)k/2‖x0",2.1. Existing rates for randomized block Gauss-Seidel,[0],[0]
"− x∗‖A , (2)
where µ = λmin(E[PA1/2S ]).",2.1. Existing rates for randomized block Gauss-Seidel,[0],[0]
"The expectation in (2) is taken with respect to the randomness of S0, S1, ..., and the expectation in the definition of µ is taken with respect to S ∼ D. Under both fixed partitioning and random coordinate selection, µ > 0 is guaranteed (see e.g. (Gower & Richtárik, 2015), Lemma 4.3).",2.1. Existing rates for randomized block Gauss-Seidel,[0],[0]
"Thus, (1) achieves a linear rate of convergence to the true solution, with the rate governed by the µ quantity shown above.
",2.1. Existing rates for randomized block Gauss-Seidel,[0],[0]
"We now specialize (2) to fixed partitioning and random coordinate sampling, and provide some intuition for why we expect the latter to outperform the former in terms of iteration complexity.",2.1. Existing rates for randomized block Gauss-Seidel,[0],[0]
We first consider the case when the sampling distribution corresponds to fixed partitioning.,2.1. Existing rates for randomized block Gauss-Seidel,[0],[0]
"Assume for notational convenience that the fixed partitioning corresponds to placing the first p coordinates in the first partition J1, the next p coordinates in the second partition J2, and so on.",2.1. Existing rates for randomized block Gauss-Seidel,[0],[0]
"Here, µ = µpart corresponds to a measure of how close the product of A with the inverse of the block diagonal is to the identity matrix, defined as
µpart = p
n λmin
( A · blkdiag ( A−1J1 , ..., A −1 Jn/p )) .",2.1. Existing rates for randomized block Gauss-Seidel,[0],[0]
"(3)
Above, AJi denotes the p × p matrix corresponding to the sub-matrix of A indexed by the i-th partition.",2.1. Existing rates for randomized block Gauss-Seidel,[0],[0]
"A loose lower bound on µpart is
µpart ≥ p
n
λmin(A)
max1≤i≤n/p λmax(AJi) .",2.1. Existing rates for randomized block Gauss-Seidel,[0],[0]
"(4)
On the other hand, in the random coordinate case, Qu et al. (2015) derive a lower bound on µ = µrand as
µrand ≥ p
n
(
β + (1− β)max1≤i≤n Aii λmin(A)
)−1 , (5)
where β = (p− 1)/(n− 1).",2.1. Existing rates for randomized block Gauss-Seidel,[0],[0]
"Using the lower bounds (4) and (5), we can upper bound the iteration complexity of fixed partition Gauss-Seidel Npart by O (
n p
max1≤i≤n/p λmax(AJi )
λmin(A) log(1/ε)
)
and random coordi-
nate Gauss-Seidel Nrand as O ( n p max1≤i≤n Aii λmin(A) log(1/ε) ) .",2.1. Existing rates for randomized block Gauss-Seidel,[0],[0]
"Comparing the bound on Npart to the bound on Nrand, it is not unreasonable to expect that random coordinate sampling has better iteration complexity than fixed partition sampling in certain cases.",2.1. Existing rates for randomized block Gauss-Seidel,[0],[0]
"In Section 3, we verify this by constructing instances A such that fixed partition Gauss-Seidel takes arbitrarily more iterations to reach a pre-specified error tolerance compared with random coordinate Gauss-Seidel.",2.1. Existing rates for randomized block Gauss-Seidel,[0],[0]
"Based on the interpretation of Gauss-Seidel as block coordinate descent on the function f , we can use Theorem 1 of Nesterov and Stich (2016) to recover a procedure and a rate for accelerating (1) in the fixed partition case; the specific details are discussed in the full version of the paper (Tu et al., 2017).",2.2. Accelerated rates for fixed partition Gauss-Seidel,[0],[0]
"We will refer to this procedure as ACDM.
",2.2. Accelerated rates for fixed partition Gauss-Seidel,[0],[0]
"The convergence guarantee of the ACDM procedure is that for all k ≥ 0,
E[‖xk − x∗‖A] ≤",2.2. Accelerated rates for fixed partition Gauss-Seidel,[0],[0]
"O ( ( 1− √ p
n µpart
)k/2
D0
)
.",2.2. Accelerated rates for fixed partition Gauss-Seidel,[0],[0]
"(6)
Above, D0 = ‖x0 − x∗‖A and µpart is the same quantity defined in (3).",2.2. Accelerated rates for fixed partition Gauss-Seidel,[0],[0]
"Comparing (6) to the non-accelerated Gauss-Seidel rate given in (2), we see that acceleration improves the iteration complexity to reach a solution with ε error from O(µ−1part log(1/ε)) to O (√ n",2.2. Accelerated rates for fixed partition Gauss-Seidel,[0],[0]
pµ −1,2.2. Accelerated rates for fixed partition Gauss-Seidel,[0],[0]
"part log(1/ε) ) , as discussed in Section 1.",2.2. Accelerated rates for fixed partition Gauss-Seidel,[0],[0]
We now present the main results of the paper.,3. Results,[0],[0]
"Proofs can be found in the full version (Tu et al., 2017) of this paper.",3. Results,[0],[0]
"Our first result is to construct instances where Gauss-Seidel with fixed partition sampling runs arbitrarily slower than random coordinate sampling, even if acceleration is used.
",3.1. Fixed partition vs random coordinate sampling,[0],[0]
"Consider the family of n × n positive definite matrices A given by A = {Aα,β : α > 0, α + β > 0} with Aα,β
defined as Aα,β = αI",3.1. Fixed partition vs random coordinate sampling,[0],[0]
+ β n1n1 T n.,3.1. Fixed partition vs random coordinate sampling,[0],[0]
"The family A exhibits a crucial property that ΠTAα,βΠ =",3.1. Fixed partition vs random coordinate sampling,[0],[0]
"Aα,β for every n × n permutation matrix Π. Lee and Wright (2016) recently exploited this invariance to illustrate the behavior of cyclic versus randomized permutations in coordinate descent.
",3.1. Fixed partition vs random coordinate sampling,[0],[0]
We explore the behavior of Gauss-Seidel as the matrices,3.1. Fixed partition vs random coordinate sampling,[0],[0]
"Aα,β become ill-conditioned.",3.1. Fixed partition vs random coordinate sampling,[0],[0]
"To do this, we consider a particular parameterization which holds the minimum eigenvalue equal to one and sends the maximum eigenvalue to infinity via the sub-family {A1,β}β>0.",3.1. Fixed partition vs random coordinate sampling,[0],[0]
"Our first proposition characterizes the behavior of Gauss-Seidel with fixed partitions on this sub-family.
",3.1. Fixed partition vs random coordinate sampling,[0],[0]
Proposition 3.1.,3.1. Fixed partition vs random coordinate sampling,[0],[0]
"Fix β > 0 and positive integers n, p, k such that n = pk.",3.1. Fixed partition vs random coordinate sampling,[0],[0]
"Let {Ji}ki=1 be any partition of {1, ..., n} with |Ji| = p, and denote Si ∈ Rn×p as the column selector for partition Ji.",3.1. Fixed partition vs random coordinate sampling,[0],[0]
Suppose S ∈ Rn×p takes on value Si with probability,3.1. Fixed partition vs random coordinate sampling,[0],[0]
1/k.,3.1. Fixed partition vs random coordinate sampling,[0],[0]
"For every A1,β ∈",3.1. Fixed partition vs random coordinate sampling,[0],[0]
"A we have that
µpart = p
n+ βp .",3.1. Fixed partition vs random coordinate sampling,[0],[0]
"(7)
Next, we perform a similar calculation under the random column sampling model.
",3.1. Fixed partition vs random coordinate sampling,[0],[0]
Proposition 3.2.,3.1. Fixed partition vs random coordinate sampling,[0],[0]
"Fix β > 0 and integers n, p such that 1 < p",3.1. Fixed partition vs random coordinate sampling,[0],[0]
"< n. Suppose each column of S ∈ Rn×p is chosen uniformly at random from {e1, ..., en} without replacement.",3.1. Fixed partition vs random coordinate sampling,[0],[0]
"For every A1,β ∈",3.1. Fixed partition vs random coordinate sampling,[0],[0]
"A we have that
µrand = p
n+ βp + (p− 1)βp (n− 1)(n+ βp) .",3.1. Fixed partition vs random coordinate sampling,[0],[0]
"(8)
The differences between (7) and (8) are striking.",3.1. Fixed partition vs random coordinate sampling,[0],[0]
"Let us assume that β is much larger than n. Then, we have that µpart ≈ 1/β for (7), whereas µrand ≈ p−1n−1 for (8).",3.1. Fixed partition vs random coordinate sampling,[0],[0]
"That is, µpart can be made arbitrarily smaller than µrand as β grows.
",3.1. Fixed partition vs random coordinate sampling,[0],[0]
"Our next proposition states that the rate of Gauss-Seidel from (2) is tight order-wise in that for any instance there always exists a starting point which saturates the bound.
",3.1. Fixed partition vs random coordinate sampling,[0],[0]
Proposition 3.3.,3.1. Fixed partition vs random coordinate sampling,[0],[0]
"Let A be an n × n positive definite matrix, and let S be a random matrix such that µ = λmin(E[PA1/2S ]) >",3.1. Fixed partition vs random coordinate sampling,[0],[0]
0.,3.1. Fixed partition vs random coordinate sampling,[0],[0]
Let x∗ denote the solution to Ax = b.,3.1. Fixed partition vs random coordinate sampling,[0],[0]
There exists a starting point x0 ∈,3.1. Fixed partition vs random coordinate sampling,[0],[0]
"Rn such that the sequence (1) satisfies for all k ≥ 0,
E[‖xk − x∗‖A]",3.1. Fixed partition vs random coordinate sampling,[0],[0]
≥ (1− µ)k‖x0 − x∗‖A .,3.1. Fixed partition vs random coordinate sampling,[0],[0]
"(9)
From (2) we see that Gauss-Seidel using random coordinates computes a solution xk satisfying E[‖xk − x∗‖A1,β ]",3.1. Fixed partition vs random coordinate sampling,[0],[0]
≤ ε in at most k = O(np log(1/ε)),3.1. Fixed partition vs random coordinate sampling,[0],[0]
iterations.,3.1. Fixed partition vs random coordinate sampling,[0],[0]
"On the other hand, Proposition 3.3 states that for any fixed partition, there exists an input x0 such that k = Ω(β log(1/ε))",3.1. Fixed partition vs random coordinate sampling,[0],[0]
"iterations are required to reach the same ε error tolerance.
",3.1. Fixed partition vs random coordinate sampling,[0],[0]
"Furthermore, the situation does not improve even if use ACDM from (Nesterov & Stich, 2016).",3.1. Fixed partition vs random coordinate sampling,[0],[0]
"Proposition 3.6, which we describe later, implies that for any fixed partition there exists an input x0 such that k = Ω ( √ n pβ log(1/ε) )",3.1. Fixed partition vs random coordinate sampling,[0],[0]
iterations are required for ACDM to reach ε error.,3.1. Fixed partition vs random coordinate sampling,[0],[0]
"Hence as β −→ ∞, the gap between random coordinate and fixed partitioning can be made arbitrarily large.",3.1. Fixed partition vs random coordinate sampling,[0],[0]
These findings are numerically verified in Section 5.1.,3.1. Fixed partition vs random coordinate sampling,[0],[0]
"Motivated by our findings, our goal is to understand the behavior of accelerated Gauss-Seidel under random coordinate sampling.",3.2. A Lyapunov analysis of accelerated Gauss-Seidel and Kaczmarz,[0],[0]
"In order to do this, we establish a general framework from which the behavior of accelerated GaussSeidel with random coordinate sampling follows immediately, along with rates for accelerated randomized Kaczmarz (Liu & Wright, 2016) and the accelerated coordinate descent methods of (Nesterov & Stich, 2016) and (AllenZhu et al., 2016).
",3.2. A Lyapunov analysis of accelerated Gauss-Seidel and Kaczmarz,[0],[0]
"For conciseness, we describe a simpler version of our framework which is still able to capture both the GaussSeidel and Kaczmarz results, deferring the general version to the full version of the paper.",3.2. A Lyapunov analysis of accelerated Gauss-Seidel and Kaczmarz,[0],[0]
"Our general result requires a bit more notation, but follows the same line of reasoning.
",3.2. A Lyapunov analysis of accelerated Gauss-Seidel and Kaczmarz,[0],[0]
Let H be,3.2. A Lyapunov analysis of accelerated Gauss-Seidel and Kaczmarz,[0],[0]
a random n × n positive semi-definite matrix.,3.2. A Lyapunov analysis of accelerated Gauss-Seidel and Kaczmarz,[0],[0]
"Put G = E[H], and suppose that G exists and is positive definite.",3.2. A Lyapunov analysis of accelerated Gauss-Seidel and Kaczmarz,[0],[0]
"Furthermore, let f :",3.2. A Lyapunov analysis of accelerated Gauss-Seidel and Kaczmarz,[0],[0]
"Rn −→ R be strongly convex and smooth, and let µ denote the strong convexity constant of f w.r.t.",3.2. A Lyapunov analysis of accelerated Gauss-Seidel and Kaczmarz,[0],[0]
the ‖·‖G−1 norm.,3.2. A Lyapunov analysis of accelerated Gauss-Seidel and Kaczmarz,[0],[0]
"Consider the following sequence {(xk, yk, zk)}k≥0 defined by the recurrence
xk+1 = 1
1 + τ yk +
τ
1 + τ zk , (10a)
yk+1 = xk+1 −Hk∇f(xk+1) , (10b) zk+1",3.2. A Lyapunov analysis of accelerated Gauss-Seidel and Kaczmarz,[0],[0]
"= zk + τ(xk+1 − zk)− τ
µ Hk∇f(xk+1) , (10c)
where H0, H1, ... are independent realizations of H and τ is a parameter to be chosen.",3.2. A Lyapunov analysis of accelerated Gauss-Seidel and Kaczmarz,[0],[0]
"Following (Wilson et al., 2016), we construct a candidate Lyapunov function Vk for the sequence (10) defined as
Vk = f(yk)− f∗ + µ
2 ‖zk − x∗‖2G−1 .",3.2. A Lyapunov analysis of accelerated Gauss-Seidel and Kaczmarz,[0],[0]
"(11)
",3.2. A Lyapunov analysis of accelerated Gauss-Seidel and Kaczmarz,[0],[0]
"The following theorem demonstrates that Vk is indeed a Lyapunov function for (xk, yk, zk).",3.2. A Lyapunov analysis of accelerated Gauss-Seidel and Kaczmarz,[0],[0]
Theorem 3.4.,3.2. A Lyapunov analysis of accelerated Gauss-Seidel and Kaczmarz,[0],[0]
"Let f,G,H be as defined above.",3.2. A Lyapunov analysis of accelerated Gauss-Seidel and Kaczmarz,[0],[0]
Suppose further that f has 1-Lipschitz gradients w.r.t.,3.2. A Lyapunov analysis of accelerated Gauss-Seidel and Kaczmarz,[0],[0]
"the ‖·‖G−1 norm, and for every fixed x ∈ Rn,
f(Φ(x;H)) ≤",3.2. A Lyapunov analysis of accelerated Gauss-Seidel and Kaczmarz,[0],[0]
"f(x)− 1 2 ‖∇f(x)‖2H , (12)
holds for a.e. H , where Φ(x;H) = x−H∇f(x).",3.2. A Lyapunov analysis of accelerated Gauss-Seidel and Kaczmarz,[0],[0]
"Set τ in (10) as τ = √ µ/ν, with
ν = λmax
(
E
[ (G−1/2HG−1/2)2 ]) .
",3.2. A Lyapunov analysis of accelerated Gauss-Seidel and Kaczmarz,[0],[0]
"Then for every k ≥ 0, we have
E[Vk] ≤ (1− τ)kV0 .
",3.2. A Lyapunov analysis of accelerated Gauss-Seidel and Kaczmarz,[0],[0]
We now proceed to specialize Theorem 3.4 to both the Gauss-Seidel and Kaczmarz settings.,3.2. A Lyapunov analysis of accelerated Gauss-Seidel and Kaczmarz,[0],[0]
Let S ∈ Rn×p denote a random sketching matrix.,3.2.1. ACCELERATED GAUSS-SEIDEL,[0],[0]
"As suggested in Section 2, we set f(x) = 12x
TAx",3.2.1. ACCELERATED GAUSS-SEIDEL,[0],[0]
− xTb and put H = S(STAS)†ST.,3.2.1. ACCELERATED GAUSS-SEIDEL,[0],[0]
Note that G = E[S(STAS)†ST] is positive definite iff λmin(E[PA1/2S ]),3.2.1. ACCELERATED GAUSS-SEIDEL,[0],[0]
"> 0, and is hence satisfied for both fixed partition and random coordinate sampling (c.f. Section 2).",3.2.1. ACCELERATED GAUSS-SEIDEL,[0],[0]
"Next, the fact that f is 1-Lipschitz w.r.t.",3.2.1. ACCELERATED GAUSS-SEIDEL,[0],[0]
the ‖·‖G−1 norm and the condition (12) are standard calculations.,3.2.1. ACCELERATED GAUSS-SEIDEL,[0],[0]
"All the hypotheses of Theorem 3.4 are thus satisfied, and the conclusion is Theorem 3.5, which characterizes the rate of convergence for accelerated Gauss-Seidel (Algorithm 1).
",3.2.1. ACCELERATED GAUSS-SEIDEL,[0],[0]
Algorithm 1 Accelerated randomized block Gauss-Seidel.,3.2.1. ACCELERATED GAUSS-SEIDEL,[0],[0]
"Require: A ∈ Rn×n, A ≻ 0, b ∈ Rn, sketching matrices {Sk}T−1k=0 ⊆ Rn×p,",3.2.1. ACCELERATED GAUSS-SEIDEL,[0],[0]
"x0 ∈ Rn, µ ∈ (0, 1), ν ≥ 1.
1: Set τ = √
µ/ν. 2: Set y0 = z0 = x0.",3.2.1. ACCELERATED GAUSS-SEIDEL,[0],[0]
"3: for k = 0, ..., T",3.2.1. ACCELERATED GAUSS-SEIDEL,[0],[0]
− 1 do 4: xk+1 = 1 1+τ yk + τ 1+τ zk. 5: Hk = Sk(S T kASk) †STk .,3.2.1. ACCELERATED GAUSS-SEIDEL,[0],[0]
6: yk+1 = xk+1 −Hk(Axk+1,3.2.1. ACCELERATED GAUSS-SEIDEL,[0],[0]
− b).,3.2.1. ACCELERATED GAUSS-SEIDEL,[0],[0]
7: zk+1 = zk + τ(xk+1 − zk)− τµHk(Axk+1 − b).,3.2.1. ACCELERATED GAUSS-SEIDEL,[0],[0]
"8: end for 9: Return yT .
",3.2.1. ACCELERATED GAUSS-SEIDEL,[0],[0]
Theorem 3.5.,3.2.1. ACCELERATED GAUSS-SEIDEL,[0],[0]
Let A be an n × n positive definite matrix and b ∈ Rn.,3.2.1. ACCELERATED GAUSS-SEIDEL,[0],[0]
Let,3.2.1. ACCELERATED GAUSS-SEIDEL,[0],[0]
x∗ ∈,3.2.1. ACCELERATED GAUSS-SEIDEL,[0],[0]
Rn denote the unique vector satisfying Ax∗ = b.,3.2.1. ACCELERATED GAUSS-SEIDEL,[0],[0]
"Suppose each Sk, k = 0, 1, 2, ... is an independent copy of a random matrix S ∈ Rn×p.",3.2.1. ACCELERATED GAUSS-SEIDEL,[0],[0]
"Put µ = λmin(E[PA1/2S ]), and suppose the distribution of S satisfies µ > 0.",3.2.1. ACCELERATED GAUSS-SEIDEL,[0],[0]
"Invoke Algorithm 1 with µ and ν, where
ν = λmax
(
E
[ (G−1/2HG−1/2)2 ]) , (13)
with H = S(STAS)†ST and G = E[H].",3.2.1. ACCELERATED GAUSS-SEIDEL,[0],[0]
"Then with τ = √
µ/ν, for all k ≥ 0,
E[‖yk − x∗‖A] ≤ √ 2(1− τ)k/2‖x0 − x∗‖A .",3.2.1. ACCELERATED GAUSS-SEIDEL,[0],[0]
"(14)
Note that in the setting of Theorem 3.5, by the definition of ν and µ, it is always the case that ν",3.2.1. ACCELERATED GAUSS-SEIDEL,[0],[0]
"≤ 1/µ. Therefore,
the iteration complexity of acceleration is at least as good as the iteration complexity without acceleration.
",3.2.1. ACCELERATED GAUSS-SEIDEL,[0],[0]
"We conclude our discussion of Gauss-Seidel by describing the analogue of Proposition 3.3 for Algorithm 1, which shows that our analysis in Theorem 3.5 is tight order-wise.",3.2.1. ACCELERATED GAUSS-SEIDEL,[0],[0]
"The following proposition applies to ACDM as well; we show in the full version of the paper how ACDM can be viewed as a special case of Algorithm 1.
",3.2.1. ACCELERATED GAUSS-SEIDEL,[0],[0]
Proposition 3.6.,3.2.1. ACCELERATED GAUSS-SEIDEL,[0],[0]
"Under the setting of Theorem 3.5, there exists starting positions y0, z0 ∈",3.2.1. ACCELERATED GAUSS-SEIDEL,[0],[0]
"Rn such that the iterates {(yk, zk)}k≥0 produced by Algorithm 1 satisfy
E[‖yk − x∗‖A + ‖zk",3.2.1. ACCELERATED GAUSS-SEIDEL,[0],[0]
− x∗‖A] ≥ (1− τ)k‖y0 − x∗‖A .,3.2.1. ACCELERATED GAUSS-SEIDEL,[0],[0]
"The argument for Theorem 3.5 can be slightly modified to yield a result for randomized accelerated Kaczmarz in the sketching framework, for the case of a consistent overdetermined linear system.
",3.2.2. ACCELERATED KACZMARZ,[0],[0]
"Specifically, suppose we are given an m×n matrix A which has full column rank, and b ∈ R(A).",3.2.2. ACCELERATED KACZMARZ,[0],[0]
Our goal is to recover the unique x∗ satisfying Ax∗ = b.,3.2.2. ACCELERATED KACZMARZ,[0],[0]
"To do this, we apply a similar line of reasoning as (Lee & Sidford, 2013).",3.2.2. ACCELERATED KACZMARZ,[0],[0]
We set f(x) = 12‖x,3.2.2. ACCELERATED KACZMARZ,[0],[0]
− x∗‖22,3.2.2. ACCELERATED KACZMARZ,[0],[0]
"and H = PATS , where S again is our random sketching matrix.",3.2.2. ACCELERATED KACZMARZ,[0],[0]
"At first, it appears our choice of f is problematic since we do not have access to f and ∇f , but a quick calculation shows that H∇f(x) =",3.2.2. ACCELERATED KACZMARZ,[0],[0]
(STA)†ST(Ax − b).,3.2.2. ACCELERATED KACZMARZ,[0],[0]
"Hence, with rk = Axk − b, the sequence (10) simplifies to
xk+1 = 1
1 + τ yk +
τ
1 + τ",3.2.2. ACCELERATED KACZMARZ,[0],[0]
"zk , (15a)
yk+1 = xk+1",3.2.2. ACCELERATED KACZMARZ,[0],[0]
"− (STkA)†STk rk+1 , (15b) zk+1",3.2.2. ACCELERATED KACZMARZ,[0],[0]
"= zk + τ(xk+1 − zk)− τ
µ (STkA)
†STk rk+1 .",3.2.2. ACCELERATED KACZMARZ,[0],[0]
"(15c)
",3.2.2. ACCELERATED KACZMARZ,[0],[0]
"The remainder of the argument proceeds nearly identically, and leads to the following theorem.
",3.2.2. ACCELERATED KACZMARZ,[0],[0]
Theorem 3.7.,3.2.2. ACCELERATED KACZMARZ,[0],[0]
"Let A be an m × n matrix with full column rank, and b = Ax∗. Suppose each Sk, k = 0, 1, 2, ... is an independent copy of a random sketching matrix S ∈ Rm×p.",3.2.2. ACCELERATED KACZMARZ,[0],[0]
Put H = PATS and G = E[H].,3.2.2. ACCELERATED KACZMARZ,[0],[0]
"The sequence (15) with µ = λmin(E[PATS ]), ν = λmax ( E [ (G−1/2HG−1/2)2 ]) , and τ = √
µ/ν satisfies for all k ≥ 0,
E[‖yk − x∗‖2] ≤ √ 2(1− τ)k/2‖x0",3.2.2. ACCELERATED KACZMARZ,[0],[0]
− x∗‖2 .,3.2.2. ACCELERATED KACZMARZ,[0],[0]
"(16)
Specialized to the setting of (Liu & Wright, 2016) where each row of A has unit norm and is sampled uniformly at every iteration, it can be shown (Section A.5.1) that
ν ≤ m and µ = 1mλmin(ATA).",3.2.2. ACCELERATED KACZMARZ,[0],[0]
"Hence, the above theorem states that the iteration complexity to reach ε er-
ror is O
(
m√ λmin(ATA) log(1/ε)
)
, which matches Theo-
rem 5.1 of (Liu & Wright, 2016) order-wise.",3.2.2. ACCELERATED KACZMARZ,[0],[0]
"However, Theorem 3.7 applies in general for any sketching matrix.",3.2.2. ACCELERATED KACZMARZ,[0],[0]
We now instantiate Theorem 3.5 to random coordinate sampling.,3.3. Specializing accelerated Gauss-Seidel to random coordinate sampling,[0],[0]
The µ quantity which appears in Theorem 3.5 is identical to the quantity appearing in the rate (2) of nonaccelerated Gauss-Seidel.,3.3. Specializing accelerated Gauss-Seidel to random coordinate sampling,[0],[0]
"That is, the iteration complex-
ity to reach tolerance ε is O
(
√
νµ−1rand log(1/ε)
)
, and the
only new term here is ν.",3.3. Specializing accelerated Gauss-Seidel to random coordinate sampling,[0],[0]
"In order to provide a more intuitive interpretation of the ν quantity, we present an upper bound on ν in terms of an effective block condition number defined as follows.",3.3. Specializing accelerated Gauss-Seidel to random coordinate sampling,[0],[0]
"Given an index set J ⊆ 2[n], define the effective block condition number of a matrix A as κeff,J(A) =
maxi∈J Aii λmin(AJ ) .",3.3. Specializing accelerated Gauss-Seidel to random coordinate sampling,[0],[0]
"Note that κeff,J(A) ≤ κ(AJ) always.",3.3. Specializing accelerated Gauss-Seidel to random coordinate sampling,[0],[0]
The following lemma gives upper and lower bounds on the ν quantity.,3.3. Specializing accelerated Gauss-Seidel to random coordinate sampling,[0],[0]
Lemma 3.8.,3.3. Specializing accelerated Gauss-Seidel to random coordinate sampling,[0],[0]
Let A be an n×n positive definite matrix and let p satisfy 1 < p,3.3. Specializing accelerated Gauss-Seidel to random coordinate sampling,[0],[0]
< n.,3.3. Specializing accelerated Gauss-Seidel to random coordinate sampling,[0],[0]
"We have that
n p ≤ ν ≤",3.3. Specializing accelerated Gauss-Seidel to random coordinate sampling,[0],[0]
n,3.3. Specializing accelerated Gauss-Seidel to random coordinate sampling,[0],[0]
"p
(
p− 1 n− 1 +
(
1− p− 1 n− 1
)
",3.3. Specializing accelerated Gauss-Seidel to random coordinate sampling,[0],[0]
"κeff,p(A)
)
,
where κeff,p(A) = maxJ⊆2[n]:|J|=p κeff,J(A), ν is defined in (13), and the distribution of S corresponds to uniformly selecting p coordinates without replacement.
",3.3. Specializing accelerated Gauss-Seidel to random coordinate sampling,[0],[0]
"Lemma 3.8 states that if the p × p sub-blocks of A are well-conditioned as defined by the effective block condition number κeff,J(A), then the speed-up of accelerated Gauss-Seidel with random coordinate selection over its non-accelerate counterpart parallels the case of fixed partitioning sampling (i.e. the rate described in (6) versus the rate in (2)).",3.3. Specializing accelerated Gauss-Seidel to random coordinate sampling,[0],[0]
"This is a reasonable condition, since very illconditioned sub-blocks will lead to numerical instabilities in solving the sub-problems when implementing GaussSeidel.",3.3. Specializing accelerated Gauss-Seidel to random coordinate sampling,[0],[0]
"On the other hand, we note that Lemma 3.8 provides merely a sufficient condition for speed-ups from acceleration, and is conservative.",3.3. Specializing accelerated Gauss-Seidel to random coordinate sampling,[0],[0]
"Our numerically experiments in Section A.7.2 suggest that in many cases the ν parameter behaves closer to the lower bound n/p than Lemma 3.8 suggests.
",3.3. Specializing accelerated Gauss-Seidel to random coordinate sampling,[0],[0]
"We can now combine Theorem 3.5 with (5) to derive the following upper bound on the iteration complexity of accelerated Gauss-Seidel with random coordinates as
Nrand,acc ≤",3.3. Specializing accelerated Gauss-Seidel to random coordinate sampling,[0],[0]
"O ( n
p
√
max1≤i≤n Aii λmin(A) κeff,p(A) log(1/ε)
)
.
",3.3. Specializing accelerated Gauss-Seidel to random coordinate sampling,[0],[0]
Illustrative example.,3.3. Specializing accelerated Gauss-Seidel to random coordinate sampling,[0],[0]
We conclude our results by illustrating our bounds on a simple example.,3.3. Specializing accelerated Gauss-Seidel to random coordinate sampling,[0],[0]
"Consider the subfamily {Aδ}δ>0 ⊆ A , with
Aδ = An+δ,−n , δ > 0 .",3.3. Specializing accelerated Gauss-Seidel to random coordinate sampling,[0],[0]
"(17)
",3.3. Specializing accelerated Gauss-Seidel to random coordinate sampling,[0],[0]
"A simple calculation yields that κeff,p(Aδ) =",3.3. Specializing accelerated Gauss-Seidel to random coordinate sampling,[0],[0]
"n−1+δ n−p+δ , and hence Lemma 3.8 states that ν(Aδ) ≤ np",3.3. Specializing accelerated Gauss-Seidel to random coordinate sampling,[0],[0]
( 1 + p−1n−1 ) .,3.3. Specializing accelerated Gauss-Seidel to random coordinate sampling,[0],[0]
"Furthermore, by a similar calculation to Proposition 3.2, µrand = pδ
n(n−p+δ) .",3.3. Specializing accelerated Gauss-Seidel to random coordinate sampling,[0],[0]
"Assuming for simplicity that p =
o(n) and δ ∈ (0, 1), Theorem 3.5 states that at most O(n 3/2
p √ δ log(1/ε)) iterations are sufficient for an ε-accurate solution.",3.3. Specializing accelerated Gauss-Seidel to random coordinate sampling,[0],[0]
"On the other hand, without acceleration (2) states that O(n 2
pδ log(1/ε))",3.3. Specializing accelerated Gauss-Seidel to random coordinate sampling,[0],[0]
iterations are sufficient and Proposition 3.3 shows there exists a starting position for which it is necessary.,3.3. Specializing accelerated Gauss-Seidel to random coordinate sampling,[0],[0]
"Hence, as either n grows large or δ tends to zero, the benefits of acceleration become more pronounced.",3.3. Specializing accelerated Gauss-Seidel to random coordinate sampling,[0],[0]
"We split the related work into two broad categories of interest: (a) work related to coordinate descent (CD) methods on convex functions and (b) randomized solvers designed for solving consistent linear systems.
",4. Related Work,[0],[0]
"When A is positive definite, Gauss-Seidel can be interpreted as an instance of coordinate descent on a strongly convex quadratic function.",4. Related Work,[0],[0]
"We therefore review related work on both non-accelerated and accelerated coordinate descent, focusing on the randomized setting instead of the more classical cyclic order or Gauss-Southwell rule for selecting the next coordinate.",4. Related Work,[0],[0]
"See (Tseng & Yun, 2009) for a discussion on non-random selection rules, (Nutini et al., 2015) for a comparison of random selection versus GaussSouthwell, and (Nutini et al., 2016) for efficient implementations of Gauss-Southwell.
Nesterov’s original paper in (2012) first considered randomized CD on convex functions, assuming a partitioning of coordinates fixed ahead of time.",4. Related Work,[0],[0]
The analysis included both non-accelerated and accelerated variants for convex functions.,4. Related Work,[0],[0]
This work sparked a resurgence of interest in CD methods for large problems.,4. Related Work,[0],[0]
"Most relevant to our paper are extensions to the block setting (Richtárik & Takác̆, 2014), handling arbitrary sampling distributions (Qu & Richtárik, 2014a;b; Fountoulakis & Tappenden, 2016), and second order updates for quadratic functions (Qu et al., 2016).
",4. Related Work,[0],[0]
"For accelerated CD, Lee and Sidford (2013) generalize the analysis of Nesterov (2012).",4. Related Work,[0],[0]
"While the analysis of (Lee & Sidford, 2013) was limited to selecting a single coordinate at a time, several follow on works (Qu & Richtárik, 2014a; Lin et al., 2014; Lu & Xiao, 2015; Fercoq & Richtárik, 2015) generalize to block and non-smooth settings.",4. Related Work,[0],[0]
"More recently, both Allen-Zhu et al. (2016) and Nesterov and
Stich (2016) independently improve the results of (Lee & Sidford, 2013) by using a different non-uniform sampling distribution.",4. Related Work,[0],[0]
"One of the most notable aspects of the analysis in (Allen-Zhu et al., 2016) is a departure from the (probabilistic) estimate sequence framework of Nesterov.",4. Related Work,[0],[0]
"Instead, the authors construct a valid Lyapunov function for coordinate descent, although they do not explicitly mention this.",4. Related Work,[0],[0]
"In our work, we make this Lyapunov point of view explicit.",4. Related Work,[0],[0]
The constants in our acceleration updates arise from a particular discretization and Lyapunov function outlined from Wilson et al. (2016).,4. Related Work,[0],[0]
"Using this framework makes our proof particularly transparent, and allows us to recover results for strongly convex functions from (Allen-Zhu et al., 2016) and (Nesterov & Stich, 2016) as a special case.
",4. Related Work,[0],[0]
From the numerical analysis side both the Gauss-Seidel and Kaczmarz algorithm are classical methods.,4. Related Work,[0],[0]
"Strohmer and Vershynin (2009) were the first to prove a linear rate of convergence for randomized Kaczmarz, and Leventhal and Lewis (2010) provide a similar kind of analysis for randomized Gauss-Seidel.",4. Related Work,[0],[0]
Both of these were in the single constraint/coordinate setting.,4. Related Work,[0],[0]
The block setting was later analyzed by Needell and Tropp (2014).,4. Related Work,[0],[0]
"More recently, Gower and Richtárik (2015) provide a unified analysis for both randomized block Gauss-Seidel and Kaczmarz in the sketching framework.",4. Related Work,[0],[0]
We adopt this framework in this paper.,4. Related Work,[0],[0]
"Finally, Liu and Wright (2016) provide an accelerated analysis of randomized Kaczmarz once again in the single constraint setting and we extend this to the block setting.",4. Related Work,[0],[0]
In this section we experimentally validate our theoretical results on how our accelerated algorithms can improve convergence rates.,5. Experiments,[0],[0]
"Our experiments use a combination of synthetic matrices and matrices from large scale machine learning tasks.
",5. Experiments,[0],[0]
Setup.,5. Experiments,[0],[0]
We run all our experiments on a 4 socket Intel Xeon CPU E7-8870 machine with 18 cores per socket and 1TB of DRAM.,5. Experiments,[0],[0]
"We implement all our algorithms in Python using numpy, and use the Intel MKL library with 72 OpenMP threads for numerical operations.",5. Experiments,[0],[0]
"We report errors as relative errors, i.e. ‖xk − x∗‖2A/‖x∗‖2A.",5. Experiments,[0],[0]
"Finally, we use the best values of µ and ν found by tuning each experiment.
",5. Experiments,[0],[0]
We implement fixed partitioning by creating random blocks of coordinates at the beginning of the experiment and cache the corresponding matrix blocks to improve performance.,5. Experiments,[0],[0]
"For random coordinate sampling, we select a new block of coordinates at each iteration.
",5. Experiments,[0],[0]
"For our fixed partition experiments, we restrict our attention to uniform sampling.",5. Experiments,[0],[0]
"While Gower and Richtárik (2015) propose a non-uniform scheme based on Tr(STAS), for translation-invariant kernels this reduces to
uniform sampling.",5. Experiments,[0],[0]
"Furthermore, as the kernel block Lipschitz constants were also roughly the same, other nonuniform schemes (Allen-Zhu et al., 2016) also reduce to nearly uniform sampling.",5. Experiments,[0],[0]
"Our first set of experiments numerically verify the separation between fixed partitioning sampling versus random coordinate sampling.
",5.1. Fixed partitioning vs random coordinate sampling,[0],[0]
"Figure 1 shows the progress per iteration on solving A1,βx = b, with the A1,β defined in Section 3.1.",5.1. Fixed partitioning vs random coordinate sampling,[0],[0]
"Here we set n = 5000, p = 500, β = 1000, and b ∼ N(0, I).",5.1. Fixed partitioning vs random coordinate sampling,[0],[0]
"Figure 1 verifies our analytical findings in Section 3.1, that the fixed partition scheme is substantially worse than uniform sampling on this instance.",5.1. Fixed partitioning vs random coordinate sampling,[0],[0]
"It also shows that in this case, acceleration provides little benefit in the case of random coordinate sampling.",5.1. Fixed partitioning vs random coordinate sampling,[0],[0]
"This is because both µ and 1/ν are order-wise p/n, and hence the rate for accelerated and non-accelerated coordinate descent coincide.",5.1. Fixed partitioning vs random coordinate sampling,[0],[0]
"However we note that this only applies for matrices where µ is as large as it can be (i.e. p/n), that is instances for which GaussSeidel is already converging at the optimal rate (see (Gower & Richtárik, 2015), Lemma 4.2).",5.1. Fixed partitioning vs random coordinate sampling,[0],[0]
We next evaluate how fixed partitioning and random coordinate sampling affects the performance of Gauss-Seidel on large scale machine learning tasks.,5.2. Kernel ridge regression,[0],[0]
We use the popular image classification dataset CIFAR-10 and evaluate a kernel ridge regression (KRR) task with a Gaussian kernel.,5.2. Kernel ridge regression,[0],[0]
"Specifically, given a labeled dataset {(xi, yi)}ni=1, we solve the linear system (K + λI)α = Y with Kij = exp(−γ‖xi − xj‖22), where λ, γ > 0 are tunable parameters.",5.2. Kernel ridge regression,[0],[0]
"The key property of KRR is that the kernel matrix K is positive semi-definite, and hence Algorithm 1 applies.",5.2. Kernel ridge regression,[0],[0]
"For the CIFAR-10 dataset, we augment the dataset1 to include five reflections, translations per-image and then apply standard pre-processing steps used in image classification (Coates & Ng, 2012; Sparks et al., 2017).",GS Fixed Partition GS-Acc Fixed Partition,[0],[0]
We finally apply a Gaussian kernel on our pre-processed images and the resulting kernel matrix has n = 250000 coordinates.,GS Fixed Partition GS-Acc Fixed Partition,[0],[0]
"We also include experiments on a smaller MNIST kernel matrix (n = 60000) in Section A.7.
Results from running 500 iterations of random coordinate sampling and fixed partitioning algorithms are shown in Figure 2.",GS Fixed Partition GS-Acc Fixed Partition,[0],[0]
"Comparing convergence across iterations, similar to previous section, we see that un-accelerated GaussSeidel with random coordinate sampling is better than accelerated Gauss-Seidel with fixed partitioning.",GS Fixed Partition GS-Acc Fixed Partition,[0],[0]
"However we also see that using acceleration with random sampling can further improve the convergence rates, especially to achieve errors of 10−3 or lower.
1Similar to https://github.com/akrizhevsky/cuda-convnet2.
",GS Fixed Partition GS-Acc Fixed Partition,[0],[0]
We also compare the convergence with respect to running time in Figure 3.,GS Fixed Partition GS-Acc Fixed Partition,[0],[0]
Fixed partitioning has better performance in practice random access is expensive in multi-core systems.,GS Fixed Partition GS-Acc Fixed Partition,[0],[0]
"However, we see that this speedup in implementation comes at a substantial cost in terms of convergence rate.",GS Fixed Partition GS-Acc Fixed Partition,[0],[0]
"For example in the case of CIFAR-10, using fixed partitions leads to an error of 1.2× 10−2 after around 7000 seconds.",GS Fixed Partition GS-Acc Fixed Partition,[0],[0]
In comparison we see that random coordinate sampling achieves a similar error in around 4500 seconds and is thus 1.5× faster.,GS Fixed Partition GS-Acc Fixed Partition,[0],[0]
We also note that this speedup increases for lower error tolerances.,GS Fixed Partition GS-Acc Fixed Partition,[0],[0]
We also compared Gauss-Seidel with random coordinate sampling to the classical conjugate-gradient (CG) algorithm.,5.3. Comparing Gauss-Seidel to Conjugate-Gradient,[0],[0]
"CG is an important baseline to compare with, as it is the de-facto standard iterative algorithm for solving linear systems in the numerical analysis community.",5.3. Comparing Gauss-Seidel to Conjugate-Gradient,[0],[0]
"While we report the results of CG without preconditioning, we remark that the performance using a standard banded preconditioner was not any better.",5.3. Comparing Gauss-Seidel to Conjugate-Gradient,[0],[0]
"However, for KRR specifically, there have been recent efforts (Avron et al., 2017; Rudi et al., 2017) to develop better preconditioners, and we leave a more thorough comparison for future work.",5.3. Comparing Gauss-Seidel to Conjugate-Gradient,[0],[0]
The results of our experiment are shown in Figure 3.,5.3. Comparing Gauss-Seidel to Conjugate-Gradient,[0],[0]
We note that Gauss-Seidel both with and without acceleration outperform CG.,5.3. Comparing Gauss-Seidel to Conjugate-Gradient,[0],[0]
"As an example, we note that to reach error 10−1 on CIFAR-10, CG takes roughly 7000 seconds, compared to less than 2000 seconds for accelerated GaussSeidel, which is a 3.5× improvement.",5.3. Comparing Gauss-Seidel to Conjugate-Gradient,[0],[0]
"To understand this performance difference, we recall that our matrices A are fully dense, and hence each iteration of CG takes O(n2).",5.3. Comparing Gauss-Seidel to Conjugate-Gradient,[0],[0]
"On the other hand, each iteration of both non-accelerated and accelerated Gauss-Seidel takes O(np2 + p3).",5.3. Comparing Gauss-Seidel to Conjugate-Gradient,[0],[0]
"Hence, as long as p = O(n2/3), the time per iteration of Gauss-Seidel is order-wise no worse than
CG.",5.3. Comparing Gauss-Seidel to Conjugate-Gradient,[0],[0]
"In terms of iteration complexity, standard results state that CG takes at most O( √ κ log(1/ε))",5.3. Comparing Gauss-Seidel to Conjugate-Gradient,[0],[0]
"iterations to reach an ε error solution, where κ denotes the condition number of A. On the other hand, Gauss-Seidel takes at most O(npκeff log(1/ε)), where κeff = max1≤i≤n Aii λmin(A) .",5.3. Comparing Gauss-Seidel to Conjugate-Gradient,[0],[0]
"In the case of any (normalized) kernel matrix associated with a translation-invariant kernel such as the Gaussian kernel, we have max1≤i≤n Aii = 1, and hence generally speaking κeff is much lower than κ.",5.3. Comparing Gauss-Seidel to Conjugate-Gradient,[0],[0]
We next analyze the importance of the block size p for the accelerated Gauss-Seidel method.,5.4. Effect of block size,[0],[0]
"As the values of µ and ν change for each setting of p, we use a smaller MNIST matrix for this experiment.",5.4. Effect of block size,[0],[0]
"We apply a random feature transformation (Rahimi & Recht, 2007) to generate an n × d matrix F with d = 5000 features.",5.4. Effect of block size,[0],[0]
We then use A = FTF and b = FTY as inputs to the algorithm.,5.4. Effect of block size,[0],[0]
"Figure 4 shows the wall clock time to converge to 10−5 error as we vary the block size from p = 50 to p = 1000.
",5.4. Effect of block size,[0],[0]
"Increasing the block-size improves the amount of progress that is made per iteration but the time taken per iteration increases as O(p3) (Line 5, Algorithm 1).",5.4. Effect of block size,[0],[0]
"However, using efficient BLAS-3 primitives usually affords a speedup from systems techniques like cache blocking.",5.4. Effect of block size,[0],[0]
We see the effects of this in Figure 4 where using p = 500 performs better than using p = 50.,5.4. Effect of block size,[0],[0]
We also see that these benefits reduce for much larger block sizes and thus p = 1000 is slower.,5.4. Effect of block size,[0],[0]
"In this paper, we extended the accelerated block GaussSeidel algorithm beyond fixed partition sampling.",6. Conclusion,[0],[0]
Our analysis introduced a new data-dependent parameter ν which governs the speed-up of acceleration.,6. Conclusion,[0],[0]
"Specializing our theory to random coordinate sampling, we derived an upper bound on ν which shows that well conditioned blocks are a sufficient condition to ensure speedup.",6. Conclusion,[0],[0]
"Experimentally, we showed that random coordinate sampling is readily accelerated beyond what our bound suggests.
",6. Conclusion,[0],[0]
The most obvious question remains to derive a sharper bound on the ν constant from Theorem 3.5.,6. Conclusion,[0],[0]
"Another interesting question is whether or not the iteration complexity of random coordinate sampling is always bounded above by the iteration complexity with fixed coordinate sampling.
",6. Conclusion,[0],[0]
"We also plan to study an implementation of accelerated Gauss-Seidel in a distributed setting (Tu et al., 2016).",6. Conclusion,[0],[0]
"The main challenges here are in determining how to sample coordinates without significant communication overheads, and to efficiently estimate µ and ν.",6. Conclusion,[0],[0]
"To do this, we wish to explore other sampling schemes such as shuffling the coordinates at the end of every epoch (Recht & Ré, 2013).",6. Conclusion,[0],[0]
"We thank Ross Boczar for assisting us with Mathematica support for non-commutative algebras, Orianna DeMasi for providing useful feedback on earlier drafts of this manuscript, and the anonymous reviewers for their helpful feedback.",Acknowledgements,[0],[0]
ACW is supported by an NSF Graduate Research Fellowship.,Acknowledgements,[0],[0]
"BR is generously supported by ONR awards N00014-11-1-0723 and N00014-13-1-0129, NSF award CCF-1359814, the DARPA Fundamental Limits of Learning (Fun LoL)",Acknowledgements,[0],[0]
"Program, a Sloan Research Fellowship, and a Google Research Award.",Acknowledgements,[0],[0]
"This research is supported in part by DHS Award HSHQDC-16-3-00083, NSF CISE Expeditions Award CCF-1139158, DOE Award SN10040 DE-SC0012463, and DARPA XData Award FA8750-12-2-0331, and gifts from Amazon Web Services, Google, IBM, SAP, The Thomas and Stacey Siebel Foundation, Apple Inc., Arimo, Blue Goji, Bosch, Cisco, Cray, Cloudera, Ericsson, Facebook, Fujitsu, HP, Huawei, Intel, Microsoft, Mitre, Pivotal, Samsung, Schlumberger, Splunk, State Farm and VMware.",Acknowledgements,[0],[0]
Recent work by Nesterov and Stich (2016) showed that momentum can be used to accelerate the rate of convergence for block GaussSeidel in the setting where a fixed partitioning of the coordinates is chosen ahead of time.,abstractText,[0],[0]
"We show that this setting is too restrictive, constructing instances where breaking locality by running non-accelerated Gauss-Seidel with randomly sampled coordinates substantially outperforms accelerated Gauss-Seidel with any fixed partitioning.",abstractText,[0],[0]
"Motivated by this finding, we analyze the accelerated block Gauss-Seidel algorithm in the random coordinate sampling setting.",abstractText,[0],[0]
Our analysis captures the benefit of acceleration with a new data-dependent parameter which is well behaved when the matrix subblocks are well-conditioned.,abstractText,[0],[0]
"Empirically, we show that accelerated Gauss-Seidel with random coordinate sampling provides speedups for large scale machine learning tasks when compared to non-accelerated Gauss-Seidel and the classical conjugate-gradient algorithm.",abstractText,[0],[0]
Breaking Locality Accelerates Block Gauss-Seidel,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 650–655 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
650",text,[0],[0]
"Recognizing textual entailment (RTE) (Dagan et al., 2013), recently framed as natural language inference (NLI) (Bowman et al., 2015) is a task concerned with identifying whether a premise sentence entails, contradicts or is neutral with the hypothesis sentence.",1 Introduction,[0],[0]
"Following the release of the large-scale SNLI dataset (Bowman et al., 2015), many end-to-end neural models have been developed for the task, achieving high accuracy on the test set.",1 Introduction,[0],[0]
"As opposed to previous-generation methods, which relied heavily on lexical resources, neural models only make use of pre-trained word embeddings.",1 Introduction,[0],[0]
"The few efforts to incorporate external lexical knowledge resulted in negligible performance gain (Chen et al., 2018).",1 Introduction,[0],[0]
"This raises the question whether (1) neural methods are inherently stronger, obviating the need of external lexical knowledge; (2) large-scale training data allows for implicit learning of previously explicit lexical knowledge; or (3) the NLI datasets are simpler than early RTE datasets, requiring less knowledge.
",1 Introduction,[0],[0]
"1The contradiction example follows the assumption in Bowman et al. (2015) that the premise contains the most prominent information in the event, hence the premise can’t describe the event of a man holding both instruments.
",1 Introduction,[0],[0]
"In this paper we show that state-of-the-art NLI systems are limited in their generalization ability, and fail to capture many simple inferences that require lexical and world knowledge.",1 Introduction,[0],[0]
"Inspired by the work of Jia and Liang (2017) on reading comprehension, we create a new NLI test set with examples that capture various kinds of lexical knowledge (Table 1).",1 Introduction,[0],[0]
"For example, that champagne is a type of wine (hypernymy), and that saxophone and electric guitar are different musical instruments (co-hyponyms).",1 Introduction,[0],[0]
"To isolate lexical knowledge aspects, our constructed examples contain only words that appear both in the training set and in pre-trained embeddings, and differ by a single word from sentences in the training set.
",1 Introduction,[0],[0]
"The performance on the new test set is substantially worse across systems, demonstrating that the SNLI test set alone is not a sufficient measure of language understanding capabilities.",1 Introduction,[0],[0]
"Our results are in line with Gururangan et al. (2018) and Poliak et al. (2018), who showed that the label can be identified by looking only at the hypothesis and exploiting annotation artifacts such as word choice and sentence length.
",1 Introduction,[0],[0]
Further investigation shows that what mostly affects the systems’ ability to correctly predict a test example is the amount of similar examples found in the training set.,1 Introduction,[0],[0]
"Given that training data will always be limited, this is a rather inefficient way to learn lexical inferences, stressing the need to develop methods that do this more
effectively.",1 Introduction,[0],[0]
"Our test set can be used to evaluate such models’ ability to recognize lexical inferences, and it is available at https://github.",1 Introduction,[0],[0]
com/BIU-NLP/Breaking_NLI.,1 Introduction,[0],[0]
NLI Datasets.,2 Background,[0],[0]
"The SNLI dataset (Stanford Natural Language Inference, Bowman et al., 2015) consists of 570k sentence-pairs manually labeled as entailment, contradiction, and neutral.",2 Background,[0],[0]
"Premises are image captions from Young et al. (2014), while hypotheses were generated by crowd-sourced workers who were shown a premise and asked to generate entailing, contradicting, and neutral sentences.",2 Background,[0],[0]
Workers were instructed to judge the relation between sentences given that they describe the same event.,2 Background,[0],[0]
"Hence, sentences that differ by a single mutually-exclusive term should be considered contradicting, as in “The president visited Alabama” and “The president visited Mississippi”.",2 Background,[0],[0]
"This differs from traditional RTE datasets, which do not assume event coreference, and in which such sentence-pairs would be considered neutral.
",2 Background,[0],[0]
"Following criticism on the simplicity of the dataset, stemming mostly from its narrow domain, two additional datasets have been collected.",2 Background,[0],[0]
"The MultiNLI dataset (Multi-Genre Natural Language Inference, Williams et al., 2018) was collected similarly to SNLI, though covering a wider range of genres, and supporting a cross-genre evaluation.",2 Background,[0],[0]
"The SciTail dataset (Khot et al., 2018), created from science exams, is somewhat different from the two datasets, being smaller (27,026 examples), and labeled only as entailment or neutral.",2 Background,[0],[0]
"The domain makes this dataset different in nature from the other two datasets, and it consists of more factual sentences rather than scene descriptions.
",2 Background,[0],[0]
Neural Approaches for NLI.,2 Background,[0],[0]
"Following the release of SNLI, there has been tremendous interest in the task, and many end-to-end neural models were developed, achieving promising results.2 Methods are divided into two main approaches.",2 Background,[0],[0]
"Sentence-encoding models (e.g. Bowman et al., 2015, 2016; Nie and Bansal, 2017; Shen et al., 2018) encode the premise and hypothesis individually, while attention-based models align words in the premise with similar words in the hypothesis, encoding the two sentences together (e.g. Rocktäschel et al., 2016; Chen et al., 2017).
2See the SNLI leaderboard for a comprehensive list: https://nlp.stanford.edu/projects/snli/.
External Lexical Knowledge.",2 Background,[0],[0]
"Traditional RTE methods typically relied on resources such as WordNet (Fellbaum, 1998) to identify lexical inferences.",2 Background,[0],[0]
"Conversely, neural methods rely solely on pre-trained word embeddings, yet, they achieve high accuracy on SNLI.
",2 Background,[0],[0]
"The only neural model to date that incorporates external lexical knowledge (from WordNet) is KIM (Chen et al., 2018), however, gaining only a small addition of 0.6 points in accuracy on the SNLI test set.",2 Background,[0],[0]
"This raises the question whether the small performance gap is a result of the model not capturing lexical knowledge well, or the SNLI test set not requiring this knowledge in the first place.",2 Background,[0],[0]
We construct a test set with the goal of evaluating the ability of state-of-the-art NLI models to make inferences that require simple lexical knowledge.,3 Data Collection,[0],[0]
We automatically generate sentence pairs (§3.1) which are then manually verified (§3.2).,3 Data Collection,[0],[0]
"In order to isolate the lexical knowledge aspects, the premises are taken from the SNLI training set.",3.1 Generating Adversarial Examples,[0],[0]
For each premise we generate several hypotheses by replacing a single word within the premise by a different word.,3.1 Generating Adversarial Examples,[0],[0]
"We also allow some multi-word noun phrases (“electric guitar”) and adapt determiners and prepositions when needed.
",3.1 Generating Adversarial Examples,[0],[0]
"We focus on generating only entailment and contradiction examples, while neutral examples may be generated as a by-product.",3.1 Generating Adversarial Examples,[0],[0]
"Entailment examples are generated by replacing a word with its synonym or hypernym, while contradiction examples are created by replacing words with mutually exclusive co-hyponyms and antonyms (see Table 1).",3.1 Generating Adversarial Examples,[0],[0]
"The generation steps are detailed below.
",3.1 Generating Adversarial Examples,[0],[0]
Replacement Words.,3.1 Generating Adversarial Examples,[0],[0]
We collected the replacement words using online resources for English learning.3,3.1 Generating Adversarial Examples,[0],[0]
"The newly introduced words are all present in the SNLI training set: from occurrence in a single training example (“Portugal”) up to 248,051 examples (“man”), with a mean of 3,663.1 and a median of 149.5.",3.1 Generating Adversarial Examples,[0],[0]
The words are also available in the pre-trained embeddings vocabulary.,3.1 Generating Adversarial Examples,[0],[0]
"The goal of this constraint is to isolate lexical knowledge aspects, and evaluate the models’ ability to generalize and make new inferences for known words.
3 www.enchantedlearning.com, www.smart-words.org
Replacement words are divided into topical categories detailed in Table 4.",3.1 Generating Adversarial Examples,[0],[0]
"In several categories we applied additional processing to ensure that examples are indeed mutually-exclusive, topicallysimilar, and interchangeable in context.",3.1 Generating Adversarial Examples,[0],[0]
"We included WordNet antonyms with the same part-ofspeech and with a cosine similarity score above a threshold, using GloVe (Pennington et al., 2014).",3.1 Generating Adversarial Examples,[0],[0]
"In nationalities and countries we focused on countries which are related geographically (Japan, China) or culturally (Argentina, Spain).
",3.1 Generating Adversarial Examples,[0],[0]
Sentence-Pairs.,3.1 Generating Adversarial Examples,[0],[0]
"To avoid introducing new information not present in the training data, we sampled premises from the SNLI training set that contain words from our lists, and generated hypotheses by replacing the selected word with its replacement.",3.1 Generating Adversarial Examples,[0],[0]
"Some of the generated sentences may be ungrammatical or nonsensical, for instance, when replacing Jordan with Syria in sentences discussing Michael Jordan.",3.1 Generating Adversarial Examples,[0],[0]
We used Wikipedia bigrams4 to discard sentences in which the replaced word created a bigram with less than 10 occurrences.,3.1 Generating Adversarial Examples,[0],[0]
We manually verify the correctness of the automatically constructed examples using crowdsourced workers in Amazon Mechanical Turk.,3.2 Manual Verification,[0],[0]
"To ensure the quality of workers, we applied a qualification test and required a 99% approval rate for at least 1,000 prior tasks.",3.2 Manual Verification,[0],[0]
"We assigned each annotation to 3 workers.
",3.2 Manual Verification,[0],[0]
"Following the SNLI guidelines, we instructed the workers to consider the sentences as describing the same event, but we simplified the annotation process into answering 3 simple yes/no questions:
1.",3.2 Manual Verification,[0],[0]
Do the sentences describe the same event?,3.2 Manual Verification,[0],[0]
"4 github.com/rmaestre/Wikipedia-Bigram-Open-Datasets
2.",3.2 Manual Verification,[0],[0]
"Does the new sentence (hypothesis) add new information to the original sentence (premise)?
3.",3.2 Manual Verification,[0],[0]
Is the new sentence incorrect/ungrammatical?,3.2 Manual Verification,[0],[0]
We then discarded any sentence-pair in which at least one worker answered the third question positively.,3.2 Manual Verification,[0],[0]
"If the answer to the first question was negative, we considered the label as contradiction.",3.2 Manual Verification,[0],[0]
"Otherwise, we considered the label as entailment if the answer to the second question was negative and neutral if it was positive.",3.2 Manual Verification,[0],[0]
"We used the majority vote to determine the gold label.
",3.2 Manual Verification,[0],[0]
"The annotations yielded substantial agreement, with Fleiss’ Kappa κ = 0.61",3.2 Manual Verification,[0],[0]
"(Landis and Koch, 1977).",3.2 Manual Verification,[0],[0]
"We estimate human performance to 94.1%, using the method described in Gong et al. (2018), showing that the new test set is substantially easier to humans than SNLI.",3.2 Manual Verification,[0],[0]
Table 2 provides additional statistics on the test set.5,3.2 Manual Verification,[0],[0]
Without External Knowledge.,4.1 Models,[0],[0]
"We chose 3 representative models in different approaches (sentence encoding and/or attention): RESIDUALSTACKED-ENCODER (Nie and Bansal, 2017) is a biLSTM-based single sentence-encoding model without attention.",4.1 Models,[0],[0]
"As opposed to traditional multilayer biLSTMs, the input to each next layer is the concatenation of the word embedding and the summation of outputs from previous layers.",4.1 Models,[0],[0]
"ESIM (Enhanced Sequential Inference Model, Chen et al., 2017) is a hybrid TreeLSTM-based and biLSTM-based model.",4.1 Models,[0],[0]
"We use the biLSTM model, which uses an inter-sentence attention mechanism to align words across sentences.",4.1 Models,[0],[0]
"Finally, DECOMPOSABLE ATTENTION (Parikh et al., 2016) performs soft alignment of words from the premise to words in the hypothesis using attention mechanism, and decomposes the task into comparison of aligned words.",4.1 Models,[0],[0]
Lexical-level decisions are merged to produce the final classification.,4.1 Models,[0],[0]
"We use the AllenNLP re-implementation,6 which does not implement the optional intrasentence attention, and achieves an accuracy of 84.7% on the SNLI test set, comparable to 86.3% by the original system.
",4.1 Models,[0],[0]
"5We note that due to its bias towards contradiction, the new test set can neither be used for training, nor serve as a main evaluation set for NLI.",4.1 Models,[0],[0]
"Instead, we suggest to use it in addition to the original test set in order to test a model’s ability to handle lexical inferences.
",4.1 Models,[0],[0]
"6http://allennlp.org/models
We chose models which are amongst the best performing within their approaches (excluding ensembles) and have available code.",4.1 Models,[0],[0]
"All models are based on pre-trained GloVe embeddings (Pennington et al., 2014), which are either fine-tuned during training (RESIDUAL-STACKED-ENCODER and ESIM) or stay fixed (DECOMPOSABLE ATTENTION).",4.1 Models,[0],[0]
"All models predict the label using a concatenation of features derived from the sentence representations (e.g. maximum, mean), for example as in Mou et al. (2016).",4.1 Models,[0],[0]
"We use the recommended hyper-parameters for each model, as they appear in the provided code.
",4.1 Models,[0],[0]
With External Knowledge.,4.1 Models,[0],[0]
"We provide a simple WORDNET BASELINE, in which we classify a sentence-pair according to the WordNet relation that holds between the original word wp and the replaced word wh.",4.1 Models,[0],[0]
"We predict entailment if wp is a hyponym of wh or if they are synonyms, neutral if wp is a hypernym of wh, and contradiction if wp and wh are antonyms or if they share a common hypernym ancestor (up to 2 edges).",4.1 Models,[0],[0]
"Word pairs with no WordNet relations are classified as other.
",4.1 Models,[0],[0]
"We also report the performance of KIM (Knowledge-based Inference Model, Chen et al., 2018), an extension of ESIM with external knowledge from WordNet, which was kindly provided to us by Qian Chen.",4.1 Models,[0],[0]
KIM improves the attention mechanism by taking into account the existence of WordNet relations between the words.,4.1 Models,[0],[0]
"The lexical inference component, operating over pairs of aligned words, is enriched with a vector encoding the specific WordNet relations between the words.",4.1 Models,[0],[0]
"We trained each model on 3 different datasets: (1) SNLI train set, (2) a union of the SNLI train set
and the MultiNLI train set, and (3) a union of the SNLI train set and the SciTail train set.",4.2 Experimental Settings,[0],[0]
"The motivation is that while SNLI might lack the training data needed to learn the required lexical knowledge, it may be available in the other datasets, which are presumably richer.",4.2 Experimental Settings,[0],[0]
Table 3 displays the results for all the models on the original SNLI test set and the new test set.,4.3 Results,[0],[0]
"Despite the task being considerably simpler, the drop in performance is substantial, ranging from 11 to 33 points in accuracy.",4.3 Results,[0],[0]
"Adding MultiNLI to the training data somewhat mitigates this drop in accuracy, thanks to almost doubling the amount of training data.",4.3 Results,[0],[0]
"We note that adding SciTail to the training data did not similarly improve the performance; we conjecture that this stems from the differences between the datasets.
",4.3 Results,[0],[0]
"KIM substantially outperforms the other neural models, demonstrating that lexical knowledge is the only requirement for good performance on the new test set, and stressing the inability of the other models to learn it.",4.3 Results,[0],[0]
Both WordNet-informed models leave room for improvement: possibly due to limited WordNet coverage and the implications of applying lexical inferences within context.,4.3 Results,[0],[0]
"We take a deeper look into the predictions of the models that don’t employ external knowledge, focusing on the models trained on SNLI.",5 Analysis,[0],[0]
Table 4 displays the accuracy of each model per replacement-word category.,5.1 Accuracy by Category,[0],[0]
"The neural models tend to perform well on categories which are frequent in the training set, such as colors, and badly
on categories such as planets, which rarely occur in SNLI.",5.1 Accuracy by Category,[0],[0]
"These models perform better than the WordNet baseline on entailment examples (synonyms), suggesting that they do so due to high lexical overlap between the premise and the hypothesis rather than recognizing synonymy.",5.1 Accuracy by Category,[0],[0]
We therefore focus the rest of the discussion on contradiction examples.,5.1 Accuracy by Category,[0],[0]
"The accuracies for ordinals, nationalities and countries are especially low.",5.2 Accuracy by Word Similarity,[0],[0]
We conjecture that this stems from the proximity of the contradicting words in the embedding space.,5.2 Accuracy by Word Similarity,[0],[0]
"Indeed, the Decomposable Attention model—which does not update its embeddings during training—seems to suffer the most.
",5.2 Accuracy by Word Similarity,[0],[0]
"Grouping its prediction accuracy by the cosine similarity between the contradicting words reveals a clear trend that the model errs more on contradicting pairs with similar pre-trained vectors:7
Similarity 0.5-0.6 0.6-0.7 0.7-0.8 0.8-0.9 0.9-1.0 Accuracy 46.2% 42.3% 37.5% 29.7% 20.2%",5.2 Accuracy by Word Similarity,[0],[0]
Models that fine-tune the word embeddings may benefit from training examples consisting of test replacement pairs.,5.3 Accuracy by Frequency in Training,[0],[0]
"Namely, for a given replacement pair (wp, wh), if many training examples labeled as contradiction contain wp in the premise and wh in the hypothesis, the model may update their embeddings to optimize predicting contradiction.",5.3 Accuracy by Frequency in Training,[0],[0]
"Indeed, we show that the ESIM accuracy on test pairs increases with the frequency in which
7We ignore multi-word replacements in §5.2 and §5.3.
",5.3 Accuracy by Frequency in Training,[0],[0]
their replacement words appear in contradiction examples in the training data:,5.3 Accuracy by Frequency in Training,[0],[0]
"Frequency 0 1-4 5-9 10-49 50-99 100+ Accuracy 40.2% 70.6% 91.4% 92.1% 97.5% 98.5%
This demonstrates that the model is capable of learning lexical knowledge when sufficient training data is given, but relying on explicit training examples is a very inefficient way of obtaining simple lexical knowledge.",5.3 Accuracy by Frequency in Training,[0],[0]
We created a new NLI test set with the goal of evaluating systems’ ability to make inferences that require simple lexical knowledge.,6 Conclusion,[0],[0]
"Although the test set is constructed to be much simpler than SNLI, and does not introduce new vocabulary, the state-of-the-art systems perform poorly on it, suggesting that they are limited in their generalization ability.",6 Conclusion,[0],[0]
The test set can be used in the future to assess the lexical inference abilities of NLI systems and to tease apart the performance of otherwise very similarly-performing systems.,6 Conclusion,[0],[0]
We would like to thank Qian Chen for evaluating KIM on our test set.,Acknowledgments,[0],[0]
"This work was supported in part by the German Research Foundation through the German-Israeli Project Cooperation (DIP, grant DA 1600/1-1), an Intel ICRI-CI grant, Theo Hoffenberg, and the Israel Science Foundation grants 1951/17 and 1555/15.",Acknowledgments,[0],[0]
"Vered is also supported by the Clore Scholars Programme (2017), and the AI2 Key Scientific Challenges Program (2017).",Acknowledgments,[0],[0]
We create a new NLI test set that shows the deficiency of state-of-the-art models in inferences that require lexical and world knowledge.,abstractText,[0],[0]
"The new examples are simpler than the SNLI test set, containing sentences that differ by at most one word from sentences in the training set.",abstractText,[0],[0]
"Yet, the performance on the new test set is substantially worse across systems trained on SNLI, demonstrating that these systems are limited in their generalization ability, failing to capture many simple inferences.",abstractText,[0],[0]
Breaking NLI Systems with Sentences that Require Simple Lexical Inferences,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 910–921 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
910
We present a deep neural network that leverages images to improve bilingual text embeddings. Relying on bilingual image tags and descriptions, our approach conditions text embedding induction on the shared visual information for both languages, producing highly correlated bilingual embeddings. In particular, we propose a novel model based on Partial Canonical Correlation Analysis (PCCA). While the original PCCA finds linear projections of two views in order to maximize their canonical correlation conditioned on a shared third variable, we introduce a non-linear Deep PCCA (DPCCA) model, and develop a new stochastic iterative algorithm for its optimization. We evaluate PCCA and DPCCA on multilingual word similarity and cross-lingual image description retrieval. Our models outperform a large variety of previous methods, despite not having access to any visual signal during test time inference.1",text,[0],[0]
"Research in multi-modal semantics deals with the grounding problem (Harnad, 1990), motivated by evidence that many semantic concepts, irrespective of the actual language, are grounded in the perceptual system (Barsalou and Wiemer-Hastings, 2005).",1 Introduction,[0],[0]
"In particular, recent studies have shown that performance on NLP tasks can be improved by joint modeling of text and vision, with multimodal and perceptually enhanced representation learning outperforming purely textual representa-
1Our code and data are available at: https://github. com/rotmanguy/DPCCA.
tions (Feng and Lapata, 2010; Kiela and Bottou, 2014; Lazaridou et al., 2015).
",1 Introduction,[0],[0]
"These findings are not surprising, and can be explained by the fact that humans understand language not only by its words, but also by their visual/perceptual context.",1 Introduction,[0],[0]
"The ability to connect vision and language has also enabled new tasks which require both visual and language understanding, such as visual question answering (Antol et al., 2015; Fukui et al., 2016; Xu and Saenko, 2016), image-to-text retrieval and text-to-image retrieval (Kiros et al., 2014; Mao et al., 2014), image caption generation (Farhadi et al., 2010; Mao et al., 2015; Vinyals et al., 2015; Xu et al., 2015), and visual sense disambiguation (Gella et al., 2016).
",1 Introduction,[0],[0]
"While the main focus is still on monolingual settings, the fact that visual data can serve as a natural bridge between languages has sparked additional interest towards multilingual multi-modal modeling.",1 Introduction,[0],[0]
"Such models induce bilingual multi-modal spaces based on multi-view learning (Calixto et al., 2017; Gella et al., 2017; Rajendran et al., 2016).
",1 Introduction,[0],[0]
"In this work, we propose a novel effective approach for learning bilingual text embeddings conditioned on shared visual information.",1 Introduction,[0],[0]
This additional perceptual modality bridges the gap between languages and reveals latent connections between concepts in the multilingual setup.,1 Introduction,[0],[0]
"The shared visual information in our work takes the form of images with word-level tags or sentence-level descriptions assigned in more than one language.
",1 Introduction,[0],[0]
"We propose a deep neural architecture termed Deep Partial Canonical Correlation Analysis (DPCCA) based on the Partial CCA (PCCA) method (Rao, 1969).",1 Introduction,[0],[0]
"To the best of our knowledge, PCCA has not been used in multilingual settings before.",1 Introduction,[0],[0]
"In short, PCCA is a variant of CCA which learns maximally correlated linear projections of two views (e.g., two language-specific “text-based views”) conditioned on a shared third view (e.g.,
the “visual view”).",1 Introduction,[0],[0]
"We discuss the PCCA and DPCCA methods in §3 and show how they can be applied without having access to the shared images at test time inference.
",1 Introduction,[0],[0]
PCCA inherits one disadvantageous property from CCA: both methods compute estimates for covariance matrices based on all training data.,1 Introduction,[0],[0]
"This would prevent feasible training of their deep nonlinear variants, since deep neural nets (DNNs) are predominantly optimized via stochastic optimization algorithms.",1 Introduction,[0],[0]
"To resolve this major hindrance, we propose an effective optimization algorithm for DPCCA, inspired by the work of Wang et al. (2015b) on Deep CCA (DCCA) optimization.
",1 Introduction,[0],[0]
We evaluate our DPCCA architecture on two semantic tasks: 1) multilingual word similarity and 2) cross-lingual image description retrieval.,1 Introduction,[0],[0]
"For the former, we construct and provide to the community a new Word-Image-Word (WIW) dataset containing bilingual lexicons for three languages with shared images for 5K+ concepts.",1 Introduction,[0],[0]
"WIW is used as training data for word similarity experiments, while evaluation is conducted on the standard multilingual SimLex-999 dataset (Hill et al., 2015; Leviant and Reichart, 2015).
",1 Introduction,[0],[0]
The results reveal stable improvements over a large space of non-deep and deep CCA-style baselines in both tasks.,1 Introduction,[0],[0]
"Most importantly, 1) PCCA is overall better than other methods which do not use the additional perceptual view; 2) DPCCA outperforms PCCA, indicating the importance of nonlinear transformations modeled through DNNs; 3) DPCCA outscores DCCA, again verifying the importance of conditioning multilingual text embedding induction on the shared visual view; and 4) DPCCA outperforms two recent multi-modal bilingual models which also leverage visual information (Gella et al., 2017; Rajendran et al., 2016).",1 Introduction,[0],[0]
"This work is related to two research threads: 1) multi-modal models that combine vision and language, with a focus on multilingual settings; 2) correlational multi-view models based on CCA which learn a shared vector space for multiple views.
",2 Related Work,[0],[0]
"Multi-Modal Modeling in Multilingual Settings Research in cognitive science suggests that human meaning representations are grounded in our perceptual system and sensori-motor experience (Harnad, 1990; Lakoff and Johnson, 1999; Louwerse, 2011).",2 Related Work,[0],[0]
"Visual context serves as a useful cross-
lingual grounding signal (Bruni et al., 2014; Glavaš et al., 2017) due to its language invariance, even enabling the induction of word-level bilingual semantic spaces solely through tagged images obtained from the Web (Bergsma and Van Durme, 2011; Kiela et al., 2015).",2 Related Work,[0],[0]
"Vulić et al. (2016) combine text embeddings with visual features via simple techniques of concatenation and averaging to obtain bilingual multi-modal representations, with noted improvements over text-only embeddings on word similarity and bilingual lexicon extraction.",2 Related Work,[0],[0]
"However, similar to the monolingual model of Kiela and Bottou (2014), their models lack the training phase, and require the visual signal at test time.
",2 Related Work,[0],[0]
Recent work from Gella et al. (2017) exploits visual content as a bridge between multiple languages by optimizing a contrastive loss function.,2 Related Work,[0],[0]
"Furthermore, Rajendran et al. (2016) extend the work of Chandar et al. (2016) and propose to use a pivot representation in multimodal multilingual setups, with English representations serving as the pivot.",2 Related Work,[0],[0]
"While these works learn shared multimodal multilingual vector spaces, we demonstrate improved performance with our models (see §7).
",2 Related Work,[0],[0]
"Finally, although not directly comparable, recent work in neural machine translation has constructed models that can translate image descriptions by additionally relying on visual features of the image provided (Calixto and Liu, 2017; Elliott et al., 2015; Hitschler et al., 2016; Huang et al., 2016; Nakayama and Nishida, 2017, inter alia).
",2 Related Work,[0],[0]
"Correlational Models CCA-based techniques support multiple views on related data: e.g., when coupled with a bilingual dictionary, input monolingual word embeddings for two different languages can be seen as two views of the same latent semantic signal.",2 Related Work,[0],[0]
"Recently, CCA-based models for bilingual text embedding induction were proposed.",2 Related Work,[0],[0]
"These models rely on the basic CCA model (Chandar et al., 2016; Faruqui and Dyer, 2014), its deep variant (Lu et al., 2015), and a CCA extension which supports more than two views (Funaki and Nakayama, 2015; Rastogi et al., 2015).",2 Related Work,[0],[0]
"In this work, we propose to use (D)PCCA, which organically supports our setup: it conditions the two (textual) views on a shared (visual) view.
",2 Related Work,[0],[0]
"CCA-based methods (including PCCA) require the estimation of covariance matrices over all training data (Kessy et al., 2017).",2 Related Work,[0],[0]
"This hinders the use of DNNs with these models, as DNNs are typically trained via stochastic optimization over mini-
batches on very large training sets.",2 Related Work,[0],[0]
"To address this limitation, various optimization methods for Deep CCA were proposed.",2 Related Work,[0],[0]
"Andrew et al. (2013) use L-BFGS (Byrd et al., 1995) over all training samples, while Arora and Livescu (2013) and Yan and Mikolajczyk (2015) train with large batches.",2 Related Work,[0],[0]
"However, these methods suffer from high memory complexity with unstable numerical computations.
",2 Related Work,[0],[0]
Wang et al. (2015b) have recently proposed a stochastic approach for CCA and DCCA which copes well with small and large batch sizes while preserving high model performance.,2 Related Work,[0],[0]
"They use orthogonal iterations to estimate a moving average of the covariance matrices, which improves memory consumption.",2 Related Work,[0],[0]
"Therefore, we base our novel optimization algorithm for DPCCA on this approach.",2 Related Work,[0],[0]
"Given two image descriptions x and y in two languages and an image z that they refer to, the task is to learn a shared bilingual space such that similar descriptions obtain similar representations in the induced space.",3 Methodology: Deep Partial CCA,[0],[0]
The image z serves as a shared third view on the textual data during training.,3 Methodology: Deep Partial CCA,[0],[0]
The representation model is then utilized in cross-lingual and monolingual tasks.,3 Methodology: Deep Partial CCA,[0],[0]
In this paper we focus on the more realistic scenario where no relevant visual content is available at test time.,3 Methodology: Deep Partial CCA,[0],[0]
"For this goal we propose a novel Deep Partial CCA (DPCCA) framework.
",3 Methodology: Deep Partial CCA,[0],[0]
"In what follows, we first review the CCA model and its deep variant: DCCA.",3 Methodology: Deep Partial CCA,[0],[0]
"We then introduce our DPCCA architecture, and describe our new stochastic optimization algorithm for DPCCA.",3 Methodology: Deep Partial CCA,[0],[0]
"DCCA (Andrew et al., 2013) extends CCA by learning non-linear (instead of linear) transformations of features contained in the input matrices X ∈ RDx×N and Y ∈ RDy×N , where Dx and Dy are input vector dimensionalities, and N is the number of input items.",3.1 CCA and Deep CCA,[0],[0]
"Since CCA is a special case of the non-linear DCCA (see below), we here briefly outline the more general DCCA model.
",3.1 CCA and Deep CCA,[0],[0]
The DCCA architecture is illustrated in Figure 1a.,3.1 CCA and Deep CCA,[0],[0]
Non-linear transformations are achieved through two DNNs f : RDx×N → RD′x×N and g : RDy×N → RD′y×N for X and Y .,3.1 CCA and Deep CCA,[0],[0]
D′x and D′y are the output dimensionalities.,3.1 CCA and Deep CCA,[0],[0]
"A final linear layer is added to resemble the linear CCA projection.
",3.1 CCA and Deep CCA,[0],[0]
"The goal is to project the features of X and
Y into a shared L-dimensional (1 ≤ L ≤ min(D′x, D ′ y)) space such that the canonical correlation of the final outputs F (X) = W Tf(X) and G(Y ) = V T g(Y ) is maximized.",3.1 CCA and Deep CCA,[0],[0]
W ∈ RD′x×L and V ∈ RD′y×L are projection matrices: they project the final outputs of the DNNs to the shared space.,3.1 CCA and Deep CCA,[0],[0]
"Wf and Vg (the parameters of f and g) and the projection matrices are the model parameters: WF = {Wf ,W }; VG = {Vg,V }.2",3.1 CCA and Deep CCA,[0],[0]
"Formally, the DCCA objective can be written as:
max WF ,VG Tr(Σ̂FG)
",3.1 CCA and Deep CCA,[0],[0]
"so that Σ̂FF = Σ̂GG = I. (1)
",3.1 CCA and Deep CCA,[0],[0]
Σ̂FG ≡ 1N−1F,3.1 CCA and Deep CCA,[0],[0]
"(X)G(Y ) T is the estimation of the cross-covariance matrix of the outputs, and Σ̂FF ≡ 1N−1F",3.1 CCA and Deep CCA,[0],[0]
"(X)F (X)
T , Σ̂GG ≡ 1 N−1G(Y )G(Y ) T are the estimations of the autocovariance matrices of the outputs.3 Further, following Wang et al. (2015b), the optimal solution of Eq.",3.1 CCA and Deep CCA,[0],[0]
"(1) is equivalent to the optimal solution of the following:
min WF ,VG
1
N",3.1 CCA and Deep CCA,[0],[0]
"− 1‖F (X)−G(Y )‖ 2 F
s.t. Σ̂FF",3.1 CCA and Deep CCA,[0],[0]
"= Σ̂GG = I.
(2)
",3.1 CCA and Deep CCA,[0],[0]
"The main disadvantage of DCCA is its inability to support more than two views, and to learn conditioned on an additional shared view, which is why we introduce Deep Partial CCA.",3.1 CCA and Deep CCA,[0],[0]
Figure 1b illustrates the architecture of DPCCA.,3.2 New Model: Deep Partial CCA,[0],[0]
"The training data now consists of triplets (xi,yi, zi) N 1=1 from three views, forming the columns of X , Y and Z, where xi ∈ RDx ,yi ∈ RDy , zi ∈ RDz for i = 1, . . .",3.2 New Model: Deep Partial CCA,[0],[0]
", N .",3.2 New Model: Deep Partial CCA,[0],[0]
"The objective is to maximize the canonical correlation of the first two views X and Y conditioned on the shared third variable Z. Following Rao (1969)’s work on Partial CCA, we first consider two multivariate linear multiple regression models:
F (X) = AZ + F (X|Z), (3) G(Y ) = BZ +G(Y |Z).",3.2 New Model: Deep Partial CCA,[0],[0]
"(4)
2For notational simplicity, we assume f(X) and g(Y ) to have zero-means, otherwise it is possible to centralize them at the final layer of each network to the same effect.
",3.2 New Model: Deep Partial CCA,[0],[0]
3The CCA model can be seen as a special (linear) case of the more general DCCA model.,3.2 New Model: Deep Partial CCA,[0],[0]
"The basic CCA objective can be recovered from the DCCA objective by simply setting D′x = Dx, D′y = Dy and f(X) = idX , g(Y )",3.2 New Model: Deep Partial CCA,[0],[0]
"= idY ; id is the identity mapping.
",3.2 New Model: Deep Partial CCA,[0],[0]
"A,B ∈ RL×Dz are matrices of coefficients, and F (X|Z),G(Y |Z) ∈ RL×N are normal random error matrices: residuals.",3.2 New Model: Deep Partial CCA,[0],[0]
"We then minimize the mean-squared error regression criterion:
min A
1
N",3.2 New Model: Deep Partial CCA,[0],[0]
"− 1‖F (X)−AZ‖ 2 F , (5)
min B
1
N",3.2 New Model: Deep Partial CCA,[0],[0]
− 1‖G(Y ),3.2 New Model: Deep Partial CCA,[0],[0]
−BZ‖ 2 F .,3.2 New Model: Deep Partial CCA,[0],[0]
"(6)
After obtaining the optimal solutions for the coefficients, Â and B̂, the residuals are as follows:
F (X|Z) = F (X)− ÂZ
= F (X)− Σ̂FZΣ̂−1ZZZ.",3.2 New Model: Deep Partial CCA,[0],[0]
"(7)
G(Y |Z) is computed in the analogous manner, now relying on G(Y ) and B̂Z. Σ̂S′Z ≡
1 N−1SZ T refers to the covariance matrix estimator of S′ and Z, where (S′, S) ∈ {(F ,F (X)), (G,G(Y )), (Z,Z)}.4
The canonical correlation between the residual matrices F (X|Z) and G(Y |Z) is referred to as the partial canonical correlation.",3.2 New Model: Deep Partial CCA,[0],[0]
The Deep PCCA objective can be obtained by replacing F (X) and G(Y ) with their residuals in Eq.,3.2 New Model: Deep Partial CCA,[0],[0]
"(2):
min WF ,VG
1
N − 1‖F",3.2 New Model: Deep Partial CCA,[0],[0]
"(X|Z)−G(Y |Z)‖ 2 F
s.t. Σ̂FF |Z = Σ̂GG|Z = I.
(8)
The computation of the conditional covariance matrix Σ̂FF |Z can be formulated as follows:
Σ̂FF |Z ≡ 1
N",3.2 New Model: Deep Partial CCA,[0],[0]
− 1F (X|Z)F (X|Z) T = Σ̂FF,3.2 New Model: Deep Partial CCA,[0],[0]
− Σ̂FZΣ̂−1ZZΣ̂ T FZ .,3.2 New Model: Deep Partial CCA,[0],[0]
"(9)
4A small value > 0 is added to the main diagonal of the covariance estimators for numerical stability.
",3.2 New Model: Deep Partial CCA,[0],[0]
"The other conditional covariance matrix Σ̂GG|Z is again computed in the analogous manner, replacing F with G and X with Y .5
While the (D)PCCA objective is computed over the residuals, after the network is trained (using multilingual texts and corresponding images) we can compute the representations of F (X) and G(Y ) at test time without having access to images (see the network structure in Figure 1b).",3.2 New Model: Deep Partial CCA,[0],[0]
"This heuristic enables the use of DPCCA in a real-life scenario in which images are unavailable at test time, and its encouraging results are demonstrated in §7.
",3.2 New Model: Deep Partial CCA,[0],[0]
"Model Variants We consider two DPCCA variants : 1) in DPCCA Variant A, the shared view Z is kept fixed; 2) DPCCA Variant B also optimizes over Z, as illustrated in Figure 1b.",3.2 New Model: Deep Partial CCA,[0],[0]
"Variant A may be seen as a special case of Variant B.6
Variant B learns a non-linear function of the shared variable, H(Z) = UTh(Z), during training, where h : RDz×N → RDz′×N is a DNN having the same architecture as f and g. U ∈ RDz′×L is the final linear layer of H , such that overall, the additional parameters of the model are UH = {Uh,U}.",3.2 New Model: Deep Partial CCA,[0],[0]
"Instead of assuming a linear connection between F (X) and G(Y ) to Z, as in Variant A, we now assume that the linear connection takes place with H(Z).",3.2 New Model: Deep Partial CCA,[0],[0]
"This assumption
5The original PCCA objective can be recovered by setting D′x = Dx, D′y = Dy and f(X) = idX , g(Y )",3.2 New Model: Deep Partial CCA,[0],[0]
"= idY .
",3.2 New Model: Deep Partial CCA,[0],[0]
"6For Variant A, in order for Z to be on the same range of values as in F and G, we pass it through the activation function of the network, Z = σ(Z).",3.2 New Model: Deep Partial CCA,[0],[0]
"Due to space constraints we discuss DPCCA Variant A in the supplementary material only.
changes Eq.",3.2 New Model: Deep Partial CCA,[0],[0]
"(3) and Eq. (4) to:7
F (X) = A′ ·H(Z) + F (X|H(Z)), (10) G(Y ) =",3.2 New Model: Deep Partial CCA,[0],[0]
B′ ·H(Z) +G(Y |H(Z)).,3.2 New Model: Deep Partial CCA,[0],[0]
(11),3.2 New Model: Deep Partial CCA,[0],[0]
"Training deep variants of CCA-style multi-view models is non-trivial due to estimation on the entire training set related to whitening constraints (i.e., the orthogonality of covariance matrices).",4 DPCCA: Optimization Algorithm,[0],[0]
"To overcome this issue, Wang et al. (2015b) proposed a stochastic optimization algorithm for DCCA via non-linear orthogonal iterations (DCCA NOI).",4 DPCCA: Optimization Algorithm,[0],[0]
"Relying on the solution for DCCA (§4.1), we develop a new optimization algorithm for DPCCA in §4.2.",4 DPCCA: Optimization Algorithm,[0],[0]
"The DCCA optimization from Wang et al. (2015b), fully provided in Algorithm 1, relies on three key steps.",4.1 Optimization of DCCA,[0],[0]
"First, the estimation of the covariance matrices in the form of Σ̂FF t at time t is calculated by a moving average over the minibatches:
Σ̂FF t ←ρΣ̂FF t−1
+ (1− ρ) ( |bt| N − 1 )−1",4.1 Optimization of DCCA,[0],[0]
F (Xbt)F (Xbt) T .,4.1 Optimization of DCCA,[0],[0]
"(12)
bt is the minibatch at time t, Xbt is the current input matrix at time t, and ρ ∈",4.1 Optimization of DCCA,[0],[0]
"[0, 1] controls the ratio between the overall covariance estimation and the covariance estimation of the current minibatch.8",4.1 Optimization of DCCA,[0],[0]
"This step eliminates the need of estimating the covariances over all training data, as well as the inherent bias when the estimate relies only on the current minibatch.
",4.1 Optimization of DCCA,[0],[0]
"Second, the DCCA NOI algorithm forces the whitening constraints to hold by performing an explicit matrix transformation in the form of:
˜F (Xbt) =",4.1 Optimization of DCCA,[0],[0]
Σ̂ − 1 2 FFt F (Xbt).,4.1 Optimization of DCCA,[0],[0]
"(13)
",4.1 Optimization of DCCA,[0],[0]
"According to Horn et al. (1988), if ρ = 0:( |bt| N − 1 )−1",4.1 Optimization of DCCA,[0],[0]
˜F (Xbt) ˜F (Xbt)T = I. (14),4.1 Optimization of DCCA,[0],[0]
"Finally, in order to optimize the DCCA objective (see Eq. (2)), the weights of the two DNNs are decoupled: i.e., the objective is disassembled into two separate mean-squared error objectives.",4.1 Optimization of DCCA,[0],[0]
"Instead of
7Note that the matrices of coefficients A′ , B′ ∈ RL×L. 8Setting ρ to a high value indicates slow updates of the estimator; setting it low mostly erases the overall estimation and relies more on the current minibatch estimation.
",4.1 Optimization of DCCA,[0],[0]
Algorithm 1,4.1 Optimization of DCCA,[0],[0]
The non-linear orthogonal iterations (NOI) algorithm for DCCA (DCCA NOI,4.1 Optimization of DCCA,[0],[0]
") Input: Data matrices X ∈ RDx×N , Y ∈ RDy×N , time constant ρ, learning rate η.
initialization: Initialize weights (WF , VG).",4.1 Optimization of DCCA,[0],[0]
"Randomly choose a minibatch (Xb0 , Yb0 ).",4.1 Optimization of DCCA,[0],[0]
Initialize covariances:,4.1 Optimization of DCCA,[0],[0]
Σ̂FF ← N−1|b0| F,4.1 Optimization of DCCA,[0],[0]
"(Xb0)F (Xb0) T Σ̂GG ← N−1|b0| G(Yb0)G(Yb0) T
for t = 1, 2, . . .",4.1 Optimization of DCCA,[0],[0]
",",4.1 Optimization of DCCA,[0],[0]
n,4.1 Optimization of DCCA,[0],[0]
"do Randomly choose a minibatch (Xbt , Ybt ).
",4.1 Optimization of DCCA,[0],[0]
Update covariances: Σ̂FF ← ρΣ̂FF + (1− ρ)N−1|bt| F (Xbt)F (Xbt) T Σ̂GG ← ρΣ̂GG + (1− ρ)N−1|bt| G(Ybt)G(Ybt) T Fix G̃(Ybt) =,4.1 Optimization of DCCA,[0],[0]
"Σ̂ − 1 2 GGG(Ybt), and compute ∇WF with respect to:
min WF
1 |bt|‖F (Xbt)− G̃(Ybt)‖ 2 F
Update parameters: WF ←WF − η∇WF",4.1 Optimization of DCCA,[0],[0]
Fix ˜F,4.1 Optimization of DCCA,[0],[0]
(Xbt) = Σ̂,4.1 Optimization of DCCA,[0],[0]
"− 1 2
FF F (Xbt), and compute ∇VG with respect to:
min VG
1 |bt|‖G(Ybt)− ˜F (Xbt)‖2F
Update parameters: VG ← VG − η∇VG end for
Output: (WF ,VG)
trying to bring F (Xbt) and G(Ybt) closer in one gradient descent step, two steps are performed: one of the views is fixed, and a gradient step over the other is performed, and so on, iteratively.",4.1 Optimization of DCCA,[0],[0]
"The final objective functions at each time step are:
min WF
1
|bt| ‖F (Xbt)− G̃(Ybt)‖ 2 F , (15)
min VG
1
|bt| ‖G(Ybt)− ˜F (Xbt)‖ 2 F .",4.1 Optimization of DCCA,[0],[0]
"(16)
Wang et al. (2015b) show that the projection matrices W and V converge to the exact solutions of CCA as t→∞ when considering linear CCA.",4.1 Optimization of DCCA,[0],[0]
Our DPCCA optimization is based on the DCCA NOI algorithm with several adjustments.,4.2 Optimization of DPCCA,[0],[0]
"Besides the requirement to obtain the sample covariances Σ̂FF and Σ̂GG, when calculating the conditional variables F (X|Z), G(Y |Z), Σ̂FF |Z and Σ̂GG|Z , we additionally have to obtain the stochastic estimators Σ̂FZ , Σ̂GZ and Σ̂ZZ .",4.2 Optimization of DPCCA,[0],[0]
"To this end, we use the moving average estimation from Eq. (12).",4.2 Optimization of DPCCA,[0],[0]
"Next, we define the whitening transformation on the residuals:
˜F",4.2 Optimization of DPCCA,[0],[0]
"(Xbt |Zbt) = Σ̂ − 1 2 FFt|ZF (Xbt |Zbt), (17)
˜G(Ybt |Zbt) =",4.2 Optimization of DPCCA,[0],[0]
Σ − 1 2 GGt|ZG(Ybt |Zbt).,4.2 Optimization of DPCCA,[0],[0]
"(18)
As before, the whitening constraints hold when ρ = 0.",4.2 Optimization of DPCCA,[0],[0]
"From here, we derive our two final objective functions over the residuals at time t:
min WF
1
|bt| ‖F (Xbt |Zbt)− ˜G(Ybt |Zbt)‖ 2 F , (19)
min VG
1
|bt| ‖G(Ybt |Zbt)− ˜F",4.2 Optimization of DPCCA,[0],[0]
(Xbt |Zbt)‖ 2 F .,4.2 Optimization of DPCCA,[0],[0]
"(20)
Equivalently to Eq. (15)-(16) that replace Eq. (2), Eq. (19)-(20) replace Eq.",4.2 Optimization of DPCCA,[0],[0]
"(8) by performing stochastic, decoupled and unconstrained steps.",4.2 Optimization of DPCCA,[0],[0]
"As our algorithm performs CCA over the residuals, we gain the same guarantees as Wang et al. (2015b), now for the projection matrices of the residuals.
",4.2 Optimization of DPCCA,[0],[0]
Algorithm 2 shows the full optimization procedure for the more complex DPCCA Variant B.,4.2 Optimization of DPCCA,[0],[0]
The full algorithm for Variant A is provided in the supplementary material.,4.2 Optimization of DPCCA,[0],[0]
"The main difference is that with Variant B we replace Z with H(Z) in all equations where it appears, and we optimize over UH along with WF and VG in Eq. (19) and Eq. (20), respectively.",4.2 Optimization of DPCCA,[0],[0]
Cross-lingual Image Description Retrieval,5 Tasks and Data,[0],[0]
"The cross-lingual image description retrieval task is formulated as follows: taking an image description as a query in the source language, the system has to retrieve a set of relevant descriptions in the target language which describe the same image.",5 Tasks and Data,[0],[0]
"Our evaluation assumes a single-best scenario, where only a single target description is relevant for each query.",5 Tasks and Data,[0],[0]
"In addition, in our setup, images are not available during inference: retrieval is performed based solely on text queries.",5 Tasks and Data,[0],[0]
This enables a fair comparison between our model and many baseline models that cannot represent images and text in a shared space.,5 Tasks and Data,[0],[0]
"Moreover, it allows us to test our model in the realistic setup where images are not available at test time.",5 Tasks and Data,[0],[0]
"To avoid the use of images at retrieval time with DPCCA, we perform the retrieval on F (X) and G(Y ), rather than on F (X|Z) and G(Y |Z) (see §3.2).
",5 Tasks and Data,[0],[0]
"We use the Multi30K dataset (Elliott et al., 2016), originated from Flickr30K (Young et al., 2014) that is comprised of Flicker images described with 1-5 English descriptions per image.",5 Tasks and Data,[0],[0]
"Multi30K adds
Algorithm 2 The non-linear orthogonal iterations (NOI) algorithm for DPCCA Variant B Input: Data matrices X ∈ RDx×N , Y ∈ RDy×N , Z ∈ RDz×N , time constant ρ, learning rate η.
initialization: Initialize weights (WF ,VG,UH ).",5 Tasks and Data,[0],[0]
"Randomly choose a minibatch (Xb0 ,Yb0 ,Zb0 ).",5 Tasks and Data,[0],[0]
Initialize covariances:,5 Tasks and Data,[0],[0]
Σ̂FF ← N−1|b0| F,5 Tasks and Data,[0],[0]
"(Xb0)F (Xb0) T Σ̂GG ← N−1|b0| G(Yb0)G(Yb0) T Σ̂HH ← N−1|b0| H(Zb0)H(Zb0) T Σ̂FH ← N−1|b0| F (Xb0)H(Zb0) T Σ̂GH ← N−1|b0| G(Yb0)H(Zb0) T
for t = 1, 2, . . .",5 Tasks and Data,[0],[0]
",",5 Tasks and Data,[0],[0]
n,5 Tasks and Data,[0],[0]
"do Randomly choose a minibatch (Xbt ,Ybt ,Zbt ).",5 Tasks and Data,[0],[0]
Update covariances: Σ̂FF ← ρΣ̂FF + (1− ρ)N−1|bt| F (Xbt)F (Xbt) T Σ̂GG ← ρΣ̂GG + (1− ρ)N−1|bt| G(Ybt)G(Ybt) T Σ̂HH ← ρΣ̂HH + (1− ρ)N−1|bt| H(Zbt)H(Zbt) T Σ̂FH ← ρΣ̂FH + (1− ρ)N−1|bt| F (Xbt)H(Zbt) T Σ̂GH,5 Tasks and Data,[0],[0]
← ρΣ̂GH,5 Tasks and Data,[0],[0]
+,5 Tasks and Data,[0],[0]
"(1− ρ)N−1|bt| G(Ybt)H(Zbt) T
Update conditional variables: F |H ← F (Xbt)− Σ̂FHΣ̂ −1",5 Tasks and Data,[0],[0]
HHH(Zbt) G|H ← G(Ybt)− Σ̂GHΣ̂ −1,5 Tasks and Data,[0],[0]
HHH(Zbt),5 Tasks and Data,[0],[0]
Σ̂FF |H,5 Tasks and Data,[0],[0]
← Σ̂FF,5 Tasks and Data,[0],[0]
"− Σ̂FHΣ̂−1HHΣ̂ T FH Σ̂GG|H ← Σ̂GG − Σ̂GHΣ̂−1HHΣ̂ T GH
Fix G̃|H = Σ̂− 1 2
GG|HG|H , and compute ∇WF , ∇UH with respect to: min WF ,UH 1 |bt|‖F |H",5 Tasks and Data,[0],[0]
− G̃|H‖,5 Tasks and Data,[0],[0]
"2 F
Update parameters: WF ←WF − η∇WF ,UH ← UH − η∇UH Fix F̃ |H = Σ̂− 1 2
FF |HF |H , and compute ∇VG, ∇UH with respect to: min VG,UH 1 |bt|‖G|H − F̃ |H‖",5 Tasks and Data,[0],[0]
"2 F
Update parameters: VG ← VG − η∇VG,UH ← UH",5 Tasks and Data,[0],[0]
"− η∇UH end for
Output: (WF ,VG,UH )
German descriptions to a total of 30,014 images: most were written independently of the English descriptions, while some are direct translations.",5 Tasks and Data,[0],[0]
Each image is associated with one English and one German description.,5 Tasks and Data,[0],[0]
"We rely on the original Multi30K splits with 29,000, 1,014, and 1,000 triplets for training, validation, and test, respectively.
",5 Tasks and Data,[0],[0]
Multilingual Word Similarity The word similarity task tests the correlation between automatic and human generated word similarity scores.,5 Tasks and Data,[0],[0]
"We evaluate with the Multilingual SimLex-999 dataset (Leviant and Reichart, 2015): the 999 English (EN)
word pairs from SimLex-999 (Hill et al., 2015) were translated to German (DE), Italian (IT), and Russian (RU), and similarity scores were crowdsourced from native speakers.
",5 Tasks and Data,[0],[0]
"We introduce a new dataset termed Word-ImageWord (WIW), which we use to train word-level models for the multilingual word similarity task.",5 Tasks and Data,[0],[0]
"WIW contains three bilingual lexicons (EN-DE, EN-IT, EN-RU) with images shared between words in a lexicon entry.",5 Tasks and Data,[0],[0]
"Each WIW entry is a triplet: an English word, its translation in DE/IT/RU, and a set of images relevant to the pair.
",5 Tasks and Data,[0],[0]
English words were taken from the January 2017 Wikipedia dump.,5 Tasks and Data,[0],[0]
"After removing stop words and punctuation, we extract the 6,000 most frequent words from the cleaned corpus not present in SimLex.",5 Tasks and Data,[0],[0]
DE/IT/RU words were obtained semiautomatically from the EN words using Google Translate.,5 Tasks and Data,[0],[0]
The images are crawled from the Bing search engine using MMFeat9,5 Tasks and Data,[0],[0]
"(Kiela, 2016) by querying the EN words only.",5 Tasks and Data,[0],[0]
"Following the suggestions from the study of Kiela et al. (2016), we save the top 20 images as relevant images.10
Table 1 provides a summary of the WIW dataset.",5 Tasks and Data,[0],[0]
"The dataset contains both concrete and abstract words, and words of different POS tags.11",5 Tasks and Data,[0],[0]
"This property has an influence on the image collection: similar to Kiela et al. (2014), we have noticed that images of more concrete concepts are less dispersed (see also examples from Figure 2).",5 Tasks and Data,[0],[0]
"Data Preprocessing and Embeddings For the sentence-level task, all descriptions were lower-
9https://github.com/douwekiela/mmfeat.",6 Experimental Setup,[0],[0]
10Offensive words and images are manually cleaned.,6 Experimental Setup,[0],[0]
"11POS tag information is taken from the NLTK toolkit for
the English words.
cased and tokenized.",6 Experimental Setup,[0],[0]
Each sentence is represented with one vector: the average of its word embeddings.,6 Experimental Setup,[0],[0]
"For English, we rely on 500-dimensional English skip-gram word embeddings (Mikolov et al., 2013) trained on the January 2017 Wikipedia dump with bag-of-words contexts (window size of 5).",6 Experimental Setup,[0],[0]
"For German we use the deWaC 1.7B corpus (Baroni et al., 2009) to obtain 500-dimensional German embeddings using the same word embedding model.",6 Experimental Setup,[0],[0]
"For word similarity, to be directly comparable to previous work, we rely on 300-dim word vectors in EN, DE, IT, and RU from Mrkšić et al. (2017).
",6 Experimental Setup,[0],[0]
"Visual features are extracted from the penultimate layer (FC7) of the VGG-19 network (Simonyan and Zisserman, 2015), and compressed to the dimensionality of the textual inputs by a Principal Component Analysis (PCA) step.",6 Experimental Setup,[0],[0]
"For the word similarity task, we average the visual vectors across all images of each word pair as done in, e.g., (Vulić et al., 2016), before the PCA step.
",6 Experimental Setup,[0],[0]
Baseline Models,6 Experimental Setup,[0],[0]
We consider a wide variety of multi-view CCA-based baselines.,6 Experimental Setup,[0],[0]
"First, we compare against the original (linear) CCA model (Hotelling, 1936), and its deep non-linear extension DCCA (Andrew et al., 2013).",6 Experimental Setup,[0],[0]
"For DCCA: 1) we rely on its improved optimization algorithm from Wang et al. (2015a) which uses a stochastic approach with large minibatches; 2) we compare against the DCCA NOI variant (Wang et al., 2015b) described by Algorithm 1, and another recent DCCA variant with the optimization algorithm based on a stochastic decorrelational loss (Chang et al., 2017) (DCCA SDL); and 3) we also test the DCCA Autoencoder model (DCCAE)",6 Experimental Setup,[0],[0]
"(Wang et al., 2015a), which offers a trade-off between maximizing the canonical correlation of two sets of variables and finding informative features for their reconstruction.
",6 Experimental Setup,[0],[0]
"Another baseline is Generalized CCA (GCCA) (Funaki and Nakayama, 2015; Horst, 1961; Rastogi et al., 2015): a linear model which extends CCA to
three or more views.",6 Experimental Setup,[0],[0]
"Unlike PCCA, GCCA does not condition two variables on the third shared one, but rather seeks to maximize the canonical correlations of all pairs of views.",6 Experimental Setup,[0],[0]
"We also compare to Nonparametric CCA (NCCA) (Michaeli et al., 2016), and to a probabilistic variant of PCCA (PPCCA, Mukuta and Harada (2014)).
",6 Experimental Setup,[0],[0]
"Finally, we compare with the two recent models which operate in the setup most similar to ours: 1) Bridge Correlational Networks (BCN) (Rajendran et al., 2016); and 2)",6 Experimental Setup,[0],[0]
Image Pivoting (IMG PIVOT) from Gella et al. (2017).,6 Experimental Setup,[0],[0]
"For both models, we report results only with the strongest variant based on the findings from the original papers, also verified by additional experimentation in our work.12
Hyperparameter Tuning The hyperparameters of the different models are tuned with a grid search over the following values: {2,3,4,5} for number of layers, {tanh, sigmoid, ReLU} as the activation functions (we use the same activation function in all the layers of the same network), {64,128,256} for minibatch size, {0.001,0.0001} for learning rate, and {128,256} for L (the size of the output vectors).",6 Experimental Setup,[0],[0]
The dimensions of all mid-layers are set to the input size.,6 Experimental Setup,[0],[0]
"We use the Adam optimizer (Kingma and Ba, 2015), with the number of epochs set to 300.
",6 Experimental Setup,[0],[0]
"For all participating models, we report test performance of the best hyperparameter on the validation set.",6 Experimental Setup,[0],[0]
"For word similarity, following a standard practice (Levy et al., 2015; Vulić et al., 2017)",6 Experimental Setup,[0],[0]
"we tune all models on one half of the SimLex data and evaluate on the other half, and vice versa.",6 Experimental Setup,[0],[0]
The reported score is the average of the two halves.,6 Experimental Setup,[0],[0]
Similarity scores for all tasks were computed using the cosine similarity measure.,6 Experimental Setup,[0],[0]
"Cross-lingual Image Description Retrieval We report two standard evaluation metrics: 1) Recall at 1 (R@1) scores, and 2) the sentence-level BLEU+1 metric (Lin and Och, 2004), a variant of BLEU which smooths terms for higher-order n-grams, making it more suitable for evaluating short sentences.",7 Results and Discussion,[0],[0]
"The scores for the retrieval task with all models are summarized in Table 2.
12 More details about preprocessing and baselines (including all links to their code), are in the the supplementary material.",7 Results and Discussion,[0],[0]
"We use original readily available implementations of all baselines whenever this is possible, and our in-house implementations for baselines for which no code is provided by the original authors.
",7 Results and Discussion,[0],[0]
The results clearly demonstrate the superiority of DPCCA (with a slight advantage to the more complex Variant B) and of the concatenation of their representation with that of the DCCA NOI (strongest) baseline.,7 Results and Discussion,[0],[0]
"Furthermore, the non-deep, linear PCCA achieves strong results: it outscores all non-deep models, as well as all deep models except from DCCA NOI, IMG PIVOT in one case, and its deep version: DPCCA.",7 Results and Discussion,[0],[0]
"This emphasizes our contribution in proposing PCCA for multilingual processing with images as a cross-lingual bridge.
",7 Results and Discussion,[0],[0]
The results suggest that: 1) the inclusion of visual information in the training process helps the retrieval task even without such information during inference.,7 Results and Discussion,[0],[0]
"DPCCA outscores all DCCA variants (either alone or through a concatenation with the DCCA NOI representation), and PCCA outscores the original two-view CCA model; and 2) deep, non-linear architectures are useful: our DPCCA outperforms the linear PCCA model.
",7 Results and Discussion,[0],[0]
We also note clear improvements over the two recent models which also rely on visual information: IMG PIVOT and BCN.,7 Results and Discussion,[0],[0]
"The gain over IMG PIVOT is observed despite the fact that IMG PIVOT is a more complex multi-modal model which relies on RNNs, and is tailored to sentence-level tasks.",7 Results and Discussion,[0],[0]
"Finally, the scores from Table 2 suggest that improved performance can be achieved by an ensemble model, that is, a simple concatenation of DPCCA (B) and DCCA NOI.
Multilingual Word Similarity The results, presented as standard Spearman’s rank correlation scores, are summarized in Table 3: we present fine-grained results over different POS classes for EN and DE, and compare them to the results from
a selection of strongest baselines.",7 Results and Discussion,[0],[0]
"Further, Table 4 presents results on all SimLex word pairs.",7 Results and Discussion,[0],[0]
The POS class result patterns for EN-IT and EN-RU are very similar to the patterns in Table 3 and are provided in the supplementary material.,7 Results and Discussion,[0],[0]
"First, the results over the initial monolingual embeddings before training (INIT EMB) clearly indicate that multilingual information is beneficial for the word similarity task.",7 Results and Discussion,[0],[0]
"We observe improvements with all models (the only exception being extremely lowscoring PPCCA and NCCA, not shown).",7 Results and Discussion,[0],[0]
"Moreover, by additionally grounding concepts from two languages in the visual modality it is possible to further boost word similarity scores.",7 Results and Discussion,[0],[0]
"This result is in line with prior work in monolingual settings (Chrupała et al., 2015; Kiela and Bottou, 2014; Lazaridou et al., 2015), which have shown to profit from multi-modal features.
",7 Results and Discussion,[0],[0]
"The results on the POS classes represented in SimLex-999 (nouns, verbs, adjectives, Table 3) form our main finding: conditioning the multilingual representations on a shared image leads to improvements in verb and adjective representations.",7 Results and Discussion,[0],[0]
"While for nouns one of the DPCCA variants is the best performing model for both languages, the gaps from the best performing baselines are much smaller.",7 Results and Discussion,[0],[0]
"This is interesting since, e.g., verbs are
more abstract than nouns (Hartmann and Søgaard, 2017; Hill et al., 2014).",7 Results and Discussion,[0],[0]
"Considering the fact that SimLex-999 consists of 666 noun pairs, 222 verb pairs and 111 adjective pairs, this is the reason that the gains of DPCCA over the strongest baselines across the entire evaluation set are more modest (Table 4).",7 Results and Discussion,[0],[0]
We note again that the same patterns presented in Table 3 for EN-DE – more prominent verb and adjective gains and a smaller gain on nouns – also hold for EN-IT and EN-RU (see the supplementary material).,7 Results and Discussion,[0],[0]
We addressed the problem of utilizing images as a bridge between languages to learn improved bilingual text representations.,8 Conclusion and Future Work,[0],[0]
Our main contribution is two-fold.,8 Conclusion and Future Work,[0],[0]
"First, we proposed to use the Partial CCA (PCCA) method.",8 Conclusion and Future Work,[0],[0]
"In addition, we proposed a stochastic optimization algorithm for the deep version of PCCA that overcomes the challenges posed by the covariance estimation required by the method.",8 Conclusion and Future Work,[0],[0]
Our experiments reveal the effectiveness of these methods for both sentence-level and wordlevel tasks.,8 Conclusion and Future Work,[0],[0]
"Crucially, our proposed solution does not require access to images at inference/test time, in line with the realistic scenario where images that describe sentential queries are not readily available.
",8 Conclusion and Future Work,[0],[0]
In future work we plan to improve our methods by exploiting the internal structure of images and sentences as well as by effectively integrating signals from more than two languages.,8 Conclusion and Future Work,[0],[0]
IV is supported by the ERC Consolidator Grant LEXICAL:,Acknowledgments,[0],[0]
Lexical Acquisition Across Languages (no 648909).,Acknowledgments,[0],[0]
GR and RR are supported by the Infomedia Magnet Grant and by an AOL grant on ”connected experience technologies”.,Acknowledgments,[0],[0]
We present a deep neural network that leverages images to improve bilingual text embeddings.,abstractText,[0],[0]
"Relying on bilingual image tags and descriptions, our approach conditions text embedding induction on the shared visual information for both languages, producing highly correlated bilingual embeddings.",abstractText,[0],[0]
"In particular, we propose a novel model based on Partial Canonical Correlation Analysis (PCCA).",abstractText,[0],[0]
"While the original PCCA finds linear projections of two views in order to maximize their canonical correlation conditioned on a shared third variable, we introduce a non-linear Deep PCCA (DPCCA) model, and develop a new stochastic iterative algorithm for its optimization.",abstractText,[0],[0]
We evaluate PCCA and DPCCA on multilingual word similarity and cross-lingual image description retrieval.,abstractText,[0],[0]
"Our models outperform a large variety of previous methods, despite not having access to any visual signal during test time inference.1",abstractText,[0],[0]
Bridging Languages through Images with Deep Partial Canonical Correlation Analysis,title,[0],[0]
"Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1699–1710, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.",text,[0],[0]
"Semantic parsers map sentences to formal representations of their meaning (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Liang et al., 2011).",1 Introduction,[0],[0]
"Existing learning algorithms have primarily focused on building actionable meaning representations which can, for example, directly query a database (Liang et al., 2011; Kwiatkowski et al., 2013) or instruct a robotic agent (Chen, 2012; Artzi and Zettlemoyer, 2013b).",1 Introduction,[0],[0]
"However, due to their end-to-end nature, such models must be relearned for each new target application and have only been used to parse restricted styles of text, such as questions and imperatives.
",1 Introduction,[0],[0]
"Recently, AMR (Banarescu et al., 2013) was proposed as a general-purpose meaning representation language for broad-coverage text, and work is ongoing to study its use for variety of applications such as machine translation (Jones et al., 2012) and summarization (Liu et al., 2015).",1 Introduction,[0],[0]
"The
∗Work done at the University of Washington.
",1 Introduction,[0],[0]
"AMR meaning bank provides a large new corpus that, for the first time, enables us to study the problem of grammar induction for broad-coverage semantic parsing.",1 Introduction,[0],[0]
"However, it also presents significant challenges for existing algorithms, including much longer sentences, more complex syntactic phenomena and increased use of noncompositional semantics, such as within-sentence coreference.",1 Introduction,[0],[0]
"In this paper, we introduce a new, scalable Combinatory Categorial Grammar (CCG; Steedman, 1996, 2000) induction approach that solves these challenges with a learned joint model of both compositional and non-compositional semantics, and achieves state-of-the-art performance on AMR Bank parsing.
",1 Introduction,[0],[0]
We map sentences to AMR structures in a twostage process (Section 5).,1 Introduction,[0],[0]
"First, we use CCG to construct lambda-calculus representations of the compositional aspects of AMR.",1 Introduction,[0],[0]
"CCG is designed to capture a wide range of linguistic phenomena, such as coordination and long-distance dependencies, and has been used extensively for semantic parsing.",1 Introduction,[0],[0]
"To use CCG for AMR parsing we define a simple encoding for AMRs in lambda calculus, for example, as seen with the logical form z and AMR a in Figure 1 for the sentence Pyongyang officials denied their involvement.",1 Introduction,[0],[0]
"However, using CCG to construct such logical forms requires a new mechanism for non-compositional reasoning, for example to model the long-range anaphoric dependency introduced by their in Figure 1.
To represent such dependencies while maintaining a relatively compact grammar, we follow Steedman’s (2011) use of generalized Skolem terms, a mechanism to allow global references in lambda calculus.",1 Introduction,[0],[0]
We then allow the CCG derivation to mark when non-compositional reasoning is required with underspecified placeholders.,1 Introduction,[0],[0]
"For example, Figure 1 shows an underspecified logical form u that would be constructed by the grammar with the bolded placeholder ID indicating an un-
1699
resolved anaphoric reference.",1 Introduction,[0],[0]
"These placeholders are resolved by a factor graph model that is defined over the output logical form and models which part of it they refer to, for example to find the referent for a pronoun.",1 Introduction,[0],[0]
"Although primarily motivated by non-compositional reasoning, we also use this mechanism to underspecify certain relations during parsing, allowing for more effective search.
",1 Introduction,[0],[0]
"Following most work in semantic parsing, we consider two learning challenges: grammar induction, which assigns meaning representations to words and phrases, and parameter estimation, where we learn a model for combining these pieces to analyze full sentences.",1 Introduction,[0],[0]
"We introduce a new CCG grammar induction algorithm which incorporates ideas from previous algorithms (Zettlemoyer and Collins, 2005; Kwiatkowski et al., 2010) in a way that scales to the longer sentences and more varied syntactic constructions observed in newswire text.",1 Introduction,[0],[0]
"During lexical generation (Section 6.1), the algorithm first attempts to use a set of templates to hypothesize new lexical entries.",1 Introduction,[0],[0]
"It then attempts to combine bottom-up parsing with top-down recursive splitting to select the best entries and learn new templates for complex syntactic and semantic phenomena, which are re-used in later sentences to hypothesize new entries.
",1 Introduction,[0],[0]
"Finally, while previous algorithms (e.g., Zettlemoyer and Collins, 2005) have assumed the existence of a grammar that can parse nearly every sentence to update its parameters, this does not hold for AMR Bank.",1 Introduction,[0],[0]
"Due to sentence complexity and search errors, our model cannot produce fully correct logical forms for a significant portion of the training data.",1 Introduction,[0],[0]
"To learn from as much of the data as possible and accelerate learning, we adopt an early update strategy to generate effective updates from partially correct analyses (Section 6.2).
",1 Introduction,[0],[0]
"We evaluate performance on the publicly available AMR Bank (Banarescu et al., 2013) and demonstrate that our modeling and learning contributions are crucial for grammar induction at this scale and achieve new state-of-the-art results for AMR parsing (Section 8).",1 Introduction,[0],[0]
"In addition, we also present, for the first time, results without surfaceform alignment heuristics, which demonstrates the need for future work, especially to generalize to other languages.",1 Introduction,[0],[0]
"The source code and learned models are available online.1
1http://yoavartzi.com/amr",1 Introduction,[0],[0]
Task Let X be the set of all possible sentences and A the set of all AMR structures.,2 Technical Overview,[0],[0]
"Given a sentence x ∈ X , we aim to generate an AMR a ∈ A.",2 Technical Overview,[0],[0]
"We define a simple, deterministic and invertible conversion process between AMRs and lambdacalculus logical forms; roughly speaking, each AMR variable gets its own lambda term, which is scoped as low as possible, and each AMR role becomes a binary predicate applied to these variables.",2 Technical Overview,[0],[0]
"Figure 1 shows an example, and the full details are provided in the supplementary materials.",2 Technical Overview,[0],[0]
"Therefore, henceforth we discuss the task of mapping a sentence x ∈ X to a logical form z ∈ Z , where Z is the set of all logical forms.",2 Technical Overview,[0],[0]
"For example, in Figure 1, we would map the sentence x to the logical form",2 Technical Overview,[0],[0]
"z. We evaluate system performance using SMATCH (Cai and Knight, 2013).
",2 Technical Overview,[0],[0]
Model,2 Technical Overview,[0],[0]
"Given a sentence x and lexicon Λ, we generate the set of possible derivations GEN(x,Λ) using a two-stage process (Section 5).",2 Technical Overview,[0],[0]
"First, we use a weighted CCG to map x to an underspecified logical form u (Section 5.1), a logical form with placeholder constants for unresolved elements.",2 Technical Overview,[0],[0]
"For example, in the underspecified logical form u in Figure 1, the constants REL-of , REL and ID are placeholders.",2 Technical Overview,[0],[0]
"We then resolve
these placeholders by defining a factor graph to find their optimal mapping and generate the final logical form z.",2 Technical Overview,[0],[0]
"In the figure, REL-of is mapped to ARG0-of , REL to ARG2 and ID to 2.
",2 Technical Overview,[0],[0]
"Learning We assume access to a training set of N examples {(xi, zi) : i = 1 . . .",2 Technical Overview,[0],[0]
"N}, each containing a sentence xi and a logical form zi.",2 Technical Overview,[0],[0]
"Our goal is to learn a CCG, which constitutes learning the lexicon and estimating the parameters of both the grammar and the factor graph.",2 Technical Overview,[0],[0]
We define a learning procedure (Section 6) that alternates between expanding the lexicon and updating the parameters.,2 Technical Overview,[0],[0]
"Learning new lexical entries relies on a two-pass process that combines learning the meaning of words and new syntactic structures, and supports learning with and without alignment heuristics (e.g., from Flanigan et al., 2014).",2 Technical Overview,[0],[0]
The problem of learning semantic parsers has received significant attention.,3 Related Work,[0],[0]
"Algorithms have been developed for learning from different forms of supervision, including logical forms (Wong and Mooney, 2007; Muresan, 2011), question-answer pairs (Clarke et al., 2010; Liang et al., 2011; Cai and Yates, 2013; Kwiatkowski et al., 2013), sentences paired with demonstrations (Goldwasser and Roth, 2011; Chen and Mooney, 2011), conversational logs (Artzi and Zettlemoyer, 2011), distant supervision (Krishnamurthy and Mitchell, 2012, 2015; Reddy et al., 2014) and without explicit semantic supervision (Poon, 2013).
",3 Related Work,[0],[0]
"Although we are first to consider using CCG to build AMR representations, our work is closely related to existing methods for CCG semantic parsing.",3 Related Work,[0],[0]
"Previous CCG induction techniques have either used hand-engineered lexical templates (e.g., Zettlemoyer and Collins, 2005) or learned templates from the data directly",3 Related Work,[0],[0]
"(e.g., Kwiatkowski et al., 2010, 2012).",3 Related Work,[0],[0]
"Our two-pass reasoning for lexical generation combines ideas from both methods in a way that greatly improves scalability to long, newswire-style sentences.",3 Related Work,[0],[0]
"CCG has also been used for broad-coverage recovery of firstorder logic representations (Bos, 2008; Lewis and Steedman, 2013).",3 Related Work,[0],[0]
"However, this work lacked corpora to evaluate the logical forms recovered.
",3 Related Work,[0],[0]
"AMR (Banarescu et al., 2013) is a generalpurpose meaning representation and has been used in a number of applications (Pan et al., 2015; Liu et al., 2015).",3 Related Work,[0],[0]
"There is also work on recovering
AMRs, including graph parsing (Flanigan et al., 2014), methods to build AMRs from dependency trees (Wang et al., 2015) and algorithms for aligning words to AMRs (Pourdamghani et al., 2014).",3 Related Work,[0],[0]
"Combinatory Categorial Grammar CCG is a categorial formalism that provides a transparent interface between syntax and semantics (Steedman, 1996, 2000).",4 Background,[0],[0]
Section 7 details our instantiation of CCG.,4 Background,[0],[0]
"In CCG trees, each node is a category.",4 Background,[0],[0]
Figure 2 shows a simple CCG tree.,4 Background,[0],[0]
"For example, S\NP[pl] : λx.λd.dance-01(d) ∧ ARG0(d, x) is a category for an intransitive verb phrase.",4 Background,[0],[0]
"The syntactic type S\NP[pl] indicates that an argument of type NP[pl] is expected and the returned syntactic type will be S. The backward slash \ indicates the argument is expected on the left, while a forward slash / indicates it is expected on the right.",4 Background,[0],[0]
The syntactic attribute pl specifies that the argument must be plural.,4 Background,[0],[0]
Attribute variables enforce agreement between syntactic attributes.,4 Background,[0],[0]
"For example, as in Figure 2, adjectives are assigned the syntax N[x]/N[x], where x is used to indicate that the attribute of the argument will determine the attribute of the returned category.",4 Background,[0],[0]
The simply-typed lambda calculus logical form in the category represents its semantic meaning.,4 Background,[0],[0]
"The typing system includes basic types (e.g., entity e, truth value t) and functional types (e.g., 〈e, t〉 is the type of a function from e to t).",4 Background,[0],[0]
"In the example category, λx.λd.dance-01(d) ∧ ARG0(d, x) is a 〈e, 〈e, t〉〉-typed function expecting an ARG0 argument, and the conjunction specifies the roles of the dance-01 frame.
",4 Background,[0],[0]
A CCG is defined by a lexicon and a set of combinators.,4 Background,[0],[0]
The lexicon pairs words and phrases with their categorial meaning.,4 Background,[0],[0]
"For example, dance ` λx.λd.dance-01(d) ∧ ARG0(d, x) pairs dance with the category above.",4 Background,[0],[0]
"We adopt a factored representation of the lexicon (Kwiatkowski et al., 2011), where entries are dynamically generated by
combining lexemes and templates.",4 Background,[0],[0]
"For example, the above lexical entry can be generated by pairing the lexeme 〈dance, {dance-01}〉with the template λv1.[S\NP : λx.λa.v1(a)",4 Background,[0],[0]
"∧ARG0(a, x)].",4 Background,[0],[0]
"Skolem Terms and IDs Generalized Skolem terms (henceforth, Skolem terms) for CCG were introduced by Steedman (2011) to capture complex dependencies with relatively local quantification.",4 Background,[0],[0]
We define here a simplified version of the theory to represent entities and allow distant references.,4 Background,[0],[0]
"Let A be a 〈〈e, t〉, e〉-typed predicate.",4 Background,[0],[0]
"Given a 〈e, t〉-typed logical expression C, the logical form An(C) is a Skolem term with the Skolem ID n.",4 Background,[0],[0]
"For example, A2(λy.boy(y)) is a Skolem term that could represent the noun phrase the boy, which introduces a new entity.",4 Background,[0],[0]
"Skolem IDs are globally scoped, i.e., they can be referred from anywhere in the logical form without scoping constraints.",4 Background,[0],[0]
"To refer to Skolem terms, we define the 〈id, e〉-typed predicate R.",4 Background,[0],[0]
"For example, the sentence the boy loves himself may be represented with A1(λx.love-01(x)",4 Background,[0],[0]
"∧ ARG0(x,A2(λy.boy(y)))",4 Background,[0],[0]
"∧ ARG1(x,R(2))), whereR(2) references A2(λy.boy(y)).",4 Background,[0],[0]
"Given a sentence x and lexicon Λ, the function GEN(x,Λ) defines the set of possible derivations.",5 Mapping Sentences to Logical Form,[0],[0]
"Each derivation d is a tuple 〈y,M〉, where y is a CCG parse tree andM is a mapping of constants from u, the underspecified logical form at the root of y, to their fully specified form.",5 Mapping Sentences to Logical Form,[0],[0]
An underspecified logical form represents multiple logical forms via a mapping function that maps its constants to sets of constants and Skolem IDs.,5.1 Underspecified Logical Forms,[0],[0]
"For example, consider the underspecified logical form u at the top of Figure 3b.",5.1 Underspecified Logical Forms,[0],[0]
"If, for example, REL can be mapped to manner or ARG2, then the sub-expression REL(h,A6(λo.official(o))) represents manner(h,A6(λo.official(o))) or ARG2(h,A6(λo.official(o))).",5.1 Underspecified Logical Forms,[0],[0]
"During learning, we assume access to fully specified logical forms, which we convert to underspecified form as needed.",5.1 Underspecified Logical Forms,[0],[0]
"In practice, all binary relations, except ARG0 and ARG1, and all Skolem ID references are underspecified.
",5.1 Underspecified Logical Forms,[0],[0]
"Formally, let C be the set of all constants and I(u) the set of all Skolem IDs in the logical form u. Let",5.1 Underspecified Logical Forms,[0],[0]
"Su : C → 2C∪I(u) be a specification func-
tion, such that its inverse is deterministic.",5.1 Underspecified Logical Forms,[0],[0]
We call a constant c a placeholder if |Su(c)| > 1.,5.1 Underspecified Logical Forms,[0],[0]
"Given an underspecified logical form u, applying Su to all constants u contains, generates a set of fully specified logical forms.
",5.1 Underspecified Logical Forms,[0],[0]
"We define Su to be (a) Su(ID) = I(u), the set of Skolem IDs in u, (b) Su(REL) = {part,ARG2, . . .",5.1 Underspecified Logical Forms,[0],[0]
"}, all 67 active AMR relations except ARG0 and ARG1, (c) Su(REL-of) =",5.1 Underspecified Logical Forms,[0],[0]
"{part-of,ARG0-of, . . .",5.1 Underspecified Logical Forms,[0],[0]
"},",5.1 Underspecified Logical Forms,[0],[0]
"all 33 passive relations, and otherwise (d) Su(c) =",5.1 Underspecified Logical Forms,[0],[0]
"c. For example, in u in Figure 3b, the set of assignments to the ID placeholder is I(u) =",5.1 Underspecified Logical Forms,[0],[0]
"{1, 2, 3, 4, 5, 6, 7}.",5.1 Underspecified Logical Forms,[0],[0]
"The first part of a derivation d = 〈y,M〉 is a CCG parse tree y with an underspecified logical form u at its root.",5.2 Derivations,[0],[0]
"For example, Figure 3a shows such a CCG parse tree, where the logical form contains the placeholders REL, REL-of and ID.
",5.2 Derivations,[0],[0]
"The second part of the derivation is a function M : CONSTS(u) → C ∪ I(u), where CONSTS(u) is the set of all occurrences of constants in u.",5.2 Derivations,[0],[0]
"For example, in Figure 3b, CONSTS(u) contains, among others, three different occurrences of ARG1 and one of ID, and M maps REL to ARG2, REL-of to ARG0-of and ID to the Skolem ID 2.",5.2 Derivations,[0],[0]
"The set of potential assignments for each occurrence of constant c is Su(c), andM, which returns a single element for each constant, is a disambiguation of Su.",5.2 Derivations,[0],[0]
"ApplyingM to all constants in u results in the final logical form z.
Decomposing the derivation provides two advantages.",5.2 Derivations,[0],[0]
"First, we are able to defer decisions from the CCG parse to the factor graph, thereby considering fewer hypotheses during parsing and simplifying the computation.",5.2 Derivations,[0],[0]
"Second, we can represent distant references while avoiding the complex parse trees that would have been required to represent these dependencies with scoped variables instead of Skolem IDs.2",5.2 Derivations,[0],[0]
"Given a sentence x, we use a weighted log-linear CCG (Lafferty et al., 2001; Clark and Curran, 2007) to rank the space of possible parses under the grammar Λ. At the root of each CCG derivation is the underspecified logical form u.
To represent a probability distribution overM, we build for each u a factor graphGu = 〈V, F,E〉,
2Similar to mention clustering methods for co-reference resolution (Ng, 2010), IDs can be viewed as creating clusters.
",5.3 Model,[0],[0]
"(a) CCG parse y: Maps the sentence x to an underspecified logical form u (Section 5.1) with placeholders for unresolved decisions: ID for reference identifiers and the predicates REL and REL-of for unresolved relations.
where V = CONSTS(u) is the set of variables, F is the set of factors and E is the set of edges.",5.3 Model,[0],[0]
"Each edge is of the form (v, f) where v ∈ V and f ∈ F .",5.3 Model,[0],[0]
"Figure 4 shows the factor graph used in generating the derivation in Figure 3, including all the variables and a subset of the factors.",5.3 Model,[0],[0]
"For each variable vc ∈ V such that c ∈ CONSTS(u) the set of possible assignments is determined by Su(c).
",5.3 Model,[0],[0]
"To generate the factors F and edges E we use the function Φ(V ′) that maps a set of variables V ′ ⊆ V to a factor f and a set of edges, each one of the form (v, f), where v ∈ V ′. Factors express various features (Section 7), such as selectional preferences and control structures.",5.3 Model,[0],[0]
"In the figure, Factor A captures the selectional preference for the assignment of the relation REL between have-org-role-91 and official.",5.3 Model,[0],[0]
"Factor B captures a similar preference, this time to resolve
REL-of .",5.3 Model,[0],[0]
Factor C2 captures a selectional preference triplet involve-01/ARG1/person that will be created if ID is resolved to the Skolem ID 2.,5.3 Model,[0],[0]
"Finally, C3 captures a similar preference for resolving ID to 3.",5.3 Model,[0],[0]
"Since the assignment of many of the variables is fixed, i.e., they are fully specified constants, in practice our factor graph representation simply conditions on them.
",5.3 Model,[0],[0]
Derivations are scored using a log-linear model that includes both CCG parse features and those defined by the factor graph.,5.3 Model,[0],[0]
Let D(z) be the subset of derivations with the final logical form z,5.3 Model,[0],[0]
and θ ∈ Rl be a l-dimensional parameter vector.,5.3 Model,[0],[0]
"We define the probability of the logical form z as
p(z|x; θ,Λ) = ∑
d∈D(z) p(d|x; θ,Λ) ,
and the probability of a derivation d is defined as
p(d|x; θ,Λ) = e θ·φ(x,d)∑
d′∈GEN(x,Λ) e θ·φ(x,d′) , (1)
where φ(x, d",5.3 Model,[0],[0]
) ∈,5.3 Model,[0],[0]
Rl is a feature vector (Section 7).,5.3 Model,[0],[0]
"To compute the set of derivations GEN(x,Λ) we define a two-stage process.",5.4 Inference,[0],[0]
We first run the CCG parser to generate underspecified logical forms.,5.4 Inference,[0],[0]
"Following previous work (Zettlemoyer and Collins, 2005), we use CKY parsing to enumerate the top-K underspecified logical forms.3 During the CKY chart construction, we ignore Skolem IDs when comparing categories.",5.4 Inference,[0],[0]
This allows us to properly combine partial derivations and to fully benefit from the dynamic programming.,5.4 Inference,[0],[0]
We dynamically generate lexical entries for numbers and dates using regular expression patterns and for named-entities using a recognizer.,5.4 Inference,[0],[0]
"For every underspecified logical form u, we construct a factor graph and use beam search to find the top-L configurations of the graph.4
During learning, we use the function GENMAX(x, z, θ,Λ) to get all derivations that map the sentence x to the logical form z, given parameters θ and lexicon Λ. To compute GENMAX, we follow Zettlemoyer and Collins (2005) and collect constant co-occurrence counts from z to prune from the CKY chart any category that cannot participate in a derivation leading to z.",5.4 Inference,[0],[0]
"Since only constant names are changed during the second stage, setting the factor graph to get z is trivial: if the underspecified logical form is identical to z except the placeholders, we replace the placeholders with the correct final assignment, otherwise the derivation cannot result in z.",5.4 Inference,[0],[0]
"Learning the two-stage model requires inducing the entries of the CCG lexicon Λ and estimating the parameters θ, which score both stages of the derivation.",6 Learning,[0],[0]
"We assume access to a training set of N examples D = {(xi, zi) : i = 1 . . .",6 Learning,[0],[0]
"N}, each containing a sentence xi and a logical form zi.",6 Learning,[0],[0]
This data does not include information about the lexical entries and CCG parsing operations required to construct the correct derivations.,6 Learning,[0],[0]
"We consider all these decisions as latent.
",6 Learning,[0],[0]
"The main learning algorithm (Algorithm 1) starts by initializing the lexicon (line 1) and then
3See Artzi et al. (2014) for a description of this process and how to approximate the partition function in Equation 1.
4Experiments with loopy belief propagation showed it to be slower and less effective for our task.
",6 Learning,[0],[0]
Algorithm 1,6 Learning,[0],[0]
The main learning algorithm.,6 Learning,[0],[0]
"Input: Training set D = {(xi, zi) : i = 1 . . .",6 Learning,[0],[0]
"N}, number of iterations T , mini-batch size M , seed lexicon Λ0 and learning rate µ. Definitions: SUB(D, i, j) is the set of the next j samples from D starting at i. GENMAX(x, z, θ,Λ) is the set of viterbi derivations from x with the final result z",6 Learning,[0],[0]
"given parameters θ and lexicon Λ. LEX(d) is the set of lexical entries used in the derivation d. COMPUTEGRAD(x, z, θ,Λ) computes the gradient for sentence x and logical form z, given the parameters θ and lexicon Λ, and it described in Section 6.2. ADAGRAD(∆) applies a per-feature learning rate to the gradient ∆",6 Learning,[0],[0]
"(Duchi et al., 2011).",6 Learning,[0],[0]
Output: Lexicon Λ and model parameters θ. 1: Λ← Λ0 2: for t = 1 to T do 3: » Generate entries and update the lexicon.,6 Learning,[0],[0]
4:,6 Learning,[0],[0]
"for i = 1 to N do 5: λnew ← λnew ∪ GENENTRIES(xi, zi, θ,Λ) 6: Λ← Λ ∪ λnew 7: » Compute and apply mini-batch gradient updates.",6 Learning,[0],[0]
"8: for i = 1 to d N
M e do
9: ∆← ~0 10: for (x, z) in SUB(D, i,M) do 11: » Compute and aggregate the gradient.",6 Learning,[0],[0]
12:,6 Learning,[0],[0]
"∆← ∆ + COMPUTEGRAD(x, z, θ,Λ) 13: θ ← θ + µADAGRAD(∆) 14",6 Learning,[0],[0]
: » Get all correct viterbi derivations.,6 Learning,[0],[0]
"15: V ← ⋃(x,z)∈D GENMAX(x, z, θ,Λ) 16: »",6 Learning,[0],[0]
Retain only entries from derivations in V .,6 Learning,[0],[0]
"17: Λ← ⋃d∈V LEX(d) 18: return Λ and θ
Algorithm 2 GENENTRIES:",6 Learning,[0],[0]
Procedure to generate lexical entries from one training sample.,6 Learning,[0],[0]
"See Section 6.1 for details.
",6 Learning,[0],[0]
"Input: Sample (x, z), model parameters θ and lexicon Λ. Definitions: GENLEX(x, z,Λ) and
RECSPLIT(z, z, θ,Λ) are defined in Section 6.1.",6 Learning,[0],[0]
"Output: Set of lexical entries λ.
1: » Augment lexicon with sample-specific entries.",6 Learning,[0],[0]
"2: Λ+ ← Λ ∪ GENLEX(x, z,Λ) 3: » Get max-scoring correct derivations.",6 Learning,[0],[0]
"4: D+ ← GENMAX(x, z,Λ+, θ) 5: if |D+| > 0",6 Learning,[0],[0]
then 6: » Return entries from max-scoring derivations.,6 Learning,[0],[0]
"7: return ⋃ d∈D+ LEX(d) 8: else 9: » Top-down splitting to generate new entries.
10: return RECSPLIT(x, z, θ,Λ+)
processes the data T times (line 2), each time alternating between batch expansion of the lexicon and a sequence of mini-batch parameter updates.",6 Learning,[0],[0]
An iteration starts with a batch pass to expand the lexicon.,6 Learning,[0],[0]
"The subroutine GENENTRIES, described in Section 6.1 and Algorithm 2, is called to generate a set of new entries for each sample (line 5).
",6 Learning,[0],[0]
"Next, we update the parameters θ with minibatch updates.",6 Learning,[0],[0]
"Given a mini-batch size of M , we use the procedure SUB(D, i,M) to get the i-th segment of the data D of size M .",6 Learning,[0],[0]
"We process this segment (line 10) to accumulate the
mini-batch gradient ∆ by calling the procedure COMPUTEGRAD(x, z, θ,Λ) (line 12), which computes the gradient for x and z given θ and Λ, as described in Section 6.2.",6 Learning,[0],[0]
"We use AdaGrad (Duchi et al., 2011) parameter updates (line 13).
",6 Learning,[0],[0]
"Each iteration concludes with removing all lexical entries not used in max-scoring correct derivations, to correct for overgeneration (lines 14-17).",6 Learning,[0],[0]
"Given a sentence x, a logical form z, parameters θ and a lexicon Λ, GENENTRIES(x, z, θ,Λ) (Algorithm 2) computes a set of lexical entries, such that there exists at least one derivation d using these entries from x to",6.1 Lexicon Expansion: GENENTRIES,[0],[0]
"z. We first use GENLEX(x, z,Λ) to generate a large set of potential lexical entries from u, the underspecified form of z, by generating lexemes (Section 4) and pairing them with all templates in Λ. We then use a two-pass process to select the entries to return.",6.1 Lexicon Expansion: GENENTRIES,[0],[0]
The set of generated lexemes is a union of: (a) the set Ggen that includes all pairings of subsets of constants from z with spans in x up to length kgen and (b) the set that is constructed by matching named-entity constants5 in z with their corresponding mentions in the text to create new lexemes with potentially any other constant (for lexemes with multiple constants).,6.1 Lexicon Expansion: GENENTRIES,[0],[0]
"Λ is augmented with the generated set of lexical entries to create Λ+ (line 2).
",6.1 Lexicon Expansion: GENENTRIES,[0],[0]
"First Pass Given the augmented lexicon Λ+, we compute the set D+ = GENMAX(x, z, θ,Λ+) (line 4).",6.1 Lexicon Expansion: GENENTRIES,[0],[0]
"Following Artzi and Zettlemoyer (2013b), we constrain the set of derivations to include only those that use at most one lexeme from Ggen.",6.1 Lexicon Expansion: GENENTRIES,[0],[0]
"If generating new lexemes is sufficient to derive z from x, D+ will contain these derivations and we return their lexical entries to be added to the lexicon Λ (lines 5-7).",6.1 Lexicon Expansion: GENENTRIES,[0],[0]
"Otherwise, we proceed to do a second pass, where we try to generate new templates to parse the sentence.
",6.1 Lexicon Expansion: GENENTRIES,[0],[0]
Second Pass: RECSPLIT In this pass we try to generate max-scoring derivations in a top-down process.,6.1 Lexicon Expansion: GENENTRIES,[0],[0]
"Starting from u, the underspecified form of z, we search for CCG parsing steps that will connect to existing partial derivations in the CKY chart to create a complete parse tree.",6.1 Lexicon Expansion: GENENTRIES,[0],[0]
"Since the space of possible operations is extremely large,
5Named-entity constants are created from name instances when converting from AMR to lambda calculus.",6.1 Lexicon Expansion: GENENTRIES,[0],[0]
"See the supplementary material for the exact procedure.
",6.1 Lexicon Expansion: GENENTRIES,[0],[0]
"we use CCGBank (Hockenmaier and Steedman, 2007) categories to prune, as described below.
",6.1 Lexicon Expansion: GENENTRIES,[0],[0]
"The second pass is executed by calling RECSPLIT(x, z, θ,Λ+), which returns a set of lexical entries to add to the model (line 10).",6.1 Lexicon Expansion: GENENTRIES,[0],[0]
We recursively apply the splitting operation introduced by Kwiatkowski et al. (2010).,6.1 Lexicon Expansion: GENENTRIES,[0],[0]
"Given a CCG category, splitting outputs all possible category pairs that could have originally generated it.",6.1 Lexicon Expansion: GENENTRIES,[0],[0]
"For example, given the category S\NP ` λy.λd.deny-01(d) ∧ ARG0(d, y) ∧ ARG1(d,A1(λi.involve-01(i) ∧ ARG1(i,R(ID)))), one of the possible splits will include the categories S\NP/NP ` λx.λy.λd.deny-01(d)",6.1 Lexicon Expansion: GENENTRIES,[0],[0]
"∧ ARG0(d, y) ∧ ARG1(d, x) and NP ` A1(λi.involve-01(i)",6.1 Lexicon Expansion: GENENTRIES,[0],[0]
"∧ ARG1(i,R(ID))) which would combine with forward application (>).",6.1 Lexicon Expansion: GENENTRIES,[0],[0]
"Kwiatkowski et al. (2010) present the full details.6 The process starts from u, the underspecified form of z, and recursively applies the splitting operation while ensuring that: (1) there is at most one entry from Ggen or one entry where both the template and lexemes are new in the derivation, (2) each parsing step must have at least one child that may be constructed from an existing partial derivation, and (3) for each new parsing step, the syntax of a newly generated child must match the syntax of a CCGBank category for the same span.",6.1 Lexicon Expansion: GENENTRIES,[0],[0]
"To search the space of derivations we populate a CKY chart and do a top-down beam search, where in each step we split categories for smaller spans.",6.1 Lexicon Expansion: GENENTRIES,[0],[0]
"Given a sentence x, its labeled logical form z, parameters θ and lexicon Λ, the procedure COMPUTEGRAD(x, z, θ,Λ) computes the gradient for the sample (x, z).",6.2 Gradient Computation: COMPUTEGRAD,[0],[0]
Let D∗(z) =,6.2 Gradient Computation: COMPUTEGRAD,[0],[0]
"GENMAX(x, z, θ,Λ), the set of max-scoring correct derivations.",6.2 Gradient Computation: COMPUTEGRAD,[0],[0]
"The hard gradient update is:
1 |D∗(z)| ∑
d∈D∗(z) φ(xi, d)− Ep(d,|xi;θ,Λ)[φ(xi, d)] , (2)
where φ(x, d) ∈",6.2 Gradient Computation: COMPUTEGRAD,[0],[0]
"Rl is a l-dimensional feature vector (Section 5.3) and the positive portion of the gradient, rather than using expected features, averages over all max-scoring correct derivations.
",6.2 Gradient Computation: COMPUTEGRAD,[0],[0]
"Early updates To generate an effective update when no correct derivation is observed, we follow Collins and Roark (2004) and do an early update if D∗(z) is empty or if GEN(x,Λ), the set
6Unlike Kwiatkowski et al. (2010), we also introduce syntactic attributes (e.g., pl, sg) when splitting.
of derivations for x, does not contain a derivation with the correct final logical form z.",6.2 Gradient Computation: COMPUTEGRAD,[0],[0]
"Given the partial derivations, our gradient computation is identical to Equation 2.",6.2 Gradient Computation: COMPUTEGRAD,[0],[0]
"However, in contrast to Collins and Roark (2004) our data does not include gold derivations.",6.2 Gradient Computation: COMPUTEGRAD,[0],[0]
"Therefore, we attempt to identify max-scoring partial derivations that may lead to the correct derivation.",6.2 Gradient Computation: COMPUTEGRAD,[0],[0]
"We extract sub-expressions from u,7 the underspecified form of z, and search the CKY chart for the top-scoring non-overlapping spans that contain categories with these logical forms.",6.2 Gradient Computation: COMPUTEGRAD,[0],[0]
"We use the partial derivations leading to these cells to compute the gradient.
",6.2 Gradient Computation: COMPUTEGRAD,[0],[0]
The benefit of early updates is two-fold.,6.2 Gradient Computation: COMPUTEGRAD,[0],[0]
"First, as expected, it leads to higher quality updates that are focused on the errors the model makes.",6.2 Gradient Computation: COMPUTEGRAD,[0],[0]
"Second, given the complexity of the data, it allows us to have updates for many examples that would be otherwise ignored.",6.2 Gradient Computation: COMPUTEGRAD,[0],[0]
"In our experiments, we observe this behavior with nearly 40% of the training set.",6.2 Gradient Computation: COMPUTEGRAD,[0],[0]
"Data, Tools and Metric For evaluation, we use AMR Bank release 1.0 (LDC2014T12).",7 Experimental Setup,[0],[0]
"We use the proxy report portion, which includes newswire articles from the English Gigaword corpus, and follow the official split for training, development and evaluation (6603/826/823 sentences).",7 Experimental Setup,[0],[0]
"We use EasyCCG (Lewis and Steedman, 2014) trained with the re-banked CCGBank (Hockenmaier and Steedman, 2007; Honnibal et al., 2010) to generate CCGBank categories, the Illinois Named Entity Tagger (Ratinov and Roth, 2009) for NER, Stanford CoreNLP (Manning et al., 2014) for tokenization and part-of-speech tagging and UW SPF (Artzi and Zettlemoyer, 2013a) to develop our system.",7 Experimental Setup,[0],[0]
"We use SMATCH (Cai and Knight, 2013) to evaluate logical forms converted back to AMRs.
CCG We use three syntactic attributes: singular sg, mass nouns nb and plural pl.",7 Experimental Setup,[0],[0]
"When factoring lexical entries, we avoid extracting binary relations and references, and leave them in the template.",7 Experimental Setup,[0],[0]
"We use backward and forward binary combinators for application, composition and crossing composition.",7 Experimental Setup,[0],[0]
We allow non-crossing composition up to the third order.,7 Experimental Setup,[0],[0]
We also add rules to handle punctuation and unary rules for typeshifting non-adjectives in adjectival positions and verb phrases in adverbial positions.,7 Experimental Setup,[0],[0]
"We allow
7We extract all sub-expressions of type e, 〈e, t〉, 〈e, t〉, 〈e, t〉〉 or 〈e, 〈e, t〉〉 from u.
shifting of bare plurals, mass nouns and named entities to noun phrases.",7 Experimental Setup,[0],[0]
"To avoid spurious ambiguity during parsing, we use normal-form constraints (Hockenmaier and Bisk, 2010).",7 Experimental Setup,[0],[0]
"We use five basic lambda calculus types: entity e, truth value t, identifier id, quoted text txt and integer i.
Features During CCG parsing, we use indicator features for unary type shifting, crossing composition, lexemes, templates and dynamically generated lexical entries.",7 Experimental Setup,[0],[0]
"We also use indicators for co-occurrence of part-of-speech tags and syntactic attributes, repetitions in logical conjunctions and attachments in the logical form.",7 Experimental Setup,[0],[0]
"In the factor graph, we use indicator features for control structures, parent-relation-child selectional preferences and for mapping a relation to its final form.",7 Experimental Setup,[0],[0]
"See the supplementary material for a detailed description.
",7 Experimental Setup,[0],[0]
Initialization and Parameters,7 Experimental Setup,[0],[0]
"We created the seed lexicon from the training data by sampling and annotating 50 sentences with lexical entries, adding entries for pronouns and adding lexemes for all alignments generated by JAMR (Flanigan et al., 2014).",7 Experimental Setup,[0],[0]
"We initialize features weights as follows: 10 for all lexeme feature for seed entries and entries generated by named-entity matching (Section 6.1), IBM Model 1 scores for all other lexemes (Kwiatkowski et al., 2011), -3 for unary type shifting and crossing composition features, 3 for features that pair singular and plural part-ofspeech tags with singular and plural attributes and 0 for all other features.",7 Experimental Setup,[0],[0]
We set the number of iterations T = 10 and select the best model based on development results.,7 Experimental Setup,[0],[0]
"We set the max number of tokens for lexical generation kgen = 2, learning rate µ = 0.1, CCG parsing beam K = 50, factor graph beam L = 100, mini batch size M = 40 and use a beam of 100 for GENMAX.
",7 Experimental Setup,[0],[0]
"Two-pass Inference During testing, we perform two passes of inference for every sentence.",7 Experimental Setup,[0],[0]
"First, we run our inference procedure (Section 5.4).",7 Experimental Setup,[0],[0]
"If no derivations are generated, we run inference again, allowing the parser to skip words at a fixed cost and use the entries for related words if a word is unknown.",7 Experimental Setup,[0],[0]
"We find related words in the lexicon using case, plurality and inflection string transformations.",7 Experimental Setup,[0],[0]
"Finally, if necessary, we heuristically transform the logical forms at the root of the CCG parse trees to valid AMR logical forms.",7 Experimental Setup,[0],[0]
We set the cost of logical form transformation and word skipping to 10 and the cost of using related entries to 5.,7 Experimental Setup,[0],[0]
Table 1 shows SMATCH test results.,8 Results,[0],[0]
"We compare our approach to the latest, fixed version of JAMR (Flanigan et al., 2014) available online,8 the only system to report test results on the official LDC release.",8 Results,[0],[0]
"Our approach outperforms JAMR by 3 SMATCH F1 points, with a significant gain in recall.",8 Results,[0],[0]
"Given consensus inter-annotator agreement of 83 SMATCH F1 (Flanigan et al., 2014), this improvement reduces the gap between automated methods and human performance by 15%.",8 Results,[0],[0]
"Although not strictly comparable, Table 1 also includes results on the pre-release AMR Bank corpus, including the published JAMR results, their fixed results and the results of Wang et al. (2015).
",8 Results,[0],[0]
"Table 2 shows SMATCH scores for the developments set, with ablations.",8 Results,[0],[0]
The supplementary material includes example output derivations and qualitative comparison to JAMR outputs.,8 Results,[0],[0]
"We first remove underspecifying constants, which leaves the factor graph to resolve only references.",8 Results,[0],[0]
"While the expressivity of the model remains the same, more decisions are considered during parsing, modestly impacting performance.
",8 Results,[0],[0]
We also study the different methods for lexical generation.,8 Results,[0],[0]
Skipping the second recursive splitting pass in GENENTRIES creates an interesting tradeoff.,8 Results,[0],[0]
"As we are unable to learn templates without splitting, we induce a significantly smaller lexicon (500K vs. 1.6M entries).",8 Results,[0],[0]
"Although we are unable to recover many syntactic constructions, our search problem is in general much simpler.",8 Results,[0],[0]
We therefore see a relatively mild drop in overall performance (1.1 F1).,8 Results,[0],[0]
"Removing Ggen during lexical generation (Section 6.1) creates a more significant drop in performance (3.4 F1), demonstrating how considering all possible lexemes allows the system to recover entries that are not covered by heuristic alignments.",8 Results,[0],[0]
"We are also able for the first time to report AMR parsing results without any surface-form similarity heuristics, by removing both JAMR alignments and named-entity matching lexical generation (Section 6.1).",8 Results,[0],[0]
"The significant drop in performance (20 points F1) demonstrates the need for better alignment algorithm.
",8 Results,[0],[0]
"Finally, Figure 5 plots development SMATCH F1 with and without early updates.",8 Results,[0],[0]
"As expected, early updates increase the learning rate significantly and have a large impact on overall performance.",8 Results,[0],[0]
"Without early updates we are unable to
8JAMR is available at http://tiny.cc/jamr.
",8 Results,[0],[0]
"learn from almost half of the data, and performance drops by nearly 15 points.",8 Results,[0],[0]
"We described an approach for broad-coverage CCG induction for semantic parsing, including a joint representation of compositional and noncompositional semantics, a new grammar induction technique and an early update procedure.",9 Conclusion,[0],[0]
"We used AMR as the target representation and present new state-of-the-art AMR parsing results.
",9 Conclusion,[0],[0]
"While we focused on recovering noncompositional dependencies, other noncompositional phenomena remain to be studied.",9 Conclusion,[0],[0]
"Although our technique is able to learn certain idioms as multi-word phrases, learning to recognize discontinuous idioms remains open.",9 Conclusion,[0],[0]
"Similarly, resolving cross-sentence references, which are not annotated in AMR Bank, is important future work.",9 Conclusion,[0],[0]
"Finally, we would like to reduce the dependency on surface-form heuristics, for example to better generalize to other languages.",9 Conclusion,[0],[0]
"This research was supported in part by a Microsoft Research PhD Fellowship, the NSF (IIS1252835), DARPA under the DEFT program through the AFRL (FA8750-13-2-0019), an Allen Distinguished Investigator Award and a gift from Google.",Acknowledgements,[0],[0]
"The authors thank Mark Yatskar, Tom Kwiatkowski, Chloé Kiddon, Eunsol Choi, Mike Lewis and the reviewers for their helpful advice.",Acknowledgements,[0],[0]
We propose a grammar induction technique for AMR semantic parsing.,abstractText,[0],[0]
"While previous grammar induction techniques were designed to re-learn a new parser for each target application, the recently annotated AMR Bank provides a unique opportunity to induce a single model for understanding broad-coverage newswire text and support a wide range of applications.",abstractText,[0],[0]
"We present a new model that combines CCG parsing to recover compositional aspects of meaning and a factor graph to model non-compositional phenomena, such as anaphoric dependencies.",abstractText,[0],[0]
"Our approach achieves 66.2 Smatch F1 score on the AMR bank, significantly outperforming the previous state of the art.",abstractText,[0],[0]
Broad-coverage CCG Semantic Parsing with AMR,title,[0],[0]
Graphical Models (GMs) express the factorization of the joint multivariate probability distribution over subsets of variables via graphical relations among them.,1. Introduction,[0],[0]
"They have played an important role in many fields, including computer vision (Freeman et al., 2000), speech recognition (Bilmes, 2004), social science (Scott, 2017) and deep learning (Hinton & Salakhutdinov, 2006).",1. Introduction,[0],[0]
"Given a GM, computing the partition function Z (the normalizing constant) is the essence of other statistical inference tasks such as marginalization and sampling.",1. Introduction,[0],[0]
"The partition function can be calculated efficiently in tree-structured GMs through an
1School of Electrical Engineering, KAIST, Daejeon, South Korea 2Theoretical Division, T-4 & Center for Nonlinear Studies, Los Alamos National Laboratory, Los Alamos, NM 87545, USA 3Skolkovo Institute of Science and Technology, 143026 Moscow, Russia 4University of Cambridge, UK 5The Alan Turing Institute, UK 6AITrics, Seoul, South Korea.",1. Introduction,[0],[0]
"Correspondence to: Jinwoo Shin <jinwoos@kaist.ac.kr>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"iterative (dynamic programming) algorithm eliminating, i.e. summing up, variables sequentially.",1. Introduction,[0],[0]
"In principle, the elimination strategy extends to arbitrary loopy graphs, but the computational complexity is exponential in the tree-width, e.g., the junction-tree method (Shafer & Shenoy, 1990).",1. Introduction,[0],[0]
"Formally, the computation task is #P-hard even to approximate (Jerrum & Sinclair, 1993).
",1. Introduction,[0],[0]
Variational approaches are often the most popular practical choice for approximate computation of the partition function.,1. Introduction,[0],[0]
They map the counting problem into an approximate optimization problem stated over a polynomial (in the graph size) number of variables.,1. Introduction,[0],[0]
"The optimization is typically solved iteratively via a message-passing algorithm, e.g., mean-field (Parisi, 1988), belief propagation (Pearl, 1982), tree-reweighted (Wainwright et al., 2005), or gauges and/or re-parametrizations (Ahn et al., 2017; 2018 (accepted to appear).",1. Introduction,[0],[0]
"Lack of accuracy control and difficulty in forcing convergence in an acceptable number of steps are, unfortunately, typical for hard GM instances.",1. Introduction,[0],[0]
"Markov chain Monte Carlo methods (e.g., see Alpaydin, 2014) are also popular to approximate the partition function, but typically suffer, even more than variational methods, from slow convergence/mixing.
",1. Introduction,[0],[0]
Approximate elimination is a sequential method to estimate the partition function.,1. Introduction,[0],[0]
Each step consists of summation over variables followed by (or combined with) approximation of the resulting complex factors.,1. Introduction,[0],[0]
"Notable flavors of this method include truncation of the Fourier coefficients (Xue et al., 2016), approximation by random mixtures of rank-1 tensors (Wrigley et al., 2017), and arguably the most popular, elimination over mini-buckets (Dechter & Rish, 2003; Liu & Ihler, 2011).",1. Introduction,[0],[0]
One advantage of the mini-bucket elimination approach is the ability to control the trade-off between computational complexity and approximation quality by adjusting an induced-width parameter.,1. Introduction,[0],[0]
"Note that analogous control in variational methods, such as varying region sizes in generalized belief propagation (Yedidia et al., 2001), typically results in much more complicated optimization formulations to solve.",1. Introduction,[0],[0]
"Another important advantage of mini-bucket elimination is that it is always guaranteed to terminate and, usually, it does so quickly.",1. Introduction,[0],[0]
"This is in contrast to iterative message-passing implementations of variational methods which can be notoriously slow on difficult instances.
",1. Introduction,[0],[0]
Contribution.,1. Introduction,[0],[0]
We improve the approximation quality of mini-bucket methods using tensor network and renormalization group approaches from statistical physics.,1. Introduction,[0],[0]
"In this regard, our method extends a series of recent papers exploring multi-linear tensor network transformations/contractions (Novikov et al., 2014; Wrigley et al., 2017; Ahn et al., 2017; 2018 (accepted to appear).",1. Introduction,[0],[0]
"More generally, tensor network renormalization algorithms (Levin & Nave, 2007; Evenbly & Vidal, 2015) have been proposed in the quantum and statistical physics literature for estimating partition functions.",1. Introduction,[0],[0]
The algorithms consist of coarse-graining the graph/network by contracting sub-graphs/networks using a low-rank projection as a subroutine.,1. Introduction,[0],[0]
"However, the existing renormalization methods in the physics literature have focused primarily on a restricted class of tensor-factorized models over regular grids/lattices,1 while factor-graph models (Clifford, 1990) over generic graphical structures are needed in most machine learning applications.
",1. Introduction,[0],[0]
"For generalizing them to factor-graph models, one would face at two challenges: (a) coarse-graining of the tensor network relies on the periodic structure of grid/lattices and (b) its low-rank projections are only defined on “edge variables” that allows only two adjacent factors.",1. Introduction,[0],[0]
"To overcome them, we first replace the coarse-graining step by sequential elimination of the mini-bucket algorithms, and then use the strategy of “variable splitting” in order to generate auxiliary edge variables.",1. Introduction,[0],[0]
"Namely, we combine ideas from tensor network renormalization and the mini-bucket schemes where one is benefical to the other.",1. Introduction,[0],[0]
"We propose two algorithms, which we call MBR and GBR:
• Mini-bucket renormalization (MBR) consists of sequentially splitting summation over the current (remaining) set of variables into subsets – multiple minibuckets which are then “renormalized”.",1. Introduction,[0],[0]
"We show that this process is, in fact, equivalent to applying low-rank projections on the mini-buckets to approximate the variable-elimination process, thus resulting in better approximation than the original mini-bucket methods.",1. Introduction,[0],[0]
"In particular, we show how to resolve approximate renormalization locally and efficiently through application of truncated singular value decomposition (SVD) over small matrices.
",1. Introduction,[0],[0]
"• While MBR is based on a sequence of local low-rank approximations applied to the mini-buckets, globalbucket renormalization (GBR) extends MBR by approximating mini-buckets globally.",1. Introduction,[0],[0]
"This is achieved by first applying MBR to mini-buckets, then calibrating the choice of low rank projections by minimizing the partition function approximation error with respect to renormalization of the “global-bucket”.",1. Introduction,[0],[0]
"Hence, GBR
1 The special models are related to what may be called Forneystyle grids/lattices (Forney, 2001) in the GM community.
",1. Introduction,[0],[0]
"takes additional time to run but may be expected to yield better accuracy.
",1. Introduction,[0],[0]
"Both algorithms are easily applicable to arbitrary GMs with interactions (factors) of high orders, hyper-graphs and large alphabets.",1. Introduction,[0],[0]
We perform extensive experiments on synthetic (Ising models on complete and grid graphs) and real-world models from the UAI dataset.,1. Introduction,[0],[0]
"In our experiments, both MBR and GBR show performance superior to other stateof-the-art elimination and variational algorithms.",1. Introduction,[0],[0]
Graphical model.,2. Preliminaries,[0],[0]
"Consider a hyper-graph G = (V, E) with vertices V = {1, · · · , n} and hyper-edges E ⊂ 2V .",2. Preliminaries,[0],[0]
"A graphical model (GM)M = (G,F) associates a collection of n discrete random variables x =",2. Preliminaries,[0],[0]
"[xi : i ∈ V] ∈ XV =∏ i∈V Xi with the following joint probability distribution:
Pr(x)",2. Preliminaries,[0],[0]
"= 1
Z ∏ α∈E fα(xα), Z = ∑ x ∏ α∈E fα(xα),
where Xi = {1, 2, · · · di}, xα =",2. Preliminaries,[0],[0]
"[xi : i ∈ α], F = {fα}α∈E is a set of non-negative functions called factors, and Z is the normalizing constant called the partition function that is computationally intractable.
",2. Preliminaries,[0],[0]
"Algorithm 1 Bucket Elimination (BE)
1: Input: GMM† = (G†,F†) and elimination order o.
2: F ← F† 3: for i in o",2. Preliminaries,[0],[0]
"do 4: Bi ← {fα|fα ∈ F , i ∈ α} 5: Generate new factor fBi\{i} by (1).",2. Preliminaries,[0],[0]
6: F ← F ∪ {fBi\{i}} \,2. Preliminaries,[0],[0]
Bi 7: end for 8:,2. Preliminaries,[0],[0]
"Output: Z = ∏ fα∈F fα
Mini-bucket elimination.",2. Preliminaries,[0],[0]
"Bucket (or variable) elimination (BE, Dechter, 1999; Koller & Friedman, 2009) is a procedure for computing the partition function exactly based on sequential elimination of variables.",2. Preliminaries,[0],[0]
"Without loss of generality, we assume through out the paper that the elimination order is fixed o =",2. Preliminaries,[0],[0]
"[1, · · · , n].",2. Preliminaries,[0],[0]
"BE groups factors by placing each factor fα in the “bucket” Bi ⊂ F of its earliest argument i ∈ α appearing in the elimination order o. Next, BE eliminates the variable by introducing a new factor marginalizing the product of factors in it, i.e.,
fBi\{i}(xBi\{i}) = ∑ xi ∏ fα∈Bi fα(xα).",2. Preliminaries,[0],[0]
"(1)
Here, xBi\{i} abbreviates xV(Bi)\{i}, where V(Bi) indicates the set of variables associated with the bucket Bi.",2. Preliminaries,[0],[0]
"The
subscript in fBi\{i} represents a similar abbreviation.",2. Preliminaries,[0],[0]
"Finally, the new function fBi\{i} is added to another bucket corresponding to its earliest argument in the elimination order.",2. Preliminaries,[0],[0]
"Formal description of BE is given in Algorithm 1.
",2. Preliminaries,[0],[0]
"One can easily check that BE applies a distributive property for computing Z exactly: groups of factors corresponding to buckets are summed out sequentially, and then the newly generated factor (without the eliminated variable) is added to another bucket.",2. Preliminaries,[0],[0]
"The computational cost of BE is exponential with respect to the number of uneliminated variables in the bucket, i.e., its complexity is O ( dmaxi |V(Bi)||V| ) .",2. Preliminaries,[0],[0]
"Here, maxi∈V |V(Bi)| is called the induced width of G given the elimination order o, and the minimum possible induced width across all possible o is called the tree-width.",2. Preliminaries,[0],[0]
"Furthermore, we remark that summation of GM over variables defined on the subset of vertices α, i.e., ∑ xα ∏ β∈E fβ , can also be computed via BE in O(dmaxi |V(Bi)|+|V\α||V|) time by summing out variables in elimination order oα on α.
Mini-bucket elimination (MBE, Dechter & Rish, 2003) achieves lower complexity by approximating each step of BE by splitting the computation of each bucket into several smaller “mini-buckets”.",2. Preliminaries,[0],[0]
"Formally, for each variable i in the elimination order o, the bucket Bi is partitioned into mi mini-buckets {B`i} mi `=1 such that Bi = ⋃mi `=1 B`i and B`1i ∩ B `2 i = ∅ for any `1, `2.",2. Preliminaries,[0],[0]
"Next, MBE generates new factors differently from BE as follows:
fB`i\{i}(xB`i\{i}) = maxxi ∏ fα∈B`i fα(xα), (2)
for all ` = 1, · · · ,mi − 1 and
fBmii \{i} (xBmii \{i} ) =",2. Preliminaries,[0],[0]
∑ xi ∏ fα∈B mi,2. Preliminaries,[0],[0]
i fα(xα).,2. Preliminaries,[0],[0]
"(3)
Other steps are equivalent to that of BE.",2. Preliminaries,[0],[0]
"Observe that MBE replaces the exact marginalization of the bucket in (1) by its upper bound, i.e., ∑ xi ∏",2. Preliminaries,[0],[0]
"fα∈Bi fα ≤ ∏m `=1 fB`i\{i}, and hence yields an upper bound of Z.",2. Preliminaries,[0],[0]
"We remark that one could instead obtain a lower bound for Z by replacing max by min in (2).
",2. Preliminaries,[0],[0]
"Note that one has to choose mini-buckets for MBE carefully as their sizes typically determine complexity and accuracy: smaller mini-buckets may be better for speed, but worse in accuracy.",2. Preliminaries,[0],[0]
"Accordingly, MBE has an additional induced width bound parameter ibound as the maximal size of a mini-bucket, i.e., |V(B`i )",2. Preliminaries,[0],[0]
| ≤ ibound + 1.,2. Preliminaries,[0],[0]
"The time complexity of MBE is O ( dibound+1|E| ·maxα∈E |α| ) , since the maximum number of mini-buckets is bounded by |E|maxα∈E |α|.",2. Preliminaries,[0],[0]
"We propose a new scheme, named mini-bucket renormalization (MBR).",3. Mini-Bucket Renormalization,[0],[0]
Our approach approximates BE by splitting each bucket into several smaller mini-buckets to be “renormalized”.,3. Mini-Bucket Renormalization,[0],[0]
"Inspired by tensor renormalization groups (TRG, Levin & Nave, 2007, see also references therein) in the physics literature, MBR utilizes low-rank approximations to the mini-buckets instead of simply applying max (or min) operations as in MBE.",3. Mini-Bucket Renormalization,[0],[0]
"Intuitively, MBR is similar to MBE but promises better accuracy.",3. Mini-Bucket Renormalization,[0],[0]
"For each variable i in the elimination order o, MBR partitions a bucket Bi into mi distinct mini-buckets {B`i} mi `=1 with maximal size bounded by ibound.",3.1. Algorithm Description,[0],[0]
"Then for ` = 1, · · · ,mi − 1, mini-bucket B`i is “renormalized” through replacing vertex i by its replicate i` and then introducing local factors r`i , ri` for error compensation, i.e.,
B̃`i ← {fα\{i}∪{i`}|fα ∈ B`i} ∪ {r`i , ri`}.
",3.1. Algorithm Description,[0],[0]
"Here, r`i , ri` are local “compensating/renormalizing factors”, chosen to approximate the factor fB`i",3.1. Algorithm Description,[0],[0]
"= ∏ fα∈B`i
fα well, where MBE approximates it using (2) and (3).",3.1. Algorithm Description,[0],[0]
See Figure 1 for illustration of the renormalization process.,3.1. Algorithm Description,[0],[0]
"Specifically, the local compensating/renormalizing factors are chosen by solving the following optimization:
min",3.1. Algorithm Description,[0],[0]
"r`i ,ri`
∑ xB",3.1. Algorithm Description,[0],[0]
"`
i
( fB`i (xB`i )",3.1. Algorithm Description,[0],[0]
"− f̃B`i (xB`i ) )2 , (4)
where f̃B`i is the factor induced on xB`i from the renormalized mini-bucket B̃`i :
f̃B`i (xB`i )",3.1. Algorithm Description,[0],[0]
"= ∑ x`i ∏ fα∈B̃`i fα(xα)
=",3.1. Algorithm Description,[0],[0]
"r`i (xi) ∑ x i` ri`(xi`) ∏ fα∈B`i fα(xi` ,xα\{i}∪{i`}).
",3.1. Algorithm Description,[0],[0]
We show that (4) can be solved efficiently in Section 3.2.,3.1. Algorithm Description,[0],[0]
"After all mini-buckets are processed, factors can be summed over the variables xi1 , · · · , ximi−1 and xi separately, i.e.,
introduce new factors as follows: fB`i\{i}(xB`i\{i}) =",3.1. Algorithm Description,[0],[0]
"∑ x i` ∏ fα∈B̃`i\{r`i} fα(xα), (5)
= ∑ x i` r`i (xi`) ∏ fα∈B`i fα(xi` ,xα\{i}∪{i`}),
for ` = 1, · · · ,mi − 1 and
fBmii \{i} (xBmii \{i} ) = ∑ xi mi−1∏",3.1. Algorithm Description,[0],[0]
"`=1 r`i (xi`) ∏
fα∈B mi i
fα(xα).
",3.1. Algorithm Description,[0],[0]
"(6) Resulting factors are then added to its corresponding minibucket and repeat until all buckets are processed, like BE and MBE.",3.1. Algorithm Description,[0],[0]
"Here, one can check that mi∏ `=1 fB`i\{i}(xB`i\{i}) =",3.1. Algorithm Description,[0],[0]
∑ xi fBmii (xBmii ),3.1. Algorithm Description,[0],[0]
"mi−1∏ `=1 f̃B`i (xB`i ),
≈ ∑ xi mi∏ `=1 fB`i (xB`i ),
from (4) and MBR indeed approximates BE.",3.1. Algorithm Description,[0],[0]
"The formal description of MBR is given in Algorithm 2.
",3.1. Algorithm Description,[0],[0]
"Algorithm 2 Mini-bucket renormalization (MBR)
1: Input: GMM† =",3.1. Algorithm Description,[0],[0]
"(G†,F†), elimination order o and induced width bound ibound.
",3.1. Algorithm Description,[0],[0]
2: F ← F† 3: for i in o,3.1. Algorithm Description,[0],[0]
"do 4: Bi ← {fα|fα ∈ F , i ∈ α} 5: Divide Bi into mi subgroups {B`i} mi `=1 such that |V(B`i )| ≤",3.1. Algorithm Description,[0],[0]
"ibound+ 1 for ` = 1, · · · ,mi. 6: for ` = 1, · · · ,mi − 1 do 7: Generate compensating factors",3.1. Algorithm Description,[0],[0]
"r`i , ri` by (4).",3.1. Algorithm Description,[0],[0]
8: Generate new factor fB`i\{i} by (5).,3.1. Algorithm Description,[0],[0]
"9: end for
10: Generate new factor fBmii \{i} by (6).",3.1. Algorithm Description,[0],[0]
"11: for ` = 1, · · · ,mi do 12: F ← F ∪ {fB`i\{i}} \ B ` i 13: end for 14: end for 15: Output: Z = ∏ fα∈F fα",3.1. Algorithm Description,[0],[0]
"The optimization (4) is related to the rank-1 approximation on fB`i , which can be solved efficiently via (truncated) singular value decomposition (SVD).",3.2. Complexity,[0],[0]
"Specifically, let M be a d× d|V(B`i )|−1",3.2. Complexity,[0],[0]
"matrix representing fB`i as follows:
M xi, ∑ j∈V(B`i ),j 6=i xj ∏ k∈V(B`i ),k>j d  = fB`i",3.2. Complexity,[0],[0]
(xB`i ).,3.2. Complexity,[0],[0]
"(7)
Then rank-1 truncated SVD for M solves the following optimization:
min",3.2. Complexity,[0],[0]
"r1,r2 ‖M−",3.2. Complexity,[0],[0]
"r1r>2 M‖F ,
where optimization is over d-dimensional vectors r1, r2 and ‖·‖F denotes the Frobenious norm.",3.2. Complexity,[0],[0]
"Namely, the solution r1 = r2 becomes the most significant (left) singular vector of M, associated with the largest singular value.2 Especially, since M is a non-negative matrix, its most significant singular vector is always non-negative due to the Perron-Frobenius theorem (Perron, 1907).",3.2. Complexity,[0],[0]
"By letting ri`(x) = r1(x) and r`i (x) = r2(x), one can check that this optimization is equivalent to (4), where in fact, ri`(x) =",3.2. Complexity,[0],[0]
"r ` i (x), i.e., they share the same values.",3.2. Complexity,[0],[0]
"Due to the above observations, the complexity of (4) is NSVD(M) that denotes the complexity of SVD for matrix M. Therefore, the overall complexity becomes
O (NSV D(M) · T ) =",3.2. Complexity,[0],[0]
"O ( NSVD(M) · |E| ·max α∈E |α| ) ,
where NSVD(M) = O(dibound+2) in general, but typically much faster in the existing SVD solver.",3.2. Complexity,[0],[0]
"In the previous section, MBR only considers the local neighborhood for renormalizing mini-buckets to approximate a single marginalization process of BE.",4. Global-Bucket Renormalization,[0],[0]
"Here we extend the approach and propose global-bucket renormalization (GBR), which incorporates a global perspective.",4. Global-Bucket Renormalization,[0],[0]
The new scheme re-updates the choice of compensating local factors obtained in MBR by considering factors that were ignored during the original process.,4. Global-Bucket Renormalization,[0],[0]
"In particular, GBR directly minimizes the error in the partition function from each renormalization, aiming for improved accuracy compared to MBR.",4. Global-Bucket Renormalization,[0],[0]
Renormalized GMs in MBR.,4.1. Intuition and Key-Optimization,[0],[0]
"For providing the underlying design principles of GBR, we first track an intermediate estimation of the partition function made during MBR by characterizing the corresponding sequence of renormalized GMs.",4.1. Intuition and Key-Optimization,[0],[0]
"Specifically, we aim for constructing a sequence of T + 1 GMs M(1), · · · ,M(T+1) with T = ∑n i=1(mi − 1) by breaking each i-th iteration of MBR into mi − 1 steps of GM renormalizations, M(1) is the original GM, and each transition fromM(t) toM(t+1) corresponds to renormalization of some mini-bucket B`i to B̃`i .",4.1. Intuition and Key-Optimization,[0],[0]
"Then, the intermediate estimation for the original partition function Z at the t-th step is partition function Z(t) ofM(t) where the last one Z(T+1) is the output of MBR.
2 r1 = r2 holds without forcing it.
",4.1. Intuition and Key-Optimization,[0],[0]
"To this end, we introduce “scope” for each factor fα appearing in MBR to indicate which parts of GM are renormalized at each step.",4.1. Intuition and Key-Optimization,[0],[0]
"In particular, the scope Sfα = (Gfα ,Ffα) consists of a graph",4.1. Intuition and Key-Optimization,[0],[0]
"Gfα = (Vfα , Efα) and set of factors Ffα that are associated to fα as follows:
fα(xα) = ∑
xVfα\α ∏ fβ∈Ffα fβ(xβ).
",4.1. Intuition and Key-Optimization,[0],[0]
"Initially, scopes associated with initial factors are defined by themselves, i.e.,
Sfα ← ((α, {α}), {fα}), (8)
for each factor fα of M(1), and others of M(t) =",4.1. Intuition and Key-Optimization,[0],[0]
"((V(t), E(t)),F (t)) with t ≥ 2 are to be defined iteratively under the MBR process, as we describe in what follows.
Consider the t-th iteration of MBR, where mini-bucket B`i is being renormalized into B̃`i .",4.1. Intuition and Key-Optimization,[0],[0]
"Then scope Sf for all f ∈ B`i goes through renormalization by replacing every i in the scope by i` as follows:
S̃f ← (Vf \ {i}∪{i`}, {ᾱ|α ∈ Ef}, {fᾱ|fα ∈ Ff}), (9)
where ᾱ =
{ α \ {i} ∪ {i`} if i ∈ α
α otherwise .",4.1. Intuition and Key-Optimization,[0],[0]
"Then, the re-
spective GM is renormalized accordingly for the change of scopes, in addition to compensating factors",4.1. Intuition and Key-Optimization,[0],[0]
"r`i , ri` :
V(t+1) ← V(t) ∪ {i`},
E(t+1) ← E(t) \ EB`i ∪ ẼB`i ∪ {{i}, {i `}}, (10)
F (t+1) ← F (t) \ FB`i ∪ F̃B`i ∪ {r ` i , ri`},
where EB`i = ∪f∈B`iEf , and other union of scope components ẼB`i ,VB`i , ṼB`i ,FB`i , F̃B`i are defined similarly.",4.1. Intuition and Key-Optimization,[0],[0]
"Finally, scope SfB`
i \{i}
for newly generated factors fB`i\{i} is
SfB` i \{i} ← ((ṼB`i , ẼB`i ∪ {{i `}}), F̃B`i ∪ {ri`}).",4.1. Intuition and Key-Optimization,[0],[0]
"(11)
Furthermore, if ` = mi − 1, we have
SfBmi i \{i} ← ((VBmii , EBmii ∪ {{i}}),FBmii ∪ {r ` i} mi−1 `=1 ).
",4.1. Intuition and Key-Optimization,[0],[0]
"(12)
",4.1. Intuition and Key-Optimization,[0],[0]
"This is repeated until the MBR process terminates, as formally described in Algorithm 3.",4.1. Intuition and Key-Optimization,[0],[0]
"By construction, the output of MBR is equal to the partition function of the last GM M(T+1), which is computable via BE with induced width smaller than ibound+ 1 given elimination order
õ =",4.1. Intuition and Key-Optimization,[0],[0]
"[11, · · · , 1m1−1, 1, · · · , n1, · · · , nmn−1, n].",4.1. Intuition and Key-Optimization,[0],[0]
"(13)
See Algorithm 3 for the formal description of this process, and Figure 2 for an example.
",4.1. Intuition and Key-Optimization,[0],[0]
Optimizing intermediate approximations.,4.1. Intuition and Key-Optimization,[0],[0]
"Finally, we provide an explicit optimization formulation for minimizing the change of intermediate partition functions in terms of induced factors.",4.1. Intuition and Key-Optimization,[0],[0]
"Specifically, for each t-th renormalization, i.e., fromM(t) toM(t+1), we consider change of the following factor fi induced from global-bucketF (t) to variable xi in a “skewed” manner as follows:
fi(x (1) i , x (2) i ) :",4.1. Intuition and Key-Optimization,[0],[0]
"= ∑ xV(t)\{i} ∏ fα∈FB`
i
fα(x",4.1. Intuition and Key-Optimization,[0],[0]
"(1) i ,xα\{i})
· ∏
fα∈F(t)\FB` i
fα(x",4.1. Intuition and Key-Optimization,[0],[0]
"(2) i ,xα\{i}),
where x(1)i , x (2) i are the newly introduced “split variables” that are associated with the same vertex i, but allowed to have different values for our purpose.",4.1. Intuition and Key-Optimization,[0],[0]
"Next, the bucket F (t) is renormalized into F (t+1), leading to the induced factor of f̃i defined as follows:
f̃i(x (1) i , x (2) i )",4.1. Intuition and Key-Optimization,[0],[0]
":= ∑ xV(t+1)\{i} ∏ fα∈F̃B`
i ∪{r`i ,ri`}
fα(x (1) i ,xα\{i})
· ∏
fα∈F(t+1)\F̃B` i \{r`i ,ri`}
fα(x (2) i ,xα\{i})
=r`i (x (1) i )",4.1. Intuition and Key-Optimization,[0],[0]
"∑ x i` ri`(xi`)fi(xi` , x (2) i ).
",4.1. Intuition and Key-Optimization,[0],[0]
"Then change in fi is directly related with change in partition function since Z(t−1) and Z(t) can be described as follows:
Z(t−1) = ∑ xi fi(xi, xi), Z (t) =",4.1. Intuition and Key-Optimization,[0],[0]
"∑ xi f̃i(xi, xi).
",4.1. Intuition and Key-Optimization,[0],[0]
"Consequently, GBR chooses to minimize the change in fi by re-updating r`i , ri` , i.e., it solves
min",4.1. Intuition and Key-Optimization,[0],[0]
"r`i ,ri` ∑ x (1) i ,x (2) i ( fi(x (1) i , x (2) i )",4.1. Intuition and Key-Optimization,[0],[0]
"− f̃i(x (1) i , x (2) i ) )2 .",4.1. Intuition and Key-Optimization,[0],[0]
"(14)
However, we remark that (14) is intractable since its objective is “global”, and requires summation over all variables except one, i.e., xV(t)\{i}, and this is the key difference from (4) which seeks to minimize the error described by the local mini-bucket.",4.1. Intuition and Key-Optimization,[0],[0]
"GBR avoids this issue by substituting fi by its tractable approximation gi, which is to be described in the following section.
",4.1. Intuition and Key-Optimization,[0],[0]
"Algorithm 3 GM renormalization
1: Input: GMM† = (G†,F†), elimination order o and induced width bound ibound.
",4.1. Intuition and Key-Optimization,[0],[0]
"2: M(1) ←M† 3: Run Algorithm 2 with inputM(1), o, ibound to obtain
mini-buckets B`i and compensating factors",4.1. Intuition and Key-Optimization,[0],[0]
"r`i , ri` for i = 1, · · · , n and ` = 1, · · · ,mi.
4: for f ∈ F (1) do 5:",4.1. Intuition and Key-Optimization,[0],[0]
"Assign scope Sf for f by (8). 6: end for 7: for i in o do 8: for ` = 1, · · · ,mi − 1 do 9: for f ∈ B`i do
10:",4.1. Intuition and Key-Optimization,[0],[0]
Renormalize scope Sf for f into S̃f by (9).,4.1. Intuition and Key-Optimization,[0],[0]
11: end for 12: Set t = ∑i−1,4.1. Intuition and Key-Optimization,[0],[0]
j=1(mi,4.1. Intuition and Key-Optimization,[0],[0]
− 1) +,4.1. Intuition and Key-Optimization,[0],[0]
`. 13: Renormalize GMM(t) intoM(t+1) by (10).,4.1. Intuition and Key-Optimization,[0],[0]
"14: Assign scope SfB`
i \{i} for factor fB`i\{i} by (11).",4.1. Intuition and Key-Optimization,[0],[0]
"15: end for 16: Assign scope SfBmi
i \{i} for factor fBmii \{i} by (12).",4.1. Intuition and Key-Optimization,[0],[0]
"17: end for
18: Output: Final GMM(T+1) with T = ∑n i=1(mi − 1).",4.1. Intuition and Key-Optimization,[0],[0]
"In this section, we provide a formal description of GBR.",4.2. Algorithm Description,[0],[0]
"First, consider the sequence of GMs M(1), · · · ,M(T+1) from interpreting MBR as GM renormalizations.",4.2. Algorithm Description,[0],[0]
"This corresponds to T choices of compensating factors made at each renormalization, i.e., r(1), · · · , r(T )",4.2. Algorithm Description,[0],[0]
where r(t)(x) =,4.2. Algorithm Description,[0],[0]
"r`i (x) = ri`(x) for the associated replicate vertex i
`.",4.2. Algorithm Description,[0],[0]
"GBR modifies this sequence iteratively by replacing intermediate choice of compensation r(t) by another choice s(t)(x) = s`i(x) = si`(x) in reversed order, approximately solving (14) until all compensating factors are updated.",4.2. Algorithm Description,[0],[0]
"Then, GBR outputs partition function Z(T+1) forM(T+1) as an approximation of the original partition function",4.2. Algorithm Description,[0],[0]
"Z.
Now we describe the process of choosing new compensating factors s`i , si` at t
′-th iteration of GBR by approximately solving (14).",4.2. Algorithm Description,[0],[0]
"To this end, the t′-th choice of compensating factors are expressed as follows:
r(1), · · · , r(t), s(t+1), · · · , s(T ), (15)
with t = T − t′ + 1 and s(t+1), · · · , s(T ) already chosen in the previous iteration of GBR.",4.2. Algorithm Description,[0],[0]
"Next, consider sequence of GMs M̂(1), · · · ,M̂(T+1) that were generated similarly with GM renormalization corresponding to MBR, but with compensating factors chosen by (15).",4.2. Algorithm Description,[0],[0]
"Observe that the first t renormalizations of GM correspond to those of MBR since the updates are done in reverse order, i.e., M̂(t′) =M(t′) for t′ < t + 1.",4.2. Algorithm Description,[0],[0]
"Next, fi in (4) is expressed as summation over x`
V̂(t+1)\{i,i`} in M̂(t+1), defined as follows:
fi(xi` , xi) = ∑
xV̂(t+1)\{i,i`} ∏ fα∈F̂(t+1)\{r`i ,ri`} fα(xα).
",4.2. Algorithm Description,[0],[0]
"Since fi resembles the partition function in a way that it is also a summation over GM with small change in a set of factors, i.e., excluding local factors r`i , ri` , we expect fi to be approximated well by a summation gi over xV̂(T+1)\{i,i`} in M̂(T+1):
gi(xi` , xi) := ∑
xV̂(T+1)\{i,i`} ∏",4.2. Algorithm Description,[0],[0]
"fα∈F̂(T+1)\{r`i ,ri`} fα(xα),
which can be computed in O(|E|dibound+2) complexity via appying BE in M̂(T+1) with elimination order",4.2. Algorithm Description,[0],[0]
"õ \ {i, i`} as in (13).",4.2. Algorithm Description,[0],[0]
"Then the following optimization is obtained as an approximation of (14):
min s`i ,si` ∑ x (1) i ,x (2) i ( gi(x (1) i , x (2) i )",4.2. Algorithm Description,[0],[0]
"− g̃i(x (1) i , x (2) i ) )2 , (16)
where g̃i corresponds to renormalized factor f̃i:
g̃i(xi` , xi) := s ` i(xi`) ∑ x i` si`(xi`)gi(xi` , xi).
",4.2. Algorithm Description,[0],[0]
"As a result, one can expect choosing compensating factors from (16) to improve over that of (4) as long as MBR provides reasonable approximation for fi.",4.2. Algorithm Description,[0],[0]
"The optimization is again solvable via rank-1 truncated SVD and the overall complexity of GBR is
O ( dibound+2NSVD(M
global) ·",4.2. Algorithm Description,[0],[0]
"|E|2 ·max α∈E |α|2
) ,
where NSVD(Mglobal) = O(d3) is the complexity for performing SVD on d× d matrix",4.2. Algorithm Description,[0],[0]
Mglobal representing function g as in (7).,4.2. Algorithm Description,[0],[0]
"While the formal description of GBR is conceptually a bit complicated, one can implement it efficiently.
",4.2. Algorithm Description,[0],[0]
"Specifically, during the GBR process, it suffices to keep only the description of renormalized GMM(T+1) with an ongoing set of compensating factors, e.g., (15), in order to update compensating factors iteratively by (16).",4.2. Algorithm Description,[0],[0]
"The formal description of the GBR scheme is provided in Algorithm 4.
",4.2. Algorithm Description,[0],[0]
"Algorithm 4 Global-Bucket Renormalization (GBR)
1: Input: GMM† = (G†,F†), elimination order o and induced width bound ibound.
2: Run Algorithm 3 with inputM†, o, ibound to obtain renormalized GMM and compensating factors r`i for i = 1, · · · , n and ` = 1, · · · ,mi. 3: Set the renormalized elimination order as follows:
õ = [11, · · · , 1m1−1, 1, · · · , n1, · · · , nmn−1, n].
4: for i` = nmn−1, · · · , n1, · · · , 1m1−1, · · · , 11 do 5: Generate s`i , s ` i by solving
min s`i ,si` ∑ x (1) i ,x (2) i ( gi(x (1) i , x (2) i )",4.2. Algorithm Description,[0],[0]
"− g̃i(x (1) i , x (2) i ) )2 ,
6: where gi, g̃i is defined as follows: gi(xi` , xi) = ∑
xV\{i,i`} ∏ fα∈F\{r`i ,ri`} fα(xα),
g̃i(xi` , xi) = s ` i(xi`) ∑ x`i si`(x ` i)gi(x ` i , xi),
with its computation done by BE with elimination order of õ \",4.2. Algorithm Description,[0],[0]
{,4.2. Algorithm Description,[0],[0]
"i, i`}.
7: Update GMM by F ← F \",4.2. Algorithm Description,[0],[0]
{,4.2. Algorithm Description,[0],[0]
"r`i , ri`} ∪ {s`i , si`}. 8: end for 9: Get Z = ∑ x ∏ fα∈F fα(xα) via BE with elimination
order õ. 10:",4.2. Algorithm Description,[0],[0]
Output: Z,4.2. Algorithm Description,[0],[0]
"In this section, we report experimental results on performance of our algorithms for approximating the partition function Z. Experiments were conducted for Ising models defined on grid-structured and complete graphs as well as two real-world datasets from the UAI 2014 Inference Competition (Gogate, 2014).",5. Experimental Results,[0],[0]
"We compare our mini-bucket renormalization (MBR) and global-bucket renormalization (GBR) scheme with other mini-bucket algorithms, i.e., minibucket elimination (MBE) by Dechter & Rish (2003) and weighted mini-bucket elimination (WMBE) by Liu & Ihler (2011).",5. Experimental Results,[0],[0]
"Further, we also run the popular variational inference algorithms: mean-field (MF), loopy belief propagation
(BP) and generalized belief propagation (GBP) by Yedidia et al. (2001).",5. Experimental Results,[0],[0]
"For all mini-bucket algorithms, we unified the choice of elimination order for each instance of GM by applying min-fill heuristics (Koller & Friedman, 2009).",5. Experimental Results,[0],[0]
"Further, WMBE used additional fixed point reparameterization updates for improving its approximation, as proposed by Liu & Ihler (2011) and GBP was implemented to use the same order of memory as the mini-bucket algorithms for given ibound.",5. Experimental Results,[0],[0]
See the supplementary material for more details on implementations of the algorithms.,5. Experimental Results,[0],[0]
"For performance measure, we use the log-partition function error, i.e., | log10 Z − log10 Zapprox| where Zapprox is the approximated partition function from a respective algorithm.
",5. Experimental Results,[0],[0]
Ising models.,5. Experimental Results,[0],[0]
"We first consider the most popular binary pairwise GMs, called Ising models (Onsager, 1944): p(x) = 1Z exp (∑ i∈V φixi + ∑ (i,j)∈E φijxixj ) , where xi ∈ {−1, 1}.",5. Experimental Results,[0],[0]
"In our experiments, we draw φij and φi uniformly from intervals of [−∆,∆] and [−0.1, 0.1] respectively, where ∆ is a parameter controlling the ‘interaction strength’ between variables.",5. Experimental Results,[0],[0]
"As ∆ grows, the inference task is typically harder.",5. Experimental Results,[0],[0]
"Experiments were conducted in two settings: complete graphs with 15 variables (105 pairwise factors), and 15 × 15 non-toroidal grid graphs (225 variables, 420 pairwise factors).",5. Experimental Results,[0],[0]
"Both settings have moderate tree-width, enabling exact computation of the partition function using BE with induced widths of 15 and 16, respectively.",5. Experimental Results,[0],[0]
"We vary the interaction strength ∆ and the induced width bound ibound (for mini-bucket algorithms and GBP), where ibound = 10 and ∆ = 1.0 are the default choices.",5. Experimental Results,[0],[0]
"For each choice of parameters, results are obtained by averaging over 100 random model instances.
",5. Experimental Results,[0],[0]
"As shown in Figure 3a-d, both MBR and GBR perform impressively compared to MF and BP.",5. Experimental Results,[0],[0]
"Somewhat surprisingly, GBR outperforms GBP and even MBR is not worse than GBP although GBP (using the same order of memory) is more expensive to run due to its iterative nature.",5. Experimental Results,[0],[0]
"Next, the relative benefit of our methods compared to the earlier approaches increases with ∆ (more difficult instances), and as the bound of induced width gets smaller.",5. Experimental Results,[0],[0]
"This suggests that our methods scale well with the size and difficulty of GM.
",5. Experimental Results,[0],[0]
"In Figure 3c, where ibound is varied for complete graphs, we observe that GBR does not improve over MBR when ibound is small, but does so after ibound grows large.",5. Experimental Results,[0],[0]
"This is consistent with our expectation that in order for GBR to improve over MBR, the initial quality of MBR should be acceptable.",5. Experimental Results,[0],[0]
"Our experimental setup on Ising grid GMs with varying interaction strength is identical to that of Xue et al. (2016), where they approximate variable elimination in the Fourier domain.",5. Experimental Results,[0],[0]
"Comparing results, one can observe that our methods significantly outperform their prior algorithm.
",5. Experimental Results,[0],[0]
"Figure 3e reports the trade-off between accuracy and elapsed
time with varying ibound.",5. Experimental Results,[0],[0]
"Here, we observe that both MBR and GBR are faster than WMBE and any of the variational inference algorithms.",5. Experimental Results,[0],[0]
"Further, we also note that increasing ibound does not necessarily lead to slower running time, while the accuracy is improved.",5. Experimental Results,[0],[0]
"This is because smaller ibound increases the number of mini-buckets and the corresponding updates.
",5. Experimental Results,[0],[0]
UAI datasets.,5. Experimental Results,[0],[0]
"We further show results of real-world models from the UAI 2014 Inference Competition, namely the Promedus (medical diagnosis) and Linkage (genetic linkage) datasets, consisting of 28 and 17 instances of GMs respectively.",5. Experimental Results,[0],[0]
More details of the datasets are provided in the supplementary material.,5. Experimental Results,[0],[0]
"Again, induced width bounds are set to ibound = 10.",5. Experimental Results,[0],[0]
The experimental results are summarized in Figure 3f and 3g. Results for MF were omitted since MF was not able to run on these instances by its construction.,5. Experimental Results,[0],[0]
"First, in Promedus dataset, i.e., Figure 3f, MBR and GBR clearly dominates over all other algorithms.",5. Experimental Results,[0],[0]
"Even when GBR fails to improve MBR, it still outperforms other algorithms.",5. Experimental Results,[0],[0]
"Next, in Linkage dataset, i.e., 3g, MBR and GBR are often outperformed by GBP where the latter is significantly (often 100×) more expensive to run than the formers.",5. Experimental Results,[0],[0]
"Typically, MBR and GBR are nearly as good as GBP.",5. Experimental Results,[0],[0]
"They outperform all mini-bucket variants and BP.
",5. Experimental Results,[0],[0]
Guide for implementation.,5. Experimental Results,[0],[0]
"Based on the experiments, we
provide useful recommendations for application of MBR and GBR.",5. Experimental Results,[0],[0]
"First, we emphasize that using the min-fill heuristics for choosing the appropriate elimination order can improve the performance of MBR and GBR (see the supplementary material).",5. Experimental Results,[0],[0]
"Whenever memory is available, running MBR with increased ibound typically leads to better tradeoff between complexity and performance than running GBR.",5. Experimental Results,[0],[0]
"When memory is limited, GBR is recommended for improving the approximation quality without additional memory.",5. Experimental Results,[0],[0]
"We developed a new family of mini-bucket algorithms, MBR and GBR, inspired by the tensor network renormalization framework in statistical physics.",6. Conclusion and Future Work,[0],[0]
The proposed schemes approximate the variable elimination process efficiently by repeating low-rank projections of mini-buckets.,6. Conclusion and Future Work,[0],[0]
"Extensions to higher-order low-rank projections (Xie et al., 2012; Evenbly, 2017) might improve performance.",6. Conclusion and Future Work,[0],[0]
GBR calibrates MBR via minimization of renormalization error for the partition function explicitly.,6. Conclusion and Future Work,[0],[0]
"A similar optimization was considered in the so-called second-order renormalization groups (Xie et al., 2009; 2012).",6. Conclusion and Future Work,[0],[0]
"Hence, there is scope to explore potential variants of GBR.",6. Conclusion and Future Work,[0],[0]
"Finally, another direction to generalize MBR is to consider larger sizes of buckets to renormalize, e.g., see (Evenbly & Vidal, 2015; Hauru et al., 2018).",6. Conclusion and Future Work,[0],[0]
"AW acknowledges support from the David MacKay Newton research fellowship at Darwin College, The Alan Turing Institute under EPSRC grant EP/N510129/1 & TU/B/000074, and the Leverhulme Trust via the CFI.",Acknowledgements,[0],[0]
"This work was partly supported by Institute for Information & communications Technology Promotion (IITP) grant funded by the Korea government (MSIP) (No.2017-0-01778, Development of Explainable Human-level Deep Machine Learning Inference Framework) and ICT R&D program of MSIP/IITP [2016-0-00563, Research on Adaptive Machine Learning Technology Development for Intelligent Autonomous Digital Companion].",Acknowledgements,[0],[0]
Probabilistic graphical models are a key tool in machine learning applications.,abstractText,[0],[0]
"Computing the partition function, i.e., normalizing constant, is a fundamental task of statistical inference but it is generally computationally intractable, leading to extensive study of approximation methods.",abstractText,[0],[0]
Iterative variational methods are a popular and successful family of approaches.,abstractText,[0],[0]
"However, even state of the art variational methods can return poor results or fail to converge on difficult instances.",abstractText,[0],[0]
"In this paper, we instead consider computing the partition function via sequential summation over variables.",abstractText,[0],[0]
We develop robust approximate algorithms by combining ideas from mini-bucket elimination with tensor network and renormalization group methods from statistical physics.,abstractText,[0],[0]
"The resulting “convergence-free” methods show good empirical performance on both synthetic and real-world benchmark models, even for difficult instances.",abstractText,[0],[0]
Bucket Renormalization for Approximate Inference,title,[0],[0]
"Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 22–32, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.",text,[0],[0]
"In recent years, the complementarity of distributional and formal semantics has become increasingly evident.",1 Introduction,[0],[0]
"While distributional semantics (Turney and Pantel, 2010; Clark, 2012; Erk, 2012) has proved very successful in modelling lexical effects such as graded similarity and polysemy, it clearly has difficulties accounting for logical phenomena which are well covered by model-theoretic semantics (Grefenstette, 2013).
",1 Introduction,[0],[0]
"A number of proposals have emerged from these considerations, suggesting that an overarching semantics integrating both distributional and formal aspects would be desirable (Coecke et al., 2011; Bernardi et al., 2013; Grefenstette, 2013; Baroni et al., 2014a; Garrette et al., 2013; Beltagy et al., 2013; Lewis and Steedman, 2013).",1 Introduction,[0],[0]
We will use the term ‘Formal Distributional Semantics’ (FDS) to refer to such proposals.,1 Introduction,[0],[0]
"This paper follows this line of work, focusing on one central question: the formalisation of the systematic dependencies between lexical and set-theoretic levels.
",1 Introduction,[0],[0]
"Let us consider the following examples.
",1 Introduction,[0],[0]
1.,1 Introduction,[0],[0]
"Kim writes books.
",1 Introduction,[0],[0]
2.,1 Introduction,[0],[0]
"Kim likes books.
",1 Introduction,[0],[0]
"The preferred reading of 1 has a logical form where the object is treated as an existential, while the object in 2 has a generic reading:
• ∃x∗[book′(x∗) ∧ write′(Kim, x∗)]",1 Introduction,[0],[0]
"• GEN x[book′(x)→ like′(Kim, x)]
with x∗ indicating a plurality and GEN the generic quantifier.
",1 Introduction,[0],[0]
"It is generally accepted that the appropriate choice of quantifier for an ambiguous bare plural object depends, amongst other things, on the lexical semantics of the verb (e.g. Glasbey (2006)).",1 Introduction,[0],[0]
"This type of interaction implies the existence of systematic influences of the lexicon over logic, which could in principle be formalised.
",1 Introduction,[0],[0]
"A model of the lexicon/logic interface would be desirable to explain how speakers resolve standard cases of ambiguity like the bare plural in 1 and 2, but more generally, it could be the basis for answering a more fundamental question: how do speakers construct a model of a sentence for which they have no prior perceptual data?
",1 Introduction,[0],[0]
People can make complex inferences about statements without having access to their real-world reference.,1 Introduction,[0],[0]
"As an example, consider the sentence The kouprey is a mammal.",1 Introduction,[0],[0]
"English speakers have no problem ascertaining that if x is a kouprey, x is a mammal (which set-theoretic semantics would express as ∀x[kouprey′(x) → mammal′(x)]), regardless of whether they have ever encountered a kouprey.",1 Introduction,[0],[0]
"The inference is supported by the lexical semantics of mammal, which applies a property (being a mammal) to all instances of a class.",1 Introduction,[0],[0]
"Much more complex inferences are routinely performed by speakers, down to estimating the cardinality of the entities involved in a particular situation.",1 Introduction,[0],[0]
"Compare e.g. The cats are on the sofa (2 / a few cats?), I picked pears today (a few / a few dozen?)",1 Introduction,[0],[0]
"and The protesters were blocking the entire avenue (hundreds/thousands of protesters?).
",1 Introduction,[0],[0]
"22
Understanding how this process works would not only give us an insight into a complex cognitive process, but also make a crucial contribution to NLP tasks relying on inference (e.g. the Recognising Textual Entailment challenge, RTE: Dagan et al. (2009)).",1 Introduction,[0],[0]
"Indeed, while systems have successfully been developed to model entailment between quantifiers, ranging from natural logic approaches (MacCartney and Manning, 2008) to distributional semantics solutions (Baroni et al., 2012), they rely on an explicit representation of quantification.",1 Introduction,[0],[0]
"That is, they can model the entailment All koupreys are mammals |=",1 Introduction,[0],[0]
"This kouprey is a mammal, but not Koupreys are mammals |=",1 Introduction,[0],[0]
"This kouprey is a mammal.
",1 Introduction,[0],[0]
"In this work, we assume the existence of a mapping between language (distributional models) and world (set-theoretic models), or to be more precise, between language and a shared set of beliefs about the world, as negotiated by a group of speakers.",1 Introduction,[0],[0]
"To operationalise this mapping, we propose that set-theoretic models, like distributions, can be expressed in terms of vectors – giving us a common representation across formalisms.",1 Introduction,[0],[0]
"Using a publicly available dataset of feature norms annotated with quantifiers1 (Herbelot and Vecchi, 2015), we show that human-like intuitions about the quantification of simple subject/predicate pairs can be induced from standard distributional data.
",1 Introduction,[0],[0]
This paper is structured as follows.,1 Introduction,[0],[0]
"§2 reviews related work, focusing in turn on approaches to formal distributional semantics, computational work on quantification, and mapping between semantic spaces.",1 Introduction,[0],[0]
"In §3, we describe our dataset.",1 Introduction,[0],[0]
"§4 and §5 describe our experiments, reporting correlation against human annotations.",1 Introduction,[0],[0]
We discuss our results in §6 and end with an attempt at generating natural language quantifiers from our mapped vectors (§7).,1 Introduction,[0],[0]
The relation between distributional and formal semantics has been the object of a number of studies in recent years.,2.1 Formal Distributional Semantics,[0],[0]
"Proposals for a FDS, i.e. a combination of both formalisms, roughly fall into two groups: a) the fully distributional approaches, which redefine the concepts of formal semantics in distributional terms (Coecke et al., 2011; Bernardi et al., 2013; Grefenstette, 2013; Hermann et al., 2013; Baroni et al., 2014a; Clarke, 2012); b) the hybrid approaches, which try to keep the set-theoretic apparatus for function words and integrate distributions as content words representations (Erk, 2013; Garrette et al., 2013; Beltagy et al., 2013; Lewis and Steedman, 2013).",2.1 Formal Distributional Semantics,[0],[0]
"This paper follows the hybrid frameworks in that we fully preserve the principles of set theory and do not attempt to give a distributional interpretation to phenomena traditionally catered for by
1Data available at http://www.cl.cam.ac.uk/ ˜ah433/mcrae-quantified-majority.txt
formal semantics such as quantification or negation.",2.1 Formal Distributional Semantics,[0],[0]
Our account is also similar to that proposed by Erk (2015).,2.1 Formal Distributional Semantics,[0],[0]
"Erk suggests that distributional data influences semantic ‘knowledge’2: specifically, while a speaker may not know the extension of the word alligator, they maintain an information state which models properties of alligators (for instance, that they are animals).",2.1 Formal Distributional Semantics,[0],[0]
"This information state is described in terms of probabilistic logic, which accounts for an agent’s uncertainty about what the world is like.",2.1 Formal Distributional Semantics,[0],[0]
The probability of a sentence is the summed probability of the possible worlds that make it true.,2.1 Formal Distributional Semantics,[0],[0]
"Similarly, we assume a systematic relation between distributional information and world knowledge, expressed set-theoretically.",2.1 Formal Distributional Semantics,[0],[0]
The knowledge representation we derive is not a model proper: it cannot be said to be a description of a world – either the real one or a speaker’s set of beliefs (c.f.,2.1 Formal Distributional Semantics,[0],[0]
§4 for more details).,2.1 Formal Distributional Semantics,[0],[0]
"But it is a good approximation of the shared intuitions people have about the world, in the way that distributional representations are an averaged representation of how a group of speakers use their language.",2.1 Formal Distributional Semantics,[0],[0]
Computational semantics has traditionally focused on very specific aspects of quantification.,2.2 Generalised quantifiers,[0],[0]
"There is a large literature on the computational formalisation of quantifiers as automata, starting with Van Benthem (1986).",2.2 Generalised quantifiers,[0],[0]
"In parallel to this work, much research has been done on drawing inferences from explicitly quantified statements – i.e. statements quantified with determiners such as some/most/all, which give information about the set overlap of a subject-predicate pair (Cooper et al., 1996; Alshawi and Crouch, 1992; MacCartney and Manning, 2008).",2.2 Generalised quantifiers,[0],[0]
"Recent work in this area has even shown that entailment between explicit quantifiers can be modelled distributionally (Baroni et al., 2012).",2.2 Generalised quantifiers,[0],[0]
"A complementary object of focus, actively pursued in the 1990s, has been inference between generic statements (Bacchus, 1989; Vogel, 1995).
",2.2 Generalised quantifiers,[0],[0]
"Beside those efforts, computational approaches have been developed to convert arbitrary text into logical forms.",2.2 Generalised quantifiers,[0],[0]
"The techniques range from completely supervised (Baldwin et al., 2004; Bos, 2008) to lightly supervised (Zettlemoyer and Collins, 2005).",2.2 Generalised quantifiers,[0],[0]
Such work has shown that it was possible to automatically give complex formal semantics analyses to large amounts of data.,2.2 Generalised quantifiers,[0],[0]
"But the formalisation of quantifiers in those systems either remains very much underspecified (e.g. bare plurals are not resolved into either existentials or generics) or relies on some grounded information, for example in the form of a database.
",2.2 Generalised quantifiers,[0],[0]
"To the best of our knowledge, no existing system is able to universally predict the generalised quantification of noun phrases, including those introduced by the (in)definite singulars a/the and definite plurals the.",2.2 Generalised quantifiers,[0],[0]
"The closest attempt is Herbelot (2013), who suggests that
2We use the term knowledge loosely, to refer to a speaker’s beliefs about the world or a state of affairs.
",2.2 Generalised quantifiers,[0],[0]
‘model-theoretic vectors’ can be built out of distributional vectors supplemented with manually annotated training data.,2.2 Generalised quantifiers,[0],[0]
"The proposed implementation, however, fails to validate the theory.
",2.2 Generalised quantifiers,[0],[0]
Our work follows the intuition that distributions can be translated into set-theoretic equivalents.,2.2 Generalised quantifiers,[0],[0]
But it implements the mapping as a systematic linear transformation.,2.2 Generalised quantifiers,[0],[0]
"Our approach is similar to Gupta et al. (2015), who predict numerical attributes for unseen concepts (countries and cities) from distributional vectors, getting comparably accurate estimates for features such as the GDP or CO2 emissions of a country.",2.2 Generalised quantifiers,[0],[0]
We complement such research by providing a more formal interpretation of the mapping between language and world knowledge.,2.2 Generalised quantifiers,[0],[0]
"In particular, we offer a) a vectorial representation of set-theoretic models; b) a mechanism for predicting the application of generalised quantifiers to the sets in a model.",2.2 Generalised quantifiers,[0],[0]
The mapping between different semantic modalities or semantic spaces has been explored in various aspects.,2.3 Mapping between Semantic Spaces,[0],[0]
"In cognitive science, research by Riordan and Jones (2011) and Andrews et al. (2009) show that models that map between and integrate perceptual and linguistic information perform better at fitting human semantic intuition.",2.3 Mapping between Semantic Spaces,[0],[0]
"In NLP, Mikolov et al. (2013b) show that a linear mapping between vector spaces of different languages can be learned to infer missing dictionary entries by relying on a small amount of bilingual information.",2.3 Mapping between Semantic Spaces,[0],[0]
"Frome et al. (2013) learn a linear regression to transform vector-based image representations onto vectors representing the same concepts in a linguistic semantic space, and Lazaridou et al. (2014) explore mapping techniques to learn a cross-modal mapping between text and images with promising performance.",2.3 Mapping between Semantic Spaces,[0],[0]
"We follow the basic intuition introduced by these previous studies: a simple linear function can map between semantic spaces, in this case between a linguistic (distributional) semantic space and a model-theoretic space.",2.3 Mapping between Semantic Spaces,[0],[0]
"The McRae norms (McRae et al., 2005) are a set of feature norms elicited from 725 human participants for
541 concepts covering living and non-living entities (e.g. alligator, chair, accordion).",3.1 The quantified McRae norms,[0],[0]
"The annotators were given concepts and asked to provide features for them, covering physical, functional and other properties.",3.1 The quantified McRae norms,[0],[0]
"The result is a set of 7257 concept-feature pairs such as airplane used-for-passengers or bear is-brown.
",3.1 The quantified McRae norms,[0],[0]
"In our work, we use the annotation layer produced by Herbelot and Vecchi (2015) for the McRae norms (henceforth QMR): for each concept-feature pair (C, f), the annotation provides a natural language quantifier expressing the ratio of instances of C having the feature f , as elicited by three coders.",3.1 The quantified McRae norms,[0],[0]
"The quantifiers in use are NO, FEW, SOME, MOST, ALL.",3.1 The quantified McRae norms,[0],[0]
Table 1 provides example annotations for concept-feature pairs (reproduced from the original paper).,3.1 The quantified McRae norms,[0],[0]
"An additional label, KIND, was introduced for usages of the concept as a kind, where quantification does not apply (e.g. beaver symbol-of-Canada).",3.1 The quantified McRae norms,[0],[0]
"A subset of the annotation layer is available for training computational models, corresponding to all instances with a majority label (i.e. those where two or three coders agreed on a label).",3.1 The quantified McRae norms,[0],[0]
"The reported average weighted Cohen kappa on this data is κ = 0.59.
",3.1 The quantified McRae norms,[0],[0]
"In the following, we use a derived gold standard including all 5 quantified classes in QMR (removing the KIND items), with the annotation set to majority opinion (6156 instances).",3.1 The quantified McRae norms,[0],[0]
The natural language quantifiers are converted to a numerical format (see §4 for details).,3.1 The quantified McRae norms,[0],[0]
"Using the numerical data, we can calculate the mean Spearman rank correlation between the three annotators, which comes to 0.63.",3.1 The quantified McRae norms,[0],[0]
QMR gives us an average of 11 features per concept.,3.2 Additional animal data,[0],[0]
This results in fairly sparse vectors in the modeltheoretic semantic space (see §4).,3.2 Additional animal data,[0],[0]
"In order to remedy data sparsity, we consider the use of additional data in the form of the animal dataset from Herbelot (2013) (henceforth AD).",3.2 Additional animal data,[0],[0]
AD3 is a set of 72 animal concepts with quantification annotations along 54 features.,3.2 Additional animal data,[0],[0]
"The main differences between QMR and AD are as follows:
• Nature of features: the features in AD are not human elicited norms, but linguistic predicates obtained from a corpus analysis.
",3.2 Additional animal data,[0],[0]
• Comprehensiveness of annotation: the 72 concepts were annotated along all 54 features.,3.2 Additional animal data,[0],[0]
"This ensures the availability of a large number of negatively quantified pairs (e.g. cat is-fish).
",3.2 Additional animal data,[0],[0]
"We manually align the AD concepts and features to the QMR format, changing e.g. bat to bat (animal).",3.2 Additional animal data,[0],[0]
"The QMR and AD sets have an overlap of 39 concepts and 33 features.
",3.2 Additional animal data,[0],[0]
3Data available at http://www.cl.cam.ac.uk/ ˜ah433/material/herbelot_iwcs13_data.,3.2 Additional animal data,[0],[0]
txt.,3.2 Additional animal data,[0],[0]
"We construct two distinct semantic spaces (distributional and model-theoretic), as described below.",4 Semantic spaces,[0],[0]
We consider two distributional semantic space architectures which have each shown to have considerable success in a number of semantic tasks.,4.1 The distributional semantic space,[0],[0]
"First, we build a co-occurrence based space (DScooc), in which a word is represented by co-occurrence counts with content words (nouns, verbs, adjectives and adverbs).",4.1 The distributional semantic space,[0],[0]
"As a source corpus, we use a concatenation of the ukWaC, a 2009 dump of the English Wikipedia and the BNC4, which consists of about 2.8 billion tokens.",4.1 The distributional semantic space,[0],[0]
"We select the top 10K content words for the contexts, using a bagof-words approach and counting co-occurrences within a sentence.",4.1 The distributional semantic space,[0],[0]
"We then apply positive Pointwise Mutual Information to the raw counts, and reduce the dimensions to 300 through Singular Value Decomposition.5
Next we consider the context-predicting vectors (DSMikolov) available as part of the word2vec6 project (Mikolov et al., 2013a).",4.1 The distributional semantic space,[0],[0]
We use the publicly available vectors which were trained on a Google News dataset of circa 100 billion tokens.,4.1 The distributional semantic space,[0],[0]
"Baroni et al. (2014b) showed that vectors constructed under this architecture outperform the classic count-based approaches across many semantic tasks, and we therefore explore this option as a valid distributional representation of a word’s semantics.",4.1 The distributional semantic space,[0],[0]
Our ‘model-theoretic space’ differs in a couple of important respects from traditional formal semantics models.,4.2 The model-theoretic space,[0],[0]
"So it may be helpful to first come back to the standard definition of a model, which relies on two components: an ontology and a denotation function (Cann, 1993).",4.2 The model-theoretic space,[0],[0]
"The ontology describes a world (which can be a simple situation or ‘state of affairs’), with everything that is contained in that world.",4.2 The model-theoretic space,[0],[0]
"Ontologies can be represented in various ways, but in this paper, we assume they are formalised in terms of sets of entities.",4.2 The model-theoretic space,[0],[0]
"The denotation function associates words with their extensions in the model, i.e. the sets they refer to.",4.2 The model-theoretic space,[0],[0]
"Thanks to the availability of the ontology, it is possible to define a truth function for sentences, which computes whether a particular statement corresponds to the model or not.
",4.2 The model-theoretic space,[0],[0]
"In our account, we do not have an a priori model of the world: we wish to infer it from our observation of language data.",4.2 The model-theoretic space,[0],[0]
"We believe this to be an advantage over traditional formal semantics, which requires full ontological data to be available in order to account for reference and truth conditions, but never spells out how this
4http://wacky.sslmit.unibo.it, http: //www.natcorp.ox.ac.uk
5All semantic spaces, both distributional and modeltheoretic, were built using the DISSECT toolkit (Dinu et al., 2013).
",4.2 The model-theoretic space,[0],[0]
"6https://code.google.com/p/word2vec
data comes into being.",4.2 The model-theoretic space,[0],[0]
This however implies that our produced ontology will necessarily be partial: we can only model what can be inferred from language use.,4.2 The model-theoretic space,[0],[0]
"This has consequences for the denotation function.
",4.2 The model-theoretic space,[0],[0]
Let’s imagine a world with three cats and two horses.,4.2 The model-theoretic space,[0],[0]
"In model theory, the word horse has an extension in that world which is the set of horses, with a cardinality of two.",4.2 The model-theoretic space,[0],[0]
This can be trivially derived because the world is fully described in the ontology.,4.2 The model-theoretic space,[0],[0]
"In our approach, however, it is unlikely we might be able to learn the cardinality of any set in any world.",4.2 The model-theoretic space,[0],[0]
"And in fact, it is clear that ‘in real life’, speakers do miss this information for many sets (how many horses are there in the world?)",4.2 The model-theoretic space,[0],[0]
"Note that we do not in principle reject the possibility to learn cardinalities from distributional data (for an example of this, see Gupta et al. (2015)).",4.2 The model-theoretic space,[0],[0]
"We simply remark that this will not always possible, or even desirable from a cognitive point of view.",4.2 The model-theoretic space,[0],[0]
"By extension, this means that a model built from distributional data does not support denotation in the standard way, and thus precludes the definition of a truth function: we cannot verify the truth of the sentence There are 25,957 white horses in the world.",4.2 The model-theoretic space,[0],[0]
"Our ‘model-theoretic’ space may then be described as an underspecified set-theoretic representation of some shared beliefs about the world.
",4.2 The model-theoretic space,[0],[0]
Our ‘ontology’ can be defined as follows.,4.2 The model-theoretic space,[0],[0]
To each word wk in vocabulary V = w1...m corresponds a set w′k with underspecified cardinality.,4.2 The model-theoretic space,[0],[0]
A number of predicates p′1...n are similarly defined as sets with an unknown number of elements.,4.2 The model-theoretic space,[0],[0]
Our claim is that this very underspecified model can be further specified by learning a function F from distributions to generalised quantifiers.,4.2 The model-theoretic space,[0],[0]
"Specifically, F ( ~wk) = {Q1(w′k, p′1), Q2(w′k, p′2)...Qn(w′k, p′n)}, where ~wk is the distribution of wk and Q1...",4.2 The model-theoretic space,[0],[0]
"Qn ∈ {no, few, some,most, all} .",4.2 The model-theoretic space,[0],[0]
"That is, F takes a distribution ~wk and returns a quantifier for each predicate in the model, corresponding to the set overlap between w′k and p ′ 1...",4.2 The model-theoretic space,[0],[0]
"n. Note that we focus here on 5 quantifiers only, but as mentioned above, we do not preclude the possibility of learning others (including cardinals in appropriate cases).",4.2 The model-theoretic space,[0],[0]
F ( ~wk) lives in a model-theoretic space which broadly follows the representation suggested by Herbelot (2013).,4.2 The model-theoretic space,[0],[0]
We assume a space with n dimensions d1...dn which correspond to predicates p′1...n,4.2 The model-theoretic space,[0],[0]
"(e.g. is fluffy, used for transportation).",4.2 The model-theoretic space,[0],[0]
"In that space, F ( ~wk) is weighted along the dimension dm in proportion to the set overlapw′k∩p′m.7 The following shows a toy vector with only four dimensions for the concept horse.
",4.2 The model-theoretic space,[0],[0]
"a mammal 1 has four legs 0.95 is brown 0.35 is scaly 0
7In Herbelot (2013), weights are taken to be probabilities, but we prefer to talk of quantifiers, as the notion models our data more directly.
",4.2 The model-theoretic space,[0],[0]
"This vector tells us that the set of horses includes the set of mammals (the number of horses that are also mammals divided by the number of horses comes to 1, i.e. all horses are mammals), and that the set of horses and the set of things that are scaly are disjoint (no horse is scaly).",4.2 The model-theoretic space,[0],[0]
"We also learn that a great majority of horses have four legs and that some are brown.
",4.2 The model-theoretic space,[0],[0]
"In the following, we experiment with 3 modeltheoretic spaces built from the McRae and AD datasets described in §3.",4.2 The model-theoretic space,[0],[0]
"As both datasets are annotated with natural language quantifiers rather than cardinality ratios, we convert the annotation into a numerical format, where ALL → 1, MOST → 0.95, SOME → 0.35, FEW → 0.05, and NO → 0.",4.2 The model-theoretic space,[0],[0]
"These values correspond to the weights giving the best inter-annotator agreement in Herbelot and Vecchi (2015), when calculating weighted Cohen’s kappa on QMR.
",4.2 The model-theoretic space,[0],[0]
"In each model-theoretic space, a concept is represented as a vector in which the dimensions are features (has buttons, is green), and the values of the vectors along each dimension are quantifiers (in numerical format).",4.2 The model-theoretic space,[0],[0]
"When a feature does not occur with a concept in QMR, the concept’s vector receives a weight of 0 on the corresponding dimension.8 We define 3 spaces as follows.",4.2 The model-theoretic space,[0],[0]
"The McRae-based model-theoretic space (MTQMR) contains 541 concepts, as described in §3.1.",4.2 The model-theoretic space,[0],[0]
The second space is constructed specifically for the additional animal data from §3.2 (MTAD).,4.2 The model-theoretic space,[0],[0]
"Finally, we merge the two into a single space of 555 unique concepts (MTQMR+AD).",4.2 The model-theoretic space,[0],[0]
"To map from one semantic representation to another, we learn a function f : DS → MT that transforms a distributional semantic vector for a concept to its model-theoretic equivalent.
",5.1 Experimental setup,[0],[0]
"Following previous research showing that similarities amongst word representations can be maintained within linear transformations (Mikolov et al., 2013b; Frome et al., 2013), we learn the mapping as a linear relationship between the distributional representation of a word and its model-theoretic representation.",5.1 Experimental setup,[0],[0]
"We estimate the coefficients of the function using (multivariate) partial least squares regression (PLSR) as implemented in the R pls package (Mevik and Wehrens, 2007).
",5.1 Experimental setup,[0],[0]
We learn a function from the distributional space to each of the model-theoretic spaces (c.f. §4).,5.1 Experimental setup,[0],[0]
"The distribution of training and test items is outlined in Table 2, expressed as a number of concept vectors.",5.1 Experimental setup,[0],[0]
"We also include the number of quantified instances in the test set (i.e. the number of actual concept-feature pairs that were explicitly annotated in QMR/AD and that
8No transformations or dimensionality reductions were performed on the MT spaces.
",5.1 Experimental setup,[0],[0]
we can thus evaluate – this is a portion of each concept vector in the spaces including QMR data).,5.1 Experimental setup,[0],[0]
"We first consider a preliminary quantitative analysis to better understand the behavior of the transformations, while a more qualitative analysis is provided in §6.",5.2 Results,[0],[0]
"The results in Table 3 show the degree to which predicted values for each dimension in a model-theoretic space correlate with the gold annotations, operationalised as the Spearman ρ (rank-order correlation).",5.2 Results,[0],[0]
"Wherever appropriate, we also report the mean Spearman correlation between the three human annotators for the particular test set under consideration, showing how much they agreed on their judgements.9 These figures provide an upper bound performance for the system, i.e. we will consider having reached human performance if the correlation between system and gold standard is in the same range as the agreement between humans.",5.2 Results,[0],[0]
"For each mapping tested, Table 3 provides details about the training data used to learn the mapping function and the test data for the respective results.",5.2 Results,[0],[0]
"Also for each mapping, results are reported when learned from either the co-occurrence distributional space (DScooc) or the context-predicting distributional space (DSMikolov).
",5.2 Results,[0],[0]
"The top section of the table reports results for the QMR and AD dataset taken separately, as well as their concatenation.",5.2 Results,[0],[0]
"Performance on the domain-specific AD is very promising, at 0.641 correlation, calculated over 648 test instances.",5.2 Results,[0],[0]
"The results when trained on just the QMR features (MTQMR) are much lower (0.35 over 1570 test instances), which we put down to the wider variety of concepts in that dataset; we however observe a substantial increase in performance when we train and test over the two datasets (MTQMR+AD: 0.569 over 1595 instances).
",5.2 Results,[0],[0]
We investigate whether merging the datasets generally benefits QMR concepts or just the animals (see middle section in Table 3).,5.2 Results,[0],[0]
"The result on the MTanimals test set, which includes animals from the AD and QMR datasets, shows that this category fares indeed very well, at ρ = 0.663.",5.2 Results,[0],[0]
"But while augmenting the training data with category-specific datapoints benefits that category, it does not improve the results
9These figures are only available for the QMR dataset, as AD only contains one annotation per subject-predicate pair.
for concepts of other classes (c.f. compare MTanimals with MTno-animals).
",5.2 Results,[0],[0]
"Finally, we quantify the specific improvement to the QMR animal concepts by comparing the correlation obtained on MTQMRanimals (a test set consisting only of QMR animal features) after training on a) the QMR data alone and b) the merged dataset (third section of Table 3).",5.2 Results,[0],[0]
Performance increases from 0.419 to 0.666 on that specific set.,5.2 Results,[0],[0]
"This is in line with the inter-annotator agreement (0.663).
",5.2 Results,[0],[0]
"To summarise, we find that the best correlations with the gold annotations are seen when we include the animal-only dataset in training (MTAD and MTQMR+AD) and test on just animal concepts (MTAD, MTanimals and MTQMRanimals ).",5.2 Results,[0],[0]
"As one might expect, category-specific training data yields high performance when tested on the same category.",5.2 Results,[0],[0]
"Although this expectation seems intuitive, it is worth noting that our system produces promisingly high correlations, reaching human-performance on a subset of our data.",5.2 Results,[0],[0]
"The assumption we can draw from these results is that, given a reasonable amount of training data for a category, we can proficiently generate modeltheoretic representations for concept-feature pairs from a distributional space.",5.2 Results,[0],[0]
"The empirical question remains whether this can be generalized for all categories in the QMR dataset.
",5.2 Results,[0],[0]
"It is important to keep in mind that the MT spaces are not full matrices, meaning that we have ‘missing values’ for various dimensions when a concept is converted into a vector.",5.2 Results,[0],[0]
"For example, the feature has a tail is not among the annotated features for bear in QMR and has a weight of 0, even though most bears have a tail.",5.2 Results,[0],[0]
"This is a consequence of the original McRae dataset, rather than the design of our approach.",5.2 Results,[0],[0]
"But it follows that in this quantitative analysis, we are not able to confirm the accuracy of the predicted values on dimensions for which we do not have gold annotations.",5.2 Results,[0],[0]
"This may also affect the performance of the system by including ‘false’ 0 weights in the training
data.",5.2 Results,[0],[0]
Although this does not affect our reported correlation results – we test the correlations on those values for which we have gold annotations only – it does open the door to a natural next step in the evaluation.,5.2 Results,[0],[0]
"In order to judge the performance of the system on the missing gold dimensions, we need a manual analysis to assess the quality of the whole vectors, which goes hand-in-hand with obtaining additional annotations for the missing dimensions.",5.2 Results,[0],[0]
"It seems, therefore, that an active learning strategy would allow us to not only evaluate the model-theoretic vectors more fully, but also improve the system by capturing new data.10
In this analysis, we focused primarily on the comparison between transformations using various truththeoretic datasets for training and generation.",5.2 Results,[0],[0]
We leave it to further work to extensively compare the effect of varying the type of the distributional space.,5.2 Results,[0],[0]
"Our results show, however, that the Mikolov model performs slightly worse than the co-occurrence space (cooc), disproving the idea that predictive models always outperform count-based models.",5.2 Results,[0],[0]
"To further assess the quality of the produced space, we perform a nearest-neighbour analysis of our results to evaluate the coherence of the estimated vectors: for
10As suggested by a reviewer, one could also treat the missing entries as latent dimensions and define the loss function on only the known entries.",6 Discussion,[0],[0]
"We leave it to future work to test this promising option to resolve the issue of data sparsity.
",6 Discussion,[0],[0]
"each concept in our test set, we return its nearest neighbours from the gold dataset, as given by the cosine similarity measure, hoping to find that the estimated vector is close to its ideal representation (see Făgărăşan",6 Discussion,[0],[0]
et al. (2015) for a similar evaluation on McRae norms).,6 Discussion,[0],[0]
Results are shown in Table 4.,6 Discussion,[0],[0]
"We find that the gold vector is among the top 5 nearest neighbours to the predicted equivalent in nearly 20% of concepts, with the percentage of gold items in the top neighbours improving as we increase the size of the neighbourhood.",6 Discussion,[0],[0]
"We perform a more in-depth analysis of the neighbourhoods for each concept to gain a better understanding of their behaviour and quality.
",6 Discussion,[0],[0]
"We discover that, in many cases, the mapped vector is close to a similar concept in the gold standard, but not to itself.",6 Discussion,[0],[0]
"So for instance, −−−−−−→ alligatormapped is very close to −−−−−−→ crocodilegold, but not to −−−−−−→ alligatorgold.",6 Discussion,[0],[0]
"Similar findings are made for church/cathedral, axe/hatchet, dishwasher/fridge, etc.",6 Discussion,[0],[0]
"A further investigation show that in the gold standard itself, those pairs are not as close to each other as they should be.",6 Discussion,[0],[0]
"Here are some relevant cosine similarities:
alligator − crocodile 0.47 church− cathedral 0.45 axe− hatchet 0.50 dishwasher − fridge 0.21
",6 Discussion,[0],[0]
Two reasons can be identified for these comparatively low11 similarities.,6 Discussion,[0],[0]
"First, the McRae norms do not make for a consistent semantic space because a feature that – from an extensional point of view – seems relevant to two concepts may only have been produced by the annotators for one of them.",6 Discussion,[0],[0]
"As an example of this, see Table 5, which shows the feature norms for axe and hatchet after processing (§3).",6 Discussion,[0],[0]
"Although the concepts share 4 features, they also differ quite strongly, an axe being seen as a weapon with a blade, while the hatchet is itself referred to as an axe.",6 Discussion,[0],[0]
"Extensionally, of course, there is no reason to think that a hatchet does not have
11Compare with e.g. ape - monkey, Sim = 0.97.
",6 Discussion,[0],[0]
"a blade or might not be dangerous, but those features do not appear in the norms for the concept.",6 Discussion,[0],[0]
This results in the two vectors being clearly separated in the set-theoretic space.,6 Discussion,[0],[0]
"This means that the distribution of axe may well be mapped to a region close to hatchet, but thereby ends up separated from the gold axe vector.
",6 Discussion,[0],[0]
"The second, related issue is that the animal concepts in the McRae norms are annotated along fewer dimensions than in AD.",6 Discussion,[0],[0]
"For example, alligator – which only appears in the McRae set – has 13 features, while crocodile (in both sets) has 70.",6 Discussion,[0],[0]
"Given that features which are not mentioned for a concept receive a weight of 0, this also results in very different vectors.
",6 Discussion,[0],[0]
"In Table 6, we provide the top weighted features for a small set of concepts.",6 Discussion,[0],[0]
"As expected, the animal representations (bear, housefly) have higher quality than the other two (plum, cottage).",6 Discussion,[0],[0]
"But overall, the ranking of dimensions is sensible.",6 Discussion,[0],[0]
We see also that these representations have ‘learnt’ features for which we do not have values in our gold data – thereby correcting some of the 0 values in the training vectors.,6 Discussion,[0],[0]
"In a last experiment, we attempt to map the settheoretic vectors obtained in §5 back to natural language quantifiers.",7 Generating natural language quantifiers,[0],[0]
"This last step completes our pipeline, giving us a system that produces quantified statements of the type All dogs are mammals or Some bears are brown from distributional data.
",7 Generating natural language quantifiers,[0],[0]
"For each mapped vector F ( ~wk) = ~vk and a set of dimensions d1...n corresponding to properties p′1...n, the value of ~vk along each dimension is indicative of the proportion of instances of w′k having the property signalled by the dimension.",7 Generating natural language quantifiers,[0],[0]
"The smaller the value, the smaller the overlap between the set of instances of w′k and the set of things having the property.",7 Generating natural language quantifiers,[0],[0]
"Deriving natural language quantifiers from these values involves setting four thresholds tall, tmost, tsome and tfew so that for instance, if the value of ~vk along dm is more than tall, it is the case that all instances of ~wk have property pm, and similarly for the other quantifiers (no has a special status as it is not entailed by any of the other quantifiers under consideration).",7 Generating natural language quantifiers,[0],[0]
"We set the tthresholds by a systematic search on a training set (see below).
",7 Generating natural language quantifiers,[0],[0]
"To evaluate this step, we propose a function that calculates precision while taking into account the two following factors: a) some errors are worse than others: the system shouldn’t be overly penalised for classifying a property as MOST rather than ALL, but much more for classifying a gold standard ALL as SOME; b) errors that are conducive to false inferences should be strongly penalised, e.g. generating all dogs are black is more serious than some dogs are mammals, because the former might lead to incorrect inferences with respect to individual dogs while the latter is true, even though it is pragmatically odd.
",7 Generating natural language quantifiers,[0],[0]
"We set a distance matrix, which we will use for penalising errors.",7 Generating natural language quantifiers,[0],[0]
"This matrix, shown in Table 7, is basically equivalent to the matrix used by Herbelot and Vecchi (2015) to calculate weighted kappa between annotators, with the difference that all errors involving NO cause incorrect inferences and receive special treatment.",7 Generating natural language quantifiers,[0],[0]
"Cases where the gold quantifier entails the mapped quantifier (all cats |= some cats) have positive distances, while cases where the entailment doesn’t hold have negative distances.",7 Generating natural language quantifiers,[0],[0]
"Using the distance matrix, we give a score to each instance in our test data as follows:
s = { 1− d if d ≥ 0 d if d < 0
(1)
where d is obtained from the distance matrix.",7 Generating natural language quantifiers,[0],[0]
"This has the effect that when the mapped quantifier equals the gold quantifier, the system scores 1; when the mapped value deviates from the gold standard but produces a true sentence (some dogs are mammals), the system gets a partial score proportional to the distance between its output and the gold data; when the mapping results in a false sentence (all dogs are black), the
system is penalised with minus points.
",7 Generating natural language quantifiers,[0],[0]
"In what follows, we report the average performance of the system as P = ∑ sm
N where sm is the score assigned to a particular test instance, and N is the number of test instances.",7 Generating natural language quantifiers,[0],[0]
"We evaluate on the 648 test instances of MTAD, as this is the only dataset containing a fair number of negatively quantified conceptpredicate pairs.",7 Generating natural language quantifiers,[0],[0]
"We perform 5-fold cross-evaluation on this data, using 4 folds to set the t thresholds, and testing on one fold.",7 Generating natural language quantifiers,[0],[0]
We obtain an average P of 0.61.,7 Generating natural language quantifiers,[0],[0]
"Inference is preserved in 73% of cases (also averaged over the 5 folds).
",7 Generating natural language quantifiers,[0],[0]
Table 8 shows the confusion matrix for our results.,7 Generating natural language quantifiers,[0],[0]
We note that the system classifies NO-quantified instances with good accuracy (72% – most confusions being with FEW).,7 Generating natural language quantifiers,[0],[0]
"Because of the penalty given to instances that violate proper entailment, the system is conservative and prefers FEW to SOME, as well as MOST to ALL.",7 Generating natural language quantifiers,[0],[0]
"Table 9 shows randomly selected instances, together with their mapped quantifier and the label from the gold standard.",7 Generating natural language quantifiers,[0],[0]
"In this paper, we introduced an approach to map from distributional to model-theoretic semantic vectors.",8 Conclusion,[0],[0]
"Using traditional distributional representations for a concept, we showed that we are able to generate vectorial representations that encapsulate generalised quantifiers.
",8 Conclusion,[0],[0]
"We found that with a relatively “cheap” linear function – cheap in that it is easy to learn and requires modest training data – we can reproduce the quantifiers in our gold annotation with high correlation, reaching human performance on a domain-specific test set.",8 Conclusion,[0],[0]
"In future work, we will however explore the effect of more powerful functions to learn the transformations from distributional to model-theoretic spaces.
",8 Conclusion,[0],[0]
"Our qualitative analysis showed that our predicted model-theoretic vectors sensibly model the concepts under consideration, even for features which do not have gold annotations.",8 Conclusion,[0],[0]
"This is not only a promising result for our approach, but it provides potential as a next step to this work: expanding our training data with non-zero dimensions in an active learning procedure.",8 Conclusion,[0],[0]
"We also experimented with generating natural language quantifiers from the mapped vectorial representations, producing ‘true’ quantified sentences with a 73% accuracy.
",8 Conclusion,[0],[0]
"We note that our approach gives a systematic way to disambiguate non-explicitly quantified sentences such as generics, opening up new possibilities for improved semantic parsing and recognising entailment.",8 Conclusion,[0],[0]
"Right now, many parsers give the same broad analysis to Mosquitoes are insects and Mosquitoes carry malaria, involving an underspecified/generic quantifier.",8 Conclusion,[0],[0]
"This prevents inferring, for instance, that Mandie the mosquito is definitely an insect but may or may not carry malaria.",8 Conclusion,[0],[0]
"In contrast, our system would attribute the most plausible quantifiers to those sentences (all/few), allowing us to produce correct inferences.
",8 Conclusion,[0],[0]
"The focus of this paper was concept-predicate pairs
out of context.",8 Conclusion,[0],[0]
"That is, we considered quantified sentences where the restrictor was the entire set denoted by a lexical item.",8 Conclusion,[0],[0]
A natural next step is to investigate the quantification of statements involving contextualised subsets.,8 Conclusion,[0],[0]
"For instance, we should obtain a different quantifier for taxis are yellow depending on whether the sentence starts with In London... or In New York...",8 Conclusion,[0],[0]
"In future work, we will test our system on such context-specific examples, using contextualised vector representations such as the ones proposed by e.g. Erk and Padó (2008) and Dinu and Lapata (2010).
",8 Conclusion,[0],[0]
We conclude by noting again that the set-theoretic models produced in this work differ from formal semantics models in important ways.,8 Conclusion,[0],[0]
"They do not represent the world per se, but rather some shared beliefs about the world, induced from an annotated dataset of feature norms.",8 Conclusion,[0],[0]
"This calls for a modified version of the standard denotation function and for the replacement of the truth function with a ‘plausibility’ function, which would indicate how likely a stereotypical speaker might be to agree with a particular sentence.",8 Conclusion,[0],[0]
"While this would be a fundamental departure from the core philosophy of model theory, we feel that it may be a worthwhile endeavour, allowing us to preserve the immense benefits of the set-theoretic apparatus in a cognitively plausible fashion.",8 Conclusion,[0],[0]
"Following this aim, we hope to expand the preliminary framework presented here into a more expressive vector-based interpretation of set theory, catering for aspects not covered in this paper (e.g. cardinality, non-intersective modification) and refining our notion of a model, together with its relation to meaning.",8 Conclusion,[0],[0]
"We thank Marco Baroni, Stephen Clark, Ann Copestake and Katrin Erk for their helpful comments on a previous version of this paper, and the three anonymous reviewers for their thorough feedback on this work.",Acknowledgments,[0],[0]
Eva Maria Vecchi is supported by ERC Starting Grant DisCoTex (306920).,Acknowledgments,[0],[0]
"In this paper, we introduce an approach to automatically map a standard distributional semantic space onto a set-theoretic model.",abstractText,[0],[0]
We predict that there is a functional relationship between distributional information and vectorial concept representations in which dimensions are predicates and weights are generalised quantifiers.,abstractText,[0],[0]
"In order to test our prediction, we learn a model of such relationship over a publicly available dataset of feature norms annotated with natural language quantifiers.",abstractText,[0],[0]
"Our initial experimental results show that, at least for domain-specific data, we can indeed map between formalisms, and generate high-quality vector representations which encapsulate set overlap information.",abstractText,[0],[0]
We further investigate the generation of natural language quantifiers from such vectors.,abstractText,[0],[0]
Building a shared world: mapping distributional to model-theoretic semantic spaces,title,[0],[0]
"Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 2236–2242, Austin, Texas, November 1-5, 2016. c©2016 Association for Computational Linguistics",text,[0],[0]
Logic-based semantic representations have played an important role in the study of semantic parsing and inference.,1 Introduction,[0],[0]
"For English, several methods have been proposed to map outputs of parsers based on syntactic theories like CCG (Steedman, 2000) onto logical formulas (Bos, 2015).",1 Introduction,[0],[0]
"Output formulas have been used in various tasks, including Question Answering (Lewis and Steedman, 2013) and Recognizing Textual Entailment (RTE) (Bos and Markert, 2005; Beltagy et al., 2013; Bjerva et al., 2014).
",1 Introduction,[0],[0]
"Syntactic and semantic parsing for Japanese, by contrast, has been dominated by chunk-based dependency parsing and semantic role labelling (Kudo and Matsumoto, 2002; Kawahara and Kurohashi, 2011; Hayashibe et al., 2011).",1 Introduction,[0],[0]
"Recently, the method of inducing wide-coverage CCG resources for English (Hockenmaier and Steedman, 2007) has been applied to Japanese and a robust CCG parser based on it has been developed (Uematsu et al., 2015).",1 Introduction,[0],[0]
"However, building a method to map CCG trees in Japanese onto logical formulas is not a trivial task,
mainly due to the differences in syntactic structures between English and Japanese (Section 3).
",1 Introduction,[0],[0]
There are two primary contributions of this paper.,1 Introduction,[0],[0]
"First, based on an in-depth analysis of the syntax-semantics interface in Japanese, we present the first system that compositionally derives semantic representations for a wide-coverage Japanese CCG parser.",1 Introduction,[0],[0]
"Output representations are formulas in higher-order logic (HOL) combined with NeoDavidsonian Event Semantics (Parsons, 1990).",1 Introduction,[0],[0]
"Second, we demonstrate the capacity of HOL for textual entailment.",1 Introduction,[0],[0]
"We evaluate the system on a Japanese textual entailment dataset (Kawazoe et al., 2015), a dataset constructed in a similar way to the FraCaS dataset for English (Cooper et al., 1994; MacCartney and Manning, 2007).",1 Introduction,[0],[0]
"Although it is usually thought that HOL is unfeasible for practical applications, the results show that the entire system is able to perform efficient logical inference on complex linguistic phenomena such as generalized quantifiers and intensional modifiers — phenomena that pose challenges to the standard first-order-logic-based approaches.",1 Introduction,[0],[0]
"This section provides a brief overview of the entire system as applied to RTE, a task of determining whether a given text (T ) entails, contradicts, or is just consistent with, a given hypothesis (H).",2 Background and system overview,[0],[0]
"In logic-based approaches, the meanings of T and H are represented by logical formulas; whether the entailment relation holds is typically determined by checking whether T → H is a theorem in a logical system with the help of a knowledge base.
",2 Background and system overview,[0],[0]
"Currently, first-order logic (FOL) is the most pop-
2236
ular logical system used for RTE (Bos and Markert, 2005; Lewis and Steedman, 2013; Bjerva et al., 2014).",2 Background and system overview,[0],[0]
One advantage of systems based on FOL is that practical general-purpose theorem provers and model-builders are available.,2 Background and system overview,[0],[0]
"However, a drawback is that there are linguistic phenomena that cannot be represented in the standard FOL; a typical example is a generalized quantifier such as most (Barwise and Cooper, 1981).",2 Background and system overview,[0],[0]
"Accordingly, it has been standard in formal semantics of natural language to use HOL as a representation language (Montague, 1974).",2 Background and system overview,[0],[0]
"Although HOL does not have general-purpose theorem provers, there is room for developing an automated reasoning system specialized for natural language inference.",2 Background and system overview,[0],[0]
"In general, a higher-order representation makes the logical structure of a sentence more explicit than a first-order encoding does and hence can simplify the process of proof search (Miller and Nadathur, 1986).",2 Background and system overview,[0],[0]
"Recently, based on the evaluation on the FraCaS dataset (Cooper et al., 1994), Mineshima et al. (2015) showed that a higher-order inference system outperformed the Boxer/Nutcracker’s firstorder system (Bos, 2008) in both speed and accuracy.",2 Background and system overview,[0],[0]
"Likewise, Abzianidze (2015) developed a higher-order prover based on natural logic tableau system and showed that it achieved high accuracy comparable to state-of-the-art results on the SICK dataset (Marelli et al., 2014).
",2 Background and system overview,[0],[0]
There are three main steps in our pipeline.,2 Background and system overview,[0],[0]
The focus of this paper is on the last two components.,2 Background and system overview,[0],[0]
1.,2 Background and system overview,[0],[0]
Syntactic parsing Input sentences are mapped onto CCG trees.,2 Background and system overview,[0],[0]
"We use a Japanese CCG parser Jigg (Noji and Miyao, 2016)1, a statistical parser based on Japanese CCGbank (Uematsu et al., 2015).",2 Background and system overview,[0],[0]
2.,2 Background and system overview,[0],[0]
Semantic parsing CCG derivation trees are compositionally mapped onto semantic representations in HOL.,2 Background and system overview,[0],[0]
"The compositional mapping is implemented via simply typed λ-calculus in the standard way (Bos, 2008; Martı́nez-Gómez et al., 2016).",2 Background and system overview,[0],[0]
3.,2 Background and system overview,[0],[0]
Logical inference Theorem proving in HOL is performed to check for entailment and contradiction.,2 Background and system overview,[0],[0]
"Axioms and proof-search procedures are largely language-independent, so we use the higherorder inference system of Mineshima et al. (2015)2 and adapt it for our purpose.
",2 Background and system overview,[0],[0]
1https://github.com/mynlp/jigg 2https://github.com/mynlp/ccg2lambda,2 Background and system overview,[0],[0]
"Combinatory Categorial Grammar (CCG) (Steedman, 2000) is a lexicalized grammar formalism suitable for implementing a compositional mapping from syntax to semantics.",3.1 CCG and semantic lexicon,[0],[0]
A syntactic category of CCG is either a basic category such as S and NP or a functional category of the form X/Y or X\Y.,3.1 CCG and semantic lexicon,[0],[0]
The meaning of a sentence is computed from a small number of combinatory rules and the meanings of constituent words.,3.1 CCG and semantic lexicon,[0],[0]
"In addition to standard combinatory rules, the Japanese CCG parser uses a small number of unary type-shifting rules (e.g., the relativization rule that changes the category S\NP to NP/NP), to which suitable meaning composition rules are given.
",3.1 CCG and semantic lexicon,[0],[0]
"We follow the standard method of building a semantic lexicon in CCG-based logical semantics (Bos, 2008).",3.1 CCG and semantic lexicon,[0],[0]
"There are two kinds of lexical entries: (1) semantic templates that are schematic entries assigned to syntactic categories, possibly with syntactic features and (2) lexical entries directly assigned to a limited number of logical and functional expressions.",3.1 CCG and semantic lexicon,[0],[0]
"Lexical entries can be sensitive to a POS tag, a surface form, and other information contained in the parser output.",3.1 CCG and semantic lexicon,[0],[0]
Table 1 shows semantic templates for main syntactic categories.,3.1 CCG and semantic lexicon,[0],[0]
"More details will be provided in Section 3.2 and 3.3.
",3.1 CCG and semantic lexicon,[0],[0]
"We use a language of standard higher-order logic (simple type theory) (Carpenter, 1997) as a representation language.",3.1 CCG and semantic lexicon,[0],[0]
Expressions in HOL are assigned semantic types.,3.1 CCG and semantic lexicon,[0],[0]
"We use three basic types: E (Entity), Ev (Event), and Prop (Proposition).",3.1 CCG and semantic lexicon,[0],[0]
"Thus, the semantic types of expressions in our system are defined by the rule T ::= E | Ev | Prop | T1 ⇒ T2 where T1 ⇒ T2 is a function type.
",3.1 CCG and semantic lexicon,[0],[0]
"First-order language can be taken as a fragment of this system; apart from logical connectives and
quantifiers, all primitive expressions in first-order logic are confined to constant symbols of type E and predicates of type E ⇒",3.1 CCG and semantic lexicon,[0],[0]
"Prop, E ⇒ E ⇒ Prop, and so on.",3.1 CCG and semantic lexicon,[0],[0]
"Thus, adopting higher-order language does not lead to the loss of the expressive power of firstorder language.
",3.1 CCG and semantic lexicon,[0],[0]
"The Japanese CCG parser simplifies the standard CCG and uses two basic categories, S and NP.",3.1 CCG and semantic lexicon,[0],[0]
"Accordingly, a mapping (·)• from syntactic categories to semantic types can be defined as in Figure 1.",3.1 CCG and semantic lexicon,[0],[0]
Keeping the correspondence between syntactic categories and semantic types in the semantic lexicon guarantees that a well-formed formula is compositionally derived from the meaning assignment to each leaf of a CCG derivation tree.,3.1 CCG and semantic lexicon,[0],[0]
"To model a semantics for VPs in Japanese, we adopt Neo-Davidsonian Event Semantics (Parsons, 1990; Jurafsky and Martin, 2009), which is widely used in the NLP field.",3.2 Semantic composition for VPs,[0],[0]
"For instance, the sentence (1) is analyzed as having the logical form in (2):
(1) ジョン John が NOM ゆっくり slowly 歩い walk た。",3.2 Semantic composition for VPs,[0],[0]
"PAST
‘John walked slowly’
(2) ∃v(walk(v)",3.2 Semantic composition for VPs,[0],[0]
"∧ (Nom(v)= john) ∧ slow(v) ∧ Past(v))
",3.2 Semantic composition for VPs,[0],[0]
"In this approach, verbs are analyzed as 1-place predicates over events; arguments and adjuncts of VPs are also analyzed as event predicates.",3.2 Semantic composition for VPs,[0],[0]
"This semantic uniformity is suitable to handling Japanese syntactic structures in which the arguments of a VP is often implicit and thus the argument-adjunct distinction is less transparent than languages like English (Pietroski, 2005).",3.2 Semantic composition for VPs,[0],[0]
"As is seen in (2), we adopt the unique-role requirement for case markers (Carlson, 1984); for instance, the nominative case marker does not denote the relation Nom(v, x), as in the event semantics in Boxer (Bos, 2008), but the function Nom(v)=x.",3.2 Semantic composition for VPs,[0],[0]
"This treatment allows us to make use of logical properties of equality and hence is more suited to theorem-proving in our setting.
",3.2 Semantic composition for VPs,[0],[0]
"To derive a semantic representation in event semantics compositionally, we adopt the compositional semantics of VPs in Champollion (2015) and analyze VPs themselves as introducing existential quantification over events.",3.2 Semantic composition for VPs,[0],[0]
"To derive the correct meaning for VP modifiers, the semantic type of a verb is raised so that the verb takes a modifier as argument but not vice versa.",3.2 Semantic composition for VPs,[0],[0]
"Figures 2 and 3 give example derivations.
",3.2 Semantic composition for VPs,[0],[0]
"VP modifiers such as slowly license an inference from John walked slowly to John walked, an inference correctly captured by the formula in (2).",3.2 Semantic composition for VPs,[0],[0]
"In English and Japanese, however, there are intensional VP modifiers that do not license this inference pattern.",3.2 Semantic composition for VPs,[0],[0]
"Thus, the sentence John almost walked does not entail John walked (Dowty, 1979).",3.2 Semantic composition for VPs,[0],[0]
"While it is not easy to provide a desirable analysis in first-order language (Hobbs, 1985), HOL gives a perspicuous representation:
(3) ∃v(almost(walk, v)∧ (Nom(v)= john)∧Past(v))
",3.2 Semantic composition for VPs,[0],[0]
"Here, almost is a higher-order predicate having the semantic type (Ev ⇒ Prop) ⇒",3.2 Semantic composition for VPs,[0],[0]
Ev ⇒,3.2 Semantic composition for VPs,[0],[0]
Prop.,3.2 Semantic composition for VPs,[0],[0]
"The meaning assignment to VP modifiers of category S/S in Table 1 is for extensional modifiers; an intensional modifier is assigned the representation λSK.S(λJv.K(Base(J), v)) in the lexical entry, which results in a representation as in (3).",3.2 Semantic composition for VPs,[0],[0]
The quantificational structure of an NP plays a crucial role in capturing basic entailment patterns such as monotonicity inference.,3.3 Semantic composition for NPs,[0],[0]
"In the case of English, quantificational structures are specified by the type of determiners (e.g. a, the, every, some, no); together with the category distinction between N and NP, which is supported in English CCGbank (Hockenmaier and Steedman, 2007), one can provide a correct representation for NPs.
",3.3 Semantic composition for NPs,[0],[0]
"By contrast, Japanese is a classifier language, where NPs freely occur without determiners in argument position (Chierchia, 1998).",3.3 Semantic composition for NPs,[0],[0]
"For example, the subject in (4) appears in argument position without accompanying any determiner.
",3.3 Semantic composition for NPs,[0],[0]
(4) 小さな small 犬 dog が NOM 吠え bark た。,3.3 Semantic composition for NPs,[0],[0]
"PAST
‘A small dog barked’
Bekki (2010) provides a comprehensive CCG grammar for Japanese that adopts the N-NP distinction and analyzes Japanese bare NPs as accompanying the null determiner.",3.3 Semantic composition for NPs,[0],[0]
"The Japanese CCGbank, by contrast, simplifies Bekki’s (2010) grammar and avoids the use of the null determiner; it does not use the category N and takes all NPs in Japanese to have the syntactic category NP.",3.3 Semantic composition for NPs,[0],[0]
"This discrepancy in NP-structure between English and Japanese poses a challenge to the standard approach to building compositional semantics.
",3.3 Semantic composition for NPs,[0],[0]
"To provide a compositional semantics adapted for the Japanese CCG, we take NPs themselves as introducing quantification over individuals, along the same lines as the semantics for VPs.",3.3 Semantic composition for NPs,[0],[0]
The semantic type of NPs needs to be raised so that they take NPmodifiers as argument (cf.,3.3 Semantic composition for NPs,[0],[0]
the template for NP in Table 1).,3.3 Semantic composition for NPs,[0],[0]
"Figure 2 shows a derivation for the sentence in (4), where the adjective small modifies the NP dog to form a bare NP small dog.",3.3 Semantic composition for NPs,[0],[0]
It should be noted that the predicate small(x) is correctly inserted inside the scope of the existential quantification introduced by the NP dog.,3.3 Semantic composition for NPs,[0],[0]
"The so-called privative adjectives (e.g. fake and former) are analyzed in the same way as intensional VP modifiers.
",3.3 Semantic composition for NPs,[0],[0]
"Following the analysis in Mineshima et al. (2015), we analyze non-first-order generalized quantifier most as having the higher-order logical form
Most(F,G), where Most has the type of generalized quantifier (E ⇒ Prop) ⇒ (E ⇒ Prop) ⇒",3.3 Semantic composition for NPs,[0],[0]
Prop.,3.3 Semantic composition for NPs,[0],[0]
Figure 3 shows an example derivation for a sentence containing a generalized quantifier most.,3.3 Semantic composition for NPs,[0],[0]
Our system also handles floating quantifiers in Japanese.,3.3 Semantic composition for NPs,[0],[0]
"We evaluate our system3 on Japanese Semantics test suite (JSeM)4 (Kawazoe et al., 2015), a Japanese dataset for textual entailment designed in a similar way to the FraCaS dataset for English.",4 Experiments,[0],[0]
These datasets focus on the types of logical inferences that do not require world knowledge.,4 Experiments,[0],[0]
JSeM has Japanese translations of FraCaS problems and an extended set of problems focusing on Japanese syntax and semantics.,4 Experiments,[0],[0]
"Each problem has one or more premises, followed by a hypothesis.",4 Experiments,[0],[0]
"There are three types of answer: yes (entailment), no (contradiction), and unknown (neutral).",4 Experiments,[0],[0]
"Each problem is annotated with the types of inference (logical entailment, presupposition, etc.) and of linguistic phenomena.
",4 Experiments,[0],[0]
We evaluate the system on 523 problems in the dataset.,4 Experiments,[0],[0]
"We focus on problems tagged with one of the five phenomena: generalized quantifier, plu-
3The system will be available at https://github. com/mynlp/ccg2lambda.
",4 Experiments,[0],[0]
"4http://researchmap.jp/community-inf/ JSeM/?lang=english
ral, adjective, verb, and attitude.",4 Experiments,[0],[0]
"We use problems whose inference type is logical entailment, excluding anaphora and presupposition.",4 Experiments,[0],[0]
We use Kuromoji5 for morphological analysis.,4 Experiments,[0],[0]
"To focus on the evaluation of semantic parsing and inference, we use gold syntactic parses, which show an upper bound on the performance of the semantic component.",4 Experiments,[0],[0]
Gold syntactic parses are manually selected from n-best outputs of the CCG parser.,4 Experiments,[0],[0]
"For the higher-order inference system, we use the axioms presented in Mineshima et al. (2015) adapted with the necessary modification for our event semantics.
",4 Experiments,[0],[0]
"Given premises P1, ... ,",4 Experiments,[0],[0]
"Pn and a hypothesis H, the system outputs",4 Experiments,[0],[0]
"yes (P1 ∧· · ·∧Pn →H is proved), no (P1 ∧· · ·∧Pn →¬H is proved), or unknown (neither is proved in a fixed proof-search space).6",4 Experiments,[0],[0]
We set a 30 seconds timeout for each inference run; the system outputs unknown after it.,4 Experiments,[0],[0]
"The current semantic lexicon has 36 templates and 113 lexical entries.
",4 Experiments,[0],[0]
Table 2 and 3 show the results.,4 Experiments,[0],[0]
"The system with gold syntactic parses achieved 86% accuracy on the total 523 problems, with high precision and reasonable speed.",4 Experiments,[0],[0]
There was no timeout.7,4 Experiments,[0],[0]
The accuracy dropped to 70% when ablating HOL axioms (Table 3).,4 Experiments,[0],[0]
SLC refers to the performance of a supervised learning classifier8 based on 5-fold cross-validation for each section.,4 Experiments,[0],[0]
"Although direct comparison is not
5http://www.atilika.org/ 6Note that natural-logic-based systems (MacCartney and Manning, 2008) do not handle multi-premised problems.",4 Experiments,[0],[0]
7Our pipeline was run single-threaded on Ubuntu Linux 64 bits with a CPU at 2.67GHz.,4 Experiments,[0],[0]
"8We used NTCIR RITE baseline tools (http://www.cl. ecei.tohoku.ac.jp/rite2/doku.php).
",4 Experiments,[0],[0]
"possible, our system with gold parses outperforms it for all sections.
",4 Experiments,[0],[0]
"Out of the 523 problems, 417 are Japanese translations of the FraCaS problems.",4 Experiments,[0],[0]
Table 4 shows a comparison between the performance of our system on this subset of the JSeM problems and the performance of the RTE system for English in Mineshima et al. (2015) on the corresponding problems in the FraCaS dataset.,4 Experiments,[0],[0]
"Mineshima et al. (2015) used system parses of the English C&C parser (Clark and Curran, 2007).",4 Experiments,[0],[0]
"The total accuracy of our system is comparable to that of Mineshima et al. (2015).
",4 Experiments,[0],[0]
"Most errors we found are due to syntactic parse errors caused by the CCG parser, where no correct syntactic parses were found in n-best responses.",4 Experiments,[0],[0]
Comparison between gold parses and system parses shows that correct syntactic disambiguation improves performance.,4 Experiments,[0],[0]
"To our knowledge, this study provides the first semantic parsing system based on CCG that compositionally maps real texts in Japanese onto logical forms.",5 Conclusion,[0],[0]
We have also demonstrated the capacity of HOL for textual entailment.,5 Conclusion,[0],[0]
"The evaluation on JSeM showed that our system performs efficient logical inference on various semantic phenomena, including those that challenge the standard FOL.",5 Conclusion,[0],[0]
"The attractiveness of a logic-based system is that it is highly modular and can be extended with other components such as a robust knowledge base (Lewis and Steedman, 2013; Beltagy et al., 2013; Bjerva et al., 2014).",5 Conclusion,[0],[0]
"Such an extension will be a focus of future work.
",5 Conclusion,[0],[0]
Acknowledgments We are grateful to the three anonymous reviewers for their helpful comments and suggestions.,5 Conclusion,[0],[0]
This research has been supported by the JST CREST program.,5 Conclusion,[0],[0]
This paper presents a system that compositionally maps outputs of a wide-coverage Japanese CCG parser onto semantic representations and performs automated inference in higher-order logic.,abstractText,[0],[0]
The system is evaluated on a textual entailment dataset.,abstractText,[0],[0]
"It is shown that the system solves inference problems that focus on a variety of complex linguistic phenomena, including those that are difficult to represent in the standard first-order logic.",abstractText,[0],[0]
Building compositional semantics and higher-order inference system for a wide-coverage Japanese CCG parser,title,[0],[0]
"Many tasks in computer vision, natural language processing and recommendation systems require learning complex prediction rules from large datasets.",1. Introduction,[0],[0]
"As the scale of the datasets in these learning tasks continues to grow, it is crucial to utilize the power of distributed computing and storage.",1. Introduction,[0],[0]
"In such large-scale distributed systems, robustness and security issues have become a major concern.",1. Introduction,[0],[0]
"In particular, individual computing units—known as worker machines—may exhibit abnormal behavior due to crashes, faulty hardware, stalled computation or unreliable communication channels.",1. Introduction,[0],[0]
"Security issues are only exacerbated in the so-called Federated Learning setting, a modern distributed learning paradigm that is more decentralized, and that uses the data owners’ devices (such as mobile phones and personal computers)
1Department of EECS, UC Berkeley 2School of ORIE, Cornell University 3Department of Statistics, UC Berkeley.",1. Introduction,[0],[0]
Correspondence to: Dong Yin,1. Introduction,[0],[0]
"<dongyin@berkeley.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"as worker machines (McMahan & Ramage, 2017; Konečnỳ et al., 2016).",1. Introduction,[0],[0]
"Such machines are often more unpredictable, and in particular may be susceptible to malicious and coordinated attacks.
",1. Introduction,[0],[0]
"Due to the inherent unpredictability of this abnormal (sometimes adversarial) behavior, it is typically modeled as Byzantine failure (Lamport et al., 1982), meaning that some worker machines may behave completely arbitrarily and can send any message to the master machine that maintains and updates an estimate of the parameter vector to be learned.",1. Introduction,[0],[0]
Byzantine failures can incur major degradation in learning performance.,1. Introduction,[0],[0]
It is well-known that standard learning algorithms based on naive aggregation of the workers’ messages can be arbitrarily skewed by a single Byzantine-faulty machine.,1. Introduction,[0],[0]
"Even when the messages from Byzantine machines take only moderate values—hence difficult to detect—and when the number of such machines is small, the performance loss can still be significant.",1. Introduction,[0],[0]
"We demonstrate such an example in our experiments in Section 7.
",1. Introduction,[0],[0]
"In this paper, we aim to develop distributed statistical learning algorithms that are provably robust against Byzantine failures.",1. Introduction,[0],[0]
"While this objective is considered in a few recent works (Feng et al., 2014; Blanchard et al., 2017; Chen et al., 2017), a fundamental problem remains poorly understood, namely the optimal statistical performance of a robust learning algorithm.",1. Introduction,[0],[0]
"A learning scheme in which the master machine always outputs zero regardless of the workers’ messages, is certainly not affected by Byzantine failures, but it will not return anything statistically useful either.",1. Introduction,[0],[0]
"On the other hand, many standard distributed algorithms that achieve good statistical performance in the absence of Byzantine failures, become completely unreliable otherwise.",1. Introduction,[0],[0]
"Therefore, a main goal of this work is to understand the following questions: what is the best achievable statistical performance while being Byzantine-robust, and how to design an algorithm that achieves such performance?
",1. Introduction,[0],[0]
"To formalize this question, we consider a standard statistical setting of empirical risk minimization (ERM).",1. Introduction,[0],[0]
"Here nm data points are sampled independently from some distribution and distributed evenly among m machines, αm of which are Byzantine.",1. Introduction,[0],[0]
The goal is to learn a parametric model by minimizing some loss function defined by the data.,1. Introduction,[0],[0]
"In this statistical setting, one expects that the error in learning
the parameter, measured in an appropriate metric, should decrease when the amount of data nm becomes larger and the fraction of Byzantine machines α becomes smaller.",1. Introduction,[0],[0]
"In fact, we can show that, at least for strongly convex problems, no algorithm can achieve an error lower than
Ω̃ ( α√ n + 1√ nm ) = Ω̃ ( 1√ n ( α+ 1√ m )) ,
regardless of communication costs;1 see Observation 1 in Section 6.",1. Introduction,[0],[0]
"Intuitively, the above error rate is the optimal rate that one should target for, as 1√
n is the effective standard
deviation for each machine with n data points, α is the bias effect of Byzantine machines, and 1√
m is the averaging
effect of m normal machines.",1. Introduction,[0],[0]
"When there are no or few Byzantine machines, we see the usual scaling 1√
mn with
the total number of data points; when some machines are Byzantine, their influence remains bounded, and moreover is proportional to α.",1. Introduction,[0],[0]
"If an algorithm is guaranteed to attain this bound, we are assured that we do not sacrifice the quality of learning when trying to guard against Byzantine failures—we pay a price that is unavoidable, but otherwise achieve the best possible statistical accuracy in the presence of Byzantine failures.
",1. Introduction,[0],[0]
Another important consideration for us is communication efficiency.,1. Introduction,[0],[0]
"As communication between machines is costly, one cannot simply send all data to the master machine.",1. Introduction,[0],[0]
"This constraint precludes direct application of standard robust learning algorithms (such as M-estimators (Huber, 2011)), which assume access to all data.",1. Introduction,[0],[0]
"Instead, a desirable algorithm should involve a small number of communication rounds as well as a small amount of data communicated per round.",1. Introduction,[0],[0]
"We consider a setting where in each round a worker or master machine can only communicate a vector of size O(d), where d is the dimension of the parameter to be learned.",1. Introduction,[0],[0]
"In this case, the total communication cost is proportional to the number of communication rounds.
",1. Introduction,[0],[0]
"To summarize, we aim to develop distributed learning algorithms that simultaneously achieve two objectives:
• Statistical optimality: attain an Õ( α√ n + 1√ nm ) rate.
",1. Introduction,[0],[0]
"• Communication efficiency: O(d) communication per round, with as few rounds as possible.
",1. Introduction,[0],[0]
"To the best of our knowledge, no existing algorithm achieves these two goals simultaneously.",1. Introduction,[0],[0]
"In particular, previous robust algorithms either have unclear or sub-optimal statistical guarantees, or incur a high communication cost and hence not applicable in a distributed setting—we discuss related work in more detail in Section 2.
",1. Introduction,[0],[0]
"1Throughout the paper, unless otherwise stated, Ω(·) and O(·) hide universal multiplicative constants; Ω̃(·) and Õ(·) further hide terms that are independent of α, n,m or logarithmic in n,m.
Our Contributions",1. Introduction,[0],[0]
"We propose two robust distributed gradient descent (GD) algorithms, one based on coordinatewise median, and the other on coordinate-wise trimmed mean.",1. Introduction,[0],[0]
"We establish their statistical error rates for strongly convex, non-strongly convex, and non-convex population loss functions.",1. Introduction,[0],[0]
"Particularly for strongly convex losses, we show that these algorithms achieve order-optimal statistical rates under mild conditions.",1. Introduction,[0],[0]
"We further propose a medianbased robust algorithm that only requires one communication round, and show that it also achieves the optimal rate for strongly convex quadratic losses.",1. Introduction,[0],[0]
"The statistical error rates of these three algorithms are summarized as follows.
",1. Introduction,[0],[0]
"• Median-based GD: Õ( α√ n + 1√ nm + 1n ), order-optimal for strongly convex loss if n & m.
•",1. Introduction,[0],[0]
"Trimmed-mean-based GD: Õ( α√ n + 1√ nm ), orderoptimal for strongly convex loss.
",1. Introduction,[0],[0]
"• Median-based one-round algorithm: Õ( α√ n + 1√ nm
+ 1 n ), order-optimal for strongly convex quadratic loss if n & m.
A major technical challenge in our statistical setting here is as follows: the nm data points are sampled once and fixed, and each worker machine has access to the same set of data throughout learning process.",1. Introduction,[0],[0]
This creates complicated probabilistic dependency across the iterations of the algorithms.,1. Introduction,[0],[0]
"Worse yet, Byzantine machines may create further unspecified dependency.",1. Introduction,[0],[0]
We overcome this difficulty by proving certain uniform bounds via careful covering arguments.,1. Introduction,[0],[0]
"Furthermore, for the analysis of median-based algorithms, we cannot simply adapt standard techniques (such as those in Minsker et al. (2015)), which can only show that the output of the master machine is as accurate as that of one normal machine, leading to a sub-optimal O( 1√
n ) rate even without Byzantine failures.",1. Introduction,[0],[0]
"Instead, we make use of a more delicate argument based on normal approximation and Berry-Esseen-type inequalities.",1. Introduction,[0],[0]
"Outlier-robust estimation in non-distributed settings is a classical topic in statistics (Huber, 2011).",2. Related Work,[0],[0]
"Particularly relevant to us is the so-called median-of-means method, in which one partitions the data m subsets, computes an estimate from each sub-dataset, and finally takes the median of these m estimates.",2. Related Work,[0],[0]
"This idea is studied in Nemirovskii et al. (1983); Jerrum et al. (1986); Alon et al. (1999); Lerasle & Oliveira (2011); Minsker et al. (2015), and has been applied to bandit and least square regression problems (Bubeck et al., 2013; Lugosi & Mendelson, 2016; Kogler & Traxler, 2016) as well as problems involving heavy-tailed distributions (Hsu & Sabato, 2016; Lugosi & Mendelson, 2017).",2. Related Work,[0],[0]
"In a very recent work, Minsker & Strawn (2017) provide new analysis of median-of-means using normal approximation.",2. Related Work,[0],[0]
"We borrow some techniques from this paper, but need to address
a significant harder problem: 1) we deal with the Byzantine setting with arbitrary/adversarial outliers, which is not considered in their paper; 2) we study iterative algorithms for general multi-dimensional problems with convex and non-convex losses, while they mainly focus on one-shot algorithms for mean-estimation-type problems.
",2. Related Work,[0],[0]
The median-of-means method is used in the context of Byzantine-robust distributed learning in two recent papers.,2. Related Work,[0],[0]
"In particular, the work of Feng et al. (2014) considers a simple one-shot application of median-of-means, and only proves a sub-optimal Õ( 1√
n ) error rate as mentioned.",2. Related Work,[0],[0]
"The
work of Chen et al. (2017) considers only strongly convex losses, and seeks to circumvent the above issue by grouping the worker machines into mini-batches; however, their rate Õ( √ α√ n + 1√ nm
) still falls short of being optimal, and in particular their algorithm fails even when there is only one Byzantine machine in each mini-batch.
",2. Related Work,[0],[0]
"Other methods have been proposed for Byzantine-robust distributed learning and optimization; e.g., Su & Vaidya (2016a;b).",2. Related Work,[0],[0]
These works consider optimizing fixed functions and do not provide guarantees on statistical error rates.,2. Related Work,[0],[0]
"Most relevant is the work by Blanchard et al. (2017), who propose to aggregate the gradients from worker machines using a robust procedure.",2. Related Work,[0],[0]
"Their optimization setting—which is at the level of stochastic gradient descent and assumes unlimited, independent access to a strong stochastic gradient oracle—is fundamentally different from ours; in particular, they do not provide a characterization of the statistical errors given a fixed number of data points.
",2. Related Work,[0],[0]
"Communication efficiency has been studied extensively in non-Byzantine distributed settings (McMahan et al., 2016; Yin et al., 2017).",2. Related Work,[0],[0]
"An important class of algorithms are based on one-round aggregation methods (Zhang et al., 2012; 2015; Rosenblatt & Nadler, 2016).",2. Related Work,[0],[0]
"More sophisticated algorithms have been proposed in order to achieve better accuracy than the one-round approach while maintaining lower communication costs; examples include DANE (Shamir et al., 2014), Disco (Zhang & Lin, 2015), distributed SVRG (Lee et al., 2015) and their variants (Reddi et al., 2016; Wang et al., 2017).",2. Related Work,[0],[0]
"Developing Byzantine-robust versions of these algorithms is an interesting future direction.
",2. Related Work,[0],[0]
"For outlier-robust estimation in non-distributed settings, much progress has been made recently in terms of improved performance in high-dimensional problems (Diakonikolas et al., 2016; Lai et al., 2016; Bhatia et al., 2015) as well as developing list-decodable and semi-verified learning schemes when a majority of the data points are adversarial (Charikar et al., 2017).",2. Related Work,[0],[0]
"These results are not directly applicable to our distributed setting with general loss functions, but it is nevertheless an interesting future problem to investigate their potential extension for our problem.",2. Related Work,[0],[0]
"In this section, we formally set up our problem and introduce a few concepts key to our the algorithm design and analysis.",3. Problem Setup,[0],[0]
Suppose that training data points are sampled from some unknown distribution D on the sample space Z .,3. Problem Setup,[0],[0]
"Let f(w; z) be a loss function of a parameter vector w ∈ W ⊆ Rd associated with the data point z, whereW is the parameter space, and F (w) := Ez∼D[f(w; z)] is the corresponding population loss function.",3. Problem Setup,[0],[0]
"Our goal is to learn a model defined by the parameter that minimizes the population loss:
w∗ = arg min w∈W F (w).",3. Problem Setup,[0],[0]
"(1)
The parameter spaceW is assumed to be convex and compact with diameter D, i.e., ‖w −w′‖2 ≤ D,∀w,w′ ∈",3. Problem Setup,[0],[0]
W .,3. Problem Setup,[0],[0]
We consider a distributed computation model with one master machine and m worker machines.,3. Problem Setup,[0],[0]
"Each worker machine stores n data points, each of which is sampled independently from D. Denote by zi,j the j-th data on the i-th worker machine, and Fi(w) :",3. Problem Setup,[0],[0]
= 1n,3. Problem Setup,[0],[0]
"∑n j=1 f(w; z
i,j) the empirical risk function for the i-th worker.",3. Problem Setup,[0],[0]
"We assume that an α fraction of the m worker machines are Byzantine, and the remaining 1− α fraction are normal.",3. Problem Setup,[0],[0]
"With the notation [N ] := {1, 2, . . .",3. Problem Setup,[0],[0]
", N}, we index the set of worker machines by [m], and denote the set of Byzantine machines by B ⊂",3. Problem Setup,[0],[0]
[m] (thus |B| = αm).,3. Problem Setup,[0],[0]
The master machine communicates with the worker machines using some predefined protocol.,3. Problem Setup,[0],[0]
"The Byzantine machines need not obey this protocol and can send arbitrary messages to the master; in particular, they may have complete knowledge of the system and learning algorithms, and can collude with each other.
",3. Problem Setup,[0],[0]
"We introduce the coordinate-wise median and trimmed mean operations, which serve as building blocks for our algorithm.",3. Problem Setup,[0],[0]
Definition 1 (Coordinate-wise median).,3. Problem Setup,[0],[0]
"For vectors xi ∈ Rd, i ∈",3. Problem Setup,[0],[0]
"[m], the coordinate-wise median g := med{xi : i ∈",3. Problem Setup,[0],[0]
[m]} is a vector with its k-th coordinate being,3. Problem Setup,[0],[0]
gk = med{xik :,3. Problem Setup,[0],[0]
i ∈,3. Problem Setup,[0],[0]
[m]} for each k ∈,3. Problem Setup,[0],[0]
"[d], where med is the usual (one-dimensional) median.",3. Problem Setup,[0],[0]
Definition 2 (Coordinate-wise trimmed mean).,3. Problem Setup,[0],[0]
For β ∈,3. Problem Setup,[0],[0]
"[0, 12 ) and vectors",3. Problem Setup,[0],[0]
"x
i",3. Problem Setup,[0],[0]
"∈ Rd, i ∈",3. Problem Setup,[0],[0]
"[m], the coordinate-wise βtrimmed",3. Problem Setup,[0],[0]
mean g := trmeanβ{xi :,3. Problem Setup,[0],[0]
i ∈,3. Problem Setup,[0],[0]
[m]} is a vector with its k-th coordinate being gk = 1(1−2β)m ∑,3. Problem Setup,[0],[0]
x∈Uk x for each k ∈,3. Problem Setup,[0],[0]
[d].,3. Problem Setup,[0],[0]
"Here Uk is a subset of {x1k, . . .",3. Problem Setup,[0],[0]
", xmk } obtained by removing the largest and smallest β fraction of its elements.",3. Problem Setup,[0],[0]
"For the analysis, we need several standard definitions concerning random variables/vectors.",3. Problem Setup,[0],[0]
Definition 3 (Variance of random vectors).,3. Problem Setup,[0],[0]
"For a random vector x, define its variance as Var(x)",3. Problem Setup,[0],[0]
:= E[‖x− E[x]‖22].,3. Problem Setup,[0],[0]
Definition 4 (Absolute skewness).,3. Problem Setup,[0],[0]
"For a one-dimensional random variable X , define its absolute skewness2 as
2Note the difference with the usual skewness E[(X−E[X]) 3]
Var(X)3/2 .
γ(X)",3. Problem Setup,[0],[0]
":= E[|X−E[X]| 3]
Var(X)3/2 .",3. Problem Setup,[0],[0]
"For a d-dimensional random vec-
tor x, we define its absolute skewness as the vector of the absolute skewness of each coordinate of x, i.e., γ(x) := [γ(x1) γ(x2) · · · γ(xd)]>.",3. Problem Setup,[0],[0]
Definition 5 (Sub-exponential random variables).,3. Problem Setup,[0],[0]
A random variable X with E[X] = µ is called v-sub-exponential if E[eλ(X−µ)] ≤,3. Problem Setup,[0],[0]
"e 12v2λ2 , ∀ |λ| < 1v .",3. Problem Setup,[0],[0]
"Finally, we need several standard concepts from convex analysis regarding a differentiable function h(·) : Rd → R. Definition 6 (Lipschitz).",3. Problem Setup,[0],[0]
h is L-Lipschitz if |h(w)− h(w′)| ≤ L‖w,3. Problem Setup,[0],[0]
"−w′‖2,∀",3. Problem Setup,[0],[0]
"w,w′. Definition 7 (Smoothness).",3. Problem Setup,[0],[0]
"h is L′-smooth if ‖∇h(w)−∇h(w′)‖2 ≤ L′‖w −w′‖2,∀",3. Problem Setup,[0],[0]
"w,w′. Definition 8 (Strong convexity).",3. Problem Setup,[0],[0]
"h is λ-strongly convex if h(w′) ≥ h(w)+〈∇h(w),w′−w〉+ λ2 ‖w ′−w‖22,∀w,w′.",3. Problem Setup,[0],[0]
"We describe two robust distributed gradient descent algorithms, one based on coordinate-wise median and the other on trimmed mean.",4. Robust Distributed Gradient Descent,[0],[0]
"These two algorithms are formally given in Algorithm 1 as Option I and Option II, respectively, where the symbol ∗ represents an arbitrary vector.
",4. Robust Distributed Gradient Descent,[0],[0]
"In each parallel iteration of the algorithms, the master machine broadcasts the current model parameter to all worker machines.",4. Robust Distributed Gradient Descent,[0],[0]
The normal worker machines compute the gradients of their local loss functions and then send the gradients back to the master machine.,4. Robust Distributed Gradient Descent,[0],[0]
The Byzantine machines may send any messages of their choices.,4. Robust Distributed Gradient Descent,[0],[0]
"The master machine then performs a gradient descent update on the model parameter with step-size η, using either the coordinate-wise median or trimmed mean of the received gradients.",4. Robust Distributed Gradient Descent,[0],[0]
"The Euclidean projection ΠW(·) ensures that the model parameter stays in the parameter spaceW .
",4. Robust Distributed Gradient Descent,[0],[0]
"Below we provide statistical guarantees on the error rates of these algorithms, and compare their performance.",4. Robust Distributed Gradient Descent,[0],[0]
"Throughout we assume that each loss functions f(w; z) and the population loss function F (w) are smooth:
Assumption 1 (Smoothness of f and F ).",4. Robust Distributed Gradient Descent,[0],[0]
"For any z ∈ Z , the partial derivative of f(·; z) with respect to the k-th coordinate of its first argument, denoted by ∂kf(·; z), is Lk-Lipschitz for each k ∈",4. Robust Distributed Gradient Descent,[0],[0]
"[d], and the function f(·; z) is L-smooth.",4. Robust Distributed Gradient Descent,[0],[0]
"Let L̂ := ( ∑d k=1 L 2 k)
1/2.",4. Robust Distributed Gradient Descent,[0],[0]
"Also assume that the population loss function F (·) is LF -smooth.
",4. Robust Distributed Gradient Descent,[0],[0]
It is easy to see hat LF ≤ L ≤ L̂.,4. Robust Distributed Gradient Descent,[0],[0]
We note that L̂ appears because we have coordinate-wise operations and the L̂ quantity combines the smoothness parameter of all the d partial derivatives.,4. Robust Distributed Gradient Descent,[0],[0]
"When the dimension of w is high, the quantity L̂ may be large.",4. Robust Distributed Gradient Descent,[0],[0]
"However, we will soon see that L̂ only appears in the logarithmic factors in our bounds and thus does not have a significant impact.
",4. Robust Distributed Gradient Descent,[0],[0]
"Algorithm 1 Robust Distributed Gradient Descent
Require: Initialize parameter vector w0 ∈",4. Robust Distributed Gradient Descent,[0],[0]
"W , algorithm parameters β",4. Robust Distributed Gradient Descent,[0],[0]
"(for Option II), η and T .",4. Robust Distributed Gradient Descent,[0],[0]
"for t = 0, 1, 2, . . .",4. Robust Distributed Gradient Descent,[0],[0]
", T − 1 do
Master machine: send wt to all the worker machines.",4. Robust Distributed Gradient Descent,[0],[0]
for i ∈,4. Robust Distributed Gradient Descent,[0],[0]
"[m] in parallel do
Worker machine i: compute local gradient
gi(wt)← { ∇Fi(wt) normal machines, ∗ Byzantine machines,
send gi(wt) to master machine.",4. Robust Distributed Gradient Descent,[0],[0]
"end for Master machine: compute aggregate gradient
g(wt)← { med{gi(wt) :",4. Robust Distributed Gradient Descent,[0],[0]
i ∈,4. Robust Distributed Gradient Descent,[0],[0]
[m]} Option I trmeanβ{gi(wt),4. Robust Distributed Gradient Descent,[0],[0]
: i ∈,4. Robust Distributed Gradient Descent,[0],[0]
"[m]} Option II
update model parameter wt+1 ← ΠW(wt",4. Robust Distributed Gradient Descent,[0],[0]
− ηg(wt)),4. Robust Distributed Gradient Descent,[0],[0]
.,4. Robust Distributed Gradient Descent,[0],[0]
"end for
In addition, when F (·) is convex, we assume that w∗, the minimizer of F (·) inW , is also the minimizer of F (·) in Rd.",4. Robust Distributed Gradient Descent,[0],[0]
"Formally, we have Assumption 2 (minimizer in W).",4. Robust Distributed Gradient Descent,[0],[0]
"Suppose that F (w) is convex, and let w∗ = arg minw∈W F (w).",4. Robust Distributed Gradient Descent,[0],[0]
We assume that ∇F (w∗) = 0.,4. Robust Distributed Gradient Descent,[0],[0]
"We first consider our median-based algorithm, namely Algorithm 1 with Option I.",4.1. Median-based Gradient Descent,[0],[0]
"We impose the assumptions that the gradient of the loss function f has bounded variance, and each coordinate of the gradient has coordinate-wise bounded absolute skewness:
Assumption 3 (Bounded variance of gradient).",4.1. Median-based Gradient Descent,[0],[0]
"For any w ∈ W , Var(∇f(w; z)) ≤ V 2.",4.1. Median-based Gradient Descent,[0],[0]
Assumption 4 (Bounded skewness of gradient).,4.1. Median-based Gradient Descent,[0],[0]
"For any w ∈ W , ‖γ(∇f(w; z))‖∞ ≤ S.",4.1. Median-based Gradient Descent,[0],[0]
"These assumptions are satisfied in many learning problems with small values of V 2 and S. Below we provide a concrete example in terms of a linear regression problem.
",4.1. Median-based Gradient Descent,[0],[0]
Proposition 1.,4.1. Median-based Gradient Descent,[0],[0]
"Suppose that each data point z = (x, y) ∈ Rd × R is generated by y = x>w∗ + ξ with some w∗ ∈ W .",4.1. Median-based Gradient Descent,[0],[0]
"Assume that the elements of x are independent and uniformly distributed in {−1, 1}, and that the noise ξ ∼ N (0, σ2) is independent of x. With the quadratic loss function",4.1. Median-based Gradient Descent,[0],[0]
"f(w;x, y)",4.1. Median-based Gradient Descent,[0],[0]
"= 12 (y − x
Tw)2, we have Var(∇f(w;x, y))",4.1. Median-based Gradient Descent,[0],[0]
=,4.1. Median-based Gradient Descent,[0],[0]
"(d− 1)‖w −w∗‖22 + dσ2, and ‖γ(∇f(w;x, y))‖∞ ≤ 480.
",4.1. Median-based Gradient Descent,[0],[0]
We prove Proposition 1 in Appendix A.1.,4.1. Median-based Gradient Descent,[0],[0]
"In this example, the upper bound V on Var(∇f(w;x, y)) depends on dimension d and the diameter of the parameter space, and if the diameter is a constant, we have V = O( √ d).",4.1. Median-based Gradient Descent,[0],[0]
"Moreover,
the gradient skewness is bounded by a universal constant S regardless of the size of the parameter space.
",4.1. Median-based Gradient Descent,[0],[0]
"We now state our main technical results on the median-based algorithm, namely statistical error guarantees for strongly convex, non-strongly convex, and smooth non-convex population loss functions F .",4.1. Median-based Gradient Descent,[0],[0]
Strongly Convex Losses: We first consider the case where the population loss function F (·) is strongly convex.,4.1. Median-based Gradient Descent,[0],[0]
Note that we do not require strong convexity of the individual loss function f(·; z).,4.1. Median-based Gradient Descent,[0],[0]
Theorem 1.,4.1. Median-based Gradient Descent,[0],[0]
Consider Option I in Algorithm 1.,4.1. Median-based Gradient Descent,[0],[0]
"Suppose that Assumptions 1, 2, 3, and 4 hold, F (·) is λF -strongly convex, and the fraction α of Byzantine machines satisfies
α+
√ d log(1 + nmL̂D)
m(1− α) + 0.4748 S√ n ≤ 1 2 − (2)
for some > 0.",4.1. Median-based Gradient Descent,[0],[0]
Choose step-size η = 1/LF .,4.1. Median-based Gradient Descent,[0],[0]
"Then, with probability at least 1− 4d
(1+nmL̂D)d , after T parallel itera-
tions, we have
‖wT −w∗‖2 ≤",4.1. Median-based Gradient Descent,[0],[0]
"(1− λF
LF + λF )",4.1. Median-based Gradient Descent,[0],[0]
T ‖w0,4.1. Median-based Gradient Descent,[0],[0]
"−w∗‖2 +
2
λF ∆,
where ∆ := O ( C V ( α√ n +
√ d log(nmL̂D)
nm + S n
))",4.1. Median-based Gradient Descent,[0],[0]
", (3)
and C is defined as
C := √ 2π exp (1
2 (Φ−1(1− ))2
) , (4)
with Φ−1(·) being the inverse of the cumulative distribution function of the standard Gaussian distribution Φ(·).",4.1. Median-based Gradient Descent,[0],[0]
"We prove Theorem 1 in Appendix B. In (3), we hide universal constants and a higher order term that scales as 1nm , and the factor C is a function of ; as a concrete example, C ≈ 4 when = 16 .",4.1. Median-based Gradient Descent,[0],[0]
"Theorem 1 together with the inequality log(1− x) ≤ −x, guarantees that after running T ≥ LF +λFλF log( λF 2∆‖w
0 −w∗‖2) parallel iterations, with high probability we can obtain a solution ŵ = wT with error ‖ŵ",4.1. Median-based Gradient Descent,[0],[0]
"−w∗‖2 ≤ 4λF ∆.
Here we achieve an the error rate (defined as the distance between ŵ and the optimal solution w∗) of the form Õ( α√
n + 1√ nm + 1n ).",4.1. Median-based Gradient Descent,[0],[0]
"In Section 6, we provide a
lower bound showing that the error rate of any algorithm is Ω̃( α√
n + 1√ nm ).",4.1. Median-based Gradient Descent,[0],[0]
Therefore the first two terms in the upper bound cannot be improved.,4.1. Median-based Gradient Descent,[0],[0]
The third term 1n is due to the dependence of median on the skewness of the gradients.,4.1. Median-based Gradient Descent,[0],[0]
"When each worker machine has a sufficient amount of data, more specifically n & m, we achieve an order-optimal error rate up to logarithmic factors.
",4.1. Median-based Gradient Descent,[0],[0]
"Non-strongly Convex Losses: We next consider the case where the population risk function F (·) is convex, but not necessarily strongly convex.",4.1. Median-based Gradient Descent,[0],[0]
"In this case, we need a mild technical assumption on the size of the parameter spaceW .
",4.1. Median-based Gradient Descent,[0],[0]
Assumption 5 (Size ofW).,4.1. Median-based Gradient Descent,[0],[0]
The parameter spaceW contains the following `2 ball centered at w∗: {w ∈ Rd : ‖w,4.1. Median-based Gradient Descent,[0],[0]
"−w∗‖2 ≤ 2‖w0 −w∗‖2}.
",4.1. Median-based Gradient Descent,[0],[0]
This assumption (and Assumption 6 below) ensures that the iterates wt always stay inW without projection.,4.1. Median-based Gradient Descent,[0],[0]
"Doing so streamlines our analysis, as our main focus is on robustness.",4.1. Median-based Gradient Descent,[0],[0]
"We then have the following result on the convergence rate in terms of the value of the population risk function.
",4.1. Median-based Gradient Descent,[0],[0]
Theorem 2.,4.1. Median-based Gradient Descent,[0],[0]
Consider Option I in Algorithm 1.,4.1. Median-based Gradient Descent,[0],[0]
"Suppose that Assumptions 1, 2, 3, 4 and 5 hold, and that the population loss F (·) is convex, and α satisfies (2) for some > 0.",4.1. Median-based Gradient Descent,[0],[0]
"Define ∆ as in (3), and choose step-size η = 1/LF .",4.1. Median-based Gradient Descent,[0],[0]
"Then, with probability at least 1− 4d(1+nmL̂D)d , after T = LF∆ ‖w 0",4.1. Median-based Gradient Descent,[0],[0]
"−w∗‖2 parallel iterations, we have
F (wT )",4.1. Median-based Gradient Descent,[0],[0]
"− F (w∗) ≤ 16‖w0 −w∗‖2∆ ( 1 + 1 2LF ∆ ) .
",4.1. Median-based Gradient Descent,[0],[0]
"We prove Theorem 2 in Appendix C. We observe that the error rate, defined as the excess risk F (wT )−F (w∗), again has the form Õ ( α√ n + 1√ nm + 1n ) .
",4.1. Median-based Gradient Descent,[0],[0]
"Non-convex Losses: When F (·) is non-convex but smooth, we need a somewhat different technical assumption on the size ofW .",4.1. Median-based Gradient Descent,[0],[0]
Assumption 6 (Size of W).,4.1. Median-based Gradient Descent,[0],[0]
"Suppose that ∀ w ∈ W , ‖∇F (w)‖2 ≤M .",4.1. Median-based Gradient Descent,[0],[0]
We assume thatW contains the `2 ball {w ∈,4.1. Median-based Gradient Descent,[0],[0]
Rd : ‖w−w0‖2 ≤,4.1. Median-based Gradient Descent,[0],[0]
"2∆2 (M+∆)(F (w
0)−F (w∗))}, where ∆ is defined as in (3).
",4.1. Median-based Gradient Descent,[0],[0]
We have the following guarantees on the rate of convergence to a critical point of the population loss F (·).,4.1. Median-based Gradient Descent,[0],[0]
Theorem 3.,4.1. Median-based Gradient Descent,[0],[0]
Consider Option I in Algorithm 1.,4.1. Median-based Gradient Descent,[0],[0]
"Suppose that Assumptions 1 3, 4 and 6 hold, and α satisfies (2) for some > 0.",4.1. Median-based Gradient Descent,[0],[0]
"Define ∆ as in (3), and choose step-size η = 1/LF .",4.1. Median-based Gradient Descent,[0],[0]
"With probability at least 1− 4d(1+nmL̂D)d , after T = 2LF∆2 (F (w 0)− F (w∗)) parallel iterations, we have
min t=0,1,...,T
‖∇F (wt)‖2 ≤ √ 2∆.
We prove Theorem 3 in Appendix D. We again obtain an Õ( α√
n + 1√ nm + 1n ) error rate in terms of the gap to a critical
point of F (w).",4.1. Median-based Gradient Descent,[0],[0]
"We next analyze the robust distributed gradient descent algorithm based on coordinate-wise trimmed mean, namely Option II in Algorithm 1.",4.2. Trimmed-mean-based Gradient Descent,[0],[0]
"Here we need stronger assumptions on the tail behavior of the partial derivatives of the loss functions—in particular, sub-exponentiality.
",4.2. Trimmed-mean-based Gradient Descent,[0],[0]
Assumption 7 (Sub-exponential gradients).,4.2. Trimmed-mean-based Gradient Descent,[0],[0]
We assume that for all k ∈,4.2. Trimmed-mean-based Gradient Descent,[0],[0]
"[d] and w ∈ W , the partial derivative of f(w; z) with respect to the k-th coordinate of w, ∂kf(w; z), is vsub-exponential.
",4.2. Trimmed-mean-based Gradient Descent,[0],[0]
The sub-exponential property implies that all the moments of the derivatives are bounded.,4.2. Trimmed-mean-based Gradient Descent,[0],[0]
"This is a stronger assumption than the bounded absolute skewness (hence bounded third moments) required by the median-based GD algorithm.
",4.2. Trimmed-mean-based Gradient Descent,[0],[0]
"We use the same example as in Proposition 1 and show that the derivatives of the loss are indeed sub-exponential.
Proposition 2.",4.2. Trimmed-mean-based Gradient Descent,[0],[0]
Consider the regression problem in Proposition 1.,4.2. Trimmed-mean-based Gradient Descent,[0],[0]
For all k ∈,4.2. Trimmed-mean-based Gradient Descent,[0],[0]
"[d] and w ∈ W , the partial derivative ∂kf(w; z) is √ σ2 + ‖w",4.2. Trimmed-mean-based Gradient Descent,[0],[0]
"−w∗‖22-sub-exponential.
",4.2. Trimmed-mean-based Gradient Descent,[0],[0]
Proposition 2 is proved in Appendix A.3.,4.2. Trimmed-mean-based Gradient Descent,[0],[0]
"We now proceed to establish the statistical guarantees of the trimmed-meanbased algorithm, for different loss function classes.",4.2. Trimmed-mean-based Gradient Descent,[0],[0]
"When the population loss F (·) is convex, we again assume that the minimizer of F (·) inW is also its minimizer in Rd.",4.2. Trimmed-mean-based Gradient Descent,[0],[0]
"The next three theorems are analogues of Theorems 1–3 for the median-based GD algorithm.
",4.2. Trimmed-mean-based Gradient Descent,[0],[0]
Strongly Convex Losses: We have the following result.,4.2. Trimmed-mean-based Gradient Descent,[0],[0]
Theorem 4.,4.2. Trimmed-mean-based Gradient Descent,[0],[0]
Consider Option II in Algorithm 1.,4.2. Trimmed-mean-based Gradient Descent,[0],[0]
"Suppose that Assumptions 1, 2, and 7 hold, F (·) is λF -strongly convex, and α ≤ β ≤ 12 − for some > 0.",4.2. Trimmed-mean-based Gradient Descent,[0],[0]
Choose step-size η = 1/LF .,4.2. Trimmed-mean-based Gradient Descent,[0],[0]
"Then, with probability at least 1− 4d(1+nmL̂D)d , after T parallel iterations, we have
‖wT −w∗‖2 ≤",4.2. Trimmed-mean-based Gradient Descent,[0],[0]
"(
1− λF",4.2. Trimmed-mean-based Gradient Descent,[0],[0]
"LF + λF
)T ‖w0",4.2. Trimmed-mean-based Gradient Descent,[0],[0]
"−w∗‖2 + 2
λF ∆′,
where ∆′ := O (vd ( β√ n + 1√ nm )√ log(nmL̂D) ) .",4.2. Trimmed-mean-based Gradient Descent,[0],[0]
"(5)
We prove Theorem 4 in Appendix E. In (5), we hide universal constants and higher order terms that scale as βn or
1 nm .",4.2. Trimmed-mean-based Gradient Descent,[0],[0]
"By running T ≥ LF +λF λF log( λF2∆′ ‖w 0 −w∗‖2) parallel iterations, we can obtain a solution ŵ = wT satisfying ‖ŵ",4.2. Trimmed-mean-based Gradient Descent,[0],[0]
− w∗‖2 ≤,4.2. Trimmed-mean-based Gradient Descent,[0],[0]
"Õ( β√n + 1√ nm
).",4.2. Trimmed-mean-based Gradient Descent,[0],[0]
Note that one needs to choose the parameter for trimmed mean to satisfy β ≥ α.,4.2. Trimmed-mean-based Gradient Descent,[0],[0]
"If we set β = cα for some universal constant c ≥ 1, we can achieve an order-optimal error rate Õ( α√
n + 1√ nm ).
",4.2. Trimmed-mean-based Gradient Descent,[0],[0]
"Non-strongly Convex Losses: Again imposing Assumption 5 on the size ofW , we have the following guarantee.",4.2. Trimmed-mean-based Gradient Descent,[0],[0]
Theorem 5.,4.2. Trimmed-mean-based Gradient Descent,[0],[0]
Consider Option II in Algorithm 1.,4.2. Trimmed-mean-based Gradient Descent,[0],[0]
"Suppose that Assumptions 1, 2, 5 and 7 hold, F (·) is convex, and α ≤ β ≤ 12",4.2. Trimmed-mean-based Gradient Descent,[0],[0]
− for some > 0.,4.2. Trimmed-mean-based Gradient Descent,[0],[0]
"Choose step-size η = 1/LF , and define ∆′ as in (5).",4.2. Trimmed-mean-based Gradient Descent,[0],[0]
"Then, with probability at least 1− 4d
(1+nmL̂D)d , after T = LF∆′ ‖w 0",4.2. Trimmed-mean-based Gradient Descent,[0],[0]
"−w∗‖2 parallel iterations, we have
F (wT )",4.2. Trimmed-mean-based Gradient Descent,[0],[0]
"− F (w∗) ≤ 16‖w0 −w∗‖2∆′ ( 1 + 1 2LF ∆′ ) .
",4.2. Trimmed-mean-based Gradient Descent,[0],[0]
"The proof of Theorem 5 is similar to that of Theorem 2, and we refer readers to Remark 1 in Appendix E. Again, by choosing β = cα (c ≥ 1), we obtain the Õ( α√
n + 1√ nm )
error rate in the function value of F (w).
",4.2. Trimmed-mean-based Gradient Descent,[0],[0]
"Non-convex Losses: In this case, imposing a version of Assumption 6 on the size ofW , we have the following.",4.2. Trimmed-mean-based Gradient Descent,[0],[0]
Theorem 6.,4.2. Trimmed-mean-based Gradient Descent,[0],[0]
"Consider Option II in Algorithm 1, and define ∆′ as in (5).",4.2. Trimmed-mean-based Gradient Descent,[0],[0]
"Suppose that Assumptions 1 and 7 hold, Assumption 6 holds with ∆ replaced by ∆′, and α ≤ β ≤ 12 − for some > 0.",4.2. Trimmed-mean-based Gradient Descent,[0],[0]
Choose step-size η = 1/LF .,4.2. Trimmed-mean-based Gradient Descent,[0],[0]
"Then, with probability at least 1− 4d(1+nmL̂D)d , after T = 2LF∆′2 (F (w
0)",4.2. Trimmed-mean-based Gradient Descent,[0],[0]
"− F (w∗)) parallel iterations, we have
min t=0,1,...,T
‖∇F (wt)‖2 ≤ √ 2∆′.
The proof of Theorem 6 is similar to that of Theorem 3; see Remark 1 in Appendix E. By choosing β = cα with c ≥ 1, we again achieve the statistical rate Õ( α√
n + 1√ nm ).",4.2. Trimmed-mean-based Gradient Descent,[0],[0]
We compare the performance guarantees of the above two robust distribute GD algorithms.,4.3. Comparisons,[0],[0]
"The trimmed-mean-based algorithm achieves the statistical error rate Õ( α√
n + 1√ nm ),
which is order-optimal for strongly convex loss.",4.3. Comparisons,[0],[0]
"In comparison, the rate of the median-based algorithm is Õ( α√
n +
1√ nm + 1n ), which has an additional 1 n term and is only optimal when n & m. In particular, the trimmed-meanbased algorithm has better rates when each worker machine has small local sample size—the rates are meaningful even in the extreme case n = O(1).",4.3. Comparisons,[0],[0]
"On the other hand, the median-based algorithm requires milder tail/moment assumptions on the loss derivatives (bounded skewness) than its trimmed-mean counterpart (sub-exponentiality).",4.3. Comparisons,[0],[0]
"Finally, the trimmed-mean operation requires an additional parameter β, which can be any upper bound on the fraction α of Byzantine machines in order to guarantee robustness.",4.3. Comparisons,[0],[0]
Using an overly large β may lead to a looser bound and sub-optimal performance.,4.3. Comparisons,[0],[0]
"In contrast, median-based GD does not require knowledge of α.",4.3. Comparisons,[0],[0]
We summarize these observations in Table 1.,4.3. Comparisons,[0],[0]
"We see that the two algorithms are complementary to each other, and our experiment results corroborate this point.",4.3. Comparisons,[0],[0]
"As mentioned, in our distributed computing framework, the communication cost is proportional to the number of parallel iterations.",5. Robust One-round Algorithm,[0],[0]
The above two GD algorithms both require a number iterations depending on the desired accuracy.,5. Robust One-round Algorithm,[0],[0]
"Can we further reduce the communication cost while keeping the algorithm Byzantine-robust and statistically optimal?
",5. Robust One-round Algorithm,[0],[0]
A natural candidate is the so-called one-round algorithm.,5. Robust One-round Algorithm,[0],[0]
"Previous work has considered a standard one-round scheme where each local machine computes the empirical risk minimizer (ERM) using its local data and the master machine receives all workers’ ERMs and computes their average (Zhang et al., 2012).",5. Robust One-round Algorithm,[0],[0]
"Clearly, a single Byzantine machine can arbitrary skew the output of this algorithm.",5. Robust One-round Algorithm,[0],[0]
We instead consider a Byzantine-robust one-round algorithm.,5. Robust One-round Algorithm,[0],[0]
"As detailed in Algorithm 2, we employ the coordinate-wise median operation to aggregate all the ERMs.
",5. Robust One-round Algorithm,[0],[0]
Algorithm 2 Robust One-round Algorithm for i ∈,5. Robust One-round Algorithm,[0],[0]
"[m] in parallel do
Worker machine",5. Robust One-round Algorithm,[0],[0]
"i: compute & send to master machine:
ŵi ← { arg minw∈W Fi(w) normal machines ∗ Byzantine machines
end for Master machine: compute ŵ← med{ŵi : i ∈",5. Robust One-round Algorithm,[0],[0]
"[m]}.
",5. Robust One-round Algorithm,[0],[0]
Our main result is a characterization of the error rate of Algorithm 2 in the presence of Byzantine failures.,5. Robust One-round Algorithm,[0],[0]
We are only able to establish such a guarantee when the loss functions are quadratic andW = Rd.,5. Robust One-round Algorithm,[0],[0]
"However, one can implement this algorithm in problems with other loss functions.
",5. Robust One-round Algorithm,[0],[0]
Definition 9 (Quadratic loss function).,5. Robust One-round Algorithm,[0],[0]
"The loss function f(w; z) is quadratic if it can be written as
f(w; z) = 1
2 wTHw + pTw + c,
where z =",5. Robust One-round Algorithm,[0],[0]
"(H,p, c), H, and p, and c are drawn from the distributions DH , Dp, and Dc, respectively.",5. Robust One-round Algorithm,[0],[0]
"Denote by HF , pF , and cF the expectations of H, p, and c, respectively.",5. Robust One-round Algorithm,[0],[0]
Thus the population risk function takes the form F (w) = 12w THFw + p T,5. Robust One-round Algorithm,[0],[0]
"Fw + cF .
",5. Robust One-round Algorithm,[0],[0]
"We need a technical assumption which guarantees that each normal worker machine has unique ERM.
",5. Robust One-round Algorithm,[0],[0]
Assumption 8 (Strong convexity of Fi).,5. Robust One-round Algorithm,[0],[0]
"With probability 1, the empirical risk minimization function Fi(·) on each normal machine is strongly convex.
",5. Robust One-round Algorithm,[0],[0]
"Note that this assumption is imposed on Fi(w), rather than on the individual loss f(w; z) associated with a single data point.",5. Robust One-round Algorithm,[0],[0]
"This assumption is satisfied, for example, when all f(·; z)’s are strongly convex, or in the linear regression problems with the features x drawn from some continuous distribution (e.g. isotropic Gaussian) and n",5. Robust One-round Algorithm,[0],[0]
≥ d.,5. Robust One-round Algorithm,[0],[0]
"We have the following guarantee for the robust one-round algorithm.
",5. Robust One-round Algorithm,[0],[0]
Theorem 7.,5. Robust One-round Algorithm,[0],[0]
"Suppose that ∀ z ∈ Z , the loss function f(·; z) is convex and quadratic, F (·) is λF -strongly convex, and Assumption 8 holds.",5. Robust One-round Algorithm,[0],[0]
"Assume that α satisfies
α+
√ log(nmd)
2m(1− α) +",5. Robust One-round Algorithm,[0],[0]
C̃√ n ≤,5. Robust One-round Algorithm,[0],[0]
"1 2 −
for some > 0, where C̃ is a quantity that depends on DH , Dp, λF and is monotonically decreasing in n. Then, with probability at least 1− 4nm , the output ŵ of the robust one-round algorithm satisfies
‖ŵ",5. Robust One-round Algorithm,[0],[0]
−w∗‖2 ≤,5. Robust One-round Algorithm,[0],[0]
C,5. Robust One-round Algorithm,[0],[0]
"√ n σ̃ ( α+
√ log(nmd)
2m(1− α) + C̃√ n
) ,
where C is defined as in (4) and σ̃2 := E",5. Robust One-round Algorithm,[0],[0]
[ ‖H−1F ( (H−HF )H−1F pF − (p− pF ) ),5. Robust One-round Algorithm,[0],[0]
"‖22 ] ,
with H and p drawn from DH and Dp, respectively.",5. Robust One-round Algorithm,[0],[0]
"We prove Theorem 7 and provide an explicit expression of C̃ in Appendix F. In terms of the dependence on α, n, and m, the robust one-round algorithm achieves the same error rate as the robust gradient descent algorithm based on coordinate-wise median, i.e., Õ( α√
n + 1√ nm + 1n ), for
quadratic problems.",5. Robust One-round Algorithm,[0],[0]
"Again, this rate is optimal when n & m. Therefore, at least for quadratic loss functions, the robust one-round algorithm has similar theoretical performance as the robust gradient descent algorithm with significantly less communication cost.",5. Robust One-round Algorithm,[0],[0]
Our experiments show that the one-round algorithm has good empirical performance for other losses as well.,5. Robust One-round Algorithm,[0],[0]
"In this section, we provide a lower bound on the error rate for strongly convex losses, which implies that the α√
n + 1√ nm
term is unimprovable.",6. Lower Bound,[0],[0]
"This lower bound is derived using a mean estimation problem, and is an extension of the lower bounds in the robust mean estimation literature such as Chen et al. (2015); Lai et al. (2016).
",6. Lower Bound,[0],[0]
"We consider the problem of estimating the mean µ of some random variable z ∼ D, which is equivalent to solving the following minimization problem:
µ = arg min w∈W
Ez∼D[‖w",6. Lower Bound,[0],[0]
"− z‖22], (6)
Note that this is a special case of the general learning problem (1).",6. Lower Bound,[0],[0]
"We consider the same distributed setting as in Section 4, with a minor technical difference regarding the Byzantine machines.",6. Lower Bound,[0],[0]
"We assume that each of the m worker machines is Byzantine with probability α, independently of each other.",6. Lower Bound,[0],[0]
The parameter α is therefore the expected fraction of Byzantine machines.,6. Lower Bound,[0],[0]
In this setting we have the lower bound in Observation 1.,6. Lower Bound,[0],[0]
"In Appendix G, we also discuss how we can translate this average-case bound to a lower bound holds under the setting of our main theorems, that is, an unknown set of αm Byzantine machines are selected without any assumption.
",6. Lower Bound,[0],[0]
Observation 1.,6. Lower Bound,[0],[0]
"Consider the distributed mean estimation problem in (6) with Byzantine failure probability α, and suppose that Z is Gaussian distribution with mean µ and covariance matrix σ2I (σ = O(1)).",6. Lower Bound,[0],[0]
"Then, any algorithm
that computes an estimation µ̂ of the mean from the data has a constant probability of error ‖µ̂−µ‖2 = Ω( α√n + √ d nm ).
",6. Lower Bound,[0],[0]
We prove Observation 1 in Appendix G.,6. Lower Bound,[0],[0]
"According to this observation, we see that the α√
n + 1√ nm dependence cannot
be avoided, which in turn implies the order-optimality of the results in Theorem 1 (when n & m) and Theorem 4.",6. Lower Bound,[0],[0]
We conduct experiments to show the effectiveness of the median and trimmed mean operations.,7. Experiments,[0],[0]
"Our experiments are implemented with Tensorflow (Abadi et al., 2016) on Microsoft Azure system.",7. Experiments,[0],[0]
"We use the MNIST (LeCun et al., 1998) dataset and randomly partition the 60,000 training data into m subsamples with equal sizes.",7. Experiments,[0],[0]
"We use these subsamples to represent the data on m machines.
",7. Experiments,[0],[0]
"In the first experiment, we compare the performance of distributed gradient descent algorithms in the following 4 settings: 1) α = 0",7. Experiments,[0],[0]
"(no Byzantine machines), using vanilla distributed gradient descent (aggregating the gradients by taking the mean), 2) α > 0, using vanilla distributed gradient descent, 3) α > 0, using median-based algorithm, and 4) α > 0, using trimmed-mean-based algorithm.",7. Experiments,[0],[0]
"We generate the Byzantine machines in the following way: we replace every training label y on these machines with 9−y, e.g., 0 is replaced with 9, 1 is replaced with 8, etc, and the Byzantine machines simply compute gradients based on these data.",7. Experiments,[0],[0]
"We also note that when generating the Byzantine machines, we do not simply add extreme values in the features or gradients; instead, the Byzantine machines send messages to the master machine with moderate values.
",7. Experiments,[0],[0]
"We train a multi-class logistic regression model and a convolutional neural network (CNN) using distributed gradient descent, and for each model, we compare the test accuracies in the aforementioned 4 settings.",7. Experiments,[0],[0]
"For the convolutional neural network model, we use the stochastic version of the distributed gradient descent algorithm; more specifically, in every iteration, each worker machine computes the gradient using 10% of its local data.",7. Experiments,[0],[0]
"We plot the test error as a function of the number of parallel iterations (i.e., communication rounds) in Figure 1.",7. Experiments,[0],[0]
"The final test accuracies are presented in Tables 2 and 3.
",7. Experiments,[0],[0]
"As we can see, in the adversarial settings, the vanilla distributed gradient descent algorithm suffers from severe performance loss, and using the median and trimmed mean operations, we observe significant improvement in test accuracy.",7. Experiments,[0],[0]
"This shows these two operations indeed have strong ability in defense against Byzantine failures.
",7. Experiments,[0],[0]
"In the second experiment, we compare the performance of distributed one-round algorithms in the following 3 settings: 1) α = 0, mean aggregation, 2) α > 0, mean aggregation, and 3) α > 0, median aggregation.",7. Experiments,[0],[0]
"To show that our algorithm is able to defend against different types of adversarial behavior, we generate the Byzantine machines differently from the first experiment—the training labels are i.i.d. uniformly sampled from {0, . . .",7. Experiments,[0],[0]
", 9}, and these machines train models using the faulty data.",7. Experiments,[0],[0]
"We choose the multi-class logistic regression model, and the test accuracies are presented in Table 4.
",7. Experiments,[0],[0]
"As we can see, for the one-round algorithm, although the theoretical guarantee is only proved for quadratic loss, in practice, the median-based one-round algorithm still improves the test accuracy in problems with other loss functions, such as the logistic loss here.",7. Experiments,[0],[0]
"We gratefully acknowledge the support of the NSF through grant IIS-1619362, CIF award 1703678, CRII award 1657420 and grant 1704828.",Acknowledgements,[0],[0]
We also acknowledge the support of Berkeley DeepDrive Industry Consortium and Gift award from Huawei.,Acknowledgements,[0],[0]
Cloud computing resources are provided by a Microsoft Azure for Research award.,Acknowledgements,[0],[0]
"In this paper, we develop distributed optimization algorithms that are provably robust against Byzantine failures—arbitrary and potentially adversarial behavior, in distributed computing systems, with a focus on achieving optimal statistical performance.",abstractText,[0],[0]
"A main result of this work is a sharp analysis of two robust distributed gradient descent algorithms based on median and trimmed mean operations, respectively.",abstractText,[0],[0]
"We prove statistical error rates for all of strongly convex, nonstrongly convex, and smooth non-convex population loss functions.",abstractText,[0],[0]
"In particular, these algorithms are shown to achieve order-optimal statistical error rates for strongly convex losses.",abstractText,[0],[0]
"To achieve better communication efficiency, we further propose a median-based distributed algorithm that is provably robust, and uses only one communication round.",abstractText,[0],[0]
"For strongly convex quadratic loss, we show that this algorithm achieves the same optimal error rate as the robust distributed gradient descent algorithms.",abstractText,[0],[0]
Byzantine-Robust Distributed Learning: Towards Optimal Statistical Rates,title,[0],[0]
"Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 846–856, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.",text,[0],[0]
"With the advent of large knowledge bases (KB) like DBpedia, YAGO, Freebase, and others, entities (people, places, organizations, etc.)",1 Introduction,[0],[0]
"along with their attributes and relationships form the basis of smart applications like search, analytics, recommendations, question answering, and more.",1 Introduction,[0],[0]
"The major task that arises in both the KB construction process and the entity-centric applications involves precise recognition, resolution, and linking of named entities distributed across web pages, news articles, and social media.
",1 Introduction,[0],[0]
"Named Entity Recognition (NER) deals with the identification of entity mentions in a text and their classification into coarse-grained semantic types (person, location, etc.)",1 Introduction,[0],[0]
"(Finkel et al., 2005; Nadeau
& Sekine, 2007; Ratinov & Roth, 2009).",1 Introduction,[0],[0]
"This involves segmentation of token sequences to obtain mention boundaries, and mapping relevant token spans to pre-defined entity categories.",1 Introduction,[0],[0]
"For example, NER on the text Einstein won the Nobel Prize identifies the mentions “Einstein” and “Nobel Prize” and marks them as person and misc type, respectively.
",1 Introduction,[0],[0]
"Named Entity Linking (NEL)1 involves the disambiguation of textual mentions, based on context and semantic information, and their mapping to proper entities in a KB (Bunescu & Paşca, 2006; Cucerzan, 2007; Milne & Witten, 2008; Hoffart et al., 2011; Ratinov et al., 2011; Cornolti et al., 2013).",1 Introduction,[0],[0]
"For example, in the above text, the mention “Einstein” is linked to the physicist Albert Einstein.
",1 Introduction,[0],[0]
"Entity Co-reference Resolution (CR) (Haghighi & Klein, 2010; Ng, 2010; Lee et al., 2013) is essentially a clustering task to identify mentions (and anaphoras) within a document referring to the same entity, thus computing equivalence classes or mention groups.",1 Introduction,[0],[0]
"For example, mentions Albert Einstein and Nobel laureate Einstein both refer to the same entity German physicist Albert Einstein, but are different from the mention Hans Albert Einstein.
",1 Introduction,[0],[0]
"When CR is extended to an entire text corpus, in order to generate equivalence classes of co-referring mentions across documents, the task is known as Cross-document Co-reference Resolution (CCR) (Bagga & Baldwin, 1998; Culotta et al., 2007; Singh et al., 2011; Dutta & Weikum, 2015).",1 Introduction,[0],[0]
Note that CCR is not the same as merely concatenating all documents in the corpus and utilizing existing CR methods.,1 Introduction,[0],[0]
The linguistic diversity across documents and high computational cost for huge numbers of mentions in the corpus would typically make such a CR-based simulation perform poorly.,1 Introduction,[0],[0]
Neither CR nor CCR links mention groups to corresponding KB entities.,1 Introduction,[0],[0]
"Thus, they represent both in-KB entities and out-of-KB entities (e.g., long-tail or emerging entities that do not have a Wikipedia article) in the same way.
",1 Introduction,[0],[0]
1Named Entity Disambiguation (NED) and “Wikification” are often used to denote the same task.,1 Introduction,[0],[0]
"The latter may be more broadly used, though, to include the disambiguation of common nouns and phrases onto concepts, whereas NED restricts itself to noun phrases that denote individual entities.
846
State-of-the-Art and its Limitations:",1 Introduction,[0],[0]
"Established CR methods rely on rule-based methods or supervised learning techniques on syntactic paths between mentions, semantic compatibility, and other linguistic features (Haghighi & Klein, 2009), with additional use of distant features from KBs (Lee et al., 2013).",1 Introduction,[0],[0]
"Modern cluster-ranking (Rahman & Ng, 2011) and multi-sieve methods (Ratinov & Roth, 2012) involve incremental expansion of mention groups by considering semantic types and Wikipedia categories.",1 Introduction,[0],[0]
"CCR methods utilize transitivity-aware clustering techniques (Singh et al., 2011), by considering mention-mention similarities (Bagga & Baldwin, 1998) along with features extracted from external KBs (Dutta & Weikum, 2015).
",1 Introduction,[0],[0]
"NEL methods often harness the semantic similarity between mentions and entities and also among candidate entities for different mentions (in Wikipedia or other KBs) for contextualization and coherence disambiguation (Hoffart et al., 2011; Milne & Witten, 2008; Kulkarni et al., 2009; Ratinov et al., 2011).",1 Introduction,[0],[0]
"However, in the absence of CR mention groups, NEL has limited context and is bound to miss out on certain kinds of difficult cases.
",1 Introduction,[0],[0]
"Although NER, CR, CCR and NEL involve closely related tasks and their tighter integration has been shown to be promising (Chen & Roth, 2013; Zheng et al., 2013), they have mostly been explored in isolation.",1 Introduction,[0],[0]
"Recently, several joint models have been proposed for CR-NER (Haghighi & Klein, 2010; Singh et al., 2013), CR-NEL (Hajishirzi et al., 2013), and NER-CR-NEL (Durrett & Klein, 2014).",1 Introduction,[0],[0]
"However, to the best of our knowledge, no method exists for jointly handling CCR and NEL on large text corpora.",1 Introduction,[0],[0]
This paper proposes the novel C3EL (CrossdoCument Co-reference resolution and Entity Linking) framework for jointly modeling crossdocument co-reference resolution (CCR) and linkage of mention groups to entities in a knowledge base (NEL).,1.1 Approach and Contributions,[0],[0]
"Example: To illustrate the potential synergies between CCR and NEL, consider the 3 documents in Figure 1 containing 9 mentions (on the left) with candidate entities from a KB (on the right).",1.1 Approach and Contributions,[0],[0]
"CCR alone would likely miss the coreference relation between Logan (Doc 1) and its alias Wolverine (Doc 2), leaving NEL with the difficult task of disambiguating “Logan” in a document with sparse and highly ambiguous context (Doc 1).",1.1 Approach and Contributions,[0],[0]
"On the other hand, NEL alone would likely map Australia (Doc 3) to the country (not the movie) and could easily choose the wrong link for mention “Hugh”.",1.1 Approach and Contributions,[0],[0]
"Moreover, the presence of Ava Eliot as an out-of-KB mention complicates the task.
",1.1 Approach and Contributions,[0],[0]
"However, if we could more freely interleave
CCR and NEL and could iterate them several times, we would be in a much stronger position.",1.1 Approach and Contributions,[0],[0]
"An initial NEL step for the easiest mention, namely “Wolverine”, maps it to the character of X-Men movies.",1.1 Approach and Contributions,[0],[0]
"This indicates that the three “Hugh” mentions could all be the same actor, and are thus easily merged into a co-reference group using CCR.",1.1 Approach and Contributions,[0],[0]
"We now have enough cues for NEL to choose the right entity for the “Hugh” mention group, which in turn enables the proper mapping of “Australia” to the movie.",1.1 Approach and Contributions,[0],[0]
"Finally, it becomes clear that mentions “Ava Eliot” and “his daughter Ava” should be merged into the same group and represented as an out-of-KB entity mapped to null.
",1.1 Approach and Contributions,[0],[0]
The above example clearly demonstrates that interleaving CCR and NEL is highly beneficial.,1.1 Approach and Contributions,[0],[0]
"However, appropriate choices for the ordering of CCR and NEL steps are usually not obvious at all.",1.1 Approach and Contributions,[0],[0]
The proposed C3EL algorithm solves this problem: automatically determining an efficient interleaving of CCR and NEL.,1.1 Approach and Contributions,[0],[0]
Approach:,1.1 Approach and Contributions,[0],[0]
"C3EL iteratively aggregates intermediate information obtained from alternating steps of CCR and NEL, thus forming a feedback loop for propagating mention features and entity knowledge.",1.1 Approach and Contributions,[0],[0]
"Intuitively, co-referring mentions obtained via CCR generate global context for improved NEL performance, while mentions linked to KB entities (by NEL) provide distant semantic features with additional cues for CCR.",1.1 Approach and Contributions,[0],[0]
"C3EL couples several building blocks like unsupervised hierarchical clustering, context summaries for mentions and distant KB features for entities, drawing inspiration from the CCR-only method of (Dutta & Weikum, 2015).",1.1 Approach and Contributions,[0],[0]
"Mention linking to the KB (NEL) is performed using distant knowledge and co-occurring mentions.
",1.1 Approach and Contributions,[0],[0]
"In a nutshell, the major contributions of this paper are: • the C3EL framework for joint computation of
cross-document co-reference resolution (CCR) and entity linking to a KB (NEL), based on propagating information across iterative CCR and NEL steps; • techniques for considering co-occurring men-
tions in context summaries and for harnessing
context-based keywords for link validation in NEL, improving accuracy on out-of-KB entities; • an experimental evaluation with two different
corpora, one based on news articles and one based on web pages, demonstrating substantial gains for both CCR and NEL over state-of-theart methods.
",1.1 Approach and Contributions,[0],[0]
"2 C3EL: Joint CCR-NEL Framework
Given an input corpus C of n documents, C = {D1, D2, · · · , Dn} with entity mentions EM = {m11,m12, · · · ,m21,m22, · · · } (mij ∈ Di), C3EL aims to jointly compute:
• CCR: an equivalence relation over EM with equivalence classesEi, such thatEi ∩i 6=j Ej = ∅ and ∪i Ei = EM , and • NEL: linking each of the classes Ei to entities
present in a KB or map it to null if there is no proper entity in the KB.
",1.1 Approach and Contributions,[0],[0]
"To this end, C3EL consists of 3 algorithmic stages: (i)",1.1 Approach and Contributions,[0],[0]
"Pre-Processing, (ii) Interleaved NEL and CCR, and (iii) Finalization.",1.1 Approach and Contributions,[0],[0]
HTML pages in the input corpusC are transformed into plain text using standard tools like jsoup. org.,2.1 Pre-Processing Stage,[0],[0]
"Recognition and markup of mentions are performed using the Stanford CoreNLP toolkit (nlp. stanford.edu), and a coarse-grained lexical type for each mention (e.g., person, location, organization, etc.) is obtained from the Stanford NER Tagger (Finkel et al., 2005).",2.1 Pre-Processing Stage,[0],[0]
"The multi-pass sieve algorithm for single-document CR (Raghunathan et al., 2010; Lee et al., 2011; Lee et al., 2013) then computes mention co-reference chains per document, and a head mention is chosen for each of the mention groups (chains).",2.1 Pre-Processing Stage,[0],[0]
"The head mention is typically represented by the most explicit denotation of the entity (e.g., person’s full name with title, location name with country, etc.).
",2.1 Pre-Processing Stage,[0],[0]
"For each of the mention groups Mi, C3EL then constructs a context summary using:
• Sentences – all sentences in the document that contain mentions of group Mi; and • Co-occurrence – all sentences for other men-
tion groups that contain mentions co-occurring in any of the sentences of Mi (as obtained above).
",2.1 Pre-Processing Stage,[0],[0]
"Formally, for each mention groupMi, let S(Mi)",2.1 Pre-Processing Stage,[0],[0]
"= {sentence(mj) |mj ∈ Mi} represent the set of extracted sentences, where sentence(mj) denotes the sentences in which mention mj occurs.",2.1 Pre-Processing Stage,[0],[0]
"Also, let the co-occurring mention set of Mi be Co(Mi) = {m′ |m′ ∈ S(Mi)",2.1 Pre-Processing Stage,[0],[0]
∧ m′ /∈,2.1 Pre-Processing Stage,[0],[0]
Mi}.,2.1 Pre-Processing Stage,[0],[0]
"The
context summary of Mi is defined as:
CS(Mi) = S(Mi) ∪  ⋃
m′∈Co(Mi) S(m′)  ",2.1 Pre-Processing Stage,[0],[0]
The context summaries intentionally do not include any distant KB features for mentions.,2.1 Pre-Processing Stage,[0],[0]
The intuition is to minimize potential noise from overly speculative mappings to the KB at this initial stage.,2.1 Pre-Processing Stage,[0],[0]
"After the preliminary CR step on each document and the construction of context summaries, C3EL now performs an initial NEL step for each of the mention groups Mi, using the extracted sentences S(Mi) as inputs to NEL.",2.2 Interleaved NEL & CCR Approach,[0],[0]
"It obtains the best matching entity, the confidence of the match, and its corresponding Wikipedia page.",2.2 Interleaved NEL & CCR Approach,[0],[0]
"Off-the-shelf NEL software (like WikipediaMiner or Illinois-Wikifier) is used for mention-entity mapping based on prior popularity of the named-entities (from the KB) and textual similarity between S(Mi) (context of the mention group) and the entity descriptions in KB.
",2.2 Interleaved NEL & CCR Approach,[0],[0]
"For each Mi, the entity link obtained (from NEL) is then “validated” using a similarity measure between features from the context summary, CS(Mi) (including co-occurring mentions) and distant KB labels – forming the link validation procedure of C3EL.",2.2 Interleaved NEL & CCR Approach,[0],[0]
This explicit use of co-occurring mentions’ (Co(Mi)) contexts helps to better identify out-of-KB entities compared to direct fullfledged NEL using the entire input text (shown in Section 3).,2.2 Interleaved NEL & CCR Approach,[0],[0]
"Also the use of NEL on S(Mi) alone, makes C3EL “light-weighted”.
",2.2 Interleaved NEL & CCR Approach,[0],[0]
"The mappings between the mention groups and KB entries are then classified, on the basis of the NEL confidence scores, into Strong Evidence (SE), Weak Evidence (WE), and No Evidence (NE) classes.",2.2 Interleaved NEL & CCR Approach,[0],[0]
"For mention groups placed in SE, the KB features (obtained previously) are appended to their context summaries, while mentions strongly linked to same KB entities are considered to be coreferring and hence grouped together (performing implicit CCR).
",2.2 Interleaved NEL & CCR Approach,[0],[0]
"Considering our example (Figure 1), we now outline the iterative steps of C3EL interleaving NEL & CCR. 1.",2.2 Interleaved NEL & CCR Approach,[0],[0]
"During Iteration 1, C3EL performs: • NEL:",2.2 Interleaved NEL & CCR Approach,[0],[0]
"The initial NEL step maps the unam-
biguous mentions, Wolverine to the X-Men movie character and Australia to the country, with high confidence.",2.2 Interleaved NEL & CCR Approach,[0],[0]
"However, link validation fails for “Australia” as there is very low similarity between the mention context features (e.g., Hugh, Wolverine, etc.) and the distant KB labels extracted from its Wikipedia page (e.g., Commonwealth, population, etc.); thus the link is dropped and the mention is added to NE.",2.2 Interleaved NEL & CCR Approach,[0],[0]
"So only the mention “Wolverine” is added to the
SE class and enriched with KB features (e.g., alias Logan).",2.2 Interleaved NEL & CCR Approach,[0],[0]
"On the other hand, the 3 “Hugh” mentions exhibit low NEL confidence due to the high ambiguity of this first name and are therefore classified into WE.",2.2 Interleaved NEL & CCR Approach,[0],[0]
The remaining mentions have extremely low NEL confidence (due to sparse contextual information) and are added to NE.,2.2 Interleaved NEL & CCR Approach,[0],[0]
•,2.2 Interleaved NEL & CCR Approach,[0],[0]
"CCR: The WE and NE classes are fed sep-
arately to the CCR procedure.",2.2 Interleaved NEL & CCR Approach,[0],[0]
"Based on the context summary similarities between mentions, C3EL performs hierarchical clustering to group together the “Hugh” mentions (in the WE class) and creates a co-referring mention group with the individual mentions’ context summaries concatenated.",2.2 Interleaved NEL & CCR Approach,[0],[0]
"This merging of summaries grows and strengthens captured contexts, which propagates across documents.",2.2 Interleaved NEL & CCR Approach,[0],[0]
"This concludes the first iteration of C3EL.
2.",2.2 Interleaved NEL & CCR Approach,[0],[0]
The above results are provided to the second Iteration: • NEL:,2.2 Interleaved NEL & CCR Approach,[0],[0]
"The context summary of the “Hugh”
mention group in WE now provides definitive cues to correctly map it to the actor Hugh Jackman with high confidence, thus placing it in the SE class.",2.2 Interleaved NEL & CCR Approach,[0],[0]
•,2.2 Interleaved NEL & CCR Approach,[0],[0]
"CCR: The ensuing CCR step groups together
“Ava Eliot” and “Ava” (in NE) using cooccurrence context of the co-referring Hugh mentions.
",2.2 Interleaved NEL & CCR Approach,[0],[0]
3.,2.2 Interleaved NEL & CCR Approach,[0],[0]
Subsequent NEL iterations (on WE and NE) identify “Ava” as an out-of-KB entity and correctly links “Australia” to the movie using CCRgenerated mention-group contexts and link validation.,2.2 Interleaved NEL & CCR Approach,[0],[0]
CCR finally groups together “Logan” with “Wolverine” based on context similarity with distant KB features.,2.2 Interleaved NEL & CCR Approach,[0],[0]
"This process of alternating CCR and NEL is repeated until all mention groups are strongly connected to KB entities (placed in SE), or no changes are made anymore.
",2.2 Interleaved NEL & CCR Approach,[0],[0]
"The NEL and CCR procedures are performed separately on the different mention types (like PER, LOC, etc.), since different mention types rarely co-refer.",2.2 Interleaved NEL & CCR Approach,[0],[0]
We next present the internal working details of the NEL and CCR stages of C3EL.,2.2 Interleaved NEL & CCR Approach,[0],[0]
"In its NEL procedure, C3EL disambiguates mentions to entities in the YAGO knowledge base (yago-knowledge.org).",2.2.1 Named-Entity Linking (NEL) Stage,[0],[0]
"We perform NEL on the sentences (S(Mi)) of a mention group, using named-entity popularity statistics and context, to obtain the best matching entity, its confidence score, and the corresponding Wikipedia page (from sameAs link in YAGO).",2.2.1 Named-Entity Linking (NEL) Stage,[0],[0]
"Assume a mention group Mi to be mapped to an entity ei with a confidence score of φ(Mi, ei).",2.2.1 Named-Entity Linking (NEL) Stage,[0],[0]
A. Link Validation:,2.2.1 Named-Entity Linking (NEL) Stage,[0],[0]
"For each mention group (e.g., Hugh), we extract distant KB labels such as se-
mantic types or categories (e.g., actor), title (e.g., Golden Globe winner), alias (e.g., Wolverine), location, and gender (for person) from the Wikipedia page infoboxes.",2.2.1 Named-Entity Linking (NEL) Stage,[0],[0]
The similarity of these features to keywords obtained from the context summary CS(Mi) is computed using IR-style term frequencies within a document (tf) and inverse document frequencies within the corpus (idf).,2.2.1 Named-Entity Linking (NEL) Stage,[0],[0]
We utilize the bag-of-words model based tf × idf -weighted cosine similarity measure.,2.2.1 Named-Entity Linking (NEL) Stage,[0],[0]
"If the similarity score is above a threshold, τ , the NEL result is accepted, otherwise it is discarded – thus avoiding noisy linkage of sparse mentions to prominent KB entries.",2.2.1 Named-Entity Linking (NEL) Stage,[0],[0]
This subtle introduction of controlled distant supervision within the C3EL framework enables efficient detection of out-of-KB mentions.,2.2.1 Named-Entity Linking (NEL) Stage,[0],[0]
"B. Classification: To sift out well-known and long-tail entities from new ones, and prevent “noisy” interactions among the contexts of inKB and out-of-KB mentions (with similar surface forms), mention groups Mi (linked to ei with score φ(Mi, ei)) are classified into 3 classes by 2 threshold parameters, δs and δw, as: • Strong Evidence (SE): For φ(Mi, ei) ≥ δs,
mention group Mi exhibits high linkage confidence with ei and is placed in SE.",2.2.1 Named-Entity Linking (NEL) Stage,[0],[0]
"If two or more mentions in SE are independently mapped to the same KB entity, they co-refer transitively and are hence grouped together with their context summaries merged (implicit CCR).",2.2.1 Named-Entity Linking (NEL) Stage,[0],[0]
"Distant KB features for mentions in SE are extracted and appended to CS(Mi), providing additional cues for later steps.",2.2.1 Named-Entity Linking (NEL) Stage,[0],[0]
•,2.2.1 Named-Entity Linking (NEL) Stage,[0],[0]
"Weak Evidence (WE): Mention groups with δw ≤ φ(Mi, ei) < δs are placed in this class.",2.2.1 Named-Entity Linking (NEL) Stage,[0],[0]
They mostly represent long-tail in-KB entities (sparsely represented in KB) with limited semantic information (for detection) but might also be new/emerging entities absent from KB.,2.2.1 Named-Entity Linking (NEL) Stage,[0],[0]
"• No Evidence (NE): φ(Mi, ei) < δw represents
mentions groups that have been mapped to null (or have near-zero match confidence) or have failed link validation during the NEL procedure.",2.2.1 Named-Entity Linking (NEL) Stage,[0],[0]
These entities are most likely to be outof-KB and are allocated to this class.,2.2.1 Named-Entity Linking (NEL) Stage,[0],[0]
"The CCR stage of C3EL adopts the samplingbased hierarchical clustering approach of (Dutta & Weikum, 2015), to obtain co-referring mention clusters.",2.2.2 Cross-Document CR (CCR) Stage,[0],[0]
"A. Similarity Measure: To infer whether two mention groups represent the same entity, the similarity between the context summaries are computed based on (i) tf-idf -weighted bag-of-words cosine distance, and (ii) partial-match scores of multiword keyphrases in bounded text windows (Taneva et al., 2011).",2.2.2 Cross-Document CR (CCR) Stage,[0],[0]
"The context summaries (with stopwords removed) are re-interpreted as, (i) bag of words, and (ii) bag of keyphrases, to extract fea-
ture vectors for similarity computation.",2.2.2 Cross-Document CR (CCR) Stage,[0],[0]
"Finally, the mixture model of bag-of-words (BoW) and keyphrases (KP) of (Dutta & Weikum, 2015) is used to assign feature weights using tf-idf measure.",2.2.2 Cross-Document CR (CCR) Stage,[0],[0]
B. Hierarchical Clustering: s mention groups are uniformly randomly sampled and their similarities to the other groups (using context summary) are computed.,2.2.2 Cross-Document CR (CCR) Stage,[0],[0]
A similarity-weighted graph with the mention groups as nodes and edge weights representing mention-mention similarities is constructed.,2.2.2 Cross-Document CR (CCR) Stage,[0],[0]
"Bisection-based hierarchical balanced min-edge-cut graph partitioning (Buluc et al., 2013) is performed, using the METIS software (Karypis & Kumar, 1999)2, to partition noncoreferent mentions groups.",2.2.2 Cross-Document CR (CCR) Stage,[0],[0]
"The Bayesian Information Criterion (BIC) (Schwarz, 1978; Hourdakis et al., 2010), a Bayesian variant of Minimum Description Length (Grünwald, 2007), is used as the cluster split stopping criterion, and the context summaries within each final cluster are merged.
",2.2.2 Cross-Document CR (CCR) Stage,[0],[0]
"CCR aims to process heterogeneous corpora that go beyond a single domain and style, such as Web collections.",2.2.2 Cross-Document CR (CCR) Stage,[0],[0]
"For the remaining mention groups in WE, we finally perform threshold based disambiguation of mention clusters using the context summaries.",2.3 Finalization Stage,[0],[0]
"For each mention groupMi ∈WE, we compute (1) its context summary similarities (as in Section 2.2.2) to all other mention groups",2.3 Finalization Stage,[0],[0]
"Mj in SE by also using distance features from the weakly linked KB entities, and (2) textual overlap between the mention group representatives.",2.3 Finalization Stage,[0],[0]
Mi is concatenated with the best matching entity Mk (in SE) if the similarity score is above a threshold θ; else Mi is marked as an out-of-KB entity (mapped to null) and is placed in theNE class.,2.3 Finalization Stage,[0],[0]
"This helps in reducing propagated CR errors like erroneous mention boundary detection (in NER), omissions in co-reference chain, etc.",2.3 Finalization Stage,[0],[0]
"(leading to “phantom” out-of-KB entities).
",2.3 Finalization Stage,[0],[0]
The obtained mention groups represent the final equivalence classes of co-referring mentions across documents – capturing both in-KB entities (with links to the KB) in the SE class and out-of-KB entities (mapped to null) in the NE class.,2.3 Finalization Stage,[0],[0]
"In this section, we empirically study the performance of C3EL against various state-of-the-art methods.",3 Experimental Evaluation,[0],[0]
We analyze the individual gains in CCR and NEL due to the joint modeling.,3 Experimental Evaluation,[0],[0]
"Datasets: We use the following 2 publicly available corpora:
• EventCorefBank (ECB) corpus3 (Bejan & Harabagiu, 2010): contains 482 news and Web articles (classified into 43 topics) with a total
2 glaros.dtc.umn.edu/gkhome/metis/metis/overview 3 faulty.washington.edu/bejan/data/ECB1.0.tar.gz
of 5447 mentions corresponding to 1068 distinct named-entities.",3 Experimental Evaluation,[0],[0]
"Entity co-reference annotations (across documents within each topic cluster) were provided by (Lee et al., 2012), and we performed manual examination of the annotations for KB linking of the entities to Wikipedia entries, if present; thus providing ground truth for both CCR and NEL.",3 Experimental Evaluation,[0],[0]
• ClueWeb2009,3 Experimental Evaluation,[0],[0]
"FACC1 dataset4 (Gabrilovich
et al., 2013): provides machine automated entity-linkage annotations of the ClueWeb09 corpus (ca.",3 Experimental Evaluation,[0],[0]
1 Billion crawled Web pages) with Freebase entries5.,3 Experimental Evaluation,[0],[0]
"The corpus contains many topical domains and highly diverse documents from news, movie reviews, people home pages to blogs and other social media posts.",3 Experimental Evaluation,[0],[0]
We randomly select 500K documents containing 4.64 Million mentions associated with 1.29 Million distinct entities to form our corpus.,3 Experimental Evaluation,[0],[0]
"For NEL ground-truth construction, we link the entities to their Wikipedia pages (using Freebase’s “on the web” property).",3 Experimental Evaluation,[0],[0]
"Since no explicit annotations of inter-document entity co-references exists, we consider two mentions (in different documents) to co-refer if they are linked with the same Freebase entity.
",3 Experimental Evaluation,[0],[0]
"Evaluation: To assess the output quality of C3EL we use the following established metrics: • B3 F1 score (Bagga & Baldwin, 1998): mea-
sures the F1 score as the harmonic mean of average precision and recall computed over all mention groups in the final equivalence classes.",3 Experimental Evaluation,[0],[0]
Precision (for a mention group) represents the ratio of the number of correctly reported coreferences (or linking) to the actual number; while recall computes the fraction of the goldstandard annotations correctly identified.,3 Experimental Evaluation,[0],[0]
"• φ3 − CEAF score (Luo, 2005): provides
an alternate F1 score computed as in the B3 measure; but calculates precision and recall of mention groups using the best 1-to-1 mapping (i.e., mapping with maximum mention overlap) between the resultant equivalence classes and those in the ground truth.",3 Experimental Evaluation,[0],[0]
"Normalization with the number of mentions for each of the resultant classes yields the φ4-CEAF score.
",3 Experimental Evaluation,[0],[0]
"We consider only the 3 most notable mention types: person (PER), location (LOC), and organization (ORG) – accounting for 99.7% of entities present in the ECB corpus and 96.3% of our ClueWeb09 corpus.",3 Experimental Evaluation,[0],[0]
All experiments were conducted on a 4 core Intel i5 2.50 GHz processor with 8GB RAM running Ubuntu 12.04 LTS.,3 Experimental Evaluation,[0],[0]
"Validation of entity linkage to KB and their subsequent classification into confidence classes (as de-
4 lemurproject.org/clueweb09/FACC1
5Human analysis of a subset of the annotations generated revealed a precision of 80− 85% (Gabrilovich et al., 2013)
scribed in Section 2) during the NEL step ofC3EL are based on 3 parameters: confidence thresholds (δs and δw) and validation threshold (τ ); the values of which can be tuned based on cross-validation approach with train and test data subsets.",3.1 Parameter Tuning & Sensitivity Study,[0],[0]
"Using the “gold annotations” of the train-set (30% of total data), parameter values providing the best precision score are individually learnt using line search with small step size.
",3.1 Parameter Tuning & Sensitivity Study,[0],[0]
"In our experimental setup, we systematically vary the parameter values and observe its effects on C3EL for the training data.",3.1 Parameter Tuning & Sensitivity Study,[0],[0]
"With increase in δs, the number of mentions mapped to the Strong Evidence (SE) class decreases.",3.1 Parameter Tuning & Sensitivity Study,[0],[0]
"This in turn limits the influx of external KB features, thus degrading CCR performance as observed in Table 1(a).",3.1 Parameter Tuning & Sensitivity Study,[0],[0]
"While for low values of δs, even weak mention links are placed in SE, leading to a decrease in precision due to noisy KB feature inclusion.",3.1 Parameter Tuning & Sensitivity Study,[0],[0]
"On the other hand, a high δw value increases the number of mentions in the NE class, while low values tends to accumulate mentions in the WE class.",3.1 Parameter Tuning & Sensitivity Study,[0],[0]
"This adversely affects the detection of out-of-KB entities due to noise from other co-occurring similar KB mentions (refer Table 1(b)) during clustering in CCR step.
",3.1 Parameter Tuning & Sensitivity Study,[0],[0]
The effect of τ on C3EL has be shown in Table 1(c).,3.1 Parameter Tuning & Sensitivity Study,[0],[0]
"Similar to the behavior induced by δs, we observe that a high τ limits entity linking and possible KB feature inclusion, while an extremely low value (near to zero) allows for noisy feature incorporation – both situations leading to lowered CCR efficiency.",3.1 Parameter Tuning & Sensitivity Study,[0],[0]
"However, since τ prevents gross mis-alignment of mentions to KB entities, a wide range of small value (0.1− 0.35) is seen to provide comparable performance.
",3.1 Parameter Tuning & Sensitivity Study,[0],[0]
"Hence, for our remaining experimental study we set δs = 0.11 and δw = 0.06",3.1 Parameter Tuning & Sensitivity Study,[0],[0]
"(as in (Hoffart et al., 2014)), while τ is set to 0.1, and threshold for the finalization stage θ = 2× δs = 0.22.",3.1 Parameter Tuning & Sensitivity Study,[0],[0]
"We initially benchmark the performance improvement in cross-document co-reference resolution (CCR) procedure by C3EL against two competing approaches: (1) state-of-the art sampling based hierarchical clustering method, CROCS (Dutta & Weikum, 2015); and (2) iterative joint entity-event CCR, EECR (Lee et al., 2012).
",3.2 CCR Performance Results,[0],[0]
Table 2 tabulates the results obtained on the ECB dataset.,3.2 CCR Performance Results,[0],[0]
"We observe C3EL to decisively outperform both the existing methods, providing a B3 F1 improvement of around 7% over CROCS and 17% over EECR.",3.2 CCR Performance Results,[0],[0]
"We further attain around 6% φ3−CEAF score enhancement over CROCS, and
a significant 20% improved φ4 − CEAF score compared to EECR.",3.2 CCR Performance Results,[0],[0]
"A. Gold Results: Errors introduced during the preprocessing stage of C3EL (e.g., mention omission, tag mis-classification, intra-document CR errors, etc., by the Stanford CoreNLP toolkit) propagate to subsequent computing stages and adversely impacts the overall system performance.",3.2 CCR Performance Results,[0],[0]
"To provide an unbiased viewpoint of the actual performance of C3EL, we manually provided “exact” mentions, mention tags, and intra-document CR mention chains for the ECB corpus; thereby obtaining gold performance results.",3.2 CCR Performance Results,[0],[0]
From Table 3 we observe a 6% F1 points improvement (for both B3 & CEAF-φ3) in C3EL compared to CROCS.,3.2 CCR Performance Results,[0],[0]
"B. Mention Categorization: Person mention type (PER) provides the greatest challenge for CCR systems (compared to other types like LOC, ORG, etc.)",3.2 CCR Performance Results,[0],[0]
"due to associated nicknames, titles, and varied surface forms (abbreviations, spellings, etc.).",3.2 CCR Performance Results,[0],[0]
"We thus evaluate the CCR performance of C3EL (and compare it with CROCS) on the ECB data, with “exact” input mentions, for the different mention categories.",3.2 CCR Performance Results,[0],[0]
"Table 4 validates that our joint modeling provides better global information cues, reporting a B3 F1 score enhancement of around 11% over CROCS for PER mentions; along with improved results for the other mention types as well.",3.2 CCR Performance Results,[0],[0]
"C. Large Data: To study the robustness of C3EL and the effects of large datasets on CCR, we performed evaluations on the ClueWeb09-FACC1 dataset.",3.2 CCR Performance Results,[0],[0]
"Similar to the ECB dataset, C3EL exhibits a B3 F1 score improvement of nearly 10% and a φ3-CEAF F1 improvement of 12% over CROCS (refer Table 5).
",3.2 CCR Performance Results,[0],[0]
The above experimental results showcase that a combined approach helps overcome challenges faced in CCR by entity linkage and corresponding distant KB feature extraction; improving the overall accuracy.,3.2 CCR Performance Results,[0],[0]
We now benchmark the performance of namedentity linking (NEL) procedure for C3EL against the state-of-the-art open-source AIDA software (github.com/yago-naga/aida).,3.3 Named-Entity Linking (NEL) Results,[0],[0]
"We separately inspect the precision of mention linking for prominent entities (in-KB) as well as new/emerging (out-of-KB) entities, and characterize the links as
Correct (C), Incorrect (I), or Unlinked (U).",3.3 Named-Entity Linking (NEL) Results,[0],[0]
The results on the ECB corpus are reported in Table 6.,3.3 Named-Entity Linking (NEL) Results,[0],[0]
C3EL attains comparable performance (∼ 85% precision) to that of AIDA for well-known entitymentions present in KB; albeit with a few mentions remaining unlinked due to our cautious link validation (using τ ) approach.,3.3 Named-Entity Linking (NEL) Results,[0],[0]
"However, the use of τ reduces aggressive KB linking to provide a significant 15% improvement (over AIDA) in precise detection of new/emerging entities absent in KB.",3.3 Named-Entity Linking (NEL) Results,[0],[0]
"Overall, an 1.5% precision gain is observed by the joint formulation.",3.3 Named-Entity Linking (NEL) Results,[0],[0]
A. Large Data:,3.3 Named-Entity Linking (NEL) Results,[0],[0]
The diverse nature of the webscale ClueWeb09 dataset clearly portrays the performance gains in NEL procedure due to CCR generated information integration.,3.3 Named-Entity Linking (NEL) Results,[0],[0]
"For entities present in the KB, we observe an accuracy improvement of 0.5% over AIDA (refer Table 7).",3.3 Named-Entity Linking (NEL) Results,[0],[0]
"Similar to that of the ECB data, C3EL attains a significant ∼ 14% improvement in the detection of new/emerging entities not represented in KB.",3.3 Named-Entity Linking (NEL) Results,[0],[0]
"For the 1 million mentions, C3EL provides around 4% overall performance improvements.
",3.3 Named-Entity Linking (NEL) Results,[0],[0]
"Using a bootstrap re-sampling t-test (as in (Durrett & Klein, 2014)), we observed high statistical significance (p < 0.01) for Out-of-KB and Overall NEL, whereas the difference for Within-KB NEL is not statistically significant.",3.3 Named-Entity Linking (NEL) Results,[0],[0]
"Coping with Out-ofKB entities is essential for joint CCR+NEL, and an improved NEL performance using propagated information from CCR using semantics along with link validation enables highly efficient detection of new or emerging entities.",3.3 Named-Entity Linking (NEL) Results,[0],[0]
"3.4 Comparison with Joint Models Traditional CR methods fail to cope with the heterogeneity of mentions and contexts across multiple documents, and some form of clustering or joint reasoning over all mentions is thus mandatory.",3.3 Named-Entity Linking (NEL) Results,[0],[0]
"These methods have quadratic or cubic (sometimes even exponential) complexity, and hence running CR+NEL on a concatenated super-document works only for small corpora, and would be prohibitively expensive for large corpora, even in offline processing mode (Singh et al., 2011).
",3.3 Named-Entity Linking (NEL) Results,[0],[0]
"However, to study the behavior of existing CRNEL joint models under “small” CCR environ-
ments, we compare C3EL with: (1) multi-sieve based NECo (Hajishirzi et al., 2013)6; and (2) conditional random field based BER (Durrett & Klein, 2014) 7.
",3.3 Named-Entity Linking (NEL) Results,[0],[0]
"Three topic clusters from the ECB corpus with 3, 4, and 5 articles respectively were selected, and the documents within each cluster were merged to form 3 “super-articles” (one per topic), forming a simulated CR setting.",3.3 Named-Entity Linking (NEL) Results,[0],[0]
"NECo and BER were then used to perform CR and NEL on these 3 articles, and the results compared with that obtained by C3EL on the original documents.",3.3 Named-Entity Linking (NEL) Results,[0],[0]
"We repeatedly sample 12 articles across 3 topic clusters, and execute the approaches to report the micro-averaged results across 5 independent runs.
",3.3 Named-Entity Linking (NEL) Results,[0],[0]
From Table 8(a),3.3 Named-Entity Linking (NEL) Results,[0],[0]
we observe that the algorithms exhibit comparable co-reference resolution performance; thus validating propagation of global semantics in C3EL due to the joint formulation.,3.3 Named-Entity Linking (NEL) Results,[0],[0]
"However, such CR methods using multi-sieves and CRF do not scale beyond few documents (upon concatenation), and require at least 4× more runtime compared to C3EL.",3.3 Named-Entity Linking (NEL) Results,[0],[0]
"Hence, CCR cannot be efficiently tackled by simply employing CR methods on a “super-document”.
",3.3 Named-Entity Linking (NEL) Results,[0],[0]
"However, harnessing of non-local mention features (via CCR) and efficient detection of new mentions using link validation enables C3EL to achieve a gain of around 5% in NEL compared to others (see Table 8(b)).",3.3 Named-Entity Linking (NEL) Results,[0],[0]
"For both procedures, we observed statistically significant improvements of C3EL over BER and NECo with p < 0.05, using the bootstrap re-sampling t-test.
",3.3 Named-Entity Linking (NEL) Results,[0],[0]
"To further study the effect of larger corpus, we sampled 25 documents (with co-referring mentions) from the ClueWeb09 dataset and performed analysis among the algorithms.",3.3 Named-Entity Linking (NEL) Results,[0],[0]
"As previously, we observed significant computational complexity for traditional CR methods when applied to CCR setting making them far slower (6− 7×) than C3EL.",3.3 Named-Entity Linking (NEL) Results,[0],[0]
Table 9 reports the CCR and NEL averaged results obtained across 5 independent runs.,3.3 Named-Entity Linking (NEL) Results,[0],[0]
We attained comparable performance in CCR with around 3% improvement in NEL.,3.3 Named-Entity Linking (NEL) Results,[0],[0]
"All the algorithms are seen to achieve high NEL results due to the large presence of well-known (in-KB) entities.
6 cs.washington.edu/research-projects/nlp/neco 7 nlp.cs.berkeley.edu/projects/entity.shtml",3.3 Named-Entity Linking (NEL) Results,[0],[0]
We explore the performance of variants of C3EL (on both corpora) ablating various system components (see Table 10).,3.5 Algorithmic Baseline Study,[0],[0]
"Explicitly, we consider:
• Co-occurring Mentions: Removal of cooccurrence mentions context from the context summaries constructed, reduces semantic information and adversely affects both NEL and CCR procedures.",3.5 Algorithmic Baseline Study,[0],[0]
We thus observe a sharp decrease in CCR performance and also a degradation in entity linking.,3.5 Algorithmic Baseline Study,[0],[0]
• Link Validation:,3.5 Algorithmic Baseline Study,[0],[0]
"Filtering of mention linking
to KB entities using link validation step (with threshold τ ) in C3EL enables corroboration of mention context keywords with the linked entity features.",3.5 Algorithmic Baseline Study,[0],[0]
This leads to enhanced detection of new or emerging entities by reducing induction of noise during the CCR phase.,3.5 Algorithmic Baseline Study,[0],[0]
"Removal of this process permits aggressive entity linking and introduces noise, affecting new/emerging entity detection.",3.5 Algorithmic Baseline Study,[0],[0]
We observe (from Table 10) nearly 20% reduction of precision (on both datasets) in identification of out-of-KB entitymentions compared to C3EL.,3.5 Algorithmic Baseline Study,[0],[0]
•,3.5 Algorithmic Baseline Study,[0],[0]
"NEL Categorization: The differentiation of
mentions (into classes) confidently mapped to KB entity reduces the collusion of “strong” linked mentions with other “noisy” mention contexts.",3.5 Algorithmic Baseline Study,[0],[0]
"This reduces incorrect grouping of different mentions with similar surface forms, contexts, etc., thereby improving precision of the CCR process.",3.5 Algorithmic Baseline Study,[0],[0]
"Use of a single NEL classification approach is observed to degrade CCR results, which in turn increases spurious entity linkage, decreasing NEL efficiency (Table 10).",3.5 Algorithmic Baseline Study,[0],[0]
"• Distant KB features: As observed in (Baker,
2012; Zheng et al., 2013), extracted external KB features provide global and enhanced information cues promoting CR.",3.5 Algorithmic Baseline Study,[0],[0]
We similarly observe CCR to attain the lowest F1 scores (compared to other baselines) when KB features are ignored.,3.5 Algorithmic Baseline Study,[0],[0]
"This in turn affects the linking of (some) well-known entities due to reduced context, leading to incorrect or low confidence NEL.",3.5 Algorithmic Baseline Study,[0],[0]
"Since no feature inclusion is performed for out-of-KB mentions, no effect is observed.
",3.5 Algorithmic Baseline Study,[0],[0]
"We observe that a joint formulation encompassing multiple information sources (along with noise filtering) enables mutually enhanced CCR and NEL within the proposed iterative feedback based framework, C3EL.",3.5 Algorithmic Baseline Study,[0],[0]
Co-reference Resolution (CR): Traditional intradocument CR methods involve syntactic and semantic feature combination for identifying the best antecedent (preceding name or phrase) for a mention.,4 Related Work,[0],[0]
"CR methods employ rules or supervised learning techniques based on linguistic features such as syntactic paths and mention distances to assess semantic compatibility (Haghighi & Klein, 2009; Raghunathan et al., 2010; Rahman & Ng, 2011), while syntactic features are derived by deep parsing of sentences and noun group parsing.",4 Related Work,[0],[0]
"Semantic features from background knowledge resources like encyclopedia were used in (Daumé & Marcu, 2005; Ponzetto & Strube, 2006; Ng, 2007).",4 Related Work,[0],[0]
"The use of Wikipedia and structured knowledge bases (such as YAGO) to obtain mention-type relation and fine-grained mention attributes was explored by (Haghighi & Klein, 2009; Rahman & Ng, 2011).",4 Related Work,[0],[0]
"An overview of CR methods is given in (Ng, 2010).
",4 Related Work,[0],[0]
"Recent methods involve the use of multi-phase sieve, applying a cascade of rules for narrowing down the antecedent candidates for a mention (Raghunathan et al., 2010).",4 Related Work,[0],[0]
"Cluster ranking functions have also been proposed (Rahman & Ng, 2011; Zheng et al., 2013) to extend this paradigm for incrementally expanding and merging mention groups with preceding candidate clusters using relatedness features (Ratinov & Roth, 2012) and distant knowledge inclusion (Durrett & Klein, 2013).",4 Related Work,[0],[0]
"Person name disambiguation, a specific variation of CR, dealing with only person names, titles, nicknames, and other surface form variations was introduced in (Chen & Martin, 2007).",4 Related Work,[0],[0]
"Distant Knowledge Labels: For obtaining semantic features, additional knowledge resources such as Wikipedia, YAGO, and FrameNet have been considered (Rahman & Ng, 2011; Baker, 2012).",4 Related Work,[0],[0]
"CR methods with confidence-thresholds were proposed in (Ratinov & Roth, 2012; Lee et al., 2013), and (Zheng et al., 2013) generalized these tech-
niques by ranking the matching entities for distant labeling.",4 Related Work,[0],[0]
"However, such prior methods utilize distance labels of the current mention and considers all matching mentions making the procedure expensive.",4 Related Work,[0],[0]
"On the other hand, we extract distant features for the strongly matching (best) candidate only, reducing the performance overhead.",4 Related Work,[0],[0]
"Cross-Document CR (CCR): Early approaches towards CCR involved the use contextual information from input documents for IR-style similarity measures (e.g., tf×idf score, KL divergence, etc.) over textual features (Bagga & Baldwin, 1998; Gooi & Allan, 2004).",4 Related Work,[0],[0]
"Probabilistic graphical models jointly learning the mappings of mentions to equivalent classes (co-referring mentions) using features similar to local CR techniques were studied in (Culotta et al., 2007; Singh et al., 2010; Singh et al., 2011), A clustering approach coupled with statistical learning of parameters was studied in (Baron & Freedman, 2008).",4 Related Work,[0],[0]
"However, such methods fail to cope with large corpora, and hence a “light-weight” streaming variant of CCR was introduced by (Rao et al., 2010).
",4 Related Work,[0],[0]
"Co-occurring mentions context have been harnessed for disambiguating person names for CR in (Mann & Yarowsky, 2003; Niu et al., 2004; Chen & Martin, 2007; Baron & Freedman, 2008).",4 Related Work,[0],[0]
"However, these methods do not use KB and depend on information extraction (IE) methods, witnessing substantial noise due to IE quality variance.",4 Related Work,[0],[0]
"A CCR framework combining co-occurring mention context with distant KB features embedded in an active hierarchical clustering procedure (Dutta & Weikum, 2015) was recently shown to perform efficiently, and provides inspiration for parts of our proposed C3EL approach.",4 Related Work,[0],[0]
"Named Entity Linking (NEL): Named entity resolution and linking stems from SemTag (Dill et al., 2003), and similar frameworks like GLOW, WikipediaMiner, AIDA, and others (Milne & Witten, 2008; Ratinov et al., 2011).",4 Related Work,[0],[0]
"A collection of entity disambiguation models was presented in (Kulkarni et al., 2009).",4 Related Work,[0],[0]
"Other NEL approaches utilize the notion of semantic similarity of entities to corresponding Wikipedia pages (Milne & Witten, 2008), while co-referent mention graph construction modeling mention co-occurrences and context similarity from outgoing hyperlinks in Wikipedia was used by (Hoffart et al., 2011).",4 Related Work,[0],[0]
"An integer linear programming (ILP) formulation also
based on Wikipedia page similarities was presented in (Ratinov et al., 2011).",4 Related Work,[0],[0]
"However, none of these methods involve the incorporation of CR results for NEL.",4 Related Work,[0],[0]
"The first study on the benefits of CR for NEL was by (Ratinov & Roth, 2012); but a joint model was not proposed, instead attributes from Wikipedia categories were used as features.",4 Related Work,[0],[0]
"An overview and evaluation of different NEL methods has been given by (Hachey et al., 2013).",4 Related Work,[0],[0]
"Joint Models: Jointly solving CR for entities and events utilizing cluster construction based on feature semantic dependencies was devised in (Lee et al., 2012).",4 Related Work,[0],[0]
"The use of CR as a pre-processing step for subsequent NEL procedure using an ILP formulation was proposed by (Chen & Roth, 2013).",4 Related Work,[0],[0]
"Recently, (Hajishirzi et al., 2013) proposed a joint model for CR and NEL using the Stanford multipass cluster update CR system with automatic linking of mentions to Wikipedia.",4 Related Work,[0],[0]
"An integrated belief propagation-based framework for CR, NER, and relation extraction was developed in (Singh et al., 2013).",4 Related Work,[0],[0]
"Subsequently, the model was enhanced by the use of structured conditional random fields, to solve CR, NER, and NEL in combination (Durrett & Klein, 2014).",4 Related Work,[0],[0]
"Other works involving joint formulation of NER and NEL use uncertainty of mention boundaries along with segmentation information extracted from Wikipedia (Sil & Yates, 2013).",4 Related Work,[0],[0]
"However, to the best of our knowledge, this work provides the first approach to jointly tackle CCR and NEL across documents in an entire corpus.",4 Related Work,[0],[0]
This paper presented the novel C3EL framework for joint computation of cross-document coreference resolution (CCR) and named-entity linking (NEL).,5 Conclusions,[0],[0]
"Our approach utilizes: (1) context summaries including co-occurring mention groups allowing for global context and feature propagation, and (2) link validation for NEL using distant KB features.",5 Conclusions,[0],[0]
This is embedded in an interleaved CCR and NEL model allowing for global semantics and feature propagation.,5 Conclusions,[0],[0]
The iterative approach enables information feedback between CCR (provides corpus-wide cues) and NEL (providing distant KB features).,5 Conclusions,[0],[0]
Experimental results on news and web data demonstrate improved performance of both CCR and NEL compared to prior methods.,5 Conclusions,[0],[0]
Cross-document co-reference resolution (CCR) computes equivalence classes over textual mentions denoting the same entity in a document corpus.,abstractText,[0],[0]
Named-entity linking (NEL) disambiguates mentions onto entities present in a knowledge base (KB) or maps them to null if not present in the KB.,abstractText,[0],[0]
"Traditionally, CCR and NEL have been addressed separately.",abstractText,[0],[0]
"However, such approaches miss out on the mutual synergies if CCR and NEL were performed jointly.",abstractText,[0],[0]
"This paper proposes C3EL, an unsupervised framework combining CCR and NEL for jointly tackling both problems.",abstractText,[0],[0]
"C3EL incorporates results from the CCR stage into NEL, and vice versa: additional global context obtained from CCR improves the feature space and performance of NEL, while NEL in turn provides distant KB features for already disambiguated mentions to improve CCR.",abstractText,[0],[0]
The CCR and NEL steps are interleaved in an iterative algorithm that focuses on the highest-confidence still unresolved mentions in each iteration.,abstractText,[0],[0]
"Experimental results on two different corpora, news-centric and web-centric, demonstrate significant gains over state-of-the-art baselines for both CCR and NEL.",abstractText,[0],[0]
C3EL: A Joint Model for Cross-Document Co-Reference Resolution and Entity Linking,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3708–3718 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
3708",text,[0],[0]
"Recently, deep neural networks have achieved state-of-the-art results in various tasks including computer vision, natural language processing, and speech processing.",1 Introduction,[0],[0]
"Specifically, neural text generation models, central focus of this work, have led to great progress in central downstream NLP tasks like text summarization, machine translation, and image captioning.",1 Introduction,[0],[0]
"For example, the abstractive summarization task, which has previously not been the popular choice for text sum-
∗Work done while interning at Google Brain.
marization due to lack of appropriate text generation methods, has gained revived attention with the success of neural sequence-to-sequence models (Sutskever et al., 2014; Bahdanau et al., 2015).",1 Introduction,[0],[0]
"There has been several recent work with an impressive progress on this task including (Rush et al., 2015; Chopra et al., 2016; Nallapati et al., 2016; Miao and Blunsom, 2016; See et al., 2017; Tan et al., 2017; Zhou et al., 2017).",1 Introduction,[0],[0]
"Machine translation is another central field in NLP where the emergence of neural sequence-to-sequence models has enabled viable alternative approaches (Luong et al., 2015; Bahdanau et al., 2015; Cho et al., 2014; Sutskever et al., 2014) to challenge traditional phrase-based methods (Koehn et al., 2003).
",1 Introduction,[0],[0]
"Most of the recent existing works on neural text generation are based on variants of sequence-tosequence models with attention (Bahdanau et al., 2015) trained with Maximum-likelihood estimation (MLE) with teacher forcing.",1 Introduction,[0],[0]
"As Ranzato et al. (2016) points out in a previous work, these models have two major drawbacks.",1 Introduction,[0],[0]
"First, they are trained to maximize the probability of correct next word given the entire sequence of previous ground truth words.",1 Introduction,[0],[0]
"While, at test time, the models need to generate the entire sequence by feeding its own predictions at previous time steps.",1 Introduction,[0],[0]
This discrepancy is called exposure bias and hurts the performance as the model is never exposed to its own predictions during training.,1 Introduction,[0],[0]
"The second drawback, called wrong objective, is due yet another discrepancy between training and testing.",1 Introduction,[0],[0]
"It refers to the critique (Ranzato et al., 2016) that MLE-trained models tend to have suboptimal performance as they are trained to maximize a convenient objective (i.e., maximum likelihood of word-level correct next step prediction) rather than a desirable sequence-level objective that correlates better with the common discrete evaluation metrics such as ROUGE (Lin and Och, 2004) for summarization,
BLEU (Papineni et al., 2002) for translation, and word error rate for speech recognition, not loglikelihood.",1 Introduction,[0],[0]
"On the other hand, training models that directly optimize for such discrete metrics as objective is hard due to non-differentiable nature of the corresponding loss functions (Rosti et al., 2011).",1 Introduction,[0],[0]
"To address these issues, Ranzato et al. (2016) introduces an incremental learning recipe that uses a hybrid loss function combining REINFORCE (Williams, 1992) and cross-entropy.",1 Introduction,[0],[0]
"Recently, Paulus et al. (2018) also explored combining maximum-likelihood and policy gradient training for text summarization.
",1 Introduction,[0],[0]
"Towards sequence level optimization, previous works (Ranzato et al., 2016; Wu et al., 2016; Paulus et al., 2018) employ reinforcement learning (RL) with a policy-gradient approach which works around the difficulty of differentiating the reward function by using it as a weight.",1 Introduction,[0],[0]
"However, REINFORCE is known to suffer from high sample variance and credit assignment problems which makes the training process difficult and unstable besides resulting in models that are hard to reproduce (Henderson et al., 2018).
",1 Introduction,[0],[0]
"In this paper, we propose an alternative approach for sequence-level training with longest common subsequence (LCS) metric that measures the sequence-level structure similarity between two sequences.",1 Introduction,[0],[0]
We essentially introduce a continuous approximation to the discrete LCS metric which can be directly optimized against using standard gradient-based methods.,1 Introduction,[0],[0]
Our proposed approach has the advantage of being able to directly optimize for a surrogate reward as opposed to using the exact reward only as a weight as in RL-inspired works.,1 Introduction,[0],[0]
"Hence, it provides a viable alternative perspective to policy-gradient methods for side stepping the non-differentiability with respect to the exact reward.",1 Introduction,[0],[0]
"In addition, it simultenuously combats the exposure bias problem through exposing the model to its own predictions while computing our approximation to LCS metric.
",1 Introduction,[0],[0]
"To this end, we introduce a new learning recipe that incorporates the aformentioned continuous approximation to LCS metric (CALCS) as an additional objective on top of maximum-likelihood loss in existing neural text generation models.",1 Introduction,[0],[0]
We evaluate the proposed approach on abstractive text summarization and machine translation tasks.,1 Introduction,[0],[0]
"To this end, we use recently introduced pointer-generator network (See et al., 2017) and
transformer (Vaswani et al., 2017) as underlying baselines for summarization and machine translation, respectively.",1 Introduction,[0],[0]
"More precisely, we start from a pre-trained baseline model with cross-entropy loss, and continue training the model to optimize for the proposed differentiable objective based on CALCS.",1 Introduction,[0],[0]
"Using this recipe, we conduct various experiments on CNN/Daily Mail (Hermann et al., 2015; Nallapati et al., 2016) summarization and WMT 2014 English-to-German machine translation tasks.",1 Introduction,[0],[0]
Experimental results validate the effectiveness of the proposed approach on both tasks.,1 Introduction,[0],[0]
"In this work, we explore the potential use of longest common subsequence (LCS) metric from an algorithmic point of view to address the aforementioned wrong objective and exposure bias problems.",2 Continuously Approximating Longest Common Subsequence Metric,[0],[0]
"LCS metric measures a sequence-level structure similarity between discrete sequences by identifying longest co-occurring in sequence ngrams and it has been shown to correlate well with human judgments for downstream text generation tasks (Lin and Och, 2004).",2 Continuously Approximating Longest Common Subsequence Metric,[0],[0]
"To this end, we propose a way to continuously approximate LCS metric and use this differentiable approximation as the objective to train text generation models rather than the exact LCS measure, which is hard to optimize for due to non-differentiability of the corresponding loss function.",2 Continuously Approximating Longest Common Subsequence Metric,[0],[0]
"Although such differentiable approximation provides a unique advantage from modeling and optimization perspective, the difficulty of controlling its tightness might be a potential drawback in terms of its applicability.",2 Continuously Approximating Longest Common Subsequence Metric,[0],[0]
"In this section, we will first introduce our proposed approximation to LCS metric, and then provide a natural way to control its tightness.
",2 Continuously Approximating Longest Common Subsequence Metric,[0],[0]
"Consider a sequence generation problem conditioned on an input sequence x = (x1, x2, . . .",2 Continuously Approximating Longest Common Subsequence Metric,[0],[0]
", xn) and let",2 Continuously Approximating Longest Common Subsequence Metric,[0],[0]
"y = (y1, y2, . . .",2 Continuously Approximating Longest Common Subsequence Metric,[0],[0]
", ym) denote its corresponding ground-truth output sequence.",2 Continuously Approximating Longest Common Subsequence Metric,[0],[0]
"Let
f(x,Θ) = z = (z1, z2, . . .",2 Continuously Approximating Longest Common Subsequence Metric,[0],[0]
", zk)
denote hypothesis sequence obtained by greedy decoding from a generic encoder-decoder architecture for input sequence x, where Θ represents model parameters.",2 Continuously Approximating Longest Common Subsequence Metric,[0],[0]
"Also, let p1, p2, . . .",2 Continuously Approximating Longest Common Subsequence Metric,[0],[0]
", pk be the probability distributions over vocabulary V at decoding time steps from which z1, z2, . . .",2 Continuously Approximating Longest Common Subsequence Metric,[0],[0]
", zk are generated via argmax operator, respectively.",2 Continuously Approximating Longest Common Subsequence Metric,[0],[0]
"In this section, we define our approach to continuously approximate the longest common subsequence measure (LCS), which is an unnormalized version of ROUGE-L metric (Lin and Och, 2004) (See Appendix B) that is commonly used for performance evaluation of text summarization models.",2.1 CALCS,[0],[0]
The main intuition behind our approach is to relax the common necessity for hard inferences while computing discrete metrics by instead comparing discrete tokens in a soft way.,2.1 CALCS,[0],[0]
"Towards this end, we start by defining LCS metric.
",2.1 CALCS,[0],[0]
Definition 1.,2.1 CALCS,[0],[0]
"Given two sequences y and z of tokens, longest common subsequence LCS(y, z) is defined as the longest sequence of tokens that appear left-to-right (but not necessarily in a contiguous block) in both sequences.
",2.1 CALCS,[0],[0]
The most common and intuitive solution for computing longest common subsequence is via dynamic programming.,2.1 CALCS,[0],[0]
We will briefly revisit this here as it will be useful in terms of both recall and notational convenience while describing our surrogate LCS measure.,2.1 CALCS,[0],[0]
"Let ri,j denote the longest common subsequence between prefix sequences y[:i] = (y1, y2, . . .",2.1 CALCS,[0],[0]
", yi) and z[:j]",2.1 CALCS,[0],[0]
"= (z1, z2, . . .",2.1 CALCS,[0],[0]
", zj) of y and z, respectively.",2.1 CALCS,[0],[0]
"A dynamic programming solution is given by
ri,j =  0",2.1 CALCS,[0],[0]
"if i = 0 or j = 0 ri−1,j−1 + 1 if yi = zj max(ri−1,j , ri,j−1) o/w.
(1)
ri,j for all i = 1, 2, . . .",2.1 CALCS,[0],[0]
",m and j = 1, 2, . . .",2.1 CALCS,[0],[0]
", k.",2.1 CALCS,[0],[0]
It can be computed in mk iterations using the formula in Eqn 1.,2.1 CALCS,[0],[0]
"After computing 2D dynamic programming matrix r, we obtain LCS(y, z) = rm,k.
Towards removing the dependence on hard inference for computing LCS, we now define our approximation to longest common subsequence, which we call CALCS.",2.1 CALCS,[0],[0]
"At high-level, the idea is to continuously relax the original LCS measure.",2.1 CALCS,[0],[0]
"To this end, we leverage output probability distributions p1, p2, . . .",2.1 CALCS,[0],[0]
", pk as soft predictions to refine the dynamic programming formulation for original LCS.",2.1 CALCS,[0],[0]
"More precisely, we recursively define soft longest common subsequence si,j between prefixes y[:i] and z[:j] in analogous to ri,j as
follows:
si,j = p (yi) j (si−1,j−1 + 1) + (2)
(1− p(yi)j )max(si−1,j , si,j−1) (3)
for i, j > 0 and si,0 = s0,j = 0, where p (yi) j denote the probability of generating yi at j-th decoding step.",2.1 CALCS,[0],[0]
"Intuitively, CALCS replaces the hard token comparison 1",2.1 CALCS,[0],[0]
[yi = zj ] in Eq. 1 with the probability p(yi)j as in Eq. 2.,2.1 CALCS,[0],[0]
"Interpreting the probability p(yi)j as a continuous relaxation of discrete comparison operator 1 [yi = zj ], si,j establishes a natural continuous approximation to ri,j .",2.1 CALCS,[0],[0]
"Similar to LCS, after iteratively filling up si,j matrix, we define
CALCS(y, z) = sm,k (4)
",2.1 CALCS,[0],[0]
"Although the proposed approximation is a natural way of relaxing/extending the hard binary comparison of discrete tokens, it is not clear how tight the approximation is, which is established in the next section.",2.1 CALCS,[0],[0]
"In this section, we first discuss the tightness of the proposed approximation, and then provide a natural way of controlling it.",2.2 On the Tightness of Approximation,[0],[0]
We now present a bound on the approximation error of the proposed CALCS compared to the original LCS measure.,2.2.1 Bounding the Approximation Error,[0],[0]
"Characterization of this bound will enable us to theoretically argue about the feasibilty of using the proposed surrogate reward function for our objective as well as controlling its tightness.
",2.2.1 Bounding the Approximation Error,[0],[0]
LCS measure is intrinsically monotonic by definition.,2.2.1 Bounding the Approximation Error,[0],[0]
We start by a lemma that establishes a similar monotonicity property for CALCS.,2.2.1 Bounding the Approximation Error,[0],[0]
Lemma 1.,2.2.1 Bounding the Approximation Error,[0],[0]
"[Monotonicity] The following two inequalities
si,j ≤ si,j+1 ≤ si,j + 1 si,j ≤ si+1,j ≤ si,j + 1
hold for all 0 ≤",2.2.1 Bounding the Approximation Error,[0],[0]
i < m and 0 ≤,2.2.1 Bounding the Approximation Error,[0],[0]
"j < k.
Proof.",2.2.1 Bounding the Approximation Error,[0],[0]
"See Appendix A for the proof.
",2.2.1 Bounding the Approximation Error,[0],[0]
"Having established a certain monotonicity property for CALCS, we will discuss its approximation error to the original LCS measure.",2.2.1 Bounding the Approximation Error,[0],[0]
"Let
δi,j = si,j − ri,j (5)
denote the approximation error of CALCS to LCS measure between generated prefix sequence y[:i] and the ground-truth prefix z[:j].
",2.2.1 Bounding the Approximation Error,[0],[0]
Lemma 2.,2.2.1 Bounding the Approximation Error,[0],[0]
"Let Pi,j = {(0, 0), (i1, j1), . . .",2.2.1 Bounding the Approximation Error,[0],[0]
", (iq−1, jq−1), (iq, jq)} denote the path of dynamic programming algorithm for LCS ending at (i, j) =",2.2.1 Bounding the Approximation Error,[0],[0]
"(iq, jq) cell of m × k grid.",2.2.1 Bounding the Approximation Error,[0],[0]
"Then,
|δi,j | < ∣∣δiq−1,jq−1∣∣+ (1−max(pj))",2.2.1 Bounding the Approximation Error,[0],[0]
"(6)
where max(pj) = max{p(1)j , p (2) j , . .",2.2.1 Bounding the Approximation Error,[0],[0]
.,2.2.1 Bounding the Approximation Error,[0],[0]
", p (|V |) j }.
",2.2.1 Bounding the Approximation Error,[0],[0]
Proof.,2.2.1 Bounding the Approximation Error,[0],[0]
"We will establish the proof by investigating two cases and combining them.
",2.2.1 Bounding the Approximation Error,[0],[0]
CASE 1: zj = yi.,2.2.1 Bounding the Approximation Error,[0],[0]
"In this case, we have
ri,j = 1 + ri−1,j−1 (7)
and
(iq−1, jq−1) =",2.2.1 Bounding the Approximation Error,[0],[0]
"(i− 1, j − 1) (8)
by 1.",2.2.1 Bounding the Approximation Error,[0],[0]
"Using Eq. 7, we get
δi,j = si,j − ri,j = (",2.2.1 Bounding the Approximation Error,[0],[0]
"1− p(yi)j ) max (si−1,j , si,j−1)
+ p",2.2.1 Bounding the Approximation Error,[0],[0]
"(yi) j (si−1,j−1 + 1)− (1 + ri−1,j−1)
= (si−1,j−1 − ri−1,j−1) +",2.2.1 Bounding the Approximation Error,[0],[0]
"( 1− p(yi)j ) [ max(si−1,j , si,j−1)
",2.2.1 Bounding the Approximation Error,[0],[0]
"− (1 + si−1,j−1) ]
Using the definition of δ and triangle inequality, we get
|δi,j | ≤ |δi−1,j−1|+ ( 1− p(yi)j ) ∣∣∣",2.2.1 Bounding the Approximation Error,[0],[0]
"(1 + si−1,j−1) − max (si−1,j , si,j−1)
∣∣∣ ≤",2.2.1 Bounding the Approximation Error,[0],[0]
"|δi−1,j−1|+ ( 1− p(yi)j ) (9)
where inequality 9 follows from the monotonicity established by Lemma 1.
",2.2.1 Bounding the Approximation Error,[0],[0]
"Moreover, zj = yi implies p (yi) j = max(pj) because z is generated by greedy decoding.",2.2.1 Bounding the Approximation Error,[0],[0]
"Plugging this in Eq. 9 and using Eq. 8, we can immediately conclude that
|δi,j | < ∣∣δiq−1,jq−1∣∣+ (1−max(pj)) (10)
CASE 2: zj 6= yi.",2.2.1 Bounding the Approximation Error,[0],[0]
"By definition 1, we have
ri,j = max (ri−1,j , ri,j−1) .
",2.2.1 Bounding the Approximation Error,[0],[0]
"Using this identity, we obtain
δi,j = si,j − ri,j = (",2.2.1 Bounding the Approximation Error,[0],[0]
"1− p(yi)j ) max (si−1,j , si,j−1)
+ p",2.2.1 Bounding the Approximation Error,[0],[0]
"(yi) j (si−1,j−1 + 1)−max (ri−1,j , ri,j−1)
",2.2.1 Bounding the Approximation Error,[0],[0]
= p (yi) j,2.2.1 Bounding the Approximation Error,[0],[0]
"[(1 + si−1,j−1)−max (si−1,j , si,j−1)]
+",2.2.1 Bounding the Approximation Error,[0],[0]
"[max (si−1,j , si,j−1)−max (ri−1,j , ri,j−1)]
",2.2.1 Bounding the Approximation Error,[0],[0]
"Applying triangle inequality on the last equation above, we get
|δi,j | ≤
p (yi) j |(1 + si−1,j−1)−max (si−1,j , si,j−1)|
+ |max (si−1,j , si,j−1)−max (ri−1,j , ri,j−1)| ≤
p (yi) j |(1 + si−1,j−1)−max (si−1,j , si,j−1)|
+max (|si−1,j −",2.2.1 Bounding the Approximation Error,[0],[0]
"ri−1,j | , |si,j−1 − ri,j−1|) (11) =
p (yi) j |(1 + si−1,j−1)−max (si−1,j , si,j−1)|
+max (|δi−1,j | , |δi,j−1|)
≤",2.2.1 Bounding the Approximation Error,[0],[0]
"p(yi)j +max (|δi−1,j | , |δi,j−1|) (12)
where inequality 12 follows from again the monotonicity of s[·, ·], and inequality 11 follows from the following identity that holds true for all real numbers a, b, c, d ≥ 0
|max(a, b)−max(c, d)| ≤ max(|a− c| , |b− d|)
",2.2.1 Bounding the Approximation Error,[0],[0]
"Moreover, since zj 6= yi, we know that p(yi)j 6= max(pj), which implies
p (yi) j ≤ 1−max(pi).",2.2.1 Bounding the Approximation Error,[0],[0]
"(13)
Combining 11 and 13 completes the proof for this case.",2.2.1 Bounding the Approximation Error,[0],[0]
"Finally, two cases investigated above together establish the proof of Lemma 2.
",2.2.1 Bounding the Approximation Error,[0],[0]
Lemma 2 leads to the following important corollary.,2.2.1 Bounding the Approximation Error,[0],[0]
Corollary 1.,2.2.1 Bounding the Approximation Error,[0],[0]
"Let Pi,j = {(0, 0), (i1, j1), . . .",2.2.1 Bounding the Approximation Error,[0],[0]
", (iq, jq)} be the path of dynamic programming algorithm for LCS ending at (i, j) =",2.2.1 Bounding the Approximation Error,[0],[0]
"(iq, jq) cell of m× k grid.",2.2.1 Bounding the Approximation Error,[0],[0]
"Then,
|δi,j | ≤ q∑
w=1
(1−max(pjw)) (14)
Proof.",2.2.1 Bounding the Approximation Error,[0],[0]
"Applying Lemma 2 iteratively and using δ0,0 = 0, we get
|δi,j | ≤ ∣∣δiq−1,jq−1∣∣+",2.2.1 Bounding the Approximation Error,[0],[0]
"(1−max(pjq))∣∣δiq−1,jq−1∣∣ ≤ ∣∣δiq−2,jq−2∣∣+ (1−max(pjq−1))∣∣δiq−2,jq−2∣∣ ≤ ∣∣δiq−3,jq−3∣∣+ (1−max(pjq−2))
...
|δi1,j1",2.2.1 Bounding the Approximation Error,[0],[0]
"| ≤ |δ0,0|+ (1−max(pj1))",2.2.1 Bounding the Approximation Error,[0],[0]
"|δ0,0| ≤ 0
",2.2.1 Bounding the Approximation Error,[0],[0]
Summing (q+1)-many inequalities above side by side and cancelling out the same terms appearing on both sides of the resulting inequality establishes the proof of corollary.,2.2.1 Bounding the Approximation Error,[0],[0]
Corollary 1 hints for a natural way of controlling the tightness of approximation CALCS by exploiting the peakedness of model’s softmax output probability distributions.,2.2.2 Controlling the Tightness of Approximation,[0],[0]
"More precisely, upper bound on the approximation error is represented as a sum of 1−max(pj)’s, hence the more peaked the model’s output probability distributions on average, the smaller the approximation error we are guaranteed by the established bounds.
",2.2.2 Controlling the Tightness of Approximation,[0],[0]
We exploit this property to control the tightness of approximation by making a modification to computation of the proposed CALCS measure.,2.2.2 Controlling the Tightness of Approximation,[0],[0]
"Formally, let l1, l2, . . .",2.2.2 Controlling the Tightness of Approximation,[0],[0]
", lk denote the unnormalized logits of the model output before applying softmax to obtain probabilities p1, p2, . . .",2.2.2 Controlling the Tightness of Approximation,[0],[0]
", pk at decoding time steps, respectively.",2.2.2 Controlling the Tightness of Approximation,[0],[0]
"Hence,
p (i) j = exp(l (i) j )∑
i exp(l (i) j )
(15)
Recall that CALCS is computed using pj’s.",2.2.2 Controlling the Tightness of Approximation,[0],[0]
"Using peaked softmax, we can obtain more peaked probability distributions without causing any change in the actual generated sequence z via greedy decoding.",2.2.2 Controlling the Tightness of Approximation,[0],[0]
"This is simply because the order of probabilities for corresponding vocabulary words will not change, only the probability disribution pj will get more peaked.",2.2.2 Controlling the Tightness of Approximation,[0],[0]
"So, we define peaked softmax operator with hyperparameter α as
p (i) j",2.2.2 Controlling the Tightness of Approximation,[0],[0]
(α) =,2.2.2 Controlling the Tightness of Approximation,[0],[0]
"exp(l (i) j /α)∑
",2.2.2 Controlling the Tightness of Approximation,[0],[0]
"i exp(l (i) j /α)
(16)
",2.2.2 Controlling the Tightness of Approximation,[0],[0]
"By Corollary 1, |δi,j | → 0 as α → 0 for CALCS measure computed with pj(α).",2.2.2 Controlling the Tightness of Approximation,[0],[0]
"One can further
attempt to use Corollary 1 as a guide to pinpoint a range of α values to force the approximation error within certain desired limits.",2.2.2 Controlling the Tightness of Approximation,[0],[0]
"We will use α as a hyperparameter in this work.
",2.2.2 Controlling the Tightness of Approximation,[0],[0]
Corollary 1 is also useful for alternative ways of controlling the tightness of approximation such as incurring penalty for high-entropy output probability distributions or simply penalizing the maximum output probability values less than a desired threshold (that explicitly controls the tightness of the approximation).,2.2.2 Controlling the Tightness of Approximation,[0],[0]
"We leave such options of controlling the approximation error for future work.
",2.2.2 Controlling the Tightness of Approximation,[0],[0]
"With the guidance of Corollary 1 and peaked softmax in Eq. 16, we conclude that CALCS establishes a promising approximation for LCS measure.",2.2.2 Controlling the Tightness of Approximation,[0],[0]
"In the next section, we introduce a new objective function using CALCS as a continuously differentiable reward to be directly maximized.",2.2.2 Controlling the Tightness of Approximation,[0],[0]
"In this section, we describe how to leverage CALCS to define a loss function for sequence level optimization.",2.3 Sequence Level Optimization via CALCS,[0],[0]
"For notational consistency, we will use f(x,Θ) to denote an encoder-decoder architecture that takes an input sequence x and outputs a sequence of tokens z = (z1, z2, . . .",2.3 Sequence Level Optimization via CALCS,[0],[0]
", zm) via greedy decoding from corresponding probability distributions p1, p2, . . .",2.3 Sequence Level Optimization via CALCS,[0],[0]
", pm at each step.
",2.3 Sequence Level Optimization via CALCS,[0],[0]
"For a pair of input sequence x and its corresponding ground-truth output sequence y, we define
JCALCS(x,y;Θ) =",2.3 Sequence Level Optimization via CALCS,[0],[0]
"− log (
CALCS(y, f(x,Θ)) |y| ) (17)
as the loss function for a sample (x,y) based on the CALCS, where |y| denote the length of sequence y. It is important to note here that while computing probability distribution pt at decoding step t, we feed model’s own prediction zt−1 at the previous time step to fight exposure bias.
",2.3 Sequence Level Optimization via CALCS,[0],[0]
"It is important to observe here that JCALCS(x,y;Θ) is differentiable in p1, p2, . . .",2.3 Sequence Level Optimization via CALCS,[0],[0]
", pk by definition and each pi is differentiable in model parameters Θ. Hence, JCALCS(x,y;Θ) is differentiable in model parameters Θ, which allows us to directly optimize the network parameters with respect to LCS metric.",2.3 Sequence Level Optimization via CALCS,[0],[0]
The bound we established on the approximation error and our proposed strategy to control it theoretically ensures the feasibility of using the introduced loss function JCALCS to optimize for LCS metric.,2.3 Sequence Level Optimization via CALCS,[0],[0]
"In this section, we first briefly revisit the pointergenerator (See et al., 2017) and transformer (Vaswani et al., 2017) networks that are used as the underlying baselines in our experiments.",3 Model,[0],[0]
"Subsequently, we describe how the proposed objective function and its variants are used to train new summarization and machine translation models.",3 Model,[0],[0]
Pointer-Generator Network.,3.1 Baseline Models,[0],[0]
"We use pointergenerator network (See et al., 2017) as our baseline sequence-to-sequence model for text summarization.",3.1 Baseline Models,[0],[0]
"It is essentially a hybrid between sequence-to-sequence model with attention (Bahdanau et al., 2015) and a pointer network (Vinyals et al., 2015) that supports two decoding modes, copying and generating, via a soft switch mechanism.",3.1 Baseline Models,[0],[0]
This enables the model to copy a word from the input sequence based on the attention distribution.,3.1 Baseline Models,[0],[0]
"On each decoding time step t, the decoder LSTM is fed the word embedding of the previous word, and computes a decoder state st, an attention distribution at over the words of input article, and a probability Pvocab(w) of generating word w for summary from output vocabulary V , which is then softly combined with the copy mode’s probability distribution Pcopy(w) via soft switch probability pgen ∈",3.1 Baseline Models,[0],[0]
"[0, 1] by
p (w) t = pgenPvocab(w) + (1− pgen)Pcopy(w)
and
Pcopy(w) = ∑
{i:wi=w}
ati
where ati indicates the attention probability on ith word of the input article.",3.1 Baseline Models,[0],[0]
"The whole network is then trained end-to-end with the negative loglikelihood loss function of
JPG(x,y;Θ) =",3.1 Baseline Models,[0],[0]
"− 1
|y| |y|∑ t=1 log(p (yt) t )
for a sample article-summary pair (x,y) where Θ denote the learnable model parameters.",3.1 Baseline Models,[0],[0]
"It is important to note here that we do not use the coverage mechanism introduced by the original work (See et al., 2017) to prevent the potential repetition problem in the summaries generated by the model.
",3.1 Baseline Models,[0],[0]
Transformer Network.,3.1 Baseline Models,[0],[0]
"For machine translation, we use the transformer network (Vaswani et al., 2017), which is a recently published model that achieved state-of-the-art results on WMT 2014 English-to-German MT task with less computational time owing to its highly parallelizable architecture.",3.1 Baseline Models,[0],[0]
"The core idea behind this model is to use stacked self-attention mechanisms along with point-wise, fully connected layers for both encoder and decoder to represent its input and output.",3.1 Baseline Models,[0],[0]
"For the sake of brevity, we refer the reader to (Vaswani et al., 2017) for further details regarding the architecture.",3.1 Baseline Models,[0],[0]
"Similar to previously defined loss functions, let JTF(x,y;Θ) denote the perexample loss function of transformer networks for an input-output translation pair (x,y) where Θ is again indicating the learnable model parameters.",3.1 Baseline Models,[0],[0]
"Let {(x(l),y(l))}Nl=1 denote the set of training examples, where x(l)’s are input sequences, and y(l)’s are their corresponding ground-truth output sequences.",3.2 Model Variants and Training,[0],[0]
"Before optimizing for the introduced objective JCALCS, we first train the corresponding baseline network by minimizing
J{PG,TF}(Θ) = 1
N",3.2 Model Variants and Training,[0],[0]
"N∑ l=1 J{PG,TF}(x,y;Θ).
",3.2 Model Variants and Training,[0],[0]
"Unlike JCALCS, loss functions J{PG,TF} for baseline models are computed by teacher forcing, feeding the previous ground-truth word at each decoding step.",3.2 Model Variants and Training,[0],[0]
"We will denote the baseline models by POINTGEN for pointer-generator network and TRANSFORMER for transformer network.
",3.2 Model Variants and Training,[0],[0]
"To optimize for the proposed objective JCALCS, we initialize the model parameters Θ from the pretrained baseline network and continue training the model by minimizing the joint loss
J(Θ)",3.2 Model Variants and Training,[0],[0]
= λJCALCS(Θ),3.2 Model Variants and Training,[0],[0]
"+ (1− λ)J{PG,TF}(Θ)
(18)
JCALCS(Θ)",3.2 Model Variants and Training,[0],[0]
"= 1
N N∑ l=1 JCALCS(x,y;Θ) (19)
where λ is a hyperparameter controlling the balance between the two losses.",3.2 Model Variants and Training,[0],[0]
"During the training with the joint loss, we compute JCALCS(x,y;Θ), defined in Eq. 17, by performing |y|-many decoding steps as a simple strategy to prevent the model from gaming the training objec-
tive by generating longer and longer hypotheses instead of incurring an additional length penalty.",3.2 Model Variants and Training,[0],[0]
"We will refer to the resulting model trained with the loss function in Eq. 18 as {POINTGEN, TRANSFORMER}+CALCS",3.2 Model Variants and Training,[0],[0]
depending on the baseline model.,3.2 Model Variants and Training,[0],[0]
We numerically evaluate the proposed method on two sequence generation benchmarks: abstractive document-summarization and machine translation.,4 Experiments,[0],[0]
"We compare the results of the proposed method against the recently proposed strong baseline models (See et al., 2017) for summarization and and (Vaswani et al., 2017) for machine translation tasks.",4 Experiments,[0],[0]
"We use a modified version of the CNN/Daily Mail dataset (Hermann et al., 2015) that is first used for summarization by (Nallapati et al., 2016).",4.1 Abstractive Summarization,[0],[0]
"However, we follow the processing script provided by (See et al., 2017) to obtain non-anonymized version of the data that contains 287,226 training pairs, 13,368 validation pairs, and 11,490 test pairs of news articles (781 tokens on average) and their corresponding ground-truth summaries (56 tokens on average).",4.1 Abstractive Summarization,[0],[0]
"We refer the reader to (See et al., 2017) for further details of the difference of their version from (Nallapati et al., 2016).
",4.1 Abstractive Summarization,[0],[0]
"For training our baseline model, we use single layer LSTM encoder (bi-directional) and decoder with hidden dimensions of 512 and 1024, respectively.",4.1 Abstractive Summarization,[0],[0]
We use a vocabulary of 50k words for both source and target.,4.1 Abstractive Summarization,[0],[0]
"Following the original paper, we also do not pre-train word embeddings, which are learned with the rest of model parameters during
training.",4.1 Abstractive Summarization,[0],[0]
"We use the Adam (Kingma and Ba, 2015) optimizer with a learning rate of 0.00001 for training.",4.1 Abstractive Summarization,[0],[0]
"We pre-train the baseline model for 20k steps by applying greedy scheduled sampling (Bengio et al., 2015) with fixed ground-truth feeding probability of 75%.",4.1 Abstractive Summarization,[0],[0]
"Once the baseline model training is complete, we start optimizing for CALCS objective as described in the previous section.",4.1 Abstractive Summarization,[0],[0]
"Also, we set λ = 1.0 and α = 1.0, which are tuned on the development set.
",4.1 Abstractive Summarization,[0],[0]
"In Table 1, we report our main results on the summarization task.",4.1 Abstractive Summarization,[0],[0]
POINTGEN+SS refers to the baseline model trained with scheduled sampling.,4.1 Abstractive Summarization,[0],[0]
POINTGEN+SS+CALCS corresponds our model trained with CALCS starting from POINTGEN+SS model.,4.1 Abstractive Summarization,[0],[0]
Experimental results demonstrate that training with our proposed objective provides an improvement of 2.2 points in ROUGE-L score.,4.1 Abstractive Summarization,[0],[0]
"This also provides empirical evidence to justify that our approximate CALCS effectively captures what the original LCS metric is supposed to measure, recalling ROUGE-L is a normalized LCS.",4.1 Abstractive Summarization,[0],[0]
"The reason why ROUGE-L scores of our models are lower than previously reported is that we evaluate ROUGE-L score by taking the entire summary as a single sequence instead of splitting it into sentences, which is also the way we compute CALCS objective during the model training process.",4.1 Abstractive Summarization,[0],[0]
"The main motivation behind this approach is to encourage the model to preserve the sentence order within a summary, and evaluate its performance in the same way.",4.1 Abstractive Summarization,[0],[0]
We consider the capability of preserving the order across produced sentences as an important attribute a multi-sentence summarization model should have in terms of readability and fluency of its generated summaries as a whole.,4.1 Abstractive Summarization,[0],[0]
"When POINTGEN*+SS and POINTGEN*+SS+CALCS are evaluated by splitting the generated summaries into sentences, their corresponding ROUGE-L scores become 35.38 and 35.12, respectively.",4.1 Abstractive Summarization,[0],[0]
"We also observe a nice sideimprovement of 1.0 point in ROUGE-1 score over the baseline, which achieves a comparable performance with the long-overdue LEAD-3 baseline score.",4.1 Abstractive Summarization,[0],[0]
"It might also be comparable to the recently reported state-of-the-art ROUGE-1 result on CNN/DailyMail dataset by Paulus et al. (2018) as they used a different dataset processing pipeline, which makes it difficult to directly compare with ours.",4.1 Abstractive Summarization,[0],[0]
"We also evaluate our sequence-level training approach on the WMT 2014 English-to-German machine translation task, which contains 4.5M pairs of sentences.
",4.2 Machine Translation,[0],[0]
"To train our baseline transformer model, we closely follow the small model in the original transformer paper (Vaswani et al., 2017).",4.2 Machine Translation,[0],[0]
We use a vocabulary of size 32k.,4.2 Machine Translation,[0],[0]
Our encoder and decoder consist of N = 6 identical layers each.,4.2 Machine Translation,[0],[0]
"Following the notation in the original paper, we set the other parameters as dmodel = 512, dff = 2048, h = 8, Pdrop = 0.1.",4.2 Machine Translation,[0],[0]
"We set λ = 0.3 and α = 1.0, which are tuned on the development set.
",4.2 Machine Translation,[0],[0]
"In Table 2, we show our empirical results on machine translation task.",4.2 Machine Translation,[0],[0]
"Our first observation is that our trained baseline transformer network achieves a better performance than the one reported in the original paper (Vaswani et al., 2017) by 0.3 BLEU score, which might be solely due to hyperparameter tuning.",4.2 Machine Translation,[0],[0]
"More importantly, we observe that training with our proposed CALCS objective leads to noticeable 0.2 BLEU point improvements over the baseline, which further reinforces our confidence in effectiveness of our proposed sequence-level training approach and its applicability to other sequence prediction tasks.",4.2 Machine Translation,[0],[0]
It is also interesting to note that optimizing for LCS metric via its continuous approximation leads to improvements in evaluation with another discrete metric BLEU.,4.2 Machine Translation,[0],[0]
"On the other had, optimizing for the exact discrete metric BLEU via reinforcement learning strategy may not improve the evaluation performance in BLEU as reported by (Wu et al., 2016).",4.2 Machine Translation,[0],[0]
"As a final remark, we would like to note that our proposed approach is orthogonal to advancements in more expressive and powerful architecture designs.",4.2 Machine Translation,[0],[0]
"Hence it has the potential to provide further improvements over the recently proposed models such as WEIGHTED TRANSFORMER (Ahmed et al., 2018).",4.2 Machine Translation,[0],[0]
Text Summarization.,5 Related Work,[0],[0]
"Before the successful application of neural generative models, most of the existing works on text summarization (Dorr et al., 2003; Durrett et al., 2016) have focused on extractive methods.",5 Related Work,[0],[0]
"While some of the early approaches have used a rich set of heuristic rules or sparse features to select textual units to include in the summary, more recent works (Cheng and Lapata, 2016; Nallapati et al., 2017) leverage neural models to select words and sentences from the original text.",5 Related Work,[0],[0]
"With the emergence of sequenceto-sequence models (Sutskever et al., 2014) and large-scale datasets like CNN/Daily Mail (Hermann et al., 2015; Nallapati et al., 2016) and NYT (Paulus et al., 2018), abstractive summarization of longer text have become a more feasible and popular task.",5 Related Work,[0],[0]
"Several recent approaches have been proposed to tackle abstractive summarization problem, where Nallapati et al. (2016) exploits hierarchical encoders, See et al. (2017) proposes pointer-generator network and coverage mechanism to overcome OOV and repetition problems, Tan et al. (2017) introduces a graphbased attention mechanism and hierarchical beam search strategy, and (Paulus et al., 2018) proposes to optimize for ROUGE metric via reinforcement learning.",5 Related Work,[0],[0]
"Although impressive progress has been achieved for sentence-level summarization, attempts on abstractive document summarization task are still in early stages where the simple LEAD-3 baseline performance is only very recently matched (Paulus et al., 2018).",5 Related Work,[0],[0]
Neural Machine Translation.,5 Related Work,[0],[0]
"With the recent success of encoder-decoder architectures (Sutskever et al., 2014; Bahdanau et al., 2015), neural machine translation systems has gained a a lot of attention both from academia (Cho et al., 2014; Luong et al., 2015; Luong and Manning, 2016) and industry (Wu et al., 2016; Vaswani et al., 2017; Ahmed et al., 2018) over statistical machine translation, which has been the dominating translation paradigm for years.",5 Related Work,[0],[0]
"Most of these works has focused more on enhancing the architecture design aspect to tackle with various challenges such as different attention mechanisms (Bahdanau et al., 2015; Luong et al., 2015), a character-level decoder (Chung et al., 2016), a translation coverage mechanism (Tu et al., 2016), and so on.",5 Related Work,[0],[0]
"However, only very recently, a few works (Wu et al., 2016; Ranzato et al., 2016;
Norouzi et al., 2016; Shen et al., 2016; Bahdanau et al., 2017; Zhukov and Kretov, 2017; Casas et al., 2018) have investigated sequence-level optimization by training to maximize BLEU score.",5 Related Work,[0],[0]
Neural Sequence Generation with RL.,5 Related Work,[0],[0]
Most neural sequence generation models are trained with the objective of maximizing the probability of the next correct word.,5 Related Work,[0],[0]
"However, this results in a major discrepancy between training and test settings of these models because they are trained with cross-entropy loss at word-level, but evaluated based on sequence-level discrete metrics such as ROUGE (Lin and Och, 2004) or BLEU (Papineni et al., 2002).",5 Related Work,[0],[0]
"On the other hand, directly optimizing for such evaluation metrics is hard due to non-differentiable nature of the exact objective (Rosti et al., 2011).",5 Related Work,[0],[0]
"Recent works (Ranzato et al., 2016; Wu et al., 2016; Bahdanau et al., 2017; Paulus et al., 2018) address the difficulty of differentiating with respect to rewards based on such discrete metrics using variants of reinforcement learning.",5 Related Work,[0],[0]
These methods essentially propose to mitigate the problem by optimizing the reward weighted log-likelihood of the hypothesis sequences generated by the model distribution.,5 Related Work,[0],[0]
"In this paper, we propose an alternative solution to tackle this problem by introducing a differentiable approximation to exact LCS metric that can be directly optimized by standard gradient-based methods without RL, while still addressing the exposure bias problem.",5 Related Work,[0],[0]
In this work we explored an alternative approach for training text generation models with sequencelevel optimization to combat wrong objective and exposure bias problems.,6 Conclusion and Future Work,[0],[0]
We introduced a new objective function based on a continuous approximation of LCS metric that measures sequence-level structure similarity between sentences.,6 Conclusion and Future Work,[0],[0]
We applied our proposed approach to CNN/Daily Mail dataset for long document summarization and WMT 2014 English-to-German machine translation task.,6 Conclusion and Future Work,[0],[0]
"By extending the objectives of strong neural baseline models with our proposed objective, we empirically demonstrated its effectiveness on these two tasks.",6 Conclusion and Future Work,[0],[0]
Our proposed approach suggests a promising alternative to policy-gradient methods to side step the difficulty of differentiating w.r.t reward function while directly optimizing for sequence-level discrete metrics.,6 Conclusion and Future Work,[0],[0]
"[Monotonicity] The following two inequalities
si,j ≤ si,j+1 ≤ si,j + 1 si,j ≤ si+1,j ≤ si,j + 1
hold for all 0 ≤",A Proof of Lemma 1,[0],[0]
i < m and 0 ≤,A Proof of Lemma 1,[0],[0]
"j < k.
Proof.",A Proof of Lemma 1,[0],[0]
"We will prove this lemma by induction on i+ j.
Base Case: i + j = 0.",A Proof of Lemma 1,[0],[0]
"In this case, we have i = j = 0.",A Proof of Lemma 1,[0],[0]
"Since s0,0 = s1,0 = s0,1 = 0 by definition, both s0,0 ≤ s0,1 ≤ s0,0 + 1 and s0,0 ≤ s1,0 ≤ s0,0 + 1 hold.
",A Proof of Lemma 1,[0],[0]
"Inductive Step: Assume for i+ j = l that
si,j ≤ si,j+1 ≤ si,j + 1 (20) si,j ≤ si+1,j ≤",A Proof of Lemma 1,[0],[0]
"si,j + 1 (21)
hold.",A Proof of Lemma 1,[0],[0]
We will now prove that the inequalities of inductive hypothesis hold for i+ j = l + 1.,A Proof of Lemma 1,[0],[0]
"We will start by showing si,j+1 ≥ si,j .",A Proof of Lemma 1,[0],[0]
"By definition, we have
si,j+1 = p (yi) j+1(si−1,j + 1)+ (22)
(1− p(yi)j+1)max(si−1,j+1, si,j) (23)
≥ p(yi)j+1(si−1,j + 1) +",A Proof of Lemma 1,[0],[0]
"(1− p (yi) j+1)si,j
(24)
≥ p(yi)j+1si,j + (1− pj+1,yi)si,j (25)",A Proof of Lemma 1,[0],[0]
"≥ si,j (26)
where inequality 24 follows from the definition of max operator, and inequality 25 follows from induction assumption 20 because (i − 1) +",A Proof of Lemma 1,[0],[0]
"j = l. Hence, final inequality 26 establishes the proof of si,j+1 ≥ si,j .
",A Proof of Lemma 1,[0],[0]
"Now, we will show that si,j+1 ≤ si,j + 1 holds.
",A Proof of Lemma 1,[0],[0]
"Again by definition, we have
si,j+1 = p (yi) j+1(si−1,j + 1)+ (27)
(1− p(yi)j+1)max(si−1,j+1, si,j) (28)
≤ p(yi)j+1(si−1,j + 1)+ (29)
(1− p(yi)j+1)(si−1,j + 1) (30) ≤ si−1,j + 1 (31) ≤",A Proof of Lemma 1,[0],[0]
"si,j + 1 (32)
where inequalities 30 and 32 follow from inequalities 20 and 21 of inductive step as (i−1)+ j = l.
Note that 26 and 32 completes the proof of si,j ≤ si,j+1 ≤ si,j + 1 for i + j = l + 1.",A Proof of Lemma 1,[0],[0]
"Following similar arguments, one can easily establish the correctness of si,j ≤",A Proof of Lemma 1,[0],[0]
"si+1,j ≤",A Proof of Lemma 1,[0],[0]
"si,j + 1 for i+j = l+1, which completes the proof of Lemma by induction.",A Proof of Lemma 1,[0],[0]
Definition 2.,B Definition of Rouge-L,[0],[0]
ROUGE-L is a discrete similarity metric that takes into account sentence level structure similarity by identifying longest co-occurring in-sequence n-grams automatically via longest common subsequence measure.,B Definition of Rouge-L,[0],[0]
"Formally, given two sequences y and z of tokens, we define ROUGE-L(y, z) as the harmonic mean of precision LCS(y,z)k and recall LCS(y,z) m based on LCS measure, where k = |z| and m = |y|.",B Definition of Rouge-L,[0],[0]
Maximum-likelihood estimation (MLE) is one of the most widely used approaches for training structured prediction models for textgeneration based natural language processing applications.,abstractText,[0],[0]
"However, besides exposure bias, models trained with MLE suffer from wrong objective problem where they are trained to maximize the word-level correct next step prediction, but are evaluated with respect to sequence-level discrete metrics such as ROUGE and BLEU.",abstractText,[0],[0]
Several variants of policy-gradient methods address some of these problems by optimizing for final discrete evaluation metrics and showing improvements over MLE training for downstream tasks like text summarization and machine translation.,abstractText,[0],[0]
"However, policy-gradient methods suffers from high sample variance, making the training process very difficult and unstable.",abstractText,[0],[0]
"In this paper, we present an alternative direction towards mitigating this problem by introducing a new objective (CALCS) based on a differentiable surrogate of longest common subsequence (LCS) measure that captures sequence-level structure similarity.",abstractText,[0],[0]
Experimental results on abstractive summarization and machine translation validate the effectiveness of the proposed approach.,abstractText,[0],[0]
CALCS: Continuously Approximating Longest Common Subsequence for Sequence Level Optimization,title,[0],[0]
"Proceedings of the SIGDIAL 2015 Conference, pages 232–236, Prague, Czech Republic, 2-4 September 2015. c©2015 Association for Computational Linguistics",text,[0],[0]
"Speech summarization has been of great interest to the community because speech is the principal modality of human communications, and it is not as easy to skim, search or browse speech transcripts as it is for textual messages.",1 Introduction,[0],[0]
Speech recorded from call centres offers a great opportunity to study goal-oriented and focused conversations between an agent and a caller.,1 Introduction,[0],[0]
The Call Centre Conversation Summarization (CCCS) task consists in automatically generating summaries of spoken conversations in the form of textual synopses that shall inform on the content of a conversation and might be used for browsing a large database of recordings.,1 Introduction,[0],[0]
"Compared to news summarization where extractive approaches have been very successful, the CCCS task’s objective is to foster work on abstractive summarization in order
to depict what happened in a conversation instead of what people actually said.
",1 Introduction,[0],[0]
"The track leverages conversations from the Decoda and Luna corpora of French and Italian call centre recordings, both with transcripts available in their original language as well as English translation (both manual and automatic).",1 Introduction,[0],[0]
"Recordings duration range from a few minutes to 15 minutes, involving two or sometimes more speakers.",1 Introduction,[0],[0]
"In the public transportation and help desk domains, the dialogs offer a rich range of situations (with emotions such as anger or frustration) while staying in a coherent and focused domain.
",1 Introduction,[0],[0]
"Given transcripts, participants to the task shall generate abstractive summaries informing a reader about the main events of the conversations, such as the objective of the caller, whether and how it was solved by the agent, and the attitude of both parties.",1 Introduction,[0],[0]
Evaluation has been performed by comparing submissions to reference synopses written by quality assurance experts from call centres.,1 Introduction,[0],[0]
"Both conversations and reference summaries are kindly provided by the SENSEI project.
",1 Introduction,[0],[0]
This paper reports on the results of the CCCS task in term ROUGE-2 evaluation metric.,1 Introduction,[0],[0]
Two participants have submitted four systems to the task.,1 Introduction,[0],[0]
"In addition, we provide three baselines which frame the performance that would be obtained by extractive systems.",1 Introduction,[0],[0]
"The results are analysed according to language, human annotator coherence and the impact of automatic translation.
",1 Introduction,[0],[0]
The remaining of the paper is organized as follows: Section 2 describes the synopsis generation task.,1 Introduction,[0],[0]
Section 3 describes the CCCS corpus.,1 Introduction,[0],[0]
Section 4 describes the results from the systems of the participants.,1 Introduction,[0],[0]
Section 5 discusses future research avenues.,1 Introduction,[0],[0]
"The CCCS task consists in creating systems that can analyse call centre conversations and generate
232
written summaries reflecting why the customer is calling, how the agent answers that query, what are the steps to solve the problem and what is the resolution status of the problem.
",2 Task,[0],[0]
"Unlike news summarization which focuses on locating facts in text written by journalists and selecting the most relevant facts, conversation synopses require an extra level of analysis in order to achieve abstraction.",2 Task,[0],[0]
"Turn taking from the speakers has to be converted to generic expression of their needs, beliefs and actions.",2 Task,[0],[0]
"Even though extractive systems might give a glimpse of the dialogs, only abstraction can yield synopses that tell the story of what happens in the conversations.
",2 Task,[0],[0]
"Contrary to previous research on meeting summarization (Gillick et al., 2009; Erol et al., 2003; Lai and Renals, 2014; Wang and Cardie, 2012) (among others), we expect that the fact that conversations are focused and goal oriented will enable to foster research on more abstractive methods, such as (Murray, 2015; Mehdad et al., 2013) and deeper analysis of the conversations.
",2 Task,[0],[0]
"Participants to the CCCS task could submit system output in any of the supported languages, and could submit a maximum of three runs per language.",2 Task,[0],[0]
"For each conversation, they had to submit one synopsis of length 7% of the number of words of the transcript of that conversation.",2 Task,[0],[0]
"The CCCS task draws from two call centre conversation corpora, the Decoda corpus in French and the Luna corpus in Italian.",3 Corpus description,[0],[0]
"Subsets from both corpora have been translated to English.
",3 Corpus description,[0],[0]
"Decoda corpus The French DECODA corpus consists in conversations between customers and one or more agent recorded in 2009 in a call centre of the public transport authority in Paris (Bechet et al., 2012).",3 Corpus description,[0],[0]
"The topics of the conversations range from itinerary and schedule requests, to lost and found, to complaints (the calls were recorded during strikes).",3 Corpus description,[0],[0]
"The dialogues, recorded in ecological conditions, are very spontaneous and focused on the objective of the caller.",3 Corpus description,[0],[0]
They are very challenging for Automatic Speech Recognition due to harsh acoustic conditions such as calling from mobile phones directly from the metro.,3 Corpus description,[0],[0]
"For the CCCS task, manual transcripts were provided to the participants.
",3 Corpus description,[0],[0]
"While the original language of the conversations is French, the SENSEI project provided man-
ual translations in English by professional translators which were trained to keep the spontaneous aspects of the originals (a very challenging task according to them).",3 Corpus description,[0],[0]
"97 conversations were manually translated, on which an automatic translation system based on Moses was trained in order to produce automatic translations for the remaining of the corpus.
",3 Corpus description,[0],[0]
The original corpus consists of 1513 conversations (about 70h of speech).,3 Corpus description,[0],[0]
1000 conversations have been distributed without synopses for unsupervised system training.,3 Corpus description,[0],[0]
50 conversations were distributed with multiple synopses from up to five annotators.,3 Corpus description,[0],[0]
"The test set consists of 47 manually translated conversations and corresponding synopses, and 53 automatically translated conversations and corresponding synopses.",3 Corpus description,[0],[0]
"The data for training and testing is also provided in French.
",3 Corpus description,[0],[0]
"The human written synopses are very diverse and show a high degree of abstraction from the words of the conversation with third person writing, telegraphic style and analysis of the conversations.",3 Corpus description,[0],[0]
"Examples:
• A man is calling cause he got a fine.",3 Corpus description,[0],[0]
He is waiting for a new card so he used his wife’s card.,3 Corpus description,[0],[0]
"He must now write a letter asking for clemency.
",3 Corpus description,[0],[0]
• A user wants to go to the Ambroise Paré clinic but the employee misunderstands and gives her the wrong itinerary.,3 Corpus description,[0],[0]
"Luckily the employee realises her mistake and gives the passenger the right information in the end.
",3 Corpus description,[0],[0]
"• School bag lost on line 4, not found.
",3 Corpus description,[0],[0]
"Luna corpus The Italian human-human Luna corpus (Dinarelli et al., 2009) consists of 572 dialogs (≈ 26.5K turns & 30 hours of speech) in the hardware/software help desk domain, where a
client and an agent are engaged in a problem solving task over the phone.",3 Corpus description,[0],[0]
The dialogs are organised in transcriptions and annotations created within the FP6 LUNA project.,3 Corpus description,[0],[0]
"For the CCCS shared task, manual transcriptions were used.
",3 Corpus description,[0],[0]
"Within the FP7 SENSEI project, 100 dialogs were translated from Italian to English using professional translation services according to the methodology described in (Stepanov et al., 2014).",3 Corpus description,[0],[0]
"For more accurate translations, manual transcriptions were converted to an ‘annotated’ text format, which contained mark-up for overlapping turns, fillers, pauses, noise, partial words, etc.; and translators received detailed guidelines on how to handle each phenomenon in translation.",3 Corpus description,[0],[0]
"Additionally, the translators were required to translate the speech phenomena such as disfluencies as closely as possible to the source language maintaining ‘naturalness’ in the target language.
",3 Corpus description,[0],[0]
"Five native Italian speakers have annotated 200 Luna dialogs with synopses so that each dialog was processed by every annotator.1 Synopses of the 100 translated dialogs were also manually translated to English.
",3 Corpus description,[0],[0]
The translated and annotated dialogs were equally split into training and test sets for the CCCS task.,3 Corpus description,[0],[0]
The training dialogs were used to automatically translate additional Luna dialogs and synopses for both training and testing.,3 Corpus description,[0],[0]
"Similar to the DECODA corpus, for the unsupervised training of the systems a supplementary set of 261 dialogs was automatically translated and provided to the participants without synopses.",3 Corpus description,[0],[0]
Dialogs and their associated synopses were provided both in English and Italian.,3 Corpus description,[0],[0]
"The statistics for Luna manual English test set are provided in Table 2.
1Few (2) synopses were found to address dialog dimensions other than the task and were removed.",3 Corpus description,[0],[0]
"Metric Evaluation is performed with the ROUGE-2 metric (Lin, 2004).",4 Results,[0],[0]
ROUGE-2 is the recall in term of word bigrams between a set of reference synopses and a system submission.,4 Results,[0],[0]
"The ROUGE 1.5.5 toolkit was adapted to deal with a conversation-dependent length limit of 7%, had lemmatization disabled and stop-words kept, to be as language independent as possible 2.",4 Results,[0],[0]
"Jackknifing and resampling is used in order to compute confidence estimate intervals.
",4 Results,[0],[0]
Participation Seven research groups had originally expressed their intention to participate to the CCCS task.,4 Results,[0],[0]
"Four groups downloaded the test data, and two groups actually submitted system output at the deadline.",4 Results,[0],[0]
"Those two groups generated four runs: NTNU:1, NTNU:2, NTNU:3, LIA-RAG:1.",4 Results,[0],[0]
"The technical details of these submissions are described in their own papers.
",4 Results,[0],[0]
"In addition to those four runs, we provide three baselines which serve to calibrate participant performance.",4 Results,[0],[0]
"The first baseline is Maximal Marginal Relevance (Baseline-MMR) (Carbonell and Goldstein, 1998) with λ = 0.7.",4 Results,[0],[0]
"The second baseline is the first words of the longest turn in the conversation, up to the length limit (Baseline-L).",4 Results,[0],[0]
"The third baseline is the words of the longest turn in the first 25% of the conversation, which usually corresponds to the description of the caller’s problem (Baseline-LB).",4 Results,[0],[0]
"Those baselines are described in more details in (Trione, 2014).
",4 Results,[0],[0]
"In order to estimate the overlap between human synopses, we remove each of the human synopses in turn from the reference and compute their performance as if they were systems.",4 Results,[0],[0]
"Across languages, 11 annotators (denoted human-1 to human-5 for IT/EN, and human-A to human-G for FR/EN) produced from 5 to 100 synopses.",4 Results,[0],[0]
"Note that some annotators only worked on English conversations.
",4 Results,[0],[0]
Performance Performance of the systems is reported in Table 3.,4 Results,[0],[0]
"It shows that in the source languages, the extractive baselines were difficult to beat while one of the systems significantly outperformed the baselines on English (the EN test set
2The options for running ROUGE 1.5.5 are -a -l 10000 -n 4 -x -2 4 -u -c 95 -r 1000 -f A -p 0.5 -t 0
corresponds to the union of manual and automatic translations).
",4 Results,[0],[0]
An analysis of the consistency of human synopsis writers is outlined in Table 4.,4 Results,[0],[0]
"Consistency is computed by considering in turn each of the human synopses as system output, and computing ROUGE-2 performance.",4 Results,[0],[0]
"Humans have much better scores than the systems, showing that they are consistent in producing the gold standard.",4 Results,[0],[0]
"However, human annotators suffer from a much higher performance variance than systems (for which confidence intervals are 4-5 times smaller).",4 Results,[0],[0]
This partly comes from the low number of manual synopses which is greater impacted by resampling than if there were hundreds of references for each conversation.,4 Results,[0],[0]
"It also comes from local inconsistencies between humans on a given conversation, resulting in diverging choices in term of which information is important.
",4 Results,[0],[0]
Table 5 shows the impact of automatic translation on system performance for the English set.,4 Results,[0],[0]
"This experiment is hard to interpret as the set of conversations for automatic and manual transla-
tions is different.",4 Results,[0],[0]
"However, it seems that processing MT results leads to better ROUGE scores, probably due to the consistency with which the MT system translates words for both conversations and synopses (reference synopses are automatic translations of source language synopses for those conversations).",4 Results,[0],[0]
The objective of the CCCS pilot task at Multiling’15 was to allow work on abstractive summarization of goal-oriented spoken conversations.,5 Conclusion,[0],[0]
"This task involved generating synopses from French and Italian call centre recording transcripts, and English translations of those transcripts.",5 Conclusion,[0],[0]
"Four systems were submitted by two participants, and obtained reasonable results but had trouble exceeding the performance of the extractive baselines.
",5 Conclusion,[0],[0]
"Clearly, ROUGE evaluation is limited for abstractive summarization in that the wording of generated text might be very different from system to system, and from reference to reference, while conveying the same meaning.",5 Conclusion,[0],[0]
"In addition, ROUGE does not assess fluency and readability of the summaries.
",5 Conclusion,[0],[0]
"Future work will focus on proposing better evaluation metrics for the task, probably involving the community for manually evaluating the fluency and adequacy of the submitted system output.",5 Conclusion,[0],[0]
"In addition, work will be conducted in evaluating and insuring the consistency of the human experts who create the gold standard for the task.",5 Conclusion,[0],[0]
The research leading to these results has received funding from the European Union - Seventh Framework Programme (FP7/2007-2013) under grant agreement n.610916 - SENSEI.,Acknowledgments,[0],[0]
This paper describes the results of the Call Centre Conversation Summarization task at Multiling’15.,abstractText,[0],[0]
The CCCS task consists in generating abstractive synopses from call centre conversations between a caller and an agent.,abstractText,[0],[0]
"Synopses are summaries of the problem of the caller, and how it is solved by the agent.",abstractText,[0],[0]
Generating them is a very challenging task given that deep analysis of the dialogs and text generation are necessary.,abstractText,[0],[0]
"Three languages were addressed: French, Italian and English translations of conversations from those two languages.",abstractText,[0],[0]
The official evaluation metric was ROUGE-2.,abstractText,[0],[0]
Two participants submitted a total of four systems which had trouble beating the extractive baselines.,abstractText,[0],[0]
The datasets released for the task will allow more research on abstractive dialog summarization.,abstractText,[0],[0]
Call Centre Conversation Summarization: A Pilot Task at Multiling 2015,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2381–2391 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
2381",text,[0],[0]
"Open book exams are a common mechanism for assessing human understanding of a subject, where test takers are allowed free access to a relevant book, study guide, or class notes when answering questions.",1 Introduction,[0],[0]
"In this context, the goal is not to evaluate memorization but a deeper understanding of the material and its application to new situations (Jenkins, 1995; Landsberger, 1996).",1 Introduction,[0],[0]
"The application, in turn, often requires combining a fact in the book (e.g., metals conduct electricity) with additional common knowledge the test taker is ex-
pected to have acquired by this stage (e.g., a suit of armor is made of metal).
",1 Introduction,[0],[0]
"Motivated by this setting, we present a new kind of question answering dataset, OpenBookQA,1 that consists of two parts: Q, a set of 5957 multiple-choice questions, andF , a set of 1326 diverse facts about elementary level science.",1 Introduction,[0],[0]
"F has three key characteristics of an ‘open book’: (a) it forms the basis for generating Q; (b) it has been deemed central to scientific explanations (Jansen et al., 2018); and (c) by itself, F is generally insufficient to answer questions in Q. Faced with a question q ∈ Q, a student or system S is expected retrieve a relevant fact f ∈ F , and appeal to their own common knowledge, KS , when applying f to answer q.
Figure 1 provides an example.",1 Introduction,[0],[0]
"Here, metals are thermal conductors is a core scientific fact available in F .",1 Introduction,[0],[0]
One way to apply this fact to decide whether a steel spoon would let the most heat travel through is to appeal to common knowledge that steel is metallic and heat travels through thermal conductors.,1 Introduction,[0],[0]
"In general, the expected common knowledge is relatively simple (taxonomic facts,
1The dataset and the code for the models are available at http://data.allenai.org/OpenBookQA.
definitions, object properties, etc.); the difficulty lies in identifying it and meaningfully combining it with a core fact from F to answer the question.
",1 Introduction,[0],[0]
OpenBookQA,1 Introduction,[0],[0]
questions are challenging as they require multi-hop reasoning with partial context provided by F .,1 Introduction,[0],[0]
"Specifically, unlike existing datasets for reading comprehension (RC), answering questions on the back of a textbook (TQA),2 as well as question answering over structured knowledge-bases (KBQA), the open book F that comes with OpenBookQA is not self-contained.",1 Introduction,[0],[0]
"A successful system must therefore go beyond the typical challenges such as paraphrase matching and coreference resolution, without benefiting from the canonicalized and complete information in KBQA.
",1 Introduction,[0],[0]
Generating interesting open book questions is a difficult task.,1 Introduction,[0],[0]
"We used a multi-stage process starting with F , using crowd-sourcing to generate (noisy) questions based on F that probe novel situations, using an automatic filter to ensure hardness for retrieval and association based systems, using a crowd filter to ensure answerability by a lay person, and further using an expert filter to ensure higher quality in Dev and Test sets.
",1 Introduction,[0],[0]
"We evaluate a number of existing QA systems for science (without retraining) on OpenBookQA, finding that they perform surprisingly close to the random guessing baseline of 25%.",1 Introduction,[0],[0]
"Human performance, on the other hand, is close to 92%.3
Motivated by recent findings of gameability of NLP datasets (Gururangan et al., 2018), we also develop and evaluate simple, attention-based, neural baselines including a plausible answer detector (which ignores the question text completely) and an odd-one-out solver.",1 Introduction,[0],[0]
"These highlight inevitable human bias in any crowdsourced dataset, increasing performance on OpenBookQA to 48%.
",1 Introduction,[0],[0]
"Building upon a recent neural model for incorporating external knowledge in the story cloze setting (Mihaylov and Frank, 2018), we propose a knowledge-aware neural baseline that can utilize both the open book F and common knowledge retrieved from sources such as ConceptNet (Speer et al., 2017).",1 Introduction,[0],[0]
"While retrieving the most useful pieces of knowledge remains an open challenge, our ‘oracle’ experiments with the fact f used while generating a question q and an interpretation (by
2Only ∼5% of the TQA questions of Kembhavi et al. (2017) require additional common knowledge.
",1 Introduction,[0],[0]
"3To avoid ambiguity in the term ‘human performance’, Section 3.2 describes the specific randomized model we use.
",1 Introduction,[0],[0]
"the question author) of the additional knowledge k needed for q, provides valuable insight into the nature of this dataset: Facts from the open book F are valuable (5% improvement) but not sufficient.",1 Introduction,[0],[0]
"Using both f and k increases the accuracy to 76%, but is still far from human level performance, suggesting the need for non-trivial reasoning to combine these facts.
",1 Introduction,[0],[0]
"To encourage further research on this new task, for each Train and Dev question q, OpenBookQA also includes f as intermediate supervision signal, which may be viewed as a partial explanation for q.",1 Introduction,[0],[0]
We leave closing the large gap to human performance as a challenge for the NLP community.,1 Introduction,[0],[0]
"By construction, answering OpenBookQA questions requires (i) some base science facts from a provided ‘open book’, (ii) broader understanding about the world (common or commonsense knowledge), and (iii) an ability to combine these facts (reasoning).",2 Related Work,[0],[0]
"This setup differs from several existing QA tasks, as summarized below.
",2 Related Work,[0],[0]
Reading Comprehension (RC) datasets have been proposed as benchmarks to evaluate the ability of systems to understand a document by answering factoid-style questions over this document.,2 Related Work,[0],[0]
"These datasets have taken various forms: multiple-choice (Richardson et al., 2013), clozestyle (Hermann et al., 2015; Onishi et al., 2016; Hill et al., 2016), and span prediction (Rajpurkar et al., 2016; Trischler et al., 2017; Joshi et al., 2017)",2 Related Work,[0],[0]
"However, analysis (Chen et al., 2016; Sugawara et al., 2017) of these datasets has shown that many of the questions can be solved with context token matching (Chen et al., 2017a; Weissenborn et al., 2017) or relatively simple paraphrasing.
",2 Related Work,[0],[0]
"To focus on the more challenging problem of reasoning across sentences, new datasets have been proposed for multi-step RC. QAngaroo (Welbl et al., 2018) have used a knowledgebase to identify entity pairs (s, o) with a known relation, r, which is also supported by a multihop path in a set of documents.",2 Related Work,[0],[0]
"They use structured tuple queries (s, r, ?) and use all the documents along the path as the input passage. NarrativeQA",2 Related Work,[0],[0]
"(Kociský et al., 2017) is an RC dataset that has been shown to require an iterative reasoning about the narrative of a story.",2 Related Work,[0],[0]
"Similar to OpenBookQA, the questions were generated to ensure that the answer is not a direct match or paraphrase
that can be retrieved with an IR approach.",2 Related Work,[0],[0]
"Most recently, Khashabi et al. (2018) proposed MultiRC, a multiple-choice RC dataset that is designed to require multi-sentence reasoning and can have multiple correct answers.",2 Related Work,[0],[0]
"Again, like most RC datasets, it is self-contained.
",2 Related Work,[0],[0]
Tasks with external knowledge.,2 Related Work,[0],[0]
"While many of the RC datasets could benefit from commonsense or background knowledge, they are designed to be self-contained, i.e., solvable by the document context alone.",2 Related Work,[0],[0]
"Datasets such as the Story Cloze Test (Mostafazadeh et al., 2016), MCScript,4 and ProPara (Mishra et al., 2018) do require additional domain knowledge about everyday events, scripts, and processes, respectively.",2 Related Work,[0],[0]
"However, these datasets need domain-specific modeling of events, whereas OpenBookQA appeals to broad common knowledge cutting across a variety of types and topics.
",2 Related Work,[0],[0]
Stasaski and Hearst (2017) explore the creation of multi-hop questions and propose generating stronger distractors for the multiple-choice setting.,2 Related Work,[0],[0]
"Their work, however, starts with structured knowledge, specifically a Biology ontology.
",2 Related Work,[0],[0]
"Lastly, many Science Question Answering datasets (e.g. Clark et al., 2016, 2018) have been released that need broad external knowledge to answer the questions.",2 Related Work,[0],[0]
"However, these questions are not associated with a core set of facts, i.e., an “open book” used to define these questions.",2 Related Work,[0],[0]
"As a result, the questions vary widely in style and complexity (Clark et al., 2018).",2 Related Work,[0],[0]
"In contrast, OpenBookQA focuses on a more well-defined subset of science QA, appealing to one core fact from the open book and one (or few) relatively simple commonly known supporting facts.",2 Related Work,[0],[0]
"The OpenBookQA dataset consists of about 6,000 4-way multiple-choice questions, each associated with one core fact from a “book” F of 1326 such facts, and an auxiliary set K of about 6000 additional facts.",3 OpenBookQA Dataset,[0],[0]
"The questions were created via a multi-stage crowdsourcing and partial expert filtering process, discussed in Section 3.1.
",3 OpenBookQA Dataset,[0],[0]
"The small “book” F consists of recurring science themes and principles, each of which can be (and here is) instantiated into multiple questions.
",3 OpenBookQA Dataset,[0],[0]
4SemEval-2018 Task 11: Machine Comprehension using Commonsense Knowledge https://competitions.,3 OpenBookQA Dataset,[0],[0]
"codalab.org/competitions/17184
",3 OpenBookQA Dataset,[0],[0]
"For F , we use a subset of the WorldTree corpus which Jansen et al. (2018) have analyzed for sufficiency for elementary level science.",3 OpenBookQA Dataset,[0],[0]
The subset we use is taken from the 2287 WorldTree facts that were marked as “central” by the original authors in at least one explanation.,3 OpenBookQA Dataset,[0],[0]
"We further filter them down to 1326 that appear general enough to be applicable to multiple situations.
OpenBookQA additionally requires broad common knowledge, which is expected to come from large corpora, such as ConceptNet, Wikipedia, or a corpus with 14M science-related sentences used by some existing baselines.",3 OpenBookQA Dataset,[0],[0]
"The crowdsourcing process below also asks workers to mark a second fact, k, needed for each question q, in addition to f .",3 OpenBookQA Dataset,[0],[0]
"These second facts, unfortunately, were often incomplete, over-complete, or only distantly related to q. We thus include in OpenBookQA the set K of such second facts only as auxiliary data for optional use.",3 OpenBookQA Dataset,[0],[0]
"We emphasize that K should not be viewed as ‘gold’ additional facts, or as a substitute for broad common knowledge.",3 OpenBookQA Dataset,[0],[0]
The overall question generation and filtering pipeline is summarized in Figure 2.,3.1 Crowdsourcing Process,[0],[0]
"Given the “book” F of core facts, the process proceeds as follows, starting with an empty question set Qs and an empty ‘second facts’ set K:
1.",3.1 Crowdsourcing Process,[0],[0]
"A crowd-worker5 w is shown a random science fact f from the set F .
2.",3.1 Crowdsourcing Process,[0],[0]
"w is asked to think of a second common fact, k, that may be combined with f to derive a new, valid assertion s.
3.",3.1 Crowdsourcing Process,[0],[0]
"w then converts s into a question-answer pair and extends this into a 4-way multiple choice question by adding 3 incorrect answer choices, qmc = (q, {c1, c2, c3, c4}), where one of the ci’s is the unique correct answer.
4.",3.1 Crowdsourcing Process,[0],[0]
"The system verifies qmc passes basic checks such as uniformity of answer choices.6
5.",3.1 Crowdsourcing Process,[0],[0]
"w then feeds the multiple-choice question qmc to an information retrieval solver (Clark et al.,
5",3.1 Crowdsourcing Process,[0],[0]
"We used Amazon Mechnical Turk, with workers from North America and with a ‘masters’ level qualification.
",3.1 Crowdsourcing Process,[0],[0]
"6Specifically, it looks for: 1) exactly 4 answer choices; 2) no negation words to trivially fool baselines (no, none, not, isn’t, doesn’t, aren’t, don’t, won’t, except, can’t, shouldn’t, wouldn’t, couldn’t, mustn’t); 3) uniform answer choice length: all with at most 3 or at least 4 words.
2016) and a word association based solver (Turney, 2017), and verifies that (a) neither of them answers qmc correctly and (b) the top 3 IR retrieved sentences are insufficient to answer qmc; if not, the question is edited and re-tried.
",3.1 Crowdsourcing Process,[0],[0]
6.,3.1 Crowdsourcing Process,[0],[0]
"Question qmc is then shown to 5 new crowdworkers, who are asked to answer it.
7.",3.1 Crowdsourcing Process,[0],[0]
"If at least 4 out of 5 workers answer qmc correctly, it is deemed answerable and the process continues.",3.1 Crowdsourcing Process,[0],[0]
"If not, qmc is discarded.
8.",3.1 Crowdsourcing Process,[0],[0]
"The answer choices of qmc are randomly shuffled to avoid unintended bias.7
9. qmc is associated with f as the core science fact and added to the question setQ. k is added to the set K of additional (noisy) facts.
",3.1 Crowdsourcing Process,[0],[0]
The Dev and Test splits were further filtered by an in-house expert to ensure higher quality.,3.1 Crowdsourcing Process,[0],[0]
"To assess human accuracy on this dataset, we consider the following model: Each question q ∈ Q has some (unknown) human accuracy pq, defined as the probability that a random human subject, chosen uniformly from a large pool H, would answer q correctly.",3.2 Human Performance,[0],[0]
"Thus, we can think of this as defining a Bernoulli random variable, Xq ∼ B(pq), whose mean is (unknown) pq.",3.2 Human Performance,[0],[0]
"The average human accuracy on Q under this model is:
H(Q)",3.2 Human Performance,[0],[0]
"= 1 |Q| ∑ q∈Q pq
where {pq | q ∈ Q} are unknown.",3.2 Human Performance,[0],[0]
"With H as the set of crowd-workers (cf. Footnote 5), step 6 of the above question generation 7Choice ‘A’ was the correct answer in 69% of the questions at the end of Step 4.
process is equivalent to obtaining 5 independent samples, Xq,i,",3.2 Human Performance,[0],[0]
i ∈,3.2 Human Performance,[0],[0]
"I, |I| = 5, from B(pq).",3.2 Human Performance,[0],[0]
"We must, however, be careful when using this data to estimate pq, as the same 5 samples were used to decide whether q makes it into the question set Q or not.",3.2 Human Performance,[0],[0]
"For instance, if we had kept only those questions that all 5 workers answered correctly, it would clearly be inaccurate to claim that the human accuracy on Q is 100%.",3.2 Human Performance,[0],[0]
"Nevertheless, it is possible to re-use the judgments from Step 6 to approximate H(Q) with high confidence, without posing the questions to new workers.
",3.2 Human Performance,[0],[0]
"Intuitively, if all questions in Q were difficult to answer (i.e., all pq were small), it would be unlikely that all |Q| questions would pass the test in Step 6.",3.2 Human Performance,[0],[0]
"We can use the contrapositive of this observation to conclude that pq, on average, must have been high for q ∈ Q.
Formally, aggregating across all questions gives the following empirical estimate of H(Q):
H̃(Q) = 1 |Q| ∑ q∈Q 1 |I| ∑ i∈I Xq,i
= 1 |Q||I| ∑
q∈Q,i∈|I|
Xq,i
For analysis, we assume all samplesXq,i are independent, i.e., every answer is obtained independently.8",3.2 Human Performance,[0],[0]
"An application of Hoeffding’s Inequality (Hoeffding, 1963) shows that H̃(Q) converges toH(Q) very rapidly as n = |Q||I| grows; specifically, H̃(Q) ≤ H(Q)+ t with probability at least 1−exp(−2nt2); similarly for H̃(Q) ≥ H(Q)−t.",3.2 Human Performance,[0],[0]
"In our Dev and Test sets, where |Q| = 500 and |I| = 5, this translates into H(Q) being at least
8Realistically, there is some dependence across questions as a single worker may answer multiple questions.",3.2 Human Performance,[0],[0]
"We leave a formal analysis of this setting as future work.
",3.2 Human Performance,[0],[0]
H̃(Q),3.2 Human Performance,[0],[0]
− 3% with probability over 98.8% and at least H̃(Q),3.2 Human Performance,[0],[0]
− 2.5% with prob 95.6%; we report the former as our conservative estimate on human performance.,3.2 Human Performance,[0],[0]
"OpenBookQA consists of 5957 questions, with 4957/500/500 in the Train/Dev/Test splits.9",3.3 Question Set Analysis,[0],[0]
Table 1 summarizes some statistics about the full dataset.,3.3 Question Set Analysis,[0],[0]
Each question has exactly four answer choices and one associated fact used in the creation process.,3.3 Question Set Analysis,[0],[0]
"We report the average length of questions, candidate choices, and associated facts, as well as how often is the longest/shortest choice the correct one.
",3.3 Question Set Analysis,[0],[0]
We analyzed 100 questions in the Train set to capture the kind of common knowledge and reasoning needed.,3.3 Question Set Analysis,[0],[0]
"For each, we wrote down the additional common knowledge needed to answer this question in addition to the original science fact.",3.3 Question Set Analysis,[0],[0]
"In 21% of the cases, the crowdsourced question actually tests for a fact that doesn’t necessarily need the original science fact.",3.3 Question Set Analysis,[0],[0]
"For example, the question: “On a rainy day the clouds are (A) low (B) white (C) small (D) gray” was written based on the science fact “clouds produce rain” but doesn’t need this fact to answer it.",3.3 Question Set Analysis,[0],[0]
We ignore such questions in our analysis.,3.3 Question Set Analysis,[0],[0]
"For the remaining questions, we categorized the additional facts into five high-level categories (and collapsed the remaining facts into a catch-all OTHERS category) based on previous approaches on similar science questions (Clark et al., 2018; Jansen et al., 2016):
1.",3.3 Question Set Analysis,[0],[0]
ISA:,3.3 Question Set Analysis,[0],[0]
"Basic taxonomic facts such as isa(tree, 9Overall, 8140 questions were collected, of which 2183
were discarded in crowdsourcing Step 7.
living thing), isa(granite, rock).",3.3 Question Set Analysis,[0],[0]
2.,3.3 Question Set Analysis,[0],[0]
PROPERTY:,3.3 Question Set Analysis,[0],[0]
"Properties of objects such as
madeof(belt buckle, metal), has(mammals, four legs), contains(lemon juice, citric acid).
3.",3.3 Question Set Analysis,[0],[0]
DEFINITION:,3.3 Question Set Analysis,[0],[0]
"Definitions of objects that may be based on their appearance (tape is a plastic with markings), working mechanism (telescope is a device that uses mirrors to view objects), etc.
4.",3.3 Question Set Analysis,[0],[0]
CAUSAL:,3.3 Question Set Analysis,[0],[0]
"Causal facts such as causes(adding lemon juice to milk, milk to break down).
5.",3.3 Question Set Analysis,[0],[0]
BASIC:,3.3 Question Set Analysis,[0],[0]
"General scientific fact that did not fit above, e.g. squirrels eat nuts for food.
",3.3 Question Set Analysis,[0],[0]
Table 2 presents the proportions of these facts in our analyzed question set.,3.3 Question Set Analysis,[0],[0]
"For each type of fact, we calculate the percentage of questions that need at least one such fact (shown as % Questions).",3.3 Question Set Analysis,[0],[0]
We also calculate the overall percentage of each fact type across all the common knowledge facts (shown as % Facts).,3.3 Question Set Analysis,[0],[0]
"Most of our questions need simple facts such as isa knowledge and properties of objects, further confirming the need for simple reasoning with common knowledge.",3.3 Question Set Analysis,[0],[0]
"Apart from these five major categories of facts, the catch-all OTHERS category contains commonsense facts (e.g., it is dark at night), world knowledge (e.g., Japan is often hit by earthquakes) and lexical rewrites10 (e.g., ad infinitum means over and over).
",3.3 Question Set Analysis,[0],[0]
Most of our questions need simple facts that should be easily retrievable from any knowledgebase/textual corpora.,3.3 Question Set Analysis,[0],[0]
"On an average, each question needed 1.16 additional facts ignoring any linguistic variations.",3.3 Question Set Analysis,[0],[0]
"Despite the simplicity of the knowledge needed for these questions, as we show
10Of course, every question had lexical variations.",3.3 Question Set Analysis,[0],[0]
"We marked it when this was the only change to the core fact.
",3.3 Question Set Analysis,[0],[0]
"empirically, most baseline approaches achieve a relatively low score on this dataset (even when the core fact is provided).",3.3 Question Set Analysis,[0],[0]
We claim that this is due to the fact that the reasoning needed to answer these questions is non-trivial.,3.3 Question Set Analysis,[0],[0]
Table 3 shows few questions with the associated facts and high-level reasoning needed to answer these questions.,3.3 Question Set Analysis,[0],[0]
"Assuming a model can extract the described relations (e.g. defn, contains), the QA system still needs to be able to chain these facts together, identify the resulting relation and verify its expression for each choice.",3.3 Question Set Analysis,[0],[0]
"In the extreme case (as shown in the last example), even though only one additional fact is needed to answer the question, it needs a system to apply the core “general” science fact to a “specific” situation.",3.3 Question Set Analysis,[0],[0]
We evaluate the performance of several baselines systems on the Dev and Test subsets of OpenBookQA.,4 Baseline Models,[0],[0]
"For each question, a solver receives 1 point towards this score if it chooses the correct answer, and 1/k if it reports a k-way tie that includes the correct answer.",4 Baseline Models,[0],[0]
"The “Guess All” baseline, which always outputs a 4-way tie, thus achieves a score of 25%, same as the expected performance of a uniform random baseline.",4 Baseline Models,[0],[0]
"Since OpenBookQA is a set of elementary level science questions, one natural baseline category is existing systems that have proven to be effective on elementary- and middle-school level science exams.","4.1 No Training, External Knowledge Only",[0],[0]
"These pre-trained systems, however, rely only on their background knowledge and do not take the set F of core facts into account.","4.1 No Training, External Knowledge Only",[0],[0]
"Further, their knowledge sources and retrieval mechanism are close to those used by the IR solver that, by design, is guaranteed to fail on OpenBookQA.","4.1 No Training, External Knowledge Only",[0],[0]
"These two aspects place a natural limit on the effectiveness of these solvers on OpenBookQA, despite their excellent fit for the domain of multiplechoice science questions.","4.1 No Training, External Knowledge Only",[0],[0]
"We consider four such solvers.
","4.1 No Training, External Knowledge Only",[0],[0]
"PMI (Clark et al., 2016) uses pointwise mutual information (PMI) to score each answer choice using statistics based on a corpus of 280 GB of plain text.","4.1 No Training, External Knowledge Only",[0],[0]
"It extracts unigrams, bigrams, trigrams, and skip-bigrams from the question q and each answer choice ci.","4.1 No Training, External Knowledge Only",[0],[0]
"Each answer choice is scored based on the average PMI across all pairs of question and
answer n-grams.","4.1 No Training, External Knowledge Only",[0],[0]
"TableILP (Khashabi et al., 2016) is an Integer Linear Programming (ILP) based reasoning system designed for science questions.","4.1 No Training, External Knowledge Only",[0],[0]
It operates over semi-structured relational tables of knowledge.,"4.1 No Training, External Knowledge Only",[0],[0]
It scores each answer choice based on the optimal (as defined by the ILP objective) “support graph” connecting the question to that answer through table rows.,"4.1 No Training, External Knowledge Only",[0],[0]
"The small set of these knowledge tables, however, often results in missing knowledge, making TableILP not answer 24% of the OpenBookQA questions at all.
","4.1 No Training, External Knowledge Only",[0],[0]
"TupleInference (Khot et al., 2017), also an ILP-based QA system, uses Open IE tuples (Banko et al., 2007) as its semi-structured representation.","4.1 No Training, External Knowledge Only",[0],[0]
It builds these subject-verb-object tuples on-the-fly by retrieving text for each question from a large corpus.,"4.1 No Training, External Knowledge Only",[0],[0]
"It then defines an ILP program to combine evidence from multiple tuples.
DGEM (Khot et al., 2018) is a neural entailment model that also uses Open IE to produce a semi-structured representation.","4.1 No Training, External Knowledge Only",[0],[0]
"We use the adaptation of this model to multiple-choice question answering proposed by Clark et al. (2018), which works as follows: (1) convert q and each ci into a hypothesis, hi, and each retrieved fact into a premise pj ; and (2) return the answer choice with the highest entailment score, argmaxi e(pj , hi).","4.1 No Training, External Knowledge Only",[0],[0]
"We also consider providing the set F of core facts to two existing solvers: the IR solver of Clark et al. (2016) (to assess how far simple wordoverlap can get), and the TupleInference solver.",4.2 No Training; F and Extr. Knowledge,[0],[0]
We consider several neural baseline models that are trained using Train set of OpenBookQA.,"4.3 Trained Models, No Knowledge",[0],[0]
"For ease of explanation, we first define the notation used in our models.","4.3 Trained Models, No Knowledge",[0],[0]
"For a given question qmc = (q, {c1, c2, c3, c4}), we define the set of token sequences , S = {q, c1, c2, c3, c4}.","4.3 Trained Models, No Knowledge",[0],[0]
"For each token sequence s ∈ S, wsj is the jth and esj = Emb(wsj ) is the embedding for this token.","4.3 Trained Models, No Knowledge",[0],[0]
We use ns to indicate the number of tokens in s and d for the dimensionality of the embeddings.11 We model multiple-choice QA as multi-class classification:,"4.3 Trained Models, No Knowledge",[0],[0]
"Given qmc, predict one of four class labels L =
11For all experiments we use d = 300 GloVe (Pennington et al., 2014) embeddings pre-trained on 840B tokens from Common Crawl (https://nlp.stanford.edu/projects/glove/).
{1, 2, 3, 4}, where the true label is the correct answer index.
","4.3 Trained Models, No Knowledge",[0],[0]
Embeddings + Similarities as Features.,"4.3 Trained Models, No Knowledge",[0],[0]
"We first experiment with a simple logistic regression model (Mihaylov and Nakov, 2016; Mihaylov and Frank, 2016, 2017) that uses centroid vectors rembs of the word embeddings of tokens in s, and then computes the cosine similarities between the question and each answer choice, rcosq,ci :
rembs = 1
ns ns∑ j=1 esj ∈ Rd
rcosq,ci = cos(r emb q , r emb ci ) ∈","4.3 Trained Models, No Knowledge",[0],[0]
"R 1
For each training instance, we build a feature representations ~f by concatenating these vectors and train an L2 logistic regression classifier:
~f =","4.3 Trained Models, No Knowledge",[0],[0]
"[rembq ; r emb c1..4 ; r cos q,c1..4 ] ∈ R 5d+4
BiLSTM Max-Out Baselines.","4.3 Trained Models, No Knowledge",[0],[0]
"As a simple neural baseline, we adapt BiLSTM max-out model (Conneau et al., 2017) to our QA task.","4.3 Trained Models, No Knowledge",[0],[0]
"That is, we first encode the question tokens and choice tokens ws1...ns , independently with a bi-directional context encoder (LSTM) to obtain a context (ctx) representation hctxs1...","4.3 Trained Models, No Knowledge",[0],[0]
ns = BiLSTM(e s 1...ns) ∈,"4.3 Trained Models, No Knowledge",[0],[0]
Rns×2h,"4.3 Trained Models, No Knowledge",[0],[0]
"Next, we perform an element-wise aggregation operation max on the encoded representations hctxs1..ns to construct a single vector:
rctxs = max(h ctx s1..ns ) ∈ R2h.","4.3 Trained Models, No Knowledge",[0],[0]
"(1)
Given the contextual representations for each token sequence, we experiment with three configurations for using these representations for QA:
(a) Plausible Answer Detector.","4.3 Trained Models, No Knowledge",[0],[0]
This baseline goes to the extreme of completely ignoring q and trying to learn how plausible it is for ci to be the correct answer to some question in this domain.,"4.3 Trained Models, No Knowledge",[0],[0]
"This captures the fact that certain choices like ‘a magical place’ or ‘flying cats’ are highly unlikely to be the correct answer to a science question without negation (which is the case for OpenBookQA).
","4.3 Trained Models, No Knowledge",[0],[0]
"We implement a plausible answer detector using a choice-only model for predicting the answer by obtaining a score αci as: αci = W Tc r ctx ci ∈ R
1, where W Tc ∈ R2h is a weights vector optimized during training, i = {1..4} is the index of the choice.","4.3 Trained Models, No Knowledge",[0],[0]
"To obtain the answer choice from the set of choice scores αc1..4 using argmax(softmax(αc1..4)), where softmax(αci) =
exp(αci )∑4 j=1 exp(αcj ) as usual.
","4.3 Trained Models, No Knowledge",[0],[0]
(b) Odd-One-Out Solver.,"4.3 Trained Models, No Knowledge",[0],[0]
It considers all 4 answer options jointly and selects the one that is least similar to the others.,"4.3 Trained Models, No Knowledge",[0],[0]
This captures bias in human authored questions arising from the fact that creating good quality incorrect answers is difficult.,"4.3 Trained Models, No Knowledge",[0],[0]
"Workers generally start with the correct answer, and then come up with three incorrect ones.","4.3 Trained Models, No Knowledge",[0],[0]
"The latter often tend to be homogeneous or share other common properties (e.g., non-scientific terms) uncharacteristic of the correct answer.
","4.3 Trained Models, No Knowledge",[0],[0]
We implement this using a choice-to-choices attention model.,"4.3 Trained Models, No Knowledge",[0],[0]
"For each choice ci, we calculate the attention to the other choices as αci,cj .","4.3 Trained Models, No Knowledge",[0],[0]
"We then sum these attention values to compute the attention for ci to the rest of the choices, αci2cr(est) , and return the choice with the lowest sum.","4.3 Trained Models, No Knowledge",[0],[0]
"The atten-
tion is computed as αci,cj = Att(r ctx ci , r ctx cj )","4.3 Trained Models, No Knowledge",[0],[0]
"where
Att(u, v) =W T","4.3 Trained Models, No Knowledge",[0],[0]
"([u; v;u · v; |u− v|]) ∈ R1
is a linear attention function and W ∈ R8h is a weight vector.","4.3 Trained Models, No Knowledge",[0],[0]
"We then compute αci2cr(est) =∑4
j=1 αci,cj (j 6= i) and select the answer with the index ac2cr = argmin(softmax(αc1..42cr)).
","4.3 Trained Models, No Knowledge",[0],[0]
(c) Question Match.,"4.3 Trained Models, No Knowledge",[0],[0]
"This solver tries to predict which choice best matches the question (Nakov et al., 2016), without relying on external knowledge.","4.3 Trained Models, No Knowledge",[0],[0]
"To achieve that, we compute an attention score αq,ci between q and each of the choices qi as αq,ci = Att(r ctx q , r ctx ci ), and select the one with the highest score.","4.3 Trained Models, No Knowledge",[0],[0]
"We also experiment with a model where rctxq and r ctx ci are obtained using token-wise interaction proposed in ESIM (Chen et al., 2017b).","4.3 Trained Models, No Knowledge",[0],[0]
"Lastly, we implement a two stage model for incorporating external common knowledge, K. The first module performs information retrieval on K to select a fixed size subset of potentially relevant facts KQ,C for each instance in the dataset (see Appendix A).",4.4 Trained Model with External Knowledge,[0],[0]
"The second module is a neural network that takes (Q, C, KQ,C) as input to predict the answer aq,c to a question Q from the set of choices C.
Knowledge-Enhanced Reader.",4.4 Trained Model with External Knowledge,[0],[0]
"As a base knowledge-aware model, we use a variant of the model of Mihaylov and Frank (2018), implemented by extending our BiLSTM max-out question-match baseline (c).",4.4 Trained Model with External Knowledge,[0],[0]
"For each instance the model reads the question q and answers c1..4 independently and attends to the set of retrieved external knowledge facts KQ,C .",4.4 Trained Model with External Knowledge,[0],[0]
"We encode each fact kj from KQ,C = k1..",4.4 Trained Model with External Knowledge,[0],[0]
"Nk (Nk is the number of facts) with same BiLSTM as used for q and c1..4 and construct a single vector rctxkj ∈ R
2h using Eq. 1.",4.4 Trained Model with External Knowledge,[0],[0]
"Having such representations for each kj results in knowledge memory matrix Mk = rctxk1..Nk
∈ RNk×2h.",4.4 Trained Model with External Knowledge,[0],[0]
"Note that Mk is dynamic memory, specific for each instance in the batch and is encoded in each step during training.",4.4 Trained Model with External Knowledge,[0],[0]
"This memory is used to calculate a knowledge-aware representation, rkns = ∑ ((MTk r ctx s ).Mk) ∈ R2h.",4.4 Trained Model with External Knowledge,[0],[0]
Each context (ctx) representation rctxs (s ∈ S) is combined with rkns to obtain a knowledge-enhanced representation rctx+kns =,4.4 Trained Model with External Knowledge,[0],[0]
(r ctx s + r kn s )/2.,4.4 Trained Model with External Knowledge,[0],[0]
"We then model the knowledge-enhanced attention αknq,ci between
q and ci as a linear combination of the ctx, kn and ctx + kn representations as
αq,ci =W T",4.4 Trained Model with External Knowledge,[0],[0]
"[Att(rctxs , r ctx ci );",4.4 Trained Model with External Knowledge,[0],[0]
"Att(r kn s , r kn ci );
Att(rctx+kns , r ctx ci ); Att(r ctx s , r ctx+kn ci );
Att(rctxs , r kn ci ); Att(r kn",4.4 Trained Model with External Knowledge,[0],[0]
"s , r ctx ci );
Att(rctx+kns ,",4.4 Trained Model with External Knowledge,[0],[0]
"r kn ci ); Att(r kn s , r ctx+kn ci );
Att(rctx+kns , r ctx+kn ci )],
where W ∈ R9 is a weight vector initialized with the ones vector and optimized during training.",4.4 Trained Model with External Knowledge,[0],[0]
We then select the answer ci with the highest score.,4.4 Trained Model with External Knowledge,[0],[0]
"The results for various baseline models are summarized in Table 4, grouped by method category.",5 Baseline Performance,[0],[0]
"We make a few observations:
First, the task is largely solvable by a layperson, as evidenced by the 92% score of crowdworkers.",5 Baseline Performance,[0],[0]
"This is measured as described in Sec-
tion 3.2.",5 Baseline Performance,[0],[0]
We use annotations from Step 6 of the question generation process and report H̃(Q)−3% as a conservative lower estimate.,5 Baseline Performance,[0],[0]
"As an additional assessment, we also obtained 5 new annotations for 100 randomly chosen questions from each of Train, Dev, and Test sets.",5 Baseline Performance,[0],[0]
"The performance remained similar at 88.6%, 90.2%, and 91.6%, resp.
",5 Baseline Performance,[0],[0]
The second group shows that pre-trained state-of-the-art solvers for multiple-choice science questions perform poorly.,5 Baseline Performance,[0],[0]
"One explanation is their correlation with the the IR method used for question filtering, as mentioned in Section 4.1.
",5 Baseline Performance,[0],[0]
"The third group of results suggests that adding F to pre-trained models has a mixed effect, improving TupleInference by 8.7% but not changing DGEM.12 Unlike DGEM, TupleInference relies on brittle word-overlap similarity measures very similar to the ones used by IR.",5 Baseline Performance,[0],[0]
"Since IR (KB) gets 0% by design, TupleInference (KB) also has poor performance and adding F helps it find better support despite the brittle measures.
",5 Baseline Performance,[0],[0]
The fourth group demonstrates that carefully designed trainable neural models—even if simplistic and knowledge-free—can be surprisingly powerful.,5 Baseline Performance,[0],[0]
"For example, the “plausible answer detector” can predict the correct answer with 49.6% accuracy without even looking at the question.",5 Baseline Performance,[0],[0]
"The “odd-one-out” solver, by considering other answer choices, raises this to 50.2%.",5 Baseline Performance,[0],[0]
"The “question match” solver, which simply compares the BiLSTM max-out encoding of the question with that of various answer choices, also achieves 50.2%.13 Similar findings have been reported for several recent datasets (Gururangan et al., 2018), making it imperative to perform such tests early.
",5 Baseline Performance,[0],[0]
"Interestingly, all of these neural knowledge-free baselines simultaneously succeed on 34.4% of the Dev questions, and simultaneously fail on 23.6%.",5 Baseline Performance,[0],[0]
"For Question Match and ESIM we also experiment with ElMo (Peters et al., 2018) which improved their score on Test with 0.4% and 1.8%.
",5 Baseline Performance,[0],[0]
The final group demonstrates the need for external knowledge and deeper reasoning.,5 Baseline Performance,[0],[0]
"When the “oracle” science fact f used by the question author is provided to the knowledge-enhanced reader,
12By design, IR with its default corpus gets 0% on OpenBookQA.",5 Baseline Performance,[0],[0]
"Hence we don’t consider the effect of adding F , which appears artificially magnified.
",5 Baseline Performance,[0],[0]
"13This model also achieves the current best score, 33.87%, on the ARC Reasoning Challenge (Clark et al., 2018).",5 Baseline Performance,[0],[0]
"When adapted for the textual entailment task by comparing BiLSTM max-out encodings of premise and hypothesis, it achieves 85% on the SciTail dataset (Khot et al., 2018).
",5 Baseline Performance,[0],[0]
it improves over the knowledge-less models by about 5%.,5 Baseline Performance,[0],[0]
"However, there is still a large gap, showing that the core fact is insufficient to answer the question.",5 Baseline Performance,[0],[0]
"When we also include facts retrieved from WordNet (Miller et al., 1990), the score improves by about 0.5%.",5 Baseline Performance,[0],[0]
"Unlike the WordNet gain, adding ConceptNet (Speer et al., 2017) introduces a distraction and reduces the score.",5 Baseline Performance,[0],[0]
"This suggests that ConceptNet is either not a good source of knowledge for our task, or only a subset of its relations should be considered.",5 Baseline Performance,[0],[0]
"Overall, external knowledge helps, although retrieving the right bits of knowledge remains difficult.",5 Baseline Performance,[0],[0]
"In the last row of Table 4, we use the oracle core fact along with question author’s interpretation of the additional fact k.",5 Baseline Performance,[0],[0]
"This increases the scores substantially, to about 76%.",5 Baseline Performance,[0],[0]
This big jump shows that improved knowledge retrieval should help on this task.,5 Baseline Performance,[0],[0]
"At the same time, we are still not close to the human performance level of 92% due to various reasons: (a) the additional fact needed can be subjective, as hinted at by our earlier analysis; (b) the authored facts K tend to be noisy (incomplete, over-complete, or only distantly related), also as mentioned earlier; and (b) even given the true gold facts, performing reliable “reasoning” to link them properly remains a challenge.
",5 Baseline Performance,[0],[0]
Sample predictions and analysis of questions from Dev are provided in Appendix D.,5 Baseline Performance,[0],[0]
"We present a new dataset, OpenBookQA, of about 6000 questions for open book question answering.",6 Conclusion,[0],[0]
The task focuses on the challenge of combining a corpus of provided science facts (open book) with external broad common knowledge.,6 Conclusion,[0],[0]
"We show that this dataset requires simple common knowledge beyond the provided core facts, as well as multihop reasoning combining the two.",6 Conclusion,[0],[0]
"While simple neural methods are able to achieve an accuracy of about 50%, this is still far from the human performance of 92% on this task.",6 Conclusion,[0],[0]
"We leave closing this gap for future research, and illustrate, via oraclestyle experiments, the potential of better retrieval and reasoning on this task.",6 Conclusion,[0],[0]
"The authors would like to thank Lane Aasen for helping develop the infrastructure for the crowdsourcing task, and Madeleine van Zuylen for providing expert annotation for the Dev and Test questions.",Acknowledgments,[0],[0]
"We present a new kind of question answering dataset, OpenBookQA, modeled after open book exams for assessing human understanding of a subject.",abstractText,[0],[0]
The open book that comes with our questions is a set of 1326 elementary level science facts.,abstractText,[0],[0]
Roughly 6000 questions probe an understanding of these facts and their application to novel situations.,abstractText,[0],[0]
"This requires combining an open book fact (e.g., metals conduct electricity) with broad common knowledge (e.g., a suit of armor is made of metal) obtained from other sources.",abstractText,[0],[0]
"While existing QA datasets over documents or knowledge bases, being generally self-contained, focus on linguistic understanding, OpenBookQA probes a deeper understanding of both the topic—in the context of common knowledge—and the language it is expressed in.",abstractText,[0],[0]
"Human performance on OpenBookQA is close to 92%, but many state-of-the-art pre-trained QA methods perform surprisingly poorly, worse than several simple neural baselines we develop.",abstractText,[0],[0]
Our oracle experiments designed to circumvent the knowledge retrieval bottleneck demonstrate the value of both the open book and additional facts.,abstractText,[0],[0]
We leave it as a challenge to solve the retrieval problem in this multi-hop setting and to close the large gap to human performance.,abstractText,[0],[0]
Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 92–105 New Orleans, Louisiana, June 1 - 6, 2018. c©2017 Association for Computational Linguistics",text,[0],[0]
"In commercial scenarios of neural machine translation (NMT), the one-best translation of a text is shown to multiple users who can reinforce highquality (or penalize low-quality) translations by explicit feedback (e.g., on a Likert scale) or implicit feedback (by clicking on a translated page).",1 Introduction,[0],[0]
In such settings this type of feedback can be easily collected in large amounts.,1 Introduction,[0],[0]
"While bandit feedback1 in form of user clicks on displayed ads is the standard learning signal for response prediction in online advertising (Bottou et al., 2013), bandit learning for machine translation has so far been restricted to simulation experiments (Sokolov et al., 2016b; Lawrence et al., 2017b;
∗The work for this paper was done while the first author was an intern at eBay.
",1 Introduction,[0],[0]
"1The fact that only feedback for a single translation is collected constitutes the “bandit feedback” scenario where the name is inspired by “one-armed bandit” slot machines.
",1 Introduction,[0],[0]
"Nguyen et al., 2017; Kreutzer et al., 2017; Bahdanau et al., 2017).
",1 Introduction,[0],[0]
The goal of our work is to show that the gold mine of cheap and abundant real-world human bandit feedback can be exploited successfully for machine learning in NMT.,1 Introduction,[0],[0]
We analyze and utilize human reinforcements that have been collected from users of the eBay e-commerce platform.,1 Introduction,[0],[0]
We show that explicit user judgments in form of fivestar ratings are not reliable and do not lead to downstream BLEU improvements in bandit learning.,1 Introduction,[0],[0]
"In contrast, we find that implicit task-based feedback that has been gathered in a cross-lingual search task can be used successfully to improve task-specific metrics and BLEU.
",1 Introduction,[0],[0]
Another crucial difference of our work to previous research is the fact that we assume a counterfactual learning scenario where human feedback has been given to a historic system different from the target system.,1 Introduction,[0],[0]
"Learning is done offline from logged data, which is desirable in commercial settings where system updates need to be tested before deployment and the risk of showing inferior translations to users needs to be avoided.",1 Introduction,[0],[0]
"Our offline learning algorithms range from a simple bandit-to-supervised conversion (i.e., using translations with good feedback for supervised tuning) to transferring the counterfactual learning techniques presented by Lawrence et al. (2017b) from statistical machine translation (SMT) to NMT models.",1 Introduction,[0],[0]
"To our surprise, the bandit-to-supervised conversion proved to be very hard to beat, despite theoretical indications of poor generalization for exploration-free learning from logged data (Langford et al., 2008; Strehl et al., 2010).",1 Introduction,[0],[0]
"However, we show that we can further improve over this method by computing a task-specific reward scoring function, resulting in significant improvements in both BLEU and in task-specific metrics.
92",1 Introduction,[0],[0]
"Sokolov et al. (2016a,b) introduced learning from bandit feedback for SMT models in an interactive online learning scenario: the MT model receives a source sentence from the user, provides a translation, receives feedback from the user for this translation, and performs a stochastic gradient update proportional to the feedback quality.",2 Related Work,[0],[0]
Kreutzer et al. (2017) showed that the objectives proposed for log-linear models can be transferred to neural sequence learning and found that standard control variate techniques do not only reduce variance but also help to produce best BLEU results.,2 Related Work,[0],[0]
Nguyen et al. (2017) proposed a very similar approach using a learned word-based critic in an advantage actor-critic reinforcement learning framework.,2 Related Work,[0],[0]
"A comparison of current approaches was recently performed in a shared task where participants had to build translation models that learn from the interaction with a service that provided e-commerce product descriptions and feedback for submitted translations (Sokolov et al., 2017).",2 Related Work,[0],[0]
"Lawrence et al. (2017b,a) were the first to address the more realistic problem of offline learning from logged bandit feedback, with special attention to the problem of exploration-free deterministic logging as is done in commercial MT systems.",2 Related Work,[0],[0]
"They show that variance reduction techniques used in counterfactual bandit learning (Dudı́k et al., 2011; Bottou et al., 2013) and off-policy reinforcement learning (Precup et al., 2000; Jiang and Li, 2016) can be used to avoid degenerate behavior of estimators under deterministic logging.",2 Related Work,[0],[0]
One way to collect reinforcement signals from human users of the eBay platform is by explicit ratings of product title translations on a five-point Likert scale.,3.1 Explicit Feedback via Star Ratings,[0],[0]
"More specifically, when users visit product pages with translated titles, they can inspect the source when hovering with the mouse over the title.",3.1 Explicit Feedback via Star Ratings,[0],[0]
Then five stars are shown with the instruction to ‘rate this translation’.,3.1 Explicit Feedback via Star Ratings,[0],[0]
A screenshot of an implementation of this rating interface is shown in Figure 1.,3.1 Explicit Feedback via Star Ratings,[0],[0]
"The original title, the translation and the given star rating are stored.",3.1 Explicit Feedback via Star Ratings,[0],[0]
"For the experiments in this paper, we focus on translations from English to Spanish.",3.1 Explicit Feedback via Star Ratings,[0],[0]
"The user star rating data set contains 69,412 rated product titles with 148k
individual ratings.",3.1 Explicit Feedback via Star Ratings,[0],[0]
"Since 34% of the titles were rated more than once, the ratings for each title are averaged.",3.1 Explicit Feedback via Star Ratings,[0],[0]
"We observe a tendency towards high ratings, in fact one half of the titles are rated with five stars (cf. Appendix C).
",3.1 Explicit Feedback via Star Ratings,[0],[0]
"To investigate the reliability and validity of these ratings, we employed three bilingual annotators (‘experts’) to independently re-evaluate and give five-star ratings for a balanced subset of 1,000 product title translations.",3.1 Explicit Feedback via Star Ratings,[0],[0]
"The annotators were presented the source title and the machine translation, together with instructions on the task provided in Appendix B.",3.1 Explicit Feedback via Star Ratings,[0],[0]
The inter-annotator agreement between experts is relatively low with Fleiss’ κ = 0.12,3.1 Explicit Feedback via Star Ratings,[0],[0]
"(Fleiss, 1971).",3.1 Explicit Feedback via Star Ratings,[0],[0]
"Furthermore, there is no correlation of the averaged ‘expert’ ratings and the averaged user star ratings (Spearman’s ρ = −0.05).",3.1 Explicit Feedback via Star Ratings,[0],[0]
"However, when we ask another three annotators to indicate whether they agree or disagree with a balanced subset of 2,000 user ratings, they agree with 42.3% of the ratings (by majority voting).",3.1 Explicit Feedback via Star Ratings,[0],[0]
"In this binary meta-judgment task, the interannotator agreement between experts is moderate with κ = 0.45.",3.1 Explicit Feedback via Star Ratings,[0],[0]
We observe a strong tendency of the expert annotators to agree with high user ratings and to disagree with low user ratings.,3.1 Explicit Feedback via Star Ratings,[0],[0]
"Two examples of user ratings, expert ratings and expert judgment are given in Table 1.",3.1 Explicit Feedback via Star Ratings,[0],[0]
"In the first example, all raters agree that the translation is good, but in the second example, there is a strong disagreement between users and experts.
",3.1 Explicit Feedback via Star Ratings,[0],[0]
"This analysis shows that it is generally not easy for non-professional users of the e-commerce platform, and even for expert annotators, to give star ratings of translations in the domain of usergenerated product titles with high reliability.",3.1 Explicit Feedback via Star Ratings,[0],[0]
"This problem is related to low validity, i.e., we do not know whether the users’ response actually expresses translation quality, since we cannot control the influence of other factors on their judgment, e.g., the displayed image (see Figure 1), the prod-
uct itself, or the users’ general satisfaction with the e-commerce transaction, nor can we exclude the possibility that the user judgment is given with an adversarial purpose.",3.1 Explicit Feedback via Star Ratings,[0],[0]
"Furthermore, we do not have control over the quality of sources2, nor can we discern to which degree a user rating reflects fluency or adequacy of the translation.",3.1 Explicit Feedback via Star Ratings,[0],[0]
Another form of collecting human reinforcement signals via the eBay e-commerce platform is to embed the feedback collection into a cross-lingual information retrieval task.,3.2 Task-Based Implicit Feedback,[0],[0]
"The product title translation system is part of the search interaction of a user with the e-commerce platform in the following way: When a user enters a query in Spanish, it is first translated to English (query translation), then a search engine retrieves a list of matching products, and their titles are translated to Spanish and displayed to the user.",3.2 Task-Based Implicit Feedback,[0],[0]
"As soon as the user clicks on one of the translated titles, we store the original query, the translated query, the source product title and its translation.",3.2 Task-Based Implicit Feedback,[0],[0]
"From this collection we filter the cases where (a) the original query and the translated query are the same, or (b) more than 90% of the words from the query translation are not contained in the retrieved source title.",3.2 Task-Based Implicit Feedback,[0],[0]
"In this way, we attempt to reduce the propagation of errors in query translation and search.",3.2 Task-Based Implicit Feedback,[0],[0]
"This leaves us with a dataset of 164,065 tuples of Spanish queries, English product titles and their Spanish translations (15% of the original collection).",3.2 Task-Based Implicit Feedback,[0],[0]
Note that this dataset is more than twice the size of the explicit feedback dataset.,3.2 Task-Based Implicit Feedback,[0],[0]
"An example is given in Table 2.
",3.2 Task-Based Implicit Feedback,[0],[0]
"The advantage of embedding feedback collection into a search task is that we can assume that users who formulate a search query have a genuine intent of finding products that fit their need, and are also likely to be satisfied with product title translations that match their query, i.e., contain
2Most titles consist of a sequence of keywords rather than a fluent sentence.",3.2 Task-Based Implicit Feedback,[0],[0]
"See Calixto et al. (2017) for a fluency analysis of product titles.
terms from the query in their own language.",3.2 Task-Based Implicit Feedback,[0],[0]
"We exploit this assumption in order to measure the quality of a product title translation by requiring a user to click on the translation when it is displayed as a result of the search, and then quantifying the quality of the clicked translation by the extent it matches the query that led the user to the product.",3.2 Task-Based Implicit Feedback,[0],[0]
"For this purpose, we define a word-based matching function match(w,q) that evaluates whether a query q contains the word",3.2 Task-Based Implicit Feedback,[0],[0]
"w:
match(w,q) = { 1, ifw ∈ q 0, otherwise.
",3.2 Task-Based Implicit Feedback,[0],[0]
"(1)
Based on this word-level matching, we compute a sequence-level reward for a sentence y of length T as follows:
recall(y,q)",3.2 Task-Based Implicit Feedback,[0],[0]
"= 1
T
T∑
t=1
match(yt,q).",3.2 Task-Based Implicit Feedback,[0],[0]
(2),3.2 Task-Based Implicit Feedback,[0],[0]
Reward Functions.,4 Learning from User Feedback,[0],[0]
"In reinforcement and bandit learning, rewards received from the environment are used as supervision signals for learning.",4 Learning from User Feedback,[0],[0]
"In our experiments, we investigate several options to obtain a reward function ∆ : Y",4 Learning from User Feedback,[0],[0]
"→ [0, 1] from logged human bandit feedback:
1.",4 Learning from User Feedback,[0],[0]
Direct User Reward:,4 Learning from User Feedback,[0],[0]
"Explicit feedback, e.g., in the form of star ratings, can directly be used as reward by treating the reward function as a black box.",4 Learning from User Feedback,[0],[0]
"Since human feedback is usually only available for one translation per input, learning from direct user rewards requires the use of bandit learning algorithms.",4 Learning from User Feedback,[0],[0]
"In our setup, human bandit feedback has been collected for translations of a historic MT system different from the target system to be optimized.",4 Learning from User Feedback,[0],[0]
"This restricts the learning setup to offline learning from logged bandit feedback.
2.",4 Learning from User Feedback,[0],[0]
Reward Scoring Function:,4 Learning from User Feedback,[0],[0]
"A possibility to use human bandit feedback to obtain rewards for more than a single translation per input is
to score translations either against a logged reference or a logged query.",4 Learning from User Feedback,[0],[0]
The first option requires a bandit-to-supervised conversion of data where high-quality logged translations are used as references against which BLEU or other MT quality metrics can be measured.,4 Learning from User Feedback,[0],[0]
"The second option uses logged queries to obtain a matching score as in Equation 2.
3.",4 Learning from User Feedback,[0],[0]
Estimated Reward:,4 Learning from User Feedback,[0],[0]
"Another option to extend bandit feedback to all translations is to learn a parametric model of rewards, e.g., by optimizing a regression objective.",4 Learning from User Feedback,[0],[0]
"The reward function is known, but the model parameters need to be trained based on a history of direct user rewards or by evaluations of a reward scoring function.
",4 Learning from User Feedback,[0],[0]
"In the following, we present how rewards can be integrated in various objectives for NMT training.
",4 Learning from User Feedback,[0],[0]
Maximum Likelihood Estimation by Banditto-Supervised Conversion.,4 Learning from User Feedback,[0],[0]
"Most commonly, NMT models are trained with Maximum Likelihood Estimation (MLE, Equation 3) on a given parallel corpus of source and target sequences D = {(x(s),y(s))}Ss=1
LMLE(θ)",4 Learning from User Feedback,[0],[0]
"=
S∑
s=1
log pθ(y (s)|x(s)).",4 Learning from User Feedback,[0],[0]
"(3)
The MLE objective requires reference translations and is agnostic to rewards.",4 Learning from User Feedback,[0],[0]
"However, in a banditto-supervised conversion, rewards can be used to filter translations to be used as pseudo-references for MLE training.",4 Learning from User Feedback,[0],[0]
"We apply this scenario to explicit and implicit human feedback data in our experiments.
",4 Learning from User Feedback,[0],[0]
Reinforcement Learning by Minimum Risk Training.,4 Learning from User Feedback,[0],[0]
"When rewards can be obtained for several translations per input instead of only for one as in the bandit setup, by using a reward estimate or scoring function, Minimum Risk Training (MRT, Equation 4) can be applied to optimize
NMT from rewards.
RMRT(θ)",4 Learning from User Feedback,[0],[0]
"= S∑
s=1
∑
ỹ∈S(x(s))",4 Learning from User Feedback,[0],[0]
"qαθ (ỹ|x(s)) ∆(ỹ), (4)
where sample probabilities are renormalized over a subset of translation samples S(x) ⊂ Y(x): qαθ (ỹ|x) = pθ(ỹ|x)α∑ y′∈S(x)",4 Learning from User Feedback,[0],[0]
"pθ(y
′|x)α .",4 Learning from User Feedback,[0],[0]
"The hyperparameter α controls the sharpness of q (see Shen et al. (2016)).
",4 Learning from User Feedback,[0],[0]
"With sequence-level rewards, all words of a translation of length T are reinforced to the same extent and are treated as if they contributed equally to the translation quality.",4 Learning from User Feedback,[0],[0]
"A word-based reward function, such as the match with a given query (Equation 1), allows the words to have individual weights.",4 Learning from User Feedback,[0],[0]
"The following modification of the sequence-level MRT objective (Equation 4) accounts for word-based rewards ∆(yt):
RW-MRT(θ) = S∑
s=1
∑
ỹ∈S(x(s))
",4 Learning from User Feedback,[0],[0]
"T∏
t=1 [ qαθ (ỹt|x(s), ỹ<t) ∆(yt) ] , (5)
where ∆(yt) in our experiments is a matching score (1).",4 Learning from User Feedback,[0],[0]
"In the following we use the bracketed prefix (W-) to subsume both sentence-level and word-level training objectives.
",4 Learning from User Feedback,[0],[0]
"When output spaces are large and reward functions sparse, (W-)MRT objectives typically benefit from a warm start, i.e., pre-training with MLE.",4 Learning from User Feedback,[0],[0]
"Following Wu et al. (2016), we furthermore adopt a linear combination of MLE and (W-)MRT to stabilize learning:
R(W-)MIX(θ)",4 Learning from User Feedback,[0],[0]
"= λ ·RMLE(θ) +R(W-)MRT(θ).
",4 Learning from User Feedback,[0],[0]
Counterfactual Learning by Deterministic Propensity Matching.,4 Learning from User Feedback,[0],[0]
"Counterfactual learning attempts to improve a target MT system from a log of source sentences, translations produced by a historic MT system, and obtained feedback L = {(x(h),y(h),∆(y(h)))}Hh=1.",4 Learning from User Feedback,[0],[0]
"For the special case of deterministically logged rewards
Lawrence et al. (2017b) introduced the Deterministic Propensity Matching (DPM) objective with self-normalization as a multiplicative control variate (Swaminathan and Joachims, 2015):3
RDPM(θ)",4 Learning from User Feedback,[0],[0]
"= 1
H
H∑
h=1
∆(y(h))",4 Learning from User Feedback,[0],[0]
"p̄θ(y (h)|x(h)), (6)
where translation probabilities are reweighted over the current mini-batch B ⊂ H,B H: p̄θ(y
(h)|x(h))",4 Learning from User Feedback,[0],[0]
= pθ(y(h)|x(h))∑B b=1 pθ(y,4 Learning from User Feedback,[0],[0]
(b)|x(b)) .,4 Learning from User Feedback,[0],[0]
"We addi-
tionally normalize the log probability of a translation y by its length |y|: pnormθ (y|x) = exp ( log pθ(y|x)|y| ).
",4 Learning from User Feedback,[0],[0]
Counterfactual Learning by Doubly Controlled Estimation.,4 Learning from User Feedback,[0],[0]
"Lawrence et al. (2017b) furthermore propose the Doubly Controlled objective (DC, Equation 7) implementing the idea of doubly robust estimation (Dudı́k et al., 2011; Jiang and Li, 2016) for deterministic logs.",4 Learning from User Feedback,[0],[0]
"In addition to learning from the historic reward for the logging system, the reward for other translations is estimated by a parametrized regression model that is trained on the log ∆̂φ : Y",4 Learning from User Feedback,[0],[0]
"→ [0, 1].",4 Learning from User Feedback,[0],[0]
"This objective contains both a multiplicative (probability reweighting) and an additive (reward estimate) control variate, hence the name.4
RDC(θ) = 1
H
H∑
h=1
[( ∆(y(h))− ∆̂φ(y(h)) )
× p̄θ(y(h)|x(h))",4 Learning from User Feedback,[0],[0]
+,4 Learning from User Feedback,[0],[0]
"∑
y∈S(x(h))",4 Learning from User Feedback,[0],[0]
"∆̂φ(y) pθ(y|x(h))
",4 Learning from User Feedback,[0],[0]
"]
(7)
",4 Learning from User Feedback,[0],[0]
"As for MRT, the expectation over the full output space is approximated with a subset of k sample translations S(x) ⊂ Y(x).
",4 Learning from User Feedback,[0],[0]
Relative Rewards.,4 Learning from User Feedback,[0],[0]
"With the objectives as defined above, gradient steps are dependent on the magnitude of the reward for the current training instance.",4 Learning from User Feedback,[0],[0]
"In reinforcement learning, an average reward baseline is commonly subtracted from the current reward with the primary goal to reduce variance (Williams, 1992).",4 Learning from User Feedback,[0],[0]
"As a side effect, the
3Lawrence et al. (2017b) propose reweighting over the whole log, but this is infeasible for NMT.",4 Learning from User Feedback,[0],[0]
"For simplicty we refer to their DPM-R objective as DPM, and DC-R as DC.
",4 Learning from User Feedback,[0],[0]
"4We find empirically that estimating ĉ over the current batch as in objective ĉDC in (Lawrence et al., 2017b) does not improve over the simple setting with c = 1.
current reward is relativized, such that the gradient step is not only determined by the magnitude of the current rewards, but is put into relation with previous rewards.",4 Learning from User Feedback,[0],[0]
We found this effect to be particularly beneficial in experiments with suboptimal reward estimators or noisy rewards and therefore apply it to all instantiations of the DPM and DC objectives.,4 Learning from User Feedback,[0],[0]
"For DPM, the running average of historic rewards ∆̄h = 1 h ∑h i=1 ∆(y
(i)) is subtracted from the current reward.",4 Learning from User Feedback,[0],[0]
"For DC we apply this to both types of rewards in Equation 7: 1) the logged reward ∆(y(h)), from which we subtract its running average ∆̄h instead of the estimated reward ∆̂φ(y(h)), and 2) the estimated reward ∆̂φ(y), from which we hence subtract the average estimated reward ¯̂ ∆h = 1 h ∑h i=1 1 k ∑ y′∈S(x(i)) ∆̂φ(y ′).",4 Learning from User Feedback,[0],[0]
"In our experiments, learning from feedback starts from a pre-trained English to Spanish NMT model that has not seen in-domain data (i.e., no product title translations).",5.1 NMT Model,[0],[0]
"The NMT baseline model (BL) is a standard subword-based encoder-decoder architecture with attention (Bahdanau et al., 2015), implemented with TensorFlow (Abadi et al., 2015).",5.1 NMT Model,[0],[0]
"The model is trained with MLE on 2.7M parallel sentences of out-of-domain data until the early stopping point which is determined on a small in-domain dev set of 1,619 product title translations.",5.1 NMT Model,[0],[0]
"A beam of size 12 and length normalization (Wu et al., 2016) are used for beam search decoding.",5.1 NMT Model,[0],[0]
"For significance tests we used approximate randomization (Clark et al., 2011), for BLEU score evaluation (lowercased) the multi-bleu script of the Moses decoder (Koehn et al., 2007), for TER computation the tercom tool (Snover et al., 2006).",5.1 NMT Model,[0],[0]
"For MRT, DC and (W)MIX models we set k = 5, for (W-)MIX models λ = 0.5 and α = 0.05.",5.1 NMT Model,[0],[0]
"For all NMT models involving random sampling, we report average results and standard deviation (in subscript) over two runs.",5.1 NMT Model,[0],[0]
Further details about training data and hyperparameters settings are described in Appendix D.,5.1 NMT Model,[0],[0]
"The model architecture for the reward estimator used in the DC objective is a bilingual extension of the convolutional neural network (CNN) for
sentence classification proposed by Kim (2014).",5.2 Reward Estimator,[0],[0]
"Both source and target sequences are padded up to a pre-defined maximum sequence length Tmax, their embeddings are concatenated and further processed by a 1D-Convolution over the time dimension with several filters of sizes from 2 to 15, which is then followed by a max-over-time pooling and fed to a fully-connected output layer (Figure 2).",5.2 Reward Estimator,[0],[0]
"The model is trained to minimize the mean squared error (MSE) on the training portion of the logged feedback data (60k for simulated sentenceBLEU feedback, 62,470 for star rating feedback).",5.2 Reward Estimator,[0],[0]
The word embeddings of the reward estimator are initialized by the word embeddings of the trained baseline NMT system and fine-tuned further together with the other CNN weights.,5.2 Reward Estimator,[0],[0]
"The best parameters are identified by early-stopping on the validation portion of the feedback data (2,162 for the simulation, 6,942 for the star ratings).",5.2 Reward Estimator,[0],[0]
"Please find a detailed description of the model’s hyperparameters in Appendix D.4.
Results for a stand-alone evaluation of the reward estimator on the validation portions of the feedback data are given in Table 3.",5.2 Reward Estimator,[0],[0]
The estimator models sBLEU much more accurately than the user star ratings.,5.2 Reward Estimator,[0],[0]
This is due to large variance and skew of the user ratings.,5.2 Reward Estimator,[0],[0]
"An MSE-trained estimator typically predicts values around the mean, which is not a suitable strategy for such a skewed distribution of labels, but is successful for the prediction of normal-distributed sBLEU.",5.2 Reward Estimator,[0],[0]
Counterfactual Bandit Learning.,5.3 Explicit Star Rating Feedback,[0],[0]
"As shown in Table 4, counterfactual learning with DPM and DC on the logged star ratings as direct reward does not yield improvements over the baseline model in terms of corpus BLEU or TER.",5.3 Explicit Star Rating Feedback,[0],[0]
"A randomization of feedback signals for translations gives the same results (DPM-random), showing that counterfactual learning from logged star ratings is equivalent to learning from noise.",5.3 Explicit Star Rating Feedback,[0],[0]
"Evaluating the models in terms of estimated user reward, however, we find an improvement of +1.49 for DC, +0.04 for DPM over the baseline (53.93) (not shown in Table 4)— but these improvements do not transfer to BLEU because the reward model largely over-estimates the translation quality of translations with major faults.",5.3 Explicit Star Rating Feedback,[0],[0]
"Hence it is not desirable to optimize towards this signal directly.
",5.3 Explicit Star Rating Feedback,[0],[0]
Bandit-to-Supervised Conversion.,5.3 Explicit Star Rating Feedback,[0],[0]
"In the following setup, we utilize the user ratings to filter the log by using only five star rated translations, and perform supervised learning of MLE and MIX using sBLEU against pseudo-references as reward function.",5.3 Explicit Star Rating Feedback,[0],[0]
"Table 4 shows that this filtering strategy leads to large improvements over the baseline, for MLE and even more for MIX, even though the data set size is reduced by 42%.",5.3 Explicit Star Rating Feedback,[0],[0]
"However, around the same improvements can be achieved with a random selection of logged translations of the same size (MIX small, containing 55% fivestar ratings).",5.3 Explicit Star Rating Feedback,[0],[0]
Using all logged translations for training MIX achieves the best results.,5.3 Explicit Star Rating Feedback,[0],[0]
"This suggests that the model does not profit from the feedback, but mostly from being exposed to in-domain translations of the logging system.",5.3 Explicit Star Rating Feedback,[0],[0]
"This effect is similar to training on pseudo-references created by back-translation (Sennrich et al., 2016b,a).",5.3 Explicit Star Rating Feedback,[0],[0]
Bandit-to-Supervised Conversion.,5.4 Task-Based Implicit Feedback,[0],[0]
We apply the same filtering technique to the logged implicit feedback by treating translations with recall = 1 as references for training MIX with sBLEU (reduction of the data set by 62%).,5.4 Task-Based Implicit Feedback,[0],[0]
"The results in Table 5 show that large improvements over the baseline can be obtained even without filtering, BLEU and TER scores being comparable to the ones observed for training on explicit user ratings.
",5.4 Task-Based Implicit Feedback,[0],[0]
Task-based Feedback.,5.4 Task-Based Implicit Feedback,[0],[0]
The key difference between the implicit feedback collected in the query-,5.4 Task-Based Implicit Feedback,[0],[0]
"title data and the explicit user ratings, is that it can be used to define reward functions like recall or match (Equations 2, 1).",Model Test BLEU Test TER,[0],[0]
"For the experiments we train W-MIX, the word-based MRT objective (Equation 5) linearly combined with MLE, on the logged translations accompanying the queries (160k sentences).",Model Test BLEU Test TER,[0],[0]
"This combination is essential here, since the model would otherwise learn to produce translations that contain nothing but the query words.",Model Test BLEU Test TER,[0],[0]
"To account for usergenerated language in the queries and subwords in the MT model, we soften the conditions for a match, counting tokens as a match that are part of a word w that is either contained in the query, or has edit distance to a word in the query with dist(w,qi) < max(3, 0.3× |w|).
",Model Test BLEU Test TER,[0],[0]
"Table 6 repeats the best MIX results from Table 4 and 5, and evaluates the models with respect to query recall.",Model Test BLEU Test TER,[0],[0]
We also report the query recall for the logged translations and the out-of-domain baseline.,Model Test BLEU Test TER,[0],[0]
These results are compared to W-MIX training on implicit feedback data described in Sec-,Model Test BLEU Test TER,[0],[0]
tion 3.2.,65.33 45.96 62.92±0.56 63.21±0.24 68.12±0.27,[0],[0]
"The development portion of the querytitle dataset contains 4,065 sentences, the test set 2,000 sentences, which is used for query recall evaluation.",65.33 45.96 62.92±0.56 63.21±0.24 68.12±0.27,[0],[0]
The W-MIX model shows the largest improvement in query recall (12% points) and BLEU (6 points) over the baseline out of all tested learning approaches.,65.33 45.96 62.92±0.56 63.21±0.24 68.12±0.27,[0],[0]
"It comes very close to the BLEU/TER results of the model trained on indomain references, but surpasses its recall by far.",65.33 45.96 62.92±0.56 63.21±0.24 68.12±0.27,[0],[0]
"This is remarkable since the model does not use any human generated references, only logged data of task-based human feedback.",65.33 45.96 62.92±0.56 63.21±0.24 68.12±0.27,[0],[0]
Appendix F contains a set of examples illustrating what the WMIX learned.,65.33 45.96 62.92±0.56 63.21±0.24 68.12±0.27,[0],[0]
We presented methods to improve NMT from human reinforcement signals.,6 Conclusion,[0],[0]
The signals were logged from user activities of an e-commerce platform and consist of explicit ratings on a five-point Likert scale and implicit task-based feedback collected in a cross-lingual search task.,6 Conclusion,[0],[0]
"We found that there are no improvements when learning from user star ratings, unless the noisy ratings themselves are stripped off in a bandit-to-supervised conversion.",6 Conclusion,[0],[0]
"Implicit task-based feedback can be used successfully as a reward signal for NMT optimization, leading to improvements both in terms of enforcing individual word translations and in terms of automatic evaluation measures.",6 Conclusion,[0],[0]
"In the future, we plan transfer these findings to production settings by performing regular NMT model updates with batches of collected user behavior data, especially focusing on improving translation of ambiguous and rare terms based on rewards from implicit partial feedback.",6 Conclusion,[0],[0]
The last author was supported in part by DFG Research Grant RI 2221/4-1.,Acknowledgements,[0],[0]
"We would like to thank Pavel Petrushkov for helping with the NMT setup, and the anonymous reviewers for their insightful comments .",Acknowledgements,[0],[0]
Section B provides the instructions that were given to the annotators when judging MT quality.,A Appendix Overview,[0],[0]
In Section C we provide histograms for simulated and explicit rewards.,A Appendix Overview,[0],[0]
Section D contains details on the data and NMT model hyperparameters.,A Appendix Overview,[0],[0]
In Section E we give results for simulation experiments on the e-commerce product title domain and a publicly available data set.,A Appendix Overview,[0],[0]
"Finally, we compare translation examples of different models in Section F.",A Appendix Overview,[0],[0]
Please rate the translation quality of the segments on the scale from 1 to 5.,B.1 Star Ratings,[0],[0]
Focus on whether or not the information contained in the source sentence is correctly and completely translated (ratings 1 - 4).,B.1 Star Ratings,[0],[0]
"Then, if you are ready to give a 4 based on the criteria below, check whether or not you can assign a 5 instead of the 4, focusing on remaining grammatical, morphological and stylistic errors.",B.1 Star Ratings,[0],[0]
"Remember that even a very fluent translation that looks like a human-produced sentence can receive a bad rating if it does not correctly convey all the information that was present in the source.
",B.1 Star Ratings,[0],[0]
"Assign the following ratings from 1 to 5:
1.",B.1 Star Ratings,[0],[0]
"Important information is missing and/or distorted in the translation, and the error is so severe that it may lead to erroneous perception of the described product.",B.1 Star Ratings,[0],[0]
"Or the translation contains profanities/insulting words.
2.",B.1 Star Ratings,[0],[0]
"Information from the source is partially present in the translation, but important information is not translated or translated incorrectly.
",B.1 Star Ratings,[0],[0]
3.,B.1 Star Ratings,[0],[0]
"The most important information from the source is translated correctly, but some other less important information is missing or translated incorrectly.
4.",B.1 Star Ratings,[0],[0]
All of the information from the source is contained in the translation.,B.1 Star Ratings,[0],[0]
This should be the only criterion to decide between 1-3 and 4.,B.1 Star Ratings,[0],[0]
"It is okay for a 4-rated translation to contain grammatical errors, disfluencies, or word choice that is not very appropriate to the style of the input text.",B.1 Star Ratings,[0],[0]
"There might be errors in casing of named entities when it is clear from the context that these are named entities.
5.",B.1 Star Ratings,[0],[0]
All of the information from the source is contained in the translation and is translated correctly.,B.1 Star Ratings,[0],[0]
"In contrast to a 4-rated translation, the translation is fluent, easy to read, and contains either no or very minor grammatical/morphological/stylistic errors.",B.1 Star Ratings,[0],[0]
The brand names and other named entities have the correct upper/lower case.,B.1 Star Ratings,[0],[0]
"The customers of the eBay e-commerce platform, when presented with a title translation on the product page, can hover with the mouse over the translation of the title and see the original (source) title in a pop-up window.",B.2 Binary Judgment,[0],[0]
"There, they have the possibility to rate the translation with 1 to 5 stars.
",B.2 Binary Judgment,[0],[0]
The goal of this evaluation is to check the ratings - you have to mark “Agree” when you agree with the rating and “Disagree” otherwise.,B.2 Binary Judgment,[0],[0]
"The rating (number from 1 to 5) is shown in the Reference line.
",B.2 Binary Judgment,[0],[0]
"Note that eBay customers did not have any instructions on what the rating of 5 stars, 3 stars, or 4 stars means.",B.2 Binary Judgment,[0],[0]
"Thus, the evaluation is subjective on their side.",B.2 Binary Judgment,[0],[0]
Please apply your common sense when agreeing or disagreeing with human judgment.,B.2 Binary Judgment,[0],[0]
The focus should be on adequacy (correct information transfer) as opposed to fluency.,B.2 Binary Judgment,[0],[0]
"Figure 3 shows the distribution of logged user star ratings, Figure 4 the distribution of sentence BLEU (sBLEU) scores for the simulation experiments with logged feedback.",C.1 Reward Distributions,[0],[0]
"The logged translations for the user star ratings were generated by the production system, the logged translations for the simulation were generated by the BL NMT system.",C.1 Reward Distributions,[0],[0]
We conduct experiments on an English-to-Spanish e-commerce item titles translation task.,D.1 Data,[0],[0]
"The indomain data for training with simulated feedback is composed of in-house eBay data (item titles, descriptions, etc.).",D.1 Data,[0],[0]
"The out-of-domain data for training the baselines contains only publicly available parallel corpora, that is Europarl, TAUS, and OpenSubtitles released by the OPUS project (Tiedemann, 2009).",D.1 Data,[0],[0]
"The out-of-domain
data has been sub-sampled according to the similarity to the domain of the product title data, and 25% of the most similar sentence pairs have been selected.",D.1 Data,[0],[0]
The corpus statistics for parallel data are shown in Table 7.,D.1 Data,[0],[0]
"Before calculating the corpus statistics, we apply pre-processing including tokenization and replacement of numbers and product specifications with a placeholder token (e.g., ‘6S’, and ‘1080p’).",D.1 Data,[0],[0]
Table 8 gives an overview of the type and the size of the translations with feedback.,D.1 Data,[0],[0]
"The NMT has a bi-directional RNN encoder with one layer of 1000 GRUs, a decoder with 1000 GRUs, and source and target word embeddings of size 620.",D.2 NMT Model Architecture,[0],[0]
"The vocabulary is generated from the out-of-domain training corpus with 40k bytepair merges (Sennrich et al., 2016c) and contains 40813 source tokens and 41050 target tokens.",D.2 NMT Model Architecture,[0],[0]
"The full softmax is approximated by 1024 samples as proposed in (Jean et al., 2015).",D.2 NMT Model Architecture,[0],[0]
"Dropout (Gal and Ghahramani, 2016) is applied with probability p = 0.1 to the embedding matrices, with p = 0.2 to the
input and recurrent connections of the RNNs.",D.2 NMT Model Architecture,[0],[0]
"The out-of-domain model is trained with minibatches of size 100 and L2 regularization with weight 1× 10−7, optimized with Adam (Kingma and Ba, 2014) with initial α = 0.0002, then decaying α by 0.9 each epoch.
",D.3 NMT Training Hyperparameters,[0],[0]
"The remaining models are trained with constant learning rates and mini-batch size 30, regularization and dropout stay the same.",D.3 NMT Training Hyperparameters,[0],[0]
The settings for the other hyperparameters are listed in Table 9.,D.3 NMT Training Hyperparameters,[0],[0]
"The estimator loss weight is only relevant for DC, where the pre-trained estimator gets further finetuned during DC training.",D.3 NMT Training Hyperparameters,[0],[0]
"We find that for reward estimation a shallow CNN architecture with wide filters performs superior to a deeper CNN architecture (Le et al., 2017) and also to a recurrent architecture.",D.4 Reward Estimation,[0],[0]
"Hence, we use one convolutional layer with ReLU activation of
nf filters each for filter sizes from 2 to 15, capturing both local and more global features.",D.4 Reward Estimation,[0],[0]
"For reward estimation on star ratings, nf = 100 and on simulated sBLEU nf = 20 worked best.",D.4 Reward Estimation,[0],[0]
Dropout with p = 0.5 is applied before the output layer for the simulation setting.,D.4 Reward Estimation,[0],[0]
We set Tmax = 60.,D.4 Reward Estimation,[0],[0]
The loss of each item in the batch is weighted by inverse frequency of its feedback in the current batch (counted in 10 buckets) to counterbalance skewed feedback distributions.,D.4 Reward Estimation,[0],[0]
"The model is optimized with Adam (Kingma and Ba, 2014) (constant α = 0.001 for star ratings, α = 0.002 for the simulation) on minibatches of size 30.",D.4 Reward Estimation,[0],[0]
Note that the differences in hyper-parameters between both settings are the result of tuning and do not cause the difference in quality of the resulting estimators.,D.4 Reward Estimation,[0],[0]
"We do not evaluate on a separate test set, since their final quality can be measured in how much well they serve as policy evaluators in counterfactual learning.",D.4 Reward Estimation,[0],[0]
Expected Loss.,E Simulated Bandit Feedback,[0],[0]
"When rewards can be retrieved for sampled translations during learning, the Online Bandit Structured Prediction framework proposed by Sokolov et al. (2016a,b) can be applied for NMT, as demonstrated in Kreutzer et al.
(2017); Sokolov et al. (2017).",E Simulated Bandit Feedback,[0],[0]
"The Expected Loss objective (EL, Equation 8) maximizes5",E Simulated Bandit Feedback,[0],[0]
"the expectation of a reward over all source and target sequences, and does in principle not require references:
REL(θ) =Ep(x)pθ(ỹ|x)",E Simulated Bandit Feedback,[0],[0]
[∆(ỹ)] .,E Simulated Bandit Feedback,[0],[0]
"(8)
While we could not apply it to the logged user feedback since it was obtained offline, we can compare to its performance in a simulation setting with simulated rewards instead of human feedback.",E Simulated Bandit Feedback,[0],[0]
It is expected to outperform methods learning with logged feedback due to the exploration during learning.,E Simulated Bandit Feedback,[0],[0]
"In the following simulation experiments, ∆(ỹ) is computed by comparing a sampled translation ỹ ∼ pθ(y|x) to a given reference translation y with smoothed sentence-level BLEU (sBLEU).",E Simulated Bandit Feedback,[0],[0]
"We test several of the proposed learning techniques with an in-domain parallel corpus (62,162 sentences) of product titles where bandit feedback is simulated by evaluating a sampled translation against a reference using sBLEU.",E.1 E-commerce Product Titles,[0],[0]
"Similar to previous studies on SMT (Lawrence et al., 2017b),
5We use the terms reward or loss interchangeably depending on minimization or maximization contexts.",E.1 E-commerce Product Titles,[0],[0]
"this reward is deterministic and does not contain user-dependent noise.
",Learning Model Test BLEU Test TER,[0],[0]
Supervised Fine-Tuning.,Learning Model Test BLEU Test TER,[0],[0]
"When fine-tuning the baseline model on in-domain references (Luong and Manning, 2015), the model improves 3.34 BLEU (MLE in Table 10) on an in-domain test set (1,000 sentences).",Learning Model Test BLEU Test TER,[0],[0]
"By tuning it on the same in-domain data for sBLEU with MIX, it gains another 3 BLEU points.
",Learning Model Test BLEU Test TER,[0],[0]
Bandit Learning.,Learning Model Test BLEU Test TER,[0],[0]
"When feedback is given to only one translation per input (=online bandit feedback), the model (EL) achieves comparable performance to MLE training with references.",Learning Model Test BLEU Test TER,[0],[0]
"When the feedback is logged offline for one round of deterministic outputs of the baseline model (=offline bandit feedback), we can still find improvements of 1.81 BLEU (DPM).",Learning Model Test BLEU Test TER,[0],[0]
"With a reward estimator trained on this log, DC achieves even higher improvements of 3 BLEU.",Learning Model Test BLEU Test TER,[0],[0]
"To test the contribution of the feedback in contrast to a simple in-domain training effect, we randomly perturbed the pairing of feedback signal and translation and retrain (DPM-random).",Learning Model Test BLEU Test TER,[0],[0]
"This clearly degrades results, confirming feedback to be a useful signal rather than noise.",Learning Model Test BLEU Test TER,[0],[0]
Simulation experiments were also run on publicly available data.,E.2 Results on Publicly Available Data,[0],[0]
"We use the same data, preprocessing and splits as (Lawrence et al., 2017b) to compare with their French-to-English news experiments on counterfactual learning with deterministically logged feedback for statistical machine translation (SMT).",E.2 Results on Publicly Available Data,[0],[0]
"The baseline model is trained with MLE on 1.6M Europarl (EP) translations, bandit feedback is then simulated from 40k News Commentary (NC) translations.",E.2 Results on Publicly Available Data,[0],[0]
"For the comparison of full supervision vs. weak feedback, we train in-domain models with MLE on in-domain NC references: training only on in-domain data (NC BL), and fine-tuning the out-of-domain baseline (EP BL) on in-domain data (MLE).",E.2 Results on Publicly Available Data,[0],[0]
The results are given in Table 11.,E.2 Results on Publicly Available Data,[0],[0]
The NMT baselines outperform the SMT equivalents.,E.2 Results on Publicly Available Data,[0],[0]
"With fully supervised fine-tuning the NMT models improve over the out-of-domain baseline (EP BL) by 5 BLEU points, outperforming also the in-domain baseline (NC BL).",E.2 Results on Publicly Available Data,[0],[0]
"Moving to weak feedback, we still find improvements over the baseline by 0.5 BLEU with beam search and 1.6 BLEU with greedy decoding for online feedback (EL), and 0.6 BLEU with beam search and 1 BLEU with greedy decoding for counterfactual learning with DC.",E.2 Results on Publicly Available Data,[0],[0]
"However, DPM performs worse than for SMT and those not manage to improve over the out-of-domain baseline.",E.2 Results on Publicly Available Data,[0],[0]
"Nevertheless these results confirm that – at least in simulation settings – the DC objective is very suitable for counterfactual learning from bandit feedback for NMT, almost reaching the gains of learning from online bandit feedback.",E.2 Results on Publicly Available Data,[0],[0]
Table 12 gives an example where W-MIX training improved lexical translation choices.,F Examples,[0],[0]
Table 13 lists two examples of W-MIX translations in comparison to the baseline and logged translations for given queries and product titles to illustrate the specific difficulties of the domain.,F Examples,[0],[0]
"We present the first real-world application of methods for improving neural machine translation (NMT) with human reinforcement, based on explicit and implicit user feedback collected on the eBay ecommerce platform.",abstractText,[0],[0]
"Previous work has been confined to simulation experiments, whereas in this paper we work with real logged feedback for offline bandit learning of NMT parameters.",abstractText,[0],[0]
We conduct a thorough analysis of the available explicit user judgments—five-star ratings of translation quality—and show that they are not reliable enough to yield significant improvements in bandit learning.,abstractText,[0],[0]
"In contrast, we successfully utilize implicit taskbased feedback collected in a cross-lingual search task to improve task-specific and machine translation quality metrics.",abstractText,[0],[0]
Can Neural Machine Translation be Improved with User Feedback?,title,[0],[0]
In practice one often encounters multi-class classification problem with a large number of classes.,1. Introduction,[0],[0]
"For example, applications in image classification (Russakovsky et al., 2015) and language modeling (Mikolov et al., 2010) usually have tens to hundreds of thousands of classes.",1. Introduction,[0],[0]
"Under such cases, training the standard softmax logistic or one-against-all models becomes impractical.
",1. Introduction,[0],[0]
One promising way to handle the large class size is to use sampling.,1. Introduction,[0],[0]
"In language models, a commonly adopted technique is Noise-Contrastive Estimation (NCE) (Gutmann & Hyvärinen, 2012).",1. Introduction,[0],[0]
"This method is originally proposed
1Tencent AI Lab, Shenzhen, China.",1. Introduction,[0],[0]
"Correspondence to: Lei Han <lxhan@tencent.com>, Yiheng Huang <arnoldhuang@tencent.com>, Tong Zhang <tongzhang@tongzhangml.org>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
for estimating probability densities and has been applied to various language modeling situations, such as learning word embeddings, context generation and neural machine translation (Mnih & Teh, 2012; Mnih & Kavukcuoglu, 2013; Vaswani et al., 2013; Sordoni et al., 2015).",1. Introduction,[0],[0]
"NCE reduces the problem of multi-class classification to binary classification problem, which discriminates between a target class distribution and a noise distribution and a few noise classes are sampled as a representation of the entire noise space.",1. Introduction,[0],[0]
"In general, the noise distribution is given a priori.",1. Introduction,[0],[0]
"For example, a power-raised unigram distribution has been shown to be effective in language models (Mikolov et al., 2013; Ji et al., 2015; Mnih & Teh, 2012).",1. Introduction,[0],[0]
"Recently, some variants of NCE have been proposed.",1. Introduction,[0],[0]
"The Negative Sampling (Mikolov et al., 2013) is a simplified version of NCE that ignores the numerical probabilities in the distributions and discriminates between only the target class and noise samples; the One vs. Each (Titsias, 2016) solves a very similar problem motivated by bounding the softmax logistic log-likelihood.",1. Introduction,[0],[0]
"Two other variants, BlackOut (Ji et al., 2015) and complementary sum sampling (Botev et al., 2017), employ parametric forms of the noise distribution and use sampled noises to approximate the normalization factor.",1. Introduction,[0],[0]
"In summary, NCE and its variants use (only) the observed class versus the noises; by sampling the noises, these methods avoid the costly computation of the normalization factor to achieve fast training speed.",1. Introduction,[0],[0]
"In this paper, we will generalize the idea by using a subset of classes (which can be automatically learned), called candidate classes, against the remaining noise classes.",1. Introduction,[0],[0]
"Compared to NCE, this approach can significantly improve the statistical efficiency when the true class belongs to the candidate classes with high probability.
",1. Introduction,[0],[0]
"Another type of popular methods for large class space is the tree structured classifier (Beygelzimer et al., 2009; Bengio et al., 2010; Deng et al., 2011; Choromanska & Langford, 2015; Daume III et al., 2017; Jernite et al., 2017).",1. Introduction,[0],[0]
"In these methods, a tree structure is defined over the classes which are treated as leaves.",1. Introduction,[0],[0]
"Each internal node of the tree is assigned with a local classifier, routing the examples to one of its descendants.",1. Introduction,[0],[0]
Decisions are made from the root until reaching a leaf.,1. Introduction,[0],[0]
"Then, the multi-class classification problem is reduced to solving a number of small local models defined by a tree, which typically admits a logarithmic complexity on the total number of classes.",1. Introduction,[0],[0]
"Generally, tree classifiers
gain training and prediction speed while suffering a loss of accuracy.",1. Introduction,[0],[0]
"The performance of tree classifier may rely heavily on the quality of the tree (Mnih & Hinton, 2009).",1. Introduction,[0],[0]
"Earlier approaches use fixed tree, such as the Filter Tree (Beygelzimer et al., 2009) and the Hierarchical Softmax (HSM) (Morin & Bengio, 2005).",1. Introduction,[0],[0]
"Recent methods are able to adjust the tree and learn the local classifiers simultaneously, such as the LOMTree (Choromanska & Langford, 2015) and Recall Tree (Daume III et al., 2017).",1. Introduction,[0],[0]
"Our approach is complementary to these tree classifiers, because we study the orthogonal issue of consistent class sampling, which in principle can be combined with many of these tree methods.",1. Introduction,[0],[0]
"In fact, a tree structure will be used in our approach to select a small subset of candidate classes.",1. Introduction,[0],[0]
"Since we focus on the class sampling aspect, we do not necessarily employ the best tree construction method in our experiments.
",1. Introduction,[0],[0]
"In this paper, we propose a method to efficiently deal with the large class problem by paying attention to a small subset of candidate classes instead of the entire class space.",1. Introduction,[0],[0]
"Given a data point x (without observing y), we select a small number of competitive candidates as a set Cx.",1. Introduction,[0],[0]
"Then, we sample the remaining classes, which are treated as noises, to represent the entire noise space in the large normalization factor.",1. Introduction,[0],[0]
The estimation is referred to as Candidates vs. Noises Estimation (CANE).,1. Introduction,[0],[0]
"We show that CANE is consistent and its computation using stochastic gradient method is independent of the class size K. Moreover, the statistical variance of the CANE estimator can approach that of the maximum likelihood estimator (MLE) of the softmax logistic regression when Cx can cover the target class y with high probability.",1. Introduction,[0],[0]
"This statistical efficiency is a key advantage of CANE over NCE, and its effect can be observed in practice.
",1. Introduction,[0],[0]
We then describe two concrete algorithms: the first one is a generic stochastic optimization procedure for CANE; the second one employs a tree structure with leaves as classes to enable fast beam search for candidate selection.,1. Introduction,[0],[0]
We also apply CANE to solve the word probability estimation problem in neural language modeling.,1. Introduction,[0],[0]
Experimental results conducted on both classification and neural language modeling problems show that CANE achieves significant speedup compared to the standard softmax logistic regression.,1. Introduction,[0],[0]
"Moreover, it achieves superior performance over NCE, its variants, and a number of the state-of-the-art tree classifiers.",1. Introduction,[0],[0]
"Consider a K-class classification problem (K is large) with n training examples (xi, yi)|ni=1, where xi is from an input space X and yi ∈ {1, · · · ,K}.",2. Candidates vs. Noises Estimation,[0],[0]
"The softmax logistic regression solves
max θ
1
n n∑ i=1 K∑",2. Candidates vs. Noises Estimation,[0],[0]
"k=1 I(yi = k) log esk(xi,θ)∑K k′=1 e sk′ (xi,θ) , (1)
",2. Candidates vs. Noises Estimation,[0],[0]
"where sk(x,θ) for k = 1, · · · ,K is a model parameterized by θ.",2. Candidates vs. Noises Estimation,[0],[0]
Solving Eq.,2. Candidates vs. Noises Estimation,[0],[0]
"(1) requires computing a score for every class and the summation in the normalization factor, which is very expensive when K is large.
Generally speaking, given x, only a small number of classes in the entire class space might be competitive to the true class.",2. Candidates vs. Noises Estimation,[0],[0]
"Therefore, we propose to find a small subset of classes as a candidate set Cx ⊂ {1, · · · ,K} and treat the classes outside Cx as noises, so that we can focus on the small set Cx instead of the entire K classes.",2. Candidates vs. Noises Estimation,[0],[0]
We will discuss one way to choose Cx in Section 4.,2. Candidates vs. Noises Estimation,[0],[0]
"Denote the remaining K − |Cx| noises as a set Nx, so",2. Candidates vs. Noises Estimation,[0],[0]
Nx is the complementary set of Cx.,2. Candidates vs. Noises Estimation,[0],[0]
We propose to sample some noise class j ∈,2. Candidates vs. Noises Estimation,[0],[0]
Nx to represent the entire Nx.,2. Candidates vs. Noises Estimation,[0],[0]
"That is, we replace the partial summation ∑ j∈Nx e
sj(x,θ) in the denominator of Eq.",2. Candidates vs. Noises Estimation,[0],[0]
"(1) by esj(x,θ)/qx(j) using some sampled class j with an arbitrary sampling probability qx(j), where qx(j) ∈ (0, 1) and∑",2. Candidates vs. Noises Estimation,[0],[0]
j∈Nx qx(j) = 1.,2. Candidates vs. Noises Estimation,[0],[0]
"Thus, the denominator ∑K k′=1 e sk′ (x,θ)
will be approximated as ∑ k′∈Cx e
sk′ (x,θ) + esj(x,θ)/qx(j).",2. Candidates vs. Noises Estimation,[0],[0]
"Given example (x, y) and its candidate set Cx, if y ∈ Cx, then for some sampled noise class j, we will focus on maximizing the approximated probability
esy(x,θ)∑ k′∈Cx e sk′ (x,θ) + esj(x,θ)/qx(j) ; (2)
otherwise, if y 6∈ Cx, we maximize
esy(x,θ)∑ k′∈Cx e sk′ (x,θ) + esy(x,θ)/qx(y) (3)
alternatively, where y is treated as the sampled noise in place.",2. Candidates vs. Noises Estimation,[0],[0]
"Now, with Eqs.",2. Candidates vs. Noises Estimation,[0],[0]
"(2) and (3), in expectation, we will need to solve the following objective:
maximize R(θ) =
Ex [ ∑ k∈Cx p(y = k|x) ∑ j∈Nx qx(j) log esk(x,θ)∑
k′∈Cx e sk′ (x,θ)+ e
sj(x,θ) qx(j)
+ ∑
k∈Nx
p(y = k|x) log esk(x,θ)∑
k′∈Cx e sk′ (x,θ) + e
sk(x,θ) qx(k)
] , (4)
and empirically, we will need to solve
maximize R̂n(θ) =
1
n n∑ i=1",2. Candidates vs. Noises Estimation,[0],[0]
"[ I(yi ∈ Cxi ) ∑ j∈Nxi qxi (j) log esyi (xi,θ)∑ k′∈Cxi esk′ (xi,θ)+ e sj(xi,θ) qxi",2. Candidates vs. Noises Estimation,[0],[0]
"(j)
+",2. Candidates vs. Noises Estimation,[0],[0]
I(yi /∈,2. Candidates vs. Noises Estimation,[0],[0]
"Cxi ) log esyi (xi,θ)∑
k′∈Cxi esk′ (xi,θ) +",2. Candidates vs. Noises Estimation,[0],[0]
"e
syi (xi,θ) qxi",2. Candidates vs. Noises Estimation,[0],[0]
"(yi)
] .",2. Candidates vs. Noises Estimation,[0],[0]
"(5)
Eq. (5) consists of two summations over both the data points and the classes in the noise set Nx.",2. Candidates vs. Noises Estimation,[0],[0]
"Therefore, we can employ a ‘doubly’ stochastic gradient optimization method by
sampling both data points i ∈ {1, . . .",2. Candidates vs. Noises Estimation,[0],[0]
",",2. Candidates vs. Noises Estimation,[0],[0]
n} and noise classes j ∈ Nxi .,2. Candidates vs. Noises Estimation,[0],[0]
"It is not difficult to check that each stochastic gradient is bounded under reasonable conditions, which means that the computational cost for solving (5) using stochastic gradient is independent of the class number K.",2. Candidates vs. Noises Estimation,[0],[0]
"Since we only choose a small number of candidates in Cx, the computation for each stochastic gradient in Eq. (5) is efficient.",2. Candidates vs. Noises Estimation,[0],[0]
The above method is referred to as Candidates vs. Noises Estimation (CANE).,2. Candidates vs. Noises Estimation,[0],[0]
"In this section, we investigate the statistical properties of CANE.",3. Properties,[0],[0]
The parameter space of the softmax logistic model in Eq.,3. Properties,[0],[0]
"(1) has redundancy, observing that adding any function h(x) to sk(x,θ) for k = 1, · · · ,K will not change the objective.",3. Properties,[0],[0]
Similar situation happens for Eqs.,3. Properties,[0],[0]
(4) and (5).,3. Properties,[0],[0]
"To avoid this redundancy, one can add some constraints on the K scores or simply fix one of them as zero, e.g., let sK(x,θ) = 0.",3. Properties,[0],[0]
"To facilitate the analysis, we will fix sK(x,θ) = 0 and consider Cx ∪ Nx = {1, · · · ,K − 1} within this section.",3. Properties,[0],[0]
"First, we have the following result.
",3. Properties,[0],[0]
Theorem 1 (Infinity-Sample Consistency).,3. Properties,[0],[0]
"By viewing the objective R as a function of {s1, · · · , sK−1}, R achieves its maximum if and only if sk = log p(y=k|x) p(y=K|x) for k = 1, · · · ,K − 1.
",3. Properties,[0],[0]
"In Theorem 1, the global optima is exactly the log-odds function with class K as the reference class.",3. Properties,[0],[0]
"Now, considering the parametric form sk(x,θ), there exists a true parameter θ∗ so that sk(x,θ∗) = log p(y=k|x) p(y=K|x)",3. Properties,[0],[0]
"if the model sk(x,θ) is correctly specified.",3. Properties,[0],[0]
"The following theorem shows that the CANE estimator θ̂ = arg maxθ R̂n(θ) is consistent with the true parameter θ∗.
Theorem 2 (Finite-Sample Asymptotic Consistency).",3. Properties,[0],[0]
"Given x, denote Cx as {i1, · · · , i|Cx|} andNx as {j1, · · · , j|Nx|}.",3. Properties,[0],[0]
"Suppose that the parameter space is compact and ∀θ 6= θ∗ such that PX (sk(x,θ) 6= sk(x,θ∗))",3. Properties,[0],[0]
> 0,3. Properties,[0],[0]
"for x ∼ X , k 6=",3. Properties,[0],[0]
"K. Assume ‖∇θsk(x,θ)‖, ‖∇2θsk(x,θ)‖ and ‖∇3θsk(x,θ)‖ for k 6= K are bounded under some norm ‖ · ‖ defined on the parameter space of θ.",3. Properties,[0],[0]
"Then, as n→∞, the estimator θ̂ converges to θ∗.
The above theorem shows that similar to the maximum likelihood estimator of Eq.",3. Properties,[0],[0]
"(1), the CANE estimator in Eq.",3. Properties,[0],[0]
(5) is also consistent.,3. Properties,[0],[0]
"Next, we have the asymptotic normality for θ̂ as follows.
",3. Properties,[0],[0]
Theorem 3 (Asymptotic Normality).,3. Properties,[0],[0]
"Under the same assumption used in Theorem 2, as n → ∞, √ n(θ̂ − θ∗) follows the asymptotic normal distribution:
√ n(θ̂ − θ∗) d−→ N(0, [Ex∇M∇>]−1), (6)
where
M = ∑
j∈Nx
qx(j) [ diag (uj)−
1 p(K,x) + ∑
k∈Cx p(k,x) + p(j,x) qx(j)
uju > j
] ,
uj = ( p(i1,x), · · · , p(i|Cx|,x)︸ ︷︷ ︸
The candidate part
, 0, · · · , p(j,x)/qx(j), · · · , 0︸ ︷︷ ︸",3. Properties,[0],[0]
"The noise part
)> ,
for j = j1, · · · , j|Nx|, ∇ = diag ([ ∇θsi1 (x,θ), · · · ,∇θsi|Cx| (x,θ),∇θsj1 (x,θ),
· · · ,∇θsj|Nx| (x,θ) ]>) .
",3. Properties,[0],[0]
Theorem 3 shows that the CANE method has a statistical variance of [Ex∇M∇>]−1.,3. Properties,[0],[0]
"As we will see in the next corollary, if one can successfully choose the candidate set Cx so that it covers the observed label y with high probability, then the difference between the statistical variance of CANE and that of Eq.",3. Properties,[0],[0]
(1) is small.,3. Properties,[0],[0]
"Therefore, choosing a good candidate set can be important for practical applications.",3. Properties,[0],[0]
"Moreover, under standard conditions, the computation of CANE using stochastic gradient is independent of the class size K because the variance of stochastic gradient is bounded.",3. Properties,[0],[0]
Corollary 1,3. Properties,[0],[0]
(Low Statistical Variance).,3. Properties,[0],[0]
The variance of the maximum likelihood estimator for the softmax logistic regression in Eq.,3. Properties,[0],[0]
(1) has the form [Ex∇Mmle∇>]−1. If∑,3. Properties,[0],[0]
"k∈Cx∪{K} p(k,x) → 1, i.e., the probability that Cx ∪ {K} covers the observed class label y approaches 1, then
[Ex∇M∇>]−1 → [Ex∇Mmle∇>]−1.",3. Properties,[0],[0]
"In this section, we propose two algorithms.",4. Algorithm,[0],[0]
The first one is a general optimization procedure for CANE.,4. Algorithm,[0],[0]
The second implementation provides an efficient way to select a competitive set Cx using a tree structure defined on the classes.,4. Algorithm,[0],[0]
Eq. (5) suggests an efficient algorithm using a ‘doubly’ stochastic gradient descend (SGD) method by sampling both the data points and classes.,4.1. A General Optimization Algorithm,[0],[0]
"That is, by sampling a data point (x, y), we find the candidate set Cx ⊂ {1, · · · ,K}.",4.1. A General Optimization Algorithm,[0],[0]
"If y ∈ Cx, we sample Nn noises from Nx according to qx and denote the selected noises as a set Tx (|Tx| = Nn).",4.1. A General Optimization Algorithm,[0],[0]
"We then optimize
1 |Tx| ∑ j∈Tx log esy(x,θ)∑ k′∈Cx e sk′ (x,θ) + esj(x,θ)/qx(j) ,
with gradient∇θR̂ given by Eq. (7).",4.1. A General Optimization Algorithm,[0],[0]
"Otherwise, if y 6∈ Cx, we optimize
log esy(x,θ)∑
k′∈Cx e sk′ (x,θ) + esy(x,θ)/qx(y)
,
Algorithm 1 A general optimization procedure for CANE.",4.1. A General Optimization Algorithm,[0],[0]
"1: Input: K, (xi, yi)|ni=1, number of candidates Nc = |Cx|,
number of sampled noises Nn = |Tx|, sampling strategy q and learning rate η.
2: Output: θ̂.
3: Initialize θ; 4: for every sampled example do 5: Receive example (x, y); 6: Find the candidate set Cx; 7: if y ∈",4.1. A General Optimization Algorithm,[0],[0]
Cx then 8:,4.1. A General Optimization Algorithm,[0],[0]
"Sample Nn noises outside Cx according to q and denote the selected noise set as Tx; 9: θ ← θ + η∇θR̂ with∇θR̂ given by
∇θsy(x,θ)− 1 |Tx| ∑ j∈Tx
(7)
∑k′∈Cx",4.1. A General Optimization Algorithm,[0],[0]
"esk′ (x,θ)∇θsk′(x,θ) + esj(x,θ)qx(j) ∇θsj(x,θ)∑ k′∈Cx e sk′ (x,θ) + e sj(x,θ) qx(j)  ; 10: else 11: θ ← θ + η∇θR̂ with∇θR̂ given by
∇θsy(x,θ)−∑ k′∈Cx e sk′ (x,θ)∇θsk′(x,θ) + e sy(x,θ)
qx(y) ∇θsy(x,θ)∑
k′∈Cx e sk′ (x,θ) + e
sy(x,θ) qx(y)
; (8)
12: end if 13: end for
with gradient∇θR̂ given by Eq.",4.1. A General Optimization Algorithm,[0],[0]
(8).,4.1. A General Optimization Algorithm,[0],[0]
This general procedure is provided in Algorithm 1.,4.1. A General Optimization Algorithm,[0],[0]
"Algorithm 1 has a complexity of O(Nc +Nn) (where Nc = |Cx|), which is independent of the class size K.",4.1. A General Optimization Algorithm,[0],[0]
"In step 6, any method can be used to select Cx.",4.1. A General Optimization Algorithm,[0],[0]
"In the second algorithm, we provide an efficient way to find a competitive Cx.",4.2. Beam Tree Algorithm,[0],[0]
"An attractive strategy is to use a tree defined on the classes, because one can perform fast heuristic search algorithms based on a tree structure to prune the uncompetitive classes.",4.2. Beam Tree Algorithm,[0],[0]
"Indeed, any structure, e.g., graph or groups, can be used alternatively as long as the structure allows to efficiently prune uncompetitive classes.",4.2. Beam Tree Algorithm,[0],[0]
"We will use tree structure for candidate selection in this paper.
",4.2. Beam Tree Algorithm,[0],[0]
"Given a tree structure defined on the K classes, the model sk(x,θ) is interpreted as a tree model illustrated in Fig. 1.",4.2. Beam Tree Algorithm,[0],[0]
"For simplicity, Fig. 1 uses a binary tree over K = 8 labels as example while any tree structure can be used for selecting Cx.",4.2. Beam Tree Algorithm,[0],[0]
"In the example, circles denote internal nodes and squares indicate classes.",4.2. Beam Tree Algorithm,[0],[0]
"The parameters are kept in the edges and denoted as θ(o,c), where o indicates an internal node and c is the index of the c-th child of node o. Therefore, a pair (o, c) represents an edge from node o to its c-th child.",4.2. Beam Tree Algorithm,[0],[0]
"The dashed circles indicate that we do not keep any
parameters in the internal nodes.",4.2. Beam Tree Algorithm,[0],[0]
"Now, define sk(x,θ) as sk(x,θ) = gψ(x) · ∑
(o,c)∈Pk
θ(o,c), (9)
where gψ(x) is a function parameterized by ψ and it maps the input x ∼ X to a representation gψ(x) ∈ Rdr for some dr.",4.2. Beam Tree Algorithm,[0],[0]
"For example, in image classification, a good choice of the representation gψ(x) of the raw pixels x is usually a deep neural network.",4.2. Beam Tree Algorithm,[0],[0]
Pk denotes the path from the root to the class k. Eq.,4.2. Beam Tree Algorithm,[0],[0]
(9) implies that the score of an example belonging to a class is calculated by summing up the scores along the corresponding path.,4.2. Beam Tree Algorithm,[0],[0]
"Now, in Fig. 1, suppose that we are given an example (x, y) with class y = 2 (blue).",4.2. Beam Tree Algorithm,[0],[0]
"Using beam search, we find two candidates with high scores, i.e., class 1 (green) and class 2.",4.2. Beam Tree Algorithm,[0],[0]
"Then, we let",4.2. Beam Tree Algorithm,[0],[0]
"Cx = {1, 2}.",4.2. Beam Tree Algorithm,[0],[0]
"In this case, we have y ∈ Cx, so we need to sample noises.",4.2. Beam Tree Algorithm,[0],[0]
Suppose we sample one class 6 (orange).,4.2. Beam Tree Algorithm,[0],[0]
"According to Eq. (7), the parameters along the corresponding paths (red) will be updated.
",4.2. Beam Tree Algorithm,[0],[0]
"Formally, given example (x, y), if y ∈ Cx, we sample noises as a set Tx.",4.2. Beam Tree Algorithm,[0],[0]
"Then for (o, c) ∈ PCx∪Tx , where PCx∪Tx = ∪k∈Cx∪TxPk, the gradient with respect to θ(o,c) is
∂R̂
∂θ(o,c) =
1 |Tx| ∑ j∈Tx
[ I ((o, c) ∈ Py)−",4.2. Beam Tree Algorithm,[0],[0]
"(10)
∑ k′∈Cx I((o, c) ∈ Pk′ )",4.2. Beam Tree Algorithm,[0],[0]
"e sk′ (x,θ) + I((o, c) ∈",4.2. Beam Tree Algorithm,[0],[0]
"Pj) e sj(x,θ)
qx(j)∑ k′∈Cx e sk′ (x,θ) + e sj(x,θ) qx(j)
] gψ(x).
",4.2. Beam Tree Algorithm,[0],[0]
Note that an edge may be included in multiple selected paths.,4.2. Beam Tree Algorithm,[0],[0]
"For example, P1 and P2 share edges (1, 1) and (2, 1) in Fig. 1.",4.2. Beam Tree Algorithm,[0],[0]
The case of y 6∈ Cx can be illustrated similarly.,4.2. Beam Tree Algorithm,[0],[0]
"The gradient with respect to θ(o,c) when y 6∈ Cx is
∂R̂
∂θ(o,c) =
[ I ((o, c) ∈",4.2. Beam Tree Algorithm,[0],[0]
"Py)− (11)
∑ k′∈Cx I((o, c) ∈ Pk′ )",4.2. Beam Tree Algorithm,[0],[0]
"e sk′ (x,θ) + I((o, c) ∈",4.2. Beam Tree Algorithm,[0],[0]
"Py) e sy(x,θ)
qx(y)∑ k′∈Cx e sk′ (x,θ) + e sy(x,θ) qx(y)
] gψ(x).
",4.2. Beam Tree Algorithm,[0],[0]
Algorithm 2 The Beam Tree Algorithm.,4.2. Beam Tree Algorithm,[0],[0]
"1: Input: K, (xi, yi)|ni=1, representation function gψ(x), num-
ber of candidates Nc = |Cx|, number of sampled noises Nn = |Tx|, sampling strategy q and learning rate η.
2: Output: θ̂.
3: Construct a tree on the K classes; 4: Initialize θ; 5: for every sampled example do 6:",4.2. Beam Tree Algorithm,[0],[0]
"Receive example (x, y); 7:",4.2. Beam Tree Algorithm,[0],[0]
"Given x, use beam search to find the Nc classes with high scores to compose Cx; 8: if y ∈",4.2. Beam Tree Algorithm,[0],[0]
Cx then 9:,4.2. Beam Tree Algorithm,[0],[0]
"Sample Nn noises outside Cx according to q and denote
the selected noise set as Tx; 10: Find the paths with respect to the classes in Cx ∪ Tx; 11: else 12: Find the paths with respect to the classes in Cx ∪ {y}; 13: end if 14: Sum up the scores along each selected path for the corresponding class; 15: θ(o,c) ← θ(o,c) + η ∂R̂∂θ(o,c) for each (o, c) included in the selected paths according to Eqs.",4.2. Beam Tree Algorithm,[0],[0]
"(10) and (11); 16: ψ ← ψ + η ∂R̂
∂g ∂g ∂ψ ; // if g is parameterized.",4.2. Beam Tree Algorithm,[0],[0]
"17: end for
The gradients in Eqs.",4.2. Beam Tree Algorithm,[0],[0]
"(10) and (11) enjoy the following property.
",4.2. Beam Tree Algorithm,[0],[0]
Proposition 1.,4.2. Beam Tree Algorithm,[0],[0]
"At each iteration of Algorithm 2, if an edge (o, c) is included in every selected path, then θ(o,c) does not need to be updated.
",4.2. Beam Tree Algorithm,[0],[0]
"The proof of Proposition 1 is straightforward that if (o, c) belongs to every selected path, then the gradients in Eqs.",4.2. Beam Tree Algorithm,[0],[0]
(10) and (11) are 0.,4.2. Beam Tree Algorithm,[0],[0]
The above property allows a fast detection of those parameters which do not need to be updated in SGD and hence can save computations.,4.2. Beam Tree Algorithm,[0],[0]
"In practice, the number of shared edges is related to the tree structure.
",4.2. Beam Tree Algorithm,[0],[0]
"Since we use beam search to choose the candidates in a tree structure, the proposed algorithm is referred to as Beam Tree, which is depicted in Algorithm 2.",4.2. Beam Tree Algorithm,[0],[0]
1,4.2. Beam Tree Algorithm,[0],[0]
"For the tree construction method in step 3, we can use some hierarchical clustering based methods which will be detailed in the experiments and supplementary material.",4.2. Beam Tree Algorithm,[0],[0]
"In the algorithm, the beam search needs O (Nc logbK) operations, where b is a constant related to the tree structure, e.g., binary tree for b = 2.",4.2. Beam Tree Algorithm,[0],[0]
The parameter updating needsO((Nc+Nn) logbK) operations.,4.2. Beam Tree Algorithm,[0],[0]
"Therefore, Algorithm 2 has a complexity of O((2Nc +Nn) logbK) which is logarithmic with respect to K. The term logbK is from the tree structure used in this specific candidate selection method, so it does not conflict with the complexity of the general Algorithm 1, which is independent of K. Another advantage of the Beam Tree
1The beam search procedure in step 7 is provided in the supplementary material.
algorithm is that it allows fast predictions and can naturally output the top-J predictions using beam search.",4.2. Beam Tree Algorithm,[0],[0]
The prediction time has an order of O (J logbK) for the top-J predictions.,4.2. Beam Tree Algorithm,[0],[0]
"In this section, we apply the CANE method to neural language modeling which solves a probability density estimation problem.",5. Application to Neural Language Modeling,[0],[0]
"In neural language models, the conditional probability distribution of the target word w given context h is defined as
Ph(w) = esw(h,θ)∑
w′∈V e sw′ (h,θ)
,
where sw(h,θ) is the scoring function with parameter θ.",5. Application to Neural Language Modeling,[0],[0]
A wordw in the context hwill be represented by an embedding vector uw ∈ Rd with embedding size d.,5. Application to Neural Language Modeling,[0],[0]
"Given context h, the model computes the score for the target word w as
sw(h,θ) = gϕ(uh)vw,
where θ = {u,v,ϕ}, gϕ(·) is a representation function (parameterized by ϕ) of the embeddings in the context h, e.g., a LSTM modular (Hochreiter & Schmidhuber, 1997), and vw is the weight parameter for the target word w.",5. Application to Neural Language Modeling,[0],[0]
Both the word embedding u and weight parameter v need to be estimated.,5. Application to Neural Language Modeling,[0],[0]
"In language models, the vocabulary size |V| is usually very large and the computation of the normalization factor is expensive.",5. Application to Neural Language Modeling,[0],[0]
"Therefore, instead of estimating the exact probability distribution Ph(w), sampling methods such as NCE and its variants (Mnih & Kavukcuoglu, 2013; Ji et al., 2015) are typically adopted to approximate Ph(w).
",5. Application to Neural Language Modeling,[0],[0]
"In order to apply the CANE method, we need to select the candidates given any context h. For multi-class classification problem, we have devised a Beam Tree algorithm in Algorithm 2 that uses a tree structure to select candidates, and the tree can be obtained by some hierarchical clustering methods over x before learning.",5. Application to Neural Language Modeling,[0],[0]
"However, different from the classification problem, the word embeddings in the language model are not known before training, and thus obtaining a hierarchical structure based on the word embeddings is not practical.",5. Application to Neural Language Modeling,[0],[0]
"In this paper, we construct a simple tree with only one layer under the root, where the layer contains N subsets formed by splitting the words according to their frequencies.",5. Application to Neural Language Modeling,[0],[0]
"At each iteration of Algorithm 2, we route the example by selecting the subset with the largest score (in place of beam search) and then sample the candidates from the subset according to some distribution.",5. Application to Neural Language Modeling,[0],[0]
"For the noises in CANE, we directly sample words out of the candidate set according to q. Other methods can be used to select the candidates alternatively, for example, one can choose candidates conditioned on the context h using a lightly pre-trained N-gram model.",5. Application to Neural Language Modeling,[0],[0]
We provide a discussion comparing CANE with the existing techniques for solving the large class space problem.,6. Related Algorithms,[0],[0]
"Given (x, y), NCE and its variants (Gutmann & Hyvärinen, 2012; Mnih & Kavukcuoglu, 2013; Mikolov et al., 2013; Ji et al., 2015; Titsias, 2016; Botev et al., 2017) use the observed class y as the only ‘candidate’, while CANE chooses a subset of candidates",6. Related Algorithms,[0],[0]
"Cx according to x. NCE assumes the entire noise distribution Pnoise(y) is known (e.g., a power-raised unigram distribution).",6. Related Algorithms,[0],[0]
"However, in general multi-class classification problems, when the knowledge of the noise distribution is absent, NCE may have unstable estimations using an inaccurate noise distribution.",6. Related Algorithms,[0],[0]
CANE is developed for general multi-class classification problems and does not rely on a known noise distribution.,6. Related Algorithms,[0],[0]
"Instead, CANE focuses on a small candidate set Cx.",6. Related Algorithms,[0],[0]
"Once the true class label is contained in Cx with high probability, CANE will have low statistical variance.",6. Related Algorithms,[0],[0]
"The variants of NCE (Mikolov et al., 2013; Ji et al., 2015; Titsias, 2016; Botev et al., 2017) also sample one or multiple noises to replace the normalization factor while according theoretical guarantees on the consistency and variance are rarely discussed.",6. Related Algorithms,[0],[0]
"NCE and its variants can not speed up prediction while the Beam Tree algorithm can reduce the prediction complexity to O(logK).
",6. Related Algorithms,[0],[0]
"The Beam Tree algorithm is related to some tree classifiers, while CANE is a general procedure and we only use tree structure to select candidates.",6. Related Algorithms,[0],[0]
The Beam Tree method itself is also different from existing tree classifiers.,6. Related Algorithms,[0],[0]
"Most of the state-of-the-art tree classifiers, e.g., LOMTree (Choromanska & Langford, 2015) and Recall Tree (Daume III et al., 2017), store local classifiers in their internal nodes, and route examples through the root until reaching the leaf.",6. Related Algorithms,[0],[0]
"Differently, the Beam Tree algorithm shown in Fig. 1 does not maintain local classifiers, and it only uses the tree structure to perform global heuristic search for candidate selection.",6. Related Algorithms,[0],[0]
We will compare our approach to some state-of-the-art tree classifiers in the experiments.,6. Related Algorithms,[0],[0]
"We evaluate the CANE method in various applications in this section, including both multi-class classification problems and neural language modeling.",7. Experiments,[0],[0]
"We compare CANE with NCE, its variants and some state-of-the-art tree classifiers that have been used for large class space problems.",7. Experiments,[0],[0]
"The competitors include the standard softmax, the NCE (Mnih & Kavukcuoglu, 2013; Mnih & Teh, 2012), the BlackOut (Ji et al., 2015), the hierarchical softmax (HSM) (Morin & Bengio, 2005), the Filter Tree (Beygelzimer et al., 2009) implemented in Vowpal-Wabbit (VW, a learning platform)2,
2https://github.com/JohnLangford/vowpal_ wabbit/wiki
the LOMTree (Choromanska & Langford, 2015) in VW and the Recall Tree (Daume III et al., 2017) in VW.",7. Experiments,[0],[0]
"In this section, we consider four multi-class classification problems, including the Sector3 dataset with 105 classes (Chang & Lin, 2011), the ALOI4 dataset with 1000 classes (Geusebroek et al., 2005), the ImageNet-20105 dataset with 1000 classes, and the ImageNet-10K5 dataset with 10K classes (ImageNet Fall 2009 release).",7.1. Classification Problems,[0],[0]
The data from Sector and ALOI is split into 90% training and 10% testing.,7.1. Classification Problems,[0],[0]
"In ImageNet-2010, the training set contains 1.3M images and we use the validation set containing 50K images as the test set.",7.1. Classification Problems,[0],[0]
"The ImageNet-10K data contains 9M images and we randomly split the data into two halves for training and testing by following the protocols in (Deng et al., 2010; Sánchez & Perronnin, 2011; Le, 2013).",7.1. Classification Problems,[0],[0]
"For ImageNet2010 and ImageNet-10K datasets, similar to (Oquab et al., 2014), we transfer the mid-level representations from the pre-trained VGG-16 net (Simonyan & Zisserman, 2014) on ImageNet 2012 data (Russakovsky et al., 2015) to our case.",7.1. Classification Problems,[0],[0]
"Then, we concatenate CANE or other compared methods above the partial VGG-16 net as the top layer.",7.1. Classification Problems,[0],[0]
The parameters of the partial VGG-16 net are pre-trained6 and kept fixed.,7.1. Classification Problems,[0],[0]
"Only the parameters in the top layer are trained on the target datasets, i.e., ImageNet-2010 and ImageNet-10K.
We use b-nary tree for CANE and set b = 10 for all classification problems.",7.1. Classification Problems,[0],[0]
We trade off |Cx| and |Tx| to see how these parameters affect the learning performance.,7.1. Classification Problems,[0],[0]
Different configurations will be referred to as ‘CANE-(|Cx| vs. |Tx|)’.,7.1. Classification Problems,[0],[0]
"We always let |Cx|+ |Tx| equal the number of noises used by NCE and BlackOut, so that these methods will have the same number of considered classes.",7.1. Classification Problems,[0],[0]
We use ‘NCE-k’ and ‘BlackOut-k’ to denote the corresponding method with k noises.,7.1. Classification Problems,[0],[0]
"Generally, a large |Cx|+ |Tx| and k will lower the variance of CANE, NCE and BlackOut and improve their performance, but this also increases the computation.",7.1. Classification Problems,[0],[0]
We set k = 10 for Sector and ALOI and k = 20 for ImageNet-2010 and ImageNet-10K. We uniformly sample noises in CANE.,7.1. Classification Problems,[0],[0]
"For NCE and BlackOut, by following (Mnih & Teh, 2012; Mnih & Kavukcuoglu, 2013; Ji et al., 2015; Botev et al., 2017), we use the power-raised unigram distribution with the power factor selected from {0, 0.1, 0.3, 0.5, 0.75, 1} to sample the noises.",7.1. Classification Problems,[0],[0]
"However, when the classes are balanced as in many cases of the classification datasets, this distribution reduces to the uniform distribution.",7.1. Classification Problems,[0],[0]
"For the com-
3http://www.cs.utexas.edu/˜xrhuang/ PDSparse/
4http://www.csie.ntu.edu.tw/˜cjlin/ libsvmtools/datasets/multiclass.html
5http://image-net.org 6http://www.robots.ox.ac.uk/˜vgg/
research/very_deep/
pared tree classifiers, the HSM adopts the same tree used by CANE, the Filter Tree generates a fixed tree itself in VW, the LOMTree and Recall Tree use binary trees and they are able to adjust the tree structure automatically.
",7.1. Classification Problems,[0],[0]
"All the methods use SGD with learning rate selected from {0.0001, 0.001, 0.01, 0.05, 0.1, 0.5, 1.0}.",7.1. Classification Problems,[0],[0]
"The Beam Tree algorithm requires a tree structure and we use some tree generated by a simple hierarchical clustering method on the centers of the individual classes.7 We run all the methods 50 epochs on Sector, ALOI and ImageNet-2010 datasets and 20 epochs on ImageNet-10K to report the accuracy vs. epoch curves.",7.1. Classification Problems,[0],[0]
"All the methods are implemented using a standard CPU machine with quad-core Intel Core i5 processor.
",7.1. Classification Problems,[0],[0]
"Fig. 2 and Table 1 show the accuracy vs. epoch plots and
7The method is provided in the supplementary material.
",7.1. Classification Problems,[0],[0]
"the training / testing time for NCE, BlackOut, CANE and Softmax.",7.1. Classification Problems,[0],[0]
"The tree classifiers in the VW platform require the number of training epochs as input and do not take evaluation directly after each epoch, so we report the final results of the tree classifiers in Table 2.",7.1. Classification Problems,[0],[0]
"For ImageNet-10K data, the Softmax method is very time consuming (even with multithread implementation) and we do not report this result.",7.1. Classification Problems,[0],[0]
"As we can observe, by fixing |Cx| + |Tx|, using more candidates than noises in CANE will achieve better performance, because a larger Cx will increase the chance to cover",7.1. Classification Problems,[0],[0]
the target class y.,7.1. Classification Problems,[0],[0]
The probability that the target class is included in the selected candidate set on the test data is reported in Table 3.,7.1. Classification Problems,[0],[0]
"On all the datasets, CANE with larger candidate set achieves considerable improvement compared to other methods in terms of accuracy.",7.1. Classification Problems,[0],[0]
"The speed of processing each example of CANE is slightly slower than that of NCE and BlackOut because of beam search, however, CANE shows faster convergence to reach higher accuracy.",7.1. Classification Problems,[0],[0]
"Moreover, the prediction time of CANE is much faster than those of NCE and BlackOut.",7.1. Classification Problems,[0],[0]
"It is worth mentioning that CANE exceeds some state-of-the-art results on the ImageNet-10K data, e.g., 19.2% top-1 accuracy reported in (Le, 2013) and 21.9% top1 accuracy reported in (Mensink et al., 2013) which are conducted fromO(K) methods; but it underperforms the recent result 28.4% in (Huang et al., 2016).",7.1. Classification Problems,[0],[0]
"This is probably because the VGG-16 net works better than the neural network structure used in (Le, 2013) and the distance-based method in (Mensink et al., 2013), while the method in (Huang et al., 2016) adopts a better feature embedding, which leads to superior prediction performance on this dataset.",7.1. Classification Problems,[0],[0]
"In this experiment, we apply the CANE method to neural language modeling.",7.2. Neural Language Modeling,[0],[0]
"We test the methods on two benchmark corpora: the Penn TreeBank (PTB) (Mikolov et al., 2010) and Gutenberg8 corpora.",7.2. Neural Language Modeling,[0],[0]
The Penn TreeBank dataset contains 1M tokens and we choose the most frequent 12K words appearing at least 5 times as the vocabulary.,7.2. Neural Language Modeling,[0],[0]
The Gutenberg dataset contains 50M tokens and the most frequent 116K words appearing at least 10 times are chosen as the vocabulary.,7.2. Neural Language Modeling,[0],[0]
We set the embedding size as 256 and use a LSTM model with 512 hidden states and 256 projection size.,7.2. Neural Language Modeling,[0],[0]
"The sequence length is fixed as 20 and the learning rate is selected from {0.025, 0.05, 0.1, 0.2}.
",7.2. Neural Language Modeling,[0],[0]
"The tree classifiers evaluated in multi-class classification problems can not be directly applied to solve the language modeling problem, so we omit their comparison and focus on the evaluation of the sampling methods.",7.2. Neural Language Modeling,[0],[0]
"We sample 40, 60 and 80 noises for NCE and Blackout respectively and use power-raised unigram distribution with the power factor selected from {0, 0.25, 0.5, 0.75, 1}.",7.2. Neural Language Modeling,[0],[0]
"For CANE, we adopt the one-layer tree structure discussed in Section 5 with N = 6 subsets, split by averaging over the word frequencies.",7.2. Neural Language Modeling,[0],[0]
We uniformly sample the candidates when reaching any subset.,7.2. Neural Language Modeling,[0],[0]
"For efficiency consideration, we respectively sample 40, 60 and 80 candidates plus one more uniform noise for CANE.",7.2. Neural Language Modeling,[0],[0]
"The experiments in this section are implemented on a machine with NVIDIA Tesla M40 GPUs.
",7.2. Neural Language Modeling,[0],[0]
The test perplexities are shown in Fig. 3.,7.2. Neural Language Modeling,[0],[0]
"As we can observe, the CANE method always achieves faster convergence and lower perplexities (approaching that of Softmax) compared to NCE and Blackout under various settings.",7.2. Neural Language Modeling,[0],[0]
"Generally, when the number of selected candidates / noises decrease, the test perplexities of all the methods increase on both datasets, while the performance degradation of CANE is not obvious.",7.2. Neural Language Modeling,[0],[0]
"By using GPUs, all the methods can finish training within a few minutes on the PTB dataset; for the Gutenberg corpus, CANE and BlackOut have similar training time that is around 5 hours on all the three settings, while NCE spends around 6-8 hours on these tasks and Softmax uses 35 hours to finish the training.
",7.2. Neural Language Modeling,[0],[0]
8www.gutenberg.org,7.2. Neural Language Modeling,[0],[0]
We proposed Candidates vs. Noises Estimation (CANE) for fast learning in multi-class classification problems with many labels and applied this method to the word probability estimation problem in neural language models.,8. Conclusion,[0],[0]
"We showed that CANE is consistent and the computation using SGD is always efficient (that is, independent of the class size K).",8. Conclusion,[0],[0]
"Moreover, the new estimator has low statistical variance approaching that of the softmax logistic regression, if the observed class label belongs to the candidate set with high probability.",8. Conclusion,[0],[0]
Empirical results demonstrated that CANE is effective for speeding up both training and prediction in multi-class classification problems and CANE is effective in neural language modeling.,8. Conclusion,[0],[0]
"We note that this work employs a fixed distribution (i.e., the uniform distribution) to sample noises in CANE.",8. Conclusion,[0],[0]
"However it can be very useful in practice to estimate the noise distribution, i.e., q, during training, and select noise classes according to this distribution.",8. Conclusion,[0],[0]
"This paper proposes a method for multi-class classification problems, where the number of classes K is large.",abstractText,[0],[0]
"The method, referred to as Candidates vs. Noises Estimation (CANE), selects a small subset of candidate classes and samples the remaining classes.",abstractText,[0],[0]
We show that CANE is always consistent and computationally efficient.,abstractText,[0],[0]
"Moreover, the resulting estimator has low statistical variance approaching that of the maximum likelihood estimator, when the observed label belongs to the selected candidates with high probability.",abstractText,[0],[0]
"In practice, we use a tree structure with leaves as classes to promote fast beam search for candidate selection.",abstractText,[0],[0]
We further apply the CANE method to estimate word probabilities in learning large neural language models.,abstractText,[0],[0]
"Extensive experimental results show that CANE achieves better prediction accuracy over the Noise-Contrastive Estimation (NCE), its variants and a number of the state-ofthe-art tree classifiers, while it gains significant speedup compared to standard O(K) methods.",abstractText,[0],[0]
Candidates vs. Noises Estimation for Large Multi-Class Classification Problem,title,[0],[0]
"In knowledge base completion, the learner is given triples (subject, predicate, object) of facts about the world, and has to infer new triples that are likely but not yet known to be true.",1. Introduction,[0],[0]
"This problem has attracted a lot of attention (Nickel et al., 2016a; Nguyen, 2017) both as an example application of large-scale tensor factorization, and as a benchmark of learning representations of relational data.
",1. Introduction,[0],[0]
"The standard completion task is link prediction, which consists in answering queries (subject, predicate, ?) or (?, predicate, object).",1. Introduction,[0],[0]
"In that context, the canonical decomposition of tensors (also called CANDECOMP/PARAFAC or CP) (Hitchcock, 1927) is known to perform poorly compared to more specialized methods.",1. Introduction,[0],[0]
"For instance, DistMult (Yang
1Facebook AI Research, Paris, France 2Université Paris-Est, Equipe Imagine, LIGM (UMR8049) Ecole des Ponts ParisTech Marne-la-Vallée, France.",1. Introduction,[0],[0]
"Correspondence to: Lacroix Timothee <timothee.lax@gmail.com>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"et al., 2014), a particular case of CP which shares the factors for the subject and object modes, was recently shown to have state-of-the-art results (Kadlec et al., 2017).",1. Introduction,[0],[0]
"This result is surprising because DistMult learns a tensor that is symmetric in the subject and object modes, while the datasets contain mostly non-symmetric predicates.
",1. Introduction,[0],[0]
The goal of this paper is to study whether and how CP can perform as well as its competitors.,1. Introduction,[0],[0]
"To that end, we evaluate three possibilities.
",1. Introduction,[0],[0]
"First, as Kadlec et al. (2017) showed that performances for these tasks are sensitive to the loss function and optimization parameters, we re-evaluate CP with a broader parameter search and a multiclass log-loss.
",1. Introduction,[0],[0]
"Second, since the best performing approaches are less expressive than CP, we evaluate whether regularization helps.",1. Introduction,[0],[0]
"On this subject, we show that the standard regularization used in knowledge base completion does not correspond to regularization with a tensor norm.",1. Introduction,[0],[0]
"We then propose to use tensor nuclear p-norms (Friedland & Lim, 2018), with the goal of designing more principled regularizers.
",1. Introduction,[0],[0]
"Third, we propose a different formulation of the objective, in which we model separately predicates and their inverse: for each predicate pred, we create an inverse predicate pred−1 and create a triple (obj,pred−1, sub) for each training triple (sub,pred, obj).",1. Introduction,[0],[0]
"At test time, queries of the form (?,pred, obj) are answered as (obj,pred−1, ?).",1. Introduction,[0],[0]
"Similar formulations were previously used by Shen et al. (2016) and Joulin et al. (2017), but for different models for which there was no clear alternative, so the impact of this reformulation has never been evaluated.
",1. Introduction,[0],[0]
"To assess whether the results we obtain are specific to CP, we also carry on the same experiments with a state-of-theart model, ComplEx (Trouillon et al., 2016).",1. Introduction,[0],[0]
"ComplEx has the same expressivity as CP in the sense that it can represent any tensor, but it implements a specific form of parameter sharing.",1. Introduction,[0],[0]
"We perform all our experiments on 5 common benchmark datasets of link prediction in knowledge bases.
",1. Introduction,[0],[0]
"Our results first confirm that within a reasonable time budget, the performance of both CP and ComplEx are highly dependent on optimization parameters.",1. Introduction,[0],[0]
"With systematic parameter searches, we obtain better results for ComplEx than what was previously reported, confirming its status as
a state-of-the-art model on all datasets.",1. Introduction,[0],[0]
"For CP, the results are still way below its competitors.
",1. Introduction,[0],[0]
"Learning and predicting with the inverse predicates, however, changes the picture entirely.",1. Introduction,[0],[0]
"First, with both CP and ComplEx, we obtain significant gains in performance on all the datasets.",1. Introduction,[0],[0]
"More precisely, we obtain state-of-the-art results with CP, matching those of ComplEx.",1. Introduction,[0],[0]
"For instance, on the benchmark dataset FB15K (Bordes et al., 2013), the mean reciprocal rank of vanilla CP and vanilla ComplEx are 0.40 and 0.80 respectively, and it grows to 0.86 for both approaches when modeling the inverse predicates.
",1. Introduction,[0],[0]
"Finally, the new regularizer we propose based on the nuclear 3-norm, does not dramatically help CP, which leads us to believe that a careful choice of regularization is not crucial for these CP models.",1. Introduction,[0],[0]
"Yet, for both CP and ComplEx with inverse predicates, it yields small but significant improvements on the more difficult datasets.",1. Introduction,[0],[0]
"We describe in this section the formal framework we consider for knowledge base completion and more generally link prediction in relational data, the learning criteria, as well as the approaches that we will discuss.",2. Tensor Factorization of Knowledge Bases,[0],[0]
"We consider relational data that comes in the form of triples (subject, predicate, object), where the subject and the object are from the same set of entities.",2.1. Link Prediction in Relational Data,[0],[0]
"In knowledge bases, these triples represent facts about entities of the world, such as (Washington, capital_of, USA).",2.1. Link Prediction in Relational Data,[0],[0]
"A training set S contains triples of indices S = {(i1, j1, k1), ..., (i|S|, j|S|, k|S|)} that represent predicates that are known to hold.",2.1. Link Prediction in Relational Data,[0],[0]
"The validation and test sets contain queries of the form (?, j, k) and (i, j, ?), created from triples (i, j, k) that are known to hold but heldout from the training set.",2.1. Link Prediction in Relational Data,[0],[0]
"To give orders of magnitude, the largest datasets we experiment on, FB15K and YAGO3-10, contain respectively 15k/1.3k and 123k/37 entities/predicates.",2.1. Link Prediction in Relational Data,[0],[0]
"Relational data can be represented as a {0, 1}-valued third order tensor Y ∈ {0, 1}N×P×N , where N is the total number of entities and P the number of predicates, with Yi,j,k",2.2. Tensor Decomposition for Link Prediction,[0],[0]
= 1,2.2. Tensor Decomposition for Link Prediction,[0],[0]
"if the relation (i, j, k) is known.",2.2. Tensor Decomposition for Link Prediction,[0],[0]
"In the rest of the paper, the three modes will be called the subject mode, the predicate mode and the object mode respectively.",2.2. Tensor Decomposition for Link Prediction,[0],[0]
Tensor factorization algorithms can thus be used to infer a predicted tensor X̂ ∈ RN×P×N that approximates Y in a sense that we describe in the next subsection.,2.2. Tensor Decomposition for Link Prediction,[0],[0]
"Val-
idation/test queries (?, j, k) are answered by ordering entities i′ by decreasing values of X̂i′,j,k, whereas queries (i, j, ?) are answered by ordering entities k′ by decreasing values of X̂i,j,k′ .
",2.2. Tensor Decomposition for Link Prediction,[0],[0]
Several approaches have considered link prediction as a low-rank tensor decomposition problem.,2.2. Tensor Decomposition for Link Prediction,[0],[0]
These models then differ only by structural constraints on the learned tensor.,2.2. Tensor Decomposition for Link Prediction,[0],[0]
"Three models of interest are:
CP.",2.2. Tensor Decomposition for Link Prediction,[0],[0]
"The canonical decomposition of tensors, also called CANDECOM/",2.2. Tensor Decomposition for Link Prediction,[0],[0]
"PARAFAC (Hitchcock, 1927), represents a tensor X ∈ RN1×N2×N3 as a sum of R rank one tensors u (1) r ⊗ u(2)r ⊗ u(3)r (with ⊗ the tensor product) where r ∈ {1, ..., R}, and u(m)r ∈ RNm :
X = R∑ r=1 u(1)r ⊗ u(2)r ⊗ u(3)r .
",2.2. Tensor Decomposition for Link Prediction,[0],[0]
"A representation of this decomposition, and the score of a specific triple is given in Figure 1 (a).",2.2. Tensor Decomposition for Link Prediction,[0],[0]
"Given X , the smallest R for which this decomposition holds is called the canonical rank of X .
DistMult.",2.2. Tensor Decomposition for Link Prediction,[0],[0]
"In the more specific context of link prediction, it has been suggested in Bordes et al. (2011); Nickel et al. (2011) that since both subject and object mode represent the same entities, they should have the same factors.",2.2. Tensor Decomposition for Link Prediction,[0],[0]
"DistMult (Yang et al., 2014) is a version of CP with this additional constraint.",2.2. Tensor Decomposition for Link Prediction,[0],[0]
It represents a tensor X ∈ RN×P×N,2.2. Tensor Decomposition for Link Prediction,[0],[0]
"as a sum of rank-1 tensors u(1)r ⊗ u(2)r ⊗ u(1)r :
X = R∑ r=1 u(1)r ⊗ u(2)r ⊗ u(1)r .
ComplEx.",2.2. Tensor Decomposition for Link Prediction,[0],[0]
"By contrast with the first models that proposed to share the subject and object mode factors, DistMult yields a tensor that is symmetric in the object and subject modes.",2.2. Tensor Decomposition for Link Prediction,[0],[0]
"The assumption that the data tensor can be properly approximated by a symmetric tensor for Knowledge base completion is not satisfied in many practical cases (e.g., while (Washington, capital_of, USA) holds, (USA, capital_of,Washington) does not).",2.2. Tensor Decomposition for Link Prediction,[0],[0]
"ComplEx (Trouillon et al., 2016) proposes an alternative where the subject and object modes share the parameters of the factors, but are complex conjugate of each other.",2.2. Tensor Decomposition for Link Prediction,[0],[0]
"More precisely, this approach represents a real-valued tensor X ∈ RN1×N2×N3 as the real part of a sum of R complex-valued rank one tensors u(1)r ⊗ u(2)r ⊗ u(1)r where r ∈ {1, ..., R}, and u(m)r ∈ CNm
X = Re ( R∑ r=1 u(1)r ⊗ u(2)r ⊗ u(1)r ) ,
where u(1)r is the complex conjugate of u (1) r .",2.2. Tensor Decomposition for Link Prediction,[0],[0]
"This decomposition can represent any real tensor (Trouillon et al., 2016).
",2.2. Tensor Decomposition for Link Prediction,[0],[0]
The good performances of DistMult on notoriously nonsymmetric datasets such as FB15K or WN18 are surprising.,2.2. Tensor Decomposition for Link Prediction,[0],[0]
"First, let us note that for the symmetricity to become an issue, one would have to evaluate queries (i, j, ?)",2.2. Tensor Decomposition for Link Prediction,[0],[0]
"while also trying to answer correctly to queries of the form (?, j, i) for a non-symmetric predicate j. The ranking for these two queries would be identical, and thus, we can expect issues with relations such as capital_of .",2.2. Tensor Decomposition for Link Prediction,[0],[0]
"In FB15K, those type of problematic queries make up only 4% of the test set and thus, have a small impact.",2.2. Tensor Decomposition for Link Prediction,[0],[0]
"On WN18 however, they make up 60% of the test set.",2.2. Tensor Decomposition for Link Prediction,[0],[0]
We describe in appendix 8.1 a simple strategy for DistMult to have a high filtered MRR on the hierarchical predicates of WN18 despite its symmetricity assumption.,2.2. Tensor Decomposition for Link Prediction,[0],[0]
"Previous work suggested ranking losses (Bordes et al., 2013), binary logistic regression (Trouillon et al., 2016) or sampled multiclass log-loss (Kadlec et al., 2017).",2.3. Training,[0],[0]
"Motivated by the solid results in Joulin et al. (2017), our own experimental results, and with a satisfactory speed of about two minutes per epoch on FB15K, we decided to use the full multiclass log-loss.
",2.3. Training,[0],[0]
"Given a training triple (i, j, k) and a predicted tensor X , the instantaneous multi-class log-loss ℓi,j,k(X) is
ℓi,j,k(X) = ℓ (1) i,j,k(X)",2.3. Training,[0],[0]
+ ℓ,2.3. Training,[0],[0]
"(3) i,j,k(X) (1)
ℓ (1) i,j,k(X) =",2.3. Training,[0],[0]
"−Xi,j,k + log (∑ k′ exp(Xi,j,k′) )
",2.3. Training,[0],[0]
"ℓ (3) i,j,k(X) =",2.3. Training,[0],[0]
"−Xi,j,k + log (∑ i′ exp(Xi′,j,k) ) .
",2.3. Training,[0],[0]
These two partial losses are represented in Figure 1 (b).,2.3. Training,[0],[0]
"For CP, the final tensor is computed by finding a minimizer
of a regularized empirical risk formulation, where the factors u(d)r are weighted in a data-dependent manner by w (d) S , which we describe below:
min (u (d) r )d=1..3
r=1..R
∑ (i,j,k)∈S ℓi,j,k ( R∑ r=1 u(1)r ⊗ u(2)r ⊗ u(3)r )
",2.3. Training,[0],[0]
+ λ R∑ r=1,2.3. Training,[0],[0]
"3∑ d=1 ∥w(d)S ⊙ u (d) r ∥ 2 2 , (2)
where ⊙ is the entry-wise multiplication of vectors.",2.3. Training,[0],[0]
"For DistMult and ComplEx, the learning objective is similar, up to the appropriate parameter sharing and computation of the tensor.
",2.3. Training,[0],[0]
"As discussed in Section 3.2, the weights w(d)S may improve performances when some rows/columns are sampled more than others.",2.3. Training,[0],[0]
They appear naturally in optimization with stochastic gradient descent when the regularizer is applied only to the parameters that are involved in the computation of the instantaneous loss.,2.3. Training,[0],[0]
"For instance, in the case of the logistic loss with negative sampling used by Trouillon et al. (2016), denoting by qdi the marginal probability (over S) that index i appears in mode d of a data triple, these weights are w(d)S,i = √ qdi + α for some α > 0",2.3. Training,[0],[0]
"that depends on the negative sampling scheme.
",2.3. Training,[0],[0]
We focus on redefining the loss (1) and the regularizer (2).,2.3. Training,[0],[0]
We discuss here in more details the work that has been done on link prediction in relational data and on regularizers for tensor completion.,3. Related Work,[0],[0]
"There has been extensive research on link prediction in relational data, especially in knowledge bases, and we review
here only the prior work that is most relevant to this paper.",3.1. Link Prediction in Relational Data,[0],[0]
"While some approaches explicitly use the graph structure during inference (Lao et al., 2011), we focus here on representation learning and tensor factorization methods, which are the state-of-the-art on the benchmark datasets we use.",3.1. Link Prediction in Relational Data,[0],[0]
"We also restrict the discussion to approaches that only use relational information, even though some approaches have been proposed to leverage additional types (Krompass et al., 2015; Ma et al., 2017) or external word embeddings (Toutanova & Chen, 2015).
",3.1. Link Prediction in Relational Data,[0],[0]
We can divide the first type of approaches into two broad categories.,3.1. Link Prediction in Relational Data,[0],[0]
"First, two-way approaches score a triple (i, j, k) depending only on bigram interaction terms of the form subject-object, subject-predicate, and predicateobject.",3.1. Link Prediction in Relational Data,[0],[0]
"Even though they are tensor approximation algorithms of limited expressivity, two-way models based on translations TransE, or on bag-of-word representations (Joulin et al., 2017) have proved competitive on many benchmarks.",3.1. Link Prediction in Relational Data,[0],[0]
"Yet, methods using three-way multiplicative interactions, as described in the previous section, show the strongest performances (Bordes et al., 2011; GarciaDuran et al., 2016; Nickel et al., 2016b; Trouillon et al., 2016).",3.1. Link Prediction in Relational Data,[0],[0]
"Compared to general-purpose tensor factorization methods such as CP, a common feature of these approaches is to share parameters between objects and subjects modes (Nickel et al., 2011), an idea that has been widely accepted except for the two-way model of Joulin et al. (2017).",3.1. Link Prediction in Relational Data,[0],[0]
"DistMult (Yang et al., 2014) is the extreme case of this parameter sharing, in which the predicted tensor is symmetric in the subject and object modes.",3.1. Link Prediction in Relational Data,[0],[0]
Norm-based regularization has been extensively studied in the context of matrix completion.,3.2. Regularization for Matrix Completion,[0],[0]
"The trace norm (or nuclear norm) has been proposed as a convex relaxation of the rank (Srebro et al., 2005) for matrix completion in the setting of rating prediction, with strong theoretical guarantees (Candès & Recht, 2009).",3.2. Regularization for Matrix Completion,[0],[0]
"While efficient algorithms to solve the convex problems have been proposed (see e.g. Cai et al., 2010; Jaggi et al., 2010), the practice is still to use the matrix equivalent of the nonconvex formulation (2).",3.2. Regularization for Matrix Completion,[0],[0]
"For the trace norm (nuclear 2-norm), in the matrix case, the regularizer simply becomes the squared 2-norm of the factors and lends itself to alternating methods or SGD optimization (Rennie & Srebro, 2005; Koren et al., 2009).",3.2. Regularization for Matrix Completion,[0],[0]
"When the samples are not taken uniformly at random from a matrix, some other norms are preferable to the usual nuclear norm.",3.2. Regularization for Matrix Completion,[0],[0]
"The weighted trace norm reweights elements of the factors based on the marginal rows and columns sampling probabilities, which can improve sample complexity bounds when sampling is non-uniform (Foygel et al., 2011; Negahban & Wainwright, 2012).",3.2. Regularization for Matrix Completion,[0],[0]
"Direct SGD implementations on the nonconvex formulation implicitly take this reweighting rule
into account and were used by the winners of the Netflix challenge (see Srebro & Salakhutdinov, 2010, Section 5).",3.2. Regularization for Matrix Completion,[0],[0]
"There is a large body of literature on low-rank tensor decompositions (see Kolda & Bader, 2009, for a comprehensive review).",3.3. Tensor Completion and Decompositions,[0],[0]
"Closely related to our work is the canonical decomposition of tensor (also called CANDECOMP/PARAFAC or CP) (Hitchcock, 1927), which solves a problem similar to (4) without the regularization (i.e., λ = 0), and usually the square loss.
",3.3. Tensor Completion and Decompositions,[0],[0]
Several norm-based regularizations for tensors have been proposed.,3.3. Tensor Completion and Decompositions,[0],[0]
"Some are based on unfolding a tensor along each of its modes to obtain matricizations, and either regularize by the sum of trace norms of the matricizations (Tomioka et al., 2010) or write the original tensor as a sum of tensors Tk, regularizing their respective kth matricizations with the trace norm (Wimalawarne et al., 2014).",3.3. Tensor Completion and Decompositions,[0],[0]
"However, in the large-scale setting, even rank-1 approximations of matricizations involve too many parameters to be tractable.
",3.3. Tensor Completion and Decompositions,[0],[0]
"Recently, the tensor trace norm (nuclear 2-norm) was proposed as a regularizer for tensor completion Yuan & Zhang (2016), and an algorithm based on the generalized conditional gradient has been developed by Cheng et al. (2016).",3.3. Tensor Completion and Decompositions,[0],[0]
"This algorithm requires, in an inner loop, to compute a (constrained) rank-1 tensor that has largest dot-product with the gradient of the data-fitting term (gradient w.r.t.",3.3. Tensor Completion and Decompositions,[0],[0]
the tensor argument).,3.3. Tensor Completion and Decompositions,[0],[0]
"This algorithm is efficient in our setup only with the square error loss (instead of the multiclass log-loss), because the gradient is then a low-rank + sparse tensor when the argument is low-rank.",3.3. Tensor Completion and Decompositions,[0],[0]
"However, on large-scale knowledge bases, the state of the art is to use a binary log-loss or a multiclass log-loss (Trouillon et al., 2016; Kadlec et al., 2017); in that case, the gradient is not adequately structured, thereby causing the approach of (Cheng et al., 2016) to be too computationally costly.
",3.3. Tensor Completion and Decompositions,[0],[0]
4.,3.3. Tensor Completion and Decompositions,[0],[0]
"Nuclear p-Norm Regularization As discussed in Section 3, norm-based regularizers have proved useful for matrices.",3.3. Tensor Completion and Decompositions,[0],[0]
We aim to reproduce these successes with tensor norms.,3.3. Tensor Completion and Decompositions,[0],[0]
We use the nuclear p-norms defined by Friedland & Lim (2018).,3.3. Tensor Completion and Decompositions,[0],[0]
"As shown in Equation (2), the community has favored so far a regularizer based on the square Frobenius norms of the factors (Yang et al., 2014; Trouillon et al., 2016).",3.3. Tensor Completion and Decompositions,[0],[0]
We first show that the unweighted version of this regularizer is not a tensor norm.,3.3. Tensor Completion and Decompositions,[0],[0]
"Then, we propose4 a variational form of the nuclear 3-norm to replace the usual regularization at no additional computational cost when used with SGD.",3.3. Tensor Completion and Decompositions,[0],[0]
"Finally, we discuss a weighting scheme analogous to the weighted trace-norm proposed in Srebro & Salakhutdinov (2010).",3.3. Tensor Completion and Decompositions,[0],[0]
"To simplify notation, let us introduce the set of CP decompositions of a tensor X of rank at most R:
UR(X) = { (u(d)r )d=1..3
r=1..R ∣∣∣ X = R∑ r=1 u(1)r ⊗ u(2)r ⊗ u(3)r ,
∀r, d, u(d)r ∈ RNd } .
",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"We will study the family of regularizers:
Ωαp (u) = 1
3 R∑ r=1",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"3∑ d=1 ∥u(d)r ∥ α p .
",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"Note that with p = α = 2, we recover the familiar squared Frobenius norm regularizer used in (2).",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"Similar to showing that the squared Frobenius norm is a variational form of the trace norm on matrices (i.e., its minimizers realize the trace norm, infM=UV T 12 (∥U∥ 2",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"F+∥V ∥2F ) = ∥M∥∗), we start with a technical lemma that links our regularizer with a function on the spectrum of our decompositions.",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"Lemma 1.
min u∈UR(X)
1
3 R∑ r=1",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
3∑ d=1 ∥u(d)r ∥ α,4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
p = min u∈UR(X) R∑ r=1,4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"3∏ d=1 ∥u(d)r ∥ α/3 p .
",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"Moreover, the minimizers of the left-hand side satisfy:
∥u(d)r ∥p = 3 √√√√ 3∏ d′=1 ∥u(d ′)",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"r ∥p.
Proof.",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"See Appendix 8.2.
",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"This Lemma motivates the introduction of the set of p-norm normalized tensor decompositions:
UpR(X) =",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"{ (σr, (ũr))r=1..R ∣∣∣ σr",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"= 3∏ d=1 ∥u(d)r ∥p,
ũ(d)r = u (d) r
∥u(d)r ∥p ,∀r, d, u ∈ UR(X)
} .
",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"Lemma 1, shows that Ωαp behaves as an ℓα/D penalty over the CP spectrum for tensors of order D. We recover the nuclear norm for matrices when α = p = 2.
",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"Using Lemma 1, we have :
min u∈UR(X) Ω22(u)",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"≤ η ⇐⇒ min (σ,ũ)∈U2R(X) ∥σ∥2/3≤",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"η3/2
(3)
",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"We show that the sub-level sets of the term on the right are not convex, which implies that Ω22 is not the variational form of a tensor norm, and hence, is not the tensor analog to the matrix trace norm.
",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
Proposition 1.,4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"The function over third order-tensors of RN1×N2×N3 defined as
|||X||| = min { ∥σ∥2/3 ∣∣∣",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"(σ, ũ) ∈ U2R(X), R ∈ N} is not convex.
",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
Proof.,4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"See Appendix 8.2.
",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
Remark 1.,4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"Cheng et al. (2016, Appendix D) already showed that regularizing with the square Frobenius norm of the factors is not related to the trace norm for tensors of order 3 and above, but their observation is that the regularizer is not positively homogeneous, i.e., minu∈αUR(X) Ω 2 2(u) ̸= |α|minu∈UR(X) Ω22(u).",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"Our result in Proposition 1 is stronger in that we show that this regularizer is not a norm even after the rescaling (3) to make it homogeneous.
",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
The nuclear p-norm of X ∈ RN1×N2×N3 for p ∈,4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"[1,+∞], is defined in Friedland & Lim (2018) as
∥X∥∗,p := min { ∥σ∥1 ∣∣∣ (σ, ũ) ∈ UpR(X), R ∈ N} .",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"Given an estimated upper bound on the optimal R, the original problem (2) can then be re-written as a non-convex problem using the equivalence in Lemma 1:
min (u (d) r )d=1..3
r=1..R
∑ (i,j,k)∈S ℓi,j,k ( R∑ r=1 u(1)r ⊗ u(2)r ⊗ u(3)r )
+ λ
3 R∑ r=1 3∑ d=1 ∥u(d)r ∥ 3 p .",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"(4)
",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"This variational form suggests to use p = 3, as a means to make the regularizer separable in each coefficients, given that then ∥u(d)r ∥3p = ∑nd i=1",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"∣∣u(d)r,i |3.",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
4.2.,4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"Weighted Nuclear p-Norm
Similar to the weighted trace-norm for matrices, the weighted nuclear 3-norm can be easily implemented by keeping the regularization terms corresponding to the sampled triplets only, as discussed in Section 3.2.",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"This leads to a formulation of the form
min (u (d) r )d=1..3
r=1..R
∑ (i,j,k)∈S [ ℓi,j,k ( R∑ r=1 u(1)r ⊗u(2)r ⊗u(3)r )
(5)
+ λ
3 R∑ r=1 (∣∣u(1)r,i |3 + ∣∣u(2)r,j |3 + ∣∣u(3)r,k|3)].",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"For an example (i, j, k), only the parameters involved in the computation of X̂i,j,k are regularized.",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"The computational
complexity is thus the same as the currently used weighted Frobenius norm regularizer.",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"With q(1) (resp. q(2), q(3))",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
the marginal probabilities of sampling a subject (resp.,4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"predicate, object), the weighting implied by this regularization scheme is
∥X∥∗,3,w = ∥( 3 √ q(1) ⊗ 3 √ q(2) ⊗ 3",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"√ q(3))⊙X∥∗,3
We justify this weighting only by analogy with the matrix case discussed by (Srebro & Salakhutdinov, 2010): to make the weighted nuclear 3-norm of the all 1 tensor independent of its dimensions for a uniform sampling (since the nuclear 3-norm grows as 3 √ MNP for an (M,N,P ) tensor).
",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"Comparatively, for the weighted version of the nuclear 2- norm analyzed in Yuan & Zhang (2016), the nuclear 2- norm of the all 1 tensor scales like √ NMP .",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"This would imply a formulation of the form
min (u (d) r )d=1..3
r=1..R
∑ (i,j,k)∈S ℓi,j,k ( R∑ r=1 u(1)r ⊗ u(2)r ⊗ u(3)r )
+ λ
3 R∑ r=1",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
3∑ d=1 ∥ √ q(d) ⊙ u(d)r ∥ 3 2 .,4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"(6)
Contrary to formulation (5), the optimization of formulation (6) with a minibatch SGD leads to an update of every coefficients for each mini-batch considered.",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"Depending on the implementation, and size of the factors, there might be a large difference in speed between the updates of the weighted nuclear {2, 3}-norm.",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"In our implementation, this difference for CP is of about 1.5× in favor of the nuclear 3-norm on FB15K.",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"Since our evaluation objective is to rank either the lefthand side or right-hand side of the predicates in our dataset, what we are trying to achieve is to model both predicates and their reciprocal.",5. A New CP Objective,[0],[0]
"This suggests appending to our input the reciprocals of each predicates, thus factorizing [Y ;2 Ỹ ] rather than Y , where [ ;2 ] is the mode-2 concatenation, and Yi,j,k = Ỹk,j,i. After that, we only need to model the object fibers of this new tensor Y .",5. A New CP Objective,[0],[0]
We represent this transformation in Figure 1 (c).,5. A New CP Objective,[0],[0]
This reformulation has an important side-effect: it makes our algorithm invariant to the arbitrary choice of including a predicate or its reciprocal in the dataset.,5. A New CP Objective,[0],[0]
"This property was introduced as ""Semantic Invariance"" in Bailly et al. (2015).",5. A New CP Objective,[0],[0]
Another way of achieving this invariance property would be to find the flipping of predicates that lead to the smallest model.,5. A New CP Objective,[0],[0]
"In the case of a CP decomposition, we would try to find the flipping that leads to lowest tensor rank.",5. A New CP Objective,[0],[0]
"This seems hopeless, given the NP-hardness of computing the tensor rank.
",5. A New CP Objective,[0],[0]
"More precisely, the instantaneous loss of a training triple (i, j, k) becomes :
ℓi,j,k(X) =−Xi,j,k + log (∑
k′
exp(Xi,j,k′) )
(7)
−Xk,j+P,i + log (∑
i′
exp(Xk,j+P,i′) ) .
",5. A New CP Objective,[0],[0]
"At test time we use X̂i,j,: to rank possible right hand sides for query (i, j, ?) and X̂k,j+P,: to rank possible left hand sides for query (?, j, k).
",5. A New CP Objective,[0],[0]
"Using CP to factor the tensor described in (7), we beat the previous state of the art on many benchmarks, as shown in Table 2.",5. A New CP Objective,[0],[0]
"This reformulation seems to help even the ComplEx decomposition, for which parameters are shared between the entity embeddings of the first and third mode.",5. A New CP Objective,[0],[0]
We conducted all experiments on a Quadro GP 100 GPU.,6. Experiments,[0],[0]
The code is available at https://github.com/ facebookresearch/kbc.,6. Experiments,[0],[0]
WN18 and FB15K are popular benchmarks in the Knowledge Base Completion community.,6.1. Datasets and Experimental Setup,[0],[0]
"The former comes from the WordNet database, was introduced in Bordes et al. (2014) and describes relations between words.",6.1. Datasets and Experimental Setup,[0],[0]
"The most frequent types of relations are highly hierarchical (e.g., hypernym, hyponym).",6.1. Datasets and Experimental Setup,[0],[0]
"The latter is a subsampling of Freebase limited to 15k entities, introduced in Bordes et al. (2013).",6.1. Datasets and Experimental Setup,[0],[0]
"It contains predicates with different characteristics (e.g., oneto-one relations such as capital_of to many-to-many such as actor_in_film).
",6.1. Datasets and Experimental Setup,[0],[0]
"Toutanova & Chen (2015) and Dettmers et al. (2017) identified train to test leakage in both these datasets, in the form of test triplets, present in the train set for the reciprocal predicates.",6.1. Datasets and Experimental Setup,[0],[0]
"Thus, both of these authors created two modified datasets: FB15K-237 and WN18RR.",6.1. Datasets and Experimental Setup,[0],[0]
"These datasets are harder to fit, so we expect regularization to have more impact.",6.1. Datasets and Experimental Setup,[0],[0]
"Dettmers et al. (2017) also introduced the dataset YAGO3-10, which is larger in scale and doesn’t suffer from leakage.",6.1. Datasets and Experimental Setup,[0],[0]
"All datasets statistics are shown in Table 1.
",6.1. Datasets and Experimental Setup,[0],[0]
"In all our experiments, we distinguish two settings: Reciprocal, in which we use the loss described in equation (7) and Standard, which uses the loss in equation (1).",6.1. Datasets and Experimental Setup,[0],[0]
"We compare our implementation of CP and ComplEx with the best published results, then the different performances between the two settings, and finally, the contribution of the regularizer in the reciprocal setting.",6.1. Datasets and Experimental Setup,[0],[0]
"In the Reciprocal setting, we compare the weighted nuclear 3-norm (N3) against the regularizer described in (2) (FRO).",6.1. Datasets and Experimental Setup,[0],[0]
"In preliminary experiments, the weighted nuclear 2-norm described in (6) did not seem to perform better than N3 and was slightly slower.",6.1. Datasets and Experimental Setup,[0],[0]
"We used Adagrad (Duchi et al., 2011) as our optimizer, whereas Kadlec et al. (2017) favored Adam (Kingma & Ba, 2014), because preliminary experiments didn’t show improvements.
",6.1. Datasets and Experimental Setup,[0],[0]
"We ran the same grid for all algorithms and regularizers on the FB15K, FB15K-237, WN18, WN18RR datasets, with a rank set to 2000 for ComplEx, and 4000 for CP.",6.1. Datasets and Experimental Setup,[0],[0]
"Our grid consisted of two learning rates: 10−1 and 10−2, two batch-sizes: 25 and 100, and regularization coefficients in [0, 10−3, 5.10−3, 10−2, 5.10−2, 10−1, 5.10−1].",6.1. Datasets and Experimental Setup,[0],[0]
"On YAGO3-10, we limited our models to rank 1000 and used batch-sizes 500 and 3000, the rest of the grid was identical.",6.1. Datasets and Experimental Setup,[0],[0]
We used the train/valid/test splits provided with these datasets and measured the filtered Mean Reciprocal Rank (MRR) and Hits@10 (Bordes et al. (2013)).,6.1. Datasets and Experimental Setup,[0],[0]
We used the filtered MRR on the validation set for early stopping and report the corresponding test metrics.,6.1. Datasets and Experimental Setup,[0],[0]
"In this setting, an epoch for ComplEx with batch-size 100 on FB15K took about 110s and 325s for a batch-size of 25.",6.1. Datasets and Experimental Setup,[0],[0]
"We trained for 100 epochs to ensure convergence, reported performances were reached within the first 25 epochs.
",6.1. Datasets and Experimental Setup,[0],[0]
All our results are reported in Table 2 and will be discussed in the next subsections.,6.1. Datasets and Experimental Setup,[0],[0]
"Besides our implementations of CP and ComplEx, we include the results of ConvE and DistMult in the baselines.",6.1. Datasets and Experimental Setup,[0],[0]
"The former because Dettmers et al. (2017) includes performances on the WN18RR and YAGO3-10 benchmarks, the latter because of the good performances on FB15K of DistMult and the extensive experiments on WN18 and FB15K reported in Kadlec et al. (2017).",6.1. Datasets and Experimental Setup,[0],[0]
"The performances of DistMult on FB15K-237, WN18RR and YAGO3-10 may be slightly underestimated, since our baseline CP results are better.",6.1. Datasets and Experimental Setup,[0],[0]
"To avoid clutter, we did not include in our table of results algorithms that make use of external data such as types (Krompass et al., 2015), external word embeddings (Toutanova & Chen, 2015), or using path queries as regularizers (Guu et al., 2015).",6.1. Datasets and Experimental Setup,[0],[0]
"The published results corresponding to these methods are subsumed in the ""Best Published"" line of Table 2, which is taken, for every single metric and dataset, as the best published result we were able to find.",6.1. Datasets and Experimental Setup,[0],[0]
The performances of our reimplementation of CP and ComplEx appear in the middle rows of Table 2 (Standard setting).,6.2. Reimplementation of the Baselines,[0],[0]
"We only kept the results for the nuclear 3-norm, which didn’t seem to differ from those with the Frobenius norm.",6.2. Reimplementation of the Baselines,[0],[0]
"Our results are slightly better than their published counterparts, going from 0.33 to 0.46 filtered MRR on FB15K for CP and 0.70 to 0.80 for ComplEx.",6.2. Reimplementation of the Baselines,[0],[0]
"This might be explained in part by the fact that in the Standard setting (2) we use a multi-class log-loss, whereas Trouillon et al. (2016) used binomial negative log-likelihood.",6.2. Reimplementation of the Baselines,[0],[0]
"Another reason for this increase can be the large rank of 2000
that we chose, where previously published results used a rank of around 200; the more extensive search for optimization/regularization parameters and the use of nuclear 3-norm instead of the usual regularization are also most likely part of the explanation.",6.2. Reimplementation of the Baselines,[0],[0]
"In this section, we compare the effect of reformulation (7), that is, the middle and bottom rows of Table 2.",6.3. Standard vs Reciprocal,[0],[0]
"The largest differences are obtained for CP, which becomes a state of the art contender going from 0.2 to 0.95 filtered MRR on WN18, or from 0.46 to 0.86 filtered MRR on FB15K.For ComplEx, we notice a weaker, but consistent improvement by using our reformulation, with the biggest improvements observed on FB15K and YAGO3-10.",6.3. Standard vs Reciprocal,[0],[0]
"Following the analysis in Bordes et al. (2013), we show in Table 3 the average filtered MRR as a function of the degree of the predicates.",6.3. Standard vs Reciprocal,[0],[0]
"We compute the average in and out degrees on the training set, and separate the predicates in 4 categories : 1-1, 1-m, m-1 and m-m, with a cut-off at 1.5 on the average degree.",6.3. Standard vs Reciprocal,[0],[0]
We include reciprocal predicates in these statistics.,6.3. Standard vs Reciprocal,[0],[0]
"That is, a predicate with an average in-degree of 1.2 and average out-degree of 3.2 will count as a 1-m when we predict its right-hand side, and as an m-1 when we predict its lefthand side.",6.3. Standard vs Reciprocal,[0],[0]
"Most of our improvements come from the 1-m and m-m categories, both on ComplEx and CP.",6.3. Standard vs Reciprocal,[0],[0]
"We focus now on the effect of our norm-based N3 regularizer, compared to the Frobenius norm regularizer favored by the community.",6.4. Frobenius vs Nuclear 3,[0],[0]
"Comparing the four last rows of Table 2, we notice a small but consistent performance gain across datasets.",6.4. Frobenius vs Nuclear 3,[0],[0]
"The biggest improvements appear on the harder datasets WN18RR, FB15K-237 and YAGO3-10.",6.4. Frobenius vs Nuclear 3,[0],[0]
We checked on WN18RR the significance of that gain with a Signed Rank test on the rank pairs for CP.,6.4. Frobenius vs Nuclear 3,[0],[0]
"During these experiments, we noticed a heavy influence of optimization hyper-parameters on final results.",6.5. Effect of Optimization Parameters,[0],[0]
This influence can account for as much as 0.1 filtered MRR and is illustrated in Figure 2.,6.5. Effect of Optimization Parameters,[0],[0]
The main contribution of this paper is to isolate and systematically explore the effect of different factors for large-scale knowledge base completion.,7. Conclusion and Discussion,[0],[0]
"While the impact of optimization parameters was well known already, neither the effect of the formulation (adding reciprocals doubles the mean reciprocal rank on FB15K for CP) nor the impact of the regularization was properly assessed.",7. Conclusion and Discussion,[0],[0]
The conclusion is that the CP model performs nearly as well as the competitors when each model is evaluated in its optimal configuration.,7. Conclusion and Discussion,[0],[0]
"We believe this observation is important to assess and prioritize directions for further research on the topic.
",7. Conclusion and Discussion,[0],[0]
"In addition, our proposal to use nuclear p-norm as regularizers with p ̸= 2 for tensor factorization in general is of independent interest.
",7. Conclusion and Discussion,[0],[0]
The results we present leave several questions open.,7. Conclusion and Discussion,[0],[0]
"Notably, whereas we give definite evidence that CP itself can perform extremely well on these datasets as long as the problem is formulated correctly, we do not have a strong theoretical justification as to why the differences in performances are so significant.",7. Conclusion and Discussion,[0],[0]
The authors thank Armand Joulin and Maximilian Nickel for valuable discussions.,Acknowledgements,[0],[0]
The problem of Knowledge Base Completion can be framed as a 3rd-order binary tensor completion problem.,abstractText,[0],[0]
"In this light, the Canonical Tensor Decomposition (CP) (Hitchcock, 1927) seems like a natural solution; however, current implementations of CP on standard Knowledge Base Completion benchmarks are lagging behind their competitors.",abstractText,[0],[0]
"In this work, we attempt to understand the limits of CP for knowledge base completion.",abstractText,[0],[0]
"First, we motivate and test a novel regularizer, based on tensor nuclear p-norms.",abstractText,[0],[0]
"Then, we present a reformulation of the problem that makes it invariant to arbitrary choices in the inclusion of predicates or their reciprocals in the dataset.",abstractText,[0],[0]
"These two methods combined allow us to beat the current state of the art on several datasets with a CP decomposition, and obtain even better results using the more advanced ComplEx model.",abstractText,[0],[0]
Canonical Tensor Decomposition for Knowledge Base Completion,title,[0],[0]
"In knowledge base completion, the learner is given triples (subject, predicate, object) of facts about the world, and has to infer new triples that are likely but not yet known to be true.",1. Introduction,[0],[0]
"This problem has attracted a lot of attention (Nickel et al., 2016a; Nguyen, 2017) both as an example application of large-scale tensor factorization, and as a benchmark of learning representations of relational data.
",1. Introduction,[0],[0]
"The standard completion task is link prediction, which consists in answering queries (subject, predicate, ?) or (?, predicate, object).",1. Introduction,[0],[0]
"In that context, the canonical decomposition of tensors (also called CANDECOMP/PARAFAC or CP) (Hitchcock, 1927) is known to perform poorly compared to more specialized methods.",1. Introduction,[0],[0]
"For instance, DistMult (Yang
1Facebook AI Research, Paris, France 2Université Paris-Est, Equipe Imagine, LIGM (UMR8049) Ecole des Ponts ParisTech Marne-la-Vallée, France.",1. Introduction,[0],[0]
"Correspondence to: Lacroix Timothee <timothee.lax@gmail.com>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"et al., 2014), a particular case of CP which shares the factors for the subject and object modes, was recently shown to have state-of-the-art results (Kadlec et al., 2017).",1. Introduction,[0],[0]
"This result is surprising because DistMult learns a tensor that is symmetric in the subject and object modes, while the datasets contain mostly non-symmetric predicates.
",1. Introduction,[0],[0]
The goal of this paper is to study whether and how CP can perform as well as its competitors.,1. Introduction,[0],[0]
"To that end, we evaluate three possibilities.
",1. Introduction,[0],[0]
"First, as Kadlec et al. (2017) showed that performances for these tasks are sensitive to the loss function and optimization parameters, we re-evaluate CP with a broader parameter search and a multiclass log-loss.
",1. Introduction,[0],[0]
"Second, since the best performing approaches are less expressive than CP, we evaluate whether regularization helps.",1. Introduction,[0],[0]
"On this subject, we show that the standard regularization used in knowledge base completion does not correspond to regularization with a tensor norm.",1. Introduction,[0],[0]
"We then propose to use tensor nuclear p-norms (Friedland & Lim, 2018), with the goal of designing more principled regularizers.
",1. Introduction,[0],[0]
"Third, we propose a different formulation of the objective, in which we model separately predicates and their inverse: for each predicate pred, we create an inverse predicate pred−1 and create a triple (obj,pred−1, sub) for each training triple (sub,pred, obj).",1. Introduction,[0],[0]
"At test time, queries of the form (?,pred, obj) are answered as (obj,pred−1, ?).",1. Introduction,[0],[0]
"Similar formulations were previously used by Shen et al. (2016) and Joulin et al. (2017), but for different models for which there was no clear alternative, so the impact of this reformulation has never been evaluated.
",1. Introduction,[0],[0]
"To assess whether the results we obtain are specific to CP, we also carry on the same experiments with a state-of-theart model, ComplEx (Trouillon et al., 2016).",1. Introduction,[0],[0]
"ComplEx has the same expressivity as CP in the sense that it can represent any tensor, but it implements a specific form of parameter sharing.",1. Introduction,[0],[0]
"We perform all our experiments on 5 common benchmark datasets of link prediction in knowledge bases.
",1. Introduction,[0],[0]
"Our results first confirm that within a reasonable time budget, the performance of both CP and ComplEx are highly dependent on optimization parameters.",1. Introduction,[0],[0]
"With systematic parameter searches, we obtain better results for ComplEx than what was previously reported, confirming its status as
a state-of-the-art model on all datasets.",1. Introduction,[0],[0]
"For CP, the results are still way below its competitors.
",1. Introduction,[0],[0]
"Learning and predicting with the inverse predicates, however, changes the picture entirely.",1. Introduction,[0],[0]
"First, with both CP and ComplEx, we obtain significant gains in performance on all the datasets.",1. Introduction,[0],[0]
"More precisely, we obtain state-of-the-art results with CP, matching those of ComplEx.",1. Introduction,[0],[0]
"For instance, on the benchmark dataset FB15K (Bordes et al., 2013), the mean reciprocal rank of vanilla CP and vanilla ComplEx are 0.40 and 0.80 respectively, and it grows to 0.86 for both approaches when modeling the inverse predicates.
",1. Introduction,[0],[0]
"Finally, the new regularizer we propose based on the nuclear 3-norm, does not dramatically help CP, which leads us to believe that a careful choice of regularization is not crucial for these CP models.",1. Introduction,[0],[0]
"Yet, for both CP and ComplEx with inverse predicates, it yields small but significant improvements on the more difficult datasets.",1. Introduction,[0],[0]
"We describe in this section the formal framework we consider for knowledge base completion and more generally link prediction in relational data, the learning criteria, as well as the approaches that we will discuss.",2. Tensor Factorization of Knowledge Bases,[0],[0]
"We consider relational data that comes in the form of triples (subject, predicate, object), where the subject and the object are from the same set of entities.",2.1. Link Prediction in Relational Data,[0],[0]
"In knowledge bases, these triples represent facts about entities of the world, such as (Washington, capital_of, USA).",2.1. Link Prediction in Relational Data,[0],[0]
"A training set S contains triples of indices S = {(i1, j1, k1), ..., (i|S|, j|S|, k|S|)} that represent predicates that are known to hold.",2.1. Link Prediction in Relational Data,[0],[0]
"The validation and test sets contain queries of the form (?, j, k) and (i, j, ?), created from triples (i, j, k) that are known to hold but heldout from the training set.",2.1. Link Prediction in Relational Data,[0],[0]
"To give orders of magnitude, the largest datasets we experiment on, FB15K and YAGO3-10, contain respectively 15k/1.3k and 123k/37 entities/predicates.",2.1. Link Prediction in Relational Data,[0],[0]
"Relational data can be represented as a {0, 1}-valued third order tensor Y ∈ {0, 1}N×P×N , where N is the total number of entities and P the number of predicates, with Yi,j,k",2.2. Tensor Decomposition for Link Prediction,[0],[0]
= 1,2.2. Tensor Decomposition for Link Prediction,[0],[0]
"if the relation (i, j, k) is known.",2.2. Tensor Decomposition for Link Prediction,[0],[0]
"In the rest of the paper, the three modes will be called the subject mode, the predicate mode and the object mode respectively.",2.2. Tensor Decomposition for Link Prediction,[0],[0]
Tensor factorization algorithms can thus be used to infer a predicted tensor X̂ ∈ RN×P×N that approximates Y in a sense that we describe in the next subsection.,2.2. Tensor Decomposition for Link Prediction,[0],[0]
"Val-
idation/test queries (?, j, k) are answered by ordering entities i′ by decreasing values of X̂i′,j,k, whereas queries (i, j, ?) are answered by ordering entities k′ by decreasing values of X̂i,j,k′ .
",2.2. Tensor Decomposition for Link Prediction,[0],[0]
Several approaches have considered link prediction as a low-rank tensor decomposition problem.,2.2. Tensor Decomposition for Link Prediction,[0],[0]
These models then differ only by structural constraints on the learned tensor.,2.2. Tensor Decomposition for Link Prediction,[0],[0]
"Three models of interest are:
CP.",2.2. Tensor Decomposition for Link Prediction,[0],[0]
"The canonical decomposition of tensors, also called CANDECOM/",2.2. Tensor Decomposition for Link Prediction,[0],[0]
"PARAFAC (Hitchcock, 1927), represents a tensor X ∈ RN1×N2×N3 as a sum of R rank one tensors u (1) r ⊗ u(2)r ⊗ u(3)r (with ⊗ the tensor product) where r ∈ {1, ..., R}, and u(m)r ∈ RNm :
X = R∑ r=1 u(1)r ⊗ u(2)r ⊗ u(3)r .
",2.2. Tensor Decomposition for Link Prediction,[0],[0]
"A representation of this decomposition, and the score of a specific triple is given in Figure 1 (a).",2.2. Tensor Decomposition for Link Prediction,[0],[0]
"Given X , the smallest R for which this decomposition holds is called the canonical rank of X .
DistMult.",2.2. Tensor Decomposition for Link Prediction,[0],[0]
"In the more specific context of link prediction, it has been suggested in Bordes et al. (2011); Nickel et al. (2011) that since both subject and object mode represent the same entities, they should have the same factors.",2.2. Tensor Decomposition for Link Prediction,[0],[0]
"DistMult (Yang et al., 2014) is a version of CP with this additional constraint.",2.2. Tensor Decomposition for Link Prediction,[0],[0]
It represents a tensor X ∈ RN×P×N,2.2. Tensor Decomposition for Link Prediction,[0],[0]
"as a sum of rank-1 tensors u(1)r ⊗ u(2)r ⊗ u(1)r :
X = R∑ r=1 u(1)r ⊗ u(2)r ⊗ u(1)r .
ComplEx.",2.2. Tensor Decomposition for Link Prediction,[0],[0]
"By contrast with the first models that proposed to share the subject and object mode factors, DistMult yields a tensor that is symmetric in the object and subject modes.",2.2. Tensor Decomposition for Link Prediction,[0],[0]
"The assumption that the data tensor can be properly approximated by a symmetric tensor for Knowledge base completion is not satisfied in many practical cases (e.g., while (Washington, capital_of, USA) holds, (USA, capital_of,Washington) does not).",2.2. Tensor Decomposition for Link Prediction,[0],[0]
"ComplEx (Trouillon et al., 2016) proposes an alternative where the subject and object modes share the parameters of the factors, but are complex conjugate of each other.",2.2. Tensor Decomposition for Link Prediction,[0],[0]
"More precisely, this approach represents a real-valued tensor X ∈ RN1×N2×N3 as the real part of a sum of R complex-valued rank one tensors u(1)r ⊗ u(2)r ⊗ u(1)r where r ∈ {1, ..., R}, and u(m)r ∈ CNm
X = Re ( R∑ r=1 u(1)r ⊗ u(2)r ⊗ u(1)r ) ,
where u(1)r is the complex conjugate of u (1) r .",2.2. Tensor Decomposition for Link Prediction,[0],[0]
"This decomposition can represent any real tensor (Trouillon et al., 2016).
",2.2. Tensor Decomposition for Link Prediction,[0],[0]
The good performances of DistMult on notoriously nonsymmetric datasets such as FB15K or WN18 are surprising.,2.2. Tensor Decomposition for Link Prediction,[0],[0]
"First, let us note that for the symmetricity to become an issue, one would have to evaluate queries (i, j, ?)",2.2. Tensor Decomposition for Link Prediction,[0],[0]
"while also trying to answer correctly to queries of the form (?, j, i) for a non-symmetric predicate j. The ranking for these two queries would be identical, and thus, we can expect issues with relations such as capital_of .",2.2. Tensor Decomposition for Link Prediction,[0],[0]
"In FB15K, those type of problematic queries make up only 4% of the test set and thus, have a small impact.",2.2. Tensor Decomposition for Link Prediction,[0],[0]
"On WN18 however, they make up 60% of the test set.",2.2. Tensor Decomposition for Link Prediction,[0],[0]
We describe in appendix 8.1 a simple strategy for DistMult to have a high filtered MRR on the hierarchical predicates of WN18 despite its symmetricity assumption.,2.2. Tensor Decomposition for Link Prediction,[0],[0]
"Previous work suggested ranking losses (Bordes et al., 2013), binary logistic regression (Trouillon et al., 2016) or sampled multiclass log-loss (Kadlec et al., 2017).",2.3. Training,[0],[0]
"Motivated by the solid results in Joulin et al. (2017), our own experimental results, and with a satisfactory speed of about two minutes per epoch on FB15K, we decided to use the full multiclass log-loss.
",2.3. Training,[0],[0]
"Given a training triple (i, j, k) and a predicted tensor X , the instantaneous multi-class log-loss ℓi,j,k(X) is
ℓi,j,k(X) = ℓ (1) i,j,k(X)",2.3. Training,[0],[0]
+ ℓ,2.3. Training,[0],[0]
"(3) i,j,k(X) (1)
ℓ (1) i,j,k(X) =",2.3. Training,[0],[0]
"−Xi,j,k + log (∑ k′ exp(Xi,j,k′) )
",2.3. Training,[0],[0]
"ℓ (3) i,j,k(X) =",2.3. Training,[0],[0]
"−Xi,j,k + log (∑ i′ exp(Xi′,j,k) ) .
",2.3. Training,[0],[0]
These two partial losses are represented in Figure 1 (b).,2.3. Training,[0],[0]
"For CP, the final tensor is computed by finding a minimizer
of a regularized empirical risk formulation, where the factors u(d)r are weighted in a data-dependent manner by w (d) S , which we describe below:
min (u (d) r )d=1..3
r=1..R
∑ (i,j,k)∈S ℓi,j,k ( R∑ r=1 u(1)r ⊗ u(2)r ⊗ u(3)r )
",2.3. Training,[0],[0]
+ λ R∑ r=1,2.3. Training,[0],[0]
"3∑ d=1 ∥w(d)S ⊙ u (d) r ∥ 2 2 , (2)
where ⊙ is the entry-wise multiplication of vectors.",2.3. Training,[0],[0]
"For DistMult and ComplEx, the learning objective is similar, up to the appropriate parameter sharing and computation of the tensor.
",2.3. Training,[0],[0]
"As discussed in Section 3.2, the weights w(d)S may improve performances when some rows/columns are sampled more than others.",2.3. Training,[0],[0]
They appear naturally in optimization with stochastic gradient descent when the regularizer is applied only to the parameters that are involved in the computation of the instantaneous loss.,2.3. Training,[0],[0]
"For instance, in the case of the logistic loss with negative sampling used by Trouillon et al. (2016), denoting by qdi the marginal probability (over S) that index i appears in mode d of a data triple, these weights are w(d)S,i = √ qdi + α for some α > 0",2.3. Training,[0],[0]
"that depends on the negative sampling scheme.
",2.3. Training,[0],[0]
We focus on redefining the loss (1) and the regularizer (2).,2.3. Training,[0],[0]
We discuss here in more details the work that has been done on link prediction in relational data and on regularizers for tensor completion.,3. Related Work,[0],[0]
"There has been extensive research on link prediction in relational data, especially in knowledge bases, and we review
here only the prior work that is most relevant to this paper.",3.1. Link Prediction in Relational Data,[0],[0]
"While some approaches explicitly use the graph structure during inference (Lao et al., 2011), we focus here on representation learning and tensor factorization methods, which are the state-of-the-art on the benchmark datasets we use.",3.1. Link Prediction in Relational Data,[0],[0]
"We also restrict the discussion to approaches that only use relational information, even though some approaches have been proposed to leverage additional types (Krompass et al., 2015; Ma et al., 2017) or external word embeddings (Toutanova & Chen, 2015).
",3.1. Link Prediction in Relational Data,[0],[0]
We can divide the first type of approaches into two broad categories.,3.1. Link Prediction in Relational Data,[0],[0]
"First, two-way approaches score a triple (i, j, k) depending only on bigram interaction terms of the form subject-object, subject-predicate, and predicateobject.",3.1. Link Prediction in Relational Data,[0],[0]
"Even though they are tensor approximation algorithms of limited expressivity, two-way models based on translations TransE, or on bag-of-word representations (Joulin et al., 2017) have proved competitive on many benchmarks.",3.1. Link Prediction in Relational Data,[0],[0]
"Yet, methods using three-way multiplicative interactions, as described in the previous section, show the strongest performances (Bordes et al., 2011; GarciaDuran et al., 2016; Nickel et al., 2016b; Trouillon et al., 2016).",3.1. Link Prediction in Relational Data,[0],[0]
"Compared to general-purpose tensor factorization methods such as CP, a common feature of these approaches is to share parameters between objects and subjects modes (Nickel et al., 2011), an idea that has been widely accepted except for the two-way model of Joulin et al. (2017).",3.1. Link Prediction in Relational Data,[0],[0]
"DistMult (Yang et al., 2014) is the extreme case of this parameter sharing, in which the predicted tensor is symmetric in the subject and object modes.",3.1. Link Prediction in Relational Data,[0],[0]
Norm-based regularization has been extensively studied in the context of matrix completion.,3.2. Regularization for Matrix Completion,[0],[0]
"The trace norm (or nuclear norm) has been proposed as a convex relaxation of the rank (Srebro et al., 2005) for matrix completion in the setting of rating prediction, with strong theoretical guarantees (Candès & Recht, 2009).",3.2. Regularization for Matrix Completion,[0],[0]
"While efficient algorithms to solve the convex problems have been proposed (see e.g. Cai et al., 2010; Jaggi et al., 2010), the practice is still to use the matrix equivalent of the nonconvex formulation (2).",3.2. Regularization for Matrix Completion,[0],[0]
"For the trace norm (nuclear 2-norm), in the matrix case, the regularizer simply becomes the squared 2-norm of the factors and lends itself to alternating methods or SGD optimization (Rennie & Srebro, 2005; Koren et al., 2009).",3.2. Regularization for Matrix Completion,[0],[0]
"When the samples are not taken uniformly at random from a matrix, some other norms are preferable to the usual nuclear norm.",3.2. Regularization for Matrix Completion,[0],[0]
"The weighted trace norm reweights elements of the factors based on the marginal rows and columns sampling probabilities, which can improve sample complexity bounds when sampling is non-uniform (Foygel et al., 2011; Negahban & Wainwright, 2012).",3.2. Regularization for Matrix Completion,[0],[0]
"Direct SGD implementations on the nonconvex formulation implicitly take this reweighting rule
into account and were used by the winners of the Netflix challenge (see Srebro & Salakhutdinov, 2010, Section 5).",3.2. Regularization for Matrix Completion,[0],[0]
"There is a large body of literature on low-rank tensor decompositions (see Kolda & Bader, 2009, for a comprehensive review).",3.3. Tensor Completion and Decompositions,[0],[0]
"Closely related to our work is the canonical decomposition of tensor (also called CANDECOMP/PARAFAC or CP) (Hitchcock, 1927), which solves a problem similar to (4) without the regularization (i.e., λ = 0), and usually the square loss.
",3.3. Tensor Completion and Decompositions,[0],[0]
Several norm-based regularizations for tensors have been proposed.,3.3. Tensor Completion and Decompositions,[0],[0]
"Some are based on unfolding a tensor along each of its modes to obtain matricizations, and either regularize by the sum of trace norms of the matricizations (Tomioka et al., 2010) or write the original tensor as a sum of tensors Tk, regularizing their respective kth matricizations with the trace norm (Wimalawarne et al., 2014).",3.3. Tensor Completion and Decompositions,[0],[0]
"However, in the large-scale setting, even rank-1 approximations of matricizations involve too many parameters to be tractable.
",3.3. Tensor Completion and Decompositions,[0],[0]
"Recently, the tensor trace norm (nuclear 2-norm) was proposed as a regularizer for tensor completion Yuan & Zhang (2016), and an algorithm based on the generalized conditional gradient has been developed by Cheng et al. (2016).",3.3. Tensor Completion and Decompositions,[0],[0]
"This algorithm requires, in an inner loop, to compute a (constrained) rank-1 tensor that has largest dot-product with the gradient of the data-fitting term (gradient w.r.t.",3.3. Tensor Completion and Decompositions,[0],[0]
the tensor argument).,3.3. Tensor Completion and Decompositions,[0],[0]
"This algorithm is efficient in our setup only with the square error loss (instead of the multiclass log-loss), because the gradient is then a low-rank + sparse tensor when the argument is low-rank.",3.3. Tensor Completion and Decompositions,[0],[0]
"However, on large-scale knowledge bases, the state of the art is to use a binary log-loss or a multiclass log-loss (Trouillon et al., 2016; Kadlec et al., 2017); in that case, the gradient is not adequately structured, thereby causing the approach of (Cheng et al., 2016) to be too computationally costly.
",3.3. Tensor Completion and Decompositions,[0],[0]
4.,3.3. Tensor Completion and Decompositions,[0],[0]
"Nuclear p-Norm Regularization As discussed in Section 3, norm-based regularizers have proved useful for matrices.",3.3. Tensor Completion and Decompositions,[0],[0]
We aim to reproduce these successes with tensor norms.,3.3. Tensor Completion and Decompositions,[0],[0]
We use the nuclear p-norms defined by Friedland & Lim (2018).,3.3. Tensor Completion and Decompositions,[0],[0]
"As shown in Equation (2), the community has favored so far a regularizer based on the square Frobenius norms of the factors (Yang et al., 2014; Trouillon et al., 2016).",3.3. Tensor Completion and Decompositions,[0],[0]
We first show that the unweighted version of this regularizer is not a tensor norm.,3.3. Tensor Completion and Decompositions,[0],[0]
"Then, we propose4 a variational form of the nuclear 3-norm to replace the usual regularization at no additional computational cost when used with SGD.",3.3. Tensor Completion and Decompositions,[0],[0]
"Finally, we discuss a weighting scheme analogous to the weighted trace-norm proposed in Srebro & Salakhutdinov (2010).",3.3. Tensor Completion and Decompositions,[0],[0]
"To simplify notation, let us introduce the set of CP decompositions of a tensor X of rank at most R:
UR(X) = { (u(d)r )d=1..3
r=1..R ∣∣∣ X = R∑ r=1 u(1)r ⊗ u(2)r ⊗ u(3)r ,
∀r, d, u(d)r ∈ RNd } .
",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"We will study the family of regularizers:
Ωαp (u) = 1
3 R∑ r=1",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"3∑ d=1 ∥u(d)r ∥ α p .
",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"Note that with p = α = 2, we recover the familiar squared Frobenius norm regularizer used in (2).",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"Similar to showing that the squared Frobenius norm is a variational form of the trace norm on matrices (i.e., its minimizers realize the trace norm, infM=UV T 12 (∥U∥ 2",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"F+∥V ∥2F ) = ∥M∥∗), we start with a technical lemma that links our regularizer with a function on the spectrum of our decompositions.",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"Lemma 1.
min u∈UR(X)
1
3 R∑ r=1",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
3∑ d=1 ∥u(d)r ∥ α,4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
p = min u∈UR(X) R∑ r=1,4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"3∏ d=1 ∥u(d)r ∥ α/3 p .
",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"Moreover, the minimizers of the left-hand side satisfy:
∥u(d)r ∥p = 3 √√√√ 3∏ d′=1 ∥u(d ′)",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"r ∥p.
Proof.",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"See Appendix 8.2.
",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"This Lemma motivates the introduction of the set of p-norm normalized tensor decompositions:
UpR(X) =",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"{ (σr, (ũr))r=1..R ∣∣∣ σr",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"= 3∏ d=1 ∥u(d)r ∥p,
ũ(d)r = u (d) r
∥u(d)r ∥p ,∀r, d, u ∈ UR(X)
} .
",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"Lemma 1, shows that Ωαp behaves as an ℓα/D penalty over the CP spectrum for tensors of order D. We recover the nuclear norm for matrices when α = p = 2.
",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"Using Lemma 1, we have :
min u∈UR(X) Ω22(u)",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"≤ η ⇐⇒ min (σ,ũ)∈U2R(X) ∥σ∥2/3≤",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"η3/2
(3)
",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"We show that the sub-level sets of the term on the right are not convex, which implies that Ω22 is not the variational form of a tensor norm, and hence, is not the tensor analog to the matrix trace norm.
",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
Proposition 1.,4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"The function over third order-tensors of RN1×N2×N3 defined as
|||X||| = min { ∥σ∥2/3 ∣∣∣",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"(σ, ũ) ∈ U2R(X), R ∈ N} is not convex.
",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
Proof.,4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"See Appendix 8.2.
",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
Remark 1.,4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"Cheng et al. (2016, Appendix D) already showed that regularizing with the square Frobenius norm of the factors is not related to the trace norm for tensors of order 3 and above, but their observation is that the regularizer is not positively homogeneous, i.e., minu∈αUR(X) Ω 2 2(u) ̸= |α|minu∈UR(X) Ω22(u).",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"Our result in Proposition 1 is stronger in that we show that this regularizer is not a norm even after the rescaling (3) to make it homogeneous.
",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
The nuclear p-norm of X ∈ RN1×N2×N3 for p ∈,4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"[1,+∞], is defined in Friedland & Lim (2018) as
∥X∥∗,p := min { ∥σ∥1 ∣∣∣ (σ, ũ) ∈ UpR(X), R ∈ N} .",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"Given an estimated upper bound on the optimal R, the original problem (2) can then be re-written as a non-convex problem using the equivalence in Lemma 1:
min (u (d) r )d=1..3
r=1..R
∑ (i,j,k)∈S ℓi,j,k ( R∑ r=1 u(1)r ⊗ u(2)r ⊗ u(3)r )
+ λ
3 R∑ r=1 3∑ d=1 ∥u(d)r ∥ 3 p .",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"(4)
",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"This variational form suggests to use p = 3, as a means to make the regularizer separable in each coefficients, given that then ∥u(d)r ∥3p = ∑nd i=1",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"∣∣u(d)r,i |3.",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
4.2.,4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"Weighted Nuclear p-Norm
Similar to the weighted trace-norm for matrices, the weighted nuclear 3-norm can be easily implemented by keeping the regularization terms corresponding to the sampled triplets only, as discussed in Section 3.2.",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"This leads to a formulation of the form
min (u (d) r )d=1..3
r=1..R
∑ (i,j,k)∈S [ ℓi,j,k ( R∑ r=1 u(1)r ⊗u(2)r ⊗u(3)r )
(5)
+ λ
3 R∑ r=1 (∣∣u(1)r,i |3 + ∣∣u(2)r,j |3 + ∣∣u(3)r,k|3)].",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"For an example (i, j, k), only the parameters involved in the computation of X̂i,j,k are regularized.",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"The computational
complexity is thus the same as the currently used weighted Frobenius norm regularizer.",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"With q(1) (resp. q(2), q(3))",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
the marginal probabilities of sampling a subject (resp.,4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"predicate, object), the weighting implied by this regularization scheme is
∥X∥∗,3,w = ∥( 3 √ q(1) ⊗ 3 √ q(2) ⊗ 3",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"√ q(3))⊙X∥∗,3
We justify this weighting only by analogy with the matrix case discussed by (Srebro & Salakhutdinov, 2010): to make the weighted nuclear 3-norm of the all 1 tensor independent of its dimensions for a uniform sampling (since the nuclear 3-norm grows as 3 √ MNP for an (M,N,P ) tensor).
",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"Comparatively, for the weighted version of the nuclear 2- norm analyzed in Yuan & Zhang (2016), the nuclear 2- norm of the all 1 tensor scales like √ NMP .",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"This would imply a formulation of the form
min (u (d) r )d=1..3
r=1..R
∑ (i,j,k)∈S ℓi,j,k ( R∑ r=1 u(1)r ⊗ u(2)r ⊗ u(3)r )
+ λ
3 R∑ r=1",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
3∑ d=1 ∥ √ q(d) ⊙ u(d)r ∥ 3 2 .,4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"(6)
Contrary to formulation (5), the optimization of formulation (6) with a minibatch SGD leads to an update of every coefficients for each mini-batch considered.",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"Depending on the implementation, and size of the factors, there might be a large difference in speed between the updates of the weighted nuclear {2, 3}-norm.",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"In our implementation, this difference for CP is of about 1.5× in favor of the nuclear 3-norm on FB15K.",4.1. From Matrix Trace-Norm to Tensor Nuclear Norms,[0],[0]
"Since our evaluation objective is to rank either the lefthand side or right-hand side of the predicates in our dataset, what we are trying to achieve is to model both predicates and their reciprocal.",5. A New CP Objective,[0],[0]
"This suggests appending to our input the reciprocals of each predicates, thus factorizing [Y ;2 Ỹ ] rather than Y , where [ ;2 ] is the mode-2 concatenation, and Yi,j,k = Ỹk,j,i. After that, we only need to model the object fibers of this new tensor Y .",5. A New CP Objective,[0],[0]
We represent this transformation in Figure 1 (c).,5. A New CP Objective,[0],[0]
This reformulation has an important side-effect: it makes our algorithm invariant to the arbitrary choice of including a predicate or its reciprocal in the dataset.,5. A New CP Objective,[0],[0]
"This property was introduced as ""Semantic Invariance"" in Bailly et al. (2015).",5. A New CP Objective,[0],[0]
Another way of achieving this invariance property would be to find the flipping of predicates that lead to the smallest model.,5. A New CP Objective,[0],[0]
"In the case of a CP decomposition, we would try to find the flipping that leads to lowest tensor rank.",5. A New CP Objective,[0],[0]
"This seems hopeless, given the NP-hardness of computing the tensor rank.
",5. A New CP Objective,[0],[0]
"More precisely, the instantaneous loss of a training triple (i, j, k) becomes :
ℓi,j,k(X) =−Xi,j,k + log (∑
k′
exp(Xi,j,k′) )
(7)
−Xk,j+P,i + log (∑
i′
exp(Xk,j+P,i′) ) .
",5. A New CP Objective,[0],[0]
"At test time we use X̂i,j,: to rank possible right hand sides for query (i, j, ?) and X̂k,j+P,: to rank possible left hand sides for query (?, j, k).
",5. A New CP Objective,[0],[0]
"Using CP to factor the tensor described in (7), we beat the previous state of the art on many benchmarks, as shown in Table 2.",5. A New CP Objective,[0],[0]
"This reformulation seems to help even the ComplEx decomposition, for which parameters are shared between the entity embeddings of the first and third mode.",5. A New CP Objective,[0],[0]
We conducted all experiments on a Quadro GP 100 GPU.,6. Experiments,[0],[0]
The code is available at https://github.com/ facebookresearch/kbc.,6. Experiments,[0],[0]
WN18 and FB15K are popular benchmarks in the Knowledge Base Completion community.,6.1. Datasets and Experimental Setup,[0],[0]
"The former comes from the WordNet database, was introduced in Bordes et al. (2014) and describes relations between words.",6.1. Datasets and Experimental Setup,[0],[0]
"The most frequent types of relations are highly hierarchical (e.g., hypernym, hyponym).",6.1. Datasets and Experimental Setup,[0],[0]
"The latter is a subsampling of Freebase limited to 15k entities, introduced in Bordes et al. (2013).",6.1. Datasets and Experimental Setup,[0],[0]
"It contains predicates with different characteristics (e.g., oneto-one relations such as capital_of to many-to-many such as actor_in_film).
",6.1. Datasets and Experimental Setup,[0],[0]
"Toutanova & Chen (2015) and Dettmers et al. (2017) identified train to test leakage in both these datasets, in the form of test triplets, present in the train set for the reciprocal predicates.",6.1. Datasets and Experimental Setup,[0],[0]
"Thus, both of these authors created two modified datasets: FB15K-237 and WN18RR.",6.1. Datasets and Experimental Setup,[0],[0]
"These datasets are harder to fit, so we expect regularization to have more impact.",6.1. Datasets and Experimental Setup,[0],[0]
"Dettmers et al. (2017) also introduced the dataset YAGO3-10, which is larger in scale and doesn’t suffer from leakage.",6.1. Datasets and Experimental Setup,[0],[0]
"All datasets statistics are shown in Table 1.
",6.1. Datasets and Experimental Setup,[0],[0]
"In all our experiments, we distinguish two settings: Reciprocal, in which we use the loss described in equation (7) and Standard, which uses the loss in equation (1).",6.1. Datasets and Experimental Setup,[0],[0]
"We compare our implementation of CP and ComplEx with the best published results, then the different performances between the two settings, and finally, the contribution of the regularizer in the reciprocal setting.",6.1. Datasets and Experimental Setup,[0],[0]
"In the Reciprocal setting, we compare the weighted nuclear 3-norm (N3) against the regularizer described in (2) (FRO).",6.1. Datasets and Experimental Setup,[0],[0]
"In preliminary experiments, the weighted nuclear 2-norm described in (6) did not seem to perform better than N3 and was slightly slower.",6.1. Datasets and Experimental Setup,[0],[0]
"We used Adagrad (Duchi et al., 2011) as our optimizer, whereas Kadlec et al. (2017) favored Adam (Kingma & Ba, 2014), because preliminary experiments didn’t show improvements.
",6.1. Datasets and Experimental Setup,[0],[0]
"We ran the same grid for all algorithms and regularizers on the FB15K, FB15K-237, WN18, WN18RR datasets, with a rank set to 2000 for ComplEx, and 4000 for CP.",6.1. Datasets and Experimental Setup,[0],[0]
"Our grid consisted of two learning rates: 10−1 and 10−2, two batch-sizes: 25 and 100, and regularization coefficients in [0, 10−3, 5.10−3, 10−2, 5.10−2, 10−1, 5.10−1].",6.1. Datasets and Experimental Setup,[0],[0]
"On YAGO3-10, we limited our models to rank 1000 and used batch-sizes 500 and 3000, the rest of the grid was identical.",6.1. Datasets and Experimental Setup,[0],[0]
We used the train/valid/test splits provided with these datasets and measured the filtered Mean Reciprocal Rank (MRR) and Hits@10 (Bordes et al. (2013)).,6.1. Datasets and Experimental Setup,[0],[0]
We used the filtered MRR on the validation set for early stopping and report the corresponding test metrics.,6.1. Datasets and Experimental Setup,[0],[0]
"In this setting, an epoch for ComplEx with batch-size 100 on FB15K took about 110s and 325s for a batch-size of 25.",6.1. Datasets and Experimental Setup,[0],[0]
"We trained for 100 epochs to ensure convergence, reported performances were reached within the first 25 epochs.
",6.1. Datasets and Experimental Setup,[0],[0]
All our results are reported in Table 2 and will be discussed in the next subsections.,6.1. Datasets and Experimental Setup,[0],[0]
"Besides our implementations of CP and ComplEx, we include the results of ConvE and DistMult in the baselines.",6.1. Datasets and Experimental Setup,[0],[0]
"The former because Dettmers et al. (2017) includes performances on the WN18RR and YAGO3-10 benchmarks, the latter because of the good performances on FB15K of DistMult and the extensive experiments on WN18 and FB15K reported in Kadlec et al. (2017).",6.1. Datasets and Experimental Setup,[0],[0]
"The performances of DistMult on FB15K-237, WN18RR and YAGO3-10 may be slightly underestimated, since our baseline CP results are better.",6.1. Datasets and Experimental Setup,[0],[0]
"To avoid clutter, we did not include in our table of results algorithms that make use of external data such as types (Krompass et al., 2015), external word embeddings (Toutanova & Chen, 2015), or using path queries as regularizers (Guu et al., 2015).",6.1. Datasets and Experimental Setup,[0],[0]
"The published results corresponding to these methods are subsumed in the ""Best Published"" line of Table 2, which is taken, for every single metric and dataset, as the best published result we were able to find.",6.1. Datasets and Experimental Setup,[0],[0]
The performances of our reimplementation of CP and ComplEx appear in the middle rows of Table 2 (Standard setting).,6.2. Reimplementation of the Baselines,[0],[0]
"We only kept the results for the nuclear 3-norm, which didn’t seem to differ from those with the Frobenius norm.",6.2. Reimplementation of the Baselines,[0],[0]
"Our results are slightly better than their published counterparts, going from 0.33 to 0.46 filtered MRR on FB15K for CP and 0.70 to 0.80 for ComplEx.",6.2. Reimplementation of the Baselines,[0],[0]
"This might be explained in part by the fact that in the Standard setting (2) we use a multi-class log-loss, whereas Trouillon et al. (2016) used binomial negative log-likelihood.",6.2. Reimplementation of the Baselines,[0],[0]
"Another reason for this increase can be the large rank of 2000
that we chose, where previously published results used a rank of around 200; the more extensive search for optimization/regularization parameters and the use of nuclear 3-norm instead of the usual regularization are also most likely part of the explanation.",6.2. Reimplementation of the Baselines,[0],[0]
"In this section, we compare the effect of reformulation (7), that is, the middle and bottom rows of Table 2.",6.3. Standard vs Reciprocal,[0],[0]
"The largest differences are obtained for CP, which becomes a state of the art contender going from 0.2 to 0.95 filtered MRR on WN18, or from 0.46 to 0.86 filtered MRR on FB15K.For ComplEx, we notice a weaker, but consistent improvement by using our reformulation, with the biggest improvements observed on FB15K and YAGO3-10.",6.3. Standard vs Reciprocal,[0],[0]
"Following the analysis in Bordes et al. (2013), we show in Table 3 the average filtered MRR as a function of the degree of the predicates.",6.3. Standard vs Reciprocal,[0],[0]
"We compute the average in and out degrees on the training set, and separate the predicates in 4 categories : 1-1, 1-m, m-1 and m-m, with a cut-off at 1.5 on the average degree.",6.3. Standard vs Reciprocal,[0],[0]
We include reciprocal predicates in these statistics.,6.3. Standard vs Reciprocal,[0],[0]
"That is, a predicate with an average in-degree of 1.2 and average out-degree of 3.2 will count as a 1-m when we predict its right-hand side, and as an m-1 when we predict its lefthand side.",6.3. Standard vs Reciprocal,[0],[0]
"Most of our improvements come from the 1-m and m-m categories, both on ComplEx and CP.",6.3. Standard vs Reciprocal,[0],[0]
"We focus now on the effect of our norm-based N3 regularizer, compared to the Frobenius norm regularizer favored by the community.",6.4. Frobenius vs Nuclear 3,[0],[0]
"Comparing the four last rows of Table 2, we notice a small but consistent performance gain across datasets.",6.4. Frobenius vs Nuclear 3,[0],[0]
"The biggest improvements appear on the harder datasets WN18RR, FB15K-237 and YAGO3-10.",6.4. Frobenius vs Nuclear 3,[0],[0]
We checked on WN18RR the significance of that gain with a Signed Rank test on the rank pairs for CP.,6.4. Frobenius vs Nuclear 3,[0],[0]
"During these experiments, we noticed a heavy influence of optimization hyper-parameters on final results.",6.5. Effect of Optimization Parameters,[0],[0]
This influence can account for as much as 0.1 filtered MRR and is illustrated in Figure 2.,6.5. Effect of Optimization Parameters,[0],[0]
The main contribution of this paper is to isolate and systematically explore the effect of different factors for large-scale knowledge base completion.,7. Conclusion and Discussion,[0],[0]
"While the impact of optimization parameters was well known already, neither the effect of the formulation (adding reciprocals doubles the mean reciprocal rank on FB15K for CP) nor the impact of the regularization was properly assessed.",7. Conclusion and Discussion,[0],[0]
The conclusion is that the CP model performs nearly as well as the competitors when each model is evaluated in its optimal configuration.,7. Conclusion and Discussion,[0],[0]
"We believe this observation is important to assess and prioritize directions for further research on the topic.
",7. Conclusion and Discussion,[0],[0]
"In addition, our proposal to use nuclear p-norm as regularizers with p ̸= 2 for tensor factorization in general is of independent interest.
",7. Conclusion and Discussion,[0],[0]
The results we present leave several questions open.,7. Conclusion and Discussion,[0],[0]
"Notably, whereas we give definite evidence that CP itself can perform extremely well on these datasets as long as the problem is formulated correctly, we do not have a strong theoretical justification as to why the differences in performances are so significant.",7. Conclusion and Discussion,[0],[0]
The authors thank Armand Joulin and Maximilian Nickel for valuable discussions.,Acknowledgements,[0],[0]
The problem of Knowledge Base Completion can be framed as a 3rd-order binary tensor completion problem.,abstractText,[0],[0]
"In this light, the Canonical Tensor Decomposition (CP) (Hitchcock, 1927) seems like a natural solution; however, current implementations of CP on standard Knowledge Base Completion benchmarks are lagging behind their competitors.",abstractText,[0],[0]
"In this work, we attempt to understand the limits of CP for knowledge base completion.",abstractText,[0],[0]
"First, we motivate and test a novel regularizer, based on tensor nuclear p-norms.",abstractText,[0],[0]
"Then, we present a reformulation of the problem that makes it invariant to arbitrary choices in the inclusion of predicates or their reciprocals in the dataset.",abstractText,[0],[0]
"These two methods combined allow us to beat the current state of the art on several datasets with a CP decomposition, and obtain even better results using the more advanced ComplEx model.",abstractText,[0],[0]
Canonical Tensor Decomposition for Knowledge Base Completion,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 4383–4394 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
4383",text,[0],[0]
"People actively use dialects to mark their regional origin (Shoemark et al., 2017a,b), making them one of the main drivers of language variation.",1 Introduction,[0],[0]
Accounting for this variation is a challenge for NLP systems (see for example the failed attempts of people with accents trying to use dialogue systems.,1 Introduction,[0],[0]
"Accounting for variation can significantly improve performance in machine translation (Mirkin and Meunier, 2015; Östling and Tiedemann, 2017), geolocation (Rahimi et al.,
2017a,b) and help personalize applications and search.
",1 Introduction,[0],[0]
"However, regional variation involves a complex set of grammatical, lexical, and phonological features, all of them continuously changing.",1 Introduction,[0],[0]
"Consequently, dialects are not static discrete entities, but exist along a continuum in most languages.",1 Introduction,[0],[0]
"Variational linguistics and dialectology typically discretize this continuum by using a set of preselected features (Trudgill, 2000), often including outdated vocabulary.",1 Introduction,[0],[0]
"The resulting dialect areas are highly accurate, but extremely timeconsuming to construct and inflexible (the largest and to date most comprehensive evaluation of German dialects, the Wenker-Atlas (Rabanus et al., 2010) is almost 150 years old and took decades to complete).",1 Introduction,[0],[0]
"Work in dialectometry has shown that computational methods, such as clustering (Nerbonne and Heeringa, 1997; Prokić and Nerbonne, 2008; Szmrecsanyi, 2008, inter alia) and dimensionality reduction (Nerbonne et al., 1999; Shackleton Jr, 2005) can instead be used to identify dimensions of variation in manually constructed discrete feature vectors.",1 Introduction,[0],[0]
"However, the success of such approaches depends on precise prior knowledge of variation features (Lameli, 2013).
",1 Introduction,[0],[0]
"Distributed representations, as unsupervised methods, can complement these methods by capturing similarities between words and documents (here: cities) along various latent dimensions, including syntactic, semantic, and pragmatic aspects.",1 Introduction,[0],[0]
"These representations are therefore more compact, less susceptible to data sparsity than latent variable models, and allow us to represent a large number of possible clusters than featurebased representations (cf.",1 Introduction,[0],[0]
Luong et al. (2013)).,1 Introduction,[0],[0]
"These properties also allow us to measure similarities on a continuous scale, which makes represen-
tation learning especially useful for the study of regional language variation along several linguistic dimensions.
",1 Introduction,[0],[0]
"We use a corpus of 16.8 million anonymous German online posts, cast cities as document labels, and induce document embeddings for these cities via Doc2Vec (Le and Mikolov, 2014).",1 Introduction,[0],[0]
"We first show that the resulting city embeddings capture regional linguistic variation at a more finegrained, continuous regional distinction than previous approaches (Bamman et al., 2014; Östling and Tiedemann, 2017), which operated at a state or language level.1 We also show that the embeddings can serve as input to a geolocation task, outperforming a bag-of-words model, and producing competitive results.
",1 Introduction,[0],[0]
"However, such representations are susceptible to linguistic data bias, ignore geographic factors, and are hard to evaluate with respect to their fit with existing linguistic distinctions.",1 Introduction,[0],[0]
"We address these problems by including geographic information via retrofitting (Faruqui et al., 2015; Hovy and Fornaciari, 2018): we use administrative region boundaries to modify the city embeddings, and evaluate the resulting vectors in a clustering approach to discover larger dialect regions.
",1 Introduction,[0],[0]
"In contrast to most dialectometric approaches (Nerbonne et al., 1999; Prokić and Nerbonne, 2008), and in line with common NLP practice (Doyle, 2014; Grieve, 2016; Huang et al., 2016; Rahimi et al., 2017a), we also evaluate the clustered dialect areas quantitatively.",1 Introduction,[0],[0]
"Rather than testing the geographic extent of individual words against known dialect areas (Doyle, 2014), we compare the match of entire geographic regions to a recent German dialect map (Lameli, 2013).",1 Introduction,[0],[0]
"We use cluster evaluation metrics to measure how well our clusters match the known dialect regions.
",1 Introduction,[0],[0]
"The results show that our method automatically captures existing (manually determined) dialect distinctions well, and even goes beyond them in that it also allows for a more fine-grained qualitative analysis.",1 Introduction,[0],[0]
"Our research shows that representation learning is well suited to the study of language variation, and demonstrates the potential of incorporating non-linguistic information via retrofitting.",1 Introduction,[0],[0]
"For an application of our methodology to a larger Twitter data set over multiple languages, see (Hovy et al.,",1 Introduction,[0],[0]
"In Preparation).
1Han et al. (2014) has used city-level representations, but have not applied them to the identification of dialect areas.
",1 Introduction,[0],[0]
"Contributions In this paper, we make the following contributions to linguistic insights, performance improvements, and algorithmic contributions.",1 Introduction,[0],[0]
"We show:
1.",1 Introduction,[0],[0]
how Doc2Vec can be used to learn distributed representations of cities that capture continuous regional linguistic variation.,1 Introduction,[0],[0]
"The approach is general and can be applied to other languages and data sets;
2. that the city representations capture enough distinction to produce competitive results in geolocation, even this was not the main focus;
3.",1 Introduction,[0],[0]
"that retrofitting can be used to incorporate geographic information into the embeddings, extending the original algorithm’s applications;
4. that the clusterings match with a sociolinguistic dialect map (Lameli, 2013), measuring their homogeneity, completeness, and their harmonic mean (V-measure), and reach a V-measure of 0.77, beating an informed baseline;
We publicly release the data, code, and map files for future research at https://github.com/BocconiNLPLab.",1 Introduction,[0],[0]
"We use data from the social media app Jodel,2 a mobile chat application that lets people anonymously talk to other users within a 10km-radius around them.",2.1 Source,[0],[0]
"The app was first published in 2014, and has seen substantial growth since its beginning.",2.1 Source,[0],[0]
"It has several million users in the Germanspeaking area (GSA), and is expanding to France, Italy, Scandinavia, Spain, and lately the United States.",2.1 Source,[0],[0]
Users can post and answer to posts within the radius around their own current location.,2.1 Source,[0],[0]
All users are anonymous.,2.1 Source,[0],[0]
Answers to an initial post are organized in threads.,2.1 Source,[0],[0]
"The vast majority of posts in Jodel are written in standard German, but since it is conceptually spoken langauge (Koch and Oesterreicher, 1985; Eisenstein, 2013), regional and dialectal forms are common, especially in Switzerland, Austria, and rural areas in Southern Germany.",2.1 Source,[0],[0]
"The data therefore reflects current
2https://jodel.com/
developments in language dynamics to mark regionality (Purschke, 2018).
",2.1 Source,[0],[0]
"We used a publicly available API to collect data between April and June 2017 from 123 initial locations: 79 German cities with a population over 100k people, all 17 major cities in Austria (“Mittel- und Oberzentren”), and 27 cities in Switzerland (the 26 cantonal capitals plus Lugano in the very south of the Italian-speaking area).",2.1 Source,[0],[0]
"Due to the 10km radius, posts from other nearby cities get collected as well.",2.1 Source,[0],[0]
"We include these additional cities if they have more than 200 threads, thereby growing the total number of locations.3 Ultimately, this results in 408 cities (333 in Germany, 27 in Austria, 48 in Switzerland).",2.1 Source,[0],[0]
"The resulting locations are spread relatively evenly across the entire GSA, albeit with some gaps in parts of Germany with low population density.",2.1 Source,[0],[0]
"In total, we collect 2.3 million threads, or 16.8 million posts.
",2.1 Source,[0],[0]
"We treat each thread as a document in our representation learning setup, labeled with the name of the city in which the thread took place.",2.1 Source,[0],[0]
"We preprocess the data to minimize vocabulary size, while maintaining regional discriminative power.",2.2 Preprocessing,[0],[0]
"We lowercase the input and restrict ourselves to content words, based on the part-ofspeech (nouns, verbs, adjectives, adverbs, and proper names), using the spacy4 tagger.
",2.2 Preprocessing,[0],[0]
"Prior studies showed that many regionallydistributed content words are topically driven (Eisenstein et al., 2010; Salehi et al., 2017).",2.2 Preprocessing,[0],[0]
"People talk more about their own region than about others, so the most indicative words include place names (the own city, or specific places within that city), and other local culture terms, such as sports teams.",2.2 Preprocessing,[0],[0]
"We try to minimize the effect of such regional topics, by excluding all named entities, as well as the names of all cities in our list, to instead focus on dialectal lexical variation.
",2.2 Preprocessing,[0],[0]
"We use NLTK5 to remove German stop words, and to lemmatize the words.",2.2 Preprocessing,[0],[0]
"While this step removes the inflectional patterns found in German, which could have regional differences, we focus here on lexical differences, and lemmatization greatly reduces vocabulary size, leading to bet-
3The number of threads differs widely even between cities, ranging from dozens to over 40k in cities like Munich, Vienna, or Berlin.
",2.2 Preprocessing,[0],[0]
"4https://spacy.io/ 5http://www.nltk.org/
ter representations.",2.2 Preprocessing,[0],[0]
"While both POS-tagging and NER can introduce noise, they are more flexible and exhaustive than pre-defined word lists.6",2.2 Preprocessing,[0],[0]
"Finally, we concatenate collocations based on the PMI of the adjacent words in the cleaned corpus.",2.2 Preprocessing,[0],[0]
The average instance length is about 40 words after cleaning.,2.2 Preprocessing,[0],[0]
"The corpus was selected to represent informal, everyday online speech across the German-speaking area in Europe, and to capture regional distinctions.",2.3 Data Statement,[0],[0]
The data was acquired via the publicly available API.,2.3 Data Statement,[0],[0]
"The language is mainly standard German, but with a substantial amount of dialectal entries, mainly from southern German varieties, as well as some French and Italian, which could not be removed without losing dialect.",2.3 Data Statement,[0],[0]
"The platform is anonymous, but mainly used by young people, as indicated by a prevalence of college-related topics.",2.3 Data Statement,[0],[0]
"It contains spontaneous, written, asynchronous interactions in a chat platform organized by threads.",2.3 Data Statement,[0],[0]
Anonymous reference to prior interlocutors is possible.,2.3 Data Statement,[0],[0]
"The app is mainly used to discuss everyday topics, entertainment, flirting, venting, and informal surveys.",2.3 Data Statement,[0],[0]
"To learn both word and city representations, we use the Doc2Vec implementation of para-
6Note that stopwords and place names are more reliably detected in their standard form than in regional variants of abbreviations, meaning the standard forms are more reliably excluded if posts are written in High German, than if posts are written in dialect.",3.1 Representation Learning,[0],[0]
"This may lead to higher coherence for regions with a higher amount of non-standard tokens (as in Switzerland), thereby actually supporting our goal of detecting regional variation.
",3.1 Representation Learning,[0],[0]
"graph2vec (Le and Mikolov, 2014)",3.1 Representation Learning,[0],[0]
"in gensim.7 The model is conceptually similar to word2vec (Mikolov et al., 2013), but also learns document label representations (in our case city names), embedded in the same space as the words.",3.1 Representation Learning,[0],[0]
We use distributed bag-of-words (DBOW) training.,3.1 Representation Learning,[0],[0]
The model parameters are fitted by predicting randomly sampled context words from a city vector.,3.1 Representation Learning,[0],[0]
"The objective is to maximize the log probability of the prediction,
y = arg max W log N∑ i=1 log(p(wi|k))
where k is a city, and W = wi...N a sequence of N randomly sampled words from the thread (see Figure 1 for a schematic representation).
",3.1 Representation Learning,[0],[0]
"During training, semantically similar words end up closer together in vector space, as do words “similar” to a particular city, and cities that are linguistically similar to each other.
",3.1 Representation Learning,[0],[0]
"Due to the nature of our task, we unfortunately do not have gold data (i.e., verified cluster labels) to tune parameters.",3.1 Representation Learning,[0],[0]
"We therefore follow the settings described in (Lau and Baldwin, 2016) for the parameters, and set the vector dimensions to 300, window size to 15, minimum frequency to 10, negative samples to 5, downsampling to 0.00001, and run for 10 iterations.",3.1 Representation Learning,[0],[0]
"In order to examine whether the city embeddings capture the continuous nature of dialects, we visualize them.",3.2 Visualization,[0],[0]
"If our assumption holds, we expect to see gradual continuous change between cities and regions.
",3.2 Visualization,[0],[0]
"We use non-negative matrix factorization (NMF) on the 300-dimensional city representation matrix to find the first three principal components, normalize them each to values 0.0–1.0 and interpret those as RGB values.8 I.e., we assume the first principal component signals the amount of red, the second component the amount of green, and the third component the amount of blue.",3.2 Visualization,[0],[0]
This triple can be translated into a single color value.,3.2 Visualization,[0],[0]
"E.g., 0.5 red, 0.5 green, and 0.5 blue translates
7https://radimrehurek.com/gensim/ models/doc2vec.html
8Note that instead learning 3-dimensional embeddings would not amount to the same, as those are likely not equivalent of the three first principal components, and thus not as useful.",3.2 Visualization,[0],[0]
"300 dimensions capture other degrees of variation, increasing the chance to capture meaningful latent dimensions.
into medium gray.",3.2 Visualization,[0],[0]
This transformation translates city representations into color values that preserve linguistic similarities.,3.2 Visualization,[0],[0]
"Similar hues correspond to similar representations, and therefore, by extension, linguistic similarity.
",3.2 Visualization,[0],[0]
NMF tries to find a decomposition of a given i-by-k matrix W into d components by a i-by-d row-representation V and a d-by-k column representationH .,3.2 Visualization,[0],[0]
"In our case, d = 3.",3.2 Visualization,[0],[0]
"Since we are only interested in a reduced representation of the cities, V , we discard H .
",3.2 Visualization,[0],[0]
"The result is indeed a continuous color gradient over the cities over 200 threads, see Figure 2.",3.2 Visualization,[0],[0]
"The circle size for every city indicates the relative number of threads per location.
",3.2 Visualization,[0],[0]
"In order to get reliable statistics, we restrict ourselves to cities with more than 200 observed conversations (about 2.1M conversations: 1.82M in Germany, 173k in Austria, and 146k in Switzerland).",3.2 Visualization,[0],[0]
"Including cities with fewer conversations adds more data points, but induces noise, as many of those representations are based on too little data, resulting in inaccurate vectors.
",3.2 Visualization,[0],[0]
"Even without in-depth linguistic analysis, we can already see differences between Switzerland (green color tones) and the rest of the GSA.",3.2 Visualization,[0],[0]
"Within
Switzerland, we see a distinction between the German (lighter green) and the French-speaking area around Lausanne and Geneva (darker tones).",3.2 Visualization,[0],[0]
"On the other hand, we find a continuous transition from red over purple to bluish colors in Germany and Austria.",3.2 Visualization,[0],[0]
These gradients largely correspond to the dimensions North→South(East): red→blue,3.2 Visualization,[0],[0]
and West→East: intense tones →pale tones.,3.2 Visualization,[0],[0]
"These dimensions mirror the well-known strong linguistic connection between the southeast of Germany and Austria, and between most cities in the north of Germany.",3.2 Visualization,[0],[0]
"The visualization in the last section already suggests that we capture the German dialect continuum, and the existence of larger dialect areas.",3.3 Clustering,[0],[0]
"However, in order to evaluate against existing dialect maps, we need to discretize the continuous representation.",3.3 Clustering,[0],[0]
"We use hierarchical agglomerative clustering (Ward Jr, 1963) with Ward linkage, Euclidean affinity, and structure to discover dialect areas.",3.3 Clustering,[0],[0]
"We compare the agglomerative clustering results to a k-means approach.
",3.3 Clustering,[0],[0]
"Agglomerative clustering starts with each city in its own cluster, and recursively merges pairs into larger clusters, until we have reached the required number.",3.3 Clustering,[0],[0]
"Pairs are chosen to minimize the increase in linkage distance (for Ward linkage, this measure is the new cluster’s variance).",3.3 Clustering,[0],[0]
"We use cities with 50–199 threads (66 cities) to tune the clustering parameters (linkage function and affinity), and report results obtained on cities with more than 200 threads.
",3.3 Clustering,[0],[0]
"Since the city representations are indirectly based on the words used in the respective cities, the clustering essentially captures regional similarity in vocabulary.",3.3 Clustering,[0],[0]
"If the clusters we find in our data match existing dialect distinctions, this provides a compelling argument for the applicability of our methodology.",3.3 Clustering,[0],[0]
"While we capture regional variation by means of linguistic similarities here, it does include a geographic component as well.",3.4 Including geographic knowledge,[0],[0]
"The embeddings we learn do not include this component, though.",3.4 Including geographic knowledge,[0],[0]
This can produce undesirable clustering results.,3.4 Including geographic knowledge,[0],[0]
"Large cities, due to their “melting-pot” function, often use similar language, so their representations are close in embedding space.",3.4 Including geographic knowledge,[0],[0]
"This is an example of Galton’s problem (Naroll, 1961): Munich and Berlin are not linguistically similar because they belong to the same dialect, but due to some outside factor (in this case, shared vocabulary through migration).
",3.4 Including geographic knowledge,[0],[0]
"To address geography, we experiment with two measures: clustering with structure, and retrofitting (Faruqui et al., 2015; Hovy and Fornaciari, 2018).
",3.4 Including geographic knowledge,[0],[0]
"Structure To introduce geographic structure into clustering, we use a connectivity matrix over the inverse distance between cities (i.e., geographically close cities have a higher number), which is used as weight during the merging.",3.4 Including geographic knowledge,[0],[0]
"This weight makes close geographic neighbors more likely to be merged before distant cities are.
",3.4 Including geographic knowledge,[0],[0]
"Note, though, that this geographic component
does not predetermine the clustering outcome: geographically close cities that are linguistically different still end up in separate clusters, as we will see.",3.4 Including geographic knowledge,[0],[0]
"The Spearman ρ correlation between the geographic distance and the cosine-similarity of cities is positive, but does not fully explain the similarities (Austria 0.40, Germany 0.42, Switzerland 0.72).",3.4 Including geographic knowledge,[0],[0]
The stronger correlation for Switzerland suggests a localized effect of regional varieties.,3.4 Including geographic knowledge,[0],[0]
"Geographic structure in clustering does, however, provide speedups, regional stability, and more stable clustering solutions than unstructured clustering.",3.4 Including geographic knowledge,[0],[0]
"We will see this in comparison to k-means.
",3.4 Including geographic knowledge,[0],[0]
Retrofitting Faruqui et al. (2015) introduced retrofitting of vectors based on external knowledge.,3.4 Including geographic knowledge,[0],[0]
We take the idea proposed for word vectors and semantic resources and extend it following Hovy and Fornaciari (2018) to apply it to city representations and membership in geographic regions.,3.4 Including geographic knowledge,[0],[0]
"We construct a set Ω with tuples of cities (ci, cj) such that there exists a region R",3.4 Including geographic knowledge,[0],[0]
where ci ∈ R and cj ∈,3.4 Including geographic knowledge,[0],[0]
"R. We use the NUTS2 regions (Nomenclature of Territorial Units for Statistics, a EuroStats geocoding standard) to determine R. In Germany, NUTS2 has 39 regions, corresponding to government regions.
",3.4 Including geographic knowledge,[0],[0]
"To include the geographic knowledge, we retrofit the existing city embeddings C. The goal is to make the representations of cities that are in the same region more similar to each other than to cities in other regions, resulting in a retrofit embeddings matrix Ĉ.",3.4 Including geographic knowledge,[0],[0]
"For a retrofit city vector ĉi, the update equation is
ĉi = αci + β
∑ j:(i,j)∈Ω ĉj
N
where ĉi is the original city vector, and α and β are tradeoff parameters to control the influence of the geographic vs. the linguistic information.",3.4 Including geographic knowledge,[0],[0]
See Faruqui et al. (2015) and Hovy and Fornaciari (2018) for more details.,3.4 Including geographic knowledge,[0],[0]
"In order to evaluate our methodology, we measure both its ability to match German dialect distinctions, and the performance of the learned embeddings in a downstream geolocation task.
",4 Evaluation,[0],[0]
Figure 3 provides examples of different clustering solutions after retrofitting.,4 Evaluation,[0],[0]
Note that colors are assigned randomly and do not correspond to the linguistic similarity from Figure 2.,4 Evaluation,[0],[0]
"Switzerland immediately forms a separate cluster (the
2-cluster solution separates Switzerland vs. everything else), and further clusters first separate out more southern German varieties before distinguishing the northern varieties.",4 Evaluation,[0],[0]
"This is in line with sociolinguistic findings (Plewnia and Rothe, 2012) about ubiquity of dialect use (more common in the south, therefore more varied regions, reflected in our clustering).",4 Evaluation,[0],[0]
"Due to space constraints, we have to omit further clustering stages, but find linguistically plausible solutions beyond the ones shown here.",4 Evaluation,[0],[0]
"For an in-depth qualitative analysis of the different clustering solutions and the sociodemographic and linguistic factors, see Purschke and Hovy (In Preparation).
",4 Evaluation,[0],[0]
Dialect match We use the map of German dialects and their regions by Lameli (2013) (see Figure 4) and its 14 large-scale areas9 as gold standard to measure how well the various clusteringsolutions correspond to the dialect boundaries.,4 Evaluation,[0],[0]
"This map is based on empirical quantitative analysis of German dialects, albeit based on data from the 19th century, and therefore naturally on different domains and media than our study.
",4 Evaluation,[0],[0]
Note that we can only assess the cities within modern-day Germany (clusters formed in Austria or Switzerland are not covered).,4 Evaluation,[0],[0]
"We therefore rerun the clusterings on the subset of German cities, so results differ slightly from the clusters induced
9Some areas partially overlap with each other.",4 Evaluation,[0],[0]
on the entire GSA.,9 0.70 0.65 0.76 0.70 0.68 0.72 0.70 0.67 0.73 0.73 0.70 0.75,[0],[0]
"We report homogeneity (whether a cluster contains only data points from a single region) and completeness (how many data points of a NUTS region are in the same cluster), as well as their harmonic mean, the V-score.",9 0.70 0.65 0.76 0.70 0.68 0.72 0.70 0.67 0.73 0.73 0.70 0.75,[0],[0]
This corresponds to precision/recall/F1 scores used in classification.,9 0.70 0.65 0.76 0.70 0.68 0.72 0.70 0.67 0.73 0.73 0.70 0.75,[0],[0]
"Note that we will not be able to faithfully reconstruct Lameli’s distinctions, since Lameli’s map contains overlapping regions, whose data points therefore already violate perfect homogeneity.
",9 0.70 0.65 0.76 0.70 0.68 0.72 0.70 0.67 0.73 0.73 0.70 0.75,[0],[0]
"The outline of dialect regions in Lameli’s map is based on the NUTS2 regions, so we compare all clustering solutions to an informed baseline that assigns each city the NUTS2 region it is located in.",9 0.70 0.65 0.76 0.70 0.68 0.72 0.70 0.67 0.73 0.73 0.70 0.75,[0],[0]
"Except for regions in dialect overlaps, each NUTS region is completely contained in one dialect region, so the baseline can achieve almost perfect homogeneity.
",9 0.70 0.65 0.76 0.70 0.68 0.72 0.70 0.67 0.73 0.73 0.70 0.75,[0],[0]
"Downstream task geolocation For the geolocation task, we randomly select 100 cities with at least 200 threads from each country (7 in Austria, 82 in Germany, 11 in Switzerland).",9 0.70 0.65 0.76 0.70 0.68 0.72 0.70 0.67 0.73 0.73 0.70 0.75,[0],[0]
"We
then collect threads with at least 100 words from these cities for each country (11,240 threads from Austria, 137,081 from Germany, and 18,590 from Switzerland).",9 0.70 0.65 0.76 0.70 0.68 0.72 0.70 0.67 0.73 0.73 0.70 0.75,[0],[0]
"Each thread is a training instance, i.e., we have 166,911 instances.",9 0.70 0.65 0.76 0.70 0.68 0.72 0.70 0.67 0.73 0.73 0.70 0.75,[0],[0]
"We use the Doc2Vec model from before to induce a document representation for each instance and use the vector as input to a logistic regression model that predicts the city name.
",9 0.70 0.65 0.76 0.70 0.68 0.72 0.70 0.67 0.73 0.73 0.70 0.75,[0],[0]
"For testing, we sample 5,000 threads from the same cities (maintaining the same proportional distribution and word count constraint), but from a separate data set, collected two months after the original sample.",9 0.70 0.65 0.76 0.70 0.68 0.72 0.70 0.67 0.73 0.73 0.70 0.75,[0],[0]
"We again use the Doc2Vec model to induce representations, and evaluate the classifier on this data.
",9 0.70 0.65 0.76 0.70 0.68 0.72 0.70 0.67 0.73 0.73 0.70 0.75,[0],[0]
"We measure accuracy, accuracy at 161km (100 miles), and the median distance between prediction and target.",9 0.70 0.65 0.76 0.70 0.68 0.72 0.70 0.67 0.73 0.73 0.70 0.75,[0],[0]
We compare the model with Doc2Vec representations to a bag-of-words (BOW) model with the same parameters.,9 0.70 0.65 0.76 0.70 0.68 0.72 0.70 0.67 0.73 0.73 0.70 0.75,[0],[0]
"Since the representation here is based on words, we can not apply retrofitting.",9 0.70 0.65 0.76 0.70 0.68 0.72 0.70 0.67 0.73 0.73 0.70 0.75,[0],[0]
"As baseline, we report the
most-frequent city prediction.",9 0.70 0.65 0.76 0.70 0.68 0.72 0.70 0.67 0.73 0.73 0.70 0.75,[0],[0]
Dialect match Table 1 shows the results of clustering solutions up to 20 clusters for both retrofit and original embeddings.,5 Results,[0],[0]
"Irrespective of the clustering approach, retrofit representations perform markedly better.
",5 Results,[0],[0]
"Homogeneity increases substantially the more clusters we induce (in the limit, each data point becomes a single cluster, resulting in perfect homogeneity), whereas completeness decreases slightly with more clusters (they increase the likelihood that a region is split up into several clusters).",5 Results,[0],[0]
"We achieve the best V-score, 0.77, with 16 clusters.
",5 Results,[0],[0]
"Averaged k-means (over 5 runs) is much less consistent, due to random initialization, but presumably also because it cannot incorporate the geographic information.",5 Results,[0],[0]
"For few clusters, its performance is better than agglomerative clustering, but as the number of clusters increases (and the geographic distribution of the cities becomes more intricate), k-means stops improving.
",5 Results,[0],[0]
"The baseline achieves almost perfect homogeneity, as expected (the only outliers are NUTS regions in overlap areas).",5 Results,[0],[0]
"Completeness is lower than almost all clustering solutions, though.",5 Results,[0],[0]
"The V-score, 0.74, is therefore lower than the best clustering solution.
",5 Results,[0],[0]
"Both the cluster evaluation metrics and the visual correspondence suggest that our method captures regional variation at a lexical level well.
",5 Results,[0],[0]
Downstream Evaluation: Geolocation Table 2 shows the results of the geolocation downstream task.,5 Results,[0],[0]
"Despite the fact that the representation learning setup was not designed for this task and excluded all the most informative words for it (Salehi et al., 2017), the induced embeddings capture enough pertinent regional differences to achieve reasonable performance (albeit slightly below state of the art, which typically has a median
distance around 100km, and an accuracy@161 of 0.54, see cf.",5 Results,[0],[0]
Rahimi et al. (2017b)),5 Results,[0],[0]
and decidedly outperform the BOW model and most-frequentcity baseline on all measures.,5 Results,[0],[0]
"Because both words and cities are represented in the same embeddings space (at least before retrofitting), we can compare the vectors of cities to each other (asking: which cities are linguistically most similar to each other, which is what we have done above) and words to cities (asking: which words are most similar to/indicative of a city).",6 Analysis,[0],[0]
"The latter allows us to get a qualitative sense of how descriptive the words are for each city.
",6 Analysis,[0],[0]
"Figure 5 shows an example of word and city similarity for the city representation of Vienna.
",6 Analysis,[0],[0]
We can also use the cluster centroid of several city vectors to represent entire regions.,6 Analysis,[0],[0]
"The new vector no longer represents a real location, but is akin to the theoretic linguistic center of a dialect region.",6 Analysis,[0],[0]
We can then find the most similar words to this centroid.,6 Analysis,[0],[0]
"For the solution with 3 clusters (cf. Figure 3), we get the solutions in Table 3.",6 Analysis,[0],[0]
"As expected, the regional prototypes do not overlap, but feature dialectal expressions in the south, and general standard German expressions in the north.
",6 Analysis,[0],[0]
"Again, for an in-depth qualitative analysis and discussion of the socio-linguistic correlations, see Purschke and Hovy (In Preparation).",6 Analysis,[0],[0]
"Dialectometric studies, exploring quantitative statistical models for regional variation, range from
work on dialect data in Dutch (Nerbonne and Heeringa, 1997; Prokić and Nerbonne, 2008; Wieling et al., 2011, inter alia) and British English (Szmrecsanyi, 2008), to Twitter-based approaches for American dialect distinctions (Grieve et al., 2011; Huang et al., 2016) and the regional differentiation of African American Vernacular English (Jones, 2015).",7 Related Work,[0],[0]
"While these papers rely on existing dialect maps for comparison, they rarely quantitatively evaluate against them, as we do.
",7 Related Work,[0],[0]
"Recently, NLP has seen increased interest in computational sociolinguistics (Nguyen et al., 2016).",7 Related Work,[0],[0]
"These works examine the correlation of socio-economic attributes with linguistic features, including regional distribution of lexical and phonological differences (Eisenstein et al., 2010; Doyle, 2014; Bamman et al., 2014), syntactic variation (Johannsen et al., 2015), diachronic variation (Danescu-Niculescu-Mizil et al., 2013; Kulkarni et al., 2015; Hamilton et al., 2016), and correlation with socio-demographic attributes (Eisenstein et al., 2011; Eisenstein, 2015).",7 Related Work,[0],[0]
"Other have further explored regional variation on social media, and showed the prevalence of regional lexical variants (Hovy et al., 2015; Hovy and Johannsen, 2016; Donoso and Sánchez, 2017).",7 Related Work,[0],[0]
"Several works include quantitative comparisons to measure the empirical fit of their findings (Peirsman et al., 2010; Han et al., 2014; Huang et al., 2016; Grieve, 2016; Kulkarni et al., 2016), albeit not on entire existing dialect maps.
",7 Related Work,[0],[0]
"The use of representation learning is new and relatively limited, especially given its prevalence in other areas of NLP.",7 Related Work,[0],[0]
"Bamman et al. (2014) have shown how regional meaning differences can be learned from Twitter via distributed word representations between US states, but not for individual cities.",7 Related Work,[0],[0]
"More recently, Kulkarni et al. (2016);
Rahimi et al. (2017a) and Rahimi et al. (2017b) have shown how neural models can exploit regional lexical variation for geolocation, while also enabling dialectological insights, whereas our goals are exactly reversed.",7 Related Work,[0],[0]
Östling and Tiedemann (2017) have shown how distributed representations of entire national languages capture typological similarities that improve translation quality.,7 Related Work,[0],[0]
"Most of these papers focus on downstream performance that accounts for regional variation, rather than on explicitly modeling variation.",7 Related Work,[0],[0]
"We include a downstream performance, but also evaluate the cluster composition quantitatively.",7 Related Work,[0],[0]
"We use representation learning, structured clustering, and geographic retrofitting on city embeddings to study regional linguistic variation in German.",8 Conclusion,[0],[0]
"Our approach captures gradual linguistic differences, and matches an existing German dialect map, achieving a V-score of 0.77.",8 Conclusion,[0],[0]
"The learned city embeddings also capture enough regional distinction serve as input to a downstream geolocation task, outperforming a BOW baseline and producing competitive results.",8 Conclusion,[0],[0]
"Our findings indicate that city embeddings capture regional linguistic variation, which can be further enriched with geographic information via retrofitting.",8 Conclusion,[0],[0]
They also suggest that traditional ideas of regionality persist online.,8 Conclusion,[0],[0]
"Our methodology is general enough to be applied to other languages that lack dialect maps (e.g., Switzerland), and to other tasks studying regional variation.",8 Conclusion,[0],[0]
We publicly release our data and code.,8 Conclusion,[0],[0]
"We would like to thank the anonymous reviewers of this paper and Barbara Plank, who helped to strengthen and clarify our findings.",Acknowledgements,[0],[0]
"Dialects are one of the main drivers of language variation, a major challenge for natural language processing tools.",abstractText,[0],[0]
"In most languages, dialects exist along a continuum, and are commonly discretized by combining the extent of several preselected linguistic variables.",abstractText,[0],[0]
"However, the selection of these variables is theorydriven and itself insensitive to change.",abstractText,[0],[0]
We use Doc2Vec on a corpus of 16.8M anonymous online posts in the German-speaking area to learn continuous document representations of cities.,abstractText,[0],[0]
"These representations capture continuous regional linguistic distinctions, and can serve as input to downstream NLP tasks sensitive to regional variation.",abstractText,[0],[0]
"By incorporating geographic information via retrofitting and agglomerative clustering with structure, we recover dialect areas at various levels of granularity.",abstractText,[0],[0]
"Evaluating these clusters against an existing dialect map, we achieve a match of up to 0.77 V-score (harmonic mean of cluster completeness and homogeneity).",abstractText,[0],[0]
Our results show that representation learning with retrofitting offers a robust general method to automatically expose dialectal differences and regional variation at a finer granularity than was previously possible.,abstractText,[0],[0]
Capturing Regional Variation with Distributed Place Representations and Geographic Retrofitting,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3687–3697 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
3687",text,[0],[0]
"Emotions reflect different users’ perspectives towards actions and events, therefore they are innately expressed in dynamic linguistic forms.",1 Introduction,[0],[0]
Capturing these linguistic variations is challenging because it involves knowledge of linguistic phenomena such as slang and coded words.,1 Introduction,[0],[0]
"Previous methods model these linguistic behaviours through rule-based (Volkova and Bachrach, 2016) and statistics-based approaches (Becker et al., 2017).",1 Introduction,[0],[0]
"These methods construct features that rely on hand-crafted resources; thus, they cannot properly capture the evolving linguistic variability found in large-scale opinionated content.
",1 Introduction,[0],[0]
Consider the social posts “Thanks God for everything” and “Tnx mom for waaaaking me two hours early.,1 Introduction,[0],[0]
"Cant get asleep now”, a lexicon-based model may not properly represent the emotion-relevant phrases: “waaaaking me”, “Thanks God”, and “Tnx mom”.",1 Introduction,[0],[0]
"First, the word
∗*",1 Introduction,[0],[0]
"Corresponding author
“waaaaking” doesn’t exist in the English vocabulary, hence its referent may vary from its standard form, “waking”.",1 Introduction,[0],[0]
"Secondly, knowledge of the semantic similarity between the words “Thanks” and “Tnx” is needed to establish any relationship between the last two phrases.",1 Introduction,[0],[0]
"Even if such relationship can be established through knowledgebased techniques, it’s difficult to reliably determine the association of these phrases to a group of emotions.",1 Introduction,[0],[0]
"This is because traditional methods analyze data at the sentence level, which may be less effective as compared to methods that model the corpus as a complex network (Santos et al., 2017).
",1 Introduction,[0],[0]
"We represent an emotion corpus as a graph, which may suffer less from the problems mentioned above.",1 Introduction,[0],[0]
This method efficiently captures the global mutual use of linguistic variations found in textual information.,1 Introduction,[0],[0]
"This is particularly important for linguistic behaviour that is socially and culturally influenced, as is common in opinionated content.",1 Introduction,[0],[0]
"Other advantages of the graph approach are that minimum domain knowledge and manual effort are required to capture important contextual and latent information, which are useful to disambiguate meaning in emotional expressions.
",1 Introduction,[0],[0]
"As an overview, we first collect an emotion dataset through noisy labels, annotated via distant supervision as in (Go et al., 2009).",1 Introduction,[0],[0]
"The graphbased mechanism helps to construct contextualized, pattern-based emotion features, which are further enriched with word embeddings in order to preserve semantic relationship between patterns.",1 Introduction,[0],[0]
"To evaluate the quality of patterns, emotion detection models are trained using various online classifiers and deep learning models.",1 Introduction,[0],[0]
"Our main contributions are as follows: 1) A graph-based algorithm for automatic emotion-relevant feature extraction, 2) a set of emotion-rich feature representations enhanced through word embeddings, 3) and a comprehensive performance analysis of various con-
ventional learning models and deep learning models used for text-based emotion recognition.
",1 Introduction,[0],[0]
"The rest of the paper is organized as follows: Section 2 discusses the relevant literature and different aspects of emotion recognition research addressed in this work; then, Section 3 provides details of the proposed methodology for extracting contextualized emotion-relevant representations; next, Section 4 lists the constructed emotion recognition models and comparison models; later, Section 5 discusses the data collection and experimental results; and finally, Section 6 further explains key insights observed from the results.",1 Introduction,[0],[0]
"Emotion Lexica: Several works use hand-crafted features and statistics-based approaches to train emotion recognition models (Blitzer et al., 2007; Wang et al., 2012; Roberts et al., 2012; Qadir and Riloff, 2013; Volkova et al., 2013; Becker et al., 2017; Saravia et al., 2016a).",2 Related Work,[0],[0]
"Some of these studies rely on affect lexicons, such as LIWC (Pennebaker et al., 2007) and WordNet Affect (Strapparava et al., 2004), to extract emotion features from a text-based corpus.",2 Related Work,[0],[0]
"A recent study trained emotion detection systems built on emoticons and hashtag features (Volkova and Bachrach, 2016).",2 Related Work,[0],[0]
Handcrafted features are useful for emotion recognition but are usually constrained by manually created resources.,2 Related Work,[0],[0]
"Our graph-based features are obtained in an semi-supervised manner, requiring minimum domain expertise and no dependency of linguistic resources that quickly become outdated.",2 Related Work,[0],[0]
Emotion Corpora:,2 Related Work,[0],[0]
"There are several affective datasets such as SemEval-2017 Task 4 (Rosenthal et al., 2017) and Olympic games dataset (Sintsova et al., 2013).",2 Related Work,[0],[0]
"However, these datasets are limited by quantity.",2 Related Work,[0],[0]
"We bootstrap a set of noisy labels to obtain large-scale emotion tweets, and then perform annotation via distant supervision as in (Go et al., 2009; González-Ibánez et al., 2011; Wang et al., 2012; Mohammad and Kiritchenko, 2015; Abdul-Mageed and Ungar, 2017).",2 Related Work,[0],[0]
"In emotion recognition studies, Plutchik’s wheel of emotions (Plutchik, 2001) or Ekman’s six basic emotions (Ekman, 1992), are commonly adopted to define emotion categories (Mohammad, 2012; Suttles and Ide, 2013).",2 Related Work,[0],[0]
"Similar to previous works, we rely on hashtags to define our emotion categories.",2 Related Work,[0],[0]
Feature Representations:,2 Related Work,[0],[0]
"Recent emotion recognition systems employ representation learning for
automatic feature extraction (Poria et al., 2016; Savigny and Purwarianti, 2017; Abdul-Mageed and Ungar, 2017).",2 Related Work,[0],[0]
"In general, a combination of word embeddings (Mikolov et al., 2013) and a convolutional neural network (CNN) performs well for sentence classification tasks (Kim, 2014; Zhang et al., 2015).",2 Related Work,[0],[0]
"These models learn features which tend to have high coverage, high adaptability, require minimum supervision, and capture contextual information to some extent.",2 Related Work,[0],[0]
We aim to leverage them and combine them with the proposed affect representations.,2 Related Work,[0],[0]
Our graph-based feature extraction algorithm focuses on the underlying interactions between important linguistic components.,2 Related Work,[0],[0]
Graph analysis measurements then help to output the building blocks for constructing pattern-based features.,2 Related Work,[0],[0]
"Hence, the patterns can be constructed to capture important contextual and latent emotion-relevant information.",2 Related Work,[0],[0]
"In this section, we introduce a graph-based algorithm which helps to output the building blocks used to bootstrap a set of emotion-rich representations.",3 Contextualized Affect Representations,[0],[0]
"The structural descriptions offered by the graph are particularly efficient at automatically surfacing important information (i.e., contextual and latent information) from a large-scale emotion corpus.",3 Contextualized Affect Representations,[0],[0]
"Two different measurements are used to surface two families of words, which are in turn used to construct contextualized, pattern-based affect representations.",3 Contextualized Affect Representations,[0],[0]
The patterns are further enriched using word embeddings so as to preserve semantic relationship between patterns.,3 Contextualized Affect Representations,[0],[0]
"After the patterns are constructed, the goal is to assign a weight to each pattern, referred to as a pattern score, which denotes how important a pattern p is to an emotion e.",3 Contextualized Affect Representations,[0],[0]
"In the context of emotion classification, patterns and their weights play the role of features.",3 Contextualized Affect Representations,[0],[0]
"The graph-based feature extraction algorithm is summarized in the following steps: Step 1 (Normalization): First, we collected two separate datasets using the Twitter API: subjective tweets S (obtained through hashtags as weak labels) and objective tweets O (obtained from Twitter feeds of news accounts).1 Both datasets are tokenized by white-spaces and then preprocessed by applying lower case and replacing user mentions and URLs with a<usermention> and<url>
1Each dataset contains 2+ million tweets.",3 Contextualized Affect Representations,[0],[0]
"S was collected using 339 hashtags, similar to the process in Section 5.1.
placeholder, respectively.",3 Contextualized Affect Representations,[0],[0]
"Hashtags are used as ground-truth in this work, so to avoid any bias we replace them with a <hashtag> placeholder.",3 Contextualized Affect Representations,[0],[0]
"Step 2 (Graph Construction): Given the normalized objective tweets O and subjective tweets S, two graphs are constructed: objective graph Go(Vo;Ao) and subjective graph Gs(Vs;As), respectively.",3 Contextualized Affect Representations,[0],[0]
Vertices V is a set of nodes which represent the tokens extracted from the corpus.,3 Contextualized Affect Representations,[0],[0]
"Edges, denoted as A, represent the relationship of words extracted using a window approach.",3 Contextualized Affect Representations,[0],[0]
These steps help to preserve the syntactic structure of the data.,3 Contextualized Affect Representations,[0],[0]
Given a post “<usermention> last night’s concert was just awesome !!!!!,3 Contextualized Affect Representations,[0],[0]
"<hashtag>”, the resulting arcs are: “<usermention>→ last”, “last→ night”, ... , “!!!!!",3 Contextualized Affect Representations,[0],[0]
→ <hashtag>”.,3 Contextualized Affect Representations,[0],[0]
Step 3 (Graph Aggregation):,3 Contextualized Affect Representations,[0],[0]
In this step we obtain a set of arcs that represent syntactic structures more common in subjective content.,3 Contextualized Affect Representations,[0],[0]
"By adjusting graph Gs with Go, we obtain a graph Ge, referred to as the emotion graph, which preserves emotionrelevant tokens and is obtained in two steps:
(1).",3 Contextualized Affect Representations,[0],[0]
For an arc ai ∈,3 Contextualized Affect Representations,[0],[0]
"A, its normalized weight can be computed as shown in Equation 1.
w(ai) = freq(ai)
maxj∈A freq(aj) (1)
where freq(ai) is the frequency of arc ai.",3 Contextualized Affect Representations,[0],[0]
(2).,3 Contextualized Affect Representations,[0],[0]
"Subsequently, new weights for arcs ai ∈ Ge are assigned based on a pairwise adjustment as
shown in Equation 2.
w(ai) =",3 Contextualized Affect Representations,[0],[0]
"{ w(asi)− w(aoj ), if aoj = asi ∈ Go w(asi), otherwise
(2) The resulting weights belonging to graph Ge were adjusted so that the most frequently occurring arcs in objective set Go are weakened in Ge.",3 Contextualized Affect Representations,[0],[0]
"As a result, arcs in Ge that have higher weights represent tokens that are more common in subjective content.",3 Contextualized Affect Representations,[0],[0]
"Furthermore, arcs ai ∈",3 Contextualized Affect Representations,[0],[0]
Ae are pruned based on a threshold φw2.,3 Contextualized Affect Representations,[0],[0]
Step 4 (Token Categorization): Two different graph measurements are used to extract two family of words from Ge.,3 Contextualized Affect Representations,[0],[0]
These will function as the building blocks to build contextualized patterns.,3 Contextualized Affect Representations,[0],[0]
We formalize this step as follows:,3 Contextualized Affect Representations,[0],[0]
"Given an adjacency matrix M, an entry Mi,j is computed as:
Mi,j = { 1 if node i and j are linked in Ge 0",3 Contextualized Affect Representations,[0],[0]
"otherwise (3) Then, the eigenvector centrality and clustering coefficient of all vertices in Ve are computed and used to categorize tokens into two types:
(1) Connector Words: To measure the influence of all nodes in graphGe, we utilize eigenvec-
2φw is an experimentally determined threshold.
",3 Contextualized Affect Representations,[0],[0]
"tor centrality, which is calculated as:
ci = 1
λ ∑ j∈Ve Mi,jcj (4)
where λ denotes a proportionality factor and ci is the centrality score of node i.
",3 Contextualized Affect Representations,[0],[0]
"Given λ as the corresponding eigenvalue, Equation 4 can be reformulated in vector notation form as Mc = λc, where c is an eigenvector of M. Given a selected eigenvector c and the eigenvector centrality score of node i, denoted as ci, the final list of connector words, hereinafter referred to as CW , is obtained by retaining all tokens with ci > φeig
3.",3 Contextualized Affect Representations,[0],[0]
"CW correspond to the set of nodes that are very frequent and have high connectivity to high-rank nodes (e.g., “or”, “and”, and “my”).
",3 Contextualized Affect Representations,[0],[0]
"(2) Subject Words: In contrast, subject words or topical words are usually clustered together, i.e., many subject words are interconnected by the same connector words.",3 Contextualized Affect Representations,[0],[0]
"Therefore, a coefficient is assigned to all nodes in Ge and is computed as:
cli =
∑ j 6=i;k 6=j;k 6=iMi,j ×Mi,k ×Mj,k∑
j 6=i;k 6=j;k 6=iMi,j ×Mi,k × 1 |Ve|
(5) where cli denotes the average clustering coefficient of node i which captures the amount of interconnectivity among neighbours of node i. Similar to the connector words, the subject words, hereinafter referred to as SW , are obtained by retaining all the tokens with cli > φcl 4.",3 Contextualized Affect Representations,[0],[0]
"Examples of subjects words obtained are: “never” and “life”.
",3 Contextualized Affect Representations,[0],[0]
"The subject words represent psychological oriented words similar to the LIWC affect lexicon (Pennebaker et al., 2007), while connector words reflect the set of most common words in the subjective tweets (e.g., pronouns, auxiliary verbs, and conjunctions).",3 Contextualized Affect Representations,[0],[0]
"As presented by Chung and Pennebaker (2007), both connector words and subject words are important for conveying emotion.",3 Contextualized Affect Representations,[0],[0]
"Influenced by their work, we aim to capture intricate relationships – through the graph – between these two families of words.",3 Contextualized Affect Representations,[0],[0]
"The graph structure helps to preserve syntax and can automatically be used to surface emotion-relevant information.
",3 Contextualized Affect Representations,[0],[0]
One of the advantages of using graphs to represent syntactic relationships is that rare and important words are also surfaced.,3 Contextualized Affect Representations,[0],[0]
"As shown in Table 1,
3φeig is an experimentally determined threshold.",3 Contextualized Affect Representations,[0],[0]
"4φcl is an experimentally defined threshold.
",3 Contextualized Affect Representations,[0],[0]
"informal words and misspellings, such as “definetley”, “happnd”, were surfaced.",3 Contextualized Affect Representations,[0],[0]
"Words containing character repetitions help to express emotion intensity (e.g., “plzzzzzzz”, “aaaaaaah”, and “yayyyyy”).",3 Contextualized Affect Representations,[0],[0]
"Interestingly, emotion-related coded words are also captured (e.g., “juju”, “sh*t”, “4ever”, and “baobei”5).",3 Contextualized Affect Representations,[0],[0]
All these examples show the benefit of using graph methods to capture emotion-relevant linguistic information.,3 Contextualized Affect Representations,[0],[0]
"Step 5 (Pattern Candidates): Given SW and CW , we bootstrap candidate patterns, which are more prevalent in opinionated content, while preserving syntactic structure.",3 Contextualized Affect Representations,[0],[0]
We provide the templates used to define the candidate patterns in Table 2.,3 Contextualized Affect Representations,[0],[0]
"(sw and cw represent arbitrary tokens obtained from the sets SW and CW , respectively).",3 Contextualized Affect Representations,[0],[0]
It is important to clarify that sequences of size two and three were used in this work since this setting experimentally produced the best results.,3 Contextualized Affect Representations,[0],[0]
Step 6 (Basic Pattern Extraction): A naive pattern extraction process consists of applying the syntactic templates to a dataset Sp6 in an exhaustive manner.,3 Contextualized Affect Representations,[0],[0]
"In addition, the sw component in each pattern is replaced with a “*” placeholder.",3 Contextualized Affect Representations,[0],[0]
"This operation allows for unknown subject words, not present in our training corpus, to be considered when constructing features.",3 Contextualized Affect Representations,[0],[0]
"This can enable many useful applications, such as applying the patterns to other domains.",3 Contextualized Affect Representations,[0],[0]
"We are interested in patterns that are highly associated with subjectivity, so patterns frequently occurring above a threshold are kept and the rest are filtered out.",3 Contextualized Affect Representations,[0],[0]
"In Table 2, we provide examples of the type of basic patterns extracted along with their corresponding templates.",3 Contextualized Affect Representations,[0],[0]
"As they stand, the patterns constructed in the previous step contain limited information relevant to emotion classification.",3.1 Enriched Patterns,[0],[0]
"Therefore, the patterns are enriched using continuous word representations so as to preserve semantic relationship between pat-
5baobei is a Chinese word used to show strong affection.",3.1 Enriched Patterns,[0],[0]
"6 Dataset Sp (size=2+ mil.) is separately collected using similar steps as the subjective dataset S, mainly to avoid bias.
terns.",3.1 Enriched Patterns,[0],[0]
The motivation behind this step is to focus on patterns that may be more useful for an emotion classification task.,3.1 Enriched Patterns,[0],[0]
"Alternatively, the whole universe of patterns can also be used, but we show in the experiments that the former method significantly improves emotion recognition results.",3.1 Enriched Patterns,[0],[0]
"Pre-trained Word Embeddings: First, we obtain Twitter-based, pre-trained word embeddings from (Deriu et al., 2017) and reweight them via a sentiment corpus through distant supervision (Read, 2005; Go et al., 2009).7 We trained a fully connected neural network (1 hidden layer) with 10 epochs via backpropagation as in (Deriu et al., 2017).",3.1 Enriched Patterns,[0],[0]
The embeddings size is d = 52.,3.1 Enriched Patterns,[0],[0]
Note that term frequency-inverse document frequency (tf-idf ) was used to reduce the vocabulary of words (from 140K to 20K words).,3.1 Enriched Patterns,[0],[0]
Word Clusters: We then apply agglomerative clustering to generate clusters of semantically related words through their word embedding information.,3.1 Enriched Patterns,[0],[0]
"To determine the quality of the clusters, they are compared with WordNet-Affect synsets (Strapparava et al., 2004) and tested for both homogeneity and completeness.",3.1 Enriched Patterns,[0],[0]
"We use Ward’s method (Ward Jr, 1963) as the linkage criterion and cosine distance as the distance metric.",3.1 Enriched Patterns,[0],[0]
"The scikit-learn package (Pedregosa et al., 2011) was used to compute a total of k = 1500 clusters.",3.1 Enriched Patterns,[0],[0]
"Enriched-Pattern Construction: The purpose of the word clusters is to enrich the patterns by preserving the semantic relationship between them, which is useful for classification purposes.",3.1 Enriched Patterns,[0],[0]
"We achieve this by revising the universe of patterns obtained from the basic pattern extraction step, and check to see if the words represented by the sw component exist in any of the word embedding clusters.",3.1 Enriched Patterns,[0],[0]
"This is done in an exhaustive manner, ensuring that all possible patterns in the dataset Sp are processed to meet the criteria.",3.1 Enriched Patterns,[0],[0]
"Furthermore, patterns that appear < 10 times in dataset Sp are filtered out, producing a total of 476,174 patterns.
",3.1 Enriched Patterns,[0],[0]
"7We collected approximately 10 million tweets via sentiment emoticons (5+ mil. negative and 5+ mil. positive).
",3.1 Enriched Patterns,[0],[0]
"The resulting enriched patterns8 now contain both the semantic information provided by the word embeddings and the contextual information provided through the graph components, hence the term contextualized affect representations.",3.1 Enriched Patterns,[0],[0]
"Before using the patterns for classification, they need to be weighted using a weighting mechanism such as tf-idf (Leskovec et al., 2014).",3.2 Emotion Pattern Weighting,[0],[0]
The weights determine the importance of patterns to each emotion category.,3.2 Emotion Pattern Weighting,[0],[0]
"The proposed pattern weighting scheme used in this work is a customized version of tf-idf, coined as pattern frequency-inverse emotion frequency (pf-ief ), and is defined in two steps.",3.2 Emotion Pattern Weighting,[0],[0]
"Firstly, we compute for pf as:
pfp,e = log
( ∑ pi∈Pe freq(pi, e) )",3.2 Emotion Pattern Weighting,[0],[0]
"+ 1
freq(p, e) + 1 (6)
where freq(p, e) represents the frequency of p in e, and pfp,e denotes the logarithmically scaled frequency of a pattern p in a collection of texts related to emotion e.
Then we compute for ief as:
iefp = log freq(p, e) + 1( ∑
ej∈E freq(p, ej)
)",3.2 Emotion Pattern Weighting,[0],[0]
"+ 1
(7)
where the inverse emotion frequency iefp is a measure of the relevance of pattern p across all emotion categories.
",3.2 Emotion Pattern Weighting,[0],[0]
"Finally, we obtain a pattern score calculated as:
psp,e = pfp,e × iefp (8)
where psp,e is the final score that reflects how important a pattern p is to an emotion class e.",3.2 Emotion Pattern Weighting,[0],[0]
"In this section, we present the emotion recognition models and comparison models used to evaluate the contextualized affect representations.",4 Models,[0],[0]
More details are provided in Appendix A. CARER:,4 Models,[0],[0]
The proposed framework combines a multi-layer CNN architecture with a matrix form of the enriched patterns.,4 Models,[0],[0]
"The input X ∈ Rn×m denotes an embedding matrix where entry Xi,j
8Refer to Table 6 for enriched patterns examples.
represents the pattern score of enriched pattern i in emotion j. 9 X is fed into two 1-D convolutional layers with filters of sizes 3 and 16.",4 Models,[0],[0]
"The output of this process is passed through a ReLU activation function (Nair and Hinton, 2010) that produces a feature map matrix.",4 Models,[0],[0]
"A 1-max pooling layer (Boureau et al., 2010) of size 3 is then applied to each feature map.",4 Models,[0],[0]
"The results of the pooling are fed into two hidden layers of dimensions 512 and 128 in that order, each applied a dropout (Hinton et al., 2012) of 0.5 for regularization.",4 Models,[0],[0]
"We chose a batch size of 128 and trained for 4 epochs using Adam optimizer (Kingma and Ba, 2014).",4 Models,[0],[0]
A softmax function is used to generate the final classifications.,4 Models,[0],[0]
"We use Keras (Chollet et al., 2015) to implement the CNN architecture.
",4 Models,[0],[0]
"Baseline Model: As baseline, we present a firstgeneration model (CARERβ) that employs primitive enriched patterns‡10.",4 Models,[0],[0]
"We adopt the CNN architecture used for CARER, however, this model differs in that the set of patterns used is significantly smaller as compared to the original size of the enriched patterns.",4 Models,[0],[0]
"The reason is because a different set of primitive pattern templates was used, which captured fewer patterns (187,648).",4 Models,[0],[0]
This shows that the proposed method offers flexibility in terms of what templates to use and what size of patterns to generate.,4 Models,[0],[0]
"This could be useful in cases where there are limited computing and data resources, and for incorporating domain expertise.
",4 Models,[0],[0]
"Traditional Models: We also compare with various traditional methods (bag of words (BoW), character-level (char), n-grams, and TF-IDF) which are commonly used in sentence classification.",4 Models,[0],[0]
"To train the models we use the default stochastic gradient descent (SGD) classifier provided by scikit-learn (Pedregosa et al., 2011).",4 Models,[0],[0]
"Deep Learning Models: Among the works that employ deep learning models for emotion recognition, they vary by the choice of input: pretrained word/character embeddings and end-toend learned word/character representations.",4 Models,[0],[0]
Our work differs in that we utilize enriched graphbased representations as input.,4 Models,[0],[0]
"We compare with convolutional neural networks (CNNs), recurrent neural networks (RNNs), bidirectional gated recurrent neural networks (BiGRNNs), and word embeddings (word2vec) (Mikolov et al., 2013).
",4 Models,[0],[0]
"9We use a zero-padding strategy as in (Kim, 2014).",4 Models,[0],[0]
10‡ hereinafter refers to the primitive enriched patterns.,4 Models,[0],[0]
We construct a set of hashtags to collect a separate dataset of English tweets from the Twitter API.,5.1 Data,[0],[0]
"Specifically, we use the eight basic emotions: anger, anticipation, disgust, fear, joy, sadness, surprise, and trust.",5.1 Data,[0],[0]
"The hashtags (339 total) serve as noisy labels, which allow annotation via distant supervision as in (Go et al., 2009).",5.1 Data,[0],[0]
"To ensure data quality, we follow the pre-processing steps proposed by (Abdul-Mageed and Ungar, 2017), and considered the hashtag appearing in the last position of a tweet as the ground truth.",5.1 Data,[0],[0]
We split the data into training (90%) and testing (10%) datasets.,5.1 Data,[0],[0]
The final distribution of the data and a list of hashtag examples for each emotion are provided in Table 3.,5.1 Data,[0],[0]
In the following section we evaluate the effectiveness of the enriched patterns on several emotion recognition tasks.,5.1 Data,[0],[0]
"We use F1score as the evaluation metric, which is commonly used in emotion recognition studies due to the imbalanced nature of the emotion datasets.",5.1 Data,[0],[0]
"Traditional Features: As shown in Table 4, TF-IDF models produce better results than basic count-based features for both character-level and word-level feature extractors.",5.2 Experimental Results,[0],[0]
"These findings are consistent with the work of Zhang et al., (2015), where traditional methods, such as n-gram, were found to perform comparable to deep neural networks on various sentence classification tasks.",5.2 Experimental Results,[0],[0]
"Pattern-based Approaches: The results of CNNBASIC11, which employs the basic graphbased patterns proposed in Step 6, perform worse than most of the conventional approaches.",5.2 Experimental Results,[0],[0]
"Both CARERβ and CARER, which use the enriched patterns, acquire better results than CNNBASIC
11CNNBASIC adopts CNN architecture of CARER.
and all the other conventional approaches.",5.2 Experimental Results,[0],[0]
"In fact, our method obtains the best F1-score on all eight emotions.",5.2 Experimental Results,[0],[0]
"We observed that there are significant gains in performance (↑27% and ↑12%) when using the enriched patterns as compared to the basic patterns and primitive patterns‡, respectively.",5.2 Experimental Results,[0],[0]
This highlights the importance of the pattern enrichment procedure and the benefit of refining the pattern templates.,5.2 Experimental Results,[0],[0]
"Note that the baseline model, CARERβ , also performs better than all other the comparison models including the state-of-the-art methods (DeepMoji and EmoNet).",5.2 Experimental Results,[0],[0]
"Comparison to state-of-the-art: Felbo et al., (2017) proposed a state-of-the-art emotion prediction model, DeepMoji, trained on billions of emoji-labeled tweets.",5.2 Experimental Results,[0],[0]
We obtained their pretrained model12 and applied it to our dataset.,5.2 Experimental Results,[0],[0]
"As shown in Table 4, their model performs as well as other traditional methods.",5.2 Experimental Results,[0],[0]
"However, our model (CARER) significantly outperforms theirs (↑20%).",5.2 Experimental Results,[0],[0]
"Moreover, we re-implemented the GRNN model proposed in (Abdul-Mageed and Ungar, 2017).",5.2 Experimental Results,[0],[0]
"We also outperform their model (EmoNet) which manually trains word embeddings, similar to DeepMoji.",5.2 Experimental Results,[0],[0]
"The CNNw2v model uses word embeddings trained on billions of tweets (Deriu et al., 2017), thus it performs better than all the other approaches, and closer to ours.",5.2 Experimental Results,[0],[0]
"Results with Deep Learning: We offer more comparison with other various deep learning models as evaluated on Ekman’s six basic emotions (i.e., sadness, disgust, anger, joy, surprise, and fear).",5.2 Experimental Results,[0],[0]
"For the RNNw2v and CNNchar models, different inputs are used, as shown in Table 5.",5.2 Experimental Results,[0],[0]
"We feed the enriched patterns as embeddings to a bidirectional GRNN, which along with CAREREK and CARERβ outperform all the other methods.",5.2 Experimental Results,[0],[0]
Contextualized Approaches:,5.2 Experimental Results,[0],[0]
DeepMoji is built on a stack of Bi-LSTM layers and performs much better with six emotion classes.,5.2 Experimental Results,[0],[0]
"However, using the enriched patterns as input, CAREREK13 performs the best (81%).",5.2 Experimental Results,[0],[0]
"Note that the number of epochs used to train our models is much lower as compared to the other methods, which provides a strong case of the benefit of contextualizing features prior to training the models.",5.2 Experimental Results,[0],[0]
"Moreover, the important distinction between connector words and subject words helps to refine and surface relevant contextual information.",5.2 Experimental Results,[0],[0]
"We also
12Model obtained from github.com/bfelbo/deepmoji 13The proposed model trained on six emotions dataset.
",5.2 Experimental Results,[0],[0]
"show that the enriched patterns can be applied to other deep learning models besides CNN, such as BiGRNN, which leaves an opportunity to explore more complex architectures and fusion models in the future.",5.2 Experimental Results,[0],[0]
"More importantly, for problems that require deeper understanding of contextualized information, there is a need to go beyond traditional features and distributed representations.",5.2 Experimental Results,[0],[0]
Multilingual Capabilities: We also tested the effectiveness of the proposed feature extraction algorithm for the Chinese language.,5.2 Experimental Results,[0],[0]
We collected Traditional Chinese datasets14 from several of Facebook’s fan pages and applied the same procedures as were done for the English datasets.,5.2 Experimental Results,[0],[0]
User comments are considered as documents and the associated user reaction to the root post represents the emotion labels.,5.2 Experimental Results,[0],[0]
"For comparison, we obtained Chinese pre-trained word vectors computed through (Bojanowski et al., 2017), and trained a model (fastTextch) using the proposed CNN architecture.",5.2 Experimental Results,[0],[0]
"For our approach (CARERch), we applied the same CNN architecture on the Chinesebased enriched patterns.",5.2 Experimental Results,[0],[0]
"As shown in Figure 2, our model performs significantly better on all four emotions (average F1 score of 70%).",5.2 Experimental Results,[0],[0]
"Overall, we show that the approach is not restricted to any specific language and that the enriched features are applicable to other languages and data sources.",5.2 Experimental Results,[0],[0]
"In the future, we seek to expand our methods to support other complex languages, such as Japanese, French, and Spanish, where there tends to exist fewer linguistic resources.",5.2 Experimental Results,[0],[0]
"One of the advantages of the contextualized enriched patterns is that they possess high coverage
14Details of the dataset are provided in Appendix B.
due to the way they were constructed.",6.1 Pattern Coverage and Consistency,[0],[0]
"High coverage also means that the enriched patterns should demonstrate stability, in terms of how useful they are in an emotion classification task, even when reduced to smaller sizes.",6.1 Pattern Coverage and Consistency,[0],[0]
There are two cases where this could be useful: limited data and limited computing resources.,6.1 Pattern Coverage and Consistency,[0],[0]
"Therefore, to test for pattern consistency, we randomly selected several pattern sizes15 and trained a random forest classifier using the eight emotions dataset.",6.1 Pattern Coverage and Consistency,[0],[0]
"This model performs comparable to CARERβ (average F1-score of 65%), and it has the benefit of faster training
15We employed the primitive patterns‡ used in CARERβ .
time, making it suitable for the aforementioned experiment.",6.1 Pattern Coverage and Consistency,[0],[0]
"We compared with the results obtained from the LIWC lexicon (affect dimension) (Pennebaker et al., 2007), word2vec (Mikolov et al., 2013), and tweet2vec (Deriu et al., 2017).16
As shown in Figure 3, due to the limited coverage of the LIWC lexicon, such resources may not be feasible on evolving, large-scale datasets.",6.1 Pattern Coverage and Consistency,[0],[0]
"In contrast, word2vec contains over 3 million unique word embeddings and has been proven effective for text classification.",6.1 Pattern Coverage and Consistency,[0],[0]
"However, if we keep reducing the available word vectors of word2vec, which is common when there are limited computing resources, the accuracy keeps dropping at significant rates.",6.1 Pattern Coverage and Consistency,[0],[0]
tweet2vec has a similar effect.,6.1 Pattern Coverage and Consistency,[0],[0]
"In the case of our patterns, the classification results remain relatively stable, even when reducing the patterns to 30% and 10% of the original size.",6.1 Pattern Coverage and Consistency,[0],[0]
These results show that the proposed features are feasible to address the text-based emotion recognition problem.,6.1 Pattern Coverage and Consistency,[0],[0]
"Moreover, the patterns are highly beneficial where
16Models were trained using the random forest implementation (depth=15 and estimators=50) provided by scikit-learn.
",6.1 Pattern Coverage and Consistency,[0],[0]
there is shortage of computing and linguistic resources.,6.1 Pattern Coverage and Consistency,[0],[0]
"In Table 6, we provide samples extracted from the testing data.",6.2 What’s captured by CARER?,[0],[0]
The examples show different cases where the comparison models struggled to capture important contextual information that helps to determine the emotion conveyed in the text.,6.2 What’s captured by CARER?,[0],[0]
"For instance, in the short text, “damn what a night”, only our model was able to interpret the statement as joy because it uses the “what a” pattern and its corresponding subject words to determine that this statement has a stronger association with joy.",6.2 What’s captured by CARER?,[0],[0]
Our model also works well for capturing rare words and for disambiguating emotional meaning using the enriched and refined contextual information of the patterns.,6.2 What’s captured by CARER?,[0],[0]
"Rare words like “whaaaaaat” and “thee” help to implicitly convey intense emotional expressions, which are also captured and considered important by our enriched patterns.",6.2 What’s captured by CARER?,[0],[0]
"Emotionrelevant verbs, such as “want” and “going” are also considered important context that help to convey and interpret emotion.",6.2 What’s captured by CARER?,[0],[0]
"Overall, the enriched patterns efficiently capture important emotional information that other models seem to ignore.",6.2 What’s captured by CARER?,[0],[0]
We proposed a graph-based feature extraction mechanism to extract emotion-relevant representations in an unsupervised manner.,7 Conclusion,[0],[0]
The contextualized affect representations are further enriched with word embeddings and are used to train several deep learning-based emotion recognition models.,7 Conclusion,[0],[0]
"The patterns capture implicit and explicit linguistic emotional information which significantly improves emotion recognition results.
",7 Conclusion,[0],[0]
We offered a detailed analysis demonstrating special cases where the patterns are helpful to further extract and understand emotional information from textual information.,7 Conclusion,[0],[0]
"For instance, short text
is a challenging problem in emotion recognition and various natural language tasks; the proposed contextualized patterns show promising results in addressing this issue by helping the models to capture nuanced information which is useful to determine the overall emotion expressed in a piece of text.",7 Conclusion,[0],[0]
"The proposed method paves the way for building more interpretable emotion recognition systems which have various implications when investigating human behavioural data (Saravia et al., 2015, 2016b; Chang et al., 2016) and building empathy-aware conversational agents.
",7 Conclusion,[0],[0]
"In the future work, we aim to investigate the graph-based patterns more in-depth and provide a more comprehensive and advanced theoretical discussion of how they are constructed.",7 Conclusion,[0],[0]
We also hope to keep improving the pattern weighting mechanism so as to improve the overall performance on emotion recognition tasks and minimize trade-off between pattern coverage and performance.,7 Conclusion,[0],[0]
We plan to employ transfer learning methods with the proposed enriched patterns and test on other emotion-related problems such as sentiment classification and sarcasm detection.,7 Conclusion,[0],[0]
The proposed methodology is also being expanded to support Spanish and Japanese emotion recognition tasks.,7 Conclusion,[0],[0]
This research was supported by the Ministry of Science and Technology (#106-2221-E-007-115MY2 and #106-3114-E-007-013).,Acknowledgements,[0],[0]
"Emotions are expressed in nuanced ways, which varies by collective or individual experiences, knowledge, and beliefs.",abstractText,[0],[0]
"Therefore, to understand emotion, as conveyed through text, a robust mechanism capable of capturing and modeling different linguistic nuances and phenomena is needed.",abstractText,[0],[0]
"We propose a semisupervised, graph-based algorithm to produce rich structural descriptors which serve as the building blocks for constructing contextualized affect representations from text.",abstractText,[0],[0]
The pattern-based representations are further enriched with word embeddings and evaluated through several emotion recognition tasks.,abstractText,[0],[0]
Our experimental results demonstrate that the proposed method outperforms state-of-the-art techniques on emotion recognition tasks.,abstractText,[0],[0]
CARER: Contextualized Affect Representations for Emotion Recognition,title,[0],[0]
"Proceedings of the SIGDIAL 2018 Conference, pages 11–19, Melbourne, Australia, 12-14 July 2018. c©2018 Association for Computational Linguistics
11",text,[0],[0]
An important part of any conversation is understanding the meaning your conversation partner is trying to convey.,1 Introduction,[0],[0]
"If we do not obscure our intent and phrase it as directly as possible, our conversation partner will have an easier time to recognise our goal and cooperate in achieving it.",1 Introduction,[0],[0]
"Thereby, we can enable a successful conversation.",1 Introduction,[0],[0]
"Nevertheless, there are countless instances in which humans choose to express their meaning indirectly, as evidenced by the work of Searle (1975) and Feghali (1997), among others.",1 Introduction,[0],[0]
Answering the question ‘How is the weather?’,1 Introduction,[0],[0]
"with ‘Let’s rather stay inside.’ gives no concrete in-
formation about the weather conditions, but is commonly understood.",1 Introduction,[0],[0]
"There are several reasons why humans could choose to express their intent indirectly, such as cultural preferences, politeness, embarrassment, or simply using common figures of speech such as ‘Can you tell me the time?’.",1 Introduction,[0],[0]
"Considering the frequency of indirectness in human-human communication, we need to anticipate the use of indirectness in human-computer communication and enable dialogue systems to handle it.
",1 Introduction,[0],[0]
"In this work, we introduce an approach to exchanging utterances with others that express the same intent in the dialogue but exhibit a differing level of directness.",1 Introduction,[0],[0]
"More concretely, our approach would replace the second utterance of the exchange ‘What pizza do you want?’",1 Introduction,[0],[0]
- ‘I want a vegetarian pizza.’,1 Introduction,[0],[0]
with an utterance like ‘I don’t like meat’.,1 Introduction,[0],[0]
"To this end, we employ models that can estimate the level of directness of an utterance on the one hand and the degree to which utterances express the same intent on the other.
",1 Introduction,[0],[0]
Our approach can be applied to solve two challenges of indirectness for dialogue systems:,1 Introduction,[0],[0]
"On the side of the language analysis, the true intent of the user needs to be recognised so that the dialogue system can react in an appropriate, cooperative manner.",1 Introduction,[0],[0]
"If the language analysis is able to not only recognise the user’s intended meaning, but also when the user is being indirect, this information can further be utilised by the dialogue manager, e.g. by scheduling a confirmation if the user is believed to have used indirectness.",1 Introduction,[0],[0]
Our approach estimates the level of directness of an utterance as a first step.,1 Introduction,[0],[0]
"If the utterance is classified as indirect, this information can be provided to the dialogue manager.",1 Introduction,[0],[0]
"Furthermore, our approach exchanges the indirect utterance for a direct counterpart that more accurately reflects the users intent, thereby facilitating the task of the lan-
guage analysis.",1 Introduction,[0],[0]
The second area of dialogue system that can benefit from taking into account indirectness is the language generation.,1 Introduction,[0],[0]
"Studies could show that under specific circumstances indirectness is preferred not only from human conversation partners, but also in human-computer interaction (e.g. (Miehle et al., 2016; Pragst et al., 2017)).",1 Introduction,[0],[0]
"Therefore, dialogue systems that can adjust the level of directness in their output to the user and their circumstances should be able to provide an improved user experience.",1 Introduction,[0],[0]
"If a certain level of directness is determined to be desirable with regards to the current circumstances, our algorithm can determine whether the utterance chosen as system output possesses the targeted level of directness and exchange it for a more suitable alternative if it does not.
",1 Introduction,[0],[0]
"In the following, we will discuss related work, before presenting our general approach and its concrete implementation.",1 Introduction,[0],[0]
This approach is evaluated in Section 4.,1 Introduction,[0],[0]
"Here, we introduce the dialogue corpus we created to obtain a reliable ground truth and discuss the results of our evaluation.",1 Introduction,[0],[0]
"Finally, we draw a conclusion in Section 5.",1 Introduction,[0],[0]
"Allen and Perrault (1980) propose a plan-based approach to understanding the intention of the speaker, explicitly mentioning indirect speech acts as application.",2 Related Work,[0],[0]
"Similarly, Briggs and Scheutz (2013) address both the understanding and the generation of indirect speech acts.",2 Related Work,[0],[0]
Their approach combines idiomatic and plan-based approaches.,2 Related Work,[0],[0]
"In plan-based approaches, a planning model that contains potential goals as well as actions with pre-and post conditions needs to be defined manually in order to anticipate the user’s plan and thereby identify the intent of an utterance.",2 Related Work,[0],[0]
"Our approach aims to eliminate the explicit preparation of the planning model, and instead relies on patterns learned from a large amount of examples.
",2 Related Work,[0],[0]
"In our work, we utilise a Dialogue Vector Model (DVM) (Pragst et al., 2018) to assess whether two utterances express the same intent in a dialogue.",2 Related Work,[0],[0]
"A number of different approaches to the representation of sentences in vector space have been proposed, e.g. utilising recurrent neural networks (Sutskever et al., 2014; Palangi et al., 2016; Tsunoo et al., 2017), convolutional neural networks (Shen et al., 2014; Kalchbrenner et al., 2014; Hu et al., 2014) and autoencoders (Socher
et al., 2011).",2 Related Work,[0],[0]
"However, those approaches rely on the words in the sentence only to generate a vector representation.",2 Related Work,[0],[0]
"As a consequence, sentences that have the same meaning, but do not share the same words (which is often the case for utterances with different levels of directness) are not mapped in the vicinity of each other.",2 Related Work,[0],[0]
"In contrast, DVMs map functionally similar sentences close to each other and are therefore better suited for our needs.
",2 Related Work,[0],[0]
"Skip thought vectors (Kiros et al., 2015) are sentence embeddings that are generated in a similar manner as word vector representations, and therefore similar to dialogue vector models.",2 Related Work,[0],[0]
"Rather than using the words in the sentence itself as basis to create a vector representation, those vectors are generated taking into account surrounding sentences.",2 Related Work,[0],[0]
"However, this representation is trained on novels rather than dialogue, as opposed to DVMs, which focus specifically on dialogue and its peculiarities.",2 Related Work,[0],[0]
Our work is concerned with the exchange of utterances for functionally similar ones with differing levels of directness.,3 Changing the Level of Directness,[0],[0]
We define functional similarity as the degree to which two utterances can be used interchangeably in a dialogue as they express the same meaning.,3 Changing the Level of Directness,[0],[0]
"Substituting a direct/indirect utterance with its respective counterpart can be achieved by performing the following steps:
Algorithm 1: Pseudocode for exchanging one utterance for another that is functionally similar and of the opposite directness.
",3 Changing the Level of Directness,[0],[0]
"Data: origU , the utterance to be exchanged prvU , the utterance occurring previous to origU allU , the set of all available utterances DVM, a function that maps an utterance to its corresponding dialogue vector evalInd, a function that returns the estimated level of directness, ranging from one to three Result: excU , the substitute for origU origDirectness←− evalInd(prvU, origU); if origDirectness ≤ 1 then
oppU ←−",3 Changing the Level of Directness,[0],[0]
"{u ∈ allU : evalInd(prvU, u) > 1}; else
oppU ←−",3 Changing the Level of Directness,[0],[0]
"{u ∈ allU : evalInd(prvU, u) ≤ 1}; excU ←− argminu∈oppU euclDist(DVM(origU),DVM(u));
1.",3 Changing the Level of Directness,[0],[0]
"Determine the level of directness of the utterance.
2.",3 Changing the Level of Directness,[0],[0]
"Gather the remaining known utterances that are of the opposite directness level.
3.",3 Changing the Level of Directness,[0],[0]
"From those, choose the utterance that is functionally most similar to the original utterance.
",3 Changing the Level of Directness,[0],[0]
"Figure 1 shows this procedure on an abstract level, while a more detailed pseudo-code is depicted in Algorithm 1.",3 Changing the Level of Directness,[0],[0]
"Two challenges need to be addressed in order to perform this approach: The first one is to correctly determine the level of directness of an utterance, the second one is to identify utterances that perform a similar semantic functionality in a dialogue.",3 Changing the Level of Directness,[0],[0]
"To solve those challenges, we utilise established approaches, namely recurrent neural networks (RNN) and dialogue vector models (DVM).",3 Changing the Level of Directness,[0],[0]
"In the following, we take a closer look at how we apply those approaches to solve the presented challenges.
",3 Changing the Level of Directness,[0],[0]
"To determine which utterances can be exchanged without altering the intended meaning, a suitable similarity measure is needed.",3 Changing the Level of Directness,[0],[0]
"In our work, we utilise DVMs (Pragst et al., 2018) to that end.",3 Changing the Level of Directness,[0],[0]
DVMs are representations of sentences as vectors that captures their semantic meaning in the dialogue context.,3 Changing the Level of Directness,[0],[0]
"They are inspired by word vector models (Mikolov et al., 2013a) and generated in a similar manner: The mapping of utterances to their vector representations is trained akin to autoencoding.",3 Changing the Level of Directness,[0],[0]
"However, rather than training against the input utterance itself, utterances are trained against their adjacent utterances in the input corpus, either using the utterance to predict its
context or using the context to predict the utterance.",3 Changing the Level of Directness,[0],[0]
"The resulting vector representation groups sentences that are used in a similar context and therefore likely to fulfil the same conversational function in close vicinity to each other, as could be shown by Pragst et al. (2018).",3 Changing the Level of Directness,[0],[0]
"Therefore, DVMs are well suited to determine whether utterances perform a similar function in a dialogue.",3 Changing the Level of Directness,[0],[0]
"Our algorithm calculates the euclidean distance between the dialogue vector representations of two utterances and chooses the utterance with the minimal distance as the most functionally similar.
",3 Changing the Level of Directness,[0],[0]
"For the estimation of the level of directness an utterance possesses, we choose a supervised learning approach with a RNN.",3 Changing the Level of Directness,[0],[0]
RNNs are a popular supervised machine learning approach to find complex relationships in large amounts of sequential data.,3 Changing the Level of Directness,[0],[0]
"As indirectness relies on the context of the conversation, the use of RNNs seems promising for the estimation the level of directness an utterances possess.",3 Changing the Level of Directness,[0],[0]
The architecture of our RNN is depicted in Figure 2.,3 Changing the Level of Directness,[0],[0]
It is a time delay network that uses the previous input in addition to the current one.,3 Changing the Level of Directness,[0],[0]
"To obtain a numerical representation of an utterance that can be used as input to the network, we utilise word vector models (Mikolov et al., 2013a) and DVMs (Pragst et al., 2018).",3 Changing the Level of Directness,[0],[0]
The input for an utterances then consists of its dialogue vector representation and the sum of the word vector representations of its words.,3 Changing the Level of Directness,[0],[0]
"Furthermore, the word and dialogue vectors of the previous utterance are provided as recurrent data to reflect the dialogue context.",3 Changing the Level of Directness,[0],[0]
The target value is given by corpus annotations of the level of directness of the utterance.,3 Changing the Level of Directness,[0],[0]
"As we are trying to solve a classification problem, the network is designed to provide the probability that the utterance belongs to each of the classes as its result.",3 Changing the Level of Directness,[0],[0]
"After training, the network constitutes the core part of the function that estimates the level directness of an utterance.",3 Changing the Level of Directness,[0],[0]
This section presents the evaluation of the proposed approach.,4 Evaluation,[0],[0]
We first introduce a dialogue corpus that is suitable to train the required models and provides a reliable ground truth to compare the results of our approach to.,4 Evaluation,[0],[0]
"Afterwards, the setup of the evaluation is described and its results presented and discussed.",4 Evaluation,[0],[0]
"Our approach requires a dialogue corpus for several task: as a source for alternative utterances, as training data for the directness classifier, as training data for the DVM and as ground truth for the evaluation.",4.1 Dialogue Corpus,[0],[0]
"To fulfil those tasks, the employed corpus has to meet two requirements: it needs to contain a sufficient amount of examples for functionally similar direct and indirect utterances, and the utterances need to be annotated with their dialogue act and level of directness.
",4.1 Dialogue Corpus,[0],[0]
"We considered several existing dialogue corpora, none of which suited our needs.",4.1 Dialogue Corpus,[0],[0]
"Furthermore, we dismissed the option to collect and annotate a dialogue corpus ourselves, considering the difficulty to make sure that speakers would use different levels of directness for the same purpose without inhibiting the naturalness of the dialogues.",4.1 Dialogue Corpus,[0],[0]
"Instead, we decided to generate a suitable dialogue corpus automatically.
",4.1 Dialogue Corpus,[0],[0]
"The advantages an automatically generated corpus offers for our work are the certainty that it contains a number of examples for functionally similar direct and indirect variants, as well as a dependable ground truth for the evaluation.",4.1 Dialogue Corpus,[0],[0]
"However, automatically generated corpora come with certain limitations.",4.1 Dialogue Corpus,[0],[0]
"After introducing our dialogue corpus in the following, we will discuss the potential advantages and limitations of automatically generated corpora.",4.1 Dialogue Corpus,[0],[0]
Our corpus contains dialogues with two different tasks: ordering pizza and arranging joint cooking.,4.1.1 Description of the Dialogue Corpus,[0],[0]
Example dialogues can be found in Figure 3.,4.1.1 Description of the Dialogue Corpus,[0],[0]
"The dialogues incorporate typical elements of human conversation: different courses of the dialogue, over-answering, misunderstandings as well as requests for confirmation and corrections, among others.",4.1.1 Description of the Dialogue Corpus,[0],[0]
"The example dialogues also show
instances of different wordings for the same purpose, such as several indirect variants of ‘Yes.’, such as ‘Great.’, ‘I’m looking forward to it.’",4.1.1 Description of the Dialogue Corpus,[0],[0]
and ‘That sounds delicious.’,4.1.1 Description of the Dialogue Corpus,[0],[0]
"that can be found across the dialogues, and the direct ‘I would like to order pizza.’",4.1.1 Description of the Dialogue Corpus,[0],[0]
in Dialogue 3 that is exchanged for the indirect ‘Can I order pizza from you?’,4.1.1 Description of the Dialogue Corpus,[0],[0]
in Dialogue 4.,4.1.1 Description of the Dialogue Corpus,[0],[0]
"Additionally, the same utterance can have a different level of directness depending on the context: in Dialogue 1, the utterance ‘I haven’t planned anything.’",4.1.1 Description of the Dialogue Corpus,[0],[0]
"as response to ‘Do you have time today?’ is indirect, whereas it is direct as response to ‘Do you have plans today?’",4.1.1 Description of the Dialogue Corpus,[0],[0]
in Dialogue 2.,4.1.1 Description of the Dialogue Corpus,[0],[0]
"Overall, the corpus contains more than 400000 different dialogue flows and about four wordings per dialogue action.
",4.1.1 Description of the Dialogue Corpus,[0],[0]
"As first step of the corpus generation, we defined a dialogue domain in a similar manner to the ones often employed by dialogue managers (e.g. OwlSpeak (Ultes and Minker, 2014)).",4.1.1 Description of the Dialogue Corpus,[0],[0]
"It contains all system and user actions foreseen for the dialogues, and defines rules about feasible successions of those.",4.1.1 Description of the Dialogue Corpus,[0],[0]
"Furthermore, each system and user action is assigned a number of different utterances that can be used to express their intent.",4.1.1 Description of the Dialogue Corpus,[0],[0]
"Each utterance incorporates a level of directness ranging from one to three, with one being direct (e.g. ‘I want vegetarian pizza.’) and three indirect (e.g. ‘I don’t like meat.’).",4.1.1 Description of the Dialogue Corpus,[0],[0]
"A rating of two is assigned if the utterance is indirect, but still very close to the direct one, or a common figure of speech (e.g ‘Can I get vegetarian pizza?’).",4.1.1 Description of the Dialogue Corpus,[0],[0]
"The directness level depends not only on the utterance itself, but also on the dialogue context.",4.1.1 Description of the Dialogue Corpus,[0],[0]
"Therefore, the utterance ‘I have time today.’ receives a rating of three if the previous utterance was ‘Do you have plans today?’, and a rating of one if the previous utterance was ‘Do you have time today?’.
",4.1.1 Description of the Dialogue Corpus,[0],[0]
"In the next step, all dialogue flows are generated by recursively picking a dialogue action, gen-
erating a list of its possible successors as stated by the rules in the dialogue domain and repeating the procedure for each of the successors.",4.1.1 Description of the Dialogue Corpus,[0],[0]
"If a dialogue action does not have successor, the sequence of dialogue actions that have been chosen to get to that point are saved as a complete dialogue.",4.1.1 Description of the Dialogue Corpus,[0],[0]
The wording is chosen randomly from the utterances associated with the respective dialogue action.,4.1.1 Description of the Dialogue Corpus,[0],[0]
The use of automatically generated corpora is not widely adopted in the research community of human-computer interaction.,4.1.2 Discussion of Automatically Generated Corpora,[0],[0]
"Due to their artificial nature, they have obvious limitations: they possess less flexibility than natural conversations, regarding both the dialogue flow and the different wordings.",4.1.2 Discussion of Automatically Generated Corpora,[0],[0]
"As a result, both dialogue flow and wording are much more predictable for automatically generated corpora and it is highly likely that machine learning approaches and similar procedures will perform better on generated dialogues than they would on natural ones.",4.1.2 Discussion of Automatically Generated Corpora,[0],[0]
"Nevertheless, we believe that generated dialogues have their benefits: they should not be used to gauge the actual performance of approaches in an applied spoken dialogue system, but rather to appraise their potential.
",4.1.2 Discussion of Automatically Generated Corpora,[0],[0]
"The comparison of natural and automatically generated dialogue corpora bears parallels to the discussion regarding laboratory experiments and field experiments, and their respective advantages and limitations (as discussed by Berkowitz and Donnerstein (1982), Harrison and List (2004) and Falk and Heckman (2009), among others).",4.1.2 Discussion of Automatically Generated Corpora,[0],[0]
"While natural dialogues more accurately represent conversations in the real world, automatically generated dialogues offer more control.",4.1.2 Discussion of Automatically Generated Corpora,[0],[0]
"In particular, that means specific questions can be tested in a structured and systematic manner, the generation ensuring that relevant data is incorporated in the corpus and irrelevant data that might interfere with the experiments is excluded, as well as the presence of a dependable ground truth.",4.1.2 Discussion of Automatically Generated Corpora,[0],[0]
"Therefore, we can reliably assess whether an approach is viable to solve a given task.
",4.1.2 Discussion of Automatically Generated Corpora,[0],[0]
"Additionally, by being able to provide the complete data set for a smaller scale use case as defined by the dialogue domain, we can get an idea about the potential performance of an approach given a large amount of data that approaches the state of total coverage.",4.1.2 Discussion of Automatically Generated Corpora,[0],[0]
"While this amount of data
is usually unobtainable for most researchers, large companies have the resources to collect a suitably big corpus and are likely already working towards it.",4.1.2 Discussion of Automatically Generated Corpora,[0],[0]
"Therefore, it is beneficial to examine the full potential of a given approach.",4.1.2 Discussion of Automatically Generated Corpora,[0],[0]
"However, in our considerations regarding the availability of large amounts of data we need to take into account that even large companies typically do not have access to a large amount of annotated data.
",4.1.2 Discussion of Automatically Generated Corpora,[0],[0]
"In summary, we believe that automatically generated dialogues, while not providing us with an accurate performance measure of an approach in the real world, can help us to assess its general viability to solve a specific task and to estimate its performance given enough data.",4.1.2 Discussion of Automatically Generated Corpora,[0],[0]
For the evaluation of our approach we determine its accuracy in finding an utterance that shares the dialogue action with the original utterance and is of the opposite level of directness.,4.2 Setup of the Evaluation,[0],[0]
The ground truth for both criteria is given by the previously presented dialogue corpus.,4.2 Setup of the Evaluation,[0],[0]
"In addition, we also evaluate the performance of the trained classifier and investigate how it influences the overall performance.",4.2 Setup of the Evaluation,[0],[0]
"As the ability of DVM to group utterances that share a dialogue action has already been shown in (Pragst et al., 2018), it will not be part of this evaluation.
",4.2 Setup of the Evaluation,[0],[0]
"To investigate the effects of the amount of available data, we use several DVMs that are trained on only a fraction of the complete corpus. Corpus sizes of 0.1, 0.2, 0.4, 0.6, 0.8 and of course the full corpus are considered.",4.2 Setup of the Evaluation,[0],[0]
"The dialogues that are part of the reduced corpora are chosen at random.
",4.2 Setup of the Evaluation,[0],[0]
Another aspect we study is the impact of the amount of available annotated training data for the classifier on its performance.,4.2 Setup of the Evaluation,[0],[0]
"As usual, we use ten-fold cross-validation in our evaluation.",4.2 Setup of the Evaluation,[0],[0]
"However, instead of only using 90% of the utterances for training and 10% for testing, we also evaluate our approach using 10% of the utterances for training and 90% for testing.",4.2 Setup of the Evaluation,[0],[0]
"With this, we want to investigate how our approach performs given only a limited amount of annotated data.
",4.2 Setup of the Evaluation,[0],[0]
"Finally, we compare the performance of the classifier when using only dialogue vectors as input and when using both dialogue vectors and the sum of word vectors.",4.2 Setup of the Evaluation,[0],[0]
"As DVMs map functionally similar utterances in close vicinity to each other, direct and indirect utterances should be hard to
distinguish with just the information from those models.",4.2 Setup of the Evaluation,[0],[0]
"On the other hand, the sum of word vectors might be missing important context information for the identification of the directness level.",4.2 Setup of the Evaluation,[0],[0]
"We believe that the combination of both the sum of word vectors and dialogue vectors will improve the performance of the classifier.
",4.2 Setup of the Evaluation,[0],[0]
The DVMs we utilise in our evaluation as similarity measure and as input to the RNN are trained on the presented dialogue corpus.,4.2 Setup of the Evaluation,[0],[0]
"The network additionally receives the sum of the word vectors of an utterance, based on the Google News Corpus model (Mikolov et al., 2013b), as input.",4.2 Setup of the Evaluation,[0],[0]
"Overall, our results show that the proposed approach has a high potential.",4.3 Results,[0],[0]
"The best mean accuracy reaches a value of 0.68 , and the classifier predicts the right class with 0.87 accuracy on average.",4.3 Results,[0],[0]
"In the following, we discuss the results and their implications in more detail, starting with the results of the classifier, before assessing the overall performance.",4.3 Results,[0],[0]
The baseline performance our classifier should surpass the prediction of the majority class.,4.3.1 Classification of Directness,[0],[0]
"With the given data, such a classifier can achieve an accuracy of 0.5291.",4.3.1 Classification of Directness,[0],[0]
Our trained classifier achieves a significantly better accuracy of 0.8710 (t(203) =,4.3.1 Classification of Directness,[0],[0]
"35.366, p < .001) averaged over all test cases.",4.3.1 Classification of Directness,[0],[0]
"Even the worst classifier, with an accuracy of 0.6354, performs more than 10% better than choosing the majority class.
",4.3.1 Classification of Directness,[0],[0]
"As expected, significant differences exist for the size of the training set (t(159.425) =",4.3.1 Classification of Directness,[0],[0]
"−4.008, p < .001), with a larger training set leading to better results.",4.3.1 Classification of Directness,[0],[0]
"Furthermore, adding the linear combination of the word vectors as input improves the performance of the classifier significantly (t(101.347) = 32.434, p < .001).",4.3.1 Classification of Directness,[0],[0]
The mean performances can be seen in Figure 4.,4.3.1 Classification of Directness,[0],[0]
"The corpus size the DVMs were trained on does not have a significant impact.
",4.3.1 Classification of Directness,[0],[0]
Those results suggest that the amount of labelled training data greatly affects the performance of a classifier using RNN.,4.3.1 Classification of Directness,[0],[0]
"If the goal is a large scale application, the necessary amount of labelled data might be difficult to achieve.",4.3.1 Classification of Directness,[0],[0]
Future work should therefore consider the possibility of unsupervised training approaches or approaches with better scalability.,4.3.1 Classification of Directness,[0],[0]
"In addition to a larger amount of training data, using the sum of word vectors as additional input greatly improves the performance.",4.3.1 Classification of Directness,[0],[0]
"As a number of extensive word vector models exist for several languages (e.g. (Bojanowski et al., 2016)), this data is easily available irrespective of the scale of the targeted dialogue domain.",4.3.1 Classification of Directness,[0],[0]
Our approach for choosing a valid replacement for an utterance was able to achieves a high accuracy of 0.70 at its best performance.,4.3.2 Exchange of Utterances,[0],[0]
"However, this performance is significantly influenced by both the accuracy of the classifier for the level of directness (F (2, 29.090) = 141.564, p < .001) and the amount of data the DVM was trained on (F (5, 52.864) = 4.304, p < .003).",4.3.2 Exchange of Utterances,[0],[0]
"Depending
on the quality of the employed components, the accuracy ranges from 0.41 to 0.70.",4.3.2 Exchange of Utterances,[0],[0]
"A graphical representation can be found in Figure 5.
",4.3.2 Exchange of Utterances,[0],[0]
"The results show the high potential of our approach, but also emphasize the importance of both a good classifier to estimate the level of directness and a good measure of the functional similarity of utterances.",4.3.2 Exchange of Utterances,[0],[0]
"If either component under performs, the accuracy declines to undesirable levels.",4.3.2 Exchange of Utterances,[0],[0]
DVMs depend on a large amount of data being available.,4.3.2 Exchange of Utterances,[0],[0]
"However, this data does not need to be annotated.",4.3.2 Exchange of Utterances,[0],[0]
"Hence, suitable DVMs for our approach can be trained with the amount of data usually available to big companies.",4.3.2 Exchange of Utterances,[0],[0]
"Training a good classifier presents a more severe challenge, as annotated data is needed.",4.3.2 Exchange of Utterances,[0],[0]
An unsupervised approach to the training of a classifier for the level of directness would therefore be highly beneficial for the viability of our approach.,4.3.2 Exchange of Utterances,[0],[0]
The evaluation of our approach yields promising results and shows its high potential.,4.4 Limitations of the Evaluation,[0],[0]
"However, we need to take into account that those results were achieved using an artificially generated corpus.",4.4 Limitations of the Evaluation,[0],[0]
"Furthermore, we tested the performance of our approach in a theoretical setting, not its impact in an actual application.",4.4 Limitations of the Evaluation,[0],[0]
"This section discusses the limitations of our evaluation.
",4.4 Limitations of the Evaluation,[0],[0]
"Natural dialogue possess a greater variability than automatically generated dialogue, and therefore finding reliable patterns in them is a more difficult task.",4.4 Limitations of the Evaluation,[0],[0]
It is likely that the quality of both the classifier and the DVMs decreases if they are trained on a comparable amount of natural dialogue data compared to artificially generated data.,4.4 Limitations of the Evaluation,[0],[0]
We could show in the evaluation that the quality of the classifier and DVM has a major impact on the performance of our approach.,4.4 Limitations of the Evaluation,[0],[0]
"This implies that more data is needed for natural dialogues than for automatically generated dialogues to achieve comparable results.
",4.4 Limitations of the Evaluation,[0],[0]
One of the main reasons to use an automatically generated dialogue corpus was to ensure the presence of pairs of direct and indirect utterances.,4.4 Limitations of the Evaluation,[0],[0]
"This is important not only for the training of the classifier and DVM, but also to ensure that a suitable substitute is known.",4.4 Limitations of the Evaluation,[0],[0]
"As our approach searches for a replacement in a set of established utterances, it can only be successful if the set does contain a suitable utterance.",4.4 Limitations of the Evaluation,[0],[0]
"While the likelihood for the
presence of a suitable substitute increases with the size of the dialogue corpus, it cannot be guaranteed that a replacement is present in natural dialogues.",4.4 Limitations of the Evaluation,[0],[0]
"When transferring our approach to actual applications, this might present a challenge.",4.4 Limitations of the Evaluation,[0],[0]
"To address this challenge, the generation of suitable utterances rather than their identification should be investigated.
",4.4 Limitations of the Evaluation,[0],[0]
"While our evaluation shows what accuracy our approach can achieve given different circumstances, we did not yet investigate what accuracy it needs to achieve in actual applications to positively impact the user experience.",4.4 Limitations of the Evaluation,[0],[0]
"Without this information, it is difficult to estimate which level of accuracy should be targeted and, as a consequence, the amount of training data needed.",4.4 Limitations of the Evaluation,[0],[0]
"In this work, we introduced an approach to exchange utterances that express the same meaning in the dialogue, but possess a differing level of directness.",5 Conclusion,[0],[0]
"In this endeavour, we utilised supervised training with RNNs for the estimation of directness levels, and DVMs as basis for the similarity measure of the meaning of two utterances in a dialogue.",5 Conclusion,[0],[0]
"A dialogue corpus that provides a sufficient amount of direct/indirect utterance pairs as well as annotations of the dialogue act and level of directness was generated automatically and utilised to show the high potential of our approach in an evaluation.
",5 Conclusion,[0],[0]
"Although the results seem promising overall, we identified several challenges that need to be addressed in future work.",5 Conclusion,[0],[0]
The chosen classifier for the level of directness relies on a large amount of annotated data.,5 Conclusion,[0],[0]
Unsupervised learning approaches will be investigated to eliminate this need.,5 Conclusion,[0],[0]
Our evaluation did not incorporate the variability of natural dialogues.,5 Conclusion,[0],[0]
We will test our approach on natural dialogues to verify its applicability on more noisy data than an automatically generated corpus provides.,5 Conclusion,[0],[0]
"Furthermore, the presence of direct/indirect pairs in natural dialogue corpora cannot be guaranteed.",5 Conclusion,[0],[0]
It might become necessary to explore the generation of suitable utterances if we find that natural dialogue data does not contain a sufficient amount of direct/indirect utterance pairs.,5 Conclusion,[0],[0]
"Finally, the integration of our approach in an actual dialogue systems can confirm its beneficial effects on the user satisfaction.",5 Conclusion,[0],[0]
"In cooperative dialogues, identifying the intent of ones conversation partner and acting accordingly is of great importance.",abstractText,[0],[0]
"While this endeavour is facilitated by phrasing intentions as directly as possible, we can observe in human-human communication that a number of factors such as cultural norms and politeness may result in expressing one’s intent indirectly.",abstractText,[0],[0]
"Therefore, in human-computer communication we have to anticipate the possibility of users being indirect and be prepared to interpret their actual meaning.",abstractText,[0],[0]
"Furthermore, a dialogue system should be able to conform to human expectations by adjusting the degree of directness it uses to improve the user experience.",abstractText,[0],[0]
"To reach those goals, we propose an approach to differentiate between direct and indirect utterances and find utterances of the opposite characteristic that express the same intent.",abstractText,[0],[0]
"In this endeavour, we employ dialogue vector models and recurrent neural networks.",abstractText,[0],[0]
Changing the Level of Directness in Dialogue using Dialogue Vector Models and Recurrent Neural Networks,title,[0],[0]
"Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 2917–2922 Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics",text,[0],[0]
Portmanteaus (or lexical blends Algeo (1977)) are novel words formed from parts of multiple root words in order to refer to a new concept which can’t otherwise be expressed concisely.,1 Introduction,[0],[0]
"Portmanteaus have become frequent in modern-day social media, news reports and advertising, one popular example being Brexit (Britain + Exit).",1 Introduction,[0],[0]
Petri (2012).,1 Introduction,[0],[0]
"These are found not only in English but many other languages such as Bahasa Indonesia Dardjowidjojo (1979), Modern Hebrew BatEl (1996); Berman (1989) and Spanish Piñeros (2004).",1 Introduction,[0],[0]
"Their short length makes them ideal for headlines and brandnames (Gabler, 2015).",1 Introduction,[0],[0]
"Unlike better-defined morphological phenomenon such as inflection and derivation, portmanteau generation
∗* denotes equal contribution
is difficult to capture using a set of rules.",1 Introduction,[0],[0]
"For instance, Shaw et al. (2014) state that the composition of the portmanteau from its root words depends on several factors, two important ones being maintaining prosody and retaining character segments from the root words, especially the head.",1 Introduction,[0],[0]
"An existing work by Deri and Knight (2015) aims to solve the problem of predicting portmanteau using a multi-tape FST model, which is datadriven, unlike prior approaches.",1 Introduction,[0],[0]
"Their methods rely on a grapheme to phoneme converter, which takes into account the phonetic features of the language, but may not be available or accurate for non-dictionary words, or low resource languages.
",1 Introduction,[0],[0]
"Prior works, such as Faruqui et al. (2016), have demonstrated the efficacy of neural approaches for morphological tasks such as inflection.",1 Introduction,[0],[0]
"We hypothesize that such neural methods can (1) provide a simpler and more integrated end-to-end framework than multiple FSTs used in the previous work, and (2) automatically capture features such as phonetic similarity through the use of character embeddings, removing the need for explicit
2917
grapheme-to-phoneme prediction.",1 Introduction,[0],[0]
"To test these hypotheses, in this paper, we propose a neural S2S model to predict portmanteaus given the two root words, specifically making 3 major contributions:
• We propose an S2S model that attends to the two input words to generate portmanteaus, and an additional improvement that leverages noisy-channel-style modelling to incorporate a language model over the vocabulary of words (§2).",1 Introduction,[0],[0]
"• Instead of using the model to directly pre-
dict output character-by-character, we use the features of portmanteaus to exhaustively generate candidates, making scoring using the noisy channel model possible (§3).",1 Introduction,[0],[0]
"• We curate and share a new and larger dataset
of 1624 portmanteaus (§4).",1 Introduction,[0],[0]
"In experiments (§5), our model performs better than the baseline Deri and Knight (2015) on both objective and subjective measures, demonstrating that such methods can be used effectively in a morphological task.",1 Introduction,[0],[0]
This section describes our neural models.,2 Proposed Models,[0],[0]
"Under our first proposed architecture, the input sequence x = concat(x(1), “;”, x(2)), while the output sequence is",2.1 Forward Architecture,[0],[0]
the portmanteau y.,2.1 Forward Architecture,[0],[0]
"The model learns the distribution P (y|x).
",2.1 Forward Architecture,[0],[0]
"The network architecture we use is an attentional S2S model (Bahdanau et al., 2014).",2.1 Forward Architecture,[0],[0]
"We use a bidirectional encoder, which is known to work well for S2S problems with similar token order, which is true in our case.",2.1 Forward Architecture,[0],[0]
Let −−−−→,2.1 Forward Architecture,[0],[0]
"LSTM and ←−−−− LSTM represent the forward and reverse encoder; eenc() and edec() represent the character embedding functions used by encoder and decoder The following equations describe the model:
h −→enc 0",2.1 Forward Architecture,[0],[0]
"= −→ 0 , h ←−enc",2.1 Forward Architecture,[0],[0]
|x|,2.1 Forward Architecture,[0],[0]
= −→ 0 h,2.1 Forward Architecture,[0],[0]
−→enc t = −−−−→,2.1 Forward Architecture,[0],[0]
"LSTM(henct−1, eenc(xt))",2.1 Forward Architecture,[0],[0]
"h ←−enc t = ←−−−− LSTM(henct+1, eenc(xt))",2.1 Forward Architecture,[0],[0]
henct = h,2.1 Forward Architecture,[0],[0]
−→enc t + h ←−enc t hdec0,2.1 Forward Architecture,[0],[0]
"= h enc |x|
hdect = LSTM(h dec t−1, [concat(edec(yt−1), ct−1)])
",2.1 Forward Architecture,[0],[0]
"pt = softmax(Whs[concat(hdect , ct)]",2.1 Forward Architecture,[0],[0]
"+ bs)
",2.1 Forward Architecture,[0],[0]
The context vector ct is computed using dotproduct attention over encoder states.,2.1 Forward Architecture,[0],[0]
"We choose dot-product attention because it doesn’t add extra parameters, which is important in a low-data scenario such as portmanteau generation.
",2.1 Forward Architecture,[0],[0]
"ati = dot(h dec t , h enc i ), α t = softmax(at)
ct = i=|x|∑ i=1",2.1 Forward Architecture,[0],[0]
αtih enc,2.1 Forward Architecture,[0],[0]
"i
",2.1 Forward Architecture,[0],[0]
"In addition to capturing the fact that portmanteaus of two English words typically sound English-like, and to compensate for the fact that available portmanteau data will be small, we pretrain the character embeddings on English language words.",2.1 Forward Architecture,[0],[0]
"We use character embeddings learnt using an LSTM language model over words in an English dictionary,1 where each word is a sequence of characters, and the model will predict next character in sequence conditioned on previous characters in the sequence.",2.1 Forward Architecture,[0],[0]
The second proposed model uses Bayes’s rule to reverse the probabilities P (y|x) = P (x|y)P (y)P (x) to get argmaxy P (y|x) = argmaxy P (x|y)P (y).,2.2 Backward Architecture,[0],[0]
"Thus, we have a reverse model of the probability P (x|y) that the given root words were generated from the portmanteau and a character language model model P (y).",2.2 Backward Architecture,[0],[0]
"This is a probability distribution over all character sequences y ∈ A∗, where A is the alphabet of the language.",2.2 Backward Architecture,[0],[0]
"This way of factorizing the probability is also known as a noisy channel model, which has recently also been shown to be effective for neural MT (Hoang et al. (2017), Yu et al. (2016)).",2.2 Backward Architecture,[0],[0]
"Such a model offers two advantages
1.",2.2 Backward Architecture,[0],[0]
"The reverse direction model (or alignment model) gives higher probability to those portmanteaus from which one can discern the root words easily, which is one feature of good portmanteaus.
2.",2.2 Backward Architecture,[0],[0]
The character language model P (y) can be trained on a large vocabulary of words in the language.,2.2 Backward Architecture,[0],[0]
The likelihood of a word y is factorized as P (y) = Πi=|y|i=1,2.2 Backward Architecture,[0],[0]
"P (yi|yi−11 ), where yij = yi, yi+1 . . .",2.2 Backward Architecture,[0],[0]
"yj , and we train a LSTM to maximize this likelihood.
",2.2 Backward Architecture,[0],[0]
"1 Specifically in our experiments, 134K words from the CMU dictionary (Weide, 1998).",2.2 Backward Architecture,[0],[0]
"Given these models, we must make predictions, which we do by two methods
Greedy Decoding: In most neural sequenceto-sequence models, we perform autoregressive greedy decoding, selecting the next character greedily based on the probability distribution for the next character at current time step.",3 Making Predictions,[0],[0]
"We refer to this decoding strategy as GREEDY.
Exhaustive Generation: Many portmanteaus were observed to be concatenation of a prefix of the first word and a suffix of the second.",3 Making Predictions,[0],[0]
We therefore generate all candidate outputs which follow this rule.,3 Making Predictions,[0],[0]
Thereafter we score these candidates with the decoder and output the one with the maximum score.,3 Making Predictions,[0],[0]
"We refer to this decoding strategy as SCORE.
",3 Making Predictions,[0],[0]
"Given that our training data is small in size, we expect ensembling (Breiman, 1996) to help reduce model variance and improve performance.",3 Making Predictions,[0],[0]
"In this paper, we ensemble our models wherever mentioned by training multiple models on 80% subsamples of the training data, and averaging log probability scores across the ensemble at test-time.",3 Making Predictions,[0],[0]
The existing dataset by Deri and Knight (2015) contains 401 portmanteau examples from Wikipedia.,4 Dataset,[0],[0]
We refer to this dataset as DWiki.,4 Dataset,[0],[0]
"Besides being small for detailed evaluation, DWiki is biased by being from just one source.",4 Dataset,[0],[0]
"We manually collect DLarge, a dataset of 1624 distinct English portmanteaus from following sources:
• Urban Dictionary2 • Wikipedia • Wiktionary • BCU’s Neologism Lists from ’94 to ’12.
",4 Dataset,[0],[0]
"Naturally, DWiki ⊂ DLarge.",4 Dataset,[0],[0]
We define DBlind = DLarge−DWiki as the dataset of 1223 examples not from Wikipedia.,4 Dataset,[0],[0]
"We observed that 84.7% of the words in DLarge can be generated by concatenating prefix of first word with a suffix of the second.
",4 Dataset,[0],[0]
"2Not all neologisms are portmanteaus, so we manually choose those which are for our dataset.",4 Dataset,[0],[0]
"In this section, we show results comparing various configurations of our model to the baseline FST model of Deri and Knight (2015) (BASELINE).",5 Experiments,[0],[0]
Models are evaluated using exactmatches (Matches) and average Levenshtein editdistance (Distance) w.r.t ground truth.,5 Experiments,[0],[0]
"In Experiment 1, we follow the same setup as Deri and Knight (2015).",5.1 Objective Evaluation Results,[0],[0]
DWiki is split into 10 folds.,5.1 Objective Evaluation Results,[0],[0]
"Each fold model uses 8 folds for training, 1 for validation, and 1 for test.",5.1 Objective Evaluation Results,[0],[0]
The average (10 fold crossvalidation style approach) performance metrics on the test fold are then evaluated.,5.1 Objective Evaluation Results,[0],[0]
Table 1 shows the results of Experiment 1 for various model configurations.,5.1 Objective Evaluation Results,[0],[0]
We get the BASELINE numbers from Deri and Knight (2015).,5.1 Objective Evaluation Results,[0],[0]
"Our best model obtains 48.75% Matches and 1.12 Distance, compared to 45.39% Matches and 1.59 Distance using BASELINE.
",5.1 Objective Evaluation Results,[0],[0]
"For Experiment 2, we seek to compare our best approaches from Experiment 1 to the BASELINE on a large, held-out dataset.",5.1 Objective Evaluation Results,[0],[0]
Each model is trained on DWiki and tested on DBlind.,5.1 Objective Evaluation Results,[0],[0]
"BASELINE was similarly trained only on DWiki , making it a fair comparison.",5.1 Objective Evaluation Results,[0],[0]
Table 2 shows the results3.,5.1 Objective Evaluation Results,[0],[0]
"Our best model gets Distance of 1.96 as compared to 2.32 from BASELINE.
",5.1 Objective Evaluation Results,[0],[0]
"We observe that the Backward architecture performs better than Forward architecture, confirming our hypothesis in §2.2.",5.1 Objective Evaluation Results,[0],[0]
"In addition, ablation results confirm the importance of attention, and
3For BASELINE (Deri and Knight, 2015), we use their trained model from http://leps.isi.edu/fst/ step-all.php
initializing the word embeddings.",5.1 Objective Evaluation Results,[0],[0]
"We believe this is because portmanteaus have high fidelity towards their root word characters and its critical that the model can observe all root sequence characters, which attention manages to do as shown in Fig. 2.",5.1 Objective Evaluation Results,[0],[0]
The set of candidates generated before scoring in the approximate SCORE decoding approach sometimes do not cover the ground truth.,5.1.1 Performance on Uncovered Examples,[0],[0]
This holds true for 229 out of 1223 examples in DBlind.,5.1.1 Performance on Uncovered Examples,[0],[0]
"We compare the FORWARD approach along with a GREEDY decoding strategy to the BASELINE approach for these examples.
",5.1.1 Performance on Uncovered Examples,[0],[0]
Both FORWARD+GREEDY and the BASELINE get 0 Matches on these examples.,5.1.1 Performance on Uncovered Examples,[0],[0]
The Distance for these examples is 4.52 for BASELINE and 4.09 for FORWARD+GREEDY.,5.1.1 Performance on Uncovered Examples,[0],[0]
"Hence, we see that one of our approaches (FORWARD+GREEDY) outperforms BASELINE even for these examples.",5.1.1 Performance on Uncovered Examples,[0],[0]
"Since our dataset is still small relatively small (1223 examples), it is essential to verify whether BACKWARD is indeed statistically significantly better than BASELINE in terms of Matches.
",5.2 Significance Tests,[0],[0]
"In order to do this, we use a paired bootstrap4 comparison (Koehn, 2004) between BACKWARD and BASELINE in terms of Matches.",5.2 Significance Tests,[0],[0]
"BACKWARD is found to be better (gets more Matches) than BASELINE in 99.9% (p = 0.999) of the subsets.
",5.2 Significance Tests,[0],[0]
"Similarly, BACKWARD has a lower Distance than BASELINE by a margin of 0.2 in 99.5% (p = 0.995) of the subsets.",5.2 Significance Tests,[0],[0]
"On inspecting outputs, we observed that often output from our system seemed good in spite of high edit distance from ground truth.",5.3 Subjective Evaluation and Analysis,[0],[0]
Such aspect of an output seeming good is not captured satisfactorily by measures like edit distance.,5.3 Subjective Evaluation and Analysis,[0],[0]
"To compare the errors made by our model to the baseline, we designed and conducted a human evaluation task on AMT.5",5.3 Subjective Evaluation and Analysis,[0],[0]
"In the survey, we show human annotators outputs from our system and that of the baseline.",5.3 Subjective Evaluation and Analysis,[0],[0]
We ask them to judge which alternative is better overall based on following criteria: 1.,5.3 Subjective Evaluation and Analysis,[0],[0]
It is a good shorthand for two original words 2.,5.3 Subjective Evaluation and Analysis,[0],[0]
It sounds better.,5.3 Subjective Evaluation and Analysis,[0],[0]
We requested annotation on a scale of 1-4.,5.3 Subjective Evaluation and Analysis,[0],[0]
"To avoid ordering bias, we shuffled the order of two portmanteau between our system and that of baseline.",5.3 Subjective Evaluation and Analysis,[0],[0]
"We restrict annotators to be from Anglophone countries, have HIT Approval Rate > 80% and pay 0.40$ per HIT (5 Questions per HIT).
",5.3 Subjective Evaluation and Analysis,[0],[0]
"As seen in Table 4, output from our system was labelled better by humans as compared to the baseline 58.12% of the time.",5.3 Subjective Evaluation and Analysis,[0],[0]
"Table 3 shows outputs from different models for a few examples.
",5.3 Subjective Evaluation and Analysis,[0],[0]
"4We average across M = 1000 randomly chosen subsets of DBlind, each of size N = 611 (",5.3 Subjective Evaluation and Analysis,[0],[0]
"≈ 1223/2)
5We avoid ground truth comparison because annotators can be biased to ground truth due to its existing popularity.",5.3 Subjective Evaluation and Analysis,[0],[0]
Özbal and Strapparava (2012) generate new words to describe a product given its category and properties.,6 Related Work,[0],[0]
"However, their method is limited to handcrafted rules as compared to our data driven approach.",6 Related Work,[0],[0]
"Also, their focus is on brand names.",6 Related Work,[0],[0]
Hiranandani et al. (2017) have proposed an approach to recommend brand names based on brand/product description.,6 Related Work,[0],[0]
"However, they consider only a limited number of features like memorability and readability.",6 Related Work,[0],[0]
"Smith et al. (2014) devise an approach to generate portmanteaus, which requires user-defined weights for attributes like sounding good.",6 Related Work,[0],[0]
Generating a portmanteau from two root words can be viewed as a S2S problem.,6 Related Work,[0],[0]
"Recently, neural approaches have been used for S2S problems (Sutskever et al., 2014) such as MT.",6 Related Work,[0],[0]
Ling et al. (2015) and Chung et al. (2016) have shown that character-level neural sequence models work as well as word-level ones for language modelling and MT.,6 Related Work,[0],[0]
"Zoph and Knight (2016) propose S2S models for multi-source MT, which have multi-sequence inputs, similar to our case.",6 Related Work,[0],[0]
We have proposed an end-to-end neural system to model portmanteau generation.,7 Conclusion,[0],[0]
Our experiments show the efficacy of proposed system in predicting portmanteaus given the root words.,7 Conclusion,[0],[0]
We conclude that pre-training character embeddings on the English vocabulary helps the model.,7 Conclusion,[0],[0]
Through human evaluation we show that our model’s predictions are superior to the baseline.,7 Conclusion,[0],[0]
We have also released our dataset and code6 to encourage further research on the phenomenon of portmanteaus.,7 Conclusion,[0],[0]
We also release an online demo 7 where our trained model can be queried for portmanteau suggestions.,7 Conclusion,[0],[0]
An obvious extension to our work is to try similar models on multiple languages.,7 Conclusion,[0],[0]
"We thank Dongyeop Kang, David Mortensen, Qinlan Shen and anonymous reviewers for their valuable comments.",Acknowledgements,[0],[0]
"This research was supported in part by DARPA grant FA8750-12-20342 funded under the DEFT program.
",Acknowledgements,[0],[0]
"6https://github.com/vgtomahawk/ Charmanteau-CamReady
7http://tinyurl.com/y9x6mvy",Acknowledgements,[0],[0]
Portmanteaus are a word formation phenomenon where two words are combined to form a new word.,abstractText,[0],[0]
"We propose character-level neural sequence-tosequence (S2S) methods for the task of portmanteau generation that are end-toend-trainable, language independent, and do not explicitly use additional phonetic information.",abstractText,[0],[0]
"We propose a noisy-channelstyle model, which allows for the incorporation of unsupervised word lists, improving performance over a standard sourceto-target model.",abstractText,[0],[0]
This model is made possible by an exhaustive candidate generation strategy specifically enabled by the features of the portmanteau task.,abstractText,[0],[0]
Experiments find our approach superior to a state-of-the-art FST-based baseline with respect to ground truth accuracy and human evaluation.,abstractText,[0],[0]
CharManteau: Character Embedding Models For Portmanteau Creation,title,[0],[0]
"Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 358–363, Baltimore, Maryland, USA, June 23-25 2014. c©2014 Association for Computational Linguistics",text,[0],[0]
"Imagine that you were working on a draft paper which contained a sentence like the following:1
A variety of coherence theories have been developed over the years ... and their principles have found application in many symbolic text generation systems (e.g. [CITATION HERE])
",1 Introduction,[0],[0]
Wouldn’t it be helpful if your editor automatically suggested some references that you could cite here?,1 Introduction,[0],[0]
This is what a citation recommendation system ought to do.,1 Introduction,[0],[0]
"If the system is able to take into account the context in which the citation occurs — for example, that papers relevant to our example above are not only about text generation
1Adapted from the introduction to Barzilay and Lapata (2008)
systems, but specifically mention applying coherence theories — then this would be much more informative.",1 Introduction,[0],[0]
"So we define a context-based citation recommendation (CBCR) system as one that assists the author of a draft document by suggesting other documents with content that is relevant to a particular context in the draft.
",1 Introduction,[0],[0]
"Our longer term research goal is to provide suggestions that satisfy the requirements of specific expository or rhetorical tasks, e.g. provide support for a particular argument, acknowledge previous work that uses the same methodology, or exemplify work that would benefit from the outcomes of the author’s work.",1 Introduction,[0],[0]
"However, our current paper has more modest aims: we present initial results using existing IR-based approaches and we introduce an evaluation method and metric.",1 Introduction,[0],[0]
"CBCR systems are not yet widely available, but a number of experiments have been carried out that may pave the way for their popularisation, e.g. He et al. (2010), Schäfer and Kasterka (2010) and He et al. (2012).",1 Introduction,[0],[0]
"It is within this early wave of experiments that our work is framed.
",1 Introduction,[0],[0]
A main problem we face is that evaluating the performance of these systems ultimately requires human judgement.,1 Introduction,[0],[0]
"This can be captured as a set of relevance judgements for candidate citations over a corpus of documents, which is an arduous effort that requires considerable manual input and very careful preparation.",1 Introduction,[0],[0]
"In designing a contextbased citation recommendation system, we would ideally like to minimise these costs.
",1 Introduction,[0],[0]
"Fortunately there is already an abundance of data that meets our requirements: every scientific paper contains human “judgements” in the form of citations to other papers which are contextually appropriate: that is, relevant to specific passages of the document and aligned with its argumentative structure.",1 Introduction,[0],[0]
"Citation Resolution is a method for evaluating CBCR systems that is exclusively based on this source of human judgements.
",1 Introduction,[0],[0]
"358
Let’s define some terminology.",1 Introduction,[0],[0]
"In the following passage, the strings ‘Scott and de Souza, 1990’ and ‘Kibble and Power, 2004’ are both citation tokens:
A variety of coherence theories have been developed over the years ... and their principles have found application in many symbolic text generation systems (e.g. Scott and de Souza, 1990; Kibble and Power, 2004)
",1 Introduction,[0],[0]
Note that a citation token can use any standard format.,1 Introduction,[0],[0]
"Furthermore
• a citation context is the context in which a citation token occurs, with no limit as to representation of this context, length or processing involved; • a collection-internal reference is a reference in the bibliography of the source document that matches a document in a given corpus; • a resolvable citation is an in-text citation token which resolves to a collection-internal reference.",1 Introduction,[0],[0]
"While the existing work in this specific area is far from extensive, previous experiments in evaluating context-based citation recommendation systems have used one of three approaches.",2 Related work,[0],[0]
"First, evaluation can be carried out through user studies, which is costly because it cannot be reused (e.g. Chandrasekaran et al. (2008)).
",2 Related work,[0],[0]
"Second, a set of relevance judgements can be created for repeated testing.",2 Related work,[0],[0]
Ritchie (2009) details the building of a large set of relevance judgements in order to evaluate an experimental document retrieval system.,2 Related work,[0],[0]
"The judgements were mainly provided by the authors of papers submitted to a locally organised conference, for over 140 queries, each of them being the main research question of one paper.",2 Related work,[0],[0]
"This is a standard approach in IR, known as building a test collection (Sanderson, 2010), which the author herself notes was an arduous and time-consuming task.
",2 Related work,[0],[0]
"Third, as we outlined above, existing citations between papers can be exploited as a source of human judgements.",2 Related work,[0],[0]
"The most relevant previous work on this is He et al. (2010), who built an experimental CBCR system using the whole index of CiteSeerX as a test collection (over 450,000 documents).",2 Related work,[0],[0]
"They avoided direct human evaluation and instead used three relevance metrics:
• Recall, the presence of the original reference in the list of suggestions generated by the system; • Co-cited probability, a ratio between, on the one hand, the number of papers citing both the original reference and a recommended one, and on the other hand, the number of papers citing either of them; and • Normalized Discounted Cumulative Gain, a measure based on the rank of the original reference in the list of suggested references, its score decreasing logarithmically.
",2 Related work,[0],[0]
"However, these metrics fail to adequately recognise that the particular reference used by an author e.g. in support of an argument or as exemplification of an approach, may not be the most appropriate that could be found in the whole collection.",2 Related work,[0],[0]
"This does not just amount to a difference of opinion between different authors; it is possible that within a large enough collection there exists a paper which the original author herself would consider to be more appropriate by any criteria (persuasive power, discoverability or the publication, etc.)",2 Related work,[0],[0]
than the one actually cited in the paper.,2 Related work,[0],[0]
"Also, given that recommending the original citation used by the author in first position is our key criterion, a metric with smooth discounting like NDCG is too lenient for our purposes.
",2 Related work,[0],[0]
"We have then chosen top-1 accuracy as our metric, where every time the original citation is first on the list of suggestions, it receives a score of 1, and 0 otherwise, and these scores are averaged over all resolved citations in the document collection.",2 Related work,[0],[0]
"This metric is intuitive in measuring the efficiency of the system at this task, as it is immediately interpretable as a percentage of success.
",2 Related work,[0],[0]
"While previous experiments in CBCR, like the ones we have just presented, have treated the task as an Information Retrieval problem, our ultimate purpose is different and travels beyond IR into Question Answering.",2 Related work,[0],[0]
"We want to ultimately be able to assess the reason a document was cited in the context of the argumentation structure of the document, following previous work on the automatic classification of citation function by Teufel et al. (2006), Liakata et al. (2012) and Schäfer and Kasterka (2010).",2 Related work,[0],[0]
"We expect this will allow us to identify claims made in a draft paper and match them with related claims made in other papers for support or contrast, and so offer answers in the form of relevant passages extracted from the sug-
gested documents.",2 Related work,[0],[0]
"It is frequently observed that the reasons for citing a paper go beyond its contribution to the field and its relevance to the research being reported (Hyland, 2009).",2 Related work,[0],[0]
"There is a large body of research on the motivations behind citing documents (MacRoberts and MacRoberts, 1996), and it is likely that this will come to play a part in our research in the future.
",2 Related work,[0],[0]
"In this paper, however, we present our initial results which compare three different sets of IRbased approaches to generating the document representation for a CBCR system.",2 Related work,[0],[0]
"One is based on the contents of the document itself, one is based on the existing contexts of citations of this paper in other documents, and the third is a mixture of the two.",2 Related work,[0],[0]
"In this section we present the evaluation method in more abstract terms; for the implementation used in this paper, please see Sections 4 and 5.",3 The task: Citation Resolution,[0],[0]
The core criterion of this task is to use only the human judgements that we have clearest evidence for.,3 The task: Citation Resolution,[0],[0]
Let d be a document and R the collection of all documents that are referenced in d.,3 The task: Citation Resolution,[0],[0]
"We believe it is reasonable to assume that the author of document d knows enough about the contents of each document Ri to choose the most appropriate citation from the collection R for every citation context in the document.
",3 The task: Citation Resolution,[0],[0]
This captures a very strong relevance judgement about the relation between a particular citation context in the document and a particular cited reference document.,3 The task: Citation Resolution,[0],[0]
"We use these judgements for evaluation: our task is to match every citation context in the document (i.e. the surrounding context of a citation token) with the right reference from the list of references cited by that paper.
",3 The task: Citation Resolution,[0],[0]
"This task differs somewhat from standard Information Retrieval, in that we are not trying to retrieve a document from a larger collection outside the source document, but trying to resolve the correct reference for a given citation context from an existing list of documents, that is, from the bibliography that has been manually curated by the authors.",3 The task: Citation Resolution,[0],[0]
"Our document collection used for retrieval is further composed of only the references of that document that we can access.
",3 The task: Citation Resolution,[0],[0]
The algorithm for the task is presented in Figure 1.,3 The task: Citation Resolution,[0],[0]
"For any given test document (2), we first extract
all the citation tokens found in the text that correspond to a collection-internal reference (a).",3 The task: Citation Resolution,[0],[0]
"We then create a document representation of the referenced document (currently a Vector Space Model, but liable to change).",3 The task: Citation Resolution,[0],[0]
"This representation can be based on any information found in the document collection, excluding the document d itself: e.g. the text of the referenced document and the text of documents that cite it.
",3 The task: Citation Resolution,[0],[0]
"For each citation token we then extract its context (b.i), which becomes the query in IR terms.",3 The task: Citation Resolution,[0],[0]
One way of doing this that we present here is to select a list of word tokens around the citation.,3 The task: Citation Resolution,[0],[0]
We then attempt to resolve the citation by computing a score for the match between each reference representation and the citation context (b.ii).,3 The task: Citation Resolution,[0],[0]
"We rank all collection-internal references by this score in decreasing order, aiming for the original reference to be in the first position (b.iii).
",3 The task: Citation Resolution,[0],[0]
"In the case where multiple citations share the same context, that is, they are made in direct succession (e.g. “...compared with previous approaches (Author (2005), Author and Author (2007))”), the first n elements of the list of suggested documents all count as the first element.",3 The task: Citation Resolution,[0],[0]
"That is, if any of the references in a multiple citation of n elements appears in the first n positions of the list of suggestions, it counts as a successful resolution and receives a score of 1.",3 The task: Citation Resolution,[0],[0]
"The final score is averaged over all citation contexts processed.
",3 The task: Citation Resolution,[0],[0]
The set of experiments we present here apply this evaluation to test a number of IR techniques which we detail in the next section.,3 The task: Citation Resolution,[0],[0]
Our test corpus consists of approx.,4 Experiments,[0],[0]
"9000 papers from the ACL Anthology 2 converted from PDF to
2http://http://aclweb.org/anthology/
XML format.",4 Experiments,[0],[0]
"This corpus, the rationale behind its selection and the process used to convert the files is described in depth in Ritchie et al. (2006).",4 Experiments,[0],[0]
"This is an ideal corpus for these tests for a large number of reasons, but these are key for us: all the papers are freely available, the ratio of collection-internal references for each paper is high (the authors measure it at 0.33) and it is a familiar domain for us.
",4 Experiments,[0],[0]
"For our tests, we selected the documents of this corpus with at least 8 collection-internal references.",4 Experiments,[0],[0]
"This yielded a total of 278 test documents and a total of 5446 resolvable citations.
",4 Experiments,[0],[0]
We substitute all citations in the text with citation token placeholders and extract the citation context for each using a simple window of up to w words left and w words right around the placeholder.,4 Experiments,[0],[0]
"This produces a list of word tokens that is equivalent to a query in IR.
",4 Experiments,[0],[0]
"This is a frequently employed technique (He et al., 2010), although it is often observed that this may be too simplistic a method (Ritchie, 2009).",4 Experiments,[0],[0]
"Other methods have been tried, e.g. full sentence extraction (He et al., 2012) and comparing these methods is something we plan to incorporate in future work.
",4 Experiments,[0],[0]
We then make the document’s collectioninternal references our test collection D and use a number of methods for generating the document representation.,4 Experiments,[0],[0]
We use the well-known Vector Space Model and a standard implementation of tfidf and cosine similarity as implemented by the scikit-learn Python framework 3.,4 Experiments,[0],[0]
"At present, we are applying no cut-off and just rank all of the document’s collection-internal references for each citation context, aiming to rank the correct one in the first positions in the list.
",4 Experiments,[0],[0]
"We tested three different approaches to generating a document’s VSM representation: internal representations, which are based on the contents of the document, external representations, which are built using a document’s incoming link citation contexts (following Ritchie (2009) and He et al. (2010)) and mixed representations, which are an attempt to combine the two.",4 Experiments,[0],[0]
•,4 Experiments,[0],[0]
"The internal representations of the documents
were generated using three different methods: title plus abstract, full text and passage.",4 Experiments,[0],[0]
"Passage consists in splitting the document into half-overlapping passages of a fixed length of k words and choosing for each document the
3http://scikit-learn.org
passage with the maximum cosine similarity score with the query.",4 Experiments,[0],[0]
"We present the results of using 250, 300 and 350 as values for k. •",4 Experiments,[0],[0]
"The external representations (inlink context) are based on extracting the context around citation tokens to the document from other documents in the collection, excluding the set of test papers.",4 Experiments,[0],[0]
This is the same as using the anchor text of a hyperlink to improve results in web-based IR (see Davison (2000) for extensive analyis).,4 Experiments,[0],[0]
"This context is extracted in the same way as the query: as a window, or list of w tokens surrounding the citation left and right.",4 Experiments,[0],[0]
"We present our best results, using symmetrical and asymmetrical windows of w =",4 Experiments,[0],[0]
"[(5, 5), (10, 10), (10, 5), (20, 20), (30, 30)].",4 Experiments,[0],[0]
"• We build the mixed representations by simply concatenating the internal and external bagsof-words that represent the documents, from which we then build the VSM representation.",4 Experiments,[0],[0]
"For this, we combine different window sizes for the inlink context with: full text, title abstract and passage350.",4 Experiments,[0],[0]
"Table 1 presents a selection of the most relevant results, where the best result and document representation method of each type is highlighted.",5 Results and discussion,[0],[0]
"We present results for the most relevant parameter values, producing the highest scores of all those tested.
",5 Results and discussion,[0],[0]
"From a close look at internal methods, we can see that the passage method with k = 400 beats both full text and title abstract, suggesting that a more elaborate way of building a document representation should improve results.",5 Results and discussion,[0],[0]
This is consistent with previous findings: Gay et al. (2005) had already reported that using selected sections plus captions of figures and title and abstract to build the internal document representation improves the results of their indexing task by 7.4% over just using title and abstract.,5 Results and discussion,[0],[0]
"Similarly, Jimeno-Yepes et al. (2013) showed that automatically generated summaries lead to similar recall and better indexing precision than full-text articles for a keywordbased indexing task.
",5 Results and discussion,[0],[0]
"However, it is immediately clear that purely external methods obtain higher scores than internal ones.",5 Results and discussion,[0],[0]
"The best score of 0.413 is obtained by the inlink context method with a window of 10 tokens left, 5 right, combined with the similarly-sized ex-
traction method for the query (window10 10).",5 Results and discussion,[0],[0]
"We find it remarkable that inlink context is superior to internal methods, beating the best (passage400) by 0.02 absolute accuracy points.",5 Results and discussion,[0],[0]
"Whether this is because the descriptions of these papers in the contexts of incoming link citations capture the essence or key relevance of the paper, or whether this effect is due to authors reusing their work or to these descriptions originating in a seed paper and being then propagated through the literature, remain interesting research questions that we intend to tackle in future work.
",5 Results and discussion,[0],[0]
The key finding from our experiments is however that a mixture of internal and external methods beats both individually.,5 Results and discussion,[0],[0]
"The highest score is 0.469, achieved by a combination of inlink context 20 and the passage method, for a window of w = 20, with a tie between using 250 and 350 as values for k (passage size).",5 Results and discussion,[0],[0]
"The small difference in score between parameter values is perhaps not as relevant as the finding that, taken together, mixed methods consistently beat both external and internal methods.
",5 Results and discussion,[0],[0]
"These results also show that the task is far from solved, with the highest accuracy achieved being just under 47%.",5 Results and discussion,[0],[0]
"There is clear room for improvement, which we believe could firstly come from a more targeted extraction of text, both for generating the document representations and for extracting the citation contexts.
",5 Results and discussion,[0],[0]
"Our ultimate goal is matching claims and comparing methods, which would likely benefit from an analysis of the full contents of the document and not just previous citations of it, so in future work we also intend to use the context from the
successful external results as training data for a summarisation stage.",5 Results and discussion,[0],[0]
In this paper we have presented Citation Resolution: an evaluation method for context-based citation recommendation (CBCR) systems.,6 Conclusion and future work,[0],[0]
"Our method exploits the implicit human relevance judgements found in existing scientific articles and so does not require purpose-specific human annotation.
",6 Conclusion and future work,[0],[0]
"We have employed Citation Resolution to test three approaches to building a document representation for a CBCR system: internal (based on the contents of the document), external (based on the surrounding contexts to citations to that document) and mixed (a mixture of the two).",6 Conclusion and future work,[0],[0]
"Our evaluation shows that: 1) using chunks of a document (passages) as its representation yields better results that using its full text, 2) external methods obtain higher scores than internal ones, and 3) mixed methods yield better results than either in isolation.
",6 Conclusion and future work,[0],[0]
We intend to investigate more sophisticated ways of document representation and of extracting a citation’s context.,6 Conclusion and future work,[0],[0]
"Our ultimate goal is not just to suggest to the author documents that are “relevant” to a specific chunk of the paper (sentence, paragraph, etc.), but to do so with attention to rhetorical structure and thus to citation function.",6 Conclusion and future work,[0],[0]
We also aim to apply our evaluation to other document collections in different scientific domains in order to test to what degree these results can be generalized.,6 Conclusion and future work,[0],[0]
Wouldn’t it be helpful if your text editor automatically suggested papers that are relevant to your research?,abstractText,[0],[0]
Wouldn’t it be even better if those suggestions were contextually relevant?,abstractText,[0],[0]
In this paper we name a system that would accomplish this a context-based citation recommendation (CBCR) system.,abstractText,[0],[0]
"We specifically present Citation Resolution, a method for the evaluation of CBCR systems which exclusively uses readily-available scientific articles.",abstractText,[0],[0]
"Exploiting the human judgements that are already implicit in available resources, we avoid purpose-specific annotation.",abstractText,[0],[0]
"We apply this evaluation to three sets of methods for representing a document, based on a) the contents of the document, b) the surrounding contexts of citations to the document found in other documents, and c) a mixture of the two.",abstractText,[0],[0]
Citation Resolution: A method for evaluating context-based citation recommendation systems,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 355–364 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics",text,[0],[0]
"Sequence to sequence models are usually trained with a simple token-level likelihood loss (Sutskever et al., 2014; Bahdanau et al., 2014).",1 Introduction,[0],[0]
"However, at test time, these models do not produce a single token but a whole sequence.",1 Introduction,[0],[0]
"In order to resolve this inconsistency and to potentially improve generation, recent work has focused on training these models at the sequence-level, for instance using REINFORCE (Ranzato et al., 2015), actor-critic (Bahdanau et al., 2016), or with beam search optimization (Wiseman and Rush, 2016).
",1 Introduction,[0],[0]
"Before the recent work on sequence level training for neural networks, there has been a large body of research on training linear models at the
∗Equal contribution.",1 Introduction,[0],[0]
"1An implementation of the losses is available as part of fairseq at https://github.com/ facebookresearch/fairseq-py/tree/ classic_seqlevel
sequence level.",1 Introduction,[0],[0]
"For example, direct loss optimization has been popularized in machine translation with the Minimum Error Rate Training algorithm (MERT; Och 2003) and expected risk minimization has an extensive history in NLP (Smith and Eisner, 2006; Rosti et al., 2010; Green et al., 2014).",1 Introduction,[0],[0]
"This paper revisits several objective functions that have been commonly used for structured prediction tasks in NLP (Gimpel and Smith, 2010) and apply them to a neural sequence to sequence model (Gehring et al., 2017b) (§2).",1 Introduction,[0],[0]
"Specifically, we consider likelihood training at the sequencelevel, a margin loss as well as expected risk training.",1 Introduction,[0],[0]
We also investigate several combinations of global losses with token-level likelihood.,1 Introduction,[0],[0]
"This is, to our knowledge, the most comprehensive comparison of structured losses in the context of neural sequence to sequence models (§3).
",1 Introduction,[0],[0]
"We experiment on the IWSLT’14 GermanEnglish translation task (Cettolo et al., 2014) as well as the Gigaword abstractive summarization task (Rush et al., 2015).",1 Introduction,[0],[0]
We achieve the best reported accuracy to date on both tasks.,1 Introduction,[0],[0]
"We find that the sequence level losses we survey perform similarly to one another and outperform beam search optimization (Wiseman and Rush, 2016) on a comparable setup.",1 Introduction,[0],[0]
"On WMT’14 English-French, we also illustrate the effectiveness of risk minimization on a larger translation task.",1 Introduction,[0],[0]
"Classical losses for structured prediction are still very competitive and effective for neural models (§5, §6).",1 Introduction,[0],[0]
"The general architecture of our sequence to sequence models follows the encoder-decoder approach with soft attention first introduced in (Bahdanau et al., 2014).",2 Sequence to Sequence Learning,[0],[0]
"As a main difference, in most of our experiments we parameterize the encoder and the decoder as convolutional neural
355
networks instead of recurrent networks (Gehring et al., 2017a,b).",2 Sequence to Sequence Learning,[0],[0]
Our use of convolution is motivated by computational and accuracy considerations.,2 Sequence to Sequence Learning,[0],[0]
"However, the objective functions we present are model agnostic and equally applicable to recurrent and convolutional models.",2 Sequence to Sequence Learning,[0],[0]
We demonstrate the applicability of our objective functions to recurrent models (LSTM) in our comparison to Wiseman and Rush (2016) in §6.6.,2 Sequence to Sequence Learning,[0],[0]
Notation.,2 Sequence to Sequence Learning,[0],[0]
"We denote the source sentence as x, an output sentence of our model as u, and the reference or target sentence as t. For some objectives, we choose a pseudo reference u∗ instead, such as a model output with the highest BLEU or ROUGE score among a set of candidate outputs, U , generated by our model.
",2 Sequence to Sequence Learning,[0],[0]
"Concretely, the encoder processes a source sentence x = (x1, . . .",2 Sequence to Sequence Learning,[0],[0]
", xm) containing m words and outputs a sequence of states z = (z1. . . .",2 Sequence to Sequence Learning,[0],[0]
", zm).",2 Sequence to Sequence Learning,[0],[0]
"The decoder takes z and generates the output sequence u = (u1, . . .",2 Sequence to Sequence Learning,[0],[0]
", un) left to right, one element at a time.",2 Sequence to Sequence Learning,[0],[0]
"For each output ui, the decoder computes hidden state hi based on the previous state hi−1, an embedding gi−1 of the previous target language word ui−1, as well as a conditional input ci derived from the encoder output z. The attention context ci is computed as a weighted sum of (z1, . . .",2 Sequence to Sequence Learning,[0],[0]
", zm) at each time step.",2 Sequence to Sequence Learning,[0],[0]
The weights of this sum are referred to as attention scores and allow the network to focus on the most relevant parts of the input at each generation step.,2 Sequence to Sequence Learning,[0],[0]
Attention scores are computed by comparing each encoder state zj to a combination of the previous decoder state hi and the last prediction ui; the result is normalized to be a distribution over input elements.,2 Sequence to Sequence Learning,[0],[0]
"At each generation step, the model scores for the V possible next target words ui by transforming the decoder output hi via a linear layer with weights Wo and bias bo: si = Wohi + bo.",2 Sequence to Sequence Learning,[0],[0]
"This is turned into a distribution via a softmax: p(ui|u1, . . .",2 Sequence to Sequence Learning,[0],[0]
", ui−1,x) = softmax(si).
",2 Sequence to Sequence Learning,[0],[0]
"Our encoder and decoder use gated convolutional neural networks which enable fast and accurate generation (Gehring et al., 2017b).",2 Sequence to Sequence Learning,[0],[0]
Fast generation is essential to efficiently train on the model output as is done in this work as sequence-level losses require generating at training time.,2 Sequence to Sequence Learning,[0],[0]
Both encoder and decoder networks share a simple block structure that computes intermediate states based on a fixed number of input tokens and we stack several blocks on top of each other.,2 Sequence to Sequence Learning,[0],[0]
"Each block
contains a 1-D convolution that takes as input k feature vectors and outputs another vector; subsequent layers operate over the k output elements of the previous layer.",2 Sequence to Sequence Learning,[0],[0]
"The output of the convolution is then fed into a gated linear unit (Dauphin et al., 2017).",2 Sequence to Sequence Learning,[0],[0]
"In the decoder network, we rely on causal convolution which rely only on states from the previous time steps.",2 Sequence to Sequence Learning,[0],[0]
The parameters θ of our model are all the weight matrices in the encoder and decoder networks.,2 Sequence to Sequence Learning,[0],[0]
Further details can be found in Gehring et al. (2017b).,2 Sequence to Sequence Learning,[0],[0]
We compare several objective functions for training the model architecture described in §2.,3 Objective Functions,[0],[0]
"The corresponding loss functions are either computed over individual tokens (§3.1), over entire sequences (§3.2) or over a combination of tokens and sequences (§3.3).",3 Objective Functions,[0],[0]
An overview of these loss functions is given in Figure 1.,3 Objective Functions,[0],[0]
"Most prior work on sequence to sequence learning has focused on optimizing token-level loss functions, i.e., functions for which the loss is computed additively over individual tokens.
",3.1 Token-Level Objectives,[0],[0]
Token Negative Log Likelihood (TokNLL),3.1 Token-Level Objectives,[0],[0]
"Token-level likelihood (TokNLL, Equation 1) minimizes the negative log likelihood of individual reference tokens t = (t1, . . .",3.1 Token-Level Objectives,[0],[0]
", tn).",3.1 Token-Level Objectives,[0],[0]
"It is the most common loss function optimized in related work and serves as a baseline for our comparison.
",3.1 Token-Level Objectives,[0],[0]
Token NLL with Label Smoothing (TokLS),3.1 Token-Level Objectives,[0],[0]
Likelihood training forces the model to make extreme zero or one predictions to distinguish between the ground truth and alternatives.,3.1 Token-Level Objectives,[0],[0]
"This may result in a model that is too confident in its training predictions, which may hurt its generalization performance.",3.1 Token-Level Objectives,[0],[0]
Label smoothing addresses this by acting as a regularizer that makes the model less confident in its predictions.,3.1 Token-Level Objectives,[0],[0]
"Specifically, we smooth the target distribution with a prior distribution f that is independent of the current input x (Szegedy et al., 2015; Pereyra et al., 2017; Vaswani et al., 2017).",3.1 Token-Level Objectives,[0],[0]
"We use a uniform prior distribution over all words in the vocabulary, f = 1V .",3.1 Token-Level Objectives,[0],[0]
"One may also use a unigram distribution which has been shown to work better on some tasks (Pereyra et al., 2017).",3.1 Token-Level Objectives,[0],[0]
"Label smoothing is equivalent to adding the KL divergence between f and the model prediction
p(u|x) to the negative log likelihood (TokLS, Equation 2).",3.1 Token-Level Objectives,[0],[0]
"In practice, we implement label smoothing by modifying the ground truth distribution for word u to be q(u) = 1− and q(u′) = V for u′ 6= u instead of q(u) = 1 and q(u′) = 0 where is a smoothing parameter.",3.1 Token-Level Objectives,[0],[0]
"We also consider a class of objective functions that are computed over entire sequences, i.e., sequence-level objectives.",3.2 Sequence-Level Objectives,[0],[0]
"Training with these objectives requires generating and scoring multiple candidate output sequences for each input sequence during training, which is computationally expensive but allows us to directly optimize taskspecific metrics such as BLEU or ROUGE.
",3.2 Sequence-Level Objectives,[0],[0]
"Unfortunately, these objectives are also typically defined over the entire space of possible output sequences, which is intractable to enumerate or score with our models.",3.2 Sequence-Level Objectives,[0],[0]
"Instead, we compute our sequence losses over a subset of the output space, U(x), generated by the model.",3.2 Sequence-Level Objectives,[0],[0]
"We discuss approaches for generating this subset in §4.
",3.2 Sequence-Level Objectives,[0],[0]
"Sequence Negative Log Likelihood (SeqNLL) Similar to TokNLL, we can minimize the negative log likelihood of an entire sequence rather than individual tokens (SeqNLL, Equation 3).",3.2 Sequence-Level Objectives,[0],[0]
"The log-
likelihood of sequence u is the sum of individual token log probabilities, normalized by the number of tokens to avoid bias towards shorter sequences:
p(u|x) = exp 1 n
n∑
i=1
log p(ui|u1, . . .",3.2 Sequence-Level Objectives,[0],[0]
", ui−1,x)
",3.2 Sequence-Level Objectives,[0],[0]
"As target we choose a pseudo reference2 amongst the candidates which maximizes either BLEU or ROUGE with respect to t, the gold reference:
u∗(x) = arg max u∈U(x) BLEU(t,u)
",3.2 Sequence-Level Objectives,[0],[0]
"As is common practice when computing BLEU at the sentence-level, we smooth all initial counts to one (except for unigram counts) so that the geometric mean is not dominated by zero-valued ngram match counts (Lin and Och, 2004).
",3.2 Sequence-Level Objectives,[0],[0]
Expected Risk Minimization (Risk),3.2 Sequence-Level Objectives,[0],[0]
"This objective minimizes the expected value of a given cost function over the space of candidate sequences (Risk, Equation 4).",3.2 Sequence-Level Objectives,[0],[0]
"In this work we use task-specific cost functions designed to maximize BLEU or ROUGE (Lin, 2004), e.g., cost(t,u) =
2Another option is to use the gold reference target, t, but in practice this can lead to degenerate solutions in which the model assigns low probabilities to nearly all outputs.",3.2 Sequence-Level Objectives,[0],[0]
"This is discussed further in §4.
",3.2 Sequence-Level Objectives,[0],[0]
"1−BLEU(t,u), for a given a candidate sequence u and target t. Different to SeqNLL",3.2 Sequence-Level Objectives,[0],[0]
"(§3.2), this loss may increase the score of several candidates that have low cost, instead of focusing on a single sequence which may only be marginally better than any alternatives.",3.2 Sequence-Level Objectives,[0],[0]
"Optimizing this loss is a particularly good strategy if the reference is not always reachable, although compared to classical phrase-based models, this is less of an issue with neural sequence to sequence models that predict individual words or even sub-word units.
",3.2 Sequence-Level Objectives,[0],[0]
"The Risk objective is similar to the REINFORCE objective used in Ranzato et al. (2015), since both objectives optimize an expected cost or reward (Williams, 1992).",3.2 Sequence-Level Objectives,[0],[0]
"However, there are a few important differences: (1) whereas REINFORCE typically approximates the expectation with a single sampled sequence, the Risk objective considers multiple sequences; (2) whereas REINFORCE relies on a baseline reward3 to determine the sign of the gradients for the current sequence, for the Risk objective we instead estimate the expected cost over a set of candidate output sequences (see §4); and (3) while the baseline reward is different for every word in REINFORCE, the expected cost is the same for every word in risk minimization since it is computed on the sequence level based on the actual cost.
",3.2 Sequence-Level Objectives,[0],[0]
"Max-Margin MaxMargin (Equation 5) is a classical margin loss for structured prediction (Taskar et al., 2003; Tsochantaridis et al., 2005) which enforces a margin between the model scores of the highest scoring candidate sequence û and a reference sequence.",3.2 Sequence-Level Objectives,[0],[0]
We replace the human reference t with a pseudo-reference u∗ since this setting performed slightly better in early experiments; u∗ is the candidate sequence with the highest BLEU score.,3.2 Sequence-Level Objectives,[0],[0]
"The size of the margin varies between samples and is given by the difference between the cost of u∗ and the cost of û. In practice, we scale the margin by a hyper-parameter β determined on the validation set: β(cost(t, û)− cost(t,u∗)).",3.2 Sequence-Level Objectives,[0],[0]
"For this loss we use the unnormalized scores computed by the model before the final softmax:
s(u|x) = 1 n
n∑
i=1
s(ui|u1, . . .",3.2 Sequence-Level Objectives,[0],[0]
", ui−1,x)
",3.2 Sequence-Level Objectives,[0],[0]
"3Ranzato et al. (2015) estimate the baseline reward for REINFORCE with a separate linear regressor over the model’s current hidden state.
",3.2 Sequence-Level Objectives,[0],[0]
Multi-Margin MaxMargin only updates two elements in the candidate set.,3.2 Sequence-Level Objectives,[0],[0]
"We therefore consider MultiMargin (Equation 6) which enforces a margin between every candidate sequence u and a reference sequence (Herbrich et al., 1999), hence the name Multi-Margin.",3.2 Sequence-Level Objectives,[0],[0]
"Similar to MaxMargin, we replace the reference t with the pseudoreference u∗.
Softmax-Margin Finally, SoftmaxMargin (Equation 7) is another classic loss that has been proposed by Gimpel and Smith (2010) as another way to optimize task-specific costs.",3.2 Sequence-Level Objectives,[0],[0]
The loss augments the scores inside the exp of SeqNLL (Equation 3) by a cost.,3.2 Sequence-Level Objectives,[0],[0]
The intuition is that we want to penalize high cost outputs proportional to their cost.,3.2 Sequence-Level Objectives,[0],[0]
We also experiment with two variants of combining sequence-level objectives (§3.2) with tokenlevel objectives (§3.1).,3.3 Combined Objectives,[0],[0]
"First, we consider a weighted combination (Weighted) of both a sequence-level and token-level objective (Wu et al., 2016), e.g., for TokLS and Risk we have:
LWeighted = αLTokLS + (1− α)LRisk (8)
where α is a scaling constant that is tuned on a held-out validation set.
",3.3 Combined Objectives,[0],[0]
"Second, we consider a constrained combination (Constrained), where for any given input we use either the token-level or sequence-level loss, but not both.",3.3 Combined Objectives,[0],[0]
The motivation is to maintain good token-level accuracy while optimizing on the sequence-level.,3.3 Combined Objectives,[0],[0]
"In particular, a sample is processed with the sequence loss if the token loss under the current model is at least as good as the token loss of a baseline model LbTokLS.",3.3 Combined Objectives,[0],[0]
"Otherwise, we update according to the token loss:
LConstrained",3.3 Combined Objectives,[0],[0]
"= { LRisk LTokLS ≤ LbTokLS LTokLS otherwise
(9)",3.3 Combined Objectives,[0],[0]
In this work we use a fixed baseline model that was trained with a token-level loss to convergence.,3.3 Combined Objectives,[0],[0]
"The sequence-level objectives we consider (§3.2) are defined over the entire space of possible output sequences, which is intractable to enumerate or
score with our models.",4 Candidate Generation Strategies,[0],[0]
"We therefore use a subset of K candidate sequences U(x) = {u1, . . .",4 Candidate Generation Strategies,[0],[0]
", uK}, which we generate with our models.
",4 Candidate Generation Strategies,[0],[0]
We consider two search strategies for generating the set of candidate sequences.,4 Candidate Generation Strategies,[0],[0]
"The first is beam search, a greedy breadth-first search that maintains a “beam” of the top-K scoring candidates at each generation step.",4 Candidate Generation Strategies,[0],[0]
Beam search is the de facto decoding strategy for achieving state-ofthe-art results in machine translation.,4 Candidate Generation Strategies,[0],[0]
"The second strategy is sampling (Chatterjee and Cancedda, 2010), which produces K independent output sequences by sampling from the model’s conditional distribution.",4 Candidate Generation Strategies,[0],[0]
"Whereas beam search focuses on high probability candidates, sampling introduces more diverse candidates (see comparison in §6.5).
",4 Candidate Generation Strategies,[0],[0]
We also consider both online and offline candidate generation settings in §6.4.,4 Candidate Generation Strategies,[0],[0]
"In the online setting, we regenerate the candidate set every time we encounter an input sentence x during training.",4 Candidate Generation Strategies,[0],[0]
"In the offline setting, candidates are generated before training and are never regenerated.",4 Candidate Generation Strategies,[0],[0]
Offline generation is also embarrassingly parallel because all samples use the same model.,4 Candidate Generation Strategies,[0],[0]
The disadvantage is that the candidates become stale.,4 Candidate Generation Strategies,[0],[0]
"Our model may perfectly be able to discriminate between them after only a single update, hindering the ability of the loss to correct eventual search errors.4
Finally, while some past work has added the reference target to the candidate set, i.e., U ′(x) = U(x) ∪ {t}, we find this can destabilize training since the model learns to assign low probabilities nearly everywhere, ruining the candidates generated by the model, while still assigning a slightly higher score to the reference (cf.",4 Candidate Generation Strategies,[0],[0]
Shen et al. (2016)).,4 Candidate Generation Strategies,[0],[0]
Accordingly we do not add the reference translation to our candidate sets.,4 Candidate Generation Strategies,[0],[0]
"We experiment on the IWSLT’14 German to English (Cettolo et al., 2014) task using a similar setup as Ranzato et al. (2015), which allows us to compare to other recent studies that also adopted this setup, e.g., Wiseman and Rush (2016).5 The training data consists of 160K sentence pairs and the validation set comprises 7K sentences ran-
4We can mitigate this issue by regenerating infrequently, i.e., once every b batches but we leave this to future work.
5Different to Ranzato et al. (2015) we train on sentences of up to 175 rather than 50 tokens.
domly sampled and held-out from the train data.",5.1 Translation,[0],[0]
"We test on the concatenation of tst2010, tst2011, tst2012, tst2013 and dev2010 which is of similar size to the validation set.",5.1 Translation,[0],[0]
"All data is lowercased and tokenized with a byte-pair encoding (BPE) of 14,000 types (Sennrich et al., 2016) and we evaluate with case-insensitive BLEU.
",5.1 Translation,[0],[0]
We also experiment on the much larger WMT’14 English-French task.,5.1 Translation,[0],[0]
We remove sentences longer than 175 words as well as pairs with a source/target length ratio exceeding 1.5 resulting in 35.5M sentence-pairs for training.,5.1 Translation,[0],[0]
The source and target vocabulary is based on 40K BPE types.,5.1 Translation,[0],[0]
"Results are reported on both newstest2014 and a validation set held-out from the training data comprising 26,658 sentence pairs.
",5.1 Translation,[0],[0]
We modify the fairseq-py toolkit to implement the objectives described in §3.6 Our translation models have four convolutional encoder layers and three convolutional decoder layers with a kernel width of 3 and 256 dimensional hidden states and word embeddings.,5.1 Translation,[0],[0]
"We optimize these models using Nesterov’s accelerated gradient method (Sutskever et al., 2013) with a learning rate of 0.25 and momentum of 0.99.",5.1 Translation,[0],[0]
"Gradient vectors are renormalized to norm 0.1 (Pascanu et al., 2013).
",5.1 Translation,[0],[0]
We train our baseline token-level models for 200 epochs and then anneal the learning by shrinking it by a factor of 10 after each subsequent epoch until the learning rate falls below 10−4.,5.1 Translation,[0],[0]
All sequence-level models are initialized with parameters of a token-level model before annealing.,5.1 Translation,[0],[0]
We then train sequence-level models for another 10 to 20 epochs depending on the objective.,5.1 Translation,[0],[0]
Our batches contain 8K tokens and we normalize gradients by the number of non-padding tokens per mini-batch.,5.1 Translation,[0],[0]
"We use weight normalization for all layers except for lookup tables (Salimans and Kingma, 2016).",5.1 Translation,[0],[0]
"Besides dropout on the embeddings and the decoder output, we also apply dropout to the input of the convolutional blocks at a rate of 0.3 (Srivastava et al., 2014).",5.1 Translation,[0],[0]
"We tuned the various parameters above and report accuracy on the test set by choosing the best configuration based on the validation set.
",5.1 Translation,[0],[0]
We length normalize all scores and probabilities in the sequence-level losses by dividing by the number of tokens in the sequence so that scores are comparable between different lengths.,5.1 Translation,[0],[0]
"Ad-
6https://github.com/facebookresearch/ fairseq-py.
ditionally, when generating candidate output sequences during training we limit the output sequence length to be less than 200 tokens for efficiency.",5.1 Translation,[0],[0]
"We generally use 16 candidate sequences per training example, except for the ablations where we use 5 for faster experimental turnaround.",5.1 Translation,[0],[0]
"For summarization we use the Gigaword corpus as training data (Graff et al., 2003) and pre-process it identically to Rush et al. (2015) resulting in 3.8M training and 190K validation examples.",5.2 Abstractive Summarization,[0],[0]
"We evaluate on a Gigaword test set of 2,000 pairs identical to the one used by Rush et al. (2015) and report F1 ROUGE similar to prior work.",5.2 Abstractive Summarization,[0],[0]
"Our results are in terms of three variants of ROUGE (Lin, 2004), namely, ROUGE-1 (RG-1, unigrams), ROUGE-2 (RG-2, bigrams), and ROUGE-L (RG-L, longestcommon substring).",5.2 Abstractive Summarization,[0],[0]
Similar to Ayana et al. (2016) we use a source and target vocabulary of 30k words.,5.2 Abstractive Summarization,[0],[0]
Our models for this task have 12 layers in the encoder and decoder each with 256 hidden units and kernel width 3.,5.2 Abstractive Summarization,[0],[0]
"We train on batches of 8,000 tokens with a learning rate of 0.25 for 20 epochs and then anneal as in §5.1.",5.2 Abstractive Summarization,[0],[0]
"First, we compare all objectives based on a weighted combination with token-level label smoothing (Equation 8).",6.1 Comparison of Sequence Level Losses,[0],[0]
"We also show the likelihood baseline (MLE) of Wiseman and Rush (2016), their beam search optimization method (BSO), the actor critic result of Bahdanau et al. (2016) as well as the best reported result on this dataset to date by Huang et al. (2017).",6.1 Comparison of Sequence Level Losses,[0],[0]
"We show a like-for-like comparison to Wiseman and Rush (2016) with a similar baseline model below (§6.6).
",6.1 Comparison of Sequence Level Losses,[0],[0]
Table 1 shows that all sequence-level losses outperform token-level losses.,6.1 Comparison of Sequence Level Losses,[0],[0]
Our baseline tokenlevel results are several points above other figures in the literature and we further improve these results by up to 0.61 BLEU with Risk training.,6.1 Comparison of Sequence Level Losses,[0],[0]
"Next, we compare various strategies to combine sequence-level and token-level objectives (cf. §3.3).",6.2 Combination with Token-Level Loss,[0],[0]
For these experiments we use 5 candidate sequences per training example for faster experimental turnaround.,6.2 Combination with Token-Level Loss,[0],[0]
"We consider Risk as
sequence-level loss and label smoothing as tokenlevel loss.",6.2 Combination with Token-Level Loss,[0],[0]
Table 2 shows that combined objectives perform better than pure Risk.,6.2 Combination with Token-Level Loss,[0],[0]
"The weighted combination (Equation 8) with α = 0.3 performs best, outperforming constrained combination (Equation 9).",6.2 Combination with Token-Level Loss,[0],[0]
We also compare to randomly choosing between token-level and sequence-level updates and find it underperforms the more principled constrained strategy.,6.2 Combination with Token-Level Loss,[0],[0]
In the remaining experiments we use the weighted strategy.,6.2 Combination with Token-Level Loss,[0],[0]
So far we initialized sequence-level models with parameters from a token-level model trained with label smoothing.,6.3 Effect of initialization,[0],[0]
"Table 3 shows that initializing weighted Risk with token-level label smoothing
achieves 0.7-0.8 better BLEU compared to initializing with parameters from token-level likelihood.",6.3 Effect of initialization,[0],[0]
"The improvement of initializing with TokNLL is only 0.3 BLEU with respect to the TokNLL baseline, whereas, the improvement from initializing with TokLS is 0.6-0.8 BLEU.",6.3 Effect of initialization,[0],[0]
We believe that the regularization provided by label smoothing leads to models with less sharp distributions that are a better starting point for sequence-level training.,6.3 Effect of initialization,[0],[0]
"Next, we consider the question if refreshing the candidate subset at every training step (online) results in better accuracy compared to generating candidates before training and keeping the set static throughout training (offline).",6.4 Online vs. Offline Candidate Generation,[0],[0]
Table 4 shows that offline generation gives lower accuracy.,6.4 Online vs. Offline Candidate Generation,[0],[0]
"However the online setting is much slower, since regenerating the candidate set requires incremental (left to right) inference with our model which is very slow compared to efficient forward/backward over large batches of pre-generated hypothesis.",6.4 Online vs. Offline Candidate Generation,[0],[0]
"In our setting, offline generation has 26 times higher throughput than the online generation setting, despite the high inference speed of fairseq (Gehring et al., 2017b).",6.4 Online vs. Offline Candidate Generation,[0],[0]
"So far we generated candidates with beam search, however, we may also sample to obtain a more diverse set of candidates (Shen et al., 2016).",6.5 Beam Search vs. Sampling and Candidate Set Size,[0],[0]
"Fig-
ure 2 compares beam search and sampling for various candidate set sizes on the validation set.",6.5 Beam Search vs. Sampling and Candidate Set Size,[0],[0]
Beam search performs better for all candidate set sizes considered.,6.5 Beam Search vs. Sampling and Candidate Set Size,[0],[0]
"In other experiments, we rely on a candidate set size of 16 which strikes a good balance between efficiency and accuracy.",6.5 Beam Search vs. Sampling and Candidate Set Size,[0],[0]
"Next, we compare classical sequence-level training to the recently proposed Beam Search Optimization (Wiseman and Rush, 2016).",6.6 Comparison to Beam-Search Optimization,[0],[0]
"To enable a fair comparison, we re-implement their baseline, a single layer LSTM encoder/decoder model with 256-dimensional hidden layers and word embeddings as well as attention and input feeding (Luong et al., 2015).",6.6 Comparison to Beam-Search Optimization,[0],[0]
"This baseline is trained with Adagrad (Duchi et al., 2011) using a learning rate of 0.05 for five epochs, with batches of 64 sequences.",6.6 Comparison to Beam-Search Optimization,[0],[0]
"For sequence-level training we initialize weights with the baseline parameters and train
with Adam (Kingma and Ba, 2014) for another 10 epochs with learning rate 0.00003 and 16 candidate sequences per training example.",6.6 Comparison to Beam-Search Optimization,[0],[0]
"We conduct experiments with Risk since it performed best in trial experiments.
",6.6 Comparison to Beam-Search Optimization,[0],[0]
"Different from other sequence-level experiments (§5), we rescale the BLEU scores in each candidate set by the difference between the maximum and minimum scores of each sentence.",6.6 Comparison to Beam-Search Optimization,[0],[0]
"This avoids short sentences dominating the sequence updates, since candidate sets for short sentences have a wider range of BLEU scores compared to longer sentences; a similar rescaling was used by Bahdanau et al. (2016).
",6.6 Comparison to Beam-Search Optimization,[0],[0]
"Table 5 shows the results from Wiseman and Rush (2016) for their token-level likelihood baseline (MLE), best beam search optimization results (BSO), as well as our reimplemented baseline.",6.6 Comparison to Beam-Search Optimization,[0],[0]
"Risk significantly improves BLEU compared to our baseline at +2.75 BLEU, which is slightly better than the +2.33 BLEU improvement reported for Beam Search Optimization (cf. Wiseman and Rush (2016)).",6.6 Comparison to Beam-Search Optimization,[0],[0]
This shows that classical objectives for structured prediction are still very competitive.,6.6 Comparison to Beam-Search Optimization,[0],[0]
"Next, we experiment on the much larger WMT’14 English-French task using the same model setup as Gehring et al. (2017b).",6.7 WMT’14 English-French results,[0],[0]
"We TokLSfor 15 epochs
and then switch to sequence-level training for another epoch.",6.7 WMT’14 English-French results,[0],[0]
Table 7 shows that sequence-level training can improve an already very strong model by another +0.37 BLEU.,6.7 WMT’14 English-French results,[0],[0]
"Next, we improve the baseline by adding self-attention (Paulus et al., 2017; Vaswani et al., 2017) to the decoder network (TokLS + selfatt) which results in a smaller gain of +0.2 BLEU by Risk.",6.7 WMT’14 English-French results,[0],[0]
"If we train Risk only on the news-commentary portion of the training data, then we achieve state of the art accuracy on this dataset of 41.5 BLEU (Xia et al., 2017).",6.7 WMT’14 English-French results,[0],[0]
Our final experiment evaluates sequence-level training on Gigaword headline summarization.,6.8 Abstractive Summarization,[0],[0]
There has been much prior art on this dataset originally introduced by Rush et al. (2015) who experiment with a feed-forward network (ABS+).,6.8 Abstractive Summarization,[0],[0]
Ayana et al. (2016) report a likelihood baseline (RNN MLE) and also experiment with risk training (RNN MRT).,6.8 Abstractive Summarization,[0],[0]
"Different to their setup we did not find a softmax temperature to be beneficial, and we use beam search instead of sampling to obtain the candidate set (cf.",6.8 Abstractive Summarization,[0],[0]
§6.5).,6.8 Abstractive Summarization,[0],[0]
Suzuki and Nagata (2017) improve over an MLE RNN baseline by limiting generation of repeated phrases.,6.8 Abstractive Summarization,[0],[0]
Zhou et al. (2017) also consider an MLE RNN baseline and add an additional gating mechanism for the encoder.,6.8 Abstractive Summarization,[0],[0]
"Li et al. (2017) equip the decoder of a similar network with additional latent variables to accommodate the uncertainty of this task.
",6.8 Abstractive Summarization,[0],[0]
Table 6 shows that our baseline (TokLS) outperforms all prior approaches in terms of ROUGE2 and ROUGE-L and it is on par to the best previous result for ROUGE-1.,6.8 Abstractive Summarization,[0],[0]
We optimize all three ROUGE metrics separately and find that Risk can further improve our strong baseline.,6.8 Abstractive Summarization,[0],[0]
We also compared Risk only training to Weighted on this dataset (cf.,6.8 Abstractive Summarization,[0],[0]
"§6.2) but accuracy was generally lower on the validation set: RG-1
(36.59 Risk only vs. 36.67 Weighted), RG-2 (17.34 vs. 18.05), and RG-L (33.66 vs. 33.98).",6.8 Abstractive Summarization,[0],[0]
We present a comprehensive comparison of classical losses for structured prediction and apply them to a strong neural sequence to sequence model.,7 Conclusion,[0],[0]
"We found that combining sequence-level and tokenlevel losses is necessary to perform best, and so is training on candidates decoded with the current model.
",7 Conclusion,[0],[0]
We show that sequence-level training improves state-of-the-art baselines both for IWSLT’14 German-English translation and Gigaword abstractive sentence summarization.,7 Conclusion,[0],[0]
Structured prediction losses are very competitive to recent work on reinforcement or beam optimization.,7 Conclusion,[0],[0]
"Classical expected risk can slightly outperform beam search optimization (Wiseman and Rush, 2016) in a likefor-like setup.",7 Conclusion,[0],[0]
"Future work may investigate better use of already generated candidates since invoking generation for each batch slows down training by a large factor, e.g., mixing with fresh and older candidates inspired by MERT (Och, 2003).",7 Conclusion,[0],[0]
There has been much recent work on training neural attention models at the sequencelevel using either reinforcement learning-style methods or by optimizing the beam.,abstractText,[0],[0]
"In this paper, we survey a range of classical objective functions that have been widely used to train linear models for structured prediction and apply them to neural sequence to sequence models.",abstractText,[0],[0]
Our experiments show that these losses can perform surprisingly well by slightly outperforming beam search optimization in a like for like setup.,abstractText,[0],[0]
We also report new state of the art results on both IWSLT’14 German-English translation as well as Gigaword abstractive summarization.,abstractText,[0],[0]
"On the large WMT’14 English-French task, sequence-level training achieves 41.5 BLEU which is on par with the state of the art.1",abstractText,[0],[0]
Classical Structured Prediction Losses for Sequence to Sequence Learning,title,[0],[0]
"In supervised classification, we need a vast amount of labeled data in the training phase.",1. Introduction,[0],[0]
"However, in many realworld problems, it is time-consuming and laborious to label a huge amount of unlabeled data.",1. Introduction,[0],[0]
"To deal with this problem, weakly-supervised classification (Zhou, 2018) has been explored in various setups, including semi-supervised classification (Chapelle & Zien, 2005; Belkin et al., 2006; Chapelle et al., 2010; Miyato et al., 2016; Laine & Aila, 2017; Sakai et al., 2017; Tarvainen & Valpola, 2017; Luo et al., 2018), multiple instance classification (Li & Vasconcelos, 2015; Miech et al., 2017; Bao et al., 2018), and positive-unlabeled (PU) classification (Elkan & Noto, 2008; du Plessis et al., 2014; 2015; Niu et al., 2016; Kiryo et al., 2017).
",1. Introduction,[0],[0]
"Another line of research from the clustering viewpoint is semi-supervised clustering, where pairwise similarity and dissimilarity data (a.k.a. must-link and cannot-link constraints) are utilized to guide unsupervised clustering to a desired solution.",1. Introduction,[0],[0]
"The common approaches are (i) constrained clustering (Wagstaff et al., 2001; Basu et al., 2002;
1The University of Tokyo, Japan 2RIKEN, Japan.",1. Introduction,[0],[0]
Correspondence to:,1. Introduction,[0],[0]
"Han Bao <tsutsumi@ms.k.u-tokyo.ac.jp>.
Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"aDiscriminative clustering methods are designed for out-ofsample inference, such as maximum margin clustering (Xu et al., 2005) and information maximization clustering (Krause et al., 2010; Sugiyama et al., 2011).
2004; Li & Liu, 2009), which utilize pairwise links as constraints on clustering.",1. Introduction,[0],[0]
"(ii) metric learning (Xing et al., 2002; Bilenko et al., 2004; Weinberger et al., 2005; Davis et al., 2007; Li et al., 2008; Niu et al., 2012), which perform (k-means) clustering on learned metrics (iii) matrix completion (Yi et al., 2013; Chiang et al., 2015), which recover unknown entries in a similarity matrix.
",1. Introduction,[0],[0]
Semi-supervised clustering and weakly-supervised classification are similar in that they do not use fully-supervised data.,1. Introduction,[0],[0]
"However, they are different from the learning theoretic viewpoint—weakly-supervised classification methods are justified as supervised learning methods, while semi-supervised clustering methods are still evaluated as unsupervised learning (see Table 1).",1. Introduction,[0],[0]
"Indeed, weaklysupervised learning methods based on empirical risk minimization (du Plessis et al., 2014; 2015; Niu et al., 2016; Sakai et al., 2017) were shown that their estimation errors achieve the optimal parametric convergence rate, while such generalization guarantee is not available for semi-supervised
clustering methods.
",1. Introduction,[0],[0]
"The goal of this paper is to propose a novel weaklysupervised learning method called SU classification, where only similar (S) data pairs (two examples belong to the same class) and unlabeled (U) data points are employed, in order to bridge these two different paradigms.",1. Introduction,[0],[0]
"In SU classification, the information available for training a classifier is similar to semi-supervised clustering.",1. Introduction,[0],[0]
"However, our proposed method gives an inductive model, which learns decision functions from training data and can be applied for out-of-sample prediction (i.e., prediction of unseen test data).",1. Introduction,[0],[0]
"Furthermore, the proposed method can not only separate two classes but also identify which class is positive (class identification) under certain conditions.
",1. Introduction,[0],[0]
"SU classification is particularly useful to predict people’s sensitive matters such as religion, politics, and opinions on racial issues—people often hesitate to give explicit answers to these matters, instead indirect questions might be easier to answer: “Which person do you have the same belief as?”1
For this SU classification problem, our contributions in this paper are three-fold:
1.",1. Introduction,[0],[0]
We propose an empirical risk minimization method for SU classification (Section 2).,1. Introduction,[0],[0]
This enables us to obtain an inductive classifier.,1. Introduction,[0],[0]
"Under certain loss conditions together with the linear-in-parameter model, its objective function becomes even convex in the parameters.
",1. Introduction,[0],[0]
2.,1. Introduction,[0],[0]
"We theoretically establish an estimation error bound for our SU classification method (Section 4), showing that the proposed method achieves the optimal parametric convergence rate.
3.",1. Introduction,[0],[0]
"We experimentally demonstrate the practical usefulness of the proposed SU classification method (Section 5).
",1. Introduction,[0],[0]
Related problem settings are summarized in Figure 1.,1. Introduction,[0],[0]
"In this section, we propose a learning method to train a classifier from pairwise similarity and unlabeled data.",2. Classification from Pairwise Similarity and Unlabeled Data,[0],[0]
We formulate the standard binary classification problem briefly.,2.1. Preliminaries,[0],[0]
"Let X ⇢ Rd be a d-dimensional example space and Y = {+1, 1} be a binary label space.",2.1. Preliminaries,[0],[0]
"We assume that labeled data (x, y) 2 X ⇥ Y is drawn from the joint
1 This questioning can be regarded as one type of randomized response (indirect questioning) techniques (Warner, 1965; Fisher, 1993), which is a survey method to avoid social desirability bias.
probability distribution with density p(x, y).",2.1. Preliminaries,[0],[0]
The goal of binary classification is to obtain a classifier f : X !,2.1. Preliminaries,[0],[0]
"R which minimizes the classification risk defined as
R(f) , E (X,Y )⇠p",2.1. Preliminaries,[0],[0]
"[`(f(X), Y )] , (1)
where E(X,Y )⇠p[·] denotes the expectation over the joint distribution p(X,Y ) and ` : R⇥Y !",2.1. Preliminaries,[0],[0]
R+ is a loss function.,2.1. Preliminaries,[0],[0]
"The loss function `(z, t) measures how well the true class label t 2 Y is estimated by an output of a classifier z 2 R, generally yielding a small/large value if t is well/poorly estimated by z.
In standard supervised classification scenarios, we are given positive and negative training data independently following p(x, y).",2.1. Preliminaries,[0],[0]
"Then, based on these training data, the classification risk (1) is empirically approximated and the empirical risk minimizer is obtained.",2.1. Preliminaries,[0],[0]
"However, in many real-world problems, collecting labeled training data is costly.",2.1. Preliminaries,[0],[0]
"The goal of this paper is to train a binary classifier only from pairwise similarity and unlabeled data, which are cheaper to collect than fully labeled data.",2.1. Preliminaries,[0],[0]
"First, we discuss underlying distributions of similar data pairs and unlabeled data points, in order to perform the empirical risk minimization.
",2.2. Pairwise Similarity and Unlabeled Data,[0],[0]
"Pairwise Similarity: If x and x0 belong to the same class, they are said to be pairwise similar (S).",2.2. Pairwise Similarity and Unlabeled Data,[0],[0]
"We assume that similar data pairs are drawn following
pS(x,x 0 ) = p(x,x0|y = y0 = +1 _",2.2. Pairwise Similarity and Unlabeled Data,[0],[0]
"y = y0 = 1)
",2.2. Pairwise Similarity and Unlabeled Data,[0],[0]
"=
⇡2+p+(x)p+(x 0 )",2.2. Pairwise Similarity and Unlabeled Data,[0],[0]
"+ ⇡2 p (x)p (x0)
⇡2+ + ⇡ 2
, (2)
where ⇡+ , p(y = +1) and ⇡ , p(y = 1) are the class-prior probabilities satisfying ⇡+ + ⇡ = 1, and p+(x) , p(x|y = +1) and p (x) , p(x|y = 1) are the class-conditional densities.",2.2. Pairwise Similarity and Unlabeled Data,[0],[0]
"Eq. (2) means that we draw two labeled data independently following p(x, y), and we accept/reject them if they belong to the same class/different classes.
",2.2. Pairwise Similarity and Unlabeled Data,[0],[0]
Unlabeled Data:,2.2. Pairwise Similarity and Unlabeled Data,[0],[0]
"We assume that unlabeled (U) data points are drawn following the marginal density p(x), which can be decomposed into the sum of the class-conditional densities as
p(x) = ⇡+p+(x) + ⇡ p (x).",2.2. Pairwise Similarity and Unlabeled Data,[0],[0]
"(3)
Our goal is to train a classifier only from SU data, which we call SU classification.",2.2. Pairwise Similarity and Unlabeled Data,[0],[0]
"We assume that we have similar pairs DS and an unlabeled dataset DU as
DS , {(xS,i,x0S,i)}nSi=1 i.i.d.⇠ pS(x,x0),
DU , {xU,i}nUi=1",2.2. Pairwise Similarity and Unlabeled Data,[0],[0]
"i.i.d.⇠ p(x).
",2.2. Pairwise Similarity and Unlabeled Data,[0],[0]
"We also use a notation eDS , {exS,i}2nSi=1 to denote pointwise similar data obtained by ignoring pairwise relations in DS.",2.2. Pairwise Similarity and Unlabeled Data,[0],[0]
Lemma 1.,2.2. Pairwise Similarity and Unlabeled Data,[0],[0]
eDS,2.2. Pairwise Similarity and Unlabeled Data,[0],[0]
"= {exS,i}2nSi=1 are independently drawn following
epS(x) = ⇡2+p+(x) + ⇡ 2 p (x) ⇡S , (4)
where ⇡S , ⇡2+ + ⇡2 .
",2.2. Pairwise Similarity and Unlabeled Data,[0],[0]
"A proof is given in Appendix A.
Lemma 1 states that a similar data pair (xS,x0S) is essentially symmetric, and xS,x0S can be regarded as being independently drawn following epS, if we assume the pair (xS,x0S) is drawn following pS.",2.2. Pairwise Similarity and Unlabeled Data,[0],[0]
"This perspective is important when we analyze the variance of the risk estimator (Section 2.4), and estimate the class-prior (Section 3.2).",2.2. Pairwise Similarity and Unlabeled Data,[0],[0]
"Below, we attempt to express the classification risk (1) only in terms of SU data.",2.3. Risk Expression with SU Data,[0],[0]
"Assume ⇡+ 6= 12 , and let è(z), LS,`(z) and LU,`(z) be
è (z) , `(z,+1) `(z, 1),
LS,`(z) , 1 2⇡+ 1 è (z), LU,`(z) , ⇡
2⇡+ 1 `(z,+1) + ⇡+ 2⇡+ 1 `(z, 1).
",2.3. Risk Expression with SU Data,[0],[0]
Then we have the following theorem.,2.3. Risk Expression with SU Data,[0],[0]
Theorem 1.,2.3. Risk Expression with SU Data,[0],[0]
"The classification risk (1) can be equivalently expressed as
RSU,`(f) = ⇡S E (X,X0)⇠pS
 LS,`(f(X)) +",2.3. Risk Expression with SU Data,[0],[0]
"LS,`(f(X 0))
2
+ E X⇠p [LU,`(f(X))] .
",2.3. Risk Expression with SU Data,[0],[0]
"A proof is given in Appendix B.
",2.3. Risk Expression with SU Data,[0],[0]
"According to Theorem 1, the following is a natural candidate for an unbiased estimator of the classification risk (1):
bRSU,`(f)
= ⇡S nS
nSX
i=1
LS,`(f(xS,i))",2.3. Risk Expression with SU Data,[0],[0]
+,2.3. Risk Expression with SU Data,[0],[0]
"LS,`(f(x0S,i))",2.3. Risk Expression with SU Data,[0],[0]
"2
+
1
nU
nUX
i=1
LU,`(f(xU,i))
= ⇡S 2nS
2nSX
i=1
LS,`(f(exS,i))",2.3. Risk Expression with SU Data,[0],[0]
"+ 1
nU
nUX
i=1
LU,`(f(xU,i)),
(5)
where in the last line we use the decomposed version of similar pairs eDS instead of DS, since the loss form is symmetric.
",2.3. Risk Expression with SU Data,[0],[0]
"LS,` and LU,` are illustrated in Figure 2.",2.3. Risk Expression with SU Data,[0],[0]
Eq. (5) is one of the candidates of an unbiased SU risk estimator.,2.4. Minimum-Variance Risk Estimator,[0],[0]
"Indeed, due to the symmetry of (x,x0) ⇠ pS(x,x0), we have the following lemma.",2.4. Minimum-Variance Risk Estimator,[0],[0]
Lemma 2.,2.4. Minimum-Variance Risk Estimator,[0],[0]
"The first term of RSU,`(f), i.e.,
⇡S E (X,X0)⇠pS
 LS,`(f(X)) + LS,`(f(X 0))
2
, (6)
can be equivalently expressed as
⇡S E (X,X0)⇠pS
[↵LS,`(f(X))",2.4. Minimum-Variance Risk Estimator,[0],[0]
"+ (1 ↵)LS,`(f(X 0))] ,
where ↵ 2 [0, 1] is an arbitrary weight.
",2.4. Minimum-Variance Risk Estimator,[0],[0]
A proof is given in Appendix C.1.,2.4. Minimum-Variance Risk Estimator,[0],[0]
"By Lemma 2,
⇡S nS
nSX
i=1
↵LS,`(f(xS,i))",2.4. Minimum-Variance Risk Estimator,[0],[0]
"+ (1 ↵)LS,`(f(x0S,i))
",2.4. Minimum-Variance Risk Estimator,[0],[0]
"(7)
is also an unbiased estimator of Eq.",2.4. Minimum-Variance Risk Estimator,[0],[0]
(6).,2.4. Minimum-Variance Risk Estimator,[0],[0]
"Then, a natural question arises: is the risk estimator (5) best among all ↵?",2.4. Minimum-Variance Risk Estimator,[0],[0]
"We answer this question by the following theorem.
",2.4. Minimum-Variance Risk Estimator,[0],[0]
Theorem 2.,2.4. Minimum-Variance Risk Estimator,[0],[0]
"The estimator
⇡S nS
nSX
i=1
LS,`(f(xS,i))",2.4. Minimum-Variance Risk Estimator,[0],[0]
+,2.4. Minimum-Variance Risk Estimator,[0],[0]
"LS,`(f(x0S,i))",2.4. Minimum-Variance Risk Estimator,[0],[0]
"2
(8)
has the minimum variance among estimators in the form Eq.",2.4. Minimum-Variance Risk Estimator,[0],[0]
"(7) with respect to ↵ 2 [0, 1].
",2.4. Minimum-Variance Risk Estimator,[0],[0]
"A proof is given in Appendix C.2.
",2.4. Minimum-Variance Risk Estimator,[0],[0]
"Thus, the variance minimality (with respect to ↵ in Eq.",2.4. Minimum-Variance Risk Estimator,[0],[0]
(7)) of the risk estimator (5) is guaranteed by Theorem 2.,2.4. Minimum-Variance Risk Estimator,[0],[0]
We use this risk estimator in the following sections.,2.4. Minimum-Variance Risk Estimator,[0],[0]
"Here, we investigate the objective function when the linearin-parameter model f(x) =",2.5. Practical Implementation,[0],[0]
"w> (x)+w0 is employed as a classifier, where w 2 Rd and w0 2 R are parameters and : Rd !",2.5. Practical Implementation,[0],[0]
Rb is basis functions.,2.5. Practical Implementation,[0],[0]
"In general, the bias parameter w0 can be ignored 2.",2.5. Practical Implementation,[0],[0]
We formulate SU classification as the following empirical risk minimization problem using Eq.,2.5. Practical Implementation,[0],[0]
"(5) together with the `2 regularization:
bw = min w
bJ`(w), (9)
where
bJ`(w) , ⇡S 2nS
2nSX
i=1
LS,`(w>",2.5. Practical Implementation,[0],[0]
"(exS,i))
",2.5. Practical Implementation,[0],[0]
"+
1
nU
nUX
i=1
LU,`(w>",2.5. Practical Implementation,[0],[0]
"(xU,i))",2.5. Practical Implementation,[0],[0]
"+
2
kwk2,
(10)
2",2.5. Practical Implementation,[0],[0]
"Let e (x) , [ (x)> 1]> and ew , [w> w0]> then w > (x) + w0 = ew> e (x).
and > 0 is the regularization parameter.",2.5. Practical Implementation,[0],[0]
We need the class-prior ⇡+ (included in ⇡S) to solve this optimization problem.,2.5. Practical Implementation,[0],[0]
"We discuss how to estimate ⇡+ in Section 3.2.
",2.5. Practical Implementation,[0],[0]
"Next, we will investigate appropriate choices of the loss function `.",2.5. Practical Implementation,[0],[0]
"From now on, we focus on margin loss functions (Mohri et al., 2012): ` is said to be a margin loss function if there exists : R! R+ such that `(z, t) =",2.5. Practical Implementation,[0],[0]
(tz).,2.5. Practical Implementation,[0],[0]
"In general, our objective function (10) is non-convex even if a convex loss function is used for ` 3.",2.5. Practical Implementation,[0],[0]
"However, the next theorem, inspired by Natarajan et al. (2013) and du Plessis et al. (2015), states that a certain loss function will result in a convex objective function.",2.5. Practical Implementation,[0],[0]
Theorem 3.,2.5. Practical Implementation,[0],[0]
"If the loss function `(z, t) is a convex margin loss, twice differentiable in z almost everywhere (for every fixed t 2 {±1}), and satisfies the condition
`(z,+1)",2.5. Practical Implementation,[0],[0]
"`(z, 1) = z,
then bJ`(w) is convex.",2.5. Practical Implementation,[0],[0]
"A proof of Theorem 3 is given in Appendix D.
Examples of margin loss functions satisfying the conditions in Theorem 3 are shown in Table 2 (also illustrated in Figure 3).",2.5. Practical Implementation,[0],[0]
"Below, as special cases, we show the objective functions for the squared and the double-hinge losses.",2.5. Practical Implementation,[0],[0]
"The detailed derivations are given in Appendix E.
Squared Loss: The squared loss is `SQ(z, t) = 14 (tz 1)2.",2.5. Practical Implementation,[0],[0]
Substituting `SQ into Eq.,2.5. Practical Implementation,[0],[0]
"(10), the objective function is bJSQ(w) =",2.5. Practical Implementation,[0],[0]
"w> ✓ 1
4nU X>UXU + 2",2.5. Practical Implementation,[0],[0]
"I
◆ w
+
1
2⇡+ 1 ✓ ⇡S 2nS 1>XS + 1 2nU 1>XU ◆ w,
3",2.5. Practical Implementation,[0],[0]
"In general, LU,` is non-convex because either ⇡ 2⇡+ 1 `(·,+1) or ⇡+ 2⇡+ 1
`(·, 1) is convex and the other is concave.",2.5. Practical Implementation,[0],[0]
"LS,` is not always convex even if ` is convex, either.
",2.5. Practical Implementation,[0],[0]
"where 1 is the vector whose elements are all ones, I is the identity matrix, XS , [ (exS,1) · · · (exS,2nS)]",2.5. Practical Implementation,[0],[0]
">, and XU , [ (xU,1) · · · (xU,nU)]",2.5. Practical Implementation,[0],[0]
>.,2.5. Practical Implementation,[0],[0]
"The minimizer of this objective function can be obtained analytically as
w = nU
2⇡+ 1
· X>UXU + 2 nUI 1 ✓ ⇡S nS X>S 1 1 nU X>U1 ◆ .
",2.5. Practical Implementation,[0],[0]
"Thus the optimization problem can be easily implemented and solved highly efficiently if the number of basis functions is not so large.
",2.5. Practical Implementation,[0],[0]
"Double-Hinge Loss: Since the hinge loss `H(z, t) = max(0, 1 tz) does not satisfy the conditions in Theorem 3, the double-hinge loss `DH(z, t) = max( tz,max(0, 12 1 2 tz)) is proposed by du Plessis et al. (2015) as an alternative.",2.5. Practical Implementation,[0],[0]
Substituting `DH into Eq.,2.5. Practical Implementation,[0],[0]
"(10), we can reformulate the optimization problem as follows:
min w,⇠,⌘ ⇡S 2nS(2⇡+ 1) 1>XSw ⇡ nS(2⇡+ 1) 1>⇠
+ ⇡+ nU(2⇡+ 1) 1>⌘",2.5. Practical Implementation,[0],[0]
"+ 2 w>w
s.t. ⇠ 0, ⇠ 1 2 1+ 1 2 XUw, ⇠ XUw,
⌘ 0, ⌘ 1 2 1 1 2 XUw, ⌘ XUw,
where for vectors denotes the element-wise inequality.",2.5. Practical Implementation,[0],[0]
This optimization problem is a quadratic program (QP).,2.5. Practical Implementation,[0],[0]
The transformation into the standard QP form is given in Appendix E.,2.5. Practical Implementation,[0],[0]
"In Section 2, we assume that the class-prior ⇡+ is given in advance.",3. Relation between Class-Prior and SU Classification,[0],[0]
"In this section, we first clarify the relation between behaviors of the proposed method and ⇡+, then we propose an algorithm to estimate ⇡+ in case we do not have ⇡+ in advance.",3. Relation between Class-Prior and SU Classification,[0],[0]
"We discuss the following three different cases on prior knowledge of ⇡+ (summarized in Table 3).
",3.1. Class-Prior-Dependent Behaviors of Proposed Method,[0],[0]
(Case 1),3.1. Class-Prior-Dependent Behaviors of Proposed Method,[0],[0]
"The class-prior is given: In this case, we can directly solve the optimization problem (9).",3.1. Class-Prior-Dependent Behaviors of Proposed Method,[0],[0]
"The solution does not only separate data but also identifies classes, i.e., determine which class is positive.
",3.1. Class-Prior-Dependent Behaviors of Proposed Method,[0],[0]
(Case 2),3.1. Class-Prior-Dependent Behaviors of Proposed Method,[0],[0]
No prior knowledge on the class-prior is given:,3.1. Class-Prior-Dependent Behaviors of Proposed Method,[0],[0]
"In this case, we need to estimate ⇡+ before solving (9).",3.1. Class-Prior-Dependent Behaviors of Proposed Method,[0],[0]
"If we assume ⇡+ > ⇡ , the estimation method in Section 3.2 gives an estimator of ⇡+.",3.1. Class-Prior-Dependent Behaviors of Proposed Method,[0],[0]
"Thus, we can regard the larger cluster as positive class and solve the optimization problem (9).",3.1. Class-Prior-Dependent Behaviors of Proposed Method,[0],[0]
"This time the solution just separates data because we have no prior information for class identifiability.
",3.1. Class-Prior-Dependent Behaviors of Proposed Method,[0],[0]
"(Case 3) Magnitude relation of the class-prior is given: Finally, consider the case where we know which class has a larger class-prior.",3.1. Class-Prior-Dependent Behaviors of Proposed Method,[0],[0]
"In this case, we also need to estimate ⇡+, but surprisingly, we can identify classes.",3.1. Class-Prior-Dependent Behaviors of Proposed Method,[0],[0]
"For example, if the negative class has a larger class-prior, first we estimate the class-prior (let b⇡ be an estimated value).",3.1. Class-Prior-Dependent Behaviors of Proposed Method,[0],[0]
"Since Algorithm 1 given in Sec. 3.2 always gives an estimate of the classprior of the larger class, the positive class-prior is given as ⇡+ = 1 b⇡.",3.1. Class-Prior-Dependent Behaviors of Proposed Method,[0],[0]
"After that, it reduces to Case 1.",3.1. Class-Prior-Dependent Behaviors of Proposed Method,[0],[0]
Remark:,3.1. Class-Prior-Dependent Behaviors of Proposed Method,[0],[0]
"In all of the three cases above, our proposed method gives an inductive model, which is applicable to out-of-sample prediction without any modification.",3.1. Class-Prior-Dependent Behaviors of Proposed Method,[0],[0]
"On the other hand, most of the unsupervised/semi-supervised clustering methods are designed for in-sample prediction, which can only give predictions for data at hand given in advance.",3.1. Class-Prior-Dependent Behaviors of Proposed Method,[0],[0]
We propose a class-prior estimation algorithm only from SU data.,3.2. Class-Prior Estimation from Pairwise Similarity and Unlabeled Data,[0],[0]
"First, let us begin with connecting the pairwise marginal distribution p(x,x0) and pS(x,x0)",3.2. Class-Prior Estimation from Pairwise Similarity and Unlabeled Data,[0],[0]
"when two examples x and x0 are drawn independently:
p(x,x0)",3.2. Class-Prior Estimation from Pairwise Similarity and Unlabeled Data,[0],[0]
"= p(x)p(x0)
= ⇡2+p+(x)p+(x 0 )",3.2. Class-Prior Estimation from Pairwise Similarity and Unlabeled Data,[0],[0]
"+ ⇡2 p (x)p (x 0 )
⇡+⇡ p+(x)p (x0) + ⇡+⇡ p (x)p+(x0) = ⇡SpS(x,x 0 ) + ⇡DpD(x,x 0 ), (11)
",3.2. Class-Prior Estimation from Pairwise Similarity and Unlabeled Data,[0],[0]
Algorithm 1,3.2. Class-Prior Estimation from Pairwise Similarity and Unlabeled Data,[0],[0]
Prior estimation from SU data.,3.2. Class-Prior Estimation from Pairwise Similarity and Unlabeled Data,[0],[0]
"CPE is a classprior estimation algorithm.
",3.2. Class-Prior Estimation from Pairwise Similarity and Unlabeled Data,[0],[0]
"Input: DU = {xU,i}nUi=1 (samples from p), eDS = {exS,i}2nSi=1 (samples from epS)",3.2. Class-Prior Estimation from Pairwise Similarity and Unlabeled Data,[0],[0]
"Output: class-prior ⇡+ ⇡S CPE(DU, eDS) ⇡+ p 2⇡S 1+1
2
where Eq.",3.2. Class-Prior Estimation from Pairwise Similarity and Unlabeled Data,[0],[0]
"(2) was used to derive the last line, ⇡D , 2⇡+⇡ , and
pD(x,x 0 )
= p(x,x0|(y =",3.2. Class-Prior Estimation from Pairwise Similarity and Unlabeled Data,[0],[0]
+1 ^ y0 = 1) _,3.2. Class-Prior Estimation from Pairwise Similarity and Unlabeled Data,[0],[0]
"(y = 1 ^ y0 = +1))
",3.2. Class-Prior Estimation from Pairwise Similarity and Unlabeled Data,[0],[0]
= ⇡+⇡ p+(x)p (x0) + ⇡+⇡ p (x)p+(x0) 2⇡+⇡ .,3.2. Class-Prior Estimation from Pairwise Similarity and Unlabeled Data,[0],[0]
"(12)
Marginalizing out x0 in Eq.",3.2. Class-Prior Estimation from Pairwise Similarity and Unlabeled Data,[0],[0]
"(11) as Lemma 1, we obtain
p(x) = ⇡SepS(x) + ⇡DepD(x),
where epS is defined in Eq. (4) and epD(x) , (p+(x) + p (x))/2.",3.2. Class-Prior Estimation from Pairwise Similarity and Unlabeled Data,[0],[0]
Since we have samples DU and eDS drawn from p and epS respectively (see Eqs.,3.2. Class-Prior Estimation from Pairwise Similarity and Unlabeled Data,[0],[0]
"(3) and (4)), we can estimate ⇡S by mixture proportion estimation4 methods (Scott, 2015; Ramaswamy et al., 2016; du Plessis et al., 2017).
",3.2. Class-Prior Estimation from Pairwise Similarity and Unlabeled Data,[0],[0]
"After estimating ⇡S, we can calculate ⇡+.",3.2. Class-Prior Estimation from Pairwise Similarity and Unlabeled Data,[0],[0]
"By the discussion in Section 3.1, we assume ⇡+ > ⇡ .",3.2. Class-Prior Estimation from Pairwise Similarity and Unlabeled Data,[0],[0]
"Then, following 2⇡S 1 = ⇡S ⇡D = (⇡+ ⇡ )2 = (2⇡+ 1)2 0, we obtain ⇡+ = p 2⇡S 1+1
2 .",3.2. Class-Prior Estimation from Pairwise Similarity and Unlabeled Data,[0],[0]
We summarize a wrapper of mixture proportion estimation in Algorithm 1.,3.2. Class-Prior Estimation from Pairwise Similarity and Unlabeled Data,[0],[0]
"In this section, we establish an estimation error bound for the proposed method.",4. Estimation Error Bound,[0],[0]
"Hereafter, let F ⇢ RX be a function class of a specified model.
",4. Estimation Error Bound,[0],[0]
Definition 1.,4. Estimation Error Bound,[0],[0]
"Let n be a positive integer, Z1, . . .",4. Estimation Error Bound,[0],[0]
", Zn be i.i.d.",4. Estimation Error Bound,[0],[0]
"random variables drawn from a probability distribution with density µ, H = {h : Z !",4. Estimation Error Bound,[0],[0]
"R} be a class of measurable functions, and = ( 1, . . .",4. Estimation Error Bound,[0],[0]
",",4. Estimation Error Bound,[0],[0]
"n) be Rademacher variables, i.e., random variables taking +1 and 1 with even probabilities.",4. Estimation Error Bound,[0],[0]
Then (expected),4. Estimation Error Bound,[0],[0]
"Rademacher complexity of H is defined as
R(H;n, µ) , E Z1,...,Zn⇠µ E
"" sup
h2H 1 n
nX
i=1
ih(Zi)
# .
4",4. Estimation Error Bound,[0],[0]
"Given a distribution F which is a convex combination of distributions G and H such that F = (1 )G+H , the mixture proportion estimation problem is to estimate  2 [0, 1] only with samples from F and H .",4. Estimation Error Bound,[0],[0]
"In our case, F , H , and  correspond to p(x), epS(x), and ⇡S, respectively.",4. Estimation Error Bound,[0],[0]
"See, e.g., Scott (2015).
",4. Estimation Error Bound,[0],[0]
"In this section, we assume for any probability density µ, our model class F satisfies
R(F ;n, µ)  CFp",4. Estimation Error Bound,[0],[0]
"n
(13)
for some constant CF > 0.",4. Estimation Error Bound,[0],[0]
This assumption is reasonable because many model classes such as the linear-inparameter model class F = {f(x) =,4. Estimation Error Bound,[0],[0]
"w> (x) | kwk  C
w , k k1  C }",4. Estimation Error Bound,[0],[0]
"(Cw and C are positive constants) satisfy it (Mohri et al., 2012).
",4. Estimation Error Bound,[0],[0]
"Subsequently, let f⇤ , arg min f2F R(f) be the true risk minimizer, and bf , arg min f2F bRSU,`(f) be the empirical risk minimizer.
",4. Estimation Error Bound,[0],[0]
Theorem 4.,4. Estimation Error Bound,[0],[0]
"Assume the loss function ` is ⇢-Lipschitz with respect to the first argument (0 < ⇢ < 1), and all functions in the model class F are bounded, i.e., there exists a constant Cb",4. Estimation Error Bound,[0],[0]
such that kfk1  Cb for any f 2 F .,4. Estimation Error Bound,[0],[0]
"Let C` , supt2{±1} `(Cb, t).",4. Estimation Error Bound,[0],[0]
"For any > 0, with probability at least 1 ,
R( bf) R(f⇤)  CF,`, ✓
2⇡Sp 2nS + 1p nU
◆ , (14)
where
CF,`, = 4⇢CF +
q 2C2` log 4
|2⇡+ 1| .
",4. Estimation Error Bound,[0],[0]
"A proof is given in Appendix F.
Theorem 4 shows that if we have ⇡+ in advance, our proposed method is consistent, i.e., R( bf) !",4. Estimation Error Bound,[0],[0]
R(f⇤) as nS !,4. Estimation Error Bound,[0],[0]
1 and nU !,4. Estimation Error Bound,[0],[0]
1.,4. Estimation Error Bound,[0],[0]
"The convergence rate is Op(1/ p nS + 1/ p nU), where Op denotes the order in probability.",4. Estimation Error Bound,[0],[0]
"This order is the optimal parametric rate for the empirical risk minimization without additional assumptions (Mendelson, 2008).",4. Estimation Error Bound,[0],[0]
"In this section, we empirically investigate the performance of class-prior estimation and the proposed method for SU classification.
",5. Experiments,[0],[0]
"Datasets: Datasets are obtained from the UCI Machine Learning Repository (Lichman, 2013), the LIBSVM (Chang & Lin, 2011), and the ELENA project 5.",5. Experiments,[0],[0]
"We randomly subsample the original datasets, to maintain that similar pairs consist of positive and negative pairs with the ratio of ⇡2+ to ⇡2 (see Eq.",5. Experiments,[0],[0]
"(2)), while the ratios of unlabeled and test data are ⇡+ to ⇡ (see Eq. (3)).
5 https://www.elen.ucl.ac.be/neural-nets/
Research/Projects/ELENA/elena.htm",5. Experiments,[0],[0]
"First, we study empirical performance of class-prior estimation.",5.1. Class-Prior Estimation,[0],[0]
We conduct experiments on benchmark datasets.,5.1. Class-Prior Estimation,[0],[0]
"Different dataset sizes {200, 400, 800, 1600} are tested, where half of the data are S pairs and the other half are U data.
",5.1. Class-Prior Estimation,[0],[0]
"In Figure 4, KM1 and KM2 are plotted, which are proposed by Ramaswamy et al. (2016).",5.1. Class-Prior Estimation,[0],[0]
We used them as CPE in Algorithm 1 6.,5.1. Class-Prior Estimation,[0],[0]
"Since ⇡S = ⇡2++⇡2 = 2(⇡+ 12 )2+ 1 2 1 2 , we use additional heuristic to set left = 2 in Algorithm 1 of Ramaswamy et al. (2016).",5.1. Class-Prior Estimation,[0],[0]
We empirically investigate our proposed method in terms of the relationship between classification performance and the number of training data.,5.2. Classification Complexity,[0],[0]
"We conduct experiments on benchmark datasets with the fixed number of S pairs (fixed to 200), and the different numbers of U data {200, 400, 800, 1600}.",5.2. Classification Complexity,[0],[0]
The experimental results are shown in Figure 5.,5.2. Classification Complexity,[0],[0]
"It indicates that the classification error decreases as nU grows, which well agree with our theoretical analysis in Theorem 4.",5.2. Classification Complexity,[0],[0]
"Furthermore, we observe a tendency that classification error becomes smaller as the class-prior becomes farther from 12 .",5.2. Classification Complexity,[0],[0]
"This is because CF,`, in Eq.",5.2. Classification Complexity,[0],[0]
"(14) has the term |2⇡+ 1| in the denominator, which will make the upper bound looser when ⇡+ is close to 12 .
",5.2. Classification Complexity,[0],[0]
The detailed setting about the proposed method is described below.,5.2. Classification Complexity,[0],[0]
"Our implementation is available at https:// github.com/levelfour/SU_Classification.
",5.2. Classification Complexity,[0],[0]
Proposed Method (SU): We use the linear-in-input model f(x) = w>x + b.,5.2. Classification Complexity,[0],[0]
"In Section 5.2, the squared loss is used, and ⇡+ is given (Case 1 in Table 3).",5.2. Classification Complexity,[0],[0]
"In Section 5.3, the squared loss and the double-hinge loss are used, and the class-prior is estimated by Algorithm 1 with KM2 (Ramaswamy et al., 2016) (Case 2 in Table 3).",5.2. Classification Complexity,[0],[0]
"The regulariza-
6We used the author’s implementations published in http://web.eecs.umich.edu/
˜
cscott/code/
kernel_CPE.zip.
tion parameter is chosen from {10 1, 10 4, 10 7}.",5.2. Classification Complexity,[0],[0]
"To choose hyperparameters, 5-fold cross-validation is used.",5.2. Classification Complexity,[0],[0]
"Since we do not have any labeled data in the training phase, the validation error cannot be computed directly.",5.2. Classification Complexity,[0],[0]
"Instead, Eq. (5) equipped with the zero-one loss `01(·) = 12 (1 sign(·)) is used as a proxy to estimate the validation error.",5.2. Classification Complexity,[0],[0]
"In each experimental trial, the model with minimum validation error is chosen.",5.2. Classification Complexity,[0],[0]
We compare our proposed method with baseline methods on benchmark datasets.,5.3. Benchmark Comparison with Baseline Methods,[0],[0]
"We conduct experiments on each dataset with 500 similar data pairs, 500 unlabeled data, and 100 test data.",5.3. Benchmark Comparison with Baseline Methods,[0],[0]
"As can be seen from Table 4, our proposed method outperforms baselines for many datasets.",5.3. Benchmark Comparison with Baseline Methods,[0],[0]
"The details about the baseline methods are described below.
",5.3. Benchmark Comparison with Baseline Methods,[0],[0]
"Baseline 1 (KM): As a simple baseline, we consider kmeans clustering (MacQueen, 1967).",5.3. Benchmark Comparison with Baseline Methods,[0],[0]
"We ignore pair information of S data and apply k-means clustering with k = 2 to U data.
",5.3. Benchmark Comparison with Baseline Methods,[0],[0]
"Baseline 2 (ITML): Information-theoretic metric learning (Davis et al., 2007) is a metric learning method by regularizing the covariance matrix based on prior knowledge, with pairwise constraints.",5.3. Benchmark Comparison with Baseline Methods,[0],[0]
"We use the identity matrix as prior knowledge, and the slack variable parameter is fixed to = 1, since we cannot employ the cross-validation without any class label information.",5.3. Benchmark Comparison with Baseline Methods,[0],[0]
"Using the obtained metric, k-means clustering is applied on test data.
",5.3. Benchmark Comparison with Baseline Methods,[0],[0]
"Baseline 3 (SERAPH): Semi-supervised metric learning paradigm with hyper sparsity (Niu et al., 2012) is another metric learning method based on entropy regularization.",5.3. Benchmark Comparison with Baseline Methods,[0],[0]
Hyperparameter choice follows SERAPHhyper.,5.3. Benchmark Comparison with Baseline Methods,[0],[0]
"Using the obtained metric, k-means clustering is applied on test data.
",5.3. Benchmark Comparison with Baseline Methods,[0],[0]
"Baseline 4 (3SMIC): Semi-supervised SMI-based clustering (Calandriello et al., 2014) models class-posteriors and maximizes mutual information between unlabeled data at hand and their cluster labels.",5.3. Benchmark Comparison with Baseline Methods,[0],[0]
"The penalty parameter and the kernel parameter t are chosen from {10 2, 100, 102} and {4, 7, 10}, respectively, via 5-fold cross-validation.",5.3. Benchmark Comparison with Baseline Methods,[0],[0]
"Baseline 5 (DIMC): DirtyIMC (Chiang et al., 2015) is a noisy version of inductive matrix completion, where the similarity matrix is recovered from a low-rank feature matrix.",5.3. Benchmark Comparison with Baseline Methods,[0],[0]
"Similarity matrix S is assumed to be expressed as UU>, where U is low-rank feature representations of input data.",5.3. Benchmark Comparison with Baseline Methods,[0],[0]
"After obtaining U , k-means clustering is conducted on U .",5.3. Benchmark Comparison with Baseline Methods,[0],[0]
"Two hyperparameters M , N in Eq.",5.3. Benchmark Comparison with Baseline Methods,[0],[0]
"(2) in (Chiang et al., 2015) are set to M = N = 10 2.
",5.3. Benchmark Comparison with Baseline Methods,[0],[0]
Baseline 6 (IMSAT):,5.3. Benchmark Comparison with Baseline Methods,[0],[0]
"Information maximizing selfaugmented training (Hu et al., 2017) is an unsupervised learning method to make a probabilistic classifier that maps
similar data to similar representations, combining information maximization clustering with self-augmented training, which make the predictions of perturbed data close to the predictions of the original ones.",5.3. Benchmark Comparison with Baseline Methods,[0],[0]
"Instead of data perturbation, self-augmented training can be applied on S data to make each pair of data similar.",5.3. Benchmark Comparison with Baseline Methods,[0],[0]
"Here the logistic regressor p ✓
(y|x)",5.3. Benchmark Comparison with Baseline Methods,[0],[0]
= (1 + exp( ✓>x)),5.3. Benchmark Comparison with Baseline Methods,[0],[0]
"1 is used as a classification model, where ✓ is parameters to learn.",5.3. Benchmark Comparison with Baseline Methods,[0],[0]
"Trade-off parameter is set to 1.
",5.3. Benchmark Comparison with Baseline Methods,[0],[0]
"Remark: KM, ITML, and SERAPH rely on k-means, which is trained by using only training data.",5.3. Benchmark Comparison with Baseline Methods,[0],[0]
Test prediction is based on the metric between test data and learned cluster centers.,5.3. Benchmark Comparison with Baseline Methods,[0],[0]
"Among the baselines, DIMC can only handle insample prediction, so it is trained by using both training and test data at the same time.",5.3. Benchmark Comparison with Baseline Methods,[0],[0]
"In this paper, we proposed a novel weakly-supervised learning problem named SU classification, where only similar pairs and unlabeled data are needed.",6. Conclusion,[0],[0]
SU classification even becomes class-identifiable under a certain condition on the class-prior (see Table 3).,6. Conclusion,[0],[0]
Its optimization problem with the linear-in-parameter model becomes convex if we choose certain loss functions such as the squared loss and the doublehinge loss.,6. Conclusion,[0],[0]
"We established an estimation error bound for the proposed method, and confirmed that the estimation error decreases with the parametric optimal order, as the number of similar data and unlabeled data becomes larger.",6. Conclusion,[0],[0]
We also investigated the empirical performance and confirmed that our proposed method performs better than baseline methods.,6. Conclusion,[0],[0]
"This work was supported by JST CREST JPMJCR1403 including the AIP challenge program, Japan.",Acknowledgements,[0],[0]
We thank Ryuichi Kiryo for fruitful discussions on this work.,Acknowledgements,[0],[0]
"Supervised learning needs a huge amount of labeled data, which can be a big bottleneck under the situation where there is a privacy concern or labeling cost is high.",abstractText,[0],[0]
"To overcome this problem, we propose a new weakly-supervised learning setting where only similar (S) data pairs (two examples belong to the same class) and unlabeled (U) data points are needed instead of fully labeled data, which is called SU classification.",abstractText,[0],[0]
"We show that an unbiased estimator of the classification risk can be obtained only from SU data, and the estimation error of its empirical risk minimizer achieves the optimal parametric convergence rate.",abstractText,[0],[0]
"Finally, we demonstrate the effectiveness of the proposed method through experiments.",abstractText,[0],[0]
Classification from Pairwise Similarity and Unlabeled Data,title,[0],[0]
"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 1–6 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics
https://doi.org/10.18653/v1/P17-2001",text,[0],[0]
"Recently, the need for extracting temporal information from text is motivated rapidly by many NLP tasks such as: question answering (QA), information extraction (IE), etc.",1 Introduction,[0],[0]
"Along with the TimeBank1 (Pustejovsky et al., 2003) and other temporal information annotated corpora, a series of temporal evaluation challenges (TempEval1,2,3) (Verhagen et al., 2009, 2010; UzZaman et al., 2012) are attracting growing research efforts.
",1 Introduction,[0],[0]
Temporal relation classification is a task to identify the pairs of temporal entities (events or temporal expressions) that have a temporal link and classify the temporal relations between them.,1 Introduction,[0],[0]
"For instance, we show an event-event (E-E) link with ‘DURING’ type in (i), an event-time (E-T) link
1https://catalog.ldc.upenn.edu/LDC2006T08
with ‘INCLUDES’ type in (ii) and an event-DCT (document creation time, E-D) with ‘BEFORE’ type in (iii).
",1 Introduction,[0],[0]
(i),1 Introduction,[0],[0]
"There was no hint of trouble in the last conversation between controllers and TWA pilot Steven Snyder.
(ii) In Washington today, the Federal Aviation Administration released air traffic control tapes.
",1 Introduction,[0],[0]
"(iii) The U.S. Navy has 27 ships in the maritime barricade of Iraq.
",1 Introduction,[0],[0]
Marcu and Echihabi (2002) propose an approach considering word-based pairs as useful features.,1 Introduction,[0],[0]
"The following researchers (Laokulrat et al., 2013; Chambers et al., 2014; Mani et al., 2006; D’Souza and Ng, 2013) focus on extracting lexical, syntactic or semantic information from various external knowledge bases such as: WordNet (Miller, 1995) and VerbOcean (Chklovski and Pantel, 2004).",1 Introduction,[0],[0]
"However, these feature based methods rely on hand-crafted efforts and external resources.",1 Introduction,[0],[0]
"In addition, these works require the features of entity attributes (class, tense, polarity, etc.), which are manually annotated to achieve high performance.",1 Introduction,[0],[0]
"Consequently, they are hard to obtain in practical application scenarios.
",1 Introduction,[0],[0]
"In relation extraction, there is an explosion of the works done with the dependency path (DP) based methods, which employ various models along dependency paths (Bunescu and Mooney, 2005; Plank and Moschitti, 2013).",1 Introduction,[0],[0]
"In recent years, the DP-based neural networks (Socher et al., 2011; Xu et al., 2015a,b) show state-of-the-art performance, with less requirements on explicit features.",1 Introduction,[0],[0]
"Intuitively, the DP-based approaches have the potential to classify temporal relations.
",1 Introduction,[0],[0]
"Both relation extraction and temporal relation classification require the identification of relation-
1
ship between entities in texts.",1 Introduction,[0],[0]
"However, temporal relation classification is more challenging, since it includes three different type of entities: ‘event’, ‘time expression’ and DCT.",1 Introduction,[0],[0]
Cross-sentence links also add additional complexity into the task.,1 Introduction,[0],[0]
"Due to the outstanding performance of DP-based neural networks revealed in relation extraction, we borrow this state-of-the-art approach to temporal relation classification.
",1 Introduction,[0],[0]
"In Section 2 of this paper, we review related work and introduce TimeBank-Dense.",1 Introduction,[0],[0]
"We discuss the cross-sentence link problem and the architectures of our E-E, E-T and E-D classifiers in Section 3.",1 Introduction,[0],[0]
"In Section 4, the experiments are performed on TimeBank-Dense and we compare our model to the baseline and two state-of-the-art systems.",1 Introduction,[0],[0]
The final conclusion is made in Section 5.,1 Introduction,[0],[0]
Current state-of-the-art temporal relation classifiers exploit a variety of features.,2.1 Related Work,[0],[0]
Laokulrat et al. (2013); Chambers et al. (2014) extract lexical and morphological features derived from WordNet synsets.,2.1 Related Work,[0],[0]
Mani et al. (2006); D’Souza and Ng (2013) incorporate semantic relations between verbs from VerbOcean as features.,2.1 Related Work,[0],[0]
"In addition, most of the systems include the entity attributes (Figure 1) specified in TimeML 2 as basic features, which actually need heavy human annotations.
",2.1 Related Work,[0],[0]
"In this work, we push this work into a more practical level by using only word, part-of-speech (POS), dependency parsing information, without incorporating entity attributes, as well as any other external resources.
",2.1 Related Work,[0],[0]
"In relation extraction, Bunescu and Mooney (2005) propose an observation that a relation can be captured by the shortest dependency path
2http://timeml.org/
(SDP) between the two entities in the entire dependency graph.",2.1 Related Work,[0],[0]
Plank and Moschitti (2013) extract syntactic and semantic information in a tree kernel.,2.1 Related Work,[0],[0]
"Following this line, researchers (Socher et al., 2011; Xu et al., 2015a,b) achieve state-of-the-art performance by building various neural networks over dependency path.
",2.1 Related Work,[0],[0]
Our system is similar to the work by Xu et al. (2015b).,2.1 Related Work,[0],[0]
They perform LSTM with max pooling separately on each feature channel along dependency path.,2.1 Related Work,[0],[0]
"In contrast, our system adopts bidirectional LSTM on the concatenation of feature embeddings.",2.1 Related Work,[0],[0]
"In the original TimeBank, temporal links have been created on those pairs with semantic connections, which led to a sparse annotation style.",2.2 TimeBank-Dense,[0],[0]
Cassidy et al. (2014) 3 propose a mechanism to force annotators to create complete graphs over the entities in neighboring sentences.,2.2 TimeBank-Dense,[0],[0]
"Compared to 6,418 links in 183 TimeBank documents, TimeBankDense achieves greater density with 12,715 links in 36 documents.
",2.2 TimeBank-Dense,[0],[0]
"We follow a similar experiment setting to the other two systems (Mirza and Tonelli, 2016; Chambers et al., 2014) with the same 9 documents
3https://www.usna.edu/Users/cs/nchamber/caevo
as test data and the others as training data (15% of training data is split as validation data for early stopping).",2.2 TimeBank-Dense,[0],[0]
"Intuitively, the dependency path based idea can be introduced into the temporal relation classification task.",3.1 Cross-sentence Dependency Paths,[0],[0]
"However, around 64% E-E, E-T links in TimeBank-Dense are with the ends in two neighboring sentences, called cross-sentence links.
",3.1 Cross-sentence Dependency Paths,[0],[0]
A crucial obstacle is how to represent the dependency path of a cross-sentence link.,3.1 Cross-sentence Dependency Paths,[0],[0]
"In this work, we make a naive assumption that two neighboring sentences share a “common root”.",3.1 Cross-sentence Dependency Paths,[0],[0]
"Therefore, a cross-sentence dependency path can be represented as two shortest dependency path branches from the ends to the “common root”, as shown in Figure 2.
",3.1 Cross-sentence Dependency Paths,[0],[0]
Stanford CoreNLP4 is used to parsing syntactic structures of sentences in this work.,3.1 Cross-sentence Dependency Paths,[0],[0]
"Long short-term memory (LSTM) (Hochreiter and Schmidhuber, 1997) is a natural choice for processing sequential dependency paths.",3.2 Temporal Relation Classifiers,[0],[0]
"As the reversed order also takes useful information, a backward representation can be achieved by feeding LSTM with the same input in reverse.",3.2 Temporal Relation Classifiers,[0],[0]
"We adopt the concatenation of the forward and backward LSTMs outputs, referred to as bidirectional LSTM (Graves and Schmidhuber, 2005).
",3.2 Temporal Relation Classifiers,[0],[0]
"Figure 3a shows the neural network architecture of our E-E, E-T classifier.",3.2 Temporal Relation Classifiers,[0],[0]
"Given an E-E or E-T temporal link, our system first generates two SDP branches: 1) the source entity to common root, 2) the target entity to common root.",3.2 Temporal Relation Classifiers,[0],[0]
"For each word along a SDP branch, concatenation of word, POS and dependency relation (DEP) embeddings (word-level) is fed into Bi-LSTM.",3.2 Temporal Relation Classifiers,[0],[0]
"The forward and backward outputs of both source and target branches are all concatenated, and fed into a fully connected hidden units layer.",3.2 Temporal Relation Classifiers,[0],[0]
The final Softmax layer generates multi-class predictions.,3.2 Temporal Relation Classifiers,[0],[0]
"Since an E-D link contains single event SDP branch, our system applies a similar architecture, but with single branch Bi-LSTM with outputs fed into the penultimate hidden layer, as shown in Figure 3b.
",3.2 Temporal Relation Classifiers,[0],[0]
"In this work, we use word2vec5",3.2 Temporal Relation Classifiers,[0],[0]
"(Mikolov et al., 4http://stanfordnlp.github.io/CoreNLP/",3.2 Temporal Relation Classifiers,[0],[0]
"5https://code.google.com/archive/p/word2vec/
2013a,b) to train 200-dimensions word embeddings on English Gigaword 4th edition with skipgram model and other default settings.",3.2 Temporal Relation Classifiers,[0],[0]
"For either of POS or DEP, we adopt the 50-dimensions lookup table initialized randomly.",3.2 Temporal Relation Classifiers,[0],[0]
"The grid search exploring a full hyper-parameter space takes time for three classifiers (E-E, E-T and E-D).",4.1 Hyper-parameters and Cross-validation,[0],[0]
"Empirically, we set each single LSTM output with the same dimensions (equal to 300) as the concatenation of word, POS, DEP embeddings.",4.1 Hyper-parameters and Cross-validation,[0],[0]
"The hidden layer is set as 200-dimensions.
",4.1 Hyper-parameters and Cross-validation,[0],[0]
"Our system adopts dependency paths as input, which means that the entities in the same sentences contain highly covered word sequence input.",4.1 Hyper-parameters and Cross-validation,[0],[0]
Simple cross-validation (CV) on links can not reflect the generalization ability of our model correctly.,4.1 Hyper-parameters and Cross-validation,[0],[0]
We use a grouped 5-fold CV based on the source entity ids (document id + sentence id) of links.,4.1 Hyper-parameters and Cross-validation,[0],[0]
This schema can reduce bias separately in either the source SDP or the target SDP.,4.1 Hyper-parameters and Cross-validation,[0],[0]
"Although document level CV can avoid this issue, it’s not feasible for TimeBank-Dense because it contains only 27 training documents.
",4.1 Hyper-parameters and Cross-validation,[0],[0]
Early stopping is used to save the best model based on the validation data.,4.1 Hyper-parameters and Cross-validation,[0],[0]
"In each run of the 5-fold cross-validation, we split 80% of ‘original training’ as ‘tentative training’ and 20% as ‘tentative test’.",4.1 Hyper-parameters and Cross-validation,[0],[0]
85% of ‘tentative training’ is used to learning and 15% is used for validation.,4.1 Hyper-parameters and Cross-validation,[0],[0]
We also adopt early stopping in the final system on the validation data (15% of ‘original training’).,4.1 Hyper-parameters and Cross-validation,[0],[0]
"The patience is set as 10.
",4.1 Hyper-parameters and Cross-validation,[0],[0]
"Dropout (Srivastava et al., 2014) recently is proved to be an useful approach to prevent neural networks from over-fitting.",4.1 Hyper-parameters and Cross-validation,[0],[0]
"We adopt dropout
separately after the following layers: embeddings, LSTM, and hidden layer to investigate the impact of dropout on performance.",4.1 Hyper-parameters and Cross-validation,[0],[0]
Table 1 shows the best CV results recorded in tuning dropout.,4.1 Hyper-parameters and Cross-validation,[0],[0]
The hyperparameter setting with the best CV performance is adopted in the final system.,4.1 Hyper-parameters and Cross-validation,[0],[0]
"Recently, Mirza and Tonelli (2016) report state-ofthe-art performance on TimeBank-Dense.",4.2 Overall Performance,[0],[0]
They show the new attempt to mine the value of lowdimensions word embeddings by concatenating them with sparse traditional features.,4.2 Overall Performance,[0],[0]
"Their traditional features include entity attributes, temporal signals, semantic information of WordNet, etc., which means it’s a hard setting for challenging their performance.",4.2 Overall Performance,[0],[0]
"In Table 2 and 3, ‘Mirza’ denotes their system.
",4.2 Overall Performance,[0],[0]
"Table 2 shows the detailed comparison to
their work.",4.2 Overall Performance,[0],[0]
"Our system achieves higher performance on ‘AFTER’, ‘VAGUE’, while lower on ‘BEFORE’, ‘INCLUDES’ (5% of all data) and ‘IS INCLUDED’ (4% of all data).",4.2 Overall Performance,[0],[0]
It is likely that their rich traditional features help the classifiers to capture more minority-class links.,4.2 Overall Performance,[0],[0]
"On the whole, our system reaches better ‘Overall’ on both E-E and E-D. As their E-T classifier does not include word embeddings, the E-T results are not listed.
",4.2 Overall Performance,[0],[0]
The final comparison is shown in Table 3.,4.2 Overall Performance,[0],[0]
"An one-layer fully connected hidden units baseline (200-dimensions) with word, POS embeddings as input (without any dependency information) is provided.",4.2 Overall Performance,[0],[0]
The significant out-performance of our proposed model over the baseline indicates the effectiveness of the dependency path information and our Bi-LSTM in classifying temporal links.,4.2 Overall Performance,[0],[0]
"As a hybrid system, ‘CAEVO’ (Chambers et al., 2014) includes hand-crafted rules for their E-T and E-D classifiers.",4.2 Overall Performance,[0],[0]
"For instance, the temporal prepositions in, on, over, during, and within indicate ‘IN INCLUDED’ relations.",4.2 Overall Performance,[0],[0]
"Their system is superior in E-T and E-D. ’Miza’ takes the pure feature-
based methods and performs slightly better in EE and overall, compared to ‘CAEVO’.",4.2 Overall Performance,[0],[0]
Our system shows the highest scores in E-E and overall among the four systems.,4.2 Overall Performance,[0],[0]
"In general, our system achieves comparable performance to two state-ofthe-art systems, without using any hand-crafted features, rules, or external resources.",4.2 Overall Performance,[0],[0]
We borrow the idea of the dependency path based neural networks into temporal relation classification.,5 Conclusion,[0],[0]
A “common root” assumption adapts our model to cross-sentence links.,5 Conclusion,[0],[0]
Our model adopts bidirectional LSTM for capturing both forward and backward orders information.,5 Conclusion,[0],[0]
We observe the significant benefit of the DP-based Bi-LSTM model by comparing it to the baseline.,5 Conclusion,[0],[0]
"Our model achieves comparable performance to two state-ofthe-art systems without using any explicit features (class, tense, polarity, etc.) or external resources, which indicates that our model can capture such information automatically.",5 Conclusion,[0],[0]
We thank the anonymous reviewers for the insightful comments.,6 Acknowledgments,[0],[0]
Temporal relation classification is becoming an active research field.,abstractText,[0],[0]
"Lots of methods have been proposed, while most of them focus on extracting features from external resources.",abstractText,[0],[0]
Less attention has been paid to a significant advance in a closely related task: relation extraction.,abstractText,[0],[0]
"In this work, we borrow a state-of-the-art method in relation extraction by adopting bidirectional long short-term memory (BiLSTM) along dependency paths (DP).",abstractText,[0],[0]
We make a “common root” assumption to extend DP representations of cross-sentence links.,abstractText,[0],[0]
"In the final comparison to two stateof-the-art systems on TimeBank-Dense, our model achieves comparable performance, without using external knowledge and manually annotated attributes of entities (class, tense, polarity, etc.).",abstractText,[0],[0]
Classifying Temporal Relations by Bidirectional LSTM over Dependency Paths,title,[0],[0]
"The Gamma-Poisson (GaP) model is a probabilistic matrix factorization model which was introduced in the field of text information retrieval (Canny, 2004; Buntine & Jakulin, 2006).",1. Introduction,[0],[0]
"In this field, a corpus of text documents is typically represented by an integer-valued matrix V of size F × N , where each column vn represents a document as a so-called “bag of words”.",1. Introduction,[0],[0]
"Given a vocabulary of F words (or in practice semantic stems), the matrix entry vfn is the number of occurrences of word f in the document n. GaP is a generative model described by a dictionary of “topics” or “patterns” W (a non-negative matrix of size F ×K) and a nonnegative “activation” or “score” matrix H (of size K×N ), as follows:
H ∼ ∏ k,n Gamma(hkn|αk, βk), (1)
V|H ∼ ∏ f,n Poisson (vfn|[WH]fn) , (2)
1IRIT, Université de Toulouse, CNRS, France.",1. Introduction,[0],[0]
"Correspondence to: Louis Filstroff <louis.filstroff@irit.fr>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
where we use the shape and rate parametrization of the Gamma distribution, i.e., Gamma(x|α, β) = βα Γ(α)x α−1e−βx.",1. Introduction,[0],[0]
"The dictionary W is treated as a free deterministic variable.
",1. Introduction,[0],[0]
"Though this generative model takes its origins in text information retrieval, it has found applications (with variants) in other areas such as image reconstruction (Cemgil, 2009), collaborative filtering (Ma et al., 2011; Gopalan et al., 2015) or audio signal processing (Virtanen et al., 2008).
",1. Introduction,[0],[0]
Denoting α =,1. Introduction,[0],[0]
"[α1, . . .",1. Introduction,[0],[0]
", αK ]T , β =",1. Introduction,[0],[0]
"[β1, . . .",1. Introduction,[0],[0]
", βK ]T , and treating the shape parameters αk as fixed hyperparameters, maximum joint likelihood estimation (MJLE) in GaP amounts to the minimization of
CJL(W,H,β) def = − log p(V,H|W,β) (3) = DKL(V|WH) +Rα(H,β) + cst (4)
where DKL(·|·) is the generalized Kullback-Leibler (KL) divergence defined by
DKL(V|V̂) = ∑ f,n ( vfn log ( vfn v̂fn )",1. Introduction,[0],[0]
"− vfn + v̂fn ) (5)
and
Rα(H,β) =∑ k,n",1. Introduction,[0],[0]
[(1− αk) log(hkn) + βkhkn]−N,1. Introduction,[0],[0]
"∑ k αk log βk.
",1. Introduction,[0],[0]
"(6)
Equation (4) shows that MJLE is tantamount to penalized KL non-negative matrix factorization (NMF) (Lee & Seung, 2000) and may be addressed using alternating majorization-minimization (Canny, 2004; Févotte & Idier, 2011; Dikmen & Févotte, 2012).
",1. Introduction,[0],[0]
"As explained in Dikmen & Févotte (2012), MJLE can be criticized from a statistical point of view.",1. Introduction,[0],[0]
"Indeed, the number of estimated parameters grows with the number of samples N (this is because H has as many columns as V).",1. Introduction,[0],[0]
"To overcome this issue, they have instead proposed to consider maximum marginal likelihood estimation (MMLE), in which H is treated as a latent variable over which the
joint likelihood is integrated.",1. Introduction,[0],[0]
"In other words, MMLE relies on the minimization of
CML(W,β) def = − log p(V|W,β) (7) =",1. Introduction,[0],[0]
"− log ∫
H p(V|H,W,β)p(H|β)dH. (8)
We emphasize that MMLE treats the dictionary W as a free deterministic variable.",1. Introduction,[0],[0]
"This is in contrast with fully Bayesian approaches where W is given a prior, and where estimation revolves around the posterior p(W,H|V).",1. Introduction,[0],[0]
"For instance, Buntine & Jakulin (2006) place a Dirichlet prior on the columns of W, while Cemgil (2009) considers independent Gamma priors.",1. Introduction,[0],[0]
"Zhou et al. (2012), Zhou & Carin (2015) set a Dirichlet prior on the columns of W and a Gamma-based non-parametric Bayesian prior on H, which allows for possible rank estimation.
",1. Introduction,[0],[0]
Dikmen & Févotte (2012) assumed that a closed-form expression of CML was not available.,1. Introduction,[0],[0]
"Besides, they proposed variational and Monte Carlo Expectation-Maximization (MCEM) algorithms based on a complete set formed by H and a set of other latent components C that will later be defined.",1. Introduction,[0],[0]
"In their experiments, they found MMLE to be robust to over-specified values of K, while MJLE clearly overfit.",1. Introduction,[0],[0]
This intriguing (and advantageous) behavior was left unexplained.,1. Introduction,[0],[0]
"In this paper, we provide the following contributions:
• We provide a computable closed-form expression of CML.",1. Introduction,[0],[0]
"The expression is tedious to compute for large F and K, as it involves combinatorial operations, but is workable for reasonably dimensioned problems.
",1. Introduction,[0],[0]
"• We show that the proposed closed-form expression reveals a penalization term on the columns of W that explains the “self-regularization” effect observed in Dikmen & Févotte (2012).
",1. Introduction,[0],[0]
"• We show that the marginalization of H allows to derive a new MCEM algorithm with favorable properties.
",1. Introduction,[0],[0]
The rest of the paper is organized as follows.,1. Introduction,[0],[0]
"Section 2 introduces preliminary material (composite form of GaP, useful probability distributions).",1. Introduction,[0],[0]
"In Section 3, we propose two new parameterizations of the GaP model in which H has been marginalized.",1. Introduction,[0],[0]
This yields a closed-form expression of CML which is discussed in Section 4.,1. Introduction,[0],[0]
"Finally, a new MCEM algorithm is introduced in Section 5 and is compared to the MCEM algorithms proposed in Dikmen & Févotte (2012) on synthetic and real data.",1. Introduction,[0],[0]
"GaP can be written as a composite model, thanks to the superposition property of the Poisson distribution (Févotte & Cemgil, 2009):
hkn ∼ Gamma(αk, βk) (9) ckn|hkn ∼ ∏",2.1. Composite structure of GaP,[0],[0]
f,2.1. Composite structure of GaP,[0],[0]
"Poisson(cfkn|wfkhkn) (10)
vn = ∑ k ckn (11)
",2.1. Composite structure of GaP,[0],[0]
The vectors ckn =,2.1. Composite structure of GaP,[0],[0]
"[c1kn, . . .",2.1. Composite structure of GaP,[0],[0]
", cFkn]T of size F and which sum up to vn are referred to as components.",2.1. Composite structure of GaP,[0],[0]
"In the remainder, C will denote the F ×K ×N tensor with coefficients cfkn.",2.1. Composite structure of GaP,[0],[0]
"In this section, we introduce two probability distributions that will be used later in the article.",2.2. Negative Binomial and Negative Multinomial distributions,[0],[0]
A discrete random variable X is said to have a negative binomial (NB) distribution with parameters α > 0,2.2.1. NEGATIVE BINOMIAL DISTRIBUTION,[0],[0]
(called the dispersion or shape parameter) and p ∈,2.2.1. NEGATIVE BINOMIAL DISTRIBUTION,[0],[0]
"[0, 1] if, for all c ∈ N, the probability mass function (p.m.f.) of X is given by:
P(X = c) =",2.2.1. NEGATIVE BINOMIAL DISTRIBUTION,[0],[0]
"Γ(α+ c)
Γ(α) c!",2.2.1. NEGATIVE BINOMIAL DISTRIBUTION,[0],[0]
"(1− p)αpc. (12)
",2.2.1. NEGATIVE BINOMIAL DISTRIBUTION,[0],[0]
"Its variance is αp(1−p)2 , which is larger than its mean, αp 1−p .",2.2.1. NEGATIVE BINOMIAL DISTRIBUTION,[0],[0]
It is therefore a suitable distribution to model over-dispersed count data.,2.2.1. NEGATIVE BINOMIAL DISTRIBUTION,[0],[0]
"Indeed, it offers more flexibility than the Poisson distribution where the variance and the mean are equal.
",2.2.1. NEGATIVE BINOMIAL DISTRIBUTION,[0],[0]
"The NB distribution can be obtained via a Gamma-Poisson mixture, that is:
P(X = c) = ∫ R+",2.2.1. NEGATIVE BINOMIAL DISTRIBUTION,[0],[0]
"Poisson(c|λ)Gamma(λ|α, β)dλ (13)
",2.2.1. NEGATIVE BINOMIAL DISTRIBUTION,[0],[0]
"= NB ( α, 1
β + 1
) .",2.2.1. NEGATIVE BINOMIAL DISTRIBUTION,[0],[0]
(14),2.2.1. NEGATIVE BINOMIAL DISTRIBUTION,[0],[0]
"The negative multinomial (NM) distribution (Sibuya et al., 1964) is the multivariate generalization of the NB distribution.",2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
It is parametrized by a dispersion parameter α > 0 and a vector of event probabilities p =,2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
"[p1, . . .",2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
", pF ]T , where 0 ≤ pf ≤ 1 and ∑ f pf ≤ 1.",2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
"Denoting p0 =
1− ∑ f pf , and for all (c1, . .",2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
.,2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
", cF )",2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
"∈ NF , the p.m.f.",2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
"of the NM distribution is given by
P(X1 = c1, . . .",2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
", XF = cF )",2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
"= Γ(α+
∑ f cf )
Γ(α) ∏ f cf !",2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
"pα0 ∏ f p cf f ,
(15) with expectation given by
E(X) = α",2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
"[ p1 p0 , . . .",2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
", pF p0 ]T .",2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
"(16)
In particular, the NM distribution arises in the following Gamma-Poisson mixture, as detailed in the next proposition.
",2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
Proposition 1.,2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
Let X =,2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
"[X1, . . .",2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
", XF ]T be a random vector whose entries are independent Poisson random variables.",2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
"Assume that each variable Xf is governed by the parameterwfλ, where λ is itself a Gamma random variable with parameters (α, β).",2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
"Then the joint probability distribution of X is a NM distribution with dispersion parameter α and event probabilities
p =",2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
"[ w1∑
f wf + β , . . .",2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
", wF∑ f wf",2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
"+ β
]T .",2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
"(17)
Proof.",2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
"P(X = [c1, . . .",2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
", cF ]T )
= ∫ R+ P(X1 = c1, . . .",2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
", XF = cF |λ)p(λ)dλ
= ∫ R+ ∏",2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
f (wfλ) cf e−wfλ cf !  ,2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
"βα Γ(α) λα−1e−βλdλ
= ∏ f w cf f cf !  βα Γ(α) Γ(α+ ∑ f cf )(∑ f wf + β )α+∑f",2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
"cf
= Γ(α+
∑ f cf )
Γ(α) ∏ f cf !
",2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
"( β∑
f wf + β )α∏ f ( wf∑ f wf",2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
+ β ),2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
"cf
The NM distribution can also be obtained with an alternative generative process, as shown in the following proposition.
",2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
Proposition 2.,2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
Let Y =,2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
"[Y1, . . .",2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
", YF ]T be a random vector following a multinomial distribution with number of trials L and event probabilities p =",2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
"[ w1∑
f wf , . . .",2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
", wF∑ f wf ]T .",2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
"As-
sume that L is a NB random variable with dispersion parameter α and probability p = ∑ f wf∑
f wf+β .",2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
"Then the ran-
dom vectors Y and X (as defined in Proposition 1) have the same distribution.
",2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
Proof.,2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
P(Y =,2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
"[c1, . .",2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
". , cF",2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
"]T )
",2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
= P(Y =,2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
"[c1, . .",2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
". , cF ]",2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
T |L)× P(L) =,2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
L!∏ f cf !,2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
∏,2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
"f ( wf∑ f wf )cf
× Γ(α+ L) Γ(α)L!
",2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
"( β∑
f wf + β
)α( ∑ f wf∑
f wf + β
)",2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
"L
Noting that L = ∑ f cf completes the proof.",2.2.2. NEGATIVE MULTINOMIAL DISTRIBUTION,[0],[0]
We now show how GaP can be rewritten free of the latent variables H in two different ways.,3. New formulations of GaP,[0],[0]
Theorem 1.,3.1. GaP as a composite NM model,[0],[0]
"GaP can be rewritten as follows:
ckn ∼ NM αk,[ w1k∑",3.1. GaP as a composite NM model,[0],[0]
"f wfk + βk , . . .",3.1. GaP as a composite NM model,[0],[0]
", wFk∑",3.1. GaP as a composite NM model,[0],[0]
"f wfk + βk ]T (18)
vn = ∑ k ckn (19)
Proof.",3.1. GaP as a composite NM model,[0],[0]
"Combining Equations (9)-(11) with Proposition 1 completes the proof.
",3.1. GaP as a composite NM model,[0],[0]
"GaP may thus be interpreted as a composite model in which the kth component has a NM distribution with parameters governed by wk (the kth column of W), αk and βk.",3.1. GaP as a composite NM model,[0],[0]
"Using straightforward computations, the data expectation can be expressed as
E(vn) = ∑ k E(ckn) (20)
",3.1. GaP as a composite NM model,[0],[0]
= ∑ k αk βk wk. (21),3.1. GaP as a composite NM model,[0],[0]
Theorem 2.,3.2. GaP as a composite multinomial model,[0],[0]
"GaP can be rewritten as follows:
Lkn ∼ NB ( αk, ∑ f wfk∑
f wfk + βk
) (22)
ckn ∼ Mult Lkn,[ w1k∑ f wfk , . . .",3.2. GaP as a composite multinomial model,[0],[0]
", wFk∑ f wfk ]T (23) vn =
∑ k ckn (24)
where “Mult” refers to the multinomial distribution.
",3.2. GaP as a composite multinomial model,[0],[0]
Proof.,3.2. GaP as a composite multinomial model,[0],[0]
"Combining Equations (9)-(11) with Proposition 2 completes the proof.
",3.2. GaP as a composite multinomial model,[0],[0]
"Theorem 2 states that another interpretation of GaP consists in modeling the data as a sum of k independent multinomial distributions, governed individually by wk and whose number of trials is random, following a NB distribution governed by wk, αk and βk.
",3.2. GaP as a composite multinomial model,[0],[0]
"A special case of the reformulation of GaP offered by Theorem 2 is given by Buntine & Jakulin (2006) using a different reasoning, when it is assumed that ∑ f wfk = 1 (a common assumption in the field of text information retrieval, where the columns of W are interpreted as discrete probability distributions).",3.2. GaP as a composite multinomial model,[0],[0]
Theorem 2 provides a more general result as it applies to any non-negative matrix W.,3.2. GaP as a composite multinomial model,[0],[0]
"Until now, it was assumed that the marginal likelihood in the GaP model was not available analytically.",4.1. Analytical expression,[0],[0]
"However, the new parametrization offered by Theorem 1 allows to obtain a computable analytical expression of the marginal likelihood CML.",4.1. Analytical expression,[0],[0]
"Denote by C the set of all “admissible” components, i.e.,
C = {C ∈ NF×K×N",4.1. Analytical expression,[0],[0]
"| ∀(f, n), ∑
k cfkn = vfn}.",4.1. Analytical expression,[0],[0]
"(25)
",4.1. Analytical expression,[0],[0]
"By marginalization of C, we may write
p(V|W,β) = ∑ C∈C p(C|W,β) (26)
= ∑ C∈C ∏ k,n p(ckn|W,β).",4.1. Analytical expression,[0],[0]
"(27)
Using Equation (18) we obtain
p(V|W,β) =∑ C∈C ∏ k,n",4.1. Analytical expression,[0],[0]
[ Γ( ∑ f cfkn + αk) Γ(αk),4.1. Analytical expression,[0],[0]
∏ f cfkn!,4.1. Analytical expression,[0],[0]
"( βk∑ f wfk + βk )αk
× ∏",4.1. Analytical expression,[0],[0]
"f
( wfk∑
f wfk + βk )cfkn .",4.1. Analytical expression,[0],[0]
"(28) Introducing the notations
Ωα(C) = ∏ k,n
Γ( ∑ f cfkn + αk)
Γ(αk)",4.1. Analytical expression,[0],[0]
"∏ f cfkn!
(29)
and pfk = wfk∑",4.1. Analytical expression,[0],[0]
"f wfk + βk
(30)
we may rewrite Eq.",4.1. Analytical expression,[0],[0]
"(28) as
p(V|W,β) = ∏ k",4.1. Analytical expression,[0],[0]
"(1− ∑ f pfk) Nαk  × ∑ C∈C Ωα(C)∏ f,k p ∑ n cfkn fk
 .",4.1. Analytical expression,[0],[0]
(31) Equation (31) is a computable closed-form expression of the marginal likelihood.,4.1. Analytical expression,[0],[0]
It is free of H and in particular of the integral that appears in Equation (8).,4.1. Analytical expression,[0],[0]
However the expression (31) is still semi-explicit because it involves a sum over the set of all admissible components C. C is countable set with cardinality,4.1. Analytical expression,[0],[0]
"#C = ∏ f,n ( vfn+K−1 K−1 ) .",4.1. Analytical expression,[0],[0]
"It is straightforward to construct but challenging to compute in large dimension, and for large values of vfn.
",4.1. Analytical expression,[0],[0]
The sum over all the matrices in the set C expresses the convolution of the (discrete) probability distributions of the K components.,4.1. Analytical expression,[0],[0]
"Unfortunately, the distribution of the sum of independent negative multinomial variables of different event probabilities is not available in closed form.
",4.1. Analytical expression,[0],[0]
"As already known from Dikmen & Févotte (2012), the value of the marginal likelihood is unchanged when the scales of the columns of W and the rates β are changed accordingly.",4.1. Analytical expression,[0],[0]
"Let Λ be a non-negative diagonal matrix of size K, it can easily be derived from Equation (31) that
p(V|WΛ,βΛ) = p(V|W,β).",4.1. Analytical expression,[0],[0]
"(32)
We therefore have a scaling invariance between W and β, and as such, we may fix β to arbitrary values and leave W free.",4.1. Analytical expression,[0],[0]
"Thus, we will treat β as a constant in the following and drop it from the arguments of CML.",4.1. Analytical expression,[0],[0]
Dikmen & Févotte (2012) empirically studied the properties of MMLE.,4.2. Self-regularization,[0],[0]
"In particular, they observed the self-ability of the estimator to regularize the number of columns of W. For example, one experiment consisted in generating synthetic data according to the GaP model, with a ground-truth number of componentsK?.",4.2. Self-regularization,[0],[0]
MMLE was run withK >,4.2. Self-regularization,[0],[0]
K?,4.2. Self-regularization,[0],[0]
and they noticed that the estimated W contained K −K?,4.2. Self-regularization,[0],[0]
empty columns.,4.2. Self-regularization,[0],[0]
"As such, the estimator was able to recover the ground-truth dimensionality.",4.2. Self-regularization,[0],[0]
"In contrast, MJLE used all K dimensions and overfit the data.",4.2. Self-regularization,[0],[0]
"They were unable to give a theoretical justification of the observed phenomenon, but provided a first insight thanks to a Laplace approximation of p(V|W).",4.2. Self-regularization,[0],[0]
"The closed-form expression (31) offers
a deeper understanding of this phenomenon, as explained next.
",4.2. Self-regularization,[0],[0]
"Using Equations (31) and (30) and treating β as a constant, the negative log-likelihood can be expressed as
1
N CML(W) =
− 1 N log ∑ C∈C Ωα(C)",4.2. Self-regularization,[0],[0]
∏,4.2. Self-regularization,[0],[0]
"f,k p ∑ n cfkn fk  (33) + ∑ k αk log(||wk||1 + βk) + cst, (34)
where cst = − ∑ k αk log βk.
",4.2. Self-regularization,[0],[0]
The negative log-likelihood reveals two terms.,4.2. Self-regularization,[0],[0]
"The first term, Equation (33), captures the interaction between data V (through C) and the parameter W (through the event probabilities pfk = wfk/(‖wk‖1 +βk)).",4.2. Self-regularization,[0],[0]
"The second term, Equation (34), only depends on the parameter W and can be interpreted as a group-regularization term.",4.2. Self-regularization,[0],[0]
"The nonconvex and sharply peaked function f(x) = ∑ k log(xk + b) is known to be sparsity-inducing (Candès et al., 2008).",4.2. Self-regularization,[0],[0]
"As such, the term (34) will promote sparsity of the norms of the columns of W. When a norm ||wk||1 is set to zero for some k, the whole column wk is set to zero because of the non-negativity constraint.",4.2. Self-regularization,[0],[0]
"This gives a formal explanation of the ability of MMLE to automatically prune columns of W, without any explicit sparsity-inducing prior at the modeling stage (recall that W is a deterministic parameter without a prior).",4.2. Self-regularization,[0],[0]
We now turn to the problem of optimizing Equation (8) by leveraging on the results of Section 4.,5.1. Expectation-Maximization,[0],[0]
"Despite obtaining a closed-form expression, the direct optimization of the marginal likelihood remains difficult.",5.1. Expectation-Maximization,[0],[0]
"However, the structure of GaP makes Expectation-Maximization (EM) a natural option (Dempster et al., 1977).",5.1. Expectation-Maximization,[0],[0]
"Indeed, GaP involves observed variables V and latent variables C and H. As such, we can derive several EM algorithms based on various choices of the complete set.",5.1. Expectation-Maximization,[0],[0]
"More precisely, we consider three possible choices that each define a different algorithm, as follows.
",5.1. Expectation-Maximization,[0],[0]
EM-CH.,5.1. Expectation-Maximization,[0],[0]
"The complete set is {C,H} and EM consists in the iterative minimization w.r.t W of the functional defined by QCH(W|W̃) =",5.1. Expectation-Maximization,[0],[0]
"− ∫
C,H log p(C,H|W)p(C,H|V, W̃)dCdH,
(35)
where W̃ is the current estimate.",5.1. Expectation-Maximization,[0],[0]
Note that V does not need to be included in the complete set because we have V = ∑ k Ck.,5.1. Expectation-Maximization,[0],[0]
"This corresponds to the general formulation of EM in which the relation between the complete set and the data is a many-to-one mapping and slightly differs from the more usual one where the complete set is formed by the union of data and a hidden set (Dempster et al., 1977; Févotte et al., 2011).
",5.1. Expectation-Maximization,[0],[0]
"EM-H. The complete set is {V,H} and EM consists in the iterative minimization of
QH(W|W̃) =",5.1. Expectation-Maximization,[0],[0]
"− ∫
H log p(V,H|W)p(H|V, W̃)dH. (36)
EM-C. The complete set is merely {C} and EM consists in the iterative minimization of
QC(W|W̃) =",5.1. Expectation-Maximization,[0],[0]
"− ∫
C log p(C|W)p(C|V, W̃)dC. (37)
EM-CH and EM-H have been considered in Dikmen & Févotte (2012).",5.1. Expectation-Maximization,[0],[0]
EM-C is a new proposal that exploits the results of Section 4.,5.1. Expectation-Maximization,[0],[0]
"In all three cases, the posteriors of the latent variables involved – p(C,H|V, W̃), p(H|V, W̃) and p(C|V, W̃) – are untractable and neither are the integrals involved in Equations (35), (36) and (37).",5.1. Expectation-Maximization,[0],[0]
"To overcome this problem, we resort to Monte Carlo EM (MCEM) (Wei & Tanner, 1990) as described in the next section.",5.1. Expectation-Maximization,[0],[0]
"MCEM consists in using a Monte Carlo (MC) approximation of the integrals in Equations (35), (36) and (37) based on samples drawn from the posterior distributions p(C,H|V, W̃), p(H|V, W̃) and p(C|V, W̃).",5.2. Monte Carlo E-step,[0],[0]
"These can be obtained by Gibbs sampling of the joint posterior p(C,H|V, W̃), which also returns samples from the marginals p(H|V, W̃) and p(C|V, W̃) at convergence.",5.2. Monte Carlo E-step,[0],[0]
"The Gibbs sampler can easily be derived because the conditional distributions p(H|C,V, W̃) = p(H|C, W̃) and p(C|H,V, W̃) are available in closed form.
",5.2. Monte Carlo E-step,[0],[0]
"At iteration j + 1, Gibbs sampling writes
h (j+1) kn ∼ Gamma(αk + ∑ f c",5.2. Monte Carlo E-step,[0],[0]
"(j) fkn, βk + ∑ f w̃fk) (38)
",5.2. Monte Carlo E-step,[0],[0]
"c(j+1)fn ∼ Mult ( vfn, [ ρ (j+1) f1 , . . .",5.2. Monte Carlo E-step,[0],[0]
", ρ (j+1) fK ]T) (39)
where cfn denotes the vector [cf1n, . . .",5.2. Monte Carlo E-step,[0],[0]
", cfKn]T of size K and
ρ (j+1) fk = w̃fkh (j+1) kn∑
k w̃fkh (j+1) kn
.",5.2. Monte Carlo E-step,[0],[0]
"(40)
Note that c(j+1)fn only needs to be sampled when vfn 6= 0, since c(j+1)fn =",5.2. Monte Carlo E-step,[0],[0]
"[0, . .",5.2. Monte Carlo E-step,[0],[0]
.,5.2. Monte Carlo E-step,[0],[0]
", 0] T when vfn = 0.",5.2. Monte Carlo E-step,[0],[0]
"Given a set of J samples {H(j),C(j)} drawn from p(C,H|V, W̃) (after burn-in), minimization of the MC approximation of QCH in Equation (35) yields
wMCEM-CHfk =
∑ j,n c
(j) fkn∑
j,n h (j) kn
, (41)
as shown by Dikmen & Févotte (2012).",5.3. M-step,[0],[0]
"They also show that the following multiplicative update decreases the MC approximation of QH in Equation (36) at every iteration
wMCEM-Hfk = w̃fk
∑ j,n h (j) knvfn[W̃H
(j)]−1fn∑ j,n h (j) kn .",5.3. M-step,[0],[0]
"(42)
We now derive the new update for EM-C. The MC approximation of QC in Equation (37) is given by:
Q̂C(W|W̃) def = − 1
J J∑ j=1 log p(C(j)|W).",5.3. M-step,[0],[0]
"(43)
Replacing p(C(j)|W) by its expression given by Equation (18), we obtain:
Q̂C(W|W̃)",5.3. M-step,[0],[0]
"= 1
J ∑ j,k,n
αk log ∑
f
wfk + βk  + ∑ f c",5.3. M-step,[0],[0]
(j) fkn,5.3. M-step,[0],[0]
( log (∑ f wfk + βk ) − log (wfk) ),5.3. M-step,[0],[0]
"+ cst
 .",5.3. M-step,[0],[0]
"(44)
",5.3. M-step,[0],[0]
The minimization of Q̂C w.r.t.,5.3. M-step,[0],[0]
"W leads toK linear systems of equations that we need to solve for each column wk:
Akwk = bk.",5.3. M-step,[0],[0]
"(45)
The matrix Ak ∈ RF×F is defined by:
afg = JNαk + ∑ j,f,n c (j) fkn  ",5.3. M-step,[0],[0]
"δfg −∑ j,n c",5.3. M-step,[0],[0]
"(j) fkn, (46)
where δfg is the Kronecker symbol, i.e. δfg = 1 if and only if f = g, and zero otherwise.",5.3. M-step,[0],[0]
"The vector bk ∈ RF×1 is defined by:
bfk = βk ∑ j,n c (j) fkn.",5.3. M-step,[0],[0]
"(47)
",5.3. M-step,[0],[0]
"The matrix Ak appears to be the sum of a diagonal matrix with a rank-1 matrix and can be inverted analytically thanks
to the Sherman-Morrison formula (Sherman & Morrison, 1950).",5.3. M-step,[0],[0]
"This results in the new closed-form update
wMCEM-Cfk = 1
JN βk αk ∑ j,n c",5.3. M-step,[0],[0]
(j) fkn.,5.3. M-step,[0],[0]
"(48)
",5.3. M-step,[0],[0]
"In the common case where βkαk is equal to a constant γ for all k, we can write:
∑ k wMCEM-Cfk = ∑ k βk αk
∑ j,n c",5.3. M-step,[0],[0]
"(j) fkn
JN = γ
∑ j,n vfn
JN = γvf
(49) where vf = N−1 ∑ n vfn is the empirical mean of the data for the feature f .",5.3. M-step,[0],[0]
Equation (49) implies that the rows of the estimate WMCEM-C at every iteration sum to a constant.,5.3. M-step,[0],[0]
This behavior is illustrated on Figure 1.,5.3. M-step,[0],[0]
"We now compare the three MCEM algorithms proposed for MMLE in the GaP model, first using synthetic toy datasets, then real-world data.",6. Experimental results,[0],[0]
Python implementations of the three algorithms are available from the first author website.,6. Experimental results,[0],[0]
"We generate a dataset of N = 100 samples according to the GaP model, with the following parameters:
W?1 =  0.638 0.075 0.009 0.568 0.044 0.126 0.309 0.231  , α? = β? = 1. (50) The columns of W?1 have been generated from a Dirichlet distribution (with parameters 1).",6.1. Experiments with synthetic data,[0],[0]
"The generated dataset (of size 4× 100) is denoted by V1.
",6.1. Experiments with synthetic data,[0],[0]
"We proceed to estimate the dictionary W using hyperparemeters K = K? + 1 = 3, αk = βk = 1 with MCEM-C, MCEM-H and MCEM-CH.",6.1. Experiments with synthetic data,[0],[0]
The algorithms are run for 500 iterations.,6.1. Experiments with synthetic data,[0],[0]
"300 Gibbs samples are generated at each iteration, with the first 150 samples being discarded for burn-in (this proves to be enough in practice), leading to J = 150.",6.1. Experiments with synthetic data,[0],[0]
The Gibbs sampler at EM iteration i + 1 is initialized with the last sample obtained at EM iteration i (warm restart).,6.1. Experiments with synthetic data,[0],[0]
"The algorithms are initialized from the same deterministic starting point given by
wfk = 1
K βk αk vf , (51)
as suggested by Equation (49).
",6.1. Experiments with synthetic data,[0],[0]
"Figure 2 displays the negative log-likelihood CML(W), computed thanks to the derivations of Section 4, and Figure 3-(a) displays the norm of the three columns of the iterates, both w.r.t.",6.1. Experiments with synthetic data,[0],[0]
CPU time in seconds.,6.1. Experiments with synthetic data,[0],[0]
"The three algorithms have almost identical computation times, most of the computational burden residing in the Gibbs sampling procedure that is common to the three algorithms.",6.1. Experiments with synthetic data,[0],[0]
"Moreover, the three algorithms converge to the same point, with MCEM-C converging marginally faster than the other two in this case.
",6.1. Experiments with synthetic data,[0],[0]
"Then we proceed to generate a second dataset V2 according to the GaP model, with now W?2 = 100 ×W?1.",6.1. Experiments with synthetic data,[0],[0]
"The
expectation of V2 is thus a hundred times the expectation of V1.",6.1. Experiments with synthetic data,[0],[0]
"We apply the exact same experimental protocol to V2 as we did for V1, except that the algorithms are now run for a larger number of 2000 iterations.",6.1. Experiments with synthetic data,[0],[0]
"In this case, because of the combinatorial nature of #C, it is impossible to compute the likelihood in reasonable time.",6.1. Experiments with synthetic data,[0],[0]
The norms of the columns of the iterates are displayed on Figure 3-(b).,6.1. Experiments with synthetic data,[0],[0]
"As we can see, MCEM-C clearly outperforms the other two algorithms in this scenario.",6.1. Experiments with synthetic data,[0],[0]
This behavior has been consistently found when estimating dictionaries from datasets with sufficiently large values.,6.1. Experiments with synthetic data,[0],[0]
This drastic difference in convergence is unexplained at this stage.,6.1. Experiments with synthetic data,[0],[0]
"However, we conjecture that this is linked to the over-dispersion of the data (i.e. when the variance is greater than the mean), which increases with the scale of W. This will be studied in future work.",6.1. Experiments with synthetic data,[0],[0]
"Finally, we consider the NIPS dataset which contains word counts from a collection of articles published at the NIPS conference.1",6.2. Experiments with the NIPS dataset,[0],[0]
"The number of articles is N = 1, 500 and the number of unique terms (appearing at least 10 times after tokenization and removing stop-words) is F = 12, 419.",6.2. Experiments with the NIPS dataset,[0],[0]
The matrix V is quite sparse as 96% of its coefficients are zeros.,6.2. Experiments with the NIPS dataset,[0],[0]
"This saves a large amount of computational effort, because we only need to sample cfn for pairs (f, n) such that vfn is non-zero.",6.2. Experiments with the NIPS dataset,[0],[0]
"Moreover, the count values range from 0 to 132.
",6.2. Experiments with the NIPS dataset,[0],[0]
We applied MCEM-C and MCEM-CH with K = 10 and αk = βk = 1.,6.2. Experiments with the NIPS dataset,[0],[0]
"The algorithms are run for 1, 000 iterations.",6.2. Experiments with the NIPS dataset,[0],[0]
250 Gibbs samples are generated in each iteration with the first half being discarded for burn-in (i.e. J = 125).,6.2. Experiments with the NIPS dataset,[0],[0]
The Gibbs sampler at iteration i + 1 is again initialized with warm restart.,6.2. Experiments with the NIPS dataset,[0],[0]
The algorithms are initialized using Equation (51).,6.2. Experiments with the NIPS dataset,[0],[0]
"MCEM-H results in similar performance than MCEM-CH and is not reported here.
",6.2. Experiments with the NIPS dataset,[0],[0]
Figure 4 shows that the column norms of the iterates w.r.t.,6.2. Experiments with the NIPS dataset,[0],[0]
CPU time in seconds.,6.2. Experiments with the NIPS dataset,[0],[0]
The difference in convergence speed between the two algorithms is again striking.,6.2. Experiments with the NIPS dataset,[0],[0]
MCEM-C efficiently explores the parameter space in the first iterations and converges dramatically faster than MCEM-CH.,6.2. Experiments with the NIPS dataset,[0],[0]
"The algorithms here converge to different solutions, which confirms the non-convexity of CML(W).",6.2. Experiments with the NIPS dataset,[0],[0]
"Other runs confirmed that MCEM-C is consistently faster, and also that the two algorithms do not always converge to the same solution.
",6.2. Experiments with the NIPS dataset,[0],[0]
MCEM-C still takes a few hours to converge.,6.2. Experiments with the NIPS dataset,[0],[0]
"We implemented stochastic variants of the EM algorithm such as SAEM (Kuhn & Lavielle, 2004), however this did not result in significant improvements in our case.",6.2. Experiments with the NIPS dataset,[0],[0]
"Finally, note that large-scale implementations are possible using for example on-line EM (Cappé & Moulines, 2009).",6.2. Experiments with the NIPS dataset,[0],[0]
"In this paper, we have shown how the Gamma-Poisson model can be rewritten free of the latent variables H.",7. Conclusion,[0],[0]
"This new parametrization enabled us to come up with a closedform expression of the marginal likelihood, which revealed a penalization term explaining the “self-regularization” effect described in Dikmen & Févotte (2012).",7. Conclusion,[0],[0]
"We then proceeded to compare three MCEM algorithms for the task of maximizing the likelihood, and the algorithm taking advantage of the marginalization H has been empirically proven to have better convergence properties.
",7. Conclusion,[0],[0]
"In this work, we treated α as a fixed hyperparameter.",7. Conclusion,[0],[0]
"Fu-
1https://archive.ics.uci.edu/ml/datasets/ bag+of+words
ture work will focus on lifting this hypothesis, and on designing algorithms to estimate both W and α.",7. Conclusion,[0],[0]
"We will also look into carrying a similar analysis in other probabilistic matrix factorization models, such as the GammaExponential model (Dikmen & Févotte, 2011).",7. Conclusion,[0],[0]
"We thank Benjamin Guedj, Vı́ctor Elvira and Jérôme Idier for fruitful discussions related to this work.",Acknowledgments,[0],[0]
This work has received funding from the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation program under grant agreement No 681839 (project FACTORY).,Acknowledgments,[0],[0]
"We present novel understandings of the GammaPoisson (GaP) model, a probabilistic matrix factorization model for count data.",abstractText,[0],[0]
We show that GaP can be rewritten free of the score/activation matrix.,abstractText,[0],[0]
This gives us new insights about the estimation of the topic/dictionary matrix by maximum marginal likelihood estimation.,abstractText,[0],[0]
"In particular, this explains the robustness of this estimator to over-specified values of the factorization rank, especially its ability to automatically prune irrelevant dictionary columns, as empirically observed in previous work.",abstractText,[0],[0]
The marginalization of the activation matrix leads in turn to a new Monte Carlo Expectation-Maximization algorithm with favorable properties.,abstractText,[0],[0]
Closed-form Marginal Likelihood in Gamma-Poisson Matrix Factorization,title,[0],[0]
Clustering is perhaps the most fundamental problem in unsupervised learning.,1. Introduction,[0],[0]
"Many clustering algorithms have been proposed in the literature (Jain et al., 1999), including Kmeans, spectral clustering, Gaussian mixture models and hierarchical clustering, to solve problems with respect to a wide range of cluster shapes.",1. Introduction,[0],[0]
"However, much research has pointed out that these methods all suffer from instabilities.",1. Introduction,[0],[0]
"For example, the formulation of K-means is NP-hard and the typical way to solve it is the Lloyds method, which
1ECE, North Carolina State University, Raleigh, NC 2CSE, Chalmers University of Technology, Göteborg, Sweden 3IMES, MIT, Cambridge, MA 4CSA, IISc, Bangalore, India.",1. Introduction,[0],[0]
"Correspondence to: Ashkan Panahi <panahi1986@gmail.com>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
requires randomly initializing the clusters.",1. Introduction,[0],[0]
"However, one needs to know the number of clusters in advance and different initializations may lead to significantly different final cluster results.
",1. Introduction,[0],[0]
"Lindsten et al. (2011) and Hocking et al. (2011) proposed the following convex optimization procedure for clustering, called SON (“Sum of norms” clustering) by the former and Clusterpath by the latter;
min {ui∈Rm}
1
2 n∑ i=1",1. Introduction,[0],[0]
‖xi,1. Introduction,[0],[0]
− ui‖22,1. Introduction,[0],[0]
"+ λ ∑ i<j ‖ui − uj‖2 (1)
",1. Introduction,[0],[0]
"The main idea of the formulation is that if input data points xi and xj belong to the same cluster, then their corresponding centroids ui and uj should be forced to be the same.",1. Introduction,[0],[0]
"Intuitively, this is due to the fact that the second term is a regularization term that enforces zeroes in the vector consisting of entries ‖ui − uj‖ and can be seen as a generalization of the fused Lasso penalty.",1. Introduction,[0],[0]
"From another point of view, the regularization term can be seen as an `1,2 norm, i.e., the sum of `2 norms.",1. Introduction,[0],[0]
"Such a group norm is known to encourage block sparse solutions (Bach et al., 2012).",1. Introduction,[0],[0]
"Thus for many pairs (i, j), we expect to enforce ui = uj .
Lindsten et al. (2011) used an off–the–shelf convex solver, CVX to generate solution paths.",1. Introduction,[0],[0]
Hocking et al. (2011) introduced three distinct algorithms for the three most commonly encountered norms.,1. Introduction,[0],[0]
"For the `1 norm, the objective function separates, and they solve the convex clustering problem by the exact path following method designed for the fused lasso.",1. Introduction,[0],[0]
"For the `1 and `2 norms, they employ subgradient descent in conjunction with active sets.",1. Introduction,[0],[0]
"Recently, Chi & Lange (2015); Chen et al. (2015) introduce two similar generic frameworks for minimizing the convex clustering objective function with an arbitrary norm.",1. Introduction,[0],[0]
"One approach solves the problem by the alternating direction method of multipliers (ADMM), while the other solves it by the alternating minimization algorithm (AMA).",1. Introduction,[0],[0]
"However both algorithms have issues with scalablity.
",1. Introduction,[0],[0]
"Moreover, none of these papers provide any theoretical guarantees about the cluster recovery property of the algorithm.",1. Introduction,[0],[0]
"The first theoretical result on cluster recovery was shown by Zhu et al. (2010): if the samples are drawn from
two cubes, each being one cluster, then SON can provably recover the clusters provided that the distance between the two cubes is larger than a threshold which depends (linearly) on the size of the cube and the ratio of numbers of samples in each cluster.",1. Introduction,[0],[0]
"Unfortunately, the conditions for recovery represent an extremely narrow special case: only two clusters which both have to be cubes.",1. Introduction,[0],[0]
"Moreover in their paper, there is no algorithm or analysis of the speed of convergence.",1. Introduction,[0],[0]
"No other theoretical guarantees for SON are known previously.
",1. Introduction,[0],[0]
"Here we develop a new algorithm in the spirit of recent advances in stochastic methods for large scale optimization (Bottou et al., 2016) to solve the optimization problem (1).",1. Introduction,[0],[0]
"We give a convergence analysis and provide quite general cluster recovery guarantees.
",1. Introduction,[0],[0]
"There has been a flurry of advances (Johnson & Zhang, 2013; Defazio et al., 2014; Schmidt et al., 2016) in developing algorithms for solving optimization problems for the case when the objective consists of the sum of two convex functions: one is the average of a large number of smooth component functions, and the other is a general convex function that admits a proximal mapping (and the whole objective function is strongly convex).",1. Introduction,[0],[0]
The optimization (1) is of this form but here we exploit the structure of (1) further by observing that the second function can also be split into component functions.,1. Introduction,[0],[0]
This results in an incremental algorithm with proximal iterations consisting of very simple and natural steps.,1. Introduction,[0],[0]
Our algorithm can be seen as a special case of the methods of Bertsekas (2011).,1. Introduction,[0],[0]
We compute the proximal operator in closed form to yield very simple and cheap iterations.,1. Introduction,[0],[0]
"Using the fact that the proximal operator is non-expansive, we refine and strengthen Bertsekas’ convergence results.",1. Introduction,[0],[0]
"The stochastic incremental nature of our algorithm makes it highly suited to large scale problems (Bottou et al., 2016) in contrast to the methods in Chi & Lange (2015); Chen et al. (2015).
",1. Introduction,[0],[0]
We show that the SON formualation (1) provides strong cluster recovery properties that go far beyond the special case considered in Zhu et al. (2010).,1. Introduction,[0],[0]
"Our cluster recovery conditions are similar in spirit to the unifying general conditions recently formulated in A. Kumar (2010); P.Awasthi (2012) of the form that the means of the clusters are well– separated, i.e., the distance between the means of any two clusters is at least Ω(k) standard deviations (the notion of standard deviations is based on the spectral norm of the matrix whose rows represent the difference between a point and the mean of the cluster to which it belongs).",1. Introduction,[0],[0]
"Besides containing the result of Zhu et al. (2010) as a special case, the condition essentially recovers the well known cluster recovery conditions for paradigm examples such as mixtures of Gaussians and planted partition models.",1. Introduction,[0],[0]
"The algorithms in A. Kumar (2010); P.Awasthi (2012) are based on
an SVD-based initialization followed by applying Lloyd’s K–means algorithm, so K must be known in advance.",1. Introduction,[0],[0]
"Our method does not need to knowK and is independent of any initialization.
",1. Introduction,[0],[0]
"A summary of our contributions are:
• We develop a new incremental proximal algorithm for the SON optimization problem (1).
",1. Introduction,[0],[0]
"• We give a convergence analysis for our algorithm that refines and strengthens the analysis in Bertsekas (2011).
",1. Introduction,[0],[0]
"• We show that the SON formulation (1) provides strong cluster recovery guarantees that is far more general than previously known recovery results, essentially similar to the recently discovered unifying center separation conditions.
",1. Introduction,[0],[0]
• We give experimental results giving evidence that our algorithm produces clusters of comparable quality to previous methods but scales much better to large scale problems.,1. Introduction,[0],[0]
"The SON formulation first appeared in (Lindsten et al., 2011) and in closely related forms in Hocking et al. (",2. Related Work,[0],[0]
"Hocking et al., 2011).",2. Related Work,[0],[0]
"Lindsten et al (Lindsten et al., 2011) used an off–the–shelf convex solver, CVX to generate solution paths.",2. Related Work,[0],[0]
Hocking et al.,2. Related Work,[0],[0]
"(Hocking et al., 2011) introduced three distinct algorithms for the three most commonly encountered norms.",2. Related Work,[0],[0]
"For the `1 norm, the objective function separates, and they solve the convex clustering problem by the exact path following method designed for the fused lasso.",2. Related Work,[0],[0]
"For the `1 and `2 norms, they employ subgradient descent in conjunction with active sets.",2. Related Work,[0],[0]
Neither provides any theoretical results on cluster recovery.,2. Related Work,[0],[0]
"Chi et al (Chi & Lange, 2015; Chen et al., 2015) introduce two similar generic frameworks for minimizing the convex clustering objective function with an arbitrary norm.",2. Related Work,[0],[0]
"One approach solves the problem by the alternating direction method of multipliers (ADMM), while the other solves it by the alternating minimization algorithm (AMA).",2. Related Work,[0],[0]
"The first (and only) theoretical results on cluster recovery are in (Zhu et al., 2010) but this is a very simple special case of exactly two cube shaped clusters that are well separated.",2. Related Work,[0],[0]
This work also does not develop a specialized algorithm for the SON formulation.,2. Related Work,[0],[0]
"To express our results, we first review few definitions: Definition 1.",3. Cluster Recovery,[0],[0]
"Take a finite set X = {x1, x2, . . .",3. Cluster Recovery,[0],[0]
", xn} ⊂ Rm and its partitioning V = {V1, V2, . . .",3. Cluster Recovery,[0],[0]
", VK}, where each
Vk is a subset of X .",3. Cluster Recovery,[0],[0]
"We say that a map φ on X perfectly recovers V when φ(xi) = φ(xj) is equivalent to xi, xj belonging to the same cluster, or in other words, there exist distinct vectors v1, v2, . . .",3. Cluster Recovery,[0],[0]
", vK such that φ(xi) = vα holds",3. Cluster Recovery,[0],[0]
whenever xi ∈ Vα.,3. Cluster Recovery,[0],[0]
Definition 2.,3. Cluster Recovery,[0],[0]
"For any set S ⊂ Rm, its diameter is defined as
D(S) =",3. Cluster Recovery,[0],[0]
"sup{‖x− y‖2 | x, y ∈ S}.
",3. Cluster Recovery,[0],[0]
"Moreover, for any finite set T ⊂",3. Cluster Recovery,[0],[0]
"Rm we define its separation as
d(T )",3. Cluster Recovery,[0],[0]
"= min{‖x− y‖2 | x, y ∈ S, x 6= y}
and its Euclidean centroid as
c(T ) =
∑ x∈T x
|V | .
",3. Cluster Recovery,[0],[0]
"Finally, for any family of mutually disjoint finite sets T = {Ti ⊂ Rm}, we define C(T ) =",3. Cluster Recovery,[0],[0]
{c(Ti)}.,3. Cluster Recovery,[0],[0]
Definition 3.,3. Cluster Recovery,[0],[0]
"Take a finite set X = {x1, x2, . . .",3. Cluster Recovery,[0],[0]
", xn} ⊂ Rm and its partitioning V = {V1, V2, . . .",3. Cluster Recovery,[0],[0]
", VK}.",3. Cluster Recovery,[0],[0]
"We call a partitioning W = {W1,W2, . . .",3. Cluster Recovery,[0],[0]
",WL} of X a coarsening of V if each partition Wl is obtained by taking the union of a number of partitions Vk.",3. Cluster Recovery,[0],[0]
"Further, W is called the trivial coarsening of V if W has exactly one element, i.e. W = {X}.",3. Cluster Recovery,[0],[0]
"Otherwise, it is called a non-trivial coarsening.
",3. Cluster Recovery,[0],[0]
"Based on the above definitions, our result can be explained as follows:
Theorem 1.",3. Cluster Recovery,[0],[0]
Consider a finite set X = {xi ∈,3. Cluster Recovery,[0],[0]
"Rm | i = 1, 2, ..., n} of vectors and its partitioning V = {V1, V2, . . .",3. Cluster Recovery,[0],[0]
", VK}.",3. Cluster Recovery,[0],[0]
Take the SON optimization in (1).,3. Cluster Recovery,[0],[0]
"Denote its optimal solution by {ūi} and define the map φ : xi → φ(xi) = ūi.
1.",3. Cluster Recovery,[0],[0]
"If
max V ∈V
D(V ) |V",3. Cluster Recovery,[0],[0]
| ≤ λ ≤ d(C(V)),3. Cluster Recovery,[0],[0]
2n,3. Cluster Recovery,[0],[0]
"√ K ,
then the map φ perfectly recovers V .
2.",3. Cluster Recovery,[0],[0]
"If
max V ∈V
D(V )
|V | ≤ λ ≤ max V ∈V ‖c(X)− c(V )",3. Cluster Recovery,[0],[0]
‖2 |X|,3. Cluster Recovery,[0],[0]
− |V,3. Cluster Recovery,[0],[0]
"| ,
then the map φ perfectly recovers a non-trivial coarsening of V .
",3. Cluster Recovery,[0],[0]
Proof.,3. Cluster Recovery,[0],[0]
"We introduce associated centroid optimization:
min {vα∈Rm}
1
2 K∑ i=1",3. Cluster Recovery,[0],[0]
‖vα,3. Cluster Recovery,[0],[0]
"− cα‖22nα + λ ∑ α 6=β nαnβ‖cα − cα‖2
(2)
",3. Cluster Recovery,[0],[0]
"where
cα =
∑ i∈Vα xi
nα
We prove the following results, which clearly imply Theorem 1:
1.",3. Cluster Recovery,[0],[0]
Suppose that for every α ∈,3. Cluster Recovery,[0],[0]
"[K],
max i,j∈Vα
‖xi − xj‖ nα ≤ λ.
",3. Cluster Recovery,[0],[0]
"Then, ui = vα for i ∈ Vα is a global solution of the SON clustering.
",3. Cluster Recovery,[0],[0]
2.,3. Cluster Recovery,[0],[0]
"If all cαs are distinct and d2n√K ≥ λ where d = min α 6=β ‖cα − cβ‖, then all centroids vα are distinct.
3.",3. Cluster Recovery,[0],[0]
If max α ‖cα−c‖ n−nα ≥ λ where c = n∑ i=1,3. Cluster Recovery,[0],[0]
"xi/n, then at least
two centroids vα are distinct.
",3. Cluster Recovery,[0],[0]
"To prove the above, notice that the solution of the centroid optimization satisfies
cα − vα = λ ∑ β nβzα,β
where ‖zα,β‖ ≤ 1, zα,β = −zβ,α and whenever vα 6= vβ , the relation zα,β =
vα−vβ ‖vα−vβ‖2 holds.",3. Cluster Recovery,[0],[0]
"Now, for the solution
ui = vα for i ∈ Vα, define
z′ij = { zα,β α 6=",3. Cluster Recovery,[0],[0]
"β xi−xj λnα α = β ,
where i ∈ Vα, j ∈ Vβ .",3. Cluster Recovery,[0],[0]
"It is easy to see that ‖z′ij‖2 ≤ 1, z′ij = −z′ji and whenever ui 6= uj , we have that z′ij = ui−uj ‖ui−uj‖2 .",3. Cluster Recovery,[0],[0]
"Further for each i,
λ ∑ j z′i,j = λ ∑ β zα,βnβ + ∑ j∈Vα xi",3. Cluster Recovery,[0],[0]
"− xj nα
= cα − vα",3. Cluster Recovery,[0],[0]
+,3. Cluster Recovery,[0],[0]
xi,3. Cluster Recovery,[0],[0]
− cα = xi,3. Cluster Recovery,[0],[0]
− vα = xi,3. Cluster Recovery,[0],[0]
− ui,3. Cluster Recovery,[0],[0]
"This shows that the local optimality conditions for the SON optimization holds and proves item a.
For item b, denote the solution of the centroid optimization by vα(λ) and notice that the solution of SON consists of distinct elements vα = cα and is continuous at λ = 0.",3. Cluster Recovery,[0],[0]
"Hence, vα:s remain distinct in an interval λ ∈",3. Cluster Recovery,[0],[0]
"[0, λ1).",3. Cluster Recovery,[0],[0]
"Take λ0 as the supremum of all possible λ1:s. Hence, the solution in λ ∈",3. Cluster Recovery,[0],[0]
"[0, λ0) contains distinct element and at λ = λ0 contains two equal elements (otherwise, one can extend [0, λ0) to some [0, λ0+ ), which is against λ being supremum).",3. Cluster Recovery,[0],[0]
"Now, notice that for λ ∈",3. Cluster Recovery,[0],[0]
"[0 λ0) the objective
function is smooth at the optimal point.",3. Cluster Recovery,[0],[0]
"Hence, vα(λ) is differentiable and satisfies
δ =",3. Cluster Recovery,[0],[0]
[ dvα dλ ],3. Cluster Recovery,[0],[0]
"α = H−1 ∂g ∂λ (3)
where [. ]α and [. ]",3. Cluster Recovery,[0],[0]
"α,β denote block vectors and block matrices respectively.",3. Cluster Recovery,[0],[0]
"Moreover, H and g are the Hessian and the gradient of the objective function at the optimal point.",3. Cluster Recovery,[0],[0]
"It is possible, by explicitly expanding H and g, to show that ‖δ‖2 ≤ n",3. Cluster Recovery,[0],[0]
√ K (see the supplementary material for more detailed derivations).,3. Cluster Recovery,[0],[0]
"Hence, ∥∥∥∥dvαdλ ∥∥∥∥ 2 ≤ ‖δ‖2 ≤",3. Cluster Recovery,[0],[0]
"√ Kn
This yields for λ < λ0 to
‖vα(λ)− vβ(λ)‖2 = ∥∥∥∥∥∥cα",3. Cluster Recovery,[0],[0]
− cβ,3. Cluster Recovery,[0],[0]
"+ λ∫
0
( dvα dλ − dvβ dλ )",3. Cluster Recovery,[0],[0]
"dλ ∥∥∥∥∥∥ 2
≥ ‖cα − cβ‖2 − λ∫
0
∥∥∥∥dvαdλ",3. Cluster Recovery,[0],[0]
"− dvβdλ ∥∥∥∥ 2 dλ
≥ d− 2nλ √ K
Since at λ = λ0, we have that vα = vβ for some α 6=",3. Cluster Recovery,[0],[0]
"β, we get that d",3. Cluster Recovery,[0],[0]
"− 2nλ0 √ K ≤ 0 or λ0 ≥ d/2n √ K. this proves item b.
For item c, Take a value of λ, where v1 = v2 = . . .",3. Cluster Recovery,[0],[0]
= vK .,3. Cluster Recovery,[0],[0]
It is simple to see that in this case vα = c.,3. Cluster Recovery,[0],[0]
"The optimality condition leads to
c− cα = λ ∑ β 6=α zα,βnβ
Hence, ‖c− cα‖2 ≤",3. Cluster Recovery,[0],[0]
λ(n− nα).,3. Cluster Recovery,[0],[0]
"This proves item c.
Remark 1.",3. Cluster Recovery,[0],[0]
The study in Zhu et al. (2010) establishes some results for the special case of two clusters in rectangular boxes.,3. Cluster Recovery,[0],[0]
"In this special case, we observe that our result improves theirs.
",3. Cluster Recovery,[0],[0]
Proof.,3. Cluster Recovery,[0],[0]
"Consider the notation in Zhu et al. (2010) with two clusters V1, V2 and notice that λ = α/2 (α denotes regularization parameter in Zhu et al. (2010)).",3. Cluster Recovery,[0],[0]
"Moreover, D(Vi) ≤ ‖si‖ as ‖si‖ is the diameter of the rectangle surrounding Vi.",3. Cluster Recovery,[0],[0]
"We observe that
w1,2 n ≥ D(Vi)
2n3−i ( ni−1 n2i ) + 1
n3−i + ni ≥ D(Vi)",3. Cluster Recovery,[0],[0]
"ni
for i = 1, 2, which shows that the condition λ ≥ w1,2n in Zhu et al. (2010) is tighter than λ ≥ maxD(V )",3. Cluster Recovery,[0],[0]
/|V,3. Cluster Recovery,[0],[0]
| in ours.,3. Cluster Recovery,[0],[0]
"On the other hand,
‖c(Vi)− c(X)‖ n− ni = ‖c(Vi)− c(V1)n1+c(V2)n2n1+n2 ‖ n− ni
= ‖c(V1)− c(V2)‖2
n (4)
= d(C(V))
",3. Cluster Recovery,[0],[0]
"n
Hence, the condition λ ≤ d(C(V))n in Zhu et al. (2010) is the same as our condition λ ≤ ‖c(Vi)−c(X)‖n−ni .
",3. Cluster Recovery,[0],[0]
Remark 2.,3. Cluster Recovery,[0],[0]
"The second result in Theorem 1 reflects a hierarchical structure in the SON clusters: Under weaker condition than the first part, SON may merge some clusters and provide larger clusters than the true ones.",3. Cluster Recovery,[0],[0]
"In a recursive way, SON clustering can be applied to each of these large clusters to refine them, which improves the guarantees in Theorem 1.",3. Cluster Recovery,[0],[0]
We postpone careful study of this method to future work.,3. Cluster Recovery,[0],[0]
"Recently, there have been a number of theoretical results of the form that if we have data points generated by a mixture of K probability distributions, then one can cluster the data points into the K clusters, one corresponding to each component, provided the means of the different components are well–separated.",3.1. Comparison with Center Separation Conditions,[0],[0]
"There are different notions of well-separated, but mainly, the (best known) results can be qualitatively stated as: “If the means of every pair of densities are at least poly(K) standard deviations apart, then we can learn the mixture in polynomial time.”.",3.1. Comparison with Center Separation Conditions,[0],[0]
"These results generally make heavy use of the generative model and particular properties of the distributions (Indeed, many of them specialize to Gaussians or independent Bernoulli trials).
",3.1. Comparison with Center Separation Conditions,[0],[0]
"Kumar and Kannan (A. Kumar, 2010) and Awasthi and Sheffet (P.Awasthi, 2012) unified these into a general deterministic condition which can be roughly stated as follows: “If the means of every pair of clusters are at least Ω(K) times standard deviations apart, then we can learn the mixture in polynomial time.”",3.1. Comparison with Center Separation Conditions,[0],[0]
"Here the spectral norm of the matrix A − C scaled by 1√
n plays the role of standard
deviation, whereA is the data matrix and C is the matrix of cluster centers.",3.1. Comparison with Center Separation Conditions,[0],[0]
"More formally, for any two distinct clusters α, β,
‖c(Vα)− c(Vβ)‖2 ≥",3.1. Comparison with Center Separation Conditions,[0],[0]
"K (
1 √ nα + 1 √ nβ
) ‖A− C‖ (5)
Our condition is similar in spirit:
‖c(Vα)− c(Vβ)‖2 ≥",3.1. Comparison with Center Separation Conditions,[0],[0]
"√ K
( n
nα d(Vα)
) (6)
",3.1. Comparison with Center Separation Conditions,[0],[0]
"If nα ≥ wn for all clusters α, then this becomes
‖c(Vα)− c(Vβ)‖2",3.1. Comparison with Center Separation Conditions,[0],[0]
≥,3.1. Comparison with Center Separation Conditions,[0],[0]
"√ K
w d(Vα).",3.1. Comparison with Center Separation Conditions,[0],[0]
"(7)
In the sequel, we specialize the above discussion in a number of examples and provide an explicit comparison of our result with the center separation condition.",3.1. Comparison with Center Separation Conditions,[0],[0]
"In some cases, our condition is slightly tighter than the center separation guarantees, but we remind that the latter is obtained by applying K-means and a SVD-based initialization, which can be intractable in large problems, while our techniques scales with the problem size more suitably.",3.1. Comparison with Center Separation Conditions,[0],[0]
"Suppose we have a mixture of K Gaussians in d dimensions with mixture weights w1, · · · , wK , let w := mini wi and let µ1, · · · , µK denote their means respectively.",3.1.1. MIXTURES OF GAUSSIANS,[0],[0]
"If we have n = Ω(poly(d/w)) points sampled from this mixture distribution, then with high probability, the center separation condition is satisfied if:
‖µr − µs‖ ≥ cKσ√ w polylog(d/w).
",3.1.1. MIXTURES OF GAUSSIANS,[0],[0]
Here σ is the maximum variance in any direction of any of the Gaussians.,3.1.1. MIXTURES OF GAUSSIANS,[0],[0]
"Our cluster recovery condition (7) is satisfied if:
‖µr − µs‖ ≥ cKσ
w polylog(n).",3.1.1. MIXTURES OF GAUSSIANS,[0],[0]
"In the planted partition model of McSherry, a set of n points is implicitly partitioned into K groups.",3.1.2. PLANTED PARTITION MODEL,[0],[0]
There is an (unknown) K ×K matrix of probabilities P .,3.1.2. PLANTED PARTITION MODEL,[0],[0]
"We are given a graph G on these n points, where an edge between two vertices from groups r and s is present with probability Pr,s.",3.1.2. PLANTED PARTITION MODEL,[0],[0]
"We can consider these n points x1, · · · , xn ∈ Rn where coordinate j in xi is 1 if (i, j) ∈ G and 0 otherwise.",3.1.2. PLANTED PARTITION MODEL,[0],[0]
The center µr of cluster r has in coordinate j the value,3.1.2. PLANTED PARTITION MODEL,[0],[0]
"Pr,ψ(j), where ψ(j) is the cluster vertex j belongs to.",3.1.2. PLANTED PARTITION MODEL,[0],[0]
Kumar and Kannan show that the center separation condition holds with probability at least 1− δ,3.1.2. PLANTED PARTITION MODEL,[0],[0]
"if:
‖µr − µs‖ ≥ cσ2K( 1
w + log
n δ )
where c is a large constant, w is such that every group has size at least w · n and σ2 := maxr,s Pr,s.",3.1.2. PLANTED PARTITION MODEL,[0],[0]
"Our center separation condition (7) is satisfied if:
‖µr − µs‖ ≥ c σ2K
w
√ n",3.1.2. PLANTED PARTITION MODEL,[0],[0]
"Besides the stochastic models, we take a closer look at the result in A. Kumar (2010) and identify deterministic cases where the SON has better performance than the proved bounds for K-means.",3.1.3. REGULAR AND DIRECTED CLUSTERS,[0],[0]
"These cases essentially guarantee that the term ‖A−C‖ in (5) remains large and the bound therein becomes highly restrictive:
Definition 4.",3.1.3. REGULAR AND DIRECTED CLUSTERS,[0],[0]
"We say that a partition V = {V1, V2, . . .",3.1.3. REGULAR AND DIRECTED CLUSTERS,[0],[0]
", VK} of X = {x1, x2, . . .",3.1.3. REGULAR AND DIRECTED CLUSTERS,[0],[0]
", xn} is (δ, γ)−expanded if
|{x ∈ V | ‖x− c(V )",3.1.3. REGULAR AND DIRECTED CLUSTERS,[0],[0]
‖2 ≥ δ}| ≥ γ|V,3.1.3. REGULAR AND DIRECTED CLUSTERS,[0],[0]
"|.
",3.1.3. REGULAR AND DIRECTED CLUSTERS,[0],[0]
"We further say that this partition is (w,D, , γ)-regular if for all V ∈ V we have D(V ) ≥ D, |V | ≥",3.1.3. REGULAR AND DIRECTED CLUSTERS,[0],[0]
wn,3.1.3. REGULAR AND DIRECTED CLUSTERS,[0],[0]
"and it is ( D, γ)−expanded.",3.1.3. REGULAR AND DIRECTED CLUSTERS,[0],[0]
Definition 5.,3.1.3. REGULAR AND DIRECTED CLUSTERS,[0],[0]
"We say that a set X = {x1, x2, . . .",3.1.3. REGULAR AND DIRECTED CLUSTERS,[0],[0]
", xn} is θ−directed if there exists a unit vector v ∈",3.1.3. REGULAR AND DIRECTED CLUSTERS,[0],[0]
"Rm such that∑
x∈X\{c(X)}
|vT",3.1.3. REGULAR AND DIRECTED CLUSTERS,[0],[0]
"(x− c(X))|2
‖x− c(X)‖22 ≥ θ|X|
For a (w,D, , γ)-regular partition, the bound in (5) implies d(C(V))",3.1.3. REGULAR AND DIRECTED CLUSTERS,[0],[0]
"≥ 2cK D √ γn√
mwn .",3.1.3. REGULAR AND DIRECTED CLUSTERS,[0],[0]
"This is because
‖A− C‖2 = σmax ( n∑ i=1 δiδ T i )",3.1.3. REGULAR AND DIRECTED CLUSTERS,[0],[0]
"≥
",3.1.3. REGULAR AND DIRECTED CLUSTERS,[0],[0]
"Tr (
n∑ i=1",3.1.3. REGULAR AND DIRECTED CLUSTERS,[0],[0]
"δiδ T i ) m
=
n∑ i=1",3.1.3. REGULAR AND DIRECTED CLUSTERS,[0],[0]
"‖δi‖22
m = γ 2D2
n
m
(8)
where δi = xi − c(Vα) for i ∈ Vα.",3.1.3. REGULAR AND DIRECTED CLUSTERS,[0],[0]
Notice that our conditions can be implied by d(C(V)),3.1.3. REGULAR AND DIRECTED CLUSTERS,[0],[0]
"≥ 2nD √ K
wn .",3.1.3. REGULAR AND DIRECTED CLUSTERS,[0],[0]
"Hence,SON can improve K-means if m ≤ wKc2γ 2, which means that the number of clusters K is large and the smallest fraction of cluster size w is Ω(1).
",3.1.3. REGULAR AND DIRECTED CLUSTERS,[0],[0]
"If the (w,D, , γ)-regular partition is further θ−directed we may improve the previous bounds as
σmax ( n∑ i=1 δiδ T i )",3.1.3. REGULAR AND DIRECTED CLUSTERS,[0],[0]
≥ ∑ x∈X |vT,3.1.3. REGULAR AND DIRECTED CLUSTERS,[0],[0]
δi|2,3.1.3. REGULAR AND DIRECTED CLUSTERS,[0],[0]
≥,3.1.3. REGULAR AND DIRECTED CLUSTERS,[0],[0]
"γ 2D2nθ
Hence (5) implies d(C(V))",3.1.3. REGULAR AND DIRECTED CLUSTERS,[0],[0]
"≥ 2cK D √ γθn√
wn .",3.1.3. REGULAR AND DIRECTED CLUSTERS,[0],[0]
"This means that
SON improves K-means if wK ≥ 1c2 2γθ , i.e. the number of clusters is higher than a fixed value.",3.1.3. REGULAR AND DIRECTED CLUSTERS,[0],[0]
"Our implementation is identical to the so-called proximalbased incremental technique in Bertsekas (2011), which is
performed in a way that it requires little amount of calculations (precisely O(m) and independent of other parameters) in each iteration.",4. Stochastic Splitting Algorithm,[0],[0]
"The proximal-based incremental method is a variant of the stochastic gradient technique, in problems where many terms in the objective function are not differentiable, and the local gradient steps are replaced by local proximal operators.",4. Stochastic Splitting Algorithm,[0],[0]
"To perform the proximalbased incremental method, we first write the SON objective function as
Φ(u1, u2, . . .",4. Stochastic Splitting Algorithm,[0],[0]
", un) = ∑ i<j φij(ui, uj)
where
φij(ui, uj) = 1
2n",4. Stochastic Splitting Algorithm,[0],[0]
"‖xi−ui‖22+
1
2n ‖xj−uj‖22+λ‖ui−uj‖.
Then, we introduce and explicitly calculate the proximal operator Π(µ)ij of φij with step size µ as
Π (µ) ij (ui, uj) =
arg min u′i,u ′",4. Stochastic Splitting Algorithm,[0],[0]
"j
φij(u ′",4. Stochastic Splitting Algorithm,[0],[0]
"i, u ′ j) + 1 2µ‖u ′",4. Stochastic Splitting Algorithm,[0],[0]
i − ui‖22 + 12µ‖u ′,4. Stochastic Splitting Algorithm,[0],[0]
"j − uj‖22
= Tλµ(ui + µxi, uj + µxj), (9)
where we also introduce the pairwise soft-thresholding operator Tη(y, z) ={ (
y + η z−y‖z−y‖2 , z + η y−z ‖y−z‖2 ) ‖y",4. Stochastic Splitting Algorithm,[0],[0]
"− z‖ ≥ 2η(
y+z 2 , y+z 2
) ‖y",4. Stochastic Splitting Algorithm,[0],[0]
"− z‖ < 2η ,
(10) and the final equality is obtained by the local optimality conditions and straightforward calculations.",4. Stochastic Splitting Algorithm,[0],[0]
Our algorithm simply consists in iteratively applying randomly selected proximal operators.,4. Stochastic Splitting Algorithm,[0],[0]
"This is depicted in Algorithm 1.
",4. Stochastic Splitting Algorithm,[0],[0]
Algorithm 1 Stochastic Splitting Algorithm Input:,4. Stochastic Splitting Algorithm,[0],[0]
"The data vectors {xk}nk=1 and step sizes {µk}∞k=1 Initialization: Set u1, u2, . . .",4. Stochastic Splitting Algorithm,[0],[0]
", un arbitrarily (we use u1 = u2 = . . .",4. Stochastic Splitting Algorithm,[0],[0]
"= un = 0) for k = 1, 2, . . .",4. Stochastic Splitting Algorithm,[0],[0]
"do
Select a pair (i, j) with i < j uniformly randomly.",4. Stochastic Splitting Algorithm,[0],[0]
"Update (ui, uj)← Π(µk)ij (ui, uj)
end for",4. Stochastic Splitting Algorithm,[0],[0]
Convergence of proximal-based incremental method is discussed in Bertsekas (2011).,4.1. Convergence Analysis,[0],[0]
We further elaborate on the convergence by further exploitation of the nonexpansiveness property of proximal operators.,4.1. Convergence Analysis,[0],[0]
"This allows us to complement the result in Bertsekas (2011) in the following two directions: First, we establish convergence in
the probability sense (uniform convergence), while the result in Bertsekas (2011) is pointwise.",4.1. Convergence Analysis,[0],[0]
"Second, we prove guaranteed speed of convergence with probability one.",4.1. Convergence Analysis,[0],[0]
We present these results by the following theorem.,4.1. Convergence Analysis,[0],[0]
"In this theorem, we consider fixed data dimensionm and bounded data vectors (i.e. ‖xk‖ ≤ C for some absolute constant C).",4.1. Convergence Analysis,[0],[0]
"Theorem 2.
1.",4.1. Convergence Analysis,[0],[0]
Assume that {µk} is non-increasing ∞∑ 0,4.1. Convergence Analysis,[0],[0]
"µk = ∞ and
∞∑ 0 µ2k < ∞.",4.1. Convergence Analysis,[0],[0]
"Then, the sequence Uk converges to Ũ in the following strong probability sense:
∀ > 0; lim k→∞",4.1. Convergence Analysis,[0],[0]
Pr ( sup l≥k ‖Ul − Ũ‖2F > ),4.1. Convergence Analysis,[0],[0]
"= 0 (11)
2.",4.1. Convergence Analysis,[0],[0]
"Take µk = µ1kα for k = 1, 2, . . .",4.1. Convergence Analysis,[0],[0]
and 2 3 < α < 1.,4.1. Convergence Analysis,[0],[0]
"For
sufficiently small values of > 0",4.1. Convergence Analysis,[0],[0]
the relation ‖Ul − Ũ‖2F =,4.1. Convergence Analysis,[0],[0]
"O ( n4
l3α−2− ) holds for every l, n with probability 1.
",4.1. Convergence Analysis,[0],[0]
Proof.,4.1. Convergence Analysis,[0],[0]
We skip many steps in our proof for lack of space.,4.1. Convergence Analysis,[0],[0]
These steps can be found in the supplement.,4.1. Convergence Analysis,[0],[0]
Denote by Uk a matrix where the ith column is the value of ui at the kth iteration.,4.1. Convergence Analysis,[0],[0]
"Define
ψµ(U) =",4.1. Convergence Analysis,[0],[0]
E,4.1. Convergence Analysis,[0],[0]
"(Uk+1 | Uk = U, µk = µ) , (12)
",4.1. Convergence Analysis,[0],[0]
"Starting from Ū0 = U0 (the initialization of the algorithm), we define the characteristic sequence {Ūk}∞k=0 by the following iteration:
Ūk+1 = ψµk(Ūk)
",4.1. Convergence Analysis,[0],[0]
"Our proof is based on the following two results, which we prove in the supplementary material:
",4.1. Convergence Analysis,[0],[0]
"i We have that
Pr ( sup k ‖Uk",4.1. Convergence Analysis,[0],[0]
− Ūk‖2F + ∞∑,4.1. Convergence Analysis,[0],[0]
"l=k µ2l > λ ) ≤ ∞∑ k=0 µ2k λ
(13)
ii Define Ũ as the unique optimal solution of the SON optimization and suppose that {µk} is a non-increasing sequence.",4.1. Convergence Analysis,[0],[0]
"There exists a universal constant a such that ‖Ūk − Ũ‖2F is upper bounded by
a k−1∑ l=0 µ2l",4.1. Convergence Analysis,[0],[0]
e − 2 n2 k−1∑ s=l+1 µs + ‖U0,4.1. Convergence Analysis,[0],[0]
− Ũ‖2Fe,4.1. Convergence Analysis,[0],[0]
"− 2 n2 k−1∑ s=0 µs
To prove Theorem 2, define Uk = {Ūkl }∞l=0 as the sequence obtained by starting from Ūk0 = Uk and applying
Ūkl+1",4.1. Convergence Analysis,[0],[0]
"= ψµl+k(Ū k l )
",4.1. Convergence Analysis,[0],[0]
"Take arbitrary (non-zero) positive numbers , δ.",4.1. Convergence Analysis,[0],[0]
Take λ such that λ ≥ 2δ,4.1. Convergence Analysis,[0],[0]
∞∑ l=0 µ2l .,4.1. Convergence Analysis,[0],[0]
"Take some values l0, k which we specialize later.",4.1. Convergence Analysis,[0],[0]
"Now, we define two outcomes H1 and H2:
H1 : ∀k ≥ 0; ‖Uk",4.1. Convergence Analysis,[0],[0]
− Ũ‖2F ≤,4.1. Convergence Analysis,[0],[0]
"λ
H2 : ∀l ≥ 0; ‖Ūkl −Ul+k‖ ≤
4
From item (i), it is simple to see that Pr(Hc1) and Pr(H c 2) are less than δ/2.",4.1. Convergence Analysis,[0],[0]
"Furthermore we can show by (ii) that under H1 ∩H2 and suitable l0, k:
∀l > l0; ‖Ul+k−Ũ‖22 ≤ 2(‖Ul+k−Ūkl ‖2F+‖Ūkl −Ũ‖2F)
≤ 2( 4 + 4 ) =
",4.1. Convergence Analysis,[0],[0]
This is detailed in the supplement.,4.1. Convergence Analysis,[0],[0]
"We conclude that
Pr( sup l>l0+k
‖Ul − Ũ‖22 > ) ≤ Pr(Hc1) + Pr(Hc2) ≤ δ
which proves part (1) of Theorem.
",4.1. Convergence Analysis,[0],[0]
"For part (2), define kr = rγ , λr = r−β , where γ = 1− 2 1−α , β < γ(2α− 1)− 1, and the outcomes:
Qr : sup l≥0 ‖Ul+kr",4.1. Convergence Analysis,[0],[0]
"− Ū kr l ‖ 2 F > λr.
",4.1. Convergence Analysis,[0],[0]
"By item (i), we have that ∞∑ r=1 Pr(Qr) <",4.1. Convergence Analysis,[0],[0]
∞.,4.1. Convergence Analysis,[0],[0]
"Hence by Borel-Cantelli lemma, Qcr0 , Q c r0+1, Q c r0+2, . . .",4.1. Convergence Analysis,[0],[0]
simultaneously hold for some r0 with probability 1.,4.1. Convergence Analysis,[0],[0]
"For simplicity and without loss of generality, we assume that r0 = 0 as it does not affect the asymptotic rate.",4.1. Convergence Analysis,[0],[0]
"Then for any r > 0, we have that
sup l≥0 ‖Ul+kr",4.1. Convergence Analysis,[0],[0]
"− Ū kr l ‖ 2 F ≤ λr
In particular,
‖Ukr+1",4.1. Convergence Analysis,[0],[0]
"− Ū kr lr ‖2F ≤ λr
where lr = kr+1 − kr.",4.1. Convergence Analysis,[0],[0]
"From item (ii), we also conclude that
‖Ūkrlr",4.1. Convergence Analysis,[0],[0]
− Ũ‖ 2 F ≤,4.1. Convergence Analysis,[0],[0]
"A lr−1∑ t=0
1 (t+ kr)2α e −2a
lr−1∑ s=t+1 1 (s+kr)α
+‖Ukr − Ũ‖2Fe −2a
lr−1∑ s=0 1 (s+kr)α
where we introduce µ1 = bn2 and A = 4an4b2 for simplicity.",4.1. Convergence Analysis,[0],[0]
"This leads to
‖Ukr+1 − Ũ‖2F ≤",4.1. Convergence Analysis,[0],[0]
LeLk 1−α r,4.1. Convergence Analysis,[0],[0]
"−Lk 1−α r+1 ‖Ukr − Ũ‖2F+
2λr +A lr∑ t=0
1
(t+ kr)2α eL(kr+t)
1−α−Lk1−αr+1
where L is a suitable constant with different values at different occurrences.",4.1. Convergence Analysis,[0],[0]
"Postponing few more steps to the supplementary material, we obtain that
‖Ukr − Ũ‖2F ≤ L log r rβ− 2 ≤ L rβ−
Take kr < l ≤ kr+1.",4.1. Convergence Analysis,[0],[0]
"We obtain that
‖Ul − Ũ‖22 ≤ 2(‖Ukr − Ũ‖22 + ‖Ukr −Ul‖22)
≤",4.1. Convergence Analysis,[0],[0]
2λr +,4.1. Convergence Analysis,[0],[0]
L rβ− ≤,4.1. Convergence Analysis,[0],[0]
L rβ− ≤,4.1. Convergence Analysis,[0],[0]
"L l β− γ
By taking β = γ(2α− 1)− 1, we obtain part (2).",4.1. Convergence Analysis,[0],[0]
We evaluate the proposed stochastic splitting algorithm in the task of clustering points generated by Gaussians mixture models.,5. Experiments,[0],[0]
We compare the results to the exact algorithm proposed by Lindsten et al. (2011) in terms of a) the quality of the produced clustering and b) the time spent solving the optimization problem.,5. Experiments,[0],[0]
The results of both algorithms are dense embeddings of the points that are then thresholded to form clusters.,5. Experiments,[0],[0]
The clusters are the largest subsets of nodes such that the maximum pairwise distance within the subset is less than τ .,5. Experiments,[0],[0]
The stochastic splitting algorithm is implemented as in Algorithm 1.,5. Experiments,[0],[0]
"We observed in practice
that a heuristic for adaptively setting the step-size improved robustness and rate of convergence.",5. Experiments,[0],[0]
"Specifically, the step size was reduced by a constant factor whenever the average change in the objective over successive rounds in a small window was positive.",5. Experiments,[0],[0]
"If the same average was negative, but small in absolute value, the step size was increased by a small constant factor.
",5. Experiments,[0],[0]
"The data is generated from Gaussian mixture models with two components in R2 where the means are separated by d = √
2 and the variance σ2 is varied.",5. Experiments,[0],[0]
"The number of samples is also varied, to illustrate the computational gains of the stochastic splitting method.",5. Experiments,[0],[0]
"As pointed out by Lindsten et al. (2011), the choice of the regularization parameter λ is perhaps the most challenging hurdle in applying SON clustering.",5. Experiments,[0],[0]
"Choosing λ too high might result in a single large cluster, and choosing it too low may cause each point to be represented by its own cluster.",5. Experiments,[0],[0]
"While this problem is of great importance in applications, we focus on the relative performance of the Lindsten et al. (2011) algorithm (CVX) and stochastic splitting (SS).",5. Experiments,[0],[0]
"We report the adjusted Rand index (Rand, 1971) as measure of cluster quality, and would like to emphasize that this does not rely on identifying the number of clusters beforehand.
",5. Experiments,[0],[0]
Results The results of the experiments are presented in Figures 1 and 2.,5. Experiments,[0],[0]
We see in Figure 1 that the quality of the clustering produced by the stochastic splitting algorithm is comparable to that of the exact algorithm.,5. Experiments,[0],[0]
"This pattern is consistant across choices of σ, where a high σ implies low sample separation between the clusters.",5. Experiments,[0],[0]
We also note that the range of λ for which the stochastic splitting algorithm achieves as good result as the exact algorithm is less wide than for the exact.,5. Experiments,[0],[0]
We believe this is due to the stochastic nature of the algorithm which makes the resulting embedding clusters less separated than in the exact version.,5. Experiments,[0],[0]
"Deviations from the optimal embedding could be magnified by the thresholding step, effectively making the stochastic algorithm more sensitive to the choice of threshold, and in effect the quality more sensitive to the choice of λ.",5. Experiments,[0],[0]
"In these
experiments, the same threshold was used for both algorithms, but tailored choices could be considered given an appropriate selection criterion.
",5. Experiments,[0],[0]
"Furthermore, we see in Figure 2 that the running time of the stochastic splitting algorithm is lower than that of the exact algorithm, and grows significantly slower.",5. Experiments,[0],[0]
"While the stochastic splitting algorithm could in principle be implemented in time constant in the number of samples, and instead determined by the number of iterations, the adaptive stepsize used to improve performance requires evaluation of the objective value which scales with the number of samples.",5. Experiments,[0],[0]
"This could be improved by subsampling the terms in the objective function, but this was not done here.",5. Experiments,[0],[0]
We developed a stochastic incremental algorithm based on proximal iterations for the SON convex relaxtion of clustering that is highly suited to large scale problems and gave an analysis of its convergence propertis.,6. Conclusions,[0],[0]
"We also gave quite general theoretical guaranteees for exact recovery of clusters similar to the unifying proximity condition in approximation algorithms that covers paradigm models for clustering data.
",6. Conclusions,[0],[0]
It has not escaped our attention that our algorithm can easily be adapted to incorporate similarity weights as used in Chi & Lange (2015); Chen et al. (2015); Hocking et al. (2011) and that it is amenable to acceleration using variance reduction and other techniques.,6. Conclusions,[0],[0]
The cluster recovery conditions can also be extended to cover almost perfect recovery i.e. correctly clustering all except a small fraction of points.,6. Conclusions,[0],[0]
A more complete experimental evaluation of our algorithm and comparison to others will be included in a longer version of the paper.,6. Conclusions,[0],[0]
This work is supported in part by the Swedish Foundation for Strategic Research (SSF).,Acknowledgements,[0],[0]
"Standard clustering methods such as K–means, Gaussian mixture models, and hierarchical clustering, are beset by local minima, which are sometimes drastically suboptimal.",abstractText,[0],[0]
Moreover the number of clustersK must be known in advance.,abstractText,[0],[0]
The recently introduced sum–of–norms (SON) or Clusterpath convex relaxation of k-means and hierarchical clustering shrinks cluster centroids toward one another and ensure a unique global minimizer.,abstractText,[0],[0]
We give a scalable stochastic incremental algorithm based on proximal iterations to solve the SON problem with convergence guarantees.,abstractText,[0],[0]
We also show that the algorithm recovers clusters under quite general conditions which have a similar form to the unifying proximity condition introduced in the approximation algorithms community (that covers paradigm cases such as Gaussian mixtures and planted partition models).,abstractText,[0],[0]
We give experimental results to confirm that our algorithm scales much better than previous methods while producing clusters of comparable quality.,abstractText,[0],[0]
"Clustering by Sum of Norms: Stochastic Incremental Algorithm, Convergence and Cluster Recovery",title,[0],[0]
"Cluster analysis aims to gather data instances into groups, called clusters, where instances within one group are similar among themselves while instances in different groups are as dissimilar as possible.",1. Introduction,[0],[0]
"Clustering methods have become more and more popular recently due to their ability to provide new insights into unlabeled data that may be difficult or even impossible to capture for a human being.
",1. Introduction,[0],[0]
"1CNRS, LIPN, Université Paris 13 - Sorbonne Paris Cité, France 2CNRS UMR 5220 - INSERM U1206, Univ.",1. Introduction,[0],[0]
"Lyon 1, INSA Lyon, F-69621 Villeurbanne, France 3CNRS, LJK, Univ.",1. Introduction,[0],[0]
"Grenoble-Alpes, France.",1. Introduction,[0],[0]
"Correspondence to: Charlotte Laclau <charlotte.laclauc@univ-grenoble-alpes.fr>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
0The first author of this paper is now a post-doc in CNRS, LIG, Univ.",1. Introduction,[0],[0]
"Grenoble-Alpes, France
Clustering methods, however, do not take into account the possible existing relationships between the features that describe the data instances.",1. Introduction,[0],[0]
"For example, one may consider a data matrix extracted from text corpus where each document is described by the terms appearing in it.",1. Introduction,[0],[0]
"In this case, clustering documents may benefit from the knowledge about the correlation that exists between different terms revealing their probability of appearing in the same documents.",1. Introduction,[0],[0]
"This idea is the cornerstone of co-clustering (Hartigan, 1972; Mirkin, 1996) where the goal is to perform clustering of both data points and features simultaneously.",1. Introduction,[0],[0]
The obtained latent structure of data is composed of blocks usually called co-clusters.,1. Introduction,[0],[0]
"Applications of co-clustering include but are not limited to recommendation systems (George & Merugu, 2005; Deodhar & Ghosh, 2010; Xu et al., 2012), gene expression analysis (Cheng et al., 2008; Hanisch et al., 2002) and text mining (Dhillon et al., 2003a; Wang et al., 2009).",1. Introduction,[0],[0]
"As a result, these methods are of an increasing interest to the data mining community.
",1. Introduction,[0],[0]
"Co-clustering methods are often distinguished into probabilistic methods (e.g., (Dhillon et al., 2003b; Banerjee et al., 2007; Nadif & Govaert, 2008; Wang et al., 2009; Shan & Banerjee, 2010)) and metric based (e.g., (Rocci & Vichi, 2008; Ding et al., 2006)) methods.",1. Introduction,[0],[0]
Probabilistic methods usually make an assumption that data was generated as a mixture of probability density functions where each one of them corresponds to one co-cluster.,1. Introduction,[0],[0]
The goal then is to estimate the parameters of the underlying distributions and the posterior probabilities of each co-cluster given the data.,1. Introduction,[0],[0]
Metric based approaches proceed in a different way and rely on introducing and optimizing a criterion commonly taking into account intra- and inter-block variances.,1. Introduction,[0],[0]
"This criterion, in its turn, is defined using some proper metric function that describes the geometry of data in the most precise way possible.",1. Introduction,[0],[0]
"Both metric and probabilistic approaches are known to have their own advantages and limitations: despite being quite efficient in modeling the data distribution, probabilistic methods are computationally demanding and hardly scalable; metric methods are less computationally demanding but present the need to choose the “right” distance that uncovers the underlying latent co-clusters’ structure based on available data.",1. Introduction,[0],[0]
"Furthermore, the vast majority of co-clustering methods require the number of co-clusters to be set in advance.",1. Introduction,[0],[0]
"This is usu-
ally done using the computationally expensive exhaustive search over a large number of possible pairs of row and column clusters as in (Keribin et al., 2015; Wyse & Friel, 2012; Wyse et al., 2014).
",1. Introduction,[0],[0]
"In this paper, we address the existing issues of co-clustering methods described above by proposing a principally new approach that efficiently solves the co-clustering problem from both qualitative and computational points of view and allows the automatic detection of the number of coclusters.",1. Introduction,[0],[0]
We pose the co-clustering problem as the task of transporting the empirical measure defined on the data instances to the empirical measure defined on the data features.,1. Introduction,[0],[0]
The intuition behind this process is very natural to co-clustering and consists in capturing the associations between instances and features of the data matrix.,1. Introduction,[0],[0]
The solution of optimal transportation problem is given by a doublystochastic coupling matrix which can be considered as the approximated joint probability distribution of the original data.,1. Introduction,[0],[0]
"Furthermore, the coupling matrix can be factorized into three terms where one of them reflects the posterior distribution of data given co-clusters while two others represent the approximated distributions of data instances and features.",1. Introduction,[0],[0]
We use these approximated distributions to obtain the final partitions.,1. Introduction,[0],[0]
"We also derive a kernelized version of our method that contrary to the original case, is based on an optimal transportation metric defined on the space of dissimilarity functions.
",1. Introduction,[0],[0]
The main novelty of our work is two-fold.,1. Introduction,[0],[0]
"To the best of our knowledge, the proposed approach is a first attempt to apply entropy regularized optimal transport for coclustering and to give its solution a co-clustering interpretation.",1. Introduction,[0],[0]
"While Wasserstein distance has already been adapted to design clustering algorithms (Cuturi & Doucet, 2014; Irpino et al., 2014), our idea is to concentrate our attention on the solution of the optimal transport given by the coupling matrix and not to minimize the quantization error with respect to (w.r.t.)",1. Introduction,[0],[0]
Wasserstein distance.,1. Introduction,[0],[0]
"We also note that using entropy regularization leads to a very efficient algorithm that can be easily parallelized (Cuturi, 2013).",1. Introduction,[0],[0]
"Second, we show that under some plausible assumptions the density estimation procedure appearing from the use of the optimal transport results in the variational inference problem with the minimization of the reversed Kullback-Leibler divergence.",1. Introduction,[0],[0]
The important implications of this difference w.r.t.,1. Introduction,[0],[0]
"other existing methods are explained in Section 3.
",1. Introduction,[0],[0]
The rest of this paper is organized as follows.,1. Introduction,[0],[0]
"In Section 2, we briefly present the discrete version of the optimal transportation problem and its entropy regularized version.",1. Introduction,[0],[0]
"Section 3 proceeds with the description of the proposed approach, its theoretical analysis and algorithmic implementation.",1. Introduction,[0],[0]
"In Section 4, we evaluate our approach on synthetic and real-world data sets and show that it is accurate and
substantially more efficient than the other state-of-the-art methods.",1. Introduction,[0],[0]
Last section concludes the paper and gives a couple of hints for possible future research.,1. Introduction,[0],[0]
"In this section, we present the formalization of the MongeKantorovich (Kantorovich, 1942) optimization problem and its entropy regularized version.",2. Background and notations,[0],[0]
"Optimal transportation theory was first introduced in (Monge, 1781) to study the problem of resource allocation.",2.1. Optimal transport,[0],[0]
"Assuming that we have a set of factories and a set of mines, the goal of optimal transportation is to move the ore from mines to factories in an optimal way, i.e., by minimizing the overall transport cost.
",2.1. Optimal transport,[0],[0]
"More formally, given two empirical probability measures1 µ̂S",2.1. Optimal transport,[0],[0]
= 1 NS ∑NS i=1,2.1. Optimal transport,[0],[0]
δxSi and µ̂T = 1 NT ∑NT i=1,2.1. Optimal transport,[0],[0]
"δxTi defined as uniformly weighted sums of Dirac with mass at locations supported on two point sets XS = {xSi ∈ Rd} NS i=1 and XT = {xTi ∈ Rd} NT i=1, the Monge-Kantorovich problem consists in finding a probabilistic coupling γ defined as a joint probability measure over XS × XT with marginals µ̂S and µ̂T that minimizes the cost of transport w.r.t.",2.1. Optimal transport,[0],[0]
"some metric l : Xs ×Xt → R+:
min γ∈Π(µ̂S ,µ̂T )
〈M,γ〉F
where 〈·,·〉F is the Frobenius dot product, Π(µ̂S , µ̂T ) = {γ ∈ RNS×NT+ |γ1 = µ̂S , γT1 = µ̂T } is a set of doubly stochastic matrices and M is a dissimilarity matrix, i.e.,",2.1. Optimal transport,[0],[0]
"Mij = l(x S i ,x T j ), defining the energy needed to move a probability mass from xSi to x T j .",2.1. Optimal transport,[0],[0]
"This problem admits a unique solution γ∗ and defines a metric on the space of probability measures (called the Wasserstein distance) as follows:
W (µ̂S , µ̂T ) =",2.1. Optimal transport,[0],[0]
"min γ∈Π(µ̂S ,µ̂T )
〈M,γ〉F .
",2.1. Optimal transport,[0],[0]
"The Wasserstein distance has been successfully used in various applications, for instance: computer vision (Rubner et al., 2000), texture analysis (Rabin et al., 2011), tomographic reconstruction (I. Abraham & Carlier, 2016), domain adaptation (Courty et al., 2014), metric learning (Cuturi & Avis, 2014) and clustering (Cuturi & Doucet, 2014; Irpino et al., 2014).",2.1. Optimal transport,[0],[0]
"This latter application is of a particular interest as Wasserstein distance is known to be a very efficient metric due to its capability of taking into account the
1Due space limitation, we present only the discrete version of optimal transport.",2.1. Optimal transport,[0],[0]
"For more details on the general continuous case and the convergence of empirical measures, we refer the interested reader to the excellent monograph by (Villani, 2009).
geometry of data through the pairwise distances between samples.",2.1. Optimal transport,[0],[0]
"The success of algorithms based on this distance is also due to (Cuturi, 2013) who introduced an entropy regularized version of optimal transport that can be optimized efficiently using matrix scaling algorithm.",2.1. Optimal transport,[0],[0]
We present this regularization below.,2.1. Optimal transport,[0],[0]
"The idea of using entropic regularization dates back to (Schrödinger, 1931).",2.2. Entropic regularization,[0],[0]
"In (Cuturi, 2013), it found its application to the optimal transportation problem through the following objective function:
min γ∈Π(µ̂S ,µ̂T )
〈M,γ〉F − 1
λ E(γ).
",2.2. Entropic regularization,[0],[0]
Second term E(γ) =,2.2. Entropic regularization,[0],[0]
"− ∑NS ,NT i,j γi,j log(γi,j) in this equation allows to obtain smoother and more numerically stable solutions compared to the original case and converges to it at the exponential rate (Benamou et al., 2015).",2.2. Entropic regularization,[0],[0]
"Another advantage of entropic regularization is that it allows to solve optimal transportation problem efficiently using Sinkhorn-Knopp matrix scaling algorithm (Sinkhorn & Knopp, 1967).
",2.2. Entropic regularization,[0],[0]
"In the next section, we explain the main underlying idea of our approach that consists in associating data instances with features through regularized optimal transport.",2.2. Entropic regularization,[0],[0]
In this section we show how the co-clustering problem can be casted in a principally new way and then solved using the ideas from the optimal transportation theory.,3. Co-clustering through optimal transport,[0],[0]
"Let us denote by X and Y two random variables taking values in the sets {xr}nr=1 and {yc}dc=1, respectively, where subscripts r and c correspond to rows (instances) and columns (features).",3.1. Problem setup,[0],[0]
"Similar to (Dhillon et al., 2003b), we assume that the joint probability distribution between X and Y denoted by p(X,Y ) is estimated from the data matrix A ∈ Rn×d.",3.1. Problem setup,[0],[0]
We further assume that X and Y consist of instances that are distributed w.r.t.,3.1. Problem setup,[0],[0]
"probability measures µr, µc supported on Ωr,Ωc where Ωr ⊆ Rd and Ωr ⊆ Rn, respectively.
",3.1. Problem setup,[0],[0]
The problem of co-clustering consists in jointly grouping the set of features and the set of instances into homogeneous blocks by finding two assignment functions Cr and Cc that map as follows:,3.1. Problem setup,[0],[0]
"Cr : {x1, . . .",3.1. Problem setup,[0],[0]
",xn} → {x̂1, . . .",3.1. Problem setup,[0],[0]
", x̂g}, Cc : {y1, . . .",3.1. Problem setup,[0],[0]
",yd} → {ŷ1, . . .",3.1. Problem setup,[0],[0]
", ŷm} where g and m denote the number of row and columns clusters, and discrete random variables X̂ and Ŷ represent the partitions induced byX and Y , i.e., X̂ = Cr(X) = and Ŷ = Cc(Y ).
",3.1. Problem setup,[0],[0]
"To use discrete optimal transport, we also define two empirical measures µ̂r and µ̂c based on X and Y as follows: µ̂r",3.1. Problem setup,[0],[0]
= 1 n,3.1. Problem setup,[0],[0]
∑n i=1 δxi and µ̂c = 1 m ∑m i=1,3.1. Problem setup,[0],[0]
δyi .,3.1. Problem setup,[0],[0]
We are now ready to present our method.,3.1. Problem setup,[0],[0]
The main underlying idea of our approach is to use the optimal transportation presented above to find a probabilistic coupling of the empirical measures defined based on rows and columns of a given data matrix.,3.2. Proposed approach,[0],[0]
"More formally, for some fixed λ > 0",3.2. Proposed approach,[0],[0]
"we solve the co-clustering problem through the following optimization procedure:
γ∗λ = argminγ∈Π(µ̂r,µ̂c)〈M, γ〉F − 1
λ E(γ), (1)
where the matrix M is computed using the Euclidean distance, i.e., Mij = ‖xi − yj‖2.",3.2. Proposed approach,[0],[0]
The elements of the resulting matrix γ∗λ provides us with the weights of associations between instances and features: similar instances and features correspond to higher values in γ∗λ.,3.2. Proposed approach,[0],[0]
"Our intuition is to use these weights to identify the most similar sets of rows and columns that should be grouped together to form coclusters.
",3.2. Proposed approach,[0],[0]
"Following (Benamou et al., 2015), this optimization problem can be equivalently rewritten in the following way:
min γ∈Π(µ̂r,µ̂c)
〈M,γ〉F − 1
λ E(γ) =
1 λ min γ∈Π(µ̂r,µ̂c) KL(γ‖ξλ),
where ξλ = e−λM is the Gibbs kernel.
",3.2. Proposed approach,[0],[0]
"Finally, we can rewrite the last expression as follows:
min γ∈Π(µ̂r,µ̂c) KL(γ‖ξλ) =",3.2. Proposed approach,[0],[0]
"min γ∈C KL(γ‖ξλ),
where C = C1 ∩ C2 is the intersection of closed convex subsets given by C1 = {γ ∈ Rd×d|γ1 = µ̂r} and C2 = {γ ∈ Rd×d|γT1 = µ̂c}.",3.2. Proposed approach,[0],[0]
"The solution of the entropy regularized optimal transport can be obtained using Sinkhorn-Knopp algorithm and has the following form (Benamou et al., 2015):
γ∗λ = diag(α)ξλdiag(β), (2)
where α and β are the scaling coefficients of the Gibbs kernel",3.2. Proposed approach,[0],[0]
"ξλ.
",3.2. Proposed approach,[0],[0]
"In what follows, we show that under some plausible assumptions, we can interpret these two vectors as approximated rows and columns probability density functions.",3.2. Proposed approach,[0],[0]
"In order to justify our approach from the theoretical point of view, we first explain how the obtained solution γ∗
can be used for co-clustering.",3.3. Connection to variational inference,[0],[0]
"As mentioned in (Dhillon et al., 2003b) and later in (Banerjee et al., 2007), the co-clustering can be seen as a density estimation problem where the goal is to approximate the real density p(X,Y ) by a simpler one depending on the obtained co-clustering in a way that it preserves the loss in the mutual information given by I(X,Y )",3.3. Connection to variational inference,[0],[0]
"− I(X̂, Ŷ )",3.3. Connection to variational inference,[0],[0]
"where I(X,Y ) = ∫ XY
p(x, y) log p(x,y)p(x)p(y)dxdy is the mutual information.",3.3. Connection to variational inference,[0],[0]
"This quantity is further shown to be equal to the Kullback-Leibler divergence between the original distribution p(X,Y ) and q(X,Y ) where the latter has the following form:
q(x, y)",3.3. Connection to variational inference,[0],[0]
"= p(y|ŷ)p(x̂, ŷ)p(x|x̂).
",3.3. Connection to variational inference,[0],[0]
"From this point, one may instantly see that the solution of the optimal transport problem γ∗ has a very similar form as it also represents the joint probability distribution that approximates the original probability distribution p(x, y) given by the Gibbs measure ξλ and also factorizes into three terms.",3.3. Connection to variational inference,[0],[0]
"The most important difference, however, lies in the asymmetry of the KL divergence: while (Dhillon et al., 2003b) and (Banerjee et al., 2007) concentrate on minimizing KL(p(X,Y )‖q(X,Y )), our idea is different and consists in minimizing KL(q(X,Y )‖p(X,Y )).",3.3. Connection to variational inference,[0],[0]
"This approach is known in the literature as the variational inference (Bishop, 2006) and exhibits a totally different behaviour compared to the minimization of KL(p(X,Y )‖q(X,Y )).",3.3. Connection to variational inference,[0],[0]
"As shown by (Bishop, 2006), in variational inference the estimated distribution q(X,Y ) concentrates on the modes of data and remains compact, while the minimizer of KL(p(X,Y )‖q(X,Y )) tends to cover the whole surface of the original density and to overestimate its support.",3.3. Connection to variational inference,[0],[0]
"As X , Y and X̂ and Ŷ represent the observed and unobserved variables, respectively, the natural goal is to try to estimate the distribution p(X,Y |X̂, Ŷ ) of the data given the obtained co-clusters by the simpler variational distribution q(X,Y ).",3.3. Connection to variational inference,[0],[0]
"However, as the maximisation of p(X,Y |X̂, Ŷ ) is computationally impossible, it is common to introduce a free distribution q(·, ·) on the parameters X̂ and Ŷ in order to obtain the following decomposition:
log p(X,Y )=L(q(X̂, Ŷ ))",3.3. Connection to variational inference,[0],[0]
"+KL(q(X̂, Ŷ )‖p(X̂, Ŷ |X,Y )),
where the lower bound L(q(X̂, Ŷ ))",3.3. Connection to variational inference,[0],[0]
= ∫,3.3. Connection to variational inference,[0],[0]
"x̂∈X̂ ∫ ŷ∈Ŷ q(x̂, ŷ) log p(x, y, x̂, ŷ) q(x̂, ŷ)",3.3. Connection to variational inference,[0],[0]
"dx̂dŷ
is maximized when the KL divergence is minimized.
",3.3. Connection to variational inference,[0],[0]
"Now, if we assume that p(X̂, Ŷ |X,Y ) follows the Gibbs distribution, i.e. p(X̂, Ŷ |X,Y ) ∝",3.3. Connection to variational inference,[0],[0]
"e−λM(x,y)",3.3. Connection to variational inference,[0],[0]
", we can consider the original formulation of the regularized optimal transport as the variational inference problem:
min q KL(q(X̂, Ŷ )‖p(X̂, Ŷ |X,Y ))",3.3. Connection to variational inference,[0],[0]
=,3.3. Connection to variational inference,[0],[0]
"min γ KL(γ‖ξλ),
where the optimal coupling γ equals to the estimated joint probability q(X̂, Ŷ ).
",3.3. Connection to variational inference,[0],[0]
"At this point, we know that the coupling matrix can be seen as an approximation to the original unknown posterior density function but the question how one can use it to obtain the clustering of rows and columns has not been answered yet.",3.3. Connection to variational inference,[0],[0]
"In order to solve the variational inference problem, it is usually assumed that the variables x̂, ŷ are independent and thus the variational distribution q(x̂, ŷ) factorizes as q(x̂, ŷ)",3.3. Connection to variational inference,[0],[0]
= q(x̂)q(ŷ).,3.3. Connection to variational inference,[0],[0]
"This assumption, however, goes against the whole idea of co-clustering that relies on the existence of a deep connection between these two variables.
",3.3. Connection to variational inference,[0],[0]
"To this end, we propose to consider the factorization of q(x̂, ŷ)",3.3. Connection to variational inference,[0],[0]
"that has the following form
q(x̂, ŷ) = q(x)q(x̂, ŷ|x, y)q(y).
",3.3. Connection to variational inference,[0],[0]
"This particular form follows the idea of structured stochastic variational inference proposed in (Hoffman & Blei, 2015) where a term depicting the conditional distribution between hidden and observed variables is added to the fully factorized traditional setting presented above.",3.3. Connection to variational inference,[0],[0]
"As stated in (Hoffman & Blei, 2015), this term allows arbitrary dependencies between observed and hidden variables which can increase the fidelity of the approximation.
",3.3. Connection to variational inference,[0],[0]
"Following (Bishop, 2006), the optimal estimated densities q(x) and q(y) are controlled by the direction of the smallest variance of p(x) and p(y) respectively.",3.3. Connection to variational inference,[0],[0]
"Furthermore, q(x) and q(y) are proportional to the joint densities p(ŷ, y) and p(x̂, x), i.e., q(x) ∝",3.3. Connection to variational inference,[0],[0]
"p(ŷ, y) and q(y) ∝",3.3. Connection to variational inference,[0],[0]
"p(x̂, x).",3.3. Connection to variational inference,[0],[0]
"Bearing in mind the equivalence between γ∗λ and q(x̂, ŷ), this brings us to the following important conclusions: (1) the matrices diag(α) and diag(β) can be seen as the approximated densities p(Ŷ , Y ) and p(X̂,X); (2) vectors α and β represent the approximated densities p(X) and p(Y ) obtained by summing X and Y out of p(X̂,X) and p(Ŷ , Y ), respectively.
",3.3. Connection to variational inference,[0],[0]
"According to (Laird, 1978), the non-parametric estimate of the mixing distribution is a piecewise step function where the number of steps depend on the number of components in the mixture.",3.3. Connection to variational inference,[0],[0]
"In the cluster analysis, we can assume that p(X) and p(Y ) consist of g and m components, respectively.",3.3. Connection to variational inference,[0],[0]
"Then, our goal is to detect these steps based on the estimates given byα and β to obtain the desired partitions.",3.3. Connection to variational inference,[0],[0]
"In this part, we introduce the kernelized version of our method and compare it to the original formulation of our algorithm.",3.4. Kernelized version and Gromov-Wasserstein distance,[0],[0]
"In order to proceed, we first define two similarity matrices Kr ∈ Rn×n and Kc ∈ Rd×d associated to empirical measures µ̂r, µ̂c thus forming metric-measure
spaces as in (Mémoli, 2011).",3.4. Kernelized version and Gromov-Wasserstein distance,[0],[0]
"Matrices Kr and Kc are defined by calculating the pairwise distances or similarities between rows and columns, respectively, without the restriction of them being positive or calculated based on a proper distance function satisfying the triangle inequality.",3.4. Kernelized version and Gromov-Wasserstein distance,[0],[0]
"The entropic Gromov-Wasserstein discrepancy in this case is defined as follows (Peyré et al., 2016):
GW(Kr,Kc, µ̂r, µ̂c)",3.4. Kernelized version and Gromov-Wasserstein distance,[0],[0]
"= min γ∈Πµ̂r,µ̂c ΓKr,Kc(γ)− λE(γ)
=",3.4. Kernelized version and Gromov-Wasserstein distance,[0],[0]
"min T∈Πµ̂r,µ̂c ∑ i,j,k,l L(Kri,j ,Kck,l)γi,jγk,l − λE(γ).
where γ is a coupling matrix between two similarity matrices and L : R × R → R+ is an arbitrary lost-function, usually the quadratic-loss or Kullback-Leibler divergence.
",3.4. Kernelized version and Gromov-Wasserstein distance,[0],[0]
"Based on this definition, one may define the problem of the entropic Gromov-Wasserstein barycenters for similarity or distance matrices Kr and Kc as follows:
min K,γr,γc ∑ i={r,c} εiΓK,Ki(γi)− λE(γi) (3)
where K is the computed barycenter and γr ∈ Πµ̂,µ̂r , γc ∈ Πµ̂,µ̂c are the coupling matrices that align it with Kr and Kc, respectively.",3.4. Kernelized version and Gromov-Wasserstein distance,[0],[0]
"εi are the weighting coefficients summing to one, i.e., ∑ i={r,c} εi = 1 that determine our interest in more accurate alignment between Kr and K or Kc and K.
The intuition behind this optimization procedure for coclustering with respect to original formulation given in (1) is the following: while in (1) we align rows with columns directly, in (3) our goal is to do it via an intermediate representation given by the barycenter K that is optimally aligned with both Kr and Kc.",3.4. Kernelized version and Gromov-Wasserstein distance,[0],[0]
"In this case, we obtain the solutions γr and γc that, similar to (2), can be decomposed as follows:
γ∗r = diag(αr)ξrdiag(βr), γ ∗ c = diag(αc)ξcdiag(βc)
where ξr = e−λMr and ξc = e−λMc are Gibbs kernels calculated between the barycenter and row and column similarity matrices using any arbitrary loss-function L as explained before.",3.4. Kernelized version and Gromov-Wasserstein distance,[0],[0]
"Finally, based on the analysis presented above, we further use vectors βr",3.4. Kernelized version and Gromov-Wasserstein distance,[0],[0]
and βc to derive row and column partitions.,3.4. Kernelized version and Gromov-Wasserstein distance,[0],[0]
"In order to detect the steps (or jumps) in the approximated marginals, we propose to adapt a procedure introduced in (Matei & Meignen, 2012) for multiscale denoising of piecewise smooth signals.",3.5. Detecting the number of clusters,[0],[0]
"This method is of particular interest for us as it determines the significant jumps in the vectors α and β without knowing their number and location, nor a specific threshold to decide the significance
of a jump.",3.5. Detecting the number of clusters,[0],[0]
"As the proposed procedure deals with nondecreasing functions, we first sort the values of α and β in the ascending order.",3.5. Detecting the number of clusters,[0],[0]
"Since the procedure is identical for both vectors, we only describe it for the vector α.
",3.5. Detecting the number of clusters,[0],[0]
We consider that the elements {αi}ni=1 of α are the local averages of a piecewise continuous function v :,3.5. Detecting the number of clusters,[0],[0]
"[0, 1[⊂ R → R on the intervals Ini",3.5. Detecting the number of clusters,[0],[0]
=,3.5. Detecting the number of clusters,[0],[0]
"[i/n, (i + 1)/n[ defined by the uniform subdivision of step 1/n of the interval",3.5. Detecting the number of clusters,[0],[0]
"[0, 1[.",3.5. Detecting the number of clusters,[0],[0]
"More precisely: αni = n ∫ Ini v(t)dt, i = 0, . . .",3.5. Detecting the number of clusters,[0],[0]
", n− 1.",3.5. Detecting the number of clusters,[0],[0]
The detection strategy is based on the following cost function: F (Ini ) =,3.5. Detecting the number of clusters,[0],[0]
∑i,3.5. Detecting the number of clusters,[0],[0]
l=i−1 |αnl+1,3.5. Detecting the number of clusters,[0],[0]
− αnl | defined for each interval.,3.5. Detecting the number of clusters,[0],[0]
"Therefore, we get the list of the interval suspicious to contain a jump for the subdivision of order n as follows:
Ln = {i∗; i∗ = argmaxiF(Ini )}.
",3.5. Detecting the number of clusters,[0],[0]
This detection should be refined in order to get only significant jumps in our vector α.,3.5. Detecting the number of clusters,[0],[0]
"To this end we use the multiscale representation of α as in (Harten, 1989) and we perform this detection on each scale.",3.5. Detecting the number of clusters,[0],[0]
"On the first scale, we get a coarse version of α by averaging:
α n/2 i =
1 2 (αn2i + α n 2i+1), i = 0, . . .",3.5. Detecting the number of clusters,[0],[0]
", n/2− 1.
",3.5. Detecting the number of clusters,[0],[0]
"Now, by considering the coarse version of α, we obtain a second list Ln/2 of suspicious intervals as before.",3.5. Detecting the number of clusters,[0],[0]
"After that, these two lists merge in the list Ljumps as follows: a jump will be considered in the interval In2i",3.5. Detecting the number of clusters,[0],[0]
or I n 2i+1 if the interval In/2i is also detected as suspicious at the coarse scale.,3.5. Detecting the number of clusters,[0],[0]
This procedure is iterated [log2 n] times and a jump is observed if a chain of detection exists from fine to coarse scales.,3.5. Detecting the number of clusters,[0],[0]
"Finally, the number of clusters is obtained by g = |Ljumps|+ 1.",3.5. Detecting the number of clusters,[0],[0]
We now briefly summarize the main steps of both CCOT and CCOT-GW methods and discuss their peculiarities with respect to each other.,3.6. Algorithmic implementation,[0],[0]
"The pseudocode of both approaches in Matlab are presented in Algorithm 1 and Algorithm 2, respectively.
",3.6. Algorithmic implementation,[0],[0]
CCOT First step of our algorithm consists in calculating the cost matrix M and using it to obtain the optimal coupling matrix γ∗λ by applying the regularized optimal transport.,3.6. Algorithmic implementation,[0],[0]
"In order to calculate M , row and column instances should both lie in a space of the same dimension.",3.6. Algorithmic implementation,[0],[0]
"This condition, however, is verified only if the matrix A is squared which occurs rarely in the real-world applications.",3.6. Algorithmic implementation,[0],[0]
"To overcome this issue, we first subsample the original data set A in a way that allows us to equalize the number of rows and columns and operate with two sets of the same dimension.",3.6. Algorithmic implementation,[0],[0]
If we assume that n,3.6. Algorithmic implementation,[0],[0]
> d then this new reduced data set is denoted by D ∈ Rd×d.,3.6. Algorithmic implementation,[0],[0]
"We repeat the sampling procedure until every individual is picked at least once.
",3.6. Algorithmic implementation,[0],[0]
"The next step is to perform for each i = 1, . . .",3.6. Algorithmic implementation,[0],[0]
", ns the jump detection on the sorted vectorsαi and βi to obtain two lists of the jumps locations Lαijumps and L βi jumps and to define the number of row and column clusters g and m. By using them, we obtain the resulting row partition:
Cir(xr) =  1, r ≤ Lαijumps(1) . . .",3.6. Algorithmic implementation,[0],[0]
"k, Lαijumps(k − 1)",3.6. Algorithmic implementation,[0],[0]
< r ≤,3.6. Algorithmic implementation,[0],[0]
"L αi jumps(k)
. .",3.6. Algorithmic implementation,[0],[0]
.,3.6. Algorithmic implementation,[0],[0]
"|Lαijumps|+ 1, r > L αi jumps(|L αi jumps|).
",3.6. Algorithmic implementation,[0],[0]
The partition for columns Cic(yc) is obtained in the same way.,3.6. Algorithmic implementation,[0],[0]
"Finally, we apply the majority vote over all samples partitions to obtain Cr and Cc.",3.6. Algorithmic implementation,[0],[0]
"Regarding complexity, both Sinkhorn-Knopp algorithm used to solve the regularized optimal transport (Knight, 2008) and the proposed jump detection techniques are known to converge at the linear rate multiplied by the number of samples, i.e.,O(nsd).",3.6. Algorithmic implementation,[0],[0]
"On the other hand, the calculation of modes of the clustering obtained on the generated samples for both features and data instances has the complexityO(ns(n+d)).",3.6. Algorithmic implementation,[0],[0]
"In the end, the complexity of the whole algorithm is O(ns(n + d)).",3.6. Algorithmic implementation,[0],[0]
"We also note that in the real-world applications, we usually deal with scenarios where n d (“big data”) or d n",3.6. Algorithmic implementation,[0],[0]
"(“small” data) thus reducing the overall complexity to O(nsn) and O(nsd), respectively.",3.6. Algorithmic implementation,[0],[0]
"This makes our approach even more computationally attractive.
",3.6. Algorithmic implementation,[0],[0]
Algorithm 1 Co-clustering through Optimal Transport (CCOT),3.6. Algorithmic implementation,[0],[0]
"Input : A - data matrix, λ - regularization parameter, ns - number of sampling Output: Cr, Cc - partition matrices for rows and columns, g,m - number of row and column clusters [n, d] = size(Z) for i = 1 to ns do
Di = datasample(Z, d)",3.6. Algorithmic implementation,[0],[0]
"Mi ← pdist2(Di, DTi)",3.6. Algorithmic implementation,[0],[0]
"[αi,βi, γ
∗]← optimal transport(Mi, λ)",3.6. Algorithmic implementation,[0],[0]
"[Lαijumps, C i r, g]← jump detection(sort(αi))",3.6. Algorithmic implementation,[0],[0]
"[Lβijumps, C i c, m]← jump detection(sort(βi))
",3.6. Algorithmic implementation,[0],[0]
Cr ← mode(Cir),3.6. Algorithmic implementation,[0],[0]
"Cc ← mode(Cic)
CCOT-GW As it can be seen from Algorithm 2, CCOT-GW allows to overcome the important disadvantage of CCOT that consists in the need to perform sampling to cluster all data objects.",3.6. Algorithmic implementation,[0],[0]
"On the other hand, the computational complexity of CCOT is only O(nsd), while for CCOT-GW it scales as O(n2d + d2n).",3.6. Algorithmic implementation,[0],[0]
We also note that CCOT-GW offers a great flexibility in terms of the possible data representation used at its input.,3.6. Algorithmic implementation,[0],[0]
"One may easily consider using any arbitrary kernel function to calculate similarity matrices or even learn them beforehand using multiple-kernel learning approaches.
",3.6. Algorithmic implementation,[0],[0]
"Algorithm 2 Co-clustering through Optimal Transport with Gromov-Wasserstein barycenters (CCOT-GW) Input : A - data matrix, λ - regularization parameter, εr , εc - weights for barycenter calculation Output: Cr, Cc - partition matrices for rows and columns, g,m - number of row and column clusters Kr ← pdist2(Z, Z)",3.6. Algorithmic implementation,[0],[0]
"Kc ← pdist2(ZT, ZT) [βr,βc, γ ∗ r , γ ∗",3.6. Algorithmic implementation,[0],[0]
c,3.6. Algorithmic implementation,[0],[0]
"]← gw barycenter(Kr, Kc, λ, εr, εc)",3.6. Algorithmic implementation,[0],[0]
"[Lβrjumps, Cr, g]← jump detection(sort(βr))",3.6. Algorithmic implementation,[0],[0]
"[Lβcjumps, Cc, m]← jump detection(sort(βc))",3.6. Algorithmic implementation,[0],[0]
"In this section, we provide empirical evaluation for the proposed algorithms.",4. Experimental evaluations,[0],[0]
"Simulation setting We simulate data following the generative process of the Gaussian Latent Block Models (for details see (Govaert & Nadif, 2013)) and we consider four scenarios with different number of co-clusters, degree of separation and size.",4.1. Synthetic data,[0],[0]
"Table 1 and Figure 1 present the characteristics of theta simulated data sets and their visualization showing the different co-clustering structures.
",4.1. Synthetic data,[0],[0]
"We use several state-of-the-art co-clustering algorithms as baselines including ITCC (Dhillon et al., 2003b), Double K-Means (DKM) (Rocci & Vichi, 2008), Orthogonal Nonnegative Matrix Tri-Factorizations (ONTMF) (Ding et al., 2006), the Gaussian Latent Block Models (GLBM) (Nadif & Govaert, 2008; Govaert & Nadif, 2013) and Residual Bayesian Co-Clustering (RBC) (Shan & Banerjee, 2010).
",4.1. Synthetic data,[0],[0]
"We also report the results of K-means and NMF, run on both modes of the data matrix, as clustering baseline.",4.1. Synthetic data,[0],[0]
"To assess the performance of all compared methods, we compute the co-clustering error (CCE) (Patrikainen & Meila, 2006) defined as follows:
CCE((z,w), (ẑ, ŵ))",4.1. Synthetic data,[0],[0]
"= e(z, ẑ)+e(w, ŵ)−e(z, ẑ)×e(w, ŵ),
where ẑ and ŵ are the partitions of instances and variables estimated by the algorithm; z and w are the true partitions and e(z, ẑ) (resp.",4.1. Synthetic data,[0],[0]
"e(w, ŵ)) denotes the error rate, i.e., the proportion of misclassified instances (resp. features).
",4.1. Synthetic data,[0],[0]
"For all configurations, we generate 100 data sets and compute the mean and standard deviation of the CCE over all sets.",4.1. Synthetic data,[0],[0]
"As all the approaches we compared with are very sensitive to the initialization, we run them 50 times with random initializations and retain the best result according to the corresponding criterion.",4.1. Synthetic data,[0],[0]
RBC is initialized with Kmeans.,4.1. Synthetic data,[0],[0]
"Regarding CCOT we set ns to 1000 for all configurations except D4 which has the same number of rows and columns, and therefore does not require any sampling.",4.1. Synthetic data,[0],[0]
"For CCOT-GW, we use Gaussian kernels for both rows and columns with σ computed as the mean of all pairwise Euclidean distances between vectors (Kar & Jain, 2011).",4.1. Synthetic data,[0],[0]
"Finally, we let both CCOT and CCOT-GW detect automatically the number of co-clusters, while for all other algorithms we set the number of clusters to its true value.
",4.1. Synthetic data,[0],[0]
Co-clustering performance We report the mean (and standard deviation) of co-clustering errors obtained in Table 2.,4.1. Synthetic data,[0],[0]
"Based on these results, we observe that on D1, which has a clear block structure, all algorithms perform equally well, however CCOT-GW gives the best results, closely followed by CCOT and K-means.",4.1. Synthetic data,[0],[0]
"Regarding D2, D3 and D4, which have more complicated structure than D1, both CCOT and CCOT-GW significantly outperform all other algorithms and this difference is all the more important on D3 and D4 where some of the compared algorithms are unable to find a partition with the desired number of clusters.
",4.1. Synthetic data,[0],[0]
"Furthermore, we argued that one of the strengths of our method is its ability to detect automatically the number of co-clusters by applying a jump detection algorithm on α and β.",4.1. Synthetic data,[0],[0]
"From Figure 2 one can observe that the plots
of these vectors, obtained with CCOT, with their elements sorted in the ascending order reveal clear steps that correspond to the correct number of clusters and also illustrate their proportions and the degree of overlapping.",4.1. Synthetic data,[0],[0]
The same observation is valid for CCOT-GW.,4.1. Synthetic data,[0],[0]
"Both approaches correctly identified the number of clusters in most cases and CCOT is slightly more accurate than CCOT-GW when the proportions of co-clusters are unbalanced.
",4.1. Synthetic data,[0],[0]
"To summarize, CCOT and CCOT-GW outperform all the other baselines for the considered data structures and present two important advantages: (1) they do not suffer from the initialization issues, (2) they are able to detect automatically the number co-clusters.",4.1. Synthetic data,[0],[0]
"Data and setting MOVIELENS-100K2 is a popular benchmark data set that consists of user-movie ratings, on a scale of one to five, collected from a movie recommendation service gathering 100,000 ratings from 943 users on 1682 movies.",4.2. MovieLens,[0],[0]
"In the context of co-clustering, our goal is to find homogeneous subgroups of users and films in order to further recommend previously unseen movies that were
2https://grouplens.org/datasets/movielens/100k/
highly rated by the users from the same group.
",4.2. MovieLens,[0],[0]
"We set the regularization parameters for CCOT and CCOT-GW using the cross-validation; the number of samplings for CCOT is set to 500 (as the dimensions of the data set are quite balanced); the weights for the barycenter in CCOT-GW are set to ε = (0.5, 0.5).
",4.2. MovieLens,[0],[0]
Results In what follows we only present figures and results obtained by CCOT-GW as both algorithms return the same number of blocks and the partitions are almost identical (with a normalized mutual information between partitions above 0.8).,4.2. MovieLens,[0],[0]
"CCOT-GW automatically detects a structure consisting of 9× 15 blocks, that corresponds to 9 user clusters and 15 movie clusters.",4.2. MovieLens,[0],[0]
"From Figure 3, one can observe that the users and the movies are almost equally distributed across clusters, except for two user and three movie clusters which have a larger size than others.
",4.2. MovieLens,[0],[0]
"Figure 4 shows the original data set as well as a summarized version where each block is represented by its mean rating value (the lighter the block, the higher the ratings), revealing a structure into homogeneous groups.",4.2. MovieLens,[0],[0]
One can observe that the first movie cluster consists of films for which all users agree on giving high ratings (most popular movies) while the last movie cluster consists of the movies with very low ratings.,4.2. MovieLens,[0],[0]
We also report the 5 best rated movies in those two clusters in Table 3.,4.2. MovieLens,[0],[0]
"One can easily see that popular movies, such that both Star Wars episodes are in M1 while M5 is composed of movies that were less critically acclaimed.
",4.2. MovieLens,[0],[0]
We can make similar observations for the interpretation of user clusters.,4.2. MovieLens,[0],[0]
"For instance, the last two user clusters include users that tend to give less good ratings to movies than the average population.",4.2. MovieLens,[0],[0]
"Also, we note that block (6, 10)",4.2. MovieLens,[0],[0]
"cor-
responds to users who liked movies from M10 better than the rest of the users.",4.2. MovieLens,[0],[0]
"These observations are also very similar to the results reported by (Banerjee et al., 2007), where the authors proposed a detailed study of a 10 × 20 blocks structure for this data set.",4.2. MovieLens,[0],[0]
Additional results can be found in the Supplementary material.,4.2. MovieLens,[0],[0]
In this paper we presented a novel approach for coclustering based on the entropy regularized optimal transport.,5. Conclusions and future perspectives,[0],[0]
Our method is principally different from other coclustering methods and consists in finding a probabilistic coupling of the empirical measures defined based on the data instances and features.,5. Conclusions and future perspectives,[0],[0]
We showed how this procedure can be seen as the variational inference problem and that the inferred distribution can be used to obtain the row and feature partitions.,5. Conclusions and future perspectives,[0],[0]
The resulting algorithm is not only more accurate than other state-of-the-art methods but also fast and capable of automatically detecting the number of co-clusters.,5. Conclusions and future perspectives,[0],[0]
"We also presented an extended version of our algorithm that makes use of the optimal transportation distance defined on similarity matrices associated to the rows’ and columns’ empirical measures.
",5. Conclusions and future perspectives,[0],[0]
"In the future, our work can be continued in multiple directions.",5. Conclusions and future perspectives,[0],[0]
"First, we would like to extend our method in order to deal with the online setting where the goal is to classify a new previously unseen observation without the need to do the co-clustering of the data set that includes it.",5. Conclusions and future perspectives,[0],[0]
"This can be done using a recent approach proposed in (Perrot et al., 2016) that allows to update the learned coupling matrix using the out-of-sample observations without recomputing it using all the data.",5. Conclusions and future perspectives,[0],[0]
We believe that this extension will make our algorithm attractive for the exploitation in real-time industrial recommendation systems due to its computational efficiency.,5. Conclusions and future perspectives,[0],[0]
"We would also like to study the generalization properties of our algorithm in a spirit similar to the results obtained in (Maurer & Pontil, 2010).",5. Conclusions and future perspectives,[0],[0]
This latter work presents a rare case where the generalization bounds are derived for some famous unsupervised learning algorithms.,5. Conclusions and future perspectives,[0],[0]
"This work has been supported by the ANR project COCLICO, ANR-12-MONU-0001.",Acknowledgements,[0],[0]
"In this paper, we present a novel method for co-clustering, an unsupervised learning approach that aims at discovering homogeneous groups of data instances and features by grouping them simultaneously.",abstractText,[0],[0]
The proposed method uses the entropy regularized optimal transport between empirical measures defined on data instances and features in order to obtain an estimated joint probability density function represented by the optimal coupling matrix.,abstractText,[0],[0]
This matrix is further factorized to obtain the induced row and columns partitions using multiscale representations approach.,abstractText,[0],[0]
"To justify our method theoretically, we show how the solution of the regularized optimal transport can be seen from the variational inference perspective thus motivating its use for co-clustering.",abstractText,[0],[0]
"The algorithm derived for the proposed method and its kernelized version based on the notion of Gromov-Wasserstein distance are fast, accurate and can determine automatically the number of both row and column clusters.",abstractText,[0],[0]
These features are vividly demonstrated through extensive experimental evaluations.,abstractText,[0],[0]
Co-clustering through Optimal Transport,title,[0],[0]
"Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2357–2366, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.",text,[0],[0]
"As science advances, scientists around the world continue to produce a large number of research articles, which provide the technological basis for worldwide dissemination of scientific discoveries.",1 Introduction,[0],[0]
"Online digital libraries such as Google Scholar, CiteSeerx, and PubMed store and index millions of such research articles and their metadata, and make it easier for researchers to search for scientific information.",1 Introduction,[0],[0]
These libraries require effective and efficient methods for topic classification of research articles in order to facilitate the retrieval of content that is tailored to the interests of specific individuals or groups.,1 Introduction,[0],[0]
"Supervised approaches for topic classification of research articles have been developed, which generally use either the content of the articles (Caragea et al., 2011), or take into account the citation relation between research articles (Lu and Getoor, 2003).
",1 Introduction,[0],[0]
"To be successful, these supervised approaches assume the availability of large amounts of labeled
data, which require intensive human labeling effort.",1 Introduction,[0],[0]
"In this paper, we explore a semi-supervised approach that can exploit large amounts of unlabeled data together with small amounts of labeled data for accurate topic classification of research articles, while minimizing the human effort required for data labeling.",1 Introduction,[0],[0]
"In the scholarly domain, research articles (or papers) are highly interconnected in giant citation networks, in which papers cite or are cited by other papers.",1 Introduction,[0],[0]
"We posit that, in addition to a document’s textual content and its local neighborhood in the citation network, other information exists that has the potential to improve topic classification.",1 Introduction,[0],[0]
"For example, in a citation network, information flows from one paper to another via the citation relation (Shi et al., 2010).",1 Introduction,[0],[0]
"This information flow and the topical influence of one paper on another are specifically captured by means of citation contexts, i.e., short text segments surrounding a citation’s mention.
",1 Introduction,[0],[0]
"These contexts are not arbitrary, but they often serve as brief summaries of a cited paper.",1 Introduction,[0],[0]
"We therefore hypothesize that these micro-summaries can be successfully used as an independent view of a research article in a co-training framework to reduce the amount of labeled data needed for the task of topic classification.
",1 Introduction,[0],[0]
"The idea of using terms from citation contexts stems from the analysis of hyperlinks and the graph structure of the Web, which are instrumental in Web search (Manning et al., 2008).",1 Introduction,[0],[0]
"Many search engines follow the intuition that the anchor text pointing to a page is a good descriptor of its content, and thus anchor text terms are used as additional index terms for a target webpage.",1 Introduction,[0],[0]
"The use of links and anchor text was thoroughly researched for information retrieval (Koolen and Kamps, 2010), broadening a user’s search (Chakrabarti et al., 1998), query refinement (Kraft and Zien, 2004), and enriching document representations (Metzler et al., 2009).",1 Introduction,[0],[0]
"Blum and
2357
Mitchell (1998) introduced the co-training algorithm using hyperlinks and anchor text as a second, independent view of the data for classifying webpages, in addition to a webpage content.
",1 Introduction,[0],[0]
Contributions and Organization.,1 Introduction,[0],[0]
"We present a co-training approach to topic classification of research papers that effectively incorporates information from a citation network, in addition to the information contained in each paper.",1 Introduction,[0],[0]
"The result of this classification task will aid indexing of documents in digital libraries, and hence, will lead to improved organization, search, retrieval, and recommendation of scientific documents.",1 Introduction,[0],[0]
"Our contributions are as follows:
• We propose the use of citation contexts as an additional view in a co-training approach, which results in high accuracy classifiers.",1 Introduction,[0],[0]
"To our knowledge, this has not been addressed in the literature.",1 Introduction,[0],[0]
"• We show experimentally that our co-training
classifiers significantly outperform: (1) supervised classifiers trained using either content or citation contexts independently, for the same fraction of labeled data; and (2) several other semi-supervised classifiers, trained on the same fractions of labeled and unlabeled data as co-training.",1 Introduction,[0],[0]
"• We also show that using the citation context
information available in citation networks, the human effort involved in data labeling for training accurate classifiers can be largely reduced.",1 Introduction,[0],[0]
"Our co-training classifiers trained on a very small sample of labeled data and a large sample of unlabeled data yield accurate topic classification of research articles.
",1 Introduction,[0],[0]
The rest of the paper is organized as follows.,1 Introduction,[0],[0]
"In Section 2, we discuss related work.",1 Introduction,[0],[0]
"Section 3 describes our data and its characteristics, followed by the presentation of our proposed co-training approach in Section 4.",1 Introduction,[0],[0]
"We present experiments and results in Section 5, and conclude the paper and present future directions of our work in Section 6.",1 Introduction,[0],[0]
We discuss here the most relevant works to our study.,2 Related Work,[0],[0]
A large variety of methods have been proposed in the literature with regard to automatic text classification and topic prediction.,2 Related Work,[0],[0]
"Different classifiers have been applied on the Vector Space Model (VSM), in which a document is represented as a vector of words or phrases asso-
ciated with their TF-IDF score, i.e. term frequency - inverse document frequency (Zhang et al., 2011; Kansheng et al., 2011).",2 Related Work,[0],[0]
"VSM is the most used method due to its simple, efficient and easy to understand implementation.",2 Related Work,[0],[0]
"Another widely used model is the Latent Semantic Indexing (LSI) where co-occurrences are analyzed to find semantic relationships between words or phrases (Zhang et al., 2011; Ganiz et al., 2011).",2 Related Work,[0],[0]
"Moreover, a great range of classifiers were used for this task, including: Naı̈ve Bayes (Lewis and Ringuette, 1994), Knearest neighbors (Yang, 1999) and Support Vector Machines (Joachims, 1998).",2 Related Work,[0],[0]
"These techniques, however, all require a large number of labeled documents in order to build accurate classifiers.",2 Related Work,[0],[0]
"In contrast, we propose a co-training algorithm that only requires a small amount of labeled data in order to make accurate topic classification.
Semi-supervised methods essentially involve different means of transferring labels from labeled to unlabeled samples in the process of learning a classifier that can generalize well on new unseen data.",2 Related Work,[0],[0]
"Co-training was originally introduced in (Blum and Mitchell, 1998) where it was used to classify web pages into academic course home page or not.",2 Related Work,[0],[0]
"This approach has two views of the data as follows: the content of a web page, and the words found in the anchor text of the hyperlinks that point to the web page.",2 Related Work,[0],[0]
"Wan (2009) used co-training for cross-lingual sentiment classification of product reviews, where English and Chinese features were considered as two independent views of the data.",2 Related Work,[0],[0]
"Furthermore, Gollapalli et al. (2013) used co-training to identify authors’ homepages from the current-day university websites.",2 Related Work,[0],[0]
"The paper presents novel features, extracted from the URL of a page, that were used in conjunction with content features, forming two complementary views of the data.
",2 Related Work,[0],[0]
Citation networks have been used before in other problems.,2 Related Work,[0],[0]
Caragea et al. (2014) used citation contexts to extract informative features for keyphrase extraction.,2 Related Work,[0],[0]
"Lu and Getoor (2003) proposed an approach for document classification that used only citation links, without any textual data from the citation contexts.",2 Related Work,[0],[0]
Ritchie et al. (2006) used a combination of terms from citation contexts and existing index terms of a paper to improve indexing of cited papers.,2 Related Work,[0],[0]
"Citation contexts were also used to improve the performance of citation recommendation systems (Kataria et al., 2010) and to study author influence in document networks
(Kataria et al., 2011).",2 Related Work,[0],[0]
"Moreover, citation contexts were used for scientific paper summarization (Abu-Jbara and Radev, 2011; Qazvinian et al., 2010; Qazvinian and Radev, 2008; Mei and Zhai, 2008; Lehnert et al., 1990)",2 Related Work,[0],[0]
"For example, in Qazvinian et al. (2010), a set of important keyphrases is extracted first from the citation contexts in which the paper to be summarized is cited by other papers and then the “best” subset of sentences that contain such keyphrases is returned as the summary.",2 Related Work,[0],[0]
Mei and Zhai (2008) used information from citation contexts to determine what sentences of a paper are of high impact (as measured by the influence of a target paper on further studies of similar or related topics).,2 Related Work,[0],[0]
"These sentences constitute the impact-based summary of the paper.
",2 Related Work,[0],[0]
"Despite the use of citation contexts and anchor text in many information retrieval and natural language processing tasks, to our knowledge, we are the first to propose the incorporation of citation context information available in citation networks in a co-training framework for topic classification of research papers.",2 Related Work,[0],[0]
The dataset used in our experiments is a subset sampled from the CiteSeerx digital library1 and labeled by Dr. Lise Getoor’s research group at the University of Maryland.,3 Data,[0],[0]
"This subset was previously used in several studies including (Lu and Getoor, 2003) and (Kataria et al., 2010).",3 Data,[0],[0]
"The dataset consists of 3186 labeled papers, with each paper being categorized into one of six classes: Agents, Artificial Intelligence (AI), Information Retrieval (IR), Machine Learning (ML), HumanComputer Interaction (HCI) and Databases (DB).",3 Data,[0],[0]
"For each paper, we acquire the citation contexts directly from CiteSeerx.",3 Data,[0],[0]
A citation context is defined as a window of n words surrounding a citation mention.,3 Data,[0],[0]
"We differentiate between cited and citing contexts for a paper as follows: let d be a target paper and C be a citation network such that d ∈ C. A cited context for d is a context in which d is cited by some paper di in C. A citing context for d is a context in which d is citing some paper dj in C. If a paper is cited in multiple contexts within another paper, the contexts are aggregated into a single context.",3 Data,[0],[0]
"For each paper in the dataset, we have at least one cited or one citing context.",3 Data,[0],[0]
"A summary of the dataset is provided in Table 1.
",3 Data,[0],[0]
"1http://citeseerx.ist.psu.edu/
As expected, we have a higher number of cited contexts than citing contexts.",3 Data,[0],[0]
This is due to the page restrictions often imposed to research articles that can limit the number of papers each article can cite.,3 Data,[0],[0]
"On the other hand, a good research paper can accumulate hundreds of citations, and hence, cited contexts over the years.
",3 Data,[0],[0]
Context lengths.,3 Data,[0],[0]
"In CiteSeerx, citation contexts have about 50 words on each side of a citation mention.",3 Data,[0],[0]
A previous study by Ritchie et al. (2008) shows that a fixed window length of about 100 words around a citation mention is generally effective for information retrieval tasks.,3 Data,[0],[0]
"For this reason, we use the contexts provided by CiteSeerx directly.",3 Data,[0],[0]
"In future, it would be interesting to study more sophisticated approaches to identifying the text that is relevant to a target citation (Abu-Jbara and Radev, 2012; Teufel, 1999) and study the influence of context lengths on our task.
",3 Data,[0],[0]
"For all experiments, our labeled dataset is split in train, validation and test sets.",3 Data,[0],[0]
The validation and test sets have about 200 papers each.,3 Data,[0],[0]
"We sampled another set of papers from the labeled dataset in order to simulate the existence of unlabeled data, with a fixed size of around 2000 papers.",3 Data,[0],[0]
The remaining 786 papers are used as labeled training data.,3 Data,[0],[0]
Each experiment was repeated 10 times with 10 different random seeds and the results were averaged.,3 Data,[0],[0]
Blum and Mitchell (1998) proposed the cotraining algorithm in the context of webpage classification.,4 Co-Training for Topic Classification,[0],[0]
"In co-training, the idea is that two classifiers trained on two different views of the data teach one another by re-training each classifier on the data enriched with predicted examples that the other classifier is most confident about.",4 Co-Training for Topic Classification,[0],[0]
"In Blum and Mitchell (1998), webpages are represented using two different views: (1) using terms from webpages’ content and (2) using terms from the anchor text of hyperlinks pointing to these pages.
",4 Co-Training for Topic Classification,[0],[0]
"Algorithm 1 Co-Training Input: L, U , ‘s’
L1 ← L, L2 ← L while U 6= ∅",4 Co-Training for Topic Classification,[0],[0]
"do
Train classifier C1 on L1 Train classifier C2 on L2 S ← ∅",4 Co-Training for Topic Classification,[0],[0]
"Move ‘s’ examples from U to S U ← U\S S1, S2 ← GetMostConfidentExamples(S,
C1, C2) L1 ← L1 ∪ S1, L2 ← L2 ∪ S2 U ← U ∪",4 Co-Training for Topic Classification,[0],[0]
"[S\(S1 ∪ S2)]
end while Ouput: The combined classifier C of C1 and C2
In this paper, we study the applicability and extension of the co-training algorithm to the task of topic classification of research papers, which are embedded in large citation networks.",4 Co-Training for Topic Classification,[0],[0]
"Here, in addition to the information contained in a paper itself, citing and cited papers capture different aspects (e.g., topicality, domain of study,",4 Co-Training for Topic Classification,[0],[0]
"algorithms used) about the target paper (Teufel et al., 2006), with citation contexts playing an instrumental role.",4 Co-Training for Topic Classification,[0],[0]
"We conjecture that citation contexts, which act as brief summaries about a cited paper, provide important clues in predicting the topicality of a target paper.",4 Co-Training for Topic Classification,[0],[0]
These clues give rise to the design of our co-training based model for topic classification of research papers.,4 Co-Training for Topic Classification,[0],[0]
"In our model, we use the content of a paper as one view and the citation contexts as another view of our data.",4 Co-Training for Topic Classification,[0],[0]
"In particular, for the content of a paper, we use its title and abstract as it is commonly used in the literature (Lu and Getoor, 2003); for the citation contexts, we use both the cited and citing contexts, as described in the previous section.
",4 Co-Training for Topic Classification,[0],[0]
Our co-training procedure is described in Algorithm 1.,4 Co-Training for Topic Classification,[0],[0]
L and U represent the labeled and unlabeled datasets and contain instances from both views.,4 Co-Training for Topic Classification,[0],[0]
The fractions of the training set are obtained from the 786 papers by selecting k% random examples from each class.,4 Co-Training for Topic Classification,[0],[0]
"For a round of co-training, we train classifiers C1 and C2 on the two views.",4 Co-Training for Topic Classification,[0],[0]
"Next, s examples are sampled from the unlabeled data into S, and C1, C2 are used to obtain predictions for these s examples.",4 Co-Training for Topic Classification,[0],[0]
"The GetMostConfidentExamples method is a generic placeholder that stands for a function that deter-
mines what examples from S are chosen to be added into training.",4 Co-Training for Topic Classification,[0],[0]
"Finally, at the end of an iteration, the examples left into S are moved back to U , and the algorithm iterates until there are no more unlabeled examples in U .",4 Co-Training for Topic Classification,[0],[0]
The final classifier C is obtained by combining C1 and C2 using the product of their class probability distributions.,4 Co-Training for Topic Classification,[0],[0]
"The class with the highest posterior probability (of the product of the two distributions) is chosen as the predicted class.
",4 Co-Training for Topic Classification,[0],[0]
"Unlike the original co-training algorithm described by Blum and Mitchell (1998), which tackled a binary classification task (course vs. noncourse page classification), we address a multiclass classification problem, where each example (i.e., research paper) is classified into one of six different classes.",4 Co-Training for Topic Classification,[0],[0]
"Moreover, in Blum and Mitchell (1998), the co-training algorithm moves p highest confidence positive examples and n highest confidence negative examples from S to L, where p : n represents the class distribution in the original labeled training set (i.e., if there are 10 positive examples and 90 negative examples in the labeled set L, then p = 1 positive and n = 9 negative examples are moved to the labeled set at each iteration of co-training).",4 Co-Training for Topic Classification,[0],[0]
"Unlike, this approach that preserves the class distribution of the original labeled training set, we move into L all examples that are classified with a confidence above a certain threshold.",4 Co-Training for Topic Classification,[0],[0]
"First, the proposed method is evaluated on the validation set.",5 Results and Discussion,[0],[0]
We first compare it against various supervised and semi-supervised baselines.,5 Results and Discussion,[0],[0]
"Next, we report the performance of our co-training algorithm under different scenarios, where either cited or citing contexts are used.",5 Results and Discussion,[0],[0]
We also show the most informative words for each classifier.,5 Results and Discussion,[0],[0]
"Finally, with the best parameters obtained on the validation set, we report the precision, recall and F1-score, obtained by each method, on the test set.
",5 Results and Discussion,[0],[0]
"In experiments, the sample size ‘s’ from Algorithm 1 is set to 300, i.e. the number of documents sampled from the unlabeled pool at each iteration; the confidence threshold is set to 0.95, i.e. if both classifiers agree on the class label and have a confidence ≥ 0.95, the instance is labeled and moved into the labeled training set.",5 Results and Discussion,[0],[0]
"These parameters are estimated on the validation set, but the results are not shown due to space limitation.
",5 Results and Discussion,[0],[0]
Evaluation Measures.,5 Results and Discussion,[0],[0]
We report results averaged over ten different runs with random splits.,5 Results and Discussion,[0],[0]
"For each random split, we return the weighted average precision, recall and F1-score.",5 Results and Discussion,[0],[0]
"In all the experiments, we use the Naı̈ve Bayes Multinomial classifier and its Weka implementation2, with term-frequencies as feature values.",5 Results and Discussion,[0],[0]
"We experimented with both TF and TF-IDF scores, using different classifiers (Support Vector Machine, Naı̈ve Bayes Multinomial, and simple Naı̈ve Bayes classifiers), but Naive Bayes Multinomial with TF performed best.",5 Results and Discussion,[0],[0]
How does co-training compare with supervised learning techniques?,5.1 Baseline Comparisons,[0],[0]
"In this experiment, we compare our co-training method with two supervised baselines: (1) when only document content is used and (2) when only citation contexts are used.
",5.1 Baseline Comparisons,[0],[0]
Figure 1 shows the F1-scores achieved using different initial training sizes.,5.1 Baseline Comparisons,[0],[0]
"We can see that overall, the citation contexts are better at predicting the topic of a document compared with the content, outperforming them in 9 out of 10 experimental settings.",5.1 Baseline Comparisons,[0],[0]
"The only exception to this trend is when a small number (5%) of training instances is available, in which case the supervised content view performs better, reaching an F1-score of 0.534.",5.1 Baseline Comparisons,[0],[0]
"Regardless, the co-training method shows significant improvement over both baselines, in all experiments.",5.1 Baseline Comparisons,[0],[0]
"Starting with an F1-score of 0.572, it continues to improve its performance as the training percentage is increasing.",5.1 Baseline Comparisons,[0],[0]
"The maximum F1score, i.e. 0.742, is reached when 30% of the labeled training set is used.",5.1 Baseline Comparisons,[0],[0]
"Note that the difference in performance between co-training and the two supervised baselines is statistically significant for
2http://www.cs.waikato.ac.nz/ml/weka/
a p value of 0.05.
",5.1 Baseline Comparisons,[0],[0]
A fully supervised baseline that uses 100% of the training set achieves an F1-score of 0.720 (using content) and 0.738 (using citation contexts).,5.1 Baseline Comparisons,[0],[0]
"In contrast, co-training requires only 15% of the labeled training set to outperform the fully supervised content baseline and 30% of the training set to outperform the fully supervised citation contexts baseline.",5.1 Baseline Comparisons,[0],[0]
"Consequently, using a co-training approach that includes citation contexts as well as the document content can not only increase the performance, but will also significantly reduce the need of expensive labeled instances.
",5.1 Baseline Comparisons,[0],[0]
"Figure 2 illustrates the confusion matrices of three experiments: (a) supervised content view, i.e. the title and abstract, (b) supervised citation contexts view, and (c) co-training that uses both views.",5.1 Baseline Comparisons,[0],[0]
These experiments use 10% of the training set.,5.1 Baseline Comparisons,[0],[0]
"Each of the matrices are represented by a heat map, i.e. the redder the color, the higher the value assigned to that position.",5.1 Baseline Comparisons,[0],[0]
An accuracy of 1 will be represented by a matrix with red blocks on the main diagonal and white blocks everywhere else.,5.1 Baseline Comparisons,[0],[0]
"This experiment was performed 10 times with 10 different seeds and the results have been averaged.
",5.1 Baseline Comparisons,[0],[0]
"As can be seen, the matrix that uses only titles and abstracts, i.e. left side, is showing the highest percentage of misclassified documents, classifying correctly about 58.8% instances, on average.",5.1 Baseline Comparisons,[0],[0]
"Using only citation contexts in a supervised framework, i.e. center matrix, we reach a higher accuracy of 60.7%.",5.1 Baseline Comparisons,[0],[0]
"The co-training method, which uses the content of the paper and citations as two independent views, significantly increases the average accuracy to 67.3%.",5.1 Baseline Comparisons,[0],[0]
This experiment shows that citation contexts are better than titles and abstracts at predicting the topic of a document.,5.1 Baseline Comparisons,[0],[0]
"Furthermore, our proposed approach, which uses the content of the paper as well as citation contexts, achieves higher results than each view used separately.",5.1 Baseline Comparisons,[0],[0]
"The difference in accuracy is statistically significant across all three experiments for a p value of 0.05.
",5.1 Baseline Comparisons,[0],[0]
"Overall, the Agents class seem to be the easiest to classify, reaching an accuracy value of 91.6% when using co-training.",5.1 Baseline Comparisons,[0],[0]
"On the other hand, the AI class is the hardest to classify.",5.1 Baseline Comparisons,[0],[0]
One reason for this is that the AI class contains the lowest number of instances in the dataset.,5.1 Baseline Comparisons,[0],[0]
"Another can be that the AI class is the most general among all classes and therefore, classifying documents with this la-
Left: using titles and abstracts; Center: using citation contexts;",5.1 Baseline Comparisons,[0],[0]
"Right: using co-training.
bel can be a difficult task even for a human.",5.1 Baseline Comparisons,[0],[0]
"Other common misclassifications occur between classes like HCI and Agents, ML and IR or AI and ML, due to their similarity.
",5.1 Baseline Comparisons,[0],[0]
How does our co-training method compare with other supervised approaches?,5.1 Baseline Comparisons,[0],[0]
"In this experiment, we compare the performance of co-training against two other methods: early and late fusion.",5.1 Baseline Comparisons,[0],[0]
"In early fusion, the feature vectors of the two views are concatenated, creating a single representation of the data.",5.1 Baseline Comparisons,[0],[0]
"In contrast, late fusion trains two separate classifiers and then combines them by taking the label with the highest confidence.
",5.1 Baseline Comparisons,[0],[0]
Figure 3 shows this comparison over different training sizes.,5.1 Baseline Comparisons,[0],[0]
"The results show that the cotraining method is more accurate than all others, performing best in all 10 experimental settings.",5.1 Baseline Comparisons,[0],[0]
"Late fusion has an overall lower performance compared with co-training, but is in a tight correlation with it.",5.1 Baseline Comparisons,[0],[0]
"On the other hand, early fusion achieves the lowest F1-score across the experiments.",5.1 Baseline Comparisons,[0],[0]
"The reported results are statistically significant at p value of 0.05, when the training percentage is between 5 and 35.",5.1 Baseline Comparisons,[0],[0]
"Therefore, we can say that train-
ing two separate classifiers, one of each view, yields higher performance compared with training a single classifier that incorporates both views.",5.1 Baseline Comparisons,[0],[0]
"Moreover, using a co-training approach that incorporates information from unlabeled data into the model, will help the two classifiers increase their confidences and minimize the error rate.
",5.1 Baseline Comparisons,[0],[0]
How does co-training compare with semisupervised methods?,5.1 Baseline Comparisons,[0],[0]
"Here, we present results comparing co-training with two other wellknown semi-supervised techniques: self-training and Naı̈ve Bayes with Expectation Maximization.
Self-Training.",5.1 Baseline Comparisons,[0],[0]
"First, we show results of the comparison of co-training with two variations of selftraining: (1) self-training using only document content, and (2) self-training using only citation contexts.",5.1 Baseline Comparisons,[0],[0]
Figure 4 shows the results of this experiment.,5.1 Baseline Comparisons,[0],[0]
"Self-training is similar to co-training, except that it uses only one view of the data (Zhu, 2005).",5.1 Baseline Comparisons,[0],[0]
"Self-training parameters, e.g., sample size ‘s’ or number of iterations, are estimated as in cotraining.
",5.1 Baseline Comparisons,[0],[0]
"Although the document content version of selftraining outperforms co-training when using 5%
of the training instances, we can see that overall, there is a significant difference in terms of F1score values in the favor of co-training.",5.1 Baseline Comparisons,[0],[0]
"In 9 out of 10 experiments, our co-training approach is superior to both self-training methods.",5.1 Baseline Comparisons,[0],[0]
"The results are statistically significant across all experimental setups for a p value of 0.05.
",5.1 Baseline Comparisons,[0],[0]
Expectation Maximization.,5.1 Baseline Comparisons,[0],[0]
"Figure 5 shows the F1-score values obtained after running NBM with EM with the same training, unlabeled and test sets.",5.1 Baseline Comparisons,[0],[0]
"The EM algorithm uses the same classifier, i.e. NBM, and the weight for each unlabeled instance is set to 1, as this setting achieved the highest results.",5.1 Baseline Comparisons,[0],[0]
"Two different experiments were performed using EM: (1) using only document content, and (2) using only citation contexts.",5.1 Baseline Comparisons,[0],[0]
"As can be seen in the figure, overall, the co-training approach significantly outperforms both variations of EM.",5.1 Baseline Comparisons,[0],[0]
"However, the co-training method falls short when using 5% of the training instances, where EM Content and EM Citations methods are achieving higher F1-score values.",5.1 Baseline Comparisons,[0],[0]
"Nonetheless, both EM variations tend to achieve an F1-score value below or equal to 0.710, whereas co-training reaches performance values of 0.74 or higher.",5.1 Baseline Comparisons,[0],[0]
"Again, the comparison results between co-training and both variations of EM are statistically significant for training sizes between 10% and 50%, for a p value of 0.05.",5.1 Baseline Comparisons,[0],[0]
Which of the two types of citation contexts (cited or citing) help the task of topic classification more and how does co-training perform in the absence of either one?,5.2 Using Different Citation Context Types,[0],[0]
The answer to this question is important as there are cases in which citation contexts are not readily available.,5.2 Using Different Citation Context Types,[0],[0]
"One frequently encountered example includes newly published research papers that have no cited contexts.
",5.2 Using Different Citation Context Types,[0],[0]
"In this case, it is important to know how our method performs when we only have one type of citation contexts.",5.2 Using Different Citation Context Types,[0],[0]
"Figure 6 shows the difference in performance when using: (1) only cited contexts, (2) only citing contexts, and (3) both context types.",5.2 Using Different Citation Context Types,[0],[0]
"Note that the content view remains the same across all three experiments.
",5.2 Using Different Citation Context Types,[0],[0]
The plot is showing that citing contexts are bringing in a significantly higher margin of knowledge compared with cited contexts.,5.2 Using Different Citation Context Types,[0],[0]
"This is consistent over different training set sizes, as shown in the figure, with a more prominent impact when a small training size is used, i.e. 5-30%.",5.2 Using Different Citation Context Types,[0],[0]
"The fact that the citing contexts achieve higher F1-score than cited contexts is consistent with the intuition that when citing a paper y, an author generally summarizes the main ideas from y using important words from a target paper x, making the citing contexts to have higher overlap with words from x.",5.2 Using Different Citation Context Types,[0],[0]
"In turn, a paper z that cites x may use paraphrasing to summarize ideas from x with words more similar to those from the content of z.
When the two types of contexts are used, cotraining achieves higher results compared with cases when only one context type is used.",5.2 Using Different Citation Context Types,[0],[0]
This experiment shows that our method can be applied for both old and new research articles.,5.2 Using Different Citation Context Types,[0],[0]
Citing contexts will be available in the text of the target paper and are independent of the existence of the cited contexts.,5.2 Using Different Citation Context Types,[0],[0]
What are the most informative words from each view: document content and citation contexts?,5.3 Informative Features,[0],[0]
Figure 7 shows the words from each view that are most useful for our topic classification task.,5.3 Informative Features,[0],[0]
"The larger the word, the more informative is for our
task.",5.3 Informative Features,[0],[0]
"To determine the informativeness of a word, we used its Information Gain score.",5.3 Informative Features,[0],[0]
"For these experiments, we used training sets consisting of 30% of the instances, setting in which we achieved the best results on the validation and test sets using our proposed co-training approach.
",5.3 Informative Features,[0],[0]
"As can be seen, the two word clouds have a high word overlap.",5.3 Informative Features,[0],[0]
"Words such as agent, database or query are almost equally important in the two views, dominating both clouds.",5.3 Informative Features,[0],[0]
"However, differences can be observed.",5.3 Informative Features,[0],[0]
"For example, words like learning, multi-agent or interface are more important in the content view.",5.3 Informative Features,[0],[0]
"On the other hand, words such as document or text achieve a higher information gain score for the citation contexts view.",5.3 Informative Features,[0],[0]
"Table 2 summarizes the results obtained by all the baselines used so far, in comparison with our proposed co-training method.",5.4 Co-Training vs. All Other Approaches,[0],[0]
"For this experiment, we show the training percentage used, the precision, recall and F1-score for each method, in the setting in which it returned the best results.",5.4 Co-Training vs. All Other Approaches,[0],[0]
"All mea-
sures were averaged after 10 runs with 10 different seeds.
",5.4 Co-Training vs. All Other Approaches,[0],[0]
"The results in Table 2 show that the proposed co-training method outperforms all compared models, reaching the highest F1-score of 0.742, while using the smallest amount of labeled documents, i.e. 30%.",5.4 Co-Training vs. All Other Approaches,[0],[0]
"Using only the citing contexts, the performance is similar to that of co-training when both context types are used.",5.4 Co-Training vs. All Other Approaches,[0],[0]
"However, using only the cited contexts, the performance decreases compared to that of the full model that uses both context types.",5.4 Co-Training vs. All Other Approaches,[0],[0]
"We see that the citing contexts perform better, reaching an F1-score value of 0.740 compared against 0.714 when only cited contexts are used.",5.4 Co-Training vs. All Other Approaches,[0],[0]
"Moreover, the method that uses only the citing contexts is using 10% less labeled data.
",5.4 Co-Training vs. All Other Approaches,[0],[0]
Self-training and EM show decreased performance compared with co-training.,5.4 Co-Training vs. All Other Approaches,[0],[0]
"Late Fusion outperforms Early Fusion, i.e., 0.738 vs. 0.714, both obtaining lower results than co-training, while using significantly more labeled data.
",5.4 Co-Training vs. All Other Approaches,[0],[0]
"The last two lines of the table show the results when all documents (except those in the validation and test), are used for training, in a supervised framework.",5.4 Co-Training vs. All Other Approaches,[0],[0]
"As can be seen, a supervised method that uses only citations will achieve a higher performance, compared against a method that uses titles and abstracts.",5.4 Co-Training vs. All Other Approaches,[0],[0]
"Nonetheless, co-training obtains higher results than both fully supervised approaches, while using only 30% of the labeled data.",5.4 Co-Training vs. All Other Approaches,[0],[0]
"In this paper, we studied the problem of using citation contexts in order to predict more accurately the topic of a research article.",6 Conclusion and Future Work,[0],[0]
"We showed that a co-training technique, which uses the paper content and its citation contexts as two conditionally independent and sufficient views of the data, can effectively incorporate cheap, unlabeled data to improve the classification performance and to reduce the need of labeled examples to only a fraction.",6 Conclusion and Future Work,[0],[0]
"The results of the experiments showed that the proposed approach performs better than other semi-supervised and supervised methods.
",6 Conclusion and Future Work,[0],[0]
This study also shows that citation contexts are rich sources of information that can be successfully used in various IR and NLP tasks.,6 Conclusion and Future Work,[0],[0]
We showed that document content and citation contexts unified under the same algorithm can dramatically decrease the annotation costs as well.,6 Conclusion and Future Work,[0],[0]
"In the future, we plan to extend co-training to include active learning for more robust classification.",6 Conclusion and Future Work,[0],[0]
"Moreover, it would be interesting to extend the co-training approach to multi-views that could potentially handle more than two feature spaces, e.g., it could include topics by Latent Dirichlet Allocation (Blei et al., 2003) as an additional view.",6 Conclusion and Future Work,[0],[0]
We are thankful to Dr. Lise Getoor for making the Citeseerx labeled subset publicly available.,Acknowledgments,[0],[0]
"We are also grateful to Dr. C. Lee Giles for the CiteSeerx data, which helped extract the citation contexts of the research papers in the collection.",Acknowledgments,[0],[0]
We very much thank our anonymous reviewers for their constructive feedback.,Acknowledgments,[0],[0]
This research is supported in part by the NSF award #1423337 to Cornelia Caragea.,Acknowledgments,[0],[0]
"Any opinions, findings, and conclusions expressed here are those of the authors and do not necessarily reflect the views of NSF.",Acknowledgments,[0],[0]
"With the exponential growth of scholarly data during the past few years, effective methods for topic classification are greatly needed.",abstractText,[0],[0]
Current approaches usually require large amounts of expensive labeled data in order to make accurate predictions.,abstractText,[0],[0]
"In this paper, we posit that, in addition to a research article’s textual content, its citation network also contains valuable information.",abstractText,[0],[0]
We describe a co-training approach that uses the text and citation information of a research article as two different views to predict the topic of an article.,abstractText,[0],[0]
"We show that this method improves significantly over the individual classifiers, while also bringing a substantial reduction in the amount of labeled data required for training accurate classifiers.",abstractText,[0],[0]
Co-Training for Topic Classification of Scholarly Data,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 731–742 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
731
Semantic parsing aims at mapping natural language utterances into structured meaning representations. In this work, we propose a structure-aware neural architecture which decomposes the semantic parsing process into two stages. Given an input utterance, we first generate a rough sketch of its meaning, where low-level information (such as variable names and arguments) is glossed over. Then, we fill in missing details by taking into account the natural language input and the sketch itself. Experimental results on four datasets characteristic of different domains and meaning representations show that our approach consistently improves performance, achieving competitive results despite the use of relatively simple decoders.",text,[0],[0]
"Semantic parsing maps natural language utterances onto machine interpretable meaning representations (e.g., executable queries or logical forms).",1 Introduction,[0],[0]
"The successful application of recurrent neural networks to a variety of NLP tasks (Bahdanau et al., 2015; Vinyals et al., 2015) has provided strong impetus to treat semantic parsing as a sequence-to-sequence problem (Jia and Liang, 2016; Dong and Lapata, 2016; Ling et al., 2016).",1 Introduction,[0],[0]
The fact that meaning representations are typically structured objects has prompted efforts to develop neural architectures which explicitly account for their structure.,1 Introduction,[0],[0]
"Examples include tree decoders (Dong and Lapata, 2016; Alvarez-Melis and Jaakkola, 2017), decoders constrained by a grammar model (Xiao et al., 2016; Yin and Neubig, 2017; Krishnamurthy et al., 2017), or modular
decoders which use syntax to dynamically compose various submodels (Rabinovich et al., 2017).
",1 Introduction,[0],[0]
"In this work, we propose to decompose the decoding process into two stages.",1 Introduction,[0],[0]
"The first decoder focuses on predicting a rough sketch of the meaning representation, which omits low-level details, such as arguments and variable names.",1 Introduction,[0],[0]
Example sketches for various meaning representations are shown in Table 1.,1 Introduction,[0],[0]
"Then, a second decoder fills in missing details by conditioning on the natural language input and the sketch itself.",1 Introduction,[0],[0]
"Specifically, the sketch constrains the generation process and is encoded into vectors to guide decoding.
",1 Introduction,[0],[0]
We argue that there are at least three advantages to the proposed approach.,1 Introduction,[0],[0]
"Firstly, the decomposition disentangles high-level from low-level semantic information, which enables the decoders to model meaning at different levels of granularity.",1 Introduction,[0],[0]
"As shown in Table 1, sketches are more compact and as a result easier to generate compared to decoding the entire meaning structure in one go.",1 Introduction,[0],[0]
"Secondly, the model can explicitly share knowledge of coarse structures for the examples that have the same sketch (i.e., basic meaning), even though their actual meaning representations are different (e.g., due to different details).",1 Introduction,[0],[0]
"Thirdly, after generating the sketch, the decoder knows what the basic meaning of the utterance looks like, and the model can use it as global context to improve the prediction of the final details.
",1 Introduction,[0],[0]
Our framework is flexible and not restricted to specific tasks or any particular model.,1 Introduction,[0],[0]
"We conduct experiments on four datasets representative of various semantic parsing tasks ranging from logical form parsing, to code generation, and SQL query generation.",1 Introduction,[0],[0]
We adapt our architecture to these tasks and present several ways to obtain sketches from their respective meaning representations.,1 Introduction,[0],[0]
"Experimental results show that our framework achieves competitive performance compared
with previous systems, despite employing relatively simple sequence decoders.",1 Introduction,[0],[0]
"Various models have been proposed over the years to learn semantic parsers from natural language expressions paired with their meaning representations (Tang and Mooney, 2000; Ge and Mooney, 2005; Zettlemoyer and Collins, 2007; Wong and Mooney, 2007; Lu et al., 2008; Kwiatkowski et al., 2011; Andreas et al., 2013; Zhao and Huang, 2015).",2 Related Work,[0],[0]
"These systems typically learn lexicalized mapping rules and scoring models to construct a meaning representation for a given input.
",2 Related Work,[0],[0]
"More recently, neural sequence-to-sequence models have been applied to semantic parsing with promising results (Dong and Lapata, 2016; Jia and Liang, 2016; Ling et al., 2016), eschewing the need for extensive feature engineering.",2 Related Work,[0],[0]
"Several ideas have been explored to enhance the performance of these models such as data augmentation (Kočiský et al., 2016; Jia and Liang, 2016), transfer learning (Fan et al., 2017), sharing parameters for multiple languages or meaning representations (Susanto and Lu, 2017; Herzig and Berant, 2017), and utilizing user feedback signals (Iyer et al., 2017).",2 Related Work,[0],[0]
There are also efforts to develop structured decoders that make use of the syntax of meaning representations.,2 Related Work,[0],[0]
Dong and Lapata (2016) and Alvarez-Melis and Jaakkola (2017) develop models which generate tree structures in a topdown fashion.,2 Related Work,[0],[0]
Xiao et al. (2016) and Krishnamurthy et al. (2017) employ the grammar to constrain the decoding process.,2 Related Work,[0],[0]
"Cheng et al. (2017)
use a transition system to generate variable-free queries.",2 Related Work,[0],[0]
"Yin and Neubig (2017) design a grammar model for the generation of abstract syntax trees (Aho et al., 2007) in depth-first, left-to-right order.",2 Related Work,[0],[0]
"Rabinovich et al. (2017) propose a modular decoder whose submodels are dynamically composed according to the generated tree structure.
",2 Related Work,[0],[0]
Our own work also aims to model the structure of meaning representations more faithfully.,2 Related Work,[0],[0]
"The flexibility of our approach enables us to easily apply sketches to different types of meaning representations, e.g., trees or other structured objects.",2 Related Work,[0],[0]
"Coarse-to-fine methods have been popular in the NLP literature, and are perhaps best known for syntactic parsing (Charniak et al., 2006; Petrov, 2011).",2 Related Work,[0],[0]
Artzi and Zettlemoyer (2013) and Zhang et al. (2017) use coarse lexical entries or macro grammars to reduce the search space of semantic parsers.,2 Related Work,[0],[0]
"Compared with coarse-to-fine inference for lexical induction, sketches in our case are abstractions of the final meaning representation.
",2 Related Work,[0],[0]
"The idea of using sketches as intermediate representations has also been explored in the field of program synthesis (Solar-Lezama, 2008; Zhang and Sun, 2013; Feng et al., 2017).",2 Related Work,[0],[0]
"Yaghmazadeh et al. (2017) use SEMPRE (Berant et al., 2013) to map a sentence into SQL sketches which are completed using program synthesis techniques and iteratively repaired if they are faulty.",2 Related Work,[0],[0]
"Our goal is to learn semantic parsers from instances of natural language expressions paired with their structured meaning representations.
",3 Problem Formulation,[0],[0]
"Let x = x1 · · ·x|x| denote a natural language expression, and y = y1 · · · y|y| its meaning representation.",3 Problem Formulation,[0],[0]
"We wish to estimate p (y|x), the conditional probability of meaning representation y given input x.",3 Problem Formulation,[0],[0]
"We decompose p (y|x) into a twostage generation process:
p (y|x)",3 Problem Formulation,[0],[0]
"= p (y|x, a) p (a|x) (1) where a = a1 · · ·",3 Problem Formulation,[0],[0]
a|a| is an abstract sketch representing the meaning of y. We defer detailed description of how sketches are extracted to Section 4.,3 Problem Formulation,[0],[0]
"Suffice it to say that the extraction amounts to stripping off arguments and variable names in logical forms, schema specific information in SQL queries, and substituting tokens with types in source code (see Table 1).
",3 Problem Formulation,[0],[0]
"As shown in Figure 1, we first predict sketch a for input x, and then fill in missing details to generate the final meaning representation y by conditioning on both x and a.",3 Problem Formulation,[0],[0]
The sketch is encoded into vectors which in turn guide and constrain the decoding of y.,3 Problem Formulation,[0],[0]
"We view the input expression x, the meaning representation y, and its sketch a as sequences.",3 Problem Formulation,[0],[0]
"The generation probabilities are factorized as:
p (a|x) = |a|∏ t=1",3 Problem Formulation,[0],[0]
"p (at|a<t, x) (2)
p (y|x, a) = |y|∏ t=1 p (yt|y<t, x, a) (3)
where a<t = a1 · · · at−1, and y<t = y1 · · · yt−1.",3 Problem Formulation,[0],[0]
"In the following, we will explain how p (a|x) and p (y|x, a) are estimated.",3 Problem Formulation,[0],[0]
An encoder is used to encode the natural language input x into vector representations.,3.1 Sketch Generation,[0],[0]
"Then, a decoder learns to compute p (a|x) and generate the sketch a conditioned on the encoding vectors.
",3.1 Sketch Generation,[0],[0]
"Input Encoder Every input word is mapped to a vector via xt = Wxo (xt), where Wx ∈ R n×|Vx| is an embedding matrix, |Vx| is the vocabulary size, and o (xt) a one-hot vector.",3.1 Sketch Generation,[0],[0]
"We use a bi-directional recurrent neural network with long short-term memory units (LSTM, Hochreiter and Schmidhuber 1997) as the input encoder.",3.1 Sketch Generation,[0],[0]
"The encoder recursively computes the hidden vectors at the t-th time step via:
−→e t = fLSTM (−→e t−1,xt) , t = 1, · · · , |x| (4)
←−e",3.1 Sketch Generation,[0],[0]
"t = fLSTM (←−e t+1,xt) , t = |x|, · · · , 1 (5)
et = [ −→e t,←−e t] (6)
where [·, ·] denotes vector concatenation, et ∈ Rn, and fLSTM is the LSTM function.
",3.1 Sketch Generation,[0],[0]
Coarse,3.1 Sketch Generation,[0],[0]
"Meaning Decoder The decoder’s hidden vector at the t-th time step is computed by dt = fLSTM (dt−1,at−1), where at−1 ∈ Rn is the embedding of the previously predicted token.",3.1 Sketch Generation,[0],[0]
The hidden states of the first time step in the decoder are initialized by the concatenated encoding vectors d0 =,3.1 Sketch Generation,[0],[0]
"[−→e |x|,←−e 1].",3.1 Sketch Generation,[0],[0]
"Additionally, we use an attention mechanism (Luong et al., 2015) to learn soft alignments.",3.1 Sketch Generation,[0],[0]
"We compute the attention score for the current time step t of the decoder, with the k-th hidden state in the encoder as:
st,k = exp{dt · ek}/Zt (7)
where Zt = ∑|x|
j=1 exp{dt · ej} is a normalization term.",3.1 Sketch Generation,[0],[0]
"Then we compute p (at|a<t, x) via:
edt = |x|∑ k=1 st,kek (8)
dattt = tanh",3.1 Sketch Generation,[0],[0]
"( W1dt +W2e d t ) (9)
p (at|a<t, x) = softmaxat ( Wod att t + bo )",3.1 Sketch Generation,[0],[0]
"(10)
where W1,W2 ∈ Rn×n, Wo ∈ R|Va|×n, and bo ∈ R|Va| are parameters.",3.1 Sketch Generation,[0],[0]
Generation terminates once an end-of-sequence token “</s>” is emitted.,3.1 Sketch Generation,[0],[0]
Meaning representations are predicted by conditioning on the input x and the generated sketch a.,3.2 Meaning Representation Generation,[0],[0]
"The model uses the encoder-decoder architecture to compute p (y|x, a), and decorates the sketch a with details to generate the final output.
",3.2 Meaning Representation Generation,[0],[0]
"Sketch Encoder As shown in Figure 1, a bidirectional LSTM encoder maps the sketch sequence a into vectors {vk}|a|k=1 as in Equation (6), where vk denotes the vector of the k-th time step.
",3.2 Meaning Representation Generation,[0],[0]
Fine,3.2 Meaning Representation Generation,[0],[0]
"Meaning Decoder The final decoder is based on recurrent neural networks with an attention mechanism, and shares the input encoder described in Section 3.1.",3.2 Meaning Representation Generation,[0],[0]
"The decoder’s hidden states {ht}|y|t=1 are computed via:
it = { vk yt−1 is determined by ak yt−1 otherwise (11)
",3.2 Meaning Representation Generation,[0],[0]
"ht = fLSTM (ht−1, it)
where h0 =",3.2 Meaning Representation Generation,[0],[0]
"[−→e |x|,←−e 1], and yt−1 is the embedding of the previously predicted token.",3.2 Meaning Representation Generation,[0],[0]
"Apart from using the embeddings of previous tokens, the decoder is also fed with {vk}|a|k=1.",3.2 Meaning Representation Generation,[0],[0]
"If yt−1 is determined by ak in the sketch (i.e., there is a one-toone alignment between yt−1 and ak), we use the corresponding token’s vector vk as input to the next time step.
",3.2 Meaning Representation Generation,[0],[0]
The sketch constrains the decoding output.,3.2 Meaning Representation Generation,[0],[0]
"If the output token yt is already in the sketch, we force yt to conform to the sketch.",3.2 Meaning Representation Generation,[0],[0]
"In some cases, sketch tokens will indicate what information is missing (e.g., in Figure 1, token “flight@1” indicates that an argument is missing for the predicate “flight”).",3.2 Meaning Representation Generation,[0],[0]
"In other cases, sketch tokens will not reveal the number of missing tokens (e.g., “STRING” in DJANGO) but the decoder’s
output will indicate whether missing details have been generated (e.g., if the decoder emits a closing quote token for “STRING”).",3.2 Meaning Representation Generation,[0],[0]
"Moreover, type information in sketches can be used to constrain generation.",3.2 Meaning Representation Generation,[0],[0]
"In Table 1, sketch token “NUMBER” specifies that a numeric token should be emitted.
",3.2 Meaning Representation Generation,[0],[0]
"For the missing details, we use the hidden vector ht to compute p (yt|y<t, x, a), analogously to Equations (7)–(10).",3.2 Meaning Representation Generation,[0],[0]
"The model’s training objective is to maximize the log likelihood of the generated meaning representations given natural language expressions:
max ∑
(x,a,y)∈D log p (y|x, a) + log p (a|x)
where D represents training pairs.",3.3 Training and Inference,[0],[0]
"At test time, the prediction for input x is obtained via â = argmaxa′ p (a ′|x) and ŷ = argmaxy′ p (y ′|x, â), where a′ and y′ represent coarse- and fine-grained meaning candidates.",3.3 Training and Inference,[0],[0]
"Because probabilities p (a|x) and p (y|x, a) are factorized as shown in Equations (2)–(3), we can obtain best results approximately by using greedy search to generate tokens one by one, rather than iterating over all candidates.",3.3 Training and Inference,[0],[0]
"In order to show that our framework applies across domains and meaning representations, we developed models for three tasks, namely parsing natural language to logical form, to Python source code, and to SQL query.",4 Semantic Parsing Tasks,[0],[0]
"For each of these tasks we describe the datasets we used, how sketches were extracted, and specify model details over and above the architecture presented in Section 3.",4 Semantic Parsing Tasks,[0],[0]
"For our first task we used two benchmark datasets, namely GEO (880 language queries to a database of U.S. geography) and ATIS (5, 410 queries to a flight booking system).",4.1 Natural Language to Logical Form,[0],[0]
Examples are shown in Table 1 (see the first and second block).,4.1 Natural Language to Logical Form,[0],[0]
"We used standard splits for both datasets: 600 training and 280 test instances for GEO (Zettlemoyer and Collins, 2005); 4, 480 training, 480 development, and 450 test examples for ATIS.",4.1 Natural Language to Logical Form,[0],[0]
"Meaning representations in these datasets are based on λ-calculus (Kwiatkowski et al., 2011).",4.1 Natural Language to Logical Form,[0],[0]
"We use brackets to linearize the hierarchical structure.
",4.1 Natural Language to Logical Form,[0],[0]
Algorithm 1 Sketch for GEO and ATIS Input: t: Tree-structure λ-calculus expression t.pred:,4.1 Natural Language to Logical Form,[0],[0]
"Predicate name, or operator name Output:",4.1 Natural Language to Logical Form,[0],[0]
"a: Meaning sketch
(count $0 (< (fare $0) 50:do))→(count#1 (< fare@1 ?))",4.1 Natural Language to Logical Form,[0],[0]
"function SKETCH(t)
if t is leaf then No nonterminal in arguments return “%s@%d” % (t.pred,len(t.args)) if t.pred is λ operator, or quantifier then e.g., count Omit variable information defined by t.pred t.pred←",4.1 Natural Language to Logical Form,[0],[0]
"“%s#%d” % (t.pred,len(variable)) for c ← argument in t.args do if c is nonterminal then
c ← SKETCH(c)",4.1 Natural Language to Logical Form,[0],[0]
"else
c ← “?”",4.1 Natural Language to Logical Form,[0],[0]
"Placeholder for terminal return t
The first element between a pair of brackets is an operator or predicate name, and any remaining elements are its arguments.
",4.1 Natural Language to Logical Form,[0],[0]
Algorithm 1 shows the pseudocode used to extract sketches from λ-calculus-based meaning representations.,4.1 Natural Language to Logical Form,[0],[0]
"We strip off arguments and variable names in logical forms, while keeping predicates, operators, and composition information.",4.1 Natural Language to Logical Form,[0],[0]
We use the symbol “@” to denote the number of missing arguments in a predicate.,4.1 Natural Language to Logical Form,[0],[0]
"For example, we extract “from@2” from the expression “(from $0 dallas:ci)” which indicates that the predicate “from” has two arguments.",4.1 Natural Language to Logical Form,[0],[0]
We use “?” as a placeholder in cases where only partial argument information can be omitted.,4.1 Natural Language to Logical Form,[0],[0]
"We also omit variable information defined by the lambda operator and quantifiers (e.g., exists, count, and argmax).",4.1 Natural Language to Logical Form,[0],[0]
We use the symbol “#” to denote the number of omitted tokens.,4.1 Natural Language to Logical Form,[0],[0]
"For the example in Figure 1, “lambda $0 e” is reduced to “lambda#2”.
",4.1 Natural Language to Logical Form,[0],[0]
"The meaning representations of these two datasets are highly compositional, which motivates us to utilize the hierarchical structure of λ-calculus.",4.1 Natural Language to Logical Form,[0],[0]
A similar idea is also explored in the tree decoders proposed in Dong and Lapata (2016) and Yin and Neubig (2017) where parent hidden states are fed to the input gate of the LSTM units.,4.1 Natural Language to Logical Form,[0],[0]
"On the contrary, parent hidden states serve as input to the softmax classifiers of both fine and coarse meaning decoders.
",4.1 Natural Language to Logical Form,[0],[0]
Parent Feeding Taking the meaning sketch “(and flight@1 from@2)”,4.1 Natural Language to Logical Form,[0],[0]
"as an example, the parent of “from@2” is “(and”.",4.1 Natural Language to Logical Form,[0],[0]
Let pt denote the parent of the t-th time step in the decoder.,4.1 Natural Language to Logical Form,[0],[0]
"Compared with Equation (10), we use the vector dattt and the hidden state of its parent dpt to compute the prob-
ability p (at|a<t, x) via:
p (at|a<t, x) = softmaxat ( Wo[d att t ,dpt ] + bo ) where [·, ·] denotes vector concatenation.",4.1 Natural Language to Logical Form,[0],[0]
The parent feeding is used for both decoding stages.,4.1 Natural Language to Logical Form,[0],[0]
"Our second semantic parsing task used DJANGO (Oda et al., 2015), a dataset built upon the Python code of the Django library.",4.2 Natural Language to Source Code,[0],[0]
"The dataset contains lines of code paired with natural language expressions (see the third block in Table 1) and exhibits a variety of use cases, such as iteration, exception handling, and string manipulation.",4.2 Natural Language to Source Code,[0],[0]
"The original split has 16, 000 training, 1, 000 development, and 1, 805 test instances.
",4.2 Natural Language to Source Code,[0],[0]
We used the built-in lexical scanner of Python1 to tokenize the code and obtain token types.,4.2 Natural Language to Source Code,[0],[0]
"Sketches were extracted by substituting the original tokens with their token types, except delimiters (e.g., “[”, and “:”), operators (e.g., “+”, and “*”), and built-in keywords (e.g., “True”, and “while”).",4.2 Natural Language to Source Code,[0],[0]
"For instance, the expression “if s[:4].lower() == ’http’:” becomes “if NAME",4.2 Natural Language to Source Code,[0],[0]
[ : NUMBER ] .,4.2 Natural Language to Source Code,[0],[0]
"NAME ( ) == STRING :”, with details about names, values, and strings being omitted.
DJANGO is a diverse dataset, spanning various real-world use cases and as a result models are often faced with out-of-vocabulary (OOV) tokens (e.g., variable names, and numbers) that are unseen during training.",4.2 Natural Language to Source Code,[0],[0]
"We handle OOV tokens with a copying mechanism (Gu et al., 2016; Gulcehre et al., 2016; Jia and Liang, 2016), which allows the fine meaning decoder (Section 3.2) to directly copy tokens from the natural language input.
",4.2 Natural Language to Source Code,[0],[0]
"Copying Mechanism Recall that we use a softmax classifier to predict the probability distribution p (yt|y<t, x, a) over the pre-defined vocabulary.",4.2 Natural Language to Source Code,[0],[0]
We also learn a copying gate gt ∈,4.2 Natural Language to Source Code,[0],[0]
"[0, 1] to decide whether yt should be copied from the input or generated from the vocabulary.",4.2 Natural Language to Source Code,[0],[0]
"We compute the modified output distribution via:
gt = sigmoid(wg · ht + bg) p̃ (yt|y<t, x, a) =",4.2 Natural Language to Source Code,[0],[0]
"(1− gt)p (yt|y<t, x, a)
+",4.2 Natural Language to Source Code,[0],[0]
[yt /∈Vy,4.2 Natural Language to Source Code,[0],[0]
"]gt ∑
k:xk=yt
st,k
1https://docs.python.org/3/library/ tokenize
where",4.2 Natural Language to Source Code,[0],[0]
wg ∈,4.2 Natural Language to Source Code,[0],[0]
"Rn and bg ∈ R are parameters, and the indicator function",4.2 Natural Language to Source Code,[0],[0]
"[yt /∈Vy ] is 1 only if yt is not in the target vocabulary Vy; the attention score st,k (see Equation (7)) measures how likely it is to copy yt from the input word xk.",4.2 Natural Language to Source Code,[0],[0]
"The WIKISQL (Zhong et al., 2017) dataset contains 80, 654 examples of questions and SQL queries distributed across 24, 241 tables from Wikipedia.",4.3 Natural Language to SQL,[0],[0]
"The goal is to generate the correct SQL query for a natural language question and table schema (i.e., table column names), without using the content values of tables (see the last block in Table 1 for an example).",4.3 Natural Language to SQL,[0],[0]
"The dataset is partitioned into a training set (70%), a development set (10%), and a test set (20%).",4.3 Natural Language to SQL,[0],[0]
"Each table is present in one split to ensure generalization to unseen tables.
",4.3 Natural Language to SQL,[0],[0]
"WIKISQL queries follow the format “SELECT agg op agg col WHERE (cond col cond op cond) AND ...”, which is a subset of the SQL syntax.",4.3 Natural Language to SQL,[0],[0]
"SELECT identifies the column that is to be included in the results after applying the aggregation operator agg op2 to column agg col. WHERE can have zero or multiple conditions, which means that column cond col must satisfy the constraints expressed by the operator cond op3 and the condition value cond.",4.3 Natural Language to SQL,[0],[0]
Sketches for SQL queries are simply the (sorted) sequences of condition operators cond op in WHERE clauses.,4.3 Natural Language to SQL,[0],[0]
"For example, in Table 1, sketch “WHERE > AND =” has two condition operators, namely “>” and “=”.
",4.3 Natural Language to SQL,[0],[0]
"The generation of SQL queries differs from our previous semantic parsing tasks, in that the table schema serves as input in addition to natural language.",4.3 Natural Language to SQL,[0],[0]
"We therefore modify our input encoder in order to render it table-aware, so to speak.",4.3 Natural Language to SQL,[0],[0]
"Furthermore, due to the formulaic nature of the SQL query, we only use our decoder to generate the WHERE clause (with the help of sketches).",4.3 Natural Language to SQL,[0],[0]
"The SELECT clause has a fixed number of slots (i.e., aggregation operator agg op and column agg col), which we straightforwardly predict with softmax classifiers (conditioned on the input).",4.3 Natural Language to SQL,[0],[0]
"We briefly explain how these components are modeled below.
",4.3 Natural Language to SQL,[0],[0]
Table-Aware Input Encoder,4.3 Natural Language to SQL,[0],[0]
"Given a table schema with M columns, we employ the special token “‖” to concatenate its header names
2agg op ∈ {empty,COUNT,MIN,MAX,SUM,AVG}.",4.3 Natural Language to SQL,[0],[0]
"3cond op ∈ {=, <,>}.
as “‖c1,1 · · · c1,|c1|‖· · · ‖cM,1 · · · cM,|cM |‖”, where the k-th column (“ck,1 · · · ck,|ck|”) has |ck| words.",4.3 Natural Language to SQL,[0],[0]
"As shown in Figure 2, we use bi-directional LSTMs to encode the whole sequence.",4.3 Natural Language to SQL,[0],[0]
"Next, for column ck, the LSTM hidden states at positions ck,1 and ck,|ck| are concatenated.",4.3 Natural Language to SQL,[0],[0]
"Finally, the concatenated vectors are used as the encoding vectors {ck}Mk=1 for table columns.
",4.3 Natural Language to SQL,[0],[0]
"As mentioned earlier, the meaning representations of questions are dependent on the tables.",4.3 Natural Language to SQL,[0],[0]
"As shown in Figure 2, we encode the input question x into {et}|x|t=1 using LSTM units.",4.3 Natural Language to SQL,[0],[0]
"At each time step t, we use an attention mechanism towards table column vectors {ck}Mk=1 to obtain the most relevant columns for et.",4.3 Natural Language to SQL,[0],[0]
"The attention score from et to ck is computed via ut,k ∝ exp{α(et) · α(ck)}, where α(·) is a one-layer neural network, and∑M
k=1 ut,k = 1.",4.3 Natural Language to SQL,[0],[0]
Then we compute the context vector cet = ∑M,4.3 Natural Language to SQL,[0],[0]
"k=1 ut,kck to summarize the relevant columns for et.",4.3 Natural Language to SQL,[0],[0]
"We feed the concatenated vectors {[et, cet ]}|x|t=1 into a bi-directional LSTM encoder, and use the new encoding vectors {ẽt}|x|t=1 to replace {et}|x|t=1 in other model components.",4.3 Natural Language to SQL,[0],[0]
"We define the vector representation of input x as:
ẽ = [ −→̃ e |x|, ←−̃ e 1] (12)
analogously to Equations (4)–(6).
",4.3 Natural Language to SQL,[0],[0]
SELECT Clause We feed the question vector ẽ into a softmax classifier to obtain the aggregation operator agg op.,4.3 Natural Language to SQL,[0],[0]
"If agg col is the k-th table column, its probability is computed via:
σ(x) = w3 · tanh (W4x+ b4)",4.3 Natural Language to SQL,[0],[0]
(13) p (agg col = k|x) ∝,4.3 Natural Language to SQL,[0],[0]
"exp{σ([ẽ, ck])} (14)
where ∑M
j=1 p",4.3 Natural Language to SQL,[0],[0]
(,4.3 Natural Language to SQL,[0],[0]
agg col = j|x),4.3 Natural Language to SQL,[0],[0]
"= 1, σ(·) is a scoring network, and W4 ∈ R2n×m,w3,b4 ∈ R m are parameters.
",4.3 Natural Language to SQL,[0],[0]
WHERE Clause We first generate sketches whose details are subsequently decorated by the fine meaning decoder described in Section 3.2.,4.3 Natural Language to SQL,[0],[0]
"As the number of sketches in the training set is small (35 in total), we model sketch generation as a classification problem.",4.3 Natural Language to SQL,[0],[0]
"We treat each sketch a as a category, and use a softmax classifier to compute p (a|x):
p (a|x) = softmaxa",4.3 Natural Language to SQL,[0],[0]
"(Waẽ+ ba) where Wa ∈ R|Va|×n,ba ∈ R|Va| are parameters, and ẽ is the table-aware input representation defined in Equation (12).
",4.3 Natural Language to SQL,[0],[0]
"Once the sketch is predicted, we know the condition operators and number of conditions in the WHERE clause which follows the format “WHERE (cond op cond col cond) AND ...”.",4.3 Natural Language to SQL,[0],[0]
"As shown in Figure 3, our generation task now amounts to populating the sketch with condition columns cond col and their values cond.
",4.3 Natural Language to SQL,[0],[0]
"Let {ht}|y|t=1 denote the LSTM hidden states of the fine meaning decoder, and {hattt }|y|t=1 the vectors obtained by the attention mechanism as in Equation (9).",4.3 Natural Language to SQL,[0],[0]
The condition column cond colyt is selected from the table’s headers.,4.3 Natural Language to SQL,[0],[0]
"For the k-th column in the table, we compute p (cond colyt = k|y<t, x, a) as in Equation (14), but use different parameters and compute the score via σ([hattt , ck]).",4.3 Natural Language to SQL,[0],[0]
"If the k-th table column is selected, we use ck for the input of the next LSTM unit in the decoder.
",4.3 Natural Language to SQL,[0],[0]
Condition values are typically mentioned in the input questions.,4.3 Natural Language to SQL,[0],[0]
"These values are often phrases with multiple tokens (e.g., Mikhail Snitko in Table 1).",4.3 Natural Language to SQL,[0],[0]
We therefore propose to select a text span from input x for each condition value condyt rather than copying tokens one by one.,4.3 Natural Language to SQL,[0],[0]
"Let xl · · ·xr denote the text span from which condyt
is copied.",4.3 Natural Language to SQL,[0],[0]
"We factorize its probability as:
p (condyt = xl · · ·xr|y<t, x, a) = p",4.3 Natural Language to SQL,[0],[0]
"( l Lyt |y<t, x, a ) p ( r Ryt |y<t, x, a, l Lyt ) p",4.3 Natural Language to SQL,[0],[0]
"( l Lyt |y<t, x, a
) ∝",4.3 Natural Language to SQL,[0],[0]
"exp{σ([hattt , ẽl])}",4.3 Natural Language to SQL,[0],[0]
"p ( r Ryt |y<t, x, a, l Lyt
) ∝",4.3 Natural Language to SQL,[0],[0]
"exp{σ([hattt , ẽl, ẽr])} where l Lyt/ r R yt represents the first/last copying index of condyt is l/r, the probabilities are normalized to 1, and σ(·) is the scoring network defined in Equation (13).",4.3 Natural Language to SQL,[0],[0]
Notice that we use different parameters for the scoring networks σ(·).,4.3 Natural Language to SQL,[0],[0]
"The copied span is represented by the concatenated vector [ẽl, ẽr], which is fed into a one-layer neural network and then used as the input to the next LSTM unit in the decoder.",4.3 Natural Language to SQL,[0],[0]
We present results on the three semantic parsing tasks discussed in Section 4.,5 Experiments,[0],[0]
Our implementation and pretrained models are available at https:// github.com/donglixp/coarse2fine.,5 Experiments,[0],[0]
"Preprocessing For GEO and ATIS, we used the preprocessed versions provided by Dong and Lapata (2016), where natural language expressions are lowercased and stemmed with NLTK (Bird et al., 2009), and entity mentions are replaced by numbered markers.",5.1 Experimental Setup,[0],[0]
We combined predicates and left brackets that indicate hierarchical structures to make meaning representations compact.,5.1 Experimental Setup,[0],[0]
"We employed the preprocessed DJANGO data provided by Yin and Neubig (2017), where input expressions are tokenized by NLTK, and quoted strings in the input are replaced with place holders.",5.1 Experimental Setup,[0],[0]
"WIKISQL was preprocessed by the script provided by Zhong et al. (2017), where inputs were lowercased and tokenized by Stanford CoreNLP",5.1 Experimental Setup,[0],[0]
"(Manning et al., 2014).
",5.1 Experimental Setup,[0],[0]
"Configuration Model hyperparameters were cross-validated on the training set for GEO, and were validated on the development split for the other datasets.",5.1 Experimental Setup,[0],[0]
"Dimensions of hidden vectors and word embeddings were selected from {250, 300} and {150, 200, 250, 300}, respectively.",5.1 Experimental Setup,[0],[0]
"The dropout rate was selected from {0.3, 0.5}.",5.1 Experimental Setup,[0],[0]
"Label smoothing (Szegedy et al., 2016) was employed for GEO and ATIS.",5.1 Experimental Setup,[0],[0]
The smoothing parameter was set to 0.1.,5.1 Experimental Setup,[0],[0]
"For WIKISQL, the hidden size of σ(·)
and α(·) in Equation (13) was set to 64.",5.1 Experimental Setup,[0],[0]
"Word embeddings were initialized by GloVe (Pennington et al., 2014), and were shared by table encoder and input encoder in Section 4.3.",5.1 Experimental Setup,[0],[0]
We appended 10-dimensional part-of-speech tag vectors to embeddings of the question words in WIKISQL.,5.1 Experimental Setup,[0],[0]
The part-of-speech tags were obtained by the spaCy toolkit.,5.1 Experimental Setup,[0],[0]
"We used the RMSProp optimizer (Tieleman and Hinton, 2012) to train the models.",5.1 Experimental Setup,[0],[0]
"The learning rate was selected from {0.002, 0.005}.",5.1 Experimental Setup,[0],[0]
"The batch size was 200 for WIKISQL, and was 64 for other datasets.",5.1 Experimental Setup,[0],[0]
"Early stopping was used to determine the number of epochs.
",5.1 Experimental Setup,[0],[0]
"Evaluation We use accuracy as the evaluation metric, i.e., the percentage of the examples that are correctly parsed to their gold standard meaning representations.",5.1 Experimental Setup,[0],[0]
"For WIKISQL, we also execute generated SQL queries on their corresponding tables, and report the execution accuracy which is defined as the proportion of correct answers.",5.1 Experimental Setup,[0],[0]
We compare our model (COARSE2FINE) against several previously published systems as well as various baselines.,5.2 Results and Analysis,[0],[0]
"Specifically, we report results with a model which decodes meaning representations in one stage (ONESTAGE) without leveraging sketches.",5.2 Results and Analysis,[0],[0]
"We also report the results of several ablation models, i.e., without a sketch encoder and without a table-aware input encoder.
",5.2 Results and Analysis,[0],[0]
Table 2 presents our results on GEO and ATIS.,5.2 Results and Analysis,[0],[0]
"Overall, we observe that COARSE2FINE outperforms ONESTAGE, which suggests that disentangling high-level from low-level information dur-
ing decoding is beneficial.",5.2 Results and Analysis,[0],[0]
The results also show that removing the sketch encoder harms performance since the decoder loses access to additional contextual information.,5.2 Results and Analysis,[0],[0]
"Compared with previous neural models that utilize syntax or grammatical information (SEQ2TREE, ASN; the second block in Table 2), our method performs competitively despite the use of relatively simple decoders.",5.2 Results and Analysis,[0],[0]
"As an upper bound, we report model accuracy when gold meaning sketches are given to the fine meaning decoder (+oracle sketch).",5.2 Results and Analysis,[0],[0]
"As can be seen, predicting the sketch correctly boosts performance.",5.2 Results and Analysis,[0],[0]
"The oracle results also indicate the accuracy of the fine meaning decoder.
",5.2 Results and Analysis,[0],[0]
Table 3 reports results on DJANGO where we observe similar tendencies.,5.2 Results and Analysis,[0],[0]
COARSE2FINE outperforms ONESTAGE by a wide margin.,5.2 Results and Analysis,[0],[0]
It is also superior to the best reported result in the literature (SNM+COPY; see the second block in the table).,5.2 Results and Analysis,[0],[0]
"Again we observe that the sketch encoder is beneficial and that there is an 8.9 point difference in accuracy between COARSE2FINE and the oracle.
Results on WIKISQL are shown in Table 4.",5.2 Results and Analysis,[0],[0]
Our model is superior to ONESTAGE as well as to previous best performing systems.,5.2 Results and Analysis,[0],[0]
"COARSE2FINE’s accuracies on aggregation agg op and agg col are 90.2% and 92.0%, respectively, which is comparable to SQLNET (Xu et al., 2017).",5.2 Results and Analysis,[0],[0]
So the most gain is obtained by the improved decoder of the WHERE clause.,5.2 Results and Analysis,[0],[0]
"We also find that a tableaware input encoder is critical for doing well on this task, since the same question might lead to different SQL queries depending on the table schemas.",5.2 Results and Analysis,[0],[0]
Consider the question “how many presidents are graduated from A”.,5.2 Results and Analysis,[0],[0]
"The SQL query over table “‖President‖College‖” is “SELECT
COUNT(President) WHERE (College = A)”, but the query over table “‖College‖Number of Presidents‖” would be “SELECT Number of Presidents",5.2 Results and Analysis,[0],[0]
"WHERE (College = A)”.
",5.2 Results and Analysis,[0],[0]
We also examine the predicted sketches themselves in Table 5.,5.2 Results and Analysis,[0],[0]
We compare sketches generated by COARSE2FINE against ONESTAGE.,5.2 Results and Analysis,[0],[0]
The latter model generates meaning representations without an intermediate sketch generation stage.,5.2 Results and Analysis,[0],[0]
"Nevertheless, we can extract sketches from the output of ONESTAGE following the procedures described in Section 4.",5.2 Results and Analysis,[0],[0]
Sketches produced by COARSE2FINE are more accurate across the board.,5.2 Results and Analysis,[0],[0]
This is not surprising because our model is trained explicitly to generate compact meaning sketches.,5.2 Results and Analysis,[0],[0]
"Taken together (Tables 2–4), our results show that better sketches bring accuracy gains on GEO, ATIS, and DJANGO.",5.2 Results and Analysis,[0],[0]
"On WIKISQL, the sketches predicted by COARSE2FINE are marginally better compared with ONESTAGE.",5.2 Results and Analysis,[0],[0]
Performance improvements on this task are mainly due to the fine meaning decoder.,5.2 Results and Analysis,[0],[0]
"We conjecture that by decomposing decoding into two stages, COARSE2FINE can better match table columns and extract condition values without interference from the prediction of condition operators.",5.2 Results and Analysis,[0],[0]
"Moreover, the sketch provides a canonical order of condition operators, which is beneficial for the decoding process (Vinyals et al., 2016; Xu et al., 2017).",5.2 Results and Analysis,[0],[0]
In this paper we presented a coarse-to-fine decoding framework for neural semantic parsing.,6 Conclusions,[0],[0]
We first generate meaning sketches which abstract away from low-level information such as arguments and variable names and then predict missing details in order to obtain full meaning representations.,6 Conclusions,[0],[0]
The proposed framework can be easily adapted to different domains and meaning representations.,6 Conclusions,[0],[0]
Experimental results show that coarseto-fine decoding improves performance across tasks.,6 Conclusions,[0],[0]
"In the future, we would like to apply the framework in a weakly supervised setting, i.e., to learn semantic parsers from question-answer pairs and to explore alternative ways of defining meaning sketches.
",6 Conclusions,[0],[0]
Acknowledgments We would like to thank Pengcheng Yin for sharing with us the preprocessed version of the DJANGO dataset.,6 Conclusions,[0],[0]
"We gratefully acknowledge the financial support of the European Research Council (award number 681760; Dong, Lapata) and the AdeptMind Scholar Fellowship program (Dong).",6 Conclusions,[0],[0]
Semantic parsing aims at mapping natural language utterances into structured meaning representations.,abstractText,[0],[0]
"In this work, we propose a structure-aware neural architecture which decomposes the semantic parsing process into two stages.",abstractText,[0],[0]
"Given an input utterance, we first generate a rough sketch of its meaning, where low-level information (such as variable names and arguments) is glossed over.",abstractText,[0],[0]
"Then, we fill in missing details by taking into account the natural language input and the sketch itself.",abstractText,[0],[0]
"Experimental results on four datasets characteristic of different domains and meaning representations show that our approach consistently improves performance, achieving competitive results despite the use of relatively simple decoders.",abstractText,[0],[0]
Coarse-to-Fine Decoding for Neural Semantic Parsing,title,[0],[0]
"Proceedings of the SIGDIAL 2018 Conference, pages 400–409, Melbourne, Australia, 12-14 July 2018. c©2018 Association for Computational Linguistics
400
The bulk of current research in dialogue systems is focused on fairly simple task models, primarily state-based. Progress on developing dialogue systems for more complex tasks has been limited by the lack generic toolkits to build from. In this paper we report on our development from the ground up of a new dialogue model based on collaborative problem solving. We implemented the model in a dialogue system shell (Cogent) that allows developers to plug in problem-solving agents to create dialogue systems in new domains. The Cogent shell has now been used by several independent teams of researchers to develop dialogue systems in different domains, with varied lexicons and interaction style, each with their own problem-solving backend. We believe this to be the first practical demonstration of the feasibility of a CPSbased dialogue system shell.",text,[0],[0]
Many areas of natural language processing have benefited from the existence of tools and frameworks that can be customized to develop specific applications.,1 Introduction,[0],[0]
"In the area of dialogue systems, there are few such tools and frameworks and they mostly remain focused on simple tasks that can be encoded in a state-based dialogue model (see, e.g., Williams et al., 2016 and the Dialogue State Tracking Challenge 1 ).",1 Introduction,[0],[0]
"In this category some of the more expressive approaches to dialogue modeling are based on the information state (Cooper, 1997); notable toolkits include TrindiKit (Larsson and Traum, 2000) and its open-source successor trindikit.py (Ljunglöf, 2009), and OpenDial (Lison and Kennington, 2016).
",1 Introduction,[0],[0]
"1 https://www.microsoft.com/en-us/research/event/dialogstate-tracking-challenge/
Unfortunately, there is a dearth of tools for developing mixed-initiative dialogue systems that involve complex back-end reasoning systems.",1 Introduction,[0],[0]
"Early theoretical work of SharedPlans (Grosz and Kraus, 1996; Lochbaum et al., 1990) and planbased dialogue systems (e.g., Allen and Perrault, 1980; Litman and Allen, 1987) laid good foundations.",1 Introduction,[0],[0]
"The Collaborative Problem Solving (CPS) model (Allen et al., 2002) seemed to promise a solution but that model has never been implemented in a truly domain-independent way.",1 Introduction,[0],[0]
"Ravenclaw (Bohus and Rudnicky, 2009) is a plan-based dialog management framework that has been used to develop a number of dialogue systems.",1 Introduction,[0],[0]
"Its dialogue engine is task-independent and includes a number of generic conversational skills; however, its behavior is driven by task-specific dialogue trees, which have to be implemented anew for every application.
",1 Introduction,[0],[0]
"Dialogue management involves understanding the intention of the user’s contributions to the dialogue, and deciding what to do or say next.",1 Introduction,[0],[0]
"It is the core component of a dialogue system, and typically requires significant development effort for every new application domain.",1 Introduction,[0],[0]
We believe that dialogue managers based on models of the collaborative problem solving process offer the highest potential for flexibility and portability.,1 Introduction,[0],[0]
"Flexibility refers to the ability to cover the full range of natural dialogues users may want to engage in, and portability refers to how easy it is to customize or modify a system to work in new domains (Blaylock, 2007).
",1 Introduction,[0],[0]
"In this paper we describe a new, domainindependent dialogue manager based on the CPS model, and its implementation in an open-source dialog system shell (Cogent 2 ).",1 Introduction,[0],[0]
"To demonstrate its flexibility, we also describe briefly a few dialogue systems for different domains.
",1 Introduction,[0],[0]
2 https://github.com/wdebeaum/cogent,1 Introduction,[0],[0]
"When agents are engaged in solving problems together, they need to communicate to agree on what goals to pursue and what steps to take to achieve those goals, negotiate roles, resources, etc.",2 Collaborative Problem Solving,[0],[0]
"To underscore its collaborative aspect, this type of joint activity has been called Collaborative Problem Solving (CPS).",2 Collaborative Problem Solving,[0],[0]
"Modeling the type of dialogue agents engage in during CPS must, therefore, take into account the nature of the joint activity itself.",2 Collaborative Problem Solving,[0],[0]
"In the early 2000s, Allen and colleagues described a preliminary plan-based CPS model of dialogue based on an analysis of an agent’s collaborative behavior at various levels:
 An individual problem-solving level, where each agent manages its own problem-
solving state, plans and executes individual actions, etc.;
 A collaborative problem-solving level, which models and manages the joint or col-
laborative problem-solving state (shared goals, resources, situations);
 An interaction level, where individual agents negotiate changes in the joint prob-
lem-solving state; and, finally,
 A communication level, where speech acts realize the interaction level acts.
",2 Collaborative Problem Solving,[0],[0]
"This model was refined in a series of publications, and several prototype systems were developed for illustration (Allen et al., 2002; Blaylock and Allen, 2005; Allen et al., 2007; Ferguson and Allen, 2007), all based on the TRIPS system (Allen et al., 2000).
",2 Collaborative Problem Solving,[0],[0]
"One of the main benefits of this model is that linguistic interpretation and high-level intention recognition could be performed independently of the individual problem-solving level, whose contribution to interpretation would be to specialize the higher-level intentions into concrete problemsolving actions and verify that such actions make sense.",2 Collaborative Problem Solving,[0],[0]
"The corollary is that in this model the back-
end problem solvers would be insulated from the need to worry about linguistic issues.
",2 Collaborative Problem Solving,[0],[0]
"On this basis, it should be possible to create a generic dialogue system shell with only domainindependent components.",2 Collaborative Problem Solving,[0],[0]
"Other developers, not necessarily specialists in NLU or dialogue systems, could use this shell to build, relatively quickly, intelligent dialogue systems for collaborative tasks in various domains.",2 Collaborative Problem Solving,[0],[0]
The various prototypes of TRIPS CPS-based systems referenced above did not fulfill this promise.,2 Collaborative Problem Solving,[0],[0]
"In each, the CPS level was integrated fairly tightly with the individual problem-solving level for the application domain, and they were all developed by the same team.",2 Collaborative Problem Solving,[0],[0]
"Thus, even though each such prototype implemented (a version of) the CPS model and used the same platform for NLU, the ultimate goal of creating a domain-independent dialogue shell that others could customize to develop independently dialogue systems has so far remained elusive.",2 Collaborative Problem Solving,[0],[0]
"Similarly, the CPS-based dialogue manager in SAMMIE (Becker et al., 2006) also aimed for domain independence but never quite realized it (Blaylock, 2007).
",2 Collaborative Problem Solving,[0],[0]
In the rest of the paper we will report on our attempt to develop a generic dialogue shell based on the CPS model.,2 Collaborative Problem Solving,[0],[0]
We start with a description of the general architecture of a dialogue system based on the CPS model.,2 Collaborative Problem Solving,[0],[0]
"Then, we will describe our dialogue manager, with a focus on its interface with the domain-specific problem solving agent.",2 Collaborative Problem Solving,[0],[0]
"Finally, we give some details on six prototype dialogue systems developed using our dialogue shell, five of which were developed by independent teams of researchers.",2 Collaborative Problem Solving,[0],[0]
"A collaborative conversational agent must understand a user’s utterances, that is, obtain a representation of the meaning of the utterance, recognize its intention, and then reason with this intention to decide what to do and/or say next.",3 CPS-based Dialogue Systems,[0],[0]
"Finally, the system must convert its own intentions into language and communicate them to the user.
",3 CPS-based Dialogue Systems,[0],[0]
Figure 1 shows a conceptual diagram of the dialogue system we envision.,3 CPS-based Dialogue Systems,[0],[0]
"This follows the common separation of a conversational agent’s functionality into interpretation, behavior and generation, but where the separation lines are is critical for realizing the idea of isolating domainindependent from domain-specific processing.",3 CPS-based Dialogue Systems,[0],[0]
"We take the output of NL Understanding (assumed here to have broad lexical, syntactic and semantic coverage) to be a domain-independent semantic representation of the user’s utterance (a communicative act), expressed in terms of a domainindependent ontology.",3 CPS-based Dialogue Systems,[0],[0]
"Intention recognition is performed by the CPS agent, which takes into account the discourse context and converts communicative acts into abstract communicative intentions.",3 CPS-based Dialogue Systems,[0],[0]
"These communicative intentions need to be further evaluated with respect to the actual problem-solving state, so they are not fully interpreted until they reach the problem solving agent.",3 CPS-based Dialogue Systems,[0],[0]
"This agent is responsible for the domain-specific behavior – hereafter we will refer to it as the Behavioral Agent (BA) – and for operationalizing the communicative intentions into actions (which may involve planning, acting on the world, updating its knowledge of the situation, etc.).",3 CPS-based Dialogue Systems,[0],[0]
"An autonomous BA should be able to plan and act on its own, but neither the BA nor the user can singlehandedly decide on the status of collaborative goals without a commitment from the other party.",3 CPS-based Dialogue Systems,[0],[0]
"The BA expresses its attitude towards shared goals by sending to the CPS agent its own communicative intentions, which the CPS agent will use to update the collaborative state and generate communicative acts for NL generation (such as accepting or rejecting a goal, or proposing a new one).
",3 CPS-based Dialogue Systems,[0],[0]
"Customization: Figure 1 includes, on the left side, a number of resources needed by our ideal dialogue system: (1) a broad lexicon for NL understanding; (2) a general-purpose (upper-level) ontology; and, optionally, (3) a domain ontology.
",3 CPS-based Dialogue Systems,[0],[0]
"Even a state-of-the-art broad coverage parser, with an extensive domain-independent high-level ontology and lexicon, will not contain all the word senses and concepts needed for every application domain.",3 CPS-based Dialogue Systems,[0],[0]
"Additionally, the general ontology concepts need to be mapped onto the domain ontology used by the back-end problem solvers.
",3 CPS-based Dialogue Systems,[0],[0]
"Lastly, NL generation from semantic representations of communicative acts is a difficult problem, with no general solutions.",3 CPS-based Dialogue Systems,[0],[0]
"Many taskoriented dialogue systems employ template-based techniques, which can lead to satisfactory, if somewhat repetitive text realizations.",3 CPS-based Dialogue Systems,[0],[0]
"Such templates are tailored for the application domain.
",3 CPS-based Dialogue Systems,[0],[0]
It may appear that customizing a generic dialogue shell to specific applications involves a considerable amount of work.,3 CPS-based Dialogue Systems,[0],[0]
"Nevertheless, we believe these customization tasks are easier to accomplish and require less linguistic expertise than building a dialogue manager for every application, let alone building domain-specific natural language understanding components.",3 CPS-based Dialogue Systems,[0],[0]
Let us now turn to the details of our new instantiation of the CPS model.,4 Our CPS Model,[0],[0]
"Unlike prior work on CPSbased dialogue management, we focus on the interface between the CPS agent (CPSA) and the BA.",4 Our CPS Model,[0],[0]
"This allows us to directly address the issue of domain-independence that posed difficulties in other approaches (e.g., Blaylock, 2007).
",4 Our CPS Model,[0],[0]
The CPSA computes communicative intentions based on the communicative acts resulting from the NLU component.,4 Our CPS Model,[0],[0]
"These communicative intentions are realized in our model as CPS Acts, represented as a pair <ACI, CONTEXT>, where ACI represents the abstract communicative intention and CONTEXT represents the semantic content of the act in a knowledge representation language.",4 Our CPS Model,[0],[0]
"Where there is no ambiguity we will omit CONTEXT and denote CPS acts by their ACI only.
",4 Our CPS Model,[0],[0]
"In the following subsections we will describe the set of CPS acts we have devised so far, grouped by the manner in which they affect the collaborative state.",4 Our CPS Model,[0],[0]
"The CPS Model defines an objective as an intention that is driving the agent’s current behavior (Allen et al., 2002).",4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
"An objective can be proposed by either agent, provided they are ready to commit to it.",4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
We represent the intention to commit to an objective via the CPS act ADOPT.,4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
"For example, if the user starts a conversation with “Let’s build a tower”, this results in the following CPS act:
(ADOPT :id O1 :what C1 :as (GOAL))
",4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
"Here, O1 represents a unique, persistent identifier for the shared objective proposed via this act (all objectives are assigned an identifier).",4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
"C1 is an identifier indexed into the CONTEXT of this CPS act (i.e., it refers to an event of building a tower).",4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
"Additionally, the act also indicates the relation between this objective and any pre-existing objectives.",4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
"In this example, the relation was identified as GOAL, indicating that this is a top-level objective (we will discuss later other types of relations between objectives available in our model).
",4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
"Once an objective has been jointly committed to, either agent can propose to drop their commitment to it, via a CPS act called ABANDON.",4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
"Or, they might propose to shift focus from the active objective (the one currently driving the agents’ behavior), by an act called DEFER, which will result in the objective becoming inactive.",4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
A proposal to bring an inactive objective back into an active state an agent results in a SELECT act.,4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
"Finally, an agent can propose that an objective should be considered completed, via a RELEASE act.",4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
"All these four acts only take as an argument the objective’s unique identifier, for example: (ABANDON :id O1).
",4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
"Note that all of these four acts can be proposed, indicating the agent’s intentional stance towards their commitment to that objective.",4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
The user performs a proposal via a speech act.,4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
The same intention may be expressed by different surface speech acts.,4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
"Going back to our example, the objective of building a tower together can be expressed via a direct proposal (""Let's build a tower""); a question (“Can we build a tower?”); or an indirect speech act (“I think we should build a tower”).",4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
"The CPSA recognizes the user intent in all these variants, using the surface speech act and other linguistic cues present in the communicative act it receives from NLU).",4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
"Thus, they all result in the same ADOPT act as above.
",4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
"If, on the other hand, the BA wants to propose that an objective be jointly pursued, say that it wants to start working on O1 by a subgoal O2 of placing a block on the table, it can do so via a PROPOSE act, whose content is the intention to commit to that objective:
(PROPOSE :content (ADOPT :id O2 :what C2 :as (SUBGOAL :of O1)))
where C2 is indexed into the CONTEXT of the act for a representation of the event of placing a block on the table.",4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
"Upon receiving this act, the CPSA will update the collaborative state to reflect the BA’s intention to commit to O2, and formulate a communicative act for NLG to realize the proposal in a system utterance.
",4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
"For a proposal to result in a shared objective, the two agents must agree to commit to it.",4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
The CPSA is responsible for gathering the agreements of both the user and the BA.,4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
"When the CPSA recognizes that the user is proposing an objective, it will first send an EVALUATE act to the BA, whose content is the proposed objective, e.g.,:
(EVALUATE :content (ADOPT :id O1 :what C1 :as (GOAL))
",4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
"This act creates an obligation on the part of the BA to evaluate whether it is able to commit to it in the current situation, and, if so, respond by signaling agreement (ACCEPTABLE), rejection (REJECTED), or, when it cannot even interpret what the objective is, a failure (FAILURE).",4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
"For example, the BA’s agreement, that is, its intention to commit to the objective proposed by the user, would be communicated via:
(ACCEPTABLE :content (ADOPT :id O1 :what C1 :as (GOAL))
",4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
"Since the user has already signaled their intention to commit to the objective by proposing it, on receiving from the BA that the objective is ACCEPTABLE, the CPSA knows that there is mutual agreement, decides that that the objective is now adopted, and sends back to the BA the following CPS act:
(COMMIT :content (ADOPT :id O1 :what C1 :as (GOAL))
to signal that now there is a joint commitment to O1.",4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
"This creates an obligation on the part of the BA to pursue O1 in whatever manner it deems appropriate.
",4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
"When we have a system-proposed objective, such
as O2 above, if the user expresses their acceptance (“Yes”, “Sure”, “I can handle that”, etc.), the CPSA will recognize this as completing the agreement, and then it would adopt the objective and send the COMMIT act to the BA.",4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
"Having described in some detail how objectives are created, and how the CPSA decides that there is joint commitment to them, let us turn briefly to some of the details that we brushed over.
",4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
"Relations between objectives: We mentioned above two relations between the objective currently under consideration and the prior objectives (either previously adopted ones, or ones that have been discussed but are still being negotiated), namely GOAL and SUBGOAL.",4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
Currently the CPSA can infer two more.,4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
"One is MODIFICATION, used when one of the agents is expressing an intention of changing in some manner a prior objective (for example, if one of the agents had suggested placing a blue block on the table, the other agent might suggest placing a red block instead).",4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
"The second one we call ELABORATION, and is used by the CPSA to signal that it has insufficient knowledge to decide whether the objective under discussion is really a subgoal or a modification of another one, or, perhaps a new top-level goal.",4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
"It is possible, however, that the BA may be able to use its more detailed knowledge of the situation to make that determination.",4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
"Thus, upon receiving an objective marked as an elaboration of another one, if the BA deems it acceptable, it has the obligation to clarify the relation as well.
Rejections and failures: If a user proposes an objective, presumably they have an expectation that the objective is achievable.",4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
"If the BA rejects it, the user will likely not be satisfied with a simple “No”.",4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
"Similarly, if the BA fails to understand the objective (or if it encounters any other type of failure, e.g., while trying to perform some action), the system should be able to explain what happened.",4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
"Thus, the REJECTED and FAILURE CPS acts have features for optionally specifying a reason and a possible way of repairing the situation.",4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
"The reason for rejection/failure is one of a relatively small set of predefined ones (e.g., UNKNOWN-OBJECT, FAILED-ACTION), and it is expected that the NLG component will make use of it to generate more helpful utterances.",4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
"As for how to repair the situation, this can be an alternative objective, that the BA is ready to commit to, which could be either a modification of the reject-
ed one, or, perhaps, an objective which, if realized, would make the rejected objective acceptable.",4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
"For example, if the user wanted to build an all-blue 5-block tower, but the BA has only 4 blue blocks, it would reject the goal (INSUFFICIENTRESOURCES), but it could suggest as an alternative that a 4-block blue tower would be an achievable alternative.",4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
"This might be realized as “Sorry, I don’t have enough blocks for that, but we can build a 4-block blue tower.”.",4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
"If the user accepts (“OK”), the CPSA will immediately commit to the suggested objective.",4.1 CPS Acts Related to Problem-Solving Objectives,[0],[0]
"Collaborative problem solving requires not only joint commitments to certain objectives, but also a set of shared beliefs about the situation.",4.2 CPS Acts Related to Situations,[0],[0]
These shared beliefs occasionally need to be updated.,4.2 CPS Acts Related to Situations,[0],[0]
One agent may inform the other of a fact that they believe the other should know.,4.2 CPS Acts Related to Situations,[0],[0]
This may come about unprompted or as a result of being asked.,4.2 CPS Acts Related to Situations,[0],[0]
"The CPS Model offers little guidance on how such acts fit in, even though they are very common in conversation.",4.2 CPS Acts Related to Situations,[0],[0]
"The examples given seem to suggest an interpretation of questions and simple assertions based on plan recognition (Allen, 1979), which is a tall order, particularly for a domainindependent dialogue manager.",4.2 CPS Acts Related to Situations,[0],[0]
"When agent A informs agent B of a fact P, this indicates A’s immediate intention that B knows P. Similarly, if A asks B whether P is true (an ask-if speech act) or what object satisfies P (an ask-wh speech act), A’s immediate intention is that B informs A of those particular facts (Allen and Perrault, 1980).",4.2 CPS Acts Related to Situations,[0],[0]
"Getting at the intentions behind these immediate intentions requires fairly sophisticated, often domainspecific reasoning (in our implementation the CPSA can do that to some extent via abstract task models, but, due to space limitations, we will not discuss it here).",4.2 CPS Acts Related to Situations,[0],[0]
"Therefore, we created a small set of CPS acts for representing the intentions to impart and request knowledge about situations.
",4.2 CPS Acts Related to Situations,[0],[0]
"In our model, an assertion of a fact results in
the following CPS act:
(ASSERTION :id A3 :what C3 :as (CONTRIBUTES-TO :goal O1))
where C3 is an identifier pointing to a representation of the content of the assertion in the CONTEXT of the CPS act.",4.2 CPS Acts Related to Situations,[0],[0]
"The relation between an ASSERTION act and an existing objective (or NIL if no such objective exists) is an underspeci-
fied one, of contributing somehow to it.",4.2 CPS Acts Related to Situations,[0],[0]
"The BA needs to decide, if it accepts A3, how this addition will change its understanding of the situation and affect O1 or any other (adopted) objective.",4.2 CPS Acts Related to Situations,[0],[0]
"For ask-if questions the CPSA will produce the following act:
(ASK-IF :id A4 :query Q4 :as (QUERY-IN-CONTEXT :goal O1))
Here Q4 is an identifier pointing to a representation (in the CONTEXT of the CPS act) of a statement to be evaluated for its truth value.
",4.2 CPS Acts Related to Situations,[0],[0]
"For ask-wh questions the CPSA produces acts
in the following format:
(ASK-WH :id A5 :what W5 :query Q5 :choices S5 :as (QUERY-IN-CONTEXT :goal O1))
",4.2 CPS Acts Related to Situations,[0],[0]
"This expresses the intention of knowing the value of an entity (W5), possibly restricted to a set of choices (S5), that makes a proposition (Q5) true.",4.2 CPS Acts Related to Situations,[0],[0]
"As before, all these identifiers should be given appropriate descriptions in the CONTEXT.",4.2 CPS Acts Related to Situations,[0],[0]
"This act can thus represent the intention expressed by a question such as “What color should we use for the first block, blue or red?”.
",4.2 CPS Acts Related to Situations,[0],[0]
"Finally, an answer to a question takes the fol-
lowing form:
(ANSWER :to A5 :what W5 :query Q5 :value V6 :justification J6)
",4.2 CPS Acts Related to Situations,[0],[0]
"This indicates the value V6 (e.g., blue) for the entity W5 makes the statement Q5 true (we should use blue for the first block), in response to the CPS act with the identifier A5.",4.2 CPS Acts Related to Situations,[0],[0]
"If the answer is in response to an ASK-IF act, V6 can only be TRUE or FALSE.",4.2 CPS Acts Related to Situations,[0],[0]
"Optionally, a justification (J6) may be added to show how the answer came about.
",4.2 CPS Acts Related to Situations,[0],[0]
"It is important to note that we treat these intentions as special types of objectives, that can become adopted, active, etc., just like other objectives.",4.2 CPS Acts Related to Situations,[0],[0]
"For example, if one of these CPS acts is initiated by the user, the act must be evaluated by the BA.",4.2 CPS Acts Related to Situations,[0],[0]
"If it deems the act ACCEPTABLE, the CPSA will commit to working on it (updating the system’s beliefs, or answering the question).",4.2 CPS Acts Related to Situations,[0],[0]
"If originating from the BA, the act must be proposed first, and realized through a communicative act.
",4.2 CPS Acts Related to Situations,[0],[0]
Side effects: We noted above that updating the system’s beliefs about the situation may affect the status of existing objectives.,4.2 CPS Acts Related to Situations,[0],[0]
"Insofar as the BA is
capable of foreseeing these effects, it ought to inform the CPSA so the collaborative state can be updated.",4.2 CPS Acts Related to Situations,[0],[0]
Any such changes would result in an obligation to inform the user.,4.2 CPS Acts Related to Situations,[0],[0]
"In our model we use an additional feature for the ACCEPTABLE act (see previous section), for describing the effect.",4.2 CPS Acts Related to Situations,[0],[0]
Its value is an objective to be proposed.,4.2 CPS Acts Related to Situations,[0],[0]
"For example, if, in the context of the shared objective of building a tower, the system asks “Who is going to move the blocks?”, and the user says “I will”, this answer has the side effect of modifying the existing objective (in this case specializing it to include the identity of the builder).",4.2 CPS Acts Related to Situations,[0],[0]
"The system’s acceptance of the answer will necessarily imply the acceptance of the modification as well, and the CPSA will update the collaborative state accordingly.",4.2 CPS Acts Related to Situations,[0],[0]
Another important role of the CPSA in managing the dialogue is to negotiate initiative.,4.3 CPS Acts Related to Initiative and Execution,[0],[0]
"To facilitate an orderly conversation, it restricts both the timing and the magnitude of the BA’s ability to affect the collaborative state.",4.3 CPS Acts Related to Initiative and Execution,[0],[0]
"It does so via a special CPS act, called WHAT-NEXT, which takes a single argument: the identifier of an adopted shared objective (usually the one that is active).",4.3 CPS Acts Related to Initiative and Execution,[0],[0]
"This act can be sent to the BA whenever there are no pending updates to the collaborative state, and no outstanding communicative acts to process or to wait on.",4.3 CPS Acts Related to Initiative and Execution,[0],[0]
"In effect, by sending this act, the CPSA transfers the task initiative to the BA, which gives it the chance to, ultimately, influence discourse initiative as well.",4.3 CPS Acts Related to Initiative and Execution,[0],[0]
"The BA has the obligation to respond with a single update to the collaborative state, presumably the one with the highest priority.",4.3 CPS Acts Related to Initiative and Execution,[0],[0]
"This restriction is critical, because it frees the CPSA from the need to consider too many options about what to do and say next, a decision that, in many situations, would require domain-specific knowledge.
",4.3 CPS Acts Related to Initiative and Execution,[0],[0]
The BA’s reply to a WHAT-NEXT depends on its own private problem-solving state.,4.3 CPS Acts Related to Initiative and Execution,[0],[0]
"It may be that it has done some planning and, as a result, it wants to propose a way of making progress towards accomplishing the active objective.",4.3 CPS Acts Related to Initiative and Execution,[0],[0]
"It may be that it does not have sufficient information to make progress, in which case it may formulate an intention to ask the user to provide the information.",4.3 CPS Acts Related to Initiative and Execution,[0],[0]
"Or, if the active objective is a question, it may have come up with an answer; that update would prob-
ably get very high priority.",4.3 CPS Acts Related to Initiative and Execution,[0],[0]
"All these possibilities are handled by acts we have already discussed.
",4.3 CPS Acts Related to Initiative and Execution,[0],[0]
"One other possibility is that the BA is currently not doing any reasoning, but simply acting on the active objective, or has accomplished it.",4.3 CPS Acts Related to Initiative and Execution,[0],[0]
"Updates to the status of an objective are communicated via a special CPS act, which takes the following form:
(EXECUTION-STATUS :goal A1 :status GS)
Here GS is an expression that indicates the status of the goal.",4.3 CPS Acts Related to Initiative and Execution,[0],[0]
"Currently it can be one of three indicators:
1.",4.3 CPS Acts Related to Initiative and Execution,[0],[0]
"DONE, which signifies that A1 was accomplished.",4.3 CPS Acts Related to Initiative and Execution,[0],[0]
"CPSA will create a commu-
nicative act to inform the user, and, if the user agrees, releases the objective.
2.",4.3 CPS Acts Related to Initiative and Execution,[0],[0]
"WORKING-ON-IT, which indicates that the BA is actively pursuing A1, but it will take more time.",4.3 CPS Acts Related to Initiative and Execution,[0],[0]
"The CPSA may decide to
inform the user, and creates a trigger for itself to check back later.
3.",4.3 CPS Acts Related to Initiative and Execution,[0],[0]
"WAITING-FOR-USER, which indicates that the BA cannot make progress on A1 because it is waiting for the user to act on
it (or another objective that A1 depends on).",4.3 CPS Acts Related to Initiative and Execution,[0],[0]
"As a result, the CPSA will construct a communicative act to prompt the user.
",4.3 CPS Acts Related to Initiative and Execution,[0],[0]
"This CPS act also allows the BA to communicate partial execution status (that it has executed some actions, though it has not accomplished the objective yet), but we leave those details out of this discussion.",4.3 CPS Acts Related to Initiative and Execution,[0],[0]
"We implemented our CPS model as a component in the TRIPS system (Allen et al., 2000), which has recently been released in the public domain under a GNU GPL License.
",5 The Cogent System,[0],[0]
"The TRIPS system comes with a broad coverage parser (Allen and Teng, 2017) with an extensive grammar and an effective 100,000+ word semantic vocabulary defined in terms of a 4000 concept domain-independent ontology.",5 The Cogent System,[0],[0]
"It operates in concert with a suite of statistical preprocessing components, performing tasks such as part-ofspeech tagging, named entity recognition, and identification of likely constituent boundaries.",5 The Cogent System,[0],[0]
These preprocessed inputs are provided to the core TRIPS parser as advice.,5 The Cogent System,[0],[0]
"The parser con-
structs from the input a logical form, which is a semantic representation that captures an unscoped modal logic (Manshadi et al., 2008).",5 The Cogent System,[0],[0]
"The logical form includes the surface speech act, semantic types, semantic roles for predicate arguments, and dependency relations.
",5 The Cogent System,[0],[0]
"TRIPS also includes an interpretation manager that converts the logical forms into communicative acts, performing language-based intention recognition and normalizing different surface forms.
",5 The Cogent System,[0],[0]
"We packaged the TRIPS NLU components (including the lexicon and ontology) with our CPS agent, thereby creating a dialogue system shell, which we call Cogent.",5 The Cogent System,[0],[0]
This system does not include a BA or an NLG component (Cogent’s components are surrounded with a dashed line in Figure 1).,5 The Cogent System,[0],[0]
"Thus, it is a true domain-independent shell, not a system that can be adapted to other domains.",5 The Cogent System,[0],[0]
It can carry out very minimal conversations because social conversational acts such as greetings are handled in a domain-independent manner in the CPSA.,5 The Cogent System,[0],[0]
"But, ultimately, the purpose of the shell is to be used to create domain applications.",5 The Cogent System,[0],[0]
"The success of the task we set to accomplish is whether this shell can be and is used by independent developers to develop operational dialogue systems in domains of their choice.
",5 The Cogent System,[0],[0]
"As discussed in the previous section, the CPS acts and the obligations they engender establish a protocol that developers of behavioral agents must implement.",5 The Cogent System,[0],[0]
"Other than that, we believe the CPSA offers functionality to develop different styles of conversational agents (user-driven, system-driven or fully mixed-initiative).",5 The Cogent System,[0],[0]
"The developers also must implement their own NL Generation component, for reasons that we touched upon earlier.
",5 The Cogent System,[0],[0]
"Of note, by default all CPS acts have their contents expressed in the TRIPS ontology.",5 The Cogent System,[0],[0]
We are also providing a tool for mapping concepts in the TRIPS ontology to domain ontologies.,5 The Cogent System,[0],[0]
"We have adapted the TRIPS interpretation manager to use these mappings to produce content in the domain ontology, to make it easier for the Behavioral Agents to interpret the CONTEXT associated with each CPS act.",5 The Cogent System,[0],[0]
"The details of the ontology mapping tool and the mappings it creates are, however, beyond the scope of this paper.",5 The Cogent System,[0],[0]
"We describe briefly six system prototypes that have been built using Cogent as the base frame-
work; thus, they all use the same CPS agent described above.",6 Systems Implemented in Cogent,[0],[0]
"In all cases, the developers of these prototypes used the protocol described above to create behavioral agents that, in turn, act as integrators of other problem solvers.",6 Systems Implemented in Cogent,[0],[0]
"The descriptions of these systems are going to be necessarily brief; the interested reader is encouraged to follow the references to get a better understanding of their capabilities and the kinds of dialogues they support (unfortunately, not all systems have been published yet).",6 Systems Implemented in Cogent,[0],[0]
"All these systems have been developed as part of DARPA’s Communicating with Computers (CwC) program 3 .
",6 Systems Implemented in Cogent,[0],[0]
Cabot:,6 Systems Implemented in Cogent,[0],[0]
"This is a mixed-initiative system for planning and execution in the blocks world, the tasks being of jointly building structures (Perera et al., 2017).",6 Systems Implemented in Cogent,[0],[0]
"Both the user and the system can come up with their own goals, and, if necessary, they will negotiate constraints on those structures (size, colors, etc.)",6 Systems Implemented in Cogent,[0],[0]
so all the goals can be completed.,6 Systems Implemented in Cogent,[0],[0]
They also negotiate their roles in building these structures (“architect” or “builder”).,6 Systems Implemented in Cogent,[0],[0]
This system uses a 2D simulated version of the blocks world.,6 Systems Implemented in Cogent,[0],[0]
"The examples used in this paper are from interactions with this system.
",6 Systems Implemented in Cogent,[0],[0]
"Cabot-L: This system learns names and structural properties of complex objects in a physically situated blocks world scenario (Perera et al., 2017; Perera et al., 2018).",6 Systems Implemented in Cogent,[0],[0]
The user teaches the system by providing examples of structures together with descriptions in language.,6 Systems Implemented in Cogent,[0],[0]
"The system has capabilities to perceive the world and detect changes to it, and can ask the user questions about various features of the structures, to learn a general model.",6 Systems Implemented in Cogent,[0],[0]
"To validate the inferred model, the user can then show additional examples and ask the system to classify them and explain its reasoning.",6 Systems Implemented in Cogent,[0],[0]
"The user and the system can interact via either written or spoken language.
",6 Systems Implemented in Cogent,[0],[0]
BoB:,6 Systems Implemented in Cogent,[0],[0]
This system acts as an assistant biologist.,6 Systems Implemented in Cogent,[0],[0]
"It has fairly extensive knowledge of molecular biology and can assist the user by responding to inquiries about properties of genes, proteins, molecular mechanisms, their relationship to cellular processes and disease, building and visualizing complex causal models, running simulations on these models to detect their dynamic properties, etc.",6 Systems Implemented in Cogent,[0],[0]
"To manage this wide range of problemsolving behaviors, BoB’s BA integrates a variety of agents with specific expertise.",6 Systems Implemented in Cogent,[0],[0]
"3 https://www.darpa.mil/program/communicating-withcomputers
Musica: This system uses a computational model of music cognition, as well as knowledge about existing pieces of music, to help a human composer create and edit a musical score (Quick and Morrison, 2017).
",6 Systems Implemented in Cogent,[0],[0]
SMILEE:,6 Systems Implemented in Cogent,[0],[0]
"This system acts as a partner for playing a cooperative game (Kim et al., 2018).",6 Systems Implemented in Cogent,[0],[0]
The game involves placing pieces (blocks) on a board to create complex symmetrical configurations.,6 Systems Implemented in Cogent,[0],[0]
"Players alternate, but each player can hold their turn for multiple rounds.",6 Systems Implemented in Cogent,[0],[0]
Each player has some freedom to be creative with respect to the configuration being pursued (it is not set in advance).,6 Systems Implemented in Cogent,[0],[0]
"Thus, they have to negotiate turn taking, and they can ask for explanations to achieve a shared understanding about the properties of the configuration being created.
",6 Systems Implemented in Cogent,[0],[0]
Aesop:,6 Systems Implemented in Cogent,[0],[0]
A system for building animated stories.,6 Systems Implemented in Cogent,[0],[0]
"The user acts as a director, and can choose scenes, props, characters, direct them what to do, etc.",6 Systems Implemented in Cogent,[0],[0]
"Essentially, the system provides a dialogue interface to a sophisticated system for creating visual narratives.
",6 Systems Implemented in Cogent,[0],[0]
"Of note, these systems work in several application domains, with varying interaction styles.",6 Systems Implemented in Cogent,[0],[0]
Musica and Aesop currently work mostly in fixedinitiative mode (user tells the system what to do).,6 Systems Implemented in Cogent,[0],[0]
All others involve varying degrees of mixed initiative.,6 Systems Implemented in Cogent,[0],[0]
"While Cabot is a more traditional planning domain, it is interesting to note that all others involve fairly open-ended collaborative tasks, for which the ultimate goal is learning or creating something new.",6 Systems Implemented in Cogent,[0],[0]
"BoB is notable for the fact that it is helping the user learn new knowledge, by helping to formulate and evaluate biological hypotheses (which may even lead to new scientific discoveries).
",6 Systems Implemented in Cogent,[0],[0]
"Importantly, with the exception of Cabot-L, which was developed by our team, all others were developed by independent teams (the BAs for Cabot and BoB were developed by a single team, though the latter also involved collaboration with a large group of biologists and bioinformaticians).",6 Systems Implemented in Cogent,[0],[0]
"We helped those teams understand how our tools work and the meaning of the CPS acts (especially to the early adopters, who did not have the benefit of much documentation), but we had no role in deciding what problemsolving behaviors they should or should not implement, how to implement them and so on.",6 Systems Implemented in Cogent,[0],[0]
"Two of the systems (BoB and Musica) required additions to our surface NLP components (mainly add-
ing domain-specific named entity recognizers) and some additional ontology concepts and mappings; we provided those customizations.",6 Systems Implemented in Cogent,[0],[0]
"The version of the TRIPS Parser we started with proved to be fairly robust, but we did have to adapt it in response to failures reported by the dialogue system developers.",6 Systems Implemented in Cogent,[0],[0]
"Nevertheless, these enhancements were not domain-specific – that is, the same parser, with the same grammar, is used for all systems.
",6 Systems Implemented in Cogent,[0],[0]
"In all systems, developers used custom tem-
plate-based NLG.",6 Systems Implemented in Cogent,[0],[0]
In this paper we reported on the development of a new domain-independent dialogue manager based on the collaborative problem solving model.,7 Summary and Discussion,[0],[0]
"We packaged this dialogue manager with a suite of broad coverage natural language understanding components (from the TRIPS system) and created a new, domain-independent CPS-based dialogue system shell.",7 Summary and Discussion,[0],[0]
"This shell has been used by several independent teams of researchers to develop dialogue systems in a variety of application domains, with different conversational styles.",7 Summary and Discussion,[0],[0]
"We believe this to be the first successful implementation of a domain-independent dialogue system shell based on the CPS model (or any other model of equivalent complexity).
",7 Summary and Discussion,[0],[0]
"We do not claim the CPSA to be complete, however.",7 Summary and Discussion,[0],[0]
"For example, it can sometimes detect an ambiguity in the user’s intention and generate a clarification question, but its abilities in this regard are fairly limited.",7 Summary and Discussion,[0],[0]
"BoB has demonstrated some limited handling of hypotheticals (in what-if questions) at the problem-solving level, but the CPSA itself does not yet track hypothetical situations.",7 Summary and Discussion,[0],[0]
"We expect that, with wider adoption, we will inevitably be confronted with the need to improve both our model and its implementation.
",7 Summary and Discussion,[0],[0]
"As noted above in reference to BoB and Musica, for domains requiring adaptation of the NLU components, language specialists are still needed.",7 Summary and Discussion,[0],[0]
"We have not yet endeavored to create tools that would make it easier for dialogue system developers to adapt/improve themselves the NLU components.
",7 Summary and Discussion,[0],[0]
Our current focus is on evaluating the robustness of the intention recognition functionality of the CPSA.,7 Summary and Discussion,[0],[0]
"This research was supported by the DARPA Communicating with Computers program, under ARO contract W911NF-15-1-0542.",Acknowledgments,[0],[0]
"The bulk of current research in dialogue systems is focused on fairly simple task models, primarily state-based.",abstractText,[0],[0]
Progress on developing dialogue systems for more complex tasks has been limited by the lack generic toolkits to build from.,abstractText,[0],[0]
In this paper we report on our development from the ground up of a new dialogue model based on collaborative problem solving.,abstractText,[0],[0]
We implemented the model in a dialogue system shell (Cogent) that allows developers to plug in problem-solving agents to create dialogue systems in new domains.,abstractText,[0],[0]
"The Cogent shell has now been used by several independent teams of researchers to develop dialogue systems in different domains, with varied lexicons and interaction style, each with their own problem-solving backend.",abstractText,[0],[0]
We believe this to be the first practical demonstration of the feasibility of a CPSbased dialogue system shell.,abstractText,[0],[0]
Cogent: A Generic Dialogue System Shell Based on a Collaborative Problem Solving Model,title,[0],[0]
"During the last half-decade deep learning has significantly improved performance on a variety of tasks (for a review, see LeCun et al. (2015)).",1. Introduction,[0],[0]
"However, deep neural network (DNN) solutions remain poorly understood, leaving many
*Equal contribution 1DeepMind, London, UK.",1. Introduction,[0],[0]
"Correspondence to: Samuel Ritter <ritters@google.com>, David G.T. Barrett <barrett@google.com>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
to think of these models as black boxes, and to question whether they can be understood at all (Bornstein, 2016; Lipton, 2016).",1. Introduction,[0],[0]
"This opacity obstructs both basic research seeking to improve these models, and applications of these models to real world problems (Caruana et al., 2015).
",1. Introduction,[0],[0]
"Recent pushes have aimed to better understand DNNs: tailor-made loss functions and architectures produce more interpretable features (Higgins et al., 2016; Raposo et al., 2017) while output-behavior analyses unveil previously opaque operations of these networks (Karpathy et al., 2015).",1. Introduction,[0],[0]
"Parallel to this work, neuroscience-inspired methods such as activation visualization (Li et al., 2015), ablation analysis (Zeiler & Fergus, 2014) and activation maximization (Yosinski et al., 2015) have also been applied.
",1. Introduction,[0],[0]
"Altogether, this line of research developed a set of promising tools for understanding DNNs, each paper producing a glimmer of insight.",1. Introduction,[0],[0]
"Here, we propose another tool for the kit, leveraging methods inspired not by neuroscience, but instead by psychology.",1. Introduction,[0],[0]
Cognitive psychologists have long wrestled with the problem of understanding another opaque intelligent system: the human mind.,1. Introduction,[0],[0]
"We contend that the search for a better understanding of DNNs may profit from the rich heritage of problem descriptions, theories, and experimental tools developed in cognitive psychology.",1. Introduction,[0],[0]
"To test this belief, we performed a proof-ofconcept study on state-of-the-art DNNs that solve a particularly challenging task: one-shot word learning.",1. Introduction,[0],[0]
"Specifically, we investigate Matching Networks (MNs) (Vinyals et al., 2016), which have state-of-the-art one-shot learning performance on ImageNet and we investigate an Inception Baseline model (Szegedy et al., 2015a).
",1. Introduction,[0],[0]
"Following the approach used in cognitive psychology, we began by hypothesizing an inductive bias our model may use to solve a word learning task.",1. Introduction,[0],[0]
"Research in developmental psychology shows that when learning new words, humans tend to assign the same name to similarly shaped items rather than to items with similar color, texture, or size.",1. Introduction,[0],[0]
"To test the hypothesis that our DNNs discover this same “shape bias”, we probed our models using datasets and an experimental setup based on the original shape bias studies (Landau et al., 1988).
",1. Introduction,[0],[0]
Our results are as follows: 1) Inception networks trained on ImageNet do indeed display a strong shape bias.,1. Introduction,[0],[0]
2),1. Introduction,[0],[0]
"There is high variance in the bias between Inception networks initialized with different random seeds, demonstrating that otherwise identical networks converge to qualitatively different solutions.",1. Introduction,[0],[0]
"3) MNs also have a strong shape bias, and this bias closely mimics the bias of the Inception model that provides input to the MN. 4) By emulating the shape bias observed in children, these models provide a candidate computational account for human one-shot word learning.",1. Introduction,[0],[0]
"Altogether, these results show that the technique of testing hypothesized biases using probe datasets can yield both expected and surprising insights about solutions discovered by trained DNNs1.",1. Introduction,[0],[0]
"Before we delve into the specifics of the shape bias and one-shot word learning, we will describe our approach in the general context of inductive biases, probe datasets, and statistical learning.","2. Inductive Biases, Statistical Learners and Probe Datasets",[0],[0]
"Suppose we have some data {yi, xi}Ni=1","2. Inductive Biases, Statistical Learners and Probe Datasets",[0],[0]
where yi = f(xi).,"2. Inductive Biases, Statistical Learners and Probe Datasets",[0],[0]
Our goal is to build a model of the data g(.),"2. Inductive Biases, Statistical Learners and Probe Datasets",[0],[0]
"to optimize some loss function L measuring the disparity between y and g(x), e.g., L = ∑ i ||yi− g(xi)||2.","2. Inductive Biases, Statistical Learners and Probe Datasets",[0],[0]
"Perhaps this data x is images of ImageNet objects to be classified, images and histology of tumors to be classified as benign or malignant (Kourou et al., 2015), or medical history and vital measurements to be classified according to likely pneumonia outcomes (Caruana et al., 2015).
","2. Inductive Biases, Statistical Learners and Probe Datasets",[0],[0]
A statistical learner such as a DNN will minimize L by discovering properties of the input x that are predictive of the labels y.,"2. Inductive Biases, Statistical Learners and Probe Datasets",[0],[0]
"These discovered predictive properties are, in effect, the properties of x for which the trained model has an inductive bias.","2. Inductive Biases, Statistical Learners and Probe Datasets",[0],[0]
"Examples of such properties include the shape of ImageNet objects, the number of nodes of a tumor, or a particular constellation of blood test values that often precedes an exacerbation of pneumonia symptoms.
","2. Inductive Biases, Statistical Learners and Probe Datasets",[0],[0]
"Critically, in real-world datasets such as these, the discovered properties are unlikely to correspond to a single feature of the input x; instead they correspond to complex conjunctions of those features.","2. Inductive Biases, Statistical Learners and Probe Datasets",[0],[0]
"We could describe one of these properties using a function h(x), which, for example, returns the shape of the focal object given an ImageNet im-
1The use of behavioral probes to understand neural network function has been extensively applied within psychology itself, where neural networks have been employed as models of human brain function (Rumelhart et al., 1988; Plaut et al., 1996; Rogers & McClelland, 2004; Mareschal et al.).","2. Inductive Biases, Statistical Learners and Probe Datasets",[0],[0]
"To our knowledge, work applying behavioral probes to DNNs in machine learning has been quite limited; we only are aware of Zoran et al. (2015) and Goodfellow et al. (2009), who used psychophysics-like experiments to better understand image processing models.
","2. Inductive Biases, Statistical Learners and Probe Datasets",[0],[0]
"age, or the number of nodes given a scan of tumor.","2. Inductive Biases, Statistical Learners and Probe Datasets",[0],[0]
"Indeed, one way to articulate the difficulty in understanding DNNs is to say that we often can’t intuitively describe these conjunctions of features h(x); although we often have numerical representations in intermediate DNN layers, they’re often too arcane for us to interpret.
","2. Inductive Biases, Statistical Learners and Probe Datasets",[0],[0]
"We advocate for addressing this problem using the following hypothesis-driven approach: First, propose a property hp(x) that the model may be using.","2. Inductive Biases, Statistical Learners and Probe Datasets",[0],[0]
"Critically, it’s not necessary that hp(x) be a function that can be evaluated using an automated method.","2. Inductive Biases, Statistical Learners and Probe Datasets",[0],[0]
"Instead, the intention is that hp(x) is a function that humans (e.g. ML researchers and practitioners) can intuitively evaluate.","2. Inductive Biases, Statistical Learners and Probe Datasets",[0],[0]
"hp(x) should be a property that is believed to be relevant to the problem, such as object shape or number of tumor nodes.
","2. Inductive Biases, Statistical Learners and Probe Datasets",[0],[0]
"After proposing a property, the next step is to generate predictions about how the model should behave when given various inputs, if in fact it uses a bias with respect to the property hp(x).","2. Inductive Biases, Statistical Learners and Probe Datasets",[0],[0]
"Then, construct and carry out an experiment wherein those predictions are tested.","2. Inductive Biases, Statistical Learners and Probe Datasets",[0],[0]
"In order to execute such an experiment, it typically will be necessary to craft a set of probe examples x that cover a relevant portion of the range of hp(x), for example a variety of object shapes.","2. Inductive Biases, Statistical Learners and Probe Datasets",[0],[0]
The results of this experiment will either support or fail to support the hypothesis that the model uses hp(x) to solve the task.,"2. Inductive Biases, Statistical Learners and Probe Datasets",[0],[0]
"This process can be especially valuable in situations where there is little or no training data available in important regions of the input space, and a practitioner needs to know how the trained model will behave in that region.
","2. Inductive Biases, Statistical Learners and Probe Datasets",[0],[0]
Psychologists have developed a repertoire of such hypotheses and experiments in their effort to understand the human mind.,"2. Inductive Biases, Statistical Learners and Probe Datasets",[0],[0]
Here we explore the application of one of these theory-experiment pairs to state of the art one-shot learning models.,"2. Inductive Biases, Statistical Learners and Probe Datasets",[0],[0]
We will begin by describing the historical backdrop for the human one-shot word learning experiments that we will then apply to our DNNs.,"2. Inductive Biases, Statistical Learners and Probe Datasets",[0],[0]
"Discussions of one-shot word learning in the psychological literature inevitably begin with the philosopher W.V.O. Quine, who broke this problem down and described one of its most computationally challenging components: there are an enormous number of tenable hypotheses that a learner can use to explain a single observed example.",3. The problem of word learning; the solution of inductive biases,[0],[0]
"To make this point, Quine penned his now-famous parable of the field linguist who has gone to visit a culture whose language is entirely different from our own (Quine, 1960).",3. The problem of word learning; the solution of inductive biases,[0],[0]
"The linguist is trying to learn some words from a helpful native, when a rabbit runs past.",3. The problem of word learning; the solution of inductive biases,[0],[0]
"The native declares “gava-
gai”, and the linguist is left to infer the meaning of this new word.",3. The problem of word learning; the solution of inductive biases,[0],[0]
"Quine points out that the linguist is faced with an abundance of possible inferences, including that “gavagai” refers to rabbits, animals, white things, that specific rabbit, or “undetached parts of rabbits”.",3. The problem of word learning; the solution of inductive biases,[0],[0]
"Quine argues that indeed there is an infinity of possible inferences to be made, and uses this conclusion to bolster the assertion that meaning itself cannot be defined in terms of internal mental events2.
",3. The problem of word learning; the solution of inductive biases,[0],[0]
"Contrary to Quine’s intentions, when this example was introduced to the developmental psychology community by Macnamara (1972), it spurred them not to give up on the idea of internal meaning, but instead to posit and test for cognitive biases that enable children to eliminate broad swaths of the hypothesis space (Bloom, 2000).",3. The problem of word learning; the solution of inductive biases,[0],[0]
"A variety of hypothesis-eliminating biases were then proposed including the whole object bias, by which children assume that a word refers to an entire object and not its components (Markman, 1990); the taxonomic bias, by which children assume a word refers to the basic level category an object belongs to (Markman & Hutchinson, 1984); the mutual exclusivity bias, by which children assume that a word only refers to one object category (Markman & Wachtel, 1988); the shape bias, with which we are concerned here (Landau et al., 1988); and a variety of others (Bloom, 2000).",3. The problem of word learning; the solution of inductive biases,[0],[0]
"These biases were tested empirically in experiments wherein children or adults were given an object (or picture of an object) along with a novel name, then were asked whether the name should apply to various other objects.
",3. The problem of word learning; the solution of inductive biases,[0],[0]
"Taken as a whole, this work yielded a computational level (Marr, 1982) account of word learning whereby people make use of biases to eliminate unlikely hypotheses when inferring the meaning of new words.",3. The problem of word learning; the solution of inductive biases,[0],[0]
"Other contrasting and complementary approaches to explaining word learning exist in the psychological literature, including association learning (Regier, 1996; Colunga & Smith, 2005) and Bayesian inference (Xu & Tenenbaum, 2007).",3. The problem of word learning; the solution of inductive biases,[0],[0]
"We leave the application of these theories to deep learning models to future work, and focus on determining what insight can be gained by applying a hypothesis elimination theory and methodology.
",3. The problem of word learning; the solution of inductive biases,[0],[0]
We begin the present work with the knowledge that part of the hypothesis elimination theory is correct: the models surely use some kind of inductive biases since they are statistical learning machines that successfully model the mapping between images and object labels.,3. The problem of word learning; the solution of inductive biases,[0],[0]
"However, several questions remain open.",3. The problem of word learning; the solution of inductive biases,[0],[0]
What predictive properties did our DNNs find?,3. The problem of word learning; the solution of inductive biases,[0],[0]
Do all of them find the same properties?,3. The problem of word learning; the solution of inductive biases,[0],[0]
Are any of those properties interpretable to humans?,3. The problem of word learning; the solution of inductive biases,[0],[0]
Are they the same properties that children use?,3. The problem of word learning; the solution of inductive biases,[0],[0]
"How do these biases change over the course of training?
",3. The problem of word learning; the solution of inductive biases,[0],[0]
"To address these questions, we carry out experiments analogous to those of Landau et al. (1988).",3. The problem of word learning; the solution of inductive biases,[0],[0]
"This enables us to
test whether the shape bias – a human interpretable feature used by children when learning language – is visible in the behavior of MNs and Inception networks.",3. The problem of word learning; the solution of inductive biases,[0],[0]
"Furthermore we are able to test whether these two models, as well as different instances of each of them, display the same bias.",3. The problem of word learning; the solution of inductive biases,[0],[0]
"In the next section we will describe in detail the one-shot word learning problem, and the MNs and Inception networks we use to solve it.",3. The problem of word learning; the solution of inductive biases,[0],[0]
The one-shot word learning task is to label a novel data example x̂,4.1. One-shot word learning task,[0],[0]
(e.g. a novel probe image) with a novel class label ŷ,4.1. One-shot word learning task,[0],[0]
(e.g. a new word) after only a single example.,4.1. One-shot word learning task,[0],[0]
"More specifically, given a support set S = {(xi, yi) :",4.1. One-shot word learning task,[0],[0]
i ∈,4.1. One-shot word learning task,[0],[0]
"[1, k]}, of images xi and their associated labels yi, and an unlabelled probe image x̂, the one-shot learning task is to identify the true label of the probe image ŷ from the support set labels {yi : i ∈",4.1. One-shot word learning task,[0],[0]
"[1, k]}:
ŷ =",4.1. One-shot word learning task,[0],[0]
"argmax y
P (y|x̂, S).",4.1. One-shot word learning task,[0],[0]
"(1)
We assume that the image labels yi are represented using a one-hot encoding and that P (y|x̂, S) is parameterised by a DNN, allowing us to leverage the ability of deep networks to learn powerful representations.",4.1. One-shot word learning task,[0],[0]
"In our simplest baseline one-shot architecture, a probe image x̂ is given the label of the nearest neighbour from the support set:
ŷ = y
(x, y) = arg min (xi,yi)∈S
d(h(xi), h(x̂)) (2)
where d is a distance function.",4.2. Inception: baseline one-shot learning model,[0],[0]
"The function h is parameterised by Inception – one of the best performing ImageNet classification models (Szegedy et al., 2015a).",4.2. Inception: baseline one-shot learning model,[0],[0]
"Specifically, h returns features from the last layer (the softmax input) of a pre-trained Inception classifier, where the Inception classifier is trained using rms-prop, as described in Szegedy et al. (2015b), section 8.",4.2. Inception: baseline one-shot learning model,[0],[0]
"With these features as input and cosine distance as the distance function, the classifier in equation 2 achieves 87.6% accuracy on one-shot classification on the ImageNet dataset (Vinyals et al., 2016).",4.2. Inception: baseline one-shot learning model,[0],[0]
"Henceforth, we call the Inception classifier together with the nearest-neighbor component the Inception Baseline (IB) model.
",4.2. Inception: baseline one-shot learning model,[0],[0]
"2Unlike Quine, we use a pragmatic definition of meaning - a human or model understands the meaning of a word if they assign that word to new instances of objects in the correct category.",4.2. Inception: baseline one-shot learning model,[0],[0]
"We also investigate a state-of-the-art one-shot learning architecture called Matching Nets (MN) (Vinyals et al., 2016).",4.3. Matching Nets model architecture and training,[0],[0]
"MNs are a fully differentiable neural network architecture with state-of-the-art one shot learning performance on ImageNet (93.2% one-shot labelling accuracy).
",4.3. Matching Nets model architecture and training,[0],[0]
"MNs are trained to assign label ŷ to probe image x̂ according to equation 1 using an attention mechanism a acting on image embeddings stored in the support set S:
a(x̂, xi) = ed(f(x̂,S),g(xi,S))∑ j e d(f(x̂,S),g(xj ,S)) , (3)
where d is a cosine distance and where f and g provide context-dependent embeddings of x̂ and xi (with context S).",4.3. Matching Nets model architecture and training,[0],[0]
"The embedding g(xi, S) is a bi-directional LSTM (Hochreiter & Schmidhuber, 1997) with the support set S provided as an input sequence.",4.3. Matching Nets model architecture and training,[0],[0]
"The embedding f(x̂, S) is an LSTM with a read-attention mechanism operating over the entire embedded support set.",4.3. Matching Nets model architecture and training,[0],[0]
"The input to the LSTM is given by the penultimate layer features of a pre-trained deep convolutional network, specifically Inception, as in our baseline IB model described above (Szegedy et al., 2015a).
",4.3. Matching Nets model architecture and training,[0],[0]
"The training procedure for the one-shot learning task is critical if we want MNs to classify a probe image x̂ after viewing only a single example of this new image class in its support set (Hochreiter et al., 2001; Santoro et al., 2016).
",4.3. Matching Nets model architecture and training,[0],[0]
"To train MNs we proceed as follows: (1) At each step of training, the model is given a small support set of images and associated labels.",4.3. Matching Nets model architecture and training,[0],[0]
"In addition to the support set, the model is fed an unlabelled probe image x̂; (2)",4.3. Matching Nets model architecture and training,[0],[0]
The model parameters are then updated to improve classification accuracy of the probe image x̂ given the support set.,4.3. Matching Nets model architecture and training,[0],[0]
"Parameters are updated using stochastic gradient descent with a learning rate of 0.1; (3) After each update, the labels {yi : i ∈",4.3. Matching Nets model architecture and training,[0],[0]
"[1, k]} in the training set are randomly re-assigned to new image classes (the label indices are randomly permuted, but the image labels are not changed).",4.3. Matching Nets model architecture and training,[0],[0]
This is a critical step.,4.3. Matching Nets model architecture and training,[0],[0]
It prevents MNs from learning a consistent mapping between a category and a label.,4.3. Matching Nets model architecture and training,[0],[0]
"Usually, in classification, this is what we want, but in one-shot learning we want to train our model for classification after viewing a single in-class example from the support set.",4.3. Matching Nets model architecture and training,[0],[0]
"Formally, our objective function is:
L = EC∼T ES∼C,B∼C  ∑ (x,y)∈B logP (y|x, S)  (4) where T is the set of all possible labelings of our classes, S is a support set sampled with a class labelling C ∼ T and B is a batch of probe images and labels, also with the same randomly chosen class labelling as the support set.
",4.3. Matching Nets model architecture and training,[0],[0]
Next we will describe the probe datasets we used to test for the shape bias in the IB and MNs after ImageNet training.,4.3. Matching Nets model architecture and training,[0],[0]
The Cognitive Psychology Probe Data (CogPsyc data) that we use consists of 150 images of objects (Figure 1).,5.1. Cognitive Psychology Probe Data,[0],[0]
"The images are arranged in triples consisting of a probe image, a shape-match image (that matches the probe in colour but not shape), and a color-match image (that matches the probe in shape but not colour).",5.1. Cognitive Psychology Probe Data,[0],[0]
"In the dataset there are 10 triples, each shown on 5 different backgrounds, giving a total of 50",5.1. Cognitive Psychology Probe Data,[0],[0]
"triples.3
The images were generously provided by cognitive psychologist Linda Smith.",5.1. Cognitive Psychology Probe Data,[0],[0]
The images are photographs of stimuli used previously in shape bias experiments conducted in the Cognitive Development Lab at Indiana University.,5.1. Cognitive Psychology Probe Data,[0],[0]
The potentially confounding variables of background content and object size are controlled in this dataset.,5.1. Cognitive Psychology Probe Data,[0],[0]
We have also assembled a real-world dataset consisting of 90 images of objects (30 triples) collected using Google Image Search.,5.2. Probe Data from the wild,[0],[0]
"Again, the images are arranged in triples consisting of a probe, a shape-match and a colour-match.",5.2. Probe Data from the wild,[0],[0]
"For the probe image, we chose images of real objects that are unlikely to appear in standard image datasets such as ImageNet.",5.2. Probe Data from the wild,[0],[0]
"In this way, our data contains the irregularity of the real world while also probing our models’ properties outside of the image space covered in our training data.",5.2. Probe Data from the wild,[0],[0]
"For the shape-match image, we chose an object with a similar shape (but with a very different colour), and for the colourmatch image, we chose an object with a similar colour (but with a very different shape).",5.2. Probe Data from the wild,[0],[0]
"For example, one triple consists of a silver tuning fork as the probe, a silver guitar capo as the colour match, and a black tuning fork as the shape match.",5.2. Probe Data from the wild,[0],[0]
"Each photo in the dataset contains a single object on a white background.
",5.2. Probe Data from the wild,[0],[0]
We collected this data to strengthen our confidence in the results obtained for the CogPsych dataset and to demonstrate the ease with which such probe datasets can be constructed.,5.2. Probe Data from the wild,[0],[0]
One of the authors crafted this dataset solely using Google Image Search in the span of roughly two days’ work.,5.2. Probe Data from the wild,[0],[0]
"Our results with this dataset, especially the fact that the bias pattern over time matches the results from the well established CogPsych dataset, support the contention that DNN practitioners can collect effective probe datasets with minimal time expenditure using readily available tools.
",5.2. Probe Data from the wild,[0],[0]
3 The CogPsyc dataset is available at http://www. indiana.edu/˜cogdev/SB_testsets.html,5.2. Probe Data from the wild,[0],[0]
"First, we measured the shape bias in IB: we used a pretrained Inception classifier (with 94% top-5 accuracy) to provide features for our nearest-neighbour one-shot classifier, and probed the model using the CogPsyc dataset.",6.1. Shape bias in the Inception Baseline Model,[0],[0]
"Specifically, for a given probe image x̂, we loaded the shape-match image xs and corresponding label ys, along with the colour-match image xc and corresponding label yc into memory, as the support set S = {(xs, ys), (xc, yc)}.",6.1. Shape bias in the Inception Baseline Model,[0],[0]
We then calculated ŷ using Equation 2.,6.1. Shape bias in the Inception Baseline Model,[0],[0]
Our model assigned either yc or ys to the probe image.,6.1. Shape bias in the Inception Baseline Model,[0],[0]
"To estimate the shape bias Bs, we calculated the proportion of shape labels assigned to the probe:
Bs = E(δ(ŷ",6.1. Shape bias in the Inception Baseline Model,[0],[0]
"− ys)), (5)
where E is an expectation across probe images and δ is the Dirac delta function.
",6.1. Shape bias in the Inception Baseline Model,[0],[0]
We ran all IB experiments using both Euclidean and cosine distance as the distance function.,6.1. Shape bias in the Inception Baseline Model,[0],[0]
"We found that the results for the two distance functions were qualitatively similar, so we only report results for Euclidean distance.
",6.1. Shape bias in the Inception Baseline Model,[0],[0]
We found the shape bias of IB to be Bs = 0.68.,6.1. Shape bias in the Inception Baseline Model,[0],[0]
"Similarly, the shape bias of IB using our real-world dataset was Bs = 0.97.",6.1. Shape bias in the Inception Baseline Model,[0],[0]
"Together, these results strongly suggest that IB
trained on ImageNet has a stronger bias towards shape than colour.
",6.1. Shape bias in the Inception Baseline Model,[0],[0]
"Note that, as expected, the shape bias of this model is qualitatively similar across datasets while being quantitatively different - largely because the datasets themselves are quite different.",6.1. Shape bias in the Inception Baseline Model,[0],[0]
"Indeed, the datasets were chosen to be quite different so that we could explore a broad space of possibilities.",6.1. Shape bias in the Inception Baseline Model,[0],[0]
"In particular, our CogPsyc dataset backgrounds have much larger variability than our real-world dataset backgrounds, and our real-world dataset objects have much greater variability than the CogPsyc dataset objects.",6.1. Shape bias in the Inception Baseline Model,[0],[0]
"Next, we probed the MNs using a similar procedure.",6.2. Shape bias in the Matching Nets Model,[0],[0]
We used the IB trained in the previous section to provide the input features for the MN as described in section 4.3.,6.2. Shape bias in the Matching Nets Model,[0],[0]
"Then, following the training procedure outlined in section 4.3 we trained MNs for one-shot word learning on ImageNet, achieving state-of-the-art performance, as reported in (Vinyals et al., 2016).",6.2. Shape bias in the Matching Nets Model,[0],[0]
"Then, repeating the analysis above, we found that MNs have a shape of bias Bs = 0.7 using our CogPsyc dataset and a bias of Bs = 1 using the real-world dataset.",6.2. Shape bias in the Matching Nets Model,[0],[0]
It is interesting to note that these bias values are very similar to the IB bias values.,6.2. Shape bias in the Matching Nets Model,[0],[0]
The observation of a shape bias immediately raises some important questions.,6.3. Shape bias statistics: within models and across models,[0],[0]
In particular: (1) Does this bias depend on the initial values of the parameters in our model?,6.3. Shape bias statistics: within models and across models,[0],[0]
(2) Does the size of the shape bias depend on model performance?,6.3. Shape bias statistics: within models and across models,[0],[0]
(3) When does shape bias emerge during training - before model convergence or afterwards?,6.3. Shape bias statistics: within models and across models,[0],[0]
"(4) How does shape bias compare between models, and within models?
To answer these questions, we extended the shape bias analysis described above to calculate the shape bias in a population of IB models and in a population of MN models with different random initialization (Figs. 2 and 5).
",6.3. Shape bias statistics: within models and across models,[0],[0]
(1) We first calculated the dependence of shape bias on the initialization of IB (Fig. 2).,6.3. Shape bias statistics: within models and across models,[0],[0]
"Surprisingly, we observed a strong variability, depending on the initialization.",6.3. Shape bias statistics: within models and across models,[0],[0]
"For the CogPsyc dataset, the average shape bias was Bs = 0.628 with standard deviation σBs = 0.049 at the end of training and for the real-world dataset the average shape bias was Bs = 0.958 with σBs = 0.037.
",6.3. Shape bias statistics: within models and across models,[0],[0]
"(2) Next, we calculated the dependence of shape bias on model performance.",6.3. Shape bias statistics: within models and across models,[0],[0]
"For the CogPsych dataset, the correlation between bias and classification accuracy was ρ = 0.15, with tn=15 = 0.55, pone tail = 0.29, and for the real-world dataset, the correlation was ρ = −0.06 with tn=15 = −0.22, pone tail = 0.42.",6.3. Shape bias statistics: within models and across models,[0],[0]
"Therefore, fluctuations
in the bias cannot be accounted for by fluctuations in classification accuracy.",6.3. Shape bias statistics: within models and across models,[0],[0]
"This is not surprising, because the classification accuracy of all models was similar at the end of training, while the shape bias was variable.",6.3. Shape bias statistics: within models and across models,[0],[0]
"This demonstrates that models can have variable behaviour along important dimensions (e.g., bias) while having the same performance measured by another (e.g., accuracy).
",6.3. Shape bias statistics: within models and across models,[0],[0]
(3) Next we explored the emergence of the shape bias during training (Fig.,6.3. Shape bias statistics: within models and across models,[0],[0]
"2a,c; Fig.",6.3. Shape bias statistics: within models and across models,[0],[0]
"5a,c).",6.3. Shape bias statistics: within models and across models,[0],[0]
"At the start of training, the average shape bias of these models was Bs = 0.448 with standard deviation σBs = 0.0835 on the CogPsyc dataset and Bs = 0.593 with σBs = 0.073 on the real-world dataset.",6.3. Shape bias statistics: within models and across models,[0],[0]
"We observe that a shape bias began to emerge very early during training, long before convergence.
",6.3. Shape bias statistics: within models and across models,[0],[0]
"(4) Finally, we compare shape bias within models during training, and between models at the end of training.",6.3. Shape bias statistics: within models and across models,[0],[0]
"During training, the shape bias within IB fluctuates signifi-
cantly (Fig. 2 b; Fig. 5b).",6.3. Shape bias statistics: within models and across models,[0],[0]
"In contrast, the shape bias does not fluctuate during training of the MN.",6.3. Shape bias statistics: within models and across models,[0],[0]
"Instead, the MN model inherits its shape bias characteristics at the start of training from the IB that provides it with input embeddings (Fig. 4) and this shape-bias remains constant throughout training.",6.3. Shape bias statistics: within models and across models,[0],[0]
"Moreover, there is no evidence that the MN and corresponding IB bias values are different from each other (paired t-test, p = 0.167).",6.3. Shape bias statistics: within models and across models,[0],[0]
Note that we do not fine-tune the Inception model providing input while training the MN.,6.3. Shape bias statistics: within models and across models,[0],[0]
We do this so that we can observe the shape-bias properties of the MN independent of the IB model properties.,6.3. Shape bias statistics: within models and across models,[0],[0]
Our psychology-inspired approach to understanding DNNs produced a number of insights.,7.1. A shape bias case study,[0],[0]
"Firstly, we found that both IB and MNs trained on ImageNet display a strong shape bias.",7.1. A shape bias case study,[0],[0]
This is an important result for practitioners who routinely use these models - especially for applications where it is known a priori that colour is more important than shape.,7.1. A shape bias case study,[0],[0]
"As an illustrative example, if a practitioner planned to build a one-shot fruit classification system, they should proceed with caution if they plan to use pre-trained ImageNet models like Inception and MNs because fruit are often defined according to colour features rather than shape.",7.1. A shape bias case study,[0],[0]
"In applications where a shape bias is desirable (as is more often the case than not), this result provides reassurance that the models are behaving sensibly in the presence of ambiguity.
",7.1. A shape bias case study,[0],[0]
"The second surprising finding was the large variability in shape bias, both within models during training and across models, depending on the randomly chosen initialisation of our model.",7.1. A shape bias case study,[0],[0]
This variability can arise because our models are not being explicitly optimised for shape biased categorisation.,7.1. A shape bias case study,[0],[0]
"This is an important result because it shows that not all models are created equally - some models will have a stronger preference for shape than others, even though they are architecturally identical and have almost identical classification accuracy.
",7.1. A shape bias case study,[0],[0]
Our third finding – that MNs retain the shape bias statistics of the downstream Inception network – demonstrates the possibility for biases to propagate across model components.,7.1. A shape bias case study,[0],[0]
"In this case, the shape bias propagates from the Inception model through to the MN memory modules.",7.1. A shape bias case study,[0],[0]
"This result is yet another cautionary observation; when combin-
ing multiple modules together, we must be aware of contamination by unknown properties across modules.",7.1. A shape bias case study,[0],[0]
"Indeed, a bias that is benign in one module might only have a detrimental effect when combined later with other modules.
",7.1. A shape bias case study,[0],[0]
A natural question immediately arises from these results - how can we remove an unwanted bias or induce a desirable bias?,7.1. A shape bias case study,[0],[0]
The biases under consideration are properties of an architecture and dataset synthesized together by an optimization procedure.,7.1. A shape bias case study,[0],[0]
"As such, the observation of a shapebias is partly a result of the statistics of natural imagelabellings as captured in the ImageNet dataset, and partly a result of the architecture attempting to extract these statistics.",7.1. A shape bias case study,[0],[0]
"Therefore, on discovering an unwanted bias, a practitioner can either attempt to change the model architecture to explicitly prevent the bias from emerging, or, they can attempt to manipulate the training data.",7.1. A shape bias case study,[0],[0]
"If neither of these are possible - for example, if the appropriate data manipulation is too expensive, or, if the bias cannot be easily suppressed in the architecture, it may be possible to do zero-th order optimization of the models.",7.1. A shape bias case study,[0],[0]
"For example, one may perform post-hoc model selection either using early stopping or by selecting a suitable model from the set of initial seeds.
",7.1. A shape bias case study,[0],[0]
An important caveat to note is that behavioral tools often do not provide insight into the neural mechanisms.,7.1. A shape bias case study,[0],[0]
"In our case, the DNN mechanism whereby model parameters and input images interact to give rise to a shape bias have not been elucidated, nor did we expect this to happen.",7.1. A shape bias case study,[0],[0]
"Indeed, just as cognitive psychology often does for neuroscience, our new computational level insights can provide a starting point for research at the mechanistic level.",7.1. A shape bias case study,[0],[0]
"For example, in future work it would be interesting to use gradient-based visualization or neuron ablation techniques to augment the current results by identifying the mechanisms underlying the shape bias.",7.1. A shape bias case study,[0],[0]
"The convergence of evidence from such
introspective methods with the current behavioral method would create a richer account of these models’ solutions to the one-shot word learning problem.",7.1. A shape bias case study,[0],[0]
"There have been previous attempts to model human word learning in the cognitive science literature (Colunga & Smith, 2005; Xu & Tenenbaum, 2007; Schilling et al., 2012; Mayor & Plunkett, 2010).",7.2. Modelling human word learning,[0],[0]
"However, none of these models are capable of one-shot word learning on the scale of real-world images.",7.2. Modelling human word learning,[0],[0]
"Because MNs both solve the task at scale and emulate hallmark experimental findings, we propose MNs as a computational-level account of human one-shot word learning.",7.2. Modelling human word learning,[0],[0]
"Another feature of our results supports this contention: in our model the shape bias increases dramatically early in training (Fig. 2a); similarly, humans show the shape bias much more strongly as adults than as children, and older children show the bias more strongly than younger children (Landau et al., 1988).
",7.2. Modelling human word learning,[0],[0]
"As a good cognitive model should, our DNNs make testable predictions about word-learning in humans.",7.2. Modelling human word learning,[0],[0]
"Specifically, the current results predict that the shape bias should vary across subjects as well as within a subject over the course of development.",7.2. Modelling human word learning,[0],[0]
"They also predict that for humans with adult-level one-shot word learning abilities, there should be no correlation between shape bias magnitude and oneshot-word learning capability.
",7.2. Modelling human word learning,[0],[0]
Another promising direction for future cognitive research would be to probe MNs for additional biases in order to predict novel computational properties in humans.,7.2. Modelling human word learning,[0],[0]
"Probing a model in this way is much faster than running human behavioural experiments, so a wider range of hypotheses for human word learning may be rapidly tested.",7.2. Modelling human word learning,[0],[0]
"Through the one-shot learning case study, we demonstrated the utility of leveraging techniques from cognitive psychology for understanding the computational properties of DNNs.",7.3. Cognitive Psychology for Deep Neural Networks,[0],[0]
There is a wide ranging literature in cognitive psychology describing techniques for probing a spectrum of behaviours in humans.,7.3. Cognitive Psychology for Deep Neural Networks,[0],[0]
"Our work here leads the way to the study of artificial cognitive psychology - the application of these techniques to better understand DNNs.
",7.3. Cognitive Psychology for Deep Neural Networks,[0],[0]
"For example, it would be useful to apply work from the massive literature on episodic memory (Tulving, 1985) to the recent flurry of episodic memory architectures (Blundell et al., 2016; Graves et al., 2016), and to apply techniques from the semantic cognition literature (Lamberts & Shanks, 2013) to recent models of concept formation (Higgins et al., 2016; Gregor et al., 2016; Raposo et al., 2017).",7.3. Cognitive Psychology for Deep Neural Networks,[0],[0]
"More generally, the rich psychological literature will be-
come increasingly useful for understanding deep reinforcement learning agents as they learn to solve increasingly complex tasks.",7.3. Cognitive Psychology for Deep Neural Networks,[0],[0]
"In this work, we have demonstrated how techniques from cognitive psychology can be leveraged to help us better understand DNNs.",8. Conclusion,[0],[0]
"As a case study, we measured the shape bias in two powerful yet poorly understood DNNs - Inception and MNs.",8. Conclusion,[0],[0]
Our analysis revealed previously unknown properties of these models.,8. Conclusion,[0],[0]
"More generally, our work leads the way for future exploration of DNNs using the rich body of techniques developed in cognitive psychology.",8. Conclusion,[0],[0]
"We would like to thank Linda Smith and Charlotte Wozniak for providing the Cognitive Psychology probe dataset; Charles Blundell for reviewing our paper prior to submission; Oriol Vinyals, Daan Wierstra, Peter Dayan, Daniel Zoran, Ian Osband and Karen Simonyan for helpful discussions; James Besley for legal assistance; and the DeepMind team for support.",Acknowledgements,[0],[0]
"Deep neural networks (DNNs) have advanced performance on a wide range of complex tasks, rapidly outpacing our understanding of the nature of their solutions.",abstractText,[0],[0]
"While past work sought to advance our understanding of these models, none has made use of the rich history of problem descriptions, theories, and experimental methods developed by cognitive psychologists to study the human mind.",abstractText,[0],[0]
"To explore the potential value of these tools, we chose a well-established analysis from developmental psychology that explains how children learn word labels for objects, and applied that analysis to DNNs.",abstractText,[0],[0]
"Using datasets of stimuli inspired by the original cognitive psychology experiments, we find that state-of-the-art one shot learning models trained on ImageNet exhibit a similar bias to that observed in humans: they prefer to categorize objects according to shape rather than color.",abstractText,[0],[0]
"The magnitude of this shape bias varies greatly among architecturally identical, but differently seeded models, and even fluctuates within seeds throughout training, despite nearly equivalent classification performance.",abstractText,[0],[0]
"These results demonstrate the capability of tools from cognitive psychology for exposing hidden computational properties of DNNs, while concurrently providing us with a computational model for human word learning.",abstractText,[0],[0]
Cognitive Psychology for Deep Neural Networks:  A Shape Bias Case Study ,title,[0],[0]
Producing forecasts that support decision-making in a hierarchical structure is a central problem for many organizations.,1. Introduction,[0],[0]
"For example, retail sales forecasts typically form a hierarchy, with the inventory control system of a retail outlet relying on forecasts for store-level demand, while forecasts of regionally aggregated demand are needed for managing inventory at a distribution centre (Kremer et al., 2016).",1. Introduction,[0],[0]
"Another context where a hierarchy naturally arises is electricity demand, where the bottom level might consist of time series of the electricity consumption of individual customers, while the top level could be the total load on the grid.",1. Introduction,[0],[0]
"Forecasts of electricity consumption are needed at
1Monash University, Melbourne, Australia 2University of Oxford, Oxford, UK.",1. Introduction,[0],[0]
"Correspondence to: Souhaib Ben Taieb <souhaib.bentaieb@monash.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"various levels of aggregation in order to operate the power grid efficiently and securely (van Erven & Cugliari, 2015).
",1. Introduction,[0],[0]
Producing accurate forecasts for these hierarchical structures is particularly challenging.,1. Introduction,[0],[0]
"First, the many time series involved can interact in varying and complex ways.",1. Introduction,[0],[0]
"In particular, time series at different levels of the hierarchy can contain very different patterns (see, for example, Figure 3); time series at the bottom level are typically very noisy sometimes exhibiting intermittency, while aggregated series at higher levels are much smoother.",1. Introduction,[0],[0]
"As a result, a naive bottom-up approach whereby forecasts of aggregates are generated by summing the forecasts of the corresponding series in the lower levels is unlikely to deliver accurate results when the aggregation involves a large number of series (Hyndman et al., 2011).",1. Introduction,[0],[0]
"Second, in order to ensure coherent decision-making at the different levels of a hierarchy, it is essential that the forecast of each aggregated series should equal the sum of the forecasts of the corresponding disaggregated series.",1. Introduction,[0],[0]
"Unfortunately, independently forecasting each time series within each level is very unlikely to deliver coherent forecasts.",1. Introduction,[1.0],"['Unfortunately, independently forecasting each time series within each level is very unlikely to deliver coherent forecasts.']"
"Finally, the bottom level can consist of several thousand or even millions of time series, which can induce a massive computational load.
",1. Introduction,[0],[0]
"Recent work in this area (Wickramasuriya et al., 2015; van Erven & Cugliari, 2015) has focused on a two-stage approach in which base forecasts are first produced independently for each series in the hierarchy; these are then combined to generate coherent revised forecasts (see Section 2).",1. Introduction,[1.0],"['Recent work in this area (Wickramasuriya et al., 2015; van Erven & Cugliari, 2015) has focused on a two-stage approach in which base forecasts are first produced independently for each series in the hierarchy; these are then combined to generate coherent revised forecasts (see Section 2).']"
"The rationale behind this approach is both to improve forecast accuracy due to the synthesis of information from different forecasts, as well as to produce coherent forecasts.",1. Introduction,[0],[0]
A fundamental limitation of actual research is that it has looked only at the problem of forecasting the mean of each time series.,1. Introduction,[0],[0]
"This contrasts with the shift in the forecasting literature over the past two decades towards probabilistic forecasting (Gneiting & Katzfuss, 2014).",1. Introduction,[1.0],"['This contrasts with the shift in the forecasting literature over the past two decades towards probabilistic forecasting (Gneiting & Katzfuss, 2014).']"
"This form of prediction quantifies the uncertainty, which enables improved decision making and risk management (see, for example, Berrocal et al. (2010)).
",1. Introduction,[0],[0]
We address the key problem of generating probabilistic forecasts for large-scale hierarchical time series.,1. Introduction,[0],[0]
"This is particularly challenging since it is requires the estimation of the entire distribution of future observations, not only the mean (Kneib, 2013; Hothorn et al., 2014).",1. Introduction,[0],[0]
"Furthermore,
because of the hierarchical structure, this problem also involves computing the distribution of hierarchical sums of random variables in high dimensions.",1. Introduction,[0],[0]
"Finally, another challenge is the possible variety of distributions in the hierarchy.",1. Introduction,[0],[0]
"In fact, although the distributions become more normally distributed with the aggregation level as a consequence of the central limit theorem, the series at lower levels often exhibit non-normality including multi-modality and high levels of skewness.
",1. Introduction,[0],[0]
We propose an algorithm that computes predictive distributions under the form of random samples for each series in the hierarchy.,1. Introduction,[0],[0]
"First, probabilistic forecasts are independently computed for all series in the hierarchy, and samples are computed from the associated predictive distributions.",1. Introduction,[0],[0]
"Then, a sequence of permutations extracted from estimated copulas are applied to the multivariate samples in a hierarchical manner to restore the dependencies between the variables before computing the sums (see Section 3).",1. Introduction,[0],[0]
"Finally, the algorithm computes sparse forecast combinations for all series in the hierarchy, where the combination weights are estimated by solving a possibly highdimensional LASSO problem (see Section 3.2).",1. Introduction,[1.0],"['Finally, the algorithm computes sparse forecast combinations for all series in the hierarchy, where the combination weights are estimated by solving a possibly highdimensional LASSO problem (see Section 3.2).']"
"The result is a set of coherent probabilistic forecasts for each series in the hierarchy.
",1. Introduction,[0],[0]
"Our algorithm has multiple advantages compared to the state-of-the art hierarchical forecasting methods: (1) it quantifies the uncertainty in the predictions for the entire hierarchy while satisfying the aggregation constraints; (2) it is scalable to high-dimensional hierarchies since the problem is decomposed into multiple lower-dimensional subproblems; and (3) it synthesizes information from different levels in the hierarchy to estimate the marginal distributions and the dependence structures through the mean forecast combination and the hierarchical aggregation, respectively.
",1. Introduction,[0],[0]
We evaluate our algorithm using both simulated data sets (see Section 4.2) and a large scale electricity smart meter data set (see Section 4.3).,1. Introduction,[0],[0]
A hierarchical time series is a multivariate time series with a hierarchical structure.,2. Mean Hierarchical Forecasting,[0],[0]
Figure 1 gives an example with five bottom series and three aggregate series.,2. Mean Hierarchical Forecasting,[0],[0]
"The different observations in the hierarchy satisfy the following aggregation constraints: yt = yA,t + yB,t, yA,t = yAA,t + yAB,t+yAC,t and yB,t = yBA,t+yBB,t for all time periods t = 1, . . .",2. Mean Hierarchical Forecasting,[0],[0]
", T .
",2. Mean Hierarchical Forecasting,[0],[0]
"Let at be an r-vector containing the observations at the different levels of aggregation at time t, bt be an m-vector with the observations at the bottom level only, and yt = (at bt)
′",2. Mean Hierarchical Forecasting,[0],[0]
be an n-vector that contains the observations of all series in the hierarchy with n,2. Mean Hierarchical Forecasting,[0],[0]
= r + m.,2. Mean Hierarchical Forecasting,[0],[0]
"For the ex-
ample in Figure 1, we have at = (yt, yA,t, yB,t)′, bt = (yAA,t, yAB,t, . . .",2. Mean Hierarchical Forecasting,[0],[0]
", yBB,t)
′, r = 3, and m = 5.",2. Mean Hierarchical Forecasting,[0],[0]
"We can then write yt = Sbt, where S = [ S′a Im ]′ ∈ {0, 1}n×m is the summing matrix, Sa ∈ {0, 1}r×m",2. Mean Hierarchical Forecasting,[0],[0]
"and Im is an identity matrix of order m.
Suppose we have access to T historical observations, y1, . . .",2. Mean Hierarchical Forecasting,[0],[0]
",yT , of a hierarchical time series.",2. Mean Hierarchical Forecasting,[0],[0]
"Under mean squared error (MSE) loss, the optimal h-period-ahead forecasts are given by the conditional mean (Gneiting, 2011), i.e.
E[yT+h|y1, . . .",2. Mean Hierarchical Forecasting,[0.9932898710090055],"['Under mean squared error (MSE) loss, the optimal h-period-ahead forecasts are given by the conditional mean (Gneiting, 2011), i.e. E[yT+h|y1, .']"
",yT ]",2. Mean Hierarchical Forecasting,[0],[0]
"= S E[bT+h|y1, . . .",2. Mean Hierarchical Forecasting,[0],[0]
",yT ], (1)
where h = 1, 2, . . .",2. Mean Hierarchical Forecasting,[0],[0]
",H .
",2. Mean Hierarchical Forecasting,[0],[0]
"It is possible to compute forecasts for all series at all levels independently, which we call base forecasts.",2. Mean Hierarchical Forecasting,[0],[0]
"For example, we can estimate E[yi,T+h|yi,1, . . .",2. Mean Hierarchical Forecasting,[0],[0]
", yi,T ] for i = 1, . . .",2. Mean Hierarchical Forecasting,[0],[0]
", n, i.e. for all series in the hierarchy.",2. Mean Hierarchical Forecasting,[0],[0]
This approach is very flexible since we can use different forecasting methods for each series and aggregation level.,2. Mean Hierarchical Forecasting,[1.0],['This approach is very flexible since we can use different forecasting methods for each series and aggregation level.']
"However, the aggregation constraints will not necessarily be satisfied.
",2. Mean Hierarchical Forecasting,[0],[0]
Definition 1.,2. Mean Hierarchical Forecasting,[0],[0]
"The coherency errors of the h-period-ahead base forecasts ŷT+h = (âT+h b̂T+h)′ are given by r̂T+h = âT+h − Sab̂T+h.
",2. Mean Hierarchical Forecasting,[0.9999999568739065],['The coherency errors of the h-period-ahead base forecasts ŷT+h = (âT+h b̂T+h)′ are given by r̂T+h = âT+h − Sab̂T+h.']
"In other words, r̂T+h is a vector containing the magnitude of constraint violations for each aggregate series.
",2. Mean Hierarchical Forecasting,[0],[0]
Definition 2.,2. Mean Hierarchical Forecasting,[0],[0]
"The h-period-ahead base forecasts ŷT+h = (âT+h b̂T+h)
′",2. Mean Hierarchical Forecasting,[0],[0]
"are (mean) coherent if r̂T+h = 0, i.e. if there are no coherency errors.
",2. Mean Hierarchical Forecasting,[0],[0]
"Since the optimal mean forecasts in (1) are coherent by definition, it seems sensible to impose the aggregation constraints when generating hierarchical mean forecasts.",2. Mean Hierarchical Forecasting,[0],[0]
"Also, from a decision-making perspective, coherent forecasts will guarantee coherent decisions over the entire hierarchy.",2. Mean Hierarchical Forecasting,[0],[0]
"Hyndman et al. (2011) proposed coherent hierarchical mean forecasts of the following form:
ỹT+h = SP ŷT+h, (2)
for some appropriately chosen matrix P ∈",2.1. Best Linear Unbiased Mean Revised Forecasts,[0],[0]
"Rm×n, and where ŷT+h are some base forecasts.
",2.1. Best Linear Unbiased Mean Revised Forecasts,[0],[0]
"This approach has multiple advantages: (1) the forecasts are coherent by construction; (2) the forecasts are generated by combining forecasts from all levels; and (3) multiple hierarchical forecasting methods can be represented as particular cases, including bottom-up forecasts with P =",2.1. Best Linear Unbiased Mean Revised Forecasts,[0],[0]
"[ 0m×r|1m×m ] , and top-down forecasts with P =[
pm×1|0m×(n−1) ]
where p is a vector of proportions that sum to one.",2.1. Best Linear Unbiased Mean Revised Forecasts,[0],[0]
Theorem 1.,2.1. Best Linear Unbiased Mean Revised Forecasts,[0],[0]
"(Adapted from Wickramasuriya et al., 2015)",2.1. Best Linear Unbiased Mean Revised Forecasts,[0],[0]
"LetWh be the positive definite covariance matrix of the hperiod-ahead base forecast errors, êT+h = yT+h− ŷT+h, i.e.Wh = E[êT+hê′T+h].
",2.1. Best Linear Unbiased Mean Revised Forecasts,[0],[0]
"Then, assuming unbiased base forecasts, the best (i.e. having minimum sum of variances) linear unbiased revised forecasts are given by (2) with P = (S′W−1h S) −1S′W−1h .",2.1. Best Linear Unbiased Mean Revised Forecasts,[0],[0]
"We will denote this method MinT.
In practice, the error covariance matrixWh needs to be estimated using historical observations of the base forecast errors.",2.1. Best Linear Unbiased Mean Revised Forecasts,[0],[0]
"Wickramasuriya et al. (2015) estimated W1, and assumed that Wh ∝ W1, since the estimation of Wh is challenging for h > 1.",2.1. Best Linear Unbiased Mean Revised Forecasts,[0],[0]
"To trade off bias and estimation variance, structural assumptions on the entries of the sample covariance matrix have also been considered in Hyndman et al. (2016).",2.1. Best Linear Unbiased Mean Revised Forecasts,[0],[0]
The approach presented in the previous section applies both combination and reconciliation of the forecasts at the same time.,2.2. Optimal Mean Combination and Reconciliation,[0],[0]
"van Erven & Cugliari (2015) proposed splitting the problem into two independent steps: “first one comes up with the best possible forecasts for the time series without worrying about aggregate consistency; and then a reconciliation procedure is used to make the forecasts aggregate consistent”.
",2.2. Optimal Mean Combination and Reconciliation,[0],[0]
"Given some possibly incoherent base forecasts ŷT+h, and a weight matrixA ∈ Rn×n, they proposed a method called GTOP, which solves the following quadratic optimization problem:
minimize xa∈Rr,xb∈Rm",2.2. Optimal Mean Combination and Reconciliation,[0],[0]
∥∥∥∥AŷT+h −A(xaxb ),2.2. Optimal Mean Combination and Reconciliation,[0],[0]
"∥∥∥∥2 (3)
subject to (xa xb)′ ∈",2.2. Optimal Mean Combination and Reconciliation,[0],[0]
"A ∩ B,
where A = {(xa xb)′ : xa = Saxb} is the set of coherent vectors, and B is an additional set that allows the specification of additional constraints.
",2.2. Optimal Mean Combination and Reconciliation,[0],[0]
"The solution of the previous problem is also equivalent to an optimal strategy in a minimax problem where the goal is to minimize the maximum error between the loss of the
reconciled and the base forecasts.",2.2. Optimal Mean Combination and Reconciliation,[0],[0]
WhenA,2.2. Optimal Mean Combination and Reconciliation,[0],[0]
"= I and B = ∅, the problem reduces to finding the closest reconciled forecasts to the base forecasts in terms of sum of squared errors (SSE).
",2.2. Optimal Mean Combination and Reconciliation,[1.0000000183274158],"['WhenA = I and B = ∅, the problem reduces to finding the closest reconciled forecasts to the base forecasts in terms of sum of squared errors (SSE).']"
A distinctive advantage of the GTOP approach compared to MinT is the guarantee of producing revised forecasts ỹT+h,2.2. Optimal Mean Combination and Reconciliation,[0],[0]
=,2.2. Optimal Mean Combination and Reconciliation,[0],[0]
(x ∗ a x ∗ b) ′,2.2. Optimal Mean Combination and Reconciliation,[0],[0]
with the same or smaller SSE than the base forecasts ŷT+h.,2.2. Optimal Mean Combination and Reconciliation,[0],[0]
"Furthermore, compared to MinT, the base forecasts are not required to be unbiased.",2.2. Optimal Mean Combination and Reconciliation,[0],[0]
"Also, by separating forecast combination and reconciliation, the GTOP approach allows the inclusion of regularization in the forecast combination step.",2.2. Optimal Mean Combination and Reconciliation,[0],[0]
One comparative weakness of GTOP is that it does not have a closed-form solution in the general case.,2.2. Optimal Mean Combination and Reconciliation,[0],[0]
"There has been a shift in the forecasting literature, over the past two decades, towards probabilistic forecasting (Gneiting & Katzfuss, 2014).",3. Probabilistic Hierarchical Forecasting,[0],[0]
"This form of prediction quantifies the uncertainty, which enables improved decision making and risk management.",3. Probabilistic Hierarchical Forecasting,[0],[0]
"GTOP does not provide any quantification of the uncertainty in the predictions, and, although MinT allows the calculation of the forecast variances, this might not be enough to fully describe the uncertainty in the predictions.
",3. Probabilistic Hierarchical Forecasting,[0],[0]
"We propose an algorithm to compute, for all series in the hierarchy, the conditional predictive cumulative distribution function:
Fi,T+h(y|y1, . . .",3. Probabilistic Hierarchical Forecasting,[0],[0]
",yT )",3. Probabilistic Hierarchical Forecasting,[0],[0]
"= P(yi,T+h ≤ y|y1, . .",3. Probabilistic Hierarchical Forecasting,[0],[0]
.,3. Probabilistic Hierarchical Forecasting,[0],[0]
",yT ),
rather than just the conditional mean E[yi,T+h|y1, . . .",3. Probabilistic Hierarchical Forecasting,[0],[0]
",yT ] and conditional variance V[yi,T+h|y1, . . .",3. Probabilistic Hierarchical Forecasting,[0],[0]
",yT ], with i = 1, . . .",3. Probabilistic Hierarchical Forecasting,[0],[0]
", n.
As with mean forecasts, it is possible to independently compute probabilistic forecasts for each series in the hierarchy, but, again, these forecasts will not necessarily be coherent.",3. Probabilistic Hierarchical Forecasting,[0],[0]
"In fact, hierarchical probabilistic forecasts are coherent if the predictive distribution of each aggregate series is equal to the distribution of the sum of the children series.",3. Probabilistic Hierarchical Forecasting,[1.0],"['In fact, hierarchical probabilistic forecasts are coherent if the predictive distribution of each aggregate series is equal to the distribution of the sum of the children series.']"
"Naturally, probabilistic coherency implies mean coherency as given in Definition 2.",3. Probabilistic Hierarchical Forecasting,[0],[0]
"With mean forecasts, it was possible to compute coherent bottom-up forecasts for the ith aggregated series by simply summing the associated lowest level mean forecasts, i.e. ỹit = sib̂t where si is the ith row of the S matrix, and i = 1, . . .",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
", r. Now, given some base probabilistic forecasts for all the bottom series, how do we compute the bottom-up coherent probabilistic forecasts for all aggregated series?
",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"Since each aggregate series is the sum of a subset of bottom series, bottom-up probabilistic forecasting is harder to compute than mean forecasting because we need to compute the joint distribution of the component random variables.",3.1. Bottom-Up Probabilistic Forecasting,[1.0],"['Since each aggregate series is the sum of a subset of bottom series, bottom-up probabilistic forecasting is harder to compute than mean forecasting because we need to compute the joint distribution of the component random variables.']"
"The marginal predictive distributions are not enough.
",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
Definition 3.,3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"Let X1, . . .",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
", Xd be a set of continuous random variables with joint distribution function F .",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"Then, the distribution of Z = ∑d i=1Xi is given by
FX1+···+Xd(z) = ∫",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"Rd
1{x1+· · ·+xd ≤ z} dF",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"(x1, . . .",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
", xd).",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"(4)
To model the joint distribution, we can use the copula framework (Nelsen, 2007).",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"Copulas originate from Sklar’s theorem (Sklar, 1959), which states that for any continuous distribution function F with marginals F1, . . .",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
", Fd, there exists a unique function C :",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"[0, 1]d → [0, 1] such that F can be written as F (x1, . . .",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
", xn) = C(F1(x1), . . .",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
", Fd(xd)).",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"In other words, starting from marginal predictive distributions for each series, and using a copula for the dependence structure, we can first compute the joint distribution, and then compute the distribution of the sum using (4).
",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"Although it is convenient to decompose the estimation of the joint distribution into the estimation of multiple marginal predictive distributions and one copula, the number of bottom series can be large in practice, which implies a high-dimensional copula.",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"Furthermore, in highly disaggregated time series data, the bottom series are often very noisy, and as a result, the estimation of the dependence structure between all bottom series will be very challenging.
",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"Since we are only interested in specific aggregations, we can avoid explicitly modelling the (often) high-dimensional copula that describes the dependence between all bottom series.",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"Building on the approach proposed by Arbenz et al. (2012), we propose to decompose the possibly highdimensional copula into multiple lower-dimensional copulas for all child series of each aggregate series.
",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
Example 3.1.,3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
Let us consider the hierarchy given in Figure 1.,3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"A classical bottom-up approach would require modelling the joint distribution of (yAA,t, yAB,t, yAC,t, yBA,t, yBB,t).",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"Then, the distribution of all aggregate series yA,t, yB,t and yt can be computed using (4).
",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"However, since the marginals and the copula completely specify the joint distribution, the following procedure allows us to compute the marginal predictive distributions of all aggregates using three lower-dimensional copulas in a hierarchal manner:
1.",3.1. Bottom-Up Probabilistic Forecasting,[1.0000000041551191],"['However, since the marginals and the copula completely specify the joint distribution, the following procedure allows us to compute the marginal predictive distributions of all aggregates using three lower-dimensional copulas in a hierarchal manner: 1.']"
"Compute FAA,t, FAB,t, FAC,t, FBA,t, and FBB,t.
2.",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"Compute FA,t using C1(FAA,t, FAB,t, FAC,t).",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
3.,3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"Compute FB,t using C2(FBA,t, FBB,t).",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
4.,3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"Compute Ft using C3(FA,t, FB,t).
",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"Except in some special cases where the distribution of the sum can be computed analytically, we would typically resort to Monte Carlo simulations.
",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"By Sklar’s theorem, we can write F (x1, . . .",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
", xd) = P(X1 ≤",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"x1, . .",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
.,3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
", Xd ≤ xd) = C(F1(x1), . . .",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
", Fd(xd)).",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"Suppose we have samples xik ∼ Fi, and uk = (u1k, . . .",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
", u d k) ∼ C, k = 1, . . .",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
",K, then we can compute
F̂ (x1, . . .",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
", xd) = Ĉ(F̂1(x1), . . .",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
", F̂d(xd)),
where F̂i are the empirical margins and Ĉ is the empirical copula (see Rüschendorf, 2009, and the references therein), given respectively by
F̂i(x) = 1
K K∑",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
k=1 1{xik ≤,3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"x}, x ∈ R,
and
Ĉ(u) = 1
K K∑",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"k=1 1 { rk(u1k) K ≤ u1, . .",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
.,3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
", rk(udk) K ≤",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"ud } ,
for u = (u1, . . .",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
", ud) ∈",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"[0, 1]d, where rk(uik) is the rank of uik within the set {ui1, . . .",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
", uiK}.
",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
The procedure of applying empirical copulas to empirical margins can be efficiently represented in terms of sample reordering.,3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"In fact, the order statistics ui(1), . . .",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
", u i (K) of the samples ui1, . . .",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
", u i K induce a permutation pi of the integers {1, . . .",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
",K}, defined by pi(k) = rk(uik) for k = 1, . . .",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
",K. If we then apply the permutations to each independent marginal sample {xi1, . . .",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
", xiK}, the reordered samples inherit the multivariate rank dependence structure from the copula Ĉ.",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"We can then compute the samples for the sum {x1, . . .",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
", xK} where xk = ∑d i=1",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
x,3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"i k.
Introducing a dependence structure into originally independent marginal samples goes back to Iman & Conover (1982) who considered the special case of normal copulas.",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"A similar idea has been considered more recently in Schefzik et al. (2013) to specify multivariate dependence structure with applications to weather forecasting.
",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"Since we are interested in multivariate forecasting, we will need another version of Sklar’s theorem for conditional joint distributions proposed by Patton (2006):
If yt|Ft−1 ∼ F (·|Ft−1), with yit|Ft−1 ∼ Fi(·|Ft−1), i = 1, . . .",3.1. Bottom-Up Probabilistic Forecasting,[0.9952011383155056],"['Since we are interested in multivariate forecasting, we will need another version of Sklar’s theorem for conditional joint distributions proposed by Patton (2006): If yt|Ft−1 ∼ F (·|Ft−1), with yit|Ft−1 ∼ Fi(·|Ft−1), i = 1, .']"
", n, then
F (y|Ft−1) = C(F1(y1|Ft−1), . . .",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
", Fn(yn|Ft−1)|Ft−1).
",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"As in Patton (2012), we will assume the following structure for our series:
yit = µi(yt−1,yt−2, . . . )",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
+,3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"σi(yt−1,yt−2, . . . )",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"εit, (5)
where εit|yt−1,yt−2, · · · ∼ Fi(0, 1).",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"In other words, each series can have a potentially time-varying conditional mean and variance, but the standardized residual, εit, has a constant conditional distribution for simplicity.",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"See Fan & Patton (2014) for a review on copulas in econometrics.
",3.1. Bottom-Up Probabilistic Forecasting,[0.9999999781045621],['See Fan & Patton (2014) for a review on copulas in econometrics.']
The following algorithm describes how to compute the bottom-up samples using the reordering procedure for a complete hierarchy: Algorithm 1.,3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"(Bottom-up Probabilistic Forecasting)
1.",3.1. Bottom-Up Probabilistic Forecasting,[0.9999999847674681],['(Bottom-up Probabilistic Forecasting) 1.']
"For all series in the hierarchy, as defined in (5), model the conditional marginal distributions; i.e. compute µ̂i and σ̂i for i = 1, . . .",3.1. Bottom-Up Probabilistic Forecasting,[0.994904464925998],"['For all series in the hierarchy, as defined in (5), model the conditional marginal distributions; i.e. compute µ̂i and σ̂i for i = 1, .']"
", n. 2.",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"Then, compute the standardized residuals ε̂it = (yi,t− µ̂i,t)/σ̂i,t, and define the permutations pi(t) = rk(ε̂it), where i = 1, . . .",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
", n and t = 1, . . .",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
", T .",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
3.,3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"For all bottom series i = r + 1, . . .",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
", n: (a) Compute h-period ahead conditional marginal
predictive distributions F̂i,T+h.",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"(b) Extract a discrete sample of size K = T , say
xi1, . . .",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
", x i K , where x i k = F̂ −1",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"i,T+h(k/K + 1), and
k = 1, . . .",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
",K. 4.",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"For all aggregate series i = 1, . . .",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
", r:
(a) Let i(1), . . .",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
", i(nc) be the nc children series of the aggregate series i. (b) Recursively compute
xik = x i(1) (pi(1)(k))",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
+ · · ·+ xi(nc)(pi(nc)(k)),3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
",
where xi(k) denotes the kth order statistics of {xi1, . . .",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
", xiK}, i.e. xi(1) ≤",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
x i (2) ≤ · · · ≤ x,3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"i (K).
",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"Similarly to the classical bottom-up algorithm, Algorithm 1 produces coherent samples by construction.",3.1. Bottom-Up Probabilistic Forecasting,[0],[0]
"Furthermore, the samples of each aggregate are computed using only the predictive distributions of the bottom series.",3.1. Bottom-Up Probabilistic Forecasting,[1.0],"['Furthermore, the samples of each aggregate are computed using only the predictive distributions of the bottom series.']"
"However, Algorithm 1 has two main advantages compared to a classical bottom-up algorithm: (1) instead of estimating a highdimensional copula for the dependence between all the bottom series, we only need to specify the joint dependence between the child series of each aggregate series, and (2) since each copula is estimated at different aggregate levels, we can benefit from better estimation since the series are smoother, and easier to model and forecast.",3.1. Bottom-Up Probabilistic Forecasting,[1.0],"['However, Algorithm 1 has two main advantages compared to a classical bottom-up algorithm: (1) instead of estimating a highdimensional copula for the dependence between all the bottom series, we only need to specify the joint dependence between the child series of each aggregate series, and (2) since each copula is estimated at different aggregate levels, we can benefit from better estimation since the series are smoother, and easier to model and forecast.']"
Algorithm 1 computes bottom-up probabilistic forecasts by estimating the copula dependence functions using data from different levels of the hierarchy.,3.2. Mean Forecast Combination and Reconciliation,[0],[0]
"However, the resulting mean forecasts are equal to classical bottom-up forecasts, i.e. no data from other levels is used.",3.2. Mean Forecast Combination and Reconciliation,[0],[0]
"In order to
further improve the accuracy of our probabilistic forecasts, we add a mean forecast combination step, which allows to exploit possibly better mean forecasts from higher levels.",3.2. Mean Forecast Combination and Reconciliation,[1.0000000467204135],"['In order to further improve the accuracy of our probabilistic forecasts, we add a mean forecast combination step, which allows to exploit possibly better mean forecasts from higher levels.']"
"Forecast combination is known to improve forecasts in many cases (Timmermann, 2006; Genre et al., 2013).",3.2. Mean Forecast Combination and Reconciliation,[1.0],"['Forecast combination is known to improve forecasts in many cases (Timmermann, 2006; Genre et al., 2013).']"
We could adjust the means of our predictive distributions using the MinT revised forecasts.,3.2. Mean Forecast Combination and Reconciliation,[1.0],['We could adjust the means of our predictive distributions using the MinT revised forecasts.']
"However, as van Erven & Cugliari (2015), we propose to first combine the mean forecasts, and then apply a reconciliation step.
Let ŷT+h be the means of our predictive distributions.",3.2. Mean Forecast Combination and Reconciliation,[0],[0]
"We compute the following forecast combination:
y̆t = Qŷt, (6)
whereQ =",3.2. Mean Forecast Combination and Reconciliation,[0],[0]
"[ q1, . . .",3.2. Mean Forecast Combination and Reconciliation,[0],[0]
", qn ]′",3.2. Mean Forecast Combination and Reconciliation,[0],[0]
∈ Rn×n is a weight matrix.,3.2. Mean Forecast Combination and Reconciliation,[0],[0]
"Since the combined mean forecasts y̆t are not necessarily coherent, we also apply a reconciliation step using the GTOP approach described in Section 2.2.",3.2. Mean Forecast Combination and Reconciliation,[1.0],"['Since the combined mean forecasts y̆t are not necessarily coherent, we also apply a reconciliation step using the GTOP approach described in Section 2.2.']"
"More precisely, we solve the quadratic optimization problem in (3), and obtain reconciled forecasts ỹt.
",3.2. Mean Forecast Combination and Reconciliation,[1.0000000075742836],"['More precisely, we solve the quadratic optimization problem in (3), and obtain reconciled forecasts ỹt.']"
"Since the total number of series in the hierarchy, n, can be very large compared to the number of observations T , it is necessary to use some regularization for the weights.",3.2. Mean Forecast Combination and Reconciliation,[0],[0]
"Therefore, we will estimate the weights by solving the following L1 optimization problem:
minimize Q
1
T T∑ t=1 ‖yt",3.2. Mean Forecast Combination and Reconciliation,[0],[0]
−Qŷt‖2 + n∑ i=1,3.2. Mean Forecast Combination and Reconciliation,[0],[0]
"λi ‖qi‖1 ,
where λi ≥ 0 is a regularization parameter for the ith weight vector qi.",3.2. Mean Forecast Combination and Reconciliation,[0],[0]
"The previous problem can be rewritten as
minimize q1,...,qn n∑ i=1",3.2. Mean Forecast Combination and Reconciliation,[0],[0]
1 T T∑ t=1 (yit − ŷ′tqi)2 + n∑ i=1,3.2. Mean Forecast Combination and Reconciliation,[0],[0]
"λi ‖qi‖1 ,
which is decomposable in the vectors qi.",3.2. Mean Forecast Combination and Reconciliation,[0],[0]
"As a result, we can solve the n problems independently.",3.2. Mean Forecast Combination and Reconciliation,[0],[0]
"Our implementation of the LASSO is based on a cyclical coordinate descent algorithm (Friedman et al., 2007), and the regularization parameters are selected by minimizing time series cross-validated errors (Hyndman & Athanasopoulos, 2014, Section 2.5).
",3.2. Mean Forecast Combination and Reconciliation,[0],[0]
The forecast combination that we are considering in (6) has multiple advantages compared to the MinT forecast combination in (2).,3.2. Mean Forecast Combination and Reconciliation,[0],[0]
"First, since Q ∈ Rn×n, all series in the hierarchy can benefit directly from the forecast combination, not only the bottom series as in MinT with P ∈ Rm×n.",3.2. Mean Forecast Combination and Reconciliation,[0],[0]
"Second, we do not assume the base forecast are unbiased, and we do not seek to compute unbiased revised forecasts as in MinT. We rather seek to optimize the weights in order to obtain combined forecasts with low forecast errors; i.e.
with the right trade-off between bias and estimation variance.",3.2. Mean Forecast Combination and Reconciliation,[0],[0]
"Finally, even if we start with coherent base forecasts, we can still apply a forecast combination, and eventually reconcile them later.",3.2. Mean Forecast Combination and Reconciliation,[0],[0]
"In contrast with MinT, no forecast combination will be applied in that case.",3.2. Mean Forecast Combination and Reconciliation,[0],[0]
"Of course, MinT has the advantage of having a closed-form solution, which does not require the solution of n possibly highdimensional regression problems.",3.2. Mean Forecast Combination and Reconciliation,[0],[0]
"Finally, our reconciled forecasts are guaranteed to have smaller or equal SSE than the combined forecasts, which is guaranteed by the GTOP method as discussed in Section 2.2.",3.2. Mean Forecast Combination and Reconciliation,[0],[0]
"Our final algorithm can be summarized as follows:
Algorithm 2.",3.2. Mean Forecast Combination and Reconciliation,[0],[0]
"(Mean Combined and Reconciled Probabilistic Forecasting)
1.",3.2. Mean Forecast Combination and Reconciliation,[0],[0]
"Run Algorithm 1 to obtain bottom-up samples for all series in the hierarchy, say xi1, . . .",3.2. Mean Forecast Combination and Reconciliation,[0],[0]
", x i K with i =
1, . . .",3.2. Mean Forecast Combination and Reconciliation,[0],[0]
", n. 2.",3.2. Mean Forecast Combination and Reconciliation,[0],[0]
"Extract mean forecasts ŷT+h from all base predictive
distributions F̂i,T+h, and compute combined forecasts y̆T+h given in (6).",3.2. Mean Forecast Combination and Reconciliation,[0],[0]
3.,3.2. Mean Forecast Combination and Reconciliation,[0],[0]
"Given a weight matrix A, and using the combined forecasts y̆T+h as base forecasts, solve the optimization problem in (3) to obtain reconciled forecasts ỹT+h.",3.2. Mean Forecast Combination and Reconciliation,[0],[0]
4.,3.2. Mean Forecast Combination and Reconciliation,[0],[0]
"Compute revised samples x̃i1, . . .",3.2. Mean Forecast Combination and Reconciliation,[0],[0]
", x̃ i K where x̃ i k =
xik+θi and θi = (y̌i,t−ŷi,t)+(ỹi,t−y̆i,t) = y̆i,t−ŷi,t is an adjustment term, with i = 1, . . .",3.2. Mean Forecast Combination and Reconciliation,[0],[0]
", n.
Algorithm 2 computes coherent forecasts since both the bottom-up samples (computed using Algorithm 1) and the reconciled means are coherent.",3.2. Mean Forecast Combination and Reconciliation,[0],[0]
"We compare the following forecasting methods: (1) BASE: the base predictive distributions; (2) NAIVEBU: the naive bottom-up forecasts computed by summing independent samples from the bottom predictive distributions (without forecast combination); (3) PERMBU: the bottom-up forecasts computed using Algorithm 1 (without forecast combination); (4) PERMBU-MINT: similar to PERMBU with mean forecasts computed using MinT; (5) PERMBU-GTOP1: the forecasts are computed using Algorithm 2 with A = I; and (6) PERMBU-GTOP2: similar to PERMBU-GTOP1 but with A = diag(0, . . .",4. Experiments,[0],[0]
", 0︸ ︷︷ ︸
r , 1, . . .",4. Experiments,[0],[0]
", 1︸ ︷︷ ︸ m ); i.e. bottom-up instead
of reconciled combined mean forecasts.",4. Experiments,[0],[0]
"We evaluate our predictive distributions using the continuous ranked probability score (CRPS), which is a proper scoring rule, i.e. the score is maximized when the true dis-
tribution is reported (Gneiting & Raftery, 2007).",4.1. Probabilistic Forecast Evaluation,[0],[0]
"Given an h-period-ahead cumulative predictive distribution function F̂t+h and an observation yt+h, the CRPS can be defined as (Gneiting & Ranjan, 2011):
CRPS(F̂t+h, yt+h) = ∫ 1 0 QSτ ( F̂−1t+h(τ), yt+h ) dτ,
where QSτ is the quantile score, defined as
QSτ ( F̂−1t+h(τ), yt+h )",4.1. Probabilistic Forecast Evaluation,[0],[0]
= 2 ( 1{yt+h ≤ F̂−1t+h(τ)},4.1. Probabilistic Forecast Evaluation,[0],[0]
"− τ )( F̂−1t+h(τ)− yt+h ) ,
which is also known as the pinball or check loss (Koenker & Bassett, 1978).
",4.1. Probabilistic Forecast Evaluation,[0],[0]
"In order to quantify the gain/loss of the different methods with respect to the base forecasts, we compute the Skill Score defined as (SCOREBASE − SCORE)/SCOREBASE where SCORE is the considered evaluation score.",4.1. Probabilistic Forecast Evaluation,[0],[0]
"Low values of the score are desirable, and so high positive values are preferable for the skill score.",4.1. Probabilistic Forecast Evaluation,[0],[0]
"In the following experiments, SCORE will be computed by averaging the CRPS or QS over all observations in the test set.",4.1. Probabilistic Forecast Evaluation,[0],[0]
"Finally, as proposed by Laio & Tamea (2007), we will plot the QSτ (skill score) versus τ as a diagnostic tool in the comparison of the different methods.",4.1. Probabilistic Forecast Evaluation,[0],[0]
"We begin with simulated time series, implemented using the same processes as Wickramasuriya et al. (2015) to evaluate different hierarchical forecasting methods.",4.2. Simulated Data,[0],[0]
"However, we focus on distributional forecasts rather than mean forecasts.",4.2. Simulated Data,[0],[0]
"We used a hierarchy with four bottom series, where the two pairs of bottom series are aggregated in two aggregate series, which are then aggregated in a top series.",4.2. Simulated Data,[0],[0]
"Hence, the hierarchy is composed of n = 7 series, m = 4 bottom series and r = 3 aggregate series.
",4.2. Simulated Data,[0],[0]
"Each series in the bottom level is generated from an ARIMA(p, d, q) process, with p and q taking values of 0, 1 and 2 with equal probability and d taking values of 0 and 1 with equal probability.",4.2. Simulated Data,[0],[0]
The parameters are chosen randomly from a uniform distribution from a specific parameter space for each each component of the ARIMA process (see Table 3.2 in Wickramasuriya et al. (2015)).,4.2. Simulated Data,[0],[0]
"The error terms of the bottom-level ARIMA processes have a multivariate Gaussian distribution with a covariance structure that allows a strongly positive correlation among series with the same parents, but a moderately positive correlation among series with different parents.
",4.2. Simulated Data,[0],[0]
"For each series, we generate T = 100, 300 or 500 observations, with an additional H = 10 observations as a test set.
",4.2. Simulated Data,[0],[0]
"We fit an ARIMA model by minimizing the AIC, and compute 10-period ahead Gaussian predictive distributions as base forecasts.",4.2. Simulated Data,[0],[0]
"The whole process is repeated 2, 000 times.
",4.2. Simulated Data,[0],[0]
Figure 2 shows the results for T = 100.,4.2. Simulated Data,[0],[0]
"The first panel gives the CRPS skill score for each horizon; the second and third panels show the QS skill score averaged over horizons h = 1–6 and h = 7–10, respectively; the last panel gives the CRPS skill score for the bottom level.
",4.2. Simulated Data,[0],[0]
"In the first panel, we can see that PERMBU has a better skill score than NAIVEBU until horizon 6, and vice versa for the subsequent horizons.",4.2. Simulated Data,[0],[0]
The second panel shows that PERMBU outperforms NAIVEBU especially in the lower and upper tails.,4.2. Simulated Data,[0],[0]
"In other word, the independence assumption of NAIVEBU is not valid, and modelling the dependence structure between the children series of each aggregated series provides better tail forecasts for the aggregate series.",4.2. Simulated Data,[0],[0]
The third panel shows that NAIVEBU has consistently better QS skill score compared to PERMBU for horizons 7–10.,4.2. Simulated Data,[0],[0]
"This suggests that using one-period ahead dependence structure for 7 to 10-period ahead forecasts (i.e. using a misspecified dependence structure) is worse than assuming independence.
",4.2. Simulated Data,[0],[0]
The first panel also shows that the methods using forecast combinations have significantly increased the CRPS skill score compared to PERMBU.,4.2. Simulated Data,[0],[0]
This suggests that the mean forecast combination step is particularly useful in further improving the distributional forecasts.,4.2. Simulated Data,[0],[0]
"Furthermore, we can see that PERMBU-GTOP2 has better skill score than PERMBU-MINT until horizon 6.",4.2. Simulated Data,[0],[0]
"This shows the benefit of our forecast combination, which learns the best combination weights, without making an unbiasedness assumption.",4.2. Simulated Data,[0],[0]
The better skill score of PERMBU-GTOP2 compared to PERMBU-GTOP1 suggests an advantage in splitting the forecast combination and reconciliation steps.,4.2. Simulated Data,[0],[0]
"The same observations can be made in the last panel for the bottom level.
",4.2. Simulated Data,[0],[0]
"Finally, with a larger training set size (T = 300 and T = 500), the forecast combination methods have similar skill scores, as can be seen in Figures A1 and A2 in the appendix.",4.2. Simulated Data,[0],[0]
"With more observations, the fitted ARIMA model becomes more accurate, and therefore, forecast combination is less likely to improve the base forecasts.",4.2. Simulated Data,[0],[0]
"However, even with a large training set, modeling the dependence structure is still important, as shown by the better skill score of PERMBU compared to NAIVEBU.",4.2. Simulated Data,[0],[0]
"We used smart meter electricity consumption data collected by four energy supply companies in Great Britain (AECOM, 2011).",4.3. Electricity Smart Meter Data,[0],[0]
"Consumption was recorded at half-hourly intervals for more than 14,000 households, along with ge-
ographic and demographic information.",4.3. Electricity Smart Meter Data,[0],[0]
"In our study, we were interested only in relatively long time series without missing values, and this led us to use data recorded at 1,578 meters for the period 20 April 2009 to 31 July 2010, inclusive.",4.3. Electricity Smart Meter Data,[0],[0]
"Each series, therefore, consisted of T = 22, 464 halfhourly observations.",4.3. Electricity Smart Meter Data,[0],[0]
"We constructed a hierarchy based on geographical information comprising four levels of aggregation with m = 1, 578 series in the bottom level of the hierarchy, and r = 55 aggregated series in the other three levels of the hierarchy .",4.3. Electricity Smart Meter Data,[0],[0]
Figure 3 presents observations for a one-week period for just one series taken from each of the four levels of the hierarchy.,4.3. Electricity Smart Meter Data,[0],[0]
"The values shown on the right hand side of the figure correspond to the number of bottom level series that have been summed to give each of the aggregated series in the figure.
",4.3. Electricity Smart Meter Data,[0],[0]
"We considered the problem of one-day-ahead (i.e. the next H = 48 half-hours) probabilistic demand forecasting, with a forecast origin at 23:30 for each day.",4.3. Electricity Smart Meter Data,[0],[0]
"We split each time series into training, validation and test sets; the first 12 months for training, the next month for validation and the remaining, approximately, three months for testing.",4.3. Electricity Smart Meter Data,[0],[0]
"Each model is re-estimated before forecasting each day in the test set using a rolling window of the historical observations.
",4.3. Electricity Smart Meter Data,[0],[0]
We used different forecasting methods for the aggregate and bottom series.,4.3. Electricity Smart Meter Data,[0],[0]
"For the aggregate series, we capture the yearly cycle, the within-day and within-week seasonalities using seasonal Fourier terms with coefficients estimated by
Time
1578
450
179
68
10
1
Figure 3.",4.3. Electricity Smart Meter Data,[0],[0]
"One week of electricity demand with different number of aggregated series.
",4.3. Electricity Smart Meter Data,[0],[0]
"0.0 0.5 1.0 1.5 2.0 2.5 3.0
− 10
0 5
10 15
20 25
Log10(number of aggregated meters)
C R
P S
s ki
ll (%
)
",4.3. Electricity Smart Meter Data,[0],[0]
"●
●
●●
●●
●
●
● ●●●
●
●
● NAIVEBU PERMBU PERMBU−MINT",4.3. Electricity Smart Meter Data,[0],[0]
"PERMBU−GTOP1 PERMBU−GTOP2
0.0 0.2 0.4 0.6 0.8 1.0
0. 0
0. 5
1. 0
1. 5
2. 0
",4.3. Electricity Smart Meter Data,[0],[0]
"Aggregate levels
Probability level
Q S
Figure 4.",4.3. Electricity Smart Meter Data,[0],[0]
CRPS skill for different aggregations and average QS of all aggregate series.,4.3. Electricity Smart Meter Data,[0],[0]
A positive/negative CRPS skill gives the percentage of decrease/increase in CRPS with respect to the base forecasts.,4.3. Electricity Smart Meter Data,[0],[0]
"Higher skill score and lower QS are better.
",4.3. Electricity Smart Meter Data,[0],[0]
LASSO.,4.3. Electricity Smart Meter Data,[0],[0]
"After extracting the trend and seasonalities, we fitted an ARIMA model and computed Gaussian predictive distributions.",4.3. Electricity Smart Meter Data,[0],[0]
"This is justified by the fact that aggregate series are often smoother and easier to forecast, and by the central limit theorem.",4.3. Electricity Smart Meter Data,[0],[0]
"For the base forecasts, we implemented the kernel density estimation approach that performed the best in the work of Arora & Taylor (2016).
",4.3. Electricity Smart Meter Data,[0],[0]
"In Figure 4, the first panel gives the skill score for different aggregations computed using the average half-hourly CRPS over the test set, while the second panel shows the average QS of all aggregated series.",4.3. Electricity Smart Meter Data,[0],[0]
"In the first panel, we can see that PERMBU has better skill score than NAIVEBU especially for large aggregations.",4.3. Electricity Smart Meter Data,[0],[0]
"The second panel shows that PERMBU, by modelling the dependence structure, has contributed to significantly decrease the QS in the lower tail.",4.3. Electricity Smart Meter Data,[0],[0]
"By analyzing the forecasts (not shown here), we noticed that NAIVEBU is penalized both for not being able to capture the trend at the top (i.e. a bad mean forecasts), and for having too sharp predictive distributions (i.e. computed using a bad dependence structure).",4.3. Electricity Smart Meter Data,[0],[0]
"The fact that NAIVEBU seems competitive at moderately large quantiles can be explained by the unnecessarily wide prediction intervals for
the other methods, which are penalized by the QS.
",4.3. Electricity Smart Meter Data,[0],[0]
"Overall, the first panel shows that the mean forecast combination methods have better skill score than the base forecasts.",4.3. Electricity Smart Meter Data,[0],[0]
"We found that 75% of the series have less than 100 non-zero weights (see appendix); i.e. many forecast combinations were very sparse — an advantage of our approach compared to MinT, which produces dense combination weights.",4.3. Electricity Smart Meter Data,[0],[0]
"Furthermore, we can see that PERMBU-GTOP1 is dominating the other methods for almost all aggregations.",4.3. Electricity Smart Meter Data,[0],[0]
This suggests that computing bottom-up mean combined forecasts is better than reconciling the aggregate and bottom combined mean forecasts.,4.3. Electricity Smart Meter Data,[0],[0]
"This can be explained by the fact that PERMBU already produces competitive forecasts with the base forecasts, and so reconciling the bottom combined forecasts with the aggregate combined forecasts is unlikely to improve the final forecasts.
",4.3. Electricity Smart Meter Data,[0],[0]
"Finally, the first panel shows that all the mean forecast combination methods have lower skill score than the base forecasts for the bottom series (i.e. for the first aggregation).",4.3. Electricity Smart Meter Data,[0],[0]
This suggests that improving the forecast accuracy at the bottom level using forecast combination is particularly challenging especially with very noisy time series.,4.3. Electricity Smart Meter Data,[0],[0]
"However, the forecast improvement at the aggregate levels are magnitudes larger than the decrease in accuracy at the bottom level.",4.3. Electricity Smart Meter Data,[0],[0]
We have proposed an algorithm to compute coherent probabilistic forecasts for hierarchical time series.,5. Conclusion,[0],[0]
The algorithm provides samples from coherent predictive distributions for each series in the hierarchy.,5. Conclusion,[0],[0]
"To do so, we first generate independent samples from all series in the hierarchy.",5. Conclusion,[0],[0]
Then a sequence of permutations are applied to the samples in order to restore the dependencies between the children series of all aggregate series.,5. Conclusion,[0],[0]
"Finally, a sparse forecast combination is applied using the base mean forecasts of all series in the hierarchy.",5. Conclusion,[0],[0]
Our algorithm has the advantage of synthesizing information from multiple levels in the hierarchy.,5. Conclusion,[0],[0]
"Using simulated data, and a large scale electricity demand data set, we showed that restoring the dependencies of the children series consistently improves the forecast accuracy, especially in the tails, while the mean forecast combining weights provide an additional improvement by enabling a synthesis of information from the different forecasts.",5. Conclusion,[0],[0]
Our algorithm can be used to produce coherent probabilistic forecasts for hierarchical time series in many applications.,5. Conclusion,[0],[0]
Many applications require forecasts for a hierarchy comprising a set of time series along with aggregates of subsets of these series.,abstractText,[0],[0]
"Hierarchical forecasting require not only good prediction accuracy at each level of the hierarchy, but also the coherency between different levels — the property that forecasts add up appropriately across the hierarchy.",abstractText,[0],[0]
A fundamental limitation of prior research is the focus on forecasting the mean of each time series.,abstractText,[0],[0]
"We consider the situation where probabilistic forecasts are needed for each series in the hierarchy, and propose an algorithm to compute predictive distributions rather than mean forecasts only.",abstractText,[0],[0]
Our algorithm has the advantage of synthesizing information from different levels in the hierarchy through a sparse forecast combination and a probabilistic hierarchical aggregation.,abstractText,[0],[0]
We evaluate the accuracy of our forecasting algorithm on both simulated data and large-scale electricity smart meter data.,abstractText,[0],[0]
The results show consistent performance gains compared to state-of-the art methods.,abstractText,[0],[0]
Coherent Probabilistic Forecasts for Hierarchical Time Series,title,[0],[0]

1	36	As Wikipedia statistics as of January 2017 show, English Wikipedia has 5.3 million articles with an average of 162.89 revisions per article, with revisions growing at a rate of about 2 revisions per second.
2	25	This provides an amazing corpus for studying the types and effectiveness of revisions.
3	43	Specifically, differences between revisions contain valuable information for modeling document quality or extracting users’ expertise, and can additionally support various natural language processing (NLP) tasks such as sentence compression (Ya- mangil and Nelken, 2008), lexical simplification (Yatskar et al., 2010), information retrieval (Aji et al., 2010), textual entailment recognition (Zanzotto and Pennacchiotti, 2010), language bias detection (Recasens et al., 2013), spelling errors and paraphrases (Zesch, 2012; Max and Wisniewski, 2010).
13	77	Compared to taxonomies that either focus on low-level syntactic operations (Faigley and Witte, 1981) or that mix syntactic and semantic classes (Daxenberger and Gurevych, 2013), a clean higher-level semantic categorization enables us to easily identify textual meaning changes, and to connect revisions to “what happens in the mind of the revising author during the revision” 2000 (Fitzgerald, 1987; Daxenberger, 2016).
46	25	Moreover, edit types simply extracted from an edit is inadequate in outlining the correct intentions, for instance, adding a sentence could be Clarification, Elaboration, or Vandalism.
47	102	Our semantic taxonomy of edit intentions builds on prior literature on collaborative writing (Faigley and Witte, 1981; Fitzgerald, 1987), research on document revision analyses (Bronner and Monz, 2012), studies on edit categories (Daxenberger and Gurevych, 2012; Fong and BiukAghai, 2010), and work on purpose/intention classification (Zhang and Litman, 2016).
48	35	In order to ensure that our taxonomy captured the intentions that Wikipedians would find meaningful, we set up discussions with a group of 12 interested editors on a Wikipedia project talk page, and iteratively refined our taxonomy based on their feedback.
51	38	We define a top level layer for the revision intention taxonomy: intentions that are common in general revisions: General Revision Intentions, and intentions that are specific in Wikipedia: Wikipedia Specific Intentions.
53	62	Specifically, general revision intentions include: Clarification, Copy Editing, Elaboration, Fact Update, Point of View, Refactoring, Simplification and verification, and can be applicable to other contexts.
58	32	To construct a reliable, hand-coded dataset to serve as ground truth for automatic recognition of edit intentions, we employed four undergraduate students who had basic Wikipedia editing experience to label edits using our intention taxonomy, based on written annotation guidelines2 vetted by Wikipedia editors and provided examples3.
64	20	We used Cronbach’s α , a measure of internal consistency, to evaluate agreement among the annotators.
65	18	The overall agreement α score was 0.782, indicating substantial agreement between different annotators; The rule of thumb 1993 suggests that Cronbachs alpha scores larger than 0.7 are considered as acceptable.
67	19	As shown in column Before in Table 1, some types of edit intentions, such as disambiguation and clarification, were very rare in the random-sample corpus.
80	19	We designed four sets of features for identifying edit intentions from revisions.
93	31	Similar to Daxenberger and Gurevych (2013); Yang et al. (2016), we used Random k-labelsets RAKEL method that randomly chooses l small subset with k categories from the overall set of categories.
109	18	As a ranking based measure, we measured One Error, which evaluates how many times the top ranked predicted intention is not in the set of true labels of the instance.
112	26	Although multiple studies have utilized revisions’ comments as “groundtruth” to collect desired edits, the CMT method, which includes only comment features, is less accurate than either the BR or MLKNN models.
114	37	The automated measurement of edit intentions provides a general framework to analyze revisions and can facilitate a wide range of applications, such as collecting specific types of revisions (Yatskar et al., 2010; Recasens et al., 2013; Zanzotto and Pennacchiotti, 2010) and outlining the evolution of author roles (Arazy et al., 2015; Yang et al., 2016).
115	31	In this section, we demonstrate two examples of how this intention taxonomy can be applied to better understand the success of online collaboration communities (Kraut et al., 2010), specifically the process of these sites to retain new contributors and create innovative products.
116	66	To this end, we first investigate what newcomers are intended for in their first sessions and whether their edit intentions can account for their survival in Wikipedia.
117	32	We then examine how edits carrying on different intentions at distinct times in an article’s history influence changes in its quality.
119	70	Here, Edit Session is defined as a sequence of edits performed by a registered user with less than one hour’s time gap between two adjacent edits (Halfaker et al., 2012).
124	86	We applied our edit intention model to 53,248 revisions in users’ first sessions, and compared the percentages of different types of edit intentions between survivors and nonsurvivors, as shown in Intention Dist column in Table 3.
125	199	We also performed 1-way ANOVA to test whether survivors and non-survivors have the same mean for each edit intention.
126	24	We observed that, survivors tend to do more copy-editing (∆+=2.3%) and more wikification (∆+=6.5%), while non-survivors seem to perform more simplification and vandalism, which might provide signals for detecting vandals.
127	31	To explore the relationship between rejection of contributions and newcomer retention, we also visualized the revert ratios of different types of edit intentions for survivors and non-survivors in their first session.
140	20	This task is framed as a prediction task, i.e. using edits’ intentions and a set of control variables to predict changes in article quality.
147	38	The results show that, keeping all control variables fixed, more Copy Editing, Elaboration, Refactoring and Verification are positively associated with improvements in article quality; in contrast, Vandalism, Counter Vandalism, Disambiguation, Process and Simplification predict declines in article quality.
150	27	To determine if the effect of edit intentions on quality changes depends upon the initial quality of the article, we added the interaction terms between the previous quality score and edit percentages of different intentions (e.g., clarification x previous quality), and visualized interaction effects in Figure 2.
165	18	We are now deploying the same edit intention taxonomy for Italian Wikipedia, and plan to apply it to other low resourced languages in Wikipedia.

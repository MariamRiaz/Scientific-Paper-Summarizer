1	75	A shift-reduce algorithm uses a sequence of transitions to modify the content of two main data structures (a buffer and a stack) and create partial phrase-structure trees (or constituents) in the stack to finally produce a complete syntactic analysis for an input sentence, running in linear time.
5	29	Some of these attempts (Cross and Huang, 2016b; Coavoux and Crabbé, 2016; FernándezGonzález and Gómez-Rodrı́guez, 2018) introduced dynamic oracles (Goldberg and Nivre, 2012), originally designed for transition-based dependency algorithms, to bottom-up constituent parsing.
7	18	The latter follows the standard procedure that uses a gold sequence of transitions to train a model for parsing new sentences at test time.
8	40	A shift-reduce parser trained with this approach tends to be prone to suffer from error propagation (i.e. errors made in previous states are propagated to subsequent states, causing further mistakes in the transition sequence).
9	23	Dynamic oracles (Goldberg and Nivre, 2012) were developed to minimize the effect of error propagation by training parsers under closer conditions to those found at test time, where mistakes are inevitably made.
11	19	This makes it possible to introduce error exploration to force the parser to go through nonoptimal states, teaching it how to recover from mistakes and lose the minimum number of gold constituents.
13	148	On the one hand, (Dyer et al., 2016; Kuncoro et al., 2017) proposed a top-down transition-based algorithm, which creates a phrase structure tree in the stack by first choosing the non-terminal on the top of the tree, and then considering which should be its child nodes.
17	69	In that way each partial constituent tree is created in a bottom-up manner, but the non-terminal node is not chosen when all child nodes are in the stack (as a purely bottom-up parser does), but after the first child is considered.
53	24	Goldberg and Nivre (2012) show that implementing a dynamic oracle reduces to defining a loss function on configurations to measure the distance from the best tree they can produce to the gold parse.
54	24	This allows us to compute which transitions will lead the parser to configurations where the minimum number of mistakes are made.
57	77	Therefore, the loss function is defined as: `(c) = min γ|c γ L(γ, γG) = |γG \ γ|+ |γ \ γG| and, according to the authors, it can be efficiently computed for a non-binary bottom-up transition system by counting the individually unreachable arcs from configuration c (|U(c, γG)|) plus the erroneous constituents created so far (|γc \ γG|): `(c) = min γ|c γ L(γ, γG) = |U(c, γG)|+ |γc \ γG| We adapt the latter to efficiently implement a loss function for the top-down and in-order strategies.
58	52	While in bottom-up parsing constituents are created at once by a Reduce transition, in the other two approaches a Non-Terminal transition begins the process by naming the future constituent and a Reduce transition builds it by setting its span and children.
59	66	Therefore, a Non-Terminal transition that deviates from the non-terminals expected in the gold tree will eventually produce a wrong constituent in future configurations, so it should be penalized.
61	68	Then, the computation of the Hamming loss in top-down and in-order phrase-structure parsing adds two more terms to the bottom-up loss expression: (1) the number of predicted non-terminal nodes that are currently in the stack (αc),3 but not included in the set of gold non-terminal nodes (αG), and (2) the number of gold non-terminal nodes in the stack that are out of order with respect to the order needed in the gold tree: `(c) = min γ|c γ L(γ, γG) = |U(c, γG)|+ |γc \ γG| +|αc \ αG|+ out of order(αc, αG) This loss function is used to implement a dynamic oracle that, when given any parser configuration, will return the set of transitions τ that do not increase the overall loss (i.e., `(τ(c)) − `(c) = 0), leading the system through optimal configurations that minimize Hamming loss with respect to tG.
62	34	As suggested by (Coavoux and Crabbé, 2016; Fernández-González and Gómez-Rodrı́guez, 2018), constituent reachability can be used to efficiently compute the first term of the symmetric difference (|γG \ γ|), by simply counting the gold constituents that are individually unreachable from configuration c, as we describe in the next subsection.
63	45	The second and third terms of the loss (|γc \γG| and |αc \ αG|) can be trivially computed and are used to penalize false positives (extra erroneous constituents) so that final F-score is not harmed due to the decrease of precision, as pointed out by (Coavoux and Crabbé, 2016; Fernández-González and Gómez-Rodrı́guez, 2018).
65	16	Finally, the function out of order of the last term can be implemented by computing the longest increasing subsequence of gold nonterminal nodes in the stack, where the order relation is given by the order of non-terminals (provided by their associated index) in the transition sequence that builds the gold tree (this order is unique, as none of our two parsers of interest have spurious ambiguity).
67	19	Once we have the largest possible sub- sequence of gold non-terminal nodes in our configuration’s stack that is compatible with the gold order, the remaining ones give us the number of erroneous constituents that we will unavoidably generate, even in the best case, due to building them in an incorrect order.
77	16	(iii) l ∈ {ik | 1 ≤ k ≤ p} ∧ j ≤ r ∧ (X,m) /∈ αc (i.e. its first child is still a totally- or partiallybuilt constituent on top of the stack and the non-terminal node has not been created yet; therefore, it has to wait till the first child is completed (if it is still pending) and, then, it can be still created by pushing onto the stack the correct non-terminal node and shifting more words if necessary).
80	20	We will now prove that the above expression of `(c) indeed provides the minimum possible Hamming loss to the gold tree among all the trees that are reachable from configuration c. This implies correctness (or optimality) of our oracle.
84	30	Let us suppose that constituent-decomposability holds for any set of m tree-compatible constituents.
94	12	If the first condition holds, then we have a situation where the constituent (X, l, r) has already been created in c, so reachability of T follows from the same reasoning as for the first condition in the top-down case.
108	15	• As we have shown that the erroneous con- stituents arising from (γc′ \γG) and (αc\αG) are unavoidable, computations yielding a tree with minimum loss are those that maximize |γc ∪ S| in the previous term.
122	12	In that way, we easily simulate test time conditions, when the parser greedily chooses the highest-scoring transition, even when it is not an optimal one, placing the parser in an incorrect state.
129	34	The in-order parser obtains similar improvements on the CTB (0.5 points), but less notable accuracy gain on the WSJ (0.2 points).
131	14	They also present a non-optimal dynamic oracle for the top-down parser that, combined with more complex error-exploration strategies and size-10 beam search, significantly outperforms the policy gradient-trained version, confirming that even non-optimal dynamic oracles are a good option.8
132	31	Dan Bikel’s randomized parsing evaluation comparator (Bikel, 2004) was used to perform significance tests on precision and recall metrics on WSJ §23 and CTB §271-300.
136	31	We report in Table 3 the F-score obtained in constituents with different number of children on WSJ §23 by the top-down and in-order algorithms trained with both static and dynamic oracles.
138	13	The results seem to confirm that, indeed, dynamic oracles manage to alleviate error propagation, since improvements in F-score are more notable for larger constituents.
141	17	In addition, these promising techniques could easily benefit from recent studies in error-exploration strategies and yield stateof-the-art accuracies in transition-based parsing in the near future.

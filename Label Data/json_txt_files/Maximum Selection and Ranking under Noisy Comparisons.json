{"sections": [{"text": "\u270f\n2\n1 + log\n1 comparisons, optimal up to a\nconstant factor. We then derive a general framework that uses noisy binary search to speed up many ranking algorithms, and combine it with merge sort to obtain a ranking algorithm that uses O n\n\u270f\n2\nlog n(log log n)3 comparisons for = 1 n , optimal up to a (log log n)3 factor."}, {"heading": "1. Introduction", "text": ""}, {"heading": "1.1. Background", "text": "Maximum selection and sorting using pairwise comparisons are computer-science staples taught in most introductory classes and used in many applications. In fact, sorting, also known as ranking, was once claimed to utilize 25% of all computer cycles, e.g., (Mukherjee, 2011).\nIn many applications, the pairwise comparisons produce only random outcomes. In sports, tournaments rank teams based on pairwise matches whose outcomes are probabilistic in nature. For example, Microsoft\u2019s TrueSkill (Herbrich et al., 2006) software matches and ranks thousands of Xbox gamers based on individual game results. And in online advertising, out of a myriad of possible ads, each web page may display only a few, and a user will typically select at most one. Based on these random comparisons, ad companies such as Google, Microsoft, or Yahoo, rank the ads\u2019 appeal (Radlinski & Joachims, 2007; Radlinski et al., 2008).\nThese and related applications have brought about a resur1University of California, San Diego 2Google Research. Correspondence to: Venkatadheeraj Pichapati <dheerajpv7@ucsd.edu>.\nProceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s).\ngence of interest in maximum selection and ranking using noisy comparisons. Several probabilistic models were considered, including the popular Bradley-TerryLuce (Bradley & Terry, 1952) and its Plackett-Luce (PL) generalization (Plackett, 1975; Luce, 2005). Yet even for such specific models, the number of pairwise comparisons needed, or sample complexity, of maximum selection and ranking was known only to within a log n factor. We consider a significantly broader class of models and yet propose algorithms that are optimal up to a constant factor for maximum selection and up to (log log n)3 for ranking."}, {"heading": "1.2. Notation", "text": "Noiseless comparison assumes an unknown underlying ranking r(1), . . . ,r(n) of the elements in {1, . . . ,n} such that if two elements are compared, the higher-ranked one is selected. Similarly for noisy comparisons, we assume an unknown ranking of the elements, but now if two elements i and j are compared, i is chosen with some unknown probability p(i, j) and j is chosen with probability p(j, i) = 1 p(i, j), where if i is higher-ranked, then p(i, j) 1\n2 . Repeated comparisons are independent of each other.\nLet p\u0303(i, j) = p(i, j) 1 2 reflect the additional probability by which i is preferable to j. Note that p\u0303(j, i) = p\u0303(i, j) and p\u0303(i, j) 0 if r(i) > r(j). |p\u0303(i, j)| can also be seen as a measure of dissimilarity between i and j. Following (Yue & Joachims, 2011), we assume that two natural properties, satisfied for example by the PL model, hold whenever r(i) > r(j) > r(k): Strong Stochastic Transitivity (SST), p\u0303(i, k) max(p\u0303(i, j), p\u0303(j, k)), and Stochastic Triangle Inequality (STI), p\u0303(i, k)  p\u0303(i, j) + p\u0303(j, k). Two types of algorithms have been proposed for maximum selection and ranking under noisy comparisons: nonadaptive or offline (Rajkumar & Agarwal, 2014; Negahban et al., 2012; 2016; Jang et al., 2016) where the comparison pairs are chosen in advance, and adaptive or online where the comparison pairs are selected sequentially based on previous comparison results. We focus on the latter.\nWe specify the desired output via the (\u270f, )-PAC paradigm (Yue & Joachims, 2011; Szo\u0308re\u0301nyi et al., 2015) that requires the output to likely closely approximate the intended outcome. Specifically, given \u270f, > 0, with prob-\nability 1 , maximum selection must output an \u270f- maximum element i such that for all j, p(i, j) 1\n2 \u270f. Similarly, with probability 1 , the ranking algorithm must output an \u270f-ranking r0(1), . . . ,r0(n) such that whenever r0(i) > r0(j), p(i, j) 1\n2\n\u270f."}, {"heading": "1.3. Outline", "text": "In Section 2 we review past work and summarize our contributions. In Section 3 we describe and analyze our maximum-selection algorithm. In Section 4 we propose and evaluate the ranking algorithm. In Section 5 we experimentally compare our algorithms with existing ones. In Section 6 we mention some future directions."}, {"heading": "2. Old and new results", "text": ""}, {"heading": "2.1. Related work", "text": "Several researchers studied algorithms that with probability 1 find the exact maximum and ranking. (Feige et al., 1994) considered a simple model where the elements are ranked, and p\u0303(i, j) = \u270f whenever r(i) > r(j). (Busa-Fekete et al., 2014a) considered comparison probabilities p(i, j) satisfying the Mallows model (Mallows, 1957). And (Urvoy et al., 2013; Busa-Fekete et al., 2014b; Heckel et al., 2016) considered general comparison probabilities, without an underlying ranking assumption, and derived rankings based on Copeland- and Borda-counts, and random-walk procedures. As expected, when the comparison probabilities approach half, the above algorithms require arbitrarily many comparisons.\nTo achieve finite complexity even with near-half comparison probabilities, researchers adopted the PAC paradigm. For the PAC model with SST and STI constraints, (Yue & Joachims, 2011) derived a maximum-selection algorithm with sample complexity O n\n\u270f\n2\nlog\nn\n\u270f\nand used it to bound\nthe regret of the problem\u2019s dueling-bandits variant. Related results appeared in (Syrgkanis et al., 2016). For the PL model, (Szo\u0308re\u0301nyi et al., 2015) derived a PAC ranking algorithm with sample complexity O( n\n\u270f\n2 log n log n \u270f ).\nDeterministic adversarial versions of the problem were considered by (Ajtai et al., 2015), and by (Acharya et al., 2014a; 2016) who were motivated by density estimation (Acharya et al., 2014b)."}, {"heading": "2.2. New results", "text": "We consider (\u270f, )-PAC adaptive maximum selection and ranking using pairwise comparisons under SST and STI constraints. Note that when \u270f 1\n2 or 1 1/n for maximum selection and 1 1/n2 for ranking, any output is correct. We show for \u270f < 1/4, < 1\n2\nand any n:\n\u2022 Maximum-selection algorithm with sample complexity O n\n\u270f\n2\n1 + log\n1 , optimal up to a constant factor.\n\u2022 Ranking algorithm with O n \u270f 2 (log n)3 log n sample\ncomplexity.\n\u2022 General framework that converts any ranking algorithm with sample complexity O n\n\u270f\n2\n(log n)x log n\ninto a ranking algorithm that for 1 n has sample complexity O n\n\u270f\n2\nlog n(log log n)x .\n\u2022 Using the above framework, a ranking algorithm with sample complexity O n\n\u270f\n2\nlog n(log log n)3 for = 1 n .\n\u2022 An \u2326 n \u270f 2 log n lower bound on the sample complex-\nity of any PAC ranking algorithm, matching our algorithm\u2019s sample complexity up to a (log log n)3 factor."}, {"heading": "3. Maximum selection", "text": ""}, {"heading": "3.1. Algorithm outline", "text": "We propose a simple maximum-selection algorithm based on Knockout tournaments. Knockout tournaments are used to find a maximum element under non-noisy comparisons. Knockout tournament of n elements runs in dlog ne rounds where in each round it randomly pairs the remaining elements and proceeds the winners to next round.\nOur algorithm, given in KNOCKOUT uses O n\n\u270f\n2\n1 + log\n1\ncomparisons and O(n) memory\nto find an \u270f-maximum. (Yue & Joachims, 2011) uses O n\n\u270f\n2\nlog\nn\n\u270f\ncomparisons and O(n2) memory to find an\n\u270f-maximum. Hence we get log n-factor improvement in the number of comparisons and also we use linear memory compared to quadratic memory. From (Zhou & Chen, 2014) it can be inferred that the best PAC maximum selection algorithm requires \u2326 n\n\u270f\n2\n1 + log\n1\ncomparisons,\nhence up to constant factor, KNOCKOUT is optimal.\n(Yue & Joachims, 2011; Szo\u0308re\u0301nyi et al., 2015) eliminate elements one by one until only \u270f-maximums are remaining. Since they potentially need n 1 eliminations, in order to appply union bound they had to ensure that each eliminated element is not an \u270f-maximum w.p. 1 /n, requiring O(log(n/ )) comparisons for each eliminated element and hence a superlinear sample complexity O(n log(n/ )). In contrast, KNOCKOUT eliminates elements in log n rounds. Since in Knockout tournaments, number of elements decrease exponentially with each round, we afford to endure more error in the initial rounds and less error in the latter rounds by repeating comparison between each pair more times in latter rounds. Specifically, let b\ni be the highest-ranked element (according to the unobserved underlying ranking) at the beginning of round i. KNOCKOUT makes sure that w.p. 1\n2\ni , p\u0303(b i , b i+1 )  \u270f i by repeating\ncomparison between each pair in round i for O \u21e3 1\n\u270f\n2 i\nlog\n2\ni\n\u2318\ntimes. Choosing \u270f i = c\u270f\n2\ni/3 with c = 21/3 1, we make sure that comparison complexity is O n\n\u270f\n2\n1 + log\n1 and by\nunion bound and STI, w.p. 1 , p\u0303(b 1 , bdlogne+1) Pdlogne+1 i=1 c\u270f\n2\ni/3  \u270f. For 1, a relaxed notion of SST, called -stochastic transitivity (Yue & Joachims, 2011), requires that if r(i) > r(j) > r(k), then max(p\u0303(i, j), p\u0303(j, k))  \u00b7 p\u0303(i, k). Our results apply to this general notion of -stochastic transitivity and the analysis of KNOCKOUT is presented under this model. KNOCKOUT uses O \u21e3 n 4\n\u270f\n2\n1 + log\n1 \u2318 com-\nparisons.\nRemark 1. (Yue & Joachims, 2011) considered a different definition of \u270f-maximum as an element i that is at most \u270f dissimilar to true maximum i.e., for j with r(j) = n, p\u0303(j, i)  \u270f. Note that this definition is less restrictive than ours, hence requires fewer comparisons. Under this definition, (Yue & Joachims, 2011) used O \u21e3 n 6\n\u270f\n2\nlog\nn\n\u270f\n\u2318 com-\nparisons to find an \u270f-maximum whereas a simple modification of KNOCKOUT shows that O \u21e3 n 2\n\u270f\n2\n1 + log\n1 \u2318 com-\nparisons suffice. Hence we also get a significant improvement in the exponent of .\nTo simplify the analysis, we assume that n is a power of 2, otherwise we can add 2dlogne n dummy elements that lose to every original element with probability 1. Note that all \u270f-maximums will still be from the original set."}, {"heading": "3.2. Algorithm", "text": "We start with a subroutine COMPARE that compares two elements. It compares two elements i, j and maintains empirical probability p\u0302\ni , a proxy for p(i, j). It also maintains a confidence value c\u0302 s.t., w.h.p., p\u0302\ni 2 (p(i, j) c\u0302, p(i, j)+ c\u0302). COMPARE stops if it is confident about the winner or if it reaches its comparison budget m. It outputs the element with more wins breaking ties randomly.\nAlgorithm 1 COMPRARE Input: element i, element j, bias \u270f, confidence . Initialize: p\u0302\ni\n=\n1\n2 , c\u0302 = 1 2 , m = 1 2\u270f 2 log 2 , r = 0, w i = 0.\n1. while (|p\u0302 i\n1 2 |  c\u0302 \u270f and r  m) (a) Compare i and j. if i wins w\ni = w i + 1.\n(b) r = r + 1, p\u0302 i = w i\nr\n, c\u0302 = q 1\n2r\nlog\n4r\n2 .\nif p\u0302 i  1 2 Output: j. else Output: i.\nWe show that COMPARE w.h.p., outputs the correct winner if the elements are well seperated.\nLemma 2. If p\u0303(i, j) \u270f, then Pr(COMPARE(i, j, \u270f, ) 6= i)  .\nNote that instead of using fixed number of comparisons, COMPARE stops the comparisons adaptively if it is confident about the winner. If |p\u0303(i, j)| \u270f, COMPARE stops much before comparison budget 1\n2\u270f\n2\nlog\n2 and hence works better in practice.\nNow we present the subroutine KNOCKOUT-ROUND that we use in main algorithm KNOCKOUT."}, {"heading": "3.2.1. KNOCKOUT-ROUND", "text": "KNOCKOUT-ROUND takes a set S and outputs a set of size |S|/2. It randomly pairs elements, compares each pair using COMPARE, and returns the set of winners. We will later show that maximum element in the output set will be comparable to maximum element in the input set.\nAlgorithm 2 KNOCKOUT-ROUND Input: Set S, bias \u270f, confidence . Initialize: Set O = ;.\n1. Pair elements in S randomly.\n2. for every pair (i, j):\nAdd COMPARE(i, j, \u270f, ) to O.\nOutput: O\nNote that comparisons between each pair can be handled by a different processor and hence this algorithm can be easily parallelized.\nS can have several maximum elements. Comparison probabilities corresponding to all maximum elements will be essentially same because of STI. We define max(S) to be the maximum element with the least index, namely,\nmax(S) def= S \u21e3 min{i : p\u0303(S(i), S(j)) 0 8j} \u2318 .\nLemma 3. KNOCKOUT-ROUND(S, \u270f, ) uses |S| 4\u270f 2 log 2 comparisons and with probability 1 ,\np\u0303 max(S),max \u21e3 KNOCKOUT-ROUND(S, \u270f, ) \u2318!  \u270f."}, {"heading": "3.2.2. KNOCKOUT", "text": "Now we present the main algorithm KNOCKOUT. KNOCKOUT takes an input set S and runs log n rounds of KNOCKOUT-ROUND halving the size of S at the end of each round. Recall that KNOCKOUT-ROUND makes sure that maximum element in the output set is comparable to\nmaximum element in the input set. Using this, KNOCKOUT makes sure that the output element is comparable to maximum element in the input set.\nSince the size of S gets halved after each round, KNOCKOUT compares each pair more times in the latter rounds. Hence the bias between maximum element in input set and maximum element in output set is small in latter rounds.\nAlgorithm 3 KNOCKOUT Input: Set S, bias \u270f, confidence , stochasticity . Initialize: i = 1, S = set of all elements, c = 21/3 1. while |S| > 1\n1. S = KNOCKOUT-ROUND \u21e3 S, c\u270f\n2\n2\ni/3 , 2 i\n\u2318 .\n2. i = i+ 1.\nOutput: the unique element in S.\nNote that KNOCKOUT uses only memory of set S and hence O(n) memory suffices. Theorem 4 shows that KNOCKOUT outputs an \u270f-maximum with probability 1 . It also bounds the number of comparisons used by the algorithm. Theorem 4. KNOCKOUT(S, \u270f, ) uses O \u21e3\n4|S| \u270f 2 1 + log 1\n\u2318 comparisons and with proba-\nbility at least 1 , outputs an \u270f-maximum."}, {"heading": "4. Ranking", "text": "We propose a ranking algorithm that with probability at least 1 1\nn\nuses O \u21e3 n logn(log logn) 3\n\u270f\n2\n\u2318 comparisons and out-\nputs an \u270f-ranking. Notice that we use only \u02dcO \u21e3 n logn\n\u270f\n2\n\u2318 comparisons for = 1\nn\nwhere as (Szo\u0308re\u0301nyi et al., 2015) uses O n(log n)2/\u270f2 comparisons even for constant error probability . Furthermore (Szo\u0308re\u0301nyi et al., 2015) provided these guarantees only under Plackett-Luce model which is more restrictive compared to ours. Also, their algorithm uses O(n2) memory compared to O(n) memory requirement of ours. Our main algorithm BINARY-SEARCH-RANKING assumes the existence of a ranking algorithm RANK-x that with probability at least 1 uses O n\n\u270f\n2\n(log n)x log n com-\nparisons and outputs an \u270f-ranking for any > 0, \u270f > 0 and some x > 1. We also present a RANK-x algorithm with x = 3.\nObserve that we need RANK-x algorithm to work for any model that satisfies SST and STI. (Szo\u0308re\u0301nyi et al., 2015) showed that their algorithm works for Plackett-Luce model but not for more general model. So we present a RANK-x\nalgorithm that works for general model.\nThe main algorithm BINARY-SEARCH-RANKING randomly selects n\n(logn)\nx elements (anchors) and rank them using RANK-x . The algorithm has then effectively created n\n(logn)\nx bins, each between two successively ranked anchors. Then for each element, the algorithm identifies the bin it belongs to using a noisy binary search algorithm. The algorithm then ranks the elements within each bin using RANK-x .\nWe first present MERGE-RANK, a RANK-3 algorithm."}, {"heading": "4.1. Merge Ranking", "text": "We present a simple ranking algorithm MERGE-RANK that uses O \u21e3 n(logn) 3\n\u270f\n2\nlog\nn \u2318 comparisons, O(n) memory and\nwith probability 1 outputs an \u270f-ranking. Thus MERGE-RANK is a RANK-x algorithm for x = 3.\nSimilar to Merge Sort, MERGE-RANK divides the elements into two sets of equal size, ranks them separately and combines the sorted sets. Due to the noisy nature of comparisons, MERGE-RANK compares two elements i, j sufficient times, so that the comparison output is correct with high probability when |p\u0303(i, j)| \u270f\nlogn . Put differently, MERGE-RANK is same as the typical Merge Sort, except it uses COMPARE as the comparison function. Due to lack of space, MERGE-RANK is presented in Appendix A.\nLet\u2019s define the error of an ordered set S as the maximum distance between two wrongly ordered items in S, namely,\nerr(S) def = max 1ij|S| p\u0303(S(i), S(j)).\nWe show that when we merge two ordered sets, the error of the resulting ordered set will be at most \u270f\nlogn more than the maximum of errors of individual ordered sets.\nObserve that MERGE-RANK is a recursive algorithm and the error of a singleton set is 0. Two singleton sets each containing a unique element from the input set merge to form a set with two elements with an error at most 2\u270f\nlogn , then two sets with two elements merge to form a set with four elements with an error of at most 3\u270f\nlogn and henceforth. Thus the error of the output ordered set is bounded by \u270f.\nLemma 5 shows that MERGE-RANK can output an \u270f- ranking of S with probability 1 . It also bounds the number of comparisons used by the algorithm. Lemma 5. MERGE-RANK \u21e3 S, \u270f\nlog |S| , |S|2\n\u2318 takes\nO \u21e3\n|S|(log |S|)3 \u270f 2 log |S|\n\u2318 comparisons and with probability\n1 , outputs an \u270f-ranking. Hence, MERGE-RANK is a RANK-3 algorithm.\nNow we present our main ranking algorithm."}, {"heading": "4.2. BINARY-SEARCH-RANKING", "text": "We first sketch the algorithm outline below. We then provide a proof outline."}, {"heading": "4.2.1. ALGORITHM OUTLINE", "text": "Our algorithm is stated in BINARY-SEARCH-RANKING. It can be summarized in three major parts.\nCreating anchors: (Steps 1 to 3) BINARY-SEARCHRANKING first selects a set S0 of n\n(logn)\nx random elements (anchors) and ranks them using RANK-x . At the end of this part, there are n\n(logn)\nx ranked anchors. Equivalently, the algorithm creates n\n(logn)\nx 1 bins, each bin between two successively ranked anchors.\nCoarse ranking: (Step 4) After forming the bins, the algorithm uses a random walk on a binary search tree, to find which bin each element belongs to. INTERVAL-BINARYSEARCH is similar to the noisy binary search algorithm in (Feige et al., 1994). It builds a binary search tree with the bins as the leaves and it does a random walk over this tree. Due to lack of space the algorithm INTERVAL-BINARYSEARCH is presented in Appendix B but more intuition is given later in this section.\nRanking within each bin: (Step 5) For each bin, we show that the number of elements far from both anchors is bounded. The algorithm checks elements inside a bin whether they are close to any of the bin\u2019s anchors. For the elements that are close to anchors, the algorithm ranks them close to the anchor. And for the elements that are away from both anchors the algorithm ranks them using RANK-x and outputs the resulting ranking."}, {"heading": "4.2.2. ANALYSIS OF BINARY-SEARCH-RANKING", "text": "Creating anchors In Step 1 of the algorithm we select n/(log n)x random elements. Since these are chosen uniformly random, they lie nearly uniformly in the set S. This intuition is formalized in the next lemma.\nLemma 6. Consider a set S of n elements. If we select n\n(logn)\nx elements uniformly randomly from S and build an ordered set S0 s.t. p\u0303(S0(i), S0(j)) 0 8i > j , then with probability 1 1\nn\n4\n, for any \u270f > 0 and all k,\n|{e 2 S : p\u0303(e, S0(k)) > \u270f, p\u0303(S0(k+1), e) > \u270f}|  5(log n)x+1.\nIn Step 2, we use RANK-x to rank S0. Lemma 7 shows the guarantee of ranking S0.\nLemma 7. After Step 2 of the BINARY-SEARCHRANKING with probability 1 1\nn\n6\n, S0 is \u270f0-ranked.\nAt the end of Step 2, we have n (logn) x 1 bins, each between two successively ranked anchors. Each bin has a left\nAlgorithm 4 BINARY-SEARCH-RANKING Input: Set S, bias \u270f. Initialize: \u270f0 = \u270f/16, \u270f00 = \u270f/15, and So = ;. S\nj = ;, C\nj = ; and B j = ;, for 1  j  j n\n(logn)\nx\nk + 2.\n1. Form a set S0 with j n\n(logn)\nx\nk random elements from\nS. Remove these elements from S.\n2. Rank S0 using RANK-x S0, \u270f0, 1\nn\n6\n.\n3. Add dummy element a at the beginning of S0 such that p(a, e) = 0 8e 2 SSS0. Add dummy element b at the end of S0 such that p(b, e) = 1 8e 2 SSS0.\n4. for e 2 S: (a) k = INTERVAL-BINARY-SEARCH(S0, e, \u270f00). (b) Insert e in S\nk\n.\n5. for j = 1 to j n\n(logn)\nx\nk + 2:\n(a) for e 2 S j\n: i. if COMPARE2(e, S0(j), 10\u270f00 2 log n) 2\u21e5\n1\n2 6\u270f00, 1 2\n+ 6\u270f00 \u21e4 , insert e in C j\n. ii. else if COMPARE2(e, S0(j +\n1), 10\u270f00 2 log n) 2 \u21e5 1 2 6\u270f00, 1 2 + 6\u270f00 \u21e4 , then insert e in C j+1\n. iii. else insert e in B\nj . (b) Rank B\nj\nusing RANK-x B\nj , \u270f00, 1 n 4 .\n(c) Append S0(j), C j , B j in order at the end of So.\nOutput: So\nanchor and a right anchor . We say that an element belongs to a bin if it wins over the bin\u2019s left anchor with probability 1\n2 and wins over the bin\u2019s right anchor with probability  1\n2 . Notice that some elements might win over S0(1) with probability < 1\n2 and thus not belong to any bin. So in Step 3, we add a dummy element a at the beginning of S0 where a loses to every element in S S S0 with probability 1. For similar reasons we add a dummy element b to the end of S0 where every element in S S S0 loses to b with probability 1.\nCoarse Ranking Note that S0(i) and S0(i+ 1) are respectively the left and right anchors of the bin S\ni\n.\nAlgorithm 5 COMPARE2 Input: element i, element j, number of comparisons m.\n1. Compare i and j for m times and return the fraction of times i wins over j.\nSince S0 is \u270f0-ranked and the comparisons are noisy, it is hard to find a bin S\ni for an element e such that p(e, S0(i)) 1\n2 and p(S0(i + 1), e) 1 2 . We call a bin S i a \u270f00 nearly correct bin for an element e if p(e, S0(i)) 1\n2 \u270f00 and p(S0(i+ 1), e) 1\n2 \u270f00 for some \u270f00 > \u270f0. In Step 4, for each element we find an \u270f00-nearly correct bin using INTERVAL-BINARY-SEARCH . Next we describe an outline of INTERVAL-BINARY-SEARCH.\nINTERVAL-BINARY-SEARCH first builds a binary search tree of intervals (see Appendix B) as follows: the root node is the entire interval between the first and the last elements in S0. Each non-leaf node interval I has two children corresponding to the left and right halves of I . The leaves of the tree are the bins between two successively ranked anchors.\nTo find an \u270f00-nearly correct bin for an element e, the algorithm starts at the root of the binary search tree and at every non-leaf node corresponding to interval I , it checks if e belongs to I or not by comparing e with I\u2019s left and right anchors. If e loses to left anchor or wins against the right anchor, the algorithm backtracks to current node\u2019s parent.\nIf e wins against I\u2019s left anchor and loses to its right one, the algorithm checks if e belongs to the left or right child by comparing e with the middle element of I and moves accordingly.\nWhen at a leaf node, the algorithm checks if e belongs to the bin by maintaining a counter. If e wins against the bin\u2019s left anchor and loses to the bin\u2019s right anchor, it increases the counter by one or otherwise it decreases the counter by one. If the counter is less than 0 the algorithm backtracks to the bin\u2019s parent. By repeating each comparison several times, the algorithm makes a correct decision with probability 19\n20\n.\nNote that there could be several \u270f00-nearly correct bins for e and even though at each step the algorithm moves in the direction of one of them, it could end up moving in a loop and never reaching one of them. We thus run the algorithm for 30 log n steps and terminate.\nIf the algorithm is at a leaf node by 30 log n steps and the counter is more than 10 log n we show that the leaf node bin is a \u270f00-nearly correct bin for e and the algorithm outputs the leaf node. If not, the algorithm puts in a set Q all the anchors visited so far and orders Q according to S0.\nWe select 30 log n steps to ensure that if there is only one nearly correct bin, then the algorithm outputs that bin w.p. 1 1\nn\n6 . Also we do not want too many steps so as to bound the size of Q.\nBy doing a simple binary search in Q using BINARYSEARCH (see Appendix B) we find an anchor f 2 Q such that |p\u0303(e, f)|  4\u270f00. Since INTERVAL-BINARY-\nSEARCH ran for at most 30 log n steps, Q can have at most 60 log n elements and hence BINARY-SEARCH can search effectively by repeating each comparison O(log n) times to maintain high confidence. Next paragraph explains how BINARY-SEARCH finds such an element f .\nBINARY-SEARCH first compares e with the middle element m of Q for O(log n) times. If the fraction of wins for e is between 1\n2 3\u270f00 and 1 2 + 3\u270f00, then w.h.p. |p\u0303(e,m)|  4\u270f00 and hence BINARY-SEARCH outputs m. If the fraction of wins for e is less than 1\n2 3\u270f00, then w.h.p. p\u0303(e,m)  2\u270f00 and hence it eliminates all elements to the right of m in Q. If the fraction of wins for e is more than 1\n2 +3\u270f00, then w.h.p. p\u0303(e,m) 2\u270f00 and hence it eliminates all elements to the left of m in Q. It continues this process until it finds an element f such that the fraction of wins for e is between 1\n2 3\u270f00 and 1 2 + 3\u270f00.\nIn next Lemma, we show that INTERVAL-BINARYSEARCH achieves to find a 5\u270f00-nearly correct bin for every element. Lemma 8. For any element e 2 S, Step 4 of BINARY-SEARCH-RANKING places e in bin S\nl such that p\u0303(e, S0(l)) > 5\u270f00 and p\u0303(S0(l+1), e) > 5\u270f00 with probability 1 1\nn\n5\n.\nRanking within each bin Once we have identified the bins, we rank the elements inside each bin. By Lemma 6, inside each bin all elements are close to the bin\u2019s anchors except at most 5(log n)x+1 of them.\nThe algorithm finds the elements close to anchors in Step 5a by comparing each element in the bin with the bin\u2019s anchors. If an element in bin S\nj is close to bin\u2019s anchors S0(j) or S0(j + 1) , the algorithm moves it to the set C\nj\nor C j+1 accordingly and if it is far away from both, the algorithm moves it to the set B\nj . The following two lemmas state that this separating process happens accurately with high probability. The proofs of these results follow from the Chernoff bound and hence omitted. Lemma 9. At the end of Step 5a, for all j, 8e 2 C\nj , |p\u0303(e, S0(j))| < 7\u270f00 with probability 1 1\nn\n3 . Lemma 10. At the end of Step 5a, for all j, 8e 2 B\nj , min(p\u0303(e, S0(j)), p\u0303(S0(j + 1), e)) > 5\u270f00 with probability 1 1\nn\n3\n.\nCombining Lemmas 6, 7 and 10 next lemma shows that the size of B\nj is bounded for all j. Lemma 11. At the end of Step 5a, |B\nj |  5(log n)x+1 for all j, with probability 1 3\nn\n3\n.\nSince all the elements in C j are already close to an anchor, they need not be ranked. By Lemma 11 with probability 1 3\nn\n3 the number of elements in B j is at most 5(log n)x+1. We use RANK-x to rank each B\nj and output the final ranking.\nLemma 12 shows that all B j \u2019s are \u270f00-ranked at the end of Step 5b. Proof follows from properties of RANK-x and union bound. Lemma 12. At the end of Step 5b, all B\nj s are \u270f00-ranked with probability 1 1\nn\n3\n.\nCombining the above set of results yields our main result. Theorem 13. Given access to RANK-x, BINARYSEARCH-RANKING with probability 1 1\nn\n, uses\nO \u21e3 n logn(log logn) x\n\u270f\n2\n\u2318 comparisons and outputs an \u270f-\nranking.\nUsing MERGE-RANK as a RANK-x algorithm with x = 3 leads to the following corollary. Corollary 14. BINARY-SEARCH-RANKING uses O \u21e3 n logn(log logn) 3\n\u270f\n2\n\u2318 comparisons and outputs an \u270f-\nranking with probability 1 1 n .\nUsing PALPAC-AMPRR (Szo\u0308re\u0301nyi et al., 2015) as a RANK-x algorithm with x = 1 leads to the following corollary over PL model. Corollary 15. Over PL model, BINARY-SEARCHRANKING with probability 1 1\nn\nuses\nO \u21e3 n logn log logn\n\u270f\n2\n\u2318 comparisons and outputs an \u270f-ranking.\nIt is well known that to rank a set of n values under the noiseless setting, \u2326(n log n) comparisons are necessary. We show that under the noisy model, \u2326 n\n\u270f\n2\nlog\nn samples\nare necessary to output an \u270f-ranking and hence our algorithm is near-optimal. Theorem 16. For \u270f  1\n4 ,  1 2\n, there exists a noisy model that satisfies SST and STI such that to output an \u270f-ranking with probability 1 , \u2326 n\n\u270f\n2\nlog\nn comparisons are\nnecessary."}, {"heading": "5. Experiments", "text": "We compare the performance of our algorithms with that of others over simulated data. Similar to (Yue & Joachims, 2011), we consider the stochastic model where p(i, j) = 0.6 8i < j. Note that this model satisfies both SST and STI. We find 0.05-maximum with error probability = 0.1. Observe that i = 1 is the only 0.05-maximum. We compare the sample complexity of KNOCKOUT with that of BTMPAC (Yue & Joachims, 2011), MallowsMPI (Busa-Fekete et al., 2014a), and AR (Heckel et al., 2016). BTM-PAC is an (\u270f, )-PAC algorithm for the same model considered in this paper. MallowsMPI finds a Condorcet winner which exists under our general model. AR finds the maximum according to Borda scores. We also tried PLPAC (Szo\u0308re\u0301nyi et al., 2015), developed originally for PL model but the algorithm could not meet guarantees of = 0.1 under this\nmodel and hence omitted. Note that in all the experiments the reported numbers are averaged over 100 runs.\nIn Figure 1, we compare the sample complexity of algorithms when there are 7, 10 and 15 elements. Our algorithm outperforms all the others. BTM-PAC performs much worse in comparison to others because of high constants in the algorithm. Further BTM-PAC allows comparing an element with itself since the main objective in (Yue & Joachims, 2011) is to reduce the regret. We exclude BTM-PAC for further experiments with higher number of elements.\nIn Figure 2, we compare the algorithms when there are 50, 100, 200 and 500 elements. Our algorithm outperforms others for higher number of elements too. Performance of AR gets worse as the number of elements increases since Borda scores of the elements get closer to each other and hence AR takes more comparisons to eliminate an element. Notice that number of comparisons is in logarithmic scale and hence the performance of MallowsMPI appears to be close to that of ours.\nAs noted in (Szo\u0308re\u0301nyi et al., 2015), sample complexity of MallowsMPI gets worse as p\u0303(i, j) gets close to 0. To\nshow the pronounced effect, we use the stochastic model p(1, j) = 0.6 8j > 1, p(i, j) = 0.5 + q\u0303 8j > i, i > 1 where q\u0303 < 0.1, and the number of elements is 15. Here too we find 0.05-maximum with = 0.1. Note that i = 1 is the only 0.05-maximum in this stochastic model. In Figure 3, we compare the algorithms for different values of q\u0303: 0.01, 0.005 and 0.001. As discussed above, the performance of MallowsMPI gets much worse whereas our algorithm\u2019s performance stays unchanged. The reason is that MallowsMPI finds the Condorcet winner using successive elimination technique and as q\u0303 gets closer to 0, MallowsMPI takes more comparisons for each elimination. Our algorithm tries to find an alternative which defeats Condorcet winner with probability 0.5 0.05 and hence for alternatives that are very close to each other, our algorithm declares either one of them as winner after comparing them for certain number of times.\nNext we evaluate KNOCKOUT on Mallows model which does not satisfy STI. Mallows is a parametric model which is specified by single parameter . As in (Busa-Fekete et al., 2014a), we consider n = 10 elements and various values for : 0.03, 0.1, 0.3, 0.5, 0.7, 0.8, 0.9, 0.95 and 0.99. Here again we seek to find 0.05-maximum with = 0.05.\nAs we can see in Figure 4, sample complexity of KNOCKOUT and MallowsMPI is essentially same under small values of but KNOCKOUT outperforms MallowsMPI as gets close to 1 since comparison probabilities grow closer to 1/2. Surprisingly, for all values of except for 0.99, KNOCKOUT returned Condorcet winner in all runs. For = 0.99, KNOCKOUT returned second best element in 10 runs out of 100. Note that p\u0303(1, 2) = 0.0025 and hence KNOCKOUT still outputed a 0.05-maximum. Even though we could not show theoretical guarantees of KNOCKOUT under Mallows model, our simulations suggest that it can perform well even under this model.\nFor the stochastic model p(i, j) = 0.6 8i < j, we run our MERGE-RANK algorithm to find an \u270f-ranking with = 0.1. Figure 5 shows that sample complexity does not increase a lot with decreasing \u270f. We attribute this to the subroutine COMPARE that finds the winner faster when the elements are more dissimilar.\nSome more experiments are provided in Appendix G."}, {"heading": "6. Conclusion", "text": "We studied maximum selection and ranking using noisy comparisons for broad comparison models satisfying SST and STI. For maximum selection we presented a simple algorithm with linear, hence optimal, sample complexity. For ranking we presented a framework that improves the performance of many ranking algorithms and applied it to merge ranking to derive a near-optimal algorithm.\nWe conducted several experiments showing that our algorithms perform well and out-perform existing algorithms on simulated data.\nThe maximum-selection experiments suggest that our algorithm performs well even without STI. It would be of interest to extend our theoretical guarantees to this case. For ranking, it would be interesting to close the (log log n)3 ratio between the upper- and lower- complexity bounds."}, {"heading": "7. Acknowledgements", "text": "We thank Yi Hao and Vaishakh Ravindrakumar for very helpful discussions and suggestions, and NSF for supporting this work through grants CIF-1564355 and CIF1619448."}], "year": 2017, "references": [{"title": "Sorting with adversarial comparators and application to density estimation", "authors": ["Acharya", "Jayadev", "Jafarpour", "Ashkan", "Orlitsky", "Alon", "Suresh", "Ananda Theertha"], "venue": "In ISIT,", "year": 2014}, {"title": "Near-optimal-sample estimators for spherical gaussian mixtures", "authors": ["Acharya", "Jayadev", "Jafarpour", "Ashkan", "Orlitsky", "Alon", "Suresh", "Ananda Theertha"], "year": 2014}, {"title": "Maximum selection and sorting with adversarial comparators and an application to density estimation", "authors": ["Acharya", "Jayadev", "Falahatgar", "Moein", "Jafarpour", "Ashkan", "Orlitsky", "Alon", "Suresh", "Ananda Theertha"], "venue": "arXiv preprint arXiv:1606.02786,", "year": 2016}, {"title": "Sorting and selection with imprecise comparisons", "authors": ["Ajtai", "Mikl\u00f3s", "Feldman", "Vitaly", "Hassidim", "Avinatan", "Nelson", "Jelani"], "venue": "ACM Transactions on Algorithms (TALG),", "year": 2015}, {"title": "Rank analysis of incomplete block designs: I. the method of paired comparisons", "authors": ["Bradley", "Ralph Allan", "Terry", "Milton E"], "year": 1952}, {"title": "Preference-based rank elicitation using statistical models: The case of mallows", "authors": ["Busa-Fekete", "R\u00f3bert", "H\u00fcllermeier", "Eyke", "Sz\u00f6r\u00e9nyi", "Bal\u00e1zs"], "venue": "In Proc. of the ICML,", "year": 2014}, {"title": "Pac rank elicitation through adaptive sampling of stochastic pairwise preferences", "authors": ["Busa-Fekete", "R\u00f3bert", "Sz\u00f6r\u00e9nyi", "Bal\u00e1zs", "H\u00fcllermeier", "Eyke"], "venue": "In AAAI,", "year": 2014}, {"title": "Computing with noisy information", "authors": ["Feige", "Uriel", "Raghavan", "Prabhakar", "Peleg", "David", "Upfal", "Eli"], "venue": "SIAM Journal on Computing,", "year": 1994}, {"title": "Active ranking from pairwise comparisons and when parametric assumptions don\u2019t help", "authors": ["Heckel", "Reinhard", "Shah", "Nihar B", "Ramchandran", "Kannan", "Wainwright", "Martin J"], "venue": "arXiv preprint arXiv:1606.08842,", "year": 2016}, {"title": "Trueskill: a bayesian skill rating system", "authors": ["Herbrich", "Ralf", "Minka", "Tom", "Graepel", "Thore"], "venue": "In Proceedings of the 19th International Conference on Neural Information Processing Systems,", "year": 2006}, {"title": "Top-k ranking from pairwise comparisons: When spectral ranking is optimal", "authors": ["Jang", "Minje", "Kim", "Sunghyun", "Suh", "Changho", "Oh", "Sewoong"], "venue": "arXiv preprint arXiv:1603.04153,", "year": 2016}, {"title": "Individual choice behavior: A theoretical analysis", "authors": ["Luce", "R Duncan"], "venue": "Courier Corporation,", "year": 2005}, {"title": "Non-null ranking models", "authors": ["Mallows", "Colin L"], "venue": "i. Biometrika,", "year": 1957}, {"title": "Data structures using C: 1000 problems and solutions", "authors": ["Mukherjee", "Sudipta"], "venue": "McGraw Hill Education,", "year": 2011}, {"title": "Iterative ranking from pair-wise comparisons", "authors": ["Negahban", "Sahand", "Oh", "Sewoong", "Shah", "Devavrat"], "venue": "In NIPS, pp", "year": 2012}, {"title": "Rank centrality: Ranking from pairwise comparisons", "authors": ["Negahban", "Sahand", "Oh", "Sewoong", "Shah", "Devavrat"], "venue": "Operations Research,", "year": 2016}, {"title": "The analysis of permutations", "authors": ["Plackett", "Robin L"], "venue": "Applied Statistics, pp", "year": 1975}, {"title": "Active exploration for learning rankings from clickthrough data", "authors": ["Radlinski", "Filip", "Joachims", "Thorsten"], "venue": "In Proceedings of the 13th ACM SIGKDD,", "year": 2007}, {"title": "How does clickthrough data reflect retrieval quality", "authors": ["Radlinski", "Filip", "Kurup", "Madhu", "Joachims", "Thorsten"], "venue": "In Proceedings of the 17th ACM conference on Information and knowledge management,", "year": 2008}, {"title": "A statistical convergence perspective of algorithms for rank aggregation from pairwise data", "authors": ["Rajkumar", "Arun", "Agarwal", "Shivani"], "venue": "In Proc. of the ICML,", "year": 2014}, {"title": "Efficient algorithms for adversarial contextual learning", "authors": ["Syrgkanis", "Vasilis", "Krishnamurthy", "Akshay", "Schapire", "Robert E"], "venue": "arXiv preprint arXiv:1602.02454,", "year": 2016}, {"title": "Online rank elicitation for plackett-luce: A dueling bandits approach", "authors": ["Sz\u00f6r\u00e9nyi", "Bal\u00e1zs", "Busa-Fekete", "R\u00f3bert", "Paul", "Adil", "H\u00fcllermeier", "Eyke"], "venue": "In NIPS,", "year": 2015}, {"title": "Generic exploration and k-armed voting bandits", "authors": ["Urvoy", "Tanguy", "Clerot", "Fabrice", "F\u00e9raud", "Raphael", "Naamane", "Sami"], "venue": "In Proc. of the ICML, pp", "year": 2013}, {"title": "Beat the mean bandit", "authors": ["Yue", "Yisong", "Joachims", "Thorsten"], "venue": "In Proc. of the ICML, pp", "year": 2011}, {"title": "Optimal pac multiple arm identification with applications to crowdsourcing", "authors": ["Zhou", "Yuan", "Chen", "Xi"], "year": 2014}], "id": "SP:d611cb63f79d7242b07d6804cd96ed17cf0e28d7", "authors": [{"name": "Moein Falahatgar", "affiliations": []}, {"name": "Alon Orlitsky", "affiliations": []}, {"name": "Venkatadheeraj Pichapati", "affiliations": []}, {"name": "Ananda Theertha Suresh", "affiliations": []}], "abstractText": "We consider (\u270f, )-PAC maximum-selection and ranking using pairwise comparisons for general probabilistic models whose comparison probabilities satisfy strong stochastic transitivity and stochastic triangle inequality. Modifying the popular knockout tournament, we propose a simple maximum-selection algorithm that uses O n \u270f 2 1 + log 1 comparisons, optimal up to a constant factor. We then derive a general framework that uses noisy binary search to speed up many ranking algorithms, and combine it with merge sort to obtain a ranking algorithm that uses O n \u270f 2 log n(log log n)3 comparisons for = 1 n , optimal up to a (log log n)3 factor.", "title": "Maximum Selection and Ranking under Noisy Comparisons"}
0	79	Scripts were originally proposed by Schank and Abelson (1977) as “structures that describe the appropriate sequence of events in a particular context”.
1	133	These event sequences define expectations for how common scenarios (such as going to a restaurant) should unfold, thus enabling better language understanding.
2	88	Although scripts represented many other factors (roles, entry conditions, outcomes) recent work in script induction (Rudinger et al., 2015; Pichotta and Mooney, 2016; Peng and Roth, 2016) has focused on language modeling (LM) approaches where the “appropriate sequence of events” is the textual order of events (tuples of event predicates and their arguments).
6	24	Count based models are restricted by window size and sparse counts, while neural language models are known to rely on the local context for predictions.
7	30	Since scripts are meant to describe longer coherent scenarios, this is a major issue.
8	24	For example, contradictory events like (he denied charges) and (he pleads guilty) are given high probability in a typical language model.
12	74	These variations are called the “tracks” of a script.
13	32	Figure 1 shows a script with two tracks learned by our model.
15	188	This muddies the water for language understanding, making it difficult to tease apart differences like going to a fancy restaurant or a casual restaurant.
16	23	To remedy these problems, we propose a model that captures hierarchical structure via global latent variables.
17	171	The latent variables are categorical (representing the various types of scripts and thier possible tracks and variations) and form a tree (or more generally, a DAG)1, thus capturing hierarchical structure with the top (or bottom) levels of the tree representing high (or low) level features of the script.
18	144	The top might control for large differences like restaurant vs crime, while the bottom selects between fancy and casual dining.
19	15	The overall model, which we describe below, takes the form of an autoencoder, with an encoder network inferring values of the latents and a decoder conditioned on the latents generating scripts.
20	15	We show the usefulness of these latent representations against a prior RNN language model based system (Pichotta and Mooney, 2016) on several tasks.
21	43	We additionally evaluate the perplexity of the system against the RNN language model, a task that autoencoder models have typically struggled with (Bowman et al., 2016).
22	16	We find that the latent tree reduces model perplexity by a significant amount, possibly indicating the usefulness of the model in a more general sense.
23	48	Variational Autoencoders (VAEs, Kingma and Welling (2014)) are generative models which learn latent codes z for the data x by maximizing a lower bound on the data likelihood: log(p(x)) ≥ Eq(z|x)[p(x|z)]−KL[q(z|x)||p(z)] VAEs consist of two components: an encoder which parameterizes the latent posterior q(z|x) and a decoder which parameterizes p(x|z).
25	21	While VAEs have been useful in continuous domains, they have been less successful in generating discrete domains whose outputs have local syntactic regularities.
26	32	Part of this is due to the “posterior collapse” problem (Bowman et al., 2016); when VAEs are equipped with powerful autoregressive decoders, they tend to ignore the latent, collapsing the posterior q(z|x) to the (usually zero-mean Gaussian) prior p(z).
28	51	Vector Quantized VAEs (VQ-VAEs, van den Oord et al. (2017)) are a recently proposed class of models which both alleviates the posterior collapse problem and allows the model to use a latent space of discrete values.
29	89	In VQ-VAEs the latent z is represented as a categorical variable that can take on K values.
30	47	Each of these values k ∈ {1, ...,K} has associated with it a vector embedding ek.
31	23	The posterior of VQ-VAEs are discrete, deterministic, and parameterized as follows: q(z = k|x) = { 1 k=argmini||f(x)− ei||2 0 elsewise where f(x) is a function defined by an encoder network.
32	15	The decoding portion of the network is similar to VAEs, where a decoder parameterizes a distribution p(x|z = k) = g(ek), where g is the decoder network, and ek is the corresponding embedding, which is fed as input to the decoder.
33	15	This process can be seen as a ”quantization” operation mapping the continuous encoder output to the latent embedding it falls closest to, and then feeding this latent embedding (in lieu of the encoder output) to the decoder.
36	31	In practice, multiple latent variables z may by used, each with their own (or shared) embeddings space.
39	18	The VQ-VAE models (described earlier) provide a way to model discrete variables in an autoencoding framework while avoiding the posterior collapse problem.
41	18	HAQAEs are autoencoders with M latent variables, z0, ..., zM .
50	26	For example, the event (he ate food) gives evidence to the high level category of a restaurant script, while the more specific event (he drank wine) gives more evidence to the lower level category fancy restaurant.
55	30	For the root of the latent tree (z0), which has no parents, we use the averaged value of the encoder vectors hx as the query vector for its attention.

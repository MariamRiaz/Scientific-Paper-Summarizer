0,1,label2,summary_sentences
"Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 93–102, Denver, Colorado, May 31 – June 5, 2015. c©2015 Association for Computational Linguistics",text,[0],[0]
"Authorship Attribution (AA) tackles the problem of determining who, among a set of authors, wrote the document at hand.",1 Introduction,[0],[0]
"AA has relevant applications ranging from plagiarism detection (Stamatatos, 2011) to Forensic Linguistics, such as identifying authorship of threatening emails or malicious code.",1 Introduction,[0],[0]
"Applied areas such as law and journalism can also benefit from authorship attribution, where identifying the true author of a piece of text (such as a ransom note) may help save lives or catch the offenders.
",1 Introduction,[0],[0]
"We know from state of the art research in AA that the length of the documents and the number of po-
tential candidate authors have an important effect on the accuracy of AA approaches (Moore, 2001; Luyckx and Daelemans, 2008; Luyckx and Daelemans, 2010).",1 Introduction,[0],[0]
"We can also point out the most common features that have been used successfully in AA work, including: bag-of-words (Madigan et al., 2005; Stamatatos, 2006), stylistic features (Zheng et al., 2006; Stamatatos et al., 2000), and word and character level n-grams (Kjell et al., 1994; Keselj et al., 2003; Peng et al., 2003; Juola, 2006).
",1 Introduction,[0],[0]
"The utility of bag-of-words features is well understood: they effectively capture correlations between authors and topics (Madigan et al., 2005; Kaster et al., 2005).",1 Introduction,[0],[0]
"The discriminative value of these features is thus directly related to the level of content divergence among authors and among train and test sets.
",1 Introduction,[0],[0]
"The utility of stylistic features is also well understood: they model author preferences for the use of punctuation marks, emoticons, white spaces, and other traces of writing style.",1 Introduction,[0],[0]
"Such preferences are less influenced by topic, and directly reflect some of the unique writing patterns of an author.
",1 Introduction,[0],[0]
Character n,1 Introduction,[0],[0]
"-grams are the single most successful feature in authorship attribution (Koppel et al., 2009; Frantzeskou et al., 2007; Koppel et al., 2011), but the reason for their success is not well understood.",1 Introduction,[0],[0]
"One hypothesis is that character n-grams carry a little bit of everything: lexical content, syntactic content, and even style by means of punctuation and white spaces (Koppel et al., 2011).",1 Introduction,[0],[0]
"While this argument seems plausible, it falls short of a rigorous explanation.
",1 Introduction,[0],[0]
"In this paper, we investigate what in the make-up
93
of these small units of text makes them so powerful.",1 Introduction,[0],[0]
"Our goal is two-fold: on the one hand we want to have a principled understanding of character ngrams that will inform their use as features for AA and other tasks; on the other hand we want to make AA approaches more accessible to non-experts so that, for example, they could be acceptable pieces of evidence in criminal cases.
",1 Introduction,[0.9526722922925658],"['Finally, extending our complexity lower bounds to time delays, variable computational speeds of local systems, or machine failures would be a notable addition to this work.']"
"The research questions we aim to answer are:
• Are all character n-grams equally important?",1 Introduction,[0],[0]
"For example, are the prefix of ‘there’, the suffix of ‘breathe’ and the whole word ‘the’ all equivalent?",1 Introduction,[0],[0]
"More generally, are character n-grams that capture morpho-syntactic information, thematic information and style information equally important?
",1 Introduction,[0],[0]
• Are the character n-grams that are most important for single-domain settings also the most important for cross-domain settings?,1 Introduction,[0],[0]
"Which character n-grams are more like bag-of-words features (which tend to track topics), and which are more like stylistic features (which tend to track authors)?
",1 Introduction,[0],[0]
• Do different classifiers agree on the importance of the different types of character n-grams?,1 Introduction,[0],[0]
"Are some character n-grams consistently the best regardless of the learning algorithm?
",1 Introduction,[0],[0]
• Are some types of character n-grams irrelevant in AA tasks?,1 Introduction,[0],[0]
Are there categories of character n-grams that we can exclude and get similar (or better) performance than using all n-grams?,1 Introduction,[0],[0]
"If there are, are they the same for both singledomain and cross-domain AA settings?
",1 Introduction,[0],[0]
"Our study shows that using the default bag-ofwords representation of char n-grams results in collapsing sequences of characters that correspond to different linguistic aspects, and that this yields suboptimal prediction performance.",1 Introduction,[0],[0]
We further show that we can boost accuracy by loosing some categories of n-grams.,1 Introduction,[0],[0]
"Char n-grams closely related to thematic content can be completely removed without loss of accuracy, even in cases where the train and test sets have the same topics represented, a counter-intuitive argument.",1 Introduction,[0],[0]
"Given the wide spread use of char n-grams
in text classification tasks, our findings have significant implications for future work in related areas.",1 Introduction,[0],[0]
"To answer our research questions and explore the value of character n-grams in authorship attribution, we propose to separate character n-grams into ten distinct categories.",2 Categories of Character N -grams,[0],[0]
"Unlike previous AA work where all character n-grams were combined into a single bagof-n-grams, we evaluate each category separately to understand its behavior and effectiveness in AA tasks.",2 Categories of Character N -grams,[0],[0]
"These categories are related to the three linguistic aspects hypothesized to be represented by character n-grams: morpho-syntax (as represented by affix-like n-grams), thematic content (as represented by word-like n-grams) and style (as represented by punctuation-based n-grams).",2 Categories of Character N -grams,[0],[0]
"We refer to these three aspects as super categories (SC).
",2 Categories of Character N -grams,[0],[0]
The following sections describe the different types of n-grams.,2 Categories of Character N -grams,[0],[0]
We use the sentence in Table 1 as a running example for the classes and in Table 2 we show the resulting n-grams in that sentence.,2 Categories of Character N -grams,[0],[0]
"For ease of understanding, we replace spaces in n-grams with underscores ( ).
2.1 Affix n-grams Character n-grams are generally too short to represent any deep syntax, but some of them can reflect morphology to some degree.",2 Categories of Character N -grams,[0],[0]
"In particular, we consider the following affix-like features by looking at n-grams that begin or end a word:
prefix A character n-gram that covers the first n characters of a word that is at least n+ 1 characters long.
suffix A character n-gram that covers the last n characters of a word that is at least n + 1 characters long.
space-prefix A character n-gram that begins with a space.
space-suffix A character n-gram that ends with a space.
",2 Categories of Character N -grams,[0],[0]
"2.2 Word n-grams While character n-grams are often too short to capture entire words, some types can capture partial words and other word-relevant tokens.",2 Categories of Character N -grams,[0],[0]
"We consider the following such features:
whole-word A character n-gram that covers all characters of a word that is exactly n characters long.
",2 Categories of Character N -grams,[0],[0]
mid-word,2 Categories of Character N -grams,[0],[0]
"A character n-gram that covers n characters of a word that is at least n + 2 characters long, and that covers neither the first nor the last character of the word.
",2 Categories of Character N -grams,[0],[0]
"multi-word N -grams that span multiple words, identified by the presence of a space in the middle of the n-gram.
",2 Categories of Character N -grams,[0],[0]
2.3 Punctuation n-grams,2 Categories of Character N -grams,[0],[0]
The main stylistic choices that character n-grams can capture are the author’s preferences for particular patterns of punctuation.,2 Categories of Character N -grams,[0],[0]
"The following features characterize punctuation by its location in the n-gram.
beg-punct A character n-gram",2 Categories of Character N -grams,[0],[0]
"whose first character is punctuation, but middle characters are not.
",2 Categories of Character N -grams,[0],[0]
"mid-punct A character n-gram with at least one punctuation character that is neither the first nor the last character.
end-punct A character n-gram whose last character is punctuation, but middle characters are not.
",2 Categories of Character N -grams,[0],[0]
"The above ten categories are intended to be disjoint, so that a character n-gram belongs to exactly one of the categories.",2 Categories of Character N -grams,[0],[0]
"For n-grams that contain both spaces and punctuation, we first categorize by punctuation and then by spaces.",2 Categories of Character N -grams,[0],[0]
"For example, ‘e, ’ is assigned to the mid-punct category, not the spacesuffix category.
",2 Categories of Character N -grams,[0],[0]
We have observed that in our data almost 80% of the n-grams in the punct-beg and punct-mid categories contain a space.,2 Categories of Character N -grams,[0],[0]
This tight coupling of punctuation and spaces is due to the rules of English orthography: most punctuation marks require a space following them.,2 Categories of Character N -grams,[0],[0]
"The 20% of n-grams that have punctuation but no spaces correspond mostly to the exceptions to this rule: quotation marks, mid-word hyphens, etc.",2 Categories of Character N -grams,[0],[0]
An interesting experiment for future work would be to split out these two types of punctuation into separate feature categories.,2 Categories of Character N -grams,[0],[0]
"We consider two corpora, a single-domain corpus, where there is only one topic that all authors are writing about, and a multi-domain corpus, where there are multiple different topics.",3 Datasets,[0],[0]
"The latter allows us to test the generalization of AA models, by testing them on a different topic from that used for training.
",3 Datasets,[0],[0]
"The first collection is the CCAT topic class, a subset of the Reuters Corpus Volume 1 (Lewis et al., 2004).",3 Datasets,[0],[0]
"Although this collection was not gathered for the goal of doing authorship attribution studies, previous work has reported results for AA with 10 and 50 authors (Stamatatos, 2008; Plakias and Stamatatos, 2008; Escalante et al., 2011).",3 Datasets,[0],[0]
"We refer to these as CCAT 10 and CCAT 50, respectively.",3 Datasets,[0],[0]
"Both CCAT 10 and CCAT 50 belong to CCAT category (about corporate/industrial news) and are balanced across authors, with 100 documents sampled for each author.",3 Datasets,[0],[0]
Manual inspection of the dataset revealed that some of the authors in this collection consistently used signatures at the end of documents.,3 Datasets,[0],[0]
"Also, we noticed some writers use quotations a lot.",3 Datasets,[0],[0]
"Con-
sidering these parts of text for measuring the frequencies of character n-grams is not a good idea because signatures provide direct clues about the authorship of document and quotations do not reflect the author’s writing style.",3 Datasets,[0],[0]
"Therefore, to clean up the CCAT collection, we preprocessed it to remove signatures and quotations from each document.",3 Datasets,[0],[0]
"Since the CCAT collection contains documents belonging to only corporate/industrial topic category, this will be our single-domain collection.
",3 Datasets,[0],[0]
"The other collection consists of texts published in The Guardian daily newspaper written by 13 authors in four different topics (Stamatatos, 2013).",3 Datasets,[0],[0]
"This dataset contains opinion articles on the topics: World, U.K., Society, and Politics.",3 Datasets,[0],[0]
"Following prior work, to make the collection balanced across authors, we choose at most ten documents per author for each of the four topics.",3 Datasets,[0],[0]
We refer to this corpus as Guardian1.,3 Datasets,[0],[0]
"We also consider a variation of this corpus that makes it more challenging but that more closely matches realistic scenarios of forensic investigation that deal with short texts such as tweets, SMS, and emails.",3 Datasets,[0],[0]
We chunk each of the documents by sentence boundaries into five new short documents.,3 Datasets,[0],[0]
"We refer to this corpus as Guardian2.
",3 Datasets,[0],[0]
"Table 3 shows some of the statistics of the CCAT and Guardian corpora and Table 4 presents some of the top character n-grams for each category (taken from an author in the Guardian data, but the top ngrams look qualitatively similar for other authors).",3 Datasets,[0],[0]
We performed various experiments using different categories of character n-grams.,4 Experimental Settings,[0],[0]
We chose n=3 since our preliminary experiments found character 3-grams to be more effective than other higher level character n-grams.,4 Experimental Settings,[0],[0]
"For each category, we considered only those 3-grams that occur at least five times in the training documents.
",4 Experimental Settings,[0],[0]
"The performance of different authorship attribu-
tion models was measured in terms of accuracy.",4 Experimental Settings,[0],[0]
"In the single-domain CCAT experiments, accuracy was measured using the train/test partition of prior work.",4 Experimental Settings,[0],[0]
"In the cross-domain Guardian experiments, accuracy was measured by considering all 12 possible pairings of the 4 topics, treating one topic as training data and the other as testing data, and averaging accuracy over these 12 scenarios.",4 Experimental Settings,[0],[0]
"This ensured that in the crossdomain experiments, the topics of the training data were always different from that of the test data.
",4 Experimental Settings,[0],[0]
"We trained support vector machine (SVM) classifiers using the Weka implementation (Witten and Frank, 2005) with default parameters.",4 Experimental Settings,[0],[0]
We also ran some comparative experiments with the Weka implementation of naive Bayes classifiers and the LibSVM implementation of SVMs.,4 Experimental Settings,[0],[0]
"In the results below, when performance of a single classifier is presented, it is the result of Weka’s SVM, which generally gave the best performance.",4 Experimental Settings,[0],[0]
"When performance of other classifiers are presented, the classifiers are explicitly indicated.",4 Experimental Settings,[0],[0]
"In this section, we present various results on authorship attribution tasks using both single as well as cross-domain datasets.",5 Experimental Results and Evaluation,[0],[0]
"We will explore character ngrams in depth and try to understand why they are so effective in discriminating authors.
5.1 Which n-gram Categories are Most Author-Discriminative?
After breaking character n-grams into ten disjoint categories, we empirically illustrate what categories are
Single Domain (CCAT)
most discriminative.",5 Experimental Results and Evaluation,[0],[0]
"Table 5 shows the accuracy of each type of n-gram for each of the different corpora.
",5 Experimental Results and Evaluation,[0],[0]
"Table 5(a) shows that the top four categories for single-domain AA are: prefix, suffix, space-prefix, and mid-word.",5 Experimental Results and Evaluation,[0],[0]
These four categories have the best performance on both CCAT 10 and CCAT 50.,5 Experimental Results and Evaluation,[0],[0]
"In contrast, Table 5(b) shows that the top four categories for cross-domain AA are: prefix, space-prefix, beg-
punct, and mid-punct.",5 Experimental Results and Evaluation,[0],[0]
"For both single-domain and cross-domain AA, prefix and space-prefix are strong features, and are generally better than the suffix features, perhaps because authors have more control over prefixes in English, while suffixes are often obligatory for grammatical reasons.",5 Experimental Results and Evaluation,[0],[0]
"For cross-domain AA, beg-punct and midpunct are the top features, likely because an author’s
use of punctuation is consistent even when the topic changes.",5 Experimental Results and Evaluation,[0],[0]
"For single-domain AA, mid-word was also a good feature, probably because it captured lexical information that correlates with authors’ preferences towards writing about specific topics.
",5 Experimental Results and Evaluation,[0],[0]
"Figure 1 shows an alternate view of these results, graphing the rank of each n-gram type.",5 Experimental Results and Evaluation,[0],[0]
"For computing the rank, the accuracies of the ten different n-gram type classifiers are sorted in decreasing order and ranked from 1 to 10 respectively with ties getting the same rank.",5 Experimental Results and Evaluation,[0],[0]
"For the Guardian corpora, the average rank of each n-gram category was computed by averaging its rank across the 12 possible test/train cross-domain combinations.",5 Experimental Results and Evaluation,[0],[0]
"In both of the single-domain CCAT corpora, the classifier based on prefix n-grams had the top accuracy (rank 1), and the classifier based on mid-punct had the worst accuracy (rank 10).",5 Experimental Results and Evaluation,[0],[0]
"In both of the cross-domain Guardian corpora, on the other hand, mid-punct was among the top-ranked n-gram categories.",5 Experimental Results and Evaluation,[0],[0]
"This suggests that punctuation features generalize the best across topic, but if AA is more of a topic classification task (as in the single-domain CCAT corpora), then punctuation adds little over other features that more directly capture the topic.
",5 Experimental Results and Evaluation,[0],[0]
"Since our cross-domain datasets are small, we performed a small number of planned comparisons using a two-tailed t-test over the accuracies on the Guardian1 and Guardian2 corpora.",5 Experimental Results and Evaluation,[0],[0]
"We found that in both corpora, the best punctuation category (punctmid) is better than the best word category (wholeword) with p < 0.001.",5 Experimental Results and Evaluation,[0],[0]
"In the Guardian2 corpus, the best affix category (space-prefix) is also better than the best word category (whole-word) with p < 0.05, but this does not hold in the Guardian1 corpus (p = 0.14).",5 Experimental Results and Evaluation,[0],[0]
"Also, we observed that in both Guardian1 and Guardian2 datasets, both punct-mid and spaceprefix are better than multi-word (p < 0.01).
",5 Experimental Results and Evaluation,[0],[0]
"Overall, we see that affix n-grams are generally effective in both single-domain and cross-domain settings, punctuation n-grams are effective in crossdomain settings, and mid-word is the only effective word n-gram, and only in the single-domain setting.",5 Experimental Results and Evaluation,[0],[0]
"Importance of Different n-gram Types?
",5.2 Do Different Classifiers Agree on the,[0],[0]
"The previous experiments have shown, for example, that prefix n-grams are universally predictive in AA
tasks, that mid-word n-grams are good predictors in single-domain settings, and that beg-punct n-grams are good predictors in cross-domain settings.",5.2 Do Different Classifiers Agree on the,[0],[0]
"But are these facts about the n-gram types themselves, or are these results only true for the specific SVM classifiers we trained?
",5.2 Do Different Classifiers Agree on the,[0],[0]
"To see whether certain types of n-grams are fundamentally good or bad, regardless of the classifier, we compare performance of the different n-gram types for three classifiers: Weka SVM classifiers (as used in our other experiments), LibSVM classifiers and Weka’s naive Bayes classifiers1.",5.2 Do Different Classifiers Agree on the,[0],[0]
"Figure 2 shows the n-gram category rankings for all these classifiers2 for both the single-domain CCAT and the cross-domain Guardian settings.
",5.2 Do Different Classifiers Agree on the,[0],[0]
"Across the different classifiers, the pattern of feature rankings are similar.",5.2 Do Different Classifiers Agree on the,[0],[0]
Table 6 shows the Spearman’s rank correlation coefficient (ρ) for the per-ngram-type accuracies of each pair of classifiers.,5.2 Do Different Classifiers Agree on the,[0],[0]
"We observe fairly high correlations, with ρ above 0.70 for all single-domain pairings, and between 0.44 and 0.81 for cross-domain pairings.
",5.2 Do Different Classifiers Agree on the,[0],[0]
"As in Section 5.1, prefix and space-prefix are among the most predictive n-gram types.",5.2 Do Different Classifiers Agree on the,[0],[0]
"In the single-domain settings, we again see that suffix and mid-word are also highly predictive, while in the cross-domain settings, we again see that beg-punct and mid-punct are highly predictive.",5.2 Do Different Classifiers Agree on the,[0],[0]
"These results all confirm that some types of n-grams are fundamentally more predictive than others, and our results are not specific to the particular type of classifier used.
",5.2 Do Different Classifiers Agree on the,[0],[0]
"1Weka SVM and LibSVM are both support vector machine classifiers, but Weka uses Platt’s sequential minimal optimization algorithm while LibSVM uses working set selection with second order information.",5.2 Do Different Classifiers Agree on the,[0],[0]
"The result is that they achieve different performance on our AA tasks.
2We also tried a decision tree classifier, C4.5 (J48) from WEKA, and it produced similar patterns (not shown).
",5.2 Do Different Classifiers Agree on the,[0],[0]
Single Domain (CCAT),5.2 Do Different Classifiers Agree on the,[0],[0]
"In the previous sections, we have seen that some types of character n-grams are more predictive than others - affix n-grams performed well in both single domain and cross-domain settings and punctuation n-grams performed well in cross-domain settings.",5.3 Are Some Character N -grams Irrelevant?,[0],[0]
"In general, word n-grams were not as predictive as other types of n-grams (with the one exception being mid-word n-grams in the single domain setting).",5.3 Are Some Character N -grams Irrelevant?,[0],[0]
"Given this poor performance of word n-grams, a natural question is: could we exclude these features entirely and achieve similar performance?
",5.3 Are Some Character N -grams Irrelevant?,[0],[0]
Our goal then is to compare a model trained on affix n-grams and punct n-grams against a model trained on “all” n-grams.,5.3 Are Some Character N -grams Irrelevant?,[0],[0]
"We consider two definitions of “all”:
all-untyped The traditional approach to extracting n-grams where n-gram types are ignored (e.g., ‘the’ as a whole word is no different from ‘the’ in the middle of a word)
all-typed The approach discussed in this paper, where n-grams of different types are distinguished (equivalent to the set of all affix+punct+word n-grams).
",5.3 Are Some Character N -grams Irrelevant?,[0],[0]
"We compare these models trained on all the n-grams to our affix+punct model.
",5.3 Are Some Character N -grams Irrelevant?,[0],[0]
Table 7 shows this analysis.,5.3 Are Some Character N -grams Irrelevant?,[0],[0]
"For either definition of “all”, the model that discards all word features achieves performance as high or higher than the model with all of the features, and does so with only about two thirds of the features.",5.3 Are Some Character N -grams Irrelevant?,[0],[0]
"This is not too surprising in the cross-domain Guardian tasks, where the word n-grams were among the worst features.",5.3 Are Some Character N -grams Irrelevant?,[0],[0]
"On the single-domain CCAT tasks this result is more surprising, since we have discarded the mid-word n-grams, which was one of the best single-domain n-gram types.",5.3 Are Some Character N -grams Irrelevant?,[0],[0]
This indicates that whatever information mid-word is capturing it is also being captured in other ways via affix and punct n-grams.,5.3 Are Some Character N -grams Irrelevant?,[0],[0]
"Of all 1024 possible combinations of features, we tried a
number of different combinations and were unable to identify one that outperformed affix+punct.",5.3 Are Some Character N -grams Irrelevant?,[0],[0]
"Overall, this experiment gives compelling evidence that affix and punct n-grams are more important than word n-grams.",5.3 Are Some Character N -grams Irrelevant?,[0],[0]
We did a manual exploration of our datasets.,6 Analysis,[0],[0]
"In our cross-domain dataset, the character 3-gram ‘sti’ shows up as both prefix and mid-word.",6 Analysis,[0],[0]
"All 13 authors use ‘sti’ frequently as a mid-word n-gram in words such as institution, existing, justice, and distinction.",6 Analysis,[0],[0]
"For example:
• The government’s story is that the existing warheads might be deteriorating.
",6 Analysis,[0],[0]
"• For all the justice of many of his accusations, the result is occasionally as dreadful as his title suggests.
",6 Analysis,[0],[0]
"But only six authors use ‘sti’ as a prefix, in examples like:
• Their mission was to convince tourists that Britain was still open for business.
",6 Analysis,[0],[0]
"• There aren’t even any dead people on it, since by the very act of being dead and still famous, they assert their long-term impact.
",6 Analysis,[0],[0]
Thus ‘sti’ as a prefix is predictive of authorship even though ‘sti’ as a mid-word n-gram is not.,6 Analysis,[0],[0]
"Notably, under the traditional untyped bag-of-n-grams approach, both versions of ‘sti’ would have been treated the same, and this discriminative power would have been lost.
",6 Analysis,[0],[0]
"As already demonstrated in Section 5 that affix+punct features perform better than using all the features, we would like to use an example from our dataset to visualize the text when features in SC word are discarded.",6 Analysis,[0],[0]
Out of seven categories in affix and punct,6 Analysis,[0],[0]
", we computed in how many of them each character belongs to, three being the maximum possible value.",6 Analysis,[0],[0]
"Therefore, we show each character with different opacity level depending on number of categories it belongs to: zero will get white color (word related n-grams), one will get 33% black, two will get 67% black, and three will get 100% black.",6 Analysis,[0],[0]
"In Table 8, we show an example sentence before (first row of Table 8) and after (second row of Table 8) showing the opacity level of each character.",6 Analysis,[0],[0]
"It is clear that the darkest characters are those around the punctuation characters and those around spaces are second darkest, while the lightest (with 0% darkness) are the ones in the middle of long words.",6 Analysis,[0],[0]
This gives us an idea about the characters in a text that are important for AA tasks.,6 Analysis,[0],[0]
"Various hypotheses have been put forth to explain the “black magic” (Kestemont, 2014) behind the success of character n-gram features in authorship attribution.",7 Discussion,[0],[0]
Kestemont (2014) conjectured that their utility was in capturing function words and morphology.,7 Discussion,[0],[0]
"Koppel et al. (2009) suggested that they were capturing topic information in single domain settings, and style and syntactic information in cross-domain settings.",7 Discussion,[0],[0]
Our study provides empirical evidence for testing these claims.,7 Discussion,[0],[0]
"We did indeed find that the ability of character n-grams to capture morphology is useful, as reflected in the high prediction performance of af-
fix n-grams in both single-domain and cross-domain settings.",7 Discussion,[0],[0]
"And we found that word n-grams (capturing topic information) were useful in single domain settings, while puct n-grams (capturing style information) were useful in cross-domain settings.",7 Discussion,[0],[0]
"We further found that word n-grams are unnecessary, even in single-domain settings.",7 Discussion,[0],[0]
"Models based only on affix and punct n-grams performed as well as models with all n-grams regardless of whether it was a single-domain or cross-domain authorship attribution task.
",7 Discussion,[0],[0]
Our findings on the value of selecting n-grams according to the linguistic aspect they represent may also be beneficial in other classification tasks where character n-grams are commonly used.,7 Discussion,[0],[0]
"Promising tasks are those related to the stylistic analysis of texts, such as native language identification, document similarity and plagiarism detection.
",7 Discussion,[0],[0]
"Morphologically speaking, English is a poor language.",7 Discussion,[0],[0]
The fact that we identified significant differences in performance by selecting n-gram categories that are related to affixation in this poorly inflected language suggests that we may find even larger differences in performance in morphologically richer languages.,7 Discussion,[0],[0]
We leave this research question for future work.,7 Discussion,[0],[0]
This research was partially supported by NSF awards 1462141 and 1254108.,Acknowledgements,[0],[0]
It was also supported in part by the CONACYT grant 134186 and the WIQ-EI IRSES project (grant no. 269180) within the FP 7 Marie Curie.,Acknowledgements,[0],[0]
"Character n-grams have been identified as the most successful feature in both singledomain and cross-domain Authorship Attribution (AA), but the reasons for their discriminative value were not fully understood.",abstractText,[0],[0]
"We identify subgroups of character n-grams that correspond to linguistic aspects commonly claimed to be covered by these features: morphosyntax, thematic content and style.",abstractText,[0],[0]
We evaluate the predictiveness of each of these groups in two AA settings: a single domain setting and a cross-domain setting where multiple topics are present.,abstractText,[0],[0]
We demonstrate that character ngrams that capture information about affixes and punctuation account for almost all of the power of character n-grams as features.,abstractText,[0],[0]
Our study contributes new insights into the use of n-grams for future AA work and other classification tasks.,abstractText,[0],[0]
Not All Character N -grams Are Created Equal: A Study in Authorship Attribution,title,[0],[0]
"Proceedings of the SIGDIAL 2017 Conference, pages 384–394, Saarbrücken, Germany, 15-17 August 2017. c©2017 Association for Computational Linguistics
Neural conversational models require substantial amounts of dialogue data to estimate their parameters and are therefore usually learned on large corpora such as chat forums, Twitter discussions or movie subtitles. These corpora are, however, often challenging to work with, notably due to their frequent lack of turn segmentation and the presence of multiple references external to the dialogue itself. This paper shows that these challenges can be mitigated by adding a weighting model into the neural architecture. The weighting model, which is itself estimated from dialogue data, associates each training example to a numerical weight that reflects its intrinsic quality for dialogue modelling. At training time, these sample weights are included into the empirical loss to be minimised. Evaluation results on retrieval-based models trained on movie and TV subtitles demonstrate that the inclusion of such a weighting model improves the model performance on unsupervised metrics.",text,[0.9510360639135007],"['In practice, summing the gradients can be distributed by computing a spanning tree (with the root as master node), and asking for each node to perform the sum of its children’s gradients before sending it to its parent.']"
"The development of conversational agents (such as mobile assistants, chatbots or interactive robots) is increasingly based on data-driven methods aiming to infer conversational patterns from dialogue data.",1 Introduction,[0],[0]
"One major trend in the last recent years is the emergence of neural conversation models (Vinyals and Le, 2015; Sordoni et al., 2015; Shang et al., 2015; Serban et al., 2016; Lowe et al., 2017; Li et al., 2017).",1 Introduction,[0],[0]
"These neural models can be directly
∗ Also affiliated with Universidad Central del Ecuador (Quito, Ecuador).
",1 Introduction,[0],[0]
"estimated from raw (non-annotated) dialogue corpora, allowing them to be deployed with a limited amount of domain-specific knowledge and feature engineering.
",1 Introduction,[0],[0]
"Due to their large parameter space, the estimation of neural conversation models requires considerable amounts of dialogue data.",1 Introduction,[0],[0]
"They are therefore often trained on conversations collected from various online resources, such as Twitter discussions (Ritter et al., 2010) online chat logs (Lowe et al., 2017), movie scripts (DanescuNiculescu-Mizil and Lee, 2011) and movie and TV subtitles (Lison and Tiedemann, 2016).
",1 Introduction,[0],[0]
"Although these corpora are undeniably useful, they also face some limitations from a dialogue modelling perspective.",1 Introduction,[0],[0]
"First of all, several dialogue corpora, most notably those extracted from subtitles, do not include any explicit turn segmentation or speaker identification (Serban and Pineau, 2015; Lison and Meena, 2016).",1 Introduction,[0],[0]
"In other words, we do not know whether two consecutive sentences are part of the same dialogue turn or were uttered by different speakers.",1 Introduction,[0],[0]
"The neural conversation model may therefore inadvertently learn responses that remain within the same dialogue turn instead of starting a new turn.
",1 Introduction,[0],[0]
"Furthermore, these dialogues contain multiple references to named entities (in particular, person names such as fictional characters) that are specific to the dialogue in question.",1 Introduction,[0],[0]
"These named entities should ideally not be part of the conversation model, since they often draw on an external context that is absent from the inputs provided to the conversation model.",1 Introduction,[0],[0]
"For instance, the mention of character names in a movie is associated with a visual context (for instance, the characters appearing in a given scene) that is not captured in the training data.",1 Introduction,[0],[0]
"Finally, a substantial portion of the utterances observed in these corpora is made of neutral, commonplace responses (“Perhaps”, “I
384
don’t know”, “Err”, ...) that can be used in most conversational situations but fall short of creating meaningful and engaging conversations with human users (Li et al., 2016a).
",1 Introduction,[0],[0]
The present paper addresses these limitations by adding a weighting model to the neural architecture.,1 Introduction,[0],[0]
"The purpose of this model is to associate each 〈context, response〉 example pair to a numerical weight that reflects the intrinsic “quality” of each example.",1 Introduction,[0],[0]
The instance weights are then included in the empirical loss to minimise when learning the parameters of the neural conversation model.,1 Introduction,[0.9503062405350127],"['Finally, the algorithm requires every node to complete its gradient computation before aggregating them on the master node, and the efficiency of the algorithm thus depends on the slowest of all machines.']"
The weights are themselves computed via a neural model learned from dialogue data.,1 Introduction,[0],[0]
Experimental results demonstrate that the use of instance weights improves the performance of neural conversation models on unsupervised metrics.,1 Introduction,[0],[0]
"Human evaluation results are, however, inconclusive.
",1 Introduction,[0],[0]
The rest of this paper is as follows.,1 Introduction,[0],[0]
The next section presents a brief overview of existing work on neural conversation models.,1 Introduction,[0],[0]
Section 3 provides a description of the instance weighting approach.,1 Introduction,[0],[0]
"Section 4 details the experimental validation of the proposed model, using both unsupervised metrics and a human evaluation of the selected responses.",1 Introduction,[0],[0]
"Finally, Section 5 discusses the advantages and limitations of the approach, and Section 6 concludes this paper.",1 Introduction,[0],[0]
Neural conversation models are a family of neural architectures (generally based on deep convolutional or recurrent networks) used to represent mappings between dialogue contexts (or queries) and possible responses.,2 Related Work,[0],[0]
"Compared to previous statistical approaches to dialogue modelling based on Markov processes (Levin et al., 2000; Rieser and Lemon, 2011; Young et al., 2013), one benefit of these neural models is their ability to be estimated from raw dialogue corpora, without having to rely on additional annotation layers for intermediate representations such as state variables or dialogue acts.",2 Related Work,[0],[0]
"Rather, neural conversation models automatically derive latent representations of the dialogue state based on the observed utterances.
",2 Related Work,[0],[0]
"Neural conversation models can be divided into two main categories, retrieval models and generative models.",2 Related Work,[0],[0]
"Retrieval models are used to select the most relevant response for a given context amongst a (possibly large) set of predefined responses, such as the set of utterances extracted
from a corpus (Lowe et al., 2015; Prakash et al., 2016).",2 Related Work,[0],[0]
"Generative models, on the other hand, rely on sequence-to-sequence models (Sordoni et al., 2015) to generate new, possibly unseen responses given the provided context.",2 Related Work,[0],[0]
"These models are built by linking together two recurrent architectures: one encoder which maps the sequence of input tokens in the context utterance(s) to a fixedsized vector, and one decoder that generates the response token by token given the context vector (Vinyals and Le, 2015; Sordoni et al., 2015).",2 Related Work,[0],[0]
"Recent papers have shown that the performance of these generative models can be improved by incorporating attentional mechanisms (Yao et al., 2016) and accounting for the structure of conversations through hierarchical networks (Serban et al., 2016).",2 Related Work,[0.9652920047995222],"['Given the numerous applications of distributed optimization in machine learning, many algorithms have recently emerged, that allow the minimization of objective functions f defined as the average 1n ∑n i=1 fi of functions fi which are respectively accessible by separate nodes in a network (Nedic & Ozdaglar, 2009; Boyd et al., 2011; Duchi et al., 2012; Shi et al., 2015).']"
"Neural conversation models can also be learned using adversarial learning (Li et al., 2017).",2 Related Work,[0],[0]
"In this setting, two neural models are jointly learned: a generative model producing the response, and a discriminator optimised to distinguish between human-generated responses and machine-generated ones.",2 Related Work,[0],[0]
"The discriminator outputs are then used to bias the generative model towards producing more human-like responses.
",2 Related Work,[0],[0]
"The linguistic coherence and diversity of the models can be enhanced by including speakeraddressee information (Li et al., 2016b) and by expressing the objective function in terms of Maximum Mutual Information to enhance the diversity of the generated responses (Li et al., 2016a).",2 Related Work,[0],[0]
"As demonstrated by (Ghazvininejad et al., 2017), neural conversation models can also be combined with external knowledge sources in the form of factual information or entity-grounded opinions, which is an important requirement for developing task-oriented dialogue systems that must ground their action in an external context.
",2 Related Work,[0],[0]
"Dialogue is a sequential decision-making process where the conversational actions of each participant influence not only the current turn but the long-term evolution of the dialogue (Levin et al., 2000).",2 Related Work,[0],[0]
"To incorporate the prediction of future outcomes in the generation process, several papers have explored the use of reinforcement learning techniques, using deep neural networks to model the expected future reward (Li et al., 2016c; Cuayáhuitl, 2017).",2 Related Work,[0],[0]
"In particular, the Hybrid Code Networks model of (Williams et al., 2017) demonstrate how a mixture of supervised learning, reinforcement learning and domain-specific knowl-
edge can be used to optimise dialogue strategies from limited amount of training data.
",2 Related Work,[0],[0]
"In contrast with the approaches outlined above, this paper does not present a new neural architecture for conversational models.",2 Related Work,[0],[0]
"Rather, it investigates how the performance of existing models can be improved “upstream”, by adapting how these models can be trained on large, noisy corpora with varying levels of quality.",2 Related Work,[0],[0]
"It should be noted that, although the experiments presented in Section 4 focus on a limited range of neural models, the approach presented in this paper is designed to be model-independent and can be applied as a preprocessing step to any data-driven model of dialogue.",2 Related Work,[0],[0]
"As mentioned in the introduction, the interactions extracted from large dialogue corpora do not all have the same intrinsic quality, due for instance to the frequent lack of turn segmentation or the presence of external, unresolvable references to person names.",3 Approach,[0],[0]
"In other words, there is a discrepancy between the actual 〈context, response〉 pairs found in these corpora and the conversational patterns that should be accounted for in the neural model.
",3 Approach,[0],[0]
"One way to address this discrepancy is by framing the problem as one of domain adaptation, the source domain being the original dialogue corpus and the target domain representing the dialogues we want our model to produce.",3 Approach,[0.9504201104795555],"['This algorithm has three limitations: first, the algorithm is not robust to machine failures, and the central role played by the master node also means that a failure of this particular machine may completely freeze the procedure.']"
"The target domain is in this case not necessarily another dialogue domain, but simply reflects the fact that the distribution of responses in the raw corpus does not necessarily reflect the distribution of responses we ultimately wish to encode in the conversational model.
",3 Approach,[0],[0]
"A popular strategy for domain adaptation in natural language processing, which has notably been used in POS-tagging, sentiment analysis, spam filtering and machine translation (Bickel et al., 2007; Jiang and Zhai, 2007; Foster et al., 2010; Xia et al., 2013), is to assign a higher weight to training instances whose properties are similar to the target domain.",3 Approach,[0],[0]
We present below such an instance weighting approach tailored for neural conversational models.,3 Approach,[0],[0]
"The quality of a particular 〈context, response〉 pair is difficult to determine using handcrafted rules – for instance, the probability of a turn bound-
ary may depend on multiple factors such as the presence of turn-yielding cues or the time gap between the utterances (Lison and Meena, 2016).",3.1 Weighting model,[0],[0]
"To overcome these limitations, we adopt a datadriven approach and automatically learn a weighting model from examples of “high-quality” responses.",3.1 Weighting model,[0],[0]
"What constitutes a high-quality response depends in practice on the specific criteria we wish to uphold in the conversation model – for instance, favouring responses that are likely to form a new dialogue turn (rather than a continuation of the current turn), avoiding the use of dull, commonplace responses, or disfavouring the selection of responses that contain unresolved references to person names.
",3.1 Weighting model,[0],[0]
"The weighting model can be expressed as a neural model which associates each 〈context, response〉 example pair to a numerical weight.",3.1 Weighting model,[0],[0]
The architecture of this neural network is depicted in Figure 1.,3.1 Weighting model,[0],[0]
"It is composed of two recurrent sub-networks with shared weights, one for the context and one for the response.",3.1 Weighting model,[0],[0]
Each sub-network takes a sequence of tokens as input and pass them through an embedding layer and a recurrent layer with LSTM or GRU cells.,3.1 Weighting model,[0],[0]
"The fixed-size vectors for the context and response are then fed to a regular densely-connected layer, and finally to the final weight value through a sigmoid activation function.",3.1 Weighting model,[0],[0]
"Additional features can also be included whenever available – for instance, timing information for movie and TV subtitles (such as the duration gap between the context and its response, in milliseconds), or document-level features such as the dialogue genre or the total duration of the dialogue.
",3.1 Weighting model,[0],[0]
"To estimate its parameters, the neural model is provided with positive examples of “high-quality” responses along with negative examples sampled at random from the corpus.",3.1 Weighting model,[0],[0]
"Based on this training data, the network learns to assign higher weights to the 〈context, response〉 pairs whose output vectors (combined with the additional inputs) are close from the high-quality examples, and a lower weight for those further away.",3.1 Weighting model,[0],[0]
"In practice, the selection of high-quality example pairs from a given corpus can be performed through a combination of simple heuristics, as detailed in Section 4.1.",3.1 Weighting model,[0],[0]
"Once the weighting model is estimated, the next step is to run it on the entire dia-
logue corpus to compute the expected weight of each 〈context, response〉 pair.",3.2 Instance weighting,[0],[0]
These sample weights are then included in the empirical loss that is being minimised during training.,3.2 Instance weighting,[0],[0]
"Formally, assuming a set of context-response pairs {(c1, r1), (c2, r2), ...(cn, rn)} with associated weights {w1, ...wn}, the estimation of the model parameters θ is expressed as a minimisation problem.",3.2 Instance weighting,[0],[0]
"For retrieval models, this minimisation is expressed as:
θ∗ = minθ n∑ 1 wi L(yi, f(ci, ri; θ)) (1)
where L is a loss function (for instance, the cross-entropy loss), and yi is set to either 1 if ri is the response to ci, and 0 otherwise (when ri is a negative example).",3.2 Instance weighting,[0],[0]
"For generative models, the minimisation is similarly expressed as:
θ∗ = minθ n∑ 1 wi L(ri, f(ci; θ)) (2)
",3.2 Instance weighting,[0],[0]
"In both cases, the loss computed from each example pair is multiplied by the weight value determined by the weight model.",3.2 Instance weighting,[0],[0]
Examples associated with a larger weight wi will therefore have a larger influence on the gradient update steps.,3.2 Instance weighting,[0],[0]
"The approach is evaluated on the basis of retrievalbased neural models trained on English-language subtitles from (Lison and Tiedemann, 2016).",4 Evaluation,[0],[0]
"Three alternative models are evaluated:
1.",4 Evaluation,[0],[0]
"A traditional TF-IDF model,
2.",4 Evaluation,[0],[0]
"A Dual Encoder model trained directly on the corpus examples,
3.",4 Evaluation,[0],[0]
A Dual Encoder model combined with the weighting model from Section 3.1.,4 Evaluation,[0],[0]
"TF-IDF model The TF-IDF (Term Frequency - Inverse Document Frequency) model computes the similarity between the context and its response using methods from information retrieval (Ramos, 2003).",4.1 Models,[0],[0]
TFIDF measures the importance of a word in a “document” (in this case the context or response) relative to the whole corpus.,4.1 Models,[0],[0]
The model transforms the context and response (represented as bag-ofwords) into TF-IDF-weighted vectors.,4.1 Models,[0],[0]
"These vectors are sparse vectors of a size equivalent to the vocabulary size, where each row corresponds, if the given word is present in the context or response, to its TF-IDF weight, and is 0 otherwise.",4.1 Models,[0],[0]
"The matching score between the context and its response is then determined as the cosine similarity between the two vectors:
similarity = vc · vr
‖vc‖2 ‖vr‖2 (3)
where vc and vr respectively denote the TF-IDFweighted vectors for the context and response.
",4.1 Models,[0],[0]
"Dual Encoder The Dual Encoder model (Lowe et al., 2017) consists of two recurrent networks, one for the context and one for the response.",4.1 Models,[0],[0]
"The tokens are first
passed through an embedding layer and then to a recurrent layer with LSTM or GRU cells.",4.1 Models,[0],[0]
"In the original formalisation of this model (Lowe et al., 2015), the context vector is transformed through a dense layer of same dimension, representing the “predicted” response.",4.1 Models,[0],[0]
"The inner product of the predicted and actual responses is then calculated and normalised, yielding a similarity score.",4.1 Models,[0],[0]
"This model, however, only seeks to capture the semantic similarity between the two sequences, while the selection of the most adequate response in a given context may also need to account for other factors such as the grammaticality and coherence of the response.",4.1 Models,[0],[0]
We therefore extend the Dual Encoder model in two ways.,4.1 Models,[0],[0]
"First, both the context and response vectors are transformed through a dense layer at the end of the recurrent layer (instead of just the context vector).",4.1 Models,[0],[0]
"Second, the final prediction is connected to both the inner product of the two vectors and to the response vector itself, as depicted in Figure 2.
",4.1 Models,[0],[0]
"Dual Encoder with instance weighting
Finally, the third model relies on the exact same Dual Encoder model as above, but applies the weighting model described in Section 3.1 prior to learning in order to assign weights to each training example.",4.1 Models,[0],[0]
The weighting model is estimated on a subset of the movie and TV subtitles augmented with speaker information and filtered through heuristics to ensure a good cohesion between the context and its response.,4.1 Models,[0],[0]
"These heuristics are detailed in the next section.
",4.1 Models,[0],[0]
"Although the architecture of the Dual Encoder
is superficially similar to the weighting model of Figure 1, the two models serve a different purpose: the weighting model returns the expected quality of a training example, while the Dual Encoder returns a score expressing the adequacy between the context and the response.",4.1 Models,[0],[0]
"Training data for the conversation models The dataset used for training the three retrieval models is the English-language portion of the OpenSubtitles corpus of movie and TV subtitles (Lison and Tiedemann, 2016).",4.2 Datasets,[0],[0]
"The full dataset is composed of 105 445 subtitles and 95.5 million utterances, each utterance being associated with a start and end time (in milliseconds).
",4.2 Datasets,[0],[0]
"Training data for the weighting model For training the weighting model, we extracted a small subset of the full corpus of subtitles corresponding to 〈context, response〉 pairs satisfying specific quality criteria.",4.2 Datasets,[0],[0]
"The first step was to align at the sentence level the subtitles with an online collection of movie and TV scripts (1 069 movies and 6 398 TV episodes), following the approach described in (Lison and Meena, 2016).
",4.2 Datasets,[0],[0]
This alignment enabled us to annotate the subtitles with speaker names and turn boundaries.,4.2 Datasets,[0],[0]
"Based on these subtitles, we then selected example pairs with two heuristics:
1.",4.2 Datasets,[0],[0]
"To ensure the response constitutes an actual reply from another speaker and not simply a continuation of the current turn, the
subtitles were segmented into sub-dialogues.",4.2 Datasets,[0],[0]
"〈context, response〉 pairs including a change of speaker from the context to the response were then extracted from these subdialogues.",4.2 Datasets,[0],[0]
"Since multi-party dialogues make it harder to determine who replies to whom, only sub-dialogues with two participants were considered in the subset.
",4.2 Datasets,[0],[0]
2.,4.2 Datasets,[0],[0]
"To ensure the response is intelligible given the context (without drawing on unresolved references to e.g. fictional person names), we also filtered out from the subset the dialogue turns including mentions of fictional character names and out-of-vocabulary words.
",4.2 Datasets,[0],[0]
"A total of 95 624 〈context, response〉 pairs can be extracted using these two heuristics.",4.2 Datasets,[0],[0]
This corresponds to about 0.1 % of the total number of examples for the OpenSubtitles corpus.,4.2 Datasets,[0],[0]
"These pairs are used as positive examples for the weighting model, along with negative pairs sampled at random from the corpus.
Test data Two distinct corpora are used as test sets for the evaluation.",4.2 Datasets,[0],[0]
"The first corpus, whose genre is relatively close to the training set, is the Cornell Movie Dialog Corpus (Danescu-Niculescu-Mizil and Lee, 2011), which is a collection of fictional conversations extracted from movie scripts (unrelated to the ones used for training the weighting model).",4.2 Datasets,[0],[0]
The transcripts from this corpus are segmented into conversations.,4.2 Datasets,[0],[0]
Each conversation is represented as a sequence of dialogue turns.,4.2 Datasets,[0],[0]
"As this paper concentrates on the selection of relevant responses in a given context, we limited the test pairs to the ones where the context ends with a question, which yields a total of 67 305 〈context, response〉 pairs.
",4.2 Datasets,[0],[0]
"The second test set comes from a slightly different conversational genre, namely theatre plays.",4.2 Datasets,[0],[0]
The scripts of 62 English-language theatre plays were downloaded from public websites.,4.2 Datasets,[0],[0]
"We also limited the test pairs to the pairs where the context ends with a question, for a total of 3 427 pairs.",4.2 Datasets,[0],[0]
"The utterances from all datasets were tokenised, lemmatised and POS-tagged using the spaCy NLP library1.",4.2.1 Experimental design Preprocessing,[0],[0]
"We also ran the named entity recogniser
1https://spacy.io/
from the same library to extract named entities.",4.2.1 Experimental design Preprocessing,[0],[0]
"Since the person names mentioned in movies and theatre plays typically refer to fictional characters, we replaced their occurrences by tags, one distinct tag per entity.",4.2.1 Experimental design Preprocessing,[0],[0]
"For instance, the pair:
Dana: Frank, do you think you could give me a hand with these bags?",4.2.1 Experimental design Preprocessing,[0],[0]
"Frank: I’m not a doorman, Miss Barrett.",4.2.1 Experimental design Preprocessing,[0],[0]
"I’m a building superintendent.
is simplified as:
Dana: <person1>, do you think you could give me a hand with these bags?",4.2.1 Experimental design Preprocessing,[0],[0]
"Frank: I’m not a doorman, <person2>.",4.2.1 Experimental design Preprocessing,[0],[0]
"I’m a building superintendent.
",4.2.1 Experimental design Preprocessing,[0],[0]
Named entities of locations and numbers are also replaced by similar tags.,4.2.1 Experimental design Preprocessing,[0],[0]
"To account for the turn structure, turn boundaries were annotated with a <newturn> tag.",4.2.1 Experimental design Preprocessing,[0],[0]
The vocabulary is capped to 25 000 words determined from their frequency in the training corpus.,4.2.1 Experimental design Preprocessing,[0],[0]
"Tokens not covered in this vocabulary are replaced by <unknown>.
",4.2.1 Experimental design Preprocessing,[0],[0]
"Training details
The dialogue contexts were limited to the last 10 utterances preceding the response and a maximum of 60 tokens.",4.2.1 Experimental design Preprocessing,[0],[0]
"The responses were defined as the next dialogue turn after the context, and limited to a maximum of 5 utterances and 30 tokens.
",4.2.1 Experimental design Preprocessing,[0],[0]
The embedding layers of the Dual Encoders were initialised with Skip-gram embeddings trained on the OpenSubtitles corpus.,4.2.1 Experimental design Preprocessing,[0],[0]
"For the recurrent layers, we tested the use of both GRU and LSTM cells, along with their bidirectional equivalents (Chung et al., 2014), without noticeable differences in accuracy.",4.2.1 Experimental design Preprocessing,[0],[0]
"As GRU cells are faster to train than LSTM cells, we opted for the use of GRU-based recurrent layers.",4.2.1 Experimental design Preprocessing,[0],[0]
The dimensionality of the output vectors from the recurrent layers was 400.,4.2.1 Experimental design Preprocessing,[0],[0]
"The neural networks are trained with a batch size of 256, binary cross-entropy as cost function and RMSProp as optimisation algorithm.",4.2.1 Experimental design Preprocessing,[0],[0]
"To avoid overfitting issues, a dropout of 0.2 was applied at all layers of the neural model.
",4.2.1 Experimental design Preprocessing,[0],[0]
"Both the weighting model and the Dual Encoder models were training with a 1:1 ratio between positive examples (actual 〈 context, response 〉 pairs) and negative examples with a response sampled at random from the training set.",4.2.1 Experimental design Preprocessing,[0],[0]
"The three models (the TF-IDF model, the baseline Dual Encoder and the Dual Encoder combined with the weighting model) are evaluated using the Recallm@i metric, which is the most common metric for the evaluation of retrieval-based models.",4.3 Results,[0],[0]
"Let {〈ci, ri〉, 1 ≤ i ≤ n} be the list of m context-response pairs from the test set.",4.3 Results,[0],[0]
"For each context ci, we create a set ofm alternative responses, one response being the actual response ri, and them−1 other responses being sampled at random from the same corpus.",4.3 Results,[0],[0]
"The m alternative responses are then ranked based on the output from the conversational model, and the Recallm@imeasures how often the correct response appears in the top i results of this ranked list.",4.3 Results,[0],[0]
"The Recallm@i metric is often used for the evaluation of retrieval models as several responses may be equally “correct” given a particular context.
",4.3 Results,[0],[0]
The experimental results are shown in Table 1.,4.3 Results,[0],[0]
"As detailed in the table, the Dual Encoder model combined with the weighting model outperforms the Dual Encoder baseline on both test sets (the Cornell Movie Dialogs corpus and the smaller corpus of theatre plays).",4.3 Results,[0],[0]
"Our hypothesis is that the weighting model biases the responses selected by the conversation model towards more cohesive adjacency pairs between context and response2.
",4.3 Results,[0],[0]
"Figure 3 illustrates the learning curve for the two Dual Encoder models, where the accuracy is measured on a validation set composed of the high-quality example pairs described in the previous section along with randomly sampled alternative responses (using a 1:1 ratio of positive vs. negative examples).",4.3 Results,[0.9541844273265244],['(9) We will see in the next section that this lower bound is met for a novel decentralized algorithm called multi-step dual accelerated (MSDA) and based on the dual formulation of the optimization problem.']
"We can observe that the Dual Encoder with instance weights outperforms the baseline model on this validation set – which is not per se a surprising result, since the purpose
2Contrary to the OpenSubtitles corpus which is made of subtitles with no turn segmentation, the Cornell Movie Dialogs corpus and the corpus of theatre plays are derived from scripts and are therefore segmented in dialogue turns.
of the weighting model is precisely to bias the conversation model to give more importance to these types of example pairs.",4.3 Results,[0],[0]
"To further investigate the potential of this weighting strategy for neural conversational models, we conducted a human evaluation of the responses generated by the two neural models included in the evaluation.",4.4 Human evaluation,[0],[0]
"We collected human judgements on 〈context, response〉 pairs using a crowdsourcing platform.",4.4 Human evaluation,[0],[0]
"We extracted 115 random contexts from the Cornell Movie Dialogs corpus and used four distinct strategies to generate dialogue responses: a random predictor (used to identify the lower bound), the two Dual Encoder models (both without and with instance weights), and expert responses (used to identify the upper bound).",4.4 Human evaluation,[0],[0]
The expert responses were manually authored by two human annotators.,4.4 Human evaluation,[0],[0]
"The resulting 460 〈context, response〉 pairs were evaluated by 8 distinct human judges each (920 ratings per model).",4.4 Human evaluation,[0],[0]
"The human judges were asked to rate the consistency between context and response on a 5-points scale, from Inconsistent to Consistent.",4.4 Human evaluation,[0],[0]
"In total,
118 individuals participated in the crowdsourced evaluation.
",4.4 Human evaluation,[0],[0]
The results of this human evaluation are presented in Figure 4.,4.4 Human evaluation,[0],[0]
"There is unfortunately no statistically significant difference between the baseline Dual Encoder (M = 2.97, SD = 1.27) and the one combined with the weighting model (M = 3.04, SD = 1.27), as established by a Wilcoxon rank-sum test, W (1838) = 410360, p = 0.23.",4.4 Human evaluation,[0],[0]
These inconclusive results are probably due to the very low agreement between the evaluation participants (Krippendorff’s α for continuous variable = 0.36).,4.4 Human evaluation,[0],[0]
The fact that the lower and upper bounds are only separated by 2 standard deviations confirms the difficulty for the raters to discriminate between responses.,4.4 Human evaluation,[0],[0]
"We hypothesise that the nature of the corpus, which is heavily dependent on an external context (the movie scenes), makes it particularly difficult to assess the consistency of the responses.
",4.4 Human evaluation,[0],[0]
Some examples of responses produced by the two Dual Encoder models illustrate the improvements brought by the weighting model.,4.4 Human evaluation,[0],[0]
"In (1), the baseline Dual Encoder selected a turn continuation rather than a reply, while the second model avoids this pitfall.",4.4 Human evaluation,[0],[0]
"Both (1) and (2) also show that the dual encoder with instance weighting tends to select utterances with fewer named entities.
",4.4 Human evaluation,[0],[0]
(1) Context of conversation: – This is General Ripper speaking.,4.4 Human evaluation,[0],[0]
"– Yes, sir. –",4.4 Human evaluation,[0],[0]
Do you recognize my voice?”,4.4 Human evaluation,[0],[0]
"⇒ Response of Dual Encoder: – This is General Nikolas Pherides, Commander of the Third Army.",4.4 Human evaluation,[0],[0]
"I’m Oliver
Davis.",4.4 Human evaluation,[0],[0]
⇒,4.4 Human evaluation,[0],[0]
"Response of Dual Encoder + weighting: – Yes, sir.",4.4 Human evaluation,[0],[0]
"I’m Gideon.
(2) Context of conversation: – Let me finish dinner before you eat it...",4.4 Human evaluation,[0],[0]
Chop the peppers... – Are you all right?,4.4 Human evaluation,[0],[0]
⇒,4.4 Human evaluation,[0],[0]
"Response of Dual Encoder: – No thanks, not hungry.",4.4 Human evaluation,[0],[0]
Harry Dunne. ⇒,4.4 Human evaluation,[0],[0]
Response of Dual Encoder + weighting: –,4.4 Human evaluation,[0],[0]
Yes I’m fine.,4.4 Human evaluation,[0],[0]
Everything is ok.,4.4 Human evaluation,[0],[0]
"The limitations of neural conversational models trained on large, noisy dialogue corpora such as movie and TV subtitles have been discussed in several papers.",5 Discussion,[0],[0]
"Some of the issues raised in previous papers are the absence of turn segmentation in subtitling corpus (Vinyals and Le, 2015; Serban and Pineau, 2015; Lison and Meena, 2016), the lack of long-term consistency and “personality” in the generated responses (Li et al., 2016b), and the ubiquity of dull, commonplace responses when training generative models (Li et al., 2016a).",5 Discussion,[0],[0]
"To the best of our knowledge, this paper is the first to propose an instance weighting approach to address some of these limitations.",5 Discussion,[0],[0]
"One related approach is described in (Zhang et al., 2017) which also relies on domain adaptation for neural response generation, using a combination of online and offline human judgement.",5 Discussion,[0],[0]
"Their focus is, however, on the construction of personalised conversation models and not on instance weighting.
",5 Discussion,[0],[0]
The empirical results corroborate the hypothesis that assigning weights to the training examples of “noisy” dialogue corpora can boost the performance of neural conversation models.,5 Discussion,[0],[0]
"In essence, the proposed approach replaces a one-pass training regime with a two-pass procedure: the first pass to determine the quality of each example pair, and a second pass to update the model based on the observed pair and its associated weight.",5 Discussion,[0],[0]
"We also showed that these weights can be determined in a data-driven manner with a neural model trained on example pairs selected for their adherence to specific quality criteria.
",5 Discussion,[0],[0]
"Instead of this two-pass procedure, an alternative approach is to directly learn a conversation model on the subset of example pairs that are known to be of high-quality.",5 Discussion,[0],[0]
"However, one major shortcoming of this approach is that it consider-
ably limits the size of the training set that can be exploited.",5 Discussion,[0],[0]
"For instance, the data used to estimate the weighting model in Section 4.2 corresponds to a mere 0.1 % of the total English-language part of the OpenSubtitles corpus (since the utterances had to be associated with speaker names derived from aligned scripts in order to apply the heuristics).",5 Discussion,[0],[0]
"In contract, the proposed two-pass procedure can scale to datasets of any size.
",5 Discussion,[0],[0]
The results from Section 4 are limited to retrieval-based models.,5 Discussion,[0],[0]
"One important question for future work is to investigate whether the results carry over to generative, sequence-to-sequence models.",5 Discussion,[0],[0]
"As generative models are more computationally intensive to train than retrieval models, the presented approach may bring another important benefit, namely the ability to filter out part of the training data to concentrate the training time on “interesting” examples with a high cohesion between the context and its response.",5 Discussion,[0],[0]
Dialogue corpora such as chat logs or movie subtitles are very useful resources for developing opendomain conversation models.,6 Conclusion,[0],[0]
"They do, however, also raise a number of challenges for conversation modelling.",6 Conclusion,[0],[0]
"Two notable challenges are the lack of segmentation in dialogue turns (at least for the movie subtitles) and the presence of external context that is not captured in the dialogue transcripts themselves (leading to mentions of person names and unresolvable named entities).
",6 Conclusion,[0],[0]
This paper showed how to mitigate these challenges through the use of a weighting model applied on the training examples.,6 Conclusion,[0],[0]
"This weighting model can be estimated in a data-driven manner, by providing example of “high-quality” training pairs along with random pairs extracted from the same corpus.",6 Conclusion,[0],[0]
The criteria that determine how these training pairs should be selected depend in practice on the type of conversational model one wishes to learn.,6 Conclusion,[0],[0]
"This instance weighting approach can be viewed as a form of domain adaptation, where the data points from the source domain (in this case, the original corpus) are re-weighted to improve the model performance in a target domain (in this case, the interactions in which the conversation model will be deployed).
",6 Conclusion,[0],[0]
Evaluation results on retrieval-based neural models demonstrate the potential of this approach.,6 Conclusion,[0],[0]
"The weighting model is essentially a preprocess-
ing step and can therefore be combined with any type of conversational model.
",6 Conclusion,[0],[0]
Future work will focus on two directions.,6 Conclusion,[0],[0]
"The first is to extend the weighting model to account for other criteria, such as ensuring diversity of responses and coherence across turns.",6 Conclusion,[0],[0]
"The second is to evaluate the approach on other types of neural conversational models, and more particularly on generative models.",6 Conclusion,[0],[0]
"Neural conversational models require substantial amounts of dialogue data to estimate their parameters and are therefore usually learned on large corpora such as chat forums, Twitter discussions or movie subtitles.",abstractText,[0],[0]
"These corpora are, however, often challenging to work with, notably due to their frequent lack of turn segmentation and the presence of multiple references external to the dialogue itself.",abstractText,[0],[0]
This paper shows that these challenges can be mitigated by adding a weighting model into the neural architecture.,abstractText,[0],[0]
"The weighting model, which is itself estimated from dialogue data, associates each training example to a numerical weight that reflects its intrinsic quality for dialogue modelling.",abstractText,[0],[0]
"At training time, these sample weights are included into the empirical loss to be minimised.",abstractText,[0],[0]
Evaluation results on retrieval-based models trained on movie and TV subtitles demonstrate that the inclusion of such a weighting model improves the model performance on unsupervised metrics.,abstractText,[0],[0]
Not All Dialogues are Created Equal: Instance Weighting for Neural Conversational Models,title,[0],[0]
"We propose to mitigate this phenomenon with a principled importance sampling scheme that focuses computation on “informative” examples, and reduces the variance of the stochastic gradients during training. Our contribution is twofold: first, we derive a tractable upper bound to the persample gradient norm, and second we derive an estimator of the variance reduction achieved with importance sampling, which enables us to switch it on when it will result in an actual speedup.
The resulting scheme can be used by changing a few lines of code in a standard SGD procedure, and we demonstrate experimentally, on image classification, CNN fine-tuning, and RNN training, that for a fixed wall-clock time budget, it provides a reduction of the train losses of up to an order of magnitude and a relative improvement of test errors between 5% and 17%.",text,[0],[0]
"The dramatic increase in available training data has made the use of deep neural networks feasible, which in turn has significantly improved the state-of-the-art in many fields, in particular computer vision and natural language processing.",1. Introduction,[0],[0]
"However, due to the complexity of the resulting optimization problem, computational cost is now the core issue in training these large architectures.
",1. Introduction,[0],[0]
"When training such models, it appears to any practitioner that not all samples are equally important; many of them are properly handled after a few epochs of training, and most could be ignored at that point without impacting the final
1Idiap Research Institute, Switzerland 2École Polytechique Fédérale de Lausanne, Switzerland.",1. Introduction,[0],[0]
"Correspondence to: Angelos Katharopoulos <firstname.lastname@idiap.ch>.
model.",1. Introduction,[0],[0]
"To this end, we propose a novel importance sampling scheme that accelerates the training of any neural network architecture by focusing the computation on the samples that will introduce the biggest change in the parameters which reduces the variance of the gradient estimates.
",1. Introduction,[0],[0]
"For convex optimization problems, many works (Bordes et al., 2005; Zhao & Zhang, 2015; Needell et al., 2014; Canévet et al., 2016; Richtárik & Takáč, 2013) have taken advantage of the difference in importance among the samples to improve the convergence speed of stochastic optimization methods.",1. Introduction,[0.9621751465339637],"['A large body of literature considers a decentralized approach to distributed optimization based on the gossip algorithm (Boyd et al., 2006; Nedic & Ozdaglar, 2009; Duchi et al., 2012; Wei & Ozdaglar, 2012).']"
"On the other hand, for deep neural networks, sample selection methods were mainly employed to generate hard negative samples for embedding learning problems or to tackle the class imbalance problem (Schroff et al., 2015; Wu et al., 2017; Simo-Serra et al., 2015).
",1. Introduction,[0],[0]
"Recently, researchers have shifted their focus on using importance sampling to improve and accelerate the training of neural networks (Alain et al., 2015; Loshchilov & Hutter, 2015; Schaul et al., 2015).",1. Introduction,[0],[0]
"Those works, employ either the gradient norm or the loss to compute each sample’s importance.",1. Introduction,[0],[0]
"However, the former is prohibitively expensive to compute and the latter is not a particularly good approximation of the gradient norm.
",1. Introduction,[0],[0]
"Compared to the aforementioned works, we derive an upper bound to the per sample gradient norm that can be computed in a single forward pass.",1. Introduction,[0],[0]
This results in reduced computational requirements of more than an order of magnitude compared to Alain et al. (2015).,1. Introduction,[0],[0]
"Furthermore, we quantify the variance reduction achieved with the proposed importance sampling scheme and associate it with the batch size increment required to achieve an equivalent variance reduction.",1. Introduction,[0],[0]
"The benefits of this are twofold, firstly we provide an intuitive metric to predict how useful importance sampling is going to be, thus we are able to decide when to switch on importance sampling during training.",1. Introduction,[0],[0]
"Secondly, we also provide theoretical guarantees for speedup, when variance reduction is above a threshold.",1. Introduction,[0],[0]
"Based on our analysis, we propose a simple to use algorithm that can be used to accelerate the training of any neural network architecture.
",1. Introduction,[0],[0]
"Our implementation is generic and can be employed by adding a single line of code in a standard Keras model
ar X
iv :1
80 3.
00 94
2v 3
[ cs
.L G
] 2
8 O
ct 2
01 9
training.",1. Introduction,[0],[0]
"We validate it on three independent tasks: image classification, fine-tuning and sequence classification with recurrent neural networks.",1. Introduction,[0],[0]
"Compared to existing batch selection schemes, we show that our method consistently achieves lower training loss and test error for equalized wall-clock time.",1. Introduction,[0],[0]
Existing importance sampling methods can be roughly categorized in methods applied to convex problems and methods designed for deep neural networks.,2. Related Work,[0],[0]
Importance sampling for convex optimization problems has been extensively studied over the last years.,2.1. Importance Sampling for Convex Problems,[0],[0]
"Bordes et al. (2005) developed LASVM, which is an online algorithm that uses importance sampling to train kernelized support vector machines.",2.1. Importance Sampling for Convex Problems,[0],[0]
"Later, Richtárik & Takáč (2013) proposed a generalized coordinate descent algorithm that samples coordinate sets in a way that optimizes the algorithm’s convergence rate.
",2.1. Importance Sampling for Convex Problems,[0],[0]
"More recent works (Zhao & Zhang, 2015; Needell et al., 2014) make a clear connection with the variance of the gradient estimates of stochastic gradient descent and show that the optimal sampling distribution is proportional to the per sample gradient norm.",2.1. Importance Sampling for Convex Problems,[0.9523543728735717],"['Indeed, (a) for a single machine the optimal number of gradient steps to optimize a function is proportional to the square root of the condition number (Nesterov, 2004), and (b) for mean estimation, the optimal number of communication steps is proportional to the diameter of the network in centralized problems or to the square root of the eigengap of the Laplacian matrix in decentralized problems (Boyd et al., 2006).']"
"Due to the relatively simple optimization problems that they deal with, the authors resort to sampling proportionally to the norm of the inputs, which in simple linear classification is proportional to the Lipschitz constant of the per sample loss function.
",2.1. Importance Sampling for Convex Problems,[0],[0]
"Such simple importance measures do not exist for Deep Learning and the direct application of the aforementioned theory (Alain et al., 2015), requires clusters of GPU workers just to compute the sampling distribution.",2.1. Importance Sampling for Convex Problems,[0],[0]
Importance sampling has been used in Deep Learning mainly in the form of manually tuned sampling schemes.,2.2. Importance Sampling for Deep Learning,[0],[0]
Bengio et al. (2009) manually design a sampling scheme inspired by the perceived way that human children learn; in practice they provide the network with examples of increasing difficulty in an arbitrary manner.,2.2. Importance Sampling for Deep Learning,[0],[0]
"Diametrically opposite, it is common for deep embedding learning to sample hard examples because of the plethora of easy non informative ones (Simo-Serra et al., 2015; Schroff et al., 2015).
",2.2. Importance Sampling for Deep Learning,[0],[0]
"More closely related to our work, Schaul et al. (2015) and Loshchilov & Hutter (2015) use the loss to create the sampling distribution.",2.2. Importance Sampling for Deep Learning,[0],[0]
"Both approaches keep a history of losses for previously seen samples, and sample either proportionally to the loss or based on the loss ranking.",2.2. Importance Sampling for Deep Learning,[0],[0]
"One of the
main limitations of history based sampling, is the need for tuning a large number of hyperparameters that control the effects of “stale” importance scores; i.e. since the model is constantly updated, the importance of samples fluctuate and previous observations may poorly reflect the current situation.",2.2. Importance Sampling for Deep Learning,[0],[0]
"In particular, Schaul et al. (2015) use various forms of smoothing for the losses and the importance sampling weights, while Loshchilov & Hutter (2015) introduce a large number of hyperparameters that control when the losses are computed, when they are sorted as well as how the sampling distribution is computed based on the rank.
",2.2. Importance Sampling for Deep Learning,[0],[0]
"In comparison to all the above methods, our importance sampling scheme based on an upper bound to the gradient norm has a solid theoretical basis with clear objectives, very easy to choose hyperparameters, theoretically guaranteed speedup and can be applied to any type of network and loss function.",2.2. Importance Sampling for Deep Learning,[0],[0]
"For completeness, we mention the work of Wu et al. (2017), who design a distribution (suitable only for the distance based losses) that maximizes the diversity of the losses in a single batch.",2.3. Other Sample Selection Methods,[0],[0]
"In addition, Fan et al. (2017) use reinforcement learning to train a neural network that selects samples for another neural network in order to optimize the convergence speed.",2.3. Other Sample Selection Methods,[0],[0]
"Although their preliminary results are promising, the overhead of training two networks makes the wall-clock speedup unlikely and their proposal not as appealing.",2.3. Other Sample Selection Methods,[0],[0]
"Finally, a class of algorithms that aim to accelerate the convergence of Stochastic Gradient Descent (SGD) through variance reduction are SVRG type algorithms (Johnson & Zhang, 2013; Defazio et al., 2014; Allen-Zhu, 2017; Lei et al., 2017).",2.4. Stochastic Variance Reduced Gradient,[0],[0]
"Although asymptotically better, those algorithms typically perform worse than plain SGD with momentum for the low accuracy optimization setting of Deep Learning.",2.4. Stochastic Variance Reduced Gradient,[0],[0]
"Contrary to the aforementioned algorithms, our proposed importance sampling does not improve the asymptotic convergence of SGD but results in pragmatic improvements in all the metrics given a fixed time budget.",2.4. Stochastic Variance Reduced Gradient,[0],[0]
Importance sampling aims at increasing the convergence speed of SGD by focusing computation on samples that actually induce a change in the model parameters.,3. Variance Reduction for Deep Neural Networks,[0],[0]
This formally translates into a reduced variance of the gradient estimates for a fixed computational cost.,3. Variance Reduction for Deep Neural Networks,[0],[0]
"In the following sections, we analyze how this works and present an efficient algorithm that can be used to train any Deep Learning model.",3. Variance Reduction for Deep Neural Networks,[0],[0]
"Let xi, yi be the i-th input-output pair from the training set, Ψ(·; θ) be a Deep Learning model parameterized by the vector θ, and L(·, ·) be the loss function to be minimized during training.",3.1. Introduction to Importance Sampling,[0],[0]
"The goal of training is to find
θ∗ = arg min θ
1
N N∑ i=1",3.1. Introduction to Importance Sampling,[0],[0]
"L(Ψ(xi; θ), yi) (1)
where N corresponds to the number of examples in the training set.
",3.1. Introduction to Importance Sampling,[0],[0]
"We use an SGD procedure with learning rate η, where the update at iteration t depends on the sampling distribution pt1, . . .",3.1. Introduction to Importance Sampling,[0],[0]
", p t N and re-scaling coefficients w t 1, . . .",3.1. Introduction to Importance Sampling,[0],[0]
", w t N .",3.1. Introduction to Importance Sampling,[0],[0]
"Let It be the data point sampled at that step, we have P (It = i) =",3.1. Introduction to Importance Sampling,[0],[0]
"pti and
θt+1 = θt − ηwIt∇θtL(Ψ(xIt ; θt), yIt) (2)
Plain SGD with uniform sampling is achieved with wti = 1 and pti = 1 N for all t and i.
If we define the convergence speed S of SGD as the reduction of the distance of the parameter vector θ from the optimal parameter vector θ∗ in two consecutive iterations t and t+ 1
S = −EPt",3.1. Introduction to Importance Sampling,[0],[0]
[ ‖θt+1 − θ∗‖22,3.1. Introduction to Importance Sampling,[0],[0]
"− ‖θt − θ ∗‖22 ] , (3)
and if we have wi = 1Npi such that
EPt [wIt∇θtL(Ψ(xIt ; θt), yIt)]",3.1. Introduction to Importance Sampling,[0],[0]
(4) = ∇θt,3.1. Introduction to Importance Sampling,[0],[0]
1N ∑N i=1,3.1. Introduction to Importance Sampling,[0],[0]
"L(Ψ(xi; θt), yi), (5)
and set Gi = wi∇θtL(Ψ(xi; θt), yi), then we get (this is a different derivation of the result by Wang et al., 2016)
",3.1. Introduction to Importance Sampling,[0],[0]
S = −EPt,3.1. Introduction to Importance Sampling,[0],[0]
"[ (θt+1−θ∗)T (θt+1−θ∗)− (θt−θ∗)T (θt−θ∗) ] = −EPt [ θTt+1θt+1−2θt+1θ∗ − θTt θt + 2θtθ∗
] = −EPt [ (θt−ηGIt) T (θt−ηGIt) + 2ηGTItθ ∗−θTt",3.1. Introduction to Importance Sampling,[0],[0]
"θt ]
= −EPt [ −2η (θt−θ∗)GIt + η2GTItGIt ] = 2η (θt−θ∗)EPt [GIt ]− η2 EPt [GIt ]
TEPt [GIt ]− η2Tr (VPt [GIt ])
(6)
Since the first two terms, in the last expression, are the speed of batch gradient descent, we observe that it is possible to gain a speedup by sampling from the distribution that minimizes Tr (VPt [GIt ]).",3.1. Introduction to Importance Sampling,[0],[0]
"Several works (Needell et al., 2014; Zhao & Zhang, 2015; Alain et al., 2015) have shown the optimal distribution to be proportional to the per-sample gradient norm.",3.1. Introduction to Importance Sampling,[0],[0]
"However, computing this distribution is computationally prohibitive.",3.1. Introduction to Importance Sampling,[0],[0]
"Given an upper bound Ĝi ≥ ‖∇θtL(Ψ(xi; θt), yi)‖2 and due to
arg min P Tr (VPt [GIt ]) = arg min P
EPt [ ‖GIt‖ 2 2 ] , (7)
we propose to relax the optimization problem in the following way
min P
EPt [ ‖GIt‖ 2 2 ] ≤",3.2. Beyond the Full Gradient Norm,[0],[0]
min P EPt,3.2. Beyond the Full Gradient Norm,[0],[0]
[ w2ItĜ 2 It ] .,3.2. Beyond the Full Gradient Norm,[0],[0]
"(8)
The minimizer of the second term of equation 8, similar to the first term, is pi ∝ Ĝi.",3.2. Beyond the Full Gradient Norm,[0],[0]
"All that remains, is to find a proper expression for Ĝi which is significantly easier to compute than the norm of the gradient for each sample.
",3.2. Beyond the Full Gradient Norm,[0],[0]
"In order to continue with the derivation of our upper bound Ĝi, let us introduce some notation specific to a multi-layer perceptron.",3.2. Beyond the Full Gradient Norm,[0],[0]
Let θ(l) ∈ RMl×Ml−1 be the weight matrix for layer l and σ(l)(·) be a Lipschitz continuous activation function.,3.2. Beyond the Full Gradient Norm,[0],[0]
"Then, let
x(0) = x (9)
z(l) = θ(l) x(l−1)",3.2. Beyond the Full Gradient Norm,[0],[0]
"(10)
x(l) = σ(l)(z(l)) (11)
Ψ(x; Θ) = x(L) (12)
",3.2. Beyond the Full Gradient Norm,[0],[0]
"Although our notation describes simple fully connected neural networks without bias, our analysis holds for any affine operation followed by a slope-bounded non-linearity (|σ′(x)| ≤ K).",3.2. Beyond the Full Gradient Norm,[0],[0]
"With
Σ′l(z) = diag ( σ′(l)(z1), . . .",3.2. Beyond the Full Gradient Norm,[0],[0]
", σ ′(l)(zMl) ) , (13)
∆",3.2. Beyond the Full Gradient Norm,[0],[0]
(l) i = Σ ′ l(z (l) i )θ T l+1 . .,3.2. Beyond the Full Gradient Norm,[0],[0]
.Σ ′,3.2. Beyond the Full Gradient Norm,[0],[0]
"L−1(z (L−1) i )θ T L , (14)
∇",3.2. Beyond the Full Gradient Norm,[0],[0]
x (L) i L = ∇,3.2. Beyond the Full Gradient Norm,[0],[0]
x,3.2. Beyond the Full Gradient Norm,[0],[0]
"(L) i L(Ψ(xi; Θ), yi) (15)
we get
‖∇θlL(Ψ(xi; Θ), yi)‖2 (16)
",3.2. Beyond the Full Gradient Norm,[0],[0]
= ∥∥∥∥(∆(l)i Σ′L(z(L)i ),3.2. Beyond the Full Gradient Norm,[0],[0]
∇x(L)i L)(x(l−1)i ),3.2. Beyond the Full Gradient Norm,[0],[0]
"T ∥∥∥∥
2
(17)
≤",3.2. Beyond the Full Gradient Norm,[0],[0]
"∥∥∥∆(l)i ∥∥∥
2 ∥∥∥Σ′L(z(L)i )∇x(L)i L∥∥∥2 ∥∥∥x(l−1)i ∥∥∥2 (18) ≤",3.2. Beyond the Full Gradient Norm,[0],[0]
"max
l,i (∥∥∥x(l−1)i ∥∥∥ 2 ∥∥∥∆(l)i ∥∥∥ 2 ) ︸",3.2. Beyond the Full Gradient Norm,[0],[0]
"︷︷ ︸
ρ
∥∥∥Σ′L(z(L)i )",3.2. Beyond the Full Gradient Norm,[0],[0]
"∇x(L)i L∥∥∥2(19)
Various weight initialization (Glorot & Bengio, 2010) and activation normalization techniques (Ioffe & Szegedy, 2015; Ba et al., 2016) uniformise the activations across samples.",3.2. Beyond the Full Gradient Norm,[0],[0]
"As a result, the variation of the gradient norm is mostly captured by the gradient of the loss function with respect
to the pre-activation outputs of the last layer of our neural network.",3.2. Beyond the Full Gradient Norm,[0],[0]
"Consequently we can derive the following upper bound to the gradient norm of all the parameters
‖∇ΘL(Ψ(xi; Θ), yi)‖2 ≤",3.2. Beyond the Full Gradient Norm,[0],[0]
"Lρ ∥∥∥Σ′L(z(L)i )∇x(L)i L∥∥∥2︸ ︷︷ ︸
Ĝi
,
(20)
which is marginally more difficult to compute than the value of the loss since it can be computed in a closed form in terms of z(L).",3.2. Beyond the Full Gradient Norm,[0],[0]
"However, our upper bound depends on the time step t, thus we cannot generate a distribution once and sample from it during training.",3.2. Beyond the Full Gradient Norm,[0],[0]
This is intuitive because the importance of each sample changes as the model changes.,3.2. Beyond the Full Gradient Norm,[0],[0]
Computing the importance score from equation 20 is more than an order of magnitude faster compared to computing the gradient norm for each sample.,3.3. When is Variance Reduction Possible?,[0],[0]
"Nevertheless, it still costs one forward pass through the network and can be wasteful.",3.3. When is Variance Reduction Possible?,[0],[0]
"For instance, during the first iterations of training, the gradients with respect to every sample have approximately equal norm; thus we would waste computational resources trying to sample from the uniform distribution.",3.3. When is Variance Reduction Possible?,[0],[0]
"In addition, computing the importance score for the whole dataset is still prohibitive and would render the method unsuitable for online learning.
",3.3. When is Variance Reduction Possible?,[0],[0]
"In order to solve the problem of computing the importance for the whole dataset, we pre-sample a large batch of data points, compute the sampling distribution for that batch and re-sample a smaller batch with replacement.",3.3. When is Variance Reduction Possible?,[0],[0]
The above procedure upper bounds both the speedup and variance reduction.,3.3. When is Variance Reduction Possible?,[0],[0]
"Given a large batch consisting of B samples and a small one consisting of b, we can achieve a maximum variance reduction of 1b − 1 B and a maximum speedup of B+3b 3B assuming that the backward pass requires twice the amount of time as the forward pass.
",3.3. When is Variance Reduction Possible?,[0],[0]
"Due to the large cost of computing the importance per sample, we only perform importance sampling when we know that the variance of the gradients can be reduced.",3.3. When is Variance Reduction Possible?,[0],[0]
"In the following equation, we show that the variance reduction is proportional to the squared L2 distance of the sampling distribution, g, to the uniform distribution u. Due to lack of space, the complete derivation is included in the supplementary material.",3.3. When is Variance Reduction Possible?,[0],[0]
Let gi ∝,3.3. When is Variance Reduction Possible?,[0],[0]
"‖∇θtL(Ψ(xi; θt), yi)‖2 =",3.3. When is Variance Reduction Possible?,[0],[0]
‖Gi‖2,3.3. When is Variance Reduction Possible?,[0],[0]
and u = 1B,3.3. When is Variance Reduction Possible?,[0],[0]
"the uniform probability.
",3.3. When is Variance Reduction Possible?,[0],[0]
Tr (Vu[Gi])− Tr (Vg[wiGi]) (21) =,3.3. When is Variance Reduction Possible?,[0],[0]
Eu [ ‖Gi‖22 ],3.3. When is Variance Reduction Possible?,[0],[0]
"− Eg [ w2i ‖Gi‖ 2 2 ] (22)
=
( 1
B B∑ i=1",3.3. When is Variance Reduction Possible?,[0],[0]
‖Gi‖2 ),3.3. When is Variance Reduction Possible?,[0],[0]
2 B ‖g,3.3. When is Variance Reduction Possible?,[0],[0]
− u‖22 .,3.3. When is Variance Reduction Possible?,[0],[0]
"(23)
Equation 23 already provides us with a useful metric to decide if the variance reduction is significant enough to justify using importance sampling.",3.3. When is Variance Reduction Possible?,[0],[0]
"However, choosing a suitable threshold for the L2 distance squared would be tedious and unintuitive.",3.3. When is Variance Reduction Possible?,[0],[0]
We can do much better by dividing the variance reduction with the original variance to derive the increase in the batch size that would achieve an equivalent variance reduction.,3.3. When is Variance Reduction Possible?,[0],[0]
"Assuming that we increase the batch size by τ , we achieve variance reduction 1τ ; thus we have 1
( 1 B ∑B i=1",3.3. When is Variance Reduction Possible?,[0],[0]
‖Gi‖2 ),3.3. When is Variance Reduction Possible?,[0],[0]
2 B ‖g,3.3. When is Variance Reduction Possible?,[0],[0]
"− u‖22 Tr (Vu[Gi]) ≥ (24)(
1 B ∑B i=1 ‖Gi‖2 )",3.3. When is Variance Reduction Possible?,[0],[0]
2 B ‖g,3.3. When is Variance Reduction Possible?,[0],[0]
"− u‖22
1 B ∑B i=1 ‖Gi‖",3.3. When is Variance Reduction Possible?,[0],[0]
"2 2
=",3.3. When is Variance Reduction Possible?,[0],[0]
"(25)
1∑B i=1",3.3. When is Variance Reduction Possible?,[0],[0]
g 2,3.3. When is Variance Reduction Possible?,[0],[0]
i ‖g,3.3. When is Variance Reduction Possible?,[0],[0]
"− u‖22 = 1− 1 τ ⇐⇒ (26) 1
τ = 1− 1∑B
i=1",3.3. When is Variance Reduction Possible?,[0],[0]
"g 2 i
‖g",3.3. When is Variance Reduction Possible?,[0],[0]
"− u‖22 (27)
Using equation 27, we have a hyperparameter that is very easy to select and can now design our training procedure which is described in pseudocode in algorithm 1.",3.3. When is Variance Reduction Possible?,[0],[0]
Computing τ from equation 27 allows us to have guaranteed speedup when B + 3b < 3τb.,3.3. When is Variance Reduction Possible?,[0],[0]
"However, as it is shown in the experiments, we can use τth smaller than B+3b3b and still get a significant speedup.
",3.3. When is Variance Reduction Possible?,[0],[0]
"Algorithm 1 Deep Learning with Importance Sampling 1: Inputs B, b, τth, aτ , θ0 2: t← 1 3: τ ← 0 4: repeat 5: if τ > τth then 6: U ← B uniformly sampled datapoints 7: gi ∝",3.3. When is Variance Reduction Possible?,[0],[0]
Ĝi ∀i ∈ U according to eq 20 8: G ← b datapoints sampled with gi from U 9: wi ← 1Bgi,3.3. When is Variance Reduction Possible?,[0],[0]
"∀i ∈ G 10: θt ← sgd step(wi,G, θt−1) 11: else 12: U ← b uniformly sampled datapoints 13: wi ← 1 ∀i ∈ U 14: θt ← sgd step(wi,U , θt−1) 15: gi ∝",3.3. When is Variance Reduction Possible?,[0],[0]
Ĝi,3.3. When is Variance Reduction Possible?,[0],[0]
"∀i ∈ U 16: end if
17: τ ← aττ +",3.3. When is Variance Reduction Possible?,[0],[0]
(,3.3. When is Variance Reduction Possible?,[0],[0]
"1− aτ ) (
1− 1∑ i g 2 i ∥∥∥g − 1|U|∥∥∥2 2 )−1 18: until convergence
1In the first version we mistakenly assume 1 τ2 which made the algorithm unnecessarily conservative.",3.3. When is Variance Reduction Possible?,[0],[0]
"All the experiments are run using the square root of line 17 in Algorithm 1.
",3.3. When is Variance Reduction Possible?,[0],[0]
"The inputs to the algorithm are the pre-sampling size B, the batch size b, the equivalent batch size increment after which we start importance sampling τth and the exponential moving average parameter aτ used to compute a smooth estimate of τ .",3.3. When is Variance Reduction Possible?,[0],[0]
θ0 denotes the initial parameters of our deep network.,3.3. When is Variance Reduction Possible?,[0],[0]
"We would like to point out that in line 15 of the algorithm, we compute gi for free since we have done the forward pass in the previous step.
",3.3. When is Variance Reduction Possible?,[0],[0]
The only parameter that has to be explicitly defined for our algorithm is the pre-sampling size B because τth can be set using equation 27.,3.3. When is Variance Reduction Possible?,[0],[0]
We provide a small ablation study for B in the supplementary material.,3.3. When is Variance Reduction Possible?,[0],[0]
"In this section, we analyse experimentally the performance of the proposed importance sampling scheme based on our upper-bound of the gradient norm.",4. Experiments,[0],[0]
"In the first subsection, we compare the variance reduction achieved with our upper bound to the theoretically maximum achieved with the true gradient norm.",4. Experiments,[0],[0]
"We also compare against sampling based on the loss, which is commonly used in practice.",4. Experiments,[0],[0]
"Subsequently, we conduct experiments which demonstrate that we are able to achieve non-negligible wall-clock speedup for a variety of tasks using our importance sampling scheme.
",4. Experiments,[0],[0]
"In all the subsequent sections, we use uniform to refer to the usual training algorithm that samples points from a uniform distribution, we use loss to refer to algorithm 1 but instead of sampling from a distribution proportional to our upperbound to the gradient norm Ĝi (equations 8 and 20), we sample from a distribution proportional to the loss value and finally upper-bound to refer to our proposed method.",4. Experiments,[0],[0]
"All the other baselines from published methods are referred to using the names of the authors.
",4. Experiments,[0],[0]
"In addition to batch selection methods, we compare with various SVRG implementations including the accelerated Katyusha (Allen-Zhu, 2017) and the online SCSG (Lei et al., 2017) method.",4. Experiments,[0],[0]
"In all cases, SGD with uniform sampling performs significantly better.",4. Experiments,[0],[0]
"Due to lack of space, we report the detailed results in the supplementary material.
",4. Experiments,[0],[0]
"Experiments were conducted using Keras (Chollet et al., 2015) with TensorFlow (Abadi et al., 2016), and the code can be found at http://github.com/idiap/ importance-sampling.",4. Experiments,[0],[0]
"For all the experiments, we use Nvidia K80 GPUs and the reported time is calculated by subtracting the timestamps before starting one epoch and after finishing one; thus it includes the time needed to transfer data between CPU and GPU memory.
",4. Experiments,[0],[0]
Our implementation provides a wrapper around models that substitutes the standard uniform sampling with our importance-sampling method.,4. Experiments,[0],[0]
"This means that adding a sin-
gle line of code to call this wrapper before actually fitting the model is sufficient to switch from the standard uniform sampling to our importance-sampling scheme.",4. Experiments,[0],[0]
"And, as specified in § 3.3 and Algorithm 1, our procedure reliably estimates at every iteration if the importance sampling will provide a speed-up and sticks to uniform sampling otherwise.",4. Experiments,[0],[0]
"As already mentioned, several works (Loshchilov & Hutter, 2015; Schaul et al., 2015) use the loss value, directly or indirectly, to generate sampling distributions.",4.1. Ablation study,[0],[0]
"In this section, we present experiments that validate the superiority of our method with respect to the loss in terms of variance reduction.",4.1. Ablation study,[0],[0]
"For completeness, in the supplementary material we include a theoretical analysis that explains why sampling based on the loss also achieves variance reduction during
the late stages of training.
",4.1. Ablation study,[0],[0]
"Our experimental setup is as follows: we train a wide residual network (Zagoruyko & Komodakis, 2016) on the CIFAR100 dataset (Krizhevsky, 2009), following closely the training procedure of Zagoruyko & Komodakis (2016) (the details are presented in § 4.2).",4.1. Ablation study,[0],[0]
"Subsequently, we sample 1, 024 images uniformly at random from the dataset.",4.1. Ablation study,[0],[0]
"Using the weights of the trained network, at intervals of 3, 000 updates, we resample 128 images from the large batch of 1, 024 images using uniform sampling or importance sampling with probabilities proportional to the loss, our upper-bound or the gradient-norm.",4.1. Ablation study,[0],[0]
"The gradient-norm is computed by running the backpropagation algorithm with a batch size of 1.
",4.1. Ablation study,[0],[0]
Figure 1 depicts the variance reduction achieved with every sampling scheme in comparison to uniform.,4.1. Ablation study,[0],[0]
"We measure this directly as the distance between the mini-batch gradient and the batch gradient of the 1, 024 samples.",4.1. Ablation study,[0],[0]
For robustness we perform the sampling 10 times and report the average.,4.1. Ablation study,[0],[0]
"We observe that our upper bound and the gradient norm result in very similar variance reduction, meaning that the bound is relatively tight and that the produced probability distributions are highly correlated.",4.1. Ablation study,[0],[0]
"This can also be deduced by observing figure 2, where the probabilities proportional to the loss and the upper-bound are plotted against the optimal ones (proportional to the gradient-norm).",4.1. Ablation study,[0],[0]
"We observe that our upper bound is almost perfectly correlated with the gradient norm, in stark contrast to the loss which is only correlated at the regime of very small gradients.",4.1. Ablation study,[0],[0]
"Quantitatively the sum of squared error of 16, 384 points in figure 2 is 0.017 for the loss and 0.002 for our proposed upper bound.
",4.1. Ablation study,[0],[0]
"Furthermore, we observe that sampling hard examples (with high loss), increases the variance, especially in the beginning of training.",4.1. Ablation study,[0],[0]
"Similar behaviour has been observed in problems such as embedding learning where semi-hard sample mining is preferred over sampling using the loss (Wu et al., 2017; Schroff et al., 2015).",4.1. Ablation study,[0],[0]
"In this section, we use importance sampling to train a residual network on CIFAR10 and CIFAR100.",4.2. Image classification,[0],[0]
"We follow the experimental setup of Zagoruyko & Komodakis (2016), specifically we train a wide resnet 28-2 with SGD with momentum.",4.2. Image classification,[0],[0]
"We use batch size 128, weight decay 0.0005, momentum 0.9, initial learning rate 0.1 divided by 5 after 20, 000 and 40, 000 parameter updates.",4.2. Image classification,[0],[0]
"Finally, we train for a total of 50, 000 iterations.",4.2. Image classification,[0],[0]
"In order for our history based baselines to be compatible with the data augmentation of the CIFAR images, we pre-augment both datasets to generate 1.5 × 106 images for each one.",4.2. Image classification,[0],[0]
Our method does not have this limitation since it can work on infinite datasets in a true online fashion.,4.2. Image classification,[0],[0]
"To compare between methods, we
use a learning rate schedule based on wall-clock time and we also fix the total seconds available for training.",4.2. Image classification,[0],[0]
"A faster method should have smaller training loss and test error given a specific time during training.
",4.2. Image classification,[0],[0]
"For this experiment, we compare the proposed method to uniform, loss, online batch selection by Loshchilov & Hutter (2015) and the history based sampling of Schaul et al. (2015).",4.2. Image classification,[0],[0]
"For the method of Schaul et al. (2015), we use their proportional sampling since the rank based is very similar to Loshchilov & Hutter (2015) and we select the best parameters from the grid a = {0.1, 0.5, 1.0} and β = {0.5, 1.0}.",4.2. Image classification,[0],[0]
"Similarly, for online batch selection, we use s = {1, 10, 102} and a recomputation of all the losses every r = {600, 1200, 3600} updates.
",4.2. Image classification,[0],[0]
"For our method, we use a presampling size of 640.",4.2. Image classification,[0],[0]
One of the goals of this experiment is to show that even a smaller reduction in variance can effectively stabilize training and provide wall-clock time speedup; thus we set τth = 1.5.,4.2. Image classification,[0],[0]
"We perform 3 independent runs and report the average.
",4.2. Image classification,[0],[0]
The results are depicted in figure 3.,4.2. Image classification,[0],[0]
"We observe that in the relatively easy CIFAR10 dataset, all methods can provide some speedup over uniform sampling.",4.2. Image classification,[0],[0]
"However, for the more complicated CIFAR100, only sampling with our proposed upper-bound to the gradient norm reduces the variance of the gradients and provides faster convergence.",4.2. Image classification,[0],[0]
"Examining the training evolution in detail, we observe that on CIFAR10 our method is the only one that achieves a significant improvement in the test error even in the first stages of training (4, 000 to 8, 000 seconds).",4.2. Image classification,[0],[0]
"Quantitatively, on CIFAR10 we achieve more than an order of magnitude lower training loss and 8% lower test error from 0.087 to 0.079 while on CIFAR100 approximately 3 times lower training loss and 5% lower test error from 0.34 to 0.32 compared to uniform sampling.
",4.2. Image classification,[0],[0]
"At this point, we would also like to discuss the performance of the loss compared to other methods that also select batches based on this metric.",4.2. Image classification,[0],[0]
"Our experiments show, that using “fresh” values for the loss combined with a warmup stage so that importance sampling is not started too early outperforms all the other baselines on the CIFAR10 dataset.",4.2. Image classification,[0],[0]
Our second experiment shows the application of importance sampling to the significant task of fine tuning a pre-trained large neural network on a new dataset.,4.3. Fine-tuning,[0],[0]
"This task is of particular importance because there exists an abundance of powerful models pre-trained on large datasets such as ImageNet (Deng et al., 2009).
",4.3. Fine-tuning,[0],[0]
"Our experimental setup is the following, we fine-tune a ResNet-50 (He et al., 2015) previously trained on ImageNet.",4.3. Fine-tuning,[0],[0]
"We replace the last classification layer and then train the
whole network end-to-end to classify indoor images among 67 possible categories (Quattoni & Torralba, 2009).",4.3. Fine-tuning,[0],[0]
We use SGD with learning rate 10−3 and momentum 0.9.,4.3. Fine-tuning,[0],[0]
We set the batch size to 16 and for our importance sampling algorithm we pre-sample 48.,4.3. Fine-tuning,[0],[0]
"The variance reduction threshold is set to 2 as designated by equation 27.
",4.3. Fine-tuning,[0],[0]
"To assess the performance of both our algorithm and our gradient norm approximation, we compare the convergence speed of our importance sampling algorithm using our upper-bound and using the loss.",4.3. Fine-tuning,[0],[0]
"Once again, for robustness, we run 3 independent runs and report the average.
",4.3. Fine-tuning,[0],[0]
The results of the experiment are depicted in figure 4.,4.3. Fine-tuning,[0],[0]
"As expected, importance sampling is very useful for the task of fine-tuning since a lot of samples are handled correctly very early in the training process.",4.3. Fine-tuning,[0],[0]
"Our upper-bound, once again, greatly outperforms sampling proportionally to the loss when the network is large and the problem is non trivial.",4.3. Fine-tuning,[0],[0]
"Compared to uniform sampling, in just half an hour importance sampling has converged close to the best performance (28.06% test error) that can be expected on this dataset without any data augmentation or multiple crops (Razavian et al.,
2014), while uniform achieves only 33.74%.",4.3. Fine-tuning,[0],[0]
"To showcase the generality of our method, we use our importance sampling algorithm to accelerate the training of an LSTM in a sequence classification problem.",4.4. Pixel by Pixel MNIST,[0],[0]
"We use the pixel by pixel classification of randomly permuted MNIST digits (LeCun et al., 2010), as defined by Le et al. (2015).",4.4. Pixel by Pixel MNIST,[0],[0]
"The problem may seem trivial at first, however as shown by Le et al. (2015)",4.4. Pixel by Pixel MNIST,[0],[0]
"it is particularly suited to benchmarking the training of recurrent neural networks, due to the long range dependency problems inherent in the dataset (784 time steps).
",4.4. Pixel by Pixel MNIST,[0],[0]
"For our experiment, we fix a permutation matrix for all the pixels to generate a training set of 60, 000 samples with 784 time steps each.",4.4. Pixel by Pixel MNIST,[0],[0]
"Subsequently, we train an LSTM (Hochreiter & Schmidhuber, 1997) with 128 dimensions in the hidden space, tanh(·) as an activation function and sigmoid(·) as the recurrent activation function.",4.4. Pixel by Pixel MNIST,[0],[0]
"Finally, we use a linear classifier on top of the LSTM to choose a digit based on the hidden representation.",4.4. Pixel by Pixel MNIST,[0],[0]
"To train the aforemen-
tioned architecture, we use the Adam optimizer (Kingma & Ba, 2014) with a learning rate of 10−3 and a batch size of 32.",4.4. Pixel by Pixel MNIST,[0],[0]
"We have also found gradient clipping to be necessary for the training not to diverge; thus we clip the norm of all gradients to 1.
",4.4. Pixel by Pixel MNIST,[0],[0]
The results of the experiment are depicted in figure 5.,4.4. Pixel by Pixel MNIST,[0],[0]
"Both for the loss and our proposed upper-bound, importance sampling starts at around 2, 000 seconds by setting τth = 1.8 and the presampling size to 128.",4.4. Pixel by Pixel MNIST,[0],[0]
We could set τth = 2.33 (equation 27) which would only result in our algorithm being more conservative and starting importance sampling later.,4.4. Pixel by Pixel MNIST,[0],[0]
We clearly observe that sampling proportionally to the loss hurts the convergence in this case.,4.4. Pixel by Pixel MNIST,[0],[0]
"On the other hand, our algorithm achieves 20% lower training loss and 7% lower test error in the given time budget.",4.4. Pixel by Pixel MNIST,[0],[0]
We have presented an efficient algorithm for accelerating the training of deep neural networks using importance sampling.,5. Conclusions,[0],[0]
"Our algorithm takes advantage of a novel upper bound to the
gradient norm of any neural network that can be computed in a single forward pass.",5. Conclusions,[0],[0]
"In addition, we show an equivalence of the variance reduction with importance sampling to increasing the batch size; thus we are able to quantify both the variance reduction and the speedup and intelligently decide when to stop sampling uniformly.
",5. Conclusions,[0],[0]
Our experiments show that our algorithm is effective in reducing the training time for several tasks both on image and sequence data.,5. Conclusions,[0],[0]
"More importantly, we show that not all data points matter equally in the duration of training, which can be exploited to gain a speedup or better quality gradients or both.
",5. Conclusions,[0],[0]
Our analysis opens several avenues of future research.,5. Conclusions,[0],[0]
The two most important ones that were not investigated in this work are automatically tuning the learning rate based on the variance of the gradients and decreasing the batch size.,5. Conclusions,[0],[0]
The variance of the gradients can be kept stable by increasing the learning rate proportionally to the batch increment or by decreasing the number of samples for which we compute the backward pass.,5. Conclusions,[0],[0]
"Thus, we can speed up convergence by increasing the step size or reducing the time per update.",5. Conclusions,[0],[0]
This work is supported by the Swiss National Science Foundation under grant number FNS-30209 “ISUL”.,6. Acknowledgement,[0],[0]
In the following equations we quantify the variance reduction achieved with importance sampling using the gradient norm.,A. Differences of variances,[0],[0]
Let gi ∝,A. Differences of variances,[0],[0]
"‖∇θtL(Ψ(xi; θt), yi)‖2 =",A. Differences of variances,[0],[0]
‖Gi‖2,A. Differences of variances,[0],[0]
and u = 1B,A. Differences of variances,[0],[0]
"the uniform probability.
",A. Differences of variances,[0],[0]
"We want to compute
Tr (Vu[Gi])− Tr (Vg[wiGi])",A. Differences of variances,[0],[0]
= Eu [ ‖Gi‖22 ] − Eg [ w2i ‖Gi‖ 2 2 ] .,A. Differences of variances,[0],[0]
"(28)
Using the fact that wi = 1Bgi we have
Eg [ w2i ‖Gi‖ 2 2 ] =
( 1
B B∑ i=1",A. Differences of variances,[0],[0]
"‖Gi‖2
)",A. Differences of variances,[0],[0]
"2 , (29)
thus
",A. Differences of variances,[0],[0]
"Tr (Vu[Gi])− Tr (Vg[wiGi]) (30)
= 1
B B∑ i=1 ‖Gi‖22",A. Differences of variances,[0],[0]
"−
( 1
B B∑ i=1",A. Differences of variances,[0],[0]
"‖Gi‖2
)",A. Differences of variances,[0],[0]
"2 (31)
",A. Differences of variances,[0],[0]
"=
(∑B i=1 ‖Gi‖2 )",A. Differences of variances,[0],[0]
2 B3 B∑ i=1,A. Differences of variances,[0],[0]
"( B2 ‖Gi‖22 ( ∑B i=1 ‖Gi‖2)2 − 1 ) (32)
",A. Differences of variances,[0],[0]
"=
(∑B i=1 ‖Gi‖2 )",A. Differences of variances,[0],[0]
2 B B∑ i=1,A. Differences of variances,[0],[0]
( g2i − u2 ) .,A. Differences of variances,[0],[0]
"(33)
Completing the squares at equation 33 and using the fact that ∑B i=1",A. Differences of variances,[0],[0]
"u = 1 we complete the derivation.
",A. Differences of variances,[0],[0]
"Tr (Vu[Gi])− Tr (Vg[wiGi]) (34)
=
(∑B i=1 ‖Gi‖2 )",A. Differences of variances,[0],[0]
2 B B∑ i=1,A. Differences of variances,[0],[0]
"(gi − u)2 (35)
=
( 1
B B∑ i=1",A. Differences of variances,[0],[0]
‖Gi‖2 ),A. Differences of variances,[0],[0]
2 B ‖g,A. Differences of variances,[0],[0]
− u‖22 .,A. Differences of variances,[0],[0]
(36),A. Differences of variances,[0],[0]
"In this section, we reiterate the analysis from the main paper (§ 3.2) with more details.
",B. An upper bound to the gradient norm,[0],[0]
Let θ(l) ∈ RMl×Ml−1 be the weight matrix for layer l and σ(l)(·) be a Lipschitz continuous activation function.,B. An upper bound to the gradient norm,[0],[0]
"Then, let
x(0) = x (37)
z(l) = θ(l) x(l−1)",B. An upper bound to the gradient norm,[0],[0]
"(38)
x(l) = σ(l)(z(l)) (39)
Ψ(x; Θ) = x(L).",B. An upper bound to the gradient norm,[0],[0]
"(40)
Equations 37-40 define a simple fully connected neural network without bias to simplify the closed form definition of the gradient with respect to the parameters Θ.
",B. An upper bound to the gradient norm,[0],[0]
"In addition we define the gradient of the loss with respect to the output of the network as
∇",B. An upper bound to the gradient norm,[0],[0]
x (L) i L = ∇,B. An upper bound to the gradient norm,[0],[0]
x,B. An upper bound to the gradient norm,[0],[0]
"(L) i L(Ψ(xi; Θ), yi) (41)
and the gradient of the loss with respect to the output of layer l as
∇ x",B. An upper bound to the gradient norm,[0],[0]
(l) i L = ∆(l)i Σ ′,B. An upper bound to the gradient norm,[0],[0]
L(z (L) i ),B. An upper bound to the gradient norm,[0],[0]
"∇x(L)i L (42)
where
∆",B. An upper bound to the gradient norm,[0],[0]
(l) i = Σ ′ l(z (l) i )θ T l+1 . .,B. An upper bound to the gradient norm,[0],[0]
.Σ ′,B. An upper bound to the gradient norm,[0],[0]
"L−1(z (L−1) i )θ T L (43)
propagates the gradient from the last layer (pre-activation) to layer l and
Σ′l(z) = diag ( σ′(l)(z1), . . .",B. An upper bound to the gradient norm,[0],[0]
", σ ′(l)(zMl) )
(44)
defines the gradient of the activation function of layer l.
Finally, the gradient with respect to the parameters of the l-th layer can be written
‖∇θlL(Ψ(xi; Θ), yi)‖2 (45)
= ∥∥∥∥(∆(l)i Σ′L(z(L)i )",B. An upper bound to the gradient norm,[0],[0]
∇x(L)i L)(x(l−1)i ),B. An upper bound to the gradient norm,[0],[0]
"T ∥∥∥∥
2
(46)
≤ ∥∥∥x(l−1)i ∥∥∥
",B. An upper bound to the gradient norm,[0],[0]
2 ∥∥∥∆(l)i ∥∥∥ 2 ∥∥∥Σ′L(z(L)i )∇x(L)i L∥∥∥2 .,B. An upper bound to the gradient norm,[0],[0]
"(47) We observe that x(l)i and ∆ (l) i depend only on zi and Θ. However, we theorize that due to various weight initialization and activation normalization techniques those quantities do not capture the important per sample variations of the
gradient norm.",B. An upper bound to the gradient norm,[0],[0]
"Using the above, which is also shown experimentally to be true in § 4.1, we deduce the following upper bound per layer
‖∇θlL(Ψ(xi; Θ), yi)‖2 (48)
≤",B. An upper bound to the gradient norm,[0],[0]
"max l,i (∥∥∥x(l−1)i ∥∥∥ 2 ∥∥∥∆(l)i ∥∥∥ 2 )∥∥∥Σ′L(z(L)i )∇x(L)i L∥∥∥2(49) = ρ
∥∥∥Σ′L(z(L)i )",B. An upper bound to the gradient norm,[0],[0]
"∇x(L)i L∥∥∥2 , (50) which can then be used to derive our final upper bound
‖∇ΘL(Ψ(xi; Θ), yi)‖2 ≤",B. An upper bound to the gradient norm,[0],[0]
"Lρ ∥∥∥Σ′L(z(L)i )∇x(L)i L∥∥∥2︸ ︷︷ ︸
Ĝi
.
(51)
Intuitively, equation 51 means that the variations of the gradient norm are mostly captured by the final classification layer.",B. An upper bound to the gradient norm,[0.9543260378279936],"['(15) This theorem relies on proving that the condition number of the dual objective function is upper bounded by κlγ , and noting that the convergence rate for accelerated gradient descent depends on the square root of the condition number (see, e.g., Bubeck (2015)).']"
"Consequently, we can use the gradient of the loss with respect to the pre-activation outputs of our neural network as an upper bound to the per-sample gradient norm.",B. An upper bound to the gradient norm,[0],[0]
"For completeness, we also compare our proposed method with Stochastic Variance Reduced Gradient methods and present the results in this section.",C. Comparison with SVRG methods,[0],[0]
We follow the experimental setup of § 4.2 and evaluate on the augmented CIFAR10 and CIFAR100 datasets.,C. Comparison with SVRG methods,[0],[0]
"The algorithms we considered were SVRG (Johnson & Zhang, 2013), accelerated SVRG with Katyusha momentum (Allen-Zhu, 2017) and, the most suitable for Deep Learning, SCSG (Lei et al., 2017) which in practice is a mini-batch version of SVRG. SAGA (Defazio et al., 2014) was not considered due to the prohibitive memory requirements for storing the per sample gradients.
",C. Comparison with SVRG methods,[0],[0]
"For all methods, we tune the learning rate and the epochs per batch gradient computation (m in SVRG literature).",C. Comparison with SVRG methods,[0],[0]
"For SCSG, we also tune the large batch (denoted as Bj in Lei et al. (2017)) and its growth rate.",C. Comparison with SVRG methods,[0],[0]
The results are depicted in figure 6.,C. Comparison with SVRG methods,[0],[0]
We observe that SGD with momentum performs significantly better than all SVRG methods.,C. Comparison with SVRG methods,[0],[0]
Full batch SVRG and Katyusha perform a small number of parameter updates thus failing to optimize the networks.,C. Comparison with SVRG methods,[0],[0]
"In all cases, the best variance reduced method achieves more than an order of magnitude higher training loss than our proposed importance sampling scheme.",C. Comparison with SVRG methods,[0],[0]
"The only hyperparameter that is somewhat hard to define in our algorithm is the pre-sampling size B. As mentioned in the main paper, it controls the maximum possible variance reduction and also how much wall-clock time one iteration with importance sampling will require.
",D. Ablation study on B,[0],[0]
In figure 7 we depict the results of training with importance sampling and different pre-sampling sizes on CIFAR10.,D. Ablation study on B,[0],[0]
"We follow the same experimental setup as in the paper.
",D. Ablation study on B,[0],[0]
"We observe that larger presampling size results in lower training loss, which follows from our theory since the maximum variance reduction is smaller with small B.",D. Ablation study on B,[0],[0]
In this experiment we use the same τth for all the methods and we observe that B = 384 reaches first to 0.6 training loss.,D. Ablation study on B,[0],[0]
"This is justified because computing the importance for 1, 024 samples in the beginning of training is wasteful according to our analysis.
",D. Ablation study on B,[0],[0]
"According to this preliminary ablation study for B, we conclude that choosing B = kb with 2 < k",D. Ablation study on B,[0],[0]
< 6 is a good strategy for achieving a speedup.,D. Ablation study on B,[0],[0]
"However, regardless of the choice of B, pairing it with a threshold τth designated by the analysis in the paper guarantees that the algorithm will be spending time on importance sampling only when the variance can be greatly reduced.
",D. Ablation study on B,[0],[0]
E. Importance Sampling with the Loss,D. Ablation study on B,[0],[0]
"In this section we will present a small analysis that provides intuition regarding using the loss as an approximation or an upper bound to the per sample gradient norm.
",D. Ablation study on B,[0],[0]
"Let L(ψ, y) :",D. Ablation study on B,[0],[0]
"D → R be either the negative log likelihood through a sigmoid or the squared error loss function defined respectively as
L1(ψ, y) =",D. Ablation study on B,[0],[0]
"− log ( exp(yψ)
1 + exp(yψ)
)",D. Ablation study on B,[0],[0]
"y ∈ {−1, 1} ψ ∈ R
L2(ψ, y) =",D. Ablation study on B,[0],[0]
‖y,D. Ablation study on B,[0],[0]
− ψ‖22 y ∈ R d ψ ∈,D. Ablation study on B,[0],[0]
"Rd
(52)
",D. Ablation study on B,[0],[0]
"Given our upper bound to the gradient norm, we can write
‖∇θtL(Ψ(xi; θt), yi)‖2 ≤",D. Ablation study on B,[0],[0]
"Lρ ‖∇ψL(Ψ(xi; θt), yi)‖2 .",D. Ablation study on B,[0],[0]
"(53)
Moreover, for the losses that we are considering, when L(ψ, y)→ 0 then ‖∇ψL(Ψ(xi; θt), yi)‖2 → 0.",D. Ablation study on B,[0],[0]
"Using this fact in combination to equation 53, we claim that so does the per sample gradient norm thus small loss values imply small gradients.",D. Ablation study on B,[0],[0]
"However, large loss values are not well correlated with the gradient norm which can also be observed in § 4.1 in the paper.
",D. Ablation study on B,[0],[0]
"To summarize, we conjecture that due to the above facts, sampling proportionally to the loss reduces the variance only when the majority of the samples have losses close to 0.",D. Ablation study on B,[0],[0]
"Our assumption is validated from our experiments, where the loss struggles to achieve a speedup in the early stages of training where most samples still have relatively large loss values.",D. Ablation study on B,[0],[0]
"Deep neural network training spends most of the computation on examples that are properly handled, and could be ignored.",abstractText,[0],[0]
"We propose to mitigate this phenomenon with a principled importance sampling scheme that focuses computation on “informative” examples, and reduces the variance of the stochastic gradients during training.",abstractText,[0],[0]
"Our contribution is twofold: first, we derive a tractable upper bound to the persample gradient norm, and second we derive an estimator of the variance reduction achieved with importance sampling, which enables us to switch it on when it will result in an actual speedup.",abstractText,[0],[0]
"The resulting scheme can be used by changing a few lines of code in a standard SGD procedure, and we demonstrate experimentally, on image classification, CNN fine-tuning, and RNN training, that for a fixed wall-clock time budget, it provides a reduction of the train losses of up to an order of magnitude and a relative improvement of test errors between 5% and 17%.",abstractText,[0],[0]
Not All Samples Are Created Equal:  Deep Learning with Importance Sampling,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 2104–2115 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
2104",text,[0],[0]
Language models (LMs) are statistical models that assign a probability over sequences of words.,1 Introduction,[0],[0]
"Language models can often help with other tasks, such as speech recognition (Mikolov et al., 2010; Prabhavalkar et al., 2017), machine translation (Luong et al., 2015; Gülçehre et al., 2017), text summarisation (Filippova et al., 2015; Gambhir and Gupta, 2017), question answering (Wang et al., 2017), semantic error detection (Rei and Yannakoudakis, 2017; Spithourakis et al., 2016a), and fact checking (Rashkin et al., 2017).
",1 Introduction,[0],[0]
"Numeracy and literacy refer to the ability to comprehend, use, and attach meaning to numbers and words, respectively.",1 Introduction,[0],[0]
"Language models exhibit literacy by being able to assign higher probabilities to sentences that
are both grammatical and realistic, as in this example:
‘I eat an apple’ (grammatical and realistic)",1 Introduction,[0],[0]
"‘An apple eats me’ (unrealistic)
",1 Introduction,[0],[0]
"‘I eats an apple’ (ungrammatical)
",1 Introduction,[0],[0]
"Likewise, a numerate language model should be able to rank numerical claims based on plausibility:
’John’s height is 1.75 metres’ (realistic) ’",1 Introduction,[0],[0]
"John’s height is 999.999 metres’ (unrealistic)
Existing approaches to language modelling treat numerals similarly to other words, typically using categorical distributions over a fixed vocabulary.
",1 Introduction,[0],[0]
"However, this maps all unseen numerals to the same unknown type and ignores the smoothness of continuous attributes, as shown in Figure 1.",1 Introduction,[0],[0]
"In that respect, existing work on language modelling does not explicitly evaluate or optimise for numeracy.",1 Introduction,[0],[0]
"Numerals are often neglected and low-resourced, e.g. they are often masked (Mitchell and Lapata, 2009), and there are only 15,164 (3.79%) numerals among GloVe’s 400,000 embeddings pretrained on 6 billion tokens (Pennington et al., 2014).",1 Introduction,[0],[0]
"Yet, numbers appear ubiquitously, from children’s magazines (Joram et al., 1995) to clinical reports (Bigeard et al., 2015), and grant objectivity to sciences (Porter, 1996).
",1 Introduction,[0],[0]
"Previous work finds that numerals have higher out-of-vocabulary rates than other words and proposes solutions for representing unseen numerals as inputs to language models, e.g. using numerical magnitudes as features (Spithourakis et al., 2016b,a).",1 Introduction,[0],[0]
"Such work identifies that the perplexity of language models on the subset of numerals can be very high, but does not directly address the issue.",1 Introduction,[0],[0]
This paper focuses on evaluating and improving the ability of language models to predict numerals.,1 Introduction,[0],[0]
"The main contributions of this paper are as follows:
1.",1 Introduction,[0],[0]
"We explore different strategies for modelling numerals, such as memorisation and digit-bydigit composition, and propose a novel neural architecture based on continuous probability density functions.
",1 Introduction,[0],[0]
2.,1 Introduction,[0],[0]
"We propose the use of evaluations that adjust for the high out-of-vocabulary rate of numerals and account for their numerical value (magnitude).
3.",1 Introduction,[0],[0]
We evaluate on a clinical and a scientific corpus and provide a qualitative analysis of learnt representations and model predictions.,1 Introduction,[0],[0]
"We find that modelling numerals separately from other words can drastically improve the perplexity of LMs, that different strategies for modelling numerals are suitable for different textual contexts, and that continuous probability density functions can improve the LM’s prediction accuracy for numbers.",1 Introduction,[0],[0]
"Let s1,s2,...,sL denote a document, where st is the token at position t. A language model estimates the probability of the next token given previous tokens, i.e. p(st|s1,...,st−1).",2 Language Models,[0],[0]
"Neural LMs estimate this probability by feeding embeddings, i.e. vectors that represent each token, into a Recurrent Neural Network (RNN) (Mikolov et al., 2010).
",2 Language Models,[0],[0]
Token Embeddings Tokens are most commonly represented by aD-dimensional dense vector that is unique for each word from a vocabulary V of known words.,2 Language Models,[0],[0]
"This vocabulary includes special symbols (e.g. ‘UNK’) to handle out-of-vocabulary tokens, such as unseen words or numerals.",2 Language Models,[0],[0]
"Let ws be the one-hot representation of token s, i.e. a sparse binary vector with a single element set to 1 for that token’s index in the vocabulary, andE∈RD×|V| be the token embeddings matrix.",2 Language Models,[0],[0]
"The token embedding for s is the vector etokens =Ews.
",2 Language Models,[0],[0]
Character-Based Embeddings,2 Language Models,[0],[0]
"A representation for a token can be build from its constituent characters (Luong and Manning, 2016; Santos and Zadrozny, 2014).",2 Language Models,[0],[0]
Such a representation takes into account the internal structure of tokens.,2 Language Models,[0],[0]
"Let d1,d2,...,dN be the characters of token s. A character-based embedding for s is the final hidden state of a D-dimensional character-level RNN:",2 Language Models,[0],[0]
"echarss =RNN(d0,d1,...dL).
",2 Language Models,[0],[0]
Recurrent and Output Layer,2 Language Models,[0],[0]
The computation of the conditional probability of the next token involves recursively feeding the embedding of the current token est and the previous hidden state ht−1 into a D-dimensional token-level RNN to obtain the current hidden state ht.,2 Language Models,[0],[0]
"The output probability is estimated using the softmax function, i.e.
p(st|ht)=softmax(ψ(st))= 1Ze ψ(st) Z= ∑ s′∈V eψ(s ′), (1)
where ψ(.) is a score function.
",2 Language Models,[0],[0]
"Training and Evaluation Neural LMs are typically trained to minimise the cross entropy on the training corpus:
Htrain=− 1
N ∑ st∈train logp(st|s<t) (2)
A common performance metric for LMs is per token perplexity (Eq. 3), evaluated on a test corpus.",2 Language Models,[0],[0]
"It can also be interpreted as the branching factor: the size of an equally weighted distribution with equivalent uncertainty, i.e. how many sides you need on a fair die to get the same uncertainty as the model distribution.
",2 Language Models,[0],[0]
PPtest=exp(Htest) (3),2 Language Models,[0],[0]
"In this section we describe models with different strategies for generating numerals and propose the
use of number-specific evaluation metrics that adjust for the high out-of-vocabulary rate of numerals and account for numerical values.",3 Strategies for Modelling Numerals,[0],[0]
We draw inspiration from theories of numerical cognition.,3 Strategies for Modelling Numerals,[0],[0]
"The triple code theory (Dehaene et al., 2003) postulates that humans process quantities through two exact systems (verbal and visual) and one approximate number system that semantically represents a number on a mental number line.",3 Strategies for Modelling Numerals,[0],[0]
"Tzelgov et al. (2015) identify two classes of numbers: i) primitives, which are holistically retrieved from long-term memory; and ii) non-primitives, which are generated online.",3 Strategies for Modelling Numerals,[0],[0]
An in-depth review of numerical and mathematical cognition can be found in Kadosh and Dowker (2015) and Campbell (2005).,3 Strategies for Modelling Numerals,[0],[0]
This class of models assumes that numerals come from a finite vocabulary that can be memorised and retrieved later.,3.1 Softmax Model and Variants,[0],[0]
"The softmax model treats all tokens (words and numerals) alike and directly uses Equation 1 with score function:
ψ(st)=h T t e token st =h T t Eoutwst, (4)
where Eout ∈ RD×|V| is an output embeddings matrix.",3.1 Softmax Model and Variants,[0],[0]
"The summation in Equation 1 is over the complete target vocabulary, which requires mapping any out-of-vocabulary tokens to special symbols, e.g. ‘UNKword’ and ‘UNKnumeral’.
",3.1 Softmax Model and Variants,[0],[0]
"Softmax with Digit-Based Embeddings The softmax+rnn variant considers the internal syntax of a numeral’s digits by adjusting the score function:
ψ(st)=h T t e token st +h T t e chars st
=hTt Eoutwst+h T t E RNN out wst,
(5)
where the columns of ERNNout are composed of character-based embeddings for in-vocabulary numerals and token embeddings for the remaining vocabulary.",3.1 Softmax Model and Variants,[0],[0]
"The character set comprises digits (0-9), the decimal point, and an end-of-sequence character.",3.1 Softmax Model and Variants,[0],[0]
"The model still requires normalisation over the whole vocabulary, and the special unknown tokens are still needed.
Hierarchical Softmax A hierarchical softmax (Morin and Bengio, 2005a) can help us decouple the modelling of numerals from that of words.",3.1 Softmax Model and Variants,[0],[0]
"The probability of the next token st is decomposed to that of its class ct and the probability of the exact token from within the class:
p(st|ht)= ∑ ct∈C",3.1 Softmax Model and Variants,[0],[0]
"p(ct|ht)p(st|ct,ht)
p(ct|ht)=σ ( hTt b ) (6)
where the valid token classes are C = {word, numeral}, σ is the sigmoid function and b is a D-dimensional vector.",3.1 Softmax Model and Variants,[0],[0]
"Each of the two branches of p(st|ct,ht) can now be modelled by independently normalised distributions.",3.1 Softmax Model and Variants,[0],[0]
The hierarchical variants (h-softmax and h-softmax+rnn) use two independent softmax distributions for words and numerals.,3.1 Softmax Model and Variants,[0],[0]
"The two branches share no parameters, and thus words and numerals will be embedded into separate spaces.
",3.1 Softmax Model and Variants,[0],[0]
The hierarchical approach allows us to use any well normalised distribution to model each of its branches.,3.1 Softmax Model and Variants,[0],[0]
"In the next subsections, we examine different strategies for modelling the branch of numerals, i.e. p(st|ct=numeral,ht).",3.1 Softmax Model and Variants,[0],[0]
"For simplicity, we will abbreviate this to p(s).",3.1 Softmax Model and Variants,[0],[0]
"Let d1,d2...dN be the digits of numeral s. A digit-bydigit composition strategy estimates the probability of the numeral from the probabilities of its digits:
p(s)=p(d1)p(d2|d1)...",3.2 Digit-RNN Model,[0],[0]
"p(dN |d<N) (7)
The d-RNN model feeds the hidden state ht of the token-level RNN into a character-level RNN (Graves, 2013; Sutskever et al., 2011) to estimate this probability.",3.2 Digit-RNN Model,[0],[0]
"This strategy can accommodate an open vocabulary, i.e. it eliminates the need for an UNKnumeral symbol, as the probability is normalised one digit at a time over the much smaller vocabulary of digits (digits 0-9, decimal separator, and end-of-sequence).",3.2 Digit-RNN Model,[0],[0]
"Inspired by the approximate number system and the mental number line (Dehaene et al., 2003), our proposed MoG model computes the probability of numerals from a probability density function (pdf) over real numbers, using a mixture of Gaussians for the underlying pdf:
q(v)= K∑ k=1 πkNk(v;µk,σ2k)
πk=softmax ( BTht ) ,
(8)
where K is the number of components, πk are mixture weights that depend on hidden state ht of the token-level RNN,",3.3 Mixture of Gaussians Model,[0],[0]
"Nk is the pdf of the normal distribution with mean µk ∈R and variance σ2k ∈R, andB∈RD×K is a matrix.
",3.3 Mixture of Gaussians Model,[0],[0]
"The difficulty with this approach is that for any continuous random variable, the probability that it equals a specific value is always zero.",3.3 Mixture of Gaussians Model,[0],[0]
"To resolve this,
we consider a probability mass function (pmf) that discretely approximates the pdf:
Q̃(v|r)= v+",3.3 Mixture of Gaussians Model,[0],[0]
"r∫ v− r q(u)du=F(v+ r)−F(v− r), (9)
where F(.) is the cumulative density function of q(.), and r =0.5×10−r is the number’s precision.",3.3 Mixture of Gaussians Model,[0.9541031138214382],"['(12) is λt+1 = λt − η∇F ∗(λt √ W ) √ W, (13) and the change of variable yt = λt √ W leads to yt+1 = yt − η∇F ∗(yt)W. (14) This equation can be interpreted as gossiping the gradients of the local conjugate functions ∇f∗i (yi,t), since ∇F ∗(yt)ij = ∇f∗j (yj,t)i. Theorem 3.']"
"The level of discretisation r, i.e. how many decimal digits to keep, is a random variable in N with distribution p(r).",3.3 Mixture of Gaussians Model,[0],[0]
"The mixed joint density is:
p(s)=p(v,r)=p(r)Q̃(v|r) (10)
",3.3 Mixture of Gaussians Model,[0],[0]
"Figure 2 summarises this strategy, where we model the level of discretisation by converting the numeral into a pattern and use a RNN to estimate the probability of that pattern sequence:
p(r)=p(SOS INT_PART .",3.3 Mixture of Gaussians Model,[0],[0]
r decimal digits︷ ︸︸,3.3 Mixture of Gaussians Model,[0],[0]
︷ \d ... \d EOS) (11),3.3 Mixture of Gaussians Model,[0],[0]
Different mechanisms might be better for predicting numerals in different contexts.,3.4 Combination of Strategies,[0],[0]
"We propose a combination model that can select among different
strategies for modelling numerals: p(s)= ∑ ∀m∈M αmp(s|m)
αm=softmax ( ATht ) ,
(12)
where M={h-softmax, d-RNN, MoG}, and A∈RD×|M|.",3.4 Combination of Strategies,[0],[0]
"Since both d-RNN and MoG are openvocabulary models, the unknown numeral token can now be removed from the vocabulary of h-softmax.",3.4 Combination of Strategies,[0],[0]
Numeracy skills are centred around the understanding of numbers and numerals.,3.5 Evaluating the Numeracy of LMs,[0],[0]
"A number is a mathematical object with a specific magnitude, whereas a numeral is its symbolic representation, usually in the positional decimal Hindu–Arabic numeral system (McCloskey and Macaruso, 1995).",3.5 Evaluating the Numeracy of LMs,[0],[0]
"In humans, the link between numerals and their numerical values boosts numerical skills (Griffin et al., 1995).
",3.5 Evaluating the Numeracy of LMs,[0],[0]
Perplexity Evaluation Test perplexity evaluated only on numerals will be informative of the symbolic component of numeracy.,3.5 Evaluating the Numeracy of LMs,[0],[0]
"However, model comparisons based on naive evaluation using Equation 3 might be problematic: perplexity is sensitive to outof-vocabulary (OOV) rate, which might differ among models, e.g. it is zero for open-vocabulary models.",3.5 Evaluating the Numeracy of LMs,[0],[0]
"As an extreme example, in a document where all words are out of vocabulary, the best perplexity is achieved by a trivial model that predicts everything as unknown.
",3.5 Evaluating the Numeracy of LMs,[0],[0]
"Ueberla (1994) proposed Adjusted Perplexity (APP; Eq. 14), also known as unknown-penalised perplexity (Ahn et al., 2016), to cancel the effect of the out-of-vocabulary rate on perplexity.",3.5 Evaluating the Numeracy of LMs,[0],[0]
"The APP is the perplexity of an adjusted model that uniformly redistributes the probability of each out-of-vocabulary class over all different types in that class:
p′(s)= { p(s) 1|OOVc| if s∈OOVc p(s) otherwise
(13)
where OOVc is an out-of-vocabulary class (e.g. words and numerals), and |OOVc| is the cardinality of each OOV set.",3.5 Evaluating the Numeracy of LMs,[0],[0]
"Equivalently, adjusted perplexity can be calculated as:
APPtest=exp ( Htest+
∑ c Hcadjust
)
",3.5 Evaluating the Numeracy of LMs,[0],[0]
"Hcadjust=− ∑ t |st∈OOVc| N log 1 |OOVc|
(14)
",3.5 Evaluating the Numeracy of LMs,[0],[0]
"whereN is the total number of tokens in the test set and |s∈OOVc| is the count of tokens from the test set belonging in each OOV set.
",3.5 Evaluating the Numeracy of LMs,[0],[0]
"Evaluation on the Number Line While perplexity looks at symbolic performance on numerals, this evaluation focuses on numbers and particularly on their numerical value, which is their most prominent semantic content (Dehaene et al., 2003; Dehaene and Cohen, 1995).
",3.5 Evaluating the Numeracy of LMs,[0],[0]
Let vt be the numerical value of token st from the test corpus.,3.5 Evaluating the Numeracy of LMs,[0],[0]
"Also, let v̂t be the value of the most probable numeral under the model st = argmax (p(st|ht,ct=num)).",3.5 Evaluating the Numeracy of LMs,[0],[0]
Any evaluation metric from the regression literature can be used to measure the models performance.,3.5 Evaluating the Numeracy of LMs,[0],[0]
"To evaluate on the number line, we can use any evaluation metric from the regression literature.",3.5 Evaluating the Numeracy of LMs,[0],[0]
"In reverse order of tolerance to extreme errors, some of the most popular are Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), and Median Absolute Error (MdAE):
ei = vi−v̂i
RMSE = √ 1 N N∑ i=1",3.5 Evaluating the Numeracy of LMs,[0],[0]
"e2i
MAE = 1N N∑ i=1",3.5 Evaluating the Numeracy of LMs,[0],[0]
"|ei|
MdAE = median{|ei|}
(15)
",3.5 Evaluating the Numeracy of LMs,[0],[0]
The above are sensitive to the scale of the data.,3.5 Evaluating the Numeracy of LMs,[0],[0]
"If the data contains values from different scales, percentage metrics are often preferred, such as the Mean/Median Absolute Percentage Error (MAPE/MdAPE):
pei = vi−v̂i",3.5 Evaluating the Numeracy of LMs,[0],[0]
"vi
MAPE = 1N N∑ i=1",3.5 Evaluating the Numeracy of LMs,[0],[0]
"|pei|
MdAPE = median{|pei|}
(16)",3.5 Evaluating the Numeracy of LMs,[0],[0]
"To evaluate our models, we created two datasets with documents from the clinical and scientific domains, where numbers abound (Bigeard et al., 2015; Porter, 1996).",4 Data,[0],[0]
"Furthermore, to ensure that the numbers will be informative of some attribute, we only selected texts that reference tables.
",4 Data,[0],[0]
Clinical Data,4 Data,[0],[0]
Our clinical dataset comprises clinical records from the London Chest Hospital.,4 Data,[0],[0]
"The records where accompanied by tables with 20 numeric attributes (age, heart volumes, etc.) that they partially describe, as well as include numbers not found in the tables.",4 Data,[0],[0]
"Numeric tokens constitute only a small proportion of each sentence (4.3%), but account
for a large part of the unique tokens vocabulary (>40%) and suffer high OOV rates.
",4 Data,[0],[0]
Scientific Data,4 Data,[0],[0]
"Our scientific dataset comprises paragraphs from Cornell’s ARXIV 1 repository of scientific articles, with more than half a million converted papers in 37 scientific sub-fields.",4 Data,[0],[0]
"We used the preprocessed ARXMLIV (Stamerjohanns et al., 2010; Stamerjohanns and Kohlhase, 2008) 2 version, where papers have been converted from LATEX into a custom XML format using the LATEXML 3 tool.",4 Data,[0],[0]
"We then kept all paragraphs with at least one reference to a table and a number.
",4 Data,[0],[0]
"For both datasets, we lowercase tokens and normalise numerals by omitting the thousands separator (""2,000"" becomes ""2000"") and leading zeros (""007"" becomes ""7"").",4 Data,[0],[0]
"Special mathematical symbols are tokenised separately, e.g. negation (“-1” as “-”, “1”), fractions (“3/4” as “3”, “/”, “4”), etc.",4 Data,[0],[0]
"For this reason, all numbers were non-negative.",4 Data,[0],[0]
Table 1 shows descriptive statistics for both datasets.,4 Data,[0],[0]
"We set the vocabularies to the 1,000 and 5,000 most frequent token types for the clinical and scientific datasets, respectively.",5 Experimental Results and Discussion,[0],[0]
"We use gated token-character embeddings (Miyamoto and Cho, 2016) for the input of numerals and token embeddings for the input and output of words, since the scope of our paper is numeracy.",5 Experimental Results and Discussion,[0],[0]
"We set the models’ hidden dimensions to D = 50 and initialise all token embeddings to pretrained GloVe (Pennington et al., 2014).",5 Experimental Results and Discussion,[0],[0]
"All our
1ARXIV.ORG.",5 Experimental Results and Discussion,[0],[0]
"Cornell University Library at http://arxiv.org/, visited December 2016
2ARXMLIV.",5 Experimental Results and Discussion,[0],[0]
"Project home page at http://arxmliv.kwarc.info/, visited December 2016
3LATEXML.",5 Experimental Results and Discussion,[0],[0]
"http://dlmf.nist.gov, visited December 2016
RNNs are LSTMs (Hochreiter and Schmidhuber, 1997) with the biases of LSTM forget gate were initialised to 1.0 (Józefowicz et al., 2015).",5 Experimental Results and Discussion,[0],[0]
"We train using mini-batch gradient decent with the Adam optimiser (Kingma and Ba, 2014) and regularise with early stopping and 0.1 dropout rate (Srivastava, 2013) in the input and output of the token-based RNN.
",5 Experimental Results and Discussion,[0],[0]
"For the mixture of Gaussians, we select the mean and variances to summarise the data at different granularities by fitting 7 separate mixture of Gaussian models on all numbers, each with twice as many components as the previous, for a total of 27+1− 1 = 256 components.",5 Experimental Results and Discussion,[0],[0]
These models are initialised at percentile points from the data and trained with the expectation-minimisation algorithm.,5 Experimental Results and Discussion,[0],[0]
The means and variances are then fixed and not updated when we train the language model.,5 Experimental Results and Discussion,[0],[0]
"Perplexities Table 2 shows perplexities evaluated on the subsets of words, numerals and all tokens of
the test data.",5.1 Quantitative Results,[0],[0]
"Overall, all models performed better on the clinical than on the scientific data.",5.1 Quantitative Results,[0],[0]
"On words, all models achieve similar perplexities in each dataset.
",5.1 Quantitative Results,[0],[0]
"On numerals, softmax variants perform much better than other models in PP, which is an artefact of the high OOV-rate of numerals.",5.1 Quantitative Results,[0],[0]
"APP is significantly worse, especially for non-hierarchical variants, which perform about 2 and 4 orders of magnitude worse than hierarchical ones.
",5.1 Quantitative Results,[0],[0]
"For open-vocabulary models, i.e. d-RNN, MoG, and combination, PP is equivalent to APP.",5.1 Quantitative Results,[0],[0]
"On numerals, d-RNN performed better than softmax variants in both datasets.",5.1 Quantitative Results,[0],[0]
"The MoG model performed twice as well as softmax variants on the clinical dataset, but had the third worse performance in the scientific dataset.",5.1 Quantitative Results,[0],[0]
"The combination model had the best overall APP results for both datasets.
",5.1 Quantitative Results,[0],[0]
"Evaluations on the Number Line To factor out model specific decoding processes for finding the best next numeral, we use our models to rank a set
of candidate numerals: we compose the union of in-vocabulary numbers and 100 percentile points from the training set, and we convert numbers into numerals by considering all formats up to n decimal points.",5.1 Quantitative Results,[0],[0]
"We select n to represent 90% of numerals seen at training, which yields n=3 and n=4 for the clinical and scientific data, respectively.
",5.1 Quantitative Results,[0],[0]
"Table 3 shows evaluation results, where we also include two naive baselines of constant predictions: with the mean and median of the training data.",5.1 Quantitative Results,[0],[0]
"For both datasets, RMSE and MAE were too sensitive to extreme errors to allow drawing safe conclusions, particularly for the scientific dataset, where both metrics were in the order of 109.",5.1 Quantitative Results,[0],[0]
"MdAE can be of some use, as 50% of the errors are absolutely smaller than that.
",5.1 Quantitative Results,[0],[0]
"Along percentage metrics, MoG achieved the best MAPE in both datasets (18% and 54% better that the second best) and was the only model to perform better than the median baseline for the clinical data.",5.1 Quantitative Results,[0],[0]
"However, it had the worst MdAPE, which means that MoG mainly reduced larger percentage errors.",5.1 Quantitative Results,[0],[0]
"The d-RNN model came third and second in the clinical and scientific datasets, respectively.",5.1 Quantitative Results,[0],[0]
"In the latter it achieved the best MdAPE, i.e. it was effective at reducing errors for 50% of the numbers.",5.1 Quantitative Results,[0],[0]
The combination model did not perform better than its constituents.,5.1 Quantitative Results,[0],[0]
This is possibly because MoG is the only strategy that takes into account the numerical magnitudes of the numerals.,5.1 Quantitative Results,[0],[0]
Softmax versus Hierarchical Softmax Figure 3 visualises the cosine similarities of the output token embeddings of numerals for the softmax and h-softmax models.,5.2 Learnt Representations,[0],[0]
"Simple softmax enforced high similarities among all numerals and the unknown numeral token, so as to make them more dissimilar to words, since the model embeds both in the same space.",5.2 Learnt Representations,[0],[0]
"This is not the case for h-softmax that uses two different spaces: similarities are concentrated along the diagonal and fan out as the magnitude grows, with the exception of numbers with special meaning, e.g. years and percentile points.
",5.2 Learnt Representations,[0],[0]
Digit embeddings Figure 4 shows the cosine similarities between the digits of the d-RNN output mode.,5.2 Learnt Representations,[0],[0]
We observe that each primitive digit is mostly similar to its previous and next digit.,5.2 Learnt Representations,[0],[0]
Similar behaviour was found for all digit embeddings of all models.,5.2 Learnt Representations,[0],[0]
"Next Numeral Figure 5 shows the probabilities of different numerals under each model for two
examples from the clinical development set.",5.3 Predictions from the Models,[0],[0]
Numerals are grouped by number of decimal points.,5.3 Predictions from the Models,[0],[0]
"The h-softmax model’s probabilities are spiked, d-RNNs are saw-tooth like and MoG’s are smooth, with the occasional spike, whenever a narrow component allows for it.",5.3 Predictions from the Models,[0],[0]
"Probabilities rapidly decrease for more decimal digits, which is reminiscent of the theoretical expectation that the probability of en exact value for a continuous variable is zero.
",5.3 Predictions from the Models,[0],[0]
"Selection of Strategy in Combination Model Table 4 shows development set examples with high selection probabilities for each strategy of the combination model, along with numerals with the highest average selection per mode.",5.3 Predictions from the Models,[0],[0]
"The h-softmax model is responsible for mostly integers with special functions,
e.g. years, typical drug dosages, percentile points, etc.",5.3 Predictions from the Models,[0],[0]
"In the clinical data, d-RNN picks up two-digit integers (mostly dimensions) and MoG is activated for continuous attributes, which are mostly out of vocabulary.",5.3 Predictions from the Models,[0],[0]
"In the scientific data, d-RNN and MoG
showed affinity to different indices from catalogues of astronomical objects: d-RNN mainly to NGC (Dreyer, 1888) and MoG to various other indices, such as GL (Gliese, 1988) and HIP (Perryman et al., 1997).",5.3 Predictions from the Models,[0],[0]
"In this case, MoG was wrongly selected for numerals with a labelling function, which also highlights a limitation of evaluating on the number line, when a numeral is not used to represent its magnitude.
",5.3 Predictions from the Models,[0],[0]
"Significant Digits Figure 5 shows the distributions of the most significant digits under the d-RNN model
and from data counts.",5.3 Predictions from the Models,[0],[0]
"The theoretical estimate has been overlayed, according to Benford’s law (Benford, 1938), also called the first-digit law, which applies to many real-life numerals.",5.3 Predictions from the Models,[0],[0]
The law predicts that the first digit is 1 with higher probability (about 30%) than 9 (< 5%) and weakens towards uniformity at higher digits.,5.3 Predictions from the Models,[0],[0]
Model probabilities closely follow estimates from the data.,5.3 Predictions from the Models,[0],[0]
"Violations from Benford’s law can be due to rounding (Beer, 2009) and can be used as evidence for fraud detection (Lu et al., 2006).",5.3 Predictions from the Models,[0],[0]
"Numerical quantities have been recognised as important for textual entailment (Lev et al., 2004; Dagan et al., 2013).",6 Related Work,[0],[0]
"Roy et al. (2015) proposed a quantity entailment sub-task that focused on whether a given quantity can be inferred from a given text and, if so, what its value should be.",6 Related Work,[0],[0]
"A common framework for acquiring common sense about numerical attributes of objects has been to collect a corpus of numerical values in pre-specified templates and then model attributes as a normal distribution (Aramaki et al., 2007; Davidov and Rappoport, 2010; Iftene and Moruz, 2010; Narisawa et al., 2013; de Marneffe et al., 2010).",6 Related Work,[0],[0]
"Our model embeds these approaches into a LM that has a sense for numbers.
",6 Related Work,[0],[0]
Other tasks that deal with numerals are numerical information extraction and solving mathematical problems.,6 Related Work,[0],[0]
"Numerical relations have at least one argument that is a number and the aim of the task is to extract all such relations from a corpus, which can range from identifying a few numerical attributes (Nguyen and Moschitti, 2011; Intxaurrondo et al., 2015) to generic numerical relation extraction (Hoffmann et al., 2010; Madaan et al., 2016).",6 Related Work,[0],[0]
"Our model does not extract values, but rather produces an probabilistic estimate.
",6 Related Work,[0],[0]
"Much work has been done in solving arithmetic (Mitra and Baral, 2016; Hosseini et al., 2014; Roy and Roth, 2016), geometric (Seo et al., 2015), and algebraic problems (Zhou et al., 2015; Koncel-Kedziorski et al., 2015; Upadhyay et al., 2016; Upadhyay and Chang, 2016; Shi et al., 2015; Kushman et al., 2014) expressed in natural language.",6 Related Work,[0],[0]
"Such models often use mathematical background knowledge, such as linear system solvers.",6 Related Work,[0],[0]
"The output of our model is not based on such algorithmic operations, but could be extended to do so in future work.
",6 Related Work,[0],[0]
"In language modelling, generating rare or unknown words has been a challenge, similar to our unknown numeral problem.",6 Related Work,[0],[0]
"Gulcehre et al. (2016) and Gu et al. (2016) adopted pointer networks (Vinyals et al., 2015)
to copy unknown words from the source in translation and summarisation tasks.",6 Related Work,[0],[0]
"Merity et al. (2016) and Lebret et al. (2016) have models that copy from context sentences and from Wikipedia’s infoboxes, respectively.",6 Related Work,[0],[0]
Ahn et al. (2016) proposed a LM that retrieves unknown words from facts in a knowledge graph.,6 Related Work,[0],[0]
They draw attention to the inappropriateness of perplexity when OOV-rates are high and instead propose an adjusted perplexity metric that is equivalent to APP.,6 Related Work,[0],[0]
"Other methods aim at speeding up LMs to allow for larger vocabularies (Chen et al., 2015), such as hierarchical softmax (Morin and Bengio, 2005b), target sampling (Jean et al., 2014), etc., but still suffer from the unknown word problem.",6 Related Work,[0],[0]
"Finally, the problem is resolved when predicting one character at a time, as done by the character-level RNN (Graves, 2013; Sutskever et al., 2011) used in our d-RNN model.",6 Related Work,[0],[0]
"In this paper, we investigated several strategies for LMs to model numerals and proposed a novel openvocabulary generative model based on a continuous probability density function.",7 Conclusion,[0],[0]
"We provided the first thorough evaluation of LMs on numerals on two corpora, taking into account their high out-of-vocabulary rate and numerical value (magnitude).",7 Conclusion,[0],[0]
"We found that modelling numerals separately from other words through a hierarchical softmax can substantially improve the perplexity of LMs, that different strategies are suitable for different contexts, and that a combination of these strategies can help improve the perplexity further.",7 Conclusion,[0],[0]
"Finally, we found that using a continuous probability density function can improve prediction accuracy of LMs for numbers by substantially reducing the mean absolute percentage metric.
",7 Conclusion,[0],[0]
"Our approaches in modelling and evaluation can be used in future work in tasks such as approximate information extraction, knowledge base completion, numerical fact checking, numerical question answering, and fraud detection.",7 Conclusion,[0],[0]
Our code and data are available at: https://github.com/uclmr/ numerate-language-models.,7 Conclusion,[0],[0]
The authors would like to thank the anonymous reviewers for their insightful comments and also Steffen Petersen for providing the clinical dataset and advising us on the clinical aspects of this work.,Acknowledgments,[0],[0]
This research was supported by the Farr Institute of Health Informatics Research and an Allen Distinguished Investigator award.,Acknowledgments,[0],[0]
Numeracy is the ability to understand and work with numbers.,abstractText,[0],[0]
"It is a necessary skill for composing and understanding documents in clinical, scientific, and other technical domains.",abstractText,[0],[0]
"In this paper, we explore different strategies for modelling numerals with language models, such as memorisation and digit-by-digit composition, and propose a novel neural architecture that uses a continuous probability density function to model numerals from an open vocabulary.",abstractText,[0],[0]
"Our evaluation on clinical and scientific datasets shows that using hierarchical models to distinguish numerals from words improves a perplexity metric on the subset of numerals by 2 and 4 orders of magnitude, respectively, over nonhierarchical models.",abstractText,[0],[0]
A combination of strategies can further improve perplexity.,abstractText,[0],[0]
"Our continuous probability density function model reduces mean absolute percentage errors by 18% and 54% in comparison to the second best strategy for each dataset, respectively.",abstractText,[0],[0]
Numeracy for Language Models: Evaluating and Improving their Ability to Predict Numbers,title,[0],[0]
"Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 177–187 Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics",text,[0],[0]
Natural Language generation (NLG) is a long standing goal in natural language processing.,1 Introduction,[0],[0]
"There have already been several successes in applications such as financial reporting (Kukich, 1983; Smadja and McKeown, 1990), or weather forecasts (Konstas and Lapata, 2012; Wen et al., 2015), however it is still a challenging task for less structured and open domains.",1 Introduction,[0],[0]
"Given recent progress in training robust visual recognition models using convolutional neural networks, the task of generating natural language descriptions for ar-
bitrary images has received considerable attention (Vinyals et al., 2015; Karpathy and Fei-Fei, 2015; Mao et al., 2015).",1 Introduction,[0],[0]
"In general, generating visually descriptive language can be useful for various tasks such as human-machine communication, accessibility, image retrieval, and search.",1 Introduction,[0],[0]
"However this task is still challenging and it depends on developing both a robust visual recognition model, and a reliable language generation model.",1 Introduction,[0],[0]
"In this paper, we instead tackle a task of describing object layouts where the categories for the objects in an input scene and their corresponding locations are known.",1 Introduction,[0],[0]
"Object layouts are commonly used for story-boarding, sketching, and computer graphics applications.",1 Introduction,[0],[0]
"Additionally, using our object layout captioning model on the outputs of an object detector we are also able to improve image caption-
177
ing models.",1 Introduction,[0],[0]
"Object layouts contain rich semantic information, however they also abstract away several other visual cues such as color, texture, and appearance, thus introducing a different set of challenges than those found in traditional image captioning.
",1 Introduction,[0],[0]
"We propose OBJ2TEXT, a sequence-tosequence model that encodes object layouts using an LSTM network (Hochreiter and Schmidhuber, 1997), and decodes natural language descriptions using an LSTM-based neural language model1.",1 Introduction,[0],[0]
"Natural language generation systems usually consist of two steps: content planning, and surface realization.",1 Introduction,[0],[0]
"The first step decides on the content to be included in the generated text, and the second step connects the concepts using structural language properties.",1 Introduction,[0],[0]
"In our proposed model, OBJ2TEXT, content planning is performed by the encoder, and surface realization is performed by the decoder.",1 Introduction,[0],[0]
"Our model is trained in the standard MS-COCO dataset (Lin et al., 2014), which includes both object annotations for the task of object detection, and textual descriptions for the task of image captioning.",1 Introduction,[0],[0]
"While most previous research has been devoted to any one of these two tasks, our paper presents, to our knowledge, the first approach for learning mappings between object annotations and textual descriptions.",1 Introduction,[0],[0]
"Using several lesioned versions of the proposed model we explored the effect of object counts and locations in the quality and accuracy of the generated natural language descriptions.
",1 Introduction,[0],[0]
"Generating visually descriptive language requires beyond syntax, and semantics; an understanding of the physical word.",1 Introduction,[0],[0]
We also take inspiration from recent work by Schmaltz et al. (2016) where the goal was to reconstruct a sentence from a bag-of-words (BOW) representation using a simple surface-level language model based on an encoder-decoder sequence-to-sequence architecture.,1 Introduction,[0],[0]
"In contrast to this previous approach, our model is grounded on visual data, and its corresponding spatial information, so it goes beyond word re-ordering.",1 Introduction,[0],[0]
Also relevant to our work is Yao et al. (2016a) which previously explored the task of oracle image captioning by providing a language generation model with a list of manually defined visual concepts known to be present in the image.,1 Introduction,[0],[0]
"In addition, our model is able to leverage
1We build on neuraltalk2 and make our Torch code, and an interactive demo of our model available in the following url: http://vision.cs.virginia.edu/obj2text
both quantity and spatial information as additional cues associated with each object/concept, thus allowing it to learn about verbosity, and spatial relations in a supervised fashion.
",1 Introduction,[0],[0]
"In summary, our contributions are as follows:
• We demonstrate that despite encoding object layouts as a sequence using an LSTM, our model can still effectively capture spatial information for the captioning task.",1 Introduction,[0],[0]
"We perform ablation studies to measure the individual impact of object counts, and locations.
",1 Introduction,[0],[0]
"• We show that a model relying only on object annotations as opposed to pixel data, performs competitively in image captioning despite the ambiguity of the setup for this task.
",1 Introduction,[0],[0]
• We show that more accurate and comprehensive descriptions can be generated on the image captioning task by combining our OBJ2TEXT model using the outputs of a state-of-the-art object detector with a standard image captioning approach.,1 Introduction,[0],[0]
"We evaluate OBJ2TEXT in the task of object layout captioning, and image captioning.",2 Task,[0],[0]
"In the first task, the input is an object layout that takes the form of a set of object categories and bounding box pairs 〈o, l〉 = {〈oi, li〉}, and the output is natural language.",2 Task,[0],[0]
This task resembles the second task of image captioning except that the input is an object layout instead of a standard raster image represented as a pixel array.,2 Task,[0],[0]
We experiment in the MS-COCO dataset for both tasks.,2 Task,[0],[0]
"For the first task, object layouts are derived from ground-truth bounding box annotations, and in the second task object layouts are obtained using the outputs of an object detector over the input image.",2 Task,[0],[0]
"Our work is related to previous works that used clipart scenes for visually-grounded tasks including sentence interpretation (Zitnick and Parikh, 2013; Zitnick et al., 2013), and predicting object dynamics (Fouhey and Zitnick, 2014).",3 Related Work,[0],[0]
"The cited advantage of abstract scene representations such as the ones provided by the clipart scenes dataset proposed in (Zitnick and Parikh, 2013) is their ability to separate the complexity of pattern recognition from semantic visual representation.",3 Related Work,[0],[0]
"Abstract scene representations also maintain
common-sense knowledge about the world.",3 Related Work,[0],[0]
"The works of Vedantam et al. (2015b); Eysenbach et al. (2016) proposed methods to learn common-sense knowledge from clipart scenes, while the method of Yatskar et al. (2016), similar to our work, leverages object annotations for natural images.",3 Related Work,[0],[0]
"Understanding abstract scenes has demonstrated to be a useful capability for both language and vision tasks and our work is another step in this direction.
",3 Related Work,[0],[0]
"Our work is also related to other language generation tasks such as image and video captioning (Farhadi et al., 2010; Ordonez et al., 2011; Mason and Charniak, 2014; Ordonez et al., 2015; Xu et al., 2015; Donahue et al., 2015; Mao et al., 2015; Fang et al., 2015).",3 Related Work,[0],[0]
"This problem is interesting because it combines two challenging but perhaps complementary tasks: visual recognition, and generating coherent language.",3 Related Work,[0],[0]
"Fueled by recent advances in training deep neural networks (Krizhevsky et al., 2012) and the availability of large annotated datasets with images and captions such as the MS-COCO dataset (Lin et al., 2014), recent methods on this task perform endto-end learning from pixels to text.",3 Related Work,[0],[0]
"Most recent approaches use a variation of an encoderdecoder model where a convolutional neural network (CNN) extracts visual features from the input image (encoder), and passes its outputs to a recurrent neural network (RNN) that generates a caption as a sequence of words (decoder) (Karpathy and Fei-Fei, 2015; Vinyals et al., 2015).",3 Related Work,[0],[0]
"However, the MS-COCO dataset, containing object annotations, is also a popular benchmark in computer vision for the task of object detection, where the objective is to go from pixels to a collection of object locations.",3 Related Work,[0],[0]
"In this paper, we instead frame our problem as going from a collection of object categories and locations (object layouts) to image captions.",3 Related Work,[0],[0]
"This requires proposing a novel encoding approach to encode these object layouts instead of pixels, and allows for analyzing the image captioning task from a different perspective.",3 Related Work,[0],[0]
"Several other recent works use a similar sequenceto-sequence approach to generate text from source code input (Iyer et al., 2016), or to translate text from one language to another (Bahdanau et al., 2015).
",3 Related Work,[0],[0]
There have also been a few previous works explicitly analyzing the role of spatial and geometric relations between objects for vision and language related tasks.,3 Related Work,[0],[0]
"The work of Elliott and Keller
(2013) manually defined a dictionary of objectobject relations based on geometric cues.",3 Related Work,[0],[0]
The work of Ramisa et al. (2015) is focused on predicting preposition given two entities and their locations in an image.,3 Related Work,[0],[0]
Previous works of Plummer et al. (2015) and Rohrbach et al. (2016) showed that switching from classification-based CNN network to detection-based Fast RCNN network improves performance for phrase localization.,3 Related Work,[0],[0]
The work of Hu et al. (2016) showed that encoding image regions with spatial information is crucial for natural language object retrieval as the task explicitly asks for locations of target objects.,3 Related Work,[0],[0]
"Unlike these previous efforts, our model is trained endto-end for the language generation task, and takes as input a holistic view of the scene layout, potentially learning higher order relations between objects.",3 Related Work,[0],[0]
"In this section we describe our base OBJ2TEXT model for encoding object layouts to produce text (section 4.1), as well as two further variations to use our model to generate captions for real images: OBJ2TEXT-YOLO which uses the YOLO object detector (Redmon and Farhadi, 2017) to generate layouts of object locations from real images (section 4.2), and OBJ2TEXT-YOLO + CNN-RNN which further combines the previous model with an encoder-decoder image captioning which uses a convolutional neural network to encode the image (section 4.3).",4 Model,[0],[0]
"OBJ2TEXT is a sequence-to-sequence model that encodes an input object layout as a sequence, and decodes a textual description by predicting the next word at each time step.",4.1 OBJ2TEXT,[0],[0]
"Given a training data set comprising N observations
{〈o(n), l(n)〉}, where 〈o(n), l(n)〉 is a pair of sequences of input category and location vectors, together with a corresponding set of target captions { s(n) } , the encoder and decoder are trained jointly by minimizing a loss function over the training set using stochastic gradient descent:
W ∗ = arg min W N∑ n=1 L(〈o(n), l(n)〉, s(n)), (1)
in which W = ( W1 W2 ) is the group of encoder parameters W1 and decoder parameters W2.",4.1 OBJ2TEXT,[0],[0]
"The loss
function is a negative log likelihood function of the generated description given the encoded object layout
L(〈o(n), l(n)〉, s(n))",4.1 OBJ2TEXT,[0],[0]
=,4.1 OBJ2TEXT,[0],[0]
"− log p(sn|hnL, W2), (2) where hnL is computed using the LSTM-based encoder (eqs. 3, and 4) from the object layout inputs 〈o(n), l(n)〉, and p(sn|hnL, W2) is computed using the LSTM-based decoder (eqs. 5, 6 and 7).
",4.1 OBJ2TEXT,[0],[0]
"At inference time we encode an input layout 〈o, l〉 into its representation hL, and sample a sentence word by word based on p(st|hL, s<t) as computed by the decoder in time-step t. Finding the optimal sentence s∗ = arg maxs p(s|hL) requires the evaluation of an exponential number of sentences as in each time-step we have K number of choices for a word vocabulary of size K.",4.1 OBJ2TEXT,[0],[0]
"As a common practice for an approximate solution, we follow (Vinyals et al., 2015) and use beam search to limit the choices for words at each time-step by only using the ones with the highest probabilities.",4.1 OBJ2TEXT,[0],[0]
"Encoder: The encoder at each time-step t takes as input a pair 〈ot, lt〉, where ot is the object category encoded as a one-hot vector of size V , and lt =",4.1 OBJ2TEXT,[0],[0]
"[Bxt , B y t , B w t , B h t ] is the location configuration vector that contains left-most position, topmost position, and the width and height of the bounding box corresponding to object ot, all normalized in the range [0,1] with respect to input image dimensions.",4.1 OBJ2TEXT,[0],[0]
"ot and lt are mapped to vectors with the same size k and added to form the input xt to one time-step of the LSTM-based encoder as follows:
xt = Woot",4.1 OBJ2TEXT,[0],[0]
"+ (Wllt + bl),",4.1 OBJ2TEXT,[0],[0]
"xt ∈ Rk, (3) in which Wo ∈ Rk×V is a categorical embedding matrix (the word encoder), and Wl ∈ Rk×4 and bias",4.1 OBJ2TEXT,[0],[0]
bl ∈,4.1 OBJ2TEXT,[0],[0]
"Rk are parameters of a linear transformation unit (the object location encoder).
",4.1 OBJ2TEXT,[0],[0]
"Setting initial value of cell state vector ce0 = 0 and hidden state vector he0 = 0, the LSTM-based encoder takes the sequence of input (x1, ..., xT1) and generates a sequence of hidden state vectors (he1, ..., h e T1
) using the following step function (we omit cell state variables and internal transition gates for simplicity as we use a standard LSTM cell definition):
het = LSTM(h e t−1, xt; W1).",4.1 OBJ2TEXT,[0],[0]
"(4)
We use the last hidden state vector hL = heT1 as the encoded representation of the input layout 〈ot, lt〉 to generate the corresponding description s.
Decoder: The decoder takes the encoded layout hL as input and generates a sequence of multinomial distributions over a vocabulary of words using an LSTM neural language model.",4.1 OBJ2TEXT,[0],[0]
"The joint probability distribution of generated sentence s = (s1, ..., sT2) is factorized into products of conditional probabilities:
p(s|hL)",4.1 OBJ2TEXT,[0],[0]
"= T2∏ t=1 p(st|hL, s<t), (5)
where each factor is computed using a softmax function over the hidden states of the decoder LSTM as follows:
p(st|hL, s<t) = softmax(Whhdt−1 + bh), (6)
hdt = LSTM(h d t−1, Wsst; W2), (7)
where Ws is the categorical embedding matrix for the one-hot encoded caption sequence of symbols.",4.1 OBJ2TEXT,[0],[0]
"By setting hd−1 = 0 and cd−1 = 0 for the initial hidden state and cell state, the layout representation is encoded into the decoder network at the 0 time step as a regular input:
hd0 = LSTM(h d −1, hL; W2).",4.1 OBJ2TEXT,[0],[0]
"(8)
We use beam search to sample from the LSTM as is routinely performed in previous literature in order to generate text.",4.1 OBJ2TEXT,[0],[0]
For the task of image captioning we propose OBJ2TEXT-YOLO.,4.2 OBJ2TEXT-YOLO,[0],[0]
"This model takes an image as input, extracts an object layout (object categories and locations) with a state-of-the-art object detection model YOLO (Redmon and Farhadi, 2017), and uses OBJ2TEXT as described in section 4.1 to generate a natural language description of the input layout and hence, the input image.",4.2 OBJ2TEXT-YOLO,[0],[0]
"The model is trained using the standard back-propagation algorithm, but the error is not back-propagated to the object detection module.",4.2 OBJ2TEXT-YOLO,[0],[0]
"For the image captioning task we experiment with a combined model (see Figure 2) where we take an image as input, and then use two separate computation branches to extract visual feature information and object layout information.",4.3 OBJ2TEXT-YOLO + CNN-RNN,[0],[0]
These two streams of information are then passed to an LSTM neural language model to generate a description.,4.3 OBJ2TEXT-YOLO + CNN-RNN,[0],[0]
"Visual features are extracted using the
VGG-16 (Simonyan and Zisserman, 2015) convolutional neural network pre-trained on the ImageNet classification task (Russakovsky et al., 2015).",4.3 OBJ2TEXT-YOLO + CNN-RNN,[0],[0]
Object layouts are extracted using the YOLO object detection system and its output object locations are encoded using our proposed OBJ2TEXT encoder.,4.3 OBJ2TEXT-YOLO + CNN-RNN,[0],[0]
These two streams of information are encoded into vectors of the same size and their sum is input to the language model to generate a textual description.,4.3 OBJ2TEXT-YOLO + CNN-RNN,[0],[0]
The model is trained using the standard back-propagation algorithm where the error is back-propagated to both branches but not the object detection module.,4.3 OBJ2TEXT-YOLO + CNN-RNN,[0],[0]
The weights of the image CNN model are fine-tuned only after the layout encoding branch is well trained but no significant overall performance improvements were observed.,4.3 OBJ2TEXT-YOLO + CNN-RNN,[0],[0]
"We evaluate the proposed models on the MSCOCO (Lin et al., 2014) dataset which is a popular image captioning benchmark that also contains object extent annotations.",5 Experimental Setup,[0],[0]
"In the object layout captioning task the model uses the groundtruth object extents as input object layouts, while in the image captioning task the model takes raw images as input.",5 Experimental Setup,[0],[0]
The qualities of generated descriptions are evaluated using both human evaluations and automatic metrics.,5 Experimental Setup,[0],[0]
"We train and validate our models based on the commonly adopted split regime (113,287 training images, 5000 validation and 5000 test images) used in (Karpathy et al., 2016), and also test our model in the MSCOCO official test benchmark.
",5 Experimental Setup,[0],[0]
"We implement our models based on the open source image captioning system Neuraltalk2 (Karpathy et al., 2016).",5 Experimental Setup,[0],[0]
Other configurations including data preprocessing and training hyper-parameters also follow Neuraltalk2.,5 Experimental Setup,[0],[0]
"We trained our models using a GTX1080 GPU with 8GB of memory for 400k iterations using a batch
size of 16 and an Adam optimizer with alpha of 0.8, beta of 0.999 and epsilon of 1e-08.",5 Experimental Setup,[0],[0]
"Descriptions of the CNN-RNN approach are generated using the publicly available code and model checkpoint provided by Neuraltalk2 (Karpathy et al., 2016).",5 Experimental Setup,[0],[0]
"Captions for online test set evaluations are generated using beam search of size 2, but score histories on split validation set are based on captions generated without beam search (i.e. max sampling at each time-step).
",5 Experimental Setup,[0],[0]
Ablation on Object Locations and Counts:.,5 Experimental Setup,[0],[0]
"We setup an experiment where we remove the input locations from the OBJ2TEXT encoder to study the effects on the generated captions, and confirm whether the model is actually using spatial information during surface realization.",5 Experimental Setup,[0],[0]
In this restricted version of our model the LSTM encoder at each time step only takes the object category embedding vector as input.,5 Experimental Setup,[0],[0]
"The OBJ2TEXT model additionally encodes different instances of the same object category in different time steps, potentially encoding in some of its hidden states information about how many objects of a particular class are in the image.",5 Experimental Setup,[0],[0]
"For example, in the object annotation presented in the input in Figure 1, there are two instances of “person”.",5 Experimental Setup,[0],[0]
"We perform an additional experiment where our model does not have access neither to object locations, nor the number of object instances by providing only a set of object categories.",5 Experimental Setup,[0],[0]
"Note that in this set of experiments the object layouts are given as inputs, thus we assume full access to ground-truth object annotations, even in the test split.",5 Experimental Setup,[0],[0]
"In the experimental results section we use the “-GT” postfix to indicate that input object layouts are obtained from ground-truth object annotations provided by the MS-COCO dataset.
",5 Experimental Setup,[0],[0]
"Image Captioning Experiment: In this experiment we assess whether the image captioning model OBJ2TEXT-YOLO that only relies on object categories and locations could give comparable performance with a CNN-RNN model based on Neuraltalk2 (Karpathy et al., 2016) that has full access to visual image features.",5 Experimental Setup,[0],[0]
"We also explore how much does a combined OBJ2TEXT-YOLO + CNN-RNN model could improve over a CNNRNN model by fusing object counts and location information that is not explicitly encoded in a traditional CNN-RNN approach.
",5 Experimental Setup,[0],[0]
Human Evaluation Protocol.,5 Experimental Setup,[0],[0]
"We use a twoalternative forced-choice evaluation (2AFC) ap-
proach to compare two methods that generate captions.",5 Experimental Setup,[0],[0]
"For this, we setup a task on Amazon Mechanical Turk where users are presented with an image and two alternative captions, and they have to choose the caption that best describes the image.",5 Experimental Setup,[0],[0]
"Users are not prompted to use any single criteria but rather a holistic assessment of the captions, including their semantics, syntax, and the degree to which they describe the image content.",5 Experimental Setup,[0],[0]
"In our experiment we randomly sample 500 captions generated by various models for MS COCO online test set images, and use three users per image to obtain annotations.",5 Experimental Setup,[0],[0]
Note that three users choosing randomly between two options have a chance of 25% to select the same caption for a given image.,5 Experimental Setup,[0],[0]
"In our experiments comparing method A vs method B, we report the percentage of times A was picked over B (Choice-all), the percentage of times all users selected the same method, either A or B, (Agreement), and the percentage of times A was picked over B only for these cases where all users agreed (Choice-agreement).",5 Experimental Setup,[0],[0]
"Impact of Object Locations and Counts: Figure 3a shows the CIDEr (Vedantam et al., 2015a), and BLEU-4 (Papineni et al., 2002) score history on our validation set during 400k iterations of training of OBJ2TEXT, as well as a version of our model that does not use object locations, and a version of our model that does not use neither object locations nor object counts.",6 Results,[0],[0]
"These results show that our model is effectively using both object locations and counts to generate better captions, and absence of any one of these two cues affects performance.",6 Results,[0],[0]
"Table 1 confirms these results on the test split after a full round of training.
",6 Results,[0],[0]
"Furthermore, human evaluation results in the first row of Table 2 show that the OBJ2TEXT model with access to object locations is preferred by users, especially in cases where all evaluators agreed on their choice (62% over the baseline that does not have access to locations).",6 Results,[0],[0]
In Figure 4 we additionally present qualitative examples showing predictions side-by-side between OBJ2TEXT-GT and OBJ2TEXT-GT (no obj-locations).,6 Results,[0],[0]
"These results indicate that 1) perhaps not surprisingly, object counts is useful for generating better quality descriptions, and 2) object location information when properly encoded, is an important cue for generating more accurate descriptions.",6 Results,[0],[0]
"We ad-
ditionally implemented a nearest neighbor baseline by representing the objects in the input layout using an orderless bag-of-words representation of object counts and the CIDEr score on the test split was only 0.387.
",6 Results,[0],[0]
"On top of OBJ2TEXT we additionally experimented with the global attention model proposed in (Luong et al., 2015) so that a weighted combination of the encoder hidden states are forwarded to the decoding neural language model, however we did not notice any overall gains in terms of accuracy from this formulation.",6 Results,[0],[0]
"We observed that this model provided gains only for larger input sequences where it is more likely that the LSTM network forgets its past history (Bahdanau et al., 2015).",6 Results,[0],[0]
"However in MS-COCO the average number of objects in each image is rather modest, so the last hidden state can capture well the overall nuances of the visual input.
",6 Results,[0],[0]
Object Layout Encoding for Image Captioning:,6 Results,[0],[0]
"Figure 3b shows the CIDEr, and BLEU-4 score history on the validation set during 400k iterations of training of OBJ2TEXT-YOLO, CNN-RNN, and their combination.",6 Results,[0],[0]
"These results show that OBJ2TEXT-YOLO performs surprisingly close to CNN-RNN, and the model resulting from combining the two, clearly outperforms each method alone.",6 Results,[0],[0]
"Table 3 shows MS-COCO evaluation results on the test set using their online benchmark service, and confirms results obtained in the validation split, where CNN-RNN seems to have only a slight edge over OBJ2TEXT-YOLO which lacks access to pixel data after the object detection stage.",6 Results,[0],[0]
"Human evaluation results in Table 2 rows 2, and 3, further confirm these findings.",6 Results,[0],[0]
"These results show that meaningful descriptions could be generated solely based on object categories and locations information, even without access to color and texture input.
",6 Results,[0],[0]
"The combined model performs better than the two models, improving the CIDEr score of the basic CNN-RNN model from 0.863 to 0.950, and human evaluation results show that the combined model is preferred over the basic CNNRNN model for 65.3% of the images for which all evaluators were in agreement about the selected method.",6 Results,[0],[0]
"These results show that explicitly encoded object counts and location information, which is often overlooked in traditional image captioning approaches, could boost the performance of existing models.",6 Results,[0],[0]
"Intuitively, object lay-
out and visual features are complementary: neural network models for visual feature extraction are trained on a classification task where object-level information such as number of instances and locations are ignored in the objective.",6 Results,[0],[0]
"Object layouts on the other hand, contain categories and their bounding-boxes but don’t have access to rich image features such as image background, object attributes and objects with categories not present in the object detection vocabulary.
",6 Results,[0],[0]
"Figure 5 provides a three-way comparison of captions generated by the three image captioning models, with preferred captions by human evaluators annotated in bold text.",6 Results,[0],[0]
Analysis on actual outputs gives us insights into the benefits of combing object layout information and visual features obtained using a CNN.,6 Results,[0],[0]
"Our OBJ2TEXT-YOLO model makes many mistakes because of lack of image context information since it only has access to object layout, while CNN-RNN makes many mistakes because the visual recognition model is imperfect at predicting the correct content.",6 Results,[0],[0]
"The combined model is usually able to generate more accurate and comprehensive descriptions.
",6 Results,[0],[0]
"In this work we only explored encoding spatial information with object labels, but object la-
bels could be readily augmented with rich semantic features that are more detailed descriptions of objects or image regions.",6 Results,[0],[0]
"For example, the work of You et al. (2016) and Yao et al. (2016b) showed that visual features trained with semantic concepts (text entities mentioned in captions) instead of object labels is useful for image captioning, although they didn’t consider encoding semantic concepts with spatial information.",6 Results,[0],[0]
"In case of object annotations the MS-COCO dataset only provides object labels and bounding-boxes, but there are other datasets such as Flick30K Entities (Plummer et al., 2015), and the Visual Genome dataset (Krishna et al., 2017) that provide richer region-tophrase correspondence annotations.",6 Results,[0],[0]
"In addition, the fusion of object counts and spatial information with CNN visual features could in principle benefit other vision and language tasks such as visual question answering.",6 Results,[0],[0]
We leave these possible extensions as future work.,6 Results,[0],[0]
"We introduced OBJ2TEXT, a sequence-tosequence model to generate visual descriptions for object layouts where only categories and locations are specified.",7 Conclusion,[0],[0]
"Our proposed model
shows that an orderless visual input representation of concepts is not enough to produce good descriptions, but object extents, locations, and object counts, all contribute to generate more accurate image descriptions.",7 Conclusion,[0],[0]
"Crucially we show that our encoding mechanism is able to capture useful spatial information using an LSTM network to produce image descriptions, even when the input is provided as a sequence rather than as an explicit 2D representation of objects.",7 Conclusion,[0],[0]
"Additionally, using
our proposed OBJ2TEXT model in combination with an existing image captioning model and a robust object detector we showed improved results in the task of image captioning.",7 Conclusion,[0],[0]
This work was supported in part by an NVIDIA Hardware Grant.,Acknowledgments,[0],[0]
"We are also thankful for the feedback from Mark Yatskar and anonymous reviewers of this paper.
",Acknowledgments,[0],[0]
"7/16/2017 vision.cs.virginia.edu:8001
http://vision.cs.virginia.edu:8001/ 1/1
(a) a yellow fire hydrant sitting on the side of a road (b) a man is standing in the snow with a snowboard (c) a fire hydrant in the snow near a road (a) a small boat in a body of water (b) a boat with a bunch of people on it (c) a boat is docked in a large body of water (a) a man and a woman are sitting on a bench (b) a man and a woman sitting on a couch (c) a man and woman are talking on their cell phones (a) a man sitting on a bench in a park (b) a woman sitting on a bench with a cell phone (c) a woman sitting on a bench with her legs crossed (a) a bird sitting on a tree branch in a tree (b) a bird sitting on a branch in a tree (c) two birds are sitting on a tree branch (a) a zebra standing in a field of grass (b) a man riding a wave on top of a surfboard (c) a zebra standing in the water near a rock wall
(a) a chair and a table in a room (b) a pile of luggage sitting on top of a wooden floor (c) a room with a table and chairs and a suitcase (a) a white plate topped with meat and vegetables (b) a white plate topped with meat and vegetables (c) a plate of food with meat and vegetables (a) a herd of cattle grazing on a lush green field (b) a herd of elephants walking across a river (c) a group of cows standing in a river (a) a man is swinging a bat at a ball (b) a man is playing with a frisbee in a park (c) a man is swinging a bat in a field (a) a little girl sitting at a table with a cake (b) a bride and groom cutting their wedding cake (c) a bride and groom cutting their wedding cake (a) a street sign with a street name sign on it (b) a large clock tower towering over a city
(c) a large body of water with a clock tower in the background
(a) a couple of giraffe standing next to each other (b) a giraffe is standing in a tree in a forest (c) two giraffes standing next to each other in a tree (a) a group of people standing around a pizza (b) a man holding a box of food in front of him (c) a couple of people that are holding a pizza (a) a group of people playing a game with remote controllers (b) a man and a woman playing a video game (c) a group of people sitting around a living room (a) a man is standing in the middle of a street (b) a man sitting on a beach with a surfboard (c) a man and woman sitting on the beach (a) a glass vase with some flowers in it (b) a vase filled with flowers on top of a table (c) a vase filled with flowers on top of a table (a) a man and a woman sitting at a table eating pizza (b) a woman is taking a picture of herself in a mirror (c) two women sitting at a table with a pizza
(a) a man sitting in a kitchen next to a woman (b) a woman standing in front of a counter in a kitchen (c) two women in a kitchen preparing food on a table (a) a man and a woman standing next to each other (b) a man in a suit and tie standing in a room (c) a man in a suit and tie standing next to a man (a) a man riding a bike down a street (b) a man riding a motorcycle down a street (c) a man riding a bike with a helmet on his head (a) a woman is playing tennis on a court (b) a woman is playing tennis on a tennis court (c) a tennis player in action on the court (a) a woman in a bathroom with a sink and a mirror (b) a man standing in a kitchen next to a stove (c) a man standing in a kitchen next to a counter (a) a man holding a nintendo wii game controller (b) a young boy sitting on a couch holding a remote control (c) a young child is holding a toy in his hand
(a) a person riding a horse on a beach (b) a woman is riding a horse in a field (c) a girl is riding a horse in a field (a) a bunch of vases sitting on a shelf (b) a bunch of flowers in a vase on a table (c) a bunch of colorful vases sitting on a table (a) a man riding a bike down a street next to tall buildings (b) a man is on a boat in the water (c) a couple of people standing on top of a bridge (a) a man riding a skateboard with a dog (b) a dog is riding a skateboard on a street (c) a dog on a skateboard in the middle of the street (a) a young boy in a baseball uniform holding a glove
(b) a man is sitting on the ground holding a skateboard (c) a man sitting on the ground with a baseball glove
(a) a woman holding a tennis racquet on a court (b) a dog with a tennis racket in a basket (c) a person holding a tennis racket in a park
Figure 5:",Acknowledgments,[0],[0]
"Qualitative examples comparing the generated captions of (a) OBJ2TEXT-YOLO, (b) CNNRNN and (c)",Acknowledgments,[0],[0]
OBJ2TEXT-YOLO + CNN-RNN.,Acknowledgments,[0],[0]
Images are selected from the 500 human evaluation images and annotated with YOLO object detection results.,Acknowledgments,[0],[0]
Captions preferred by human evaluators with agreement are highlighted in bold text.,Acknowledgments,[0],[0]
Generating captions for images is a task that has recently received considerable attention.,abstractText,[0],[0]
"In this work we focus on caption generation for abstract scenes, or object layouts where the only information provided is a set of objects and their locations.",abstractText,[0],[0]
"We propose OBJ2TEXT, a sequence-tosequence model that encodes a set of objects and their locations as an input sequence using an LSTM network, and decodes this representation using an LSTM language model.",abstractText,[0],[0]
"We show that our model, despite encoding object layouts as a sequence, can represent spatial relationships between objects, and generate descriptions that are globally coherent and semantically relevant.",abstractText,[0],[0]
We test our approach in a task of object-layout captioning by using only object annotations as inputs.,abstractText,[0],[0]
"We additionally show that our model, combined with a state-of-the-art object detector, improves an image captioning model from 0.863 to 0.950 (CIDEr score) in the test benchmark of the standard MS-COCO Captioning task.",abstractText,[0.9635140101743779],"['For the decentralized setting, we introduced the multi-step dual accelerated (MSDA) algorithm with a provable optimal linear convergence rate, and showed its high efficiency compared to other state-of-the-art methods, including distributed ADMM and EXTRA.']"
OBJ2TEXT: Generating Visually Descriptive Language from Object Layouts,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 444–451 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics",text,[0],[0]
"Visual Reasoning (Antol et al., 2015; Andreas et al., 2016; Bisk et al., 2016; Johnson et al., 2017) requires a sophisticated understanding of the compositional language instruction and its relationship with the corresponding image.",1 Introduction,[0],[0]
Suhr et al. (2017) recently proposed a challenging new NLVR task and dataset in this direction with natural and complex language statements that have to be classified as true or false given a multi-image set (shown in Fig. 1).,1 Introduction,[0],[0]
"Specifically, each task instance consists of an image with three sub-images and a statement which describes the image.",1 Introduction,[0],[0]
"The model is asked to answer the question whether the given statement is consistent with the image or not.
",1 Introduction,[0],[0]
"To solve the task, the designed model needs to fuse the information from two different domains,
the visual objects and the language, and learn accurate relationships between the two.",1 Introduction,[0],[0]
Another difficulty is that the objects in the image do not have a fixed order and the number of objects also varies.,1 Introduction,[0],[0]
"Moreover, each statement reasons for truth over three sub-images (instead of the usual single image setup), which also breaks most of the existing models.",1 Introduction,[0],[0]
"In our paper, we introduce a novel end-to-end model to address these three problems, leading to strong gains over the previous best model.",1 Introduction,[0],[0]
"Our pointer network based LSTM-RNN sorts and learns recurrent representations of the objects in each sub-image, so as to match it better with the order of the phrases in the language statement.",1 Introduction,[0],[0]
"For this, it employs an RL-based policy gradient method with a reward extracted from the subsequent comprehension model.",1 Introduction,[0],[0]
"With these strong representations of the visual objects and the statement units, a joint-bidirectional attention flow model builds consistent, two-way matchings between the representations in different domains.",1 Introduction,[0],[0]
"Finally, since the scores computed by the bidirectional attention are about the three sub-images, a pooling combination layer over the three subimage representations is required to give the final score of the whole image.
",1 Introduction,[0],[0]
"On the structured-object-representation version of the dataset, our pointer-based, end-to-end bidi-
444
rectional attention model achieves an accuracy of 73.9%, outperforming the previous (end-to-end) state-of-the-art method by 6.2% absolute, where both the pointer network and the bidirectional attention modules contribute significantly.",1 Introduction,[0],[0]
"We also contribute several other strong baselines for this new NLVR task based on Relation Networks (Santoro et al., 2017) and BiDAF (Seo et al., 2016).",1 Introduction,[0],[0]
"Furthermore, we also show the result of our joint bidirectional attention model on the raw-image version (with pixel-level, spatial-filter CNNs) of the NLVR dataset, where our model achieves an accuracy of 69.7% and outperforms the previous best result by 3.6%.",1 Introduction,[0],[0]
"On the unreleased leaderboard test set, our model achieves an accuracy of 71.8% and 66.1% on the structured and raw-image versions, respectively, leading to 4% absolute improvements on both tasks.",1 Introduction,[0],[0]
"Besides the NLVR corpus with a focus on complex and natural compositional language (Suhr et al., 2017), other useful visual reasoning datasets have been proposed for navigation and assembly tasks (MacMahon et al., 2006; Bisk et al., 2016), as well as for visual Q&A tasks which focus more on complex real-world images (Antol et al., 2015; Johnson et al., 2017).",2 Related work,[0],[0]
"Specifically for the NLVR dataset, previous models have incorporated property- and count-based features of the objects and the language (Suhr et al., 2017), or extra semantic parsing (logical form) annotations (Goldman et al., 2017) – we focus on end-toend models for this visual reasoning task.
",2 Related work,[0],[0]
"Attention mechanism (Bahdanau et al., 2014; Luong et al., 2015; Xu et al., 2015) has been widely used for conditioned language generation tasks.",2 Related work,[0],[0]
"It is further used to learn alignments between different modalities (Lu et al., 2016; Wang and Jiang, 2016; Seo et al., 2016; Andreas et al., 2016; Chaplot et al., 2017).",2 Related work,[0],[0]
"In our work, a bidirectional attention mechanism is used to learn a joint representation of the visual objects and the words by building matchings between them.
",2 Related work,[0],[0]
"Pointer network (Vinyals et al., 2015) was introduced to learn the conditional probability of an output sequence.",2 Related work,[0],[0]
Bello et al. (2016) extended this to near-optimal combinatorial optimization via reinforcement learning.,2 Related work,[0],[0]
"In our work, a policy gradient based pointer network is used to “sort” the objects conditioned on the statement, such that the sequence of ordered objects is sent to the subse-
quent comprehension model for a reward.",2 Related work,[0],[0]
"The training datum for this task consists of the statement s, the structured-representation objects o in the image I , and the ground truth label y (which is 1 for true and 0 for false).",3 Model,[0],[0]
"Our BiATTPointer model (shown in Fig. 2) for the structuredrepresentation task uses the pointer network to sort the object sequence (optimized by policy gradient), and then uses the comprehension model to calculate the probability P (s, o) of the statement s being consistent with the image.",3 Model,[0.9583361063369107],"['Computing the gradient of f̄ is performed by sending all the local gradients ∇fi to a single node (denoted as master node) in ∆ communication steps (which may involve several simultaneous messages), and then returning the new parameter θt+1 to every node in the network (which requires another ∆ communication steps).']"
"Our CNNBiATT model for the raw-image I dataset version is similar but learns the structure directly via pixellevel, spatial-filter CNNs – details in Sec. 5 and the appendix.",3 Model,[0],[0]
"In the remainder of this section, we first describe our BiATT comprehension model and then the pointer network.",3 Model,[0],[0]
"We use one bidirectional LSTM-RNN (Hochreiter and Schmidhuber, 1997) (denoted by LANGLSTM) to read the statement s = w1, w2, . . .",3.1 Comprehension Model with Joint Bidirectional Attention,[0],[0]
", wT, and output the hidden state representations {hi}.",3.1 Comprehension Model with Joint Bidirectional Attention,[0],[0]
A word embedding layer is added before the LSTM to project the words to high-dimension vectors {w̃i}.,3.1 Comprehension Model with Joint Bidirectional Attention,[0],[0]
"h1,h2, . .",3.1 Comprehension Model with Joint Bidirectional Attention,[0],[0]
.,3.1 Comprehension Model with Joint Bidirectional Attention,[0],[0]
", hT = LSTM (w̃1, w̃2, . . .",3.1 Comprehension Model with Joint Bidirectional Attention,[0],[0]
", w̃T) (1)
The raw features of the objects in the j-th subimage are {ojk} (since the NLVR dataset has 3 subimages per task).",3.1 Comprehension Model with Joint Bidirectional Attention,[0],[0]
A fully-connected (FC) layer without nonlinearity projects the raw features to object embeddings {ejk}.,3.1 Comprehension Model with Joint Bidirectional Attention,[0],[0]
"We then go through all the objects in random order (or some learnable order, e.g., via our pointer network, see Sec. 3.2) by another bidirectional LSTM-RNN (denoted by OBJ-LSTM), whose output is a sequence of vectors {gjk}which is used as the (left plus right memory) representation of the objects (the objects in different sub-images are handled separately):
ejk = W o",3.1 Comprehension Model with Joint Bidirectional Attention,[0],[0]
j k + b,3.1 Comprehension Model with Joint Bidirectional Attention,[0],[0]
"(2)
gj1, g j 2, . . .",3.1 Comprehension Model with Joint Bidirectional Attention,[0],[0]
", g j Nj = LSTM (e j 1, e j 2, . . .",3.1 Comprehension Model with Joint Bidirectional Attention,[0],[0]
", e j Nj ) (3)
where Nj is the number of the objects in jth subimage.",3.1 Comprehension Model with Joint Bidirectional Attention,[0],[0]
"Now, we have two vector sequences for the representations of the words and the objects, using which the bidirectional attention then calculates the score measuring the correspondence be-
tween the statement and the image’s object structure.",3.1 Comprehension Model with Joint Bidirectional Attention,[0],[0]
"To simplify the notation, we will ignore the sub-image index j. We first merge the LANGLSTM hidden outputs {hi} and the object-aware context vectors {ci} together to get the joint representation {ĥi}.",3.1 Comprehension Model with Joint Bidirectional Attention,[0],[0]
"The object-aware context vector ci for a particular word wi is calculated based on the bilinear attention between the word representation hi and the representations of the objects {gk}:
αi,k = softmaxk (h ᵀ i B1 gk) (4)
ci = ∑
k
αi,k · gk (5)
ĥi",3.1 Comprehension Model with Joint Bidirectional Attention,[0],[0]
"= relu (WLANG [hi; ci; hi−ci; hi◦ci]) (6) where the symbol ◦ denotes element-wise multiplication.
",3.1 Comprehension Model with Joint Bidirectional Attention,[0],[0]
Improvement over BiDAF The BiDAF model of Seo et al. (2016) does not use a full objectto-words attention mechanism.,3.1 Comprehension Model with Joint Bidirectional Attention,[0],[0]
The query-todocument attention module in BiDAF added the attended-context vector to the document representation instead of the query representation.,3.1 Comprehension Model with Joint Bidirectional Attention,[0],[0]
"However, the inverse attention from the objects to the words is important in our task because the representation of the object depends on its corresponding words.",3.1 Comprehension Model with Joint Bidirectional Attention,[0],[0]
"Therefore, different from the BiDAF model, we create an additional ‘symmetric’ attention to merge the OBJ-LSTM hidden outputs {gk} and the statement-aware context vectors {dk} together to get the joint representation {ĝk}.",3.1 Comprehension Model with Joint Bidirectional Attention,[0],[0]
"The improvement (6.1%) of our BiATT model over the BiDAF model is shown in Table 1.
",3.1 Comprehension Model with Joint Bidirectional Attention,[0],[0]
"βk,i = softmaxi",3.1 Comprehension Model with Joint Bidirectional Attention,[0],[0]
"( gᵀk B2 hi ) (7)
dk = ∑
i
βk,i · hi (8)
ĝk = relu",3.1 Comprehension Model with Joint Bidirectional Attention,[0],[0]
"(WOBJ [gk; dk; gk−dk; gk◦dk]) (9)
These above vectors {ĥi} and {ĝk} are the representations of the words and the objects which
are aware of each other bidirectionally.",3.1 Comprehension Model with Joint Bidirectional Attention,[0],[0]
"To make the final decision, two additional bidirectional LSTM-RNNs are used to further process the above attention-based representations via an additional memory-based layer.",3.1 Comprehension Model with Joint Bidirectional Attention,[0],[0]
"Lastly, two max pooling layers over the hidden output states create two single-vector outputs for the statement and the sub-image, respectively:
h̄1, h̄2, . . .",3.1 Comprehension Model with Joint Bidirectional Attention,[0],[0]
", h̄T = LSTM(ĥ1, ĥ2, . . .",3.1 Comprehension Model with Joint Bidirectional Attention,[0],[0]
", ĥT)",3.1 Comprehension Model with Joint Bidirectional Attention,[0],[0]
"(10)
ḡ1, ḡ2, . . .",3.1 Comprehension Model with Joint Bidirectional Attention,[0],[0]
", ḡN = LSTM(ĝ1, ĝ2, . . .",3.1 Comprehension Model with Joint Bidirectional Attention,[0],[0]
", ĝN) (11)
h̄ = ele max i
{ h̄i }
(12)
ḡ = ele max k {ḡk} (13)
where the operator ele max denotes the elementwise maximum over the vectors.",3.1 Comprehension Model with Joint Bidirectional Attention,[0],[0]
"The final scalar score for the sub-image is given by a 2-layer MLP over the concatenation of h̄ and ḡ as follows:
score = W2 tanh ( W1[h̄; ḡ] + b1 ) (14)
Max-Pooling over Sub-Images In order to address the 3 sub-images present in each NLVR task, a max-pooling layer is used to combine the above-defined scores of the sub-images.",3.1 Comprehension Model with Joint Bidirectional Attention,[0],[0]
"Given that the sub-images do not have any specific ordering among them (based on the data collection procedure (Suhr et al., 2017)), a pooling layer is suitable because it is permutation invariant.",3.1 Comprehension Model with Joint Bidirectional Attention,[0],[0]
"Moreover, many of the statements are about the existence of a special object or relationship in one sub-image (see Fig. 1) and hence the max-pooling layer effectively captures the meaning of these statements.",3.1 Comprehension Model with Joint Bidirectional Attention,[0],[0]
"We also tried other combination methods (meanpooling, concatenation, LSTM, early pooling on the features/vectors, etc.); the max pooling (on scores) approach was the simplest and most effective method among these (based on the dev set).
",3.1 Comprehension Model with Joint Bidirectional Attention,[0],[0]
"The overall probability that the statement correctly describes the full image (with three subimages) is the sigmoid of the final max-pooled
score.",3.1 Comprehension Model with Joint Bidirectional Attention,[0],[0]
"The loss of the comprehension model is the negative log probability (i.e., the cross entropy):
P (s, o) =σ",3.1 Comprehension Model with Joint Bidirectional Attention,[0],[0]
"( max j scorej )
(15)
L(s, o, y) =",3.1 Comprehension Model with Joint Bidirectional Attention,[0],[0]
"− y logP (s, o)",3.1 Comprehension Model with Joint Bidirectional Attention,[0],[0]
"− (1− y) log(1− P (s, o))",3.1 Comprehension Model with Joint Bidirectional Attention,[0],[0]
"(16)
where y is the ground truth label.",3.1 Comprehension Model with Joint Bidirectional Attention,[0],[0]
"Instead of randomly ordering the objects, humans look at the objects in an appropriate order w.r.t.",3.2 Pointer Network,[0],[0]
their reading of the given statement and after the first glance of the image.,3.2 Pointer Network,[0],[0]
"Following this idea, we use an additional pointer network (Vinyals et al., 2015) to find the best object ordering for the subsequent language comprehension model.",3.2 Pointer Network,[0],[0]
"The pointer network contains two RNNs, the encoder and the decoder.",3.2 Pointer Network,[0],[0]
The encoder reads all the objects in a random order.,3.2 Pointer Network,[0],[0]
"The decoder then learns a permutation π of the objects’ indices, by recurrently outputting a distribution over the objects based on the attention over the encoder hidden outputs.",3.2 Pointer Network,[0],[0]
"At each time step, an object is sampled without replacement following this distribution.",3.2 Pointer Network,[0],[0]
"Thus, the pointer network models a distribution p(π | s, o) over all the permutations:
p(π | s, o) =",3.2 Pointer Network,[0],[0]
"∏
i
p (π(i) | π(< i), s, o) (17)
",3.2 Pointer Network,[0],[0]
"Furthermore, the appropriate order of the objects depends on the language statement, and hence the decoder importantly attends to the hidden outputs of the LANG-LSTM (see Eqn. 1).
",3.2 Pointer Network,[0],[0]
The pointer network is trained via reinforcement learning (RL) based policy gradient optimization.,3.2 Pointer Network,[0],[0]
"The RL loss LRL(s, o, y) is defined as the expected comprehension loss (expectation over the distribution of permutations):
LRL(s, o, y) =",3.2 Pointer Network,[0],[0]
"Eπ∼p(·|s,o)L(s, o[π], y) (18)
where o[π] denotes the permuted input objects for permutation π, and L is the loss function defined in Eqn. 16.",3.2 Pointer Network,[0],[0]
"Suppose that we sampled a permutation π∗ from the distribution p(π|s, o); then the above RL loss could be optimized via policy gradient methods (Williams, 1992).",3.2 Pointer Network,[0],[0]
"The reward R is the negative loss of the subsequent comprehension model L(s, o[π∗], y).",3.2 Pointer Network,[0],[0]
"A baseline b is subtracted from the reward to reduce the variance (we use the
self-critical baseline of Rennie et al. (2016)).",3.2 Pointer Network,[0],[0]
"The gradient of the loss LRL could then be approximated as:
R =− L(s, o[π∗], y) (19) ∇θLRL(s, o, y)",3.2 Pointer Network,[0],[0]
"≈ − (R− b)∇θ log p(π∗ | s, o)
+∇θL(s, o[π∗], y) (20)
",3.2 Pointer Network,[0],[0]
This overall BiATT-Pointer model (for the structured-representation task) is shown in Fig. 2.,3.2 Pointer Network,[0],[0]
"We evaluate our model on the NLVR dataset (Suhr et al., 2017), for both the structured and raw-image versions.",4 Experimental Setup,[0],[0]
All model tuning was performed on the dev set.,4 Experimental Setup,[0],[0]
"Given the fact that the dataset is balanced (the number of true labels and false labels are roughly the same), the accuracy of the whole corpus is used as the metric.",4 Experimental Setup,[0],[0]
"We only use the raw features of the statement and the objects with minimal standard preprocessing (e.g., tokenization and UNK replacement; see appendix for reproducibility training details).",4 Experimental Setup,[0],[0]
Results on Structured Representations Dataset: Table 1 shows our primary model results.,5 Results and Analysis,[0],[0]
"In terms of previous work, the state-of-the-art result for end-to-end models is ‘MAXENT’, shown in Suhr et al. (2017).1 Our proposed BiATT-Pointer model (Fig. 2) achieves a 6.2% improvement on the public test set and a 4.0% improvement on the unreleased test set over this SotA model.",5 Results and Analysis,[0],[0]
"To show the individual effectiveness of our BiATT and Pointer components, we also provide two ablation results: (1) the bidirectional attention BiATT model without the pointer network; and (2) our BiENC baseline model without any attention or the pointer mechanisms.",5 Results and Analysis,[0],[0]
"The BiENC model uses the similarity between the last hidden outputs of the LANGLSTM and the OBJ-LSTM as the score (Eqn. 14).
",5 Results and Analysis,[0],[0]
"Finally, we also reproduce some recent popular frameworks, i.e., Relationship Network (Santoro et al., 2017) and BiDAF model (Seo et al., 2016), which have been proven to be successful in other machine comprehension and visual reasoning tasks.",5 Results and Analysis,[0],[0]
The results of these models are weaker than our proposed model.,5 Results and Analysis,[0],[0]
"Reimplementation details are shown in the appendix.
",5 Results and Analysis,[0],[0]
"1There is also recent work by Goldman et al. (2017), who use extra, manually-labeled semantic parsing data to achieve a released/unreleased test accuracy of 80.4%/83.5%, resp.",5 Results and Analysis,[0],[0]
"Results on Raw Images Dataset: To further show the effectiveness of our BiATT model, we apply this model to the raw image version of the NLVR dataset, with minimal modification.",Negative Examples,[0],[0]
"We simply replace each object-related LSTM with a visual feature CNN that directly learns the structure via pixel-level, spatial filters (instead of a pointer network which addresses an unordered sequence of structured object representations).",Negative Examples,[0],[0]
"As shown in Table 1, this CNN-BiATT model outperforms the neural module networks (NMN) (Andreas et al., 2016) previous-best result by 3.6% on the public test set and 4.1% on the unreleased test set.",Negative Examples,[0],[0]
More details and the model figure are in the appendix.,Negative Examples,[0],[0]
Output Example Analysis:,Negative Examples,[0],[0]
"Finally, in Fig. 1, we show some output examples which were successfully solved by our BiATT-Pointer model but failed in our strong baselines.",Negative Examples,[0],[0]
The left two examples in Fig. 1 could not be handled by the BiENC model.,Negative Examples,[0],[0]
The right two examples are incorrect for the BiATT model without the ordering-based pointer network.,Negative Examples,[0],[0]
"Our model can quite successfully understand the complex meanings of the attributes and their relationships with the diverse objects, as well as count the occurrence of and reason over objects without any specialized features.
",Negative Examples,[0],[0]
"Next, in Fig. 3, we also show some negative examples on which our model fails to predict the correct answer.",Negative Examples,[0],[0]
"The top two examples involve com-
plex high-level phrases e.g., “touching any edge” or “touching the base”, which are hard for an endto-end model to capture, given that such statements are rare in the training data.",Negative Examples,[0],[0]
"Based on the result of the validation set, the max-pooling layer is selected as the combination method in our model.",Negative Examples,[0],[0]
The max-pooling layer will choose the highest score from the sub-images as the final score.,Negative Examples,[0],[0]
"Thus, the layer could easily handle statements about single-subimage-existence based reasoning (e.g., the 4 positively-classified examples in Fig. 1).",Negative Examples,[0],[0]
"However, the bottom two negatively-classified examples in Fig. 3 could not be resolved because of the limitation of the max-pooling layer on scenarios that consider multiple-subimage-existence.",Negative Examples,[0],[0]
"We did try multiple other pooling and combination methods, as mentioned in Sec. 3.1.",Negative Examples,[0],[0]
"Among these methods, the concatenation, early pooling and LSTM-fusion approaches might have the ability to solve these particular bottom-two failed statements.",Negative Examples,[0],[0]
"In our future work, we are addressing multiple types of pooling methods jointly.",Negative Examples,[0],[0]
We presented a novel end-to-end model with joint bidirectional attention and object-ordering pointer networks for visual reasoning.,6 Conclusion,[0],[0]
We evaluate our model on both the structured-representation and raw-image versions of the NLVR dataset and achieve substantial improvements over the previous end-to-end state-of-the-art results.,6 Conclusion,[0],[0]
We thank the anonymous reviewers for their helpful comments.,Acknowledgments,[0],[0]
"This work was supported by a Google Faculty Research Award, a Bloomberg Data Science Research Grant, an IBM Faculty Award, and NVidia GPU awards.",Acknowledgments,[0],[0]
"As shown in Fig. 4, we apply our BiATT model to the raw image dataset with minimal modification.",A.1 CNN-BiATT Model Details,[0],[0]
The visual input of the model for this task is changed from the unordered structured representation set of objects o to the raw image pixels I .,A.1 CNN-BiATT Model Details,[0],[0]
"Hence, we replace all object-related LSTMs (e.g., the OBJ-LSTM and the LSTM-RNN in the bidirectional attention in Fig. 2) with visual feature convolutional neural networks (CNNs) that directly learn the structure via pixel-level, spatial filters (instead of a pointer network which addresses an unordered sequence of structured object representations).
",A.1 CNN-BiATT Model Details,[0],[0]
"The training datum for the NLVR raw-image version consists of the statement s, the image I and the ground truth label y.",A.1 CNN-BiATT Model Details,[0],[0]
"The image I contains three sub-images x1, x2 and x3.",A.1 CNN-BiATT Model Details,[0],[0]
We will use x to indicate any sub-image.,A.1 CNN-BiATT Model Details,[0],[0]
The superscript which indicates the index of the sub-image is ignored to simplify the notation.,A.1 CNN-BiATT Model Details,[0],[0]
The representation of the statement {hi} is calculated by the LANGLSTM as before.,A.1 CNN-BiATT Model Details,[0],[0]
"For the image representation, we project the sub-image to a sequence of feature vectors (i.e., the feature map) {al : l = 1, . . .",A.1 CNN-BiATT Model Details,[0],[0]
", L} corresponding to the different image locations.",A.1 CNN-BiATT Model Details,[0],[0]
L = m × m is the size of the features and m is the width and height of the feature map.,A.1 CNN-BiATT Model Details,[0],[0]
"The projection consists of ResNet-V2-101 (He et al., 2016) and a following fully-connected (FC) layer.",A.1 CNN-BiATT Model Details,[0],[0]
"We only use the blocks in the ResNet before the average pooling layer and the output of the ResNet is a feature map of size m×m×2048.
f1, . . .",A.1 CNN-BiATT Model Details,[0],[0]
", fL = ResNet(x) (21)
al = relu(Wx fl + bx) (22)
",A.1 CNN-BiATT Model Details,[0],[0]
The joint-representation of the statement {ĥi} is the combination of the LANG-LSTM,A.1 CNN-BiATT Model Details,[0],[0]
"hidden output states {hi} and the image-aware context vectors {ci}:
αi,l = softmaxl",A.1 CNN-BiATT Model Details,[0],[0]
"(h ᵀ i B1 al) (23)
ci = ∑
l
αi,l · al (24)
ĥi",A.1 CNN-BiATT Model Details,[0],[0]
"= relu (WLANG [hi; ci; hi−ci; hi◦ci]) (25)
",A.1 CNN-BiATT Model Details,[0],[0]
"The joint-representation of the image {âl} is cal-
culated in the same way:
βl,i = softmaxi ( aᵀl B2 hi ) (26)
",A.1 CNN-BiATT Model Details,[0],[0]
"dl = ∑
i
βl,i · hi (27)
âl = relu",A.1 CNN-BiATT Model Details,[0],[0]
"(WIMG [al; dl; al−dl; al◦dl]) (28)
",A.1 CNN-BiATT Model Details,[0],[0]
The joint-representation of the statement is further processed by a LSTM-RNN.,A.1 CNN-BiATT Model Details,[0],[0]
"Different from our BiATT model, a 3-layers CNN is used for modeling the joint-representation of the image {âl}.",A.1 CNN-BiATT Model Details,[0],[0]
The output of the CNN layer is another feature map {āl}.,A.1 CNN-BiATT Model Details,[0],[0]
"Each CNN layer has kernel size 3 × 3 and uses relu as the activation function, and then we finally use element-wise max operator similar to Sec. 3.1:
h̄1, h̄2, . . .",A.1 CNN-BiATT Model Details,[0],[0]
", h̄T = LSTM(ĥ1, ĥ2, . . .",A.1 CNN-BiATT Model Details,[0],[0]
", ĥT) (29)
ā1, ā2, . . .",A.1 CNN-BiATT Model Details,[0],[0]
", āL’ = CNN(â1, â2, . . .",A.1 CNN-BiATT Model Details,[0],[0]
", âL) (30)
h̄ = ele max i
{ h̄i }
(31)
ā = ele max l {āl} (32)
",A.1 CNN-BiATT Model Details,[0],[0]
"At last, we use the same method as our BiATT model to calculate the score and the loss function:
score(s, x) =W2 tanh ( W1[h̄; ā] + b1 ) (33)
P (s, I) =σ",A.1 CNN-BiATT Model Details,[0],[0]
"( max j score(s, xj) ) (34)
",A.1 CNN-BiATT Model Details,[0],[0]
"L(s, I, y) =",A.1 CNN-BiATT Model Details,[0],[0]
"− y logP (s, I)",A.1 CNN-BiATT Model Details,[0],[0]
"− (1− y) log(1− P (s, I))",A.1 CNN-BiATT Model Details,[0],[0]
(35),A.1 CNN-BiATT Model Details,[0],[0]
"We reimplement a Relationship Network (Santoro et al., 2017), using a three-layer MLP with
256 units per layer in the G-net and a three-layer MLP consisting of 256, 256 (with 0.3 dropout), and 1 units with ReLU nonlinearities for F-net.",A.2 Reimplementation Details for Relationship Network and BiDAF Models,[0],[0]
"We also reimplement a BiDAF model (Seo et al., 2016) using 128-dimensional word embedding, 256-dimensional LSTM-RNN and 0.3 dropout rate.",A.2 Reimplementation Details for Relationship Network and BiDAF Models,[0],[0]
A max pooling layer on top of the modeling layer of BiDAF is used to merge the hidden outputs to a single vector.,A.2 Reimplementation Details for Relationship Network and BiDAF Models,[0],[0]
"For preprocessing, we replace the words whose occurrence is less than 3 with the “UNK” token.",A.3.1 BiATT-Pointer,[0],[0]
We create a 9 dimension vector as the feature of each object.,A.3.1 BiATT-Pointer,[0],[0]
"This feature contains the location (x, y) in 2D coordinate, the size of the object and two 3-dimensional hot vectors for the shape and the color.",A.3.1 BiATT-Pointer,[0],[0]
"The (x, y) coordinates are normalized to the range [−1, 1].
",A.3.1 BiATT-Pointer,[0],[0]
"For the model hyperparameters (all lightly tuned on dev set), the dimension of the word embedding is 128, and the number of units in an LSTM cell is 256.",A.3.1 BiATT-Pointer,[0],[0]
The word embedding is trained from scratch.,A.3.1 BiATT-Pointer,[0],[0]
The object feature is projected to a 64-dimensional vector.,A.3.1 BiATT-Pointer,[0],[0]
The dimensions of joint representation ĥi,A.3.1 BiATT-Pointer,[0],[0]
and ĝk are both 512.,A.3.1 BiATT-Pointer,[0],[0]
The first fully-connected layer in calculating the subimages score has 512 units.,A.3.1 BiATT-Pointer,[0],[0]
All the trainable variables are initialized with the Xavier initializer.,A.3.1 BiATT-Pointer,[0],[0]
"To regularize the training process, we add a dropout rate 0.3 to the hidden output of the LSTM-RNNs and before the last MLP layer which calculates the score for sub-images.",A.3.1 BiATT-Pointer,[0],[0]
We also clip the gradients by their norm to avoid gradient exploding.,A.3.1 BiATT-Pointer,[0],[0]
"The losses are optimized by a single Adam optimizer and the learning rate is fixed at 1e-4.
",A.3.1 BiATT-Pointer,[0],[0]
"For the pointer network, we sample the objects following the distribution of the objects at each decoder step during training.",A.3.1 BiATT-Pointer,[0],[0]
"In inference, we select the object with maximum probability.",A.3.1 BiATT-Pointer,[0],[0]
"We use the self-critical baseline (Rennie et al., 2016) to stabilize the RL training, where the final score in inference (choosing object with maximum probability) is subtracted from the reward.",A.3.1 BiATT-Pointer,[0],[0]
"To reduce the number of parameters, we share the weight of the fully-connected layer which projects the raw object feature to the high dimensional vector in the pointer encoder, the pointer decoder, and the OBJ-
LSTM.",A.3.1 BiATT-Pointer,[0],[0]
"The pointer decoder attends to the hidden outputs of the LANG-LSTM using bilinear attention (Luong et al., 2015).",A.3.1 BiATT-Pointer,[0],[0]
We initialize our model with weights of the public pretrained ResNet-V2-101 (based on the ImageNet dataset) and freeze it during training.,A.3.2 CNN-BiATT,[0],[0]
The ResNet projects the sub-image to a feature map of 10× 10 × 2048.,A.3.2 CNN-BiATT,[0],[0]
The feature map is normalized to a mean of 0 and a standard deviation of 1 before feeding into the FC layer.,A.3.2 CNN-BiATT,[0],[0]
The fully connected layer after the ResNet has 512 units.,A.3.2 CNN-BiATT,[0],[0]
Each layer of the 3-layers CNN in the bidirectional attention has kernel size 3× 3 with 512 filters and no padding.,A.3.2 CNN-BiATT,[0],[0]
The BiENC model uses LANG-LSTM and OBJLSTM to read the statement and the objects.,A.3.3 BiENC,[0],[0]
A bilinear form calculates the similarity between the last hidden outputs of the two LSTM-RNNs.,A.3.3 BiENC,[0],[0]
The similarity is directly used as the score of the subimage.,A.3.3 BiENC,[0],[0]
The CNN-BiENC model replaces the OBJLSTM with a CNN.,A.3.3 BiENC,[0],[0]
"Visual reasoning with compositional natural language instructions, e.g., based on the newly-released Cornell Natural Language Visual Reasoning (NLVR) dataset, is a challenging task, where the model needs to have the ability to create an accurate mapping between the diverse phrases and the several objects placed in complex arrangements in the image.",abstractText,[0],[0]
"Further, this mapping needs to be processed to answer the question in the statement given the ordering and relationship of the objects across three similar images.",abstractText,[0],[0]
"In this paper, we propose a novel end-to-end neural model for the NLVR task, where we first use joint bidirectional attention to build a two-way conditioning between the visual information and the language phrases.",abstractText,[0],[0]
"Next, we use an RL-based pointer network to sort and process the varying number of unordered objects (so as to match the order of the statement phrases) in each of the three images and then pool over the three decisions.",abstractText,[0],[0]
Our model achieves strong improvements (of 4-6% absolute) over the state-of-theart on both the structured representation and raw image versions of the dataset.,abstractText,[0],[0]
Object Ordering with Bidirectional Matchings for Visual Reasoning,title,[0],[0]
"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 243–254 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics
https://doi.org/10.18653/v1/P17-1023",text,[0],[0]
"Expressions referring to objects in visual scenes typically include a word naming the type of the object: E.g., house in Figure 1 (a), or, as a very general type, thingy in Figure 1 (d).",1 Introduction,[0],[0]
"Determining such a name is a crucial step for referring expression generation (REG) systems, as many other decisions concerning, e.g., the selection of attributes follow from it (Dale and Reiter, 1995; Krahmer and Van Deemter, 2012).",1 Introduction,[0],[0]
"For a long time, however, research on REG mostly assumed the availability of symbolic representations of ref-
erent and scene, and sidestepped questions about how speakers actually choose these names, due to the lack of models capable of capturing what a word like house refers to in the real world.
",1 Introduction,[0],[0]
"Recent advances in image processing promise to fill this gap, with state-of-the-art computer vision systems being able to classify images into thousands of different categories (e.g. Szegedy et al. (2015)).",1 Introduction,[0],[0]
"However, classification is not naming (Ordonez et al., 2016).",1 Introduction,[0],[0]
"Standard object classification schemes are inherently “flat”, and treat object labels as mutually exclusive (Deng et al., 2014).",1 Introduction,[0],[0]
"A state-of-the-art object recognition system would be trained to classify the object in e.g. Figure 1 (a) as either house or building, ignoring the lexical similarity between these two names.",1 Introduction,[0],[0]
"In contrast, humans seem to be more flexible as to the chosen level of generality.",1 Introduction,[0],[0]
"Depending on the prototypicality of the object to name, and possibly other visual properties, a general name might be more or less appropriate.",1 Introduction,[0],[0]
"For instance, a robin can be named bird, but a penguin is better referred
243
to as “penguin” (Rosch, 1978); along the same lines, the rather unusual building in Figure 1 (c) that is not easy to otherwise categorise was named “structure”.
",1 Introduction,[0],[0]
"Other work at the intersection of image and language processing has investigated models that learn to directly associate visual objects with a continuous representation of word meaning, i.e. through cross-modal transfer into distributional vector spaces (Frome et al., 2013; Norouzi et al., 2013).",1 Introduction,[0],[0]
"Here, the idea is to exploit a powerful model of lexical similarity induced from large amounts text for being able to capture inherent lexical relations between object categories.",1 Introduction,[0],[0]
"Thus, under the assumption that such semantic spaces represent, in some form at least, taxonomic knowledge, this makes labels on different levels of specificity available for a given object.",1 Introduction,[0],[0]
"Moreover, if the mapping is sufficiently general, it should be able to map objects to an appropriate label, even if during training of the mapping this label has not been seen (zero-shot learning).
",1 Introduction,[0],[0]
"While cross-modal transfer seems to be a conceptually attractive model for learning object names, it is based on an important assumption that, in our view, has not received sufficient attention in previous works: it assumes that a given distributional vector space constitutes an optimal target representation that visual instances of objects can be mapped to.",1 Introduction,[0],[0]
"However, distributional representations of word meaning are known to capture a rather fuzzy notion of lexical similarity, e.g. car is similar to van and to street.",1 Introduction,[0],[0]
"A cross-modal transfer model is “forced” to learn to map objects into the same area in the semantic space if their names are distributionally similar, but regardless of their actual visual similarity.",1 Introduction,[0],[0]
"Indeed, we have found in a recent study that the contribution of distributional information to learning referential word meanings is restricted to certain types of words and does not generalize across the vocabulary (Zarrieß and Schlangen, 2017).
",1 Introduction,[0],[0]
"The goal of this work is to learn a model of referential word meaning that makes accurate object naming predictions and goes beyond treating words as independent, mutually exclusive labels in a flat classification scheme.",1 Introduction,[0],[0]
"We extend upon work on learning models of referential word use from corpora of images paired with referring expressions (Schlangen et al., 2016; Zarrieß and Schlangen, 2017) that treats words as individual
predictors capturing referential appropriateness.",1 Introduction,[0],[0]
"We explore different ways of linking these predictors to distributional knowledge, during application and during training.",1 Introduction,[0],[0]
"We find that these different models achieve very similar performance in a standard object naming task, though experiments on model combination suggest that they capture complementary aspects of referential meaning.",1 Introduction,[0],[0]
"In a zero-shot setup of an object naming task, we find that combining lexical and visual information during training is most beneficial, outperforming variants of cross-modal transfer.",1 Introduction,[0],[0]
"Grounding and Reference An early example for work in REG that goes beyond Dale and Reiter (1995)’s dominant symbolic paradigm is Deb Roy’s work from the early 2000s (Roy et al., 2002; Roy, 2002, 2005).",2 Related Work,[0],[0]
"Roy et al. (2002) use computer vision techniques to process a video feed, and to compute colour, positional and spatial features.",2 Related Work,[0],[0]
"These features are then associated in a learning process with certain words, resulting in an association of colour features with colour words, spatial features with prepositions, etc., and based on this, these words can be interpreted with reference to the scene currently presented to the video feed.",2 Related Work,[0],[0]
"Whereas Roy’s work still looked at relatively simple scenes with graphical objects, research on REG has recently started to investigate set-ups based on real-world images (Kazemzadeh et al., 2014; Gkatzia et al., 2015; Zarrieß and Schlangen, 2016; Mao et al., 2015).",2 Related Work,[0],[0]
"Importantly, the lowlevel visual features that can be extracted from these scenes correspond less directly to particular word classes.",2 Related Work,[0],[0]
"Moreover, the visual scenes contain many different types of objects, which poses new challenges for REG.",2 Related Work,[0],[0]
"For instance, Zarrieß and Schlangen (2016) find that semantic errors related to mismatches between nouns (e.g. the system generates tree vs. man) are particularly disturbing for users.",2 Related Work,[0],[0]
"Whereas Zarrieß and Schlangen (2016) propose a strategy to avoid object names when the systems confidence is low, we focus on improving the generation of object names, using distributional knowledge as an additional source.",2 Related Work,[0],[0]
"Similarly, Ordonez et al. (2016) have studied the problem of deriving appropriate object names, or so-called entry-level categories, from the output of an object recognizer.",2 Related Work,[0],[0]
"Their approach focusses on linking abstract object categories in ImageNet
to actual words via various translation procedures.",2 Related Work,[0],[0]
"We are interested in learning referential appropriateness and extensional word meanings directly from actual human referring expressions (REs) paired with objects in images, using an existing object recognizer for feature extraction.
",2 Related Work,[0],[0]
"Multi-modal distributional semantics Distributional semantic models are a well-known method for capturing lexical word meaning in a variety of tasks (Turney and Pantel, 2010; Mikolov et al., 2013; Erk, 2016).",2 Related Work,[0],[0]
"Recent work on multimodal distributional vector spaces (Feng and Lapata, 2010; Silberer and Lapata, 2014; Kiela and Bottou, 2014; Lazaridou et al., 2015b; Kottur et al., 2016) has aimed at capturing semantic similarity even more accurately by integrating distributional and perceptual features associated with words (mostly taken from images) into a single representation.
",2 Related Work,[0],[0]
"Cross-modal transfer Rather than fusing different modalities into a single, joint space, other work has looked at cross-modal mapping between spaces.",2 Related Work,[0],[0]
"Herbelot and Vecchi (2015) present a model that learns to map vectors in a distributional space to vectors in a set-theoretic space, showing that there is a functional relationship between distributional information and conceptual knowledge representing quantifiers and predicates.",2 Related Work,[0],[0]
"More related to our work are cross-modal mapping models,that learn to transfer from a representation of an object or image in the visual space to a vector in a distributional space (Socher et al., 2013; Frome et al., 2013; Norouzi et al., 2013; Lazaridou et al., 2014).",2 Related Work,[0],[0]
"Here, the motivation is to exploit the rich lexical knowledge encoded in a distributional space for learning visual classifications.",2 Related Work,[0],[0]
"In practice, these models are mostly used for zeroshot learning where the test set contains object categories not observed during training.",2 Related Work,[0],[0]
"When tested on standard object recognition tasks, transfer, however, comes at a price.",2 Related Work,[0],[0]
Frome et al. (2013) and Norouzi et al. (2013) both find that it slightly degrades performance as compared to a plain object classification using standard accuracy metrics (called flat “hit @k metric” in their paper).,2 Related Work,[0],[0]
"Interestingly though, Frome et al. (2013) report better performance using “hierarchical precision”, which essentially means that transfer predicts words that are ontologically closer to the gold label and makes “semantically more reasonable er-
rors”.",2 Related Work,[0],[0]
"To the best of our knowledge, this pattern has not been systematically investigated any further.",2 Related Work,[0],[0]
"Another known problem with cross-modal transfer is that it seems to generalize less well than expected, i.e. tends to reproduce word vectors observed during training (Lazaridou et al., 2015a).",2 Related Work,[0],[0]
"In this work, we present a model that exploits distributional knowledge for learning referential word meaning as well, but explore and compare different ways of combining visual and lexical aspects of referential word meaning.",2 Related Work,[0],[0]
We define object naming as follows:,3 Task and Data,[0],[0]
"Given an object x in an image, the task is to predict a word w that could be used as the head noun of a realistic referring expression.",3 Task and Data,[0],[0]
"(Cf. discussion above: “bird” when naming a robin, but “penguin” when naming a penguin.)",3 Task and Data,[0],[0]
"To get at this, we develop our approach using a corpus of referring expressions produced by human users under natural, interactive conditions (Kazemzadeh et al., 2014), and train and test on the corresponding head nouns in these REs.",3 Task and Data,[0],[0]
This is similar to picture naming setups used in psycholinguistic research (cf.,3 Task and Data,[0],[0]
"Levelt et al. (1991)) and based on the simplifying assumption that the name used for referring to an object can be determined successfully without looking at other objects in the image.
",3 Task and Data,[0],[0]
"We now summarise the details of our setup:
Corpus We train and test on the REFERIT corpus (Kazemzadeh et al., 2014), which is based on the SAIAPR image collection (Grubinger et al., 2006) (99.5k image regions;120K REs).",3 Task and Data,[0],[0]
"We follow (Schlangen et al., 2016) and select words with a minimum frequency of 40 in these two data sets, which gives us a vocabulary of 793 words.
",3 Task and Data,[0],[0]
"Names For most of our experiments, we only use a subset of this vocabulary, namely the set of object names.",3 Task and Data,[0],[0]
"As the REs contain nouns that cannot be considered to be object names (background, bottom, etc.), we extract a list of names from the semantically annotated held-out set released with the REFERIT.",3 Task and Data,[0],[0]
These correspond to ‘entry-level’ nouns mentioned in Kazemzadeh et al. (2014).,3 Task and Data,[0],[0]
This gives us a list of 159 names.,3 Task and Data,[0],[0]
"This set corresponds to the majority of object names in the corpus: out of the 99.5K available image regions, we use 80K for training and testing.",3 Task and Data,[0],[0]
"Thus, our experiments are on a smaller scale as compared
to (Ordonez et al., 2016).",3 Task and Data,[0],[0]
"Nevertheless, the data is challenging, as the corpus contains references to objects that fall outside of the object labeling scheme that available object recognition systems are typically optimized for, cf. Hu et al. (2015)’s discussion on “stuff” entities such “sky” or “grass” in the REFERIT data.",3 Task and Data,[0],[0]
"For testing, we remove relational REs (containing a relational preposition such as ‘left of X’), because here we cannot be sure that the head noun of the target is fully informative; we also remove REs with more than one head noun from our list (i.e. these are mostly relational expressions as well such as ‘girl laughing at boy’).",3 Task and Data,[0],[0]
"We pair each image region from the test set with its corresponding names from the remaining REs.
",3 Task and Data,[0],[0]
Image and Word Embeddings,3 Task and Data,[0],[0]
"Following Schlangen et al. (2016), we derive representations of our visual inputs with a convolutional neural network, ‘GoogleNet’ (Szegedy et al., 2015), which was trained on the ImageNet corpus (Deng et al., 2009), and extract the final fully-connected layer before the classification layer, to give us a 1024 dimensional representation of the region.",3 Task and Data,[0],[0]
"We add 7 features that encode information about the region relative to the image, thus representing each object as a vector of 1031 features.",3 Task and Data,[0],[0]
"As distributional word vectors, we use the word2vec representations provided by Baroni et al. (2014) (trained with CBOW, 5-word context window, 10 negative samples, 400 dimensions).",3 Task and Data,[0],[0]
Distributional Information,4 Three Models of Interfacing Visual and,[0],[0]
"Following Lazaridou et al. (2014), referential meaning can be represented as a translation function that projects visual representations of objects to linguistic representations of words in a distributional vector space.",4.1 Direct Cross-Modal Mapping,[0],[0]
"Thus, in contrast to standard object recognition systems or the other models we will use here, cross-modal mapping does not treat words as individual labels or classifiers, but learns to directly predict continuous representations of words in a vector space, such as the space defined by the word2vec embeddings that we use in this work.",4.1 Direct Cross-Modal Mapping,[0],[0]
"This model will be called TRANSFER below.
",4.1 Direct Cross-Modal Mapping,[0],[0]
"During training, we pair each object with the distributional embedding of its name, and use standard Ridge regression for learning the trans-
formation.",4.1 Direct Cross-Modal Mapping,[0],[0]
Lazaridou et al. (2014) and Lazaridou et al. (2015a) test a range of technical tweaks and different algorithms for cross-modal mapping.,4.1 Direct Cross-Modal Mapping,[0.9524873601678939],"['These algorithms typically alternate local incremental improvement steps (such as gradient steps) with communication steps between nodes in the network, and come with a variety of convergence rates (see for example Shi et al. (2014; 2015); Jakovetić et al. (2015); Nedich et al. (2016)).']"
"For ease of comparison with other models, we stick with simple Ridge Regression in this work.
",4.1 Direct Cross-Modal Mapping,[0],[0]
"For decoding, we map an object into the distributional space, and retrieve the nearest neighbors of the predicted vector using cosine similarity.",4.1 Direct Cross-Modal Mapping,[0],[0]
"In theory, the model should generalize easily to words that it has not observed in a pair with an object during training as it can map an object anywhere in the distributional space.",4.1 Direct Cross-Modal Mapping,[0],[0]
"Another approach is to keep visual and distributional information separate, by training a separate visual classifier for each word w in the vocabulary.",4.2 Lexical Mapping Through Individual Word Classifiers,[0],[0]
Predictions can then be mapped into distributional space during application time via the vectors of the predicted words.,4.2 Lexical Mapping Through Individual Word Classifiers,[0],[0]
"Here, we use Schlangen et al. (2016)’s WAC model, building the training set for each word w as follows: all visual objects in a corpus that have been referred to as w are used as positive instances, the remaining objects as negative instances.",4.2 Lexical Mapping Through Individual Word Classifiers,[0],[0]
"Thus, the classifiers learn to predict referential appropriateness for individual words based on the visual features of the objects they refer to, in isolation of other words.
",4.2 Lexical Mapping Through Individual Word Classifiers,[0],[0]
"During decoding, we apply all word classifiers from the model’s vocabulary to the given object, and take the argmax over the individual word probabilities.",4.2 Lexical Mapping Through Individual Word Classifiers,[0],[0]
"The model predicts names directly, without links into a distributional space.
",4.2 Lexical Mapping Through Individual Word Classifiers,[0],[0]
"In order to extend the model’s vocabulary for zero-shot learning, we follow Norouzi et al. (2013) and associate the top n words with their corresponding distributional vector and compute the convex combination of these vectors.",4.2 Lexical Mapping Through Individual Word Classifiers,[0],[0]
"Then, in parallel to cross-modal mapping, we retrieve the nearest neighbors of the combined embedding from the distributional space.",4.2 Lexical Mapping Through Individual Word Classifiers,[0],[0]
"Thus, with this model, we use two different modes of decoding: one that projects into distributional space, one that only applies the available word classifiers.
",4.2 Lexical Mapping Through Individual Word Classifiers,[0],[0]
"We did some small-scale experiments to find an optimal value for n, similar to Norouzi et al. (2013).",4.2 Lexical Mapping Through Individual Word Classifiers,[0],[0]
"In our case, performance started to decrease systematically with n > 10, but did not differ significantly for values below 10.",4.2 Lexical Mapping Through Individual Word Classifiers,[0],[0]
"In Section 5, we will report results for n set to 5 and 10.",4.2 Lexical Mapping Through Individual Word Classifiers,[0],[0]
"Finally, we implement an approach that combines ideas from cross-modal mapping with the WAC model: we train individual predictors for each word in the vocabulary, but, during training, we exploit lexical similarity relations encoded in a distributional space.",4.3 Word Prediction via Cross-Modal Similarity Mapping,[0],[0]
"Instead of treating a word as a binary classifier, we annotate its training instances with a fine-grained similarity signal according to their object names.",4.3 Word Prediction via Cross-Modal Similarity Mapping,[0],[0]
"When building the training set for such a word predictor w, instead of simply dividing objects into w and ¬w instances, we label each object with a real-valued similarity obtained from cosine similarity between w and v in a distributional vector space, where v is the word that was used to refer to the object.",4.3 Word Prediction via Cross-Modal Similarity Mapping,[0],[0]
"Thus, we task the model with jointly learning similarities and referential appropriateness, by training it with Ridge regression on a continuous output space.",4.3 Word Prediction via Cross-Modal Similarity Mapping,[0],[0]
"Object instances where v = w (i.e., the positive instances in the binary setup) have maximal similarity; the remaining instances have a lower value which is more or less close to maximal similarity.",4.3 Word Prediction via Cross-Modal Similarity Mapping,[0],[0]
"This is the SIM-WAP model, recently proposed in Zarrieß and Schlangen (2017).
",4.3 Word Prediction via Cross-Modal Similarity Mapping,[0],[0]
"Importantly, and going beyond Zarrieß and Schlangen (2017), this model allows for an innovative treatment of words that only exist in a distributional space (without being paired with visual referents in the image corpus): as the predictors are trained on a continuous output space, no genuine positive instances of a word’s referent are needed.",4.3 Word Prediction via Cross-Modal Similarity Mapping,[0],[0]
"When training a predictor for such a word w, we use all available objects from our corpus and annotate them with the expected lexical similarity between w and the actual object names v, which for all objects will be below the maximal value that marks genuine positive instances.",4.3 Word Prediction via Cross-Modal Similarity Mapping,[0],[0]
"During decoding, this model does not need to project its predictions into a distributional space, but it simply applies all available predictors to the object, and takes the argmax over the predicted referential appropriateness scores.",4.3 Word Prediction via Cross-Modal Similarity Mapping,[0],[0]
This Section reports on experiments in a standard setup of the object naming task where all object names are paired with visual instances of their referents during training.,5 Experiment 1: Naming Objects,[0],[0]
"In a comparable task, i.e. object recognition with known ob-
ject categories, cross-modal projection or transfer approaches have been reported to perform worse than standard object classification methods (Frome et al., 2013; Norouzi et al., 2013).",5 Experiment 1: Naming Objects,[0],[0]
This seems to suggest that lexical or at least distributional knowledge is detrimental when learning what a word refers to in the real world and that referential meaning should potentially be learned from visual object representation only.,5 Experiment 1: Naming Objects,[0],[0]
"Setup We use the train/test split of REFERIT data as in (Schlangen et al., 2016).",5.1 Model comparison,[0],[0]
We consider image regions with non-relational referring expressions that contain at least one of the 159 head nouns from the list of entry-level nouns (see section 3).,5.1 Model comparison,[0],[0]
"This amounts to 6208 image regions for testing and 73K instances for training.
",5.1 Model comparison,[0],[0]
"Results Table 1 shows accuracies in the object naming task for the TRANSFER, WAC and SIMWAP models according to their accuracies in the top n, including two variants of WAC where its top 5 and top 10 predictions are projected into the distributional space.",5.1 Model comparison,[0],[0]
"Overall, the models achieve very similar performance.",5.1 Model comparison,[0],[0]
"However, there is an interesting pattern when comparing accuracies @1 and @2 to accuracies in the top 5 predictions.",5.1 Model comparison,[0],[0]
"Thus, looking at accuracies for the top (two) predictions, the various models that link referential meaning to word representations in the distributional space all perform slightly worse than the plain WAC model, i.e. individual word classifiers trained on visual features only.",5.1 Model comparison,[0],[0]
This might suggest that certain aspects of referential word meaning are learned less accurately when mapping from visual to distributional space (which replicates results reported in the literature on standard object recognition benchmarks).,5.1 Model comparison,[0],[0]
"On the other hand, the SIM-WAP model is on a par with WAC in terms of the @5 accuracy.",5.1 Model comparison,[0],[0]
"This effect suggests that distributional knowledge that SIM-WAP has access to during training sometimes distracts the model from predicting the exact name chosen by a human speaker, but that SIM-WAP is still able to rank it among the most probable names.",5.1 Model comparison,[0],[0]
"As a simple accuracy-based evaluation is not suited to fully explain this pattern, we carry out a more detailed analysis in Section 5.3.",5.1 Model comparison,[0],[0]
"In order to get more insight into why the TRANSFER and SIM-WAP models produce slightly worse results than individual visual word classifiers, we now test to what extent the different models are complementary and combine them by aggregating over their naming predictions.",5.2 Model combination,[0],[0]
"If the models are complementary, their combination should lead to more confident and accurate naming decisions.
",5.2 Model combination,[0],[0]
"Setup We combine TRANSFER, SIM-WAP and WAC by aggregating the scores they predict for different object names for a given object.",5.2 Model combination,[0],[0]
"During testing, we apply all models to an image region and consider words ranked among the top 10.",5.2 Model combination,[0],[0]
We first normalize the referential appropriateness scores in each top-10 list and then compute their sum.,5.2 Model combination,[0],[0]
"This aggregation scheme will give more weight to words that appear in the top 10 list of different models, and less weight to words that only get top-ranked by a single model.",5.2 Model combination,[0],[0]
"We test on the same data as in Section 5.1.
",5.2 Model combination,[0],[0]
"Results Table 2 shows that all model combinations improve over the results of their isolated models in Table 1, suggesting that WAC, TRANSFER and SIM-WAP indeed do capture complementary aspects of referential word meaning.",5.2 Model combination,[0],[0]
"On their own, the distributionally informed models are less tuned to specific word occurrences than the visual word classifiers in the WAC model, but they can add useful information which leads to a clear overall improvement.",5.2 Model combination,[0],[0]
"We take this as a promising finding, supporting our initial hypothesis that knowledge on lexical distributional meaning should and
can be exploited when learning how to use words for reference.",5.2 Model combination,[0],[0]
"Figure 2 illustrates objects from our test set where the combination of TRANSFER, SIM-WAP and WAC predicts an accurate name, whereas the models in isolation do not.",5.3 Analysis,[0],[0]
"These examples give some interesting insight into why the models capture different aspects of referential word meaning.
",5.3 Analysis,[0],[0]
"Word Similarities Many of the examples in Figure 2 suggest that the object names ranked among the top 3 by the TRANSFER and SIMWAP model are semantically similar to each other, whereas WAC generates object names on top that describe very different underlying object categories, such as seal / rock in Figure 2(a), animal / lamp in Figure 2(g) or chair / shirt in Figure 2(c).",5.3 Analysis,[0],[0]
"To quantify this general impression, Table 3 shows cosine similarities among words in the top n generated by our models, using their word2vec embeddings.",5.3 Analysis,[0],[0]
The average cosine similarity between words in our vocabulary is 0.17.,5.3 Analysis,[0],[0]
"The TRANSFER and SIM-WAP model rank words on top that are clearly more similar to each other than word pairs on average, whereas words ranked top by the WAC model are more dissimilar to each other.",5.3 Analysis,[0],[0]
"Another remarkable finding is that the words generated by TRANSFER and SIM-WAP are not only more similar among the top predictions, but also more similar to the gold name (Table 3 , right columns).",5.3 Analysis,[0],[0]
This result is noteworthy since the accuracies for the top predictions shown in Table 1 are slightly below WAC.,5.3 Analysis,[0],[0]
"In general, this suggests that there is a trade-off between optimizing a model of referential word meaning to exact naming decisions, or tailoring it to make lexically consistent predictions.",5.3 Analysis,[0],[0]
"This parallels findings by Frome et al. (2013) who found that their transfer-based object recognition made “semantically more reasonable” errors than a standard convolutional network while
not improving accuracies for object recognition, see discussion in Section 2.",5.3 Analysis,[0],[0]
"Additional evaluation metrics, such as success rates in a human evaluation (cf. Zarrieß and Schlangen (2016)), would be an interesting direction for more detailed investigation here.
",5.3 Analysis,[0],[0]
Word Use,5.3 Analysis,[0],[0]
"But even though the WAC classifiers lack knowledge on lexical similarities, they seem to able to detect relatively specific instances of word use such as hut in Figure 2(b), shirt in 2(c) or lamp in 2(h).",5.3 Analysis,[0],[0]
"Here, the combination with TRANSFER and SIM-WAP is helpful to give more weight to the object name that is taxonomically correct (sometimes pushing up words below the top-3 and hence not shown in Figure 2).",5.3 Analysis,[0],[0]
"In Figure 1(e), SIMWAP and TRANSFER give more weight to typical names for persons, whereas WAC top-ranks more unusual names, reflecting that the person is difficult to identify visually.",5.3 Analysis,[0],[0]
Another observation is that the mapping models have difficulties dealing with object names in singular and plural.,5.3 Analysis,[0],[0]
"As these words have very similar representations in the distributional space, they are often predicted as likely variants among the top 10 by SIM-WAP and TRANSFER, whereas the WAC model seems to predict inappropriate plural words less often among the top 3.",5.3 Analysis,[0],[0]
Such specific phenomena at the intersection of visual and semantic similarity have found very little attention in the literature.,5.3 Analysis,[0],[0]
We will investigate them further in our Experiments on zeroshot naming in the following Section.,5.3 Analysis,[0],[0]
"Zero-shot learning is an attractive prospect for REG from images, as it promises to overcome dependence on pairings of visual instances and natural names being available for all names, if visual/referential data can be generalised from other types of information.",6 Zero-Shot Naming,[0],[0]
"Previous work has looked at the feasibility of zero-shot learning as a function of semantic similarity or ontological closeness between unknown and known categories, and confirmed the intuition that the task is harder the less close unknown categories are to known ones (Frome et al., 2013; Norouzi et al., 2013).
",6 Zero-Shot Naming,[0],[0]
Our experiments on object naming in Section 5 suggest that lexical similarities encoded in a distributional space might not always fully carry over to referential meaning.,6 Zero-Shot Naming,[0],[0]
"This could constitute an additional challenge for zero-shot learning, as distributional similarities might be misleading when
the model has to fully rely on them for learning referential word meanings.",6 Zero-Shot Naming,[0],[0]
"Therefore, the following experiments investigate the performance of our models in zero-shot naming as a function of the lexical relation between unknown and known object names, i.e. namely hypernyms and singular/plurals.",6 Zero-Shot Naming,[0],[0]
"Both relations are typically captured by distributional models of word meaning in terms of closeness in the vector space, but their visual and referential relation is clearly different.",6 Zero-Shot Naming,[0],[0]
"Random As in previous work on zero-shot learning, we consider zero-shot naming for words of varying degrees of similarity.",6.1 Vocabulary Splits and Testsets,[0],[0]
We randomly split our 159 names from Experiment 1 into 10 subsets.,6.1 Vocabulary Splits and Testsets,[0],[0]
We train the models on 90% of the nouns (and all their visual instances in the image corpus) and test on the set of image regions that are named with words which the model did not observe during training.,6.1 Vocabulary Splits and Testsets,[0],[0]
"Results reported in Table 4 on the random test set correspond to averaged scores from cross-validation over the 10 splits.
",6.1 Vocabulary Splits and Testsets,[0],[0]
Hypernyms We manually split the model’s vocabulary into set of hypernyms (see Appendix A) and the remaining nouns.,6.1 Vocabulary Splits and Testsets,[0],[0]
"We train the models on those 84K image regions that where not named with a hypernym, and test on 8895 image regions that were named with a hypernym in the corpus.",6.1 Vocabulary Splits and Testsets,[0],[0]
"We checked that for each of these hypernyms, the vocabulary contains at least one or two names that can be considered as hyponyms, i.e. the model sees objects during training that are instances of vehicle for example, but never encounters actual uses of that name.",6.1 Vocabulary Splits and Testsets,[0],[0]
"This test set is particularly interesting from an REG perspective, as objects named with very general terms by human speakers are often difficult to describe with more common, but more specific terms, as is illustrated by the uses of structure and thingy in Figure 1.
",6.1 Vocabulary Splits and Testsets,[0],[0]
Singulars/Plurals We pick 68 words from our vocabulary that can be grouped into 34 singularplural noun pairs (see Appendix A).,6.1 Vocabulary Splits and Testsets,[0],[0]
"From each pair, we randomly include the singular or plural noun in the set of zero-shot nouns.",6.1 Vocabulary Splits and Testsets,[0],[0]
"Thus, we make sure that the model encounters singular and plural names during training, but it never encounters both variants of a name.",6.1 Vocabulary Splits and Testsets,[0],[0]
This results training split of 23K image regions and a test split of 13825 instances.,6.1 Vocabulary Splits and Testsets,[0],[0]
"Some previous work on zero-shot image labeling assumes additional components that first identify whether an image should be labelled by a known or unknown word (Frome et al., 2013).",6.2 Evaluation,[0],[0]
We follow Lazaridou et al. (2014) and let the model decide whether to refer to an object by a known or unknown name.,6.2 Evaluation,[0],[0]
"Related to that, distinct evaluation procedures have been used in the literature on zero-shot learning:
Testing on full vocabulary A realistic way to test zero-shot learning performance is to consider all words from a given vocabulary during testing, though the testset only contains instances of objects that have been named with a ‘zero-shot word’ (for which no visual instances were seen during training).",6.2 Evaluation,[0],[0]
"Accuracies in this setup reflect how well the model is able to generalize, i.e. how often it decides to deviate from the words it was trained on, and (implicitly) predicts that the given object requires a “new” name.",6.2 Evaluation,[0],[0]
"In case of the (i) hypernym and (ii) singular/plural test set, this accuracy also reflects to what extent the model is able to detect cases where (i) a more general or vague term is needed, where (ii) an unknown singular/plural counterpart of a known object type occurs.
",6.2 Evaluation,[0],[0]
"Testing on disjoint vocabulary Alternatively, the model’s vocabulary can be restricted during testing to zero-shot words only, such that names encountered during training and testing are disjoint, see e.g. (Lampert et al., 2009, 2013).",6.2 Evaluation,[0],[0]
"This setup factors out the generalization problem, and assesses to what extent a model is able to capture the referential meaning of a word that does not have instances in the training data.",6.2 Evaluation,[0],[0]
"As compared to Experiment 1 where models achieved similar performance, differences are more pronounced in the zero-shot setup, as shown in Table 4.",6.3 Results,[0],[0]
"In particular, we find that the SIMWAP model which induces individual predictors for words that have not been observed in the training data is clearly more successful than TRANSFER or WAC that project predictions into the distributional space.",6.3 Results,[0],[0]
"When tested on the full vocabulary, we find that TRANSFER and WAC very rarely generate names whose referents were excluded from training, which is in line with observations made by Lazaridou et al. (2015a).",6.3 Results,[0],[0]
"The SIM-WAP
predictors generalize much better, in particular on the singular/plural testset.
",6.3 Results,[0],[0]
"An interesting exception is the good performance of the TRANSFER model on the hypernym test set, when evaluated with a disjoint vocabulary.",6.3 Results,[0],[0]
"This corroborates evidence from Experiment 1, namely that the transfer model captures taxonomic aspects of object names better than the other models.",6.3 Results,[0],[0]
"Projection via individual word classifiers, on the other hand, seems to generalize better than TRANSFER, at least when looking at accuracies @2 ... @10.",6.3 Results,[0],[0]
"Thus, combining several vectors predicted by a model of referential word meaning can provide additional information, as compared to mapping an object to a single vector in distributional space.",6.3 Results,[0],[0]
More work is needed to establish how these approaches can be integrated more effectively.,6.3 Results,[0],[0]
"In this paper, we have investigated models of referential word meaning, using different ways of combining visual information about a word’s referent and distributional knowledge about its lexical similarities.",7 Discussion and Conclusion,[0],[0]
Previous cross-modal mapping models essentially force semantically similar objects to be mapped into the same area in the semantic space regardless of their actual visual similarity.,7 Discussion and Conclusion,[0],[0]
"We found that cross-modal mapping produces semantically appropriate and mutually highly similar object names in its top-n list, but does not preserve differences in referential word use (e.g. appropriatness of person vs. woman) especially within the same semantic field.",7 Discussion and Conclusion,[0],[0]
"We have shown that it is beneficial for performance in standard and zeroshot object naming to treat words as individual predictors that capture referential appropriateness and are only indirectly linked to a distributional space, either through lexical mapping during application or through cross-modal similarity mapping during training.",7 Discussion and Conclusion,[0],[0]
"As we have tested these approaches on a rather small vocabulary, which may limit generality of conclusions, future work will be devoted to scaling up these findings to larger test sets, as e.g. recently collected through conversational agents (Das et al., 2016) that circumvent the need for human-human interaction data.",7 Discussion and Conclusion,[0],[0]
"Also from an REG perspective, various extensions of this approach are possible, such as the inclusion of contextual information during object naming and its combination with attribute selection.",7 Discussion and Conclusion,[0],[0]
"We acknowledge support by the Cluster of Excellence “Cognitive Interaction Technology” (CITEC; EXC 277) at Bielefeld University, which is funded by the German Research Foundation (DFG).",Acknowledgments,[0],[0]
"We thank the anonymous reviewers for their very valuable, very detailed and highly interesting comments.",Acknowledgments,[0],[0]
"We investigate object naming, which is an important sub-task of referring expression generation on real-world images.",abstractText,[0],[0]
"As opposed to mutually exclusive labels used in object recognition, object names are more flexible, subject to communicative preferences and semantically related to each other.",abstractText,[0],[0]
"Therefore, we investigate models of referential word meaning that link visual to lexical information which we assume to be given through distributional word embeddings.",abstractText,[0],[0]
We present a model that learns individual predictors for object names that link visual and distributional aspects of word meaning during training.,abstractText,[0],[0]
"We show that this is particularly beneficial for zero-shot learning, as compared to projecting visual objects directly into the distributional space.",abstractText,[0],[0]
"In a standard object naming task, we find that different ways of combining lexical and visual information achieve very similar performance, though experiments on model combination suggest that they capture complementary aspects of referential meaning.",abstractText,[0],[0]
Obtaining referential word meanings from visual and distributional information: Experiments on object naming,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 174–184 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
174",text,[0],[0]
Words are the smallest meaningful utterances in language.,1 Introduction,[0],[0]
They play a central role in our understanding and descriptions of the world around us.,1 Introduction,[0],[0]
Some believe that the structure of a language even affects how we think (principle of linguistic relativity aka the SapirWhorf hypothesis).,1 Introduction,[0],[0]
"Several influential factor analysis studies have shown that the three most important, largely independent, dimensions of word meaning are valence (positiveness–negativeness/pleasure– displeasure), arousal (active–passive), and dominance (dominant–submissive) (Osgood et al., 1957; Russell, 1980, 2003).1 Thus, when comparing the meanings of two words, we can compare their degrees of valence, arousal, or domi-
1We will refer to the three dimensions individually as V, A, and D, and together as VAD.
nance.",1 Introduction,[0],[0]
"For example, the word banquet indicates more positiveness than the word funeral; nervous indicates more arousal than lazy; and fight indicates more dominance than delicate.
",1 Introduction,[0],[0]
"Access to these degrees of valence, arousal, and dominance of words is beneficial for a number of applications, including those in natural language processing (e.g., automatic sentiment and emotion analysis of text), in cognitive science (e.g., for understanding how humans represent and use language), in psychology (e.g., for understanding how people view the world around them), in social sciences (e.g., for understanding relationships between people), and even in evolutionary linguistics (e.g., for understanding how language and behaviour inter-relate to give us an advantage).
",1 Introduction,[0],[0]
"Existing VAD lexicons (Bradley and Lang, 1999; Warriner et al., 2013) were created using rating scales and thus suffer from limitations associated with the method (Presser and Schuman, 1996; Baumgartner and Steenkamp, 2001).",1 Introduction,[0],[0]
"These include: inconsistencies in annotations by different annotators, inconsistencies in annotations by the same annotator, scale region bias (annotators often have a bias towards a portion of the scale), and problems associated with a fixed granularity.
",1 Introduction,[0],[0]
"In this paper, we describe how we obtained human ratings of valence, arousal, and dominance for more than 20,000 commonly used English words by crowdsourcing.",1 Introduction,[0],[0]
"Notably, we use a comparative annotation technique called Best-Worst Scaling (BWS) that addresses the limitations of traditional rating scales (Louviere, 1991; Cohen, 2003; Louviere et al., 2015).",1 Introduction,[0],[0]
"The scores are finegrained real-valued numbers in the interval from 0 (lowest V, A, or D) to 1 (highest V, A, or D).",1 Introduction,[0],[0]
"We will refer to this new lexicon as the NRC Valence, Arousal, and Dominance (VAD) Lexicon.2
2NRC refers to National Research Council Canada.
",1 Introduction,[0],[0]
"Correlations (r) between repeated annotations, through metrics such as split-half reliability (SHR), are a common way to evaluate the reliabilities of ordinal and rank annotations.",1 Introduction,[0],[0]
"We show that our annotations have SHR scores of r = 0.95 for valence, r = 0.90 for arousal, and r = 0.91 for dominance.",1 Introduction,[0],[0]
"These scores are well above the SHR scores obtained by Warriner et al. (2013), and indicate high reliability.
",1 Introduction,[0],[0]
"Respondents who provided valence, arousal, and dominance annotations, were given the option of additionally filling out a brief demographic questionnaire to provide details of their age, gender, and personality traits.",1 Introduction,[0],[0]
"This demographic information along with the VAD annotations allows us to determine whether attributes such as age, gender, and personality impact our understanding of the valence, arousal, and dominance of words.",1 Introduction,[0],[0]
"We show that even though overall the annotations are consistent (as seen from the high SHR scores), people aged over 35 are significantly more consistent in their annotations than people aged 35 or less.",1 Introduction,[0],[0]
"We show for the first time that men have a significantly higher shared understanding of dominance and valence of words, whereas women have a higher shared understanding of the degree of arousal of words.",1 Introduction,[0],[0]
"We find that some personality traits significantly impact a person’s annotations of one or more of valence, arousal, and dominance.",1 Introduction,[0],[0]
"We hope that these and other findings described in the paper foster further research into how we use language, how we represent concepts in our minds, and how certain aspects of the world are more important to certain demographic groups leading to higher degrees of shared representations of those concepts within those groups.
",1 Introduction,[0],[0]
"All of the annotation tasks described in this paper were approved by our institution’s review board, which examined the methods to ensure that they were ethical.",1 Introduction,[0],[0]
Special attention was paid to obtaining informed consent and protecting participant anonymity.,1 Introduction,[0],[0]
The NRC VAD Lexicon is made freely available for research and non-commercial use through our project webpage.3,1 Introduction,[0],[0]
"Primary Dimensions of Meaning: Osgood et al. (1957) asked human participants to rate words along dimensions of opposites such as heavy– light, good–bad, strong–weak, etc.",2 Related Work,[0],[0]
"Factor analysis
3http://saifmohammad.com/WebPages/nrc-vad.html
of these judgments revealed that the three most prominent dimensions of meaning are evaluation (good–bad), potency (strong–weak), and activity (active–passive).",2 Related Work,[0],[0]
"Russell (1980, 2003) showed through similar analyses of emotion words that the three primary independent dimensions of emotions are valence or pleasure (positiveness– negativeness/pleasure–displeasure), arousal (active–passive), and dominance (dominant– submissive).",2 Related Work,[0],[0]
"He argues that individual emotions such as joy, anger, and fear are points in a three-dimensional space of valence, arousal, and dominance.",2 Related Work,[0],[0]
"It is worth noting that even though the names given by Osgood et al. (1957) and Russell (1980) are different, they describe similar dimensions (Bakker et al., 2014).
",2 Related Work,[0],[0]
"Existing Affect Lexicons: Bradley and Lang (1999) asked annotators to rate valence, arousal, and dominance—for more than 1,000 words—on a 9-point rating scale.",2 Related Work,[0],[0]
"The ratings from multiple annotators were averaged to obtain a score between 1 (lowest V, A, or D) to 9 (highest V, A, or D).",2 Related Work,[0],[0]
"Their lexicon, called the Affective Norms of English Words (ANEW), has since been widely used across many different fields of study.",2 Related Work,[0],[0]
"More than a decade later, Warriner et al. (2013) created a similar lexicon for more than 13,000 words, using a similar annotation method.",2 Related Work,[0],[0]
"There exist a small number of VAD lexicons in non-English languages as well, such as the ones created by Moors et al. (2013) for Dutch, by Võ et al. (2009) for German, and by Redondo et al. (2007) for Spanish.",2 Related Work,[0],[0]
"The NRC VAD lexicon is the largest manually created VAD lexicon (in any language), and the only one that was created via comparative annotations (instead of rating scales).
",2 Related Work,[0],[0]
"Best-Worst Scaling: Best-Worst Scaling (BWS) was developed by (Louviere, 1991), building on work in the 1960’s in mathematical psychology and psychophysics.",2 Related Work,[0],[0]
"Annotators are given n items (an n-tuple, where n > 1 and commonly n = 4).4",2 Related Work,[0],[0]
They are asked which item is the best (highest in terms of the property of interest) and which is the worst (least in terms of the property of interest).,2 Related Work,[0],[0]
"When working on 4-tuples, best–worst annotations are particularly efficient because each best and worst annotation will reveal the order of five of the six item pairs (e.g., for a 4-tuple with items
4At its limit, when n = 2, BWS becomes a paired comparison (Thurstone, 1927; David, 1963), but then a much larger set of tuples need to be annotated (closer to N2).
",2 Related Work,[0],[0]
"A, B, C, and D, if A is the best, and D is the worst, then A > B, A > C, A > D, B > D, and C > D).",2 Related Work,[0],[0]
"Real-valued scores of association between the items and the property of interest can be determined using simple arithmetic on the number of times an item was chosen best and number of times it was chosen worst (as described in Section 3) (Orme, 2009; Flynn and Marley, 2014).
",2 Related Work,[0],[0]
"It has been empirically shown that three annotations each for 2N 4-tuples is sufficient for obtaining reliable scores (where N is the number of items) (Louviere, 1991; Kiritchenko and Mohammad, 2016).",2 Related Work,[0],[0]
Kiritchenko and Mohammad (2017) showed through empirical experiments that BWS produces more reliable and more discriminating scores than those obtained using rating scales.,2 Related Work,[0],[0]
"(See Kiritchenko and Mohammad (2016, 2017) for further details on BWS.)
",2 Related Work,[0],[0]
"Within the NLP community, BWS has been used for creating datasets for relational similarity (Jurgens et al., 2012), word-sense disambiguation (Jurgens, 2013), word–sentiment intensity (Kiritchenko and Mohammad, 2016), word–emotion intensity (Mohammad, 2018), and tweet–emotion intensity (Mohammad and Bravo-Marquez, 2017; Mohammad et al., 2018; Mohammad and Kiritchenko, 2018).",2 Related Work,[0],[0]
"Automatically Creating Affect Lexicons: There is growing work on automatically determining word–sentiment and word–emotion associations (Yang et al., 2007; Mohammad and Kiritchenko, 2015; Yu et al., 2015; Staiano and Guerini, 2014).",2 Related Work,[0],[0]
"The VAD Lexicon can be used to evaluate how accurately the automatic methods capture valence, arousal, and dominance.",2 Related Work,[0],[0]
We now describe how we selected the terms to be annotated and how we crowdsourced the annotation of the terms using best–worst scaling.,"3 Obtaining Human Ratings of Valence, Arousal, and Dominance",[0],[0]
We chose to annotate commonly used English terms.,3.1 Term Selection,[0],[0]
We especially wanted to include terms that denotate or connotate emotions.,3.1 Term Selection,[0],[0]
"We also include terms common in tweets.5 Specifically, we include terms from the following sources:
5Tweets include non-standard language such as emoticons, emojis, creatively spelled words (happee), hashtags (#takingastand, #lonely) and conjoined words (loveumom).
",3.1 Term Selection,[0],[0]
"• All terms in the NRC Emotion Lexicon (Mohammad and Turney, 2013).",3.1 Term Selection,[0],[0]
"It has about 14,000 words with labels indicating whether they are associated with any of the eight basic emotions: anger, anticipation, disgust, fear, joy, sadness, surprise, and trust (Plutchik, 1980).
",3.1 Term Selection,[0],[0]
•,3.1 Term Selection,[0],[0]
"All 4,206 terms in the positive and negative lists of the General Inquirer (Stone et al., 1966).
",3.1 Term Selection,[0],[0]
"• All 1,061 terms listed in ANEW (Bradley and Lang, 1999).
",3.1 Term Selection,[0],[0]
"• All 13,915 terms listed in the Warriner et al. (2013) lexicon.
",3.1 Term Selection,[0],[0]
"• 520 words from the Roget’s Thesaurus categories corresponding to the eight basic Plutchik emotions.6
• About 1000 high-frequency content terms, including emoticons, from the Hashtag Emotion Corpus (HEC) (Mohammad, 2012).7
The union of the above sets resulted in 20,007 terms that were then annotated for valence, arousal, and dominance.",3.1 Term Selection,[0],[0]
We describe below how we annotated words for valence.,3.2 Annotating VAD via Best–Worst Scaling,[0],[0]
The same approach is followed for arousal and dominance.,3.2 Annotating VAD via Best–Worst Scaling,[0],[0]
The annotators were presented with four words at a time (4-tuples) and asked to select the word with the highest valence and the word with the lowest valence.,3.2 Annotating VAD via Best–Worst Scaling,[0],[0]
The questionnaire uses a set of paradigm words that signify the two ends of the valence dimension.,3.2 Annotating VAD via Best–Worst Scaling,[0],[0]
"The paradigm words were taken from past literature on VAD (Bradley and Lang, 1999; Osgood et al., 1957; Russell, 1980).",3.2 Annotating VAD via Best–Worst Scaling,[0],[0]
"The questions used for valence are shown below.
Q1.",3.2 Annotating VAD via Best–Worst Scaling,[0],[0]
"Which of the four words below is associated with the
MOST happiness / pleasure / positiveness / satisfaction / con-
tentedness / hopefulness OR LEAST unhappiness / annoy-
ance / negativeness / dissatisfaction / melancholy / despair?
",3.2 Annotating VAD via Best–Worst Scaling,[0],[0]
"(Four words listed as options.)
Q2.",3.2 Annotating VAD via Best–Worst Scaling,[0],[0]
"Which of the four words below is associated with the
LEAST",3.2 Annotating VAD via Best–Worst Scaling,[0],[0]
"happiness / pleasure / positiveness / satisfaction /
contentedness / hopefulness",3.2 Annotating VAD via Best–Worst Scaling,[0],[0]
"OR MOST unhappiness / annoy-
ance / negativeness / dissatisfaction / melancholy / despair?
",3.2 Annotating VAD via Best–Worst Scaling,[0],[0]
"(Four words listed as options.)
",3.2 Annotating VAD via Best–Worst Scaling,[0],[0]
"6http://www.gutenberg.org/ebooks/10681 7All tweets in the HEC include at least one of the eight basic emotion words as a hashtag word (#anger, #sadness, etc.).
",3.2 Annotating VAD via Best–Worst Scaling,[0],[0]
"Questions for arousal and dominance are similar.8
Detailed directions and example questions (with suitable responses) were provided in advance.",3.2 Annotating VAD via Best–Worst Scaling,[0],[0]
"2 × N distinct 4-tuples were randomly generated in such a manner that each word is seen in eight different 4-tuples and no two 4-tuples have more than two items in common (where N is the number of words to be annotated).9
Crowdsourcing: We setup three separate crowdsourcing tasks corresponding to valence, arousal, and dominance.",3.2 Annotating VAD via Best–Worst Scaling,[0],[0]
"The 4-tuples of words were uploaded for annotation on the crowdsourcing platform, CrowdFlower.10 We obtained annotations from native speakers of English residing around the world.",3.2 Annotating VAD via Best–Worst Scaling,[0],[0]
Annotators were free to provide responses to as many 4-tuples as they wished.,3.2 Annotating VAD via Best–Worst Scaling,[0],[0]
"The annotation tasks were approved by our institution’s review board.
",3.2 Annotating VAD via Best–Worst Scaling,[0],[0]
About 2% of the data was annotated beforehand by the authors.,3.2 Annotating VAD via Best–Worst Scaling,[0],[0]
These questions are referred to as gold questions.,3.2 Annotating VAD via Best–Worst Scaling,[0],[0]
CrowdFlower interspersed the gold questions with the other questions.,3.2 Annotating VAD via Best–Worst Scaling,[0],[0]
"If a crowd worker answered a gold question incorrectly, then they were immediately notified, the annotation was discarded, and an additional annotation was requested from a different annotator.",3.2 Annotating VAD via Best–Worst Scaling,[0],[0]
"If an annotator’s accuracy on the gold questions fell below 80%, then they were refused further annotation, and all of their annotations were discarded.",3.2 Annotating VAD via Best–Worst Scaling,[0],[0]
This served as a mechanism to avoid malicious and random annotations.,3.2 Annotating VAD via Best–Worst Scaling,[0],[0]
"The gold questions also served as examples to guide the annotators.
",3.2 Annotating VAD via Best–Worst Scaling,[0],[0]
"8The two ends of the arousal dimension were described with the words: arousal, activeness, stimulation, frenzy, jitteriness, alertness AND unarousal, passiveness, relaxation, calmness, sluggishness, dullness, sleepiness.",3.2 Annotating VAD via Best–Worst Scaling,[0],[0]
"The two ends of the dominance dimension were described with the words: dominant, in control of the situation, powerful, influential, important, autonomous AND submissive, controlled by outside factors, weak, influenced, cared-for, guided.
",3.2 Annotating VAD via Best–Worst Scaling,[0],[0]
"9We used the script provided by Kiritchenko and Mohammad (2016) to generate the 4-tuples from the list of terms: http://saifmohammad.com/WebPages/BestWorst.html
10CrowdFlower later changed its name to Figure Eight: https://www.figure-eight.com
",3.2 Annotating VAD via Best–Worst Scaling,[0],[0]
"In the task settings for CrowdFlower, we specified that we needed annotations from six people for each word.11 However, because of the way the gold questions work in CrowdFlower, they were annotated by more than six people.",3.2 Annotating VAD via Best–Worst Scaling,[0],[0]
Both the minimum and the median number of annotations per item was six.,3.2 Annotating VAD via Best–Worst Scaling,[0],[0]
"See Table 1 for summary statistics on the annotations.12
Annotation Aggregation:",3.2 Annotating VAD via Best–Worst Scaling,[0],[0]
"The final VAD scores were calculated from the BWS responses using a simple counting procedure (Orme, 2009; Flynn and Marley, 2014):",3.2 Annotating VAD via Best–Worst Scaling,[0],[0]
"For each item, the score is the proportion of times the item was chosen as the best (highest V/A/D) minus the proportion of times the item was chosen as the worst (lowest V/A/D).",3.2 Annotating VAD via Best–Worst Scaling,[0],[0]
The scores were linearly transformed to the interval: 0 (lowest V/A/D) to 1 (the highest V/A/D).,3.2 Annotating VAD via Best–Worst Scaling,[0],[0]
"We refer to the list of words along with their scores for valence, arousal, and dominance as the NRC Valence, Arousal, and Dominance Lexicon, or the NRC VAD Lexicon for short.",3.2 Annotating VAD via Best–Worst Scaling,[0],[0]
"Table 2 shows entries from the lexicon with the highest and lowest scores for V, A, and D.
11Note that since each word occurs in eight different 4- tuples, it is involved in 8× 6 = 48 best–worst judgments.
",3.2 Annotating VAD via Best–Worst Scaling,[0],[0]
"12In a post-annotation survey, the respondents gave the task high scores for clarity of instruction (an average of 4.5 out of 5) and overall satisfaction (an average of 4.3 out of 5).",3.2 Annotating VAD via Best–Worst Scaling,[0],[0]
"Respondents who annotated our VAD questionnaires were given a special code through which they could then optionally respond to a separate CrowdFlower survey asking for their demographic information: age, gender, country they live in, and personality traits.",4 Demographic Survey,[0],[0]
"For the latter, we asked how they viewed themselves across the big five (Barrick and Mount, 1991) personality traits:
• Agreeableness (Ag) – Disagreeableness (Di): friendly and compassionate or careful in whom to trust, argumentative
•",4 Demographic Survey,[0],[0]
"Conscientiousness (Co) – Easygoing (Ea): efficient and organized (prefer planned and self-disciplined behaviour) or easy-going and carefree (prefer flexibility and spontaneity)
•",4 Demographic Survey,[0],[0]
"Extrovert (Ex) – Introvert (In): outgoing, energetic, seek the company of others or solitary, reserved, meeting many people causes anxiety
• Neurotic (Ne) – Secure (Se): sensitive and nervous (often feel anger, anxiety, depression, and vulnerability) or secure and confident (rarely feel anger, anxiety, depression, and vulnerability)
",4 Demographic Survey,[0],[0]
"• Open to experiences (Op) – Closed to experiences (Cl): inventive and curious (seek out new experiences) or consistent and cautious (anxious about new experiences)
",4 Demographic Survey,[0],[0]
"The questionnaire described the two sides of the dimension using only the texts after the colons above.13 The questionnaire did not ask for identifying information such as name or date of birth.
",4 Demographic Survey,[0],[0]
"In total, 991 people (55% of the VAD annotators) chose to provide their demographic information.",4 Demographic Survey,[0],[0]
Table 3 shows the details.,4 Demographic Survey,[0],[0]
We calculated the Pearson correlations r between the NRC VAD Lexicon scores and the Warriner et al. Lexicon scores.,5.1 A Comparsion of the NRC VAD Lexicon and the Warriner et al. Lexicon Scores,[0],[0]
Table 4 shows the results.,5.1 A Comparsion of the NRC VAD Lexicon and the Warriner et al. Lexicon Scores,[0],[0]
"(These numbers were calculated for the 13,915 common terms across the two lexicons.)",5.1 A Comparsion of the NRC VAD Lexicon and the Warriner et al. Lexicon Scores,[0],[0]
Observe that the especially low correlations for dominance and arousal indicate that our lexicon has substantially different scores and rankings of terms by these dimensions.,5.1 A Comparsion of the NRC VAD Lexicon and the Warriner et al. Lexicon Scores,[0],[0]
"Even for valence, a correlation of 0.81 indicates a marked amount of differences in scores.",5.1 A Comparsion of the NRC VAD Lexicon and the Warriner et al. Lexicon Scores,[0],[0]
"Russell (1980) found through his factor analysis work that valence, arousal, and dominance are nearly independent dimensions.",5.2 Independence of Dimensions,[0],[0]
"However, Warriner et al. (2013) report that their scores for valence and dominance have substantial correlation (r = 0.717).",5.2 Independence of Dimensions,[0],[0]
"Given that the split-half reliability score for their dominance annotations is only 0.77, the high V–D correlations raises the suspicion whether annotators sufficiently understood the difference between dominance and valence.",5.2 Independence of Dimensions,[0],[0]
"Table 5 shows the correlations between various pair-wise combinations of valence, arousal, and dominance for both our lexicon and the Warriner lexicon.",5.2 Independence of Dimensions,[0],[0]
"Observe that unlike the Warriner annotations where V and D are highly correlated, our annotations show that V and D are only slightly correlated.",5.2 Independence of Dimensions,[0],[0]
"The correlations for V–A and A–D are low in both our and Warriner annotations, albeit slightly higher in magnitude in our annotations.
",5.2 Independence of Dimensions,[0],[0]
13How people view themselves may be different from what they truly are.,5.2 Independence of Dimensions,[0],[0]
The conclusions in this paper apply to groups that view themselves to be a certain personality type.,5.2 Independence of Dimensions,[0],[0]
A useful measure of quality is reproducibility of the end result—repeated independent manual annotations from multiple respondents should result in similar scores.,5.3 Reliability of the Annotations,[0],[0]
"To assess this reproducibility, we calculate average split-half reliability (SHR) over 100 trials.",5.3 Reliability of the Annotations,[0],[0]
"All annotations for an item (in our case, 4-tuples) are randomly split into two halves.",5.3 Reliability of the Annotations,[0],[0]
Two sets of scores are produced independently from the two halves.,5.3 Reliability of the Annotations,[0],[0]
Then the correlation between the two sets of scores is calculated.,5.3 Reliability of the Annotations,[0],[0]
"If the annotations are of good quality, then the correlation between the two halves will be high.",5.3 Reliability of the Annotations,[0],[0]
"Table 6 shows the split-half reliabilities (SHR) for valence, arousal, and dominance annotations.",5.3 Reliability of the Annotations,[0],[0]
Row a. shows the SHR on the full set of terms in the VAD lexicon.,5.3 Reliability of the Annotations,[0],[0]
Row b. shows the SHR on just the Warriner subset of terms in the VAD lexicon.,5.3 Reliability of the Annotations,[0],[0]
Row c. shows the SHR reported by Warriner et al. (2013) on their annotations.,5.3 Reliability of the Annotations,[0],[0]
"Observe that the SHR scores for our annotations are markedly higher than those reported by Warriner et al. (2013), especially for arousal and dominance.",5.3 Reliability of the Annotations,[0],[0]
"All differences in SHR scores between rows b and c are statistically significant.
",5.3 Reliability of the Annotations,[0],[0]
Summary of Main Results: The low correlations between the scores in our lexicon and the Warriner lexicon (especially for D and A) show that the scores in the two lexicons are substantially different.,5.3 Reliability of the Annotations,[0],[0]
The scores for correlations across all pairs of dimensions in our lexicon are low (r < 0.5).,5.3 Reliability of the Annotations,[0],[0]
"SHR scores of 0.95 for valence, 0.9 for arousal, and 0.9 for dominance show for the first time that highly reliable fine-grained ratings can be obtained for valence, arousal, and dominance.",5.3 Reliability of the Annotations,[0],[0]
Human cognition and behaviour is impacted by evolutionary and socio-cultural factors.,6 Shared Understanding of VAD Within and Across Demographic Groups,[0],[0]
"These factors are known to impact different groups of people differently (men vs. women, young vs. old, etc.).",6 Shared Understanding of VAD Within and Across Demographic Groups,[0],[0]
"Thus it is not surprising that our understanding of the world may be slightly different de-
pending on our demographic attributes.",6 Shared Understanding of VAD Within and Across Demographic Groups,[0],[0]
"Consider gender—a key demographic attribute.14 Men, women, and other genders are substantially more alike than they are different.",6 Shared Understanding of VAD Within and Across Demographic Groups,[0],[0]
"However, they have encountered different socio-cultural influences for thousands of years.",6 Shared Understanding of VAD Within and Across Demographic Groups,[0],[0]
Often these disparities have been a means to exert unequal status and asymmetric power relations.,6 Shared Understanding of VAD Within and Across Demographic Groups,[0],[0]
"Thus a crucial area in gender studies is to examine both the overt and subtle impacts of these socio-cultural influences, as well as ways to mitigate the inequity.",6 Shared Understanding of VAD Within and Across Demographic Groups,[0],[0]
Understanding how different genders perceive and use language is an important component of that research.,6 Shared Understanding of VAD Within and Across Demographic Groups,[0],[0]
"Language use is also relevant to the understanding and treatment of neuropsychiatric disorders, such as sleep, mood, and anxiety disorders, which have been shown to occur more frequently in women than men (Bao and Swaab, 2011; Lewinsohn et al., 1998; McLean et al., 2011; Johnson et al., 2006; Chmielewski et al., 1995).
",6 Shared Understanding of VAD Within and Across Demographic Groups,[0],[0]
"In addition to the VAD Lexicon (created by aggregating human judgments), we also make available the demographic information of the annotators.",6 Shared Understanding of VAD Within and Across Demographic Groups,[0],[0]
This demographic information along with the individual judgments on the best–worst tuples forms a significant resource in the study of how demographic attributes are correlated with our understanding of language.,6 Shared Understanding of VAD Within and Across Demographic Groups,[0],[0]
"The data can be used to shed light on research questions such as: ‘are there significant differences in the shared understanding of word meanings in men and women?’, ‘how is the social construct of gender reflected in language, especially in socio-political interactions?’, ‘does age impact our view of the valence, arousal, and dominance of concepts?’, ‘do people that view themselves as conscientious have slightly different judgments of valence, arousal, and dominance, than people who view themselves as easy going?’, and so on.
",6 Shared Understanding of VAD Within and Across Demographic Groups,[0],[0]
"14Note that the term sex refers to a biological attribute pertaining to the anatomy of one’s reproductive system and sex chromosomes, whereas gender refers to a psycho-sociocultural construct based on a person’s sex or a person’s self identification of levels of masculinity and femininity.",6 Shared Understanding of VAD Within and Across Demographic Groups,[0],[0]
"One may identify their gender as female, male, agender, trans, queer, etc.",6 Shared Understanding of VAD Within and Across Demographic Groups,[0],[0]
"We now describe experiments we conducted to determine whether demographic attributes impact how we judge words for valence, arousal, and dominance.",6.1 Experiments,[0],[0]
"For each demographic attribute, we partitioned the annotators into two groups: male (m) and female (f), ages 18 to 35 (≤35) and ages over 35 (>35), and so on.15 For each of the five personality traits, annotators are partitioned into the two groups shown in the bullet list of Section 4.",6.1 Experiments,[0],[0]
"We then calculated the extent to which people within the same group agreed with each other, and the extent to which people across groups agreed with each other on the VAD annotations (as described in the paragraph below).",6.1 Experiments,[0],[0]
"We also determined if the differences in agreement were statistically significant.
",6.1 Experiments,[0],[0]
"For each dimension (V, A, and D), we first collected only those 4-tuples where at least two female and at least two male responses were available.",6.1 Experiments,[0],[0]
We will refer to this set as the base set.,6.1 Experiments,[0],[0]
"For each of the base set 4-tuples, we calculated three agreement percentages: 1.",6.1 Experiments,[0],[0]
"the percentage of all female–female best–worst responses where the two agreed with each other, 2.",6.1 Experiments,[0],[0]
"the percentage of all male–male responses where the two agreed with each other, and 3.",6.1 Experiments,[0],[0]
the percentage of all female–male responses where the two agreed with each other.,6.1 Experiments,[0],[0]
We then calculated the averages of the agreement percentages across all the 4-tuples in the base set.,6.1 Experiments,[0],[0]
"We conducted similar experiments for age groups and personality traits.
",6.1 Experiments,[0],[0]
"15For age, we chose 35 to create the two groups because several psychology and medical studies report changes in health and well-being at this age.",6.1 Experiments,[0],[0]
"Nonetheless, other partitions of age are also worth exploring.",6.1 Experiments,[0],[0]
Table 7 shows the results for gender.,6.2 Results,[0],[0]
Note that the average agreement numbers are not expected to be high because often a 4-tuple may include two words that are close to each other in terms of the property of interest (V/A/D).16,6.2 Results,[0],[0]
"However, the relative values of the agreement percentages indicate the relative levels of agreements within groups and across groups.
",6.2 Results,[0],[0]
"Table 7 numbers indicate that women have a higher shared understanding of the degree of arousal of words (higher f–f average agreement scores on A), whereas men have a higher shared understanding of dominance and valence of words (higher m–m average agreement scores on V and D).",6.2 Results,[0],[0]
"The table also shows the cross-group (f–m) average agreements are the lowest for valence and arousal, but higher than f–f pairs for dominance.",6.2 Results,[0],[0]
"(Each of these agreements was determined from 1 to 1.5 million judgment pairs.)
",6.2 Results,[0],[0]
Table 8 shows which of the Table 7 average agreements are statistically significantly different (shown with a ‘y’).,6.2 Results,[0],[0]
Significance values were calculated using the chi-square test for independence and significance level of 0.05.,6.2 Results,[0],[0]
"Observe that all score differences are statistically significant except for between f–f and f–m scores for V and m– m and f–m scores for A.
Tables 9 through 12 are similar to Tables 7 and 8, but for age groups and personality traits.",6.2 Results,[0],[0]
"Tables 9 and 10 show that respondents over the age of 35 obtain significantly higher agreements with each other on valence and arousal and lower agreements on dominance, than respondents aged 35 and under (with each other).",6.2 Results,[0],[0]
"Tables 11 and 12 show that
16Such disagreements are useful as they cause the two words to obtain scores close to each other.
",6.2 Results,[0],[0]
"some personality traits significantly impact a person’s annotations of one or more of V, A, and D. Notably, those who view themselves as conscientious have a particularly higher shared understanding of the dominance of words, as compared to those who view themselves as easy going.",6.2 Results,[0],[0]
"They also have higher in-group agreement for arousal, than those who view themselves as easy going, but the difference for valence is not statistically significant.",6.2 Results,[0],[0]
"Also notable, is that those who view themselves as extroverts have a particularly higher shared understanding of the valence, arousal, and dominance of words, as compared to those who view themselves as introverts.
",6.2 Results,[0],[0]
"Finally, as a sanity check, we divided respondents into those whose CrowdFlower worker ids are odd and those whose worker ids are even.",6.2 Results,[0],[0]
"We then determined average agreements for even–even, odd-odd, and even–odd groups just as we did for the demographic variables.",6.2 Results,[0],[0]
"We found that, as expected, there were no significant differences in average agreements.
",6.2 Results,[0],[0]
"Summary of Main Results: We showed that several demographic attributes such as age, gender, and personality traits impact how we judge words for valence, arousal, and dominance.",6.2 Results,[0],[0]
"Further,
people that share certain demographic attributes show a higher shared understanding of the relative rankings of words by (one or more of) V, A, or D than others.",6.2 Results,[0],[0]
"However, this raises new questions: why do certain demographic attributes impact our judgments of V, A, and D?",6.2 Results,[0],[0]
"Are there evolutionary forces that caused some groups such as women to develop a higher shared understanding or the arousal, whereas different evolutionary forces caused some groups, such as men, to have a higher shared understanding of dominance?",6.2 Results,[0],[0]
We hope that the data collected as part of this project will spur further inquiry into these and other questions.,6.2 Results,[0],[0]
The large number of entries in the VAD Lexicon and the high reliability of the scores make it useful for a number of research projects and applications.,7 Applications and Future Work,[0],[0]
"We list a few below:
• To provide features for sentiment or emotion detection systems.",7 Applications and Future Work,[0],[0]
"They can also be used to obtain sentiment-aware word embeddings and sentiment-aware sentence representations.
",7 Applications and Future Work,[0],[0]
• To study the interplay between the basic emotion model and the VAD model of affect.,7 Applications and Future Work,[0],[0]
"The VAD lexicon can be used along with lists of words associated with emotions such as joy, sadness, fear, etc. to study the correlation of V, A, and D, with those emotions.
",7 Applications and Future Work,[0],[0]
• To study the role emotion words play in high emotion intensity sentences or tweets.,7 Applications and Future Work,[0],[0]
"The Tweet Emotion Intensity Dataset has emotion intensity and valence scores for whole tweets (Mohammad and Bravo-Marquez, 2017).",7 Applications and Future Work,[0],[0]
"We will use the VAD lexicon to determine the extent to which high intensity and high valence tweets consist of high V, A, and D words, and to identify sentences that express high emotional intensity without using high V, A, and D words.
",7 Applications and Future Work,[0],[0]
•,7 Applications and Future Work,[0],[0]
"To identify syllables that tend to occur in words with high VAD scores, which in turn can be used to generate names for literary characters and commercial products that have the desired affectual response.
",7 Applications and Future Work,[0],[0]
"• To identify high V, A, and D words in books and literature.",7 Applications and Future Work,[0],[0]
To facilitate research in digital humanities.,7 Applications and Future Work,[0],[0]
"To facilitate work on literary analysis.
",7 Applications and Future Work,[0],[0]
•,7 Applications and Future Work,[0],[0]
"As a source of gold (reference) scores, the entries in the VAD lexicon can be used in the evaluation of automatic methods of determining V, A, and D.
• To analyze V, A, ad D annotations for different groups of words, such as: hashtag words and emojis common in tweets, emotion denotating words, emotion associated words, neutral terms, words belonging to particular parts of speech such as nouns, verbs, and adjectives, etc.
",7 Applications and Future Work,[0],[0]
"• To analyze interactions between demographic groups and specific groups of words, for example, whether younger annotators have a higher shared understanding of tweet terms, whether a certain gender is associated with a higher shared understanding of adjectives, etc.
",7 Applications and Future Work,[0],[0]
"• To analyze the shared understanding of V, A, and D within and across geographic and language groups.",7 Applications and Future Work,[0],[0]
We are interested in creating VAD lexicons for other languages.,7 Applications and Future Work,[0],[0]
"We can then explore characteristics of valence, arousal, and dominance that are common across cultures.",7 Applications and Future Work,[0],[0]
"We can also test whether some of the conclusions reached in this work apply only to English, or more broadly to multiple languages.
",7 Applications and Future Work,[0],[0]
"• The dataset is of use to psychologists and evolutionary linguists interested in determining how evolution shaped our representation of the world around us, and why certain personality traits are associated with higher or lower shared understanding of V, A, and D.",7 Applications and Future Work,[0],[0]
"We obtained reliable human ratings of valence, arousal, and dominance for more than 20,000 English words.",8 Conclusions,[0],[0]
(It has about 40% more words than the largest existing manually created VAD lexicon).,8 Conclusions,[0],[0]
We used best–worst scaling to obtain finegrained scores (and word rankings) and addressed issues of annotation consistency that plague traditional rating scale methods of annotation.,8 Conclusions,[0],[0]
"We showed that the lexicon has split-half reliability scores of 0.95 for valence, 0.90 for arousal, and 0.90 for dominance.",8 Conclusions,[0],[0]
"These scores are markedly higher than that of existing lexicons.
",8 Conclusions,[0],[0]
"We analyzed demographic information to show that even though the annotations overall lead to consistent scores in repeated annotations, there exist statistically significant differences in agreements across demographic groups such as males and females, those above the age of 35 and those that are 35 or under, and across personality dimensions (extroverts and introverts, neurotic and secure, etc.).",8 Conclusions,[0],[0]
"These results show that certain demographic attributes impact how we view the world around us in terms of the relative valence, arousal, and dominance of the concepts in it.
",8 Conclusions,[0],[0]
"The NRC Valence, Arousal, and Dominance Lexicon is made available.17 It can be used in combination with other manually created affect lexicons such as the NRC Word–Emotion Association Lexicon (Mohammad and Turney, 2013)18 and the NRC Affect Intensity Lexicon (Mohammad, 2018).19",8 Conclusions,[0],[0]
"Many thanks to Svetlana Kiritchenko, Michael Wojatzki, Norm Vinson, and Tara Small for helpful discussions.
",Acknowledgments,[0],[0]
"17The NRC Valence, Arousal, and Dominance Lexicon provides human ratings of valence, arousal, and dominance for more than 20,000 English words: http://saifmohammad.com/WebPages/nrc-vad.html
18The NRC Emotion Lexicon includes about 14,000 words annotated to indicate whether they are associated with any of the eight basic emotions (anger, anticipation, disgust, fear, joy, sadness, surprise, and trust): http://saifmohammad.com/WebPages/NRC-EmotionLexicon.htm
19The NRC Affect Intensity Lexicon provides realvalued affect intensity scores for four basic emotions (anger, fear, sadness, joy): http://saifmohammad.com/WebPages/AffectIntensity.htm",Acknowledgments,[0],[0]
Words play a central role in language and thought.,abstractText,[0],[0]
"Factor analysis studies have shown that the primary dimensions of meaning are valence, arousal, and dominance (VAD).",abstractText,[0],[0]
"We present the NRC VAD Lexicon, which has human ratings of valence, arousal, and dominance for more than 20,000 English words.",abstractText,[0],[0]
We use Best–Worst Scaling to obtain fine-grained scores and address issues of annotation consistency that plague traditional rating scale methods of annotation.,abstractText,[0],[0]
We show that the ratings obtained are vastly more reliable than those in existing lexicons.,abstractText,[0],[0]
"We also show that there exist statistically significant differences in the shared understanding of valence, arousal, and dominance across demographic variables such as age, gender, and personality.",abstractText,[0],[0]
"Obtaining Reliable Human Ratings of Valence, Arousal, and Dominance for 20,000 English Words",title,[0],[0]
"Many datasets of interest in machine learning are comprised of high-dimensional, complex objects.",1. Introduction,[0],[0]
"Often, one is interested in describing these observations using a lowdimensional latent subspace that captures the statistical variations.",1. Introduction,[0],[0]
"Such approaches fall under the umbrella of factor analysis (Bishop, 2016), where we wish to learn a mapping between the latent and observed spaces.",1. Introduction,[0],[0]
"The motivation is two-fold: (i) factor models provide a compact representation
1Paul G. Allen School of Computer Science and Engineering, University of Washington 2Institute for Learning & Brain Sciences and Department of Speech and Hearing Sciences, University of Washington.",1. Introduction,[0],[0]
"Correspondence to: Samuel K. Ainsworth <skainsworth@gmail.com>, Nicholas J. Foti <nfoti@uw.edu>, Adrian K. C. Lee <akclee@uw.edu>, Emily B. Fox <ebfox@uw.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
of the data, and (ii) the mapping can be used to describe the correlation structure of the high-dimensional data.",1. Introduction,[0],[0]
"In many applications, we are particularly interested in mappings that elucidate interpretable interactions.
",1. Introduction,[0],[0]
The challenge arises from the push and pull between interpretability and expressivity in factor modeling approaches.,1. Introduction,[0],[0]
"Methods emphasizing interpretability have focused primarily on linear models, resulting in lower expressivity.",1. Introduction,[0],[0]
"A popular choice in these settings is to consider sparse linear factor models (Zhao et al., 2016; Carvalho et al., 2008).",1. Introduction,[0],[0]
"However, it is well known that neural (Vejmelka et al., 2010), genomic (Prill et al., 2010), and financial data (Harvey et al., 1994), for example, exhibit complex nonlinearities.
",1. Introduction,[0],[0]
"Recently, there has been a significant amount of work on expressive models for complex, high dimensional data.",1. Introduction,[0],[0]
"In particular, deep generative models (Kingma & Welling, 2013; Rezende et al., 2014; Goodfellow et al., 2014; Damianou & Lawrence, 2013) have proven wildly successful in efficiently modeling complex observations—such as images—as nonlinear mappings of simple latent representations.",1. Introduction,[0],[0]
"These nonlinear maps are based on deep neural networks that parameterize an observation distribution, often referred to as the generator.",1. Introduction,[0],[0]
"We focus on the class of variational autoencoders (VAEs) (Kingma & Welling, 2013).",1. Introduction,[0],[0]
"Unlike linear models which posit a latent variable per observation, VAEs introduce a mapping from observations to a distribution on the latent space; when parameterized by a deep neural network, this mapping is called the inference network.",1. Introduction,[0],[0]
"The generator and inference network are jointly trained to minimize a variational objective.
",1. Introduction,[0],[0]
The VAE can be viewed as a nonlinear factor model that provides a scalable means of learning latent representations.,1. Introduction,[0],[0]
"The focus, however, has primarily been on their use as a generative mechanism.",1. Introduction,[0],[0]
"One shortcoming of the VAE is that, due to the tangled web of connections between neural network layers, it is not possible to interpret how changes in the latent code influence changes in the observations—as in linear latent factor models.",1. Introduction,[0],[0]
"For example, imagine you are trying to synthesize human body poses.",1. Introduction,[0],[0]
"One might hope to have a disentangled representation where a given latent dimension controls a subset of highly correlated body parts; unfortunately, the standard VAE cannot yield these types of interpretations.",1. Introduction,[0],[0]
"Another shortcoming of the VAE
is that training—as in most neural network-based models— typically requires a massive amount of data.",1. Introduction,[0],[0]
"In many applications, we have limited access to training data.
",1. Introduction,[0],[0]
One natural way to encourage disentangled latent representations is by introducing structure and sparsity into the generator.,1. Introduction,[0],[0]
"Specifically, we propose an output interpretable VAE (oi-VAE) that factorizes the generator across observation dimensions, with a separate generator per group of variables.",1. Introduction,[0],[0]
"The generators are coupled both through a shared latent space, and by jointly training with a single inference network.",1. Introduction,[0],[0]
"We also introduce a sparsity-inducing penalty that leads each latent dimension to influence a limited subset of groups, resulting in a disentangled latent representation.",1. Introduction,[0],[0]
"We develop an amortized variational inference algorithm for a collapsed objective, allowing us to use efficient proximal updates to learn latent-dimension-to-group interactions.
",1. Introduction,[0],[0]
The factorization of generators across dimensions is readily apparent when the data are inherently group structured.,1. Introduction,[0],[0]
There are many applications where this is the case.,1. Introduction,[0],[0]
"In the analysis of neuroimaging data, studies are typically done at the level of regions of interest that aggregate over corticallylocalized signals.",1. Introduction,[0],[0]
"In genomics, there are different treatment regimes.",1. Introduction,[0],[0]
"In finance, the data might be described in terms of asset classes (stocks, bonds, . . . ).",1. Introduction,[0],[0]
"And for motion capture data, multiple angle measurements are grouped by their associated joints.",1. Introduction,[0],[0]
In these group-structured scenarios we may additionally garner interpretability from the oi-VAE mappings.,1. Introduction,[0],[0]
"For example, we may learn that a given latent dimension controls a collection of highly correlated joints— e.g., joints in a limb—that comprise a system of interest.",1. Introduction,[0],[0]
"A side benefit of this structured oi-VAE framework is its ability to handle scenarios with limited amounts of data.
",1. Introduction,[0],[0]
We evaluate the oi-VAE on motion capture and magnetoencephalography datasets.,1. Introduction,[0],[0]
"In these scenarios where there is a natural notion of groupings of observations, we demonstrate the interpretability of the learned features and how these structures of interaction correspond to physically meaningful systems.",1. Introduction,[0],[0]
"Furthermore, in such cases we show that the regularization employed by oi-VAE leads to better generalization and synthesis capabilities, especially in limited training data scenarios or when the training data might not fully capture the observed space of interest.",1. Introduction,[0],[0]
"In addition, we found that oi-VAE produces unconditional samples that are qualitatively superior to standard VAEs due to oi-VAE’s bias towards disentangled representations in the latent space.",1. Introduction,[0],[0]
Nonlinear factor analysis aims to relax the strict linearity assumption of classical factor analysis and has a long history in the statistics community.,2. Background,[0],[0]
"The work of (Gibson, 1959) initially circumvented the issues of linear factor analysis by
discretizing continuous nonlinearities.",2. Background,[0],[0]
"However, (McDonald, 1962) was the first to develop a parametric nonlinear factor analysis model.",2. Background,[0],[0]
"Significant progress has been made since then as described in Yalcin & Amemiya (2001), including developments in the Bayesian context (Arminger & Muthén, 1998).",2. Background,[0],[0]
"Recent work in machine learning has also considered similar approaches leveraging Gaussian processes (Lawrence, 2003; Damianou et al., 2012).",2. Background,[0],[0]
"Despite the resemblance to autoencoding models (Ballard, 1987)— especially in the age of “disentanglement”—little work exists exploring connections between the two.
",2. Background,[0],[0]
The study of deep generative models is an active area of research in the machine learning community.,2. Background,[0],[0]
"The variational autoencoder (VAE) (Kingma & Welling, 2013) is one such example that efficiently trains a generative model via amortized inference (see also Rezende et al., 2014).",2. Background,[0],[0]
"Though deep generative models like the VAE have demonstrated an ability to produce convincing samples of complex data (cf., Archer et al., 2015; Johnson et al., 2017), the learned latent representations are not readily interpretable due to the entangled interactions between latent dimensions and the observations, as depicted in Fig. 2.",2. Background,[0],[0]
"We further review the VAE specification in Sec. 3 and its implementation in Sec. 5.
",2. Background,[0],[0]
"A common approach to encourage simple and interpretable models is through use of sparsity inducing penalties such as the lasso (Tibshirani, 1994) and group lasso (Yuan & Lin, 2006).",2. Background,[0],[0]
"These methods work by shrinking many model parameters toward zero and have seen great success in regression models, covariance selection (Danaher et al.), and linear factor analysis (Hirose & Konishi, 2012).",2. Background,[0],[0]
The group lasso penalty is of particular interest to us as it simultaneously shrinks entire groups of model parameters toward zero.,2. Background,[0],[0]
"The usage of group lasso penalties for learning structured inputs to neural networks was explored in Tank et al. (2018) previously, and was inspirational to this work.
",2. Background,[0],[0]
"To specify a valid generative model, we focus on sparsityinducing priors for the parameters of the generator network.",2. Background,[0],[0]
"Historically, the spike-and-slab prior (Mitchell & Beauchamp, 1988) was used to encourage sparsity in Bayesian models.",2. Background,[0],[0]
The prior consists of a two-component mixture with mass on a model parameter being exactly zero.,2. Background,[0],[0]
"Unfortunately, inference in spike-and-slab models is difficult because of the combinatorial nature of the resulting posterior.",2. Background,[0],[0]
"A more computationally tractable family arises from the class of global-local shrinkage priors (Polson & Scott, 2010).",2. Background,[0],[0]
"One popular example is the horseshoe prior (Bhadra et al., 2016).",2. Background,[0],[0]
"However, these priors do not result in exact zeros, making interpretability difficult.
",2. Background,[0],[0]
A sophisticated hierarchical Bayesian prior for sparse group linear factor analysis has recently been developed by Zhao et al. (2016).,2. Background,[0],[0]
"This prior encourages both a sparse set of factors to be used as well as having the factors themselves
be sparse.",2. Background,[0],[0]
The resulting model admits an efficient EM algorithm.,2. Background,[0],[0]
"This builds on previous work on group factor analysis (Virtanen et al., 2012; Klami et al., 2015).",2. Background,[0],[0]
"Sparsity inducing hierarchical Bayesian priors have also been applied to learn the complexity of the Bayesian deep neural networks (Louizos et al., 2017; Ghosh & Doshi-Velez, 2017).",2. Background,[0],[0]
"Our focus, however, is on using (structured) sparsityinducing hierarchical Bayesian priors in the context of deep learning for the sake of interpretability, as in linear factor analysis, rather than model selection.",2. Background,[0],[0]
We frame our proposed output interpretable VAE (oi-VAE) method using the same terminology as the VAE.,3. The oi-VAE model,[0],[0]
Let x ∈,3. The oi-VAE model,[0],[0]
"RD denote a D-dimensional observation and z ∈ RK denote the associated latent representation of fixed dimension K. We then write the generative process of the model as:
z ∼ N (0, I) (1) x",3. The oi-VAE model,[0],[0]
"∼ N (fθ(z),D), (2)
where D is a diagonal matrix containing the marginal variances of each component of x.",3. The oi-VAE model,[0],[0]
The generator is encoded with the function fθ(·) specified as a deep neural network with parameters θ.,3. The oi-VAE model,[0],[0]
Note that the formulation in Eq.,3. The oi-VAE model,[0],[0]
(2) is simpler than that described in Kingma & Welling (2013) where the noise variances were observation specific.,3. The oi-VAE model,[0],[0]
"This simplifying assumption is common with traditional factor models, but could easily be relaxed.
",3. The oi-VAE model,[0],[0]
"When our observations x admit a natural grouping over the components, we write x =",3. The oi-VAE model,[0],[0]
"[x(1), . . .",3. The oi-VAE model,[0],[0]
",x(G)] for each of the G groups.",3. The oi-VAE model,[0],[0]
We model the components within each group g ∈,3. The oi-VAE model,[0],[0]
[G] with separate generative networks f (g)θg parameterized by θg.,3. The oi-VAE model,[0],[0]
"It is possible to share generator parameters θg
across groups, however we chose to model each separately.",3. The oi-VAE model,[0],[0]
"Critically, the latent representation z is shared across all of the group-specific generators.",3. The oi-VAE model,[0],[0]
"In particular:
z ∼ N (0, I) (3)
x(g)",3. The oi-VAE model,[0],[0]
"∼ N (f (g)θg (z),Dg).",3. The oi-VAE model,[0],[0]
"(4)
To this point, our specified group-structured VAE can describe within-group and cross-group correlation structure.",3. The oi-VAE model,[0],[0]
"However, one of the primary goals of this framework is to capture interpretable relationships between groups through the latent representation.
",3. The oi-VAE model,[0],[0]
"Inspired by the sparse factor analysis literature, we extract notions of interpretable interactions by encouraging sparse latent-to-group mappings.",3. The oi-VAE model,[0],[0]
"Specifically, we insert a groupspecific linear transformation W(g) ∈ Rp×K between the latent representation z and the group generator f (g):
x(g) ∼ N (f (g)θ (W (g)z),Dg).",3. The oi-VAE model,[0],[0]
"(5)
We refer to W(g) as the latent-to-group matrix.",3. The oi-VAE model,[0],[0]
"For simplicity, we assume that each generator has input dimension p. When the jth column of the latent-to-group matrix for group g, W(g)·,j , is all zeros then the jth latent dimension, zj , will have no influence on group g in the generative process.",3. The oi-VAE model,[0],[0]
"To induce this column-wise sparsity, we place a hierarchical Bayesian prior on the columns W(g)·,j as follows (Kyung et al., 2010):
γ2gj ∼ Gamma ( p+ 1
2 , λ2 2
) (6)
W (g) ·,j ∼ N (0, γ 2 gjI) (7)
where Gamma(·, ·) is defined by shape and rate.",3. The oi-VAE model,[0],[0]
"The rate parameter λ defines the amount of sparsity, with larger λ implying more column-wise sparsity in W(g).",3. The oi-VAE model,[0],[0]
"Marginalizing over γ2gj induces group sparsity over the columns of W(g); the MAP of the resulting posterior is equivalent to a group lasso penalized objective (Kyung et al., 2010).
",3. The oi-VAE model,[0],[0]
"Unlike linear factor models, the deep structure of our model allows rescaling of the parameters across layer boundaries without affecting the end behavior of the network (Neyshabur et al., 2015).",3. The oi-VAE model,[0],[0]
"In particular, it is possible— and in fact encouraged behavior—to learn a set of W(g) matrices with very small weights and a subsequent layer with very large weights that nullify the shrinkage imposed by the sparsity-inducing prior.",3. The oi-VAE model,[0],[0]
"In order to mitigate this we additionally place a standard normal prior with fixed scale on the parameters of each generative network, θg ∼ N (0, I).
",3. The oi-VAE model,[0],[0]
Special cases of the oi-VAE There are a few notable special cases of our oi-VAE framework.,3. The oi-VAE model,[0],[0]
"When we treat the observations as forming a single group, the model resembles
a traditional VAE since there is a single generator.",3. The oi-VAE model,[0],[0]
"However, the sparsity inducing prior still has an effect that differs from the standard VAE.",3. The oi-VAE model,[0],[0]
"In particular, by shrinking columns of W (dropping the g superscript) the prior will essentially encourage a sparse subset of the components of z to be used to explain the data, similar to a traditional sparse factor model.",3. The oi-VAE model,[0],[0]
"Note that the z’s themselves will still be standard normal, but the columns of W will dictate which components are used.",3. The oi-VAE model,[0],[0]
"This regularization may be advantageous even in the classical, single-group setting as it can provide improved generalization performance in the case of limited training data.",3. The oi-VAE model,[0],[0]
Another special case arises when the generator networks are given by the identity mapping.,3. The oi-VAE model,[0],[0]
"In this case, the only transformation of the latent representation is given by W(g) and the oi-VAE reduces to a classical group sparse linear factor model.",3. The oi-VAE model,[0],[0]
"In oi-VAE, each latent factor influences a sparse set of the observational groups.",4. Interpretability of the oi-VAE,[0],[0]
"The interpretability garnered from this sparse structure is two-fold:
Disentanglement of latent embeddings By associating each component of z with only a sparse subset of the observational groups, we are able to quickly identify disentangled representations in the latent space.",4. Interpretability of the oi-VAE,[0],[0]
"That is, by penalizing interactions between the components of z and each of the groups, we effectively force the model to arrive at a representation that minimizes correlation across the components of z, encouraging each dimension to capture distinct modes of variation.",4. Interpretability of the oi-VAE,[0],[0]
"For example, in Table 1 we see that each of the dimensions of the latent space learned on motion capture recordings of human motion corresponds to a direction of variation relevant to only a subset of the joints (groups) that are used in specific submotions related to walking.",4. Interpretability of the oi-VAE,[0],[0]
"Additionally, it is observed that although the VAE and oi-VAE have similar reconstruction performance the meaningfully disentangled latent representation allows oi-VAE to produce superior unconditional random samples.
",4. Interpretability of the oi-VAE,[0],[0]
"Discovery of group interactions Disregarding any interest in the learned representation z, each latent dimension influences only a sparse subset of the observational groups.",4. Interpretability of the oi-VAE,[0],[0]
"As such, we can view the observational groups associated with a specific latent dimension as a related system of sorts.",4. Interpretability of the oi-VAE,[0],[0]
"For example, in neuroscience often our goal is to uncover functionally-connected brain networks.",4. Interpretability of the oi-VAE,[0],[0]
In this setting we may split the signal into groups based on a standard parcellation.,4. Interpretability of the oi-VAE,[0],[0]
"Then networks can be identified by inspecting the subset of groups influenced by a component in the latent code, zi.",4. Interpretability of the oi-VAE,[0],[0]
Such an approach is attractive in the context of analyzing functional connectivity from MEG data where we seek modules of highly correlated regions.,4. Interpretability of the oi-VAE,[0],[0]
"See the ex-
periments of Sec. 6.3.",4. Interpretability of the oi-VAE,[0],[0]
"Likewise, in our motion capture experiments of Sec. 6.2, we see (again from Table 1) how we can treat collections of joints as a system that covary in meaningful ways within a given human motion category.
",4. Interpretability of the oi-VAE,[0],[0]
"Broadly speaking, the relationship between dimensions of z and observational groups can be thought of as a bipartite graph in which we can quickly identify correlation and independence relationships among the groups themselves.",4. Interpretability of the oi-VAE,[0],[0]
The ability to expose or refute correlations among observational groups is attractive as an exploratory scientific tool independent of building a generative model.,4. Interpretability of the oi-VAE,[0],[0]
"This is especially useful since standard measures of correlation are linear, leaving much to be desired in the face of high-dimensional data with many potential nonlinear relationships.",4. Interpretability of the oi-VAE,[0],[0]
"Our hope is that oi-VAE serves as one initial tool to spark a new wave of interest in nonlinear factor models and their application to complicated and rich data across a variety of fields.
",4. Interpretability of the oi-VAE,[0],[0]
It is worth emphasizing that the goal is not to learn sparse representations in the z’s.,4. Interpretability of the oi-VAE,[0],[0]
"Sparsity in z may be desirable in certain contexts, but it does not actually provide any interpretability in the data generating process.",4. Interpretability of the oi-VAE,[0],[0]
"Still, we find that oi-VAE does prune dimensions that are not necessary in synthetic examples.",4. Interpretability of the oi-VAE,[0],[0]
"Traditionally, VAEs are learned by applying stochastic gradient methods directly to the evidence lower bound (ELBO):
log p(x) ≥ Eqφ(z|x)[log pθ(x, z)− log qφ(z|x)],
where qφ(z|x) denotes the amortized posterior distribution of z given observation x, parameterized by a neural network with weights φ.",5. Collapsed variational inference,[0],[0]
Using a neural network to parameterize the observation distribution p(x|z) as in Eq.,5. Collapsed variational inference,[0],[0]
(1) makes the expectation in the ELBO intractable.,5. Collapsed variational inference,[0],[0]
"To address this, the VAE employs Monte Carlo variational inference (MCVI) (Kingma & Welling, 2013):",5. Collapsed variational inference,[0],[0]
"The troublesome expectation is approximated with samples of the latent variables from the variational distribution, z ∼ qφ(z|x), where qφ(z|x) is reparameterized to allow differentiating through the expectation operator in order to reduce gradient variance.
",5. Collapsed variational inference,[0],[0]
We extend the basic VAE amortized inference procedure to incorporate our sparsity inducing prior over the columns of the latent-to-group matrices.,5. Collapsed variational inference,[0],[0]
"The naive approach of optimizing variational distributions for γ2gj and W (g) ·,j will not result in true sparsity of the columns W(g)·,j .",5. Collapsed variational inference,[0],[0]
"Instead, we consider a collapsed variational objective function.",5. Collapsed variational inference,[0],[0]
"Since our sparsity inducing prior over W(g)·,j is marginally equivalent to the convex group lasso penalty we can use proximal gradient descent on the collapsed objective and obtain true group sparsity (Parikh & Boyd, 2013).",5. Collapsed variational inference,[0],[0]
"Following the standard VAE approach of Kingma & Welling (2013), we use sim-
ple point estimates for the variational distributions on the neural network parametersW =",5. Collapsed variational inference,[0],[0]
"( W(1), · · · ,W(G) )",5. Collapsed variational inference,[0],[0]
"and θ = (θ1, . . .",5. Collapsed variational inference,[0],[0]
", θG)",5. Collapsed variational inference,[0],[0]
.,5. Collapsed variational inference,[0],[0]
"We take qφ(z|x) = N (µ(x), σ2(x)))",5. Collapsed variational inference,[0],[0]
where the mean and variances are parameterized by an inference network with parameters φ.,5. Collapsed variational inference,[0],[0]
"We construct a collapsed variational objective by marginalizing the γ2gj to compute log p(x) as:
log ∫ p(x|z,W, θ)p(z)p(W|γ2)p(γ2)p(θ) dγ2 dz
= log ∫ (∫ p(W, γ2) dγ2 )",5.1. The collapsed objective,[0],[0]
"p(x|z,W, θ)p(z)p(θ) qφ(z|x)/qφ(z|x) dz
≥ Eqφ(z|x)",5.1. The collapsed objective,[0],[0]
"[log p(x|z,W, θ)]−KL(qφ(z|x)||p(z))",5.1. The collapsed objective,[0],[0]
"+ log p(θ)− λ ∑ g,j ||W(g)·,j ||2
, L(φ, θ,W).
",5.1. The collapsed objective,[0],[0]
"Importantly, the columns of the latent-to-group matrices W
(g) ·,j appear in a 2-norm penalty in the collapsed ELBO.",5.1. The collapsed objective,[0],[0]
"This is exactly a group lasso penalty on the columns of W
(g) ·,j and encourages the entire column to be set to zero.
",5.1. The collapsed objective,[0],[0]
"Now our goal becomes maximizing this collapsed ELBO over φ, θ, andW .",5.1. The collapsed objective,[0],[0]
"Since this objective contains a standard group lasso penalty, we can leverage efficient proximal gradient descent updates on the latent-to-group matrices W as detailed in Sec. 5.2.",5.1. The collapsed objective,[0],[0]
Proximal algorithms achieve better rates of convergence than sub-gradient methods and have shown great success in solving convex objectives with group lasso penalties.,5.1. The collapsed objective,[0],[0]
"We can use any off-the-shelf optimization method for the remaining neural net parameters, θg and φ.",5.1. The collapsed objective,[0],[0]
"Proximal gradient descent algorithms are a broad class of optimization techniques for separable objectives with both differentiable and potentially non-differentiable components,
min x g(x) + h(x), (8)
where g(x) is differentiable and h(x) is potentially nonsmooth or non-differentiable (Parikh & Boyd, 2013).",5.2. Proximal gradient descent,[0],[0]
Stochastic proximal algorithms are well-studied for convex optimization problems.,5.2. Proximal gradient descent,[0],[0]
"Recent work has shown that some variants are guaranteed to converge to a first-order stationary point even if the objective is comprised of a non-convex g(x) as long as the non-smooth h(x) is convex (Reddi et al., 2016).",5.2. Proximal gradient descent,[0],[0]
"The usual tactic is to take gradient steps on g(x) followed by “corrective” proximal steps to respect h(x):
xt+1 = proxηh(xt − η∇g(xt))",5.2. Proximal gradient descent,[0],[0]
"(9)
Algorithm 1 Collapsed VI for oi-VAE
Input: data x(i), sparsity parameter λ Let L̃ = L(φ, θ,W) +",5.2. Proximal gradient descent,[0],[0]
"λ ∑ g,j ||W (g) ·,j ||2.",5.2. Proximal gradient descent,[0],[0]
"repeat Calculate∇φL̃,∇θL̃, and ∇W L̃.",5.2. Proximal gradient descent,[0],[0]
Update φ,5.2. Proximal gradient descent,[0],[0]
and θ with an optimizer of your choice.,5.2. Proximal gradient descent,[0],[0]
LetWt+1 =Wt − η∇W L̃. for all groups g and j,5.2. Proximal gradient descent,[0],[0]
"= 1 to K do
Set W(g)·,j ← W
(g) ·,j
||W(g)·,j ||2
( ||W(g)·,j ||2 − ηλ )",5.2. Proximal gradient descent,[0],[0]
"+
end for until convergence in both L̂ and −λ ∑ g,j ||W (g) ·,j ||2
where proxf (x) is the proximal operator for the function f .",5.2. Proximal gradient descent,[0],[0]
"For example, if h(x) is the indicator function for a convex set then the proximal operator is simply the projection operator onto the set and the update in Eq.",5.2. Proximal gradient descent,[0],[0]
(9) is projected gradient.,5.2. Proximal gradient descent,[0],[0]
Expanding the definition of proxηh in Eq.,5.2. Proximal gradient descent,[0],[0]
"(9), one can see that the proximal step corresponds to minimizing h(x) plus a quadratic approximation to g(x) centered on xt.",5.2. Proximal gradient descent,[0],[0]
"For h(x) = λ||x||2, the proximal operator is given by
proxηh(x) = x
||x||2 (||x||2 − ηλ)+",5.2. Proximal gradient descent,[0],[0]
"(10)
",5.2. Proximal gradient descent,[0],[0]
"where (v)+ , max(0, v) (Parikh & Boyd, 2013)",5.2. Proximal gradient descent,[0],[0]
.,5.2. Proximal gradient descent,[0],[0]
"Geometrically, this operator reduces the norm of x by ηλ, and shrinks x’s with ||x||2 ≤ ηλ to zero.",5.2. Proximal gradient descent,[0],[0]
"This operator is especially convenient since it is both cheap to compute and results in machine-precision zeros, unlike many Bayesian approaches to sparsity that result in small but non-zero values and thus require an extra thresholding step to attain exact zeros.
",5.2. Proximal gradient descent,[0],[0]
"We experimented with standard (non-collapsed) variational inference as well other schemes, but found that collapsed variational inference with proximal updates provided faster convergence and succeeded in identifying sparser models than other techniques.",5.2. Proximal gradient descent,[0],[0]
In practice we apply proximal stochastic gradient updates per Eq.,5.2. Proximal gradient descent,[0],[0]
"(9) on theW matrices and Adam (Kingma & Ba, 2014) on the remaining parameters.",5.2. Proximal gradient descent,[0],[0]
See Alg. 1 for complete pseudocode.,5.2. Proximal gradient descent,[0],[0]
"To evaluate oi-VAE’s ability to identify sparse models on well-understood data, we generated 8× 8 images with one randomly selected row of pixels shaded and additive noise corrupting the entire image.",6.1. Synthetic data,[0],[0]
We then built and trained an oi-VAE model on the images with each group defined as an entire row of pixels in the image.,6.1. Synthetic data,[0],[0]
We used an 8-dimensional latent space in order to encourage the model to associate each dimension of z with a unique row in the image.,6.1. Synthetic data,[0],[0]
"Results
are shown in Fig. 2.",6.1. Synthetic data,[0],[0]
Our oi-VAE successfully disentangles each of the dimensions of z to correspond to exactly one row (group) of the image.,6.1. Synthetic data,[0],[0]
We also trained an oi-VAE model with a 16-dimensional latent space (see the Supplement) and see that when additional latent components are not needed to describe any group they are pruned from the model.,6.1. Synthetic data,[0],[0]
Using data collected from CMU’s motion capture database we evaluated oi-VAE’s ability to handle complex physical constraints and interactions across groups of joint angles while simultaneously identifying a sparse decomposition of human motion.,6.2. Motion Capture,[0],[0]
The dataset consists of 11 examples of walking and one example of brisk walking from the same subject.,6.2. Motion Capture,[0],[0]
The recordings measure 59 joint angles split across 29 distinct joints.,6.2. Motion Capture,[0],[0]
The joint angles were normalized from their full ranges to lie between zero and one.,6.2. Motion Capture,[0],[0]
"We treat the set of measurements from each distinct joint as a group; since each joint has anywhere from 1 to 3 observed degrees of freedom, this setting demonstrates how oi-VAE can handle variable-sized groups.",6.2. Motion Capture,[0],[0]
"For training, we randomly sample 1 to 10 walking trials, resulting in up to 3791 frames.",6.2. Motion Capture,[0],[0]
"Our experiments evaluate the following performance metrics: interpretability of the learned interaction structure amongst groups and of the latent representation; test log-likelihood, assessing the model’s generalization ability; and both conditional and unconditional samples to evaluate the quality of the learned generative process.",6.2. Motion Capture,[0],[0]
"In all experiments, we use λ = 1.",6.2. Motion Capture,[0],[0]
"For further details on the specification of all considered models (VAE and oi-VAE), see the Supplement.
To begin, we train our oi-VAE on the full set of 10 training trials with the goal of examining the learned latent-togroup mappings.",6.2. Motion Capture,[0],[0]
"To explore how the learned disentangled latent representation varies with latent dimension K, we use K = 4, 8, and 16.",6.2. Motion Capture,[0],[0]
The results are summarized in Fig. 3.,6.2. Motion Capture,[0],[0]
"We see that as K increases, individual “features” (i.e., components of z) are refined to capture more localized anatomical structures.",6.2. Motion Capture,[0],[0]
"For example, feature 2 in the K = 4 case turns into feature 7 in the K = 16 case, but in that case we also add feature 3 to capture just variations of lfingers, lthumb separate from head, upperneck, lowerneck.",6.2. Motion Capture,[0],[0]
"Likewise, feature 2 when K = 16 repre-
sents head, upperneck, lowerneck separately from lfingers, lthumb.",6.2. Motion Capture,[0],[0]
"To help interpret the learned disentangled latent representation, for the K = 16 embedding we provide lists of the 3 joints per dimension that are most strongly influenced by that component.",6.2. Motion Capture,[0],[0]
"From these lists, we see how the learned decomposition of the latent representation has an intuitive anatomical interpretation.",6.2. Motion Capture,[0],[0]
"For example, one of the very prominent features is feature 14, which jointly influences the thorax, upperback, and lowerback.",6.2. Motion Capture,[0],[0]
"Collectively, these results clearly demonstrate how the oi-VAE provides meaningful interpretability.",6.2. Motion Capture,[0],[0]
"We emphasize that it is not even possible to make these types of images or lists for the VAE.
",6.2. Motion Capture,[0],[0]
"One might be concerned that by gaining interpretability, we lose out on expressivity.",6.2. Motion Capture,[0],[0]
"However, as we demonstrate in Table 2 and Figs. 4-5, the regularization provided by our sparsity-inducing penalty actually leads to as good or better performance.",6.2. Motion Capture,[0],[0]
We first examine oi-VAE and VAE’s ability to generalize to held out data.,6.2. Motion Capture,[0],[0]
"To examine robustness to different amounts of training data, we consider training on increasing numbers of walk trials and testing on a single heldout example of either walk or brisk walk.",6.2. Motion Capture,[0],[0]
"The latter represents an example of data that is a variation of what was trained on, whereas the former is a heldout example, very similar to the training data.",6.2. Motion Capture,[0],[0]
"In Table 2, we see the benefit of the regularization in oi-VAE in both test scenarios in the limited data regime.",6.2. Motion Capture,[0],[0]
"Unsurprisingly, for the full 10 trials, there are little to no differences between the generalization abilities of oi-VAE and VAE (though of course the oi-VAE still provides interpretability).",6.2. Motion Capture,[0],[0]
"We highlight that
when we have both a limited amount of training data that might not be fully representative of the full possible dataset of interest (e.g., all types of walking), the regularization provided by oi-VAE provides dramatic improvements for generalization.",6.2. Motion Capture,[0],[0]
"Finally, in almost all scenarios, the more decomposed oi-VAE K = 16 setting has better or comparable performance to smaller K settings.",6.2. Motion Capture,[0],[0]
"We leave choosing K and investigating the effects of pruning to future work.
",6.2. Motion Capture,[0],[0]
"Next, we turn to assessing the learned oi-VAE’s generative process relative to that of the VAE.",6.2. Motion Capture,[0],[0]
"In Fig. 4 we take our test trial of walk, run each frame through the learned inference network to get a set of approximate posteriors.",6.2. Motion Capture,[0],[0]
"For every such qφ(z|x), we sample 32 times from the distribution and run each sample through the generator networks to synthesize a batch of reconstructions.",6.2. Motion Capture,[0],[0]
"To fully explore the space of human motion the learned generators can capture, we take 100 unconditional samples from both the oi-VAE and VAE models and show a representative subset in Fig. 5.",6.2. Motion Capture,[0],[0]
The full set of 100 random samples from both oi-VAE and VAE are provided in the Supplement.,6.2. Motion Capture,[0],[0]
"Note that even when trained on the full set of 10 walk trials where we see little to no difference in test log-likelihood between the oi-VAE and VAE, we do see that the learned generator for the oi-VAE is more representative of physically plausible human motion poses.",6.2. Motion Capture,[0],[0]
"We attribute this to the fact that the test log-likelihood does not encourage quality unconditional samples, but a disentangled latent representation should yield qualitatively better results on samples from the prior.",6.2. Motion Capture,[0],[0]
"Magnetoencephalography (MEG) records the weak magnetic field produced by the brain during cognitive activity
with great temporal resolution and good spatial resolution.",6.3. Magnetoencephalography,[0],[0]
Analyzing this data holds great promise for understanding the neural underpinnings of cognitive behaviors and for characterizing neurological disorders such as autism.,6.3. Magnetoencephalography,[0],[0]
"A common step when analyzing MEG data is to project the MEG sensor data into source-space where we obtain observations over time on a mesh (≈ 5-10K vertices) of the cortical surface (Gramfort et al., 2013).",6.3. Magnetoencephalography,[0],[0]
The resulting source-space signals likely live on a low-dimensional manifold making methods such as the VAE attractive.,6.3. Magnetoencephalography,[0],[0]
"Still, neuroscientists have meticulously studied particular brain regions of interest and what behaviors they are involved in by hand.
",6.3. Magnetoencephalography,[0],[0]
"We apply our oi-VAE method to infer low-rank representations of source-space MEG data where the groups are specified as the ≈ 40 regions defined in the HCP-MMP1 brain parcellation (Glasser et al., 2016).",6.3. Magnetoencephalography,[0],[0]
See Fig.,6.3. Magnetoencephalography,[0],[0]
6(left).,6.3. Magnetoencephalography,[0],[0]
The recordings were collected from a single subject performing an auditory attention task where they were asked to maintain their attention to one of two auditory streams.,6.3. Magnetoencephalography,[0],[0]
We use 106 trials each of length 385.,6.3. Magnetoencephalography,[0],[0]
"We treat each time point
Table 2.",6.3. Magnetoencephalography,[0],[0]
"Test log-likelihood for VAE and oi-VAE trained on 1,2,5, or 10 trials of walk data.",6.3. Magnetoencephalography,[0],[0]
Table includes results for a test walk (same as training) or brisk walk trial (unseen in training).,6.3. Magnetoencephalography,[0],[0]
Bold numbers indicate the best performance.,6.3. Magnetoencephalography,[0],[0]
"The standard VAE uses the same structure as oi-VAE for a consistent comparison (equivalent to λ = 0).
",6.3. Magnetoencephalography,[0],[0]
"STANDARD WALK BRISK WALK
# TRIALS 1 2 5 10 1 2 5 10
VAE (K = 16) −3, 518 −251 18 114 −723, 795 −15, 413, 445 −19, 302, 644 −19, 303, 072",6.3. Magnetoencephalography,[0],[0]
"OI-VAE (K = 4) −2,722 −214 27 70 −664, 608 −13, 438, 602 −19,289,548 −19, 302, 680 OI-VAE (K = 8) −3, 196 −195 29 75 −283, 352 −10, 305, 693 −19, 356, 218 −19, 302, 764 OI-VAE (K = 16) −3, 550 −188 31 108 −198,663 −6,781,047 −19, 299, 964 −19, 302, 924
of each trial as an i.i.d.",6.3. Magnetoencephalography,[0],[0]
observation resulting in ≈ 41K observations.,6.3. Magnetoencephalography,[0],[0]
"For details on the specification of all considered models, see the Supplement.
",6.3. Magnetoencephalography,[0],[0]
For each region we compute the average source-space activity over all vertices in each region resulting in 44- dimensional observations.,6.3. Magnetoencephalography,[0],[0]
"We applied oi-VAE withK = 20, λ = 10, and Alg.",6.3. Magnetoencephalography,[0],[0]
"1 for 10, 000 iterations.",6.3. Magnetoencephalography,[0],[0]
"In Fig. 6 we depict the learned group-weights ||W(g)·,j ||2 for all groups g and components j. We observe that each component manifests itself in a sparse subset of the regions.",6.3. Magnetoencephalography,[0],[0]
"Next, we dig into specific latent components and evaluate whether each influences a subset of regions in a neuroscientifically interpretable manner.
",6.3. Magnetoencephalography,[0],[0]
"For a given latent component zj , the value ||W(g)·,j ||2 allows us to interpret how much component j influences region g.",6.3. Magnetoencephalography,[0],[0]
We visualize some of these weights for two prominent learned components in Fig. 7.,6.3. Magnetoencephalography,[0],[0]
"Specifically, we find that component 6 captures the regions that make up the dorsal attention network pertaining to an auditory spatial task, viz., early visual, auditory sensory areas as well as inferior parietal sulcus and the region covering the right temporoparietal junction (Lee et al., 2014).",6.3. Magnetoencephalography,[0],[0]
"We also find that component 15 corresponds to regions associated with the default mode network, viz., medial prefrontal as well as posterior cingulate cortex (Buckner et al., 2008).",6.3. Magnetoencephalography,[0],[0]
Again the oi-VAE leads to interpretable results that align with meaningful and previously studied physiological systems.,6.3. Magnetoencephalography,[0],[0]
"These systems can be
Figure 7.",6.3. Magnetoencephalography,[0],[0]
Influence of z6 (top) and z15 (bottom) on the HCPMMP1 regions.,6.3. Magnetoencephalography,[0],[0]
"Active regions (shaded) correspond to the dorsal attention network and default mode network, respectively.
further probed through functional connectivity analysis.",6.3. Magnetoencephalography,[0],[0]
See the Supplement for the analysis of more components.,6.3. Magnetoencephalography,[0],[0]
We proposed an output interpretable VAE (oi-VAE) that can be viewed as either a nonlinear group latent factor model or as a structured VAE with disentangled latent embeddings.,7. Conclusion,[0],[0]
The approach combines deep generative models with a sparsity-inducing prior that leads to our ability to extract meaningful notions of latent-to-observed interactions when the observations are structured into groups.,7. Conclusion,[0],[0]
"From this interaction structure, we can infer correlated systems of interaction amongst the observational groups.",7. Conclusion,[0],[0]
In our motion capture and MEG experiments we demonstrated that the resulting systems are physically meaningful.,7. Conclusion,[0],[0]
"Importantly, this interpretability does not appear to come at the cost of expressiveness, and in our group-structured case can actually lead to improved generalization and generative processes.
",7. Conclusion,[0],[0]
"In contrast to alternative approaches for nonlinear group sparse factor analysis, leveraging the amortized inference associated with VAEs leads to computational efficiencies.",7. Conclusion,[0],[0]
We see even more significant gains through our proposed collapsed objective.,7. Conclusion,[0],[0]
"The proximal updates we can apply lead quickly to true sparsity.
",7. Conclusion,[0],[0]
Note that nothing fundamentally prevents applying this architecture to other generative models du jour.,7. Conclusion,[0],[0]
"Extending this work to generative adversarial models, for example, should be straightforward (Goodfellow et al., 2014).",7. Conclusion,[0],[0]
Oy-vey!,7. Conclusion,[0],[0]
Special thanks to Ian Covert and Alex Tank for helpful discussions and insight.,Acknowledgements,[0],[0]
"This work was supported by ONR Grant N00014-15-1-2380, NSF CAREER Award IIS-1350133, NSF CRCNS Grant NSF-IIS-1607468, and AFOSR Grant FA9550-16-1-0038.",Acknowledgements,[0],[0]
The authors also gratefully acknowledge the support of NVIDIA Corporation for the donated GPU used for this research.,Acknowledgements,[0],[0]
Deep generative models have recently yielded encouraging results in producing subjectively realistic samples of complex data.,abstractText,[0],[0]
Far less attention has been paid to making these generative models interpretable.,abstractText,[0],[0]
"In many scenarios, ranging from scientific applications to finance, the observed variables have a natural grouping.",abstractText,[0],[0]
"It is often of interest to understand systems of interaction amongst these groups, and latent factor models (LFMs) are an attractive approach.",abstractText,[0],[0]
"However, traditional LFMs are limited by assuming a linear correlation structure.",abstractText,[0],[0]
"We present an output interpretable VAE (oi-VAE) for grouped data that models complex, nonlinear latent-to-observed relationships.",abstractText,[0],[0]
We combine a structured VAE comprised of group-specific generators with a sparsity-inducing prior.,abstractText,[0],[0]
We demonstrate that oi-VAE yields meaningful notions of interpretability in the analysis of motion capture and MEG data.,abstractText,[0],[0]
"We further show that in these situations, the regularization inherent to oi-VAE can actually lead to improved generalization and learned generative processes.",abstractText,[0],[0]
oi-VAE: Output Interpretable VAEs for Nonlinear Group Factor Analysis,title,[0],[0]
Low rank matrix optimization stands as a major tool in modern dimensionality reduction and unsupervised learning.,1. Introduction,[0],[0]
The singular value decomposition can be used when the optimization objective is rotationally invariant to the parameters.,1. Introduction,[0],[0]
"However, if we wish to optimize over more complex, non-convex objectives we must choose to either rely on convex relaxations (Recht et al., 2010; Negahban & Wainwright, 2011; Rohde & Tsybakov, 2011) or directly optimize over the non-convex space (Park et al., 2016; Jain et al., 2013; Chen & Wainwright, 2015; Lee & Bresler, 2013; Jain et al., 2014).
",1. Introduction,[0],[0]
"More concretely, in the low rank matrix optimization problem, we wish to solve
argmax
⇥
`(⇥) s.t. rank(⇥)  ",1. Introduction,[0],[0]
"r. (1)
Rather than perform the computationally intractable optimization above researchers have studied convex relaxations of the form
argmax
⇥
`(⇥) |||⇥||| nuc .
",1. Introduction,[0],[0]
1UT Austin 2Yale University.,1. Introduction,[0],[0]
"Correspondence to: Rajiv Khanna <rajivak@utexas.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"Unfortunately, the above optimization can be computationally taxing.",1. Introduction,[0],[0]
"General purpose solvers for the above optimization problem that rely on semidefinite programming (SDP) require ⇥(n3d3) computation, which is prohibitive.",1. Introduction,[0],[0]
Gradient descent techniques require ⇥(✏ 1/2(n3 + d3)) computational cost for an epsilon accurate solution.,1. Introduction,[0],[0]
This improvement is sizable in comparison to SDP solvers.,1. Introduction,[0],[0]
"Unfortunately, it is still prohibitive for large scale matrix estimation.
",1. Introduction,[0],[0]
An alternate vein of research has focused on directly optimizing the non-convex problem (1).,1. Introduction,[0],[0]
"To that end, authors have seen recent theoretical success in studying the convergence properties of
argmax U2Rn⇥r,V2Rd⇥r",1. Introduction,[0],[0]
"`(UVT ).
",1. Introduction,[0],[0]
"Solving the problem above automatically forces the solution to be low rank, and recent results have shown promising behavior.
",1. Introduction,[0],[0]
"Another approach is to optimize (1) incrementally via rank one updates to the current estimate (Shalev-Shwartz et al., 2011; Wang et al., 2015).",1. Introduction,[0],[0]
"This approach has also been studied in more general contexts such as boosting (Buhlmann & Yu, 2009), coordinate descent (Jaggi, 2013; Jaggi & Sulovský, 2010), and incremental atomic norm optimization (Gribonval & Vandergheynst, 2006; Barron et al., 2008; Khanna et al., 2016; Rao et al., 2015; Dudik et al., 2012; Locatello et al., 2017).",1. Introduction,[0],[0]
"In this paper, we interpret low rank matrix estimation as a set optimization problem over an infinite set of atoms.",1.1. Set Function Optimization and Coordinate Descent,[0],[0]
"Specifically, we wish to optimize
argmax {X1,...Xk}2A",1.1. Set Function Optimization and Coordinate Descent,[0],[0]
"`
kX
i=1
↵iXi
! ,
where the set of atoms A is the set of all rank one matrices with unit operator norm.",1.1. Set Function Optimization and Coordinate Descent,[0],[0]
"This settings is analogous to that taken in the results studying atomic norm optimization, coordinate descent via the total variation norm, and Frank-Wolfe style algorithms for atomic optimization.",1.1. Set Function Optimization and Coordinate Descent,[0],[0]
"This formulation allows us to connect the problem of low rank matrix estimation to that of submodular set function optimization, which
we discuss in the sequel.",1.1. Set Function Optimization and Coordinate Descent,[0],[0]
Before proceeding we discuss related work and an informal statement of our main result.,1.1. Set Function Optimization and Coordinate Descent,[0],[0]
Our result demonstrates an exponential decrease in the amount of error incurred by greedily adding rank one matrices to the low rank matrix approximation.,1.2. Informal Result and Related Work,[0],[0]
"Theorem 1 (Approximation Guarantee, Informal).",1.2. Informal Result and Related Work,[0],[0]
"If we let ⇥k be our estimate of the rank r matrix ⇥⇤ at iteration k, then for some universal constant c related to the restricted condition number of the problem we have
`(⇥k) `(0) (1 exp( ck/r))(`(⇥⇤) `(0)).
",1.2. Informal Result and Related Work,[0],[0]
"Note that after k iterations the matrix ⇥k will be at most rank k.
Related work: There has been a wide array of studies looking at the computational and statistical benefits of rank one updates to estimating a low rank matrix.",1.2. Informal Result and Related Work,[0],[0]
"At its most basic, the singular value decomposition will keep adding rank one approximations through deflation steps.",1.2. Informal Result and Related Work,[0],[0]
This work can be generally segmented into two sets of results – the ones that present sublinear rates of convergence and those that obtain linear rates.,1.2. Informal Result and Related Work,[0],[0]
"Interestingly, parallel lines of work have also demonstrated similar convergence bounds for more general atomic or dictionary element approximations (Buhlmann & Yu, 2009; Gribonval & Vandergheynst, 2006; Barron et al., 2008; Khanna et al., 2016).",1.2. Informal Result and Related Work,[0],[0]
"For space constraints, we will summarize these results into two categories rather than explicitly state the results for each individual paper.
",1.2. Informal Result and Related Work,[0],[0]
"If we define the atomic norm of a matrix M 2 Rn⇥d written as |||M|||
nuc to be the sum of the singular values of that matrix, then the bounds establishing sublinear convergence behave as
`(⇥⇤) `(⇥k)  |||⇥⇤|||2 nuc
k ,
where we take ⇥⇤ to be the best rank r solution.",1.2. Informal Result and Related Work,[0],[0]
What we then see is convergence towards the optimal bound.,1.2. Informal Result and Related Work,[0],[0]
"However, we expect our statistical error to behave as r(n+ d)/n where n is the number of samples that we have received from our statistical model and ⇥⇤ is rank r (Negahban & Wainwright, 2011; Rohde & Tsybakov, 2011).",1.2. Informal Result and Related Work,[0],[0]
"We can take |||⇥⇤|||
nuc ⇡ r, which would then imply that we would need k to behave as n/(n+ d).",1.2. Informal Result and Related Work,[0],[0]
"However, that would then imply that the rank of our matrix should grow linearly in the number of observations in order to achieve the same statistical error bounds.",1.2. Informal Result and Related Work,[0],[0]
The above error bounds are “fast”.,1.2. Informal Result and Related Work,[0],[0]
"If we consider a model that yields slow error bounds, then we expect the error to behave like |||⇥⇤|||
nuc q n+d n .",1.2. Informal Result and Related Work,[0],[0]
"In that case,
we can take k |||⇥⇤|||",1.2. Informal Result and Related Work,[0],[0]
"nuc
q n
n+d , which looks better, but
still requires significant growth in k as a function of n. To overcome the above points, some authors have aimed to study similar greedy algorithms that then enjoy exponential rates of convergence as we show in our paper.",1.2. Informal Result and Related Work,[0],[0]
"These results share the most similarities with our own and behave as
`(⇥k) (1 k)`(⇥⇤).
",1.2. Informal Result and Related Work,[0],[0]
This result decays exponentially.,1.2. Informal Result and Related Work,[0],[0]
"However, when one looks at the behavior of it will typically act as exp ( 1/min(n,d)), for an n⇥ d matrix.",1.2. Informal Result and Related Work,[0],[0]
"As a result, we would need to choose k of the order of the dimensionality of the problem in order to begin to see gains.",1.2. Informal Result and Related Work,[0],[0]
"In contrast, for our result listed above, if we seek to only compare to the best rank r solution, then the gamma we find is = exp ( 1/r).",1.2. Informal Result and Related Work,[0],[0]
"Of course, if we wish to find a solution with full rank, then the bounds we stated above match the existing bounds.
",1.2. Informal Result and Related Work,[0],[0]
In order to establish our results we rely on a notion introduced in the statistical community called restricted strong convexity.,1.2. Informal Result and Related Work,[0],[0]
"This assumption has connections to ideas such as the restricted isometry property, restricted eigenvalue condition, and incoherence (Negahban & Wainwright, 2012).",1.2. Informal Result and Related Work,[0],[0]
"In the work by Shalev-Shwartz, Gonen, and Shamir (2011) a form of strong convexity condition is imposed over matrices.",1.2. Informal Result and Related Work,[0],[0]
"Under that setting, the authors demonstrate that
`(⇥k) `(⇥⇤) `(0)r
k ,
where r is the rank of ⇥⇤.",1.2. Informal Result and Related Work,[0],[0]
"In contrast, our bound behaves as
`(⇥k) `(⇥⇤) (`(⇥⇤) `(0))",1.2. Informal Result and Related Work,[0],[0]
"exp ( k/r).
",1.2. Informal Result and Related Work,[0],[0]
Our contributions: We improve upon the linear rates of convergence for low rank approximation using rank one updates by connecting the coordinate descent problem to that of submodular optimization.,1.2. Informal Result and Related Work,[0],[0]
We present this result in the sequel along with the algorithmic consequences.,1.2. Informal Result and Related Work,[0],[0]
We demonstrate the good performance of these rank one updates in the experimental section.,1.2. Informal Result and Related Work,[0],[0]
We begin by fixing some notation.,2. Background,[0],[0]
"We represent sets using sans script fonts e.g. A,B. Vectors are represented using lower case bold letters e.g. x,y, and matrices are represented using upper case bold letters e.g. X,Y. Non-bold face letters are used for scalars e.g. j,M, r and function names e.g. f(·).",2. Background,[0],[0]
The transpose of a vector or a matrix is represented by > e.g. X>.,2. Background,[0],[0]
Define,2. Background,[0],[0]
"[p] := {1, 2, . . .",2. Background,[0],[0]
", p}.",2. Background,[0],[0]
"For singleton sets, we write f(j) := f({j}).",2. Background,[0],[0]
"Size of a set S is denoted by |S|. h·, ·i is used for matrix inner product.
",2. Background,[0],[0]
Our goal is to analyze greedy algorithms for low rank estimation.,2. Background,[0],[0]
"Consider the classic greedy algorithm that picks up
the next element myopically i.e. given the solution set built so far, the algorithm picks the next element as the one which maximizes the gain obtained by adding the said element into the solution set.",2. Background,[0],[0]
Approximation guarantees for the greedy algorithm readily imply for the class of functions defined as follows.,2. Background,[0],[0]
Definition 1.,2. Background,[0],[0]
A set function f(·) :,2. Background,[0],[0]
[p]!,2. Background,[0],[0]
"R is submodular if for all A,B ✓",2. Background,[0],[0]
"[p],
f(A)",2. Background,[0],[0]
"+ f(B) f(A [ B) + f(A \ B).
",2. Background,[0],[0]
Submodular set functions are well studied and have many desirable properties that allow for efficient minimization and maximization with approximation guarantees.,2. Background,[0],[0]
Our low rank estimation problem also falls under the purview of another class of functions called monotone functions.,2. Background,[0],[0]
"A function is called monotone if and only if f(A)  f(B) for all A ✓ B. For the specific case of maximizing monotone submodular set functions, it is known that the greedy algorithm run for k iterations is guaranteed to return a solution that is within (1 1/e) of the optimum set of size",2. Background,[0],[0]
"k (Nemhauser et al., 1978).",2. Background,[0],[0]
"Without further assumptions or knowledge of the function, no other polynomial time algorithm can provide a better approximation guarantee unless P=NP (Feige, 1998).
",2. Background,[0],[0]
"More recently, the aforementioned greedy approximation guarantee has been extended to a larger class of functions called weakly submodular functions (Elenberg et al., 2016; Khanna et al., 2017).",2. Background,[0],[0]
Central to the notion of weak submodularity is a quantity called the submodularity ratio.,2. Background,[0],[0]
"Definition 2 (Submodularity Ratio (Das & Kempe, 2011)).",2. Background,[0],[0]
"Let S, L ⇢",2. Background,[0],[0]
"[p] be two disjoint sets, and f(·) :",2. Background,[0],[0]
[p]!,2. Background,[0],[0]
"R. The submodularity ratio of L with respect to S is given by
L,S := P j2S [f(L [ {j}) f(L)] f(L [ S) f(L) .",2. Background,[0],[0]
"(2)
The submodularity ratio of a set U with respect to an integer k is given by
U,k := min L,S:L\S=;, L✓U,|S|k
L,S. (3)
",2. Background,[0],[0]
"It is easy to show that f(·) is submodular if and only if L,S 1 for all sets L and S. However, an approximation guarantee is obtained when 0 <",2. Background,[0],[0]
"L,S 8 L, S (Das & Kempe, 2011; Elenberg et al., 2016).",2. Background,[0],[0]
"The subset of monotone functions which have L,S > 0 8 L, S are called weakly submodular functions in the sense that even though the function is not submodular, it still provides a provable bound for greedy selections.
",2. Background,[0],[0]
"Also vital to our analysis is the notion of restricted strong concavity and smoothness (Negahban et al., 2012; Loh & Wainwright, 2015).
",2. Background,[0],[0]
"Definition 3 (Low Rank Restricted Strong Concavity (RSC), Restricted Smoothness (RSM)).",2. Background,[0],[0]
A function ` : Rn⇥d !,2. Background,[0],[0]
"R is said to be restricted strong concave with parameter m
⌦
and restricted smooth with parameter M ⌦ if for all X,Y 2 ⌦ ⇢ Rn⇥d,
m⌦ 2 kY Xk2F",2. Background,[0],[0]
"`(Y) `(X) hr`(X),Y Xi
M⌦ 2 kY Xk2F .
",2. Background,[0],[0]
Remark 1.,2. Background,[0],[0]
"If a function `(·) has restricted strong concavity parameter m, then its negative `(·) has restricted strong convexity parameter m. We choose to use the nomenclature of concavity for ease of exposition in terms of relationship to submodular maximization.",2. Background,[0],[0]
"Further, note that we define RSC/RSM conditions on the space of matrices rather than vectors, on a domain ⌦ constrained by rank rather than sparsity.",2. Background,[0],[0]
"It is straightforward to see that if ⌦0 ✓ ⌦, then M
⌦ 0 M ⌦ and m ⌦ 0 m ⌦ .",2. Background,[0],[0]
"In this section, we delineate our setup of low rank estimation.",3. Setup,[0],[0]
"In order to connect to the weak submodular maximization framework more easily, we operate in the setting of maximization of a concave matrix variate function under a low rank constraint.",3. Setup,[0],[0]
This is equivalent to minimizing a convex matrix variate function under the low rank constraint as considered by Shalev-Shwartz et al. (2011) or under nuclear norm constraint or regularization as considered by Jaggi & Sulovský (2010).,3. Setup,[0],[0]
The goal is to maximize a function ` : Rn⇥d !,3. Setup,[0],[0]
"R:
max rank(X)r `(X).",3. Setup,[0],[0]
"(4)
Instead of using a convex relaxation of (4), our approach is to enforce the rank constraint directly by adding rank 1 matrices greedily until X is of",3. Setup,[0],[0]
rank k.,3. Setup,[0],[0]
The rank 1 matrices to be added are obtained as outer product of vectors from the given vector sets U and V .,3. Setup,[0],[0]
"While our results hold for general vector sets U ,V assuming an oracle access to subroutines GreedySel and OMPSel (to be detailed later), for the rest of the paper we focus on the case of norm 1 balls U := {x 2 Rn s.t. kxk
2 = 1} and V := {x 2 Rd s.t. kxk 2 = 1}.
",3. Setup,[0],[0]
The problem (4) can be interpreted in the context of sparsity assuming U and V are enumerable.,3. Setup,[0],[0]
"For example, by the SVD theorem, it is known that we can rewrite X",3. Setup,[0],[0]
"asPk
i=1",3. Setup,[0],[0]
↵iuiv >,3. Setup,[0],[0]
"i , where 8i, ui 2 U and vi 2 V .",3. Setup,[0],[0]
"By enumerating U and V under a finite precision representation of real values, one can rethink of the optimization (4) as finding a sparse solution for the infinite dimensional vector ↵ (Shalev-Shwartz et al., 2011; Dudik et al., 2012).",3. Setup,[0],[0]
"We can also optimize over support sets, similar to the classical setting of support selection for sparse vectors.",3. Setup,[0],[0]
"For a specified support set L consisting of vectors from U and V , let
UL and VL be the matrices formed by stacking the chosen elements of U and V respectively.",3. Setup,[0],[0]
"We define the following set function to maximize `(·) given L.
f(L) = max H2R|L|⇥|L|
`(U>L HVL) `(0).",3. Setup,[0],[0]
"(5)
We will denote the optimizing matrix for a support set L as B(L).",3. Setup,[0],[0]
"In other words, letting ˆHL be the argmax obtained in (5), then B(L)",3. Setup,[0],[0]
:= U>L ˆHLVL.,3. Setup,[0],[0]
"Thus, the low rank matrix estimation problem (4) can be reinterpreted as the following equivalent combinatorial optimization problem:
max |S|k f(S).",3. Setup,[0],[0]
(6),3. Setup,[0],[0]
"Our greedy algorithm, illustrated in Algorithm 1, builds the support set incrementally – adding rank 1 matrices one at a time such that at iteration i for 1  i  k the size of the chosen support set (and hence rank of the current iterate) is",3.1. Algorithms,[0],[0]
i. We assume access to a subroutine GreedySel for the greedy selection (Step 4).,3.1. Algorithms,[0],[0]
"This subroutine solves an inner optimization problem by calling a subroutine GreedySel which returns an atom s from the candidate support set that ensures
f(SGi 1 [ {s}) f(SGi 1) ⌧ f(SGi 1 [ {s?}) f(SGi 1) ,
where
s? argmax a2(U⇥V)?SGi 1 f(SGi 1",3.1. Algorithms,[0],[0]
"[ {a}) f(SGi 1).
",3.1. Algorithms,[0],[0]
"In words, the subroutine GreedySel ensures that the gain in f(·) obtained by using the selected atom is within ⌧ 2 (0, 1] multiplicative approximation to the atom with the best possible gain in f(·).",3.1. Algorithms,[0],[0]
"The hyperparameter ⌧ governs a tradeoff allowing a compromise in myopic gain for a possibly quicker selection.
",3.1. Algorithms,[0],[0]
"The greedy selection requires fitting and scoring every candidate support, which is often prohibitively expensive.",3.1. Algorithms,[0],[0]
"An alternative is to choose the next atom by using the linear maximization oracle used by Frank-Wolfe (Jaggi, 2013) or Matching Pursuit algorithms (Gribonval & Vandergheynst, 2006; Locatello et al., 2017).",3.1. Algorithms,[0],[0]
This step replaces Step 4 of Algorithm 1 as illustrated in Algorithm 2.,3.1. Algorithms,[0],[0]
Let L = SOi 1 be the set constructed by the algorithm at iteration (i 1).,3.1. Algorithms,[0],[0]
"The linear oracle OMPSel returns an atom s for iteration i ensuring
hr`(B(L)),usv>s i ⌧ max (u,v)2(U⇥V)?SOi 1 hr`(B(L)),uv>i.
",3.1. Algorithms,[0],[0]
The linear problem OMPSel can be considerably faster that GreedySel.,3.1. Algorithms,[0],[0]
"OMPSel reduces to finding the left and right
singular vectors of r`(B(L)) corresponding to its largest singular value.",3.1. Algorithms,[0],[0]
"If t is the number of non-zero entries in r`(B(L)), then this takes O( t
1 ⌧ (log n+ log d)) time.
",3.1. Algorithms,[0],[0]
We note that Algorithm 2 is the same as considered by Shalev-Shwartz et al. (2011) as GECO (Greedy Efficient Component Optimization).,3.1. Algorithms,[0],[0]
"However, as we shall see, our analysis provides stronger bounds than their Theorem 2.
",3.1. Algorithms,[0],[0]
"Algorithm 1 GREEDY(U , V , k, ⌧ ) 1: Input: vector sets U , V , sparsity parameter k, subrou-
tine hyperparameter ⌧ 2: SG
0 ; 3: for i = 1 . . .",3.1. Algorithms,[0],[0]
k do 4: s GreedySel(⌧) 5: SGi SGi 1,3.1. Algorithms,[0],[0]
"[ {s} 6: end for 7: return SGk , B(S G k ), f(SGk ).
",3.1. Algorithms,[0],[0]
"Algorithm 2 GECO(U , V , k, ⌧ ) same as Algorithm 1 except
4: s OMPSel(⌧)
Remark 2.",3.1. Algorithms,[0],[0]
We note that Step 5 of Algorithms 1 and 2 requires solving the RHS of (5) which is a matrix variate problem of size i2 at iteration i.,3.1. Algorithms,[0],[0]
"This refitting is equivalent to the “fully-corrective” versions of Frank-Wolfe/Matching Pursuit algorithms (Locatello et al., 2017; Lacoste-Julien & Jaggi, 2015) which, intuitively speaking, extract out all the information",3.1. Algorithms,[0],[0]
"w.r.t `(·) from the chosen set of atoms, thereby ensuring that the next rank 1 atom chosen has row and column space orthogonal to the previously chosen atoms.",3.1. Algorithms,[0],[0]
"Thus the constrained maximization on the orthogonal complement of SOi in subroutine OMPSel (SGi in GreedySel) need not be explicitly enforced, but is still shown for clarity.",3.1. Algorithms,[0],[0]
"In this section, we prove that low rank matrix optimization over the rank one atoms satisfies weak submodularity.",4. Analysis,[0],[0]
We explicitly delineate some notation and assumptions.,4. Analysis,[0],[0]
"With slight abuse of notation, we assume `(·) is mi-strongly concave and Mi-smooth over pairs of matrices of rank i.",4. Analysis,[0],[0]
"For i  j, note that mi mj and Mi Mj .",4. Analysis,[0],[0]
"Additionally, let ˜
⌦ := {(X,Y) :",4. Analysis,[0],[0]
"rank(X Y)  1}, and assume `(·) is ˜M 1 -smooth over ˜⌦.",4. Analysis,[0],[0]
"It is easy to see ˜M 1 M 1 .
",4. Analysis,[0],[0]
"First we prove that if the low rank RSC holds (Definition 3), then the submodularity ratio (Definition 2) is lower-bounded by the inverse condition number.",4. Analysis,[0],[0]
Theorem 2.,4. Analysis,[0],[0]
"Let L be a set of k rank 1 atoms and S be a set of r rank 1 atoms where we sequentially orthogonalize the atoms against L. If `(·) is mi-strongly con-
cave over matrices of rank i, and ˜M 1 -smooth over the set ˜
⌦ := {(X,Y) :",4. Analysis,[0],[0]
"rank(X Y) = 1}, then
L,r :=
P a2S",4. Analysis,[0],[0]
"[f(L [ {a}) f(L)]
f(L [ S) f(L) mr+k ˜M 1 .
",4. Analysis,[0],[0]
The proof of Theorem 2 is structured around individually obtaining a lower bound for the numerator and an upper bound for the denominator of the submodularity ratio by exploiting the concavity and convexity conditions.,4. Analysis,[0],[0]
Bounding the submodularity ratio is crucial to obtaining approximation guarantees for Algorithm 1.,4.1. Greedy Improvement,[0],[0]
Theorem 3.,4.1. Greedy Improvement,[0],[0]
"Let S := SGk be the greedy solution set obtained by running Algorithm 1 for k iterations, and let S? be an optimal support set of size r. Let `(·) be mi strongly concave on the set of matrices with rank less than or equal to i, and ˜M
1 smooth on the set of matrices in the set ˜⌦.",4.1. Greedy Improvement,[0],[0]
"Then,
f(S)",4.1. Greedy Improvement,[0],[0]
"✓ 1 1
ec1
◆ f(S?)",4.1. Greedy Improvement,[0],[0]
"✓ 1 1
ec2
◆ f(S?),
where c 1 = ⌧ S,r k r and c2 = ⌧ mr+k ˜M1 k r .
",4.1. Greedy Improvement,[0],[0]
The proof technique for the first inequality of Theorem 3 relies on lower bounding the progress made in each iteration of Algorithm 1.,4.1. Greedy Improvement,[0],[0]
"Intuitively, it exploits weak submodularity to make sure that each iteration makes enough progress, and then applies an induction argument for r iterations.",4.1. Greedy Improvement,[0],[0]
We also emphasize that the bounds in Theorem 3 are for normalized set function f(·) (which means f(;) = 0).,4.1. Greedy Improvement,[0],[0]
"A more detailed proof is presented in the appendix.
",4.1. Greedy Improvement,[0],[0]
"The bounds obtained in Theorem 3 are similar to the one obtained in submodular maximization of monotone normalized functions (Nemhauser et al., 1978).",4.1. Greedy Improvement,[0],[0]
"In fact, our result can be re-interpreted as an extension to previous results.",4.1. Greedy Improvement,[0],[0]
The greedy algorithm for submodular maximization assumes finite ground sets.,4.1. Greedy Improvement,[0],[0]
We extend this for infinite ground sets.,4.1. Greedy Improvement,[0],[0]
We can do this (for matrices) as long as we have an implementation of the oracle GreedySel.,4.1. Greedy Improvement,[0],[0]
"Once the choice is made by the oracle, standard analysis holds.",4.1. Greedy Improvement,[0],[0]
Remark 3.,4.1. Greedy Improvement,[0],[0]
Theorem 3 provides the approximation guarantees for running the greedy selection algorithm up to k iterations to obtain a rank k matrix iterate vis-a-vis the best rank r approximation.,4.1. Greedy Improvement,[0],[0]
"For r = k, and ⌧ = 1, we get an approximation bound (1 e m/M) which is reminiscent of the greedy bound of (1 1/e) under the framework of submodularity.",4.1. Greedy Improvement,[0],[0]
Note that our analysis can not be used to establish classical submodularity.,4.1. Greedy Improvement,[0],[0]
"However, establishing weak submodularity that lower bounds is sufficient to provide slightly weaker than classical submodularity guarantees.
",4.1. Greedy Improvement,[0],[0]
Remark 4.,4.1. Greedy Improvement,[0],[0]
"Theorem 3 implies that to obtain (1 ✏) approximation guarantee in the worst case, running Algorithm 1 for k = rMm⌧ log 1 ✏ ) = O(r log 1/✏) iterations suffices.",4.1. Greedy Improvement,[0],[0]
This is useful when the application allows a tradeoff: compromising on the low rank constraint a little to achieve tighter approximation guarantees.,4.1. Greedy Improvement,[0],[0]
Remark 5.,4.1. Greedy Improvement,[0],[0]
"Das & Kempe (2011) considered the special case of greedily maximizing R2 statistic for linear regression, which corresponds to classical sparsity in vectors.",4.1. Greedy Improvement,[0],[0]
"They also obtain a bound of (1 1/e ), where is the submodularity ratio for their respective setup.",4.1. Greedy Improvement,[0],[0]
This was generalized by Elenberg et al. (2016) to general concave functions under sparsity constraints.,4.1. Greedy Improvement,[0],[0]
"Our analysis is for the low rank constraint, as opposed to sparsity in vectors that was considered by them.",4.1. Greedy Improvement,[0],[0]
"In this section, we obtain approximation guarantees for Algorithm 2.",4.2. GECO Improvement,[0],[0]
"The greedy search over the infinitely many candidate atoms is infeasible, especially when ⌧ = 1.",4.2. GECO Improvement,[0],[0]
"Thus while Algorithm 1 establishes interesting theoretical connections with submodularity, it is not practical in general.",4.2. GECO Improvement,[0],[0]
"To obtain a tractable and practically useful algorithm, the greedy search is replaced by a Frank Wolfe or Matching Pursuit style linear optimization which can be easily implemented as finding the top singular vectors of the gradient at iteration i.",4.2. GECO Improvement,[0],[0]
"In this section, we show that despite the speedup, we lose very little in terms of approximation guarantees.",4.2. GECO Improvement,[0],[0]
"In fact, if the approximation factor ⌧ in OMPSel() is 1, we get the same bounds as those obtained for the greedy algorithm.",4.2. GECO Improvement,[0],[0]
Theorem 4.,4.2. GECO Improvement,[0],[0]
"Let S := SOk be the greedy solution set obtained using Algorithm 2 for k iterations, and let S? be the optimum size r support set.",4.2. GECO Improvement,[0],[0]
"Let `(·) be mr+k strongly concave on the set of matrices with rank less than or equal to (r + k), and ˜M
1 smooth on the set of matrices with rank in the set ˜⌦.",4.2. GECO Improvement,[0],[0]
"Then,
f(S) ✓ 1 1
ec3
◆ f(S?),
where c 3 = ⌧2mr+k ˜M1 k r .
",4.2. GECO Improvement,[0],[0]
The proof of Theorem 4 follows along the lines of Theorem 3.,4.2. GECO Improvement,[0],[0]
"The central idea is similar – to exploit the RSC conditions to make sure that each iteration makes sufficient progress, and then provide an induction argument for r iterations.",4.2. GECO Improvement,[0],[0]
"Unlike the greedy algorithm, however, using the submodularity ratio is no longer required.",4.2. GECO Improvement,[0],[0]
"Note that the bound obtained in Theorem 4 is similar to Theorem 3, except the exponent on the approximation factor ⌧ .",4.2. GECO Improvement,[0],[0]
Remark 6.,4.2. GECO Improvement,[0],[0]
"Our proof technique for Theorem 4 can be applied for classical sparsity to improve the bounds obtained by Elenberg et al. (2016) for OMP for support selection
under RSC, and by Das & Kempe (2011) for R2 statistic.",4.2. GECO Improvement,[0],[0]
"If ⌧ = 1, r = k, their bounds involve terms of the form O(m2/M2) in the exponent, as opposed to our bounds which only has m/M in the exponent.
",4.2. GECO Improvement,[0],[0]
Remark 7.,4.2. GECO Improvement,[0],[0]
"Similar to the greedy algorithm, to achieve a tighter approximation to best rank k solution, one can relax the low rank constraint a little by running the algorithm for r > k",4.2. GECO Improvement,[0],[0]
greedy iterations.,4.2. GECO Improvement,[0],[0]
"The result obtained by our Theorem 4 can be compared to the bound obtained by (ShalevShwartz et al., 2011)",4.2. GECO Improvement,[0],[0]
[Theorem 2] for the same algorithm.,4.2. GECO Improvement,[0],[0]
"For an ✏ multiplicative approximation, Theorem 4 implies we need r/k = O(log 1/✏).",4.2. GECO Improvement,[0],[0]
"On the other hand, Shalev-Shwartz et al. (2011) obtain an additive approximation bound with r/k = O(1/""), which is an exponential improvement.",4.2. GECO Improvement,[0],[0]
"While understanding approximation guarantees are useful, providing parameter recovery bounds can further help us understand the practical utility of greedy algorithms.",5. Recovery Guarantees,[0],[0]
"In this section, we present a general theorem that provides us with recovery bounds of the true underlying low rank structure.",5. Recovery Guarantees,[0],[0]
Theorem 5.,5. Recovery Guarantees,[0],[0]
"Suppose that an algorithm achieves the approximation guarantee:
f(Sk) Cr,kf(S?r),
where Sk is the set of size k at iteration k of the algorithm, S?r be the optimal solution for r-cardinality constrained maximization of f(·), and Cr,k be the corresponding approximation ratio guaranteed by the algorithm.",5. Recovery Guarantees,[0],[0]
"Recall that we represent by US,VS the matrices formed by stacking the vectors represented by the support set S chosen from U ,V respectively, s.t. |S| =",5. Recovery Guarantees,[0],[0]
r.,5. Recovery Guarantees,[0],[0]
"Then under mk+r RSC, with Br = U>S HVS for any H 2",5. Recovery Guarantees,[0],[0]
"Rr⇥r, we have
kB(Sk) Brk2F  4(k",5. Recovery Guarantees,[0],[0]
"+ r) kr`(Br)k2 2
m2k+r
+ 4(1",5. Recovery Guarantees,[0],[0]
"Cr,k) mk+r",5. Recovery Guarantees,[0],[0]
"[`(Br) `(0)]
Theorem 5 can be applied for Br = B(S ?",5. Recovery Guarantees,[0],[0]
"r), which is the argmax for maximizing `(·) under the low rank constraint.",5. Recovery Guarantees,[0],[0]
"It is general in the sense that it can be applied for getting recovery bounds from approximation guarantees for any algorithm, and hence is applicable for both Algorithms 1 and 2.
",5. Recovery Guarantees,[0],[0]
Statistical recovery guarantees can be obtained from Theorem 5 for specific choice of `(·) and statistical model.,5. Recovery Guarantees,[0],[0]
Consider the case of low rank matrix estimation from noisy linear measurements.,5. Recovery Guarantees,[0],[0]
Let Xi 2 Rm1⇥m2 for i 2,5. Recovery Guarantees,[0],[0]
"[n] be generated so that each entry of Xi is N (0, 1).",5. Recovery Guarantees,[0],[0]
"We observe yi = hXi,⇥?i",5. Recovery Guarantees,[0],[0]
"+ "", where ⇥?",5. Recovery Guarantees,[0],[0]
"is low rank, and say "" ⇠
N (0, 2).",5. Recovery Guarantees,[0],[0]
"Let N = m 1 m 2 , and let '(⇥) : Rm1⇥m2 !",5. Recovery Guarantees,[0],[0]
Rn be the linear operator so that ['(⇥),5. Recovery Guarantees,[0],[0]
"]i = hXi,⇥i.",5. Recovery Guarantees,[0],[0]
Our corresponding function is now `(⇥) = 1nky '(⇥),5. Recovery Guarantees,[0],[0]
"k 2 2
.",5. Recovery Guarantees,[0],[0]
"For this function, using arguments by Negahban et al. (2012), we know kr`(BS?r )",5. Recovery Guarantees,[0],[0]
"k2
2  logNn and `(B S?r )",5. Recovery Guarantees,[0],[0]
"`(0)  (r + 1)
with high probability.",5. Recovery Guarantees,[0],[0]
"It is also straightforward to apply their results to bound mk+r ⇣ 1
32 162(k+r) logNn ⌘
, and M
1  1, which gives explicit bounds as per Theorem 5 for Algorithms 1, 2 for the considered function and the design matrix.",5. Recovery Guarantees,[0],[0]
"In this section, we empirically evaluate the proposed algorithms.",6. Experiments,[0],[0]
"First, we test empirically the performance of GECO (Algorithm 2 with ⌧ = 1) for a clustering task.",6.1. Clustering under Stochastic Block Model,[0],[0]
We are provided with a graph with nodes and the respective edges between the nodes.,6.1. Clustering under Stochastic Block Model,[0],[0]
The observed graph is assumed to have been noisily generated from a true underlying clustering.,6.1. Clustering under Stochastic Block Model,[0],[0]
The goal is to recover the underlying clustering structure from the noisy graph provided to us.,6.1. Clustering under Stochastic Block Model,[0],[0]
Our greedy framework is applicable because the adjacency matrix of the true clustering is low rank.,6.1. Clustering under Stochastic Block Model,[0],[0]
We compare performance of Algorithm 2 on simulated data against standard baselines of spectral clustering which are commonly used for this task.,6.1. Clustering under Stochastic Block Model,[0],[0]
"We begin by describing a generative model for creating edges between nodes given the ground truth.
",6.1. Clustering under Stochastic Block Model,[0],[0]
The Stochastic Block Model is a model to generate random graphs.,6.1. Clustering under Stochastic Block Model,[0],[0]
"It takes its input the set of n nodes, and a partition of [n] which form a set of disjoint clusters, and returns the graph with nodes and the generated edges.",6.1. Clustering under Stochastic Block Model,[0],[0]
"The model has two additional parameters, the generative probabilities (p, q).",6.1. Clustering under Stochastic Block Model,[0],[0]
"A pair of nodes within the same cluster have an edge between them with probability p, while a pair of nodes belonging to different clusters have an edge between them with probability q.",6.1. Clustering under Stochastic Block Model,[0],[0]
For simplicity we assume q = (1 p).,6.1. Clustering under Stochastic Block Model,[0],[0]
The model then iterates over each pair of nodes.,6.1. Clustering under Stochastic Block Model,[0],[0]
"For each such pair that belongs to same cluster, it samples an edge as Bernoulli(p), otherwise as Bernoulli(1 p).",6.1. Clustering under Stochastic Block Model,[0],[0]
"This provides us with a {0, 1} adjacency matrix.
",6.1. Clustering under Stochastic Block Model,[0],[0]
"We compare against two versions of spectral clustering, which is a standard technique applied to find communities in a graph.",6.1. Clustering under Stochastic Block Model,[0],[0]
"The method takes as input the n⇥ n adjacency matrix A, which is a {0, 1} matrix with an entry Aij = 1 if there is an edge between node i and j, and is 0 otherwise.",6.1. Clustering under Stochastic Block Model,[0],[0]
"From the adjacency matrix, the graph Laplacian L is constructed.",6.1. Clustering under Stochastic Block Model,[0],[0]
"The Laplacian may be unnormalized, in which case it is simply L = D A, where D is the diagonal matrix of degrees of nodes.",6.1. Clustering under Stochastic Block Model,[0],[0]
"A normalized Laplacian is
computed as Lnorm = D 1/2LD 1/2.",6.1. Clustering under Stochastic Block Model,[0],[0]
"After calculating the Laplacian, the algorithm solves for bottom k eigenvectors of the Laplacian, and then apply k-means clustering on the rows of the thus obtained eigenvector matrix.",6.1. Clustering under Stochastic Block Model,[0],[0]
"We refer to the works of Shi & Malik (2000); Ng et al. (2001) for the specific details of clustering algorithms using unnormalized and normalized graph Laplacian respectively.
",6.1. Clustering under Stochastic Block Model,[0],[0]
"We use our greedy algorithm to cluster the graph by optimizing a logistic PCA objective function, which is a special case of the exponential family PCA (Collins et al., 2001).",6.1. Clustering under Stochastic Block Model,[0],[0]
"For a given matrix X, each entry Xij is assumed to be independently drawn with likelihood proportional to exp h⇥ij ,Xiji G(⇥ij), where ⇥ is the true underlying parameter, and G(·) is the partition function corresponding to a generalized linear model (GLM).",6.1. Clustering under Stochastic Block Model,[0],[0]
"It is easy to see we can apply our framework of greedy selection by defining `(·) as the log-likelihood:
`(⇥) =",6.1. Clustering under Stochastic Block Model,[0],[0]
"h⇥,Xi X
i,j
logG(⇥ij),
where ⇥ is the true parameter matrix of p and q that generates a realization of A. Since the true ⇥ is low rank, we get the low rank constrained optimization problem:
max rank(⇥)k `(⇥),
where k is a hyperparameter suggesting the true number of clusters.",6.1. Clustering under Stochastic Block Model,[0],[0]
"Note that lack of knowledge of true value of k is not more restrictive than spectral clustering algorithms which typically also require the true value of k. Having cast the clustering problem in the same form as (4), we can apply our greedy selection algorithm as opposed to the more costly alternating minimizing algorithms suggested by Collins et al. (2001).
",6.1. Clustering under Stochastic Block Model,[0],[0]
We generate the data as follows.,6.1. Clustering under Stochastic Block Model,[0],[0]
"For n = 100 nodes, and fixed number of cluster k = 5, we vary the within cluster edge generation probability p from 0.55 to 0.95 in increments of 0.05, and use the Stochastic Block model to generate a noisy graph with each p.",6.1. Clustering under Stochastic Block Model,[0],[0]
"Note that smaller p implies that the sampled graph will be more noisy and likely to be more different than the underlying clustering.
",6.1. Clustering under Stochastic Block Model,[0],[0]
"We compare against the spectral clustering algorithm using unnormalized Laplacian of Shi & Malik (2000) which we label “Spectral unnorm{k}” for k = {3, 5, 10}, and the spectral clustering algorithm using normalized Laplacian of Ng et al. (2001) which we label “Spectral norm{k}” for k = {3, 5, 10}.",6.1. Clustering under Stochastic Block Model,[0],[0]
"We use Algorithm 2 which we label “Greedy{k}” for k = {3, 5, 10}.",6.1. Clustering under Stochastic Block Model,[0],[0]
"For each of these models, the referred k is the supplied hyperparameter.",6.1. Clustering under Stochastic Block Model,[0],[0]
We report the least squares error of the output from each model to the true underlying ⇥,6.1. Clustering under Stochastic Block Model,[0],[0]
"(generalization error), and to the instantiation used for training X (reconstruction error).
",6.1. Clustering under Stochastic Block Model,[0],[0]
Figure 1 shows that the greedy logistic PCA performs well in not only recreating the given noisy matrix (reconstruction) but also captures the true low rank structure better (generalization).,6.1. Clustering under Stochastic Block Model,[0],[0]
"Further, note that providing the true hyperparameter k is vital for spectral clustering algorithms, while on the other hand greedy is less sensitive to k.",6.1. Clustering under Stochastic Block Model,[0],[0]
This is very useful in practice as k is typically not known.,6.1. Clustering under Stochastic Block Model,[0],[0]
Spectral clustering algorithms typically select k by computing an SVD and rerunning k-means for different values of k.,6.1. Clustering under Stochastic Block Model,[0],[0]
"In addition to being more robust, our greedy algorithm does not need to be rerun for different values of k – it produces solutions incrementally.",6.1. Clustering under Stochastic Block Model,[0],[0]
"Algorithms for embedding text into a vector space yield representations that can be quite beneficial in many applications, e.g. features for sentiment analysis.",6.2. Word Embeddings,[0],[0]
Mikolov et al. (2013b) proposed a context-based embedding called skipgram or word2vec.,6.2. Word Embeddings,[0],[0]
"The context of a word can be defined as a set of words before, around, or after the respective word.",6.2. Word Embeddings,[0],[0]
Their model strives to find an embedding of each word so that the representation predicts the embedding of each context word around it.,6.2. Word Embeddings,[0],[0]
Levy & Goldberg (2014) subsequently showed that the word embedding model proposed by Mikolov et al. (2013b) can be reinterpreted as matrix factorization of the PMI matrix constructed as follows.,6.2. Word Embeddings,[0],[0]
A word c is in context of w if it lies within the respective window of w.,6.2. Word Embeddings,[0],[0]
"The PMI matrix is then calculated as
PMIw,c = log ✓ p(w, c)
p(w)p(c)
◆ .
",6.2. Word Embeddings,[0],[0]
"In practice the probabilities p(w, c), p(w), p(c) are replaced by their empirical counterparts.",6.2. Word Embeddings,[0],[0]
"Further, note that p(w, c) is 0 if words c and w do not coexist in the same context, which yields 1 for PMI.",6.2. Word Embeddings,[0],[0]
"Levy & Goldberg (2014) suggest using an alternative: PPMIw,c = max{PMIw,c, 0}.",6.2. Word Embeddings,[0],[0]
"They also suggest variations of PMI hyper parameterized by k which corresponds to the number of negative samples in the training of the original skip gram model.
",6.2. Word Embeddings,[0],[0]
"We employ the binomial PCA model on the normalized count matrix (instead of the PMI), in a manner similar to the clustering approach in Section 6.1.",6.2. Word Embeddings,[0],[0]
"The normalized count matrix is calculated simply as p(w,c)p(w) , without taking logarithms.",6.2. Word Embeddings,[0],[0]
"This gives us a probability matrix which has each entry between 0 and 1, and which can be factorized under the binomial model greedily as per Algorithm 2.
",6.2. Word Embeddings,[0],[0]
We empirically study the embeddings obtained by binomial factorization on two tasks – word similarity and analogies.,6.2. Word Embeddings,[0],[0]
"For word similarity, we use the W353 dataset (Finkelstein et al., 2001) and the MEN data (Bruni et al., 2012).",6.2. Word Embeddings,[0],[0]
Both these datasets contain words with human assigned similarity scores.,6.2. Word Embeddings,[0],[0]
"We evaluate the embeddings by their cosine similarity, and measuring the correlation with the available human ratings.",6.2. Word Embeddings,[0],[0]
The fraction of correctly answered queries are returned as the metric.,6.2. Word Embeddings,[0],[0]
"For the analogy task, we use the Microsoft Research (MSR) syntactic analogies (Mikolov et al., 2013c) and the Google mixed analogies dataset (Mikolov et al., 2013a).",6.2. Word Embeddings,[0],[0]
"For completing analogy a:b::c:x, the prediction is calculated as argmaxx cos(c,x) cos(b,x) cos(a,x) .",6.2. Word Embeddings,[0],[0]
"To compute accuracy, we use the multiplication similarity metric as used by Levy & Goldberg (2014).",6.2. Word Embeddings,[0],[0]
"To train the word embeddings, we use the 2013 news crawl dataset1.",6.2. Word Embeddings,[0],[0]
"We filter out stop words, non-ASCII characters, and words occurring less than
1http://www.statmt.org/wmt14/ training-monolingual-news-crawl
2000 times (which yields a vocabulary of 6713).",6.2. Word Embeddings,[0],[0]
"Note that since we keep only the most common words, several queries from the datasets are invalid because we do not have embeddings for words appearing in them.",6.2. Word Embeddings,[0],[0]
"However, we do include them by assigning invalid queries a value of 0 and reporting the overall average over the entire dataset.
",6.2. Word Embeddings,[0],[0]
Table 1 shows the empirical evaluation.,6.2. Word Embeddings,[0],[0]
"SVD and PPMI are the models proposed by Levy & Goldberg (2014), while SGNS is the skipgram with negative sampling model of Mikolov et al. (2013b).",6.2. Word Embeddings,[0],[0]
"We run each of these for k = {5, 10, 15, 20} and report the best results.",6.2. Word Embeddings,[0],[0]
"This shows that alternative factorizations such as our application of binomial PCA can be more consistent and competitive with other embedding methods.
",6.2. Word Embeddings,[0],[0]
Conclusion: We have connected the problem of greedy low rank matrix estimation to that of submodular optimization.,6.2. Word Embeddings,[0],[0]
Through that connection we have provided improved exponential rates of convergence for the algorithm.,6.2. Word Embeddings,[0],[0]
An interesting area of future study will be to connect these ideas to general atoms or dictionary elements.,6.2. Word Embeddings,[0],[0]
We thank the anonymous reviewers for their helpful feedback.,Acknowledgements,[0],[0]
"Research supported by William Hartwig Fellowship, NSF Grants CCF 1344179, 1344364, 1407278, 1422549, 1618689, IIS 1421729, and ARO YIP W911NF-14-1-0258.",Acknowledgements,[0],[0]
We provide new approximation guarantees for greedy low rank matrix estimation under standard assumptions of restricted strong convexity and smoothness.,abstractText,[0],[0]
"Our novel analysis also uncovers previously unknown connections between the low rank estimation and combinatorial optimization, so much so that our bounds are reminiscent of corresponding approximation bounds in submodular maximization.",abstractText,[0],[0]
"Additionally, we also provide statistical recovery guarantees.",abstractText,[0],[0]
"Finally, we present empirical comparison of greedy estimation with established baselines on two important real-world problems.",abstractText,[0],[0]
On Approximation Guarantees for Greedy Low Rank Optimization,title,[0],[0]
"Recent advances in deep learning have dramatically improved neural network accuracy (Simonyan & Zisserman, 2015; Srivastava et al., 2015; He et al., 2016; Huang et al., 2016; 2017).",1. Introduction,[0],[0]
"As a result, neural networks are now entrusted with making complex decisions in applications, such as object detection (Girshick, 2015), speech recognition (Hannun et al., 2014), and medical diagnosis (Caruana et al., 2015).",1. Introduction,[0],[0]
"In these settings, neural networks are an essential component of larger decision making pipelines.
",1. Introduction,[0],[0]
"In real-world decision making systems, classification networks must not only be accurate, but also should indicate when they are likely to be incorrect.",1. Introduction,[0],[0]
"As an example, consider a self-driving car that uses a neural network to detect pedestrians and other obstructions (Bojarski et al., 2016).
",1. Introduction,[0],[0]
"*Equal contribution, alphabetical order.",1. Introduction,[0],[0]
1Cornell University.,1. Introduction,[0],[0]
"Correspondence to: Chuan Guo <cg563@cornell.edu>, Geoff Pleiss <geoff@cs.cornell.edu>, Yu Sun <ys646@cornell.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
0.0 0.2 0.4 0.6 0.8 1.0 0.0
0.2
0.4
0.6
0.8
1.0
% of
Sa m
pl es
A vg
.c on
fid en ce",1. Introduction,[0],[0]
"A cc ur ac y
LeNet (1998) CIFAR-100
0.0 0.2 0.4 0.6 0.8 1.0
A vg
.c on
fid en
ce
A cc
ur ac
y
ResNet (2016) CIFAR-100
0.0 0.2 0.4 0.6 0.8 1.0 0.0
0.2
0.4
0.6
0.8 1.0 A cc ur ac y
Error=44.9
Outputs Gap
0.0 0.2 0.4 0.6 0.8 1.0
Error=30.6
Outputs Gap
Confidence
Figure 1.",1. Introduction,[0],[0]
Confidence histograms (top) and reliability diagrams (bottom) for a 5-layer LeNet (left) and a 110-layer ResNet (right) on CIFAR-100.,1. Introduction,[0],[0]
"Refer to the text below for detailed illustration.
",1. Introduction,[0],[0]
"If the detection network is not able to confidently predict the presence or absence of immediate obstructions, the car should rely more on the output of other sensors for braking.",1. Introduction,[0],[0]
"Alternatively, in automated health care, control should be passed on to human doctors when the confidence of a disease diagnosis network is low (Jiang et al., 2012).",1. Introduction,[0],[0]
"Specifically, a network should provide a calibrated confidence measure in addition to its prediction.",1. Introduction,[0],[0]
"In other words, the probability associated with the predicted class label should reflect its ground truth correctness likelihood.
",1. Introduction,[0],[0]
Calibrated confidence estimates are also important for model interpretability.,1. Introduction,[0],[0]
"Humans have a natural cognitive intuition for probabilities (Cosmides & Tooby, 1996).",1. Introduction,[0],[0]
"Good confidence estimates provide a valuable extra bit of information to establish trustworthiness with the user – especially for neural networks, whose classification decisions are often difficult to interpret.",1. Introduction,[0],[0]
"Further, good probability estimates can be used to incorporate neural networks into other probabilistic models.",1. Introduction,[0],[0]
"For example, one can improve performance by combining network outputs with a lan-
guage model in speech recognition (Hannun et al., 2014; Xiong et al., 2016), or with camera information for object detection (Kendall & Cipolla, 2016).
",1. Introduction,[0],[0]
"In 2005, Niculescu-Mizil & Caruana (2005) showed that neural networks typically produce well-calibrated probabilities on binary classification tasks.",1. Introduction,[0],[0]
"While neural networks today are undoubtedly more accurate than they were a decade ago, we discover with great surprise that modern neural networks are no longer well-calibrated.",1. Introduction,[0],[0]
"This is visualized in Figure 1, which compares a 5-layer LeNet (left) (LeCun et al., 1998) with a 110-layer ResNet (right) (He et al., 2016) on the CIFAR-100 dataset.",1. Introduction,[0],[0]
The top row shows the distribution of prediction confidence (i.e. probabilities associated with the predicted label) as histograms.,1. Introduction,[0],[0]
"The average confidence of LeNet closely matches its accuracy, while the average confidence of the ResNet is substantially higher than its accuracy.",1. Introduction,[0],[0]
"This is further illustrated in the bottom row reliability diagrams (DeGroot & Fienberg, 1983; Niculescu-Mizil & Caruana, 2005), which show accuracy as a function of confidence.",1. Introduction,[0],[0]
"We see that LeNet is well-calibrated, as confidence closely approximates the expected accuracy (i.e. the bars align roughly along the diagonal).",1. Introduction,[0],[0]
"On the other hand, the ResNet’s accuracy is better, but does not match its confidence.
",1. Introduction,[0],[0]
"Our goal is not only to understand why neural networks have become miscalibrated, but also to identify what methods can alleviate this problem.",1. Introduction,[0],[0]
"In this paper, we demonstrate on several computer vision and NLP tasks that neural networks produce confidences that cannot represent true probabilities.",1. Introduction,[0],[0]
"Additionally, we offer insight and intuition into network training and architectural trends that may cause miscalibration.",1. Introduction,[0],[0]
"Finally, we compare various postprocessing calibration methods on state-of-the-art neural networks, and introduce several extensions of our own.",1. Introduction,[0],[0]
"Surprisingly, we find that a single-parameter variant of Platt scaling (Platt et al., 1999) – which we refer to as temperature scaling – is often the most effective method at obtaining calibrated probabilities.",1. Introduction,[0],[0]
"Because this method is straightforward to implement with existing deep learning frameworks, it can be easily adopted in practical settings.",1. Introduction,[0],[0]
The problem we address in this paper is supervised multiclass classification with neural networks.,2. Definitions,[0],[0]
The inputX ∈ X and label Y ∈,2. Definitions,[0],[0]
"Y = {1, . . .",2. Definitions,[0],[0]
",K} are random variables that follow a ground truth joint distribution π(X,Y ) = π(Y |X)π(X).",2. Definitions,[0],[0]
"Let h be a neural network with h(X) = (Ŷ , P̂ ), where Ŷ is a class prediction and P̂ is its associated confidence, i.e. probability of correctness.",2. Definitions,[0],[0]
"We would like the confidence estimate P̂ to be calibrated, which intuitively means that P̂ represents a true probability.",2. Definitions,[0],[0]
"For example, given 100 predictions, each with confidence of
0.8, we expect that 80 should be correctly classified.",2. Definitions,[0],[0]
"More formally, we define perfect calibration as
P ( Ŷ = Y | P̂ = p ) = p, ∀p ∈",2. Definitions,[0],[0]
"[0, 1] (1)
where the probability is over the joint distribution.",2. Definitions,[0],[0]
"In all practical settings, achieving perfect calibration is impossible.",2. Definitions,[0],[0]
"Additionally, the probability in (1) cannot be computed using finitely many samples since P̂ is a continuous random variable.",2. Definitions,[0],[0]
"This motivates the need for empirical approximations that capture the essence of (1).
",2. Definitions,[0],[0]
"Reliability Diagrams (e.g. Figure 1 bottom) are a visual representation of model calibration (DeGroot & Fienberg, 1983; Niculescu-Mizil & Caruana, 2005).",2. Definitions,[0],[0]
These diagrams plot expected sample accuracy as a function of confidence.,2. Definitions,[0],[0]
If the model is perfectly calibrated – i.e. if (1) holds – then the diagram should plot the identity function.,2. Definitions,[0],[0]
"Any deviation from a perfect diagonal represents miscalibration.
",2. Definitions,[0],[0]
"To estimate the expected accuracy from finite samples, we group predictions into M interval bins (each of size 1/M ) and calculate the accuracy of each bin.",2. Definitions,[0],[0]
Let Bm be the set of indices of samples whose prediction confidence falls into the interval,2. Definitions,[0],[0]
"Im = (m−1M , m M ].",2. Definitions,[0],[0]
"The accuracy of Bm is
acc(Bm) = 1 |Bm| ∑
i∈Bm 1(ŷi = yi),
where ŷi and yi are the predicted and true class labels for sample i. Basic probability tells us that acc(Bm) is an unbiased and consistent estimator of P(Ŷ = Y | P̂ ∈",2. Definitions,[0],[0]
Im).,2. Definitions,[0],[0]
"We define the average confidence within bin Bm as
conf(Bm) = 1 |Bm| ∑
i∈Bm p̂i,
where p̂i is the confidence for sample i. acc(Bm) and conf(Bm) approximate the left-hand and right-hand sides of (1) respectively for bin Bm.",2. Definitions,[0],[0]
"Therefore, a perfectly calibrated model will have acc(Bm) = conf(Bm) for all m ∈ {1, . . .",2. Definitions,[0],[0]
",M}.",2. Definitions,[0],[0]
"Note that reliability diagrams do not display the proportion of samples in a given bin, and thus cannot be used to estimate how many samples are calibrated.
",2. Definitions,[0],[0]
Expected Calibration Error (ECE).,2. Definitions,[0],[0]
"While reliability diagrams are useful visual tools, it is more convenient to have a scalar summary statistic of calibration.",2. Definitions,[0],[0]
"Since statistics comparing two distributions cannot be comprehensive, previous works have proposed variants, each with a unique emphasis.",2. Definitions,[0],[0]
"One notion of miscalibration is the difference in expectation between confidence and accuracy, i.e.
Ê P
[∣∣∣P ( Ŷ = Y | P̂ = p )",2. Definitions,[0],[0]
"− p ∣∣∣ ]
",2. Definitions,[0],[0]
"(2)
Expected Calibration Error (Naeini et al., 2015) – or ECE – approximates (2) by partitioning predictions into M equally-spaced bins (similar to the reliability diagrams) and
taking a weighted average of the bins’ accuracy/confidence difference.",2. Definitions,[0],[0]
"More precisely,
ECE = M∑
m=1
|Bm| n ∣∣∣∣ acc(Bm)− conf(Bm) ∣∣∣∣, (3)
where n is the number of samples.",2. Definitions,[0],[0]
The difference between acc and conf for a given bin represents the calibration gap (red bars in reliability diagrams – e.g. Figure 1).,2. Definitions,[0],[0]
We use ECE as the primary empirical metric to measure calibration.,2. Definitions,[0],[0]
"See Section S1 for more analysis of this metric.
",2. Definitions,[0],[0]
Maximum Calibration Error (MCE).,2. Definitions,[0],[0]
"In high-risk applications where reliable confidence measures are absolutely necessary, we may wish to minimize the worst-case deviation between confidence and accuracy:
max p∈[0,1]
∣∣∣P ( Ŷ = Y | P̂ = p )",2. Definitions,[0],[0]
− p ∣∣∣ .,2. Definitions,[0],[0]
"(4)
The Maximum Calibration Error (Naeini et al., 2015) – or MCE – estimates an upper bound of this deviation.",2. Definitions,[0],[0]
"Similarly to ECE, this approximation involves binning:
MCE = max m∈{1,...,M} |acc(Bm)− conf(Bm)| .",2. Definitions,[0],[0]
"(5)
In reliability diagrams, MCE measures the largest calibration gap (red bars) across all bins, whereas ECE measures a weighted average of all gaps.",2. Definitions,[0],[0]
"For perfectly calibrated classifiers, MCE and ECE both equal 0.
",2. Definitions,[0],[0]
"Negative log likelihood is a standard measure of a probabilistic model’s quality (Friedman et al., 2001).",2. Definitions,[0],[0]
"It is also referred to as the cross entropy loss in the context of deep learning (Bengio et al., 2015).",2. Definitions,[0],[0]
"Given a probabilistic model π̂(Y |X) and n samples, NLL is defined as:
L = − n∑
i=1
log(π̂(yi|xi))",2. Definitions,[0],[0]
"(6)
It is a standard result (Friedman et al., 2001) that, in expectation, NLL is minimized if and only if π̂(Y |X) recovers the ground truth conditional distribution π(Y |X).",2. Definitions,[0],[0]
The architecture and training procedures of neural networks have rapidly evolved in recent years.,3. Observing Miscalibration,[0],[0]
In this section we identify some recent changes that are responsible for the miscalibration phenomenon observed in Figure 1.,3. Observing Miscalibration,[0],[0]
"Though we cannot claim causality, we find that model capacity and lack of regularization are closely related to model (mis)calibration.
Model capacity.",3. Observing Miscalibration,[0],[0]
The model capacity of neural networks has increased at a dramatic pace over the past few years.,3. Observing Miscalibration,[0],[0]
"It is now common to see networks with hundreds, if not thousands of layers (He et al., 2016; Huang et al., 2016) and hundreds of convolutional filters per layer (Zagoruyko & Komodakis, 2016).",3. Observing Miscalibration,[0],[0]
"Recent work shows that very deep or wide models are able to generalize better than smaller ones, while exhibiting the capacity to easily fit the training set (Zhang et al., 2017).
",3. Observing Miscalibration,[0],[0]
"Although increasing depth and width may reduce classification error, we observe that these increases negatively affect model calibration.",3. Observing Miscalibration,[0],[0]
Figure 2 displays error and ECE as a function of depth and width on a ResNet trained on CIFAR-100.,3. Observing Miscalibration,[0],[0]
"The far left figure varies depth for a network with 64 convolutional filters per layer, while the middle left figure fixes the depth at 14 layers and varies the number of convolutional filters per layer.",3. Observing Miscalibration,[0],[0]
"Though even the smallest models in the graph exhibit some degree of miscalibration, the ECE metric grows substantially with model capacity.",3. Observing Miscalibration,[0],[0]
"During training, after the model is able to correctly classify (almost) all training samples, NLL can be further minimized by increasing the confidence of predictions.",3. Observing Miscalibration,[0],[0]
"Increased model capacity will lower training NLL, and thus the model will be more (over)confident on average.
",3. Observing Miscalibration,[0],[0]
"Batch Normalization (Ioffe & Szegedy, 2015) improves the optimization of neural networks by minimizing distribution shifts in activations within the neural network’s hid-
den layers.",3. Observing Miscalibration,[0],[0]
"Recent research suggests that these normalization techniques have enabled the development of very deep architectures, such as ResNets (He et al., 2016) and DenseNets (Huang et al., 2017).",3. Observing Miscalibration,[0],[0]
"It has been shown that Batch Normalization improves training time, reduces the need for additional regularization, and can in some cases improve the accuracy of networks.
",3. Observing Miscalibration,[0],[0]
"While it is difficult to pinpoint exactly how Batch Normalization affects the final predictions of a model, we do observe that models trained with Batch Normalization tend to be more miscalibrated.",3. Observing Miscalibration,[0],[0]
"In the middle right plot of Figure 2, we see that a 6-layer ConvNet obtains worse calibration when Batch Normalization is applied, even though classification accuracy improves slightly.",3. Observing Miscalibration,[0],[0]
"We find that this result holds regardless of the hyperparameters used on the Batch Normalization model (i.e. low or high learning rate, etc.).
",3. Observing Miscalibration,[0],[0]
"Weight decay, which used to be the predominant regularization mechanism for neural networks, is decreasingly utilized when training modern neural networks.",3. Observing Miscalibration,[0],[0]
"Learning theory suggests that regularization is necessary to prevent overfitting, especially as model capacity increases (Vapnik, 1998).",3. Observing Miscalibration,[0],[0]
"However, due to the apparent regularization effects of Batch Normalization, recent research seems to suggest that models with less L2 regularization tend to generalize better (Ioffe & Szegedy, 2015).",3. Observing Miscalibration,[0],[0]
"As a result, it is now common to train models with little weight decay, if any at all.",3. Observing Miscalibration,[0],[0]
"The top performing ImageNet models of 2015 all use an order of magnitude less weight decay than models of previous years (He et al., 2016; Simonyan & Zisserman, 2015).
",3. Observing Miscalibration,[0],[0]
We find that training with less weight decay has a negative impact on calibration.,3. Observing Miscalibration,[0],[0]
"The far right plot in Figure 2 dis-
plays training error and ECE for a 110-layer ResNet with varying amounts of weight decay.",3. Observing Miscalibration,[0],[0]
The only other forms of regularization are data augmentation and Batch Normalization.,3. Observing Miscalibration,[0],[0]
We observe that calibration and accuracy are not optimized by the same parameter setting.,3. Observing Miscalibration,[0],[0]
"While the model exhibits both over-regularization and under-regularization with respect to classification error, it does not appear that calibration is negatively impacted by having too much weight decay.",3. Observing Miscalibration,[0],[0]
"Model calibration continues to improve when more regularization is added, well after the point of achieving optimal accuracy.",3. Observing Miscalibration,[0],[0]
"The slight uptick at the end of the graph may be an artifact of using a weight decay factor that impedes optimization.
",3. Observing Miscalibration,[0],[0]
NLL can be used to indirectly measure model calibration.,3. Observing Miscalibration,[0],[0]
"In practice, we observe a disconnect between NLL and accuracy, which may explain the miscalibration in Figure 2.",3. Observing Miscalibration,[0.951073429897257],"['In this paper, we derived optimal convergence rates for strongly convex and smooth distributed optimization in two settings: centralized and decentralized communications in a network.']"
This disconnect occurs because neural networks can overfit to NLL without overfitting to the 0/1 loss.,3. Observing Miscalibration,[0],[0]
We observe this trend in the training curves of some miscalibrated models.,3. Observing Miscalibration,[0],[0]
Figure 3 shows test error and NLL (rescaled to match error) on CIFAR-100 as training progresses.,3. Observing Miscalibration,[0],[0]
"Both error and NLL immediately drop at epoch 250, when the learning rate is dropped; however, NLL overfits during the remainder of training.",3. Observing Miscalibration,[0],[0]
"Surprisingly, overfitting to NLL is beneficial to classification accuracy.",3. Observing Miscalibration,[0],[0]
"On CIFAR-100, test error drops from 29% to 27% in the region where NLL overfits.",3. Observing Miscalibration,[0],[0]
"This phenomenon renders a concrete explanation of miscalibration: the network learns better classification accuracy at the expense of well-modeled probabilities.
",3. Observing Miscalibration,[0],[0]
We can connect this finding to recent work examining the generalization of large neural networks.,3. Observing Miscalibration,[0],[0]
Zhang et al. (2017) observe that deep neural networks seemingly violate the common understanding of learning theory that large models with little regularization will not generalize well.,3. Observing Miscalibration,[0],[0]
"The observed disconnect between NLL and 0/1 loss suggests that these high capacity models are not necessarily immune from overfitting, but rather, overfitting manifests in probabilistic error rather than classification error.",3. Observing Miscalibration,[0],[0]
"In this section, we first review existing calibration methods, and introduce new variants of our own.",4. Calibration Methods,[0],[0]
All methods are post-processing steps that produce (calibrated) probabilities.,4. Calibration Methods,[0],[0]
"Each method requires a hold-out validation set, which in practice can be the same set used for hyperparameter tuning.",4. Calibration Methods,[0],[0]
"We assume that the training, validation, and test sets are drawn from the same distribution.",4. Calibration Methods,[0],[0]
"We first introduce calibration in the binary setting, i.e. Y = {0, 1}.",4.1. Calibrating Binary Models,[0],[0]
"For simplicity, throughout this subsection,
we assume the model outputs only the confidence for the positive class.1",4.1. Calibrating Binary Models,[0],[0]
"Given a sample xi, we have access to p̂i – the network’s predicted probability of yi = 1, as well as zi ∈ R – which is the network’s non-probabilistic output, or logit.",4.1. Calibrating Binary Models,[0],[0]
The predicted probability p̂i is derived from zi using a sigmoid function σ; i.e. p̂i = σ(zi).,4.1. Calibrating Binary Models,[0],[0]
"Our goal is to produce a calibrated probability q̂i based on yi, p̂i, and zi.
Histogram binning (Zadrozny & Elkan, 2001) is a simple non-parametric calibration method.",4.1. Calibrating Binary Models,[0],[0]
"In a nutshell, all uncalibrated predictions p̂i are divided into mutually exclusive bins B1, . . .",4.1. Calibrating Binary Models,[0],[0]
", BM .",4.1. Calibrating Binary Models,[0],[0]
"Each bin is assigned a calibrated score θm; i.e. if p̂i is assigned to bin Bm, then q̂i = θm.",4.1. Calibrating Binary Models,[0],[0]
"At test time, if prediction p̂te falls into bin Bm, then the calibrated prediction q̂te is θm.",4.1. Calibrating Binary Models,[0],[0]
"More precisely, for a suitably chosen M (usually small), we first define bin boundaries 0 =",4.1. Calibrating Binary Models,[0],[0]
a1 ≤ a2 ≤ . . .,4.1. Calibrating Binary Models,[0],[0]
≤,4.1. Calibrating Binary Models,[0],[0]
aM+1,4.1. Calibrating Binary Models,[0],[0]
"= 1, where the bin Bm is defined by the interval (am, am+1].",4.1. Calibrating Binary Models,[0],[0]
Typically the bin boundaries are either chosen to be equal length intervals or to equalize the number of samples in each bin.,4.1. Calibrating Binary Models,[0],[0]
"The predictions θi are chosen to minimize the bin-wise squared loss:
min θ1,...,θM
M∑
m=1
n∑
i=1
1(am ≤",4.1. Calibrating Binary Models,[0],[0]
"p̂i < am+1) (θm − yi)2 , (7)
where 1 is the indicator function.",4.1. Calibrating Binary Models,[0],[0]
"Given fixed bins boundaries, the solution to (7) results in θm that correspond to the average number of positive-class samples in bin Bm.
",4.1. Calibrating Binary Models,[0],[0]
"Isotonic regression (Zadrozny & Elkan, 2002), arguably the most common non-parametric calibration method, learns a piecewise constant function f to transform uncalibrated outputs; i.e. q̂i = f(p̂i).",4.1. Calibrating Binary Models,[0],[0]
"Specifically, isotonic regression produces f to minimize the square loss∑n i=1(f(p̂i)",4.1. Calibrating Binary Models,[0],[0]
− yi)2.,4.1. Calibrating Binary Models,[0],[0]
"Because f is constrained to be piecewise constant, we can write the optimization problem as:
min M
θ1,...,θM a1,...,aM+1
M∑
m=1
n∑
i=1
1(am ≤ p̂i < am+1) (θm − yi)2
subject to 0 = a1 ≤ a2 ≤ . . .",4.1. Calibrating Binary Models,[0],[0]
≤,4.1. Calibrating Binary Models,[0],[0]
aM+1,4.1. Calibrating Binary Models,[0],[0]
"= 1, θ1 ≤ θ2 ≤ . . .",4.1. Calibrating Binary Models,[0],[0]
"≤ θM .
",4.1. Calibrating Binary Models,[0],[0]
"where M is the number of intervals; a1, . . .",4.1. Calibrating Binary Models,[0],[0]
", aM+1 are the interval boundaries; and θ1, . . .",4.1. Calibrating Binary Models,[0],[0]
", θM are the function values.",4.1. Calibrating Binary Models,[0],[0]
"Under this parameterization, isotonic regression is a strict generalization of histogram binning in which the bin boundaries and bin predictions are jointly optimized.
",4.1. Calibrating Binary Models,[0],[0]
"Bayesian Binning into Quantiles (BBQ) (Naeini et al., 2015) is a extension of histogram binning using Bayesian
1 This is in contrast with the setting in Section 2, in which the model produces both a class prediction and confidence.
model averaging.",4.1. Calibrating Binary Models,[0],[0]
"Essentially, BBQ marginalizes out all possible binning schemes to produce q̂i.",4.1. Calibrating Binary Models,[0],[0]
"More formally, a binning scheme s is a pair (M, I) where M is the number of bins, and I is a corresponding partitioning of [0, 1] into disjoint intervals (0 = a1 ≤ a2 ≤ . . .",4.1. Calibrating Binary Models,[0],[0]
≤,4.1. Calibrating Binary Models,[0],[0]
aM+1 = 1).,4.1. Calibrating Binary Models,[0],[0]
"The parameters of a binning scheme are θ1, . . .",4.1. Calibrating Binary Models,[0],[0]
", θM .",4.1. Calibrating Binary Models,[0],[0]
"Under this framework, histogram binning and isotonic regression both produce a single binning scheme, whereas BBQ considers a space S of all possible binning schemes for the validation dataset D. BBQ performs Bayesian averaging of the probabilities produced by each scheme:2
P(q̂te",4.1. Calibrating Binary Models,[0],[0]
"| p̂te, D) = ∑
s∈S P(q̂te, S = s | p̂te, D)
= ∑
s∈S P(q̂te",4.1. Calibrating Binary Models,[0],[0]
"| p̂te, S=s,D)P(S=s | D).
",4.1. Calibrating Binary Models,[0],[0]
"where P(q̂te | p̂te, S = s,D) is the calibrated probability using binning scheme s. Using a uniform prior, the weight P(S=s | D) can be derived using Bayes’ rule:
P(S=s | D) =",4.1. Calibrating Binary Models,[0],[0]
P(D,4.1. Calibrating Binary Models,[0],[0]
"| S=s)∑ s′∈S P(D | S=s′) .
",4.1. Calibrating Binary Models,[0],[0]
"The parameters θ1, . . .",4.1. Calibrating Binary Models,[0],[0]
", θM can be viewed as parameters of M independent binomial distributions.",4.1. Calibrating Binary Models,[0],[0]
"Hence, by placing a Beta prior on θ1, . . .",4.1. Calibrating Binary Models,[0],[0]
", θM , we can obtain a closed form expression for the marginal likelihood",4.1. Calibrating Binary Models,[0],[0]
P(D | S= s).,4.1. Calibrating Binary Models,[0],[0]
This allows us to compute P(q̂te,4.1. Calibrating Binary Models,[0],[0]
"| p̂te, D) for any test input.
",4.1. Calibrating Binary Models,[0],[0]
"Platt scaling (Platt et al., 1999) is a parametric approach to calibration, unlike the other approaches.",4.1. Calibrating Binary Models,[0],[0]
"The nonprobabilistic predictions of a classifier are used as features for a logistic regression model, which is trained on the validation set to return probabilities.",4.1. Calibrating Binary Models,[0],[0]
"More specifically, in the context of neural networks (Niculescu-Mizil & Caruana, 2005), Platt scaling learns scalar parameters a, b ∈ R and outputs q̂i = σ(azi + b) as the calibrated probability.",4.1. Calibrating Binary Models,[0],[0]
Parameters a and b can be optimized using the NLL loss over the validation set.,4.1. Calibrating Binary Models,[0],[0]
It is important to note that the neural network’s parameters are fixed during this stage.,4.1. Calibrating Binary Models,[0],[0]
"For classification problems involving K > 2 classes, we return to the original problem formulation.",4.2. Extension to Multiclass Models,[0],[0]
The network outputs a class prediction ŷi and confidence score p̂i for each input xi.,4.2. Extension to Multiclass Models,[0],[0]
"In this case, the network logits zi are vectors, where ŷi = argmaxk z",4.2. Extension to Multiclass Models,[0],[0]
"(k) i , and p̂i is typically derived using the softmax function σSM:
σSM(zi) (k) =",4.2. Extension to Multiclass Models,[0],[0]
exp(z (k) i ),4.2. Extension to Multiclass Models,[0],[0]
"∑K
j=1 exp(z (j) i )
, p̂i = max k
σSM(zi) (k).
",4.2. Extension to Multiclass Models,[0],[0]
"The goal is to produce a calibrated confidence q̂i and (possibly new) class prediction ŷ′i based on yi, ŷi, p̂i, and zi.
2 Because the validation dataset is finite, S is as well.
",4.2. Extension to Multiclass Models,[0],[0]
Extension of binning methods.,4.2. Extension to Multiclass Models,[0],[0]
"One common way of extending binary calibration methods to the multiclass setting is by treating the problem as K one-versus-all problems (Zadrozny & Elkan, 2002).",4.2. Extension to Multiclass Models,[0],[0]
"For k = 1, . . .",4.2. Extension to Multiclass Models,[0],[0]
",K, we form a binary calibration problem where the label is 1(yi = k) and the predicted probability is σSM(zi)(k).",4.2. Extension to Multiclass Models,[0],[0]
"This gives us K calibration models, each for a particular class.",4.2. Extension to Multiclass Models,[0],[0]
"At test time, we obtain an unnormalized probability vector [q̂
(1) i , . . .",4.2. Extension to Multiclass Models,[0],[0]
", q̂ (K) i ], where q̂ (k) i is the calibrated probability for class k.",4.2. Extension to Multiclass Models,[0],[0]
"The new class prediction ŷ′i is the argmax of the vector, and the new confidence q̂′i is the max of the vector normalized by ∑K k=1 q̂ (k) i .",4.2. Extension to Multiclass Models,[0],[0]
"This extension can be applied to histogram binning, isotonic regression, and BBQ.
",4.2. Extension to Multiclass Models,[0],[0]
Matrix and vector scaling are two multi-class extensions of Platt scaling.,4.2. Extension to Multiclass Models,[0],[0]
Let zi be the logits vector produced before the softmax layer for input xi.,4.2. Extension to Multiclass Models,[0],[0]
"Matrix scaling applies a linear transformation Wzi + b to the logits:
q̂i = max k
σSM(Wzi + b) (k),
ŷ′i = argmax k",4.2. Extension to Multiclass Models,[0],[0]
"(Wzi + b) (k).
",4.2. Extension to Multiclass Models,[0],[0]
"(8)
The parameters W and b are optimized with respect to NLL on the validation set.",4.2. Extension to Multiclass Models,[0],[0]
"As the number of parameters for matrix scaling grows quadratically with the number of classes K, we define vector scaling as a variant where W is restricted to be a diagonal matrix.
",4.2. Extension to Multiclass Models,[0],[0]
"Temperature scaling, the simplest extension of Platt scaling, uses a single scalar parameter T > 0",4.2. Extension to Multiclass Models,[0],[0]
for all classes.,4.2. Extension to Multiclass Models,[0],[0]
"Given the logit vector zi, the new confidence prediction is
q̂i = max k
σSM(zi/T ) (k).",4.2. Extension to Multiclass Models,[0],[0]
"(9)
T is called the temperature, and it “softens” the softmax (i.e. raises the output entropy) with T > 1.",4.2. Extension to Multiclass Models,[0],[0]
"As T → ∞, the probability q̂i approaches 1/K, which represents maximum uncertainty.",4.2. Extension to Multiclass Models,[0],[0]
"With T = 1, we recover the original probability p̂i.",4.2. Extension to Multiclass Models,[0],[0]
"As T → 0, the probability collapses to a point mass (i.e. q̂i = 1).",4.2. Extension to Multiclass Models,[0],[0]
T is optimized with respect to NLL on the validation set.,4.2. Extension to Multiclass Models,[0],[0]
"Because the parameter T does not change the maximum of the softmax function, the class prediction ŷ′i remains unchanged.",4.2. Extension to Multiclass Models,[0],[0]
"In other words, temperature scaling does not affect the model’s accuracy.
",4.2. Extension to Multiclass Models,[0],[0]
"Temperature scaling is commonly used in settings such as knowledge distillation (Hinton et al., 2015) and statistical mechanics (Jaynes, 1957).",4.2. Extension to Multiclass Models,[0],[0]
"To the best of our knowledge, we are not aware of any prior use in the context of calibrating",4.2. Extension to Multiclass Models,[0],[0]
probabilistic models.3 The model is equivalent to maximizing the entropy of the output probability distribution subject to certain constraints on the logits (see Section S2).,4.2. Extension to Multiclass Models,[0],[0]
Calibration and confidence scores have been studied in various contexts in recent years.,4.3. Other Related Works,[0],[0]
"Kuleshov & Ermon (2016) study the problem of calibration in the online setting, where the inputs can come from a potentially adversarial source.",4.3. Other Related Works,[0],[0]
Kuleshov & Liang (2015) investigate how to produce calibrated probabilities when the output space is a structured object.,4.3. Other Related Works,[0],[0]
Lakshminarayanan et al. (2016) use ensembles of networks to obtain uncertainty estimates.,4.3. Other Related Works,[0],[0]
Pereyra et al. (2017) penalize overconfident predictions as a form of regularization.,4.3. Other Related Works,[0],[0]
"Hendrycks & Gimpel (2017) use confidence
3To highlight the connection with prior works we define temperature scaling in terms of 1
T instead of a multiplicative scalar.
scores to determine if samples are out-of-distribution.
",4.3. Other Related Works,[0],[0]
"Bayesian neural networks (Denker & Lecun, 1990; MacKay, 1992) return a probability distribution over outputs as an alternative way to represent model uncertainty.",4.3. Other Related Works,[0],[0]
"Gal & Ghahramani (2016) draw a connection between Dropout (Srivastava et al., 2014) and model uncertainty, claiming that sampling models with dropped nodes is a way to estimate the probability distribution over all possible models for a given sample.",4.3. Other Related Works,[0],[0]
Kendall & Gal (2017) combine this approach with a model that outputs a predictive mean and variance for each data point.,4.3. Other Related Works,[0],[0]
This notion of uncertainty is not restricted to classification problems.,4.3. Other Related Works,[0],[0]
"In contrast, our framework, which does not require model sampling, returns a confidence for a given output rather than returning a distribution of possible outputs.",4.3. Other Related Works,[0],[0]
We apply the calibration methods in Section 4 to image classification and document classification neural networks.,5. Results,[0],[0]
"For image classification we use 6 datasets:
1.",5. Results,[0],[0]
"Caltech-UCSD Birds (Welinder et al., 2010): 200 bird species.",5. Results,[0],[0]
5994/2897/2897 images for train/validation/test sets.,5. Results,[0],[0]
2.,5. Results,[0],[0]
"Stanford Cars (Krause et al., 2013): 196 classes of cars by make, model, and year.",5. Results,[0],[0]
8041/4020/4020 images for train/validation/test.,5. Results,[0],[0]
"3. ImageNet 2012 (Deng et al., 2009): Natural scene images from 1000 classes.",5. Results,[0],[0]
"1.3 million/25,000/25,000 images for train/validation/test.",5. Results,[0],[0]
"4. CIFAR-10/CIFAR-100 (Krizhevsky & Hinton, 2009):",5. Results,[0],[0]
Color images (32 × 32) from 10/100 classes.,5. Results,[0],[0]
"45,000/5,000/10,000 images for train/validation/test.",5. Results,[0],[0]
5.,5. Results,[0],[0]
"Street View House Numbers (SVHN) (Netzer et al., 2011): 32 × 32 colored images of cropped out house numbers from Google Street View.",5. Results,[0],[0]
"604,388/6,000/26,032 images for train/validation/test.
",5. Results,[0],[0]
We train state-of-the-art convolutional networks:,5. Results,[0],[0]
"ResNets (He et al., 2016), ResNets with stochastic depth (SD) (Huang et al., 2016), Wide ResNets (Zagoruyko & Komodakis, 2016), and DenseNets (Huang et al., 2017).",5. Results,[0],[0]
"We use the data preprocessing, training procedures, and hyperparameters as described in each paper.",5. Results,[0],[0]
"For Birds and Cars, we fine-tune networks pretrained on ImageNet.
",5. Results,[0],[0]
"For document classification we experiment with 4 datasets:
1.",5. Results,[0],[0]
"20 News: News articles, partitioned into 20 categories by content.",5. Results,[0],[0]
9034/2259/7528 documents for train/validation/test.,5. Results,[0],[0]
2.,5. Results,[0],[0]
"Reuters: News articles, partitioned into 8 categories by topic.",5. Results,[0],[0]
"4388/1097/2189 documents for train/validation/test.
3.",5. Results,[0],[0]
"Stanford Sentiment Treebank (SST) (Socher et al., 2013): Movie reviews, represented as sentence parse trees that are annotated by sentiment.",5. Results,[0],[0]
Each sample includes a coarse binary label and a fine grained 5-class label.,5. Results,[0],[0]
"As described in (Tai et al., 2015), the training/validation/test sets contain 6920/872/1821 documents for binary, and 544/1101/2210 for fine-grained.
",5. Results,[0],[0]
"On 20 News and Reuters, we train Deep Averaging Networks (DANs)",5. Results,[0],[0]
"(Iyyer et al., 2015) with 3 feed-forward layers and Batch Normalization.",5. Results,[0],[0]
These networks obtain competitive accuracy using the optimization hyperparameters suggested by the original paper.,5. Results,[0],[0]
"On SST, we train TreeLSTMs",5. Results,[0],[0]
"(Long Short Term Memory) (Tai et al., 2015) using the default settings in the authors’ code.
",5. Results,[0],[0]
Calibration Results.,5. Results,[0],[0]
"Table 1 displays model calibration, as measured by ECE (with M = 15 bins), before and after applying the various methods (see Section S3 for MCE, NLL, and error tables).",5. Results,[0],[0]
"It is worth noting that most datasets and models experience some degree of miscalibration, with ECE typically between 4 to 10%.",5. Results,[0],[0]
"This is not architecture specific: we observe miscalibration on convolutional networks (with and without skip connections), recurrent networks, and deep averaging networks.",5. Results,[0],[0]
"The two notable exceptions are SVHN and Reuters, both of which experience ECE values below 1%.",5. Results,[0],[0]
"Both of these datasets have very low error (1.98% and 2.97%, respectively); and therefore the ratio of ECE to error is comparable to other datasets.
",5. Results,[0],[0]
Our most important discovery is the surprising effectiveness of temperature scaling despite its remarkable simplicity.,5. Results,[0],[0]
"Temperature scaling outperforms all other methods on the vision tasks, and performs comparably to other methods on the NLP datasets.",5. Results,[0],[0]
"What is perhaps even more surprising is that temperature scaling outperforms the vector and matrix Platt scaling variants, which are strictly more general methods.",5. Results,[0],[0]
"In fact, vector scaling recovers essentially the same solution as temperature scaling – the learned vector has nearly constant entries, and therefore is no different than a scalar transformation.",5. Results,[0],[0]
"In other words, network miscalibration is intrinsically low dimensional.
",5. Results,[0],[0]
The only dataset that temperature scaling does not calibrate is the Reuters dataset.,5. Results,[0],[0]
"In this instance, only one of the above methods is able to improve calibration.",5. Results,[0],[0]
"Because this dataset is well-calibrated to begin with (ECE ≤ 1%), there is not much room for improvement with any method, and post-processing may not even be necessary to begin with.",5. Results,[0],[0]
"It is also possible that our measurements are affected by dataset split or by the particular binning scheme.
",5. Results,[0],[0]
"Matrix scaling performs poorly on datasets with hundreds of classes (i.e. Birds, Cars, and CIFAR-100), and fails to converge on the 1000-class ImageNet dataset.",5. Results,[0],[0]
"This is expected, since the number of parameters scales quadrat-
ically with the number of classes.",5. Results,[0],[0]
"Any calibration model with tens of thousands (or more) parameters will overfit to a small validation set, even when applying regularization.
",5. Results,[0],[0]
"Binning methods improve calibration on most datasets, but do not outperform temperature scaling.",5. Results,[0],[0]
"Additionally, binning methods tend to change class predictions which hurts accuracy (see Section S3).",5. Results,[0],[0]
"Histogram binning, the simplest binning method, typically outperforms isotonic regression and BBQ, despite the fact that both methods are strictly more general.",5. Results,[0],[0]
"This further supports our finding that calibration is best corrected by simple models.
",5. Results,[0],[0]
Reliability diagrams.,5. Results,[0],[0]
Figure 4 contains reliability diagrams for 110-layer ResNets on CIFAR-100 before and after calibration.,5. Results,[0],[0]
"From the far left diagram, we see that the uncalibrated ResNet tends to be overconfident in its predictions.",5. Results,[0],[0]
"We then can observe the effects of temperature scaling (middle left), histogram binning (middle right), and isotonic regression (far right) on calibration.",5. Results,[0],[0]
All three displayed methods produce much better confidence estimates.,5. Results,[0],[0]
"Of the three methods, temperature scaling most closely recovers the desired diagonal function.",5. Results,[0],[0]
"Each of the bins are well calibrated, which is remarkable given that all the probabilities were modified by only a single parameter.",5. Results,[0],[0]
"We include reliability diagrams for other datasets in Section S4.
",5. Results,[0],[0]
Computation time.,5. Results,[0],[0]
All methods scale linearly with the number of validation set samples.,5. Results,[0],[0]
"Temperature scaling is by far the fastest method, as it amounts to a onedimensional convex optimization problem.",5. Results,[0],[0]
"Using a conjugate gradient solver, the optimal temperature can be found in 10 iterations, or a fraction of a second on most modern hardware.",5. Results,[0],[0]
"In fact, even a naive line-search for the optimal temperature is faster than any of the other methods.",5. Results,[0],[0]
"The computational complexity of vector and matrix scaling are linear and quadratic respectively in the number of classes, reflecting the number of parameters in each method.",5. Results,[0],[0]
"For CIFAR-100 (K = 100), finding a near-optimal vector scal-
ing solution with conjugate gradient descent requires at least 2 orders of magnitude more time.",5. Results,[0],[0]
"Histogram binning and isotonic regression take an order of magnitude longer than temperature scaling, and BBQ takes roughly 3 orders of magnitude more time.
",5. Results,[0],[0]
Ease of implementation.,5. Results,[0],[0]
"BBQ is arguably the most difficult to implement, as it requires implementing a model averaging scheme.",5. Results,[0],[0]
"While all other methods are relatively easy to implement, temperature scaling may arguably be the most straightforward to incorporate into a neural network pipeline.",5. Results,[0],[0]
"In Torch7 (Collobert et al., 2011), for example, we implement temperature scaling by inserting a nn.MulConstant between the logits and the softmax, whose parameter is 1/T .",5. Results,[0],[0]
"We set T =1 during training, and subsequently find its optimal value on the validation set.",5. Results,[0],[0]
Modern neural networks exhibit a strange phenomenon: probabilistic error and miscalibration worsen even as classification error is reduced.,6. Conclusion,[0],[0]
"We have demonstrated that recent advances in neural network architecture and training – model capacity, normalization, and regularization – have strong effects on network calibration.",6. Conclusion,[0],[0]
It remains future work to understand why these trends affect calibration while improving accuracy.,6. Conclusion,[0],[0]
"Nevertheless, simple techniques can effectively remedy the miscalibration phenomenon in neural networks.",6. Conclusion,[0],[0]
"Temperature scaling is the simplest, fastest, and most straightforward of the methods, and surprisingly is often the most effective.",6. Conclusion,[0],[0]
"The authors are supported in part by the III-1618134, III1526012, and IIS-1149882 grants from the National Science Foundation, as well as the Bill and Melinda Gates Foundation and the Office of Naval Research.",Acknowledgments,[0],[0]
Confidence calibration – the problem of predicting probability estimates representative of the true correctness likelihood – is important for classification models in many applications.,abstractText,[0],[0]
"We discover that modern neural networks, unlike those from a decade ago, are poorly calibrated.",abstractText,[0],[0]
"Through extensive experiments, we observe that depth, width, weight decay, and Batch Normalization are important factors influencing calibration.",abstractText,[0],[0]
We evaluate the performance of various post-processing calibration methods on state-ofthe-art architectures with image and document classification datasets.,abstractText,[0],[0]
"Our analysis and experiments not only offer insights into neural network learning, but also provide a simple and straightforward recipe for practical settings: on most datasets, temperature scaling – a singleparameter variant of Platt Scaling – is surprisingly effective at calibrating predictions.",abstractText,[0],[0]
On Calibration of Modern Neural Networks,title,[0],[0]
"In this paper, we consider a variant of the problem of dictionary learning, a widely used unsupervised technique for learning compact (sparse) representations of high dimensional data.",1.1. Motivation,[0],[0]
"At its core, the challenge in dictionary learning is to discover a basis (or dictionary) that can sparsely represent a given set of data samples with as little empirical representation error as possible.",1.1. Motivation,[0],[0]
"The study of sparse coding enjoys a rich history in image processing, machine learning, and compressive sensing (Elad & Aharon, 2006; Aharon et al., 2006; Olshausen & Field, 1997; Candes & Tao, 2005; Rubinstein et al., 2010; Gregor & LeCun, 2010; Boureau et al., 2010).",1.1. Motivation,[0],[0]
"While the majority of these aforementioned works involved heuristics, several exciting re-
1Iowa State University 2Yahoo!",1.1. Motivation,[0],[0]
Research.,1.1. Motivation,[0],[0]
"Correspondence to: Thanh V. Nguyen <thanhng@iastate.edu>.
",1.1. Motivation,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1.1. Motivation,[0],[0]
"Copyright 2018 by the author(s).
cent results (Spielman et al., 2012; Agarwal et al., 2013; 2014; Arora et al., 2014; 2015; Sun et al., 2015; Chatterji & Bartlett, 2017; Nguyen et al., 2018) have established rigorous conditions under which their algorithms recover the true dictionary under suitable generative models for the data.
",1.1. Motivation,[0],[0]
An important underlying assumption that guides the success of all existing dictionary learning algorithms is the availability of (sufficiently many) data samples that are fully observed.,1.1. Motivation,[0],[0]
"Our focus, on the other hand, is on the special case where the given data points are only partially observed, that is, we are given access to only a small fraction of the coordinates of the data samples.
",1.1. Motivation,[0],[0]
"Such a setting of incomplete observations is natural in many applications like image-inpainting and demosaicing (Rubinstein et al., 2010).",1.1. Motivation,[0],[0]
"For example, this routinely appears in hyper-spectral imaging (Xing et al., 2012) where entire spectral bands of signals could be missing or unobserved.",1.1. Motivation,[0],[0]
"Moreover, in other applications, collecting fully observed samples can be expensive (or in some cases, even infeasible).",1.1. Motivation,[0],[0]
"Examples include the highly unreliable continuous blood glucose (CBG) monitoring systems that suffer from signal dropouts, where often the task is to learn a dictionary from partially observed signals (Naumova & Schnass, 2017a).
",1.1. Motivation,[0],[0]
"Earlier works that tackle the incomplete variant of the dictionary learning problem only offer heuristic solutions (Xing et al., 2012; Naumova & Schnass, 2017a) or involve constructing intractable statistical estimators (Soni et al., 2016).",1.1. Motivation,[0],[0]
"Indeed, the recovery of the true dictionary involves analyzing an extremely non-convex optimization problem that is, in general, not solvable in polynomial time (Loh & Wainwright, 2011).",1.1. Motivation,[0],[0]
"To our knowledge, our work is the first to give a theoretically sound as well as tractable algorithm to recover the exact dictionary from missing data (provided certain natural assumptions are met).",1.1. Motivation,[0],[0]
"In this paper, we make concrete theoretical algorithmic progress to the dictionary learning problem with incomplete samples.",1.2. Our Contributions,[0],[0]
"Inspired by recent algorithmic advances in dictionary learning (Arora et al., 2014; 2015), we adopt a learning-theoretic setup.",1.2. Our Contributions,[0],[0]
"Specifically, we assume that each data sample is synthesized from a generative model with an unknown dictionary and a random k-sparse coefficient
vector (or sparse code).",1.2. Our Contributions,[0],[0]
"Mathematically, the data samples Y =",1.2. Our Contributions,[0],[0]
"[y(1), y(2), . . .",1.2. Our Contributions,[0],[0]
", y(p)]",1.2. Our Contributions,[0],[0]
"2 Rn⇥p are of the form
Y = A⇤X⇤ ,
where A⇤ 2 Rn⇥m denotes the dictionary and X⇤ 2 Rm⇥p denotes the (column-wise) k-sparse codes.
",1.2. Our Contributions,[0],[0]
"However, we do not have direct access to the data; instead, each high-dimensional data sample is further subsampled such that only a small fraction of the entries are observed.",1.2. Our Contributions,[0],[0]
"The assumption we make is that each entry of Y is observed independently with probability ⇢ 2 (0, 1].",1.2. Our Contributions,[0],[0]
"For reasons that will become clear, we also assume that the ground truth dictionary A⇤ is both incoherent (i.e., the columns of A⇤ are sufficiently close to orthogonal) and democratic (i.e., the energy of each atom is well spread).",1.2. Our Contributions,[0],[0]
Both these assumptions are standard in the compressive-sensing literature.,1.2. Our Contributions,[0],[0]
"We clarify the generative model more precisely in the sequel.
",1.2. Our Contributions,[0],[0]
"Given a set of such (partially observed) data samples, our goal is to recover the true dictionary A⇤.",1.2. Our Contributions,[0],[0]
"Towards this goal, we make the following contributions:
1.",1.2. Our Contributions,[0],[0]
"Let us assume, for a moment, that we are given a coarse estimate A0 that is sufficiently close to the true dictionary.",1.2. Our Contributions,[0],[0]
"We devise a descent-style algorithm that leverages the given incomplete data to iteratively refine the dictionary estimate; moreover, we show that it converges rapidly to an estimate within a small ball of the ground truth A⇤ (whose radius decreases given more samples).",1.2. Our Contributions,[0],[0]
"Our result can be informally summarized as follows:
Theorem 1 (Informal, descent).",1.2. Our Contributions,[0],[0]
"When given a “sufficientlyclose” initial estimate A 0 , there exists an iterative gradient
descent-type algorithm that linearly converges to the true dictionary with O(mk polylog(n))",1.2. Our Contributions,[0],[0]
"incomplete samples.
",1.2. Our Contributions,[0],[0]
"Our above result mirrors several recent results in non-convex learning that all develop a descent algorithm which succeeds given a good enough initialization (Yuan & Zhang, 2013; Cai et al., 2016; Tu et al., 2016).",1.2. Our Contributions,[0],[0]
"Indeed, similar guarantees for descent-style algorithms (such as alternating minimization) exist for the related problem of matrix completion (Jain et al., 2013), which coincides with our setting if m ⌧ n.",1.2. Our Contributions,[0],[0]
"However, our setting is distinct, since we are interested in learning overcomplete dictionaries, where m > n.
2.",1.2. Our Contributions,[0],[0]
"Having established the efficiency of the above refinement procedure, we then address the challenge of actually coming up with a coarse estimate of A⇤.",1.2. Our Contributions,[0],[0]
We do not know of a provable procedure that produces a good enough initial estimate using partial samples.,1.2. Our Contributions,[0],[0]
"To circumvent this issue, we assume availability of O(m) fully observed samples along with the partial samples1.",1.2. Our Contributions,[0],[0]
"Given this setting, we show
1While this might be a limitation of our analysis, we emphasize
that we can provide a “sufficiently close” initial estimate in polynomial time.",1.2. Our Contributions,[0],[0]
"Our result can be summarized as follows:
Theorem 2 (Informal, initialization).",1.2. Our Contributions,[0],[0]
"There exists an initialization algorithm that, given O(m polylog(n)) fully observed samples and an additional O(mk polylog(n)) partially observed samples, returns an initial estimate A 0 that is sufficiently close to A ⇤ in a column-wise sense.",1.2. Our Contributions,[0],[0]
"The majority of our theoretical contributions are fairly technical, so for clarity, we provide some non-rigorous intuition.
",1.3. Techniques,[0],[0]
"At a high level, our approach merges ideas from two main themes in the algorithmic learning theory literature.",1.3. Techniques,[0],[0]
"We build upon recent seminal, theoretically-sound algorithms for sparse coding (specifically, the framework of Arora et al. (2015)).",1.3. Techniques,[0],[0]
Their approach consists of a descent-based algorithm performed over the surface of a suitably defined loss function of the dictionary parameters.,1.3. Techniques,[0],[0]
The descent is achieved by alternating between updating the dictionary estimate and updating the sparse codes of the data samples.,1.3. Techniques,[0],[0]
"The authors prove that this algorithm succeeds provided that the codes are sparse enough, the columns of A⇤ are incoherent, and that we are given sufficiently many samples.
",1.3. Techniques,[0],[0]
"However, a direct application of the above framework to the partially observed setting does not seem to succeed.",1.3. Techniques,[0],[0]
"To resolve this, we leverage a specific property that is commonly assumed in the matrix completion literature: we suppose that the dictionaries are not “spiky” and that the energy of each atom is spread out among its coordinates; specifically, the sub-dictionaries formed by randomly sub-selecting rows are still incoherent.",1.3. Techniques,[0],[0]
"We call such dictionaries democratic, following the terminology of Davenport et al. (2009).",1.3. Techniques,[0],[0]
"(In matrix completion papers, this property is also sometimes referred to incoherence, but we avoid doing so since that overloads the term.)",1.3. Techniques,[0],[0]
"Our main contribution is to show that democratic, incoherent dictionaries can be learned via a similar alternating descent scheme if only a small fraction of the data entries are available.",1.3. Techniques,[0],[0]
"Our analysis is novel and distinct than that provided in (Arora et al., 2015).
",1.3. Techniques,[0],[0]
"Of course, the above analysis is somewhat local in nature since we are using a descent-style method.",1.3. Techniques,[0],[0]
"In order to get global guarantees for recovery of A⇤, we need to initialize carefully.",1.3. Techniques,[0],[0]
"Here too, the spectral initialization strategies suggested in earlier dictionary learning papers (Arora et al., 2014; 2015) do not succeed.",1.3. Techniques,[0],[0]
"To resolve this, we again appeal to the democracy property of A⇤.",1.3. Techniques,[0],[0]
"We also need
that the number of full samples needed by our method is relatively small.",1.3. Techniques,[0],[0]
"Indeed, the state-of-the-art approach for dictionary learning (Arora et al., 2015) requires O(mk polylog(n)) fully observed samples, while our method needs only O(m polylog(n)) samples, which represents a polynomial improvement since k can be as large as p n.
to assume that provided a small hold-out set of additional, fully observed samples is available2.",1.3. Techniques,[0],[0]
"Using this hold-out set (which can be construed as additional prior information or “side” information) together with the available samples gives us a spectral initialization strategy that provably gives a good enough initial estimate.
",1.3. Techniques,[0],[0]
"Putting the above two pieces together: if we are provided O(mk/⇢4 polylog n) partially observed samples from the generative model, together with an additional O(m polylog n) full samples, then we can guarantee a fast, provable algorithm for learning A⇤.",1.3. Techniques,[0],[0]
"See Table 1 for a summary of our results, and comparison with existing work.",1.3. Techniques,[0],[0]
"We remark that while our algorithms only succeed up to sparsity level k  O(⇢ p n), we obtain a running time improvement over the best available dictionary learning approaches.",1.3. Techniques,[0],[0]
The literature on dictionary learning (or sparse coding) is very vast and hence our references to prior work will necessarily be incomplete; we refer to the seminal work of Rubinstein et al. (2010) for a list of applications.,1.4. Relation to Prior Work,[0],[0]
"Dictionary learning with incompletely observed data, however, is far less well-understood.",1.4. Relation to Prior Work,[0],[0]
"Initial attempts in this direction (Xing et al., 2012) involve Bayesian-style techniques; more recent attempts have focused on alternating minimization techniques, along with incoherence- and democracy-type assumptions akin to our framework (Naumova & Schnass, 2017b;a).",1.4. Relation to Prior Work,[0],[0]
"However, none of these methods provide rigorous polynomial-time algorithms that provably succeed in recovering the dictionary parameters.
",1.4. Relation to Prior Work,[0],[0]
"Our setup can also be viewed as an instance of matrix completion, which has been a source of intense interest in the machine learning community over the last decade (Candès & Recht, 2009; Keshavan et al., 2010).",1.4. Relation to Prior Work,[0],[0]
"The typical assumption in such approaches is that the data matrix Y = A⇤X⇤ is low-rank (i.e., A⇤ typically spans a low-dimensional subspace).",1.4. Relation to Prior Work,[0],[0]
"This assumption leads to either feasible convex relaxations, or a bilinear form that can be solved approximately via alternating minimization.",1.4. Relation to Prior Work,[0],[0]
"However, our work differs significantly from this setup, since we are interested in the case where A⇤ is over-complete; moreover, our guarantees are not in terms of estimating the missing entries of Y , but rather obtaining the atoms in A⇤.",1.4. Relation to Prior Work,[0],[0]
"Note that our generative model also differs from the setup of high-rank matrix completion (Eriksson et al., 2012), where the data is sampled randomly from a finite union-of-subspaces.",1.4. Relation to Prior Work,[0],[0]
"In contrast, our data samples are synthesized via sparse linear combinations of a given dictionary.
",1.4. Relation to Prior Work,[0],[0]
"2We do not know how to remove this assumption, and it appears that techniques stronger than spectral initialization (e.g., involving higher-order moments) are required.
",1.4. Relation to Prior Work,[0],[0]
"In the context of matrix-completion, perhaps the most related work to ours is the statistical analysis of matrixcompletion under the sparse-factor model of Soni et al. (2016), which employs a similar generative data model to ours.",1.4. Relation to Prior Work,[0],[0]
"(Similar sparse-factor models have been studied in the work of Lan et al. (2014), but no complexity guarantees are provided.)",1.4. Relation to Prior Work,[0],[0]
"For this model, Soni et al. (2016) propose a highly non-convex statistical estimator for estimate Y and provide error bounds for this estimator under various noise models.",1.4. Relation to Prior Work,[0],[0]
"However, they do not discuss an efficient algorithm to realize that estimator.",1.4. Relation to Prior Work,[0],[0]
"In contrast, we provide rigorous polynomial time algorithms, together with error bounds on the estimation quality of A⇤.",1.4. Relation to Prior Work,[0],[0]
"Overall, we anticipate that our work can shed some light on the design of provable algorithms for matrix-completion in such more general settings.",1.4. Relation to Prior Work,[0],[0]
Notation.,2. Preliminaries,[0],[0]
"Given a vector x 2 Rm and a subset S ✓ [m], we denote xS 2 Rm as a vector which equals x in indices belonging to S and equals zero elsewhere.",2. Preliminaries,[0],[0]
"We use A•i and A T
j• respectively to denote the ith column and the jth row of matrix A 2 Rn⇥m. We use A•S as the submatrix of A with columns in S. In contrast, we use A • to indicate the submatrix of A with rows not in set to zero.",2. Preliminaries,[0],[0]
Let supp(x) and sgn(x) be the support and element-wise sign of x. Let thresholdK(x) be the hard-thresholding operator that sets all entries of x with magnitude less than K to zero.,2. Preliminaries,[0],[0]
"The symbol k·k refers to the `2-norm, unless otherwise specified.
",2. Preliminaries,[0],[0]
"For asymptotic analysis, we use e⌦(·) and eO(·) to represent ⌦(·) and O(·) up to (unspecified) poly-logarithmic factors depending on n. Besides, g(n) =",2. Preliminaries,[0],[0]
"O⇤(f(n)) denotes g(n)  Kf(n) for some sufficiently small constant K. Finally, the terms “with high probability” (abbreviated to w.h.p.) is used to indicate an event with failure probability O(n !(1)).",2. Preliminaries,[0],[0]
"We make use of the following definitions.
",2. Preliminaries,[0],[0]
Definition 1 (Incoherence).,2. Preliminaries,[0],[0]
The matrix A is incoherent with parameter µ if the following holds for all columns i 6=,2. Preliminaries,[0],[0]
"j:
|hA•i, A•ji| kA•ikkA•jk  µp n .
",2. Preliminaries,[0],[0]
"The incoherence property requires the columns of A to be approximately orthogonal, and is a canonical property to resolve identifiability issues in dictionary learning and sparse recovery.",2. Preliminaries,[0],[0]
We distinguish this from the conventional notion of “incoherence” widely used in the matrix completion literature.,2. Preliminaries,[0],[0]
"This notion is related to a notion that we call democracy, which we define next.
",2. Preliminaries,[0],[0]
Definition 2 (Democracy).,2. Preliminaries,[0],[0]
Suppose that the matrix A is µ-incoherent.,2. Preliminaries,[0],[0]
A is further said to be democratic if the submatrix A • is µ-incoherent for any subset ⇢,2. Preliminaries,[0],[0]
[n] of size p n  | |  ,2. Preliminaries,[0],[0]
"n.
This property tells us that the rows of A have roughly the same amount of “information”, and that the submatrix of A restricted to any subset of rows is also incoherent.",2. Preliminaries,[0],[0]
"A similar concept (stated in terms of the restricted isometry property) is well-known in the compressive sensing literature (Davenport et al., 2009).",2. Preliminaries,[0],[0]
Several probabilistic constructions of dictionaries satisfy this property; typical examples include random matrices drawn from i.i.d.,2. Preliminaries,[0],[0]
Gaussian or Rademacher distributions.,2. Preliminaries,[0],[0]
"The p n lower bound on | | is to ensure that the submatrix of A including only the rows in is balanced in terms of dimensions.
",2. Preliminaries,[0],[0]
We seek an algorithm that provides a provably “good” estimate of A⇤.,2. Preliminaries,[0],[0]
"For this, we need a suitable measure of “goodness”.",2. Preliminaries,[0],[0]
The following notion of distance records the maximal column-wise difference between any estimate A and A⇤ in `2-norm under a suitable permutation and sign flip.,2. Preliminaries,[0],[0]
"Definition 3 (( ,)-nearness).",2. Preliminaries,[0],[0]
"The matrix A is said to be -close to A
⇤ if k (i)A•⇡(i)",2. Preliminaries,[0],[0]
"A⇤•ik  holds for every i =
1, 2, . . .",2. Preliminaries,[0],[0]
",m and some permutation ⇡ : [m]!",2. Preliminaries,[0],[0]
[m] and sign flip : [m] : {±1}.,2. Preliminaries,[0],[0]
"In addition, if kA•⇡ A⇤k  kA⇤k holds, then A is said to be ( ,)-near to A⇤.
",2. Preliminaries,[0],[0]
"To keep notation simple, in our convergence theorems below, whenever we discuss nearness, we simply replace the transformations ⇡ and in the above definition with the identity mapping ⇡(i) =",2. Preliminaries,[0],[0]
"i and the positive sign (·) = +1 while keeping in mind that in reality, we are referring to finding one element in the equivalence class of all permutations and sign flips of A⇤.
",2. Preliminaries,[0],[0]
"Armed with the above concepts, we now posit a generative model for our observed data.",2. Preliminaries,[0],[0]
Suppose that the data samples Y =,2. Preliminaries,[0],[0]
"[y(1), y(2), . . .",2. Preliminaries,[0],[0]
", y(p)] are such that each column is generated according to the rule:
y = P (A⇤x⇤), (1)
where A⇤ is an unknown, ground truth dictionary; x⇤ and are drawn from some distribution D and P is the sampling
operator that keeps entries in untouched and zeroes out everything else.",2. Preliminaries,[0],[0]
"We emphasize that is independently chosen for each y(i), so more precisely, y(i) = y(i)
(i) 2 Rn.
",2. Preliminaries,[0],[0]
We ignore the superscript to keep the notation simple.,2. Preliminaries,[0],[0]
We also make the following assumptions: Assumption 1.,2. Preliminaries,[0],[0]
"The true dictionary A⇤ is over-complete with m  Kn for some constant K > 1, and democratic with parameter µ. All columns of A ⇤ have unit norms.
",2. Preliminaries,[0],[0]
Assumption 2.,2. Preliminaries,[0],[0]
The true dictionary A⇤ has bounded spectral and max (`1-) norms such that kA⇤k  O( p m/n) and kA⇤kmax  O(1/ p n).,2. Preliminaries,[0],[0]
Assumption 3.,2. Preliminaries,[0],[0]
The code vector x⇤ is k-sparse random with uniform support S.,2. Preliminaries,[0],[0]
"The nonzero entries of x ⇤ are pairwise
independent sub-Gaussian with variance 1, and bounded
below by some known constant C.
Assumption 4.",2. Preliminaries,[0],[0]
"Each entry of the sample A⇤x⇤ is independently observed with constant probability ⇢ 2 (0, 1].
",2. Preliminaries,[0],[0]
"The incoherence and spectral bound are ubiquitous in the dictionary learning literature (Arora et al., 2014; 2015).",2. Preliminaries,[0],[0]
"For the incomplete setting, we further require the democracy and max-norm bounds to control the spread of energy of the entries of A⇤, so that A⇤ is not “spiky”.",2. Preliminaries,[0],[0]
"Such conditions are often encountered in the matrix completion literature (Candès & Recht, 2009; Keshavan et al., 2010).",2. Preliminaries,[0],[0]
"The distributional assumptions on the code vectors x⇤ are standard in theoretical dictionary learning (Agarwal et al., 2014; Arora et al., 2014; Gribonval et al., 2015; Arora et al., 2015).",2. Preliminaries,[0],[0]
"Finally, we also require the sparsity k  O⇤(⇢ p n/ log n) throughout the paper.",2. Preliminaries,[0],[0]
We now design and analyze an algorithm for learning the dictionary A⇤ given incomplete samples of the form (1).,3. A Descent-Style Learning Algorithm,[0],[0]
"Our strategy will be to use a descent-like scheme to construct a sequence of estimates A which successively gets closer to
A ⇤ in the sense of ( ,)-nearness.
",3. A Descent-Style Learning Algorithm,[0],[0]
Let us first provide some intuition.,3. A Descent-Style Learning Algorithm,[0],[0]
The natural approach to solve this problem is to perform gradient descent over an appropriate empirical loss of the dictionary parameters.,3. A Descent-Style Learning Algorithm,[0],[0]
"More precisely, we consider the squared loss between observed entries of Y and their estimates (which is the typical loss function used in the incomplete observations setting (Jain et al., 2013)):
L(A) = 1 2
X
i,j2⌦ (Yij (AX)ij)2, (2)
where ⌦ is the set of locations of observed entries in the samples Y .",3. A Descent-Style Learning Algorithm,[0],[0]
"However, straightforward gradient descent over A is not possible for several reasons: (i) the gradient depends on the finite sample variability of Y ; (ii) the gradient with respect to A depends on the optimal code vectors of the data samples, x⇤
i , which are unknown a priori; (iii) since
we are working in the overcomplete setting, care has to be taken to ensure that the code vectors (i.e., columns of X) obey the sparsity model (as specified in Assumption 2).
",3. A Descent-Style Learning Algorithm,[0],[0]
The neurally-plausible sparse coding algorithm of Arora et al. (2015) provides a crucial insight into the understanding of the loss surface of LA in the fully observed setting.,3. A Descent-Style Learning Algorithm,[0],[0]
"Basically, within a small ball around the ground truth A⇤, the surface is well behaved such that a noisy version of X⇤ is sufficient to construct a good enough approximation to the gradient of L. Moreover, given an estimate within a small ball around A⇤, a noisy (but good enough) estimate of X⇤ can be quickly computed using a thresholding operation.
",3. A Descent-Style Learning Algorithm,[0],[0]
We extend this understanding to the (much more challenging) setting of incomplete observations.,3. A Descent-Style Learning Algorithm,[0],[0]
"Specifically, we show the loss surface in (2) behaves well even with missing data.",3. A Descent-Style Learning Algorithm,[0],[0]
This enables us to devise an algorithm similar to that of Arora et al. (2015) and obtain a descent property directly related to (the population parameter) A⇤.,3. A Descent-Style Learning Algorithm,[0],[0]
"The full procedure is detailed as Algorithm 1.
",3. A Descent-Style Learning Algorithm,[0],[0]
We now analyze our proposed algorithm.,3. A Descent-Style Learning Algorithm,[0],[0]
"Specifically, we can show that if initialized properly and with proper choice of step size, Algorithm 1 exhibits linear convergence to a ball of radius O( p k/n) around A⇤.",3. A Descent-Style Learning Algorithm,[0],[0]
"Formally, we have:
Theorem 3.",3. A Descent-Style Learning Algorithm,[0],[0]
"Suppose that the initial estimate A0 is ( , 2)- near to A ⇤ with = O⇤(1/ log n) and the sampling prob-
ability satisfies ⇢ 1/(k + 1).",3. A Descent-Style Learning Algorithm,[0],[0]
"If Algorithm 1 is given p = e⌦(mk) fresh partial samples at each step and uses learning rate ⌘ = ⇥(m/⇢k), then
E[kAs•i A⇤•ik 2]  (1 ⌧)skA0•i A⇤•ik
2 +O( p k/n)
for some 0 < ⌧ < 1/2 and s = 1, 2, . . .",3. A Descent-Style Learning Algorithm,[0],[0]
", T .",3. A Descent-Style Learning Algorithm,[0],[0]
"As a corollary, A s converges geometrically to A ⇤ until column-wise O( p k/n) error.
",3. A Descent-Style Learning Algorithm,[0],[0]
"Algorithm 1 Gradient descent-style algorithm Input: Partial samples Y with observed entry set (i) Initial A0 that is ( , 2)-near to A⇤ for s = 0, 1, . . .",3. A Descent-Style Learning Algorithm,[0],[0]
", T do
/*",3. A Descent-Style Learning Algorithm,[0],[0]
"Encoding step */ for i = 1, 2, . . .",3. A Descent-Style Learning Algorithm,[0],[0]
", p do
x",3. A Descent-Style Learning Algorithm,[0],[0]
"(i) thresholdC/2( 1⇢ (A s)T y(i))
",3. A Descent-Style Learning Algorithm,[0],[0]
end /*,3. A Descent-Style Learning Algorithm,[0],[0]
"Update step */ bgs 1
p
P p
i=1(P (i)(Asx(i))",3. A Descent-Style Learning Algorithm,[0],[0]
"y(i))sgn(x(i))T
A s+1 As ⌘bgs
end Output: A AT as a learned dictionary
We defer the full proof of Theorem 3 to Appendix C. To understand the working of the algorithm and its correctness, let us consider the setting where we have access to infinitely many samples.",3. A Descent-Style Learning Algorithm,[0],[0]
"This setting is, of course, fictional; however, expectations are easier to analyze than empirical averages, and moreover, this exercise reveals several key elements for proving Theorem 3.",3. A Descent-Style Learning Algorithm,[0],[0]
"More precisely, we first provide bounds on the expected value of bgs, denoted as
g s , Ey[(P (Asx) y)sgn(x)T ],
to establish the descent property for the infinite sample case.",3. A Descent-Style Learning Algorithm,[0],[0]
"The sample complexity argument emerges when we control the concentration of bgs, detailed in Appendix C. Here, we separately discuss the encoding and update steps in Algorithm 1.
",3. A Descent-Style Learning Algorithm,[0],[0]
Encoding step.,3. A Descent-Style Learning Algorithm,[0],[0]
The first main result is to show that the hard-thresholding (or pooling)-based rule for estimating the sparse code vectors is sufficiently accurate.,3. A Descent-Style Learning Algorithm,[0],[0]
"This rule adapts the encoding step of the dictionary learning algorithm proposed in (Arora et al., 2015), with an additional scaling factor 1/⇢.",3. A Descent-Style Learning Algorithm,[0],[0]
"This scaling is necessary to avoid biases arising due to the presence of incomplete information.
",3. A Descent-Style Learning Algorithm,[0],[0]
The primary novelty is in our analysis.,3. A Descent-Style Learning Algorithm,[0],[0]
"Specifically, we prove that the estimate of X obtained via the encoding step (even under partial observations) enables a good enough identification of the support of the true X⇤.",3. A Descent-Style Learning Algorithm,[0],[0]
"The key, here, is to leverage the fact that A⇤ is democratic and that As is near A⇤.",3. A Descent-Style Learning Algorithm,[0],[0]
"We call this property support consistency and establish it as follows.
",3. A Descent-Style Learning Algorithm,[0],[0]
Lemma 1.,3. A Descent-Style Learning Algorithm,[0],[0]
"Suppose that As is ( , 2)-near to A⇤ with = O
⇤(1/ log n).",3. A Descent-Style Learning Algorithm,[0],[0]
"With high probability over y = P (A⇤x⇤), the estimate x obtained by the encoding step of Algorithm 1 has the same sign as the true x ⇤ ; that is,
sgn thresholdC/2 1 ⇢ (As)T y = sgn(x⇤), (3)
This holds true for incoherence parameter µ  p n
2k , sparsity
parameter k ⌦(logm) and subsampling probability ⇢",3. A Descent-Style Learning Algorithm,[0.9560066542673711],"['(11) is a convex problem, it is equivalent to its dual optimization problem: max λ∈Rd×n −F ∗(λ √ W ), (12) where F ∗(y) = supx∈Rd×n〈y, x〉 − F (x) is the Fenchel conjugate of F , and 〈y, x〉 = tr(y>x) is the standard scalar product between matrices.']"
"1/(k + 1).
",3. A Descent-Style Learning Algorithm,[0],[0]
"Lemma 1 implies that when the “mass” of A⇤ is spread out across entries, within a small neighborhood of A⇤ the estimate x is reliable even if y is incompletely observed.",3. A Descent-Style Learning Algorithm,[0],[0]
"This lemma is the main ingredient for bounding the behavior of the update rule.
",3. A Descent-Style Learning Algorithm,[0],[0]
Update step.,3. A Descent-Style Learning Algorithm,[0],[0]
The support consistency property of the estimated x arising in the encoding step is key to rigorously analyzing the expected gradient gs.,3. A Descent-Style Learning Algorithm,[0],[0]
"This relatively ‘simple’ encoding enables an explicit form of the update rule, and gives an intuitive reasoning on how the descent property can be achieved.",3. A Descent-Style Learning Algorithm,[0],[0]
"In fact, we will see that
g s i = ⇢piqi( s i A s •i A⇤•i) + o(⇢piqi)
for pi = E[|x⇤i ||i 2 S], qi = P[i 2 S] and si = hA•i, A⇤•ii.",3. A Descent-Style Learning Algorithm,[0],[0]
"Since we assume that the current estimate As is (columnwise) sufficiently close to A⇤, each s
i is approximately
equal to 1, and hence gs i ⇡ ⇢piqi(As•i A⇤•i), i.e., the gradient points in the desired direction.",3. A Descent-Style Learning Algorithm,[0],[0]
"Combining this with standard analysis of gradient descent, we can prove that the overall algorithm geometrically decreases the error in each step s as long as the learning rate ⌘ is properly chosen.",3. A Descent-Style Learning Algorithm,[0],[0]
"Specifically, we get the following theoretical result.",3. A Descent-Style Learning Algorithm,[0],[0]
Theorem 4.,3. A Descent-Style Learning Algorithm,[0],[0]
"Suppose that A0 is ( , 2)-near to A⇤ with = O
⇤(1/ log n) and the sampling probability satisfies ⇢ 1/(k + 1).",3. A Descent-Style Learning Algorithm,[0],[0]
"Assuming infinitely many partial samples at each step, Algorithm 1 geometrically converges to A ⇤ until
column-wise error O(k/⇢n).",3. A Descent-Style Learning Algorithm,[0],[0]
"More precisely,
kAs+1•i",3. A Descent-Style Learning Algorithm,[0],[0]
"A ⇤ •ik 2  (1 ⌧)kAs•i A⇤•ik 2 +O k 2 /⇢ 2 n 2
for some 0 < ⌧ < 1/2 and for s = 1, 2, . . .",3. A Descent-Style Learning Algorithm,[0],[0]
", T provided the learning rate obeys ⌘ = ⇥(m/⇢k).
",3. A Descent-Style Learning Algorithm,[0],[0]
We provide the mathematical proof for the form of gs as well as the descent in Appendix A.2.,3. A Descent-Style Learning Algorithm,[0],[0]
"We also argue that the ( , 2)-nearness of As+1 and A⇤ is maintained after each update.",3. A Descent-Style Learning Algorithm,[0],[0]
This is studied in Lemma 7 in Appendix A.,3. A Descent-Style Learning Algorithm,[0],[0]
"In the previous section, we provided an algorithm that (accurately) recovers A⇤ in an iterative descent-style approach.",4. An Initialization Algorithm,[0],[0]
"In order to establish correctness guarantees, the algorithm requires a coarse estimate A0 that is -close to the ground truth with closeness parameter = O⇤(1/ log n).",4. An Initialization Algorithm,[0],[0]
"This section presents an initialization strategy to obtain such a good starting point for A⇤.
",4. An Initialization Algorithm,[0],[0]
"Again, we begin with some intuition.",4. An Initialization Algorithm,[0],[0]
"At a high level, our algorithm mimics the spectral initialization strategy for dictionary learning proposed by (Arora et al., 2015).",4. An Initialization Algorithm,[0],[0]
"In essence,
the idea is to re-weight the data samples (which are fully observed) appropriately.",4. An Initialization Algorithm,[0],[0]
"When this is the case, analyzing the spectral properties of the covariance matrix of the new re-weighted samples gives us the desired initialization.",4. An Initialization Algorithm,[0],[0]
"The re-weighting itself relies upon the computation of pairwise correlations between the samples with two fixed samples (say, u and v) chosen from an independent hold-out set.",4. An Initialization Algorithm,[0],[0]
"This strategy is appealing in both from the standpoint of statistical efficiency as well as computational ease.
",4. An Initialization Algorithm,[0],[0]
"Unfortunately, a straightforward application of this strategy to our setting of incomplete observations does not work.",4. An Initialization Algorithm,[0],[0]
"The major issue, of course, is that pairwise correlation (the inner product) of two high dimensional vectors is highly uninformative if each vector is only partially observed.",4. An Initialization Algorithm,[0],[0]
"We circumvent this issue via the following simple (but key) observation: provided the underlying dictionary is democratic and the representation is sufficiently sparse, the correlation between a partially observed data sample y with a fully observed sample u is indeed proportional to the actual correlation between y and u. Therefore, assuming that we are given a hold-out set that is fully observed, an adaptation of the spectral approach of Arora et al. (2015) provably succeeds.",4. An Initialization Algorithm,[0],[0]
"Moreover, the size of the hold-out set need not be large; in particular, we need only O(m polylog(n)) fully-observed samples, as opposed to the O(mk polylog(n))",4. An Initialization Algorithm,[0],[0]
samples required by the analysis of Arora et al. (2015).,4. An Initialization Algorithm,[0],[0]
"The parameter k can be as big as p n, so in fact we require polynomially fewer fully-observed samples.
",4. An Initialization Algorithm,[0],[0]
"In summary: in order to initialize our descent procedure, we assume the availability of a small (but fully observed) hold-out set.",4. An Initialization Algorithm,[0],[0]
"In practice, we can imagine expending some amount of effort in the beginning to collect all the entries of a small subset of the available data samples.",4. An Initialization Algorithm,[0],[0]
"The availability of such additional information (or “side-information”) has been made in the literature on matrix completion (Natarajan & Dhillon, 2014).
",4. An Initialization Algorithm,[0],[0]
The full procedure is described in pseudocode form as Algorithm 2.,4. An Initialization Algorithm,[0],[0]
"Our main theoretical result (Theorem 5) summarizes its performance.
",4. An Initialization Algorithm,[0],[0]
Theorem 5.,4. An Initialization Algorithm,[0],[0]
"Suppose that the available training dataset consists of p1 fully observed samples, together with p2 in-
completely observed samples according to the observation model (1).",4. An Initialization Algorithm,[0],[0]
"Suppose µ = O⇤ p n
k log3 n
, 1 ⇢ 1  k 
O ⇤( ⇢
p n
logn ).",4. An Initialization Algorithm,[0],[0]
"When p1 = e⌦(m) and p2 = e⌦(mk/⇢4), then with high probability, Algorithm 2 returns an initial estimate A 0 whose columns share the same support as A ⇤ and is ( , 2)-near to A⇤ with = O⇤(1/ log n).
",4. An Initialization Algorithm,[0],[0]
"The full proof is provided in Appendix B. To provide some intuition about the working of the algorithm and its proof, let us again consider the setting where we have access to infinitely many samples.",4. An Initialization Algorithm,[0],[0]
"These analyses result in key lemmas,
Algorithm 2 Spectral initialization algorithm Input: P1: p1 fully observed samples P2: p2 partially observed samples Set L = ; while |L| < m do
Pick u and v from P1 at random Construct the weighted covariance matrix cMu,v using samples y(i) from P2
cMu,v 1
p2⇢ 4
p2X
i=1
hy(i), uihy(i), viy(i)(y(i))T
1, 2 top singular values if 1 ⌦(k/m) and 2 < O⇤(k/m log n) then
z top singular vector if z is not within distance 1/ log n of vectors in L even with sign flip then
L L [ {z} end
end end",4. An Initialization Algorithm,[0],[0]
"Output: A0 ProjB(Ã) where Ã is the matrix whose columns in L and B = {A : kAk  2kA⇤k}
which we will reuse extensively for proving Theorem 5.
",4. An Initialization Algorithm,[0],[0]
"First, consider two fully observed data samples u = A⇤↵ and v = A⇤↵0 drawn from the hold-out set.",4. An Initialization Algorithm,[0],[0]
"(Here, A⇤,↵,↵0 are unknown.)",4. An Initialization Algorithm,[0],[0]
Consider also a partially observed sample y = A⇤ •x ⇤ under a random subset ✓,4. An Initialization Algorithm,[0],[0]
[n].,4. An Initialization Algorithm,[0],[0]
"Define:
= 1
⇢ A
⇤T •u, and
0 = 1
⇢ A
⇤T •v
respectively as (crude) estimates of ↵ and ↵0, simply obtained by applying a (scaled) adjoint of A • to u and v respectively.",4. An Initialization Algorithm,[0],[0]
"It follows from the above definition that:
= 1
⇢",4. An Initialization Algorithm,[0],[0]
"A
⇤T •A ⇤ ↵, and hy, ui = ⇢h , x⇤i.
",4. An Initialization Algorithm,[0],[0]
"Our main claim is that since A⇤ is assumed to satisfy the democracy property, 1
⇢ A ⇤T •A ⇤ resembles the identity, and hence “looks” like the true code vector ↵.",4. An Initialization Algorithm,[0],[0]
"In particular, we have the following lemma.
",4. An Initialization Algorithm,[0],[0]
Lemma 2.,4. An Initialization Algorithm,[0],[0]
"With high probability over the randomness in u and , we have: (a) | i ↵i|  µk lognpn + q 1 ⇢ ⇢n1/2 for each i = 1, 2, . . .",4. An Initialization Algorithm,[0],[0]
",m and (b) k k  p k logn ⇢ .
",4. An Initialization Algorithm,[0],[0]
Proof.,4. An Initialization Algorithm,[0],[0]
"Denote U = supp(↵) and W = U\{i}, then
| i ↵i| = 1
⇢",4. An Initialization Algorithm,[0],[0]
"A
⇤T ,iA ⇤ •W↵W + 1 ⇢ hA⇤ ,i, A⇤•ii 1 ↵i
 1 ⇢ A⇤T ,iA⇤•W↵W + ( 1 ⇢ A ⇤T ,iA ⇤ •i 1)↵i .
(4)
",4. An Initialization Algorithm,[0],[0]
We will bound these terms on the right hand side of (4) using the properties of A⇤ and ↵.,4. An Initialization Algorithm,[0],[0]
"First, we notice that for any ⇢ [n]:
kA⇤T ,iA⇤•W k 2 =
X j2W hA⇤ ,i, A⇤•ji 2  µ 2 n X j2W kA⇤ ,ik 2kA⇤ ,jk 2 ,
where we have used the democracy of A⇤ with respect to .",4. An Initialization Algorithm,[0],[0]
"Moreover, using the Chernoff bound for kA⇤ ,ik
2 = P
n i=1",4. An Initialization Algorithm,[0],[0]
"A ⇤2 li 1[l 2 ], we have kA⇤ ,ik 2  ⇢ + o(⇢) w.h.p.",4. An Initialization Algorithm,[0],[0]
"Hence, kA⇤T ,iA⇤•W k
2  ⇢2µ2k/n with high probability.",4. An Initialization Algorithm,[0],[0]
"In addition, k↵W k  p k log n w.h.p.",4. An Initialization Algorithm,[0],[0]
because ↵W is ksparse sub-Gaussian.,4. An Initialization Algorithm,[0],[0]
"Therefore, the first term in (4) gives 1 ⇢ |A⇤T ,iA⇤•W↵W |  µk lognp n with high probability.
",4. An Initialization Algorithm,[0],[0]
"For the second term in (4), consider a random variable T = ( 1
⇢ A ⇤T ,iA ⇤ •i 1)↵i over and ↵i. We first observe for
any vector w 2 Rn that:
E[(wT w)2] = nX
i=1
E[w4 i 1i2 ]",4. An Initialization Algorithm,[0],[0]
"+
nX i 6=j E[w2",4. An Initialization Algorithm,[0],[0]
"i w 2 j 1i,j2 ]
= ⇢(1 ⇢) nX
i=1
",4. An Initialization Algorithm,[0],[0]
w 4,4. An Initialization Algorithm,[0],[0]
"i + ⇢2.
",4. An Initialization Algorithm,[0],[0]
"Hence, T has mean 0 and variance 2 T
= (1 ⇢)/⇢",4. An Initialization Algorithm,[0],[0]
"P n
j=1 A 4 ji , which is bounded by O( 1 ⇢ ⇢n )",4. An Initialization Algorithm,[0],[0]
because kA⇤kmax  O(1/ p n),4. An Initialization Algorithm,[0],[0]
.,4. An Initialization Algorithm,[0],[0]
"By Chebyshev’s inequality, we
have |T |  q
1 ⇢ ⇢n1/2
with failure probability 1/ p n. Com-
bining everything, we get
| i ↵i|  µk log np
n + s 1 ⇢ ⇢n1/2 ,
w.h.p., which is the first part of the claim.
",4. An Initialization Algorithm,[0],[0]
"For the second part, we bound k k by expanding it as:
k k = 1 ⇢ kA⇤T •A⇤•U↵Uk  1 ⇢ kA⇤ •kkA⇤•Ukk↵Uk,
and again, if we use k↵Uk  p k log n w.h.p.and kA⇤k 
O(1), then k k  p k log n/⇢.
",4. An Initialization Algorithm,[0],[0]
We briefly compare the above result with that of Arora et al. (2015).,4. An Initialization Algorithm,[0],[0]
"Our upper bounds are more general, and are stated in terms of the incompleteness factor ⇢.",4. An Initialization Algorithm,[0],[0]
"Indeed,
and reconstruction error in sample size and sampling probability.
",4. An Initialization Algorithm,[0],[0]
our results match the previous bounds when ⇢ = 1.,4. An Initialization Algorithm,[0],[0]
The above lemma suggests the following interesting regime of parameters.,4. An Initialization Algorithm,[0],[0]
"Specifically, for µ = O⇤ p n
k",4. An Initialization Algorithm,[0],[0]
"log3 n
and 1 ⇢ 1 
k  ",4. An Initialization Algorithm,[0],[0]
"O⇤( ⇢ p n
logn ), one can see that | i ↵i|  O ⇤(1/ log2 n)
w.h.p., which implies that is a good estimate of ↵ even when a subset of rows in A⇤ is given.
",4. An Initialization Algorithm,[0],[0]
"In the next lemma, we show that that the pairwise correlation of u and any sample y is sufficiently informative for the same re-weighted spectral estimation strategy of Arora et al. (2015) to succeed in the incomplete setting.
",4. An Initialization Algorithm,[0],[0]
Lemma 3.,4. An Initialization Algorithm,[0],[0]
"Suppose that u, v are a pair of fully observed samples and y is an incomplete sample independent of u, v.
The weighted covariance matrix Mu,v has the form:
Mu,v , 1
⇢4 Ey[hy, uihy, viyyT ]
= X
i2U\V qici i
0",4. An Initialization Algorithm,[0],[0]
i A ⇤ •iA,4. An Initialization Algorithm,[0],[0]
⇤T •i,4. An Initialization Algorithm,[0],[0]
"+O ⇤(k/m log n),
where ci = E[x⇤4i |i 2 S] and qi = P[i 2 S].
",4. An Initialization Algorithm,[0],[0]
The complete proof is relegated to Appendix B. We will instead discuss some implications of this Lemma.,4. An Initialization Algorithm,[0],[0]
Recall that ci is a constant with 0,4. An Initialization Algorithm,[0],[0]
"< c < 1 and qi = ⇥(k/m).
",4. An Initialization Algorithm,[0],[0]
"Suppose, for a moment, that the sparse representations of u and v share exactly one common dictionary element, say A
⇤ •i (i.e., if U = supp(u) and V = supp(v) then U \ V = {i}.)",4. An Initialization Algorithm,[0],[0]
"The first term, qici i 0iA⇤•iA⇤T•i , has norm |qici i 0i|.",4. An Initialization Algorithm,[0],[0]
"From Claim 2, | i| |↵i| | i ↵i| C o(1).",4. An Initialization Algorithm,[0],[0]
"Therefore, qici i 0",4. An Initialization Algorithm,[0],[0]
i A ⇤ •iA,4. An Initialization Algorithm,[0],[0]
⇤T •i has norm at least ⌦(k/m) whereas the perturbation terms are at most O⇤(k/m log n).,4. An Initialization Algorithm,[0],[0]
"According to Wedin’s theorem, we conclude that the top singular vector of Mu,v must be O⇤(k/m log n)/⌦(k/m) =",4. An Initialization Algorithm,[0],[0]
O⇤(1/ log n) -close to A⇤•i.,4. An Initialization Algorithm,[0],[0]
"This gives us a coarse estimate of A⇤•i.
",4. An Initialization Algorithm,[0],[0]
"The question remains when and how whether we can a priori certify whether u, v share a unique dictionary atom among their sparse representations.",4. An Initialization Algorithm,[0],[0]
"Fortunately, the following Lemma provides a simple test for this via examining the decay of the singular vectors of the cross-covariance matrix Mu,v. The proof follows directly from that of Lemma 37 in (Arora et al., 2015).
",4. An Initialization Algorithm,[0],[0]
Lemma 4.,4. An Initialization Algorithm,[0],[0]
"When the top singular value of Mu,v is at least ⌦(k/m) and the second largest one is at most O
⇤(k/m log n), then u and v share a unique dictionary element with high probability.
",4. An Initialization Algorithm,[0],[0]
The above discussion isolates one of the columns of A⇤.,4. An Initialization Algorithm,[0],[0]
We can repeat this procedure several times by randomly choosing pairs of samples u and v from the hold-out set.,4. An Initialization Algorithm,[0],[0]
"Using the result of Arora et al. (2015), if |P1| is p1 = eO(m), then we can estimate all the m dictionary atoms.",4. An Initialization Algorithm,[0],[0]
"Overall, the sample complexity of Algorithm 2 is dominated by p2 = eO(mk/⇢4).",4. An Initialization Algorithm,[0],[0]
We corroborate our theory by demonstrating some representative numerical benefits of our proposed algorithms.,5. Experiments,[0],[0]
We generate a synthetic dataset based on the generative model described in Section 2.,5. Experiments,[0],[0]
The ground truth dictionary A⇤ is of size 256⇥ 256 with independent standard Gaussian entries.,5. Experiments,[0],[0]
We normalize columns of A⇤ to be unit norm.,5. Experiments,[0],[0]
"Then, we generate 6-sparse code vectors x⇤ with support drawn uniformly at random.",5. Experiments,[0],[0]
Entries in the support are sampled from ±1 with equal probability.,5. Experiments,[0],[0]
"We generate all full samples, and isolate 5000 samples as “side information” for the initialization step.",5. Experiments,[0],[0]
"The remaining are then subsampled with different parameters ⇢.
",5. Experiments,[0],[0]
We set the number of iterations to T = 3000 in the initialization procedure and the number of descent steps T = 50 for the descent scheme.,5. Experiments,[0],[0]
"Besides, we slightly modify the thresholding operator in the encoding step of Algorithm 1.",5. Experiments,[0],[0]
We use another operator that keeps k largest entries of the input untouched and sets everything else to zero due to its stability.,5. Experiments,[0],[0]
"For each Monte Carlo trial, we uniformly draw p partial samples.",5. Experiments,[0],[0]
"The task, for our algorithm, is to learn A⇤.",5. Experiments,[0],[0]
"An implementation of our method is available online3.
",5. Experiments,[0],[0]
"We evaluate our algorithm on two metrics against p and ⇢: (i) recovery rate, i.e., the fraction of trials in which each algorithm successfully recovers the ground truth A⇤; and (ii) reconstruction error.",5. Experiments,[0],[0]
All the metrics are averaged over 50 Monte Carlo simulations.,5. Experiments,[0],[0]
“Successful recovery” is defined according to a threshold ⌧ = 6 on the Frobenius norm of the difference between the estimate bA and the ground truth A⇤.,5. Experiments,[0],[0]
"(Since we can only estimate bA modulo a permutation and sign flip, the optimal column and sign matching is computed using the Hungarian algorithm.)
",5. Experiments,[0],[0]
Figure 1 shows our experimental results.,5. Experiments,[0],[0]
"Here, sample size refers to the number of incomplete samples.",5. Experiments,[0],[0]
"Our algorithms are able to recover the dictionary for ⇢ = 0.6, 0.8, 1.0.",5. Experiments,[0],[0]
"For ⇢ = 0.4, we can observe a “phase transition” in sample complexity of successful recovery around p = 10, 000 samples.
",5. Experiments,[0],[0]
"3https://github.com/thanh-isu
Acknowledgements The authors thank the anonymous reviewers for many insightful comments and suggestions during the review process.",5. Experiments,[0],[0]
"This work was supported in part by the National Science Foundation under grants CCF-1566281 and CCF-1750920, and in part by a Faculty Fellowship from the Black and Veatch Foundation.",5. Experiments,[0],[0]
Existing algorithms for dictionary learning assume that the entries of the (high-dimensional) input data are fully observed.,abstractText,[0],[0]
"However, in several practical applications, only an incomplete fraction of the data entries may be available.",abstractText,[0],[0]
"For incomplete settings, no provably correct and polynomialtime algorithm has been reported in the dictionary learning literature.",abstractText,[0],[0]
"In this paper, we provide provable approaches for learning – from incomplete samples – a family of dictionaries whose atoms have sufficiently “spread-out” mass.",abstractText,[0],[0]
"First, we propose a descent-style iterative algorithm that linearly converges to the true dictionary when provided a sufficiently coarse initial estimate.",abstractText,[0],[0]
"Second, we propose an initialization algorithm that utilizes a small number of extra fully observed samples to produce such a coarse initial estimate.",abstractText,[0],[0]
"Finally, we theoretically analyze their performance and provide asymptotic statistical and computational guarantees.",abstractText,[0],[0]
On Learning Sparsely Used Dictionaries from Incomplete Samples,title,[0],[0]
"The depth of deep neural networks confers representational power, but also makes model optimization more challenging.",1. Introduction,[0],[0]
"Training deep networks with gradient descent based methods is known to be difficult as a consequence of the vanishing and exploding gradient problem (Hochreiter & Schmidhuber, 1997).",1. Introduction,[0],[0]
"Typically, exploding gradients are avoided by clipping large gradients (Pascanu et al., 2013) or introducing an L2 or L1 weight norm penalty.",1. Introduction,[0],[0]
"The latter has the effect of bounding the spectral radius of the linear transformations, thus limiting the maximal gain across the transformation.",1. Introduction,[0],[0]
"Krueger & Memisevic (2015) attempt to
1École Polytechnique de Montréal, Montréal, Canada 2Montreal Institute for Learning Algorithms, Montréal, Canada 3CHUM Research Center, Montréal, Canada.",1. Introduction,[0],[0]
"Correspondence to: Eugene Vorontsov <eugene.vorontsov@gmail.com>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
stabilize the norm of propagating signals directly by penalizing differences in successive norm pairs in the forward pass and Pascanu et al. (2013) propose to penalize successive gradient norm pairs in the backward pass.,1. Introduction,[0],[0]
"These regularizers affect the network parameterization with respect to the data instead of penalizing weights directly.
",1. Introduction,[0],[0]
Both expansivity and contractivity of linear transformations can also be limited by more tightly bounding their spectra.,1. Introduction,[0],[0]
"By limiting the transformations to be orthogonal, their singular spectra are limited to unitary gain causing the transformations to be norm-preserving.",1. Introduction,[0],[0]
Le et al. (2015) and Henaff et al. (2016) have respectively shown that identity initialization and orthogonal initialization can be beneficial.,1. Introduction,[0],[0]
"Arjovsky et al. (2015) have gone beyond initialization, building unitary recurrent neural network (RNN) models with transformations that are unitary by construction which they achieved by composing multiple basic unitary transformations.",1. Introduction,[0],[0]
"The resulting transformations, for some n-dimensional input, cover only some subset of possible n × n unitary matrices but appear to perform well on simple tasks and have the benefit of having low complexity in memory and computation.
",1. Introduction,[0],[0]
The entire set of possible unitary or orthogonal parameterizations forms the Stiefel manifold.,1. Introduction,[0],[0]
"At a much higher computational cost, gradient descent optimization directly along this manifold can be done via geodesic steps (Nishimori, 2005; Tagare, 2011).",1. Introduction,[0],[0]
"Recent work (Wisdom et al., 2016) has proposed the optimization of unitary matrices along the Stiefel manifold using geodesic gradient descent.",1. Introduction,[0],[0]
"To produce a full-capacity parameterization for unitary matrices they use some insights from Tagare (2011), combining the use of canonical inner products and Cayley transformations.",1. Introduction,[0],[0]
Their experimental work indicates that full capacity unitary RNN models can solve the copy memory problem whereas both LSTM networks and restricted capacity unitary RNN models having similar complexity appear unable to solve the task for a longer sequence length (T = 2000).,1. Introduction,[0],[0]
"(Harandi & Fernando, 2016) also find that the use of fully connected “Stiefel layers” improves the performance of some convolutional neural networks.
",1. Introduction,[0],[0]
"We seek to gain a new perspective on this line of research by exploring the optimization of real valued matrices within a configurable margin about the Stiefel mani-
fold.",1. Introduction,[0],[0]
"We suspect that a strong constraint of orthogonality limits the model’s representational power, hindering its performance, and may make optimization more difficult.",1. Introduction,[0],[0]
We explore this hypothesis empirically by employing a factorization technique that allows us to limit the degree of deviation from the Stiefel manifold.,1. Introduction,[0],[0]
"While we use geodesic gradient descent, we simultaneously update the singular spectra of our matrices along Euclidean steps, allowing optimization to step away from the manifold while still curving about it.",1. Introduction,[0],[0]
"The issue of vanishing and exploding gradients as it pertains to the parameterization of neural networks can be illuminated by looking at the gradient back-propagation chain through a network.
",1.1. Vanishing and Exploding Gradients,[0],[0]
"A neural network with n hidden layers has pre-activations
ai(hi−1) =",1.1. Vanishing and Exploding Gradients,[0],[0]
"Wi hi−1 + bi, i ∈ {2, · · · , n} (1)
",1.1. Vanishing and Exploding Gradients,[0],[0]
"For notational convenience, we combine parameters Wi and bi to form an affine matrix θ.",1.1. Vanishing and Exploding Gradients,[0],[0]
"We can see that for some loss function L at layer n , the derivative with respect to parameters θi is:
∂L ∂θi = ∂an+1 ∂θi ∂L ∂an+1",1.1. Vanishing and Exploding Gradients,[0],[0]
"(2)
The partial derivatives for the pre-activations can be decomposed as follows:
∂ai+1 ∂θi = ∂ai ∂θi ∂hi ∂ai ∂ai+1 ∂hi
= ∂ai ∂θi DiWi+1 → ∂ai+1 ∂ai = DiWi+1,
(3)
where Di is the Jacobian corresponding to the activation function, containing partial derivatives of the hidden units at layer i + 1 with respect to the pre-activation inputs.",1.1. Vanishing and Exploding Gradients,[0],[0]
"Typically, D is diagonal.",1.1. Vanishing and Exploding Gradients,[0],[0]
"Following the above, the gradient in equation 2 can be fully decomposed into a recursive chain of matrix products:
∂L ∂θi = ∂ai",1.1. Vanishing and Exploding Gradients,[0],[0]
"∂θi n∏ j=i (DjWj+1) ∂L ∂an+1 (4)
",1.1. Vanishing and Exploding Gradients,[0],[0]
"In (Pascanu et al., 2013), it is shown that the 2-norm of ∂ai+1 ∂ai is bounded by the product of the norms of the nonlinearity’s Jacobian and transition matrix at time t (layer i ), as follows:∣∣∣∣∣∣∣∣∂at+1∂at
∣∣∣∣∣∣∣∣ ≤",1.1. Vanishing and Exploding Gradients,[0],[0]
||Dt|| ||Wt|| ≤,1.1. Vanishing and Exploding Gradients,[0],[0]
"λDt λWt = ηt, λDt , λWt ∈ R. (5)
where λDt and λWt are the largest singular values of the non-linearity’s Jacobian Dt and the transition matrix Wt .",1.1. Vanishing and Exploding Gradients,[0],[0]
"In RNNs, Wt is shared across time and can be simply denoted as W.
Equation 5 shows that the gradient can grow or shrink at each layer depending on the gain of each layer’s linear transformation W and the gain of the Jacobian D. The gain caused by each layer is magnified across all time steps or layers.",1.1. Vanishing and Exploding Gradients,[0],[0]
It is easy to have extreme amplification in a recurrent neural network where W is shared across time steps and a non-unitary gain in W is amplified exponentially.,1.1. Vanishing and Exploding Gradients,[0],[0]
"The phenomena of extreme growth or contraction of the gradient across time steps or layers are known as the exploding and the vanishing gradient problems, respectively.",1.1. Vanishing and Exploding Gradients,[0],[0]
"It is sufficient for RNNs to have ηt ≤ 1 at each time t to enable the possibility of vanishing gradients, typically for some large number of time steps T .",1.1. Vanishing and Exploding Gradients,[0],[0]
The rate at which a gradient (or forward signal) vanishes depends on both the parameterization of the model and on the input data.,1.1. Vanishing and Exploding Gradients,[0],[0]
"The parameterization may be conditioned by placing appropriate constraints on W. It is worth keeping in mind that the Jacobian D is typically contractive, thus tending to be norm-reducing) and is also data-dependent, whereas W can vary from being contractive to norm-preserving, to expansive and applies the same gain on the forward signal as on the back-propagated gradient signal.",1.1. Vanishing and Exploding Gradients,[0],[0]
"Vanishing and exploding gradients can be controlled to a large extent by controlling the maximum and minimum gain of W. The maximum gain of a matrix W is given by the spectral norm which is given by
||W||2 = max [ ||Wx|| ||x|| ] .",2. Our Approach,[0],[0]
"(6)
By keeping our weight matrix W close to orthogonal, one can ensure that it is close to a norm-preserving transformation (where the spectral norm is equal to one, but the minimum gain is also one).",2. Our Approach,[0],[0]
"One way to achieve this is via a simple soft constraint or regularization term of the form:
λ ∑ i ||WTi",2. Our Approach,[0],[0]
Wi − I||2.,2. Our Approach,[0],[0]
"(7)
However, it is possible to formulate a more direct parameterization or factorization for W which permits hard bounds on the amount of expansion and contraction induced by W. This can be achieved by simply parameterizing W according to its singular value decomposition, which consists of the composition of orthogonal basis matrices U and V with a diagonal spectral matrix S containing the singular values which are real and positive by defi-
nition.",2. Our Approach,[0],[0]
We have W = USVT .,2. Our Approach,[0],[0]
"(8)
Since the spectral norm or maximum gain of a matrix is equal to its largest singular value, this decomposition allows us to control the maximum gain or expansivity of the weight matrix by controlling the magnitude of the largest singular value.",2. Our Approach,[0],[0]
"Similarly, the minimum gain or contractivity of a matrix can be obtained from the minimum singular value.
",2. Our Approach,[0],[0]
We can keep the bases U and V orthogonal via geodesic gradient descent along the set of weights that satisfy UTU = I and VTV,2. Our Approach,[0],[0]
= I respectively.,2. Our Approach,[0],[0]
The submanifolds that satisfy these constraints are called Stiefel manifolds.,2. Our Approach,[0],[0]
"We discuss how this is achieved in more detail below, then discuss our construction for bounding the singular values.
",2. Our Approach,[0],[0]
"During optimization, in order to maintain the orthogonality of an orthogonally-initialized matrix M, i.e. where M = U, M = V or M = W if so desired, we employ a Cayley transformation of the update step onto the Stiefel manifold of (semi-)orthogonal matrices, as in Nishimori (2005) and Tagare (2011).",2. Our Approach,[0],[0]
"Given an orthogonally-initialized parameter matrix M and its Jacobian, G with respect to the objective function, an update is performed as follows:
A = GMT −MGT
Mnew = M+ (I+ η 2 A)−1(I− η 2 A),
(9)
where A is a skew-symmetric matrix (that depends on the Jacobian and on the parameter matrix) which is mapped to an orthogonal matrix via a Cayley transform and η is the learning rate.
",2. Our Approach,[0],[0]
"While the update rule in (9) allows us to maintain an orthogonal hidden to hidden transition matrix W if desired, we are interested in exploring the effect of stepping away from the Stiefel manifold.",2. Our Approach,[0],[0]
"As such, we parameterize the transition matrix W in factorized form, as a singular value decomposition with orthogonal bases U and V updated by geodesic gradient descent using the Cayley transform approach above.
",2. Our Approach,[0],[0]
"If W is an orthogonal matrix, the singular values in the diagonal matrix S are all equal to one.",2. Our Approach,[0],[0]
"However, in our formulation we allow these singular values to deviate from one and employ a sigmoidal parameterization to apply a hard constraint on the maximum and minimum amount of deviation.",2. Our Approach,[0],[0]
"Specifically, we define a margin m around 1 within which the singular values must lie.",2. Our Approach,[0],[0]
"This is achieved with the parameterization
si = 2m(σ(pi)− 0.5)",2. Our Approach,[0],[0]
"+ 1, si ∈ {diag(S)}, m ∈",2. Our Approach,[0],[0]
"[0, 1].",2. Our Approach,[0],[0]
"(10) The singular values are thus restricted to the range [1−m, 1 +m] and the underlying parameters pi are updated freely via stochastic gradient descent.",2. Our Approach,[0],[0]
"Note that this
parameterization strategy also has implications on the step sizes that gradient descent based optimization will take when updating the singular values – they tend to be smaller compared to models with no margin constraining their values.",2. Our Approach,[0.9571151037516541],"['Note that these results provide optimal convergence rates with respect to κl and γ, but do not imply that γ is the right quantity to consider on general graphs.']"
"Specifically, a singular value’s progression toward a margin is slowed the closer it is to the margin.",2. Our Approach,[0],[0]
The sigmoidal parameterization can also impart another effect on the step size along the spectrum which needs to be accounted for.,2. Our Approach,[0],[0]
"Considering 10, the gradient backpropagation of some loss L toward parameters pi is found as
dL dpi = dsi",2. Our Approach,[0],[0]
dpi dL dsi,2. Our Approach,[0],[0]
= 2m dσ(pi),2. Our Approach,[0],[0]
dpi dL dsi .,2. Our Approach,[0],[0]
"(11)
From (11), it can be seen that the magnitude of the update step for pi is scaled by the margin hyperparameter m .",2. Our Approach,[0],[0]
"This means for example that for margins less than one, the effective learning rate for the spectrum is reduced in proportion to the margin.",2. Our Approach,[0],[0]
"Consequently, we adjust the learning rate along the spectrum to be independent of the margin by renormalizing it by 2m .
",2. Our Approach,[0],[0]
This margin formulation both guarantees singular values lie within a well defined range and slows deviation from orthogonality.,2. Our Approach,[0],[0]
"Alternatively, one could enforce the orthogonality of U and V and impose a regularization term corresponding to a mean one Gaussian prior on these singular values.",2. Our Approach,[0],[0]
This encourages the weight matrix W to be norm preserving with a controllable strength equivalent to the variance of the Gaussian.,2. Our Approach,[0],[0]
We also explore this approach further below.,2. Our Approach,[0],[0]
"In this section, we explore hard and soft orthogonality constraints on factorized weight matrices for recurrent neural network hidden to hidden transitions.",3. Experiments,[0],[0]
"With hard orthogonality constraints on U and V, we investigate the effect of widening the spectral margin or bounds on convergence and performance.",3. Experiments,[0],[0]
Loosening these bounds allows increasingly larger margins within which the transition matrix W can deviate from orthogonality.,3. Experiments,[0],[0]
"We confirm that orthogonal initialization is useful as noted in Henaff et al. (2016), and we show that although strict orthogonality guarantees stable gradient norm, loosening orthogonality constraints can increase the rate of gradient descent convergence.",3. Experiments,[0],[0]
"We begin our analyses on tasks that are designed to stress memory: a sequence copying task and a basic addition task (Hochreiter & Schmidhuber, 1997).",3. Experiments,[0],[0]
"We then move on to tasks on real data that require models to capture long-range dependencies: digit classification based on sequential and permuted MNIST vectors (Le et al., 2015; LeCun et al., 1998).",3. Experiments,[0],[0]
"Finally, we look at a basic language modeling task using the Penn Treebank dataset (Marcus et al., 1993).
",3. Experiments,[0],[0]
"The copy and adding tasks, introduced by Hochreiter &
Schmidhuber (1997), are synthetic benchmarks with pathologically hard long distance dependencies that require long-term memory in models.",3. Experiments,[0],[0]
"The copy task consists of an input sequence that must be remembered by the network, followed by a series of blank inputs terminated by a delimiter that denotes the point at which the network must begin to output a copy of the initial sequence.",3. Experiments,[0],[0]
"We use an input sequence of T + 20 elements that begins with a subsequence of 10 elements to copy, each containing a symbol ai ∈",3. Experiments,[0],[0]
"{a1 , ..., ap} out of p = 8 possible symbols.",3. Experiments,[0],[0]
This sub-sequence is followed by T − 1 elements of the blank category a0 which is terminated at step T by a delimiter symbol ap+1 and 10 more elements of the blank category.,3. Experiments,[0],[0]
"The network must learn to remember the initial 10 element sequence for T time steps and output it after receiving the delimiter symbol.
",3. Experiments,[0],[0]
The goal of the adding task is to add two numbers together after a long delay.,3. Experiments,[0],[0]
Each number is randomly picked at a unique position in a sequence of length T .,3. Experiments,[0],[0]
The sequence is composed of T values sampled from a uniform distribution in the range,3. Experiments,[0],[0]
"[0, 1), with each value paired with an indicator value that identifies the value as one of the two numbers to remember (marked 1) or as a value to ignore (marked 0).",3. Experiments,[0],[0]
"The two numbers are positioned randomly in the sequence, the first in the range",3. Experiments,[0],[0]
"[0, T2 − 1] and the second in the range",3. Experiments,[0],[0]
"[T2 , T",3. Experiments,[0],[0]
"− 1], where 0 marks the first element.",3. Experiments,[0],[0]
"The network must learn to identify and remember the two numbers and output their sum.
",3. Experiments,[0],[0]
"In the sequential MNIST task from Le et al. (2015), MNIST digits are flattened into vectors that can be traversed sequentially by a recurrent neural network.",3. Experiments,[0],[0]
The goal is to classify the digit based on the sequential input of pixels.,3. Experiments,[0],[0]
The simple variant of this task is with a simple flattening of the image matrices; the harder variant of this task includes a random permutation of the pixels in the input vector that is determined once for an experiment.,3. Experiments,[0],[0]
"The latter formulation introduces longer distance dependencies between pixels that must be interpreted by the classification model.
",3. Experiments,[0],[0]
"The English Penn Treebank (PTB) dataset from Marcus et al. (1993) is an annotated corpus of English sentences, commonly used for benchmarking language models.",3. Experiments,[0],[0]
"We employ a sequential character prediction task: given a sentence, a recurrent neural network must predict the next character at each step, from left to right.",3. Experiments,[0],[0]
"We use input sequences of variable length, with each sequence containing one sentence.",3. Experiments,[0],[0]
"We model 49 characters including lowercase letters (all strings are in lowercase), numbers, common punctuation, and an unknown character placeholder.",3. Experiments,[0],[0]
"We use two subsets of the data in our experiments: in the first, we first use 23% of the data with strings with up to 75 characters and in the second we include over 99% of the dataset, picking strings with up to 300 characters.",3. Experiments,[0],[0]
"In this section, we experimentally explore the effect of loosening hard orthogonality constraints through loosening the spectral margin defined above for the hidden to hidden transition matrix.
",3.1. Loosening Hard Orthogonality Constraints,[0],[0]
"In all experiments, we employed RMSprop (Tieleman & Hinton, 2012) when not using geodesic gradient descent.",3.1. Loosening Hard Orthogonality Constraints,[0],[0]
"We used minibatches of size 50 and for generated data (the copy and adding tasks), we assumed an epoch length of 100 minibatches.",3.1. Loosening Hard Orthogonality Constraints,[0],[0]
We cautiously introduced gradient clipping at magnitude 100 (unless stated otherwise) in all of our RNN experiments although it may not be required and we consistently applied a small weight decay of 0.0001.,3.1. Loosening Hard Orthogonality Constraints,[0],[0]
"Unless otherwise specified, we trained all simple recurrent neural networks with the hidden to hidden matrix factorization as in (8) using geodesic gradient descent on the bases (learning rate 10−6) and RMSprop on the other parameters (learning rate 0.0001), using a tanh transition nonlinearity, and clipping gradients of 100 magnitude.",3.1. Loosening Hard Orthogonality Constraints,[0],[0]
"The neural network code was built on the Theano framework (Theano Development Team, 2016).",3.1. Loosening Hard Orthogonality Constraints,[0],[0]
"When parameterizing a matrix in factorized form, we apply the weight decay on the composite matrix rather than on the factors in order to be consistent across experiments.",3.1. Loosening Hard Orthogonality Constraints,[0],[0]
"For MNIST and PTB, hyperparameter selection and early stopping were performed targeting the best validation set accuracy, with results reported on the test set.",3.1. Loosening Hard Orthogonality Constraints,[0],[0]
"For different sequence lengths T of the copy and adding tasks, we trained a factorized RNN with 128 hidden units and various spectral margins m .",3.1.1. CONVERGENCE ON SYNTHETIC MEMORY TASKS,[0],[0]
"For the copy task, we used Elman networks without a transition non-linearity as in Henaff et al. (2016).",3.1.1. CONVERGENCE ON SYNTHETIC MEMORY TASKS,[0],[0]
"We also investigated the use of nonlinearities, as discussed below.
",3.1.1. CONVERGENCE ON SYNTHETIC MEMORY TASKS,[0],[0]
As shown in Figure 1 we see an increase in the rate of convergence as we increase the spectral margin.,3.1.1. CONVERGENCE ON SYNTHETIC MEMORY TASKS,[0],[0]
"This observation generally holds across the tested sequence lengths (T = 200, T = 500, T = 1000, T = 10000); however, large spectral margins hinder convergence on extremely long sequence lengths.",3.1.1. CONVERGENCE ON SYNTHETIC MEMORY TASKS,[0],[0]
"At sequence length T = 10000, parameterizations with spectral margins larger than 0.001 converge slower than when using a margin of 0.001.",3.1.1. CONVERGENCE ON SYNTHETIC MEMORY TASKS,[0],[0]
"In addition, the experiment without a margin failed to converge on the longest sequence length.",3.1.1. CONVERGENCE ON SYNTHETIC MEMORY TASKS,[0],[0]
"This follows the expected pattern where stepping away from the Stiefel manifold may help with gradient descent optimization but loosening orthogonality constraints can reduce the stability of signal propagation through the network.
",3.1.1. CONVERGENCE ON SYNTHETIC MEMORY TASKS,[0],[0]
"For the adding task, we trained a factorized RNN on T = 1000 length sequences, using a ReLU activation function on the hidden to hidden transition matrix.",3.1.1. CONVERGENCE ON SYNTHETIC MEMORY TASKS,[0],[0]
"The mean
squared error (MSE) is shown for different spectral margins in Figure 2.",3.1.1. CONVERGENCE ON SYNTHETIC MEMORY TASKS,[0],[0]
"Testing spectral margins m = 0, m = 1, m = 10, m = 100, and no margin, we find that the models with the purely orthogonal (m = 0) and the unconstrained (no margin) transition matrices failed to begin converging beyond baseline MSE within 2000 epochs.
",3.1.1. CONVERGENCE ON SYNTHETIC MEMORY TASKS,[0],[0]
"We found that nonlinearities such as a rectified linear unit (ReLU) (Nair & Hinton, 2010) or hyperbolic tangent (tanh) made the copy task far more difficult to solve.",3.1.1. CONVERGENCE ON SYNTHETIC MEMORY TASKS,[0],[0]
"Using tanh, a short sequence length (T = 100) copy task required both a soft constraint that encourages orthogonality and thousands of epochs for training.",3.1.1. CONVERGENCE ON SYNTHETIC MEMORY TASKS,[0],[0]
"It is worth noting that in the unitary evolution recurrent neural network of Arjovsky et al. (2015), the non-linearity (referred to as the ”modReLU”) is actually initialized as an identity operation that is free to deviate from identity during training.",3.1.1. CONVERGENCE ON SYNTHETIC MEMORY TASKS,[0],[0]
"Furthermore, Henaff et al. (2016) derive a solution mechanism for the copy task that drops the non-linearity from an RNN.",3.1.1. CONVERGENCE ON SYNTHETIC MEMORY TASKS,[0],[0]
"To explore this further, we experimented with a parametric leaky ReLU activation function (PReLU) which introduces a trainable slope α for negative valued inputs x , producing f (x ) = max(x , 0) + αmin(x , 0) (He et al., 2015).",3.1.1. CONVERGENCE ON SYNTHETIC MEMORY TASKS,[0],[0]
Setting the slope α to one would make the PReLU equivalent to an identity function.,3.1.1. CONVERGENCE ON SYNTHETIC MEMORY TASKS,[0],[0]
"We experimented with clamping α to 0.5, 0.7 or 1 in a factorized RNN with a spectral margin of 0.3 and found that only the model with α = 1 solved the T = 1000 length copy task.",3.1.1. CONVERGENCE ON SYNTHETIC MEMORY TASKS,[0],[0]
"We also experimented with a trainable slope α, initialized to 0.7 and found that it converges to 0.96, further suggesting the optimal solution for
the copy task is without a transition nonlinearity.",3.1.1. CONVERGENCE ON SYNTHETIC MEMORY TASKS,[0],[0]
"Since the copy task is purely a memory task, one may imagine that a transition nonlinearity such as a tanh or ReLU may be detrimental to the task as it can lose information.",3.1.1. CONVERGENCE ON SYNTHETIC MEMORY TASKS,[0],[0]
"Thus, we also tried a recent activation function that preserves information, called an orthogonal permutation linear unit (OPLU) (Chernodub & Nowicki, 2016).",3.1.1. CONVERGENCE ON SYNTHETIC MEMORY TASKS,[0],[0]
"The OPLU preserves norm, making a fully norm-preserving RNN possible.",3.1.1. CONVERGENCE ON SYNTHETIC MEMORY TASKS,[0],[0]
"Interestingly, this activation function allowed us to recover identical results on the copy task to those without a nonlinearity for different spectral margins.",3.1.1. CONVERGENCE ON SYNTHETIC MEMORY TASKS,[0],[0]
"Having confirmed that an orthogonality constraint can negatively impact convergence rate, we seek to investigate the effect on model performance for tasks on real data.",3.1.2. PERFORMANCE ON REAL DATA,[0],[0]
"In Table 1, we show the results of experiments on ordered and permuted sequential MNIST classification tasks and on the PTB character prediction task.
",3.1.2. PERFORMANCE ON REAL DATA,[0],[0]
"For the sequential MNIST experiments, loss curves are shown in Figure 3 and reveal an increased convergence rate for larger spectral margins.",3.1.2. PERFORMANCE ON REAL DATA,[0],[0]
We trained the factorized RNN models with 128 hidden units for 120 epochs.,3.1.2. PERFORMANCE ON REAL DATA,[0],[0]
"We also trained an LSTM with 128 hidden units (tanh activation) on both tasks for 150 epochs, configured with peephole connections, orthogonally initialized (and forget gate bias initialized to one), and trained with RMSprop (learning rate 0.0001, clipping gradients of magnitude 1).
",3.1.2. PERFORMANCE ON REAL DATA,[0],[0]
"For PTB character prediction, we evaluate results in terms of bits per character (bpc) and prediction accuracy.",3.1.2. PERFORMANCE ON REAL DATA,[0],[0]
Prediction results are shown in 1 both for a subset of short sequences (up to 75 characters; 23% of data) and for a subset of long sequences (up to 300 characters; 99% of data).,3.1.2. PERFORMANCE ON REAL DATA,[0],[0]
"We trained factorized RNN models with 512 hidden units for 200 epochs with geodesic gradient descent on the bases (learning rate 10−6) and RMSprop on the other parameters (learning rate 0.001), using a tanh transition nonlinearity, and clipping gradients of 30 magnitude.",3.1.2. PERFORMANCE ON REAL DATA,[0],[0]
"As a rough point of reference, we also trained an LSTM with 512 hidden units for each of the data subsets (configured as for MNIST).",3.1.2. PERFORMANCE ON REAL DATA,[0],[0]
"On sequences up to 75 characters, LSTM performance was
limited by early stopping of training due to overfitting.
",3.1.2. PERFORMANCE ON REAL DATA,[0],[0]
"Interestingly, for both the ordered and permuted sequential MNIST tasks, models with a non-zero margin significantly outperform those that are constrained to have purely orthogonal transition matrices (margin of zero).",3.1.2. PERFORMANCE ON REAL DATA,[0],[0]
"The best results on both the ordered and sequential MNIST tasks were yielded by models with a spectral margin of 0.1, at 94.10% accuracy and 91.44% accuracy, respectively.",3.1.2. PERFORMANCE ON REAL DATA,[0],[0]
"An LSTM outperformed the RNNs in both tasks; nevertheless, RNNs with hidden to hidden transitions initialized as orthogonal matrices performed admirably without a memory component and without all of the additional parameters associated with gates.",3.1.2. PERFORMANCE ON REAL DATA,[0],[0]
"Indeed, orthogonally initialized RNNs performed almost on par with the LSTM in the permuted sequential MNIST task which presents longer distance dependencies than the ordered task.",3.1.2. PERFORMANCE ON REAL DATA,[0],[0]
"Although the optimal margin appears to be 0.1, RNNs with large margins perform almost identically to an RNN without a margin, as long as the transition matrix is initialized as orthogonal.",3.1.2. PERFORMANCE ON REAL DATA,[0],[0]
"On these tasks, orthogonal initialization appears to significantly outperform Glorot normal initialization (Glorot &
Bengio, 2010) or initializing the matrix as identity.",3.1.2. PERFORMANCE ON REAL DATA,[0],[0]
"It is interesting to note that for the MNIST tasks, orthogonal initialization appears useful while orthogonality constraints appear mainly detrimental.",3.1.2. PERFORMANCE ON REAL DATA,[0],[0]
"This suggests that while orthogonality helps early training by stabilizing gradient flow across many time steps, orthogonality constraints may need to be loosened on some tasks so as not to over-constrain the model’s representational ability.
",3.1.2. PERFORMANCE ON REAL DATA,[0],[0]
"Curiously, larger margins and even models without sigmoidal constraints on the spectrum (no margin) performed well as long as they were initialized to be orthogonal, suggesting that evolution away from orthogonality is not a serious problem on MNIST.",3.1.2. PERFORMANCE ON REAL DATA,[0],[0]
It is not surprising that orthogonality is useful for the MNIST tasks since they depend on long distance signal propagation with a single output at the end of the input sequence.,3.1.2. PERFORMANCE ON REAL DATA,[0],[0]
"On the other hand, character prediction with PTB produces an output at every time step.",3.1.2. PERFORMANCE ON REAL DATA,[0],[0]
Constraining deviation from orthogonality proved detrimental for short sentences and beneficial when long sentences were included.,3.1.2. PERFORMANCE ON REAL DATA,[0],[0]
"Furthermore, Glorot normal initialization did not perform worse than orthogonal initialization for PTB.",3.1.2. PERFORMANCE ON REAL DATA,[0],[0]
"Since an output is generated for every character in a sentence, short distance signal propagation is possible.",3.1.2. PERFORMANCE ON REAL DATA,[0],[0]
"Thus it is possible that the RNN is first learning very local dependencies between neighbouring characters and that given enough context, constraining deviation from orthogonality can help force the network to learn longer distance dependencies.",3.1.2. PERFORMANCE ON REAL DATA,[0],[0]
It is interesting to note that even long sequence lengths (T=1000) in the copy task can be solved efficiently with rather large margins on the spectrum.,3.1.3. SPECTRAL AND GRADIENT EVOLUTION,[0],[0]
In Figure 4 we look at the gradient propagation of the loss from the last time step in the network with respect to the hidden activations.,3.1.3. SPECTRAL AND GRADIENT EVOLUTION,[0],[0]
"We can see that for a purely orthogonal parameterization of
the transition matrix (when the margin is zero), the gradient norm is preserved across time steps, as expected.",3.1.3. SPECTRAL AND GRADIENT EVOLUTION,[0],[0]
"We further observe that with increasing margin size, the number of update steps over which this norm preservation survives decreases, though surprisingly not as quickly as expected.
",3.1.3. SPECTRAL AND GRADIENT EVOLUTION,[0],[0]
"Although the deviation of singular values from one should be slowed by the sigmoidal parameterizations, even parameterizations without a sigmoid (no margin) can be effectively trained for all but the longest sequence lengths.",3.1.3. SPECTRAL AND GRADIENT EVOLUTION,[0],[0]
This suggests that the spectrum is not deviating far from orthogonality and that inputs to the hidden to hidden transitions are mostly not aligned along the dimensions of greatest expansion or contraction.,3.1.3. SPECTRAL AND GRADIENT EVOLUTION,[0],[0]
"We evaluated the spread of the spectrum in all of our experiments and found that indeed, singular values tend to stay well within their prescribed bounds and only reach the margin when using a very large learning rate that does not permit convergence.",3.1.3. SPECTRAL AND GRADIENT EVOLUTION,[0],[0]
"Furthermore, when transition matrices are initialized as orthogonal, singular values remain near one throughout training even without a sigmoidal margin for tasks that require long term memory (copy, adding, sequential MNIST).",3.1.3. SPECTRAL AND GRADIENT EVOLUTION,[0],[0]
"On the other hand, singular value distributions tend to drift away from one for PTB character prediction which may help explain why enforcing an orthogonality constraint can be helpful for this task, when modeling long sequences.",3.1.3. SPECTRAL AND GRADIENT EVOLUTION,[0],[0]
"Interestingly, singular values spread out less for longer sequence lengths (nevertheless, the T=10000 copy task could not be solved with no sigmoid on the spectrum).
",3.1.3. SPECTRAL AND GRADIENT EVOLUTION,[0],[0]
We visualize the spread of singular values for different model parameterizations on the permuted sequential MNIST task in Figure 5.,3.1.3. SPECTRAL AND GRADIENT EVOLUTION,[0],[0]
"Curiously, we find that the distribution of singular values tends to shift upward to a mean of approximately 1.05 on both the ordered and permuted sequential MNIST tasks.",3.1.3. SPECTRAL AND GRADIENT EVOLUTION,[0],[0]
"We note that in those experiments, a tanh transition nonlinearity was used which is contractive in both the forward signal pass and the gradient backward pass.",3.1.3. SPECTRAL AND GRADIENT EVOLUTION,[0],[0]
"An upward shift in the distribution of singular val-
ues of the transition matrix would help compensate for that contraction.",3.1.3. SPECTRAL AND GRADIENT EVOLUTION,[0],[0]
"Indeed, (Saxe et al., 2013) describe this as a possibly good regime for learning in deep neural networks.",3.1.3. SPECTRAL AND GRADIENT EVOLUTION,[0],[0]
That the model appears to evolve toward this regime suggests that deviating from it may incur a cost.,3.1.3. SPECTRAL AND GRADIENT EVOLUTION,[0],[0]
This is interesting because the cost function cannot take into account numerical issues such as vanishing or exploding gradients (or forward signals); we do not know what could make this deviation costly.,3.1.3. SPECTRAL AND GRADIENT EVOLUTION,[0],[0]
That the transition matrix may be compensating for the contraction of the tanh is supported by further experiments: applying a 1.05 pre-activation gain appears to allow a model with a margin of 0 to nearly match the top performance reached on both of the MNIST tasks.,3.1.3. SPECTRAL AND GRADIENT EVOLUTION,[0],[0]
"Furthermore, when using the OPLU norm-preserving activation function (Chernodub & Nowicki, 2016), we found that orthogonally initialized models performed equally well with all margins, achieving over 90% accuracy on the permuted sequential MNIST task.",3.1.3. SPECTRAL AND GRADIENT EVOLUTION,[0],[0]
"Unlike orthgonally initialized models, the RNN on the bottom right of Figure 5 with Glorot normal initialized transition matrices begins and ends with a wide singular spectrum.",3.1.3. SPECTRAL AND GRADIENT EVOLUTION,[0],[0]
"While there is no clear positive shift in the distribution of singular values, the mean value appears to very gradually increase for both the ordered and permuted sequential MNIST tasks.",3.1.3. SPECTRAL AND GRADIENT EVOLUTION,[0],[0]
"If the model is to be expected to positively shift singular values to compensate for the contractivity of the tanh nonlinearity, it is not doing so well for the Glorot-initialized case; however, this may be due to the inefficiency of training as a result of vanishing gradients, given that initialization.",3.1.3. SPECTRAL AND GRADIENT EVOLUTION,[0],[0]
"Having established that it may indeed be useful to step away from orthogonality, here we explore two forms of soft constraints (rather than hard bounds as above) on hidden to hidden transition matrix orthogonality.",3.2. Exploring Soft Orthogonality Constraints,[0],[0]
"The first is a simple penalty that directly encourages a transition matrix W to be orthogonal, of the form λ||WTW − I||22.",3.2. Exploring Soft Orthogonality Constraints,[0],[0]
This is similar to the orthogonality penalty introduced by Henaff et al. (2016).,3.2. Exploring Soft Orthogonality Constraints,[0],[0]
"In subfigures (A) and (B) of Figure 6, we explore the effect of weakening this form of regularization.",3.2. Exploring Soft Orthogonality Constraints,[0],[0]
We trained both a regular non-factorized RNN on the T = 200 copy task (A) and a factorized RNN with orthogonal bases on the T = 500 copy task (B).,3.2. Exploring Soft Orthogonality Constraints,[0],[0]
"For the regular RNN, we had to reduce the learning rate to 10−5.",3.2. Exploring Soft Orthogonality Constraints,[0],[0]
"Here again we see that weakening the strength of the orthogonalityencouraging penalty can increase convergence speed.
",3.2. Exploring Soft Orthogonality Constraints,[0],[0]
The second approach we explore replaces the sigmoidal margin parameterization with a mean one Gaussian prior on the singular values.,3.2. Exploring Soft Orthogonality Constraints,[0],[0]
"In subfigures (C) and (D) of Figure 6, we visualize the accuracy on the length 200 copy task, using geoSGD (learning rate 10−6) to keep U and V orthogonal and different strengths γ of a Gaussian prior with mean one on the singular values si",3.2. Exploring Soft Orthogonality Constraints,[0],[0]
: γ ∑ i ||si − 1||2.,3.2. Exploring Soft Orthogonality Constraints,[0],[0]
"We
trained these experiments with regular SGD on the spectrum and other non-orthogonal parameter matrices, using a 10−5 learning rate.",3.2. Exploring Soft Orthogonality Constraints,[0],[0]
We see that strong priors lead to slow convergence.,3.2. Exploring Soft Orthogonality Constraints,[0],[0]
Loosening the strength of the prior makes the optimization more efficient.,3.2. Exploring Soft Orthogonality Constraints,[0],[0]
"Furthermore, we compare a direct parameterization of the spectrum (no sigmoid) in (C) with a sigmoidal parameterization, using a large margin of 1 in (D).",3.2. Exploring Soft Orthogonality Constraints,[0],[0]
"Without the sigmoidal parameterization, optimization quickly becomes unstable; on the other hand, the optimization also becomes unstable if the prior is removed completely in the sigmoidal formulation (margin 1).",3.2. Exploring Soft Orthogonality Constraints,[0],[0]
"These results further motivate the idea that parameterizations that deviate from orthogonality may perform better than purely orthogonal ones, as long as they are sufficiently constrained to avoid instability during training.",3.2. Exploring Soft Orthogonality Constraints,[0],[0]
"We have explored a number of methods for controlling the expansivity of gradients during backpropagation based
learning in RNNs through manipulating orthogonality constraints and regularization on weight matrices.",4. Conclusions,[0],[0]
"Our experiments indicate that while orthogonal initialization may be beneficial, maintaining hard constraints on orthogonality can be detrimental.",4. Conclusions,[0],[0]
"Indeed, moving away from hard constraints on matrix orthogonality can help improve optimization convergence rate and model performance.",4. Conclusions,[0],[0]
"However, we also observe with synthetic tasks that relaxing regularization which encourages the spectral norms of weight matrices to be close to one too much, or allowing bounds on the spectral norms of weight matrices to be too wide, can reverse these gains and may lead to unstable optimization.",4. Conclusions,[0],[0]
We thank the Natural Sciences and Engineeering Research Council (NSERC) of Canada and Samsung for supporting this research.,ACKNOWLEDGMENTS,[0],[0]
It is well known that it is challenging to train deep neural networks and recurrent neural networks for tasks that exhibit long term dependencies.,abstractText,[0],[0]
The vanishing or exploding gradient problem is a well known issue associated with these challenges.,abstractText,[0],[0]
One approach to addressing vanishing and exploding gradients is to use either soft or hard constraints on weight matrices so as to encourage or enforce orthogonality.,abstractText,[0],[0]
Orthogonal matrices preserve gradient norm during backpropagation and may therefore be a desirable property.,abstractText,[0],[0]
"This paper explores issues with optimization convergence, speed and gradient stability when encouraging or enforcing orthogonality.",abstractText,[0],[0]
"To perform this analysis, we propose a weight matrix factorization and parameterization strategy through which we can bound matrix norms and therein control the degree of expansivity induced during backpropagation.",abstractText,[0],[0]
We find that hard constraints on orthogonality can negatively affect the speed of convergence and model performance.,abstractText,[0],[0]
On orthogonality and learning recurrent networks with long term dependencies,title,[0],[0]
"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 92–96 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics
https://doi.org/10.18653/v1/P17-2015",text,[0],[0]
"Natural language processing (NLP) has made significant progress over the last two decades, in particular due to the success of data-driven machine learning methods.",1 Introduction,[0],[0]
"Recently, deep learning has led to another wave of remarkable improvements in NLP and other areas of machine learning and artificial intelligence (AI).",1 Introduction,[0],[0]
"Not surprisingly, many industry players are investing heavily in machine learning and AI to create new products and services (MIT Technology Review, 2016).
",1 Introduction,[0],[0]
"However, translating research into a successful product has its own challenges.",1 Introduction,[0],[0]
"Traditionally, technology transfer is often assumed to happen in a linear transition from pure research to applied research to commercialization (Stokes, 1997).",1 Introduction,[0],[0]
The model assumes that the discoveries from researchers will naturally be picked up by engineers and industry players who will use it to build new products.,1 Introduction,[0],[0]
"In reality, the transfer from research to commercial products is considerably more complex and far from guaranteed.",1 Introduction,[0],[0]
"In fact, many research projects fail to successfully transfer their discoveries to commercial products.
",1 Introduction,[0],[0]
"In this position paper, I highlight some of the reasons why it is so difficult to translate NLP research into successful products.",1 Introduction,[0],[0]
"This paper does not contain any new algorithms, experiments, or results.",1 Introduction,[0],[0]
"Instead, it seeks to share my experience working at the intersection of academic research and industry with the aim to stimulate a discussion how technology transfer of NLP research can be improved.",1 Introduction,[0],[0]
I want to emphasize upfront that the paper is not arguing that all NLP researchers should focus their efforts on building commercial products nor does every new product require a research breakthrough to be successful.,1 Introduction,[0],[0]
"The paper’s aim is rather to discuss how we can improve useinspired basic research that satisfies both the desire for fundamental understanding and considerations of use, sometimes referred to as Pasteur’s quadrant (Stokes, 1997).
",1 Introduction,[0],[0]
The contributions of this paper are twofold.,1 Introduction,[0],[0]
"First, I highlight common obstacles in the path of transferring research into commercial products.",1 Introduction,[0],[0]
"Second, I offer suggestions for increasing the chances of success based on my experience at SAP, the world’s largest enterprise software company.",1 Introduction,[0],[0]
This section highlights challenges in NLP research that make it difficult to translate the results into impactful innovation.,2 Challenges to Innovation,[0],[0]
The first step to creating a successful product is understanding your customers.,2.1 Lack of Value Focus,[0],[0]
"That is why many methodologies for creating new products or business models start with a user persona and how to create value for the user (Ries, 2011; Osterwalder et al., 2014).",2.1 Lack of Value Focus,[0],[0]
"Similarly, to conduct research with practical impact, it is worthwhile to consider what potential applications the research could enable
92
and what the value proposition for a potential user might be.",2.1 Lack of Value Focus,[0],[0]
"The value proposition is closely linked to the user persona and the tasks that she tries to solve in her daily life (Christensen and Raynor, 2013).",2.1 Lack of Value Focus,[0],[0]
"Thus, choosing the right research task is important when aiming for impactful research.",2.1 Lack of Value Focus,[0],[0]
"It is instructive that NLP tasks which solve practical problems, like machine translation or sentiment analysis, have seen significant adoption in commercial applications.",2.1 Lack of Value Focus,[0],[0]
"But many applications that are requested by industry are still beyond the capabilities of current NLP research, for example chatbots that can respond to arbitrary user questions.
",2.1 Lack of Value Focus,[0],[0]
It is also important for researchers to understand that the priorities in industry are different from priorities in academic research.,2.1 Lack of Value Focus,[0],[0]
"In academic research, the priorities are to create contributions to the body of knowledge in the field, e.g., defining a new task, a novel, elegant model, or a new stateof-the-art benchmark result.",2.1 Lack of Value Focus,[0],[0]
In industry the priorities are creating innovative products that delight users and create new revenue streams.,2.1 Lack of Value Focus,[0],[0]
"To have the best of both worlds, researchers should occasionally take a step back and consider what value proposition their work has for people outside the NLP community.",2.1 Lack of Value Focus,[0],[0]
Reproducible research is one of the pillars of the scientific method and thus important to good research work in general.,2.2 Lack of Reproducibility,[0],[0]
But the ability to reproduce a model is also a prerequisite to incorporating it into a product.,2.2 Lack of Reproducibility,[0],[0]
"As NLP models often depend on a complex set of parameters and pre-processing steps which cannot always be explained in all detail in a paper, it is often hard to reproduce other’s results.",2.2 Lack of Reproducibility,[0],[0]
The author himself has his own experience trying to (unsuccessfully) reproduce published results.,2.2 Lack of Reproducibility,[0],[0]
"As problems to reproduce research are seldom reported (but see (Bikel, 2004) for an exception), it is also hard for researchers to find information on how to improve their implementation when they struggle to re-produce published results.",2.2 Lack of Reproducibility,[0],[0]
Data is the fuel that powers machine learning and most of NLP research.,2.3 Lack of (Domain) Data,[0],[0]
"While the “big data” revolution has given us access to large quantities of text data from some domains, for many industry problems there is no or very limited data available to conduct research on.",2.3 Lack of (Domain) Data,[0],[0]
"For example, in my group we have been working on text classi-
fication for customer service tickets.",2.3 Lack of (Domain) Data,[0],[0]
"While there are many datasets available for text classification, these are primarily from newswire or online reviews.",2.3 Lack of (Domain) Data,[0],[0]
"For customer service, there is no public dataset to compare to.",2.3 Lack of (Domain) Data,[0],[0]
"Due to the confidential nature of the data and data privacy concerns, companies who have such data cannot easily release it for research purposes.",2.3 Lack of (Domain) Data,[0],[0]
"Some companies host shared tasks or data science competitions in which they make data available, for example on Kaggle1, but access to data remains one of the biggest obstacles for researcher who want to work on industry problems.
",2.3 Lack of (Domain) Data,[0],[0]
"Even when there is data available from public sources, e.g., from the web, using the data for commercial purposes can be tricky from a legal standpoint.",2.3 Lack of (Domain) Data,[0],[0]
"Crawling data from web (or using corpora created by others in this manner) might be acceptable for research purposes, but when building a commercial product the exact license, copyright, etc. of every data source needs to be checked.",2.3 Lack of (Domain) Data,[0],[0]
"The same holds for publicly available NLP models derived from such data.
",2.3 Lack of (Domain) Data,[0],[0]
"For everyone who believes that working in industry solves all data problem, I note here that working with real data sets has its own challenges.",2.3 Lack of (Domain) Data,[0],[0]
"Real data sets are often small, noisy, scrambled, or otherwise incomplete, making it hard to achieve good results.",2.3 Lack of (Domain) Data,[0],[0]
"To effectively use the data, researchers also have to understand the data schema and the business process behind the data.",2.3 Lack of (Domain) Data,[0],[0]
This can be challenging without and in-depth domain knowledge.,2.3 Lack of (Domain) Data,[0],[0]
"The empirical evaluation of statistical methods on common benchmarks has without a doubt revolutionized NLP (Johnson, 2009).",2.4 Overemphasis on Test Scores,[0],[0]
"However, sometimes the score on the test set is taken as the only factor that determines the success of a piece of research.",2.4 Overemphasis on Test Scores,[0],[0]
"For practical applications, the test score on a benchmark dataset is only one criteria among many when it comes to choosing an algorithm for practical use.",2.4 Overemphasis on Test Scores,[0],[0]
"Other factors include the time and costs required to implement the method, the computational resources required, speed and performance, the ease of integration, support for multi-lingual input, the ability to adapt and customize the method, the ability to incorporate prior knowledge, and the ability to interpret and explain
1https://www.kaggle.com
the model.",2.4 Overemphasis on Test Scores,[0],[0]
"For example, in our text categorization work, we encountered the requirement to accommodate changes in the the output classes, i.e., adding, merging, splitting, and removing classes, without re-training the model from scratch.",2.4 Overemphasis on Test Scores,[0],[0]
These factors are currently underrepresented in NLP research.,2.4 Overemphasis on Test Scores,[0],[0]
"No matter how good an NLP model is, it cannot have practical impact if it is never implemented.",2.5 Difficulty of Adoption,[0],[0]
"But in any application, the NLP model will only be one component in a larger software system.",2.5 Difficulty of Adoption,[0],[0]
How easily the NLP component can work together with the remaining components is important for the ease of adoption of the method into productive applications.,2.5 Difficulty of Adoption,[0],[0]
"Unlike rule-based methods, statistical NLP models often require expensive collection and labeling of data, data pre-processing, model (re-)training, parameter tuning, and monitoring of the model to avoid model staleness.",2.5 Difficulty of Adoption,[0],[0]
"This makes it harder to adopt statistical models in practical applications (Chiticariu et al., 2013).",2.5 Difficulty of Adoption,[0],[0]
The time horizon within which stakeholders expect results is generally shorter in industry projects.,2.6 Timelines,[0],[0]
"While research grants typically run for three to five years, industry research is under pressure to deliver tangible outcomes in less than two years.",2.6 Timelines,[0],[0]
"For projects with actual customers and proof of concepts, timelines are usually not longer than a few months.",2.6 Timelines,[0],[0]
This results in the following chicken and egg problem: it is difficult to produce groundbreaking research within a short time frame but long investments into research are hard to justify if the value the research will ultimately produce is not clear.,2.6 Timelines,[0],[0]
That is why academic research is generally better equipped to focus on fundamental research questions.,2.6 Timelines,[0],[0]
Fundamental research does not exclude practical usage but incremental research that fine-tunes every aspect of the implementation of an NLP model is often better done in industry labs.,2.6 Timelines,[0],[0]
"In this section, I offer some suggestions about how the disconnect between NLP research and commercial products can be reduced.",3 Bridging the Gap,[0],[0]
"The following approach describes the criteria that we typically apply in our team when we evaluate new machine learning use cases, including NLP use cases.
",3.1 A “Recipe” for Qualifying a Research Problem,[0],[0]
"First, we make sure we understand the “job to be done”: what is the business problem, who is the potential user and what problem are we trying to solve?",3.1 A “Recipe” for Qualifying a Research Problem,[0],[0]
"Once we have understood the task, a first question to ask is whether the task actually requires NLP.",3.1 A “Recipe” for Qualifying a Research Problem,[0],[0]
Is the data volume so high that automation is needed?,3.1 A “Recipe” for Qualifying a Research Problem,[0],[0]
Would it be easier or cheaper to solve the task manually?,3.1 A “Recipe” for Qualifying a Research Problem,[0],[0]
Can the task be solved via simple rules?,3.1 A “Recipe” for Qualifying a Research Problem,[0],[0]
"Typically, tasks with high data volume and complex or ambiguous rules are good candidates for NLP.
",3.1 A “Recipe” for Qualifying a Research Problem,[0],[0]
"To ensure that the use cases we work on have practical relevance, we include stakeholders from the lines of business and industry units in the company in any new project right from the beginning and gather feedback from actual customers.
",3.1 A “Recipe” for Qualifying a Research Problem,[0],[0]
"Once we believe that NLP is required, we try to formulate the problem as a machine learning task.",3.1 A “Recipe” for Qualifying a Research Problem,[0],[0]
"The simple template given X, predict Y together with the question what are the inputs and what are the outputs?",3.1 A “Recipe” for Qualifying a Research Problem,[0],[0]
helps significantly to get from a vague idea to a concrete task formulation.,3.1 A “Recipe” for Qualifying a Research Problem,[0],[0]
"At this stage, we can often already map the problem to a standard NLP task, e.g., text classification, sequence tagging, or sequence-to-sequence learning.
",3.1 A “Recipe” for Qualifying a Research Problem,[0],[0]
"Next, we establish whether data is available.",3.1 A “Recipe” for Qualifying a Research Problem,[0],[0]
"If real data is not available easily, can we work with publicly available proxy data?",3.1 A “Recipe” for Qualifying a Research Problem,[0],[0]
"For example for learning to classify customer service tickets, we can start with text classification on public datasets.",3.1 A “Recipe” for Qualifying a Research Problem,[0],[0]
"If it is unlikely that data will be available in the foreseeable future, we do not proceed with a use case.
",3.1 A “Recipe” for Qualifying a Research Problem,[0],[0]
"Next, we make a best guess whether the problem can be solved with the current state of the art in NLP.",3.1 A “Recipe” for Qualifying a Research Problem,[0],[0]
Is there an intuitive regularity in the data which we believe a statistical model could pick up?,3.1 A “Recipe” for Qualifying a Research Problem,[0],[0]
Can we represent the input via meaningful features?,3.1 A “Recipe” for Qualifying a Research Problem,[0],[0]
"Do we have a way to measure the success of the method with a well-defined metric?
",3.1 A “Recipe” for Qualifying a Research Problem,[0],[0]
"Finally, we determine the right approach to execute the use case.",3.1 A “Recipe” for Qualifying a Research Problem,[0],[0]
"If it is a hard problem which needs at least a few more years of research before it becomes useful, we would most likely decide on a research project.",3.1 A “Recipe” for Qualifying a Research Problem,[0],[0]
"We fund external
research projects at top universities around the world, where we provide the research problem and the data and let others try to crack the tough problems.",3.1 A “Recipe” for Qualifying a Research Problem,[0],[0]
"We also sponsor Ph.D. students who are working at SAP during their studies.
",3.1 A “Recipe” for Qualifying a Research Problem,[0],[0]
"If we think that the use case has a strong business case and the technology is mature enough, we will move it to building a proof of concept, and ultimately a commercial product.",3.1 A “Recipe” for Qualifying a Research Problem,[0],[0]
"While this “recipe” for qualifying an NLP use case is simple and common sense, we have found it helpful in prioritizing use cases.
",3.1 A “Recipe” for Qualifying a Research Problem,[0],[0]
Researchers in academia might not have access to a business unit to provide feedback on research ideas but many funding bodies are trying to encourage increased collaborations between industry and academia.,3.1 A “Recipe” for Qualifying a Research Problem,[0],[0]
"The European Union, for example, has specifically funded an initiative, LT-innovate2 to encourage commercial exploitation of NLP research.",3.1 A “Recipe” for Qualifying a Research Problem,[0],[0]
"I believe that a more rigorous application of (software) engineering principles and tools can greatly increase the odds of having practical impact with NLP research.
",3.2 Engineering Approach to NLP,[0],[0]
"To address the problem of reproducibility, I suggest the following.",3.2 Engineering Approach to NLP,[0],[0]
"First, the community should be more stringent about reproducibility.",3.2 Engineering Approach to NLP,[0],[0]
"In some research communities, for example databases, the criteria for reproducible research are a lot stricter.",3.2 Engineering Approach to NLP,[0],[0]
"If the results are not reproducible, the results are generally not considered valid.",3.2 Engineering Approach to NLP,[0],[0]
"However, the large number of parameters and implementation details in NLP systems makes it hard to exactly reproduce published results based on the paper alone.",3.2 Engineering Approach to NLP,[0],[0]
"Therefore, we should encourage the dissemination of results through software tools that make code reproducible.",3.2 Engineering Approach to NLP,[0],[0]
"To reproduce the results in a paper, we essentially need the code, the data, and the parameters of the experimental run that produced the results of the experiment.",3.2 Engineering Approach to NLP,[0],[0]
"Fortunately, the open source community has created great tools that make this possible.",3.2 Engineering Approach to NLP,[0],[0]
"First, social code repository platforms, such as GitHub3, make it easy to share code and data.",3.2 Engineering Approach to NLP,[0],[0]
"In fact, the ease of sharing and contributing to code has arguably accelerated the progress in machine learning significantly.",3.2 Engineering Approach to NLP,[0],[0]
"Second, interactive computational environments,
2http://www.lt-innovate.org 3https://github.com/
such as Jupyter notebooks4, that tie together data, code, and documentation, allow for reproducible results that can easily be shared and published.",3.2 Engineering Approach to NLP,[0],[0]
"Finally, software containers, such as Docker5, allow light-weight virtualization that pulls in all software dependencies and allow the same code to run in a reliable and reproducible manner.",3.2 Engineering Approach to NLP,[0],[0]
"If a Jupyter notebook or Dockerfile is published with the paper, it should be easier for other researchers to reproduce results and integrate them into larger systems.",3.2 Engineering Approach to NLP,[0],[0]
"Projects like CodaLab6 try to build online platforms for reproducible research with similar goals.
",3.2 Engineering Approach to NLP,[0],[0]
"On the problem of data availability, there is already a considerable amount of work in the area of building NLP models in low-resource environments (see for example (Duong et al., 2014; Garrette and Baldridge, 2013; Wang et al., 2015)) which deals with limited data availability.",3.2 Engineering Approach to NLP,[0],[0]
"Techniques like domain adaptation, semi-supervised learning and transfer learning (Pan and Yang, 2010) are extremely relevant to address the problem of data availability for industry applications.",3.2 Engineering Approach to NLP,[0],[0]
"Finally, recent work on learning models from private data (Papernot et al., 2016) and federated learning across many devices (McMahan et al., 2016) appear to be promising directions for practical NLP engineering research.",3.2 Engineering Approach to NLP,[0],[0]
"I believe that there is an opportunity to increase the exchange between industry and the research community by establishing an industry paper submission format, potentially with its own industry track at NLP conferences.",3.3 Industry Papers,[0],[0]
"Such a track could offer a venue to discuss practical challenges in building large-scale NLP systems and deploying NLP models in production settings, such as scalability, trade-offs between accuracy and computational costs, robustness, data quality, etc.",3.3 Industry Papers,[0],[0]
This would help to counter-balance the overemphasis on test scores in pure research papers and aid the adoption of research in industry applications.,3.3 Industry Papers,[0],[0]
"Industry tracks are common in other communities and have strong participation from industry players there.
",3.3 Industry Papers,[0],[0]
4http://jupyter.org/ 5https://www.docker.com/ 6http://codalab.org/,3.3 Industry Papers,[0],[0]
Wagstaff (2012) argues for making machine learning research more relevant.,4 Related Work,[0],[0]
He laments a hyperfocus on UCI benchmark datasets and abstract metrics.,4 Related Work,[0],[0]
"Spector et al. (2012) present Google’s hybrid approach to research, which tries to avoid separation between research and engineering.",4 Related Work,[0],[0]
"Recently, several groups at Google have published papers on practical challenges in deploying machine learning in production (Sculley et al., 2014; McMahan et al., 2013; Breck et al., 2016).",4 Related Work,[0],[0]
Belz (2009) discusses the practical applications of NLP research.,4 Related Work,[0],[0]
Mani (2011) gives suggestions for improving the review process.,4 Related Work,[0],[0]
None of the works provides a detailed discussion on the difficulties in bringing NLP research to commercial products – the main contribution of this paper.,4 Related Work,[0],[0]
I have highlighted difficulties that exist for researchers who try to bring NLP research into commercially products and offered suggestions for improving the odds of commercial success.,5 Conclusion,[0],[0]
I hope that my experience can stimulate creative thought and a healthy discussion in the NLP community.,5 Conclusion,[0],[0]
This paper highlights challenges in industrial research related to translating research in natural language processing into commercial products.,abstractText,[0],[0]
"While the interest in natural language processing from industry is significant, the transfer of research to commercial products is non-trivial and its challenges are often unknown to or underestimated by many researchers.",abstractText,[0],[0]
I discuss current obstacles and provide suggestions for increasing the chances for translating research to commercial success based on my experience in industrial research.,abstractText,[0],[0]
On the Challenges of Translating NLP Research into Commercial Products,title,[0],[0]
"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 79–84 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics
https://doi.org/10.18653/v1/P17-2013",text,[0],[0]
"NLP for studying people has grown rapidly as more than one-third of the human population use social media actively.1 While traditional NLP tasks (e.g. POS tagging, parsing, sentiment analysis) mostly work at the word, sentence, or document level, the increased focus on social scientific applications has shifted attention to new levels of analysis (e.g. user-level and communitylevel) (Koppel et al., 2009; Sarawgi et al., 2011; Schwartz et al., 2013a; Coppersmith et al., 2014; Flekova et al., 2016).
",1 Introduction,[0],[0]
"Figure 1 shows the distribution of two unigrams, ‘the’ and ‘love’ at three levels of analysis.",1 Introduction,[0],[0]
"While both words have zero counts in most messages, ‘the’ starts to look Normal across
1Social Insights; Global social media research summary 2017
users, and both words are approximately Normal at the county level.",1 Introduction,[0],[0]
"Methods performing optimally at the document level may suffer at the user or community level due to this shift in the distribution of lexical features.2
In this paper, we ask a fundamental statistical question: How does the shift in unit-of-analysis from document-level to user-or-community level shift lexical distributions in social media?3",1 Introduction,[0],[0]
"The central limit theorem suggests that count data is better approximated by a Normal distribution as one increases the number of events, or as one aggregates more features (e.g. combining words using LDA topics or hand-built word sets).",1 Introduction,[0],[0]
"However, we do not know how far towards a Normal these new levels of analysis bring us.
",1 Introduction,[0],[0]
Related work.,1 Introduction,[0],[0]
"The question we ask harks back to work from pioneers in corpus-based computational linguistics, including Shannon (1948) who suggested that probabilistic distributions of ngrams could be used to solve a range of communications problems, and Mosteller and Wallace (1963) who found that a negative binomial distribution seemed to model unigram usage by authors of the Federalist Papers.",1 Introduction,[0],[0]
Numerous works have since continued the tradition of examining the distribution of lexical features.,1 Introduction,[0],[0]
"For example, McCallum et al. (1998) compares the results of probabilistic models based on multivariate Bernoulli with those based on multinomial distributions for document classification.",1 Introduction,[0],[0]
"Jansche
2While the distribution of word frequencies (i.e. a Zipfian distribution) is often discussed in NLP, it is important to note that we are focused on the distribution of single features (e.g. words) over documents, users, or communities.
",1 Introduction,[0],[0]
"3While other sources of corpora can also be aggregated to the user- or community-level (e.g. newswire, books), we believe the question of distributions is particularly important in social media because it often contains very short posts and a growing body of work in NLP for social science focuses on social media.
79
(2003) extended this line of work, observing lexical count data often display an extra probability mass concentrated at zero and suggesting ZeroInflated negative binomial distributions can capture this phenomenon better and are easier to implement than alternatives such as overdispersed binomial models.",1 Introduction,[0],[0]
"While these works are numerous, none, to the best of our knowledge, have focused on distributions across social media or at multiple levels of analysis.
",1 Introduction,[0],[0]
Contributions.,1 Introduction,[0],[0]
"Our study is perhaps unconventional in modern computational linguistics due to the elementary nature of our contributions, focusing on understanding the empirical distributions of lexical features in Twitter.",1 Introduction,[0],[0]
"First, we use zeroinflated kernel density estimated plots to show how distributions of different language features (words, LDA topics, and hand-curated word sets) vary with level of analysis (message, user, and county).",1 Introduction,[0],[0]
"Second, we quantify which distributions best describe the different feature types and analysis levels of social media.",1 Introduction,[0],[0]
"Finally, we show the utility of such information, finding that using the appropriate model for each feature type improves Naive Bayes classification results across three common social scientific tasks: sarcasm detection at the message-level, gender identification at the user-level, and political ideology classification at the community-level.",1 Introduction,[0],[0]
"Examining data at three different levels of analysis and across three different lexical feature types (unigrams, data-driven topics, and manual lexica), we seek to (1) visually characterize distributions, (2) empirically test which distributions best fit the data, and (3) evaluate classification models utilizing multiple distributions at each level.",2 Methods,[0],[0]
"Unigrams underlie all data where as each level of analysis
and feature type represent a different degree of aggregation and covariance structure.
",2 Methods,[0],[0]
Data preparation.,2 Methods,[0],[0]
"We start with a set of about two million Twitter posts and supplemental information about the users: their ID, county, and gender.",2 Methods,[0],[0]
"The data was based on that of Volkova et al. (2013), who provide tweet ids and gender, and mapped to counties using the method of Schwartz et al. (2013a).",2 Methods,[0],[0]
We limit our data to users who have used at least 1000 words and counties that have at least 30 users and a total word count of 5000.,2 Methods,[0],[0]
"Applying these constraints, the final set of data consists of 1,639,750 tweets (representing the message-level) from 5,226 users in 420 different counties (representing the community-level).
",2 Methods,[0],[0]
We consider three lexical features that are commonly used in NLP for social science:,2 Methods,[0],[0]
"1- grams (the top 10,000 most common unigrams found with happierFunTokenizing social media tokenizer), 2000 LDA topics downloaded from Schwartz et al. (2013b)), and lexica (64 categories from the linguistic inquiry and word count dictionary (Pennebaker et al., 2007)).",2 Methods,[0],[0]
"Note that the features progress from most sparse (1grams) to least sparse (lexica).
Distributions.",2 Methods,[0],[0]
Figure 2 shows the empirical distributions of different lexical features at different levels of analysis.,2 Methods,[0],[0]
"500 features were sampled from the top 20,000 unigrams 4, 2000 social media LDA topics (Schwartz et al., 2013a), and all 64 categories from the LIWC lexica (Pennebaker et al., 2007).",2 Methods,[0],[0]
"To encode the variables continuously we used relative frequencies for unigrams and lexica (count of word or category divided by count of all words), and probability of topics, calculated from the posterior probabilities from the LDA models.",2 Methods,[0],[0]
"Each line in the kernel density plot
4In social media analyses, the top 20,000 features are often used (Schwartz and Ungar, 2015)
is semi-transparent such that an aggregate trend across multiple features will emerge darkest.",2 Methods,[0],[0]
"As we move along a row ranging specific features (unigrams) to generic features (lexicon), the empirical distribution gradually changes from resembling a “power law” (or binomial distribution with low number of trials and probability of success) to something more “Normal”.",2 Methods,[0],[0]
"Similar shifts are also observed as we move across levels of modeling.
",2 Methods,[0],[0]
We investigate whether the best-fitting distributions vary across the three levels of analysis and three types of lexical features.,2 Methods,[0],[0]
"We consider the following candidate distributions to see how well they fit each of these empirical distributions:
• Continuous Distributions: (a) Power-law, (b), Log-normal and (c) Normal
• Discrete Distributions: (a) Bernoulli, (b) Multinomial, (c) Poisson, and (d) Zero Inflated Poisson
Since most of the distributions outlined above are standard distributions, we only briefly describe the zero-inflated variants which handle excess zero counts.",2 Methods,[0],[0]
Zero-inflated models explicitly model the idea that a distribution does not fully capture the mass at 0 in real world data.,2 Methods,[0],[0]
They assume that the data is generated from two components.,2 Methods,[0],[0]
"The first
component is governed by a Bernoulli distribution that generates excess zeros, while the second component generates counts, some of which also could be zero (Jansche, 2003).",2 Methods,[0],[0]
"We evaluate the distributions we considered by first characterizing the goodness of fit at different levels of analyses and then by their predictive performance on social media prediction tasks, both of which we describe below.",3 Evaluation,[0],[0]
"Following the central limit theorem, we seek to determine across the range levels of analysis and feature types, whether the distribution can be approximated by a Normal.",3.1 Goodness of fit,[0],[0]
"Focusing just on the non-zero portions of data encoded as relative frequencies, we quantify the fit of each candidate distribution to the data.
",3.1 Goodness of fit,[0],[0]
We estimate the parameters for each distribution using MLE on a training data set (i.e. 80% of data).,3.1 Goodness of fit,[0],[0]
"Then, we evaluate their likelihoods of a held-out test dataset, given the estimated parameters.",3.1 Goodness of fit,[0],[0]
"Since we are trying to approximate the discrete distribution with a continuous model, all data were converted to relative frequencies.",3.1 Goodness of fit,[0],[0]
"Finally, the distribution under which the test data is most likely
is chosen as the ’best fit’ distribution.",3.1 Goodness of fit,[0],[0]
"We repeat this 100 times and pick the most likely distribution over all these 100 independent runs.
Results.",3.1 Goodness of fit,[0],[0]
"Table 1 shows the percentage of features in each level that were best fit from an underlying distribution of Normal, Log-Normal, or Power Law.",3.1 Goodness of fit,[0],[0]
"We see empirically that there is a trend toward Normal approximation moving from message to county level, as well as 1grams to lexica.",3.1 Goodness of fit,[0],[0]
"In fact, a majority of lexica at the county-level were best approximated by a Normal distribution.",3.1 Goodness of fit,[0],[0]
"In the previous section, we showed that the distribution of lexical features depends on the scale of analysis considered (for example, the message level or the user level).",3.2 Predictive Power,[0],[0]
"Here, we demonstrate that predictive models which use these lexical features as co-variates can leverage this information to boost predictive performance.",3.2 Predictive Power,[0],[0]
We consider three predictive tasks using a generative predictive model.,3.2 Predictive Power,[0],[0]
"The primary purpose of this evaluation is not to characterize the best distribution at a level or task, but to demonstrate that the choice of distribution assumed when modeling features significantly affects the predictive performance.
",3.2 Predictive Power,[0],[0]
"Predictive Tasks : We consider the following common predictive tasks and also outline details of the datasets considered:
1.",3.2 Predictive Power,[0],[0]
Sarcasm Detection (Message level):,3.2 Predictive Power,[0],[0]
"This task consists of determining whether tweets contain a sarcastic expression (Bamman and Smith, 2015).",3.2 Predictive Power,[0],[0]
"The dataset consists of 16,833 messages with an average of 12 words per message.
2.",3.2 Predictive Power,[0],[0]
"Gender Identification (User level): This task involves determining the gender of the author utilizing a previously described Twitter dataset (Volkova et al., 2013).",3.2 Predictive Power,[0],[0]
"This dataset consists of 5,044 users each of which have
at least a 1,000 tokens as is standard in userlevel analyses (Schwartz et al., 2013b).
3.",3.2 Predictive Power,[0],[0]
Ideology Classification (Community level): We utilized county voting records from 2012 along with a dataset of tweets mapped to counties.,3.2 Predictive Power,[0],[0]
"This data consists of 2,175 counties with atleast 10,000 unigrams as is common in community level analyses (Eichstaedt et al., 2015).
",3.2 Predictive Power,[0],[0]
"We consider a Naive Bayes classifier (a generative model) which enables one to directly incorporate the inferred feature distribution at a particular level of analysis, the results of which we discuss in Table 2.",3.2 Predictive Power,[0],[0]
"Variable encoding for the classifiers varied from binary encoding of present or not (Bernoulli), to counts (Poisson, Zero-inflated Poisson), multivariate counts (Multinomial), and continuous relative frequencies (Normal).",3.2 Predictive Power,[0],[0]
"All distributions have closed form MLE solutions except for Zero-Inflated Poisson, in which case we used LBFGS optimization to fit both of its parameters (Head and Zerner, 1985).
",3.2 Predictive Power,[0],[0]
Results.,3.2 Predictive Power,[0],[0]
We report macro F1-score for each of the underlying distributions in Table 2.,3.2 Predictive Power,[0],[0]
"For each of the tasks, we used 80% of the data for training and evaluate on the held-out 20%.",3.2 Predictive Power,[0],[0]
"We observe a similar pattern as that observed in the goodness of fit setting, with a shift in the best performing distribution from Bernoulli (which simply models if a feature exists or not) toward something more Gaussian (Poisson or Normal) as we move along from message-level to county-level analysis and from unigrams to lexica.",3.2 Predictive Power,[0],[0]
"Specifically note that at higher levels of analysis (at user and county levels) as the distribution of features becomes closer to Normal, modeling features as Bernoulli is clearly sub-optimal where as at the message level modeling unigrams as a Bernoulli is superior.",3.2 Predictive Power,[0],[0]
"These observations underscore the main insight that the distribution family used to model features can be con-
sidered a function of level of analysis and featuretype considered and has a significant bearing on predictive performance.",3.2 Predictive Power,[0],[0]
"While computational linguistics has a long history of studying the distributions of lexical features, social media and social scientific studies have brought about a need to understand how these change at multiple levels of analyses.",4 Conclusion,[0],[0]
"Here, we explored empirical distributions of different types of linguistic features (unigrams, topics, lexica) in three different levels of analysis in Twitter data (message, user, and community).",4 Conclusion,[0],[0]
"To show which distribution can better describe features of different levels, we approached the problem in three different ways: (1) visualization of empirical distributions, (2) goodness-of-fit comparisons, and (3) for predictive tasks.
",4 Conclusion,[0],[0]
"We showed that the best-fit distribution depends on feature-type (i.e. unigram versus lexica) and the level of analysis (i.e. message-, user-, or community-level).",4 Conclusion,[0],[0]
"Following the central limit theorem, all user-level features were predominantly Log-normal, while a power law best fit unigrams at the message level and a Normal distribution best approximated lexica at the community level.",4 Conclusion,[0],[0]
"Finally, we demonstrated that predictive performance can also vary considerably by the level of analysis and feature-type, following a similar trend from Bernoulli distributions at the messagelevel to Poisson or Normal at the community-level.",4 Conclusion,[0],[0]
Our results underscore the significance of the level of analysis for the ever-growing focus in NLP on social scientific problems which seek to not only better model words and documents but also the people and communities generating them.,4 Conclusion,[0],[0]
"This work was supported in part by the Templeton Religion Trust, Grant TRT-0048.",Acknowledgements,[0],[0]
Natural language processing has increasingly moved from modeling documents and words toward studying the people behind the language.,abstractText,[0],[0]
This move to working with data at the user or community level has presented the field with different characteristics of linguistic data.,abstractText,[0],[0]
"In this paper, we empirically characterize various lexical distributions at different levels of analysis, showing that, while most features are decidedly sparse and non-normal at the message-level (as with traditional NLP), they follow the central limit theorem to become much more Log-normal or even Normal at the userand county-levels.",abstractText,[0],[0]
"Finally, we demonstrate that modeling lexical features for the correct level of analysis leads to marked improvements in common social scientific prediction tasks.",abstractText,[0],[0]
On the Distribution of Lexical Features at Multiple Levels of Analysis,title,[0],[0]
"(1) The complexity of the computed function grows exponentially with depth. We design measures of expressivity that capture the non-linearity of the computed function. Due to how the network transforms its input, these measures grow exponentially with depth.
(2) All weights are not equal (initial layers matter more). We find that trained networks are far more sensitive to their lower (initial) layer weights: they are much less robust to noise in these layer weights, and also perform better when these weights are optimized well.
(3) Trajectory Regularization works like Batch Normalization. We find that batch norm stabilizes the learnt representation, and based on this propose a new regularization scheme, trajectory regularization.",text,[0],[0]
"Deep neural networks have proved astoundingly effective at a wide range of empirical tasks, from image classification (Krizhevsky et al., 2012) to playing Go (Silver et al., 2016), and even modeling human learning (Piech et al., 2015).
",1. Introduction,[0],[0]
1Cornell University 2Google Brain 3Stanford University.,1. Introduction,[0],[0]
"Correspondence to: Maithra Raghu <maithrar@gmail.com>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"Despite these successes, understanding of how and why neural network architectures achieve their empirical successes is still lacking.",1. Introduction,[0],[0]
"This includes even the fundamental question of neural network expressivity, how the architectural properties of a neural network (depth, width, layer type) affect the resulting functions it can compute, and its ensuing performance.
",1. Introduction,[0],[0]
"This is a foundational question, and there is a rich history of prior work addressing expressivity in neural networks.",1. Introduction,[0],[0]
"However, it has been challenging to derive conclusions that provide both theoretical generality with respect to choices of architecture as well as meaningful insights into practical performance.
",1. Introduction,[0],[0]
"Indeed, the very first results on this question take a highly theoretical approach, from using functional analysis to show universal approximation results (Hornik et al., 1989; Cybenko, 1989), to analysing expressivity via comparisons to boolean circuits (Maass et al., 1994) and studying network VC dimension (Bartlett et al., 1998).",1. Introduction,[0],[0]
"While these results provided theoretically general conclusions, the shallow networks they studied are very different from the deep models that have proven so successful in recent years.
",1. Introduction,[0],[0]
"In response, several recent papers have focused on understanding the benefits of depth for neural networks (Pascanu et al., 2013; Montufar et al., 2014; Eldan and Shamir, 2015; Telgarsky, 2015; Martens et al., 2013; Bianchini and Scarselli, 2014).",1. Introduction,[0],[0]
"These results are compelling and take modern architectural changes into account, but they only show that a specific choice of weights for a deeper network results in inapproximability by a shallow (typically one or two hidden layers) network.
",1. Introduction,[0],[0]
"In particular, the goal of this new line of work has been to establish lower bounds — showing separations between shallow and deep networks — and as such they are based on hand-coded constructions of specific network weights.",1. Introduction,[0],[0]
"Even if the weight values used in these constructions are robust to small perturbations (as in (Pascanu et al., 2013; Montufar et al., 2014)), the functions that arise from these constructions tend toward extremal properties by design, and there is no evidence that a network trained on data ever resembles such a function.
",1. Introduction,[0],[0]
"This has meant that a set of fundamental questions about
ar X
iv :1
60 6.
05 33
6v 6
[ st
at .M
L ]
1 8
Ju n
20 17
neural network expressivity has remained largely unanswered.",1. Introduction,[0],[0]
"First, we lack a good understanding of the “typical” case rather than the worst case in these bounds for deep networks, and consequently have no way to evaluate whether the hand-coded extremal constructions provide a reflection of the complexity encountered in more standard settings.",1. Introduction,[0],[0]
"Second, we lack an understanding of upper bounds to match the lower bounds produced by this prior work; do the constructions used to date place us near the limit of the expressive power of neural networks, or are there still large gaps?",1. Introduction,[0],[0]
"Finally, if we had an understanding of these two issues, we might begin to draw connections between network expressivity and observed performance.
",1. Introduction,[0],[0]
"Our contributions: Measures of Expressivity and their Applications In this paper, we address this set of challenges by defining and analyzing an interrelated set of measures of expressivity for neural networks; our framework applies to a wide range of standard architectures, independent of specific weight choices.",1. Introduction,[0],[0]
"We begin our analysis at the start of training, after random initialization, and later derive insights connecting network expressivity and performance.
",1. Introduction,[0],[0]
"Our first measure of expressivity is based on the notion of an activation pattern: in a network where the units compute functions based on discrete thresholds, we can ask which units are above or below their thresholds (i.e. which units are “active” and which are not).",1. Introduction,[0],[0]
"For the range of standard architectures that we consider, the network is essentially computing a linear function once we fix the activation pattern; thus, counting the number of possible activation patterns provides a concrete way of measuring the complexity beyond linearity that the network provides.",1. Introduction,[0],[0]
"We give an upper bound on the number of possible activation patterns, over any setting of the weights.",1. Introduction,[0],[0]
"This bound is tight as it matches the hand-constructed lower bounds of earlier work (Pascanu et al., 2013; Montufar et al., 2014).
",1. Introduction,[0],[0]
"Key to our analysis is the notion of a transition, in which changing an input x to a nearby input x + δ changes the activation pattern.",1. Introduction,[0],[0]
We study the behavior of transitions as we pass the input along a one-dimensional parametrized trajectory x(t).,1. Introduction,[0],[0]
"Our central finding is that the trajectory length grows exponentially in the depth of the network.
",1. Introduction,[0],[0]
"Trajectory length serves as a unifying notion in our measures of expressivity, and it leads to insights into the behavior of trained networks.",1. Introduction,[0],[0]
"Specifically, we find that the exponential growth in trajectory length as a function of depth implies that small adjustments in parameters lower in the network induce larger changes than comparable adjustments higher in the network.",1. Introduction,[0],[0]
"We demonstrate this phenomenon through experiments on MNIST and CIFAR-10, where the network displays much less robustness to noise
in the lower layers, and better performance when they are trained well.",1. Introduction,[0],[0]
"We also explore the effects of regularization methods on trajectory length as the network trains and propose a less computationally intensive method of regularization, trajectory regularization, that offers the same performance as batch normalization.
",1. Introduction,[0],[0]
"The contributions of this paper are thus:
(1) Measures of expressivity: We propose easily computable measures of neural network expressivity that capture the expressive power inherent in different neural network architectures, independent of specific weight settings.
",1. Introduction,[0],[0]
"(2) Exponential trajectories: We find an exponential depth dependence displayed by these measures, through a unifying analysis in which we study how the network transforms its input by measuring trajectory length
(3) All weights are not equal (the lower layers matter more): We show how these results on trajectory length suggest that optimizing weights in lower layers of the network is particularly important.
(4) Trajectory Regularization Based on understanding the effect of batch norm on trajectory length, we propose a new method of regularization, trajectory regularization, that offers the same advantages as batch norm, and is computationally more efficient.
",1. Introduction,[0],[0]
"In prior work (Poole et al., 2016), we studied the propagation of Riemannian curvature through random networks by developing a mean field theory approach.",1. Introduction,[0],[0]
"Here, we take an approach grounded in computational geometry, presenting measures with a combinatorial flavor and explore the consequences during and after training.",1. Introduction,[0],[0]
"Given a neural network of a certain architecture A (some depth, width, layer types), we have an associated function, FA(x;W ), where x is an input and W represents all the parameters of the network.",2. Measures of Expressivity,[0],[0]
"Our goal is to understand how the behavior of FA(x;W ) changes asA changes, for values of W that we might encounter during training, and across inputs x.
The first major difficulty comes from the high dimensionality of the input.",2. Measures of Expressivity,[0],[0]
Precisely quantifying the properties of FA(x;W ) over the entire input space is intractable.,2. Measures of Expressivity,[0],[0]
"As a tractable alternative, we study simple one dimensional trajectories through input space.",2. Measures of Expressivity,[0],[0]
"More formally:
Definition:",2. Measures of Expressivity,[0],[0]
"Given two points, x0, x1 ∈ Rm, we say x(t) is a trajectory (between x0 and x1) if x(t) is a curve
parametrized by a scalar t ∈",2. Measures of Expressivity,[0],[0]
"[0, 1], with x(0) = x0 and x(1) =",2. Measures of Expressivity,[0],[0]
"x1.
",2. Measures of Expressivity,[0],[0]
"Simple examples of a trajectory would be a line (x(t) = tx1 + (1 − t)x0) or a circular arc (x(t) = cos(πt/2)x0 + sin(πt/2)x1), but in general x(t) may be more complicated, and potentially not expressible in closed form.
",2. Measures of Expressivity,[0],[0]
"Armed with this notion of trajectories, we can begin to define measures of expressivity of a network FA(x;W ) over trajectories x(t).",2. Measures of Expressivity,[0],[0]
"In (Montufar et al., 2014) the notion of a “linear region” is introduced.",2.1. Neuron Transitions and Activation Patterns,[0],[0]
"Given a neural network with piecewise linear activations (such as ReLU or hard tanh), the function it computes is also piecewise linear, a consequence of the fact that composing piecewise linear functions results in a piecewise linear function.",2.1. Neuron Transitions and Activation Patterns,[0],[0]
"So one way to measure the “expressive power” of different architectures A is to count the number of linear pieces (regions), which determines how nonlinear the function is.
",2.1. Neuron Transitions and Activation Patterns,[0],[0]
"In fact, a change in linear region is caused by a neuron transition in the output layer.",2.1. Neuron Transitions and Activation Patterns,[0],[0]
"More precisely:
Definition For fixed W , we say a neuron with piecewise linear region transitions between inputs x, x+ δ if its activation function switches linear region between x and x+δ.
",2.1. Neuron Transitions and Activation Patterns,[0],[0]
So a ReLU transition would be given by a neuron switching from off to on (or vice versa) and for hard tanh by switching between saturation at −1 to its linear middle region to saturation at 1.,2.1. Neuron Transitions and Activation Patterns,[0],[0]
"For any generic trajectory x(t), we can thus define T (FA(x(t);W )) to be the number of transitions undergone by output neurons (i.e. the number of linear regions) as we sweep the input x(t).",2.1. Neuron Transitions and Activation Patterns,[0],[0]
"Instead of just concentrating on the output neurons however, we can look at this pattern over the entire network.",2.1. Neuron Transitions and Activation Patterns,[0],[0]
"We call this an activation patten:
Definition We can defineAP(FA(x;W )) to be the activation pattern – a string of form {0, 1}num neurons (for ReLUs) and {−1, 0, 1}num neurons (for hard tanh) of the network encoding the linear region of the activation function of every neuron, for an input x and weights W .
",2.1. Neuron Transitions and Activation Patterns,[0],[0]
"Overloading notation slightly, we can also define (similarly to transitions) A(FA(x(t);W ))",2.1. Neuron Transitions and Activation Patterns,[0],[0]
as the number of distinct activation patterns as we sweep x along x(t).,2.1. Neuron Transitions and Activation Patterns,[0],[0]
"As each distinct activation pattern corresponds to a different linear function of the input, this combinatorial measure captures how much more expressive A is over a simple linear mapping.
",2.1. Neuron Transitions and Activation Patterns,[0],[0]
"Returning to Montufar et al, they provide a construction i.e. a specific set of weights W0, that results in an exponen-
tial increase of linear regions with the depth of the architectures.",2.1. Neuron Transitions and Activation Patterns,[0],[0]
"They also appeal to Zaslavsky’s theorem (Stanley, 2011) from the theory of hyperplane arrangements to show that a shallow network, i.e. one hidden layer, with the same number of parameters as a deep network, has a much smaller number of linear regions than the number achieved by their choice of weights W0 for the deep network.
",2.1. Neuron Transitions and Activation Patterns,[0],[0]
"More formally, letting A1 be a fully connected network with one hidden layer, and Al a fully connected network with the same number of parameters, but l hidden layers, they show
∀WT (FA1([0, 1];W ))",2.1. Neuron Transitions and Activation Patterns,[0],[0]
"< T (FA1([0, 1];W0) (*)
",2.1. Neuron Transitions and Activation Patterns,[0],[0]
"We derive a much more general result by considering the ‘global’ activation patterns over the entire input space, and prove that for any fully connected network, with any number of hidden layers, we can upper bound the number of linear regions it can achieve, over all possible weight settings W .",2.1. Neuron Transitions and Activation Patterns,[0],[0]
"This upper bound is asymptotically tight, matched by the construction given in (Montufar et al., 2014).",2.1. Neuron Transitions and Activation Patterns,[0],[0]
"Our result can be written formally as:
Theorem 1.",2.1. Neuron Transitions and Activation Patterns,[0],[0]
"(Tight) Upper Bound for Number of Activation Patterns Let A(n,k) denote a fully connected network with n hidden layers of width k, and inputs in Rm.",2.1. Neuron Transitions and Activation Patterns,[0],[0]
"Then the number of activation patterns A(FAn,k(Rm;W ) is upper bounded byO(kmn) for ReLU activations, andO((2k)mn) for hard tanh.
",2.1. Neuron Transitions and Activation Patterns,[0],[0]
From this we can derive a chain of inequalities.,2.1. Neuron Transitions and Activation Patterns,[0],[0]
"Firstly, from the theorem above we find an upper bound of A(FAn,k(Rm;W ))",2.1. Neuron Transitions and Activation Patterns,[0],[0]
"over all W , i.e.
∀W A(FA(n,k))(R m;W ) ≤",2.1. Neuron Transitions and Activation Patterns,[0],[0]
"U(n, k,m).
",2.1. Neuron Transitions and Activation Patterns,[0],[0]
"Next, suppose we haveN neurons in total.",2.1. Neuron Transitions and Activation Patterns,[0],[0]
"Then we want to compare (for wlog ReLUs), quantities like U(n′, N/n′,m) for different n′.
But U(n′, N/n′,m) = O((N/n′)mn ′ ), and so, noting that the maxima of ( a x )mx (for a > e) is x = a/e, we get, (for n, k > e), in comparison to (*),
U(1, N,m) < U(2, N
2 ,m) < · · ·
· · · < U(n− 1, N n− 1 ,m) <",2.1. Neuron Transitions and Activation Patterns,[0],[0]
"U(n, k,m)
",2.1. Neuron Transitions and Activation Patterns,[0],[0]
We prove this via an inductive proof on regions in a hyperplane arrangement.,2.1. Neuron Transitions and Activation Patterns,[0],[0]
The proof can be found in the Appendix.,2.1. Neuron Transitions and Activation Patterns,[0],[0]
"As noted in the introduction, this result differs from earlier lower-bound constructions in that it is an upper bound that applies to all possible sets of weights.",2.1. Neuron Transitions and Activation Patterns,[0],[0]
"Via our analysis, we also prove
-1 0 1 x0
-1
0 1 x 1 Layer 0
-1 0 1 x0
-1
0
1 Layer 1
-1 0 1 x0
-1
0
1 Layer 2
Figure 1.",2.1. Neuron Transitions and Activation Patterns,[0],[0]
Deep networks with piecewise linear activations subdivide input space into convex polytopes.,2.1. Neuron Transitions and Activation Patterns,[0],[0]
"We take a three hidden layer ReLU network, with input x ∈ R2, and four units in each layer.",2.1. Neuron Transitions and Activation Patterns,[0],[0]
The left pane shows activations for the first layer only.,2.1. Neuron Transitions and Activation Patterns,[0],[0]
"As the input is in R2, neurons in the first hidden layer have an associated line in R2, depicting their activation boundary.",2.1. Neuron Transitions and Activation Patterns,[0],[0]
The left pane thus has four such lines.,2.1. Neuron Transitions and Activation Patterns,[0],[0]
"For the second hidden layer each neuron again has a line in input space corresponding to on/off, but this line is different for each region described by the first layer activation pattern.",2.1. Neuron Transitions and Activation Patterns,[0],[0]
"So in the centre pane, which shows activation boundary lines corresponding to second hidden layer neurons in green (and first hidden layer in black), we can see the green lines ‘bend’ at the boundaries.",2.1. Neuron Transitions and Activation Patterns,[0],[0]
(The reason for this bending becomes apparent through the proof of Theorem 2.),2.1. Neuron Transitions and Activation Patterns,[0],[0]
"Finally, the right pane adds the on/off boundaries for neurons in the third hidden layer, in purple.",2.1. Neuron Transitions and Activation Patterns,[0],[0]
"These lines can bend at both black and green boundaries, as the image shows.",2.1. Neuron Transitions and Activation Patterns,[0],[0]
"This final set of convex polytopes corresponds to all activation patterns for this network (with its current set of weights) over the unit square, with each polytope representing a different linear function.
",2.1. Neuron Transitions and Activation Patterns,[0],[0]
Theorem 2.,2.1. Neuron Transitions and Activation Patterns,[0],[0]
"Regions in Input Space Given the corresponding function of a neural network FA(Rm;W ) with ReLU or hard tanh activations, the input space is partitioned into convex polytopes, with FA(Rm;W ) corresponding to a different linear function on each region.
",2.1. Neuron Transitions and Activation Patterns,[0],[0]
This result is of independent interest for optimization – a linear function over a convex polytope results in a well behaved loss function and an easy optimization problem.,2.1. Neuron Transitions and Activation Patterns,[0],[0]
"Understanding the density of these regions during the training process would likely shed light on properties of the loss surface, and improved optimization methods.",2.1. Neuron Transitions and Activation Patterns,[0],[0]
A picture of a network’s regions is shown in Figure 1.,2.1. Neuron Transitions and Activation Patterns,[0],[0]
We empirically tested the growth of the number of activations and transitions as we varied x along x(t) to understand their behavior.,2.1.1. EMPIRICALLY COUNTING TRANSITIONS,[0],[0]
"We found that for bounded non linearities, especially tanh and hard-tanh, not only do we observe exponential growth with depth (as hinted at by the upper bound) but that the scale of parameter initialization also affects the observations (Figure 2).",2.1.1. EMPIRICALLY COUNTING TRANSITIONS,[0],[0]
"We also experimented with sweeping the weights W of a layer through a trajectory W (t), and counting the different labellings output by the network.",2.1.1. EMPIRICALLY COUNTING TRANSITIONS,[0],[0]
"This ‘dichotomies’ measure is discussed further in the Appendix, and also exhibits the same growth properties, Figure 14.",2.1.1. EMPIRICALLY COUNTING TRANSITIONS,[0],[0]
"In fact, there turns out to be a reason for the exponential growth with depth, and the sensitivity to initialization scale.",2.2. Trajectory Length,[0],[0]
"Returning to our definition of trajectory, we can define an immediately related quantity, trajectory length
Definition:",2.2. Trajectory Length,[0],[0]
"Given a trajectory, x(t), we define its length, l(x(t)), to be the standard arc length:
l(x(t)) = ∫",2.2. Trajectory Length,[0],[0]
t ∣∣∣∣∣∣∣∣dx(t)dt,2.2. Trajectory Length,[0],[0]
∣∣∣∣∣∣∣∣,2.2. Trajectory Length,[0],[0]
"dt
Intuitively, the arc length breaks x(t) up into infinitesimal intervals and sums together the Euclidean length of these intervals.
",2.2. Trajectory Length,[0],[0]
"If we letA(n,k) denote, as before, fully connected networks with n hidden layers each of width k, and initializing with weights ∼ N (0, σ2w/k) (accounting for input scaling as typical), and biases ∼ N (0, σ2b ), we find that: Theorem 3.",2.2. Trajectory Length,[0],[0]
"Bound on Growth of Trajectory Length Let FA(x
′,W ) be a ReLU or hard tanh random neural network and x(t) a one dimensional trajectory with x(t+ δ) having a non trival perpendicular component to x(t) for all t, δ
(i.e, not a line).",2.2. Trajectory Length,[0],[0]
Then defining z(d)(x(t)),2.2. Trajectory Length,[0],[0]
"= z(d)(t) to be the image of the trajectory in layer d of the network, we have
(a)
E [ l(z(d)(t)) ]",2.2. Trajectory Length,[0],[0]
"≥ O ( σw √ k√
k + 1
)d l(x(t))
for ReLUs
(b)
",2.2. Trajectory Length,[0],[0]
E [ l(z(d)(t)) ],2.2. Trajectory Length,[0],[0]
"≥ O  σw√k√ σ2w + σ 2 b + k √ σ2w + σ 2 b d l(x(t)) for hard tanh
That is, l(x(t) grows exponentially with the depth of the network, but the width only appears as a base (of the exponent).",2.2. Trajectory Length,[0],[0]
"This bound is in fact tight in the limits of large σw and k.
A schematic image depicting this can be seen in Figure 3 and the proof can be found in the Appendix.",2.2. Trajectory Length,[0],[0]
"A rough outline is as follows: we look at the expected growth of the difference between a point z(d)(t) on the curve and a small perturbation z(d)(t+dt), from layer d to layer d+1.",2.2. Trajectory Length,[0],[0]
"Denoting this quantity
∣∣∣∣δz(d)(t)∣∣∣∣, we derive a recurrence relating ∣∣∣∣δz(d+1)(t)∣∣∣∣ and ∣∣∣∣δz(d)(t)∣∣∣∣ which can be composed to give the desired growth rate.
",2.2. Trajectory Length,[0],[0]
The analysis is complicated by the statistical dependence on the image of the input z(d+1)(t).,2.2. Trajectory Length,[0],[0]
"So we instead form a recursion by looking at the component of the difference perpendicular to the image of the input in that layer, i.e.
∣∣∣∣∣∣δz(d+1)⊥",2.2. Trajectory Length,[0],[0]
"(t)∣∣∣∣∣∣, which results in the condition on x(t) in the statement.
",2.2. Trajectory Length,[0],[0]
"In Figures 4, 12, we see the growth of an input trajectory for ReLU networks on CIFAR-10 and MNIST.",2.2. Trajectory Length,[0],[0]
The CIFAR10 network is convolutional but we observe that these layers also result in similar rates of trajectory length increases to the fully connected layers.,2.2. Trajectory Length,[0],[0]
"We also see, as would be expected, that pooling layers act to reduce the trajectory length.",2.2. Trajectory Length,[0],[0]
"We discuss upper bounds in the Appendix.
",2.2. Trajectory Length,[0],[0]
"For the hard tanh case (and more generally any bounded non-linearity), we can formally prove the relation of trajectory length and transitions under an assumption: assume that while we sweep x(t) all neurons are saturated unless transitioning saturation endpoints, which happens very rapidly.",2.2. Trajectory Length,[0],[0]
(This is the case for e.g. large initialization scales).,2.2. Trajectory Length,[0],[0]
"Then we have:
Theorem 4.",2.2. Trajectory Length,[0],[0]
"Transitions proportional to trajectory length Let FAn,k be a hard tanh network with n hidden layers each of width k. And let
g(k, σw, σb, n) =",2.2. Trajectory Length,[0],[0]
"O  √k√ 1 +
σ2b σ2w
n
Then T (FAn,k(x(t);W ) = O(g(k, σw, σb, n)) for W initialized with weight and bias scales σw, σb.
Note that the expression for g(k, σw, σb, n) is exactly the expression given by Theorem 3 when σw is very large and dominates σb.",2.2. Trajectory Length,[0],[0]
"We can also verify this experimentally in settings where the simpilfying assumption does not hold, as in Figure 5.",2.2. Trajectory Length,[0],[0]
"Here we explore the insights gained from applying our measurements of expressivity, particularly trajectory length, to understand network performance.",3. Insights from Network Expressivity,[0],[0]
"We examine the connection of expressivity and stability, and inspired by this, propose a new method of regularization, trajectory
regularization that offers the same advantages as the more computationally intensive batch normalization.",3. Insights from Network Expressivity,[0],[0]
The analysis of network expressivity offers interesting takeaways related to the parameter and functional stability of a network.,3.1. Expressivity and Network Stability,[0],[0]
"From the proof of Theorem 3, we saw that a perturbation to the input would grow exponentially in the depth of the network.",3.1. Expressivity and Network Stability,[0],[0]
"It is easy to see that this analysis is not limited to the input layer, but can be applied to any layer.",3.1. Expressivity and Network Stability,[0],[0]
"In this form, it would say
A perturbation at a layer grows exponentially in the remaining depth after that layer.
",3.1. Expressivity and Network Stability,[0],[0]
"This means that perturbations to weights in lower layers should be more costly than perturbations in the upper layers, due to exponentially increasing magnitude of noise, and result in a much larger drop of accuracy.",3.1. Expressivity and Network Stability,[0],[0]
"Figure 6, in which we train a conv network on CIFAR-10 and add noise of varying magnitudes to exactly one layer, shows exactly this.
",3.1. Expressivity and Network Stability,[0],[0]
"We also find that the converse (in some sense) holds: after initializing a network, we trained a single layer at different depths in the network and found monotonically increasing performance as layers lower in the network were trained.",3.1. Expressivity and Network Stability,[0],[0]
This is shown in Figure 7 and Figure 17 in the Appendix.,3.1. Expressivity and Network Stability,[0],[0]
"Expressivity measures, especially trajectory length, can also be used to better understand the effect of regulariza-
tion.",3.2. Trajectory Length and Regularization: The Effect of Batch Normalization,[0],[0]
"One regularization technique that has been extremely successful for training neural networks is Batch Normalization (Ioffe and Szegedy, 2015).
",3.2. Trajectory Length and Regularization: The Effect of Batch Normalization,[0],[0]
"By taking measures of trajectories during training we find that without batch norm, trajectory length tends to increase during training, as shown in Figures 8 and Figure 18 in the Appendix.",3.2. Trajectory Length and Regularization: The Effect of Batch Normalization,[0],[0]
"In these experiments, two networks were initialized with σ2w = 2 and trained to high test accuracy on CIFAR10 and MNIST.",3.2. Trajectory Length and Regularization: The Effect of Batch Normalization,[0],[0]
"We see that in both cases, trajectory length increases as training progresses.
",3.2. Trajectory Length and Regularization: The Effect of Batch Normalization,[0],[0]
"A surprising observation is σ2w = 2 is not in the exponential growth increase regime at initialization for the CIFAR10
architecture (Figure 8 at Step 0.).",3.2. Trajectory Length and Regularization: The Effect of Batch Normalization,[0],[0]
"But note that even with a smaller weight initialization, weight norms increase during training, shown in Figure 9, pushing typically initialized networks into the exponential growth regime.
",3.2. Trajectory Length and Regularization: The Effect of Batch Normalization,[0],[0]
"While the initial growth of trajectory length enables greater functional expressivity, large trajectory growth in the learnt representation results in an unstable representation, witnessed in Figure 6.",3.2. Trajectory Length and Regularization: The Effect of Batch Normalization,[0],[0]
"In Figure 10 we train another conv net on CIFAR10, but this time with batch normalization.",3.2. Trajectory Length and Regularization: The Effect of Batch Normalization,[0],[0]
"We see that the batch norm layers reduce trajectory length, helping stability.",3.2. Trajectory Length and Regularization: The Effect of Batch Normalization,[0],[0]
"Motivated by the fact that batch normalization decreases trajectory length and hence helps stability and generalization, we consider directly regularizing on trajectory length: we replace every batch norm layer used in the conv net in Figure 10 with a trajectory regularization layer.",3.3. Trajectory Regularization,[0],[0]
"This layer adds to the loss λ(current length/orig length), and
then scales the outgoing activations by λ, where λ is a parameter to be learnt.",3.3. Trajectory Regularization,[0],[0]
"In implementation, we typically scale the additional loss above with a constant (0.01) to reduce magnitude in comparison to classification loss.",3.3. Trajectory Regularization,[0],[0]
"Our results, Figure 11 show that both trajectory regularization and batch norm perform comparably, and considerably better than not using batch norm.",3.3. Trajectory Regularization,[0],[0]
"One advantage of using Trajectory Regularization is that we don’t require different computations to be performed for train and test, enabling more efficient implementation.",3.3. Trajectory Regularization,[0],[0]
"Characterizing the expressiveness of neural networks, and understanding how expressiveness varies with parameters of the architecture, has been a challenging problem due to the difficulty in identifying meaningful notions of expressivity and in linking their analysis to implications for these networks in practice.",4. Discussion,[0],[0]
"In this paper we have presented an interrelated set of expressivity measures; we have shown tight exponential bounds on the growth of these measures in the depth of the networks, and we have offered a unifying view of the analysis through the notion of trajectory length.",4. Discussion,[0],[0]
"Our analysis of trajectories provides insights for the performance of trained networks as well, suggesting that networks in practice may be more sensitive to small perturbations in weights at lower layers.",4. Discussion,[0],[0]
"We also used this to explore the empirical success of batch norm, and developed a new regularization method – trajectory regularization.
",4. Discussion,[0],[0]
This work raises many interesting directions for future work.,4. Discussion,[0],[0]
"At a general level, continuing the theme of ‘principled deep understanding’, it would be interesting to link
measures of expressivity to other properties of neural network performance.",4. Discussion,[0],[0]
"There is also a natural connection between adversarial examples, (Goodfellow et al., 2014), and trajectory length: adversarial perturbations are only a small distance away in input space, but result in a large change in classification (the output layer).",4. Discussion,[0],[0]
Understanding how trajectories between the original input and an adversarial perturbation grow might provide insights into this phenomenon.,4. Discussion,[0],[0]
"Another direction, partially explored in this paper, is regularizing based on trajectory length.",4. Discussion,[0],[0]
"A very simple version of this was presented, but further performance gains might be achieved through more sophisticated use of this method.",4. Discussion,[0],[0]
"We thank Samy Bengio, Ian Goodfellow, Laurent Dinh, and Quoc Le for extremely helpful discussion.",Acknowledgements,[0],[0]
Here we include the full proofs from sections in the paper.,Appendix,[0],[0]
Proof.,Proof of Theorem 2,[0],[0]
We show inductively that FA(x;W ) partitions the input space into convex polytopes via hyperplanes.,Proof of Theorem 2,[0],[0]
Consider the image of the input space under the first hidden layer.,Proof of Theorem 2,[0],[0]
"Each neuron v(1)i defines hyperplane(s) on the input space: letting W (0)i be the ith row of W (0), b(0)i the bias, we have the hyperplane W (0)",Proof of Theorem 2,[0],[0]
i x + bi = 0 for a ReLU and hyperplanes W (0) i x + bi = ±1 for a hard-tanh.,Proof of Theorem 2,[0],[0]
"Considering all such hyperplanes over neurons in the first layer, we get a hyperplane arrangement in the input space, each polytope corresponding to a specific activation pattern in the first hidden layer.
",Proof of Theorem 2,[0],[0]
"Now, assume we have partitioned our input space into convex polytopes with hyperplanes from layers ≤ d",Proof of Theorem 2,[0],[0]
− 1.,Proof of Theorem 2,[0],[0]
Consider v (d) i and a specific polytope Ri.,Proof of Theorem 2,[0],[0]
Then the activation pattern on layers ≤ d,Proof of Theorem 2,[0],[0]
"− 1 is constant on Ri, and so the input to v (d)",Proof of Theorem 2,[0],[0]
"i
on Ri is a linear function of the inputs ∑ j λjxj + b and some constant term, comprising of the bias and the output of saturated units.",Proof of Theorem 2,[0],[0]
"Setting this expression to zero (for ReLUs) or to ±1 (for hard-tanh) again gives a hyperplane equation, but this time, the equation is only valid in Ri (as we get a different linear function of the inputs in a different region.)",Proof of Theorem 2,[0],[0]
So the defined hyperplane(s) either partition Ri (if they intersect Ri) or the output pattern of v (d) i is also constant on Ri.,Proof of Theorem 2,[0],[0]
"The theorem then follows.
",Proof of Theorem 2,[0],[0]
"This implies that any one dimensional trajectory x(t), that does not ‘double back’ on itself (i.e. reenter a polytope it has previously passed through), will not repeat activation patterns.",Proof of Theorem 2,[0],[0]
"In particular, after seeing a transition (crossing a hyperplane to a different region in input space) we will never return to the region we left.",Proof of Theorem 2,[0],[0]
"A simple example of such a trajectory is a straight line:
Corollary 1.",Proof of Theorem 2,[0],[0]
"Transitions and Output Patterns in an Affine Trajectory For any affine one dimensional trajectory x(t) = x0 + t(x1 − x0) input into a neural network FW ,",Proof of Theorem 2,[0],[0]
we partition R 3 t into intervals every time a neuron transitions.,Proof of Theorem 2,[0],[0]
"Every interval has a unique network activation pattern on FW .
",Proof of Theorem 2,[0],[0]
"Generalizing from a one dimensional trajectory, we can ask how many regions are achieved over the entire input – i.e. how many distinct activation patterns are seen?",Proof of Theorem 2,[0],[0]
"We first prove a bound on the number of regions formed by k hyperplanes in Rm (in a purely elementary fashion, unlike the proof presented in (Stanley, 2011))
",Proof of Theorem 2,[0],[0]
Theorem 5.,Proof of Theorem 2,[0],[0]
Upper Bound on Regions in a Hyperplane Arrangement Suppose we have k hyperplanes in Rm - i.e. k equations of form αix = βi.,Proof of Theorem 2,[0],[0]
"for αi ∈ Rm, βi ∈ R. Let the number of regions (connected open sets bounded on some sides by the hyperplanes) be r(k,m).",Proof of Theorem 2,[0],[0]
"Then
r(k,m) ≤",Proof of Theorem 2,[0],[0]
m∑ i=0,Proof of Theorem 2,[0],[0]
( k i ),Proof of Theorem 2,[0],[0]
Proof.,Proof of Theorem 5,[0],[0]
"Let the hyperplane arrangement be denoted H, and let H ∈ H be one specific hyperplane.",Proof of Theorem 5,[0],[0]
Then the number of regions in H is precisely the number of regions in H − H plus the number of regions in H ∩ H .,Proof of Theorem 5,[0],[0]
"(This follows from the fact that H subdivides into two regions exactly all of the regions inH ∩H , and does not affect any of the other regions.)
",Proof of Theorem 5,[0],[0]
"In particular, we have the recursive formula
r(k,m) =",Proof of Theorem 5,[0],[0]
"r(k − 1,m) + r(k − 1,m− 1)
We now induct on k + m to assert the claim.",Proof of Theorem 5,[0],[0]
"The base cases of r(1, 0) = r(0, 1) = 1 are trivial, and assuming the claim
for ≤ k",Proof of Theorem 5,[0],[0]
"+m− 1 as the induction hypothesis, we have
r(k − 1,m) +",Proof of Theorem 5,[0],[0]
"r(k − 1,m− 1) ≤",Proof of Theorem 5,[0],[0]
m∑ i=0 ( k − 1 i ) + m−1∑,Proof of Theorem 5,[0],[0]
i=0,Proof of Theorem 5,[0],[0]
(,Proof of Theorem 5,[0],[0]
"k − 1 i )
≤ ( k − 1
0
) + d−1∑ i=0 ( k − 1 i ) +",Proof of Theorem 5,[0],[0]
"( k − 1 i+ 1 )
≤ ( k
0
) + m−1∑",Proof of Theorem 5,[0],[0]
"i=0 ( k i+ 1 ) where the last equality follows by the well known identity(
a
b
)",Proof of Theorem 5,[0],[0]
+,Proof of Theorem 5,[0],[0]
"( a
b+ 1
) = ( a+ 1
b+ 1
)
",Proof of Theorem 5,[0],[0]
"This concludes the proof.
",Proof of Theorem 5,[0],[0]
"With this result, we can easily prove Theorem 1 as follows:",Proof of Theorem 5,[0],[0]
Proof.,Proof of Theorem 1,[0],[0]
First consider the ReLU case.,Proof of Theorem 1,[0],[0]
"Each neuron has one hyperplane associated with it, and so by Theorem 5, the first hidden layer divides up the inputs space into r(k,m) regions, with r(k,m) ≤ O(km).
",Proof of Theorem 1,[0],[0]
Now consider the second hidden layer.,Proof of Theorem 1,[0],[0]
"For every region in the first hidden layer, there is a different activation pattern in the first layer, and so (as described in the proof of Theorem 2) a different hyperplane arrangement of k hyperplanes in an m dimensional space, contributing at most r(k,m) regions.
",Proof of Theorem 1,[0],[0]
"In particular, the total number of regions in input space as a result of the first and second hidden layers is ≤ r(k,m) ∗ r(k,m) ≤",Proof of Theorem 1,[0],[0]
O(k2m).,Proof of Theorem 1,[0],[0]
"Continuing in this way for each of the n hidden layers gives the O(kmn) bound.
",Proof of Theorem 1,[0],[0]
"A very similar method works for hard tanh, but here each neuron produces two hyperplanes, resulting in a bound of O((2k)mn).",Proof of Theorem 1,[0],[0]
"Difference of points on trajectory Given x(t) = x, x(t+ dt) = x+ δx in the trajectory, let δz(d) =",B.1. Notation and Preliminary Results,[0],[0]
"z(d)(x+ δx)− z(d)(x)
Parallel and Perpendicular Components:",B.1. Notation and Preliminary Results,[0],[0]
"Given vectors x, y, we can write y = y⊥ + y‖ where y⊥ is the component of y perpendicular to x, and y‖ is the component parallel to x. (Strictly speaking, these components should also have a subscript x, but we suppress it as the direction with respect to which parallel and perpendicular components are being taken will be explicitly stated.)
",B.1. Notation and Preliminary Results,[0],[0]
"This notation can also be used with a matrix W , see Lemma 1.
",B.1. Notation and Preliminary Results,[0],[0]
"Before stating and proving the main theorem, we need a few preliminary results.
",B.1. Notation and Preliminary Results,[0],[0]
Lemma 1.,B.1. Notation and Preliminary Results,[0],[0]
"Matrix Decomposition Let x, y ∈",B.1. Notation and Preliminary Results,[0],[0]
"Rk be fixed non-zero vectors, and let W be a (full rank) matrix.",B.1. Notation and Preliminary Results,[0],[0]
"Then, we can write
W = ‖W‖ + ‖W⊥",B.1. Notation and Preliminary Results,[0],[0]
+,B.1. Notation and Preliminary Results,[0],[0]
"⊥W‖ + ⊥W⊥
such that
‖W⊥x",B.1. Notation and Preliminary Results,[0],[0]
= 0 ⊥W⊥x,B.1. Notation and Preliminary Results,[0],[0]
= 0,B.1. Notation and Preliminary Results,[0],[0]
"yT⊥W‖ = 0 y T⊥W⊥ = 0
i.e. the row space of W is decomposed to perpendicular and parallel components with respect to x (subscript on right), and the column space is decomposed to perpendicular and parallel components of y (superscript on left).
",B.1. Notation and Preliminary Results,[0],[0]
Proof.,B.1. Notation and Preliminary Results,[0],[0]
"Let V,U be rotations such that V x = (||x|| , 0..., 0)T and Uy = (||y|| , 0...0)T .",B.1. Notation and Preliminary Results,[0],[0]
"Now let W̃ = UWV T , and let W̃ = ‖W̃‖ + ‖W̃⊥ + ⊥W̃‖",B.1. Notation and Preliminary Results,[0],[0]
"+
⊥W̃⊥, with ‖W̃‖ having non-zero term exactly W̃11, ‖W̃⊥ having non-zero entries exactly W̃1i for 2 ≤",B.1. Notation and Preliminary Results,[0],[0]
i ≤,B.1. Notation and Preliminary Results,[0],[0]
"k. Finally, we let ⊥W̃‖ have non-zero entries exactly W̃i1, with 2 ≤ i ≤ k",B.1. Notation and Preliminary Results,[0],[0]
"and ⊥W̃⊥ have the remaining entries non-zero.
",B.1. Notation and Preliminary Results,[0],[0]
"If we define x̃ = V x and ỹ = Uy, then we see that
‖W̃⊥x̃ = 0",B.1. Notation and Preliminary Results,[0],[0]
⊥W̃⊥x̃ = 0 ỹT⊥W̃‖,B.1. Notation and Preliminary Results,[0],[0]
"= 0 ỹ T⊥W̃⊥ = 0
as x̃, ỹ have only one non-zero term, which does not correspond to a non-zero term in the components of W̃ in the equations.
",B.1. Notation and Preliminary Results,[0],[0]
"Then, defining ‖W‖ = UT ‖W̃‖V , and the other components analogously, we get equations of the form
‖W⊥x",B.1. Notation and Preliminary Results,[0],[0]
= U T ‖W̃⊥V x = U T ‖W̃⊥x̃,B.1. Notation and Preliminary Results,[0],[0]
"= 0
Observation 1.",B.1. Notation and Preliminary Results,[0],[0]
"Given W,x as before, and considering W‖, W⊥ with respect to x (wlog a unit vector) we can express them directly in terms of W as follows: Letting W (i) be the ith row of W , we have
W‖ =",B.1. Notation and Preliminary Results,[0],[0]
"((W (0))T · x)x
... ((W (k))T · x)x  i.e. the projection of each row in the direction of x.",B.1. Notation and Preliminary Results,[0],[0]
"And of course
W⊥",B.1. Notation and Preliminary Results,[0],[0]
"= W −W‖
The motivation to consider such a decomposition of W is for the resulting independence between different components, as shown in the following lemma.
",B.1. Notation and Preliminary Results,[0],[0]
Lemma 2.,B.1. Notation and Preliminary Results,[0],[0]
Independence of Projections Let x be a given vector (wlog of unit norm.),B.1. Notation and Preliminary Results,[0],[0]
"If W is a random matrix with Wij ∼ N (0, σ2), then W‖ and W⊥ with respect to x are independent random variables.
",B.1. Notation and Preliminary Results,[0],[0]
Proof.,B.1. Notation and Preliminary Results,[0],[0]
"There are two possible proof methods:
(a) We use the rotational invariance of random Gaussian matrices, i.e. if W is a Gaussian matrix, iid entries N (0, σ2), and R is a rotation, then RW is also iid Gaussian, entries N (0, σ2).",B.1. Notation and Preliminary Results,[0],[0]
"(This follows easily from affine transformation rules for multivariate Gaussians.)
",B.1. Notation and Preliminary Results,[0],[0]
Let V be a rotation as in Lemma 1.,B.1. Notation and Preliminary Results,[0],[0]
"Then W̃ = WV T is also iid Gaussian, and furthermore, W̃‖ and W̃⊥ partition the entries of W̃ , so are evidently independent.",B.1. Notation and Preliminary Results,[0],[0]
"But then W‖ = W̃‖V T and W⊥ = W̃⊥V T are also independent.
",B.1. Notation and Preliminary Results,[0],[0]
(b) From the observation note that W‖ and W⊥ have a centered multivariate joint Gaussian distribution (both consist of linear combinations of the entries Wij in W .),B.1. Notation and Preliminary Results,[0],[0]
So it suffices to show that W‖ and W⊥ have covariance 0.,B.1. Notation and Preliminary Results,[0],[0]
"Because both are centered Gaussians, this is equivalent to showing E(< W‖,W⊥ >) = 0.",B.1. Notation and Preliminary Results,[0],[0]
"We have that
E(< W‖,W⊥ >) = E(W‖WT⊥ ) = E(W‖WT )",B.1. Notation and Preliminary Results,[0],[0]
"− E(W‖WT‖ )
",B.1. Notation and Preliminary Results,[0],[0]
"As any two rows of W are independent, we see from the observation that E(W‖WT ) is a diagonal matrix, with the ith diagonal entry just ((W (0))T · x)2.",B.1. Notation and Preliminary Results,[0],[0]
"But similarly, E(W‖WT‖ ) is also a diagonal matrix, with the same diagonal entries - so the claim follows.
",B.1. Notation and Preliminary Results,[0],[0]
"In the following two lemmas, we use the rotational invariance of Gaussians as well as the chi distribution to prove results about the expected norm of a random Gaussian vector.
Lemma 3.",B.1. Notation and Preliminary Results,[0],[0]
Norm of a Gaussian vector Let X ∈,B.1. Notation and Preliminary Results,[0],[0]
"Rk be a random Gaussian vector, with Xi iid, ∼ N (0, σ2).",B.1. Notation and Preliminary Results,[0],[0]
"Then
E [||X||] = σ",B.1. Notation and Preliminary Results,[0],[0]
"√ 2 Γ((k + 1)/2)
Γ(k/2)
",B.1. Notation and Preliminary Results,[0],[0]
Proof.,B.1. Notation and Preliminary Results,[0],[0]
"We use the fact that if Y is a random Gaussian, and Yi ∼ N (0, 1) then ||Y || follows a chi distribution.",B.1. Notation and Preliminary Results,[0],[0]
"This means that E(||X/σ||) = √ 2Γ((k + 1)/2)/Γ(k/2), the mean of a chi distribution with k degrees of freedom, and the result follows by noting that the expectation in the lemma is σ multiplied by the above expectation.
",B.1. Notation and Preliminary Results,[0],[0]
"We will find it useful to bound ratios of the Gamma function (as appear in Lemma 3) and so introduce the following inequality, from (Kershaw, 1983) that provides an extension of Gautschi’s Inequality.
",B.1. Notation and Preliminary Results,[0],[0]
Theorem 6.,B.1. Notation and Preliminary Results,[0],[0]
An Extension of Gautschi’s Inequality For 0,B.1. Notation and Preliminary Results,[0],[0]
"< s < 1, we have
( x+ s
2
)1−s ≤ Γ(x+ 1)
Γ(x+ s) ≤
( x− 1
2 +
( s+ 1
4
) 1 2 )1−s
We now show:
Lemma 4.",B.1. Notation and Preliminary Results,[0],[0]
"Norm of Projections Let W be a k by k random Gaussian matrix with iid entries ∼ N (0, σ2), and x, y two given vectors.",B.1. Notation and Preliminary Results,[0],[0]
Partition W into components as in Lemma 1 and let x⊥ be a nonzero vector perpendicular to x.,B.1. Notation and Preliminary Results,[0],[0]
"Then
(a)
",B.1. Notation and Preliminary Results,[0],[0]
E,B.1. Notation and Preliminary Results,[0],[0]
[∣∣∣∣⊥W⊥x⊥∣∣∣∣] =,B.1. Notation and Preliminary Results,[0],[0]
"||x⊥||σ√2 Γ(k/2)
",B.1. Notation and Preliminary Results,[0],[0]
"Γ((k − 1)/2 ≥ ||x⊥||σ
√ 2
( k
2 − 3 4 )1/2 (b)",B.1. Notation and Preliminary Results,[0],[0]
If 1A is an identity matrix with non-zeros diagonal entry i iff,B.1. Notation and Preliminary Results,[0],[0]
i ∈,B.1. Notation and Preliminary Results,[0],[0]
A ⊂,B.1. Notation and Preliminary Results,[0],[0]
"[k], and |A| > 2, then
E",B.1. Notation and Preliminary Results,[0],[0]
"[∣∣∣∣1A⊥W⊥x⊥∣∣∣∣] ≥ ||x⊥||σ√2 Γ(|A|/2)
",B.1. Notation and Preliminary Results,[0],[0]
Γ((|A|,B.1. Notation and Preliminary Results,[0],[0]
"− 1)/2) ≥ ||x⊥||σ
√ 2 ( |A| 2 − 3 4 )1/2 Proof.",B.1. Notation and Preliminary Results,[0],[0]
"(a) Let U, V, W̃ be as in Lemma 1.",B.1. Notation and Preliminary Results,[0],[0]
"As U, V are rotations, W̃ is also iid Gaussian.",B.1. Notation and Preliminary Results,[0],[0]
"Furthermore for any fixed W ,
with ã = V a, by taking inner products, and square-rooting, we see that ∣∣∣∣∣∣W̃ ã∣∣∣∣∣∣ = ||Wa||.",B.1. Notation and Preliminary Results,[0],[0]
"So in particular
E [∣∣∣∣⊥W⊥x⊥∣∣∣∣] =",B.1. Notation and Preliminary Results,[0],[0]
"E [∣∣∣∣∣∣⊥W̃⊥x̃⊥∣∣∣∣∣∣]
But from the definition of non-zero entries of ⊥W̃⊥, and the form of x̃⊥ (a zero entry in the first coordinate), it follows that ⊥W̃⊥x̃⊥ has exactly k−1 non zero entries, each a centered Gaussian with variance (k−1)σ2 ||x⊥||2.",B.1. Notation and Preliminary Results,[0],[0]
"By Lemma 3, the expected norm is as in the statement.",B.1. Notation and Preliminary Results,[0],[0]
"We then apply Theorem 6 to get the lower bound.
",B.1. Notation and Preliminary Results,[0],[0]
"(b) First note we can view 1A⊥W⊥ = ⊥1AW⊥. (Projecting down to a random (as W is random) subspace of fixed size |A| = m and then making perpendicular commutes with making perpendicular and then projecting everything down to the subspace.)
",B.1. Notation and Preliminary Results,[0],[0]
"So we can viewW as a randomm by k matrix, and for x, y as in Lemma 1 (with y projected down ontom dimensions), we can again define U, V as k by k and m by m rotation matrices respectively, and W̃ = UWV T , with analogous
properties to Lemma 1.",B.1. Notation and Preliminary Results,[0],[0]
"Now we can finish as in part (a), except that ⊥W̃⊥x̃ may have only m− 1 entries, (depending on whether y is annihilated by projecting down by1A) each of variance (k − 1)σ2 ||x⊥||2.
",B.1. Notation and Preliminary Results,[0],[0]
Lemma 5.,B.1. Notation and Preliminary Results,[0],[0]
"Norm and Translation Let X be a centered multivariate Gaussian, with diagonal covariance matrix, and µ a constant vector.
",B.1. Notation and Preliminary Results,[0],[0]
"E(||X − µ||) ≥ E(||X||)
Proof.",B.1. Notation and Preliminary Results,[0],[0]
"The inequality can be seen intuitively geometrically: as X has diagonal covariance matrix, the contours of the pdf of ||X|| are circular centered at 0, decreasing radially.",B.1. Notation and Preliminary Results,[0],[0]
"However, the contours of the pdf of ||X − µ|| are shifted to be centered around ||µ||, and so shifting back µ to 0 reduces the norm.
",B.1. Notation and Preliminary Results,[0],[0]
A more formal proof can be seen as follows: let the pdf of X be fX(·).,B.1. Notation and Preliminary Results,[0],[0]
"Then we wish to show∫ x ||x− µ|| fX(x)dx ≥ ∫ x ||x|| fX(x)dx
Now we can pair points x,−x, using the fact that fX(x) = fX(−x) and the triangle inequality on the integrand to get∫ |x|",B.1. Notation and Preliminary Results,[0],[0]
(||x− µ||+ ||−x−,B.1. Notation and Preliminary Results,[0],[0]
µ||) fX(x)dx ≥ ∫,B.1. Notation and Preliminary Results,[0],[0]
|x| ||2x||,B.1. Notation and Preliminary Results,[0],[0]
fX(x)dx = ∫ |x|,B.1. Notation and Preliminary Results,[0],[0]
(||x||+ ||−x||),B.1. Notation and Preliminary Results,[0],[0]
fX(x)dx,B.1. Notation and Preliminary Results,[0],[0]
We use v(d)i to denote the i th neuron in hidden layer d.,B.2. Proof of Theorem,[0],[0]
"We also let x = z(0) be an input, h(d) be the hidden representation at layer d, and φ the non-linearity.",B.2. Proof of Theorem,[0],[0]
The weights and bias are called W (d) and b(d) respectively.,B.2. Proof of Theorem,[0],[0]
"So we have the relations
h(d)",B.2. Proof of Theorem,[0],[0]
=,B.2. Proof of Theorem,[0],[0]
"W (d)z(d) + b(d), z(d+1) = φ(h(d)).",B.2. Proof of Theorem,[0],[0]
"(1)
Proof.",B.2. Proof of Theorem,[0],[0]
We first prove the zero bias case.,B.2. Proof of Theorem,[0],[0]
"To do so, it is sufficient to prove that
E",B.2. Proof of Theorem,[0],[0]
[∣∣∣∣∣∣δz(d+1)(t)∣∣∣∣∣∣] ≥,B.2. Proof of Theorem,[0],[0]
O ( √σk√ σ + k )d+1∣∣∣∣∣∣δz(0)(t)∣∣∣∣∣∣,B.2. Proof of Theorem,[0],[0]
"(**) as integrating over t gives us the statement of the theorem.
",B.2. Proof of Theorem,[0],[0]
"For ease of notation, we will suppress the t in z(d)(t).
",B.2. Proof of Theorem,[0],[0]
"We first write W (d) = W
(d) ⊥ +W (d) ‖
where the division is done with respect to z(d).",B.2. Proof of Theorem,[0],[0]
Note that this means h(d+1) =,B.2. Proof of Theorem,[0],[0]
"W (d)‖ z (d) as the other component annihilates (maps to 0) z(d).
",B.2. Proof of Theorem,[0],[0]
We can also define A W (d) ‖,B.2. Proof of Theorem,[0],[0]
= {i : i ∈,B.2. Proof of Theorem,[0],[0]
"[k], |h(d+1)i | < 1} i.e. the set of indices for which the hidden representation is not saturated.",B.2. Proof of Theorem,[0],[0]
"Letting Wi denote the ith row of matrix W , we now claim that:
EW (d)",B.2. Proof of Theorem,[0],[0]
"[∣∣∣∣∣∣δz(d+1)∣∣∣∣∣∣] = EW (d)‖ EW (d)⊥   ∑ i∈A
W (d) ‖
((W (d) ⊥ )iδz (d) +",B.2. Proof of Theorem,[0],[0]
"(W (d) ‖ )iδz (d))2  1/2  (*)
Indeed, by Lemma 2 we first split the expectation over W (d) into a tower of expectations over the two independent parts of W to get EW (d)",B.2. Proof of Theorem,[0],[0]
"[∣∣∣∣∣∣δz(d+1)∣∣∣∣∣∣] = EW (d)‖ EW (d)⊥ [∣∣∣∣∣∣φ(W (d)δz(d))∣∣∣∣∣∣]
But conditioning on W (d)‖ in the inner expectation gives us h (d+1) and A W (d)
‖ , allowing us to replace the norm over
φ(W (d)δz(d)) with the sum in the term on the right hand side of the claim.
",B.2. Proof of Theorem,[0],[0]
"Till now, we have mostly focused on partitioning the matrix W (d).",B.2. Proof of Theorem,[0],[0]
But we can also set δz(d) = δz(d)‖ + δz (d) ⊥ where the perpendicular and parallel are with respect to z(d).,B.2. Proof of Theorem,[0],[0]
"In fact, to get the expression in (**), we derive a recurrence as below:
EW (d) [∣∣∣∣∣∣δz(d+1)⊥ ∣∣∣∣∣∣] ≥ O ( √ σk√ σ",B.2. Proof of Theorem,[0],[0]
+ k ),B.2. Proof of Theorem,[0],[0]
EW (d),B.2. Proof of Theorem,[0],[0]
"[∣∣∣∣∣∣δz(d)⊥ ∣∣∣∣∣∣]
To get this, we first need to define z̃(d+1)",B.2. Proof of Theorem,[0],[0]
=,B.2. Proof of Theorem,[0],[0]
"1A W
(d) ‖
h(d+1) - the latent vector h(d+1) with all saturated units zeroed out.
",B.2. Proof of Theorem,[0],[0]
"We then split the column space of W (d) = ⊥W (d) + ‖W (d), where the split is with respect to z̃(d+1).",B.2. Proof of Theorem,[0],[0]
"Letting δz(d+1)⊥ be the part perpendicular to z(d+1), and A the set of units that are unsaturated, we have an important relation: Claim ∣∣∣∣∣∣δz(d+1)⊥ ∣∣∣∣∣∣ ≥ ∣∣∣∣∣∣⊥W",B.2. Proof of Theorem,[0],[0]
"(d)δz(d)1A∣∣∣∣∣∣ (where the indicator in the right hand side zeros out coordinates not in the active set.)
",B.2. Proof of Theorem,[0],[0]
"To see this, first note, by definition,
δz (d+1) ⊥ = W (d)δz(d) · 1A − 〈W (d)δz(d) · 1A, ẑ(d+1)〉ẑ(d+1) (1)
where the ·̂ indicates a unit vector.
",B.2. Proof of Theorem,[0],[0]
"Similarly ⊥W (d)δz(d) = W (d)δz(d) − 〈W (d)δz(d), ˆ̃z(d+1)〉ˆ̃z(d+1) (2)
Now note that for any index",B.2. Proof of Theorem,[0],[0]
i ∈,B.2. Proof of Theorem,[0],[0]
"A, the right hand sides of (1) and (2) are identical, and so the vectors on the left hand side agree for all i ∈ A.",B.2. Proof of Theorem,[0],[0]
"In particular,
δz (d+1) ⊥ · 1A = ⊥W",B.2. Proof of Theorem,[0],[0]
"(d)δz(d) · 1A
Now the claim follows easily by noting that ∣∣∣∣∣∣δz(d+1)⊥",B.2. Proof of Theorem,[0],[0]
"∣∣∣∣∣∣ ≥ ∣∣∣∣∣∣δz(d+1)⊥ · 1A∣∣∣∣∣∣.
Returning to (*), we split δz(d) =",B.2. Proof of Theorem,[0],[0]
"δz(d)⊥ + δz (d) ‖ , W (d) ⊥ = ‖W (d) ⊥ + ⊥W",B.2. Proof of Theorem,[0],[0]
"(d) ⊥ (and W (d) ‖ analogously), and after some cancellation, we have
EW (d)",B.2. Proof of Theorem,[0],[0]
"[∣∣∣∣∣∣δz(d+1)∣∣∣∣∣∣] = EW (d)‖ EW (d)⊥   ∑ i∈A
W (d) ‖
( (⊥W
(d) ⊥ + ‖W (d) ⊥ )",B.2. Proof of Theorem,[0],[0]
iδz (d) ⊥ +,B.2. Proof of Theorem,[0],[0]
( ⊥W (d) ‖ + ‖W (d) ‖ ),B.2. Proof of Theorem,[0],[0]
"iδz (d) ‖ )2 1/2 
We would like a recurrence in terms of only perpendicular components however, so we first drop the ‖W (d)⊥ , ‖W (d) ‖ (which can be done without decreasing the norm as they are perpendicular to the remaining terms) and using the above claim, have
EW (d)",B.2. Proof of Theorem,[0],[0]
"[∣∣∣∣∣∣δz(d+1)⊥ ∣∣∣∣∣∣] ≥ EW (d)‖ EW (d)⊥   ∑ i∈A
W (d) ‖
( (⊥W
(d) ⊥ )iδz (d) ⊥ + ( ⊥W (d) ‖ )",B.2. Proof of Theorem,[0],[0]
"iδz (d) ‖ )2 1/2 
",B.2. Proof of Theorem,[0],[0]
"But in the inner expectation, the term ⊥W (d)‖ δz (d) ‖ is just a constant, as we are conditioning on W (d) ‖ .",B.2. Proof of Theorem,[0],[0]
"So using Lemma 5 we have
E W
(d) ⊥   ∑ i∈A
W (d) ‖
( (⊥W
(d) ⊥ )iδz (d) ⊥ +",B.2. Proof of Theorem,[0],[0]
"( ⊥W (d) ‖ )iδz (d) ‖ )2 1/2  ≥ EW (d)⊥   ∑ i∈A
W (d) ‖
( (⊥W
(d) ⊥ )iδz (d) ⊥ )2 1/2 
We can then apply Lemma 4 to get
E W
(d) ⊥   ∑ i∈A
W (d) ‖
( (⊥W
(d) ⊥ )iδz (d) ⊥ )2 1/2  ≥ σ√k√2 √ 2|A",B.2. Proof of Theorem,[0],[0]
W (d) ‖,B.2. Proof of Theorem,[0],[0]
"| − 3 2 E [∣∣∣∣∣∣δz(d)⊥ ∣∣∣∣∣∣]
The outer expectation on the right hand side only affects the term in the expectation through the size of the active set of units.",B.2. Proof of Theorem,[0],[0]
"For ReLUs, p = P(h(d+1)i > 0) and for hard tanh, we have p = P(|h (d+1) i | < 1), and noting that we get a non-zero norm only if |A W (d) ‖",B.2. Proof of Theorem,[0],[0]
"| ≥ 2 (else we cannot project down a dimension), and for |A W (d) ‖",B.2. Proof of Theorem,[0],[0]
"| ≥ 2,
√ 2
√ 2|A
W (d) ‖",B.2. Proof of Theorem,[0],[0]
"| − 3
2 ≥ 1√
2
√ |A
W (d) ‖",B.2. Proof of Theorem,[0],[0]
"|
we get
EW (d)",B.2. Proof of Theorem,[0],[0]
[∣∣∣∣∣∣δz(d+1)⊥ ∣∣∣∣∣∣] ≥ 1√2  k∑ j=2,B.2. Proof of Theorem,[0],[0]
( k j ) pj(1− p)k−j σ√ k √ j E,B.2. Proof of Theorem,[0],[0]
[∣∣∣∣∣∣δz(d)⊥ ∣∣∣∣∣∣],B.2. Proof of Theorem,[0],[0]
"We use the fact that we have the probability mass function for an (k, p) binomial random variable to bound the √ j term:
k∑ j=2",B.2. Proof of Theorem,[0],[0]
( k j ) pj(1− p)k−j σ√ k √ j =,B.2. Proof of Theorem,[0],[0]
− ( k 1 ) p(1− p)k−1 σ√ k + k∑ j=0,B.2. Proof of Theorem,[0],[0]
"( k j ) pj(1− p)k−j σ√ k √ j
= −σ",B.2. Proof of Theorem,[0],[0]
"√ kp(1− p)k−1 + kp · σ√
k k∑ j=1",B.2. Proof of Theorem,[0],[0]
1√ j,B.2. Proof of Theorem,[0],[0]
(,B.2. Proof of Theorem,[0],[0]
"k − 1 j − 1 ) pj−1(1− p)k−j
",B.2. Proof of Theorem,[0],[0]
"But by using Jensen’s inequality with 1/ √ x, we get
k∑ j=1 1√ j",B.2. Proof of Theorem,[0],[0]
( k − 1 j − 1 ),B.2. Proof of Theorem,[0],[0]
pj−1(1− p)k−j ≥ 1√∑k j=1 j,B.2. Proof of Theorem,[0],[0]
( k−1 j−1 ),B.2. Proof of Theorem,[0],[0]
"pj−1(1− p)k−j = 1√ (k − 1)p+ 1
where the last equality follows by recognising the expectation of a binomial(k−1, p) random variable.",B.2. Proof of Theorem,[0],[0]
"So putting together, we get
EW (d)",B.2. Proof of Theorem,[0],[0]
[∣∣∣∣∣∣δz(d+1)⊥ ∣∣∣∣∣∣] ≥ 1√2 ( −σ √ kp(1− p)k−1 + σ ·,B.2. Proof of Theorem,[0],[0]
√ kp√ 1 + (k − 1)p ),B.2. Proof of Theorem,[0],[0]
E,B.2. Proof of Theorem,[0],[0]
"[∣∣∣∣∣∣δz(d)⊥ ∣∣∣∣∣∣] (a)
From here, we must analyse the hard tanh and ReLU cases separately.",B.2. Proof of Theorem,[0],[0]
"First considering the hard tanh case:
To lower bound p, we first note that as h(d+1)i is a normal random variable with variance ≤ σ2, if A ∼ N (0, σ2)
",B.2. Proof of Theorem,[0],[0]
P(|h(d+1)i | < 1),B.2. Proof of Theorem,[0],[0]
≥,B.2. Proof of Theorem,[0],[0]
"P(|A| < 1) ≥ 1
σ",B.2. Proof of Theorem,[0],[0]
√ 2π,B.2. Proof of Theorem,[0],[0]
(,B.2. Proof of Theorem,[0],[0]
"b)
where the last inequality holds for σ ≥ 1 and follows by Taylor expanding e−x2/2 around 0.",B.2. Proof of Theorem,[0],[0]
"Similarly, we can also show that p ≤",B.2. Proof of Theorem,[0],[0]
"1σ .
",B.2. Proof of Theorem,[0],[0]
"So this becomes
E [∣∣∣∣∣∣δz(d+1)∣∣∣∣∣∣] ≥  1√ 2  1 (2π)1/4 √ σk√
σ √ 2π",B.2. Proof of Theorem,[0],[0]
+,B.2. Proof of Theorem,[0],[0]
(k − 1),B.2. Proof of Theorem,[0],[0]
"− √ k
( 1− 1
σ
)k−1E",B.2. Proof of Theorem,[0],[0]
"[∣∣∣∣∣∣δz(d)⊥ ∣∣∣∣∣∣]
=",B.2. Proof of Theorem,[0],[0]
O ( √ σk√ σ,B.2. Proof of Theorem,[0],[0]
+ k ) E,B.2. Proof of Theorem,[0],[0]
"[∣∣∣∣∣∣δz(d)⊥ ∣∣∣∣∣∣]
Finally, we can compose this, to get
E [∣∣∣∣∣∣δz(d+1)∣∣∣∣∣∣] ≥  1√ 2  1 (2π)1/4 √ σk√
σ √ 2π + (k − 1)",B.2. Proof of Theorem,[0],[0]
"− √ k
( 1− 1
σ )k−1d+1 c · ||δx(t)|| (c) with the constant c being the ratio of ||δx(t)⊥|| to ||δx(t)||.",B.2. Proof of Theorem,[0],[0]
"So if our trajectory direction is almost orthogonal to x(t) (which will be the case for e.g. random circular arcs, c can be seen to be ≈ 1 by splitting into components as in Lemma 1, and using Lemmas 3, 4.)
",B.2. Proof of Theorem,[0],[0]
The ReLU case (with no bias) is even easier.,B.2. Proof of Theorem,[0],[0]
"Noting that for random weights, p = 1/2, and plugging in to equation (a), we get
EW (d)",B.2. Proof of Theorem,[0],[0]
[∣∣∣∣∣∣δz(d+1)⊥ ∣∣∣∣∣∣] ≥ 1√2 ( −σ √ k 2k + σ ·,B.2. Proof of Theorem,[0],[0]
√ k√ 2(k + 1) ),B.2. Proof of Theorem,[0],[0]
E,B.2. Proof of Theorem,[0],[0]
"[∣∣∣∣∣∣δz(d)⊥ ∣∣∣∣∣∣] (d)
But the expression on the right hand side has exactly the asymptotic form O(σ √ k/ √ k + 1), and we finish as in (c).
",B.2. Proof of Theorem,[0],[0]
"Result for non-zero bias In fact, we can easily extend the above result to the case of non-zero bias.",B.2. Proof of Theorem,[0],[0]
"The insight is to note that because δz(d+1) involves taking a difference between z(d+1)(t + dt) and z(d+1)(t), the bias term does not enter at all into the expression for δz(d+1).",B.2. Proof of Theorem,[0],[0]
"So the computations above hold, and equation (a) becomes
EW (d)",B.2. Proof of Theorem,[0],[0]
[∣∣∣∣∣∣δz(d+1)⊥ ∣∣∣∣∣∣] ≥ 1√2 ( −σw √ kp(1− p)k−1 + σw · √ kp√ 1 + (k − 1)p ),B.2. Proof of Theorem,[0],[0]
E,B.2. Proof of Theorem,[0],[0]
"[∣∣∣∣∣∣δz(d)⊥ ∣∣∣∣∣∣]
For ReLUs, we require h(d+1)i = w (d+1) i z",B.2. Proof of Theorem,[0],[0]
"(d) i + b (d+1) i > 0 where the bias and weight are drawn from N (0, σ2b ) and N (0, σ2w) respectively.",B.2. Proof of Theorem,[0],[0]
"But with p ≥ 1/4, this holds as the signs for w, b are purely random.",B.2. Proof of Theorem,[0],[0]
"Substituting in and working through results in the same asymptotic behavior as without bias.
",B.2. Proof of Theorem,[0],[0]
"For hard tanh, not that as h(d+1)i is a normal random variable with variance ≤ σ2w",B.2. Proof of Theorem,[0],[0]
"+ σ2b (as equation (b) becomes
P(|h(d+1)i | < 1) ≥ 1√
(σ2w + σ 2 b )",B.2. Proof of Theorem,[0],[0]
"√ 2π
This gives Theorem 3
E",B.2. Proof of Theorem,[0],[0]
[∣∣∣∣∣∣δz(d+1)∣∣∣∣∣∣] ≥ O  σw (σ2w + σ 2 b ) 1/4 ·,B.2. Proof of Theorem,[0],[0]
"√ k√√
σ2w",B.2. Proof of Theorem,[0],[0]
"+ σ 2 b + k
E",B.2. Proof of Theorem,[0],[0]
"[∣∣∣∣∣∣δz(d)⊥ ∣∣∣∣∣∣]
Statement and Proof of Upper Bound for Trajectory Growth for Hard Tanh Replace hard-tanh with a linear coordinate-wise identity map, h(d+1)i = (W
(d)z(d))i + bi.",B.2. Proof of Theorem,[0],[0]
This provides an upper bound on the norm.,B.2. Proof of Theorem,[0],[0]
"We also then recover a chi distribution with k terms, each with standard deviation σw
k 1 2
,
E",B.2. Proof of Theorem,[0],[0]
[∣∣∣∣∣∣δz(d+1)∣∣∣∣∣∣] ≤ √2Γ,B.2. Proof of Theorem,[0],[0]
"((k + 1)/2)
",B.2. Proof of Theorem,[0],[0]
"Γ (k/2)
σw k 1 2 ∣∣∣∣∣∣δz(d)∣∣∣∣∣∣ (2) ≤ σw ( k + 1
k
) 1 2 ∣∣∣∣∣∣δz(d)∣∣∣∣∣∣ , (3)
where the second step follows from (Laforgia and Natalini, 2013), and holds for k > 1.",B.2. Proof of Theorem,[0],[0]
Proof.,Proof of Theorem 4,[0],[0]
"For σb = 0: For hidden layer d < n, consider neuron v(d)1 .",Proof of Theorem 4,[0],[0]
This has as input ∑k i=1W (d−1) i1 z,Proof of Theorem 4,[0],[0]
(d−1) i .,Proof of Theorem 4,[0],[0]
"As we are in the large σ case, we assume that |z(d−1)i | = 1.",Proof of Theorem 4,[0],[0]
"Furthermore, as signs for z (d−1) i and W (d−1) i1 are both completely random, we can also assume wlog that z(d−1)i = 1.",Proof of Theorem 4,[0],[0]
"For a particular input, we can define v (d) 1 as sensitive to v (d−1) i if v (d−1) i transitioning (to
wlog −1) will induce a transition in node v(d)1 .",Proof of Theorem 4,[0],[0]
A sufficient condition for this to happen is if |Wi1| ≥ | ∑ j 6=iWj1|.,Proof of Theorem 4,[0],[0]
"But
X = Wi1 ∼ N (0, σ2/k) and ∑ j 6=iWj1 = Y
′",Proof of Theorem 4,[0],[0]
"∼ N (0, (k− 1)σ2/k).",Proof of Theorem 4,[0],[0]
So we want to compute P(|X| > |Y ′|).,Proof of Theorem 4,[0],[0]
"For ease of computation, we instead look at P(|X| > |Y |), where Y ∼ N (0, σ2).
",Proof of Theorem 4,[0],[0]
But this is the same as computing P(|X|/|Y | > 1) = P(X/Y < −1) + P(X/Y > 1).,Proof of Theorem 4,[0],[0]
"But the ratio of two centered independent normals with variances σ21 , σ 2 2 follows a Cauchy distribution, with parameter σ1/σ2, which in this case is
1/ √ k. Substituting this in to the cdf of the Cauchy distribution, we get that
P ( |X| |Y | > 1 )",Proof of Theorem 4,[0],[0]
"= 1− 2 π arctan( √ k)
Finally, using the identity arctan(x)+arctan(1/x) and the Laurent series for arctan(1/x), we can evaluate the right hand side to be O(1/ √ k).",Proof of Theorem 4,[0],[0]
In particular P ( |X| |Y | > 1 ) ≥ O ( 1√ k ),Proof of Theorem 4,[0],[0]
(c),Proof of Theorem 4,[0],[0]
"This means that in expectation, any neuron in layer d will be sensitive to the transitions of √ k neurons in the layer below.",Proof of Theorem 4,[0],[0]
"Using this, and the fact the while v(d−1)i might flip very quickly from say −1 to 1, the gradation in the transition ensures that neurons in layer d sensitive to v(d−1)i will transition at distinct times, we get the desired growth rate in expectation as follows:
Let T (d) be a random variable denoting the number of transitions in layer d.",Proof of Theorem 4,[0],[0]
"And let T (d)i be a random variable denoting the number of transitions of neuron i in layer d. Note that by linearity of expectation and symmetry, E [ T (d) ]",Proof of Theorem 4,[0],[0]
"= ∑ i E [ T (d) i ] =
kE [ T
(d) 1 ]",Proof of Theorem 4,[0],[0]
"Now, E [ T
(d+1) 1
] ≥",Proof of Theorem 4,[0],[0]
E,Proof of Theorem 4,[0],[0]
"[∑ i 1(1,i)T (d) i ] = kE [ 1(1,1)T (d) 1 ] where 1(1,i) is the indicator function of neuron 1 in layer d+ 1
being sensitive to neuron i in layer d.",Proof of Theorem 4,[0],[0]
"But by the independence of these two events, E [ 1(1,1)T (d) 1 ] = E [ 1(1,1) ]",Proof of Theorem 4,[0],[0]
· E [ T (d) 1 ] .,Proof of Theorem 4,[0],[0]
"But the firt time on the right hand side is O(1/ √ k) by (c), so putting it all together, E [ T
(d+1) 1
] ≥ √ kE [ T
(d) 1
] .
",Proof of Theorem 4,[0],[0]
"Written in terms of the entire layer, we have E [ T (d+1) ]",Proof of Theorem 4,[0],[0]
"≥ √ kE [ T (d) ] as desired.
",Proof of Theorem 4,[0],[0]
"For σb > 0: We replace √ k with √ k(1 + σ2b/σ 2 w), by noting that Y ∼ N (0, σ2w + σ2b ).",Proof of Theorem 4,[0],[0]
"This results in a growth rate of form
O( √ k/ √
1 + σ2b σ2w ).
",Proof of Theorem 4,[0],[0]
B.3.,Proof of Theorem 4,[0],[0]
"Dichotomies: a natural dual
Our measures of expressivity have mostly concentrated on sweeping the input along a trajectory x(t) and taking measures of FA(x(t);W ).",Proof of Theorem 4,[0],[0]
"Instead, we can also sweep the weights W along a trajectory W (t), and look at the consequences (e.g. binary labels – i.e. dichotomies), say for a fixed set of inputs x1, ..., xs.
",Proof of Theorem 4,[0],[0]
"In fact, after random initialization, sweeping the first layer weights is statistically very similar to sweeping the input along a trajectory x(t).",Proof of Theorem 4,[0],[0]
"In particular, letting W ′ denote the first layer weights, for a particular input x0, x0W ′ is a vector, each coordinate is iid, ∼ N (0, ||x0||2σ2w).",Proof of Theorem 4,[0],[0]
"Extending this observation, we see that (providing norms are chosen appropriately), x0W ′ cos(t) +x1W ′",Proof of Theorem 4,[0],[0]
"sin(t) (fixed x0, x1,W ) has the same distribution as x0W ′0 cos(t) +x0W ′",Proof of Theorem 4,[0],[0]
"1 sin(t) (fixed x0,W ′",Proof of Theorem 4,[0],[0]
"0,W ′",Proof of Theorem 4,[0],[0]
"1).
",Proof of Theorem 4,[0],[0]
"So we expect that there will be similarities between results for sweeping weights and for sweeping input trajectories, which we explore through some synthetic experiments, primarily for hard tanh, in Figures 15, 16.",Proof of Theorem 4,[0],[0]
"We find that the proportionality of transitions to trajectory length extends to dichotomies, as do results on the expressive power afforded by remaining depth.
",Proof of Theorem 4,[0],[0]
"For non-random inputs and non-random functions, this is a well known question upper bounded by the Sauer-Shelah lemma (Sauer, 1972).",Proof of Theorem 4,[0],[0]
We discuss this further in Appendix ??.,Proof of Theorem 4,[0],[0]
"In the random setting, the statistical duality of weight sweeping and input sweeping suggests a direct proportion to transitions and trajectory length for a fixed input.",Proof of Theorem 4,[0],[0]
"Furthermore, if the xi ∈ S are sufficiently uncorrelated (e.g. random) class label transitions should occur independently for each xi",Proof of Theorem 4,[0],[0]
"Indeed, we show this in Figure 14.",Proof of Theorem 4,[0],[0]
Here we include additional experiments from Section 3,C. Addtional Experiments from Section 3,[0],[0]
"We propose a new approach to the problem of neural network expressivity, which seeks to characterize how structural properties of a neural network family affect the functions it is able to compute.",abstractText,[0],[0]
"Our approach is based on an interrelated set of measures of expressivity, unified by the novel notion of trajectory length, which measures how the output of a network changes as the input sweeps along a one-dimensional path.",abstractText,[0],[0]
Our findings can be summarized as follows: (1) The complexity of the computed function grows exponentially with depth.,abstractText,[0],[0]
We design measures of expressivity that capture the non-linearity of the computed function.,abstractText,[0],[0]
"Due to how the network transforms its input, these measures grow exponentially with depth.",abstractText,[0],[0]
(2) All weights are not equal (initial layers matter more).,abstractText,[0],[0]
"We find that trained networks are far more sensitive to their lower (initial) layer weights: they are much less robust to noise in these layer weights, and also perform better when these weights are optimized well.",abstractText,[0],[0]
(3) Trajectory Regularization works like Batch Normalization.,abstractText,[0],[0]
"We find that batch norm stabilizes the learnt representation, and based on this propose a new regularization scheme, trajectory regularization.",abstractText,[0],[0]
On the Expressive Power of Deep Neural Networks,title,[0],[0]
"ar X
iv :1
80 2.
03 69
0v 3
[ st
at .M
L ]
1 0
N ov
2 01
tremely successful in the image recognition domain because they ensure equivariance to translations. There have been many recent attempts to generalize this framework to other domains, including graphs and data lying on manifolds. In this paper we give a rigorous, theoretical treatment of convolution and equivariance in neural networks with respect to not just translations, but the action of any compact group. Our main result is to prove that (given some natural constraints) convolutional structure is not just a sufficient, but also a necessary condition for equivariance to the action of a compact group. Our exposition makes use of concepts from representation theory and noncommutative harmonic analysis and derives new generalized convolution formulae.",text,[0],[0]
"One of the most successful neural network architectures is convolutional neural networks (CNNs) (LeCun et al., 1989).",1. Introduction,[0],[0]
"In the image recognition domain, where CNNs were originally conceived, convolution plays two crucial roles.",1. Introduction,[0],[0]
"First, it ensures that in any given layer, exactly the same filters are applied to each part of the image.",1. Introduction,[0],[0]
"Consequently, if the input image is translated, the activations of the network in each layer will translate the same way.",1. Introduction,[0],[0]
"This property is called equivariance (Cohen & Welling, 2016).",1. Introduction,[0],[0]
"Second, in conjunction with pooling, convolution ensures that each neuron’s effective receptive field is a spatially contiguous domain.",1. Introduction,[0],[0]
"As we move higher in the network, these domains generally get larger, allowing the CNN to capture structure in images at multiple different scales.
",1. Introduction,[0],[0]
"1Departments of Statistics and Computer Science, The University of Chicago 2Toyota Technological Institute at Chicago.",1. Introduction,[0],[0]
Correspondence to:,1. Introduction,[0],[0]
"Risi Kondor <risi@cs.uchicago.edu>, Shubhendu Trivedi <shubhendu@ttic.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"Recently, there has been considerable interest in extending neural networks to more exotic types of data, such as graphs or functions on manifolds (Niepert et al., 2016; Defferrard et al., 2016; Duvenaud et al., 2015; Li et al., 2016; Cohen et al., 2018; Monti et al., 2017; Masci et al., 2015).",1. Introduction,[0],[0]
"In these domains, equivariance and multiscale structure are just as important as for images, but finding the right notion of convolution is not obvious.
",1. Introduction,[0],[0]
"On the other hand, mathematics does offer a sweeping generalization of convolution tied in deeply with some fundamental ideas of abstract algebra: if G is a compact group and f and g are two functionsG→ C, then the convolution of f with g is defined
(f ∗ g)(u) = ∫
G
f(uv−1) g(v) dµ(v).",1. Introduction,[0],[0]
"(1)
Note the striking similarity of this formula to the ordinary notion of convolution, except that in the argument of f , u − v has been replaced by the group operation uv−1, and integration is with respect to the Haar measure, µ.
The goal of this paper is to relate (1) to the various looser notions of convolution used in the neural networks literature, and show that several practical neural networks implicitly already take advantange of the above group theoretic concept of convolution.",1. Introduction,[0],[0]
"In particular, we prove the following theorem (paraphrased here for simplicity).
",1. Introduction,[0],[0]
Theorem 1.,1. Introduction,[0],[0]
"A feed forward neural network N is equivariant to the action of a compact group G on its inputs if and only if each layer of N implements a generalized form of convolution derived from (1).
",1. Introduction,[0],[0]
"To the best of our knowledge, this is the first time that the connection between equivariance and convolution in neural networks has been stated at this level of generality.",1. Introduction,[0],[0]
One of the technical challenges in proving our theorem is that the activations in each layer of a neural net correspond to functions on a sequence of spaces acted on byG (called homogeneous spaces or quotient spaces) rather than functions on G itself.,1. Introduction,[0],[0]
"This necessitates a discussion of group convolution that is rather more thoroughgoing than is customary in pure algebra.
",1. Introduction,[0],[0]
"This paper does not present any new algorithms or neural
network architectures.",1. Introduction,[0],[0]
"Rather, its goal is to provide the language for thinking about generalized notions of equivariance and convolution in neural networks, and thereby facilitate the development of future architectures for data with non-trivial symmetries.",1. Introduction,[0.9502205407857891],"['The simplicity of the approach makes the algorithm extremely flexible, and allows for future extensions, including time-varying networks and an analysis for non-strongly-convex functions.']"
"To avoid interruptions in the flow of our exposition, we first present the theory in its abstract form, and then illustrate it with examples in Section 6.",1. Introduction,[0],[0]
"For better understanding, the reader might choose to skip back and forth between these sections.",1. Introduction,[0],[0]
"One work that is close in spirit to the present paper but only considers discrete groups is (Ravanbakhsh et al., 2017).",1. Introduction,[0],[0]
"In the following [a] will denote the set {1, 2, . . .",2. Notation,[0],[0]
", a}.",2. Notation,[0],[0]
"Given a set X and a vector space V , LV (X ) will denote the space of functions {f : X → V }.",2. Notation,[0],[0]
A feed-forward neural network consists of some number of “neurons” arranged in L+1 distinct layers.,3. Equivariance in neural networks,[0],[0]
Layer ℓ,3. Equivariance in neural networks,[0],[0]
"= 0 is the input layer, where data is presented to the network, while layer ℓ=L is where the output is read out.",3. Equivariance in neural networks,[0],[0]
Each neuron nℓx (denoting neuron number x in layer ℓ) has an activation f ℓx.,3. Equivariance in neural networks,[0],[0]
"For the input layer, the activations come directly from the data, whereas in higher layers they are computed via a simple function of the activations of the previous layer, such as f ℓx = σ ( bℓx + ∑ y w ℓ x,y f ℓ−1 y ) .",3. Equivariance in neural networks,[0],[0]
"(2) Here, the {bℓx} bias terms and the {wℓx,y} weights are the network’s learnable parameters, while σ is a fixed nonlinear function, such as the ReLU function σ(z) =max(0, z).",3. Equivariance in neural networks,[0],[0]
"In the simplest case, each f ℓx is a scalar, but, in the second half of the paper we consider neural networks with more general, vector or tensor valued activations.
",3. Equivariance in neural networks,[0],[0]
"For the purposes of the following discussion it is actually helpful to take a slightly more abstract view, and, instead of focusing on the individual activations, consider the activations in any given layer collectively as a function f ℓ",3. Equivariance in neural networks,[0],[0]
:,3. Equivariance in neural networks,[0],[0]
"Xℓ → Vℓ, where Xℓ is a set indexing the neurons and Vℓ is a vector space.",3. Equivariance in neural networks,[0],[0]
"Omitting the bias terms in (2) for simplicity, each layer ℓ = 1, 2, . . .",3. Equivariance in neural networks,[0],[0]
", L can then just be thought of as implementing a linear transformation φℓ : LVℓ−1(Xℓ−1) → LVℓ(Xℓ) followed by the pointwise nonlinearity σ.",3. Equivariance in neural networks,[0],[0]
"Our operational definition of neural networks for the rest of this paper will be as follows.
",3. Equivariance in neural networks,[0],[0]
Definition 1.,3. Equivariance in neural networks,[0],[0]
"Let X0, . . .",3. Equivariance in neural networks,[0],[0]
",XL be a sequence of index sets, V0, . . .",3. Equivariance in neural networks,[0],[0]
", VL vector spaces, φ1, . . .",3. Equivariance in neural networks,[0],[0]
", φL linear maps φℓ : LVℓ−1(Xℓ−1) −→ LVℓ(Xℓ), and σℓ :",3. Equivariance in neural networks,[0],[0]
"Vℓ → Vℓ appropriate pointwise nonlinearities, such as the ReLU operator.",3. Equivariance in neural networks,[0],[0]
"The corresponding multilayer feed-forward neural network (MFF-NN) is then a
sequence of maps f0 7→ f1 7→ f2 7→ . . .",3. Equivariance in neural networks,[0],[0]
"7→ fL, where fℓ(x) = σℓ(φℓ(fℓ−1)(x)).
",3. Equivariance in neural networks,[0],[0]
"If we are interested in constructing a neural net for recognizing m × m pixel images, it is tempting to take X0 =",3. Equivariance in neural networks,[0],[0]
"[m]× [m] and define X1, . . .",3. Equivariance in neural networks,[0],[0]
",XL similarly.",3. Equivariance in neural networks,[0],[0]
"However, again for notational simplicity, we extend each of these index sets to the entire integer plane Z2, and simply assume that outside of the square region [m]× [m], f0(x1, x2) = 0.",3. Equivariance in neural networks,[0],[0]
"A traditional convolutional neural network (CNN) is a network of this type where the φℓ functions are constrained to have the special form
φℓ(fℓ−1)(x1, x2) = w∑
u1=1
w∑
u2=1
fℓ−1(x1−u1, x2−u2) χℓ(u1, u2).",3. Equivariance in neural networks,[0],[0]
"(3)
The above function is known as the discrete convolution of f ℓ−1 with the filter χ, and is usually denoted fℓ−1 ∗ χℓ.",3. Equivariance in neural networks,[0],[0]
"In most CNNs the width w of the filters is quite small, on the order of 3 ∼ 10, while the number of layers can be as small as 3 or as large as a few dozen.
",3. Equivariance in neural networks,[0],[0]
"Some of the key features of CNNs are immediately apparent from the convolution formula (3):
1.",3. Equivariance in neural networks,[0],[0]
"The number of parameters in CNNs is much smaller
than in general (fully connected) feed-forward networks, since we only have to learn the w2 numbers defining the χℓ filters rather than O((m
2)2) weights.",3. Equivariance in neural networks,[0],[0]
"2. (3) applies the same filter to every part of the image.
",3. Equivariance in neural networks,[0],[0]
"Therefore, if the networks learns to recognize a certain feature, e.g., eyes, in one part of the image, then it will be able to do so in any other part as well.",3. Equivariance in neural networks,[0],[0]
3.,3. Equivariance in neural networks,[0],[0]
"Equivalently to the above, if the input image is trans-
lated by any vector (t1, t2) (i.e., f 0′(x1, x2)",3. Equivariance in neural networks,[0],[0]
"= f 0(x1− t1, x2 − t2), then all higher layers will translate in exactly the same way.",3. Equivariance in neural networks,[0],[0]
"This property is called equivariance (sometimes covariance) to translations.
",3. Equivariance in neural networks,[0],[0]
"The goal of the present paper is to understand the mathematical generalization of the above properties to other domains, such as graphs, manifolds, and so on.",3. Equivariance in neural networks,[0],[0]
"The jumping off point to our analysis is the observation that the above is a special case of the following scenario.
",3.1. Group actions,[0],[0]
1.,3.1. Group actions,[0],[0]
We have a set X and a function f :,3.1. Group actions,[0],[0]
X → C. 2.,3.1. Group actions,[0],[0]
We have a group G acting on X .,3.1. Group actions,[0],[0]
This means that each g ∈G has a corresponding transformation,3.1. Group actions,[0],[0]
"Tg : X → X , and for any g1, g2 ∈G, Tg2g1 = Tg2 ◦ Tg1 .",3.1. Group actions,[0],[0]
3.,3.1. Group actions,[0],[0]
The action of G on X extends to functions on X by Tg : f 7→ f ′ f ′(Tg(x)),3.1. Group actions,[0],[0]
"= f(x).
",3.1. Group actions,[0],[0]
"In the case of translation invariant image recognition, X = Z2, G is the group of integer translations, which is isomorphic to Z2 (note that this is a very special case, in general
X and G are different objects), the action is
T(t1,t2)(x1, x2) =",3.1. Group actions,[0],[0]
"(x1+ t1, x2+ t2) (t1, t2)∈Z2,
and the corresponding (induced) action on functions is
T : f 7→ f ′ f ′(x1, x2) = f(x1−",3.1. Group actions,[0],[0]
"t1, x2− t2).
",3.1. Group actions,[0],[0]
"We give several other (more interesting) examples of group actions in Section 6, but for now continue with our abstract development.",3.1. Group actions,[0],[0]
"Also note that to simplify notation, in the following, where this does not cause confusion, we will simply write group actions as x 7→ g(x) rather than the more cumbersome x 7→ Tg(x).",3.1. Group actions,[0],[0]
"Most of the actions considered in this paper have the property that taking any x0 ∈X , any other x∈X can be reached by the action of some g ∈G, i.e., x= g(x0).",3.1. Group actions,[0],[0]
"This property is called transitivity, and if the action of G on X is transitive, we say that X is a homogeneous space of G.",3.1. Group actions,[0],[0]
"Equivariance is a concept that applies very broadly, whenever we have a group acting on a pair of spaces and there is a map from functions on one to functions on the other.
",3.2. Equivariance,[0],[0]
Definition 2.,3.2. Equivariance,[0],[0]
"LetG be a group and X1,X2 be two sets with correspondingG-actions
Tg : X1 → X1, T ′g : X2 → X2.
",3.2. Equivariance,[0],[0]
"Let V1 and V2 be vector spaces, and T and T ′ be the induced actions of G on LV1(X1) and LV2(X2).",3.2. Equivariance,[0],[0]
We say that a (linear or non-linear) map φ : LV1(X1) → LV2(X2) is equivariant with the action of G (or G–equivariant for short),3.2. Equivariance,[0],[0]
"if
φ(Tg(f))",3.2. Equivariance,[0],[0]
= T ′ g(φ(f)) ∀f,3.2. Equivariance,[0],[0]
"∈LV1(X1)
for any group element g ∈G.
Equivariance is represented graphically by a so-called commutative diagram, in our case
LV1(X1)",3.2. Equivariance,[0],[0]
"Tg //
φ
LV1(X1)
φ
LV2(X2) T ′",3.2. Equivariance,[0],[0]
"g // LV2(X2)
",3.2. Equivariance,[0],[0]
"We are finally in a position to define the objects that we study in this paper, namely generalized equivariant neural networks.
",3.2. Equivariance,[0],[0]
Definition 3.,3.2. Equivariance,[0],[0]
"Let N be a feed-forward neural network as defined in Definition 1, andG be a group that acts on each index spaceX0, . . .",3.2. Equivariance,[0],[0]
",XL.",3.2. Equivariance,[0],[0]
"Let T0,T1, . . .",3.2. Equivariance,[0],[0]
",TL be the corresponding actions on LV0(X0), . . .",3.2. Equivariance,[0],[0]
", LVL(XL).",3.2. Equivariance,[0],[0]
"We say that N is a G–equivariant feed-forward network if, when the inputs are transformed f0 7→ T0g(f0)",3.2. Equivariance,[0],[0]
"(for any g ∈ G), the activations of the other layers correspondingly transform as fℓ 7→ Tℓg(fℓ).
",3.2. Equivariance,[0],[0]
It is important to note how general the above framework is.,3.2. Equivariance,[0],[0]
"In particular, we have not said whether G and X0, . . .",3.2. Equivariance,[0],[0]
",XL are discrete or continuous.",3.2. Equivariance,[0],[0]
"In any actual implementation of a neural network, the index sets would of course be finite.",3.2. Equivariance,[0],[0]
"However, it has been observed before that in certain cases, specifically whenX0 is an object such as the sphere or other manifold which does not have a discretization that fully takes into account its symmetries, it is easier to describe the situation in terms of abstract “continuous” neural networks than seemingly simpler discrete ones (Cohen et al., 2018).
",3.2. Equivariance,[0],[0]
"Note also that invariance is a special case of equivariance, where Tg = id for all g. In fact, this is another major reason why equivariant architectures are so prevalent in the literature: any equivariant network can be turned into a G– invariant network simply by tacking on an extra layer that is equivariant in this degenerate sense (in practice, this often means either averaging or creating a histogram of the activations of the last layer).",3.2. Equivariance,[0],[0]
"Nowhere is this more important than in graph learning, where it is a hard constraint that whatever representation is learnt by a neural network, it must be invariant to reordering the vertices.",3.2. Equivariance,[0],[0]
"Today’s state of the art solution to this problem are message passing networks (Gilmer et al., 2017), whose invariance behavior we discuss in section 6.",3.2. Equivariance,[0],[0]
"Another architecture that achieves invariance by stacking equivariant layers followed by a final invariant one is that of scattering networks (Mallat, 2012).",3.2. Equivariance,[0],[0]
"According to its usual definition in signal processing, the convolution of two functions f, g : R → R is
(f ∗ g)(x) = ∫ f(x−y) g(y) dy.",4. Convolution on groups and quotient spaces,[0],[0]
"(4)
Intuitively, we can think of f as a template and g as a modulating function (or the other way round, since convolution on R is commutative): we get f ∗ g by a placing a “copy” of f at each point on the x axis, but scaled by the value of g at that point, and superimposing the results.",4. Convolution on groups and quotient spaces,[0],[0]
"The discrete variant of (4) for f, g : Z → R is of course
(f ∗ g)(x) = ∑
y∈Z
f(x− y) g(y), (5)
and both the above formulae have natural generalizations to higher dimensions.",4. Convolution on groups and quotient spaces,[0],[0]
"In particular, (3) is just the two dimensional version of (5) with a limited width filter.
",4. Convolution on groups and quotient spaces,[0],[0]
"What we are interested in for this paper, however, is the much broader generalization of convolution to the case when f and g are functions on a compact group G. As mentioned in the Introduction, this takes the form
(f ∗ g)(u) = ∫
G
f(uv−1) g(v) dµ(v).",4. Convolution on groups and quotient spaces,[0.9533059126441747],"['In this section, we show that, for any black-box optimization procedure, at least Ω(√κg ln(1/ε)) gradient steps and Ω(∆ √ κg ln(1/ε)) communication steps are necessary to achieve a precision ε > 0, where κg is the global condition number and ∆ is the diameter of the network.']"
"(6)
Note that (6) only differs from (4) in that x−y is replaced by the group operation uv−1, which is not surprising, since the group operation on R in fact is exactly (x, y) 7→ x+y, and the “inverse” of y in the group sense is −y.",4. Convolution on groups and quotient spaces,[0],[0]
"Furthermore, the Haar measure µmakes an appearance.",4. Convolution on groups and quotient spaces,[0],[0]
"At this point, the main reason that we restrict ourselves to compact groups is because this guarantees that µ is essentially unique1.",4. Convolution on groups and quotient spaces,[0],[0]
"The discrete counterpart of (6) for countable (including finite) groups is
(f ∗ g)(u) = ∑
v∈G
f(uv−1) g(v).",4. Convolution on groups and quotient spaces,[0],[0]
"(7)
All these definitions are standard and have deep connections to the algebraic properties of groups.",4. Convolution on groups and quotient spaces,[0],[0]
"In contrast, the various extensions of convolution to homogeneous spaces that we derive below are not often discussed in pure algebra.",4. Convolution on groups and quotient spaces,[0],[0]
"The major complication in neural networks is that X0, . . .",4.1. Convolution on quotient spaces,[0],[0]
",XL (which are the spaces that the f0, . . .",4.1. Convolution on quotient spaces,[0],[0]
", fL activations are defined on) are homogeneous spaces of G, rather than being G itself.",4.1. Convolution on quotient spaces,[0],[0]
"Fortunately, the strong connection between the structure of groups and their homogeneous spaces (see boxed text) allows generalizing convolution to this case as well.",4.1. Convolution on quotient spaces,[0],[0]
"Note that from now on, to keep the exposition as simple as possible, we present our results assuming thatG is countable (or finite).",4.1. Convolution on quotient spaces,[0],[0]
The generalization to continuous groups is straightforward.,4.1. Convolution on quotient spaces,[0],[0]
"We also allow all our functions to be complex valued, because representation theory itself, which is the workhorse behind our results, is easiest to formulate over C.
Definition 4.",4.1. Convolution on quotient spaces,[0],[0]
"Let G be a finite or countable group, X and Y be (left or right) quotient spaces of G, f : X → C, and g : Y → C. We then define the convolution of f with g as
(f ∗ g)(u) = ∑
v∈G
f↑G(uv−1) g↑G(v), u∈G. (8)
1Non-compact groups would also cause trouble because their representation theory is much more involved.",4.1. Convolution on quotient spaces,[0],[0]
"R2, which is the group behind traditional CCNs, is of course not compact.",4.1. Convolution on quotient spaces,[0],[0]
"The reason that it is still amenable to our analysis (with small modifications) is that it belongs to one of a handful of families of exceptional non-compact groups that are easy to handle.
ESSENTIAL DEFINITIONS FOR QUOTIENT SPACES
Certain connections between the structure of a group G and its homogeneous space X are crucial for our exposition.",4.1. Convolution on quotient spaces,[0],[0]
"First, by definition, fixing an “origin” x0 ∈X , any x∈X can be reached as x= g(x0) for some g ∈G.",4.1. Convolution on quotient spaces,[0],[0]
"This allows us to “index” elements of X by elements of G. Since we use this mechanism so often, we introduce the shorthand",4.1. Convolution on quotient spaces,[0],[0]
"[g ]X = g(x0), which hides the dependence on the (arbitrary) choice of x0.",4.1. Convolution on quotient spaces,[0],[0]
"Second, elementary group theory tells us that the set of group elements that fix x0 actually form a subgroup H .",4.1. Convolution on quotient spaces,[0],[0]
"By further elementary results (see Appendix), the set of group elements that map x0 7→ x is a so-called left coset gH",4.1. Convolution on quotient spaces,[0],[0]
:,4.1. Convolution on quotient spaces,[0],[0]
= {gh | h∈H }.,4.1. Convolution on quotient spaces,[0],[0]
The set of all such cosets forms the (left) quotient space G/H .,4.1. Convolution on quotient spaces,[0],[0]
"Therefore, X can be identified with G/H .",4.1. Convolution on quotient spaces,[0],[0]
"Now for each gH coset we may pick a coset representative g′ ∈ gH , and let x denote the representative of the coset of group elements that map x0 to x. Note",4.1. Convolution on quotient spaces,[0],[0]
"that while the map g 7→ [g ]G/H is well defined, the map x 7→ x going in the opposite direction is more arbitary, since it depends on the choice of coset representatives.",4.1. Convolution on quotient spaces,[0],[0]
The right quotient space H\G is similarly defined as the space of right cosets,4.1. Convolution on quotient spaces,[0],[0]
Hg := {hg | h∈H }.,4.1. Convolution on quotient spaces,[0],[0]
"Furthermore, if K is another subgroup of G, we can talk about double cosets HgK = {hgk | h∈H, k ∈K } and the corresponding space H\G/K .",4.1. Convolution on quotient spaces,[0],[0]
"Given f :G→C, we define its projection to X =G/H
f↓X : X → C f↓X (x) = 1 |H | ∑
g∈xH
f(g).
",4.1. Convolution on quotient spaces,[0],[0]
"Conversely, given f : X → C, we define the lifting of f to G f↑G : G→ C f↑G(g) = f([g ]X ).",4.1. Convolution on quotient spaces,[0],[0]
"Projection and lifting to/from right quotient spaces and double quotient spaces is defined analogously.
",4.1. Convolution on quotient spaces,[0],[0]
"This definition includes X =G or Y =G as special cases, since any group is a quotient space of itself with respect to the trivial subgroup H = {e}.
",4.1. Convolution on quotient spaces,[0],[0]
"Definition 4 hides the facts that depending on the choice of X and Y: (a) the summation might only have to extend over a quotient space of G rather than the entire group, (b) the result f ∗g",4.1. Convolution on quotient spaces,[0],[0]
might have symmetries that effectively make it a function on a quotient space rather than G itself (this is exactly what the case will be in generalized convolutional networks).,4.1. Convolution on quotient spaces,[0],[0]
"Therefore we now discuss three special cases.
",4.1. Convolution on quotient spaces,[0],[0]
CASE,4.1. Convolution on quotient spaces,[0],[0]
I: X =G AND Y =G/H,4.1. Convolution on quotient spaces,[0],[0]
When f :,4.1. Convolution on quotient spaces,[0],[0]
G→ C,4.1. Convolution on quotient spaces,[0],[0]
"but g : G/H → C for some subgroup H of G, (8) reduces to
(f ∗ g)(u) = ∑
v∈G
f(uv−1) g↑G(v).
",4.1. Convolution on quotient spaces,[0],[0]
"Plugging u′ = uh into this formula (for any h ∈ H) and changing the variable of summation to w := vh−1 gives
(f ∗ g)(u′) =",4.1. Convolution on quotient spaces,[0],[0]
"∑
v∈G
f(uhv−1) g↑G(v)
= ∑
w∈G
f(uw−1) g↑G(wh).
",4.1. Convolution on quotient spaces,[0],[0]
"However, since w and wh are in the same left H–coset, g↑G(wh) = g↑G(w), so (f ∗ g)(u′) =",4.1. Convolution on quotient spaces,[0],[0]
"(f ∗ g)(u), i.e., f ∗ g is constant on left H–cosets.",4.1. Convolution on quotient spaces,[0],[0]
This makes it natural to interpret f ∗ g,4.1. Convolution on quotient spaces,[0],[0]
as a function on G/H rather than the full group,4.1. Convolution on quotient spaces,[0],[0]
.,4.1. Convolution on quotient spaces,[0],[0]
"Thus, we have the following definition.
",4.1. Convolution on quotient spaces,[0],[0]
"If f : G→C, and g : G/H→C then f ∗g : G/H → C with
(f ∗ g)(x) = ∑
v∈G
f(xv−1) g([v",4.1. Convolution on quotient spaces,[0],[0]
]G/H ).,4.1. Convolution on quotient spaces,[0],[0]
"(9)
CASE II: X =G/H AND Y =H\G",4.1. Convolution on quotient spaces,[0],[0]
"When f : G/H → C, but g : G→ C, (8) reduces to
(f ∗ g)(u) = ∑
v∈G
f↑G(uv−1) g(v).",4.1. Convolution on quotient spaces,[0],[0]
"(10)
This time it is not f ∗ g, but g that shows a spurious symmetry.",4.1. Convolution on quotient spaces,[0],[0]
Letting v′ =,4.1. Convolution on quotient spaces,[0],[0]
"hv (for any h∈H), by the right H–invariance of f↑G, f↑G(uv′−1) = f↑G(uv−1h−1) = f↑G(uv).",4.1. Convolution on quotient spaces,[0],[0]
"Considering that any v can be uniquely written as v = hy, where y is the representative of one of its cosets, while h ∈ H , we get that (10) factorizes in the form
(f ∗ g)(u) = ∑
y∈H\G
f↑G(uy−1) ∑
h∈H
g(hy)
= ∑
y∈H\G
f↑G(uy−1) g̃(y),
where g̃(y) := ∑
h∈H g(hy).",4.1. Convolution on quotient spaces,[0],[0]
"In other words, without loss of generality we can take g to be a function on H\G rather than the full group.
",4.1. Convolution on quotient spaces,[0],[0]
"If f : G/H → C, and g : H\G→ C, then f∗g : G→ C with
(f ∗ g)(u) = |H",4.1. Convolution on quotient spaces,[0],[0]
"| ∑
y∈H\G
f([uy−1",4.1. Convolution on quotient spaces,[0],[0]
]G/H) g(y).,4.1. Convolution on quotient spaces,[0],[0]
"(11)
CASE III: X =G/H AND Y =H\G/K",4.1. Convolution on quotient spaces,[0],[0]
"Finally, we consider the case when f : G/H → C and g : G/K → C for two subgroups H,K of G, which might or might not be the same.",4.1. Convolution on quotient spaces,[0],[0]
"This combines features of the above two cases in the sense that, similarly to Case I, setting u′ = uk for any k ∈K and letting w = vk−1,
(f ∗ g)(u′)",4.1. Convolution on quotient spaces,[0],[0]
=,4.1. Convolution on quotient spaces,[0],[0]
"∑
v∈G
f↑G(u′v−1) g↑G(v) =
= ∑
v∈G
f↑G(ukv−1) g↑G(v) =",4.1. Convolution on quotient spaces,[0],[0]
"∑
w∈G
f↑G(uw−1) g↑G(wk)
",4.1. Convolution on quotient spaces,[0],[0]
"= ∑
w∈G
f↑G(uw−1) g↑G(w) =",4.1. Convolution on quotient spaces,[0],[0]
"(f ∗ g)(u),
showing that f ∗ g is right K–invariant, and therefore can be regarded as a function G/K → C. At the same time, similarly to (10), letting v = hy,
(f ∗ g)(u) = ∑
y∈H\G
f↑G(uy−1) ∑
h∈H
g↑G(hy)
",4.1. Convolution on quotient spaces,[0],[0]
"= ∑
y∈H\G
f↑G(uy−1) g̃(y),
",4.1. Convolution on quotient spaces,[0],[0]
"where g̃(y) := ∑
h∈H g(hy), which is left H–invariant.",4.1. Convolution on quotient spaces,[0],[0]
"Therefore, without loss of generality, we can take g to be a functionH\G/K → C.
If f : G/H → C, and g : H\G/K → C then we define the convolution of f with g as f",4.1. Convolution on quotient spaces,[0],[0]
"∗ g : G/K → C with
(f ∗ g)(x) = |H | ∑
y∈H\G
",4.1. Convolution on quotient spaces,[0],[0]
f([xy−1 ],4.1. Convolution on quotient spaces,[0],[0]
X ) g([y,4.1. Convolution on quotient spaces,[0],[0]
"]H\G/K).
(12)
",4.1. Convolution on quotient spaces,[0],[0]
Since f 7→ f ∗,4.1. Convolution on quotient spaces,[0],[0]
"g is a map from one homogeneous space, X = G/H , to another homogeneous space, Y = H/K , it is this last defintion that will be of most relevance to us in constructing neural networks.",4.1. Convolution on quotient spaces,[0],[0]
"The nature of convolution on homogeneous spaces is further explicated by considering its form in Fourier space (see (Terras, 1999)).",4.2. Relationship to Fourier analysis,[0],[0]
"Recall that the Fourier transform of a function f on a countable group is defined
f̂(ρi) = ∑
u∈G
f(u)ρi(u), i = 0, 1, 2, . . .",4.2. Relationship to Fourier analysis,[0],[0]
", (13)
where ρ0, ρ1, . . .",4.2. Relationship to Fourier analysis,[0],[0]
are matrix valued functions called irreducible representations or irreps of G (see the Appendix for details).,4.2. Relationship to Fourier analysis,[0],[0]
"As expected, the generalization of this to the case when f is a function on G/H , H\G or H\G/K is
f̂(ρi)",4.2. Relationship to Fourier analysis,[0],[0]
=,4.2. Relationship to Fourier analysis,[0],[0]
"∑
u∈G
ρi(u)f↑G(u), i = 1, 2, . . .",4.2. Relationship to Fourier analysis,[0],[0]
".
",4.2. Relationship to Fourier analysis,[0],[0]
"Analogous formulae hold for continuous groups, involving integration with respect to the Haar measure.
",4.2. Relationship to Fourier analysis,[0],[0]
"At first sight it might be surprising that the Fourier transform of a function on a quotient space consists of the same number of matrices of the same sizes as the Fourier transform of a function on G itself, since G/H , H\G or H\G/K are smaller objects than G. This puzzle is resolved by the following proposition, which tells us that in the latter cases, the Fourier matrices have characteristic sparsity patterns.
",4.2. Relationship to Fourier analysis,[0],[0]
Proposition 1.,4.2. Relationship to Fourier analysis,[0],[0]
"Let ρ be an irrep of G, and assume that on restriction to H it decomposes into irreps of H in the form ρ|H = µ1 ⊕ µ2 ⊕ . . .",4.2. Relationship to Fourier analysis,[0],[0]
⊕ µk.,4.2. Relationship to Fourier analysis,[0],[0]
"Let f̂ be the Fourier transform of a function f : G/H → C. Then [f̂(ρ)]∗,j = 0 unless the block at column j in the decomposition of ρ|H is the trivial representation.",4.2. Relationship to Fourier analysis,[0],[0]
"Similarly, if f : H\G → C, then [f̂(ρ)]i,∗ = 0 unless the block of ρ|H at row i is the trivial representation.",4.2. Relationship to Fourier analysis,[0],[0]
"Finally, if f : H\G/K → C, then [f̂(ρ)]i,j = 0 unless the block of ρ|H at row i is the trivial representation of H and the block at column j in the decomposition of ρ|K is the trivial representation of K .
",4.2. Relationship to Fourier analysis,[0],[0]
"Schematically, this proposition implies that in the three different cases, the Fourier matrices have three different forms of sparsity:
G/K H\G H\G/K
Fortuitously, just like in the classical, Euclidean case, convolution also takes on a very nice form in the Fourier domain, even when f or g (or both) are defined on homogeneous spaces.
",4.2. Relationship to Fourier analysis,[0],[0]
Proposition 2 (Convolution theorem on groups).,4.2. Relationship to Fourier analysis,[0],[0]
"Let G be a compact group, H and K subgroups of G, and f, g be complex valued functions on G, G/H , H\G or H\G/K .",4.2. Relationship to Fourier analysis,[0],[0]
"In any combination of these cases,
f̂ ∗g(ρi) = f̂(ρi) ĝ(ρi) (14)
for any given system of irreps RG = {ρ0, ρ1, . . .}.
",4.2. Relationship to Fourier analysis,[0],[0]
"Plugging in matrices with the appropriate sparsity patterns into (19) now gives us an intuitive way of thinking about Cases I–III above.
",4.2. Relationship to Fourier analysis,[0],[0]
CASE,4.2. Relationship to Fourier analysis,[0],[0]
"I: X =G AND Y =G/H Mutiplying a column sparse matrix with a dense matrix from the left gives a column sparse matrix with the same
pattern, therefore f ∗ g is a function on G/H :    
f̂ ∗ g(ρ)
=
 
 
f̂(ρ)
",4.2. Relationship to Fourier analysis,[0],[0]
"×
 
 
ĝ↑G(ρ)
.
",4.2. Relationship to Fourier analysis,[0],[0]
CASE II: X =G/H AND Y =H\G Multiplying a column sparse matrix from the right by another matrix picks out the corresponding rows of the second matrix.,4.2. Relationship to Fourier analysis,[0],[0]
"Therefore, if f is a function on G/H , then w.l.o.g.",4.2. Relationship to Fourier analysis,[0],[0]
"we can take g to be a function on H\G.
 
 
f̂ ∗ g(ρ)
=
 
 
f̂↑G(ρ)
×
 
 
ĝ↑G(ρ)
.
",4.2. Relationship to Fourier analysis,[0],[0]
CASE III: f : G/H → C AND g : H\G/K → C,4.2. Relationship to Fourier analysis,[0],[0]
"Finally, if f is a function on G/H , and we want to make f ∗ g to be a function on G/K , then we should take g : H\G/K:
 
 
f̂ ∗ g(ρ)
=
 
 
f̂↑G(ρ)
×
 
 
ĝ↑G(ρ)
.",4.2. Relationship to Fourier analysis,[0],[0]
"We are finally in a position to define the notion of generalized convolutional networks, and state our main result connecting convolutions and equivariance.
",5. Main result: the connection between convolution and equivariance,[0],[0]
Definition 5.,5. Main result: the connection between convolution and equivariance,[0],[0]
"Let G be a compact group and N an L+1 layer feed-forward network in which the i’th index set is G/Hi for some subgroup Hi of G. We say that N is a G–convolutional neural network (or G-CNN for short) if each of the linear maps φ1, . . .",5. Main result: the connection between convolution and equivariance,[0],[0]
", φL in N is a generalized convolution (see Definition 4) of the form
φℓ(fℓ−1) = fℓ−1 ∗ χℓ
with some filter χℓ ∈LVℓ−1×Vℓ(Hℓ−1\G/Hℓ).
",5. Main result: the connection between convolution and equivariance,[0],[0]
Theorem 1.,5. Main result: the connection between convolution and equivariance,[0],[0]
"Let G be a compact group and N be an L + 1 layer feed-forward neural network in which the ℓ’th index set is of the form Xℓ = G/Hℓ, where Hℓ is some subgroup of G. Then N is equivariant to the action ofG in the sense of Definition 3 if and only if it is a G-CNN.
",5. Main result: the connection between convolution and equivariance,[0],[0]
"Proving this theorem in the forward direction is relatively easy and only requires some elementary facts about cosets and group actions.
",5. Main result: the connection between convolution and equivariance,[0],[0]
Proof of Theorem 1 (forward direction).,5. Main result: the connection between convolution and equivariance,[0],[0]
"Assume that we translate fℓ−1 by some group element g ∈G and get f ′ℓ−1, i.e., f ′ℓ−1 = T ℓ−1 g (fℓ−1), where f ′ ℓ−1(x) = fℓ−1(g
−1x).",5. Main result: the connection between convolution and equivariance,[0],[0]
"Then
φℓ(f ′",5. Main result: the connection between convolution and equivariance,[0],[0]
"ℓ−1)(u) = (f ′ ℓ−1 ∗ χℓ)(u)
= ∑
v∈G
f ′ℓ−1([uv −1]X )χℓ(v)
= ∑
v∈G
fℓ−1(g −1([uv−1]X ))χℓ(v).
",5. Main result: the connection between convolution and equivariance,[0],[0]
By g−1([uv−1]X ),5. Main result: the connection between convolution and equivariance,[0],[0]
=,5. Main result: the connection between convolution and equivariance,[0],[0]
"[g −1uv−1]X this is further equal to
∑
v∈G
fℓ−1([g −1uv−1]X )χℓ(v)
= (fℓ−1 ∗ χℓ)(g−1u) = φℓ(fℓ−1)(g−1u).
",5. Main result: the connection between convolution and equivariance,[0],[0]
"Therefore, φℓ(fℓ−1) is equivariant with fℓ−1.",5. Main result: the connection between convolution and equivariance,[0],[0]
"Since σℓ is a pointwise operator, so is fℓ = σℓ(φℓ(fℓ−1)).",5. Main result: the connection between convolution and equivariance,[0],[0]
"By induction on ℓ, using the transitivity of equivariance, this implies that every layer of N is equivariant with layer 0.",5. Main result: the connection between convolution and equivariance,[0],[0]
"Note that this proof holds not only in the base case, when each fℓ is a function X → C, but also in the more general case when fℓ :",5. Main result: the connection between convolution and equivariance,[0],[0]
"Xℓ → Vℓ and the filters are χℓ : Xℓ → Vℓ−1 × Vℓ.
Proving the “only if” part of Theorem 1 is more technical, therefore we leave it to the Appendix.",5. Main result: the connection between convolution and equivariance,[0],[0]
We are not aware of any prior papers that have exposed the above algebraic theory of equivariance and convolution in its full generality.,6. Examples of algebraic convolution in neural networks,[0],[0]
"However, there are a few recent publications that implicitly exploit these ideas in specific contexts.",6. Examples of algebraic convolution in neural networks,[0],[0]
In image recognition applications it is a natural goal to achieve equivariance to both translation and rotation.,6.1. Rotation equivariant networks,[0],[0]
"The most common approach is to use CNNs, but with filters that are replicated at a certain number of rotational angles (typically multiples of 90 degrees), connected in such as a way as to achieve a generalization of equivariance called steerability.",6.1. Rotation equivariant networks,[0],[0]
"Steerability also has a group theoretic interpretation, which is most lucidly explained in (Cohen & Welling, 2017).
",6.1. Rotation equivariant networks,[0],[0]
"The recent papers (Marcos et al., 2017) and (Worrall et al., 2017) extend these architectures by considering continuous rotations at each point of the visual field.",6.1. Rotation equivariant networks,[0],[0]
"Thus, putting
aside the steerability aspect for now and only considering the behavior of the network at a single point, both these papers deal with the case where G = SO(2) (the two dimensional rotation group) and X is the circle S1.",6.1. Rotation equivariant networks,[0],[0]
"The group SO(2) is commutative, therefore its irreducible representations are one dimensional, and are, in fact, ρj(θ)",6.1. Rotation equivariant networks,[0],[0]
"= e 2πιjθ ,
where ι = √ −1.",6.1. Rotation equivariant networks,[0],[0]
"While not calling it a group Fourier transform, Worrall et al. (2017) explicitly expand the local activations in this basis and scale them with weights, which, by virtue of Proposition 2, amounts to convolution on the group, as prescribed by our main theorem.
",6.1. Rotation equivariant networks,[0],[0]
"The form of the nonlinearity in (Worrall et al., 2017) is different from that prescribed in Definition 3, which leads to a coupling between the indices of the Fourier components in any path from the input layer to the output layer.",6.1. Rotation equivariant networks,[0],[0]
"This is compensated by what they call their “equivariance condition”, asserting that only Fourier components for which M = ∑ ℓ jℓ is the same may mix.",6.1. Rotation equivariant networks,[0],[0]
"This restores equivariance in the last layer, but analyzing it group theoretically is beyond the scope of the present paper.",6.1. Rotation equivariant networks,[0],[0]
"Very close in spirit to our present exposition are the recent papers (Cohen et al., 2018; Kondor et al., 2018), which propose convolutional architectures for recognizing images painted on the sphere, satisfying equivariance with respect to rotations.",6.2. Spherical CNNs,[0],[0]
"Thus, in this case, G = SO(3), the group of three dimensional rotations, and Xℓ is the sphere, S2.",6.2. Spherical CNNs,[0],[0]
The case of rotations acting on the sphere is one of the textbook examples of continuous group actions.,6.2. Spherical CNNs,[0],[0]
"In particular, letting x0 be the North pole, we see that two-dimensional rotations in the x–z plane fix x0, therefore, S 2 is identified with the quotient space SO(3)/SO(2).",6.2. Spherical CNNs,[0],[0]
The irreducible representations of SO(3) are given by the so-called Wigner matrices.,6.2. Spherical CNNs,[0],[0]
"The ℓ’th irreducible representation is 2ℓ+1 dimensional and of the form
[ρℓ(θ, φ, ψ)]m,m′",6.2. Spherical CNNs,[0],[0]
"= e −ιm′φ dℓm′,m(θ)",6.2. Spherical CNNs,[0],[0]
"e −ιmψ,
where m,m′ ∈",6.2. Spherical CNNs,[0],[0]
"{−ℓ, . . .",6.2. Spherical CNNs,[0],[0]
", ℓ}, (θ, φ, ψ) are the Euler angles of the rotation and the dℓm′,m(θ) funcion is related to the spherical harmonics.",6.2. Spherical CNNs,[0],[0]
"It is immediately clear that on restriction to SO(2) (corresponding to θ, φ = 0) only the middle column in each of these matrices reduces to the trivial representation of SO(2), therefore, by Proposition 1, in the case f : SO(3)/SO(2) → C, only the middle column of each f̂(ρℓ) matrix will be nonzero.",6.2. Spherical CNNs,[0],[0]
"In fact, up to constant scaling factors, the entries in that middle column are just the customary spherical harmonic expansion coefficients.
",6.2. Spherical CNNs,[0],[0]
"Cohen et al. (2018) explicitly make this connection between spherical harmonics and SO(3) Fourier transforms, and store the activations in terms of this representation.",6.2. Spherical CNNs,[0],[0]
"Moreover, just like in the present paper, they define convo-
lution in terms of the noncommutative convolution theorem (Proposition 2), use pointwise nonlinearities, and prove that the resulting neural network is SO(3)–equivariant.",6.2. Spherical CNNs,[0],[0]
"However, they do not prove the converse, i.e., that equivariance implies that the network must be convolutional.",6.2. Spherical CNNs,[0],[0]
"To apply the nonlinearity, the algorithm presented in (Cohen et al., 2018) requires repeated forward and backward SO(3) fast Fourier transforms.",6.2. Spherical CNNs,[0],[0]
"While this leads to a non-conventional architecture, the discussion echoes our observation that when dealing with continuous symmetries such as rotations, one must generalize to more abstract “continuous” neural networks, as afforded by Definition 3.",6.2. Spherical CNNs,[0],[0]
"There has been considerable interest in extending the convolutional network formalism to learning from graphs (Niepert et al., 2016; Defferrard et al., 2016; Duvenaud et al., 2015), and the current consensus for approaching this problem is to use neural networks based on the message passing idea (Gilmer et al., 2017).",6.3. Message passing neural networks,[0],[0]
Let G be a graph with n vertices.,6.3. Message passing neural networks,[0],[0]
"Message passing neural networks (MPNNs) are usually presented in terms of an iterative process, where in each round ℓ, each vertex v collects the labels of its neighbors w1, . . .",6.3. Message passing neural networks,[0],[0]
", wk, and updates its own label f̃v according to a simple formula such as
f̃ ℓv = Φ ( f̃ ℓ−1w1 + . .",6.3. Message passing neural networks,[0],[0]
".+ f̃ ℓ−1 wk ) .
",6.3. Message passing neural networks,[0],[0]
"An equivalent way of seeing this process, however, is in terms of the “effective receptive fields” Sℓv of each vertex at round ℓ, i.e., the set of all vertices from which information can propagate to v by round ℓ.
MPNNs can also be viewed as group convolutional networks.",6.3. Message passing neural networks,[0],[0]
"A receptive field of size k is just a subset {s1, . . .",6.3. Message passing neural networks,[0],[0]
", sk} ⊆ {1, 2, . . .",6.3. Message passing neural networks,[0],[0]
",",6.3. Message passing neural networks,[0],[0]
"n}, and the symmetric group Sn (the group of permutations of {1, 2, . .",6.3. Message passing neural networks,[0],[0]
.,6.3. Message passing neural networks,[0],[0]
",",6.3. Message passing neural networks,[0],[0]
"n}) acts on the set of such subsets transitively by {s1, . . .",6.3. Message passing neural networks,[0],[0]
", sk} σ7→ {σ(s1), . . .",6.3. Message passing neural networks,[0],[0]
", σ(sk)} σ ∈ Sn.",6.3. Message passing neural networks,[0],[0]
"Since permuting the n− k vertices not in S amongst themselves, as well as permuting the k vertices that are in S both leave S invariant, the stablizier of this action is Sn−k × Sk.",6.3. Message passing neural networks,[0],[0]
"Thus, the set of all k-subsets of vertices is identified with the quotient space X = Sn/(Sk × Sn−k), and the labeling function for k-element receptive fields is identified with fk : X → C. Effectively, this turns the MPNN into a generalized feed-forward network in the sense of Definition 3.",6.3. Message passing neural networks,[0],[0]
Note that fk is a redundant representation of the labeling function because Sn/(Sk×Sn−k) also includes subsets that do not correspond to contiguous neighborhoods.,6.3. Message passing neural networks,[0],[0]
However this is not a problem because for such S we simply set fk(S) = 0.,6.3. Message passing neural networks,[0],[0]
"The key feature of the message passing formalism is that, by construction, it ensures that the f̃ ℓv labels only depend
on the graph topology and are invariant to renumbering the vertices of G.",6.3. Message passing neural networks,[0],[0]
In terms of our “k–subset network” this means that each fk must be Sn–equivariant.,6.3. Message passing neural networks,[0],[0]
"Thus, in contrast to the previous two examples, now each index set Xℓ = Sn/(Sn−ℓ × Sℓ) is different.",6.3. Message passing neural networks,[0],[0]
The form of the corresponding convolutions LVℓ−1(Xℓ−1) → LVℓ(Xℓ) are best described in the Fourier domain.,6.3. Message passing neural networks,[0],[0]
"Unfortunately, the representation theory of symmetric groups is beyond the scope of the present paper (Sagan, 2001).",6.3. Message passing neural networks,[0],[0]
"We content ourselves by stating that the irreps of Sn are indexed by so-called integer partitions, (λ1, . . .",6.3. Message passing neural networks,[0],[0]
", λm), where λ1 ≥ . . .",6.3. Message passing neural networks,[0],[0]
≥ λm and∑,6.3. Message passing neural networks,[0],[0]
"i λi = n. Moreover, the structure of the Fourier transform of a function f :",6.3. Message passing neural networks,[0],[0]
"Sn/(Sn−ℓ × Sℓ) dictated by Proposition 1 in this case is that each of the Fourier matrices are zero except for a single column in each of the f̂((n−p, p)) components, where 0 ≤ p ≤",6.3. Message passing neural networks,[0],[0]
ℓ. The main theorem of our paper dictates that the linear map φℓ in each layer must be a convolution.,6.3. Message passing neural networks,[0],[0]
"In the case of Fourier matrices with such extreme sparsity structure, this means that each of the ℓ+1 Fourier matrices can be multiplied by a scalar, χℓp.",6.3. Message passing neural networks,[0],[0]
These are the learnable parameters of the network.,6.3. Message passing neural networks,[0],[0]
"A real MPNN of course has multiple channels and various corresponding parameters, which could also be introduced in the k– subset network.",6.3. Message passing neural networks,[0],[0]
"The above observation about the form of χℓ is nonetheless interesting, because it at once implies that permutation equivariance is a severe constraint the significantly limits the form of the convolutional filters, yet the framework is still richer than traditional MPNNs where the labels of the neighbors are simply summed.",6.3. Message passing neural networks,[0],[0]
Convolution has emerged as one of the key organizing principles of deep neural network architectures.,7. Conclusions,[0],[0]
"Nonetheless, depending on their background, the word “convolution” means different things to different researchers.",7. Conclusions,[0],[0]
"The goal of this paper was to show that in the common setting when there is a group acting on the data that the architecture must be equivariant to, convolution has a specific mathematical meaning that has far reaching consequences: we proved that a feed forward network is equivariant to the group action if and only if it respects this notion of convolution.
",7. Conclusions,[0],[0]
"Our theory gives a clear prescription to practitioners on how to design neural networks for data with non-trivial symmetries, such as data on the sphere, etc..",7. Conclusions,[0],[0]
"In particular, we argue for Fourier space representations, similar to those that have appeared in (Worrall et al., 2017; Cohen et al., 2018; Kondor et al., 2018)), and, even more recently, since the submission of the original version of the present paper in (Thomas et al., 2018; Kondor, 2018; Weiler et al., 2018).",7. Conclusions,[0],[0]
This work was supported in part by DARPA Young Faculty Award D16AP00112.,Acknowledgements,[0],[0]
"For a more detailed background on representation theory, we point the reader to Serre, 1977.
Groups.",A. Background from group and representation theory,[0],[0]
"A group is a set G endowed with an operation G×G→ G (usually denoted multiplicatively) obeying the following axioms:
G1.",A. Background from group and representation theory,[0],[0]
"for any g1, g2 ∈G, g1g2",A. Background from group and representation theory,[0],[0]
"∈G (closure);
G2.",A. Background from group and representation theory,[0],[0]
"for any g1, g2, g3 ∈G, g1(g2g3)",A. Background from group and representation theory,[0],[0]
= (g1g2)g3 (associativity); G3.,A. Background from group and representation theory,[0],[0]
"there is a unique e∈G, called the identity ofG, such that eg = ge = g for any u∈G; G4. for any g ∈G, there is a corresponding element g−1∈ G called the inverse of g, such that gg−1 = g−1g = e.
We do not require that the group operation be commutative, i.e., in general, g1g2",A. Background from group and representation theory,[0],[0]
6= g2g1.,A. Background from group and representation theory,[0],[0]
"Groups can be finite or infinite, countable or uncountable, compact or non-compact.",A. Background from group and representation theory,[0],[0]
"While most of the results in this paper would generalize to any compact group, to keep the exposition as simple as possible, throughout we assume that G is finite or countably infinite.",A. Background from group and representation theory,[0],[0]
"As usual, |G| will denote the size (cardinality) of G, sometimes also called the order of the group.",A. Background from group and representation theory,[0],[0]
"A subset H of G is called a subgroup of G, denoted H ≤ G, if H itself forms a group under the same operation as G, i.e., if for any g1, g2 ∈H , g1g2 ∈H .
",A. Background from group and representation theory,[0],[0]
"Homogeneous Spaces.
",A. Background from group and representation theory,[0],[0]
Definition 6.,A. Background from group and representation theory,[0],[0]
Let G be a group acting on a set X .,A. Background from group and representation theory,[0],[0]
"We say that X is a homogeneous space of G if for any x, y ∈ X , there is a g ∈G such that y= g(x).
",A. Background from group and representation theory,[0],[0]
"The significance of homogeneous spaces for our purposes is that once we fix the “origin” x0, the above correspondence between points in X and the group elements that map x0 to them allows to lift various operations on the homogeneous space to the group.",A. Background from group and representation theory,[0],[0]
"Because expressions like g(x0) appear so often in the following, we introduce the shorthand",A. Background from group and representation theory,[0],[0]
[g]X :=g(x0).,A. Background from group and representation theory,[0],[0]
"Note that this hides the dependency on the (arbitrary) choice of x0.
",A. Background from group and representation theory,[0],[0]
"For some examples, we see that Z2 is a homogeneous space of itself with respect to the trivial action (i, j) 7→ (g1+i, g2+ j), and the sphere is a homogeneous space of the rotation group with respect to the action:
x 7→",A. Background from group and representation theory,[0],[0]
R(x),A. Background from group and representation theory,[0],[0]
R(x),A. Background from group and representation theory,[0],[0]
=,A. Background from group and representation theory,[0],[0]
"Rx x∈S2, (15)
",A. Background from group and representation theory,[0],[0]
"On the other hand, the entries of the adjacency matrix are not a homogeneous space of Sn with respect to
(i, j) 7→ (σ(i), σ(j))",A. Background from group and representation theory,[0],[0]
σ ∈,A. Background from group and representation theory,[0],[0]
Sn.,A. Background from group and representation theory,[0],[0]
"(16)
, because if we take some (i, j) with i 6= j, then 16 can map it to any other (i′, j′) with i′ 6= j′, but not to any of the diagonal elements, where i′ = j′. If we split the matrix into its “diagonal”, and “off-diagonal” parts, individually these two parts are homogeneous spaces.
",A. Background from group and representation theory,[0],[0]
Representations.,A. Background from group and representation theory,[0],[0]
"A (finite dimensional) representation of a group G over a field F is a matrix-valued function ρ : G → Fdρ×dρ such that ρ(g1)ρ(g2) = ρ(g1g2) for any
g1,",A. Background from group and representation theory,[0],[0]
g2 ∈ G.,A. Background from group and representation theory,[0],[0]
"In this paper, unless stated otherwise, we always assume that F = C. A representation ρ is said to be unitary if ρ(g−1) = ρ(g)† for any g ∈ G. One representation shared by every group is the trivial representation ρtr that simply evaluates to the one dimensional matrix ρtr(g) = (1) on every group element.
",A. Background from group and representation theory,[0],[0]
"Equivalence, reducibility and irreps.",A. Background from group and representation theory,[0],[0]
"Two representations ρ and ρ′ of the same dimensionality d are said to be equivalent if for some invertible matrix Q ∈ Cd×d, ρ(g) = Q−1ρ′(g)Q for any g ∈ G.",A. Background from group and representation theory,[0],[0]
"A representation ρ is said to be reducible if it decomposes into a direct sum of smaller representations in the form
ρ(g)
= Q−1 (ρ1(g)⊕ρ2(g))",A. Background from group and representation theory,[0],[0]
Q = Q−1 ( ρ1(g) 0 0 ρ2(g) ),A. Background from group and representation theory,[0],[0]
Q ∀,A. Background from group and representation theory,[0],[0]
"g ∈G
for some invertible matrix Q ∈ Cdρ×dρ .",A. Background from group and representation theory,[0],[0]
We use RG to denote a complete set of inequivalent irreducible representations ofG.,A. Background from group and representation theory,[0],[0]
"However, since this is quite a mouthful, in this paper we also use the alternative term system of irreps to refer to RG.",A. Background from group and representation theory,[0],[0]
"Note that the choice of irreps in RG is far from unique, since each ρ ∈ RG can be replaced by an equivalent irrep Q⊤ρ(g)Q, where Q is any orthogonal matrix of the appropriate size.
",A. Background from group and representation theory,[0],[0]
Complete reducibility and irreps.,A. Background from group and representation theory,[0],[0]
Representation theory takes on its simplest form when G is compact (and F = C).,A. Background from group and representation theory,[0],[0]
"One of the reasons for this is that it is possible to prove (“theorem of complete reducibility”) that any representation ρ of a compact group can be reduced into a direct sum of irreducible ones, i.e.,
ρ(g) = Q−1",A. Background from group and representation theory,[0],[0]
( ρ(1)(g)⊕ρ(2)(g)⊕ . .,A. Background from group and representation theory,[0],[0]
.⊕,A. Background from group and representation theory,[0],[0]
ρ(k)(g) ),A. Background from group and representation theory,[0],[0]
"Q, g ∈G
(17)
for some sequence ρ(1), ρ(2), . . .",A. Background from group and representation theory,[0],[0]
", ρ(k)",A. Background from group and representation theory,[0],[0]
of irreducible representations of G and some Q ∈ Cd×d.,A. Background from group and representation theory,[0],[0]
"In this sense, for compact groups, RG plays a role very similar to the primes in arithmetic.",A. Background from group and representation theory,[0],[0]
"Fixing RG, the number of times that a particular ρ′ ∈ RG appears in (17) is a well-defined quantity called the multiplicity of ρ′ in ρ, denoted mρ(ρ
′).",A. Background from group and representation theory,[0],[0]
"Compactness also has a number of other advantages:
1.",A. Background from group and representation theory,[0],[0]
"When G is compact, RG is a countable set, therefore we can refer to the individual irreps as ρ1, ρ2, . .",A. Background from group and representation theory,[0],[0]
..,A. Background from group and representation theory,[0],[0]
"(WhenG is finite, RG is not only countable but finite.)",A. Background from group and representation theory,[0],[0]
2.,A. Background from group and representation theory,[0],[0]
"The system of irreps of a compact group is essentially
unique in the sense that if R′G is any other system of irreps, then there is a bijection φ : RG → R′G mapping each irrep ρ∈RG to an equivalent irrep φ(ρ)∈R′G. 3.",A. Background from group and representation theory,[0],[0]
"When G is compact, RG can be chosen in such a way that each ρ∈R is unitary.
",A. Background from group and representation theory,[0],[0]
Restricted representations.,A. Background from group and representation theory,[0],[0]
"Given any representation ρ of G and subgroup H ≤ G, the restriction of ρ to H is defined as the function ρ|H : H → Cdρ×dρ , where ρ|H(h) = ρ(h) for all h ∈ H .",A. Background from group and representation theory,[0],[0]
"It is trivial to check that ρ|H is a representation of H , but, in general, it is not irreducible (even when ρ itself is irreducible).
",A. Background from group and representation theory,[0],[0]
Fourier Transforms.,A. Background from group and representation theory,[0],[0]
"In the Euclidean domain convolution and cross-correlation have close relationships with the Fourier transform
f̂(k) = ∫ e−2πιkx f(x) dx, (18)
where ι is the imaginary unit, √ −1.",A. Background from group and representation theory,[0],[0]
"In particular, the Fourier transform of f ∗ g is just the pointwise product of the Fourier transforms of f and g,
f̂ ∗ g(k) = f̂(k) ĝ(k), (19)
while cross-correlation is
f̂ ⋆ g(k) = f̂(k)∗ ĝ(k).",A. Background from group and representation theory,[0],[0]
"(20)
",A. Background from group and representation theory,[0],[0]
The concept of group representations (see Section A) allows generalizing the Fourier transform to any compact group.,A. Background from group and representation theory,[0],[0]
"The Fourier transform of f : G → C is defined as:
f̂(ρi) =
∫
G
ρi(u) f(u) dµ(u), i = 1, 2, . . .",A. Background from group and representation theory,[0],[0]
", (21)
which, in the countable (or finite) case simplifies to
f̂(ρi) = ∑
u∈G
f(u)ρ(u), i = 1, 2, . . . .",A. Background from group and representation theory,[0],[0]
"(22)
",A. Background from group and representation theory,[0],[0]
"Despite R not being a compact group, (18) can be seen as a special case of (21), since e−2πιkx trivially obeys e−2πιk(x1+x2) = e−2πιkx1e−2πιkx2 , and the functions ρk(x) =",A. Background from group and representation theory,[0],[0]
"e −2πιkx are, in fact, the irreducible representations of R. The fundamental novelty in (21) and (22) compared to (18), however, is that since, in general (in particular, when G is not commutative), irreducible representations are matrix valued functions, each “Fourier compo-
nent” f̂(ρ) is now a matrix.",A. Background from group and representation theory,[0],[0]
"In other respects, Fourier transforms on groups behave very similarly to classical Fourier transforms.",A. Background from group and representation theory,[0],[0]
"For example, we have an inverse Fourier transform
f(u) = 1 |G| ∑
ρ∈R
dρ tr [ f(ρ)ρ(u)−1 ] ,
and also an analog of the convolution theorem, which is stated in the main body of the paper.",A. Background from group and representation theory,[0],[0]
"Since neural nets have multiple channels, we need to further extend equations 6-12 to vector/matrix valued functions.",B. Convolution of vector valued functions,[0],[0]
"Once again, there are multiple cases to consider.
",B. Convolution of vector valued functions,[0],[0]
Definition 7.,B. Convolution of vector valued functions,[0],[0]
"Let G be a finite or countable group, and X and Y be (left or right) quotient spaces of G. 1.",B. Convolution of vector valued functions,[0],[0]
"If f : X → Cm, and g : Y → Cm, we define f∗g : G→
C with
(f ∗ g)(u) = ∑
v∈G
f↑G(uv−1) · g↑G(v), (23)
where · denotes the dot product.",B. Convolution of vector valued functions,[0],[0]
2.,B. Convolution of vector valued functions,[0],[0]
"If f : X → Cn×m, and g : Y → Cm, we define f ∗",B. Convolution of vector valued functions,[0],[0]
g,B. Convolution of vector valued functions,[0],[0]
:,B. Convolution of vector valued functions,[0],[0]
"G→ Cn with
(f ∗ g)(u) = ∑
v∈G
f↑G(uv−1) × g↑G(v), (24)
where × denotes the matrix/vector product.",B. Convolution of vector valued functions,[0],[0]
3.,B. Convolution of vector valued functions,[0],[0]
"If f : X → Cm, and g : Y → Cn×m, we define f ∗ g :",B. Convolution of vector valued functions,[0],[0]
"G→ Cm with
(f ∗ g)(u) = ∑
v∈G
f↑G(uv−1) ×̃ g↑G(v), (25)
where v×̃A denotes the “reverse matrix/vector product” Av.
Since in cases 2 and 3 the nature of the product is clear from the definition of f and g, we will omit the × and ×̃ symbols.",B. Convolution of vector valued functions,[0],[0]
"The specializations of these formulae to the cases
of Equations 6-12 are as to be expected.",B. Convolution of vector valued functions,[0],[0]
Proposition 1 has three parts.,C. Proof of Proposition 1,[0],[0]
"To proceed with the proof, we introduce two simple lemmas.
",C. Proof of Proposition 1,[0],[0]
"Recall that if H is a subgroup of G, a function f : G → C is called right H–invariant if f(uh) = f(u) for all h∈H and all u∈G, and it is called left H–invariant if f(hu) = f(u) for all h∈H and all u∈G. Lemma 1.",C. Proof of Proposition 1,[0],[0]
"Let H and K be two subgroups of a group G. Then
1.",C. Proof of Proposition 1,[0],[0]
"If f : G/H → C, then f↑G : G → C is right H– invariant.",C. Proof of Proposition 1,[0],[0]
2.,C. Proof of Proposition 1,[0],[0]
"If f : H\G → C, then f↑G : G → C is left H– invariant. 3.",C. Proof of Proposition 1,[0],[0]
"If f : K\G/H → C, then f↑G : G → C is right H invariant and left K–invariant.
",C. Proof of Proposition 1,[0],[0]
Lemma 2.,C. Proof of Proposition 1,[0],[0]
Let ρ be an irreducible representation of a countable group G. Then ∑ u∈G ρ(u) = 0,C. Proof of Proposition 1,[0],[0]
"unless ρ is the trivial representation, ρtr(u) = (1).
",C. Proof of Proposition 1,[0],[0]
Proof.,C. Proof of Proposition 1,[0],[0]
"Let us define the functions rρi,j(u) =",C. Proof of Proposition 1,[0],[0]
"[ρ(u)]i,j .",C. Proof of Proposition 1,[0],[0]
"Recall that for f, g : G → C, the inner product 〈f, g〉 is
defined 〈f, g〉 = ∑u∈G f(u)∗g(u).",C. Proof of Proposition 1,[0],[0]
"The Fourier transform of a function f can then be written element-wise as [f̂(ρ)]i,j = 〈rρi,j ∗ , f〉.",C. Proof of Proposition 1,[0],[0]
"However, since the Fourier transform is a unitary transformation, for any ρ, ρ′ ∈RG, unless ρ = ρ′, i = i′ and j = j′, we must have 〈rρi,j , rρ ′
i′,j′〉 = 0.",C. Proof of Proposition 1,[0],[0]
"In particular, [∑ u∈G ρ(u) ]",C. Proof of Proposition 1,[0],[0]
"i,j
= 〈rρtr1,1, rρi,j〉 = 0, unless ρ = ρtr (and i= j =1).
",C. Proof of Proposition 1,[0],[0]
"Now recall that given an irrep ρ of G, the restriction of ρ to H is ρ|H : H → Cdρ×dρ , where ρ|H(h) = ρ(h) for all h ∈ H .",C. Proof of Proposition 1,[0],[0]
"It is trivial to check that ρ|H is a representation of H , but, in general, it is not irreducible.",C. Proof of Proposition 1,[0],[0]
"Thus, by the Theorem of Complete Decomposability (see section A), it must decompose in the form ρ|H(h) = Q(µ1(h)⊕µ2(h)⊕ . .",C. Proof of Proposition 1,[0],[0]
.⊕,C. Proof of Proposition 1,[0],[0]
µk(h))Q†,C. Proof of Proposition 1,[0],[0]
"for some sequence µ1, . . .",C. Proof of Proposition 1,[0],[0]
", µk of irreps of H and some unitary martrix Q. In the special case when the irreps of G and H are adapted to H ≤ G, however, Q is just the unity.
",C. Proof of Proposition 1,[0],[0]
This is essentially the case that we consider in Proposition 1.,C. Proof of Proposition 1,[0],[0]
"Now, armed with the above lemmas, we are in a position to prove Proposition 1.
C.0.1.",C. Proof of Proposition 1,[0],[0]
"PROOF OF PART 1
Proof.",C. Proof of Proposition 1,[0],[0]
The fact that any u ∈ G can be written uniquely as u = gh where g is the representative of one of the gH cosets and h∈H immediately tells us that f̂(ρ) factors as f̂(ρ) =,C. Proof of Proposition 1,[0],[0]
"∑
u∈G
f↑G(u)ρ(u) =",C. Proof of Proposition 1,[0],[0]
"∑
x∈G/H
∑
h∈H
f↑G(xh)ρ(xh)
",C. Proof of Proposition 1,[0],[0]
"= ∑
x∈G/H
∑
h∈H
f(x)ρ(xh) =",C. Proof of Proposition 1,[0],[0]
"∑
x∈G/H
∑
h∈H
f(x)ρ(x)ρ(h)
= ∑
x∈G/H
f(x)ρ(x)",C. Proof of Proposition 1,[0],[0]
"[∑
h∈H
ρ(h) ] .
",C. Proof of Proposition 1,[0],[0]
"However, ρ(h) = µ1(h) ⊕ µ2(h) ⊕ . . .",C. Proof of Proposition 1,[0],[0]
"⊕ µk(h) for some sequence of irreps µ1, . . .",C. Proof of Proposition 1,[0],[0]
", µk of H , so
∑
h∈H
ρ(h) =",C. Proof of Proposition 1,[0],[0]
"[∑
h∈H
µ1(h) ] ⊕ [∑
h∈H
µ2(h) ]",C. Proof of Proposition 1,[0],[0]
⊕. . .⊕,C. Proof of Proposition 1,[0],[0]
"[∑
h∈H
µk(h) ] ,
and by Lemma 2 each of the terms in this sum where µi is not the trivial representation (on H) is a zero matrix,
zeroing out all the corresponding columns in f̂(ρ).
",C. Proof of Proposition 1,[0],[0]
C.0.2.,C. Proof of Proposition 1,[0],[0]
"PROOF OF PART 2
Proof.",C. Proof of Proposition 1,[0],[0]
"Analogous to the proof of part 1, using u = hg and
a factorization similar to that of f̂(ρ) in C.0.1 except that∑ h∈H ρ(h) will now multiply ∑ x∈H\G f(x)ρ(x) from the left.
C.0.3.",C. Proof of Proposition 1,[0],[0]
"PROOF OF PART 3
Proof.",C. Proof of Proposition 1,[0],[0]
Immediate from combining case 3 of Lemma 1 with Parts 1 and 2 of Proposition 1.,C. Proof of Proposition 1,[0],[0]
Proof.,D. Proof of Proposition 2,[0],[0]
Let us assume that G is countable.,D. Proof of Proposition 2,[0],[0]
"Then
f̂ ∗g(ρi) = ∑
u∈G
[∑
v∈G
f(uv−1) g(v) ] ρi(u)
= ∑
u∈G
∑
v∈G
f(uv−1) g(v)ρi(uv −1)ρi(v)
= ∑
v∈G
∑
u∈G
f(uv−1) g(v)ρi(uv −1)ρi(v)
= ∑
v∈G
[∑
u∈G
f(uv−1) ρi(uv −1)",D. Proof of Proposition 2,[0],[0]
"] g(v)ρi(v)
= ∑
v∈G
[∑
w∈G
f(w) ρi(w) ]",D. Proof of Proposition 2,[0],[0]
"g(v)ρi(v)
=",D. Proof of Proposition 2,[0],[0]
"[∑
w∈G
f(w) ρi(w) ][∑
v∈G
g(v)ρi(v) ]
= f̂(ρi) ĝ(ρi).
",D. Proof of Proposition 2,[0],[0]
The continuous case is proved similarly but with integrals with respect Haar measure instead of sums.,D. Proof of Proposition 2,[0],[0]
E.1.,E. Proof of Theorem 1,[0],[0]
"Reverse Direction
Proving the “only if” part of Theorem 1 requires concepts from representation theory and the notion of generalized Fourier transforms (Section A)).",E. Proof of Theorem 1,[0],[0]
"We also need two versions of Schur’s Lemma.
Lemma 3.",E. Proof of Theorem 1,[0],[0]
(Schur’s lemma I),E. Proof of Theorem 1,[0],[0]
Let {ρ(g) : U →U}g∈G and {ρ′(g) : V → V }g∈G be two irreducible representations of a compact group G. Let φ : U → V be a linear (not necessarily invertible) mapping that is equivariant with these representations in the sense that φ(ρ(g)(u)),E. Proof of Theorem 1,[0],[0]
= ρ′(g)(φ(u)) for any u∈U .,E. Proof of Theorem 1,[0],[0]
"Then, unless φ is the zero map, ρ and ρ′ are equivalent representations.
",E. Proof of Theorem 1,[0],[0]
Lemma 4.,E. Proof of Theorem 1,[0],[0]
(Schur’s lemma II),E. Proof of Theorem 1,[0],[0]
"Let {ρ(g) : U → U}g∈G be an irreducible representation of a compact group G on a space U , and φ : U → U a linear map that commutes with each ρ(g) (i.e., ρ(g) ◦ φ = φ ◦ ρ(g) for any g ∈ G).",E. Proof of Theorem 1,[0],[0]
"Then φ is a multiple of the identity.
",E. Proof of Theorem 1,[0],[0]
"We build up the proof through a sequence of lemmas.
",E. Proof of Theorem 1,[0],[0]
Lemma 5.,E. Proof of Theorem 1,[0],[0]
Let U and V be two vector spaces on which a compact group G acts by the linear actions {,E. Proof of Theorem 1,[0],[0]
"Tg : U →
U}g∈G and {T ′g : V→V }g∈G, respectively.",E. Proof of Theorem 1,[0],[0]
"Let φ : U→V be a linear map that is equivariant with the {Tg} and {T ′g} actions, and W be an irreducible subspace of U (with respect to {Tg}).",E. Proof of Theorem 1,[0],[0]
"Then Z =φ(W ) is an irreducible subspace of V , and the restriction of {Tg} to W , as a representation, is equivalent with the restriction of {T ′g} to Z .
",E. Proof of Theorem 1,[0],[0]
Proof.,E. Proof of Theorem 1,[0],[0]
"Assume for contradiction that Z is reducible, i.e., that it has a proper subspace Z ⊂ Z that is fixed by {T ′g} (in other words, T ′g(v) ∈Z for all v ∈Z",E. Proof of Theorem 1,[0],[0]
and g ∈G).,E. Proof of Theorem 1,[0],[0]
"Let v be any nonzero vector in Z , u ∈ U be such that φ(u) = v, and W = span {Tg(u) | g ∈G }.",E. Proof of Theorem 1,[0],[0]
"Since W is irreducible, W cannot be a proper subspace of W , so W =W .",E. Proof of Theorem 1,[0],[0]
"Thus,
Z = φ(span {Tg(u) | g ∈G }) = span{T ′g(φ(u))|g ∈G} = span{T ′g(v)|g ∈G} ⊆ Z,
(26)
contradicting our assumption.",E. Proof of Theorem 1,[0],[0]
"Thus, the restriction {Tg|W } of {Tg} to W and the restriction {T ′g|Z} of {T ′g} to Z are both irreducible representations, and φ : W → Z is a linear map that is equivariant with them.",E. Proof of Theorem 1,[0],[0]
"By Schur’s lemma it follows that {Tg|W } and {T ′g|Z} are equivalent representations.
",E. Proof of Theorem 1,[0],[0]
Lemma 6.,E. Proof of Theorem 1,[0],[0]
Let U and V be two vector spaces on which a compact group G acts by the linear actions {,E. Proof of Theorem 1,[0],[0]
"Tg : U → U}g∈G and {T ′g : V → V }g∈G, and let U = U1 ⊕ U2 ⊕ . . .",E. Proof of Theorem 1,[0],[0]
and V = V1 ⊕ V2 ⊕ . .,E. Proof of Theorem 1,[0],[0]
.,E. Proof of Theorem 1,[0],[0]
be the corresponding isotypic decompositions.,E. Proof of Theorem 1,[0],[0]
Let φ : U → V be a linear map that is equivariant with the {Tg} and {T ′g} actions.,E. Proof of Theorem 1,[0],[0]
Then φ(Ui),E. Proof of Theorem 1,[0],[0]
"⊆ Vi for any i.
Proof.",E. Proof of Theorem 1,[0],[0]
Let Ui = U 1,E. Proof of Theorem 1,[0],[0]
i ⊕ U2i ⊕ . .,E. Proof of Theorem 1,[0],[0]
.,E. Proof of Theorem 1,[0],[0]
"be the decomposition of Ui into irreducible G–modules, and V j i = φ(U j i ).",E. Proof of Theorem 1,[0],[0]
"By Lemma 5, each V ji is an irreducible G–module that is equivalent with U ji , hence V j i ⊆ Vi.",E. Proof of Theorem 1,[0],[0]
"Consequently, φ(Ui) = φ(U 1 i ⊕ U2i ⊕ . . .)",E. Proof of Theorem 1,[0],[0]
"⊆ Vi.
Lemma 7.",E. Proof of Theorem 1,[0],[0]
"Let X = G/H and X ′ = G/K be two homogeneous spaces of a compact group G, let {Tg : L(X ) → L(X )}g∈G and {T′g : L(X ′)",E. Proof of Theorem 1,[0],[0]
"→ L(X ′)}g∈G be the corresponding translation actions, and let φ : L(X )",E. Proof of Theorem 1,[0],[0]
→ L(X ′) be a linear map that is equivariant with these actions.,E. Proof of Theorem 1,[0],[0]
"Given f ∈ L(X ) let f̂ denote its Fourier transform with respect to a specific choice of origin x0 ∈ X and system or irreps RG = {ρ1, ρ2, . . .}.",E. Proof of Theorem 1,[0],[0]
"Similarly, f̂ ′ is the Fourier transform of f ′ ∈L(X ′), with respect to some x′0",E. Proof of Theorem 1,[0],[0]
∈X ′,E. Proof of Theorem 1,[0],[0]
"and the same system of irreps.
",E. Proof of Theorem 1,[0],[0]
"Now if f ′ = φ(f), then each Fourier component of f ′ is a linear function of the corresponding Fourier component of f , i.e., there is a sequence of linear maps {Φi} such that f̂ ′(ρi) = Φi(f̂(ρi)).
",E. Proof of Theorem 1,[0],[0]
Proof.,E. Proof of Theorem 1,[0],[0]
Let U1 ⊕ U2 ⊕ . . .,E. Proof of Theorem 1,[0],[0]
and V1 ⊕ V2 ⊕ . . .,E. Proof of Theorem 1,[0],[0]
be the isotypic decompositions of L(X ) and L(X ′) with respect to the {Tg} and {T′g} actions.,E. Proof of Theorem 1,[0],[0]
"By our discussion in Section ??, each Fourier component f̂(ρi) captures the part of f falling in the corresponding isotypic subspace Ui.",E. Proof of Theorem 1,[0],[0]
"Similarly, f̂ ′(ρj) captures the part of f
′ falling in Vj .",E. Proof of Theorem 1,[0],[0]
"Lemma 6 tells us that because φ is equivariant with the translation actions, it maps each Ui to the corresponding isotypic Vi.",E. Proof of Theorem 1,[0],[0]
"Therefore, f̂ ′(ρi)",E. Proof of Theorem 1,[0],[0]
= Φi(f̂(ρi)),E. Proof of Theorem 1,[0],[0]
for some function Φi.,E. Proof of Theorem 1,[0],[0]
"By the linearity of φ, each Φi must be linear.
",E. Proof of Theorem 1,[0],[0]
"Lemma 7 is a big step towards describing what form equivariant mappings take in Fourier space, but it doesn’t yet fully pin down the individual Φi maps.",E. Proof of Theorem 1,[0],[0]
"We now focus on a single pair of isotypics (Ui, Vi) and the corresponding map Φi taking f̂(ρi) 7→ f̂ ′(ρi).",E. Proof of Theorem 1,[0],[0]
"We will say that Φi is an allowable map if there is some equivariant φ such
that φ̂(f)(ρi) = Φi(f̂(ρi)).",E. Proof of Theorem 1,[0],[0]
"Clearly, if Φ1,Φ2, . .",E. Proof of Theorem 1,[0],[0]
.,E. Proof of Theorem 1,[0],[0]
"are individually allowable, then they are also jointly allowable.
",E. Proof of Theorem 1,[0],[0]
Lemma 8.,E. Proof of Theorem 1,[0],[0]
All linear maps of the form,E. Proof of Theorem 1,[0],[0]
"Φi : M 7→ MB where B ∈Cδ×δ are allowable.
",E. Proof of Theorem 1,[0],[0]
Proof.,E. Proof of Theorem 1,[0],[0]
"Recall that the {Tg} action takes f 7→ fg , where fg(x) = f(g−1x).",E. Proof of Theorem 1,[0],[0]
"In Fourier space,
f̂g(ρi) =",E. Proof of Theorem 1,[0],[0]
"∑
u∈G
ρi(u)f g↑G(u)
= ∑
u∈G
ρi(u)f↑G(g−1u)
= ∑
w∈G
ρi(gw)f↑G(w)
",E. Proof of Theorem 1,[0],[0]
"= ρi(g) ∑
w∈G
ρi(w)f↑G(w)
= ρi(g) f̂(ρi).",E. Proof of Theorem 1,[0],[0]
"(27)
(This is actually a general result called the (left) translation theorem.)",E. Proof of Theorem 1,[0],[0]
"Thus,
Φi ( T̂g(f)(ρi) ) = Φi ( ρi(g)f̂(ρi) )",E. Proof of Theorem 1,[0],[0]
"= ρi(g) f̂(ρi)B.
",E. Proof of Theorem 1,[0],[0]
"Similarly, the {T′g} action maps f̂ ′(ρi) 7→ g(ρi)f̂ ′(ρi), so
T′g ( Φi(f̂(ρi)) )",E. Proof of Theorem 1,[0],[0]
"= T′g ( f̂(ρi)B ) = ρi(g) f̂(ρi)B.
",E. Proof of Theorem 1,[0],[0]
"Therefore, Φi is equivariant with the {T} and {T′} actions.
",E. Proof of Theorem 1,[0],[0]
Lemma 9.,E. Proof of Theorem 1,[0],[0]
Let Φi : M 7→ BM for some B ∈ Cδ×δ.,E. Proof of Theorem 1,[0],[0]
Then Φi is not allowable unless B is a multiple of the identity.,E. Proof of Theorem 1,[0],[0]
"Moreover, this theorem also hold in the columnwise sense that if Φi : M → M ′ such that [M ′]∗,j = Bj [M ]∗,j for some sequence of matrices B1, . . .",E. Proof of Theorem 1,[0],[0]
", Bd, then Φi is not allowable unless each Bj is a multiple of the identity.
",E. Proof of Theorem 1,[0],[0]
Proof.,E. Proof of Theorem 1,[0],[0]
"Following the same steps as in the proof of Lemma 8, we now have
Φi ( T̂g(f)(ρi) )",E. Proof of Theorem 1,[0],[0]
"= Bρi(g) f̂(ρi),
T′g ( Φi(f̂(ρi)) )",E. Proof of Theorem 1,[0],[0]
"= ρi(g)Bf̂ (ρi).
",E. Proof of Theorem 1,[0],[0]
"However, by the second form of Schur’s Lemma, we cannot have Bρi(g) = ρi(g)B for all g ∈G, unless B is a multiple of the identity.
",E. Proof of Theorem 1,[0],[0]
Lemma 10.,E. Proof of Theorem 1,[0],[0]
"Φi is allowable if and only if it is of the form M 7→MB for some B ∈Cδ×δ .
",E. Proof of Theorem 1,[0],[0]
Proof.,E. Proof of Theorem 1,[0],[0]
"For the “if” part of this lemma, see Lemma 8.",E. Proof of Theorem 1,[0],[0]
"For the “only if” part, note that the set of allowable Φi form a subspace of all linear maps Cδ×δ → Cδ×δ, and any allowable Φi can be expressed in the form
[Φi(M)]a,b = ∑
c,d
αa,b,c,dMc,d.
By Lemma 9, if a 6= c but b = d, then αa,b,c,d = 0.",E. Proof of Theorem 1,[0],[0]
"On the other hand, by Lemma 8 if a= c, then αa,b,c,d can take on any value, regardless of the values of b and d, as long as αa,b,a,d is constant across varying a.
Now consider the remaining case a 6= c and b 6= d, and assume that αa,b,c,d 6= 0 while Φi is still allowable.",E. Proof of Theorem 1,[0],[0]
"Then, by Lemma 8, it is possible to construct a second allowable mapΦ′i (namely one in whichα ′",E. Proof of Theorem 1,[0],[0]
"a,d,a,b = 1 andα ′",E. Proof of Theorem 1,[0],[0]
"a,d,x,y = 0 for all (x, y) 6=",E. Proof of Theorem 1,[0],[0]
"(c, d)) such that in the composite map Φ′′i =",E. Proof of Theorem 1,[0],[0]
Φ ′,E. Proof of Theorem 1,[0],[0]
i ◦,E. Proof of Theorem 1,[0],[0]
"Φi, α′′a,d,c,d 6= 0.",E. Proof of Theorem 1,[0],[0]
"Thus, Φ′′i is not allowable.",E. Proof of Theorem 1,[0],[0]
"However, the composition of one allowable map with another allowable map is allowable, contradicting our assumption that Φi is allowable.
",E. Proof of Theorem 1,[0],[0]
"Thus, we have established that if Φi is allowable, then αa,b,c,d=0, unless a= c. To show that any allowable Φi of the form M 7→ MB, it remains to prove that additionally αa,b,a,d is constant across a. Assume for contradiction that Φi is allowable, but for some (a, e, b, d) indices αa,b,a,d 6= αe,b,e,d. Now let Φ0 be the allowable map that zeros out every column except column d (i.e., α0x,d,x,d = 1 for all x, but all other coefficients are zero), and let Φ′ be the allowable map that moves column b to column d (i.e., α′x,d,x,b = 1 for any x, but all other coeffcients are zero).",E. Proof of Theorem 1,[0],[0]
"Since the composition of allowable maps is allowable, we expect Φ′′ = Φ′ ◦",E. Proof of Theorem 1,[0],[0]
Φ ◦ Φ0 to be allowable.,E. Proof of Theorem 1,[0],[0]
"However Φ′′ is a map that falls under the purview of Lemma 9, yet α′′a,d,a,d 6= α′′e,d,e,d (i.e., Mj is not a multiple of the identity) creating a contradiction.
",E. Proof of Theorem 1,[0],[0]
Proof of Theorem 1 (reverse direction).,E. Proof of Theorem 1,[0],[0]
"For simplicty we first prove the theorem assuming Yℓ=C for each ℓ.
Since N is a G-CNN, each of the mappings (σℓ ◦ φℓ) : L(Xℓ−1) → L(Xℓ) is equivariant with the corresponding translation actions {Tℓ−1g }g∈G and {Tℓg}g∈G. Since σℓ is a pointwise operator, this is equivalent to asserting that φℓ is equivariant with {Tℓ−1g }g∈G and {Tℓg}g∈G. Letting X = Xℓ−1 and X ′",E. Proof of Theorem 1,[0],[0]
"= Xℓ, Lemma 8 then tells us the the Fourier transforms of fℓ−1 and φℓ(fℓ−1) are related by
̂φℓ(fℓ−1)(ρi) =",E. Proof of Theorem 1,[0],[0]
"Φ ( f̂ℓ−1(ρi) )
for some fixed set of linear maps Φ1,Φ2, . .",E. Proof of Theorem 1,[0],[0]
..,E. Proof of Theorem 1,[0],[0]
"Furthermore, by Lemma 10, each Φi must be of the formM 7→MBi for some appropriate matrix Bi ∈ Cdρ×dρ .",E. Proof of Theorem 1,[0],[0]
"If we then define χℓ as the inverse Fourier transform of (B1, B2, . . .), then by the convolution theorem (Proposition 2), φℓ(fℓ−1) = fℓ−1 ∗ χ, confirming that N is a G-CNN.",E. Proof of Theorem 1,[0],[0]
"The extension of this result to the vector valued case, fℓ :",E. Proof of Theorem 1,[0],[0]
"Xℓ → Vℓ, is straightforward.",E. Proof of Theorem 1,[0],[0]
Convolutional neural networks have been extremely successful in the image recognition domain because they ensure equivariance to translations.,abstractText,[0],[0]
"There have been many recent attempts to generalize this framework to other domains, including graphs and data lying on manifolds.",abstractText,[0],[0]
"In this paper we give a rigorous, theoretical treatment of convolution and equivariance in neural networks with respect to not just translations, but the action of any compact group.",abstractText,[0],[0]
"Our main result is to prove that (given some natural constraints) convolutional structure is not just a sufficient, but also a necessary condition for equivariance to the action of a compact group.",abstractText,[0],[0]
Our exposition makes use of concepts from representation theory and noncommutative harmonic analysis and derives new generalized convolution formulae.,abstractText,[0],[0]
On the Generalization of Equivariance and Convolution in Neural Networks  to the Action of Compact Groups,title,[0],[0]
"Modern machine learning systems based on deep neural networks are usually over-parameterized, i.e. the number of parameters in the model is much larger than the size of the training data, which makes these systems prone to overfitting.",1. Introduction,[0],[0]
"Several explicit regularization strategies have been used in practice to help these systems generalize, including `1 and `2 regularization of the parameters (Nowlan and Hinton, 1992).",1. Introduction,[0],[0]
"Recently, (Neyshabur et al., 2015) showed that a variety of such norm-based regularizers can provide sizeindependent capacity control, suggesting that the network size is not a good measure of complexity in such settings.",1. Introduction,[0],[0]
"Such a view had been previously motivated in the context of matrix factorization (Srebro et al., 2005), where it is preferable to have many factors of limited overall influence rather than a few important ones.
",1. Introduction,[0],[0]
"Besides explicit regularization techniques, practitioners have used a spectrum of algorithmic approaches to improve the generalization ability of over-parametrized models.",1. Introduction,[0],[0]
"This includes early stopping of back propagation (Caruana et al., 2001), batch normalization (Ioffe and Szegedy, 2015) and
1Department of Computer Science, Johns Hopkins University, Baltimore, USA 2Department of Biomedical Engineering, Johns Hopkins University, Baltimore, USA.",1. Introduction,[0],[0]
"Correspondence to: Raman Arora <arora@cs.jhu.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
dropout (Srivastava et al., 2014).",1. Introduction,[0],[0]
"In particular, dropout, which is the focus of this paper, randomly drops hidden nodes along with their connections at training time.",1. Introduction,[0],[0]
"Dropout was introduced by Srivastava et al. (2014) as a way of breaking up co-adaptation among neurons, drawing insights from the success of the sexual reproduction model in the evolution of advanced organisms.",1. Introduction,[0],[0]
"While dropout has enjoyed tremendous success in training deep neural networks, the theoretical understanding of how dropout (and other algorithmic heuristics) provide regularization in deep learning remains somewhat limited.
",1. Introduction,[0],[0]
"We argue that a prerequisite for understanding implicit regularization due to various algorithmic heuristics in deep learning, including dropout, is to analyze their behavior in simpler models.",1. Introduction,[0],[0]
"Therefore, in this paper, we consider the following learning problem.",1. Introduction,[0],[0]
Let x ∈ Rd2 represent an input feature vector with some unknown distribution D such that Ex∼D[xx>] = I.,1. Introduction,[0],[0]
The output label vector y ∈ Rd1 is given as y = Mx for some M ∈ Rd1×d2 .,1. Introduction,[0],[0]
"We consider the hypothesis class represented by a single hidden-layer linear network parametrized as hU,V(x) = UV>x, where V ∈ Rd2×r and U ∈ Rd1×r are the weight matrices in the first and the second layers, respectively.",1. Introduction,[0],[0]
"The goal of learning is to find weight matrices U,V that minimize the expected loss `(U,V) := Ex∼D[‖y−hU,V(x)‖2] = Ex∼D[‖y−UV>x‖2].
",1. Introduction,[0],[0]
"A natural learning algorithm to consider is back-propagation with dropout, which can be seen as an instance of stochastic gradient descent on the following objective:
f(U,V) :",1. Introduction,[0],[0]
"=Ebi∼Ber(θ),x∼D [∥∥∥∥y− 1θU diag(b)V>x ∥∥∥∥2 ] , (1)
where the expectation is w.r.t.",1. Introduction,[0],[0]
the underlying distribution on data as well as randomization due to dropout (each hidden unit is dropped independently with probability 1− θ).,1. Introduction,[0],[0]
"This procedure, which we simply refer to as dropout in this paper, is given in Algorithm 1.
",1. Introduction,[0],[0]
"It is easy to check (see Lemma A.1 in the supplementary) that the objective in equation (1) can be written as
f(U,V) =",1. Introduction,[0],[0]
"`(U,V) + λ r∑ i=1",1. Introduction,[0],[0]
"‖ui‖2‖vi‖2, (2)
where λ = 1−θθ is the regularization parameter, and ui and vi represent the ith columns of U and V, respectively.",1. Introduction,[0],[0]
"Note
that while the goal was to minimize the expected squared loss, using dropout with gradient descent amounts to finding a minimum of the objective in equation (2); we argue that the additional term in the objective serves as a regularizer, R(U,V) := λ ∑r i=1",1. Introduction,[0],[0]
"‖ui‖2‖vi‖2, and is an explicit instantiation of the implicit bias of dropout.",1. Introduction,[0],[0]
"Furthermore, we note that this regularizer is closely related to path regularization which is given as the square-root of the sum over all paths, from input to output, of the product of the squared weights along the path (Neyshabur et al., 2015).",1. Introduction,[0],[0]
"Formally, for a single layer network, path regularization is given as
ψ2(U,V) =  r∑ i=1",1. Introduction,[0],[0]
d1∑ j=1 d2∑ k=1 u2jiv 2 ki  12 .,1. Introduction,[0],[0]
"(3) Interestingly, the dropout regularizer is equal to the square of the path regularizer, i.e. R(U,V) = λψ22(U,V).",1. Introduction,[0],[0]
"While this observation is rather immediate, it has profound implications owing to the fact that path regularization provides size-independent capacity control in deep learning, thereby supporting empirical evidence that dropout finds good solutions in over-parametrized settings.
",1. Introduction,[0],[0]
"In this paper, we focus on studying the optimization landscape of the objective in equation (2) for a single hiddenlayer linear network with dropout and the special case of an autoencoder with tied weights.",1. Introduction,[0],[0]
"Furthermore, we are interested in characterizing the solutions to which dropout (i.e. Algorithm 1) converges.",1. Introduction,[0],[0]
"We make the following progress toward addressing these questions.
",1. Introduction,[0],[0]
1.,1. Introduction,[0],[0]
We formally characterize the implicit bias of dropout.,1. Introduction,[0],[0]
"We show that, when minimizing the expected loss `(U,V) with dropout, any global minimum (Ũ, Ṽ) satisfies ψ2(Ũ, Ṽ) = min{ψ2(U,V) s.t. UV> = ŨṼ
>}.",1. Introduction,[0],[0]
"More importantly, for auto-encoders with tied weights, we show that all local minima inherit this property.
2.",1. Introduction,[0],[0]
"Despite the non-convex nature of the problem, we completely characterize the global optima by giving necessary and sufficient conditions for optimality.
3.",1. Introduction,[0],[0]
We describe the optimization landscape of the dropout problem.,1. Introduction,[0],[0]
"In particular, we show that for a sufficiently small dropout rate, all local minima of the objective in equation (2) are global and all saddle points are non-degenerate.",1. Introduction,[0],[0]
"This allows Algorithm 1 to efficiently escape saddle points and converge to a global optimum.
",1. Introduction,[0],[0]
The rest of the paper is organized as follows.,1. Introduction,[0],[0]
"In Section 2, we study dropout for single hidden-layer linear auto-encoder networks with weights tied between the first and the second layers.",1. Introduction,[0],[0]
"This gives us the tools to study the dropout problem in a more general setting of single hidden-layer linear
Algorithm 1 Dropout with Stochastic Gradient Descent
input Data {(xt, yt)} T−1 t=0 , dropout rate 1−θ, learning rate η
1: Initialize U0,V0 2: for t = 0, 1, . . .",1. Introduction,[0],[0]
", T − 1 do 3: sample bt element-wise from Bernoulli(θ) 4: Update the weights
Ut+1←Ut−η ( 1
θ Ut diag(bt)V>t xt−yt
)",1. Introduction,[0],[0]
"x>t Vt diag(bt)
Vt+1←Vt−ηxt",1. Introduction,[0],[0]
"( 1
θ x>t Vt diag(bt)U > t −y>t
)",1. Introduction,[0],[0]
"Ut diag(bt)
5: end for output UT ,VT
networks in Section 3.",1. Introduction,[0],[0]
"In Section 4, we characterize the optimization landscape of the objective in (2), show that it satisfies the strict saddle property, and that there are no spurious local minima.",1. Introduction,[0],[0]
"We specialize our results to matrix factorization in Section 5, and in Section 6, we discuss preliminary experiments to support our theoretical results.",1. Introduction,[0],[0]
"We denote matrices, vectors, scalar variables and sets by Roman capital letters, Roman small letters, small letters and script letters respectively (e.g. X, x, x, and X ).",1.1. Notation,[0],[0]
"For any integer d, we represent the set {1, . . .",1.1. Notation,[0],[0]
", d} by [d].",1.1. Notation,[0],[0]
"For any integer i, ei denotes the i-th standard basis.",1.1. Notation,[0],[0]
"For any integer d, 1d ∈ Rd is the vector of all ones, ‖x‖ represents the `2-norm of vector x, and ‖X‖, ‖X‖F , ‖X‖∗ and λi(X) represent the spectral norm, the Frobenius norm, the nuclear norm and the i-th largest singular value of matrix X, respectively.",1.1. Notation,[0],[0]
"〈·, ·〉 represents the standard inner product, for vectors or matrices, where 〈X,X′〉 = Tr(X>X′).",1.1. Notation,[0],[0]
"For a matrix X ∈ Rd1×d2 , diag(X) ∈ Rmin{d1,d2} returns its diagonal elements.",1.1. Notation,[0],[0]
"Similarly, for a vector x ∈ Rd, diag(x) ∈ Rd×d is a diagonal matrix with x on its diagonal.",1.1. Notation,[0],[0]
"For any scalar x, we define (x)+ = max{x, 0}, and for a matrix X, (X)+ is the elementwise application of (·)+ to X. For a matrix X with a compact singular value decomposition X = UΣV>, and for any scalar α ≥ 0, we define the singular-value shrinkagethresholding operator as Sα(X) := U(Σ− αI)+V>.",1.1. Notation,[0],[0]
We begin with a simpler hypothesis family of single hiddenlayer linear auto-encoders with weights tied such that U = V.,2. Linear autoencoders with tied weights,[0],[0]
Studying the problem in this setting helps our intuition about the implicit bias that dropout induces on weight matrices U.,2. Linear autoencoders with tied weights,[0],[0]
"This analysis will be extended to the more general setting of single hidden-layer linear networks in the next section.
",2. Linear autoencoders with tied weights,[0],[0]
"Recall that the goal here is to find an autoencoder network represented by a weight matrix U ∈ Rd2×r that solves:
min U∈Rd2×r `(U,U) + λ r∑ i=1",2. Linear autoencoders with tied weights,[0],[0]
‖ui‖4,2. Linear autoencoders with tied weights,[0],[0]
", (4)
where ui is the ith column of U. Note that the loss function `(U,U) is invariant under rotations, i.e., for any orthogonal transformation Q ∈ Rd×d,Q>Q = QQ> =",2. Linear autoencoders with tied weights,[0],[0]
"Id, it holds that
`(U,U)=Ex∼D[‖y− UQQ>U>x‖2]=`(UQ,UQ),
so that applying a rotation matrix to a candidate solution U does not change the value of the loss function.",2. Linear autoencoders with tied weights,[0],[0]
"However, the regularizer is not rotation-invariant and clearly depends on the choice of Q. Therefore, in order to solve Problem (4), we need to find a rotation matrix that minimizes the value of the regularizer for a given weight matrix.
",2. Linear autoencoders with tied weights,[0],[0]
"To that end, let us denote the squared column norms of the weight matrix U by nu = (‖u1‖2, . . .",2. Linear autoencoders with tied weights,[0],[0]
", ‖ur‖2)",2. Linear autoencoders with tied weights,[0],[0]
and let 1r ∈,2. Linear autoencoders with tied weights,[0],[0]
Rr be the vector of all ones.,2. Linear autoencoders with tied weights,[0],[0]
"Then, for any U,
R(U,U) = λ r∑ i=1 ‖ui‖4",2. Linear autoencoders with tied weights,[0],[0]
"= λ r ‖1r‖2‖nu‖2
≥ λ r 〈1r, nu〉2 = λ r ( r∑ i=1 ‖ui‖2 )",2. Linear autoencoders with tied weights,[0],[0]
"2 = λ r ‖U‖4F ,
where the inequality follows from Cauchy-Schwartz inequality.",2. Linear autoencoders with tied weights,[0],[0]
"Hence, the regularizer is lower bounded by λr ‖U‖ 4 F , with equality if and only if nu is parallel to 1r, i.e. when all the columns of U have equal norms.",2. Linear autoencoders with tied weights,[0],[0]
"Since the loss function is rotation invariant, one can always decrease the value of the overall objective by rotating U such that UQ has a smaller regularizer.",2. Linear autoencoders with tied weights,[0],[0]
"A natural question to ask, therefore, is if there always exists a rotation matrix Q such that the matrix UQ has equal column norms.",2. Linear autoencoders with tied weights,[0],[0]
"In order to formally address this question, we introduce the following definition.",2. Linear autoencoders with tied weights,[0],[0]
"Definition 2.1 (Equalized weight matrix, equalized autoencoder, equalizer).",2. Linear autoencoders with tied weights,[0],[0]
A weight matrix U is said to be equalized if all its columns have equal norms.,2. Linear autoencoders with tied weights,[0],[0]
An autoencoder with tied weights is said to be equalized if the norm of the incoming weight vector is equal across all hidden nodes in the network.,2. Linear autoencoders with tied weights,[0],[0]
"An orthogonal transformation Q is said to be an equalizer of U (equivalently, of the corresponding autoencoder) if UQ is equalized.
",2. Linear autoencoders with tied weights,[0],[0]
"Next, we show that any matrix U can be equalized.",2. Linear autoencoders with tied weights,[0],[0]
Theorem 2.2.,2. Linear autoencoders with tied weights,[0],[0]
Any weight matrix U ∈,2. Linear autoencoders with tied weights,[0],[0]
"Rd×r (equivalently, the corresponding autoencoder network hU,U) can be equalized.",2. Linear autoencoders with tied weights,[0],[0]
"Furthermore, there exists a polynomial time algorithm (Algorithm 2) that returns an equalizer for a given matrix.
",2. Linear autoencoders with tied weights,[0],[0]
"The key insight here is that if GU := U>U is the Gram matrix associated with the weight matrix U, then hU,U is equalized by Q if and only if all diagonal elements of Q>GUQ
Algorithm 2 EQZ(U) equalizer of an auto-encoder hU,U input U ∈",2. Linear autoencoders with tied weights,[0],[0]
"Rd×r
1:",2. Linear autoencoders with tied weights,[0],[0]
"G← U>U 2: Q← Ir 3: for i = 1 to r do 4: [V,Λ]←eig(G) {G=VΛV> eigendecomposition} 5: w = 1√ r−i+1 ∑r−i+1 i=1",2. Linear autoencoders with tied weights,[0],[0]
vi 6: Qi,2. Linear autoencoders with tied weights,[0],[0]
←,2. Linear autoencoders with tied weights,[0],[0]
[w w⊥] {w⊥ ∈ R(r−i+1)×(r−i) orthonormal basis for the Null space of w} 7:,2. Linear autoencoders with tied weights,[0],[0]
"G← Q>i GQi {Making first diagonal element zero} 8: G← G(2 : end, 2 : end) {First principal submatrix}
9: Q← Q",2. Linear autoencoders with tied weights,[0],[0]
"[
Ii−1 0 0",2. Linear autoencoders with tied weights,[0],[0]
"Qi ] 10: end for output Q {such that UQ is equalized}
are equal.",2. Linear autoencoders with tied weights,[0],[0]
"More importantly, if GU = VΛV> is an eigendecomposition of GU, then for w = 1√r ∑r i=1",2. Linear autoencoders with tied weights,[0],[0]
"vi, it holds that w>GUw = Tr GUr ; Proof of Theorem 2.2 uses this property to recursively equalize all diagonal elements of GU.
",2. Linear autoencoders with tied weights,[0],[0]
"Finally, we argue that the implicit bias induced by dropout is closely related to the notion of equalized network introduced above.",2. Linear autoencoders with tied weights,[0],[0]
"In particular, our main result of the section states that the dropout enforces any globally optimal network to be equalized.",2. Linear autoencoders with tied weights,[0],[0]
"Formally, we show the following.",2. Linear autoencoders with tied weights,[0],[0]
Theorem 2.3.,2. Linear autoencoders with tied weights,[0],[0]
"If U is a global optimum of Problem 4, then U is equalized.",2. Linear autoencoders with tied weights,[0],[0]
"Furthermore, it holds that
R(U) = λ
r ‖U‖4F .
",2. Linear autoencoders with tied weights,[0],[0]
Theorem 2.3 characterizes the effect of regularization induced by dropout in learning autoencoders with tied weights.,2. Linear autoencoders with tied weights,[0],[0]
"It states that for any globally optimal network, the columns of the corresponding weight matrix have equal norms.",2. Linear autoencoders with tied weights,[0],[0]
"In other words, dropout tends to give equal weights to all hidden nodes – it shows that dropout implicitly biases the optimal networks towards having hidden nodes with limited overall influence rather than a few important ones.
",2. Linear autoencoders with tied weights,[0],[0]
"While Theorem 2.3 makes explicit the bias of dropout and gives a necessary condition for global optimality in terms of the weight matrix U∗, it does not characterize the bias induced in terms of the network (i.e. in terms of U∗U>∗ ).",2. Linear autoencoders with tied weights,[0],[0]
The following theorem completes the characterization by describing globally optimal autoencoder networks.,2. Linear autoencoders with tied weights,[0],[0]
"Since the goal is to understand the implicit bias of dropout, we specify the global optimum in terms of the true concept, M. Theorem 2.4.",2. Linear autoencoders with tied weights,[0],[0]
For any j ∈,2. Linear autoencoders with tied weights,[0],[0]
"[r], let κj := 1j ∑j i=1",2. Linear autoencoders with tied weights,[0],[0]
λi(M).,2. Linear autoencoders with tied weights,[0],[0]
"Furthermore, define ρ := max{j ∈",2. Linear autoencoders with tied weights,[0],[0]
[r] : λj(M) > λjκjr+λj }.,2. Linear autoencoders with tied weights,[0],[0]
"Then, if U∗ is a global optimum of Problem 4, it satisfies that U∗U>∗ = S λρκρ
r+λρ
(M).
",2. Linear autoencoders with tied weights,[0],[0]
Remark 2.5.,2. Linear autoencoders with tied weights,[0],[0]
"In light of Theorem 2.3, the proof of Theorem 2.4 entails solving the following optimization problem
min U∈Rd×r
`(U,U) + λ
r ‖U‖4F , (5)
instead of Problem 4.",2. Linear autoencoders with tied weights,[0],[0]
"This follows since the loss function `(U,U) is invariant under rotations, hence a weight matrix U cannot be optimal if there exists a rotation matrix Q such that R(UQ,UQ) < R(U,U).",2. Linear autoencoders with tied weights,[0],[0]
"Now, while the objective in Problem 5 is a lower bound on the objective in Problem 4, by Theorem 2.2, we know that any weight matrix can be equalized.",2. Linear autoencoders with tied weights,[0],[0]
"Thus, it follows that the minimum of the two problems coincide.",2. Linear autoencoders with tied weights,[0],[0]
"Although Problem 5 is still non-convex, it is easier to study owing to a simpler form of the regularizer.",2. Linear autoencoders with tied weights,[0],[0]
Figure 1 shows how optimization landscape changes with different dropout rates for a single hidden layer linear autoencoder with one dimensional input and output and with a hidden layer of width two.,2. Linear autoencoders with tied weights,[0],[0]
"Next, we consider the more general setting of a shallow linear network with a single hidden layer.",3. Single hidden-layer linear networks,[0],[0]
"Recall, that the
goal is to find weight matrices U,V that solve
min U∈Rd1×r,V∈Rd2×r `(U,V) + λ r∑ i=1",3. Single hidden-layer linear networks,[0],[0]
‖ui‖2‖vi‖2.,3. Single hidden-layer linear networks,[0],[0]
"(6)
As in the previous section, we note that the loss function is rotation invariant, i.e. `(UQ,VQ) =",3. Single hidden-layer linear networks,[0],[0]
"`(U,V) for any rotation matrix Q, however the regularizer is not invariant to rotations.",3. Single hidden-layer linear networks,[0],[0]
"Furthermore, it is easy to verify that both the loss function and the regularizer are invariant under rescaling of the incoming and outgoing weights to hidden neurons.",3. Single hidden-layer linear networks,[0],[0]
Remark 3.1 (Rescaling invariance).,3. Single hidden-layer linear networks,[0],[0]
"The objective function in Problem (2) is invariant under rescaling of weight matrices, i.e. invariant to transformations of the form Ū = UD, V̄ = VD−1, where D is a diagonal matrix with positive entries.",3. Single hidden-layer linear networks,[0],[0]
"This follows since ŪV̄> = UDD−>V> = UV>, so that `(Ū, V̄) =",3. Single hidden-layer linear networks,[0],[0]
"`(U,V), and also R(Ū, V̄) = R(U,V) since r∑ i=1",3. Single hidden-layer linear networks,[0],[0]
‖ūi‖2‖v̄i‖2 = r∑ i=1,3. Single hidden-layer linear networks,[0],[0]
‖diui‖2‖ 1 di vi‖2 = r∑ i=1,3. Single hidden-layer linear networks,[0],[0]
"‖ui‖2‖vi‖2.
",3. Single hidden-layer linear networks,[0],[0]
"As a result of rescaling invariance, f(Ū, V̄) = f(U,V).",3. Single hidden-layer linear networks,[0],[0]
"Now, following similar arguments as in the previous section,
we define nu,v = (‖u1‖‖v1‖, . . .",3. Single hidden-layer linear networks,[0],[0]
", ‖ur‖‖vr‖), and note that
R(U,V) = λ r∑ i=1",3. Single hidden-layer linear networks,[0],[0]
‖ui‖2‖vi‖2,3. Single hidden-layer linear networks,[0],[0]
"= λ r ‖1r‖2‖nu,v‖2
≥ λ r 〈",3. Single hidden-layer linear networks,[0],[0]
"1r, nu,v〉2 = λ r ( r∑ i=1 ‖ui‖‖vi‖ )2 ,
where the inequality is due to Cauchy-Schwartz, and the lower bound is achieved if and only if nu,v is a scalar multiple of 1r, i.e. iff ‖ui‖‖vi‖",3. Single hidden-layer linear networks,[0],[0]
= ‖u1‖‖v1‖,3. Single hidden-layer linear networks,[0],[0]
"for all i = 1, . . .",3. Single hidden-layer linear networks,[0],[0]
", r. This observation motivates the following definition.",3. Single hidden-layer linear networks,[0],[0]
"Definition 3.2 (Jointly equalized weight matrices, equalized linear networks).",3. Single hidden-layer linear networks,[0],[0]
"A pair of weight matrices (U,V) ∈ Rd1×r×Rd2×r is said to be jointly equalized if ‖ui‖‖vi‖ = ‖u1‖‖v1‖ for all i ∈",3. Single hidden-layer linear networks,[0],[0]
[r].,3. Single hidden-layer linear networks,[0],[0]
A single hidden-layer linear network is said to be equalized if the product of the norms of the incoming and outgoing weights are equal for all hidden nodes.,3. Single hidden-layer linear networks,[0],[0]
"Equivalently, a single hidden-layer network parametrized by weight matrices U,V, is equalized if U,V are jointly equalized.",3. Single hidden-layer linear networks,[0],[0]
"An orthogonal transformation Q ∈ Rr×r is an equalizer of a single hidden-layer network hU,V parametrized by weight matrices U,V, if hUQ,VQ is equalized.",3. Single hidden-layer linear networks,[0],[0]
"The network hU,V (the pair(U,V)) then are said to be jointly equalizable by Q.
Note that Theorem 2.2 only guarantees the existence of an equalizer for an autoencoder with tied weights.",3. Single hidden-layer linear networks,[0],[0]
"It does not inform us regarding the existence of a rotation matrix that jointly equalizes a general network parameterized by a pair of weight matrices (U,V); in fact, it is not true in general that any pair (U,V) is jointly equalizable.",3. Single hidden-layer linear networks,[0],[0]
"Indeed, the general case requires a more careful treatment.",3. Single hidden-layer linear networks,[0],[0]
"It turns out that while a given pair of matrices (U,V) may not be jointly equalizable there exists a pair (Ũ, Ṽ) that is jointly equalizable and implements the same network function, i.e. hŨ,Ṽ = hU,V. Formally, we state the following result.",3. Single hidden-layer linear networks,[0],[0]
Theorem 3.3.,3. Single hidden-layer linear networks,[0],[0]
"For any given pair of weight matrices (U,V) ∈ Rd1×r×Rd2×r, there exists another pair (Ũ, Ṽ) ∈ Rd1×r × Rd2×r and a rotation matrix Q ∈ Rr×r such that hŨ,Ṽ = hU,V and hŨ,Ṽ is jointly equalizable by Q. Furthermore, for Ū := ŨQ and V̄ := ṼQ it holds that ‖ūi‖2 = ‖v̄i‖2 = 1r‖UV >‖∗ for i = 1, . . .",3. Single hidden-layer linear networks,[0],[0]
", r.
Theorem 3.3 implies that for any network hU,V there exists an equalized network hŪ,V̄ such that hŪ,V̄ = hU,V. Hence, it is always possible to reduce the objective by equalizing the network, and a network hU,V is globally optimal only if it is equalized.",3. Single hidden-layer linear networks,[0],[0]
Theorem 3.4.,3. Single hidden-layer linear networks,[0],[0]
"If (U,V) is a global optimum of Problem 6, then U,V are jointly equalized.",3. Single hidden-layer linear networks,[0],[0]
"Furthermore, it holds that
R(U,V) = λ
r ( r∑ i=1 ‖ui‖‖vi‖",3. Single hidden-layer linear networks,[0],[0]
),3. Single hidden-layer linear networks,[0],[0]
"2 = λ r ‖UV>‖2∗
Remark 3.5.",3. Single hidden-layer linear networks,[0],[0]
"As in the case of autoencoders with tied weights in Section 2, a complete characterization of the implicit bias of dropout is given by considering the global optimality in terms of the network, i.e. in terms of the product of the weight matrices UV>.",3. Single hidden-layer linear networks,[0],[0]
"Not surprisingly, even in the case of single hidden-layer networks, dropout promotes sparsity, i.e. favors low-rank weight matrices.
",3. Single hidden-layer linear networks,[0],[0]
Theorem 3.6.,3. Single hidden-layer linear networks,[0],[0]
For any j ∈,3. Single hidden-layer linear networks,[0],[0]
"[r], let κj := 1j ∑j i=1",3. Single hidden-layer linear networks,[0],[0]
λi(M).,3. Single hidden-layer linear networks,[0],[0]
"Furthermore, define ρ := max{j ∈",3. Single hidden-layer linear networks,[0],[0]
[r] : λj(M) > λjκjr+λj }.,3. Single hidden-layer linear networks,[0],[0]
"Then, if (U∗,V∗) is a global optimum of Problem 6, it satisfies that U∗V>∗ = S λρκρ
r+λρ
(M).",3. Single hidden-layer linear networks,[0],[0]
"While the focus in Section 2 and Section 3 was on understanding the implicit bias of dropout in terms of the global optima of the resulting regularized learning problem, here we focus on computational aspects of dropout as an optimization procedure.",4. Geometry of the Optimization Problem,[0],[0]
"Since dropout is a first-order method (see Algorithm 1) and the landscape of Problem 4 is highly non-convex, we can perhaps only hope to find a local minimum, that too provided if the problem has no degenerate saddle points (Lee et al., 2016; Ge et al., 2015).",4. Geometry of the Optimization Problem,[0],[0]
"Therefore, in this section, we pose the following questions: What is the implicit bias of dropout in terms of local minima?",4. Geometry of the Optimization Problem,[0],[0]
Do local minima share anything with global minima structurally or in terms of the objective?,4. Geometry of the Optimization Problem,[0],[0]
"Can dropout find a local optimum?
",4. Geometry of the Optimization Problem,[0],[0]
"For the sake of simplicity of analysis, we focus on the case of autoencoders with tied weight as in Section 2.",4. Geometry of the Optimization Problem,[0],[0]
"We show in Section 4.1 that (a) local minima of Problem 4 inherit the same implicit bias as the global optima, i.e. all local minima are equalized.",4. Geometry of the Optimization Problem,[0],[0]
"Then, in Section 4.2, we show that for sufficiently small regularization parameter, (b) there are no spurious local minima, i.e. all local minima are global, and (c) all saddle points are non-degenerate (see Definition 4.2).",4. Geometry of the Optimization Problem,[0],[0]
"We begin by recalling that the loss `(U,U) is rotation invariant, i.e. `(UQ,UQ) =",4.1. Implicit bias in local optima,[0],[0]
"`(U,U) for any rotation matrix Q.",4.1. Implicit bias in local optima,[0],[0]
"Now, if the weight matrix U were not equalized, then there exist indices",4.1. Implicit bias in local optima,[0],[0]
"i, j ∈",4.1. Implicit bias in local optima,[0],[0]
[r] such that ‖ui‖,4.1. Implicit bias in local optima,[0],[0]
>,4.1. Implicit bias in local optima,[0],[0]
‖uj‖.,4.1. Implicit bias in local optima,[0],[0]
We show that it is easy to design a rotation matrix (equal to identity everywhere expect for columns i and j) that moves mass from ui to uj such that the difference in the norms of the corresponding columns of UQ decreases strictly while leaving the norms of other columns invariant.,4.1. Implicit bias in local optima,[0],[0]
"In other words, this rotation strictly reduces the regularizer and hence the objective.",4.1. Implicit bias in local optima,[0],[0]
"Formally, this implies the following result.
",4.1. Implicit bias in local optima,[0],[0]
Lemma 4.1.,4.1. Implicit bias in local optima,[0],[0]
"All local optima of Problem 4 are equalized, i.e. if U is a local optimum, then ‖ui‖ = ‖uj‖ ∀i, j ∈",4.1. Implicit bias in local optima,[0],[0]
"[r].
Lemma 4.1 unveils a fundamental property of dropout.",4.1. Implicit bias in local optima,[0],[0]
"As
soon as we perform dropout in the hidden layer – no matter how small the dropout rate – all local minima become equalized.",4.1. Implicit bias in local optima,[0],[0]
"Next, we characterize the solutions to which dropout (i.e. Algorithm 1) converges.",4.2. Landscape properties,[0],[0]
We do so by understanding the optimization landscape of Problem 4.,4.2. Landscape properties,[0],[0]
"Central to our analysis, is the following notion of strict saddle property.",4.2. Landscape properties,[0],[0]
Definition 4.2 (Strict saddle point/property).,4.2. Landscape properties,[0],[0]
Let f : U → R be a twice differentiable function and let U ∈ U be a critical point of f .,4.2. Landscape properties,[0],[0]
"Then, U is a strict saddle point of f if the Hessian of f at U has at least one negative eigenvalue, i.e. λmin(∇2f(U))",4.2. Landscape properties,[0],[0]
< 0.,4.2. Landscape properties,[0],[0]
"Furthermore, f satisfies strict saddle property if all saddle points of f are strict saddle.
",4.2. Landscape properties,[0],[0]
"Strict saddle property ensures that for any critical point U that is not a local optimum, the Hessian has a significant negative eigenvalue which allows first order methods such as gradient descent (GD) and stochastic gradient descent (SGD) to escape saddle points and converge to a local minimum (Lee et al., 2016; Ge et al., 2015).",4.2. Landscape properties,[0],[0]
"Following this idea, there has been a flurry of works on studying the landscape of different machine learning problems, including low rank matrix recovery (Bhojanapalli et al., 2016), generalized phase retrieval problem (Sun et al., 2016), matrix completion (Ge et al., 2016), deep linear networks (Kawaguchi, 2016), matrix sensing and robust PCA (Ge et al., 2017) and tensor decomposition (Ge et al., 2015), making a case for global optimality of first order methods.
",4.2. Landscape properties,[0],[0]
"For the special case of no regularization (i.e. λ = 0; equivalently, no dropout), Problem 4 reduces to standard squared loss minimization which has been shown to have no spurious local minima and satisfy strict saddle property (see, e.g. (Baldi and Hornik, 1989; Jin et al., 2017)).",4.2. Landscape properties,[0],[0]
"However, the regularizer induced by dropout can potentially introduce new spurious local minima as well as degenerate saddle points.",4.2. Landscape properties,[0],[0]
"Our next result establishes that that is not the case, at least when the dropout rate is sufficiently small.",4.2. Landscape properties,[0],[0]
Theorem 4.3.,4.2. Landscape properties,[0],[0]
For regularization parameter λ < rλr(M)∑r i=1,4.2. Landscape properties,[0],[0]
"λi(M)−rλr(M)
, (a) all local minima of Problem 4 are global, and (b) all saddle points are strict saddle points.
",4.2. Landscape properties,[0],[0]
A couple of remarks are in order.,4.2. Landscape properties,[0],[0]
"First, Theorem 4.3 guarantees that any critical point U that is not a global optimum is a strict saddle point, i.e. ∇2f(U,U) has a negative eigenvalue.",4.2. Landscape properties,[0],[0]
"This property allows first order methods, such as dropout given in Algorithm 1, to escape such saddle points.",4.2. Landscape properties,[0],[0]
"Second, note that the guarantees in Theorem 4.3 hold when the regularization parameter λ is sufficiently small.",4.2. Landscape properties,[0],[0]
"Assumptions of this kind are common in the literature (see, for example (Ge et al., 2017)).",4.2. Landscape properties,[0],[0]
"While this is a sufficient condition for the result in Theorem 4.3, it is not clear if it is necessary.",4.2. Landscape properties,[0],[0]
"The optimization problem associated with learning a shallow network, i.e. Problem 6, is closely related to the optimization problem for matrix factorization.",5. Matrix Factorization with Dropout,[0],[0]
"Recall that in matrix factorization, given a matrix M ∈ Rd1×d2 , one seeks to find factors U,V that minimize `(U,V) =",5. Matrix Factorization with Dropout,[0],[0]
‖M − UV>‖2F .,5. Matrix Factorization with Dropout,[0],[0]
"Matrix factorization has recently been studied with dropout by Zhai and Zhang (2015); He et al. (2016) and Cavazza et al. (2018) where at each iteration of gradient descent on the loss function, the columns of factors U,V are dropped independently and with equal probability.",5. Matrix Factorization with Dropout,[0],[0]
"Following Cavazza et al. (2018), we can write the resulting problem as
min U∈Rd1×r,V∈Rd2×r ‖M− UV>‖2F",5. Matrix Factorization with Dropout,[0],[0]
+ λ r∑ i=1,5. Matrix Factorization with Dropout,[0],[0]
"‖ui‖2‖vi‖2, (7)
which is identical to Problem 6.",5. Matrix Factorization with Dropout,[0],[0]
"However, there are two key distinctions.",5. Matrix Factorization with Dropout,[0],[0]
"First, we are interested in stochastic optimization problem whereas the matrix factorization problem is typically posed for a given matrix.",5. Matrix Factorization with Dropout,[0],[0]
"Second, for the learning problem that we consider here, it is unreasonable to assume access to the true model (i.e. matrix M).",5. Matrix Factorization with Dropout,[0],[0]
"Nonetheless, many of the insights we develop here as well as the technical results and algorithmic contributions apply to matrix factorization.",5. Matrix Factorization with Dropout,[0],[0]
"Therefore, the goal in this section is to bring to bear the results in Sections 2, 3 and 4 to matrix factorization.
",5. Matrix Factorization with Dropout,[0],[0]
"We note that Theorem 3.6 and Theorem 3.3, both of which hold for matrix factorization, imply that there is a polynomial time algorithm to solve the matrix factorization problem.",5. Matrix Factorization with Dropout,[0],[0]
"In order to find a global optimum of Problem 7, we first compute the optimal M̄",5. Matrix Factorization with Dropout,[0],[0]
= ŨṼ > using shrinkagethresholding operation (see Theorem 3.6).,5. Matrix Factorization with Dropout,[0],[0]
"A global optimum (Ū, V̄) is then obtained by joint equalization of (Ũ, Ṽ) (see Theorem 3.3) using Algorithm 2.",5. Matrix Factorization with Dropout,[0],[0]
The whole procedure is described in Algorithm 3.,5. Matrix Factorization with Dropout,[0],[0]
"Few remarks are in order.
",5. Matrix Factorization with Dropout,[0],[0]
Remark 5.1 (Computational cost of Algorithm 3).,5. Matrix Factorization with Dropout,[0],[0]
"It is easy to check that computing ρ, M̄, Ũ and Ṽ requires computing a rank-r SVD of M, which costs O(d2r), where
Algorithm 3 Polynomial time solver for Problem 7
input Matrix M ∈ Rd2×d1 to be factorized, size of factorization r, regularization parameter λ
1: ρ← max{j ∈",5. Matrix Factorization with Dropout,[0],[0]
"[r] : λj(M) > λjκjr+λj }, where κj = 1j ∑j i=1",5. Matrix Factorization with Dropout,[0],[0]
λi(M),5. Matrix Factorization with Dropout,[0],[0]
for j ∈,5. Matrix Factorization with Dropout,[0],[0]
[r].,5. Matrix Factorization with Dropout,[0],[0]
2:,5. Matrix Factorization with Dropout,[0],[0]
"M̄← S λρκρ r+λρ (M) 3: (U,Σ,V)← svd(M̄) 4: Ũ← UΣ 12 , Ṽ← VΣ 12 5: Q← EQZ(Ũ) {Algorithm 2} 6: Ū← ŨQ, V̄← ṼQ
output Ū, V̄ {global optimum of Problem 7}
d = max{d1, d2}.",5. Matrix Factorization with Dropout,[0],[0]
"Algorithm 2 entails computing GU = U>U, which costs O(r2d) and the cost of each iterate of Algorithm 2 is dominated by computing the eigendecomposition which is O(r3).",5. Matrix Factorization with Dropout,[0],[0]
"Overall, the computational cost of Algorithm 3 is O(d2r +",5. Matrix Factorization with Dropout,[0],[0]
"dr2 + r4).
",5. Matrix Factorization with Dropout,[0],[0]
Remark 5.2 (Universal Equalizer).,5. Matrix Factorization with Dropout,[0],[0]
"While Algorithm 2 is efficient (only linear in the dimension) for any rank r, there is a more effective equalization procedure when r is a power of 2.",5. Matrix Factorization with Dropout,[0],[0]
"In this case, we can give a universal equalizer which works simultaneously for all matrices in Rd×r.",5. Matrix Factorization with Dropout,[0],[0]
Let U ∈,5. Matrix Factorization with Dropout,[0],[0]
"Rd×r, r = 2k, k ∈ N",5. Matrix Factorization with Dropout,[0],[0]
and let U = WΣV> be its full SVD.,5. Matrix Factorization with Dropout,[0],[0]
"The matrix Ũ = UQ is equalized, where Q = VZk and
Zk :=  1 k = 1 2 −k+1 2 [ Zk−1 Zk−1 −Zk−1 Zk−1 ]",5. Matrix Factorization with Dropout,[0],[0]
"k > 1 .
",5. Matrix Factorization with Dropout,[0],[0]
"Finally, we note that Problem 7 is an instance of regularized matrix factorization which has recently received considerable attention in the machine learning literature (Ge et al., 2016; 2017; Haeffele and Vidal, 2017).",5. Matrix Factorization with Dropout,[0],[0]
"These works show that the saddle points of a class of regularized matrix factorization problems have certain “nice” properties (i.e. escape directions characterized by negative curvature around saddle points) which allow variants of first-order methods such as perturbed gradient descent (Ge et al., 2015; Jin et al., 2017) to converge to a local optimum.",5. Matrix Factorization with Dropout,[0],[0]
"Distinct from that line of research, we completely characterize the set of global optima of Problem 7, and provide a polynomial time algorithm to find a global optimum.
",5. Matrix Factorization with Dropout,[0],[0]
"The work most similar to the matrix factorization problem we consider in this section is that of Cavazza et al. (2018), with respect to which we make several important contributions: (I)",5. Matrix Factorization with Dropout,[0],[0]
"Cavazza et al. (2018) characterize optimal solu-
tions only in terms of the product of the factors, and not in terms of the factors themselves, whereas we provide globally optimal solutions in terms of the factors; (II) Cavazza et al. (2018) require the rank r of the desired factorization to be variable and above some threshold, whereas we consider fixed rank-r factorization for any r; (III) Cavazza et al. (2018) can only find low rank solutions using an adaptive dropout rate, which is not how dropout is used in practice, whereas we consider any fixed dropout rate; and (IV) we give an efficient poly time algorithm to find optimal factors.",5. Matrix Factorization with Dropout,[0],[0]
Dropout is a popular algorithmic technique used for avoiding overfitting when training large deep neural networks.,6. Empirical Results,[0],[0]
The goal of this section is not to attest to the already wellestablished success of dropout.,6. Empirical Results,[0],[0]
"Instead, the purpose of this section is to simply confirm the theoretical results we showed in the previous section, as a proof of concept.
",6. Empirical Results,[0],[0]
We begin with a toy example in order to visually illustrate the optimization landscape.,6. Empirical Results,[0],[0]
We use dropout to learn a simple linear auto-encoder with one-dimensional input and output (i.e. a network represented by a scalar M = 2) and a single hidden layer of width r = 2.,6. Empirical Results,[0],[0]
The input features are sampled for a standard normal distribution.,6. Empirical Results,[0],[0]
"Figure 2 shows the optimization landscape along with the contours of the level sets, and a trace of iterates of dropout (Algorithm 1).",6. Empirical Results,[0],[0]
"The initial iterates and global optima (given by Theorem 2.4) are shown by red and green dots, respectively.",6. Empirical Results,[0],[0]
"Since at any global optimum the weights are equalized, the optimal weight vector in this case is parallel to the vector (±1,±1).",6. Empirical Results,[0],[0]
"We see that dropout converges to a global minimum.
",6. Empirical Results,[0],[0]
"For a second illustrative experiment, we use Algorithm 1 to train a shallow linear network, where the input x ∈ R80",6. Empirical Results,[0],[0]
is distributed according to the standard Normal distribution.,100 101 102 103 104 105,[0],[0]
"The output y ∈ R120 is generated as y = Mx, where M ∈ R120×80 is drawn randomly by uniformly sampling the right and left singular subspaces and with a spectrum decaying exponentially.",100 101 102 103 104 105,[0],[0]
"Figure 3 illustrates the behavior of Algorithm 1 for different values of the regularization parameter (λ ∈ {0.1, 0.5, 1}), and for different sizes of factors (r ∈ {20, 80}).",100 101 102 103 104 105,[0],[0]
"The curve in blue shows the objective value for the iterates of dropout, and the line in red shows the optimal value of the objective (i.e. objective for a global optimum found using Theorem 3.6).",100 101 102 103 104 105,[0],[0]
"All plots are averaged over 50 runs of Algorithm 1 (averaged over different random initializations, random realizations of Bernoulli dropout, as well as random draws of training examples).
",100 101 102 103 104 105,[0],[0]
"To verify that the solution found by dropout actually has equalized factors, we consider the following measure.",100 101 102 103 104 105,[0],[0]
"At each iteration, we compute the “importance scores”, α(i)t = ‖uti‖‖vti‖, i ∈",100 101 102 103 104 105,[0],[0]
"[r], where uti and vti are the i-th columns of Ut and Vt, respectively.",100 101 102 103 104 105,[0],[0]
"The rightmost panel of Figure 3 shows the variance of α(i)t ’s, over the hidden nodes",100 101 102 103 104 105,[0],[0]
i ∈,100 101 102 103 104 105,[0],[0]
"[r], at each iterate t. Note that a high variance in αt corresponds to large variation in the values of ‖uti‖‖vti‖. When the variance is equal to zero, all importance scores are equal, thus the factors are equalized.",100 101 102 103 104 105,[0],[0]
"We see that iterations of Algorithm 1 decrease this measure monotonically, and the larger the value of λ, the faster the weights become equalized.",100 101 102 103 104 105,[0],[0]
"There has been much effort in recent years to understand the theoretical underpinnings of dropout (see Baldi and Sad-
owski (2013); Gal and Ghahramani (2016); Wager et al. (2013); Helmbold and Long (2015)).",7. Discussion,[0],[0]
"In this paper, we study the implicit bias of dropout in shallow linear networks.",7. Discussion,[0],[0]
We show that dropout prefers solutions with minimal path regularization which yield strong capacity control guarantees in deep learning.,7. Discussion,[0],[0]
"Despite being a non-convex optimization problem, we are able to fully characterize the global optima of the dropout objective.",7. Discussion,[0],[0]
Our analysis shows that dropout favors low-rank weight matrices that are equalized.,7. Discussion,[0],[0]
"This theoretical finding confirms that dropout as a procedure uniformly allocates weights to different subnetworks, which is akin to preventing co-adaptation.
",7. Discussion,[0],[0]
We characterize the optimization landscape of learning autoencoders with dropout.,7. Discussion,[0],[0]
"We first show that the local optima inherit the same implicit bias as global optimal, i.e. all local optima are equalized.",7. Discussion,[0],[0]
"Then, we show that for sufficiently small dropout rates, there are no spurious local minima in the landscape, and all saddle points are non-degenerate.",7. Discussion,[0],[0]
"These properties suggest that dropout – as an optimization procedure – can efficiently converge to a globally optimal solution specified by our theorems.
",7. Discussion,[0],[0]
Understanding dropout in shallow linear networks is a prerequisite for understanding dropout in deep learning.,7. Discussion,[0],[0]
"We see natural extensions of our results in two directions: 1) shallow networks with non-linear activation function such as rectified linear units (ReLU) which have been shown to enable faster training (Glorot et al., 2011) and are better understood in terms of the family of functions represented by ReLU-nets (Arora et al., 2018), and 2) exploring the global optimality in deeper networks, even for linear activations.",7. Discussion,[0],[0]
This research was supported in part by NSF BIGDATA grant IIS-1546482 and NSF grant IIS-1618485.,Acknowledgements,[0],[0]
Algorithmic approaches endow deep learning systems with implicit bias that helps them generalize even in over-parametrized settings.,abstractText,[0],[0]
"In this paper, we focus on understanding such a bias induced in learning through dropout, a popular technique to avoid overfitting in deep learning.",abstractText,[0],[0]
"For single hidden-layer linear neural networks, we show that dropout tends to make the norm of incoming/outgoing weight vectors of all the hidden nodes equal.",abstractText,[0],[0]
"In addition, we provide a complete characterization of the optimization landscape induced by dropout.",abstractText,[0],[0]
On the Implicit Bias of Dropout,title,[0],[0]
"Generative Adversarial Networks (GANs) have recently been proposed as a novel framework for learning generative models (Goodfellow et al., 2014).",1. Introduction,[0],[0]
"In a nutshell, the key idea of GANs is to learn both the generative model and the loss function at the same time.",1. Introduction,[0],[0]
The resulting training dynamics are usually described as a game between a generator (the generative model) and a discriminator (the loss function).,1. Introduction,[0],[0]
"The goal of the generator is to produce realistic samples that fool the discriminator, while the discriminator is trained to distinguish between the true training data and samples from the generator.",1. Introduction,[0],[0]
"GANs have shown promising results on a variety of tasks, and there is now a large body of work that explores the power of this framework (Goodfellow, 2017).
",1. Introduction,[0],[0]
"Unfortunately, reliably training GANs is a challenging prob1MIT.",1. Introduction,[0],[0]
"Correspondence to: Jerry Li <jerryzli@mit.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
lem that often hinders further research and applicability in this area.",1. Introduction,[0],[0]
"Practitioners have encountered a variety of obstacles in this context such as vanishing gradients, mode collapse, and diverging or oscillatory behavior (Goodfellow, 2017).",1. Introduction,[0],[0]
"At the same time, the theoretical underpinnings of GAN dynamics are not yet well understood.",1. Introduction,[0],[0]
"To date, there were no convergence proofs for GAN models, even in very simple settings.",1. Introduction,[0],[0]
"As a result, the root cause of frequent failures of GAN dynamics in practice remains unclear.
",1. Introduction,[0],[0]
"In this paper, we take a first step towards a principled understanding of GAN dynamics.",1. Introduction,[0],[0]
Our general methodology is to propose and examine a problem setup that exhibits all common failure cases of GAN dynamics while remaining sufficiently simple to allow for a rigorous analysis.,1. Introduction,[0],[0]
"Concretely, we introduce and study the GMM-GAN: a variant of GAN dynamics that captures learning a mixture of two univariate Gaussians.",1. Introduction,[0],[0]
We first show experimentally that standard gradient dynamics of the GMM-GAN often fail to converge due to mode collapse or oscillatory behavior.,1. Introduction,[0],[0]
"Interestingly, this also holds for techniques that were recently proposed to improve GAN training such as unrolled GANs (Metz et al., 2017).",1. Introduction,[0],[0]
"In contrast, we then show that GAN dynamics with an optimal discriminator do converge, both experimentally and provably.",1. Introduction,[0],[0]
"To the best of our knowledge, our theoretical analysis of the GMM-GAN is the first global convergence proof for parametric and non-trivial GAN dynamics.
",1. Introduction,[0],[0]
Our results show a clear dichotomy between the dynamics arising from applying simultaneous gradient descent and the one that is able to use an optimal discriminator.,1. Introduction,[0],[0]
The GAN with optimal discriminator provably converges from (essentially) any starting point.,1. Introduction,[0],[0]
"On the other hand, the simultaneous gradient GAN empirically often fails to converge, even when the discriminator is allowed many more gradient steps than the generator.",1. Introduction,[0],[0]
These findings go against the common wisdom that first order methods are sufficiently strong for all deep learning applications.,1. Introduction,[0],[0]
"By carefully inspecting our models, we are able to pinpoint some of the causes of this, and we highlight a phenomena we call discriminator collapse which often causes first order methods to fail in our setting.",1. Introduction,[0],[0]
"Generative adversarial networks are commonly described as a two player game (Goodfellow et al., 2014).",2. Generative Adversarial Dynamics,[0],[0]
"Given a true distribution P , a set of generators G = {Gu, u 2 U}, a set of discriminators D = {Dv, v 2 V}, and a monotone measuring function m : R !",2. Generative Adversarial Dynamics,[0],[0]
"R, the objective of GAN training is to find a generator u in
argmin u2U max v2V Ex⇠P [m(Dv(x))]+Ex⇠Gu [m(1 Dv(x))] .",2. Generative Adversarial Dynamics,[0],[0]
"(1) In other words, the game is between two players called the generator and discriminator, respectively.",2. Generative Adversarial Dynamics,[0],[0]
The goal of the discriminator is to distinguish between samples from the generator and the true distribution.,2. Generative Adversarial Dynamics,[0],[0]
"The goal of the generator is to fool the discriminator by generating samples that are similar to the data distribution.
",2. Generative Adversarial Dynamics,[0],[0]
"By varying the choice of the measuring function and the set of discriminators, one can capture a wide variety of loss functions.",2. Generative Adversarial Dynamics,[0],[0]
"Typical choices that have been previously studied include the KL divergence and the Wasserstein distance (Goodfellow et al., 2014; Arjovsky et al., 2017).",2. Generative Adversarial Dynamics,[0],[0]
"This formulation can also encode other common objectives: most notably, as we will show, the total variation distance.
",2. Generative Adversarial Dynamics,[0],[0]
"To optimize the objective (1), the most common approaches are variants of simultaneous gradient descent on the generator u and the discriminator v.",2. Generative Adversarial Dynamics,[0],[0]
"But despite its attractive theoretical grounding, GAN training is plagued by a variety of issues in practice.",2. Generative Adversarial Dynamics,[0],[0]
Two major problems are mode collapse and vanishing gradients.,2. Generative Adversarial Dynamics,[0],[0]
"Mode collapse corresponds to situations in which the generator only learns a subset (a few modes) of the true distribution P (Goodfellow, 2017; Arora & Zhang, 2018).",2. Generative Adversarial Dynamics,[0],[0]
"For instance, a GAN trained on an image modeling task would only produce variations of a small number of images.",2. Generative Adversarial Dynamics,[0],[0]
"Vanishing gradients (Arjovsky et al., 2017; Arjovsky & Bottou, 2017; Arora et al., 2017) are, on the other hand, a failure case where the generator updates become vanishingly small, thus making the GAN dynamics not converge to a satisfying solution.",2. Generative Adversarial Dynamics,[0],[0]
"Despite many proposed explanations and approaches to solve the vanishing gradient problem, it is still often observed in practice (Goodfellow, 2017).",2. Generative Adversarial Dynamics,[0],[0]
GANs provide a powerful framework for generative modeling.,2.1. Towards a principled understanding of GAN dynamics,[0],[0]
"However, there is a large gap between the theory and practice of GANs.",2.1. Towards a principled understanding of GAN dynamics,[0],[0]
"Specifically, to the best of the authors’ knowledge, all theoretical studies of GAN dynamics for parametric models simply consider global optima and stationary points of the dynamics, and there has been no rigorous study of the actual GAN dynamics.",2.1. Towards a principled understanding of GAN dynamics,[0],[0]
"In practice, GANs are always optimized using first order methods, and
the current theory of GANs cannot tell us whether or not these methods converge to a meaningful solution.",2.1. Towards a principled understanding of GAN dynamics,[0],[0]
"This raises a natural question, also posed as an open problem in (Goodfellow, 2017):
Our theoretical understanding of GANs is still fairly poor.",2.1. Towards a principled understanding of GAN dynamics,[0],[0]
"In particular, to the best of the authors’ knowledge, all existing analyzes of GAN dynamics for parametric models simply consider global optima and stationary points of the dynamics.",2.1. Towards a principled understanding of GAN dynamics,[0],[0]
"There has been no rigorous study of the actual GAN dynamics, except studying it in the immediate neighborhood of such stationary points (Nagarajan & Kolter, 2017).",2.1. Towards a principled understanding of GAN dynamics,[0],[0]
"This raises a natural question:
Can we understand the convergence behavior of GANs?
",2.1. Towards a principled understanding of GAN dynamics,[0],[0]
This question is difficult to tackle for many reasons.,2.1. Towards a principled understanding of GAN dynamics,[0],[0]
"One of them is the non-convexity of the GAN objective/loss function, and of the generator and discriminator sets.",2.1. Towards a principled understanding of GAN dynamics,[0],[0]
"Another one is that, in practice, GANs are always optimized using first order methods.",2.1. Towards a principled understanding of GAN dynamics,[0],[0]
"That is, instead of following the “ideal” dynamics that has both the generator and discriminator always perform the optimal update, we just approximate such updates by a sequence of gradient steps.",2.1. Towards a principled understanding of GAN dynamics,[0],[0]
"This is motivated by the fact that computing such optimal updates is, in general, algorithmically intractable, and adds an additional layer of complexity to the problem.
",2.1. Towards a principled understanding of GAN dynamics,[0],[0]
"In this paper, we want to change this state of affairs and initiate the study of GAN dynamics from an algorithmic perspective.",2.1. Towards a principled understanding of GAN dynamics,[0],[0]
"Specifically, we pursue the following question:
What is the impact of using first order approximation on the convergence of GAN dynamics?
",2.1. Towards a principled understanding of GAN dynamics,[0],[0]
"Concretely, we focus on analyzing the difference between two GAN dynamics: a “first order” dynamics, in which both the generator and discriminator use first order updates; and an “optimal discriminator” dynamics, in which only the generator uses first order updates but the discriminator always makes an optimal update.",2.1. Towards a principled understanding of GAN dynamics,[0],[0]
"Even the latter, simpler dynamics has proven to be challenging to understand.",2.1. Towards a principled understanding of GAN dynamics,[0],[0]
Even the question of whether using the optimal discriminator updates is the right approach has already received considerable attention.,2.1. Towards a principled understanding of GAN dynamics,[0],[0]
"In particular, (Arjovsky & Bottou, 2017) present theoretical evidence that using the optimal discriminator at each step may not be desirable in certain settings (although these settings are very different to the one we consider in this paper).
",2.1. Towards a principled understanding of GAN dynamics,[0],[0]
"We approach our goal by defining a simple GAN model whose dynamics, on one hand, captures many of the difficulties of real-world GANs but, on the other hand, is still simple enough to make analysis possible.",2.1. Towards a principled understanding of GAN dynamics,[0],[0]
We then rigorously study our questions in the context of this model.,2.1. Towards a principled understanding of GAN dynamics,[0],[0]
Our intention is to make the resulting understanding be the first step towards crystallizing a more general picture.,2.1. Towards a principled understanding of GAN dynamics,[0],[0]
Perhaps a tempting starting place for coming up with a simple but meaningful set of GAN dynamics is to consider the generators being univariate Gaussians with fixed variance.,3. A Simple Model for Studying GAN Dynamics,[0],[0]
"Indeed, in the supplementary material we give a short proof that simple GAN dynamics always converge for this class of generators.",3. A Simple Model for Studying GAN Dynamics,[0],[0]
"However, it seems that this class of distributions is insufficiently expressive to exhibit many of the phenomena such as mode collapse mentioned above.",3. A Simple Model for Studying GAN Dynamics,[0],[0]
"In particular, the distributions in this class are all unimodal, and it is unclear what mode collapse would even mean in this context.
",3. A Simple Model for Studying GAN Dynamics,[0],[0]
Generators.,3. A Simple Model for Studying GAN Dynamics,[0],[0]
The above considerations motivate us to make our model slightly more complicated.,3. A Simple Model for Studying GAN Dynamics,[0],[0]
"We assume that the true distribution and the generator distributions are all mixtures of two univariate Gaussians with unit variance, and uniform mixing weights.",3. A Simple Model for Studying GAN Dynamics,[0],[0]
"Formally, our generator set is G, where
G = ⇢ 1
2 N (µ1, 1) +
1 2 N (µ2, 1) | µ1, µ2 2 R .",3. A Simple Model for Studying GAN Dynamics,[0],[0]
"(2)
For any µ 2 R2, we let Gµ(x) denote the distribution in G with means at µ1 and µ2.",3. A Simple Model for Studying GAN Dynamics,[0],[0]
"While this is a simple change compared to a single Gaussian case, it makes a large difference in the behavior of the dynamics.",3. A Simple Model for Studying GAN Dynamics,[0],[0]
"In particular, many of the pathologies present in real-world GAN training begin to appear.
",3. A Simple Model for Studying GAN Dynamics,[0],[0]
Loss function.,3. A Simple Model for Studying GAN Dynamics,[0],[0]
"While GANs are usually viewed as a generative framework, they can also be viewed as a general method for density estimation.",3. A Simple Model for Studying GAN Dynamics,[0],[0]
We want to set up learning an unknown generator,3. A Simple Model for Studying GAN Dynamics,[0],[0]
Gµ⇤ 2 G as a generative adversarial dynamics.,3. A Simple Model for Studying GAN Dynamics,[0],[0]
"To this end, we must first define the loss function for the density estimation problem.",3. A Simple Model for Studying GAN Dynamics,[0],[0]
"A well-studied goal in this setting is to recover Gµ⇤(x) in total variation (also known as L1 or statistical) distance, where the total variation distance between two distributions P,Q is defined as
dTV(P,Q) = 1
2
Z
⌦ |P (x) Q(x)|dx = max A P (A) Q(A) ,
(3) where the maximum is taken over all measurable events A.
",3. A Simple Model for Studying GAN Dynamics,[0],[0]
Such finding the best-fit distribution in total variation distance can indeed be naturally phrased as generative adversarial dynamics.,3. A Simple Model for Studying GAN Dynamics,[0],[0]
"Unfortunately, for arbitrary distributions, this is algorithmically problematic, simply because the set of discriminators one would need is intractable to optimize over.
",3. A Simple Model for Studying GAN Dynamics,[0],[0]
"However, for distributions that are structurally simple, like mixtures of Gaussians, it turns out we can consider a much
simpler set of discriminators.",3. A Simple Model for Studying GAN Dynamics,[0],[0]
"In Appendix A.1 in the supplementary material, motivated by connections to VC theory, we show that for two generators Gµ1 , Gµ2 2 G, we have
dTV(Gµ1 , Gµ2) = max E=I1[I2 Gµ1(E) Gµ2(E) , (4)
where the maxima is taken over two disjoint intervals I1, I2 ✓ R. In other words, instead of considering the difference of measure between the two generators Gµ1 , Gµ2 on arbitrary events, we may restrict our attention to unions of two disjoint intervals in R. This is a special case of a well-studied distance measure known as the Ak-distance, for k = 2 (Devroye & Lugosi, 2012; Chan et al., 2014).",3. A Simple Model for Studying GAN Dynamics,[0],[0]
"Moreover, this class of subsets has a simple parametric description.
Discriminators.",3. A Simple Model for Studying GAN Dynamics,[0],[0]
"Now, the above discussion motivates our definition of discriminators to be
D = {I[`1,r1] + I[`2,r2]",3. A Simple Model for Studying GAN Dynamics,[0],[0]
"|`, r 2 R 2 s.t. `1  r1  `2  r2} .
(5)
In other words, the set of discriminators is taken to be the set of indicator functions of sets which can be expressed as a union of at most two disjoint intervals.",3. A Simple Model for Studying GAN Dynamics,[0],[0]
"With this definition, finding the best fit in total variation distance to some unknown Gµ⇤ 2 G is equivalent to finding bµ minimizing
bµ = argmin µ max `,r L(µ, `, r) , where
L(µ, `, r) =",3. A Simple Model for Studying GAN Dynamics,[0],[0]
Ex⇠Gµ⇤ [D(x)],3. A Simple Model for Studying GAN Dynamics,[0],[0]
+ Ex⇠Gµ [1 D(x)],3. A Simple Model for Studying GAN Dynamics,[0],[0]
"(6)
is a smooth function of all three parameters (see the supplementary material for details).
",3. A Simple Model for Studying GAN Dynamics,[0],[0]
Dynamics.,3. A Simple Model for Studying GAN Dynamics,[0],[0]
The objective in (6) is easily amenable to optimization at parameter level.,3. A Simple Model for Studying GAN Dynamics,[0],[0]
"A natural approach for optimizing this function would be to define G(bµ) = max`,r L(bµ, `, r), and to perform (stochastic) gradient descent on this function.",3. A Simple Model for Studying GAN Dynamics,[0],[0]
"This corresponds to, at each step, finding the the optimal discriminator, and updating the current bµ in that direction.",3. A Simple Model for Studying GAN Dynamics,[0],[0]
We call these dynamics the optimal discriminator dynamics.,3. A Simple Model for Studying GAN Dynamics,[0],[0]
"Formally, given bµ(0) and a stepsize ⌘g, and a true distribution Gµ⇤ 2 G, the optimal discriminator dynamics for Gµ⇤ ,G,D starting at bµ(0) are given iteratively as
`(t), r(t) =",3. A Simple Model for Studying GAN Dynamics,[0],[0]
"argmax `,r L(bµ(t), `, r) , (7)
bµ(t+1) = bµ(t) ⌘grµL(bµ(t), `(t), r(t)) , (8)
where the maximum is taken over `, r which induce two disjoint intervals.
",3. A Simple Model for Studying GAN Dynamics,[0],[0]
"For more complicated generators and discriminators such as neural networks, these dynamics are computationally
difficult to perform.",3. A Simple Model for Studying GAN Dynamics,[0],[0]
"Therefore, instead of the updates as in (8), one resorts to simultaneous gradient iterations on the generator and discriminator.",3. A Simple Model for Studying GAN Dynamics,[0],[0]
These dynamics are called the first order dynamics.,3. A Simple Model for Studying GAN Dynamics,[0],[0]
"Formally, given bµ(0), `(0), r(0) and a stepsize ⌘g, ⌘d, and a true distribution Gµ⇤ 2 G, the first order dynamics for Gµ⇤ ,G,D starting at bµ(0) are specified as
bµ(t+1) = bµ(t) ⌘grµL(bµ(t), `(t), r(t)) (9) r(t+1) = r(t) +",3. A Simple Model for Studying GAN Dynamics,[0],[0]
"⌘drrL(bµ(t), `(t), r(t))",3. A Simple Model for Studying GAN Dynamics,[0],[0]
"(10) `(t+1) = `(t) + ⌘dr`L(bµ(t), `(t), r(t)) .",3. A Simple Model for Studying GAN Dynamics,[0],[0]
"(11)
Even for our relatively simple setting, the first order dynamics can exhibit a variety of behaviors, depending on the starting conditions of the generators and discriminators.",3. A Simple Model for Studying GAN Dynamics,[0],[0]
"In particular, in Figure 1, we see that depending on the initialization, the dynamics can either converge to optimality, exhibit a primitive form of mode collapse, where the two generators collapse into a single generator, or converge to the wrong value, because the gradients vanish.",3. A Simple Model for Studying GAN Dynamics,[0],[0]
"This provides empirical justification for our model, and shows that these dynamics are complicated enough to model the complex behaviors which real-world GANs exhibit.",3. A Simple Model for Studying GAN Dynamics,[0],[0]
"Moreover, as we show in Section 5 below, these behaviors are not just due to very specific pathological initial conditions: indeed, when given random initial conditions, the first order dynamics still more often than not fail to converge.
",3. A Simple Model for Studying GAN Dynamics,[0],[0]
Parametrization We note here that there could be several potential GAN dynamics to consider here.,3. A Simple Model for Studying GAN Dynamics,[0],[0]
Each one resulting from slightly different parametrization of the total variation distance.,3. A Simple Model for Studying GAN Dynamics,[0],[0]
"For instance, a completely equivalent way to define the total variation distance is
dTV(P,Q) = max",3. A Simple Model for Studying GAN Dynamics,[0],[0]
"A
|P",3. A Simple Model for Studying GAN Dynamics,[0],[0]
"(A) Q(A)| , (12)
which does not change the value of the variational distance, but does change the induced dynamics.",3. A Simple Model for Studying GAN Dynamics,[0],[0]
"We do not focus on these induced dynamics in this paper since they do not exactly fit within the traditional GAN framework, i.e. it is not of the form (1) (see Appendix B).",3. A Simple Model for Studying GAN Dynamics,[0],[0]
"Nevertheless, it is an interesting set of dynamics and it is a natural question whether similar phenomena occur in these dynamics.",3. A Simple Model for Studying GAN Dynamics,[0],[0]
"In Appendix B, we show the the optimal discriminator dynamics are unchanged, and the induced first order dynamics have qualitatively similar behavior to the ones we consider in this paper.",3. A Simple Model for Studying GAN Dynamics,[0],[0]
This also suggests that the phenomena we exhibit might be more fundamental.,3. A Simple Model for Studying GAN Dynamics,[0],[0]
We now describe our results in more detail.,4. Optimal Discriminator vs. First Order Dynamics,[0],[0]
We first consider the dynamics induced by the optimal discriminator.,4. Optimal Discriminator vs. First Order Dynamics,[0],[0]
"Our
main theoretical result is1:
Theorem 4.1.",4. Optimal Discriminator vs. First Order Dynamics,[0],[0]
Fix > 0,4. Optimal Discriminator vs. First Order Dynamics,[0],[0]
sufficiently small and C > 0.,4. Optimal Discriminator vs. First Order Dynamics,[0],[0]
"Let µ⇤ 2 R2 so that |µ⇤i |  C, and |µ⇤1 µ⇤2| .",4. Optimal Discriminator vs. First Order Dynamics,[0],[0]
"Then, for all initial points bµ(0) so that |bµ(0)i |  C for all i and so that |bµ(0)1 bµ (0) 2 | , if we let ⌘ = poly(1/ , e C 2
) and T = poly(1/ , e C 2
), then if bµ(T ) is specified by the optimal discriminator dynamics, we have dTV(Gµ⇤ , Gbµ(T ))  .
",4. Optimal Discriminator vs. First Order Dynamics,[0],[0]
"In other words, if the µ⇤ are bounded by a constant, and not too close together, then in time which is polynomial in the inverse of the desired accuracy and e C 2
, where C is a bound on how far apart the µ⇤ and bµ are, the optimal discriminator dynamics converge to the ground truth in total variation distance.",4. Optimal Discriminator vs. First Order Dynamics,[0],[0]
"Note that the dependence on e C 2
is necessary, as if the bµ and µ⇤ are initially very far apart, then the initial gradients for the bµ will necessarily be of this scale as well.
",4. Optimal Discriminator vs. First Order Dynamics,[0],[0]
"On the other hand, we provide simulation results that demonstrate that first order updates, or more complicated heuristics such as unrolling, all fail to consistently converge to the true distribution, even under the same sorts of conditions as in Theorem 4.1.",4. Optimal Discriminator vs. First Order Dynamics,[0],[0]
"In Figure 1, we gave some specific examples where the first order dynamics fail to converge.",4. Optimal Discriminator vs. First Order Dynamics,[0],[0]
"In Section 5 we show that this sort of divergence is common, even with random initializations for the discriminators.",4. Optimal Discriminator vs. First Order Dynamics,[0],[0]
"In particular, the probability of convergence is generally much lower than 1, for both the regular GAN dynamics, and unrolling.",4. Optimal Discriminator vs. First Order Dynamics,[0],[0]
"In general, we believe that this phenomena should occur for any natural first order dynamics for the generator.",4. Optimal Discriminator vs. First Order Dynamics,[0],[0]
"In particular, one barrier we observed for any such dynamics is something we call discriminator collapse, that we describe in Section 6.",4. Optimal Discriminator vs. First Order Dynamics,[0],[0]
"We do not provide a proof of convergence for the first order dynamics, but we remark that in light of our simulation results, this is simply because the first order dynamics do not converge.",4. Optimal Discriminator vs. First Order Dynamics,[0],[0]
We provide now a high level overview of the proof of Theorem 4.1.,4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
The key element we will need in our proof is the ability to quantify the progress our updates make on converging towards the optimal solution.,4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
This is particularly challenging as our objective function is neither convex nor smooth.,4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
The following lemma is our main tool for achieving that.,4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
"Roughly stated, it says that for any Lipschitz function,
1We actually analyze a minor variation on the optimal discriminator dynamics.",4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
"In particular, we do not rule out the existence of a measure zero set on which the dynamics are ill-behaved.",4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
"Thus, we will analyze the optimal discriminator dynamics after adding an arbitrarily small amount of Gaussian noise.",4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
"It is clear that by taking this noise to be sufficiently small (say exponentially small) then we avoid this pathological set with probability 1, and moreover the noise does not otherwise affect the convergence analysis at all.",4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
"For simplicity, we will ignore this issue for the rest of the paper.
",4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
"even if it is non-convex and non-smooth, as long as the change in its derivative is smaller in magnitude than the value of the derivative, gradient descent makes progress on the function value.",4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
"Note that this condition is much weaker than typical assumptions used to analyze gradient descent.
",4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
Lemma 4.2.,4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
Let g :,4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
Rk !,4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
R be a Lipschitz function that is differentiable at some fixed x 2 Rk.,4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
"For some ⌘ > 0, let x0 = x ⌘rf(x).",4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
"Suppose there exists c < 1 so that almost all v 2 L(x, x0), where L(x, y) denotes the line between x and y, g is differentiable, and moreover, we have krg(x) rg(v)k2  ckrg(x)k2.",4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
"Then g(x0) g(x)  ⌘(1 c)krg(x)k22 .
",4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
"Here, we will use the convention that µ⇤1  µ⇤2, and during the analysis, we will always assume for simplicity of notation that bµ1  bµ2.",4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
"Also, in what follows, let f(bµ) = fµ⇤(bµ) = dTV(Gbµ, Gµ⇤) and F (bµ, x) =",4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
"Gµ⇤(x) Gbµ(x) be the objective function and the difference of the PDFs between the true distribution and the generator, respectively.
",4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
"For any > 0, define the sets
Rect( ) = {bµ : |bµi µ⇤j | < for some i, j} Opt( ) = {bµ : |bµi µ⇤i | < for all i} .
to be the set of parameter values which have at least one
parameter which is not too far from optimality, and the set of parameter values so that all parameter values are close.",4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
"We also let B(C) denote the box of sidelength C around the origin, and we let Sep( ) = {v 2 R2 : |v1 v2| > } be the set of parameter vectors which are not too close together.
",4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
Our main work lies within a set of lemmas which allow us to instantiate the bounds in Lemma 4.2.,4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
"We first show a pair of lemmas which show that, explicitly excluding bad cases such as mode collapse, our dynamics satisfy the conditions of Lemma 4.2.",4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
"We do so by establishing a strong (in fact, nearly constant) lower bound on the gradient when we are fairly away from optimality (Lemma 4.3).",4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
"Then, we show a relatively weak bound on the smoothness of the function (Lemma 4.4), but which is sufficiently strong in combination with Lemma 4.3 to satisfy Lemma 4.2.",4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
"Finally, we rule out the pathological cases we explicitly excluded earlier, such as mode collapse or divergent behavior (Lemmas 4.5 and 4.6).",4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
Putting all these together appropriately yields the desired statement.,4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
Our first lemma is a lower bound on the gradient value: Lemma 4.3.,4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
Fix C 1 > 0.,4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
"Suppose bµ 62 Rect(0), and suppose µ⇤, bµ 2 B(C) and µ⇤ 2 Sep( ), bµ 2 Sep( ).",4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
"There is some K = ⌦(1) · ( e C2/C)O(1) so that krfµ⇤(bµ)k2 K.
The above lemma statement is slightly surprising at first glance.",4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
"It says that the gradient is never 0, which would suggest there are no local optima at all.",4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
"To reconcile this, one should note that the gradient is not continuous (defined) everywhere.
",4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
The second lemma states a bound on the smoothness of the function: Lemma 4.4.,4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
Fix C 1 and > 0,4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
so that is sufficiently small.,4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
"Let µ⇤, bµ, bµ0 be such that L(bµ, bµ0)\Opt( ) = ?, µ⇤ 2 Sep( ), bµ0, bµ 2 Sep( ), and µ⇤, bµ, bµ0 2 B(C).",4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
Let K = ⌦(1) · ( e C2/C)O(1) be the K for which Lemma 4.3 holds with those parameters.,4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
"If we have kbµ0 bµk2  ⌦(1) ·( e C 2
/C)O(1) for appropriate choices of constants on the RHS, we get
krfµ⇤(bµ0) rfµ⇤(bµ)k2  K/2  ",4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
"krfµ⇤(bµ)k2/2.
",4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
"These two lemmas almost suffice to prove progress as in Lemma 4.2, however, there is a major caveat.",4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
"Specifically, Lemma 4.4 needs to assume that bµ and bµ0 are sufficiently well-separated, and that they are bounded.",4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
"While the bµi start out separated and bounded, it is not clear that it does not mode collapse or diverge off to infinity.",4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
"However, we are able to rule these sorts of behaviors out.",4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
Formally: Lemma 4.5 (No mode collapse).,4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
"Fix > 0, and let be sufficiently small.",4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
Let ⌘  /C for some C large.,4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
Suppose µ⇤ 2 Sep( ).,4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
"Then, if bµ 2 Sep( ), and bµ0 = bµ ⌘rfµ⇤(bµ), we have bµ0 2 Sep( ).
",4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
Lemma 4.6 (No diverging to infinity).,4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
"Let C > 0 be sufficiently large, and let ⌘ > 0 be sufficiently small.",4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
"Suppose µ⇤ 2 B(C), and bµ 2 B(2C).",4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
"Then, if we let bµ0 =",4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
"bµ ⌘rfµ⇤(bµ), then bµ0 2 B(2C).
",4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
"Together, these four lemmas together suffice to prove Theorem 4.1 by setting parameters appropriately.",4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
We refer the reader to the supplementary material for more details including the proofs.,4.1. Analyzing the Optimal Discriminator Dynamics,[0],[0]
"To illustrate more conclusively that the phenomena demonstrated in Figure 1 are not particularly rare, and that first order dynamics do often fail to converge, we also conducted the following heatmap experiments.",5. Experiments,[0],[0]
"We set µ⇤ = ( 0.5, 0.5) as in Figure 1.",5. Experiments,[0],[0]
"We then set a grid for the bµ, so that each coordinate is allowed to vary from 1 to 1.",5. Experiments,[0],[0]
"For each of these grid points, we randomly chose a set of initial discriminator intervals, and ran the first order dynamics for 3000 iterations, with constant stepsize 0.3.",5. Experiments,[0],[0]
"We then repeated this 120 times for each grid point, and plotted the probability that the generator converged to the truth, where we say the generator converged to the truth if the TV distance between the generator and optimality is < 0.1.",5. Experiments,[0],[0]
"The choice of these parameters was somewhat arbitrary, however, we did not observe any qualitative difference in the results by varying these numbers, and so we only report results for these parameters.",5. Experiments,[0],[0]
"We also did the same thing for the optimal discriminator dynamics, and for unrolled discriminator dynamics with 5 unrolling steps, as described in (Metz et al., 2017), which attempt to match the optimal discriminator dynamics.
",5. Experiments,[0],[0]
The results of the experiment are given in Figure 2.,5. Experiments,[0],[0]
We see that all three methods fail when we initialize the two generator means to be the same.,5. Experiments,[0],[0]
"This makes sense, since in that regime, the generator starts out mode collapsed and it is impossible for it to un-“mode collapse”, so it cannot fit the true distribution well.",5. Experiments,[0],[0]
"Ignoring this pathology, we see that the optimal discriminator otherwise always converges to the ground truth, as our theory predicts.",5. Experiments,[0],[0]
"On the other hand, both regular first order dynamics and unrolled dynamics often times fail, although unrolled dynamics do succeed more often than regular first order dynamics.",5. Experiments,[0],[0]
"This suggests that the pathologies in Figure 1 are not so rare, and that these first order methods are quite often unable to emulate optimal discriminator dynamics.",5. Experiments,[0],[0]
"As discussed above, our simple GAN dynamics are able to capture the same undesired behaviors that more sophisticated GANs exhibit.",6. Why do first order methods get stuck?,[0],[0]
"In addition to these behaviors, our dynamics enables us to discern another degenerate behavior
which does not seem to have previously been observed in the literature.",6. Why do first order methods get stuck?,[0],[0]
We call this behavior discriminator collapse.,6. Why do first order methods get stuck?,[0],[0]
"At a high level, this phenomenon is when the local optimization landscape around the current discriminator encourages it to make updates which decrease its representational power.",6. Why do first order methods get stuck?,[0],[0]
"We view understanding the exact nature of discriminator collapse in more general settings and interesting research problem to explore further.
",6. Why do first order methods get stuck?,[0],[0]
We explain this phenomenon using language specific to our GMM-GAN dynamics.,6. Why do first order methods get stuck?,[0],[0]
"In our dynamics, discriminator collapse occurs when a discriminator interval which originally had finite width is forced by the dynamics to have its width converge to 0.",6. Why do first order methods get stuck?,[0],[0]
This happens whenever this interval lies entirely in a region where the generator PDF is much larger than the discriminator PDF.,6. Why do first order methods get stuck?,[0],[0]
"We will shortly argue why this
is undesirable.
",6. Why do first order methods get stuck?,[0],[0]
"In Figure 3, we show an example of discriminator collapse in our dynamics.",6. Why do first order methods get stuck?,[0],[0]
"Each plot in the figure shows the true PDF minus the PDF of the generators, where the regions covered by the discriminator are shaded.",6. Why do first order methods get stuck?,[0],[0]
Plot (a) shows the initial configuration of our example.,6. Why do first order methods get stuck?,[0],[0]
Notice that the leftmost discriminator interval lies entirely in a region for which the true PDF minus the generators’ PDF is negative.,6. Why do first order methods get stuck?,[0],[0]
"Since the discriminator is incentivized to only have mass on regions where the difference is positive, the first order dynamics will cause the discriminator interval to collapse to have length zero if it is in a negative region.",6. Why do first order methods get stuck?,[0],[0]
We see in Plot (c) that this discriminator collapses if we run many discriminator steps for this fixed generator.,6. Why do first order methods get stuck?,[0],[0]
"In particular, these steps do not converge to the globally optimal discriminator shown in
Plot (b).
",6. Why do first order methods get stuck?,[0],[0]
This collapse also occurs when we run the dynamics.,6. Why do first order methods get stuck?,[0],[0]
"In Plots (d) and (e), we see that after running the first order dynamics – or even unrolled dynamics – for many iterations, eventually both discriminators collapse.",6. Why do first order methods get stuck?,[0],[0]
"When a discriminator interval has length zero, it can never uncollapse, and moreover, its contribution to the gradient of the generator is zero.",6. Why do first order methods get stuck?,[0],[0]
Thus these dynamics will never converge to the ground truth.,6. Why do first order methods get stuck?,[0],[0]
"GANs have received a tremendous amount of attention over the past two years (Goodfellow, 2017).",7. Related Work,[0],[0]
"Hence we only compare our results to the most closely related papers here.
",7. Related Work,[0],[0]
"The recent paper (Arora et al., 2017) studies generalization aspects of GANs and the existence of equilibria in the two-player game.",7. Related Work,[0],[0]
"In contrast, our paper focuses on the dynamics of GAN training.",7. Related Work,[0],[0]
"We provide the first rigorous proof of global convergence and show that a GAN with an optimal discriminator always converges to an approximate equilibrium.
",7. Related Work,[0],[0]
"One recently proposed method for improving the convergence of GAN dynamics is the unrolled GAN (Metz et al., 2017).",7. Related Work,[0],[0]
The paper proposes to “unroll” multiple discriminator gradient steps in the generator loss function.,7. Related Work,[0],[0]
The authors argue that this improves the GAN dynamics by bringing the discriminator closer to an optimal discriminator response.,7. Related Work,[0],[0]
"Our experiments show that this is not a perfect approximation: the unrolled GAN still fails to converge in multiple initial configurations (however, it does converge more often than a “vanilla” one-step discriminator).
",7. Related Work,[0],[0]
"The authors of (Arjovsky & Bottou, 2017) also take a theoretical view on GANs.",7. Related Work,[0],[0]
"They identify two important properties of GAN dynamics: (i) Absolute continuity of the population distribution, and (ii) overlapping support between the population and generator distribution.",7. Related Work,[0],[0]
"If these conditions do not hold, they show that the GAN dynamics fail to converge in some settings.",7. Related Work,[0],[0]
"However, they do not prove that the GAN dynamics do converge under such assumptions.",7. Related Work,[0],[0]
We take a complementary view: we give a convergence proof for a concrete GAN dynamics.,7. Related Work,[0],[0]
"Moreover, our model shows that absolute continuity and support overlap are not the only important aspects in GAN dynamics: although our distributions clearly satisfy both of their conditions, the first-order dynamics still fail to converge.
",7. Related Work,[0],[0]
"The paper (Nagarajan & Kolter, 2017) studies the stability of equilibria in GAN training.",7. Related Work,[0],[0]
"In contrast to our work, the results focus on local stability while we establish global convergence results.",7. Related Work,[0],[0]
"Moreover, their theorems rely on fairly strong assumptions.",7. Related Work,[0],[0]
"While the authors give a concrete
model for which these assumptions are satisfied (the linear quadratic Gaussian GAN), the corresponding target and generator distributions are unimodal.",7. Related Work,[0],[0]
Hence this model cannot exhibit mode collapse.,7. Related Work,[0],[0]
"We propose the GMM-GAN specifically because it is rich enough to exhibit mode collapse.
",7. Related Work,[0],[0]
"The recent work (Grnarova et al., 2018) views GAN training through the lens of online learning.",7. Related Work,[0],[0]
The paper gives results for the game-theoretic minimax formulation based on results from online learning.,7. Related Work,[0],[0]
"The authors give results that go beyond the convex-concave setting, but do not address generalization questions.",7. Related Work,[0],[0]
"Moreover, their algorithm is not based on gradient descent (in contrast to essentially all practical GAN training) and relies on an oracle for minimizing the highly non-convex generator loss.",7. Related Work,[0],[0]
This viewpoint is complementary to our approach.,7. Related Work,[0],[0]
We establish results for learning the unknown distribution and analyze the commonly used gradient descent approach for learning GANs.,7. Related Work,[0],[0]
We haven taken a step towards a principled understanding of GAN dynamics.,8. Conclusions,[0],[0]
We define a simple yet rich model of GAN training and prove convergence of the corresponding dynamics.,8. Conclusions,[0],[0]
"To the best of our knowledge, our work is the first to establish global convergence guarantees for a parametric GAN.",8. Conclusions,[0],[0]
"We find an interesting dichotomy: If we take optimal discriminator steps, the training dynamics provably converge.",8. Conclusions,[0],[0]
"In contrast, we show experimentally that the dynamics often fail if we take first order discriminator steps.",8. Conclusions,[0],[0]
We believe that our results provide new insights into GAN training and point towards a rich algorithmic landscape to be explored in order to further understand GAN dynamics.,8. Conclusions,[0],[0]
"Jerry Li was supported by NSF Award CCF-1453261 (CAREER), CCF-1565235, a Google Faculty Research Award, and an NSF Graduate Research Fellowship.",Acknowledgements,[0],[0]
"Aleksander Mądry was supported in part by an Alfred P. Sloan Research Fellowship, a Google Research Award, and the NSF grant CCF-1553428.",Acknowledgements,[0],[0]
John Peebles was supported by the NSF Graduate Research Fellowship under Grant No. 1122374 and by the NSF Grant No. 1065125.,Acknowledgements,[0],[0]
Ludwig Schmidt was supported by a Google PhD Fellowship.,Acknowledgements,[0],[0]
"While Generative Adversarial Networks (GANs) have demonstrated promising performance on multiple vision tasks, their learning dynamics are not yet well understood, both in theory and in practice.",abstractText,[0],[0]
"To address this issue, we study GAN dynamics in a simple yet rich parametric model that exhibits several of the common problematic convergence behaviors such as vanishing gradients, mode collapse, and diverging or oscillatory behavior.",abstractText,[0],[0]
"In spite of the non-convex nature of our model, we are able to perform a rigorous theoretical analysis of its convergence behavior.",abstractText,[0],[0]
"Our analysis reveals an interesting dichotomy: a GAN with an optimal discriminator provably converges, while first order approximations of the discriminator steps lead to unstable GAN dynamics and mode collapse.",abstractText,[0],[0]
Our result suggests that using first order discriminator steps (the de-facto standard in most existing GAN setups) might be one of the factors that makes GAN training challenging in practice.,abstractText,[0],[0]
On the Limitations of First-Order Approximation in GAN Dynamics,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 778–788 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
778",text,[0],[0]
"Cross-lingual word representations enable us to reason about word meaning in multilingual contexts and facilitate cross-lingual transfer (Ruder et al., 2018).",1 Introduction,[0],[0]
"Early cross-lingual word embedding models relied on large amounts of parallel data (Klementiev et al., 2012; Mikolov et al., 2013a), but more recent approaches have tried to minimize the amount of supervision necessary (Vulić and Korhonen, 2016; Levy et al., 2017; Artetxe et al., 2017).",1 Introduction,[0],[0]
"Some researchers have even presented unsupervised methods that do not rely on any form
of cross-lingual supervision at all (Barone, 2016; Conneau et al., 2018; Zhang et al., 2017).
",1 Introduction,[0],[0]
"Unsupervised cross-lingual word embeddings hold promise to induce bilingual lexicons and machine translation models in the absence of dictionaries and translations (Barone, 2016; Zhang et al., 2017; Lample et al., 2018a), and would therefore be a major step toward machine translation to, from, or even between low-resource languages.
",1 Introduction,[0],[0]
"Unsupervised approaches to learning crosslingual word embeddings are based on the assumption that monolingual word embedding graphs are approximately isomorphic, that is, after removing a small set of vertices (words) (Mikolov et al., 2013b; Barone, 2016; Zhang et al., 2017; Conneau et al., 2018).",1 Introduction,[0],[0]
"In the words of Barone (2016):
. . .",1 Introduction,[0],[0]
"we hypothesize that, if languages are used to convey thematically similar information in similar contexts, these random processes should be approximately isomorphic between languages, and that this isomorphism can be learned from the statistics of the realizations of these processes, the monolingual corpora, in principle without any form of explicit alignment.
",1 Introduction,[0],[0]
"Our results indicate this assumption is not true in general, and that approaches based on this assumption have important limitations.
",1 Introduction,[0],[0]
Contributions We focus on the recent stateof-the-art unsupervised model of Conneau et al. (2018).1 Our contributions are: (a),1 Introduction,[0],[0]
"In §2, we show that the monolingual word embeddings used in Conneau et al. (2018) are not approximately isomorphic, using the VF2 algorithm (Cordella et al., 2001) and we therefore introduce a metric for quantifying the similarity of word embeddings, based on Laplacian eigenvalues.",1 Introduction,[0],[0]
"(b) In §3, we identify circumstances under which the unsupervised bilingual
1Our motivation for this is that Artetxe et al. (2017) use small dictionary seeds for supervision, and Barone (2016) seems to obtain worse performance than Conneau et al. (2018).",1 Introduction,[0],[0]
"Our results should extend to Barone (2016) and Zhang et al. (2017), which rely on very similar methodology.
dictionary induction (BDI) algorithm proposed in Conneau et al. (2018) does not lead to good performance.",1 Introduction,[0],[0]
"(c) We show that a simple trick, exploiting a weak supervision signal from words that are identical across languages, makes the algorithm much more robust.",1 Introduction,[0],[0]
"Our main finding is that the performance of unsupervised BDI depends heavily on all three factors: the language pair, the comparability of the monolingual corpora, and the parameters of the word embedding algorithms.",1 Introduction,[0],[0]
"As mentioned, recent work focused on unsupervised BDI assumes that monolingual word embedding spaces (or at least the subgraphs formed by the most frequent words) are approximately isomorphic.",2 How similar are embeddings across languages?,[0],[0]
"In this section, we show, by investigating the nearest neighbor graphs of word embedding spaces, that word embeddings are far from isomorphic.",2 How similar are embeddings across languages?,[0],[0]
We therefore introduce a method for computing the similarity of non-isomorphic graphs.,2 How similar are embeddings across languages?,[0],[0]
"In §4.7, we correlate our similarity metric with performance on unsupervised BDI.
",2 How similar are embeddings across languages?,[0],[0]
"Isomorphism To motivate our study, we first establish that word embeddings are far from graph isomorphic2—even for two closely re-
2Two graphs that contain the same number of graph vertices connected in the same way are said to be isomorphic.",2 How similar are embeddings across languages?,[0],[0]
"In the context of weighted graphs such as word embeddings, a
lated languages, English and German, and using embeddings induced from comparable corpora (Wikipedia) with the same hyper-parameters.
",2 How similar are embeddings across languages?,[0],[0]
"If we take the top k most frequent words in English, and the top k most frequent words in German, and build nearest neighbor graphs for English and German using the monolingual word embeddings used in Conneau et al. (2018), the graphs are of course very different.",2 How similar are embeddings across languages?,[0],[0]
"This is, among other things, due to German case and the fact that the translates into der, die, and das, but unsupervised alignment does not have access to this kind of information.",2 How similar are embeddings across languages?,[0],[0]
"Even if we consider the top k most frequent English words and their translations into German, the nearest neighbor graphs are not isomorphic.",2 How similar are embeddings across languages?,[0],[0]
"Figure 1a-b shows the nearest neighbor graphs of the top 10 most frequent English words on Wikipedia, and their German translations.
",2 How similar are embeddings across languages?,[0],[0]
"Word embeddings are particularly good at capturing relations between nouns, but even if we consider the top k most frequent English nouns and their translations, the graphs are not isomorphic; see Figure 1c-d. We take this as evidence that word embeddings are not approximately isomorphic across languages.",2 How similar are embeddings across languages?,[0],[0]
"We also ran graph isomorphism checks on 10 random samples of frequent English nouns and their translations into Spanish, and only in 1/10 of the samples were the corresponding nearest neighbor graphs isomorphic.
",2 How similar are embeddings across languages?,[0],[0]
"Eigenvector similarity Since the nearest neighbor graphs are not isomorphic, even for frequent translation pairs in neighboring languages, we want to quantify the potential for unsupervised BDI using a metric that captures varying degrees of graph similarity.",2 How similar are embeddings across languages?,[0],[0]
"Eigenvalues are compact representations of global properties of graphs, and we introduce a spectral metric based on Laplacian eigenvalues (Shigehalli and Shettar, 2011) that quantifies the extent to which the nearest neighbor graphs are isospectral.",2 How similar are embeddings across languages?,[0],[0]
"Note that (approximately) isospectral graphs need not be (approximately) isomorphic, but (approximately) isomorphic graphs are always (approximately) isospectral (Gordon et al., 1992).",2 How similar are embeddings across languages?,[0],[0]
"Let A1 and A2 be the adjacency matrices of the nearest neighbor graphs G1 and G2 of our two word embeddings, respectively.",2 How similar are embeddings across languages?,[0],[0]
"Let L1 = D1−A1 and L2 = D2−A2 be the Laplacians of the nearest neighbor graphs, where D1 and D2 are the corresponding diagonal matrices of degrees.",2 How similar are embeddings across languages?,[0],[0]
"We now
weak version of this is to require that the underlying nearest neighbor graphs for the most frequent k words are isomorphic.
",2 How similar are embeddings across languages?,[0],[0]
"compute the eigensimilarity of the Laplacians of the nearest neighbor graphs, L1 and L2.",2 How similar are embeddings across languages?,[0],[0]
"For each graph, we find the smallest k such that the sum of the k largest Laplacian eigenvalues is <90% of the Laplacian eigenvalues.",2 How similar are embeddings across languages?,[0],[0]
"We take the smallest k of the two, and use the sum of the squared differences between the largest k Laplacian eigenvalues ∆ as our similarity metric.
∆ = k∑ i=1",2 How similar are embeddings across languages?,[0],[0]
"(λ1i − λ2i)2
where k is chosen s.t.
min j { ∑k i=1 λji∑n i=1",2 How similar are embeddings across languages?,[0],[0]
"λji > 0.9}
Note that ∆ = 0 means the graphs are isospectral, and the metric goes to infinite.",2 How similar are embeddings across languages?,[0],[0]
"Thus, the higher ∆ is, the less similar the graphs (i.e., their Laplacian spectra).",2 How similar are embeddings across languages?,[0],[0]
We discuss the correlation between unsupervised BDI performance and approximate isospectrality or eigenvector similarity in §4.7.,2 How similar are embeddings across languages?,[0],[0]
"Unsupervised neural machine translation relies on BDI using cross-lingual embeddings (Lample et al., 2018a; Artetxe et al., 2018), which in turn relies on the assumption that word embedding graphs are approximately isomorphic.",3.1 Learning scenarios,[0],[0]
"The work of Conneau et al. (2018), which we focus on here, also makes several implicit assumptions that may or may not be necessary to achieve such isomorphism, and which may or may not scale to low-resource languages.",3.1 Learning scenarios,[0],[0]
"The algorithms are not intended to be limited to learning scenarios where these assumptions hold, but since they do in the reported experiments, it is important to see to what extent these assumptions are necessary for the algorithms to produce useful embeddings or dictionaries.
",3.1 Learning scenarios,[0],[0]
"We focus on the work of Conneau et al. (2018), who present a fully unsupervised approach to aligning monolingual word embeddings, induced using fastText (Bojanowski et al., 2017).",3.1 Learning scenarios,[0],[0]
We describe the learning algorithm in §3.2.,3.1 Learning scenarios,[0],[0]
"Conneau et al. (2018) consider a specific set of learning scenarios:
(a) The authors work with the following languages: English-{French, German, Chinese, Russian, Spanish}.",3.1 Learning scenarios,[0],[0]
"These languages, except
French, are dependent marking (Table 1).3 We evaluate Conneau et al. (2018) on (English to) Estonian (ET), Finnish (FI), Greek (EL), Hungarian (HU), Polish (PL), and Turkish (TR) in §4.2, to test whether the selection of languages in the original study introduces a bias.
",3.1 Learning scenarios,[0],[0]
"(b) The monolingual corpora in their experiments are comparable; Wikipedia corpora are used, except for an experiment in which they include Google Gigawords.",3.1 Learning scenarios,[0],[0]
"We evaluate across different domains, i.e., on all combinations of Wikipedia, EuroParl, and the EMEA medical corpus, in §4.3.",3.1 Learning scenarios,[0],[0]
"We believe such scenarios are more realistic for low-resource languages.
",3.1 Learning scenarios,[0],[0]
(c),3.1 Learning scenarios,[0],[0]
The monolingual embedding models are induced using the same algorithms with the same hyper-parameters.,3.1 Learning scenarios,[0],[0]
We evaluate Conneau et al. (2018) on pairs of embeddings induced with different hyper-parameters in §4.4.,3.1 Learning scenarios,[0],[0]
"While keeping hyper-parameters fixed is always possible, it is of practical interest to know whether the unsupervised methods work on any set of pre-trained word embeddings.
",3.1 Learning scenarios,[0],[0]
We also investigate the sensitivity of unsupervised BDI to the dimensionality of the monolingual word embeddings in §4.5.,3.1 Learning scenarios,[0],[0]
"The motivation for this is that dimensionality reduction will alter the geometric shape and remove characteristics of the embedding graphs that are important for alignment; but on the other hand, lower dimensionality introduces regularization, which will make the graphs more similar.",3.1 Learning scenarios,[0],[0]
"Finally, in §4.6, we investigate the impact of different types of query test words on performance, including how performance varies across part-of-speech word classes and on shared vocabulary items.",3.1 Learning scenarios,[0],[0]
"We now introduce the method of Conneau et al. (2018).4 The approach builds on existing work on learning a mapping between monolingual word embeddings (Mikolov et al., 2013b; Xing et al., 2015) and consists of the following steps: 1) Monolingual word embeddings: An off-the-shelf word embedding algorithm (Bojanowski et al., 2017) is used to learn source and target language spaces X
3A dependent-marking language marks agreement and case more commonly on dependents than on heads.
",3.2 Summary of Conneau et al. (2018),[0],[0]
"4https://github.com/facebookresearch/ MUSE
and Y .",3.2 Summary of Conneau et al. (2018),[0],[0]
2),3.2 Summary of Conneau et al. (2018),[0],[0]
"Adversarial mapping: A translation matrix W is learned between the spaces X and Y using adversarial techniques (Ganin et al., 2016).",3.2 Summary of Conneau et al. (2018),[0],[0]
"A discriminator is trained to discriminate samples from the translated source space WX from the target space Y , while W is trained to prevent this.",3.2 Summary of Conneau et al. (2018),[0],[0]
"This, again, is motivated by the assumption that source and target language word embeddings are approximately isomorphic.",3.2 Summary of Conneau et al. (2018),[0],[0]
"3) Refinement (Procrustes analysis): W is used to build a small bilingual dictionary of frequent words, which is pruned such that only bidirectional translations are kept (Vulić and Korhonen, 2016).",3.2 Summary of Conneau et al. (2018),[0],[0]
"A new translation matrix W that translates between the spaces X and Y of these frequent word pairs is then induced by solving the Orthogonal Procrustes problem:
W ∗ =",3.2 Summary of Conneau et al. (2018),[0],[0]
"argminW ‖WX − Y ‖F = UV >
s.t. UΣV > = SVD(Y X>) (1)
",3.2 Summary of Conneau et al. (2018),[0],[0]
This step can be used iteratively by using the new matrix W to create new seed translation pairs.,3.2 Summary of Conneau et al. (2018),[0],[0]
It requires frequent words to serve as reliable anchors for learning a translation matrix.,3.2 Summary of Conneau et al. (2018),[0],[0]
"In the experiments in Conneau et al. (2018), as well as in ours, the iterative Procrustes refinement improves performance across the board.",3.2 Summary of Conneau et al. (2018),[0],[0]
"4) Cross-domain similarity local scaling (CSLS) is used to expand high-density areas and condense low-density ones, for more accurate nearest neighbor calculation, CSLS reduces the hubness problem in high-dimensional spaces (Radovanović et al., 2010; Dinu et al., 2015).",3.2 Summary of Conneau et al. (2018),[0],[0]
"It relies on the mean similarity of a source language embedding x to itsK target language nearest neighbours (K = 10 suggested) nn1, . . .",3.2 Summary of Conneau et al. (2018),[0],[0]
", nnK :
mnnT (x) = 1
K K∑ i=1",3.2 Summary of Conneau et al. (2018),[0],[0]
"cos(x, nni) (2)
where cos is the cosine similarity.",3.2 Summary of Conneau et al. (2018),[0],[0]
"mnnS(y) is defined in an analogous manner for any target language embedding y. CSLS(x, y) is then calculated as follows:
2cos(x, y)−mnnT (x)−mnnS(y) (3)",3.2 Summary of Conneau et al. (2018),[0],[0]
"Instead of learning cross-lingual embeddings completely without supervision, we can extract inexpensive supervision signals by harvesting identically spelled words as in, e.g. (Artetxe et al., 2017;
Smith et al., 2017).",3.3 A simple supervised method,[0],[0]
"Specifically, we use identically spelled words that occur in the vocabularies of both languages as bilingual seeds, without employing any additional transliteration or lemmatization/normalization methods.",3.3 A simple supervised method,[0],[0]
"Using this seed dictionary, we then run the refinement step using Procrustes analysis of Conneau et al. (2018).",3.3 A simple supervised method,[0],[0]
"In the following experiments, we investigate the robustness of unsupervised cross-lingual word embedding learning, varying the language pairs, monolingual corpora, hyper-parameters, etc., to obtain a better understanding of when and why unsupervised BDI works.
",4 Experiments,[0],[0]
"Task: Bilingual dictionary induction After the shared cross-lingual space is induced, given a list of N source language words xu,1, . . .",4 Experiments,[0],[0]
", xu,N , the task is to find a target language word t for each query word xu relying on the representations in the space.",4 Experiments,[0],[0]
ti is the target language word closest to the source language word,4 Experiments,[0],[0]
"xu,i in the induced cross-lingual space, also known as the cross-lingual nearest neighbor.",4 Experiments,[0],[0]
"The set of learned N (xu,i, ti) pairs is then run against a gold standard dictionary.
",4 Experiments,[0],[0]
"We use bilingual dictionaries compiled by Conneau et al. (2018) as gold standard, and adopt their evaluation procedure: each test set in each language consists of 1500 gold translation pairs.",4 Experiments,[0],[0]
"We rely on CSLS for retrieving the nearest neighbors, as it consistently outperformed the cosine similarity in all our experiments.",4 Experiments,[0],[0]
"Following a standard evaluation practice (Vulić and Moens, 2013; Mikolov et al., 2013b; Conneau et al., 2018), we report Precision at 1 scores (P@1): how many times one of the correct translations of a source word w is retrieved as the nearest neighbor of w in the target language.",4 Experiments,[0],[0]
Our default experimental setup closely follows the setup of Conneau et al. (2018).,4.1 Experimental setup,[0],[0]
"For each language we induce monolingual word embeddings for all languages from their respective tokenized and lowercased Polyglot Wikipedias (Al-Rfou et al., 2013) using fastText (Bojanowski et al., 2017).",4.1 Experimental setup,[0],[0]
Only words with more than 5 occurrences are retained for training.,4.1 Experimental setup,[0],[0]
"Our fastText setup relies on skip-gram with negative sampling (Mikolov et al., 2013a) with standard hyper-parameters: bag-of-words contexts with the window size 2, 15 negative samples, subsampling rate 10−4, and character n-gram length
3-6.",4.1 Experimental setup,[0],[0]
All embeddings are 300-dimensional.,4.1 Experimental setup,[0],[0]
"As we analyze the impact of various modeling assumptions in the following sections (e.g., domain differences, algorithm choices, hyper-parameters), we also train monolingual word embeddings using other corpora and different hyper-parameter choices.",4.1 Experimental setup,[0],[0]
Quick summaries of each experimental setup are provided in the respective subsections.,4.1 Experimental setup,[0],[0]
"Conneau et al. (2018) present results for several target languages: Spanish, French, German, Russian, Chinese, and Esperanto.",4.2 Impact of language similarity,[0],[0]
All languages but Esperanto are isolating or exclusively concatenating languages from a morphological point of view.,4.2 Impact of language similarity,[0],[0]
All languages but French are dependent-marking.,4.2 Impact of language similarity,[0],[0]
"Ta-
ble 1 lists three important morphological properties of the languages involved in their/our experiments.
",4.2 Impact of language similarity,[0],[0]
"Agglutinative languages with mixed or double marking show more morphological variance with content words, and we speculate whether unsupervised BDI is challenged by this kind of morphological complexity.",4.2 Impact of language similarity,[0],[0]
"To evaluate this, we experiment with Estonian and Finnish, and we include Greek, Hungarian, Polish, and Turkish to see how their approach fares on combinations of these two morphological traits.
",4.2 Impact of language similarity,[0],[0]
We show results in the left column of Table 2.,4.2 Impact of language similarity,[0],[0]
The results are quite dramatic.,4.2 Impact of language similarity,[0],[0]
"The approach achieves impressive performance for Spanish, one of the languages Conneau et al. (2018) include in their paper.",4.2 Impact of language similarity,[0],[0]
"For the languages we add here, performance is less impressive.",4.2 Impact of language similarity,[0],[0]
"For the languages with dependent marking (Hungarian, Polish, and Turkish), P@1 scores are still reasonable, with Turkish being slightly lower (0.327) than the others.",4.2 Impact of language similarity,[0],[0]
"However, for Estonian and Finnish, the method fails completely.",4.2 Impact of language similarity,[0],[0]
"Only in less than 1/1000 cases does a nearest neighbor search in the induced embeddings return a correct translation of a query word.5
The sizes of Wikipedias naturally vary across languages: e.g., fastText trains on approximately 16M sentences and 363M word tokens for Spanish, while it trains on 1M sentences and 12M words for Finnish.",4.2 Impact of language similarity,[0],[0]
"However, the difference in performance cannot be explained by the difference in training data sizes.",4.2 Impact of language similarity,[0],[0]
"To verify that near-zero performance in Finnish is not a result of insufficient training data, we have conducted another experiment using the large Finnish WaC corpus (Ljubešić et al., 2016) containing 1.7B words in total (this is similar in size to the English Polyglot Wikipedia).",4.2 Impact of language similarity,[0],[0]
"However, even with this large Finnish corpus, the model does not induce anything useful: P@1 equals 0.0.
",4.2 Impact of language similarity,[0],[0]
"We note that while languages with mixed marking may be harder to align, it seems unsupervised BDI is possible between similar, mixed marking languages.",4.2 Impact of language similarity,[0],[0]
"So while unsupervised learning fails for English-Finnish and English-Estonian, performance is reasonable and stable for the more similar Estonian-Finnish pair (Table 2).",4.2 Impact of language similarity,[0],[0]
"In general, unsupervised BDI, using the approach in Conneau et al. (2018), seems challenged when pairing En-
5We note, though, that varying our random seed, performance for Estonian, Finnish, and Greek is sometimes (approximately 1 out of 10 runs) on par with Turkish.",4.2 Impact of language similarity,[0],[0]
"Detecting main causes and remedies for the inherent instability of adversarial training is one the most important avenues for future research.
",4.2 Impact of language similarity,[0],[0]
glish with languages that are not isolating and do not have,4.2 Impact of language similarity,[0],[0]
"dependent marking.6
",4.2 Impact of language similarity,[0],[0]
The promise of zero-supervision models is that we can learn cross-lingual embeddings even for low-resource languages.,4.2 Impact of language similarity,[0],[0]
"On the other hand, a similar distribution of embeddings requires languages to be similar.",4.2 Impact of language similarity,[0],[0]
This raises the question whether we need fully unsupervised methods at all.,4.2 Impact of language similarity,[0],[0]
"In fact, our supervised method that relies on very naive supervision in the form of identically spelled words leads to competitive performance for similar language pairs and better results for dissimilar pairs.",4.2 Impact of language similarity,[0],[0]
The fact that we can reach competitive and more robust performance with such a simple heuristic questions the true applicability of fully unsupervised approaches and suggests that it might often be better to rely on available weak supervision.,4.2 Impact of language similarity,[0],[0]
"Monolingual word embeddings used in Conneau et al. (2018) are induced from Wikipedia, a nearparallel corpus.",4.3 Impact of domain differences,[0],[0]
"In order to assess the sensitivity of unsupervised BDI to the comparability and domain similarity of the monolingual corpora, we replicate the experiments in Conneau et al. (2018) using combinations of word embeddings extracted from three different domains: 1) parliamentary proceedings from EuroParl.v7 (Koehn, 2005), 2)",4.3 Impact of domain differences,[0],[0]
"Wikipedia (Al-Rfou et al., 2013), and 3) the EMEA corpus in the medical domain (Tiedemann, 2009).",4.3 Impact of domain differences,[0],[0]
"We report experiments with three language pairs: English{Spanish, Finnish, Hungarian}.
",4.3 Impact of domain differences,[0],[0]
"To control for the corpus size, we restrict each corpus in each language to 1.1M sentences in total (i.e., the number of sentences in the smallest, EMEA corpus).",4.3 Impact of domain differences,[0],[0]
"300-dim fastText vectors are induced as in §4.1, retaining all words with more than 5 occurrences in the training data.",4.3 Impact of domain differences,[0],[0]
"For each pair of monolingual corpora, we compute their domain (dis)similarity by calculating the Jensen-Shannon divergence (El-Gamal, 1991), based on term distributions.7",4.3 Impact of domain differences,[0],[0]
"The domain similarities are displayed in Figures 2a–c.8
We show the results of unsupervised BDI in Figures 2g–i. For Spanish, we see good performance in all three cases where the English and Spanish
6One exception here is French, which they include in their paper, but French arguably has a relatively simple morphology.
",4.3 Impact of domain differences,[0],[0]
"7In order to get comparable term distributions, we translate the source language to the target language using the bilingual dictionaries provided by Conneau et al. (2018).
",4.3 Impact of domain differences,[0],[0]
"8We also computed A-distances (Blitzer et al., 2007) and confirmed that trends were similar.
corpora are from the same domain.",4.3 Impact of domain differences,[0],[0]
"When the two corpora are from different domains, performance is close to zero.",4.3 Impact of domain differences,[0],[0]
"For Finnish and Hungarian, performance is always poor, suggesting that more data is needed, even when domains are similar.",4.3 Impact of domain differences,[0],[0]
"This is in sharp contrast with the results of our minimally supervised approach (Figures 2d–f) based on identical words, which achieves decent performance in many set-ups.
",4.3 Impact of domain differences,[0],[0]
We also observe a strong decrease in P@1 for English-Spanish (from 81.19% to 46.52%) when using the smaller Wikipedia corpora.,4.3 Impact of domain differences,[0],[0]
This result indicates the importance of procuring large monolingual corpora from similar domains in order to enable unsupervised dictionary induction.,4.3 Impact of domain differences,[0],[0]
"However, resource-lean languages, for which the unsupervised method was designed in the first place, cannot be guaranteed to have as large monolingual training corpora as available for English, Spanish or other major resource-rich languages.",4.3 Impact of domain differences,[0],[0]
Conneau et al. (2018) use the same hyperparameters for inducing embeddings for all languages.,4.4 Impact of hyper-parameters,[0],[0]
"This is of course always practically possible, but we are interested in seeing whether their approach works on pre-trained embeddings induced with possibly very different hyper-parameters.",4.4 Impact of hyper-parameters,[0],[0]
"We focus on two hyper-parameters: context windowsize (win) and the parameter controlling the number of n-gram features in the fastText model (chn), while at the same time varying the underlying algorithm: skip-gram vs. cbow.",4.4 Impact of hyper-parameters,[0],[0]
"The results for EnglishSpanish are listed in Table 3.
",4.4 Impact of hyper-parameters,[0],[0]
"The small variations in the hyper-parameters with the same underlying algorithm (i.e., using skipgram or cbow for both EN and ES) yield only slight drops in the final scores.",4.4 Impact of hyper-parameters,[0],[0]
"Still, the best scores are obtained with the same configuration on both sides.",4.4 Impact of hyper-parameters,[0],[0]
Our main finding here is that unsupervised BDI fails (even) for EN-ES when the two monolingual embedding spaces are induced by two different algorithms (see the results of the entire Spanish cbow column).9,4.4 Impact of hyper-parameters,[0],[0]
"In sum, this means that the unsupervised approach is unlikely to work on pre-trained word embeddings unless they are induced on same-
9We also checked if this result might be due to a lowerquality monolingual ES space.",4.4 Impact of hyper-parameters,[0],[0]
"However, monolingual word similarity scores on available datasets in Spanish show performance comparable to that of Spanish skip-gram vectors: e.g., Spearman’s ρ correlation is ≈ 0.7 on the ES evaluation set from SemEval-2017 Task 2 (Camacho-Collados et al., 2017).
or comparable-domain, reasonably-sized training data using the same underlying algorithm.",4.4 Impact of hyper-parameters,[0],[0]
We also perform an experiment on 40-dimensional monolingual word embeddings.,4.5 Impact of dimensionality,[0],[0]
"This leads to reduced expressivity, and can potentially make the geometric shapes of embedding spaces harder to align; on the other hand, reduced dimensionality may also lead to less overfitting.",4.5 Impact of dimensionality,[0],[0]
"We generally
see worse performance (P@1 is 50.33 for Spanish, 21.81 for Hungarian, 20.11 for Polish, and 22.03 for Turkish) – but, very interestingly, we obtain better performance for Estonian (13.53), Finnish (15.33), and Greek (24.17) than we did with 300 dimensions.",4.5 Impact of dimensionality,[0],[0]
We hypothesize this indicates monolingual word embedding algorithms over-fit to some of the rarer peculiarities of these languages.,4.5 Impact of dimensionality,[0],[0]
BDI models are evaluated on a held-out set of query words.,4.6 Impact of evaluation procedure,[0],[0]
"Here, we analyze the performance of the unsupervised approach across different parts-ofspeech, frequency bins, and with respect to query words that have orthographically identical counterparts in the target language with the same or a different meaning.
",4.6 Impact of evaluation procedure,[0],[0]
Part-of-speech We show the impact of the partof-speech of the query words in Table 4; again on a representative subset of our languages.,4.6 Impact of evaluation procedure,[0],[0]
The results indicate that performance on verbs is lowest across the board.,4.6 Impact of evaluation procedure,[0],[0]
"This is consistent with research on distributional semantics and verb meaning (Schwartz et al., 2015; Gerz et al., 2016).
",4.6 Impact of evaluation procedure,[0],[0]
Frequency We also investigate the impact of the frequency of query words.,4.6 Impact of evaluation procedure,[0],[0]
"We calculate the word frequency of English words based on Google’s Trillion Word Corpus: query words are divided in groups based on their rank – i.e., the first group contains the top 100 most frequent words, the second one contains the 101th-1000th most frequent words, etc. – and plot performance (P@1) relative to rank in Figure 3.",4.6 Impact of evaluation procedure,[0],[0]
"For EN-FI, P@1 was 0 across all frequency ranks.",4.6 Impact of evaluation procedure,[0],[0]
"The plot shows sensitivity to frequency for HU, but less so for ES.
Homographs Since we use identical word forms (homographs) for supervision, we investigated
whether these are representative or harder to align than other words.",4.6 Impact of evaluation procedure,[0],[0]
"Table 5 lists performance for three sets of query words: (a) source words that have homographs (words that are spelled the same way) with the same meaning (homonyms) in the target language, e.g., many proper names; (b) source words that have homographs that are not homonyms in the target language, e.g., many short words; and (c) other words.",4.6 Impact of evaluation procedure,[0],[0]
"Somewhat surprisingly, words which have translations that are homographs, are associated with lower precision than other words.",4.6 Impact of evaluation procedure,[0],[0]
"This is probably due to loan words and proper names, but note that using homographs as supervision for alignment, we achieve high precision for this part of the vocabulary for free.",4.6 Impact of evaluation procedure,[0],[0]
"Finally, in order to get a better understanding of the limitations of unsupervised BDI, we correlate the graph similarity metric described in §2 (right column of Table 2) with performance across languages (left column).",4.7 Evaluating eigenvector similarity,[0],[0]
"Since we already established that the monolingual word embeddings are far from isomorphic—in contrast with the intuitions motivating previous work (Mikolov et al., 2013b; Barone, 2016; Zhang et al., 2017; Conneau et al., 2018)— we would like to establish another diagnostic metric that identifies embedding spaces for which the approach in Conneau et al. (2018) is likely to work.",4.7 Evaluating eigenvector similarity,[0],[0]
"Differences in morphology, domain, or embedding parameters seem to be predictive of poor performance, but a metric that is independent of linguistic
categorizations and the characteristics of the monolingual corpora would be more widely applicable.",4.7 Evaluating eigenvector similarity,[0],[0]
We plot the values in Table 2 in Figure 4.,4.7 Evaluating eigenvector similarity,[0],[0]
"Recall that our graph similarity metric returns a value in the half-open interval [0,∞).",4.7 Evaluating eigenvector similarity,[0],[0]
The correlation between BDI performance and graph similarity is strong (ρ ∼ 0.89).,4.7 Evaluating eigenvector similarity,[0],[0]
"Cross-lingual word embeddings Cross-lingual word embedding models typically, unlike Conneau et al. (2018), require aligned words, sentences, or documents (Levy et al., 2017).",5 Related work,[0],[0]
"Most approaches based on word alignments learn an explicit mapping between the two embedding spaces (Mikolov et al., 2013b; Xing et al., 2015).",5 Related work,[0],[0]
"Recent approaches try to minimize the amount of supervision needed (Vulić and Korhonen, 2016; Artetxe et al., 2017; Smith et al., 2017).",5 Related work,[0],[0]
"See Upadhyay et al. (2016) and Ruder et al. (2018) for surveys.
",5 Related work,[0],[0]
"Unsupervised cross-lingual learning Haghighi et al. (2008) were first to explore unsupervised BDI, using features such as context counts and orthographic substrings, and canonical correlation analysis.",5 Related work,[0],[0]
"Recent approaches use adversarial learning (Goodfellow et al., 2014) and employ a discriminator, trained to distinguish between the translated source and the target language space, and a generator learning a translation matrix (Barone, 2016).",5 Related work,[0],[0]
"Zhang et al. (2017), in addition, use different forms of regularization for convergence, while Conneau et al. (2018) uses additional steps to refine the induced embedding space.
",5 Related work,[0],[0]
"Unsupervised machine translation Research on unsupervised machine translation (Lample et al., 2018a; Artetxe et al., 2018; Lample et al., 2018b) has generated a lot of interest recently with a
promise to support the construction of MT systems for and between resource-poor languages.",5 Related work,[0],[0]
All unsupervised NMT methods critically rely on accurate unsupervised BDI and back-translation.,5 Related work,[0],[0]
Models are trained to reconstruct a corrupted version of the source sentence and to translate its translated version back to the source language.,5 Related work,[0],[0]
"Since the crucial input to these systems are indeed cross-lingual word embedding spaces induced in an unsupervised fashion, in this paper we also implicitly investigate one core limitation of such unsupervised MT techniques.",5 Related work,[0],[0]
"We investigated when unsupervised BDI (Conneau et al., 2018) is possible and found that differences in morphology, domains or word embedding algorithms may challenge this approach.",6 Conclusion,[0],[0]
"Further, we found eigenvector similarity of sampled nearest neighbor subgraphs to be predictive of unsupervised BDI performance.",6 Conclusion,[0],[0]
We hope that this work will guide further developments in this new and exciting field.,6 Conclusion,[0],[0]
"We thank the anonymous reviewers, as well as Hinrich Schütze and Yova Kementchedjhieva, for their valuable feedback.",Acknowledgments,[0],[0]
Anders is supported by the ERC Starting Grant LOWLANDS,Acknowledgments,[0],[0]
No. 313695 and a Google Focused Research Award.,Acknowledgments,[0],[0]
Sebastian is supported by Irish Research Council Grant Number EBPPG/2014/30 and Science Foundation Ireland Grant Number SFI/12/RC/2289.,Acknowledgments,[0],[0]
Ivan is supported by the ERC Consolidator Grant LEXICAL,Acknowledgments,[0],[0]
No. 648909.,Acknowledgments,[0],[0]
"Unsupervised machine translation—i.e., not assuming any cross-lingual supervision signal, whether a dictionary, translations, or comparable corpora—seems impossible, but nevertheless, Lample et al. (2018a) recently proposed a fully unsupervised machine translation (MT) model.",abstractText,[0],[0]
"The model relies heavily on an adversarial, unsupervised alignment of word embedding spaces for bilingual dictionary induction (Conneau et al., 2018), which we examine here.",abstractText,[0],[0]
"Our results identify the limitations of current unsupervised MT: unsupervised bilingual dictionary induction performs much worse on morphologically rich languages that are not dependent marking, when monolingual corpora from different domains or different embedding algorithms are used.",abstractText,[0],[0]
"We show that a simple trick, exploiting a weak supervision signal from identical words, enables more robust induction, and establish a near-perfect correlation between unsupervised bilingual dictionary induction performance and a previously unexplored graph similarity metric.",abstractText,[0],[0]
On the Limitations of Unsupervised Bilingual Dictionary Induction,title,[0],[0]
How does depth help?,1. Introduction,[0],[0]
This central question of deep learning still eludes full theoretical understanding.,1. Introduction,[0],[0]
"The general consensus is that there is a trade-off: increasing depth improves expressiveness, but complicates optimization.",1. Introduction,[0],[0]
"Superior expressiveness of deeper networks, long suspected, is now confirmed by theory, albeit for fairly limited learning problems (Eldan & Shamir, 2015; Raghu et al., 2016; Lee et al., 2017; Cohen et al., 2017; Daniely, 2017; Arora et al., 2018).",1. Introduction,[0],[0]
Difficulties in optimizing deeper networks have also been long clear – the signal held by a gradient gets buried as it propagates through many layers.,1. Introduction,[0],[0]
This is known as the “vanishing/exploding gradient problem”.,1. Introduction,[0],[0]
"Modern techniques such as batch normalization (Ioffe & Szegedy, 2015) and residual connections (He et al., 2015) have somewhat alleviated these difficulties in practice.
",1. Introduction,[0],[0]
"1Department of Computer Science, Princeton University, Princeton, NJ, USA 2School of Mathematics, Institute for Advanced Study, Princeton, NJ, USA 3Google Brain, USA.",1. Introduction,[0],[0]
"Correspondence to: Nadav Cohen <cohennadav@ias.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"Given the longstanding consensus on expressiveness vs. optimization trade-offs, this paper conveys a rather counterintuitive message: increasing depth can accelerate optimization.",1. Introduction,[0],[0]
"The effect is shown, via first-cut theoretical and empirical analyses, to resemble a combination of two wellknown tools in the field of optimization: momentum, which led to provable acceleration bounds (Nesterov, 1983); and adaptive regularization, a more recent technique proven to accelerate by Duchi et al. (2011) in their proposal of the AdaGrad algorithm.",1. Introduction,[0],[0]
"Explicit mergers of both techniques are quite popular in deep learning (Kingma & Ba, 2014; Tieleman & Hinton, 2012).",1. Introduction,[0],[0]
"It is thus intriguing that merely introducing depth, with no other modification, can have a similar effect, but implicitly.
",1. Introduction,[0],[0]
"There is an obvious hurdle in isolating the effect of depth on optimization: if increasing depth leads to faster training on a given dataset, how can one tell whether the improvement arose from a true acceleration phenomenon, or simply due to better representational power (the shallower network was unable to attain the same training loss)?",1. Introduction,[0],[0]
We respond to this hurdle by focusing on linear neural networks (cf. Saxe et al. (2013); Goodfellow et al. (2016); Hardt & Ma (2016); Kawaguchi (2016)).,1. Introduction,[0],[0]
"With these models, adding layers does not alter expressiveness; it manifests itself only in the replacement of a matrix parameter by a product of matrices – an overparameterization.
",1. Introduction,[0],[0]
We provide a new analysis of linear neural network optimization via direct treatment of the differential equations associated with gradient descent when training arbitrarily deep networks on arbitrary loss functions.,1. Introduction,[0],[0]
"We find that the overparameterization introduced by depth leads gradient descent to operate as if it were training a shallow (single layer) network, while employing a particular preconditioning scheme.",1. Introduction,[0],[0]
"The preconditioning promotes movement along directions already taken by the optimization, and can be seen as an acceleration procedure that combines momentum with adaptive learning rates.",1. Introduction,[0],[0]
"Even on simple convex problems such as linear regression with `p loss, p > 2, overparameterization via depth can significantly speed up training.",1. Introduction,[0],[0]
"Surprisingly, in some of our experiments, not only did overparameterization outperform naı̈ve gradient descent, but it was also faster than two well-known acceleration methods – AdaGrad (Duchi et al., 2011) and AdaDelta (Zeiler, 2012).
",1. Introduction,[0],[0]
"In addition to purely linear networks, we also demonstrate (empirically) the implicit acceleration of overparameterization on a non-linear model, by replacing hidden layers with depth-2 linear networks.",1. Introduction,[0],[0]
"The implicit acceleration of overparametrization is different from standard regularization – we prove its effect cannot be attained via gradients of any fixed regularizer.
",1. Introduction,[0],[0]
Both our theoretical analysis and our empirical evaluation indicate that acceleration via overparameterization need not be computationally expensive.,1. Introduction,[0],[0]
"From an optimization perspective, overparameterizing using wide or narrow networks has the same effect – it is only the depth that matters.",1. Introduction,[0],[0]
Theoretical study of optimization in deep learning is a highly active area of research.,2. Related Work,[0],[0]
"Works along this line typically analyze critical points (local minima, saddles) in the landscape of the training objective, either for linear networks (see for example Kawaguchi (2016); Hardt & Ma (2016) or Baldi & Hornik (1989) for a classic account), or for specific non-linear networks under different restrictive assumptions (cf.",2. Related Work,[0],[0]
Choromanska et al. (2015); Haeffele & Vidal (2015); Soudry & Carmon (2016); Safran & Shamir (2017)).,2. Related Work,[0],[0]
"Other works characterize other aspects of objective landscapes, for example Safran & Shamir (2016) showed that under certain conditions a monotonically descending path from initialization to global optimum exists (in compliance with the empirical observations of Goodfellow et al. (2014)).
",2. Related Work,[0],[0]
"The dynamics of optimization was studied in Fukumizu (1998) and Saxe et al. (2013), for linear networks.",2. Related Work,[0],[0]
"Like ours, these works analyze gradient descent through its corresponding differential equations.",2. Related Work,[0],[0]
"Fukumizu (1998) focuses on linear regression with `2 loss, and does not consider the effect of varying depth – only a two (single hidden) layer network is analyzed.",2. Related Work,[0],[0]
"Saxe et al. (2013) also focuses on `2 regression, but considers any depth beyond two (inclusive), ultimately concluding that increasing depth can slow down optimization, albeit by a modest amount.",2. Related Work,[0],[0]
"In contrast to these two works, our analysis applies to a general loss function, and any depth including one.",2. Related Work,[0],[0]
"Intriguingly, we find that for `p regression, acceleration by depth is revealed only when p > 2.",2. Related Work,[0],[0]
"This explains why the conclusion reached in Saxe et al. (2013) differs from ours.
",2. Related Work,[0],[0]
"Turning to general optimization, accelerated gradient (momentum) methods were introduced in Nesterov (1983), and later studied in numerous works (see Wibisono et al. (2016) for a short review).",2. Related Work,[0],[0]
"Such methods effectively accumulate gradients throughout the entire optimization path, using the collected history to determine the step at a current point in time.",2. Related Work,[0],[0]
Use of preconditioners to speed up optimization is also a well-known technique.,2. Related Work,[0],[0]
"Indeed, the classic Newton’s method can be seen as preconditioning based on second
derivatives.",2. Related Work,[0],[0]
Adaptive preconditioning with only first-order (gradient) information was popularized by the BFGS algorithm and its variants (cf. Nocedal (1980)).,2. Related Work,[0],[0]
"Relevant theoretical guarantees, in the context of regret minimization, were given in Hazan et al. (2007); Duchi et al. (2011).",2. Related Work,[0],[0]
"In terms of combining momentum and adaptive preconditioning, Adam (Kingma & Ba, 2014) is a popular approach, particularly for optimization of deep networks.",2. Related Work,[0],[0]
We begin with a simple yet striking example of the effect being studied.,3. Warmup: `p Regression,[0],[0]
"For linear regression with `p loss, we will see how even the slightest overparameterization can have an immense effect on optimization.",3. Warmup: `p Regression,[0],[0]
"Specifically, we will see that simple gradient descent on an objective overparameterized by a single scalar, corresponds to a form of accelerated gradient descent on the original objective.
",3. Warmup: `p Regression,[0],[0]
"Consider the objective for a scalar linear regression problem with `p loss (p – even positive integer): L(w) = E(x,y)∼S",3. Warmup: `p Regression,[0],[0]
[ 1 p (x >w,3. Warmup: `p Regression,[0],[0]
"− y)p ] x ∈ Rd here are instances, y ∈ R are continuous labels, S is a finite collection of labeled instances (training set), and w ∈ Rd is a learned parameter vector.",3. Warmup: `p Regression,[0],[0]
"Suppose now that we apply a simple overparameterization, replacing the parameter vector w by a vector w1 ∈ Rd times a scalar w2 ∈ R:
L(w1, w2) = E(x,y)∼S",3. Warmup: `p Regression,[0],[0]
[ 1 p (x >w1w2,3. Warmup: `p Regression,[0],[0]
− y)p ],3. Warmup: `p Regression,[0],[0]
Obviously the overparameterization does not affect the expressiveness of the linear model.,3. Warmup: `p Regression,[0],[0]
How does it affect optimization?,3. Warmup: `p Regression,[0],[0]
"What happens to gradient descent on this nonconvex objective?
",3. Warmup: `p Regression,[0],[0]
Observation 1.,3. Warmup: `p Regression,[0],[0]
"Gradient descent over L(w1, w2), with fixed small learning rate and near-zero initialization, is equivalent to gradient descent over L(w) with particular adaptive learning rate and momentum terms.
",3. Warmup: `p Regression,[0],[0]
"To see this, consider the gradients of L(w) andL(w1, w2): ∇w := E(x,y)∼S",3. Warmup: `p Regression,[0],[0]
"[ (x>w − y)p−1x ] ∇w1 := E(x,y)∼S",3. Warmup: `p Regression,[0],[0]
[,3. Warmup: `p Regression,[0],[0]
(x>w1w2,3. Warmup: `p Regression,[0],[0]
"− y)p−1w2x
] ∇w2 := E(x,y)∼S",3. Warmup: `p Regression,[0],[0]
[,3. Warmup: `p Regression,[0],[0]
(x>w1w2,3. Warmup: `p Regression,[0],[0]
"− y)p−1w>1 x
] Gradient descent over L(w1, w2) with learning rate η > 0",3. Warmup: `p Regression,[0],[0]
":
w (t+1) 1",3. Warmup: `p Regression,[0],[0]
"← [ w (t) 1 −η∇w(t)1 , w (t+1) 2",3. Warmup: `p Regression,[0],[0]
"← [ w (t) 2 −η∇w(t)2
The dynamics of the underlying parameter w = w1w2 are: w(t+1) = w (t+1) 1 w (t+1) 2
←[ (w(t)1 −η∇w(t)1 )(w (t) 2 −η∇w(t)2 ) =",3. Warmup: `p Regression,[0],[0]
w (t) 1 w (t) 2,3. Warmup: `p Regression,[0],[0]
"− ηw
(t) 2 ∇w(t)1",3. Warmup: `p Regression,[0],[0]
"− η∇w(t)2 w (t) 1 +O(η2)
= w(t)",3. Warmup: `p Regression,[0],[0]
− η(w(t)2 )2∇w(t),3. Warmup: `p Regression,[0],[0]
"− η(w (t) 2 ) −1∇ w (t) 2 w(t) +O(η2)
η is assumed to be small, thus we neglect O(η2).",3. Warmup: `p Regression,[0],[0]
"Denoting ρ(t):=η(w(t)2 )
2 ∈R and γ(t):=η(w(t)2 )−1∇w(t)2 ∈R, this gives:
w(t+1)",3. Warmup: `p Regression,[0],[0]
←[ w(t),3. Warmup: `p Regression,[0],[0]
− ρ(t)∇w(t),3. Warmup: `p Regression,[0],[0]
− γ(t)w(t),3. Warmup: `p Regression,[0],[0]
"Since by assumption w1 and w2 are initialized near zero, w will initialize near zero as well.",3. Warmup: `p Regression,[0],[0]
"This implies that at every iteration t, w(t) is a weighted combination of past gradients.",3. Warmup: `p Regression,[0],[0]
"There thus exist µ(t,τ) ∈ R such that:
w(t+1)",3. Warmup: `p Regression,[0],[0]
← [ w(t) − ρ(t)∇w(t),3. Warmup: `p Regression,[0],[0]
"− ∑t−1
τ=1 µ(t,τ)∇w(τ)
We conclude that the dynamics governing the underlying parameter w correspond to gradient descent with a momentum term, where both the learning rate (ρ(t)) and momentum coefficients (µ(t,τ)) are time-varying and adaptive.",3. Warmup: `p Regression,[0],[0]
"Let X := Rd be a space of objects (e.g. images or word embeddings) that we would like to infer something about, and let Y := Rk be the space of possible inferences.",4. Linear Neural Networks,[0],[0]
"Suppose we are given a training set {(x(i),y(i))}mi=1 ⊂ X × Y , along with a (point-wise) loss function",4. Linear Neural Networks,[0],[0]
l : Y × Y → R≥0.,4. Linear Neural Networks,[0],[0]
"For example, y(i) could hold continuous values with l(·) being the `2 loss: l(ŷ,y) = 12 ‖ŷ − y‖ 2 2; or it could hold one-hot vectors representing categories with l(·) being the softmax-cross-entropy loss: l(ŷ,y) =",4. Linear Neural Networks,[0],[0]
− ∑k r=1,4. Linear Neural Networks,[0],[0]
yr,4. Linear Neural Networks,[0],[0]
log(e ŷr/,4. Linear Neural Networks,[0],[0]
"∑k r′=1 e
ŷr′ ), where yr and ŷr stand for coordinate r of y and ŷ respectively.",4. Linear Neural Networks,[0],[0]
"For a predictor φ, i.e. a mapping from X to Y , the overall training loss is L(φ) := 1m ∑m i=1",4. Linear Neural Networks,[0],[0]
"l(φ(x
(i)),y(i)).",4. Linear Neural Networks,[0],[0]
"If φ comes from some parametric family Φ := {φθ : X → Y|θ ∈ Θ}, we view the corresponding training loss as a function of the parameters, i.e. we consider LΦ(θ)",4. Linear Neural Networks,[0],[0]
:= 1m ∑m i=1,4. Linear Neural Networks,[0],[0]
"l(φθ(x
(i)),y(i)).",4. Linear Neural Networks,[0],[0]
"For example, if the parametric family in question is the class of (directly parameterized) linear predictors:
",4. Linear Neural Networks,[0],[0]
Φlin := {x 7→Wx|W ∈,4. Linear Neural Networks,[0],[0]
"Rk,d} (1) the respective training loss is a function from Rk,d to R≥0.
",4. Linear Neural Networks,[0],[0]
"In our context, a depth-N (N ≥ 2) linear neural network, with hidden widths n1, n2, . . .",4. Linear Neural Networks,[0],[0]
", nN−1∈N, is the following parametric family of linear predictors: Φn1...nN−1",4. Linear Neural Networks,[0],[0]
":= {x 7→WNWN−1· · ·W1x|Wj∈Rnj ,nj−1 , j=1...N}, where by definition n0 := d and nN := k. As customary, we refer to each Wj , j=1...N , as the weight matrix of layer j. For simplicity of presentation, we hereinafter omit from our notation the hidden widths n1...nN−1, and simply write ΦN instead of Φn1...nN−1 (n1. .",4. Linear Neural Networks,[0],[0]
.nN−1 will be specified explicitly if not clear by context).,4. Linear Neural Networks,[0],[0]
"That is, we denote:
ΦN := (2) {x 7→WNWN−1· · ·W1x|Wj ∈ Rnj ,nj−1 , j=1...N}
For completeness, we regard a depth-1 network as the family of directly parameterized linear predictors, i.e. we set Φ1 := Φlin (see Equation 1).
",4. Linear Neural Networks,[0],[0]
"The training loss that corresponds to a depth-N linear network – LΦ N
(W1, ...,WN ), is a function from Rn1,n0×· · ·×RnN ,nN−1 to R≥0.",4. Linear Neural Networks,[0],[0]
"For brevity, we will denote this function by LN (·).",4. Linear Neural Networks,[0],[0]
"Our focus lies on the behavior
of gradient descent when minimizing LN (·).",4. Linear Neural Networks,[0],[0]
"More specifically, we are interested in the dependence of this behavior on N , and in particular, in the possibility of increasing N leading to acceleration.",4. Linear Neural Networks,[0],[0]
"Notice that for any N ≥ 2 we have:
LN (W1, ...,WN ) =",4. Linear Neural Networks,[0],[0]
"L 1(WNWN−1· · ·W1) (3)
and so the sole difference between the training loss of a depth-N network and that of a depth-1 network (classic linear model) lies in the replacement of a matrix parameter by a product of N matrices.",4. Linear Neural Networks,[0],[0]
"This implies that if increasing N can indeed accelerate convergence, it is not an outcome of any phenomenon other than favorable properties of depthinduced overparameterization for optimization.",4. Linear Neural Networks,[0],[0]
"In this section we present a new result for linear neural networks, tying the dynamics of gradient descent on LN (·) – the training loss corresponding to a depth-N network, to those on L1(·) – training loss of a depth-1 network (classic linear model).",5. Implicit Dynamics of Gradient Descent,[0],[0]
"Specifically, we show that gradient descent on LN (·), a complicated and seemingly pointless overparameterization, can be directly rewritten as a particular preconditioning scheme over gradient descent on L1(·).
",5. Implicit Dynamics of Gradient Descent,[0],[0]
"When applied to LN (·), gradient descent takes on the following form:
W (t+1) j ← [ (1− ηλ)W (t)",5. Implicit Dynamics of Gradient Descent,[0],[0]
j,5. Implicit Dynamics of Gradient Descent,[0],[0]
"− η
∂LN ∂Wj (W (t) 1 , . . .",5. Implicit Dynamics of Gradient Descent,[0],[0]
",W (t) N ) (4)
, j = 1. .",5. Implicit Dynamics of Gradient Descent,[0],[0]
".N
",5. Implicit Dynamics of Gradient Descent,[0],[0]
η > 0,5. Implicit Dynamics of Gradient Descent,[0],[0]
"here is a learning rate, and λ ≥ 0 is an optional weight decay coefficient.",5. Implicit Dynamics of Gradient Descent,[0],[0]
"For simplicity, we regard both η and λ as fixed (no dependence on t).",5. Implicit Dynamics of Gradient Descent,[0],[0]
"Define the underlying end-to-end weight matrix:
We := WNWN−1 · · ·W1 (5)
",5. Implicit Dynamics of Gradient Descent,[0],[0]
"Given that LN (W1, . . .",5. Implicit Dynamics of Gradient Descent,[0],[0]
",WN ) = L1(We) (Equation 3), we view We as an optimized weight matrix for L1(·), whose dynamics are governed by Equation 4.",5. Implicit Dynamics of Gradient Descent,[0],[0]
Our interest then boils down to the study of these dynamics for different choices of N .,5. Implicit Dynamics of Gradient Descent,[0],[0]
For N = 1 they are (trivially) equivalent to standard gradient descent over L1(·).,5. Implicit Dynamics of Gradient Descent,[0],[0]
"We will characterize the dynamics for N ≥ 2.
",5. Implicit Dynamics of Gradient Descent,[0],[0]
"To be able to derive, in our general setting, an explicit update rule for the end-to-end weight matrix",5. Implicit Dynamics of Gradient Descent,[0],[0]
"We (Equation 5), we introduce an assumption by which the learning rate is small, i.e. η2 ≈ 0.",5. Implicit Dynamics of Gradient Descent,[0],[0]
"Formally, this amounts to translating Equation 4 to the following set of differential equations:
Ẇj(t) = −ηλWj(t)−",5. Implicit Dynamics of Gradient Descent,[0],[0]
η,5. Implicit Dynamics of Gradient Descent,[0],[0]
"∂LN
∂Wj (W1(t), . .",5. Implicit Dynamics of Gradient Descent,[0],[0]
.,5. Implicit Dynamics of Gradient Descent,[0],[0]
",WN (t)) (6)
, j = 1. .",5. Implicit Dynamics of Gradient Descent,[0],[0]
".N
where t is now a continuous time index, and Ẇj(t) stands for the derivative of Wj with respect to time.",5. Implicit Dynamics of Gradient Descent,[0],[0]
"The use of differential equations, for both theoretical analysis and algorithm design, has a long and rich history in optimization
research (see Helmke & Moore (2012) for an overview).",5. Implicit Dynamics of Gradient Descent,[0],[0]
"When step sizes (learning rates) are taken to be small, trajectories of discrete optimization algorithms converge to smooth curves modeled by continuous-time differential equations, paving way to the well-established theory of the latter (cf. Boyce et al. (1969)).",5. Implicit Dynamics of Gradient Descent,[0],[0]
"This approach has led to numerous interesting findings, including recent results in the context of acceleration methods (e.g. Su et al. (2014); Wibisono et al. (2016)).
",5. Implicit Dynamics of Gradient Descent,[0],[0]
"With the continuous formulation in place, we turn to express the dynamics of the end-to-end matrix",5. Implicit Dynamics of Gradient Descent,[0],[0]
"We:
Theorem 1.",5. Implicit Dynamics of Gradient Descent,[0],[0]
Assume the weight matrices W1. .,5. Implicit Dynamics of Gradient Descent,[0],[0]
.WN,5. Implicit Dynamics of Gradient Descent,[0],[0]
follow the dynamics of continuous gradient descent (Equation 6).,5. Implicit Dynamics of Gradient Descent,[0],[0]
"Assume also that their initial values (time t0) satisfy, for j = 1. . .N",5. Implicit Dynamics of Gradient Descent,[0],[0]
"− 1:
W>j+1(t0)Wj+1(t0) =",5. Implicit Dynamics of Gradient Descent,[0],[0]
"Wj(t0)W > j (t0) (7)
",5. Implicit Dynamics of Gradient Descent,[0],[0]
"Then, the end-to-end weight matrix We (Equation 5) is governed by the following differential equation: Ẇe(t) =",5. Implicit Dynamics of Gradient Descent,[0],[0]
"−ηλN ·We(t) (8) −η ∑N
j=1
[ We(t)W > e (t) ]",5. Implicit Dynamics of Gradient Descent,[0],[0]
"j−1 N ·
dL1 dW (We(t)) ·",5. Implicit Dynamics of Gradient Descent,[0],[0]
"[ W>e (t)We(t) ]N−j N
where [·] j−1 N and [·] N−j N , j = 1 . . .",5. Implicit Dynamics of Gradient Descent,[0],[0]
"N , are fractional power operators defined over positive semidefinite matrices.
",5. Implicit Dynamics of Gradient Descent,[0],[0]
Proof.,5. Implicit Dynamics of Gradient Descent,[0],[0]
(sketch – full details in Appendix A.1),5. Implicit Dynamics of Gradient Descent,[0],[0]
If λ= 0 (no weight decay) then one can easily show that W>j+1(t)Ẇj+1(t) = Ẇj(t)W,5. Implicit Dynamics of Gradient Descent,[0],[0]
> j (t) throughout optimization.,5. Implicit Dynamics of Gradient Descent,[0],[0]
"Taking the transpose of this equation and adding to itself, followed by integration over time, imply that the difference between W>j+1(t)Wj+1(t) and Wj(t)W > j (t) is constant.",5. Implicit Dynamics of Gradient Descent,[0],[0]
"This difference is zero at initialization (Equation 7), thus will remain zero throughout, i.e.:
W>j+1(t)Wj+1(t) = Wj(t)W",5. Implicit Dynamics of Gradient Descent,[0],[0]
>,5. Implicit Dynamics of Gradient Descent,[0],[0]
"j (t) , ∀t ≥ t0 (9)
A slightly more delicate treatment shows that this is true even if λ > 0, i.e. with weight decay included.
",5. Implicit Dynamics of Gradient Descent,[0],[0]
"Equation 9 implies alignment of the (left and right) singular spaces of Wj(t) and Wj+1(t), simplifying the product Wj+1(t)Wj(t).",5. Implicit Dynamics of Gradient Descent,[0],[0]
"Successive application of this simplification allows a clean computation for the product of all layers (that is, We), leading to the explicit form presented in theorem statement (Equation 8).
",5. Implicit Dynamics of Gradient Descent,[0],[0]
"Translating the continuous dynamics of Equation 8 back to discrete time, we obtain the sought-after update rule for the end-to-end weight matrix: W (t+1)e ← [ (1− ηλN)W (t)e (10) −η ∑N
j=1
[ W (t)e (W (t) e )",5. Implicit Dynamics of Gradient Descent,[0],[0]
>,5. Implicit Dynamics of Gradient Descent,[0],[0]
"] j−1 N ·
dL1 dW (W (t) e ) ·",5. Implicit Dynamics of Gradient Descent,[0],[0]
[ (W (t)e ) >,5. Implicit Dynamics of Gradient Descent,[0],[0]
"W (t)e ]N−j N
",5. Implicit Dynamics of Gradient Descent,[0],[0]
"This update rule relies on two assumptions: first, that the
learning rate η is small enough for discrete updates to approximate continuous ones; and second, that weights are initialized on par with Equation 7, which will approximately be the case if initialization values are close enough to zero.",5. Implicit Dynamics of Gradient Descent,[0],[0]
"It is customary in deep learning for both learning rate and weight initializations to be small, but nonetheless above assumptions are only met to a certain extent.",5. Implicit Dynamics of Gradient Descent,[0],[0]
"We support their applicability by showing empirically (Section 8) that the end-to-end update rule (Equation 10) indeed provides an accurate description for the dynamics of We.
",5. Implicit Dynamics of Gradient Descent,[0],[0]
A close look at Equation 10 reveals that the dynamics of the end-to-end weight matrix We are similar to gradient descent over L1(·) – training loss corresponding to a depth-1 network (classic linear model).,5. Implicit Dynamics of Gradient Descent,[0],[0]
"The only difference (besides the scaling by N of the weight decay coefficient λ) is that the gradient dL 1
dW (We) is subject to a transformation before being used.",5. Implicit Dynamics of Gradient Descent,[0],[0]
"Namely, for j = 1. .",5. Implicit Dynamics of Gradient Descent,[0],[0]
".N , it is multiplied from the left by [WeW>e ]",5. Implicit Dynamics of Gradient Descent,[0],[0]
j−1 N and from the right by [W>e,5. Implicit Dynamics of Gradient Descent,[0],[0]
"We] N−j N , followed by summation over j. Clearly, when N = 1 (depth-1 network) this transformation reduces to identity, and as expected, We precisely adheres to gradient descent over L1(·).",5. Implicit Dynamics of Gradient Descent,[0],[0]
When N ≥ 2 the dynamics of We are less interpretable.,5. Implicit Dynamics of Gradient Descent,[0],[0]
"We arrange it as a vector to gain more insight:
Claim 1.",5. Implicit Dynamics of Gradient Descent,[0],[0]
"For an arbitrary matrix A, denote by vec(A) its arrangement as a vector in column-first order.",5. Implicit Dynamics of Gradient Descent,[0],[0]
"Then, the end-to-end update rule in Equation 10 can be written as:
vec(W (t+1)e )←",5. Implicit Dynamics of Gradient Descent,[0],[0]
"[ (1− ηλN) · vec(W (t)e ) (11) −η · P
W (t) e vec
( dL1 dW (W (t) e ) )
where P W (t) e is a positive semidefinite preconditioning matrix that depends on W (t)e .",5. Implicit Dynamics of Gradient Descent,[0],[0]
"Namely, if we denote the singular values of W (t)e ∈ Rk,d by σ1 . . .",5. Implicit Dynamics of Gradient Descent,[0],[0]
"σmax{k,d} ∈ R≥0 (by definition σr = 0",5. Implicit Dynamics of Gradient Descent,[0],[0]
"if r > min{k, d}), and corresponding left and right singular vectors by u1 . . .uk",5. Implicit Dynamics of Gradient Descent,[0],[0]
∈ Rk and v1 . .,5. Implicit Dynamics of Gradient Descent,[0],[0]
.vd,5. Implicit Dynamics of Gradient Descent,[0],[0]
"∈ Rd respectively, the eigenvectors of PW (t)e are:
vec(urv > r′) , r = 1 . . .",5. Implicit Dynamics of Gradient Descent,[0],[0]
"k , r ′ = 1 . . .",5. Implicit Dynamics of Gradient Descent,[0],[0]
"d
with corresponding eigenvalues:∑N j=1 σ 2N−jN r σ 2 j−1N r′ , r = 1 . . .",5. Implicit Dynamics of Gradient Descent,[0],[0]
"k , r ′ = 1 . . .",5. Implicit Dynamics of Gradient Descent,[0],[0]
"d
Proof.",5. Implicit Dynamics of Gradient Descent,[0],[0]
"The result readily follows from the properties of the Kronecker product – see Appendix A.2 for details.
",5. Implicit Dynamics of Gradient Descent,[0],[0]
"Claim 1 implies that in the end-to-end update rule of Equation 10, the transformation applied to the gradient dL 1
dW (We) is essentially a preconditioning, whose eigendirections and eigenvalues depend on the singular value decomposition of We.",5. Implicit Dynamics of Gradient Descent,[0],[0]
"The eigendirections are the rank-1 matrices urv>r′ , where ur and vr′ are left and right (respectively) singular vectors of We.",5. Implicit Dynamics of Gradient Descent,[0],[0]
The eigenvalue of urv>r′ is ∑N j=1 σ,5. Implicit Dynamics of Gradient Descent,[0],[0]
"2(N−j)/N r σ 2(j−1)/N r′ , where σr and σr′ are the singular values of We corresponding to ur and vr′ (respectively).",5. Implicit Dynamics of Gradient Descent,[0],[0]
"When N ≥ 2, an increase in σr or σr′ leads to
an increase in the eigenvalue corresponding to the eigendirection urv>r′ .",5. Implicit Dynamics of Gradient Descent,[0],[0]
"Qualitatively, this implies that the preconditioning favors directions that correspond to singular vectors whose presence in We is stronger.",5. Implicit Dynamics of Gradient Descent,[0],[0]
"We conclude that the effect of overparameterization, i.e. of replacing a classic linear model (depth-1 network) by a depth-N linear network, boils down to modifying gradient descent by promoting movement along directions that fall in line with the current location in parameter space.",5. Implicit Dynamics of Gradient Descent,[0],[0]
"A-priori, such a preference may seem peculiar – why should an optimization algorithm be sensitive to its location in parameter space?",5. Implicit Dynamics of Gradient Descent,[0],[0]
"Indeed, we generally expect sensible algorithms to be translation invariant, i.e. be oblivious to parameter value.",5. Implicit Dynamics of Gradient Descent,[0],[0]
"However, if one takes into account the common practice in deep learning of initializing weights near zero, the location in parameter space can also be regarded as the overall movement made by the algorithm.",5. Implicit Dynamics of Gradient Descent,[0],[0]
"We thus interpret our findings as indicating that overparameterization promotes movement along directions already taken by the optimization, and therefore can be seen as a form of acceleration.",5. Implicit Dynamics of Gradient Descent,[0],[0]
"This intuitive interpretation will become more concrete in the subsection that follows.
",5. Implicit Dynamics of Gradient Descent,[0],[0]
"A final point to make, is that the end-to-end update rule (Equation 10 or 11), which obviously depends on N – number of layers in the deep linear network, does not depend on the hidden widths n1 . . .",5. Implicit Dynamics of Gradient Descent,[0],[0]
nN−1 (see Section 4).,5. Implicit Dynamics of Gradient Descent,[0],[0]
"This implies that from an optimization perspective, overparameterizing using wide or narrow networks has the same effect – it is only the depth that matters.",5. Implicit Dynamics of Gradient Descent,[0],[0]
"Consequently, the acceleration of overparameterization can be attained at a minimal computational price, as we demonstrate empirically in Section 8.",5. Implicit Dynamics of Gradient Descent,[0],[0]
"To facilitate a straightforward presentation of our findings, we hereinafter focus on the special case where the optimized models have a single output, i.e. where k = 1.",5.1. Single Output Case,[0],[0]
"This corresponds, for example, to a binary (two-class) classification problem, or to the prediction of a numeric scalar property (regression).",5.1. Single Output Case,[0],[0]
It admits a particularly simple form for the end-to-end update rule of Equation 10: Claim 2.,5.1. Single Output Case,[0],[0]
"Assume k = 1, i.e. We ∈ R1,d.",5.1. Single Output Case,[0],[0]
"Then, the end-toend update rule in Equation 10 can be written as follows: W (t+1)e ← [ (1− ηλN) ·W (t)e (12)
−η‖W (t)e ‖ 2− 2N 2 ·
( dL1
dW (W (t) e )",5.1. Single Output Case,[0],[0]
"+
(N − 1) ·",5.1. Single Output Case,[0],[0]
"Pr W (t) e
{ dL1 dW (W (t) e ) })
where ‖·‖2− 2 N
2 stands for Euclidean norm raised to the power of 2− 2N , and PrW {·}, W ∈ R
1,d, is defined to be the projection operator onto the direction of W :
PrW : R1,d → R1,d (13)
",5.1. Single Output Case,[0],[0]
"PrW {V } :=
{ W ‖W‖2
V > · W‖W‖2 , W 6= 0 0 , W = 0
Proof.",5.1. Single Output Case,[0],[0]
"The result follows from the definition of a fractional power operator over matrices – see Appendix A.3.
",5.1. Single Output Case,[0],[0]
"Claim 2 implies that in the single output case, the effect of overparameterization (replacing classic linear model by depth-N linear network) on gradient descent is twofold: first, it leads to an adaptive learning rate schedule, by introducing the multiplicative factor ‖We‖2−2/N2 ; and second, it amplifies (by N )",5.1. Single Output Case,[0],[0]
the projection of the gradient on the direction of We.,5.1. Single Output Case,[0],[0]
"Recall that we view We not only as the optimized parameter, but also as the overall movement made in optimization (initialization is assumed to be near zero).",5.1. Single Output Case,[0],[0]
"Accordingly, the adaptive learning rate schedule can be seen as gaining confidence (increasing step sizes) when optimization moves farther away from initialization, and the gradient projection amplification can be thought of as a certain type of momentum that favors movement along the azimuth taken so far.",5.1. Single Output Case,[0],[0]
"These effects bear potential to accelerate convergence, as we illustrate qualitatively in Section 7, and demonstrate empirically in Section 8.",5.1. Single Output Case,[0],[0]
Adding a regularizer to the objective is a standard approach for improving optimization (though lately the term regularization is typically associated with generalization).,6. Overparametrization Effects Cannot Be Attained via Regularization,[0],[0]
"For example, AdaGrad was originally invented to compete with the best regularizer from a particular family.",6. Overparametrization Effects Cannot Be Attained via Regularization,[0],[0]
"The next theorem shows (for single output case) that the effects of overparameterization cannot be attained by adding a regularization term to the original training loss, or via any similar modification.",6. Overparametrization Effects Cannot Be Attained via Regularization,[0],[0]
"This is not obvious a-priori, as unlike many acceleration methods that explicitly maintain memory of past gradients, updates under overparametrization are by definition the gradients of something.",6. Overparametrization Effects Cannot Be Attained via Regularization,[0],[0]
"The assumptions in the theorem are minimal and also necessary, as one must rule-out the trivial counter-example of a constant training loss.
",6. Overparametrization Effects Cannot Be Attained via Regularization,[0],[0]
Theorem 2.,6. Overparametrization Effects Cannot Be Attained via Regularization,[0],[0]
"Assume dL 1
dW does not vanish at W = 0, and is continuous on some neighborhood around this point.",6. Overparametrization Effects Cannot Be Attained via Regularization,[0],[0]
"For a given N ∈ N, N > 2,1 define:
F (W ) := (14)
",6. Overparametrization Effects Cannot Be Attained via Regularization,[0],[0]
‖W‖2− 2 N 2 · ( dL1 dW (W ) + (N−1) ·,6. Overparametrization Effects Cannot Be Attained via Regularization,[0],[0]
"PrW { dL1 dW (W ) })
where PrW {·} is the projection given in Equation 13.",6. Overparametrization Effects Cannot Be Attained via Regularization,[0],[0]
"Then, there exists no function (of W ) whose gradient field is F (·).",6. Overparametrization Effects Cannot Be Attained via Regularization,[0],[0]
Proof.,6. Overparametrization Effects Cannot Be Attained via Regularization,[0],[0]
(sketch – full details in Appendix A.4),6. Overparametrization Effects Cannot Be Attained via Regularization,[0],[0]
"The proof uses the fundamental theorem for line integrals, which states that the integral of ∇g for any differentiable function g amounts to 0 along every closed curve.",6. Overparametrization Effects Cannot Be Attained via Regularization,[0],[0]
"Overparametrization changes gradient descent’s behavior: instead of following the original gradient dL 1
dW , it follows some other direction F (·) (see Equations 12 and 14) that
1 For the result to hold with N = 2, additional assumptions on L1(·) are required; otherwise any non-zero linear function L1(W )",6. Overparametrization Effects Cannot Be Attained via Regularization,[0],[0]
= WU> serves as a counter-example – it leads to a vector field F (·) that is the gradient of W 7→,6. Overparametrization Effects Cannot Be Attained via Regularization,[0],[0]
"‖W‖2 ·WU >.
is a function of the original gradient as well as the current point W .",6. Overparametrization Effects Cannot Be Attained via Regularization,[0],[0]
We think of this change as a transformation that maps one vector field φ(·) to another – Fφ(·): Fφ(W ),6. Overparametrization Effects Cannot Be Attained via Regularization,[0],[0]
"={ ‖W‖2− 2 N ( φ(W )+(N−1) 〈 φ(W ), W‖W‖ 〉 W ‖W‖ ) ,",6. Overparametrization Effects Cannot Be Attained via Regularization,[0],[0]
"W 6=0
0 ,W=0
Notice that for φ = dL 1
dW , we get exactly the vector field F (·) defined in theorem statement.",6. Overparametrization Effects Cannot Be Attained via Regularization,[0],[0]
The mapping φ 7→,6. Overparametrization Effects Cannot Be Attained via Regularization,[0],[0]
Fφ is linear.,6. Overparametrization Effects Cannot Be Attained via Regularization,[0],[0]
"Moreover, because of the linearity of line integrals, for any curve Γ, the functional φ 7→ ∫",6. Overparametrization Effects Cannot Be Attained via Regularization,[0],[0]
"Γ Fφ – a mapping of vector fields to scalars, is linear as well.
",6. Overparametrization Effects Cannot Be Attained via Regularization,[0],[0]
We show that F (·) contradicts the fundamental theorem for line integrals.,6. Overparametrization Effects Cannot Be Attained via Regularization,[0],[0]
"To do so, we construct a closed curve Γ=Γr,R for which the linear functional φ 7→ ∮ Γ Fφ does not vanish at φ=dL 1
dW .",6. Overparametrization Effects Cannot Be Attained via Regularization,[0],[0]
"Let e := dL1 dW (W=0)/‖ dL1
dW (W=0)‖, which is well-defined since by assumption dL 1
dW (W=0) 6= 0.",6. Overparametrization Effects Cannot Be Attained via Regularization,[0],[0]
"For r < Rwe define Γr,R := Γ1r,R → Γ2r,R → Γ3r,R → Γ4r,R as illustrated in Figure 1.",6. Overparametrization Effects Cannot Be Attained via Regularization,[0],[0]
"With the definition of Γr,R in place, we decompose dL 1
dW into a constant vector field κ≡",6. Overparametrization Effects Cannot Be Attained via Regularization,[0],[0]
"dL 1
dW (W=0) plus a residual ξ.",6. Overparametrization Effects Cannot Be Attained via Regularization,[0],[0]
"We explicitly compute the line integrals along Γ1r,R . .",6. Overparametrization Effects Cannot Be Attained via Regularization,[0],[0]
.Γ,6. Overparametrization Effects Cannot Be Attained via Regularization,[0],[0]
"4 r,R for Fκ, and derive bounds for Fξ.",6. Overparametrization Effects Cannot Be Attained via Regularization,[0],[0]
"This, along with the linearity of the functional φ 7→ ∫",6. Overparametrization Effects Cannot Be Attained via Regularization,[0],[0]
"Γ Fφ, provides a lower bound on the line integral of F (·) over Γr,R. We show the lower bound is positive as r,R→ 0, thus F (·) indeed contradicts the fundamental theorem for line integrals.",6. Overparametrization Effects Cannot Be Attained via Regularization,[0],[0]
"To this end, we showed that overparameterization (use of depth-N linear network in place of classic linear model) induces on gradient descent a particular preconditioning scheme (Equation 10 in general and 12 in the single output case), which can be interpreted as introducing some forms of momentum and adaptive learning rate.",7. Illustration of Acceleration,[0],[0]
"We now illustrate qualitatively, on a very simple hypothetical learning problem, the potential of these to accelerate optimization.
",7. Illustration of Acceleration,[0],[0]
"Consider the task of linear regression, assigning to vectors in R2 labels in R. Suppose that our training set consists of two points in R2 × R: ([1, 0]>, y1) and ([0, 1]>, y2).",7. Illustration of Acceleration,[0],[0]
"Assume also that the loss function of interest is `p, p ∈ 2N: `p(ŷ, y) = 1 p (ŷ",7. Illustration of Acceleration,[0],[0]
"− y)
",7. Illustration of Acceleration,[0],[0]
p.,7. Illustration of Acceleration,[0],[0]
Denoting the learned parameter by w =,7. Illustration of Acceleration,[0],[0]
"[w1, w2] >, the overall training loss can be written as:2
2 We omit the averaging constant 1 2 for conciseness.
",7. Illustration of Acceleration,[0],[0]
"L(w1, w2) = 1 p (w1 − y1)",7. Illustration of Acceleration,[0],[0]
p + 1p (w2 − y2),7. Illustration of Acceleration,[0],[0]
"p
With fixed learning rate η > 0",7. Illustration of Acceleration,[0],[0]
"(weight decay omitted for simplicity), gradient descent over L(·) gives:
w (t+1) i",7. Illustration of Acceleration,[0],[0]
← [ w (t) i,7. Illustration of Acceleration,[0],[0]
− η(w (t),7. Illustration of Acceleration,[0],[0]
"i − yi) p−1 , i = 1, 2
Changing variables per ∆i = wi − yi, we have: ∆
(t+1) i ←[ ∆ (t) i ( 1− η(∆(t)i )",7. Illustration of Acceleration,[0],[0]
"p−2) , i = 1, 2 (15)",7. Illustration of Acceleration,[0],[0]
"Assuming the original weights w1 and w2 are initialized near zero, ∆1 and ∆2 start off at −y1 and −y2 respectively, and will eventually reach the optimum ∆∗1 = ∆ ∗ 2 = 0",7. Illustration of Acceleration,[0],[0]
"if the learning rate is small enough to prevent divergence: η < 2
yp−2i , i = 1, 2
Suppose now that the problem is ill-conditioned, in the sense that y1 y2.",7. Illustration of Acceleration,[0],[0]
If p = 2 this has no effect on the bound for η.3,7. Illustration of Acceleration,[0],[0]
"If p > 2 the learning rate is determined by y1, leading ∆2 to converge very slowly.",7. Illustration of Acceleration,[0],[0]
"In a sense, ∆2 will suffer from the fact that there is no “communication” between the coordinates (this will actually be the case not just with gradient descent, but with most algorithms typically used in large-scale settings – AdaGrad, Adam, etc.).
",7. Illustration of Acceleration,[0],[0]
"Now consider the scenario where we optimize L(·) via overparameterization, i.e. with the update rule in Equation 12 (single output).",7. Illustration of Acceleration,[0],[0]
"In this case the coordinates are coupled, and as ∆1 gets small (w1 gets close to y1), the learning rate is effectively scaled by y2− 2 N
1 (in addition to a scaling by N in coordinate 1 only), allowing (if y1>1) faster convergence of ∆2.",7. Illustration of Acceleration,[0],[0]
"We thus have the luxury of temporarily slowing down ∆2 to ensure that ∆1 does not diverge, with the latter speeding up the former as it reaches safe grounds.",7. Illustration of Acceleration,[0],[0]
"In Appendix B we consider a special case and formalize this intuition, deriving a concrete bound for the acceleration of overparameterization.",7. Illustration of Acceleration,[0],[0]
"Our analysis (Section 5) suggests that overparameterization – replacement of a classic linear model by a deep linear network, induces on gradient descent a certain preconditioning scheme.",8. Experiments,[0],[0]
"We qualitatively argued (Section 7) that in some cases, this preconditioning may accelerate convergence.",8. Experiments,[0],[0]
"In this section we put these claims to the test, through a series of empirical evaluations based on TensorFlow toolbox (Abadi et al. (2016)).",8. Experiments,[0],[0]
"For conciseness, many of the details behind our implementation are deferred to Appendix C.
We begin by evaluating our analytically-derived preconditioning scheme – the end-to-end update rule in Equation 10.",8. Experiments,[0],[0]
"Our objective in this experiment is to ensure that our analysis, continuous in nature and based on a particular assumption on weight initialization (Equation 7), is indeed applicable to practical scenarios.",8. Experiments,[0],[0]
"We focus on the single output
3 Optimal learning rate for gradient descent on quadratic objective does not depend on current parameter value (cf.",8. Experiments,[0],[0]
"Goh (2017)).
case, where the update-rule takes on a particularly simple (and efficiently implementable) form – Equation 12.",8. Experiments,[0],[0]
"The dataset chosen was UCI Machine Learning Repository’s “Gas Sensor Array Drift at Different Concentrations” (Vergara et al., 2012; Rodriguez-Lujan et al., 2014).",8. Experiments,[0],[0]
"Specifically, we used the dataset’s “Ethanol” problem – a scalar regression task with 2565 examples, each comprising 128 features (one of the largest numeric regression tasks in the repository).",8. Experiments,[0],[0]
"As training objectives, we tried both `2 and `4 losses.",8. Experiments,[0],[0]
Figure 2 shows convergence (training objective per iteration) of gradient descent optimizing depth-2 and depth3,8. Experiments,[0],[0]
"linear networks, against optimization of a single layer model using the respective preconditioning schemes (Equation 12 with N = 2, 3).",8. Experiments,[0],[0]
"As can be seen, the preconditioning schemes reliably emulate deep network optimization, suggesting that, at least in some cases, our analysis indeed captures practical dynamics.
",8. Experiments,[0],[0]
"Alongside the validity of the end-to-end update rule, Figure 2 also demonstrates the negligible effect of network width on convergence, in accordance with our analysis (see Section 5).",8. Experiments,[0],[0]
"Specifically, it shows that in the evaluated setting, hidden layers of size 1 (scalars) suffice in order for the essence of overparameterization to fully emerge.",8. Experiments,[0],[0]
"Unless otherwise indicated, all results reported hereinafter are based on this configuration, i.e. on scalar hidden layers.",8. Experiments,[0],[0]
"The computational toll associated with overparameterization will thus be virtually non-existent.
",8. Experiments,[0],[0]
"As a final observation on Figure 2, notice that it exhibits faster convergence with a deeper network.",8. Experiments,[0],[0]
"This however does not serve as evidence in favor of acceleration by depth, as we did not set learning rates optimally per model (simply used the common choice of 10−3).",8. Experiments,[0],[0]
"To conduct a fair comparison between the networks, and more importantly, between them and a classic single layer model, multiple learning rates were tried, and the one giving fastest convergence was taken on a per-model basis.",8. Experiments,[0],[0]
Figure 3 shows the results of this experiment.,8. Experiments,[0],[0]
"As can be seen, convergence of deeper
networks is (slightly) slower in the case of `2 loss.",8. Experiments,[0],[0]
This falls in line with the findings of Saxe et al. (2013).,8. Experiments,[0],[0]
"In stark contrast, and on par with our qualitative analysis in Section 7, is the fact that with `4 loss adding depth significantly accelerated convergence.",8. Experiments,[0],[0]
"To the best of our knowledge, this provides first empirical evidence to the fact that depth, even without any gain in expressiveness, and despite introducing non-convexity to a formerly convex problem, can lead to favorable optimization.
",8. Experiments,[0],[0]
"In light of the speedup observed with `4 loss, it is natural to ask how the implicit acceleration of depth compares against explicit methods for acceleration and adaptive learning.",8. Experiments,[0],[0]
"Figure 4-left shows convergence of a depth-3 network (optimized with gradient descent) against that of a single layer model optimized with AdaGrad (Duchi et al., 2011) and AdaDelta (Zeiler, 2012).",8. Experiments,[0],[0]
"The displayed curves correspond to optimal learning rates, chosen individually via grid search.",8. Experiments,[0],[0]
"Quite surprisingly, we find that in this specific setting, overparameterizing, thereby turning a convex problem non-convex, is a more effective optimization strategy than carefully designed algorithms tailored for convex problems.",8. Experiments,[0],[0]
"We note that this was not observed with all algorithms – for example Adam (Kingma & Ba, 2014) was considerably faster than overparameterization.",8. Experiments,[0],[0]
"However, when introducing overparameterization simultaneously with Adam (a setting we did not theoretically analyze), further acceleration is attained – see Figure 4-right.",8. Experiments,[0],[0]
"This suggests that at least in some cases, not only plain gradient descent benefits from depth, but also more elaborate algorithms commonly employed in state of the art applications.
",8. Experiments,[0],[0]
An immediate question arises at this point.,8. Experiments,[0],[0]
"If depth indeed accelerates convergence, why not add as many layers as one can computationally afford?",8. Experiments,[0],[0]
"The reason, which is actually apparent in our analysis, is the so-called vanishing gradient problem.",8. Experiments,[0],[0]
"When training a very deep network (large N ), while initializing weights to be small, the end-to-end matrix We (Equation 5) is extremely close to zero, severely attenuating gradients in the preconditioning scheme (Equation 10).",8. Experiments,[0],[0]
"A possible approach for alleviating this issue is to initialize weights to be larger, yet small enough such that the
end-to-end matrix does not “explode”.",8. Experiments,[0],[0]
"The choice of identity (or near identity) initialization leads to what is known as linear residual networks (Hardt & Ma, 2016), akin to the successful residual networks architecture (He et al., 2015) commonly employed in deep learning.",8. Experiments,[0],[0]
"Notice that identity initialization satisfies the condition in Equation 7, rendering the end-to-end update rule (Equation 10) applicable.",8. Experiments,[0],[0]
"Figure 5-left shows convergence, under gradient descent, of a single layer model against deeper networks than those evaluated before – depths 4 and 8.",8. Experiments,[0],[0]
"As can be seen, with standard, near-zero initialization, the depth-4 network starts making visible progress only after about 65K iterations, whereas the depth-8 network seems stuck even after 100K iterations.",8. Experiments,[0],[0]
"In contrast, under identity initialization, both networks immediately make progress, and again depth serves as an implicit accelerator.
",8. Experiments,[0],[0]
"As a final sanity test, we evaluate the effect of overparameterization on optimization in a non-idealized (yet simple) deep learning setting.",8. Experiments,[0],[0]
"Specifically, we experiment with the convolutional network tutorial for MNIST built into TensorFlow,4 which includes convolution, pooling and dense layers, ReLU non-linearities, stochastic gradient descent with momentum, and dropout (Srivastava et al., 2014).",8. Experiments,[0],[0]
We introduced overparameterization by simply placing two matrices in succession instead of the matrix in each dense layer.,8. Experiments,[0],[0]
"Here, as opposed to previous experiments, widths of the newly formed hidden layers were not set to 1, but rather to the minimal values that do not deteriorate expressiveness (see Appendix C).",8. Experiments,[0],[0]
"Overall, with an addition of roughly 15% in number of parameters, optimization has accelerated considerably – see Figure 5-right.",8. Experiments,[0],[0]
The displayed results were obtained with the hyperparameter settings hardcoded into the tutorial.,8. Experiments,[0],[0]
"We have tried alternative settings (varying learning rates and standard deviations of initializations – see
4 https://github.com/tensorflow/models/ tree/master/tutorials/image/mnist
Appendix C), and in all cases observed an outcome similar to that in Figure 5-right – overparameterization led to significant speedup.",8. Experiments,[0],[0]
"Nevertheless, as reported above for linear networks, it is likely that for non-linear networks the effect of depth on optimization is mixed – some settings accelerate by it, while others do not.",8. Experiments,[0],[0]
Comprehensive characterization of the cases in which depth accelerates optimization warrants much further study.,8. Experiments,[0],[0]
We hope our work will spur interest in this avenue of research.,8. Experiments,[0],[0]
"Through theory and experiments, we demonstrated that overparameterizing a neural network by increasing its depth can accelerate optimization, even on very simple problems.
",9. Conclusion,[0],[0]
"Our analysis of linear neural networks, the subject of various recent studies, yielded a new result: for these models, overparameterization by depth can be understood as a preconditioning scheme with a closed form description (Theorem 1 and the claims thereafter).",9. Conclusion,[0],[0]
The preconditioning may be interpreted as a combination between certain forms of adaptive learning rate and momentum.,9. Conclusion,[0],[0]
"Given that it depends on network depth but not on width, acceleration by overparameterization can be attained at a minimal computational price, as we demonstrate empirically in Section 8.
",9. Conclusion,[0],[0]
"Clearly, complete theoretical analysis for non-linear networks will be challenging.",9. Conclusion,[0],[0]
"Empirically however, we showed that the trivial idea of replacing an internal weight matrix by a product of two can significantly accelerate optimization, with absolutely no effect on expressiveness (Figure 5-right).
",9. Conclusion,[0],[0]
"The fact that gradient descent over classic convex problems such as linear regression with `p loss, p > 2, can accelerate from transitioning to a non-convex overparameterized objective, does not coincide with conventional wisdom, and provides food for thought.",9. Conclusion,[0],[0]
"Can this effect be rigorously quantified, similarly to analyses of explicit acceleration methods such as momentum or adaptive regularization (AdaGrad)?",9. Conclusion,[0],[0]
"Sanjeev Arora’s work is supported by NSF, ONR, Simons Foundation, Schmidt Foundation, Mozilla Research, Amazon Research, DARPA and SRC.",Acknowledgments,[0],[0]
Elad Hazan’s work is supported by NSF grant 1523815 and Google Brain.,Acknowledgments,[0],[0]
"Nadav Cohen is a member of the Zuckerman Israeli Postdoctoral Scholars Program, and is supported by Eric and Wendy Schmidt.",Acknowledgments,[0],[0]
Conventional wisdom in deep learning states that increasing depth improves expressiveness but complicates optimization.,abstractText,[0],[0]
"This paper suggests that, sometimes, increasing depth can speed up optimization.",abstractText,[0],[0]
"The effect of depth on optimization is decoupled from expressiveness by focusing on settings where additional layers amount to overparameterization – linear neural networks, a wellstudied model.",abstractText,[0],[0]
"Theoretical analysis, as well as experiments, show that here depth acts as a preconditioner which may accelerate convergence.",abstractText,[0],[0]
"Even on simple convex problems such as linear regression with `p loss, p > 2, gradient descent can benefit from transitioning to a non-convex overparameterized objective, more than it would from some common acceleration schemes.",abstractText,[0],[0]
We also prove that it is mathematically impossible to obtain the acceleration effect of overparametrization via gradients of any regularizer.,abstractText,[0],[0]
On the Optimization of Deep Networks: Implicit Acceleration by Overparameterization,title,[0],[0]
"√ 2n, over-parametrization
enables local search algorithms to find a globally optimal solution for general smooth and convex loss functions. Further, despite that the number of parameters may exceed the sample size, using theory of Rademacher complexity, we show with weight decay, the solution also generalizes well if the data is sampled from a regular distribution such as Gaussian. To prove when k ≥ √ 2n, the loss function has benign landscape properties, we adopt an idea from smoothed analysis, which may have other applications in studying loss surfaces of neural networks.",text,[0],[0]
"Neural networks have achieved a remarkable impact on many applications such computer vision, reinforcement learning and natural language processing.",1. Introduction,[0],[0]
"Though neural networks are successful in practice, their theoretical properties are not yet well understood.",1. Introduction,[0],[0]
"Specifically, there are two intriguing empirical observations that existing theories cannot explain.
",1. Introduction,[0],[0]
"• Optimization: Despite the highly non-convex nature of the objective function, simple first-order algorithms like stochastic gradient descent are able to minimize the training loss of neural networks.",1. Introduction,[0],[0]
"Researchers have conjectured that the use of over-parametrization (Livni et al., 2014; Safran and Shamir, 2017) is the primary
1Machine Learning Department, Carnegie Mellon University 2Department of Data Sciences and Operations, University of Southern California.",1. Introduction,[0],[0]
"Correspondence to: Simon S. Du <ssdu@cs.cmu.edu>.
Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
reason why local search algorithms can achieve low training error.",1. Introduction,[0],[0]
"The intuition is over-parametrization alters the loss function to have a large manifold of globally optimal solutions, which in turn allows local search algorithms to more easily find a global optimal solution.
",1. Introduction,[0],[0]
"• Generalization: From the statistical point of view, over-parametrization may hinder effective generalization, since it greatly increases the number of parameters to the point of having number of parameters exceed the sample size.",1. Introduction,[0],[0]
"To address this, practitioners often use explicit forms of regularization such as weight decay, dropout, or early stopping to improve generalization.",1. Introduction,[0],[0]
"However in the non-convex setting, theoretically, we do not have a good quantitative understanding on how these regularizations help generalization for neural network models.
",1. Introduction,[0],[0]
"In this paper, we provide new theoretical insights into the optimization landscape and generalization ability of overparametrized neural networks.",1. Introduction,[0],[0]
"Specifically we consider the neural network of the following form:
f(x,W) = k∑ j=1 aiσ (〈wj ,x〉) .",1. Introduction,[0],[0]
"(1)
In the above x ∈",1. Introduction,[0],[0]
"Rd is the input vector, W ∈ Rd×k with wj ∈ Rd denotes the j-th row of W and ai’s are the weights in the second layer.",1. Introduction,[0],[0]
Finally σ (·) : R → R denotes the activation function applied to each hidden node.,1. Introduction,[0],[0]
"When the neural network is over-parameterized, the number of hidden notes k can be very large compared with input dimension d or the number of training samples.
",1. Introduction,[0],[0]
"In our setting, we fix the second layer to be a = (1, . . .",1. Introduction,[0],[0]
", 1).",1. Introduction,[0],[0]
"Although it is simpler than the case where the second layer is not fixed, the effect of over-parameterization can be studied in this setting as well because we do not have any restriction on the number of hidden nodes.
",1. Introduction,[0],[0]
We focus on quadratic activation function σ (z) = z2.,1. Introduction,[0],[0]
"Though quadratic activations are rarely used in practice, stacking multiple such two-layer blocks can be used to simulate higher-order polynomial neural networks and sigmodial
activated neural networks (Livni et al., 2014; Soltani and Hegde, 2017).
",1. Introduction,[0],[0]
"In practice, we have n training samples {xi, yi}ni=1 and solve the following optimization problem to learn a neural network
min W
1
n n∑ i=1",1. Introduction,[0],[0]
"` (f(xi,W), yi)
where `(·, ·) is some loss function such as `2 or logistic loss.",1. Introduction,[0],[0]
"For gradient descent we use the following update
W←W",1. Introduction,[0],[0]
− η n∑ i=1,1. Introduction,[0],[0]
"∇W` (f(xi), yi)
where η is the step size.
",1. Introduction,[0],[0]
"To improve the generalization ability, we often add explicit regularization.",1. Introduction,[0],[0]
"In this paper, we focus on a particular regularization technique, weight decay for which we slightly change the gradient descent algorithm to
W←W",1. Introduction,[0],[0]
− η n∑ i=1,1. Introduction,[0],[0]
"∇W` (f(xi,W), yi)− ηλW.
where λ is the decay rate.",1. Introduction,[0],[0]
"Note this algorithm is equivalent to applying the gradient descent algorithm on the regularized loss
min W
L (W)",1. Introduction,[0],[0]
"= 1
n n∑ i=1",1. Introduction,[0],[0]
"` (f(xi), yi) + λ 2 ‖W‖2F .",1. Introduction,[0],[0]
"(2)
In this setup, we make the following theoretical contributions to explain why over-parametrization helps optimization and still allows for generalization.",1. Introduction,[0],[0]
Over-parametrization Helps Optimization.,1.1. Main Contributions,[0],[0]
We analyze two kinds of over-parameterization.,1.1. Main Contributions,[0],[0]
"First we show that for
k ≥ d,
then all local minima in Problem (2) is global and all saddle points are strict.",1.1. Main Contributions,[0],[0]
"This properties together with recent algorithmic advances in non-convex optimization (Lee et al., 2016) imply gradient descent can find a globally optimal solution with random initialization.",1.1. Main Contributions,[0],[0]
"This is a minor generalization of results in (Soltanolkotabi et al., 2017) which only includes `2 loss, and (Haeffele and Vidal, 2015; Haeffele et al., 2014) which only include k ≥ d+ 1.
",1.1. Main Contributions,[0],[0]
"Second, we consider another form of over-parametrization,
k(k + 1)
",1.1. Main Contributions,[0],[0]
2 >,1.1. Main Contributions,[0],[0]
"n.
This condition on the amount of over-parameterization is much milder than k ≥ n, a condition used in many previous papers (Nguyen and Hein, 2017a;b).",1.1. Main Contributions,[0],[0]
"Further in practice, k(k + 1)/2 > n is a much milder requirement than k ≥ d, since if k ≈ √ 2n and n << d2 then",1.1. Main Contributions,[0],[0]
k,1.1. Main Contributions,[0],[0]
<,1.1. Main Contributions,[0],[0]
<,1.1. Main Contributions,[0],[0]
d.,1.1. Main Contributions,[0],[0]
"In this setting, we consider the perturbed version of the Problem (2):
min W
LC (W) = 1
n n∑ i=1",1.1. Main Contributions,[0],[0]
"` (f(xi), yi) + λ 2 ‖W‖2F + 〈C,W>W〉 (3)
where C is a random positive semidefinite matrix with arbitrarily small Frobenius norm.",1.1. Main Contributions,[0],[0]
"We show that if k(k+1)2 > n, Problem (3) also has the desired properties that all local minima are global and all saddle points are strict with probability 1.",1.1. Main Contributions,[0],[0]
"Since C has small Frobenius norm, the optimal value of Problem (3) is very close to that of Problem (2).",1.1. Main Contributions,[0],[0]
"See Section 3 for the precise statement.
",1.1. Main Contributions,[0],[0]
"To prove this surprising fact, we bring forward ideas from smoothed analysis in constructing the perturbed loss function (3), which we believe is useful for analyzing the landscape of non-convex losses.
",1.1. Main Contributions,[0],[0]
Weight-decay Helps Generalization.,1.1. Main Contributions,[0],[0]
"We show because of weight-decay, the optimal solution of Problem (2) also generalizes well.",1.1. Main Contributions,[0],[0]
"The major observation is weight-decay ensures the solution of Problem (2) has low Frobenius norm, which is equivalent to matrix W>W having low nuclear norm (Srebro et al., 2005).",1.1. Main Contributions,[0],[0]
This observation allows us to use theory of Rademacher complexity to directly obtain quantitative generalization bounds.,1.1. Main Contributions,[0],[0]
"Our theory applies to a wide range of data distribution and in particular, does not need to assume the model is realizable.",1.1. Main Contributions,[0],[0]
"Further, the generalization bound does not depend on the number of epochs SGD runs or the number of hidden nodes.
",1.1. Main Contributions,[0],[0]
"To sum up, in this paper we justify the following folklore.
",1.1. Main Contributions,[0],[0]
"Over-parametrization allows us to find global optima and with weight decay, the solution also generalizes well.",1.1. Main Contributions,[0],[0]
This paper is organized as follows.,1.2. Organization,[0],[0]
In Section 2 we introduce necessary background and definitions.,1.2. Organization,[0],[0]
In Section 3 we present our main theorems on why over-parametrization helps optimization when k ≥ d or k(k+1)2 > n.,1.2. Organization,[0],[0]
"In Section 4, we give quantitative generalization bounds to explain why weight decay helps generalization in the presence of over-parametrization.",1.2. Organization,[0],[0]
"In Section 5, we prove our main theorems.",1.2. Organization,[0],[0]
We conclude and list future works in Section 6.,1.2. Organization,[0],[0]
"Neural networks have enjoyed great success in many practical applications (Krizhevsky et al., 2012; Dauphin et al., 2016; Silver et al., 2016).",1.3. Related Works,[0],[0]
"To explain this success, many works have studied the expressiveness of neural networks.",1.3. Related Works,[0],[0]
"The expressive ability of shallow neural network dates back to 90s (Barron, 1994).",1.3. Related Works,[0],[0]
"Recent results give more refined analysis on deeper models (Bölcskei et al., 2017; Telgarsky, 2016; Wiatowski et al., 2017).
",1.3. Related Works,[0],[0]
"However, from the point of view of learning theory, it is well known that training a neural network is hard in the worst case (Blum and Rivest, 1989).",1.3. Related Works,[0],[0]
"Despite the worst-case pessimism, local search algorithms such as gradient descent are very successful in practice.",1.3. Related Works,[0],[0]
"With some additional assumptions, many works tried to design algorithms that provably learn a neural network (Goel et al., 2016; Sedghi and Anandkumar, 2014; Janzamin et al., 2015).",1.3. Related Works,[0],[0]
"However these algorithms are not gradient-based and do not provide insight on why local search algorithm works well.
",1.3. Related Works,[0],[0]
"Focusing on gradient-based algorithms, a line of research (Tian, 2017; Brutzkus and Globerson, 2017; Zhong et al., 2017a;b; Li and Yuan, 2017; Du et al., 2017b;c) analyzed the behavior of (stochastic) gradient descent with a structural assumption on the input distribution.",1.3. Related Works,[0],[0]
"The major drawback of these papers is that they all focus on the regression setting with least-squares loss and further assume the model is realizable meaning the label is the output of a neural network plus a zero mean noise, which is unrealistic.",1.3. Related Works,[0],[0]
"In the case of more than one hidden unit, the papers of (Li and Yuan, 2017; Zhong et al., 2017b) further require a stringent initialization condition to recover the true parameters.
",1.3. Related Works,[0],[0]
Finding the optimal weights of a neural network is nonconvex problem.,1.3. Related Works,[0],[0]
"Recently, researchers found that if the objective functions satisfy the following two key properties: (1) all local minima are global and (2) all saddle points and local maxima are strict, then first order method like gradient descent (Ge et al., 2015; Jin et al., 2017; Levy, 2016; Du et al., 2017a; Lee et al., 2016) can find a global minimum.
",1.3. Related Works,[0],[0]
"This motivates the research of studying the landscape of neural networks (Kawaguchi, 2016; Choromanska et al., 2015; Freeman and Bruna, 2016; Zhou and Feng, 2017; Nguyen and Hein, 2017a;b; Ge et al., 2017; Safran and Shamir, 2017; Soltanolkotabi et al., 2017; Poston et al., 1991; Haeffele and Vidal, 2015; Haeffele et al., 2014; Soudry and Hoffer, 2017)",1.3. Related Works,[0],[0]
"In particular, Haeffele and Vidal (2015); Poston et al. (1991); Nguyen and Hein (2017a;b)studied the effect of over-parameterization on training the neural networks.",1.3. Related Works,[0],[0]
"These results require a large amount of overparameterization that the width of one of the hidden layers has to be greater than the number of training examples, which is unrealistic in commonly used neural networks.",1.3. Related Works,[0],[0]
"Re-
cently, Soltanolkotabi et al. (2017) showed for shallow neural networks, the number of hidden nodes is only required to be larger or equal to the input dimension for `2-loss.",1.3. Related Works,[0],[0]
"In comparison, our theorems work for general loss functions with regularization under the same assumption.",1.3. Related Works,[0],[0]
"Further we also propose a new form of over-parameterization, namely as long as k ≥ √ 2n, the loss function also admits a benign landscape.
",1.3. Related Works,[0],[0]
We now turn our attention to generalization ability of learned neural networks.,1.3. Related Works,[0],[0]
"It is well known that the classical learning theory cannot explain the generalization ability because VCdimension of neural networks is large (Harvey et al., 2017; Zhang et al., 2016).",1.3. Related Works,[0],[0]
"A line of research tries to explain this phenomenon by studying the implicit regularization from stochastic gradient descent algorithm (Hardt et al., 2015; Pensia et al., 2018; Mou et al., 2017; Brutzkus et al., 2017; Li et al., 2017).",1.3. Related Works,[0],[0]
"However, the generalization bounds of these papers often depend on the number of epochs SGD runs, which is large in practice.",1.3. Related Works,[0],[0]
"Another direction is to study the generalization ability based on the norms of weight matrices in neural networks (Neyshabur et al., 2015; 2017a;b; Bartlett et al., 2017; Liang et al., 2017; Golowich et al., 2017; Dziugaite and Roy, 2017; Wu et al., 2017).",1.3. Related Works,[0],[0]
"Our theorem on generalization ability also uses this idea but is more specialized to the network architecture (1).
",1.3. Related Works,[0],[0]
"After the initial submission of this manuscript, we became aware of concurrent work of (Bhojanapalli et al., 2018), which also considered the smoothed analysis technique to solve semi-definite programs in penalty form.",1.3. Related Works,[0],[0]
"The mathematical techniques in our work and (Bhojanapalli et al., 2018) are similar, but the focus is on two distinct problems of solving semi-definite programs and quadratic activation neural networks.",1.3. Related Works,[0],[0]
We use bold-faced letters for vectors and matrices.,2. Preliminaries,[0],[0]
"For a vector v, we use ‖v‖2 to denote the Euclidean norm.",2. Preliminaries,[0],[0]
"For a matrix M, we denote ‖M‖2 the spectral norm and ‖M‖F the Frobenius norm.",2. Preliminaries,[0],[0]
"We let N (M) to denote the left nullspace of M, i.e.
N (M) = { v : v>M = 0 } .
",2. Preliminaries,[0],[0]
We use Σ (M) to denote the set of matrices with Frobenius norm bounded by M and Σ1 (1) to denote the set of rank-1 matrices with spectral norm bounded by 1.,2. Preliminaries,[0],[0]
"We also denote Sd the set of d×d symmetric positive semidefinite matrices.
",2. Preliminaries,[0],[0]
"In this paper, we characterize the landscape of overparameterized neural networks.",2. Preliminaries,[0],[0]
More specifically we study the properties of critical points of empirical loss.,2. Preliminaries,[0],[0]
"Here for a loss function L (W), a critical point W∗ satisfies ∇L (W∗) = 0.",2. Preliminaries,[0],[0]
"A critical point can be a local minimum or
a saddle point.1",2. Preliminaries,[0],[0]
"If W∗ is a local minimum, then there is a neighborhood O around W∗ such that L (W∗) ≤",2. Preliminaries,[0],[0]
L (W) for all W ∈ O.,2. Preliminaries,[0],[0]
"If W∗ is a saddle point, then for all neighborhood O around W∗, there is a W ∈ O such that L (W)",2. Preliminaries,[0],[0]
"< L (W∗).
",2. Preliminaries,[0],[0]
"Ideally, we would like a loss function that satisfies the following two geometric properties.
",2. Preliminaries,[0],[0]
Property 2.1 (All local minima are global).,2. Preliminaries,[0],[0]
"If W∗ is a local minimum of L (·) it is also the global minimum, i.e., W∗ ∈ argminWL",2. Preliminaries,[0],[0]
(W).,2. Preliminaries,[0],[0]
Property 2.2 (All saddles are strict).,2. Preliminaries,[0],[0]
"At a saddle point Ws, there is a direction U ∈ Rk×d such that
vect (U)>∇2L (Ws) vect (U) < 0.
",2. Preliminaries,[0],[0]
"If a loss function L (·) satisfies Property 2.1 and Property 2.2, recent algorithmic advances in non-convex optimization show randomly initialized gradient descent algorithm or perturbed gradient descent can find a global minimum (Lee et al., 2016; Ge et al., 2015; Jin et al., 2017; Du et al., 2017a).
",2. Preliminaries,[0],[0]
"Lastly, standard applications of Rademacher complexity theory will be used to derive generalization bounds.
",2. Preliminaries,[0],[0]
Definition 2.1 (Definition of Rademacher Complexity).,2. Preliminaries,[0],[0]
"Given a sample S = (x1, . . .",2. Preliminaries,[0],[0]
",xn), the empirical Rademacher complexity of a function class F is defined as
RS (F) = 1
n",2. Preliminaries,[0],[0]
"Eσ [ sup f∈F n∑ i=1 σif(xi) ]
where σ =",2. Preliminaries,[0],[0]
"(σ1, . . .",2. Preliminaries,[0],[0]
", σm) are independent random varaibles drawn from the Rademacher distribution, i.e., P (σi = 1)",2. Preliminaries,[0],[0]
"= P (σi = −1) = 1/2 for i = 1, . . .",2. Preliminaries,[0],[0]
", n.",2. Preliminaries,[0],[0]
In this section we present our main results on explaining why over-parametrization helps local search algorithms find a global optimal solution.,3. Overparametrization Helps Optimization,[0],[0]
"We consider two kinds of overparameterization, k ≥ d and k(k+1)2 > n.",3. Overparametrization Helps Optimization,[0],[0]
We begin with the simpler case when k ≥ d. Theorem 3.1.,3. Overparametrization Helps Optimization,[0],[0]
"Assume we have an arbitrary data set of input/label pairs xi ∈ Rd and yi ∈ R for i = 1, . . .",3. Overparametrization Helps Optimization,[0],[0]
", n and a convex C2 loss `(ŷ, y).",3. Overparametrization Helps Optimization,[0],[0]
"Consider a neural network of the form f(x,W) =",3. Overparametrization Helps Optimization,[0],[0]
∑k j=1 σ,3. Overparametrization Helps Optimization,[0],[0]
( w>j x ) with σ (z) = z2 and W ∈ Rk×d denoting the weights connecting input to hidden layers.,3. Overparametrization Helps Optimization,[0],[0]
Suppose k ≥,3. Overparametrization Helps Optimization,[0],[0]
d.,3. Overparametrization Helps Optimization,[0],[0]
"Then, the training loss as a
1We do not differentiate between saddle points and local maxima in this paper.
function of weight W of the hidden layers
L (W) = 1
2n ` (f(xi,W), yi) +
λ 2 ‖W‖2F
obeys Property 2.1 and Property 2.2.
",3. Overparametrization Helps Optimization,[0],[0]
"The above result states that given an arbitrary data set, the optimization landscape has benign properties that facilitate finding globally optimal neural networks.",3. Overparametrization Helps Optimization,[0],[0]
"In particular, by setting the last layer to be the average pooling layer, all local minima are global minima and all saddles have a direction of negative curvature.",3. Overparametrization Helps Optimization,[0],[0]
"This in turn implies that gradient descent on the first layer weights, when initialized at random, converges to a global optimum.",3. Overparametrization Helps Optimization,[0],[0]
"These desired properties hold as long as the hidden layer is wide (k ≥ d).
",3. Overparametrization Helps Optimization,[0],[0]
An interesting and perhaps surprising aspect of Theorem 3.1 is its generality.,3. Overparametrization Helps Optimization,[0],[0]
"It applies to arbitrary data set of any size with any convex differentiable loss function.
",3. Overparametrization Helps Optimization,[0],[0]
Now we consider the second case when k(k+1)2 > n.,3. Overparametrization Helps Optimization,[0],[0]
"As mentioned earlier, in practice this is often a milder requirement than k ≥ d, and one of the main novelties of this paper.
",3. Overparametrization Helps Optimization,[0],[0]
Theorem 3.2.,3. Overparametrization Helps Optimization,[0],[0]
"Assume we have an arbitrary data set of input/label pairs xi ∈ Rd and yi ∈ R for i = 1, . . .",3. Overparametrization Helps Optimization,[0],[0]
",",3. Overparametrization Helps Optimization,[0],[0]
"n, and a convex C2 loss `(ŷ, y).",3. Overparametrization Helps Optimization,[0],[0]
Consider a neural network of the form f(x) =,3. Overparametrization Helps Optimization,[0],[0]
∑k j=1 σ,3. Overparametrization Helps Optimization,[0],[0]
( w>j x ) with σ (z) = z2 and W ∈ Rk×d denoting the weights connecting input to hidden layers.,3. Overparametrization Helps Optimization,[0],[0]
"Suppose k(k+1)2 > n, k < d and C is a random positive semidefinite matrix with ‖C‖F ≤ δ",3. Overparametrization Helps Optimization,[0],[0]
whose distribution is absolutely continuous with respect to Lebesgue measure.,3. Overparametrization Helps Optimization,[0],[0]
"Then, the training loss as a function of weight W of the hidden layers
L (W) = 1
2n ` (f(xi), yi) +
λ 2 ‖W‖2F + 〈C,W >W〉 (4)
obeys Property 2.1 and Property 2.2.",3. Overparametrization Helps Optimization,[0],[0]
"Further, any global optimal solution Ŵof Problem (4) satisfies
1
2n n∑ i=1",3. Overparametrization Helps Optimization,[0],[0]
"` ( f(xi,Ŵ), yi ) +",3. Overparametrization Helps Optimization,[0],[0]
λ 2,3. Overparametrization Helps Optimization,[0],[0]
"∥∥∥Ŵ∥∥∥2 F
≤ 1 2n n∑ i=1",3. Overparametrization Helps Optimization,[0],[0]
"` (f(xi,W ∗), yi) +",3. Overparametrization Helps Optimization,[0],[0]
λ 2 ‖W∗‖F2 + δ,3. Overparametrization Helps Optimization,[0],[0]
"‖W ∗‖2F
where
W∗ ∈ argminW n∑ i=1",3. Overparametrization Helps Optimization,[0],[0]
"1 2n ` (f(xi,W), yi) + λ 2 ‖W∗‖2F .
",3. Overparametrization Helps Optimization,[0],[0]
"Similar to Theorem 3.1, Theorem 3.2 states that if k(k+1)2 > n, then for an arbitrary data set, the perturbed objective
function (3) has the desired properties that enable local search heuristics to find globally optimal solution for a general class of loss functions.",3. Overparametrization Helps Optimization,[0],[0]
"Further, we can choose this perturbation to be arbitrarily small so the minimum of (3) is close to (2).
",3. Overparametrization Helps Optimization,[0],[0]
The proof of theorem is inspired by a line of literature started by Pataki (1998; 2000); Burer and Monteiro (2003); Boumal et al. (2016).,3. Overparametrization Helps Optimization,[0],[0]
"In summary, Boumal et al. (2016) showed that for “almost all” semidefinite programs, every local minima of the rank r non-convex formulation of an SDP is a global minimum of the original SDP.",3. Overparametrization Helps Optimization,[0],[0]
"However, this theorem applies with the important caveat of only applying to semidefinite programs that do not fall into a measure zero set.",3. Overparametrization Helps Optimization,[0],[0]
"Our primary contribution is to develop a procedure that exploits this by a) constructing a perturbed objective to avoid the measure zero set, b) proving that the perturbed objective has Property 2.1 and 2.2, and c) showing the optimal value of the perturbed objective is close to the original objective.",3. Overparametrization Helps Optimization,[0],[0]
"Further note that the analysis of (Boumal et al., 2016) does not apply since our loss functions, such as the logistic loss, are not semi-definite representable.",3. Overparametrization Helps Optimization,[0],[0]
We refer readers to Section 5.2 for more technical insights.,3. Overparametrization Helps Optimization,[0],[0]
In this section we switch our focus to the generalization ability of the learned neural network.,4. Weight-decay Helps Generalization,[0],[0]
"Since we use weightdecay or equivalently `2 regularization in (2), the Frobenius norm of learned weight W is bounded.",4. Weight-decay Helps Generalization,[0],[0]
"Therefore, in this section we focus weight matrix in bounded Frobenius norm space, i.e., ‖W‖F ∈ Σ (M).
",4. Weight-decay Helps Generalization,[0],[0]
"To derive the generalization bound, we first recall the classical generalization bound based on Rademacher complexity bound (c.f. Theorem 2 of (Koltchinskii and Panchenko, 2002)).
",4. Weight-decay Helps Generalization,[0],[0]
Theorem 4.1.,4. Weight-decay Helps Generalization,[0],[0]
"Assume each data point is sampled i.i.d from some distribution P , i.e.,
(xi, yi) ∼ P for i = 1, . . .",4. Weight-decay Helps Generalization,[0],[0]
", n.
We denote S = {xi, yi}ni=1 and Ltr (W) = 1 n ∑n i=1 ` (f(xi,W), yi) and Lte (W) = E(x,y)∼P",4. Weight-decay Helps Generalization,[0],[0]
"[` (f(xi,W), yi)].",4. Weight-decay Helps Generalization,[0],[0]
"Suppose loss function `(·, ·) is L-Lipschitz in the first argument, then for all W ∈ Σ (M), we have with high probability
Lte (W)− Ltr (W) ≤",4. Weight-decay Helps Generalization,[0],[0]
"CL ·RS (Σ (M))
where C > 0 is an absolute constant and RS (Σ (M)) is the Rademacher complexity of Σ (M).
",4. Weight-decay Helps Generalization,[0],[0]
"With Theorem 4.1 at hand, we only need to bound the Rademacher complexity of Σ (M).",4. Weight-decay Helps Generalization,[0],[0]
Note that Rademacher complexity is a distribution dependent quantity.,4. Weight-decay Helps Generalization,[0],[0]
"If the data
is arbitrary, we cannot have any guarantee.",4. Weight-decay Helps Generalization,[0],[0]
We begin with a theorem for bounded input domain.,4. Weight-decay Helps Generalization,[0],[0]
Theorem 4.2.,4. Weight-decay Helps Generalization,[0],[0]
"Suppose input is sampled from a bounded ball in Rd, i.e., ‖x‖2 ≤ b for some b > 0",4. Weight-decay Helps Generalization,[0],[0]
and,4. Weight-decay Helps Generalization,[0],[0]
"E [∥∥xx>∥∥2
2
]",4. Weight-decay Helps Generalization,[0],[0]
"≤ B, then the Rademacher complexity sat-
isfies
RS (Σ (M)) ≤",4. Weight-decay Helps Generalization,[0],[0]
"√ 2b4M4 log d
n .
",4. Weight-decay Helps Generalization,[0],[0]
Combining Theorem 4.1 and Theorem 4.2 we can obtain a generalization bound.,4. Weight-decay Helps Generalization,[0],[0]
Theorem 4.3.,4. Weight-decay Helps Generalization,[0],[0]
"Under the same assumptions of Theorem 4.1 and Theorem 4.2, we have
Lte (W)− Ltr (W) ≤",4. Weight-decay Helps Generalization,[0],[0]
CLM2b2,4. Weight-decay Helps Generalization,[0],[0]
"√ log d
n .
for some absolute constant C > 0.
",4. Weight-decay Helps Generalization,[0],[0]
"While Theorem 4.2 is a valid bound, it is rather pessimistic because we only assume x is bounded.",4. Weight-decay Helps Generalization,[0],[0]
"Consider the following scenario in which each input is sampled from a standard Gaussian distribution xi ∼ N (0, I).",4. Weight-decay Helps Generalization,[0],[0]
"Then ignoring the logarithmic factors, using standard Gaussian concentration bound we can show with high probability ‖xi‖2 = Õ (√ d )
.",4. Weight-decay Helps Generalization,[0],[0]
2,4. Weight-decay Helps Generalization,[0],[0]
"Plugging in this bound we have
Lte (W)− Ltr (W) ≤",4. Weight-decay Helps Generalization,[0],[0]
"CLM2 √ d2 log d
n (5)
",4. Weight-decay Helps Generalization,[0],[0]
"Note in this bound, it has a quadratic dependency on the dimension, so we need to have n = Ω ( d2 )
to have a meaningful bound.
",4. Weight-decay Helps Generalization,[0],[0]
"In fact, for specific distributions like Gaussian using Theorem 5.2, we can often derive a stronger generalization bound.",4. Weight-decay Helps Generalization,[0],[0]
Corollary 4.1.,4. Weight-decay Helps Generalization,[0],[0]
"Suppose xi ∼ N(0, I) for i = 1, . . .",4. Weight-decay Helps Generalization,[0],[0]
", n.",4. Weight-decay Helps Generalization,[0],[0]
"If the number of samples satisfies n ≥ d log d, we have with high probability that Rademacher complexity satisfies
RS (Σ (M))",4. Weight-decay Helps Generalization,[0],[0]
"≤ C √ M4d
n .
",4. Weight-decay Helps Generalization,[0],[0]
"for some absolute constant C > 0.
Again, combining Theorem 4.1 and Corollary 4.1 we obtain the following generalization bound for Gaussian input distribution Theorem 4.4.",4. Weight-decay Helps Generalization,[0],[0]
"Under the same assumptions of Theorem 4.1 and Corollary 4.1, we have
Lte (W)− Ltr (W) ≤",4. Weight-decay Helps Generalization,[0],[0]
"CLM2 √ d
n .
for some absolute constant C > 0.
2Õ(·) hides logarithmic factors.
",4. Weight-decay Helps Generalization,[0],[0]
"Comparing Theorem 4.4 with generalization bound (5), Theorem 4.4 has an O( √ d) advantage.",4. Weight-decay Helps Generalization,[0],[0]
"Theorem 4.4 has the√
d/n dependency, which is the usual parametric rate.",4. Weight-decay Helps Generalization,[0],[0]
"Further in practice, number of training samples and input dimension are often of the same order for common datasets and architectures (Zhang et al., 2016).
",4. Weight-decay Helps Generalization,[0],[0]
"Corollary 4.1 is a special case of the more general Theorem 5.2 which only requires a bound on the fourth moment,∥∥∑n
",4. Weight-decay Helps Generalization,[0],[0]
"i=1(xix > i )
2 ∥∥
2 ≤ s.",4. Weight-decay Helps Generalization,[0],[0]
"In general, our theorems suggest if
the Frobenius norm of weight matrix W is small and the input x is sampled from a benign distribution with controlled 4th moments, then we have good generalization.
",4. Weight-decay Helps Generalization,[0],[0]
"As a concrete scenario, consider a favorable setting where the true data can be correctly classified by a small network using only k0 k hidden units.",4. Weight-decay Helps Generalization,[0],[0]
"The weights W ∗ are nonzero only in the first k0 rows and maxj∈[k0]
∥∥e>j W ∗∥∥2 ≤",4. Weight-decay Helps Generalization,[0],[0]
"R. From Theorem 4.4 to reach generalization gap of , we have sample complexity of n",4. Weight-decay Helps Generalization,[0],[0]
"≥ 1 2C
2L2R4dk20 , which only depends on the effective number of hidden units",4. Weight-decay Helps Generalization,[0],[0]
k0 k.,4. Weight-decay Helps Generalization,[0],[0]
The same result can be reached for more general input distributions by using Theorem 5.2 in place of Theorem 4.4.,4. Weight-decay Helps Generalization,[0],[0]
Our proofs of over-parametrization helps optimization build upon existing geometric characterization on matrix factorization.,5.1. Proof of Theorem 3.1 and Theorem 3.2,[0],[0]
"We first cite a useful Theorem by Haeffele et al. (2014).3
Theorem 5.1 (Theorem 2 of (Haeffele et al., 2014) adapted to our setting).",5.1. Proof of Theorem 3.1 and Theorem 3.2,[0],[0]
"Let ` (·, ·) be a twice differentiable convex function in the first argument.",5.1. Proof of Theorem 3.1 and Theorem 3.2,[0],[0]
"If the function L (W) defined in (2) at a rank-deficient matrix W satisfies
∇L (W) = 0 and ∇2L (W) < 0,
then W is a global minimum.
",5.1. Proof of Theorem 3.1 and Theorem 3.2,[0],[0]
Proof of Theorem 3.1.,5.1. Proof of Theorem 3.1 and Theorem 3.2,[0],[0]
"We prove Property 2.1 and Property 2.2 simultaneously by showing if a W satisfy
∇L (W) = 0 and ∇2L (W) < 0
then it is a global minimum.
",5.1. Proof of Theorem 3.1 and Theorem 3.2,[0],[0]
"If rank (W) < d, we can directly apply Theorem 5.1.",5.1. Proof of Theorem 3.1 and Theorem 3.2,[0],[0]
Thus it remains to consider the case rank (W) =,5.1. Proof of Theorem 3.1 and Theorem 3.2,[0],[0]
d.,5.1. Proof of Theorem 3.1 and Theorem 3.2,[0],[0]
"We first
3Theorem 2 of (Haeffele et al., 2014) assumes W is a local minimum, but scrutinizing its proof, we can see that the assumption can be relaxed to∇L (W) = 0",5.1. Proof of Theorem 3.1 and Theorem 3.2,[0],[0]
"and∇2L (W) < 0.
notice that ∇L (W) = 0 is equivalent to
W
( 1
n n∑ i=1 ∂",5.1. Proof of Theorem 3.1 and Theorem 3.2,[0],[0]
`,5.1. Proof of Theorem 3.1 and Theorem 3.2,[0],[0]
"(ŷi, yi) ∂ŷi xix >",5.1. Proof of Theorem 3.1 and Theorem 3.2,[0],[0]
"i + λI
)",5.1. Proof of Theorem 3.1 and Theorem 3.2,[0],[0]
"= 0 (6)
where ŷi = f(xi,W)",5.1. Proof of Theorem 3.1 and Theorem 3.2,[0],[0]
.,5.1. Proof of Theorem 3.1 and Theorem 3.2,[0],[0]
"Since rank (W) = d and k ≥ d, we know W has a left pseudo-inverse, i.e., there exists W† such that W†W = I. Multiplying W† on the left in Equation (6), we have
1
n n∑ i=1 ∂",5.1. Proof of Theorem 3.1 and Theorem 3.2,[0],[0]
`,5.1. Proof of Theorem 3.1 and Theorem 3.2,[0],[0]
"(ŷi, yi) ∂ŷi xix >",5.1. Proof of Theorem 3.1 and Theorem 3.2,[0],[0]
i + λI = 0.,5.1. Proof of Theorem 3.1 and Theorem 3.2,[0],[0]
"(7)
To prove Theorem 3.1, the key idea is to consider the follow reference optimization problem.
",5.1. Proof of Theorem 3.1 and Theorem 3.2,[0],[0]
"min M:M∈Sd
L (M) = 1
n n∑ i=1",5.1. Proof of Theorem 3.1 and Theorem 3.2,[0],[0]
"` ( x>i Mxi, yi ) + λ ‖M‖∗ .",5.1. Proof of Theorem 3.1 and Theorem 3.2,[0],[0]
"(8)
Problem (8) is a convex optimization problem in M and has the same global minimum as the original problem.",5.1. Proof of Theorem 3.1 and Theorem 3.2,[0],[0]
Now we denote ỹi = x>i Mxi.,5.1. Proof of Theorem 3.1 and Theorem 3.2,[0],[0]
"Since this is a convex function, the first-order optimality condition for global optimality is
0 ∈ 1 n n∑ i=1 ∂",5.1. Proof of Theorem 3.1 and Theorem 3.2,[0],[0]
"` (ỹi, yi)",5.1. Proof of Theorem 3.1 and Theorem 3.2,[0],[0]
∂ỹi,5.1. Proof of Theorem 3.1 and Theorem 3.2,[0],[0]
xix >,5.1. Proof of Theorem 3.1 and Theorem 3.2,[0],[0]
"i + λ∂ ‖M‖∗ ,
M is a global minimum.
",5.1. Proof of Theorem 3.1 and Theorem 3.2,[0],[0]
"Using Equation (7), we know M = W>W achieves the global minimum in Problem (8).",5.1. Proof of Theorem 3.1 and Theorem 3.2,[0],[0]
The proof is thus complete.,5.1. Proof of Theorem 3.1 and Theorem 3.2,[0],[0]
Proof.,5.2. Proof of Theorem 3.2,[0],[0]
We first prove LC (W) satisfies Property 2.1 and Property 2.2.,5.2. Proof of Theorem 3.2,[0],[0]
"Similar to the proof of Theorem 3.1, we prove these two properties simultaneously by showing if a W satisfy
∇LC (W) = 0 and ∇2LC (W) < 0 (9)
then it is a global minimum.",5.2. Proof of Theorem 3.2,[0],[0]
"Because of Theorem 5.1, we only need to show that if W satisfy condition (9), it is rank deficient, i.e. rank (W) <",5.2. Proof of Theorem 3.2,[0],[0]
"k.
For the gradient condition, we have
W
( 1
n n∑ i=1 ∂",5.2. Proof of Theorem 3.2,[0],[0]
`,5.2. Proof of Theorem 3.2,[0],[0]
"(ŷi, yi) ∂ŷi xix >",5.2. Proof of Theorem 3.2,[0],[0]
"i + λI
) + WC = 0.
",5.2. Proof of Theorem 3.2,[0],[0]
"For simplicity we denote vi = ∂`(ŷi,yi) ∂ŷi where ŷi = x>i W >Wxi and S (v) = ∑n i=1",5.2. Proof of Theorem 3.2,[0],[0]
vixix > i .,5.2. Proof of Theorem 3.2,[0],[0]
Using the first order condition we know W is in the null space of (S (v) + λI + C).,5.2. Proof of Theorem 3.2,[0],[0]
"Thus, we can bound the rank of W by
rank (W) ≤dimN (S (v) + λI + C) ≤max
v dimN (S (v) + λI + C) .
",5.2. Proof of Theorem 3.2,[0],[0]
We prove by contradiction.,5.2. Proof of Theorem 3.2,[0],[0]
Assume rank (W) ≥,5.2. Proof of Theorem 3.2,[0],[0]
"k, we must have
k ≤ max v N (S (v) + λI + C) .
",5.2. Proof of Theorem 3.2,[0],[0]
"Now define M = S (v∗) + λI + C with
v∗ = argmax dimN (S (v) + λI + C) .
",5.2. Proof of Theorem 3.2,[0],[0]
"Thus we have following conditions
C =M− S (v∗)− λI, dimN (M) ≥k.
",5.2. Proof of Theorem 3.2,[0],[0]
"The key idea is to use these two conditions to upper bound the dimension of C. To this end, we first define the set
B` = { A : A = M− S (v)− λI,M ∈ Sd,v ∈ Rn,
dimN (M− λI) = `} .
",5.2. Proof of Theorem 3.2,[0],[0]
"Note that the dimension of the manifold B` is( d(d+ 1)
2 − ` (`+ 1) 2
) + n
where the first term is the dimension of d× d matrices, the second term is the dimension of the null space and the last term is dimension of Range(S (v)) for v ∈ Rn, which is upper bounded by n.
Next note that B`1 ⊂ B`2 for `1 ≥ `2.",5.2. Proof of Theorem 3.2,[0],[0]
"Therefore, we can compute the dimension of the union
dim ( ∪d`=kB` ) =
( d(d+ 1)
2 − k(k + 1) 2
) +",5.2. Proof of Theorem 3.2,[0],[0]
"n.
Note because we assume k(k+1)2 > n, we have dim ( ∪d`=kB` ) < d(d+1)2 .",5.2. Proof of Theorem 3.2,[0],[0]
"However, recall C ∈ ∪ d `=kB` by definition, so we have C is sampled from a low-dimensional manifold which has Lebesuge measure 0.",5.2. Proof of Theorem 3.2,[0],[0]
"Since we sample C from a distribution that is absolute continuous with respect to the Lebesgue measure, the event { C ∈ ∪d`=kB`
} happens with probability 0.",5.2. Proof of Theorem 3.2,[0],[0]
"Therefore, with probability 1, rank (W) < k.",5.2. Proof of Theorem 3.2,[0],[0]
"The proof of the first part of Theorem 3.2 is complete.
",5.2. Proof of Theorem 3.2,[0],[0]
For the second part.,5.2. Proof of Theorem 3.2,[0],[0]
Let Ŵ = argminWLC (W) and W∗ = argminW (W).,5.2. Proof of Theorem 3.2,[0],[0]
"Therefore we have
L ( Ŵ ) +",5.2. Proof of Theorem 3.2,[0],[0]
"〈C,Ŵ>Ŵ〉
≤L (W∗) +",5.2. Proof of Theorem 3.2,[0],[0]
"〈C, (W∗)>W∗〉
≤L (W∗) + δ ‖W∗‖2F .
",5.2. Proof of Theorem 3.2,[0],[0]
"Note because C and Ŵ>Ŵ are both positive semidefinite, we have 〈C,Ŵ>Ŵ〉 ≥ 0.",5.2. Proof of Theorem 3.2,[0],[0]
Thus L ( Ŵ ) ≤,5.2. Proof of Theorem 3.2,[0],[0]
"L (W∗) +
δ ‖W∗‖2F .",5.2. Proof of Theorem 3.2,[0],[0]
"Our proof is inspired by (Srebro and Shraibman, 2005) which exploits the structure of nuclear norm bounded space.",5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
We first prove a general Theorem that only depends on the property of the fourth-moment of input random variables.,5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
Theorem 5.2.,5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
Suppose the input random variable satisfies∥∥∥∑ni=1,5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
(,5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
xix>i )2∥∥∥ 2 ≤ s.,5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
"Then the Rademacher complexity of Σ (M) is bounded by
RS (Σ (M))",5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
≤,5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
"√ 2M4s log d
n .
",5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
Proof.,5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
"For a given set of inputs S = {xi}ni=1 in our context, we can write Rademacher complexity as
RS (Σ (M))",5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
"= 1
n",5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
"Eσ
[ sup
W∈Σ(M) n∑ i=1",5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
σix >,5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
"i W >Wxi
]
Since Rademacher complexity does not change when taking convex combinations, we can first bound Rademacher complexity of the class of rank-1 matrices with spectral norm bounded by 1 and then take convex hull and scale by M .",5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
"Note for W ∈ Σ1 (1), we can write W = vw> with ‖w‖2 ≤ 1 and ‖v‖2 = 1.",5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
"Using this expression, we can obtain an explicit formula of Rademacher complexity.
",5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
"RS (Σ1 (1))
",5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
"= 1
n",5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
"Eσ
[ sup
W∈Σ1(1) n∑ i=1",5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
σix >,5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
"i W >Wxi
]
= 1
n",5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
"Eσ
[ sup
W∈Σ1(1) n∑ i=1",5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
σix >,5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
i ( w>v )>,5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
( vw> ),5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
"xi
]
= 1
n Eσ
[ sup
w:‖w‖2≤1 n∑ i=1",5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
σix >,5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
"i ww >xi
]
= 1
n",5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
"Eσ
[ sup
w:‖w‖2≤1 n∑ i=1",5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
"σiw >x>i xiw
]
= 1
n",5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
"Eσ [∥∥∥∥∥ n∑ i=1 σixix > i ∥∥∥∥∥ 2 ] .
",5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
"Now, to bound Eσ [∥∥∑n i=1 σixix > i ∥∥ 2 ] , we can use the results from random matrix theory on Rademacher series.",5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
Recall that we assume∥∥∥∥∥ n∑ i=1,5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
"( xix > i )2∥∥∥∥∥ 2 ≤ s
and notice that
Eσ [ n∑ i=1 σixix > i ] = 0.
",5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
"Applying Rademacher matrix series expectation bound (Theorem 4.6.1 of (Tropp et al., 2015)), we have
Eσ [∥∥∥∥∥ n∑ i=1 σixix > i ∥∥∥∥∥ 2 ] ≤ √√√√2 ∥∥∥∥∥ n∑ i=1",5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
"( xix>i )2∥∥∥∥∥ 2 log d
≤ √ 2s log d.
Now taking the convex hull and, scaling by M we obtain the desired result.
",5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
"With Theorem 5.2 at hand, for different distributions, we only need to bound ∥∥∥∑ni=1",5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
"(xix>i )2∥∥∥ 2 .
",5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
Proof of Theorem 4.3.,5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
"Since we assume ‖xi‖2 ≤ b, we directly have∥∥∥∥∥ n∑ i=1",5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
( xix > i ),5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
2∥∥∥∥∥ 2 ≤ n∑ i=1,5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
"∥∥∥(xix>i )2∥∥∥ 2
",5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
= n∑ i=1,5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
‖xi‖22 ∥∥xix>,5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
"i ∥∥2 ≤nb4.
",5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
"Plugging this bound in Theorem 5.2 we obtain the desired inequality.
",5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
Proof of Corollary 4.1 and Theorem 4.4.,5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
"To prove Corollary 4.1, we use Theorem 5.2 and Lemma 4.7 in (Soltanolkotabi et al., 2017) to upper bound s =∥∥∥∑ni=1 ‖xi‖2",5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
xix>,5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
"i ∥∥∥. By letting A = I in Lemma 4.7, we find that s ≤ Cnd, with probability at least 1− Cd .",5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
"This completes the proof of Corollary 4.1.
",5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
Using this bound in Theorem 5.2 comletes the proof of Theorem 4.4.,5.3. Proof of Theorem 4.2 and Theorem 4.4,[0],[0]
In this paper we provided new theoretical results on overparameterized neural networks.,6. Conclusion and Future Works,[0],[0]
"Using smoothed analysis, we showed as long as the number of hidden nodes is bigger than the input dimension or square root of the number of training data, the loss surface has benign properties that enable local search algorithms to find global minima.",6. Conclusion and Future Works,[0],[0]
"We further use the theory of Rademacher complexity to show the learned neural can generalize well.
",6. Conclusion and Future Works,[0],[0]
Our next step is consider neural networks with other activation functions and how over-parametrization allows for efficient local-search algorithms to find near global minimzers.,6. Conclusion and Future Works,[0],[0]
Another interesting direction to extend our results to deeper model.,6. Conclusion and Future Works,[0],[0]
"S.S.D. was supported by NSF grant IIS1563887, AFRL grant FA8750-17-2-0212 and DARPA D17AP00001.",7. Acknowledgment,[0],[0]
J.D.L. acknowledges support of the ARO under MURI Award W911NF-11-1-0303.,7. Acknowledgment,[0],[0]
"This is part of the collaboration between US DOD, UK MOD and UK Engineering and Physical Research Council (EPSRC) under the Multidisciplinary University Research Initiative.",7. Acknowledgment,[0],[0]
We provide new theoretical insights on why overparametrization is effective in learning neural networks.,abstractText,[0],[0]
"For a k hidden node shallow network with quadratic activation and n training data points, we show as long as k ≥ √ 2n, over-parametrization enables local search algorithms to find a globally optimal solution for general smooth and convex loss functions.",abstractText,[0],[0]
"Further, despite that the number of parameters may exceed the sample size, using theory of Rademacher complexity, we show with weight decay, the solution also generalizes well if the data is sampled from a regular distribution such as Gaussian.",abstractText,[0],[0]
"To prove when k ≥ √ 2n, the loss function has benign landscape properties, we adopt an idea from smoothed analysis, which may have other applications in studying loss surfaces of neural networks.",abstractText,[0],[0]
On the Power of Over-parametrization in Neural Networks with Quadratic Activation,title,[0],[0]
Recurrent Neural Network (RNNs) emerge as very strong learners of sequential data.,1 Introduction,[0],[0]
"A famous result by Siegelmann and Sontag (1992; 1994), and its extension in (Siegelmann, 1999), demonstrates that an Elman-RNN (Elman, 1990) with a sigmoid activation function, rational weights and infinite precision states can simulate a Turingmachine in real-time, making RNNs Turingcomplete.",1 Introduction,[0],[0]
"Recently, Chen et al (2017) extended the result to the ReLU activation function.",1 Introduction,[0],[0]
"However, these constructions (a) assume reading the entire input into the RNN state and only then performing the computation, using unbounded time; and (b) rely on having infinite precision in the network states.",1 Introduction,[0],[0]
"As argued by Chen et al (2017), this is not the model of RNN computation used in NLP applications.",1 Introduction,[0],[0]
"Instead, RNNs are often used by feeding an input sequence into the RNN one item at a time, each immediately returning a state-
vector that corresponds to a prefix of the sequence and which can be passed as input for a subsequent feed-forward prediction network operating in constant time.",1 Introduction,[0],[0]
"The amount of tape used by a Turing machine under this restriction is linear in the input length, reducing its power to recognition of context-sensitive language.",1 Introduction,[0],[0]
"More importantly, computation is often performed on GPUs with 32bit floating point computation, and there is increasing evidence that competitive performance can be achieved also for quantized networks with 4-bit weights or fixed-point arithmetics (Hubara et al., 2016).",1 Introduction,[0],[0]
"The construction of (Siegelmann, 1999) implements pushing 0 into a binary stack by the operation g ← g/4 + 1/4.",1 Introduction,[0],[0]
This allows pushing roughly 15 zeros before reaching the limit of the 32bit floating point precision.,1 Introduction,[0],[0]
"Finally, RNN solutions that rely on carefully orchestrated mathematical constructions are unlikely to be found using backpropagation-based training.
",1 Introduction,[0],[0]
"In this work we restrict ourselves to inputbound recurrent neural networks with finiteprecision states (IBFP-RNN), trained using backpropagation.",1 Introduction,[0],[0]
This class of networks is likely to coincide with the networks one can expect to obtain when training RNNs for NLP applications.,1 Introduction,[0],[0]
An IBFP Elman-RNN is finite state.,1 Introduction,[0],[0]
But what about other RNN variants?,1 Introduction,[0],[0]
"In particular, we consider the Elman RNN (SRNN) (Elman, 1990) with squashing and with ReLU activations, the Long ShortTerm Memory (LSTM) (Hochreiter and Schmidhuber, 1997) and the Gated Recurrent Unit (GRU) (Cho et al., 2014; Chung et al., 2014).
",1 Introduction,[0],[0]
"The common wisdom is that the LSTM and GRU introduce additional gating components that handle the vanishing gradients problem of training SRNNs, thus stabilizing training and making it more robust.",1 Introduction,[0],[0]
"The LSTM and GRU are often considered as almost equivalent variants of each other.
",1 Introduction,[0],[0]
"ar X
iv :1
80 5.
04 90
8v 1
[ cs
.L",1 Introduction,[0],[0]
"G
] 1
3 M
ay 2
01 8
We show that in the input-bound, finiteprecision case, there is a real difference between the computational capacities of the LSTM and the GRU: the LSTM can easily perform unbounded counting, while the GRU (and the SRNN) cannot.",1 Introduction,[0],[0]
"This makes the LSTM a variant of a k-counter machine (Fischer et al., 1968), while the GRU remains finite-state.",1 Introduction,[0],[0]
"Interestingly, the SRNN with ReLU activation followed by an MLP classifier also has power similar to a k-counter machine.
",1 Introduction,[0],[0]
These results suggest there is a class of formal languages that can be recognized by LSTMs but not by GRUs.,1 Introduction,[0],[0]
"In section 5, we demonstrate that for at least two such languages, the LSTM manages to learn the desired concept classes using back-propagation, while using the hypothesized control structure.",1 Introduction,[0],[0]
Figure 1 shows the activations of 10-d LSTM and GRU trained to recognize the languages anbn and anbncn.,1 Introduction,[0],[0]
"It is clear that the LSTM learned to dedicate specific dimensions for counting, in contrast to the GRU.1
1Is the ability to perform unbounded counting relevant to “real world” NLP tasks?",1 Introduction,[0],[0]
In some cases it might be.,1 Introduction,[0],[0]
"For example, processing linearized parse trees (Vinyals et al., 2015; Choe and Charniak, 2016; Aharoni and Goldberg, 2017) requires counting brackets and nesting levels.",1 Introduction,[0],[0]
"Indeed, previous works that process linearized parse trees report using LSTMs and not GRUs for this purpose.",1 Introduction,[0],[0]
Our work here suggests that this may not be a coincidence.,1 Introduction,[0],[0]
"An RNN is a parameterized function R that takes as input an input vector xt and a state vector ht−1 and returns a state vector ht:
ht = R(xt, ht−1) (1)
The RNN is applied to a sequence x1, ..., xn by starting with an initial vector h0 (often the 0 vector) and applying R repeatedly according to equation (1).",2 The RNN Models,[0],[0]
"Let Σ be an input vocabulary (alphabet), and assume a mapping E from every vocabulary item to a vector x (achieved through a 1- hot encoding, an embedding layer, or some other means).",2 The RNN Models,[0],[0]
"Let RNN(x1, ..., xn) denote the state vector h resulting from the application of R to the sequence E(x1), ..., E(xn).",2 The RNN Models,[0],[0]
"An RNN recognizer (or RNN acceptor) has an additional function f mapping states h to 0, 1.",2 The RNN Models,[0],[0]
"Typically, f is a log-linear classifier or multi-layer perceptron.",2 The RNN Models,[0],[0]
We say that an RNN recognizes a language L⊆ Σ∗,2 The RNN Models,[0],[0]
"if f(RNN(w)) returns 1 for all and only words w = x1, ..., xn ∈ L.
Elman-RNN (SRNN)",2 The RNN Models,[0],[0]
"In the Elman-RNN (Elman, 1990), also called the Simple RNN (SRNN), the function R takes the form of an affine transform followed by a tanh nonlinearity:
ht = tanh(Wxt + Uht−1 + b) (2)
Elman-RNNs are known to be at-least finitestate.",2 The RNN Models,[0],[0]
"Siegelmann (1996) proved that the tanh can be replaced by any other squashing function without sacrificing computational power.
",2 The RNN Models,[0],[0]
"IRNN The IRNN model, explored by (Le et al., 2015), replaces the tanh activation with a nonsquashing ReLU:
ht = max(0, (Wxt + Uht−1 + b))",2 The RNN Models,[0],[0]
"(3)
The computational power of such RNNs (given infinite precision) is explored in (Chen et al., 2017).
",2 The RNN Models,[0],[0]
Gated Recurrent Unit (GRU),2 The RNN Models,[0],[0]
"In the GRU (Cho et al., 2014), the function R incorporates a gating mechanism, taking the form:
zt = σ(W zxt + U",2 The RNN Models,[0],[0]
zht−1 + b z) (4) rt = σ(W rxt + U rht−1 + b,2 The RNN Models,[0],[0]
"r) (5) h̃t = tanh(W hxt + U
h(rt ◦ ht−1) + bh)(6) ht = zt ◦",2 The RNN Models,[0],[0]
"ht−1 + (1− zt) ◦ h̃t (7)
",2 The RNN Models,[0],[0]
"Where σ is the sigmoid function and ◦ is the Hadamard product (element-wise product).
",2 The RNN Models,[0],[0]
Long Short Term Memory (LSTM),2 The RNN Models,[0],[0]
"In the LSTM (Hochreiter and Schmidhuber, 1997), R uses a different gating component configuration:
ft = σ(W fxt + U fht−1 + b f ) (8) it = σ(W ixt + U iht−1 + b i) (9) ot = σ(W oxt + U oht−1 + b o) (10) c̃t = tanh(W cxt + U cht−1 + b c) (11) ct",2 The RNN Models,[0],[0]
= ft ◦ ct−1 + it ◦ c̃t (12) ht = ot ◦ g(ct),2 The RNN Models,[0],[0]
"(13)
where g can be either tanh or the identity.
",2 The RNN Models,[0],[0]
Equivalences The GRU and LSTM are at least as strong as the SRNN:,2 The RNN Models,[0],[0]
by setting the gates of the GRU to zt = 0 and rt = 1 we obtain the SRNN computation.,2 The RNN Models,[0],[0]
"Similarly by setting the LSTM gates to it = 1,ot = 1, and ft = 0.",2 The RNN Models,[0],[0]
"This is easily achieved by setting the matrices W and U to 0, and the biases b to the (constant) desired gate values.
",2 The RNN Models,[0],[0]
"Thus, all the above RNNs can recognize finitestate languages.",2 The RNN Models,[0],[0]
Power beyond finite state can be obtained by introducing counters.,3 Power of Counting,[0],[0]
"Counting languages and kcounter machines are discussed in depth in (Fischer et al., 1968).",3 Power of Counting,[0],[0]
"When unbounded computation is allowed, a 2-counter machine has Turing power.",3 Power of Counting,[0],[0]
"However, for computation bound by input length (real-time) there is a more interesting hierarchy.",3 Power of Counting,[0],[0]
"In particular, real-time counting languages cut across the traditional Chomsky hierarchy: real-time k-counter machines can recognize at least one context-free language (anbn), and at least one context-sensitive one (anbncn).",3 Power of Counting,[0],[0]
"However, they cannot recognize the context free language given by the grammar S → x|aSa|bSb (palindromes).
",3 Power of Counting,[0],[0]
SKCM,3 Power of Counting,[0],[0]
"For our purposes, we consider a simplified variant of k-counter machines (SKCM).",3 Power of Counting,[0],[0]
"A counter is a device which can be incremented by a fixed amount (INC), decremented by a fixed amount (DEC) or compared to 0 (COMP0).",3 Power of Counting,[0],[0]
"Informally,2 an SKCM is a finite-state automaton extended with k counters, where at each step of the computation each counter can be incremented, decremented or ignored in an input-dependent way, and state-transitions and accept/reject decisions can inspect the counters’ states using COMP0.",3 Power of Counting,[0],[0]
"The results for the three languages discussed above hold for the SKCM variant as well, with proofs provided in Appendix A.",3 Power of Counting,[0],[0]
"In what follows, we consider the effect on the state-update equations on a single dimension, ht[j].",4 RNNs as SKCMs,[0],[0]
We omit the index,4 RNNs as SKCMs,[0],[0]
"[j] for readability.
",4 RNNs as SKCMs,[0],[0]
LSTM The LSTM acts as an SKCM by designating k dimensions of the memory cell ct as counters.,4 RNNs as SKCMs,[0],[0]
"In non-counting steps, set it = 0, ft = 1 through equations (8-9).",4 RNNs as SKCMs,[0],[0]
"In counting steps, the counter direction (+1 or -1) is set in c̃t (equation 11) based on the input xt and state ht−1.",4 RNNs as SKCMs,[0],[0]
"The counting itself is performed in equation (12), after setting it = ft = 1.",4 RNNs as SKCMs,[0],[0]
"The counter can be reset to 0 by setting it = ft = 0.
",4 RNNs as SKCMs,[0],[0]
"Finally, the counter values are exposed through ht = otg(ct), making it trivial to compare the counter’s value to 0.3
2Formal definition is given in Appendix A. 3Some further remarks on the LSTM:",4 RNNs as SKCMs,[0],[0]
LSTM supports both increment and decrement in a single dimension.,4 RNNs as SKCMs,[0],[0]
"The counting dimensions in ct are exposed through a function
We note that this implementation of the SKCM operations is achieved by saturating the activations to their boundaries, making it relatively easy to reach and maintain in practice.
",4 RNNs as SKCMs,[0],[0]
"SRNN The finite-precision SRNN cannot designate unbounded counting dimensions.
",4 RNNs as SKCMs,[0],[0]
"The SRNN update equation is:
ht = tanh(Wx+",4 RNNs as SKCMs,[0],[0]
Uht−1,4 RNNs as SKCMs,[0],[0]
"+ b)
ht[i] = tanh( dx∑ j=1 Wijx[j]+ dh∑ j=1 Uijht−1[j]+b[i])
",4 RNNs as SKCMs,[0],[0]
"By properly setting U and W, one can get certain dimensions of h to update according to the value of x, by ht[i] = tanh(ht−1[i] +wix+ b[i]).",4 RNNs as SKCMs,[0],[0]
"However, this counting behavior is within a tanh activation.",4 RNNs as SKCMs,[0],[0]
"Theoretically, this means unbounded counting cannot be achieved without infinite precision.",4 RNNs as SKCMs,[0],[0]
"Practically, this makes the counting behavior inherently unstable, and bounded to a relatively narrow region.",4 RNNs as SKCMs,[0],[0]
"While the network could adapt to set w to be small enough such that counting works for the needed range seen in training without overflowing the tanh, attempting to count to larger n will quickly leave this safe region and diverge.
IRNN Finite-precision IRNNs can perform unbounded counting conditioned on input symbols.",4 RNNs as SKCMs,[0],[0]
"This requires representing each counter as two dimensions, and implementing INC as incrementing one dimension, DEC as incrementing the other, and COMP0 as comparing their difference to 0.",4 RNNs as SKCMs,[0],[0]
"Indeed, Appendix A in (Chen et al., 2017) provides concrete IRNNs for recognizing the languages anbn and anbncn.",4 RNNs as SKCMs,[0],[0]
This makes IBFP-RNN with ReLU activation more powerful than IBFP-RNN with a squashing activation.,4 RNNs as SKCMs,[0],[0]
"Practically, ReLUactivated RNNs are known to be notoriously hard
g. For both g(x) = x and g(x) = tanh(x), it is trivial to do compare 0.",4 RNNs as SKCMs,[0],[0]
"Another operation of interest is comparing two counters (for example, checking the difference between them).",4 RNNs as SKCMs,[0],[0]
"This cannot be reliably achieved with g(x) = tanh(x), due to the non-linearity and saturation properties of the tanh function, but is possible in the g(x) = x case.",4 RNNs as SKCMs,[0],[0]
LSTM can also easily set the value of a counter to 0 in one step.,4 RNNs as SKCMs,[0],[0]
"The ability to set the counter to 0 gives slightly more power for real-time recognition, as discussed by Fischer et al. (1968).
",4 RNNs as SKCMs,[0],[0]
"Relation to known architectural variants: Adding peephole connections (Gers and Schmidhuber, 2000) essentially sets g(x) = x and allows comparing counters in a stable way.",4 RNNs as SKCMs,[0],[0]
"Coupling the input and the forget gates (it = 1 − ft) (Greff et al., 2017) removes the single-dimension unbounded counting ability, as discussed for the GRU.
to train because of the exploding gradient problem.
",4 RNNs as SKCMs,[0],[0]
GRU Finite-precision GRUs cannot implement unbounded counting on a given dimension.,4 RNNs as SKCMs,[0],[0]
"The tanh in equation (6) combined with the interpolation (tying zt and 1 − zt) in equation (7) restricts the range of values in h to between -1 and 1, precluding unbounded counting with finite precision.",4 RNNs as SKCMs,[0],[0]
"Practically, the GRU can learn to count up to some bound m seen in training, but will not generalize well beyond that.4 Moreover, simulating forms of counting behavior in equation (7) require consistently setting the gates zt, rt and the proposal h̃t to precise, non-saturated values, making it much harder to find and maintain stable solutions.
",4 RNNs as SKCMs,[0],[0]
"Summary We show that LSTM and IRNN can implement unbounded counting in dedicated counting dimensions, while the GRU and SRNN cannot.",4 RNNs as SKCMs,[0],[0]
"This makes the LSTM and IRNN at least as strong as SKCMs, and strictly stronger than the SRNN and the GRU.5",4 RNNs as SKCMs,[0],[0]
Can the LSTM indeed learn to behave as a kcounter machine when trained using backpropagation?,5 Experimental Results,[0],[0]
"We show empirically that:
1.",5 Experimental Results,[0],[0]
"LSTMs can be trained to recognize anbn and anbncn.
2.",5 Experimental Results,[0],[0]
"These LSTMs generalize to much higher n than seen in the training set (though not infinitely so).
",5 Experimental Results,[0],[0]
3.,5 Experimental Results,[0],[0]
"The trained LSTM learn to use the perdimension counting mechanism.
4.",5 Experimental Results,[0],[0]
"The GRU can also be trained to recognize anbn and anbncn, but they do not have clear counting dimensions, and they generalize to much smaller n than the LSTMs, often failing to generalize correctly even for n within their training domain.
4One such mechanism could be to divide a given dimension by k > 1 at each symbol encounter, by setting zt = 1/k and h̃t = 0.",5 Experimental Results,[0],[0]
"Note that the inverse operation would not be implementable, and counting down would have to be realized with a second counter.
5One can argue that other counting mechanisms— involving several dimensions—are also possible.",5 Experimental Results,[0],[0]
"Intuitively, such mechanisms cannot be trained to perform unbounded counting based on a finite sample as the model has no means of generalizing the counting behavior to dimensions beyond those seen in training.",5 Experimental Results,[0],[0]
"We discuss this more in depth in Appendix B, where we also prove that an SRNN cannot represent a binary counter.
5.",5 Experimental Results,[0],[0]
"Trained LSTM networks outperform trained GRU networks on random test sets for the languages anbn and anbncn.
",5 Experimental Results,[0],[0]
"Similar empirical observations regarding the ability of the LSTM to learn to recognize anbn and anbncn are described also in (Gers and Schmidhuber, 2001).
",5 Experimental Results,[0],[0]
"We train 10-dimension, 1-layer LSTM and GRU networks to recognize anbn and anbncn.",5 Experimental Results,[0],[0]
"For anbn the training samples went up to n = 100 and for anbncn up to n = 50.6
Results On anbn, the LSTM generalizes well up to n = 256, after which it accumulates a deviation making it reject anbn but recognize anbn+1 for a while, until the deviation grows.7 The GRU does not capture the desired concept even within its training domain: accepting anbn+1 for n > 38, and also accepting anbn+2 for n > 97.",5 Experimental Results,[0],[0]
"It stops accepting anbn for n > 198.
",5 Experimental Results,[0],[0]
On anbncn the LSTM recognizes well until n = 100.,5 Experimental Results,[0],[0]
It then starts accepting also anbn+1cn.,5 Experimental Results,[0],[0]
"At n > 120 it stops accepting anbncn and switches to accepting anbn+1cn, until at some point the deviation grows.",5 Experimental Results,[0],[0]
"The GRU accepts already a9b10c12, and stops accepting anbncn for n > 63.
",5 Experimental Results,[0],[0]
Figure 1a plots the activations of the 10 dimensions of the anbn-LSTM for the input a1000b1000.,5 Experimental Results,[0],[0]
"While the LSTM misclassifies this example, the use of the counting mechanism is clear.",5 Experimental Results,[0],[0]
Figure 1b plots the activation for the anbncn LSTM on a100b100c100.,5 Experimental Results,[0],[0]
"Here, again, the two counting dimensions are clearly identified—indicating the LSTM learned the canonical 2-counter solution— although the slightly-imprecise counting also starts to show.",5 Experimental Results,[0],[0]
"In contrast, Figures 1c and 1d show the state values of the GRU-networks.",5 Experimental Results,[0],[0]
The GRU behavior is much less interpretable than the LSTM.,5 Experimental Results,[0],[0]
"In the anbn case, some dimensions may be performing counting within a bounded range, but move to erratic behavior at around t = 1750 (the
6Implementation in DyNet, using the SGD Optimizer.",5 Experimental Results,[0],[0]
Positive examples are generated by sampling n in the desired range.,5 Experimental Results,[0],[0]
"For negative examples we sample 2 or 3 n values independently, and ensuring at least one of them differs from the others.",5 Experimental Results,[0],[0]
"We dedicate a portion of the examples as the dev set, and train up to 100% dev set accuracy.
",5 Experimental Results,[0],[0]
"7These fluctuations occur as the networks do not fully saturate their gates, meaning the LSTM implements an imperfect counter that accumulates small deviations during computation, e.g.: increasing the counting dimension by 0.99 but decreasing only by 0.98.",5 Experimental Results,[0],[0]
"Despite this, we see that the its solution remains much more robust than that found by the GRU — the LSTM has learned the essence of the counting based solution, but its implementation is imprecise.
network starts to misclassify on sequences much shorter than that).",5 Experimental Results,[0],[0]
"The anbncn state dynamics are even less interpretable.
",5 Experimental Results,[0],[0]
"Finally, we created 1000-sample test sets for each of the languages.",5 Experimental Results,[0],[0]
"For anbn we used words with the form an+ibn+j where n ∈ rand(0, 200) and i, j ∈ rand(−2, 2), and for anbncn we use words of the form an+ibn+jcn+k where n ∈ rand(0, 150) and i, j, k ∈ rand(−2, 2).",5 Experimental Results,[0],[0]
"The LSTM’s accuracy was 100% and 98.6% on anbn and anbncn respectively, as opposed to the GRU’s 87.0% and 86.9%, also respectively.
",5 Experimental Results,[0],[0]
"All of this empirically supports our result, showing that IBFP-LSTMs can not only theoretically implement “unbounded” counters, but also learn to do so in practice (although not perfectly), while IBFP-GRUs do not manage to learn proper counting behavior, even when allowing floating point computations.",5 Experimental Results,[0],[0]
"We show that the IBFP-LSTM can model a realtime SKCM, both in theory and in practice.",6 Conclusions,[0],[0]
"This makes it more powerful than the IBFP-SRNN and the IBFP-GRU, which cannot implement unbounded counting and are hence restricted to recognizing regular languages.",6 Conclusions,[0],[0]
"The IBFP-IRNN can also perform input-dependent counting, and is thus more powerful than the IBFP-SRNN.
",6 Conclusions,[0],[0]
"We note that in addition to theoretical distinctions between architectures, it is important to consider also the practicality of different solutions: how easy it is for a given architecture to discover and maintain a stable behavior in practice.",6 Conclusions,[0],[0]
We leave further exploration of this question for future work.,6 Conclusions,[0],[0]
The research leading to the results presented in this paper is supported by the European Union’s Seventh Framework Programme (FP7) under grant agreement no.,Acknowledgments,[0],[0]
"615688 (PRIME), The Israeli Science Foundation (grant number 1555/15), and The Allen Institute for Artificial Intelligence.
Appendix",Acknowledgments,[0],[0]
"We use a simplified variant of the k-counter machines (SKCM) defined in (Fischer et al., 1968), which has no autonomous states and makes classification decisions based on a combination of its current state and counter values.",A Simplified K-Counter Machines,[0],[0]
"This variant consumes input sequences on a symbol by symbol basis, updating at each step its state and its counters, the latter of which may be manipulated by increment, decrement, zero, or no-ops alone, and observed only by checking equivalence to zero.",A Simplified K-Counter Machines,[0],[0]
"To define the transitions of this model its accepting configurations, we will introduce the following notations:
Notations We define z :",A Simplified K-Counter Machines,[0],[0]
"Zk → {0, 1}k as follows: for every n ∈ Zk, for every 1 ≤",A Simplified K-Counter Machines,[0],[0]
"i ≤ k, z(n)i",A Simplified K-Counter Machines,[0],[0]
= 0 iff ni = 0,A Simplified K-Counter Machines,[0],[0]
(this function masks a set of integers such that only their zero-ness is observed).,A Simplified K-Counter Machines,[0],[0]
"For a vector of operations, o ∈ {−1,+1,×0,×1}k, we denote by o(n) the pointwise application of the operations to the vector n ∈",A Simplified K-Counter Machines,[0],[0]
"Zk, e.g. for o = (+1,×0,×1), o((5, 2, 3))",A Simplified K-Counter Machines,[0],[0]
"= (6, 0, 3).
",A Simplified K-Counter Machines,[0],[0]
We now define the model.,A Simplified K-Counter Machines,[0],[0]
"An SKCM is a tuple M = 〈Σ, Q, qo, k, δ, u, F 〉 containing:
1.",A Simplified K-Counter Machines,[0],[0]
A finite input alphabet Σ 2.,A Simplified K-Counter Machines,[0],[0]
A finite state set Q 3.,A Simplified K-Counter Machines,[0],[0]
An initial state q0 ∈ Q 4.,A Simplified K-Counter Machines,[0],[0]
"k ∈ N, the number of counters 5.",A Simplified K-Counter Machines,[0],[0]
"A state transition function
δ : Q× Σ× {0, 1}k",A Simplified K-Counter Machines,[0],[0]
"→ Q
6.",A Simplified K-Counter Machines,[0],[0]
"A counter update function8
u : Σ→ {−1,+1,×0,×1}k
7.",A Simplified K-Counter Machines,[0],[0]
"A set of accepting masked9 configurations
F ⊆ Q× {0, 1}k
The set of configurations of an SKCM is the set C = Q× Zk, and the initial configuration is c0 = (q0, 0̄) (i.e., the counters are initiated to zero).",A Simplified K-Counter Machines,[0],[0]
"The
8 We note that in this definition, the counter update function depends only on the input symbol.",A Simplified K-Counter Machines,[0],[0]
"In practice we see that the LSTM is not limited in this way, and can also update according to some state-input combinations — as can be seen when it it is taught, for instance, the language anban",A Simplified K-Counter Machines,[0],[0]
"We do not explore this here however, leaving a more complete characterization of the learnable models to future work.
9i.e., counters are observed only by zero-ness.
",A Simplified K-Counter Machines,[0],[0]
transitions of an SKCM are as follows: given a configuration ct,A Simplified K-Counter Machines,[0],[0]
"= (q, n) (n ∈ Zk) and inputwt ∈ Σ, the next configuration of the SKCM is ct+1 = (δ(q, wt, z(n)), u(wt)(n)).
",A Simplified K-Counter Machines,[0],[0]
"The language recognized by a k-counter machine is the set of words w for which the machine reaches an accepting configuration — a configuration c = (q, n) for which (q, z(n))",A Simplified K-Counter Machines,[0],[0]
"∈ F .
Note that while the counters can and are increased to various non-zero values, the transition function δ",A Simplified K-Counter Machines,[0],[0]
"and the accept/reject classification of the configurations observe only their zero-ness.
",A Simplified K-Counter Machines,[0],[0]
A.1 Computational Power of SKCMs,A Simplified K-Counter Machines,[0],[0]
"We show that the SKCM model can recognize the context-free and context-sensitive languages anbn and anbncn, but not the context free language of palindromes, meaning its computational power differs from the language classes defined in the Chomsky hierarchy.",A Simplified K-Counter Machines,[0],[0]
"Similar proofs appear in (Fischer et al., 1968) for their variant of the kcounter machine.
",A Simplified K-Counter Machines,[0],[0]
anbn:,A Simplified K-Counter Machines,[0],[0]
"We define the following SKCM over the alphabet {a, b}:
1.",A Simplified K-Counter Machines,[0],[0]
"Q = {qa, qb, qr} 2.",A Simplified K-Counter Machines,[0],[0]
q0 = qa 3.,A Simplified K-Counter Machines,[0],[0]
k,A Simplified K-Counter Machines,[0],[0]
= 1 4.,A Simplified K-Counter Machines,[0],[0]
"u(a) = +1, u(b) = −1",A Simplified K-Counter Machines,[0],[0]
5.,A Simplified K-Counter Machines,[0],[0]
"for any z ∈ {0, 1}: δ(qa, a, z) = qa, δ(qa, b, z) = qb, δ(qb, a, z) = qr, δ(qb, b, z) = qb δ(qr, a, z) = qr, δ(qr, b, z) = qr 6.",A Simplified K-Counter Machines,[0],[0]
"C = {(qb, 0)}
",A Simplified K-Counter Machines,[0],[0]
"The state qr is a rejecting sink state, and the states qa and qb keep track of whether the sequence is currently in the “a” or “b” phase.",A Simplified K-Counter Machines,[0],[0]
"If an a is seen after moving to the b phase, the machine moves to (and stays in) the rejecting state.",A Simplified K-Counter Machines,[0],[0]
"The counter is increased on input a and decreased on input b, and the machine accepts only sequences that reach the state qb with counter value zero, i.e., that have increased and decreased the counter an equal number of times, without switching from b to a.",A Simplified K-Counter Machines,[0],[0]
"It follows easily that this machine recognizes exactly the language anbn.
anbncn: We define the following SKCM over the alphabet {a, b}.",A Simplified K-Counter Machines,[0],[0]
"As its state transition function ignores the counter values, we use the shorthand δ(q, σ) for δ(q, σ, z), for all z ∈ {0, 1}2.
1.",A Simplified K-Counter Machines,[0],[0]
"Q = {qa, qb, qc, qr}
2.",A Simplified K-Counter Machines,[0],[0]
q0 = qa 3.,A Simplified K-Counter Machines,[0],[0]
k,A Simplified K-Counter Machines,[0],[0]
= 2 4.,A Simplified K-Counter Machines,[0],[0]
"u(a) = (+1, ∅), u(b) = (−1,+1), u(c) = (∅,−1) 5.",A Simplified K-Counter Machines,[0],[0]
"for any z ∈ {0, 1}: δ(qa, a) = qa, δ(qa, b) = qb, δ(qa, c) = qr, δ(qb, a) = qr, δ(qb, b) = qb, δ(qb, c) = qc, δ(qc, a) = qr, δ(qc, b) = qr, δ(qc, c) = qc, δ(qr, a) = qr, δ(qr, b) = qr, δ(qr, c) = qr 6.",A Simplified K-Counter Machines,[0],[0]
"C = {(qc, 0, 0)}
By similar reasoning as that for anbn, we see that this machine recognizes exactly the language anbncn.",A Simplified K-Counter Machines,[0],[0]
"We note that this construction can be extended to build an SKCM for any language of the sort an1a n 2 ...a n m, using k = m − 1 counters and k + 1 states.
",A Simplified K-Counter Machines,[0],[0]
"Palindromes: We prove that no SKCM can recognize the language of palindromes defined over the alphabet {a, b, x} by the grammar S → x|aSa|bSb.",A Simplified K-Counter Machines,[0],[0]
"The intuition is that in order to correctly recognize this language in an one-way setting, one must be able to reach a unique configuration for every possible input sequence over {a, b} (requiring an exponential number of reachable configurations), whereas for any SKCM, the number of reachable configurations is always polynomial in the input length.10
Let M be an SKCM with k counters.",A Simplified K-Counter Machines,[0],[0]
"As its counters are only manipulated by steps of 1 or resets, the maximum and minimum values that each counter can attain on any input w ∈ Σ∗",A Simplified K-Counter Machines,[0],[0]
"are +|w| and −|w|, and in particular the total number of possible values a counter could reach at the end of input w is 2|w| + 1.",A Simplified K-Counter Machines,[0],[0]
This means that the total number of possible configurations M could reach on input of length n is c(n) = |Q| · (2n+ 1)k.,A Simplified K-Counter Machines,[0],[0]
"c(n) is polynomial in n, and so there exists a value m for which the number of input sequences of length m over {a, b} — 2m — is greater than c(m).",A Simplified K-Counter Machines,[0],[0]
It follows by the pigeonhole principle that there exist two input sequences w1 6=,A Simplified K-Counter Machines,[0],[0]
"w2 ∈ {a, b}m for which M reaches the same configuration.",A Simplified K-Counter Machines,[0],[0]
"This means that for any suffix w ∈ Σ∗, and in particular for w = x · w−11 where w −1 1 is the reverse of w1, M classifies w1 · w and w2 · w 10This will hold even if the counter update function can rely on any state-input combination.
identically—despite the fact that w1 · x ·w−11 is in the language and w2 · x · w−11 is not.",A Simplified K-Counter Machines,[0],[0]
"This means that M necessarily does not recognize this palindrome language, and ultimately that no such M exists.
",A Simplified K-Counter Machines,[0],[0]
"Note that this proof can be easily generalized to any palindrome grammar over 2 or more characters, with or without a clear ‘midpoint’ marker.
",A Simplified K-Counter Machines,[0],[0]
"B Impossibility of Counting in Binary
While we have seen that the SRNN and GRU cannot allocate individual counting dimensions, the question remains whether they can count using a more elaborate mechanism, perhaps over several dimensions.",A Simplified K-Counter Machines,[0],[0]
"We show here that one such mechanism — a binary counter — is not implementable in the SRNN.
",A Simplified K-Counter Machines,[0],[0]
"For the purposes of this discussion, we first define a binary counter in an RNN.
",A Simplified K-Counter Machines,[0],[0]
"Binary Interpretation In an RNN with hidden state values in the range (−1, 1), the binary interpretation of a sequence of dimensions d1, ..., dn of its hidden state is the binary number obtained by replacing each positive hidden value in the sequence with a ‘1’ and each negative value with a ‘0’.",A Simplified K-Counter Machines,[0],[0]
"For instance: the binary interpretation of the dimensions 3,0,1 in the hidden state vector (0.5,−0.1, 0.3, 0.8) is 110, i.e., 6.
",A Simplified K-Counter Machines,[0],[0]
"Binary Counting We say that the dimensions d1, d2, ..., dn in an RNN’s hidden state implement a binary counter in the RNN if, in every transition, their binary interpretation either increases, decreases, resets to 0, or doesn’t change.11
A similar pair of definitions can be made for state values in the range (0, 1).
",A Simplified K-Counter Machines,[0],[0]
We first note intuitively that an SRNN would not generalize binary counting to a counter with dimensions beyond those seen in training — as it would have no reason to learn the ‘carry’ behavior between the untrained dimensions.,A Simplified K-Counter Machines,[0],[0]
"We prove further that we cannot reasonably implement such counters regardless.
",A Simplified K-Counter Machines,[0],[0]
We now present a proof sketch that a singlelayer SRNN with hidden size n ≥ 3 cannot implement an n-dimensional binary counter that will consistently increase on one of its input symbols.,A Simplified K-Counter Machines,[0],[0]
"After this, we will prove that even with helper
11We note that the SKCMs presented here are more restricted in their relation between counter action and transition, but prefer here to give a general definition.",A Simplified K-Counter Machines,[0],[0]
"Our proof will be relevant even within the restrictions.
dimensions, we cannot implement a counter that will consistently increase on one input token and decrease on another — as we might want in order to classify the language of all words w for which #a(w)",A Simplified K-Counter Machines,[0],[0]
"= #b(w).12
Consistently Increasing Counter: The proof relies on the linearity of the affine transform Wx+",A Simplified K-Counter Machines,[0],[0]
"Uh + b, and the fact that ‘carry’ is a non-linear operation.",A Simplified K-Counter Machines,[0],[0]
"We work with state values in the range (−1, 1), but the proof can easily be adapted to (0, 1) by rewriting h as h′ + 0.5, where h′",A Simplified K-Counter Machines,[0],[0]
"= h − 0.5 is a vector with values in the range (−0.5, 0.5).
",A Simplified K-Counter Machines,[0],[0]
"Suppose we have a single-layer SRNN with hidden size n = 3, such that its entire hidden state represents a binary counter that increases every time it receives the input symbol a.",A Simplified K-Counter Machines,[0],[0]
"We denote by xa the embedding of a, and assume w.l.o.g. that the hidden state dimensions are ordered from MSB to LSB, e.g. the hidden state vector (1, 1,−1) represents the number 110=6.
",A Simplified K-Counter Machines,[0],[0]
Recall that the binary interpretation of the hidden state relies only on the signs of its values.,A Simplified K-Counter Machines,[0],[0]
"We use p and n to denote ‘some’ positive or negative value, respectively.",A Simplified K-Counter Machines,[0],[0]
"Then the number 6 can be represented by any state vector (p, p, n).
",A Simplified K-Counter Machines,[0],[0]
"Recall also that the SRNN state transition is
ht = tanh(Wxt + Uht−1 + b)
and consider the state vectors (−1, 1, 1) and (1,−1,−1), which represent 3 and 4 respectively.",A Simplified K-Counter Machines,[0],[0]
"Denoting b̃ = Wxa + b, we find that the constants U and b̃ must satisfy:
tanh(U(−1, 1, 1)",A Simplified K-Counter Machines,[0],[0]
+ b̃) =,A Simplified K-Counter Machines,[0],[0]
"(p, n, n) tanh(U(1,−1,−1) + b̃) =",A Simplified K-Counter Machines,[0],[0]
"(p, n, p)
As tanh is sign-preserving, this simplifies to:
U(−1, 1, 1) = (p, n, n)− b̃ U(1,−1,−1) =",A Simplified K-Counter Machines,[0],[0]
"(p, n, p)−",A Simplified K-Counter Machines,[0],[0]
"b̃
Noting the linearity of matrix multiplication and that (1,−1,−1) = −(−1, 1, 1), we obtain:
U(−1, 1, 1) = U(−(1,−1,−1))",A Simplified K-Counter Machines,[0],[0]
"= −U(1,−1,−1) 12Of course a counter could also be ‘decreased’ by incrementing a parallel, ‘negative’ counter, and implementing compare-to-zero as a comparison between these two.",A Simplified K-Counter Machines,[0],[0]
"As intuitively no RNN could generalize binary counting behavior to dimensions not used in training, this approach could quickly find both counters outside of their learned range even on a sequence where the difference between them is never larger than in training.
",A Simplified K-Counter Machines,[0],[0]
"(p, n, n)− b̃ = b̃− (p, n, p) i.e. for some assignment to each p and n, 2b̃ = (p, n, n)",A Simplified K-Counter Machines,[0],[0]
"+ (p, n, p), and in particular b̃[1]",A Simplified K-Counter Machines,[0],[0]
"< 0.
",A Simplified K-Counter Machines,[0],[0]
"Similarly, for (−1,−1, 1) and (1, 1,−1), we obtain
U(−1,−1, 1) =",A Simplified K-Counter Machines,[0],[0]
"(n, p, n)− b̃ U(1, 1,−1)",A Simplified K-Counter Machines,[0],[0]
"= (p, p, p)−",A Simplified K-Counter Machines,[0],[0]
"b̃
i.e. (n, p, n)− b̃ =",A Simplified K-Counter Machines,[0],[0]
"b̃− (p, p, p)
or 2b̃ = (p, p, p) + (n, p, n), and in particular that b̃[1]",A Simplified K-Counter Machines,[0],[0]
"> 0, leading to a contradiction and proving that such an SRNN cannot exist.",A Simplified K-Counter Machines,[0],[0]
The argument trivially extends to n > 3,A Simplified K-Counter Machines,[0],[0]
"(by padding from the MSB).
",A Simplified K-Counter Machines,[0],[0]
"We note that this proof does not extend to the case where additional, non counting dimensions are added to the RNN — at least not without further assumptions, such as the assumption that the counter behave correctly for all values of these dimensions, reachable and unreachable.",A Simplified K-Counter Machines,[0],[0]
"One may argue then that, with enough dimensions, it could be possible to implement a consistently increasing binary counter on a subset of the SRNN’s state.13 We now show a counting mechanism that cannot be implemented even with such ‘helper’ dimensions.
",A Simplified K-Counter Machines,[0],[0]
"Bi-Directional Counter: We show that for n ≥ 3, no SRNN can implement an n-dimensional binary counter that increases for one token, σup, and decreases for another, σdown.",A Simplified K-Counter Machines,[0],[0]
"As before, we show the proof explicitly for n = 3, and note that it can be simply expanded to any n > 3",A Simplified K-Counter Machines,[0],[0]
"by padding.
",A Simplified K-Counter Machines,[0],[0]
"Assume by contradiction we have such an SRNN, with m ≥ 3 dimensions, and assume w.l.o.g.",A Simplified K-Counter Machines,[0],[0]
that a counter is encoded along the first 3 of these.,A Simplified K-Counter Machines,[0],[0]
"We use the shorthand (v1, v2, v3)c to show the values of the counter dimensions explicitly while abstracting the remaining state dimensions, e.g. we write the hidden state (−0.5, 0.1, 1, 1, 1) as (−0.5, 0.1, 1)c where c = (1, 1).
",A Simplified K-Counter Machines,[0],[0]
"Let xup and xdown be the embeddings of σup and σdown, and as before denote",A Simplified K-Counter Machines,[0],[0]
bup = Wxup + b and bdown = Wxdown,A Simplified K-Counter Machines,[0],[0]
+,A Simplified K-Counter Machines,[0],[0]
b.,A Simplified K-Counter Machines,[0],[0]
"Then for some reachable state h1 ∈ R where the counter value is 1 (e.g., the state reached on the input sequence σup
14)), we find that the constants U, bdown, and 13(By storing processing information on the additional, ‘helper’ dimensions) 14(Or",A Simplified K-Counter Machines,[0],[0]
"whichever appropriate sequence if the counter is not initiated to zero.)
",A Simplified K-Counter Machines,[0],[0]
"bup must satisfy:
tanh(Uh1 + bup) = (n, p, n)c1
tanh(Uh1 + bdown) =",A Simplified K-Counter Machines,[0],[0]
"(n, n, n)c2
(i.e., σup increases the counter and updates the additional dimensions to the values c1, while σdown decreases and updates to c2.)",A Simplified K-Counter Machines,[0],[0]
"Removing the signpreserving function tanh we obtain the constraints
Uh1 + bup",A Simplified K-Counter Machines,[0],[0]
"= (n, p, n)sign(c1)
Uh1 + bdown = (n, n, n)sign(c2)
i.e. (bup − bdown)[0 : 2] = (n, p, n)",A Simplified K-Counter Machines,[0],[0]
"− (n, n, n), and in particular (bup − bdown)[1] >",A Simplified K-Counter Machines,[0],[0]
0.,A Simplified K-Counter Machines,[0],[0]
Now consider a reachable state h3 for which the counter value is 3.,A Simplified K-Counter Machines,[0],[0]
"Similarly to before, we now obtain
Uh3 + bup = (p, n, n)sign(c3)
Uh3 + bdown = (n, p, n)sign(c4)
from which we get (bup − bdown)[0 : 2] = (p, n, n)",A Simplified K-Counter Machines,[0],[0]
"− (n, p, n), and in particular (bup − bdown)[1] < 0, a contradiction to the previous statement.",A Simplified K-Counter Machines,[0],[0]
Again we conclude that no such SRNN can exist.,A Simplified K-Counter Machines,[0],[0]
"While Recurrent Neural Networks (RNNs) are famously known to be Turing complete, this relies on infinite precision in the states and unbounded computation time.",abstractText,[0],[0]
We consider the case of RNNs with finite precision whose computation time is linear in the input length.,abstractText,[0],[0]
"Under these limitations, we show that different RNN variants have different computational power.",abstractText,[0],[0]
"In particular, we show that the LSTM and the Elman-RNN with ReLU activation are strictly stronger than the RNN with a squashing activation and the GRU.",abstractText,[0],[0]
This is achieved because LSTMs and ReLU-RNNs can easily implement counting behavior.,abstractText,[0],[0]
We show empirically that the LSTM does indeed learn to effectively use the counting mechanism.,abstractText,[0],[0]
On the Practical Computational Power of Finite Precision RNNs for Language Recognition,title,[0],[0]
"The cardinality constraint is an intrinsic way to restrict the solution structure in many real problems, for example, sparse learning (Olshausen & Field, 1997), feature selection (Zhang, 2009), and compressed sensing (Candes et al., 2006).",1. Introduction,[0],[0]
"The generic cardinality constrained optimization can be expressed as
min w2Rp f(w) (1a) subject to kwgk0  sg 8g 2 G (1b) 1University of Rochester, Rochester, NY, USA 2NEC, Cupertino, CA, USA.",1. Introduction,[0],[0]
Correspondence to: Haichuan Yang,1. Introduction,[0],[0]
"<h.yang@rochester.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"where w is the optimization variable, g is an index subset of [p] := {1, 2, · · · , p}, wg is the sub-vector of w indexed by g. kwgk0 denotes the cardinality of the sub-vector, i.e., the number of nonzeros in wg , G is the hyper set of all predefined groups, and s 2 R|G| is the upper bound vector - sg 2 R refers to the upper bound of the sparsity over group g. Objective f is the loss function which could be defined with different form according to the specific application.",1. Introduction,[0],[0]
The problem (1) refers to a nonconvex optimization (NP-hard) due to the cardinality constraint.,1. Introduction,[0],[0]
"Some efficient iterative methods such as IHT (Yuan et al., 2014), CoSaMP (Needell & Tropp, 2009), GradMP (Nguyen et al., 2012), and their variants can guarantee to solve the original problem under some mild conditions.",1. Introduction,[0],[0]
"A key component in all of these methods is the projection operator
P ⌦(G,s)(v) := argmin w2⌦(G,s) kw vk2 (2)
where ⌦(G, s) denotes the feasible set to the constraint (1b).",1. Introduction,[0],[0]
"While in some special case, for example, G = {[p]}, the projection is trivial, it is quite challenging, especially when G includes multiple overlapped index sets (even NP-hard in some cases).
",1. Introduction,[0],[0]
"In this paper, we consider the scenario where the overlapped cardinality constraints (1b) satisfy a Three-view Cardinality Structure (TVCS):
Definition 1.",1. Introduction,[0],[0]
(Three-view Cardinality Structure (TVCS)),1. Introduction,[0],[0]
"For ⌦(G, s), the hyper set G consisting of subsets of [p] admits the TVCS structure if the following conditions are satisfied:
• There exists a partition G 0 , G 1 and G 2 such that G = G 0",1. Introduction,[0],[0]
"[ G 1 [ G 2 ;
• G 0 =",1. Introduction,[0],[0]
{,1. Introduction,[0],[0]
"[p]};
• All element sets in G 1 have no overlap;
•",1. Introduction,[0],[0]
"All element sets in G 2 have no overlap.
",1. Introduction,[0],[0]
"This definition basically requires that G can be partitioned into three hyper sets G
0 , G 1 , and G 2 , and overlaps can only happen between element sets in different hyper sets.",1. Introduction,[0],[0]
"G
0
is
usually used to restrict the overall sparsity.",1. Introduction,[0],[0]
"Figure 1 provides two examples of G for TVCS.
",1. Introduction,[0],[0]
"The TVCS model is motivated from some important applications, for example, in recommendation, task-worker assignment, and bioinformatics.
",1. Introduction,[0],[0]
• Online recommendation.,1. Introduction,[0],[0]
"Suppose we want to recommend a certain number of books (among p books) to a customer - corresponding to the G
0 based sparsity constraint.",1. Introduction,[0],[0]
"Among the selected books, we want to maintain some diversities - the recommended books by the same author should not exceed a certain number (G
1 based sparsity constraint) and about the same topic should not exceed a certain number either (G
2
based sparsity constraint).",1. Introduction,[0],[0]
"One can refer to the top graph in Figure 1: G
1 is grouped by authors and G 2 is grouped by topics.
",1. Introduction,[0],[0]
• Task-worker assignment.,1. Introduction,[0],[0]
"Suppose we have a bunch of tasks and workers, and we want to assign the tasks to workers.",1. Introduction,[0],[0]
"For example, in crowdsourcing, we usually assign several different workers to each task since we want to use the answers from multiple workers to improve the accuracy.",1. Introduction,[0],[0]
"On the other hand, each worker is usually assigned to multiple tasks so there is a “many to many” relationship in this assignment.
",1. Introduction,[0],[0]
"The goal is to pursue the optimal assignment under a certain criteria in crowdsourcing, while satisfying some restrictions.",1. Introduction,[0],[0]
"For example, the total assignments should be bounded by the total budget (corresponding to G
0 ), the total cost of assignments to a single worker cannot exceed a certain threshold (corresponding to G 1
), and the total cost of assignments on a single task cannot exceed a certain threshold (corresponding to G 2
).",1. Introduction,[0],[0]
"Let X be the assignment matrix, and its rows are indexed by workers and the columns are indexed by tasks.",1. Introduction,[0],[0]
"These constraints can be illustrated by the bottom graph in Figure 1.
",1. Introduction,[0],[0]
• Identification of gene regulatory networks.,1. Introduction,[0],[0]
"The essential goal of identifying gene regulatory network is to identify a weighted directed graph, which can be represented by a square matrix W with p = N ⇥ N elements in total where N is the number of vertices.",1. Introduction,[0],[0]
"A sparse network constraint is to restrict the in-degree and out-degree for each vertex, which corresponds to the sparsity in each row and column of W .
",1. Introduction,[0],[0]
"To solve the TVCS constrained projection (2), we show an interesting connection between the projection and a linear programming (LP) that the vertex solution to this linear programming is an integer solution which solves the original problem.
",1. Introduction,[0],[0]
"To find an integer solution to such LP efficiently, we formulate it into a feasibility problem, and further an equivalent quadratic convex optimization.",1. Introduction,[0],[0]
"By using the rounding technique, we can avoid solving the exact solution of this LP problem.",1. Introduction,[0],[0]
We propose an iterative algorithm to solve it and each iteration can be completed in linear time.,1. Introduction,[0],[0]
We also show that the iterate linearly converges to the optimal point.,1. Introduction,[0],[0]
"Finally, the proposed TVCS model is validated by the synthetic experiment and two important and novel applications in identification of gene regulatory networks and task assignment problem of crowdsourcing.",1. Introduction,[0],[0]
Recent years have witnessed many research works in the field of structured sparsity and group-based sparsity.,2. Related Works,[0],[0]
"Yuan & Lin (2006) introduced the group LASSO, which pursues group-wise sparsity that restricts the number of groups for the selected variables.",2. Related Works,[0],[0]
Jenatton et al. (2011) construct a hierarchical structure over the variables and use group LASSO with overlapped groups to solve it.,2. Related Works,[0],[0]
"Exclusive LASSO (Zhou et al., 2010; Kong et al., 2014) was proposed for the exclusive group sparsity which can be treated as relaxing our cardinality constraints to convex regularizations.",2. Related Works,[0],[0]
"In (Kong et al., 2014), the authors discussed the overlapping situation and tried to solve the problem using convex relaxation, which is different from our approach.
",2. Related Works,[0],[0]
"Besides the aforementioned works, some proposed more general models to cover various sparsity structures.",2. Related Works,[0],[0]
"Bach et al. (2012) extended the usage of L
1 -norm relaxation to several different categories of structures.",2. Related Works,[0],[0]
"And recently, another generalization work (El Halabi & Cevher, 2015) proposed convex envelopes for various sparsity structures.",2. Related Works,[0],[0]
"They built the framework by defining a totally unimodular penalty, and showed how to formulate different sparsity structures using the penalty.",2. Related Works,[0],[0]
"The work above concentrated on using convex relaxation to control the sparsity.
",2. Related Works,[0],[0]
"Besides using convex relaxation, there are also some works focusing on projection-based methods.",2. Related Works,[0],[0]
"When the exact projection operator was provided, Baraniuk et al. (2010) extended the traditional IHT and CoSaMP methods to general sparsity structures.",2. Related Works,[0],[0]
"In this work, the authors also introduced the projection operator for block sparsity and tree sparsity.",2. Related Works,[0],[0]
Cevher et al. (2009) investigated cluster sparsity,2. Related Works,[0],[0]
and they applied dynamic programming to solve the projection operator for their sparsity model.,2. Related Works,[0],[0]
"Hegde et al. (2009) introduced a “spike trains” signal model, which is also related to exclusive group sparsity.",2. Related Works,[0],[0]
"Its groups always have consecutive coordinates, and each group cannot contain more than one nonzero element.",2. Related Works,[0],[0]
"To solve the projection problem of their model, they showed the basic feasible solutions of the relaxed linear programming (LP) are always integer points.",2. Related Works,[0],[0]
"In our work, we also use LP to solve the projection problem.",2. Related Works,[0],[0]
"But our model defines the group structure differently and aims at different applications.
",2. Related Works,[0],[0]
"In addition, there are some works for the cases without an efficient exact projection operator (Hegde et al., 2015a;b; Nguyen et al., 2014).",2. Related Works,[0],[0]
This is meaningful since the projection operator for complex structured sparsity often involves solving complicated combinatorial optimization problems.,2. Related Works,[0],[0]
Hegde et al. (2015a) discussed how to guarantee convergence if using approximate projection in IHT and CoSaMP for compressive sensing.,2. Related Works,[0],[0]
They proved that the convergence needs a “head approximation” to project the update (gradient) before applying it.,2. Related Works,[0],[0]
"Hegde et al. (2015b) proposed a general framework to formulate a series of models as a weighted graph, and designed an efficient approximate projection operator for the models.",2. Related Works,[0],[0]
Nguyen et al. (2014) applied the approximate projection-based IHT and CoSaMP to general convex functions and stochastic gradients.,2. Related Works,[0],[0]
"This section briefly reviews two commonly used algorithm frameworks to solve the cardinality constrained optimization (1): iterative hard thresholding (IHT) (Yuan et al., 2014; Nguyen et al., 2014) and gradient matching pursuit (GradMP) (Nguyen et al., 2012; 2014) (the general version of CoSaMP (Needell & Tropp, 2009)) for solving
cardinality constrained problem.",3. Preliminary: GradMP and IHT Frameworks,[0],[0]
"Other methods like hard thresholding pursuit (HTP) also follows similar steps and has been shown to be effective both empirically and theoretically (Yuan et al., 2016).",3. Preliminary: GradMP and IHT Frameworks,[0],[0]
"The procedures of IHT and GradMP for our model are shown in Algorithms 1 and 2, where supp(·) is the support set of the argument vector.
",3. Preliminary: GradMP and IHT Frameworks,[0],[0]
"Therefore, one can see that the efficiency of both algorithms relies on the computation of the gradient and the projection.",3. Preliminary: GradMP and IHT Frameworks,[0],[0]
"To avoid the expensive computation of the gradient, GradMP and IHT can be extended to the stochastic versions (Nguyen et al., 2014) by assigning g the stochastic gradient at the gradient computation step.
",3. Preliminary: GradMP and IHT Frameworks,[0],[0]
"Both Algorithms 1 and 2 (and their stochastic variants) guarantee some nice properties: the iterate converges to a small ball surrounding the true solution at a linear rate under certain RIP-type conditions (Nguyen et al., 2014) and the radius of such ball converges to zero when the number of samples goes to infinity.
",3. Preliminary: GradMP and IHT Frameworks,[0],[0]
Algorithm 1: Iterative Hard Thresholding.,3. Preliminary: GradMP and IHT Frameworks,[0],[0]
Input: Sparsity parameter s. Result:,3. Preliminary: GradMP and IHT Frameworks,[0],[0]
"Problem solution wt. Initialize w0, t = 0; while stop criterion is not met do
g = rf(wt) ; // Gradient computation z t = w
t g ; // Gradient descent w t+1 = P ⌦(G,s)(z t ) ; // Projection
t = t+ 1; end
Algorithm 2: Gradient Matching Pursuit.",3. Preliminary: GradMP and IHT Frameworks,[0],[0]
Input: Sparsity parameter s. Result:,3. Preliminary: GradMP and IHT Frameworks,[0],[0]
"Problem solution wt. Initialize w0, t = 0; while stop criterion is not met do
g = rf(wt); // Gradient computation = supp(P
⌦(G,2s)(g));",3. Preliminary: GradMP and IHT Frameworks,[0],[0]
"ˆ
=",3. Preliminary: GradMP and IHT Frameworks,[0],[0]
"[ supp(wt) ; // Subspace selection z
t = argminsupp(z)=ˆ f(z) ; // Subspace
optimization
w t+1 = P ⌦(G,s)(z t ) ; // Projection
t = t+ 1; end
A common component in Algorithms 1 and 2 is the projection operator.",3. Preliminary: GradMP and IHT Frameworks,[0],[0]
"If all the groups except [p] in G do not overlap each other, the projection problem can be easily solved by sequential projections (Yang et al., 2016).",3. Preliminary: GradMP and IHT Frameworks,[0],[0]
"But for those cases involving overlapped groups, it is generally challenging to solve them efficiently.",3. Preliminary: GradMP and IHT Frameworks,[0],[0]
This section introduces how to solve the essential projection step.,4. Projection Operator,[0],[0]
Note that the projection onto a nonconvex set is NP-hard in general.,4. Projection Operator,[0],[0]
"By utilizing the special structure of TVCS, we show that the projection can be solved efficiently.",4. Projection Operator,[0],[0]
"Due to the page limitation, all proofs are provided in the supplementary material.",4. Projection Operator,[0],[0]
"Firstly, we can cast the projection problem (2) to an equivalent integer linear programming problem (ILP) according to Lemma 1.",4.1. LP Relaxation,[0],[0]
Lemma 1.,4.1. LP Relaxation,[0],[0]
"The projection problem (2) is equivalent to the following integer linear programming problem (ILP):
max
x
hv2,xi (3)
subject to Ax  s x 2 {0, 1}p
where v2 is applying element-wise square operation on vector v. A is a |G|⇥ p matrix which is defined as:
A =
 1 >
C
(4)
where C 2 {0, 1}|G1[G2|⇥p, whose rows represent the indicator vector of each group g 2 G
1 and G 2 .
",4.1. LP Relaxation,[0],[0]
"Each row in A corresponds to one group g from G. For example, Cij = 1 if the j-th coordinate is in the i-th group, otherwise Cij = 0.",4.1. LP Relaxation,[0],[0]
"The first row 1> corresponds to the overall sparsity i.e. G
0
.
",4.1. LP Relaxation,[0],[0]
It is NP-hard to solve an ILP in general.,4.1. LP Relaxation,[0],[0]
One common way to handle such ILP is making a linear programming (LP) relaxation.,4.1. LP Relaxation,[0],[0]
"In our case, we can use a box constraint x 2",4.1. LP Relaxation,[0],[0]
"[0, 1]p to replace the integer constraint x 2 {0, 1}p:
max
x
hv2,xi (5)
subject to Ax  s x 2",4.1. LP Relaxation,[0],[0]
"[0, 1]p
However, there is no guarantee that a general ILP can be solved via its LP relaxation, because the solution of the relaxed LP is not always integer.",4.1. LP Relaxation,[0],[0]
"Although one can make a rounding to the LP solution and acquire a integer solution, such solution is not guaranteed to be optimal (or even feasible) to the original ILP.
",4.1. LP Relaxation,[0],[0]
"Fortunately, due to the special structure of our TVCS model, we find that its relaxed LP has some nice properties which make it possible to get the optimal solution of the ILP efficiently.",4.1. LP Relaxation,[0],[0]
"The following theorem reveals the relationship between the ILP problem and the relaxed LP problem.
",4.1. LP Relaxation,[0],[0]
Theorem 2.,4.1. LP Relaxation,[0],[0]
"Given G satisfying TV CS, all the vertices of the feasible set to (5) are integer points.",4.1. LP Relaxation,[0],[0]
"Furthermore, there is an optimal solution on the vertex that solves the ILP (3).
",4.1. LP Relaxation,[0],[0]
"This theorem suggests that finding a vertex solution of the relaxed LP can solve the original projection problem onto a TVCS G. The proof basically shows that matrix A (for TVCS) is a totally unimodular matrix (Papadimitriou & Steiglitz, 1982).",4.1. LP Relaxation,[0],[0]
We provide the detailed proof in the supplementary material.,4.1. LP Relaxation,[0],[0]
"To find a solution on the vertex, one can use the Simplex method.",4.2. Linearly Convergent Algorithm for Projection Operator onto TVCS,[0],[0]
"Although Simplex method guarantees to find an optimal solution on the vertex and could be very efficient in practice, it does not have a deterministic complexity bound.",4.2. Linearly Convergent Algorithm for Projection Operator onto TVCS,[0],[0]
"In the IHT and GradMP algorithms, projection operator is only a sub-procedure in one iteration.",4.2. Linearly Convergent Algorithm for Projection Operator onto TVCS,[0],[0]
"Hence, we are usually supposed to solve lots of instances of problem (3).",4.2. Linearly Convergent Algorithm for Projection Operator onto TVCS,[0],[0]
"Simplex might be efficient practically, but its worst case may lead to exponential time complexity (Papadimitriou & Steiglitz, 1982).",4.2. Linearly Convergent Algorithm for Projection Operator onto TVCS,[0],[0]
"In this section, the integer solution to the linear programming can be found within the complexity proportional to the number of variables and constraints.
",4.2. Linearly Convergent Algorithm for Projection Operator onto TVCS,[0],[0]
Equivalent Feasibility Problem Formulation.,4.2. Linearly Convergent Algorithm for Projection Operator onto TVCS,[0],[0]
"The dual of LP problem (5) can be written as:
min
y
h[s> 1>]>,yi (6)
subject to ⇥",4.2. Linearly Convergent Algorithm for Projection Operator onto TVCS,[0],[0]
A>,4.2. Linearly Convergent Algorithm for Projection Operator onto TVCS,[0],[0]
I ⇤ y,4.2. Linearly Convergent Algorithm for Projection Operator onto TVCS,[0],[0]
"v2,y 0
Since the duality gap of LP is zero, combining the primal LP (5) and dual LP (6), we can formulate an equivalent problem, i.e. the feasibility problem over the following constraints:
find x,y
subject to h[s> 1>]>,yi = hv2,xi ⇥",4.2. Linearly Convergent Algorithm for Projection Operator onto TVCS,[0],[0]
A>,4.2. Linearly Convergent Algorithm for Projection Operator onto TVCS,[0],[0]
"I ⇤ y v2
 A I x   s 1
y 0,x 0
Iterative Algorithm.",4.2. Linearly Convergent Algorithm for Projection Operator onto TVCS,[0],[0]
"The feasibility problem with linear constraints above is equivalent to the following optimiza-
tion problem:
min
x,y
1
2
(h[s> 1>]>,yi hv2,xi)2
+
1
2
k[v2",4.2. Linearly Convergent Algorithm for Projection Operator onto TVCS,[0],[0]
"[A> I]y] +
k2 + 1 2 k[Ax s] + k2
(7)
subject to 0  x  1,y 0
where [z] + is the element-wise hinge operator, i.e. it transforms each element zi to max(zi, 0).
",4.2. Linearly Convergent Algorithm for Projection Operator onto TVCS,[0],[0]
This is a convex optimization problem with a quadratic objective and box constraints.,4.2. Linearly Convergent Algorithm for Projection Operator onto TVCS,[0],[0]
"We adopt the projected gradient descent to solve this problem, and show it converges linearly.
",4.2. Linearly Convergent Algorithm for Projection Operator onto TVCS,[0],[0]
Theorem 3.,4.2. Linearly Convergent Algorithm for Projection Operator onto TVCS,[0],[0]
"For the optimization problem with the form
min
z
f(z) := k[Az a] + k2 + kBz bk2
subject to z 2 ⌦
where ⌦ = {z | Cz  c}, the projected gradient descent algorithm zt+1 P
⌦
(z t rf(zt)) has a linear convergence rate with some ↵ < 1 (depending on A and B):
kzt+1 P z ⇤ (z t+1 )k  ↵kzt P z ⇤ (z t )k,
where P z ⇤ (·) is the projection onto the optimal solution set.
",4.2. Linearly Convergent Algorithm for Projection Operator onto TVCS,[0],[0]
"Notice that the objective function f in Theorem 3 is not necessarily strongly convex, which means the well recognized linear convergence conclusion from the strong convexity is not applicable here.
",4.2. Linearly Convergent Algorithm for Projection Operator onto TVCS,[0],[0]
"Theorem 3 mainly applies Hoffman’s Theorem (Hoffman, 2003) to show that f is an optimal strongly convex function (Liu & Wright, 2015).",4.2. Linearly Convergent Algorithm for Projection Operator onto TVCS,[0],[0]
"This leads to a linear convergence rate.
",4.2. Linearly Convergent Algorithm for Projection Operator onto TVCS,[0],[0]
"The convergence rate ↵ = 1/(1+ L ), where is the Hoffman constant (Hoffman, 2003) that depends on A,B and is always positive.",4.2. Linearly Convergent Algorithm for Projection Operator onto TVCS,[0],[0]
L is the Lipschitz continuous gradient constant.,4.2. Linearly Convergent Algorithm for Projection Operator onto TVCS,[0],[0]
"More details are included in the supplementary materials.
",4.2. Linearly Convergent Algorithm for Projection Operator onto TVCS,[0],[0]
"To show the complexity of this algorithm, we firstly count how many iterations we need.",4.2. Linearly Convergent Algorithm for Projection Operator onto TVCS,[0],[0]
Since we know that we can just make a rounding1 to the result xt when we attain kxt ˜,4.2. Linearly Convergent Algorithm for Projection Operator onto TVCS,[0],[0]
"x
⇤k1 < 0.5.",4.2. Linearly Convergent Algorithm for Projection Operator onto TVCS,[0],[0]
Let z,4.2. Linearly Convergent Algorithm for Projection Operator onto TVCS,[0],[0]
:=,4.2. Linearly Convergent Algorithm for Projection Operator onto TVCS,[0],[0]
[x> y>]> represent all the variables in (7).,4.2. Linearly Convergent Algorithm for Projection Operator onto TVCS,[0],[0]
Because kzt z⇤k kzt z⇤k1 kxt,4.2. Linearly Convergent Algorithm for Projection Operator onto TVCS,[0],[0]
"x⇤k1, we can do the rounding safely when kzt z⇤k < 0.5, where z
⇤,x⇤ are the optimal points of this problem.",4.2. Linearly Convergent Algorithm for Projection Operator onto TVCS,[0],[0]
According to 1Acute readers may notice that the convergent point may be on the face of the polytope in some cases instead of vertex.,4.2. Linearly Convergent Algorithm for Projection Operator onto TVCS,[0],[0]
"However, we can add a small random perturbation to ensure the optimal point to be vertices with probability 1.
",4.2. Linearly Convergent Algorithm for Projection Operator onto TVCS,[0],[0]
"Theorem 3, we have the linear convergence rate ↵ < 1, so the number of iterations we need is
t > log↵ 1
",4.2. Linearly Convergent Algorithm for Projection Operator onto TVCS,[0],[0]
"2kz0 z⇤k Therefore, we claim that we can obtain the solution x⇤ by rounding after log↵ 1 2kz0 z⇤k iterations.
",4.2. Linearly Convergent Algorithm for Projection Operator onto TVCS,[0],[0]
"Secondly, we show that the computation complexity in each iteration is linear with dimensionality p and the amount of groups |G|.",4.2. Linearly Convergent Algorithm for Projection Operator onto TVCS,[0],[0]
"Since each column of A contains at most 3 nonzero elements, the complexity of the matrix multiplications in computing the gradient of (7) is O(p+ |G|).",4.2. Linearly Convergent Algorithm for Projection Operator onto TVCS,[0],[0]
"Together with other computation, the complexity for each iteration is O(p+ |G|).",4.2. Linearly Convergent Algorithm for Projection Operator onto TVCS,[0],[0]
This section will validate the proposed method on both synthetic data and two practical applications: crowdsourcing and identification of gene regulatory networks.,5. Empirical Study,[0],[0]
"In this section, we validate the proposed method with linear regression objective and squared hinge objective (classification) on synthetic data.",5.1. Linear Regression and Classification on Synthetic Data,[0],[0]
"Let w 2 R p p⇥pp be a matrix, G 1 and G 2
are defined as groups with all rows and all columns respectively.",5.1. Linear Regression and Classification on Synthetic Data,[0],[0]
"The linear regression loss is defined as Pn i=1(hXi,wi yi)2 and the squared hinge loss is de-
fined as Pn
i=1 max(0, 1 yihXi,wi)2, where n is the total number of training samples.",5.1. Linear Regression and Classification on Synthetic Data,[0],[0]
Xi and yi are the features and label of the i-th sample respectively.,5.1. Linear Regression and Classification on Synthetic Data,[0],[0]
R p p⇥pp is generated from the following procedure: generate a random vector and apply the projection operator to get a support set which satisfy our sparsity constraints; the elements of positions in support set are drawn from standard normal distribution.,"In the linear regression experiment, the true model ¯w 2",[0],[0]
p is fixed as 400 and n is gradually increased.,"In the linear regression experiment, the true model ¯w 2",[0],[0]
"The group sparsity upper bounds sg for g 2 G
1 and g 2 G 2 are uniformly generated from the integers in the range[1,pp].","In the linear regression experiment, the true model ¯w 2",[0],[0]
"The overall sparsity upper bound is set by 0.8⇥min(
P g2G1 s g, P g2G2 s g ).","In the linear regression experiment, the true model ¯w 2",[0],[0]
"Each Xi’s is anp
p ⇥","In the linear regression experiment, the true model ¯w 2",[0],[0]
pp i.i.d.,"In the linear regression experiment, the true model ¯w 2",[0],[0]
Gaussian random matrix.,"In the linear regression experiment, the true model ¯w 2",[0],[0]
"yi is generated from yi = hXi, ¯wi + ei, where ei is the i.i.d.","In the linear regression experiment, the true model ¯w 2",[0],[0]
"Gaussian random noise drawn from N (0, 0.012).","In the linear regression experiment, the true model ¯w 2",[0],[0]
We compare the proposed methods to bilevel exclusive sparsity with nonoverlapped groups (row-wise or column-wise),"In the linear regression experiment, the true model ¯w 2",[0],[0]
"(Yang et al., 2016), overall sparsity (Needell & Tropp, 2009), and exclusive LASSO (Kong et al., 2014).","In the linear regression experiment, the true model ¯w 2",[0],[0]
For fairness we project the final result of all the compared methods to satisfy all constraints.,"In the linear regression experiment, the true model ¯w 2",[0],[0]
All the experiments are repeated 30 times and we use the averaged result.,"In the linear regression experiment, the true model ¯w 2",[0],[0]
We use selection recall and successful recovery rate to evaluate the performance.,"In the linear regression experiment, the true model ¯w 2",[0],[0]
"Selection
recall is defined as |supp(w⇤)\supp( ¯w)|/k ¯wk0, where w⇤ is the optimization result.","In the linear regression experiment, the true model ¯w 2",[0],[0]
Successful recovery rate is the ratio of the successful feature selection i.e. supp(w⇤) = supp( ¯w) to the total number of repeated experiments.,"In the linear regression experiment, the true model ¯w 2",[0],[0]
In Figure 2 we can observe that our model with all sparsity constraints always have the best performance.,"In the linear regression experiment, the true model ¯w 2",[0],[0]
"While the performance of exclusive LASSO and our method is comparable when the number of samples are very limited, our method outperforms exclusive LASSO when the number of samples increases.
","In the linear regression experiment, the true model ¯w 2",[0],[0]
"For classification experiments, we use the same settings of sparsity with linear regression.","In the linear regression experiment, the true model ¯w 2",[0],[0]
"Here we set p = 400, and change n from 200 to 800.","In the linear regression experiment, the true model ¯w 2",[0],[0]
The true model ¯w and feature matrices are generated by the same way as the linear regression experiment.,"In the linear regression experiment, the true model ¯w 2",[0],[0]
"The class label yi 2 { 1, 1} is got by yi = signhXi, ¯wi.","In the linear regression experiment, the true model ¯w 2",[0],[0]
"Besides the selection recall, we also compare the classification error.","In the linear regression experiment, the true model ¯w 2",[0],[0]
"In Figure 3, we can see that the superiority of our method is even more significant in the classification experiment.","In the linear regression experiment, the true model ¯w 2",[0],[0]
"Although the overall sparsity has the lowest selection recall, it still has a similar classification error with the methods that consider row or column groups.","In the linear regression experiment, the true model ¯w 2",[0],[0]
This section applies the proposed method to the workertask assignment problem in crowdsourcing.,5.2. Application in Crowdsourcing,[0],[0]
"Take the im-
age labeling task as an example.",5.2. Application in Crowdsourcing,[0],[0]
"Given n workers and m images, each image can be assigned to multiple workers and each worker can label multiple images.",5.2. Application in Crowdsourcing,[0],[0]
The predicted label for each image is decided by all the labels provided by the assigned workers and the quality of each worker on the image.,5.2. Application in Crowdsourcing,[0],[0]
The goal is to maximize the expected prediction accuracy based on the assignment.,5.2. Application in Crowdsourcing,[0],[0]
"Let X 2 {0, 1}n⇥m be the assignment matrix, i.e. Xij = 1 if assign the i-th worker to j-th task, otherwise Xij = 0.",5.2. Application in Crowdsourcing,[0],[0]
Q 2,5.2. Application in Crowdsourcing,[0],[0]
"[0, 1]n⇥m is the corresponding quality matrix, which is usually estimated from the golden standard test (Ho et al., 2013).",5.2. Application in Crowdsourcing,[0],[0]
"The whole formulation is defined to maximize the average of the expected prediction accuracy over m tasks over a TVCS constraint:
max
X
1
m
mX
j=1
Eacc(Q·,j , X·,j) (8)
subject to nX
i=1
Xij  sworker, 8j;
mX
j=1
Xij  stask, 8i;
X
i,j
Xij  stotal; X 2 {0, 1}n⇥m
where Eacc(·, ·) is the expected prediction accuracy, sworker is the “worker sparsity”, i.e. the largest number of assigned workers for each task, and stask is the “task sparsity”, i.e. each worker can be assigned with at most stask tasks, and s
total is the total sparsity to control the budget, i.e., the maximal number of assignment.",5.2. Application in Crowdsourcing,[0],[0]
"In image labeling task, we assume that each image can only have two possible classes and the percentage of images in each class is one half.",5.2. Application in Crowdsourcing,[0],[0]
We use the Bayesian rule to infer the predicted labels given the workers’ answer.,5.2. Application in Crowdsourcing,[0],[0]
Here we consider the binary classification task.,5.2. Application in Crowdsourcing,[0],[0]
"Let yj 2 {1, 0} be the true label of the j-th task and ˆyj be the prediction given labels by selected workers, i.e.,
ˆ yj =",5.2. Application in Crowdsourcing,[0],[0]
"( 0, if P(yj = 1| ˆY⌦j ,j) < P(yj = 0| ˆY⌦j ,j); 1, otherwise
where ˆYij is the i-th worker’s predication on j-th task.",5.2. Application in Crowdsourcing,[0],[0]
"Set ⌦j contains the indices of the selected workers for j-th task, i.e. Xij = 1, 8i 2 ⌦j , and Xi0j = 0, 8i0 /2 ⌦j",5.2. Application in Crowdsourcing,[0],[0]
"Eacc(Q·,j , X·,j) =","Then Eacc(Q·,j , X·,j) can be defined in the following:",[0],[0]
"P(ˆyj = 1,yj = 1)+P(ˆyj = 0,yj = 0)
","Then Eacc(Q·,j , X·,j) can be defined in the following:",[0],[0]
"By this way, the expected accuracy will not be continuous, so we use smooth function to approximate the expected accuracy and adopt the stochastic gradient with the proposed
projection operator to optimize it.","Then Eacc(Q·,j , X·,j) can be defined in the following:",[0],[0]
"Due to the space limitation, the detailed derivation of the objective formulation can be found in the supplemental material.
","Then Eacc(Q·,j , X·,j) can be defined in the following:",[0],[0]
We conduct experiment for crowdsourcing task assignment on synthetic data.,"Then Eacc(Q·,j , X·,j) can be defined in the following:",[0],[0]
"Specifically, we generate the quality matrix Q from uniformly random distribution with interval [0.5, 0.9].","Then Eacc(Q·,j , X·,j) can be defined in the following:",[0],[0]
"The prior probability P(yj = 1) and P(yj = 0) are set as 0.5 for all the tasks.
","Then Eacc(Q·,j , X·,j) can be defined in the following:",[0],[0]
"To avoid evaluating the expectation term, we apply the stochastic iterative hard thresholding framework (Nguyen et al., 2014).","Then Eacc(Q·,j , X·,j) can be defined in the following:",[0],[0]
Each iteration we get ˆY |yj = 1 and ˆY |yj = 0 by sampling based on Q i.e. P( ˆYij = 1|yj = 1) =,"Then Eacc(Q·,j , X·,j) can be defined in the following:",[0],[0]
"Qij , P( ˆYij = 0|yj = 0) = Qij .","Then Eacc(Q·,j , X·,j) can be defined in the following:",[0],[0]
"Then we can get a stochastic gradient based on the sampled ˆY .
","Then Eacc(Q·,j , X·,j) can be defined in the following:",[0],[0]
"Besides the proposed formulation (8), we evaluate the random assignment algorithm and the Q-based linear programming (Ho et al., 2013).","Then Eacc(Q·,j , X·,j) can be defined in the following:",[0],[0]
"The random assignment algorithm widely used in practice is the most straightforward approach: given the total assignment budget stotal and the restrictions (sworker and stask) for workers and tasks, randomly assign tasks to the workers.","Then Eacc(Q·,j , X·,j) can be defined in the following:",[0],[0]
The Q-based linear programming uses the linear combination of Qij over i to evaluate the overall accuracy on task j for simpler formulation.,"Then Eacc(Q·,j , X·,j) can be defined in the following:",[0],[0]
"In addition, it does not consider the restriction on tasks, thus it may assign lots of workers to a difficult task2.","Then Eacc(Q·,j , X·,j) can be defined in the following:",[0],[0]
"To make a fair comparison, the task restriction is added into this method.","Then Eacc(Q·,j , X·,j) can be defined in the following:",[0],[0]
"To get the assignment result which satisfies the task and worker restriction, we use our projection operator in the other methods too.
","Then Eacc(Q·,j , X·,j) can be defined in the following:",[0],[0]
"We evaluate the experiments on different value of s
task, sworker by setting them as different ratios of the total number of tasks and workers.","Then Eacc(Q·,j , X·,j) can be defined in the following:",[0],[0]
The overall sparsity is set by the same way as in Section 5.1.,"Then Eacc(Q·,j , X·,j) can be defined in the following:",[0],[0]
"To measure the performance, we compare the sampled expected accuracy.","Then Eacc(Q·,j , X·,j) can be defined in the following:",[0],[0]
"The samples (i.e., ˆY ) are independent to the samples used in training.","Then Eacc(Q·,j , X·,j) can be defined in the following:",[0],[0]
Figure 4 shows the comparison of the expected accuracy of the three approaches.,"Then Eacc(Q·,j , X·,j) can be defined in the following:",[0],[0]
We can observe that the accuracy increases with larger ratio (i.e. more assignments).,"Then Eacc(Q·,j , X·,j) can be defined in the following:",[0],[0]
The random assignment strategy needs more assignments to get the same accuracy compared with the other two methods.,"Then Eacc(Q·,j , X·,j) can be defined in the following:",[0],[0]
"In this section, we apply the projection operator to the identification of gene regulatory networks (GRN).
",5.3. Application in Identification of Gene Regulatory Networks,[0],[0]
"2A “difficult” task means that all workers’ qualities are low on this task.
",5.3. Application in Identification of Gene Regulatory Networks,[0],[0]
Background.,5.3. Application in Identification of Gene Regulatory Networks,[0],[0]
"Gene regulatory network represents the relations between different genes, which plays important roles in biological processes and activities by controlling the expression level of RNAs.",5.3. Application in Identification of Gene Regulatory Networks,[0],[0]
There is a well-known biological competition named DREAM challenge about identifying GRN.,5.3. Application in Identification of Gene Regulatory Networks,[0],[0]
"Based on the time series gene expression data which are RNAs’ level along time sequence, contestants are required to recover the whole gene network of given size.",5.3. Application in Identification of Gene Regulatory Networks,[0],[0]
"One popular way to infer GRN is to utilize the sparse property of GRN: e.g., one gene in the network is only related to a small number of genes and we already know that there exists no relationship between some genes.",5.3. Application in Identification of Gene Regulatory Networks,[0],[0]
"Therefore, the amount of edges connecting to one vertex is far less than the dimension of the graph.",5.3. Application in Identification of Gene Regulatory Networks,[0],[0]
It is a practical case of row-wise and column-wise sparsity for matrix.,5.3. Application in Identification of Gene Regulatory Networks,[0],[0]
We could apply the projection operator to constrain the number of edges related to each vertex to identify the whole network.,5.3. Application in Identification of Gene Regulatory Networks,[0],[0]
"Recently, the dynamic Bayesian network (DBN) (Zou & Conzen, 2005) is supposed to be an effective model to recover GRNs.",5.3. Application in Identification of Gene Regulatory Networks,[0],[0]
"The RNAs’ level of all genes in GRN at time t is stored in gene expression vector xt 2 RN , where each entry corresponds to one gene respectively and N is the number of genes in GRN.",5.3. Application in Identification of Gene Regulatory Networks,[0],[0]
"Hence, We define the total amount of time points in the experiment as T .",5.3. Application in Identification of Gene Regulatory Networks,[0],[0]
"Gene activity model is usually assumed to be
xt+1 = Pxt + et, t = 1 . . .",5.3. Application in Identification of Gene Regulatory Networks,[0],[0]
"T 1,
where P 2 RN⇥N is the covariance matrix of GRN and et 2 RN is Gaussian white noise.",5.3. Application in Identification of Gene Regulatory Networks,[0],[0]
"Then the difference of RNA levels between time points t + 1 and t, i.e. yt+1,t 2 RN is defined as follows:
yt+1,t",5.3. Application in Identification of Gene Regulatory Networks,[0],[0]
:,5.3. Application in Identification of Gene Regulatory Networks,[0],[0]
= xt+1 xt,5.3. Application in Identification of Gene Regulatory Networks,[0],[0]
= ¯Wxt,5.3. Application in Identification of Gene Regulatory Networks,[0],[0]
"+ et, t = 1 . . .",5.3. Application in Identification of Gene Regulatory Networks,[0],[0]
"T 1,
where ¯W = P I is the true sparse N -by-N matrix.",5.3. Application in Identification of Gene Regulatory Networks,[0],[0]
"Therefore, the GRN is only considered between different genes and we eliminate edges whose start and end vertex are the same.",5.3. Application in Identification of Gene Regulatory Networks,[0],[0]
We define that Y :=,5.3. Application in Identification of Gene Regulatory Networks,[0],[0]
"[y
2,1, . . .",5.3. Application in Identification of Gene Regulatory Networks,[0],[0]
",yT,T 1] 2 RN⇥(T 1) and X :=",5.3. Application in Identification of Gene Regulatory Networks,[0],[0]
"[x
1 , . . .",5.3. Application in Identification of Gene Regulatory Networks,[0],[0]
",xT 1] 2 RN⇥(T 1).",5.3. Application in Identification of Gene Regulatory Networks,[0],[0]
"The objective function is
f(W ) = 1
2
kY ¯WXk2F = 1
2
T 1X
t=1
k(xt+1 xt) ¯Wxtk2.
",5.3. Application in Identification of Gene Regulatory Networks,[0],[0]
Time-course Gene Expression Data.,5.3. Application in Identification of Gene Regulatory Networks,[0],[0]
"To evaluate our method, we employ GeneNetWeaver (Marbach et al., 2009; Schaffter et al., 2011), the official DREAM Challenge tool for time-series expression data generation.",5.3. Application in Identification of Gene Regulatory Networks,[0],[0]
"With typical gene network structure and ordinary differential equation (ODE) models, GeneNetWeaver will produce the timecourse gene expression data at pre-specified time points.",5.3. Application in Identification of Gene Regulatory Networks,[0],[0]
"In the simulation studies, we control the size of gene network to be N = 30 vertexes and the gene expression data are generated under 10% Gaussian white noise.
",5.3. Application in Identification of Gene Regulatory Networks,[0],[0]
The network is shown in Figure 5.,5.3. Application in Identification of Gene Regulatory Networks,[0],[0]
"In this Figure, it is clear that one gene only has a few connections to other genes.",5.3. Application in Identification of Gene Regulatory Networks,[0],[0]
"Therefore, the GRN is sparse and we are able to restrict the in-degree and out-degree of every vertex by representing the network as a matrix and controlling the sparsity within each row and column.
",5.3. Application in Identification of Gene Regulatory Networks,[0],[0]
Performance evaluation.,5.3. Application in Identification of Gene Regulatory Networks,[0],[0]
"Six commonly-used criteria are considered to measure the performance, i.e., sensitivity (SN), specificity (SP), accuracy (ACC), F-measure, Matthews correlation coefficient (MCC), and the Area Under ROC Curve (AUC):
SN = TP
TP + FN , SP = TN TN + FP ,
ACC = TP + TN
TP + FP + TN + FN ,
F-measure = 2⇥ SN ⇥",5.3. Application in Identification of Gene Regulatory Networks,[0],[0]
"SP
SN + SP ,
MCC = TP ⇥",5.3. Application in Identification of Gene Regulatory Networks,[0],[0]
"TN FP ⇥ FNp
(TP + FP)(TP + FN)(TN + FP)(TN + FN) ,
where TP and TN denote the true positive and true negative, and FP and FN denote the false positive and false negative, respectively.",5.3. Application in Identification of Gene Regulatory Networks,[0],[0]
"With these criteria, we compare the performance of our method with six representative algorithms, including PCC, ARACNE (Margolin et al., 2006), CLR (Faith et al., 2007), MINET (Meyer et al., 2008), GENIE3 (Huynh-Thu et al., 2010), TIGRESS (Haury et al., 2012).",5.3. Application in Identification of Gene Regulatory Networks,[0],[0]
The results are summarized in Table 1.,5.3. Application in Identification of Gene Regulatory Networks,[0],[0]
Our method outperforms other six state-of-art methods: the AUC of our method achieve 0.7 higher which is far more than other methods; 5 out of 6 different measure show that our method has significant advantage compared to other algorithms.,5.3. Application in Identification of Gene Regulatory Networks,[0],[0]
"This paper considers the TVCS constrained optimization, motivated by the intrinsic restrictions for many important applications, for example, in bioinformatics, recommendation system, and crowdsourcing.",6. Conclusion,[0],[0]
"To solve the cardinality constrained problem, the key step is the projection onto the cardinality constraints.",6. Conclusion,[0],[0]
"Although the projection onto the overlapped cardinality constraints is NP-hard in general, we prove that if the TVCS condition is satisfied the projection can be reduced to a linear programming.",6. Conclusion,[0],[0]
"We further prove that there is an iterative algorithm which finds an integer solution to the linear programming within time complexity O((p+ |G|) log↵ 1R ), where R is the distance from the initial point to the optimization solution and ↵ < 1 is the convergence rate.",6. Conclusion,[0],[0]
We finally use synthetic experiments and two interesting applications in bioinformatics and crowdsourcing to validate the proposed TVCS model.,6. Conclusion,[0],[0]
This project is supported in part by the NSF grant CNS1548078 and the NEC fellowship.,Acknowledgements,[0],[0]
"and Hegde, Chinmay.","Baraniuk, Richard G, Cevher, Volkan, Duarte, Marco F,",[0],[0]
Model-based compressive sensing.,"Baraniuk, Richard G, Cevher, Volkan, Duarte, Marco F,",[0],[0]
"Information Theory, IEEE Transactions on, 56(4): 1982–2001, 2010.
","Baraniuk, Richard G, Cevher, Volkan, Duarte, Marco F,",[0],[0]
"Candes, Emmanuel J, Romberg, Justin K, and Tao, Terence.","Baraniuk, Richard G, Cevher, Volkan, Duarte, Marco F,",[0],[0]
Stable signal recovery from incomplete and inaccurate measurements.,"Baraniuk, Richard G, Cevher, Volkan, Duarte, Marco F,",[0],[0]
"Communications on pure and applied mathematics, 59(8):1207–1223, 2006.
","Baraniuk, Richard G, Cevher, Volkan, Duarte, Marco F,",[0],[0]
"Cevher, Volkan, Indyk, Piotr, Hegde, Chinmay, and Baraniuk, Richard G. Recovery of clustered sparse signals from compressive measurements.","Baraniuk, Richard G, Cevher, Volkan, Duarte, Marco F,",[0],[0]
"Technical report, DTIC Document, 2009.
","Baraniuk, Richard G, Cevher, Volkan, Duarte, Marco F,",[0],[0]
"El Halabi, Marwa and Cevher, Volkan.","Baraniuk, Richard G, Cevher, Volkan, Duarte, Marco F,",[0],[0]
A totally unimodular view of structured sparsity.,"Baraniuk, Richard G, Cevher, Volkan, Duarte, Marco F,",[0],[0]
"In Proceedings of the Eighteenth International Conference on Artificial Intelligence and Statistics, pp. 223–231, 2015.","Baraniuk, Richard G, Cevher, Volkan, Duarte, Marco F,",[0],[0]
"Mogno, Ilaria, Wierzbowski, Jamey, Cottarel, Guillaume, Kasif, Simon, Collins, James J, and Gardner, Timothy S. Large-scale mapping and validation of escherichia coli transcriptional regulation from a compendium of expression profiles.","Faith, Jeremiah J, Hayete, Boris, Thaden, Joshua T,",[0],[0]
"PLoS biol, 5(1):e8, 2007.","Faith, Jeremiah J, Hayete, Boris, Thaden, Joshua T,",[0],[0]
"Paola, and Vert, Jean-Philippe.","Haury, Anne-Claire, Mordelet, Fantine, Vera-Licona,",[0],[0]
Tigress: trustful inference of gene regulation using stability selection.,"Haury, Anne-Claire, Mordelet, Fantine, Vera-Licona,",[0],[0]
"BMC systems biology, 6(1):145, 2012.","Haury, Anne-Claire, Mordelet, Fantine, Vera-Licona,",[0],[0]
Compressive sensing recovery of spike trains using a structured sparsity model.,"Hegde, Chinmay, Duarte, Marco F, and Cevher, Volkan.",[0],[0]
"In SPARS’09-Signal Processing with Adaptive Sparse Structured Representations, 2009.
Hegde, Chinmay, Indyk, Piotr, and Schmidt, Ludwig.","Hegde, Chinmay, Duarte, Marco F, and Cevher, Volkan.",[0],[0]
Approximation algorithms for model-based compressive sensing.,"Hegde, Chinmay, Duarte, Marco F, and Cevher, Volkan.",[0],[0]
"Information Theory, IEEE Transactions on, 61 (9):5129–5147, 2015a.","Hegde, Chinmay, Duarte, Marco F, and Cevher, Volkan.",[0],[0]
nearly-linear time framework for graph-structured sparsity.,"Hegde, Chinmay, Indyk, Piotr, and Schmidt, Ludwig. A",[0],[0]
"In Proceedings of the 32nd International Conference on Machine Learning (ICML-15), pp. 928–937, 2015b.
Ho, Chien-Ju, Jabbari, Shahin, and Vaughan, Jennifer Wortman.","Hegde, Chinmay, Indyk, Piotr, and Schmidt, Ludwig. A",[0],[0]
Adaptive task assignment for crowdsourced classification.,"Hegde, Chinmay, Indyk, Piotr, and Schmidt, Ludwig. A",[0],[0]
"In Proceedings of The 30th International Conference on Machine Learning, pp.","Hegde, Chinmay, Indyk, Piotr, and Schmidt, Ludwig. A",[0],[0]
"534–542, 2013.
","Hegde, Chinmay, Indyk, Piotr, and Schmidt, Ludwig. A",[0],[0]
"Hoffman, Alan J. On approximate solutions of systems of linear inequalities.","Hegde, Chinmay, Indyk, Piotr, and Schmidt, Ludwig. A",[0],[0]
In Selected Papers Of Alan J Hoffman:,"Hegde, Chinmay, Indyk, Piotr, and Schmidt, Ludwig. A",[0],[0]
"With Commentary, pp.","Hegde, Chinmay, Indyk, Piotr, and Schmidt, Ludwig. A",[0],[0]
"174–176. 2003.
Huynh-Thu, Vn Anh, Irrthum, Alexandre, Wehenkel, Louis, and Geurts, Pierre.","Hegde, Chinmay, Indyk, Piotr, and Schmidt, Ludwig. A",[0],[0]
Inferring regulatory networks from expression data using tree-based methods.,"Hegde, Chinmay, Indyk, Piotr, and Schmidt, Ludwig. A",[0],[0]
"PloS one, 5(9):e12776, 2010.","Hegde, Chinmay, Indyk, Piotr, and Schmidt, Ludwig. A",[0],[0]
"and Bach, Francis.","Jenatton, Rodolphe, Mairal, Julien, Obozinski, Guillaume,",[0],[0]
Proximal methods for hierarchical sparse coding.,"Jenatton, Rodolphe, Mairal, Julien, Obozinski, Guillaume,",[0],[0]
"Journal of Machine Learning Research, 12(Jul):2297–2334, 2011.","Jenatton, Rodolphe, Mairal, Julien, Obozinski, Guillaume,",[0],[0]
"and Ding, Chris.","Kong, Deguang, Fujimaki, Ryohei, Liu, Ji, Nie, Feiping,",[0],[0]
"Exclusive feature learning on arbitrary structures via l
1,2-norm.","Kong, Deguang, Fujimaki, Ryohei, Liu, Ji, Nie, Feiping,",[0],[0]
"In Advances in Neural Information Processing Systems, pp. 1655–1663, 2014.","Kong, Deguang, Fujimaki, Ryohei, Liu, Ji, Nie, Feiping,",[0],[0]
coordinate descent: Parallelism and convergence properties.,"Liu, Ji and Wright, Stephen J. Asynchronous stochastic",[0],[0]
"SIAM Journal on Optimization, 25(1):351–376, 2015.","Liu, Ji and Wright, Stephen J. Asynchronous stochastic",[0],[0]
"and Floreano, Dario.","Marbach, Daniel, Schaffter, Thomas, Mattiussi, Claudio,",[0],[0]
Generating realistic in silico gene networks for performance assessment of reverse engineering methods.,"Marbach, Daniel, Schaffter, Thomas, Mattiussi, Claudio,",[0],[0]
"Journal of computational biology, 16 (2):229–239, 2009.","Marbach, Daniel, Schaffter, Thomas, Mattiussi, Claudio,",[0],[0]
"and Califano, Andrea.","Margolin, Adam A, Nemenman, Ilya, Basso, Katia, Wiggins, Chris, Stolovitzky, Gustavo, Favera, Riccardo D,",[0],[0]
Aracne: an algorithm for the reconstruction of gene regulatory networks in a mammalian cellular context.,"Margolin, Adam A, Nemenman, Ilya, Basso, Katia, Wiggins, Chris, Stolovitzky, Gustavo, Favera, Riccardo D,",[0],[0]
"BMC bioinformatics, 7(Suppl 1):S7, 2006.
","Margolin, Adam A, Nemenman, Ilya, Basso, Katia, Wiggins, Chris, Stolovitzky, Gustavo, Favera, Riccardo D,",[0],[0]
"Meyer, Patrick E, Lafitte, Frederic, and Bontempi, Gianluca.","Margolin, Adam A, Nemenman, Ilya, Basso, Katia, Wiggins, Chris, Stolovitzky, Gustavo, Favera, Riccardo D,",[0],[0]
minet: Ar/bioconductor package for inferring large transcriptional networks using mutual information.,"Margolin, Adam A, Nemenman, Ilya, Basso, Katia, Wiggins, Chris, Stolovitzky, Gustavo, Favera, Riccardo D,",[0],[0]
"BMC bioinformatics, 9(1):461, 2008.
","Margolin, Adam A, Nemenman, Ilya, Basso, Katia, Wiggins, Chris, Stolovitzky, Gustavo, Favera, Riccardo D,",[0],[0]
"Needell, Deanna and Tropp, Joel A. Cosamp:","Margolin, Adam A, Nemenman, Ilya, Basso, Katia, Wiggins, Chris, Stolovitzky, Gustavo, Favera, Riccardo D,",[0],[0]
Iterative signal recovery from incomplete and inaccurate samples.,"Margolin, Adam A, Nemenman, Ilya, Basso, Katia, Wiggins, Chris, Stolovitzky, Gustavo, Favera, Riccardo D,",[0],[0]
"Applied and Computational Harmonic Analysis, 26(3): 301–321, 2009.","Margolin, Adam A, Nemenman, Ilya, Basso, Katia, Wiggins, Chris, Stolovitzky, Gustavo, Favera, Riccardo D,",[0],[0]
"iterative greedy algorithm for sparsity constrained optimization. 2012.
","Nguyen, Nam, Chin, Sang, and Tran, Trac D. A unified",[0],[0]
"Nguyen, Nam, Needell, Deanna, and Woolf, Tina.","Nguyen, Nam, Chin, Sang, and Tran, Trac D. A unified",[0],[0]
Linear convergence of stochastic iterative greedy algorithms with sparse constraints.,"Nguyen, Nam, Chin, Sang, and Tran, Trac D. A unified",[0],[0]
"arXiv preprint arXiv:1407.0088, 2014.
","Nguyen, Nam, Chin, Sang, and Tran, Trac D. A unified",[0],[0]
"Olshausen, Bruno A and Field, David J. Sparse coding with an overcomplete basis set: A strategy employed by v1?","Nguyen, Nam, Chin, Sang, and Tran, Trac D. A unified",[0],[0]
"Vision research, 37(23):3311–3325, 1997.
","Nguyen, Nam, Chin, Sang, and Tran, Trac D. A unified",[0],[0]
"Papadimitriou, Christos H and Steiglitz, Kenneth.","Nguyen, Nam, Chin, Sang, and Tran, Trac D. A unified",[0],[0]
Combinatorial optimization: algorithms and complexity.,"Nguyen, Nam, Chin, Sang, and Tran, Trac D. A unified",[0],[0]
"Courier Corporation, 1982.","Nguyen, Nam, Chin, Sang, and Tran, Trac D. A unified",[0],[0]
Genenetweaver: in silico benchmark generation and performance profiling of network inference methods.,"Schaffter, Thomas, Marbach, Daniel, and Floreano, Dario.",[0],[0]
"Bioinformatics, 27(16):2263–2270, 2011.","Schaffter, Thomas, Marbach, Daniel, and Floreano, Dario.",[0],[0]
"Huang, Shuai.","Yang, Haichuan, Huang, Yijun, Tran, Lam, Liu, Ji, and",[0],[0]
On benefits of selection diversity via bilevel exclusive sparsity.,"Yang, Haichuan, Huang, Yijun, Tran, Lam, Liu, Ji, and",[0],[0]
"In Computer Vision and Pattern Recognition (CVPR), 2016 IEEE Conference on.","Yang, Haichuan, Huang, Yijun, Tran, Lam, Liu, Ji, and",[0],[0]
"IEEE, 2016.
","Yang, Haichuan, Huang, Yijun, Tran, Lam, Liu, Ji, and",[0],[0]
"Yuan, Ming and Lin, Yi.","Yang, Haichuan, Huang, Yijun, Tran, Lam, Liu, Ji, and",[0],[0]
Model selection and estimation in regression with grouped variables.,"Yang, Haichuan, Huang, Yijun, Tran, Lam, Liu, Ji, and",[0],[0]
"Journal of the Royal Statistical Society: Series B (Statistical Methodology), 68(1):49–67, 2006.
","Yang, Haichuan, Huang, Yijun, Tran, Lam, Liu, Ji, and",[0],[0]
"Yuan, Xiaotong, Li, Ping, and Zhang, Tong.","Yang, Haichuan, Huang, Yijun, Tran, Lam, Liu, Ji, and",[0],[0]
Gradient hard thresholding pursuit for sparsity-constrained optimization.,"Yang, Haichuan, Huang, Yijun, Tran, Lam, Liu, Ji, and",[0],[0]
"In Proceedings of The 31st International Conference on Machine Learning, pp. 127–135, 2014.
Yuan, Xiaotong, Li, Ping, and Zhang, Tong.","Yang, Haichuan, Huang, Yijun, Tran, Lam, Liu, Ji, and",[0],[0]
Exact recovery of hard thresholding pursuit.,"Yang, Haichuan, Huang, Yijun, Tran, Lam, Liu, Ji, and",[0],[0]
"In Advances in Neural Information Processing Systems, pp. 3558–3566, 2016.
Zhang, Tong.","Yang, Haichuan, Huang, Yijun, Tran, Lam, Liu, Ji, and",[0],[0]
On the consistency of feature selection using greedy least squares regression.,"Yang, Haichuan, Huang, Yijun, Tran, Lam, Liu, Ji, and",[0],[0]
"Journal of Machine Learning Research, 10(Mar):555–568, 2009.","Yang, Haichuan, Huang, Yijun, Tran, Lam, Liu, Ji, and",[0],[0]
lasso for multi-task feature selection.,"Zhou, Yang, Jin, Rong, and Hoi, Steven CH. Exclusive",[0],[0]
"In AISTATS, volume 9, pp. 988–995, 2010.","Zhou, Yang, Jin, Rong, and Hoi, Steven CH. Exclusive",[0],[0]
bayesian network (dbn) approach for identifying gene regulatory networks from time course microarray data.,"Zou, Min and Conzen, Suzanne D. A new dynamic",[0],[0]
"Bioinformatics, 21(1):71–79, 2005.","Zou, Min and Conzen, Suzanne D. A new dynamic",[0],[0]
"The cardinality constraint is an intrinsic way to restrict the solution structure in many domains, for example, sparse learning, feature selection, and compressed sensing.",abstractText,[0],[0]
"To solve a cardinality constrained problem, the key challenge is to solve the projection onto the cardinality constraint set, which is NP-hard in general when there exist multiple overlapped cardinality constraints.",abstractText,[0],[0]
"In this paper, we consider the scenario where the overlapped cardinality constraints satisfy a Three-view Cardinality Structure (TVCS), which reflects the natural restriction in many applications, such as identification of gene regulatory networks and task-worker assignment problem.",abstractText,[0],[0]
"We cast the projection into a linear programming, and show that for TVCS, the vertex solution of this linear programming is the solution for the original projection problem.",abstractText,[0],[0]
We further prove that such solution can be found with the complexity proportional to the number of variables and constraints.,abstractText,[0],[0]
We finally use synthetic experiments and two interesting applications in bioinformatics and crowdsourcing to validate the proposed TVCS model and method.,abstractText,[0],[0]
On The Projection Operator to A Three-view Cardinality Constrained Set,title,[0],[0]
"Consider approximation of the Lebesgue integral
Π(f) = ∫",1. INTRODUCTION,[0],[0]
"X fdΠ (1)
where Π is a Borel measure defined over X ⊆ Rd and f is Borel measurable.",1. INTRODUCTION,[0],[0]
"Define P(f) to be the set of Borel measures Π′ such that f ∈ L2(Π′), meaning that ‖f‖2L2(Π′) = ∫ X f
2dΠ′ < ∞, and assume Π ∈ P(f).",1. INTRODUCTION,[0],[0]
"In situations where Π(f) does not admit a closed-form, Monte
1University of Warwick, Department of Statistics.",1. INTRODUCTION,[0],[0]
"2Imperial College London, Department of Mathematics.",1. INTRODUCTION,[0],[0]
"3Newcastle University, School of Mathematics and Statistics 4The Alan Turing Institute for Data Science 5University of Technology Sydney, School of Mathematical and Physical Sciences.",1. INTRODUCTION,[0],[0]
"Correspondence to: François-Xavier Briol <f-x.briol@warwick.ac.uk>.
",1. INTRODUCTION,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. INTRODUCTION,[0],[0]
"Copyright 2017 by the author(s).
",1. INTRODUCTION,[0],[0]
Carlo (MC) methods can be used to estimate the numerical value of Eqn. 1.,1. INTRODUCTION,[0],[0]
"A classical research problem in computational statistics is to reduce the MC estimation error in this context, where the integral can, for example, represent an expectation or marginalisation over a random variable of interest.
",1. INTRODUCTION,[0],[0]
"The default MC estimator comprises of
Π̂MC(f)",1. INTRODUCTION,[0],[0]
"= 1
n n∑ j=1 f(xj),
where xj are sampled identically and independently (i.i.d.) from Π.",1. INTRODUCTION,[0],[0]
"Then we have a root mean square error (RMSE) bound √
E[Π̂MC(f)−Π(f)]2 ≤ CMC(f ; Π)√
n ,
where CMC(f ; Π) = Std(f ; Π) and the expectation is with respect to the joint distribution of the {xj}nj=1.",1. INTRODUCTION,[0],[0]
"For settings where the Lebesgue density of Π is only known up to normalising constant, Markov chain Monte Carlo (MCMC) methods can be used; the rate-constant CMC(f ; Π) is then related to the asymptotic variance of f under the Markov chain sample path.
",1. INTRODUCTION,[0],[0]
Considerations of computational cost place emphasis on methods to reduce the rate constant CMC(f ; Π).,1. INTRODUCTION,[0],[0]
"For the MC estimator, this rate constant can be made smaller via importance sampling (IS): f 7→ f · dΠ/dΠ′ where an optimal choice Π′ ∈",1. INTRODUCTION,[0],[0]
"P(f · dΠ/dΠ′), that minimises Std(f · dΠ/dΠ′; Π′), is available in explicit closed-form (see Robert and Casella, 2013, Thm. 3.3.4).",1. INTRODUCTION,[0],[0]
"However, the RMSE remains asymptotically gated at O(n−1/2).
",1. INTRODUCTION,[0],[0]
"The default Kernel Quadrature (KQ) estimate comprises of
Π̂(f) = n∑ j=1 wjf(xj), (2)
where the xj ∼ Π′ are independent (or arise from a Markov chain) and supp(Π) ⊆ supp(Π′).",1. INTRODUCTION,[0],[0]
"In contrast to MC, the weights {wj}nj=1 in KQ are in general non-uniform, real-valued and depend on {xj}nj=1.",1. INTRODUCTION,[0],[0]
"The KQ nomenclature derives from the (symmetric, positivedefinite) kernel k :",1. INTRODUCTION,[0],[0]
"X × X → R that is used to construct an interpolant f̂(x) = ∑n j=1 βjk(x,xj) such that
f̂(xj) = f(xj) for j = 1, . . .",1. INTRODUCTION,[0],[0]
",",1. INTRODUCTION,[0],[0]
n. The weights wj in Eqn. 2 are implicitly defined via the equation Π̂(f) = ∫ X f̂dΠ.,1. INTRODUCTION,[0],[0]
"The KQ estimator is identical to the posterior mean in Bayesian Monte Carlo (O’Hagan, 1991; Rasmussen and Ghahramani, 2002), and its relationship with classical numerical quadrature rules has been studied (Diaconis, 1988; Särkkä et al., 2015).
",1. INTRODUCTION,[0],[0]
"Under regularity conditions, Briol et al. (2015b) established the following RMSE bound for KQ:√
E[Π̂(f)−Π(f)]2 ≤ C(f ; Π ′)
ns/d− , (s > d/2)
where both the integrand f and each argument of the kernel k admit continuous mixed weak derivatives of order s and > 0 can be arbitrarily small.",1. INTRODUCTION,[0],[0]
An information-theoretic lower bound on the RMSE is O(n−s/d−1/2),1. INTRODUCTION,[0],[0]
"(Bakhvalov, 1959).",1. INTRODUCTION,[0],[0]
"The faster convergence of the RMSE, relative to MC, can lead to improved precision in applications.",1. INTRODUCTION,[0],[0]
"Akin to IS, the samples {xj}nj=1 need not be draws from Π in order for KQ to provide consistent estimation (since Π is encoded in the weights wj).",1. INTRODUCTION,[0],[0]
"Importantly, KQ can be viewed as post-processing of MC samples; the kernel k can be reverse-engineered (e.g. via cross-validation) and does not need to be specified up-front.
",1. INTRODUCTION,[0],[0]
"One notable disadvantage of KQ methods is that little is known about how the rate constant C(f ; Π′) depends on the choice of sampling distribution Π′. In contrast to IS, no general closed-form expression has been established for an optimal distribution Π′ for KQ (the technical meaning of ‘optimal’ is defined below).",1. INTRODUCTION,[0],[0]
"Moreover, limited practical guidance is available on the selection of the sampling distribution (an exception is Bach, 2015, as explained in Sec. 2.4) and in applications it is usual to take Π′ =",1. INTRODUCTION,[0],[0]
"Π. This choice is convenient but leads to estimators that are not efficient, as we demonstrate in dramatic empirical examples in Sec. 2.3.
",1. INTRODUCTION,[0],[0]
The main contributions of this paper are twofold.,1. INTRODUCTION,[0],[0]
"First, we formalise the problem of optimal sampling for KQ as an important and open challenge in computational statistics.",1. INTRODUCTION,[0],[0]
"To be precise, our target is an optimal sampling distribution for KQ, defined as
Π∗ ∈ arg",1. INTRODUCTION,[0],[0]
"min Π′ sup f∈F
√ E[Π̂(f)−Π(f)]2.",1. INTRODUCTION,[0],[0]
"(3)
for some functional class F to be specified.",1. INTRODUCTION,[0],[0]
"In general a (possibly non-unique) optimal Π∗ will depend on F and, unlike for IS, also on the kernel k and the number of samples n.
Second, we propose a novel and automatic method for selection of Π′ that is rooted in approximation of the unavailable Π∗.",1. INTRODUCTION,[0],[0]
"In brief, our method considers candidate sampling
distributions of the form Π′ = Π1−t0 Π t for t ∈",1. INTRODUCTION,[0],[0]
"[0, 1] and Π0",1. INTRODUCTION,[0],[0]
a reference distribution on X .,1. INTRODUCTION,[0],[0]
The exponent t is chosen such that Π′ minimises an empirical upper bound on the RMSE.,1. INTRODUCTION,[0],[0]
The overall approach is facilitated with an efficient sequential MC (SMC) sampler and called SMC-KQ.,1. INTRODUCTION,[0],[0]
"In particular, the approach (i) provides practical guidance for selection of Π′ for KQ, (ii) offers robustness to kernel misspecification, and (iii) extends recent work on computing posterior expectations with kernels obtained using Stein’s method (Oates et al., 2017).
",1. INTRODUCTION,[0],[0]
The paper proceeds as follows: Empirical results in Sec. 2 reveal that the RMSE for KQ is highly sensitive to the choice of Π′. The proposed approach to selection of Π′ is contained in Sec. 3.,1. INTRODUCTION,[0],[0]
"Numerical experiments, presented in Sec. 4, demonstrate that dramatic reductions in integration error (up to 4 orders of magnitude) can be achieved with SMC-KQ.",1. INTRODUCTION,[0],[0]
"Lastly, a discussion is provided in Sec. 5.",1. INTRODUCTION,[0],[0]
"This section presents an overview of KQ (Sec. 2.1 and 2.2), empirical (Secs. 2.3) and theoretical (Sec. 2.4) results on the choice of sampling distribution, and discusses kernel learning for KQ (Sec. 2.5).",2. BACKGROUND,[0],[0]
"We now proceed to describe KQ: Recall the approximation f̂ to f ; an explicit form for the coefficients βj is given as β = K−1f , where Ki,j = k(xi,xj) and fj = f(xj).",2.1. Overview of Kernel Quadrature,[0],[0]
"It is assumed that K−1 exists almost surely; for non-degenerate kernels, this corresponds to Π having no atoms.",2.1. Overview of Kernel Quadrature,[0],[0]
"From the above definition of KQ,
Π̂(f) = n∑ j=1 βj ∫ X k(x,xj)Π(dx).
",2.1. Overview of Kernel Quadrature,[0],[0]
"Defining zj = ∫ X k(·,xj)dΠ leads to the estimate in Eqn. 2 with weights w = K−1z.",2.1. Overview of Kernel Quadrature,[0],[0]
"Pairs (Π, k) for which the zj have closed form are reported in Table 1 of Briol et al. (2015b).",2.1. Overview of Kernel Quadrature,[0],[0]
"Computation of these weights incurs a computational cost of at most O(n3) and can be justified when either (i) evaluation of f forms the computational bottleneck, or (ii) the gain in estimator precision (as a function in n) dominates this cost (i.e. whenever s/d > 3 + 1/2).
",2.1. Overview of Kernel Quadrature,[0],[0]
Notable contributions on KQ include Diaconis (1988); O’Hagan (1991); Rasmussen and Ghahramani (2002) who introduced the method and Huszar and Duvenaud (2012); Osborne et al. (2012a;b); Gunter et al. (2014); Bach (2015); Briol et al. (2015a;b); Särkkä et al. (2015); Kanagawa et al. (2016); Liu and Lee (2017) who provided consequent methodological extensions.,2.1. Overview of Kernel Quadrature,[0],[0]
"KQ has been applied to a wide range of problems including probabilistic ODE
solvers (Kersting and Hennig, 2016), reinforcement learning (Paul et al., 2016), filtering (Prüher and Šimandl, 2015) and design of experiments (Ma et al., 2014).
",2.1. Overview of Kernel Quadrature,[0],[0]
Several characterisations of the KQ estimator are known and detailed below.,2.1. Overview of Kernel Quadrature,[0],[0]
"LetH denote the Hilbert space characterised by the reproducing kernel k, and denote its norm as ‖ · ‖H (Berlinet and Thomas-Agnan, 2011).",2.1. Overview of Kernel Quadrature,[0],[0]
"Then we have the following: (a) The function f̂ is the minimiser of ‖g‖H over g ∈ H subject to g(xj) = f(xj) for all j = 1, . . .",2.1. Overview of Kernel Quadrature,[0],[0]
",",2.1. Overview of Kernel Quadrature,[0],[0]
n. (b),2.1. Overview of Kernel Quadrature,[0],[0]
"The function f̂ is the posterior mean for f under the Gaussian process prior f ∼ GP(0, k) conditioned on data f and Π̂(f) is the mean of the implied posterior marginal over Π[f ].",2.1. Overview of Kernel Quadrature,[0],[0]
"(c) The weightsw are characterised as the minimiser over γ ∈ Rn of
en(γ; {xj}nj=1) = sup ‖f‖H=1",2.1. Overview of Kernel Quadrature,[0],[0]
∣∣∣∣∣,2.1. Overview of Kernel Quadrature,[0],[0]
"n∑ j=1 γjf(xj)−Π(f) ∣∣∣∣∣, the maximal error in the unit ball of H. These characterisations connect KQ to (a) non-parametric regression, (b) probabilistic integration and (c) quasi-Monte Carlo (QMC) methods (Dick and Pillichshammer, 2010).",2.1. Overview of Kernel Quadrature,[0],[0]
"The scattered data approximation literature (Sommariva and Vianello, 2006) and the numerical analysis literature (where KQ is known as the ‘empirical interpolation method’; Eftang and Stamm, 2012; Kristoffersen, 2013) can also be connected to KQ.",2.1. Overview of Kernel Quadrature,[0],[0]
"However, our search of all of these literatures did not yield guidance on the optimal selection of the sampling distribution Π′ (with the exception of Bach (2015) reported in Sec. 2.4).",2.1. Overview of Kernel Quadrature,[0],[0]
"In Osborne et al. (2012a); Huszar and Duvenaud (2012); Gunter et al. (2014); Briol et al. (2015a), the selection ofxn was approached as a greedy optimisation problem, wherein the maximal integration error en(w; {xj}nj=1) was minimised, given the location of the previous {xj}n−1j=1 .",2.2. Over-Reliance on the Kernel,[0],[0]
This approach has demonstrated considerable success in applications.,2.2. Over-Reliance on the Kernel,[0],[0]
"However, the error criterion en is strongly dependant on the choice of kernel k and the sequential optimisation approach is vulnerable to kernel misspecification.",2.2. Over-Reliance on the Kernel,[0],[0]
"In particular, if the intrinsic length scale of k is “too small” then the {xj}nj=1 all cluster around the mode of Π, leading to poor integral estimation (see Fig. 5 in the Appendix).",2.2. Over-Reliance on the Kernel,[0],[0]
"Related work on sub-sample selection, such as leverage scores (Bach, 2013), can also be non-robust to mis-specified kernels.",2.2. Over-Reliance on the Kernel,[0],[0]
"The partial solution of online kernel learning requires a sufficient number n of data and is not always practicable in small-n regimes that motivate KQ.
",2.2. Over-Reliance on the Kernel,[0],[0]
This paper considers sampling methods as a robust alternative to optimisation methods.,2.2. Over-Reliance on the Kernel,[0],[0]
"Although our method also makes use of k to select Π′, it reverts to Π′ = Π in the
limit as the length scale of k is made small.",2.2. Over-Reliance on the Kernel,[0],[0]
"In this sense, sampling offers more robustness to kernel mis-specification than optimisation methods, at the expense of a possible (non-asymptotic) decrease in precision in the case of a well-specified kernel.",2.2. Over-Reliance on the Kernel,[0],[0]
This line of research is thus complementary to existing work.,2.2. Over-Reliance on the Kernel,[0],[0]
"However, we emphasise that robustness is an important consideration for general applications of KQ in which kernel specification may be a nontrivial task.",2.2. Over-Reliance on the Kernel,[0],[0]
"To date, we are not aware of a clear demonstration of the acute dependence of the performance of the KQ estimator on the choice of distribution Π′. It is therefore important to illustrate this phenomenon in order to build intuition.
",2.3. Sensitivity to the Sampling Distribution,[0],[0]
"Consider the toy problem with state space X = R, target distribution Π = N(0, 1), a single test function f(x) = 1 + sin(2πx) and kernel k(x, x′) = exp(−(x− x′)2).",2.3. Sensitivity to the Sampling Distribution,[0],[0]
"For this problem, consider a range of sampling distributions of the form Π′ = N(0, σ2) for σ ∈ (0,∞).",2.3. Sensitivity to the Sampling Distribution,[0],[0]
"Fig. 1 plots
R̂n,σ = √√√√ 1 M M∑ m=1 (Π̂n,m,σ(f)−Π(f))2,
an empirical estimate for the RMSE where Π̂n,m,σ(f) is the mth of M independent KQ estimates for Π(f) based on n samples drawn from the distribution Π′ with standard deviation σ",2.3. Sensitivity to the Sampling Distribution,[0],[0]
(M = 1000).,2.3. Sensitivity to the Sampling Distribution,[0],[0]
In this case Π(f) = 1 is available in closed-form.,2.3. Sensitivity to the Sampling Distribution,[0],[0]
"It is seen that the ‘obvious’ choice of σ = 1, i.e. Π′ = Π, is sub-optimal.",2.3. Sensitivity to the Sampling Distribution,[0],[0]
"The intuition here is that ‘extreme’ samples xi from the tails of Π are rather informative for building the interpolant f̂ underlying KQ; we should therefore over-sample these values via a heaviertailed Π′. The same intuition is used for column sampling and to construct leverage scores (Mahoney, 2011; Drineas et al., 2012).",2.3. Sensitivity to the Sampling Distribution,[0],[0]
Here we recall the main convergence results to-date on KQ and discuss how these relate to choices of sampling distribution.,2.4. Established Results,[0],[0]
"To reduce the level of detail below, we make several assumptions at the outset:
Assumption on the domain: The domain X will either be Rd itself or a compact subset of Rd that satisfies an ‘interior cone condition’, meaning that there exists an angle θ ∈ (0, π/2) and a radius r > 0",2.4. Established Results,[0],[0]
such that for every x ∈ X there exists ‖ξ‖2,2.4. Established Results,[0],[0]
"= 1 such that the cone {x + λy : y ∈ Rd, ‖y‖2 = 1, yT ξ ≥ cos θ, λ ∈",2.4. Established Results,[0],[0]
"[0, r]} is contained in X (see Wendland, 2004, for background).
",2.4. Established Results,[0],[0]
"Assumption on the kernel: Consider the integral operator Σ : L2(Π) → L2(Π), with (Σf)(x) defined as the
Bochner integral ∫ X f(x
′)k(x,x′)Π(dx′).",2.4. Established Results,[0],[0]
"Assume that∫ X k(x,x)Π(dx) < ∞, so that Σ is self-adjoint, positive semi-definite and trace-class (Simon, 1979).",2.4. Established Results,[0],[0]
"Then, from an extension of Mercer’s theorem (König, 1986) we have a decomposition k(x,x′) = ∑∞",2.4. Established Results,[0],[0]
"m=1 µmem(x)em(x
′), where µm and em(x) are the eigenvalues and eigenfunctions of Σ. Further assume thatH is dense in L2(Π).
",2.4. Established Results,[0],[0]
"The first result is adapted and extended from Thm. 1 in Oates et al. (2016).
",2.4. Established Results,[0],[0]
Theorem 1.,2.4. Established Results,[0],[0]
Assume that Π′ admits a density π′ defined on a compact domain X .,2.4. Established Results,[0],[0]
Assume that π′,2.4. Established Results,[0],[0]
>,2.4. Established Results,[0],[0]
c for some c > 0.,2.4. Established Results,[0],[0]
"Let x1, . . .",2.4. Established Results,[0],[0]
",xm be fixed and define the Euclidean fill distance
hm = sup x∈X",2.4. Established Results,[0],[0]
"min j=1,...,m
‖x− xj‖2.
Let xm+1, . . .",2.4. Established Results,[0],[0]
",xn be independent draws from Π′. Assume k gives rise to a Sobolev space Hs(Π).",2.4. Established Results,[0],[0]
Then there exists h0 > 0,2.4. Established Results,[0],[0]
"such that, for hm < h0,√
E[Π̂(f)−Π(f)]2 ≤",2.4. Established Results,[0],[0]
"C(f)n−s/d+
for all > 0.",2.4. Established Results,[0],[0]
"Here C(f) = ck,Π′, ‖f‖H for some constant 0 < ck,Π′, <∞ independent of n and f .
",2.4. Established Results,[0],[0]
All proofs are reserved for the Appendix.,2.4. Established Results,[0],[0]
The main contribution of Thm. 1 is to establish a convergence rate for KQ when using importance sampling distributions.,2.4. Established Results,[0],[0]
A similar result appeared in Thm. 1 of Briol et al. (2015b) for samples from Π (see the Appendix) and was extended to MCMC samples in Oates et al. (2016).,2.4. Established Results,[0],[0]
"An extension to
the case of a mis-specified kernel was considered in Kanagawa et al. (2016).",2.4. Established Results,[0],[0]
"However a limitation of this direction of research is that it does not address the question of how to select Π′.
The second result that we present is a consequence of the recent work of Bach (2015), who considered a particular choice of Π′ = ΠB, depending on a fixed λ > 0, via the density πB(x;λ) ∝ ∑∞",2.4. Established Results,[0],[0]
m=1,2.4. Established Results,[0],[0]
"µm µm+λ
e2m(x).",2.4. Established Results,[0],[0]
The following is adapted from Prop. 1 in Bach (2015): Theorem 2.,2.4. Established Results,[0],[0]
"Let x1, . . .",2.4. Established Results,[0],[0]
",xn ∼ ΠB be independent and λ > 0.",2.4. Established Results,[0],[0]
"For δ ∈ (0, 1) and n ≥ 5d(λ) log 16d(λ)δ , d(λ) = ∑∞",2.4. Established Results,[0],[0]
m=1,2.4. Established Results,[0],[0]
"µm µm+λ , we have that
|Π̂(f)−Π(f)| ≤ 2λ1/2‖f‖H,
with probability greater than 1− δ.
",2.4. Established Results,[0],[0]
"Some remarks are in order: (i) Bach (2015, Prop. 3) showed that, for ΠB, integration error scales at an optimal rate in n up to logarithmic terms and, after n samples, is of size √ µn.",2.4. Established Results,[0],[0]
(ii),2.4. Established Results,[0],[0]
"The distribution ΠB is obtained from minimising an upper bound on the integration error, rather than the error itself.",2.4. Established Results,[0],[0]
It is unclear to us how well ΠB approximates an optimal sampling distribution for KQ.,2.4. Established Results,[0],[0]
(iii) In general ΠB is hard to compute.,2.4. Established Results,[0],[0]
"For the specific case X = [0, 1]d, H equal to Hs(Π) and Π uniform, the distribution ΠB is also uniform (and hence independent of n; see Sec. 4.4 of Bach (2015)).",2.4. Established Results,[0],[0]
"However, even for the simple example of Sec. 2.3, ΠB does not appear to have a closed form (details in Appendix).",2.4. Established Results,[0],[0]
"An approximation scheme was proposed in Sec. 4.2 of Bach (2015) but the error of this scheme was not studied.
",2.4. Established Results,[0],[0]
"Optimal sampling for approximation in ‖ · ‖L2(Π) with weighted least squares (not in the kernel setting) was
considered in Hampton and Doostan (2015); Cohen and Migliorati (2016).",2.4. Established Results,[0],[0]
Our first goal was to formalise the sampling problem for KQ; this is now completed.,2.5. Goals,[0],[0]
"Our second goal was to develop a novel automatic approach to selection of Π′, called SMC-KQ; full details are provided in Sec. 3.
",2.5. Goals,[0],[0]
"Also, observe that the integrand f will in general belong to an infinitude of Hilbert spaces, while for KQ a single kernel k must be selected.",2.5. Goals,[0],[0]
"This choice will affect the performance of the KQ estimator; for example, in Fig. 2, the problem of Sec. 2.3 was reconsidered based on a class of kernels k(x, x′) = exp(−(x",2.5. Goals,[0],[0]
− x′)2/`2),2.5. Goals,[0],[0]
"parametrised by ` ∈ (0,∞).",2.5. Goals,[0],[0]
"Results showed that, for all choices of σ parameter, the RMSE of KQ is sensitive to choice of `.",2.5. Goals,[0],[0]
"In particular, the default choice of ` = 1 is not optimal.",2.5. Goals,[0],[0]
"For this reason, an extension that includes kernel learning, called SMC-KQ-KL, is proposed in Sec. 3.",2.5. Goals,[0],[0]
In this section the SMC-KQ and SMC-KQ-KL methods are presented.,3. METHODS,[0],[0]
"Our aim is to explain in detail the main components (SMC, temp, crit) of Alg.",3. METHODS,[0],[0]
1.,3. METHODS,[0],[0]
"To this end, Secs.",3. METHODS,[0],[0]
"3.1 and 3.2 set up our SMC sampler to target tempered distributions, while Sec. 3.3 presents a heuristic for the choice of temperature schedule.",3. METHODS,[0],[0]
Sec. 3.4 extends the approach to kernel learning and Sec. 3.5 proposes a novel criterion to determine when a desired error tolerance is reached.,3. METHODS,[0],[0]
"To begin, consider f , k and n as fixed.",3.1. Thermodynamic Ansatz,[0],[0]
"The following ansatz is central to our proposed SMC-KQ method: An optimal distribution Π∗ (in the sense of Eqn. 3) can be wellapproximated by a distribution of the form
Πt = Π 1−t 0",3.1. Thermodynamic Ansatz,[0],[0]
"Π t, t ∈",3.1. Thermodynamic Ansatz,[0],[0]
"[0, 1] (4)
for a specific (but unknown) ‘inverse temperature’ parameter t = t∗.",3.1. Thermodynamic Ansatz,[0],[0]
Here Π0 is a reference distribution to be specified and which should be chosen to be un-informative in practice.,3.1. Thermodynamic Ansatz,[0],[0]
It is assumed that all Πt exist (i.e. can be normalised).,3.1. Thermodynamic Ansatz,[0],[0]
"The motivation for this ansatz stems from Sec. 2.3, where Π = N(0, 1) and Πt = N(0, σ2) can be cast in this form with t = σ−1 and Π0 an (improper) uniform distribution on R. In general, tempering generates a class of distributions which over-represent extreme events relative to Π (i.e. have heavier tails).",3.1. Thermodynamic Ansatz,[0],[0]
"This property has the potential to improve performance for KQ, as demonstrated in Sec. 2.3.
",3.1. Thermodynamic Ansatz,[0],[0]
"The ansatz of Eqn. 4 reduces the non-parametric sampling problem for KQ to the one-dimensional parametric prob-
lem of selecting a suitable t ∈",3.1. Thermodynamic Ansatz,[0],[0]
"[0, 1].",3.1. Thermodynamic Ansatz,[0],[0]
"The problem can be further simplified by focusing on a discrete temperature ladder {ti}Ti=0 such that t0 = 0, ti < ti+1 and tT = 1.",3.1. Thermodynamic Ansatz,[0],[0]
Discussion of the choice of ladder is deferred to Sec. 3.3.,3.1. Thermodynamic Ansatz,[0],[0]
"This reduced problem, where we seek an optimal index i∗ ∈ {0, . . .",3.1. Thermodynamic Ansatz,[0],[0]
", T}, is still non-trivial as no closed-form expression is available for the RMSE at each candidate ti.",3.1. Thermodynamic Ansatz,[0],[0]
"To overcome this impasse a novel approach to estimate the RMSE is presented in Sec. 3.5.
3.2.",3.1. Thermodynamic Ansatz,[0],[0]
"Convex Ansatz (SMC)
",3.1. Thermodynamic Ansatz,[0],[0]
"The proposed SMC-KQ algorithm requires a second ansatz, namely that the RMSE is convex in t and possesses a global minimum in the range t ∈ (0, 1).",3.1. Thermodynamic Ansatz,[0],[0]
"This second ansatz (borne out in numerical results in Fig. 1) motivates an algorithm that begins at t0 = 0 and tracks the RMSE until an increase is detected, say at ti; at which point the index i∗ = i− 1 is taken for KQ.
To realise such an algorithm, this paper exploited SMC methods (Chopin, 2002; Del Moral et al., 2006).",3.1. Thermodynamic Ansatz,[0],[0]
"Here, a particle approximation {(wj ,xj)}Nj=1 to Πt0 is first obtained where xj are independent draws from Π0, wj = N−1",3.1. Thermodynamic Ansatz,[0],[0]
"and N n. Then, at iteration i, the particle approximation to Πti−1 is re-weighted, re-sampled and subject to a Markov transition, to deliver a particle approximation {(w′j ,x′j)}Nj=1 to Πti .",3.1. Thermodynamic Ansatz,[0],[0]
"This ‘re-sample-move’ algorithm, denoted SMC, is standard but, for completeness, pseudo-code is provided as Alg.",3.1. Thermodynamic Ansatz,[0],[0]
"2 in the Appendix.
",3.1. Thermodynamic Ansatz,[0],[0]
"At iteration i, a subset of size n is drawn from the unique1 elements in {x′j}Nj=1, from the particle approximation to Πti , and proposed for use in KQ.",3.1. Thermodynamic Ansatz,[0],[0]
"A criterion crit, defined in Sec. 3.5, is used to determine whether the resultant KQ error has increased relative to Πti−1 .",3.1. Thermodynamic Ansatz,[0],[0]
"If this is the case, then the distribution Πti−1 from the previous iteration is taken for use in KQ.",3.1. Thermodynamic Ansatz,[0],[0]
Otherwise the algorithm proceeds to ti+1 and the process repeats.,3.1. Thermodynamic Ansatz,[0],[0]
"In the degenerate case where the RMSE has a minimum at tT , the algorithm defaults to standard KQ with Π′ =",3.1. Thermodynamic Ansatz,[0],[0]
"Π.
Both ansatz of the SMC-KQ algorithm are justified through the strong empirical results presented in Sec. 4.
3.3.",3.1. Thermodynamic Ansatz,[0],[0]
"Choice of Temperature Schedule (temp)
",3.1. Thermodynamic Ansatz,[0],[0]
The choice of temperature schedule {ti}Ti=0 influences several aspects of SMC-KQ: (i),3.1. Thermodynamic Ansatz,[0],[0]
The SMC approximation to Πti is governed by the “distance” (in some appropriate metric) between Πti−1 and Πti .,3.1. Thermodynamic Ansatz,[0],[0]
(ii),3.1. Thermodynamic Ansatz,[0],[0]
"The speed at which the minimum t∗ can be reached is linear in the number of
1This ensures that kernel matrices have full rank.",3.1. Thermodynamic Ansatz,[0],[0]
"It does not introduce bias into KQ, since in general Π′ need not equal Π.",3.1. Thermodynamic Ansatz,[0],[0]
"However, to keep notation clear, we do not make this operation explicit.
",3.1. Thermodynamic Ansatz,[0],[0]
temperatures between 0 and t∗. (iii) The precision of KQ depends on the approximation t∗,3.1. Thermodynamic Ansatz,[0],[0]
≈ ti∗ .,3.1. Thermodynamic Ansatz,[0],[0]
"Factors (i,iii) motivate the use of a fine schedule with T large, while (ii) motivates a coarse schedule with T small.
",3.1. Thermodynamic Ansatz,[0],[0]
"For this work, a temperature schedule was used that is well suited to both (i) and (ii), while a strict constraint ti − ti−1 ≤ ∆ was imposed on the grid spacing to acknowledge (iii).",3.1. Thermodynamic Ansatz,[0],[0]
"The specific schedule used in this work was determined based on the conditional effective sample size of the current particle population, as proposed in the recent work of Zhou et al. (2016).",3.1. Thermodynamic Ansatz,[0],[0]
Full details are presented in Algs.,3.1. Thermodynamic Ansatz,[0],[0]
4 and 5 in the Appendix.,3.1. Thermodynamic Ansatz,[0],[0]
In Sec. 2.5 we demonstrated the benefit of kernel learning for KQ.,3.4. Kernel Learning,[0],[0]
"From the Gaussian process characterisation of KQ from Sec. 2.1, it follows that kernel parameters θ can be estimated, conditional on a vector of function evaluations f , via maximum marginal likelihood:
θ′ ← arg max θ p(f |θ) = arg min",3.4. Kernel Learning,[0],[0]
"θ f>K−1θ f + log |Kθ|.
",3.4. Kernel Learning,[0],[0]
"In SMC-KQ-KL, the function evaluations f are obtained at the first2 n (of N )",3.4. Kernel Learning,[0],[0]
states {xj}nj=1 and the parameters θ are updated in each iteration of the SMC.,3.4. Kernel Learning,[0],[0]
This demands repeated function evaluation; this burden can be reduced with less frequent parameter updates and caching of all previous function evaluations.,3.4. Kernel Learning,[0],[0]
"The experiments in Sec. 4 assessed both SMC-KQ and SMC-KQ-KL in terms of precision per total number of function evaluations, so that the additional cost of kernel learning was taken into account.
3.5.",3.4. Kernel Learning,[0],[0]
"Termination Criterion (crit)
",3.4. Kernel Learning,[0],[0]
The SMC-KQ-KL algorithm is designed to track the RMSE as t is increased.,3.4. Kernel Learning,[0],[0]
"However, the RMSE is not available in closed form.",3.4. Kernel Learning,[0],[0]
"In this section we derive a tight upper bound on the RMSE that is used for the crit component in Alg. 1.
",3.4. Kernel Learning,[0],[0]
"From the worst-case characterisation of KQ presented in Sec. 2.1, we have an upper bound
|Π̂(f)−Π(f)| ≤ en(w; {xj}nj=1)‖f‖H. (5)
The term en(w; {xj}nj=1), denoted henceforth as en({xj}nj=1) (since w depends on {xj}nj=1), can be computed in closed form (see the Appendix).",3.4. Kernel Learning,[0],[0]
"This motivates
2This is a notational convention and is without loss of generality.",3.4. Kernel Learning,[0],[0]
"In this paper these states were a random sample (without replacement) of size n, though stratified sampling among the N states could be used.",3.4. Kernel Learning,[0],[0]
"More sophisticated alternatives that also involve the kernel k, such as leverage scores, were not considered, since in general these (i) introduce a vulnerability to mis-specified kernels and (ii) require manipulation of a N × N kernel matrix (Patel et al., 2015).
",3.4. Kernel Learning,[0],[0]
"Algorithm 1 SMC Algorithm for KQ function SMC-KQ(f,Π, k,Π0, ρ, n,N) input f (integrand) input Π (target disn.)",3.4. Kernel Learning,[0],[0]
input k (kernel) input Π0 (reference disn.),3.4. Kernel Learning,[0],[0]
input ρ (re-sample threshold) input n (num. func.,3.4. Kernel Learning,[0],[0]
evaluations) input N (num. particles) i← 0; ti ← 0;,3.4. Kernel Learning,[0],[0]
Rmin ←∞ x′j ∼ Π0 (initialise states ∀j ∈ 1 : N ),3.4. Kernel Learning,[0],[0]
w′j ← N−1 (initialise weights ∀j ∈ 1 : N ),3.4. Kernel Learning,[0],[0]
"R← crit(Π, k, {x′j}Nj=1) (est’d error)",3.4. Kernel Learning,[0],[0]
"while test(R < Rmin) and ti < 1 do i← i+ 1; Rmin ← R {(wj ,xj)}Nj=1 ← {(w′j ,x′j)}Nj=1 ti ← temp({(wj ,xj)}Nj=1, ti−1, ρ) (next temp.)",3.4. Kernel Learning,[0],[0]
"{(w′j ,x′j)}Nj=1 ← SMC({(wj ,xj)}Nj=1, ti, ti−1, ρ) (next particle approx.)",3.4. Kernel Learning,[0],[0]
"R← crit(Π, k, {x′j}Nj=1) (est’d error)
end while fj ← f(xj) (function eval.",3.4. Kernel Learning,[0],[0]
"∀j ∈ 1 : n) zj ← ∫ X k(·,xj)dΠ (kernel mean eval.",3.4. Kernel Learning,[0],[0]
∀j ∈ 1 : n),3.4. Kernel Learning,[0],[0]
"Kj,j′",3.4. Kernel Learning,[0],[0]
"← k(xj ,xj′)",3.4. Kernel Learning,[0],[0]
(kernel eval.,3.4. Kernel Learning,[0],[0]
"∀j, j′ ∈ 1 : n)",3.4. Kernel Learning,[0],[0]
Π̂(f)← z>K−1f (eval.,3.4. Kernel Learning,[0],[0]
"KQ estimator) return Π̂(f)
the following upper bound on MSE:
E[Π̂(f)−Π(f)]2 ≤ E[en({xj}nj=1)2]︸ ︷︷ ︸ (∗)",3.4. Kernel Learning,[0],[0]
"‖f‖2H︸ ︷︷ ︸ (∗∗)
(6)
",3.4. Kernel Learning,[0],[0]
"The term (∗) can be estimated with the bootstrap approximation
E[en({xj}nj=1)2] = M∑ m=1 en({x̃m,j}nj=1)2 M =: R2
where x̃m,j are independent draws from {xj}Nj=1.",3.4. Kernel Learning,[0],[0]
"In SMC-KQ the term (∗∗) is an unknown constant and the statistic R, an empirical proxy for the RMSE, is monitored at each iteration.",3.4. Kernel Learning,[0],[0]
The algorithm terminates once an increase in this statistic occurs.,3.4. Kernel Learning,[0],[0]
For SMC-KQ-KL the term (∗∗) is non-constant as it depends on the kernel hyper-parameters; then (∗∗) can in addition be estimated as ‖f̂‖2H = w>Kθw,3.4. Kernel Learning,[0],[0]
"and we monitor the product of R and ‖f̂‖H, with termination when an increase is observed (c.f. test, defined in the Appendix).
",3.4. Kernel Learning,[0],[0]
"Full pseudo-code for SMC-KQ is provided as Alg. 1, while SMC-KQ-KL is Alg. 9 in the Appendix.",3.4. Kernel Learning,[0],[0]
"To summarise, we have developed a novel procedure, SMC-KQ (and an extension SMC-KQ-KL), designed to approximate the optimal
KQ estimator based on the unavailable optimal distribution in Eqn. 3 where F is the unit ball of H. Earlier empirical results in Sec. 2.3 suggest that SMC-KQ has potential to provide a powerful and general algorithm for numerical integration.",3.4. Kernel Learning,[0],[0]
"The additional computational cost of optimising the sampling distribution does however have to be counterbalanced with the potential gain in error, and so this method will mainly be of practical interest for problems with expensive integrands or complex target distributions.",3.4. Kernel Learning,[0],[0]
The following section reports experiments designed to test this claim.,3.4. Kernel Learning,[0],[0]
"Here we compared SMC-KQ (and SMC-KQ-KL) against the corresponding default approaches KQ (and KQ-KL) that are based on Π′ = Π. Sec. 4.1 below reports an assessment in which the true value of integrals is known by design, while in Sec. 4.2 the methods were deployed to solve a parameter estimation problem involving differential equations.",4. RESULTS,[0],[0]
"To continue our illustration from Sec. 2, we investigated the performance of SMC-KQ and SMC-KQ-KL for integration of f(x) = 1 + sin(2πx) against the distribution Π = N(0, 1).",4.1. Simulation Study,[0],[0]
"Here the reference distribution was taken to be Π0 = N(0, 82).",4.1. Simulation Study,[0],[0]
"All experiments employed SMC with N = 300 particles, random walk Metropolis transitions (Alg. 3), the re-sample threshold ρ = 0.95 and a maximum grid size ∆ = 0.1.",4.1. Simulation Study,[0],[0]
"Dependence of the subsequent results on the choice of Π0 was investigated in Fig. 10 in the Appendix.
",4.1. Simulation Study,[0],[0]
"Fig. 3 (top) reports results for SMC-KQ against KQ, for fixed length-scale ` = 1.",4.1. Simulation Study,[0],[0]
Corresponding results for SMC-KQ-KL against KQ-KL are shown in the bottom plot.,4.1. Simulation Study,[0],[0]
It was observed that SMC-KQ (resp.,4.1. Simulation Study,[0],[0]
SMC-KQ-KL) outperformed KQ (resp.,4.1. Simulation Study,[0],[0]
"KQ-KL) in the sense that, on a perfunction-evaluation basis, the MSE achieved by the proposed method was lower than for the standard method.",4.1. Simulation Study,[0],[0]
The largest reduction in MSE achieved was about 8 orders of magnitude (correspondingly 4 orders of magnitude in RMSE).,4.1. Simulation Study,[0],[0]
"A fair approximation to the σ = 2 method, which is approximately optimal for n = 75 (c.f. results in Fig. 1), was observed.",4.1. Simulation Study,[0],[0]
The termination criterion in Sec. 3.5 was observed to be a good approximation to the optimal temperature t∗,4.1. Simulation Study,[0],[0]
(Fig. 9 in Appendix).,4.1. Simulation Study,[0],[0]
"As an aside, we note that the MSE was gated at 10−16 for all methods due to numerical condition of the kernel matrix K (a known feature of the Gaussian kernel used in this experiment).
",4.1. Simulation Study,[0],[0]
"The investigation was extended to larger dimensions (d = 3 and d = 10) and more complex integrands f in the Ap-
pendix.",4.1. Simulation Study,[0],[0]
"In all cases, considerable improvements were obtained using SMC-KQ over KQ.",4.1. Simulation Study,[0],[0]
Consider the model given by dx/dt = f(t|θ) with solution x(t|θ) depending on unknown parameters θ.,4.2. Inference for Differential Equations,[0],[0]
Suppose we can obtain observations through the following noise model (likelihood): y(ti) = x(ti|θ) +,4.2. Inference for Differential Equations,[0],[0]
ei at times 0 = t1 < . . .,4.2. Inference for Differential Equations,[0],[0]
"< tn where we assume ei ∼ N(0, σ2) for known σ > 0.",4.2. Inference for Differential Equations,[0],[0]
Our goal is to estimate x(T |θ) for a fixed (potentially large) T > 0.,4.2. Inference for Differential Equations,[0],[0]
"To do so, we will use a Bayesian approach and specify a prior p(θ), then obtain samples from the posterior π(θ) := p(θ|y) using MCMC.",4.2. Inference for Differential Equations,[0],[0]
The posterior predictive mean is then defined as: Π ( x(T |·) ),4.2. Inference for Differential Equations,[0],[0]
= ∫ x(T,4.2. Inference for Differential Equations,[0],[0]
"|θ)π(θ)dθ, and this can be estimated using an empirical average from the posterior samples.",4.2. Inference for Differential Equations,[0],[0]
This type of integration problem is particularly challenging as the integrand requires simulating from the differential equation at each iteration.,4.2. Inference for Differential Equations,[0],[0]
"Furthermore, the larger T or the smaller the grid, the longer the simulation will be and the higher the computational cost.
",4.2. Inference for Differential Equations,[0],[0]
"For a tractable test-bed, we considered Hooke’s law, given
by the following second order homogeneous ODE given by
θ5 d2x
dt2 + θ4
dx dt + θ3x = 0,
with initial conditions x(0) = θ1 and x′(0) = θ2.",4.2. Inference for Differential Equations,[0],[0]
"This equation represents the evolution of a mass on a spring with friction (Robinson, 2004, Chapter 13).",4.2. Inference for Differential Equations,[0],[0]
"More precisely, θ3 denotes the spring constant, θ4 the damping coefficient representing friction and θ5 the mass of the object.",4.2. Inference for Differential Equations,[0],[0]
Since this differential equation is an overdetermined system we fixed θ5 = 1.,4.2. Inference for Differential Equations,[0],[0]
"In this case, if θ24 ≤ 4θ3, we get a damped oscillatory behaviour as presented in Fig. 4 (top).",4.2. Inference for Differential Equations,[0],[0]
"Data were generated with σ = 0.4, (θ1, θ2, θ3, θ4) =",4.2. Inference for Differential Equations,[0],[0]
"(1, 3.75, 2.5, 0.5).",4.2. Inference for Differential Equations,[0],[0]
"with log-normal priors with scale equal to 0.5 for all parameters.
To implement KQ under an unknown normalisation constant for Π, we followed Oates et al. (2017) and made use of a Gaussian kernel that was adapted with Stein’s method (see the Appendix for details).",4.2. Inference for Differential Equations,[0],[0]
"The reference distribution Π0 was an wide uniform prior on the hypercube [0, 10]4.",4.2. Inference for Differential Equations,[0],[0]
Brute force computation was used to obtain a benchmark value for the integral.,4.2. Inference for Differential Equations,[0],[0]
"For the SMC algorithm, an independent lognormal transition kernel was used at each iteration with parameters automatically tuned to the current set of particles.",4.2. Inference for Differential Equations,[0],[0]
Results in Fig. 4 demonstrate that SMC-KQ outperforms KQ for these integration problems.,4.2. Inference for Differential Equations,[0],[0]
These results improve upon those reported in Oates et al. (2016) for a similar integration problem based on parameter estimation for differential equations.,4.2. Inference for Differential Equations,[0],[0]
In this paper we formalised the optimal sampling problem for KQ.,5. DISCUSSION,[0],[0]
"A general, practical solution was proposed, based on novel use of SMC methods.",5. DISCUSSION,[0],[0]
Initial empirical results demonstrate performance gains relative to standard approach of KQ with Π′ =,5. DISCUSSION,[0],[0]
"Π. A more challenging example based on parameter estimation for differential equations was used to illustrate the potential of SMC-KQ for Bayesian computation in combination with Stein’s method.
",5. DISCUSSION,[0],[0]
Our methods were general but required user-specified choice of an initial distribution Π0.,5. DISCUSSION,[0],[0]
For compact state spaces X we recommend taking Π0 to be uniform.,5. DISCUSSION,[0],[0]
"For non-compact spaces, however, there is a degree of flexibility here and default solutions, such as wide Gaussian distributions, necessarily require user input.",5. DISCUSSION,[0],[0]
"However, the choice of Π0 is easier than the choice of Π′ itself, since Π0 is not required to be optimal.",5. DISCUSSION,[0],[0]
"In our examples, improved performance (relative to standard KQ) was observed for a range of reference distributions Π0.
",5. DISCUSSION,[0],[0]
A main motivation for this research was to provide an alternative to optimisation-based KQ that alleviates strong dependence on the choice of kernel (Sec. 2.2).,5. DISCUSSION,[0],[0]
"This paper provides essential groundwork toward that goal, in developing sampling-based methods for KQ in the case of complex and expensive integration problems.",5. DISCUSSION,[0],[0]
"An empirical comparison of sampling-based and optimisation-based methods is reserved for future work.
",5. DISCUSSION,[0],[0]
"Two extensions of this research are identified: First, the curse of dimension that is intrinsic to standard Sobolev spaces can be alleviated by demanding ‘dominating mixed smoothness’; our methods are compatible with these (essentially tensor product) kernels (Dick et al., 2013).",5. DISCUSSION,[0],[0]
"Second, the use of sequential QMC (Gerber and Chopin, 2015) can be considered, motivated by further orders of magnitude reduction in numerical error observed for deterministic point sets (see Fig. 13 in the Appendix).",5. DISCUSSION,[0],[0]
FXB was supported by the EPSRC grant [EP/L016710/1].,ACKNOWLEDGEMENTS,[0],[0]
CJO & MG we supported by the Lloyds Register Foundation Programme on Data-Centric Engineering.,ACKNOWLEDGEMENTS,[0],[0]
WYC was supported by the ARC Centre of Excellence in Mathematical and Statistical Frontiers.,ACKNOWLEDGEMENTS,[0],[0]
"MG was supported by the EPSRC grants [EP/J016934/3, EP/K034154/1, EP/P020720/1], an EPSRC Established Career Fellowship, the EU grant [EU/259348], a Royal Society Wolfson Research Merit Award.",ACKNOWLEDGEMENTS,[0],[0]
"FXB, CJO, JC & MG were also supported by the SAMSI working group on Probabilistic Numerics.",ACKNOWLEDGEMENTS,[0],[0]
"The standard Kernel Quadrature method for numerical integration with random point sets (also called Bayesian Monte Carlo) is known to converge in root mean square error at a rate determined by the ratio s/d, where s and d encode the smoothness and dimension of the integrand.",abstractText,[0],[0]
"However, an empirical investigation reveals that the rate constant C is highly sensitive to the distribution of the random points.",abstractText,[0],[0]
"In contrast to standard Monte Carlo integration, for which optimal importance sampling is wellunderstood, the sampling distribution that minimises C for Kernel Quadrature does not admit a closed form.",abstractText,[0],[0]
This paper argues that the practical choice of sampling distribution is an important open problem.,abstractText,[0],[0]
One solution is considered; a novel automatic approach based on adaptive tempering and sequential Monte Carlo.,abstractText,[0],[0]
Empirical results demonstrate a dramatic reduction in integration error of up to 4 orders of magnitude can be achieved with the proposed method.,abstractText,[0],[0]
On the Sampling Problem for Kernel Quadrature,title,[0],[0]
Finding relevant features is one of the key steps for solving a machine learning problem.,1. Introduction,[0],[0]
"To this end, the backpropagation algorithm is probably the best-known method, with which superhuman performances are commonly achieved for specific tasks in applications of computer vision (Krizhevsky et al., 2012) and many others (Schmidhuber, 2015).",1. Introduction,[0],[0]
"But data-driven approaches such as the backpropagation method, in addition to being computationally demanding, fail to cope with limited amounts of available training data.
",1. Introduction,[0],[0]
"One successful alternative in this regard is the use of “random features”, exploited both in feed-forward neural networks (Huang et al., 2012; Scardapane & Wang, 2017), in large-scale kernel estimation (Rahimi & Recht, 2008; Vedaldi & Zisserman, 2012) and more recently in random sketching schemes (Keriven et al., 2016).",1. Introduction,[0],[0]
"Random feature maps consist in projections randomly exploring the set of nonlinear representations of the data, hopefully extracting
1Laboratoire des",1. Introduction,[0],[0]
"Signaux et Systèmes (L2S), CentraleSupélec, Université Paris-Saclay, France; 2G-STATS Data Science Chair, GIPSA-lab, University Grenobles-Alpes, France.",1. Introduction,[0],[0]
Correspondence to:,1. Introduction,[0],[0]
"Zhenyu Liao <zhenyu.liao@l2s.centralesupelec.fr>, Romain Couillet <romain.couillet@centralesupelec.fr>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
features relevant to some given task.",1. Introduction,[0],[0]
"The nonlinearities make these representations more mighty but meanwhile theoretically more difficult to analyze and optimize.
",1. Introduction,[0],[0]
"Infinitely large random features maps are nonetheless well understood as they result in (asymptotically) equivalent kernels, the most popular example being random Fourier features and their limiting radial basis kernels (Rahimi & Recht, 2008).",1. Introduction,[0],[0]
"Beyond those asymptotic results, recent advances in random matrix theory give rise to unexpected simplification on the understanding of the finite-dimensional version of these kernels, i.e., when the data number and size are large but of similar order as the random feature vector size (El Karoui et al., 2010; Couillet",1. Introduction,[0],[0]
"et al., 2016).",1. Introduction,[0],[0]
"Following the same approach, in this work, we perform a spectral analysis on the Gram matrix of the random feature matrices.",1. Introduction,[0],[0]
"This matrix is of key relevance in many associated machine learning methods (e.g., spectral clustering (Ng et al., 2002) and kernel SVM (Schölkopf & Smola, 2002)) and understanding its spectrum casts an indispensable light on their asymptotic performances.",1. Introduction,[0],[0]
"In the remainder of the article, we shall constantly consider spectral clustering as a concrete example of application; however, similar analyses can be performed for other types of random feature-based algorithms.
",1. Introduction,[0],[0]
Our contribution is twofold.,1. Introduction,[0],[0]
"From a random matrix theory perspective, it is a natural extension of the sample covariance matrix analysis (Silverstein & Bai, 1995) to a nonlinear setting and can also be seen as the generalization of the recent work of (Pennington & Worah, 2017) to a more practical data model.",1. Introduction,[0],[0]
"From a machine learning point of view, we describe quantitatively the mutual influence of different nonlinearities and data statistics on the resulting random feature maps.",1. Introduction,[0],[0]
"More concretely, based on the ratio of two coefficients from our analysis, commonly used activation functions are divided into three classes: means-oriented, covariance-oriented and balanced, which eventually allows one to choose the activation function with respect to the statistical properties of the data (or task) at hand, with a solid theoretical basis.
",1. Introduction,[0],[0]
"We show by experiments that our results, applicable theoretically only to Gaussian mixture data, show an almost perfect match when applied to some real-world datasets.",1. Introduction,[0],[0]
"We are thus optimistic that our findings, although restricted to Gaussian assumptions on the data model, can be applied to
a larger set of problems beyond strongly structured ones.
",1. Introduction,[0],[0]
"Notations: Boldface lowercase (uppercase) characters stand for vectors (matrices), and non-boldface scalars respectively.",1. Introduction,[0],[0]
"1T is the column vector of ones of size T , and IT the T ⇥T identity matrix.",1. Introduction,[0],[0]
The notation (·)T denotes the transpose operator.,1. Introduction,[0],[0]
"The norm k · k is the Euclidean norm for vectors and the operator norm for matrices.
",1. Introduction,[0],[0]
"In the remainder of this article, we introduce the objects of interest and necessary preliminaries in Section 2.",1. Introduction,[0],[0]
"Our main results on the spectrum of random feature maps will be presented in Section 3, followed by experiments on two types of classification tasks in Section 4.",1. Introduction,[0],[0]
The article closes on concluding remarks and envisioned extensions in Section 5.,1. Introduction,[0],[0]
"Let x1, . . .",2. Problem Statement and Preliminaries,[0],[0]
",xT 2",2. Problem Statement and Preliminaries,[0],[0]
"Rp be independent data vectors, each belonging to one of K distribution classes C1, . . .",2. Problem Statement and Preliminaries,[0],[0]
", CK .",2. Problem Statement and Preliminaries,[0],[0]
"Class Ca has cardinality Ta, for all a 2 {1, . . .",2. Problem Statement and Preliminaries,[0],[0]
",K}.",2. Problem Statement and Preliminaries,[0],[0]
"We assume that the data vector xi follows a Gaussian mixture model1, i.e.,
xi = µa/ p p+ !",2. Problem Statement and Preliminaries,[0],[0]
"i
with !",2. Problem Statement and Preliminaries,[0],[0]
"i ⇠ N (0,Ca/p) for some mean µa 2 Rp and covariance Ca 2 Rp⇥p of associated class Ca.",2. Problem Statement and Preliminaries,[0],[0]
We denote the data matrix X = ⇥,2. Problem Statement and Preliminaries,[0],[0]
"x1, . . .",2. Problem Statement and Preliminaries,[0],[0]
",xT",2. Problem Statement and Preliminaries,[0],[0]
⇤ 2 Rp⇥T of size T by cascading all xi as column vectors.,2. Problem Statement and Preliminaries,[0],[0]
"To extract random features, X is premultiplied by some random matrix W 2 Rn⇥p with i.i.d. entries and then applied entry-wise some nonlinear activation function (·) to obtain the random feature matrix ⌃ ⌘ (WX) 2 Rn⇥T , whose columns are simply (Wxi) the associated random feature of xi.
",2. Problem Statement and Preliminaries,[0],[0]
"In this article, we focus on the Gram matrix G ⌘ 1 n ⌃T⌃ of the random features, the entry (i, j) of which is given by
Gij = 1
n",2. Problem Statement and Preliminaries,[0],[0]
"(Wxi)
T (Wxj) =
1
n
nX
k=1
(wT k xi) (w T k xj)
with wT k the k-th row of W. Note that all wk follow the same distribution, so that taking expectation over w ⌘ wk of the above equation one results in the average kernel matrix , with the (i, j) entry of which given by
(xi,xj) =",2. Problem Statement and Preliminaries,[0],[0]
EwGij = Ew (wTxi) (wTxj).,2. Problem Statement and Preliminaries,[0],[0]
"(1)
When the entries of W follow a standard Gaussian distribution, one can compute the generic form (a,b) =",2. Problem Statement and Preliminaries,[0],[0]
"Ew (wTa) (wTb) by applying the integral trick from (Williams, 1997), for a large set of nonlinear functions (·) and arbitrary vector a,b of appropriate dimension.",2. Problem Statement and Preliminaries,[0],[0]
"We list the results for commonly used functions in Table 1.
",2. Problem Statement and Preliminaries,[0],[0]
"1We normalize the data by p 1/2 to guarantee that kxik = O(1) with high probability when kCak = O(1).
",2. Problem Statement and Preliminaries,[0],[0]
"Since the Gram matrix G describes the correlation of data in the feature space, it is natural to recenter G, and thus by pre- and post-multiplying a projection matrix P ⌘ IT 1T 1T1 T T .",2. Problem Statement and Preliminaries,[0],[0]
"In the case of , we get
c ⌘",2. Problem Statement and Preliminaries,[0],[0]
"P P.
In the recent line of works (Louart et al., 2018; Pennington & Worah, 2017), it has been shown that the large dimensional (large n, p, T ) characterization of G, in particular its eigenspectrum, is fully determined by and the ratio n/",2. Problem Statement and Preliminaries,[0],[0]
p.,2. Problem Statement and Preliminaries,[0],[0]
"For instance, by defining the empirical spectral distribution of Gc = PGP as ⇢Gc(x) ⌘ 1T P T
i=1 1 ix(x), with 1, . . .",2. Problem Statement and Preliminaries,[0],[0]
", T the eigenvalues of Gc, it has been shown in (Louart et al., 2018)",2. Problem Statement and Preliminaries,[0],[0]
"that, as n, p, T ! 1, ⇢G(x) almost surely converges to a non-random distribution ⇢(x), referred to as the limiting spectral distribution of Gc such that
⇢(x) = 1
⇡ lim y!0+
Z x
1 =",2. Problem Statement and Preliminaries,[0],[0]
"[m(t+ iy)] dt.
with m(z) the associated Stieltjes transform given by
m(z) = 1
n trQ(z), Q(z) ⌘
✓ c
1 + (z) zIT
◆ 1
with (z) the unique solution of (z) = 1 n tr ( cQ(z)).
",2. Problem Statement and Preliminaries,[0],[0]
"As a consequence, in the objective of understanding the asymptotic behavior of Gc as n, p, T are simultaneously large, we shall focus our analysis on c. To this end, the following assumptions will be needed throughout the paper.
",2. Problem Statement and Preliminaries,[0],[0]
Assumption 1 (Growth rate).,2. Problem Statement and Preliminaries,[0],[0]
As T !,2. Problem Statement and Preliminaries,[0],[0]
"1,
1) p/T !",2. Problem Statement and Preliminaries,[0],[0]
"c0 2 (0,1),
2) for each a 2 {1, . .",2. Problem Statement and Preliminaries,[0],[0]
.,2. Problem Statement and Preliminaries,[0],[0]
",K}, Ta/T !",2. Problem Statement and Preliminaries,[0],[0]
"ca 2 (0, 1),
3) kµak = O(1), 4) let C ⌘ P K
a=1 Ta T Ca and for a 2 {1, . . .",2. Problem Statement and Preliminaries,[0],[0]
",K}, C a ⌘
Ca C , then kCak = O(1) and tr(C a)/ p p = O(1),
5) for technical convenience we assume in addition that ⌧ ⌘ tr (C ) /p converges in (0,1).
",2. Problem Statement and Preliminaries,[0],[0]
"Assumption 1 ensures that the information of means or covariances is neither too simple nor impossible to be extracted from the data, as investigated in (Couillet et al., 2016).
",2. Problem Statement and Preliminaries,[0],[0]
Let us now introduce the key steps of our analysis.,2. Problem Statement and Preliminaries,[0],[0]
"Under Assumption 1, note that for xi 2 Ca and xj 2 Cb, i 6= j,
xT",2. Problem Statement and Preliminaries,[0],[0]
i xj = !,2. Problem Statement and Preliminaries,[0],[0]
T i !j|,2. Problem Statement and Preliminaries,[0],[0]
"{z }
O(p 1/2)
+µT a µb/p+ µ T a !j/
p p+ µT
b !",2. Problem Statement and Preliminaries,[0],[0]
"i/
p p
| {z } O(p 1)
which allows one to perform a Taylor expansion around 0 as p, T !",2. Problem Statement and Preliminaries,[0],[0]
"1, to give a reasonable approximation of nonlinear functions of xT
i xj , such as those appearing in ij (see again
Table 1).",2. Problem Statement and Preliminaries,[0],[0]
"For i = j, one has instead
kxik2 = k!ik2| {z } O(1)
+ kµak2/p+ 2µTa!i/ p p
| {z } O(p 1)
.
",2. Problem Statement and Preliminaries,[0],[0]
From E!i [k!ik2] = tr(Ca)/p it is convenient to further write k!ik2 = tr(Ca)/p,2. Problem Statement and Preliminaries,[0],[0]
+ k!ik2,2. Problem Statement and Preliminaries,[0],[0]
"tr(Ca)/p , where tr(Ca)/p = O(1) and k!ik2 tr(Ca)/p = O(p 1/2).",2. Problem Statement and Preliminaries,[0],[0]
By definition ⌧ ⌘ tr(C )/p,2. Problem Statement and Preliminaries,[0],[0]
"= O(1) and exploiting again Assumption 1 one results in,
kxik2 = ⌧|{z} O(1) +tr(C a )/p+",2. Problem Statement and Preliminaries,[0],[0]
"k!ik2 tr(Ca)/p| {z }
O(p 1/2)
+ kµak2/p+ 2µTa!i/ p p
| {z } O(p 1)
which allows for a Taylor expansion of nonlinear functions of kxik2 around ⌧ , as has been done for xTi xj .
",2. Problem Statement and Preliminaries,[0],[0]
"From Table 1, it appears that, for every listed (·), (xi,xj) is a smooth function of xT
i xj and kxik, kxjk, despite
their possible discontinuities (e.g., the ReLU function and (t) = |t|).",2. Problem Statement and Preliminaries,[0],[0]
"The above results thus allow for an entry-wise Taylor expansion of the matrix in the large p, T limit.
",2. Problem Statement and Preliminaries,[0],[0]
"A critical aspect of the analysis where random matrix theory comes into play now consists in developing as a sum of matrices arising from the Taylor expansion and ignoring terms that give rise to a vanishing operator norm,
so as to find an asymptotic equivalent matrix ̃ such that k ̃k ! 0",2. Problem Statement and Preliminaries,[0],[0]
"as p, T ! 1, as described in detail in the following section",2. Problem Statement and Preliminaries,[0],[0]
.,2. Problem Statement and Preliminaries,[0],[0]
"This analysis provides a simplified asymptotically equivalent expression for with all nonlinearities removed, which is the crux of the present study.",2. Problem Statement and Preliminaries,[0],[0]
"In the remainder of this article, we shall use the following notations for random elements,
⌦ ⌘ ⇥ !1, . . .",3. Main Results,[0],[0]
",!",3. Main Results,[0],[0]
"T ⇤ , ⌘",3. Main Results,[0],[0]
"k!ik2 Ek!ik2 T i=1
such that ⌦ 2 Rp⇥T , 2 RT .",3. Main Results,[0],[0]
"For deterministic elements2,
M ⌘ ⇥ µ1, . . .",3. Main Results,[0],[0]
",µK ⇤ 2 Rp⇥K , t ⌘ {trC a / p p}K
a=1
J ⌘ ⇥ j1, . . .",3. Main Results,[0],[0]
", jK ⇤ 2 RT⇥K ,S ⌘ {tr(CaCb)/p}Ka,b=1
with t 2 RK , S 2 RK⇥K and ja 2 RT denotes the canonical vector of class Ca such that (ja)i = xi2Ca .",3. Main Results,[0],[0]
Theorem 1 (Asymptotic Equivalent of c).,3. Main Results,[0],[0]
"Let Assumption 1 hold and c be defined as c ⌘ P P, with given in (1).",3. Main Results,[0],[0]
"Then, as T ! 1, for all (·) given in Table 1,3
k c ̃ck ! 0",3. Main Results,[0],[0]
"2As a reminder here, M stands for means, t accounts for (difference in) traces while S for the “shapes” of covariances.",3. Main Results,[0],[0]
"3For all functions (·) listed in Table 1 we identified a “pattern” in the structure of ̃c, which then led to Theorem 1 and Table 2.",3. Main Results,[0],[0]
"This two-step approach does not yet allow to justify whether this pattern goes beyond these (listed) functions; hence Theorem 1 is stated so far solely for these functions.
",3. Main Results,[0],[0]
"On the Spectrum of Random Features Maps of High Dimensional Data
almost surely, with ̃c = P̃P and ̃ ⌘",3. Main Results,[0],[0]
"d1 ✓ ⌦+M
JT p p
◆T✓ ⌦+M
JT p p
◆ +d2UBU T+d0IT
where we recall that P ⌘ IT 1T 1T1 T T and
U ⌘",3. Main Results,[0],[0]
"h Jp p , i , B ⌘
 ttT + 2S t
tT 1
with the coefficients d0, d1, d2 given in Table 2.
",3. Main Results,[0],[0]
"We refer the readers to Section A in Supplementary Material for a detailed proof of Theorem 1.
0 0.2 0.4 0.6 0.8 1 1.2
Eigenvalues of c
0 0.2 0.4 0.6 0.8 1 1.2
Eigenvalues of c
0 0.2 0.4 0.6 0.8 1 1.2
Eigenvalues of ̃c
0 0.2 0.4 0.6 0.8 1 1.2
Eigenvalues of ̃c
0.1 0.05
0 0.05 0.1
Leading eigenvector of c Leading eigenvector of ̃c
C1 C2
0.1 0.05
0 0.05 0.1
Leading eigenvector of c Leading eigenvector of ̃c
C1 C2
Figure 2.",3. Main Results,[0],[0]
"Leading eigenvector of c and ̃c in the settings of Figure 1, with j1 = ⇥ 1T1 ;0T2 ⇤ and j2 = ⇥ 0T1",3. Main Results,[0],[0]
";1T2 ⇤ .
",3. Main Results,[0],[0]
"Theorem 1 tells us as a corollary (see Corollary 4.3.15 in (Horn & Johnson, 2012)) that the maximal difference between the eigenvalues of c and ̃c vanishes asymptotically as p, T !",3. Main Results,[0],[0]
"1, as confirmed in Figure 1.",3. Main Results,[0],[0]
"Similarly the distance between the “isolated eigenvectors4” also vanishes, as seen in Figure 2.",3. Main Results,[0],[0]
"This is of tremendous importance as the determination of the leading eigenvalues and eigenvectors of c (that contain crucial information for clustering, for example) can be studied from the equivalent problem performed on ̃c and becomes mathematically more tractable.
",3. Main Results,[0],[0]
"4Eigenvectors that correspond to the eigenvalues found at a non-vanishing distance from the other eigenvalues.
",3. Main Results,[0],[0]
"On closer inspection of Theorem 1, the matrix ̃ is expressed as the sum of three terms, weighted respectively by the three coefficients d0, d1 and d2, that depend on the nonlinear function (·) via Table 2.",3. Main Results,[0],[0]
Note that the statistical structure of the data {xi}Ti=1 (namely the means in M and the covariances in t and S) is perturbed by random fluctuations (⌦ and ) and it is thus impossible to get rid of these noisy terms by wisely choosing the function (·).,3. Main Results,[0],[0]
"This is in sharp contrast to (Couillet et al., 2016) where it is shown that more general kernels (i.e., not arising from random feature maps) allow for a more flexible treatment of information versus noise.
",3. Main Results,[0],[0]
"However, there does exist a balance between the means and covariances, that provides some instructions in the appropriate choice of the nonlinearity.",3. Main Results,[0],[0]
"From Table 2, the functions (·) can be divided into the following three groups:
Before entering into a more detailed discussion of Theorem 1, first note importantly that, for practical interests, the quantity ⌧ can be estimated consistently from the data, as described in the following lemma.",3. Main Results,[0],[0]
Lemma 1 (Consistent estimator of ⌧ ).,3. Main Results,[0],[0]
Let Assumption 1 hold and recall the definition ⌧ ⌘ tr (C ) /p.,3. Main Results,[0],[0]
"Then, as T ! 1, with probability 1
1
T
TX
i=1
kxik2 ⌧ ! 0.
Proof.",3. Main Results,[0],[0]
"Since
1
T
TX
i=1
kxik2 = 1
T
KX
a=1
TaX
i=1
1 p kµak2 2 p p µT a !",3. Main Results,[0],[0]
"i + k!ik2,
with Assumption 1 we have 1 T
P K
a=1
P Ta
i=1",3. Main Results,[0],[0]
"1 p kµak2 =
O(p 1).",3. Main Results,[0],[0]
"The term 1 T
P K
a=1
P Ta
i=1",3. Main Results,[0],[0]
2p p µT a !,3. Main Results,[0],[0]
"i is a linear com-
bination of independent zero-mean Gaussian variables and vanishes with probability 1 as p, T !",3. Main Results,[0],[0]
1 with Chebyshev’s inequality and the Borel-Cantelli lemma.,3. Main Results,[0],[0]
"Ultimately by the strong law of large numbers, we have 1
T
P T
i=1",3. Main Results,[0],[0]
k!ik2 ⌧ ! 0,3. Main Results,[0],[0]
"almost surely, which concludes the proof.
",3. Main Results,[0],[0]
"From a practical aspect, a few remarks on the conclusions of Theorem 1 can be made.",3. Main Results,[0],[0]
Remark 1 (Constant shift in feature space).,3. Main Results,[0],[0]
"For (t) = &2t
2 + &1t+ &0, note the absence of &0 in Table 2, meaning that the constant of the quadratic function does not affect the spectrum of the feature matrix.",3. Main Results,[0],[0]
"More generally, it can be shown through the integral trick of (Williams, 1997) that the function (t) + c for some constant shift c gives the same matrix c as the original function (t).
",3. Main Results,[0],[0]
"A direct consequence of Remark 1 is that the coefficients d0, d1, d2 of the function sign(t) are four times those of 1t>0, as a result of the fact that sign(t) = 2 · 1t>0 1.",3. Main Results,[0],[0]
"Constant shifts have, as such, no consequence in classification or clustering applications.",3. Main Results,[0],[0]
Remark 2 (Universality of quadratic and Leaky ReLU functions).,3. Main Results,[0],[0]
"Ignoring the coefficient d0 that gives rise to a constant shift of all eigenvalues of ̃c and thus of no practical relevance, observe from Table 2 that by tuning the parameters of the quadratic and Leaky ReLU functions (LReLU(t)), one can select arbitrary positive value for the ratio d1/d2, while the other listed functions have constraints linking d1 to d2.
",3. Main Results,[0],[0]
"Following the discussions in Remark 2, the parameters &+, & of the LReLU, as well as &1, &2 of the quadratic function, essentially act to balance the weights of means
and covariances in the mixture model of the data.",3. Main Results,[0],[0]
"More precisely, as &+
& ! 1 or &2 &1, more emphasis is set on
the “distance” between covariance matrices while &+ & !",3. Main Results,[0],[0]
"1 or &1 &2 stresses the differences in means.
",3. Main Results,[0],[0]
"In Figure 5, spectral clustering on four classes of Gaussian data is performed: N (µ1,C1), N (µ1,C2), N (µ2,C1) and N (µ2,C2) with the LReLU function that takes different values for &+ and & .",3. Main Results,[0],[0]
"For a = 1, 2, µa =⇥ 0a 1; 5;0p a ⇤ and Ca = ⇣ 1 + 15(a",3. Main Results,[0],[0]
"1)p
p
⌘ Ip.",3. Main Results,[0],[0]
"By choosing
&+ = & = 1 (equivalent to (t) = |t|) and &+ = & = 1 (equivalent to the linear map (t) = t), with the leading two eigenvectors we always recover two classes instead of four, as each setting of parameters only allows for a part of the statistical information of the data to be used for clustering.",3. Main Results,[0],[0]
"However, by taking &+ = 1, & = 0 (the ReLU function) we distinguish all four classes in the leading two eigenvectors, to which the k-means method can then be applied for final classification, as shown in Figure 6.
",3. Main Results,[0],[0]
"Of utmost importance for random feature-based spectral methods (such as kernel spectral clustering discussed above (Ng et al., 2002)) is the presence of informative eigenvectors in the spectrum of G, and thus of c. To gain a deeper understanding on the spectrum of c, one can rewrite ̃ in the more compact form,
̃ = d1⌦ T⌦+VAVT + d0IT (2)
where
V ⌘ h
Jp p , ,⌦TM
i , A ⌘
2 4 A11 d2t d1IK d2tT d2 0",3. Main Results,[0],[0]
"d1IK 0 0 3 5
with A11 ⌘ d1MTM",3. Main Results,[0],[0]
"+ d2(ttT + 2S), that is akin to the so-called “spiked model” in the random matrix literature (Baik et al., 2005), as it equals, if d1 6= 0, the sum of some standard (noise-like) random matrix ⌦T⌦, and a low rank (here up to 2K + 1) informative matrix VAVT, that may induce some isolated eigenvalues outside the main bulk of eigenvalues in the spectrum of ̃c, as shown in Figure 1.
",3. Main Results,[0],[0]
The eigenvectors associated to these eigenvalues often contain crucial information about the data statistics (the classes in a classification settings).,3. Main Results,[0],[0]
"In particular, note that the matrix V contains the canonical vector ja of class Ca",3. Main Results,[0],[0]
and we thus hope to find some isolated eigenvector of c aligned to ja that can be directly used to perform clustering.,3. Main Results,[0],[0]
"Intuitively speaking, if the matrix A contains sufficient energy (has sufficiently large operator norm), the eigenvalues associated to the small rank matrix VAVT may jump out from the main bulk of ⌦T⌦ and becomes “isolated” as in Figure 1, referred to as the phase transition phenomenon in the random matrix literature (Baik et al., 2005).",3. Main Results,[0],[0]
The associated eigenvectors then tend to align to linear combinations of the canonical vectors ja as seen in Figure 5-6.,3. Main Results,[0],[0]
"This alignment between the isolated eigenvectors and ja is essentially measured by the amplitude of the eigenvalues of the matrix A11, or more concretely, the statistical differences of the data (namely, t, S and M).",3. Main Results,[0],[0]
"Therefore, a good adaptation of the ratio d1/d2 ensures the (asymptotic) detectability of different classes from the spectrum of c.
On the Spectrum of Random Features Maps of High Dimensional Data",3. Main Results,[0],[0]
"We complete this article by showing that our theoretical results, derived from Gaussian mixture models, show an unexpected close match in practice when applied to some real-world datasets.",4. Numerical Validations,[0],[0]
"We consider two different types of classification tasks: one on handwritten digits of the popular MNIST (LeCun et al., 1998) database (number 6 and 8), and the other on epileptic EEG time series data (Andrzejak et al., 2001) (set B and E).",4. Numerical Validations,[0],[0]
These two datasets are typical examples of means-dominant (handwritten digits recognition) and covariances-dominant (EEG times series classification) tasks.,4. Numerical Validations,[0],[0]
This is numerically confirmed in Table 3.,4. Numerical Validations,[0],[0]
"Python 3 codes to reproduce the results in this section are available at https://github.com/Zhenyu-LIAO/RMT4RFM.
",4. Numerical Validations,[0],[0]
Table 3.,4. Numerical Validations,[0],[0]
"Empirical estimation of (normalized) differences in means and covariances of the MNIST (Figure 7 and 8) and epileptic EEG (Figure 9 and 10) datasets.
kMTMk kttT + 2Sk MNIST DATA 172.4 86.0 EEG DATA 1.2 182.7",4. Numerical Validations,[0],[0]
"We perform random feature-based spectral clustering on data matrices that consist of T = 32, 64 and 128 randomly selected vectorized images of size p = 784 from the MNIST dataset.",4.1. Handwritten digits recognition,[0],[0]
The “true” means and covariances are empirically obtained from the full set of 11 769 MNIST images (5 918 images of number 6 and 5 851 of number 8) to construct the matrix ̃c as per Theorem 1.,4.1. Handwritten digits recognition,[0],[0]
"Comparing the matrix c built from the data and the theoretically equivalent ̃c obtained as if the data were Gaussian with the (empirically) computed means and covariances, we observe an extremely close fit in the behavior of the eigenvalues in Figure 7, as well of the leading eigenvector in Figure 8.",4.1. Handwritten digits recognition,[0],[0]
"The k-means method is then applied to the leading two eigenvectors of the matrix Gc 2 RT⇥T that consists of n = 32 random features to perform unsupervised classification, with resulting accuracies (averaged over 50 runs) reported in Table 4.",4.1. Handwritten digits recognition,[0],[0]
"As remarked from Table 3, the mean-oriented (t) functions are expected to outperform the covariance-oriented ones in this task, which is consistent with the results in Table 4.",4.1. Handwritten digits recognition,[0],[0]
"The epileptic EEG dataset5, developed by the University of Bonn, Germany, is described in (Andrzejak et al., 2001).",4.2. EEG time series classification,[0],[0]
"The dataset consists of five subsets (denoted A-E), each containing 100 single-channel EEG segments of 23.6-sec
5 http://www.meb.unibonn.de/epileptologie/
science/physik/eegdata.html.
1 2 3 4 5 6 0
0.5
1
1.5 Eigenvalues of c Eigenvalues of ̃c
1 2 3 4 5 6 0
0.5
1 1.5 Eigenvalues of c Eigenvalues of ̃c
1 2 3 4 5 6 0
0.5
1 1.5 Eigenvalues of c Eigenvalues of ̃c
Figure 7.",4.2. EEG time series classification,[0],[0]
"Eigenvalue distribution of c and ̃c for the MNIST data, with the ReLU function, p = 784, T = 128 and c1 = c2 = 12 , with j1 = ⇥ 1T1 ;0T2 ⇤ and j2 = ⇥ 0T1 ;1T2 ⇤ .",4.2. EEG time series classification,[0],[0]
"Expectation estimated by averaging over 500 realizations of W.
Leading eigenvector for MNIST data",4.2. EEG time series classification,[0],[0]
"Simulation: mean/std for MNIST data
Theory: mean/std for Gaussian data
C1 C2
Figure 8.",4.2. EEG time series classification,[0],[0]
"Leading eigenvector of c for the MNIST and Gaussian mixture data with a width of ±1 standard deviations (generated from 500 trials) in the settings of Figure 7.
duration.",4.2. EEG time series classification,[0],[0]
"Sets A and B were collected from surface EEG recordings of five healthy volunteers, while sets C, D and E were collected from the EEG records of the pre-surgical diagnosis of five epileptic patients.",4.2. EEG time series classification,[0],[0]
"Here we perform random feature-based spectral clustering on T = 32, 64 and 128 randomly picked EEG segments of length p = 100 from the dataset.",4.2. EEG time series classification,[0],[0]
Means and covariances are empirically estimated from the full set (4 097 segments of set B and 4 097 segments of set E).,4.2. EEG time series classification,[0],[0]
Similar behavior of eigenpairs as for Gaussian mixture models is once more observed in Figure 9 and 10.,4.2. EEG time series classification,[0],[0]
After k-means classification on the leading two eigenvectors of the (centered),4.2. EEG time series classification,[0],[0]
"Gram matrix composed of n = 32 random features, the accuracies (averaged over 50 runs) are reported in Table 5.
",4.2. EEG time series classification,[0],[0]
"As opposed to the MNIST image recognition task, from Table 5 it is easy to check that the covariance-oriented functions (i.e., (t) = |t|, cos(t) and exp( t2/2)) far outperform any other with almost perfect classification accuracies.",4.2. EEG time series classification,[0],[0]
"It is particularly interesting to note that the popular ReLU function is suboptimal in both tasks, but never performs very badly, thereby offering a good risk-performance tradeoff.",4.2. EEG time series classification,[0],[0]
"In this article, we have provided a theoretical analysis on random feature-based spectral algorithms for large dimensional data, providing a better understanding of the precise mechanism underlying these methods.",5. Conclusion,[0],[0]
"Our results show a quite simple relation between the nonlinear function involved in the random feature map (only through two scalars
d1 and d2) and the capacity of the latter to discriminate data upon their means and covariances.",5. Conclusion,[0],[0]
"In obtaining this result, we demonstrated that point-wise nonlinearities can be incorporated into a classical Taylor expansion as a consequence of the concentration phenomenon in high dimensional space.",5. Conclusion,[0],[0]
"This result was then validated through experimental classification tasks on the MNIST and EEG datasets.
",5. Conclusion,[0],[0]
"Although Theorem 1 is stated here solely for the functions listed in Table 1, our current line of investigation consists in directly linking the activation function (·) and the coefficients d0, d1 and d2 in Table 2 so as to generalize our results and to provide more insights into the attributes of a function that makes it mean- or covariance-oriented; this undertaking is however more technically demanding but still likely achievable through the extension of existing results related to the work of (Cheng & Singer, 2013).
",5. Conclusion,[0],[0]
"From a point of view of clustering, the crucial information to distinguish different classes is contained in the isolated eigenvalue/eigenvector pairs as shown in (2), the asymptotic behavior of these pairs, as well as their significance for clustering are technically reachable within the analysis framework presented in this paper.",5. Conclusion,[0],[0]
"When W follows a non-Gaussian distribution, or when different nonlinearities are combined (e.g., cos+ sin to get the Gaussian kernel (Rahimi & Recht, 2008)), obtaining the equivalent kernel in the large p, T regime would be a key enabler to gain a deeper understanding under these more elaborate settings.
",5. Conclusion,[0],[0]
"Besides, this paper can be taken as a first step of the random matrix-based understanding of various learning methods using random features, for example the randomly designed deep neural networks (Lillicrap et al., 2016), the nonlinear activation of which being the main difficulty for a thorough analysis.",5. Conclusion,[0],[0]
"Moreover, along with recent advances in random matrix analysis (Tiomoko Ali & Couillet, 2016), the hyperparameter d1/d2 of utmost importance envisions to be consistently estimated and thus allows for an efficient tuning technique for all nonlinear random feature-based methods.",5. Conclusion,[0],[0]
We thank the anonymous reviewers for their comments and constructive suggestions.,Acknowledgments,[0],[0]
We would like to acknowledge this work is supported by the ANR Project RMT4GRAPH (ANR-14-CE28-0006) and the Project DeepRMT of La Fondation Supélec.,Acknowledgments,[0],[0]
"Random feature maps are ubiquitous in modern statistical machine learning, where they generalize random projections by means of powerful, yet often difficult to analyze nonlinear operators.",abstractText,[0],[0]
"In this paper, we leverage the “concentration” phenomenon induced by random matrix theory to perform a spectral analysis on the Gram matrix of these random feature maps, here for Gaussian mixture models of simultaneously large dimension and size.",abstractText,[0],[0]
"Our results are instrumental to a deeper understanding on the interplay of the nonlinearity and the statistics of the data, thereby allowing for a better tuning of random featurebased techniques.",abstractText,[0],[0]
On the Spectrum of Random Features Maps of High Dimensional Data,title,[0],[0]
"The high-level organization of text can be characterized in terms of discourse relations between adjacent spans of text (Knott, 1996; Mann, 1984; Webber et al., 1999).",1 Introduction,[0],[0]
"Identifying these relations has been shown to be relevant to tasks such as summarization (Louis et al., 2010a; Yoshida et al., 2014), sentiment analysis (Somasundaran et al., 2009), coherence evaluation (Lin et al., 2011), and question answering (Jansen et al., 2014).",1 Introduction,[0],[0]
"While the Penn Discourse Treebank (PDTB) now provides a large dataset annotated for discourse relations (Prasad et al., 2008), the automatic identification of implicit relations is a difficult task, with state-of-the-art performance at roughly 40% (Lin et al., 2009).
",1 Introduction,[0],[0]
"One reason for this poor performance is that discourse relations are rooted in semantics (Forbes-
Riley et al., 2006), which can be difficult to recover from surface level features.",1 Introduction,[0],[0]
"Consider the implicit discourse relation between the following two sentences (also shown in Figure 1a):
(1) Bob gave Tina the burger.",1 Introduction,[0],[0]
"She was hungry.
",1 Introduction,[0],[0]
"While a connector like because seems appropriate here, there is little surface information to signal this relationship, unless the model has managed to learn a bilexical relationship between burger and hungry.",1 Introduction,[0],[0]
"Learning all such relationships from annotated data — including the relationship of hungry to knish, pierogie, pupusa etc — would require far more data than can possibly be annotated.
329
Transactions of the Association for Computational Linguistics, vol. 3, pp. 329–344, 2015.",1 Introduction,[0],[0]
Action Editor: Alexander Koller.,1 Introduction,[0],[0]
"Submission batch: 12/2014; Revision batch 3/2015; Revision batch 4/2015; Published 6/2015.
",1 Introduction,[0],[0]
c©2015 Association for Computational Linguistics.,1 Introduction,[0],[0]
"Distributed under a CC-BY-NC-SA 4.0 license.
",1 Introduction,[0],[0]
"We address this issue by applying a discriminatively-trained model of compositional distributed semantics to discourse relation classification (Socher et al., 2013; Baroni et al., 2014a).",1 Introduction,[0],[0]
"The meaning of each discourse argument is represented as a vector (Turney and Pantel, 2010), which is computed through a series of bottom-up compositional operations over the syntactic parse tree.",1 Introduction,[0],[0]
The discourse relation can then be predicted as a bilinear combination of these vector representations.,1 Introduction,[0],[0]
"Both the prediction matrix and the compositional operator are trained in a supervised large-margin framework (Socher et al., 2011), ensuring that the learned compositional operation produces semantic representations that are useful for discourse.",1 Introduction,[0],[0]
"We show that when combined with a small number of surface features, this approach outperforms prior work on the classification of implicit discourse relations in the PDTB.
",1 Introduction,[0],[0]
"Despite these positive results, we argue that bottom-up vector-based representations of discourse arguments are insufficient to capture their relations.",1 Introduction,[0],[0]
"To see why, consider what happens if we make a tiny change to example (1):
(2) Bob gave Tina the burger.",1 Introduction,[0],[0]
"He was hungry.
",1 Introduction,[0],[0]
"After changing the subject of the second sentence to Bob, the connective “because” no longer seems appropriate; a contrastive connector like although is preferred.",1 Introduction,[0],[0]
"But despite the radical difference in meaning, the bottom-up distributed representation of the second sentence will be almost unchanged: the syntactic structure remains identical, and the words he and she have very similar word representations (see Figure 2).",1 Introduction,[0],[0]
"If we
reduce each discourse argument span to a single vector, built from the elements in the argument itself, we cannot possibly capture the ways that discourse relations are signaled by entities and their roles (Cristea et al., 1998; Louis et al., 2010b).",1 Introduction,[0],[0]
"As Mooney (2014) puts it, “you can’t cram the meaning of a whole %&!$# sentence into a single $&!#* vector!”
",1 Introduction,[0],[0]
"We address this issue by computing vector representations not only for each discourse argument, but also for each coreferent entity mention.",1 Introduction,[0],[0]
"These representations are meant to capture the role played by the entity in the text, and so they must take the entire span of text into account.",1 Introduction,[0],[0]
"We compute entity-role representations using a feed-forward compositional model, which combines “upward” and “downward” passes through the syntactic structure, shown in Figure 1b.",1 Introduction,[0],[0]
"In the example, the downward representations for Tina and she are computed from a combination of the parent and sibling nodes in the binarized parse tree.",1 Introduction,[0],[0]
"Representations for these coreferent mentions are then combined in a bilinear product, and help to predict the implicit discourse relation.",1 Introduction,[0],[0]
"In example (2), we resolve he to Bob, and combine their vector representations instead, yielding a different prediction about the discourse relation.
",1 Introduction,[0],[0]
"Our overall approach combines surface features, distributed representations of discourse arguments, and distributed representations of entity mentions.",1 Introduction,[0],[0]
"It achieves a 4% improvement in accuracy over the best previous work (Lin et al., 2009) on multiclass discourse relation classification, and also outperforms more recent work on binary classification.",1 Introduction,[0],[0]
"The novel entity-augmented distributed representation improves accuracy over the “upward” compositional model, showing the importance of representing the meaning of coreferent entity mentions.",1 Introduction,[0],[0]
"We now formally define our approach to entityaugmented distributed semantics, using the notation shown in Table 1.",2 Entity augmented distributed semantics,[0],[0]
"For clarity of exposition, we focus on discourse relations between pairs of sentences.",2 Entity augmented distributed semantics,[0],[0]
The extension to non-sentence arguments is discussed in Section 5.,2 Entity augmented distributed semantics,[0],[0]
"Distributed representations for discourse arguments are computed in a feed-forward “upward” pass: each non-terminal in the binarized syntactic parse tree has a K-dimensional vector representation that is computed from the representations of its children, bottoming out in pre-trained representations of individual words.
",2.1 Upward pass: argument semantics,[0],[0]
We follow the Recursive Neural Network (RNN) model of Socher et al. (2011).,2.1 Upward pass: argument semantics,[0],[0]
"For a given parent node i, we denote the left child as `(i), and the right child as r(i); we compose their representations to obtain,
ui = tanh ( U[u`(i);ur(i)] ) , (1)
where tanh (·) is the element-wise hyperbolic tangent function (Pascanu et al., 2012), and U ∈ RK×2K is the upward composition matrix.",2.1 Upward pass: argument semantics,[0],[0]
"We apply this compositional procedure from the bottom up, ultimately obtaining the argument-level representation u0.",2.1 Upward pass: argument semantics,[0],[0]
"The base case is found at the leaves of the tree, which are set equal to pre-trained word vector representations.",2.1 Upward pass: argument semantics,[0],[0]
"For example, in the second sentence of Figure 1, we combine the word representations of was and hungry to obtain u(r)1 , and then combine u(r)1 with the word representation of she to obtain u(r)0 .",2.1 Upward pass: argument semantics,[0],[0]
"Note that the upward pass is feedforward, meaning that there are no cycles and all nodes can be computed in linear time.",2.1 Upward pass: argument semantics,[0],[0]
"As seen in the contrast between Examples 1 and 2, a model that uses a bottom-up vector representa-
tion for each discourse argument would find little to distinguish between she was hungry and he was hungry.",2.2 Downward pass: entity semantics,[0],[0]
"It would therefore almost certainly fail to identify the correct discourse relation for at least one of these cases, which requires tracking the roles played by the entities that are coreferent in each pair of sentences.",2.2 Downward pass: entity semantics,[0],[0]
"To address this issue, we augment the representation of each argument with additional vectors, representing the semantics of the role played by each coreferent entity in each argument.",2.2 Downward pass: entity semantics,[0],[0]
"For example, in (1a), Tina got the burger, and in (1b), she was hungry.",2.2 Downward pass: entity semantics,[0],[0]
"Rather than represent this information in a logical form — which would require robust parsing to a logical representation — we represent it through additional distributed vectors.
",2.2 Downward pass: entity semantics,[0],[0]
"The role of a constituent i can be viewed as a combination of information from two neighboring nodes in the parse tree: its parent ρ(i), and its sibling s(i).",2.2 Downward pass: entity semantics,[0],[0]
"We can make a downward pass, computing the downward vector di from the downward vector of the parent dρ(i), and the upward vector of the sibling us(i):
di = tanh ( V[dρ(i);us(i)] ) , (2)
where V ∈ RK×2K is the downward composition matrix.",2.2 Downward pass: entity semantics,[0],[0]
"The base case of this recursive procedure occurs at the root of the parse tree, which is set equal to the upward representation, d0 , u0.",2.2 Downward pass: entity semantics,[0],[0]
"This procedure is illustrated in Figure 1b: for Tina, the parent node is d(`)2 , and the sibling is u (`) 3 .
",2.2 Downward pass: entity semantics,[0],[0]
This up-down compositional algorithm propagates sentence-level distributed semantics back to entity mentions.,2.2 Downward pass: entity semantics,[0],[0]
"The representation of each mention’s role in the sentence is based on the corresponding role of the parent node in the parse tree, and on the internal meaning representation of the sibling node, which is computed by upward composition.",2.2 Downward pass: entity semantics,[0],[0]
"Note that this algorithm is designed to maintain the feedforward nature of the neural network, so that we can efficiently compute all nodes without iterating.",2.2 Downward pass: entity semantics,[0],[0]
"Each downward node di influences only other downward nodes dj where j > i, meaning that the downward pass is feedforward.",2.2 Downward pass: entity semantics,[0],[0]
"The upward node is also feedforward: each upward node ui influences only other upward nodes uj where j < i. Since the upward and downward passes are each feedforward, and the downward nodes do not influence any upward nodes, the combined up-down network is also feedforward.",2.2 Downward pass: entity semantics,[0],[0]
"This ensures that we can efficiently com-
pute all ui and di in time that is linear in the length of the input.",2.2 Downward pass: entity semantics,[0],[0]
"In Section 7.2, we compare our approach with recent related work on alternative two-pass distributed compositional models.
",2.2 Downward pass: entity semantics,[0],[0]
"Connection to the inside-outside algorithm In the inside-outside algorithm for computing marginal probabilities in a probabilistic contextfree grammar (Lari and Young, 1990), the inside scores are constructed in a bottom-up fashion, like our upward nodes; the outside score for node i is constructed from a product of the outside score of the parent ρ(i) and the inside score of the sibling s(i), like our downward nodes.",2.2 Downward pass: entity semantics,[0],[0]
"The standard inside-outside algorithm sums over all possible parse trees, but since the parse tree is observed in our case, a closer analogy would be to the constrained version of the inside-outside algorithm for latent variable grammars (Petrov et al., 2006).",2.2 Downward pass: entity semantics,[0],[0]
"Cohen et al. (2014) describe a tensor formulation of the constrained inside-outside algorithm; similarly, we could compute the downward vectors by a tensor contraction of the parent and sibling vectors (Smolensky, 1990; Socher et al., 2014).",2.2 Downward pass: entity semantics,[0],[0]
"However, this would involve K3 parameters, rather than the K2 parameters in our matrixvector composition.",2.2 Downward pass: entity semantics,[0],[0]
"To predict the discourse relation between an argument pair (m,n), the decision function is a sum of bilinear products,
ψ(y) =",3 Predicting discourse relations,[0],[0]
(u (m) 0 ),3 Predicting discourse relations,[0],[0]
>,3 Predicting discourse relations,[0],[0]
"Ayu (n) 0
+ ∑
i,j∈A(m,n) (d
(m) i ) >",3 Predicting discourse relations,[0],[0]
"Byd (n) j + by, (3)
where",3 Predicting discourse relations,[0],[0]
Ay ∈ RK×K and By ∈ RK×K are the classification parameters for,3 Predicting discourse relations,[0],[0]
relation y.,3 Predicting discourse relations,[0],[0]
"A scalar by is used as the bias term for relation y, andA(m,n) is the set of coreferent entity mentions shared by the argument pair (m,n).",3 Predicting discourse relations,[0],[0]
"The decision value ψ(y) of relation y is therefore based on the upward vectors at the root, u(m)0 and u (n) 0 , as well as on the downward vectors for each pair of aligned entity mentions.",3 Predicting discourse relations,[0],[0]
"For the cases where there are no coreferent entity mentions between two sentences, A(m,n) = ∅, the classification model considers only the upward vectors at the root.
",3 Predicting discourse relations,[0],[0]
"To avoid overfitting, we apply a lowdimensional approximation to each Ay,
Ay = ay,1a > y,2 + diag(ay,3).",3 Predicting discourse relations,[0],[0]
"(4)
The same approximation is also applied to each By, reducing the number of classification parameters from 2×#|Y| ×K2 to 2×#|Y| × 3K. Surface features Prior work has identified a number of useful surface-level features (Lin et al., 2009), and the classification model can easily be extended to include them.",3 Predicting discourse relations,[0],[0]
"Defining φ(m,n) as the vector of surface features extracted from the argument pair (m,n), the corresponding decision function is modified as,
ψ(y) =",3 Predicting discourse relations,[0],[0]
(u (m) 0 ),3 Predicting discourse relations,[0],[0]
>,3 Predicting discourse relations,[0],[0]
Ayu (n) 0,3 Predicting discourse relations,[0],[0]
"+
∑
i,j∈A(m,n)",3 Predicting discourse relations,[0],[0]
"(d
(m) i ) >",3 Predicting discourse relations,[0],[0]
"Byd (n) j
+ β>y φ(m,n) + by,
(5) where βy is the classification weight on surface features for relation y.",3 Predicting discourse relations,[0],[0]
We describe these features in Section 5.,3 Predicting discourse relations,[0],[0]
"There are two sets of parameters to be learned: the classification parameters θclass = {Ay,By,βy, by}y∈Y , and the composition parameters θcomp = {U,V}.",4 Large-margin learning framework,[0],[0]
"We use pre-trained word representations, and do not update them.",4 Large-margin learning framework,[0],[0]
"While prior work shows that it can be advantageous to retrain word representations for discourse analysis (Ji and Eisenstein, 2014), our preliminary experiments found that updating the word representations led to serious overfitting in this model.
",4 Large-margin learning framework,[0],[0]
"Following Socher et al. (2011), we define a large margin objective, and use backpropagation to learn all parameters of the network jointly (Goller and Kuchler, 1996).",4 Large-margin learning framework,[0],[0]
"Learning is performed using stochastic gradient descent (Bottou, 1998), so we present the learning problem for a single argument pair (m,n) with the gold discourse relation y∗.",4 Large-margin learning framework,[0],[0]
"The objective function for this training example is a regularized hinge loss,
L(θ) = ∑
y′:y′ 6=y∗ max
( 0, 1− ψ(y∗) + ψ(y′) )",4 Large-margin learning framework,[0],[0]
"+ λ||θ||22
(6) where θ = θclass ∪ θcomp is the set of learning parameters.",4 Large-margin learning framework,[0],[0]
"The regularization term λ||θ||22 indicates that the squared values of all parameters are penalized by λ; this corresponds to penalizing the
squared Frobenius norm for the matrix parameters, and the squared Euclidean norm for the vector parameters.",4 Large-margin learning framework,[0],[0]
"In Equation 6, L(θ) = 0, if for every y′ 6= y∗, ψ(y∗)",4.1 Learning the classification parameters,[0],[0]
− ψ(y′) ≥ 1 holds.,4.1 Learning the classification parameters,[0],[0]
"Otherwise, the loss will be caused by any y′, where y′ 6= y∗ and ψ(y∗)",4.1 Learning the classification parameters,[0],[0]
− ψ(y′) < 1.,4.1 Learning the classification parameters,[0],[0]
The gradient for the classification parameters therefore depends on the margin value between gold label and all other labels.,4.1 Learning the classification parameters,[0],[0]
"Specifically, taking one component of Ay, ay,1, as an example, the derivative of the objective for y = y∗ is
∂L(θ) ∂ay∗,1",4.1 Learning the classification parameters,[0],[0]
"= − ∑
y′:y′ 6=y∗ δ(ψ(y∗)−ψ(y′)<1) · u(m)0 , (7)
where δ(·) is the delta function.",4.1 Learning the classification parameters,[0],[0]
The derivative for y′ 6=,4.1 Learning the classification parameters,[0],[0]
"y∗ is
∂L(θ) ∂ay′,1 = δ(ψ(y∗)−ψ(y′)<1) · u(m)0 (8)
During learning, the updating rule for Ay is
Ay ←",4.1 Learning the classification parameters,[0],[0]
"Ay − η(∂L(θ) ∂Ay + λAy) (9)
where η is the learning rate.",4.1 Learning the classification parameters,[0],[0]
"Similarly, we can obtain the gradient information and updating rules for parameters {By,βy, by}y∈Y .",4.1 Learning the classification parameters,[0],[0]
"There are two composition matrices U and V, corresponding to the upward and downward composition procedures respectively.",4.2 Learning the composition parameters,[0],[0]
"Taking the upward composition parameter U as an example, the derivative of L(θ) with respect to U is
∂L(θ) ∂U = ∑
y′:y′ 6=y∗ δ(ψ(y∗)−ψ(y′)<1) · (∂ψ(y′)
∂U − ∂ψ(y
∗)
∂U
) (10)
",4.2 Learning the composition parameters,[0],[0]
"As with the classification parameters, the derivative depends on the margin between y′ and y∗.
For every y ∈ Y , we have the unified derivative form,
∂ψ(y) ∂U = ∂ψ(y)
",4.2 Learning the composition parameters,[0],[0]
"∂u (m) 0
∂u (m) 0
∂U + ∂ψ(y)
∂u (n) 0
∂u (n) 0
∂U
+ ∑
i,j∈A(m,n)
∂ψ(y) ∂d (m) i
∂d (m) i
∂U
+ ∑
i,j∈A(m,n)
∂ψ(y) ∂d (n) j
∂d (n) j
∂U ,
(11)
",4.2 Learning the composition parameters,[0],[0]
"The gradient of U also depends on the gradient of ψ(y) with respect to every downward vector d, as shown in the last two terms in Equation 11.",4.2 Learning the composition parameters,[0],[0]
"This is because the computation of each downward vector di includes the upward vector of the sibling node, us(i), as shown in Equation 2.",4.2 Learning the composition parameters,[0],[0]
"For an example, see the construction of the downward vectors for Tina and she in Figure 1b.
",4.2 Learning the composition parameters,[0],[0]
"The partial derivatives of the decision function in Equation 11 are computed as,
∂ψ(y) ∂u (m) 0",4.2 Learning the composition parameters,[0],[0]
=,4.2 Learning the composition parameters,[0],[0]
"Ayu (n) 0 , ∂ψ(y)",4.2 Learning the composition parameters,[0],[0]
∂u (n) 0,4.2 Learning the composition parameters,[0],[0]
"= A>y u (m) 0 , ∂ψ(y) ∂d (m) i = Byd (n) j , ∂ψ(y)",4.2 Learning the composition parameters,[0],[0]
∂d (n),4.2 Learning the composition parameters,[0],[0]
"i = B>y d (m) j , 〈i, j〉 ∈ A. (12)
",4.2 Learning the composition parameters,[0],[0]
"The partial derivatives of the upward and downward vectors with respect to the upward compositional operator are computed as,
∂u (m) i
∂U =
∑
u (m) k",4.2 Learning the composition parameters,[0],[0]
"∈T (u(m)i )
∂u (m) i ∂u (m) k",4.2 Learning the composition parameters,[0],[0]
(u (m) k ),4.2 Learning the composition parameters,[0],[0]
>,4.2 Learning the composition parameters,[0],[0]
"(13)
and
∂d (m)",4.2 Learning the composition parameters,[0],[0]
"i
∂U =
∑
u (m)",4.2 Learning the composition parameters,[0],[0]
k,4.2 Learning the composition parameters,[0],[0]
"∈T (d(m)i )
∂d",4.2 Learning the composition parameters,[0],[0]
(m) i ∂u (m) k (u (m) k ),4.2 Learning the composition parameters,[0],[0]
">, (14)
where T (um) is the set of all nodes in the upward composition model that help to generate um.",4.2 Learning the composition parameters,[0],[0]
"For example, in Figure 1a, the set T (u(`)2 ) includes u (`) 3 and the word representations for Tina, the, and burger.",4.2 Learning the composition parameters,[0],[0]
"The set T (dm,i) includes all the upward nodes involved in the downward composition model generating d(m)i .",4.2 Learning the composition parameters,[0],[0]
"For example, in Figure 1b, the set T (d(r)she) includes u (r) 1 and the word representations for was and hungry.",4.2 Learning the composition parameters,[0],[0]
"The derivative of the objective with respect to the downward compositional operator V is computed in a similar fashion, but it depends only on the downward nodes, d(m)i .",4.2 Learning the composition parameters,[0],[0]
Our implementation is available online at https://github.com/jiyfeng/ updown.,5 Implementation,[0],[0]
"Training on the PDTB takes roughly three hours to converge, on an Intel(R) Xeon(R) CPU 2.20GHz without parallel computing.",5 Implementation,[0],[0]
Convergence is faster if the surface feature weights β are trained separately first.,5 Implementation,[0],[0]
"We now describe some additional details of our implementation.
",5 Implementation,[0],[0]
"Learning During learning, we used AdaGrad (Duchi et al., 2011) to tune the learning rate in each iteration.",5 Implementation,[0],[0]
"To avoid the exploding gradient problem (Bengio et al., 1994), we used the norm clipping trick proposed by Pascanu et al. (2012), fixing the norm threshold at τ = 5.0.
",5 Implementation,[0],[0]
"Hyperparameters Our model includes three tunable hyperparameters: the latent dimension K for the distributed representation, the regularization parameter λ, and the initial learning rate η.",5 Implementation,[0],[0]
All hyperparameters are tuned by randomly selecting a development set of 20% of the training data.,5 Implementation,[0],[0]
"We consider the values K ∈ {20, 30, 40, 50, 60} for the latent dimensionality, λ ∈ {0.0002, 0.002, 0.02, 0.2} for the regularization (on each training instance), and η ∈ {0.01, 0.03, 0.05, 0.09} for the learning rate.",5 Implementation,[0],[0]
"We assign separate regularizers and learning rates to the upward composition model, downward composition model, feature model and the classification model with composition vectors.
",5 Implementation,[0],[0]
Initialization All the classification parameters are initialized to 0.,5 Implementation,[0],[0]
"For the composition parameters, we follow Bengio (2012) and initialize U and V with uniform random values drawn from the range",5 Implementation,[0],[0]
"[− √ 6/2K, √ 6/2K].
",5 Implementation,[0],[0]
"Word representations We trained a word2vec model (Mikolov et al., 2013) on the PDTB corpus, standardizing the induced representations to zeromean, unit-variance (LeCun et al., 2012).",5 Implementation,[0],[0]
"Experiments with pre-trained GloVe word vector representations (Pennington et al., 2014) gave broadly similar results.
",5 Implementation,[0],[0]
Syntactic structure Our model requires that the syntactic structure for each argument is represented as a binary tree.,5 Implementation,[0],[0]
"We run the Stanford parser (Klein and Manning, 2003) to obtain constituent parse trees of each sentence in the PDTB, and binarize all resulting parse trees.",5 Implementation,[0],[0]
"Argument spans in the Penn Discourse Treebank need not be sentences or syntactic constituents: they can include multiple sentences, non-constituent spans, and even discontinuous spans (Prasad et al., 2008).",5 Implementation,[0],[0]
"In all cases, we identify the syntactic subtrees within the argument span, and unify them in a right branching superstructure.
",5 Implementation,[0],[0]
Coreference,5 Implementation,[0],[0]
"The impact of entity semantics on discourse relation detection is inherently limited by two factors: (1) the frequency with which the
arguments of a discourse relation share coreferent entity mentions, and (2) the ability of automated coreference resolution systems to detect these coreferent mentions.",5 Implementation,[0],[0]
"To extract entities and their mentions from the PDTB, we ran the Berkeley coreference system (Durrett and Klein, 2013) on each document.",5 Implementation,[0],[0]
"For each argument pair, we simply ignore the non-corefential entity mentions.",5 Implementation,[0],[0]
"Line 1 in Table 2 shows the proportion of the instances with shared entities in the PDTB training and test data, as detected by the Berkeley system.",5 Implementation,[0],[0]
"As the system does not detect coreferent mentions in more than 70% of the cases, the performance improvements offered by distributed entity semantics are therefore limited.",5 Implementation,[0],[0]
"To determine whether this low rate of coreference is an intrinsic property of the data, or whether it is due to the quality of state-of-the-art coreference resolution, we also consider the gold coreference annotations in the OntoNotes corpus (Pradhan et al., 2007), a portion of which intersects with the PDTB (597 documents).",5 Implementation,[0],[0]
Lines 2 and 3 of Table 2 give the statistics for automatic and gold coreference on this intersection.,5 Implementation,[0],[0]
"These results indicate that with perfect coreference resolution, the applicability of distributed entity semantics would reach 40% of the training set and nearly 50% of the test set.",5 Implementation,[0],[0]
"Thus, improvements in coreference resolution can be expected to yield further improvements in the effectiveness of distributed entity semantics for discourse relation detection.
",5 Implementation,[0],[0]
Additional features We supplement our classification model using additional surface features proposed by Lin et al. (2009).,5 Implementation,[0],[0]
"These include four categories: word pair features, constituent parse features, dependency parse features, and contextual features.",5 Implementation,[0],[0]
"As done in this prior work, we use mutual information to select features in the first three categories, obtaining 500 word pair features, 100 constituent features, and 100 dependency features.",5 Implementation,[0],[0]
"In addition, Rutherford and Xue (2014) discovered that replacing word pair with their Brown
cluster assignments could give further improvements.",5 Implementation,[0],[0]
"In our implementation, we used the Brown word clusters provided by Turian et al. (2010), in which words from the Reuters Corpus (RCV1) are grouped into 3,200 clusters.",5 Implementation,[0],[0]
The feature selection method of Lin et al. (2009) was then used to obtain a set of 600 Brown cluster features.,5 Implementation,[0],[0]
"We evaluate our approach on the Penn Discourse Treebank (PDTB; Prasad et al., 2008), which provides a discourse level annotation over the Wall Street Journal corpus.",6 Experiments,[0],[0]
"In the PDTB, each discourse relation is annotated between two argument spans.",6 Experiments,[0],[0]
"Identifying the argument spans of discourse relations is a challenging task (Lin et al., 2012), which we do not attempt here; instead, we use gold argument spans, as in most of the relevant prior work.",6 Experiments,[0],[0]
"PDTB relations may be explicit, meaning that they are signaled by discourse connectives (e.g., because); alternatively, they may be implicit, meaning that the connective is absent.",6 Experiments,[0],[0]
"Pitler et al. (2008) show that most explicit connectives are unambiguous, so we focus on the problem of classifying implicit discourse relations.
",6 Experiments,[0],[0]
The PDTB provides a three-level hierarchy of discourse relations.,6 Experiments,[0],[0]
"The first level consists of four major relation classes: TEMPORAL, CONTINGENCY, COMPARISON and EXPANSION.",6 Experiments,[0],[0]
"For each class, a second level of types is defined to provide finer semantic or pragmatic distinctions; there are sixteen such relation types.",6 Experiments,[0],[0]
"A third level of subtypes is defined for only some types, specifying the semantic contribution of each argument.
",6 Experiments,[0],[0]
There are two main approaches to evaluating implicit discourse relation classification.,6 Experiments,[0],[0]
Multiclass classification requires identifying the discourse relation from all possible choices.,6 Experiments,[0],[0]
"This task was explored by Lin et al. (2009), who focus on second-level discourse relations.",6 Experiments,[0],[0]
"More recent work has emphasized binary classification, where the goal is to build and evaluate separate “one-versus-all” classifiers for each discourse relation (Pitler et al., 2009; Park and Cardie, 2012; Biran and McKeown, 2013).",6 Experiments,[0],[0]
"We primarily focus on multiclass classification, because it is more relevant for the ultimate goal of building a PDTB parser; however, to compare with recent prior work, we also evaluate on binary relation classification.",6 Experiments,[0],[0]
"Our main evaluation involves predicting the correct discourse relation for each argument pair, from among the second-level relation types.",6.1 Multiclass classification,[0],[0]
"The training and test set construction follows Lin et al. (2009) with a few changes:
• We use sections 2-20 of the PDTB as a training set, sections 0-1 as a development set for parameter tuning, and sections 21-22 for testing.
",6.1 Multiclass classification,[0],[0]
"• Five relation types have a combined total of only nine instances in the training set, and are therefore excluded by Lin et al. (2009): CONDITION, PRAGMATIC CONDITION, PRAGMATIC CONTRAST, PRAGMATIC CONCESSION and EXCEPTION.",6.1 Multiclass classification,[0],[0]
None of these relations appear in the test or development data.,6.1 Multiclass classification,[0],[0]
"We tried training with and without these relation types in the training data, and found no difference in the overall results.
",6.1 Multiclass classification,[0],[0]
"• In the main multiclass experiment, we consider only the problem of distinguishing between implicit relations.",6.1 Multiclass classification,[0],[0]
"We perform an additional, reviewer-recommended experiment that distinguishes implicit relations from entity-based coherence relations, labeled ENTREL.",6.1 Multiclass classification,[0],[0]
"See below for more detail.
",6.1 Multiclass classification,[0],[0]
• Roughly 2% of the implicit relations in the PDTB are annotated with more than one type.,6.1 Multiclass classification,[0],[0]
"During training, each argument pair that is annotated with two relation types is considered as two training instances, each with one relation type.",6.1 Multiclass classification,[0],[0]
"During testing, if the classifier assigns either of the two types, it is considered to be correct.",6.1 Multiclass classification,[0],[0]
"Most common class The most common class is
CAUSE, accounting for 26.03% of the implicit discourse relations in the PDTB test set.
",6.1.1 Baseline and competitive systems,[0],[0]
Additive word representations Blacoe and Lapata (2012) show that simply adding word vectors can perform surprisingly well at assessing the meaning of short phrases.,6.1.1 Baseline and competitive systems,[0],[0]
"In this baseline, we represent each argument as a sum of its word representations, and estimate a bilinear prediction matrix.
",6.1.1 Baseline and competitive systems,[0],[0]
Lin et al. (2009),6.1.1 Baseline and competitive systems,[0],[0]
"To our knowledge, the best published accuracy on multiclass classification
of second-level implicit discourse relations is from Lin et al. (2009), who apply feature selection to obtain a set of lexical and syntactic features over the arguments.
",6.1.1 Baseline and competitive systems,[0],[0]
"Surface features + Brown clusters To get a more precise comparison, we reimplemented the system of Lin et al. (2009).",6.1.1 Baseline and competitive systems,[0],[0]
"The major differences are (1) we apply our online learning framework, rather than batch classification, and (2) we include the Brown cluster features described in Section 5 and originally proposed by Rutherford and Xue (2014).
",6.1.1 Baseline and competitive systems,[0],[0]
"Compositional Finally, we report results for the method described in this paper.",6.1.1 Baseline and competitive systems,[0],[0]
"Since it is a distributional compositional approach to discourse relations, we name it DISCO2.",6.1.1 Baseline and competitive systems,[0],[0]
Table 3 presents results for multiclass identification of second-level PDTB relations.,6.1.2 Results,[0],[0]
"As shown in lines 7 and 8, DISCO2 outperforms both baseline systems and the prior state-of-the-art (line 3).",6.1.2 Results,[0],[0]
"The strongest performance is obtained by including the entity distributed semantics, with a 4.4% improvement over the accuracy reported by Lin et al. (2009) (p < .05 by a binomial test).",6.1.2 Results,[0],[0]
We also obtain a significant improvement over the Surface Feature + Brown Cluster model.,6.1.2 Results,[0],[0]
"Because we have reimplemented this system, we can ob-
serve individual predictions, and can therefore use the sign test for statistical significance, again finding that DISCO2 is significantly better (p < .05).",6.1.2 Results,[0],[0]
"Even without entity semantics, DISCO2 significantly outperforms these competitive models from prior work.",6.1.2 Results,[0],[0]
"However, the surface features remain important, as the performance of DISCO2 is substantially worse when only the distributed representation is included.",6.1.2 Results,[0],[0]
"The latent dimension K is chosen from a development set (see Section 5), as shown in Figure 3.
",6.1.2 Results,[0],[0]
The multiclass evaluation introduced by Lin et al. (2009) focused on classification of implicit relations.,6.1.2 Results,[0],[0]
"Another question is whether it is possible to identify entity-based coherence, annotated in the PDTB as ENTREL, which is when a shared entity is the only meaningful relation that holds between two sentences (Prasad et al., 2008).",6.1.2 Results,[0],[0]
"As suggested by a reviewer, we add ENTREL to the set of possible relations, and perform an additional evaluation.",6.1.2 Results,[0],[0]
"Since this setting has not previously been considered, we cannot evaluate against published results; instead, we retrain and evaluate the following models:
• the surface feature baseline with Brown clusters, corresponding to line 4 of Table 3;
• DISCO2 with surface features but without entity semantics, corresponding to line 7 of Table 3;
• DISCO2 with surface features and entity semantics, corresponding to line 8 of Table 3.
",6.1.2 Results,[0],[0]
"As before, all parameters are tuned on a development set.",6.1.2 Results,[0],[0]
"In this evaluation, we obtain larger improvements from our approach: our full model (with entity semantics) gives 47.27% accuracy, as compared to 44.96% without entity semantics; the result for the surface feature baseline is 41.48%.",6.1.2 Results,[0],[0]
"The contribution of entity semantics is shown in Table 3 by the accuracy differences between lines 5 and 6, and between lines 7 and 8.",6.1.3 Coreference,[0],[0]
"On the subset of relations in which the arguments share at least one coreferent entity, the difference is substantially larger: the accuracy of DISCO2 is 45.7% with entity mention semantics, and 43.1% without.",6.1.3 Coreference,[0],[0]
"Considering that only 29.1% of the relations in the PDTB test set include shared entities, it therefore seems likely that a more sensitive coreference system could yield further improvements for the entity-semantics model.",6.1.3 Coreference,[0],[0]
"Indeed, gold coreference annotation on the intersection between the PDTB and the OntoNotes corpus shows that 40-50% of discourse relations involve coreferent entities (Table 2).",6.1.3 Coreference,[0],[0]
"Evaluating on just this intersection, we find that the inclusion of entity semantics yields an improvement in accuracy from 37.5% to 39.1%.",6.1.3 Coreference,[0],[0]
"Thus, while the overall improvements offered by entity mention semantics are relatively small, this is due in part to the poor recall of the state-of-the-art coreference resolution system; if coreference improved, the impact of the entity mention semantics would increase correspondingly.
",6.1.3 Coreference,[0],[0]
"A reviewer asked whether it was necessary to have the correct coreference alignment, or whether similar improvements could be obtained by com-
puting bilinear products between all pairs of noun phrases in the two discourse arguments.",6.1.3 Coreference,[0],[0]
"In fact, this strategy of aligning all entity mentions resulted in a decrease in accuracy, from 44.59 to 42.14%.",6.1.3 Coreference,[0],[0]
This is below the performance of DISCO2 without entity semantics.,6.1.3 Coreference,[0],[0]
"The following examples help highlight how entity semantics can improve the accuracy of discourse relation classification.
",6.1.4 Examples,[0],[0]
"(3) Arg 1: The drop in profit reflected, in part, continued softness in financial advertising at [The Wall Street Journal] and Barron’s magazine.",6.1.4 Examples,[0],[0]
Arg 2:,6.1.4 Examples,[0],[0]
"Ad linage at [the Journal] fell 6.1% in the third quarter.
",6.1.4 Examples,[0],[0]
(4) Arg 1:,6.1.4 Examples,[0],[0]
"[Mr. Greenberg] got out just before the 1987 crash and, to [his] regret, never went back even as the market soared.",6.1.4 Examples,[0],[0]
Arg 2:,6.1.4 Examples,[0],[0]
"This time [he]’s ready to buy in “when the panic wears off.”
",6.1.4 Examples,[0],[0]
(5) Arg 1: Half of [them]1 are really scared and want to sell but [I]2’m trying to talk them out of it.,6.1.4 Examples,[0],[0]
Arg 2:,6.1.4 Examples,[0],[0]
"If [they]1 all were bullish, [I]2’d really be upset.
",6.1.4 Examples,[0],[0]
"In example (3), the entity-augmented model correctly identifies the relation as RESTATEMENT, due in part to the detected coreference between The Wall Street Journal and the Journal: in both arguments, the entity experiences a drop in profits.",6.1.4 Examples,[0],[0]
"Without this information, DISCO2 incorrectly labels this relation as CAUSE.",6.1.4 Examples,[0],[0]
"In example (4), the entity-augmented model correctly identifies the relation as CONTRAST, which is reasonable given the very different role of the shared entity Mr. Greenberg in the two arguments; without entity semantics, it is classified as CONJUNCTION.",6.1.4 Examples,[0],[0]
"Example (5) is more complex because it involves two entities, but again, the CONTRAST relation is correctly detected, in part because of the differing experiences of the two entities in the two arguments; without entity semantics, this example is again incorrectly classified as CONJUNCTION.",6.1.4 Examples,[0],[0]
"Much of the recent work in PDTB relation detection has focused on binary classification, building
and evaluating separate one-versus-all classifiers for each relation type (Pitler et al., 2009; Park and Cardie, 2012; Biran and McKeown, 2013).",6.2 Binary classification,[0],[0]
"This work has focused on recognition of the four firstlevel relations, grouping ENTREL with the EXPANSION relation.",6.2 Binary classification,[0],[0]
"We follow this evaluation approach as closely as possible, using sections 2-20 of the PDTB as a training set, sections 0-1 as a development set for parameter tuning, and sections 21-22 for testing.",6.2 Binary classification,[0],[0]
We apply DISCO2 with entity-augmented semantics and the surface features listed in Section 5; this corresponds to the system reported in line 8 of Table 3.,6.2.1 Classification method,[0],[0]
"However, instead of employing a multiclass classifier for all four relations, we train four binary classifiers, one for each first-level discourse relation.",6.2.1 Classification method,[0],[0]
"We optimize the hyperparametersK,λ, η separately for each classifier (see Section 5 for details), by performing a grid search to optimize the F-measure on the development data.",6.2.1 Classification method,[0],[0]
"Following Pitler et al. (2009), we obtain a balanced training set by resampling training instances in each class until the number of positive and negative instances are equal.",6.2.1 Classification method,[0],[0]
"We compare against the published results from several competitive systems, focusing on systems which use the predominant training / test split, with sections 2-20 for training and 21-22 for testing.",6.2.2 Competitive systems,[0],[0]
"This means we cannot compare with recent work from Li and Nenkova (2014), who use sections 20-24 for testing.
",6.2.2 Competitive systems,[0],[0]
"Pitler et al. (2009) present a classification model using linguistically-informed features, such as polarity tags and Levin verb classes.
",6.2.2 Competitive systems,[0],[0]
"Zhou et al. (2010) predict discourse connective words, and then use these predicted connectives as features in a downstream model to predict relations.
",6.2.2 Competitive systems,[0],[0]
"Park and Cardie (2012) showed that the performance on each relation can be improved by selecting a locally-optimal feature set.
",6.2.2 Competitive systems,[0],[0]
"Biran and McKeown (2013) reweight word pair features using distributional statistics from the Gigaword corpus, obtaining denser aggregated score features.",6.2.2 Competitive systems,[0],[0]
Table 4 presents the performance of the DISCO2 model and the published results of competitive systems.,6.2.3 Experimental results,[0],[0]
"DISCO2 achieves the best results on most metrics, achieving F-measure improvements of 4.14% on COMPARISON, 2.96% on CONTINGENCY, 0.8% on EXPANSION, and 1.06% on TEMPORAL.",6.2.3 Experimental results,[0],[0]
"These results are attained without performing per-relation feature selection, as in prior work.",6.2.3 Experimental results,[0],[0]
"While computing significance over F-measures is challenging, we can compute statistical significance on the accuracy results by using the binomial test.",6.2.3 Experimental results,[0],[0]
"We find that DISCO2 is significantly more accurate than all other systems on the CONTINGENCY and TEMPORAL relations p .001, not significantly more accurate on the EXPANSION relation, and significantly less accurate than the Park and Cardie (2012) system on the COMPARISON relation at p .001.",6.2.3 Experimental results,[0],[0]
This paper draws on previous work in discourse relation detection and compositional distributed semantics.,7 Related Work,[0],[0]
"Many models of discourse structure focus on relations between spans of text (Knott, 1996), including rhetorical structure theory (RST; Mann and Thompson, 1988), lexicalized tree-adjoining grammar for discourse (D-LTAG; Webber, 2004), and even centering theory (Grosz et al., 1995), which posits relations such as CONTINUATION and SMOOTH SHIFT between adjacent spans.",7.1 Discourse relations,[0],[0]
"Consequently, the automatic identification of discourse relations has long been considered a key component of discourse parsing (Marcu, 1999).",7.1 Discourse relations,[0],[0]
"We work within the D-LTAG framework, as annotated in the Penn Discourse Treebank (PDTB; Prasad et al., 2008), with the task of identifying implicit discourse relations.",7.1 Discourse relations,[0],[0]
The seminal work in this task is from Pitler et al. (2009) and Lin et al. (2009).,7.1 Discourse relations,[0],[0]
"Pitler et al. (2009) focus on lexical features, including linguistically motivated word groupings such as Levin verb classes and polarity tags.",7.1 Discourse relations,[0],[0]
"Lin et al. (2009) identify four different feature categories, based on the raw text, the context, and syntactic parse trees; the same feature sets are used in later work on end-to-end discourse parsing (Lin et al., 2012), which also includes components for identifying argument spans.",7.1 Discourse relations,[0],[0]
"Subsequent
research has explored feature selection (Park and Cardie, 2012; Lin et al., 2012), as well as combating feature sparsity by aggregating features (Biran and McKeown, 2013).",7.1 Discourse relations,[0],[0]
"Our model includes surface features that are based on a reimplementation of the work of Lin et al. (2009), because they also undertake the task of multiclass relation classification; however, the techniques introduced in more recent research may also be applicable and complementary to the distributed representation that constitutes the central contribution of this paper; if so, applying these techniques could further improve performance.
",7.1 Discourse relations,[0],[0]
Our contribution of entity-augmented distributed semantics is motivated by the intuition that entities play a central role in discourse structure.,7.1 Discourse relations,[0],[0]
"Centering theory draws heavily on referring expressions to entities over the discourse (Grosz et al., 1995; Barzilay and Lapata, 2008); similar ideas have been extended to rhetorical structure theory (Corston-Oliver, 1998; Cristea et al., 1998).",7.1 Discourse relations,[0],[0]
"In the specific case of PDTB relations, Louis et al. (2010b) explore a number of entity-based features, including grammatical role, syntactic realization, and information status.",7.1 Discourse relations,[0],[0]
"Despite the solid linguistic foundation for these features, they are shown to contribute little in comparison with more traditional word-pair features.",7.1 Discourse relations,[0],[0]
"This suggests that syntax and information status may not be enough, and that it is crucial to capture the semantics of each entity’s role in the discourse.",7.1 Discourse relations,[0],[0]
"Our approach does this by propagating distributed semantics from throughout the sentence into the entity span, using our up-down compositional procedure.",7.1 Discourse relations,[0],[0]
"In recent work, Rutherford and Xue (2014) take an alternative approach, using features that represent whether coreferent mentions are argu-
ments of similar predicates (using Brown clusters); they obtain nearly a 1% improvement on CONTINGENCY relations but no significant improvement on the other three first-level relation types.",7.1 Discourse relations,[0],[0]
"Finally, Kehler and Rohde (2013) show that information also flows in the opposite direction, from discourse relations to coreference: in some cases, knowing the discourse relation is crucial to resolving pronoun ambiguity.",7.1 Discourse relations,[0],[0]
Future work should therefore consider joint models of discourse analysis and coreference resolution.,7.1 Discourse relations,[0],[0]
"Distributional semantics begins with the hypothesis that words and phrases that tend to appear in the same contexts have the same meaning (Firth, 1957).",7.2 Compositional distributed semantics,[0],[0]
"The current renaissance of interest in distributional and distributed semantics can be attributed in part to the application of discriminative techniques, which emphasize predictive models (Bengio et al., 2006; Baroni et al., 2014b), rather than context-counting and matrix factorization (Landauer et al., 1998; Turney and Pantel, 2010).",7.2 Compositional distributed semantics,[0],[0]
"Recent work has made practical the idea of propagating distributed information through linguistic structures (Smolensky, 1990; Collobert et al., 2011).",7.2 Compositional distributed semantics,[0],[0]
"In such models, the distributed representations and compositional operators can be fine-tuned by backpropagating supervision from task-specific labels, enabling accurate and fast models for a wide range of language technologies (Socher et al., 2011; Socher et al., 2013; Chen and Manning, 2014).
",7.2 Compositional distributed semantics,[0],[0]
Of particular relevance is recent work on twopass procedures for distributed compositional semantics.,7.2 Compositional distributed semantics,[0],[0]
"Paulus et al. (2014) perform targeted sentiment analysis by propagating information from
the sentence level back to child non-terminals in the parse tree.",7.2 Compositional distributed semantics,[0],[0]
"Their compositional procedure is different from ours: in their work, the “downward” meaning of each non-terminal is reconstructed from the upward and downward meanings of its parents.",7.2 Compositional distributed semantics,[0],[0]
"İrsoy and Cardie (2013) propose an alternative two-pass procedure, where the downward representation for a node is computed from the downward representation of its parent, and from its own upward representation.",7.2 Compositional distributed semantics,[0],[0]
"A key difference in our approach is that the siblings in a production are more directly connected: the upward representation of a given node is used to compute the downward representation of its sibling, similar to the inside-outside algorithm.",7.2 Compositional distributed semantics,[0],[0]
"In the models of Paulus et al. (2014) and İrsoy and Cardie (2013), the connection between siblings nodes is less direct, as it is channeled through the representation of the parent node.",7.2 Compositional distributed semantics,[0],[0]
"From this perspective, the most closely related prior work is the Inside-Outside Recursive Neural Network (Le and Zuidema, 2014), published shortly before this paper was submitted.",7.2 Compositional distributed semantics,[0],[0]
"The compositional procedure in this paper is identical, although the application is quite different: rather than inducing distributed representations of entity mentions, the goal of this work is to support an infinite-order generative model of dependency parsing.",7.2 Compositional distributed semantics,[0],[0]
"While Le and Zuidema apply this idea as a generative reranker within a supervised dependency parsing framework, we are interested to explore whether it could be employed to do unsupervised syntactic analysis, which could substitute for the supervised syntactic parser in our system.
",7.2 Compositional distributed semantics,[0],[0]
"The application of distributional and distributed semantics to discourse includes the use of latent semantic analysis for text segmentation (Choi et al., 2001) and coherence assessment (Foltz et al., 1998), as well as paraphrase detection by the factorization of matrices of distributional counts (Kauchak and Barzilay, 2006; Mihalcea et al., 2006).",7.2 Compositional distributed semantics,[0],[0]
"These approaches essentially compute a distributional representation in advance, and then use it alongside other features.",7.2 Compositional distributed semantics,[0],[0]
"In contrast, our approach follows more recent work in which the distributed representation is driven by supervision from discourse annotations.",7.2 Compositional distributed semantics,[0],[0]
"For example, Ji and Eisenstein (2014) show that RST parsing can be performed by learning task-specific word representations, which perform considerably better than generic word2vec representations (Mikolov et al.,
2013).",7.2 Compositional distributed semantics,[0],[0]
"Li et al. (2014) propose a recursive neural network approach to RST parsing, which is similar to the upward pass in our model, and Kalchbrenner and Blunsom (2013) show how a recurrent neural network can be used to identify dialogue acts.",7.2 Compositional distributed semantics,[0],[0]
"However, prior work has not applied these ideas to the classification of implicit relations in the PDTB, and does not consider the role of entities.",7.2 Compositional distributed semantics,[0],[0]
"As we argue in the introduction, a single vector representation is insufficiently expressive, because it obliterates the entity chains that help to tie discourse together.
",7.2 Compositional distributed semantics,[0],[0]
"More generally, our entity-augmented distributed representation can be viewed in the context of recent literature on combining distributed and formal semantics: by representing entities, we are taking a small step away from purely vectorial representations, and towards more traditional logical representations of meaning.",7.2 Compositional distributed semantics,[0],[0]
"In this sense, our approach is “bottom-up”, as we try to add a small amount of logical formalism to distributed representations; other approaches are “top-down”, softening purely logical representations by using distributional clustering (Poon and Domingos, 2009; Lewis and Steedman, 2013) or Bayesian non-parametrics (Titov and Klementiev, 2011) to obtain types for entities and relations.",7.2 Compositional distributed semantics,[0],[0]
"Still more ambitious would be to implement logical semantics within a distributed compositional framework (Clark et al., 2011; Grefenstette, 2013).",7.2 Compositional distributed semantics,[0],[0]
"At present, these combinations of logical and distributed semantics have been explored only at the sentence level.",7.2 Compositional distributed semantics,[0],[0]
"In generalizing such approaches to multi-sentence discourse, we argue that it will not be sufficient to compute distributed representations of sentences: a multitude of other elements, such as entities, will also have to represented.",7.2 Compositional distributed semantics,[0],[0]
"Discourse relations are determined by the meaning of their arguments, and progress on discourse parsing therefore requires computing representations of the argument semantics.",8 Conclusion,[0],[0]
"We present a compositional method for inducing distributed representations not only of discourse arguments, but also of the entities that thread through the discourse.",8 Conclusion,[0],[0]
"In this approach, semantic composition is applied up the syntactic parse tree to induce the argument-level representation, and then down the parse tree to induce representations of entity
spans.",8 Conclusion,[0],[0]
"Discourse arguments can then be compared in terms of their overall distributed representation, as well as by the representations of coreferent entity mentions.",8 Conclusion,[0],[0]
This enables the compositional operators to be learned by backpropagation from discourse annotations.,8 Conclusion,[0],[0]
"In combination with traditional surface features, this approach outperforms previous work on classification of implicit discourse relations in the Penn Discourse Treebank.",8 Conclusion,[0],[0]
"While the entity mention representations offer only a small improvement in overall performance, we show that this is limited by the recall of the coreference resolution system: when evaluated on argument pairs for which coreference is detected, the raw improvement from entity semantics is more than 2%.",8 Conclusion,[0],[0]
"Future work will consider joint models of discourse structure and coreference, and consideration of coreference across the entire document.",8 Conclusion,[0],[0]
"In the longer term, we hope to induce and exploit representations of other discourse elements, such as event coreference and shallow semantics.
",8 Conclusion,[0],[0]
Acknowledgments This work was supported by a Google Faculty Research Award to the second author.,8 Conclusion,[0],[0]
"Chris Dyer, Ray Mooney, and Bonnie Webber provided helpful feedback, as did the anonymous reviewers and the editor.",8 Conclusion,[0],[0]
"Thanks also to Te Rutherford, who both publicly released his code and helped us to use and understand it.",8 Conclusion,[0],[0]
Discourse relations bind smaller linguistic units into coherent texts.,abstractText,[0],[0]
"Automatically identifying discourse relations is difficult, because it requires understanding the semantics of the linked arguments.",abstractText,[0],[0]
"A more subtle challenge is that it is not enough to represent the meaning of each argument of a discourse relation, because the relation may depend on links between lowerlevel components, such as entity mentions.",abstractText,[0],[0]
Our solution computes distributed meaning representations for each discourse argument by composition up the syntactic parse tree.,abstractText,[0],[0]
We also perform a downward compositional pass to capture the meaning of coreferent entity mentions.,abstractText,[0],[0]
"Implicit discourse relations are then predicted from these two representations, obtaining substantial improvements on the Penn Discourse Treebank.",abstractText,[0],[0]
One Vector is Not Enough: Entity-Augmented Distributed Semantics for Discourse Relations,title,[0],[0]
"Humans are not only good at learning to recognize novel, unknown objects from a single instruction example (oneshot learning), but can also localize these objects in highly cluttered scenes and segment them from the background.
",1. Introduction,[0],[0]
"In the computer vision community, one-shot learning has recently received a lot of attention and substantial progress has been made in the context of image classification (Koch et al.,
1Centre for Integrative Neuroscience and Institute for Theoretical Physics, University of Tübingen, Germany 2Bernstein Centre for Computational Neuroscience, Tübingen, Germany 3Max Planck Institute for Biological Cybernetics, Tübingen, Germany 4Center for Neuroscience and Artificial Intelligence, Baylor College of Medicine, Houston, TX, USA.",1. Introduction,[0],[0]
"Correspondence to: Alexander Ecker <alexander.ecker@uni-tuebingen.de>.
",1. Introduction,[0],[0]
"To appaer in: Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
2015; Lake et al., 2015; Vinyals et al., 2016; Bertinetto et al., 2016; Snell et al., 2017; Triantafillou et al., 2017; Shyam et al., 2017).",1. Introduction,[0],[0]
"Segmentation, however, is still very much tied to classification, limiting its applicability to datasets with less than a few hundred semantic or object classes (or subsets thereof, e. g. the SceneParse150 benchmark on ADE20k",1. Introduction,[0],[0]
"(Zhou et al., 2017)).",1. Introduction,[0],[0]
"This stands in contrast to humans who can segment previously unseen objects simply by using contextual information.
",1. Introduction,[0],[0]
"In the present paper, we work towards closing this gap by tackling the problem of one-shot segmentation:",1. Introduction,[0],[0]
"Given a single instruction example (the target) and a cluttered image
ar X
iv :1
80 3.
09 59
7v 2
[ cs
.C V
] 1
3 Ju
n 20
18
with many objects (the scene), find the target in the scene and produce a pixel-wise segmentation (Fig 1A).",1. Introduction,[0],[0]
This task is harder than the multi-way discrimination task often employed for one-shot learning because it additionally requires (a) localizing the target among a potentially large number of distractors and (b) segmenting the detected object.,1. Introduction,[0],[0]
"While a few groups have started working on variants of this task (Caelles et al., 2017; Shaban et al., 2017), no commonly employed benchmark has emerged yet.
",1. Introduction,[0],[0]
"Our contributions are as follows:
• We propose a new benchmark dataset: “cluttered Omniglot” (Fig. 1A).",1. Introduction,[0],[0]
"It is based on simple components – characters from Omniglot (Lake et al., 2015) – yet turns out to be hard for current state-of-the-art computer vision components.",1. Introduction,[0],[0]
"We publish the dataset, the code and our models.1
• We present a baseline for one-shot segmentation on cluttered Omniglot.",1. Introduction,[0],[0]
"It combines two principled yet simple components: a Siamese network for object detection and a U-net for segmentation (Fig. 1B).
",1. Introduction,[0],[0]
• We identify clutter as a substantial problem for current computer vision systems and investigate it using various oracles – models with access to some ground truth information.,1. Introduction,[0],[0]
"Although the statistical complexity of the objects in cluttered Omniglot is low – color alone completely identifies each instance –, the dead leaves environment creates difficulties for both detection and segmentation due to the similar foreground and background statistics.
",1. Introduction,[0],[0]
"• We propose to solve this task by a form of object-based attention: we first generate and segment multiple object proposals, then mask out background and finally decide among the “cleaned-up” objects (Fig. 1C).",1. Introduction,[0],[0]
"We show that this approach, which we call MaskNet, improves both segmentation and localization.
",1. Introduction,[0],[0]
"Our paper is structured as follows: We start by describing the cluttered Omniglot dataset (Sec. 2), then explain our Siamese U-net baseline (Sec. 3) and MaskNet, our improved architecture (Sec. 4), as well as the oracles we use (Sec. 5).",1. Introduction,[0],[0]
"We then present our experimental results (Sec. 6), discuss related work (Sec. 7) and conclude (Sec. 8).",1. Introduction,[0],[0]
Cluttered Omniglot is a visual search task: the goal is to find a previously unseen target character in a cluttered scene and to produce a pixelwise segmentation (Fig. 1A).,2. Cluttered Omniglot,[0],[0]
"It is based on the Omniglot dataset (Lake et al., 2015), which we chose for two reasons: First, it is a popular and well-studied dataset
1 https://github.com/michaelisc/cluttered-omniglot
for one-shot learning.",2. Cluttered Omniglot,[0],[0]
"Second, the statistics of the individual objects in Omniglot are relatively simple.",2. Cluttered Omniglot,[0],[0]
"Nevertheless, we show below that cluttered Omniglot presents a serious challenge to convolutional neural networks.",2. Cluttered Omniglot,[0],[0]
"Thus, we think of this dataset as the essence of the clutter problem.
",2. Cluttered Omniglot,[0],[0]
"Each sample in the dataset consists of three images: a target, a scene and a segmentation map.",2. Cluttered Omniglot,[0],[0]
"Targets are individual characters from Omniglot, rescaled to 32 × 32 pixels and colored in a random RGB color.",2. Cluttered Omniglot,[0],[0]
"Scenes are 96× 96 pixel collages of multiple (4–256) randomly drawn Omniglot characters, one of which is the target (Fig. 2).",2. Cluttered Omniglot,[0],[0]
"The characters are sequentially “dropped” into the image like dead leaves, occluding any characters previously drawn at the same pixel locations.",2. Cluttered Omniglot,[0],[0]
"Each character is placed at a random location, has a random RGB color and is transformed with a random affine transformation of up to 20◦ rotation, 10◦ shearing and scaling between 16 and 64 pixels.",2. Cluttered Omniglot,[0],[0]
"At the end, a random instance of the target character is added.",2. Cluttered Omniglot,[0],[0]
This instance is always fully visible and not occluded.,2. Cluttered Omniglot,[0],[0]
"We specifically avoid occlusion of the target instance, so we do not confound the effect of visual clutter with that of occlusion.
",2. Cluttered Omniglot,[0],[0]
"We split the dataset into three splits: training, validation and one-shot.",2. Cluttered Omniglot,[0],[0]
"As in the original work on Omniglot (Lake et al., 2015), we use the background set for training and validation, while we use the evaluation set for testing oneshot performance.",2. Cluttered Omniglot,[0],[0]
"For simplicity, we use only the first ten drawers in each alphabet for the training set and the other ten drawers for the validation and one-shot sets.
",2. Cluttered Omniglot,[0],[0]
"The difficulty of this task depends on the number of distractors (Wolfe, 1998).",2. Cluttered Omniglot,[0],[0]
"We show below (Section 6.1) that our baseline scores a close-to-perfect Intersection over Union (IoU) for the easiest version with just four distractors, similar to the accuracies of high-performing architectures designed for one-shot discrimination on Omniglot (Koch et al., 2015; Vinyals et al., 2016; Snell et al., 2017; Triantafillou et al., 2017; Shyam et al., 2017).",2. Cluttered Omniglot,[0],[0]
"In contrast, performance drops below 40% IoU for the hardest version with 256 distractors.
",2. Cluttered Omniglot,[0],[0]
"For each difficulty level, we generate a training set consisting of 2 million samples and validation and one-shot sets consisting of 10,000 samples each.",2. Cluttered Omniglot,[0],[0]
Note that the entire dataset is generated using a total of 9640 (6590) character instances for the training (one-shot) set.,2. Cluttered Omniglot,[0],[0]
"Intuitively, the one-shot segmentation task can be broken down into two steps: detect the target in the scene and segment it.",3. Baseline: Siamese U-net,[0],[0]
We implement a baseline that performs the detection part with a Siamese net applied in sliding windows over the scene to produce a heat map of candidate locations (Fig. 3A).,3. Baseline: Siamese U-net,[0],[0]
"The segmentation mask is then generated by a
deconvolutional net with skip connections from the encoder.",3. Baseline: Siamese U-net,[0],[0]
The encoder is inspired by Siamese networks.,3.1. Encoder,[0],[0]
"It consists of two parallel fully convolutional neural networks that process the target (32× 32× 3) and the scene image (96× 96× 3), respectively (Fig. 3A).",3.1. Encoder,[0],[0]
"All convolutions use 3× 3 kernels with “same” padding, followed by layer normalization (Ba et al., 2016) and ReLUs.",3.1. Encoder,[0],[0]
"An exception is made in the last two layers, which use 2× 2 and 1× 1 kernels respectively (the size of the feature maps of the target encoder in these layers) (Fig. 3C).",3.1. Encoder,[0],[0]
"Before each but the first convolution, the image is downsampled by a factor of two using average pooling.",3.1. Encoder,[0],[0]
This architecture produces an embedding of the target in form of a 384-dimensional vector (1× 1 spatially).,3.1. Encoder,[0],[0]
The scene image is processed analogously.,3.1. Encoder,[0],[0]
"To retain a higher resolution in the last layer, we do not use downsampling in the last two layers of the scene encoder.",3.1. Encoder,[0],[0]
Instead we us a dilation factor of 2 for the convolutions in the second-to-last layer.,3.1. Encoder,[0],[0]
"This results in a 12× 12 pixel encoding with – as for the target – 384 feature maps.
",3.1. Encoder,[0],[0]
"Although the encoder is inspired by Siamese networks, we found in initial experiments that untying the weights improves performance and therefore do not use weight sharing between the two paths (see also Bertinetto et al., 2016).",3.1. Encoder,[0],[0]
This result could potentially be attributed to the differing statistics of the clean target and the cluttered scene image.,3.1. Encoder,[0],[0]
"To get an estimate of the target’s location in the scene, we compute the cosine similarity in the embedding space given by the encoder.",3.2. Target matching,[0],[0]
"We do so by taking the pixelwise inner product of the scene embedding with that of the target (Fig. 3C), which is implemented by a 1 × 1 convolution using the target embedding as the filter.",3.2. Target matching,[0],[0]
"This step can be thought of as applying a Siamese network in sliding windows over the scene image (with a stride of 8, the stride of the final layer of the scene encoder).",3.2. Target matching,[0],[0]
"The output is a 12 × 12 heatmap, which can be seen as a (subsampled) pixel-level likelihood that the target is at a given location within the scene.
",3.2. Target matching,[0],[0]
"This heatmap does not contain any information about what
the target is.",3.2. Target matching,[0],[0]
"To inform the decoder about the target that should be segmented, we compute the outer tensor product of the heatmap with the target embedding.",3.2. Target matching,[0],[0]
"Thus, the final output of the matching step is a 12× 12× 384 tensor, which encodes at each location the direction of the target in embedding space, weighted by how likely the encoder considers the target to be at that location.",3.2. Target matching,[0],[0]
"As all other layers, this output is normalized using layer normalization.",3.2. Target matching,[0],[0]
"The segmentation part of our baseline model is inspired by the U-net architecture (Ronneberger et al., 2015).",3.3. Decoder,[0],[0]
"The decoder is essentially a mirror image of the encoder: six convolutional layers with 3×3 kernels and “same” padding, followed by layer normalization, ReLU and – for the third, fourth and fifth layer – nearest neighbor upsampling by a factor of two to incrementally increase the image size to the original 96× 96 pixels (Fig. 3C).",3.3. Decoder,[0],[0]
The input to each convolutional layer in the decoder is the concatenation of the previous layer’s output and the output of the corresponding layer in the encoder (skip connections).,3.3. Decoder,[0],[0]
"The final layer of the decoder outputs two feature maps, which are combined into a segmentation map by taking the pixelwise softmax.",3.3. Decoder,[0],[0]
"During training, we minimize the binary cross-entropy between the ground truth segmentation and the network’s prediction.",3.4. Training,[0],[0]
The cross-entropy is computed pixelwise and averaged across all pixels.,3.4. Training,[0],[0]
"The weights are initialized randomly from a Gaussian distribution following the MSRA initialization scheme (He et al., 2015).",3.4. Training,[0],[0]
We regularize the weights using L2 weight decay with a factor of 10−9.,3.4. Training,[0],[0]
"We train the network for 20 epochs using Adam (Kingma & Ba, 2014) with a batch size of 250 and an initial learning rate of 5 × 10−4.",3.4. Training,[0],[0]
"After 10, 15 and 17 epochs, we divide the learning rate by 2.",3.4. Training,[0],[0]
We evaluated the baseline model using intersection over union (IoU).,3.5. Evaluation,[0],[0]
"Therefore the generated segmentation maps are binarized using a threshold or 0.3, which was determined
to be optimal across models and datasets.",3.5. Evaluation,[0],[0]
MaskNet (Fig. 3B) adds two additional processing stages to the baseline.,"4. MaskNet: Segment first, decide later",[0],[0]
"Instead of generating the segmentation in a single pass through the U-net, we let the decoder attend to different locations.","4. MaskNet: Segment first, decide later",[0],[0]
We branch off at the target matching stage and generate multiple object proposals with associated instance segmentations.,"4. MaskNet: Segment first, decide later",[0],[0]
We then decide which of these proposals is the best match.,"4. MaskNet: Segment first, decide later",[0],[0]
"This last stage reduces to the one-shot multi-way discrimination task for image classification, and we solve it using a Siamese net.","4. MaskNet: Segment first, decide later",[0],[0]
We modify our Siamese U-net to turn it into a targeted proposal network (Fig.3B+C).,4.1. Proposal network,[0],[0]
Its output is a set of segmentation proposals (96×96 pixels).,4.1. Proposal network,[0],[0]
"To this end, we modify the target matching step: instead of computing the heatmap by an inner product of target and scene embeddings, we simply set it to a one-hot map encoding a single location (Fig.3C, orange block).",4.1. Proposal network,[0],[0]
"We then use the simplest possible strategy for selecting candidate locations: sweeping all possible locations, thus generating 144 proposals (Fig.3B).",4.1. Proposal network,[0],[0]
"While there are certainly more elaborate ways of generating proposals, we opt for simplicity over efficiency.",4.1. Proposal network,[0],[0]
"Similar to the target matching step in the baseline network, these one-hot heatmaps are multiplied with the target embedding and normalized using layer normalization.",4.1. Proposal network,[0],[0]
"Thus, for each proposal, the decoder is seeded by an embedding of the target confined to a single pixel within the 12× 12 spatial grid and generates a segmentation mask for the target at this location (or background if the target is not present).",4.1. Proposal network,[0],[0]
The decision stage takes multiple object proposals as input and uses a Siamese network to pick the one that most closely resembles the target (Fig. 3B).,4.2. Decision stage,[0],[0]
This step is essentially a 144- way one-shot discrimination task.,4.2. Decision stage,[0],[0]
"The key ingredient here is the input: instead of just taking crops from the scene, we use the generated segmentations to mask out background clutter and perform the discrimination on “clean” objects (Fig. 3B & Fig. 1C).",4.2. Decision stage,[0],[0]
"To do so, we binarize the segmentation proposals using a threshold of 0.3 and extend them to RGB colors by simply coloring them white.",4.2. Decision stage,[0],[0]
"For each proposal, we compute the center of mass of the segmentation mask and extract a 32 × 32 pixel crop centered on this point.",4.2. Decision stage,[0],[0]
We found this solution using the mask directly to perform slightly better then applying it to the image.,4.2. Decision stage,[0],[0]
These crops are then fed into an encoder with the same architecture as the one used for the target (i. e. outputs a 384-dimensional embedding).,4.2. Decision stage,[0],[0]
"As in Siamese networks (Koch et al., 2015), we use the sigmoid of a weighted sum of the L1 distance
between two embeddings as a similarity measure.",4.2. Decision stage,[0],[0]
The full segmentation map corresponding to the crop that is most similar to the target is the final output.,4.2. Decision stage,[0],[0]
"We train proposal network and discriminator separately, by initializing the weights (where possible) from the Siamese U-net baseline and then fine-tuning (Sec. 3.4).",4.3. Training,[0],[0]
All other weights are initialized randomly as for the baseline.,4.3. Training,[0],[0]
We use the same optimizer and regularization as before.,4.3. Training,[0],[0]
"We train for five epochs, dividing the learning rate by two after two, three and four epochs, respectively.
",4.3. Training,[0],[0]
"To train the proposal network, we generate eight proposals for each training sample: four positive ones as above and four negative ones, which are drawn from random locations.",4.3. Training,[0],[0]
We then fine-tune encoder and decoder using the same pixelwise cross-entropy loss as above using the ground truth segmentation for the positive samples and “background” as the label for the negative ones.,4.3. Training,[0],[0]
"The initial learning rate is set to 5× 10−5 and the batch size is 50.
",4.3. Training,[0],[0]
"To train the discriminator, we fix the target encoder, train the encoder for the segmented patches by initializing with the weights of the target encoder and fine-tuning, and train the weights for the weighted L1 distance.",4.3. Training,[0],[0]
"For each training sample, we generate four segmentation proposals: one centered at one of the four locations around the center of mass of the target and three at other random positions.",4.3. Training,[0],[0]
We minimize the binary cross-entropy of the same/different task for each proposal.,4.3. Training,[0],[0]
The initial learning rate is set to 2.5× 10−4 and the batch size is 250.,4.3. Training,[0],[0]
"To evaluate MaskNet, we use intersection over union (IoU) as for the baseline.",4.4. Evaluation,[0],[0]
"As before, we apply a threshold of 0.3 to the predicted segmentation mask.",4.4. Evaluation,[0],[0]
"In addition, we evaluate the localization accuracy of the network independent of the quality of the generated segmentation masks.",4.4. Evaluation,[0],[0]
"To do so, we use the center of mass of the chosen segmentation proposal as the prediction of the target’s location.",4.4. Evaluation,[0],[0]
We count all predictions that are within five pixels of the ground truth location (also center of mass) as correct and report localization accuracy in percent correct.,4.4. Evaluation,[0],[0]
We evaluate two oracles that have access to ground truth segmentation masks of all characters in the scene.,5. Oracles,[0],[0]
"Being able to define such oracles is a useful feature of cluttered Omniglot, which allows us to test the quality of individual model components.",5. Oracles,[0],[0]
The pre-segmented discriminator operates on individual characters that have been pre-segmented and cropped to the same size as the target.,5.1. Pre-segmented discriminator,[0],[0]
"Specifically, we use the fact that the characters are uniformly colored to segment each character and extract a 32 × 32 pixel crop centered on its center of mass.",5.1. Pre-segmented discriminator,[0],[0]
"The task of this oracle is the same as for the decision step of MaskNet (Sec. 4.2) and can be reduced to the widely used one-shot multi-way discrimination, hence the name discriminator.",5.1. Pre-segmented discriminator,[0],[0]
"We implement it by a Siamese network using the same encoder as before (Sec. 3.1) comparing the generated embeddings with a weighted L1 distance, followed by a sigmoid (Koch et al., 2015).",5.1. Pre-segmented discriminator,[0],[0]
The pre-segmented discriminator lets us assess the additional difficulty (if any) introduced by (a) the random affine transformations in cluttered Omniglot and (b) the potentially large number of candidate characters to decide among.,5.1. Pre-segmented discriminator,[0],[0]
The cluttered discriminator does not pre-segment characters.,5.2. Cluttered discriminator,[0],[0]
"Instead it takes the same crops as the pre-segmented discriminator, but keeps the cluttered background intact.",5.2. Cluttered discriminator,[0],[0]
The rest is identical to the pre-segmented discriminator.,5.2. Cluttered discriminator,[0],[0]
"Thus, the cluttered discriminator performs the one-shot multi-way discrimination on cluttered crops.",5.2. Cluttered discriminator,[0],[0]
"By comparing its performance to that of the pre-segmented version, we can directly assess the effect of clutter on discrimination.",5.2. Cluttered discriminator,[0],[0]
We train both discriminators by minimizing the binary crossentropy in the same/different task.,5.3. Training,[0],[0]
"In each training step, four crops are sampled: one containing the target and three randomly selected ones.",5.3. Training,[0],[0]
Each crop is compared with the target and the average cross-entropy is computed.,5.3. Training,[0],[0]
"Initialization, regularization and optimization are done in the same way as for the baseline (Sec. 3.4).",5.3. Training,[0],[0]
A batch size of 250 and an initial learning rate of 5× 10−4 are chosen.,5.3. Training,[0],[0]
"Like the baseline, the
discriminators are trained for 20 epochs and the learning rate is divided by 2 after epochs 10, 15 and 17.",5.3. Training,[0],[0]
We evaluate the pre-segmented discriminator using the same two metrics used for MaskNet: IoU and localization accuracy.,5.4. Evaluation,[0],[0]
"To evaluate IoU, we use the ground truth segmentations associated with the best-matching crop.",5.4. Evaluation,[0],[0]
"Due to the access to ground truth segmentations, IoU is equivalent to the percentage of correct decisions in the discrimination task.",5.4. Evaluation,[0],[0]
"To evaluate localization accuracy, we take the same measure as for MaskNet:",5.4. Evaluation,[0],[0]
The Euclidean distance between the center of each crop and the true location of the target thresholded at 5 pixels.,5.4. Evaluation,[0],[0]
"For the cluttered discriminator, we evaluate only localization accuracy.",5.4. Evaluation,[0],[0]
We used the same encoder and decoder architectures for all experiments.,6. Results,[0],[0]
"Both consist of six convolutional layers interleaved with pooling, dilation or upsampling operations (see Fig. 3C and Sec. 3.1).",6. Results,[0],[0]
"All comparisons between architectures are therefore independent of the expressiveness of encoder and decoder, but rely only on the different approaches to segmentation and detection.",6. Results,[0],[0]
All reported results are evaluated on the one-shot set unless specified otherwise.,6. Results,[0],[0]
"We start by characterizing the difficulty of the one-shot segmentation task on cluttered Omniglot by evaluating the performance of our baseline model (Section 3) on both, the one-shot and the validation set across all difficulty levels.
",6.1. Baseline,[0],[0]
We first consider the results on the validation set (Fig.,6.1. Baseline,[0],[0]
"4A, light blue).",6.1. Baseline,[0],[0]
"The validation set contains characters seen during training, but drawn by a different set of drawers (see
Section 2).",6.1. Baseline,[0],[0]
"For a small number of distractors, the network performs well – as expected, because the characters are mostly isolated within the scene.",6.1. Baseline,[0],[0]
"Performance is above 90% IoU, similar to discrimination performance in one-shot fiveway discrimination on regular Omniglot (Koch et al., 2015; Vinyals et al., 2016; Snell et al., 2017; Triantafillou et al., 2017; Shyam et al., 2017).",6.1. Baseline,[0],[0]
"However, performance drops substantially with increasing number of distractors (< 40% for 256 distractors).
",6.1. Baseline,[0],[0]
"On the one-shot set – that is, characters from alphabets not seen during training – performance is on average only 3% worse than validation performance (",6.1. Baseline,[0],[0]
"Fig. 4A, blue), showing that the network has indeed learned the right metric to identify previously unseen letters and segment them.",6.1. Baseline,[0],[0]
The performance drop of our baseline model with increasing number of distractors could have two reasons.,6.2. Clutter reduces performance more than the number of comparisons,[0],[0]
"First, the scenes are highly cluttered, which may cause problems for the detection of the target.",6.2. Clutter reduces performance more than the number of comparisons,[0],[0]
"Second, the large number of comparisons may simply increase the probability of making a mistake by chance (n-way discrimination with large n).",6.2. Clutter reduces performance more than the number of comparisons,[0],[0]
"To understand the influence of these factors, we constructed two oracles, which both have access to the ground truth locations of all characters in the scene (Sec. 5).",6.2. Clutter reduces performance more than the number of comparisons,[0],[0]
"Both models
extract crops centered at the location of each character in the scene and perform a discrimination task between these crops and the target.
",6.2. Clutter reduces performance more than the number of comparisons,[0],[0]
"The pre-segmented discriminator has access not only to the ground truth location but also the segmentation mask of each character, allowing it to pre-segment all crops.",6.2. Clutter reduces performance more than the number of comparisons,[0],[0]
The resulting task is essentially the classical one-shot n-way discrimination task.,6.2. Clutter reduces performance more than the number of comparisons,[0],[0]
"The only difference is that it is a bit easier since many characters in the background are highly occluded, whereas the target is always unoccluded.",6.2. Clutter reduces performance more than the number of comparisons,[0],[0]
"Remarkably, the performance of the pre-segmented discriminator remains above 95% IoU even for the most cluttered scenes with 256 characters (Fig.",6.2. Clutter reduces performance more than the number of comparisons,[0],[0]
"4C+D, red), demonstrating that our encoder can solve the task in an uncluttered environment.
",6.2. Clutter reduces performance more than the number of comparisons,[0],[0]
The cluttered discriminator has access to only the ground truth locations.,6.2. Clutter reduces performance more than the number of comparisons,[0],[0]
It cannot segment the characters and has to perform the n-way discrimination on cluttered crops.,6.2. Clutter reduces performance more than the number of comparisons,[0],[0]
"In contrast to the pre-segmented discriminatior its performance takes a substantial hit with increased clutter (Fig. 4D, yellow).",6.2. Clutter reduces performance more than the number of comparisons,[0],[0]
Thus we conclude that the difficulty of cluttered Omniglot arises due to clutter rather than the potentially large number of candidate characters in the scene.,6.2. Clutter reduces performance more than the number of comparisons,[0],[0]
"A lot of work on one-shot learning has used Omniglot, but we are not aware of any work evaluating simple approaches like template matching.",6.3. Template matching is not sufficient,[0],[0]
"As a sanity check, we implemented a template matching procedure for our task based on the presegmented discriminator.2 Accuracy ranged from 62% for 4 characters to 29% for 256 characters (Table 1).3 Despite the highly simplified setting with oracle information available, template matching performs not only worse than the presegmented discriminator (99−96%), but even worse than our baseline on the full task (97−38%).",6.3. Template matching is not sufficient,[0],[0]
"Thus, template matching is not a viable solution for (cluttered) Omniglot.",6.3. Template matching is not sufficient,[0],[0]
"Motivated by the superb discrimination performance on presegmented objects, we developed MaskNet, a novel model
2We generated 9317 transformed versions of the target (11 rotations, 7 shearing angles, 11x11 x/y scales), convolved them with each segmented, binarized character and picked the best match.
",6.4. Background masking improves performance,[0],[0]
"3For comparison: on the standard 5-way one-shot task on Omniglot, we achieved 84% accuracy using template matching.
that operates in three steps (Sec. 4).",6.4. Background masking improves performance,[0],[0]
"First, we generate a number of object proposals.",6.4. Background masking improves performance,[0],[0]
"Next, we generate corresponding object segmentations which mask out the background.",6.4. Background masking improves performance,[0],[0]
"In the last step, we perform discrimination on these segmented objects to decide which one to pick.",6.4. Background masking improves performance,[0],[0]
"This model outperforms the baseline (Fig. 4B+C, green line), suggesting that segmenting objects (and masking out background) before classifying them is beneficial when processing highly cluttered scenes.",6.4. Background masking improves performance,[0],[0]
"Nevertheless, there is still a large margin to the performance of the pre-segmented oracle.",6.4. Background masking improves performance,[0],[0]
We investigate the reasons for this margin below.,6.4. Background masking improves performance,[0],[0]
A crucial feature of MaskNet (and perhaps its main weakness) is that the final discriminator can only be as good as the segmentations it receives as input.,6.5. Quality of segmentation limits performance,[0],[0]
We therefore evaluate the quality of these segmentations.,6.5. Quality of segmentation limits performance,[0],[0]
"To this end, we evaluate the maximal IoU among all proposals, which is equivalent to assuming a perfect discriminator that always picks the correct character.",6.5. Quality of segmentation limits performance,[0],[0]
"We find that indeed the instance segmentations of the proposals appear to be a limiting factor: for the most cluttered scenes the proposal with the highest IoU achieves only around 60% on average (Fig. 4B, black).",6.5. Quality of segmentation limits performance,[0],[0]
"Next, we test whether it is necessary to seed the decoder with an embedding of the target, instead of just seeding it with a location and segment the most salient character at that location.",6.6. Targeted segmentations improve performance,[0],[0]
"To this end, we remove the target multiplication step from MaskNet’s proposal network and simply seed the decoder with the spatial one-hot encoding (Section 4.1).",6.6. Targeted segmentations improve performance,[0],[0]
"Using this non-targeted proposal network instead of the targeted one reduces performance (Fig. 4B, grey), showing that it is important to supply the decoder with information what to segment.",6.6. Targeted segmentations improve performance,[0],[0]
"So far, we have focused our evaluation of MaskNet’s performance on segmentation.",6.7. Performing segmentation improves localization,[0],[0]
"Interestingly, though, segmenting objects also helps if we are interested only in localizing the target rather than segmenting it.",6.7. Performing segmentation improves localization,[0],[0]
"To provide evidence for this claim, we compare the localization performance of MaskNet to that of the cluttered discriminator.",6.7. Performing segmentation improves localization,[0],[0]
"For the cluttered discriminator, we simply use the location of the crop it chooses as the prediction for the target’s location.",6.7. Performing segmentation improves localization,[0],[0]
"For MaskNet, we use the center of mass of its predicted segmentation mask.",6.7. Performing segmentation improves localization,[0],[0]
We then compute the localization accuracy (Sec. 4.4) of these predictions to the ground truth center of mass of the target.,6.7. Performing segmentation improves localization,[0],[0]
"Indeed, MaskNet predicts the location of the target more accurately than the cluttered discriminator (Fig. 4D and Table. 2), showing that segmenting objects to mask out background clutter improves localization.",6.7. Performing segmentation improves localization,[0],[0]
One-shot learning has been explored mostly in the context of multi-way discrimination for image classification.,7.1. One-shot discrimination,[0],[0]
Lake et al. (2015) developed the Omniglot dataset for this purpose and approach it using a generative model of stroke patterns.,7.1. One-shot discrimination,[0],[0]
"Most competing approaches learn an embedding to compute a similarity metric (Koch et al., 2015; Vinyals et al., 2016; Snell et al., 2017; Triantafillou et al., 2017).",7.1. One-shot discrimination,[0],[0]
Bertinetto et al. (2016) train a meta network that predicts the weights of a discriminator in a single feedforward step.,7.1. One-shot discrimination,[0],[0]
"Another approach compares image parts in an iterative fashion (Shyam et al., 2017).",7.1. One-shot discrimination,[0],[0]
"Most recent approaches to segmentation use an encoder/decoder architecture (Noh et al., 2015; Badrinarayanan et al., 2017).",7.2. Semantic/instance segmentation,[0],[0]
"The encoders are usually highperforming architectures for image classification [e. g. AlexNet (Krizhevsky et al., 2012), VGG (Simonyan & Zisserman, 2015), ResNet (He et al., 2016)].",7.2. Semantic/instance segmentation,[0],[0]
The main differences lie in the decoder design.,7.2. Semantic/instance segmentation,[0],[0]
"Where early works converted high-level representations into pixelwise labels using upsampling in combination with linear transformation (Long et al., 2015) or conditional random fields (Chen et al., 2014; 2018), recent approaches rely on more complex decoders [DeconvNet (Noh et al., 2015), SegNet (Badrinarayanan et al., 2017), RefineNet (Lin et al., 2017)] and introduce skip connections from the encoder.",7.2. Semantic/instance segmentation,[0],[0]
"The U-net architecture (Ronneberger et al., 2015), which uses skip connections is a particularly simple and elegant generalpurpose architecture for dense labeling and image-to-image problems (e. g. Isola et al., 2016).
",7.2. Semantic/instance segmentation,[0],[0]
"More recent work focuses on multi-scale pooling (Zhao et al., 2017) and dilated convolutions (Chen et al., 2017).",7.2. Semantic/instance segmentation,[0],[0]
"These architectures improve performance, but simplify the decoders, relying more on upsampling.",7.2. Semantic/instance segmentation,[0],[0]
"While this approach works well on datasets such as MS-COCO, it renders them infeasible for segmenting on Omniglot, where characters have fine detail at the pixel level.
",7.2. Semantic/instance segmentation,[0],[0]
"Our proposal network is inspired by Mask R-CNN (He et al., 2017), which achieved state-of-the-art performance on MS-COCO by splitting object detection and instance segmentation into two consecutive steps.",7.2. Semantic/instance segmentation,[0],[0]
"Similarly, our class-agnostic segmentation is inspired by the work of Hong et al. (2015) and Mask R-CNN (He et al., 2017).",7.2. Semantic/instance segmentation,[0],[0]
"Also related is work on class-agnostic segmentation using extreme point annotations (Maninis et al., 2017; Papadopoulos et al., 2017): while these works inform the segmentation by clicks in the image, our architecture seeds the decoder with a location information at the embedding layer.",7.2. Semantic/instance segmentation,[0],[0]
One-shot segmentation has emerged only recently.,7.3. One-shot segmentation,[0],[0]
Caelles et al. (2017) tackle the problem of segmenting an unseen object in a video based on a single (or a few) initial labeled frame(s).,7.3. One-shot segmentation,[0],[0]
"The work by Shaban et al. (2017) is very similar to our approach, except that they use logistic regression with a large stride and upsampling for the decoder and tackle Pascal VOC (Everingham et al., 2012).",7.3. One-shot segmentation,[0],[0]
"Co-segmentation (Faktor & Irani, 2013; Quan et al., 2016; Sharma, 2017) is somewhat related to one-shot segmentation, as the common object in multiple images has to be segmented.",7.4. Other related problems,[0],[0]
"However, objects are typically quite salient (otherwise the problem is not well defined).",7.4. Other related problems,[0],[0]
"We can think of cluttered Omniglot as an asymmetric co-segmentation problem with one object-centered and one scene image.
",7.4. Other related problems,[0],[0]
"Apparel recognition (Hadi Kiapour et al., 2015; Zhao et al., 2016; Cheng et al., 2017) and particular object retrieval (Razavian et al., 2014; Tolias et al., 2016; Li et al., 2017; Siméoni et al., 2017) are related in the sense that the goal is to find objects specified by one image in other images.",7.4. Other related problems,[0],[0]
"However, both problems are primarily about image retrieval rather than segmentation of objects within these images.",7.4. Other related problems,[0],[0]
One exception is the work of Zhao et al. (2016) in which co-segmentation is performed on pieces of clothing.,7.4. Other related problems,[0],[0]
We explored one-shot segmentation in cluttered Omniglot and found increasing clutter to quickly diminish performance even though characters can be easily identified by color.,8. Conclusions,[0],[0]
Thus clutter is a serious problem for current state-ofthe-art CNN architectures.,8. Conclusions,[0],[0]
"As a first step towards solving this problem, we showed that segmenting objects first improves detection when scenes are cluttered.",8. Conclusions,[0],[0]
"We aimed for a proof of principle and thus used the simplest model possible, which performs only one iteration of segmentation and then decides directly based upon this first segmentation.",8. Conclusions,[0],[0]
"Fully recurrent architectures that iteratively refine detection and segmentation by cycling through this process multiple times could lead to even larger performance gains.
",8. Conclusions,[0],[0]
"As we focus on the role of clutter, we specifically designed cluttered Omniglot to have relatively simple object statistics but various levels of clutter.",8. Conclusions,[0],[0]
"An interesting avenue for future work would be to specifically investigate cluttered image regions in real-world datasets such as Pascal VOC, MS-COCO or ADE20k.",8. Conclusions,[0],[0]
"Both, the task and our MaskNet architecture should be directly applicable to these datatsets, for instance by searching for unseen object categories in natural scenes could be done by replacing our encoder by a state-of-the-art ImageNet classifier.",8. Conclusions,[0],[0]
This work was supported by the German Research Foundation (DFG) through Collaborative Research Center (CRC 1233),Acknowledgements,[0],[0]
"“Robust Vision” and DFG grant EC 479/1-1, and by the Advanced Research Projects Activity (IARPA) via Department of Interior/Interior Business Center (DoI/IBC) contract number D16PC00003.",Acknowledgements,[0],[0]
The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright annotation thereon.,Acknowledgements,[0],[0]
"Disclaimer: The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of IARPA, DoI/IBC, or the U.S. Government.",Acknowledgements,[0],[0]
We tackle the problem of one-shot segmentation: finding and segmenting a previously unseen object in a cluttered scene based on a single instruction example.,abstractText,[0],[0]
"We propose a novel dataset, which we call cluttered Omniglot.",abstractText,[0],[0]
Using a baseline architecture combining a Siamese embedding for detection with a U-net for segmentation we show that increasing levels of clutter make the task progressively harder.,abstractText,[0],[0]
"Using oracle models with access to various amounts of ground-truth information, we evaluate different aspects of the problem and show that in this kind of visual search task, detection and segmentation are two intertwined problems, the solution to each of which helps solving the other.",abstractText,[0],[0]
"We therefore introduce MaskNet, an improved model that attends to multiple candidate locations, generates segmentation proposals to mask out background clutter and selects among the segmented objects.",abstractText,[0],[0]
Our findings suggest that such image recognition models based on an iterative refinement of object detection and foreground segmentation may provide a way to deal with highly cluttered scenes.,abstractText,[0],[0]
One-Shot Segmentation in Clutter,title,[0],[0]
"Recently, the “sequence-to-sequence” framework (Sutskever et al., 2014; Cho et al., 2014) has facilitated the use of recurrent neural networks (RNNs) on sequence transduction problems such as machine translation and speech recognition.",1. Introduction,[0],[0]
"In this framework, an input sequence is processed with an RNN to produce an “encoding”; this encoding is then used by a second RNN to produce the target sequence.",1. Introduction,[0],[0]
"As originally proposed, the encoding is a single fixed-length vector representation of the input sequence.",1. Introduction,[0],[0]
This requires the model to effectively compress all important information about the input sequence into a single vector.,1. Introduction,[0],[0]
"In practice, this often results in the model having difficulty generalizing to longer sequences than those seen during training (Bahdanau et al., 2015).
",1. Introduction,[0],[0]
"An effective solution to these shortcomings are attention 1Google Brain, Mountain View, California, USA.",1. Introduction,[0],[0]
"Correspondence to: Colin Raffel <craffel@gmail.com>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
mechanisms (Bahdanau et al., 2015).",1. Introduction,[0],[0]
"In a sequence-tosequence model with attention, the encoder produces a sequence of hidden states (instead of a single fixed-length vector) which correspond to entries in the input sequence.",1. Introduction,[0],[0]
The decoder is then allowed to refer back to any of the encoder states as it produces its output.,1. Introduction,[0],[0]
"Similar mechanisms have been used as soft addressing schemes in memoryaugmented neural network architectures (Graves et al., 2014; Sukhbaatar et al., 2015) and RNNs used for sequence generation (Graves, 2013).",1. Introduction,[0],[0]
"Attention-based sequence-tosequence models have proven to be extremely effective on a wide variety of problems, including machine translation (Bahdanau et al., 2015; Luong et al., 2015), image captioning (Xu et al., 2015), speech recognition (Chorowski et al., 2015; Chan et al., 2016), and sentence summarization (Rush et al., 2015).",1. Introduction,[0],[0]
"In addition, attention creates an implicit soft alignment between entries in the output sequence and entries in the input sequence, which can give useful insight into the model’s behavior.
",1. Introduction,[0],[0]
A common criticism of soft attention is that the model must perform a pass over the entire input sequence when producing each element of the output sequence.,1. Introduction,[0],[0]
"This results in the decoding process having complexity O(TU), where T and U are the input and output sequence lengths respectively.",1. Introduction,[0],[0]
"Furthermore, because the entire sequence must be processed prior to outputting any symbols, soft attention cannot be used in “online” settings where output sequence elements are produced when the input has only been partially observed.
",1. Introduction,[0],[0]
The focus of this paper is to propose an alternative attention mechanism which has linear-time complexity and can be used in online settings.,1. Introduction,[0],[0]
"To achieve this, we first note that in many problems, the input-output alignment is roughly monotonic.",1. Introduction,[0],[0]
"For example, when transcribing an audio recording of someone saying “good morning”, the region of the speech utterance corresponding to “good” will always precede the region corresponding to “morning”.",1. Introduction,[0],[0]
"Even when the alignment is not strictly monotonic, it often only contains local input-output reorderings.",1. Introduction,[0],[0]
"Separately, despite the fact that soft attention allows for assignment of focus to multiple disparate entries of the input sequence, in many cases the attention is assigned mostly to a single entry.",1. Introduction,[0],[0]
"For examples of alignments with these characteristics, we refer to e.g. (Chorowski et al. 2015",1. Introduction,[0],[0]
"Figure
2; Chan et al. 2016",1. Introduction,[0],[0]
Figure 2; Rush et al. 2015,1. Introduction,[0],[0]
Figure 1; Bahdanau et al. 2015,1. Introduction,[0],[0]
"Figure 3), etc.",1. Introduction,[0],[0]
"Of course, this is not true in all problems; for example, when using soft attention for image captioning, the model will often change focus arbitrarily between output steps and will spread attention across large regions of the input image (Xu et al., 2015).
",1. Introduction,[0],[0]
"Motivated by these observations, we propose using hard monotonic alignments for sequence-to-sequence problems because, as we argue in section 2.2, they enable computing attention online and in linear time.",1. Introduction,[0],[0]
"Towards this end, we show that it is possible to train such an attention mechanism with a quadratic-time algorithm which computes its expected output.",1. Introduction,[0],[0]
This allows us to continue using standard backpropagation for training while still facilitating efficient online decoding at test-time.,1. Introduction,[0],[0]
"On all problems we studied, we found these added benefits only incur a small decrease in performance compared to softmax-based attention.
",1. Introduction,[0],[0]
"The rest of this paper is structured as follows: In the following section, we develop an interpretation of soft attention as optimizing a stochastic process in expectation and formulate a corresponding stochastic process which allows for online and linear-time decoding by relying on hard monotonic alignments.",1. Introduction,[0],[0]
"In analogy with soft attention, we then show how to compute the expected output of the monotonic attention process and elucidate how the resulting algorithm differs from standard softmax attention.",1. Introduction,[0],[0]
"After giving an overview of related work, we apply our approach to the tasks of sentence summarization, machine translation, and online speech recognition, achieving results competitive with existing sequence-to-sequence models.",1. Introduction,[0],[0]
"Finally, we present additional derivations, experimental details, and ideas for future research in the appendix.",1. Introduction,[0],[0]
"To motivate our approach, we first point out that softmaxbased attention is computing the expected output of a simple stochastic process.",2. Online and Linear-Time Attention,[0],[0]
We then detail an alternative process which enables online and linear-time decoding.,2. Online and Linear-Time Attention,[0],[0]
"Because this process is nondifferentiable, we derive an algorithm for computing its expected output, allowing us to train a model with standard backpropagation while applying our online and linear-time process at test time.",2. Online and Linear-Time Attention,[0],[0]
"Finally, we propose an alternative energy function motivated by the differences between monotonic attention and softmax-based attention.",2. Online and Linear-Time Attention,[0],[0]
"To begin with, we review the commonly-used form of soft attention proposed originally in (Bahdanau et al., 2015).",2.1. Soft Attention,[0],[0]
"Broadly, a sequence-to-sequence model produces a sequence of outputs based on a processed input sequence.",2.1. Soft Attention,[0],[0]
"The model consists of two RNNs, referred to
as the “encoder” and “decoder”.",2.1. Soft Attention,[0],[0]
"The encoder RNN processes the input sequence x = {x1, . . .",2.1. Soft Attention,[0],[0]
", xT } to produce a sequence of hidden states h = {h1, . . .",2.1. Soft Attention,[0],[0]
", hT }.",2.1. Soft Attention,[0],[0]
"We refer to h as the “memory” to emphasize its connection to memory-augmented neural networks (Graves et al., 2014; Sukhbaatar et al., 2015).",2.1. Soft Attention,[0],[0]
"The decoder RNN then produces an output sequence y = {y1, . . .",2.1. Soft Attention,[0],[0]
", yU}, conditioned on the memory, until a special end-of-sequence token is produced.
",2.1. Soft Attention,[0],[0]
"When computing y i , a soft attention-based decoder uses a learnable nonlinear function a(·) to produce a scalar value e
i,j for each entry h j in the memory based on h j and the decoder’s state at the previous timestep s
i 1.",2.1. Soft Attention,[0],[0]
"Typically, a(·) is a single-layer neural network using a tanh nonlinearity, but other functions such as a simple dot product between s
i 1 and hj have been used (Luong et al., 2015; Graves et al., 2014).",2.1. Soft Attention,[0],[0]
"These scalar values are normalized using the softmax function to produce a probability distribution over the memory, which is used to compute a context vector c
i as the weighted sum of h. Because items in the memory have a sequential correspondence with items in the input, these attention distributions create a soft alignment between the output and input.",2.1. Soft Attention,[0],[0]
"Finally, the decoder updates its state to s
i
based on s i 1 and ci and produces yi.",2.1. Soft Attention,[0],[0]
"In total, producing
y
i
involves
e
i,j = a(s",2.1. Soft Attention,[0],[0]
"i 1, hj) (1)
↵
i,j = exp(e",2.1. Soft Attention,[0],[0]
"i,j )
TX
k=1
exp(e",2.1. Soft Attention,[0],[0]
"i,k ) (2)
",2.1. Soft Attention,[0],[0]
"c
i
= TX
j=1
↵
i,j
h
j
(3)
s
i =",2.1. Soft Attention,[0],[0]
"f(s i 1, yi 1, ci) (4)
",2.1. Soft Attention,[0],[0]
"y
i = g(s",2.1. Soft Attention,[0],[0]
"i , c i ) (5)
where f(·) is a recurrent neural network (typically one or more LSTM (Hochreiter & Schmidhuber, 1997) or GRU (Chung et al., 2014) layers) and g(·) is a learnable nonlinear function which maps the decoder state to the output space (e.g. an affine transformation followed by a softmax when the target sequences consist of discrete symbols).
",2.1. Soft Attention,[0],[0]
"To motivate our monotonic alignment scheme, we observe that eqs.",2.1. Soft Attention,[0],[0]
"(2) and (3) are computing the expected output of a simple stochastic process, which can be formulated as follows: First, a probability ↵
i,j is computed independently for each entry h
j of the memory.",2.1. Soft Attention,[0],[0]
"Then, a memory index k is sampled by k ⇠ Categorical(↵
i ) and c i is set to h k .",2.1. Soft Attention,[0],[0]
We visualize this process in fig.,2.1. Soft Attention,[0],[0]
1.,2.1. Soft Attention,[0],[0]
"Clearly, eq. (3) shows that soft attention replaces sampling k and assigning c
i = h k
with direct computation of the expected value of c i .",2.1. Soft Attention,[0],[0]
"The discussion above makes clear that softmax-based attention requires a pass over the entire memory to compute the terms ↵
i,j required to produce each element of the output sequence.",2.2. A Hard Monotonic Attention Process,[0],[0]
"This precludes its use in online settings, and results in a complexity of O(TU) for generating the output sequence.",2.2. A Hard Monotonic Attention Process,[0],[0]
"In addition, despite the fact that h represents a transformation of a sequence (which ostensibly exhibits dependencies between subsequent elements), the attention probabilities are computed independent of temporal order and the attention distribution at the previous timestep.
",2.2. A Hard Monotonic Attention Process,[0],[0]
We address these shortcomings by first formulating a stochastic process which explicitly processes the memory in a left-to-right manner.,2.2. A Hard Monotonic Attention Process,[0],[0]
"Specifically, for output timestep i we begin processing memory entries from index t
i 1, where t
i is the index of the memory entry chosen at output timestep i (for convenience, letting t0 = 1).",2.2. A Hard Monotonic Attention Process,[0],[0]
"We sequentially compute, for j = t
i 1, ti 1 + 1, ti 1 + 2, . . .
",2.2. A Hard Monotonic Attention Process,[0],[0]
"e
i,j = a(s i 1, hj) (6)
",2.2. A Hard Monotonic Attention Process,[0],[0]
"p
i,j = s(e i,j ) (7)",2.2. A Hard Monotonic Attention Process,[0],[0]
"z
i,j ⇠ Bernoulli(p i,j ) (8)
where a(·) is a learnable deterministic “energy function” and s(·) is the logistic sigmoid function.",2.2. A Hard Monotonic Attention Process,[0],[0]
"As soon as we sample z
i,j = 1 for some j, we stop and set c i = h j
and t i = j, “choosing” memory entry j for the context vector.",2.2. A Hard Monotonic Attention Process,[0],[0]
"Each z
i,j can be seen as representing a discrete choice of whether to ingest a new item from the memory (z
i,j = 0) or produce an output (z i,j = 1).",2.2. A Hard Monotonic Attention Process,[0],[0]
"For all sub-
sequent output timesteps, we repeat this process, always starting from t
i 1 (the memory index chosen at the previous timestep).",2.2. A Hard Monotonic Attention Process,[0],[0]
"If for any output timestep i we have z
i,j = 0 for j 2 {t
i 1, . . .",2.2. A Hard Monotonic Attention Process,[0],[0]
", T}, we simply set ci to a vector of zeros.",2.2. A Hard Monotonic Attention Process,[0],[0]
This process is visualized in fig.,2.2. A Hard Monotonic Attention Process,[0],[0]
"2 and is presented more explicitly in algorithm 1 (appendix A).
",2.2. A Hard Monotonic Attention Process,[0],[0]
"Note that by construction, in order to compute p",2.2. A Hard Monotonic Attention Process,[0],[0]
"i,j , we only need to have computed h
k for k 2 {1, . . .",2.2. A Hard Monotonic Attention Process,[0],[0]
", j}.",2.2. A Hard Monotonic Attention Process,[0],[0]
It follows that our novel process can be computed in an online manner; i.e. we do not need to wait to observe the entire input sequence before we start producing the output sequence.,2.2. A Hard Monotonic Attention Process,[0],[0]
"Furthermore, because we start inspecting memory elements from where we left off at the previous output timestep (i.e. at index t
i 1), the resulting process only computes at most max(T, U) terms",2.2. A Hard Monotonic Attention Process,[0],[0]
"p
i,j , giving it a linear runtime.",2.2. A Hard Monotonic Attention Process,[0],[0]
"Of course, it also makes the strong assumption that the alignment between the input and output sequence is strictly monotonic.",2.2. A Hard Monotonic Attention Process,[0],[0]
"The online alignment process described above involves sampling, which precludes the use of standard backpropagation.",2.3. Training in Expectation,[0],[0]
"In analogy with softmax-based attention, we therefore propose training with respect to the expected value of c
i , which can be computed straightforwardly as follows.",2.3. Training in Expectation,[0],[0]
"We first compute e
i,j and p i,j exactly as in eqs.",2.3. Training in Expectation,[0],[0]
"(6) and (7), where p
i,j are interpreted as the probability of choosing memory element j at output timestep i. The attention distribution over the memory is then given by (see appendix C
for a derivation)
",2.3. Training in Expectation,[0],[0]
"↵
i,j = p",2.3. Training in Expectation,[0],[0]
"i,j
jX
k=1
↵ i 1,k
j 1Y
l=k
(1 p i,l )
!",2.3. Training in Expectation,[0],[0]
"(9)
= p",2.3. Training in Expectation,[0],[0]
"i,j
✓ (1 p i,j 1) ↵
i,j 1 p i,j 1 + ↵",2.3. Training in Expectation,[0],[0]
"i 1,j
◆ (10)
",2.3. Training in Expectation,[0],[0]
"We provide a solution to the recurrence relation of eq. (10) which allows computing ↵
i,j for j 2 {1, . . .",2.3. Training in Expectation,[0],[0]
", T} in parallel with cumulative sum and cumulative product operations in appendix C.1.",2.3. Training in Expectation,[0],[0]
"Defining q
i,j = ↵",2.3. Training in Expectation,[0],[0]
"i,j /p",2.3. Training in Expectation,[0],[0]
"i,j gives the following procedure for computing ↵
i,j
:
e
i,j = a(s",2.3. Training in Expectation,[0],[0]
"i 1, hj) (11)
",2.3. Training in Expectation,[0],[0]
"p
i,j = s(e i,j ) (12) q
i,j = (1 p i,j 1)qi,j 1 + ↵i 1,j (13)
",2.3. Training in Expectation,[0],[0]
"↵
i,j = p",2.3. Training in Expectation,[0],[0]
"i,j q",2.3. Training in Expectation,[0],[0]
"i,j
(14)
where we define the special cases of q i,0 = 0, pi,0 = 0 to maintain equivalence with eq. (9).",2.3. Training in Expectation,[0],[0]
"As in softmaxbased attention, the ↵
i,j values produce a weighting over the memory, which are then used to compute the context vector at each timestep as in eq.",2.3. Training in Expectation,[0],[0]
(3).,2.3. Training in Expectation,[0],[0]
"However, note that ↵
i may not be a valid probability distribution becauseP j ↵",2.3. Training in Expectation,[0],[0]
"i,j  1.",2.3. Training in Expectation,[0],[0]
"Using ↵ i
as-is, without normalization, effectively associates any additional probability not allocated to memory entries to an additional all-zero memory location.",2.3. Training in Expectation,[0],[0]
"Normalizing ↵
i
so that P T
j=1 ↵i,j = 1 has two issues: First, we can’t perform this normalization at test time and still achieve online decoding because the normalization depends on ↵
i,j for j 2 {1, . . .",2.3. Training in Expectation,[0],[0]
", T}, and second, it would result in a mismatch compared to the probability distribution induced by the hard monotonic attention process which sets c
i to a vector of zeros when z i,j = 0 for j 2 {t i 1, . . .",2.3. Training in Expectation,[0],[0]
", T}.
Note that computing c",2.3. Training in Expectation,[0],[0]
"i still has a quadratic complexity because we must compute ↵
i,j for j 2 {1, . . .",2.3. Training in Expectation,[0],[0]
", T} for each output timestep i.",2.3. Training in Expectation,[0],[0]
"However, because we are training directly with respect to the expected value of c
i , we will train our decoders using eqs.",2.3. Training in Expectation,[0],[0]
"(11) to (14) and then use the online, linear-time attention process of section 2.2 at test time.",2.3. Training in Expectation,[0],[0]
"Furthermore, if p
i,j 2 {0, 1} these approaches are equivalent, so in order for the model to exhibit similar behavior at training and test time, we need p
i,j ⇡ 0 or p i,j ⇡ 1.",2.3. Training in Expectation,[0],[0]
We address this in section 2.5.,2.3. Training in Expectation,[0],[0]
"While various “energy functions” a(·) have been proposed, the most common to our knowledge is the one proposed in (Bahdanau et al., 2015):
a(s",2.4. Modified Energy Function,[0],[0]
"i 1, hj) = v > tanh(Ws i 1 + V hj + b) (15)
where W and V are weight matrices, b is a bias vector,1 and v is a weight vector.",2.4. Modified Energy Function,[0],[0]
We make two modifications to eq.,2.4. Modified Energy Function,[0],[0]
"(15) for use with our monotonic decoder: First, while the softmax is invariant to offset,2 the logistic sigmoid is not.",2.4. Modified Energy Function,[0],[0]
"As a result, we make the simple modification of adding a scalar variable r after the tanh function, allowing the model to learn the appropriate offset for the pre-sigmoid activations.",2.4. Modified Energy Function,[0],[0]
Note that eq.,2.4. Modified Energy Function,[0],[0]
"(13) tends to exponentially decay attention over the memory because 1 p
i,j 2",2.4. Modified Energy Function,[0],[0]
"[0, 1]; we therefore initialized r to a negative value prior to training so that 1 p
i,j tends to be close to 1.",2.4. Modified Energy Function,[0],[0]
"Second, the use of the sigmoid nonlinearity in eq.",2.4. Modified Energy Function,[0],[0]
"(12) implies that our mechanism is particularly sensitive to the scale of the energy terms e
i,j , or correspondingly, the scale of the energy vector v. We found an effective solution to this issue was to apply weight normalization (Salimans & Kingma, 2016) to v, replacing it by gv/kvk where g is a scalar parameter.",2.4. Modified Energy Function,[0],[0]
"Initializing g to the inverse square root of the attention hidden dimension worked well for all problems we studied.
",2.4. Modified Energy Function,[0],[0]
"The above produces the energy function
a(s",2.4. Modified Energy Function,[0],[0]
"i 1, hj) =",2.4. Modified Energy Function,[0],[0]
"g
v
>
kvk tanh(Wsi 1 + V hj + b)",2.4. Modified Energy Function,[0],[0]
"+ r (16)
",2.4. Modified Energy Function,[0],[0]
The addition of the two scalar parameters g and r prevented the issues described above in all our experiments while incurring a negligible increase in the number of parameters.,2.4. Modified Energy Function,[0],[0]
"As mentioned above, in order for our mechanism to exhibit similar behavior when training in expectation and when using the hard monotonic attention process at test time, we require that p
i,j ⇡ 0 or p i,j ⇡ 1.",2.5. Encouraging Discreteness,[0],[0]
A straightforward way to encourage this behavior is to add noise before the sigmoid in eq.,2.5. Encouraging Discreteness,[0],[0]
"(12), as was done e.g. in (Frey, 1997; Salakhutdinov & Hinton, 2009; Foerster et al., 2016).",2.5. Encouraging Discreteness,[0],[0]
"We found that simply adding zero-mean, unit-variance Gaussian noise to the pre-sigmoid activations was sufficient in all of our experiments.",2.5. Encouraging Discreteness,[0],[0]
"This approach is similar to the recently proposed Gumbel-Softmax trick (Jang et al., 2016; Maddison et al., 2016), except we did not find it necessary to anneal the temperature as suggested in (Jang et al., 2016).
",2.5. Encouraging Discreteness,[0],[0]
"Note that once we have a model which produces p i,j which are effectively discrete, we can eschew the sampling involved in the process of section 2.2 and instead simply set z
i,j = I(p",2.5. Encouraging Discreteness,[0],[0]
"i,j > ⌧) where I is the indicator function and ⌧ is a threshold.",2.5. Encouraging Discreteness,[0],[0]
"We used this approach in all of our experiments, setting ⌧ = 0.5.",2.5. Encouraging Discreteness,[0],[0]
"Furthermore, at test time we do not add pre-sigmoid noise, making decoding purely deter-
1b is occasionally omitted, but we found it often improves performance and only incurs a modest increase in parameters, so we include it.
",2.5. Encouraging Discreteness,[0],[0]
"2That is, softmax(e) = softmax(e+ r) for any r 2 R.
ministic.",2.5. Encouraging Discreteness,[0],[0]
"Combining all of the above, we present our differentiable approach to training the monotonic alignment decoder in algorithm 2 (appendix A).",2.5. Encouraging Discreteness,[0],[0]
"(Luo et al., 2016) and (Zaremba & Sutskever, 2015) both study a similar framework in which a decoder RNN can decide whether to ingest another entry from the input sequence or emit an entry of the output sequence.",3. Related Work,[0],[0]
"Instead of training in expectation, they maintain the discrete nature of this decision while training and use reinforcement learning (RL) techniques.",3. Related Work,[0],[0]
We initially experimented with RL-based training methods but were unable to find an approach which worked reliably on the different tasks we studied.,3. Related Work,[0],[0]
"Empirically, we also show superior performance to (Luo et al., 2016) on online speech recognition tasks; we did not attempt any of the tasks from (Zaremba & Sutskever, 2015).",3. Related Work,[0],[0]
"(Aharoni & Goldberg, 2016) also study hard monotonic alignments, but their approach requires target alignments computed via a separate statistical alignment algorithm in order to be trained.
",3. Related Work,[0],[0]
"As an alternative approach to monotonic alignments, Connectionist Temporal Classification (CTC) (Graves et al., 2006) and the RNN Transducer (Graves, 2012) both assume that the output sequences consist of symbols, and add an additional “null” symbol which corresponds to “produce no output”.",3. Related Work,[0],[0]
"More closely to our model, (Yu et al., 2016b) similarly add “shift” and “emit” operations to an RNN.",3. Related Work,[0],[0]
"Finally, the Segmental RNN (Kong et al., 2015) treats a segmentation of the input sequence as a latent random variable.",3. Related Work,[0],[0]
"In all cases, the alignment path is marginalized out via a dynamic program in order to obtain a conditional probability distribution over label sequences and train directly with maximum likelihood.",3. Related Work,[0],[0]
These models either require conditional independence assumptions between output symbols or don’t condition the decoder (language model) RNN on the input sequence.,3. Related Work,[0],[0]
We instead follow the framework of attention and marginalize out alignment paths when computing the context vectors,3. Related Work,[0],[0]
"c
i",3. Related Work,[0],[0]
"which are subsequently fed into the decoder RNN, which allows the decoder to condition on its past output as well as the input sequence.",3. Related Work,[0],[0]
Our approach can therefore be seen as a marriage of these CTCstyle techniques and attention.,3. Related Work,[0],[0]
"Separately, instead of performing an approximate search for the most probable output sequence at test time, we use hard alignments which facilitates linear-time decoding.
",3. Related Work,[0],[0]
"A related idea is proposed in (Raffel & Lawson, 2017), where “subsampling” probabilities are assigned to each entry in the memory and a stochastic process is formulated which involves keeping or discarding entries from the input sequence according to the subsampling probabilities.",3. Related Work,[0],[0]
"A dynamic program similar to the one derived in section 2.3 is
then used to compute the expected output which allows for training with standard backpropagation.",3. Related Work,[0],[0]
"Our approach differs in that we utilize an RNN decoder to construct the output sequence, and furthermore allows for output sequences which are longer than the input.
",3. Related Work,[0],[0]
"Some similar ideas to those in section 2.3 were proposed in the context of speech recognition in (Chorowski et al., 2015):",3. Related Work,[0],[0]
"First, the prior attention distributions are convolved with a bank of one-dimensional filters and then included in the energy function calculation.",3. Related Work,[0],[0]
"Second, instead of computing attention over the entire memory they only compute it over a sliding window.",3. Related Work,[0],[0]
This reduces the runtime complexity at the expense of the strong assumption that memory locations attended to at subsequent output timesteps fall within a small window of one another.,3. Related Work,[0],[0]
"Finally, they also advocate replacing the softmax function with a sigmoid, but they then normalize by the sum of these sigmoid activations across the memory window instead of interpreting these probabilities in the left-to-right framework we use.",3. Related Work,[0],[0]
"While these modifications encourage monotonic attention, they do not explicitly enforce it, and so the authors do not investigate online decoding.
",3. Related Work,[0],[0]
"In a similar vein, (Luong et al., 2015) explore only computing attention over a small window of the memory.",3. Related Work,[0],[0]
"In addition to simply monotonically increasing the window location at each output timestep, they also consider learning a policy for producing the center of the memory window based on the current decoder state.
",3. Related Work,[0],[0]
"(Kim et al., 2017) also make the connection between soft attention and selecting items from memory in expectation.",3. Related Work,[0],[0]
"They consider replacing the softmax in standard soft attention with an elementwise sigmoid nonlinearity, but do not formulate the interpretation of addressing memory from left-to-right and the corresponding probability distributions as we do in section 2.3.
",3. Related Work,[0],[0]
"(Jaitly et al., 2015) apply standard softmax attention in online settings by splitting the input sequence into chunks and producing output tokens using the attentive sequence-tosequence framework over each chunk.",3. Related Work,[0],[0]
They then devise a dynamic program for finding the approximate best alignment between the model output and the target sequence.,3. Related Work,[0],[0]
"In contrast, our ingest/emit probabilities p
i,j can be seen as adaptively chunking the input sequence (rather than providing a fixed setting of the chunk size) and we instead train by exactly computing the expectation over alignment paths.",3. Related Work,[0],[0]
"To validate our proposed approach for learning monotonic alignments, we applied it to a variety of sequenceto-sequence problems: sentence summarization, machine translation, and online speech recognition.",4. Experiments,[0],[0]
"In the follow-
ing subsections, we give an overview of the models used and the results we obtained; for more details about hyperparamers and training specifics please see appendix D. Incidentally, all experiments involved predicting discrete symbols (e.g. phonemes, characters, or words); as a result, the output of the decoder in each of our models was fed into an affine transformation followed by a softmax nonlinearity with a dimensionality corresponding to the number of possible symbols.",4. Experiments,[0],[0]
"At test time, we performed a beam search over softmax predictions on all problems except machine translation.",4. Experiments,[0],[0]
"All networks were trained using standard cross-entropy loss with teacher forcing against target sequences using the Adam optimizer (Kingma & Ba, 2014).",4. Experiments,[0],[0]
All of our decoders used the monotonic attention mechanism of section 2.3 during training to address the hidden states of the encoder.,4. Experiments,[0],[0]
"For comparison, we report test-time results using both the hard linear-time decoding method of section 2.2 and the “soft” monotonic attention distribution.",4. Experiments,[0],[0]
"We also present the results of a synthetic benchmark we used to measure the potential speedup offered by our linear-time decoding process in appendix F.
Online Speech Recognition Online speech recognition involves transcribing the words spoken in a speech utterance in real-time, i.e. as a person is talking.",4. Experiments,[0],[0]
This problem is a natural application for monotonic alignments because online decoding is an explicit requirement.,4. Experiments,[0],[0]
"In addition, this precludes the use of bidirectional RNNs, which degrades performance somewhat (Graves et al., 2013).",4. Experiments,[0],[0]
"We tested our approach on two datasets: TIMIT (Garofolo et al., 1993) and the Wall Street Journal corpus (Paul & Baker, 1992).
",4. Experiments,[0],[0]
Speech recognition on the TIMIT dataset involves transcribing the phoneme sequence underlying a given speech utterance.,4. Experiments,[0],[0]
Speech utterances were represented as sequences of 40-filter (plus energy),4. Experiments,[0],[0]
"mel-filterbank spectra, computed every 10 milliseconds, with delta- and deltadelta-features.",4. Experiments,[0],[0]
Our encoder RNN consisted of three unidirectional LSTM layers.,4. Experiments,[0],[0]
"Following (Chan et al., 2016), after the first and second LSTM layer we placed time reduction layers which skip every other sequence element.",4. Experiments,[0],[0]
Our decoder RNN was a single unidirectional LSTM.,4. Experiments,[0],[0]
"Our output softmax had 62 dimensions, corresponding to the 60 phonemes from TIMIT plus special start-of-sequence and end-of-sequence tokens.",4. Experiments,[0],[0]
"At test time, we utilized a beam search over softmax predictions, with a beam width of 10.",4. Experiments,[0],[0]
"We report the phone error rate (PER) after applying the standard mapping to 39 phonemes (Graves et al., 2013).",4. Experiments,[0],[0]
"We used the standard train/validation/test split and report results on the test set.
",4. Experiments,[0],[0]
"Our model’s performance, with a comparison to other online approaches, is shown in table 1.",4. Experiments,[0],[0]
"We achieve better performance than recently proposed sequence-to-sequence models (Luo et al., 2016; Jaitly et al., 2015), though the
small size of the TIMIT dataset and the resulting variability of results precludes making substantiative claims about one approach being best.",4. Experiments,[0],[0]
"We note that (Jaitly et al., 2015) were able to improve performance by precomputing alignments using an HMM system and providing them as a supervised signal to their decoder; we did not experiment with this idea.",4. Experiments,[0],[0]
"CTC (Graves et al., 2013) still outperforms all sequence-to-sequence models.",4. Experiments,[0],[0]
"In addition, there remains a substantial gap between these online results and offline results using bidirectional LSTMs, e.g. (Chorowski et al., 2015) achieves a 17.6% phone error rate using a softmax-based attention mechanism and (Graves et al., 2013) achieved 17.7% using a pre-trained RNN transducer model.",4. Experiments,[0],[0]
"We are interested in investigating ways to close this gap in future work.
",4. Experiments,[0],[0]
"Because of the size of the dataset, performance on TIMIT is often highly dependent on appropriate regularization.",4. Experiments,[0],[0]
"We therefore also evaluated our approach on the Wall Street Journal (WSJ) speech recognition dataset, which is about 10 times larger.",4. Experiments,[0],[0]
"For the WSJ corpus, we present speech utterances to the network as 80-filter mel-filterbank spectra with delta- and delta-delta features, and normalized using per-speaker mean and variance computed offline.",4. Experiments,[0],[0]
"The model architecture is a variation of that from (Zhang et al., 2016), using an 8 layer encoder including: two convolutional layers which downsample the sequence in time, followed by one unidirectional convolutional LSTM layer, and finally a stack of three unidirectional LSTM layers interleaved with linear projection layers and batch normalization.",4. Experiments,[0],[0]
"The encoder output sequence is consumed by the proposed online attention mechanism which is passed into a decoder consisting of a single unidirectional LSTM layer followed by a softmax layer.
",4. Experiments,[0],[0]
"Our output softmax predicted one of 49 symbols, consisting of alphanumeric characters, punctuation marks, and start-of sequence, end-of-sequence, “unknown”, “noise”, and word delimiter tokens.",4. Experiments,[0],[0]
"We utilized label smoothing during training (Chorowski & Jaitly, 2017), replacing the targets at time y
t with a convex weighted combination of the surrounding five labels (full details in appendix D.1.2).",4. Experiments,[0],[0]
"Performance was measured in terms of word error rate (WER) on the test set after segmenting the model’s predic-
tions according to the word delimiter tokens.",4. Experiments,[0],[0]
"We used the standard dataset split of si284 for training, dev93 for validation, and eval92 for testing.",4. Experiments,[0],[0]
"We did not use a language model to improve decoding performance.
",4. Experiments,[0],[0]
Our results on WSJ are shown in table 2.,4. Experiments,[0],[0]
"Our model, with hard monotonic decoding, achieved a significantly lower WER than the other online methods.",4. Experiments,[0],[0]
"While these figures show a clear advantage to our approach, our model architecture differed significantly from those of (Luo et al., 2016; Wang et al., 2016).",4. Experiments,[0],[0]
We therefore additionally measured performance against a baseline model which was identical to our model except that it used softmax-based attention (which makes it quadratic-time and offline) instead of a monotonic alignment decoder.,4. Experiments,[0],[0]
"This resulted in a small decrease of 1.4% WER, suggesting that our hard monotonic attention approach achieves competitive performance while being substantially more efficient.",4. Experiments,[0],[0]
"To get a qualitative picture of our model’s behavior compared to the softmax-attention baseline, we plot each model’s inputoutput alignments for two example speech utterances in fig.",4. Experiments,[0],[0]
4 (appendix B).,4. Experiments,[0],[0]
"Both models learn roughly the same alignment, with some minor differences caused by ours being both hard and strictly monotonic.
",4. Experiments,[0],[0]
Sentence Summarization Speech recognition exhibits a strictly monotonic input-output alignment.,4. Experiments,[0],[0]
We are interested in testing whether our approach is also effective on problems which only exhibit approximately monotonic alignments.,4. Experiments,[0],[0]
"We therefore ran a “sentence summarization” experiment using the Gigaword corpus, which involves predicting the headline of a news article from its first sentence.
",4. Experiments,[0],[0]
"Overall, we used the model of (Liu & Pan, 2016), modifying it only so that it used our monotonic alignment decoder instead of a soft attention decoder.",4. Experiments,[0],[0]
"Because online decoding is not important for sentence summarization, we utilized bidirectional RNNs in the encoder for this task (as is standard).",4. Experiments,[0],[0]
We expect that the bidirectional RNNs will give the model local context which may help allow for strictly monotonic alignments.,4. Experiments,[0],[0]
"The model both took as input and produced as output one-hot representations of the word IDs, with a vocabulary of the 200,000 most common words in the training set.",4. Experiments,[0],[0]
"Our encoder consisted of
a word embedding matrix (which was initialized randomly and trained as part of the model) followed by four bidirectional LSTM layers.",4. Experiments,[0],[0]
We used a single LSTM layer for the decoder.,4. Experiments,[0],[0]
"For data preparation and evaluation, we followed the approach of (Rush et al., 2015), measuring performance using the ROUGE metric.
",4. Experiments,[0],[0]
"Our results, along with the scores achieved by other approaches, are presented in table 3.",4. Experiments,[0],[0]
"While the monotonic alignment model outperformed existing models by a substantial margin, it fell slightly behind the model of (Liu & Pan, 2016) which we used as a baseline.",4. Experiments,[0],[0]
"The higher performance of our model and the model of (Liu & Pan, 2016) can be partially explained by the fact that their encoders have roughly twice as many layers as most models proposed in the literature.
",4. Experiments,[0],[0]
"For qualitative evaluation, we plot an example input-output
pair and alignment matrices for our hard monotonic attention model and the softmax-attention baseline of (Liu & Pan, 2016) in fig.",4. Experiments,[0],[0]
3 (an additional example is shown in fig.,4. Experiments,[0],[0]
"6, appendix B).",4. Experiments,[0],[0]
"Most apparent is that a given word in the summary is not always aligned to the most obvious word in the input sentence; the hard monotonic decoder aligns the first four words in the summary reasonably (greek $ greek, government $ finance, approves $ approved, more $ more), but the latter four words have unexpected alignments (funds $ in, to $ for, bird $ measures, bird $ flu).",4. Experiments,[0],[0]
We believe this is due to the ability of the multilayer bidirectional RNN encoder to reorder words in the input sequence.,4. Experiments,[0],[0]
This effect is also apparent in fig.,4. Experiments,[0],[0]
"6/ (appendix B), where the monotonic alignment decoder is able to produce the phrase “human rights criticism” despite the fact that the input sentence has the phrase “criticism of human rights”.",4. Experiments,[0],[0]
"Separately, we note that the softmax attention model’s alignments are extremely “soft” and nonmonotonic; this may be advantageous for this problem and partially explain its slightly superior performance.
",4. Experiments,[0],[0]
"Machine Translation We also evaluated our approach on machine translation, another task which does not exhibit strictly monotonic alignments.",4. Experiments,[0],[0]
"In fact, for some language pairs (e.g. English and Japanese, English and Korean), we do not expect monotonicity at all.",4. Experiments,[0],[0]
"However, for other pairs (e.g. English and French, English and Vietnamese) only local word reorderings are required.",4. Experiments,[0],[0]
"Our translation experiments therefore involved English to Vietnamese translation using the parallel corpus of TED talks (133K sentence pairs) provided by the IWSLT 2015 Evaluation Campaign (Cettolo et al., 2015).",4. Experiments,[0],[0]
"Following (Luong & Manning, 2015), we tokenize the corpus with the default Moses tokenizer, preserve casing, and replace words whose frequencies are less than 5 by <unk>.",4. Experiments,[0],[0]
"As a result, our vocabulary sizes are 17K and 7.7K for English and Vietnamese respectively.",4. Experiments,[0],[0]
We use the TED tst2012 (1553 sentences) as a validation set for hyperparameter tuning and TED tst2013 (1268 sentences) as a test set.,4. Experiments,[0],[0]
"We report results in both perplexity and BLEU.
",4. Experiments,[0],[0]
"Our baseline neural machine translation (NMT) system is the softmax attention-based sequence-to-sequence model described in (Luong et al., 2015).",4. Experiments,[0],[0]
"From that baseline, we substitute the softmax-based attention mechanism with our proposed monotonic alignment decoder.",4. Experiments,[0],[0]
"The model utilizes two-layer unidirectional LSTM networks for both the encoder and decoder.
",4. Experiments,[0],[0]
"In (Luong et al., 2015), the authors demonstrated that under their proposed architecture, a dot product-based energy function worked better than eq. (15).",4. Experiments,[0],[0]
"Since our architecture is based on that of (Luong et al., 2015), to facilitate comparison we also tested the following variant:
a(s",4. Experiments,[0],[0]
"i 1, hj) =",4. Experiments,[0],[0]
g(s > i 1Wh) +,4. Experiments,[0],[0]
"r (17)
where g and r are scalars (initialized as in section 2.4) and W is a weight matrix.
",4. Experiments,[0],[0]
Our results are shown in Table 4.,4. Experiments,[0],[0]
"To get a better picture of each model’s behavior, we plot input-output alignments in fig.",4. Experiments,[0],[0]
5 (appendix B).,4. Experiments,[0],[0]
Most noticeable is that the monotonic alignment model tends to focus attention later in the input sequence than the baseline softmax-attention model.,4. Experiments,[0],[0]
"We hypothesize that this is a way to compensate for non-monotonic alignments when a unidirectional encoder is used; i.e. the model has effectively learned to focus on words at the end of phrases which require reordering, at which point the unidirectional encoder has observed the whole phrase.",4. Experiments,[0],[0]
"This can be seen most clearly in the example on the right, where translating “a huge famine” to Vietnamese requires reordering (as suggested by the softmax-attention model’s alignment), so the hard monotonic alignment model focuses attention on the final word in the phrase (“famine”) while producing its translation.",4. Experiments,[0],[0]
We suspect our model’s small decrease in BLEU compared to the baseline model may be due in part to this increased modeling burden.,4. Experiments,[0],[0]
"Our results show that our differentiable approach to enforcing monotonic alignments can produce models which, following the decoding process of section 2.2, provide efficient online decoding at test time without sacrificing substantial performance on a wide variety of tasks.",5. Discussion,[0],[0]
We believe our framework presents a promising environment for future work on online and linear-time sequence-to-sequence models.,5. Discussion,[0],[0]
"We are interested in investigating various extensions to this approach, which we outline in appendix E. To facilitate experimentation with our proposed attention mechanism, we have made an example TensorFlow",5. Discussion,[0],[0]
"(Abadi et al., 2016) implementation of our approach available online3 and added a reference implementation to TensorFlow’s tf.contrib.seq2seq module.",5. Discussion,[0],[0]
"We also provide a “practitioner’s guide” in appendix G.
3 https://github.com/craffel/mad",5. Discussion,[0],[0]
"We thank Jan Chorowski, Mark Daoust, Pietro Kreitlon Carolino, Dieterich Lawson, Navdeep Jaitly, George Tucker, Quoc V. Le, Kelvin Xu, Cinjon Resnick, Melody Guan, Matthew D. Hoffman, Jeffrey Dean, Kevin Swersky, Ashish Vaswani, and members of the Google Brain team for helpful discussions and insight.",Acknowledgements,[0],[0]
Recurrent neural network models with an attention mechanism have proven to be extremely effective on a wide variety of sequence-tosequence problems.,abstractText,[0],[0]
"However, the fact that soft attention mechanisms perform a pass over the entire input sequence when producing each element in the output sequence precludes their use in online settings and results in a quadratic time complexity.",abstractText,[0],[0]
"Based on the insight that the alignment between input and output sequence elements is monotonic in many problems of interest, we propose an end-to-end differentiable method for learning monotonic alignments which, at test time, enables computing attention online and in linear time.",abstractText,[0],[0]
"We validate our approach on sentence summarization, machine translation, and online speech recognition problems and achieve results competitive with existing sequence-tosequence models.",abstractText,[0],[0]
Online and Linear-Time Attention by Enforcing Monotonic Alignments,title,[0],[0]
"Convolutional sparse coding (CSC) (Zeiler et al., 2010) has been successfully used in image processing (Gu et al., 2015; Heide et al., 2015), signal processing (Cogliati et al., 2016), and biomedical applications (Pachitariu et al., 2013; Andilla & Hamprecht, 2014; Chang et al., 2017; Jas et al., 2017; Peter et al., 2017).",1. Introduction,[0],[0]
"It is closely related to sparse coding (Aharon et al., 2006), but CSC is advantageous in that its shift-invariant dictionary can capture shifted local patterns common in signals and images.",1. Introduction,[0],[0]
"Each data sample is then represented by the sum of a set of filters from the dictionary convolved with the corresponding codes.
",1. Introduction,[0],[0]
"Traditional CSC algorithms operate in the batch mode 1Department of Computer Science and Engineering, Hong Kong University of Science and Technology University, Hong Kong 24Paradigm Inc, Beijing, China.",1. Introduction,[0],[0]
"3Department of Computer and Information Science, University of Macau, Macau.",1. Introduction,[0],[0]
Correspondence to: jamesk@cse.ust.hk <,1. Introduction,[0],[0]
"James T. Kwok>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"(Kavukcuoglu et al., 2010; Zeiler et al., 2010; Bristow et al., 2013; Heide et al., 2015; Šorel & Šroubek, 2016; Wohlberg, 2016; Papyan et al., 2017), which take O(NK2P + NKP logP ) time and O(NKP ) space (where N is the number of samples, K is the number of filters, and P is the dimensionality.",1. Introduction,[0],[0]
"Recently, a number of online CSC algorithms have been proposed for better scalability (Degraux et al., 2017; Liu et al., 2017; Wang et al., 2018).",1. Introduction,[0],[0]
"As data samples arrive, relevant information is compressed into small history statistics, and the model is incrementally updated.",1. Introduction,[0],[0]
"In particular, the state-of-the-art OCSC algorithm (Wang et al., 2018) has the much smaller time and space complexities of O(K2P +KP logP ) and O(K2P ), respectively.
",1. Introduction,[0],[0]
"However, the complexities of OCSC still depend quadratically on K, and cannot be used with a large number of filters.",1. Introduction,[0],[0]
"The number of local patterns that can be captured is thus limited, and may lead to inferior performance especially on higher-dimensional data sets.",1. Introduction,[0],[0]
"Besides, the use of more filters also leads to a larger number of expensive convolution operations.",1. Introduction,[0],[0]
"Rigamonti et al. (2013) and Sironi et al. (2015) proposed to post-process the learned filters by approximating them with separable filters, making the convolutions less expensive.",1. Introduction,[0],[0]
"However, as learning and post-processing are then two independent procedures, the resultant filters may not be optimal.",1. Introduction,[0],[0]
"Moreover, these separate filters cannot be updated online with the arrival of new samples.
",1. Introduction,[0],[0]
"Another direction to scale up CSC is via distributed computation (Bertsekas & Tsitsiklis, 1997).",1. Introduction,[0],[0]
"By distributing the data and workload onto multiple machines, the recent consensus CSC algorithm (Choudhury et al., 2017) can handle large, higher-dimensional data sets such as videos, multispectral images and light field images.",1. Introduction,[0],[0]
"However, the heavy computational demands of the CSC problem are only shared over the computing platform, but not fundamentally reduced.
",1. Introduction,[0],[0]
"In this paper, we propose to approximate the possibly large number of filters by a sample-dependent combination of a small set of base filters learned from the data.",1. Introduction,[0],[0]
"While the standard CSC dictionary is shared by all samples, we propose each sample to have its own “personal” dictionary to compensate for the reduced flexibility of using these
base filters.",1. Introduction,[0],[0]
"In this way, the representation power can remain the same but with a reduced number of parameters.",1. Introduction,[0],[0]
"Computationally, this structure also allows efficient online learning algorithms to be developed.",1. Introduction,[0],[0]
"Specifically, the base filter can be updated by the alternating direction method of multipliers (ADMM) (Boyd et al., 2011), while the codes and combination weights can be learned by accelerated proximal algorithms (Yao et al., 2017).",1. Introduction,[0],[0]
"Extensive experimental results on a variety of data sets show that the proposed algorithm is more efficient in both time and space, and outperforms existing batch, online and distributed CSC algorithms.
",1. Introduction,[0],[0]
The rest of the paper is organized as follows.,1. Introduction,[0],[0]
Section 2 briefly reviews convolutional sparse coding.,1. Introduction,[0],[0]
Section 3 describes the proposed algorithm.,1. Introduction,[0],[0]
"Experimental results are presented in Section 4, and the last section gives some concluding remarks.
Notations: For a vector a, its ith element is a(i), `1-norm is kak1 = P i |a(i)|",1. Introduction,[0],[0]
"and `2-norm is kak2 = pP i a
2(i).",1. Introduction,[0],[0]
The convolution of two vectors a and b is denoted a ⇤ b.,1. Introduction,[0],[0]
"For a matrix A, A? is its complex conjugate, and A† =",1. Introduction,[0],[0]
(A>)?,1. Introduction,[0],[0]
its conjugate transpose.,1. Introduction,[0],[0]
"The Hadamard product of two matrices A and B is (A B)(i, j) = A(i, j)B(i, j).",1. Introduction,[0],[0]
The identity matrix is denoted I .,1. Introduction,[0],[0]
"F(x) is the Fourier transform that maps x from the spatial domain to the frequency domain, while F 1(x) is the inverse operator which maps F(x) back to x.",1. Introduction,[0],[0]
"Given samples {x1, . . .",2. Review: Convolutional Sparse Coding,[0],[0]
", xN} in RP , CSC learns a shiftinvariant dictionary D 2 RM⇥K , with the columns {D(: , k)} representing the K filters.",2. Review: Convolutional Sparse Coding,[0],[0]
"Each sample xi is encoded as Zi 2 RP⇥K , with the kth column being the code convolved with filter D(:, k).",2. Review: Convolutional Sparse Coding,[0],[0]
"The dictionary and codes are learned together by solving the optimization problem:
min D2D,{Zi}
1
N
NX
i=1
1
2
xi KX
k=1
D(:, k)⇤Zi(:, k)
2
2
+ kZik1,
(1) where the first term measures the signal reconstruction error, D = {D : kD(:, k)k2  1, 8k = 1, . . .",2. Review: Convolutional Sparse Coding,[0],[0]
",K} ensures that the filters are normalized, and > 0 is a regularization parameter controlling the sparsity of Zi’s.
",2. Review: Convolutional Sparse Coding,[0],[0]
Convolution in (1) is performed in the spatial domain.,2. Review: Convolutional Sparse Coding,[0],[0]
"This takes O(KPM) time, and is expensive.",2. Review: Convolutional Sparse Coding,[0],[0]
"In contrast, recent CSC methods perform convolution in the frequency domain, which takes O(KP logP ) time (Mallat, 1999) and is faster for typical choices of M and P .",2. Review: Convolutional Sparse Coding,[0],[0]
"Let x̃i ⌘ F(xi), D̃(:, k) ⌘ F(D(:, k)), and Z̃i(:, k) ⌘ F(Zi(:, k))",2. Review: Convolutional Sparse Coding,[0],[0]
"be the Fourier-transformed counterparts of xi, D(:, k) and Zi(:, k).",2. Review: Convolutional Sparse Coding,[0],[0]
"The codes and filters are updated in an alternating manner by block coordinate descent, as:
Update Codes: Given D̃, each Z̃i is independently obtained as
min Z̃i,Ui
1
2P
x̃i KX
k=1
D̃(:, k) Z̃i",2. Review: Convolutional Sparse Coding,[0],[0]
"(:, k)
2
2
+ kUik1",2. Review: Convolutional Sparse Coding,[0],[0]
"(2)
s.t. F(Ui(:, k))",2. Review: Convolutional Sparse Coding,[0],[0]
"= Z̃i(:, k), k = 1, . . .",2. Review: Convolutional Sparse Coding,[0],[0]
",K,
where Ui is an auxiliary variable.
",2. Review: Convolutional Sparse Coding,[0],[0]
"Update Dictionary: D̃ is updated by solving
minD̃,V 1
2NP
NX
i=1
x̃i KX
k=1
D̃(:, k) Z̃i",2. Review: Convolutional Sparse Coding,[0],[0]
"(:, k)
2
2
(3)
s.t. F(V (:, k))",2. Review: Convolutional Sparse Coding,[0],[0]
"= D̃(:, k), k = 1, . . .",2. Review: Convolutional Sparse Coding,[0],[0]
",K, kC(V (:, k))k22  1, k = 1, . . .",2. Review: Convolutional Sparse Coding,[0],[0]
",K,
where V is an auxiliary variable, and C(·) crops the extra P M dimensions in V (:, k).
",2. Review: Convolutional Sparse Coding,[0],[0]
"Both (2) and (3) can be solved by the alternating direction method of multipliers (ADMM) (Boyd et al., 2011).",2. Review: Convolutional Sparse Coding,[0],[0]
"Subsequently, {Z̃i} and D̃ can be transformed back to the spatial domain as Zi(:, k) = F 1(Z̃i(:, k))",2. Review: Convolutional Sparse Coding,[0],[0]
"and D(: , k) = C(F 1(D̃(:, k))).",2. Review: Convolutional Sparse Coding,[0],[0]
"Note that while Zi’s (in the spatial domain) are sparse, the FFT-transformed Z̃i’s are not.
",2. Review: Convolutional Sparse Coding,[0],[0]
"On inference, given the learned dictionary D, the testing sample xj is reconstructed as PK k=1 D(:, k)",2. Review: Convolutional Sparse Coding,[0],[0]
"⇤ Zj(:, k), where Zj is the obtained code.",2. Review: Convolutional Sparse Coding,[0],[0]
Filters obtained by CSC are non-separable and subsequent convolutions may be slow.,2.1. Post-Processing for Separable Filters,[0],[0]
"To speed this up, they can be postprocessed and approximated by separable filters (Rigamonti et al., 2013; Sironi et al., 2015).",2.1. Post-Processing for Separable Filters,[0],[0]
"Specifically, the learned D is approximated by SW , where S 2 RM⇥R contains R rank-1 base filters {S(:, 1), . . .",2.1. Post-Processing for Separable Filters,[0],[0]
", S(:, R)}, and W 2 RR⇥K contains the combination weights.",2.1. Post-Processing for Separable Filters,[0],[0]
"However, this often leads to performance deterioration.",2.1. Post-Processing for Separable Filters,[0],[0]
"An online CSC algorithm (OCSC) is recently proposed in (Wang et al., 2018).",2.2. Online CSC,[0],[0]
"Given the Fourier-transformed sample x̃t and dictionary D̃t 1 from the last iteration, the corresponding {Z̃t, Ut} are obtained as in (2).",2.2. Online CSC,[0],[0]
"The following Proposition updates D̃t and Vt by reformulating (3) for use with smaller history statistics.
",2.2. Online CSC,[0],[0]
"Proposition 1 ((Wang et al., 2018)).",2.2. Online CSC,[0],[0]
"D̃t,",2.2. Online CSC,[0],[0]
"Vt can be obtained
by solving the optimization problem:
minD̃,V 1
2P
PX
p=1
D̃(p, :)",2.2. Online CSC,[0],[0]
"Ht(:, :, p)D̃ †(:, p)
2D̃(p, :)Gt(:, p) (4) s.t. F(V (:, k))",2.2. Online CSC,[0],[0]
"= D̃(:, k), k = 1, . . .",2.2. Online CSC,[0],[0]
",K,
kC(V (:, k))k22  1, k = 1, . . .",2.2. Online CSC,[0],[0]
",K,
where Ht(:, :, p)= 1 t",2.2. Online CSC,[0],[0]
"Pt i=1 Z̃ > i (:, p)Z̃ ?",2.2. Online CSC,[0],[0]
"i (p, :)2RK⇥K , and Gt(:, p)= 1 t",2.2. Online CSC,[0],[0]
Pt i=1,2.2. Online CSC,[0],[0]
x̃ ?,2.2. Online CSC,[0],[0]
"i (p)Z̃ > i (:, p)2RK .
",2.2. Online CSC,[0],[0]
Problem (4) can be solved by ADMM.,2.2. Online CSC,[0],[0]
"The total space complexity is only O(K2P ), which is independent of N .",2.2. Online CSC,[0],[0]
"Moreover, Ht and Gt can be updated incrementally.
",2.2. Online CSC,[0],[0]
Two other online CSC reformulations have also been proposed recently.,2.2. Online CSC,[0],[0]
"Degraux et al. (2017) performs convolution in the spatial domain, and is slow.",2.2. Online CSC,[0],[0]
"Liu et al. (2017) performs convolution in the frequency domain, but requires expensive huge sparse matrix operations.",2.2. Online CSC,[0],[0]
"Though OCSC scales well with sample size N , its space complexity still depends on K quadratically.",3. Online CSC with Sample-Dependent Dictionary,[0],[0]
This limits the number of filters that can be used and can impact performance.,3. Online CSC with Sample-Dependent Dictionary,[0],[0]
"Motivated by the ideas of separable filters in Section 2.1, we enable learning with more filters by approximating the K filters with R base filters, where R ⌧ K.",3. Online CSC with Sample-Dependent Dictionary,[0],[0]
"In contrast to the separable filters, which are obtained by post-processing and may not be optimal, we propose to learn the dictionary directly during signal reconstruction.",3. Online CSC with Sample-Dependent Dictionary,[0],[0]
"Moreover, filters in the dictionary are combined from the base filters in a sample-dependent manner.",3. Online CSC with Sample-Dependent Dictionary,[0],[0]
"Recall that each xi in (1) is represented by PK
k=1 D(:, k) ⇤ Zi(:, k).",3.1. Problem Formulation,[0],[0]
"Let B 2 RM⇥R, with columns {B(:, r)} being the base filters.",3.1. Problem Formulation,[0],[0]
"We propose to represent xi as:
xi = KX
k=1
RX
r=1
Wi(r, k)B(:, r) !",3.1. Problem Formulation,[0],[0]
"⇤ Zi(:, k), (5)
where Wi 2 RR⇥K is the matrix for the filter combination weights.",3.1. Problem Formulation,[0],[0]
"In other words, each D(:, k) in (1) is replaced byPR
r=1 Wi(r, k)B(:, r), or equivalently,
Di = BWi, (6)
which is sample-dependent.",3.1. Problem Formulation,[0],[0]
"As will be seen, this allows the Wi’s to be learned independently (Section 3.3).",3.1. Problem Formulation,[0],[0]
"This also leads to more sample-dependent patterns being captured and thus better performance (Section 4.4).
",3.1. Problem Formulation,[0],[0]
Sample-dependent filters have been recently studied in convolutional neural networks (CNN),3.1. Problem Formulation,[0],[0]
"(Jia et al., 2016).",3.1. Problem Formulation,[0],[0]
"Empirically, this outperforms standard CNNs in one-shot learning (Bertinetto et al., 2016), video prediction (Jia et al., 2016) and image deblurring (Kang et al., 2017).",3.1. Problem Formulation,[0],[0]
"Jia et al. (2016) uses a specially designed neural network to learn the filters, and does not consider the CSC model.",3.1. Problem Formulation,[0],[0]
"In contrast, the sample-dependent filters here are integrated into CSC.
",3.1. Problem Formulation,[0],[0]
"The dictionary can also be adapted to individual samples by fine-tuning (Donahue et al., 2014).",3.1. Problem Formulation,[0],[0]
"However, learning the initial shared dictionary is still expensive when K is large.",3.1. Problem Formulation,[0],[0]
"Besides, as will be shown in Section 4.2, the proposed method outperforms fine-tuning empirically.",3.1. Problem Formulation,[0],[0]
"Plugging (6) into the CSC formulation in (1), we obtain
minB,{Wi,Zi} 1
N
NX
i=1
fi(B,Wi, Zi) + kZik1",3.2. Learning,[0],[0]
"(7)
s.t. BWi 2 D, i = 1, . .",3.2. Learning,[0],[0]
.,3.2. Learning,[0],[0]
", N, (8) B 2 B, (9)
",3.2. Learning,[0],[0]
"where
fi(B,Wi, Zi)⌘ 1
2
xi KX
k=1
RX
r=1
Wi(r, k)B(:, r) !",3.2. Learning,[0],[0]
"⇤Zi(:, k) 2
2
,
and B ⌘ {B : kB(:, r)k2  1, 8 r = 1, . . .",3.2. Learning,[0],[0]
", R}.",3.2. Learning,[0],[0]
"As B and Wi are coupled together in (8), this makes the optimization problem difficult.",3.2. Learning,[0],[0]
The following Proposition decouples B and Wi.,3.2. Learning,[0],[0]
"All the proofs are in the Appendix.
",3.2. Learning,[0],[0]
Proposition 2.,3.2. Learning,[0],[0]
"For B 2 B, we have BWi 2 D if (i) Wi 2 W`1",3.2. Learning,[0],[0]
"⌘ {W : kWi(:, k)k1  1, k = 1, . . .",3.2. Learning,[0],[0]
",K}, or (ii) Wi 2 W`2 ⌘ {W : kWi(:, k)k2  1/ p R, k = 1, . . .",3.2. Learning,[0],[0]
",K}.
To simplify notations, we use W to denote W`1 or W`2.",3.2. Learning,[0],[0]
"By imposing either one of the above structures on {Wi}, we have the following optimization problem:
minB,{Wi,Zi} 1
N
NX
i=1
fi(B,Wi, Zi) + kZik1 (10)
s.t. B 2 B, and Wi 2 W, i = 1, . . .",3.2. Learning,[0],[0]
", N.
On inference with sample xj , the corresponding (Wj , Zj) can be obtained by solving (10) with the learned B fixed.",3.2. Learning,[0],[0]
"As in Section 2.2, we propose an online algorithm for better scalability.",3.3. Online Learning Algorithm for (10),[0],[0]
"At the tth iteration, consider
minB,{Wi,Zi} 1
t
tX
i=1
fi(B,Wi, Zi) + kZik1",3.3. Online Learning Algorithm for (10),[0],[0]
"(11)
s.t. B 2 B, and Wi 2 W, i = 1, . . .",3.3. Online Learning Algorithm for (10),[0],[0]
", N.
Let B̃(:, r) ⌘ F(B(:, r)), where B(:, r) 2 RM is zeropadded to be P -dimensional.",3.3. Online Learning Algorithm for (10),[0],[0]
"Note that the number of convolutions can be reduced from K to R by rewriting the summation above as PR r=1 B(:, r)",3.3. Online Learning Algorithm for (10),[0],[0]
"⇤ ( PK k=1 Wi(r, k)Zi(: , k)).",3.3. Online Learning Algorithm for (10),[0],[0]
The following Proposition rewrites (11) and performs convolutions in the frequency domain.,3.3. Online Learning Algorithm for (10),[0],[0]
Proposition 3.,3.3. Online Learning Algorithm for (10),[0],[0]
"Problem (11) can be rewritten as
minB̃,{Wi,Zi} 1
t
tX
i=1
f̃i(B̃,Wi, Zi)+ kZik1",3.3. Online Learning Algorithm for (10),[0],[0]
"(12)
s.t. kC(F",3.3. Online Learning Algorithm for (10),[0],[0]
"1(B̃(:, r)))k21, r = 1, . . .",3.3. Online Learning Algorithm for (10),[0],[0]
", R, Wi 2 W, i = 1, . . .",3.3. Online Learning Algorithm for (10),[0],[0]
", N,
where f̃i(B̃,Wi, Zi) ⌘ 12P kx̃i PR
r=1 B̃(:, r) Ỹi(:, r)k22, and Ỹi(:, r) ⌘",3.3. Online Learning Algorithm for (10),[0],[0]
"F(ZiW>i (:, r)).
",3.3. Online Learning Algorithm for (10),[0],[0]
"The spatial-domain base filters can be recovered from B̃ as B(:, r) = C(F 1(B̃(:, r))).
",3.3. Online Learning Algorithm for (10),[0],[0]
3.3.1.,3.3. Online Learning Algorithm for (10),[0],[0]
"OBTAINING B̃t
",3.3. Online Learning Algorithm for (10),[0],[0]
"From (12), B̃t can be obtained by solving the subproblem:
minB̃,V̄ 1
2tP
tX
i=1
x̃i RX
r=1
B̃(:, r) Ỹi(:, r)
2
2
s.t. F(V̄ (:, r))",3.3. Online Learning Algorithm for (10),[0],[0]
"= B̃(:, r), r = 1, . . .",3.3. Online Learning Algorithm for (10),[0],[0]
", R, kC(V̄ (:, r))k2  1, r = 1, . . .",3.3. Online Learning Algorithm for (10),[0],[0]
", R,
where V̄ is an auxiliary variable.",3.3. Online Learning Algorithm for (10),[0],[0]
This is of the same form as (3).,3.3. Online Learning Algorithm for (10),[0],[0]
"Hence, analogous to (4), B̃t can be obtained as:
minB̃,V̄ 1
2tP
tX
i=1
PX
p=1
B̃(p, :)H̄t(:, :, p)B̃ †(:, p)
2B̃(p, :)Ḡt(:, p) (13) s.t. F(V̄ (:, r))",3.3. Online Learning Algorithm for (10),[0],[0]
"= B̃(:, r), r = 1, . . .",3.3. Online Learning Algorithm for (10),[0],[0]
", R,
kC(V̄ (:, r))k2  1, r = 1, . . .",3.3. Online Learning Algorithm for (10),[0],[0]
", R, where H̄t(:, :, p)=1t Pt i=1",3.3. Online Learning Algorithm for (10),[0],[0]
Ỹ >,3.3. Online Learning Algorithm for (10),[0],[0]
"i (:, p)Ỹ ?",3.3. Online Learning Algorithm for (10),[0],[0]
"i (p, :) 2 RR⇥R, and Ḡt(:, p) = 1 t Pt i=1",3.3. Online Learning Algorithm for (10),[0],[0]
x̃ ?,3.3. Online Learning Algorithm for (10),[0],[0]
"i (p)Ỹ > i (:, p) 2 RR.",3.3. Online Learning Algorithm for (10),[0],[0]
"They can be incrementally updated as
H̄t(:, :, p) =",3.3. Online Learning Algorithm for (10),[0],[0]
"t 1 t H̄t 1(:, :, p)+ 1 t Ỹ >t (:, p)Ỹ ?",3.3. Online Learning Algorithm for (10),[0],[0]
"t (p, :), (14)
",3.3. Online Learning Algorithm for (10),[0],[0]
"Ḡt(:, p) = t 1 t Ḡt 1(:, p) + 1 t x̃?t",3.3. Online Learning Algorithm for (10),[0],[0]
"(p)Ỹ > t (:, p).",3.3. Online Learning Algorithm for (10),[0],[0]
"(15)
Problem (13) can then be solved using ADMM as in (4).
3.3.2.",3.3. Online Learning Algorithm for (10),[0],[0]
"OBTAINING Wt AND Zt
With the arrival of xt, we fix the base filters to B̃t 1 learned at the last iteration, and obtain (Wt, Zt) from (12) as:
min W,Z F (W,Z)⌘",3.3. Online Learning Algorithm for (10),[0],[0]
"f̃t(B̃t 1,W,Z)+IW(W )+ kZk1, (16)
where IW(W ) is the indicator function on W (i.e., IW(W )",3.3. Online Learning Algorithm for (10),[0],[0]
= 0,3.3. Online Learning Algorithm for (10),[0],[0]
if W 2 W and 1 otherwise),3.3. Online Learning Algorithm for (10),[0],[0]
".
",3.3. Online Learning Algorithm for (10),[0],[0]
"As in the CSC literature, it can be shown that ADMM can also be used to solve (16).",3.3. Online Learning Algorithm for (10),[0],[0]
"While CSC’s code update subproblem in (2) is convex, problem (16) is nonconvex and existing convergence results for ADMM (Wang et al., 2015) do not apply.
",3.3. Online Learning Algorithm for (10),[0],[0]
"In this paper, we will instead use the nonconvex and inexact accelerated proximal gradient (niAPG) algorithm (Yao et al., 2017).",3.3. Online Learning Algorithm for (10),[0],[0]
This is a recent proximal algorithm for nonconvex problems.,3.3. Online Learning Algorithm for (10),[0],[0]
"As the regularizers on W and Z in (16) are independent, the proximal step w.r.t.",3.3. Online Learning Algorithm for (10),[0],[0]
"the two blocks can be performed separately as: (proxIW(·)(W ), prox k·k1(Z)) (Parikh & Boyd, 2014).",3.3. Online Learning Algorithm for (10),[0],[0]
"As shown in (Parikh & Boyd, 2014), these individual proximal steps can be easily computed (for W = W`1 or W`2).",3.3. Online Learning Algorithm for (10),[0],[0]
"The whole procedure, which will be called “Sampledependent Convolutional Sparse Coding (SCSC)”, is shown in Algorithm 1.",3.3.3. COMPLETE ALGORITHM,[0],[0]
"Its space complexity, which is dominated by H̄t and Ḡt, is O(R2P ).",3.3.3. COMPLETE ALGORITHM,[0],[0]
"Its per-iteration time complexity is O(RKP + RP logP ), where the O(RKP ) term is due to gradient computation, and O(RP logP ) is due to FFT/inverse FFT.",3.3.3. COMPLETE ALGORITHM,[0],[0]
Table 1 compares its complexities with those of the other online and distributed CSC algorithms.,3.3.3. COMPLETE ALGORITHM,[0],[0]
"As can be seen, SCSC has much lower time and space complexities as R ⌧ K.",3.3.3. COMPLETE ALGORITHM,[0],[0]
Experiments are performed on a number of data sets (Table 2).,4. Experiments,[0],[0]
"Fruit and City are two small image data sets that have been commonly used in the CSC literature (Zeiler et al., 2010; Bristow et al., 2013; Heide et al., 2015; Papyan et al., 2017).",4. Experiments,[0],[0]
"We use the default training and testing splits provided in (Bristow et al., 2013).",4. Experiments,[0],[0]
"The images are preprocessed as in (Zeiler et al., 2010; Heide et al., 2015; Wang et al., 2018), which includes conversion to grayscale, feature standardization, local contrast normalization and edge tapering.",4. Experiments,[0],[0]
These two data sets are small.,4. Experiments,[0],[0]
"In some experiments, we will also use two larger data sets, CIFAR10 (Krizhevsky & Hinton, 2009) and Flower (Nilsback & Zisserman, 2008).",4. Experiments,[0],[0]
"Following (Heide et al., 2015; Choudhury et al., 2017; Papyan et al., 2017; Wang et al., 2018), we set the filter size M as 11⇥11, and the regularization parameter
Algorithm 1 Sample-dependent CSC (SCSC).",4. Experiments,[0],[0]
"1: Initialize W0 2 W , B0 2 B, H̄0 = 0, Ḡ0 = 0; 2: for t = 1, 2, . . .",4. Experiments,[0],[0]
", T do 3: draw xt from {xi}; 4: x̃t = F(xt); 5: obtain Wt, Zt using niAPG; 6: for r = 1, 2, . . .",4. Experiments,[0],[0]
", R do 7: Ỹt(:, r) =",4. Experiments,[0],[0]
"F(ZtW>t (:, r));",4. Experiments,[0],[0]
"8: end for 9: update {H̄t(:, :, 1), . . .",4. Experiments,[0],[0]
", H̄t(:, :, P )} using (14); 10: update {Ḡt(:, 1), . . .",4. Experiments,[0],[0]
", Ḡt(:, P )} using (15); 11: update B̃t by (13) using ADMM; 12: end for 13: for r = 1, 2, . . .",4. Experiments,[0],[0]
", R do 14: BT (:, r) =",4. Experiments,[0],[0]
C(F,4. Experiments,[0],[0]
"1(B̃T (:, r))); 15: end for output BT .
",4. Experiments,[0],[0]
"in (1) as 1.
To evaluate efficacy of the learned dictionary, we will mainly consider the task of image reconstruction as in (Aharon et al., 2006; Heide et al., 2015; Sironi et al., 2015).",4. Experiments,[0],[0]
"The reconstructed image quality is evaluated by the testing peak signal-to-noise ratio (Papyan et al., 2017): PSNR = 1|⌦| P xj2⌦ 20 log10 ⇣ p P kx̂j xjk2",4. Experiments,[0],[0]
"⌘ , where x̂j is the reconstruction of xj from test set ⌦.",4. Experiments,[0],[0]
"The experiment is repeated five times with different dictionary initializations.
4.1.",4. Experiments,[0],[0]
"Choice of W : W`1 versus W`2
First, we study the choice of W in Proposition 2.",4. Experiments,[0],[0]
"We compare SCSC-L1, which uses W = W`1, with SCSCL2, which uses W = W`2.",4. Experiments,[0],[0]
Experiments are performed on Fruit and City.,4. Experiments,[0],[0]
"As in (Heide et al., 2015; Papyan et al., 2017; Wang et al., 2018), the number of filters K is set to
100.",4. Experiments,[0],[0]
"Recall the space complexity results in Table 1, we define the compression ratio of SCSC relative to OCSC (using the same K) as CR = (K/R)2.",4. Experiments,[0],[0]
"We vary R in {K/20,K/10,K/9, . . .",4. Experiments,[0],[0]
",K/2,K}.",4. Experiments,[0],[0]
"The corresponding CR is {400, 100, 81, . . .",4. Experiments,[0],[0]
", 1}.
Results are shown in Figure 1.",4. Experiments,[0],[0]
"As can be seen, SCSC-L1 is much inferior.",4. Experiments,[0],[0]
Figure 2(a) shows the weight Wj obtained with K = 100 and R = 10 by SCSC-L1 on a test sample xj from City (results on the other data sets are similar).,4. Experiments,[0],[0]
"As can be seen, most of its entries are zero because of the sparsity induced by the `1 norm.",4. Experiments,[0],[0]
The expressive power is severely limited as typically only one base filter is used to approximate the original filter.,4. Experiments,[0],[0]
"On the other hand, the Wj learned by SCSC-L2 is dense and has more nonzero entries (Figure 2(b)).",4. Experiments,[0],[0]
"In the sequel, we will only focus on SCSC-L2, which will be simply denoted as SCSC.",4. Experiments,[0],[0]
"In this experiment, we set K = 100, and compare SCSC with the following algorithms that use sample-independent dictionaries: (i) SCSC (shared): This is a SCSC variant in which all Wi’s in (5) are the same.",4.2. Sample-Dependent Dictionary,[0],[0]
Its optimization is based on alternating minimization.,4.2. Sample-Dependent Dictionary,[0],[0]
"(ii) Separable filters learned by tensor decomposition (SEP-TD) (Sironi et al., 2015), which
is based on post-processing the (shared) dictionary learned by OCSC as reviewed in Section 2.1; (iii) OCSC (Wang et al., 2018): the state-of-the-art online CSC algorithm.
",4.2. Sample-Dependent Dictionary,[0],[0]
Results are shown in Figure 3.,4.2. Sample-Dependent Dictionary,[0],[0]
"As can be seen, SCSC always outperforms SCSC(shared) and SEP-TD, and outperforms OCSC when R = 10 (corresponding to CR = 100) or above.",4.2. Sample-Dependent Dictionary,[0],[0]
"This demonstrates the advantage of using a sampledependent dictionary.
",4.2. Sample-Dependent Dictionary,[0],[0]
"Next, we compare against OCSC with fine-tuned filters, which are also sample-dependent.",4.2. Sample-Dependent Dictionary,[0],[0]
"Specifically, given test sample xj , we first obtain its code Zj from (2) with the learned dictionary D, and then fine-tune D by solving (3) using the newly computed Zj .",4.2. Sample-Dependent Dictionary,[0],[0]
"As in (Donahue et al., 2014), this is repeated for a few iterations.1 We set OCSC’s K to be equal to SCSC’s R, so that the two methods take the same space (Table 1).",4.2. Sample-Dependent Dictionary,[0],[0]
The K used in SCSC is still 100.,4.2. Sample-Dependent Dictionary,[0],[0]
Results are shown in Figure 4.,4.2. Sample-Dependent Dictionary,[0],[0]
"As can be seen, though fine-tuning improves the performance of OCSC slightly, this approach of generating sample-dependent filters is still much worse than SCSC.",4.2. Sample-Dependent Dictionary,[0],[0]
"Recall that SCSC allows the use of more filters (i.e., a larger K) because of its lower time and space complexities.",4.3. Learning with More Filters,[0],[0]
"In this Section, we demonstrate that this can lead to better performance.",4.3. Learning with More Filters,[0],[0]
"We compare SCSC with two most recent batch and online CSC methods, namely, slice-based CSC
1In the experiments, we stop after five iterations.
",4.3. Learning with More Filters,[0],[0]
"(SBCSC) (Papyan et al., 2017) and OCSC.",4.3. Learning with More Filters,[0],[0]
"For SCSC, we set R = 10 for Fruit and City, and R = 30 for CIFAR-10 and Flower.
Figure 5 shows the testing PSNR’s at different K’s.",4.3. Learning with More Filters,[0],[0]
"As can be seen, a larger K consistently leads to better performance for all methods.",4.3. Learning with More Filters,[0],[0]
SCSC allows the use of a larger K because of its much smaller memory footprint.,4.3. Learning with More Filters,[0],[0]
"For example, on CIFAR-10, CR = 1024 at K = 800; on Flower, CR = 1600 at K = 400.",4.3. Learning with More Filters,[0],[0]
"First, we perform experiments on the two smaller data sets of Fruit and City, with K = 100.",4.4. Comparison with the State-of-the-Art,[0],[0]
"We set R = 10 (i.e., CR = 100) for SCSC.",4.4. Comparison with the State-of-the-Art,[0],[0]
"This is compared with the batch CSC algorithms, including (i) deconvolution network (DeconvNet) (Zeiler et al., 2010), (ii) fast CSC (FCSC) (Bristow et al., 2013), (iii) fast and flexible CSC (FFCSC) (Heide et al., 2015), (iv) convolutional basis pursuit denoising (CBPDN) (Wohlberg, 2016), (v) the CONSENSUS algorithm (Šorel & Šroubek, 2016), and (vi) slice-based CSC (SBCSC) (Papyan et al., 2017).",4.4. Comparison with the State-of-the-Art,[0],[0]
"We also compare with the online CSC algorithms, including (vii) OCSC (Wang et al., 2018), (viii) OCDL-Degraux (Degraux et al., 2017), and (ix) OCDL-Liu (Liu et al., 2017).
",4.4. Comparison with the State-of-the-Art,[0],[0]
Figure 6 shows convergence of the testing PSNR with clock time.,4.4. Comparison with the State-of-the-Art,[0],[0]
"As also demonstrated in (Degraux et al., 2017; Liu et al., 2017; Wang et al., 2018), online CSC methods converge faster and have better PSNR than batch CSC methods.",4.4. Comparison with the State-of-the-Art,[0],[0]
"Among the online methods, SCSC has comparable PSNR as OCSC, but is faster and requires much less storage (CR = 100).
",4.4. Comparison with the State-of-the-Art,[0],[0]
"Next, we perform experiments on the two large data sets, CIFAR-10 and Flower.",4.4. Comparison with the State-of-the-Art,[0],[0]
"All the batch CSC algorithms and two online CSC algorithms, OCDL-Degraux and OCDLLiu, cannot handle such large data sets.",4.4. Comparison with the State-of-the-Art,[0],[0]
"Hence, we will only compare SCSC with OCSC.",4.4. Comparison with the State-of-the-Art,[0],[0]
"On CIFAR-10, we set K = 300, and the corresponding CR for SCSC is 100.",4.4. Comparison with the State-of-the-Art,[0],[0]
"On Flower, K is still 300 for SCSC.",4.4. Comparison with the State-of-the-Art,[0],[0]
"However, OCSC can only use K = 50 because of its much larger memory footprint.",4.4. Comparison with the State-of-the-Art,[0],[0]
Figure 7 shows convergence of the testing PSNR.,4.4. Comparison with the State-of-the-Art,[0],[0]
"In both cases, SCSC significantly outperforms OCSC.",4.4. Comparison with the State-of-the-Art,[0],[0]
"In this section, we perform experiments on data sets with dimensionalities larger than two.",4.5. Higher-Dimensional Data,[0],[0]
"To alleviate the large memory problem, Choudhury et al. (2017) proposed the use of distributed algorithms.",4.5. Higher-Dimensional Data,[0],[0]
"Here, we show that SCSC can effectively handle these data sets using one single machine.
",4.5. Higher-Dimensional Data,[0],[0]
"Experiments are performed on three data sets (Table 3) in (Choudhury et al., 2017).",4.5. Higher-Dimensional Data,[0],[0]
"The Video data set contains image subsequences recorded in an airport (Li et al., 2004).",4.5. Higher-Dimensional Data,[0],[0]
"The length of each video is 7, and each image frame is of size 100⇥ 100.",4.5. Higher-Dimensional Data,[0],[0]
"The Multispectral data contains 60⇥ 60 patches from multispectral images (covering 31 wavelengths) of real-world objects and materials (Yasuma et al., 2010).",4.5. Higher-Dimensional Data,[0],[0]
"The Light field data contains 60⇥60 patches of light field images on objects and scenes (Kalantari et al., 2016).",4.5. Higher-Dimensional Data,[0],[0]
"For each pixel, the light rays are from 8 ⇥ 8 different directions.",4.5. Higher-Dimensional Data,[0],[0]
"Following (Choudhury et al., 2017), we set the filter size M
to 11⇥ 11⇥ 11 for Video, 11⇥ 11⇥ 31 for Multispectral, and 11⇥ 11⇥ 8⇥ 8 for Light field.
",4.5. Higher-Dimensional Data,[0],[0]
"We compare SCSC with OCSC and the concensus CSC (CCSC) (Choudhury et al., 2017) algorithms, with K = 50.",4.5. Higher-Dimensional Data,[0],[0]
"For fair comparison, only one machine is used for all methods.",4.5. Higher-Dimensional Data,[0],[0]
"We do not compare with the batch methods and the two online methods (OCDL-Degraux and OCDL-Liu) as they are not scalable (as already shown in Section 4.4).
",4.5. Higher-Dimensional Data,[0],[0]
"Because of the small memory footprint of SCSC, we run it on a GTX 1080 Ti GPU in this experiment.",4.5. Higher-Dimensional Data,[0],[0]
OCSC is also run on GPU for Video.,4.5. Higher-Dimensional Data,[0],[0]
"However, OCSC can only run on CPU for Multispectral and Light field.",4.5. Higher-Dimensional Data,[0],[0]
"CCSC, which needs to access all the samples and codes during processing, can only be on CPU.2
Results are shown in Table 4.",4.5. Higher-Dimensional Data,[0],[0]
"Note that SCSC is the only method that can handle the whole of Video, Multispectral and Light field data sets on a single machine.",4.5. Higher-Dimensional Data,[0],[0]
"In comparison, CCSC can only handle a maximum of 30 Video samples, 40 Multispectral samples, and 35 Light field samples.",4.5. Higher-Dimensional Data,[0],[0]
"OCSC can handle the whole of Video and Multispectral, but cannot converge in 2 days when the whole Light field data set is used.",4.5. Higher-Dimensional Data,[0],[0]
"Again, SCSC outperforms OCSC and CCSC.
",4.5. Higher-Dimensional Data,[0],[0]
"As for speed, SCSC is the fastest.",4.5. Higher-Dimensional Data,[0],[0]
"However, note that this is for reference only as SCSC is run on GPU while the others (except for OCSC on Video) are run on CPU.",4.5. Higher-Dimensional Data,[0],[0]
"Nevertheless, this still demonstrates an important advantage of SCSC, namely that its small memory footprint can benefit from the use of GPU, while the others cannot.",4.5. Higher-Dimensional Data,[0],[0]
"In previous experiments, superiority of the learned dictionary is demonstrated by reconstruction of clean images.",4.6. Image Denoising and Inpainting,[0],[0]
"In this section, we further examine the learned dictionary on two applications: image denoising and inpainting.",4.6. Image Denoising and Inpainting,[0],[0]
"Ten test images provided by (Choudhury et al., 2017) are used.",4.6. Image Denoising and Inpainting,[0],[0]
"In denoising, we add Gaussian noise with zero mean and variance 0.01 to the test images (the average input PSNR is 10dB).",4.6. Image Denoising and Inpainting,[0],[0]
"In inpainting, we random sub-sample 50% of the pixels as 0 (the average input PSNR is 9.12dB).",4.6. Image Denoising and Inpainting,[0],[0]
"Following (Heide et al., 2015; Choudhury et al., 2017; Papyan et al.,
2For Video, the memory used (in GB) by CCSC, OCSC, SCSC (with R = 5) and SCSC (with R = 10) are 28.73, 7.58, 2.66, and 2.87, respectively.",4.6. Image Denoising and Inpainting,[0],[0]
"On Multispectral, they are 28.26, 11.09, 0.73 and 0.76; on Light field, they are 29.79, 15.94, 7.26 and 8.88, respectively.
2017), we use a binary weight matrix to mask out positions of the missing pixels.",4.6. Image Denoising and Inpainting,[0],[0]
We use the filters learned from Fruit in Section 4.4.,4.6. Image Denoising and Inpainting,[0],[0]
"SCSC is compared with (batch) SBCSC and (online) OCSC.
",4.6. Image Denoising and Inpainting,[0],[0]
Results are shown in Table 5.,4.6. Image Denoising and Inpainting,[0],[0]
"As can be seen, the PSNRs obtained by SCSC are consistently higher than those by the other methods.",4.6. Image Denoising and Inpainting,[0],[0]
"This shows that the dictionary, which yields high PSNR on image reconstruction, also leads to better performance in other image processing applications.
4.7.",4.6. Image Denoising and Inpainting,[0],[0]
"Solving (16): niAPG vs ADMM
Finally, we compare the performance of ADMM and niAPG in solving subproblem (16).",4.6. Image Denoising and Inpainting,[0],[0]
We use a training sample xi from City.,4.6. Image Denoising and Inpainting,[0],[0]
"The experiment is repeated five times with different (Wi, Zi) initializations.",4.6. Image Denoising and Inpainting,[0],[0]
Figure 8 shows convergence of the objective in (16) with time.,4.6. Image Denoising and Inpainting,[0],[0]
"As can be seen, niAPG has fast convergence while ADMM fails to converge.",4.6. Image Denoising and Inpainting,[0],[0]
Figure 9 shows kỸi,4.6. Image Denoising and Inpainting,[0],[0]
"F(ZiW>i )k2F , which measures violation of the ADMM constraints, with the number of iterations.",4.6. Image Denoising and Inpainting,[0],[0]
"As can be seen, the violation does not go to zero, which indicates that ADMM does not converge.",4.6. Image Denoising and Inpainting,[0],[0]
"In this paper, we proposed a novel CSC extension, in which each sample has its own sample-dependent dictionary constructed from a small set of shared base filters.",5. Conclusion,[0],[0]
"Using online learning, the model can be efficiently updated with low time and space complexities.",5. Conclusion,[0],[0]
"Extensive experiments on a variety of data sets including large image data sets and
Figure 8.",5. Conclusion,[0],[0]
"Convergence of niAPG and ADMM on solving (16).
",5. Conclusion,[0],[0]
Figure 9.,5. Conclusion,[0],[0]
"Constraint violation in ADMM.
",5. Conclusion,[0],[0]
higher-dimensional data sets all demonstrate its efficiency and scalability.,5. Conclusion,[0],[0]
The second author especially thanks Weiwei Tu and Yuqiang Chen from 4Paradigm Inc.,Acknowledgements,[0],[0]
"This research was supported in part by the Research Grants Council, Hong Kong, under Grant 614513, and by the University of Macau Grant SRG2015-00050-FST.",Acknowledgements,[0],[0]
Convolutional sparse coding (CSC) has been popularly used for the learning of shift-invariant dictionaries in image and signal processing.,abstractText,[0],[0]
"However, existing methods have limited scalability.",abstractText,[0],[0]
"In this paper, instead of convolving with a dictionary shared by all samples, we propose the use of a sample-dependent dictionary in which each filter is a linear combination of a small set of base filters learned from data.",abstractText,[0],[0]
"This added flexibility allows a large number of sample-dependent patterns to be captured, which is especially useful in the handling of large or high-dimensional data sets.",abstractText,[0],[0]
"Computationally, the resultant model can be efficiently learned by online learning.",abstractText,[0],[0]
Extensive experimental results on a number of data sets show that the proposed method outperforms existing CSC algorithms with significantly reduced time and space complexities.,abstractText,[0],[0]
Online Convolutional Sparse Coding with Sample-Dependent Dictionary,title,[0],[0]
"We consider an online learning scenario, prevalent in many applications, where the learner is granted the option of abstaining from making a prediction, at a certain cost.",1. Introduction,[0],[0]
"For example, in the classification setting, at each round, the learner can choose to make a prediction and incur a standard zero-one misclassification cost, or elect to abstain, in which case she incurs an abstention cost, typically less than one.",1. Introduction,[0],[0]
Abstention can thus represent an attractive option to avoid a higher cost of misclassification.,1. Introduction,[0],[0]
"Note, however, that when the learner abstains, she does not receive the true label (correct class), which results in a loss of information.
",1. Introduction,[0],[0]
This scenario of online learning with abstention is relevant to many real-life problems.,1. Introduction,[0],[0]
"As an example, consider the scenario where a doctor can choose to make a diagnosis based on the current information available about a patient,
⇤Work done at the Courant Institute of Mathematical Sciences.",1. Introduction,[0],[0]
"1Google Research, New York, NY.",1. Introduction,[0],[0]
2INRIA Lille Nord Europe.,1. Introduction,[0],[0]
"3Courant Institute of Mathematical Sciences, New York, NY.",1. Introduction,[0],[0]
"4D. E. Shaw & Co., New York, NY.",1. Introduction,[0],[0]
Correspondence to:,1. Introduction,[0],[0]
Giulia DeSalvo <giuliad@google.com,1. Introduction,[0],[0]
">.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
or abstain and request further laboratory tests, which can represent both a time delay and a financial cost.",1. Introduction,[0],[0]
"In this case, the abstention cost is usually substantially lower than that of a wrong diagnosis.",1. Introduction,[0],[0]
"The online model is appropriate since it captures the gradual experience a doctor gains by testing, examining and following new patients.
",1. Introduction,[0],[0]
Another instance of this problem appears in the design of spoken-dialog applications such as those in modern personal assistants.,1. Introduction,[0],[0]
"Each time the user asks a question, the assistant can either offer a direct response to the question, at the risk of providing an inaccurate response, or choose to say “I am sorry, I do not understand?”, which results in a longer and thereby more costly dialog requesting the user to reformulate his question.",1. Introduction,[0],[0]
"Similar online learning problems arise in the context of self-driving cars where, at each instant, the assistant must determine whether to continue steering the car or return the control to the driver.",1. Introduction,[0],[0]
"Online learning with abstention also naturally models many problems arising in electronic commerce platforms such as an Ad Exchange, an online platform set up by a publisher where several advertisers bid in order to compete for an ad slot, the abstention cost being the opportunity loss of not bidding for a specific ad slot.
",1. Introduction,[0],[0]
"In the batch setting, the problem of learning with abstention has been studied in a number of publications, starting with (Chow, 1957; 1970).",1. Introduction,[0],[0]
Its theoretical aspects have been analyzed by several authors in the last decade.,1. Introduction,[0],[0]
El-Yaniv & Wiener (2010; 2011) studied the trade-off between the coverage and accuracy of classifiers.,1. Introduction,[0],[0]
Bartlett & Wegkamp (2008) introduced a loss function including explicitly an abstention cost and gave a consistency analysis of a surrogate loss that they used to derive an algorithm.,1. Introduction,[0],[0]
"More recently, Cortes et al. (2016a;b) presented a comprehensive study of the problem, including an analysis of the properties of a corresponding abstention (or rejection) loss with a series of theoretical guarantees and algorithmic results both for learning with kernel-based hypotheses and for boosting.
",1. Introduction,[0],[0]
"This paper presents an extensive study of the problem of online learning with abstention, in both the adversarial and the stochastic settings.",1. Introduction,[0],[0]
"We consider the common scenario of prediction with expert advice (Littlestone & Warmuth, 1994) and adopt the same general abstention loss function as in (Cortes et al., 2016a), with each expert formed by a
pair made of a predictor and an abstention function.
",1. Introduction,[0],[0]
"A key aspect of the problem we investigate, which makes it distinct from both batch learning with abstention, where labels are known for all training points, and standard online learning (in the full information setting) is the following: if the algorithm abstains from making a prediction for the input point received at a given round, the true label of that point is not revealed.",1. Introduction,[0],[0]
"As a result, the loss of the experts that would have instead made a prediction on that point cannot be determined at that round.",1. Introduction,[0],[0]
"Thus, we are dealing with an online learning scenario with partial feedback.",1. Introduction,[0],[0]
"If the algorithm chooses to predict, then the true label is revealed and the losses of all experts, including abstaining ones, are known.",1. Introduction,[0],[0]
"But, if the algorithm elects to abstain, then only the losses of the abstaining experts are known, all of them being equal to the same abstention cost.
",1. Introduction,[0],[0]
"As we shall see, our learning problem can be cast as a specific instance of online learning with a feedback graph, a framework introduced by Mannor & Shamir (2011) and later extensively analyzed by several authors (Caron et al., 2012; Alon et al., 2013; 2014; 2015; Kocák et al., 2014; Neu, 2015; Cohen et al., 2016)).",1. Introduction,[0],[0]
"In our context, the feedback graph varies over time, a scenario for which most of the existing algorithms and analyses (specifically, in the stochastic setting) do not readily apply.",1. Introduction,[0],[0]
"Our setting is distinct from the KWIK (knows what it knows) framework of Li et al. (2008) and its later extensions, though there are some connections, as discussed in Appendix A.
Our contribution can be summarized as follows.",1. Introduction,[0],[0]
"In Section 3, we analyze an adversarial setting both in the case of a finite family of experts and that of an infinite family.",1. Introduction,[0],[0]
We show that the problem of learning with abstention can be cast as that of online learning with a time-varying feedback graph tailored to the problem.,1. Introduction,[0],[0]
"In the finite case, we show how ideas from (Alon et al., 2014; 2015) can be extended and combined with this time-varying feedback graph to devise an algorithm, EXP3-ABS, that benefits from favorable guarantees.",1. Introduction,[0],[0]
"In turn, EXP3-ABS is used as a subroutine for the infinite case where we show how a surrogate loss function can be carefully designed for the abstention loss, while maintaining the same partial observability.",1. Introduction,[0],[0]
"We use the structure of this loss function to extend CONTEXTUALEXP3 (Cesa-Bianchi et al., 2017) to the abstention scenario and prove regret guarantees for its performance.
",1. Introduction,[0],[0]
"In Section 4, we shift our attention to the stochastic setting.",1. Introduction,[0],[0]
Stochastic bandits with a fixed feedback graph have been previously studied by Caron et al. (2012) and Cohen et al. (2016).,1. Introduction,[0],[0]
We first show that an immediate extension of these algorithms to the time-varying graphs in the abstention scenario faces a technical bias problem in the estimation of the expert losses.,1. Introduction,[0],[0]
"Next, we characterize a set of feedback graphs that can circumvent this bias problem in the general
setting of online learning with feedback graphs.",1. Introduction,[0],[0]
"We further design a new algorithm, UCB-GT, whose feedback graph is estimated based on past observations.",1. Introduction,[0],[0]
"We prove that the algorithm admits more favorable regret guarantees than the UCB-N algorithm (Caron et al., 2012).",1. Introduction,[0],[0]
"Finally, in Section 5 we report the results of several experiments with both artificial and real-world datasets demonstrating that UCB-GT in practice significantly outperforms an unbiased, but limited, extension of UCB-N, as well as a standard bandit baseline, like UCB (Auer et al., 2002a).",1. Introduction,[0],[0]
"Let X denote the input space (e.g., X is a bounded subset of Rd).",2. Learning Problem,[0],[0]
"We denote by H a family of predictors h : X! R, and consider the familiar binary classification problem where the loss `(y, h(x)) of h 2 H on a labeled pair (x, y) 2 X ⇥ {±1} is defined by either the 0/1-loss 1yh(x)60, or some Lipschitz variant thereof (see Section 3).",2. Learning Problem,[0],[0]
"In all cases, we assume `(·, ·) 2",2. Learning Problem,[0],[0]
"[0, 1].",2. Learning Problem,[0],[0]
We also denote by R a family of abstention functions r : X !,2. Learning Problem,[0],[0]
"R, with r(x) 6 0 indicating an abstention on x 2 X (or that x is rejected), and r(x)",2. Learning Problem,[0],[0]
> 0,2. Learning Problem,[0],[0]
"that x is predicted upon (or that x is accepted).
",2. Learning Problem,[0],[0]
"We consider a specific online learning scenario whose regime lies between bandit and full information, sometimes referred to as bandit with side-information (e.g., Mannor & Shamir (2011); Caron et al. (2012); Alon et al. (2013; 2014; 2015); Kocák et al. (2014); Neu (2015); Cohen et al. (2016)).",2. Learning Problem,[0],[0]
"In our case, the arms are pairs made of a predictor function h and an abstention function r in a given family E ✓ H⇥R. We will denote by ⇠j = (hj , rj), j 2",2. Learning Problem,[0],[0]
"[K], the elements of E. In fact, depending on the setting, K may be finite or (uncountably) infinite.",2. Learning Problem,[0],[0]
"Given hj , one natural choice for the associated abstention function rj is a confidence-based abstention function of the form rj(x) = |hj(x)|",2. Learning Problem,[0],[0]
"✓, for some threshold ✓ > 0.",2. Learning Problem,[0],[0]
"Yet, more general pairs (hj , rj) can be considered here.",2. Learning Problem,[0],[0]
"This provides an important degree of flexibility in the design of algorithms where abstentions are allowed, as shown in (Cortes et al., 2016a;b).",2. Learning Problem,[0],[0]
"Appendix A presents a concrete example illustrating the benefits of learning with these pair of functions.
",2. Learning Problem,[0],[0]
The online learning protocol is described as follows.,2. Learning Problem,[0],[0]
The set E is known to the learning algorithm beforehand.,2. Learning Problem,[0],[0]
At each round t 2,2. Learning Problem,[0],[0]
"[T ], the online algorithm receives an input xt 2 X and chooses (possibly at random) an arm (henceforth also called “expert” or “pair”) ⇠It = (hIt , rIt) 2 E. If the inequality rIt(xt) 6 0 holds, then the algorithm abstains and incurs as loss an abstention cost c(xt) 2",2. Learning Problem,[0],[0]
"[0, 1].",2. Learning Problem,[0],[0]
"Otherwise, it predicts based on the sign of hIt(xt), receives the true label yt 2 {±1}, and incurs the loss `(yt, hIt(xt)).",2. Learning Problem,[0],[0]
"Thus, the overall abstention loss L of expert ⇠ = (h, r) 2 E on the labeled pair z = (x, y) 2 X ⇥",2. Learning Problem,[0],[0]
"{±1} is defined as
follows:
L(⇠, z) =",2. Learning Problem,[0],[0]
"`(y, h(x))1r(x)>0 + c(x)1r(x)60 .",2. Learning Problem,[0],[0]
"(1)
For simplicity, we will assume throughout that the abstention cost c(x) is a (known) constant c 2",2. Learning Problem,[0],[0]
"[0, 1], independent of x, though all our results can be straightforwardly extended to the case when c is a (Lipschitz) function of x, which is indeed desirable in some applications.
",2. Learning Problem,[0],[0]
Our problem can be naturally cast as an online learning problem with side information in the form of a feedback graph.,2. Learning Problem,[0],[0]
"Online learning with a feedback graph is a general framework that covers a variety of problems with partial information, including the full information scenario, where the graph is fully connected, and the bandit scenario where all vertices admit only self-loops and are disconnected (Alon et al., 2013; 2014).",2. Learning Problem,[0],[0]
"In our case, we have a directed graph GABSt = (V, Et) that depends on the instance xt received by the algorithm at round t 2",2. Learning Problem,[0],[0]
[T ].,2. Learning Problem,[0],[0]
"Here, V denotes the finite set of vertices of this graph, which, in the case of a finite set of arms, coincides with the set of experts E, while Et denotes the set of directed edges at round t. The directed edge ⇠i !",2. Learning Problem,[0],[0]
⇠j is in Et if the loss of expert ⇠j 2 V is observed when expert ⇠i is selected by the algorithm at round t.,2. Learning Problem,[0],[0]
"In our problem, if the learner chooses to predict at round t (i.e., if rIt(xt) > 0), then she observes the loss L(⇠j , zt) of all experts ⇠j , since the label yt is revealed to her.",2. Learning Problem,[0],[0]
"If instead she abstains at round t (i.e., if rIt(xt) 6 0), then she only observes L(⇠j , zt) for those experts ⇠j that are abstaining in that round, that is, the set of j such that rj(xt) 6 0, since for all such ⇠j , we have L(⇠j , zt) =",2. Learning Problem,[0],[0]
c. Notice that in both cases the learner can observe the loss of her own action.,2. Learning Problem,[0],[0]
"Thus, the feedback graph we are operating with is a nearly fully connected directed graph with self-loops, except that it admits only one-way edges from predicting to abstaining vertices (see Figure 1 for an example).",2. Learning Problem,[0],[0]
"Observe also that the feedback graph GABSt is fully determined by xt.
",2. Learning Problem,[0],[0]
"We will consider both an adversarial setting (Section 3), where no distributional assumption is made about the sequence zt = (xt, yt), t 2",2. Learning Problem,[0],[0]
"[T ], and a stochastic setting (Section 4), where zt is assumed to be drawn i.i.d.",2. Learning Problem,[0],[0]
from some unknown distribution D over X ⇥ {±1}.,2. Learning Problem,[0],[0]
"For both settings, we measure the performance of an algorithm A by its (pseudo-)regret RT (A), defined as RT (A) =
sup⇠2E E[ PT t=1 L(⇠It , zt) PT
t=1 L(⇠, zt)] , where the expectation is taken both with respect to the algorithm’s choice of actions Its and, in the stochastic setting, the random draw of the zts.
",2. Learning Problem,[0],[0]
"In the stochastic setting, we will be mainly concerned with the case where E is a finite set of experts E = {⇠1, . . .",2. Learning Problem,[0],[0]
", ⇠K}.",2. Learning Problem,[0],[0]
"We then denote by µj the expected loss of expert ⇠j 2 E, µj = Ez⇠D[L(⇠j , z)], by µ⇤ the expected loss of the best expert, µ⇤ = minj2[K] µj , and by j the loss gap to the best, j = µj µ⇤.",2. Learning Problem,[0],[0]
"In the adversarial setting, we will analyze both the finite and infinite expert scenarios.",2. Learning Problem,[0],[0]
"In the infinite case, since L is non-convex in the relevant parameters (Eq. (1)), further care is needed.",2. Learning Problem,[0],[0]
"As a warm-up, we start with the adversarial setting with finitely-many experts.",3. Adversarial setting,[0],[0]
"Following ideas from Alon et al. (2014; 2015), we design an online algorithm for the abstention scenario by combining standard finite-arm bandit algorithms, like EXP3 (Auer et al., 2003), with the feedback graph GABSt of Section 2.",3. Adversarial setting,[0],[0]
We call the resulting algorithm EXP3-ABS (EXP3 with abstention).,3. Adversarial setting,[0],[0]
The algorithm is a variant of EXP3 where the importance weighting scheme to achieve unbiased loss estimates is based on the probability of the loss of an expert being observed as opposed to that of an expert being selected — see Appendix B (Algorithm 3).,3. Adversarial setting,[0],[0]
"The following guarantee holds for this algorithm.
",3. Adversarial setting,[0],[0]
"Theorem 1 Let EXP3-ABS be run with learning rate ⌘ over a set of K experts ⇠1, . . .",3. Adversarial setting,[0],[0]
", ⇠K .",3. Adversarial setting,[0],[0]
"Then, the algorithm admits the following regret guarantee after T rounds:
RT (EXP3-ABS) 6 (log K)/⌘",3. Adversarial setting,[0],[0]
"+ ⌘ T (c2 + 1)/2.
",3. Adversarial setting,[0],[0]
"In particular, if EXP3-ABS is run with ⌘ = q
2 log K (c2+1)T , then
RT (EXP3-ABS) 6 p 2(c2 + 1)T log K.
The proof of this result, as well as all other proofs, is given in the appendix.",3. Adversarial setting,[0],[0]
The dependency of the bound on the number of experts is clearly more favorable than the standard bound for EXP3 ( p log K instead of p K).,3. Adversarial setting,[0],[0]
Theorem 1 is in fact reminiscent of what one can achieve using the contextualbandit algorithm,3. Adversarial setting,[0],[0]
"EXP4 (Auer et al., 2002b) run on K experts, each one having two actions.
",3. Adversarial setting,[0],[0]
"We now turn our attention to the case of an uncountably infinite E. To model this more general framework, one might be tempted to focus on parametric classes of functions h and r, e.g., the family E of linear functions (h, r) : h(x) =",3. Adversarial setting,[0],[0]
"w>x, r(x) = |w>x|",3. Adversarial setting,[0],[0]
"✓, w 2 Rd, ✓ > 0 ,
introduce some convex surrogate of the abstention loss (1), and work in the parametric space of (w, ✓) through some
Bandit Convex Optimization technique (e.g., (Hazan, 2016)).",3. Adversarial setting,[0],[0]
"Unfortunately, this approach is not easy to put in place, since the surrogate loss not only needs to ensure convexity and some form of calibration, but also the ability for the algorithm to observe the loss of its own action (the self-loops in the graph of Figure 1).
",3. Adversarial setting,[0],[0]
"We have been unable to get around this problem by just resorting to convex surrogate losses (and we strongly suspect that it is not possible), and in what follows we instead introduce a surrogate abstention loss which is Lipschitz but not convex.",3. Adversarial setting,[0],[0]
"Moreover, we take the more general viewpoint of competing with pairs (h, r) of Lipschitz functions with bounded Lipschitz constant.",3. Adversarial setting,[0],[0]
"Let us then consider the version of the abstention loss (1) with `(y, h(x))",3. Adversarial setting,[0],[0]
"= f ( yh(x)), where f is the 0/1-loss with slope 1/(2 ) at the origin, f (a) = ⇣ +a 2 ⌘ 1|a|6 + 1a>01|a|> (see Figure 2 (a)), and the class of experts E = ⇠ = (h, r) |h, r : X ✓ Rd !
",3. Adversarial setting,[0],[0]
"[ 1, 1] .",3. Adversarial setting,[0],[0]
"Here, functions h and r in the definition of E are assumed to be LE-Lipschitz with respect to an appropriate distance on Rd, for some constant LE which determines the size of the family E.
Using ideas from (Cesa-Bianchi et al., 2017), we present an algorithm that approximates the action space by a finite cover while using the structure of the abstention setting.",3. Adversarial setting,[0],[0]
"The crux of the problem is to define a Lipschitz function eL that uppers bounds the abstention loss while maintaining the same feedback assumptions, namely the feedback graph given in Figure 1.",3. Adversarial setting,[0],[0]
"One Lipschitz function eL that precisely solves this problem is the following:
eL(⇠, z) =
8 >",3. Adversarial setting,[0],[0]
>,3. Adversarial setting,[0],[0]
">><
>>>>:
c if r(x) 6 1 + ⇣ 1 c ⌘ r(x) if r(x) 2",3. Adversarial setting,[0],[0]
"( , 0) 1 ⇣ 1 f ( yh(x)) ⌘",3. Adversarial setting,[0],[0]
r(x) if r(x) 2,3. Adversarial setting,[0],[0]
"[0, )
",3. Adversarial setting,[0],[0]
f ( yh(x)),3. Adversarial setting,[0],[0]
"if r(x) > ,
for 2 (0, 1).",3. Adversarial setting,[0],[0]
"eL(⇠, z) is plotted in Figure 2(b).",3. Adversarial setting,[0],[0]
"Notice that this function is consistent with the feedback requirements of Section 2: rIt(xt) 6 0 implies that eL((h(xt), r(xt)), zt) is known to the algorithm (i.e., is independent of yt) for all (h, r) 2 E such that r(xt) 6 0, while rIt(xt) > 0 gives complete knowledge of eL((h(xt), r(xt)), zt) for all (h, r) 2 E, since yt is observed.
",3. Adversarial setting,[0],[0]
"We can then adapt the machinery from (Cesa-Bianchi et al., 2017) so as to apply a contextual version of EXP3-ABS to the sequence of losses eL(⇠, zt), t 2",3. Adversarial setting,[0],[0]
[T ].,3. Adversarial setting,[0],[0]
"The algorithm adaptively covers X with balls of a fixed radius "", each ball hosting an instance of EXP3-ABS.",3. Adversarial setting,[0],[0]
"We call this algorithm CONTEXP3-ABS – see Appendix B.2 for details.
",3. Adversarial setting,[0],[0]
"Theorem 2 Consider the abstention loss
L(⇠, z) = f",3. Adversarial setting,[0],[0]
( yh(x))1r(x)>0 +,3. Adversarial setting,[0],[0]
"c1r(x)60 ,
and let ⇠⇤ = (h⇤, r⇤) = argmin⇠2E PT
t=1 L(⇠, zt), with E = {(h, r)} made of pairs of Lipschitz functions as described above.",3. Adversarial setting,[0],[0]
"If CONTEXP3-ABS is run with parameter "" ' T 1 2+d 2 2+d and an appropriate learning rate (see Appendix B), then, it admits the following regret guarantee:
RT (CONTEXP3-ABS) 6 eO ⇣ T d+1 d+2
d d+2",3. Adversarial setting,[0],[0]
"⌘ + M⇤T ( ),
where M⇤T ( ) is the number of xt such that |r⇤(xt)| 6 .
",3. Adversarial setting,[0],[0]
"In the above, eO hides constant and ln(T ) factors, while ' disregards constants like LE, and various log factors.",3. Adversarial setting,[0],[0]
"CONTEXP3-ABS is also computationally efficient, thereby providing a compelling solution to the infinite armed case of online learning with abstention.",3. Adversarial setting,[0],[0]
We now turn to studying the stochastic setting.,4. Stochastic setting,[0],[0]
"As pointed out in Section 2, the problem can be cast as an instance of online learning with time-varying feedback graphs GABSt .",4. Stochastic setting,[0],[0]
"Thus, a natural method for tackling the problem would be to extend existing algorithms designed for the stochastic setting with feedback graphs to our abstention scenario (Cohen et al., 2016; Caron et al., 2012).",4. Stochastic setting,[0],[0]
We cannot benefit from the algorithm of Cohen et al. (2016) in our scenario.,4. Stochastic setting,[0],[0]
This is because at the heart of its design and theoretical guarantees lies the assumption that the graphs and losses are independent.,4. Stochastic setting,[0],[0]
"The dependency of the feedback graphs on the observations zt, which also define the losses, is precisely a property that we wish to exploit in our scenario.
",4. Stochastic setting,[0],[0]
"An alternative is to extend the UCB-N algorithm of Caron et al. (2012), for which the authors provide gap-based regret guarantees.",4. Stochastic setting,[0],[0]
This algorithm is defined for a stochastic setting with an undirected feedback graph that is fixed over time.,4. Stochastic setting,[0],[0]
The algorithm can be straightforwardly extended to the case of directed time-varying feedback graphs (see Algorithm 1).,4. Stochastic setting,[0],[0]
"We will denote that extension by UCB-NT to explicitly differentiate it from UCB-N. Let Nt(j) denote the set of out-neighbors of vertex ⇠j in the directed graph at time t, i.e., the set of vertices ⇠k destinations of an edge from ⇠j .",4. Stochastic setting,[0],[0]
"Then, as with UCB-N, the algorithm updates, at
each round t, the upper-confidence bound of every expert for which a feedback is received (those in Nt(It)), as opposed to updating only the upper-confidence bound of the expert selected, as in the standard UCB of Auer et al. (2002a).
",4. Stochastic setting,[0],[0]
"In the context of learning with abstention, the natural feedback graph GABSt at time t depends on the observation xt and varies over time.",4. Stochastic setting,[0],[0]
Can we extend the regret guarantees of Caron et al. (2012) to UCB-NT with such graphs?,4. Stochastic setting,[0],[0]
We will show in Section 4.1 that vanishing regret guarantees do not hold for UCB-NT run with graphs GABSt .,4. Stochastic setting,[0],[0]
This is because of a fundamental estimation bias problem that arises when the graph at time t depends on the observation xt.,4. Stochastic setting,[0],[0]
This issue affects more generally any natural method using the GABSt graphs.,4. Stochastic setting,[0],[0]
"Nevertheless, we will show in Section 4.2 that UCB-NT does benefit from favorable guarantees, provided the feedback graph GABSt it uses at round t is replaced by one that only depends on events up to time t 1.",4. Stochastic setting,[0],[0]
Assume there are two experts: ⇠1 (red) and ⇠2 (blue) with µ2 < µ1 and X =,4.1. Bias problem,[0],[0]
"[0, 1] (see Figure 3).",4.1. Bias problem,[0],[0]
"For x > 12 , the red expert ⇠1 is abstaining and incurring a loss c, whereas the blue expert is never abstaining.",4.1. Bias problem,[0],[0]
Assume that the probability mass is quasi-uniform over the interval,4.1. Bias problem,[0],[0]
"[0, 1] but with slightly more mass over the region x < 12 .",4.1. Bias problem,[0],[0]
The algorithm may then start out by observing points in this region.,4.1. Bias problem,[0],[0]
"Here, both experts accept and the algorithm obtains error estimates corresponding to the solid red and blue lines for x < 12 .",4.1. Bias problem,[0],[0]
"When the algorithm observes a point x > 1 2 , it naturally selects the red abstaining expert since it admits a better current estimated loss.",4.1. Bias problem,[0],[0]
"However, for x > 12 , the red expert is worse than the blue expert ⇠2.",4.1. Bias problem,[0],[0]
"Furthermore, it is abstaining and thus providing no updates for expert ⇠2 (which is instead predicting).",4.1. Bias problem,[0],[0]
"Hence, the algorithm continues to maintain an estimate of ⇠2’s loss at the level of the blue solid line indicated for x < 12 ; it then continues to select the red expert for all xs and incurs a high regret.1
This simple example shows that, unlike the adversarial scenario (Section 3), GABSt , here, cannot depend on the input xt, and that, in general, the indiscriminate use of feedback graphs may result in biased loss observations.",4.1. Bias problem,[0],[0]
"On the other
1 For the sake of clarity, we did not introduce specific real values for the expected loss of each expert on each of the half intervals, but that can be done straightforwardly.",4.1. Bias problem,[0],[0]
"We have also verified experimentally with such values that the bias problem just pointed out indeed leads to poor regret for UCB-NT.
ALGORITHM 1: UCB-NT for t > 1",4.1. Bias problem,[0],[0]
"do
RECEIVE(xt); ⇠It argmin⇠j2E n bµj,t 1 Sj,t 1 o ; for ⇠j 2 E do Qj,t Pt s=1 1j2Ns(Is) ;
Sj,t q
5 log t Qj,t ;
bµj,t 1Qj,t Pt
s=1 L(⇠j , zs)1j2Ns(Is).",4.1. Bias problem,[0],[0]
"end for
end for
hand, we know that if we were to avoid using feedback graphs at all (which is always possible using UCB), we would always be able to define unbiased loss estimates.",4.1. Bias problem,[0],[0]
A natural question is then: can we construct time-varying feedback graphs that lead to unbiased loss observations?,4.1. Bias problem,[0],[0]
"In the next section, we show how to design such a sequence of auxiliary feedback graphs, which in turn allows us to then extend UCB-NT to the setting of time-varying feedback graphs for general loss functions.",4.1. Bias problem,[0],[0]
"Under this assumption, we can achieve unbiased empirical estimates of the average losses µj of the experts, which will allow us to apply standard concentration bounds in the proof of this algorithm.",4.1. Bias problem,[0],[0]
"We now show that UCB-NT benefits from favorable guarantees, so long as the feedback graph GABSt it uses at time t depends only on events up to time t 1.",4.2. Time-varying graphs for UCB-NT,[0],[0]
"This extension works for general bounded losses and does not only apply to our specific abstention loss L.
So, let us assume that the feedback graph in round t (and the associated out-neighborhoods Nt(·)) in Algorithm 1 only depends on the observed losses L(⇠i, zs) and inputs xs, for s = 1, . . .",4.2. Time-varying graphs for UCB-NT,[0],[0]
", t 1, and i 2",4.2. Time-varying graphs for UCB-NT,[0],[0]
"[K], and let us denote this feedback graph by Gt, so as not to get confused with GABSt .",4.2. Time-varying graphs for UCB-NT,[0],[0]
"Under this assumption, we can derive strong regret guarantees for UCBNT with time-varying graphs.",4.2. Time-varying graphs for UCB-NT,[0],[0]
Our guarantees are expressed in terms of the best sequence of admissible p-partitionings of graphs Gt.,4.2. Time-varying graphs for UCB-NT,[0],[0]
"For p 2 [K], we say that (Ct,k)k2[p] is an admissible p-partitioning of Gt = (V, Et) if V = {⇠j : j 2 [K]} is the union of p (disjoint) components Ct,k, that is V = S k2[p] Ct,k, and all vertices within a component Ct,k are neighbors in Gt with reciprocal edges: if ⇠i and ⇠j are in Ct,k, then we have ⇠i 2 Nt(⇠j) and ⇠j 2 Nt(⇠i).",4.2. Time-varying graphs for UCB-NT,[0],[0]
Note that admissible p-partitionings are typically not unique since two neighbor vertices ⇠i and ⇠j may be placed in the same component or not.,4.2. Time-varying graphs for UCB-NT,[0],[0]
"We denote by Sp the set of all sequences ((C1,k)k2[p], . . .",4.2. Time-varying graphs for UCB-NT,[0],[0]
", (CT,k)k2[p]) of admissible p-partitionings (Ct,k)k2[p] of graphs Gt.",4.2. Time-varying graphs for UCB-NT,[0],[0]
"Moreover, for any sequence ((C1,k)k2[p], . . .",4.2. Time-varying graphs for UCB-NT,[0],[0]
", (CT,k)k2[p]) in Sp, we denote by Ck the union of the components indexed by k over all
rounds: Ck = S t2[T ] Ct,k.
Theorem 3 Assume that, for all t 2 [T ], the feedback graph Gt depends only on information up to time t 1.",4.2. Time-varying graphs for UCB-NT,[0],[0]
"Then, the regret of UCB-NT is bounded as follows:
O ⇣ E h min p,Sp X
k2[p]
maxj2Ck j minj2Ck 2 j
log(T )",4.2. Time-varying graphs for UCB-NT,[0],[0]
+,4.2. Time-varying graphs for UCB-NT,[0],[0]
"K i⌘ .
",4.2. Time-varying graphs for UCB-NT,[0],[0]
"For a sequence Sp made up of the same partition (C1,k)k2[p] repeated T times, the theorem gives a bound on the regret based on this fixed partition, as it is the sum of p components, one per cluster C1,k in the partition.",4.2. Time-varying graphs for UCB-NT,[0],[0]
"The minimum over (p, Sp) then simply chooses the number of clusters p and the partitioning of V into p clusters having the smallest regret.
",4.2. Time-varying graphs for UCB-NT,[0],[0]
Theorem 3 can be interpreted as an extension of Theorem 2 in Caron et al. (2012) to time-varying feedback graphs.,4.2. Time-varying graphs for UCB-NT,[0],[0]
"Its proof involves showing that the use of feedback graphs Gt that depend only on information up to t 1 can result in unbiased loss estimates, and it also uses the newly defined notion of admissible p-partitionings to derive a time-varying bound that leverages the shared updates from the graph.
",4.2. Time-varying graphs for UCB-NT,[0],[0]
"Moreover, the bound illustrates that if the feedback graphs in a problem admit a p-partitioning for some small p⌧ K (e.g. if the feedback graphs can be decomposed into a small number of components that are approximately fixed across time) for which maxj2Ck j ⇡ minj2Ck j , then this bound can be up to a factor pK tighter than the bound guaranteed by the standard UCB algorithm.",4.2. Time-varying graphs for UCB-NT,[0],[0]
"Moreover, this regret guarantee is always more favorable than that of the standard UCB since the (trivial) K-partitioning that splits V into K singletons for all t is an admissible K-partitioning for all Gt’s.",4.2. Time-varying graphs for UCB-NT,[0],[0]
"Furthermore, note that by construction, all vertices within the same component of an admissible p-partitioning are connected to one another.",4.2. Time-varying graphs for UCB-NT,[0],[0]
"Thus, if the feedback graph is fixed throughout all rounds and we interpret the doubly-directed edges as edges of an undirected graph GU , we straightforwardly obtain the following result, which is comparable to Theorem 2 in (Caron et al., 2012).
",4.2. Time-varying graphs for UCB-NT,[0],[0]
Corollary 1,4.2. Time-varying graphs for UCB-NT,[0],[0]
"If the feedback graph Gt = G is fixed over time, then the guarantee of Theorem 3 is upper-bounded by:
O ⇣ min C X
C2C
maxi2C",4.2. Time-varying graphs for UCB-NT,[0],[0]
i mini2C,4.2. Time-varying graphs for UCB-NT,[0],[0]
"2i
log(T )",4.2. Time-varying graphs for UCB-NT,[0],[0]
+,4.2. Time-varying graphs for UCB-NT,[0],[0]
"K ⌘ ,
the outer minimum being over all clique coverings C of GU .
",4.2. Time-varying graphs for UCB-NT,[0],[0]
Caron et al. (2012) present matching lower bounds for the case of stochastic bandits with a fixed feedback graph.,4.2. Time-varying graphs for UCB-NT,[0],[0]
"Since we can again design abstention scenarios with fixed feedback graphs, these bounds carry over to our setting.
",4.2. Time-varying graphs for UCB-NT,[0],[0]
"Now, how can we use the results of this section to design an algorithm for the abstention scenario?",4.2. Time-varying graphs for UCB-NT,[0],[0]
"The natural feedback
graphs we discussed in Section 3 are no longer applicable since GABSt depends on xt.",4.2. Time-varying graphs for UCB-NT,[0],[0]
"Nevertheless, we will present two solutions to this problem.",4.2. Time-varying graphs for UCB-NT,[0],[0]
"In Section 4.3, we present a solution with a fixed graph G that closely captures the problem of learning with abstention.",4.2. Time-varying graphs for UCB-NT,[0],[0]
"Next, in Section 4.4, we will show how to define and leverage a time-varying graph Gt that is estimated based on past observations.",4.2. Time-varying graphs for UCB-NT,[0],[0]
"In this section, we define a subset feedback graph, GSUB, that captures the most informative feedback in the problem of learning with abstention and yet is safe in the sense that it does not depend on xt.",4.3. UCB-N with the subset feedback graph,[0],[0]
"The definition of the graph is based on the following simple observation: if the abstention region associated with ⇠i is a subset of that of ⇠j , then, if ⇠i is selected at some round t and is abstaining, so is ⇠j .",4.3. UCB-N with the subset feedback graph,[0],[0]
"For an example, see ⇠i and ⇠j in Figure 4 (top).",4.3. UCB-N with the subset feedback graph,[0],[0]
"Crucially, this implication holds regardless of the particular input point xt received in the region of abstention of ⇠i. Thus, the set of vertices of GSUB is E, and GSUB admits an edge from ⇠i to ⇠j , iff {x 2 X : ri(x) 6 0} ✓ {x 2 X : rj(x) 6 0}.",4.3. UCB-N with the subset feedback graph,[0],[0]
"Since GSUB does not vary with time, it trivially verifies the condition of the previous section.",4.3. UCB-N with the subset feedback graph,[0],[0]
"Thus, UCB-NT run with GSUB admits the regret guarantees of Theorem 3, where the admissible p-partitionings are those of fixed graph GSUB.
",4.3. UCB-N with the subset feedback graph,[0],[0]
The example of Section 4.1 illustrated a bias problem in a special case where the feedback graphs Gt were not subgraphs of GSUB.,4.3. UCB-N with the subset feedback graph,[0],[0]
"The following result shows more generally that feedback graphs not included in GSUB may result in catastrophic regret behavior.
",4.3. UCB-N with the subset feedback graph,[0],[0]
Proposition 1 Assume that UCB-NT is run with feedback graphs Gt that are not subsets of GSUB.,4.3. UCB-N with the subset feedback graph,[0],[0]
"Then, there exists a family of predictors H, a Lipschitz loss function ` in (1), and a distribution D over zts for which UCB-NT incurs linear regret with arbitrarily high probability.
",4.3. UCB-N with the subset feedback graph,[0],[0]
The proof of the proposition is given in Appendix C.3.,4.3. UCB-N with the subset feedback graph,[0],[0]
"In view of this result, no fixed feedback graph for UCB-NT can be more informative than GSUB.",4.3. UCB-N with the subset feedback graph,[0],[0]
But how can we leverage past observations (up to time t 1) to derive a feedback graph that would be more informative than the simple subset graph GSUB?,4.3. UCB-N with the subset feedback graph,[0],[0]
The next section provides a solution based on feedback graphs estimated based on past observations and a new algorithm.,4.3. UCB-N with the subset feedback graph,[0],[0]
We seek graphs Gt that admit GSUB as a subgraph.,4.4. UCB-GT algorithm,[0],[0]
We will show how certain types of edges can be safely added to GSUB based on past observations.,4.4. UCB-GT algorithm,[0],[0]
"This leads to a new algorithm, UCB-GT (UCB with estimated time-varying graph), whose pseudocode is given in Algorithm 2.",4.4. UCB-GT algorithm,[0],[0]
"As illustrated by Figure 4, the key idea of UCB-GT is to augment
ALGORITHM 2: UCB-GT for t > 1",4.4. UCB-GT algorithm,[0],[0]
"do
RECEIVE(xt); ⇠It argmin⇠i2E bµi,t 1 Si,t 1 , where Si,t 1 is as in Algorithm 1; for ⇠i 2 E do
if bpt 1It,i 6",4.4. UCB-GT algorithm,[0],[0]
"i,t 1 then Qi,t Qi,t 1 + 1; if rIt(xt) 6 0 ^ ri(xt)",4.4. UCB-GT algorithm,[0],[0]
> 0,4.4. UCB-GT algorithm,[0],[0]
"then bµi,t ⇣ 1 1Qi,t ⌘ bµi,t 1; (*)
else bµi,t L(⇠i,zt)Qi,t + ⇣ 1 1Qi,t ⌘ bµi,t 1;
else Qi,t Qi,t 1, bµi,t bµi,t 1 .",4.4. UCB-GT algorithm,[0],[0]
"end for
end for
GSUB with edges from ⇠j to ⇠i where the subset property {x : rj(x) 6 0} ✓ {x : ri(x) 6 0} may not hold, but where the implication (rj(x) 6 0) ri(x) 6 0) holds with high probability over the choice of x 2 X, that is, the region {x : rj(x) 6 0 ^",4.4. UCB-GT algorithm,[0],[0]
ri(x) > 0} admits low probability.,4.4. UCB-GT algorithm,[0],[0]
"Of course, adding such an edge ⇠j !",4.4. UCB-GT algorithm,[0],[0]
⇠i can cause the estimation bias of Section 4.1.,4.4. UCB-GT algorithm,[0],[0]
"But, if we restrict ourselves to cases where pj,i = P[rj(x) 6 0 ^ ri(x) > 0] is upper bounded by some carefully chosen quantity that changes over rounds, the effect of this bias will be limited.",4.4. UCB-GT algorithm,[0],[0]
"In reverse, as illustrated in Figure 4, the resulting feedback graph can be substantially more beneficial since it may have many more edges than GSUB, hence leading to more frequent updates of the experts’ losses and more favorable regret guarantees.",4.4. UCB-GT algorithm,[0],[0]
"This benefit is further corroborated by our experimental results (Section 5).
",4.4. UCB-GT algorithm,[0],[0]
"Since we do not have access to pj,i, we use instead empirical estimates",4.4. UCB-GT algorithm,[0],[0]
"bpt 1j,i := 1t 1 Pt 1 s=1 1rj(xs)60,ri(xs)>0.",4.4. UCB-GT algorithm,[0],[0]
"At time t, if expert ⇠j is selected, we update expert ⇠i if the condition bpt",4.4. UCB-GT algorithm,[0],[0]
"1j,i 6",4.4. UCB-GT algorithm,[0],[0]
"i,t 1 holds with i,t 1 =p
5Qi(t 1) log(t)/((K 1)(t 1)).",4.4. UCB-GT algorithm,[0],[0]
"If the expert ⇠It chosen abstains while expert ⇠j predicts and satisfies bpt 1It,j 6 j,t 1, then we do not have access to the true label yt.",4.4. UCB-GT algorithm,[0],[0]
"In that case, we update optimistically our empirical estimate as if the expert had loss 0 at that round (Step (*) in Alg. 2).
",4.4. UCB-GT algorithm,[0],[0]
The feedback graph Gt just described can be defined via the out-neighborhood of vertex ⇠j : Nt(j) = {⇠i 2 E :,4.4. UCB-GT algorithm,[0],[0]
"bpt 1j,i 6 i,t 1}.",4.4. UCB-GT algorithm,[0],[0]
"Let Sp = (Ct,k)t2[T ],k2[p] denote any sequence of admissible p-partitionings of these feedback graphs, then the following regret guarantee holds for UCB-GT.
",4.4. UCB-GT algorithm,[0],[0]
Theorem 4,4.4. UCB-GT algorithm,[0],[0]
For any t 2,4.4. UCB-GT algorithm,[0],[0]
"[T ], let the feedback graph Gt be defined by the out-neighborhood Nt(j) = {⇠i 2 E : bpt",4.4. UCB-GT algorithm,[0],[0]
"1j,i 6 i,t 1}.",4.4. UCB-GT algorithm,[0],[0]
"Then, the regret of UCB-GT is bounded as follows:
O ⇣ E h min p,Sp X
k2[p]
maxj2Ck j minj2Ck 2 j
log(T )",4.4. UCB-GT algorithm,[0],[0]
+,4.4. UCB-GT algorithm,[0],[0]
"K i⌘ .
",4.4. UCB-GT algorithm,[0],[0]
"Since the graph Gt of UCB-GT has more edges than GSUB, it admits more admissible partitionings than GSUB, which leads to a more favorable guarantee than that of UCB-NT run with GSUB.",4.4. UCB-GT algorithm,[0],[0]
The proof of this result differs from the standard UCB analysis and that of Theorem 3 in that it involves showing that the UCB-GT algorithm can adequately control the amount of bias introduced by the skewed loss estimates.,4.4. UCB-GT algorithm,[0],[0]
The experiments in the next section provide an empirical validation of this theoretical comparison.,4.4. UCB-GT algorithm,[0],[0]
"In this section, we report the results of several experiments on ten datasets comparing UCB-GT, UCB-NT with feedback graph GSUB, vanilla UCB (with no sharing information across experts), as well as Full-Supervision, FS. FS is an algorithm that at each round chooses the expert ⇠j with the smallest abstention loss so far, bµj,t 1, and even if this expert abstains, the algorithm receives the true label and can update the empirical abstention loss estimates for all experts.",5. Experiments,[0],[0]
"FS reflects an unrealistic and overly optimistic scenario that clearly falls outside the abstention setting, but it provides an upper bound for the best performance we may hope for.
",5. Experiments,[0],[0]
"We used the following eight datasets from the UCI data repository: HIGGS, phishing, ijcnn, covtype, eye, skin, cod-rna, and guide.",5. Experiments,[0],[0]
"We also used the CIFAR dataset from (Krizhevsky et al., 2009), where we extracted the first twenty-five principal components and used their
projections as features, and a synthetic dataset of points drawn according to the uniform distribution in [ 1, 1]2.",5. Experiments,[0],[0]
"For each dataset, we generated a total of K = 2,100 experts and all the algorithms were tested for a total of T = 10,000 rounds.",5. Experiments,[0],[0]
"The experts, ⇠ = (h, r), were chosen in the following way.",5. Experiments,[0],[0]
"The predictors h are hyperplanes centered at the origin whose normal vector in Rd is drawn randomly from the Gaussian distribution, N (0, 1)d, where d is the dimension of the feature space of the dataset.",5. Experiments,[0],[0]
"The abstention functions r are concentric annuli around the origin with radii in (0, p d 20 , 2 p d 20 . . .",5. Experiments,[0],[0]
", p d).",5. Experiments,[0],[0]
"For each dataset, we generated 100 predictors and each predictor h is paired with the 21 abstention functions r.",5. Experiments,[0],[0]
"For a fixed set of experts, we first calculated the regret by averaging over five random draws of the data, where the best-in-class expert was determined in hindsight as the one with the minimum average cumulative abstention loss.",5. Experiments,[0],[0]
We then repeated this experiment five times over different sets of experts and averaged the results.,5. Experiments,[0],[0]
"We report these results for c 2 {0.1, 0.2, 0.3}.
",5. Experiments,[0],[0]
Figure 5 shows the averaged regret Rt(·)/t with standard deviations across the five repetitions for the different algorithms as a function of t 2,5. Experiments,[0],[0]
[T ] for two datasets.,5. Experiments,[0],[0]
"In Appendix D, we present plots of the regret for all ten datasets.",5. Experiments,[0],[0]
These results show that UCB-GT outperforms both UCB-NT and UCB on all datasets for all abstention cost values.,5. Experiments,[0],[0]
"Remarkably, UCB-GT’s performance is close to that of FS for most datasets, thereby implying that UCB-GT attains almost the best regret that we could hope for.",5. Experiments,[0],[0]
We also find that UCB-NT performs better than the vanilla,5. Experiments,[0],[0]
"UCB.
Figure 5 also illustrates the fraction of points in which the chosen expert abstains, as well as the number of edges in the feedback graph as a function of rounds.",5. Experiments,[0],[0]
We only plot the number of edges of UCB-GT since that is the only graph that varies with time.,5. Experiments,[0],[0]
"For both experiments depicted and in general for the rest of the datasets, the number of edges for UCB-GT is between 1 million to 3 million, which is at least
a factor of 5 more than for UCB-NT, where the number of edges we observed are of the order 200,000.",5. Experiments,[0],[0]
FS enjoys the full information property and the number of edges is fixed at 4 million (complete graph).,5. Experiments,[0],[0]
The increased information sharing of UCB-GT is clearly a strong contributing factor to the algorithm’s improvement in regret relative to UCB-NT.,5. Experiments,[0],[0]
"In general, we find that, provided that the estimation bias is controlled, the higher is the number of edges, the smaller the regret.",5. Experiments,[0],[0]
"Regarding the value of the cost c, as expected, we observe that the fraction of points that the chosen expert abstains on always decreases as c increases, but also that that fraction depends on the dataset and the experts used.
",5. Experiments,[0],[0]
"Finally, Appendix D includes more experiments for different aspects of the problem.",5. Experiments,[0],[0]
"In particular, we tested how the number of experts or a different choice of experts (confidencebased experts) affected the results.",5. Experiments,[0],[0]
"We also experimented with some extreme abstention costs and, as expected, found the fraction of abstained points to be large for c = 0.001 and small for c = 0.9.",5. Experiments,[0],[0]
"In all of these additional experiments, UCB-GT outperformed UCB-NT.",5. Experiments,[0],[0]
"We presented a comprehensive analysis of the novel setting of online learning with abstention, including algorithms with favorable guarantees both in the stochastic and adversarial scenarios, and extensive experiments demonstrating the performance of UCB-GT in practice.",6. Conclusion,[0],[0]
"Our algorithms and analysis can be straightforwardly extended to similar problems, including the multi-class and regression settings, as well as other related scenarios, such as online learning with budget constraints.",6. Conclusion,[0],[0]
A key idea behind the design of our algorithms in the stochastic setting is to leverage the stochastic sequence of feedback graphs.,6. Conclusion,[0],[0]
This idea can perhaps be generalized and applied to other problems where time-varying feedback graphs naturally appear.,6. Conclusion,[0],[0]
"We present an extensive study of a key problem in online learning where the learner can opt to abstain from making a prediction, at a certain cost.",abstractText,[0],[0]
"In the adversarial setting, we show how existing online algorithms and guarantees can be adapted to this problem.",abstractText,[0],[0]
"In the stochastic setting, we first point out a bias problem that limits the straightforward extension of algorithms such as UCB-N to this context.",abstractText,[0],[0]
"Next, we give a new algorithm, UCBGT, that exploits historical data and time-varying feedback graphs.",abstractText,[0],[0]
"We show that this algorithm benefits from more favorable regret guarantees than a natural extension of UCB-N. We further report the results of a series of experiments demonstrating that UCB-GT largely outperforms that extension of UCB-N, as well as other standard baselines.",abstractText,[0],[0]
Online Learning with Abstention,title,[0],[0]
"Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1307–1316, Austin, Texas, November 1-5, 2016. c©2016 Association for Computational Linguistics
We introduce an online neural sequence to sequence model that learns to alternate between encoding and decoding segments of the input as it is read. By independently tracking the encoding and decoding representations our algorithm permits exact polynomial marginalization of the latent segmentation during training, and during decoding beam search is employed to find the best alignment path together with the predicted output sequence. Our model tackles the bottleneck of vanilla encoder-decoders that have to read and memorize the entire input sequence in their fixedlength hidden states before producing any output. It is different from previous attentive models in that, instead of treating the attention weights as output of a deterministic function, our model assigns attention weights to a sequential latent variable which can be marginalized out and permits online generation. Experiments on abstractive sentence summarization and morphological inflection show significant performance gains over the baseline encoder-decoders.",text,[0],[0]
The problem of mapping from one sequence to another is an importance challenge of natural language processing.,1 Introduction,[0],[0]
Common applications include machine translation and abstractive sentence summarisation.,1 Introduction,[0],[0]
"Traditionally this type of problem has been tackled by a combination of hand-crafted features, alignment models, segmentation heuristics, and language models, all of which are tuned separately.
",1 Introduction,[0],[0]
"The recently introduced encoder-decoder paradigm has proved very successful for machine translation, where an input sequence is encoded into a fixed-length vector and an output sequence is then decoded from said vector (Kalchbrenner and Blunsom, 2013; Sutskever et al., 2014; Cho et al., 2014).",1 Introduction,[0],[0]
"This architecture is appealing, as it makes it possible to tackle the problem of sequenceto-sequence mapping by training a large neural network in an end-to-end fashion.",1 Introduction,[0],[0]
"However it is difficult for a fixed-length vector to memorize all the necessary information of an input sequence, especially for long sequences.",1 Introduction,[0],[0]
"Often a very large encoding needs to be employed in order to capture the longest sequences, which invariably wastes capacity and computation for short sequences.",1 Introduction,[0],[0]
"While the attention mechanism of Bahdanau et al. (2015) goes some way to address this issue, it still requires the full input to be seen before any output can be produced.
",1 Introduction,[0],[0]
"In this paper we propose an architecture to tackle the limitations of the vanilla encoder-decoder model, a segment to segment neural transduction model (SSNT) that learns to generate and align simultaneously.",1 Introduction,[0],[0]
"Our model is inspired by the HMM word alignment model proposed for statistical machine translation (Vogel et al., 1996; Tillmann et al., 1997); we impose a monotone restriction on the alignments but incorporate recurrent dependencies on the input which enable rich locally non-monotone alignments to be captured.",1 Introduction,[0],[0]
"This is similar to the sequence transduction model of Graves (2012), but we propose alignment distributions which are parameterised separately, making the model more flexible
1307
and allowing online inference.",1 Introduction,[0],[0]
Our model introduces a latent segmentation which determines correspondences between tokens of the input sequence and those of the output sequence.,1 Introduction,[0],[0]
The aligned hidden states of the encoder and decoder are used to predict the next output token and to calculate the transition probability of the alignment.,1 Introduction,[0],[0]
We carefully design the input and output RNNs such that they independently update their respective hidden states.,1 Introduction,[0],[0]
This enables us to derive an exact dynamic programme to marginalize out the hidden segmentation during training and an efficient beam search to generate online the best alignment path together with the output sequence during decoding.,1 Introduction,[0],[0]
"Unlike previous recurrent segmentation models that only capture dependencies in the input (Graves et al., 2006; Kong et al., 2016), our segmentation model is able to capture unbounded dependencies in both the input and output sequences while still permitting polynomial inference.
",1 Introduction,[0],[0]
"While attentive models treat the attention weights as output of a deterministic function, our model assigns attention weights to a sequential latent variable which can be marginalized out.",1 Introduction,[0],[0]
"Our model is general and could be incorporated into any RNN-based encoder-decoder architecture, such as Neural Turing Machines (Graves et al., 2014), memory networks (Weston et al., 2015; Kumar et al., 2016) or stackbased networks (Grefenstette et al., 2015), enabling such models to process data online.
",1 Introduction,[0],[0]
"We conduct experiments on two different transduction tasks, abstractive sentence summarisation (sequence to sequence mapping at word level) and morphological inflection generation (sequence to sequence mapping at character level).",1 Introduction,[0],[0]
"We evaluate our proposed algorithms in both the online setting, where the input is encoded with a unidirectional LSTM, and where the whole input is available such that it can be encoded with a bidirectional network.",1 Introduction,[0],[0]
"The experimental results demonstrate the effectiveness of SSNT — it consistently output performs the baseline encoder-decoder approach while requiring significantly smaller hidden layers, thus showing that the segmentation model is able to learn to break one large transduction task into a series of smaller encodings and decodings.",1 Introduction,[0],[0]
When bidirectional encodings are used the segmentation model outperforms an attention-based benchmark.,1 Introduction,[0],[0]
"Quali-
",1 Introduction,[0],[0]
tative analysis shows that the alignments found by our model are highly intuitive and demonstrates that the model learns to read ahead the required number of tokens before producing output.,1 Introduction,[0],[0]
Let xI1 be the input sequence of length I and y J 1 the output sequence of length J .,2 Model,[0],[0]
"Let yj denote the jth token of y. Our goal is to model the conditional distribution
p(y|x)",2 Model,[0],[0]
"= J∏
j=1
p(yj |yj−11 ,x).",2 Model,[0],[0]
"(1)
We introduce a hidden alignment sequence aJ1 where each aj = i corresponds to an input position i ∈ {1, . .",2 Model,[0],[0]
.,2 Model,[0],[0]
", I} that we want to focus on when generating yj .",2 Model,[0],[0]
"Then p(y|x) is calculated by marginalizing over all the hidden alignments,
p(y|x) =",2 Model,[0],[0]
"∑a p(y,a|x) (2)",2 Model,[0],[0]
"≈ ∑a ∏J j=1 p(aj |aj−1,y
j−1 1 ,x)︸ ︷︷ ︸
transition probability
·
p(yj |yj−11 , aj ,x).︸ ︷︷ ︸ word prediction
Figure 1 illustrates the model graphically.",2 Model,[0],[0]
Each path from the top left node to the right-most column in the graph corresponds to an alignment.,2 Model,[0],[0]
"We constrain the alignments to be monotone, i.e. only forward and downward transitions are permitted at each point in the grid.",2 Model,[0],[0]
This constraint enables the model to learn to perform online generation.,2 Model,[0],[0]
"Additionally, the model learns to align input and output segments, which means that it can learn local reorderings by memorizing phrases.",2 Model,[0],[0]
"Another possible constraint on the alignments would be to ensure that the entire input sequence is consumed before last output word is emitted, i.e. all valid alignment paths have to end in the bottom right corner of the grid.",2 Model,[0],[0]
"However, we do not enforce this constraint in our setup.
",2 Model,[0],[0]
The probability contributed by an alignment is obtained by accumulating the probability of word predictions at each point on the path and the transition probability between points.,2 Model,[0],[0]
"The transition probabilities and the word output probabilities are modeled by neural networks, which are described in detail in the following sub-sections.",2 Model,[0],[0]
"The input sentence x is encoded with a Recurrent Neural Network (RNN), in particular an LSTM (Hochreiter and Schmidhuber, 1997).",2.1 Probabilities of Output Word Predictions,[0],[0]
The encoder can either be a unidirectional or bidirectional LSTM.,2.1 Probabilities of Output Word Predictions,[0],[0]
If a unidirectional encoder is used the model is able to read input and generate output symbols online.,2.1 Probabilities of Output Word Predictions,[0],[0]
"The hidden state vectors are computed as
h→i = RNN(h → i−1, v (e)(xi)), (3) h←i",2.1 Probabilities of Output Word Predictions,[0],[0]
"= RNN(h ← i+1, v (e)(xi)), (4)
where v(e)(xi) denotes the vector representation of the token x, and h→i and h ←",2.1 Probabilities of Output Word Predictions,[0],[0]
"i are the forward and backward hidden states, respectively.",2.1 Probabilities of Output Word Predictions,[0],[0]
"For a bidirectional encoder, they are concatenated as hi =
[h→i ;h ← i ]; and for unidirectional encoder hi = h → i .",2.1 Probabilities of Output Word Predictions,[0],[0]
"The hidden state sj of the RNN for the output sequence y is computed as
sj = RNN(sj−1, v(d)(yj−1)), (5)
where v(d)(yj−1) is the encoded vector of the previously generated output word yj−1.",2.1 Probabilities of Output Word Predictions,[0],[0]
"That is, sj encodes yj−11 .
",2.1 Probabilities of Output Word Predictions,[0],[0]
"To calculate the probability of the next word, we concatenate the aligned hidden state vectors sj and haj and feed the result into a softmax layer,
p(yj = l|yj−11 , aj ,x) = p(yj = l|haj , sj) = softmax(Ww[haj ; sj ] + bw)l.
",2.1 Probabilities of Output Word Predictions,[0],[0]
"(6)
The word output distribution in Graves (2012) is parameterised in similar way.
",2.1 Probabilities of Output Word Predictions,[0],[0]
Figure 2 illustrates the model structure.,2.1 Probabilities of Output Word Predictions,[0],[0]
"Note that the hidden states of the input and output decoders are kept independent to permit tractable inference, while the output distributions are conditionally dependent on both.",2.1 Probabilities of Output Word Predictions,[0],[0]
"As the alignments are constrained to be monotone, we can treat the transition from timestep j to j+1 as a sequence of shift and emit operations.",2.2 Transition Probabilities,[0],[0]
"Specifically, at each input position, a decision of shift or emit is made by the model; if the operation is emit then the next output word is generated; otherwise, the model will shift to the next input word.",2.2 Transition Probabilities,[0],[0]
"While the multinomial distribution is an alternative for parameterising alignments, the shift/emit parameterisation does not place an upper limit on the jump size, as a multinomial distribution would, and biases the model towards shorter jump sizes, which a multinomial model would have to learn.
",2.2 Transition Probabilities,[0],[0]
We describe two methods for modelling the alignment transition probability.,2.2 Transition Probabilities,[0],[0]
The first approach is independent of the input or output words.,2.2 Transition Probabilities,[0],[0]
"To parameterise the alignment distribution in terms of shift and emit operations we use a geometric distribution,
p(aj |aj−1) = (1− e)aj−aj−1e, (7)
where e is the emission probability.",2.2 Transition Probabilities,[0],[0]
"This transition probability only has one parameter e, which can be
estimated directly by maximum likelihood as
e = ∑ n Jn∑
n",2.2 Transition Probabilities,[0],[0]
In + ∑ n,2.2 Transition Probabilities,[0],[0]
"Jn , (8)
where In and Jn are the lengths of the input and output sequences of training example n, respectively.
",2.2 Transition Probabilities,[0],[0]
"For the second method we model the transition probability with a neural network,
p(a1 = i) =
i−1∏
d=1
(1− p(ed,1))p(ei,1),
p(aj = i|aj−1 = k) = i−1∏
d=k
(1− p(ed,j))p(ei,j),
(9)
where p(ei,j) denotes the probability of emit for the alignment aj = i.",2.2 Transition Probabilities,[0],[0]
"This probability is obtained by feeding [hi; sj ] into a feed forward neural network,
p(ei,j) = σ(MLP(Wt[hi; sj ] + bt)).",2.2 Transition Probabilities,[0],[0]
"(10)
For simplicity, p(aj = i|aj−1 = k, sj ,hik) is abbreviated as p(aj = i|aj−1 = k).",2.2 Transition Probabilities,[0],[0]
"Since there are an exponential number of possible alignments, it is computationally intractable to
explicitly calculate every p(y,a|x) and then sum them to get the conditional probability p(y|x).",3 Training and Decoding,[0],[0]
"We instead approach the problem using a dynamicprogramming algorithm similar to the forwardbackward algorithm for HMMs (Rabiner, 1989).",3 Training and Decoding,[0],[0]
"For an input x and output y, the forward variable α(i, j) = p(aj = i,y j 1|x).",3.1 Training,[0],[0]
"The value of α(i, j) is computed by summing over the probabilities of every path that could lead to this cell.",3.1 Training,[0],[0]
"Formally, α(i, j) is defined as follows:
For i ∈",3.1 Training,[0],[0]
"[1, I]:
α(i, 1) = p(a1 = i)p(y1|hi, s1).",3.1 Training,[0],[0]
"(11)
",3.1 Training,[0],[0]
For j ∈,3.1 Training,[0],[0]
"[2, J ], i ∈",3.1 Training,[0],[0]
"[1, I]: α(i, j) = p(yj |hi, sj)· (12)
i∑
k=1
α(k, j − 1)p(aj = i|aj−1 = k).
",3.1 Training,[0],[0]
"The backward variables, defined as β(i, j) = p(yJj+1|aj = i,yj1,x), are computed as:
For i ∈",3.1 Training,[0],[0]
"[1, I]: β(i, J) = 1. (13)
",3.1 Training,[0],[0]
For j ∈,3.1 Training,[0],[0]
"[1, J − 1], i ∈",3.1 Training,[0],[0]
"[1, I]:
β(i, j) = I∑
k=i
p(aj+1 = k|aj = i)β(k, j + 1)·
p(yj+1|hk, sj+1).",3.1 Training,[0],[0]
"(14) During training we estimate the parameters by minimizing the negative log likelihood of the training set S:
L(θ) = − ∑
(x,y)∈S log p(y|x;θ)
",3.1 Training,[0],[0]
"= − ∑
(x,y)∈S log
I∑
i=1
α(i, J).
",3.1 Training,[0],[0]
"(15)
Let θj be the neural network parameters w.r.t.",3.1 Training,[0],[0]
"the model output at position j. The gradient is computed as:
∂ log p(y|x;θ) ∂θ",3.1 Training,[0],[0]
"= J∑
j=1
I∑
i=1
∂ log p(y|x;θ) ∂α(i, j) ∂α(i, j) ∂θj .
(16)
",3.1 Training,[0],[0]
The derivative w.r.t.,3.1 Training,[0],[0]
"the forward weights is
∂ log p(y|x;θ) ∂α(i, j) = β(i, j) p(y|x;θ) .",3.1 Training,[0],[0]
"(17)
The derivative of the forward weights w.r.t.",3.1 Training,[0],[0]
"the model parameters at position j is
∂α(i, j) ∂θj = ∂p(yj |hi, sj) ∂θj α(i, j) p(yj |hi, sj) + p(yj |hi, sj) i∑
k=1
α(j − 1, k) ∂",3.1 Training,[0],[0]
"∂θj p(aj=i|aj−1=k).
(18)
",3.1 Training,[0],[0]
For the geometric distribution transition probability model ∂∂θj p(aj = i|aj−1 = k) = 0.,3.1 Training,[0],[0]
Algorithm 1 DP search algorithm Input: source sentence x Output: best output sentence y∗,3.2 Decoding,[0],[0]
"Initialization: Q ∈ RI×Jmax , bp ∈ NI×Jmax , W ∈ NI×Jmax , Iend, Jend.",3.2 Decoding,[0],[0]
for i ∈,3.2 Decoding,[0],[0]
"[1, I] do
Q[i, 1]← maxy∈V p(a1 = i)p(y|hi, s1) bp[i, 1]← 0",3.2 Decoding,[0],[0]
"W [i, 1]← argmaxy∈V p(a1 = i)p(y|hi, s1)
end for for j ∈",3.2 Decoding,[0],[0]
"[2, Jmax] do
for i ∈",3.2 Decoding,[0],[0]
"[1, I] do Q[i, j]← maxy∈V,k∈[1,i]Q[k, j − 1]·
p(aj = i|aj−1 = k)p(y|hi, sj) bp[i, j],W",3.2 Decoding,[0],[0]
"[i, j]← argmaxy∈V,k∈[1,i] · Q[k, j − 1]p(aj = i|aj−1 = k)p(y|hi, sj)
end for Iend ← argmaxiQ[i, j] if W [Iend, j] = EOS then
Jend ← j break
end if end for return a sequence of words stored in W by following backpointers starting from (Iend, Jend).
",3.2 Decoding,[0],[0]
"For decoding, we aim to find the best output sequence y∗ for a given input sequence x:
y∗ = argmax y p(y|x) (19)
",3.2 Decoding,[0],[0]
"The search algorithm is based on dynamic programming (Tillmann et al., 1997).",3.2 Decoding,[0],[0]
"The main idea is to create a path probability matrix Q, and fill each cell Q[i, j] by recursively taking the most probable path that could lead to this cell.",3.2 Decoding,[0],[0]
We present the greedy search algorithm in Algorithm 1.,3.2 Decoding,[0],[0]
"We also implemented a beam search that tracks the k best partial sequences at position (i, j).",3.2 Decoding,[0],[0]
"The notation bp refers to backpointers, W stores words to be predicted, V denotes the output vocabulary, Jmax is the maximum length of the output sequences that the model is allowed to predict.",3.2 Decoding,[0],[0]
"We evaluate the effectiveness of our model on two representative natural language processing tasks, sentence compression and morphological inflection.",4 Experiments,[0],[0]
The primary aim of this evaluation is to assess whether our proposed architecture is able to outperform the baseline encoder-decoder model by overcoming its encoding bottleneck.,4 Experiments,[0],[0]
We further benchmark our results against an attention model in order to determine whether our alternative alignment strategy is able to provide similar benefits while processing the input online.,4 Experiments,[0],[0]
Sentence summarisation is the task of generating a condensed version of a sentence while preserving its meaning.,4.1 Abstractive Sentence Summarisation,[0],[0]
"In abstractive sentence summarisation, summaries are generated from the given vocabulary without the constraint of copying words in the input sentence.",4.1 Abstractive Sentence Summarisation,[0],[0]
"Rush et al. (2015) compiled a data set for this task from the annotated Gigaword data set (Graff et al., 2003; Napoles et al., 2012), where sentence-summary pairs are obtained by pairing the headline of each article with its first sentence.",4.1 Abstractive Sentence Summarisation,[0],[0]
"Rush et al. (2015) use the splits of 3.8m/190k/381k for training, validation and testing.",4.1 Abstractive Sentence Summarisation,[0],[0]
"In previous work on this dataset, Rush et al. (2015) proposed an attention-based model with feed-forward neural networks, and Chopra et al. (2016) proposed an attention-based recurrent encoder-decoder, similar to one of our baselines.
",4.1 Abstractive Sentence Summarisation,[0],[0]
"Due to computational constraints we place the following restrictions on the training and validation set:
1.",4.1 Abstractive Sentence Summarisation,[0],[0]
"The maximum lengths for the input sentences
and summaries are 50 and 25, respectively.
2.",4.1 Abstractive Sentence Summarisation,[0],[0]
"For each sentence-summary pair, the product of the input and output lengths should be no greater than 500.
",4.1 Abstractive Sentence Summarisation,[0],[0]
We use the filtered 172k pairs for validation and sample 1m pairs for training.,4.1 Abstractive Sentence Summarisation,[0],[0]
"While this training set is smaller than that used in previous work (and therefore our results cannot be compared directly against reported results), it serves our purpose for evaluating our algorithm against sequence to sequence and attention-based approaches under identical data conditions.",4.1 Abstractive Sentence Summarisation,[0],[0]
"Following from previous work (Rush et al., 2015; Chopra et al., 2016; Gülçehre et al., 2016), we report results on a randomly sampled test set of 2000 sentence-summary pairs.",4.1 Abstractive Sentence Summarisation,[0],[0]
"The quality of the generated summaries are evaluated by three versions of ROUGE for different match lengths, namely ROUGE-1 (unigrams), ROUGE-2 (bigrams), and ROUGE-L (longest-common substring).
",4.1 Abstractive Sentence Summarisation,[0],[0]
"For training, we use Adam (Kingma and Ba, 2015) for optimization, with an initial learning rate of 0.001.",4.1 Abstractive Sentence Summarisation,[0],[0]
The mini-batch size is set to 32.,4.1 Abstractive Sentence Summarisation,[0],[0]
"The number of hidden units H is set to 256 for both our model and the baseline models, and dropout of 0.2 is applied to the input of LSTMs.",4.1 Abstractive Sentence Summarisation,[0],[0]
All hyperparameters were optimised via grid search on the perplexity of the validation set.,4.1 Abstractive Sentence Summarisation,[0],[0]
"We use greedy decoding to generate summaries.
",4.1 Abstractive Sentence Summarisation,[0],[0]
"Table 1 displays the ROUGE-F1 scores of our models on the test set, together with baseline models, including the attention-based model.",4.1 Abstractive Sentence Summarisation,[0],[0]
Our models achieve significantly better results than the vanilla encoder-decoder and outperform the attention-based model.,4.1 Abstractive Sentence Summarisation,[0],[0]
"The fact that SSNT+ performs better is in line with our expectations, as the neural network-parameterised alignment model is more expressive than that modelled by geometric distribution.
",4.1 Abstractive Sentence Summarisation,[0],[0]
"To make further comparison, we experimented with different sizes of hidden units and adding more layers to the baseline encoder-decoder.",4.1 Abstractive Sentence Summarisation,[0],[0]
Table 2 lists the configurations of different models and their corresponding perplexities on the validation set.,4.1 Abstractive Sentence Summarisation,[0],[0]
We can see that the vanilla encoder-decoder tends to get better results by adding more hidden units and stacking more layers.,4.1 Abstractive Sentence Summarisation,[0],[0]
This is due to the limitation of compressing information into a fixed-size vector.,4.1 Abstractive Sentence Summarisation,[0],[0]
It has to use larger vectors and deeper structure in order to memorize more information.,4.1 Abstractive Sentence Summarisation,[0],[0]
"By contrast, our model can do well with smaller networks.",4.1 Abstractive Sentence Summarisation,[0],[0]
"In fact, even with 1 layer and 128 hidden units, our model works much better than the vanilla encoder-decoder with 3 layers and 256 hidden units per layer.",4.1 Abstractive Sentence Summarisation,[0],[0]
Morphological inflection generation is the task of predicting the inflected form of a given lexical item based on a morphological attribute.,4.2 Morphological Inflection,[0],[0]
The transformation from a base form to an inflected form usually includes concatenating it with a prefix or a suffix and substituting some characters.,4.2 Morphological Inflection,[0],[0]
"For example, the inflected form of a German stem abgang is abgängen when the case is dative and the number is plural.
",4.2 Morphological Inflection,[0],[0]
"In our experiments, we use the same dataset as
Faruqui et al. (2016).",4.2 Morphological Inflection,[0],[0]
"This dataset was originally created by Durrett and DeNero (2013) from Wiktionary, containing inflections for German nouns (de-N), German verbs (de-V), Spanish verbs (esV), Finnish noun and adjective (fi-NA), and Finnish verbs (fi-V).",4.2 Morphological Inflection,[0],[0]
It was further expanded by Nicolai et al. (2015) by adding Dutch verbs (nl-V) and French verbs (fr-V).,4.2 Morphological Inflection,[0],[0]
The number of inflection types for each language ranges from 8 to 57.,4.2 Morphological Inflection,[0],[0]
"The number of base forms, i.e. the number of instances in each dataset, ranges from 2000 to 11200.",4.2 Morphological Inflection,[0],[0]
"The predefined split is 200/200 for dev and test sets, and the rest of the data for training.
",4.2 Morphological Inflection,[0],[0]
"Our model is trained separately for each type of inflection, the same setting as the factored model described in Faruqui et al. (2016).",4.2 Morphological Inflection,[0],[0]
The model is trained to predict the character sequence of the inflected form given that of the stem.,4.2 Morphological Inflection,[0],[0]
The output is evaluated by accuracies of string matching.,4.2 Morphological Inflection,[0],[0]
For all the experiments on this task we use 128 hidden units for the LSTMs and apply dropout of 0.5 on the input and output of the LSTMs.,4.2 Morphological Inflection,[0],[0]
"We use Adam (Kingma and Ba, 2015) for optimisation with initial learning rate of 0.001.",4.2 Morphological Inflection,[0],[0]
"During decoding, beam search is employed with beam size of 30.
",4.2 Morphological Inflection,[0],[0]
"Table 3 gives the average accuracy of the uniSSNT+, biSSNT+, vanilla encoder-decoder, and attention-based models.",4.2 Morphological Inflection,[0],[0]
"The model with the best previous average result — denoted as adaptedseq2seq (FTND16) (Faruqui et al., 2016) — is also included for comparison.",4.2 Morphological Inflection,[0],[0]
Our biSSNT+ model outperforms the vanilla encoder-decoder by a large margin and almost matches the state-of-the-art result on this task.,4.2 Morphological Inflection,[0],[0]
"As mentioned earlier, a characteristic of these datasets is that the stems and their corre-
sponding inflected forms mostly overlap.",4.2 Morphological Inflection,[0],[0]
"Compare to the vanilla encoder-decoder, our model is better at copying and finding correspondences between prefix, stem and suffix segments.
",4.2 Morphological Inflection,[0],[0]
Table 4 compares the results of biSSNT+ and previous models on each individual dataset.,4.2 Morphological Inflection,[0],[0]
"DDN13 and NCK15 denote the models of Durrett and DeNero (2013) and Nicolai et al. (2015), respectively.",4.2 Morphological Inflection,[0],[0]
Both models tackle the task by feature engineering.,4.2 Morphological Inflection,[0],[0]
FTND16,4.2 Morphological Inflection,[0],[0]
"(Faruqui et al., 2016) adapted the vanilla encoder-decoder by feeding the i-th character of the encoded string as an extra input into the i-th position of the decoder.",4.2 Morphological Inflection,[0],[0]
It can be considered as a special case of our model by forcing a fixed diagonal alignment between input and output sequences.,4.2 Morphological Inflection,[0],[0]
Our model achieves comparable results to these models on all the datasets.,4.2 Morphological Inflection,[0],[0]
"Notably it outperforms other models on the Finnish noun and adjective, and verbs datasets, whose stems and inflected forms are the longest.",4.2 Morphological Inflection,[0],[0]
Figure 3 presents visualisations of segment alignments generated by our model for sample instances from both tasks.,5 Alignment Quality,[0],[0]
We see that the model is able to learn the correct correspondences between segments of the input and output sequences.,5 Alignment Quality,[0],[0]
"For instance, the alignment follows a nearly diagonal path for the example in Figure 3c, where the input and output sequences are identical.",5 Alignment Quality,[0],[0]
"In Figure 3b, it learns to add the prefix ‘ge’ at the start of the sequence and replace ‘en’ with ‘t’ after copying ‘zock’.",5 Alignment Quality,[0],[0]
We observe that the model is robust on long phrasal mappings.,5 Alignment Quality,[0],[0]
"As
shown in Figure 3a, the mapping between ‘the wall street journal asia, the asian edition of the us-based business daily’ and ‘wall street journal asia’ demonstrates that our model learns to ignore phrasal modifiers containing additional information.",5 Alignment Quality,[0],[0]
"We also find some examples of word reordering, e.g., the phrase ‘industrial production in france’ is reordered as ‘france industrial output’ in the model’s predicted output.",5 Alignment Quality,[0],[0]
"Our work is inspired by the seminal HMM alignment model (Vogel et al., 1996; Tillmann et al., 1997) proposed for machine translation.",6 Related Work,[0],[0]
"In contrast to that work, when predicting a target word we additionally condition on all previously generated words, which is enabled by the recurrent neural models.",6 Related Work,[0],[0]
This means that the model also functions as a conditional language model.,6 Related Work,[0],[0]
"It can therefore be applied directly, while traditional models have to be combined with a language model through a noisy channel in order to be effective.",6 Related Work,[0],[0]
"Additionally, instead of EM training on the most likely alignments at each
iteration, our model is trained with direct gradient descent, marginalizing over all the alignments.
",6 Related Work,[0],[0]
Latent variables have been employed in neural network-based models for sequence labelling tasks in the past.,6 Related Work,[0],[0]
"Examples include connectionist temporal classification (CTC) (Graves et al., 2006) for speech recognition and the more recent segmental recurrent neural networks (SRNNs) (Kong et al., 2016), with applications on handwriting recognition and part-of-speech tagging.",6 Related Work,[0],[0]
"Weighted finitestate transducers (WFSTs) have also been augmented to encode input sequences with bidirectional LSTMs (Rastogi et al., 2016), permitting exact inference over all possible output strings.",6 Related Work,[0],[0]
"While these models have been shown to achieve appealing performance on different applications, they have common limitations in terms of modelling dependencies between labels.",6 Related Work,[0],[0]
It is not possible for CTCs to model explicit dependencies.,6 Related Work,[0],[0]
"SRNNs and neural WFSTs model fixed-length dependencies, making it is difficult to carry out effective inference as the dependencies become longer.
",6 Related Work,[0],[0]
"Our model shares the property of the sequence
transduction model of Graves (2012) in being able to model unbounded dependencies between output tokens via an output RNN.",6 Related Work,[0],[0]
This property makes it possible to apply our model to tasks like summarisation and machine translation that require the tokens in the output sequence to be modelled highly dependently.,6 Related Work,[0],[0]
Graves (2012) models the joint distribution over outputs and alignments by inserting null symbols (representing shift operations) into the output sequence.,6 Related Work,[0],[0]
"During training the model uses dynamic programming to marginalize over permutations of the null symbols, while beam search is employed during decoding.",6 Related Work,[0],[0]
"In contrast our model defines a separate latent alignment variable, which adds flexibility to the way the alignment distribution can be defined (as a geometric distribution or parameterised by a neural network) and how the alignments can be constrained, without redefining the dynamic program.",6 Related Work,[0],[0]
"In addition to marginalizing during training, our decoding algorithm also makes use of dynamic programming, allowing us to use either no beam or small beam sizes.
",6 Related Work,[0],[0]
"Our work is also related to the attentionbased models first introduced for machine translation (Bahdanau et al., 2015).",6 Related Work,[0],[0]
"Luong et al. (2015) proposed two alternative attention mechanisms: a global method that attends all words in the input sentence, and a local one that points to parts of the input words.",6 Related Work,[0],[0]
"Another variation on this theme are pointer networks (Vinyals et al., 2015), where the outputs are pointers to elements of the variable-length input, predicted by the attention distribution.",6 Related Work,[0],[0]
Jaitly et al. (2016) propose an online sequence to sequence model with attention that conditions on fixed-sized blocks of the input sequence and emits output tokens corresponding to each block.,6 Related Work,[0],[0]
"The model is trained with alignment information to generate supervised segmentations.
",6 Related Work,[0],[0]
"Although our model shares the same idea of joint training and aligning with the attention-based models, our design has fundamental differences and advantages.",6 Related Work,[0],[0]
"While attention-based models treat the attention weights as output of a deterministic function (soft-alignment), in our model the attention weights correspond to a hidden variable, that can be marginalized out using dynamic programming.",6 Related Work,[0],[0]
"Further, our model’s inherent online nature permits it the flexibility to use its capacity to chose how much
input to encode before decoding each segment.",6 Related Work,[0],[0]
We have proposed a novel segment to segment neural transduction model that tackles the limitations of vanilla encoder-decoders that have to read and memorize an entire input sequence in a fixed-length context vector before producing any output.,7 Conclusion,[0],[0]
"By introducing a latent segmentation that determines correspondences between tokens of the input and output sequences, our model learns to generate and align jointly.",7 Conclusion,[0],[0]
"During training, the hidden alignment is marginalized out using dynamic programming, and during decoding the best alignment path is generated alongside the predicted output sequence.",7 Conclusion,[0],[0]
"By employing a unidirectional LSTM as encoder, our model is capable of doing online generation.",7 Conclusion,[0],[0]
"Experiments on two representative natural language processing tasks, abstractive sentence summarisation and morphological inflection generation, showed that our model significantly outperforms encoderdecoder baselines while requiring much smaller hidden layers.",7 Conclusion,[0],[0]
For future work we would like to incorporate attention-based models to our framework to enable such models to process data online.,7 Conclusion,[0],[0]
"We thank Chris Dyer, Karl Moritz Hermann, Edward Grefenstette, Tomáš Kǒciský, Gabor Melis, Yishu Miao and many others for their helpful comments.",Acknowledgments,[0],[0]
The first author is funded by EPSRC.,Acknowledgments,[0],[0]
We introduce an online neural sequence to sequence model that learns to alternate between encoding and decoding segments of the input as it is read.,abstractText,[0],[0]
"By independently tracking the encoding and decoding representations our algorithm permits exact polynomial marginalization of the latent segmentation during training, and during decoding beam search is employed to find the best alignment path together with the predicted output sequence.",abstractText,[0],[0]
Our model tackles the bottleneck of vanilla encoder-decoders that have to read and memorize the entire input sequence in their fixedlength hidden states before producing any output.,abstractText,[0],[0]
"It is different from previous attentive models in that, instead of treating the attention weights as output of a deterministic function, our model assigns attention weights to a sequential latent variable which can be marginalized out and permits online generation.",abstractText,[0],[0]
Experiments on abstractive sentence summarization and morphological inflection show significant performance gains over the baseline encoder-decoders.,abstractText,[0],[0]
Online Segment to Segment Neural Transduction,title,[0],[0]
Most machine learning systems implicitly or explicitly assume that their training experience is representative of their test experience.,1. Introduction,[0],[0]
"This assumption is rarely true in real-world deployments of machine learning, where “unknown unknowns”, or “alien” data, can arise without warning.",1. Introduction,[0],[0]
"Ig-
*Equal contribution 1Department of Statistics, Oregon State University, Oregon, USA 2School of EECS, Oregon State University, Oregon, USA 3University of California, Berkeley, California, USA.",1. Introduction,[0],[0]
"Correspondence to: Si Liu <lius2@oregonstate.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
noring the potential for such aliens can lead to serious safety concerns in many applications and significantly degrade the accuracy of test set predictions in others.,1. Introduction,[0],[0]
"For example, consider a scientific application where a classifier is trained to recognize specific categories of insects in freshwater samples in order to detect important environmental changes (Lytle et al., 2010).",1. Introduction,[0],[0]
Test samples will typically contain some fraction of specimens belonging to species not represented in the training data.,1. Introduction,[0],[0]
A classifier that is unaware of these new species will misclassify the specimens as belonging to existing species.,1. Introduction,[0],[0]
"This will produce incorrect scientific conclusions.
",1. Introduction,[0],[0]
The problem of open category detection is to detect such alien examples at test time.,1. Introduction,[0],[0]
"An ideal algorithm for this problem would guarantee a user-specified alien-detection rate (e.g., 95%), while attempting to minimize the false alarm rate.",1. Introduction,[0],[0]
"Unfortunately, no existing algorithm provides such guarantees under general conditions.",1. Introduction,[0],[0]
"In addition, empirical evaluations of existing algorithms for open category detection typically do not directly evaluate alien detection rates, which are perhaps the most relevant for safety-critical applications.",1. Introduction,[0],[0]
"Overall, our current theoretical and practical understanding of open category detection is lacking from a safety and accuracy perspective.
",1. Introduction,[0],[0]
Is it possible to achieve open category detection with guarantees?,1. Introduction,[0],[0]
"In this paper, we take a step toward answering this question by studying a simplified, but practically relevant, problem setting.",1. Introduction,[0],[0]
"To motivate our setting, consider the above insect identification problem.",1. Introduction,[0],[0]
At training time it is reasonable to expect that a clean training set is available that contains only the insect categories of interest.,1. Introduction,[0],[0]
"At test time, a new sample will include insects from the training categories along with some percentage of insects from new alien categories.",1. Introduction,[0],[0]
"Further, scientists may have reasonable estimates for this percentage based on their scientific knowledge and practical experience.",1. Introduction,[0],[0]
"We would like to guarantee that the system is able to raise an alarm for, say, 95% of the insects from alien classes, with each alarm being examined by a scientist.",1. Introduction,[0],[0]
"At the same time, we would like to avoid as many “false alarms” as possible, since each alarm requires scientist effort.
",1. Introduction,[0],[0]
"To formalize the example, our setting assumes two training sets: a clean training dataset involving a finite set of cate-
gories and a contaminated dataset that contains a fraction α of aliens.",1. Introduction,[0],[0]
"Our first contribution is to show that, in this setting, theoretical guarantees are possible given knowledge of an upper bound on α.",1. Introduction,[0],[0]
"In particular, we give an algorithm that uses this knowledge to provide Probably Approximately Correct (PAC) guarantees for achieving a user-specified alien detection rate.",1. Introduction,[0],[0]
"While knowledge of a non-trivial upper bound on α may not always be possible, in many situations it will be possible to select a reasonable value based on domain knowledge, prior data, or by inspecting a sample of the test data.
",1. Introduction,[0],[0]
"The key idea behind our algorithm is to leverage modern anomaly detectors, which are trained on the clean data.",1. Introduction,[0],[0]
Our algorithm combines the anomaly-score distributions over the clean and contaminated training data in order to derive an alarm threshold that achieves the desired guarantee on the alien detection rate on new test queries.,1. Introduction,[0],[0]
In theory the detection rate guarantee will be met regardless of the quality of the anomaly detector.,1. Introduction,[0],[0]
"The quality of the detector, however, has a significant impact on the false alarm rate, with better detectors leading to fewer false alarms.
",1. Introduction,[0],[0]
"We carry out experiments1 on synthetic and benchmark datasets using a state-of-the-art anomaly detector, the Isolation Forest (Liu et al., 2008).",1. Introduction,[0],[0]
"We vary the amount of training data, the fraction α of alien data points, along with the accuracy of the upper bound on α provided to our algorithm.",1. Introduction,[0],[0]
"The results indicate that our algorithm can achieve the guaranteed performance when enough data is available, as predicted by the theory.",1. Introduction,[0],[0]
"The results also show that for the considered benchmarks, the Isolation Forest anomaly detector is able to support non-trivial false positive rates given enough data.",1. Introduction,[0],[0]
The results also illustrate the inherent difficulty of the problem for small datasets and/or small values of α.,1. Introduction,[0],[0]
"Overall, our results provide a useful baseline for driving future work on open category detection with guarantees.",1. Introduction,[0],[0]
"Open category detection is related to the problem of oneclass classification, which aims to detect outliers relative to a single training class.",2. Related Work,[0],[0]
One-class SVMs (OCSVMs),2. Related Work,[0],[0]
"(Schölkopf et al., 2001) are popular for this problem.",2. Related Work,[0],[0]
"However, they have been found to perform poorly for open category detection due to poor generalization (Zhou & Huang, 2003), which has been partly addressed by later work (Manevitz & Yousef, 2002; Wu & Ye, 2009; Jin et al., 2004; Cevikalp & Triggs, 2012).",2. Related Work,[0],[0]
"OCSVMs have been employed in a multi-class setting similar to open category detection (Heflin et al., 2012; Pritsos & Stamatatos, 2013).
",2. Related Work,[0],[0]
"1Code for reproducing our experiments can be found at https://github.com/liusi2019/ocd.
",2. Related Work,[0],[0]
"However, there are no direct mechanisms to control the alien detection rate of these methods, which is a key requirement for our problem setting.
",2. Related Work,[0],[0]
"Work on classification with rejection/abstaining options (Chow, 1970; Wegkamp, 2007; Tax & Duin, 2008; Pietraszek, 2005; Geifman & El-Yaniv, 2017) allows classifiers to abstain from making predictions when they are not confident.",2. Related Work,[0],[0]
"While loosely related to open category detection, these approaches do not directly consider the possibility of novel categories, but rather focus on assessing confidence with respect to the known categories.",2. Related Work,[0],[0]
"Due to their closedworld discriminative nature, it is easy to construct scenarios where such methods are incorrectly confident about the class of an alien and do not abstain.
",2. Related Work,[0],[0]
A variety of prior work has addressed variants of open category detection.,2. Related Work,[0],[0]
"This includes work on formalizing the concept of “open space” to characterize the region of the feature space outside of the support of the training set (Scheirer et al., 2013).",2. Related Work,[0],[0]
"Variants of SVMs have also been developed, such as the One-vs-Set Machine (Scheirer et al., 2013) and the Weibull-calibrated SVM (Scheirer et al., 2014).",2. Related Work,[0],[0]
"Additional work has addressed open category detection by tuning the decision boundary based on unlabeled data which contains data from novel categories (Da et al., 2014).",2. Related Work,[0],[0]
"Approaches based on nearest neighbor methods have also been proposed (Mendes Júnior et al., 2017).",2. Related Work,[0],[0]
"None of these methods, however, allow for the direct control of alien detection rates, nor do they provide theoretical guarantees.
",2. Related Work,[0],[0]
"There is also recent interest in open category detection for deep neural networks applied to vision and text classification (Bendale & Boult, 2016; Shu et al., 2017).",2. Related Work,[0],[0]
"These methods usually train a neural network in a standard closed-world setting, but then analyze various activations in the network in order to detect aliens.",2. Related Work,[0],[0]
"Another related line of work is detection of out-of-distribution instances, which is similar to open category detection but assumes that the test data come from a completely different distribution compared to the training distribution (Hendrycks & Gimpel, 2017; Liang et al., 2018).",2. Related Work,[0],[0]
All of this work is quite specialized to deep neural networks and does not provide direct control of alien detection rates or theoretical guarantees.,2. Related Work,[0],[0]
We consider open category detection where there is an unknown nominal data distribution D0 over labeled examples from a known set of category labels.,3. Problem Setup,[0],[0]
We receive as input a “clean” nominal training set S0 containing k i.i.d.,3. Problem Setup,[0],[0]
draws from D0.,3. Problem Setup,[0],[0]
"In practice, S0 will correspond to some curated labeled data that contains only known categories of interest.
",3. Problem Setup,[0],[0]
We also receive as input an unlabeled “mixture” dataset Sm that contains n points drawn i.i.d.,3. Problem Setup,[0],[0]
"from a mixture dis-
tribution Dm.",3. Problem Setup,[0],[0]
"Specifically, the mixture distribution Dm is a combination of the nominal distribution D0 and an unknown alien distribution Da, which is a distribution over novel categories (alien data points).",3. Problem Setup,[0],[0]
"We assume that Da is stationary, so that all alien points that appear as future test queries will also be drawn from Da.
",3. Problem Setup,[0],[0]
"At training time, we assume that Dm is a mixture distribution, with probability α of generating an alien data point from Da and probability of 1− α of generating a nominal point.",3. Problem Setup,[0],[0]
"Our results hold even if the test queries come from a mixture with a different value of α as long as the alien test points are drawn from Da.
",3. Problem Setup,[0],[0]
"Given these datasets, our problem is to label test instances from Dm as either “alien” or “nominal”.",3. Problem Setup,[0],[0]
"In particular, we wish to achieve a specified alien detection rate, which is the fraction of alien data points in Dm that are classified as “alien” (e.g., 95%).",3. Problem Setup,[0],[0]
"At the same time we would like the false positive rate to be small, which is the fraction of nominal data points incorrectly classified as aliens.
",3. Problem Setup,[0],[0]
Our approach to this problem assumes the availability of an anomaly detector that is trained on S0 and assigns anomaly scores to all data points in both S0 and Sm.,3. Problem Setup,[0],[0]
"Intuitively, the anomaly scores order the test examples according to how anomalous they appear relative to the nominal data (higher scores being more anomalous).",3. Problem Setup,[0],[0]
"An ideal detector would rank all alien data points higher than all nominals, though in practice, the ordering will not be so clean.",3. Problem Setup,[0],[0]
Our approach labels data in Sm by selecting a threshold on the anomaly scores and labeling all data points with scores above the threshold as aliens and the remaining points as nominals.,3. Problem Setup,[0],[0]
Our key challenge is to select a threshold that provides a guarantee on the alien detection rate.,3. Problem Setup,[0],[0]
"In order to obtain theoretical guarantees, our algorithm assumes knowledge of the alien mixture probability α that generates the mixture data Sm.",4. Algorithms for Open Category Detection,[0],[0]
"Later, we will show that knowing an upper bound on α is sufficient to obtain a guarantee.
",4. Algorithms for Open Category Detection,[0],[0]
Our approach is based on considering the cumulative distribution functions (CDFs) over anomaly scores of a fixed anomaly detector.,4. Algorithms for Open Category Detection,[0],[0]
"Let F0, Fa, and Fm be the CDFs of anomaly scores for the nominal data distribution D0, alien distribution Da, and mixture distribution Dm respectively.",4. Algorithms for Open Category Detection,[0],[0]
"Since Dm is a simple mixture of D0 and Da, we can write Fm as
Fm(x) = (1− α)F0(x) + αFa(x).
",4. Algorithms for Open Category Detection,[0],[0]
"From this we can derive the CDF for Fa in terms of Fm and F0:
Fa(x) = Fm(x)− (1− α)F0(x)
α .
",4. Algorithms for Open Category Detection,[0],[0]
"Given the ability to derive Fa, it is straightforward to achieve an alien detection rate of 1− q (e.g. 95%) by selecting an anomaly score threshold τq that is the q quantile of Fa and raising an alarm on all test queries whose anomaly score is greater than τq .
",4. Algorithms for Open Category Detection,[0],[0]
"In reality, we do not have access to Fm or F0 and hence cannot exactly determine Fa.",4. Algorithms for Open Category Detection,[0],[0]
"Rather, we have samples Sm and S0.",4. Algorithms for Open Category Detection,[0],[0]
"Thus, our algorithm works with the empirical CDFs F̂0 and F̂m, which are simple step-wise constant approximations, and estimates an empirical CDF over aliens:
F̂a(x)",4. Algorithms for Open Category Detection,[0],[0]
"= F̂m(x)− (1− α)F̂0(x)
α .",4. Algorithms for Open Category Detection,[0],[0]
"(1)
Our algorithm computes the above estimate of F̂a and uses it to select a threshold τ̂q to be the largest threshold such that F̂a(τ̂q) ≤ q, where 1 − q is the target alien detection rate.",4. Algorithms for Open Category Detection,[0],[0]
This choice will minimize the number of false alarms.,4. Algorithms for Open Category Detection,[0],[0]
"The steps of this algorithm are as follows.
",4. Algorithms for Open Category Detection,[0],[0]
"Algorithm 1 1: Get anomaly scores for all points in S0 and Sm, denoted x1, x2, . . .",4. Algorithms for Open Category Detection,[0],[0]
", xk and y1, y2, . . .",4. Algorithms for Open Category Detection,[0],[0]
", yn respectively.
2: Compute empirical CDFs F̂0 and F̂m.",4. Algorithms for Open Category Detection,[0],[0]
3: Calculate F̂a using equation 1.,4. Algorithms for Open Category Detection,[0],[0]
"4: Output detection threshold
τ̂q = max{u ∈ S : F̂a(u) ≤ q},
where S = {x1, x2, . . .",4. Algorithms for Open Category Detection,[0],[0]
", xk, y1, y2, . . .",4. Algorithms for Open Category Detection,[0],[0]
", yn}.
",4. Algorithms for Open Category Detection,[0],[0]
"Although F̂m and F̂0 are both legal CDFs, the estimate for F̂a from step 3 may not be a legal CDF, because it is the difference of two noisy estimates—it may not increase monotonically and it may even be negative.",4. Algorithms for Open Category Detection,[0],[0]
"A good technique for dealing with this problem is to employ isotonization (Barlow & Brunk, 1972) and clipping.",4. Algorithms for Open Category Detection,[0],[0]
Isotonization finds the monotonically increasing function F̂ ∗a closest to F̂a in squared error.,4. Algorithms for Open Category Detection,[0],[0]
"To convert F̂a into a legal CDF, define F̌a = min{max{F̂ ∗a ,0},1}, where the min and max operators are applied pointwise to their arguments.",4. Algorithms for Open Category Detection,[0],[0]
We performed experiments (shown in the supplementary materials) to test whether using F̌a in Step 4 would improve the performance of the overall algorithm.,4. Algorithms for Open Category Detection,[0],[0]
We found that it did not.,4. Algorithms for Open Category Detection,[0],[0]
"In the limit of infinite data (both nominal and mixture) and perfect knowledge of α, F̂a will converge to the true alien CDF, and our algorithm will achieve the desired alien detection rate.",5. Finite Sample Guarantee,[0],[0]
"In this section, we consider the finite data case where |S0| = |Sm| = n.",5. Finite Sample Guarantee,[0],[0]
"We derive a value for the sample size n that guarantees with high probability over random
draws of S0 and Sm, that fraction 1 − q",5. Finite Sample Guarantee,[0],[0]
"− of the alien test points will be detected, where is an additional error incurred because of the finite sample size n.
Our key theoretical tool is a finite sample result on the uniform convergence of empirical CDF functions (Massart, 1990).",5. Finite Sample Guarantee,[0],[0]
"To use this result, we make the reasonable technical assumption that the nominal and alien CDFs, F0 and Fa, are continuous.",5. Finite Sample Guarantee,[0],[0]
"In the following, let η be the target alien detection rate, q be the input to Algorithm 1, τ̂q be the estimated q-quantile of the alien CDF (step 4 of Alg. 1), and be an error parameter.",5. Finite Sample Guarantee,[0],[0]
"The following theorem gives the sample complexity for guaranteeing that 1 − η of the alien examples will be detected using threshold τ̂q .
",5. Finite Sample Guarantee,[0],[0]
Theorem 1.,5. Finite Sample Guarantee,[0],[0]
Let S0 and Sm be nominal and mixture datasets containing n i.i.d.,5. Finite Sample Guarantee,[0],[0]
samples from the nominal and mixture data distributions respectively.,5. Finite Sample Guarantee,[0],[0]
"For any ∈ (0, 1−q) and δ ∈ (0, 1), if
n > 1
2 ln
2
1− √ 1− δ
( 1 )2 ( 2− α α )2 ,
then with probability at least 1− δ, Algorithm 1 will return a threshold τ̂q that achieves an alien detection rate of at least 1− η, where η = q",5. Finite Sample Guarantee,[0],[0]
"+ .
",5. Finite Sample Guarantee,[0],[0]
The proof is in the Appendix.,5. Finite Sample Guarantee,[0],[0]
Note that n grows as O( 1 2α2 log 1 δ ).,5. Finite Sample Guarantee,[0],[0]
"Hence, this guarantee is polynomial in all relevant parameters, which we believe is the first such guarantee for open category detection.",5. Finite Sample Guarantee,[0],[0]
"The result can be generalized to the case where n0 < nm; in practice, the larger the mixture sample Sm is, the easier it is to estimate τq, because this provides more alien points for estimating the q-th quantile of Fa.
",5. Finite Sample Guarantee,[0],[0]
The theorem gives us flexibility in setting and q (the algorithm input) to achieve a guarantee of 1−η.,5. Finite Sample Guarantee,[0],[0]
The parameter controls a trade-off between sample size and false alarm rate.,5. Finite Sample Guarantee,[0],[0]
"To minimize the false alarm rate, we want to make q large (to obtain a larger threshold), so we want to set q close to η.",5. Finite Sample Guarantee,[0],[0]
"But, as q → η, → 0, and n→∞. To minimize the sample size n, we want to make q as small as possible, because that allows to be larger and hence n becomes smaller.",5. Finite Sample Guarantee,[0],[0]
"The optimal setting of depends on how the false alarm rate grows with τq, which in turn depends on the relative shape of F0 and Fa.",5. Finite Sample Guarantee,[0],[0]
"In a real safety application, we can estimate these from S0 and Sm and choose an appropriate q value.
",5. Finite Sample Guarantee,[0],[0]
What if we don’t know the exact value of α?,5. Finite Sample Guarantee,[0],[0]
"If our algorithm uses an upper bound α′ on the true α to compute F̂a, we can still provide a guarantee.",5. Finite Sample Guarantee,[0],[0]
"In this case, in addition to the assumptions in Theorem 1, we need a concept of an anomaly detector being admissible.",5. Finite Sample Guarantee,[0],[0]
"We say that an anomaly detector is admissible for a problem, if the anomaly score CDFs satisfy F0(x) ≥ Fm(x) for all x ∈ R.",5. Finite Sample Guarantee,[0],[0]
"Most reasonable anomaly detectors will be admissible in this sense, since
the alien CDF will typically concentrate more mass toward larger anomaly score values compared to F0.",5. Finite Sample Guarantee,[0],[0]
"Indeed, if this is not the case, there is little hope since there is effectively no signal to distinguish between aliens and nominals.
",5. Finite Sample Guarantee,[0],[0]
Corollary 1.,5. Finite Sample Guarantee,[0],[0]
Consider running Algorithm 1 using an upper bound α′ on the true α.,5. Finite Sample Guarantee,[0],[0]
"Under the same assumptions as Theorem 1, if the anomaly detector is admissible and
n > 1
2 ln
2
1− √ 1− δ
( 1 )2 ( 2− α′
α′
)2 ,
then with probability at least 1− δ, Algorithm 1 will return a threshold τ̂q that achieves an alien detection rate of at least 1− η, where η = q",5. Finite Sample Guarantee,[0],[0]
"+ .
",5. Finite Sample Guarantee,[0],[0]
The proof is in the Appendix.,5. Finite Sample Guarantee,[0],[0]
"While we can achieve a guarantee using an upper bound on α′, the returned threshold will be more conservative (smaller) than if we had used the true α.",5. Finite Sample Guarantee,[0],[0]
"This will result in higher false alarm rates, since more nominal points will be above the threshold.",5. Finite Sample Guarantee,[0],[0]
Thus it is desirable to use a value of α′ that is as close to α as possible.,5. Finite Sample Guarantee,[0],[0]
We performed experiments to answer four questions.,6. Experiments,[0],[0]
Question Q1: how accurate is our estimate of τ̂q as a function of n and α?,6. Experiments,[0],[0]
Question Q2: how loose are the bounds from Theorem 1?,6. Experiments,[0],[0]
Question Q3: what are typical values of the false alarm rates for various settings of n and α on real datasets?,6. Experiments,[0],[0]
Question Q4: how do these observed values change if we employ an overestimate α′ >,6. Experiments,[0],[0]
"α?
",6. Experiments,[0],[0]
"All of our experiments employ the Isolation Forest anomaly detector (Liu et al., 2008), which has been demonstrated to be a state-of-the-art detector in recent empirical studies (Emmott et al., 2013).",6. Experiments,[0],[0]
"In the Supplementary Materials we show similar results with the LODA anomaly detector (Pevný, 2015).
",6. Experiments,[0],[0]
"To address Q1 and Q2, we run controlled experiments on synthetic data.",6. Experiments,[0],[0]
The data points are generated from 9- dimensional normal distributions.,6. Experiments,[0],[0]
"The dimensions of the nominal distribution D0 are independently distributed as N(0, 1).",6. Experiments,[0],[0]
"The alien distribution is similar, but with probability 0.4, 3 of the 9 dimensions (chosen uniformly at random) are distributed as N(3, 1) and with probability 0.6, 4 of the 9 dimensions (chosen uniformly at random) follow N(3, 1).",6. Experiments,[0],[0]
"This ensures that the anomalies are not highly similar to each other and models the situation in which there are many different kinds of alien objects, not just a single alien class forming a tight cluster.
",6. Experiments,[0],[0]
"In each experiment, the nominal dataset and the mixture dataset are of the same size n, and the mixture dataset contains a proportion α of anomaly points.",6. Experiments,[0],[0]
We fixed the target quantile to be q = 0.05.,6. Experiments,[0],[0]
"The experiments are
0.65
0.7
0.75
0.8
0.85
0.9
0.95 1",6. Experiments,[0],[0]
"Re ca ll
5! = 0.01
100⋯10000 100⋯10000
! =",6. Experiments,[0],[0]
"0.05
100⋯10000
!",6. Experiments,[0],[0]
"= 0.10
100⋯10000
!",6. Experiments,[0],[0]
= 0.20 !,6. Experiments,[0],[0]
"= 0.50
)",6. Experiments,[0],[0]
"= 100⋯10000
Figure 1.",6. Experiments,[0],[0]
Comparison of recall achieved by τ̂q compared to oracle recall of 0.95.,6. Experiments,[0],[0]
Error bars are 95% confidence intervals.,6. Experiments,[0],[0]
"Settings of n and α increase from left to right starting with α = 0.01 and n ∈ {100, 500, 1K, 5K, 10K} up to α = 0.5 and n = 10K.
carried out for n ∈ {100, 500, 1K, 5K, 10K} and α ∈ {0.01, 0.05, 0.10, 0.20, 0.50}.",6. Experiments,[0],[0]
"For testing, we create two large datasets G0 and Ga, with G0 being a pure nominal dataset, Ga being a pure alien dataset, and |G0| = |Ga| = 20K.",6. Experiments,[0],[0]
The Isolation Forest algorithm computes 1000 full depth isolation trees on the nominal data.,6. Experiments,[0],[0]
Each tree is grown on a randomly-selected 20% subsample of the clean data points.,6. Experiments,[0],[0]
"We compute anomaly scores for the nominal points via out-of-bag estimates and anomaly scores for the mixture points, G0, and Ga using the full isolation forest.",6. Experiments,[0],[0]
"For each combination of n and α, we repeat the experiment 100 times.",6. Experiments,[0],[0]
"We measure the fraction of aliens detected (the “recall”) and the fraction of nominal points declared to be alien (the “false positive rate”) by applying the τ̂q estimate to threshold the anomaly scores in G0 and Ga.
To assess the accuracy of our τ̂q estimates (Q1), we could compare them to the true values.",6. Experiments,[0],[0]
"However, this comparison is hard to interpret, because τ is expressed on the scale of anomaly scores, which are somewhat arbitrary.",6. Experiments,[0],[0]
"Instead, Figure 1 plots the recall achieved by τ̂q.",6. Experiments,[0],[0]
"If τ̂q had been estimated perfectly, the recall would always be 1−q = 0.95.",6. Experiments,[0],[0]
"However, we see that the recall is often less than 0.95, which indicates that τ̂q is over-estimated, especially when n and α are small.",6. Experiments,[0],[0]
"This behavior is predicted by our theory, where we see that the sample size requirements grow inversely with α2.",6. Experiments,[0],[0]
"For larger α and n, the recall guarantee is generally achieved.",6. Experiments,[0],[0]
Figure 2 compares the false positive rate of the true oracle τq to the false positive rate of the estimate τ̂q .,6. Experiments,[0],[0]
"For each combination of α and n, we have 100 replications of the experiment and therefore 100 estimates τ̂a and 100 FPR rates.",6. Experiments,[0],[0]
"For each of these, the true FPR is computed using G0.
2! = 0.01
100⋯10000 100⋯10000
!",6. Experiments,[0],[0]
"= 0.05
100⋯10000
!",6. Experiments,[0],[0]
"= 0.10
100⋯10000
!",6. Experiments,[0],[0]
= 0.20 !,6. Experiments,[0],[0]
"= 0.50
)",6. Experiments,[0],[0]
"= 100⋯100000
0.02
0.04
0.06
0.08
0.1
0.12
FP R
Figure 2.",6. Experiments,[0],[0]
Comparison of oracle FPR to the FPR achieved by τ̂q .,6. Experiments,[0],[0]
Error bars span from the 25th to 75th percentile with the blue dot marking the median of the 100 trials.,6. Experiments,[0],[0]
Orange markers indicate the oracle FPR.,6. Experiments,[0],[0]
"Settings of n and α increase from left to right starting with α = 0.01 and n ∈ {100, 500, 1K, 5K, 10K} up to α = 0.5 and n = 10K.
",6. Experiments,[0],[0]
The error bars summarize the resulting 100 FPR values by the median and inter-quartile range.,6. Experiments,[0],[0]
"We see that for small n and α, the FPR can be quite different from the oracle rate, but for larger n and α, the estimates are very good.
",6. Experiments,[0],[0]
"To assess the looseness of the bounds (Q2), for each combination of n and α, we fix δ = 0.05 and compute the value of η such that 95 of the 100 runs achieved a recall of at least 1− η (thus η empirially achieves the 1− δ guarantee).",6. Experiments,[0],[0]
We then compute = η,6. Experiments,[0],[0]
− q and the corresponding required sample size n∗ according to Theorem 1.,6. Experiments,[0],[0]
"Figure 3 shows a
plot of n∗ versus the actual n.",6. Experiments,[0],[0]
"The distance of these points from the n∗ = n diagonal line show that the theory is fairly loose, although it becomes tighter as n gets large.
",6. Experiments,[0],[0]
Benchmark Data Experiments.,6. Experiments,[0],[0]
"To address our third and fourth questions, we performed experiments on six UCI multiclass datasets: Landsat, Opt.digits, pageb, Shuttle, Covertype and MNIST.",6. Experiments,[0],[0]
"In addition to these, we provide results for the Tiny ImageNet dataset.",6. Experiments,[0],[0]
"In each multiclass dataset, we split the classes into two groups: nominal and alien.",6. Experiments,[0],[0]
"For Tiny ImageNet, we train a deep neural network classifier on 200 nominal classes and treat the remaining 800 as aliens.",6. Experiments,[0],[0]
"The nominal classes for UCI datasets are MNIST(1,3,7), Landsat(1,7), OCR(1,3,4,5,7), pageb(1,5), Letter recognition(1,3), and Shuttle(1,4).",6. Experiments,[0],[0]
"We generated
nominal and mixture datasets for various values of α.",6. Experiments,[0],[0]
"The value of n for each dataset is 1532 for Landsat,788 for Letter recognition, 568 for OCR, 4912 for pageb, 5000 for Shuttle, 13,624 for Covertype, 11,154 for MNIST, and 10,000 for Tiny ImageNet.",6. Experiments,[0],[0]
"Because we cannot create datasets with large n, we cannot measure the true value of τq .
",6. Experiments,[0],[0]
"After computing the anomaly scores for both nominal and mixture datasets, we applied Algorithm 1 within a 10-fold cross validation.",6. Experiments,[0],[0]
We divide the mixture data points at random into 10 groups.,6. Experiments,[0],[0]
"For each fold, we estimate F̂a and τ̂a from 9 of the 10 groups and then score the mixture points in the held-out fold according to τ̂a.",6. Experiments,[0],[0]
"In all other respects, the experimental protocol is the same as for the synthetic data.",6. Experiments,[0],[0]
"For Tiny ImageNet, the anomaly scores are obtained by applying a baseline method (Hendrycks & Gimpel, 2017).
",6. Experiments,[0],[0]
"To answer Q3, Figures 4 and 6 plot the false positive rate as a function of α for the UCI and vision datasets, respectively.",6. Experiments,[0],[0]
We see that the FPR ranges from 3.6% to 26.9% on UCI depending on the dataset and the level of α.,6. Experiments,[0],[0]
"The vision datasets have higher FPR, especially MNIST, which has a large number of alien classes that are not distinguished well by the anomaly detector.",6. Experiments,[0],[0]
"The FPR depends primarily on the domain, because the key issue is how well the anomaly detector distinguishes between nominal and alien examples.",6. Experiments,[0],[0]
The false alarm rate generally improves as α increases.,6. Experiments,[0],[0]
"In some applications, it may be possible to enrich Sm so that α is larger on the training set to take advantage of this phenomenon.",6. Experiments,[0],[0]
"It is interesting to note that once τ̂a has been computed, it can be applied to test datasets having different (or unknown) values of α.
",6. Experiments,[0],[0]
Figures 5 and 7 plot the recall rate as a function of α for the UCI and vision datasets.,6. Experiments,[0],[0]
We set q = 0.05 in these experiments.,6. Experiments,[0],[0]
"Theorem 1 only guarantees a recall of 1−q− ,
where depends on n. Hence, it is nice to see that for three of the domains (Shuttle, Covertype, and Landsat) in UCI and for both vision datasets, the recall is very close to 1− q = 0.95.",6. Experiments,[0],[0]
These are the domains with the largest values of n.,6. Experiments,[0],[0]
The value of α has a bigger impact on recall than it does on FPR.,6. Experiments,[0],[0]
"This is because the effective number of alien training examples is αn, which can be very small for some datasets when α = 0.1.",6. Experiments,[0],[0]
"This shows that in applications such as fraud detection, where α may be very small, the mixture dataset Sm needs to be very large.
",6. Experiments,[0],[0]
To answer Q4 regarding the impact of using an incorrect value α′,6. Experiments,[0],[0]
"> α, we repeated these experiments with α′ = α+ξ, for ξ ∈ {0.002, 0.004, 0.006, 0.008, 0.010}.",6. Experiments,[0],[0]
"Figure 8 plots the change in false positive rate and recall as a function
of α′",6. Experiments,[0],[0]
− α.,6. Experiments,[0],[0]
"Two points are plotted for each combination of α′ and dataset, the change in Recall and the change in FPR.",6. Experiments,[0],[0]
We observe that the recall increases slightly (in the range from 0.01 to 0.05).,6. Experiments,[0],[0]
"However, the false positive rate increases by much larger amounts (from 0.01 to 0.336).",6. Experiments,[0],[0]
This demonstrates that it is very important to determine the value of α accurately.,6. Experiments,[0],[0]
We have taken a step toward open category detection with guarantees by providing a PAC-style guarantee on the probability of detecting 1− η of the aliens on the test data.,7. Summary,[0],[0]
This is the first such guarantee under any similarly general conditions.,7. Summary,[0],[0]
"We have shown that this guarantee is satisfied in our experiments, although the guarantee is somewhat loose, especially on small training sets.",7. Summary,[0],[0]
Obtaining a guarantee requires more data than standard PAC guarantees on expected prediction accuracy.,7. Summary,[0],[0]
"This is because we must estimate the q quantile of the alien anomaly score distribution, where q is typically quite small.",7. Summary,[0],[0]
"Nonetheless, our experiments show that our algorithm gives good recall performance and non-trivial false alarm rates on datasets of reasonable size.
",7. Summary,[0],[0]
It is important to note that the very formulation of a PACstyle guarantee on the probability of detecting aliens requires assuming that the aliens are drawn from a welldefined distribution Da.,7. Summary,[0],[0]
"While this is appropriate in some applications, such as the insect survey application described in the introduction, it is not appropriate for adversarial settings.",7. Summary,[0],[0]
"In such settings, a PAC-style guarantee does not make sense, and some other form of safety guarantee needs to be formulated.
",7. Summary,[0],[0]
"To obtain the guarantee, we employ two training datasets: a clean dataset that contains no aliens and an (unlabeled) contaminated dataset that contains a known fraction α of aliens.",7. Summary,[0],[0]
An important theoretical problem for future research is to develop a method that can estimate a tight upper bound on α̂ > α.,7. Summary,[0],[0]
"We believe this is possible, but we have not yet found a method that guarantees that α̂ > α.
",7. Summary,[0],[0]
Our guarantee requires more data as α becomes small.,7. Summary,[0],[0]
"Fortunately, when α is small, it may be possible in some applications to afford lower recall rates, since the frequency of aliens will be smaller.",7. Summary,[0],[0]
"However, in safety-critical applications where a single undetected alien poses a serious threat, there is little recourse other than to collect more data or allow for higher false positive rates.",7. Summary,[0],[0]
"This research was supported by a gift from Huawei, Inc., and grants from the Future of Life Institute and the NSF Grant 1514550.",Acknowledgements,[0],[0]
"Any opinions, findings, and conclusions
or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the sponsors.",Acknowledgements,[0],[0]
Suppose there are n random variables which are i.i.d. from the distribution with CDF F and let F̂n be the empirical CDF calculated from this sample.,A. Proof for Theorem 1,[0],[0]
"Then Massart (1990) shows that
P ( √ n sup
x |F̂n(x)− F (x)| > λ) ≤ 2 exp(−2λ2) (2)
holds without any restriction on λ.",A. Proof for Theorem 1,[0],[0]
"Making use of this, and assuming we use the same sample size n for both the mixture dataset and the clean data set, for any ∈ (0, 1−q), we seek to determine how large n needs to be in order to guarantee that with probability at least 1 − δ our quantile estimate τ̂q satisfies Fa(τ̂q) ≤ q + .",A. Proof for Theorem 1,[0],[0]
"To achieve this, we want to have
P (sup x |F̂a(x)−",A. Proof for Theorem 1,[0],[0]
Fa(x)| > ) ≤,A. Proof for Theorem 1,[0],[0]
"δ.
",A. Proof for Theorem 1,[0],[0]
"We have
P (sup x |F̂a(x)−",A. Proof for Theorem 1,[0],[0]
"Fa(x)| > )
= P (sup x | F̂m(x)− (1− α)F̂0(x) α",A. Proof for Theorem 1,[0],[0]
"−
Fm(x)− (1− α)F0(x) α",A. Proof for Theorem 1,[0],[0]
"| > )
= P (sup x",A. Proof for Theorem 1,[0],[0]
"| 1 α (F̂m(x)− Fm(x))−
1− α α",A. Proof for Theorem 1,[0],[0]
"(F̂0(x)− F0(x))| > )
≤ P (( 1 α sup x |F̂m(x)− Fm(x)|+
1− α α sup x |F̂0(x)− F0(x)|) > )
≤ P ({ 1 α sup x |F̂m(x)− Fm(x)| > 1 2− α }
∪ {1− α α sup x |F̂0(x)− F0(x)| > 1− α 2− α })
= P ({sup x |F̂m(x)− Fm(x)| >
α
2− α }
∪ {sup x |F̂0(x)− F0(x)| >
α
2− α }).
",A. Proof for Theorem 1,[0],[0]
"Making use of (2), when
n >",A. Proof for Theorem 1,[0],[0]
"1
2 ln
2
1− √ 1− δ",A. Proof for Theorem 1,[0],[0]
"( 1 )2( 2− α α )2,
we will have
P (sup x |F̂m(x)− Fm(x)| >
α
2− α ) ≤",A. Proof for Theorem 1,[0],[0]
"1−
√ 1− δ,
P (sup x |F̂0(x)− F0(x)| >
α
2− α ) ≤",A. Proof for Theorem 1,[0],[0]
"1−
",A. Proof for Theorem 1,[0],[0]
"√ 1− δ.
",A. Proof for Theorem 1,[0],[0]
"In this case we will have
P (sup x |F̂a(x)−",A. Proof for Theorem 1,[0],[0]
"Fa(x)| > )
≤ 1− P ({sup x |F̂m(x)− Fm(x)| ≤
α
2− α }
∩ {sup x |F̂0(x)− F0(x)| ≤
α
2− α })
≤ 1− (1− 1 + √ 1− δ)2
= δ.
",A. Proof for Theorem 1,[0],[0]
"Now we have with probability at least 1− δ,
|F̂a(x)− Fa(x)| ≤ , ∀x ∈",A. Proof for Theorem 1,[0],[0]
"R.
",A. Proof for Theorem 1,[0],[0]
"If this inequality holds, then for any value τ̂q such that F̂a(τ̂q) ≤ q, we have
Fa(τ̂q) ≤ F̂a(τ̂q)",A. Proof for Theorem 1,[0],[0]
"+ ≤ q + .
",A. Proof for Theorem 1,[0],[0]
"So we have with probability at least 1− δ, any τ̂q satisfying F̂a(τ̂q) ≤ q will satisfy Fa(τ̂q) ≤ q + .",A. Proof for Theorem 1,[0],[0]
"If α′ ≥ α, and if we write
F ′a(x) = Fm(x)− (1− α′)F0(x)
α′ ,
then F ′a is still a legal CDF, because
F ′a(−∞) = 0, F ′a(∞) = 1,
and it is easy to show that F ′a is monotonically nondecreasing.
",B. Proof for Corollary 1,[0],[0]
"But
F ′a(x)−Fa(x) =",B. Proof for Corollary 1,[0],[0]
"(α− α′)(Fm(x)− F0(x))
",B. Proof for Corollary 1,[0],[0]
"αα′ ≥ 0,∀x ∈ R,
and because of this, if we let τ̂ ′q denote the threshold we get from using α′, we will have Fa(τ̂ ′q) ≤",B. Proof for Corollary 1,[0],[0]
F ′a(τ̂ ′q).,B. Proof for Corollary 1,[0],[0]
"By the proof of previous theorem, we know that when n >",B. Proof for Corollary 1,[0],[0]
1 2 ln 2 1− √ 1−δ,B. Proof for Corollary 1,[0],[0]
( 1 ) 2( 2−α ′ α′ ),B. Proof for Corollary 1,[0],[0]
"2, we have with probability at least 1− δ, F ′a(τ̂ ′q) ≤ q",B. Proof for Corollary 1,[0],[0]
"+ ,",B. Proof for Corollary 1,[0],[0]
and thus we have Fa(τ̂ ′q) ≤ q,B. Proof for Corollary 1,[0],[0]
+ .,B. Proof for Corollary 1,[0],[0]
Open category detection is the problem of detecting “alien” test instances that belong to categories or classes that were not present in the training data.,abstractText,[0],[0]
"In many applications, reliably detecting such aliens is central to ensuring the safety and accuracy of test set predictions.",abstractText,[0],[0]
"Unfortunately, there are no algorithms that provide theoretical guarantees on their ability to detect aliens under general assumptions.",abstractText,[0],[0]
"Further, while there are algorithms for open category detection, there are few empirical results that directly report alien detection rates.",abstractText,[0],[0]
"Thus, there are significant theoretical and empirical gaps in our understanding of open category detection.",abstractText,[0],[0]
"In this paper, we take a step toward addressing this gap by studying a simple, but practically-relevant variant of open category detection.",abstractText,[0],[0]
"In our setting, we are provided with a “clean” training set that contains only the target categories of interest and an unlabeled “contaminated” training set that contains a fraction α of alien examples.",abstractText,[0],[0]
"Under the assumption that we know an upper bound on α, we develop an algorithm with PAC-style guarantees on the alien detection rate, while aiming to minimize false alarms.",abstractText,[0],[0]
Empirical results on synthetic and standard benchmark datasets demonstrate the regimes in which the algorithm can be effective and provide a baseline for further advancements.,abstractText,[0],[0]
Open Category Detection with PAC Guarantees,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 4231–4242 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
4231",text,[0],[0]
Open domain Question Answering (QA) is the task of finding answers to questions posed in natural language.,1 Introduction,[0],[0]
"Historically, this required a specialized pipeline consisting of multiple machinelearned and hand-crafted modules (Ferrucci et al., 2010).",1 Introduction,[0],[0]
"Recently, the paradigm has shifted towards training end-to-end deep neural network models for the task (Chen et al., 2017; Liang et al., 2017; Raison et al., 2018; Talmor and Berant, 2018; Iyyer et al., 2017).",1 Introduction,[0],[0]
"Most existing models, however, answer questions using a single information source, usually either text from an encyclopedia, or a single knowledge base (KB).
",1 Introduction,[0],[0]
"Intuitively, the suitability of an information source for QA depends on both its coverage and
∗Haitian Sun and Bhuwan Dhingra contributed equally to this work.",1 Introduction,[0],[0]
the difficulty of extracting answers from it.,Q. Who voiced Meg in Family Guy?,[0],[0]
"A large text corpus has high coverage, but the information is expressed using many different text patterns.",Q. Who voiced Meg in Family Guy?,[0],[0]
"As a result, models which operate on these patterns (e.g. BiDAF (Seo et al., 2017)) do not generalize beyond their training domains (Wiese et al., 2017; Dhingra et al., 2018) or to novel types of reasoning (Welbl et al., 2018; Talmor and Berant, 2018).",Q. Who voiced Meg in Family Guy?,[0],[0]
"KBs, on the other hand, suffer from low coverage due to their inevitable incompleteness and restricted schema (Min et al., 2013), but are easier to extract answers from, since they are constructed precisely for the purpose of being queried.
",Q. Who voiced Meg in Family Guy?,[0],[0]
"In practice, some questions are best answered using text, while others are best answered using KBs.",Q. Who voiced Meg in Family Guy?,[0],[0]
"A natural question, then, is how to effectively combine both types of information.",Q. Who voiced Meg in Family Guy?,[0],[0]
Surprisingly little prior work has looked at this problem.,Q. Who voiced Meg in Family Guy?,[0],[0]
"In this paper we focus on a scenario in which a large-scale KB (Bollacker et al., 2008; Auer et al., 2007) and a text corpus are available, but neither is sufficient alone for answering all questions.
",Q. Who voiced Meg in Family Guy?,[0],[0]
"A naı̈ve option, in such a setting, is to take stateof-the-art QA systems developed for each source, and aggregate their predictions using some heuristic (Ferrucci et al., 2010; Baudiš, 2015).",Q. Who voiced Meg in Family Guy?,[0],[0]
"We call this approach late fusion, and show that it can be sub-optimal, as models have limited ability to aggregate evidence across the different sources (§ 5.4).",Q. Who voiced Meg in Family Guy?,[0],[0]
"Instead, we focus on an early fusion strategy, where a single model is trained to extract answers from a question subgraph (Fig 1) containing relevant KB facts as well as text sentences.",Q. Who voiced Meg in Family Guy?,[0],[0]
"Early fusion allows more flexibility in combining information from multiple sources.
",Q. Who voiced Meg in Family Guy?,[0],[0]
"To enable early fusion, in this paper we propose a novel graph convolution based neural network, called GRAFT-Net (Graphs of Relations Among Facts and Text Networks), specifically designed to operate over heterogeneous graphs of KB facts and text sentences.",Q. Who voiced Meg in Family Guy?,[0],[0]
"We build upon recent work on graph representation learning (Kipf and Welling, 2016; Schlichtkrull et al., 2017), but propose two key modifications to adopt them for the task of QA.",Q. Who voiced Meg in Family Guy?,[0],[0]
"First, we propose heterogeneous update rules that handle KB nodes differently from the text nodes: for instance, LSTM-based updates are used to propagate information into and out of text nodes (§ 3.2).",Q. Who voiced Meg in Family Guy?,[0],[0]
"Second, we introduce a directed propagation method, inspired by personalized Pagerank in IR (Haveliwala, 2002), which constrains the propagation of embeddings in the graph to follow paths starting from seed nodes linked to the question (§ 3.3).",Q. Who voiced Meg in Family Guy?,[0],[0]
"Empirically, we show that both these extensions are crucial for the task of QA.
We evaluate these methods on a new suite of benchmark tasks for testing QA models when both KB and text are present.",Q. Who voiced Meg in Family Guy?,[0],[0]
"Using WikiMovies (Miller et al., 2016) and WebQuestionsSP (Yih et al., 2016), we construct datasets with a varying amount of training supervision and KB completeness, and with a varying degree of question complexity.",Q. Who voiced Meg in Family Guy?,[0],[0]
"We report baselines for future comparison, including Key Value Memory Networks (Miller et al., 2016; Das et al., 2017c), and show that our proposed GRAFT-Nets have superior performance across a wide range of conditions (§ 5).",Q. Who voiced Meg in Family Guy?,[0],[0]
"We also show that GRAFT-Nets are competitive with the state-of-the-art methods developed specifically for text-only QA, and state-of-the art methods developed for KB-only QA (§ 5.4)1.
1Source code and data are available at https:// github.com/OceanskySun/GraftNet",Q. Who voiced Meg in Family Guy?,[0],[0]
"A knowledge base is denoted as K = (V, E ,R), where V is the set of entities in the KB, and the edges E are triplets (s, r, o) which denote that relation r ∈ R holds between the subject s ∈ V and object o ∈ V .",2.1 Description,[0],[0]
"A text corpus D is a set of documents {d1, . . .",2.1 Description,[0],[0]
", d|D|} where each document is a sequence of words di = (w1, . . .",2.1 Description,[0],[0]
", w|di|).",2.1 Description,[0],[0]
"We further assume that an (imperfect) entity linking system has been run on the collection of documents whose output is a set L of links (v, dp) connecting an entity v ∈ V with a word at position p in document d, and we denote with Ld the set of all entity links in document d. For entity mentions spanning multiple words in d, we include links to all the words in the mention in L.
The task is, given a natural language question q = (w1, . . .",2.1 Description,[0],[0]
", w|q|), extract its answers {a}q from G = (K,D,L).",2.1 Description,[0],[0]
There may be multiple correct answers for a question.,2.1 Description,[0],[0]
"In this paper, we assume that the answers are entities from either the documents or the KB.",2.1 Description,[0],[0]
"We are interested in a wide range of settings, where the KB K varies from highly incomplete to complete for answering the questions, and we will introduce datasets for testing our models under these settings.
",2.1 Description,[0],[0]
To solve this task we proceed in two steps.,2.1 Description,[0],[0]
"First, we extract a subgraph Gq ⊂ G which contains the answer to the question with high probability.",2.1 Description,[0],[0]
The goal for this step is to ensure high recall for answers while producing a graph small enough to fit into GPU memory for gradient-based learning.,2.1 Description,[0],[0]
"Next, we use our proposed model GRAFT-Net to learn node representations in Gq, conditioned on q, which are used to classify each node as being an answer or not.",2.1 Description,[0],[0]
Training data for the second step is generated using distant supervision.,2.1 Description,[0],[0]
"The entire process mimics the search-and-read paradigm for text-based QA (Dhingra et al., 2017).",2.1 Description,[0],[0]
"We retrieve the subgraph Gq using two parallel pipelines – one over the KB K which returns a set of entities, and the other over the corpus D which returns a set of documents.",2.2 Question Subgraph Retrieval,[0],[0]
"The retrieved entities and documents are then combined with entity links to produce a fully-connected graph.
",2.2 Question Subgraph Retrieval,[0],[0]
KB Retrieval.,2.2 Question Subgraph Retrieval,[0],[0]
"To retrieve relevant entities from the KB we first perform entity linking on the ques-
tion q, producing a set of seed entities, denoted Sq.",2.2 Question Subgraph Retrieval,[0],[0]
"Next we run the Personalized PageRank (PPR) method (Haveliwala, 2002) around these seeds to identify other entities which might be an answer to the question.",2.2 Question Subgraph Retrieval,[0],[0]
"The edge-weights around Sq are distributed equally among all edges of the same type, and they are weighted such that edges relevant to the question receive a higher weight than those which are not.",2.2 Question Subgraph Retrieval,[0],[0]
"Specifically, we average word vectors to compute a relation vector v(r) from the surface form of the relation, and a question vector v(q) from the words in the question, and use cosine similarity between these as the edge weights.",2.2 Question Subgraph Retrieval,[0],[0]
"After running PPR we retain the top E entities v1, . . .",2.2 Question Subgraph Retrieval,[0],[0]
", vE by PPR score, along with any edges between them, and add them to Gq.
",2.2 Question Subgraph Retrieval,[0],[0]
Text Retrieval.,2.2 Question Subgraph Retrieval,[0],[0]
"We use Wikipedia as the corpus and retrieve text at the sentence level, i.e. documents in D are defined along sentences boundaries2.",2.2 Question Subgraph Retrieval,[0],[0]
"We perform text retrieval in two steps: first we retrieve the top 5 most relevant Wikipedia articles, using the weighted bag-of-words model from DrQA (Chen et al., 2017); then we populate a Lucene3 index with sentences from these articles, and retrieve the top ranking ones d1, . . .",2.2 Question Subgraph Retrieval,[0],[0]
", dD, based on the words in the question.",2.2 Question Subgraph Retrieval,[0],[0]
"For the sentence-retrieval step, we found it beneficial to include the title of the article as an additional field in the Lucene index.",2.2 Question Subgraph Retrieval,[0],[0]
"As most sentences in an article talk about the title entity, this helps in retrieving relevant sentences that do not explicitly mention the entity in the question.",2.2 Question Subgraph Retrieval,[0],[0]
"We add the retrieved documents, along with any entities linked to them, to the subgraph Gq.
",2.2 Question Subgraph Retrieval,[0],[0]
"The final question subgraph is Gq = (Vq, Eq,R+), where the vertices Vq consist of all the retrieved entities and documents, i.e. Vq = {v1, . . .",2.2 Question Subgraph Retrieval,[0],[0]
", vE} ∪{d1, . . .",2.2 Question Subgraph Retrieval,[0],[0]
", dD}.",2.2 Question Subgraph Retrieval,[0],[0]
"The edges are all relations from K among these entities, plus the entity-links between documents and entities, i.e.
Eq ={(s, o, r) ∈ E : s,",2.2 Question Subgraph Retrieval,[0],[0]
"o ∈ Vq, r ∈ R} ∪ {(v, dp, rL) : (v, dp) ∈",2.2 Question Subgraph Retrieval,[0],[0]
"Ld, d ∈ Vq},
where rL denotes a special “linking” relation.",2.2 Question Subgraph Retrieval,[0],[0]
"R+ = R ∪ {rL} is the set of all edge types in the subgraph.
",2.2 Question Subgraph Retrieval,[0],[0]
"2The term document will always refer to a sentence in the rest of this paper.
",2.2 Question Subgraph Retrieval,[0],[0]
3https://lucene.apache.org/,2.2 Question Subgraph Retrieval,[0],[0]
The question q and its answers {a}q induce a labeling of the nodes in Vq: we let yv = 1 if v ∈ {a}q and yv = 0 otherwise for all v ∈,3 GRAFT-Nets,[0],[0]
Vq .,3 GRAFT-Nets,[0],[0]
The task of QA then reduces to performing binary classification over the nodes of the graph Gq.,3 GRAFT-Nets,[0],[0]
"Several graph-propagation based models have been proposed in the literature which learn node representations and then perform classification of the nodes (Kipf and Welling, 2016; Schlichtkrull et al., 2017).",3 GRAFT-Nets,[0],[0]
"Such models follow the standard gather-apply-scatter paradigm to learn the node representation with homogeneous updates, i.e. treating all neighbors equally.
",3 GRAFT-Nets,[0],[0]
"The basic recipe for these models is as follows:
1.",3 GRAFT-Nets,[0],[0]
"Initialize node representations h(0)v .
2.",3 GRAFT-Nets,[0],[0]
"For l = 1, . . .",3 GRAFT-Nets,[0],[0]
", L update node representations
h(l)v = φ h(l−1)v , ∑ v′∈Nr(v) h (l−1) v′  , where Nr(v) denotes the neighbours of v along incoming edges of type r, and φ is a neural network layer.
",3 GRAFT-Nets,[0],[0]
Here L is the number of layers in the model and corresponds to the maximum length of the paths along which information should be propagated in the graph.,3 GRAFT-Nets,[0],[0]
"Once the propagation is complete the final layer representations h(L)v are used to perform the desired task, for example link prediction in knowledge bases (Schlichtkrull et al., 2017).
",3 GRAFT-Nets,[0],[0]
"However, there are two differences in our setting from previously studied graph-based classification tasks.",3 GRAFT-Nets,[0],[0]
"The first difference is that, in our case, the graph Gq consists of heterogeneous nodes.",3 GRAFT-Nets,[0],[0]
"Some nodes in the graph correspond to KB entities which represent symbolic objects, whereas other nodes represent textual documents which are variable length sequences of words.",3 GRAFT-Nets,[0],[0]
The second difference is that we want to condition the representation of nodes in the graph on the natural language question q.,3 GRAFT-Nets,[0],[0]
"In §3.2 we introduce heterogeneous updates to address the first difference, and in §3.3 we introduce mechanisms for conditioning on the question (and its entities) for the second.",3 GRAFT-Nets,[0],[0]
Nodes corresponding to entities are initialized using fixed-size vectors h(0)v = xv ∈,3.1 Node Initialization,[0],[0]
"Rn, where
xv can be pre-trained KB embeddings or random, and n is the embedding size.",3.1 Node Initialization,[0],[0]
Document nodes in the graph describe a variable length sequence of text.,3.1 Node Initialization,[0],[0]
"Since multiple entities might link to different positions in the document, we maintain a variable length representation of the document in each layer.",3.1 Node Initialization,[0],[0]
"This is denoted by H(l)d ∈ R
|d|×n.",3.1 Node Initialization,[0],[0]
"Given the words in the document (w1, . . .",3.1 Node Initialization,[0],[0]
", w|d|), we initialize its hidden representation as:
H (0) d = LSTM(w1, w2, . . .",3.1 Node Initialization,[0],[0]
"),
where LSTM refers to a long short-term memory unit.",3.1 Node Initialization,[0],[0]
"We denote the p-th row of H(l)d , corresponding to the embedding of p-th word in the document d at layer l, as H(l)d,p.",3.1 Node Initialization,[0],[0]
"Figure 2 shows the update rules for entities and documents, which we describe in detail here.
",3.2 Heterogeneous Updates,[0],[0]
Entities.,3.2 Heterogeneous Updates,[0],[0]
"Let M(v) = {(d, p)} be the set of positions p in documents d which correspond to a mention of entity v. The update for entity nodes involves a single-layer feed-forward network (FFN) over the concatenation of four states:
h(l)v",3.2 Heterogeneous Updates,[0],[0]
"= FFN  
h (l−1) v
h (l−1) q∑
r ∑ v′∈Nr(v) α v′",3.2 Heterogeneous Updates,[0],[0]
"r ψr(h
(l−1) v′ )",3.2 Heterogeneous Updates,[0],[0]
"∑
(d,p)∈M(v)H (l−1) d,p
  .",3.2 Heterogeneous Updates,[0],[0]
"(1)
The first two terms correspond to the entity representation and question representation (details below), respectively, from the previous layer.
",3.2 Heterogeneous Updates,[0],[0]
"The third term aggregates the states from the entity neighbours of the current node, Nr(v), after scaling with an attention weight αv ′",3.2 Heterogeneous Updates,[0],[0]
"r (described in the next section), and applying relation specific transformations ψr.",3.2 Heterogeneous Updates,[0],[0]
"Previous work on RelationalGraph Convolution Networks (Schlichtkrull et al., 2017) used a linear projection for ψr.",3.2 Heterogeneous Updates,[0],[0]
"For a batched implementation, this results in matrices of size O(B|Rq||Eq|n), where B is the batch size, which can be prohibitively large for large subgraphs4.",3.2 Heterogeneous Updates,[0],[0]
Hence in this work we use relation vectors xr for r ∈,3.2 Heterogeneous Updates,[0],[0]
"Rq instead of matrices, and compute the update along an edge as:
ψr(h (l−1) v′ )",3.2 Heterogeneous Updates,[0],[0]
"= pr (l−1) v′ FFN ( xr, h (l−1) v′ ) .",3.2 Heterogeneous Updates,[0],[0]
"(2)
4This is because we have to use adjacency matrices of size |Rq| × |Eq| × |Eq| to aggregate embeddings from neighbours of all nodes simultaneously.
",3.2 Heterogeneous Updates,[0],[0]
"Here pr(l−1)v′ is a PageRank score used to control the propagation of embeddings along paths starting from the seed nodes, which we describe in detail in the next section.",3.2 Heterogeneous Updates,[0],[0]
"The memory complexity of the above isO(B(|Fq|+ |Eq|)n), where |Fq| is the number of facts in the subgraph Gq.
",3.2 Heterogeneous Updates,[0],[0]
The last term aggregates the states of all tokens that correspond to mentions of the entity v among the documents in the subgraph.,3.2 Heterogeneous Updates,[0],[0]
"Note that the update depends on the positions of entities in their containing document.
",3.2 Heterogeneous Updates,[0],[0]
Documents.,3.2 Heterogeneous Updates,[0],[0]
"Let L(d, p) be the set of all entities linked to the word at position p in",3.2 Heterogeneous Updates,[0],[0]
document d.,3.2 Heterogeneous Updates,[0],[0]
The document update proceeds in two steps.,3.2 Heterogeneous Updates,[0],[0]
"First we aggregate over the entity states coming in at each position separately:
H̃ (l) d,p = FFN H(l−1)d,p , ∑ v∈L(d,p) h(l−1)v  .",3.2 Heterogeneous Updates,[0],[0]
(3a),3.2 Heterogeneous Updates,[0],[0]
Here h(l−1)v are normalized by the number of outgoing edges at v.,3.2 Heterogeneous Updates,[0],[0]
"Next we aggregate states within the document using an LSTM:
H (l) d = LSTM(H̃",3.2 Heterogeneous Updates,[0],[0]
(l) d ).,3.2 Heterogeneous Updates,[0],[0]
(3b),3.2 Heterogeneous Updates,[0],[0]
"For the parts described thus far, the graph learner is largely agnostic of the question.",3.3 Conditioning on the Question,[0],[0]
"We introduce dependence on question in two ways: by attention over relations, and by personalized propagation.
",3.3 Conditioning on the Question,[0],[0]
"To represent q, let wq1, . . .",3.3 Conditioning on the Question,[0],[0]
", w q |q| be the words in the question.",3.3 Conditioning on the Question,[0],[0]
"The initial representation is computed as:
h(0)q = LSTM(w q 1, . . .",3.3 Conditioning on the Question,[0],[0]
", w q |q|)|q| ∈ R n, (4)
where we extract the final state from the output of the LSTM.",3.3 Conditioning on the Question,[0],[0]
"In subsequent layers the question representation is updated as h(l)q =
FFN (∑
v∈Sq h (l) v ) , where Sq denotes the seed en-
tities mentioned in the question.
",3.3 Conditioning on the Question,[0],[0]
Attention over Relations.,3.3 Conditioning on the Question,[0],[0]
The attention weight in the third term of Eq.,3.3 Conditioning on the Question,[0],[0]
"(1) is computed using the question and relation embeddings:
αv ′
r = softmax(x T r h (l−1) q ),
where the softmax normalization is over all outgoing edges from v′, and xr is the relation vector for relation r.",3.3 Conditioning on the Question,[0],[0]
"This ensures that embeddings are propagated more along edges relevant to the question.
",3.3 Conditioning on the Question,[0],[0]
Directed Propagation.,3.3 Conditioning on the Question,[0],[0]
"Many questions require multi-hop reasoning, which follows a path from a seed node mentioned in the question to the target answer node.",3.3 Conditioning on the Question,[0],[0]
"To encourage such a behaviour when propagating embeddings, we develop a technique inspired from personalized PageRank in IR (Haveliwala, 2002).",3.3 Conditioning on the Question,[0],[0]
The propagation starts at the seed entities Sq mentioned in the question.,3.3 Conditioning on the Question,[0],[0]
"In addition to the vector embeddings h(l)v at the nodes, we also maintain scalar “PageRank” scores pr(l)v which measure the total weight of paths from a seed entity to the current node, as follows:
pr(0)v = { 1 |Sq | if v ∈",3.3 Conditioning on the Question,[0],[0]
"Sq 0 o.w. ,
pr(l)v = (1− λ)pr(l−1)v + λ ∑ r ∑ v′∈Nr(v) αv ′",3.3 Conditioning on the Question,[0],[0]
"r pr (l−1) v′ .
",3.3 Conditioning on the Question,[0],[0]
"Notice that we reuse the attention weights αv ′
r
when propagating PageRank, to ensure that nodes along paths relevant to the question receive a high weight.",3.3 Conditioning on the Question,[0],[0]
The PageRank score is used as a scaling factor when propagating embeddings along the edges in Eq.,3.3 Conditioning on the Question,[0],[0]
(2).,3.3 Conditioning on the Question,[0],[0]
"For l = 1, the PageRank score will be 0 for all entities except the seed entities, and hence propagation will only happen outward from these nodes.",3.3 Conditioning on the Question,[0],[0]
"For l = 2, it will be non-zero for the seed entities and their 1-hop neighbors, and propagation will only happen along these edges.",3.3 Conditioning on the Question,[0],[0]
Figure 3 illustrates this process.,3.3 Conditioning on the Question,[0],[0]
"The final representations h(L)v ∈ Rn, are used for binary classification to select the answers:
",3.4 Answer Selection,[0],[0]
"Pr (v ∈ {a}q|Gq, q) = σ(wTh(L)v + b), (5)
where σ is the sigmoid function.",3.4 Answer Selection,[0],[0]
Training uses binary cross-entropy loss over these probabilities.,3.4 Answer Selection,[0],[0]
"To encourage the model to learn a robust classifier, which exploits all available sources of information, we randomly drop edges from the graph during training with probability p0.",3.5 Regularization via Fact Dropout,[0],[0]
We call this fact-dropout.,3.5 Regularization via Fact Dropout,[0],[0]
"It is usually easier to extract answers from the KB than from the documents, so the model tends to rely on the former, especially when the KB is complete.",3.5 Regularization via Fact Dropout,[0],[0]
"This method is similar to DropConnect (Wan et al., 2013).",3.5 Regularization via Fact Dropout,[0],[0]
The work of Das et al. (2017c) attempts an early fusion strategy for QA over KB facts and text.,4 Related Work,[0],[0]
"Their approach is based on Key-Value Memory Networks (KV-MemNNs) (Miller et al., 2016) coupled with a universal schema (Riedel et al., 2013) to populate a memory module with representations of KB triples and text snippets independently.",4 Related Work,[0],[0]
"The key limitation for this model is that it ignores the rich relational structure between the
facts and text snippets.",4 Related Work,[0],[0]
"Our graph-based method, on the other hand, explicitly uses this structure for the propagation of embeddings.",4 Related Work,[0],[0]
"We compare the two approaches in our experiments (§5), and show that GRAFT-Nets outperform KV-MemNNs over all tasks.
",4 Related Work,[0],[0]
Non-deep learning approaches have been also attempted for QA over both text assertions and KB facts.,4 Related Work,[0],[0]
Gardner and Krishnamurthy (2017) use traditional feature extraction methods of openvocabulary semantic parsing for the task.,4 Related Work,[0],[0]
"Ryu et al. (2014) use a pipelined system aggregating evidence from both unstructured and semistructured sources for open-domain QA.
Another line of work has looked at learning combined representations of KBs and text for relation extraction and Knowledge Base Completion (KBC) (Lao et al., 2012; Riedel et al., 2013; Toutanova et al., 2015; Verga et al., 2016; Das et al., 2017b; Han et al., 2016).",4 Related Work,[0],[0]
"The key difference in QA compared to KBC is that in QA the inference process on the knowledge source has to be conditioned on the question, so different questions induce different representations of the KB and warrant a different inference process.",4 Related Work,[0],[0]
"Furthermore, KBC operates under the fixed schema defined by the KB before-hand, whereas natural language questions might not adhere to this schema.
",4 Related Work,[0],[0]
"The GRAFT-Net model itself is motivated from the large body of work on graph representation learning (Scarselli et al., 2009; Li et al., 2016; Kipf and Welling, 2016; Atwood and Towsley, 2016; Schlichtkrull et al., 2017).",4 Related Work,[0],[0]
"Like most other graph-based models, GRAFT-Nets can also be viewed as an instantiation of the Message Passing Neural Network (MPNN) framework of Gilmer et al. (2017).",4 Related Work,[0],[0]
"GRAFT-Nets are also inductive representation learners like GraphSAGE (Hamilton et al., 2017), but operate on a heterogeneous mixture of nodes and use retrieval for getting a subgraph instead of random sampling.",4 Related Work,[0],[0]
"The recently proposed Walk-Steered Convolution model uses random walks for learning graph representations (Jiang et al., 2018).",4 Related Work,[0],[0]
"Our personalization technique also borrows from such random walk literature, but uses it to localize propagation of embeddings.
",4 Related Work,[0],[0]
"Tremendous progress on QA over KB has been made with deep learning based approaches like memory networks (Bordes et al., 2015; Jain, 2016) and reinforcement learning (Liang et al., 2017; Das et al., 2017a).",4 Related Work,[0],[0]
"But extending them with text,
which is our main focus, is non-trivial.",4 Related Work,[0],[0]
"In another direction, there is also work on producing parsimonious graphical representations of textual data (Krause et al., 2016; Lu et al., 2017); however in this paper we use a simple sequential representation augmented with entity links to the KB which works well.
",4 Related Work,[0],[0]
"For QA over text only, a major focus has been on the task of reading comprehension (Seo et al., 2017; Gong and Bowman, 2017; Hu et al., 2017; Shen et al., 2017; Yu et al., 2018) since the introduction of SQuAD (Rajpurkar et al., 2016).",4 Related Work,[0],[0]
"These systems assume that the answer-containing passage is known apriori, but there has been progress when this assumption is relaxed (Chen et al., 2017; Raison et al., 2018; Dhingra et al., 2017; Wang et al., 2018, 2017; Watanabe et al., 2017).",4 Related Work,[0],[0]
"We work in the latter setting, where relevant information must be retrieved from large information sources, but we also incorporate KBs into this process.",4 Related Work,[0],[0]
"WikiMovies-10K consists of 10K randomly sampled training questions from the WikiMovies dataset (Miller et al., 2016), along with the original test and validation sets.",5.1 Datasets,[0],[0]
"We sample the training questions to create a more difficult setting, since the original dataset has 100K questions over only 8 different relation types, which is unrealistic in our opinion.",5.1 Datasets,[0],[0]
"In § 5.4 we also compare to the existing state-of-the-art using the full training set.
",5.1 Datasets,[0],[0]
We use the KB and text corpus constructed from Wikipedia released by Miller et al. (2016).,5.1 Datasets,[0],[0]
"For entity linking we use simple surface level matches, and retrieve the top 50 entities around the seeds to create the question subgraph.",5.1 Datasets,[0],[0]
We further add the top 50 sentences (along with their article titles) to the subgraph using Lucene search over the text corpus.,5.1 Datasets,[0],[0]
The overall answer recall in our constructed subgraphs is 99.6%.,5.1 Datasets,[0],[0]
WebQuestionsSP,5.1 Datasets,[0],[0]
"(Yih et al., 2016) consists of 4737 natural language questions posed over Freebase entities, split up into 3098 training and 1639 test questions.",5.1 Datasets,[0],[0]
We reserve 250 training questions for model development and early stopping.,5.1 Datasets,[0],[0]
"We use the entity linking outputs from S-MART5 and retrieve 500 entities from the neighbourhood around the question seeds in Freebase to populate the
5https://github.com/scottyih/STAGG
question subgraphs6.",5.1 Datasets,[0],[0]
We further retrieve the top 50 sentences from Wikipedia with the two-stage process described in §2.,5.1 Datasets,[0],[0]
"The overall recall of answers among the subgraphs is 94.0%.
",5.1 Datasets,[0],[0]
Table 1 shows the combined statistics of all the retreived subgraphs for the questions in each dataset.,5.1 Datasets,[0],[0]
These two datasets present varying levels of difficulty.,5.1 Datasets,[0],[0]
"While all questions in WikiMovies correspond to a single KB relation, for WebQuestionsSP the model needs to aggregate over two KB facts for ∼30% of the questions, and also requires reasoning over constraints for ∼7% of the questions (Liang et al., 2017).",5.1 Datasets,[0],[0]
"For maximum portability, QA systems need to be robust across several degrees of KB availability since different domains might contain different amounts of structured data; and KB completeness may also vary over time.",5.1 Datasets,[0],[0]
"Hence, we construct an additional 3 datasets each from the above two, with the number of KB facts downsampled to 10%, 30% and 50% of the original to simulate settings where the KB is incomplete.",5.1 Datasets,[0],[0]
We repeat the retrieval process for each sampled KB.,5.1 Datasets,[0],[0]
KV-KB is the Key Value Memory Networks model from Miller et al. (2016); Das et al. (2017c) but using only KB and ignoring the text.,5.2 Compared Models,[0],[0]
KV-EF (early fusion) is the same model with access to both KB and text as memories.,5.2 Compared Models,[0],[0]
"For text we use a BiLSTM over the entire sentence as keys, and entity mentions as values.",5.2 Compared Models,[0],[0]
This re-implementation shows better performance on the text-only and KB-only WikiMovies tasks than the results reported previously7 (see Table 4).,5.2 Compared Models,[0],[0]
GN-KB is the GRAFT-Net model ignoring the text.,5.2 Compared Models,[0],[0]
"GN-LF is a late fusion version of the GRAFT-Net model: we train two separate models, one using text only and the other using KB only, and then ensemble the two8.",5.2 Compared Models,[0],[0]
GN-EF is our main GRAFT-Net model with early fusion.,5.2 Compared Models,[0],[0]
"GN-EF+LF is an ensemble over the GN-EF and GN-LF models, with the same ensembling method as GN-LF.",5.2 Compared Models,[0],[0]
"We report Hits@1, which
6A total of 13 questions had no detected entities.",5.2 Compared Models,[0],[0]
"These were ignored during training and considered as incorrect during evaluation.
",5.2 Compared Models,[0],[0]
"7For all KV models we tuned the number of layers {1, 2, 3}, batch size {10, 30, 50}, model dimension {50, 80}.",5.2 Compared Models,[0],[0]
"We also use fact dropout regularization in the KB+Text setting tuned between {0, 0.2, 0.4}.
8For ensembles we take a weighted combination of the answer probabilities produced by the models, with the weights tuned on the dev set.",5.2 Compared Models,[0],[0]
"For answers only in text or only in KB, we use the probability as is.
is the accuracy of the top-predicted answer from the model, and the F1 score.",5.2 Compared Models,[0],[0]
To compute the F1 score we tune a threshold on the development set to select answers based on binary probabilities for each node in the subgraph.,5.2 Compared Models,[0],[0]
Table 2 presents a comparison of the above models across all datasets.,5.3 Main Results,[0],[0]
"GRAFT-Nets (GN) shows consistent improvement over KV-MemNNs on both datasets in all settings, including KB only (-KB), text only (-EF, Text Only column), and early fusion (-EF).",5.3 Main Results,[0],[0]
"Interestingly, we observe a larger relative gap between the Hits and F1 scores for the KV models than we do for our GN models.",5.3 Main Results,[0],[0]
"We believe this is because the attention for KV is normalized over the memories, which are KB facts (or text sentences): hence the model is unable to assign high probabilities to multiple facts at the same time.",5.3 Main Results,[0],[0]
"On the other hand, in GN, we normalize the attention over types of relations outgoing from a node, and hence can assign high weights to all the correct answers.
",5.3 Main Results,[0],[0]
"We also see a consistent improvement of early fusion over late fusion (-LF), and by ensembling them together we see the best performance across all the models.",5.3 Main Results,[0],[0]
"In Table 2 (right), we further show the improvement for KV-EF over KV-KB, and GN-LF and GN-EF over GN-KB, as the amount of KB is increased.",5.3 Main Results,[0],[0]
This measures how effective these approaches are in utilizing text plus a KB.,5.3 Main Results,[0],[0]
"For KV-EF we see improvements when the KB is highly incomplete, but in the full KB setting, the performance of the fused approach is worse.",5.3 Main Results,[0],[0]
A similar trend holds for GN-LF.,5.3 Main Results,[0],[0]
"On the other hand, GN-EF with text improves over the KB-only approach in all settings.",5.3 Main Results,[0],[0]
"As we would expect, though, the benefit of adding text decreases as the KB becomes more and more complete.",5.3 Main Results,[0],[0]
In Table 4 we compare GRAFT-Nets to state-ofthe-art models that are specifically designed and tuned for QA using either only KB or only text.,5.4 Comparison to Specialized Methods,[0],[0]
For this experiment we use the full WikiMovies dataset to enable direct comparison to previously reported numbers.,5.4 Comparison to Specialized Methods,[0],[0]
"For DrQA (Chen et al., 2017), following the original paper, we restrict answer spans for WebQuestionsSP to match an entity in Freebase.",5.4 Comparison to Specialized Methods,[0],[0]
In each case we also train GRAFT-Nets using only KB facts or only text sentences.,5.4 Comparison to Specialized Methods,[0],[0]
"In three out of the four cases, we find that GRAFT-Nets ei-
ther match or outperform the existing state-of-theart models.",5.4 Comparison to Specialized Methods,[0],[0]
"We emphasize that the latter have no mechanism for dealing with the fused setting.
",5.4 Comparison to Specialized Methods,[0],[0]
"The one exception is the KB-only case for WebQuestionsSP where GRAFT-Net does 6.2% F1 points worse than Neural Symbolic Machines (Liang et al., 2017).",5.4 Comparison to Specialized Methods,[0],[0]
"Analysis suggested three explanations: (1) In the KB-only setting, the recall of subgraph retrieval is only 90.2%, which limits overall performance.",5.4 Comparison to Specialized Methods,[0],[0]
"In an oracle setting where we ensure the answers are part of the subgraph, the F1 score increases by 4.8%.",5.4 Comparison to Specialized Methods,[0],[0]
"(2) We use the same probability threshold for all questions, even though the number of answers may vary significantly.",5.4 Comparison to Specialized Methods,[0],[0]
Models which parse the query into a symbolic form do not suffer from this problem since answers are retrieved in a deterministic fashion.,5.4 Comparison to Specialized Methods,[0],[0]
If we tune separate thresholds for each question the F1 score improves by 7.6%.,5.4 Comparison to Specialized Methods,[0],[0]
"(3) GRAFT-Nets perform poorly in the few cases where there is a constraint involved in picking out the answer (for example, “who first voiced Meg in Family Guy”).",5.4 Comparison to Specialized Methods,[0],[0]
"If we ignore such constraints, and consider all entities with the same sequence of relations to the seed as correct, the performance improves by 3.8% F1.",5.4 Comparison to Specialized Methods,[0],[0]
Heuristics such as those used by Yu et al. (2017) can be used to improve these cases.,5.4 Comparison to Specialized Methods,[0],[0]
"Figure 3 shows
examples where GRAFT-Net fails to predict the correct answer set exactly.",5.4 Comparison to Specialized Methods,[0],[0]
Heterogeneous Updates.,5.5 Effect of Model Components,[0],[0]
"We tested a nonheterogeneous version of our model, where instead of using fine-grained entity linking information for updating the node representations (M(v) and L(d, p) in Eqs. 1, 3a), we aggregate the document states across all its positions as ∑ pH (l) d,p and use this combined state for all updates.",5.5 Effect of Model Components,[0],[0]
"Without the heterogeneous update, all entities v ∈ L(d, ·) will receive the same update from document d. Therefore, the model cannot disambiguate different entities mentioned in the same document.",5.5 Effect of Model Components,[0],[0]
"The result in Table 5 shows that this version is consistently worse than the heterogeneous model.
",5.5 Effect of Model Components,[0],[0]
Conditioning on the Question.,5.5 Effect of Model Components,[0],[0]
We performed an ablation test on the directed propagation method and attention over relations.,5.5 Effect of Model Components,[0],[0]
We observe that both components lead to better performance.,5.5 Effect of Model Components,[0],[0]
"Such effects are observed in both complete and incomplete KB scenarios, e.g. on WebQuestionsSP dataset, as shown in Figure 4 (left).
",5.5 Effect of Model Components,[0],[0]
Fact Dropout.,5.5 Effect of Model Components,[0],[0]
"Figure 4 (right) compares the performance of the early fusion model as we vary
0",5.5 Effect of Model Components,[0],[0]
"KB 0.1 KB 0.3 KB 0.5 KB 1.0 KB NH 22.7 / 13.6 28.7 / 15.8 35.6 / 23.2 47.2 / 33.3 66.5 / 59.8 H 25.3 / 15.3 31.5 / 17.7 40.7 / 25.2 49.9 / 34.7 67.8 / 60.4
Table 5: Non-Heterogeneous (NH) vs. Heterogeneous (H) updates on WebQuestionsSP
the rate of fact dropout.",5.5 Effect of Model Components,[0],[0]
Moderate levels of fact dropout improve performance on both datasets.,5.5 Effect of Model Components,[0],[0]
The performance increases as the fact dropout rate increases until the model is unable to learn the inference chain from KB.,5.5 Effect of Model Components,[0],[0]
"In this paper we investigate QA using text combined with an incomplete KB, a task which has received limited attention in the past.",6 Conclusion,[0],[0]
"We introduce several benchmark problems for this task by modifying existing question-answering datasets, and discuss two broad approaches to solving this problem—“late fusion” and “early fusion”.",6 Conclusion,[0],[0]
"We show that early fusion approaches perform better.
",6 Conclusion,[0],[0]
"We also introduce a novel early-fusion model, called GRAFT-Net, for classifying nodes in subgraph consisting of both KB entities and text doc-
uments.",6 Conclusion,[0],[0]
GRAFT-Net builds on recent advances in graph representation learning but includes several innovations which improve performance on this task.,6 Conclusion,[0],[0]
"GRAFT-Nets are a single model which achieve performance competitive to state-of-theart methods in both text-only and KB-only settings, and outperform baseline models when using text combined with an incomplete KB.",6 Conclusion,[0],[0]
"Current directions for future work include – (1) extending GRAFT-Nets to pick spans of text as answers, rather than only entities and (2) improving the subgraph retrieval process.",6 Conclusion,[0],[0]
Bhuwan Dhingra is supported by NSF under grants CCF-1414030 and IIS-1250956 and by grants from Google.,Acknowledgments,[0],[0]
"Ruslan Salakhutdinov is supported in part by ONR grant N000141812861, Apple, and Nvidia NVAIL Award.",Acknowledgments,[0],[0]
Open Domain Question Answering (QA) is evolving from complex pipelined systems to end-to-end deep neural networks.,abstractText,[0],[0]
Specialized neural models have been developed for extracting answers from either text alone or Knowledge Bases (KBs) alone.,abstractText,[0],[0]
"In this paper we look at a more practical setting, namely QA over the combination of a KB and entitylinked text, which is appropriate when an incomplete KB is available with a large text corpus.",abstractText,[0],[0]
"Building on recent advances in graph representation learning we propose a novel model, GRAFT-Net, for extracting answers from a question-specific subgraph containing text and KB entities and relations.",abstractText,[0],[0]
"We construct a suite of benchmark tasks for this problem, varying the difficulty of questions, the amount of training data, and KB completeness.",abstractText,[0],[0]
"We show that GRAFT-Net is competitive with the state-of-the-art when tested using either KBs or text alone, and vastly outperforms existing methods in the combined setting.",abstractText,[0],[0]
Open Domain Question Answering Using Early Fusion of Knowledge Bases and Text,title,[0],[0]
"Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 1626–1637 Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics",text,[0],[0]
"Offering a channel for customers to share opinions and give scores to products and services, review websites have become a highly influential information source that customers refer to for making purchase decisions.",1 Introduction,[0],[0]
"Popular examples include IMDB.com on the movie domain, Epinions.com on the product domain, and Yelp.com on the service domain.",1 Introduction,[0],[0]
"Figure 1 shows a screenshot of a restaurant review page on Yelp.com, which offers two main types of information.",1 Introduction,[0],[0]
"First, an overall rating score is given under the restaurant name; second, detailed user reviews are listed below the rating.
∗This work has been done when the first author worked at SUTD.
",1 Introduction,[0],[0]
"Though offering useful overview and details about a product or service, such information has several limitations for a user who has not used the product or service.",1 Introduction,[0],[0]
"First, the overall rating is general and not necessarily agreeable to the taste of an individual customer.",1 Introduction,[0],[0]
"Being a simple reflection of all customer scores, it serves an average customer well, but can be rather inaccurate for individuals.",1 Introduction,[0],[0]
"For example, the authors themselves often find highly rated movies being tedious.",1 Introduction,[0],[0]
"Second, there can be hundreds of reviews for a product or service, which makes it infeasible for exhaustive reading.",1 Introduction,[0],[0]
"It would be useful to have a brief summary of all reviews, which ideally should be customized to the reader.
",1 Introduction,[0],[0]
"To address the limitations above, we propose a new task called opinion recommendation, which is to generate a customized review score of the product that the user is likely to give, as well as a customized review that the user would have written for the target product, if the user had reviewed the product.",1 Introduction,[0],[0]
The proposed opinion recommendation task is closely related to several existing lines of work in NLP.,1 Introduction,[0],[0]
"The first is sentiment analysis (Hu and Liu, 2004; Pang and Lee, 2008) and opinion summarization (Nishikawa et al., 2010; Wang and Ling, 2016), which is to give a rating score or summary based on existing customer reviews.",1 Introduction,[0],[0]
"Our
1626
task is different in that we aim to generate user rating scores and review of a product unreviewed by the user.",1 Introduction,[0],[0]
"The second is recommendation (Su and Khoshgoftaar, 2009; Yang et al., 2014), which is to give a ranking score to a certain product or service based on the purchase history of the user and other customers who have purchased the target product.",1 Introduction,[0],[0]
"Our task is different in the source of input, which is textual customer reviews and ratings rather than numerical purchase history.
",1 Introduction,[0],[0]
"There are two types of inputs for our task, namely existing reviews of the target product, and the reviews of the user on other products, and two types of outputs, namely a customized rating score and a customized review.",1 Introduction,[0],[0]
"The ideal solution should consider the interaction between all given types of information, jointly predicting the two types of outputs.",1 Introduction,[0],[0]
"This poses significant challenges to statistical models, which require manually defined features to capture relevant patterns from training data.",1 Introduction,[0],[0]
"Deep learning is a relatively more feasible choice, offering viabilities of information fusion by fully connected hidden layers (Collobert et al., 2011; Henderson et al., 2013; Zhang and Weiss, 2016; Chen et al., 2016a).",1 Introduction,[0],[0]
"We leverage this advantage in building our model.
",1 Introduction,[0],[0]
"In particular, we use a sub RNN to model the semantic content of each review.",1 Introduction,[0],[0]
"A sub product model is used to consolidate existing reviews for the target product, and a user model is built by consolidating the reviews of the given user into a single vector form.",1 Introduction,[0],[0]
"To address potential sparsity of a user’s history reviews, neighbor users are identified by collaborative filtering (Ding et al., 2006), and a vector representation is learned by using a neural neighborhood model.",1 Introduction,[0],[0]
"Finally, a deep memory network is utilized to find the association between the user and target product, jointly yielding the rating score and customised review.",1 Introduction,[0],[0]
Experiments on a Yelp dataset show that the model outperforms several pipelined baselines.,1 Introduction,[0],[0]
We make our source code publicly available under GPL at https://github.com/ wangzq870305/opinion_recommend.,1 Introduction,[0],[0]
Sentiment Analysis.,2 Related Work,[0],[0]
"Our task is related to document-level sentiment classification (Pang and Lee, 2008) for various neural network models have been used, including convolutional neural networks (Kim, 2014), recursive neural net-
work (Socher et al., 2013) and recurrent neural network (Teng et al., 2016; Tai et al., 2015), Review rating prediction aims to predict the numeric rating of a given review.",2 Related Work,[0],[0]
Pang and Lee (2005) pioneered this task by regarding it as a classification/regression problem.,2 Related Work,[0],[0]
"Most subsequent work focuses on designing effective textural features of reviews (Qu et al., 2010; Li et al., 2011; Wan, 2013).
",2 Related Work,[0],[0]
User information has been widely investigated in sentiment analysis.,2 Related Work,[0],[0]
"Gao et al. (2013) developed user-specific features to capture user leniency, and Li et al. (2014) incorporated textual topic and userword factors through topic modeling.",2 Related Work,[0],[0]
"For integrating user information into neural network models, Tang et al. (2015) predicted the rating score given a review by using both lexical semantic information and a user embedding model.",2 Related Work,[0],[0]
"Chen et al. (2016b) proposed a neural network to incorporate global user and product information for sentiment classification via an attention mechanism.
",2 Related Work,[0],[0]
"Different from the above research, which focuses on predicting the opinion on existing reviews, our task is to recommend the score that a user would give to a new product without knowing his review text.",2 Related Work,[0],[0]
The difference originates from the objective.,2 Related Work,[0],[0]
"Previous research aims to predict opinions on reviewed products, while our task is to recommend opinion on new products, which the user has not reviewed.
",2 Related Work,[0],[0]
Opinion Summarization.,2 Related Work,[0],[0]
"Our work also overlaps with to the area of opinion summarization, which constructs natural language summaries for multiple product reviews (Hu and Liu, 2004).",2 Related Work,[0],[0]
Most previous work extracts opinion words and aspect terms.,2 Related Work,[0],[0]
"Typical approaches include association mining of frequent candidate aspects (Hu and Liu, 2004; Qiu et al., 2011), sequence labeling based methods (Jakob and Gurevych, 2010; Yang and Cardie, 2013), as well as topic modeling techniques (Lin and He, 2009).",2 Related Work,[0],[0]
"Recently, word embeddings and recurrent neural networks are also used to extract aspect terms (Irsoy and Cardie, 2014; Liu et al., 2015).",2 Related Work,[0],[0]
"While all the methods above are extractive, Ganesan et al. (2010) presented a graph-based summarization framework to generate concise abstractive summaries of highly redundant opinions, and Wang and Ling (2016) used an attention-based neural network model to absorb information from multiple text units and generate summaries of movie reviews.",2 Related Work,[0],[0]
"We also
perform abstractive summarization.",2 Related Work,[0],[0]
"However, different from the above research, which summarize existing reviews, we generate customized reviews for a unreviewed product.
Recommendation.",2 Related Work,[0],[0]
has been solved on mainly purchase history.,2 Related Work,[0],[0]
"There are two main approaches, which are content-based and collaborativefiltering (CF) based (Adomavicius and Tuzhilin, 2005; Yang et al., 2014), respectively.",2 Related Work,[0],[0]
"Most existing social recommendation systems are CF-based, and can be further grouped into model-based CF and neighborhood-based CF (Kantor et al., 2011; Su and Khoshgoftaar, 2009).",2 Related Work,[0],[0]
Matrix Factorization (MF) is one of the most popular models for CF.,2 Related Work,[0],[0]
"In recent MF-based social recommendation works, user-user social trust information is integrated with user-item feedback history (e.g., ratings, clicks, purchases) to improve the accuracy of traditional recommendation systems, which only factorize user-item feedback data (Ding et al., 2006; Koren, 2008; He et al., 2016).
",2 Related Work,[0],[0]
"There has been work integrating sentiment analysis and recommendation systems, which use recommendation strategies such as matrix factorization to improve the performance of sentiment analysis (Leung et al., 2006; Singh et al., 2011).",2 Related Work,[0],[0]
"These methods typically use ensemble learning (Singh et al., 2011) or probabilistic graph models (Wu and Ester, 2015).",2 Related Work,[0],[0]
"For example, Zhang et al. (2014) proposed a factor graph model to recommend opinion rating scores by using explicit product features as hidden variables.",2 Related Work,[0],[0]
"Different from the above research, we recommend user opinions.
",2 Related Work,[0],[0]
Neural Network Models.,2 Related Work,[0],[0]
"Multi-task learning has been recognised as a strength of neural network models for natural language processing (Collobert et al., 2011; Henderson et al., 2013; Zhang and Weiss, 2016; Chen et al., 2016a), where hidden feature layers are shared between different tasks that have common basis.",2 Related Work,[0],[0]
"Our work can be regarded as an instance of such multi-tasks learning via shared parameters, which has been widely used in the research community recently.
",2 Related Work,[0],[0]
"Dynamic memory network models have been applied for NLP tasks such as question answering (Sukhbaatar et al., 2015; Kumar et al., 2016), language modeling (Tran et al., 2016) and machine translation (Wang et al., 2016).",2 Related Work,[0],[0]
"There are typically used to find abstract semantic representations of texts towards certain tasks, which are consistent with our main need, namely abstract-
ing the representation of a product that is biased towards the taste of a certain user.",2 Related Work,[0],[0]
We use a variation of the memory network model for obtaining user-specific review representation.,2 Related Work,[0],[0]
"Formally, the input to our model is a tuple 〈RT , RU , RN 〉, where RT = {rT1 , rT2 , ..., rTnt} is the set of existing reviews of a target product, RU = {rU1 , rU2 , ..., rUnu} is the set of user’s history reviews, and RN = {rN1 , rN2 , ..., rNnn} is the set of the user’s neighborhood reviews.",3 Model,[0],[0]
All the reviews are sorted with temporal order.,3 Model,[0],[0]
"The output is a pair 〈YS , YR〉, where YS is a real number between 0 and 5 representing the customized rating score of the target product, and YR is a customised review.",3 Model,[0],[0]
"A characteristic of our model is that YS and YR are generated on a product that the user has not reviewed.
",3 Model,[0],[0]
"For capturing both general and personalized information, we first build a product model, a user model, and a neighborhood model, respectively, and using a memory network model to integrate these three types of information, constructing a customized product model.",3 Model,[0],[0]
"Finally, we predict a customized rating score and a review collectively using neural stacking framework.",3 Model,[0],[0]
The overall architecture of the model is shown in Figure 2.,3 Model,[0],[0]
"A review is the foundation of our model, based on which we derive representations of both a user and a target product.",3.1 Review Model,[0],[0]
"In particular, a user profile can be achieved by modeling all the reviews RU of the user, and a target product profile can be obtained by using all existing reviews RT of the product.",3.1 Review Model,[0],[0]
We use the average of word embeddings to model a review.,3.1 Review Model,[0],[0]
"Formally, given a review r = {x1, x2, ..., xm}, where m is the length of
the review, each word xk is represented with a Kdimensional embedding ewk (Mikolov et al., 2013).",3.1 Review Model,[0],[0]
We use the ∑ k(e w k )/m,3.1 Review Model,[0],[0]
for the representation of the review ed(r).,3.1 Review Model,[0],[0]
"A standard LSTM (Hochreiter and Schmidhuber, 1997) is used to learn the hidden states of an user’s reviews to build the user model.",3.2 User Model,[0],[0]
"Denoting the recurrent function at step t as LSTM(xt, ht−1), we obtain a sequence of hidden state vectors {hU1 , hU2 , ..., hUnu} recurrently by feeding {ed(rU1), ed(rU2), ..., ed(rUnu )} as inputs, where hUi = LSTM(e
d(rUi), hUi−1).",3.2 User Model,[0],[0]
"The initial state and all standard LSTM parameters are randomly initialized and tuned during training.
",3.2 User Model,[0],[0]
Not all reviews contribute equally to the representation of a user.,3.2 User Model,[0],[0]
"We use the attention mechanism (Bahdanau et al., 2014; Yang et al., 2016) to extract the reviews that are relatively more important, aggregating the representation of reviews to form a vector.",3.2 User Model,[0],[0]
"Taking the hidden state {hU1 , ...hU2 , ..., hUnu} of user model as input, the attention model outputs, a continuous vector vU ∈ Rd×1, which is computed as a weighted sum of each hidden state hUi , namely
vU = nu∑ i αihUi (1)
where nu is the hidden variable size, αi ∈",3.2 User Model,[0],[0]
"[0, 1] is the weight of hUi , and ∑ i αi = 1.
",3.2 User Model,[0],[0]
"For each piece of hidden state hUi , the scoring function is calculated by
ui = tanh(WUhUi + bU )",3.2 User Model,[0],[0]
"(2)
αi = exp(ui)∑ j exp(uj)
(3)
where WU and bU are model parameters.",3.2 User Model,[0],[0]
The attention vector vU is used to represent the user for the User Model.,3.2 User Model,[0],[0]
"We use neighborhood reviews to improve the user model, since a user may not have sufficient reviews to construct a reliable model.",3.3 Neighborhood Model,[0],[0]
"Here a neighbor refers to a user that has similar tastes to the target user (Koren, 2008; Desrosiers and Karypis, 2011).",3.3 Neighborhood Model,[0],[0]
"The same as the user model, we construct
the neighborhood model vN using the neighborhood reviews RN = {rN1 , rN2 , ..., rNnn} with an attention recurrent network.
",3.3 Neighborhood Model,[0],[0]
A key issue in building the neighborhood model is how to find neighbors of a certain user.,3.3 Neighborhood Model,[0],[0]
"In this study, we use matrix factorization (Koren, 2008) to detect neighbors, which is a standard approach for recommendation (Ding et al., 2006; Li et al., 2009; He et al., 2016).",3.3 Neighborhood Model,[0],[0]
"In particular, users’ rating scores of products are used to build a productusers matrix M ∈ Rnt×nu with nt products and nu users.",3.3 Neighborhood Model,[0],[0]
"We approximate it using three factors, specifying soft membership of products and users (Ding et al., 2006) by finding:
min F,S,T ||M − FST T || s.t.S ≥ 0, F ≥ 0, T ≥ 0
(4)
where F ∈ Rnt×K represents the posterior probability of K topic clusters for each product; S ∈ RK×K encodes the distribution of each topic k; and T ∈ RK×nu indicates the posterior probability of K topic clusters for each user.
",3.3 Neighborhood Model,[0],[0]
"As a result of matrix factorization, we directly obtain the probability of each user on each topic from the person-topic matrix T .",3.3 Neighborhood Model,[0],[0]
"To infer T , the optimization problem in Eq.4 can be solved using the following updating rule:
",3.3 Neighborhood Model,[0],[0]
"Tjk ← Tjk (M TFS)jk
(TT TMTFS)jk (5)
With the user-topic matrix T , we measure the implicit connection between two users using:
sim(i, j) = k∑
k=1
TikTjk (6)
where sim(i, j) measure the implicit connection degree between users i and j. If sim(i, j) is higher than a threshold η, we consider user j as the neighbor of user i.",3.3 Neighborhood Model,[0],[0]
"Given the representations of existing reviews {ed(rT1), ed(rT2), ..., ed(rTnt )} of the product, we use LSTM to model their temporal orders, obtaining a sequence of hidden vectors hT = {hT1 , hT2 , ..., hTnt} by recurrently feeding {ed(rT1), ed(rT2), ..., ed(rTnt} as inputs.",3.4 Product Model,[0],[0]
"The hidden state vectors hT are used to represent the product.
",3.4 Product Model,[0],[0]
Customized Product Model.,3.4 Product Model,[0],[0]
"The product model represents salient information of existing reviews in their temporal order, yet do not reflect the taste of a particular user.",3.4 Product Model,[0],[0]
"We build the customised product model to integrate user information and product information (as reflected by the product model), resulting in a single vector that represents a customised product.",3.4 Product Model,[0],[0]
From this vector we are able to synthesis both a customised review and a customised rating score.,3.4 Product Model,[0],[0]
"In particular, we use the user representation vU and the neighbour representation vN to transform the target product representation hT",3.4 Product Model,[0],[0]
=,3.4 Product Model,[0],[0]
"{hT1 , hT2 , ..., hTnt} into a customised product representation vC , which is tailored to the taste of the user.
",3.4 Product Model,[0],[0]
"A naive model of yielding vC could utilise the attention mechanism over ht, deriving a weighted sum according to user information.",3.4 Product Model,[0],[0]
"On the other hand, dynamic memory networks have been shown highly useful for deriving abstract semantic information compared with simple attention, and hence we follow Sukhbaatar et al. (2015) and Xiong et al. (2016), building a variation of DMN to iteratively find increasingly abstract representations of ht, by injecting vU and vN information.
",3.4 Product Model,[0],[0]
"The memory model consists of multiple dynamic computational layers (hops), each of which contains an attention layer and a linear layer.",3.4 Product Model,[0],[0]
"In the first computational layer (hop 1), we take the hidden variables hTi (0 ≤",3.4 Product Model,[0],[0]
"i ≤ nt) of product model as input, adaptively selecting important evidences through one attention layer using vU and vN .",3.4 Product Model,[0],[0]
"The output of the attention layer gives a linear interpolation of hT , and the result is considered as input to the next layer (hop 2).",3.4 Product Model,[0],[0]
"In the same way, we stack multiple hops and run the steps multiple times, so that more abstract representations of the target product can be derived.
",3.4 Product Model,[0],[0]
"The attention model outputs a continuous vector vC ∈ Rd×1, which is computed as a weighted sum of hTi (0 ≤",3.4 Product Model,[0],[0]
"i ≤ nt), namely
vC = nt∑ i βihTi (7)
where nt is the hidden variable size, βi ∈",3.4 Product Model,[0],[0]
"[0, 1] is the weight of hTi , and ∑ i βi = 1.",3.4 Product Model,[0],[0]
"For each piece of hidden state hTi , we use a feed forward neural network to compute its semantic relatedness with the abstract representation vC .",3.4 Product Model,[0],[0]
"The scoring func-
tion is calculated as follows at hop t:
uti = tanh(WThTi +WCv t−1 C
+WUvU +WNvN + b) (8)
βti = exp(uti)∑ j exp(u t j)
(9)
",3.4 Product Model,[0],[0]
The vector vC is used to represent the customized product model.,3.4 Product Model,[0],[0]
"At the first hop, we define V 0C =∑
i hTi/nt.",3.4 Product Model,[0],[0]
The product model hTi (0 ≤,3.4 Product Model,[0],[0]
"i ≤ nt) represents salient information of existing reviews in their temporal order, they do not reflect the taste of a particular user.",3.4 Product Model,[0],[0]
"We use the customised product model to integrate user information and product information (as reflected by the product model), resulting in a single vector that represents a customised product.",3.4 Product Model,[0],[0]
From this vector we are able to synthesis both a customised review and a customised rating score.,3.4 Product Model,[0],[0]
"The goal of customized review generation is to generate a review YR from the customized product representation vC , composed by a sequence of words yR1 , ..., yRnr .",3.5 Customized Review Generation,[0],[0]
"We use a standard LSTM decoder (Rush et al., 2015) to decompose the prediction of YR into a sequence of word-level predictions:
logP (YR|vC) =∑ j P (yRj |yR1 , ..., yRj−1 , vC) (10)
where each word yRj is predicted conditional on the previously generated yR1 , ..., yRj−1 and the customized product vector vC .",3.5 Customized Review Generation,[0],[0]
"The probability is estimated by using standard word softmax:
P (yRj |yR1 , ..., yRj−1 , vC) = softmax(hRj ) (11)
where hRj is the hidden state variable at timestamp j, which is modeled as LSTM(uj−1, hRj).",3.5 Customized Review Generation,[0],[0]
Here a LSTM is used to generate a new state hRj from the representation of the previous state hRj−1 and uj−1.,3.5 Customized Review Generation,[0],[0]
uj−1 is the concatenation of previously generated word yRj−1 and the input representation of customized model vC .,3.5 Customized Review Generation,[0],[0]
A straightforward approach to predicting the rating score of a product is to take the average of existing review scores.,3.6 Customized Rating Prediction,[0],[0]
"However, the drawback is that it cannot reflect the the variance in user tastes.",3.6 Customized Rating Prediction,[0],[0]
"In order to integrate user preferences into the rating, we instead take a user-based weighted average of existing rating scores, so that the scores of reviews that are closer to the user preference are given higher weights.",3.6 Customized Rating Prediction,[0],[0]
"However, existing ratings can be all different from a users personal rating, if the existing reviews do not come from the user’s neighbours.",3.6 Customized Rating Prediction,[0],[0]
"We thus use the customized product vector vc as a bias of the weighted average of existing rating scores.
",3.6 Customized Rating Prediction,[0],[0]
"Formally, given the rating scores s1, s2, ..., sn of existing reviews, and the the customized product representation vC , we calculate:
YS = n∑ i βi · si + µ tanh(WSvC + bS) (12)
",3.6 Customized Rating Prediction,[0],[0]
"In the left term ∑n
i βi ·si, we use attention weights βi in Eq.9 to measure the important of each rating score si.",3.6 Customized Rating Prediction,[0],[0]
"The right term tanh(WSvC + bS) is a review-based shift, weighted by µ.
Since the result of customized review generation can be helpful for rating score prediction, we use neural stacking additionally feeding the last hidden state hRn of review generation model as input for YS prediction, resulting in
YS = n∑ i αi · si+
+ µ tanh(WS(vC ⊕ hRn) + bS) (13)
where ⊕ denotes vector concatenation.",3.6 Customized Rating Prediction,[0],[0]
"For our task, there are two joint training objectives, for review scoring and review summarisation, respectively.",3.7 Training,[0],[0]
"For review scoring, the loss function is defined as:
L(Θ) = N∑
i=1
(Y ∗Si",3.7 Training,[0],[0]
"− YSi)2 + λ
2 ||Θ||2 (14)
where Y ∗Si is the predicted rating score, YSi is the rating score in the training data, Θ is the set of model parameters and λ is a parameter for L2 regularization.
",3.7 Training,[0],[0]
"For customized review generation, loss is defined by maximizing the log probability of Eq.10 (Sutskever et al., 2014; Rush et al., 2015).",3.7 Training,[0],[0]
"The two loss functions for score and review prediction share the representation vectors under vC , hence forming multi-task learning.
",3.7 Training,[0],[0]
"Standard back propagation is performed to optimize parameters, where gradients also propagate from the scoring objective to the review generation objective due to neural stacking (Eq.13).",3.7 Training,[0],[0]
"We apply online training, where model parameters are optimized by using AdaGrad (Duchi et al., 2011).",3.7 Training,[0],[0]
"Word embeddings are trained using the Skip-gram algorithm (Mikolov et al., 2013)1.",3.7 Training,[0],[0]
"Our data are collected from the yelp academic dataset2, provided by Yelp.com, a popular restaurant review website.",4.1 Experimental Settings,[0],[0]
"The data set contains three types of objects: business, user, and review, where business objects contain basic information about local businesses (i.e. restaurants), review objects contain review texts and star rating, and user objects contain aggregate information about a single user across all of Yelp.",4.1 Experimental Settings,[0],[0]
"Table 1 illustrates the general statistics of the dataset.
",4.1 Experimental Settings,[0],[0]
"For evaluating our model, we choose 4,755 user-product pairs from the dataset.",4.1 Experimental Settings,[0],[0]
"The userproduct pairs are extracted by following criterions: for each selected user-product pair, the user should have written 10 reviews at least, and the product should contain 100 reviews at least.",4.1 Experimental Settings,[0],[0]
"In addition, the gold-standard review that the user write for the corresponding product should contain 10 helpful hits at least.",4.1 Experimental Settings,[0],[0]
We did not try alternative data selection rules.,4.1 Experimental Settings,[0],[0]
"We will give the detail in our draft.
",4.1 Experimental Settings,[0],[0]
"For each pair, the existing reviews of the target service (restaurant) are used for the product model.",4.1 Experimental Settings,[0],[0]
"The rating score given by each user to the target service is considered as the gold customized rating score, and the review of the target service given by
1 https://code.google.com/p/word2vec/ 2https://www.yelp.com/academic dataset
each user is used as the gold-standard customized review for the user.",4.1 Experimental Settings,[0],[0]
The remaining reviews of each user are used for training the user model.,4.1 Experimental Settings,[0],[0]
"We use 3,000 user-product pairs to train the model, 1,000 pairs as testing data, and remaining data for development.
",4.1 Experimental Settings,[0],[0]
"We use the ROUGE-1.5.5 (Lin, 2004) toolkit for evaluating the performance of customized review generation, and report unigram overlap (ROUGE-1) as a means of assessing informativeness.",4.1 Experimental Settings,[0],[0]
"Mean Square Error (MSE) (Wan, 2013; Tang et al., 2015) is used as the evaluation metric for measuring the performance of customized rating score prediction.",4.1 Experimental Settings,[0],[0]
MSE penalizes more severe errors more heavily.,4.1 Experimental Settings,[0],[0]
"There are several important hyper-parameters in our models, and we tune their values using the development dataset.",4.2 Hyper-parameters,[0],[0]
We set the regularization weight λ = 10−8 and the initial learning rate to 0.01.,4.2 Hyper-parameters,[0],[0]
"We set the size of word vectors to 128, the size of hidden vectors in LSTM to 128.",4.2 Hyper-parameters,[0],[0]
"In order to avoid over-fitting, dropout (Hinton et al., 2012) is used for word embedding with a ratio of 0.2.",4.2 Hyper-parameters,[0],[0]
The neighbor similarity threshold η is set to 0.25.,4.2 Hyper-parameters,[0],[0]
"Effects of various configurations of our model, are shown on Table 2, where Joint is the full model of this paper, -user ablates the user model, -neighbor ablates the neighbor model, -rating is a single-task model that generates a review without the rating score, and -generation yields only the rating.
",4.3.1 Ablation Test,[0],[0]
"By comparing “Joint” and “-user,-neighbor”, we can find that customized information have significant influence on both the rating and review generation results (p − value < 0.01 using ttest).",4.3.1 Ablation Test,[0],[0]
"In addition, comparison between “-Joint” and “-user”, and between “-user” and “-user, - neighbor” shows that both the user information and the neighbour user information of the user are effective for improving the results.",4.3.1 Ablation Test,[0],[0]
"A users neighbours can indeed alleviate scarcity of user reviews.
",4.3.1 Ablation Test,[0],[0]
"Finally, comparison between “Joint” and “- generation”, and between “Joint” and “-rating” shows that multi-task learning by parameter sharing is highly useful.",4.3.1 Ablation Test,[0],[0]
We show the influence of hops of memory network for customized review generation on Figure 3.,4.3.2 Influence of Hops,[0],[0]
"When hop = 0, the model considers only the general product reviews (−user,−neighbor).",4.3.2 Influence of Hops,[0],[0]
"When hop ≥ 1, customized product information is leveraged.",4.3.2 Influence of Hops,[0],[0]
"From the figure we can find that, when hop = 3, the performance is the best.",4.3.2 Influence of Hops,[0],[0]
It indicates that multiple hops can capture more abstract evidences from external memory to improve the performance.,4.3.2 Influence of Hops,[0],[0]
"However, too many hops leads to over-fitting, thereby harms the performance.",4.3.2 Influence of Hops,[0],[0]
"As a result, we choose 3 as the number of hops in our final test.",4.3.2 Influence of Hops,[0],[0]
We show the influence of the bias weight parameter µ for rating prediction in Figure 4.,4.3.3 Influence of µ,[0],[0]
"With µ being 0, the model uses the weighted sum of existing reviews to score the product.",4.3.3 Influence of µ,[0],[0]
"When µ is very large, the system tends to use only the customized product representation vc to score the product, hence ignoring existing review scores, which are a useful source of information.",4.3.3 Influence of µ,[0],[0]
"Our results show that when µ is 1, the performance is optimal, thus indicating both existing review scores and review contents are equally useful.",4.3.3 Influence of µ,[0],[0]
"We show the final results for opinion recommendation, comparing our proposed model with the
HOP Bais 0 1.342 0 1.102 1 1.102 1 0.904 2 1.046 2 1.067 3 0.904 3 1.136 4 0.987 4 1.206 5 1.102 5 1.227 6 1.045 7 1.126 8 1.172 9 1.152 10 1.167
0.90
0.95
1.00
1.05
1.10
1.15
1.20
1.25
0 1 2 3 4 5
M S
E
μ
0.90
0.95
1.00
1.05
1.10
1.15
1.20
1.25
1.30
1.35
1.40
0 1 2 3 4 5 6 7 8 9 10
M S
E
hop
Figure 4: Influence of bias score.
",4.4 Final Results,[0],[0]
"following state-of-the-art baseline systems:
• RS-Average-Yelp is the widely-adopted baseline (e.g., by Yelp.com), using the averaged review scores as the final score.
",4.4 Final Results,[0],[0]
"• RS-Linear estimates the rating score that a user would give by sui = sall + su + si (Ricci et al., 2011), where su and si are the the training deviations of rating score of the user u and the product i, respectively.
",4.4 Final Results,[0],[0]
"• RS-Item applies kNN to estimate the rating score (Sarwar et al., 2001).",4.4 Final Results,[0],[0]
"We choose the cosine similarity between vc to measure the distance between product.
",4.4 Final Results,[0],[0]
"• RS-MF is a state-of-the-art recommendation model, which uses matrix factorisation to predict rating score (Ding et al., 2006; Li et al., 2009; He et al., 2016).
",4.4 Final Results,[0],[0]
"• Sum-Opinosis uses a graph-based framework to generate abstractive summarisation given redundant opinions (Ganesan et al., 2010).
",4.4 Final Results,[0],[0]
"• Sum-LSTM-Att is a state-of-the-art neural abstractive summariser, which uses an attentional neural model to consolidate information from multiple text sources, generating summaries using LSTM decoding (Rush et al., 2015; Wang and Ling, 2016).
",4.4 Final Results,[0],[0]
"Being non-opinion recommendation methods, all the baselines are single-task models, without considering rating and summarisation prediction jointly.",4.4 Final Results,[0],[0]
The results are shown in Table 3.,4.4 Final Results,[0],[0]
Our model (“ Joint”) significantly outperforms both “RS-Average-Yelp” and “RS-Linear” (p − value < 0.01 using t-test).,4.4 Final Results,[0],[0]
"Note that, our proposed rating recommendation for the user are significantly closer individual real user rating compared with Yelp’s rating.
",4.4 Final Results,[0],[0]
"Our proposed model also significantly outperforms state-of-the-art recommendation systems (RS-Item and RS-MF) (p− value < 0.01 using ttest), indicating that textual information are a useful addition to the rating scores themselves for recommending a product.
",4.4 Final Results,[0],[0]
"Finally, comparison between our proposed model and state-of-the-art summarisation techniques (Sum-Opinosis and Sum-LSTM-Att) shows the advantage of leveraging user information to enhance customised review generation, and also the strength of joint learning.",4.4 Final Results,[0],[0]
Table 4 shows example outputs of rating scores and reviews.,4.5 Example Output,[0],[0]
"Ref. is the rating score and review written by user her/himself, and Base is the baseline model, that generates the rating score by RS-MF, and review by Sum-LSTM-Att.",4.5 Example Output,[0],[0]
"From these examples, we can find that, both rating score and review which generated by the proposed Joint model is closer to the real user.",4.5 Example Output,[0],[0]
"In particular, in the first example, the baseline system correctly identifies the main both price and quality information, which the target user wrote in the review, yet the baseline model did not yield comments about the price based on reviews of other users.",4.5 Example Output,[0],[0]
"Associating reviews and ratings closely, the joint model gives a rating score that is much closer to the real user score compared to the score given by the recommendation model MF.",4.5 Example Output,[0],[0]
"In addition, we can also find some habits of certain users from their customized reviews, for example, Mexican food, cheap and clean restaurant.",4.5 Example Output,[0],[0]
"We proposed a novel task called opinion recommendation, which is to generate the review and rating score that a certain user would give to an unreviewed product or service.",5 Conclusion,[0],[0]
"In particular, a
deep memory network was utilized to find the association between the user and the product, jointly yielding the rating score and customised review.",5 Conclusion,[0],[0]
Results show that our methods are better results compared to several pipelines baselines using state-of-the-art sentiment rating and summarisation systems.,5 Conclusion,[0],[0]
Review scores given by the opinion recordation system are closer to real user review scores compared to the review scores which Yelp assigns to target products.,5 Conclusion,[0],[0]
The corresponding author is Yue Zhang.,Acknowledgments,[0],[0]
We are grateful for the help of Xuanyi Li for his initial exploration.,Acknowledgments,[0],[0]
"We thank our anonymous reviewers for their constructive comments, which helped to improve the paper.",Acknowledgments,[0],[0]
"This work is supported by the Temasek Lab grant IGDST1403012 at Singapore University of Technology and Design, and supported by the National Natural Science Foundation of China (No.61402314).",Acknowledgments,[0],[0]
"We present opinion recommendation, a novel task of jointly generating a review with a rating score that a certain user would give to a certain product which is unreviewed by the user, given existing reviews to the product by other users, and the reviews that the user has given to other products.",abstractText,[0],[0]
A characteristic of opinion recommendation is the reliance of multiple data sources for multi-task joint learning.,abstractText,[0],[0]
"We use a single neural network to model users and products, generating customised product representations using a deep memory network, from which customised ratings and reviews are constructed jointly.",abstractText,[0],[0]
Results show that our opinion recommendation system gives ratings that are closer to real user ratings on Yelp.com data compared with Yelp’s own ratings.,abstractText,[0],[0]
our methods give better results compared to several pipelines baselines.,abstractText,[0],[0]
Opinion Recommendation Using A Neural Model,title,[0],[0]
"√ κl(1 +
τ√ γ ) ln(1/ε)), where κl is the condition number of the local functions and γ is the (normalized) eigengap of the gossip matrix used for communication between nodes. We then verify the efficiency of MSDA against state-of-the-art methods for two problems: least-squares regression and classification by logistic regression.",text,[0],[0]
"Given the numerous applications of distributed optimization in machine learning, many algorithms have recently emerged, that allow the minimization of objective functions f defined as the average 1 n ∑n i=1 fi of functions fi which are respectively accessible by separate nodes in a network [1, 2, 3, 4].",1 Introduction,[0],[0]
"These algorithms typically alternate local incremental improvement steps (such as gradient steps) with communication steps between nodes in the network, and come with a variety of convergence rates (see for example [5, 4, 6, 7]).
",1 Introduction,[0],[0]
Two main regimes have been looked at: (a) centralized where communications are precisely scheduled and (b) decentralized where communications may not exhibit a precise schedule.,1 Introduction,[1.0],['Two main regimes have been looked at: (a) centralized where communications are precisely scheduled and (b) decentralized where communications may not exhibit a precise schedule.']
"In this paper, we consider these two regimes for objective functions which are smooth and strongly-convex and for which algorithms are linearly (exponentially) convergent.",1 Introduction,[0],[0]
"The main contribution of this paper
ar X
iv :1
70 2.
08 70
4v 2
[ m
at h.
is to propose new and matching upper and lower bounds of complexity for this class of distributed problems.
",1 Introduction,[0],[0]
The optimal complexity bounds depend on natural quantities in optimization and network theory.,1 Introduction,[0],[0]
"Indeed, (a) for a single machine the optimal number of gradient steps to optimize a function is proportional to the square root of the condition number [8], and (b) for mean estimation, the optimal number of communication steps is proportional to the diameter of the network in centralized problems or to the square root of the eigengap of the Laplacian matrix in decentralized problems [9].",1 Introduction,[0],[0]
"As shown in Section 3, our lower complexity bounds happen to be combinations of the two contributions above.
",1 Introduction,[0],[0]
These lower complexity bounds are attained by two separate algorithms.,1 Introduction,[0],[0]
"In the centralized case, the trivial distribution of Nesterov’s accelerated gradient attains this rate, while in the decentralized case, as shown in Section 4, the rate is achieved by a dual algorithm.",1 Introduction,[0],[0]
"We compare favorably our new optimal algorithms to existing work in Section 5.
",1 Introduction,[0],[0]
Related work.,1 Introduction,[0],[0]
"Decentralized optimization has been extensively studied and early methods such as decentralized gradient descent [1, 10] or decentralized dual averaging [3] exhibited sublinear convergence rates.",1 Introduction,[0],[0]
"More recently, a number of methods with provable linear convergence rates were developed, including EXTRA [4, 11], augmented Lagrangians [6], and more recent approaches [7].",1 Introduction,[0],[0]
The most popular of such approaches is the distributed alternating direction method of multipliers (D-ADMM),1 Introduction,[0],[0]
"[2, 12, 5] and has led to a large number of variations and extensions.",1 Introduction,[0],[0]
"In a different direction, second order methods were also investigated [13, 14].",1 Introduction,[0],[0]
"However, to the best of our knowledge, the field still lacks a coherent theoretical understanding of the optimal convergence rates and its dependency on the characteristics of the communication network.",1 Introduction,[0],[0]
"In several related fields, complexity lower bounds were recently investigated, including the sequential optimization of a sum of functions [15, 16], distributed optimization in flat (i.e. totally connected) networks [17, 18], or distributed stochastic optimization [19].",1 Introduction,[0],[0]
"Let G = (V, E) be a connected simple (i.e. undirected) graph of n computing units and diameter ∆, each having access to a function fi(θ) over θ ∈ Rd.",2.1 Optimization problem,[0],[0]
"We consider minimizing the average of the local functions
min θ∈Rd
f̄(θ) = 1
n n∑ i=1 fi(θ) (1)
in a distributed setting.",2.1 Optimization problem,[0],[0]
"More specifically, we assume that:
1.",2.1 Optimization problem,[0],[0]
"Each computing unit can compute first-order characteristics, such as the gradient of its own function or its Fenchel conjugate.",2.1 Optimization problem,[0],[0]
"By renormalization of the time axis, and without loss of generality, we assume that this computation is performed in one unit of time.
",2.1 Optimization problem,[0],[0]
2.,2.1 Optimization problem,[0],[0]
Each computing unit can communicate values (i.e. vectors in Rd) to its neighbors.,2.1 Optimization problem,[0],[0]
This communication requires a time τ,2.1 Optimization problem,[0],[0]
"(which may be smaller or greater than 1).
",2.1 Optimization problem,[0],[0]
"These actions may be performed asynchronously and in parallel, and each node i possesses a local version of the parameter, which we refer to as θi.",2.1 Optimization problem,[0],[0]
"Moreover, we assume that each function fi is α-strongly convex and β-smooth, and we denote by κl = βα ≥ 1 the local condition number.",2.1 Optimization problem,[0],[0]
"We also denote by αg , βg and κg , respectively, the strong convexity, smoothness and condition number of the average (global) function f̄ .",2.1 Optimization problem,[1.0],"['We also denote by αg , βg and κg , respectively, the strong convexity, smoothness and condition number of the average (global) function f̄ .']"
"Note that we always have κg ≤ κl, while the opposite inequality is, in general, not true (take for example f1(θ) = 1{θ < 0}θ2 and f2(θ) = 1{θ > 0}θ2 for which κl = +∞ and κg = 1).",2.1 Optimization problem,[0],[0]
"However, the two quantities are close (resp. equal) when the local functions are similar (resp. equal) to one another.",2.1 Optimization problem,[0],[0]
A large body of literature considers a decentralized approach to distributed optimization based on the gossip algorithm,2.2 Decentralized communication,[0],[0]
"[9, 1, 3, 12].",2.2 Decentralized communication,[0],[0]
"In such a case, communication is represented as a matrix multiplication with a matrix W verifying the following constraints:
1.",2.2 Decentralized communication,[0],[0]
"W is an n× n symmetric matrix,
2.",2.2 Decentralized communication,[0],[0]
"W is positive semi-definite,
3.",2.2 Decentralized communication,[0],[0]
The kernel of W is the set of constant vectors: Ker(W ),2.2 Decentralized communication,[0],[0]
"= Span(1), where 1 = (1, ..., 1)>,
4.",2.2 Decentralized communication,[0],[0]
W is defined on the edges of the network:,2.2 Decentralized communication,[0],[0]
Wij 6= 0,2.2 Decentralized communication,[0],[0]
"only if i = j or (i, j) ∈ E .
",2.2 Decentralized communication,[0],[0]
The third condition will ensure that the gossip step converges to the average of all the vectors shared between the nodes.,2.2 Decentralized communication,[0],[0]
"We will denote the matrix W as the gossip matrix, since each communication step will be represented using it.",2.2 Decentralized communication,[0],[0]
Note that a simple choice for the gossip matrix is the Laplacian matrix L = D,2.2 Decentralized communication,[0],[0]
"− A, where A is the adjacency matrix of the network and D = diag (∑ iAij ) .",2.2 Decentralized communication,[0],[0]
"However, in the presence of large degree nodes, weighted Laplacian matrices are usually a better choice, and the problem of optimizing these weights is known as the fastest distributed consensus averaging problem and is investigated by [20, 21].
",2.2 Decentralized communication,[0],[0]
We will denote by λ1(W ) ≥ · · · ≥ λn(W ),2.2 Decentralized communication,[0],[0]
= 0,2.2 Decentralized communication,[0],[0]
"the spectrum of the gossip matrix W , and its (normalized) eigengap the ratio γ(W ) = λn−1(W )/λ1(W ) between the second smallest and the largest eigenvalue.",2.2 Decentralized communication,[0],[0]
"Equivalently, this is the inverse of the condition number of W projected on the space orthogonal to the constant vector 1.",2.2 Decentralized communication,[0],[0]
This quantity will be the main parameter describing the connectivity of the communication network in Section 3.3 and Section 4.,2.2 Decentralized communication,[0],[0]
"In this section, we prove oracle complexity lower bounds for distributed optimization in two settings: strongly convex and smooth functions for centralized (i.e. master/slave) and decentralized algorithms based on a gossip matrix W .
",3 Optimal convergence rates,[1.000000010975326],"['In this section, we prove oracle complexity lower bounds for distributed optimization in two settings: strongly convex and smooth functions for centralized (i.e. master/slave) and decentralized algorithms based on a gossip matrix W .']"
"In the first setting, we show that distributing accelerated gradient descent matches the optimal convergence rate, while, in the second setting, the algorithm proposed in Section 4 is shown to be optimal.",3 Optimal convergence rates,[0],[0]
"Note that we will use the notation g(ε) = Ω(f(ε)) for ∃C > 0 s.t. ∀ε > 0, g(ε) ≥ Cf(ε), and will, for simplicity, omit the additive terms that do not depend on the precision ε in Corollary 1 and Corollary 2.",3 Optimal convergence rates,[0],[0]
The lower bounds provided hereafter depend on a new notion of black-box optimization procedures for the problem in Eq.,3.1 Black-box optimization procedures,[0],[0]
"(1), where we consider distributed algorithms verifying the following constraints:
1.",3.1 Black-box optimization procedures,[0],[0]
"Local memory: each node i can store past values in a (finite) internal memoryMi,t ⊂ Rd at time t ≥ 0.",3.1 Black-box optimization procedures,[0],[0]
"These values can be accessed and used at time t by the algorithm run by node i, and are updated either by local computation or by communication (defined below), that is, for all i ∈ {1, ..., n},
Mi,t ⊂Mcompi,t ∪M comm i,t .",3.1 Black-box optimization procedures,[0],[0]
"(2)
2.",3.1 Black-box optimization procedures,[0],[0]
"Local computation: each node i can, at time t, compute the gradient of its local function ∇fi(θ) or its Fenchel conjugate ∇f∗i (θ) for a value θ ∈ Mi,t in the node’s internal memory, that is, for all i ∈ {1, ..., n},
Mcompi,t = Span ({θ,∇fi(θ),∇f ∗",3.1 Black-box optimization procedures,[0],[0]
"i (θ) : θ ∈Mi,t−1}) .",3.1 Black-box optimization procedures,[0],[0]
"(3)
3.",3.1 Black-box optimization procedures,[0],[0]
"Local communication: each node i can, at time t, share a value to all or part of its neighbors, that is, for all i ∈ {1, ..., n},
Mcommi,t = Span ( ⋃
(i,j)∈E
Mj,t−τ ) .",3.1 Black-box optimization procedures,[0],[0]
"(4)
4.",3.1 Black-box optimization procedures,[0],[0]
"Output value: each node i must, at time t, specify one vector in its memory as local output of the algorithm, that is, for all i ∈ {1, ..., n},
θi,t ∈Mi,t. (5)
Hence, a black-box procedure will return n output values—one for each node of the network— and our analysis will focus on ensuring that all local output values are converging to the optimal parameter of Eq.",3.1 Black-box optimization procedures,[0],[0]
(1).,3.1 Black-box optimization procedures,[0],[0]
"Moreover, we will say that a black-box procedure uses a gossip matrix W if the local communication is achieved by multiplication of a vector withW .",3.1 Black-box optimization procedures,[0],[0]
"For simplicity, we assume that all nodes start with the simple internal memoryMi,0 = {0}.",3.1 Black-box optimization procedures,[0],[0]
Note that communications and local computations may be performed in parallel and asynchronously.,3.1 Black-box optimization procedures,[0],[0]
"In this section, we show that, for any black-box optimization procedure, at least Ω(√κg ln(1/ε)) gradient steps and Ω(∆√κg ln(1/ε))",3.2 Centralized algorithms,[0],[0]
"communication steps are necessary to achieve a precision ε > 0, where κg is the global condition number and ∆ is the diameter of the network.",3.2 Centralized algorithms,[0],[0]
"These lower bounds extend the communication complexity lower bounds for totally connected communication networks of [18], and are natural since at least Ω(√κg ln(1/ε)) steps are necessary to solve a strongly convex and smooth problem up to a fixed precision, and at least ∆ communication steps are required to transmit a message between any given pair of nodes.
",3.2 Centralized algorithms,[0],[0]
"In order to simplify the proofs of the following theorems, and following the approach of [22], we will consider the limiting situation d→ +∞. More specifically, we now assume that we are working in `2 = {θ = (θk)k∈N : ∑ k θ 2 k",3.2 Centralized algorithms,[0],[0]
<,3.2 Centralized algorithms,[0],[0]
"+∞} rather than Rd.
Theorem 1.",3.2 Centralized algorithms,[0],[0]
Let G be a graph of diameter ∆,3.2 Centralized algorithms,[0],[0]
"> 0 and size n > 0, and βg ≥ αg >",3.2 Centralized algorithms,[0],[0]
0.,3.2 Centralized algorithms,[0],[0]
"There exists n functions fi : `2 → R such that f̄ is αg strongly convex and βg smooth, and for any t ≥ 0 and any black-box procedure one has, for all i ∈ {1, ..., n},
f̄(θi,t)− f̄(θ∗) ≥ αg 2
( 1− 4√
κg
)1+ t1+∆τ ‖θi,0",3.2 Centralized algorithms,[0.9565653471229024],"['There exists a gossip matrix W of eigengap γ(W ) = γ, and α-strongly convex and β-smooth functions fi : `2 → R such that, for any t ≥ 0 and any black-box procedure using W one has, for all i ∈ {1, ..., n}, f̄(θi,t)− f̄(θ∗) ≥ 3α 2 ( 1− 16√ κl )1+ t 1+ τ 5 √ γ ‖θi,0 − θ∗‖2, (8) where κl = β/α is the local condition number.']"
"− θ∗‖2, (6)
where κg = βg/αg .
",3.2 Centralized algorithms,[0],[0]
"The proof of Theorem 1 relies on splitting the function used by Nesterov to prove oracle complexities for strongly convex and smooth optimization [8, 22] on two nodes at distance ∆. One can show that most dimensions of the parameters θi,t will remain zero, and local gradient computations may only increase the number of non-zero dimensions by one.",3.2 Centralized algorithms,[0],[0]
"Finally, at least ∆ communication rounds are necessary in-between every gradient computation, in order to share information between the two nodes.",3.2 Centralized algorithms,[0],[0]
The detailed proof is available as supplementary material.,3.2 Centralized algorithms,[0],[0]
Corollary 1.,3.2 Centralized algorithms,[0],[0]
"For any graph of diameter ∆ and any black-box procedure, there exists functions fi such that the time to reach a precision ε",3.2 Centralized algorithms,[0],[0]
"> 0 is lower bounded by
Ω ( √ κg ( 1 + ∆τ )",3.2 Centralized algorithms,[0],[0]
"ln ( 1
ε
)) , (7)
",3.2 Centralized algorithms,[0],[0]
This optimal convergence rate is achieved by distributing Nesterov’s accelerated gradient descent on the global function.,3.2 Centralized algorithms,[0],[0]
"Computing the gradient of f̄ is performed by sending all the local gradients ∇fi to a single node (denoted as master node) in ∆ communication steps (which may involve several simultaneous messages), and then returning the new parameter θt+1 to every node in the network (which requires another ∆ communication steps).",3.2 Centralized algorithms,[0],[0]
"In practice, summing the gradients can be distributed by computing a spanning tree (with the root as master node), and asking for each node to perform the sum of its children’s gradients before sending it to its parent.",3.2 Centralized algorithms,[0],[0]
"Standard methods as described by [23] can be used for performing this parallelization of gradient computations.
",3.2 Centralized algorithms,[0],[0]
"This algorithm has three limitations: first, the algorithm is not robust to machine failures, and the central role played by the master node also means that a failure of this particular machine may completely freeze the procedure.",3.2 Centralized algorithms,[0],[0]
"Second, and more generally, the algorithm requires precomputing a spanning tree, and is thus not suited to time-varying graphs, in which the connectivity between the nodes may change through time (e.g. in peer-to-peer networks).",3.2 Centralized algorithms,[0],[0]
"Finally, the algorithm requires every node to complete its gradient computation before aggregating them on the master node, and the efficiency of the algorithm thus depends on the slowest of all machines.",3.2 Centralized algorithms,[0],[0]
"Hence, in the presence of non-uniform latency of the local computations, or the slow down of a specific machine due to a hardware failure, the algorithm will suffer a significant drop in performance.",3.2 Centralized algorithms,[0],[0]
The gossip algorithm [9] is a standard method for averaging values across a network when its connectivity may vary through time.,3.3 Decentralized algorithms,[0],[0]
"This approach was shown to be robust against machine failures, non-uniform latencies and asynchronous or time-varying graphs, and a large body of literature extended this algorithm to distributed optimization [1, 3, 12, 4, 6, 7, 13].
",3.3 Decentralized algorithms,[0],[0]
"The convergence analysis of decentralized algorithms usually relies on the spectrum of the gossip matrix W used for communicating values in the network, and more specifically on the ratio between the second smallest and the largest eigenvalue of W , denoted γ.",3.3 Decentralized algorithms,[0],[0]
"In this section, we show that, with respect to this quantity and κl, reaching a precision ε requires at least Ω( √ κl ln(1/ε)) gradient steps
and Ω (√
κl γ ln(1/ε)
) communication steps, by exhibiting a gossip matrix such that a corresponding
lower bound exists.",3.3 Decentralized algorithms,[0],[0]
Theorem 2.,3.3 Decentralized algorithms,[0],[0]
"Let α, β > 0 and γ ∈ (0, 1].",3.3 Decentralized algorithms,[0],[0]
There exists a gossip matrix W of eigengap γ(W ) =,3.3 Decentralized algorithms,[0],[0]
"γ, and α-strongly convex and β-smooth functions fi : `2 → R such that, for any t ≥ 0 and any black-box procedure using W one has, for all i ∈ {1, ..., n},
f̄(θi,t)− f̄(θ∗) ≥ 3α
2
( 1− 16√
κl
)1+ t 1+ τ
5 √ γ ‖θi,0 − θ∗‖2, (8)
where κl = β/α is the local condition number.
",3.3 Decentralized algorithms,[0],[0]
"The proof of Theorem 2 relies on the same technique as that of Theorem 1, except that we now split the two functions on a subset of a linear graph.",3.3 Decentralized algorithms,[0],[0]
These networks have the appreciable property that ∆,3.3 Decentralized algorithms,[0],[0]
"≈ 1/√γ, and we can thus use a slightly extended version of Theorem 1 to derive the desired result.",3.3 Decentralized algorithms,[0],[0]
The complete proof is available as supplementary material.,3.3 Decentralized algorithms,[0],[0]
Corollary 2.,3.3 Decentralized algorithms,[0],[0]
"For any γ > 0, there exists a gossip matrix W of eigengap γ and α-strongly convex, β-smooth functions such that, with κl = β/α, for any black-box procedure using W the time to reach a precision ε",3.3 Decentralized algorithms,[0],[0]
"> 0 is lower bounded by
Ω ( √ κl ( 1 +
τ √ γ
)",3.3 Decentralized algorithms,[0],[0]
"ln ( 1
ε
)) .",3.3 Decentralized algorithms,[0],[0]
"(9)
We will see in the next section that this lower bound is met for a novel decentralized algorithm called multi-step dual accelerated (MSDA) and based on the dual formulation of the optimization problem.",3.3 Decentralized algorithms,[0],[0]
"Note that these results provide optimal convergence rates with respect to κl and γ, but do not imply that γ is the right quantity to consider on general graphs.",3.3 Decentralized algorithms,[0],[0]
"The quantity 1/ √ γ may indeed be very large compared to ∆, for example for star networks, for which ∆ = 2 and 1/ √ γ = √ n.",3.3 Decentralized algorithms,[0],[0]
"However, on many simple networks, the diameter ∆ and the eigengap of the Laplacian matrix are tightly connected, and ∆",3.3 Decentralized algorithms,[0],[0]
≈ 1/√γ.,3.3 Decentralized algorithms,[0],[0]
"For example, for linear graphs, ∆ = n− 1 and 1/√γ ≈ 2n/π, for totally connected networks, ∆ = 1 and 1/ √ γ = 1, and for regular networks, 1/ √ γ ≥ ∆
2 √
2 ln2 n
[24].",3.3 Decentralized algorithms,[0.963856753287985],"['For example, for linear graphs, ∆ = n − 1 and 1/√γ ≈ 2n/π, for totally connected networks, ∆ = 1 and 1/ √ γ = 1, and for regular networks, 1/ √ γ ≥ ∆ 2 √ 2 ln2 n (Alon & Milman, 1985).']"
"Finally, note that the case of totally connected networks corresponds to a previous complexity lower bound on communications proven by [18], and is equivalent to our result for centralized algorithms with ∆ = 1.",3.3 Decentralized algorithms,[0],[0]
"In this section, we present a simple framework for solving the optimization problem in Eq.",4 Optimal decentralized algorithms,[0],[0]
"(1) in a decentralized setting, from which we will derive several variants, including a synchronized algorithm whose convergence rate matches the lower bound in Corollary 2 .",4 Optimal decentralized algorithms,[1.0],"['(1) in a decentralized setting, from which we will derive several variants, including a synchronized algorithm whose convergence rate matches the lower bound in Corollary 2.']"
"Note that the naive approach of distributing each (accelerated) gradient step by gossiping does not lead to a linear convergence rate, as the number of gossip steps has to increase with the number of iterations to ensure the linear rate is preserved.",4 Optimal decentralized algorithms,[0],[0]
"We begin with the simplest form of the algorithm, before extending it to more advanced scenarios.
",4 Optimal decentralized algorithms,[0],[0]
"Algorithm 1 Single-Step Dual Accelerated method Input: number of iterations T > 0, gossip matrix W ∈ Rn×n, η = αλ1(W ) , µ = √ κl− √ γ√ κl+",4 Optimal decentralized algorithms,[0.9508492184412847],"[', θn) and W is a gossip matrix verifying the assumptions described Algorithm 1 Single-Step Dual Accelerated method Input: number of iterations T > 0, gossip matrix W ∈ Rn×n, η = αλ1(W ) , µ = √ κl− √ γ√ κl+ √ γ Output: θi,T , for i = 1, ..., n 1: x0 = 0, y0 = 0 2: for t = 0 to T − 1 do 3: θi,t = ∇f∗i (xi,t), for all i = 1, ..., n 4: yt+1 = xt − ηΘtW 5: xt+1 = (1 + µ)yt+1 − µyt 6: end for in Section 2.']"
"√ γ Output: θi,T , for i = 1, ..., n 1: x0 = 0, y0 = 0 2: for t = 0 to T − 1 do 3: θi,t = ∇f∗i",4 Optimal decentralized algorithms,[0],[0]
"(xi,t), for all i = 1, ..., n 4: yt+1 = xt",4 Optimal decentralized algorithms,[0],[0]
− ηΘtW 5: xt+1 = (1 + µ)yt+1 − µyt 6: end for,4 Optimal decentralized algorithms,[0],[0]
A standard approach for solving Eq.,4.1 Single-Step Dual Accelerated method,[0],[0]
"(1) (see [2, 6]) consists in rewriting the optimization problem as
min θ∈Rd f̄(θ) = min θ1=···=θn
1
n n∑ i=1 fi(θi).",4.1 Single-Step Dual Accelerated method,[0],[0]
"(10)
Furthermore, the equality constraint θ1 = · · · = θn is equivalent to Θ √ W = 0, where Θ = (θ1, . . .",4.1 Single-Step Dual Accelerated method,[0],[0]
", θn) and W is a gossip matrix verifying the assumptions described in Section 2.",4.1 Single-Step Dual Accelerated method,[0],[0]
"Note that, since W is positive semi-definite, √ W exists and is defined as √ W = V >Σ1/2V , where W = V >ΣV is the singular value decomposition of W .",4.1 Single-Step Dual Accelerated method,[0],[0]
"The equality Θ √ W = 0 implies that each row of Θ is constant (since Ker( √ W ) = Span(1)), and is thus equivalent to θ1 = · · · = θn.",4.1 Single-Step Dual Accelerated method,[0],[0]
"This leads to the following primal version of the optimization problem:
min Θ∈Rd×n : Θ √ W=0 F (Θ), (11)
where F (Θ) =",4.1 Single-Step Dual Accelerated method,[0],[0]
∑n i=1 fi(θi).,4.1 Single-Step Dual Accelerated method,[0],[0]
Since Eq.,4.1 Single-Step Dual Accelerated method,[0],[0]
"(11) is a convex problem, it is equivalent to its dual optimization problem: max
λ∈Rd×n −F ∗(λ
√ W ), (12)
where F ∗(y) = supx∈Rd×n〈y, x〉 − F (x) is the Fenchel conjugate of F , and 〈y, x〉 = tr(y>x) is the standard scalar product between matrices.
",4.1 Single-Step Dual Accelerated method,[0],[0]
The optimization problem in Eq.,4.1 Single-Step Dual Accelerated method,[0],[0]
"(12) is unconstrained and convex, and can thus be solved using a variety of convex optimization techniques.",4.1 Single-Step Dual Accelerated method,[0],[0]
The proposed single-step dual accelerated (SSDA) algorithm described in Alg.,4.1 Single-Step Dual Accelerated method,[0],[0]
"(1) uses Nesterov’s accelerated gradient descent, and can be thought of as an accelerated version of the distributed augmented Lagrangian method of [6] for ρ = 0.",4.1 Single-Step Dual Accelerated method,[0],[0]
The algorithm is derived by noting that a gradient step of size η > 0 for Eq.,4.1 Single-Step Dual Accelerated method,[1.0],['The algorithm is derived by noting that a gradient step of size η > 0 for Eq.']
"(12) is
λt+1 =",4.1 Single-Step Dual Accelerated method,[0],[0]
λt − η∇F ∗(λt √ W ),4.1 Single-Step Dual Accelerated method,[0],[0]
"√ W, (13)
and the change of variable",4.1 Single-Step Dual Accelerated method,[0],[0]
yt =,4.1 Single-Step Dual Accelerated method,[0],[0]
"λt √ W leads to
yt+1 =",4.1 Single-Step Dual Accelerated method,[0],[0]
yt,4.1 Single-Step Dual Accelerated method,[0],[0]
"− η∇F ∗(yt)W. (14)
",4.1 Single-Step Dual Accelerated method,[0],[0]
"This equation can be interpreted as gossiping the gradients of the local conjugate functions∇f∗i (yi,t), since ∇F ∗(yt)ij =",4.1 Single-Step Dual Accelerated method,[0],[0]
∇f∗j,4.1 Single-Step Dual Accelerated method,[0],[0]
"(yj,t)i.
Theorem 3.",4.1 Single-Step Dual Accelerated method,[0],[0]
The iterative scheme in Alg.,4.1 Single-Step Dual Accelerated method,[0],[0]
(1) converges to Θ = θ∗1> where θ∗ is the solution of Eq.,4.1 Single-Step Dual Accelerated method,[0],[0]
(1).,4.1 Single-Step Dual Accelerated method,[0],[0]
"Furthermore, the time needed for this algorithm to reach any given precision ε > 0 is
O ( (1 + τ)",4.1 Single-Step Dual Accelerated method,[0],[0]
√ κl γ ln,4.1 Single-Step Dual Accelerated method,[0],[0]
( 1 ε )),4.1 Single-Step Dual Accelerated method,[0],[0]
.,4.1 Single-Step Dual Accelerated method,[0],[0]
"(15)
",4.1 Single-Step Dual Accelerated method,[0],[0]
"This theorem relies on proving that the condition number of the dual objective function is upper bounded by κlγ , and noting that the convergence rate for accelerated gradient descent depends on the square root of the condition number (see, e.g., [22]).",4.1 Single-Step Dual Accelerated method,[0],[0]
A detailed proof is available as supplementary material.,4.1 Single-Step Dual Accelerated method,[0],[0]
The main problem of Alg.,4.2 Multi-Step Dual Accelerated method,[0],[0]
(1) is that it always performs the same number of gradient and gossip steps.,4.2 Multi-Step Dual Accelerated method,[0],[0]
"When communication is cheap compared to local computations (τ 1), it would be preferable to perform more gossip steps than gradient steps in order to propagate the local gradients further than the local neighborhoods of each node.",4.2 Multi-Step Dual Accelerated method,[0],[0]
This can be achieved by replacingW by PK(W ) in Alg.,4.2 Multi-Step Dual Accelerated method,[0],[0]
"(1), where PK is a polynomial of degree at most K. If PK(W ) is itself a gossip matrix, then the analysis of the previous section can be applied and the convergence rate of the resulting algorithm depends on the eigengap of PK(W ).",4.2 Multi-Step Dual Accelerated method,[0],[0]
"Maximizing this quantity for a fixed K leads to a common acceleration scheme known as Chebyshev acceleration [25, 26] and the choice
PK(x) = 1− TK(c2(1− x))
TK(c2) , (16)
where c2 = 1+γ1−γ and TK are the Chebyshev polynomials [25] defined as T0(x)",4.2 Multi-Step Dual Accelerated method,[0],[0]
"= 1, T1(x) = x, and, for all k ≥ 1,
Tk+1(x) = 2xTk(x)− Tk−1(x).",4.2 Multi-Step Dual Accelerated method,[0],[0]
"(17)
Finally, verifying that this particular choice of PK(W ) is indeed a gossip matrix, and taking K = b 1√γ c leads to Alg.",4.2 Multi-Step Dual Accelerated method,[0],[0]
(2) with an optimal convergence rate with respect to γ and κl. Theorem 4.,4.2 Multi-Step Dual Accelerated method,[0],[0]
The iterative scheme in Alg.,4.2 Multi-Step Dual Accelerated method,[0],[0]
(2) converges to Θ = θ∗1> where θ∗ is the solution of Eq.,4.2 Multi-Step Dual Accelerated method,[0],[0]
(1).,4.2 Multi-Step Dual Accelerated method,[0],[0]
"Furthermore, the time needed for this algorithm to reach any given precision ε > 0 is
O ( √ κl ( 1 +
τ √ γ
)",4.2 Multi-Step Dual Accelerated method,[0],[0]
"ln ( 1
ε
)) .",4.2 Multi-Step Dual Accelerated method,[0],[0]
"(18)
The proof of Theorem 4 relies on standard properties of Chebyshev polynomials that imply that, for the particular choice of K = b 1√γ c, we have
1√ γ(PK(W ))",4.2 Multi-Step Dual Accelerated method,[0],[0]
≤ 2.,4.2 Multi-Step Dual Accelerated method,[0],[0]
"Hence, Theorem 3 applied to the gossip matrix W ′",4.2 Multi-Step Dual Accelerated method,[0],[0]
= PK(W ) gives the desired convergence rate.,4.2 Multi-Step Dual Accelerated method,[0],[0]
The complete proof is available as supplementary material.,4.2 Multi-Step Dual Accelerated method,[0],[0]
"We now discuss several extensions to the proposed algorithms.
",4.3 Discussion and further developments,[0],[0]
"Algorithm 2 Multi-Step Dual Accelerated method Input: number of iterations T > 0, gossip matrix W ∈ Rn×n, c1 = 1−√γ 1+ √ γ , c2 = 1+γ 1−γ , c3 =
2 (1+γ)λ1(W )
, K = ⌊
1√ γ
⌋ , η = α(1+c 2K 1 )
(1+cK1 ) 2 , µ =
(1+cK1 )",4.3 Discussion and further developments,[0.9759624190543543],"['Algorithm 2 Multi-Step Dual Accelerated method Input: number of iterations T > 0, gossip matrix W ∈ Rn×n, c1 = 1−√γ 1+ √ γ , c2 = 1+γ 1−γ , c3 = 2 (1+γ)λ1(W ) , K = ⌊ 1√ γ ⌋ , η = α(1+c 2K 1 ) (1+cK1 ) 2 , µ = (1+cK1 ) √ κl−1+cK1 (1+cK1 ) √ κl+1−cK1 Output: θi,T , for i = 1, ..., n 1: x0 = 0, y0 = 0 2: for t = 0 to T − 1 do 3: θi,t = ∇f∗i (xi,t), for all i = 1, ..., n 4: yt+1 = xt − η ACCELERATEDGOSSIP(Θt,W ,K) 5: xt+1 = (1 + µ)yt+1 − µyt 6: end for 7: procedure ACCELERATEDGOSSIP(x,W ,K) 8: a0 = 1, a1 = c2 9: x0 = x, x1 = c2x(I − c3W ) 10: for k = 1 to K − 1 do 11: ak+1 = 2c2ak − ak−1 12: xk+1 = 2c2xk(I − c3W )− xk−1 13: end for 14: return x0 − xKaK 15: end procedure Computation of ∇f∗i (xi,t).']"
√ κl−1+cK1 (1+cK1 ),4.3 Discussion and further developments,[0],[0]
"√ κl+1−cK1
Output: θi,T , for i = 1, ..., n 1: x0 = 0, y0 = 0 2: for t = 0 to T",4.3 Discussion and further developments,[0],[0]
"− 1 do 3: θi,t = ∇f∗i (xi,t), for all i = 1, ..., n 4: yt+1 =",4.3 Discussion and further developments,[0],[0]
xt,4.3 Discussion and further developments,[0],[0]
"− η ACCELERATEDGOSSIP(Θt,W ,K) 5: xt+1 = (1 + µ)yt+1 − µyt 6: end for
7: procedure ACCELERATEDGOSSIP(x,W ,K) 8: a0 = 1, a1 = c2 9: x0 = x, x1 = c2x(I − c3W )
10: for k = 1 to K − 1 do 11: ak+1 = 2c2ak − ak−1 12: xk+1 = 2c2xk(I − c3W )",4.3 Discussion and further developments,[0],[0]
"− xk−1 13: end for 14: return x0 − xKaK 15: end procedure
1.",4.3 Discussion and further developments,[0],[0]
"Computation of∇f∗i (xi,t): In practice, it may be hard to apply the dual algorithm when conjugate functions are hard to compute.",4.3 Discussion and further developments,[0],[0]
"We now provide three potential solutions to this problem: (1) warm starts may be used for the optimization problem∇f∗i (xi,t) = argminθ fi(θ)−",4.3 Discussion and further developments,[0],[0]
"x>i,tθ by starting from the previous iteration θi,t−1.",4.3 Discussion and further developments,[0],[0]
This will drastically reduce the number of steps required for convergence.,4.3 Discussion and further developments,[0],[0]
"(2) SSDA and MSDA can be extended to composite functions of the form fi(θ) = gi(Biθ) + c‖θ‖22 for Bi ∈ Rmi×d and gi smooth, and for which we know how to compute the proximal operator.",4.3 Discussion and further developments,[0],[0]
This allows applications in machine learning such as logistic regression.,4.3 Discussion and further developments,[0],[0]
See supplementary material for details.,4.3 Discussion and further developments,[0],[0]
"(3) Beyond the composite case, one can also add a small (well-chosen) quadratic term to the dual, and by applying accelerated gradient descent on the corresponding primal, get an algorithm that uses primal gradient computations and achieves almost the same guarantee as SSDA and MSDA (off by a log(κl/γ) factor).
2.",4.3 Discussion and further developments,[0],[0]
"Local vs. global condition number: MSDA and SSDA depend on the worst strong convexity of the local functions mini αi, which may be very small.",4.3 Discussion and further developments,[0],[0]
A simple trick can be used to depend on the average strong convexity.,4.3 Discussion and further developments,[0],[0]
Using the proxy functions gi(θ) = fi(θ),4.3 Discussion and further developments,[0],[0]
"− (αi − ᾱ)‖θ‖22 instead of fi, where ᾱ = 1n ∑ i αi is the average strong convexity, will improve the local
condition number from κl = maxi βimini αi to
κ′l = maxi βi",4.3 Discussion and further developments,[0],[0]
"− αi
ᾱ",4.3 Discussion and further developments,[0],[0]
"− 1. (19)
Several algorithms, including EXTRA [4] and DIGing [7], have convergence rates that depend on the strong convexity of the global function αg .",4.3 Discussion and further developments,[0],[0]
"However, their convergence rates are not optimal, and it is still an open question to know if a rate close to O (√
κg(1 + τ√ γ )",4.3 Discussion and further developments,[0],[0]
"ln(1/ε)
)
can be achieved with a decentralized algorithm.
",4.3 Discussion and further developments,[0],[0]
3.,4.3 Discussion and further developments,[0],[0]
Asynchronous setting: Accelerated stochastic gradient descent such as SVRG [27] or SAGA [28] can be used on the dual problem in Eq.,4.3 Discussion and further developments,[0],[0]
"(12) instead of accelerated gradient descent, in order to obtain an asynchronous algorithm with a linear convergence rate.",4.3 Discussion and further developments,[0],[0]
The details and exact convergence rate of such an approach are left as future work.,4.3 Discussion and further developments,[0],[0]
"In this section, we compare our new algorithms, single-step dual accelerated (SSDA) descent and multi-step dual accelerated (MSDA) descent, to standard distributed optimization algorithms in two settings: least-squares regression and classification by logistic regression.",5 Experiments,[0],[0]
"Note that these experiments on simple generated datasets are made to assess the differences between existing state-of-theart algorithms and the ones provided in Section 4, and do not address the practical implementation details nor the efficiency of the compared algorithms on real-world distributed platforms.",5 Experiments,[0],[0]
"The effect of latency, machine failures or variable communication time is thus left for future work.",5 Experiments,[0],[0]
We compare SSDA and MSDA to four state-of-the-art distributed algorithms that achieve linear convergence rates: distributed ADMM (D-ADMM),5.1 Competitors and setup,[0],[0]
"[5], EXTRA [4], a recent approach named DIGing [7], and the distributed version of accelerated gradient descent (DAGD) described in Section 3.2 and shown to be optimal among centralized algorithms.",5.1 Competitors and setup,[0],[0]
"When available in the literature, we used the optimal parameters for each algorithm (see Theorem 2 by [5] for D-ADMM and Remark 3 by [4] for EXTRA).",5.1 Competitors and setup,[0],[0]
"For the DIGing algorithm, the parameters provided by [7] are very conservative, and lead to a very slow convergence.",5.1 Competitors and setup,[0],[0]
We thus manually optimized the parameter for this algorithm.,5.1 Competitors and setup,[0],[0]
"The experiments are simulated using a generated dataset consisting of 10, 000 samples randomly distributed to the nodes of a network of size 100.",5.1 Competitors and setup,[0],[0]
"In order to assess the effect of the connectivity of the network, we ran each experiment on two networks: one 10×10 grid and an Erdös-Rényi random network with parameter p = 6100 (i.e. of average degree 6).",5.1 Competitors and setup,[0],[0]
"The quality metric used in this section is be the maximum approximation error among the nodes of the network
et = max i∈V
f̄(θi,t)− f̄(θ∗), (20)
where θ∗ is the optimal parameter of the optimization problem in Eq.",5.1 Competitors and setup,[0],[0]
(1).,5.1 Competitors and setup,[0],[0]
"The regularized least-squares regression problem consists in solving the optimization problem
min θ∈Rd
1 m ‖y −X>θ‖22 + c‖θ‖22, (21)
where X ∈ Rd×m is a matrix containing the m data points, and y ∈ Rm is a vector containing the m associated values.",5.2 Least-squares regression,[0],[0]
The task is thus to minimize the empirical quadratic error between a function yi = g(Xi) of d variables and its linear regression ĝ(Xi) =,5.2 Least-squares regression,[0],[0]
"X>i θ on the original dataset (for
i = 1, ...,m), while smoothing the resulting approximation by adding a regularizer c‖θ‖22.",5.2 Least-squares regression,[0],[0]
"For our experiments, we fixed c = 0.1, d = 10, and sampled m = 10, 000 Gaussian random variables Xi ∼ N (0, 1) of mean 0 and variance 1.",5.2 Least-squares regression,[0],[0]
"The function to regress is then yi = X>i 1+cos(X>i 1)+ξi where ξi ∼ N (0, 1/4) is an i.i.d.",5.2 Least-squares regression,[0],[0]
Gaussian noise of variance 1/4.,5.2 Least-squares regression,[0],[0]
These data points are then distributed randomly and evenly to the n = 100 nodes of the network.,5.2 Least-squares regression,[0],[0]
"Note that the choice of function to regress y does not impact the Hessian of the objective function, and thus the convergence rate of the optimization algorithms.
",5.2 Least-squares regression,[0],[0]
Figure 1 and Figure 2 show the performance of the compared algorithms on two networks: a 10×10 grid graph and an Erdös-Rényi random graph of average degree 6.,5.2 Least-squares regression,[0],[0]
"All algorithms are linearly convergent, although their convergence rates scale on several orders of magnitude.",5.2 Least-squares regression,[0],[0]
"In all experiments, the centralized optimal algorithm DAGD has the best convergence rate, while MSDA has the best convergence rate among decentralized methods.",5.2 Least-squares regression,[0],[0]
"When the communication time is smaller than the computation time (τ 1), performing several communication rounds per gradient iteration will improve the efficiency of the algorithm and MSDA substantially outperforms SSDA.",5.2 Least-squares regression,[0],[0]
"The logistic classification problem consists in solving the optimization problem
min θ∈Rd
1
m m∑ i=1",5.3 Logistic classification,[0],[0]
ln ( 1 + e−yi·X,5.3 Logistic classification,[0],[0]
>,5.3 Logistic classification,[0],[0]
"i θ ) + c‖θ‖22, (22)
where X ∈ Rd×m is a matrix containing m data points, and y ∈ {−1, 1}m is a vector containing the m class assignments.",5.3 Logistic classification,[0],[0]
"The task is thus to classify a dataset by learning a linear classifier mapping data points Xi to their associated class yi ∈ {−1, 1}.",5.3 Logistic classification,[0],[0]
"For our experiments, we fixed c = 0.1, d = 10, and sampled m = 10, 000 data points, 5, 000 for the first class and 5, 000 for the second.",5.3 Logistic classification,[0],[0]
"Each data point Xi ∼ N (yi1, 1) is a Gaussian random variable of mean yi1 and variance 1, where yi = 21{i ≤ 5, 000} − 1 is the true class of Xi.",5.3 Logistic classification,[0],[0]
"These data points are then distributed randomly and evenly to the n = 100 nodes of the network.
",5.3 Logistic classification,[0],[0]
Figure 3 and Figure 4 show the performance of the compared algorithms for logistic classification on two networks: a 10×10 grid graph and an Erdös-Rényi random graph of average degree 6.,5.3 Logistic classification,[0],[0]
"As for
least-squares regression, all algorithms are linearly convergent, and their convergence rates scale on several orders of magnitude.",5.3 Logistic classification,[0],[0]
"In this case, the centralized optimal algorithm DAGD is outperformed by MSDA, although the two convergence rates are relatively similar.",5.3 Logistic classification,[0],[0]
"Again, when the communication time is smaller than the computation time (τ 1), performing several communication rounds per gradient iteration will improve the efficiency of the algorithm and MSDA substantially outperforms SSDA.",5.3 Logistic classification,[0],[0]
"Note that, in Figure 4(a), D-ADMM requires 383 iterations to reach the same error obtained after only 10 iterations of SSDA, demonstrating a substantial improvement over state-ofthe-art methods.",5.3 Logistic classification,[0],[0]
"In this paper, we derived optimal convergence rates for strongly convex and smooth distributed optimization in two settings: centralized and decentralized communications in a network.",6 Conclusion,[0],[0]
"For the decentralized setting, we introduced the multi-step dual accelerated (MSDA) algorithm with a provable optimal linear convergence rate, and showed its high efficiency compared to other state-of-the-art methods, including distributed ADMM and EXTRA.",6 Conclusion,[0],[0]
"The simplicity of the approach makes the algorithm extremely flexible, and allows for future extensions, including time-varying networks and an analysis for non-strongly-convex functions.",6 Conclusion,[0],[0]
"Finally, extending our complexity lower bounds to time delays, variable computational speeds of local systems, or machine failures would be a notable addition to this work.",6 Conclusion,[0],[0]
"A.1 Complexity lower bounds
Proof of Theorem 1.",A Detailed proofs,[0],[0]
"This proof relies on splitting the function used by Nesterov to prove oracle complexities for strongly convex and smooth optimization [8, 22].",A Detailed proofs,[0],[0]
Let β ≥ α,A Detailed proofs,[0],[0]
"> 0, G = (V, E) a graph and A ⊂ V a set of nodes of G. For all d > 0, we denote as Acd = {v ∈ V : d(A, v) ≥ d} the set of nodes at distance at least d from A, and let, for all i ∈ V , fAi : `2 → R be the functions defined as:
fAi (θ) =  α 2n‖θ‖ 2 2 + β−α 8|A| (θ >M1θ − θ1) if i ∈",A Detailed proofs,[0],[0]
"A α 2n‖θ‖ 2 2 + β−α 8|Acd|
θ>M2θ",A Detailed proofs,[0],[0]
"if i ∈ Acd α 2n‖θ‖ 2 2 otherwise
(23)
where M1 : `2 → `2 is the infinite block diagonal matrix with (
1 −1 −1 1
) on the diagonal, and
M2 = ( 1 0
0 M1
) .",A Detailed proofs,[0],[0]
"First, note that, since 0 M1 + M2 4I , f̄A = 1n",A Detailed proofs,[0],[0]
∑n i=1,A Detailed proofs,[0],[0]
f,A Detailed proofs,[0],[0]
"A i is α-strongly
convex and β-smooth.",A Detailed proofs,[0],[0]
"Then, Theorem 1 is a direct consequence of the following lemma:
Lemma 1.",A Detailed proofs,[0],[0]
"IfAcd 6= ∅, then for any t ≥ 0",A Detailed proofs,[0],[0]
"and any black-box procedure one has, for all i ∈ {1, ..., n},
f̄A(θi,t)− f̄A(θ∗)",A Detailed proofs,[0],[0]
"≥ α
2 (√ κg − 1 √ κg + 1 )2(1+ t1+dτ ) ‖θi,0 − θ∗‖2, (24)
where κg = β/α.
",A Detailed proofs,[0],[0]
Proof.,A Detailed proofs,[0],[0]
This lemma relies on the fact that most of the coordinates of the vectors in the memory of any node will remain equal to 0.,A Detailed proofs,[0],[0]
"More precisely, let ki,t = max{k ∈ N : ∃θ ∈",A Detailed proofs,[0],[0]
"Mi,t s.t. θk 6= 0} be the last non-zero coordinate of a vector in the memory of node i at time t. Then, under any black-box procedure, we have, for any local computation step,
ki,t+1 ≤  ki,t + 1{ki,t ≡ 0",A Detailed proofs,[0],[0]
"mod 2} if i ∈ Aki,t + 1{ki,t ≡ 1 mod 2} if i ∈ Acd ki,t otherwise .",A Detailed proofs,[0],[0]
"(25)
Indeed, local gradients can only increase even dimensions for nodes in A and odd dimensions for nodes in Acd.",A Detailed proofs,[0],[0]
"The same holds for gradients of the dual functions, since these have the same block structure as their convex conjugates.",A Detailed proofs,[0],[0]
"Thus, in order to reach the third coordinate, algorithms must first perform one local computation in A, then d communication steps in order for a node in Acd to have a non-zero second coordinate, and finally, one local computation in Acd.",A Detailed proofs,[0],[0]
"Accordingly, one must perform at least k local computation steps and (k − 1)d communication steps to achieve ki,t ≥ k for at least one node i ∈ V , and thus, for any k ∈ N∗,
∀t < 1 + (k − 1)(1 + dτ), ki,t ≤ k",A Detailed proofs,[0],[0]
"− 1. (26)
",A Detailed proofs,[0],[0]
"This implies in particular: ∀i ∈ V, ki,t ≤ ⌊ t− 1
1 + dτ
⌋ + 1 ≤ t
1 + dτ + 1. (27)
",A Detailed proofs,[0],[0]
"Furthermore, by definition of ki,t, one has θi,k = 0 for all k > ki,t, and thus
‖θi,t − θ∗‖22 ≥ +∞∑
k=ki,t+1
θ∗k 2.",A Detailed proofs,[0],[0]
"(28)
and, since f̄A is α-strongly convex,
f̄A(θi,t)− f̄A(θ∗) ≥ α
2 ‖θi,t − θ∗‖22. (29)
Finally, the solution of the global problem minθ f̄A(θ) is θ∗k = (√ β− √ α√ β+",A Detailed proofs,[0],[0]
√ α )k .,A Detailed proofs,[0],[0]
Combining this result with Eqs.,A Detailed proofs,[0],[0]
"(27), (28) and (29) leads to the desired inequality.
",A Detailed proofs,[0],[0]
"Using the previous lemma with d = ∆ the diameter of G and A = {v} one of the pair of nodes at distance ∆ returns the desired result.
",A Detailed proofs,[0],[0]
Proof of Theorem 2.,A Detailed proofs,[0],[0]
Let γn = 1−cos(πn ),A Detailed proofs,[0],[0]
"1+cos(πn )
be a decreasing sequence of positive numbers.",A Detailed proofs,[0],[0]
"Since γ2 = 1 and limn γn = 0, there exists n ≥ 2 such that γn ≥",A Detailed proofs,[0],[0]
γ > γn+1.,A Detailed proofs,[0],[0]
The cases n = 2 and n ≥ 3 are treated separately.,A Detailed proofs,[0],[0]
"If n ≥ 3, let G be the linear graph of size n ordered from node v1 to vn, and weighted with wi,i+1 = 1− a1{i = 1}.",A Detailed proofs,[0],[0]
"Then, if A = {v1, ..., vdn/32e} and d = (1− 1/16)n− 1, we have |Acd| ≥ |A| and Lemma 1 implies:
f̄A(θi,t)− f̄A(θ∗) ≥ nα
2 (√ κg − 1 √ κg + 1 )2(1+ t1+dτ ) ‖θi,0",A Detailed proofs,[0],[0]
− θ∗‖2.,A Detailed proofs,[0],[0]
"(30)
",A Detailed proofs,[0],[0]
"A simple calculation gives κl = 1 + (κg − 1) n2|A| , and thus κg ≥ κl/16.",A Detailed proofs,[0],[0]
"Finally, if we take Wa as the Laplacian of the weighted graph G, a simple calculation gives that, if a = 0, γ(Wa) = γn and, if a = 1, the network is disconnected and γ(Wa) = 0.",A Detailed proofs,[0],[0]
"Thus, by continuity of the eigenvalues of a matrix, there exists a value a ∈",A Detailed proofs,[0],[0]
"[0, 1] such that γ(Wa) = γ.",A Detailed proofs,[0],[0]
"Finally, by definition of n, one has γ > γn+1",A Detailed proofs,[0],[0]
"≥ 2(n+1)2 , and d ≥ 15 16 ( √ 2 γ − 1)− 1 ≥ 1 5 √ γ",A Detailed proofs,[0],[0]
"when γ ≤ γ3 = 1 3 .
",A Detailed proofs,[0],[0]
"For the case n = 2, we consider the totally connected network of 3 nodes, reweight only the edge (v1, v3) by a ∈",A Detailed proofs,[0],[0]
"[0, 1], and let Wa be its Laplacian matrix.",A Detailed proofs,[0],[0]
"If a = 1, then the network is totally connected and γ(Wa) = 1.",A Detailed proofs,[0],[0]
"If, on the contrary, a = 0, then the network is a linear graph and γ(Wa) = γ3.",A Detailed proofs,[0],[0]
"Thus, there exists a value a ∈",A Detailed proofs,[0],[0]
"[0, 1] such that γ(Wa) = γ, and applying Lemma 1 with A = {v1} and d = 1 returns the desired result, since then κg ≥ 2κl/3 and d = 1 ≥ 1√3γ .
",A Detailed proofs,[0],[0]
"A.2 Convergence rates of SSDA and MSDA
Proof of Theorem 3.",A Detailed proofs,[0],[0]
"Each step of the algorithm can be decomposed in first computing gradients, and then communicating these gradients across all neighborhoods.",A Detailed proofs,[0],[0]
"Thus, one step takes a time 1 + τ .",A Detailed proofs,[0],[0]
"Moreover, the Hessian of the dual function F ∗(λ √ W ) is
( √ W ⊗ Id)∇2F ∗(λ √ W )(",A Detailed proofs,[0],[0]
"√ W ⊗ Id), (31)
where ⊗ is the Kronecker product and Id is the identity matrix of size d. Also, note that, in Alg.(2), the current values xt and yt are always in the image of √ W ⊗",A Detailed proofs,[0],[0]
"Id (i.e. the set of matrices x such that
x>1 = 0).",A Detailed proofs,[0],[0]
"The condition number (in the image of √ W ⊗ Id) can thus be upper bounded by κlγ , and Nesterov’s acceleration requires √
κl γ steps to achieve any given precision [22].
",A Detailed proofs,[0],[0]
Proof of Theorem 4.,A Detailed proofs,[0],[0]
"First, since PK(W ) is a gossip matrix, Theorem 3 implies the convergence of Alg.(3).",A Detailed proofs,[0],[0]
"In order to simplify the analysis, we multiply W by 2(1+γ)λ1(W ) , so that the resulting gossip matrix has a spectrum in [1−c−12 , 1+c −1 2 ].",A Detailed proofs,[0],[0]
"Applying Theorem 6.2 in [25] with α = 1−c −1 2 , β = 1 + c−12 and γ = 0 implies that the minimum
min p∈PK ,p(0)=0 max x∈[1−c−12 ,1+c −1 2 ]",A Detailed proofs,[0],[0]
"|p(t)− 1| (32)
is attained by PK(x) = 1− TK(c2(1−x))TK(c2) .",A Detailed proofs,[0],[0]
"Finally, Corollary 6.3 of [25] leads to
γ(PK(W ))",A Detailed proofs,[0],[0]
"≥ 1− 2 c
K 1
1+c2K1
1 + 2 cK1
1+c2K1
=",A Detailed proofs,[0],[0]
"( 1− cK1 1 + cK1 )2 , (33)
where c1 = 1−√γ 1+ √ γ , and taking K = b 1√ γ c implies
1√ γ(PK(W ))",A Detailed proofs,[0],[0]
≤ 1,A Detailed proofs,[0],[0]
"+ c 1√ γ+1 1
1− c 1√ γ+1
1
≤ 2.",A Detailed proofs,[0],[0]
"(34)
",A Detailed proofs,[0],[0]
"The time required to reach an ε > 0 precision using Alg.(3) is thus upper bounded by
O ( (1 +Kτ) √ κl
γ(PK(W ))",A Detailed proofs,[0],[0]
"ln(1/ε)
) =",A Detailed proofs,[0],[0]
O (√ κl(1 + 1√ γ τ) ln(1/ε) ) .,A Detailed proofs,[0],[0]
"When the local functions are of the form
fi(θ) = gi(Biθ)",B Composite problems for machine learning,[0],[0]
"+ c‖θ‖2, (35)
where Bi ∈ Rmi×d and gi is smooth and has proximal operator which is easy to compute (and hence also g∗i ), an additional Lagrange multiplier ν can be used to make the Fenchel conjugate of gi appear in the dual optimization problem.",B Composite problems for machine learning,[0],[0]
"More specifically, from the primal problem of Eq.",B Composite problems for machine learning,[0],[0]
"(12), one has, with ρ > 0",B Composite problems for machine learning,[0],[0]
"an arbitrary parameter:
inf Θ √ W=0 F (Θ) = inf Θ √ W=0, ∀i,xi=Biθi
1
n n∑ i=1 gi(xi)",B Composite problems for machine learning,[0],[0]
+,B Composite problems for machine learning,[0],[0]
"c‖θi‖22
= inf Θ sup λ,ν
1
n n∑ i=1",B Composite problems for machine learning,[0],[0]
{ ν>i Biθi − g∗i (νi) + c‖θi‖22 },B Composite problems for machine learning,[0],[0]
"+ ρ n tr(λ>Θ √ W )
= sup ν∈ ∏n i=1Rmi , λ∈Rd×n − 1 n n∑ i=1",B Composite problems for machine learning,[0],[0]
g∗i (νi)− 1 4cn n∑ i=1,B Composite problems for machine learning,[0],[0]
‖B>,B Composite problems for machine learning,[0],[0]
"i νi + ρλ √ W i‖22.
",B Composite problems for machine learning,[0],[0]
"To maximize the dual problem, we can use (accelerated) proximal gradient, with the updates:
νi,t+1 = inf ν∈Rmi
g∗i (ν) + 1
2η ∥∥ν − νi,t + η 2c Bi(B > i νi,t + ρλt √ W i) ∥∥2",B Composite problems for machine learning,[0],[0]
"2
λt+1 =",B Composite problems for machine learning,[0],[0]
"λt − η ρ
2cn n∑ i=1",B Composite problems for machine learning,[0],[0]
"(B>i νi,t + ρλt √ W i)",B Composite problems for machine learning,[0],[0]
"√ W > i .
",B Composite problems for machine learning,[0],[0]
"We can rewrite all updates in terms of zt = λt √ W ∈ Rd×n, as
νi,t+1 = inf ν∈Rmi
g∗i (ν) + 1
2η ∥∥ν − νi,t + η 2c Bi(B > i νi,t + ρzi,t) ∥∥2 2
zt+1 = zt − η ρ
2cn n∑ i=1",B Composite problems for machine learning,[0],[0]
"(B>i νi,t + ρzi)W",B Composite problems for machine learning,[0],[0]
"> i .
",B Composite problems for machine learning,[0],[0]
"In order to compute the convergence rate of such an algorithm, if we assume that:
• each gi is µ-smooth,
• the largest singular value of each Bi is less than M ,
then we simply need to compute the condition number of the quadratic function
Q(ν, λ) = 1
2µ n∑ i=1",B Composite problems for machine learning,[0],[0]
‖νi‖22 +,B Composite problems for machine learning,[0],[0]
1 4c n∑ i=1,B Composite problems for machine learning,[0],[0]
‖B>,B Composite problems for machine learning,[0],[0]
"i νi + ρλ √ W i‖22.
",B Composite problems for machine learning,[0],[0]
With the choice ρ2 = 1λmax(W ),B Composite problems for machine learning,[0],[0]
"( c µ+M 2), it is lower bounded by ( 1+µM 2 c ) 4 γ , which is a natural upper bound on κl/γ.",B Composite problems for machine learning,[0],[0]
"Thus this essentially leads to the same convergence rate than the non-composite case with the Nesterov and Chebyshev accelerations, i.e. √ κl/γ.
",B Composite problems for machine learning,[0],[0]
"The bound on the conditional number may be shown through the two inequalities:
Q(ν, λ) 6 1
2µ n∑ i=1 ‖νi‖2",B Composite problems for machine learning,[0],[0]
+ 1 2c n∑ i=1,B Composite problems for machine learning,[0],[0]
‖ρλ √ W i‖22 + 1 2c n∑ i=1,B Composite problems for machine learning,[0],[0]
"‖B>i νi‖22,
Q(ν, λ) > 1
2µ n∑ i=1",B Composite problems for machine learning,[0],[0]
‖νi‖2,B Composite problems for machine learning,[0],[0]
+ 1 1 + η 1 4c n∑ i=1,B Composite problems for machine learning,[0],[0]
‖ρλ,B Composite problems for machine learning,[0],[0]
√ W i‖22 − 1 η 1 4c n∑ i=1,B Composite problems for machine learning,[0],[0]
"‖B>i νi‖22,
with η = M2µ/c.",B Composite problems for machine learning,[0],[0]
"In this paper, we determine the optimal convergence rates for strongly convex and smooth distributed optimization in two settings: centralized and decentralized communications over a network.",abstractText,[0],[0]
"For centralized (i.e. master/slave) algorithms, we show that distributing Nesterov’s accelerated gradient descent is optimal and achieves a precision ε > 0",abstractText,[0],[0]
"in time O(κg(1 + ∆τ) ln(1/ε)), where κg is the condition number of the (global) function to optimize, ∆ is the diameter of the network, and τ (resp. 1) is the time needed to communicate values between two neighbors (resp. perform local computations).",abstractText,[0],[0]
"For decentralized algorithms based on gossip, we provide the first optimal algorithm, called the multi-step dual accelerated (MSDA) method, that achieves a precision ε > 0",abstractText,[0],[0]
in time O( √ κl(1 + τ,abstractText,[0],[0]
√ γ ),abstractText,[0],[0]
"ln(1/ε)), where κl is the condition number of the local functions and γ is the (normalized) eigengap of the gossip matrix used for communication between nodes.",abstractText,[0],[0]
We then verify the efficiency of MSDA against state-of-the-art methods for two problems: least-squares regression and classification by logistic regression.,abstractText,[0],[0]
Optimal algorithms for smooth and strongly convex distributed optimization in networks,title,[0],[0]

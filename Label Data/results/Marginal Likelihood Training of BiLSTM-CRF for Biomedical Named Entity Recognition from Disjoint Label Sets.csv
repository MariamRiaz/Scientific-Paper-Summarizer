0,1,label2,summary_sentences
"Decades of research have been dedicated to heuristics for speeding up inference in natural language processing tasks, such as constituency parsing (Pauls and Klein, 2009; Caraballo and Charniak, 1998) and machine translation (Petrov et al., 2008; Xu et al., 2013).",1 Introduction,[0],[0]
"Such research is necessary because of a trend toward richer models, which improve accuracy at the cost of slower inference.",1 Introduction,[0],[0]
"For example, state-of-theart constituency parsers use grammars with millions of rules, while dependency parsers routinely use millions of features.",1 Introduction,[0],[0]
"Without heuristics, these parsers take minutes to process a single sentence.
",1 Introduction,[0],[0]
"To speed up inference, we will learn a pruning policy.",1 Introduction,[0],[0]
"During inference, the pruning policy is invoked to decide whether to keep or prune various parts of the search space, based on features of the input and (potentially) the state of the inference process.
",1 Introduction,[0],[0]
"Our approach searches for a policy with maximum end-to-end performance (reward) on training data, where the reward is a linear combination of problemspecific measures of accuracy and runtime, namely reward = accuracy−λ · runtime.",1 Introduction,[0],[0]
"The parameter λ ≥ 0
specifies the relative importance of runtime and accuracy.",1 Introduction,[0],[0]
"By adjusting λ, we obtain policies with different speed-accuracy tradeoffs.
",1 Introduction,[0],[0]
"For learning, we use Locally Optimal Learning to Search (LOLS) (Chang et al., 2015b), an algorithm for learning sequential decision-making policies, which accounts for the end-to-end performance of the entire decision sequence jointly.",1 Introduction,[0],[0]
"Unfortunately, executing LOLS naively in our setting is prohibitive because it would run inference from scratch millions of times under different policies, training examples, and variations of the decision sequence.",1 Introduction,[0],[0]
"Thus, this paper presents efficient algorithms for repeated inference, which are applicable to a wide variety of NLP tasks, including parsing, machine translation and sequence tagging.",1 Introduction,[0],[0]
"These algorithms, based on change propagation and dynamic programming, dramatically reduce time spent evaluating similar decision sequences by leveraging problem structure and sharing work among evaluations.
",1 Introduction,[0],[0]
We evaluate our approach by learning pruning heuristics for constituency parsing.,1 Introduction,[0],[0]
"In this setting, our approach is the first to account for end-to-end performance of the pruning policy, without making independence assumptions about the reward function, as in prior work (Bodenstab et al., 2011).",1 Introduction,[0],[0]
"In the larger context of learning-to-search for structured prediction, our work is unusual in that it learns to control a dynamic programming algorithm (i.e., graphbased parsing) rather than a greedy algorithm (e.g., transition-based parsing).",1 Introduction,[0],[0]
Our experiments show that accounting for end-to-end performance in training leads to better policies along the entire Pareto frontier of accuracy and runtime.,1 Introduction,[0],[0]
"A simple yet effective approach to speeding up parsing was proposed by Bodenstab et al. (2011), who trained a pruning policy π to classify whether or not spans of the input sentence w1 · · ·wn form plausible
263
Transactions of the Association for Computational Linguistics, vol. 5, pp.",2 Weighted CKY with pruning,[0],[0]
"263–278, 2017.",2 Weighted CKY with pruning,[0],[0]
Action Editor: Marco Kuhlmann.,2 Weighted CKY with pruning,[0],[0]
"Submission batch: 5/2016; Revision batch: 9/2016; Published 8/2017.
",2 Weighted CKY with pruning,[0],[0]
c©2017 Association for Computational Linguistics.,2 Weighted CKY with pruning,[0],[0]
"Distributed under a CC-BY 4.0 license.
constituents based on features of the input sentence.",2 Weighted CKY with pruning,[0],[0]
"These predictions enable a parsing algorithm, such as CKY, to skip expensive steps during its execution: unlikely constituents are pruned.",2 Weighted CKY with pruning,[0],[0]
"Only plausible constituents are kept, and the parser assembles the highest-scoring parse from the available constituents.
",2 Weighted CKY with pruning,[0],[0]
Alg. 1 provides pseudocode for weighted CKY with pruning.,2 Weighted CKY with pruning,[0],[0]
"Weighted CKY aims to find the highestscoring derivation (parse tree) of a given sentence, where a given grammar specifies a non-negative score for each derivation rule and a derivation’s score is the product of the scores of the rules it uses.1 CKY uses a dynamic programming strategy to fill in a three-dimensional array β, known as the chart.",2 Weighted CKY with pruning,[0],[0]
The score βikx is the score of the highest-scoring subderivation with fringe wi+1 . . .,2 Weighted CKY with pruning,[0],[0]
wk and root,2 Weighted CKY with pruning,[0],[0]
x.,2 Weighted CKY with pruning,[0],[0]
This value is computed by looping over the possible ways to assemble such a subderivation from smaller subderivations with scores βijy and βjkz (lines 17–22).,2 Weighted CKY with pruning,[0],[0]
"Additionally, we track a witness (backpointer) for each βikx, so that we can easily reconstruct the corresponding subderivation at line 23.",2 Weighted CKY with pruning,[0],[0]
"The chart is initialized with lexical grammar rules (lines 3–9), which derive words from grammar symbols.
",2 Weighted CKY with pruning,[0],[0]
"The key difference between pruned and unpruned CKY is an additional “if” statement (line 14), which queries the pruning policy π to decide whether to compute the several values βikx associated with a span (i, k).",2 Weighted CKY with pruning,[0],[0]
Note that width-1 and width-n spans are always kept because all valid parses require them.,2 Weighted CKY with pruning,[0],[0]
Bodenstab et al. (2011) train their pruning policy as a supervised classifier of spans.,3 End-to-end training,[0],[0]
"They derive direct supervision as follows: try to keep a span if it appears in the gold-standard parse, and prune it otherwise.",3 End-to-end training,[0],[0]
They found that using an asymmetric weighting scheme helped find the right balance between false positives and false negatives.,3 End-to-end training,[0],[0]
"Intuitively, failing to prune is only a slight slowdown, whereas pruning a good item can ruin the accuracy of the parse.
",3 End-to-end training,[0],[0]
"1As is common practice, we assume the grammar has been binarized.",3 End-to-end training,[0],[0]
"We focus on pre-trained grammars, leaving coadaptation of the grammar and pruning policy to future work.",3 End-to-end training,[0],[0]
"As indicated at lines 6 and 19, a rule’s score may be made to depend on the context in which that rule is applied (Finkel et al., 2008), although the pre-trained grammars in our present experiments are ordinary PCFGs for which this is not the case.
",3 End-to-end training,[0],[0]
"Algorithm 1 PARSE: Weighted CKY with pruning 1: Input: grammar G, sentence w, policy π
Output: completed chart β, derivation d 2: .",3 End-to-end training,[0],[0]
"Initialize chart 3: β := 0 4: for k := 1 to n : 5: for x such that (x→ wk) ∈ rules(G) : 6: s := G(x→ wk | w, k) 7: if s > βk−1,k,x : 8: βk−1,k,x := s 9: witness(k−1, k, x) := (k−1, k, wk)
10: for width := 2 to n : 11: for i := 0 to n− width : 12: k := i+ width .",3 End-to-end training,[0],[0]
"Current span is (i, k) 13: .",3 End-to-end training,[0],[0]
"Policy determines whether to fill in this span 14: if π(w, i, k) = prune : 15: continue 16: .",3 End-to-end training,[0],[0]
Fill in span by considering each split point j 17: for j := i+ 1 to k,3 End-to-end training,[0],[0]
"− 1 : 18: for (x→ y z) ∈ rules(G) : 19: s := βijy ·βjkz ·G(x→ y z | w, i, j, k) 20: if s > βikx : 21: βikx := s 22: witness(i, k, x) := (j, y, z) 23: d̂ := follow backpointers from (0, n,ROOT) 24: return (β, d̂)
",3 End-to-end training,[0],[0]
"Our end-to-end training approach improves upon asymmetric weighting by jointly evaluating the sequence of pruning decisions, measuring its effect on the test-time evaluation metric by actually running pruned CKY (Alg. 1).",3 End-to-end training,[0],[0]
"To estimate the value of a pruning policy π, we call PARSE(G,w(i), π) on each training sentence w(i), and apply the reward function, r = accuracy−λ · runtime.",3 End-to-end training,[0],[0]
"The empirical value of a policy is its average reward on the training set:
R(π) = 1 m
m∑
i=1
E",3 End-to-end training,[0],[0]
"[ r(PARSE(G,w(i), π)) ]",3 End-to-end training,[0],[0]
"(1)
The expectation in the definition may be dropped if PARSE, π, and r are all deterministic, as in our setting.2 Our definition of r depends on the user parameter λ ≥ 0, which specifies the amount of accuracy the user would sacrifice to save one unit of
2Parsers may break ties randomly or use Monte Carlo methods.",3 End-to-end training,[0.9514962911044976],"['However, since we cannot make the complete annotation assumption, we should instead maximize only the marginal probability of the observed entities on the dataset i, Pi(yE|x), allowing yN to take any values from the labels of the other datasets: ∪Dj 6=iSj .']"
"The reward function r can be nondeterministic when it involves wallclock time or human judgments.
runtime.",3 End-to-end training,[0],[0]
"Training under a range of values for λ gives rise to policies covering a number of operating points along the Pareto frontier of accuracy and runtime.
",3 End-to-end training,[0],[0]
End-to-end training gives us a principled way to decide what to prune.,3 End-to-end training,[0],[0]
"Rather than artificially labeling each pruning decision as inherently good or bad, we evaluate its effect in the context of the particular sentence and the other pruning decisions.",3 End-to-end training,[0],[0]
"Actions that prune a gold constituent are not equally bad—some cause cascading errors, while others are “worked around” in the sense that the grammar still selects a mostly-gold parse.",3 End-to-end training,[0],[0]
"Similarly, actions that prune a non-gold constituent are not equally good—some provide more overall speedup (e.g., pruning narrow constituents prevents wider ones from being built), and some even improve accuracy by suppressing an incorrect but high-scoring parse.
",3 End-to-end training,[0],[0]
"More generally, the gold vs. non-gold distinction is not even available in NLP tasks where one is pruning potential elements of a latent structure, such as an alignment (Xu et al., 2013) or a finer-grained parse (Matsuzaki et al., 2005).",3 End-to-end training,[0],[0]
"Yet our approach can still be used in such settings, by evaluating the reward on the downstream task that the latent structure serves.
",3 End-to-end training,[0],[0]
Past work on optimizing end-to-end performance is discussed in §8.,3 End-to-end training,[0],[0]
"One might try to scale these techniques to learning to prune, but in this work we take a different approach.",3 End-to-end training,[0],[0]
"Given a policy, we can easily find small ways to improve it on specific sentences by varying individual pruning actions (e.g., if π currently prunes a span then try keeping it instead).",3 End-to-end training,[0],[0]
"Given a batch of improved action sequences (trajectories), the remaining step is to search for a policy which produces the improved trajectories.",3 End-to-end training,[0],[0]
"Conveniently, this can be reduced to a classification problem, much like the asymmetric weighting approach, except that the supervised labels and misclassification costs are not fixed across iterations, but rather are derived from interaction with the environment (i.e., PARSE and the reward function).",3 End-to-end training,[0],[0]
"This idea is formalized as a learning algorithm called Locally Optimal Learning to Search (Chang et al., 2015b), described in §4.
",3 End-to-end training,[0],[0]
The counterfactual interventions we require— evaluating how reward would change if we changed one action—can be computed more efficiently using our novel algorithms (§5) than by the default strategy of running the parser repeatedly from scratch.,3 End-to-end training,[0],[0]
"The key is to reuse work among evaluations, which is
possible because LOLS only makes tiny changes.",3 End-to-end training,[0],[0]
Pruned inference is a sequential decision process.,4 Learning algorithm,[0],[0]
The process begins in an initial state s0.,4 Learning algorithm,[0],[0]
"In pruned CKY, s0 specifies the state of Alg.",4 Learning algorithm,[0],[0]
"1 at line 10, after the chart has been initialized from some selected sentence.",4 Learning algorithm,[0],[0]
"Next, the policy is invoked to choose action a0 = π(s0)—in",4 Learning algorithm,[0],[0]
our case at line 14—which affects what the parser does next.,4 Learning algorithm,[0],[0]
"Eventually the parser reaches some state s1 from which it calls the policy to choose action a1 = π(s1), and so on.",4 Learning algorithm,[0],[0]
"When the policy is invoked at state st, it selects action at based on features extracted from the current state st—a snapshot of the input sentence, grammar and parse chart at time t.3",4 Learning algorithm,[0],[0]
"We call the state-action sequence s0 a0 s1 a1 · · · sT a trajectory, where T is the trajectory length.",4 Learning algorithm,[0],[0]
"At the final state, the reward function is evaluated, r(sT ).
",4 Learning algorithm,[0],[0]
The LOLS algorithm for learning a policy is given in Alg.,4 Learning algorithm,[0],[0]
"2,4 with a graphical illustration in Fig. 1.",4 Learning algorithm,[0],[0]
"At a high level, LOLS alternates between evaluating and improving the current policy πi.
",4 Learning algorithm,[0],[0]
"The evaluation phase first samples a trajectory from πi, called a roll-in: s0 a0 s1 a1 · · · sT ∼ ROLL-IN(πi).",4 Learning algorithm,[0],[0]
"In our setting, s0 is derived from a randomly sampled training sentence, but the rest of the trajectory is then deterministically computed by πi given s0.",4 Learning algorithm,[0],[0]
"Then we revisit each state s in the roll-in (line 7), and try each available action ā∈A(s)",4 Learning algorithm,[0],[0]
"(line 9), executing πi thereafter—a rollout—to measure the resulting reward r̂[ā] (line 10).",4 Learning algorithm,[0],[0]
"Our parser is deterministic, so a single rollout is an unbiased, 0-variance estimate of the expected reward.",4 Learning algorithm,[0],[0]
"This process is repeated many times, yielding a large list Q̂i of pairs 〈s, r̂〉, where s is a state that was encountered in some roll-in and r̂ maps the possible actions A(s) in that state to their measured rewards.
",4 Learning algorithm,[0],[0]
"The improvement phase now trains a new policy πi+1 to try to choose high-reward actions, seeking a policy that will “on average” get high rewards r[πi+1(s)].",4 Learning algorithm,[0],[0]
"Good generalization is important: the policy must select high-reward actions even in states s that are not represented in Q̂i, in case they are
3Our experiments do not make use of the current state of the chart.",4 Learning algorithm,[0],[0]
"We discuss this decision in §8.
4Alg.",4 Learning algorithm,[0],[0]
"2 is simpler than in Chang et al. (2015b) because it omits oracle rollouts, which we do not use in our experiments.
",4 Learning algorithm,[0],[0]
Algorithm 2 LOLS algorithm for learning to prune.,4 Learning algorithm,[0],[0]
1: π1 := INITIALIZEPOLICY(. . . ),4 Learning algorithm,[0],[0]
2: for i := 1 to number of iterations : 3: .,4 Learning algorithm,[0],[0]
Evaluate: Collect dataset for πi 4: Q̂i := ∅ 5: for j := 1 to minibatch size : 6: s0 a0 s1 a1 · · · sT ∼ ROLL-IN(πi) .,4 Learning algorithm,[0],[0]
Sample 7: for t := 0 to T−1 : 8: .,4 Learning algorithm,[0],[0]
Intervene: Evaluate each action at st 9: for āt ∈ A(st) : .,4 Learning algorithm,[0],[0]
"Possible actions
10: r̂t[āt] ∼ ROLLOUT(πi, st, āt) 11: Q̂i.append(〈st, r̂t 〉) 12: .",4 Learning algorithm,[0],[0]
"Improve: Train with dataset aggregation
13: πi+1 ← TRAIN",4 Learning algorithm,[0],[0]
(,4 Learning algorithm,[0],[0]
"⋃i k=1 Q̂k )
14: .",4 Learning algorithm,[0],[0]
Finalize: Pick the best policy over all iterations 15: return argmaxi′ R(πi′) encountered when running the new policy πi+1 (or when parsing test sentences).,4 Learning algorithm,[0],[0]
"Thus, beyond just regularizing the training objective, we apply dataset aggregation (Ross et al., 2011): we take the training set to include not just Q̂i but also the examples from previous iterations (line 13).",4 Learning algorithm,[0],[0]
"This also ensures that the sequence of policies π1, π2, . .",4 Learning algorithm,[0],[0]
".will be “stable” (Ross and Bagnell, 2011) and will eventually converge.
",4 Learning algorithm,[0],[0]
"So line 13 seeks to find a good classifier πi+1 using a training set: a possible classifier π would receive from each training example 〈s, r̂〉 a reward of r̂[π(s)].",4 Learning algorithm,[0],[0]
"In our case, where A(s) = {keep, prune}, this cost-sensitive classification problem is equivalent to training an ordinary binary classifier, after converting each training example 〈s, r̂〉 to 〈s, argmaxa",4 Learning algorithm,[0],[0]
"r̂[a]〉 and giving this example a weight of |r̂t,keep− r̂t,prune|.",4 Learning algorithm,[0],[0]
"Our specific classifier is described in §6.
",4 Learning algorithm,[0],[0]
"In summary, the evaluation phase of LOLS collects training data for a cost-sensitive classifier, where the
inputs (states), outputs (actions), and costs are obtained by interacting with the environment.",4 Learning algorithm,[0],[0]
"LOLS concocts a training set and repeatedly revises it, similar to the well-known Expectation-Maximization algorithm.",4 Learning algorithm,[0],[0]
This enables end-to-end training of systems with discrete decisions and nondecomposable reward functions.,4 Learning algorithm,[0],[0]
LOLS gives us a principled framework for deriving (nonstationary) “supervision” even in tricky cases such as latent-variable inference (mentioned in §3).,4 Learning algorithm,[0],[0]
"LOLS has strong theoretical guarantees, though in pathological cases, it may take exponential time to converge (Chang et al., 2015b).
",4 Learning algorithm,[0],[0]
"The inner loop of the evaluation phase performs roll-ins, interventions and rollouts.",4 Learning algorithm,[0],[0]
Roll-ins ensure that the policy is (eventually) trained under the distribution of states it tends to encounter at test time.,4 Learning algorithm,[0],[0]
Interventions and rollouts force πi to explore the effect of currently disfavored actions.,4 Learning algorithm,[0],[0]
"Unlike most applications of LOLS and related algorithms, such as SEARN (Daumé III, 2006) and DAGGER (Ross et al., 2011), executing the policy is a major bottleneck in training.",5 Efficient rollouts,[0],[0]
"Because our dynamic programming parser explores many possibilities (unlike a greedy, transition-based decoder) its trajectories are quite long.",5 Efficient rollouts,[0],[0]
"This not only slows down each rollout: it means we must do more rollouts.
",5 Efficient rollouts,[0],[0]
"In our case, the trajectory has length T = n·(n+1)
2",5 Efficient rollouts,[0],[0]
− 1− n,5 Efficient rollouts,[0],[0]
"for a sentence of length n, where T is also the number of pruning decisions: one for each span other than the root and width-1 spans.",5 Efficient rollouts,[0],[0]
LOLS must then perform T rollouts on this example.,5 Efficient rollouts,[0],[0]
"This means that to evaluate policy πi, we must parse each sentence in the minibatch hundreds of times (e.g., 189 for n=20, 434 for n=30, and 779 for n=40).
",5 Efficient rollouts,[0],[0]
"We can regard each policy π as defining a pruning
mask m, an array that maps each of the T spans (i, k) to a decision mik (1 = keep, 0 = prune).",5 Efficient rollouts,[0],[0]
"Each rollout tries flipping a different bit in this mask.
",5 Efficient rollouts,[0],[0]
We could spend less time on each sentence by sampling only some of its T rollouts (see §6).,5 Efficient rollouts,[0],[0]
"Regardless, the rollouts we do on a given sentence are related: in this section we show how to get further speedups by sharing work among them.",5 Efficient rollouts,[0],[0]
"In §5.2, we leverage the fact that rollouts will be similar to one another (differing by a single pruning decision).",5 Efficient rollouts,[0],[0]
"In §5.3, we show that the reward of all T rollouts can be computed simultaneously by dynamic programming under some assumptions about the structure of the reward function (described later).",5 Efficient rollouts,[0],[0]
We found these algorithms to be crucial to training in a “reasonable” amount of time (see the empirical comparison in §7.2).,5 Efficient rollouts,[0],[0]
"It is convenient to present our efficient rollout algorithms in terms of the hypergraph structure of Alg. 1 (Klein and Manning, 2001; Huang, 2008; Li and Eisner, 2009; Eisner and Blatz, 2007).",5.1 Background: Parsing as hypergraphs,[0],[0]
A hypergraph describes the information flow among related quantities in a dynamic programming algorithm.,5.1 Background: Parsing as hypergraphs,[0],[0]
"Many computational tricks apply generically to hypergraphs.
",5.1 Background: Parsing as hypergraphs,[0],[0]
A hypergraph edge e (or hyperedge) is a “generalized arrow” e.head ≺ e.Tail with one output and a list of inputs.,5.1 Background: Parsing as hypergraphs,[0],[0]
"We regard each quantity βikx,mik, or G(. . .)",5.1 Background: Parsing as hypergraphs,[0],[0]
"in Alg. 1 as the value of a corresponding hypergraph vertex β̇ikx, ṁik, or Ġ(. . .).",5.1 Background: Parsing as hypergraphs,[0],[0]
"Thus, value(v̇) = v for any vertex v̇. Each ṁik’s value is computed by the policy π or chosen by a rollout intervention.",5.1 Background: Parsing as hypergraphs,[0],[0]
"Each Ġ’s value is given by the grammar.
",5.1 Background: Parsing as hypergraphs,[0],[0]
"Values of β̇ikx, by contrast, are computed at line 19 if k − i > 1.",5.1 Background: Parsing as hypergraphs,[0],[0]
"To record the dependence of βikx on other quantities, our hypergraph includes the hyperedge β̇ikx ≺",5.1 Background: Parsing as hypergraphs,[0],[0]
"(β̇ijy, β̇jkz, ṁik, ġ) for each 0 ≤",5.1 Background: Parsing as hypergraphs,[0],[0]
i < j < k ≤ n,5.1 Background: Parsing as hypergraphs,[0],[0]
"and (x→ y z) ∈ rules(G), where ġ denotes the vertex Ġ(x→ y z | w, i, j, k).
",5.1 Background: Parsing as hypergraphs,[0],[0]
"If k − i = 1, then values of βikx are instead computed at line 6, which does not access any other β values or the pruning mask.",5.1 Background: Parsing as hypergraphs,[0],[0]
"Thus our hypergraph includes the hyperedge vikx ≺(ġ) whenever i = k−1, 0 ≤",5.1 Background: Parsing as hypergraphs,[0],[0]
"i < k ≤ n, and (x→ wk) ∈ rules(G), with ġ = Ġ(x→ wk | w, k).
",5.1 Background: Parsing as hypergraphs,[0],[0]
"With this setup, the value βikx is the maximum score of any derivation of vertex β̇ikx (a tree rooted at β̇ikx, representing a subderivation), where the score
of a derivation is the product of its leaf values.",5.1 Background: Parsing as hypergraphs,[0],[0]
Alg. 1 computes it by considering hyperedges β̇ikx ≺ T and the previously computed values of the vertices in the tail T .,5.1 Background: Parsing as hypergraphs,[0],[0]
"For a vertex v̇, we write In(v̇) and Out(v̇) for its sets of incoming and outgoing hyperedges.",5.1 Background: Parsing as hypergraphs,[0],[0]
"Our algorithms follow these hyperedges implicitly, without the overhead of materializing or storing them.",5.1 Background: Parsing as hypergraphs,[0],[0]
"Change propagation is an efficient method for incrementally re-evaluating a computation under a change to its inputs (Acar and Ley-Wild, 2008; Filardo and Eisner, 2012).",5.2 Change propagation (CP),[0],[0]
"In our setting, each roll-in at Alg. 2 line 6 evaluates the reward r(PARSE(G, xi, π)) from (1), which involves computing an entire parse chart via Alg. 1.",5.2 Change propagation (CP),[0],[0]
"The inner loop at line 10 performs T interventions per roll-in, which ask how reward would have changed if one bit in the pruning maskm had been different.",5.2 Change propagation (CP),[0],[0]
"Rather than reparsing from scratch (T times) to determine this, we can simply adjust the initial roll-in computation (T times).
",5.2 Change propagation (CP),[0],[0]
CP is efficient when only a small fraction of the computation needs to be adjusted.,5.2 Change propagation (CP),[0],[0]
"In principle, flipping a single pruning bit can change up to 50% of the chart, so one might expect the bookkeeping overhead of CP to outweigh the gains.",5.2 Change propagation (CP),[0],[0]
"In practice, however, 90% of the interventions change < 10% of the β values in the chart.",5.2 Change propagation (CP),[0],[0]
"The reason is that βikx is a maximum over many quantities, only one of which “wins.”",5.2 Change propagation (CP),[0],[0]
"Changing a given βijy rarely affects this maximum, and so changes are unlikely to propagate from vertex β̇ijy to β̇ikx.",5.2 Change propagation (CP),[0],[0]
"Since changes are not very contagious, the “epidemic of changes” does not spread far.
",5.2 Change propagation (CP),[0],[0]
Alg. 3 provides pseudocode for updating the highest-scoring derivation found by Alg. 1.,5.2 Change propagation (CP),[0],[0]
"We remark that the RECOMPUTE is called only when we flip a bit from keep to prune, which removes hyperedges and potentially decreases vertex values.",5.2 Change propagation (CP),[0],[0]
"The reverse flip only adds hyperedges, which increases vertex values via a running max (lines 12–14).
",5.2 Change propagation (CP),[0],[0]
"After determining the effect of flipping a bit, we must restore the original chart before trying a different bit (the next rollout).",5.2 Change propagation (CP),[0],[0]
The simplest approach is to call Alg. 3 again to flip the bit,5.2 Change propagation (CP),[0],[0]
"back.5
5Our implementation uses a slightly faster method which accumulates an “undo list” of changes that it makes to the chart to quickly revert the modified chart to the original roll-in state.
",5.2 Change propagation (CP),[0],[0]
Algorithm 3 Change propagation algorithm 1: Global: Alg.,5.2 Change propagation (CP),[0],[0]
"1’s vertex values/witnesses (roll-in) 2: procedure CHANGE(v̇, v) 3: .",5.2 Change propagation (CP),[0],[0]
Change the value of a leaf vertex v̇ to v 4: value(v̇) := v ; witness(v̇) = LEAF 5: Q := ∅; Q.push(v̇) .,5.2 Change propagation (CP),[0],[0]
Work queue (“agenda”) 6: while Q 6= ∅ : .,5.2 Change propagation (CP),[0],[0]
Propagate until convergence 7: u̇,5.2 Change propagation (CP),[0],[0]
:= Q.pop() .,5.2 Change propagation (CP),[0],[0]
Narrower constituents first 8: if witness(u̇) = NULL : .,5.2 Change propagation (CP),[0],[0]
Value is unknown 9: RECOMPUTE(u̇) .,5.2 Change propagation (CP),[0],[0]
"Get value & witness
10: for e ∈ Out(u̇) : .",5.2 Change propagation (CP),[0],[0]
Propagate new value of u̇ 11: ṡ := e.head; s := ∏ u̇′∈e.,5.2 Change propagation (CP),[0],[0]
"Tail value(u̇
′) 12: if s > value(ṡ) : .",5.2 Change propagation (CP),[0],[0]
Increase value 13: value(ṡ) := s; witness(ṡ) := e 14: Q.push(ṡ) 15: else if witness(ṡ) = e and s < value(ṡ): 16: witness(ṡ) := NULL .Value,5.2 Change propagation (CP),[0],[0]
may decrease 17: Q.push(ṡ) .,5.2 Change propagation (CP),[0],[0]
"so, recompute upon pop 18: procedure RECOMPUTE(ṡ) 19: for e ∈ In(ṡ) : .",5.2 Change propagation (CP),[0],[0]
Max over incoming hyperedges 20: s := ∏ u̇∈e.,5.2 Change propagation (CP),[0],[0]
Tail value(u̇) 21: if s > value(ṡ) : 22: value(ṡ) = s; witness(ṡ) =,5.2 Change propagation (CP),[0],[0]
e,5.2 Change propagation (CP),[0],[0]
The naive rollout algorithm runs the parser T times— once for each variation of the pruning mask.,5.3 Dynamic programming (DP),[0],[0]
"The reader may be reminded of the finite difference approximation to the gradient of a function, which also measures the effects from perturbing each input value individually.",5.3 Dynamic programming (DP),[0],[0]
"In fact, for certain reward functions, the naive algorithm can be precisely regarded as computing a gradient—and thus we can use a more efficient algorithm, back-propagation, which finds the entire gradient vector of reward as fast (in the big-O sense) as computing the reward once.",5.3 Dynamic programming (DP),[0],[0]
"The overall algorithm is O(|E| + T ) where |E| is the total number of hyperedges, whereas the naive algorithm is O(|E′|·T ) where |E′| ≤ |E| is the maximum number of hyperedges actually visited on any rollout.
",5.3 Dynamic programming (DP),[0],[0]
What accuracy measure must we use?,5.3 Dynamic programming (DP),[0],[0]
Let r(d) denote the recall of a derivation d—the fraction of gold constituents that appear as vertices in the derivation.,5.3 Dynamic programming (DP),[0],[0]
"A simple accuracy metric would be 1-best recall, the recall r(d̂) of the highest-scoring derivation d̂ that was not pruned.",5.3 Dynamic programming (DP),[0],[0]
"In this section, we relax that to ex-
pected recall,6 r̄= ∑
d p(d)r(d).",5.3 Dynamic programming (DP),[0],[0]
"Here we interpret the pruned hypergraph’s values as an unnormalized probability distribution over derivations, where the probability p(d) =",5.3 Dynamic programming (DP),[0],[0]
p̃(d)/Z of a derivation is proportional to its score p̃(d) =,5.3 Dynamic programming (DP),[0],[0]
"∏ u̇∈leaves(d) value(u̇).
",5.3 Dynamic programming (DP),[0],[0]
"Though r̄ is not quite our evaluation metric, it captures more information about the parse forest, and so may offer some regularizing effect when used in a training criterion (see §7.1).",5.3 Dynamic programming (DP),[0],[0]
"In any case, r̄ is close to r(d̂) when probability mass is concentrated on a few derivations, which is common with heavy pruning.
",5.3 Dynamic programming (DP),[0],[0]
"We can re-express r̄ as r̃/Z, where
r̃ = ∑
d
p̃(d)r(d) Z = ∑
d
p̃(d) (2)
These can be efficiently computed by dynamic programming (DP), specifically by a variant of the inside algorithm (Li and Eisner, 2009).",5.3 Dynamic programming (DP),[0],[0]
"Since p̃(d) is a product of rule weights and pruning mask bits at d’s leaves (§5.1), each appearing at most once, both r̃ and Z vary linearly in any one of these inputs provided that all other inputs are held constant.",5.3 Dynamic programming (DP),[0],[0]
"Thus, the exact effect on r̃ or Z of changing an input mik can be found from the partial derivatives with respect to it.",5.3 Dynamic programming (DP),[0],[0]
"In particular, if we increased mik by ∆ ∈ {−1, 1} (to flip this bit), the new value of r̄ would be exactly
r̃ + ∆ · ∂r̃/∂mik",5.3 Dynamic programming (DP),[0],[0]
"Z + ∆ · ∂Z/∂mik
(3)
",5.3 Dynamic programming (DP),[0],[0]
It remains to compute these partial derivatives.,5.3 Dynamic programming (DP),[0],[0]
"All partials can be jointly computed by back-propagation, which equivalent to another dynamic program known as the outside algorithm (Eisner, 2016).
",5.3 Dynamic programming (DP),[0],[0]
"The inside algorithm only needs to visit the |E′| unpruned edges, but the outside algorithm must also visit some pruned edges, to determine the effect of “unpruning” them (changing their mik input from 0 to 1) by finding ∂r̃/∂mik and ∂Z/∂mik.",5.3 Dynamic programming (DP),[0],[0]
"On the other hand, these partials are 0 when some other input to the hyperedge is 0.",5.3 Dynamic programming (DP),[0],[0]
"This case is common when the hypergraph is heavily pruned (|E′| |E|), and means that back-propagation need not descend further through that hyperedge.
",5.3 Dynamic programming (DP),[0],[0]
"6In theory, we could anneal from expected to 1-best recall (Smith and Eisner, 2006).",5.3 Dynamic programming (DP),[0],[0]
"We experimented extensively with annealing but found it to be too numerically unstable for our purposes, even with high-precision arithmetic libraries.
",5.3 Dynamic programming (DP),[0],[0]
Note that the DP method computes only the accuracies of rollouts—not the runtimes.,5.3 Dynamic programming (DP),[0],[0]
"In this paper, we will combine DP with a very simple runtime measure that is trivial to roll out (see §7).",5.3 Dynamic programming (DP),[0],[0]
An alternative would be to use CP to roll out the runtimes.,5.3 Dynamic programming (DP),[0],[0]
"This is very efficient: to measure just runtime, CP only needs to update the record of which constituents or edges are built, and not their scores, so the changes are easier to compute than in §5.2, and peter out more quickly.
6 Parser details7
Setup: We use the standard English parsing setup: the Penn Treebank (Marcus et al., 1993) with the standard train/dev/test split, and standard tree normalization.8 For efficiency during training, we restrict the length of sentences to ≤ 40.",5.3 Dynamic programming (DP),[0],[0]
We do not restrict the length of test sentences.,5.3 Dynamic programming (DP),[0],[0]
"We experiment with two grammars: coarse, the “no frills” left-binarized treebank grammar, and fine, a variant of the Berkeley split-merge level-6 grammar (Petrov et al., 2006) as provided by Dunlop (2014, ch. 5).",5.3 Dynamic programming (DP),[0],[0]
The parsing algorithms used during training are described in §5.,5.3 Dynamic programming (DP),[0],[0]
"Our test-time parsing algorithm uses the left-child loop implementation of CKY (Dunlop et al., 2010).",5.3 Dynamic programming (DP),[0],[0]
All algorithms allow unary rules (though not chains).,5.3 Dynamic programming (DP),[0],[0]
"We evaluate accuracy at test time with the F1 score from the official EVALB script (Sekine and Collins, 1997).
",5.3 Dynamic programming (DP),[0],[0]
Training:,5.3 Dynamic programming (DP),[0],[0]
Note that we never retrain the grammar weights—we train only the pruning policy.,5.3 Dynamic programming (DP),[0],[0]
"To TRAIN our classifiers (Alg. 2 line 13), we use L2-regularized logistic regression, trained with L-BFGS optimization.",5.3 Dynamic programming (DP),[0],[0]
"We always rescale the example weights in the training set to sum to 1 (otherwise as LOLS proceeds, dataset aggregation overwhelms the regularizer).",5.3 Dynamic programming (DP),[0],[0]
"For the baseline (defined in next section), we determine the regularization coefficient by sweeping {2−11, 2−12, 2−13, 2−14, 2−15} and picking the best value (2−13) based on the dev frontier.",5.3 Dynamic programming (DP),[0],[0]
We re-used this regularization parameter for LOLS.,5.3 Dynamic programming (DP),[0],[0]
"The number of LOLS iterations is determined by a 6-day training-time limit9 (meaning some jobs run many
7Code for experiments is available at http://github.",5.3 Dynamic programming (DP),[0],[0]
"com/timvieira/learning-to-prune.
",5.3 Dynamic programming (DP),[0],[0]
8Data train/dev/test split (by section) 2–21 / 22 / 23.,5.3 Dynamic programming (DP),[0],[0]
"Normalization operations: Remove function tags, traces, spurious unary edges (X → X), and empty subtrees left by other operations.",5.3 Dynamic programming (DP),[0],[0]
"Relabel ADVP and PRT|ADVP tags to PRT.
",5.3 Dynamic programming (DP),[0],[0]
"9On the 7th day, LOLS rested and performance was good.
",5.3 Dynamic programming (DP),[0],[0]
fewer iterations than others).,5.3 Dynamic programming (DP),[0],[0]
For LOLS minibatch size we use 10K on the coarse grammar and 5K on the fine grammar.,5.3 Dynamic programming (DP),[0],[0]
"At line 15 of Alg. 2, we return the policy that maximized reward on development data, using the reward function from training.
",5.3 Dynamic programming (DP),[0],[0]
"Features: We use similar features to Bodenstab et al. (2011), but we have removed features that depend on part-of-speech tags.",5.3 Dynamic programming (DP),[0],[0]
"We use the following 16 feature templates for span (i, k) with 1 < k−i < N : bias, sentence length, boundary words, conjunctions of boundary words, conjunctions of word shapes, span shape, width bucket.",5.3 Dynamic programming (DP),[0],[0]
"Shape features map a word or phrase into a string of character classes (uppercase, lowercase, numeric, spaces); we truncate substrings of identical classes to length two; punctuation chars are never modified in any way.",5.3 Dynamic programming (DP),[0],[0]
"Width buckets use the following partition: 2, 3, 4, 5, [6, 10], [11, 20], [21,∞).",5.3 Dynamic programming (DP),[0],[0]
"We use feature hashing (Weinberger et al., 2009) with MurmurHash3 (Appleby, 2008) and project to 222 features.",5.3 Dynamic programming (DP),[0],[0]
"Conjunctions are taken at positions (i−1, i), (k, k+1), (i−1, k+1) and (i, k).",5.3 Dynamic programming (DP),[0],[0]
"We use special begin and end symbols when a template accesses positions beyond the sentence boundary.
",5.3 Dynamic programming (DP),[0],[0]
Hall et al. (2014) give examples motivating our feature templates and show experimentally that they are effective in multiple languages.,5.3 Dynamic programming (DP),[0],[0]
Boundary words are strong surface cues for phrase boundaries.,5.3 Dynamic programming (DP),[0],[0]
Span shape features are also useful as they (minimally) check for matched parentheses and quotation marks.,5.3 Dynamic programming (DP),[0],[0]
Reward functions and surrogates: Each user has a personal reward function.,7 Experimental design and results,[0],[0]
"In this paper, we choose to specify our true reward as accuracy − λ · runtime, where accuracy is given by labeled F1 percentage and runtime by mega-pushes (mpush), millions of calls per sentence to lines 6 and 19 of Alg. 1, which is in practice proportional to seconds per sentence (correlation > 0.95) and is more replicable.",7 Experimental design and results,[0],[0]
We evaluate accordingly (on test data)—but during LOLS training we approximate these metrics.,7 Experimental design and results,[0],[0]
"We compare:
• rCP (fast): Use change propagation (§5.2) to compute accuracy on a sentence as F1 of just that sentence, and to approximate runtime as ||β||0,
the number of constituents that were built.10
• rDP (faster): Use dynamic programming (§5.3) to approximate accuracy on a sentence as expected recall.11 This time we approximate runtime more crudely as ||m||0, the number of nonzeros in the pruning mask for the sentence (i.e., the number of spans whose constituents the policy would be willing to keep if they were built).
",7 Experimental design and results,[0],[0]
We use these surrogates because they admit efficient rollout algorithms.,7 Experimental design and results,[0],[0]
"Less important, they preserve the training objective (1) as an average over sentences.",7 Experimental design and results,[0],[0]
"(Our true F1 metric on a corpus cannot be computed in this way, though it could reasonably be estimated by averaging over minibatches of sentences in (1).)
",7 Experimental design and results,[0],[0]
"Controlled experimental design: Our baseline system is an adaptation of Bodenstab et al. (2011) to learning-to-prune, as described in §3 and §6.",7 Experimental design and results,[0],[0]
Our goal is to determine whether such systems can be improved by LOLS training.,7 Experimental design and results,[0],[0]
"We repeat the following design for both reward surrogates (rCP and rDP) and for both grammars (coarse and fine).
",7 Experimental design and results,[0],[0]
¬ We start by training a number of baseline models by sweeping the asymmetric weighting parameter.,7 Experimental design and results,[0],[0]
"For the coarse grammar we train 8 such models, and for the fine grammar 12.
 ",7 Experimental design and results,[0],[0]
"For each baseline policy, we estimate a value of λ for which that policy is optimal (among baseline policies) according to surrogate reward.12
10When using rCP, we speed up LOLS by doing≤ 2n rollouts per sentence of length n. We sample these uniformly without replacement from the T possible rollouts (§5), and compensate by upweighting the resulting training examples by T/(2n).
",7 Experimental design and results,[0],[0]
"11Considering all nodes in the binarized tree, except for the root, width-1 constituents, and children of unary rules.
",7 Experimental design and results,[0],[0]
"12We estimate λ by first fitting a parametric model yi = h(xi) , ymax · sigmoid(a · log(xi + c) + b) to the baseline runtime-accuracy measurements on dev data (shown in green in Fig. 2) by minimizing mean squared error.",7 Experimental design and results,[0],[0]
"We then use the fitted curve’s slope h′ to estimate each λi = h′(xi), where xi is the runtime of baseline i. The resulting choice of reward function y−λi",7 Experimental design and results,[0],[0]
"·x increases along the green arrow in Fig. 2, and is indeed maximized (subject to y ≤ h(x), and in the region where h is concave) at x = xi.",7 Experimental design and results,[0],[0]
"As a sanity check, notice since λi is a derivative of the function y = h(x), its units are in units of y (accuracy) per unit of x (runtime), as appropriate for use in the expression",7 Experimental design and results,[0],[0]
y,7 Experimental design and results,[0],[0]
− λi · x.,7 Experimental design and results,[0],[0]
"Indeed, this procedure will construct the same reward function regardless of the units we use to express x.",7 Experimental design and results,[0.9532252886933791],"['Ultimately, we would like to identify all entity types present across the union of the label sets during inference while leveraging all the available annotations to train our models.']"
"Our specific parametric model h is a sigmoidal curve, with
® For each baseline policy, we run LOLS with the same surrogate reward function (defined by λ) for which that baseline policy was optimal.",7 Experimental design and results,[0],[0]
We initialize LOLS by setting π0 to the baseline policy.,7 Experimental design and results,[0],[0]
"Furthermore, we include the baseline policy’s weighted training set Q̂0 in the ⋃ at line 13.
",7 Experimental design and results,[0],[0]
"Fig. 2 shows that LOLS learns to improve on the baseline, as evaluated on development data.
¯",7 Experimental design and results,[0],[0]
But do these surrogate reward improvements also improve our true reward?,7 Experimental design and results,[0],[0]
"For each baseline policy, we use dev data to estimate a value of λ for which that policy is optimal according to our true reward function.",7 Experimental design and results,[0],[0]
"We use blind test data to compare the baseline policy to its corresponding LOLS policy on this true reward function, testing significance with a paired permutation test.",7 Experimental design and results,[0],[0]
"The improvements hold up, as shown in Fig. 3.
",7 Experimental design and results,[0],[0]
"The rationale behind this design is that a user who actually wishes to maximize accuracy−λ·runtime, for some specific λ, could reasonably start by choosing the best baseline policy for this reward function, and then try to improve that baseline by running LOLS with the same reward function.",7 Experimental design and results,[0],[0]
"Our experiments show this procedure works for a range of λ values.
",7 Experimental design and results,[0],[0]
"In the real world, a user’s true objective might instead be some nonlinear function of runtime and accuracy.",7 Experimental design and results,[0],[0]
"For example, when accuracy is “good enough,” it may be more important to improve runtime, and vice-versa.",7 Experimental design and results,[0],[0]
LOLS could be used with such a nonlinear reward function as well.,7 Experimental design and results,[0],[0]
"In fact, a user does not even have to quantify their global preferences by writing down such a function.",7 Experimental design and results,[0],[0]
"Rather, they could select manually among the baseline policies, choosing one with an attractive speed-accuracy tradeoff, and then specify λ to indicate a local direction of desired improvement (like the green arrows in Fig. 2), modifying this direction periodically as LOLS runs.",7 Experimental design and results,[0],[0]
"As previous work has shown, learning to prune gives us excellent parsers with less than < 2% overhead
accuracy → ymax asymptotically as runtime → ∞. It obtains an excellent fit by placing accuracy and runtime on the loglogit scale—that is, log(xi + c) and logit(yi/ymax) transforms are used to convert our bounded random variables xi and yi to unbounded ones—and then assuming they are linearly related.
for deciding what to prune (i.e., pruning feature extraction and span classification).",7.1 Discussion,[0],[0]
"Even the baseline pruner has access to features unavailable to the grammar, and so it learns to override the grammar, improving an unpruned coarse parser’s accuracy from 61.1 to as high as 70.1% F1 on test data (i.e., beneficial search error).",7.1 Discussion,[0],[0]
"It is also 8.1x faster!13 LOLS simply does a better job at figuring out where to prune, raising accuracy 2.1 points to 72.2 (while maintaining a 7.4x speedup).",7.1 Discussion,[0],[0]
"Where pruning is more aggressive,
13We measure runtime as best of 10 runs (recommended by Dunlop (2014)).",7.1 Discussion,[0],[0]
"All parser timing experiments were performed on a Linux laptop with the following specs: Intel® Core™ i5-2540M 2.60GHz CPU, 8GB memory, 32K/256K/3072K L1/L2/L3 cache.",7.1 Discussion,[0],[0]
"Code is written in the Cython language.
",7.1 Discussion,[0],[0]
"LOLS has even more impact on accuracy.
",7.1 Discussion,[0],[0]
"Even on the fine grammar, where there is less room to improve accuracy, the most accurate LOLS system improves an unpruned parser by +0.16% F1 with a 8.6x speedup.",7.1 Discussion,[0],[0]
"For comparison, the most accurate baseline drops −0.03% F1 with a 9.7x speedup.
",7.1 Discussion,[0],[0]
"With the fine grammar, we do not see much improvement over the baseline in the accuracy > 85 regions.",7.1 Discussion,[0],[0]
This is because the supervision specified by asymmetric weighting is similar to what LOLS surmises via rollouts.,7.1 Discussion,[0],[0]
"However, in lower-accuracy regions we see that LOLS can significantly improve reward over its baseline policy.",7.1 Discussion,[0],[0]
"This is because the baseline supervision does not teach which plausible
constituents are “safest” to prune, nor can it learn strategies such as “skip all long sentences.”",7.1 Discussion,[0],[0]
"We discuss why LOLS does not help as much in the high accuracy regions further in §7.3.
",7.1 Discussion,[0],[0]
"In a few cases in Fig. 2, LOLS finds no policy that improves surrogate reward on dev data.",7.1 Discussion,[0],[0]
"In these cases, surrogate reward does improve slightly on training data (not shown), but early stopping just keeps the initial (baseline) policy since it is just as good on dev data.",7.1 Discussion,[0],[0]
"Adding a bit of additional random exploration might help break out of this initialization.
",7.1 Discussion,[0],[0]
"Interestingly, the rDP LOLS policies find higheraccuracy policies than the corresponding rCP policies, despite a greater mismatch in surrogate accuracy definitions.",7.1 Discussion,[0],[0]
"We suspect that rDP’s approach of trying to improve expected accuracy may provide a useful regularizing effect, which smooths out the reward signal and provides a useful bias (§5.3).
",7.1 Discussion,[0],[0]
"The most pronounced qualitative difference due to LOLS training is substantially lower rates of parse failure in the mid- to high- λ-range on both grammars
(not shown).",7.1 Discussion,[0],[0]
"Since LOLS does end-to-end training, it can advise the learner that a certain pruning decision catastrophically results in no parse being found.",7.1 Discussion,[0],[0]
Part of the contribution of this paper is faster algorithms for performing LOLS rollouts during training (§5).,7.2 Training speed and convergence,[0],[0]
"Compared to the naive strategy of running the parser from scratch T times, rCP achieves speedups of 4.9–6.6x on the coarse grammar and 1.9–2.4x on the fine grammar.",7.2 Training speed and convergence,[0],[0]
"rDP is even faster, 10.4–11.9x on coarse and 10.5–13.8x on fine.",7.2 Training speed and convergence,[0],[0]
"Most of the speedup comes from longer sentences, which take up most of the runtime for all methods.",7.2 Training speed and convergence,[0],[0]
Our new algorithms enable us to train on fairly long sentences (≤ 40).,7.2 Training speed and convergence,[0],[0]
"We note that our implementations of rCP and rDP are not as highly optimized as our test-time parser, so there may be room for improvement.
",7.2 Training speed and convergence,[0],[0]
Orthogonal to the cost per rollout is the number of training iterations.,7.2 Training speed and convergence,[0],[0]
"LOLS may take many steps to converge if trajectories are long (i.e., T is large)
because each iteration of LOLS training attempts to improve the current policy by a single action.",7.2 Training speed and convergence,[0],[0]
"In our setting, T is quite large (discussed extensively in §5), but we are able to circumvent slow convergence by initializing the policy (via the baseline method).",7.2 Training speed and convergence,[0],[0]
This means that LOLS can focus on fine-tuning a policy which is already quite good.,7.2 Training speed and convergence,[0],[0]
"In fact, in 4 cases, LOLS did not improve from its initial policy.
",7.2 Training speed and convergence,[0],[0]
We find that when λ is large—the cases where we get meaningful improvements because the initial policy is far from locally optimal—LOLS steadily and smoothly improves the surrogate reward on both training and development data.,7.2 Training speed and convergence,[0],[0]
"Because these are fast parsers, LOLS was able to run on the order of 10 (fine grammar) or 100 (coarse grammar) epochs within our 6-day limit; usually it was still improving when we terminated it.",7.2 Training speed and convergence,[0],[0]
"By contrast, for the slower and more accurate small-λ parsers (which completed fewer training epochs), LOLS still improves surrogate reward on training data, but without systematically improving on development data—often the reward on development fluctuates, and early stopping simply picks the best of this small set of “random” variants.",7.2 Training speed and convergence,[0],[0]
"In §3, we argued that LOLS gives a more appropriate training signal for pruning than the baseline method of consulting the gold parse, because it uses rollouts to measure the full effect of each pruning decision in the context of the other decisions made by the policy.
",7.3 Understanding the LOLS training signal,[0.9531065657636566],"['To remedy these problems, we propose methods to train a joint model across the multiple tag-sets of the different datasets, sharing statistical strength by using a single feature encoder across datasets while respecting the incompleteness of the labels during training.']"
"To better understand the results of our previous experiments, we analyze how often a rollout does determine that the baseline supervision for a span is suboptimal, and how suboptimal it is in those cases.
",7.3 Understanding the LOLS training signal,[0],[0]
We specifically consider LOLS rollouts that evaluate the rCP surrogate (because rDP is a cruder approximation to true reward).,7.3 Understanding the LOLS training signal,[0],[0]
"These rollouts Q̂i tell us what actions LOLS is trying to improve in its current policy πi for a given λ, although there is no guarantee that the learner in §4 will succeed at classifying Q̂i correctly (due to limited features, regularization, and the effects of dataset aggregation).
",7.3 Understanding the LOLS training signal,[0],[0]
We define regret of the baseline oracle.,7.3 Understanding the LOLS training signal,[0],[0]
"Let best(s) , argmaxaROLLOUT(π, s, a) and regret(s) , (ROLLOUT(π, s, best(s) − ROLLOUT(π, s, gold(s)))).",7.3 Understanding the LOLS training signal,[0],[0]
"Note that regret(s)≥0 for all s, and let diff(s) be the event that regret(s) > 0 strictly.",7.3 Understanding the LOLS training signal,[0],[0]
"We are interested in analyzing the expected regret over all gold and
non-gold spans, which we break down as
E[regret] = p(diff) (4) · ( p(gold | diff) · E[regret | gold, diff] + p(¬ gold | diff) · E[regret | ¬ gold, diff] )
where expectations are taken over s ∼ ROLL-IN(π).",7.3 Understanding the LOLS training signal,[0],[0]
"Empirical analysis of regret: To show where the benefit of the LOLS oracle comes from, Fig. 4 graphs the various quantities that enter into the definition (4) of baseline regret, for different π, λ, and grammar.",7.3 Understanding the LOLS training signal,[0],[0]
"The LOLS oracle evolves along with the policy π, since it identifies the best action given π.",7.3 Understanding the LOLS training signal,[0],[0]
"We thus evaluate the oracle baseline against two LOLS oracles: the one used at the start of LOLS training (derived from the initial policy π1 that was trained on baseline supervision), and the one obtained at the end (derived from the LOLS-trained policy π∗ selected by early stopping).",7.3 Understanding the LOLS training signal,[0],[0]
"These comparisons are shown by solid and dashed lines respectively.
",7.3 Understanding the LOLS training signal,[0],[0]
"Class imbalance (black curves): In all graphs, the aggregate curves primarily reflect the non-gold spans, since only 8% of spans are gold.
",7.3 Understanding the LOLS training signal,[0],[0]
"Gold spans (gold curves): The top graphs show that a substantial fraction of the gold spans should be pruned (whereas the baseline tries to keep them all), although the middle row shows that the benefit of pruning them is small.",7.3 Understanding the LOLS training signal,[0],[0]
"In most of these cases, pruning a gold span improves speed but leaves accuracy unchanged—because that gold span was missed anyway by the highest-scoring parse.",7.3 Understanding the LOLS training signal,[0],[0]
Such cases become both more frequent and more beneficial as λ increases and we prune more heavily.,7.3 Understanding the LOLS training signal,[0],[0]
"In a minority of cases, however, pruning a gold span also improves accuracy (through beneficial search error).
",7.3 Understanding the LOLS training signal,[0],[0]
"Non-gold spans (purple curves): Conversely, the top graphs show that a few non-gold spans should be kept (whereas the baseline tries to prune them all), and the middle row shows a large benefit from keeping them.",7.3 Understanding the LOLS training signal,[0],[0]
"They are needed to recover from catastrophic errors and get a mostly-correct parse.
",7.3 Understanding the LOLS training signal,[0],[0]
Coarse vs. fine (left vs. right):,7.3 Understanding the LOLS training signal,[0],[0]
"The two grammars differ mainly for small λ, and this difference comes especially from the top row.",7.3 Understanding the LOLS training signal,[0],[0]
"With a fine grammar and small λ, the baseline parses are more accurate, so LOLS has less room for improvement: fewer
gold spans go unused, and fewer non-gold spans are needed for recovery.
",7.3 Understanding the LOLS training signal,[0],[0]
"Effect of λ: Aggressive pruning (large λ) reduces accuracy, so its effect on the top row is similar to that of using a coarse grammar.",7.3 Understanding the LOLS training signal,[0],[0]
"Aggressive pruning also has an effect on the middle row: there is more benefit to be derived from pruning unused gold spans (surprisingly), and especially from keeping those non-gold spans that are helpful (presumably they enable recovery from more severe parse errors).",7.3 Understanding the LOLS training signal,[0],[0]
"These effects are considerably sharper with rDP reward (not shown here), which more smoothly evaluates the entire weighted pruned parse forest rather than trying to coordinate actions to ensure a good single 1-best tree; the baseline oracle is excellent at choosing the action that gets the better forest when the forest is mostly present (small λ) but not when it is mostly pruned (large λ).
",7.3 Understanding the LOLS training signal,[0],[0]
Effect on retraining the policy: The black lines in the bottom graphs show the overall regret (on training data) if we were to perfectly follow the baseline oracle rather than the LOLS oracle.,7.3 Understanding the LOLS training signal,[0],[0]
"In practice, retraining the policy to match the oracle will not match it perfectly in either case.",7.3 Understanding the LOLS training signal,[0],[0]
"Thus the baseline method has a further disadvantage: when it trains a policy, its training objective weights all gold or all non-gold examples equally, whereas LOLS invests greater effort in matching the oracle on those states where doing so would give greater downstream reward.",7.3 Understanding the LOLS training signal,[0],[0]
Our experiments have focused on using LOLS to improve a reasonable baseline.,8 Related work,[0],[0]
Fig. 5 shows that our resulting parser fits reasonably among state-of-the-art constituency parsers trained and tested on the Penn Treebank.,8 Related work,[0],[0]
These parsers include a variety of techniques that improve speed or accuracy.,8 Related work,[0],[0]
"Many are quite orthogonal to our work here—e.g., the SpMV method (which is necessary for Bodenstab’s parser to beat ours) is a set of cache-efficient optimizations (Dunlop, 2014) that could be added to our parser (just as it was added to Bodenstab’s), while Hall et al. (2014) and Fernández-González and Martins (2015) replace the grammar with faster scoring models that have more conditional independence.",8 Related work,[0],[0]
"Overall, other fast parsers could also be trained using LOLS, so that
they quickly find parses that are accurate, or at least helpful to the accuracy of some downstream task.
",8 Related work,[0],[0]
"Pruning methods14 can use classifiers not only to select spans but also to prune at other granularities (Roark and Hollingshead, 2008; Bodenstab et al., 2011).",8 Related work,[0],[0]
"Prioritization methods do not prune substructures, but instead delay their processing until they are needed—if ever (Caraballo and Charniak, 1998).
",8 Related work,[0],[0]
This paper focuses on learning pruning heuristics that have trainable parameters.,8 Related work,[0],[0]
"In the same way, Stoyanov and Eisner (2012) learn to turn off unneeded factors in a graphical model, and Jiang et al. (2012) and Berant and Liang (2015) train prioritization heuristics (using policy gradient).",8 Related work,[0],[0]
"In both of those 2012 papers, we explicitly sought to maximize accuracy − λ · runtime as we do here.",8 Related work,[0],[0]
"Some previous “coarse-to-fine” work does not optimize heuris-
14We focus here on parsing, but pruning is generally useful in structured prediction.",8 Related work,[0],[0]
"E.g., Xu et al. (2013) train a classifier to prune (latent) alignments in a machine translation system.
tics directly but rather derives heuristics for pruning (Charniak et al., 2006; Petrov and Klein, 2007; Weiss and Taskar, 2010; Rush and Petrov, 2012) or prioritization (Klein and Manning, 2003; Pauls and Klein, 2009) from a coarser version of the model.",8 Related work,[0],[0]
"Combining these automatic methods with LOLS would require first enriching their heuristics with trainable parameters, or parameterizing the coarse-to-fine hierarchy itself as in the “feature pruning” work of He et al. (2013) and Strubell et al. (2015).
",8 Related work,[0],[0]
Dynamic features are ones that depend on previous actions.,8 Related work,[0],[0]
"In our setting, a policy could in principle benefit from considering the full state of the chart at Alg. 1 line 14.",8 Related work,[0],[0]
"While coarse-to-fine methods implicitly use certain dynamic features, training with dynamic features is a fairly new goal that is challenging to treat efficiently.",8 Related work,[0],[0]
"It has usually been treated with some form of simple imitation learning, using a heuristic training signal much as in our baseline (Jiang, 2014; He et al., 2013).",8 Related work,[0],[0]
"LOLS would be a more principled way to train such features, but for efficiency, our present paper restricts to static features that only access the state via π(w, i, k).",8 Related work,[0],[0]
This permits our fast CP and DP rollout algorithms.,8 Related work,[0],[0]
"It also reduces the time and space cost of dataset aggregation.15
LOLS attempts to do end-to-end training of a sequential decision-making system, without falling back on black-box optimization tools (Och, 2003; Chung and Galley, 2012) that ignore the sequential structure.",8 Related work,[0],[0]
"In NLP, sequential decisions are more commonly trained with step-by-step supervision
15LOLS repeatedly evaluates actions given (w, i, k).",8 Related work,[0],[0]
"We consolidate the resulting training examples by summing their reward vectors r̂, so the aggregated dataset does not grow over time.
",8 Related work,[0],[0]
"(Kuhlmann et al., 2011), using methods such as local classification (Punyakanok and Roth, 2001) or beam search with early update (Collins and Roark, 2004).",8 Related work,[0],[0]
LOLS tackles the harder setting where the only training signal is a joint assessment of the entire sequence of actions.,8 Related work,[0],[0]
"It is an alternative to policy gradient, which does not scale well to our long trajectories because of high variance in the estimated gradient and because random exploration around (even good) pruning policies most often results in no parse at all.",8 Related work,[0],[0]
"LOLS uses controlled comparisons, resulting in more precise “credit assignment” and tighter exploration.
",8 Related work,[0],[0]
"We would be remiss not to note that current transition-based parsers—for constituency parsing (Zhu et al., 2013; Crabbé, 2015) as well as dependency parsing (Chen and Manning, 2014)—are both incredibly fast and surprisingly accurate.",8 Related work,[0],[0]
"This may appear to undermine the motivation for our work, or at least for its application to fast parsing.16",8 Related work,[0],[0]
"However, transition-based parsers do not produce marginal probabilities of substructures, which can be useful features for downstream tasks.",8 Related work,[0],[0]
"Indeed, the transitionbased approach is essentially greedy and so it may fail on tasks with more ambiguity than parsing.",8 Related work,[0],[0]
"Current transition-based parsers also require step-by-step supervision, whereas our method can also be used to train in the presence of incomplete supervision, latent structure, or indirect feedback.",8 Related work,[0],[0]
"Our method could also be used immediately to speed up dynamic programming methods for MT, synchronous parsing, parsing with non-context-free grammar formalisms, and other structured prediction problems for which transition systems have not (yet) been designed.",8 Related work,[0],[0]
We presented an approach to learning pruning policies that optimizes end-to-end performance on a userspecified speed-accuracy tradeoff.,9 Conclusions,[0],[0]
We developed two novel algorithms for efficiently measuring how varying policy actions affects reward.,9 Conclusions,[0],[0]
"In the case of parsing, given a performance criterion and a good baseline policy for that criterion, the learner consistently manages to find a higher-reward policy.",9 Conclusions,[0],[0]
"We hope this work inspires a new generation of fast and accurate structured prediction models with tunable runtimes.
16Of course, LOLS can also train transition-based parsers (Chang et al., 2015a), or even vary their beam width dynamically.",9 Conclusions,[0],[0]
This material is based in part on research sponsored by the National Science Foundation under Grant No. 0964681 and DARPA under agreement number FA8750-13-2-0017 (DEFT program).,Acknowledgments,[0],[0]
"We’d like to thank Nathaniel Wesley Filardo, Adam Teichert, Matt Gormley and Hal Daumé III for helpful discussions.",Acknowledgments,[0],[0]
"Finally, we thank TACL action editor Marco Kuhlmann and the anonymous reviewers and copy editor for suggestions that improved this paper.",Acknowledgments,[0],[0]
Pruning hypotheses during dynamic programming is commonly used to speed up inference in settings such as parsing.,abstractText,[0],[0]
"Unlike prior work, we train a pruning policy under an objective that measures end-to-end performance: we search for a fast and accurate policy.",abstractText,[0],[0]
"This poses a difficult machine learning problem, which we tackle with the LOLS algorithm.",abstractText,[0],[0]
"LOLS training must continually compute the effects of changing pruning decisions: we show how to make this efficient in the constituency parsing setting, via dynamic programming and change propagation algorithms.",abstractText,[0],[0]
"We find that optimizing end-to-end performance in this way leads to a better Pareto frontier—i.e., parsers which are more accurate for a given runtime.",abstractText,[0],[0]
Learning to Prune: Exploring the Frontier of Fast and Accurate Parsing,title,[0],[0]
Deep neural networks (DNNs) have been widely used for machine learning applications due to their powerful capacity for modeling complex input patterns.,1. Introduction,[0],[0]
"Despite their success, it has been shown that DNNs are prone to training set biases, i.e. the training set is drawn from a joint distribution p(x, y) that is different from the distribution p(xv, yv) of the evaluation set.",1. Introduction,[0],[0]
"This distribution mismatch could have many
1Uber Advanced Technologies Group, Toronto ON, CANADA 2Department of Computer Science, University of Toronto, Toronto ON, CANADA.",1. Introduction,[0],[0]
"Correspondence to: Mengye Ren <mren3@uber.com>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
different forms.",1. Introduction,[0],[0]
Class imbalance in the training set is a very common example.,1. Introduction,[0],[0]
"In applications such as object detection in the context of autonomous driving, the vast majority of the training data is composed of standard vehicles but models also need to recognize rarely seen classes such as emergency vehicles or animals with very high accuracy.",1. Introduction,[0],[0]
"This will sometime lead to biased training models that do not perform well in practice.
",1. Introduction,[0],[0]
Another popular type of training set bias is label noise.,1. Introduction,[0],[0]
"To train a reasonable supervised deep model, we ideally need a large dataset with high-quality labels, which require many passes of expensive human quality assurance (QA).",1. Introduction,[0],[0]
"Although coarse labels are cheap and of high availability, the presence of noise will hurt the model performance, e.g. Zhang et al. (2017) has shown that a standard CNN can fit any ratio of label flipping noise in the training set and eventually leads to poor generalization performance.
",1. Introduction,[0],[0]
"Training set biases and misspecification can sometimes be addressed with dataset resampling (Chawla et al., 2002), i.e. choosing the correct proportion of labels to train a network on, or more generally by assigning a weight to each example and minimizing a weighted training loss.",1. Introduction,[0],[0]
"The example weights are typically calculated based on the training loss, as in many classical algorithms such as AdaBoost (Freund & Schapire, 1997), hard negative mining (Malisiewicz et al., 2011), self-paced learning (Kumar et al., 2010), and other more recent work (Chang et al., 2017; Jiang et al., 2017).
",1. Introduction,[0],[0]
"However, there exist two contradicting ideas in training loss based approaches.",1. Introduction,[0],[0]
"In noisy label problems, we prefer examples with smaller training losses as they are more likely to be clean images; yet in class imbalance problems, algorithms such as hard negative mining (Malisiewicz et al., 2011) prioritize examples with higher training loss since they are more likely to be the minority class.",1. Introduction,[0],[0]
"In cases when the training set is both imbalanced and noisy, these existing methods would have the wrong model assumptions.",1. Introduction,[0],[0]
"In fact, without a proper definition of an unbiased test set, solving the training set bias problem is inherently ill-defined.",1. Introduction,[0],[0]
"As the model cannot distinguish the right from the wrong, stronger regularization can usually work surprisingly well in certain synthetic noise settings.",1. Introduction,[0],[0]
"Here we argue that in order to learn general forms of training set biases, it is necessary to have a small unbiased validation to guide training.",1. Introduction,[0],[0]
"It is actually
not uncommon to construct a dataset with two parts - one relatively small but very accurately labeled, and another massive but coarsely labeled.",1. Introduction,[0],[0]
"Coarse labels can come from inexpensive crowdsourcing services or weakly supervised data (Cordts et al., 2016; Russakovsky et al., 2015; Chen & Gupta, 2015).
",1. Introduction,[0],[0]
"Different from existing training loss based approaches, we follow a meta-learning paradigm and model the most basic assumption instead: the best example weighting should minimize the loss of a set of unbiased clean validation examples that are consistent with the evaluation procedure.",1. Introduction,[0.9532655613294254],['We propose and evaluate a simple heuristic procedure for merging the outputs of the different CRF predictions.']
"Traditionally, validation is performed at the end of training, which can be prohibitively expensive if we treat the example weights as some hyperparameters to optimize; to circumvent this, we perform validation at every training iteration to dynamically determine the example weights of the current batch.",1. Introduction,[0],[0]
"Towards this goal, we propose an online reweighting method that leverages an additional small validation set and adaptively assigns importance weights to examples in every iteration.",1. Introduction,[0],[0]
We experiment with both class imbalance and corrupted label problems and find that our approach significantly increases the robustness to training set biases.,1. Introduction,[0],[0]
The idea of weighting each training example has been well studied in the literature.,2. Related Work,[0],[0]
"Importance sampling (Kahn & Marshall, 1953), a classical method in statistics, assigns weights to samples in order to match one distribution to another.",2. Related Work,[0],[0]
"Boosting algorithms such as AdaBoost (Freund & Schapire, 1997), select harder examples to train subsequent classifiers.",2. Related Work,[0],[0]
"Similarly, hard example mining (Malisiewicz et al., 2011), downsamples the majority class and exploits the most difficult examples.",2. Related Work,[0],[0]
"Focal loss (Lin et al., 2017) adds a soft weighting scheme that emphasizes harder examples.
",2. Related Work,[0],[0]
Hard examples are not always preferred in the presence of outliers and noise processes.,2. Related Work,[0],[0]
Robust loss estimators typically downweigh examples with high loss.,2. Related Work,[0],[0]
"In selfpaced learning (Kumar et al., 2010), example weights are obtained through optimizing the weighted training loss encouraging learning easier examples first.",2. Related Work,[0],[0]
"In each step, the learning algorithm jointly solves a mixed integer program that iterates optimizing over model parameters and binary example weights.",2. Related Work,[0],[0]
"Various regularization terms on the example weights have since been proposed to prevent overfitting and trivial solutions of assigning weights to be all zeros (Kumar et al., 2010; Ma et al., 2017; Jiang et al., 2015).",2. Related Work,[0],[0]
Wang et al. (2017) proposed a Bayesian method that infers the example weights as latent variables.,2. Related Work,[0],[0]
"More recently, Jiang et al. (2017) proposed to use a meta-learning LSTM to output the weights of the examples based on the training loss.",2. Related Work,[0],[0]
"Reweighting examples is also related to curriculum learning (Bengio et al., 2009), where the model reweights
among many available tasks.",2. Related Work,[0],[0]
"Similar to self-paced learning, typically it is beneficial to start with easier examples.
",2. Related Work,[0],[0]
One crucial advantage of reweighting examples is robustness against training set bias.,2. Related Work,[0],[0]
"There has also been a multitude of prior studies on class imbalance problems, including using dataset resampling (Chawla et al., 2002; Dong et al., 2017), cost-sensitive weighting (Ting, 2000; Khan et al., 2015), and structured margin based objectives (Huang et al., 2016).",2. Related Work,[0],[0]
"Meanwhile, the noisy label problem has been thoroughly studied by the learning theory community (Natarajan et al., 2013; Angluin & Laird, 1988) and practical methods have also been proposed (Reed et al., 2014; Sukhbaatar & Fergus, 2014; Xiao et al., 2015; Azadi et al., 2016; Goldberger & Ben-Reuven, 2017; Li et al., 2017; Jiang et al., 2017; Vahdat, 2017; Hendrycks et al., 2018).",2. Related Work,[0],[0]
"In addition to corrupted data, Koh & Liang (2017); Muñoz-González et al. (2017) demonstrate the possibility of a dataset adversarial attack (i.e. dataset poisoning).
",2. Related Work,[0],[0]
"Our method improves the training objective through a weighted loss rather than an average loss and is an instantiation of meta-learning (Thrun & Pratt, 1998; Lake et al., 2017; Andrychowicz et al., 2016), i.e. learning to learn better.",2. Related Work,[0],[0]
"Using validation loss as the meta-objective has been explored in recent meta-learning literature for few-shot learning (Ravi & Larochelle, 2017; Ren et al., 2018; Lorraine & Duvenaud, 2018), where only a handful of examples are available for each class.",2. Related Work,[0],[0]
"Our algorithm also resembles MAML (Finn et al., 2017) by taking one gradient descent step on the meta-objective for each iteration.",2. Related Work,[0],[0]
"However, different from these meta-learning approaches, our reweighting method does not have any additional hyperparameters and circumvents an expensive offline training stage.",2. Related Work,[0],[0]
"Hence, our method can work in an online fashion during regular training.",2. Related Work,[0],[0]
"In this section, we derive our model from a meta-learning objective towards an online approximation that can fit into any regular supervised training.",3. Learning to Reweight Examples,[0],[0]
We give a practical implementation suitable for any deep network type and provide theoretical guarantees under mild conditions that our algorithm has a convergence rate of O(1/ 2).,3. Learning to Reweight Examples,[0],[0]
Note that this is the same as that of stochastic gradient descent (SGD).,3. Learning to Reweight Examples,[0],[0]
"Let (x, y) be an input-target pair, and {(xi, yi), 1 ≤",3.1. From a meta-learning objective to an online approximation,[0],[0]
i ≤ N} be the training set.,3.1. From a meta-learning objective to an online approximation,[0],[0]
"We assume that there is a small unbiased and clean validation set {(xvi , yvi ), 1 ≤ i ≤M}, and M N .",3.1. From a meta-learning objective to an online approximation,[0],[0]
"Hereafter, we will use superscript v to denote validation set and subscript i to denote the ith data.",3.1. From a meta-learning objective to an online approximation,[0],[0]
"We also assume
that the training set contains the validation set; otherwise, we can always add this small validation set into the training set and leverage more information during training.
",3.1. From a meta-learning objective to an online approximation,[0],[0]
"Let Φ(x, θ) be our neural network model, and θ be the model parameters.",3.1. From a meta-learning objective to an online approximation,[0],[0]
"We consider a loss function C(ŷ, y) to minimize during training, where ŷ = Φ(x, θ).
",3.1. From a meta-learning objective to an online approximation,[0],[0]
"In standard training, we aim to minimize the expected loss for the training set: 1N ∑N i=1",3.1. From a meta-learning objective to an online approximation,[0],[0]
"C(ŷi, yi) = 1 N ∑N i=1 fi(θ), where each input example is weighted equally, and fi(θ) stands for the loss function associating with data xi.",3.1. From a meta-learning objective to an online approximation,[0],[0]
"Here we aim to learn a reweighting of the inputs, where we minimize a weighted loss:
θ∗(w) = arg min θ N∑ i=1",3.1. From a meta-learning objective to an online approximation,[0],[0]
"wifi(θ), (1)
with wi unknown upon beginning.",3.1. From a meta-learning objective to an online approximation,[0],[0]
"Note that {wi}Ni=1 can be understood as training hyperparameters, and the optimal selection of w is based on its validation performance:
w∗ = arg min w,w≥0
1
M M∑ i=1",3.1. From a meta-learning objective to an online approximation,[0],[0]
fvi,3.1. From a meta-learning objective to an online approximation,[0],[0]
(θ ∗(w)).,3.1. From a meta-learning objective to an online approximation,[0],[0]
"(2)
It is necessary that wi ≥ 0 for all i, since minimizing the negative training loss can usually result in unstable behavior.
",3.1. From a meta-learning objective to an online approximation,[0],[0]
"Online approximation Calculating the optimal wi requires two nested loops of optimization, and every single loop can be very expensive.",3.1. From a meta-learning objective to an online approximation,[0],[0]
The motivation of our approach is to adapt online w through a single optimization loop.,3.1. From a meta-learning objective to an online approximation,[0],[0]
"For each training iteration, we inspect the descent direction of some training examples locally on the training loss surface and reweight them according to their similarity to the descent direction of the validation loss surface.
",3.1. From a meta-learning objective to an online approximation,[0],[0]
"For most training of deep neural networks, SGD or its variants are used to optimize such loss functions.",3.1. From a meta-learning objective to an online approximation,[0],[0]
"At every step t of training, a mini-batch of training examples {(xi, yi), 1 ≤ i ≤ n} is sampled, where n is the mini-batch size, n N .",3.1. From a meta-learning objective to an online approximation,[0],[0]
Then the parameters are adjusted according to the descent direction of the expected loss on the mini-batch.,3.1. From a meta-learning objective to an online approximation,[0],[0]
"Let’s consider vanilla SGD:
θt+1 = θt − α∇
( 1
n n∑ i=1",3.1. From a meta-learning objective to an online approximation,[0],[0]
"fi(θt)
) , (3)
where α is the step size.
",3.1. From a meta-learning objective to an online approximation,[0],[0]
We want to understand what would be the impact of training example,3.1. From a meta-learning objective to an online approximation,[0],[0]
"i towards the performance of the validation set at training step t. Following a similar analysis to Koh & Liang (2017), we consider perturbing the weighting by i for each
training example in the mini- batch,
fi, (θ) = ifi(θ), (4)
θ̂t+1( ) = θt − α∇ n∑ i=1",3.1. From a meta-learning objective to an online approximation,[0],[0]
"fi, (θ) ∣∣∣ θ=θt .",3.1. From a meta-learning objective to an online approximation,[0],[0]
"(5)
We can then look for the optimal ∗ that minimizes the validation loss fv locally at step t:
∗t = arg min
1
M M∑ i=1",3.1. From a meta-learning objective to an online approximation,[0],[0]
fvi (θt+1( )).,3.1. From a meta-learning objective to an online approximation,[0],[0]
"(6)
Unfortunately, this can still be quite time-consuming.",3.1. From a meta-learning objective to an online approximation,[0],[0]
"To get a cheap estimate of wi at step t, we take a single gradient descent step on a mini-batch of validation samples wrt. t, and then rectify the output to get a non-negative weighting:
ui,t = −η ∂
∂",3.1. From a meta-learning objective to an online approximation,[0],[0]
"i,t
1
m m∑ j=1 fvj (θt+1( )) ∣∣∣",3.1. From a meta-learning objective to an online approximation,[0],[0]
"i,t=0 , (7)
w̃i,t = max(ui,t, 0).",3.1. From a meta-learning objective to an online approximation,[0],[0]
"(8)
where η is the descent step size on .
",3.1. From a meta-learning objective to an online approximation,[0],[0]
"To match the original training step size, in practice, we can consider normalizing the weights of all examples in a training batch so that they sum up to one.",3.1. From a meta-learning objective to an online approximation,[0],[0]
"In other words, we choose to have a hard constraint within the set {w : ‖w‖1 = 1} ∪ {0}.
wi,t = w̃i,t ( ∑ j w̃j,t) + δ",3.1. From a meta-learning objective to an online approximation,[0],[0]
"( ∑ j w̃j,t) , (9)
where δ(·) is to prevent the degenerate case when all wi’s in a mini-batch are zeros, i.e. δ(a) = 1 if a = 0, and equals to 0 otherwise.",3.1. From a meta-learning objective to an online approximation,[0],[0]
"Without the batch-normalization step, it is possible that the algorithm modifies its effective learning rate of the training progress, and our one-step look ahead may be too conservative in terms of the choice of learning rate (Wu et al., 2018).",3.1. From a meta-learning objective to an online approximation,[0],[0]
"Moreover, with batch normalization, we effectively cancel the meta learning rate parameter η.",3.1. From a meta-learning objective to an online approximation,[0],[0]
"In this section, we study how to compute wi,t in a multilayer perceptron (MLP) network.",3.2. Example: learning to reweight examples in a multi-layer perceptron network,[0],[0]
One of the core steps is to compute the gradients of the validation loss wrt.,3.2. Example: learning to reweight examples in a multi-layer perceptron network,[0],[0]
"the local perturbation , We can consider a multi-layered network where we have parameters for each layer θ = {θl}Ll=1, and at every layer, we first compute zl the pre-activation, a weighted sum of inputs to the layer, and afterwards we apply a non-linear activation function σ to obtain z̃l the post-activation:
zl = θ > l z̃l−1, (10)
z̃l = σ(zl).",3.2. Example: learning to reweight examples in a multi-layer perceptron network,[0],[0]
"(11)
During backpropagation, let gl be the gradients of loss wrt. zl, and the gradients wrt.",3.2. Example: learning to reweight examples in a multi-layer perceptron network,[0],[0]
θl is given by z̃l−1g>l .,3.2. Example: learning to reweight examples in a multi-layer perceptron network,[0],[0]
"We can further express the gradients towards as a sum of local dot products.
∂ ∂",3.2. Example: learning to reweight examples in a multi-layer perceptron network,[0],[0]
"i,t E [ fv(θt+1( )) ∣∣∣",3.2. Example: learning to reweight examples in a multi-layer perceptron network,[0],[0]
"i,t=0 ] ∝− 1
m m∑ j=1 ∂fvj (θ) ∂θ ∣∣∣",3.2. Example: learning to reweight examples in a multi-layer perceptron network,[0],[0]
>,3.2. Example: learning to reweight examples in a multi-layer perceptron network,[0],[0]
θ=θt ∂fi(θ) ∂θ ∣∣∣ θ,3.2. Example: learning to reweight examples in a multi-layer perceptron network,[0],[0]
"=θt
=− 1 m m∑ j=1 L∑ l=1",3.2. Example: learning to reweight examples in a multi-layer perceptron network,[0],[0]
"(z̃vj,l−1 >z̃i,l−1)(g v j,l >gi,l).
",3.2. Example: learning to reweight examples in a multi-layer perceptron network,[0],[0]
"(12)
Detailed derivations can be found in Supplementary Materials.",3.2. Example: learning to reweight examples in a multi-layer perceptron network,[0],[0]
Eq. 12 suggests that the meta-gradient on is composed of the sum of the products of two terms: z>zv and g>gv.,3.2. Example: learning to reweight examples in a multi-layer perceptron network,[0],[0]
"The first dot product computes the similarity between the training and validation inputs to the layer, while the second computes the similarity between the training and validation gradient directions.",3.2. Example: learning to reweight examples in a multi-layer perceptron network,[0],[0]
"In other words, suppose that a pair of training and validation examples are very similar, and they also provide similar gradient directions, then this training example is helpful and should be up-weighted, and conversely, if they provide opposite gradient directions, this training example is harmful and should be downweighed.",3.2. Example: learning to reweight examples in a multi-layer perceptron network,[0],[0]
"In an MLP and a CNN, the unnormalized weights can be calculated based on the sum of the correlations of layerwise activation gradients and input activations.",3.3. Implementation using automatic differentiation,[0],[0]
"In more general networks, we can leverage automatic differentiation techniques to compute the gradient of the validation loss wrt.",3.3. Implementation using automatic differentiation,[0],[0]
the example weights of the current batch.,3.3. Implementation using automatic differentiation,[0],[0]
"As shown in Figure 1, to get the gradients of the example weights, one needs to first unroll the gradient graph of the training batch, and then use backward-on-backward automatic differentiation to take a second order gradient
pass (see Step 5 in Figure 1).",3.3. Implementation using automatic differentiation,[0],[0]
We list detailed step-bystep pseudo-code in Algorithm 1.,3.3. Implementation using automatic differentiation,[0],[0]
"This implementation can be generalized to any deep learning architectures and can be very easily implemented using popular deep learning frameworks such as TensorFlow (Abadi et al., 2016).
",3.3. Implementation using automatic differentiation,[0],[0]
"Algorithm 1 Learning to Reweight Examples using Automatic Differentiation Require: θ0, Df , Dg , n, m Ensure: θT
1: for t = 0 ...",3.3. Implementation using automatic differentiation,[0],[0]
T,3.3. Implementation using automatic differentiation,[0],[0]
"− 1 do 2: {Xf , yf} ← SampleMiniBatch(Df , n) 3: {Xg, yg} ← SampleMiniBatch(Dg , m) 4: ŷf ← Forward(Xf , yf , θt) 5: ← 0; lf ← ∑n i=1",3.3. Implementation using automatic differentiation,[0],[0]
"iC(yf,i, ŷf,i) 6: ∇θt ← BackwardAD(lf , θt) 7: θ̂t ← θt − α∇θt 8: ŷg",3.3. Implementation using automatic differentiation,[0],[0]
"← Forward(Xg, yg, θ̂t) 9: lg ← 1m ∑m i=1",3.3. Implementation using automatic differentiation,[0],[0]
"C(yg,i, ŷg,i)
10: ∇ ← BackwardAD(lg, ) 11:",3.3. Implementation using automatic differentiation,[0],[0]
"w̃ ← max(−∇ , 0); w ← w̃∑
j w̃+δ( ∑ j w̃)
12: l̂f ← ∑n i=1",3.3. Implementation using automatic differentiation,[0],[0]
"wiC(yi, ŷf,i) 13: ∇θt",3.3. Implementation using automatic differentiation,[0],[0]
"← BackwardAD(l̂f , θt) 14: θt+1 ← OptimizerStep(θt,∇θt) 15: end for
Training time Our automatic reweighting method will introduce a constant factor of overhead.",3.3. Implementation using automatic differentiation,[0],[0]
"First, it requires two full forward and backward passes of the network on training and validation respectively, and then another backward on backward pass (Step 5 in Figure 1), to get the gradients to the example weights, and finally a backward pass to minimize the reweighted objective.",3.3. Implementation using automatic differentiation,[0],[0]
"In modern networks, a backwardon-backward pass usually takes about the same time as a forward pass, and therefore compared to regular training, our method needs approximately 3× training time; it is also possible to reduce the batch size of the validation pass for speedup.",3.3. Implementation using automatic differentiation,[0],[0]
"We expect that it is worthwhile to spend the extra time to avoid the irritation of choosing early stopping, finetuning schedules, and other hyperparameters.",3.3. Implementation using automatic differentiation,[0],[0]
"Convergence results of SGD based optimization methods are well-known (Reddi et al., 2016).",3.4. Analysis: convergence of the reweighted training,[0],[0]
"However it is still meaningful to establish a convergence result about our method since it involves optimization of two-level objectives (Eq. 1, 2) rather than one, and we further make some firstorder approximation by introducing Eq. 7.",3.4. Analysis: convergence of the reweighted training,[0],[0]
"Here, we show theoretically that our method converges to the critical point of the validation loss function under some mild conditions, and we also give its convergence rate.",3.4. Analysis: convergence of the reweighted training,[0],[0]
"More detailed proofs can be found in the Supplementary Materials.
",3.4. Analysis: convergence of the reweighted training,[0],[0]
Definition 1.,3.4. Analysis: convergence of the reweighted training,[0],[0]
"A function f(x) : Rd → R is said to be Lipschitz-smooth with constant L if
‖∇f(x)−∇f(y)‖ ≤",3.4. Analysis: convergence of the reweighted training,[0],[0]
"L‖x− y‖,∀x, y ∈ Rd.
Definition 2. f(x) has σ-bounded gradients if ‖∇f(x)‖ ≤ σ for all x ∈ Rd.
",3.4. Analysis: convergence of the reweighted training,[0],[0]
"In most real-world cases, the high-quality validation set is really small, and thus we could set the mini-batch size m to be the same as the size of the validation set M .",3.4. Analysis: convergence of the reweighted training,[0],[0]
"Under this condition, the following lemma shows that our algorithm always converges to a critical point of the validation loss.",3.4. Analysis: convergence of the reweighted training,[0],[0]
"However, our method is not equivalent to training a model only on this small validation set.",3.4. Analysis: convergence of the reweighted training,[0],[0]
Because directly training a model on a small validation set will lead to severe overfitting issues.,3.4. Analysis: convergence of the reweighted training,[0],[0]
"On the contrary, our method can leverage useful information from a larger training set, and still converge to an appropriate distribution favored by this clean and balanced validation dataset.",3.4. Analysis: convergence of the reweighted training,[0],[0]
"This helps both generalization and robustness to biases in the training set, which will be shown in our experiments.
",3.4. Analysis: convergence of the reweighted training,[0],[0]
Lemma 1.,3.4. Analysis: convergence of the reweighted training,[0],[0]
"Suppose the validation loss function is Lipschitzsmooth with constant L, and the train loss function fi of training data xi have σ-bounded gradients.",3.4. Analysis: convergence of the reweighted training,[0],[0]
"Let the learning rate αt satisfies αt ≤ 2nLσ2 , where n is the training batch size.",3.4. Analysis: convergence of the reweighted training,[0],[0]
"Then, following our algorithm, the validation loss always monotonically decreases for any sequence of training batches, namely,
G(θt+1) ≤ G(θt), (13)
where G(θ) is the total validation loss
G(θ) = 1
M M∑ i=1",3.4. Analysis: convergence of the reweighted training,[0],[0]
fvi (θt+1( )).,3.4. Analysis: convergence of the reweighted training,[0],[0]
"(14)
Furthermore, in expectation, the equality in Eq. 13 holds only when the gradient of validation loss becomes 0 at some time step t, namely Et [G(θt+1)]",3.4. Analysis: convergence of the reweighted training,[0],[0]
"= G(θt) if and only if ∇G(θt) = 0, where the expectation is taking over possible training batches at time step t.
Moreover, we can prove the convergence rate of our method to be O(1/ 2).
",3.4. Analysis: convergence of the reweighted training,[0],[0]
Theorem 2.,3.4. Analysis: convergence of the reweighted training,[0],[0]
"Suppose G, fi and αt satisfy the aforementioned conditions, then Algorithm 1 achieves E",3.4. Analysis: convergence of the reweighted training,[0],[0]
[ ‖∇G(θt)‖2 ] ≤ in O(1/ 2) steps.,3.4. Analysis: convergence of the reweighted training,[0],[0]
"More specifically,
min 0<t<T
E [ ‖∇G(θt)‖2 ] ≤ C√
T , (15)
where C is some constant independent of the convergence process.",3.4. Analysis: convergence of the reweighted training,[0],[0]
"To test the effectiveness of our reweighting algorithm, we designed both class imbalance and noisy label settings, and a combination of both, on standard MNIST and CIFAR benchmarks for image classification using deep CNNs.",4. Experiments,[0],[0]
We use the standard MNIST handwritten digit classification dataset and subsample the dataset to generate a class imbalance binary classification task.,4.1. MNIST data imbalance experiments,[0],[0]
"We select a total of 5,000 images of size 28×28 on class 4 and 9, where 9 dominates the training data distribution.",4.1. MNIST data imbalance experiments,[0],[0]
We train a standard LeNet on this task and we compare our method with a suite of commonly used tricks for class imbalance: 1) PROPORTION weights each example by the inverse frequency 2),4.1. MNIST data imbalance experiments,[0],[0]
"RESAMPLE samples a class-balanced minibatch for each iteration 3) HARD MINING selects the highest loss examples from the majority class and 4) RANDOM is a random example weight baseline that assigns weights based on a rectified Gaussian distribution:
wrndi = max(zi, 0)∑",4.1. MNIST data imbalance experiments,[0],[0]
"i max(zi, 0) , where zi ∼ N (0, 1).",4.1. MNIST data imbalance experiments,[0],[0]
"(16)
To make sure that our method does not have the privilege of training on more data, we split the balanced validation set of 10 images directly from the training set.",4.1. MNIST data imbalance experiments,[0],[0]
"The network is trained with SGD with a learning rate of 1e-3 and mini-batch size of 100 for a total of 8,000 steps.
",4.1. MNIST data imbalance experiments,[0],[0]
Figure 2 plots the test error rate across various imbalance ratios averaged from 10 runs with random splits.,4.1. MNIST data imbalance experiments,[0],[0]
Note that our method significantly outperforms all the baselines.,4.1. MNIST data imbalance experiments,[0],[0]
"With class imbalance ratio of 200:1, our method only reports a small increase of error rate around 2%, whereas other methods suffer terribly under this setting.",4.1. MNIST data imbalance experiments,[0],[0]
"Compared with resampling and hard negative mining baselines, our approach does not throw away samples based on its class or training loss - as long as a sample is helpful towards the validation loss, it will be included as a part of the training loss.",4.1. MNIST data imbalance experiments,[0],[0]
Reweighting algorithm can also be useful on datasets where the labels are noisy.,4.2. CIFAR noisy label experiments,[0],[0]
"We study two settings of label noise here:
• UNIFORMFLIP: All label classes can uniformly flip to any other label classes, which is the most studied in the literature.",4.2. CIFAR noisy label experiments,[0],[0]
• BACKGROUNDFLIP:,4.2. CIFAR noisy label experiments,[0],[0]
All label classes can flip to a single background class.,4.2. CIFAR noisy label experiments,[0],[0]
This noise setting is very realistic.,4.2. CIFAR noisy label experiments,[0],[0]
"For instance, human annotators may not have recognized all the positive instances, while the
rest remain in the background class.",4.2. CIFAR noisy label experiments,[0],[0]
"This is also a combination of label imbalance and label noise since the background class usually dominates the label distribution.
",4.2. CIFAR noisy label experiments,[0],[0]
"We compare our method with prior work on the noisy label problem.
",4.2. CIFAR noisy label experiments,[0],[0]
"• REED, proposed by Reed et al. (2014), is a bootstrapping technique where the training target is a convex combination of the model prediction and the label.
",4.2. CIFAR noisy label experiments,[0],[0]
"• S-MODEL, proposed by Goldberger & Ben-Reuven (2017), adds a fully connected softmax layer after the regular classification output layer to model the noise transition matrix.
",4.2. CIFAR noisy label experiments,[0],[0]
"• MENTORNET, proposed by Jiang et al. (2017), is an RNN-based meta-learning model that takes in a sequence of loss values and outputs the example weights.",4.2. CIFAR noisy label experiments,[0],[0]
"We compare numbers reported in their paper with a base model that achieves similar test accuracy under 0% noise.
",4.2. CIFAR noisy label experiments,[0],[0]
"In addition, we propose two simple baselines: 1) RANDOM, which assigns weights according to a rectified Gaussian (see Eq. 16); 2) WEIGHTED, designed for BACKGROUNDFLIP, where the model knows the oracle noise ratio for each class and reweights the training loss proportional to the percentage of clean images of that label class.
",4.2. CIFAR noisy label experiments,[0],[0]
"Clean validation set For UNIFORMFLIP, we use 1,000 clean images in the validation set; for BACKGROUNDFLIP, we use 10 clean images per label class.",4.2. CIFAR noisy label experiments,[0],[0]
"Since our method uses information from the clean validation, for a fair comparison, we conduct an additional finetuning on the clean data based on the pre-trained baselines.",4.2. CIFAR noisy label experiments,[0],[0]
"We also study the effect on the size of the clean validation set in an ablation study.
",4.2. CIFAR noisy label experiments,[0],[0]
"Hyper-validation set For monitoring training progress and tuning baseline hyperparameters, we split out another
5,000 hyper-validation set from the 50,000 training images.",4.2. CIFAR noisy label experiments,[0],[0]
"We also corrupt the hyper-validation set with the same noise type.
",4.2. CIFAR noisy label experiments,[0],[0]
"Experimental details For REED model, we use the best β reported in Reed et al. (2014) (β = 0.8 for hard bootstrapping and β = 0.95 for soft bootstrapping).",4.2. CIFAR noisy label experiments,[0],[0]
"For the S-MODEL, we explore two versions to initialize the transition weights: 1) a smoothed identity matrix; 2) in background flip experiments we consider initializing the transition matrix with the confusion matrix of a pre-trained baseline model (S-MODEL +CONF).",4.2. CIFAR noisy label experiments,[0],[0]
"We find baselines can easily overfit the training noise, and therefore we also study early stopped versions of the baselines to provide a stronger comparison.",4.2. CIFAR noisy label experiments,[0],[0]
"In contrast, we find early stopping not necessary for our method.
",4.2. CIFAR noisy label experiments,[0],[0]
"To make our results comparable with the ones reported in MENTORNET and to save computation time, we exchange their Wide ResNet-101-10 with a Wide ResNet28-10 (WRN-28-10) (Zagoruyko & Komodakis, 2016) with dropout 0.3 as our base model in the UNIFORMFLIP experiments.",4.2. CIFAR noisy label experiments,[0],[0]
We find that test accuracy differences between the two base models are within 0.5% on CIFAR datasets under 0% noise.,4.2. CIFAR noisy label experiments,[0],[0]
"In the BACKGROUNDFLIP experiments, we use a ResNet-32 (He et al., 2016) as our base model.
",4.2. CIFAR noisy label experiments,[0],[0]
"We train the models with SGD with momentum, at an initial learning rate 0.1 and a momentum 0.9 with mini-batch size 100.",4.2. CIFAR noisy label experiments,[0],[0]
"For ResNet-32 models, the learning rate decays×0.1 at 40K and 60K steps, for a total of 80K steps.",4.2. CIFAR noisy label experiments,[0],[0]
"For WRN and early stopped versions of ResNet-32 models, the learning rate decays at 40K and 50K steps, for a total of 60K steps.",4.2. CIFAR noisy label experiments,[0],[0]
"Under regular 0% noise settings, our base ResNet-32 gets 92.5% and 68.1% classification accuracy on CIFAR-10 and 100, and the WRN-28-10 gets 95.5% and 78.2%.",4.2. CIFAR noisy label experiments,[0],[0]
"For the finetuning stage, we run extra 5K steps of training on the
CLEAN ONLY 15.90 ± 3.32 8.06 ± 0.76 BASELINE +FT 82.82 ± 0.93 54.23 ± 1.75 BASELINE +ES +FT 85.19 ± 0.46 55.22 ± 1.40 WEIGHTED +FT 85.98 ± 0.47 53.99 ± 1.62 S-MODEL +CONF +FT 81.90 ± 0.85 53.11 ± 1.33 S-MODEL +CONF +ES +FT 85.86 ± 0.63 55.75 ± 1.26
OURS 86.73 ± 0.48 59.30 ± 0.60
limited clean data.
",4.2. CIFAR noisy label experiments,[0],[0]
"We report the average test accuracy for 5 different random splits of clean and noisy labels, with 95% confidence interval in Table 1 and 2.",4.2. CIFAR noisy label experiments,[0],[0]
"The background classes for the 5 trials are [0, 1, 3, 5, 7] (CIFAR-10) and [7, 12, 41, 62, 85] (CIFAR-100).",4.2. CIFAR noisy label experiments,[0],[0]
"The first result that draws our attention is that “Random” performs surprisingly well on the UNIFORMFLIP benchmark, outperforming all historical methods that we compared.",4.3. Results and Discussion,[0],[0]
"Given that its performance is comparable with Baseline on BACKGROUNDFLIP and MNIST class imbalance, we hypothesize that random example weights act as a strong regularizer and under which the learning objective on UNIFORMFLIP is still consistent.
",4.3. Results and Discussion,[0],[0]
"Regardless of the strong baseline, our method ranks the top on both UNIFORMFLIP and BACKGROUNDFLIP, showing our method is less affected by the changes in the noise type.",4.3. Results and Discussion,[0],[0]
"On CIFAR-100, our method wins more than 3% compared to the state-of-the-art method.
",4.3. Results and Discussion,[0],[0]
Understanding the reweighting mechanism It is beneficial to understand how our reweighting algorithm contributes to learning more robust models during training.,4.3. Results and Discussion,[0],[0]
"First, we use a pre-trained model (trained at half of the total iterations without learning rate decay) and measure the example weight distribution of a randomly sampled batch of validation images, which the model has never seen.",4.3. Results and Discussion,[0],[0]
"As shown in the left figure of Figure 3, our model correctly
pushes most noisy images to zero weights.",4.3. Results and Discussion,[0],[0]
"Secondly, we conditioned the input mini-batch to be a single nonbackground class and randomly flip 40% of the images to the background, and we would like to see how well our model can distinguish clean and noisy images.",4.3. Results and Discussion,[0],[0]
"As shown in Figure 3 right, the model is able to reliably detect images that are flipped to the background class.
",4.3. Results and Discussion,[0],[0]
"Robustness to overfitting noise Throughout experimentation, we find baseline models can easily overfit to the noise in the training set.",4.3. Results and Discussion,[0],[0]
"For example, shown in Table 2, applying early stopping (“ES”) helps the classification performance of “S-Model” by over 10% on CIFAR-10.",4.3. Results and Discussion,[0],[0]
"Figure 6 compares the final confusion matrices of the baseline and the proposed algorithm, where a large proportion of noise transition probability is cleared in the final prediction.",4.3. Results and Discussion,[0],[0]
Figure 7 shows training curves on the BACKGROUNDFLIP experiments.,4.3. Results and Discussion,[0],[0]
"After the first learning rate decay, both “Baseline” and “SModel” quickly degrade their validation performance due to overfitting, while our model remains the same validation accuracy until termination.",4.3. Results and Discussion,[0],[0]
"Note that here “S-Model” knows the oracle noise ratio in each class, and this information is
not available in our method.
",4.3. Results and Discussion,[0],[0]
Impact of the noise level We would like to investigate how strongly our method can perform on a variety of noise levels.,4.3. Results and Discussion,[0],[0]
"Shown in Figure 5, our method only drops 6% accuracy when the noise ratio increased from 0% to 50%;
whereas the baseline has dropped more than 40%.",4.3. Results and Discussion,[0],[0]
"At 0% noise, our method only slightly underperforms baseline.",4.3. Results and Discussion,[0],[0]
"This is reasonable since we are optimizing on the validation set, which is strictly a subset of the full training set, and therefore suffers from its own subsample bias.
",4.3. Results and Discussion,[0],[0]
"Size of the clean validation set When the size of the clean validation set grows larger, fine-tuning on the validation set will be a reasonble approach.",4.3. Results and Discussion,[0],[0]
"Here, we make an attempt to explore the tradeoff and understand when fine-tuning becomes beneficial.",4.3. Results and Discussion,[0],[0]
Figure 4 plots the classification performance when we varied the size of the clean validation on BACKGROUNDFLIP.,4.3. Results and Discussion,[0],[0]
"Surprisingly, using 15 validation images for all classes only results in a 2% drop in performance, and the overall classification performance does not grow after having more than 100 validation images.",4.3. Results and Discussion,[0],[0]
"In comparison, we observe a significant drop in performance when only fine-tuning on these 15 validation images for the baselines, and the performance catches up around using 1,000 validation images (100 per class).",4.3. Results and Discussion,[0],[0]
"This phenomenon suggests that in our method the clean validation acts more like a regularizer rather than a data source for parameter finetuning, and potentially our method can be complementary with fine-tuning based method when the size of the clean set grows larger.",4.3. Results and Discussion,[0],[0]
"In this work, we propose an online meta-learning algorithm for reweighting training examples and training more robust deep learning models.",5. Conclusion,[0],[0]
"While various types of training set biases exist and manually designed reweighting objectives have their own bias, our automatic reweighting algorithm shows superior performance dealing with class imbalance, noisy labels, and both.",5. Conclusion,[0],[0]
Our method can be directly applied to any deep learning architecture and is expected to train end-to-end without any additional hyperparameter search.,5. Conclusion,[0],[0]
"Validating on every training step is a novel setting and we show that it has links with model regularization, which can be a fruitful future research direction.",5. Conclusion,[0],[0]
Deep neural networks have been shown to be very powerful modeling tools for many supervised learning tasks involving complex input patterns.,abstractText,[0],[0]
"However, they can also easily overfit to training set biases and label noises.",abstractText,[0],[0]
"In addition to various regularizers, example reweighting algorithms are popular solutions to these problems, but they require careful tuning of additional hyperparameters, such as example mining schedules and regularization hyperparameters.",abstractText,[0],[0]
"In contrast to past reweighting methods, which typically consist of functions of the cost value of each example, in this work we propose a novel meta-learning algorithm that learns to assign weights to training examples based on their gradient directions.",abstractText,[0],[0]
"To determine the example weights, our method performs a meta gradient descent step on the current mini-batch example weights (which are initialized from zero) to minimize the loss on a clean unbiased validation set.",abstractText,[0],[0]
"Our proposed method can be easily implemented on any type of deep network, does not require any additional hyperparameter tuning, and achieves impressive performance on class imbalance and corrupted label problems where only a small amount of clean validation data is available.",abstractText,[0],[0]
Learning to Reweight Examples for Robust Deep Learning,title,[0],[0]
"Many natural language processing (NLP) and computer vision problems necessitate predicting structured outputs such as labeled sequences, trees or general graphs (Smith, 2010; Nowozin & Lampert, 2011).",1. Introduction,[0],[0]
Such tasks require modeling both input-output relationships and the interactions between predicted outputs to capture correlations.,1. Introduction,[0],[0]
"Across the various structured prediction formulations (Lafferty et al., 2001; Taskar et al., 2003; Chang et al., 2012), prediction requires solving inference problems by searching for scoremaximizing output structures.",1. Introduction,[0],[0]
"The search space for inference is typically large (e.g., all parse trees), and grows with input size.",1. Introduction,[0],[0]
"Exhaustive search can be prohibitive and standard alternatives are either: (a) perform exact inference with a large computational cost or, (b) approximate inference to sacrifice accuracy in favor of time.
",1. Introduction,[0],[0]
"1School of Computing, University of Utah, Salt Lake City, Utah, USA.",1. Introduction,[0],[0]
"Correspondence to: Xingyuan Pan <xpan@cs.utah.edu>, Vivek Srikumar <svivek@cs.utah.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"In this paper, we focus on the computational cost of inference.",1. Introduction,[0],[0]
"We argue that naturally occurring problems have remarkable regularities across both inputs and outputs, and traditional formulations of inference ignore them.",1. Introduction,[0],[0]
"For example, parsing an n-word sentence will cost a standard head-driven lexical parser O(n5) time.",1. Introduction,[0],[0]
Current practice in NLP is to treat each new sentence as a fresh discrete optimization problem and pay the computational price each time.,1. Introduction,[0],[0]
"However, this practice is not only expensive, but also wasteful!",1. Introduction,[0],[0]
"We ignore the fact that slight changes to inputs often do not change the output, or even the sequence of steps taken to produce it.",1. Introduction,[0],[0]
"Moreover, not all outputs are linguistically meaningful structures; as we make more predictions, we should be able to learn to prune the output space.
",1. Introduction,[0],[0]
The motivating question that drives our work is: Can we design inference schemes that learn to make a trained structured predictor faster without sacrificing output quality?,1. Introduction,[0],[0]
"After training, the structured classifier can be thought as a black-box.",1. Introduction,[0],[0]
"Typically, once deployed, it is never modified over its lifetime of classifying new examples.",1. Introduction,[0],[0]
"Subsequently, we can view each prediction of the black-box classifier as an opportunity to learn how to navigate the output space more efficiently.",1. Introduction,[0],[0]
"Thus, if the classifier sees a previously encountered situation, it could make some decisions without needless computations.
",1. Introduction,[0],[0]
We formalize this intuition by considering the trained models as solving arbitrary integer linear programs (ILPs) for combinatorial inference.,1. Introduction,[0],[0]
"We train a second, inexpensive speedup classifier which acts as a heuristic for a searchbased inference algorithm that mimics the more expensive black-box classifier.",1. Introduction,[0],[0]
The speedup heuristic is a function that learns regularities among predicted structures.,1. Introduction,[0],[0]
"We present a mistake bound algorithm that, over the classifier’s lifetime, learns to navigate the feasible regions of the ILPs.",1. Introduction,[0],[0]
"By doing so, we can achieve a reduction in inference time.
",1. Introduction,[0],[0]
We further identify inference situations where the learned speedup heuristic alone can correctly label parts of the outputs without computing the corresponding input features.,1. Introduction,[0],[0]
"In such situations, the search algorithm can safely ignore parts of inputs if the corresponding outputs can be decided based on the sub-structures constructed so far.",1. Introduction,[0],[0]
"Seen this way, the speedup classifier can be seen as a statistical cache of past decisions made by the black-box classifier.
",1. Introduction,[0],[0]
We instantiate our strategy to the task of predicting entities and relations from sentences.,1. Introduction,[0],[0]
"Using an ILP based black-box classifier, we show that the trained speedup classifier mimics the reference inference algorithm to obtain improvements in running time, and also recovers its accuracy.",1. Introduction,[0],[0]
"Indeed, by learning to ignore input components when they will not change the prediction, we show that learned search strategy outperforms even greedy search in terms of speed.
",1. Introduction,[0],[0]
"To summarize, the main contribution of this paper is the formalization of the problem of learning to make structured output classifiers faster without sacrificing accuracy.",1. Introduction,[0],[0]
We develop a learning-to-search framework to train a speedup classifier with a mistake-bound guarantee and a sufficient condition to safely avoid computing input-based features.,1. Introduction,[0],[0]
"We show empirically on an entity-relation extraction task that we can learn a speedup classifier that is (a) faster than both the state-of-the-art Gurobi optimizer and greedy search, and (b) does not incur a loss in output quality.",1. Introduction,[0],[0]
"First, we will define the notation used in this paper with a running example that requires of identifying entity types and their relationships in text.",2. Notation and Preliminaries,[0],[0]
"The input to the problem consists of sentences such as:
Colin went back home in Ordon Village.
",2. Notation and Preliminaries,[0],[0]
"These inputs are typically preprocessed — here, we are given spans of text (underlined) corresponding to entities.",2. Notation and Preliminaries,[0],[0]
"We will denote such preprocessed inputs to the structured prediction problem as x.
We seek to produce a structure y ∈",2. Notation and Preliminaries,[0],[0]
"Yx (e.g., labeled trees, graphs) associated with these inputs.",2. Notation and Preliminaries,[0],[0]
"Here, Yx is the set of all possible output structures for the input x.",2. Notation and Preliminaries,[0],[0]
"In the example problem, our goal is to assign types to the entities and also label the relationships between them.",2. Notation and Preliminaries,[0],[0]
"Suppose our task has three types of entities: person, location and organization.",2. Notation and Preliminaries,[0],[0]
"A pair of entities can participate in one of five possible directed relations: Kill, LiveIn, WorkFor, LocatedAt and OrgBasedIn.",2. Notation and Preliminaries,[0],[0]
"Additionally, there is a special entity label NoEnt meaning a text span is not an entity, and a special relation label NoRel indicating that two spans are unrelated.",2. Notation and Preliminaries,[0],[0]
"Figure 1 shows a plausible structure for the example sentence as per this scheme.
",2. Notation and Preliminaries,[0],[0]
A standard way to model the prediction problem requires learning a model that scores all structures in Yx and searching for the score-maximizing structure.,2. Notation and Preliminaries,[0],[0]
"Linear models are commonly used as scoring functions, and require a feature vector characterizing input-output relationships Φ (x,y).",2. Notation and Preliminaries,[0],[0]
We will represent the model by a weight vector α.,2. Notation and Preliminaries,[0],[0]
"Every structure y associated with an input x is scored as the dot product α · Φ (x,y).",2. Notation and Preliminaries,[0],[0]
"The goal of prediction is to find the
structure y∗ that maximizes this score.",2. Notation and Preliminaries,[0],[0]
"That is,
y∗ = arg max y∈Yx α ·",2. Notation and Preliminaries,[0],[0]
"Φ (x,y) .",2. Notation and Preliminaries,[0],[0]
"(1)
Learning involves using training data to find the best weight vector α.
",2. Notation and Preliminaries,[0],[0]
"In general, the output structure y is a set of K categorical inference variables {y1, y2, · · · , yK} , each of which can take a value from a predefined set of n labels.",2. Notation and Preliminaries,[0],[0]
"That is, each yk ∈ y takes a value from {l1, l2, · · · , ln}.1 In our running example, the inference variables correspond to the four decisions that define the structure: the labels for the two entities, and the relations in each direction.",2. Notation and Preliminaries,[0],[0]
"The feature function Φ decomposes into a sum of features over each yk, each denoted by Φk, giving us the inference problem:
y∗ = arg max y∈Yx K∑",2. Notation and Preliminaries,[0],[0]
k=1 α ·,2. Notation and Preliminaries,[0],[0]
"Φk ( x, yk ) .",2. Notation and Preliminaries,[0],[0]
"(2)
The dependencies between the yk’s specify the nature of the output space.",2. Notation and Preliminaries,[0],[0]
Determining each yk in isolation greedily does not typically represent a viable inference strategy because constraints connecting the variables are ignored.,2. Notation and Preliminaries,[0],[0]
"In this spirit, the problem of finding the best structure can be viewed as a combinatorial optimization problem.
",2. Notation and Preliminaries,[0],[0]
"In this paper, we consider the scenario in which we have already trained a model α.",2. Notation and Preliminaries,[0],[0]
"We focus on solving the inference problem (i.e.,Eq.",2. Notation and Preliminaries,[0],[0]
(2)) efficiently.,2. Notation and Preliminaries,[0],[0]
We conjecture that it should be possible to observe a black-box inference algorithm over its lifetime to learn to predict faster without losing accuracy.,2. Notation and Preliminaries,[0],[0]
One common way to solve inference is by designing efficient dynamic programming algorithms that exploit problem structure.,2.1. Black-box Inference Mechanisms,[0],[0]
"While effective, this approach is limited to special cases where the problem admits efficient decoding, thus placing restrictions on factorization and feature design.
",2.1. Black-box Inference Mechanisms,[0],[0]
"In this paper, we seek to reason about the problem of predicting structures in the general case.",2.1. Black-box Inference Mechanisms,[0],[0]
"Since inference is essentially a combinatorial optimization problem, without loss
1We make this choice for simplicity of notation.",2.1. Black-box Inference Mechanisms,[0],[0]
"In general, K depends on the size of the input x, and categorical variables may take values from different label sets.
of generality, we can represent any inference problem as an integer linear programming (ILP) instance (Schrijver, 1998).",2.1. Black-box Inference Mechanisms,[0],[0]
To represent the inference task in Eq.,2.1. Black-box Inference Mechanisms,[0],[0]
"(2) as an ILP instance, we will define indicator variables of the form zki ∈ {0, 1}, which stands for the decision that the categorical variable yk is assigned the ith label among the n labels.",2.1. Black-box Inference Mechanisms,[0],[0]
"That is, zki = 1 if yk = li, and 0 otherwise.",2.1. Black-box Inference Mechanisms,[0],[0]
"Using this notation, we can write the cost of any structure y in terms of the indicators as
K∑ k=1 n∑ i=1",2.1. Black-box Inference Mechanisms,[0],[0]
cki,2.1. Black-box Inference Mechanisms,[0],[0]
z,2.1. Black-box Inference Mechanisms,[0],[0]
k,2.1. Black-box Inference Mechanisms,[0],[0]
i .,2.1. Black-box Inference Mechanisms,[0],[0]
"(3)
Here, cki is a stand in for −α ·",2.1. Black-box Inference Mechanisms,[0],[0]
"Φk (x, li), namely the cost (negative score) associated with this decision.2",2.1. Black-box Inference Mechanisms,[0],[0]
"In our example, suppose the first categorical variable y1 corresponds to the entity Colin, and it has possible labels {person,location, . . .",2.1. Black-box Inference Mechanisms,[0],[0]
}.,2.1. Black-box Inference Mechanisms,[0],[0]
"Then, assigning person to Colin would correspond to setting z11 = 1, and z 1 i = 0 for all i 6= 1.",2.1. Black-box Inference Mechanisms,[0],[0]
"Using the labels enumerated in §2, there will be 20 indicators for the four categorical decisions.
",2.1. Black-box Inference Mechanisms,[0],[0]
"Of course, arbitrary assignments to the indicators is not allowed.",2.1. Black-box Inference Mechanisms,[0],[0]
We can define the set of feasible structures using linear constraints.,2.1. Black-box Inference Mechanisms,[0],[0]
"Clearly, each categorical variable can take exactly one label, which can be expressed via:
n∑ i=1 zki = 1, for all k. (4)
",2.1. Black-box Inference Mechanisms,[0],[0]
"In addition, we can define the set of valid structures Yx using a collection of m linear constraints, the jth one of which can be written as
K∑ k=1 n∑ i=1",2.1. Black-box Inference Mechanisms,[0],[0]
"Akjiz k i = bj , for all j. (5)
",2.1. Black-box Inference Mechanisms,[0],[0]
These structural constraints characterize the interactions between the categorical variables.,2.1. Black-box Inference Mechanisms,[0],[0]
"For example, if a directed edge in our running example is labeled as LiveIn, then, its source and target must be a person and a location respectively.",2.1. Black-box Inference Mechanisms,[0],[0]
"While Eq.(5) only shows equality constraints, in practice, inequality constraints can also be included.
",2.1. Black-box Inference Mechanisms,[0],[0]
The inference problem in Eq.,2.1. Black-box Inference Mechanisms,[0],[0]
(2) is equivalent to the problem of minimizing the objective in Eq.,2.1. Black-box Inference Mechanisms,[0],[0]
(3) over the 0-1 indicator variables subject to the constraints in Eqs.,2.1. Black-box Inference Mechanisms,[0],[0]
"(4) and (5).
",2.1. Black-box Inference Mechanisms,[0],[0]
We should note the difference between the ability to write an inference problem as an ILP instance and actually solving it as one.,2.1. Black-box Inference Mechanisms,[0],[0]
"The former gives us the ability to reason about inference in general, and perhaps using other methods (such as Lagrangian relaxation (Lemaréchal, 2001)) for inference.",2.1. Black-box Inference Mechanisms,[0],[0]
"However, solving problems with industrial strength ILP
2The negation defines an equivalent minimization problem and makes subsequent description of the search framework easier.
solvers such as the Gurobi solver3 is competitive with other approaches in terms of inference time, even though they may not directly exploit problem structure.
",2.1. Black-box Inference Mechanisms,[0],[0]
"In this work, we use the general structure of the ILP inference formulation to develop the theory for speeding up inference.",2.1. Black-box Inference Mechanisms,[0],[0]
"In addition, because of its general applicability and fast inference speed, we use the Gurobi ILP solver as our black-box classifier, and learn a speedup heuristic to make even faster inference.",2.1. Black-box Inference Mechanisms,[0],[0]
Directly applying the black-box solver for the large output spaces may be impractical.,2.2. Inference as Search,[0],[0]
An alternative general purpose strategy for inference involves framing the maximization in Eq.,2.2. Inference as Search,[0],[0]
"(2) as a graph search problem.
",2.2. Inference as Search,[0],[0]
"Following Russell & Norvig (2003); Xu et al. (2009), a general graph search problem requires defining an initial search node I , a successor function s(·), and a goal test.",2.2. Inference as Search,[0],[0]
The successor function s(·) maps a search node to its successors.,2.2. Inference as Search,[0],[0]
The goal test determines whether a node is a goal node.,2.2. Inference as Search,[0],[0]
"Usually, each search step is associated with a cost function, and we seek to find a goal node with the least total cost.
",2.2. Inference as Search,[0],[0]
We can define the search problem corresponding to inference as follows.,2.2. Inference as Search,[0],[0]
"We will denote a generic search node in the graph as v, which corresponds to a set of partially assigned categorical variables.",2.2. Inference as Search,[0],[0]
"Specifically, we will define the search node v as a set of pairs {(k, i)}, each element of which specifies that the variable yk is assigned the ith label.",2.2. Inference as Search,[0],[0]
The initial search node I is the empty set since none of the variables has been assigned when the search begins.,2.2. Inference as Search,[0],[0]
"For a node v, its successors s(v) is a set of nodes, each containing one more assigned variable than v. A node is a goal node if all variables yk’s have been assigned.",2.2. Inference as Search,[0],[0]
"The size of any goal node is K, the number of categorical variables.
",2.2. Inference as Search,[0],[0]
"In our running example, at the start of search, we may choose to assign the first label l1 (person) to the variable y1 – the entity Colin – leading us to the successor {(1, 1)}.",2.2. Inference as Search,[0],[0]
Every search node specifies a partial or a full assignment to all the entities and relations.,2.2. Inference as Search,[0],[0]
"The goal test simply checks if we arrive at a full assignment, i.e., all the entity and relation candidates have been assigned a label.
",2.2. Inference as Search,[0],[0]
"Note that goal test does not test the quality of the node, it simply tests whether the search process is finished.",2.2. Inference as Search,[0],[0]
"The quality of the goal node is determined by the path cost from the initial node to the goal node, which is the accumulated cost of each step along the way.",2.2. Inference as Search,[0],[0]
The step cost for assigning label li to a variable yk is the same cki we defined for the ILP objective in Eq.,2.2. Inference as Search,[0],[0]
(3).,2.2. Inference as Search,[0],[0]
"Finding a shortest path in such a search space is equivalent to the original ILP problem
3http://www.gurobi.com
without the structural constraints in Eq.",2.2. Inference as Search,[0],[0]
(5).,2.2. Inference as Search,[0],[0]
The uniquelabel constraints in Eq.,2.2. Inference as Search,[0],[0]
"(4) are automatically satisfied by our formulation of the search process.
",2.2. Inference as Search,[0],[0]
"Indeed, solving inference without the constraints in Eq.(5) is trivial.",2.2. Inference as Search,[0],[0]
"For each categorical variable yk, we can pick the label li that has the lowest value of cki .",2.2. Inference as Search,[0],[0]
"This gives us two possible options for solving inference as search: We can (a) ignore the constraints that make inference slow to greedily predict all the labels, or, (b) enforce constraints at each step of the search, and only consider search nodes that satisfy all constraints.",2.2. Inference as Search,[0],[0]
"The first option is fast, but can give us outputs that are invalid.",2.2. Inference as Search,[0],[0]
"For example, we might get a structure that mandates that the person Colin lives in a person called Ordon Village.",2.2. Inference as Search,[0],[0]
"The second option will give us structurally valid outputs, but can be prohibitively slow.
",2.2. Inference as Search,[0],[0]
Various graph search algorithms can be used for performing inference.,2.2. Inference as Search,[0],[0]
"For efficiency, we can use beam search with a fixed beam width b.",2.2. Inference as Search,[0],[0]
When search begins the beam B0 contains only the initial node B0 =,2.2. Inference as Search,[0],[0]
[I].,2.2. Inference as Search,[0],[0]
"Following Collins & Roark (2004); Xu et al. (2009), we define the function BreadthExpand which takes the beam Bt at step t and generates the candidates Ct+1 for the next beam:
Ct+1 = BreadthExpand(Bt) = ∪v∈Bts(v)
The next beam is given by Bt+1 = Filter(Ct+1), where Filter takes top b nodes according to some priority function p(v).",2.2. Inference as Search,[0],[0]
"In the simplest case, the priority of a node v is the total path cost of reaching that node.",2.2. Inference as Search,[0],[0]
"More generally, the priority function can be informed not only by the path cost, but also by a heuristic function as in the popular A∗ algorithm.",2.2. Inference as Search,[0],[0]
"In the previous section, we saw that using a black-box ILP solver may be slower than greedy search which ignores constraints, but produces valid outputs.",3. Speeding up Structured Prediction,[0],[0]
"However, over its lifetime, a trained classifier predicts structures for a large number of inputs.",3. Speeding up Structured Prediction,[0],[0]
"While the number of unique inputs (e.g. sentences) may be large, the number of unique structures that actually occur among the predictions is not only finite, but also small.",3. Speeding up Structured Prediction,[0],[0]
"This observation was exploited by Srikumar et al. (2012); Kundu et al. (2013) for amortizing inference costs.
",3. Speeding up Structured Prediction,[0],[0]
"In this paper, we are driven by the need for an inference algorithm that learns regularities across outputs to become faster at producing structurally valid outputs.",3. Speeding up Structured Prediction,[0],[0]
"In order to do so, we will develop an inference-as-search scheme that inherits the speed of greedy search, but learns to produce structurally valid outputs.",3. Speeding up Structured Prediction,[0],[0]
"Before developing the algorithmic aspects of such an inference scheme, let us first see a proofof-concept for such a scheme.",3. Speeding up Structured Prediction,[0],[0]
Our goal is to incorporate the structural constraints from Eq.,3.1. Heuristics for Structural Validity,[0],[0]
(5) as a heuristic for greedy or beam search.,3.1. Heuristics for Structural Validity,[0],[0]
"To do so, at each step during search, we need to estimate how likely an assignment can lead to a constraint violation.",3.1. Heuristics for Structural Validity,[0],[0]
"This information can be characterized by using a heuristic function h(v), which will be used to evaluated a node v during search.
",3.1. Heuristics for Structural Validity,[0],[0]
The dual form the ILP in Eqs.,3.1. Heuristics for Structural Validity,[0],[0]
(3) to (5) help justify the idea of capturing constraint information using a heuristic function.,3.1. Heuristics for Structural Validity,[0],[0]
We treat the unique label constraints in Eq.,3.1. Heuristics for Structural Validity,[0],[0]
"(4) as defining the domain in which each 0-1 variable zki lives, and the only real constraints are given by Eq. (5).
Let uj represent the dual variable for the jth constraint.",3.1. Heuristics for Structural Validity,[0],[0]
"Thus, we obtain the Lagrangian4
L(z, u) =",3.1. Heuristics for Structural Validity,[0],[0]
K∑,3.1. Heuristics for Structural Validity,[0],[0]
k=1 n∑ i=1,3.1. Heuristics for Structural Validity,[0],[0]
cki z,3.1. Heuristics for Structural Validity,[0],[0]
k i,3.1. Heuristics for Structural Validity,[0],[0]
− m∑ j=1 uj (,3.1. Heuristics for Structural Validity,[0],[0]
K∑ k=1 n∑ i=1,3.1. Heuristics for Structural Validity,[0],[0]
Akjiz k i,3.1. Heuristics for Structural Validity,[0],[0]
"− bj )
",3.1. Heuristics for Structural Validity,[0],[0]
"= ∑ k,i cki",3.1. Heuristics for Structural Validity,[0],[0]
"−∑ j ujA k ji  zki +∑ j bjuj
",3.1. Heuristics for Structural Validity,[0],[0]
"The dual function θ(u) = minz L(z, u), where the minimization is over the domain of the z variables.
",3.1. Heuristics for Structural Validity,[0],[0]
Denote u∗ = arg max θ(u) as the solution to the dual problem.,3.1. Heuristics for Structural Validity,[0],[0]
"In the case of zero duality gap, the theory of Lagrangian relaxation (Lemaréchal, 2001) tells us that solving the following relaxed minimization problem will solve the original ILP:
min ∑ k,i cki",3.1. Heuristics for Structural Validity,[0],[0]
"−∑ j u∗jA k ji  zki (6)∑ i zki = 1, for all k (7) zki ∈ {0, 1}, for all k, i (8)
This new optimization problem does not have any structural constraints and can be solved greedily for each k if we know the optimal dual variables u∗.
To formulate the minimization in Eqs (6) to (8) as a search problem, we define the priority function p(v) for ranking the nodes as p(v) = g(v) + h∗(v), where the path cost g(v) and heuristic function h∗(v) are given by
g(v) = ∑
(k,i)∈v
cki , (9)
h∗(v) =",3.1. Heuristics for Structural Validity,[0],[0]
"− ∑
(k,i)∈v ∑ j Akjiu ∗ j (x).",3.1. Heuristics for Structural Validity,[0],[0]
"(10)
Since Eq. (6) is a minimization problem, smaller priority value p(v) means higher ranking during search.",3.1. Heuristics for Structural Validity,[0],[0]
"Note that
4We omit the ranges of the summation indices",3.1. Heuristics for Structural Validity,[0],[0]
"i, j, k hereafter.
even though heuristic function defined in this way is not always admissible, greedy search with ranking function p(v) will lead to the exact solution of Eqs.",3.1. Heuristics for Structural Validity,[0],[0]
(6) to (8).,3.1. Heuristics for Structural Validity,[0],[0]
"In practice, however, we do not have the optimal values for the dual variables u∗.",3.1. Heuristics for Structural Validity,[0],[0]
"Indeed, when Lagrangian relaxation is used for inference, the optmial dual variables are computed using subgradient optimization for each example because their value depends on the original input via the c’s.
",3.1. Heuristics for Structural Validity,[0],[0]
"Instead of performing expensive gradient based optimization for every input instance, we will approximate the heuristic function as a classifier that learns to prioritize structurally valid outputs.",3.1. Heuristics for Structural Validity,[0],[0]
"In this paper, we use a linear model based on a weight vector w to approximate the heuristic as
h(v) = −w · φ(v) (11)
",3.1. Heuristics for Structural Validity,[0],[0]
"For an appropriate choice of node features φ(v), the heuristic h(v) in Eq.(10) is indeed a linear function.5",3.1. Heuristics for Structural Validity,[0],[0]
"In other words, there exists a linear heuristic function that can guide graph search towards creating structurally valid outputs.
",3.1. Heuristics for Structural Validity,[0],[0]
"In this setting, the priority function p(v) for each node is determined by two components: the path cost g(v) from the initial node to the current node, and the learned heuristic cost h(v), which is an estimate of how good the current node is.",3.1. Heuristics for Structural Validity,[0],[0]
"Because the purpose of the heuristic is to help improve inference speed, we call φ(v) speedup features.",3.1. Heuristics for Structural Validity,[0],[0]
The speedup features can be different from the original model features in Eq.,3.1. Heuristics for Structural Validity,[0],[0]
(2).,3.1. Heuristics for Structural Validity,[0],[0]
In particular it can includes features for partial assignments made so far which were not available in the original model features.,3.1. Heuristics for Structural Validity,[0],[0]
"In this setting, the goal of speedup learning is to find suitable weight vector w over the black-box classifier’s lifetime.",3.1. Heuristics for Structural Validity,[0],[0]
"In this section, we will describe a mistake-bound algorithm to learn the weight vector w of the speedup classifier.",4. Learning the Speedup Classifier,[0],[0]
"The design of this algorithm is influenced by learning to search algorithms such as LaSO (Daumé III & Marcu, 2005; Xu et al., 2009).",4. Learning the Speedup Classifier,[0],[0]
"We assume that we have access to a trained black-box ILP solver called Solve, which can solve the structured prediction problems, and we have a large set of examples {xi}Ni=1.",4. Learning the Speedup Classifier,[0],[0]
Our goal is to use this set to train a speedup classifier to mimic the ILP solver while predicting structures for this set of examples.,4. Learning the Speedup Classifier,[0],[0]
"Subsequently, we can use the less expensive speedup influenced search procedure to replace the ILP solver.
",4. Learning the Speedup Classifier,[0],[0]
"To define the algorithm, we will need additional terminology.",4. Learning the Speedup Classifier,[0],[0]
"Given a reference solution y, we define a node v to be ygood, if it can possibly lead to the reference solution.",4. Learning the Speedup Classifier,[0],[0]
"If a node v is y-good, then the already assigned variables have the same labels as in the reference solution.",4. Learning the Speedup Classifier,[0],[0]
"We define a
5See supplementary material for an elaboration.
",4. Learning the Speedup Classifier,[0],[0]
"Algorithm 1 Learning a speedup classifier using examples {xi}Ni=1, and a black-box Solver Solve.
1: Initialize the speedup weight vector w← 0 2: for epoch = 1 . .",4. Learning the Speedup Classifier,[0],[0]
.M,4. Learning the Speedup Classifier,[0],[0]
do 3: for i = 1 . . .,4. Learning the Speedup Classifier,[0],[0]
N,4. Learning the Speedup Classifier,[0],[0]
do 4: y← Solve(xi) 5: Initialize the beam B ←,4. Learning the Speedup Classifier,[0],[0]
"[I] 6: while B is y-good and v̂ is not goal do 7: B ← Filter(BreadthExpand(B)) 8: end while 9: if B is not y-good then
10: v∗ ← SetGood(v̂) 11: w←",4. Learning the Speedup Classifier,[0],[0]
w + φ(v∗)− 1|B| ∑ v∈B φ(v) 12: else if v̂ is not y-good then 13: v∗ ← SetGood(v̂) 14: w←,4. Learning the Speedup Classifier,[0],[0]
"w + φ(v∗)− φ(v̂) 15: end if 16: end for 17: end for
beam B is y",4. Learning the Speedup Classifier,[0],[0]
-good if it contains at least one y-good node to represent the notion that search is still viable.,4. Learning the Speedup Classifier,[0],[0]
"We denote the first element (the highest ranked) in a beam by v̂. Finally, we define an operator SetGood, which takes a node that is not y-good, and return its corresponding y-good node by fixing the incorrect assignments according to the reference solution.",4. Learning the Speedup Classifier,[0],[0]
"The unassigned variables are still left unassigned by the SetGood operator.
",4. Learning the Speedup Classifier,[0],[0]
The speedup-learning algorithm is listed as Algorithm 1.,4. Learning the Speedup Classifier,[0],[0]
It begins by initializing the weight w to the zero vector.,4. Learning the Speedup Classifier,[0],[0]
We iterate over the examples for M epochs.,4. Learning the Speedup Classifier,[0],[0]
"For each example xi, we first solve inference using the ILP solver to obtain the reference structure y (line 4).",4. Learning the Speedup Classifier,[0],[0]
Next a breadth-expand search is performed (lines 5-8).,4. Learning the Speedup Classifier,[0],[0]
"Every time the beam B is updated, we check if the beam contains at least one ygood node that can possibly lead to the reference solution y. Search terminates if the beam is not y-good, or if the highest ranking node v̂ is a goal.",4. Learning the Speedup Classifier,[0],[0]
"If the beam is not y-good, we compute the corresponding y-good node v∗ from v̂, and perform a perceptron style update to the speedup weights (line 9-11).",4. Learning the Speedup Classifier,[0],[0]
"In other words, we update the weight vector by adding feature vector of φ(v∗), and subtracting the average feature vector of all the nodes in the beam.",4. Learning the Speedup Classifier,[0],[0]
Otherwise v̂ must be a goal node.,4. Learning the Speedup Classifier,[0],[0]
We then check if v̂ agrees with the reference solution (lines 12-15).,4. Learning the Speedup Classifier,[0],[0]
"If not, we perform a similar weight update, by adding the feature vector of φ(v∗), and subtracting φ(v̂).
",4. Learning the Speedup Classifier,[0],[0]
"Mistake bound Next, we show that the Algorithm 1 has a mistake bound.",4. Learning the Speedup Classifier,[0],[0]
"Let Rφ be a positive constant such that for every pair of nodes (v, v′), we have ‖φ(v)− φ(v′)‖ ≤ Rφ.",4. Learning the Speedup Classifier,[0],[0]
"Let Rg be a positive constant such that for every pair of
search nodes (v, v′), we have |g(v)− g(v′)| ≤",4. Learning the Speedup Classifier,[0],[0]
Rg .,4. Learning the Speedup Classifier,[0],[0]
"Finally we define the level margin of a weight vector w for a training set as
γ = min",4. Learning the Speedup Classifier,[0],[0]
"{(v,v′)}
",4. Learning the Speedup Classifier,[0],[0]
"w · ( φ(v)− φ(v′) ) (12)
",4. Learning the Speedup Classifier,[0],[0]
"Here, the set {(v, v′)} contains any pair such that v is ygood, v′ is not y-good, and v and v′ are at the same search level.",4. Learning the Speedup Classifier,[0],[0]
"The level margin denotes the minimum score gap between a y-good and a y-bad node at the same search level.
",4. Learning the Speedup Classifier,[0],[0]
The priority function used to rank the search nodes is defined as pw(v) = g(v)−w,4. Learning the Speedup Classifier,[0],[0]
·φ(v).,4. Learning the Speedup Classifier,[0],[0]
Smaller priority function value ranks higher during search.,4. Learning the Speedup Classifier,[0],[0]
With these definitions we have the following theorem: Theorem 1 (Speedup mistake bound).,4. Learning the Speedup Classifier,[0],[0]
"Given a training set such that there exists a weight vector w with level margin γ > 0 and ‖w‖ = 1, the speedup learning algorithm (Algorithm 1) will converge with a consistent weight vector after making no more than R2φ+2Rg
γ2 weight updates.
",4. Learning the Speedup Classifier,[0],[0]
Proof.,4. Learning the Speedup Classifier,[0],[0]
The complete proof is in the supplementary material of the paper.,4. Learning the Speedup Classifier,[0],[0]
"So far, we have shown that a structured prediction problem can be converted to a beam search problem.",4.1. Avoiding Computing the Input Features,[0],[0]
The priority function for ranking search nodes is determined by p(v) = g(v) + h(v).,4.1. Avoiding Computing the Input Features,[0],[0]
We have seen how the h function be trained to enforce structural constraints.,4.1. Avoiding Computing the Input Features,[0],[0]
"However, there are other opportunities for speeding up as well.
",4.1. Avoiding Computing the Input Features,[0],[0]
"Computing the path cost g(v) involves calculating the corresponding ILP coefficients, which in turn requires feature extraction using the original trained model.",4.1. Avoiding Computing the Input Features,[0],[0]
"This is usually a time-consuming step (Srikumar, 2017), thus motivating the question of whether we can avoid calculating them without losing accuracy.",4.1. Avoiding Computing the Input Features,[0],[0]
"If a search node is strongly preferred by the heuristic function, the path cost is unlikely to reverse the heuristic function’s decision.",4.1. Avoiding Computing the Input Features,[0],[0]
"In this case, we can rank the candidate search nodes with heuristic function only.
",4.1. Avoiding Computing the Input Features,[0],[0]
"Formally, given a fixed beam size b and the beam candidates Ct at step t from which we need to select the beam Bt, we can rank the nodes in Ct from smallest to largest according to the heuristic function value h(v).",4.1. Avoiding Computing the Input Features,[0],[0]
"Denote the bth smallest node as vb and the (b+1)th smallest node as vb+1, we define the heuristic gap ∆t as
∆t = h(vb+1)− h(vb).",4.1. Avoiding Computing the Input Features,[0],[0]
"(13)
If the beam Bt is selected from Ct only according to heuristic function, then ∆t is the gap between the last node in the beam and the first node outside the beam.",4.1. Avoiding Computing the Input Features,[0],[0]
"Next we define the path-cost gap δt as
δt = max v,v′∈Ct
(v − v′) (14)
",4.1. Avoiding Computing the Input Features,[0],[0]
With these definitions we immediately have the following theorem: Theorem 2.,4.1. Avoiding Computing the Input Features,[0],[0]
"Given the beam candidates Ct with heuristic gap ∆t and path-cost gap δt, if ∆t > δt, then using only heuristic function to select the beam Bt will have the same set of nodes selected as using the full priority function up to their ordering in the beam.
",4.1. Avoiding Computing the Input Features,[0],[0]
"If the condition of Theorem 2 holds, then we can rank the candidates using only heuristic function without calculating the path cost.",4.1. Avoiding Computing the Input Features,[0],[0]
This will further save computation time.,4.1. Avoiding Computing the Input Features,[0],[0]
"However, without actually calculating the path cost there is no way to determine the path-cost gap δt at each step.",4.1. Avoiding Computing the Input Features,[0],[0]
"In practice we can treat δt as an empirical parameter θ and define the following priority function
pθ(v) = { h(v), if ∆t > θ, g(v) + h(v), otherwise.
",4.1. Avoiding Computing the Input Features,[0],[0]
(15),4.1. Avoiding Computing the Input Features,[0],[0]
We empirically evaluate the speedup based inference scheme described in Section 4 on the problem of predicting entities and relations (i.e. our running example).,5. Experiments,[0],[0]
"In this task, we are asked to label each entity, and the relation between each pair of the entities.",5. Experiments,[0],[0]
"We assume the entity candidates are given, either from human annotators or from a preprocessing step.",5. Experiments,[0],[0]
"The goal of inference is to determine the types of the entity spans, and the relations between them, as opposed to identify entity candidates.",5. Experiments,[0],[0]
"The research questions we seek to resolve empirically are:
1.",5. Experiments,[0],[0]
Does using a learned speedup heuristic recover structurally valid outputs without paying the inference cost of the integer linear program solver?,5. Experiments,[0],[0]
2.,5. Experiments,[0],[0]
"Can we construct accurate outputs without always computing input features and using only the learned heuristic to guide search?
",5. Experiments,[0],[0]
The dataset we used is from the previous work by Roth & Yih (2004).,5. Experiments,[0],[0]
It contains 1441 sentences.,5. Experiments,[0],[0]
"Each sentence contains several entities with labels, and the labeled relations between every pair of entity.",5. Experiments,[0],[0]
"There are three types of entities, person, location and organization, and five types of relations, Kill, LiveIn, WorkFor, LocatedAt and OrgBasedIn.",5. Experiments,[0],[0]
"There are two constraints associated with each relation type, specifying the allowed source and target arguments.",5. Experiments,[0],[0]
"For example, if the relation label is LiveIn, the source entity must be person and the target entity must be location.",5. Experiments,[0],[0]
"There is also another kind of constraint which says for every pair of entities, they can not have a relation label in both directions between them, i.e., one of the direction must be labeled as NoRel.
",5. Experiments,[0],[0]
"We re-implemented the model from the original work using the same set of features as for the entity and relation scoring
functions.",5. Experiments,[0],[0]
"We used 70% of the labeled data to train an ILPbased inference scheme, which will become our black-box solver for learning the speedup classifier.",5. Experiments,[0],[0]
"The remaining 30% labeled data are held out for evaluations.
",5. Experiments,[0],[0]
"We use 29950 sentences from the Gigaword corpus (Graff et al., 2003) to train the speedup classifier.",5. Experiments,[0],[0]
"The entity candidates are extracted using the Stanford Named Entity Recognizer (Manning et al., 2014).",5. Experiments,[0],[0]
"We ignore the entity labels, however, since our task requires determining the type of the entities and relations.",5. Experiments,[0],[0]
"The features we use for the speedup classifiers are counts of the pairs of labels of the form (source label, relation label), (relation label, target label), and counts of the triples of labels of the form (source label, relation label, target label).",5. Experiments,[0],[0]
"We run Algorithm 1 over this unlabeled dataset, and evaluate the resulting speedup classifier on the held out test set.",5. Experiments,[0],[0]
"In all of our speedup search implementations, we first assign labels to the entities from left to right, then the relations among them.
",5. Experiments,[0],[0]
We evaluate the learned speedup classifier in terms of both accuracy and speed.,5. Experiments,[0],[0]
"The accuracy of the speedup classifier can be evaluated using three kinds of metrics: F-1 scores against gold labels, F-1 scores against the ILP solver’s prediction, and the validity ratio, which is the percentage of the predicted examples agreeing with all constraints.6",5. Experiments,[0],[0]
Our first set of experiments evaluates the impact of Algorithm 1.,5.1. Evaluation of Algorithm 1,[0],[0]
These results are shown in Table 1.,5.1. Evaluation of Algorithm 1,[0],[0]
We see the ILP solver achieves perfect entity and relation F-1 when compared with ILP model itself.,5.1. Evaluation of Algorithm 1,[0],[0]
It guarantees all constraints are satisfied.,5.1. Evaluation of Algorithm 1,[0],[0]
Its accuracy against gold label and its prediction time becomes the baselines of our speedup classifiers.,5.1. Evaluation of Algorithm 1,[0],[0]
We also provide two search baselines.,5.1. Evaluation of Algorithm 1,[0],[0]
The first search baseline just uses greedy search without any constraint considerations.,5.1. Evaluation of Algorithm 1,[0],[0]
"In this setting each label is assigned independently, since the step cost of assigning a label to an entity or a relation variable depends only on the corresponding coefficients in the ILP objectives.",5.1. Evaluation of Algorithm 1,[0],[0]
"In this case, a structured prediction problem becomes several independent multi-class classification problems.",5.1. Evaluation of Algorithm 1,[0],[0]
The prediction time is faster than ILP but the validity ratio is rather low (0.29).,5.1. Evaluation of Algorithm 1,[0],[0]
The second search baseline is greedy search with constraint satisfaction.,5.1. Evaluation of Algorithm 1,[0],[0]
The constraints are guaranteed to be satisfied by using the standard arc-consistency search.,5.1. Evaluation of Algorithm 1,[0],[0]
"The prediction takes much longer than the ILP solver (844 ms vs. 239 ms.).
",5.1. Evaluation of Algorithm 1,[0],[0]
We trained a speedup classifier with two different beam sizes.,5.1. Evaluation of Algorithm 1,[0],[0]
"Even with beam width b = 1, we are able to obtain > 95% validity ratio, and the prediction time is much faster
6All our experiments were conducted on a server with eight Intel i7 3.40 GHz cores and 16G memory.",5.1. Evaluation of Algorithm 1,[0],[0]
"We disabled multithreaded execution in all cases for a fair comparison.
than the ILP model.",5.1. Evaluation of Algorithm 1,[0],[0]
"Furthermore, we see that the F-1 score evaluated against gold labels is only slightly worse than ILP model.",5.1. Evaluation of Algorithm 1,[0],[0]
"With beam width b = 2, we recover the ILP model accuracy when evaluated against gold labels.",5.1. Evaluation of Algorithm 1,[0],[0]
The prediction time is still much less than the ILP solver.,5.1. Evaluation of Algorithm 1,[0],[0]
"In this section, we empirically verify the idea that we do not always need to compute the path cost, if the heuristic gap ∆t is large.",5.2. Experiments on Ignoring the Model Cost,[0],[0]
We use the evaluation function pθ(v) in Eq.,5.2. Experiments on Ignoring the Model Cost,[0],[0]
(15) with different values of θ to rank the search nodes.,5.2. Experiments on Ignoring the Model Cost,[0],[0]
"The results are given in Table 2.
",5.2. Experiments on Ignoring the Model Cost,[0],[0]
"For both beam widths, θ = 0 is the case in which the original model is completely ignored.",5.2. Experiments on Ignoring the Model Cost,[0],[0]
All the nodes are ranked using the speedup heuristic function only.,5.2. Experiments on Ignoring the Model Cost,[0],[0]
"Even though it has perfect validity ratio, the result is rather poor when evaluated on F-1 scores.",5.2. Experiments on Ignoring the Model Cost,[0],[0]
"When θ increases, the entity and relation F-1 scores quickly jump up, essentially getting back the same accuracy as the speedup classifiers in Table 1.",5.2. Experiments on Ignoring the Model Cost,[0],[0]
But the prediction time is lowered compared to the results from Table 1.,5.2. Experiments on Ignoring the Model Cost,[0],[0]
The idea of learning memo functions to make computation more efficient goes back to Michie (1968).,6. Discussion and Related Work,[0],[0]
"Speedup learning has been studied since the eighties in the context of general problem solving, where the goal is to learn a problem solver that becomes faster as opposed to becoming more accurate as it sees more data.",6. Discussion and Related Work,[0],[0]
Fern (2011) gives a broad survey of this area.,6. Discussion and Related Work,[0],[0]
"In this paper, we presented a variant of this idea that is more concretely applied to structured output prediction.
",6. Discussion and Related Work,[0],[0]
Efficient inference is a central topic in structured prediction.,6. Discussion and Related Work,[0],[0]
"In order to achieve efficiency, various strategies are adopted in the literature.",6. Discussion and Related Work,[0],[0]
Search based strategies are commonly used for this purpose and several variants abound.,6. Discussion and Related Work,[0],[0]
"The idea of framing a structured prediction problem as a search problem has been explored by several previous works (Collins & Roark, 2004; Daumé III & Marcu, 2005; Daumé III et al., 2009; Huang et al., 2012; Doppa et al., 2014).",6. Discussion and Related Work,[0],[0]
"It usually admits incorporating arbitrary features more easily than fully global structured prediction models like conditional random fields (Lafferty et al., 2001), structured perceptron (Collins, 2002), and structured support vector machines (Taskar et al., 2003; Tsochantaridis et al., 2004).",6. Discussion and Related Work,[0],[0]
"In such cases too, inference can be solved approximately using heuristic search.",6. Discussion and Related Work,[0],[0]
"Either a fixed beam size (Xu et al., 2009), or a dynamicallysized beam (Bodenstab et al., 2011) can be used.",6. Discussion and Related Work,[0],[0]
In our work we fix the beam size.,6. Discussion and Related Work,[0],[0]
The key difference from previous work is that our ranking function combines information from the trained model with the heuristic function which characterizes constraint information.,6. Discussion and Related Work,[0],[0]
"Closely related to the
work described in this paper are approaches that learn to prune the search space (He et al., 2014; Vieira & Eisner, 2016) and learn to select features (He et al., 2013).
",6. Discussion and Related Work,[0],[0]
Another line of recent related work focuses on discovering problem level regularities across the inference space.,6. Discussion and Related Work,[0],[0]
"These amortized inference schemes are designed using deterministic rules for discovering when a new inference problem can re-use previously computed solutions (Srikumar et al., 2012; Kundu et al., 2013) or in the context of a Bayesian network by learning a stochastic inverse network that generates outputs (Stuhlmüller et al., 2013).
",6. Discussion and Related Work,[0],[0]
"Our work is also related to the idea of imitation learning (Daumé III et al., 2009; Ross et al., 2011; Ross & Bagnell, 2014; Chang et al., 2015).",6. Discussion and Related Work,[0],[0]
"In this setting, we are given a reference policy, which may or may not be a good policy.",6. Discussion and Related Work,[0],[0]
"The goal of learning is to learn another policy to imitate the given policy, or even learn a better one.",6. Discussion and Related Work,[0],[0]
Learning usually proceeds in an online fashion.,6. Discussion and Related Work,[0],[0]
"However, imitation learning requires learning a new policy which is independent of the given reference policy, since during test time the reference policy is no longer available.",6. Discussion and Related Work,[0],[0]
"In our case, we can think of the black-box solver as a reference policy.",6. Discussion and Related Work,[0],[0]
"During prediction we always have this solver at our disposal, what we want is avoiding unnecessary calls to the solver.",6. Discussion and Related Work,[0],[0]
"Following recent successes in imitation learning, we expect that we can replace the linear heuristic function with a deep network to avoid feature design.
",6. Discussion and Related Work,[0],[0]
"Also related is the idea of knowledge distillation (Bucilă et al., 2006; Hinton et al., 2015; Kim & Rush, 2016), that seeks to train a student classifier (usually a neural network) to compress and mimic a larger teacher network, thus improve prediction speed.",6. Discussion and Related Work,[0],[0]
The primary difference with the speedup idea of this paper is that our goal is to be more efficient at constructing internally self-consistent structures without explicitly searching over the combinatorially large output space with complex constraints.,6. Discussion and Related Work,[0],[0]
"In this paper, we asked whether we can learn to make inference faster over the lifetime of a structured output classifier.",7. Conclusions,[0],[0]
"To address this question, we developed a search-based strategy that learns to mimic a black-box inference engine but is substantially faster.",7. Conclusions,[0],[0]
We further extended this strategy by identifying cases where the learned search algorithm can avoid expensive input feature extraction to further improve speed without losing accuracy.,7. Conclusions,[0],[0]
We empirically evaluated our proposed algorithms on the problem of extracting entities and relations from text.,7. Conclusions,[0],[0]
"Despite using an object-heavy JVM-based implementation of search, we showed that by exploiting regularities across the output space, we can outperform the industrial strength Gurobi integer linear program solver in terms of speed, while matching its accuracy.
",7. Conclusions,[0],[0]
Acknowledgments We thank the Utah NLP group members and the anonymous reviewers for their valuable feedback.,7. Conclusions,[0],[0]
Predicting structured outputs can be computationally onerous due to the combinatorially large output spaces.,abstractText,[0],[0]
"In this paper, we focus on reducing the prediction time of a trained black-box structured classifier without losing accuracy.",abstractText,[0],[0]
"To do so, we train a speedup classifier that learns to mimic a black-box classifier under the learning-to-search approach.",abstractText,[0],[0]
"As the structured classifier predicts more examples, the speedup classifier will operate as a learned heuristic to guide search to favorable regions of the output space.",abstractText,[0],[0]
We present a mistake bound for the speedup classifier and identify inference situations where it can independently make correct judgments without input features.,abstractText,[0],[0]
We evaluate our method on the task of entity and relation extraction and show that the speedup classifier outperforms even greedy search in terms of speed without loss of accuracy.,abstractText,[0],[0]
Learning to Speed Up Structured Output Prediction,title,[0],[0]
"In conventional ODE modelling coefficients of an equation driving the system state forward in time are estimated. However, for many complex systems it is practically impossible to determine the equations or interactions governing the underlying dynamics. In these settings, parametric ODE model cannot be formulated. Here, we overcome this issue by introducing a novel paradigm of nonparametric ODE modelling that can learn the underlying dynamics of arbitrary continuous-time systems without prior knowledge. We propose to learn non-linear, unknown differential functions from state observations using Gaussian process vector fields within the exact ODE formalism. We demonstrate the model’s capabilities to infer dynamics from sparse data and to simulate the system forward into future.",text,[0],[0]
Dynamical systems modelling is a cornerstone of experimental sciences.,1. Introduction,[0],[0]
"In biology, as well as in physics and chemistry, modelers attempt to capture the dynamical behavior of a given system or a phenomenon in order to improve its understanding and make predictions about its future state.",1. Introduction,[0],[0]
Systems of coupled ordinary differential equations (ODEs) are undoubtedly the most widely used models in science.,1. Introduction,[0],[0]
"Even simple ODE functions can describe complex dynamical behaviours (Hirsch et al., 2004).",1. Introduction,[0],[0]
"Typically, the dynamics are firmly grounded in physics with only a few parameters to be estimated from data.",1. Introduction,[0],[0]
"However, equally ubiquitous are the cases where the governing dynamics are partially or completely unknown.
",1. Introduction,[0],[0]
"We consider the dynamics of a system governed by multi-
*Equal contribution 1Aalto University, Finland 2Helsinki Institute of Information Technology HIIT, Finland.",1. Introduction,[0],[0]
Correspondence to: Markus Heinonen,1. Introduction,[0],[0]
<,1. Introduction,[0],[0]
"markus.o.heinonen@aalto.fi>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"variate ordinary differential functions:
ẋ(t) = dx(t)
dt = f(x(t)) (1)
where x(t) ∈ X",1. Introduction,[0],[0]
"= RD is the state vector of a Ddimensional dynamical system at time t, and the ẋ(t) ∈",1. Introduction,[0],[0]
Ẋ =,1. Introduction,[0],[0]
"RD is the first order time derivative of x(t) that drives the state x(t) forward, and where f :",1. Introduction,[0],[0]
RD → RD is the vector-valued derivative function.,1. Introduction,[0],[0]
"The ODE solution is determined by
x(t) = x0 + ∫",1. Introduction,[0],[0]
t 0,1. Introduction,[0],[0]
"f(x(τ))dτ, (2)
where we integrate the system state from an initial state x(0) = x0 for time t forward.",1. Introduction,[0],[0]
We assume that f(·) is completely unknown and we only observe one or several multivariate time series Y =,1. Introduction,[0],[0]
"(y1, . . .",1. Introduction,[0],[0]
",yN )",1. Introduction,[0],[0]
"T ∈ RN×D obtained from an additive noisy observation model at observation time points T = (t1, . . .",1. Introduction,[0],[0]
", tN ) ∈ RN ,
y(t)",1. Introduction,[0],[0]
= x(t) +,1. Introduction,[0],[0]
"εt, (3)
where εt ∼ N (0,Ω) follows a stationary zero-mean multivariate Gaussian distribution with diagonal noise variances Ω = diag(ω21 , . . .",1. Introduction,[0],[0]
", ω 2 D).",1. Introduction,[0],[0]
The observation time points do not need to be equally spaced.,1. Introduction,[0],[0]
"Our task is to learn the differential function f(·) given observations Y , with no prior knowledge of the ODE system.
",1. Introduction,[0],[0]
"There is a vast literature on conventional ODEs (Butcher, 2016) where a parametric form for function f(x;θ, t) is assumed to be known, and its parameters θ are subsequently optimised with least squares or Bayesian approach, where the expensive forward solution xθ(ti)",1. Introduction,[0],[0]
"=∫ ti 0
f(x(τ);θ, t)dτ is required to evaluate the system responses xθ(ti) from parameters θ against observations y(ti).",1. Introduction,[0],[0]
"To overcome the computationally intensive forward solution, a family of methods denoted as gradient matching (Varah, 1982; Ellner et al., 2002; Ramsay et al., 2007) have proposed to replace the forward solution by matching f(yi)",1. Introduction,[0],[0]
"≈ ẏi to empirical gradients ẏi of the data instead, which do not require the costly integration step.",1. Introduction,[0],[0]
"Recently several authors have proposed embedding a parametric differential function within a Bayesian or Gaussian process (GP) framework (Graepel, 2003; Calderhead et al., 2008;
Dondelinger et al., 2013; Wang and Barber, 2014; Macdonald, 2017) (see Macdonald et al. (2015) for a review).",1. Introduction,[0],[0]
"GPs have been successfully applied to model linear differential equations as they are analytically tractable (Gao et al., 2008; Raissi et al., 2017).
",1. Introduction,[0],[0]
"However, conventional ODE modelling can only proceed if a parametric form of the driving function f(·) is known.",1. Introduction,[0],[0]
"Recently, initial work to handle unknown or non-parametric ODE models have been proposed, although with various limiting approximations.",1. Introduction,[0],[0]
"Early works include spline-based smoothing and additive functions ∑D j fj(xj) to infer gene regulatory networks (De Hoon et al., 2002; Henderson and Michailidis, 2014).",1. Introduction,[0],[0]
"Äijö and Lähdesmäki (2009) proposed estimating the unknown nonlinear function with GPs using either finite time differences, or analytically solving the derivative function as a function of only time, ẋ(t) = f(t) (Äijö et al., 2013).",1. Introduction,[0],[0]
"In a seminal technical report of Heinonen and d’Alche Buc (2014) a full vector-valued kernel model f(x) was proposed, however using a gradient matching approximation.",1. Introduction,[0],[0]
"To our knowledge, there exists no model that can learn non-linear ODE functions ẋ(t) = f(x(t)) over the state x against the true forward solutions x(ti).
",1. Introduction,[0],[0]
"In this work we propose NPODE1: the first ODE model for learning arbitrary, and a priori completely unknown nonparametric, non-linear differential functions f : X → Ẋ from data in a Bayesian way.",1. Introduction,[0],[0]
"We do not use gradient matching or other approximative models, but instead propose to directly optimise the exact ODE system with the fully forward simulated responses against data.",1. Introduction,[0],[0]
"We parameterise our model as an augmented Gaussian process vector field with inducing points, while we propose sensitivity equations to efficiently compute the gradients of the system.",1. Introduction,[0],[0]
"Our model can forecast continuous-time systems arbitrary amounts to future, and we demonstrate the state-of-the-art performance in human motion datasets.",1. Introduction,[0],[0]
"The differential function f(x) to be learned defines a vector field2 f , that is, an assignment of a gradient vector f(x) ∈ RD to every state x ∈ RD.",2. Nonparametric ODE Model,[0],[0]
"We model the vector field as a vector-valued Gaussian process (Rasmussen and Williams, 2006)
f(x) ∼ GP(0,K(x,x′)), (4)
which defines a priori distribution over function values f(x) whose mean and covariances are
E[f(x)]",2. Nonparametric ODE Model,[0],[0]
"= 0 (5) cov[f(x), f(x′)] = K(x,x′), (6)
1The implementation is publicly available in http://www. github.com/cagatayyildiz/npode
2We use vector field and differential function interchangeably.
and where the kernel K(x,x′) ∈ RD×D is matrixvalued.",2. Nonparametric ODE Model,[0.958625240379073],"['Thus, logPi(yE|x) = log ∑ yN∈∪j 6=iSj Pi(yE,yN|x) logPi(yE|x) = logsumexp yN∈∪j 6=iSj s(x,yE ,yN )− logZ where logZ is the log normalization term which is the same as in (1).']"
A GP prior defines that for any collection of states X =,2. Nonparametric ODE Model,[0],[0]
"(x1, . . .",2. Nonparametric ODE Model,[0],[0]
",xN )",2. Nonparametric ODE Model,[0],[0]
"T ∈ RN×D, the function values F = (f(x1), . . .",2. Nonparametric ODE Model,[0],[0]
", f(xN ))",2. Nonparametric ODE Model,[0],[0]
"T ∈ RN×D follow a matrixvalued normal distribution,
p(F ) = N (vec(F )|0,K(X,X)), (7)
where K(X,X) =",2. Nonparametric ODE Model,[0],[0]
"(K(xi,xj))Ni,j=1 ∈",2. Nonparametric ODE Model,[0],[0]
"RND×ND is a block matrix of matrix-valued kernels K(xi,xj).",2. Nonparametric ODE Model,[0],[0]
"The key property of Gaussian processes is that they encode functions where similar states x,x′ induce similar differentials f(x), f(x′), and where the state similarity is defined by the kernel K(x,x′).
",2. Nonparametric ODE Model,[0],[0]
"In standard GP regression we would obtain the posterior of the vector field by conditioning the GP prior with the data (Rasmussen and Williams, 2006).",2. Nonparametric ODE Model,[0],[0]
In ODE models the conditional f(x)|Y of a vector field is intractable due to the integral mapping (2) between observed states y(ti) and differentials f(x).,2. Nonparametric ODE Model,[0],[0]
"Instead, we resort to augmenting the Gaussian process with a set of M inducing points z ∈ X and u ∈",2. Nonparametric ODE Model,[0],[0]
"Ẋ , such that f(z) = u (Quiñonero-Candela and
Rasmussen, 2005).",2. Nonparametric ODE Model,[0],[0]
"We choose to interpolate the differential function between the inducing points as (See Figure 1)
f(x) , Kθ(x, Z)Kθ(Z,Z) −1vec(U), (8)
which supports the function f(x) with inducing locations Z = (z1, . . .",2. Nonparametric ODE Model,[0],[0]
", zM ), inducing vectors U = (u1, . . .",2. Nonparametric ODE Model,[0],[0]
",uM ), and θ are the kernel parameters.",2. Nonparametric ODE Model,[0],[0]
"The function above corresponds to a vector-valued kernel function (Alvarez et al., 2012), or to a multi-task Gaussian process conditional mean without the variance term (Rasmussen and Williams, 2006).",2. Nonparametric ODE Model,[0],[0]
This definition is then compatible with the deterministic nature of the ODE formalism.,2. Nonparametric ODE Model,[0],[0]
"Due to universality of several kernels and kernel functions (Shawe-Taylor and Cristianini, 2004), we can represent arbitrary vector fields with appropriate inducing point and kernel choices.",2. Nonparametric ODE Model,[0],[0]
"The vector-valued kernel function (8) uses operator-valued kernels, which result in matrix-valued kernels Kθ(z, z′) ∈ RD×D for real valued states x, z, while the kernel matrix over data points becomes Kθ = (K(zi, zj))Mi,j=1 ∈ RMD×MD (See Alvarez et al. (2012) for a review).",2.1. Operator-valued Kernels,[0],[0]
"Most straightforward operator-valued kernel is the identity decomposable kernel Kdec(z, z′) = k(z, z′) ·",2.1. Operator-valued Kernels,[0],[0]
"ID, where the scalar Gaussian kernel
Kθ(z, z ′) =",2.1. Operator-valued Kernels,[0],[0]
σ2f exp −1 2 D∑ j=1 (zj − z′j)2,2.1. Operator-valued Kernels,[0],[0]
"`2j  (9) with differential variance σ2f and dimension-specific lengthscales ` = (`1, . . .",2.1. Operator-valued Kernels,[0],[0]
", `D) are expanded into a diagonal matrix of size D × D. We collect the kernel parameters as θ = (σf , `).
",2.1. Operator-valued Kernels,[0],[0]
We note that more complex kernels can also be considered given prior information of the underlying system characteristics.,2.1. Operator-valued Kernels,[0],[0]
"The divergence-free matrix-valued kernel induces vector fields that have zero divergence (Wahlström et al., 2013; Solin et al., 2015).",2.1. Operator-valued Kernels,[0],[0]
"Intuitively, these vector fields do not have sinks or sources, and every state always finally returns to itself after sufficient amount of time.",2.1. Operator-valued Kernels,[0],[0]
"Similarly, curl-free kernels induce curl-free vector fields that can contain sources or sinks, that is, trajectories can accelerate or decelerate.",2.1. Operator-valued Kernels,[0],[0]
"For theoretical treatment of vector field kernels, see (Narcowich and Ward, 1994; Bhatia et al., 2013; Fuselier and Wright, 2017).",2.1. Operator-valued Kernels,[0],[0]
"Non-stationary vector fields can be modeled with input-dependent lengthscales (Heinonen et al., 2016), while spectral kernels can represent stationary (Wilson et al., 2013) or non-stationary (Remes et al., 2017) recurring patterns in the differential function.",2.1. Operator-valued Kernels,[0],[0]
"We assume a Gaussian likelihood over the observations yi and the corresponding simulated responses x(ti) of Equation (2),
p(Y |x0, U, Z,ω) = N∏ i=1 N",2.2. Joint Model,[0],[0]
"(yi|x(ti),Ω), (10)
where x(ti) are forward simulated responses using the integral Equation (2) and differential Equation (8), and Ω = diag(ω21 . .",2.2. Joint Model,[0],[0]
.,2.2. Joint Model,[0],[0]
", ω 2 D) collects the dimension-specific noise variances.
",2.2. Joint Model,[0],[0]
"The inducing vectors have a Gaussian process prior
p(U |Z,θ) = N",2.2. Joint Model,[0],[0]
"(vec(U)|0,Kθ(Z,Z)).",2.2. Joint Model,[0],[0]
"(11)
",2.2. Joint Model,[0],[0]
"The model posterior is then
p(U,x0,θ,ω|Y ) ∝",2.2. Joint Model,[0],[0]
"p(Y |x0, U,ω)p(U |θ) = L, (12)
where we have for brevity omitted the dependency on the locations of the inducing points Z and also the parameter hyperpriors p(θ) and p(ω) since we assume them to be uniform, unless there is specific domain knowledge of the priors.
",2.2. Joint Model,[0],[0]
"The model parameters are the initial state x03, the inducing vectors U , the noise standard deviations ω = (ω1, . . .",2.2. Joint Model,[0],[0]
", ωD), and the kernel hyperparameters θ = (σf , `1, . . .",2.2. Joint Model,[0],[0]
", `D).",2.2. Joint Model,[0],[0]
"We apply a latent parameterisation using Cholesky decomposition LθLTθ = Kθ(Z,Z), which maps the inducing vectors to whitened domain (Kuss and Rasmussen, 2005)
",2.3. Noncentral Parameterisation,[0],[0]
"U = LθŨ , Ũ = L −1 θ U. (13)
",2.3. Noncentral Parameterisation,[0],[0]
The latent variables Ũ are projected on the kernel manifold Lθ to obtain the inducing vectors U .,2.3. Noncentral Parameterisation,[0],[0]
"This non-centered parameterisation (NCP) transforms the hierarchical posterior L of Equation (12) into a reparameterised form
p(x0, Ũ ,θ,ω|Y ) ∝",2.3. Noncentral Parameterisation,[0],[0]
"p(Y |x0, Ũ ,ω,θ)p(Ũ), (14)
where all variables to be optimised are decoupled, with the latent inducing vectors having a standard normal prior Ũ ∼ N (0, I).",2.3. Noncentral Parameterisation,[0],[0]
Optimizing Ũ and θ is now more efficient since they have independent contributions to the vector field via U = LθŨ .,2.3. Noncentral Parameterisation,[0],[0]
"The gradients of the whitened posterior can be retrieved analytically as (Heinonen et al., 2016)
",2.3. Noncentral Parameterisation,[0],[0]
∇Ũ logL = L T,2.3. Noncentral Parameterisation,[0],[0]
"θ∇U logL. (15)
3In case of multiple time-series, we will use one initial state for each time-series.
",2.3. Noncentral Parameterisation,[0],[0]
"Finally, we find a maximum a posteriori (MAP) estimate for the initial state x0, latent vector field Ũ , kernel parameters θ and noise variances ω by gradient ascent,
x0,MAP, ŨMAP,θMAP,ωMAP = arg max x0,Ũ ,θ,ω
logL, (16)
while keeping the inducing locations Z fixed on a sufficiently dense grid (See Figure 1).",2.3. Noncentral Parameterisation,[0],[0]
"The partial derivatives of the posterior with respect to noise parameters ω can be found analytically, while the derivative with respect to σf is approximated with finite differences.",2.3. Noncentral Parameterisation,[0],[0]
We select the optimal lengthscales ` by cross-validation.,2.3. Noncentral Parameterisation,[0],[0]
"The key term to carry out the MAP gradient ascent optimization is the likelihood
log p(Y |x0, Ũ ,ω)
that requires forward integration and computing the partial derivatives with respect to the whitened inducing vectors Ũ .",3. Sensitivity Equations,[0],[0]
Given Equation (15) we only need to compute the gradients with respect to the inducing vectors u = vec(U) ∈,3. Sensitivity Equations,[0],[0]
"RMD,
d log p(Y |x0,u,ω)",3. Sensitivity Equations,[0],[0]
"du
= N∑ s=1 d logN (ys|x(ts,u),Ω)",3. Sensitivity Equations,[0],[0]
"dx dx(ts,u) du .",3. Sensitivity Equations,[0],[0]
"(17)
",3. Sensitivity Equations,[0],[0]
"This requires computing the derivatives of the simulated system response x(t,u) against the vector field parameters u,
dx(t,u)
du ≡ S(t) ∈ RD×MD, (18)
which we denote by Sij(t)",3. Sensitivity Equations,[0],[0]
"= ∂x(t,u)i
∂uj , and expand the no-
tation to make the dependency of x on u explicit.",3. Sensitivity Equations,[0],[0]
"Approximating these with finite differences is possible in principle, but is highly inefficient and has been reported to cause unstability (Raue et al., 2013).",3. Sensitivity Equations,[0],[0]
"We instead turn to sensitivity equations for u and x0 that provide computationally efficient, analytical gradients S(t) (Kokotovic and Heller, 1967; Fröhlich et al., 2017).
",3. Sensitivity Equations,[0],[0]
"The solution for dx(t,u)du can be derived by differentiating the full nonparametric ODE system with respect to u by
d
du
dx(t,u)
dt =
d
du f(x(t,u)).",3. Sensitivity Equations,[0],[0]
"(19)
The sensitivity equation for the given system can be obtained by changing the order of differentiation on the left hand side and carrying out the differentiation on the right hand side.
",3. Sensitivity Equations,[0],[0]
"The resulting sensitivity equation can then be expressed in the form
Ṡ(t)︷ ︸︸ ︷",3. Sensitivity Equations,[0],[0]
"d
dt
dx(t,u)
du =
J(t)︷ ︸︸ ︷",3. Sensitivity Equations,[0],[0]
"∂f(x(t,u))
",3. Sensitivity Equations,[0],[0]
"∂x
S(t)︷ ︸︸ ︷",3. Sensitivity Equations,[0],[0]
"dx(t,u)
",3. Sensitivity Equations,[0],[0]
"du +
R(t)︷ ︸︸ ︷",3. Sensitivity Equations,[0],[0]
"∂f(x(t,u))
",3. Sensitivity Equations,[0],[0]
"∂u ,
(20)
",3. Sensitivity Equations,[0],[0]
"where J(t) ∈ RD×D, R(t), Ṡ(t) ∈ RD×MD (See Supplements for detailed specification).",3. Sensitivity Equations,[0],[0]
"For our nonparametric ODE system the sensitivity equation is fully determined by
J(t) = ∂K(x, Z)
∂x K(Z,Z)−1u",3. Sensitivity Equations,[0],[0]
"(21)
R(t) = K(x, Z)K(Z,Z)−1. (22)
",3. Sensitivity Equations,[0],[0]
The sensitivity equation provides us with an additional ODE system which describes the time evolution of the derivatives with respect to the inducing vectors S(t).,3. Sensitivity Equations,[0],[0]
"The sensitivities are coupled with the actual ODE system and, thus both systems x(t) and S(t) are concatenated as the new augmented state that is solved jointly by Equation (2) driven by the differentials ẋ(t) and Ṡ(t) (Leis and Kramer, 1988).",3. Sensitivity Equations,[0],[0]
The initial sensitivities are computed as S(0) = dx0du .,3. Sensitivity Equations,[0],[0]
"In our implementation, we merge x0 with u for sensitivity analysis to obtain the partial derivatives with respect to the initial state which is estimated along with the other parameters.",3. Sensitivity Equations,[0],[0]
"We use the CVODES solver from the SUNDIALS package (Hindmarsh et al., 2005) to solve the nonparametric ODE models and the corresponding gradients numerically.",3. Sensitivity Equations,[0],[0]
"The sensitivity equation based approach is superior to the finite differences approximation because we have exact formulation for the gradients of state over inducing points, which can be solved up to the numerical accuracy of the ODE solver.",3. Sensitivity Equations,[0],[0]
"As first illustration of the proposed nonparametric ODE method we consider three simulated differential systems: the Van der Pol (VDP), FitzHugh-Nagumo (FHN) and Lotka-Volterra (LV) oscillators of form
VDP : ẋ1 = x2 ẋ2 =",4. Simple Simulated Dynamics,[0],[0]
(1− x21)x2,4. Simple Simulated Dynamics,[0],[0]
− x1 FHN :,4. Simple Simulated Dynamics,[0],[0]
ẋ1 = 3(x1 − x31 3 + x2),4. Simple Simulated Dynamics,[0],[0]
"ẋ2 = 0.2− 3x1 − 0.2x2
3 LV :",4. Simple Simulated Dynamics,[0],[0]
ẋ1 = 1.5x1,4. Simple Simulated Dynamics,[0],[0]
− x1x2,4. Simple Simulated Dynamics,[0],[0]
"ẋ2 = −3x2 + x1x2.
",4. Simple Simulated Dynamics,[0],[0]
"In the conventional ODE case the coefficients of these equations can be inferred using standard statistical techniques if sufficient amount of time series data is available (Girolami, 2008; Raue et al., 2013).",4. Simple Simulated Dynamics,[0.9585397474688906],"['Thus, this can be computed using the same dynamic programming algorithm (Tsuboi et al., 2008), and the implementation of training this model is compatible with modern automatic differentiation libraries.']"
"Our main goal is to infer unknown dynamics, that is, when these equations are unavailable and we instead represent the dynamics with a nonparametric
vector field of Equation (8).",4. Simple Simulated Dynamics,[0],[0]
"We use these simulated models to only illustrate our model behavior against the true dynamics.
",4. Simple Simulated Dynamics,[0],[0]
"We employ 25 data points from one cycle of noisy observation data from VDP and FHN models, and 25 data points from 1.7 cycles from the LV model with a noise variance of σ2n = 0.1
2.",4. Simple Simulated Dynamics,[0],[0]
"We learn the npODE model with five training sequences using M = 62 inducing locations on a fixed grid, and forecast between 4 and 8 future cycles starting from true initial state x0 at time 0.",4. Simple Simulated Dynamics,[0],[0]
Training takes approximately 100 seconds per oscillator.,4. Simple Simulated Dynamics,[0],[0]
"Figure 2 (bottom) shows the training datasets (grey regions), initial states, true trajectories (black lines) and the forecasted trajectory likelihoods (colored regions).",4. Simple Simulated Dynamics,[0],[0]
"The model accurately learns the dynamics from less than two cycles of data and can reproduce them reliably into future.
",4. Simple Simulated Dynamics,[0],[0]
Figure 2 (top) shows the corresponding true vector field (black arrows) and the estimated vector field (grey arrows).,4. Simple Simulated Dynamics,[0],[0]
"The vector field is a continuous function, which is plotted on a 8x8 grid for visualisation.",4. Simple Simulated Dynamics,[0],[0]
"In general the most difficult part of the system is learning the middle of the loop (as seen in the FHN model), and learning the most outermost regions (bottom left in the LV model).",4. Simple Simulated Dynamics,[0],[0]
"The model learns the
underlying differential f(x) accurately close to observed points, while making only few errors in the border regions with no data.",4. Simple Simulated Dynamics,[0],[0]
"Next, we illustrate how the model estimates realistic, unknown dynamics from noisy observations y(t1), . . .",5. Unknown System Estimation,[0],[0]
",y(tN ).",5. Unknown System Estimation,[0],[0]
"As in Section 4, we make no assumptions on the structure or form of the underlying system, and capture the underlying dynamics with the nonparameteric system alone.",5. Unknown System Estimation,[0],[0]
"We employ no subjective priors, and assume no inputs, controls or other sources of information.",5. Unknown System Estimation,[0],[0]
"The task is to infer the underlying dynamics f(x), and interpolate or extrapolate the state trajectory outside the observed data.
",5. Unknown System Estimation,[0],[0]
We use a benchmark dataset of human motion capture data from the Carnegie Mellon University motion capture (CMU mocap) database.,5. Unknown System Estimation,[0],[0]
"Our dataset contains 50-dimensional pose measurements y(ti) from humans walking, where each pose dimension records a measurement in different parts of the body during movement (Wang et al., 2008).",5. Unknown System Estimation,[0],[0]
We apply the preprocessing of Wang et al. (2008) by downsampling the datasets by a factor of four and centering the data.,5. Unknown System Estimation,[0],[0]
"This resulted in a total of 4303 datapoints spread across 43 trajec-
tories with on average 100 frames per trajectory.",5. Unknown System Estimation,[0],[0]
"In order to tackle the problem of dimensionality, we project the original dataset with PCA to a three dimensional latent space where the system is specified, following Damianou et al. (2011) and Wang et al. (2006).",5. Unknown System Estimation,[0],[0]
"We place M = 53 inducing vectors on a fixed grid, and optimize our model starting from 100 different initial values, which we set by perturbing the projected empirical differences y(ti)−y(ti−1) to the inducing vectors.",5. Unknown System Estimation,[0],[0]
We use an L-BFGS optimizer in Matlab.,5. Unknown System Estimation,[0],[0]
"The whole inference takes approximately few minutes per trajectory.
",5. Unknown System Estimation,[0],[0]
We evaluate the method with two types of experiments: imputing missing values and forecasting future cycles.,5. Unknown System Estimation,[0],[0]
"For the forecasting the first half of the trajectory is reserved for model training, and the second half is to be forecasted.",5. Unknown System Estimation,[0],[0]
"For imputation we remove roughly 20% of the frames from the middle of the trajectory, which are to be filled by the models.",5. Unknown System Estimation,[0],[0]
We perform model selection for lengthscales ` with crossvalidation split of 80/20.,5. Unknown System Estimation,[0],[0]
"We record the root mean square error (RMSE) over test points in the original feature space in both cases, where we reconstruct the original dimensions from the latent space trajectories.
",5. Unknown System Estimation,[0],[0]
"Due to the current lack of ODE methods suitable for this nonparametric inference task, we instead compare our method to the state-of-the-art state-space models where such problems have been previously considered (Wang et al., 2008).",5. Unknown System Estimation,[0],[0]
In a state-space or dynamical model a transition function x(tk+1) = g(x(tk)) moves the system forward in discrete steps.,5. Unknown System Estimation,[0],[0]
"With sufficiently high sampling rate, such models can estimate and forecast finite approximations of smooth dynamics.",5. Unknown System Estimation,[0],[0]
"In Gaussian process dynamical model (Wang et al., 2006; Frigola et al., 2014; Svensson et al., 2016)",5. Unknown System Estimation,[0],[0]
"a GP transition function is inferred in a latent space, which can be inferred with a standard GPLVM (Lawrence, 2004) or with a dependent GPLVM (Zhao and Sun, 2016).",5. Unknown System Estimation,[0],[0]
"In dynamical systems the transition function is replaced by a GP interpolation (Damianou et al., 2011).",5. Unknown System Estimation,[0],[0]
"The discrete time state-space models emphasize inference of a low-dimensional manifold as an explanation of the high-dimensional measurement trajectories.
",5. Unknown System Estimation,[0],[0]
"We compare our method to the dynamical model GPDM of Wang et al. (2006) and to the dynamical system VGPLVM of Damianou et al. (2011), where we directly apply the implementations provided by the authors at inverseprobability.com/vargplvm and dgp.",5. Unknown System Estimation,[0],[0]
toronto.edu/˜jmwang/gpdm.,5. Unknown System Estimation,[0],[0]
"Both methods optimize their latent spaces separately, and they are thus not directly comparable.",5. Unknown System Estimation,[0],[0]
"In the forecasting task we train all models with the first half of the trajectory, while forecasting the second half starting from the first frame.",5.1. Forecasting,[0],[0]
"The models are trained and forecasted
within a low-dimensional space, and subsequently projected back into the original space via inverting the PCA or with GPLVM mean predictions.",5.1. Forecasting,[0],[0]
"As all methods optimize their latent spaces separately, they are not directly comparable.",5.1. Forecasting,[0],[0]
"Thus, the mean errors are computed in the original highdimensional space.",5.1. Forecasting,[0],[0]
"Note that the low-dimensional representation necessarily causes some reconstruction errors.
",5.1. Forecasting,[0],[0]
Figure 3 illustrates the models on one of the trajectories 35 12.amc.,5.1. Forecasting,[0],[0]
"The top part (a) shows the training data in the PCA space for npODE, and optimized training data representation for GPDM and VGPLVM (black points).",5.1. Forecasting,[0],[0]
"The colored lines (npODE) and points (GPDM, VGPLVM) indicate the future forecast.",5.1. Forecasting,[0],[0]
The bottom part (b) shows the first 9 reconstructed original pose dimensions reconstructed from the latent forecasted trajectories.,5.1. Forecasting,[0],[0]
"The training data is shown in grey background, while test data is shown with circles.
",5.1. Forecasting,[0],[0]
"The VGPLVM has most trouble forecasting future points, and reverts quickly after training data to a value close to zero, failing to predict future points.",5.1. Forecasting,[0],[0]
"The GPDM model produces more realistic trajectories, but fails to predict any of the poses accurately.",5.1. Forecasting,[0],[0]
"Finally, npODE can accurately predict five poses, and still retains adequate performance on remaining poses, except for pose 2.
",5.1. Forecasting,[0],[0]
"Furthermore, Table 1 indicates that npODE is also best performing method on average over the whole dataset in the forecasting.",5.1. Forecasting,[0],[0]
In the imputation task we remove approximately 20% of the training data from the middle of the trajectory.,5.2. Imputation,[0],[0]
The goals are to learn a model with the remaining data and to forecast the missing values.,5.2. Imputation,[0],[0]
Figure 4 highlights the performance of the three models on the trajectory 07 07.amc.,5.2. Imputation,[0],[0]
"The top part (a) shows the training data (black points) in the PCA space (npODE) or optimized training locations in the latent space (GPDM, VGPLVM).",5.2. Imputation,[0],[0]
The middle part imputation is shown with colored points or lines.,5.2. Imputation,[0],[0]
"Interestingly both npODE and GPDM operate on cyclic representations, while VGPLVM is not cyclic.
",5.2. Imputation,[0],[0]
"The bottom panel (b) shows the first 9 reconstructed pose
dimensions from the three models.",5.2. Imputation,[0],[0]
"The missing values are shown in circles, while training points are shown with black dots.",5.2. Imputation,[0],[0]
"All models can accurately reproduce the overall trends, while npODE seems to fit slightly worse than the other methods.",5.2. Imputation,[0],[0]
The PCA projection causes the seemingly perfect fit of the npODE prediction (at the top) to lead to slightly warped reconstructions (at the bottom).,5.2. Imputation,[0],[0]
All methods mostly fit the missing parts as well.,5.2. Imputation,[0],[0]
Table 1 shows that on average the npODE and VGPLVM have approximately equal top performance on the imputing missing values task.,5.2. Imputation,[0],[0]
"We proposed the framework of nonparametric ODE model that can accurately learn arbitrary, nonlinear continuos-time dynamics from purely observational data without making assumptions of the underlying system dynamics.",6. Discussion,[0],[0]
We demonstrated that the model excels at learning dynamics that can be forecasted into the future.,6. Discussion,[0],[0]
"We consider this work as the
first in a line of studies of nonparametric ODE systems, and foresee several aspects as future work.",6. Discussion,[0],[0]
"Currently we do not handle non-stationary vector fields, that is time-dependent differentials ft(x).",6. Discussion,[0],[0]
"Furthermore, an interesting future avenue is the study of various vector field kernels, such as divergence-free, curl-free or spectral kernels (Remes et al., 2017).",6. Discussion,[0],[0]
"Finally, including inputs or controls to the system would allow precise modelling in interactive settings, such as robotics.
",6. Discussion,[0],[0]
"The proposed nonparametric ODE model operates along a continuous-time trajectory, while dynamic models such as hidden Markov models or state-space models are restricted to discrete time steps.",6. Discussion,[0],[0]
"These models are unable to consider system state at arbitrary times, for instance, between two successive timepoints.
",6. Discussion,[0],[0]
"Conventional ODE models have also been considered from the stochastic perspective with stochastic differential equation (SDE) models that commonly model the deterministic
system drift and diffusion processes separately leading to a distribution of trajectories p(x(t))",6. Discussion,[0],[0]
"(Archambeau et al., 2007; Garcı́a et al., 2017).",6. Discussion,[0],[0]
"As future work we will consider stochastic extensions of our nonparametric ODE model, as well as MCMC sampling of the inducing point posterior p(U |Y ), leading to trajectory distribution as well.
Acknowledgements.",6. Discussion,[0],[0]
The data used in this project was obtained from mocap.cs.cmu.edu.,6. Discussion,[0],[0]
The database was created with funding from NSF EIA-0196217.,6. Discussion,[0],[0]
"This work has been supported by the Academy of Finland Center of Excellence in Systems Immunology and Physiology, the Academy of Finland grants no. 284597, 311584, 313271, 299915.",6. Discussion,[0],[0]
In conventional ODE modelling coefficients of an equation driving the system state forward in time are estimated.,abstractText,[0],[0]
"However, for many complex systems it is practically impossible to determine the equations or interactions governing the underlying dynamics.",abstractText,[0],[0]
"In these settings, parametric ODE model cannot be formulated.",abstractText,[0],[0]
"Here, we overcome this issue by introducing a novel paradigm of nonparametric ODE modelling that can learn the underlying dynamics of arbitrary continuous-time systems without prior knowledge.",abstractText,[0],[0]
"We propose to learn non-linear, unknown differential functions from state observations using Gaussian process vector fields within the exact ODE formalism.",abstractText,[0],[0]
We demonstrate the model’s capabilities to infer dynamics from sparse data and to simulate the system forward into future.,abstractText,[0],[0]
Learning unknown ODE models with Gaussian processes,title,[0],[0]
"Translating words between languages, or more generally inferring bilingual dictionaries, is a long-studied research direction with applications including machine translation (Lample et al., 2017), multilingual word embeddings (Klementiev et al., 2012), and knowledge transfer to low resource languages (Guo et al., 2016).",1 Introduction,[0],[0]
"Research here has a long history under the guise of decipherment (Knight et al., 2006).",1 Introduction,[0],[0]
"Current contemporary methods have achieve effective word translation through theme-aligned corpora (Gouws et al., 2015), or seed dictionaries (Mikolov et al., 2013).
",1 Introduction,[0],[0]
"Mikolov et al. (2013) showed that monolingual word embeddings exhibit isomorphism across languages, and can be aligned with a simple linear transformation.",1 Introduction,[0],[0]
"Given two sets word vectors learned independently from monolingual corpora, and a dictionary of seed pairs to learn a linear transformation for alignment; they were able to
estimate a complete bilingual lexicon.",1 Introduction,[0],[0]
"Many studies have since followed this approach, proposing various improvements such as orthogonal mappings (Artetxe et al., 2016) and improved objectives (Lazaridou et al., 2015).
",1 Introduction,[0],[0]
Obtaining aligned corpora or bilingual seed dictionaries is nevertheless not straightforward for all language pairs.,1 Introduction,[0],[0]
"This has motivated a wave of very recent research into unsupervised word translation: inducing bilingual dictionaries given only monolingual word embeddings (Conneau et al., 2018; Zhang et al., 2017b,a; Artetxe et al., 2017).",1 Introduction,[0],[0]
"The most successful have leveraged ideas from Generative Adversarial Networks (GANs) (Goodfellow et al., 2014).",1 Introduction,[0],[0]
"In this approach the generator provides the cross-modal mapping, taking embeddings of dictionary words in one language and ‘generating’ their translation in another.",1 Introduction,[0],[0]
The discriminator tries to distinguish between this ‘fake’ set of translations and the true dictionary of embeddings in the target language.,1 Introduction,[0],[0]
"The two play a competitive game, and if the generator learns to fool the discriminator, then its cross-modal mapping should be capable of inducing a complete dictionary, as per Mikolov et al. (2013).
",1 Introduction,[0],[0]
"Despite these successes, such adversarial methods have a number of well-known drawbacks (Arjovsky et al., 2017):",1 Introduction,[0],[0]
"Due to the nature of their min-max game, adversarial training is very unstable, and they are prone to divergence.",1 Introduction,[0],[0]
"It is extremely hyper-parameter sensitive, requiring problem-specific tuning.",1 Introduction,[0],[0]
"Convergence is also hard to diagnose and does not correspond well to efficacy of the generator in downstream tasks (Hoshen and Wolf, 2018).
",1 Introduction,[0],[0]
"In this paper, we propose an alternative statistical dependency-based approach to unsupervised word translation.",1 Introduction,[0],[0]
"Specifically, we propose to search for the cross-lingual word pairing that maximizes statistical dependency in terms of squared
loss mutual information (SMI) (Yamada et al., 2015; Suzuki and Sugiyama, 2010).",1 Introduction,[0],[0]
"Compared to prior statistical dependency-based approaches such as Kernelized Sorting (KS) (Quadrianto et al., 2009) we advance: (i) through use of SMI rather than their Hilbert Schmidt Independence Criterion (HSIC) and (ii) through jointly optimising cross-modal pairing with representation learning within each view.",1 Introduction,[0],[0]
"In contrast to prior work that uses a fixed representation, by non-linearly projecting monolingual world vectors before matching, we learn a new embedding where statistical dependency is easier to establish.",1 Introduction,[0],[0]
"Our method: (i) achieves similar unsupervised translation performance to recent adversarial methods, while being significantly easier to train and (ii) clearly outperforms prior non-adversarial methods.",1 Introduction,[0],[0]
"Let dataset D contain two sets of unpaired monolingual word embeddings from two languages D = ({xi}ni=1, {yj}nj=1) where x,y ∈ Rd.",2.1 Deep Distribution Matching,[0],[0]
"Let π be a permutation function over {1, 2, . . .",2.1 Deep Distribution Matching,[0],[0]
",",2.1 Deep Distribution Matching,[0],[0]
"n}, and Π the corresponding permutation indicator matrix: Π ∈ {0, 1}n×n,Π1n",2.1 Deep Distribution Matching,[0],[0]
"= 1n, and Π>1n = 1n.",2.1 Deep Distribution Matching,[0],[0]
Where 1n is the n-dimensional vector with all ones.,2.1 Deep Distribution Matching,[0],[0]
"We aim to optimize for both the permutation Π (bilingual dictionary), and non-linear transformations gx(·) and gy(·) of the respective wordvectors, that maximize statistical dependency between the views.",2.1 Deep Distribution Matching,[0],[0]
While regularising by requiring the original word embedding information is preserved through reconstruction using decoders fx(·) and fy(·).,2.1 Deep Distribution Matching,[0],[0]
"Our overall loss function is:
min Θx,Θy ,Π Ω(D; Θx,Θy)︸ ︷︷ ︸ Regularizer −λDΠ(D; Θx,Θy)︸ ︷︷ ︸ Dependency ,
DΠ(D; Θx,Θy) = DΠ({gx(xi), gy(yπ(i))}ni=1),
Ω(D; Θx,Θy) = n∑ i=1",2.1 Deep Distribution Matching,[0],[0]
"‖xi − fx(gx(xi))‖22
+ ‖yi",2.1 Deep Distribution Matching,[0],[0]
− fy(gy(yi))‖22 +R(Θx),2.1 Deep Distribution Matching,[0],[0]
"+R(Θy).
(1)
where Θs parameterize the encoding and reconstruction transformations, R(·) is a regularizer (e.g., `2-norm and `1-norm), and DΠ(·, ·) is a statistical dependency measure.",2.1 Deep Distribution Matching,[0],[0]
"Crucially compared to prior methods such as matching CCA (Haghighi
et al., 2008), dependency measures such as SMI do not need comparable representations to get started, making the bootstrapping problem less severe.",2.1 Deep Distribution Matching,[0],[0]
Squared-Loss Mutual Information (SMI),2.2 Dependence Estimation,[0],[0]
"The squared loss mutual information between two random variables x and y is defined as (Suzuki and Sugiyama, 2010):
SMI = ∫∫ ( p(x,y) p(x)p(y)",2.2 Dependence Estimation,[0],[0]
"− 1 )2 p(x)p(y)dxdy,
which is the Pearson divergence (Pearson, 1900) from p(x,y) to p(x)p(y).",2.2 Dependence Estimation,[0],[0]
"The SMI is an f - divergence (Ali and Silvey, 1966).",2.2 Dependence Estimation,[0],[0]
"That is, it is a non-negative measure and is zero only if the random variables are independent.
",2.2 Dependence Estimation,[0],[0]
"To measure SMI from a set of samples we take a direct density ratio estimation approach (Suzuki and Sugiyama, 2010), which leads (Yamada et al., 2015) to the estimator:
ŜMI({(xi,yi)}ni=1)",2.2 Dependence Estimation,[0],[0]
"= 1 2n tr (diag (α̂)KL)− 1 2 ,
where K ∈ Rn×n and L ∈ Rn×n are the gram matricies for x and y respectively, and
Ĥ = 1
n2 (KK>) ◦",2.2 Dependence Estimation,[0],[0]
"(LL>),
ĥ = 1
n",2.2 Dependence Estimation,[0],[0]
"(K ◦L)1n, α̂ =
( Ĥ + λIn )−1 ĥ,
λ > 0 is a regularizer and In ∈ Rn×n is the identity matrix.
",2.2 Dependence Estimation,[0],[0]
"SMI for Matching SMI computes the dependency between two sets of variables, under an assumption of known correspondence.",2.2 Dependence Estimation,[0],[0]
In our application this corresponds to a measure of dependency between two aligned sets of monolingual wordvectors.,2.2 Dependence Estimation,[0],[0]
"To exploit SMI for matching, we introduce a permutation variable Π by replacing L→ Π>LΠ in the estimator:
ŜMI({(xi,yπ(i))}n1 )",2.2 Dependence Estimation,[0],[0]
= 1 2n tr ( diag (α̂Π)KΠ >LΠ ),2.2 Dependence Estimation,[0],[0]
"− 1 2 ,
that will enable optimizing Π to maximize SMI.",2.2 Dependence Estimation,[0],[0]
"To initialize Θx and Θy, we first independently estimate them using autoencoders.",2.3 Optimization of parameters,[0],[0]
Then we employ an alternative optimization on Eq.,2.3 Optimization of parameters,[0],[0]
"(1) for
(Θx,Θy) and Π until convergence.",2.3 Optimization of parameters,[0],[0]
We use 3 layer MLP neural networks for both f and g. Algorithm 1 summarises the steps.,2.3 Optimization of parameters,[0],[0]
"Optimization for Θx and Θy With fixed permutation matrix Π (or π), the objective function
min Θx,Θy
Ω(D; Θx,Θy)− λDΠ(D; Θx,Θy) (2)
is an autoencoder optimization with regularizer DΠ(·), and can be solved with backpropagation.",2.3 Optimization of parameters,[0],[0]
"Optimization for Π To find the permutation (word matching) Π that maximizes SMI given fixed encoding parameters Θx,Θy, we only need to optimize the dependency term DΠ in Eq.",2.3 Optimization of parameters,[0],[0]
(1).,2.3 Optimization of parameters,[0],[0]
"We employ the LSOM algorithm (Yamada et al., 2015).",2.3 Optimization of parameters,[0],[0]
"The estimator of SMI for samples {gx(xi), gy(yπ(i))}ni=1 encoded with gx, gy is:
ŜMI = 1 2n tr ( diag (α̂Θ,Π)KΘxΠ >LΘyΠ )",2.3 Optimization of parameters,[0],[0]
"− 1 2 .
",2.3 Optimization of parameters,[0],[0]
"Which leads to the optimization problem:
max Π∈{0,1}n×n
tr (
diag (α̂Θ,Π)KΘxΠ >LΘyΠ ) s.t. Π1n",2.3 Optimization of parameters,[0],[0]
"= 1n,Π>1n = 1n.",2.3 Optimization of parameters,[0],[0]
"(3)
Since the optimization problem is NP-hard, we iteratively solve the relaxed problem (Yamada et al., 2015):
",2.3 Optimization of parameters,[0],[0]
"Πnew = (1− η)Πold+
η argmax Π
tr ( diag ( α̂Θ,Πold ) KΘxΠ >LΘyΠ old ) ,
where 0 <",2.3 Optimization of parameters,[0],[0]
η ≤ 1 is a step size.,2.3 Optimization of parameters,[0],[0]
The optimization problem is a linear assignment problem (LAP).,2.3 Optimization of parameters,[0],[0]
"Thus, we can efficiently solve the algorithm by using the Hungarian method (Kuhn, 1955).",2.3 Optimization of parameters,[0],[0]
"To get discrete Π, we solve the last step by setting η = 1.
",2.3 Optimization of parameters,[0],[0]
"Intuitively, this can be seen as searching for the permutation Π for which the data in the two (initially unsorted views) have a matching withinview affinity (gram) matrix, where matching is defined by maximum SMI.",2.3 Optimization of parameters,[0],[0]
"In this section, we evaluate the efficacy of our proposed method against various state of the art methods for word translation.",3 Experiments,[0],[0]
Implementation Details,3 Experiments,[0],[0]
Our autoencoder consists of two layers with dropout and a tanh nonlinearity.,3 Experiments,[0],[0]
"We use polynomial kernel to compute
Algorithm 1 SMI-based unsupervised word translation Input: Unpaired word embeddings D = ({xi}ni=1, {yj}nj=1).
1: Init: weights Θx, Θy, permutation matrix Π. 2: while not converged do 3: Update Θx,Θy given Π: Backprop (2).",3 Experiments,[0],[0]
"4: Update Π given Θx,Θy: LSOM (3).",3 Experiments,[0],[0]
"5: end while
Output: Permutation Matrix Π. Params Θx, Θy.
the gram matrices K and L.",3 Experiments,[0],[0]
"For all pairs of languages, we fix the number of training epochs to 20.",3 Experiments,[0],[0]
All the word vectors are `2 unit normalized.,3 Experiments,[0],[0]
For CSLS we set the number of neighbors to 10.,3 Experiments,[0],[0]
"For optimizing Π at each epoch, we set the step size η = 0.75 and use 20 iterations.",3 Experiments,[0],[0]
"For the regularization R(Θ), we use the sum of the Frobenius norms of weight matrices.",3 Experiments,[0],[0]
"We train Θ using full batch gradient-descent, with learning rate 0.05.",3 Experiments,[0],[0]
"Datasets We performed experiments on the publicly available English-Italian, EnglishSpanish and English-Chinese datasets released by (Dinu and Baroni, 2015; Zhang et al., 2017b; Vulic and Moens, 2013).",3 Experiments,[0],[0]
We name this collective set of benchmarks BLI.,3 Experiments,[0],[0]
"We also conduct further experiments on a much larger recent public benchmark, MUSE (Conneau et al., 2018)1.",3 Experiments,[0],[0]
"Setting and Metrics We evaluate all methods in terms of Precision@1, following standard practice.",3 Experiments,[0],[0]
"We note that while various methods in the literature were initially presented as fully supervised (Mikolov et al., 2013), semi-supervised (using a seed dictionary)",3 Experiments,[0],[0]
"(Haghighi et al., 2008), or unsupervised (Zhang et al., 2017b), most of them can be straightforwardly adapted to run in any of these settings.",3 Experiments,[0],[0]
"Therefore we evaluate all methods both in the unsupervised setting in which we are primarily interested, and also the commonly evaluated semi-supervised setting with 500 seed pairs.",3 Experiments,[0],[0]
"Competitors: Non-Adversarial In terms of competitors that, like us, do not make use of GANs, we evaluate: Translation Matrix (Mikolov et al., 2013), which alternates between estimating a linear transformation by least squares and matching by nearest neighbour (NN).",3 Experiments,[0],[0]
"Multilingual Correlation (Faruqui and Dyer, 2014), and Matching CCA (Haghighi et al., 2008), which alternates between matching and estimat-
1https://github.com/facebookresearch/MUSE/
ing a joint linear subspace.",3 Experiments,[0],[0]
"Kernelized Sorting (Quadrianto et al., 2009), which directly uses HSIC-based statistical dependency to match heterogeneous data points.",3 Experiments,[0],[0]
"Self Training (Artetxe et al., 2017)",3 Experiments,[0],[0]
"A recent state of the art method that alternate between estimating an orthonormal transformation, and NN matching.
",3 Experiments,[0],[0]
"Competitors: Adversarial In terms of competitors that do make use of adversarial training, we compare: W-GAN and EMDOT (Zhang et al., 2017b) make use of adversarial learning using Wasserstein GAN and Earth Movers Distance respectively.",3 Experiments,[0],[0]
"GAN-NN (Conneau et al., 2018) uses adversarial learning to train an orthogonal transformation, along with some refinement steps and an improvement to the conventional NN matching procedure called ‘cross-domain similarity lo-
cal scaling’ (CSLS).",3 Experiments,[0],[0]
"Since this is a distinct step, we also evaluate our method with CSLS.
",3 Experiments,[0],[0]
"We use the provided code for GAN-NN and Self-Train, while re-implementing EDOT/WGAN to avoid dependency on theano.",3 Experiments,[0],[0]
Fully Unsupervised Table 1 presents comparative results for unsupervised word translation on BLI and MUSE.,3.1 Results,[0],[0]
From these we observe: (i),3.1 Results,[0],[0]
Our method (bottom) is consistently and significantly better than non-adversarial alternatives (top).,3.1 Results,[0],[0]
(ii),3.1 Results,[0],[0]
"Compared to adversarial alternatives Deep-SMI performs comparably.
",3.1 Results,[0],[0]
All methods generally perform better on the MUSE dataset than BLI.,3.1 Results,[0],[0]
"These differences are due to a few factors: MUSE is a significantly
larger dataset than BLI, benefitting methods that can exploit a large amount of training data.",3.1 Results,[0],[0]
"In the ground-truth annotation, BLI contains 1-1 translations while MUSE contains more realistic 1-many translations (if any correct translation is picked, a success is counted), making it easier to reach a higher score.
",3.1 Results,[0],[0]
Semi-supervised Results using a 500-word bilingual seed dictionary are presented in Table 2.,3.1 Results,[0],[0]
From these we observe: (i),3.1 Results,[0],[0]
"The conventional methods’ performances (top) jump up, showing that they are more competitive if at least some sparse data is available.",3.1 Results,[0],[0]
"(ii) Deep-SMI performance also improves, and still outperforms the classic methods significantly overall.",3.1 Results,[0],[0]
"(iii) Again, we perform comparably to the GAN methods.",3.1 Results,[0],[0]
Figure 1 shows the convergence process of DeepSMI.,3.2 Discussion,[0],[0]
"From this we see that: (i) Unlike the adversarial methods, our objective (Eq. (1)) improves smoothly over time, making convergence much easier to assess.",3.2 Discussion,[0],[0]
"(ii) Unlike the adversarial methods, our accuracy generally mirrors the model’s loss.",3.2 Discussion,[0],[0]
"In contrast, the various losses of the adversarial approaches do not well reflect translation accuracy, making model selection or early stopping a challenge in itself.",3.2 Discussion,[0],[0]
"Please compare our Figure 1 with Fig 3 in Zhang et al. (2017b), and Fig 2 in Conneau et al. (2018).
",3.2 Discussion,[0],[0]
There are two steps in our optimization: matching permutation Π and representation weights Θ.,3.2 Discussion,[0],[0]
"Although this is an alternating optimization, it is analogous to an EM-type algorithm optimizing latent variables (Π) and parameters (Θ).",3.2 Discussion,[0],[0]
"While local minima are a risk, every optimisation step for either variable reduces our objective Eq.",3.2 Discussion,[0],[0]
"(1).
",3.2 Discussion,[0],[0]
"There is no min-max game, so no risk of divergence as in the case of adversarial GAN-type methods.
",3.2 Discussion,[0],[0]
Our method can also be understood as providing an unsupervised Deep-CCA type model for relating heterogeneous data across two views.,3.2 Discussion,[0],[0]
"This is in contrast to the recently proposed unsupervised shallow CCA (Hoshen and Wolf, 2018), and conventional supervised Deep-CCA (Chang et al., 2018) that requires paired data for training; and using SMI rather than correlation as the optimisation objective.",3.2 Discussion,[0],[0]
We have presented an effective approach to unsupervised word translation that performs comparably to adversarial approaches while being significantly easier to train and diagnose; as well as outperforming prior non-adversarial approaches.,4 Conclusion,[0],[0]
"Word translation, or bilingual dictionary induction, is an important capability that impacts many multilingual language processing tasks.",abstractText,[0],[0]
"Recent research has shown that word translation can be achieved in an unsupervised manner, without parallel seed dictionaries or aligned corpora.",abstractText,[0],[0]
"However, state of the art methods for unsupervised bilingual dictionary induction are based on generative adversarial models, and as such suffer from their well known problems of instability and hyperparameter sensitivity.",abstractText,[0],[0]
We present a statistical dependency-based approach to bilingual dictionary induction that is unsupervised – no seed dictionary or parallel corpora required; and introduces no adversary – therefore being much easier to train.,abstractText,[0],[0]
Our method performs comparably to adversarial alternatives and outperforms prior non-adversarial methods.,abstractText,[0],[0]
Learning Unsupervised Word Translations Without Adversaries,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 1024–1034 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics",text,[0],[0]
Learning word representations has become a fundamental problem in processing natural languages.,1 Introduction,[0],[0]
"These semantic representations, which map a word into a point in a linear space, have been widely applied in downstream applications, including named entity recognition (Guo et al., 2014), document ranking (Nalisnick et al., 2016), sentiment analysis (Irsoy and Cardie, 2014), question answering (Antol et al., 2015), and image captioning (Karpathy and Fei-Fei, 2015).
",1 Introduction,[0],[0]
"Over the past few years, various approaches have been proposed to learn word vectors (e.g., (Pennington et al., 2014; Mikolov et al., 2013a; Levy and Goldberg, 2014b; Ji et al., 2015)) based on co-occurrence information between words observed on the training corpus.",1 Introduction,[0],[0]
"The intuition behind this is to represent words with similar vectors if
they have similar contexts.",1 Introduction,[0],[0]
"To learn a good word embedding, most approaches assume a large collection of text is freely available, such that the estimation of word co-occurrences is accurate.",1 Introduction,[0],[0]
"For example, the Google Word2Vec model (Mikolov et al., 2013a) is trained on the Google News dataset, which contains around 100 billion tokens, and the GloVe embedding (Pennington et al., 2014) is trained on a crawled corpus that contains 840 billion tokens in total.",1 Introduction,[0],[0]
"However, such an assumption may not hold for low-resource languages such as Inuit or Sindhi, which are not spoken by many people or have not been put into a digital format.",1 Introduction,[0],[0]
"For those languages, usually, only a limited size corpus is available.",1 Introduction,[0],[0]
"Training word vectors under such a setting is a challenging problem.
",1 Introduction,[0],[0]
One key restriction of the existing approaches is that they often mainly rely on the word pairs that are observed to co-occur on the training data.,1 Introduction,[0],[0]
"When the size of the text corpus is small, most word pairs are unobserved, resulting in an extremely sparse co-occurrence matrix (i.e., most entries are zero)1.",1 Introduction,[0],[0]
"For example, the text82 corpus has about 17,000,000 tokens and 71,000 distinct words.",1 Introduction,[0],[0]
"The corresponding co-occurrence matrix has more than five billion entries, but only about 45,000,000 are non-zeros (observed on the training corpus).",1 Introduction,[0],[0]
"Most existing approaches, such as Glove and Skip-gram, cannot handle a vast number of zero terms in the co-occurrence matrix; therefore, they only sub-sample a small subset of zero entries during the training.
",1 Introduction,[0],[0]
"In contrast, we argue that the unobserved word pairs can provide valuable information for training a word embedding model, especially when the co-occurrence matrix is very sparse.",1 Introduction,[0],[0]
"Inspired
1Note that the zero term can mean either the pairs of words cannot co-occur or the co-occurrence is not observed in the training corpus.
2http://mattmahoney.net/dc/text8.zip
1024
by the success of Positive-Unlabeled Learning (PU-Learning) in collaborative filtering applications (Pan et al., 2008; Hu et al., 2008; Pan and Scholz, 2009; Qin et al., 2010; Paquet and Koenigstein, 2013; Hsieh et al., 2015), we design an algorithm to effectively learn word embeddings from both positive (observed terms) and unlabeled (unobserved/zero terms) examples.",1 Introduction,[0],[0]
"Essentially, by using the square loss to model the unobserved terms and designing an efficient update rule based on linear algebra operations, the proposed PULearning framework can be trained efficiently and effectively.
",1 Introduction,[0],[0]
We evaluate the performance of the proposed approach in English3 and other three resourcescarce languages.,1 Introduction,[0],[0]
"We collected unlabeled language corpora from Wikipedia and compared the proposed approach with popular approaches, the Glove and the Skip-gram models, for training word embeddings.",1 Introduction,[0],[0]
"The experimental results show that our approach significantly outperforms the baseline models, especially when the size of the training corpus is small.
",1 Introduction,[0],[0]
"Our key contributions are summarized below.
",1 Introduction,[0],[0]
"• We propose a PU-Learning framework for learning word embedding.
",1 Introduction,[0],[0]
"• We tailor the coordinate descent algorithm (Yu et al., 2017b) for solving the corresponding optimization problem.
",1 Introduction,[0],[0]
• Our experimental results show that PULearning improves the word embedding training in the low-resource setting.,1 Introduction,[0],[0]
Learning word vectors.,2 Related work,[0],[0]
"The idea of learning word representations can be traced back to Latent Semantic Analysis (LSA) (Deerwester et al., 1990) and Hyperspace Analogue to Language (HAL) (Lund and Burgess, 1996), where word vectors are generated by factorizing a worddocument and word-word co-occurrence matrix, respectively.",2 Related work,[0],[0]
"Similar approaches can also be extended to learn other types of relations between words (Yih et al., 2012; Chang et al., 2013) or entities (Chang et al., 2014).",2 Related work,[0],[0]
"However, due to the limitation of the use of principal component analysis,
3Although English is not a resource-scarce language, we simulate the low-resource setting in an English corpus.",2 Related work,[0],[0]
"In this way, we leverage the existing evaluation methods to evaluate the proposed approach.
",2 Related work,[0],[0]
these approaches are often less flexible.,2 Related work,[0],[0]
"Besides, directly factorizing the co-occurrence matrix may cause the frequent words dominating the training objective.
",2 Related work,[0],[0]
"In the past decade, various approaches have been proposed to improve the training of word embeddings.",2 Related work,[0],[0]
"For example, instead of factorizing the co-occurrence count matrix, Bullinaria and Levy (2007); Levy and Goldberg (2014b) proposed to factorize point-wise mutual information (PMI) and positive PMI (PPMI) matrices as these metrics scale the co-occurrence counts (Bullinaria and Levy, 2007; Levy and Goldberg, 2014b).",2 Related work,[0],[0]
"Skipgram model with negative-sampling (SGNS) and Continuous Bag-of-Words models (Mikolov et al., 2013b) were proposed for training word vectors on a large scale without consuming a large amount of memory.",2 Related work,[0],[0]
"GloVe (Pennington et al., 2014) is proposed as an alternative to decompose a weighted log co-occurrence matrix with a bias term added to each word.",2 Related work,[0],[0]
"Very recently, WordRank model (Ji et al., 2015) has been proposed to minimize a ranking loss which naturally fits the tasks requiring ranking based evaluation metrics.",2 Related work,[0],[0]
Stratos et al. (2015) also proposed CCA (canonical correlation analysis)-based word embedding which shows competitive performance.,2 Related work,[0],[0]
"All these approaches focus on the situations where a large text corpus is available.
",2 Related work,[0],[0]
"Positive and Unlabeled (PU) Learning: Positive and Unlabeled (PU) learning (Li and Liu, 2005) is proposed for training a model when the positive instances are partially labeled and the unlabeled instances are mostly negative.",2 Related work,[0],[0]
"Recently, PU learning has been used in many classification and collaborative filtering applications due to the nature of “implicit feedback” in many recommendation systems—users usually only provide positive feedback (e.g., purchases, clicks) and it is very hard to collect negative feedback.
",2 Related work,[0],[0]
"To resolve this problem, a series of PU matrix completion algorithms have been proposed (Pan et al., 2008; Hu et al., 2008; Pan and Scholz, 2009; Qin et al., 2010; Paquet and Koenigstein, 2013; Hsieh et al., 2015; Yu et al., 2017b).",2 Related work,[0],[0]
The main idea is to assign a small uniform weight to all the missing or zero entries and factorize the corresponding matrix.,2 Related work,[0],[0]
"Among them, Yu et al. (2017b) proposed an efficient algorithm for matrix factorization with PU-learning, such that the weighted matrix is constructed implicitly.",2 Related work,[0],[0]
"In this paper, we
W, C vocabulary of central and context words m,n vocabulary sizes k dimension of word vectors W,H m× k and n×",2 Related work,[0],[0]
"k latent matrices Cij weight for the (i, j) entry Aij value of the PPMI matrix Qij value of the co-occurrence matrix wi,hj i-th row of W and j-th row of H b, b̂ bias term λi, λj regularization parameters | · | the size of a set Ω Set of possible word-context pairs Ω+ Set of observed word-context pairs Ω− Set of unobserved word-context pairs
Table 1: Notations.
design a new approach for training word vectors by leveraging the PU-Learning framework and existing word embedding techniques.",2 Related work,[0],[0]
"To the best of our knowledge, this is the first work to train word embedding models using the PU-learning framework.",2 Related work,[0],[0]
"Similar to GloVe and other word embedding learning algorithms, the proposed approach consists of three steps.",3 PU-Learning for Word Embedding,[0],[0]
The first step is to construct a cooccurrence matrix.,3 PU-Learning for Word Embedding,[0],[0]
"Follow the literature (Levy and Goldberg, 2014a), we use the PPMI metric to measure the co-occurrence between words.",3 PU-Learning for Word Embedding,[0],[0]
"Then, in the second step, a PU-Learning approach is applied to factorize the co-occurrence matrix and generate word vectors and context vectors.",3 PU-Learning for Word Embedding,[0],[0]
"Finally, a post-processing step generates the final embedding vector for each word by combining the word vector and the context vector.
",3 PU-Learning for Word Embedding,[0],[0]
We summarize the notations used in this paper in Table 1 and describe the details of each step in the remainder of this section.,3 PU-Learning for Word Embedding,[0],[0]
Various metrics can be used for estimating the co-occurrence between words in a corpus.,3.1 Building the Co-Occurrence Matrix,[0],[0]
"PPMI metric stems from point-wise mutual information (PMI) which has been widely used as a measure of word association in NLP for various tasks (Church and Hanks, 1990).",3.1 Building the Co-Occurrence Matrix,[0],[0]
"In our case, each entry PMI(w, c) represents the relevant measure between a word w and a context word c by calculating the ratio between their joint probability (the
chance they appear together in a local context window) and their marginal probabilities (the chance they appear independently) (Levy and Goldberg, 2014b).",3.1 Building the Co-Occurrence Matrix,[0],[0]
"More specifically, each entry of PMI matrix can be defined by
PMI(w, c) = log P̂ (w, c)
P̂ (w) ·",3.1 Building the Co-Occurrence Matrix,[0],[0]
"P̂ (c) , (1)
where P̂ (w), P̂ (c) and P̂ (w, c) are the the frequency of word w, word c, and word pairs (w, c), respectively.",3.1 Building the Co-Occurrence Matrix,[0],[0]
"The PMI matrix can be computed based on the co-occurrence counts of word pairs, and it is an information-theoretic association measure which effectively eliminates the big differences in magnitude among entries in the cooccurrence matrix.
",3.1 Building the Co-Occurrence Matrix,[0],[0]
"Extending from the PMI metric, the PPMI metric replaces all the negative entries in PMI matrix by 0:
PPMI(w, c) = max(PMI(w, c), 0).",3.1 Building the Co-Occurrence Matrix,[0],[0]
"(2)
The intuition behind this is that people usually perceive positive associations between words (e.g. “ice” and “snow”).",3.1 Building the Co-Occurrence Matrix,[0],[0]
"In contrast, the negative association is hard to define (Levy and Goldberg, 2014b).",3.1 Building the Co-Occurrence Matrix,[0],[0]
"Therefore, it is reasonable to replace the negative entries in the PMI matrix by 0, such that the negative association is treated as “uninformative”.",3.1 Building the Co-Occurrence Matrix,[0],[0]
"Empirically, several existing works (Levy et al., 2015; Bullinaria and Levy, 2007) showed that the PPMI metric achieves good performance on various semantic similarity tasks.
",3.1 Building the Co-Occurrence Matrix,[0],[0]
"In practice, we follow the pipeline described in Levy et al. (2015) to build the PPMI matrix and apply several useful tricks to improve its quality.",3.1 Building the Co-Occurrence Matrix,[0],[0]
"First, we apply a context distribution smoothing mechanism to enlarge the probability of sampling a rare context.",3.1 Building the Co-Occurrence Matrix,[0],[0]
"In particular, all context counts are scaled to the power of α.4:
PPMIα(w, c) = max
( log P̂ (w, c)
P̂ (w)P̂α(c) , 0
)
P̂α(c) = #(c)α∑ c̄ #(c̄) α ,
where #(w) denotes the number of times word w appears.",3.1 Building the Co-Occurrence Matrix,[0],[0]
"This smoothing mechanism effectively
4Empirically, α = 0.75 works well (Mikolov et al., 2013b).
",3.1 Building the Co-Occurrence Matrix,[0],[0]
"alleviates PPMI’s bias towards rare words (Levy et al., 2015).
",3.1 Building the Co-Occurrence Matrix,[0],[0]
"Next, previous studies show that words that occur too frequent often dominate the training objective (Levy et al., 2015) and degrade the performance of word embedding.",3.1 Building the Co-Occurrence Matrix,[0],[0]
"To avoid this issue, we follow Levy et al. (2015) to sub-sample words with frequency more than a threshold twith a probability p defined as:
p = 1− √ t
P̂ (w) .",3.1 Building the Co-Occurrence Matrix,[0],[0]
We proposed a matrix factorization based word embedding model which aims to minimize the reconstruction error on the PPMI matrix.,3.2 PU-Learning for Matrix Factorization,[0],[0]
"The lowrank embeddings are obtained by solving the following optimization problem:
min W,H
∑
i,j∈Ω",3.2 PU-Learning for Matrix Factorization,[0],[0]
Cij(Aij −wTi hj,3.2 PU-Learning for Matrix Factorization,[0],[0]
"− bi − b̂j)2 + ∑
i
λi‖wi‖2 + ∑
j
λj‖hj‖2, (3)
where W and H are m× k and n× k latent matrices, representing words and context words, respectively.",3.2 PU-Learning for Matrix Factorization,[0],[0]
The first term in Eq.,3.2 PU-Learning for Matrix Factorization,[0],[0]
"(3) aims for minimizing reconstruction error, and the second and third terms are regularization terms.",3.2 PU-Learning for Matrix Factorization,[0],[0]
λi and λj are weights of regularization term.,3.2 PU-Learning for Matrix Factorization,[0],[0]
"They are hyperparameters that need to be tuned.
",3.2 PU-Learning for Matrix Factorization,[0],[0]
"The zero entries in co-occurrence matrix denote that two words never appear together in the current corpus, which also refers to unobserved terms.",3.2 PU-Learning for Matrix Factorization,[0],[0]
The unobserved term can be either real zero (two words shouldn’t be co-occurred even when we use very large corpus) or just missing in the small corpus.,3.2 PU-Learning for Matrix Factorization,[0],[0]
"In contrast to SGNS sub-sampling a small set of zero entries as negative samples, our model will try to use the information from all zeros.
",3.2 PU-Learning for Matrix Factorization,[0],[0]
"The set Ω includes all the |W| × |C| entries— both positive and zero entries:
Ω = Ω+ ∪ Ω−. (4)
Note that we define the positive samples Ω+ to be all the (w, c) pairs that appear at least one time in the corpus, and negative samples Ω− are word pairs that never appear in the corpus.
Weighting function.",3.2 PU-Learning for Matrix Factorization,[0],[0]
"Eq (3) is very similar to the one used in previous matrix factorization approaches such as GloVe, but we propose a new way to set the weights Cij .",3.2 PU-Learning for Matrix Factorization,[0],[0]
"If we set equal weights for all the entries, then Cij = constant, and the model is very similar to conducting SVD for the PPMI matrix.",3.2 PU-Learning for Matrix Factorization,[0],[0]
"Previous work has shown that this approach often suffers from poor performance (Pennington et al., 2014).",3.2 PU-Learning for Matrix Factorization,[0],[0]
"More advanced methods, such as GloVe, set non-uniform weights for observed entries to reflect their confidence.",3.2 PU-Learning for Matrix Factorization,[0],[0]
"However, the time complexity of their algorithm is proportional to number of nonzero weights (|(i, j) | Cij 6= 0|), thus they have to set zero weights for all the unobserved entries (Cij = 0 for Ω−), or try to incorporate a small set of unobserved entries by negative sampling.
",3.2 PU-Learning for Matrix Factorization,[0],[0]
"We propose to set the weights for Ω+ and Ω−
differently using the following scheme:
Cij =   (Qij/xmax)",3.2 PU-Learning for Matrix Factorization,[0],[0]
"α, if Qij ≤ xmax, and (i, j) ∈ Ω+
1,",3.2 PU-Learning for Matrix Factorization,[0],[0]
"if Qij > xmax, and (i, j) ∈ Ω+",3.2 PU-Learning for Matrix Factorization,[0],[0]
"ρ, (i, j) ∈ Ω−
(5)
",3.2 PU-Learning for Matrix Factorization,[0],[0]
"Here xmax and α are re-weighting parameters, and ρ is the unified weight for unobserved terms.",3.2 PU-Learning for Matrix Factorization,[0],[0]
"We will discuss them later.
",3.2 PU-Learning for Matrix Factorization,[0],[0]
"For entries in Ω+, we set the non-uniform weights as in GloVe (Pennington et al., 2014), which assigns larger weights to context word that appears more often with the given word, but also avoids overwhelming the other terms.",3.2 PU-Learning for Matrix Factorization,[0],[0]
"For entries in Ω−, instead of setting their weights to be 0, we assign a small constant weight ρ.",3.2 PU-Learning for Matrix Factorization,[0],[0]
"The main idea is from the literature of PU-learning (Hu et al., 2008; Hsieh et al., 2015): although missing entries are highly uncertain, they are still likely to be true 0, so we should incorporate them in the learning process but multiplying with a smaller weight according to the uncertainty.",3.2 PU-Learning for Matrix Factorization,[0],[0]
"Therefore, ρ in (5) reflects how confident we are to the zero entries.
",3.2 PU-Learning for Matrix Factorization,[0],[0]
"In our experiments, we set xmax = 10, α = 3/4 according to (Pennington et al., 2014), and let ρ be a parameter to tune.",3.2 PU-Learning for Matrix Factorization,[0],[0]
"Experiments show that adding weighting function obviously improves the performance especially on analogy tasks.
",3.2 PU-Learning for Matrix Factorization,[0],[0]
Bias term.,3.2 PU-Learning for Matrix Factorization,[0],[0]
"Unlike previous work on PU matrix completion (Yu et al., 2017b; Hsieh et al., 2015), we add the bias terms for word and context word
vectors.",3.2 PU-Learning for Matrix Factorization,[0],[0]
"Instead of directly using w>i hj to approximate Aij , we use
Aij ≈ w>i hj + bi + b̂j .
Yu et al. (2017b) design an efficient columnwise coordinate descent algorithm for solving the PU matrix factorization problem; however, they do not consider the bias term in their implementations.",3.2 PU-Learning for Matrix Factorization,[0],[0]
"To incorporate the bias term in (3), we propose the following training algorithm based on the coordinate descent approach.",3.2 PU-Learning for Matrix Factorization,[0],[0]
"Our algorithm does not introduce much overhead compared to that in (Yu et al., 2017b).
",3.2 PU-Learning for Matrix Factorization,[0],[0]
"We augment each wi,hj ∈ Rk into the following (k + 2) dimensional vectors:
w′i =   wi1 ...",3.2 PU-Learning for Matrix Factorization,[0],[0]
"wik 1 bi   h′j =   hj1 ... hjk b̂j 1  
Therefore, for each word and context vector, we have the following equality
〈w′i,h′j〉 = 〈wi,hj〉+ bi + b̂j ,
which means the loss function in (3) can be written as
∑
i,j∈Ω Cij(Aij −w′>i h′j)2.
",3.2 PU-Learning for Matrix Factorization,[0],[0]
"Also, we denote W ′ =",3.2 PU-Learning for Matrix Factorization,[0],[0]
"[w′1,w ′ 2, . . .",3.2 PU-Learning for Matrix Factorization,[0],[0]
",w ′ n] > and H ′ =",3.2 PU-Learning for Matrix Factorization,[0],[0]
"[h′1,h ′ 2, . . .",3.2 PU-Learning for Matrix Factorization,[0],[0]
",h ′ n]",3.2 PU-Learning for Matrix Factorization,[0],[0]
>.,3.2 PU-Learning for Matrix Factorization,[0],[0]
"In the column-wise coordinate descent method, at each iteration we pick a t ∈ {1, . . .",3.2 PU-Learning for Matrix Factorization,[0],[0]
", (k+2)}, and update the t-th column of W ′ and H ′. The updates can be derived for the following two cases:
a. When t ≤ k, the elements in the t-th column is w1t, . . .",3.2 PU-Learning for Matrix Factorization,[0],[0]
", wnt and we can directly use the update rule derived in Yu et al. (2017b) to update them.
",3.2 PU-Learning for Matrix Factorization,[0],[0]
b.,3.2 PU-Learning for Matrix Factorization,[0],[0]
"When t = k + 1, we do not update the corresponding column of W ′ since the elements are all 1, and we use the similar coordinate descent update to update the k+ 1-th column of H ′ (corresponding to b̂1, . . .",3.2 PU-Learning for Matrix Factorization,[0],[0]
", b̂n).",3.2 PU-Learning for Matrix Factorization,[0],[0]
"When t = k+2, we do not update the corresponding column of H ′",3.2 PU-Learning for Matrix Factorization,[0],[0]
(they are all 1) and we update the k+ 2-th column of W ′,3.2 PU-Learning for Matrix Factorization,[0],[0]
"(corresponding to b1, . . .",3.2 PU-Learning for Matrix Factorization,[0],[0]
", bn) using coordinate descent.
",3.2 PU-Learning for Matrix Factorization,[0],[0]
"With some further derivations, we can show that the algorithm only requires O(nnz(A) + nk) time to update each column,5 so the overall complexity is O(nnz(A)k + nk2) time per epoch, which is only proportional to number of nonzero terms in A. Therefore, with the same time complexity as GloVe, we can utilize the information from all the zero entries in A instead of only sub-sampling a small set of zero entries.",3.2 PU-Learning for Matrix Factorization,[0],[0]
"In the PU-Learning formulation, ρ represents the unified weight that assigned to the unobserved terms.",3.3 Interpretation of Parameters,[0],[0]
"Intuitively, ρ reflects the confidence on unobserved entries—larger ρmeans that we are quite certain about the zeroes, while small ρ indicates the many of unobserved pairs are not truly zero.",3.3 Interpretation of Parameters,[0],[0]
"When ρ = 0, the PU-Learning approach reduces to a model similar to GloVe, which discards all the unobserved terms.",3.3 Interpretation of Parameters,[0],[0]
"In practice, ρ is an important parameter to tune, and we find that ρ = 0.0625 achieves the best results in general.",3.3 Interpretation of Parameters,[0],[0]
"Regarding the other parameter, λ is the regularization term for preventing the embedding model from overfitting.",3.3 Interpretation of Parameters,[0],[0]
"In practice, we found the performance is not very sensitive to λ as long as it is resonably small.",3.3 Interpretation of Parameters,[0],[0]
"More discussion about the parameter setting can be found in Section 5.
",3.3 Interpretation of Parameters,[0],[0]
Post-processing of Word/Context Vectors The PU-Learning framework factorizes the PPMI matrix and generates two vectors for each word,3.3 Interpretation of Parameters,[0],[0]
"i, wi ∈ Rk and hi ∈ Rk.",3.3 Interpretation of Parameters,[0],[0]
The former represents the word when it is the central word and the latter represents the word when it is in context.,3.3 Interpretation of Parameters,[0],[0]
Levy et al. (2015) shows that averaging these two vectors (uavgi = wi + hi) leads to consistently better performance.,3.3 Interpretation of Parameters,[0],[0]
The same trick of constructing word vectors is also used in GloVe.,3.3 Interpretation of Parameters,[0],[0]
"Therefore, in the experiments, we evaluate all models with uavg.",3.3 Interpretation of Parameters,[0],[0]
Our goal in this paper is to train word embedding models for low-resource languages.,4 Experimental Setup,[0],[0]
"In this section, we describe the experimental designs to evaluate the proposed PU-learning approach.",4 Experimental Setup,[0],[0]
We first describe the data sets and the evaluation metrics.,4 Experimental Setup,[0],[0]
"Then, we provide details of parameter tuning.
",4 Experimental Setup,[0],[0]
5Here we assume m = n for the sake of simplicity.,4 Experimental Setup,[0],[0]
"And, nnz(A) denotes the number of nonzero terms in the matrix A.",4 Experimental Setup,[0],[0]
"We consider two widely used tasks for evaluating word embeddings, the word similarity task and the word analogy task.",4.1 Evaluation tasks,[0],[0]
"In the word similarity task, each question contains a word pairs and an annotated similarity score.",4.1 Evaluation tasks,[0],[0]
The goal is to predict the similarity score between two words based on the inner product between the corresponding word vectors.,4.1 Evaluation tasks,[0],[0]
"The performance is then measured by the Spearmans rank correlation coefficient, which estimates the correlation between the model predictions and human annotations.",4.1 Evaluation tasks,[0],[0]
"Following the settings in literature, the experiments are conducted on five data sets, WordSim353 (Finkelstein et al., 2001), WordSim Similarity (Zesch et al., 2008), WordSim Relatedness (Agirre et al., 2009), Mechanical Turk (Radinsky et al., 2011) and MEN (Bruni et al., 2012).
",4.1 Evaluation tasks,[0],[0]
"In the word analogy task, we aim at solving analogy puzzles like “man is to woman as king is to ?”, where the expected answer is “queen.”",4.1 Evaluation tasks,[0],[0]
"We consider two approaches for generating answers to the puzzles, namely 3CosAdd and 3CosMul (see (Levy and Goldberg, 2014a) for details).",4.1 Evaluation tasks,[0],[0]
"We evaluate the performances on Google analogy dataset (Mikolov et al., 2013a) which contains 8,860 semantic and 10,675 syntactic questions.",4.1 Evaluation tasks,[0],[0]
"For the analogy task, only the answer that exactly matches the annotated answer is counted as correct.",4.1 Evaluation tasks,[0],[0]
"As a result, the analogy task is more difficult than the similarity task because the evalu-
ation metric is stricter and it requires algorithms to differentiate words with similar meaning and find the right answer.
",4.1 Evaluation tasks,[0],[0]
"To evaluate the performances of models in the low-resource setting, we train word embedding models on Dutch, Danish, Czech and, English data sets collected from Wikipedia.",4.1 Evaluation tasks,[0],[0]
"The original Wikipedia corpora in Dutch, Danish, Czech and English contain 216 million, 47 million, 92 million, and 1.8 billion tokens, respectively.",4.1 Evaluation tasks,[0],[0]
"To simulate the low-resource setting, we sub-sample the Wikipedia corpora and create a subset of 64 million tokens for Dutch and Czech and a subset of 32 million tokens for English.",4.1 Evaluation tasks,[0],[0]
"We will demonstrate how the size of the corpus affects the performance of embedding models in the experiments.
",4.1 Evaluation tasks,[0],[0]
"To evaluate the performance of word embeddings in Czech, Danish, and Dutch, we translate the English similarity and analogy test sets to the other languages by using Google Cloud Translation API6.",4.1 Evaluation tasks,[0],[0]
"However, an English word may be translated to multiple words in another language (e.g., compound nouns).",4.1 Evaluation tasks,[0],[0]
We discard questions containing such words (see Table 3 for details).,4.1 Evaluation tasks,[0],[0]
"Because all approaches are compared on the same test set for each language, the comparisons are fair.",4.1 Evaluation tasks,[0],[0]
"We compare the proposed approach with two baseline methods, GloVe and SGNS.",4.2 Implementation and Parameter Setting,[0],[0]
"The imple-
6https://cloud.google.com/translate
mentations of Glove7 and SGNS8 and provided by the original authors, and we apply the default settings when appropriate.",4.2 Implementation and Parameter Setting,[0],[0]
The proposed PULearning framework is implemented based on Yu et al. (2017a).,4.2 Implementation and Parameter Setting,[0],[0]
"With the implementation of efficient update rules, our model requires less than 500 seconds to perform one iteration over the entire text8 corpus, which consists of 17 million tokens 9.",4.2 Implementation and Parameter Setting,[0],[0]
"All the models are implemented in C++.
",4.2 Implementation and Parameter Setting,[0],[0]
"We follow Levy et al. (2015)10 to set windows size as 15, minimal count as 5, and dimension of word vectors as 300 in the experiments.",4.2 Implementation and Parameter Setting,[0],[0]
Training word embedding models involves selecting several hyper-parameters.,4.2 Implementation and Parameter Setting,[0],[0]
"However, as the word embeddings are usually evaluated in an unsupervised setting (i.e., the evaluation data sets are not seen during the training), the parameters should not be tuned on each dataset.",4.2 Implementation and Parameter Setting,[0],[0]
"To conduct a fair comparison, we tune hyper-parameters on the text8 dataset.",4.2 Implementation and Parameter Setting,[0],[0]
"For GloVe model, we tune the discount parameters xmax and find that xmax = 10 per-
7https://nlp.stanford.edu/projects/glove 8https://code.google.com/archive/p/word2vec/ 9http://mattmahoney.net/dc/text8.zip
10https://bitbucket.org/omerlevy/hyperwords
forms the best.",4.2 Implementation and Parameter Setting,[0],[0]
SGNS has a natural parameter k which denotes the number of negative samples.,4.2 Implementation and Parameter Setting,[0],[0]
"Same as Levy et al. (2015), we found that setting k to 5 leads to the best performance.",4.2 Implementation and Parameter Setting,[0],[0]
"For the PU-learning model, ρ and λ are two important parameters that denote the unified weight of zero entries and the weight of regularization terms, respectively.",4.2 Implementation and Parameter Setting,[0],[0]
We tune ρ in a range from 2−1 to 2−14 and λ in a range from 20 to 2−10.,4.2 Implementation and Parameter Setting,[0],[0]
We analyze the sensitivity of the model to these hyper-parameters in the experimental result section.,4.2 Implementation and Parameter Setting,[0],[0]
The best performance of each model on the text8 dataset is shown in the Table 2.,4.2 Implementation and Parameter Setting,[0],[0]
It shows that PU-learning model outperforms two baseline models.,4.2 Implementation and Parameter Setting,[0],[0]
"We compared the proposed PU-Learning framework with two popular word embedding models – SGNS (Mikolov et al., 2013b) and Glove (Pennington et al., 2014) on English and three other languages.",5 Experimental Results,[0],[0]
The experimental results are reported in Table 4.,5 Experimental Results,[0],[0]
The results show that the proposed PULearning framework outperforms the two baseline approaches significantly in most datasets.,5 Experimental Results,[0],[0]
"This re-
sults confirm that the unobserved word pairs carry important information and the PU-Learning model leverages such information and achieves better performance.",5 Experimental Results,[0],[0]
"To better understand the model, we conduct detailed analysis as follows.
",5 Experimental Results,[0],[0]
"Performance v.s. Corpus size We investigate the performance of our algorithm with respect to different corpus size, and plot the results in Figure 1.",5 Experimental Results,[0],[0]
"The results in analogy task are obtained by 3CosMul method (Levy and Goldberg, 2014a).",5 Experimental Results,[0],[0]
"As the corpus size grows, the performance of all models improves, and the PU-learning model consistently outperforms other methods in all the tasks.",5 Experimental Results,[0],[0]
"However, with the size of the corpus increases, the difference becomes smaller.",5 Experimental Results,[0],[0]
"This is reasonable as when the corpus size increases the number of nonzero terms becomes smaller and the PU-learning approach is resemblance to Glove.
",5 Experimental Results,[0],[0]
Impacts of ρ and λ,5 Experimental Results,[0],[0]
"We investigate how sensitive the model is to the hyper-parameters, ρ and λ.",5 Experimental Results,[0],[0]
"Figure 2 shows the performance along with various values of λ and ρ when training on the text8 corpus, respectively.",5 Experimental Results,[0],[0]
Note that the x-axis is in log scale.,5 Experimental Results,[0],[0]
"When ρ is fixed, a big λ degrades the performance of the model significantly.",5 Experimental Results,[0],[0]
This is because when λ is too big the model suffers from underfitting.,5 Experimental Results,[0],[0]
"The model is less sensitive when λ is small and in general, λ = 2−11 achieves consistently good performance.
",5 Experimental Results,[0],[0]
"When λ is fixed, we observe that large ρ (e.g., ρ ≈ 2−4) leads to better performance.",5 Experimental Results,[0],[0]
"As ρ represents the weight assigned to the unobserved term, this result confirms that the model benefits from using the zero terms in the co-occurrences matrix.",5 Experimental Results,[0],[0]
"In this paper, we presented a PU-Learning framework for learning word embeddings of lowresource languages.",6 Conclusion,[0],[0]
"We evaluated the proposed approach on English and other three languages and showed that the proposed approach outperforms other baselines by effectively leveraging the information from unobserved word pairs.
",6 Conclusion,[0],[0]
"In the future, we would like to conduct experiments on other languages where available text corpora are relatively hard to obtain.",6 Conclusion,[0],[0]
"We are also interested in applying the proposed approach to domains, such as legal documents and clinical notes, where the amount of accessible data is small.",6 Conclusion,[0],[0]
"Besides, we plan to study how to leverage other information to facilitate the training of word embeddings under the low-resource setting.
",6 Conclusion,[0],[0]
"Acknowledge
This work was supported in part by National Science Foundation Grant IIS-1760523, IIS-1719097 and an NVIDIA Hardware Grant.",6 Conclusion,[0],[0]
Word embedding is a key component in many downstream applications in processing natural languages.,abstractText,[0],[0]
Existing approaches often assume the existence of a large collection of text for learning effective word embedding.,abstractText,[0],[0]
"However, such a corpus may not be available for some low-resource languages.",abstractText,[0],[0]
"In this paper, we study how to effectively learn a word embedding model on a corpus with only a few million tokens.",abstractText,[0],[0]
"In such a situation, the co-occurrence matrix is sparse as the co-occurrences of many word pairs are unobserved.",abstractText,[0],[0]
"In contrast to existing approaches often only sample a few unobserved word pairs as negative samples, we argue that the zero entries in the co-occurrence matrix also provide valuable information.",abstractText,[0],[0]
We then design a Positive-Unlabeled Learning (PU-Learning) approach to factorize the co-occurrence matrix and validate the proposed approaches in four different languages.,abstractText,[0],[0]
Learning Word Embeddings for Low-resource Languages by PU Learning,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 4829–4833 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
4829",text,[0],[0]
Co-reference resolution requires models to cluster mentions that refer to the same physical entities.,1 Introduction,[0],[0]
The models based on neural networks typically require different levels of semantic representations of input sentences.,1 Introduction,[0],[0]
"The models usually need to calculate the representations of word spans, or mentions, given pre-trained character and wordlevel embeddings (Turian et al., 2010; Pennington et al., 2014) before predicting antecedents.",1 Introduction,[0],[0]
"The mention-level embeddings are used to make coreference decisions, typically by scoring mention pairs and making links (Lee et al., 2017; Clark and Manning, 2016a; Wiseman et al., 2016).",1 Introduction,[0],[0]
"Long short-term memories (LSTMs) are often used to encode the syntactic and semantic information of input sentences.
",1 Introduction,[0],[0]
Articles and conversations include more than one sentences.,1 Introduction,[0],[0]
"Considering the accuracy and efficiency of co-reference resolution models, the encoder LSTM usually processes input sentences separately as a batch (Lee et al., 2017).",1 Introduction,[0],[0]
"The disadvantage of this method is that the models do not consider the dependency among words from different sentences, which plays a significant role in word representation learning and co-reference predicting.",1 Introduction,[0],[0]
"For example, pronouns are often linked to entities mentioned in other sentences, while their initial word vectors lack dependency information.",1 Introduction,[0],[0]
"As a result, a word representation model cannot learn an informative embedding of a pronoun without considering cross-sentence dependency in this case.
",1 Introduction,[0],[0]
It is also problematic if we encode the input document considering cross-sentence dependency and treat the entire document as one sentence.,1 Introduction,[0],[0]
An input article or conversation can be too long for a single LSTM cell to memorize.,1 Introduction,[0],[0]
"If the LSTM updates itself for too many steps, gradients will vanish or explode (Pascanu et al., 2013), and the coreference resolution model will be very difficult to optimize.",1 Introduction,[0],[0]
"Regarding the entire input corpus as one sequence instead of a batch also significantly increases the time complexity of the model.
",1 Introduction,[0],[0]
"To solve the problem that traditional LSTM encoders, which treat the input sentences as a batch, lack an ability to capture cross-sentence dependency, and to avoid the time complexity and difficulties of training the model concatenating all input sentences, we propose a cross-sentence encoder for end-to-end co-reference (E2E-CR).",1 Introduction,[0],[0]
"Borrowing the idea of an external memory module from Sukhbaatar et al. (2015), an external memory block containing syntactic and semantic information from context sentences is added to the standard LSTM model.",1 Introduction,[0],[0]
"With this context memory block, the proposed model is able to encode
input sentences as a batch, and also calculate the representations of input words by taking both target sentences and context sentences into consideration.",1 Introduction,[0],[0]
Experiments showed that this approach improved the performance of co-reference resolution models.,1 Introduction,[0],[0]
"A popular method of co-reference resolution is mention ranking (Durrett and Klein, 2013).",2.1 Co-reference Resolution,[0],[0]
"Reading each mention, the model calculates coreference scores for all antecedent mentions, and picks the mention with the highest positive score to be its co-reference.",2.1 Co-reference Resolution,[0],[0]
Many recent works are based on this approach.,2.1 Co-reference Resolution,[0],[0]
Durrett and Klein (2013) designed a set of feature templates to improve the mention-ranking model.,2.1 Co-reference Resolution,[0],[0]
Peng et al. (2015) proposed a mention-ranking model by jointly learning mention heads and co-references.,2.1 Co-reference Resolution,[0],[0]
Clark and Manning (2016a) proposed a reinforcement learning framework for the mention ranking approach.,2.1 Co-reference Resolution,[0],[0]
"Based on similar ideas but without using parsing features, the authors of Lee et al. (2017) proposed the current state-of-the-art model which uses neural networks to embed mentions and calculate mention and antecedent scores.",2.1 Co-reference Resolution,[0],[0]
"Lee et al. (2018) applied ELMo embeddings (Peters et al., 2018) to improve within-sentence dependency modeling and word representation learning.",2.1 Co-reference Resolution,[0],[0]
Wiseman et al. (2016) and Clark and Manning (2016b) proposed models using global entity-level features.,2.1 Co-reference Resolution,[0],[0]
"Distributed word embeddings has been used as the basic unit of language representation for over a decade (Bengio et al., 2003).",2.2 Language Representation Learning,[0],[0]
"Pre-trained word embeddings, for example GloVe (Pennington et al., 2014) and Skip-Gram (Mikolov et al., 2013) are widely used as the input of natural language processing models.
",2.2 Language Representation Learning,[0],[0]
"Long short-term memory (LSTM) networks (Hochreiter and Schmidhuber, 1997) are widely used for sentence modeling.",2.2 Language Representation Learning,[0],[0]
"A single-layer LSTM network was applied in the previous state-of-theart co-reference model (Lee et al., 2017) to generate word and mention representations.",2.2 Language Representation Learning,[0],[0]
"To capture dependency of longer distances, Campos et al. (2017) proposed a recurrent model that outputs hidden states by skipping input tokens.
",2.2 Language Representation Learning,[0],[0]
"Recently, memory networks (Sukhbaatar et al.,
2015) have been applied in language modeling (Cheng et al., 2016; Tran et al., 2016).",2.2 Language Representation Learning,[0],[0]
"Applying an attention mechanism on memory cells, memory networks allow the model to focus on significant words or segments for classification and generation tasks.",2.2 Language Representation Learning,[0],[0]
"Previous works have shown that applying memory blocks in LSTMs also improves longdistance dependency extraction (Yogatama et al., 2018).",2.2 Language Representation Learning,[0],[0]
"To improve the word representation learning model for better co-reference resolution performance, we propose two word representation models that learn cross-sentence dependency.",3 Learning Cross-Sentence dependency,[0],[0]
"Instead of treating the entire input document as separate sentences and encode the sentences as a batch with an LSTM, the most direct way to consider cross-sentence dependency is to initialize LSTM states with the encodings of adjacent sentences.",3.1 Linear Sentence Linking,[0],[0]
"We name this method linear sentence linking (LSL).
",3.1 Linear Sentence Linking,[0],[0]
"In LSL, we encode input sentences with a 2- layer bidirectional LSTM.",3.1 Linear Sentence Linking,[0],[0]
"Give input sentences [s1, s2 . . .",3.1 Linear Sentence Linking,[0],[0]
"sn], the outputs of the first layer are [[−→s 1;←−s 1],",3.1 Linear Sentence Linking,[0],[0]
"[−→s 2;←−s 2], . . .",3.1 Linear Sentence Linking,[0],[0]
[−→s n;←−s n]].,3.1 Linear Sentence Linking,[0],[0]
"In the second LSTM layer, the initial state of the forward LSTM of si is initialized as
−→ S i =",3.1 Linear Sentence Linking,[0],[0]
"[ −→c 20; [−→s i−1;←−s i−1]]
while the backward state is initialized as
←−",3.1 Linear Sentence Linking,[0],[0]
"S i = [ ←−c 20; [−→s i−1;←−s i−1]]
where ci0 stands for the initial cell of the ith layer, and x stands for the final output of the LSTMs in first layer.",3.1 Linear Sentence Linking,[0],[0]
We then concatenate the outputs of the forward and backward LSTMs in the second layer as the word representations for coreference prediction.,3.1 Linear Sentence Linking,[0],[0]
It is difficult for LSTMs to embed enough information about a long sentence into a lowdimensional distributed vector.,3.2 Attentional Sentence Linking,[0],[0]
"To collect richer knowledge from neighbor sentences, we propose a long short-term recurrent memory module and an attention mechanism to improve sentence linking.
",3.2 Attentional Sentence Linking,[0],[0]
"To describe the architecture of the proposed model, we focus on adjacent input sentences si−1
and si.",3.2 Attentional Sentence Linking,[0],[0]
"We present the input embeddings of the j-th word in the i-th sentence with xi,j .",3.2 Attentional Sentence Linking,[0],[0]
"To solve the traditional recurrent neural networks, Hochreiter and Schmidhuber (1997) proposed the LSTM architecture.",3.2.1 Long Short-Term Memory RNNs,[0],[0]
"The detail of recurrent state updating in LSTMs ht = flstm(xt, ht−1, ct−1) is shown in following equations.
",3.2.1 Long Short-Term Memory RNNs,[0],[0]
it = σ(Wxixt +Whiht−1 + bi) ft = σ(Wxfxt,3.2.1 Long Short-Term Memory RNNs,[0],[0]
+Whfht−1 + bf ),3.2.1 Long Short-Term Memory RNNs,[0],[0]
ct = ft ct−1 + it tanh(Wxcxt +Whcht−1 + bc) ot = σ(Wxoxt +Whoht−1 + bo),3.2.1 Long Short-Term Memory RNNs,[0],[0]
"ht = ot tanh(ct)
where xt is the input embedding and ht is the output representation of the t-th word.",3.2.1 Long Short-Term Memory RNNs,[0],[0]
We design an LSTM module with cross-sentence attention for capturing cross-sentence dependency.,3.2.2 LSTMs with Cross-Sentence Attention,[0],[0]
We name this method attentional sentence linking (ASL).,3.2.2 LSTMs with Cross-Sentence Attention,[0],[0]
"Considering input word xi,t in the ith sentence and all words from the previous sentence Xi−1 =",3.2.2 LSTMs with Cross-Sentence Attention,[0],[0]
"[xi−1,1, xi−1,2, . . .",3.2.2 LSTMs with Cross-Sentence Attention,[0],[0]
", xi−1,m], we regard the matrix Xi−1 as an external memory module and calculate an attention on its cells, where each cell contains a word embedding.
",3.2.2 LSTMs with Cross-Sentence Attention,[0],[0]
"αj = ecj∑ k e ck (1)
ck = fc([xi,t;ht−1;xi−1,k] T ) (2)
",3.2.2 LSTMs with Cross-Sentence Attention,[0],[0]
"With the attention distribution α, we can get a vector summarizing related information from si−1,
vi−1 = ∑ j αj · xi−1,j (3)
",3.2.2 LSTMs with Cross-Sentence Attention,[0],[0]
"The model decides if it needs to pay more attention on the current input or cross-sentence information with a context gate.
",3.2.2 LSTMs with Cross-Sentence Attention,[0],[0]
"gt = σ(fg([xi,t;ht−1; vi−1] T )) (4)
x̂i,t = gt · xi,t + (1− gt) · vi−1 (5)
σ",3.2.2 LSTMs with Cross-Sentence Attention,[0],[0]
(·) stands for the Sigmoid function.,3.2.2 LSTMs with Cross-Sentence Attention,[0],[0]
"The word representation of the target word is calculated as
hi,t = flstm(x̂i,t, hi,t−1, ci,t−1) (6)
where flstm stands for standard LSTM update described in section 3.2.1.",3.2.2 LSTMs with Cross-Sentence Attention,[0],[0]
"In this work, we apply the mention-ranking endto-end co-reference resolution (E2E-CR) model proposed by Lee et al. (2017) for co-reference prediction.",3.3 Co-reference Prediction,[0],[0]
The word representations applied in E2ECR model is formed by concatenating pre-trained word embeddings and the outputs of LSTMs.,3.3 Co-reference Prediction,[0],[0]
"In our work, we represent words by concatenating pre-trained word embeddings and the outputs of LSL- and ASL-LSTMs.",3.3 Co-reference Prediction,[0],[0]
"We train and evaluate our model on the English corpus of the CoNLL-2012 shared task (Pradhan et al., 2012).",4 Experiments,[0],[0]
"We implement our model based on the published implementation of the baseline E2ECR model (Lee et al., 2017) 1.",4 Experiments,[0],[0]
Our implementation is also available online for reproducing the results reported in this paper 2.,4 Experiments,[0],[0]
"In this section, we first describe our hyperparameter setup, and then show the experimental results of previous work and our proposed models.",4 Experiments,[0],[0]
"In practice, the LSTM modules applied in our model have 200 output units.",4.1 Model and Hyperparameter Setup,[0],[0]
"In ASL, we calculate cross-sentence dependency using a multilayer perceptron with one hidden layer consisting of 150 hidden units.",4.1 Model and Hyperparameter Setup,[0],[0]
The initial learning rate is set as 0.001 and decays 0.001% every 100 steps.,4.1 Model and Hyperparameter Setup,[0],[0]
"The model is optimized with the Adam algorithm (Kingma and Ba, 2014).",4.1 Model and Hyperparameter Setup,[0],[0]
We randomly select up to 40 continuous sentences for training if the input is too long.,4.1 Model and Hyperparameter Setup,[0],[0]
"In co-reference prediction, we select 250 candidate antecedents as our baseline model.",4.1 Model and Hyperparameter Setup,[0],[0]
We evaluate our model on the test set of the CoNLL-2012 shared task.,4.2 Experiment Results and Discussion,[0],[0]
The performance of previous work and our model are shown in Table 1.,4.2 Experiment Results and Discussion,[0],[0]
"We mainly focus on the average F1 score of MUC, B3, and CEAF metrics.",4.2 Experiment Results and Discussion,[0],[0]
"Comparing with the baseline model that achieved 67.2% F1 score, the ASL model improved the performance by 0.6% and achieved 67.8% average F1.",4.2 Experiment Results and Discussion,[0],[0]
"Experiments
1https://github.com/kentonl/e2e-coref 2https://github.com/luohongyin/
coatt-coref
show that the models that consider cross-sentence dependency significantly outperform the baseline model, which encodes each sentence from the input document separately.
",4.2 Experiment Results and Discussion,[0],[0]
"Experiments also indicated that the ASL model has better performance than the LSL model, since it summarizes extracts context information with an attention mechanism instead of simply viewing sentence-level embeddings.",4.2 Experiment Results and Discussion,[0],[0]
"This gives the model a better ability to model cross-sentence dependency.
",4.2 Experiment Results and Discussion,[0],[0]
Examples for comparing the performance of the ASL model and the baseline are shown in Table 2.,4.2 Experiment Results and Discussion,[0],[0]
Each example contains two continuous sentences with co-references distritubed in different sentences.,4.2 Experiment Results and Discussion,[0],[0]
Underlined spans in bold are target mentions and annotated co-references.,4.2 Experiment Results and Discussion,[0],[0]
"Spans in
green are ASL predictions, and spans in red are baseline predictions.",4.2 Experiment Results and Discussion,[0],[0]
"A prediction on “-” means that no mention is predicted as a co-reference.
",4.2 Experiment Results and Discussion,[0],[0]
"Table 2 shows that the baseline model, which does not consider cross-sentence dependency, has difficulty in learning the semantics of pronouns whose co-references are not in the same sentence.",4.2 Experiment Results and Discussion,[0],[0]
The pretrained embeddings of pronouns are not informative enough.,4.2 Experiment Results and Discussion,[0],[0]
"In the first example, “it” is not semantically similar with “SMS” in GloVe without any context, and in this case, “it” and “SMS” are in different sentences.",4.2 Experiment Results and Discussion,[0],[0]
"As a result, if reading this two sentences separately, it is hard for the encoder to represent “it” with the semantics of “SMS”.",4.2 Experiment Results and Discussion,[0],[0]
"This difficulty makes the co-reference resolution model either prediction a wrong antecedent mention, or cannot find any co-reference.
",4.2 Experiment Results and Discussion,[0],[0]
"However, with ASL, the model learns the semantics of pronouns with an attention to words in other sentences.",4.2 Experiment Results and Discussion,[0],[0]
"With the proposed context gate, ASL takes knowledge from context sentences if local inputs are not informative enough.",4.2 Experiment Results and Discussion,[0],[0]
"Based on word represents enhanced with cross-sentence dependency, the co-reference scoring model can make better predictions.",4.2 Experiment Results and Discussion,[0],[0]
We proposed linear and attentional sentence linking models for learning word representations that captures cross-sentence dependency.,5 Conclusion and Future Work,[0],[0]
"Experiments showed that the embeddings learned by proposed models successfully improved the performance of the state-of-the-art co-reference resolution model, indicating that cross-sentence dependency plays an important role in semantic learning in articles and conversations consists of multiple sentences.",5 Conclusion and Future Work,[0],[0]
"It worth exploring if our model can improve the performance of other natural language processing
applications whose inputs contain multiple sentences, for example, reading comprehension, dialog generation, and sentiment analysis.",5 Conclusion and Future Work,[0],[0]
"In this work, we present a word embedding model that learns cross-sentence dependency for improving end-to-end co-reference resolution (E2E-CR).",abstractText,[0],[0]
"While the traditional E2ECR model generates word representations by running long short-term memory (LSTM) recurrent neural networks on each sentence of an input article or conversation separately, we propose linear sentence linking and attentional sentence linking models to learn crosssentence dependency.",abstractText,[0],[0]
Both sentence linking strategies enable the LSTMs to make use of valuable information from context sentences while calculating the representation of the current input word.,abstractText,[0],[0]
"With this approach, the LSTMs learn word embeddings considering knowledge not only from the current sentence but also from the entire input document.",abstractText,[0],[0]
"Experiments show that learning cross-sentence dependency enriches information contained by the word representations, and improves the performance of the co-reference resolution model compared with our baseline.",abstractText,[0],[0]
Learning Word Representations with Cross-Sentence Dependency for End-to-End Co-reference Resolution,title,[0],[0]
"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 506–517 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics
https://doi.org/10.18653/v1/P17-1047",text,[0],[0]
"Automatically discovering words and other elements of linguistic structure from continuous speech has been a longstanding goal in computational linguists, cognitive science, and other speech processing fields.",1.1 Problem Statement and Motivation,[0],[0]
"Practically all humans acquire language at a very early age, but this task has proven to be an incredibly difficult problem for computers.",1.1 Problem Statement and Motivation,[0],[0]
"While conventional automatic speech recognition (ASR) systems have a long history and have recently made great strides thanks to the revival of deep neural networks (DNNs), their reliance on highly supervised training paradigms has essentially restricted their application to the major languages of the world, accounting for a small fraction of the more than 7,000 human languages spoken worldwide (Lewis et al., 2016).",1.1 Problem Statement and Motivation,[0],[0]
"The main
reason for this limitation is the fact that these supervised approaches require enormous amounts of very expensive human transcripts.",1.1 Problem Statement and Motivation,[0],[0]
"Moreover, the use of the written word is a convenient but limiting convention, since there are many oral languages which do not even employ a writing system.",1.1 Problem Statement and Motivation,[0],[0]
"In constrast, infants learn to communicate verbally before they are capable of reading and writing - so there is no inherent reason why spoken language systems need to be inseparably tied to text.
",1.1 Problem Statement and Motivation,[0],[0]
The key contribution of this paper has two facets.,1.1 Problem Statement and Motivation,[0],[0]
"First, we introduce a methodology capable of not only discovering word-like units from continuous speech at the waveform level with no additional text transcriptions or conventional speech recognition apparatus.",1.1 Problem Statement and Motivation,[0],[0]
"Instead, we jointly learn the semantics of those units via visual associations.",1.1 Problem Statement and Motivation,[0],[0]
"Although we evaluate our algorithm on an English corpus, it could conceivably run on any language without requiring any text or associated ASR capability.",1.1 Problem Statement and Motivation,[0],[0]
"Second, from a computational perspective, our method of speech pattern discovery runs in linear time.",1.1 Problem Statement and Motivation,[0],[0]
"Previous work has presented algorithms for performing acoustic pattern discovery in continuous speech (Park and Glass, 2008; Jansen et al., 2010; Jansen and Van Durme, 2011) without the use of transcriptions or another modality, but those algorithms are limited in their ability to scale by their inherent O(n2) complexity, since they do an exhaustive comparison of the data against itself.",1.1 Problem Statement and Motivation,[0],[0]
Our method leverages correlated information from a second modality - the visual domain - to guide the discovery of words and phrases.,1.1 Problem Statement and Motivation,[0],[0]
"This enables our method to run in O(n) time, and we demonstrate it scalability by discovering acoustic patterns in over 522 hours of audio.",1.1 Problem Statement and Motivation,[0],[0]
"A sub-field within speech processing that has garnered much attention recently is unsupervised
506
speech pattern discovery.",1.2 Previous Work,[0],[0]
"Segmental Dynamic Time Warping (S-DTW) was introduced by Park and Glass (2008), which discovers repetitions of the same words and phrases in a collection of untranscribed acoustic data.",1.2 Previous Work,[0],[0]
"Many subsequent efforts extended these ideas (Jansen et al., 2010; Jansen and Van Durme, 2011; Dredze et al., 2010; Harwath et al., 2012; Zhang and Glass, 2009).",1.2 Previous Work,[0],[0]
"Alternative approaches based on Bayesian nonparametric modeling (Lee and Glass, 2012; Ondel et al., 2016) employed a generative model to cluster acoustic segments into phoneme-like categories, and related works aimed to segment and cluster either reference or learned phonemelike tokens into higher-level units (Johnson, 2008; Goldwater et al., 2009; Lee et al., 2015).
",1.2 Previous Work,[0],[0]
"While supervised object detection is a standard problem in the vision community, several recent works have tackled the problem of weaklysupervised or unsupervised object localization (Bergamo et al., 2014; Cho et al., 2015; Zhou et al., 2015; Cinbis et al., 2016).",1.2 Previous Work,[0],[0]
"Although the focus of this work is discovering acoustic patterns, in the process we jointly associate the acoustic patterns with clusters of image crops, which we demonstrate capture visual patterns as well.
",1.2 Previous Work,[0],[0]
The computer vision and NLP communities have begun to leverage deep learning to create multimodal models of images and text.,1.2 Previous Work,[0],[0]
"Many works have focused on generating annotations or text captions for images (Socher and Li, 2010; Frome et al., 2013; Socher et al., 2014; Karpathy et al., 2014; Karpathy and Li, 2015; Vinyals et al., 2015; Fang et al., 2015; Johnson et al., 2016).",1.2 Previous Work,[0],[0]
"One interesting intersection between word induction from phoneme strings and multimodal modeling of images and text is that of Gelderloos and Chrupaa (2016), who uses images to segment words within captions at the phoneme string level.",1.2 Previous Work,[0],[0]
"Other work has taken these ideas beyond text, and attempted to relate images to spoken audio captions directly at the waveform level (Roy, 2003; Harwath and Glass, 2015; Harwath et al., 2016).",1.2 Previous Work,[0],[0]
"The work of (Harwath et al., 2016) is the most similar to ours, in which the authors learned embeddings at the entire image and entire spoken caption level and then used the embeddings to perform bidirectional retrieval.",1.2 Previous Work,[0],[0]
"In this work, we go further by automatically segmenting and clustering the spoken captions into individual word-like units, as well as the images into object-like categories.",1.2 Previous Work,[0],[0]
"We employ a corpus of over 200,000 spoken captions for images taken from the Places205 dataset (Zhou et al., 2014), corresponding to over 522 hours of speech data.",2 Experimental Data,[0],[0]
"The captions were collected using Amazon’s Mechanical Turk service, in which workers were shown images and asked to describe them verbally in a free-form manner.",2 Experimental Data,[0],[0]
"The data collection scheme is described in detail in Harwath et al. (2016), but the experiments in this paper leverage nearly twice the amount of data.",2 Experimental Data,[0],[0]
"For training our multimodal neural network as well as the pattern discovery experiments, we use a subset of 214,585 image/caption pairs, and we hold out a set of 1,000 pairs for evaluating the multimodal network’s retrieval ability.",2 Experimental Data,[0],[0]
"Because we lack ground truth text transcripts for the data, we used Google’s Speech Recognition public API to generate proxy transcripts which we use when analyzing our system.",2 Experimental Data,[0],[0]
"Note that the ASR was only used for analysis of the results, and was not involved in any of the learning.",2 Experimental Data,[0],[0]
"We first train a deep multimodal embedding network similar in spirit to the one described in Harwath et al. (2016), but with a more sophisticated architecture.",3 Audio-Visual Embedding Neural Networks,[0],[0]
"The model is trained to map entire image frames and entire spoken captions into a shared embedding space; however, as we will show, the trained network can then be used to localize patterns corresponding to words and phrases within the spectrogram, as well as visual objects within the image by applying it to small sub-regions of the image and spectrogram.",3 Audio-Visual Embedding Neural Networks,[0],[0]
"The model is comprised of two branches, one which takes as input images, and the other which takes as input spectrograms.",3 Audio-Visual Embedding Neural Networks,[0],[0]
"The image network is formed by taking the off-the-shelf VGG 16 layer network (Simonyan and Zisserman, 2014) and replacing the softmax classification layer with a linear transform which maps the 4096-dimensional activations of the second fully connected layer into our 1024-dimensional multimodal embedding space.",3 Audio-Visual Embedding Neural Networks,[0],[0]
"In our experiments, the weights of this projection layer are trained, but the layers taken from the VGG network below it are kept fixed.",3 Audio-Visual Embedding Neural Networks,[0],[0]
The second branch of our network analyzes speech spectrograms as if they were black and white images.,3 Audio-Visual Embedding Neural Networks,[0],[0]
"Our spectrograms are computed using 40 log Mel
filterbanks with a 25ms Hamming window and a 10ms shift.",3 Audio-Visual Embedding Neural Networks,[0],[0]
"The input to this branch always has 1 color channel and is always 40 pixels high (corresponding to the 40 Mel filterbanks), but the width of the spectrogram varies depending upon the duration of the spoken caption, with each pixel corresponding to approximately 10 milliseconds worth of audio.",3 Audio-Visual Embedding Neural Networks,[0],[0]
"The architecture we use is entirely convolutional and shown below, where C denotes the number of convolutional channels, W is filter width, H is filter height, and S is pooling stride.
",3 Audio-Visual Embedding Neural Networks,[0],[0]
1.,3 Audio-Visual Embedding Neural Networks,[0],[0]
"Convolution: C=128, W=1, H=40, ReLU 2.",3 Audio-Visual Embedding Neural Networks,[0],[0]
"Convolution: C=256, W=11, H=1, ReLU 3.",3 Audio-Visual Embedding Neural Networks,[0],[0]
"Maxpool: W=3, H=1, S=2 4.",3 Audio-Visual Embedding Neural Networks,[0],[0]
"Convolution: C=512, W=17, H=1, ReLU 5.",3 Audio-Visual Embedding Neural Networks,[0],[0]
"Maxpool: W=3, H=1, S=2 6.",3 Audio-Visual Embedding Neural Networks,[0],[0]
"Convolution: C=512, W=17, H=1, ReLU 7.",3 Audio-Visual Embedding Neural Networks,[0],[0]
"Maxpool: W=3, H=1, S=2 8.",3 Audio-Visual Embedding Neural Networks,[0],[0]
"Convolution: C=1024, W=17, H=1, ReLU 9.",3 Audio-Visual Embedding Neural Networks,[0],[0]
"Meanpool over entire caption
10.",3 Audio-Visual Embedding Neural Networks,[0],[0]
"L2 normalization In practice during training, we restrict the caption spectrograms to all be 1024 frames wide (i.e., 10sec of speech) by applying truncation or zero padding.",3 Audio-Visual Embedding Neural Networks,[0],[0]
"Additionally, both the images and spectrograms are mean normalized before training.",3 Audio-Visual Embedding Neural Networks,[0],[0]
"The overall multimodal network is formed by tying together the image and audio branches with a layer which takes both of their output vectors and computes an inner product between them, representing the similarity score between a given image/caption pair.",3 Audio-Visual Embedding Neural Networks,[0],[0]
"We train the network to assign high scores to matching image/caption pairs, and lower scores to mismatched pairs.
",3 Audio-Visual Embedding Neural Networks,[0],[0]
"Within a minibatch of B image/caption pairs, let Spj , j = 1, . . .",3 Audio-Visual Embedding Neural Networks,[0],[0]
", B denote the similarity score of the jth image/caption pair as output by the neural network.",3 Audio-Visual Embedding Neural Networks,[0],[0]
"Next, for each pair we randomly sample one impostor caption and one impostor image from the same minibatch.",3 Audio-Visual Embedding Neural Networks,[0],[0]
"Let Sij denote the similarity score between the jth caption and its impostor image, and Scj be the similarity score between the jth image and its impostor caption.",3 Audio-Visual Embedding Neural Networks,[0],[0]
"The total loss for the entire minibatch is then computed as
L(θ) = B∑
j=1
[max(0, Scj − Spj + 1)
+ max(0,",3 Audio-Visual Embedding Neural Networks,[0],[0]
"Sij − Spj + 1)] (1)
We train the neural network with 50 epochs of stochastic gradient descent using a batch size B =
128, a momentum of 0.9, and a learning rate of 1e5 which is set to geometrically decay by a factor between 2 and 5 every 5 to 10 epochs.",3 Audio-Visual Embedding Neural Networks,[0],[0]
"Although we have trained our multimodal network to compute embeddings at the granularity of entire images and entire caption spectrograms, we can easily apply it in a more localized fashion.",4 Finding and Clustering Audio-Visual Caption Groundings,[0],[0]
"In the case of images, we can simply take any arbitrary crop of an original image and resize it to 224x224 pixels.",4 Finding and Clustering Audio-Visual Caption Groundings,[0],[0]
"The audio network is even more trivial to apply locally, because it is entirely convolutional and the final mean pooling layer ensures that the output will be a 1024-dim vector no matter the extent of the input.",4 Finding and Clustering Audio-Visual Caption Groundings,[0],[0]
"The bigger question is where to locally apply the networks in order to discover meaningful acoustic and visual patterns.
",4 Finding and Clustering Audio-Visual Caption Groundings,[0],[0]
"Given an image and its corresponding spoken audio caption, we use the term grounding to refer to extracting meaningful segments from the caption and associating them with an appropriate subregion of the image.",4 Finding and Clustering Audio-Visual Caption Groundings,[0],[0]
"For example, if an image depicted a person eating ice cream and its caption contained the spoken words “A person is enjoying some ice cream,” an ideal set of groundings would entail the acoustic segment containing the word “person” linked to a bounding box around the person, and the segment containing the word “ice cream” linked to a box around the ice cream.",4 Finding and Clustering Audio-Visual Caption Groundings,[0],[0]
We use a constrained brute force ranking scheme to evaluate all possible groundings (with a restricted granularity) between an image and its caption.,4 Finding and Clustering Audio-Visual Caption Groundings,[0],[0]
"Specifically, we divide the image into a grid, and extract all of the image crops whose boundaries sit on the grid lines.",4 Finding and Clustering Audio-Visual Caption Groundings,[0],[0]
"Because we are mainly interested in extracting regions of interest and not high precision object detection boxes, to keep the number of proposal regions under control we impose several restrictions.",4 Finding and Clustering Audio-Visual Caption Groundings,[0],[0]
"First, we use a 10x10 grid on each image regardless of its original size.",4 Finding and Clustering Audio-Visual Caption Groundings,[0],[0]
"Second, we define minimum and maximum aspect ratios as 2:3 and 3:2 so as not to introduce too much distortion and also to reduce the number of proposal boxes.",4 Finding and Clustering Audio-Visual Caption Groundings,[0],[0]
"Third, we define a minimum bounding width as 30% of the original image width, and similarly a minimum height as 30% of the original image height.",4 Finding and Clustering Audio-Visual Caption Groundings,[0],[0]
"In practice, this results in a few thousand proposal regions per image.
",4 Finding and Clustering Audio-Visual Caption Groundings,[0],[0]
"To extract proposal segments from the audio
caption spectrogram, we similarly define a 1-dim grid along the time axis, and consider all possible start/end points at 10 frame (pixel) intervals.",4 Finding and Clustering Audio-Visual Caption Groundings,[0],[0]
"We impose minimum and maximum segment length constraints at 50 and 100 frames (pixels), implying that our discovered acoustic patterns are restricted to fall between 0.5 and 1 second in duration.",4 Finding and Clustering Audio-Visual Caption Groundings,[0],[0]
"The number of proposal segments will vary depending on the caption length, and typically number in the several thousands.",4 Finding and Clustering Audio-Visual Caption Groundings,[0],[0]
"Note that when learning groundings we consider the entire audio sequence, and do not incorporate the 10sec duration constraint imposed during training.
",4 Finding and Clustering Audio-Visual Caption Groundings,[0],[0]
"Once we have extracted a set of proposed visual bounding boxes and acoustic segments for a given image/caption pair, we use our multimodal network to compute a similarity score between each unique image crop/acoustic segment pair.",4 Finding and Clustering Audio-Visual Caption Groundings,[0],[0]
"Each triplet of an image crop, acoustic segment, and similarity score constitutes a proposed grounding.",4 Finding and Clustering Audio-Visual Caption Groundings,[0],[0]
"A naive approach would be to simply keep the top N groundings from this list, but in practice we ran into two problems with this strategy.",4 Finding and Clustering Audio-Visual Caption Groundings,[0],[0]
"First, many proposed acoustic segments capture mostly silence due to pauses present in natural speech.",4 Finding and Clustering Audio-Visual Caption Groundings,[0],[0]
"We solve this issue by using a simple voice activity detector (VAD) which was trained on the TIMIT corpus(Garofolo et al., 1993).",4 Finding and Clustering Audio-Visual Caption Groundings,[0],[0]
"If the VAD estimates that 40% or more of any proposed acoustic segment is silence, we discard that entire grounding.",4 Finding and Clustering Audio-Visual Caption Groundings,[0],[0]
The second problem we ran into is the fact that the top of the sorted grounding list is dominated by highly overlapping acoustic segments.,4 Finding and Clustering Audio-Visual Caption Groundings,[0],[0]
"This makes sense, because highly informative content words will show up in many different groundings with slightly perturbed start or end times.",4 Finding and Clustering Audio-Visual Caption Groundings,[0],[0]
"To alleviate this issue, when evaluating a grounding from the top of the proposal list we compare the interval intersection over union (IOU) of its acoustic segment against all acoustic segments already accepted for further consideration.",4 Finding and Clustering Audio-Visual Caption Groundings,[0],[0]
"If the IOU exceeds a threshold of 0.1, we discard the new grounding and continue moving down the list.",4 Finding and Clustering Audio-Visual Caption Groundings,[0],[0]
"We stop accumulating groundings once the scores fall to below 50% of the top score in the “keep” list, or when 10 groundings have been added to the “keep” list.",4 Finding and Clustering Audio-Visual Caption Groundings,[0],[0]
"Figure 1 displays a pictorial example of our grounding procedure.
",4 Finding and Clustering Audio-Visual Caption Groundings,[0],[0]
"Once we have completed the grounding procedure, we are left with a small set of regions of interest in each image and caption spectrogram.
",4 Finding and Clustering Audio-Visual Caption Groundings,[0],[0]
We use the respective branches of our multimodal network to compute embedding vectors for each grounding’s image crop and acoustic segment.,4 Finding and Clustering Audio-Visual Caption Groundings,[0],[0]
We then employ k-means clustering separately on the collection of image embedding vectors as well as the collection of acoustic embedding vectors.,4 Finding and Clustering Audio-Visual Caption Groundings,[0],[0]
"The last step is to establish an affinity score between each image cluster I and each acoustic cluster A; we do so using the equation
Affinity(I,A) = ∑
i∈I
∑ a∈A",4 Finding and Clustering Audio-Visual Caption Groundings,[0],[0]
"i>a · Pair(i,a) (2)
where i is an image crop embedding vector, a is an acoustic segment embedding vector, and Pair(i,a) is equal to 1",4 Finding and Clustering Audio-Visual Caption Groundings,[0],[0]
"when i and a belong to the same grounding pair, and 0 otherwise.",4 Finding and Clustering Audio-Visual Caption Groundings,[0],[0]
"After clustering, we are left with a set of acoustic pattern clusters, a set of visual pattern clusters, and a set of linkages describing which acoustic clusters are associated with which image clusters.",4 Finding and Clustering Audio-Visual Caption Groundings,[0],[0]
"In the next section, we investigate these clusters in more detail.",4 Finding and Clustering Audio-Visual Caption Groundings,[0],[0]
"We trained our multimodal network on a set of 214,585 image/caption pairs, and vetted it with an image search (given caption, find image) and annotation (given image, find caption) task similar to the one used in Harwath et al. (2016); Karpathy et al. (2014); Karpathy and Li (2015).",5 Experiments and Analysis,[0],[0]
"The image annotation and search recall scores on a 1,000 image/caption pair held-out test set are shown in Table 1.",5 Experiments and Analysis,[0],[0]
"Also shown in this table are the scores
achieved by a model which uses the ASR text transcriptions for each caption instead of the speech audio.",5 Experiments and Analysis,[0],[0]
"The text captions were truncated/padded to 20 words, and the audio branch of the network was replaced with a branch with the following architecture:
1.",5 Experiments and Analysis,[0],[0]
"Word embedding layer of dimension 200
2.",5 Experiments and Analysis,[0],[0]
"Temporal Convolution: C=512, W=3, ReLU 3.",5 Experiments and Analysis,[0],[0]
"Temporal Convolution: C=1024, W=3 4.",5 Experiments and Analysis,[0],[0]
Meanpool over entire caption 5.,5 Experiments and Analysis,[0],[0]
"L2 normalization
One would expect that access to ASR hypotheses should improve the recall scores, but the performance gap is not enormous.",5 Experiments and Analysis,[0],[0]
"Access to the ASR hypotheses provides a relative improvement of approximately 21.8% for image search R@10 and 12.5% for annotation R@10 compared to using no transcriptions or ASR whatsoever.
",5 Experiments and Analysis,[0],[0]
"We performed the grounding and pattern clustering steps on the entire training dataset, which resulted in a total of 1,161,305 unique grounding pairs.",5 Experiments and Analysis,[0],[0]
"For evaluation, we wish to assign a label to each cluster and cluster member, but this is not completely straightforward since each acoustic segment may capture part of a word, a whole word, multiple words, etc.",5 Experiments and Analysis,[0],[0]
"Our strategy is to forcealign the Google recognition hypothesis text to the audio, and then assign a label string to each acoustic segment based upon which words it overlaps in time.",5 Experiments and Analysis,[0],[0]
"The alignments are created with the help of a Kaldi (Povey et al., 2011) speech recognizer
Table 3:",5 Experiments and Analysis,[0],[0]
Top 50 clusters with k = 500 sorted by increasing variance.,5 Experiments and Analysis,[0],[0]
"Legend: |Cc| is acoustic cluster size, |Ci| is associated image cluster size, Pur. is acoustic cluster purity, σ2 is acoustic cluster variance, and Cov. is acoustic cluster coverage.",5 Experiments and Analysis,[0],[0]
"A dash (-) indicates a cluster whose majority label is silence.
",5 Experiments and Analysis,[0],[0]
"Trans |Cc| |Ci| Pur. σ2 Cov. Trans |Cc| |Ci| Pur. σ2 Cov. - 1059 3480 0.70 0.26 - snow 4331 3480 0.85 0.26 0.45
desert 1936 2896 0.82 0.27 0.67 kitchen 3200 2990 0.88 0.28 0.76 restaurant 1921 2536 0.89 0.29 0.71 mountain 4571 2768 0.86 0.30 0.38
black 4369 2387 0.64 0.30 0.17 skyscraper 843 3205 0.84 0.30 0.84 bridge 1654 2025 0.84 0.30 0.25 tree 5303 3758 0.90 0.30 0.16 castle 1298 2887 0.72 0.31 0.74 bridge 2779 2025 0.81 0.32 0.41
- 2349 2165 0.31 0.33 - ocean 2913 3505 0.87 0.33 0.71 table 3765 2165 0.94 0.33 0.23 windmill 1458 3752 0.71 0.33 0.76 window 1890 2795 0.85 0.34 0.21 river 2643 3204 0.76 0.35 0.62 water 5868 3204 0.90 0.35 0.27 beach 1897 2964 0.79 0.35 0.64 flower 3906 2587 0.92 0.35 0.67 wall 3158 3636 0.84 0.35 0.23
sky 4306 6055 0.76 0.36 0.34 street 2602 2385 0.86 0.36 0.49 golf course 1678 3864 0.44 0.36 0.63 field 3896 3261 0.74 0.36 0.37
tree 4098 3758 0.89 0.36 0.13 lighthouse 1254 1518 0.61 0.36 0.83 forest 1752 3431 0.80 0.37 0.56 church 2503 3140 0.86 0.37 0.72 people 3624 2275 0.91 0.37 0.14 baseball 2777 1929 0.66 0.37 0.86 field 2603 3922 0.74 0.37 0.25 car 3442 2118 0.79 0.38 0.27
people 4074 2286 0.92 0.38 0.17 shower 1271 2206 0.74 0.38 0.82 people walking 918 2224 0.63 0.38 0.25 wooden 3095 2723 0.63 0.38 0.28
mountain 3464 3239 0.88 0.38 0.29 tree 3676 2393 0.89 0.39 0.11 - 1976 3158 0.28 0.39 - snow 2521 3480 0.79 0.39 0.24
water 3102 2948 0.90 0.39 0.14 rock 2897 2967 0.76 0.39 0.26 - 2918 3459 0.08 0.39 - night 3027 3185 0.44 0.39 0.59
station 2063 2083 0.85 0.39 0.62 chair 2589 2288 0.89 0.39 0.22 building 6791 3450 0.89 0.40 0.21 city 2951 3190 0.67 0.40 0.50
Figure 2:",5 Experiments and Analysis,[0],[0]
"Scatter plot of audio cluster purity weighted by log cluster size vs variance for k = 500 (least-squares line superimposed).
based on the standard WSJ recipe and trained using the Google ASR hypothesis as a proxy for the transcriptions.",5 Experiments and Analysis,[0],[0]
Any word whose duration is overlapped 30% or more by the acoustic segment is included in the label string for the segment.,5 Experiments and Analysis,[0],[0]
We then employ a majority vote scheme to derive the overall cluster labels.,5 Experiments and Analysis,[0],[0]
"When computing the purity of a
cluster, we count a cluster member as matching the cluster label as long as the overall cluster label appears in the member’s label string.",5 Experiments and Analysis,[0],[0]
"In other words, an acoustic segment overlapping the words “the lighthouse” would receive credit for matching the overall cluster label “lighthouse”.",5 Experiments and Analysis,[0],[0]
A breakdown of the segments captured by two clusters is shown in Table 2.,5 Experiments and Analysis,[0],[0]
"We investigated some simple schemes for predicting highly pure clusters, and found that the empirical variance of the cluster members (average squared distance to the cluster centroid) was a good indicator.",5 Experiments and Analysis,[0],[0]
Figure 2 displays a scatter plot of cluster purity weighted by the natural log of the cluster size against the empirical variance.,5 Experiments and Analysis,[0],[0]
"Large, pure clusters are easily predicted by their low empirical variance, while a high variance is indicative of a garbage cluster.
",5 Experiments and Analysis,[0],[0]
"Ranking a set of k = 500 acoustic clusters by their variance, Table 3 displays some statistics for the 50 lowest-variance clusters.",5 Experiments and Analysis,[0],[0]
"We see that most of the clusters are very large and highly pure, and their labels reflect interesting object categories being identified by the neural network.",5 Experiments and Analysis,[0],[0]
"We additionally compute the coverage of each cluster by counting the total number of instances of the clus-
ter label anywhere in the training data, and then compute what fraction of those instances were captured by the cluster.",5 Experiments and Analysis,[0],[0]
"There are many examples of high coverage clusters, e.g. the “skyscraper” cluster captures 84% of all occurrences of the word “skyscraper”, while the “baseball” cluster captures 86% of all occurrences of the word “baseball”.",5 Experiments and Analysis,[0],[0]
"This is quite impressive given the fact that no conventional speech recognition was employed, and neither the multimodal neural network nor the grounding algorithm had access to the text transcripts of the captions.
",5 Experiments and Analysis,[0],[0]
"To get an idea of the impact of the k parameter as well as a variance-based cluster pruning threshold based on Figure 2, we swept k from 250 to 2000 and computed a set of statistics shown in Table 4.",5 Experiments and Analysis,[0],[0]
We compute the standard overall cluster purity evaluation metric in addition to the average coverage across clusters.,5 Experiments and Analysis,[0],[0]
"The table shows the natural tradeoff between cluster purity and redun-
dancy (indicated by the average cluster coverage) as k is increased.",5 Experiments and Analysis,[0],[0]
"In all cases, the variance-based cluster pruning greatly increases both the overall purity and average cluster coverage metrics.",5 Experiments and Analysis,[0],[0]
"We also notice that more unique cluster labels are discovered with a larger k.
Next, we examine the image clusters.",5 Experiments and Analysis,[0],[0]
"Figure 3 displays the 9 most central image crops for a set of 10 different image clusters, along with the majority-vote label of each image cluster’s associated audio cluster.",5 Experiments and Analysis,[0],[0]
"In all cases, we see that the image crops are highly relevant to their audio cluster label.",5 Experiments and Analysis,[0],[0]
"We include many more example image clusters in Appendix A.
In order to examine the semantic embedding space in more depth, we took the top 150 clusters from the same k = 500 clustering run described in Table 3 and performed t-SNE (van der Maaten and Hinton, 2008) analysis on the cluster centroid vectors.",5 Experiments and Analysis,[0],[0]
"We projected each centroid down to 2 di-
mensions and plotted their majority-vote labels in Figure 4.",5 Experiments and Analysis,[0],[0]
"Immediately we see that different clusters which capture the same label closely neighbor one another, indicating that distances in the embedding space do indeed carry information discriminative across word types (and suggesting that a more sophisticated clustering algorithm than kmeans would perform better).",5 Experiments and Analysis,[0],[0]
"More interestingly, we see that semantic information is also reflected in these distances.",5 Experiments and Analysis,[0],[0]
"The cluster centroids for “lake,” “river,” “body,” “water,” “waterfall,” “pond,” and “pool” all form a tight meta-cluster, as do “restaurant,” “store,” “shop,” and “shelves,” as well as “children,” “girl,” “woman,” and “man.”",5 Experiments and Analysis,[0],[0]
"Many other semantic meta-clusters can be seen in Figure 4, suggesting that the embedding space is capturing information that is highly discriminative both acoustically and semantically.
",5 Experiments and Analysis,[0],[0]
"Because our experiments revolve around the discovery of word and object categories, a key question to address is the extent to which the supervision used to train the VGG network constrains or influences the kinds of objects learned.",5 Experiments and Analysis,[0],[0]
"Because the 1,000 object classes from the ILSVRC2012 task (Russakovsky et al., 2015) used to train the VGG network were derived from WordNet synsets (Fellbaum, 1998), we can measure the semantic similarity between the words
learned by our network and the ILSVRC2012 class labels by using synset similarity measures within WordNet.",5 Experiments and Analysis,[0],[0]
"We do this by first building a list of the 1,000 WordNet synsets associated with the ILSVRC2012 classes.",5 Experiments and Analysis,[0],[0]
"We then take the set of unique majority-vote labels associated with the discovered word clusters for k = 500, filtered by setting a threshold on their variance (σ2 ≤ 0.65) so as to get rid of garbage clusters, leaving us with 197 unique acoustic cluster labels.",5 Experiments and Analysis,[0],[0]
"We then look up each cluster label in WordNet, and compare all noun senses of the label to every ILSVRC2012 class synset according to the path similarity measure.",5 Experiments and Analysis,[0],[0]
"This measure describes the distance between two synsets in a hyponym/hypernym hierarchy, where a score of 1 represents identity and lower scores indicate less similarity.",5 Experiments and Analysis,[0],[0]
We retain the highest score between any sense of the cluster label and any ILSVRC2012 synset.,5 Experiments and Analysis,[0],[0]
"Of the 197 unique cluster labels, only 16 had a distance of 1 from any ILSVRC12 class, which would indicate an exact match.",5 Experiments and Analysis,[0],[0]
"A path similarity of 0.5 indicates one degree of separation in the hyponym/hypernym hierarchy - for example, the similarity between “desk” and “table” is 0.5.",5 Experiments and Analysis,[0],[0]
"47 cluster labels were found to have a similarity of 0.5 to some ILSVRC12 class, leaving 134 cluster labels whose highest similarity to any ILSVRC12 class was less than 0.5.",5 Experiments and Analysis,[0],[0]
"In
other words, more than two thirds of the highly pure pattern clusters learned by our network were dissimilar to all of the 1,000 ILSVRC12 classes used to pretrain the VGG network, indicating that our model is able to generalize far beyond the set of classes found in the ILSVRC12 data.",5 Experiments and Analysis,[0],[0]
We display the labels of the 40 lowest variance acoustic clusters labels along with the name and similarity score of their closest ILSVRC12 synset in Table 5.,5 Experiments and Analysis,[0],[0]
"In this paper, we have demonstrated that a neural network trained to associate images with the waveforms representing their spoken audio captions can successfully be applied to discover and
cluster acoustic patterns representing words or short phrases in untranscribed audio data.",6 Conclusions and Future Work,[0],[0]
"An analogous procedure can be applied to visual images to discover visual patterns, and then the two modalities can be linked, allowing the network to learn, for example, that spoken instances of the word “train” are associated with image regions containing trains.",6 Conclusions and Future Work,[0],[0]
"This is done without the use of a conventional automatic speech recognition system and zero text transcriptions, and therefore is completely agnostic to the language in which the captions are spoken.",6 Conclusions and Future Work,[0],[0]
"Further, this is done in O(n) time with respect to the number of image/caption pairs, whereas previous stateof-the-art acoustic pattern discovery algorithms which leveraged acoustic data alone run in O(n2) time.",6 Conclusions and Future Work,[0],[0]
"We demonstrate the success of our methodology on a large-scale dataset of over 214,000 image/caption pairs comprising over 522 hours of spoken audio data, which is to our knowledge the largest scale acoustic pattern discovery experiment ever performed.",6 Conclusions and Future Work,[0],[0]
"We have shown that the shared multimodal embedding space learned by our model is discriminative not only across visual object categories, but also acoustically and semantically across spoken words.
",6 Conclusions and Future Work,[0],[0]
The future directions in which this research could be taken are incredibly fertile.,6 Conclusions and Future Work,[0],[0]
"Because our method creates a segmentation as well as an alignment between images and their spoken captions, a generative model could be trained using these alignments.",6 Conclusions and Future Work,[0],[0]
"The model could provide a spoken caption for an arbitrary image, or even synthesize an image given a spoken description.",6 Conclusions and Future Work,[0],[0]
"Modeling improvements are also possible, aimed at the goal of incorporating both visual and acoustic localization into the neural network itself.",6 Conclusions and Future Work,[0],[0]
"The same framework we use here could be extended to video, enabling the learning of actions, verbs, environmental sounds, and the like.",6 Conclusions and Future Work,[0],[0]
"Additionally, by collecting a second dataset of captions for our images in a different language, such as Spanish, our model could be extended to learn the acoustic correspondences for a given object category in both languages.",6 Conclusions and Future Work,[0],[0]
"This paves the way for creating a speech-to-speech translation model not only with absolutely zero need for any sort of text transcriptions, but also with zero need for directly parallel linguistic data or manual human translations.",6 Conclusions and Future Work,[0],[0]
"beach cliff pool desert field
chair table staircase statue stone
church forest mountain skyscraper trees
waterfall windmills window city bridge
flowers man wall archway baseball
boat shelves cockpit girl children
building rock kitchen plant hallway",A Additional Cluster Visualizations,[0],[0]
"Given a collection of images and spoken audio captions, we present a method for discovering word-like acoustic units in the continuous speech signal and grounding them to semantically relevant image regions.",abstractText,[0],[0]
"For example, our model is able to detect spoken instances of the words “lighthouse” within an utterance and associate them with image regions containing lighthouses.",abstractText,[0],[0]
"We do not use any form of conventional automatic speech recognition, nor do we use any text transcriptions or conventional linguistic annotations.",abstractText,[0],[0]
"Our model effectively implements a form of spoken language acquisition, in which the computer learns not only to recognize word categories by sound, but also to enrich the words it learns with semantics by grounding them in images.",abstractText,[0],[0]
Learning word-like units from joint audio-visual analysis,title,[0],[0]
"Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1817–1827, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.",text,[0],[0]
Unsupervised word alignment (WA) on bilingual sentence pairs serves as an essential foundation for building most statistical machine translation (SMT) systems.,1 Introduction,[0],[0]
A lot of methods have been proposed to raise the accuracy of WA in an effort to improve end-to-end translation quality.,1 Introduction,[0],[0]
"This paper contributes to this effort through refining the widely used expectation-maximization (EM) algorithm for WA (Dempster et al., 1977; Brown et al., 1993b; Och and Ney, 2000).
∗",1 Introduction,[0],[0]
"The author now is affiliated with Google, Japan.
",1 Introduction,[0],[0]
The EM algorithm for WA has a great influence in SMT.,1 Introduction,[0],[0]
"Many well-known toolkits including GIZA++ (Och and Ney, 2003), the Berkeley Aligner (Liang et al., 2006; DeNero and Klein, 2007), Fast Align (Dyer et al., 2013) and SyMGIZA++ (Junczys-Dowmunt and Sza, 2012), all employ this algorithm.",1 Introduction,[0],[0]
GIZA++,1 Introduction,[0],[0]
"in particular is frequently used in systems participating in many shared tasks (Goto et al., 2011; Cettolo et al., 2013; Bojar et al., 2013).
",1 Introduction,[0],[0]
"However, the EM algorithm for WA is wellknown for introducing “garbage collector effects.”",1 Introduction,[0],[0]
"Rare words have a tendency to collect garbage, that is they have a tendency to be erroneously aligned to untranslated words (Brown et al., 1993a; Moore, 2004; Ganchev et al., 2008; V Graça et al., 2010).",1 Introduction,[0.9517649665748726],"['Each token t produced from BPE is mapped to a d dimensional word embedding w. Character level features have been shown to improve NER accuracy (Lafferty et al., 2001; Lample et al., 2016; Passos et al., 2014).']"
"Figure 1(a) shows a real sentence pair, denoted s, from the GALE ChineseEnglish Word Alignment and Tagging Training corpus (GALE WA corpus)1 with it’s humanannotated word alignment.",1 Introduction,[0],[0]
"The Chinese word “HE ZHANG,” denoted wr, which means river custodian, only occurs once in the whole corpus.",1 Introduction,[0],[0]
"We performed EM training using GIZA++ on this corpus concatenated with 442,967 training sentence pairs from the NIST Open Machine Translation (OpenMT) 2006 evaluation2.",1 Introduction,[0],[0]
The resulting alignment is shown in Figure 1(b).,1 Introduction,[0],[0]
"It can be seen that wr is erroneously aligned to multiple English words.
",1 Introduction,[0],[0]
"To find the cause of this, we checked the alignments in each iteration i of s, denoted ais.",1 Introduction,[0],[0]
"We found that in a1s , wr together with the other source-side words were aligned with uniform probability to all the target-side words since the alignment models provided no prior information.",1 Introduction,[0],[0]
"However, in a2s , wr became erroneously aligned,
1Released by Linguistic Data Consortium, catalog number LDC2012T16, LDC2012T20, LDC2012T24 and LDC2013T05.
2http://www.itl.nist.gov/iad/mig/ tests/mt/2006/
1817
because the alignment distribution3 of wr was only learned from a1s , thus consisted of non-zero values only for generating the target-side words in s. Therefore, the alignment probabilities from the rare word wr to the unaligned words in s were extraordinarily high, since almost all of the probability mass was distributed among them.",1 Introduction,[0],[0]
"In other words, the story behind these garbage collector effects is that erroneous alignments are able to provide support for themselves; the probability distribution learned only from s is re-applied to s. In this way, these “garbage collector effects” are a form of over-fitting.
",1 Introduction,[0],[0]
"Motivated by this observation, we propose a leave-one-out EM algorithm for WA in this paper.",1 Introduction,[0],[0]
"Recently this technique has been applied to avoid over-fitting in kernel density estimation (Roux and Bach, 2011); instead of performing maximum likelihood estimation, maximum leaveone-out likelihood estimation is performed.",1 Introduction,[0],[0]
Figure 1(c) shows the effect of using our technique on the example.,1 Introduction,[0],[0]
"The garbage collection has not occurred, and the alignment of the word “HE ZHANG” is identical to the human annotation.",1 Introduction,[0],[0]
"The most related work to this paper is training phrase translation models with leave-one-out forced alignment (Wuebker et al., 2010; Wuebker et al., 2012).",2 Related Work,[0],[0]
"The differences are that their work operates at the phrase level, and their aim is to improve translation models; while our work operates at the word level, and our aim is to provide better word alignment.",2 Related Work,[0],[0]
"As word alignment is a foundation of most MT systems, our method have a wider application.
",2 Related Work,[0],[0]
"Recently, better estimation methods during the maximization step of EM have been proposed to avoid the over-fitting in WA, such as using Kneser-Ney Smoothing to back-off the expected counts (Zhang and Chiang, 2014) or integrating the smoothed l0 prior to the estimation of probability (Vaswani et al., 2012).",2 Related Work,[0],[0]
"Our work differs from theirs by addressing the over-fitting directly in the EM algorithm by adopting a leave-one-out approach.
",2 Related Work,[0],[0]
"Bayesian methods (Gilks et al., 1996; Andrieu et al., 2003; DeNero et al., 2008; Neubig et al.,
3The probability distribution of generating target language words from wr .",2 Related Work,[0],[0]
"The description here is only based on IBM model1 for simplicity, and the other alignment models are similar.
",2 Related Work,[0],[0]
"(a)
2011), also attempt to address the issue of overfitting, however EM algorithms related to the proposed method have been shown to be more efficient (Wang et al., 2014).",2 Related Work,[0],[0]
"This section first formulates the standard EM for WA, then presents the leave-one-out EM for WA, and finally briefly discusses handling singletons and effecient implementation.",3 Methodology,[0],[0]
The main notation used in this section is shown in Table 1.,3 Methodology,[0],[0]
"To perform WA through EM, the parallel corpus is taken as observed data, the alignments are taken as latent data.","3.1 Standard EM for IBM Models 1, 2 and HMM Model",[0],[0]
"In order to maximize the likelihood of the alignment model θ given the data S, the following two steps are conducted iteratively (Brown et al., 1993b; Och and Ney, 2000; Och and Ney, 2003),
Expectation Step (E step): calculating the conditional probability of alignments for each sentence pair, P (a|s, θ) = ∏Jj=1 θali(aj |aj−1, I)θlex(fj |eaj ),(1) where θali(i|i′, I) is the alignment probability and θlex(f |e) is the translation probability.","3.1 Standard EM for IBM Models 1, 2 and HMM Model",[0],[0]
"Note that
(1) is a general form for IBM model 1, model 2 and the HMM model.
","3.1 Standard EM for IBM Models 1, 2 and HMM Model",[0],[0]
"Maximization step (M step): re-estimating the probability models,
θali(i|i′, I)","3.1 Standard EM for IBM Models 1, 2 and HMM Model",[0],[0]
"← ∑
s Ni|i′,I(s)∑ s Ni′,I(s)
(2) θlex(f |e)","3.1 Standard EM for IBM Models 1, 2 and HMM Model",[0],[0]
"← ∑
s Nf |e(s)∑ s ne(s)
(3)
where Ni′,I(s) is the marginal number of times ei′ is aligned to some foreign word if the length of e is I , or 0 otherwise; Ni|i′,I(s) is the marginal number of times the next alignment position after i′ is i in a if the length of e is I , or 0 otherwise; ne(s) is the count of e in e; Nf |e(s,a) is the marginal number of times e is aligned to f .","3.1 Standard EM for IBM Models 1, 2 and HMM Model",[0],[0]
Leave-one-out EM for WA differs from standard EM in the way the alignment and translation probabilities are calculated.,"3.2 Leave-one-out EM for IBM Models 1, 2 and HMM Model",[0],[0]
"Each sentence pair will
have its own alignment and translation probability models calculated by excluding the sentence pair itself.","3.2 Leave-one-out EM for IBM Models 1, 2 and HMM Model",[0],[0]
"More formally, leave-one-out EM for WA are formulated as follows,
Leave-one-out E step: employing leave-oneout models for each s to calculate the conditional probability of alignments
P (a|s, θs̄) = ∏J j=1 θ s̄ ali(aj |aj−1, I)θs̄lex(fj |eaj ),(4)
where θs̄ali(i|i′, I) and θs̄lex(fj |eaj ) are the leaveone-out alignment probability and translation probability, respectively.
","3.2 Leave-one-out EM for IBM Models 1, 2 and HMM Model",[0],[0]
"Leave-one-out M step: re-estimating leaveone-out probability models,
θs̄ali(i|i′, I)","3.2 Leave-one-out EM for IBM Models 1, 2 and HMM Model",[0],[0]
"← ∑ s′ 6=s Ni|i′,I(s ′)∑
s′ 6=s Ni′,I(s′) (5) θs̄lex(f |e)","3.2 Leave-one-out EM for IBM Models 1, 2 and HMM Model",[0],[0]
"← ∑ s′ 6=s Nf |e(s ′)∑
s′ 6=s ne(s′) .","3.2 Leave-one-out EM for IBM Models 1, 2 and HMM Model",[0],[0]
(6),"3.2 Leave-one-out EM for IBM Models 1, 2 and HMM Model",[0],[0]
"The framework of the standard EM for IBM Model 4 is similar with the one for IBM Models 1, 2 and HMM Model, but the calculation of alignment probability is more complicated.
",3.3 Standard EM for IBM Model 4,[0],[0]
"E step: calculating the conditional probability through the reverted alignment (Och and Ney, 2003),
P (a|s, θ) = P (B0|B1, . .",3.3 Standard EM for IBM Model 4,[0],[0]
.,3.3 Standard EM for IBM Model 4,[0],[0]
", BI)·",3.3 Standard EM for IBM Model 4,[0],[0]
"I∏
i=1
P (Bi|Bi−1, ei) · I∏
i=1",3.3 Standard EM for IBM Model 4,[0],[0]
∏,3.3 Standard EM for IBM Model 4,[0],[0]
"j∈Bi θlex(fj |ei), (7)
where B0 means the set of foreign words aligned with the empty word; P (B0|B1, . .",3.3 Standard EM for IBM Model 4,[0],[0]
.,3.3 Standard EM for IBM Model 4,[0],[0]
", BI) is assumed to be a binomial distribution for the size of B0 (Brown et al., 1993b) or an modified distribution to relieve deficiency (Och and Ney, 2003).
",3.3 Standard EM for IBM Model 4,[0],[0]
"The distribution P (Bi|Bi−1, ei) is decomposed as
P (Bi|Bi−1, ei) = θfer(φi|ei)· θhea(Bi,1 −Bρi |Eρi) · φi∏
k=2
θoth(Bi,k −Bi,k−1),
(8)
where θfer is a fertility model; θhea is a probability model for the head (first) aligned foreign word; θoth is a probability model for the other aligned foreign words.",3.3 Standard EM for IBM Model 4,[0],[0]
"θhea is assumed to be conditioned
on the word class Eρi , following the paper of (Och and Ney, 2003) and the implementation of GIZA++ and CICADA.
",3.3 Standard EM for IBM Model 4,[0],[0]
"M step: re-estimating the probability models, θfer(φ|e) ← ∑
s Nφ|e(s)∑ s ∑ φ′ Nφ′|e(s)
(9)
θhea(∆i|E)",3.3 Standard EM for IBM Model 4,[0],[0]
"← ∑ s N hea ∆i|E(s)∑
s ∑ ∆i′ N hea ∆i′|E(s)
(10)
θoth(∆i) ← ∑ s N oth ∆i (s)∑
s ∑ ∆i′ N oth ∆i′(s) , (11)
where ∆i is a difference of the indexes of two foreign words.",3.3 Standard EM for IBM Model 4,[0],[0]
"The leave-one-out treatment were applied to the three component probability models θfer, θhea and θoth of IBM model 4.
",3.4 Leave-one-out EM for IBM Model 4,[0],[0]
"Leave-one-out E step: calculating the conditional probability through leave-one-out probability models
P (a|s, θs̄) = P (B0|B1, . .",3.4 Leave-one-out EM for IBM Model 4,[0],[0]
.,3.4 Leave-one-out EM for IBM Model 4,[0],[0]
", BI)·",3.4 Leave-one-out EM for IBM Model 4,[0],[0]
"I∏
i=1
P s̄(Bi|Bi−1, ei) · I∏
i=1",3.4 Leave-one-out EM for IBM Model 4,[0],[0]
∏,3.4 Leave-one-out EM for IBM Model 4,[0],[0]
"j∈Bi θs̄lex(fj |ei), (12)
P s̄(Bi|Bi−1, ei) = θs̄fer(φi|ei)·
θs̄hea(Bi,1 −Bρi |Eρi) · φi∏
k=2
θs̄oth(Bi,k −Bi,k−1).
",3.4 Leave-one-out EM for IBM Model 4,[0],[0]
"(13)
Leave-one-out M step: re-estimating the leaveone-out probability models,
θs̄fer(φ|e) ← ∑ s′ 6=s Nφ|e(s ′)∑
s′ 6=s ∑ φ′ Nφ′|e(s′) (14)
θs̄hea(∆i|E)",3.4 Leave-one-out EM for IBM Model 4,[0],[0]
"← ∑ s′ 6=s N hea ∆i|E(s
′)∑ s′ 6=s ∑ ∆i′ N hea ∆i′|E(s ′) (15)
θs̄oth(∆i) ← ∑ s′ 6=s N oth ∆i (s
′)∑ s′ 6=s ∑ ∆i′ N oth ∆i′(s ′) .",3.4 Leave-one-out EM for IBM Model 4,[0],[0]
(16),3.4 Leave-one-out EM for IBM Model 4,[0],[0]
Singletons are the words that occur only once in corpora.,3.5 Handling Singletons,[0],[0]
Singletons cause problems when applying leave-one-out to lexicalized models such as the translation model θs̄lex and the fertility model θ s̄ fer.,3.5 Handling Singletons,[0],[0]
"When calculating (6) and (14) for singletons, the
denominators become zero, thus the probabilities are undefined.
",3.5 Handling Singletons,[0],[0]
"For singletons, there is no prior information to guide their alignment, so we back off to uniform distributions.",3.5 Handling Singletons,[0],[0]
"In that case, the alignments are primarily determined by the rest of the sentence.
",3.5 Handling Singletons,[0],[0]
"In addition, singletons can be in the target side of the translation model θs̄lex.",3.5 Handling Singletons,[0],[0]
"In that case, the probabilities become zero.",3.5 Handling Singletons,[0],[0]
"This is handled by setting a minimum probability value of 1.0× 10−12, which was decided by pilot experiments.",3.5 Handling Singletons,[0],[0]
"To alleviate memory requirements and increase speed, our implementation did not build or store the local alignment models explicitly for each sentence pair.",3.6 Implementation Details,[0],[0]
"The following formula was used to efficiently calculate (5), (6) and (14–16) to build temporary probability models,∑
s′ 6=s Nx(s′) =",3.6 Implementation Details,[0],[0]
"( ∑ s′ Nx(s′))−Nx(s), (17)
where x is a alignment event.",3.6 Implementation Details,[0],[0]
"Our implementation maintained global counts of all alignment events ∑ s′ Nx(s
′), and (considerably smaller) local counts Nx(s) from each sentence pair s.
Take the translation model θs̄lex for example.",3.6 Implementation Details,[0],[0]
For a sentence pair s = (f1 . . .,3.6 Implementation Details,[0],[0]
"fJ , e1 . . .",3.6 Implementation Details,[0],[0]
"eI), it is cauclulated as,
θs̄lex(fj |ei) =",3.6 Implementation Details,[0],[0]
"( ∑ s′ N(fj |ei)(s ′))−N(fj |ei)(s) ( ∑ s′ nei(s′))− nei(s) .
",3.6 Implementation Details,[0],[0]
"(18)
",3.6 Implementation Details,[0],[0]
"The global counts to be maintained are∑ s′ N(fj |ei)(s
′) and nei(s′), and the local counts are ∑ s N(fj |ei)(s) and nei(s).",3.6 Implementation Details,[0],[0]
"Therefore the memory cost is,
|E| · (|F|+ 1) + ∑ s Is(Js + 1), (19)
where |E| is the size of English vocabulary, |F| is the size of foreign language vocabulary, Is is the length of the English sentence of s, and Js is the length of the foreign sentence of s.
",3.6 Implementation Details,[0],[0]
"The calculation of the leave-one-out translation model is performed for each English word and foreign word in s. Therefore, the time cost is,∑
s
Is(Js + 1).",3.6 Implementation Details,[0],[0]
"(20)
In addition, because the local counts N(fj |ei)(s) and nei(s) are read in order, storing them in a external memory such as a hard disk will not slow down the running speed much.",3.6 Implementation Details,[0],[0]
"This will reduce the memory cost to
|E| · (|F|+ 1).",3.6 Implementation Details,[0],[0]
"(21) This cost is independent to the number of sentence pairs4.
",3.6 Implementation Details,[0],[0]
The speed of the proposed method can be boosted through parallelism.,3.6 Implementation Details,[0],[0]
These calculations on each sentence pair can be performed independently.,3.6 Implementation Details,[0],[0]
"We found empirically that when our implementation of the proposed method is run on a 16-core computer, it finishes the task earlier than GIZA++5.",3.6 Implementation Details,[0],[0]
The proposed WA method was tested on two language pairs: Chinese-English and JapaneseEnglish (Table 2).,4 Experiments,[0],[0]
"Performance was measured both directly using the agreement with reference to manual WA annotations, and indirectly using the BLEU score in end-to-end machine translation tasks.",4 Experiments,[0],[0]
GIZA++ and our own implementation of standard EM were used as baselines.,4 Experiments,[0],[0]
The Chinese-English experimental data consisted of the GALE WA corpus and the OpenMT corpus.,4.1 Experimental Settings,[0],[0]
"They are from the same domain, both contain newswire texts and web blogs.",4.1 Experimental Settings,[0],[0]
"The OpenMT evaluation 2005 was used as a development set for MERT tuning (Och, 2003), and the OpenMT evaluation 2006 was used as a test set.",4.1 Experimental Settings,[0],[0]
"The JapaneseEnglish experimental data was the Kyoto Free Translation Task (Neubig, 2011)6.",4.1 Experimental Settings,[0],[0]
"The corpus contains a set of 1,235 sentence pairs that are manually word aligned.
",4.1 Experimental Settings,[0],[0]
The corpora were processed using a standard procedure for machine translation.,4.1 Experimental Settings,[0],[0]
"The English texts were tokenized with the tokenization script released with Europarl corpus (Koehn, 2005) and converted to lowercase; the Chinese texts were segmented into words using the Stanford Word Segmenter (Xue et al., 2002)7; the Japanese texts
4We found the memory of our server is large enough, so we did not implement it
5We plan to make our code public available.",4.1 Experimental Settings,[0],[0]
"6http://www.phontron.com/kftt/ 7http://nlp.stanford.edu/software/
segmenter.shtml
were segmented into words using the Kyoto Text Analysis Toolkit (KyTea8).",4.1 Experimental Settings,[0],[0]
"Sentences longer than 100 words or those with foreign/English word length ratios between larger than 9 were filtered out.
",4.1 Experimental Settings,[0],[0]
"GIZA++ was run with the default Moses settings (Koehn et al., 2007).",4.1 Experimental Settings,[0],[0]
"The IBM model 1, HMM model, IBM model 3 and IBM model 4 were run with 5, 5, 3 and 3 iterations.",4.1 Experimental Settings,[0],[0]
"We implemented the proposed leave-one-out EM and standard EM in IBM model 1, HMM model and IBM model 4.",4.1 Experimental Settings,[0],[0]
"In the original work (Och and Ney, 2003) this combination of models achieved comparable performance to the default Moses settings.",4.1 Experimental Settings,[0],[0]
"They were run with 5, 5 and 6 iterations.
",4.1 Experimental Settings,[0],[0]
"The standard EM was re-implemented as a baseline to provide a solid basis for comparison, because GIZA++ contains many undocumented details.",4.1 Experimental Settings,[0],[0]
"Our implementation is based on the toolkit of CICADA (Watanabe and Sumita, 2011; Watanabe, 2012; Tamura et al., 2013)9.",4.1 Experimental Settings,[0],[0]
"We named the implemented aligner AGRIPPA, to support our inhouse decoders OCTAVIAN and AUGUSTUS.
",4.1 Experimental Settings,[0],[0]
"In all experiments, WA was performed independently in two directions: from foreign languages to English, and from English to foreign languages.",4.1 Experimental Settings,[0],[0]
"Then the grow-diag-final-and heuristic was used to combine the two alignments from both directions to yield the final alignments for evaluation (Och and Ney, 2000; Och and Ney, 2003).",4.1 Experimental Settings,[0],[0]
"Word alignment accuracy of the baseline and the proposed method is shown in Table 3 in terms of precision, recall and F1 (Och and Ney, 2003).",4.2 Word Alignment Accuracy,[0],[0]
The proposed method gave rise to higher quality alignments in all our experiments.,4.2 Word Alignment Accuracy,[0],[0]
"The improvement in F1, precision and recall based on IBM Model 4 is in the range 8.3% to 9.1% compared with the GIZA++ baseline, and in the range 5.0% to 17.2% compared with our own baseline.
",4.2 Word Alignment Accuracy,[0],[0]
"The most meaningful result comes from the comparison of the models trained using standard EM log-likelihood training, and the proposed EM leave-one-out log-likelihood training.",4.2 Word Alignment Accuracy,[0],[0]
These models are identical except for way in which the model likelihood is calculated.,4.2 Word Alignment Accuracy,[0],[0]
In all our experiments the proposed method gave rise to higher quality alignments.,4.2 Word Alignment Accuracy,[0],[0]
"The standard EM implementation achieved
8http://www.phontron.com/kytea/ 9http://www2.nict.go.jp/univ-com/multi trans/cicada/
alignment performance approximately comparable to GIZA++, whereas the proposed method exceeded the performance of both implementations.",4.2 Word Alignment Accuracy,[0],[0]
"BLEU scores achieved by the phrase-based and hierachical SMT systems10 which were trained from different alignment results, are shown in Table 4.",4.3 End-to-end Translation Quality,[0],[0]
Each experiment was conducted three times to mitigate the variance in the results due to MERT.,4.3 End-to-end Translation Quality,[0],[0]
The results show that the proposed alignment method achieved the highest BLEU score in all experiments.,4.3 End-to-end Translation Quality,[0],[0]
"The improvement over the baseline is in range 0.03 to 1.03 for phrase-based systems, and ranged from 0.43 to 1.30 for hierarchical systems.
",4.3 End-to-end Translation Quality,[0],[0]
Hierarchical systems benifit more from the proposed method than phrase-based systems.,4.3 End-to-end Translation Quality,[0],[0]
We think this is because that hierarchical systems are more sensitive to word alignment quality than phrase-based systems.,4.3 End-to-end Translation Quality,[0],[0]
"Phrase-based systems only
10from the Moses toolkit
take contiguous parallel phrase pairs as translation rules, while hierarchical systems also use patterns made by subtracting (inner) short parallel phrases from (outer) longer parallel phrases.",4.3 End-to-end Translation Quality,[0],[0]
Both the outer and inner phrases typically need to be noisefree in order to produce high quality rules.,4.3 End-to-end Translation Quality,[0],[0]
This puts a high demand on the alignment quality.,4.3 End-to-end Translation Quality,[0],[0]
"Training corpora of different sizes were employed to perform unsupervised WA experiments and MT experiments (see Tables 5 and 6).
",4.4 Effect of Training Corpus Size,[0],[0]
The training corpora were randomly sampled from the Chinese-English manual WA corpora and the parallel training corpus.,4.4 Effect of Training Corpus Size,[0],[0]
"The manual WA corpus has a priority for being sampled so that the gold WA annotation is available for MT experi-
ments.",4.4 Effect of Training Corpus Size,[0],[0]
The settings of the unsupervised WA experiments and the MT experiments are the same with the previous experiments.,4.4 Effect of Training Corpus Size,[0],[0]
"In the WA experiments, GIZA++, our implemented standard EM and the proposed leave-one-out EM are applied to training corpora with the same parameter settings as the previous.",4.4 Effect of Training Corpus Size,[0],[0]
"In the MT experiments, the WA results of different methods and the gold WA (if available) are employed to extract translation rules; the rest settings including language models, development and test corpus, and parameters are the same as the previous.
",4.4 Effect of Training Corpus Size,[0],[0]
"On word alignment accuracy, the proposed method achieved improvements of F1 from 0.041 to 0.090 under the different training corpora (Table 5.",4.4 Effect of Training Corpus Size,[0],[0]
"The maximum improvement compared with GIZA++ is 0.069 when the training corpus has 4,000 sentence pairs.",4.4 Effect of Training Corpus Size,[0],[0]
"The maximum improvement compared with our own implement is 0.090 when the training corpus has 64,000 sentence pairs.
",4.4 Effect of Training Corpus Size,[0],[0]
"Figure 2 shows that the extent of improvements slightly changes under different training corpora, but they are all quite stable and obvious.
",4.4 Effect of Training Corpus Size,[0],[0]
"On translation quality, the proposed method achieved improvements of BLEU under the different training corpora.",4.4 Effect of Training Corpus Size,[0],[0]
The improvements ranged from 0.19 to 1.72 for phrase-based MT and ranged from 0.25 to 3.02 (see Table 5).,4.4 Effect of Training Corpus Size,[0],[0]
"The improvements are larger under smaller training corpora (see Figure 3).
",4.4 Effect of Training Corpus Size,[0],[0]
"In addition, the BLEUs achieved by the proposed method is close to the ones achieved by gold WA annotations.",4.4 Effect of Training Corpus Size,[0],[0]
"The proposed method slightly outperforms the gold WA annotations when using the full manual WA corpus of 18,057 sentence pairs.
",4.4 Effect of Training Corpus Size,[0],[0]
"4.5 Comparison to l0-Normalization and Kneser-Ney Smoothing Methods
The proposed leave-one-word word alignment method was empirically compared to l0-normalized GIZA++",4.4 Effect of Training Corpus Size,[0],[0]
"(Vaswani et al., 2012)11 and Kneser-Ney smoothed GIZA++",4.4 Effect of Training Corpus Size,[0],[0]
"(Zhang and Chiang, 2014)12.",4.4 Effect of Training Corpus Size,[0],[0]
l0-normalization and KneserNey smoothing methods are established methods to overcome the sparse problem.,4.4 Effect of Training Corpus Size,[0],[0]
This enables the probability distributions on rare words to be estimated more effectively.,4.4 Effect of Training Corpus Size,[0],[0]
"In this way, these two GIZA++ variants are related to the proposed method.
",4.4 Effect of Training Corpus Size,[0],[0]
"l0-normalized GIZA++ and Kneser-Ney smoothed GIZA++ were run with the same settings as GIZA++, which came from the default settings of MOSES.",4.4 Effect of Training Corpus Size,[0],[0]
For the settings of l0-normalized GIZA++ that are not in common with GIZA++ were the default settings.,4.4 Effect of Training Corpus Size,[0],[0]
"As for Kneser-Ney smoothed GIZA++, the smooth switches of IBM models 1 – 4 and HMM model
11http://www.isi.edu/˜avaswani/ giza-pp-l0.html
12https://github.com/hznlp/giza-kn
were turned on.
",4.4 Effect of Training Corpus Size,[0],[0]
The experimental results are presented in Table 7.,4.4 Effect of Training Corpus Size,[0],[0]
The experiments were run on the ChineseEnglish language pair.,4.4 Effect of Training Corpus Size,[0],[0]
The word alignment quality was evaluated separately for all words and for various levels of rare words.,4.4 Effect of Training Corpus Size,[0],[0]
"The leave-one-out method outperformed related methods in terms of precision, recall and F1 when evaluated on all words.
",4.4 Effect of Training Corpus Size,[0],[0]
Rare words were categorized based on the number of occurences in the source-language text of the training data.,4.4 Effect of Training Corpus Size,[0],[0]
The evaluations were carried out on the subset of alignment links that had a rare word on the source side.,4.4 Effect of Training Corpus Size,[0],[0]
"Table 7 presents the results for thresholds 1, 2, 5 and 10.",4.4 Effect of Training Corpus Size,[0],[0]
"The proposed method achieved much higher precision on rare words than the other methods, but performed poorly on recall.",4.4 Effect of Training Corpus Size,[0],[0]
The Kneser-Ney Smoothed GIZA++ had higher recall.,4.4 Effect of Training Corpus Size,[0],[0]
"The explanation might be that the leave-one-out method punishes rare words more than the Kneser-Ney smoothing method, by totally removing the derived expected counts of current sentence pair from the alignment models.",4.4 Effect of Training Corpus Size,[0],[0]
This leads to rare words being passively aligned.,4.4 Effect of Training Corpus Size,[0],[0]
"In other words, the leave-one-out method would align rare words unless the confidence is high.",4.4 Effect of Training Corpus Size,[0],[0]
"Therefore, we plan to seek a method to integrate Kneser-Ney smoothing into the proposed leave-one-out method in the future work.
",4.4 Effect of Training Corpus Size,[0],[0]
The BLEU scores achieved by phrase-based SMT and hierarchical SMT for different alignment methods are presented in Table 7.,4.4 Effect of Training Corpus Size,[0],[0]
The proposed method outperforms the other methods.,4.4 Effect of Training Corpus Size,[0],[0]
The Kneser-Ney Smoothed GIZA++ performed the second best.,4.4 Effect of Training Corpus Size,[0],[0]
"We tried to further analyze the relation between word alignment and BLEU, but found the analysis was obscured by the many processing stages.",4.4 Effect of Training Corpus Size,[0],[0]
"These stages include paral-
lel phrase extraction (or translation rule extraction from hierarchical SMT), log-linear model, MERT tuning and practical decoding where a lot of pruning happened.",4.4 Effect of Training Corpus Size,[0],[0]
This paper proposes a leave-one-out EM algorithm for WA to overcome the over-fitting problem that occurs when using standard EM for WA.,5 Conclusion,[0],[0]
"The experimental results on Chinese-English and Japanese-English corpora show that both the WA accuracy and the end-to-end translation are improved.
",5 Conclusion,[0],[0]
"In addition, we have a interesting finding about the effect of manual WA annotations on training MT systems.",5 Conclusion,[0],[0]
"In a Chinese-English parallel training corpus of 18,057 sentence pairs, the manual WA annotation outperformed the unsupervised WA results produced by standard EM algorithms.",5 Conclusion,[0],[0]
"However, the unsupervised WA results produced by proposed leave-one-out EM algorithm outperformed the manual WA annotation.
",5 Conclusion,[0],[0]
Our future work will focus on increasing the gains in end-to-end translation quality through the proposed leave-one-out aligner.,5 Conclusion,[0],[0]
It is a interesting question why GIZA++ achieved competitive BLEU scores though its alignment accuracy measured by F1 was substantially lower.,5 Conclusion,[0],[0]
The answer to this question which may reveal essence of good word alignment for MT and eventually help to improve MT.,5 Conclusion,[0],[0]
"In addition, we plan to improve the proposed method by integrating Kneser-Ney smoothing.",5 Conclusion,[0],[0]
We appreciated the valuable comments from the reviewers.,Acknowledgments,[0],[0]
"Expectation-maximization algorithms, such as those implemented in GIZA++ pervade the field of unsupervised word alignment.",abstractText,[0],[0]
"However, these algorithms have a problem of over-fitting, leading to “garbage collector effects,” where rare words tend to be erroneously aligned to untranslated words.",abstractText,[0],[0]
This paper proposes a leave-one-out expectationmaximization algorithm for unsupervised word alignment to address this problem.,abstractText,[0],[0]
The proposed method excludes information derived from the alignment of a sentence pair from the alignment models used to align it.,abstractText,[0],[0]
This prevents erroneous alignments within a sentence pair from supporting themselves.,abstractText,[0],[0]
"Experimental results on Chinese-English and Japanese-English corpora show that the F1, precision and recall of alignment were consistently increased by 5.0% – 17.2%, and BLEU scores of end-to-end translation were raised by 0.03 – 1.30.",abstractText,[0],[0]
The proposed method also outperformed l0-normalized GIZA++ and Kneser-Ney smoothed GIZA++.,abstractText,[0],[0]
Leave-one-out Word Alignment without Garbage Collector Effects,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 1090–1100 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics
Multilingual topic models enable document analysis across languages through coherent multilingual summaries of the data. However, there is no standard and effective metric to evaluate the quality of multilingual topics. We introduce a new intrinsic evaluation of multilingual topic models that correlates well with human judgments of multilingual topic coherence as well as performance in downstream applications. Importantly, we also study evaluation for low-resource languages. Because standard metrics fail to accurately measure topic quality when robust external resources are unavailable, we propose an adaptation model that improves the accuracy and reliability of these metrics in low-resource settings.",text,[0],[0]
"Topic models provide a high-level view of the main themes of a document collection (Boyd-Graber et al., 2017).",1 Introduction,[0],[0]
"Document collections, however, are often not in a single language, driving the development of multilingual topic models.",1 Introduction,[0],[0]
"These models discover topics that are consistent across languages, providing useful tools for multilingual text analysis (Vulić et al., 2015), such as detecting cultural differences (Gutiérrez et al., 2016) and bilingual dictionary extraction (Liu et al., 2015).
",1 Introduction,[0],[0]
"Monolingual topic models can be evaluated through likelihood (Wallach et al., 2009b) or coherence (Newman et al., 2010), but topic model evaluation is not well understood in multilingual settings.",1 Introduction,[0],[0]
Our contributions are two-fold.,1 Introduction,[0],[0]
"We introduce an improved intrinsic evaluation metric for multilingual topic models, called Crosslingual Normalized Pointwise Mutual Information (CNPMI, Section 2).",1 Introduction,[0],[0]
We explore the behaviors of CNPMI at both the model and topic levels with six language pairs and varying model specifications.,1 Introduction,[0],[0]
"This metric
correlates well with human judgments and crosslingual classification results (Sections 5 and 6).
",1 Introduction,[0],[0]
"We also focus on evaluation in low-resource languages, which lack large parallel corpora, dictionaries, and other tools that are often used in learning and evaluating topic models.",1 Introduction,[0],[0]
"To adapt CNPMI to these settings, we create a coherence estimator (Section 3) that extrapolates statistics derived from antiquated, specialized texts like the Bible: often the only resource available for many languages.",1 Introduction,[0],[0]
A multilingual topic contains one topic for each language.,2 Evaluating Multilingual Coherence,[0],[0]
"For a multilingual topic to be meaningful to humans (Figure 1), the meanings should be consistent across the languages, in addition to coherent within each language (i.e., all words in a topic are related).
",2 Evaluating Multilingual Coherence,[0],[0]
This section describes our approach to evaluating the quality of multilingual topics.,2 Evaluating Multilingual Coherence,[0],[0]
"After defining the multilingual topic model, we describe topic model evaluation extending standard monolingual approaches to multilingual settings.",2 Evaluating Multilingual Coherence,[0],[0]
"Probabilistic topic models associate each document in a corpus with a distribution over latent topics, while each topic is associated with a distribution over words in the vocabulary.",2.1 Multilingual Topic Modeling,[0],[0]
"The most widely used topic model, latent Dirichlet allocation (Blei et al., 2003, LDA), can be extended to connect languages.",2.1 Multilingual Topic Modeling,[0],[0]
"These extensions require additional knowledge to link languages together.
",2.1 Multilingual Topic Modeling,[0],[0]
"One common encoding of multilingual knowledge is document links (indicators that documents are parallel or comparable), used in polylingual topic models (Mimno et al., 2009; Ni et al., 2009).",2.1 Multilingual Topic Modeling,[0],[0]
"In these models, each document d indexes a tuple of parallel/comparable language-specific documents,
1090
d(`), and the language-specific “views” of a document share the document-topic distribution θd.",2.1 Multilingual Topic Modeling,[0],[0]
"The generative story for the document-links model is:
1 for each topic k and each language ` do 2 Draw a distribution over words φ`k ∼ Dirichlet(β); 3 for each document tuple d = ( d(1), . . .",2.1 Multilingual Topic Modeling,[0],[0]
", d(L) )",2.1 Multilingual Topic Modeling,[0],[0]
"do 4 Draw a distribution over topics θd ∼ Dirichlet(α); 5 for each language ` = 1, . . .",2.1 Multilingual Topic Modeling,[0],[0]
",L do 6 for each token t ∈ d(`) do 7 Draw a topic zn ∼ θd; 8 Draw a word wn ∼ φ`z;
Alternatively, word translations (Jagarlamudi and Daumé III, 2010), concept links (Gutiérrez et al., 2016; Yang et al., 2017), and multi-level priors (Krstovski et al., 2016) can also provide multilingual knowledges.",2.1 Multilingual Topic Modeling,[0],[0]
"Since the polylingual topic model is the most common approach for building multilingual topic models (Vulić et al., 2013, 2015; Liu et al., 2015; Krstovski and Smith, 2016), our study will focus on this model.",2.1 Multilingual Topic Modeling,[0],[0]
"Most automatic topic model evaluation metrics use co-occurrence statistics of word pairs from a reference corpus to evaluate topic coherence, assuming that coherent topics contain words that often appear together (Newman et al., 2010).",2.2 Monolingual Evaluation,[0],[0]
"The most successful (Lau et al., 2014) is normalized pointwise mutual information (Bouma, 2009, NPMI).",2.2 Monolingual Evaluation,[0],[0]
"NPMI compares the joint probability of words appearing together Pr(wi,wj) to their probability assuming independence Pr(wi) Pr(wj), normalized by the joint probability:
NPMI(wi,wj) = log
Pr(wi,wj) Pr(wi) Pr(wj)
log Pr(wi,wj) .",2.2 Monolingual Evaluation,[0],[0]
"(1)
The word probabilities are calculated from a reference corpus, R, typically a large corpus such as Wikipedia that can provide meaningful cooccurrence patterns that are independent of the target dataset.
",2.2 Monolingual Evaluation,[0],[0]
"The quality of topic k is the average NPMI of all word pairs (wi,wj) in the topic:
NPMIk = −1",2.2 Monolingual Evaluation,[0],[0]
"( C 2 ) ∑ i∈W(k,C) ∑ j 6=i NPMI(wi,wj), (2)
where W(k,C) are the C most probable words in the topic-word distribution φk (the number of words is the topic’s cardinality).",2.2 Monolingual Evaluation,[0],[0]
Higher NPMIk means the topic’s top words are more coupled.,2.2 Monolingual Evaluation,[0],[0]
"While automatic evaluation has been well-studied for monolingual topic models, there are no robust evaluations for multilingual topic models.",2.3 Existing Multilingual Evaluations,[0],[0]
"We first consider two straightforward metrics that could be used for multilingual evaluation, both with limitations.",2.3 Existing Multilingual Evaluations,[0],[0]
"We then propose an extension of NPMI that addresses these limitations.
",2.3 Existing Multilingual Evaluations,[0],[0]
Internal Coherence.,2.3 Existing Multilingual Evaluations,[0],[0]
A simple adaptation of NPMI is to calculate the monolingual NPMI score for each language independently and take the average.,2.3 Existing Multilingual Evaluations,[0],[0]
We refer this as internal NPMI (INPMI) as it evaluates coherence within a language.,2.3 Existing Multilingual Evaluations,[0],[0]
"However, this metric does not consider whether the topic is coherent across languages—that is, whether a language-specific word distribution φ`1k is related to the corresponding distribution in another language, φ`2k.
Crosslingual Consistency.",2.3 Existing Multilingual Evaluations,[0],[0]
"Another straightforward measurement is Matching Translation Accuracy (Boyd-Graber and Blei, 2009, MTA), which counts the number of word translations in a topic between two languages using a bilingual dictionary.",2.3 Existing Multilingual Evaluations,[0],[0]
"This metric can measure whether a topic is well-aligned across languages literally, but cannot capture non-literal more holistic similarities across languages.",2.3 Existing Multilingual Evaluations,[0],[0]
"We extend NPMI to multilingual models, with a metric we call crosslingual normalized pointwise mutual information (CNPMI).",2.4 New Metric: Crosslingual NPMI,[0],[0]
"This metric will be the focus of our experiments.
",2.4 New Metric: Crosslingual NPMI,[0],[0]
"A multilingually coherent topic means that if wi,`1 in language `1 and wj,`2 in language `2 are in the same topic, they should appear in similar contexts in comparable or parallel corporaR(`1,`2).
",2.4 New Metric: Crosslingual NPMI,[0],[0]
"Our adaptation of NPMI is based on the same principles as the monolingual version, but focuses on the co-occurrences of bilingual word pairs.",2.4 New Metric: Crosslingual NPMI,[0],[0]
"Given a bilingual word pair (wi,`1 ,wj,`2) the co-occurrence of this word pair is the event where word wi,`1 appears in a document in language `1 and the word wj,`2 appears in a comparable or parallel document in language `2.
",2.4 New Metric: Crosslingual NPMI,[0],[0]
"The co-occurrence probability of each bilingual word pair is:
Pr (wi,`1 ,wj,`2) , ∣∣{d : wi,`1 ∈ d(`1),wj,`2 ∈ d(`2) }∣∣ ∣∣R(`1,`2) ∣∣ , (3)
where d = ( d(`1), d(`2) ) is a pair of parallel/comparable documents in the reference corpus R(`1,`2).",2.4 New Metric: Crosslingual NPMI,[0],[0]
"When one or both words in a bilingual pair do not appear in the reference corpus, the cooccurrence score is zero.
",2.4 New Metric: Crosslingual NPMI,[0],[0]
"Similar to monolingual settings, CNPMI for a bilingual topic k is the average of the NPMI scores of all C2 bilingual word pairs,
CNPMI(`1, `2, k) =
∑C",2.4 New Metric: Crosslingual NPMI,[0],[0]
"i,j NPMI (wi,`1 ,wj,`2)
C2 .",2.4 New Metric: Crosslingual NPMI,[0],[0]
"(4)
It is straightforward to generalize CNPMI from a language pair to multiple languages by averaging CNPMI(`i, `j , k) over all language pairs (`i, `j).",2.4 New Metric: Crosslingual NPMI,[0],[0]
CNPMI needs a reference corpus for co-occurrence statistics.,3 Adapting to Low-Resource Languages,[0],[0]
"Wikipedia, which has good coverage of topics and vocabularies is a common choice (Lau and Baldwin, 2016).",3 Adapting to Low-Resource Languages,[0],[0]
"Unfortunately, Wikipedia is often unavailable or not large enough for lowresource languages.",3 Adapting to Low-Resource Languages,[0],[0]
"It only covers 282 languages,1 and only 249 languages have more than 1,000 pages: many of pages are short or unlinked to
1 https://meta.wikimedia.org/wiki/List_of_Wikipedias
a high-resource language.",3 Adapting to Low-Resource Languages,[0],[0]
"Since CNPMI requires comparable documents, the usable reference corpus is defined by paired documents.
",3 Adapting to Low-Resource Languages,[0],[0]
"Another option for a parallel reference corpus is the Bible (Resnik et al., 1999), which is available in most world languages;2 however, it is small and archaic.",3 Adapting to Low-Resource Languages,[0],[0]
"It is good at evaluating topics such as family and religion, but not “modern” topics like biology and Internet.",3 Adapting to Low-Resource Languages,[0],[0]
"Without reference co-occurrence statistics relevant to these topics, CNPMI will fail to judge topic coherence—it must give the ambiguous answer of zero.",3 Adapting to Low-Resource Languages,[0],[0]
"Such a score could mean a totally incoherent topic where each word pair never appears together (Topics 6 in Figure 1), or an unjudgeable topic (Topic 5).
",3 Adapting to Low-Resource Languages,[0],[0]
Our goal is to obtain a reliable estimation of topic coherence for low-resource languages when the Bible is the only reference.,3 Adapting to Low-Resource Languages,[0],[0]
We propose a model that can correct the drawbacks of a Bible-derived CNPMI.,3 Adapting to Low-Resource Languages,[0],[0]
"While we assume bilingual topics paired with English, our approach can be applied to any high-resource/low-resource language pair.
",3 Adapting to Low-Resource Languages,[0],[0]
We take Wikipedia’s CNPMI from high-resource languages as accurate estimations.,3 Adapting to Low-Resource Languages,[0],[0]
"We then build a coherence estimator on topics from high-resource languages, with the Wikipedia CNPMI as the target output.",3 Adapting to Low-Resource Languages,[0],[0]
We use linear regression using the below features.,3 Adapting to Low-Resource Languages,[0],[0]
"Given a topic in low-resource language, the estimator produces an estimated coherence (Figure 2).",3 Adapting to Low-Resource Languages,[0],[0]
The key to the estimator is to find features that capture whether we should trust the Bible.,3.1 Estimator Features,[0],[0]
"For generality, we focus on features independent of the available resources other than the Bible.",3.1 Estimator Features,[0],[0]
"This section describes the features, which we split into four groups.
",3.1 Estimator Features,[0],[0]
Base Features (BASE),3.1 Estimator Features,[0],[0]
"Our base features include information we can collect from the Bible and the topic model: cardinality C, CNPMI and INPMI, MTA, and topic word coverage (TWC), which counts the percentage of topic words in a topic that appear in a reference corpus.
Crosslingual Gap (GAP) A low CNPMI score could indicate a topic pair where each language has a monolingually coherent topic but that are not about the same theme (Topic 6 in Figure 1).",3.1 Estimator Features,[0],[0]
"Thus, we add two features to capture this information
2The Bible is available in 2,530 languages.
using the Bible: mismatch coefficients (MC) and internal comparison coefficients (ICC):
MC(`1; `2, k) = CNPMI(`1, `2, k)
INPMI(`1, k) + α , (5)
",3.1 Estimator Features,[0],[0]
"ICC(`1, `2, k) = INPMI(`1, k) + α
INPMI(`2, k) + α , (6)
where α is a smoothing factor (α = 0.001 in our experiments).",3.1 Estimator Features,[0],[0]
"MC recognizes the gap between crosslingual and monolingual coherence, so a higher MC score indicates a gap between coherence within and across languages.",3.1 Estimator Features,[0],[0]
"Similarly, ICC compares monolingual coherence to tell if both languages are coherent: the closer to 1 the ICC is, the more comparable internal coherence both languages have.
",3.1 Estimator Features,[0],[0]
"Word Era (ERA) Because the Bible’s vocabulary is unable to evaluate modern topics, we must tell the model what the modern words are.",3.1 Estimator Features,[0],[0]
The word era features are the earliest usage year 3 for each word in a topic.,3.1 Estimator Features,[0],[0]
"We use both the mean and standard deviation as features.
",3.1 Estimator Features,[0],[0]
Meaning Drift (DRIFT).,3.1 Estimator Features,[0],[0]
The meaning of a word can expand and drift over time.,3.1 Estimator Features,[0],[0]
"For example, in the Bible, “web” appears in Isaiah 59:5:
They hatch cockatrice’ eggs, and weave the spider’s web.
3 https://oxforddictionaries.com/
The word “web” could be evaluated correctly in an animal topic.",3.1 Estimator Features,[0],[0]
"For modern topics, however, Bible fails to capture modern meanings of “web”, as in Topic 5 (Figure 1).
",3.1 Estimator Features,[0],[0]
"To address this meaning drift, we use a method similar to Hamilton et al. (2016).",3.1 Estimator Features,[0],[0]
"For each English word, we calculate the context vector from Bible and from Wikipedia with a window size of five and calculate the cosine similarity between them as word similarity.",3.1 Estimator Features,[0],[0]
Similar context vectors mean that the usage in the Bible is consistent with Wikipedia.,3.1 Estimator Features,[0],[0]
We calculate word similarities for all the English topic words in a topic and use the average and standard deviation as features.,3.1 Estimator Features,[0],[0]
"In Figure 3, Topic 1 is coherent while Topic 8 is not.",3.2 Example,[0],[0]
"From left to right, we incrementally add new feature sets, and show how the estimated topic coherence scores (dashed lines) approach the ideal CNPMI (dotted lines).",3.2 Example,[0],[0]
"When only using the BASE features, the estimator gives a higher prediction to Topic 8 than to Topic 1.",3.2 Example,[0],[0]
Their low MTA and TWC prevent accurate evaluations.,3.2 Example,[0],[0]
Adding GAP does not help much.,3.2 Example,[0],[0]
"However, ICC(EN, AM, k = 1) is much smaller, which might indicate a large gap of internal coherence between the two languages.
",3.2 Example,[0],[0]
Adding ERA makes the estimated scores flip between the two topics.,3.2 Example,[0],[0]
"Topic 1 has word era of 1823, much older than Topic 8’s word era of 1923, in-
dicating that Topic 8 includes modern words the Bible lacks (e.g., “computer”).",3.2 Example,[0],[0]
"Using all the features, the estimator gives more accurate topic coherence evaluations.",3.2 Example,[0],[0]
"We experiment on six languages (Table 1) from three corpora: Romanian (RO) and Swedish (SV) from EuroParl as representative of well-studied and rich-resource languages (Koehn, 2005); Amharic (AM) and Tagalog (TL) from collected news, as lowresource languages (Huang et al., 2002a,b); and Chinese (ZH) and Turkish (TR) from TED Talks 2013 (Tiedemann, 2012), adding language variety to our experiments.",4 Experiments: Bible to Wikipedia,[0],[0]
"Each language is paired with English as a bilingual corpus.
",4 Experiments: Bible to Wikipedia,[0],[0]
"Typical preprocessing methods (stemming, stop word removal, etc.) are often unavailable for lowresource languages.",4 Experiments: Bible to Wikipedia,[0],[0]
"For a meaningful comparison across languages, we do not apply any stemming or lemmatization strategies, including English, except removing digit numbers and symbols.",4 Experiments: Bible to Wikipedia,[0],[0]
"However, we remove words that appear in more than 30% of documents for each language.
",4 Experiments: Bible to Wikipedia,[0],[0]
"Each language pair is separately trained using the MALLET (McCallum, 2002) implementation of the polylingual topic model.",4 Experiments: Bible to Wikipedia,[0],[0]
"Each experiment runs five Gibbs sampling chains with 1,000 iterations per chain with twenty topics.",4 Experiments: Bible to Wikipedia,[0],[0]
"The hyperparameters are set to the default values (α = 0.1, β = 0.01), and are optimized every 50 iterations in MALLET using slice sampling (Wallach et al., 2009a).",4 Experiments: Bible to Wikipedia,[0],[0]
We use Wikipedia and the Bible as reference corpora for calculating co-occurrence statistics.,4.1 Evaluating Multilingual Topics,[0],[0]
"Different numbers of Wikipedia articles are available for each language pair (Table 1), while the Bible contains a complete set of 1,189 chapters for all of its translations (Christodoulopoulos and Steed-
Are these two groups of words talking about the same thing?
man, 2015).",4.1 Evaluating Multilingual Topics,[0],[0]
We use Wiktionary as the dictionary to calculate MTA.,4.1 Evaluating Multilingual Topics,[0],[0]
"In addition to experimenting on Wikipedia-based CNPMI, we also re-evaluate the topics’ Bible coherence using our estimator.",4.2 Training the Estimator,[0],[0]
"In the following experiments, we use an AdaBoost regressor with linear regression as the coherence estimator (Friedman, 2002; Collins et al., 2000).",4.2 Training the Estimator,[0],[0]
"The estimator takes a topic and low-quality CNPMI score as input and outputs (hopefully) an improved CNPMI score.
",4.2 Training the Estimator,[0],[0]
"To make our testing scenario more realistic, we treat one language as our estimator’s test language and train on multilingual topics from the other languages.",4.2 Training the Estimator,[0],[0]
"We use three-fold cross-validation over languages to select the best hyperparameters, including the learning rate and loss function in AdaBoost.",4.2 Training the Estimator,[0],[0]
"R2 (Drucker, 1997).",4.2 Training the Estimator,[0],[0]
We first study CNPMI at the topic level: does a particular topic make sense?,5 Topic-Level Evaluation,[0],[0]
"An effective evaluation should be consistent with human judgment of the topics (Chang et al., 2009).",5 Topic-Level Evaluation,[0],[0]
"In this section, we measure gold-standard human interpretability of multilingual topics to establish which automatic measures of topic interpretability work best.",5 Topic-Level Evaluation,[0],[0]
"Following monolingual coherence evaluations (Lau et al., 2014), we present topic pairs to bilingual CrowdFlower users.",5.1 Task Design,[0],[0]
Each task is a topic pair with the top ten topic words (C = 10) for each language.,5.1 Task Design,[0],[0]
"We ask if both languages’ top words in a multilingual topic are talking about the same concept (Figure 4), and make a judgment on a three-point scale—coherent (2 points), somewhat coherent (1 point), and incoherent (0 points).",5.1 Task Design,[0],[0]
"To ensure the users have adequate language competency, we insert several topics that are easily identifiable as incoherent as a qualification test.
",5.1 Task Design,[0],[0]
"We randomly select sixty topics from each language pair (360 topics total), and each topic is judged by five users.",5.1 Task Design,[0],[0]
We take the average of the judgment points and calculate Pearson correlations with the proposed evaluation metrics (Table 2).,5.1 Task Design,[0],[0]
NPMI-based scores are separately calculated from each reference corpus.,5.1 Task Design,[0],[0]
"CNPMI (the extended metric) has higher correlations with human judgments than INPMI (the naive adaptation of monolingual NPMI), while MTA (matching translation accuracy) correlations are comparable to CNPMI.
",5.2 Agreement with Human Judgments,[0],[0]
"Unsurprisingly, when using Wikipedia as the reference, the correlations are usually higher than when using the Bible.",5.2 Agreement with Human Judgments,[0],[0]
"The Bible’s archaic content limits its ability to estimate human judgments in modern corpora (Section 3).
",5.2 Agreement with Human Judgments,[0],[0]
"Next, we compare CNPMI to two baselines: INPMI and MTA.",5.2 Agreement with Human Judgments,[0],[0]
"As expected, CNPMI outperforms INPMI regardless of reference corpus overall, because INPMI only considers monolingual coherence.",5.2 Agreement with Human Judgments,[0],[0]
"MTA has higher correlations than CNPMI
scores from the Bible, because the Bible fails to give accurate estimates due to limited topic coverage.",5.2 Agreement with Human Judgments,[0],[0]
"MTA, on the other hand, only depends on dictionaries, which are more comprehensive than the Bible.",5.2 Agreement with Human Judgments,[0],[0]
"It is also possible that users are judging coherence based on translations across a topic pair, rather than the overall coherence, which would closely correlate with MTA.",5.2 Agreement with Human Judgments,[0],[0]
The Bible—by itself—produces CNPMI values that do not correlate well with human judgments (Table 2).,5.3 Re-Estimating Topic-Level Coherence,[0],[0]
"After training an estimator (Section 4.2), we calculate Pearson’s correlation between Wikipedia’s CNPMI and the estimated topic coherence score (Table 3).",5.3 Re-Estimating Topic-Level Coherence,[0],[0]
"A higher correlation with Wikipedia’s CNPMI means more accurate coherence.
",5.3 Re-Estimating Topic-Level Coherence,[0],[0]
"As a baseline, the correlation of Bible-based CNPMI without adaptation has negative and nearzero correlations with Wikipedia;4 it does not capture coherence.",5.3 Re-Estimating Topic-Level Coherence,[0],[0]
"After training the estimator, the correlations become stronger, indicating the estimated scores are closer to Wikipedia’s CNPMI.",5.3 Re-Estimating Topic-Level Coherence,[0],[0]
"We analyze MTA from two aspects—the inability to capture semantically-related non-translation topic words, and insensitivity to cardinality—to show why MTA is not an ideal measurement, even though it correlates well with human judgments.
",5.4 When MTA Falls Short,[0],[0]
Semantics We take two examples with EN-ZH (Topic 1) and EN-TL (Topic 2) in Figure 5.,5.4 When MTA Falls Short,[0],[0]
"Topic 1 has fewer translation pairs than Topic 2, which leads to a lower MTA score for Topic 1.",5.4 When MTA Falls Short,[0],[0]
"However, all words in Topic 1 talk about art, while it is hard to interpret Topic 2.",5.4 When MTA Falls Short,[0],[0]
"Wikipedia CNPMI scores reveals
4Normally one would not estimate CNPMI on rich-resource languages using low-resource languages.",5.4 When MTA Falls Short,[0],[0]
"For completeness, however, we also include these situations.
",5.4 When MTA Falls Short,[0],[0]
Topic 1 is more coherent.,5.4 When MTA Falls Short,[0],[0]
"Because our experiments are on datasets with little divergence between the themes discussed across languages, this is uncommon for us but could appear in noisier datasets.
",5.4 When MTA Falls Short,[0],[0]
"Cardinality Increasing cardinality diminishes a topic’s coherence (Lau and Baldwin, 2016).",5.4 When MTA Falls Short,[0],[0]
We vary the cardinality of topics from ten to fifty at intervals of ten (Figure 6).,5.4 When MTA Falls Short,[0],[0]
"As cardinality increases, more low-probability and irrelevant words appear the topic, which lowers CNPMI scores.",5.4 When MTA Falls Short,[0],[0]
"However, MTA stays stable or increases with increasing cardinality.",5.4 When MTA Falls Short,[0],[0]
"Thus, MTA fails to fulfill a critical property of topic model evaluation.
",5.4 When MTA Falls Short,[0],[0]
"Finally, MTA requires a comprehensive multilingual dictionary, which may be unavailable for lowresource languages.",5.4 When MTA Falls Short,[0],[0]
"Additionally, most languages often only have one dictionary, which makes it problematic to use the same resource (a language’s single multilingual dictionary) for training and evaluating models that use a dictionary to build multilingual topics (Hu et al., 2014).",5.4 When MTA Falls Short,[0],[0]
"Given these concerns, we continue the paper’s focus on CNPMI as a data-driven alternative to MTA.",5.4 When MTA Falls Short,[0],[0]
"However, for many applications MTA may suffice as a simple, adequate evaluation metric.",5.4 When MTA Falls Short,[0],[0]
"While the previous section looked at individual topics, we also care about how well CNPMI characterizes the quality of models through an average of a model’s constituent topics.",6 Model-Level Evaluation,[0],[0]
"Adding more knowledge to multilingual topic models improves topics (Hu et al., 2014), so an effective evaluation should reflect this improvement as knowlege is added to the model.",6.1 Training Knowledge,[0],[0]
"For polylingual topic models, this knowledge takes the form of the number of linked documents.
",6.1 Training Knowledge,[0],[0]
We start by experimenting with no multilingual knowledge: no document pairs share a topic distribution,6.1 Training Knowledge,[0],[0]
θd (but the documents are in the collection as unlinked documents).,6.1 Training Knowledge,[0],[0]
We then increase the number of document pairs that share θd from 20% of the corpus to 100%.,6.1 Training Knowledge,[0],[0]
"Fixing the topic cardinality at ten, CNPMI captures the improvements in models (Figure 7) through a higher coherence score.",6.1 Training Knowledge,[0],[0]
"Topic models are often used as a feature extraction technique for downstream machine learning
applications, and topic model evaluations should reflect whether these features are useful (Ramage et al., 2009).",6.2 Agreement with Machines,[0],[0]
"For each model, we apply a document classifier trained on the model parameters to test whether CNPMI is consistent with classification accuracy.
",6.2 Agreement with Machines,[0],[0]
"Specifically, we want our classifier to transfer information from training on one language to testing on another (Smet et al., 2011; Heyman et al., 2016).",6.2 Agreement with Machines,[0],[0]
"We train a classifier on one language’s documents, where each document’s feature vector is the document-topic distribution θd.",6.2 Agreement with Machines,[0],[0]
"We apply this to TED Talks, where each document is labeled with multiple categories.",6.2 Agreement with Machines,[0],[0]
"We choose the most frequent seven categories across the corpus as labels,5 and only have labeled documents in one side of a bilingual topic model.",6.2 Agreement with Machines,[0],[0]
"CNPMI has very strong correlations with classification results, though using the Bible as the reference corpus gives slightly lower correlation—with higher variance— than Wikipedia (Figure 8).",6.2 Agreement with Machines,[0],[0]
"In Section 5.3, we improve Bible-based CNPMI scores for individual topics.",6.3 Re-Estimating Model-Level Coherence,[0],[0]
"Here, we show the estimator also improves model-level coherence.",6.3 Re-Estimating Model-Level Coherence,[0],[0]
"We apply the estimator on the models created in Section 6.2 and calculate the correlation between estimated scores and Wikipedia’s CNPMI (Table 4).
",6.3 Re-Estimating Model-Level Coherence,[0],[0]
The coherence estimator substantially improves scores except for Turkish: the correlation is better before applying the estimator (0.911).,6.3 Re-Estimating Model-Level Coherence,[0],[0]
"We suspect a lack of overlap between topics between Turkish and languages other than Chinese is to blame (Figure 9); the features used by the estimator do not generalize well to other kinds of features; training on many languages pairs would hopefully solve this
5design, global issues, art, science, technology, business, and culture
issue.",6.3 Re-Estimating Model-Level Coherence,[0],[0]
"Turkish is also morphologically rich, and our preprocessing completely ignores morphology.",6.3 Re-Estimating Model-Level Coherence,[0],[0]
"One challenge with low-resource languages is that even if Wikipedia is available, it may have too few documents to accurately calculate coherence.",6.4 Reference Size,[0],[0]
"As a final analysis, we examine how the reliability of CNPMI degrades with a smaller reference corpus.
",6.4 Reference Size,[0],[0]
"We randomly sample 20% to 100% of document pairs from the reference corpora and evaluate the polylingual topic model with all document links (Figure 10), again fixing the cardinality as 10.
",6.4 Reference Size,[0],[0]
"CNPMI is stable across different amounts of ref-
erence documents, as long as the number of reference documents is sufficiently large.",6.4 Reference Size,[0],[0]
"If there are too few reference documents (for example, 20% of Amharic Wikipedia is only 316 documents), then CNPMI degrades.",6.4 Reference Size,[0],[0]
Topic Coherence Many coherence metrics based on co-occurrence statistics have been proposed besides NPMI.,7 Related Work,[0],[0]
"Similar metrics—such as asymmetrical word pair metrics (Mimno et al., 2011) and combinations of existing measurements (Lau et al., 2014; Röder et al., 2015)— correlate well with human judgments.",7 Related Work,[0],[0]
"NPMI has been the current gold standard for evaluation and improvements of monolingual topic models (Pecina, 2010; Newman et al., 2011).
",7 Related Work,[0],[0]
"External Tasks Another approach is to use a model for predictive tasks: the better the results are on external tasks, the better a topic model is assumed to be.",7 Related Work,[0],[0]
"A common task is held-out likelihood (Wallach et al., 2009b; Jagarlamudi and Daumé III, 2010; Fukumasu et al., 2012), but as Chang et al. (2009) show, this does not always reflect human interpretability.",7 Related Work,[0],[0]
"Other specific tasks have also been used, such as bilingual dictionary extraction (Liu et al., 2015; Ma and Nasukawa, 2017), cultural difference deteciton (Gutiérrez et al., 2016), and crosslingual document clustering (Vulić et al., 2015).
",7 Related Work,[0],[0]
"Representation Learning Topic models are one example of a broad class of techniques of learning representations of documents (Bengio et al., 2013).",7 Related Work,[0.9557531515569169],"['MedMentions (Murty et al., 2018) is a recently introduced large dataset of PubMed abstracts containing entity linked mentions of many different semantic types.']"
"Other approaches learn respresentations at the word (Klementiev et al., 2012; Vyas and Carpuat, 2016), paragraph (Mogadala and Rettinger, 2016), or corpus level (Søgaard et al., 2015).",7 Related Work,[0],[0]
"However, neural representation learning approaches are often data hungry and not adaptable to low-resource languages.",7 Related Work,[0],[0]
"The approaches here could help improve the evaluation of all multilingual representation learning algorithms (Schnabel et al., 2015).",7 Related Work,[0],[0]
"We have provided a comprehensive analysis of topic model evaluation in multilingual settings, including for low-resource languages.",8 Conclusion,[0],[0]
"While evaluation is an important area of topic model research, no previous work has studied evaluation of multilingual topic models.",8 Conclusion,[0],[0]
"Our work provided two primary contributions to this area, including a new intrinsic evaluation metric, CNPMI, as well as a model for adapting this metric to low-resource languages without large reference corpora.
",8 Conclusion,[0],[0]
"As the first study on evaluation for multilingual topic models, there is still room for improvement and further applications.",8 Conclusion,[0],[0]
"For example, human judgment is more difficult to measure than in monolingual settings, and it is still an open question on how to design a reliable and accurate survey for multilingual quality judgments.",8 Conclusion,[0],[0]
"As a measurement of multilingual coherence, we plan to extend CNPMI to high-dimensional representations, e.g., multilingual word embeddings, particularly in low-resource languages (Ruder et al., 2017).",8 Conclusion,[0],[0]
We thank the anonymous reviewers for their insightful and constructive comments.,Acknowledgement,[0],[0]
"Hao has been supported under subcontract to Raytheon BBN Technologies, by DARPA award HR0011-15-C-0113.",Acknowledgement,[0],[0]
Boyd-Graber and Paul were supported by NSF grant IIS-1564275.,Acknowledgement,[0],[0]
"Any opinions, findings, conclusions, or recommendations expressed here are those of the authors and do not necessarily reflect the view of the sponsors.",Acknowledgement,[0],[0]
Multilingual topic models enable document analysis across languages through coherent multilingual summaries of the data.,abstractText,[0],[0]
"However, there is no standard and effective metric to evaluate the quality of multilingual topics.",abstractText,[0],[0]
We introduce a new intrinsic evaluation of multilingual topic models that correlates well with human judgments of multilingual topic coherence as well as performance in downstream applications.,abstractText,[0],[0]
"Importantly, we also study evaluation for low-resource languages.",abstractText,[0],[0]
"Because standard metrics fail to accurately measure topic quality when robust external resources are unavailable, we propose an adaptation model that improves the accuracy and reliability of these metrics in low-resource settings.",abstractText,[0],[0]
Lessons from the Bible on Modern Topics: Low-Resource Multilingual Topic Model Evaluation,title,[0],[0]
"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 741–752 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics
https://doi.org/10.18653/v1/P17-1069",text,[0],[0]
The importance of understanding political discourse on social media platforms is becoming increasingly clear.,1 Introduction,[0],[0]
"In recent U.S. presidential elections, Twitter was widely used by all candidates to promote their agenda, interact with supporters, and attack their opponents.",1 Introduction,[0],[0]
Social interactions on such platforms allow politicians to quickly react to current events and gauge interest in and support for their actions.,1 Introduction,[0],[0]
These dynamic settings emphasize the importance of constructing automated tools for analyzing this content.,1 Introduction,[0],[0]
"However, these same dynamics make constructing such tools difficult, as the language used to discuss new events and political agendas continuously changes.",1 Introduction,[0],[0]
"Consequently, the rich social interactions on Twitter can be leveraged to help support such analysis by providing alternatives to direct supervision.
",1 Introduction,[0],[0]
"In this paper we focus on political framing, a very nuanced political discourse analysis task, on
a variety of issues frequently discussed on Twitter.",1 Introduction,[0],[0]
"Framing (Entman, 1993; Chong and Druckman, 2007) is employed by politicians to bias the discussion towards their stance by emphasizing specific aspects of the issue.",1 Introduction,[0],[0]
"For example, the debate around increasing the minimum wage can be framed as a quality of life issue or as an economic issue.",1 Introduction,[0],[0]
"While the first frame supports increasing minimum wage because it improves workers’ lives, the second frame, by conversely emphasizing the costs involved, opposes the increase.",1 Introduction,[0],[0]
"Using framing to analyze political discourse has gathered significant interest over the last few years (Tsur et al., 2015; Card et al., 2015; Baumer et al., 2015) as a way to automatically analyze political discourse in congressional speeches and political news articles.",1 Introduction,[0],[0]
"Different from previous works which focus on these longer texts or single issues, our dataset includes tweets authored by all members of the U.S. Congress from both parties, dealing with several policy issues (e.g., immigration, ACA, etc.).",1 Introduction,[0],[0]
"These tweets were annotated by adapting the annotation guidelines developed by Boydstun et al. (2014) for Twitter.
",1 Introduction,[0],[0]
Twitter issue framing is a challenging multilabel prediction task.,1 Introduction,[0],[0]
"Each tweet can be labeled as using one or more frames, out of 17 possibilities, while only providing 140 characters as input to the classifier.",1 Introduction,[0],[0]
The main contribution of this work is to evaluate whether the social and behavioral information available on Twitter is sufficient for constructing a reliable classifier for this task.,1 Introduction,[0],[0]
"We approach this framing prediction task using a weakly supervised collective classification approach which leverages the dependencies between tweet frame predictions based on the interactions between their authors.
",1 Introduction,[0],[0]
These dependencies are modeled by connecting Twitter users who have social connections or behavioral similarities.,1 Introduction,[0],[0]
"Social connections are di-
741
rected dependencies that represent the followers of each user as well as retweeting behavior (i.e., user A retweets user B’s content).",1 Introduction,[0],[0]
"Interestingly, such social connections capture the flow of influence within political parties; however, the number of connections that cross party lines is extremely low.",1 Introduction,[0],[0]
"Instead, we rely on capturing behavioral similarity between users to provide this information.",1 Introduction,[0],[0]
"For example, users whose Twitter activity peaks at similar times tend to discuss issues in similar ways, providing indicators of their frame usage for those issues.",1 Introduction,[0],[0]
"In addition to using social and behavioral information, our approach also incorporates each politician’s party affiliation and the frequent phrases (e.g., bigrams and trigrams) used by politicians on Twitter.
",1 Introduction,[0],[0]
"These lexical, social, and behavioral features are extracted from tweets via weakly supervised models and then declaratively compiled into a graphical model using Probabilistic Soft Logic (PSL), a recently introduced probabilistic modeling framework.1 As described in Section 4, PSL specifies high level rules over a relational representation of these features.",1 Introduction,[0],[0]
"These rules are then compiled into a graphical model called a hingeloss Markov random field (Bach et al., 2013), which is used to make the frame prediction.",1 Introduction,[0],[0]
"Instead of direct supervision we take a bootstrapping approach by providing a small seed set of keywords adapted from Boydstun et al. (2014), for each frame.
",1 Introduction,[0],[0]
"Our experiments show that modeling social and behavioral connections improves F1 prediction scores in both supervised and unsupervised settings, with double the increase in the latter.",1 Introduction,[0],[0]
We apply our unsupervised model to our entire dataset of tweets to analyze framing patterns over time by both party and individual politicians.,1 Introduction,[0],[0]
"Our analysis provides insight into the usage of framing for identification of aisle-crossing politicians, i.e., those politicians who vote against their party.",1 Introduction,[0],[0]
"Issue framing is related to the broader challenges of biased language analysis (Recasens et al., 2013; Choi et al., 2012; Greene and Resnik, 2009) and subjectivity (Wiebe et al., 2004).",2 Related Work,[0],[0]
"Several previous works have explored framing in public statements, congressional speeches, and news articles (Fulgoni et al., 2016; Tsur et al., 2015; Card
1http://psl.cs.umd.edu
et al., 2015; Baumer et al., 2015).",2 Related Work,[0],[0]
"Our approach builds upon the previous work on frame analysis of Boydstun et al. (2014), by adapting and applying their annotation guidelines for Twitter.
",2 Related Work,[0],[0]
In recent years there has been growing interest in analyzing political discourse.,2 Related Work,[0],[0]
"Most previous work focuses on opinion mining and stance prediction (Sridhar et al., 2015; Hasan and Ng, 2014; Abu-Jbara et al., 2013; Walker et al., 2012; Abbott et al., 2011; Somasundaran and Wiebe, 2010, 2009).",2 Related Work,[0],[0]
"Analyzing political tweets has also attracted considerable interest: a recent SemEval task looked into stance prediction,2 and more related to our work, Tan et al. (2014) have shown how wording choices can affect message propagation on Twitter.",2 Related Work,[0],[0]
"Two recent works look into predicting stance (at user and tweet levels respectively) on Twitter using PSL (Johnson and Goldwasser, 2016; Ebrahimi et al., 2016).",2 Related Work,[0],[0]
"Frame classification, however, has a finer granularity than stance classification and describes how someone expresses their view on an issue, not whether they support the issue.",2 Related Work,[0],[0]
"Other works focus on identifying and measuring political ideologies (Iyyer et al., 2014; Bamman and Smith, 2015; Sim et al., 2013), policies (Nguyen et al., 2015), and voting patterns (Gerrish and Blei, 2012).
",2 Related Work,[0],[0]
"Exploiting social interactions and group structure for prediction has also been explored (Sridhar et al., 2015; Abu-Jbara et al., 2013; West et al., 2014).",2 Related Work,[0],[0]
"Works focusing on inferring signed social networks (West et al., 2014), stance classification (Sridhar et al., 2015), social group modeling (Huang et al., 2012), and collective classification using PSL (Bach et al., 2015) are closest to our approach.",2 Related Work,[0],[0]
"Unsupervised and weakly supervised models of Twitter data for several various tasks have been suggested, including: profile (Li et al., 2014b) and life event extraction (Li et al., 2014a), conversation modeling (Ritter et al., 2010), and methods for dealing with the unique language used in microblogs (Eisenstein, 2013).
",2 Related Work,[0],[0]
"Predicting political affiliation and other characteristics of Twitter users has been explored (Volkova et al., 2015, 2014; Yano et al., 2013; Conover et al., 2011).",2 Related Work,[0],[0]
"Others have focused on sentiment analysis (Pla and Hurtado, 2014; Bakliwal et al., 2013), predicting ideology (Djemili et al., 2014), automatic polls
2http://alt.qcri.org/semeval2016/ task6/
based on Twitter sentiment and political forecasting using Twitter (Bermingham and Smeaton, 2011; O’Connor et al., 2010; Tumasjan et al., 2010), as well as distant supervision applications (Marchetti-Bowick and Chambers, 2012).
",2 Related Work,[0],[0]
"Several works from political and social science research have studied the role of Twitter and framing in shaping public opinion of certain events, e.g. the Vancouver riots (Burch et al., 2015) and the Egyptian protests (Harlow and Johnson, 2011; Meraz and Papacharissi, 2013).",2 Related Work,[0],[0]
"Others have covered framing and sentiment analysis of opponents (Groshek and Al-Rawi, 2013) and network agenda modeling (Vargo et al., 2014) in the 2012 U.S. presidential election.",2 Related Work,[0],[0]
Jang and Hart (2015) studied frames used by the general population specific to global warming.,2 Related Work,[0],[0]
"In contrast to these works, we predict the issue-independent general frames of tweets, by U.S. politicians, which discuss six different policy issues.",2 Related Work,[0],[0]
"Data Collection and Preprocessing: We collected 184,914 of the most recent tweets of members of the U.S. Congress (both the House of Representatives and Senate).",3 Data Collection and Annotation,[0],[0]
"Using an average of ten keywords per issue, we filtered out tweets not related to the following six issues of interest: (1) limiting or gaining access to abortion, (2) debates concerning the Affordable Care Act (i.e., ACA or Obamacare), (3) the issue of gun rights versus gun control, (4) effects of immigration policies, (5) acts of terrorism, and (6) issues concerning the LGBTQ community.",3 Data Collection and Annotation,[0],[0]
"Forty politicians (10 Republicans and 10 Democrats, from both the House and Senate), were chosen randomly for annotation.",3 Data Collection and Annotation,[0],[0]
"Table 1 presents the statistics of our congressional tweets dataset, which is available for the community.3 Appendix A contains more details of our dataset and preprocessing steps.
",3 Data Collection and Annotation,[0],[0]
Data Annotation: Two graduate students were trained in the use of the Policy Frames Codebook developed by Boydstun et al. (2014) for annotating each tweet with a frame.,3 Data Collection and Annotation,[0],[0]
The general aspects of each frame are shown in Table 2.,3 Data Collection and Annotation,[0],[0]
Frames are designed to generalize across issues and overlap of multiple frames is possible.,3 Data Collection and Annotation,[0],[0]
"Additionally, the Codebook is typically applied to newspaper ar-
3The dataset and PSL scripts are available at: http://purduenlp.cs.purdue.edu/projects/ twitterframing.
",3 Data Collection and Annotation,[0],[0]
ticles where discussion of policy can encompass other frames in the text.,3 Data Collection and Annotation,[0],[0]
"Consequently, annotators using the Codebook are advised to be careful when assigning Frame 13 to a text.
",3 Data Collection and Annotation,[0],[0]
"Based on this guidance and the difficulty of labeling tweets (as discussed in Card et al. (2015)), annotators were instructed to use the following procedure: (1) attempt to assign a primary frame to the tweet if possible, (2) if not possible, assign two frames to the tweet where the first frame is chosen as the more accurate of the two frames, (3) when assigning frames 12 through 17, double check that the tweet cannot be assigned to any other frames.",3 Data Collection and Annotation,[0],[0]
Annotators spent one month labeling the randomly chosen tweets.,3 Data Collection and Annotation,[0],[0]
"For all tweets with more than one frame, annotators met to come to a consensus on whether the tweet should have one frame or both.",3 Data Collection and Annotation,[0],[0]
"The labeled dataset has an inter-annotator agreement, calculated using Cohen’s Kappa statistic, of 73.4%.
",3 Data Collection and Annotation,[0],[0]
Extensions of the Codebook for Twitter Use: The first 14 frames outlined in Table 2 are directly applicable to the tweets of U.S. politicians.,3 Data Collection and Annotation,[0],[0]
"In our labeled set, Frame 15 (Other) was never used.",3 Data Collection and Annotation,[0],[0]
"Therefore, we drop its analysis from this paper.",3 Data Collection and Annotation,[0],[0]
"From our observations, we propose the addition of the 3 frames at the bottom of Table 2 for Twitter analysis: Factual, (Self) Promotion, and Personal Sympathy and Support.",3 Data Collection and Annotation,[0],[0]
"Tweets that present a fact, with no detectable political spin or twists, are labeled as having the Factual frame (15).",3 Data Collection and Annotation,[0],[0]
"Tweets that discuss a politician’s appearances, speeches, statements, or refer to political friends are considered to have the (Self) Promotion frame.",3 Data Collection and Annotation,[0],[0]
"Finally, tweets where a politician offers their “thoughts and prayers”, condolences, or stands in support of others, are considered to have the Personal frame.
",3 Data Collection and Annotation,[0],[0]
"We find that for many tweets, one frame is not enough.",3 Data Collection and Annotation,[0],[0]
"This is caused by the compound nature of many tweets, e.g., some tweets are two separate sentences, with each sentence having a different frame or tweets begin with one frame and end with another.",3 Data Collection and Annotation,[0],[0]
"A final problem, that may also be relevant to longer text articles, is that of subframes within a larger frame.",3 Data Collection and Annotation,[0],[0]
"For example, the tweet “We must bolster the security of our borders and craft an immigration policy that grows our economy.”",3 Data Collection and Annotation,[0],[0]
has two frames: Security & Defense and Economic.,3 Data Collection and Annotation,[0],[0]
"However, both frames could fall under Frame 13 (Policy), if this tweet as a whole was a rebuttal point about an immigration policy.",3 Data Collection and Annotation,[0],[0]
"The lack of
available context for short tweets can make it difficult to determine if a tweet should have one primary frame or is more accurately represented by multiple frames.",3 Data Collection and Annotation,[0],[0]
"Due to the dynamic nature of political discourse on Twitter, our approach is designed to require as little supervision as possible.",4 Global Models of Twitter Language and Activity,[0],[0]
We implement 6 weakly supervised models which are datadependent and used to extract and format information from tweets into input for PSL predicates.,4 Global Models of Twitter Language and Activity,[0],[0]
These predicates are then combined into the probabilistic rules of each model as shown in Table 3.,4 Global Models of Twitter Language and Activity,[0],[0]
"The only sources of supervision these models require includes: unigrams related to the issues, unigrams adapted from the Boydstun et al. (2014) Codebook for frames, and political party of the author of the tweets.",4 Global Models of Twitter Language and Activity,[0],[0]
"PSL is a declarative modeling language which can be used to specify weighted, first-order logic rules.",4.1 Global Modeling Using PSL,[0],[0]
"These rules are compiled into a hinge-loss Markov random field which defines a probability distribution over possible continuous value assignments to the random variables of the model (Bach et al.,
2015).4 This probability density function is represented as:
P (Y | X) = 1 Z exp
MX
r=1
r r(Y , X)
!
where Z is a normalization constant, is the weight vector, and
r(Y, X) =",4.1 Global Modeling Using PSL,[0],[0]
"(max{lr(Y, X), 0})⇢r
is the hinge-loss potential specified by a linear function lr.",4.1 Global Modeling Using PSL,[0],[0]
"The exponent ⇢r 2 1, 2 is optional.",4.1 Global Modeling Using PSL,[0],[0]
"Each potential represents the instantiation of a rule, which takes the following form:
1 : P1(x) ^",4.1 Global Modeling Using PSL,[0],[0]
"P2(x, y) !",4.1 Global Modeling Using PSL,[0],[0]
P3(y) 2 : P1(x) ^,4.1 Global Modeling Using PSL,[0],[0]
"P4(x, y) !",4.1 Global Modeling Using PSL,[0],[0]
"¬P3(y)
P1, P2, P3, and P4 are predicates (e.g., political party, issue, frame, and presence of n-grams) and x, y are variables.",4.1 Global Modeling Using PSL,[0],[0]
Each rule has a weight which reflects that rule’s importance and is learned using the Expectation-Maximization algorithm in our unsupervised experiments.,4.1 Global Modeling Using PSL,[0],[0]
"Using concrete constants a, b (e.g., tweets and words) which instantiate the variables x, y, model atoms are mapped
4Unlike other probabilistic logical models, e.g. MLNs, in which the model’s random variables are strictly true or false.
",4.1 Global Modeling Using PSL,[0],[0]
"to continuous [0,1] assignments.",4.1 Global Modeling Using PSL,[0],[0]
"More important rules (i.e., those with larger weights) are given preference by the model.",4.1 Global Modeling Using PSL,[0],[0]
"Unigrams: Using the guidelines provided in the Policy Frames Codebook (Boydstun et al., 2014), we adapted a list of expected unigrams for each frame.",4.2 Language Based Models,[0],[0]
"For example, unigrams that should be related to Frame 12 (Political Factors & Implications) include: filibuster, lobby, Democrats, Republicans.",4.2 Language Based Models,[0],[0]
"We expect that if a tweet and frame contain a matching unigram, then that frame is likely present in that tweet.",4.2 Language Based Models,[0],[0]
"The information that tweet T has expected unigram U of frame F is represented with the PSL predicate: UNIGRAMF (T, U).",4.2 Language Based Models,[0],[0]
"This knowledge is then used as input to PSL Model 1 via the rule: UNIGRAMF (T, U) !",4.2 Language Based Models,[0],[0]
"FRAME(T, F) (shown in line 1 of Table 3).
",4.2 Language Based Models,[0],[0]
"However, not every tweet will have a unigram that matches those in this list.",4.2 Language Based Models,[0],[0]
"Under the intuition that at least one unigram in a tweet should be similar to a unigram in the list, we designed the following MaxSim metric to compute the maximum similarity between a word in a tweet and a word from the list of unigrams.
MAXSIM(T, F) = arg max u2F,w2T SIMILARITY(W,U)
(1) T is a tweet, W is each word in T, and U is each unigram in the list of expected unigrams (per frame).",4.2 Language Based Models,[0],[0]
SIMILARITY is the computed word2vec similarity (using pretrained embeddings) of each word in the tweet with every unigram in the list of unigrams for each frame.,4.2 Language Based Models,[0],[0]
"The frame F of the maximum scoring unigram is input to the PSL predicate: MAXSIMF (T, F), which indicates that tweet T has the highest similarity to frame F.
Bigrams and Trigrams:",4.2 Language Based Models,[0],[0]
"In addition to unigrams, we also explored the effects of political party slogans on frame prediction.",4.2 Language Based Models,[0],[0]
Slogans are common catch phrases or sayings that people typically associate with different U.S. political parties.,4.2 Language Based Models,[0],[0]
"For example, Republicans are known for using the phrase “repeal and replace” when they discuss the ACA.",4.2 Language Based Models,[0],[0]
"Similarly, in the 2016 U.S. presidential election, Secretary Hillary Clinton’s campaign slogan became “Love Trumps Hate”.",4.2 Language Based Models,[0],[0]
"To visualize slogan usage by parties for different issues, we used the entire tweets dataset, including all unlabeled tweets, to extract the top bigrams
and trigrams per party for each issue.",4.2 Language Based Models,[0],[0]
The histograms in Figure 1 show these distributions for the top 100 bigrams and trigrams.,4.2 Language Based Models,[0],[0]
"Based on these results, we use the top 20 bigrams (e.g., women’s healthcare and immigration reform) and trigrams (e.g. prevent gun violence) as input to PSL predicates BIGRAMIP (T, B) and TRIGRAMIP (T, TG).",4.2 Language Based Models,[0],[0]
These rules represent that tweet T has bigram B or trigram TG from the respective issue I phrase lists of either party P.,4.2 Language Based Models,[0],[0]
"In addition to language based features of tweets, we also exploit the behavioral and social features of Twitter including similarities between temporal activity and network relationships.
",4.3 Twitter Behavior Based Models,[0],[0]
Temporal Similarity: We construct a temporal histogram for each politician which captures their Twitter activity over time.,4.3 Twitter Behavior Based Models,[0],[0]
When an event happens politicians are most likely to tweet about that event within hours of its occurrence.,4.3 Twitter Behavior Based Models,[0],[0]
"Similarly, most politicians tweet about the event most frequently the day of the event and this frequency decreases over time.",4.3 Twitter Behavior Based Models,[0],[0]
"From these temporal histograms, we observed that the frames used the day of an event were similar and gradually changed over time.",4.3 Twitter Behavior Based Models,[0],[0]
"For example, once the public is notified of a shooting, politicians respond with Frame 17 to offer sympathy to the victims and their families.",4.3 Twitter Behavior Based Models,[0],[0]
"Over the next days or weeks, both parties slowly transition to using additional frames, e.g. Democrats use Frame 7 to argue for gun control legislation.",4.3 Twitter Behavior Based Models,[0],[0]
"To capture this behavior we use the PSL predicate SAMETIME(T1, T2).",4.3 Twitter Behavior Based Models,[0],[0]
"This indicates that tweet T1 occurs around the same time as tweet
T2.5 This information is used in Model 4 via rules such as: SAMETIME(T1, T2) & FRAME(T1, F) !",4.3 Twitter Behavior Based Models,[0],[0]
"FRAME(T2, F), as shown in line 4 of Table 3.
",4.3 Twitter Behavior Based Models,[0],[0]
"Network Similarity: Finally, we expect that politicians who share ideologies, and thus are likely to frame issues similarly, will retweet and/or follow each other on Twitter.",4.3 Twitter Behavior Based Models,[0],[0]
"Due to the compound nature of tweets, retweeting with additional comments can add more frames to the original tweet.",4.3 Twitter Behavior Based Models,[0],[0]
"Additionally, politicians on Twitter are more likely to follow members of their own party or similar non-political entities than those of the opposing party.",4.3 Twitter Behavior Based Models,[0],[0]
"To capture this network-based behavior we use two PSL predicates: RETWEETS(T1, T2) and FOLLOWS(T1, T2).",4.3 Twitter Behavior Based Models,[0],[0]
"These predicates indicate that the content of tweet T1 includes a retweet of tweet T2 and that the author of T1 follows the author of T2 on Twitter, respectively.",4.3 Twitter Behavior Based Models,[0],[0]
The last two lines of Table 3 show examples of how network similarity is incorporated into PSL rules.,4.3 Twitter Behavior Based Models,[0],[0]
"Evaluation Metrics: Since each tweet can have more than one frame, our prediction task is a multilabel classification task.",5 Experiments,[0],[0]
"The precision of a multilabel model is the ratio of how many predicted labels are correct:
Precision = 1
T
TX
t=1
|Yt \ h(xt)|",5 Experiments,[0],[0]
"|h(xt)|
(2)
",5 Experiments,[0],[0]
"The recall of this model is the ratio of how many of the actual labels were predicted:
Recall = 1
T
TX
t=1
|Yt \ h(xt)|",5 Experiments,[0],[0]
"|Yt|
(3)
5We conducted experiments with different hour and day limits and found that using a time frame of one hour results in the best accuracy while limiting noise.
",5 Experiments,[0],[0]
"In both formulas, T is the number of tweets, Yt is the true label for tweet t, xt is a tweet example, and h(xt) are the predicted labels for that tweet.",5 Experiments,[0],[0]
The F1 score is computed as the harmonic mean of the precision and recall.,5 Experiments,[0],[0]
"Additionally, in Tables 4, 5, and 6 the reported average is the micro-weighted average F1 scores over all frames.
",5 Experiments,[0],[0]
Experimental Settings: We provide an analysis of our PSL models under both supervised and unsupervised settings.,5 Experiments,[0],[0]
"In the PSL supervised experiments, we used five-fold cross validation with randomly chosen splits.
",5 Experiments,[0],[0]
"Previous works typically use an SVM, with bagof-words features, which is not used in a multilabel prediction, i.e., each frame is predicted individually.",5 Experiments,[0],[0]
The results of this approach on our dataset are shown in column 2 of Table 4.,5 Experiments,[0],[0]
"In this scenario, the SVM tends to prefer the majority class, which results in many incorrect labels.",5 Experiments,[0],[0]
Column 3 shows the results of using an SVM with bag-of-words features to perform multilabel classification.,5 Experiments,[0],[0]
This approach decreases the F1 score for a majority of frames.,5 Experiments,[0],[0]
"Both SVMs also result in F1 scores of 0 for some frames, further lowering the overall performance.",5 Experiments,[0],[0]
"Finally, columns 4 and 5 show the results of using our worst and best PSL models, respectively.",5 Experiments,[0],[0]
"PSL Model 1, which uses our adapted unigram features instead of the bag-of-words features for multilabel classification, serves as our baseline to improve upon.",5 Experiments,[0],[0]
"Additionally, Model 6 of the supervised, collective network setting represents the best results we can achieve.
",5 Experiments,[0],[0]
We also explore the results of our PSL models in an unsupervised setting because the highly dynamic nature of political discourse on Twitter makes it unrealistic to expect annotated data to generalize to future discussions.,5 Experiments,[0],[0]
The only source of supervision comes from the initial unigrams lists and party information as described in Section 4.,5 Experiments,[0],[0]
The labeled tweets are used for evaluation only.,5 Experiments,[0],[0]
"As seen in Table 4, we are able to improve
the best unsupervised model to within an F1 score of 7.36 points of the unigram baseline of 66.02, and 19.13 points of the best supervised score of 77.79.
",5 Experiments,[0],[0]
Analysis of Supervised Experiments: Table 5 shows the results of our supervised experiments.,5 Experiments,[0],[0]
"Here we can see that by adding Twitter behavior (beginning with Model 4), our behaviorbased models achieve the best F1 scores across all frames.",5 Experiments,[0],[0]
"Model 4 achieves the highest results on two frames, suggesting retweeting and network follower information do not help improve the prediction score for these frames.",5 Experiments,[0],[0]
"Similarly, Model 5 achieves the highest prediction for 5 of the frames, suggesting network follower information cannot further improve the score for these frames.",5 Experiments,[0],[0]
"Overall, the Twitter behavior based models are able to outperform language based models alone, including the best performing language model (Model 3) which combines unigrams, bigrams, and trigrams together to collectively infer the correct frames.
",5 Experiments,[0],[0]
"Analysis of Unsupervised Experiments: In the unsupervised setting, Model 6, the combination of language and Twitter behavior features achieves the best results on 16 of the 17 issues, as shown in Table 6.",5 Experiments,[0],[0]
There are a few interesting aspects of the unsupervised setting which differ from the supervised setting.,5 Experiments,[0],[0]
"Six of the frame predictions do worse in Model 2, which is double that of the supervised version.",5 Experiments,[0],[0]
"This is likely due to the presence of overlapping bigrams across frames and issues, e.g., “women’s healthcare” could appear in both Frames 4 and 8 and the issues of ACA and abortion.",5 Experiments,[0],[0]
"However, all six are able to improve with the addition of trigrams (Model 3), whereas only 1 of 3 frames improves in the supervised setting.",5 Experiments,[0],[0]
This suggests that bigrams may not be as useful as trigrams in an unsupervised setting.,5 Experiments,[0],[0]
"Finally, in Model 5, which adds retweet behaviors, we notice that 5 of the frames decrease in F1 score and 11
of the frames have the same score as the previous model.",5 Experiments,[0],[0]
These results suggest that retweet behaviors are not as useful as the follower network relationships in an unsupervised setting.,5 Experiments,[0],[0]
"To explore the usefulness of frame identification in political discourse analysis, we apply our best performing model (Model 6) on the unlabeled dataset to determine framing patterns over time, both by party and individual.",6 Qualitative Analysis,[0],[0]
Figure 2 shows the results of our frame analysis for both parties over time for two issues: ACA and terrorism.6 We compiled the predicted frames for tweets from 2014 to 2016 for each party.,6 Qualitative Analysis,[0],[0]
"Figure 3 presents the results of frame prediction for 2015 tweets of aisle-crossing individual politicians for these two issues.
",6 Qualitative Analysis,[0],[0]
"Party Frames: From Figure 2(a) we can see that Democrats mainly use Frames 1, 4, 8, 9, and 15 to discuss ACA, while Figure 2(c) shows that Republicans predominantly use Frames 1, 8, 9, 12, and 13.",6 Qualitative Analysis,[0],[0]
"Though the parties use similar frames, they are used to express different agendas.",6 Qualitative Analysis,[0],[0]
"For example, Democrats use Frame 8 to indicate the positive effect that the ACA has had in granting more Americans health care access.",6 Qualitative Analysis,[0],[0]
"Republicans, however, use Frame 8 (and Frame 13) to indicate their party’s agenda to replace the ACA with access to different options for health care.",6 Qualitative Analysis,[0],[0]
"Additionally, Democrats use the Fairness & Equality Frame (Frame 4) to convey that the ACA gives minority groups a better chance at accessing health care.
6Due to space, we omit the other 4 issues.",6 Qualitative Analysis,[0],[0]
"These 2 were chosen because they are among the most frequently discussed issues in our dataset.
",6 Qualitative Analysis,[0],[0]
They also use Frame 15 to express statistics about enrollment of Americans under the ACA.,6 Qualitative Analysis,[0],[0]
"Finally, Republicans use Frames 12 and 13 to bring attention to their own party’s actions to “repeal and replace” the ACA with different policies.
",6 Qualitative Analysis,[0],[0]
Figures 2(b) and 2(d) show the party-based framing patterns over time for terrorism related tweets.,6 Qualitative Analysis,[0],[0]
"For this issue both parties use similar frames: 3, 7, 10, 14, 16, and 17, but to express different views.",6 Qualitative Analysis,[0],[0]
"For example, Democrats use Frame 3 to indicate a moral responsibility to fight ISIS.",6 Qualitative Analysis,[0],[0]
Republicans use Frame 3 to frame terrorists or their attacks as a result of “radical Islam”.,6 Qualitative Analysis,[0],[0]
An interesting pattern to note is seen in Frames 10 and 14 for both parties.,6 Qualitative Analysis,[0],[0]
"In 2015 there is a large in-
crease in the usage of this frame.",6 Qualitative Analysis,[0],[0]
"This seems to indicate that parties possibly adopt new frames simultaneously or in response to the opposing party, perhaps in an effort to be in control of the way the message is delivered through that frame.
",6 Qualitative Analysis,[0],[0]
"Individual Frames: In addition to entire party analysis, we were interested in seeing if frames could shed light on the behavior of aisle-crossing politicians.",6 Qualitative Analysis,[0],[0]
"These are politicians who do not vote the same as the majority vote of their party (i.e., they vote the same as the opposing party).",6 Qualitative Analysis,[0],[0]
"Identifying such politicians can be useful in governments which are heavily split by party, i.e., governments such as the recent U.S. Congress (2015 to 2017), where politicians tend to vote the same
as the rest of their party members.",6 Qualitative Analysis,[0],[0]
"For this analysis, we collected five 2015 votes from the House of Representatives on both issues and compiled a list of the politicians who voted opposite to their party.",6 Qualitative Analysis,[0],[0]
The most important descriptor we noticed was that all aisle-crossing politicians tweet less frequently on the issue than their fellow party members.,6 Qualitative Analysis,[0],[0]
This is true for both parties.,6 Qualitative Analysis,[0],[0]
"This behavior could indicate lack of desire to draw attention to one’s stance on the particular issue.
",6 Qualitative Analysis,[0],[0]
Figure 3(a) shows the framing patterns of aislecrossing Republicans on ACA votes from 2015.,6 Qualitative Analysis,[0],[0]
"Recall from Figure 2 that Democrats mostly use Frames 1, 4, 8, 9, and 15, while Republicans mainly use Frames 1, 8, and 9.",6 Qualitative Analysis,[0],[0]
"In this example, these Republicans are considered aislecrossing votes because they have voted the same as Democrats on this issue.",6 Qualitative Analysis,[0],[0]
"The most interesting pattern to note here is that these Republicans use the same framing patterns as the Republicans (Frames 1, 8, and 9), but they also use the frames that are unique to Democrats: Frames 4 and 15.",6 Qualitative Analysis,[0],[0]
These latter two frames appear significantly less in the Republican tweets of our entire dataset as well.,6 Qualitative Analysis,[0],[0]
"These results suggest that to predict aisle-crossing
Republicans it would be useful to check for usage of typically Democrat-associated frames, especially if those frames are infrequently used by Republicans.
",6 Qualitative Analysis,[0],[0]
Figure 3(b) shows the predicted frames for aisle-crossing Democrats on terrorism-related votes.,6 Qualitative Analysis,[0],[0]
"We see here that there are very few tweets from these Democrats on this issue and that overall they use the same framing patterns as seen previously: Frames 3, 7, 10, 14, 16, and 17.",6 Qualitative Analysis,[0],[0]
"However, given the small scale of these tweets, we can also consider Frames 12 and 13 to show peaks for this example.",6 Qualitative Analysis,[0],[0]
This suggests that for aisle-crossing Democrats the use of additional frames not often used by their party for discussing an issue might indicate potentially different voting behaviors.,6 Qualitative Analysis,[0],[0]
In this paper we present the task of collective classification of Twitter data for framing prediction.,7 Conclusion,[0],[0]
"We show that by incorporating Twitter behaviors such as similar activity times and similar networks, we can increase F1 score prediction.",7 Conclusion,[0],[0]
"We provide an analysis of our approach in both supervised and unsupervised settings, as well as a real world analysis of framing patterns over time.",7 Conclusion,[0],[0]
"Finally, our global PSL models can be applied to other domains, such as politics in other countries, simply by changing the initial unigram keywords to reflect the politics of those countries.",7 Conclusion,[0],[0]
We thank the anonymous reviewers for their thoughtful comments and suggestions.,Acknowledgments,[0],[0]
"In this section we provide additional information about our congressional tweets dataset, as well as the lists of keywords and phrases used to filter tweets by issue and the unigrams used to extract information used for the Unigram and MaxSim PSL predicates.",A Supplementary Material,[0],[0]
"It is important to note that during preprocessing capitalization, stop words, URLs, and punctuation have been removed from tweets in our dataset.",A Supplementary Material,[0],[0]
"Additional word lists along with our PSL scripts and dataset are available at: http://purduenlp.cs.purdue.edu/ projects/twitterframing.
",A Supplementary Material,[0],[0]
Dataset Statistics:,A Supplementary Material,[0],[0]
Figure 4 shows the coverage of the labeled frames by party.,A Supplementary Material,[0],[0]
"From this, general patterns can be observed.",A Supplementary Material,[0],[0]
"For example, Republicans use Frames 12 and 17 more frequently than Democrats, while Democrats tend to use Frames 4, 9, 10, and 11.",A Supplementary Material,[0],[0]
"Table 7 shows the count of each type of frame that appears in each issue in our labeled dataset.
",A Supplementary Material,[0],[0]
Word Lists: Table 8 lists the keywords or phrases used to filter the entire dataset to only tweets related to the six issues studied in this paper.,A Supplementary Material,[0],[0]
"Table 9 lists the unigrams that were designed based on the descriptions for Frames 1 through 14
provided in the Policy Frames Codebook (Boydstun et al., 2014).",A Supplementary Material,[0],[0]
These unigrams provide the initial supervision for our models as described in Section 4.,A Supplementary Material,[0],[0]
Framing is a political strategy in which politicians carefully word their statements in order to control public perception of issues.,abstractText,[0],[0]
"Previous works exploring political framing typically analyze frame usage in longer texts, such as congressional speeches.",abstractText,[0],[0]
"We present a collection of weakly supervised models which harness collective classification to predict the frames used in political discourse on the microblogging platform, Twitter.",abstractText,[0],[0]
"Our global probabilistic models show that by combining both lexical features of tweets and network-based behavioral features of Twitter, we are able to increase the average, unsupervised F1 score by 21.52 points over a lexical baseline alone.",abstractText,[0],[0]
Leveraging Behavioral and Social Information for Weakly Supervised Collective Classification of Political Discourse on Twitter,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 345–350 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
345",text,[0],[0]
"Multiword expressions (MWEs) are combinations of multiple words that exhibit some degree of idiomaticity (Baldwin and Kim, 2010).",1 Introduction,[0],[0]
"Verb–noun combinations (VNCs), consisting of a verb with a noun in its direct object position, are a common type of semantically-idiomatic MWE in English and cross-lingually (Fazly et al., 2009).",1 Introduction,[0],[0]
"Many VNCs are ambiguous between MWEs and literal combinations, as in the following examples of see stars, in which 1 is an idiomatic usage (i.e., an MWE), while 2 is a literal combination.1
1.",1 Introduction,[0],[0]
"Hereford United were seeing stars at Gillingham after letting in 2 early goals
2.",1 Introduction,[0],[0]
"Look into the night sky to see the stars 1These examples, and idiomaticity judgements, are taken
from the VNC-Tokens dataset (Cook et al., 2008).
",1 Introduction,[0],[0]
"MWE identification is the task of automatically determining which word combinations at the token-level form MWEs (Baldwin and Kim, 2010), and must be able to make such distinctions.",1 Introduction,[0],[0]
"This is particularly important for applications such as machine translation (Sag et al., 2002), where the appropriate meaning of word combinations in context must be preserved for accurate translation.
",1 Introduction,[0],[0]
"In this paper, following prior work (e.g., Salton et al., 2016), we frame token-level identification of VNCs as a supervised binary classification problem, i.e., idiomatic vs. literal.",1 Introduction,[0],[0]
"We consider a range of approaches to forming distributed representations of the context in which a VNC occurs, including word embeddings (Mikolov et al., 2013), word embeddings tailored to representing sentences (Kenter et al., 2016), and skip-thoughts sentence embeddings (Kiros et al., 2015).",1 Introduction,[0],[0]
We then train a support vector machine (SVM) on these representations to classify unseen VNC instances.,1 Introduction,[0],[0]
"Surprisingly, we find that an approach based on representing sentences as the average of their word embeddings performs comparably to, or better than, the skip-thoughts based approach previously proposed by Salton et al. (2016).
VNCs exhibit lexico-syntactic fixedness.",1 Introduction,[0],[0]
"For example, the idiomatic interpretation in example 1 above is typically only accessible when the verb see has active voice, the determiner is null, and the noun star is in plural form, as in see stars or seeing stars.",1 Introduction,[0],[0]
"Usages with a determiner (as in example 2), a singular noun (e.g., see a star), or passive voice (e.g., stars were seen) typically only have the literal interpretation.
",1 Introduction,[0],[0]
In this paper we further incorporate knowledge of the lexico-syntactic fixedness of VNCs — automatically acquired from corpora using the method of Fazly et al. (2009) — into our various embedding-based approaches.,1 Introduction,[0],[0]
"Our experimental results show that this leads to substantial improve-
ments, indicating that this rich linguistic knowledge is complementary to that available in distributed representations.",1 Introduction,[0],[0]
"Much research on MWE identification has focused on specific kinds of MWEs (e.g., Patrick and Fletcher, 2005; Uchiyama et al., 2005), including English VNCs (e.g., Fazly et al., 2009; Salton et al., 2016), although some recent work has considered the identification of a broad range of kinds of MWEs (e.g., Schneider et al., 2014; Brooke et al., 2014; Savary et al., 2017).
",2 Related work,[0],[0]
"Work on MWE identification has leveraged rich linguistic knowledge of the constructions under consideration (e.g., Fazly et al., 2009; Fothergill and Baldwin, 2012), treated literal and idiomatic as two senses of an expression and applied approaches similar to word-sense disambiguation (e.g., Birke and Sarkar, 2006; Hashimoto and Kawahara, 2008), incorporated topic models (e.g., Li et al., 2010), and made use of distributed representations of words (Gharbieh et al., 2016).
",2 Related work,[0.9519261940504794],"['Biocreative VI ChemProt (CP): consists of 2,432 PubMed titles and abstracts, and contains human annotated mentions of both chemicals and proteins (Krallinger et al., 2017)1.']"
"In the most closely related work to ours, Salton et al. (2016) represent token instances of VNCs by embedding the sentence that they occur in using skip-thoughts (Kiros et al., 2015) — an encoder– decoder model that can be viewed as a sentencelevel counterpart to the word2vec (Mikolov et al., 2013) skip-gram model.",2 Related work,[0],[0]
"During training the target sentence is encoded using a recurrent neural network, and is used to predict the previous and next sentences.",2 Related work,[0],[0]
"Salton et al. then use these sentence embeddings, representing VNC token instances, as features in a supervised classifier.",2 Related work,[0],[0]
"We treat this skip-thoughts based approach as a strong baseline to compare against.
",2 Related work,[0],[0]
"Fazly et al. (2009) formed a set of eleven lexicosyntactic patterns for VNC instances capturing the voice of the verb (active or passive), determiner (e.g., a, the), and number of the noun (singular or plural).",2 Related work,[0],[0]
"They then determine the canonical form, C(v, n), for a given VNC as follows:2
C(v, n)",2 Related work,[0],[0]
=,2 Related work,[0],[0]
"{ptk ∈ P |z(v, n, ptk) >",2 Related work,[0],[0]
"Tz} (1) where P is the set of patterns, Tz is a predetermined threshold, which is set to 1, and z(v, n, ptk) is calculated as follows:
z(v, n, ptk) = f(v, n,",2 Related work,[0],[0]
"ptk)− f
s (2)
2In a small number of cases a VNC is found to have a small number of canonical forms, as opposed to just one.
",2 Related work,[0],[0]
"where f(·) is the frequency of a VNC occurring in a given pattern in a corpus,3 and f and s are the mean and standard deviations for all patterns for the given VNC, respectively.
",2 Related work,[0],[0]
"Fazly et al. (2009) showed that idiomatic usages of a VNC tend to occur in that expression’s canonical form, while literal usages do not.",2 Related work,[0],[0]
"This approach provides a strong, linguistically-informed, unsupervised baseline, referred to as CForm, for predicting whether VNC instances are idiomatic or literal.",2 Related work,[0],[0]
"In this paper we incorporate knowledge of canonical forms into embedding-based approaches to VNC token classification, and show that this linguistic knowledge can be leveraged to improve such approaches.",2 Related work,[0],[0]
We describe the models used to represent VNC token instances below.,3 Models,[0],[0]
"For each model, a linear SVM classifier is trained on these representations.",3 Models,[0],[0]
"We trained word2vec’s skip-gram model (Mikolov et al., 2013) on a snapshot of Wikipedia from September 2015, which consists of approximately 2.6 billion tokens.",3.1 Word2vec,[0],[0]
We used a window size of ±8 and 300 dimensions.,3.1 Word2vec,[0],[0]
"We ignore all words that occur less than fifteen times in the training corpus, and did not set a maximum vocabulary size.",3.1 Word2vec,[0],[0]
We perform negative sampling and set the number of training epochs to five.,3.1 Word2vec,[0],[0]
"We used batch processing with approximately 10k words in each batch.
",3.1 Word2vec,[0],[0]
"To embed a given a sentence containing a VNC token instance, we average the word embeddings for each word in the sentence, including stopwords.4 Prior to averaging, we normalize each embedding to have unit length.",3.1 Word2vec,[0],[0]
"The Siamese CBOW model (Kenter et al., 2016) learns word embeddings that are better able to represent a sentence through averaging than conventional word embeddings such as skip-gram or CBOW.",3.2 Siamese CBOW,[0],[0]
"We use a Siamese CBOW model that was pretrained on a snapshot of Wikipedia from November 2012 using randomly initialized word
3Fazly et al. (2009) used the British National Corpus (Burnard, 2000).
",3.2 Siamese CBOW,[0],[0]
"4Preliminary experiments showed that models performed better when stopword removal was not applied.
embeddings.5 Similarly to the word2vec model, to embed a given sentence containing a VNC instance, we average the word embeddings for each word in the sentence.",3.2 Siamese CBOW,[0],[0]
"We use a publicly-available skip-thoughts model, that was pre-trained on a corpus of books.6 We represent a given sentence containing a VNC instance using the skip-thoughts encoder.",3.3 Skip-thoughts,[0],[0]
"Note that this approach is our re-implementation of the skipthoughts based method of Salton et al. (2016), and we use it as a strong baseline for comparison.",3.3 Skip-thoughts,[0],[0]
"In this section, we discuss the dataset used in our experiments, and the evaluation of our models.",4 Data and evaluation,[0],[0]
"We use the VNC-Tokens dataset (Cook et al., 2008) — the same dataset used by Fazly et al. (2009) and Salton et al. (2016) — to train and evaluate our models.",4.1 Dataset,[0],[0]
"This dataset consists of sentences containing VNC usages drawn from the British National Corpus (Burnard, 2000),7 along with a label indicating whether the VNC is an idiomatic or literal usage (or whether this cannot be determined, in which case it is labelled “unknown”).
",4.1 Dataset,[0],[0]
VNC-Tokens is divided into DEV and TEST sets that each include fourteen VNC types and a total of roughly six hundred instances of these types annotated as literal or idiomatic.,4.1 Dataset,[0],[0]
"Following Salton et al. (2016), we use DEV and TEST, and ignore all token instances annotated as “unknown”.
",4.1 Dataset,[0],[0]
Fazly et al. (2009) and Salton et al. (2016) structured their experiments differently.,4.1 Dataset,[0],[0]
Fazly et al. report results over DEV and TEST separately.,4.1 Dataset,[0],[0]
In this setup TEST consists of expressions that were not seen during model development (done on DEV).,4.1 Dataset,[0],[0]
"Salton et al., on the other hand, merge DEV and TEST, and create new training and testing sets, such that each expression is present in the training and testing data, and the ratio of idiomatic to literal usages of each expression in the training data is roughly equal to that in the testing data.
",4.1 Dataset,[0.9508886434612784],"['The multi CRF and EM CRF both perform well and come close to the performance of a single CRF trained on the full data, which is approximately twice as much annotated data.']"
We borrowed ideas from both of these approaches in structuring our experiments.,4.1 Dataset,[0],[0]
"We retain
5https://bitbucket.org/TomKenter/ siamese-cbow
6https://github.com/ryankiros/ skip-thoughts
7http://www.natcorp.ox.ac.uk
the type-level division of Fazly et al. (2009) into DEV and TEST.",4.1 Dataset,[0],[0]
"We then divide each of these into training and testing sets, using the same ratios of idiomatic to literal usages for each expression as Salton et al. (2016).",4.1 Dataset,[0],[0]
"This allows us to develop and tune a model on DEV, and then determine whether, when retrained on instances of unseen VNCs in (the training portion of) TEST, that model is able to generalize to new VNCs without further tuning to the specific expressions in TEST.",4.1 Dataset,[0],[0]
The proportion of idiomatic usages in the testing portions of both DEV and TEST is 63%.,4.2 Evaluation,[0],[0]
We therefore use accuracy to evaluate our models following Fazly et al. (2009) because the classes are roughly balanced.,4.2 Evaluation,[0],[0]
"We randomly divide both DEV and TEST into training and testing portions ten times, following Salton et al. (2016).",4.2 Evaluation,[0],[0]
"For each of the ten runs, we compute the accuracy for each expression, and then compute the average accuracy over the expressions.",4.2 Evaluation,[0],[0]
We then report the average accuracy over the ten runs.,4.2 Evaluation,[0],[0]
"In this section we first consider the effect of tuning the cost parameter of the SVM for each model on DEV, and then report results on DEV and TEST using the tuned models.",5 Experimental results,[0],[0]
"We tune the SVM for each model on DEV by carrying out a linear search for the penalty cost from 0.01–100, increasing by a factor of ten each time.",5.1 Parameter tuning,[0],[0]
Results for this parameter tuning are shown in Table 1.,5.1 Parameter tuning,[0],[0]
These results highlight the importance of choosing an appropriate setting for the penalty cost.,5.1 Parameter tuning,[0],[0]
"For example, the accuracy of the word2vec model ranges from 0.619–0.830 depending on the cost setting.",5.1 Parameter tuning,[0],[0]
"In subsequent experiments, for each
model, we use the penalty cost that achieves the highest accuracy in Table 1.",5.1 Parameter tuning,[0],[0]
"In Table 2 we report results on DEV and TEST for each model, as well as the unsupervised CForm model of Fazly et al. (2009), which simply labels a VNC as idiomatic if it occurs in its canonical form, and as literal otherwise.",5.2 DEV and TEST results,[0],[0]
We further consider each model (other than CForm) in two setups.,5.2 DEV and TEST results,[0],[0]
−CF corresponds to the models as described in Section 3.,5.2 DEV and TEST results,[0],[0]
"+CF further incorporates lexico-syntactic knowledge of canonical forms into each model by concatenating the embedding representing each VNC token instance with a one-dimensional vector which is one if the VNC occurs in its canonical form, and zero otherwise.
",5.2 DEV and TEST results,[0],[0]
We first consider results for the −CF setup.,5.2 DEV and TEST results,[0],[0]
"On both DEV and TEST, the accuracy achieved by each supervised model is higher than that of the unsupervised CForm approach, except for Siamese CBOW on TEST.",5.2 DEV and TEST results,[0],[0]
"The word2vec model achieves the highest accuracy on DEV and TEST of 0.830 and 0.804, respectively.",5.2 DEV and TEST results,[0],[0]
"The difference between the word2vec model and the next-best model, skip-thoughts, is significant using a bootstrap test (Berg-Kirkpatrick et al., 2012) with 10k repetitions for DEV (p = 0.006), but not for TEST (p = 0.051).",5.2 DEV and TEST results,[0],[0]
"Nevertheless, it is remarkable that the relatively simple approach to averaging word embeddings used by word2vec performs as well as, or better than, the much more complex skipthoughts model used by Salton et al. (2016).8
8The word2vec and skip-thoughts models were trained on different corpora, which could contribute to the differences in results for these models.",5.2 DEV and TEST results,[0],[0]
"We therefore carried out an additional experiment in which we trained word2vec on BookCorpus, the corpus on which skip-thoughts was trained.",5.2 DEV and TEST results,[0],[0]
"This new word2vec model achieved accuracies of 0.825 and 0.809, on DEV and TEST, respectively, which are also higher accu-
Turning to the +CF setup, we observe that, for both DEV and TEST, each model achieves higher accuracy than in the −CF setup.9",5.2 DEV and TEST results,[0],[0]
All of these differences are significant using a bootstrap test (p < 0.002 in each case).,5.2 DEV and TEST results,[0],[0]
"In addition, each method outperforms the unsupervised CForm approach on both DEV and TEST.",5.2 DEV and TEST results,[0],[0]
"These findings demonstrate that the linguistically-motivated, lexico-syntactic knowledge encoded by the canonical form feature is complementary to the information from a wide range of types of distributed representations.",5.2 DEV and TEST results,[0],[0]
"In the +CF setup, the word2vec model again achieves the highest accuracy on both DEV and TEST of 0.854 and 0.852, respectively.10 The difference between the word2vec model and the next-best model, again skip-thoughts, is significant for both DEV and TEST using a bootstrap test (p < 0.05 in each case).
",5.2 DEV and TEST results,[0],[0]
"To better understand the impact of the canonical form feature when combined with the word2vec model, we compute the average precision, recall, and F1 score for each MWE for both the positive (idiomatic) and negative (literal) classes, for each run on TEST.11 For a given run, we then compute the average precision, recall, and F1 score across all MWEs, and then the average over all ten runs.",5.2 DEV and TEST results,[0],[0]
"We do this using CForm, and the word2vec model with and without the canonical form feature.",5.2 DEV and TEST results,[0],[0]
Results are shown in Table 3.,5.2 DEV and TEST results,[0],[0]
"In line with the findings of Fazly et al. (2009), CForm achieves higher precision and recall on idiomatic usages than literal ones.",5.2 DEV and TEST results,[0],[0]
"In particular, the relatively low recall for the literal class indicates that many literal usages occur in a canonical form.",5.2 DEV and TEST results,[0],[0]
"Comparing the word2vec model with and without the canonical form feature, we see that, when this feature is used, there is a relatively larger increase in precision and recall (and F1 score) for the literal class, than for the idiomatic class.",5.2 DEV and TEST results,[0],[0]
"This indicates that, although the
racies than those obtained by the skip-thoughts model.",5.2 DEV and TEST results,[0],[0]
"9In order to determine that this improvement is due to the information about canonical forms carried by the additional feature in the +CF setup, and not due to the increase in number of dimensions, we performed additional experiments in which we concatenated the embedding representations with a random binary feature, and with a randomly chosen value between 0 and 1.",5.2 DEV and TEST results,[0.9525362228182899],"['In Table 3, we see that the single CRF model performs very poorly in this extreme setting due to the large amount of missing annotations.']"
"For each model, neither of these approaches outperformed that model using the +CF setup.
",5.2 DEV and TEST results,[0],[0]
"10In the +CF setup, the word2vec model using embeddings that were trained on the same corpus as skip-thoughts achieved accuracies of 0.846 and 0.851, on DEV and TEST, respectively.",5.2 DEV and TEST results,[0],[0]
"These are again higher accuracies than the corresponding setup for the skip-thoughts model.
",5.2 DEV and TEST results,[0],[0]
11We carried out the same analysis on DEV.,5.2 DEV and TEST results,[0],[0]
"The findings were similar.
canonical form feature itself performs relatively poorly on literal usages, it provides information that enables the word2vec model to better identify literal usages.",5.2 DEV and TEST results,[0],[0]
"Determining whether a usage of a VNC is idiomatic or literal is important for applications such as machine translation, where it is vital to preserve the meanings of word combinations.",6 Conclusions,[0],[0]
In this paper we proposed two approaches to the task of classifying VNC token instances as idiomatic or literal based on word2vec embeddings and Siamese CBOW.,6 Conclusions,[0],[0]
"We compared these approaches against a linguistically-informed unsupervised baseline, and a model based on skip-thoughts previously applied to this task (Salton et al., 2016).",6 Conclusions,[0],[0]
"Our experimental results show that a comparatively simple approach based on averaging word embeddings performs at least as well as, or better than, the approach based on skip-thoughts.",6 Conclusions,[0],[0]
"We further proposed methods to combine linguistic knowledge of the lexico-syntactic fixedness of VNCs — socalled “canonical forms”, which can be automatically acquired from corpora via statistical methods — with the embedding based approaches.",6 Conclusions,[0],[0]
"Our findings indicate that this rich linguistic knowledge is complementary to that available in distributed representations.
",6 Conclusions,[0],[0]
"Alternative approaches to embedding sentences containing VNC instances could also be considered, for example, FastSent (Hill et al., 2016).",6 Conclusions,[0],[0]
"However, all of the models we used represent the context of a VNC by the sentence in which it occurs.",6 Conclusions,[0.9527897977979223],"['Whenever the different CRF predictions disagree on a span of tokens, we choose the prediction from the CRF that has higher marginal probability of predicting that span of tokens (Alg.']"
"In future work we therefore also intend to consider approaches such as context2vec (Melamud et al., 2016) which explicitly encode the context in which a token occurs.",6 Conclusions,[0],[0]
"Finally, one known challenge of VNC token classification is to develop models that are able to generalize to VNC types that were not seen during training (Gharbieh et al., 2016).",6 Conclusions,[0],[0]
"In future work we plan to explore
this experimental setup.",6 Conclusions,[0],[0]
"Verb–noun combinations (VNCs) — e.g., blow the whistle, hit the roof, and see stars — are a common type of English idiom that are ambiguous with literal usages.",abstractText,[0],[0]
"In this paper we propose and evaluate models for classifying VNC usages as idiomatic or literal, based on a variety of approaches to forming distributed representations.",abstractText,[0],[0]
"Our results show that a model based on averaging word embeddings performs on par with, or better than, a previously-proposed approach based on skip-thoughts.",abstractText,[0],[0]
Idiomatic usages of VNCs are known to exhibit lexico-syntactic fixedness.,abstractText,[0],[0]
"We further incorporate this information into our models, demonstrating that this rich linguistic knowledge is complementary to the information carried by distributed representations.",abstractText,[0],[0]
Leveraging distributed representations and lexico-syntactic fixedness for token-level prediction of the idiomaticity of English verb-noun combinations,title,[0],[0]
"Relational learning from network data, particularly with probabilistic methods, has gained a wide range of applications such as social network analysis (Xiang et al., 2010), recommender systems (Gopalan et al., 2014b), knowledge graph completion (Hu et al., 2016b), and bioinformatics (Huopaniemi et al., 2010).",1. Introduction,[0],[0]
"Generally speaking, the goal of relational learning is to discover and analyse latent clusters of entities (i.e., community detection), and predict missing links (i.e., link prediction).
",1. Introduction,[0],[0]
The standard approach for modelling relational data is latent factor analysis via matrix factorisation and its variations.,1. Introduction,[0],[0]
"Among the existing approaches, Non-negative Matrix Factorisation (NMF) and the Stochastic Block Model (SBM) are prominent foundational methods.",1. Introduction,[0],[0]
"NMF is usually used to model relationships between two sets of entities such as users and movies in collaborative filtering (Mnih & Salakhutdinov, 2008).",1. Introduction,[0],[0]
"While developed independently, SBM (Wang & Wong, 1987; Nowicki & Snijders, 2001) can be viewed as an extension of NMF that introduces
1Faculty of Information Technology, Monash University, Australia.",1. Introduction,[0],[0]
Correspondence to:,1. Introduction,[0],[0]
"He Zhao <he.zhao@monash.edu>.
Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
a block matrix to capture the interactions between latent factors.,1. Introduction,[0],[0]
"There have been many Bayesian extensions of these two methods, relaxing the assumptions and/or introducing extra components, such as the Infinite Relational Model (IRM) (Kemp et al., 2006), the mixture membership stochastic block model (MMSB) (Airoldi et al., 2008), and the non-parametric latent feature models (NLFM) (Miller et al., 2009).",1. Introduction,[0],[0]
"Poisson Factorisation (PF) (Dunson & Herring, 2005; Zhou et al., 2012), is a popular version of NMF which models count data with convenient statistical properties (Gopalan et al., 2014b; 2015).",1. Introduction,[0],[0]
"Combining the ideas of PF and SBM, the infinite Edge Partition Model (EPM) (Zhou, 2015) and its extensions (Hu et al., 2016b) have proven successful for relational networks.
",1. Introduction,[0],[0]
"When a network has less data, relational learning becomes more difficult.",1. Introduction,[0],[0]
"One extreme case is the cold-start problem (Lin et al., 2013; Sedhain et al., 2014; Zhang & Wang, 2015), where a node has no observed links, making suggestion of links for that node even more challenging.",1. Introduction,[0],[0]
"In such cases, it is natural to appeal to side information such as node attributes or features.",1. Introduction,[0],[0]
"For instance, papers in citation networks are often associated with categories and authors, and users in Facebook or Twitter are often asked to provide information such as age, gender and interests.",1. Introduction,[0],[0]
"It is reasonable to assume that nodes having similar attributes are more likely to relate to each other (i.e., homophily, Nickel et al., 2016).",1. Introduction,[0],[0]
"Thus, node attributes serve as important complementary information to relational data.
",1. Introduction,[0],[0]
There are few Bayesian probabilistic relational models that are able to leverage side information.,1. Introduction,[0],[0]
"For example, NLFM uses a linear regression model to transform the features of each node into a single number, which contributes to link probabilities.",1. Introduction,[0],[0]
"However, side information in NLFM cannot directly influence the latent factors, which gives little support for community detection.",1. Introduction,[0],[0]
"As an extension of MMSB, the Non-parametric Meta-data Dependent Relational (NMDR) model (Kim et al., 2012) incorporates attributes into the mixed-membership distribution of each node with the logistic-normal transform, which results in non-conjugacy for inference.",1. Introduction,[0],[0]
"Fan et al. (2016) further developed this idea in the Node information Involved Mixture Membership model (niMM), where side information is integrated in a conjugate way.",1. Introduction,[0],[0]
"Although these models demonstrate improvement using side information, they
scale quadratically in the number of nodes and the incorporation of side information is often complicated.
",1. Introduction,[0],[0]
"Several recent methods (Gopalan et al., 2014a; Acharya et al., 2015; Hu et al., 2016a) extend PF with side information using the additivity of the Poisson and gamma distributions/processes.",1. Introduction,[0],[0]
"With improved scalability, the Structural Side Information Poisson Factorisation (SSI-PF) (Hu et al., 2016a) models directed unweighted networks with node labels, such as citation networks with papers labelled with one of several categories.",1. Introduction,[0],[0]
"However, its performance remains untested when a node has multiple attributes.",1. Introduction,[0],[0]
"Moreover, undirected networks are not handled by SSI-PF.
",1. Introduction,[0],[0]
"In this paper we present the Node Attribute Relational Model (NARM)1, a fully Bayesian approach that models large, sparse, and unweighted relational networks with arbitrary node attributes encoded in binary form.",1. Introduction,[0],[0]
It works with Poisson gamma relational models to incorporate side information.,1. Introduction,[0],[0]
"Specifically, we propose the Symmetric NARM (Sym-NARM) for undirected networks, an extension of EPM (Zhou, 2015) and the Asymmetric NARM (Asym-NARM) for directed networks, an extension of PF (Zhou et al., 2012).",1. Introduction,[0],[0]
"The proposed models have several key properties: (1) Effectively modelling node attributes: the proposed models are able to achieve improved link prediction performance, especially where training data are limited.",1. Introduction,[0],[0]
"(2) Fully Bayesian and conjugate: the inference is done by efficient, closed-form Gibbs sampling which scales linearly in the number of observed links and takes advantage of the sparsity of node attributes.",1. Introduction,[0],[0]
It makes our models scalable for large but sparse relational networks with large sets of node attributes.,1. Introduction,[0],[0]
(3) Flexibility: the proposed models work on directed and undirected relational networks with flat and hierarchical node attributes.,1. Introduction,[0],[0]
"Here we focus on modelling unweighted networks that can be either directed (i.e., the relationship is asymmetric) or undirected.",2. The Node Attribute Relational Model,[0],[0]
"Assume a relational network with N nodes is stored in a binary adjacency matrix Y ∈ {0, 1}N×N where yi,j = 1 indicates the presence of a link between nodes i and j. If the relationship described in the network is symmetric, then yi,j = yj,i, and if asymmetric, possibly yi,j 6= yj,i. Node attributes are encoded in a binary matrix F ∈ {0, 1}N×L, where L is the total number of attributes.",2. The Node Attribute Relational Model,[0],[0]
"Attribute fi,l = 1 indicates attribute l is active with node i and vice versa.",2. The Node Attribute Relational Model,[0],[0]
"Although our models incorporate binary attributes, categorical attributes and real-valued attributes can be converted into binary values with proper transformations (Kim et al., 2012; Fan et al., 2016; Hu et al., 2016a).
",2. The Node Attribute Relational Model,[0],[0]
1Code available at https://github.com/ ethanhezhao/NARM/,2. The Node Attribute Relational Model,[0],[0]
Sym-NARM works with undirected networks.,2.1. The Symmetric Node Attribute Relational Model,[0],[0]
Its generative process is shown in Figure 1.,2.1. The Symmetric Node Attribute Relational Model,[0],[0]
"Instead of modelling the binary matrix Y directly, it applies the Bernoulli-Poisson link (BPL) function (Zhou, 2015) using an underlying latent count matrix X. One first draws a latent count xi,j from the Poisson distribution and then thresholds it at 1 to generate a binary value yi,j .",2.1. The Symmetric Node Attribute Relational Model,[0],[0]
This is shown in Eqs.,2.1. The Symmetric Node Attribute Relational Model,[0],[0]
(1)- (3).,2.1. The Symmetric Node Attribute Relational Model,[0],[0]
"Analysed in (Zhou, 2015; Hu et al., 2016b;a), BPL has the appealing property that if yi,j = 0, then xi,j = 0 with probability one.",2.1. The Symmetric Node Attribute Relational Model,[0],[0]
"Thus, only non-zeros in Y need to be sampled, giving huge computational savings for large sparse networks, illustrated in Section 3 and Section 5.4.
",2.1. The Symmetric Node Attribute Relational Model,[0],[0]
The latent matrix X is further factorised into K latent factors with a non-negative bilinear model: X ∼ Poi(ΦΛΦT ) where Φ ∈ RN×K+ and Λ ∈ RK×K+ .,2.1. The Symmetric Node Attribute Relational Model,[0],[0]
"Φ is referred to as the node factor loading matrix where φi,k models the strength of the connection between node i and latent factor k.",2.1. The Symmetric Node Attribute Relational Model,[0],[0]
"As in SBM, the correlations of the latent factors are modelled in a symmetric matrix Λ, referred to as the block matrix.",2.1. The Symmetric Node Attribute Relational Model,[0],[0]
"Following (Zhou, 2015), we draw Λ from a hierarchical relational gamma process (implemented with truncation as a vector of gamma variables) , shown in Eqs.",2.1. The Symmetric Node Attribute Relational Model,[0],[0]
"(8) and (9).
",2.1. The Symmetric Node Attribute Relational Model,[0],[0]
"One appealing aspect of our model is the incorporation of node attributes on the prior of φi,k (i.e., gi,k).",2.1. The Symmetric Node Attribute Relational Model,[0],[0]
Shown in Eq.,2.1. The Symmetric Node Attribute Relational Model,[0],[0]
"(5), gi,k is constructed with a log linear combination of fi,l. hl,k is referred to as the kth attribute factor loading of attribute l, which influences gi,k iff attribute l is active with node i (i.e., fi,l = 1).",2.1. The Symmetric Node Attribute Relational Model,[0],[0]
"bk acts as an attribute-free bias for each latent factor k. hl,k and bk are gamma distributed with mean 1, hence if attribute l does not contribute to latent factor k or is less useful, hl,k is expected to be near 1 and to have little influence on gi,k.",2.1. The Symmetric Node Attribute Relational Model,[0],[0]
"The hyper-parameter µ0 controls the variation of hl,k.
The intuition of our model is: if two nodes have more common attributes, their gamma shape parameters will be more similar, with similar node factor loadings, resulting in a larger probability that they relate to each other.",2.1. The Symmetric Node Attribute Relational Model,[0],[0]
"Moreover, instead of incorporating the node attributes directly into the node factor loadings, Sym-NARM uses them as the prior information using Eq.",2.1. The Symmetric Node Attribute Relational Model,[0],[0]
"(4), which results in a principled way of balancing the side information and the network data.",2.1. The Symmetric Node Attribute Relational Model,[0],[0]
"In addition, different attributes can contribute differently to the latent factors.",2.1. The Symmetric Node Attribute Relational Model,[0],[0]
"For example, the gender of an author may be much less important to co-authorship with others than the research fields.",2.1. The Symmetric Node Attribute Relational Model,[0],[0]
"This is controlled by the attribute factor loading hl,k in our model.",2.1. The Symmetric Node Attribute Relational Model,[0],[0]
"Extending the Beta Gamma Gamma Poisson factorisation (BGGPF) (Zhou et al., 2012), Asym-NARM works on di-
rected relational networks with node attributes incorporated in a similar way to Sym-NARM.",2.2. The Asymmetric Node Attribute Relational Model,[0],[0]
Figure 2 shows its generative process.,2.2. The Asymmetric Node Attribute Relational Model,[0],[0]
"Here the latent count matrix X is factorised as X ∼ Poi(ΦΘ), where Φ ∈ RN×K+ and Θ ∈ RK×N+ are referred to as the factor loading matrix and the factor score matrix respectively.",2.2. The Asymmetric Node Attribute Relational Model,[0],[0]
"Similar to SSI-PF, the node attributes are incorporated on the prior of Φ.",2.2. The Asymmetric Node Attribute Relational Model,[0],[0]
"Relational networks can be associated with hierarchical side information (Hu et al., 2016a).",2.3. Incorporating Hierarchical Node Attributes,[0],[0]
"For example, in a patent citation network, patents can be labelled with the International Patent Classification (IPC) code, which is a hierarchy of patent categories and sub-categories.",2.3. Incorporating Hierarchical Node Attributes,[0],[0]
"Suppose the second level attributes are stored in a binary matrix F′ ∈ {0, 1}L×M whereM is the number of attributes in the second level.",2.3. Incorporating Hierarchical Node Attributes,[0],[0]
"Our models can be used to incorporate hierarchical node attributes via a straightforward extension: re-
place hyper-parameter µ0 in Eq.",2.3. Incorporating Hierarchical Node Attributes,[0],[0]
"(6) with µl,k = ∏M m δ f ′l,m m,k .",2.3. Incorporating Hierarchical Node Attributes,[0],[0]
This extension mirrors what is done for first level attributes.,2.3. Incorporating Hierarchical Node Attributes,[0],[0]
Both Sym-NARM and Asym-NARM enjoy local conjugacy so the inference of all latent variables can be done by closed-form Gibbs sampling.,3. Inference with Gibbs Sampling,[0],[0]
"Moreover, the inference only needs to be conducted on the non-zero entries in Y and F. This section focuses on the sampling of hl,k (bk), the key variable in the proposed incorporation of node attributes.",3. Inference with Gibbs Sampling,[0],[0]
"The sampling of the other latent variables is similar to those in EPM and BGGPF, detailed in (Zhou, 2015;
Zhou et al., 2012).",3. Inference with Gibbs Sampling,[0],[0]
"As the sampling for hl,k is analogous in Sym-NARM and Asym-NARM, our introduction will be based on Asym-NARM alone.
",3. Inference with Gibbs Sampling,[0],[0]
"With the Poisson gamma conjugacy, the likelihood for gi,k with φi,k marginalised out is:
p(gi,k | xi,·,k) ∝",3. Inference with Gibbs Sampling,[0],[0]
"(1− qk)gi,k Γ(gi,k + xi,·,k)
Γ(gi,k) (19) where xi,·,k = ∑
j xi,j,k and xi,j,k is the latent count.",3. Inference with Gibbs Sampling,[0],[0]
The gamma ratio in Eq.,3. Inference with Gibbs Sampling,[0],[0]
"(19), i.e., the Pochhammer symbol for a rising factorial, can be augmented with an auxiliary variable ti,k:
Γ(gi,k+xi,·,k) Γ(gi,k)
",3. Inference with Gibbs Sampling,[0],[0]
"= ∑xi,·,k
ti,k=0 S xi,·,k",3. Inference with Gibbs Sampling,[0],[0]
"ti,k g ti,k",3. Inference with Gibbs Sampling,[0],[0]
"i,k where S x t in-
dicates an unsigned Stirling number of the first kind (Chen et al., 2011; Teh et al., 2012; Zhou & Carin, 2015).
TakingO(xi,·,k), ti,k can be directly sampled by a Chinese Restaurant Process with gi,k as the concentration and xi,·,k",3. Inference with Gibbs Sampling,[0],[0]
"as the number of customers:
ti,k ← ti,k + Bern (
gi,k gi,k + i′
) for i′ = 1 : xi,·,k (20)
where Bern(·) is the Bernoulli distribution.",3. Inference with Gibbs Sampling,[0],[0]
"Alternatively, for large xi,·,k, because the standard deviation of ti,k is O( √
log xi,·,k) (Buntine & Hutter, 2012), one can sample ti,k in a small window around the current value (Du et al., 2010).
",3. Inference with Gibbs Sampling,[0],[0]
With the above augmentation and Eq.,3. Inference with Gibbs Sampling,[0],[0]
"(15), we get: p(G,H | x:,·,:,T,F) ∝",3. Inference with Gibbs Sampling,[0],[0]
(21) N∏ i=1,3. Inference with Gibbs Sampling,[0],[0]
K∏,3. Inference with Gibbs Sampling,[0],[0]
"k=1 S xi,·,k",3. Inference with Gibbs Sampling,[0],[0]
"ti,k e",3. Inference with Gibbs Sampling,[0],[0]
− log ( 1 1−qk ),3. Inference with Gibbs Sampling,[0],[0]
"gi,k · L∏ l=1 K∏",3. Inference with Gibbs Sampling,[0],[0]
"k=1 h ∑N i=1 fi,lti,k l,k
Recall that all the attributes are binary and hl,k influences gi,k only when fi,l = 1.",3. Inference with Gibbs Sampling,[0],[0]
"Extracting all the terms related to
hl,k in Eq.",3. Inference with Gibbs Sampling,[0],[0]
"(21), we get the likelihood of hl,k:
p ( hl,k ∣∣∣∣ gi,khl,k , t:,k, f:,l ) ∝",3. Inference with Gibbs Sampling,[0],[0]
"(22)
e −hl,k log
( 1
1−qk )",3. Inference with Gibbs Sampling,[0],[0]
∑N i=1,3. Inference with Gibbs Sampling,[0],[0]
:,3. Inference with Gibbs Sampling,[0],[0]
"fi,l=1 gi,k hl,k h ∑N i=1 fi,lti,k
l,k
where gi,khl,k is the value of gi,k with hl,k removed when fi,l = 1.",3. Inference with Gibbs Sampling,[0],[0]
The likelihood function above is in a form that is conjugate to the gamma prior.,3. Inference with Gibbs Sampling,[0],[0]
"Therefore, it is straightforward to yield the following sampling strategy for hl,k:
hl,k ∼ Ga(µ′, 1/ν′) (23)
µ′ = µ0 + N∑ i=1",3. Inference with Gibbs Sampling,[0],[0]
":fi,l=1 ti,k (24)
ν′ = 1/µ0",3. Inference with Gibbs Sampling,[0],[0]
"− log (1− qk) N∑
i=1:fi,l=1
gi,k hl,k
(25)
Precomputed with Eq. (15), gi,k can be updated with Eq.",3. Inference with Gibbs Sampling,[0],[0]
"(26), after hl,k is sampled.
",3. Inference with Gibbs Sampling,[0],[0]
"gi,k ← gi,kh
′",3. Inference with Gibbs Sampling,[0],[0]
"l,k
hl,k for i = 1 : N and fi,l = 1 (26)
where h′i,k is the newly sampled value of hi,k.
To compute Eqs.",3. Inference with Gibbs Sampling,[0],[0]
"(24)-(26), we only need to iterate over the nodes that attribute l is active with (i.e., fi,l = 1).",3. Inference with Gibbs Sampling,[0],[0]
"Thus, the sampling for H takes O(D′KL) where D′ is the average number of nodes that an attribute is active with.",3. Inference with Gibbs Sampling,[0],[0]
This demonstrates how the sparsity of node attributes is leveraged.,3. Inference with Gibbs Sampling,[0],[0]
"As the mean of xi,·,k is D/K, sampling the tables T ∈ NN×K takes O(ND) which can be accelerated with the window sampling technique explained above.
",3. Inference with Gibbs Sampling,[0],[0]
We show the computational complexity of our and related models in Table 1.,3. Inference with Gibbs Sampling,[0],[0]
The empirical comparison of running speed is in Section 5.4.,3. Inference with Gibbs Sampling,[0],[0]
"By taking advantage of both network sparsity and node attribute sparsity, our models are more efficient than the competitors, especially on large sparse networks with large sets of attributes.",3. Inference with Gibbs Sampling,[0],[0]
"Compared with the node-attribute models such as NMDR and niMM whose methods result in complicated inference, our Sym-NARM is much more efficient on large sparse networks, illustrated in Table 1.
",4. Related work,[0],[0]
"The most closely related model to our Asym-NARM, also extending the BGGPF algorithm, is SSI-PF.",4. Related work,[0],[0]
But it uses the gamma additivity to construct the prior of node factor loadings with the sum of attribute factor loadings.,4. Related work,[0],[0]
Our model has several advantages over SSI-PF: (1) The derivation of Gibbs sampling of SSI-PF requires that each column of Θ is normalised (Eq. (18)).,4. Related work,[0],[0]
This limits the application of SSI-PF to other models such as EPM which is an unnormalised model.,4. Related work,[0],[0]
"(2) Shown in Table 1, Asym-NARM enjoys more efficient computational complexity.",4. Related work,[0],[0]
"(3) Shown
in Section 5, our model is more effective especially when a node has multiple attributes.
",4. Related work,[0],[0]
"There are also models that extend PF and collective matrix factorisation (Singh & Gordon, 2008) to jointly factorise relational networks and document-word matrices such as (Gopalan et al., 2014a; Zhang & Wang, 2015; Acharya et al., 2015).",4. Related work,[0],[0]
"Our NARM models incorporate general node attributes (not only texts) as the priors of the factor loading matrix in a supervised manner, rather than jointly modelling the side information in an unsupervised manner.
",4. Related work,[0],[0]
"Another related area is supervised topic models such as (Mcauliffe & Blei, 2008; Ramage et al., 2009; Lim & Buntine, 2016).",4. Related work,[0],[0]
"The Dirichlet Multinomial Regression (DMR) model (Mimno & McCallum, 2012) is the most related one to ours.",4. Related work,[0],[0]
It models document attributes on the priors of the topic proportions with the logistic-normal transform.,4. Related work,[0],[0]
"For comparison, we propose DMR-MMSB, extending MMSB with the DMR technique to incorporate side information on the mixed-membership distribution of each node.",4. Related work,[0],[0]
In this section we evaluate Sym-NARM and Asym-NARM with a set of the link prediction tasks on 10 real-world relational datasets with different sizes and various kinds of node attributes.,5. Experiments,[0],[0]
"We compare our models with the stateof-the-art relational models, demonstrating that our models outperform the competitors on those datasets in terms of link prediction performance and per-iteration running time.",5. Experiments,[0],[0]
We report the average area under the curve of both the receiver operating characteristic (AUC-ROC) and precision recall (AUC-PR) for quantitatively analysing the models.,5. Experiments,[0],[0]
"Moreover, we perform qualitative analysis by comparing the link probabilities estimated by the compared models.",5. Experiments,[0],[0]
"For the link prediction task on undirected network data, we compared our Sym-NARM with two models that do
not consider node attributes, EPM (Zhou, 2015), a stateof-the-art relational model, and iMMM (Koutsourelakis & Eliassi-Rad, 2008), a non-parametric version of MMSB,
and two node attribute models, niMM (Fan et al., 2016), a non-parametric relational model which has been demonstrated to outperform NMDR (Kim et al., 2012), and DMRMMSB, our extension to MMSB using the Dirichlet Multinomial Regression (Mimno & McCallum, 2012).",5.1. Link Prediction on Undirected Networks,[0],[0]
SymNAMR was implemented in MATLAB on top of the EPM code and we used the code released by the original authors for EPM and niMM.,5.1. Link Prediction on Undirected Networks,[0],[0]
"iMMM was implemented by Fan et al. (2016) as a variant of niMM.
",5.1. Link Prediction on Undirected Networks,[0],[0]
"The description of the four datasets used is given below:
• Lazega-cowork:",5.1. Link Prediction on Undirected Networks,[0],[0]
"This dataset (Lazega, 2001) contains 378 links of the co-work relationship among 71 attorneys.",5.1. Link Prediction on Undirected Networks,[0],[0]
"Each attorney is associated with attributes such as gender, office location, and age.",5.1. Link Prediction on Undirected Networks,[0],[0]
"After discretisation and binarisation, we derived a 71× 18 binary node attribute matrix with 497 non-zero entries.",5.1. Link Prediction on Undirected Networks,[0],[0]
• NIPS234:,5.1. Link Prediction on Undirected Networks,[0],[0]
"This is a co-author network of the 234 authors with 598 links extracted from NIPS 1-17 conferences (Zhou, 2015).",5.1. Link Prediction on Undirected Networks,[0],[0]
"We merged all the papers written by the same author as a document, and then trained a LDA model with 100 topics.",5.1. Link Prediction on Undirected Networks,[0],[0]
"The 5 most frequent topics were used as the attributes, which gives us a 234 × 100 attribute matrix with 1170 non-zero entries.",5.1. Link Prediction on Undirected Networks,[0],[0]
"• Facebook-ego: The original dataset (McAuley & Leskovec, 2012) was collected from survey participants of Facebook users.",5.1. Link Prediction on Undirected Networks,[0],[0]
"Out of the 10 circles (i.e., friend lists), we used the first circle that contains 347 users with 2519 links.",5.1. Link Prediction on Undirected Networks,[0],[0]
"Each user is associated with 227 binary attributes, encoding side information such as age, gender, and education.",5.1. Link Prediction on Undirected Networks,[0],[0]
We got a 347×227 binary node attribute matrix with 3318 non-zero entries.,5.1. Link Prediction on Undirected Networks,[0],[0]
• NIPS12:,5.1. Link Prediction on Undirected Networks,[0],[0]
NIPS12 was collected from NIPS papers in vols 0-12.,5.1. Link Prediction on Undirected Networks,[0],[0]
It is a median-size co-author network with 2037 authors and 3134 links.,5.1. Link Prediction on Undirected Networks,[0],[0]
"Similar to NIPS234, we used the 5 most frequent topics as the attributes for each author.",5.1. Link Prediction on Undirected Networks,[0],[0]
We got a 2037×100 binary node attribute matrix with 10185 non-zero entries.,5.1. Link Prediction on Undirected Networks,[0],[0]
"For each dataset, we varied the training data from 10% to 90% and used the remaining in testing.",5.1.1. EXPERIMENTAL SETTINGS,[0],[0]
"For each proportion, to generate five random splits, we used the code in the EPM package (Zhou, 2015) which splits a network in terms of its nodes.",5.1.1. EXPERIMENTAL SETTINGS,[0],[0]
The reported AUC-ROC/PR scores were averaged over the five splits.,5.1.1. EXPERIMENTAL SETTINGS,[0],[0]
"We used the default hyper-parameter settings enclosed in the released code for EPM, niMM and iMMM.",5.1.1. EXPERIMENTAL SETTINGS,[0],[0]
"For our Sym-NARM, we set µ0 = 1 and all the other hyper-parameters the same as those in EPM.",5.1.1. EXPERIMENTAL SETTINGS,[0],[0]
Note that the models in comparison except DMR-MMSB are non-parametric models.,5.1.1. EXPERIMENTAL SETTINGS,[0],[0]
"For Sym-NARM and EPM, we set the truncation level large enough for each dataset: Kmax = 50, 100, 256 for Lazega-
cowork, Facebook-ego and NIPS234, NIPS12 respectively.",5.1.1. EXPERIMENTAL SETTINGS,[0],[0]
"For DMR-MMSB, we varied K in {5, 10, 25, 50} and reported the best one.",5.1.1. EXPERIMENTAL SETTINGS,[0],[0]
"Following (Zhou, 2015), we used 3000 MCMC iterations and computed AUC-ROC/PR with the average probability over the last 1500.",5.1.1. EXPERIMENTAL SETTINGS,[0],[0]
The performance of iMMM and niMM on NIPS12 and DMR-MMSB on Facebook-ego and NIPS12 are not reported as the datasets are too large for them given our computational resources.,5.1.1. EXPERIMENTAL SETTINGS,[0],[0]
The AUC-ROC/PR scores are reported in Figure 3.,5.1.2. RESULTS,[0],[0]
"Overall, our Sym-NARM model performs significantly better than niMM, iMMM, and DMR-MMSB on all the datasets, and EPM on 3 datasets (except Facebook-ego with large training proportions).",5.1.2. RESULTS,[0],[0]
It is interesting that the performance of EPM on Facebook-ego gradually approaches ours when more than 30% training data were used.,5.1.2. RESULTS,[0],[0]
"Note that Facebook-ego is much denser than the others, which means the network information itself could be rich enough for EPM to reconstruct the network and the node attributes contribute less.",5.1.2. RESULTS,[0],[0]
"However in general, when relational data are highly incomplete (with less training data), our model is able to achieve improved link prediction performance.
",5.1.2. RESULTS,[0],[0]
"To illustrate how side information helps, we qualitatively compared our model with EPM and niMM by estimating the link probabilities on NIPS234, shown in Figure 4.",5.1.2. RESULTS,[0],[0]
"With 20% training data, EPM does not give a meaningful reconstruction of the original network, but it starts to with more data presented.",5.1.2. RESULTS,[0],[0]
"The similarity of the authors’ topics in Figure 4e matches the original network, demonstrating the usefulness of the topics, but with some error.",5.1.2. RESULTS,[0],[0]
"Using the topics as the authors’ attributes, our Sym-NARM achieves reasonably good reconstruction of the network with only 20% training data, further improving with 80% training data.",5.1.2. RESULTS,[0],[0]
"Although niMM uses the same node attributes, its performance is not as good and is even outperformed by EPM with 80% training data.",5.1.2. RESULTS,[0],[0]
"Here we compared our Asym-NARM (implemented in MATLAB on top of the BGGPF code) with two models that do not consider node attributes, BGGPF (Zhou et al., 2012) and iMMM, and three node-attribute models, niMM, SSIPF (Hu et al., 2016a) and DMR-MMSB.",5.2. Link Prediction on Directed Networks,[0],[0]
"We used the following four datasets:
• Lazega-advice: This dataset is a directed network with 892 links of the advice relation among the attorneys.",5.2. Link Prediction on Directed Networks,[0],[0]
The node attributes are the same as in Lazega-cowork.,5.2. Link Prediction on Directed Networks,[0],[0]
•,5.2. Link Prediction on Directed Networks,[0],[0]
Citeseer:,5.2. Link Prediction on Directed Networks,[0],[0]
"This dataset2 contains a citation network with 2http://linqs.umiacs.umd.edu/projects/ /projects/lbc/index.html
4591 links of 3312 papers, labelled with one of 6 categories.",5.2. Link Prediction on Directed Networks,[0],[0]
"For each paper, we used both the category label and the presence/absence of 500 most frequent words as two separate attribute sets.",5.2. Link Prediction on Directed Networks,[0],[0]
We got a 3312 × 500 word attribute matrix with 65674 non-zero entries.,5.2. Link Prediction on Directed Networks,[0],[0]
•,5.2. Link Prediction on Directed Networks,[0],[0]
Cora:,5.2. Link Prediction on Directed Networks,[0],[0]
"This dataset2 contains a citation network with 5429 links of 2708 papers in machine learning, labelled with one of 7 categories.",5.2. Link Prediction on Directed Networks,[0],[0]
"Similar to Citeseer, we used both the category label and the 500 most frequent words as two separate attribute sets.",5.2. Link Prediction on Directed Networks,[0],[0]
We got a 2708×500 word attribute matrix with 39268 non-zero entries.,5.2. Link Prediction on Directed Networks,[0],[0]
•,5.2. Link Prediction on Directed Networks,[0],[0]
"Aminer: The Aminer dataset (Tang et al., 2009) contains a citation network with 2555 papers labelled with 10 categories and 5967 links.",5.2. Link Prediction on Directed Networks,[0],[0]
"We further collected information of each paper via the Aminer’s API, including the authors’ names (2597 unique authors), abstract, venue, year, and number of citations.",5.2. Link Prediction on Directed Networks,[0],[0]
"For the abstract, we extract the 5 most frequent topics for each paper in a similar way to NIPS234.",5.2. Link Prediction on Directed Networks,[0],[0]
"In total, we prepared two sets of attributes: the labels and the others formed with the combination of all collected information.",5.2. Link Prediction on Directed Networks,[0],[0]
"For fair comparison, we generated training/testing data with the code in the SSI-PF package, which splits a network in terms of its links.",5.2.1. EXPERIMENTAL SETTINGS,[0],[0]
"We used the default hyper-parameter settings of BGGPF, SSI-PF, and niMM, provided by the original authors.",5.2.1. EXPERIMENTAL SETTINGS,[0],[0]
"Kmax was set to 50 on Lazega-advice and 200 (same as (Hu et al., 2016a))",5.2.1. EXPERIMENTAL SETTINGS,[0],[0]
on all the other three datasets.,5.2.1. EXPERIMENTAL SETTINGS,[0],[0]
"For our Asym-NARM, we set µ0 = 1 and the
other hyper-parameters the same as those used in (Zhou et al., 2012; Hu et al., 2016a).",5.2.1. EXPERIMENTAL SETTINGS,[0],[0]
"Following the suggestion of Hu et al. (2016a), we used 1500 MCMC iterations in total and the last 500 samples to compute the AUC-ROC/PR scores.",5.2.1. EXPERIMENTAL SETTINGS,[0],[0]
"Since Citeseer, Cora, and Aminer are already too large for niMM, iMMM, and DMR-MMSB to produce results in reasonable time given our computational resources, we reported their performance only on Lazega-advice.",5.2.1. EXPERIMENTAL SETTINGS,[0],[0]
"Shown in Figure 5a, Asym-NARM gains better results in terms of AUC-ROC/PR on Lazega-advice in most of the training proportions.",5.2.2. RESULTS,[0],[0]
"Overall, the node-attribute models perform better than the models that do not consider node attributes, showing the usefulness of node attributes.",5.2.2. RESULTS,[0],[0]
"On the other three datasets, we used different sets of attributes to study how different attributes influence the performance of Asym-NARM and SSI-PF.
",5.2.2. RESULTS,[0],[0]
"In general, Asym-NARM performs better than SSI-PF regardless of which set of attributes is used.",5.2.2. RESULTS,[0],[0]
The performance of SSI-PF approaches ours in Citeseer with the labels as attributes (indicated by “-l”).,5.2.2. RESULTS,[0],[0]
But the gap between SSI-PF and our model becomes larger when the words are used as attributes (indicated by “-w”).,5.2.2. RESULTS,[0],[0]
"In Cora, SSI-PF with the words does not perform as well as its non-node-attribute counterpart, BGGPF, indicating it may not be as robust as our model with large sets of attributes.",5.2.2. RESULTS,[0],[0]
"To investigate this, we varied the number of the most frequent words from 10 to 500 for Asym-NARM and SSI-PF on Citeseer and Cora.",5.2.2. RESULTS,[0],[0]
"With more words, the AUC-ROC/PR score of SSI-PF de-
grades increasingly.",5.2.2. RESULTS,[0],[0]
"We further checked the prior of the node factor loadings in SSI-PF (the variable that incorporates node attributes and corresponds to gi,k in our model) and found that the coefficient of variation of each node’s prior drops dramatically, indicating with more words, SSIPF is failing to use the supervised information in the words.",5.2.2. RESULTS,[0],[0]
Here we used two datasets with hierarchical node attributes: (1) Cora-hier: a citation network with 1712 papers and 6308 links extracted from the original Cora dataset3.,5.3. Link Prediction with Hierarchical Node Attributes,[0],[0]
"The papers are labelled with one of 63 sub-areas (first level) and each sub-area belongs to one of 10 primary areas (second level), such as “machine learning in artificial intelligence” and “memory management in operating systems”; (2) Patent-hier: a citation network with 1461 patents and 2141 links from the National Bureau of Economic Research where the hierarchical International Patent Classification (IPC) code of a patent is used as attributes.
",5.3. Link Prediction with Hierarchical Node Attributes,[0],[0]
"The AUC-ROC/PR scores in Figure 6 show that our AsymNARM with hierarchical attributes outperforms the others, which demonstrates leveraging hierarchical side information is beneficial to link prediction.",5.3. Link Prediction with Hierarchical Node Attributes,[0],[0]
"Although SSI-PF also models the hierarchical attributes, its performance in these two datasets is not comparable with our model’s.",5.3. Link Prediction with Hierarchical Node Attributes,[0],[0]
"In this section, we compare the running time of the models for directed networks (all implemented in MATLAB and running on a desktop with 3.40 GHz CPU and 16GB RAM).",5.4. Running Time,[0],[0]
"Using 80% data for training, the running time for Asym-NARM, SSI-PF, and niMM on Aminer with different sets of node attributes is reported in Table 2.",5.4. Running Time,[0],[0]
Note DMR-MMSB did not complete with “Authors” and “All” due to our computational resources.,5.4. Running Time,[0],[0]
"Asym-NARM is about 10 times faster than SSI-PF with all the attributes and about
3https://people.cs.umass.edu/˜mccallum/ data.html
2 times faster with the labels.",5.4. Running Time,[0],[0]
"Thus Asym-NARM is more efficient, especially with large sets of attributes, supporting the complexity analysis in Table 1.",5.4. Running Time,[0],[0]
"As a summary of the experiments, Asym/Sym-NARM achieved better link prediction performance with faster inference.",6. Conclusion,[0],[0]
"While EPM, a non-node-attribute model, performed well on nearly complete networks, it degraded with less training data.",6. Conclusion,[0],[0]
"niMM and DMR-MMSB, extensions to MMSB with the logistic-normal transform, had similar results to Sym-NARM but scaled inefficiently.",6. Conclusion,[0],[0]
"SSI-PF’s performance and scalability were not as good as Asym-NARM in the presented cases with flat and hierarchical attributes and it was less effective with larger numbers of attributes.
",6. Conclusion,[0],[0]
"Thus NARM is a comparatively simple yet effective and efficient way of incorporating node attributes, including hierarchical attributes, for relational models with Poisson likelihood.",6. Conclusion,[0],[0]
This leads to improved link prediction and matrix completion for less complete relational data of both directed and undirected networks.,6. Conclusion,[0],[0]
"With the efficient inference, our models can be used to model large sparse relational networks with node attributes.
",6. Conclusion,[0],[0]
"NARM can easily be extended to multi-relational networks such as (Hu et al., 2016b) and topic models with document and word attributes, which is left for our future work.",6. Conclusion,[0],[0]
"Relational data are usually highly incomplete in practice, which inspires us to leverage side information to improve the performance of community detection and link prediction.",abstractText,[0],[0]
This paper presents a Bayesian probabilistic approach that incorporates various kinds of node attributes encoded in binary form in relational models with Poisson likelihood.,abstractText,[0],[0]
Our method works flexibly with both directed and undirected relational networks.,abstractText,[0],[0]
The inference can be done by efficient Gibbs sampling which leverages sparsity of both networks and node attributes.,abstractText,[0],[0]
"Extensive experiments show that our models achieve the stateof-the-art link prediction results, especially with highly incomplete relational data.",abstractText,[0],[0]
Leveraging Node Attributes for Incomplete Relational Data,title,[0],[0]
"The union of subspaces (UoS) model, in which data vectors lie near one of several subspaces, has been used actively in the computer vision community on datasets ranging from images of objects under various lighting conditions (Basri & Jacobs, 2003) to visual surveillance tasks (Oliver et al., 2000).",1. Introduction,[0],[0]
"The recent textbook (Vidal et al., 2016) includes a number of useful applications for this model, including lossy image compression, clustering of face images under different lighting conditions, and video segmentation.",1. Introduction,[0],[0]
"Subspace clustering algorithms utilize the UoS model to cluster data
1Department of Electrical and Computer Engineering, University Michigan, Ann Arbor, MI, USA.",1. Introduction,[0],[0]
"Correspondence to: John Lipor <lipor@umich.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
vectors and estimate the underlying subspaces, achieving excellent performance on a variety of real datasets.",1. Introduction,[0],[0]
"However, as we will show in Section 4, even oracle UoS classifiers do not achieve perfect clustering on these datasets.",1. Introduction,[0],[0]
"While current algorithms for subspace clustering are unsupervised, in many cases a human could provide relevant information in the form of pairwise constraints between points, e.g., answering whether two images are of the same person or whether two objects are the same.
",1. Introduction,[0],[0]
The incorporation of pairwise constraints into clustering algorithms is known as pairwise-constrained clustering (PCC).,1. Introduction,[0],[0]
PCC algorithms use supervision in the form of must-link and cannot-link constraints by ensuring that points with must-link constraints are clustered together and points with cannot-link constraints are clustered apart.,1. Introduction,[0],[0]
"In (Davidson et al., 2006), the authors investigate the phenomenon that incorporating poorly-chosen constraints can lead to an increase in clustering error, rather than a decrease as one would expect from additional label information.",1. Introduction,[0],[0]
This is because points constrained to be in the same cluster that are otherwise dissimilar can confound the constrained clustering algorithm.,1. Introduction,[0],[0]
"For this reason, researchers have turned to active query selection methods, in which constraints are intelligently selected based on a number of heuristics.",1. Introduction,[0],[0]
These algorithms perform well across a number of datasets but do not take advantage of any known structure in the data.,1. Introduction,[0],[0]
"In the case where data lie on a union of subspaces, one would hope that knowledge of the underlying geometry could give hints as to which points are likely to be clustered incorrectly.
",1. Introduction,[0],[0]
Let X = { xi ∈,1. Introduction,[0],[0]
"RD }N i=1
be a set of data points lying near a union of K linear subspaces of the ambient space.",1. Introduction,[0],[0]
"We denote the subspaces by {Sk}Kk=1, each having dimension dk.",1. Introduction,[0],[0]
"An example union of subspaces is shown in Fig. 1, where d1 = 2, d2 = d3 = 1.",1. Introduction,[0],[0]
The goal of subspace clustering algorithms has traditionally been to cluster the points in X according to their nearest subspace without any supervised input.,1. Introduction,[0],[0]
"We turn this around and ask whether this model is useful for active clustering, where we request a very small number of intelligently selected labels.",1. Introduction,[0],[0]
A key observation when considering data well-modeled by a union of subspaces is that uncertain points will be ones lying equally distant to multiple subspaces.,1. Introduction,[0],[0]
"Using a novel definition of margin tailored for the union of subspaces model, we incorporate this observation into an active subspace clustering
algorithm.
",1. Introduction,[0],[0]
Our contributions are as follows.,1. Introduction,[0],[0]
We introduce a novel algorithm for pairwise constrained clustering that leverages UoS structure in the data.,1. Introduction,[0],[0]
"A key step in our algorithm is choosing points of minimum margin, i.e., those lying near a decision boundary between subspaces.",1. Introduction,[0],[0]
We define a notion of margin for the UoS model and provide theoretical insight as to why points of minimum margin are likely to be misclustered by unsupervised algorithms.,1. Introduction,[0],[0]
"We show through extensive experimental results that when the data lie near a union of subspaces, our method drastically outperforms existing PCC algorithms, requiring far fewer queries to achieve perfect clustering.",1. Introduction,[0],[0]
"Our datasets range in dimension from 256-2016, number of data points from 320-9298, and number of subspaces from 5-100.",1. Introduction,[0],[0]
"On ten MNIST digits with a modest number of queries, we get 5% classification error with only 500 pairwise queries compared to about 20% error for current state-of-the-art PCC algorithms and 35% for unsupervised algorithms.",1. Introduction,[0],[0]
"We also achieve 0% classification error on the full Yale, COIL, and USPS datasets with a small fraction of the number of queries needed by competing algorithms.",1. Introduction,[0],[0]
"In datasets where we do not expect subspace structure, our algorithm still achieves competitive performance.",1. Introduction,[0],[0]
"Further, our algorithm is agnostic to the input subspace clustering algorithm and can therefore take advantage of any future algorithmic advances for subspace clustering.",1. Introduction,[0],[0]
"A survey of recently developed subspace clustering algorithms can be found in (Vidal, 2011) and the textbook (Vidal et al., 2016).",2. Related Work,[0],[0]
"In these and more recent work, clustering algorithms that employ spectral methods achieve the best performance on most datasets.",2. Related Work,[0],[0]
"Notable examples of such algorithms include Sparse Subspace Clustering (SSC) (Elhamifar & Vidal, 2013) and its extensions (You et al., 2016b;a), Low-Rank Representation (LRR) (Liu et al., 2010), Thresholded Subspace Clustering (TSC) (Heckel & Bölcskei, 2015), and Greedy Subspace Clustering (GSC)
(Park et al., 2014).",2. Related Work,[0],[0]
"Many recent algorithms exist with both strong theoretical guarantees and empirical performance, and a full review of all approaches is beyond the scope of this work.",2. Related Work,[0],[0]
"However, the core element of all recent algorithms lies in the formation of the affinity matrix, after which spectral clustering is performed to obtain label estimates.",2. Related Work,[0],[0]
"In SSC, the affinity matrix is formed via a series of `1-penalized regressions.",2. Related Work,[0],[0]
LRR uses a similar cost function but penalizes the nuclear norm instead of the `1.,2. Related Work,[0],[0]
"TSC thresholds the spherical distance between points, and GSC works by successively (greedily) building subspaces from points likely to lie in the same subspace.",2. Related Work,[0],[0]
"Of these methods, variants of SSC achieve the best overall performance on benchmark datasets and has the strongest theoretical guarantees, which were introduced in (Elhamifar & Vidal, 2013) and strengthened in numerous recent works (Soltanolkotabi & Candes, 2012; 2014; Wang & Xu, 2013; Wang et al., 2016).",2. Related Work,[0],[0]
"While the development of efficient algorithms with stronger guarantees has received a great deal of attention, very little attention has been paid to the question of what to do about data that cannot be correctly clustered.",2. Related Work,[0],[0]
"Thus, when reducing clustering error to zero (or near zero) is a priority, users must look beyond unsupervised subspace clustering algorithms to alternative methods.",2. Related Work,[0],[0]
"One such method is to request some supervised input in the form of pairwise constraints, leading to the study of pairwise-constrained clustering (PCC).
",2. Related Work,[0],[0]
"PCC algorithms work by incorporating must-link and cannot-link constraints between points, where points with must-link constraints are forced (or encouraged in the case of spectral clustering) to be clustered together, and points with cannot-link constraints are forced to be in separate clusters.",2. Related Work,[0],[0]
"In many cases, these constraints can be provided by a human labeler.",2. Related Work,[0],[0]
"For example, in (Biswas & Jacobs, 2014), the authors perform experiments where comparisons between human faces are provided by users of Amazon Mechanical Turk with an error rate of 1.2%.",2. Related Work,[0],[0]
"Similarly, for subspace clustering datasets such as Yale B and MNIST, a human could easily answer questions such as, “Are these two faces the same person?” and “Are these two images the same number?”",2. Related Work,[0],[0]
"An early example of PCC is found in (Wagstaff et al., 2001), where the authors modify the K-means cost function to incorporate such constraints.",2. Related Work,[0],[0]
"In (Basu et al., 2004), the authors utilize active methods to initialize K-means in an intelligent “EXPLORE” phase, during which neighborhoods of must-linked points are built up.",2. Related Work,[0],[0]
"After this phase, new points are queried against representatives from each neighborhood until a must-link is obtained.",2. Related Work,[0],[0]
"A similar explore phase is used in (Mallapragada et al., 2008), after which a min-max approach is used to select the most uncertain sample.",2. Related Work,[0],[0]
"Early work on constrained spectral clustering appears in (Xu et al., 2005; Wang & Davidson, 2010), in which spectral clustering is improved by examining the
eigenvectors of the affinity matrix in order to determine the most informative points.",2. Related Work,[0],[0]
"However, these methods are limited to the case of two clusters and therefore impractical in many cases.
",2. Related Work,[0],[0]
"More recently, the authors in (Xiong et al., 2016; Biswas & Jacobs, 2014) improve constrained clustering by modeling which points will be most informative given the current clustering, with state-of-the-art results achieved on numerous datasets by the algorithm in (Xiong et al., 2016), referred to as Uncertainty Reducing Active Spectral Clustering (URASC).",2. Related Work,[0],[0]
"URASC works by maintaining a set of certain sets, whereby points in the same certain set are mustlinked and points in different certain sets are cannot-linked.",2. Related Work,[0],[0]
"A test point xT is selected via an uncertainty-reduction model motivated by matrix perturbation theory, after which queries are presented in an intelligent manner until xT is either matched with an existing certain set or placed in its own new certain set.",2. Related Work,[0],[0]
"In practice (Xiong, 2016), the certain sets are initialized using the EXPLORE algorithm of (Basu et al., 2004).
",2. Related Work,[0],[0]
"While we are certainly not the first to consider actively selecting labels to improve clustering performance, to the best of our knowledge we are the first to do so with structured clusters.",2. Related Work,[0],[0]
"Structure within and between data clusters is often leveraged for unsupervised clustering (Wright et al., 2009), and that structure is also leveraged for adaptive sampling of the structured signals themselves (e.g., see previous work on sparse (Haupt et al., 2011; Indyk et al., 2011), structured sparse (Soni & Haupt, 2014), and low rank signals (Krishnamurthy & Singh, 2013)).",2. Related Work,[0],[0]
"This paper emphasizes the power of that structure for reducing the number of required labels in an active learning algorithm as opposed to reducing the number of samples of the signal itself, and points to exciting open questions regarding the tradeoff between signal measurements and query requirements in semi-supervised clustering.",2. Related Work,[0],[0]
Recall that X = { xi ∈,3. UoS-Based Pairwise-Constrained Clustering,[0],[0]
"RD }N i=1
is a set of data points lying on a union ofK subspaces {Sk}Kk=1, each having dimension d.",3. UoS-Based Pairwise-Constrained Clustering,[0],[0]
"In this work, we assume all subspaces have the same dimension, but it is possible to extend our algorithm to deal with non-uniform dimensions.",3. UoS-Based Pairwise-Constrained Clustering,[0],[0]
"The goal is to cluster the data points according to this generative model, i.e., assigning each data point to its (unknown) subspace.",3. UoS-Based Pairwise-Constrained Clustering,[0],[0]
"In this section we describe our algorithm, which actively selects pairwise constraints in order to improve clustering accuracy.",3. UoS-Based Pairwise-Constrained Clustering,[0],[0]
"The key step is choosing an informative query test point, which we do using a novel notion of minimum subspace margin.
",3. UoS-Based Pairwise-Constrained Clustering,[0],[0]
Denote the true clustering of a point x ∈ X by C(x).,3. UoS-Based Pairwise-Constrained Clustering,[0],[0]
"Let
the output of a clustering algorithm (such as SSC) be an affinity/similarity matrix A and a set of label estimates{ Ĉ(xi) }N i=1
.",3. UoS-Based Pairwise-Constrained Clustering,[0],[0]
These are the inputs to our algorithm.,3. UoS-Based Pairwise-Constrained Clustering,[0],[0]
The high-level operation of our algorithm is as follows.,3. UoS-Based Pairwise-Constrained Clustering,[0],[0]
"To initialize, we build a set of certain sets Z using an EXPLORE-like algorithm similar to that of (Basu et al., 2004).",3. UoS-Based Pairwise-Constrained Clustering,[0],[0]
Certain sets are in some sense equivalent to labels in that points within a certain set belong to the same cluster and points across certain sets belong to different clusters.,3. UoS-Based Pairwise-Constrained Clustering,[0],[0]
"Following this, the following steps are repeated until a maximum number of queries has been made:
1.",3. UoS-Based Pairwise-Constrained Clustering,[0],[0]
Spectral Clustering:,3. UoS-Based Pairwise-Constrained Clustering,[0],[0]
"Obtain label estimates via spectral clustering.
2.",3. UoS-Based Pairwise-Constrained Clustering,[0],[0]
"PCA on each cluster: Obtain a low-dimensional subspace estimate from points currently sharing the same estimated cluster label.
3.",3. UoS-Based Pairwise-Constrained Clustering,[0],[0]
"Select Test Point: Obtain a test point xT using subspace margin with respect to the just estimated subspaces.
",3. UoS-Based Pairwise-Constrained Clustering,[0],[0]
4.,3. UoS-Based Pairwise-Constrained Clustering,[0],[0]
"Assign xT to Certain Set: Query the human to compare the test point with representatives from certain sets until a must-link is found or all certain sets have been queried, in which case the test point becomes its own certain set.
5.",3. UoS-Based Pairwise-Constrained Clustering,[0],[0]
Impute Label Information:,3. UoS-Based Pairwise-Constrained Clustering,[0],[0]
"Certain sets are used to impute must-link and cannot-link values in the affinity matrix.
",3. UoS-Based Pairwise-Constrained Clustering,[0],[0]
We refer to our algorithm as SUPERPAC (SUbsPace clustERing with Pairwise Active Constraints).,3. UoS-Based Pairwise-Constrained Clustering,[0],[0]
"A diagram of the algorithm is given in Fig. 2, and we outline each of these steps below and provide pseudocode in Algorithm 1.",3. UoS-Based Pairwise-Constrained Clustering,[0],[0]
"Min-margin points have been studied extensively in active learning; intuitively, these are points that lie near the decision boundary of the current classifier.",3.1. Sample Selection via Margin,[0],[0]
"In (Settles, 2012), the author notes that actively querying points of minimum margin (as opposed to maximum entropy or minimum confidence) is an appropriate choice for reducing classification error.",3.1. Sample Selection via Margin,[0],[0]
"In (Wang & Singh, 2016), the authors present a margin-based binary classification algorithm that achieves an optimal rate of convergence (within a logarithmic factor).
",3.1. Sample Selection via Margin,[0],[0]
"In this section, we define a novel notion of margin for the UoS model and provide theoretical insight as to why points of minimum margin are likely to be misclustered.",3.1. Sample Selection via Margin,[0],[0]
"For a subspace Sk with orthonormal basis Uk, let the distance of a point to that subspace be dist(x,Sk) =",3.1. Sample Selection via Margin,[0],[0]
miny∈Sk ‖x,3.1. Sample Selection via Margin,[0],[0]
"− y‖2 =
∥∥x− UkUTk x∥∥2 .",3.1. Sample Selection via Margin,[0],[0]
"Let k∗ = arg mink∈[K] dist(x,Sk) be the index of the closest subspace, where [K] = {1, 2, · · · ,K}.",3.1. Sample Selection via Margin,[0],[0]
"Then the subspace
margin of a point x ∈ X is the ratio of closest and second closest subspaces, defined as
µ̂(x) = 1− max j 6=k∗,j∈[K]
dist(x, Sk∗)
",3.1. Sample Selection via Margin,[0],[0]
"dist(x, Sj) .",3.1. Sample Selection via Margin,[0],[0]
"(1)
The point of minimum margin is then defined as arg minx∈X µ̂(x).",3.1. Sample Selection via Margin,[0],[0]
"Note that the fraction is a value in [0, 1], where the a value of 0 implies that the point x is equidistant to its two closest subspaces.",3.1. Sample Selection via Margin,[0],[0]
"This notion is illustrated in Figure 3, where the yellow-green color shows the region within some margin of the decision boundary.
",3.1. Sample Selection via Margin,[0],[0]
"In the following theorem, we show that points lying near the intersection of subspaces are included among those of minimum margin with high probability.",3.1. Sample Selection via Margin,[0],[0]
This method of point selection is then motivated by the fact that the difficult points to cluster are those lying near the intersection of subspaces [12].,3.1. Sample Selection via Margin,[0],[0]
"Further, theory for SSC ([11],[15]) shows that problematic points are those having large inner product with some or all directions in other subspaces.",3.1. Sample Selection via Margin,[0],[0]
Subspace margin captures exactly this phenomenon.,3.1. Sample Selection via Margin,[0],[0]
Theorem 1.,3.1. Sample Selection via Margin,[0],[0]
Consider two d-dimensional subspaces S1 and S2.,3.1. Sample Selection via Margin,[0],[0]
"Let y = x + n, where x ∈ S1 and n ∼ N (0, σ2ID).",3.1. Sample Selection via Margin,[0],[0]
"Define
µ(y) = 1− dist(y,S1) dist(y,S2) .
",3.1. Sample Selection via Margin,[0],[0]
"Then 1− (1 + ε) √ σ2(D − d)
(1− ε) √ σ2(D − d) +",3.1. Sample Selection via Margin,[0],[0]
"dist(x,S2)2 ≤ µ(y)
and µ(y) ≤ 1− (1− ε) √",3.1. Sample Selection via Margin,[0],[0]
"σ2(D − d)
(1 + ε) √",3.1. Sample Selection via Margin,[0],[0]
σ2(D − d) +,3.1. Sample Selection via Margin,[0],[0]
"dist(x,S2)2 ,
with probability at least 1 − 4e−cε2(D−d), where c is an absolute constant.
",3.1. Sample Selection via Margin,[0],[0]
The proof is given in the supplementary material.,3.1. Sample Selection via Margin,[0],[0]
"Note that if dist(y,S1) ≤",3.1. Sample Selection via Margin,[0],[0]
"dist(y,S2), then µ(y) = µ̂(y).",3.1. Sample Selection via Margin,[0],[0]
"In this case, Thm. 1 states that under the given noise model, points with small residual to the incorrect subspace (i.e., points near the intersection of subspaces) will have small margin.",3.1. Sample Selection via Margin,[0],[0]
"These are exactly the points for which supervised label information will be most beneficial.
",3.1. Sample Selection via Margin,[0],[0]
The statement of Thm. 1 allows us to quantify exactly how near a point must be to the intersection of two subspaces to be considered a point of minimum margin.,3.1. Sample Selection via Margin,[0],[0]
Let φ1 ≤ φ2 ≤ · · · ≤ φd be the d principal angles1 between S1 and S2.,3.1. Sample Selection via Margin,[0],[0]
"If the subspaces are very far apart, 1d ∑d i=1",3.1. Sample Selection via Margin,[0],[0]
"sin
2(φi) is near 1, and if they are very close 1d ∑d i=1",3.1. Sample Selection via Margin,[0],[0]
"sin
2(φi) is near zero.",3.1. Sample Selection via Margin,[0],[0]
"Note that, for any x ∈ S1,
sin2(φ1) ≤",3.1. Sample Selection via Margin,[0],[0]
"dist(x,S2)2 ≤ sin2(φd) ;
that is, there are bounds on dist(x,S2) depending on the relationship of the two subspaces.",3.1. Sample Selection via Margin,[0],[0]
"We also know that if x is drawn using isotropic Gaussian weights from a basis for S1, then
E [ dist(x,S2)2 ]",3.1. Sample Selection via Margin,[0],[0]
"= 1
d d∑ i=1",3.1. Sample Selection via Margin,[0],[0]
"sin2(φi) .
",3.1. Sample Selection via Margin,[0],[0]
"Given this, we might imagine that margin of the noisy points is a useful indicator of points near the intersection in a scenario where sin2(φ1) is small but 1d ∑d i=1 sin 2(φi) is not,
1See (Golub & Loan, 2012) for a definition of principal angles.
",3.1. Sample Selection via Margin,[0],[0]
"e.g., when the subspaces have an intersection but are distant in other directions.",3.1. Sample Selection via Margin,[0],[0]
"With this in mind we state the following corollary, whose proof can be found in the supplementary material.
",3.1. Sample Selection via Margin,[0],[0]
Corollary 1.,3.1. Sample Selection via Margin,[0],[0]
"Suppose x1 ∈ S1 is such that
dist(x1,S2)2 = sin2(φ1) + δ",3.1. Sample Selection via Margin,[0],[0]
"( 1
d d∑ i=1",3.1. Sample Selection via Margin,[0],[0]
"sin2(φi)
) (2)
for some small δ ≥ 0; that is, x1 is close to the intersection of S1 and S2.",3.1. Sample Selection via Margin,[0],[0]
"Let x2 be a random point in S1 generated as x2 = U1w where U1 is a basis for S1 and w ∼ N (0, 1dId).",3.1. Sample Selection via Margin,[0],[0]
"We observe yi = xi + ni, where ni ∼ N (0, σ2), i = 1, 2.",3.1. Sample Selection via Margin,[0],[0]
If there exists τ,3.1. Sample Selection via Margin,[0],[0]
"> 1 such that
δ < 5 7",3.1. Sample Selection via Margin,[0],[0]
"− 1 τ
and
τ ( sin2(φ1) + 1
6 σ2 (D − d)
)",3.1. Sample Selection via Margin,[0],[0]
"< 1
d d∑ i=1",3.1. Sample Selection via Margin,[0],[0]
"sin2(φi) , (3)
that is, the average angle is sufficiently larger than the smallest angle, then
P {µ(y1) <",3.1. Sample Selection via Margin,[0],[0]
µ(y2)},3.1. Sample Selection via Margin,[0],[0]
"≥ 1− e−c( 7 100 ) 2 ds − 4e−c( 150 ) 2 (D−d)
where µ(y) is defined as in Thm. 1, c is an absolute constant, and s = 1d ∑d i=1 sin 2(φi).
",3.1. Sample Selection via Margin,[0],[0]
We make some remarks first to connect our results to other subspace distances that are often used.,3.1. Sample Selection via Margin,[0],[0]
Perhaps the most intuitive form of subspace distance between that spanned by U1 and U2 is 1d‖(I,3.1. Sample Selection via Margin,[0],[0]
"− U1U1)TU2‖2F ; if the two subspaces are the same, the projection onto the orthogonal complement is zero; if they are orthogonal, we get the norm of U2 alone, giving a distance of 1.",3.1. Sample Selection via Margin,[0],[0]
"This is equal to the more visually symmetric 1− 1d‖UT1 U2‖2F , another common distance.",3.1. Sample Selection via Margin,[0],[0]
"Further we note that, by the definition of principal angles (Golub & Loan, 2012),
1− 1 d ‖UT1 U2‖2F = 1− 1 d d∑ i=1",3.1. Sample Selection via Margin,[0],[0]
cos2(φi),3.1. Sample Selection via Margin,[0],[0]
= 1 d d∑ i=1,3.1. Sample Selection via Margin,[0],[0]
"sin2(φi) .
",3.1. Sample Selection via Margin,[0],[0]
"From Equation (2), we see that the size of δ determines how close x1 ∈ S1 is to S2; if δ = 0, x1 is as close to S2 as possible.",3.1. Sample Selection via Margin,[0],[0]
"For example, if φ1 = 0, the two subspaces intersect, and δ = 0 implies that x1 ∈ S1 ∩ S2.",3.1. Sample Selection via Margin,[0],[0]
Equation (3) captures the gap between average principal angle and the smallest principal angle.,3.1. Sample Selection via Margin,[0],[0]
"We conclude that if this gap is large enough and δ is small enough so that x1 is close to S2, then the observed y1 will have smaller margin than the average point in S1, even when observed with noise.
",3.1. Sample Selection via Margin,[0],[0]
"Algorithm 1 SUPERPAC Input: X = {x1, x2, . . .",3.1. Sample Selection via Margin,[0],[0]
", xN}: data, K: number of clusters, d: subspace dimension, A: affinity matrix, maxQueries: maximum number of pairwise comparisons Estimate Labels: Ĉ ← SPECTRALCLUSTERING(A,K) Initialize Certain Sets: Initialize Z = {Z1, · · · , Znc} and numQueries via UOS-EXPLORE in supplementary material.",3.1. Sample Selection via Margin,[0],[0]
"while numQueries < maxQueries do
PCA on Each Cluster: Solve
Sk = min U∈RD×d ∑ i:Ĉ(xi)=k ‖xi − UU ′xi‖2 .
",3.1. Sample Selection via Margin,[0],[0]
Obtain Test Point: select xT,3.1. Sample Selection via Margin,[0],[0]
"← arg minx∈X µ̂(x) Assign xT to Certain Set:
Sort {Z1, · · · , Znc} in order of most likely mustlink (via subspace residual for xT ), query xT against representatives from Zk until must-link constraint is found or k = nc.",3.1. Sample Selection via Margin,[0],[0]
"If no must-link constraint is found, set Z ← {Z1, · · · , Znc , {xT }} and increment nc.",3.1. Sample Selection via Margin,[0],[0]
"Impute Constraints: Set Aij = Aji = 1 for (xi, xj) in the same certain set and Aij = Aji = 0 for (xi, xj) in different certain sets (do not impute for points absent from certain sets).",3.1. Sample Selection via Margin,[0],[0]
"Estimate Labels: Ĉ ← SPECTRALCLUSTERING(A,K)
end while
For another perspective, consider that in the noiseless case, for x1, x2 ∈ S1, the condition dist(x1,S2) < dist(x2,S2) is enough to guarantee that x1 lies nearer to S2.",3.1. Sample Selection via Margin,[0],[0]
"Under the given additive noise model (yi = xi + ni for i = 1, 2) the gap between dist(x1,S2) and dist(x2,S2) must be larger by some factor depending on the noise level.",3.1. Sample Selection via Margin,[0],[0]
"After two applications of Thm. 1 and rearranging terms, we have that µ(y1) < µ(y2) with high probability if
βdist(x2,S2)2−dist(x1,S2)2 > (1−β)σ2(D−d).",3.1. Sample Selection via Margin,[0],[0]
"(4)
where β = ((1− ε)/(1 + ε))4, a value near 1 for small ε.",3.1. Sample Selection via Margin,[0],[0]
"Equation (4) shows that the gap dist(x2,S2)2 − dist(x1,S2)2 must grow (approximately linearly) with the noise level σ2.",3.1. Sample Selection via Margin,[0],[0]
The relationship of this gap to the subspace distances is quantified by Corollary 1; plugging sin2(φ1) from Equation (2) into Equation (3) and rearranging yields a statement of the form in Equation (4).,3.1. Sample Selection via Margin,[0],[0]
"We now describe SUPERPAC in more detail, our algorithm for PCC when data lie near a union of subspaces, given in Algorithm 1.",3.2. Pairwise Constrained Clustering with SUPERPAC,[0],[0]
"The algorithm begins by initializing a set of disjoint certain sets, an optional process described in the
supplementary material due to space constraints.",3.2. Pairwise Constrained Clustering with SUPERPAC,[0],[0]
Next our algorithm assigns the points most likely to be misclassified to certain sets by presenting a series of pairwise comparisons.,3.2. Pairwise Constrained Clustering with SUPERPAC,[0],[0]
"Finally, we impute values onto the affinity matrix for all points in the certain sets and perform spectral clustering.",3.2. Pairwise Constrained Clustering with SUPERPAC,[0],[0]
"The process is then repeated until the maximum number of pairwise comparisons has been reached.
",3.2. Pairwise Constrained Clustering with SUPERPAC,[0],[0]
Let xT be the test point chosen as the min-margin point.,3.2. Pairwise Constrained Clustering with SUPERPAC,[0],[0]
Our goal is to assign xT to a certain set using as the fewest number of queries possible.,3.2. Pairwise Constrained Clustering with SUPERPAC,[0],[0]
"For each certain set Zk, the representative xk is chosen as the maximum-margin point within the set.",3.2. Pairwise Constrained Clustering with SUPERPAC,[0],[0]
"Next, for each k, we let Uk be the ddimensional PCA estimate of the matrix whose columns are the points { x ∈ X",3.2. Pairwise Constrained Clustering with SUPERPAC,[0],[0]
:,3.2. Pairwise Constrained Clustering with SUPERPAC,[0],[0]
Ĉ(x) = Ĉ(xk) } .,3.2. Pairwise Constrained Clustering with SUPERPAC,[0],[0]
"We then query
our test point xT against the representatives xk in order of residual ∥∥xT − UkUTk xT∥∥2",3.2. Pairwise Constrained Clustering with SUPERPAC,[0],[0]
(smallest first).,3.2. Pairwise Constrained Clustering with SUPERPAC,[0],[0]
"If a must-link constraint is found, we place xT in the corresponding certain set.",3.2. Pairwise Constrained Clustering with SUPERPAC,[0],[0]
"Otherwise, we place xT in its own certain set and update the number of certain sets.",3.2. Pairwise Constrained Clustering with SUPERPAC,[0],[0]
Pseudocode for the complete algorithm is given in Algorithm 1.,3.2. Pairwise Constrained Clustering with SUPERPAC,[0],[0]
"As a technical note, we first normalize the input affinity matrix A so that the maximum value is 2.",3.2. Pairwise Constrained Clustering with SUPERPAC,[0],[0]
"For must-link constraints, we impute a value of 1 in the affinity matrix, while for cannot-link constraints we impute a 0.",3.2. Pairwise Constrained Clustering with SUPERPAC,[0],[0]
The approach of imputing values in the affinity matrix is common in the literature but does not strictly enforce the constraints.,3.2. Pairwise Constrained Clustering with SUPERPAC,[0],[0]
"Further, we found in our experiments that imputing the maximum value in the affinity matrix resulted in unstable results.",3.2. Pairwise Constrained Clustering with SUPERPAC,[0],[0]
"Thus, users must be careful to not only choose the correct constraints as noted in (Basu et al., 2004), but to incorporate these constraints in a way that allows for robust clustering.
",3.2. Pairwise Constrained Clustering with SUPERPAC,[0],[0]
"SUPERPAC can be thought of as an extension of ideas from PCC literature (Basu et al., 2004; Biswas & Jacobs, 2014; Xiong et al., 2016) to leverage prior knowledge about the underlying geometry of the data.",3.2. Pairwise Constrained Clustering with SUPERPAC,[0],[0]
"For datasets such as Yale B and MNIST, the strong subspace structure makes Euclidean distance a poor proxy for similarity between points in the same cluster, leading to the superior performance of our algorithm demonstrated in the following sections.",3.2. Pairwise Constrained Clustering with SUPERPAC,[0],[0]
"This
structure does not exist in all datasets, in which case we do not expect our algorithm to outperform current PCC algorithms.",3.2. Pairwise Constrained Clustering with SUPERPAC,[0],[0]
"The reader will note we made a choice to order the certain sets according to the UoS model; this is similar to the choice in (Xiong et al., 2016) to query according to similarity, where our notion of similarity here is based on subspace distances.",3.2. Pairwise Constrained Clustering with SUPERPAC,[0],[0]
"We found this resulted in significant performance benefits, matching our intuition that points are clustered based on their nearest subspace.",3.2. Pairwise Constrained Clustering with SUPERPAC,[0],[0]
"In contrast to (Biswas & Jacobs, 2014; Xiong et al., 2016), where the test point is chosen according to a global improvement metric, we choose test points according to their classification margin.",3.2. Pairwise Constrained Clustering with SUPERPAC,[0],[0]
"In our experiments, we found subspace margin to be a strong indicator of which points are misclassified, meaning that our algorithm rapidly corrects the errors that occur as a result of unsupervised subspace clustering.
",3.2. Pairwise Constrained Clustering with SUPERPAC,[0],[0]
"Finally, note that the use of certain sets relies on the assumption that the pairwise queries are answered correctly—an assumption that is common in the literature (Basu et al., 2004; Mallapragada et al., 2008; Xiong et al., 2016).",3.2. Pairwise Constrained Clustering with SUPERPAC,[0],[0]
"However, in (Xiong et al., 2016), the authors demonstrate that an algorithm based on certain sets still yields significant improvements under a small error rate.",3.2. Pairwise Constrained Clustering with SUPERPAC,[0],[0]
The study of robustly incorporating noisy pairwise comparisons is an interesting topic for further study.,3.2. Pairwise Constrained Clustering with SUPERPAC,[0],[0]
We compare the performance of our method and the nonparametric version of the URASC algorithm (URASC-N)2 over a variety of datasets.,4. Experimental Results,[0],[0]
"Note that while numerous PCC algorithms exist, URASC achieves both the best empirical results and computational complexity on a variety of datasets.",4. Experimental Results,[0],[0]
"We also compared with the methods from (Basu et al., 2004) and (Biswas & Jacobs, 2014) but found both to perform significanly worse than URASC on all datasets considered, with a far greater computational cost in the case
2In our experiments, the parametric version of URASC was found to be numerically unstable and did not have significantly different performance from URASC-N in the best cases.
of (Biswas & Jacobs, 2014).",4. Experimental Results,[0],[0]
We use a maximum query budget of 2K for UOS-EXPLORE and EXPLORE.,4. Experimental Results,[0],[0]
"For completeness, we also compare to random constraints, in which queries are chosen uniformly at random from the set of unqueried pairs.
",4. Experimental Results,[0],[0]
"Finally, we compare against the oracle PCA classifier, which we now define.",4. Experimental Results,[0],[0]
Let Uk be the d-dimensional PCA estimate of the points whose true label C(x) =,4. Experimental Results,[0],[0]
"k. Then the oracle label is Ĉo(x) = arg mink∈[K]
∥∥x− UkUTk",4. Experimental Results,[0],[0]
x∥∥2.,4. Experimental Results,[0],[0]
"This allows us to quantitatively capture the idea that, because the true classes are not perfectly low-rank, some points would not be clustered with the low-rank approximation of their own true cluster.",4. Experimental Results,[0],[0]
"In our experiments, we also compared with oracle robust PCA (Candes et al., 2011) implemented via the augmented Lagrange multiplier method (Lin et al., 2011) but did not find any improvement in classification error.
",4. Experimental Results,[0],[0]
"Datasets We consider five datasets commonly used as benchmarks in the subspace clustering literature3, with a summary of the datasets and their relevant parameters are given in Table 1.",4. Experimental Results,[0],[0]
The Yale B dataset consists of 64 images of size 192 × 168 of each of 38 different subjects under a variety of lighting conditions.,4. Experimental Results,[0],[0]
"For values of K less than 38, we follow the methodology of (Zhang et al., 2012) and perform clustering on 100 randomly selected subsets of size K. We choose d = 9 as is common in the literature (Elhamifar & Vidal, 2013; Heckel & Bölcskei, 2015).",4. Experimental Results,[0],[0]
"The MNIST handwritten digit database test dataset consists of 10,000 centered 28 × 28 pixel images of handwritten digits 0-9.",4. Experimental Results,[0],[0]
"We follow a similar methodology to the previous section and select 100 random subsets of size K, using subspace dimension d = 3 as in (Heckel & Bölcskei, 2015).",4. Experimental Results,[0],[0]
"The COIL-20 dataset (Nene et al., 1996b) consists of 72 images
3The validity of the UoS assumption for two of these datasets is investigated in (Elhamifar & Vidal, 2013; Heckel & Bölcskei, 2015).
of size 32× 32 of each of 20 objects.",4. Experimental Results,[0],[0]
"The COIL-100 dataset (Nene et al., 1996a) contains 100 objects (distinct from the COIL-20 objects) of the same size and with the same number of images of each object.",4. Experimental Results,[0],[0]
"For both datasets, we use subspace dimension d = 9.",4. Experimental Results,[0],[0]
"Finally, we apply our algorithm to the USPS dataset provided by (Cai et al., 2011), which contains 9,298 total images of handwritten digits 0-9 of size 16 × 16 with roughly even label distribution.",4. Experimental Results,[0],[0]
"We again use subspace dimension d = 9.
",4. Experimental Results,[0],[0]
Input Subspace Clustering Algorithms,4. Experimental Results,[0],[0]
A major strength of our algorithm is that it is agnostic to the initial subspace clustering algorithm used to generate the input affinity matrix.,4. Experimental Results,[0],[0]
"To demonstrate this fact, we apply our algorithm with an input affinity matrix obtained from a variety of subspace clustering methods, summarized in Table 1.",4. Experimental Results,[0],[0]
Note that some recent algorithms are not included in the simulations here.,4. Experimental Results,[0],[0]
"However, the simulations show that our algorithm works well with any initial clustering, and hence we expect similar results as new algorithms are developed.
",4. Experimental Results,[0],[0]
Experimental Results Fig. 4 shows the clustering error versus the number of pairwise comparisons for the Yale and MNIST datasets.,4. Experimental Results,[0],[0]
The input affinity matrix is obtained by running SSC for the Yale datset and by running TSC for the MNIST dataset.,4. Experimental Results,[0],[0]
"The figure clearly demonstrates the benefits of leveraging UoS structure in constrained clustering—in all cases, SUPERPAC requires roughly half the number of queries needed by URASC to achieve perfect clustering.",4. Experimental Results,[0],[0]
"For the Yale dataset with K = 5, roughly 2Kd queries are required to surpass oracle performance, and for K = 10 roughly 3Kd queries are required.",4. Experimental Results,[0],[0]
"Note that for the Yale dataset, the clustering error increases using URASC.",4. Experimental Results,[0],[0]
This is due to the previously mentioned fact that imputing the wrong constraints can lead to worse clustering performance.,4. Experimental Results,[0],[0]
"For sufficiently many queries, the error decreases as expected.",4. Experimental Results,[0],[0]
"Fig. 5 shows the misclassification rate versus number of points for allK = 38 subjects of the Yale databse, with the input affinity matrix taken from SSC-OMP (You et al., 2016b).",4. Experimental Results,[0],[0]
We space out the markers for clearer plots.,4. Experimental Results,[0],[0]
"In this case, URASC performs roughly the same as random query selection, while SUPERPAC performs significantly
better.
",4. Experimental Results,[0],[0]
Fig. 6 demonstrates the continued superiority of our algorithm in the case where UoS structure exists.,4. Experimental Results,[0],[0]
"In the case of COIL-20, the clustering is sometimes unstable, alternating between roughly 0% and 7% clustering error for both active algorithms.",4. Experimental Results,[0],[0]
This further demonstrates the observed phenomenon that spectral clustering is sensitive to small perturbations.,4. Experimental Results,[0],[0]
"To avoid this issue, we kept track of the K-subspaces cost function (see (Bradley & Mangasarian, 2000)) and ensured the cost decreased at every iteration.",4. Experimental Results,[0],[0]
We refer to this added heuristic as SUPERPAC-S in the figure.,4. Experimental Results,[0],[0]
"The incorporation of this heuristic into our algorithm is a topic for further study.
",4. Experimental Results,[0],[0]
"Fig. 7 shows the resulting error on the USPS dataset, again indicating the superiority of our method.",4. Experimental Results,[0],[0]
"Note that N is large for this dataset, making spectral clustering computationally burdensome.",4. Experimental Results,[0],[0]
"Further, the computational complexity of URASC is dependent on N .",4. Experimental Results,[0],[0]
"As a result, URASC did not complete 2000 queries in 48 hours of run time when using 10 cores, so we compare to the result after completing only 1000 queries.",4. Experimental Results,[0],[0]
"Finally, in Fig. 8, we demonstrate that even on data without natural subspace structure, SUPERPAC performs competitively with URASC.",4. Experimental Results,[0],[0]
We have presented a method of selecting and incorporating pairwise constraints into subspace clustering that considers the underlying geometric structure of the problem.,5. Conclusion,[0],[0]
The union of subspaces model is often used in computer vision applications where it is possible to request input from human labelers in the form of pairwise constraints.,5. Conclusion,[0],[0]
"We showed that labeling is often necessary for subspace classifiers to achieve a clustering error near zero; additionally, these constraints can be chosen intelligently to improve the clustering procedure overall and allow for perfect clustering with a modest number of requests for human input.
",5. Conclusion,[0],[0]
Developing techniques for handling noisy query responses will allow extension to undersampled or compressed data.,5. Conclusion,[0],[0]
"One may assume that compressed data would be harder to distinguish, leading to noisier query responses.",5. Conclusion,[0],[0]
"Finally, we saw that for datasets with different types of cluster structure, the structure assumptions of each algorithm had direct impact on performance; in the future we plan to additionally develop techniques for learning from unlabeled data whether the union of subspace model or a standard clustering approach is more appropriate.",5. Conclusion,[0],[0]
This work was supported by NSF F031543-071159-GRFP and US ARO Grant W911NF1410634.,Acknowledgements,[0],[0]
"Many clustering problems in computer vision and other contexts are also classification problems, where each cluster shares a meaningful label.",abstractText,[0],[0]
"Subspace clustering algorithms in particular are often applied to problems that fit this description, for example with face images or handwritten digits.",abstractText,[0],[0]
"While it is straightforward to request human input on these datasets, our goal is to reduce this input as much as possible.",abstractText,[0],[0]
We present a pairwiseconstrained clustering algorithm that actively selects queries based on the union-of-subspaces model.,abstractText,[0],[0]
"The central step of the algorithm is in querying points of minimum margin between estimated subspaces; analogous to classifier margin, these lie near the decision boundary.",abstractText,[0],[0]
We prove that points lying near the intersection of subspaces are points with low margin.,abstractText,[0],[0]
Our procedure can be used after any subspace clustering algorithm that outputs an affinity matrix.,abstractText,[0],[0]
We demonstrate on several datasets that our algorithm drives the clustering error down considerably faster than the stateof-the-art active query algorithms on datasets with subspace structure and is competitive on other datasets.,abstractText,[0],[0]
Leveraging Union of Subspace Structure to Improve Constrained Clustering,title,[0],[0]
"Analyzing high dimensional, high volume data can be timeconsuming and resource intensive.",1. Introduction,[0],[0]
"Core data analysis, such as robust instances of regression, involve convex optimization tasks over large matrices, and do not naturally distribute or parallelize.",1. Introduction,[0],[0]
"In response to this, approximation algorithms have been proposed which follow a “sketch and solve” paradigm: produce a reduced size representation of the data, and solve a version of the problem on this summary (Woodruff, 2014).",1. Introduction,[0],[0]
It is then argued that the solution on the reduced data provides an approximation to the original problem on the original data.,1. Introduction,[0],[0]
"This paradigm is particularly attractive when the summarization can be computed efficiently on partial views of the full data—for example, when it can be computed incrementally as the data arrives (streaming model) or assembled from summarizations of disjoint partitions of the data (distributed model) (Woodruff, 2014; Agarwal et al., 2012; Feldman et al., 2006).",1. Introduction,[0],[0]
"This
*Equal contribution 1Department of Computer Science, University of Warwick, Coventry, UK 2School of Computer Science, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA.",1. Introduction,[0],[0]
"Correspondence to: Charlie Dickens <c.dickens@warwick.ac.uk>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"template has been instantiated for a number of fundamental tasks in high dimensional linear algebra such as matrix multiplication, low rank approximation, and regression.
",1. Introduction,[0],[0]
"Our understanding is well-established in the common case of the Euclidean norm, i.e., when distances are measured under the Minkowski p-norm for p = 2.",1. Introduction,[0],[0]
"Here, it suffices to choose a sketching matrix independent of the data—where each entry is i.i.d.",1. Introduction,[0],[0]
"Gaussian, Rademacher, or more efficient variants of these.",1. Introduction,[0],[0]
"For other p values, less is known, but these are often needed to handle limitations of the 2-norm.",1. Introduction,[0],[0]
"For instance, p = 1 is widely used as it is extremely robust with respect to the presence of outliers while p > 2 can be used to detect outlying observations.
",1. Introduction,[0],[0]
We continue the study of algorithms for `p norms on streaming and distributed data.,1. Introduction,[0],[0]
"A particular novelty of our results is that unlike previous distributed and streaming algorithms, they can all be implemented deterministically, i.e., our algorithms make no random choices.",1. Introduction,[0],[0]
"While in a number of settings randomized algorithms are highly beneficial, leading to massive computational savings, there are other applications which require extremely high reliability, for which one needs to obtain guaranteed performance across a large number of inputs.",1. Introduction,[0],[0]
"If one were to use a randomized algorithm, then it would need vanishingly small error probability; however, many celebrated algorithms in numerical linear algebra succeed with only constant probability.",1. Introduction,[0],[0]
"Another limitation of randomized algorithms was shown in (Hardt & Woodruff, 2013): if the input to a randomized sketch depends on the output of a preceding algorithm using the same sketch, then the randomized sketch can give an arbitrarily bad answer.",1. Introduction,[0],[0]
"Hence, such methods cannot handle adaptively chosen inputs.",1. Introduction,[0],[0]
"Thus, while randomized algorithms certainly have their place, the issues of high reliability and adaptivity motivate the development of deterministic methods for a number of other settings, for which algorithms are scarce.
",1. Introduction,[0],[0]
"Our techniques can be viewed as a conceptual generalization of Liberty’s Frequent Directions (in the 2-norm) (Liberty, 2013), which progressively computes an SVD on subsequent blocks of the input.",1. Introduction,[0],[0]
"This line of work (Liberty, 2013; Ghashami & Phillips, 2014; Ghashami et al., 2016; Ghashami et al., 2016) is the notable exception in numerical linear algebra, as it provides deterministic methods,
although all such methods are specific to the 2-norm.",1. Introduction,[0],[0]
"Our core algorithm is similar in nature, but we require a very different technical analysis to argue that the basis transformation computed preserves the shape in the target p-norm.
",1. Introduction,[0],[0]
Our main application is to show how high dimensional regression and low rank approximation problems can be solved approximately and deterministically in the sketch and solve paradigm.,1. Introduction,[0],[0]
The core of the summary is to find rows of the original matrix which have high leverage scores.,1. Introduction,[0],[0]
"That is, they contain a lot of information about the shape of the data.",1. Introduction,[0],[0]
"In the Euclidean norm, leverage scores correspond directly to row norms of an orthonormal basis.",1. Introduction,[0],[0]
"This is less straightforward for other `p norms, where the scores correspond to the row norms of so-called `p-well-conditioned bases.",1. Introduction,[0],[0]
"Moreover, while leverage scores are often used for sampling in randomized algorithms, we use them here in the context of fully deterministic algorithms.
",1. Introduction,[0],[0]
"We show how a superset of rows with high leverage scores can be found for arbitrary `p norms, based on only local information.",1. Introduction,[0],[0]
"This leads to efficient algorithms which identify rows with high (local) leverage scores within subsets of the data, and proceed hierarchically to collect a sufficient set of rows.",1. Introduction,[0],[0]
"These rows then allow us to solve regression problems: essentially, we solve the regression problem corresponding to just the retained input rows.",1. Introduction,[0],[0]
We apply this technique to `p-regression and entrywise `p-low rank approximation.,1. Introduction,[0],[0]
"In particular, we use it to solve the `∞-regression problem with additive error in a stream.",1. Introduction,[0],[0]
"Note that the `∞ problem reduces to finding a ball of minimum radius which covers the data, and global solutions are slow due to the need to solve a linear program.",1. Introduction,[0],[0]
"Instead, we show that only a subset of the data needs to be retained in the streaming model to compute accurate approximations.",1. Introduction,[0],[0]
"Given the relationship between the streaming model and the distributed model that we later define, this could be seen in the context of having data stored over multiple machines who could send ‘important’ rows of their data to a central coordinator in order to compute the approximation.
",1. Introduction,[0],[0]
Summary of Results.,1. Introduction,[0],[0]
"All our algorithms are deterministic polynomial time, and use significantly sublinear memory or communication in streaming and distributed models, respectively.",1. Introduction,[0],[0]
We consider tall and thin n× d matrices A for overconstrained regression so one should think of n,1. Introduction,[0],[0]
d. We implement both deterministic and randomized variants of our algorithms.,1. Introduction,[0],[0]
Section 3 presents an algorithm which returns rows of high ‘importance’ in a data matrix with additive error.,1. Introduction,[0],[0]
This follows by storing a polynomial number (in d) of rows and using these to compute a well-conditioned basis.,1. Introduction,[0],[0]
"The key insight here is that rows of high norm in the full wellconditioned basis cannot have their norm decrease too much in a well-conditioned basis associated with a subblock; in
fact they remain large up to a multiplicative poly(d) factor.",1. Introduction,[0],[0]
Section 4 gives a method for computing a so-called `psubspace embedding of a data matrix in polynomial time.,1. Introduction,[0],[0]
"The space is nγ to obtain dO(1/γ) distortion, for γ ∈ (0, 1) a small constant.",1. Introduction,[0],[0]
This result is then applied to `p-regression which is shown to have a poly(d) approximation factor with the same amount of space.,1. Introduction,[0],[0]
Section 5 describes a deterministic algorithm which gives a poly(k)-approximation to the optimal low rank approximation problem in entrywise `1-norm.,1. Introduction,[0],[0]
It runs in polynomial time for constant k.,1. Introduction,[0],[0]
"This method builds on prior work by derandomizing a subroutine from (Song et al., 2017).",1. Introduction,[0],[0]
"Section 6 describes an algorithm for computing an additiveerror solution to the `∞-regression problem, and shows a corresponding lower bound, showing that relative error solutions in this norm are not possible in sublinear space, even for randomized algorithms.",1. Introduction,[0],[0]
Section 7 concludes with an empirical evaluation.,1. Introduction,[0],[0]
"More experiments, intermediate results, and formal proofs can be found in the Supplementary Material, as can results on approximate matrix multiplication.
",1. Introduction,[0],[0]
Comparison to Related Work.,1. Introduction,[0],[0]
There is a rich literature on algorithms for numerical linear algebra in general p-norms; most of which are randomized with the notable exception of Frequent Directions.,1. Introduction,[0],[0]
"The key contributions of our work for each of the problems considered and its relation to prior work is as follows:
Finding high leverage rows: our algorithm is a single pass streaming algorithm and uses small space.",1. Introduction,[0],[0]
We show that the global property of `p-leverage scores can be understood by considering only local statistics.,1. Introduction,[0],[0]
Frequent Directions is the only comparable result to ours and outputs a summary of the rows only in the `2-norm.,1. Introduction,[0],[0]
"However, our method covers all p ≥ 1.",1. Introduction,[0],[0]
"Theorem 3.3 is the key result and is later used to prove Theorem 6.1 and approximate the `∞-regression problem.
",1. Introduction,[0],[0]
"Subspace embedding, regression and `1 low-rank approximation: various approaches using row-sampling (Cohen & Peng, 2015; Dasgupta et al., 2008), and data oblivious methods such as low-distortion embeddings can solve regression in time proportional to the sparsity of the input matrix (Clarkson et al., 2013; Meng & Mahoney, 2013; Song et al., 2017; Woodruff & Zhang, 2013).",1. Introduction,[0],[0]
"However, despite the attractive running times and error guarantees of these works, they are all randomized and do not necessarily translate well to the streaming model of computation.",1. Introduction,[0],[0]
Our contribution here is a fully deterministic algorithm that works for all p ≥ 1 in both streaming and distributed models.,1. Introduction,[0],[0]
"Randomized methods for `1 low-rank approximation have also been developed in (Song et al., 2017) and our result exploits a derandomized subroutine from this work to obtain a deterministic result which applies in both models.",1. Introduction,[0],[0]
"We consider computing `p-leverage scores of a matrix, lowrank approximation, regression, and matrix multiplication.",2. Preliminaries and Notation,[0],[0]
We assume the input is a matrix A ∈ Rn×d and,2. Preliminaries and Notation,[0],[0]
n d so rank(A) ≤ d and the regression problems are overconstrained.,2. Preliminaries and Notation,[0],[0]
Without loss of generality we may assume that the columns of the input matrix are linearly independent so that rank(A) =,2. Preliminaries and Notation,[0],[0]
"d. Throughout this paper we rely heavily on the notion of a well-conditioned basis for the column space of an input matrix, in the context of the entrywise p-norm which is ‖A‖p = ( ∑ i,j |Aij |p)1/",2. Preliminaries and Notation,[0],[0]
p. Definition 2.1 (Well-conditioned basis).,2. Preliminaries and Notation,[0],[0]
Let A ∈ Rn×d have rank d. For p ∈,2. Preliminaries and Notation,[0],[0]
"[1,∞) let q = pp−1 be its dual norm.",2. Preliminaries and Notation,[0],[0]
"An n× d matrix U is an (α, β, p)-well-conditioned basis for A if the column span of U is equal to that of A, ‖U‖p",2. Preliminaries and Notation,[0],[0]
"≤ α, for all z ∈ Rd, ‖z‖q ≤ β‖Uz‖p , and α, β, dO(1) are independent of n",2. Preliminaries and Notation,[0],[0]
"(Dasgupta et al., 2008).
",2. Preliminaries and Notation,[0],[0]
We focus on the cases p < 2 and p > 2 because the deterministic p = 2 case is relatively straightforward.,2. Preliminaries and Notation,[0],[0]
"Indeed, for p = 2, ATA can be maintained incrementally as rows are added, allowing xTATAx to be computed for any vector x.",2. Preliminaries and Notation,[0],[0]
So it is possible to find an exact `2 subspace embedding using O(d2) space in a stream and O(ndω−1) time (ω is the matrix multiplication constant).,2. Preliminaries and Notation,[0],[0]
"We adopt the convention that when p = 1 we take q =∞. Theorem 2.2 ((Dasgupta et al., 2008)).",2. Preliminaries and Notation,[0],[0]
"Let A be an n× d matrix of rank d, let p ∈",2. Preliminaries and Notation,[0],[0]
"[1,∞)",2. Preliminaries and Notation,[0],[0]
and let q be its dual norm.,2. Preliminaries and Notation,[0],[0]
"There exists an (α, β, p)-well-conditioned basis U for the column space of A such that:
1.",2. Preliminaries and Notation,[0],[0]
"if p < 2 then α = d 1 p+ 1 2 and β = 1, 2.",2. Preliminaries and Notation,[0],[0]
"if p = 2 then α = √ d and β = 1, and 3.",2. Preliminaries and Notation,[0],[0]
if p > 2,2. Preliminaries and Notation,[0],[0]
"then α = d 1 p+ 1 2 and β = d 1 p− 12 .
",2. Preliminaries and Notation,[0],[0]
"Moreover,U can be computed in deterministic timeO(nd2+ nd5 log n) for p 6= 2 and O(nd2) if p = 2.
",2. Preliminaries and Notation,[0],[0]
"We freely use the fact that a well-conditioned basis U = AR can be efficiently computed for the given data matrix A. Details for the computation can be found in (Dasgupta et al., 2008) but this is done by computing a change of basis R such that U = AR is well-conditioned.",2. Preliminaries and Notation,[0],[0]
"Similarly, as R can be inverted we have the relation that UR−1 = A.",2. Preliminaries and Notation,[0],[0]
Both methods are used so we adopt the convention that U = AR when writing a well-conditioned basis in terms of the input and US = A for the input in terms of the basis.,2. Preliminaries and Notation,[0],[0]
Our algorithms operate under the streaming and distributed models of computation.,2.1. Computation Models,[0],[0]
In both settings an algorithm receives as input a matrix A ∈ Rn×d.,2.1. Computation Models,[0],[0]
"For a problem P, the
algorithm must keep a subset of the rows of A and, upon reading the full input, may use a black-box solver to compute an approximate solution to P with only the subset of rows stored.",2.1. Computation Models,[0],[0]
"In both models we measure the summary size (storage), the update time which is the time taken to find the local summary, and the query time which is the time taken to compute an approximation to P using the summary.
",2.1. Computation Models,[0],[0]
The Streaming Model: The rows of A are given to the (centralized) algorithm one-by-one.,2.1. Computation Models,[0],[0]
Let b be the maximum number of rows that can be stored under the constraint that b is sublinear in n.,2.1. Computation Models,[0],[0]
The stored subset is used to compute local statistics which determine those rows to be kept or discarded from the stored set.,2.1. Computation Models,[0],[0]
Further rows are then appended and the process is repeated until the full matrix has been read.,2.1. Computation Models,[0],[0]
"An approximation to the problem is then computed by solving P on the reduced subset of rows.
",2.1. Computation Models,[0],[0]
The Distributed Summary Model:,2.1. Computation Models,[0],[0]
"Given a small constant γ ∈ (0, 1), the input in the form of matrix A ∈ Rn×d is partitioned into blocks among distributed compute nodes so that no block exceeds nγ rows.",2.1. Computation Models,[0],[0]
The computation then follows a tree structure: the initial blocks of the matrix form n1−γ leaves of the compute tree.,2.1. Computation Models,[0],[0]
Each internal node merges and reduces its input from its child nodes.,2.1. Computation Models,[0],[0]
"The first phase is for the leaf nodes l1, . . .",2.1. Computation Models,[0],[0]
", lm of the tree to reduce their input by computing a local summary on the block they receive as input.",2.1. Computation Models,[0],[0]
"This is then sent to parent nodes p1, . . .",2.1. Computation Models,[0],[0]
", pm which merge and reduce the received rows until the space bound is reached.",2.1. Computation Models,[0],[0]
"The resulting summaries are passed up the tree until we reach the root where a single summary of bounded size is obtained which can be used to compute an approximation to P. In total, there are O(1/γ) levels in the tree.",2.1. Computation Models,[0],[0]
"As the methods require only light synchronization (compute summary and return to coordinator), we do not model implementation issues relating to synchronization.",2.1. Computation Models,[0],[0]
Remark 2.3.,2.1. Computation Models,[0],[0]
"The two models are quite close: the streaming model can be seen as a special case of the distributed model with only one participant who individually computes a summary, appends rows to the stored set, and reduces the new summary.",2.1. Computation Models,[0],[0]
"This is represented as a deep binary tree, where each internal node has one leaf child.",2.1. Computation Models,[0],[0]
"Likewise, the Distributed Summary Model can be implemented in a full streaming fashion over the entire binary tree.",2.1. Computation Models,[0],[0]
The experiments in Section 7 perform one round of merge-and-reduce in the distributed model to simulate the streaming approach.,2.1. Computation Models,[0],[0]
This section is concerned with finding rows of high leverage from a matrix with respect to various p-norms.,3. Finding Rows of High Leverage,[0],[0]
We conclude the section with an algorithm that returns rows of high leverage up to polynomial additive error.,3. Finding Rows of High Leverage,[0],[0]
Definition 3.1.,3. Finding Rows of High Leverage,[0],[0]
"Let R be a change of basis matrix such that AR is a well-conditioned basis for the column space of A.
The (full) `p-leverage scores are defined as wi = ‖eTi AR‖pp.
Note that wi depends both on A and the choice of R, but we suppress this dependence in our notation.",3. Finding Rows of High Leverage,[0],[0]
Next we present some basic facts about the `p leverage scores.,3. Finding Rows of High Leverage,[0],[0]
Fact 1.,3. Finding Rows of High Leverage,[0],[0]
"By Definition 2.1 we have ∑ i wi =∑
i ‖(AR)i‖pp ≤ αp.",3. Finding Rows of High Leverage,[0],[0]
Theorem 2.2 shows α = poly(d).,3. Finding Rows of High Leverage,[0],[0]
Define I,3. Finding Rows of High Leverage,[0],[0]
= {i ∈,3. Finding Rows of High Leverage,[0],[0]
"[n] : wi > τ‖AR‖pp} to be the index set of all rows whose `p leverage exceeds a τ fraction of ‖AR‖pp, then: αp ≥ ∑ i wi ≥ ∑ i∈I wi ≥ |I| · τ‖AR‖pp.",3. Finding Rows of High Leverage,[0],[0]
"Hence, |I| ≤ αp/τ‖AR‖pp = poly(d)/τ .",3. Finding Rows of High Leverage,[0],[0]
So there are at most poly(d)/τ rows i for which wi ≥ τ‖AR‖pp.,3. Finding Rows of High Leverage,[0],[0]
Fact 2.,3. Finding Rows of High Leverage,[0],[0]
Definition 2.1 and Hölder’s inequality show that for any vector x we have |(ARx)i|p ≤ β‖eTi,3. Finding Rows of High Leverage,[0],[0]
AR‖pp · ‖ARx‖pp.,3. Finding Rows of High Leverage,[0],[0]
Then τ ≤ |eTi ARx|p/‖ARx‖pp ≤ βwi.,3. Finding Rows of High Leverage,[0],[0]
From this we deduce that if a row contributes at least a τ fraction of ‖ARx‖pp then τ ≤ wiβ.,3. Finding Rows of High Leverage,[0],[0]
"That is, τ ≤ wi for p ∈",3. Finding Rows of High Leverage,[0],[0]
"[1, 2] and τ ≤ d1/2wi for p ∈ (2,∞) by using Theorem 2.2.",3. Finding Rows of High Leverage,[0],[0]
Definition 3.2.,3. Finding Rows of High Leverage,[0],[0]
Let X be a matrix and Y be a subset of the rows of X .,3. Finding Rows of High Leverage,[0],[0]
"Define the local `p-leverage scores of Y with respect to X to be the leverage scores of rows Y found by computing a well-conditioned basis for Y rather than the whole matrix X .
",3. Finding Rows of High Leverage,[0],[0]
A key technical insight to proving Theorem 3.3 below is that rows of high leverage globally can be found by repeatedly finding rows of local high leverage.,3. Finding Rows of High Leverage,[0],[0]
"While relative `p row norms of a submatrix are at least as large as the full relative `p norms, it is not guaranteed that this property holds for leverage scores.",3. Finding Rows of High Leverage,[0],[0]
This is because leverage scores are calculated from a well-conditioned basis for a matrix which need not be a well-conditioned basis for a block.,3. Finding Rows of High Leverage,[0],[0]
"However, we show that local `p leverage scores restricted to a coordinate subspace of a matrix basis do not decrease too much when compared to leverage scores in the original space.",3. Finding Rows of High Leverage,[0],[0]
Let i be a row in A with local leverage score ŵi and global leverage score wi.,3. Finding Rows of High Leverage,[0],[0]
Then ŵi ≥ wi/ poly(d).,3. Finding Rows of High Leverage,[0],[0]
"The proof relies heavily on properties of the well-conditioned basis and details are given in the Supplementary Material, Lemma A.1.",3. Finding Rows of High Leverage,[0],[0]
"This lemma shows that local leverage scores can potentially drop in arbitrary `p norm, contrasting the behavior in `2.",3. Finding Rows of High Leverage,[0],[0]
"However, it is possible to find all rows exceeding a threshold globally by altering the local threshold.",3. Finding Rows of High Leverage,[0],[0]
"That is, to find all wi > τ",3. Finding Rows of High Leverage,[0],[0]
globally we can find all local leverage scores exceeding an adjusted threshold ŵi > τ/poly(d) to obtain a superset of all rows which exceed the global threshold.,3. Finding Rows of High Leverage,[0],[0]
"The price to pay for this is a poly(d) increase in space cost which, importantly, remains sublinear in n.",3. Finding Rows of High Leverage,[0],[0]
"Hence, we can gradually prune out rows of small leverage and keep only the most important rows of a matrix.",3. Finding Rows of High Leverage,[0],[0]
"Combining Lemmas A.1 and A.2 we can present the main theorem of the section.
",3. Finding Rows of High Leverage,[0],[0]
"We prove Theorem 3.3 by arguing the correctness of Algorithm 1 which reads A once only, row by row, and so
operates in the streaming model of computation as follows.",3. Finding Rows of High Leverage,[0],[0]
Let A′ be the submatrix of A induced by the b block of poly(d)/τ rows.,3. Finding Rows of High Leverage,[0],[0]
"Upon storing A′, we compute U , a local well-conditioned basis for A′ and the local leverage scores with respect to U , ŵi(U) are calculated.",3. Finding Rows of High Leverage,[0],[0]
"Now, the local and global leverage scores can be related by Lemma A.1 as wi/poly(d) ≤",3. Finding Rows of High Leverage,[0],[0]
ŵi so we can decide which rows to keep using an adjusted threshold.,3. Finding Rows of High Leverage,[0],[0]
Any i for which the local leverage exceeds the adjusted threshold is kept in the sample and all other rows are deleted.,3. Finding Rows of High Leverage,[0],[0]
The sample cannot be too large by properties of the well-conditioned basis and leverage scores so these kept rows can be appended to the next block which is read in before computing another well-conditioned basis and repeating in the same fashion.,3. Finding Rows of High Leverage,[0],[0]
The proof of Theorem 3.3 is deferred to Appendix A. Theorem 3.3.,3. Finding Rows of High Leverage,[0],[0]
Let τ > 0 be a fixed constant and let b denote a bound on the available space.,3. Finding Rows of High Leverage,[0],[0]
"There exists a deterministic algorithm, namely, Algorithm 1, which computes the `p-leverage scores of a matrix A ∈ Rn×d with O(bd2 + bd5 log b) update time, poly(d) space, and returns all rows of A with `p leverage score satisfying wi ≥ τ/ poly(d).
4.",3. Finding Rows of High Leverage,[0],[0]
`p-Subspace Embeddings,3. Finding Rows of High Leverage,[0],[0]
Under the assumptions of the Distributed Summary Model we present an algorithm which computes an `p-subspace embedding.,3. Finding Rows of High Leverage,[0],[0]
"By extension, this applies to both the distributed and streaming models of computation as described in Section 2.1.",3. Finding Rows of High Leverage,[0],[0]
Two operations are needed for this model of computation: the merge and reduce steps.,3. Finding Rows of High Leverage,[0],[0]
To reduce the input at each level a summary is computed by taking a block of input B (corresponding to a leaf node or a node higher up the tree) and computing a well-conditioned basis B = US.,3. Finding Rows of High Leverage,[0],[0]
"In particular, the summary is now the matrix S with U and B deleted.",3. Finding Rows of High Leverage,[0],[0]
"For the merge step, successive matrices S are concatenated until the space requirement is met.",3. Finding Rows of High Leverage,[0],[0]
A further reduce step takes as input this concatenated matrix and the process is repeated.,3. Finding Rows of High Leverage,[0],[0]
"Further details, pseudocode, and proofs for this section are given in Appendix B. Definition 4.1.",3. Finding Rows of High Leverage,[0],[0]
"A matrix T is a relative error (c1, c2)-`p subspace embedding for the column space of a matrix A ∈ Rn×d",3. Finding Rows of High Leverage,[0],[0]
"if there are constants c1, c2 > 0",3. Finding Rows of High Leverage,[0],[0]
"so that for all x ∈ Rd, c1‖Ax‖p ≤ ‖Tx‖p ≤ c2‖Ax‖p.",3. Finding Rows of High Leverage,[0],[0]
Theorem 4.2.,3. Finding Rows of High Leverage,[0],[0]
"Let A ∈ Rn×d, p 6= 2,∞ be fixed and fix a constant γ ∈ (0, 1).",3. Finding Rows of High Leverage,[0],[0]
"Then there exists a one-pass deterministic algorithm which constructs a (1/dO(1/γ), 1) relative error `p-subspace embedding in with O(nγd2 +nγd5 log nγ) update time and O(nγd) space in the streaming and distributed models of computation.
",3. Finding Rows of High Leverage,[0],[0]
"The algorithm is used in a tree structure as follows: split inputA ∈ Rn×d into n1−γ blocks of size nγ , these form the leaves of the tree.",3. Finding Rows of High Leverage,[0],[0]
"For each block, a well-conditioned basis is
computed and the change of basis matrix S ∈ Rd×d is stored and passed to the next level of the tree.",3. Finding Rows of High Leverage,[0],[0]
This is repeated until the concatenation of all the S matrices would exceed nγ .,3. Finding Rows of High Leverage,[0],[0]
"At this point, the concatenated S matrices form the parent node of the leaves in the tree and the process is repeated upon this node: this is the merge and reduce step of the algorithm.",3. Finding Rows of High Leverage,[0],[0]
"At every iteration of the merge-and-reduce steps it can be shown that a distortion of 1/d is introduced by using the summaries S. However, this can be controlled across all of the O(1/γ) levels in the tree to give a deterministic relative error `p subspace embedding which requires only sublinear space and little communication.",3. Finding Rows of High Leverage,[0],[0]
"In addition, the subspace embedding can be used to achieve a deterministic relativeerror approximate regression result.",3. Finding Rows of High Leverage,[0],[0]
"The proof relies upon analyzing the merge-and-reduce behaviour across all nodes of the tree.
",3. Finding Rows of High Leverage,[0],[0]
`p-Regression Problem:,3. Finding Rows of High Leverage,[0],[0]
"Given matrix A ∈ Rn×d and target vector b ∈ Rn, find x̂ = argminx ‖Ax− b‖p.",3. Finding Rows of High Leverage,[0],[0]
Theorem 4.3.,3. Finding Rows of High Leverage,[0],[0]
"Let A ∈ Rn×d, b ∈ Rn, fix p 6= 2,∞ and a constant γ > 0.",3. Finding Rows of High Leverage,[0],[0]
The `p-regression problem can be solved deterministically in the streaming and distributed models with a (d + 1)O(1/γ) = poly(d) relative error approximation factor.,3. Finding Rows of High Leverage,[0],[0]
The update time is poly(nγ(d + 1)) and O((1/γ)nγ(d + 1)) storage.,3. Finding Rows of High Leverage,[0],[0]
The query time is poly(nγ) for the cost of convex optimization.,3. Finding Rows of High Leverage,[0],[0]
`1-Low-Rank Approximation Problem:,5. Low-Rank Approximation,[0],[0]
"Given matrix A ∈ Rn×d output a matrix B of rank k s.t., for constant k:
‖A−B‖1 ≤ poly(k) min A′:rankk ‖A−A′‖1.",5. Low-Rank Approximation,[0],[0]
"(1)
Theorem 5.1.",5. Low-Rank Approximation,[0],[0]
Let A ∈ Rn×d be the given data matrix and k be the (constant) target rank.,5. Low-Rank Approximation,[0],[0]
Let γ > 0 be an arbitrary (small) constant.,5. Low-Rank Approximation,[0],[0]
"Then there exists a deterministic distributed and streaming algorithm (namely Algorithm 5 in Appendix C) which can output a solution to
the `1-Low Rank Approximation Problem with relative error poly(k) approximation factor, update time poly(n, d), space bounded by nγpoly(d), and query time poly(n, d).
",5. Low-Rank Approximation,[0],[0]
The key technique is similar to that of the previous section by using a tree structure with merge-and-reduce operations.,5. Low-Rank Approximation,[0],[0]
For input A ∈ Rn×d and constant γ > 0 partition A into n1−γ groups of rows which form the leaves of the tree.,5. Low-Rank Approximation,[0],[0]
"The tree is defined as previously with the same ‘merge’ operation, but the ‘reduce’ step to summarize the data exploits a derandomization (subroutine Algorithm 4) of (Song et al., 2017) to compute an approximation to the optimal `1-lowrank approximation.",5. Low-Rank Approximation,[0],[0]
"Once this is computed, k of the rows in the summary are kept for later merge steps.
",5. Low-Rank Approximation,[0],[0]
This process is continued with the successive k rows from nγ rows being ‘merged’ or added to the matrix until it has nγ rows.,5. Low-Rank Approximation,[0],[0]
"The process is repeated across all of the groups in the level and again on the successive levels on the tree from which it can be shown that the error does not propagate too much over the tree, thus giving the desired result.",5. Low-Rank Approximation,[0],[0]
Here we present a method for solving `∞-regression in a streaming fashion.,6. Application: `∞-Regression,[0],[0]
"Given input A and a target vector b, it is possible to achieve additive approximation error of the form ε‖b‖p for arbitrarily large p.",6. Application: `∞-Regression,[0],[0]
This contrasts with both Theorems 4.2 and 4.3 which achieve a relative error poly(d) approximation.,6. Application: `∞-Regression,[0],[0]
Both of these theorems require that p is constant and not equal to the ∞-norm.,6. Application: `∞-Regression,[0],[0]
This restriction is due to a lower bound for `∞- regression showing that it cannot be approximated with relative error in sublinear space.,6. Application: `∞-Regression,[0],[0]
"The key to proving Theorem 6.1 below is using Theorem 3.3 to find high leverage rows and arguing that these are sufficient to give the claimed error guarantee.
",6. Application: `∞-Regression,[0],[0]
The `∞-regression problem has been previously studied in the overdetermined case and can naturally be applied to curve-fitting under this norm.,6. Application: `∞-Regression,[0],[0]
"`∞-regression can be solved
by linear programming (Sposito, 1976) and such a transformation allows the identification of outliers in the data.",6. Application: `∞-Regression,[0],[0]
"Also, if the errors are known to be distributed uniformly across an interval then `∞-regression estimator is the maximumlikelihood parameter choice (Hand, 1978).",6. Application: `∞-Regression,[0],[0]
The same work argues that such uniform distributions on the errors often arise as round-off errors in industrial applications whereby the error is controlled or is small relative to the signal.,6. Application: `∞-Regression,[0],[0]
"There are further applications such as using `∞-regression to remove outliers prior to `2 regression in order to make the problem more robust (Shen et al., 2014).",6. Application: `∞-Regression,[0],[0]
By applying `∞ regression on subsets of the data an approximation to the Least Median of Squares (another robust form of regression) can be found.,6. Application: `∞-Regression,[0],[0]
"We now define the problem and proceed to show that it is possible to compute an approximate solution with additive error in `p-norm for arbitrarily large p.
Approximate `∞-Regression problem:",6. Application: `∞-Regression,[0],[0]
"Given data A ∈ Rn×d, target vector b ∈ Rn, and error parameter ε > 0, compute an additive ε‖b‖p error solution to:
min x∈Rd ‖Ax− b‖∞ = min x∈Rd",6. Application: `∞-Regression,[0],[0]
"[ max i |(Ax)i − bi| ] .
",6. Application: `∞-Regression,[0],[0]
Theorem 6.1.,6. Application: `∞-Regression,[0],[0]
"Let A ∈ Rn×d, b ∈ Rn and fix constants p ≥ 1, ε > 0 with p 6=∞. There exists a one-pass deterministic streaming algorithm which solves the `∞-regression problem up to an additive ε‖b‖p error in dO(p)/εO(1) space, O(md5 + md2 logm) update time and Tsolve(m, d) query time.
",6. Application: `∞-Regression,[0],[0]
"Note that Tsolve(m, d) query time is the time taken to solve the linear program associated with the above problem on a reduced instance size.",6. Application: `∞-Regression,[0],[0]
"Also, observe that Theorem 6.1 requires p < ∞.",6. Application: `∞-Regression,[0],[0]
This restriction is necessary to forbid relative error with respect to the infinity norm.,6. Application: `∞-Regression,[0],[0]
"Indeed, p can be an arbitrarily large constant, but for p = ∞ we can look for rows above an ε/poly(d) threshold in the case when A is an all-ones column n-vector (so an n× 1 matrix).",6. Application: `∞-Regression,[0],[0]
Then ‖Ax‖∞ = ‖x‖∞ since x is a scalar.,6. Application: `∞-Regression,[0],[0]
"Also, A is a wellconditioned basis for its own column span but the number of rows of leverage exceeding ε/poly(d) = ε is n for a small constant ε.",6. Application: `∞-Regression,[0],[0]
"This intuition allows us to prove the following theorem.
",6. Application: `∞-Regression,[0],[0]
Theorem 6.2.,6. Application: `∞-Regression,[0],[0]
"Any algorithm which outputs an ε‖b‖∞ relative error solution to the `∞-regression problem requires min { n, 2Ω(d) } space.",6. Application: `∞-Regression,[0],[0]
"To validate our approach, we evaluate the use of high `p-leverage rows in order to approximate `∞-regression1, focusing particularly on the cases using `1 and `2 well-
1Code available at https://github.com/c-dickens/ stream-summaries-high-lev-rows
conditioned bases.",7. Experimental Evaluation,[0],[0]
It is straightforward to model `∞- regression as a linear program in the offline setting.,7. Experimental Evaluation,[0],[0]
We use this to measure the accuracy of our algorithm.,7. Experimental Evaluation,[0],[0]
"The implementation is carried out in the single pass streaming model with a fixed space constraint, m, and threshold, αp/m for both conditioning methods to ensure the number of rows kept in the summary did not exceed m. Recall from Remark 2.3 that the single-pass streaming implementation is equivalent to the distributed model with only one participant applying merge-and-reduce, so this experiment can also be seen as a distributed computation with the merge step being the appending of new rows and the reduce step being the thresholding in the new well-conditioned basis.
",7. Experimental Evaluation,[0],[0]
Methods.,7. Experimental Evaluation,[0],[0]
We analyze two instantiations of our methods based on how we find a well-conditioned basis and repeat over 5 independent trials with random permutations of the data.,7. Experimental Evaluation,[0],[0]
"The methods are as follows:
SPC3: We use an algorithm of Yang et al. (2013) to compute an `1-wcb.",7. Experimental Evaluation,[0],[0]
"This method is randomized as it employs the Sparse Cauchy Transform and is only an `1-wellconditioned basis with constant probability We also implemented a check condition which showed that almost always, roughly 99% of the time, the randomized construction SPC3 would return a (d2.5, 1, 1)-well-conditioned basis.",7. Experimental Evaluation,[0],[0]
"Thus, we bypassed this check in our experiment to ensure quick update times.
",7. Experimental Evaluation,[0],[0]
Orth:,7. Experimental Evaluation,[0],[0]
"In addition, we also used an orthonormal basis using the QR decomposition which is an `2-wcb.",7. Experimental Evaluation,[0],[0]
"This method is fully deterministic and outputs a ( √ d, 1, 2)-well- conditioned basis.
",7. Experimental Evaluation,[0],[0]
"Sample: A sample of the data is chosen uniformly at random and the retained summary has size exactly m.
Identity: No conditioning is performed.",7. Experimental Evaluation,[0],[0]
"For a block B of the input, the surrogate scores wi(B) =",7. Experimental Evaluation,[0],[0]
‖eTi B‖22/‖B‖2F are used to determine which rows to keep.,7. Experimental Evaluation,[0],[0]
"As the sum of these wi(B) is 1, we keep all rows which have wi(B) > 2/m. Since no more than m/2 of the rows can satisfy wi(B)",7. Experimental Evaluation,[0],[0]
"> 2/m, the size of the stored subset of rows can be controlled and cannot grow too large.
",7. Experimental Evaluation,[0],[0]
Remark 7.1.,7. Experimental Evaluation,[0],[0]
The Identity method keeps only the rows with high norm which contrasts our conditioning approach: if most of the mass of the block is concentrated on a few rows then these will appear heavy locally despite the possibility that they may correspond to previously seen or unimportant directions.,7. Experimental Evaluation,[0],[0]
"In particular, if these heavy rows significantly outweigh the weight of some sparse directions in the data it is likely that the sparse directions will not be found at all.",7. Experimental Evaluation,[0],[0]
"For instance, consider data X ∈ Rn×d which is then augmented by appending the identity (and zeros) so that these are the only vectors in the new directions.",7. Experimental Evaluation,[0],[0]
"That is, set X ′ =",7. Experimental Evaluation,[0],[0]
"[X,0n×k;0k×d, Ik×k] and then
permute the rows of X ′. The appended sparse vectors from Ik×k will have leverage of 1 so will be detected by the wellconditioned basis methods.",7. Experimental Evaluation,[0],[0]
However there is no guarantee that the Identity method will identify these directions if the entries in X significantly outweigh those in Ik×k.,7. Experimental Evaluation,[0],[0]
"In addition, there is also no guarantee that using uniform sampling will identify these points, particularly when k is small compared to n and d.",7. Experimental Evaluation,[0],[0]
"So while choosing to do no conditioning seems attractive, this example shows that doing so may not give any meaningful guarantees and hence we prefer the approach in Section 3.",7. Experimental Evaluation,[0],[0]
"We compare only to these baselines as we are not aware of any other competing methods in the small memory regime for the `∞-regression problem.
Datasets.",7. Experimental Evaluation,[0],[0]
"We tested the methods on a subset of the US Census Data containing 5 million rows and 11 columns2 and YearPredictionMSD3 which has roughly 500,000 rows and 90 columns (although we focus on a fixed 50,000 row sample so that the LP for regression is tractable: see Figure 4c in the Supplementary Material, Appendix F).",7. Experimental Evaluation,[0],[0]
"For the census dataset, space constraints between 50,000 and 500,000 rows were tested and for the YearPredictionsMSD data space budgets were tested between 2,500 and 25,000.",7. Experimental Evaluation,[0],[0]
"The general behavior is roughly the same for both datasets so for brevity we primarily show the results for US Census Data, and defer corresponding plots for YearPredictionsMSD to Appendix F.
Results on approximation error compared to storage Let f∗ denote the minimal value of the full regression obtained by x∗ and let x′ be the output of the reduced problem.",7. Experimental Evaluation,[0],[0]
The approximate solution to the full problem is then f̂ = ‖Ax′,7. Experimental Evaluation,[0],[0]
− b‖∞ and approximation error is measured as f̂/f∗ − 1 (note that f̂ ≥ f∗).,7. Experimental Evaluation,[0],[0]
An error closer to 0 demonstrates that f̂ is roughly the same as f∗ so the optimal value is well-approximated.,7. Experimental Evaluation,[0],[0]
Figures 2a and 2b show that on both datasets the Identity method consistently performs poorly while Sample achieves comparable accuracy to the conditioning methods.,7. Experimental Evaluation,[0],[0]
"Despite the simplicity of uniform sampling to keep a summary, the succeeding sections discuss the increased time and space costs of using such a sample and show that doing so is not favourable.",7. Experimental Evaluation,[0],[0]
"Thus, neither of the baseline methods output a summary which can be used to approximate the regression problem both accurately and quickly, hence justifying our use of leverage scores.",7. Experimental Evaluation,[0],[0]
"Our conditioning methods perform particularly well in the US Census Data data (Figure 2a) with Orth appearing to give the most accurate summary and SPC3 performing comparably well but with slightly more fluctuation: similar behaviour is observed in the YearPredictionMSD
2http://www.census.gov/census2000/PUMS5.",7. Experimental Evaluation,[0],[0]
"html
3https://archive.ics.uci.edu/ml/datasets/ yearpredictionmsd
(Figure 2b) data too.",7. Experimental Evaluation,[0],[0]
"The conditioning methods are also seen to be robust to the storage constraint, give accurate performance across both datasets using significantly less storage than sampling, and give a better estimate in general than doing no conditioning.
",7. Experimental Evaluation,[0],[0]
Results on Space Complexity.,7. Experimental Evaluation,[0],[0]
"Recall that the space constraint is m rows and throughout the stream, after a local computation, the merge step concatenates more rows to the existing summary until the bound m is met, prior to computing the next reduction.",7. Experimental Evaluation,[0],[0]
"During the initialization of the block A′ by Algorithm 1, the number of stored rows is exactly m.",7. Experimental Evaluation,[0],[0]
"However, we measure the maximum number of rows kept in a summary after every reduction step to understand how large the returned summary can grow.",7. Experimental Evaluation,[0],[0]
"As seen in Figure 2c, Identity keeps the smallest summary but there is no reason to expect it has kept the most important rows.",7. Experimental Evaluation,[0],[0]
"In contrast, if m is the bound on the summary size, then uniform sampling always returns a summary of size exactly m. However, we see that this is not optimal as both conditioning methods can return a set of rows which are pruned at every iteration to roughly half the size and contains only the most important rows in that block.",7. Experimental Evaluation,[0],[0]
Both conditioning methods exhibit similar behavior and are bounded between both Sample and Identity methods.,7. Experimental Evaluation,[0],[0]
"Therefore, both of the conditioning methods respect the theoretical bound and, crucially, return a summary which is sublinear in the space constraint and hence a significantly smaller fraction of the input size.
Results on Time Complexity.",7. Experimental Evaluation,[0],[0]
There are three time costs measured.,7. Experimental Evaluation,[0],[0]
The first is the update time taken to compute the local well-conditioned basis which is theoretically O(md2 +md5 logm) by Theorem 2.2.,7. Experimental Evaluation,[0],[0]
"However, the two bases that we test are an orthonormal basis, computable in time O(md2) and the SPC3 transform which takes time O(nnz(B) logm) for a block B with m rows and nnz(B) non-zero entries.",7. Experimental Evaluation,[0],[0]
Figure 3a demonstrates that SPC3 is faster than Orth on this data in practice but this small absolute difference becomes negligible over the entirety of the stream as seen in Figure 3c.,7. Experimental Evaluation,[0],[0]
The query time in Figure 3b is roughly proportional to the summary size in all instances but here the conditioning methods perform noticeably better due to the smaller summary size that is returned as discussed in the previous section.,7. Experimental Evaluation,[0],[0]
"However, as seen in Figure 4c, (Supplementary Material, Appendix F ) this disparity becomes hugely significant on higher dimensionality data due to the increased size summary retained by sampling, further justifying our approach of pruning rows at every stage.",7. Experimental Evaluation,[0],[0]
"While Identity appears to have fast query time, this is due to the summary being smaller.",7. Experimental Evaluation,[0],[0]
"Although it may seem that for smaller summaries more local bases need to be computed and this time could prohibitively increase over the stream, Figure 3c demonstrates that even using small blocks does not cause the overall time (to process the stream and pro-
duce an approximate query) to increase too much.",7. Experimental Evaluation,[0],[0]
"Hence, an approximation can be obtained which is highly accurate, and in total time faster than the brute force solver.
",7. Experimental Evaluation,[0],[0]
Experimental Summary.,7. Experimental Evaluation,[0],[0]
"While it might seem attractive not to perform any conditioning on the matrix and just pick heavy rows, our experiments show that this strategy is not effective in practice, and delivers poor accuracy.",7. Experimental Evaluation,[0],[0]
"Although a simple sample of randomly chosen rows can be easily maintained, this appears less useful due to the increased time costs associated with larger summaries when conditioning methods output a similar estimate in less time over the entire stream.",7. Experimental Evaluation,[0],[0]
As the `∞-regression problems depend only on a few rows of the data there are cases when uniform sampling can perform well: if many of the critical rows look similar then there is a chance that uniform sampling will select some examples.,7. Experimental Evaluation,[0],[0]
"In this case, the leverage of the important direction is divided across the repetitions, and so it is harder to ensure that desired direction is identified.",7. Experimental Evaluation,[0],[0]
Despite this potential drawback we have shown that both Orth and SPC3 can be used to find accurate summaries which perform robustly across each of the measures we have tested.,7. Experimental Evaluation,[0],[0]
"It appears that SPC3 performs comparably
to Orth; both are relatively quick to compute and admit accurate summaries in similar space.",7. Experimental Evaluation,[0],[0]
"In particular, both conditioning methods return summaries which are a fraction of the space budget and hence highly sublinear in the input size, which give accurate approximations and are robust to the concatenation of new rows.",7. Experimental Evaluation,[0],[0]
"All of these factors make the conditioning method fast in practice to both find the important rows in the data and then compute the reduced regression problem with high accuracy.
",7. Experimental Evaluation,[0],[0]
"Due to the problems in constructing summaries which can be used to solve regression quickly and accurately when using random sampling or no transformation, our methods are shown to be efficient and accurate alternatives.",7. Experimental Evaluation,[0],[0]
Our approach is vindicated both theoretically and practically: this is most clear in the U.S. Census dataset where small error can be achieved using a summary roughly 2% the size of the data.,7. Experimental Evaluation,[0],[0]
This also results in an overall speedup as solving the optimization on the reduced set is much faster than solving on the full problem.,7. Experimental Evaluation,[0],[0]
Such significant savings show that this general approach can be useful in large-scale applications.,7. Experimental Evaluation,[0],[0]
The work of G. Cormode and C. Dickens is supported by European Research Council grant ERC-2014-CoG 647557 and The Alan Turing Institute under the EPSRC grant EP/N510129/1.,Acknowledgements,[0],[0]
D. Woodruff would like to acknowledge the support by the National Science Foundation under Grant No.,Acknowledgements,[0],[0]
CCF-1815840.,Acknowledgements,[0],[0]
"Work on approximate linear algebra has led to efficient distributed and streaming algorithms for problems such as approximate matrix multiplication, low rank approximation, and regression, primarily for the Euclidean norm `2.",abstractText,[0],[0]
"We study other `p norms, which are more robust for p < 2, and can be used to find outliers for p > 2.",abstractText,[0],[0]
"Unlike previous algorithms for such norms, we give algorithms that are (1) deterministic, (2) work simultaneously for every p ≥ 1, including p =∞, and (3) can be implemented in both distributed and streaming environments.",abstractText,[0],[0]
"We apply our results to `p-regression, entrywise `1-low rank approximation, and approximate matrix multiplication.",abstractText,[0],[0]
Leveraging Well-Conditioned Bases: Streaming and Distributed Summaries in Minkowski p-Norms,title,[0],[0]
"Proceedings of the SIGDIAL 2017 Conference, pages 50–59, Saarbrücken, Germany, 15-17 August 2017. c©2017 Association for Computational Linguistics",text,[0],[0]
"Much attention has recently been paid to non-task-oriented dialogue systems —or chatoriented dialogue systems— both in research (Higashinaka et al., 2014; Yu et al., 2016) and in industry.",1 Introduction,[0],[0]
"In addition to pure chat-oriented systems, some task-oriented dialogue systems can engage in chat-oriented dialogues (Lee et al., 2009; Dingli and Scerri, 2013; Kobori et al., 2016; Papaioannou and Lemon, 2017) because such dialogues are expected to build rapport (Bickmore and Picard, 2005) between users and systems.",1 Introduction,[0],[0]
"For simplicity, we will call any system that can engage in chat-oriented dialogue a chat-
bot.",1 Introduction,[0],[0]
"Since an open-domain chatbot that always generates appropriate utterances is still difficult to build (Higashinaka et al., 2015), we think it is worth building a closed-domain chatbot, which tries to continue dialogues in a specific domain.
",1 Introduction,[0],[0]
"One problem in building closed-domain chatbots is that, although they should preferably have comprehensive lexical knowledge in their domains, all the knowledge cannot realistically be prepared in advance.",1 Introduction,[0],[0]
"Therefore, we must consider the case where a user uses terms outside of the system’s vocabulary1, i.e. terms that have ontological categories the system does not know.",1 Introduction,[0],[0]
"If the system can acquire the term’s category during dialogues, it will be able to interact with users more naturally and the cost of expanding its knowledge base will be reduced.
",1 Introduction,[0],[0]
We call the problem of acquiring the category of an unknown term lexical acquisition.,1 Introduction,[0],[0]
"If the system can predict the category of an unknown term, it can ask the user if it is correct (Otsuka et al., 2013; Komatani et al., 2016).",1 Introduction,[0],[0]
"However, repeating such explicit confirmation requests can degrade the user experience in chat-oriented dialogues2.",1 Introduction,[0],[0]
We therefore need to find a way to enable chatbots to: (1) interact with the user naturally and (2) acquire lexical information.,1 Introduction,[0],[0]
"To solve this dilemma, we proposed an approach using implicit confirmation (Ono et al., 2016), where the system makes a confirmation request about the predicted category and uses the user’s response to decide if the category is correct or not.",1 Introduction,[0],[0]
"However, whether such an approach is really possible or not has not been well studied.
",1 Introduction,[0],[0]
"This paper proposes a method that utilizes im-
1Here, we use term to mean an expression denoting an entity that can be in the knowledge base.",1 Introduction,[0],[0]
"A term may consist of multiple words.
",1 Introduction,[0],[0]
2Some typical examples will be shown in Section 2.,1 Introduction,[0],[0]
"We will verify this intuition by conducting a user study.
50
plicit confirmation dialogues from multiple users to increase the accuracy for determining if the predicted category is correct or not3.",1 Introduction,[0],[0]
The system estimates the confidence score that the category prediction is correct from the responses of multiple users to the same implicit confirmation requests (Figure 1: right).,1 Introduction,[0],[0]
Our proposed method has the goal of improving the confidence score estimation by using implicit confirmation sub-dialogues with multiple users.,1 Introduction,[0],[0]
Then the system can determine if it should add the lexical information to the system’s knowledge.,1 Introduction,[0],[0]
"For a sub-task, we consider the problem of estimating how likely the predicted category is to be correct from implicit confirmation sub-dialogues with one user (Figure 1: left).
",1 Introduction,[0],[0]
It is reasonable to assume that the system can make confirmation requests about the same unknown term with different users because chatbots typically run on servers so they can share interaction logs for different users.,1 Introduction,[0],[0]
"Furthermore, it is difficult to ask a single user to respond to confirmation requests with the same predicted category many times, so collecting responses from multiple users is desirable.
",1 Introduction,[0],[0]
This paper is organized as follows.,1 Introduction,[0],[0]
The problem settings and related work are discussed in the next two sections.,1 Introduction,[0],[0]
Section 4 describes the proposed method to determine correct categories in implicit confirmation requests on the basis of multiple implicit confirmation sub-dialogues with different users.,1 Introduction,[0],[0]
"Sections 5 and 6 show the data collection by crowdsourcing and several results as preparation for the main experimental evaluation of the proposed method, which is detailed in Section 7.",1 Introduction,[0],[0]
"Section 8 concludes this paper and discusses future work.
",1 Introduction,[0],[0]
"3We do not deal with multi-party dialogues but utilize the interaction logs of two-party dialogues with different users.
",1 Introduction,[0],[0]
"(a) explicit, correct",1 Introduction,[0],[0]
This section describes the problem we address in this paper in detail.,2 Problem Setting,[0],[0]
"We are building a closeddomain Japanese language chatbot targeting the food and restaurant domain, so we use examples in this domain throughout this paper.",2 Problem Setting,[0],[0]
"In this domain, the problem is to acquire the categories of foods that the system does not know.",2 Problem Setting,[0],[0]
"We assume that the system can identify a food name in the user’s input even if it is not in the system’s vocabulary by using methods such as named entity recognition (Mesnil et al., 2015).",2 Problem Setting,[0],[0]
"Note that in this paper we also assume the category of an unknown term is predicted with an existing method (Otsuka et al., 2013; Ono et al., 2016).",2 Problem Setting,[0],[0]
"We do not assume any ontological structure of foods.
",2 Problem Setting,[0],[0]
This paper focuses on deciding if the predicted category of unknown terms is correct or not in dialogues.,2 Problem Setting,[0],[0]
"To this end, methods for generating explicit confirmation have been proposed.",2 Problem Setting,[0],[0]
Otsuka et al. (2013) proposed lexical acquisition methods that explicitly ask the user questions on the basis of category prediction results.,2 Problem Setting,[0],[0]
"For example, if the system does not know nasi goreng in the user input (denote as U1) in Figure 2 (a), the system predicts its category as Indonesian food and asks the user “Is nasi goreng Indonesian?”4 Komatani et al. (2016) also proposed a utilitybased method for selecting appropriate questions
4Note that Figures 2 through 4 show artificial examples, rather than those excerpted from the experimental data described in Section 5 because the experimental data are in Japanese and their direct translations are not natural.
",2 Problem Setting,[0],[0]
"(a) implicit, correct",2 Problem Setting,[0],[0]
on the basis of the results of category prediction.,U1: Philly cheesesteaks have a lot of,[0],[0]
"However, such explicit confirmation requests can degrade the user experience in chat-oriented dialogues, especially when the predicted category is incorrect as in Figure 2 (b), or the category of the unknown term is obvious as in Figure 2 (c).
",U1: Philly cheesesteaks have a lot of,[0],[0]
"We have proposed using implicit confirmation (Ono et al., 2016).",U1: Philly cheesesteaks have a lot of,[0],[0]
"For example, S1 in Figure 3 (a) does not explicitly ask the user if the category of tempura soba is Japanese, but from U2, it is possible to determine the category is correct.",U1: Philly cheesesteaks have a lot of,[0],[0]
"As another example, in Figure 3 (b), the system can determine the predicted category is incorrect from U2.
",U1: Philly cheesesteaks have a lot of,[0],[0]
"Determining if the predicted category is correct or not in implicit confirmation, however, is not always easy.",U1: Philly cheesesteaks have a lot of,[0],[0]
"Since user responses to implicit confirmation requests can come in various forms, looking at just the linguistic expressions of the user responses is not enough.",U1: Philly cheesesteaks have a lot of,[0],[0]
"For example, in Figure 4, the system incorrectly predicts the category Japanese food for Pandoro mentioned in U1 although it is Italian and generates an implicit confirmation request, S1.",U1: Philly cheesesteaks have a lot of,[0],[0]
The user then talks about Japanese food to continue the dialogue (U2).,U1: Philly cheesesteaks have a lot of,[0],[0]
"In
such cases, it is not simple to determine if the category is incorrect.",U1: Philly cheesesteaks have a lot of,[0],[0]
"If the system’s determination is wrong, it might add incorrect information to its database.",U1: Philly cheesesteaks have a lot of,[0],[0]
"Thus, we need to find a way to accurately determine the correctness of the predicted categories through implicit confirmation.",U1: Philly cheesesteaks have a lot of,[0],[0]
"So far, several studies have addressed lexical acquisition in dialogues.",3 Related Work,[0],[0]
Meng et al. (2004) and Takahashi et al. (2002) proposed methods for predicting the categories of unknown terms.,3 Related Work,[0],[0]
"They acquire coarse categories for unknown terms, which roughly correspond to named entity categories.",3 Related Work,[0],[0]
Those categories can be acquired more easily than the more specific categories that we are trying to acquire.,3 Related Work,[0],[0]
Holzapfel et al. (2008) proposed a method for a robot to acquire fine-grained categories for unknown terms by iteratively asking questions.,3 Related Work,[0],[0]
We do not think this method is suitable for chatbots as it repeats explicit questions.,3 Related Work,[0],[0]
"Whereas a previous study tried to acquire relationships among domain-dependent entities in dialogues (Pappu and Rudnicky, 2014), here we focus on acquiring lexical information, which is required before such relations are obtained.
",3 Related Work,[0],[0]
We address the problem of deciding if the content of an implicit confirmation request is correct or not.,3 Related Work,[0],[0]
Some studies related to this problem have tried to classify affirmative and negative sentences by using rules or statistical methods.,3 Related Work,[0],[0]
"For example, de Marneffe et al. (2009) built rules for judging if a response to a yes/no question is affirmative or negative when it is not a simple “yes” or “no.” Gokcen and de Marneffe (2015)",3 Related Work,[0],[0]
investigated features for detecting disagreement in the corpus of arguments on the Web.,3 Related Work,[0],[0]
"In contrast, in this paper, we do not try to classify user responses into affirmative and negative ones but try to determine whether a category in an implicit confirmation request is correct or not.",3 Related Work,[0],[0]
"Furthermore, we utilize multiple sub-dialogues with different users.
",3 Related Work,[0],[0]
"Our method can be considered as an instance of implicitly supervised learning (Banerjee and Rudnicky, 2007; Komatani and Rudnicky, 2009) in that user responses to implicit confirmation requests are used as indicators for acquisition, though the target knowledge is different from those works.",3 Related Work,[0],[0]
The purpose of our method is to prevent the system from learning incorrect categories for an unknown term by using multiple implicit confirmation subdialogues with different users.,4 Determining Correct Categories Using Responses from Multiple Users,[0],[0]
This is possible because our system is designed as a server-based dialogue system and can give implicit confirmation requests with the same predicted category to different users.,4 Determining Correct Categories Using Responses from Multiple Users,[0],[0]
"The proposed method determines more accurately whether or not the predicted category in the implicit confirmation request is correct by exploiting multiple responses to them.
",4 Determining Correct Categories Using Responses from Multiple Users,[0],[0]
"Let pi(w, c) be the probability that a predicted category c of an unknown term w is correct after a single implicit confirmation request.",4 Determining Correct Categories Using Responses from Multiple Users,[0],[0]
"The category can be predicted using surface information of the unknown term such as character n-gram and character types in Japanese (Otsuka et al., 2013).",4 Determining Correct Categories Using Responses from Multiple Users,[0],[0]
The index i denotes the i-th response to implicit confirmation requests.,4 Determining Correct Categories Using Responses from Multiple Users,[0],[0]
"Our goal here is to obtain a confidence score Conf (w , c) representing how likely category c of the unknown term w is to be correct on the basis of replies to implicit confirmation requests from n different users.",4 Determining Correct Categories Using Responses from Multiple Users,[0],[0]
"We can then determine whether or not the system can add the pair of the unknown term w and category c into the system knowledge by setting a threshold for Conf (w , c).",4 Determining Correct Categories Using Responses from Multiple Users,[0],[0]
Figure 5 gives an overview of the proposed method.,4.1 Procedure,[0],[0]
"The steps below initially start with i = 1.
1.",4.1 Procedure,[0],[0]
"Generate an implicit confirmation request containing a predicted category c for user i after an unknown term w appears.
",4.1 Procedure,[0],[0]
2.,4.1 Procedure,[0],[0]
"Obtain the probability pi(w, c) from the implicit confirmation sub-dialogue with user i.",4.1 Procedure,[0],[0]
"The probability can be obtained by machine learning that has features based on expressions from the user response and its context.
3.",4.1 Procedure,[0],[0]
"Extract features from p1(w, c), ..., pi(w, c) and calculate the confidence score Conf (w , c) that represents how likely the category c of the unknown term w is to be correct.
4.",4.1 Procedure,[0],[0]
"If Conf (w , c) exceeds a predetermined threshold, c is regarded as correct and is acquired as knowledge.",4.1 Procedure,[0],[0]
"Otherwise, increment i, go to Step 1, and generate one more implicit confirmation with c to another user after the unknown term w appears.",4.1 Procedure,[0],[0]
"The problem of obtaining the confidence score Conf (w , c) can be formulated as a regression using probabilities of n user responses {p1(w, c), ..., pn(w, c)} as its input.",4.2 Obtaining Confidence Scores for Correct Categories,[0],[0]
"Intuitively, the category c can be regarded as more likely to be correct when pi(w, c) with higher values are obtained more times.
",4.2 Obtaining Confidence Scores for Correct Categories,[0],[0]
"Table 1 lists the features used in this regression for when probabilities pi(w, c) are obtained n times.",4.2 Obtaining Confidence Scores for Correct Categories,[0],[0]
"To use the same regression function when
n increases, we design features that consist of a constant number even when n varies and that are derived from n responses to implicit confirmation requests with category c.",4.2 Obtaining Confidence Scores for Correct Categories,[0],[0]
We conducted experiments to verify if our method is effective.,5 Data Collection via Crowdsourcing,[0],[0]
"Although it would have been desirable to collect experimental data by incorporating our method into the chatbot we are developing and having it used by many people without giving any instructions, this would have required a huge amount of interactions to collect enough data to verify our method.",5 Data Collection via Crowdsourcing,[0],[0]
We therefore collected user responses to implicit confirmation requests from 100 workers via crowdsourcing5.,5 Data Collection via Crowdsourcing,[0],[0]
"The data collection procedure consists of three steps: (1) a worker inputs an utterance containing a term specified on the interface at the crowdsourcing site, (2) the system generates an implicit confirmation request about the term, and (3) the worker fills in the response to the confirmation request.",5 Data Collection via Crowdsourcing,[0],[0]
"This procedure was repeated for 20 specified terms per worker.
",5 Data Collection via Crowdsourcing,[0],[0]
Figure 6 shows a schematic diagram of the graphical user interface (GUI) used in the crowdsourcing.,5 Data Collection via Crowdsourcing,[0],[0]
Note that it was actually in Japanese.,5 Data Collection via Crowdsourcing,[0],[0]
"The lines starting with “YOU” and “SYSTEM” denote the worker’s and the system’s utterances, respectively.",5 Data Collection via Crowdsourcing,[0],[0]
"At Step (1), the worker was asked to input an utterance that contains a term specified in
5 We used a crowdsourcing platform provided by Crowdworks, Inc. https://crowdworks.co.jp/
the uppermost part in Figure 6.",5 Data Collection via Crowdsourcing,[0],[0]
The worker was able to check the Wikipedia page for the specified term by following a link on the GUI.,5 Data Collection via Crowdsourcing,[0],[0]
"This was to prevent them from talking without understanding the term.
",5 Data Collection via Crowdsourcing,[0],[0]
We prepared 20 terms and their corresponding implicit confirmation requests used at Step (2): 10 had correct categories and the other 10 had incorrect categories.,5 Data Collection via Crowdsourcing,[0],[0]
"For example, for “shurasuko” (the Japanese rendering of churrasco), an implicit confirmation request with its correct category “meat dish6” is “Eating meat is fun, isn’t it?”",5 Data Collection via Crowdsourcing,[0],[0]
"On the other hand, for “sangria,” an implicit confirmation request with an incorrect category “yogashi7” is “Yogashi have a rich taste, don’t they?”",5 Data Collection via Crowdsourcing,[0],[0]
"Furthermore, expressions of the implicit confirmation request were altered to make the confirmation request more natural when a worker’s input was interrogative or negative.
",5 Data Collection via Crowdsourcing,[0],[0]
"We obtained 1,956 responses from 98 workers, half of which were responses to implicit confirmation requests with correct categories, and the other half were responses to those with incorrect ones.",5 Data Collection via Crowdsourcing,[0],[0]
We removed data from two workers who just input only specified words or repeated the same sentences.,5 Data Collection via Crowdsourcing,[0],[0]
We also removed four invalid inputs consisting of only spaces.,5 Data Collection via Crowdsourcing,[0],[0]
"Table 2 lists the features for estimating how likely the categories in system confirmations are to be
6Food category hierarchies usually used in Japan are different from those used in other countries.
",6.1 Features for Obtaining Probabilities with Single User Responses,[0],[0]
"7Yogashi means western sweets in Japanese.
correct.",6.1 Features for Obtaining Probabilities with Single User Responses,[0],[0]
"Here, U1，S1，and U2 respectively denote a user input, the implicit confirmation request by the system after U1, and the user response to the request.",6.1 Features for Obtaining Probabilities with Single User Responses,[0],[0]
"All feature values are binary; if the sentence for a feature is true, its value is 1, otherwise it is 0.",6.1 Features for Obtaining Probabilities with Single User Responses,[0],[0]
"These features were designed to represent differences in expressions of user responses to implicit confirmation requests with either a correct or incorrect category.
",6.1 Features for Obtaining Probabilities with Single User Responses,[0],[0]
We briefly explain some important features by using the examples below.,6.1 Features for Obtaining Probabilities with Single User Responses,[0],[0]
A user often uses affirmative expressions when responding to an implicit confirmation request with a correct category.,6.1 Features for Obtaining Probabilities with Single User Responses,[0],[0]
"This is represented by Feature g1, for which 15 affirmative expressions in Japanese were used such as “Yes” and “That’s right.”
",6.1 Features for Obtaining Probabilities with Single User Responses,[0],[0]
"When a category in an implicit confirmation request is correct, a user tends to continue with the same topic in U2 as in U1.",6.1 Features for Obtaining Probabilities with Single User Responses,[0],[0]
"In the example in Figure 3 (a), the user continues with the same topic and uses the same term tempura soba in U1 and U2.",6.1 Features for Obtaining Probabilities with Single User Responses,[0],[0]
"This is represented by Feature g4.
",6.1 Features for Obtaining Probabilities with Single User Responses,[0],[0]
"When the system makes an implicit confirmation request on the basis of an incorrect category, users tend to feel the system has suddenly changed the topic.",6.1 Features for Obtaining Probabilities with Single User Responses,[0],[0]
"In this case, the user tries to return the topic in U2 to the original one in U1.",6.1 Features for Obtaining Probabilities with Single User Responses,[0],[0]
"An example is as follows.
U1: I like sangria with its fruity taste.",6.1 Features for Obtaining Probabilities with Single User Responses,[0],[0]
S1:,6.1 Features for Obtaining Probabilities with Single User Responses,[0],[0]
"Yogashi have a rich taste, don’t they?",6.1 Features for Obtaining Probabilities with Single User Responses,[0],[0]
"U2: I am talking about the alcoholic bev-
erage.
",6.1 Features for Obtaining Probabilities with Single User Responses,[0],[0]
"In this example, the system generates an implicit confirmation with the incorrect category “yogashi” in S1 although the correct category of sangria is “alcoholic beverage.”",6.1 Features for Obtaining Probabilities with Single User Responses,[0],[0]
Then the user says that the topic is an alcoholic beverage and tries to return to the original topic.,6.1 Features for Obtaining Probabilities with Single User Responses,[0],[0]
"Here, another category name not used in S1 is included in U2.",6.1 Features for Obtaining Probabilities with Single User Responses,[0],[0]
"This is represented as Feature g6.
",6.1 Features for Obtaining Probabilities with Single User Responses,[0],[0]
"For Feature g2, 17 negative expressions were used such as “is not [category name used in S1]” and “No.”",6.1 Features for Obtaining Probabilities with Single User Responses,[0],[0]
"For Feature g3, six expressions such as “It is [category name not used in S1]” that tries to correct the system’s previous confirmation request were used.",6.1 Features for Obtaining Probabilities with Single User Responses,[0],[0]
"Our system has 20 categories, and five more names such as “cheese” and “pasta” were used as category names for Features g6 and g9.",6.1 Features for Obtaining Probabilities with Single User Responses,[0],[0]
Eighteen expressions including interrogatives were used for Feature g10.,6.1 Features for Obtaining Probabilities with Single User Responses,[0],[0]
We conducted a preliminary experiment to classify responses to implicit confirmation requests with correct and incorrect categories.,6.2 Classification Performance with Single User Responses,[0],[0]
"The data consists of the 1,956 responses and their contexts obtained by crowdsourcing as described in Section 5.",6.2 Classification Performance with Single User Responses,[0],[0]
We applied logistic regression to them with the features listed in Table 2.,6.2 Classification Performance with Single User Responses,[0],[0]
"We used the module in Weka (version 3.8.1) (Hall et al., 2009) as its implementation.",6.2 Classification Performance with Single User Responses,[0],[0]
The parameters were the default values.,6.2 Classification Performance with Single User Responses,[0],[0]
"The classification was performed by setting a threshold to the obtained probability pi(w, c).",6.2 Classification Performance with Single User Responses,[0],[0]
"The threshold was 0.5, which is also the default value of Weka.",6.2 Classification Performance with Single User Responses,[0],[0]
"Evaluation was conducted with a 10-fold cross validation.
",6.2 Classification Performance with Single User Responses,[0],[0]
We compared two feature sets: one consists of all 11 features listed in Table 2 and the other consists of Features g1 and g2 only.,6.2 Classification Performance with Single User Responses,[0],[0]
"The latter corresponds to a baseline condition that only considers affirmative and negative expressions of U2 and does not consider any relationship with S1 and U1.
",6.2 Classification Performance with Single User Responses,[0],[0]
The results are shown in Tables 3 and 4.,6.2 Classification Performance with Single User Responses,[0],[0]
Table 3 shows confusion matrices of the raw outputs for the two feature sets.,6.2 Classification Performance with Single User Responses,[0],[0]
Table 4 summarizes the results as precision and recall rates and F-measures of the two categories (correct and incorrect) also for the two feature sets.,6.2 Classification Performance with Single User Responses,[0],[0]
"The average-F scores, i.e. the arithmetic means of F-measures for the two categories, were 0.719 and 0.528 when all features and only g1 and g2 were used, respectively.
",6.2 Classification Performance with Single User Responses,[0],[0]
"This indicates that using the features representing context improves the classification more than using only the features obtained from U2.
",6.2 Classification Performance with Single User Responses,[0],[0]
We also performed feature selection to analyze which features were effective for the classification.,6.2 Classification Performance with Single User Responses,[0],[0]
"More specifically, we performed the same experiments with all combinations of the 11 features, i.e., 2047(= 211 − 1) feature sets, and calculated their average-F scores.",6.2 Classification Performance with Single User Responses,[0],[0]
Table 5 lists top-10 feature sets sorted by the scores.,6.2 Classification Performance with Single User Responses,[0],[0]
“None” denotes the case when all the 11 features were used.,6.2 Classification Performance with Single User Responses,[0],[0]
"First, the “None” condition was ranked second in the table, which shows that almost all features were effective for the classification.",6.2 Classification Performance with Single User Responses,[0],[0]
"Next, when Feature g10 was removed, the F-value for the Incorrect category slightly improved and thus the average-F score also improved, as shown in the table.",6.2 Classification Performance with Single User Responses,[0],[0]
"Because Feature g10 also appears in the table several times, Feature g10 was implied to be less helpful in this classification.",6.2 Classification Performance with Single User Responses,[0],[0]
"On the other hand, the weight value for Feature g8 of the logistic regression function had the largest and positive value when Feature g10 was removed.",6.2 Classification Performance with Single User Responses,[0],[0]
"This shows Feature g8 gave strong evidence and resulting pi(w, c) tended to be higher when Feature g8 was 1.",6.2 Classification Performance with Single User Responses,[0],[0]
"This means that, when the common category name is included both in U1 and S1, the category included in S1 tended to be correct because the topic is not changed abruptly.
",6.2 Classification Performance with Single User Responses,[0],[0]
The results shown above indicate the classification performance was about 70% precision and recall rates on the basis of the user response and its context.,6.2 Classification Performance with Single User Responses,[0],[0]
"However, we need higher precision because pairs of an unknown term and its predicted category will be added to the system knowledge, which must not contain errors.",6.2 Classification Performance with Single User Responses,[0],[0]
"Thus, we have proposed a method using multiple user responses as described in Section 4, the effectiveness of which
is verified in the following section.",6.2 Classification Performance with Single User Responses,[0],[0]
"In this section, we explain how to prepare data for training and evaluating the regression function to obtain Conf (w , c).",7.1 Data Preparation,[0],[0]
We performed the experiment in a perfectly open manner: no data were shared in training and test phases from the viewpoint of either workers or questions.,7.1 Data Preparation,[0],[0]
"More specifically, we had 98 (or 97) responses to implicit confirmation requests with 10 correct and 10 incorrect categories for making implicit confirmation requests, as explained in Section 5.",7.1 Data Preparation,[0],[0]
"Thus, we divided them into four disjointed groups, i.e., one group consists of 49 (or 48) workers with five correct and five incorrect categories.
",7.1 Data Preparation,[0],[0]
The data were generated using responses collected from multiple users.,7.1 Data Preparation,[0],[0]
"The responses are mutually independent because they are obtained by a server-based dialogue system, so they can be combined in an arbitrary order.",7.1 Data Preparation,[0],[0]
"Thus, when we have N responses to single implicit confirmation requests, we can generate ( N n ) patterns.",7.1 Data Preparation,[0],[0]
"In our experiment, N was 49 (or 48) in each group.",7.1 Data Preparation,[0],[0]
"Since the values of ( N n ) become very large, we set a cut-off value when generating the combination randomly.",7.1 Data Preparation,[0],[0]
"The value was set to 1, 000 when ( N n ) exceeds 1, 000.
",7.1 Data Preparation,[0],[0]
"From this data combination, we obtained feature values listed in Table 1 with the reference values for every case.",7.1 Data Preparation,[0],[0]
"The reference value was set to either 1 or 0 depending on whether the category used in the implicit confirmation request was correct or not, respectively.
",7.1 Data Preparation,[0],[0]
We then trained the regression function with each set of divided data of the four groups.,7.1 Data Preparation,[0],[0]
"We selected test data sets to be completely disjointed
from each of the four data sets from the viewpoint of both workers and questions.",7.1 Data Preparation,[0],[0]
"We also used the logistic regression, which was implemented in Weka (version 3.8.1) (Hall et al., 2009), with its default parameters.",7.1 Data Preparation,[0],[0]
The results by the regression for the four test sets are used together and analyzed hereafter.,7.1 Data Preparation,[0],[0]
We first investigated if the performance was better when the system used multiple responses from users.,7.2 Performance of Regression with Multiple Responses,[0],[0]
"The precision and recall rates were calculated by setting various thresholds to Conf (w , c) representing how likely a category c is to be correct for an unknown term w.
Figure 7 depicts the precision and recall curves for n up to 8.",7.2 Performance of Regression with Multiple Responses,[0],[0]
"It also shows a line indicating the breakeven points (BEPs), meaning the value where the two rates are equal.",7.2 Performance of Regression with Multiple Responses,[0],[0]
The BEP is used as a single point representing a precision and recall curve and to show how good the estimated confidence score is when n changes.,7.2 Performance of Regression with Multiple Responses,[0],[0]
"Note that n = 1 corresponds to the case when only single responses were used for the regression.
",7.2 Performance of Regression with Multiple Responses,[0],[0]
The performance represented by the BEP values became better as n became larger.,7.2 Performance of Regression with Multiple Responses,[0],[0]
"In particular, the BEP values of n ≥ 2 were larger than that of n = 1.",7.2 Performance of Regression with Multiple Responses,[0],[0]
"This proves that the proposed method using multiple user responses more accurately determines whether the predicted category is correct or not.
",7.2 Performance of Regression with Multiple Responses,[0],[0]
We also performed feature selection by removing arbitrary features listed in Table 1.,7.2 Performance of Regression with Multiple Responses,[0],[0]
"The performance of the regression function was measured by the summation of BEP values for each n (1 ≤
n ≤ 48).",7.2 Performance of Regression with Multiple Responses,[0],[0]
The result revealed the best performance in the case was obtained when we used only Features f3 and f4.,7.2 Performance of Regression with Multiple Responses,[0],[0]
One reason for this result was that the correlations among the features might be high.,7.2 Performance of Regression with Multiple Responses,[0],[0]
"We still need to further investigate feature sets to obtain better Conf(w, c), which is future work.",7.2 Performance of Regression with Multiple Responses,[0],[0]
We discuss the relationship between the values of n and the performance of the regression function in more detail.,7.3 Discussion on Reasonable Number of Responses,[0],[0]
Figure 7 shows that the performance represented by the BEP improved when n increased.,7.3 Discussion on Reasonable Number of Responses,[0],[0]
"On the other hand, cost will need to be incurred for increasing n, i.e., collecting responses from more human users.",7.3 Discussion on Reasonable Number of Responses,[0],[0]
"Thus, we investigate how much the performance of the regression function changed when n increased.
",7.3 Discussion on Reasonable Number of Responses,[0],[0]
We first investigated how the BEP values increased in accordance with n values.,7.3 Discussion on Reasonable Number of Responses,[0],[0]
Figure 8 depicts the increases in the BEP values when n was incremented by 1.,7.3 Discussion on Reasonable Number of Responses,[0],[0]
It shows the increases were large while n ≤ 5.,7.3 Discussion on Reasonable Number of Responses,[0],[0]
"This result indicates that it is worthwhile to ask more users implicit confirmation requests with predicted category c especially while n is small, to more accurately determine whether or not the category is correct.",7.3 Discussion on Reasonable Number of Responses,[0],[0]
"The figure also shows that the improvement mostly diminished, especially when n ≥ 10.",7.3 Discussion on Reasonable Number of Responses,[0],[0]
"This indicates that the effect by asking implicit confirmation requests to more human users shows diminishing returns as n increases from the viewpoint of the performance represented by the BEP.
",7.3 Discussion on Reasonable Number of Responses,[0],[0]
"We furthermore investigated recall rates when thresholds were set to Conf (w , c) so as to keep precision rates high.",7.3 Discussion on Reasonable Number of Responses,[0],[0]
"In our problem setting, high precision rates rather than high recall rates are re-
quired to avoid incorrect information being mistakenly added to the system knowledge.",7.3 Discussion on Reasonable Number of Responses,[0],[0]
"Figure 7 also shows the precision rate approached 1 for n ≥ 5 by setting very large thresholds to Conf (w , c).",7.3 Discussion on Reasonable Number of Responses,[0],[0]
These cases indicate that the system can be almost perfectly confident that the predicted category c is correct.,7.3 Discussion on Reasonable Number of Responses,[0],[0]
The recall rates were low for such cases because the precision and recall rates are in a trade-off relationship.,7.3 Discussion on Reasonable Number of Responses,[0],[0]
"We investigated the recall rates for such cases when n increased.
",7.3 Discussion on Reasonable Number of Responses,[0],[0]
"Figure 9 depicts the recall rates when we set very high threshold values for Conf (w , c) so that the precision rates become almost one, i.e., 1 − ϵ. Here, we set ϵ = 0.0058.",7.3 Discussion on Reasonable Number of Responses,[0],[0]
"First, the graph shows that the precision rate existed when n was 5 or more.",7.3 Discussion on Reasonable Number of Responses,[0],[0]
"For example, the recall rate for n = 5 was 0.175.",7.3 Discussion on Reasonable Number of Responses,[0],[0]
"This recall rate was rather low, but we think high precision rates should be prioritized over recall rates, even if some correct information is discarded at the current n. Second, the graph also shows that the recall rates increased with n. This means that, if the system asks more implicit confirmation requests with category c, more unknown terms the categories of which are c will be acquired with a sufficiently high precision rate.",7.3 Discussion on Reasonable Number of Responses,[0],[0]
We have proposed a method to determine if the ontological category of an unknown term included in an implicit confirmation request is correct or not.,8 Concluding Remarks,[0],[0]
"Although responses to implicit confirmation requests seem to be insufficient for determining this, our method makes it effective by using the information on the context of the responses and exploiting responses from multiple users.",8 Concluding Remarks,[0],[0]
"Exper-
",8 Concluding Remarks,[0],[0]
8,8 Concluding Remarks,[0],[0]
The margin ϵ,8 Concluding Remarks,[0],[0]
is required because the confidence score obtained by the logistic regression function cannot be 1 theoretically (the score can only converge to 1).,8 Concluding Remarks,[0],[0]
"Therefore, we selected the smallest ϵ with which we can calculate reasonable recall values.
",8 Concluding Remarks,[0],[0]
imental results revealed that the proposed method exhibited higher performance than when only single user responses were used.,8 Concluding Remarks,[0],[0]
"We hope the performance will be improved with further feature engineering.
",8 Concluding Remarks,[0],[0]
"The proposed method is expected to enable a chatbot to acquire knowledge through dialogues without annoying users with repetitive simple explicit confirmation requests, while it can avoid acquiring wrong knowledge by achieving a high precision rate for determining the correctness of the knowledge.
",8 Concluding Remarks,[0],[0]
We are planning to address several issues before deploying this method in a chatbot.,8 Concluding Remarks,[0],[0]
"Although we intuitively think implicit confirmation requests do not degrade users’ impressions compared with repetitive explicit confirmation requests, we need to experimentally verify this by a user study.",8 Concluding Remarks,[0],[0]
"On the basis of its results, we will define a strategy of when to make implicit confirmation requests and when to make explicit confirmation requests.",8 Concluding Remarks,[0],[0]
"Despite these remaining issues, we believe that the experimental results presented in this paper are valuable in that they show the possibility of lexical acquisition through implicit confirmation.",8 Concluding Remarks,[0],[0]
This work was partly supported by JSPS KAKENHI Grant Number JP16H02869.,Acknowledgments,[0],[0]
We address the problem of acquiring the ontological categories of unknown terms through implicit confirmation in dialogues.,abstractText,[0],[0]
We develop an approach that makes implicit confirmation requests with an unknown term’s predicted category.,abstractText,[0],[0]
"Our approach does not degrade user experience with repetitive explicit confirmations, but the system has difficulty determining if information in the confirmation request can be correctly acquired.",abstractText,[0],[0]
"To overcome this challenge, we propose a method for determining whether or not the predicted category is correct, which is included in an implicit confirmation request.",abstractText,[0],[0]
Our method exploits multiple user responses to implicit confirmation requests containing the same ontological category.,abstractText,[0],[0]
Experimental results revealed that the proposed method exhibited a higher precision rate for determining the correctly predicted categories than when only single user responses were considered.,abstractText,[0],[0]
Lexical Acquisition through Implicit Confirmations over Multiple Dialogues,title,[0],[0]
"Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 1161–1171, Denver, Colorado, May 31 – June 5, 2015. c©2015 Association for Computational Linguistics",text,[0],[0]
"Temporal relations between events are often implicit, and inferring them relies on lexical and world knowledge about the likely order of events.",1 Introduction,[0],[0]
"For instance, to execute the instruction “fry the onion,” the hearer should probably obtain oil beforehand, even if not instructed so explicitly.",1 Introduction,[0],[0]
"Lexical knowledge about the likely order of events is therefore necessary for any semantic task that requires temporal reasoning or planning, such as classifying temporal relations (Mani et al., 2006; Lapata and Lascarides, 2006; Yoshikawa et al., 2009; D’Souza and Ng, 2013; Mirza and Tonelli, 2014, inter alia), textual entailment (Dagan et al., 2013) or temporal information extraction (Ling and Weld, 2010).",1 Introduction,[0],[0]
"Lexical temporal knowledge is further important for model-
ing grammatical phenomena such as tense and aspect (Steedman, 2002).
",1 Introduction,[0],[0]
"In this paper we address the task of lexical event ordering, namely predicting the ordering of events based only on the identity of the words comprising their predicates and arguments.",1 Introduction,[0],[0]
"Concretely, the task is to predict the order of an unordered set of predicate-argument structures.",1 Introduction,[0],[0]
"Predicting the likely order of event types is a step towards more intricate planning and reasoning scenarios (see §3), and is useful in itself for tasks such as conceptto-text generation (Reiter et al., 2000), or in validating the correctness of instruction sets.",1 Introduction,[0],[0]
"A related idea can be found in modeling sentence coherence (Lapata, 2003; Barzilay and Lapata, 2008, inter alia), although here we focus on lexical relations between events, rather than coherence relations between complete sentences.
",1 Introduction,[0],[0]
"Compiling a resource of temporal tendencies between events can hardly be done manually, given the number and wealth of phenomena that have to be accounted for.",1 Introduction,[0],[0]
"Temporally annotated corpora, often annotated according to TimeML principles (Pustejovsky et al., 2003), are a useful resource for studying temporal relations.",1 Introduction,[0],[0]
"However, due to incurred costs, annotated corpora are too small for most lexical tasks.",1 Introduction,[0],[0]
"For instance, the TimeML annotated data used in the latest TempEval shared task contains only 100K words or so (UzZaman et al., 2013).
",1 Introduction,[0],[0]
"Previous work that does not rely on manually annotated data has had some success in discovering temporal lexical relations between predicates (Chklovski and Pantel, 2004; Chambers and Jurafsky, 2008b; Talukdar et al., 2012).",1 Introduction,[0],[0]
"However, despite their appeal, these methods have mostly fo-
1161
cused on inducing simple event types, consisting of single words (e.g., “buy-own”) or fixed expressions, and are hard to extend to include rich features (e.g., order-based and pattern-based features).",1 Introduction,[0],[0]
"Furthermore, measuring recall without annotated data is notoriously difficult, and evaluation is often precisionbased or extrinsic.
",1 Introduction,[0],[0]
"We take a graph-based structured prediction approach to the task, motivated by the flexibility it allows in incorporating various feature sets and constraints.",1 Introduction,[0],[0]
"We use an edge-factored model, which decomposes over the edges in the graph of events comprising the recipe (§4).",1 Introduction,[0],[0]
We estimate the model using the structured perceptron algorithm.,1 Introduction,[0],[0]
"We compare the structured perceptron approach to an approximate greedy baseline and to a locally normalized model reminiscent of common approaches for order learning, obtaining superior results (§8).",1 Introduction,[0],[0]
"The learning algorithm is of potential use in other ordering tasks such as machine translation reordering (Tromble and Eisner, 2009).
",1 Introduction,[0],[0]
We focus on domains in which the order of events in the text is aligned with their temporal order.,1 Introduction,[0],[0]
"By doing so we avoid the costly and error-prone manual annotation of temporal relations by using the textual order of recipes to approximate their temporal order.1 Specifically, we address the cooking recipes domain, which we motivate in §2.
",1 Introduction,[0],[0]
"In summary, the contribution of this paper is three-fold: (1) we explore the task of lexical event ordering and means for its evaluation; (2) we present an edge-factored model for the task, and show it can be used to predict the order of events well (77.7% according to standard measures for ordering evaluation); (3) we present a method for extracting events and create a dataset of ordered events using recipes extracted from the web.",1 Introduction,[0],[0]
Temporal semantics is receiving increasing attention in recent years.,2 Related Work,[0],[0]
Lexical features are in frequent use and rely in most part on external resources which are either manually compiled or automatically induced.,2 Related Work,[0],[0]
"The line of work most closely related to ours focuses on inducing lexical relations between
1See Cassidy et al. (2014) for a discussion of inter-annotator agreement in TimeML-based schemes.
event types.",2 Related Work,[0],[0]
"Most work has been unsupervised, often using pattern-based approaches relying on manually crafted (Chklovski and Pantel, 2004) or induced patterns (Davidov et al., 2007), that correlate with temporal relations (e.g., temporal discourse connectives).",2 Related Work,[0],[0]
Talukdar et al. (2012) uses the textual order of events in Wikipedia biographical articles to induce lexical information.,2 Related Work,[0],[0]
"We use both textual order and discourse connectives to define our feature set, and explore a setting which allows for the straightforward incorporation of additional features.
Chambers and Jurafsky (2008b; 2009) addressed the unsupervised induction of partially ordered event chains (or schema) in the news domain, centered around a common protagonist.",2 Related Work,[0],[0]
"One of their evaluation scenarios tackles a binary classification related to event ordering, and seeks to distinguish ordered sets of events from randomly permuted ones, yielding an accuracy of 75%.",2 Related Work,[0],[0]
Manshadi et al. (2008) used language models to learn event sequences and conducted a similar evaluation on weblogs with about 65% accuracy.,2 Related Work,[0],[0]
"The classification task we explore here is considerably more complex (see §8).
",2 Related Work,[0],[0]
The task of script knowledge induction has been frequently addressed in recent years.,2 Related Work,[0],[0]
Balasubramanian et al. (2013) and Pichotta and Mooney (2014) extended Chambers and Jurafsky’s model to include events that have multiple arguments.,2 Related Work,[0],[0]
"Jans et al. (2012) use skip-grams to capture event-event relations between not necessarily consecutive events.
",2 Related Work,[0],[0]
Regneri et al. (2010) constructed a temporal lexical knowledge base through crowd-sourcing.,2 Related Work,[0],[0]
Their approach is appealing as it greatly reduces the costs incurred by manual annotation and can potentially be used in conjunction with lexical information obtained from raw text.,2 Related Work,[0],[0]
"Modi and Titov (2014) jointly learns the stereotypical order of events and their distributional representation, in order to capture paraphrased instances of the same event type.",2 Related Work,[0],[0]
Frermann et al. (2014) models the joint task of inducing event paraphrases and their order using a Bayesian framework.,2 Related Work,[0],[0]
"All latter three works evaluated their induced temporal ordering knowledge on a binary prediction of whether a temporal relation between a pair of (not necessarily related) events holds, and not on the prediction of a complete permutation given an unordered event set as in this work.",2 Related Work,[0],[0]
"Their evaluation was conducted on 30 event pairs manually an-
notated through crowd-sourcing, where Modi and Titov (2014) further included an evaluation on a large set of pairs automatically extracted from the Gigaword corpus.
",2 Related Work,[0],[0]
"The appeal of the cooking domain for studying various semantic phenomena has been recognized by several studies in NLP and AI (Tasse and Smith, 2008; Bollini et al., 2013; Cimiano et al., 2013; Regneri et al., 2013; Malmaud et al., 2014).",2 Related Work,[0],[0]
The domain is here motivated by several considerations.,2 Related Work,[0],[0]
"First, recipes mostly describe concrete actions, rather than abstract relations, which are less relevant to temporal ordering.",2 Related Work,[0],[0]
"Second, from a practical point of view, many recipes are available online in computerreadable format.",2 Related Work,[0],[0]
"Third, the restrictiveness of the cooking domain can also be seen as an advantage, as it can reveal major conceptual challenges raised by the task, without introducing additional confounds.",2 Related Work,[0],[0]
We formalize our task as follows.,3 Temporally Ordering Lexical Events,[0],[0]
"Let U be a set of event types, namely actions or states (represented as predicates) and objects which these actions operate on (represented as arguments to the predicates; mostly ingredients or kitchenware).",3 Temporally Ordering Lexical Events,[0],[0]
"Formally, each e ∈ U is a tuple 〈a, c1, . . .",3 Temporally Ordering Lexical Events,[0],[0]
", cn〉 where a is the main verb or predicate describing the event (such as “stir” or “mix”) and c1, . . .",3 Temporally Ordering Lexical Events,[0],[0]
", cn is a list of arguments that the predicate takes (e.g., “salt” or “spoon”).",3 Temporally Ordering Lexical Events,[0],[0]
"Two additional marked events, s and f , correspond to “start” and “finish” events.",3 Temporally Ordering Lexical Events,[0],[0]
"A recipe is a sequence of events in U , starting at s and ending at f .
",3 Temporally Ordering Lexical Events,[0],[0]
"Given a recipe R = 〈e1, ..., em〉, we wish to predict the order of the events just from the (multi)set {ei}mi=1.",3 Temporally Ordering Lexical Events,[0],[0]
"In this work we use the textual order of events to approximate their temporal order (see, e.g., Talukdar et al. (2012) for a similar assumption).",3 Temporally Ordering Lexical Events,[0],[0]
"The validity of this assumption for cooking recipes is supported in §6.
",3 Temporally Ordering Lexical Events,[0],[0]
Figure 1 gives an example of a set of events extracted from our dataset for the dish “Apple Crisp Ala [sic] Brigitte.”,3 Temporally Ordering Lexical Events,[0],[0]
Lexical information places quite a few limitations on the order of this recipe.,3 Temporally Ordering Lexical Events,[0],[0]
"For instance, in most cases serving is carried out at the end while putting the ingredients in is done prior to baking them.",3 Temporally Ordering Lexical Events,[0],[0]
"However, lexical knowledge in itself is unlikely to predict the exact ordering of the events
as given in the recipe (e.g., spreading butter might be done before or after baking).
",3 Temporally Ordering Lexical Events,[0],[0]
One of the major obstacles in tackling planning problems in AI is the knowledge bottleneck.,3 Temporally Ordering Lexical Events,[0],[0]
Lexical event ordering is therefore a step towards more ambitious goals in planning.,3 Temporally Ordering Lexical Events,[0],[0]
"For instance, temporal relations may be used to induce planning operators (Mourão et al., 2012), which can in turn be used to generate a plan (recipe) given a specified goal and an initial set of ingredients.",3 Temporally Ordering Lexical Events,[0],[0]
In this section we describe the main learning components that compose our approach to event ordering.,"4 Model, Inference and Learning",[0],[0]
We hereby detail the linear model we use for ordering events.,4.1 Edge-Factored Model for Event Ordering,[0],[0]
"Let S = {e1, . . .",4.1 Edge-Factored Model for Event Ordering,[0],[0]
", em} ⊆ U be a set of events as mentioned in §3.",4.1 Edge-Factored Model for Event Ordering,[0],[0]
Let G(S) =,4.1 Edge-Factored Model for Event Ordering,[0],[0]
"(S ∪ {s, f}, E(S)) be an almost-complete directed graph withE(S)",4.1 Edge-Factored Model for Event Ordering,[0],[0]
=,4.1 Edge-Factored Model for Event Ordering,[0],[0]
(S∪{s})×(S∪{f}) ⊆ U×U .,4.1 Edge-Factored Model for Event Ordering,[0],[0]
"Every Hamiltonian path2 inG(S) that starts in s and ends in f defines an ordering of the events in S. The edge (ei, ej) in such a path denotes that ei is the event that comes before ej .
",4.1 Edge-Factored Model for Event Ordering,[0],[0]
The modeling problem is to score Hamiltonian paths in a given directed graph G(S).,4.1 Edge-Factored Model for Event Ordering,[0],[0]
"Here, we use an edge-factored model.",4.1 Edge-Factored Model for Event Ordering,[0],[0]
"Let φ : (U × U) → Rd be a feature function for pairs of events, represented as directed edges.",4.1 Edge-Factored Model for Event Ordering,[0],[0]
"In addition, let θ ∈ Rd be a weight vector.",4.1 Edge-Factored Model for Event Ordering,[0],[0]
"We define the score of a Hamiltonian path h = (h1, . . .",4.1 Edge-Factored Model for Event Ordering,[0],[0]
", hm+1)",4.1 Edge-Factored Model for Event Ordering,[0],[0]
(hi ∈ E(S)),4.1 Edge-Factored Model for Event Ordering,[0],[0]
"as:
score(h|S) = m+1∑ i=1",4.1 Edge-Factored Model for Event Ordering,[0],[0]
"θ>φ(hi) (1)
Given a weight vector θ and a set of events S, inference is carried out by computing the highest scoring Hamiltonian path in G(S):
h∗ = arg max h∈H(S) score(h|S) (2)
where H(S) is the set of Hamiltonian paths inG(S) that start with s and end with f .",4.1 Edge-Factored Model for Event Ordering,[0],[0]
"The path h∗ is the best temporal ordering of the set of events S according to the model in Eq. 1 with weight vector θ.
2A path in a graph that visits all nodes exactly once.
",4.1 Edge-Factored Model for Event Ordering,[0],[0]
"(a) e1 = 〈butter, dish〉 e2 = 〈put, apples,water, ...",4.1 Edge-Factored Model for Event Ordering,[0],[0]
"flour, cinnamon, it〉 e3 = 〈mix,with spoon, 〉 e4 = 〈spread, butter, salt, ... over mix〉 e5 = 〈bake,F〉 e6 = 〈serve, cream, cream〉
(b) Butter a deep baking dish, put apples, water, flour, sugar and cin-
namon in it.",4.1 Edge-Factored Model for Event Ordering,[0],[0]
"Mix with spoon and
spread butter and salt over the ap-
ple mix.",4.1 Edge-Factored Model for Event Ordering,[0],[0]
"Bake at 350 degrees F until
the apples are tender and the crust
brown, about 30 minutes.",4.1 Edge-Factored Model for Event Ordering,[0],[0]
"Serve
with cream or whipped cream.
",4.1 Edge-Factored Model for Event Ordering,[0],[0]
"(c)
(a) e 1
= hbutter, dishi e 2
= hput, apples,water, ... flour, cinnamon, iti
e 3 = hmix, spoon, i e 4
= hspread, butter, salt,mixi e 5
= hbake,Fi e 6 = hserve, cream, creami
(b) Butter a deep baking dish, put apples, water, flour, sugar and cinnamon in it.",4.1 Edge-Factored Model for Event Ordering,[0],[0]
Mix with spoon and spread butter and salt over the apple mix.,4.1 Edge-Factored Model for Event Ordering,[0],[0]
"Bake at 350 degrees F until the apples are tender and the crust brown, about 30 minutes.",4.1 Edge-Factored Model for Event Ordering,[0],[0]
"Serve with cream or whipped cream.
",4.1 Edge-Factored Model for Event Ordering,[0],[0]
"s
e 1
e 2
e 3
e 4
e 5
e 6
f
(c) (a) e1 = hmix, ✏, tarragon, vinegari e2 = hblend, ✏,mustardi e3 = hmix, ✏, salt, pepperi e4 = hblend, ✏,mayonnaise,",4.1 Edge-Factored Model for Event Ordering,[0],[0]
"sour creami e5 = hcover, ✏i e6 = hchill, ✏i (b) you mix the tarragon and vinegar together and blend in the mustard.",4.1 Edge-Factored Model for Event Ordering,[0],[0]
"you mix in the salt and pepper, blending well.",4.1 Edge-Factored Model for Event Ordering,[0],[0]
you blend in the mayonnaise and then the sour cream.,4.1 Edge-Factored Model for Event Ordering,[0],[0]
you cover and chill.,4.1 Edge-Factored Model for Event Ordering,[0],[0]
"s
e1 e2
e3 e4
e5
e6
e
Figure 1: (a) Example of events describing a recipe for the dish “.”",4.1 Edge-Factored Model for Event Ordering,[0],[0]
(b) The actual recipe for this dish.,4.1 Edge-Factored Model for Event Ordering,[0],[0]
(c) A complete graph over the set of events with start and end states.,4.1 Edge-Factored Model for Event Ordering,[0],[0]
"Each internal node in the graph is one of the events ei for i 2 {1, . . .",4.1 Edge-Factored Model for Event Ordering,[0],[0]
", 5}.",4.1 Edge-Factored Model for Event Ordering,[0],[0]
"The path in bold denotes the correct Hamiltonian path describing the set of actions that need to be taken to follow the recipe.
",4.1 Edge-Factored Model for Event Ordering,[0],[0]
"3 Model, Inference and Learning
In this section we describe the main learning components that compose our approach to event ordering.
",4.1 Edge-Factored Model for Event Ordering,[0],[0]
"3.1 Edge-Factored Model for Event Ordering
We now turn to explain the linear model we use for ordering events in time.",4.1 Edge-Factored Model for Event Ordering,[0],[0]
"Let S = {v1, . . .",4.1 Edge-Factored Model for Event Ordering,[0],[0]
", vm} ✓ U be a set of events as mentioned in section 2.",4.1 Edge-Factored Model for Event Ordering,[0],[0]
Let G(S) =,4.1 Edge-Factored Model for Event Ordering,[0],[0]
"(S [ {s, e}, E(S)) be an almost-complete directed graph with E(S)",4.1 Edge-Factored Model for Event Ordering,[0],[0]
= (S[{s})⇥(S[{e}),4.1 Edge-Factored Model for Event Ordering,[0],[0]
✓ (U ⇥ U).,4.1 Edge-Factored Model for Event Ordering,[0],[0]
"Every Hamiltonian path5 in G(S) that starts in s and ends in e can be thought of as an ordering of the events in S. The edge (vi, vj) in such a path denotes that vi is the event that comes before vj .
",4.1 Edge-Factored Model for Event Ordering,[0],[0]
"The modeling problem, therefore, is to score Hamiltonian paths in a given directed graph G(S) such as the above.",4.1 Edge-Factored Model for Event Ordering,[0],[0]
"Here, we use an edge-factored model.",4.1 Edge-Factored Model for Event Ordering,[0],[0]
Let : (U ⇥ U) !,4.1 Edge-Factored Model for Event Ordering,[0],[0]
"Rd be a feature vector for pairs of events, represented as directed edges.",4.1 Edge-Factored Model for Event Ordering,[0],[0]
"In addition, let ✓ 2 Rd be a weight vector.",4.1 Edge-Factored Model for Event Ordering,[0],[0]
"Then, we define the score of an Hamiltonian path h = (h1, . . .",4.1 Edge-Factored Model for Event Ordering,[0],[0]
", hm+1) (where hi 2 E(S) for i 2 {1, . . .",4.1 Edge-Factored Model for Event Ordering,[0],[0]
",m+ 1}) as:
5An Hamiltonian path in a graph is a path that visits all nodes exactly once.
",4.1 Edge-Factored Model for Event Ordering,[0],[0]
"score(h|S) = m+1X
i=1
✓> (hi) (1)
",4.1 Edge-Factored Model for Event Ordering,[0],[0]
"Given a weight vector w and a set of events S, inference is carried out by computing the highest scoring Hamiltonian path in G(S):
h⇤ = arg max h2H(S) score(h|S) (2)
where H(S) is the set of Hamiltonian paths in G(S) that start with s and end with e. h⇤ is the best temporal ordering of the set of events S according to the structured model in Equation 1 with weight vector w.
3.2 Inference As mentioned above, inference with the edgefactored model we presented would have to solve the maximization problem in Eq. 2.",4.1 Edge-Factored Model for Event Ordering,[0],[0]
"This corresponds to finding an Hamiltonian path in a complete graph, which is generally an NP-hard problem6.",4.1 Edge-Factored Model for Event Ordering,[0],[0]
"In the general case there is no reasonable approximation algorithm to solve the maximization algorithm, although
6The NP complete problem of finding a Hamiltonian cycle in an undirected graph can be trivially reduced to finding the maximal Hamiltonian cycle in a directed graph.
",4.1 Edge-Factored Model for Event Ordering,[0],[0]
Figure 1: (a) Example of events describing a recipe for the dish “Apple Crisp Ala [sic] Brigitte.”,4.1 Edge-Factored Model for Event Ordering,[0],[0]
"For brevity, arguments are represented as headwords and their syntactic type is omitted.",4.1 Edge-Factored Model for Event Ordering,[0],[0]
(b) The actual recipe for this dish.,4.1 Edge-Factored Model for Event Ordering,[0],[0]
(c) A complete graph over the set of events with start and end states.,4.1 Edge-Factored Model for Event Ordering,[0],[0]
"Each internal node in the graph is one of the events ei for i 2 {1, . . .",4.1 Edge-Factored Model for Event Ordering,[0],[0]
", 6}.",4.1 Edge-Factored Model for Event Ordering,[0],[0]
The path in blue bold denotes the correct Hamiltonian path describing the set of actions as ordered in the recipe.,4.1 Edge-Factored Model for Event Ordering,[0],[0]
Red edges denote edges from the start state a d to the end state.,4.1 Edge-Factored Model for Event Ordering,[0],[0]
"The edges, in practice, are weighted.
",4.1 Edge-Factored Model for Event Ordering,[0],[0]
ILP formulation yields superior performance to the other evaluated systems (§8).,4.1 Edge-Factored Model for Event Ordering,[0],[0]
"ILP has been proven to be a practical and flexible tool in various structured prediction tasks in NLP (Roth and tau Yih, 2007; Talukdar et al., 2012; Scaria et al., 2013).",4.1 Edge-Factored Model for Event Ordering,[0],[0]
"Our ILP formulation is given in Appendix A.
We experiment with an additional greedy inference algorithm, similar to the one described by Lapata (2003) for sentence ordering.",4.1 Edge-Factored Model for Event Ordering,[0],[0]
"The algorithm iteratively selects an outgoing edge (starting from the node s) that has the largest weight to a node that has not been visited so far, until all vertices are covered, at which point the path terminates by travelling to f .",4.1 Edge-Factored Model for Event Ordering,[0],[0]
"4.3 Learning The learning problem takes as input a dataset consisting of unordered sets of events, paired with a target ordering.",4.1 Edge-Factored Model for Event Ordering,[0],[0]
We consider two types of learning algorithms for the edge-factored model in the previous section.,4.1 Edge-Factored Model for Event Ordering,[0],[0]
"The first learns in a global training setting using the averaged structured perceptron (Collins, 2002), with the decoding algorithm being either the one based on ILP (henceforth, GLOBAL-PRC), or the greedy one (GREEDY-PRC).
",4.1 Edge-Factored Model for Event Ordering,[0],[0]
The second learning algorithm we try is based on factored training.,4.1 Edge-Factored Model for Event Ordering,[0],[0]
"This algorithm maximizes the likelihood of a conditional log-linear model p:
p(e2|e1, ✓, S) = exp
✓> (e1, e2)
Z(✓, S, e1)
Z(✓, S, e1) =",4.1 Edge-Factored Model for Event Ordering,[0],[0]
"X
e : (e1,e)2E(S)
exp ✓> (e1, e)
where e 1 , e 2 2 S",4.1 Edge-Factored Model for Event Ordering,[0],[0]
"[ {s, f}.",4.1 Edge-Factored Model for Event Ordering,[0],[0]
"This is a locally normalized log-linear model that gives the probability of transitioning to node e
2 from node e 1 .",4.1 Edge-Factored Model for Event Ordering,[0],[0]
"Maximizing the score in Eq. 1 has an interpretation of finding the highest scoring path according to an edge-factored Markovian model, such that:
p(h|✓, S) = m+1Y
i=2
p(ei|ei 1, ✓, S),
where h = (h 1 , . . .",4.1 Edge-Factored Model for Event Ordering,[0],[0]
", h m+1 ) is a Hamiltonian path with h
i =",4.1 Edge-Factored Model for Event Ordering,[0],[0]
"(e i 1, ei) being a directed edge in
the path.",4.1 Edge-Factored Model for Event Ordering,[0],[0]
"Initial experimentation suggested that greedy inference (henceforth, GREEDY-LOGLIN) works better in practice than the ILP formulation for the locally-normalized model.",4.1 Edge-Factored Model for Event Ordering,[0],[0]
We therefore do not report results on global inference with this loglinear model.,4.1 Edge-Factored Model for Event Ordering,[0],[0]
"GREEDY-LOGLIN closely resembles the learning model of Lapata (2003), except that it is a discriminative log-linear model, rather of a generative Markovian model.",4.1 Edge-Factored Model for Event Ordering,[0],[0]
5,4.1 Edge-Factored Model for Event Ordering,[0],[0]
The Feature Set Table 1 presents all the complete set of features used for defining the feature function .,4.1 Edge-Factored Model for Event Ordering,[0],[0]
"We consider three sets of features: Lexical encodes the written forms of the event pair predicates and objects;
Figure 1: (a) The sequence of events representing the recipe for the dish “Apple Crisp Ala [sic] Brigitte.”",4.1 Edge-Factored Model for Event Ordering,[0],[0]
"(b) The actual recipe
for this dish.",4.1 Edge-Factored Model for Event Ordering,[0],[0]
(c) A complete graph over the set of events with start and finish states.,4.1 Edge-Factored Model for Event Ordering,[0],[0]
"Each internal node in the graph is one of the
events ei for i ∈ {1, . . .",4.1 Edge-Factored Model for Event Ordering,[0],[0]
", 6}.",4.1 Edge-Factored Model for Event Ordering,[0],[0]
"The path in blue bold denotes the correct Hamiltonian path describing the set of actions as ordered in
the recipe.",4.1 Edge-Factored Model for Event Ordering,[0],[0]
Red edges denot edges from the start state and to the end state.,4.1 Edge-Factored Model for Event Ordering,[0],[0]
"The edges, in practice, are weighted.",4.1 Edge-Factored Model for Event Ordering,[0],[0]
"As mentioned above, inference with the edgefactored model requires solving he maximization problem in Eq. 2.",4.2 Inference,[0],[0]
"This corresponds to finding a Hamiltonian path in a complete graph, which is generally an NP-hard problem.",4.2 Inference,[0],[0]
Reasonable approximations for this problem are also NP-hard.,4.2 Inference,[0],[0]
"Still tec - niques are developed for specialized cases, due to the problem’s importance in discrete optimization.
",4.2 Inference,[0],[0]
"Despite its the retical NP-hardness, this maximization problem can be repr sented as an Integer Linear Program (ILP), and then solved using generic techniques for ILP optimizatio .",4.2 Inference,[0],[0]
"Due to the relatively short length of recipes (13.8 vents on average in our corpus), th probl m can be effectively solved in most cases.
",4.2 Inference,[0],[0]
The proposed algorithmic setting is appealing for its flexibility.,4.2 Inference,[0],[0]
"The linear score formulation allows us to use rich features, while using ILP allows to easily incorporate structural constraints.",4.2 Inference,[0],[0]
"Indeed, ILP has been proven valuable in various NLP tasks (Roth and Yih, 2007; Talukdar et al., 2012; Scaria al., 2013).",4.2 Inference,[0],[0]
"See Appendix A for our ILP formulation.
",4.2 Inference,[0],[0]
"As a baseline, we experiment with an additional greedy inference algorithm, similar to the one described by Lapata (2003) for sentence ordering.",4.2 Inference,[0],[0]
"he algorithm iteratively selects an outgoing edge (starting from the node s) that has the largest weight to a node that has not been visited so far, until all vertices are covered, at which point the path terminates by traveling to f .",4.2 Inference,[0],[0]
"The learning problem takes as input a dataset con-
sisting of unordered sets of events, paired with a target ordering.",4.3 Learning,[0],[0]
We c nsider two types of learning algorithms for the edge-factored model in the previous section.,4.3 Learning,[0],[0]
"The first learns in a global training setting using the averaged structured perceptron (Collins, 200 ), with the decoding algorithm being either the one based on ILP (henceforth, GLOBAL-PRC), or the greedy one (GREEDY-PRC).",4.3 Learning,[0],[0]
"Given a training instance S and its correct label hc, the structured perceptron calls the inference procedure as a subroutine and updates the weight vector θ according to the difference between the value of the feature function on the predicted path ( ∑ h∗ φ(hi)) and on the correct
path ( ∑
hc φ(hi)).",4.3 Learning,[0],[0]
The second learning algorithm we try is based on factored training.,4.3 Learning,[0],[0]
"This algorithm maximizes the likelihood of a conditional log-linear model p:
p(e2|e1, θ, S) = exp
( θ>φ(e1, e2) )",4.3 Learning,[0],[0]
"Z(θ, S, e1)
Z(θ, S, e1)",4.3 Learning,[0],[0]
"= ∑
e : (e1,e)∈E(S) exp
( θ>φ(e1, e) ) where e1, e2 ∈ S ∪ {s, f}.",4.3 Learning,[0],[0]
This is a locally normalized log-linear model that gives the probability of transitioning to node e2 from node e1.,4.3 Learning,[0],[0]
"Maximizing the score in Eq. 1 has an interpretation of finding the highest scoring path according to an edge-factored Markovian model, such that:
p(h|θ, S) = m+1∏ i=1",4.3 Learning,[0],[0]
"p(ei|ei−1, θ, S),
where h = (h1, . . .",4.3 Learning,[0],[0]
", hm+1) is a Hamiltonian path with hi = (ei−1, ei) being a directed edge in the path.",4.3 Learning,[0],[0]
"Initial experimentation suggested that greedy inference (henceforth, GREEDY-LOGLIN) works better in practice than the ILP formulation for the locally-normalized model.",4.3 Learning,[0],[0]
We therefore do not report results on global inference with this log-linear model.,4.3 Learning,[0],[0]
"We suspect that greedy inference works better with the log-linear model because it is trained locally, while the perceptron algorithm includes a global inference step in its training, and therefore better matches global decoding.
",4.3 Learning,[0],[0]
"GREEDY-LOGLIN closely resembles the learning model of Lapata (2003), as both are firstorder Markovian and use the same (greedy) inference procedure.",4.3 Learning,[0],[0]
"Lapata’s model differs from GREEDY-LOGLIN in being a generative model, where each event is a tuple of features, and the transition probability between events is defined as the product of transition probabilities between feature pairs.",4.3 Learning,[0],[0]
"GREEDY-LOGLIN is discriminative, so to be maximally comparable to the presented model.",4.3 Learning,[0],[0]
Table 1 presents the complete set of features.,5 The Feature Set,[0],[0]
"We consider three sets of features: Lexical encodes the written forms of the event pair predicates and objects; Brown uses Brown clusters (Brown et al., 1992) to encode similar information, but allows generalization between distributionally similar words; and Frequency encodes the empirical distribution of temporally-related phenomena.
",5 The Feature Set,[0],[0]
The feature definitions make use of several functions.,5 The Feature Set,[0],[0]
"For brevity, we sometimes say that an event e is (a, c1) if e’s predicate is a and its first argument is c1, disregarding its other arguments.",5 The Feature Set,[0],[0]
Let C be a reference corpus of recipes for collecting statistics.,5 The Feature Set,[0],[0]
"The function B(w) gives the Brown cluster of a word w, as determined by clustering C into 50 clusters {1, . . .",5 The Feature Set,[0],[0]
", 50}.",5 The Feature Set,[0],[0]
"The function ORD(a, c) returns the mean ordinal number of an (a, c) event in C. The ordinal number of the event ei in a recipe (e1, ..., em) is defined as i− m2 .
",5 The Feature Set,[0],[0]
"We further encode the tendency of two events to appear with temporal discourse connectives, such as “before” or “until.”",5 The Feature Set,[0],[0]
"We define a linkage between two events as a triplet (e1, e2, `) ∈",5 The Feature Set,[0],[0]
"(U × U × L), where L is the set of linkage types, defined according to their marker’s written form.",5 The Feature Set,[0],[0]
§6 details the extraction process of linkages from recipes.,5 The Feature Set,[0],[0]
"We further include a special linkage type linear based on the order of events in the text, and consider every pair of events e1 and e2 that follow one another in a recipe as linked under this linkage type.
",5 The Feature Set,[0],[0]
"For each linkage type ` ∈ L, we define an empirical probability distribution P`((a, c1), (a′, c′1))",5 The Feature Set,[0],[0]
"= P ((a, c1), (a′, c′1)|`), based on simple counting.",5 The Feature Set,[0],[0]
"The function PMI gives the point-wise mutual information of two events and is defined as:
PMI`((a, c), (a′, c′))",5 The Feature Set,[0],[0]
"= log ( P`((a, c1), (a′, c′1))",5 The Feature Set,[0],[0]
"P`(a, c1) ·",5 The Feature Set,[0],[0]
"P`(a′, c′1) )
",5 The Feature Set,[0],[0]
Frequency-based features encode the empirical estimate of the probabilities that various pairs of features would occur one after the other or linked with a discourse marker.,5 The Feature Set,[0],[0]
"They are equivalent to using probabilities extracted from maximum likelihood estima-
tion according to a bigram model in the discriminative learning.",5 The Feature Set,[0],[0]
"While some of this information is implicitly found in the lexical features, collecting frequency counts from a large training set is much quicker than running costly structured optimization.",5 The Feature Set,[0],[0]
Rather the discriminative training can weigh the different empirical probabilities according to their discriminative power.,5 The Feature Set,[0],[0]
Indeed we find that these features are important in practice and can result in high accuracy even after training on a small training set.,5 The Feature Set,[0],[0]
Data and Preprocessing.,6 The Recipe Dataset,[0],[0]
The data is extracted from a recipe repository found on the web.3,6 The Recipe Dataset,[0],[0]
The recipes are given as free text.,6 The Recipe Dataset,[0],[0]
"To extract event types we run the Stanford CoreNLP4 pipeline of a tokenizer, POS tagger, a lexical constituency parser (the englishPCFG parsing model) and extract typed Stanford dependencies (de Marneffe and Manning, 2008).",6 The Recipe Dataset,[0],[0]
"As is common with web extractions, the recipes contain occasional spelling, grammatical and formatting errors.",6 The Recipe Dataset,[0],[0]
"The corpus consists of 139 files, 73484 recipes, 1.02M events (13.8 events per recipe on average) and 11.05M words.5
Event Extraction.",6 The Recipe Dataset,[0],[0]
"We focus on verbal events and do not extract nominal and adjectival argument structures, which are not as well supported by current parsing technology.",6 The Recipe Dataset,[0],[0]
"Any verb is taken to define an event, aside from modal verbs, auxiliaries and secondary verbs.",6 The Recipe Dataset,[0],[0]
"A secondary verb (e.g., “let,” “begin”) does not describe an action in its own right, but rather modifies an event introduced by another verb.",6 The Recipe Dataset,[0],[0]
"We identify these verbs heuristically using a list given in Dixon (2005, p. 490–491) and a few simple rules defined over parse trees.",6 The Recipe Dataset,[0],[0]
"E.g., from the sentence “you should begin to chop the onion,” we extract a single event with a predicate “chop.”",6 The Recipe Dataset,[0],[0]
Arguments are taken to be the immediate dependents of the predicate that have an argument dependency type (such as direct or indirect objects) according to the extracted Stanford dependencies.,6 The Recipe Dataset,[0],[0]
"For prepositional phrases, we include the preposition as part of
3 http://www.ffts.com/recipes.htm 4 http://nlp.stanford.edu/software/corenlp.shtml
5Links to the original recipes, the preprocessed recipes and all extracted events can be found in http://homepages. inf.ed.ac.uk/oabend/event_order.html.
",6 The Recipe Dataset,[0],[0]
the argument.,6 The Recipe Dataset,[0],[0]
Argument indices are determined by their order in the text.,6 The Recipe Dataset,[0],[0]
"The order of events is taken to be the order of their verbs in the text.
",6 The Recipe Dataset,[0],[0]
Linkage Extraction.,6 The Recipe Dataset,[0],[0]
"We focus on a subset of linkage relations, which are relevant for temporal relations.",6 The Recipe Dataset,[0],[0]
"We use Pitler and Nenkova’s (2009) explicit discourse connectives classifier to identify temporal discourse linkers, discarding all other discourse linkers.",6 The Recipe Dataset,[0],[0]
"Once a discourse linker has been detected, we heuristically extract its arguments (namely the pair of verbs it links) according to a deterministic extraction rule defined over the parse tree.",6 The Recipe Dataset,[0],[0]
"We find 28 distinct connectives in our training set, where the 5 most common linkers “until,” “then,” “before,” “when” and “as” cover over 95% of the instances.",6 The Recipe Dataset,[0],[0]
"We extract 36756 such linkages from the corpus, 0.5 linkages per recipe on average.
",6 The Recipe Dataset,[0],[0]
Temporal and Textual Ordering.,6 The Recipe Dataset,[0],[0]
"In order to confirm that temporal and textual order of recipes are generally in agreement, we manually examine the first 20 recipes in our development set.",6 The Recipe Dataset,[0],[0]
"One recipe was excluded as noise6, resulting in 19 recipes and 353 events.",6 The Recipe Dataset,[0],[0]
We identify the sources of misalignment between the linear order and the temporal order of the events.7 13 events (3.7%) did not have any clear temporal orderings.,6 The Recipe Dataset,[0],[0]
"These consisted of mostly negations and modalities (e.g., “do not overbrown!”), sub-section headings (e.g., “Preparation”) or other general statements that do not constitute actions or states.",6 The Recipe Dataset,[0],[0]
"For the remaining 340 events, we compare their linear and the temporal orderings.
",6 The Recipe Dataset,[0],[0]
We estimate the frequency of sub-sequences that contradict the temporal order and confirm that they occur only infrequently.,6 The Recipe Dataset,[0],[0]
"We find that most disagreements fall into these two categories: (1) disjunctions between several events, only one of which will actually take place (e.g., “roll Springerle pin over dough, or press mold into top”); (2) a pair, or less commonly a triplet, of events are expressed in reverse order.",6 The Recipe Dataset,[0],[0]
"For instance, “place on greased and floured cookie sheet,” where greasing and flouring should occur before the placing action.",6 The Recipe Dataset,[0],[0]
"We note that assuming the alignment of the temporal and textual order
6This did not result from an extraction problem, but rather from the recipe text itself being too noisy to interpret.
7Events are parsed manually so to avoid confounding the results with the parser’s performance.
of recipes does not suggest that the textual order is the only order of events that would yield the same outcome.
",6 The Recipe Dataset,[0],[0]
"We compute the Kendall’s Tau correlation, a standard measure for information ordering (Lapata, 2006), between the temporal and linear orderings for each recipe.",6 The Recipe Dataset,[0],[0]
"In cases of several events that happen simultaneously (including disjunctions), we take their ordinals to be equal.",6 The Recipe Dataset,[0],[0]
"For instance, for three events where the last two happen at the same time, we take their ordering to be (1,2,2) in our analysis.",6 The Recipe Dataset,[0],[0]
"We find that indeed temporal and textual orderings are in very high agreement, with 6 recipes of the 19 perfectly aligned.",6 The Recipe Dataset,[0],[0]
The average Kendall’s Tau between the temporal ordering and the linear one is 0.924.,6 The Recipe Dataset,[0],[0]
Evaluation.,7 Experimental Setup,[0],[0]
We compute the accuracy of our algorithms by comparing the predicted order to the one in which the events are written.,7 Experimental Setup,[0],[0]
"We first compute the number of exact matches, denoted with EXACT, namely the percentage of recipes in which the predicted and the textual orders are the same.
",7 Experimental Setup,[0],[0]
"For a more detailed analysis of imperfect predictions, we compute the agreement between subsequences of the orderings.",7 Experimental Setup,[0],[0]
We borrow the notion of a “concordant pair” from the definition of Kendall’s Tau and generalize it to capture agreement of longer sub-sequences.,7 Experimental Setup,[0],[0]
"Two k-tuples of integers (x1, ..., xk) and (y1, ..., yk) are said to “agree in order” if for every 1 ≤",7 Experimental Setup,[0],[0]
"i < j ≤ k, xi < xj iff yi < yj .",7 Experimental Setup,[0],[0]
"Given two orderings of the same recipe O1 = (eτ(1), ..., eτ(m)) and O2 = (eσ(1), ..., eσ(m)) (where τ and σ are permutations over [m] = {1, . . .",7 Experimental Setup,[0],[0]
",m})",7 Experimental Setup,[0],[0]
"and given a sequence of k monotonically increasing indices t = (i1, ..., ik), t is said to be a “concordant k-tuple” of O1 andO2 if (τ(i1), ..., τ(ik))",7 Experimental Setup,[0],[0]
"and (σ(i1), ..., σ(ik)) agree in order, as defined above.
",7 Experimental Setup,[0],[0]
"Denote the unordered recipes of the test data as {Ri}Ni=1, where Ri = {ei1, ..., eimi} ⊂ U for all i, and their target orderings Σ = {σi}Ni=1, where σi is a permutation over [mi].",7 Experimental Setup,[0],[0]
"Assume we wish to evaluate a set of predicted orderings for this test data T = {τi}Ni=1, where again τi is a permutation over [mi].",7 Experimental Setup,[0],[0]
"Denote the number of concordant k-tuples of σi and τi as conc(σi, τi).",7 Experimental Setup,[0],[0]
"The total number of of
monotonically increasing k-tuples of indices is ( mi k ) .",7 Experimental Setup,[0],[0]
"The k-wise (micro-averaged) accuracy of T with respect to Σ is:
acck(Σ,T) = ∑N
i=1",7 Experimental Setup,[0],[0]
"conc(σi, τi)∑N i=1",7 Experimental Setup,[0],[0]
( mi k ),7 Experimental Setup,[0],[0]
"Any k-tuples containing the start node s or the end node f are excluded, as their ordering is trivial.",7 Experimental Setup,[0],[0]
Recipes of length less than k are discarded when computing acck.,7 Experimental Setup,[0],[0]
A micro-averaged accuracy measure is used so as not to disproportionately weigh short recipes.,7 Experimental Setup,[0],[0]
"However, in order to allow comparison to mean Kendall’s Tau, commonly used in works on order learning, we further report a macroaveraged acc2 by computing acc2 for each recipe separately, and taking the average of resulting accuracy levels.",7 Experimental Setup,[0],[0]
"Average Kendall’s Tau can now be computed by 2acc2−1 for the macro-averaged acc2 score.
",7 Experimental Setup,[0],[0]
Data.,7 Experimental Setup,[0],[0]
"We randomly partition the text into training, test and development sets, taking an 80-10-10 percent split.",7 Experimental Setup,[0],[0]
We do not partition the individual files so as to avoid statistical artifacts introduced by recipe duplications or near-duplications.,7 Experimental Setup,[0],[0]
"The training, development and test sets contain 58038, 7667 and 7779 recipes respectively.",7 Experimental Setup,[0],[0]
"The total number of feature template instantiations in the training data is 8.94M.
Baselines and Algorithms.",7 Experimental Setup,[0],[0]
We compare three learning algorithms.,7 Experimental Setup,[0],[0]
GLOBAL-PRC is the structured perceptron algorithm that uses ILP inference.,7 Experimental Setup,[0],[0]
GREEDY-PRC is a structured perceptron in which inference is done greedily.,7 Experimental Setup,[0],[0]
GREEDY-LOGLIN is the locally normalized log-linear model with greedy inference.,7 Experimental Setup,[0],[0]
"RANDOM randomly (uniformly) selects a permutation of the recipe’s events.
",7 Experimental Setup,[0],[0]
Experimental Settings.,7 Experimental Setup,[0],[0]
"The structured perceptron algorithms, GLOBAL-PRC and GREEDY-PRC, are run with a learning rate of 0.1 for 3 iterations.",7 Experimental Setup,[0],[0]
"To avoid exceedingly long runs, we set a time limit in seconds β on the running time of each ILP inference stage used in GLOBAL-PRC.",7 Experimental Setup,[0],[0]
"We consider two training scenarios: 4K, which trains on the first 4K recipes of the training set, and 58K, which trains on the full training data of 58K recipes.",7 Experimental Setup,[0],[0]
In GLOBAL-PRC we set β to be 30 seconds for the 4K,7 Experimental Setup,[0],[0]
"scenario, and 5 seconds in the 58K scenario.",K GLOBAL-PRC 68.9 76.4 41.3 24.8 34.4,[0],[0]
The number of threads was limited to 3.,K GLOBAL-PRC 68.9 76.4 41.3 24.8 34.4,[0],[0]
"Where the time limit is reached before an optimal solution is found, the highest scoring Hamiltonian path found up to that point is returned by the ILP solver.",K GLOBAL-PRC 68.9 76.4 41.3 24.8 34.4,[0],[0]
"In the infrequent samples where no feasible solution is found during training, the sample is skipped over, while at test time, we perform greedy inference instead.
",K GLOBAL-PRC 68.9 76.4 41.3 24.8 34.4,[0],[0]
We define the following feature sets.,K GLOBAL-PRC 68.9 76.4 41.3 24.8 34.4,[0],[0]
"Fr includes only features of class Frequency, while Fr + Lex includes features from both the Frequency and Lexical categories.",K GLOBAL-PRC 68.9 76.4 41.3 24.8 34.4,[0],[0]
Full includes all feature sets.,K GLOBAL-PRC 68.9 76.4 41.3 24.8 34.4,[0],[0]
"All above feature sets take C, the reference corpus for computing FREQUENCY features, to be the entire 58K training samples in both scenarios.",K GLOBAL-PRC 68.9 76.4 41.3 24.8 34.4,[0],[0]
"In the 4K scenario, we also experiment with FrLim, which includes all features, but takes C to contain only the 4K samples of the training data.
",K GLOBAL-PRC 68.9 76.4 41.3 24.8 34.4,[0],[0]
We use the Gurobi package for ILP.8 Brown clusters are extracted from the 58K samples of the training data using Liang’s implementation.9,K GLOBAL-PRC 68.9 76.4 41.3 24.8 34.4,[0],[0]
The convex log-likelihood function of GREEDY-LOGLIN is optimized using LBFGS.,K GLOBAL-PRC 68.9 76.4 41.3 24.8 34.4,[0],[0]
All features are selected and all parameters are tuned using the development set.,K GLOBAL-PRC 68.9 76.4 41.3 24.8 34.4,[0],[0]
"Table 2 presents the results of the three major algorithms in the two main scenarios 58K and 4K.
8 http://www.gurobi.com 9 https://github.com/percyliang/brown-cluster
We find that the structured perceptron algorithm, GLOBAL-PRC, obtains the best results in both cases and under all evaluation measures.",8 Results,[0],[0]
"The importance of global optimization was also stressed in other works on event ordering (Chambers and Jurafsky, 2008a; Talukdar et al., 2012).
",8 Results,[0],[0]
"In order to assess the contribution of the different components of the model of the best scoring model, GLOBAL-PRC, we compare the performance of the different feature sets and settings of β on the development set in 4K (Table 3).",8 Results,[0],[0]
Results reveal the strong impact of the Frequency feature set on the results.,8 Results,[0],[0]
"Using this category set alone (Fr) yields slightly lower results than using the full feature set, while estimating the Frequency features on a small corpus (FrLim) lowers results dramatically.",8 Results,[0],[0]
"Adding Lexical and Brown features yields a small improvement over using Frequency alone.
",8 Results,[0],[0]
"While Table 3 demonstrates the importance of β in the performance of GLOBAL-PRC, it also shows that on a limited time budget, a small training set and few features (4K, Fr) and a reasonably small β (5) can yield competitive results.",8 Results,[0],[0]
Increasing β from 5 to 30 generally improves results by 2 to 3 percent absolute.,8 Results,[0],[0]
"The importance of β is further demonstrated in Table 2, where performance with 4K training instances and β = 30 is better than with 58K training instances and β = 5.",8 Results,[0],[0]
"Preliminary experiments conducted on the development data with higher values of β of 60 and 120 suggest that further increasing β
yields no further improvement.",8 Results,[0],[0]
Previous studies evaluated their models on the related problem of distinguishing randomly permuted and correctly ordered chains of events (§2).,8 Results,[0],[0]
In this paper we generalize this task to complete event ordering.,8 Results,[0],[0]
"In order to demonstrate the relative difficulty of the tasks, we apply our highest scoring model (4K, Fr + Le) to the binary task (without re-training it).",8 Results,[0],[0]
We do so by computing the percentage of cases in which the correct ordering obtains a higher score than an average ordering.,8 Results,[0],[0]
"The high resulting accuracy of 93%, as opposed to considerably lower accuracies obtained under ordering evaluation measures, reflects the relative difficulty of the tasks.
",8 Results,[0],[0]
"The proposed edge-factored model can easily capture pair-wise ordering relations between events, but is more limited in accounting for relations between larger sets of events.",8 Results,[0],[0]
A simple way of doing so is by adding the feature ∑ e P (ei|e)P (e|ej) between events ei and ej (in addition to the regular transition probabilities P (ei|ej)).,8 Results,[0],[0]
"However, preliminary experimentation with this technique did not yield improved performance.",8 Results,[0],[0]
"Future work will address higher-order models that straightforwardly account for such long-distance dependencies.
",8 Results,[0],[0]
"To qualitatively assess what generalizations are learned by the model, we apply GLOBAL-PRC to the development data and look at what event pairs obtained either particularly high or particularly low results.",8 Results,[0],[0]
"For each pair of predicates and their first arguments (a1,c11), (a
2,c21), we compute the average weight of an edge connecting events of these types, discarding pairs of frequency less than 20.
",8 Results,[0],[0]
"The 20 highest scoring edges contain pairs such as (“add,” “mixing after addition”), (“beat whites,” “fold into mixture”) and (“cover for minutes,” “cook”), in addition to a few noisy pairs resulting from parser errors.",8 Results,[0],[0]
The 20 lowest scoring edges contain event pairs that are likely to appear in the opposite order.,8 Results,[0],[0]
"11 of the cases include as a first argument the predicates “serve,” “cool” or “chill,” which are likely to occur at the end of a recipe.",8 Results,[0],[0]
"3 other edges linked duplications (e.g., (“reduce heat,” “reduce heat”)), which are indeed unlikely to immediately follow one another.",8 Results,[0],[0]
"These findings suggest the importance of detecting both lexical pairs that are unlikely to follow one another, in addition to those that are likely to.",8 Results,[0],[0]
"We addressed the problem of lexical event ordering, and developed an edge-factored model for tackling it.",9 Conclusion,[0],[0]
"We rely on temporally aligned texts, using a new dataset of cooking recipes as a test case, thereby avoiding the need for costly and error-prone manual annotation.",9 Conclusion,[0],[0]
"We present results of a pair-wise accuracy of over 70% using a basic set of features, and show the utility of the structured perceptron algorithm over simpler greedy and local approaches.",9 Conclusion,[0],[0]
"The setup we explore, which uses a discriminative model and an ILP formulation, is easy to extend both in terms of features and in terms of more complex formal constraints and edge dependencies, as was done in graph-based dependency parsing (McDonald et al., 2005).",9 Conclusion,[0],[0]
"Future work will address the extension of the feature set and model, and the application of this model to temporal semantics and planning tasks.",9 Conclusion,[0],[0]
"We will further address the application of semi-supervised variants of the proposed techniques (e.g., self-training) to other domains, where no sizable corpora of temporally aligned data can be found.",9 Conclusion,[0],[0]
"We would like to thank Nathan Schneider, Roy Schwartz, Bonnie Webber and the members of the Probmodels group at the University of Edinburgh for helpful comments.",Acknowledgments,[0],[0]
This work was supported by ERC Advanced Fellowship 249520 GRAMPLUS.,Acknowledgments,[0],[0]
Let G(S),Appendix A: Maximal Hamiltonian Path,[0],[0]
=,Appendix A: Maximal Hamiltonian Path,[0],[0]
"(S ∪ {s, f}, E(S)) be an almostcomplete directed graph with E = E(S)",Appendix A: Maximal Hamiltonian Path,[0],[0]
= (S ∪ {s}) × (S ∪ {f}).,Appendix A: Maximal Hamiltonian Path,[0],[0]
"Let cij ∈ R be weights for its edges ((i, j) ∈ E).",Appendix A: Maximal Hamiltonian Path,[0],[0]
"A Hamiltonian path between s, f ∈ V can be found by solving the following program, returning P = {(i, j)|xij = 1}.
max xij∈{0,1} : (i,j)∈E
ui∈Z : i∈V
n∑ i6=j cijxij
s.t. n∑
i=0,i6=j xij = 1 ∀j 6= s; n∑ j=0,j 6",Appendix A: Maximal Hamiltonian Path,[0],[0]
=i xij = 1 ∀i 6=,Appendix A: Maximal Hamiltonian Path,[0],[0]
"e;
ui − uj + |V |xij ≤ |V",Appendix A: Maximal Hamiltonian Path,[0],[0]
"| − 1 ∀(i, j) ∈ E",Appendix A: Maximal Hamiltonian Path,[0],[0]
Extensive lexical knowledge is necessary for temporal analysis and planning tasks.,abstractText,[0],[0]
We address in this paper a lexical setting that allows for the straightforward incorporation of rich features and structural constraints.,abstractText,[0],[0]
"We explore a lexical event ordering task, namely determining the likely temporal order of events based solely on the identity of their predicates and arguments.",abstractText,[0],[0]
We propose an “edgefactored” model for the task that decomposes over the edges of the event graph.,abstractText,[0],[0]
We learn it using the structured perceptron.,abstractText,[0],[0]
"As lexical tasks require large amounts of text, we do not attempt manual annotation and instead use the textual order of events in a domain where this order is aligned with their temporal order, namely cooking recipes.",abstractText,[0],[0]
Lexical Event Ordering with an Edge-Factored Model,title,[0],[0]
"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 14–19 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics
https://doi.org/10.18653/v1/P17-2003",text,[0],[0]
"Similar to many other tasks, lexical features are a major source of information in current coreference resolvers.",1 Introduction,[0],[0]
Coreference resolution is a set partitioning problem in which each resulting partition refers to an entity.,1 Introduction,[0],[0]
"As shown by Durrett and Klein (2013), lexical features implicitly model some linguistic phenomena, which were previously modeled by heuristic features, but at a finer level of granularity.",1 Introduction,[0],[0]
"However, we question whether the knowledge that is mainly captured by lexical features can be generalized to other domains.
",1 Introduction,[0],[0]
"The introduction of the CoNLL dataset enabled a significant boost in the performance of coreference resolvers, i.e. about 10 percent difference between the CoNLL score of the currently best coreference resolver, deep-coref by Clark and Manning (2016b), and the winner of the CoNLL 2011 shared task, the Stanford rule-based system
by Lee et al. (2013).",1 Introduction,[0],[0]
"However, this substantial improvement does not seem to be visible in downstream tasks.",1 Introduction,[0],[0]
"Worse, the difference between stateof-the-art coreference resolvers and the rule-based system drops significantly when they are applied on a new dataset, even with consistent definitions of mentions and coreference relations (Ghaddar and Langlais, 2016a).
",1 Introduction,[0],[0]
"In this paper, we show that if we mainly rely on lexical features, as it is the case in state-of-theart coreference resolvers, overfitting become more sever.",1 Introduction,[0],[0]
Overfitting to the training dataset is a problem that cannot be completely avoided.,1 Introduction,[0],[0]
"However, there is a notable overlap between the CoNLL training, development and test sets that encourages overfitting.",1 Introduction,[0],[0]
"Therefore, the current coreference evaluation scheme is flawed by only evaluating on this overlapped validation set.",1 Introduction,[0],[0]
"To ensure meaningful improvements in coreference resolution, we believe an out-of-domain evaluation is a must in the coreference literature.",1 Introduction,[0],[0]
"The large difference in performance between coreference resolvers that use lexical features and ones which do not, implies the importance of lexical features.",2 Lexical Features,[0],[0]
"Durrett and Klein (2013) show that lexical features implicitly capture some phenomena, e.g. definiteness and syntactic roles, which were previously modeled by heuristic features.",2 Lexical Features,[0],[0]
Durrett and Klein (2013) use exact surface forms as lexical features.,2 Lexical Features,[0],[0]
"However, when word embeddings are used instead of surface forms, the use of lexical features is even more beneficial.",2 Lexical Features,[0],[0]
Word embeddings are an efficient way of capturing semantic relatedness.,2 Lexical Features,[0],[0]
"Especially, they provide an efficient way for describing the context of mentions.
",2 Lexical Features,[0],[0]
"Durrett and Klein (2013) show that the addition of some heuristic features like gender, num-
14
ber, person and animacy agreements and syntactic roles on top of their lexical features does not result in a significant improvement.
",2 Lexical Features,[0],[0]
"deep-coref, the state-of-the-art coreference resolver, follows the same approach.",2 Lexical Features,[0],[0]
"Clark and Manning (2016b) capture the required information for resolving coreference relations by using a large number of lexical features and a small set of nonlexical features including string match, distance, mention type, speaker and genre features.",2 Lexical Features,[0],[0]
"The main difference is that Clark and Manning (2016b) use word embeddings instead of the exact surface forms that are used by Durrett and Klein (2013).
",2 Lexical Features,[0],[0]
"Based on the error analysis by cort (Martschat and Strube, 2014), in comparison to systems that do not use word embeddings, deep-coref has fewer recall and precision errors especially for pronouns.",2 Lexical Features,[0],[0]
"For example, deep-coref correctly recognizes around 83 percent of non-anaphoric “it” in the CoNLL development set.",2 Lexical Features,[0],[0]
This could be a direct result of a better context representation by word embeddings.,2 Lexical Features,[0],[0]
"Aside from the evident success of lexical features, it is debatable how well the knowledge that is mainly captured by the lexical information of the training data can be generalized to other domains.",3 Out-of-Domain Evaluation,[0],[0]
"As reported by Ghaddar and Langlais (2016b), state-of-the-art coreference resolvers trained on the CoNLL dataset perform poorly, i.e. worse than the rule-based system (Lee et al., 2013), on the new dataset, WikiCoref (Ghaddar and Langlais, 2016b), even though WikiCoref is annotated with the same annotation guidelines as the CoNLL dataset.",3 Out-of-Domain Evaluation,[0],[0]
"The results of some of recent coreference resolvers on this dataset are listed in Table 1.
",3 Out-of-Domain Evaluation,[0],[0]
"The results are reported using MUC (Vilain
et al., 1995), B3 (Bagga and Baldwin, 1998), CEAFe (Luo, 2005), the average F1 score of these three metrics, i.e. CoNLL score, and LEA (Moosavi and Strube, 2016).
",3 Out-of-Domain Evaluation,[0],[0]
"berkeley is the mention-ranking model of Durrett and Klein (2013) with the FINAL feature set including the head, first, last, preceding and following words of a mention, the ancestry, length, gender and number of a mention, distance of two mentions, whether the anaphor and antecedent are nested, same speaker and a small set of string match features.
",3 Out-of-Domain Evaluation,[0],[0]
cort is the mention-ranking model of Martschat and Strube (2015).,3 Out-of-Domain Evaluation,[0],[0]
"cort uses the following set of features: the head, first, last, preceding and following words of a mention, the ancestry, length, gender, number, type, semantic class, dependency relation and dependency governor of a mention, the named entity type of the head word, distance of two mentions, same speaker, whether the anaphor and antecedent are nested, and a set of string match features.",3 Out-of-Domain Evaluation,[0],[0]
"berkeley and cort scores in Table 1 are taken from Ghaddar and Langlais (2016a).
",3 Out-of-Domain Evaluation,[0],[0]
deep-coref is the mention-ranking model of Clark and Manning (2016b).,3 Out-of-Domain Evaluation,[0],[0]
"deep-coref incorporates a large set of embeddings, i.e. embeddings of the head, first, last, two previous/following words, and the dependency governor of a mention in addition to the averaged embeddings of the five previous/following words, all words of the mention, sentence words, and document words.",3 Out-of-Domain Evaluation,[0],[0]
"deep-coref also incorporates type, length, and position of a mention, whether the mention is nested in any other mention, distance of two mentions, speaker features and a small set of string match features.
",3 Out-of-Domain Evaluation,[0],[0]
For deep-coref [conll] the averaged CoNLL score is used to select the best trained model on the development set.,3 Out-of-Domain Evaluation,[0],[0]
"deep-coref [lea] uses the LEA
metric (Moosavi and Strube, 2016) for choosing the best model.",3 Out-of-Domain Evaluation,[0],[0]
It is worth noting that the results of deep-coref ’s ranking model may be slightly different at various experiments.,3 Out-of-Domain Evaluation,[0],[0]
"However, the performance of deep-coref [lea] is always higher than that of deep-coref [conll].
",3 Out-of-Domain Evaluation,[0],[0]
We add WikiCoref’s words to deep-coref ’s dictionary for both deep-coref [conll] and deep-coref [lea].,3 Out-of-Domain Evaluation,[0],[0]
deep-coref− reports the performance of deep-coref [lea] in which WikiCoref’s words are not incorporated into the dictionary.,3 Out-of-Domain Evaluation,[0],[0]
"Therefore, for deep-coref−, WikiCoref’s words that do not exist in CoNLL will be initialized randomly instead of using pre-trained word2vec word embeddings.",3 Out-of-Domain Evaluation,[0],[0]
The performance gain of deep-coref [lea] in comparison to deep-coref− indicates the benefit of using pre-trained word embeddings and word embeddings in general.,3 Out-of-Domain Evaluation,[0],[0]
"Henceforth, we refer to deep-coref [lea] as deep-coref.",3 Out-of-Domain Evaluation,[0],[0]
"In this section, we investigate how much lexical features contribute to the fact that current improvements in coreference resolution do not properly apply to a new domain.
",4 Why do Improvements Fade Away?,[0],[0]
Table 2 shows the ratio of non-pronominal coreferent mentions in the CoNLL test set that also appear as coreferent mentions in the training data.,4 Why do Improvements Fade Away?,[0],[0]
"These high ratios indicate a high degree of overlap between the mentions of the CoNLL datasets.
",4 Why do Improvements Fade Away?,[0],[0]
The highest overlap between the training and test sets exists in genre pt (Bible).,4 Why do Improvements Fade Away?,[0],[0]
The tc (telephone conversation) genre has the lowest overlap for non-pronominal mentions.,4 Why do Improvements Fade Away?,[0],[0]
"However, this genre includes a large number of pronouns.",4 Why do Improvements Fade Away?,[0],[0]
"We choose wb (weblog) and pt for our analysis as two genres with low and high degree of overlap.
",4 Why do Improvements Fade Away?,[0],[0]
"Table 3 shows the results of the examined coreference resolvers when the test set only includes one genre, i.e. pt or wb, in two different settings: (1) the training set includes all genres (in-domain
evaluation), and (2) the corresponding genre of the test set is excluded from the training and development sets (out-of-domain evaluation).
",4 Why do Improvements Fade Away?,[0],[0]
berkeley-final is the coreference resolver of Durrett and Klein (2013) with the FINAL feature set explained in Section 3.,4 Why do Improvements Fade Away?,[0],[0]
"berkeley-surface is the same coreference resolver with only surface features, i.e. ancestry, gender, number, same speaker and nested features are excluded from the FINAL feature set.
",4 Why do Improvements Fade Away?,[0],[0]
"cort−lexical is a version of cort in which no lexical feature is used, i.e. the head, first, last, governor, preceding and following words of a mention are excluded.
",4 Why do Improvements Fade Away?,[0],[0]
"For in-domain evaluations we train deep-coref ’s ranking model for 100 iterations, i.e. the setting used by Clark and Manning (2016a).",4 Why do Improvements Fade Away?,[0],[0]
"However, based on the performance on the development set, we only train the model for 50 iterations in out-ofdomain evaluations.
",4 Why do Improvements Fade Away?,[0],[0]
"The results of the pt genre show that when there is a high overlap between the training and test datasets, the performance of all learning-based classifiers significantly improves.",4 Why do Improvements Fade Away?,[0],[0]
deep-coref has the largest gain from including pt in the training data that is more than 13% based on the LEA score.,4 Why do Improvements Fade Away?,[0],[0]
cort uses both lexical and a relatively large number of non-lexical features while berkeley-surface is a pure lexicalized system.,4 Why do Improvements Fade Away?,[0],[0]
"However, the difference between the berkeley-surface’s performances when pt is included or excluded from the training data is lower than that of cort.",4 Why do Improvements Fade Away?,[0],[0]
berkeley uses feature-value pruning so lexical features that occur fewer than 20 times are pruned from the training data.,4 Why do Improvements Fade Away?,[0],[0]
"Maybe, this is the reason that berkeley’s performance difference is less than other lexicalized systems in highly overlapping datasets.
",4 Why do Improvements Fade Away?,[0],[0]
"For a less overlapping genre, i.e. wb, the performance gain of including the genre in the training data is significantly lower for all lexicalized systems.",4 Why do Improvements Fade Away?,[0],[0]
"Interestingly, the performance of berkeleyfinal, cort and cort−lexical increases for the wb genre when this genre is excluded from the training set.",4 Why do Improvements Fade Away?,[0],[0]
"deep-coref, which uses a complex deep neural network and mainly lexical features, has the highest gain from the redundancy in the training and test datasets.",4 Why do Improvements Fade Away?,[0],[0]
"As we use more complex neural networks, there is more capacity for brute-force memorization of the training dataset.
",4 Why do Improvements Fade Away?,[0],[0]
"It is also worth noting that the performance gains and drops in out-of-domain evaluations are
not entirely because of lexical features, as the performance of cort−lexical also drops significantly in pt out-of-domain evaluation.",4 Why do Improvements Fade Away?,[0],[0]
The classifier may also memorize other properties of the seen mentions in the training data.,4 Why do Improvements Fade Away?,[0],[0]
"However, in comparison to features like gender and number agreement or syntactic roles, lexical features have the highest potential for overfitting.
",4 Why do Improvements Fade Away?,[0],[0]
We further analyze the output of deep-coref on the development set.,4 Why do Improvements Fade Away?,[0],[0]
The all rows in Table 4 show the number of pairwise links that are created by deep-coref on the development set for different mention types.,4 Why do Improvements Fade Away?,[0],[0]
"The seen rows show the ratio of each category of links for which the (antecedent head, anaphor head) pair is seen in the training set.",4 Why do Improvements Fade Away?,[0],[0]
All ratios are surprisingly high.,4 Why do Improvements Fade Away?,[0],[0]
"The most worrisome cases are those in which both mentions are either a proper name or a common noun.
",4 Why do Improvements Fade Away?,[0],[0]
Table 5 further divides the links of Table 4 based on whether they are correct coreferent links.,4 Why do Improvements Fade Away?,[0],[0]
"The results of Table 5 show that most of the incorrect links are also made between the mentions that are both seen in the training data.
",4 Why do Improvements Fade Away?,[0],[0]
"The high ratios indicate that (1) there is a high
overlap between the mention pairs of the training and development sets, and (2) even though that deep-coref uses generalized word embeddings instead of exact surface forms, it is strongly biased towards the seen mentions.
",4 Why do Improvements Fade Away?,[0],[0]
We analyze the links that are created by Stanford’s rule-based system and compute the ratio of the links that exist in the training set.,4 Why do Improvements Fade Away?,[0],[0]
All corresponding ratios are lower than those of deep-coref in Table 5.,4 Why do Improvements Fade Away?,[0],[0]
"However, the ratios are surprisingly high for a system that does not use the training data.",4 Why do Improvements Fade Away?,[0],[0]
This analysis emphasizes the overlap in the CoNLL datasets.,4 Why do Improvements Fade Away?,[0],[0]
"Because of this high overlap, it is not easy to assess the generalizability of a coreference resolver to unseen mentions on the CoNLL dataset given its official split.
",4 Why do Improvements Fade Away?,[0],[0]
"We also compute the ratios of Table 5 for the missing links that are associated with the recall er-
rors of deep-coref.",4 Why do Improvements Fade Away?,[0],[0]
"We compute the recall errors by cort error analysis tool (Martschat and Strube, 2014).",4 Why do Improvements Fade Away?,[0],[0]
Table 6 shows the corresponding ratios for recall errors.,4 Why do Improvements Fade Away?,[0],[0]
"The lower ratios of Table 6 in comparison to those of Table 4 emphasize the bias of deep-coref towards the seen mentions.
",4 Why do Improvements Fade Away?,[0],[0]
"For example, the deep-coref links include 31 cases in which both mentions are either proper names or common nouns and the head of one of the mentions is “country”.",4 Why do Improvements Fade Away?,[0],[0]
"For all these links, “country” is linked to a mention that is seen in the training data.",4 Why do Improvements Fade Away?,[0],[0]
"Therefore, this raises the question how the classifier would perform on a text about countries not mentioned in the training data.
",4 Why do Improvements Fade Away?,[0],[0]
Memorizing the pairs in which one of them is a common noun could help the classifier to capture world knowledge to some extent.,4 Why do Improvements Fade Away?,[0],[0]
"From the seen pairs like (Haiti, his country), and (Guangzhou, the city) the classifier could learn that “Haiti” is a country and “Guangzhou” is a city.",4 Why do Improvements Fade Away?,[0],[0]
"However, it is questionable how useful word knowledge is if it is mainly based on the training data.
",4 Why do Improvements Fade Away?,[0],[0]
The coreference relation of two nominal noun phrases with no head match can be very hard to resolve.,4 Why do Improvements Fade Away?,[0],[0]
"The resolution of such pairs has been referred to as capturing semantic similarity (Clark and Manning, 2016b).",4 Why do Improvements Fade Away?,[0],[0]
deep-coref links 49 such pairs on the development set.,4 Why do Improvements Fade Away?,[0],[0]
"Among all these links, only 5 pairs are unseen on the training set and all of them are incorrect links.
",4 Why do Improvements Fade Away?,[0],[0]
The effect of lexical features is also analyzed by Levy et al. (2015) for tasks like hypernymy and entailment.,4 Why do Improvements Fade Away?,[0],[0]
They show that state-of-the-art classifiers memorize words from the training data.,4 Why do Improvements Fade Away?,[0],[0]
The classifiers benefit from this lexical memorization when there are common words between the training and test sets.,4 Why do Improvements Fade Away?,[0],[0]
"We show the extensive use of lexical features biases coreference resolvers towards seen mentions.
",5 Discussion,[0],[0]
This bias holds us back from developing more robust and generalizable coreference resolvers.,5 Discussion,[0],[0]
"After all, while coreference resolution is an important step for text understanding, it is not an endtask.",5 Discussion,[0],[0]
Coreference resolvers are going to be used in tasks and domains for which coreference annotated corpora may not be available.,5 Discussion,[0],[0]
"Therefore, generalizability should be brought into attention in developing coreference resolvers.
",5 Discussion,[0],[0]
"Moreover, we show that there is a significant overlap between the training and validation sets in the CoNLL dataset.",5 Discussion,[0],[0]
"The LEA metric (Moosavi and Strube, 2016) is introduced as an attempt to make coreference evaluations more reliable.",5 Discussion,[0],[0]
"However, in order to ensure valid developments on coreference resolution, it is not enough to have reliable evaluation metrics.",5 Discussion,[0],[0]
The validation set on which the evaluations are performed also needs to be reliable.,5 Discussion,[0],[0]
"A dataset is reliable for evaluations if a considerable improvement on this dataset indicates a better solution for the coreference problem instead of a better exploitation of the dataset itself.
",5 Discussion,[0],[0]
This paper is not intended to argue against the use of lexical features.,5 Discussion,[0],[0]
"Especially, when word embeddings are used as lexical features.",5 Discussion,[0],[0]
The incorporation of word embeddings is an efficient way for capturing semantic relatedness.,5 Discussion,[0],[0]
Maybe we should use them more for describing the context and less for describing the mentions themselves.,5 Discussion,[0],[0]
"Pruning rare lexical features plus incorporating more generalizable features could also help to prevent overfitting.
",5 Discussion,[0],[0]
"To ensure more meaningful improvements, we ask to incorporate out-of-domain evaluations in the current coreference evaluation scheme.",5 Discussion,[0],[0]
"Outof-domain evaluations could be performed by using either the existing genres of the CoNLL dataset or by using other existing coreference annotated datasets like WikiCoref, MUC or ACE.",5 Discussion,[0],[0]
The authors would like to thank Kevin Clark for answering all of our questions regarding deepcoref.,Acknowledgments,[0],[0]
We would also like to thank the three anonymous reviewers for their thoughtful comments.,Acknowledgments,[0],[0]
"This work has been funded by the Klaus Tschira Foundation, Heidelberg, Germany.",Acknowledgments,[0],[0]
The first author has been supported by a Heidelberg Institute for Theoretical Studies PhD. scholarship.,Acknowledgments,[0],[0]
Lexical features are a major source of information in state-of-the-art coreference resolvers.,abstractText,[0],[0]
Lexical features implicitly model some of the linguistic phenomena at a fine granularity level.,abstractText,[0],[0]
They are especially useful for representing the context of mentions.,abstractText,[0],[0]
In this paper we investigate a drawback of using many lexical features in state-of-the-art coreference resolvers.,abstractText,[0],[0]
"We show that if coreference resolvers mainly rely on lexical features, they can hardly generalize to unseen domains.",abstractText,[0],[0]
"Furthermore, we show that the current coreference resolution evaluation is clearly flawed by only evaluating on a specific split of a specific dataset in which there is a notable overlap between the training, development and test sets.",abstractText,[0],[0]
Lexical Features in Coreference Resolution: To be Used With Caution,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 4717–4724 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
4717",text,[0],[0]
"The formal semantics literature has long been concerned with the complex array of inferences that different open class lexical items trigger (Kiparsky and Kiparsky, 1970; Karttunen, 1971a,b; Horn, 1972; Karttunen and Peters, 1979; Heim, 1992; Simons, 2001, 2007; Simons et al., 2010; Abusch, 2002, 2010; Gajewski, 2007; Anand and Hacquard, 2013, 2014).",1 Introduction,[0],[0]
"For example, why does (1a) give rise to the inference (2a), while the structurally identical (1b) triggers the inference (2b)?",1 Introduction,[0],[0]
"(1) a. Jo doesn’t believe that Bo left.
",1 Introduction,[0],[0]
b. Jo doesn’t know that Bo left.,1 Introduction,[0],[0]
"(2) a. Jo believes that Bo didn’t leave.
",1 Introduction,[0],[0]
b. Bo left.,1 Introduction,[0],[0]
"c. Bo didn’t leave.
",1 Introduction,[0],[0]
A major finding of this literature is that lexically triggered inferences are conditioned by surprising aspects of the syntactic context that a word occurs in.,1 Introduction,[0],[0]
"For example, while (3a), (3b), and (4a) trigger the inference (2b), (4b) triggers the inference (2c).",1 Introduction,[0],[0]
"(3) a. Jo remembered that Bo left.
",1 Introduction,[0],[0]
b. Jo didn’t remember that Bo left.,1 Introduction,[0],[0]
"(4) a. Bo remembered to leave.
",1 Introduction,[0],[0]
"b. Bo didn’t remember to leave.
",1 Introduction,[0],[0]
"Accurately capturing such interactions – e.g. between clause-embedding verbs, negation, and embedded clause type – is important for any system that aims to do general natural language inference (MacCartney et al. 2008",1 Introduction,[0],[0]
"et seq; cf. Dagan et al. 2006) or event extraction (see Grishman and Sundheim 1996 et seq), and it seems unlikely to be a trivial phenomenon to capture, given the complexity and variability of the inferences involved (see, e.g., Karttunen, 2012, 2013; Karttunen et al., 2014; van Leusen, 2012; White, 2014; Baglini and Francez, 2016; Nadathur, 2016, on implicatives).
",1 Introduction,[0],[0]
"In this paper, we investigate how well current state-of-the-art neural systems for a subtask of general event extraction – event factuality prediction (EFP; Nairn et al., 2006; Saurı́ and Pustejovsky, 2009, 2012; de Marneffe et al., 2012; Lee et al., 2015; Stanovsky et al., 2017; Rudinger et al., 2018) – capture inferential interactions between lexical items and syntactic context – lexicosyntactic inferences – when trained on current event factuality datasets.",1 Introduction,[0],[0]
"Probing these particular systems is useful for understanding neural systems’ behavior more generally because (i) the best performing neural models for EFP (Rudinger et al., 2018) are simple instances of common baseline models; and (ii) the task itself is relatively constrained.
",1 Introduction,[0],[0]
"To do this, we substantially extend the MegaVeridicality1 dataset (White and Rawlins, 2018) to cover all English clause-embedding verbs in a variety of the syntactic contexts covered by recent psycholinguistic work (White and Rawlins, 2016), and we use the resulting dataset – MegaVeridicality2 – to probe these models’ behavior.",1 Introduction,[0],[0]
"We focus on clause-embedding verbs because they show effectively every possible patterning of lexicosyntactic inference (Karttunen, 2012).
",1 Introduction,[0],[0]
We discuss three findings: (i) Tree biLSTMs,1 Introduction,[0],[0]
"(TbiLSTMs) are better able to correctly predict lexicosyntactic inferences than linear-chain biLSTMs
(L-biLSTMs); (ii) L-biLSTMs and T-biLSTMs capture different lexicosyntactic inferences, and thus ensembling their predictions can reliably improve performance; and (iii) even when ensembled, these models show systematic errors – e.g. performing well when the polarity of the matrix clause matches the polarity of the true inference, but poorly when these polarities mismatch.
",1 Introduction,[0],[0]
We furthermore release MegaVeridicality2 at MegaAttitude.io as a benchmark for probing the ability of neural systems – whether for factuality prediction or for general natural language inference – to capture lexicosyntactic inference.,1 Introduction,[0],[0]
"We substantially extend the MegaVeridicality1 dataset (White and Rawlins, 2018), which contains factuality judgments for all English clauseembedding verbs that take tensed subordinate clauses.",2 Data collection,[0],[0]
"In White and Rawlins’s annotation protocol, all verbs that are grammatical with such subordinate clauses – based on the MegaAttitude dataset (White and Rawlins, 2016) – are slotted into contexts either like (5a) or (5b), depending on whether they take a direct object or not.",2 Data collection,[0],[0]
"(5) a. Someone {knew, didn’t know} that a par-
ticular thing happened.",2 Data collection,[0],[0]
"b. Someone {was, wasn’t} told that a particu-
lar thing happened.",2 Data collection,[0],[0]
"For each sentence generated in this way, 10 different annotators are asked to answer the question did that thing happen?:",2 Data collection,[0],[0]
"yes, maybe or maybe not, no.
",2 Data collection,[0],[0]
There are two important aspects of these contexts to note.,2 Data collection,[0],[0]
"First, all lexical items besides the embedding verbs are semantically bleached to ensure that the measured lexicosyntactic inferences are only due to interactions between the embedding predicate – e.g. know or tell – and the syntactic context.",2 Data collection,[0],[0]
"Second, the matrix polarity – i.e. the presence or absence of not as a direct dependent of the embedding verb – is manipulated to create two sentences for each verb-context pair.
",2 Data collection,[0],[0]
"Our extension, MegaVeridicality2, includes judgments for a variety of infinitival subordinate clause types, exemplified in (6).1 We investigate infinitival clauses because they can give rise to dif-
1We also explicitly manipulate two aspects of the subordinate clause in our extension of the MegaVeridicality dataset: (i) how NP embedded subjects are introduced; and (ii) whether the embedded clause contains an eventive predicate (do, happen) or a stative predicate (have).",2 Data collection,[0],[0]
"See Appendix A for details on the reasoning behind these manipulations.
",2 Data collection,[0],[0]
ferent lexicosyntactic inferences than finite subordinate clauses – e.g. compare (3) and (4).,2 Data collection,[0],[0]
"(6) a. Someone {needed, didn’t need} for a par-
ticular thing to happen.",2 Data collection,[0],[0]
"b. Someone {wanted, didn’t want} a particu-
lar person to do, have a particular thing.",2 Data collection,[0],[0]
"c. Someone {wanted, didn’t want} a particu-
lar person to have a particular thing.",2 Data collection,[0],[0]
d.,2 Data collection,[0],[0]
"A particular person {was, wasn’t} over-
joyed to do a particular thing.",2 Data collection,[0],[0]
e.,2 Data collection,[0],[0]
"A particular person {was, wasn’t} over-
joyed to have a particular thing.",2 Data collection,[0],[0]
f.,2 Data collection,[0],[0]
"A particular person {managed, didn’t man-
age} to do a particular thing.",2 Data collection,[0],[0]
"g. A particular person {managed, didn’t man-
age} to have a particular thing.",2 Data collection,[0],[0]
"For each sentence, we also collect judgments from 10 different annotators, using the same question as White and Rawlins for context (6a) and modified questions for contexts (6b)-(6g): did that person do that thing?",2 Data collection,[0],[0]
"for (6b), (6d), and (6f); and did that person have that thing?",2 Data collection,[0],[0]
"for for (6c), (6e), and (6g).",2 Data collection,[0],[0]
Table 1 shows the number of verb types for each syntactic context.,2 Data collection,[0],[0]
"With the polarity manipulation, this yields a total of 3,938 sentences.
",2 Data collection,[0],[0]
"To build a factuality prediction test set from these sentences, we combine MegaVeridicality1 with our dataset and replace each instance of a particular person or a particular thing with someone or something (respectively).",2 Data collection,[0],[0]
"Then, following White and Rawlins, we normalize the 10 responses for each sentence to a single real value using an ordinal mixed model-based procedure.",2 Data collection,[0],[0]
We refer to the resulting dataset as MegaVeridicality2.,2 Data collection,[0],[0]
"We use MegaVeridicality2 to evaluate the performance of three state-of-the-art neural models of
event factuality (Rudinger et al., 2018): a linearchain biLSTM (L-biLSTM), a dependency tree biLSTM",3 Model and evaluation,[0],[0]
"(T-biLSTM), and a hybrid biLSTM (HbiLSTM) that ensembles the two.",3 Model and evaluation,[0],[0]
"To predict the factuality of the event referred to by a particular predicate, these models pass the output state of the biLSTM at that predicate through a two-layer regression.",3 Model and evaluation,[0],[0]
"In the case of the H-biLSTM, the output state of both the L- and T-biLSTMs are simply concatenated and passed through the regression.2
Following the multi-task training regime described by Rudinger et al. (2018), we train these models on four standard factuality datasets – FactBank (Saurı́ and Pustejovsky, 2009, 2012), UW (Lee et al., 2015), MEANTIME (Minard et al., 2016), and UDS (White et al., 2016; Rudinger et al., 2018) – with tied biLSTM weights but regression parameters specific to each dataset.",3 Model and evaluation,[0],[0]
"We then use these trained models to predict the factuality of the embedded predicate in our dataset.
",3 Model and evaluation,[0],[0]
"To understand how much of these models’ performance on our dataset is really due to a correct computation of lexicosyntactic inferences, we also generate predictions for the sentences in our dataset with the embedding verbs UNKed.",3 Model and evaluation,[0],[0]
"In this case, the model can rely only on the syntactic context surrounding the predicate to make its inferences.",3 Model and evaluation,[0],[0]
"We refer to the models with lexical information as the LEX models and the ones without lexical information as the UNK models.
",3 Model and evaluation,[0],[0]
"Each model produces four predictions, corresponding to the four different datasets it was trained on.",3 Model and evaluation,[0],[0]
"We consider three different ways of ensembling these predictions using a cross-validated ridge regression: (i) ensembling the four predictions for each specific model (LEX or UNK); (ii) ensembling the predictions for the LEX version of a particular model with the UNK version of that same model (LEX+UNK); and (iii) ensembling the predictions across all models (LEX, UNK, or LEX+UNK).",3 Model and evaluation,[0],[0]
"Each ensemble is evaluated in a 10- fold/10-fold nested cross-validation (see Cawley and Talbot, 2010).",3 Model and evaluation,[0],[0]
"In each iteration of the outer cross-validation, a 10% test set is split off, and a 10-fold cross-validation to tune the regularization is conducted on the remaining 90%.",3 Model and evaluation,[0],[0]
"Figure 1 shows the mean correlation between model predictions and true factuality on the outer
2See Appendix B for further details.
",4 Results,[0],[0]
fold test sets of the nested cross-validation described in §3.,4 Results,[0],[0]
"We note three aspects of this plot.
",4 Results,[0],[0]
"First, among the LEX models, the T-biLSTM performs best, followed by the L-biLSTM, then the H-biLSTM.",4 Results,[0],[0]
"This is somewhat surprising, since Rudinger et al. find the opposite pattern of performance: the L- and H-biLSTMs vie for dominance, both outperforming the T-biLSTM.",4 Results,[0],[0]
"This indicates that T-biLSTMs are better able to represent the lexicosyntactic inferences relevant to this dataset, even though they underperform on more general datasets.",4 Results,[0],[0]
"This possibility is bolstered by the fact that, in contrast to the L- and H-biLSTMs, the LEX version of the T-biLSTMs performs significantly better than the UNK version, suggesting that the T-biLSTM is potentially more reliant on the lexical information than the other two.
",4 Results,[0],[0]
"Second, when the LEX and UNK version of each model is ensembled (LEX+UNK), we find comparable performance for all three biLSTMs – each outperforming the LEX version of the TbiLSTM.",4 Results,[0],[0]
"This indicates that each model captures similar amounts of information about lexicosyntactic inference, but this information is captured in the models’ parameterizations in different ways.
",4 Results,[0],[0]
"Finally, when all three models are ensembled, we find that both the LEX and UNK version perform significantly better than any specific LEX+UNK model.",4 Results,[0],[0]
"This may indicate two things: (i) the models that only have access to syntax can perform just as well as ones that have access to both lexical information and syntax; but (ii) these models appear to capture different aspects of inference, since an ensemble of all models (AllLEX+UNK) performs significantly better than ei-
ther the All-LEX or All-UNK ensembles alone.",4 Results,[0],[0]
"Interestingly, however, even this ensemble performs more than 10 points worse than each model alone on FactBank, UW, and UDS.",4 Results,[0],[0]
This raises the question of which lexicosyntactic inferences these models are missing – investigated below.,4 Results,[0],[0]
We investigate two questions: (i) which inferences do all models do poorly on?; and (ii) what drives the differing strengths of each model?,5 Analysis,[0],[0]
Where do all models fail?,5 Analysis,[0],[0]
Table 2 shows the 20 sentences with the highest prediction errors under the All-LEX+UNK ensemble.,5 Analysis,[0],[0]
There are two interesting things to note about these sentences.,5 Analysis,[0],[0]
"First, most of them involve negative lexicosyntactic inferences that the model predicts to be either positive or near zero.",5 Analysis,[0],[0]
"Second, when the true inference is not positive, the matrix polarity of the original sentence is negative.",5 Analysis,[0],[0]
"This suggests that the models are not able to capture inferences whose polarity mismatches the matrix clause polarity.
",5 Analysis,[0],[0]
One question that arises here is whether this inability affects all contexts equally.,5 Analysis,[0],[0]
"To answer this, we regress the absolute error of the predictions from this same ensemble (logged and standardized) against true factuality, matrix polarity, and context (as well as all of their two- and three-way interactions).3",5 Analysis,[0],[0]
"We find that the three-way interactions in this regression are reliable ( 2(8)=27.97, p < 0.001) – suggesting that there are nontrivial differences in these state-of-the-art factuality systems’ ability to capture inferential interactions across verbs and syntactic contexts.",5 Analysis,[0],[0]
"The differences can be verified visually in Figure 2, which
3See Appendix C for further details, including a summary of the regression on which the above discussion is based.",5 Analysis,[0],[0]
"plots the factuality predicted by this ensemble against the true factuality from MegaVeridicality2.
",NP _ed that S NP was _ed that S NP _ed for NP to VP,[0],[0]
"To elaborate, the ensemble does best overall on contexts like (7a) and (7b), and worst overall on contexts like (7c).",NP _ed that S NP was _ed that S NP _ed for NP to VP,[0],[0]
"The contrast between (7b) and (7c) is particularly interesting because (i) (7c) is just the passivized form of (7b); and (ii) we do not observe similar behavior for contexts (7d) and (7e), which are analogous to (7b) and (7c), but replace the stative have with the eventive do.",NP _ed that S NP was _ed that S NP _ed for NP to VP,[0],[0]
"(7) Someone...
a. { ed, didn’t } for something to happen.",NP _ed that S NP was _ed that S NP _ed for NP to VP,[0],[0]
"b. { ed, didn’t } someone to have something.",NP _ed that S NP was _ed that S NP _ed for NP to VP,[0],[0]
"c. {was ed, wasn’t ed} to have something.",NP _ed that S NP was _ed that S NP _ed for NP to VP,[0],[0]
"d. { ed, didn’t } someone to do something.",NP _ed that S NP was _ed that S NP _ed for NP to VP,[0],[0]
"e. {was ed, wasn’t ed} to do something.",NP _ed that S NP was _ed that S NP _ed for NP to VP,[0],[0]
"f. { ed, didn’t } that something happened.
",NP _ed that S NP was _ed that S NP _ed for NP to VP,[0],[0]
"An additional nuance is that the ensemble does reliably better on the negative matrix polarity version of (7b) than on the positive, with the opposite true for (7e).",NP _ed that S NP was _ed that S NP _ed for NP to VP,[0],[0]
"This suggests these models do not capture an important inferential interaction between passivization and eventivity.
",NP _ed that S NP was _ed that S NP _ed for NP to VP,[0],[0]
"This suggestion is further bolstered by the fact that the ensemble’s ability to predict cases where the matrix polarity mismatches the true factuality are reliably poorer in context (7c) but not in its minimal pairs (7e) and (7b), where the ensemble performs reliably poorer when the two match.",NP _ed that S NP was _ed that S NP _ed for NP to VP,[0],[0]
"Indeed, it is contexts (7c) and (7f) that drive the polarity mismatch effect evident in Table 2.",NP _ed that S NP was _ed that S NP _ed for NP to VP,[0],[0]
What drives differences between models?,NP _ed that S NP was _ed that S NP _ed for NP to VP,[0],[0]
"In §4, we noted two ways that the biLSTMs we in-
vestigate differ: (i) the T-biLSTM appears to be more reliant on lexical information than L- and HbiLSTMs; and (ii) each model appears to encode information about lexicosyntactic inference in its parameterizations in different ways.",NP _ed that S NP was _ed that S NP _ed for NP to VP,[0],[0]
"We hypothesize that these two differences are related – specifically, that the T-biLSTM’s heavier reliance on lexical information comes about as a consequence of stronger entanglement between lexical and syntactic information in its hidden states.
",NP _ed that S NP was _ed that S NP _ed for NP to VP,[0],[0]
"To probe this, we ask to what extent the embedding verb’s embedding can be recovered from the embedded verb’s hidden state using linear functions.",NP _ed that S NP was _ed that S NP _ed for NP to VP,[0],[0]
"If the lexical information is more strongly entangled with the syntactic information, it should be more difficult to construct a homomorphic (linear) function to decode the embedding verb’s embedding from the embedded verb’s hidden state.",NP _ed that S NP was _ed that S NP _ed for NP to VP,[0],[0]
"To measure this, we conduct a Canonical Correlation Analysis (CCA; Hotelling, 1936) between these two vector space representations for every sentence in our dataset.",NP _ed that S NP was _ed that S NP _ed for NP to VP,[0],[0]
"Given two matrices X (the embedding verb embeddings column stacked) and Y (the embedded verb hidden states column stacked), CCA constructs matrices A and B, such that ai,bi = arga0,b0max corr(a0X,b0Y) and corr(aiX,ajX) = corr(biY,bjY) = 0, 8i <",NP _ed that S NP was _ed that S NP _ed for NP to VP,[0],[0]
"j. This guarantees that the canonical correlation at component i, corr(aiX,biY), is nonincreasing in i, and thus the linearly decodable information about Y in X can be assessed using this function.
",NP _ed that S NP was _ed that S NP _ed for NP to VP,[0],[0]
Figure 3 plots the canonical correlations for the first 50 components for each of the biLSTMs we investigated.,NP _ed that S NP was _ed that S NP _ed for NP to VP,[0],[0]
We find that the canonical correlations associated with the T-biLSTM are substantially lower than those associated with the Land H-biLSTMs across these first 50 components.,NP _ed that S NP was _ed that S NP _ed for NP to VP,[0],[0]
"This suggests that the T-biLSTM more strongly entangles lexical and syntactic information, per-
haps explaining its apparently heavier reliance on lexical information, observed in §4.
",NP _ed that S NP was _ed that S NP _ed for NP to VP,[0],[0]
"Of note here is that the pattern seen in Figure 3 is probably at least partly a consequence of the different nonlinearities used for the L-biLSTM (tanh) and T-biLSTM (ReLU), and not the architectures themselves.",NP _ed that S NP was _ed that S NP _ed for NP to VP,[0],[0]
"But whether or not this pattern is due to the architectures, nonlinearities, or both, the entanglement hypothesis may still help explain the pattern of results discussed in §4.",NP _ed that S NP was _ed that S NP _ed for NP to VP,[0],[0]
"This work is inspired by recent work in recasting various semantic annotations into natural language inference (NLI) datasets (White et al., 2017; Poliak et al., 2018a,b; Wang et al., 2018) to gain a better understanding of which phenomena standard neural NLI models (Bowman et al., 2015; Conneau et al., 2017) can capture – a line of work with deep roots (Cooper et al., 1996).",6 Related work,[0],[0]
"The experimental setup – specifically, the idea of UNKing the embedding verb – was inspired by recent work that uses hypothesis-only baselines for a similar purpose (Gururangan et al., 2018; Poliak et al., 2018c; Tsuchiya, 2018).",6 Related work,[0],[0]
"This work is also related to the broader investigation of sentence representations – particularly, tasks aimed at probing these representations’ content (Pavlick and Callison-Burch, 2016; Adi et al., 2016; Conneau et al., 2018; Conneau and Kiela, 2018; Dasgupta et al., 2018).",6 Related work,[0],[0]
"We investigated neural models’ ability to capture lexicosyntactic inference, taking the task of event factuality prediction (EFP) as a case study.",7 Conclusion,[0],[0]
We built a factuality judgment dataset for all English clause-embedding verbs in various syntactic contexts and used this dataset to probe current stateof-the-art EFP systems.,7 Conclusion,[0],[0]
We showed that these systems make certain systematic errors that are clearly visible through the lens of factuality.,7 Conclusion,[0],[0]
"This research was supported by the JHU HLTCOE, DARPA LORELEI and AIDA, NSF-BCS (1748969/1749025), and NSF-GRFP (1232825).",Acknowledgments,[0],[0]
The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes.,Acknowledgments,[0],[0]
The views and conclusions contained in this publication are those of the authors and should not be interpreted as representing official policies or endorsements of DARPA or the U.S. Government.,Acknowledgments,[0],[0]
We investigate neural models’ ability to capture lexicosyntactic inferences: inferences triggered by the interaction of lexical and syntactic information.,abstractText,[0],[0]
We take the task of event factuality prediction as a case study and build a factuality judgment dataset for all English clause-embedding verbs in various syntactic contexts.,abstractText,[0],[0]
"We use this dataset, which we make publicly available, to probe the behavior of current state-of-the-art neural systems, showing that these systems make certain systematic errors that are clearly visible through the lens of factuality prediction.",abstractText,[0],[0]
Lexicosyntactic Inference in Neural Models,title,[0],[0]
"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 148–154 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics
https://doi.org/10.18653/v1/P17-2023",text,[0],[0]
"Aspect extraction is a key task of opinion mining (Liu, 2012).",1 Introduction,[0],[0]
It extracts opinion targets from opinion text.,1 Introduction,[0],[0]
"For example, from the sentence “The screen is great”, it aims to extract “screen”, which is a product feature, also called an aspect.
",1 Introduction,[0],[0]
Aspect extraction is commonly done using a supervised or an unsupervised approach.,1 Introduction,[0],[0]
"The unsupervised approach includes methods such as frequent pattern mining (Hu and Liu, 2004; Popescu and Etzioni, 2005; Zhu et al., 2009), syntactic rules-based extraction (Zhuang et al., 2006; Wang and Wang, 2008; Wu et al., 2009; Zhang et al., 2010; Qiu et al., 2011; Poria et al., 2014), topic modeling (Mei et al., 2007; Titov and McDonald, 2008; Li et al., 2010; Brody and Elhadad, 2010; Wang et al., 2010; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012; Lin and He, 2009; Zhao et al., 2010; Jo and Oh, 2011; Fang and Huang, 2012; Wang et al., 2016), word alignment (Liu et al., 2013), label propagation (Zhou et al., 2013; Shu et al., 2016), and others (Zhao et al., 2015).
",1 Introduction,[0],[0]
"This paper focuses on the supervised approach (Jakob and Gurevych, 2010; Choi and Cardie,
2010; Mitchell et al., 2013) using Conditional Random Fields (CRF) (Lafferty et al., 2001).",1 Introduction,[0],[0]
"It shows that the results of CRF can be significantly improved by leveraging some prior knowledge automatically mined from the extraction results of previous domains, including domains without labeled data.",1 Introduction,[0],[0]
"The improvement is possible because although every product (domain) is different, there is a fair amount of aspects sharing across domains (Chen and Liu, 2014).",1 Introduction,[0],[0]
"For example, every review domain has the aspect price and reviews of many products have the aspect battery life or screen.",1 Introduction,[0],[0]
Those shared aspects may not appear in the training data but appear in unlabeled data and the test data.,1 Introduction,[0],[0]
"We can exploit such sharing to help CRF perform much better.
",1 Introduction,[0],[0]
"Due to leveraging the knowledge gained from the past to help the new domain extraction, we are using the idea of lifelong machine learning (LML) (Chen and Liu, 2016; Thrun, 1998; Silver et al., 2013), which is a continuous learning paradigm that retains the knowledge learned in the past and uses it to help future learning and problem solving with possible adaptations.
",1 Introduction,[0],[0]
The setting of the proposed approach L-CRF (Lifelong CRF) is as follows: A CRF model M has been trained with a labeled training review dataset.,1 Introduction,[0],[0]
"At a particular point in time, M has extracted aspects from data in n previous domains D1, . . .",1 Introduction,[0],[0]
", Dn (which are unlabeled) and the extracted sets of aspects are A1, . . .",1 Introduction,[0],[0]
", An.",1 Introduction,[0],[0]
"Now, the system is faced with a new domain data Dn+1.",1 Introduction,[0],[0]
"M can leverage some reliable prior knowledge in A1, . . .",1 Introduction,[0],[0]
", An to make a better extraction fromDn+1 than without leveraging this prior knowledge.
",1 Introduction,[0],[0]
"The key innovation of L-CRF is that even after supervised training, the model can still improve its extraction in testing or its applications with experiences.",1 Introduction,[0],[0]
"Note that L-CRF is different from semisupervised learning (Zhu, 2005) as the n previous
148
(unlabeled) domain data used in extraction are not used or not available during model training.
",1 Introduction,[0],[0]
"There are prior LML works for aspect extraction (Chen et al., 2014; Liu et al., 2016), but they were all unsupervised methods.",1 Introduction,[0],[0]
"Supervised LML methods exist (Chen et al., 2015; Ruvolo and Eaton, 2013), but they are for classification rather than for sequence learning or labeling like CRF.",1 Introduction,[0],[0]
"A semi-supervised LML method is used in NELL (Mitchell et al., 2015), but it is heuristic patternbased.",1 Introduction,[0],[0]
It doesn’t use sequence learning and is not for aspect extraction.,1 Introduction,[0],[0]
"LML is related to transfer learning and multi-task learning (Pan and Yang, 2010), but they are also quite different (see (Chen and Liu, 2016) for details).
",1 Introduction,[0],[0]
"To the best of our knowledge, this is the first paper that uses LML to help a supervised extraction method to markedly improve its results.",1 Introduction,[0],[0]
"CRF learns from an observation sequence x to estimate a label sequence y: p(y|x;θ), where θ is a set of weights.",2 Conditional Random Fields,[0],[0]
Let l be the l-th position in the sequence.,2 Conditional Random Fields,[0],[0]
"The core parts of CRF are a set of feature functions F = {fh(yl, yl−1,xl)}Hh=1 and their corresponding weights θ = {θh}Hh=1.",2 Conditional Random Fields,[0],[0]
Feature Functions: We use two types of feature functions (FF).,2 Conditional Random Fields,[0],[0]
"One is Label-Label (LL) FF:
fLLij (yl, yl−1)",2 Conditional Random Fields,[0],[0]
"= 1{yl = i}1{yl−1 = j},∀i, j ∈ Y, (1)
where Y is the set of labels, and 1{·} an indicator function.",2 Conditional Random Fields,[0],[0]
The other is Label-Word (LW),2 Conditional Random Fields,[0],[0]
"FF:
fLWiv (yl,xl) = 1{yl = i}1{xl = v}, ∀i ∈ Y,∀v ∈ V, (2)
where V is the vocabulary.",2 Conditional Random Fields,[0],[0]
This FF returns 1 when the l-th word is v and the l-th label is v’s specific label i; otherwise 0.,2 Conditional Random Fields,[0],[0]
"xl is the current word, and is represented as a multi-dimensional vector.",2 Conditional Random Fields,[0],[0]
"Each dimension in the vector is a feature of xl.
",2 Conditional Random Fields,[0],[0]
"Following the previous work in (Jakob and Gurevych, 2010), we use the feature set {W, -1W, +1W, P, -1P, +1P, G}, where W is the word and P is its POS-tag, -1W is the previous word, -1P is its POS-tag, +1W is the next word, +1P is its POStag, and G is the generalized dependency feature.
",2 Conditional Random Fields,[0],[0]
"Under the Label-Word FF type, we have two sub-types of FF: Label-dimension FF and Label-G FF.",2 Conditional Random Fields,[0],[0]
"Label-dimension FF is for the first 6 features, and Label-G is for the G feature.
",2 Conditional Random Fields,[0],[0]
"The Label-dimension (Ld) FF is defined as
fLd ivd (yl,xl) = 1{yl = i}1{xdl = vd},∀i ∈ Y, ∀vd ∈",2 Conditional Random Fields,[0],[0]
"Vd, (3)
where Vd is the set of observed values in feature d ∈ {W,−1W,+1W,P,−1P,+1P}",2 Conditional Random Fields,[0],[0]
and we call Vd feature d’s feature values.,2 Conditional Random Fields,[0],[0]
Eq. (3) is a FF that returns 1 when xl’s feature d equals to the feature value vd and the variable yl (lth label) equals to the label value i; otherwise,2 Conditional Random Fields,[0],[0]
"0.
We describe G and its feature function next, which also holds the key to the proposed L-CRF.",2 Conditional Random Fields,[0],[0]
Feature G uses generalized dependency relations.,3 General Dependency Feature (G),[0],[0]
What is interesting about this feature is that it enables L-CRF to use past knowledge in its sequence prediction at the test time in order to perform much better.,3 General Dependency Feature (G),[0],[0]
This will become clear shortly.,3 General Dependency Feature (G),[0],[0]
"This feature takes a dependency pattern as its value, which is generalized from dependency relations.
",3 General Dependency Feature (G),[0],[0]
The general dependency feature (G) of the variable xl takes a set of feature values VG.,3 General Dependency Feature (G),[0],[0]
Each feature value vG is a dependency pattern.,3 General Dependency Feature (G),[0],[0]
"The LabelG (LG) FF is defined as:
fLG ivG (yl,xl) =",3 General Dependency Feature (G),[0],[0]
"1{yl = i}1{xGl = vG},∀i ∈ Y, ∀vG ∈ VG.",3 General Dependency Feature (G),[0],[0]
"(4)
Such a FF returns 1 when the dependency feature of the variable xl equals to a dependency pattern vG and the variable yl equals to the label value i.",3 General Dependency Feature (G),[0],[0]
"Dependency relations have been shown useful in many sentiment analysis applications (Johansson and Moschitti, 2010; Jakob and Gurevych, 2010).",3.1 Dependency Relation,[0],[0]
"A dependency relation 1 is a quintuple-tuple: (type, gov, govpos, dep, deppos), where type is the type of the dependency relation, gov is the governor word, govpos is the POS tag of the governor word, dep is the dependent word, and deppos is the POS tag of the dependent word.",3.1 Dependency Relation,[0],[0]
The l-th word can either be the governor word or the dependent word in a dependency relation.,3.1 Dependency Relation,[0],[0]
"We generalize dependency relations into dependency patterns using the following steps:
1.",3.2 Dependency Pattern,[0],[0]
"For each dependency relation, replace the current word (governor word or dependent word) and its POS tag with a wildcard since we already have the word (W) and the POS tag (P) features.
",3.2 Dependency Pattern,[0],[0]
"1We obtain dependency relations using Stanford CoreNLP: http://stanfordnlp.github.io/CoreNLP/.
2.",3.2 Dependency Pattern,[0],[0]
Replace the context word (the word other than the l-th word) in each dependency relation with a knowledge label to form a more general dependency pattern.,3.2 Dependency Pattern,[0],[0]
Let the set of aspects annotated in the training data be Kt.,3.2 Dependency Pattern,[0],[0]
"If the context word in the dependency relation appears in Kt, we replace it with a knowledge label ‘A’ (aspect); otherwise ‘O’ (other).
",3.2 Dependency Pattern,[0],[0]
"For example, we work on the sentence “The battery of this camera is great.”",3.2 Dependency Pattern,[0],[0]
The dependency relations are given in Table 1.,3.2 Dependency Pattern,[0],[0]
"Assume the current word is “battery,” and “camera” is annotated as an aspect.",3.2 Dependency Pattern,[0],[0]
"The original dependency relation between “camera” and “battery” produced by a parser is (nmod, battery, NN, camera, NN).",3.2 Dependency Pattern,[0],[0]
Note that we do not use the word positions in the relations in Table 1.,3.2 Dependency Pattern,[0],[0]
"Since the current word’s information (the word itself and its POS-tag) in the dependency relation is redundant, we replace it with a wild-card.",3.2 Dependency Pattern,[0],[0]
"The relation becomes (nmod, *, camera, NN).",3.2 Dependency Pattern,[0],[0]
"Secondly, since “camera” is in Kt, we replace “camera” with a general label ‘A’.",3.2 Dependency Pattern,[0],[0]
"The final dependency pattern becomes (nmod,*, A, NN).
",3.2 Dependency Pattern,[0],[0]
We now explain why dependency patterns can enable a CRF model to leverage the past knowledge.,3.2 Dependency Pattern,[0],[0]
"The key is the knowledge label ‘A’ above, which indicates a likely aspect.",3.2 Dependency Pattern,[0],[0]
"Recall that our problem setting is that when we need to extract from the new domain Dn+1 using a trained CRF model M , we have already extracted from many previous domains D1, . . .",3.2 Dependency Pattern,[0],[0]
", Dn and retained their extracted sets of aspects A1, . . .",3.2 Dependency Pattern,[0],[0]
", An.",3.2 Dependency Pattern,[0],[0]
"Then, we can mine reliable aspects from A1, . . .",3.2 Dependency Pattern,[0],[0]
", An and add them in Kt, which enables many knowledge labels in the dependency patterns of the new data An+1 due to sharing of aspects across domains.",3.2 Dependency Pattern,[0],[0]
"This enriches the dependency pattern features, which consequently allows more aspects to be extracted from the new domain Dn+1.",3.2 Dependency Pattern,[0],[0]
We now present the L-CRF algorithm.,4 The Proposed L-CRF Algorithm,[0],[0]
"As the dependency patterns for the general dependency fea-
Algorithm 1 Lifelong Extraction of L-CRF 1: Kp ← ∅ 2: loop 3: F ← FeatureGeneration(Dn+1,K) 4: An+1 ← Apply-CRF-Model(M,F ) 5: S ← S ∪ {An+1} 6: Kn+1 ← Frequent-Aspects-Mining(S, λ) 7: if Kp = Kn+1 then 8: break 9: else 10: K ← Kt ∪Kn+1 11:",4 The Proposed L-CRF Algorithm,[0],[0]
"Kp ← Kn+1 12: S ← S − {An+1} 13: end if 14: end loop
ture do not use any actual words and they can also use the prior knowledge, they are quite powerful for cross-domain extraction (the test domain is not used in training).
",4 The Proposed L-CRF Algorithm,[0],[0]
Let K be a set of reliable aspects mined from the aspects extracted in past domain datasets using the CRF model M .,4 The Proposed L-CRF Algorithm,[0],[0]
Note that we assume that M has already been trained using some labeled training data Dt.,4 The Proposed L-CRF Algorithm,[0],[0]
"Initially, K is Kt (the set of all annotated aspects in the training data Dt).",4 The Proposed L-CRF Algorithm,[0],[0]
"The more domainsM has worked on, the more aspects it extracts, and the larger the set K gets.",4 The Proposed L-CRF Algorithm,[0],[0]
"When faced with a new domain Dn+1, K allows the general dependency feature to generate more dependency patterns related to aspects due to more knowledge labels ‘A’ as we explained in the previous section.",4 The Proposed L-CRF Algorithm,[0],[0]
"Consequently, CRF has more informed features to produce better extraction results.
",4 The Proposed L-CRF Algorithm,[0],[0]
L-CRF works in two phases: training phase and lifelong extraction phase.,4 The Proposed L-CRF Algorithm,[0],[0]
"The training phase trains a CRF model M using the training data Dt, which is the same as normal CRF training, and will not be discussed further.",4 The Proposed L-CRF Algorithm,[0],[0]
"In the lifelong extraction phase, M is used to extract aspects from coming domains (M does not change and the domain data are unlabeled).",4 The Proposed L-CRF Algorithm,[0],[0]
"All the results from the domains are retained in past aspect store S. At
a particular time, it is assumed M has been applied to n past domains, and is now faced with the n + 1 domain.",4 The Proposed L-CRF Algorithm,[0],[0]
L-CRF uses M and reliable aspects (denoted Kn+1) mined from S and Kt (K = Kt ∪ Kn+1) to extract from Dn+1.,4 The Proposed L-CRF Algorithm,[0],[0]
"Note that aspects Kt from the training data are considered always reliable as they are manually labeled, thus a subset ofK. We cannot use all extracted aspects from past domains as reliable aspects due to many extraction errors.",4 The Proposed L-CRF Algorithm,[0],[0]
But those aspects that appear in multiple past domains are more likely to be correct.,4 The Proposed L-CRF Algorithm,[0],[0]
"ThusK contains those frequent aspects in S. The lifelong extraction phase is in Algorithm 1.
",4 The Proposed L-CRF Algorithm,[0],[0]
"Lifelong Extraction Phase: Algorithm 1 performs extraction on Dn+1 iteratively.
1.",4 The Proposed L-CRF Algorithm,[0],[0]
"It generates features (F ) on the data Dn+1 (line 3), and applies the CRF model M on F to produce a set of aspects An+1",4 The Proposed L-CRF Algorithm,[0],[0]
"(line 4).
2. An+1 is added to S, the past aspect store.",4 The Proposed L-CRF Algorithm,[0],[0]
"From S, we mine a set of frequent aspects Kn+1.",4 The Proposed L-CRF Algorithm,[0],[0]
"The frequency threshold is λ.
3.",4 The Proposed L-CRF Algorithm,[0],[0]
"If Kn+1 is the same as Kp from the previous iteration, the algorithm exits as no new aspects can be found.",4 The Proposed L-CRF Algorithm,[0],[0]
"We use an iterative process because each extraction gives new results, which may increase the size of K, the reliable past aspects or past knowledge.",4 The Proposed L-CRF Algorithm,[0],[0]
"The increased K may produce more dependency patterns, which can enable more extractions.
4.",4 The Proposed L-CRF Algorithm,[0],[0]
Else: some additional reliable aspects are found.,4 The Proposed L-CRF Algorithm,[0],[0]
M may extract additional aspects in the next iteration.,4 The Proposed L-CRF Algorithm,[0],[0]
Lines 10 and 11 update the two sets for the next iteration.,4 The Proposed L-CRF Algorithm,[0],[0]
We now evaluate the proposed L-CRF method and compare with baselines.,5 Experiments,[0],[0]
We use two types of data for our experiments.,5.1 Evaluation Datasets,[0],[0]
The first type consists of seven (7) annotated benchmark review datasets from 7 domains (types of products).,5.1 Evaluation Datasets,[0],[0]
"Since they are annotated, they are used in training and testing.",5.1 Evaluation Datasets,[0],[0]
"The first 4 datasets are from (Hu and Liu, 2004), which actually has 5 datasets from 4 domains.",5.1 Evaluation Datasets,[0],[0]
"Since we are mainly interested in results at the domain level, we did not use one of the domain-repeated datasets.",5.1 Evaluation Datasets,[0],[0]
"The last 3 datasets of three domains (products) are from (Liu et al., 2016).",5.1 Evaluation Datasets,[0],[0]
These datasets are used to make up our CRF training data Dt and test data Dn+1.,5.1 Evaluation Datasets,[0],[0]
"The annotation details are given in Table 2.
",5.1 Evaluation Datasets,[0],[0]
"The second type has 50 unlabeled review datasets from 50 domains or types of products (Chen and Liu, 2014).",5.1 Evaluation Datasets,[0],[0]
Each dataset has 1000 reviews.,5.1 Evaluation Datasets,[0],[0]
"They are used as the past domain data, i.e., D1, . . .",5.1 Evaluation Datasets,[0],[0]
", Dn (n = 50).",5.1 Evaluation Datasets,[0],[0]
"Since they are not labeled, they cannot be used for training or testing.",5.1 Evaluation Datasets,[0],[0]
We compare L-CRF with CRF.,5.2 Baseline Methods,[0],[0]
"We will not compare with unsupervised methods, which have been shown improvable by lifelong learning (Chen et al., 2014; Liu et al., 2016).",5.2 Baseline Methods,[0],[0]
"The frequency threshold λ in Algorithm 1 used in our experiment to judge which extracted aspects are considered reliable is empirically set to 2.
",5.2 Baseline Methods,[0],[0]
CRF:,5.2 Baseline Methods,[0],[0]
We use the linear chain CRF from 2.,5.2 Baseline Methods,[0],[0]
"Note that CRF uses all features including dependency features as the proposed L-CRF but does not employ the 50 domains unlabeled data used for lifelong learning
CRF+R:",5.2 Baseline Methods,[0],[0]
It treats the reliable aspect set K as a dictionary.,5.2 Baseline Methods,[0],[0]
It adds those reliable aspects in K that are not extracted by CRF but are in the test data to the final results.,5.2 Baseline Methods,[0],[0]
"We want to see whether incorporating K into the CRF extraction through dependency patterns in L-CRF is actually needed.
",5.2 Baseline Methods,[0],[0]
We do not compare with domain adaptation or transfer learning because domain adaption basically uses the source domain labeled data to help learning in the target domain with few or no labeled data.,5.2 Baseline Methods,[0],[0]
Our 50 domains used in lifelong learning have no labels.,5.2 Baseline Methods,[0],[0]
So they cannot help in transfer learning.,5.2 Baseline Methods,[0],[0]
"Although in transfer learning, the target domain usually has a large quantity of unlabeled data, but the 50 domains are not used as the target domains in our experiments.
",5.2 Baseline Methods,[0],[0]
2https://github.com/huangzhengsjtu/pcrf/,5.2 Baseline Methods,[0],[0]
"To compare the systems using the same training and test data, for each dataset we use 200 sentences for training and 200 sentences for testing to avoid bias towards any dataset or domain because we will combine multiple domain datasets for CRF training.",5.3 Experiment Setting,[0],[0]
We conducted both cross-domain and in-domain tests.,5.3 Experiment Setting,[0],[0]
Our problem setting is crossdomain.,5.3 Experiment Setting,[0],[0]
In-domain is used for completeness.,5.3 Experiment Setting,[0],[0]
"In both cases, we assume that extraction has been done for the 50 domains.
Cross-domain experiments: We combine 6 labeled domain datasets for training (1200 sentences) and test on the 7th domain (not used in training).",5.3 Experiment Setting,[0],[0]
This gives us 7 cross-domain results.,5.3 Experiment Setting,[0],[0]
"This set of tests is particularly interesting as it is desirable to have the trained model used in crossdomain situations to save manual labeling effort.
",5.3 Experiment Setting,[0],[0]
In-domain experiments: We train and test on the same 6 domains (1200 sentences for training and 1200 sentences for testing).,5.3 Experiment Setting,[0],[0]
"This also gives us 7 in-domain results.
",5.3 Experiment Setting,[0],[0]
"Evaluating Measures: We use the popular precision P , recallR, and F1-score.",5.3 Experiment Setting,[0],[0]
All the experiment results are given in Table 3.,5.4 Results and Analysis,[0],[0]
Cross-domain: Each −X in column 1 means that domain X is not used in training.,5.4 Results and Analysis,[0],[0]
"X in col-
umn 2 means that domain X is used in testing.",5.4 Results and Analysis,[0],[0]
We can see that L-CRF is markedly better than CRF and CRF+R in F1.,5.4 Results and Analysis,[0],[0]
"CRF+R is very poor due to poor precisions, which shows treating the reliable aspects set K as a dictionary isn’t a good idea.
",5.4 Results and Analysis,[0],[0]
In-domain: −X in training and test columns means that the other 6 domains are used in both training and testing (thus in-domain).,5.4 Results and Analysis,[0],[0]
We again see that L-CRF is consistently better than CRF and CRF+R in F1.,5.4 Results and Analysis,[0],[0]
The amount of gain is smaller.,5.4 Results and Analysis,[0],[0]
This is expected because most aspects appeared in training probably also appear in the test data as they are reviews from the same 6 products.,5.4 Results and Analysis,[0],[0]
This paper proposed a lifelong learning method to enable CRF to leverage the knowledge gained from extraction results of previous domains (unlabeled) to improve its extraction.,6 Conclusion,[0],[0]
Experimental results showed the effectiveness of L-CRF.,6 Conclusion,[0],[0]
The current approach does not change the CRF model itself.,6 Conclusion,[0],[0]
"In our future work, we plan to modify CRF so that it can consider previous extraction results as well as the knowledge in previous CRF models.",6 Conclusion,[0],[0]
This work was supported in part by grants from National Science Foundation (NSF) under grant no.,Acknowledgments,[0],[0]
IIS-1407927 and IIS-1650900.,Acknowledgments,[0],[0]
This paper makes a focused contribution to supervised aspect extraction.,abstractText,[0],[0]
"It shows that if the system has performed aspect extraction from many past domains and retained their results as knowledge, Conditional Random Fields (CRF) can leverage this knowledge in a lifelong learning manner to extract in a new domain markedly better than the traditional CRF without using this prior knowledge.",abstractText,[0],[0]
"The key innovation is that even after CRF training, the model can still improve its extraction with experiences in its applications.",abstractText,[0],[0]
Lifelong Learning CRF for Supervised Aspect Extraction,title,[0],[0]
"Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 225–235, Austin, Texas, November 1-5, 2016. c©2016 Association for Computational Linguistics",text,[0],[0]
"A core problem of opinion mining or sentiment analysis is to identify each opinion/sentiment target and to classify the opinion/sentiment polarity on the target (Liu, 2012).",1 Introduction,[0],[0]
"For example, in a review sentence for a car, one wrote “Although the engine is slightly weak, this car is great.”",1 Introduction,[0],[0]
"The person is positive (opinion polarity) about the car (opinion target) as a whole, but slightly negative (opinion polarity) about the car’s engine (opinion target).
",1 Introduction,[0],[0]
"Past research has proposed many techniques to extract opinion targets (we will just call them targets
hereafter for simplicity) and also to classify sentiment polarities on the targets.",1 Introduction,[0],[0]
"However, a target can be an entity or an aspect (part or attribute) of an entity.",1 Introduction,[0],[0]
"“Engine” in the above sentence is just one aspect of the car, while “this car” refers to the whole car.",1 Introduction,[0],[0]
"Note that in (Liu, 2012), an entity is called a general aspect.",1 Introduction,[0],[0]
"For effective opinion mining, we need to classify whether a target is an entity or an aspect because they refer to very different things.",1 Introduction,[0],[0]
"One can be positive about the whole entity (car) but negative about some aspects of it (e.g., engine) and vice versa.",1 Introduction,[0],[0]
"This paper aims to perform the target classification task, which, to our knowledge, has not been attempted before.",1 Introduction,[0],[0]
"Although in supervised extraction one can annotate entities and aspects with separate labels in the training data to build a model to extract them separately, in this paper our goal is to help unsupervised target extraction methods to classify targets.",1 Introduction,[0],[0]
"Unsupervised target extraction methods are often preferred because they save the time-consuming data labeling or annotation step for each domain.
",1 Introduction,[0],[0]
Problem Statement:,1 Introduction,[0],[0]
"Given a set of opinion targets T = {t1, . . .",1 Introduction,[0],[0]
", tn} extracted from an opinion corpus d, we want to classify each target ti ∈ T into one of the three classes, entity, aspect, or NIL, which are called class labels.",1 Introduction,[0],[0]
"NIL means that the target is neither an entity nor an aspect and is used because target extraction algorithms can make mistakes.
",1 Introduction,[0],[0]
This paper does not propose a new target extraction algorithm.,1 Introduction,[0],[0]
"We use an existing unsupervised method, called Double Propagation (DP) (Qiu et al., 2011), for extraction.",1 Introduction,[0],[0]
We only focus on target classification after the targets have been extracted.,1 Introduction,[0],[0]
"Note that an entity here can be a named entity, a prod-
225
uct category, or an abstract product (e.g., “this machine” and “this product”).",1 Introduction,[0],[0]
"An named entity can be the name of a brand, a model, or a manufacturer.",1 Introduction,[0],[0]
"An aspect is a part or attribute of an entity, e.g., “battery” and “price” of the entity “camera”.
",1 Introduction,[0],[0]
"Since our entities not just include the traditional named entities (e.g., “Microsoft” and “Google”) but also other expressions that refer to such entities, traditional named entity recognition algorithms are not sufficient.",1 Introduction,[0],[0]
"Pronouns such as “it,” “they,” etc., are not considered in this paper as co-reference resolution is out of the scope of this work.
",1 Introduction,[0],[0]
We solve this problem in an unsupervised manner so that there is no need for labor-intensive manual labeling of the training data.,1 Introduction,[0],[0]
"One key observation of the problem is that although entities and aspects are different, they are closely related because aspects are parts or attributes of entities and they often have syntactic relationships in a sentence, e.g., “This phone’s screen is super.”",1 Introduction,[0],[0]
Thus it is natural to solve the problem using a relational learning method.,1 Introduction,[0],[0]
"We employ the graph labeling algorithm, Relaxation Labeling (RL) (Hummel and Zucker, 1983), which performs unsupervised belief propagation on a graph.",1 Introduction,[0],[0]
"In our case, each target extracted from the given corpus d forms a graph node and each relation identified in d between two targets forms an edge.",1 Introduction,[0],[0]
"With some initial probability assignments, RL can assign each target node the most probable class label.",1 Introduction,[0],[0]
"Although some other graph labeling methods can be applied as well, the key issue here is that just using a propagation method in isolation is far from sufficient due to lack of information from the given corpus, which we detail in Section 5.",1 Introduction,[0],[0]
"We then employ Lifelong Machine Learning (LML) (Thrun, 1998; Chen and Liu, 2014b) to make a major improvement.
",1 Introduction,[0],[0]
LML works as follows: The learner has performed a number learning tasks in the past and has retained the knowledge gained so far.,1 Introduction,[0],[0]
"In the new/current task, it makes use of the past knowledge to help current learning and problem solving.",1 Introduction,[0],[0]
"Since RL is unsupervised, we can assume that the system has performed the same task on reviews of a large number of products/domains (or corpora).",1 Introduction,[0],[0]
It has also saved all the graphs and classification results from those past domains in a Knowledge Base (KB).,1 Introduction,[0],[0]
It then exploits this past knowledge to help classification in the current task/domain.,1 Introduction,[0],[0]
"We call this
combined approach of relaxation labeling and LML Lifelong-RL.",1 Introduction,[0],[0]
"The approach is effective because there is a significant amount of sharing of targets and target relations across domains.
",1 Introduction,[0],[0]
LML is different from the classic learning paradigm (supervised or unsupervised) because classic learning has no memory.,1 Introduction,[0],[0]
"It basically runs a learning algorithm on a given data in isolation without considering any past learned knowledge (Silver et al., 2013).",1 Introduction,[0],[0]
"LML aims to mimic human learning, which always retains the learned knowledge from the past and uses it to help future learning.
",1 Introduction,[0],[0]
Our experimental results show that the proposed Lifelong-RL system is highly promising.,1 Introduction,[0],[0]
The paradigm of LML helps improve the classification results greatly.,1 Introduction,[0],[0]
"Although many target extraction methods exist (Hu and Liu, 2004; Zhuang et al., 2006; Ku et al., 2006; Wang and Wang, 2008; Wu et al., 2009; Lin and He, 2009; Zhang et al., 2010; Mei et al., 2007; Li et al., 2010; Brody and Elhadad, 2010; Wang et al., 2010; Mukherjee and Liu, 2012; Fang and Huang, 2012; Zhou et al., 2013; Liu et al., 2013; Poria et al., 2014), we are not aware of any attempt to solve the proposed problem.",2 Related Work,[0],[0]
"As mentioned in the introduction, although in supervised target extraction, one can annotate entities and aspects with different labels, supervised methods need manually labeled training data, which is time-consuming and laborintensive to produce (Jakob and Gurevych, 2010; Choi and Cardie, 2010; Mitchell et al., 2013).",2 Related Work,[0],[0]
"Note that relaxation labeling was used for sentiment classification in (Popescu and Etzioni, 2007), but not for target classification.",2 Related Work,[0],[0]
"More details of opinion mining can be found in (Liu, 2012; Pang and Lee, 2008).
",2 Related Work,[0],[0]
"Our work is related to transfer learning (Pan and Yang, 2010), which uses the source domain labeled data to help target domain learning, which has little or no labeled data.",2 Related Work,[0],[0]
Our work is not just using a source domain to help a target domain.,2 Related Work,[0],[0]
It is a continuous and cumulative learning process.,2 Related Work,[0],[0]
Each new task can make use of the knowledge learned from all past tasks.,2 Related Work,[0],[0]
Knowledge learned from the new task can also help improve learning of any past task.,2 Related Work,[0],[0]
"Transfer learning is not continuous, does not
accumulate knowledge over time and cannot improve learning in the source domain.",2 Related Work,[0],[0]
"Our work is also related to multi-task learning (Caruana, 1997), which jointly optimizes a set of related learning tasks.",2 Related Work,[0],[0]
"Clearly, multi-task learning is different as we learn and save information which is more realistic when a large number of tasks are involved.
",2 Related Work,[0],[0]
Our work is most related to Lifelong Machine Learning (LML).,2 Related Work,[0],[0]
"Traditional LML focuses on supervised learning (Thrun, 1998; Ruvolo and Eaton, 2013; Chen et al., 2015).",2 Related Work,[0],[0]
"Recent work used LML in topic modeling (Chen and Liu, 2014a), which is unsupervised.",2 Related Work,[0],[0]
"Basically, they used topics generated from past domains to help current domain model inference.",2 Related Work,[0],[0]
"However, they are just for aspect extraction.",2 Related Work,[0],[0]
"So is the method in (Liu et al., 2016).",2 Related Work,[0],[0]
They do not solve our problem.,2 Related Work,[0],[0]
Their LML methods are also different from ours as we use a graph and results obtained in the past domains to augment the current task/domain graph to solve the problem.,2 Related Work,[0],[0]
"In this section, we present the proposed general framework of lifelong relaxation labeling (LifelongRL).",3 Lifelong-RL: The General Framework,[0],[0]
"We first give an overview of the relaxation labeling algorithm, which forms the base.",3 Lifelong-RL: The General Framework,[0],[0]
We then incorporate it with the LML capability.,3 Lifelong-RL: The General Framework,[0],[0]
The next two sections detail how this general framework is applied to our proposed task of separating entities and aspects in opinion targets.,3 Lifelong-RL: The General Framework,[0],[0]
Relaxation Labeling (RL) is an unsupervised graphbased label propagation algorithm that works iteratively.,3.1 Relaxation Labeling,[0],[0]
The graph consists of nodes and edges.,3.1 Relaxation Labeling,[0],[0]
Each edge represents a binary relationship between two nodes.,3.1 Relaxation Labeling,[0],[0]
Each node ti in the graph is associated with a multinomial distribution P (L(ti)),3.1 Relaxation Labeling,[0],[0]
(L(ti) being the label of ti) on a label set Y .,3.1 Relaxation Labeling,[0],[0]
"Each edge is associated with two conditional probability distributions P (L(ti)|L(tj)) and P (L(tj)|L(ti)), where P (L(ti)|L(tj)) represents how the label L(tj) influences the label L(ti) and vice versa.",3.1 Relaxation Labeling,[0],[0]
"The neighbors Ne(ti) of a node ti are associated with a weight distribution w(tj |ti) with ∑ tj∈Ne(ti)w(tj |ti) = 1.
",3.1 Relaxation Labeling,[0],[0]
"Given the initial values of these quantities as inputs, RL iteratively updates the label distribution
of each node until convergence.",3.1 Relaxation Labeling,[0],[0]
"Initially, we have P 0(L(ti)).",3.1 Relaxation Labeling,[0],[0]
Let ∆P r+1(L(ti)),3.1 Relaxation Labeling,[0],[0]
be the change of P (L(ti)) at iteration r+ 1.,3.1 Relaxation Labeling,[0],[0]
"Given P r(L(ti)) at iteration r, ∆P r+1(L(ti)) is computed by:
∆P r+1(L(ti))",3.1 Relaxation Labeling,[0],[0]
"= ∑
tj∈Ne(ti)(w(tj |ti) ·∑y∈Y (P (L(ti)|L(tj) = y)P r(L(tj) = y)))",3.1 Relaxation Labeling,[0],[0]
"(1) Then, the updated label distribution for iteration
r + 1, P r+1(L(ti)), is computed as follows:
P r+1(L(ti))",3.1 Relaxation Labeling,[0],[0]
"= P r(L(ti))(1+∆P
r+1(L(ti)))∑ y∈Y P r(L(ti)=y)(1+∆P r+1(L(ti)=y))
(2)
",3.1 Relaxation Labeling,[0],[0]
"Once RL ends, the final label of node ti is its highest probable label: L(ti) =",3.1 Relaxation Labeling,[0],[0]
"argmax
y∈Y (P (L(ti) = y)).
",3.1 Relaxation Labeling,[0],[0]
Note that P (L(ti)|L(tj)) and w(tj |ti) are not updated in each RL iteration but only P (L(ti)) is.,3.1 Relaxation Labeling,[0],[0]
"P (L(ti)|L(tj)), w(tj |ti) and P 0(L(ti)) are provided by the user or computed based on the application context.",3.1 Relaxation Labeling,[0],[0]
RL uses these values as input and iteratively updates P (L(ti)) based on Equations (1) and (2) until convergence.,3.1 Relaxation Labeling,[0],[0]
Next we discuss how to incorporate LML in RL.,3.1 Relaxation Labeling,[0],[0]
"For LML, it is assumed that at any time step, the system has worked on u past domain corpora D = {d1, . . .",3.2 Lifelong Relaxation Labeling,[0],[0]
", du}.",3.2 Lifelong Relaxation Labeling,[0],[0]
"For each past domain corpus d ∈ D, the same Lifelong-RL algorithm was applied and its results were saved in the Knowledge Base (KB).",3.2 Lifelong Relaxation Labeling,[0],[0]
Then the algorithm can borrow some useful prior/past knowledge in the KB to help RL in the new/current domain du+1.,3.2 Lifelong Relaxation Labeling,[0],[0]
"Once the results of the current domain are produced, they are also added to the KB for future use.
",3.2 Lifelong Relaxation Labeling,[0],[0]
"We now detail the specific types of information or knowledge that can be obtained from the past domains to help RL in the future, which should thus be stored in the KB.
1.",3.2 Lifelong Relaxation Labeling,[0],[0]
"Prior edges: In many applications, the graph is not given.",3.2 Lifelong Relaxation Labeling,[0],[0]
"Instead, it has to be constructed based on the data from the new task/domain data du+1.",3.2 Lifelong Relaxation Labeling,[0],[0]
"However, due to the limited data in du+1, some edges between nodes that should be present are not extracted from the data.",3.2 Lifelong Relaxation Labeling,[0],[0]
"But such edges between the nodes may exist in
some past domains.",3.2 Lifelong Relaxation Labeling,[0],[0]
"Then, those edges and their associated probabilities can be borrowed.
2.",3.2 Lifelong Relaxation Labeling,[0],[0]
Prior labels: Some nodes in the current new domain may also exist in some past domains.,3.2 Lifelong Relaxation Labeling,[0],[0]
Their labels in the past domains are very likely to be the same as those in the current domain.,3.2 Lifelong Relaxation Labeling,[0],[0]
"Then, those prior labels can give us a better idea about the initial label probability distributions of the nodes in the current domain du+1.
",3.2 Lifelong Relaxation Labeling,[0],[0]
"To leverage those edges and labels from the past domains, the system needs to ensure that they are likely to be correct and applicable to the current task domain.",3.2 Lifelong Relaxation Labeling,[0],[0]
This is a challenge problem.,3.2 Lifelong Relaxation Labeling,[0],[0]
"In the next two sections, we detail how to ensure these to a large extent in our application context along with how to compute those initial probabilities.",3.2 Lifelong Relaxation Labeling,[0],[0]
We now discuss how the proposed Lifelong-RL general framework is applied to solve our problem.,4 Initialization of Relaxation Labeling,[0],[0]
"In our case, each node in the graph is an extracted target ti ∈ T , and each edge represents a binary relationship between two targets.",4 Initialization of Relaxation Labeling,[0],[0]
"T is the given set of all opinion targets extracted by an extraction algorithm from a review dataset/corpus d. The label set for each target is Y = {entity, aspect,NIL}.",4 Initialization of Relaxation Labeling,[0],[0]
"In this section, we describe how to use text clues in the corpus d to compute P (L(ti)|L(tj)), w(tj |ti) and P 0(L(ti)).",4 Initialization of Relaxation Labeling,[0],[0]
"In the next section, we present how these quantities are improved using prior knowledge from the past domains in the LML fashion.",4 Initialization of Relaxation Labeling,[0],[0]
"We use two kinds of text clues, called type modifiers M(t) and relation modifiers MR to compute the initial label distribution P (L(ti)) and conditional label distribution P (L(ti)|L(tj)) respectively.
",4.1 Text Clues for Initialization,[0],[0]
Type Modifier:,4.1 Text Clues for Initialization,[0],[0]
"This has two kinds MT = {mE ,mA}, where mE and mA represent entity modifier and aspect modifier respectively.",4.1 Text Clues for Initialization,[0],[0]
"For example, the word “this” as in “this camera is great” indicates that “camera” is probably an entity.",4.1 Text Clues for Initialization,[0],[0]
"Thus, “this” is a type modifier indicating M(camera) = mE .",4.1 Text Clues for Initialization,[0],[0]
“These” is also a type modifier.,4.1 Text Clues for Initialization,[0],[0]
"Aspect modifier is implicitly assumed when the number of appearances of entity modifiers is less than or equal to a threshold (see Section 4.2).
",4.1 Text Clues for Initialization,[0],[0]
Relation Modifier:,4.1 Text Clues for Initialization,[0],[0]
"Given two targets, ti and tj , we use Mtj (ti) to denote the relation modifier that the label of target ti is influenced by the label of target tj .",4.1 Text Clues for Initialization,[0],[0]
"Relation modifiers are further divided into 3 kinds: MR = {mc,mA|E ,mE|A}.
",4.1 Text Clues for Initialization,[0],[0]
Conjunction modifier mc: Conjoined items are usually of the same type.,4.1 Text Clues for Initialization,[0],[0]
"For example, in “price and service”, “and service” indicates a conjunction modifier for “price” and vice versa.
",4.1 Text Clues for Initialization,[0],[0]
Entity-aspect modifier mA|E : A possessive expression indicates an entity and an aspect relation.,4.1 Text Clues for Initialization,[0],[0]
"For example, in “the camera’s battery”, “camera” indicates an entity-aspect modifier for “battery”.
",4.1 Text Clues for Initialization,[0],[0]
"Aspect-entity modifier mE|A: Same as above except that “battery” indicates an aspect-entity modifier for “camera”.
",4.1 Text Clues for Initialization,[0],[0]
Modifier Extraction: These modifiers are identified from the corpus d using three syntactic rules.,4.1 Text Clues for Initialization,[0],[0]
“This” and “these” are used to extract type modifier M(t) = mE .,4.1 Text Clues for Initialization,[0],[0]
"CmE (t) is the occurrence count of that modifier on target t, which is used in determining the initial label distribution in Section 4.2.
",4.1 Text Clues for Initialization,[0],[0]
"Relation modifiers are identified by dependency relations conj(ti, tj) and poss(ti, tj) using the Stanford Parser (Klein and Manning, 2003).",4.1 Text Clues for Initialization,[0],[0]
Each occurrence of a relation rule contributes one count of Mtj (ti) for ti and one count of Mti(tj) for tj .,4.1 Text Clues for Initialization,[0],[0]
"We use Cmc,tj (ti), CmA|E ,tj (ti) and CmE|A,tj (ti) to denote the count of tj modifying ti with conjunction, entity-aspect and aspect-entity modifiers respectively.",4.1 Text Clues for Initialization,[0],[0]
"For example, “price and service” will contribute one count to Cmc,price(service) and one count to Cmc,service(price).",4.1 Text Clues for Initialization,[0],[0]
"Similarly, “camera’s battery” will contribute one count to CmA|E ,camera(battery) and one count to CmE|A,battery(camera).",4.1 Text Clues for Initialization,[0],[0]
"The initial label probability distribution of target t is computed based on CmE (t), i.e.,
P 0(L(t))",4.2 Computing Initial Probabilities,[0],[0]
= { PmE (L(t)) if CmE (t) >,4.2 Computing Initial Probabilities,[0],[0]
α PmA(L(t)),4.2 Computing Initial Probabilities,[0],[0]
"if CmE (t) ≤ α
(3) Here, we have two pre-defined distributions: PmE and PmA , which have a higher probability on entity and aspect respectively.",4.2 Computing Initial Probabilities,[0],[0]
"The parameter α is a threshold indicating that if the entity modifier rarely occurs, the target is more likely to be an aspect.",4.2 Computing Initial Probabilities,[0],[0]
"These
values are set empirically (see Section 6).",4.2 Computing Initial Probabilities,[0],[0]
"Let term q(Mtj (ti) = m) be the normalized weight on the count for each kind of relation modifier m ∈MR:
q(Mtj (ti) = m)",4.2 Computing Initial Probabilities,[0],[0]
=,4.2 Computing Initial Probabilities,[0],[0]
"Cm,tj (ti)
Ctj (ti) (4)
where Ctj (ti) = ∑
m∈MR",4.2 Computing Initial Probabilities,[0],[0]
"Cm,tj (ti).",4.2 Computing Initial Probabilities,[0],[0]
"The conditional label distribution P (L(ti)|L(tj)) of ti given the label of tj is the weighted sum over the three kinds of relation modifiers:
P (L(ti)|L(tj))",4.2 Computing Initial Probabilities,[0],[0]
= q(Mtj (ti) = mc) · Pmc(L(ti)|L(tj)),4.2 Computing Initial Probabilities,[0],[0]
+q(Mtj (ti) = mA|E) · PmA|E (L(ti)|L(tj)),4.2 Computing Initial Probabilities,[0],[0]
"+q(Mtj (ti) = mE|A) · PmE|A(L(ti)|L(tj)) (5)
where Pmc , PmA|E , and PmE|A are pre-defined conditional distributions.",4.2 Computing Initial Probabilities,[0],[0]
"They are filled with values to model the label influence from neighbors and can be found in Section 6.
",4.2 Computing Initial Probabilities,[0],[0]
"Finally, target ti’s neighbor weight for target tj , i.e., w(tj |ti), is the ratio of the count of relation modifiers Ctj (ti) over the total of all ti’s neighbors:
w(tj |ti) = Ctj (ti)∑
tj′∈Ne(ti)Ctj′ (ti) (6)
If Ctj (ti) = 0, ti and tj has no edge between them.",4.2 Computing Initial Probabilities,[0],[0]
"Due to the fact that the review corpus du+1 in the current task domain may not be very large and that we use high quality syntactic rules to extract relations to build the graph to ensure precision, the number of relations extracted can be small and insufficient to produce a graph that is information rich with accurate initial probabilities.",5 Using Past Knowledge in Lifelong-RL,[0],[0]
We thus apply LML to help using knowledge learned in the past.,5 Using Past Knowledge in Lifelong-RL,[0],[0]
"The proposed LML process in Lifelong-RL for our task is shown in Figure 1.
",5 Using Past Knowledge in Lifelong-RL,[0],[0]
"Our prior knowledge includes type modifiers, relation modifiers and labels of targets obtained from past domains in D. Each record in the KB is stored as a 9-tuple: (d, ti, tj ,M d(ti),M d(tj), C d m,tj (ti), C d m,ti(tj), L d(ti), L d(tj)) where d ∈ D is a past domain; ti and tj are two targets; Md(ti), Md(tj) are their type
modifiers, Cdm,tj (ti) and C d m,ti(tj) are counts for relation modifiers; Ld(ti) and Ld(tj) are labels decided by RL.",5 Using Past Knowledge in Lifelong-RL,[0],[0]
"For example, the sentence “This camera’s battery is good” forms: (d, camera, battery,mE ,mA, CmE|A,battery(camera)",5 Using Past Knowledge in Lifelong-RL,[0],[0]
"= 1, CmA|E ,camera(battery) = 1, entity, aspect) .",5 Using Past Knowledge in Lifelong-RL,[0],[0]
"It means that in the past domain d, “camera” and “battery” are extracted targets.",5 Using Past Knowledge in Lifelong-RL,[0],[0]
"Since “camera” is followed by “this”, its type modifier is mE .",5 Using Past Knowledge in Lifelong-RL,[0],[0]
"Since “battery” is not identified by an entity modifier, it is mA.",5 Using Past Knowledge in Lifelong-RL,[0],[0]
"The pattern “camera’s battery” contributes one count for both relation modifiers CmE|A,battery(camera) and CmA|E ,camera(battery).",5 Using Past Knowledge in Lifelong-RL,[0],[0]
"RL has labeled “camera” as entity and “battery” as aspect in d.
The next two subsections present how to use the knowledge in the KB to improve the initial assignments for the label distributions, conditional label distributions and neighborhood weight distributions in order to achieve better final labeling/classification results for the current/new domain du+1.",5 Using Past Knowledge in Lifelong-RL,[0],[0]
"If two targets in the current domain corpus have no edge, we can check whether relation modifiers of the same two targets exist in some past domains.",5.1 Exploiting Relation Modifiers in the KB,[0],[0]
"If so, we may be able to borrow them.",5.1 Exploiting Relation Modifiers in the KB,[0],[0]
"But to ensure suitability, two consistency checks are performed.
",5.1 Exploiting Relation Modifiers in the KB,[0],[0]
"Label Consistency Check: Since RL makes mistakes, we need to ensure that relation modifiers in a record in the KB are consistent with target labels in that past domain.",5.1 Exploiting Relation Modifiers in the KB,[0],[0]
"For example, “camera’s battery” is confirmed by “camera” being labeled as entity and “battery” being labeled as aspect in a past domain d ∈ D. Without this consistency, the record may not be reliable and should be discarded from the KB.
",5.1 Exploiting Relation Modifiers in the KB,[0],[0]
"We define an indicator variable Idm,tj (ti) to ensure that the record r’s relation modifier is consistent
with the labels of its two targets:
IdmA|E ,tj (ti) =    1 if CdmA|E ,tj (ti) > 0 and Ld(ti) = aspect and Ld(tj) = entity
0 otherwise
(7)
",5.1 Exploiting Relation Modifiers in the KB,[0],[0]
"For example, if “camera” is labeled as entity and “battery” is labeled as aspect in the past domain d, we have IdmA|E ,camera(battery) = 1 and IdmE|A,battery(camera)",5.1 Exploiting Relation Modifiers in the KB,[0],[0]
"= 1.
",5.1 Exploiting Relation Modifiers in the KB,[0],[0]
Type Consistency Check: Here we ensure the type modifiers for two targets in the current domain du+1 are consistent with these type modifiers in the past domain d ∈ D.,5.1 Exploiting Relation Modifiers in the KB,[0],[0]
This is because an item can be an aspect in one domain but an entity in another.,5.1 Exploiting Relation Modifiers in the KB,[0],[0]
"For example, if the current domain is “Cellphone”, borrowing the relation “camera’s battery” from domain “Camera” can introduce an error because “camera” is an aspect in domain “Cellphone”.
",5.1 Exploiting Relation Modifiers in the KB,[0],[0]
Syntactic pattern “this” is a good indicator for this checking.,5.1 Exploiting Relation Modifiers in the KB,[0],[0]
"In the “Cellphone” domain, “its camera” or “the camera” are often mentioned but not “this camera”.",5.1 Exploiting Relation Modifiers in the KB,[0],[0]
"In the “Camera” domain, “this camera” is often mentioned.",5.1 Exploiting Relation Modifiers in the KB,[0],[0]
"The type modifier of “camera” in “Cellphone” is mA, but in “Camera” it is mE .
",5.1 Exploiting Relation Modifiers in the KB,[0],[0]
Updating Probabilities in Current Domain du+1: Edges for RL are in the forms of conditional label distribution P (L(ti)|L(tj)) and neighborhood weight distribution w(tj |ti).,5.1 Exploiting Relation Modifiers in the KB,[0],[0]
"We now discuss how to use the KB to estimate them more accurately.
",5.1 Exploiting Relation Modifiers in the KB,[0],[0]
"Updating Conditional Label Distribution: Equation (5) tells that conditional label distribution P (L(ti)|L(tj)) is the weighted sum of relation modifiers’ label distributions Pmc , PmA|E , and PmE|A .",5.1 Exploiting Relation Modifiers in the KB,[0],[0]
These 3 label distributions are pre-defined and given in Table 2.,5.1 Exploiting Relation Modifiers in the KB,[0],[0]
They are not changed.,5.1 Exploiting Relation Modifiers in the KB,[0],[0]
"Thus, we update conditional label distribution through updating the three relation modifiers’ weights q(Mtj (ti)) with the knowledge in the KB.",5.1 Exploiting Relation Modifiers in the KB,[0],[0]
"Recall the three relation modifiers are MR = {mc,mA|E ,mE|A}.
",5.1 Exploiting Relation Modifiers in the KB,[0],[0]
"After consistency check, there can be multiple relation modifiers between two targets in similar past domains",5.1 Exploiting Relation Modifiers in the KB,[0],[0]
Ds ⊂ D. The number of domains supporting a relation modifier m ∈ MR can tell which kind of relation modifiers is common and likely to be correct.,5.1 Exploiting Relation Modifiers in the KB,[0],[0]
"For example, given many past domains like “Laptop”, “Tablet”, “Cellphone”, etc., “camera
and battery” appears more than “camera’s battery”, “camera” should be modified by “battery” more with mE|A rather than mc (likely to be an aspect).
",5.1 Exploiting Relation Modifiers in the KB,[0],[0]
"Let Cdu+1m,tj (ti) be the count that target ti modified by target tj on relation m in the current domain du+1 (not in KB).",5.1 Exploiting Relation Modifiers in the KB,[0],[0]
The count C(CL) is for updating the Conditional Label (CL) distributions considering the information in both the current domain du+1 and the KB.,5.1 Exploiting Relation Modifiers in the KB,[0],[0]
"It is calculated as:
C (CL) m,tj (ti) =
{ C du+1 m,tj (ti) if C du+1 m,tj
(ti) >",5.1 Exploiting Relation Modifiers in the KB,[0],[0]
0∑,5.1 Exploiting Relation Modifiers in the KB,[0],[0]
"d∈Ds Idm,tj (ti) if ∑ m∈MR C du+1",5.1 Exploiting Relation Modifiers in the KB,[0],[0]
m,5.1 Exploiting Relation Modifiers in the KB,[0],[0]
",tj (ti)) = 0
",5.1 Exploiting Relation Modifiers in the KB,[0],[0]
"This equation says that if there is any relation modifier existing between the two targets in the new domain du+1, we do not borrow edges from the KB; Otherwise, the number of similar past domains supporting the relation modifier m is used.",5.1 Exploiting Relation Modifiers in the KB,[0],[0]
"Recall that Idm,tj (ti) is the result calculated by Equation (7) after label consistency check.
",5.1 Exploiting Relation Modifiers in the KB,[0],[0]
"We use count C(CL)m,tj (ti) to update q du+1(Mtj (ti)) using Equation (4) in Section 4.2.",5.1 Exploiting Relation Modifiers in the KB,[0],[0]
"Then the conditional label distribution accommodating relation modifiers in the KB, P (LL1)(L(ti)|L(tj)), is calculated by Equation, (5) using qdu+1(Mtj (ti)).",5.1 Exploiting Relation Modifiers in the KB,[0],[0]
"LL1 denotes Lifelong Learning 1.
",5.1 Exploiting Relation Modifiers in the KB,[0],[0]
Updating Neighbor Weight Distribution: Equation (6) says that w(tj |ti) is the importance of target ti’s neighbor tj to ti among all ti’s neighbors.,5.1 Exploiting Relation Modifiers in the KB,[0],[0]
"When updating conditional label distribution using the KB, the number of domains can decide which kind of relation modifiersm is more common between the two targets ti and tj .",5.1 Exploiting Relation Modifiers in the KB,[0],[0]
"But we cannot tell that neighbor tj is more important than another neighbor tj′ to ti.
",5.1 Exploiting Relation Modifiers in the KB,[0],[0]
"For example, given the past domains such as “Laptop”, “Tablet”, “Cellphone”, etc., no matter how many domains believe “camera” is an aspect given “battery” is also an aspect, if the current domain is “All-in-one desktop computer”, we should not consider the strong influences from “battery” in the past domains.",5.1 Exploiting Relation Modifiers in the KB,[0],[0]
We should rely more on the weights of “camera”’s neighbors provided by “Allin-one desktop computer”.,5.1 Exploiting Relation Modifiers in the KB,[0],[0]
"That means “mouse”, “keyboard”, “screen” etc., should have strong influences on “camera” than “battery” because most Allin-one desktops (e.g. iMac) do not have battery.
",5.1 Exploiting Relation Modifiers in the KB,[0],[0]
"We introduce another indicator variable IDm,tj (ti) =",5.1 Exploiting Relation Modifiers in the KB,[0],[0]
"⋃ d∈Ds Idm,tj (ti), to indicate whether target tj modified ti on relation m in past similar domains Ds.",5.1 Exploiting Relation Modifiers in the KB,[0],[0]
"It only considers the existence of a
relation modifier m among domains Ds.",5.1 Exploiting Relation Modifiers in the KB,[0],[0]
The count C(w)tj (ti) for updating the neighbor weight (w) distribution considers both the KB and the current domain du+1.,5.1 Exploiting Relation Modifiers in the KB,[0],[0]
"It is as follows:
C (w) tj (ti) =
{ ∑ m∈MR C du+1 m,tj (ti) if ∑ m∈MR C du+1 m,tj
(ti) >",5.1 Exploiting Relation Modifiers in the KB,[0],[0]
0∑ m∈MR,5.1 Exploiting Relation Modifiers in the KB,[0],[0]
"I Du m,tj (ti) if ∑ m∈MR C du+1 m,tj (ti) = 0
",5.1 Exploiting Relation Modifiers in the KB,[0],[0]
"This equation tells that if there are relation modifiers existing between the two targets in the new domain du+1, we count the total times that tj modifies ti in the new domain; Otherwise, we count the total kinds of relation modifiers in MR if a relation modifier m ∈ MR existed in past domains.",5.1 Exploiting Relation Modifiers in the KB,[0],[0]
Let w(LL1)(tj |ti) be the neighbor weight distribution considering knowledge from the KB and du+1.,5.1 Exploiting Relation Modifiers in the KB,[0],[0]
"It is calculated by Equation (6) using C(w)tj (ti).
",5.1 Exploiting Relation Modifiers in the KB,[0],[0]
"The initial label distribution P du+1,0 is calculated by Equation (3) only using type modifiers found in the new domain du+1.",5.1 Exploiting Relation Modifiers in the KB,[0],[0]
"We use Lifelong-RL-1 to denote the method that employs P (LL1)(L(ti)|L(tj)), w(LL1)(tj |ti) and P du+1,0 as inputs for RL.",5.1 Exploiting Relation Modifiers in the KB,[0],[0]
"Since we have target labels from past domains, we may have a better idea about the initial label probabilities of targets in the current domain du+1.",5.2 Exploiting Target Labels in the KB,[0],[0]
"For example, after labeling domains like “Cellphone”, “Laptop”, “Tablet,” and “E-reader”, we may have a good sense that “camera” is likely to be an aspect.",5.2 Exploiting Target Labels in the KB,[0],[0]
"To use such knowledge, we need to check if the type modifier of target t in the current domain matches those in past domains and only keep those domains that have such a matching type modifier.
",5.2 Exploiting Target Labels in the KB,[0],[0]
Let Ds ⊂ D be the past domains consistent with target t’s type modifier in the current domain du+1.,5.2 Exploiting Target Labels in the KB,[0],[0]
Let CD s (L(t)) be the number of domains in Ds that target t is labeled as L(t).,5.2 Exploiting Target Labels in the KB,[0],[0]
Let λ be the ratio that controls how much we trust knowledge from the KB.,5.2 Exploiting Target Labels in the KB,[0],[0]
"Then the initial label probability distribution P du+1,0 calculated by Equation (3) only using type modifier found in du+1 is replaced by :
P (LL2),0(L(t))",5.2 Exploiting Target Labels in the KB,[0],[0]
"= |D|×P du+1,0(L(t))+λCD
s (L(t))
|D|+λ|D| (8)
Similarly, let Ds ⊂ D be the past domains consistent with both targets ti’s and tj’s type modifiers in du+1.",5.2 Exploiting Target Labels in the KB,[0],[0]
"Let CD s (L(ti), L(tj)) be the number of domains inDs that ti and tj are labeled as L(ti) and
L(tj) respectively.",5.2 Exploiting Target Labels in the KB,[0],[0]
"The conditional label probability distribution accommodating relation modifiers in the KB, P (LL1)(L(ti)|L(tj)), is further updated to P (LL2)(L(ti)|L(tj)) by exploiting the target labels in KB (LL2 denotes Lifelong Learning 2):
P (LL2)(L(ti)|L(tj))",5.2 Exploiting Target Labels in the KB,[0],[0]
= |D|×P,5.2 Exploiting Target Labels in the KB,[0],[0]
"(LL1)(L(ti)|L(tj))+λCD s (L(ti),L(tj))
|D|+λ|D| (9)
",5.2 Exploiting Target Labels in the KB,[0],[0]
"For example, given “this camera”, “battery” in the current domain, we are more likely to consider domains (e.g. “Film Camera”, “DSLR”, but not “Cellphone”) that have entity modifiers on “camera” and aspect modifiers on “battery”.",5.2 Exploiting Target Labels in the KB,[0],[0]
"Then we count the number of those domains that label “camera” as entity and “battery” as aspect: CD s (L(camera) = entity, L(battery) = aspect).",5.2 Exploiting Target Labels in the KB,[0],[0]
"Similarly, we count domains having other types of target labels on “camera” and “battery”.",5.2 Exploiting Target Labels in the KB,[0],[0]
"These counts form an updated conditional label distribution that estimates “camera” as an entity and “battery” as an aspect.
",5.2 Exploiting Target Labels in the KB,[0],[0]
Note that |D,5.2 Exploiting Target Labels in the KB,[0],[0]
"− Ds|, the number of past domains not consistent with targets’ type modifiers, is added to CD s (L(ti) = NIL) and CD s (L(ti) = NIL, L(tj)) for Equations (8) and (9) respectively to make the sum over L(ti) equal to 1.",5.2 Exploiting Target Labels in the KB,[0],[0]
"We use Lifelong-RL to denote this method which uses P (LL2),0(L(t)), P (LL2)(L(ti)|L(tj)) and w(LL1)(tj |ti) as input for RL.",5.2 Exploiting Target Labels in the KB,[0],[0]
We now evaluate the proposed method and compare with baselines.,6 Experiments,[0],[0]
"We use the DP method for target extraction (Qiu et al., 2011).",6 Experiments,[0],[0]
This method uses dependency relations between opinion words and targets to extract targets using seed opinion words.,6 Experiments,[0],[0]
"Since our paper does not focus on extraction, interested readers can refer to (Qiu et al., 2011) for details.",6 Experiments,[0],[0]
Evaluation Datasets: We use two sets of datasets.,6.1 Experiment Settings,[0],[0]
The first set consists of eight (8) annotated review datasets.,6.1 Experiment Settings,[0],[0]
"We use each of them as the new domain data in LML to compute precision, recall, F1 scores.",6.1 Experiment Settings,[0],[0]
"Five of them are from (Hu and Liu, 2004), and the remaining three are from (Liu et al., 2016).",6.1 Experiment Settings,[0],[0]
"They have been used for target extraction, and thus have annotated targets, but no annotation on whether a
target is an entity or aspect.",6.1 Experiment Settings,[0],[0]
"We made this annotation, which is straightforward.",6.1 Experiment Settings,[0],[0]
We used two annotators to annotate the datasets.,6.1 Experiment Settings,[0],[0]
The Cohen’s kappa is 0.84.,6.1 Experiment Settings,[0],[0]
"Through discussion, the annotators got complete agreement.",6.1 Experiment Settings,[0],[0]
Details of the datasets are listed in Table 1.,6.1 Experiment Settings,[0],[0]
Each cell is the number of distinct terms.,6.1 Experiment Settings,[0],[0]
"These datasets are not very large but they are realistic because many products do not have a large number of reviews.
",6.1 Experiment Settings,[0],[0]
The second set consists of unlabeled review datasets from 100 diverse products or domains (Chen and Liu 2014).,6.1 Experiment Settings,[0],[0]
Each domain has 1000 reviews.,6.1 Experiment Settings,[0],[0]
"They are treated as past domain data in LML since they are not annotated and thus cannot be used for computing evaluation measures.
",6.1 Experiment Settings,[0],[0]
"Evaluating Measures: We mainly use precision P , recall R, and F1-score F1 as evaluation measures.",6.1 Experiment Settings,[0],[0]
"We take multiple occurrences of the same target as one count, and only evaluate entities and aspects.",6.1 Experiment Settings,[0],[0]
"We will also give the accuracy results.
",6.1 Experiment Settings,[0],[0]
"Compared Methods: We compare the following methods, including our proposed method, LifelongRL.
NER+TM: NER is Named Entity Recognition.
",6.1 Experiment Settings,[0],[0]
We can regard the extracted terms from a NER system as entities and the rest of the targets as aspects.,6.1 Experiment Settings,[0],[0]
"However, a NER system cannot identify entities such as “this car” from “this car is great.”",6.1 Experiment Settings,[0],[0]
Its result is rather poor.,6.1 Experiment Settings,[0],[0]
"But our type modifier (TM) does that, i.e., if an opinion target appears after “this” or “these” in at least two sentences, TM labels the target as an entity; otherwise an aspect.",6.1 Experiment Settings,[0],[0]
"However, TM cannot extract named entities.",6.1 Experiment Settings,[0],[0]
Its result is also rather poor.,6.1 Experiment Settings,[0],[0]
We thus combine the two methods to give NER+TM as they complement each other very well.,6.1 Experiment Settings,[0],[0]
"To make NER more powerful, we use two NER systems: Stanford-NER 1(Manning et al., 2014) and UIUC-NER2 (Ratinov and Roth, 2009).",6.1 Experiment Settings,[0],[0]
"NER+TM treats the extracted entities by the three systems as entities and the rest of the targets as aspects.
",6.1 Experiment Settings,[0],[0]
"NER+TM+DICT: We run NER+TM on the 100 datasets for LML to get a list of entities, which we call the dictionary (DICT).",6.1 Experiment Settings,[0],[0]
"For a new task, if any target word is in the list, it is treated as an entity; otherwise an aspect.
",6.1 Experiment Settings,[0],[0]
RL:,6.1 Experiment Settings,[0],[0]
This is the base method described in Section 3.,6.1 Experiment Settings,[0],[0]
"It performs relaxation labeling (RL) without the help of LML.
",6.1 Experiment Settings,[0],[0]
Lifelong-RL-1:,6.1 Experiment Settings,[0],[0]
"This performs LML with RL but the current task only uses the relations in the KB from previous tasks (Section 5.1).
",6.1 Experiment Settings,[0],[0]
Lifelong-RL:,6.1 Experiment Settings,[0],[0]
This is our proposed final method.,6.1 Experiment Settings,[0],[0]
"It improves Lifelong-RL-1 by further incorporating target labels in the KB from previous tasks (Section 5.2).
",6.1 Experiment Settings,[0],[0]
"Parameter Settings: RL has 2 initial label distributions PmE and PmA and 3 conditional label distributions Pmc , PmE|A and PmA|E .",6.1 Experiment Settings,[0],[0]
"Like other belief propagation algorithms, these probabilities need to be set empirically, as shown in Table 2.",6.1 Experiment Settings,[0],[0]
The parameter α is set to 1.,6.1 Experiment Settings,[0],[0]
Our LML method has one parameter λ for Lifelong-RL.,6.1 Experiment Settings,[0],[0]
We set it to 0.1.,6.1 Experiment Settings,[0],[0]
"Table 3 shows the test results of all systems in precision, recall and F1-score except NER+TM+DICT.",6.2 Results Analysis,[0],[0]
NER+TM+DICT is not included due to space limitations and because it performed very poorly.,6.2 Results Analysis,[0],[0]
"The reason is that a target can be an entity in one domain
1http://nlp.stanford.edu/software/CRF-NER.shtml 2https://cogcomp.cs.illinois.edu/page/software view/NETagger
but an aspect in another.",6.2 Results Analysis,[0],[0]
"Its average F1-score for entity is only 49.2, and for aspect is only 50.2.
",6.2 Results Analysis,[0],[0]
"Entity Results Comparison: We observe from the table that although NER+TM combines NER and TM, its result for entities is still rather poor.",6.2 Results Analysis,[0],[0]
We notice that phrases like “this price” causes low precision.,6.2 Results Analysis,[0],[0]
"Since it does not use many other relations and NER does not recognize many named entities that are written in lower case letters (e.g., “apple is good”), its recall is also low.
",6.2 Results Analysis,[0],[0]
RL has a higher precision as it considers relation modifiers.,6.2 Results Analysis,[0],[0]
"However, its recall is low because it lacks information in its graph, which causes RL to make many wrong decisions.",6.2 Results Analysis,[0],[0]
Lifelong-RL-1 introduces relation modifiers in KB from past domains into the current task.,6.2 Results Analysis,[0],[0]
"Both precision and recall increase markedly.
",6.2 Results Analysis,[0],[0]
Lifelong-RL improves Lifelong-RL-1 further by considering target labels of past domains.,6.2 Results Analysis,[0],[0]
Their counts improve the initial label probability distributions and conditional label probability distributions.,6.2 Results Analysis,[0],[0]
"For example, “this price” may appear in some domains but “price”’s target label is mostly aspect.",6.2 Results Analysis,[0],[0]
We consider their counts in initial label distributions and thus rectify the initial distribution of “price”.,6.2 Results Analysis,[0],[0]
"This makes “price” easier to be classified as aspect and thus improves the precision for entity.
",6.2 Results Analysis,[0],[0]
Aspect Results,6.2 Results Analysis,[0],[0]
"Comparison: For aspects, the trend is the same but the improvements are not as dramatic as for entity.",6.2 Results Analysis,[0],[0]
This is because the distribution of entity and aspect in the data is highly skewed.,6.2 Results Analysis,[0],[0]
There are many more aspects than entities as we can see from the Table 1.,6.2 Results Analysis,[0],[0]
"When an entity term is wrongly classified as an aspect, it has much less impact on the aspect result than on the entity result.
",6.2 Results Analysis,[0],[0]
"Accuracy Results Comparison: Table 4 gives the classification accuracy results considering all
three classes.",6.2 Results Analysis,[0],[0]
We can see the similar trend.,6.2 Results Analysis,[0],[0]
NER+TM+DICT’s average accuracy is only 45.89 and is not included in the table.,6.2 Results Analysis,[0],[0]
This paper studied the problem of classifying opinion targets into entities and aspects.,7 Conclusion,[0],[0]
"To the best of our knowledge, this problem has not been attempted in the unsupervised opinion target extraction setting.",7 Conclusion,[0],[0]
But this is an important problem because without separating or classifying them one will not know whether an opinion is about an entity as a whole or about a specific aspect of an entity.,7 Conclusion,[0],[0]
This paper proposed a novel method based on relaxation labeling and the paradigm of lifelong machine learning to solve the problem.,7 Conclusion,[0],[0]
Experimental results showed the effectiveness of the proposed method.,7 Conclusion,[0],[0]
"This work was partially supported by National Science Foundation (NSF) grants IIS-1407927 and IIS1650900, and NCI grant R01CA192240.",Acknowledgments,[0],[0]
The content of the paper is solely the responsibility of the authors and does not necessarily represent the official views of the NSF or NCI.,Acknowledgments,[0],[0]
It is well-known that opinions have targets.,abstractText,[0],[0]
"Extracting such targets is an important problem of opinion mining because without knowing the target of an opinion, the opinion is of limited use.",abstractText,[0],[0]
So far many algorithms have been proposed to extract opinion targets.,abstractText,[0],[0]
"However, an opinion target can be an entity or an aspect (part or attribute) of an entity.",abstractText,[0],[0]
"An opinion about an entity is an opinion about the entity as a whole, while an opinion about an aspect is just an opinion about that specific attribute or aspect of an entity.",abstractText,[0],[0]
"Thus, opinion targets should be separated into entities and aspects before use because they represent very different things about opinions.",abstractText,[0],[0]
"This paper proposes a novel algorithm, called Lifelong-RL, to solve the problem based on lifelong machine learning and relaxation labeling.",abstractText,[0],[0]
Extensive experiments show that the proposed algorithm Lifelong-RL outperforms baseline methods markedly.,abstractText,[0],[0]
Lifelong-RL: Lifelong Relaxation Labeling for Separating Entities and Aspects in Opinion Targets,title,[0],[0]
"Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1389–1399, Austin, Texas, November 1-5, 2016. c©2016 Association for Computational Linguistics",text,[0],[0]
"Current successful methods for automated knowledge base construction tasks heavily rely on learned distributed vector representations (Nickel et al., 2012; Riedel et al., 2013; Socher et al., 2013; Chang et al., 2014; Neelakantan et al., 2015; Toutanova et al., 2015; Nickel et al., 2015; Verga et al., 2016;
Verga and McCallum, 2016).",1 Introduction,[0],[0]
"Although these models are able to learn robust representations from large amounts of data, they often lack commonsense knowledge.",1 Introduction,[0],[0]
"Such knowledge is rarely explicitly stated in texts but can be found in resources like PPDB (Ganitkevitch et al., 2013) or WordNet (Miller, 1995).
",1 Introduction,[0],[0]
"Combining neural methods with symbolic commonsense knowledge, for instance in the form of implication rules, is in the focus of current research (Rocktäschel et al., 2014; Wang et al., 2014; Bowman et al., 2015; Wang et al., 2015; Vendrov et al., 2016; Hu et al., 2016; Rocktäschel and Riedel, 2016; Cohen, 2016).",1 Introduction,[0],[0]
"A recent approach (Rocktäschel et al., 2015) regularizes entity-tuple and relation embeddings via first-order logic rules.",1 Introduction,[0],[0]
"To this end, every first-order rule is propositionalized based on observed entity-tuples, and a differentiable loss term is added for every propositional rule.",1 Introduction,[0],[0]
This approach does not scale beyond only a few entity-tuples and rules.,1 Introduction,[0],[0]
"For example, propositionalizing the rule ∀x : isMan(x)⇒ isMortal(x) would result in a very large number of loss terms on a large database.
",1 Introduction,[0],[0]
"In this paper, we present a method to incorporate simple rules while maintaining the computational efficiency of only modeling training facts.",1 Introduction,[0],[0]
"This is achieved by minimizing an upper bound of the loss that encourages the implication between relations to hold, entirely independent from the number of entity pairs.",1 Introduction,[0],[0]
"It only involves representations of the relations that are mentioned in rules, as well as a general rule-independent constraint on the entity-tuple embedding space.",1 Introduction,[0],[0]
"In the example given above, if we require that every component of the
1389
vector representation of isMan is smaller than the corresponding component of relation isMortal, then we can show that the rule holds for any nonnegative representation of an entity-tuple.",1 Introduction,[0],[0]
Hence our method avoids the need for separate loss terms for every ground atom resulting from propositionalizing rules.,1 Introduction,[0],[0]
"In statistical relational learning this type of approach is often referred to as lifted inference or learning (Poole, 2003; Braz, 2007) because it deals with groups of random variables at a first-order level.",1 Introduction,[0],[0]
In this sense our approach is a lifted form of rule injection.,1 Introduction,[0],[0]
This allows for imposing large numbers of rules while learning distributed representations of relations and entity-tuples.,1 Introduction,[0],[0]
"Besides drastically lower computation time, an important advantage of our method over Rocktäschel et al. (2015) is that when these constraints are satisfied, the injected rules always hold, even for unseen but inferred facts.",1 Introduction,[0],[0]
"While the method presented here only deals with implications and not general first-order rules, it does not rely on the assumption of independence between relations, and is hence more generally applicable.
",1 Introduction,[0],[0]
"Our contributions are fourfold: (i) we develop a very efficient way of regularizing relation representations to incorporate first-order logic implications (§3), (ii) we reveal that, against expectation, mapping entity-tuple embeddings to non-negative space does not hurt but instead improves the generalization ability of our model (§5.1) (iii) we show improvements on a knowledge base completion task by injecting mined commonsense rules from WordNet (§5.3), and finally (iv) we give a qualitative analysis of the results, demonstrating that implication constraints are indeed satisfied in an asymmetric way and result in a substantially increased structuring of the relation embedding space (§5.6).",1 Introduction,[0],[0]
In this section we revisit the matrix factorization relation extraction model by Riedel et al. (2013) and introduce the notation used throughout the paper.,2 Background,[0],[0]
"We choose the matrix factorization model for its simplicity as the base on which we develop implication injection.
",2 Background,[0],[0]
"Riedel et al. (2013) represent every relation r ∈ R (selected from Freebase (Bollacker et al., 2008) or extracted as textual surface pattern) by a k-
dimensional latent representation r ∈ Rk.",2 Background,[0],[0]
"A particular relation instance or fact is the combination of a relation r and a tuple t of entities that are engaged in that relation, and is written as 〈r, t〉.",2 Background,[0],[0]
We write O as the set of all such input facts available for training.,2 Background,[0],[0]
"Furthermore, every entity-tuple t ∈ T is represented by a latent vector t ∈ Rk (with T the set of all entity-tuples in O).
",2 Background,[0],[0]
Model F by Riedel et al. (2013) measures the compatibility between a relation r and an entitytuple t using the dot product r>t of their respective vector representations.,2 Background,[0],[0]
"During training, the representations are learned such that valid facts receive high scores, whereas negative ones receive low scores.",2 Background,[0],[0]
"Typically no negative evidence is available at training time, and therefore a Bayesian Personalized Ranking (BPR) objective (Rendle et al., 2009) is used.",2 Background,[0],[0]
"Given a pair of facts fp := 〈rp, tp〉 6∈",2 Background,[0],[0]
"O and fq := 〈rq, tq",2 Background,[0],[0]
"〉 ∈ O, this objective requires that
r>p tp ≤ r>q tq.",2 Background,[0],[0]
"(1)
The embeddings can be trained by minimizing a convex loss function `R that penalizes violations of that requirement when iterating over the training set.",2 Background,[0],[0]
"In practice, each positive training fact 〈r, tq〉 is compared with a randomly sampled unobserved fact 〈r, tp〉 for the same relation.",2 Background,[0],[0]
"The overall loss can hence be written as
LR = ∑
〈r,tq〉∈O tp∈T , 〈r,tp〉6∈O
`R ( r>[tp − tq] ) .",2 Background,[0],[0]
"(2)
and measures how well observed valid facts are ranked above unobserved facts, thus reconstructing the ranking of the training data.",2 Background,[0],[0]
"We will henceforth call LR the reconstruction loss, to make a distinction with the implication loss that we will introduce later.",2 Background,[0],[0]
"Riedel et al. (2013) use the logistic loss `R(s) := − log σ(−s), where σ(s) := (1 + e−x)−1 denotes the sigmoid function.",2 Background,[0],[0]
"In order to avoid overfitting, an L2 regularization term on the r and t embeddings is added to the reconstruction loss.",2 Background,[0],[0]
"The overall objective to minimize hence is
LF = LR + α (∑ r‖r‖22 + ∑ t‖t‖22 )
(3)
where α is the regularization strength.",2 Background,[0],[0]
"In this section, we show how an implication
∀t ∈ T : 〈rp, t〉 ⇒ 〈rq, t〉, (4)
can be imposed independently of the entity-tuples.",3 Lifted Injection of Implications,[0],[0]
"For simplicity, we abbreviate such implications as rp ⇒ rq (e.g., professorAt⇒ employeeAt).",3 Lifted Injection of Implications,[0],[0]
The implication rule can be imposed by requiring that every tuple t ∈ T is at least as compatible with relation rp as with rq.,3.1 Grounded Loss Formulation,[0],[0]
"Written in terms of the latent representations, eq. (4) therefore becomes
∀t ∈ T :",3.1 Grounded Loss Formulation,[0],[0]
"r>p t ≤ r>q t (5)
",3.1 Grounded Loss Formulation,[0],[0]
"If 〈rp, t〉 is a true fact with a high score r>p t, and the fact 〈rq, t〉 has an even higher score, it must also be true, but not vice versa.",3.1 Grounded Loss Formulation,[0],[0]
"We can therefore inject an implication rule by minimizing a loss term with a separate contribution from every t ∈ T , adding up to the total loss if the corresponding inequality is not satisfied.",3.1 Grounded Loss Formulation,[0],[0]
"In order to make the contribution of every tuple t to that loss independent of the magnitude of the tuple embedding, we divide both sides of the above inequality by ‖t‖1.",3.1 Grounded Loss Formulation,[0],[0]
"With t̃ := t/‖t‖1, the implication loss for the rule rp ⇒ rq can be written as
LI = ∑ ∀t∈T `I ( [rp − rq]>t̃ ) (6)
for an appropriate convex loss function `I , similarly to eq.",3.1 Grounded Loss Formulation,[0],[0]
(2).,3.1 Grounded Loss Formulation,[0],[0]
"In practice, the summation can be reduced to those tuples that occur in combination with rp or rq in the training data.",3.1 Grounded Loss Formulation,[0],[0]
"Still, the propositionalization in terms of training facts leads to a heavy computational cost for imposing a single implication, similar to the technique introduced in Rocktäschel et al. (2015).",3.1 Grounded Loss Formulation,[0],[0]
"Moreover, with that simplification there is no guarantee that the implication between both relations would generalize towards inferred facts not seen during training.",3.1 Grounded Loss Formulation,[0],[0]
"The problems mentioned above can be avoided if instead of LI , a tuple-independent upper bound is minimized.",3.2 Lifted Loss Formulation,[0],[0]
"Such a bound can be constructed, provided all components of t are restricted to a nonnegative embedding space, i.e., T ⊆ Rk,+.",3.2 Lifted Loss Formulation,[0],[0]
"If this
holds, Jensen’s inequality allows us to transform eq.",3.2 Lifted Loss Formulation,[0],[0]
"(6) as follows
LI = ∑
∀t∈T `I
( k∑
i=1
t̃i [rp − rq]>1i )
(7)
≤ k∑
i=1
`I ( [rp − rq]>1i )",3.2 Lifted Loss Formulation,[0],[0]
"∑
∀t∈T t̃i (8)
where 1i is the unit vector along dimension i in tuple-space.",3.2 Lifted Loss Formulation,[0],[0]
"This is allowed because the {t̃i}ki=1 form convex coefficients (t̃i > 0, and ∑ i t̃i = 1), and `I is a convex function.",3.2 Lifted Loss Formulation,[0],[0]
"If we define
LUI := k∑
i=1
`I ( [rp − rq]>1i ) (9)
we can write LI ≤ βLUI",3.2 Lifted Loss Formulation,[0],[0]
"(10) in which β is an upper bound on ∑
t t̃i.",3.2 Lifted Loss Formulation,[0],[0]
"One such bound is |T |, but others are conceivable too.",3.2 Lifted Loss Formulation,[0],[0]
In practice we rescale β to a hyper-parameter β̃ that we use to control the impact of the upper bound to the overall loss.,3.2 Lifted Loss Formulation,[0],[0]
"We call LUI the lifted loss, as it no longer depends on any of the entity-tuples; it is grounded over the unit tuples 1i instead.
",3.2 Lifted Loss Formulation,[0],[0]
The implication rp ⇒ rq can thus be imposed by minimizing the lifted loss LUI .,3.2 Lifted Loss Formulation,[0],[0]
"Note that by minimizing LUI , the model is encouraged to satisfy the constraint",3.2 Lifted Loss Formulation,[0],[0]
"rp ≤ rq on the relation embeddings, where ≤ denotes the component-wise comparison.",3.2 Lifted Loss Formulation,[0],[0]
"In fact, a sufficient condition for eq. (5) to hold, is
rp ≤ rq and ∀t ∈ T :",3.2 Lifted Loss Formulation,[0],[0]
"t ≥ 0 (11)
with 0 the k-dimensional null vector.",3.2 Lifted Loss Formulation,[0],[0]
"This corresponds to a single relation-specific loss term, and the general restriction T ⊆ Rk,+ on the tupleembedding space.",3.2 Lifted Loss Formulation,[0],[0]
"In order to impose implications by minimizing a lifted loss LUI , the tuple-embedding space needs to be restricted to Rk,+.",3.3 Approximately Boolean Entity Tuples,[0],[0]
"We have chosen to restrict the tuple space even more than required, namely to the hypercube t ∈",3.3 Approximately Boolean Entity Tuples,[0],[0]
"[0, 1]k, as approximately Boolean embeddings (Kruszewski et al., 2015).",3.3 Approximately Boolean Entity Tuples,[0],[0]
"The tuple
embeddings are constructed from real-valued vectors e, using the component-wise sigmoid function
t = σ(e), e ∈ Rk.",3.3 Approximately Boolean Entity Tuples,[0],[0]
"(12)
",3.3 Approximately Boolean Entity Tuples,[0],[0]
"For minimizing the loss, the gradients are hence computed with respect to e, and the L2 regularization is applied to the components of e instead of t.
Other choices for ensuring the restriction t ≥ 0 in eq.",3.3 Approximately Boolean Entity Tuples,[0],[0]
"(11) are possible, but we found that our approach works better in practice than those (e.g., the exponential transformation proposed by Demeester et al. (2016)).",3.3 Approximately Boolean Entity Tuples,[0],[0]
"It can also be observed that the unit tuples over which the implication loss is grounded, form a special case of approximately Boolean embeddings.
",3.3 Approximately Boolean Entity Tuples,[0],[0]
"In order to investigate the impact of this restriction even when not injecting any rules, we introduce model FS: the original model F, but with sigmoidal entity-tuples:
LFS = ∑
〈r,tq〉∈O tp∈T , 〈r,tp〉6∈O
`R ( r>[σ(ep)− σ(eq)] )
+ α (∑ r‖r‖22 + ∑ e‖e‖22 )
(13)
Here, ep and eq are the real-valued representations as in eq.",3.3 Approximately Boolean Entity Tuples,[0],[0]
"(12), for tuples tp and tq, respectively.
",3.3 Approximately Boolean Entity Tuples,[0],[0]
"With the above choice of a non-negative tupleembedding space we can now state the full lifted rule injection model (FSL):
LFSL = LFS + β̃ ∑
I∈I LUI (14)
LUI denotes a lifted loss term for every rule in a set I of implication rules that we want to inject.",3.3 Approximately Boolean Entity Tuples,[0],[0]
The logistic loss `R (see §2) is not suited for imposing implications because once the inequality in eq.,3.4 Convex Implication Loss,[0],[0]
"(11) is satisfied, the components of rp and rq do not need to be separated any further.",3.4 Convex Implication Loss,[0],[0]
"However, with `R this would continue to happen due to the small non-zero gradient.",3.4 Convex Implication Loss,[0],[0]
In the reconstruction loss LR this is a desirable effect which further separates the scores for positive from negative examples.,3.4 Convex Implication Loss,[0],[0]
"However, if an implication is imposed between two relations that are almost equivalent according to the
training data, we still want to find almost equivalent embedding vectors.",3.4 Convex Implication Loss,[0],[0]
"Hence, we propose to use the loss
`I(s) = max(0, s+ δ) (15)
with δ a small positive margin to ensure that the gradient does not disappear before the inequality is actually satisfied.",3.4 Convex Implication Loss,[0],[0]
"We use δ = 0.01 in all experiments.
",3.4 Convex Implication Loss,[0],[0]
"The main advantage of the presented approach over earlier methods that impose the rules in a grounded way (Rocktäschel et al., 2015; Wang et al., 2015) is the computational efficiency of imposing the lifted loss.",3.4 Convex Implication Loss,[0],[0]
Evaluating LUI or its gradient for one implication rule is comparable to evaluating the reconstruction loss for one pair of training facts.,3.4 Convex Implication Loss,[0],[0]
In typical applications there are much fewer rules than training facts and the extra computation time needed to inject these rules is therefore negligible.,3.4 Convex Implication Loss,[0],[0]
Recent research on combining rules with learned vector representations has been important for new developments in the field of knowledge base completion.,4 Related Work,[0],[0]
Rocktäschel et al. (2014) and Rocktäschel et al. (2015) provided a framework to jointly maximize the probability of observed facts and propositionalized first-order logic rules.,4 Related Work,[0],[0]
Wang et al. (2015) demonstrated how different types of rules can be incorporated using an Integer Linear Programming approach.,4 Related Work,[0],[0]
Wang and Cohen (2016) learned embeddings for facts and first-order logic rules using matrix factorization.,4 Related Work,[0],[0]
"Yet, all of these approaches ground the rules in the training data, limiting their scalability towards large rule sets and KBs with many entities.",4 Related Work,[0],[0]
"As argued in the introduction, this forms an important motivation for the lifted rule injection model put forward in this work, which by construction does not suffer from that limitation.",4 Related Work,[0],[0]
"Wei et al. (2015) proposed an alternative strategy to tackle the scalability problem by reasoning on a filtered subset of grounded facts.
",4 Related Work,[0],[0]
"Wu et al. (2015) proposed to use a path ranking approach for capturing long-range interactions between entities, and to add these as an extra loss term, besides the loss that models pairwise relations.",4 Related Work,[0],[0]
"Our model FSL differs substantially from their approach, in that we consider tuples instead of separate entities, and we inject a given set of rules.",4 Related Work,[0],[0]
"Yet, by cre-
ating a partial ordering in the relation embeddings as a result of injecting implication rules, model FSL can also capture interactions beyond direct relations.",4 Related Work,[0],[0]
"This will be demonstrated in §5.3 by injecting rules between surface patterns only and still measuring an improvement on predictions for structured Freebase relations.
",4 Related Work,[0],[0]
Combining logic and distributed representations is also an active field of research outside of automated knowledge base completion.,4 Related Work,[0],[0]
"Recent advances include the work by Faruqui et al. (2014), who injected ontological knowledge from WordNet into word representations.",4 Related Work,[0],[0]
"Furthermore, Vendrov et al. (2016) proposed to enforce a partial ordering in an embeddings space of images and phrases.",4 Related Work,[0],[0]
Our method is related to such order embeddings since we define a partial ordering on relation embeddings.,4 Related Work,[0],[0]
"However, to ensure that implications hold for all entity-tuples we also need a restriction on the entitytuple embedding space and derive bounds on the loss.",4 Related Work,[0],[0]
"Another important contribution is the recent work by Hu et al. (2016), who proposed a framework for injecting rules into general neural network architectures, by jointly training on the actual targets and on the rule-regularized predictions provided by a teacher network.",4 Related Work,[0],[0]
"Although quite different at first sight, their work could offer a way to use our model in various neural network architectures, by integrating the proposed lifted loss into the teacher network.
",4 Related Work,[0],[0]
"This paper builds upon our previous workshop paper (Demeester et al., 2016).",4 Related Work,[0],[0]
"In that work, we tested different tuple embedding transformations in an ad-hoc manner.",4 Related Work,[0],[0]
"We used approximately Boolean representations of relations instead of entity-tuples, strongly reducing the model’s degrees of freedom.",4 Related Work,[0],[0]
We now derive the FSL model from a carefully considered mathematical transformation of the grounded loss.,4 Related Work,[0],[0]
"The FSL model only restricts the tuple embedding space, whereby relation vectors remain real valued.",4 Related Work,[0],[0]
"Furthermore, previous experiments were performed on small-scale artificial datasets, whereas we now test on a real-world relation extraction benchmark.
",4 Related Work,[0],[0]
"Finally, we explicitly discuss the main differences with respect to the strongly related work from Rocktäschel et al. (2015).",4 Related Work,[0],[0]
"Their method is more general, as they cover a wide range of first-order logic rules, whereas we only discuss implications.",4 Related Work,[0],[0]
"Lifted
rule injection beyond implications will be studied in future research contributions.",4 Related Work,[0],[0]
"However, albeit less general, our model has a number of clear advantages:
Scalability – Our proposed model of lifted rule injection scales according to the number of implication rules, instead of the number of rules times the number of observed facts for every relation present in a rule.
",4 Related Work,[0],[0]
"Generalizability – Injected implications will hold even for facts not seen during training, because their validity only depends on the order relation imposed on the relation representations.",4 Related Work,[0],[0]
"This is not guaranteed when training on rules grounded in training facts by Rocktäschel et al. (2015).
",4 Related Work,[0],[0]
"Training Flexibility – Our method can be trained with various loss functions, including the rank-based loss as used in Riedel et al. (2013).",4 Related Work,[0],[0]
"This was not possible for the model of Rocktäschel et al. (2015) and already leads to an improved accuracy as seen from the zero-shot learning experiment in §5.2.
",4 Related Work,[0],[0]
Independence Assumption –,4 Related Work,[0],[0]
"In Rocktäschel et al. (2015) an implication of the form ap ⇒ aq for two ground atoms ap and aq is modeled by the logical equivalence ¬(ap ∧ ¬aq), and its probability is approximated in terms of the elementary probabilities π(ap) and π(aq) as 1 − π(ap) ( 1 − π(aq) ) .",4 Related Work,[0],[0]
"This assumes the independence of the two atoms ap and aq, which may not hold in practice.",4 Related Work,[0],[0]
Our approach does not rely on that assumption and also works for cases of statistical dependence.,4 Related Work,[0],[0]
"For example, the independence assumption does not hold in the trivial case where the relations rp and rq in the two atoms are equivalent, whereas in our model, the constraints rp ≤ rq and rp ≥ rq would simply reduce to rp = rq.",4 Related Work,[0],[0]
We now present our experimental results.,5 Experiments and Results,[0],[0]
We start by describing the experimental setup and hyperparameters.,5 Experiments and Results,[0],[0]
"Before turning to the injection of rules, we compare model F with model FS, and show that restricting the tuple embedding space has a regularization effect, rather than limiting the expressiveness of the model (§5.1).",5 Experiments and Results,[0],[0]
"We then demonstrate that model FSL is capable of zero-shot learning (§5.2), and show that injecting high-quality WordNet rules
leads to an improved precision (§5.3).",5 Experiments and Results,[0],[0]
"We proceed with a visual illustration of the relation embeddings with and without injected rules (§5.4), provide details on time efficiency of the lifted rule injection method (§5.5), and show that it correctly captures the asymmetry of implication rules (§5.6).
",5 Experiments and Results,[0],[0]
"All models were implemented in TensorFlow (Abadi et al., 2015).",5 Experiments and Results,[0],[0]
"We use the hyperparameters of Riedel et al. (2013), with k = 100 hidden dimensions and a weight of α = 0.01 for the L2 regularization loss.",5 Experiments and Results,[0],[0]
"We use ADAM (Kingma and Ba, 2014) for optimization with an initial learning rate of 0.005 and a mini-batch size of 8192.",5 Experiments and Results,[0],[0]
"The embeddings are initialized by sampling uniformly from [−0.1, 0.1] and we use β̃ = 0.1 for the implication loss throughout our experiments.",5 Experiments and Results,[0],[0]
"Before incorporating external commonsense knowledge into relation representations, we were curious how much we lose by restricting the entity-tuple space to approximately Boolean embeddings.",5.1 Restricted Embedding Space,[0],[0]
We evaluate our models on the New York Times dataset introduced by Riedel et al. (2013).,5.1 Restricted Embedding Space,[0],[0]
"Surprisingly, we find that the expressiveness of the model does not
suffer from this strong restriction.",5.1 Restricted Embedding Space,[0],[0]
"From Table 1 we see that restricting the tuple-embedding space seems to perform slightly better (FS) as opposed to a realvalued tuple-embedding space (F), suggesting that this restriction has a regularization effect that improves generalization.",5.1 Restricted Embedding Space,[0],[0]
We also provide the original results for model F by Riedel et al. (2013) (denoted as R13-F) for comparison.,5.1 Restricted Embedding Space,[0],[0]
"Due to a different implementation and optimization procedure, the results for our model F and R13-F are not identical.
",5.1 Restricted Embedding Space,[0],[0]
Inspecting the top relations for a sampled dimension in the embedding space reveals that the relation space of model FS more closely resembles clusters than that of model F (Table 2).,5.1 Restricted Embedding Space,[0],[0]
"We hypothesize that this might be caused by approximately Boolean entity-tuple representations in model FS, resulting in attribute-like entity-tuple vectors that capture which relation clusters they belong to.",5.1 Restricted Embedding Space,[0],[0]
"The zero-shot learning experiment performed in Rocktäschel et al. (2015) leads to an important finding: when injecting implications with right-hand sides for Freebase relations for which no or very limited training facts are available, the model should be able to infer the validity of Freebase facts for those relations based on rules and correlations between textual surface patterns.
",5.2 Zero-shot Learning,[0],[0]
"We inject the same hand-picked relations as used by Rocktäschel et al. (2015), after removing all Freebase training facts.",5.2 Zero-shot Learning,[0],[0]
"The lifted rule injection (model FSL) reaches a weighted MAP of 0.35, comparable with 0.38 by the Joint model from Rocktäschel et al. (2015) (denoted R15-Joint).",5.2 Zero-shot Learning,[0],[0]
"Note that for this experiment we initialized the Freebase relations implied by the rules with negative random vectors (sampled uniformly from [−7.9,−8.1]).",5.2 Zero-shot Learning,[0],[0]
"The reason is that without any negative training facts for these relations, their components can only go up due to the implication loss, and we do not want to get values that are too high before optimization.
",5.2 Zero-shot Learning,[0],[0]
Figure 1 shows how the relation extraction performance improves when more Freebase relation training facts are added.,5.2 Zero-shot Learning,[0],[0]
"It effictively measures how well the proposed models, matrix factorization (F), propositionalized rule injection (R15-Joint), and our model (FSL), can make use of the provided rules and correlations between textual surface form pat-
terns and increased fractions of Freebase training facts.",5.2 Zero-shot Learning,[0],[0]
"Although FSL starts at a lower performance than R15-Joint when no Freebase training facts are present, it outperforms R15-Joint and a plain matrix factorization model by a substantial margin when provided with more than 7.5% of Freebase training facts.",5.2 Zero-shot Learning,[0],[0]
"This indicates that, in addition to being much faster than R15-Joint, it can make better use of provided rules and few training facts.",5.2 Zero-shot Learning,[0],[0]
We attribute this to the Bayesian personalized ranking loss instead of the logistic loss used in Rocktäschel et al. (2015).,5.2 Zero-shot Learning,[0],[0]
"The former is compatible with our ruleinjection method, but not with the approach of maximizing the expectation of propositional rules used by R15-Joint.",5.2 Zero-shot Learning,[0],[0]
"The main purpose of this work is to be able to incorporate rules from external resources for aid-
ing relation extraction.",5.3 Injecting Knowledge from WordNet,[0],[0]
We use WordNet hypernyms to generate rules for the NYT dataset.,5.3 Injecting Knowledge from WordNet,[0],[0]
To this end we iterate over all surface form patterns in the dataset and attempt to replace words in the pattern by their hypernyms.,5.3 Injecting Knowledge from WordNet,[0],[0]
"If the resulting pattern is contained in the dataset, we generate the corresponding rule.",5.3 Injecting Knowledge from WordNet,[0],[0]
"For instance, we generate a rule appos->diplomat->amod ⇒ appos->official->amod since both patterns are contained in the NYT dataset and we know from WordNet that a diplomat is an official.",5.3 Injecting Knowledge from WordNet,[0],[0]
This leads to 427 rules from WordNet that we subsequently annotate manually to obtain 36 high-quality rules.,5.3 Injecting Knowledge from WordNet,[0],[0]
Note that none of these rules directly imply a Freebase relation.,5.3 Injecting Knowledge from WordNet,[0],[0]
"Although the test relations all originate from Freebase, we still hope to see improvements by transitive effects, i.e., better surface form representations that in turn help to predict Freebase facts.
",5.3 Injecting Knowledge from WordNet,[0],[0]
We show results obtained by injecting these WordNet rules in Table 1 (column FSL).,5.3 Injecting Knowledge from WordNet,[0],[0]
"The weighted MAP measure increases by 2% with respect to model FS, and 4% compared to our reimplementation of the matrix factorization model F. This demonstrates that imposing a partial ordering based on implication rules can be used to incorporate logical commonsense knowledge and increase the quality of information extraction systems.",5.3 Injecting Knowledge from WordNet,[0],[0]
"Note that our evaluation setting guarantees that only indirect effects of the rules are measured, i.e., we do not use any rules directly implying test relations.",5.3 Injecting Knowledge from WordNet,[0],[0]
This shows that injecting such rules influences the relation embedding space beyond only the relations explicitly stated in the rules.,5.3 Injecting Knowledge from WordNet,[0],[0]
"For example, injecting the rule appos<-father->appos ⇒ poss<-parent->appos can contribute to improved predictions for the test relation parent/child.",5.3 Injecting Knowledge from WordNet,[0],[0]
We provide a visual inspection of how the structure of the relation embedding space changes when rules are imposed.,5.4 Visualizing Relation Embeddings,[0],[0]
"We select all relations involved in the WordNet rules, and gather them as columns in a single matrix, sorted by increasing `1 norm (values in the 100 dimensions are similarly sorted).",5.4 Visualizing Relation Embeddings,[0],[0]
Figures 2a and 2b show the difference between model F (without injected rules) and FSL (with rules).,5.4 Visualizing Relation Embeddings,[0],[0]
"The values of the embeddings in model FSL are more polarized, i.e., we observe stronger negative or positive components than for model F. Furthermore, FSL also reveals a clearer difference between the leftmost (mostly negative, more specific) and right-most (predominantly positive, more general) embeddings (i.e., a clearer separation between positive and negative values in the plot), which results from imposing the order relation in eq.",5.4 Visualizing Relation Embeddings,[0],[0]
(11) when injecting implications.,5.4 Visualizing Relation Embeddings,[0],[0]
"In order to get an idea of the time efficiency of injecting rules, we measure the time per epoch when restricting the program execution to a single 2.4GHz CPU core.",5.5 Efficiency of Lifted Injection of Rules,[0],[0]
"We measure on average 6.33s per epoch without rules (model FS), against 6.76s and 6.97s
when injecting the 36 high-quality WordNet rules and the unfiltered 427 rules (model FSL), respectively.",5.5 Efficiency of Lifted Injection of Rules,[0],[0]
"Increasing the amount of injected rules from 36 to 427 leads to an increase of only 3% in computation time, even though in our setup all rule losses are used in every training batch.",5.5 Efficiency of Lifted Injection of Rules,[0],[0]
This confirms the high efficiency of our lifted rule injection method.,5.5 Efficiency of Lifted Injection of Rules,[0],[0]
"In order to demonstrate that injecting implications conserves their asymmetric nature, we perform the following experiment.",5.6 Asymmetric Character of Implications,[0],[0]
"After incorporating highquality Wordnet rules rp ⇒ rq into model FSL we select all of the tuples tp that occur with relation rp in a training fact 〈rp, tp〉.",5.6 Asymmetric Character of Implications,[0],[0]
"Matching these with relation rq should result in high values for the scores r>q tp, if the implication holds.",5.6 Asymmetric Character of Implications,[0],[0]
"If however the tuples tq are selected from the training facts 〈rq, tq〉, and matched with relation rp, the scores r>p tq should be much lower if the inverse implication does not hold (in other words, if rq and rp are not equivalent).",5.6 Asymmetric Character of Implications,[0],[0]
"Table 3 lists the averaged results for 5 example rules, and the average over all relations in WordNet rules, both for the case with injected rules (model FSL), and without rules (model FS).",5.6 Asymmetric Character of Implications,[0],[0]
"For easier comparison, the scores are mapped to the unit interval via the sigmoid function.",5.6 Asymmetric Character of Implications,[0],[0]
"This quantity σ(r>t) is often interpreted as the probability that the corresponding fact holds (Riedel et al., 2013), but because of the BPR-based training, only differences between scores play a role here.",5.6 Asymmetric Character of Implications,[0],[0]
"After injecting rules, the average scores of facts inferred by these rules (i.e., column σ(r>q tp) for model FSL) are always higher than for facts (incorrectly) inferred by the inverse rules (column σ(r>p tq) for model FSL).",5.6 Asymmetric Character of Implications,[0],[0]
"In the fourth example, the inverse rule leads to high scores as well (on average 0.79, vs. 0.98 for the actual rule).",5.6 Asymmetric Character of Implications,[0],[0]
"This is due to the fact that the daily and newspaper relations are more or less equivalent, such that the components of rp are not much below those of rq.",5.6 Asymmetric Character of Implications,[0],[0]
"For the last example (the ambassador ⇒ diplomat rule), the asymmetry in the implication is maintained, although the absolute scores are rather low for these two relations.
",5.6 Asymmetric Character of Implications,[0],[0]
The results for model FS reflect how strongly the implications in either direction are latently present in the training data.,5.6 Asymmetric Character of Implications,[0],[0]
"We can only conclude that model FS manages to capture the similarity be-
tween relations, but not the asymmetric character of implications.",5.6 Asymmetric Character of Implications,[0],[0]
"For example, purely based on the training data, it appears to be more likely that the parent relation implies the father relation, than vice versa.",5.6 Asymmetric Character of Implications,[0],[0]
This again demonstrates the importance and added value of injecting external rules capturing commonsense knowledge.,5.6 Asymmetric Character of Implications,[0],[0]
"We presented a novel, fast approach for incorporating first-order implication rules into distributed representations of relations.",6 Conclusions,[0],[0]
"We termed our approach ‘lifted rule injection’, as it avoids the costly grounding of first-order implication rules and is thus independent of the size of the domain of entities.",6 Conclusions,[0],[0]
"By construction, these rules are satisfied for any observed or unobserved fact.",6 Conclusions,[0],[0]
The presented approach requires a restriction on the entity-tuple embedding space.,6 Conclusions,[0],[0]
"However, experiments on a real-world dataset show that this does not impair the expressiveness of the learned representations.",6 Conclusions,[0],[0]
"On the contrary, it appears to have a beneficial regularization effect.
",6 Conclusions,[0],[0]
"By incorporating rules generated from WordNet hypernyms, our model improved over a matrix factorization baseline for knowledge base completion.",6 Conclusions,[0],[0]
"Especially for domains where annotation is costly and only small amounts of training facts are available, our approach provides a way to leverage external knowledge sources for inferring facts.
",6 Conclusions,[0],[0]
"In future work, we want to extend the proposed ideas beyond implications towards general firstorder logic rules.",6 Conclusions,[0],[0]
"We believe that supporting conjunctions, disjunctions and negations would enable to debug and improve representation learning based knowledge base completion.",6 Conclusions,[0],[0]
"Furthermore, we want to integrate these ideas into neural methods beyond matrix factorization approaches.",6 Conclusions,[0],[0]
"This work was supported by the Research Foundation - Flanders (FWO), Ghent University - iMinds, Microsoft Research through its PhD Scholarship Programme, an Allen Distinguished Investigator Award, and a Marie Curie Career Integration Award.",Acknowledgments,[0],[0]
Methods based on representation learning currently hold the state-of-the-art in many natural language processing and knowledge base inference tasks.,abstractText,[0],[0]
"Yet, a major challenge is how to efficiently incorporate commonsense knowledge into such models.",abstractText,[0],[0]
A recent approach regularizes relation and entity representations by propositionalization of first-order logic rules.,abstractText,[0],[0]
"However, propositionalization does not scale beyond domains with only few entities and rules.",abstractText,[0],[0]
In this paper we present a highly efficient method for incorporating implication rules into distributed representations for automated knowledge base construction.,abstractText,[0],[0]
We map entity-tuple embeddings into an approximately Boolean space and encourage a partial ordering over relation embeddings based on implication rules mined from WordNet.,abstractText,[0],[0]
"Surprisingly, we find that the strong restriction of the entity-tuple embedding space does not hurt the expressiveness of the model and even acts as a regularizer that improves generalization.",abstractText,[0],[0]
"By incorporating few commonsense rules, we achieve an increase of 2 percentage points mean average precision over a matrix factorization baseline, while observing a negligible increase in runtime.",abstractText,[0],[0]
Lifted Rule Injection for Relation Embeddings,title,[0],[0]
"The problem of estimating heterogeneous (individualized) causal effects of a treatment from observational data is central in many application domains, including public health and drug development (Foster et al., 2011), computational
1University of California, Los Angeles, USA 2University of Oxford, Oxford, UK 3Alan Turing Institute, London, UK.",1. Introduction,[0],[0]
"Correspondence to: Ahmed M. Alaa <ahmedmalaa@ucla.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"advertising (Bottou et al., 2013), and social sciences (Xie et al., 2012).",1. Introduction,[0],[0]
"The increasing availability of observational data in all these domains has encouraged the development of various machine learning algorithms tailored for inferring treatment effects using observational data (e.g. (Li & Fu, 2017; Wager & Athey, 2017; Shalit et al., 2017; Alaa & van der Schaar, 2017)).",1. Introduction,[0],[0]
"Due to the peculiarity of the treatment effect estimation problem, these algorithms needed to address various modeling aspects that are foreign to standard supervised learning setups; such aspects include ways to handle sample selection bias (Heckman, 1977), and ways to model treated and untreated data points.",1. Introduction,[0],[0]
"Despite a variety of recent algorithmic approaches, principled guidelines for model design are lacking.
",1. Introduction,[0],[0]
"In this paper, we identify guiding principles for designing practical treatment effect estimation algorithms in the context of Bayesian nonparametric inference, and propose one an algorithm that follows these guidelines.",1. Introduction,[0],[0]
"We set these guidelines by characterizing the fundamental limits of estimating treatment effects, and studying the impact of various common modeling choices on the achievability of those limits.",1. Introduction,[0],[0]
"In what follows, we provide a brief technical background for the treatment effect estimation problem, along with a summary of our contributions.",1. Introduction,[0],[0]
"Our analysis hinges on the Rubin-Neyman potential outcomes model (Rubin, 2005).",1.1. Background and Summary of Contributions,[0],[0]
"That is, we consider an observational dataset with a population of subjects, where each subject i is endowed with a d-dimensional feature Xi ∈ X .",1.1. Background and Summary of Contributions,[0],[0]
We assume that X =,1.1. Background and Summary of Contributions,[0],[0]
"[0, 1]d, but most of our results hold for general compact metric spaces (bounded, closed sets in Rd).",1.1. Background and Summary of Contributions,[0],[0]
"A treatment assignment indicator Wi ∈ {0, 1} is associated with subject i; Wi = 1 if the treatment under study was applied to subject i, and Wi = 0 otherwise.",1.1. Background and Summary of Contributions,[0],[0]
"Subject i’s responses with and without the treatment (the potential outcomes) are denoted as Y (1)i and Y (0)
i , respectively.",1.1. Background and Summary of Contributions,[0],[0]
"Treatments are assigned to subjects according to an underlying policy that depends on the subjects’ features, i.e. Wi ⊥̸⊥ Xi.",1.1. Background and Summary of Contributions,[0],[0]
This dependence is quantified via the conditional distribution p(x) =,1.1. Background and Summary of Contributions,[0],[0]
"P(Wi = 1|Xi = x), also known as the propensity score of subject i (Rosenbaum & Rubin,
1984).",1.1. Background and Summary of Contributions,[0],[0]
"The response Y (Wi)i is the “factual outcome” which we observe in the data, whereas Y (1 − Wi)i is the unrealized “counterfactual outcome” (Bottou et al., 2013).",1.1. Background and Summary of Contributions,[0],[0]
An observational dataset Dn comprises n samples of the form:,1.1. Background and Summary of Contributions,[0],[0]
"Dn = {Xi,Wi, Y (Wi)i }ni=1 (1)",1.1. Background and Summary of Contributions,[0],[0]
"The causal effect of the treatment on subject i with a feature Xi = x is characterized through the conditional average treatment effect (CATE) function T (x), which is defined as the expected difference between the two potential outcomes (Rubin, 2005), i.e. T (x) = E[Y (1)i",1.1. Background and Summary of Contributions,[0],[0]
− Y (0)i |Xi = x ] (2) Our goal is to identify a set of guiding principles for building estimators of the CATE T (x) using samples from Dn.,1.1. Background and Summary of Contributions,[0],[0]
"Throughout the paper, we will assume that the joint density dP(Xi,Wi, Y (0)i , Y (1)
i ) supports the assumptions of unconfoundedness and overlap, which are necessary for causal identifiability and consistency.",1.1. Background and Summary of Contributions,[0],[0]
"Unconfoundedness requires that (Y (0)i , Y (1)
i )",1.1. Background and Summary of Contributions,[0],[0]
"⊥⊥ Wi |Xi, whereas overlap requires that 0 < p(x) < 1",1.1. Background and Summary of Contributions,[0],[0]
"(Rosenbaum & Rubin, 1984).",1.1. Background and Summary of Contributions,[0],[0]
"Selection bias occurs in Dn since the distribution of the treated/control subjects does not match that of the overall population.
",1.1. Background and Summary of Contributions,[0],[0]
"In order to come up with principled guidelines for building estimators of T (x), we characterize the fundamental (information-theoretic) limits of estimating the CATE using samples from Dn, and identify the modeling choices that would allow achieving those limits.",1.1. Background and Summary of Contributions,[0],[0]
"To this end, in Section 3 we tackle the following question: what are the fundamental limits of CATE estimation?",1.1. Background and Summary of Contributions,[0],[0]
We answer this question by deriving the optimal minimax rate for estimating T (x) using Dn.,1.1. Background and Summary of Contributions,[0],[0]
"Interestingly, it turns out that the optimal rate does not depend on selection bias, but rather on the smoothness and sparsity of the more “complex” of the functions E[Y (0)i |Xi = x ] and E[Y (1) i |Xi = x ].",1.1. Background and Summary of Contributions,[0],[0]
"We focus our analysis on Bayesian nonparametric methods, since they have the appealing properties of being robust to misspecification and are accessible for theoretical analysis.
",1.1. Background and Summary of Contributions,[0],[0]
Our analysis reveals that the relative importance of the different modeling aspects vary with the sample size.,1.1. Background and Summary of Contributions,[0],[0]
"In particular, in the large-sample regime, selection bias does not pose a serious problem, and the model’s performance would be mainly determined by its structure, i.e. the way the outcomes Y (0)i and Y (1) i are modeled, and the impact of that on variable selection and hyperparameter tuning.",1.1. Background and Summary of Contributions,[0],[0]
"On the contrary, selection bias can seriously harm a model’s generalization performance in small-sample regimes.",1.1. Background and Summary of Contributions,[0],[0]
"A good model should then be carefully designed so that it operates well in both regimes by possessing the right model structure that would allow learning at a fast rate, and the right model selection (hyperparameter optimization) scheme that would account for selection bias.
",1.1. Background and Summary of Contributions,[0],[0]
"In Section 4, we build a practical CATE estimation algorithm guided by the results of the analyses in Section 3.",1.1. Background and Summary of Contributions,[0],[0]
We model the outcomes Y (0)i and Y (1) i using a Gaussian process with a non-stationary kernel that captures the different relevant variables and different levels of smoothness of the functions E[Y (0)i |Xi = x ] and E[Y (1),1.1. Background and Summary of Contributions,[0],[0]
i |Xi = x ].,1.1. Background and Summary of Contributions,[0],[0]
We prove that this model structure can achieve the optimal rate of CATE estimation when tuned with the right hyperparameters.,1.1. Background and Summary of Contributions,[0],[0]
"We also propose a doubly-robust hyperparameter optimization scheme that accounts for selection bias in smallsample regimes, without hindering the model’s minimaxoptimality in the large sample limit.",1.1. Background and Summary of Contributions,[0],[0]
We show that our algorithm outperforms state-of-the-art methods using a wellknown semi-synthetic simulation setup.,1.1. Background and Summary of Contributions,[0],[0]
"Very few works have attempted to characterize the limits of CATE estimation, or study the impact of different modeling choices on the CATE estimation performance in a principled manner.",1.2. Related Work,[0],[0]
"(Alaa & van der Schaar, 2018) characterized the asymptotic “information rates” for different CATE estimators, but provided no clear guidelines on practical model design or an analysis of the impact of sample selection bias.",1.2. Related Work,[0],[0]
"The study in (Künzel et al., 2017) was rather empirical in nature, comparing the performance of different regression structures for the potential outcomes while ignoring selection bias.",1.2. Related Work,[0],[0]
"A similar study, but focusing only on random forest models, was conducted in (Lu et al., 2017).
",1.2. Related Work,[0],[0]
"Most of the previous works have been algorithmic in nature, focusing mainly on devising algorithms that correct for selection bias (e.g. (Johansson et al., 2016; Yoon et al., 2018; Wager & Athey, 2017; Li & Fu, 2017)).",1.2. Related Work,[0],[0]
"Some of these works cast the selection bias problem as a problem of covariate shift (Sugiyama et al., 2007), and use techniques from representation learning to learn feature maps that balance the biased data (e.g. (Li & Fu, 2017; Shalit et al., 2017; Johansson et al., 2016)).",1.2. Related Work,[0],[0]
"However, those works report much bigger improvements in CATE estimation when changing their model structure (e.g. architecture of a neural network), as compared to the gains attained by only accounting for bias (see the comparisons between the TARnet and BNN models in (Shalit et al., 2017)).",1.2. Related Work,[0],[0]
"Similar observations are reported in (Alaa & van der Schaar, 2017; Atan et al., 2018), where the selection of the model structure seemed to influence the achieved CATE estimation performance even when selection bias is not accounted for.",1.2. Related Work,[0],[0]
"However, none of these works offer a discussion on whether selection bias is actually the main challenge in CATE estimation, or whether the outcomes’ model structure may have a bigger influence on performance.
",1.2. Related Work,[0],[0]
"In contrast to the works above, this paper does not attempt to develop a model by presupposing that particular model-
ing aspects are of greater importance than others, but rather provides a framework for understanding the limits on the achievable performance, and how different modeling aspects influence a model’s chance of achieving those limits.",1.2. Related Work,[0],[0]
"We use our analyses to both reflect on the modeling choices made in the works above, and also devise a novel, principled CATE estimation algorithms that achieves the fundamental performance limits.",1.2. Related Work,[0],[0]
"We consider the following random design regression model for the potential outcomes:
Y (w)i = fw(Xi) +",2.1. Potential Outcomes & Propensity Score,[0],[0]
"εi,w, w ∈ {0, 1}, (3)
where εi,w ∼ N (0, σ2w) is a Gaussian noise variable.",2.1. Potential Outcomes & Propensity Score,[0],[0]
It follows from (2) that the CATE is T (x) = f1(x),2.1. Potential Outcomes & Propensity Score,[0],[0]
− f0(x),2.1. Potential Outcomes & Propensity Score,[0],[0]
.,2.1. Potential Outcomes & Propensity Score,[0],[0]
"The response surfaces f1(x) and f0(x) correspond to the subjects’ responses with and without the treatment.
",2.1. Potential Outcomes & Propensity Score,[0],[0]
We assume that fw(.) :,2.1. Potential Outcomes & Propensity Score,[0],[0]
"X → R, w ∈ {0, 1}, is a totally bounded function that lives in a space of “smooth” or “regular” functions, with an unknown smoothness parameter αw.",2.1. Potential Outcomes & Propensity Score,[0],[0]
"We use Hölder balls for concreteness, although our results extend to other function spaces.",2.1. Potential Outcomes & Propensity Score,[0],[0]
"A function fw(.) lies in the Hölder ball Hαw , with a Hölder exponent",2.1. Potential Outcomes & Propensity Score,[0],[0]
"αw > 0, if and only if it is bounded in sup-norm by a constant C > 0, all its partial derivatives up to order ⌊αw⌋ exist, and all its partial derivatives of order ⌊αw⌋ are Lipschitz with exponent (αw − ⌊αw⌋) and constant C. The Hölder exponents quantify the complexities of f0 and f1, and hence the hardness of estimating T (x) would depend on α0 and α1.",2.1. Potential Outcomes & Propensity Score,[0],[0]
"Nonparametric inference is immune to misspecification of the outcomes’ and propensity models (Kennedy, 2018), and hence we focus on Bayesian nonparametric methods for inferring T (.) on the basis of Dn.",2.2. Bayesian Nonparametric Inference,[0],[0]
"Bayesian inference entails specifying a prior distribution Π over f1(.) and f0(.), i.e.
f0, f1 ∼ Π(φ̄β0 , φ̄β1), (4)
where φ̄βw = {φkβw} ∞ k=1, w ∈ {0, 1}, are complete orthonormal bases (indexed by a parameter βw > 0) with respect to Lebesgue measure in X , fw = ∑ k f̄ k w ·φkβw , and f̄kw = ⟨fw, φkβw⟩.",2.2. Bayesian Nonparametric Inference,[0],[0]
"Thus, for given bases φ̄β0 and φ̄β1 , Π places a probability distribution on the projections {f̄kw}k.",2.2. Bayesian Nonparametric Inference,[0],[0]
"Potential choices for the basis φ̄βw that would give rise to implementable Bayesian inference algorithms include regular wavelet basis (Zhang, 1997), radial basis for a reproducing kernel Hilbert space (RKHS) (van der Vaart et al., 2008), etc.",2.2. Bayesian Nonparametric Inference,[0],[0]
"In general, the parameter βw would determine the smoothness of the function space spanned by φ̄βw .",2.2. Bayesian Nonparametric Inference,[0],[0]
"To evaluate the predictive accuracy of the Bayesian inference procedure, we analyze the “frequentist” loss of point estimators T̂ (x) induced by the Bayesian posterior dΠn(T (x) | Dn), assuming that Dn is generated based on fixed, true response surfaces f1(x) and f0(x).",2.3. Towards Principled CATE Estimation,[0],[0]
"(This type of analysis is sometimes referred to as the “FrequentistBayes” analysis (Sniekers et al., 2015).)",2.3. Towards Principled CATE Estimation,[0],[0]
"In particular, we quantify the performance of a point estimator T̂ (x) = δ(dΠn(T (x) | Dn)) by its squared-L2(P) error, which was dubbed the precision of estimating heterogeneous effects (PEHE) in (Hill, 2011), and is formally defined as:
ψ(T̂ ) , E ∥",2.3. Towards Principled CATE Estimation,[0],[0]
T̂,2.3. Towards Principled CATE Estimation,[0],[0]
"− T ∥2 L2(P), (5)
where L2(P) is the L2 norm with respect to the feature distribution, i.e. ∥f(x)∥2 L2(P) = ∫ f2(x) dP(X = x).
",2.3. Towards Principled CATE Estimation,[0],[0]
"Not a standard supervised learning problem...
",2.3. Towards Principled CATE Estimation,[0],[0]
"The “fundamental problem of causal inference” is that for every subject i in Dn, we only observe the factual outcome Y (Wi)i , whereas the counterfactual Y (1 − Wi) i remains unknown, which renders empirical evaluation of the PEHE in (5) impossible.",2.3. Towards Principled CATE Estimation,[0],[0]
"Moreover, Dn would generally exhibit sample selection bias (Heckman, 1977), because the treatment assignment mechanism (decided by p(x)) creates a discrepancy between the feature distributions of the treated/control population and the overall population.",2.3. Towards Principled CATE Estimation,[0],[0]
"Thus, standard supervised learning approaches based on empirical risk minimization cannot be used to learn a generalizable model for the CATE from samples in Dn.",2.3. Towards Principled CATE Estimation,[0],[0]
"This gives rise to the following fundamental modeling questions that are peculiar to the CATE estimation problem:
•",2.3. Towards Principled CATE Estimation,[0],[0]
"[Q1]: How should the treatment assignment indicator Wi be incorporated into the learning model?
",2.3. Towards Principled CATE Estimation,[0],[0]
•,2.3. Towards Principled CATE Estimation,[0],[0]
"[Q2]: How should selection bias be handled?
",2.3. Towards Principled CATE Estimation,[0],[0]
"Adequate answers to [Q1] and [Q2] would provide guidelines for selecting the prior Π(φ̄β0 , φ̄β1).",2.3. Towards Principled CATE Estimation,[0],[0]
"Addressing the modeling questions above requires a profound understanding of the fundamental limits of CATE estimation, in addition to an understanding of the impact of different modeling choices on the achievability of such limits.",2.3. Towards Principled CATE Estimation,[0],[0]
"The next Sections provide principled answers to [Q1] and [Q2] by addressing the following, more fundamental questions:
Section 3: What are the limits on the performance that can be achieved by any estimator of the CATE?
Section 4: How can we build practical algorithms that can achieve the performance limits?",2.3. Towards Principled CATE Estimation,[0],[0]
"In this Section, we establish an information-theoretic limit on the performance of any CATE estimator.",3. Fundamental Limits of CATE Estimation,[0],[0]
"In what follows, we use the standard Bachmann-Landau order notation, and write a∨ b = max{a, b}, a∧ b = min{a, b}.",3. Fundamental Limits of CATE Estimation,[0],[0]
The notation a .,3. Fundamental Limits of CATE Estimation,[0],[0]
"b means that a ≤ Cb for a universal constant C, and ≍ denotes asymptotic equivalence.",3. Fundamental Limits of CATE Estimation,[0],[0]
"The “hardness” of a nonparametric estimation problem is typically characterized by its minimax risk (Stone, 1982), i.e. the minimum worst case risk achieved by any estimator when the estimand is known to live in a given function space (Yang et al., 2015).",3.1. Optimal Minimax Rates,[0],[0]
"In the following Theorem, we establish the optimal minimax rate for the PEHE risk in terms of the complexity of the response surfaces f0 and f1.
Theorem 1.",3.1. Optimal Minimax Rates,[0],[0]
Suppose that X =,3.1. Optimal Minimax Rates,[0],[0]
"[0, 1]d, and that fw depends on a subset of dw features with dw ≤ min{n, d} for w ∈ {0, 1}.",3.1. Optimal Minimax Rates,[0],[0]
"If f0 ∈ Hα0 and f1 ∈ Hα1 , then the optimal minimax rate is:
inf T̂ sup f0,f1
ψ(T̂ ) ≍",3.1. Optimal Minimax Rates,[0],[0]
n− ( 1+ 1 2 ( d0 α0 ∨ d1 α1 )),3.1. Optimal Minimax Rates,[0],[0]
"−1︸ ︷︷ ︸ CATE estimation
∨ log ( dd0+d1
d d0 0 d d1 1
) 1 n
.︸",3.1. Optimal Minimax Rates,[0],[0]
︷︷ ︸,3.1. Optimal Minimax Rates,[0],[0]
"Variable selection
The above holds for any p(.)",3.1. Optimal Minimax Rates,[0],[0]
"∈ Hαp , αp > 0.
",3.1. Optimal Minimax Rates,[0],[0]
"In Theorem 1, the supremum is taken over αw-Hölder balls (w ∈ {0, 1}), whereas the infimum is taken over all possible Bayesian estimators.",3.1. Optimal Minimax Rates,[0],[0]
The minimax rate in Theorem 1 corresponds to the fastest rate by which any (Bayesian) estimator T̂ (.) can approximate the CATE function T (.).,3.1. Optimal Minimax Rates,[0],[0]
"The proof of Theorem 1 (provided in the supplement) uses information-theoretic techniques based on Fano’s method to derive algorithm-independent estimation rates (Yang & Barron, 1999).",3.1. Optimal Minimax Rates,[0],[0]
"In the following set of remarks, we revisit [Q1] and [Q2] in the light of the results of Theorem 1.
",3.1. Optimal Minimax Rates,[0],[0]
"How can Theorem 1 help us address [Q1] & [Q2]?
◃",3.1. Optimal Minimax Rates,[0],[0]
"Remark 1 (Smoothness & sparsity)
",3.1. Optimal Minimax Rates,[0],[0]
"Theorem 1 says that estimating CATE is as hard as nonparametric regression for functions with additive sparsity (Raskutti et al., 2009; Yang et al., 2015).",3.1. Optimal Minimax Rates,[0],[0]
"The minimax rate in Theorem 1 decomposes into a term reflecting the complexity of CATE estimation under correct variable selection for f0 and f1, and a term reflecting the complexity of variable selection.",3.1. Optimal Minimax Rates,[0],[0]
"Variable selection complexity remains small as long as log(d) = Θ(nζ), for some ζ ∈ (0, 1), and approaches the parametric rates as ζ → 0.",3.1. Optimal Minimax Rates,[0],[0]
"The minimax rate will generally be dominated by the complexity of CATE estimation, and will approach the parametric rates only for very smooth response surfaces with small number of relevant dimensions, i.e. d0α0 ∨ d1 α1 → 0.
",3.1. Optimal Minimax Rates,[0],[0]
"The main takeaway from Theorem 1 is that the CATE learning rate is determined by the more “complex” of the surfaces f0 and f1, where complexity is quantified by the sparsity-to-smoothness ratio dw/αw for w ∈ {0, 1}.",3.1. Optimal Minimax Rates,[0],[0]
"Thus, a model would achieve the optimal CATE learning rate only if it selects the correct relevant variables for f0 and f1, and tunes its “hyperparameters” (i.e. smoothness of the prior) to cope with a complexity of d0α0 ∨ d1 α1 .",3.1. Optimal Minimax Rates,[0],[0]
"When d0α0 and d1 α1
are very different (e.g. f0 and f1 have different relevant features), rate-optimal estimation is possible only if the model incorporates such differences in Π(φ̄β0 , φ̄β1).
",3.1. Optimal Minimax Rates,[0],[0]
The discussion above provides a concrete answer to [Q1]: the treatment assignment variablew should be incorporated into the model in such a way that it encodes the different relevant dimensions and smoothness levels of f0 and f1 in the bases φ̄β0 and φ̄β1 .,3.1. Optimal Minimax Rates,[0],[0]
(The simplest way to achieve this is to use two separate models for f0 and f1.),3.1. Optimal Minimax Rates,[0],[0]
"This is not fulfilled by many of the previous models that built a single regression function of the from f : X ×{0, 1} → R, and estimated the CATE as T̂ (x) = f(x, 1)−f(x, 0) (Hill, 2011; Johansson et al., 2016; Powers et al., 2017).",3.1. Optimal Minimax Rates,[0],[0]
"This is because such models enforced the smoothness of the prior along all features to be the same for w = 0 and w = 1.
◃",3.1. Optimal Minimax Rates,[0],[0]
"Remark 2 (Selection bias)
Theorem 1 gives a rather surprising answer to [Q2]: the optimal learning rate is oblivious to selection bias.",3.1. Optimal Minimax Rates,[0],[0]
"Such a finding is consistent with previous results on nonparametric kernel density estimation under selection bias (Borrajo et al., 2017), and parametric Bayesian inference under covariate shift (Shimodaira, 2000; Sugiyama & Storkey, 2007).",3.1. Optimal Minimax Rates,[0],[0]
"It shows that many of the recent works have missed the target; the works in (Johansson et al., 2016; Shalit et al., 2017; Alaa & van der Schaar, 2017) cast the problem of CATE estimation as one of covariate shift that results from selection bias.",3.1. Optimal Minimax Rates,[0],[0]
"However, Theorem 1 says that selection bias is not a problem when we have a sufficiently large amount of data.",3.1. Optimal Minimax Rates,[0],[0]
"This is because selection bias is inherently a misspecification problem, and hence its impact on nonparametric inference is washed away in large-sample regimes.
",3.1. Optimal Minimax Rates,[0],[0]
Remarks 1 and 2 posit an explanation for various recurrent (empirical) findings reported in previous literature.,3.1. Optimal Minimax Rates,[0],[0]
"For instance, (Hahn et al., 2017) found that separate modeling of f0 and f1 via Bayesian additive regression trees (BART) outperforms the well-known single-surface BART model developed in (Hill, 2011).",3.1. Optimal Minimax Rates,[0],[0]
"Similar findings were reported for models based on Gaussian processes (Alaa & van der Schaar, 2017), and models based on deep neural networks (Shalit et al., 2017).",3.1. Optimal Minimax Rates,[0],[0]
All such findings can be explained in the light of Remark 1.,3.1. Optimal Minimax Rates,[0],[0]
"On the other hand, Remark 2 may provide an explanation as to why the “TARnet” model in (Shalit et al., 2017), which models f0 and f1 using separate neural networks and does not account for selection
bias, outperformed the “BNN” model in (Johansson et al., 2016), which regularizes for selection bias but fits a singleoutput network for f0 and f1.",3.1. Optimal Minimax Rates,[0],[0]
"Theorem 1 shows that selection bias does not hinder the optimal minimax rates, and that it is only the structural properties of the prior Π(φ̄β0 , φ̄β1) that determine a model’s rate of learning.",3.2. Backing off from “Asymptopia”,[0],[0]
But does the achieved learning rate suffice as a sole criterion for addressing the modeling questions,3.2. Backing off from “Asymptopia”,[0],[0]
[Q1] and [Q2]?,3.2. Backing off from “Asymptopia”,[0],[0]
"The answer is “yes” only if Dn comes from a large observational dataset, in which case the learning rate suffices as a descriptor for the large-sample performance.",3.2. Backing off from “Asymptopia”,[0],[0]
"However, if Dn is small, which is typical in posthoc analyses of clinical trials (Foster et al., 2011), then one should make the design choices that would optimize the small-sample performance.",3.2. Backing off from “Asymptopia”,[0],[0]
"In order to give a more complete picture of the performance in large and small-sample regimes, we derive the following bound on the PEHE:
ψ(T̂ ) ≤ C̄ ·",3.2. Backing off from “Asymptopia”,[0],[0]
exp(D2(Q0 ∥Q)) · ∥f0 − f̂0∥2L2(P0) + C̄,3.2. Backing off from “Asymptopia”,[0],[0]
"· exp(D2(Q1 ∥Q)︸ ︷︷ ︸
Réyni Divergence ) · ∥f1",3.2. Backing off from “Asymptopia”,[0],[0]
"− f̂1∥2L2(P1)︸ ︷︷ ︸ Supervised learning loss , (6)
for some C̄",3.2. Backing off from “Asymptopia”,[0],[0]
"> 0, where L2(Pw), for w ∈ {0, 1}, is the L2 norm with respect to dP(X = x |W = w), Q = dP(X = x), Qw = dP(X = x |W = w), and Dm(p ∥ q) is the mth order Réyni divergence.",3.2. Backing off from “Asymptopia”,[0],[0]
"The bound in (6) holds for all n > 0, and is tight (refer to the supplement); it shows that the PEHE is a weighted linear combination of the mean squared losses for the two underlying supervised problems of learning f0 and f1 with no covariate shift, where the weights are determined by the extent of the mismatch between the distributions of the treated and control populations, quantified by the Réyni divergence measure.",3.2. Backing off from “Asymptopia”,[0],[0]
"If Dn is a dataset obtained from a randomized controlled trial (Q = Q0 = Q1), then we have D2(Q0 ∥Q) = D2(Q1 ∥Q) = 0, and the bound boils down to a sum of two supervised learning losses, i.e. ψ(T̂ ) ≤ C̄ · ∥f0 − f̂0∥2L2(P) + C̄ · ∥f1 − f̂1∥ 2 L2(P).
",3.2. Backing off from “Asymptopia”,[0],[0]
Since the minimax rate for standard nonparametric regression is ∥fw − f̂w∥22 ≍,3.2. Backing off from “Asymptopia”,[0],[0]
"Cw · n −2αw 2αw+dw (Stone, 1982), when d0/α0 >",3.2. Backing off from “Asymptopia”,[0],[0]
"> d1/α1, the first-order Taylor approximation for the logarithm of the PEHE in (6) is given by:
log(ψ(T̂ ))",3.2. Backing off from “Asymptopia”,[0],[0]
"≈D2(Q0∥Q)︸ ︷︷ ︸ Selection
bias
+ log(C0)︸ ︷︷ ︸ Bias
correction
− 2α0 2α0 + d0︸ ︷︷ ︸
Learning rate
log(n)
+O ( n −2α1 2α1+d1 + 2α0 2α0+d0 ) .",3.2. Backing off from “Asymptopia”,[0],[0]
"(7)
That is, when viewed on a log-log scale, the behavior of the PEHE versus the number of samples can be described
as follows. log(PEHE) is a linear function of log(n).",3.2. Backing off from “Asymptopia”,[0],[0]
"Selection bias adds a constant offset to log(PEHE), but does not affect its slope, which harms the performance only in the small-sample regime.",3.2. Backing off from “Asymptopia”,[0],[0]
"In the large-sample regime, the slope of log(PEHE), which depends solely on the smoothness and sparsity of the response surfaces, dominates the performance, and selection bias becomes less of a problem.",3.2. Backing off from “Asymptopia”,[0],[0]
Figure 1 depicts the PEHE in (7) on a log-log scale.,3.2. Backing off from “Asymptopia”,[0],[0]
"In this Section, we build on the analyses conducted in Section 3 to design a practical algorithm for CATE estimation.",4. CATE Estimation using Non-Stationary Gaussian Process Regression,[0],[0]
"We specify the prior Π(φ̄β0 , φ̄β1) as a Gaussian process (GP) over functions of the form g :",4.1. Non-Stationary Gaussian Process Priors,[0],[0]
"X × {0, 1} → R, with a kernel Kβ , and a hyperparameter set β as follows:
g ∼ GP (0,Kβ(z, z′)) , (8)
where z = (x,w) ∈ X × {0, 1}, and fw(x) = g(x,w).",4.1. Non-Stationary Gaussian Process Priors,[0],[0]
"The kernel Kβ specifies the bases φ̄β0 and φ̄β1 through its induced canonical feature map Kβ(., z) (Rasmussen & Williams, 2006; Alvarez et al., 2012).",4.1. Non-Stationary Gaussian Process Priors,[0],[0]
"As pointed out in remark 1, the treatment assignment variable w should encode the different relevant dimensions and smoothness levels of f0 and f1.",4.1. Non-Stationary Gaussian Process Priors,[0],[0]
"Thus, we model Kβ as a non-stationary kernel that depends explicitly on w as follows:
Kβ(z, z ′)= Γ(w,w′) ·",4.1. Non-Stationary Gaussian Process Priors,[0],[0]
"kTβ (x, x′), kβ(x, x ′)=",4.1. Non-Stationary Gaussian Process Priors,[0],[0]
"[kβ0(x, x ′), kβ1(x, x ′), kβ0(x, x ′) +",4.1. Non-Stationary Gaussian Process Priors,[0],[0]
"kβ1(x, x ′)],
Γ(w,w′)=",4.1. Non-Stationary Gaussian Process Priors,[0],[0]
"[Γ0(w,w ′), Γ1(w,w ′), 1− Γ0(w,w′)− Γ1(w,w′)],
where Γ0(w,w′) = (1− w)(1− w′), Γ1(w,w′) = w · w′, and kβw(x, x ′) is a Matérn kernel with a length-scale parameter
βw, for w ∈ {0, 1}.",4.1. Non-Stationary Gaussian Process Priors,[0],[0]
"The kernel defined above ensures that any covariance matrix induced by points in X × {0, 1} is positive definite.",4.1. Non-Stationary Gaussian Process Priors,[0],[0]
"Variable selection is implemented by using the automatic relevance determination version of the Matérn kernel (Rasmussen & Williams, 2006).",4.1. Non-Stationary Gaussian Process Priors,[0],[0]
"The nonstationarity of Kβ allows setting different length-scales and relevant variables for the marginal priors on f0 and f1 while sharing data between the two surfaces, i.e.
Kβ((x,w), (x ′, w))= kβw (x, x ′), w ∈ {0, 1}, Kβ((x,w), (x ′, w′))= kβ0(x, x ′) +",4.1. Non-Stationary Gaussian Process Priors,[0],[0]
"kβ1(x, x ′), w ̸=",4.1. Non-Stationary Gaussian Process Priors,[0],[0]
"w′. (9)
That is, all draws from the prior give Matérn sample paths with different smoothness levels (β0 and β1) for f0 and f1, respectively, and the correlations between the paths are captured via the kernel mixture kβ0(x, x ′) +",4.1. Non-Stationary Gaussian Process Priors,[0],[0]
"kβ1(x, x ′).",4.1. Non-Stationary Gaussian Process Priors,[0],[0]
Note that draws from a Matérn prior with length-scale β are almost surely β̄-Hölder for all β̄ ≤,4.1. Non-Stationary Gaussian Process Priors,[0],[0]
β,4.1. Non-Stationary Gaussian Process Priors,[0],[0]
"(Vaart & Zanten, 2011).",4.1. Non-Stationary Gaussian Process Priors,[0],[0]
"Thus, GP(0,Kβ) specifies a βw-Hölder ball as an a priori regularity class for response surface fw, w ∈ {0, 1}.
",4.1. Non-Stationary Gaussian Process Priors,[0],[0]
"In the following Theorem, we show that point estimators induced by the prior GP(0,Kβ) can achieve the optimal minimax rate in Theorem 1.
",4.1. Non-Stationary Gaussian Process Priors,[0],[0]
Theorem 2.,4.1. Non-Stationary Gaussian Process Priors,[0],[0]
"Suppose that the dw relevant features for fw are known a priori for w ∈ {0, 1}.",4.1. Non-Stationary Gaussian Process Priors,[0],[0]
"If f0 ∈ Hα0 , f1 ∈ Hα1 , Π = GP(0,Kβ), and T̂ = EΠ [T | Dn ], then we have that
ψ(T̂ ) .",4.1. Non-Stationary Gaussian Process Priors,[0],[0]
"n− 2(α0∧β0) 2β0+d0 ∨ n− 2(α1∧β1) 2β1+d1
whenever min{α0, α1, β0, β1} ≥ d/2.
",4.1. Non-Stationary Gaussian Process Priors,[0],[0]
"Note that posterior consistency holds for all combinations of (α0, α1, β0, β1) since the support of the Matérn prior is the space of bounded continuous functions1.",4.1. Non-Stationary Gaussian Process Priors,[0],[0]
"The bound in Theorem 2 can be shown to be tight using the results in (Castillo, 2008).",4.1. Non-Stationary Gaussian Process Priors,[0],[0]
"Theorem 2 says that the posterior induced by the prior GP(0,Kβ) contracts around the true CATE function at the optimal rate given in Theorem 1 provided that the following matching condition is met:
βv = αv
αv d1−v dv ≤ β1−v ≤",4.1. Non-Stationary Gaussian Process Priors,[0],[0]
"α1−v + α1−v ·dv2αv − d1−v 2 , (10)
",4.1. Non-Stationary Gaussian Process Priors,[0],[0]
where v = 1,4.1. Non-Stationary Gaussian Process Priors,[0],[0]
"if d1/α1 > d0/α0, and v = 0 otherwise",4.1. Non-Stationary Gaussian Process Priors,[0],[0]
.,4.1. Non-Stationary Gaussian Process Priors,[0],[0]
The condition in (10) implies that achieving the optimal rate (steepest slope in Figure 1) via the non-stationary GP prior in Section 4.1 is only a matter of hyperparameter tuning: the smoothness of the prior needs to match the smoothness of the “more complex” of the two response surfaces.,4.1. Non-Stationary Gaussian Process Priors,[0],[0]
"Note that Theorem 2 implies that we do not need to handle selection bias in order to achieve the optimal rate, which is consistent with the earlier discussion in remark 2.
",4.1. Non-Stationary Gaussian Process Priors,[0],[0]
"1This is because the RKHS associated with the prior lies dense in the space of bounded continuous functions (van der Vaart & van Zanten, 2008; van der Vaart et al., 2008).",4.1. Non-Stationary Gaussian Process Priors,[0],[0]
Theorem 2 says that the optimal minimax rate for CATE estimation can be achieved by satisfying the smoothness matching condition in (10).,4.2. Doubly-Robust Hyperparameters,[0],[0]
"However, in practice, the smoothness levels of the true response functions are unknown and need to be learned from the data.",4.2. Doubly-Robust Hyperparameters,[0],[0]
"Moreover, since selection bias is impactful in small-sample regimes, ignoring it may lead to a poor generalization performance when the size of Dn is small.",4.2. Doubly-Robust Hyperparameters,[0],[0]
"In this Section, we propose a hyperparameter optimization algorithm that accounts for selection bias while ensuring minimax-optimality in the large-sample limit.
",4.2. Doubly-Robust Hyperparameters,[0],[0]
"Previous works tend to adjust for selection bias “mechanically” using variants of importance sampling approaches based on inverse-propensity-weighting (IPW) (Sugiyama et al., 2007; Shimodaira, 2000), and kernel mean matching (Huang et al., 2007), or by learning a “balanced representation” of treated and control populations (Li & Fu, 2017).",4.2. Doubly-Robust Hyperparameters,[0],[0]
"We do not attempt to explicitly adjust for selection bias using ad-hoc approaches, and rather seek the “informationally optimal” estimator of the PEHE.",4.2. Doubly-Robust Hyperparameters,[0],[0]
"That is, we seek the most efficient (unbiased) estimator ψ̂∗(T̂ ) of ψ(T̂ ), which satisfies an analog of the Cramér-Rao bound (information-inequality) in parametric estimation, i.e. Var[ψ̂∗(T̂ )] ≤ Var[ψ̂(T̂ )], for any estimator ψ̂(T̂ ).
",4.2. Doubly-Robust Hyperparameters,[0],[0]
"Classical Cramér-Rao bounds do not apply to estimators of the form ψ̂∗(T̂ ), since such estimators are functionals of nonparametric objects.",4.2. Doubly-Robust Hyperparameters,[0],[0]
"There are, however, analogous information inequalities for nonparametric estimation, including Bhattacharyya’s variance bound (Bhattacharyya, 1946), and its generalization due to Bickel (Bickel et al., 1998).",4.2. Doubly-Robust Hyperparameters,[0],[0]
"We proceed by realizing that the PEHE ψ(T̂ ) is simply a functional that belongs to the doubly-robust class of functionals analyzed by Robins in (Robins et al., 2008).",4.2. Doubly-Robust Hyperparameters,[0],[0]
"Thus, one can construct the “most” efficient estimator of ψ(T̂ ) using the most efficient influence function of ψ(T̂ ) as follows (Robins et al., 2008; Robins, 2004):
ψ̂∗(T̂ ) =",4.2. Doubly-Robust Hyperparameters,[0],[0]
"∑n
i=1
( Y
(Wi) i −(Wi−p(Xi))·T̂ (Xi)
p(Xi)·(1−p(Xi))
)2 .
",4.2. Doubly-Robust Hyperparameters,[0],[0]
"The derivation of the estimator above can be found in Theorem 9 in (Robins, 2004) and Section 5 in (Robins et al., 2008).",4.2. Doubly-Robust Hyperparameters,[0],[0]
"When the propensity function p(.) is known, this estimator approximate the PEHE at its optimal minimax rate.",4.2. Doubly-Robust Hyperparameters,[0],[0]
We estimate p(.) via standard kernel density estimation methods.,4.2. Doubly-Robust Hyperparameters,[0],[0]
"It can be easily shown using the results in (Dudoit & van der Laan, 2005) that when using the estimator above to tune the GP hyperparameters via crossvalidation, then the learned length-scale parameters will satisfy the matching condition for minimax optimality.",4.2. Doubly-Robust Hyperparameters,[0],[0]
"In this Section, we check the validity of our analyses using a synthetic simulation setup (Subsection 5.1), and then evaluate the performance of our proposed model using data from a real-world clinical trial with simulated potential outcomes (Subsection 5.2).",5. Experiments,[0],[0]
We will use the acronym NSGP to refer to the non-stationary GP model proposed in Section 4.,5. Experiments,[0],[0]
Let X =,5.1.1. SYNTHETIC MODEL,[0],[0]
"[0, 1], and define a κ-fold integrated Brownian motion Bκ, κ ∈ N+, on X as follows:
Bκ(x)",5.1.1. SYNTHETIC MODEL,[0],[0]
= ∫ x 0 ∫ xκ 0 · · · ∫,5.1.1. SYNTHETIC MODEL,[0],[0]
x2 0,5.1.1. SYNTHETIC MODEL,[0],[0]
"B0(x1) dx1 dx2 · · · dxxκ ,
where B0(.) is a standard Brownian motion (Wiener process).",5.1.1. SYNTHETIC MODEL,[0],[0]
"Sample paths of B0 are almost surely Hölder regular with exponent 1
2 (Karatzas & Shreve, 2012).",5.1.1. SYNTHETIC MODEL,[0],[0]
"Since
B0(x) is almost surely non-differentiable everywhere in X , then sample paths of Bκ(x) are Hölder with exponent κ+ 1
2 , i.e. Bκ ∈ Hκ+
1 2 with probability 1.",5.1.1. SYNTHETIC MODEL,[0],[0]
"Therefore, when
the true response surfaces are κ-fold integrated Brownian paths, the optimality and achievability results in Theorems 1 and 2 should hold.",5.1.1. SYNTHETIC MODEL,[0],[0]
"To this end, we simulate the true response surfaces f0 ∈ Hα0 and f1 ∈ Hα1 as f0 ∼ Bα0− 12 , and f1 ∼ Bα1− 12 , where we set α0 = 2.5 and α1 = 5.5.
",5.1.1. SYNTHETIC MODEL,[0],[0]
The propensity score is modeled as a parametrized logistic function p(x |η) =,5.1.1. SYNTHETIC MODEL,[0],[0]
"(1 + e−η (x− 12 ))−1, where η ∈ R is a parameter that determines the severity of selection bias.",5.1.1. SYNTHETIC MODEL,[0],[0]
"For a pair of fixed Brownian paths f0 and f1, synthetic observational samples (Xi,Wi, Y (Wi)i )i are generated as follows: Xi ∼ Uniform[0,1], Wi ∼ Bernoulli(p(x |η)), and Y
(Wi) i ∼ fWi +N (0, σ 2), where σ2 = 0.1.",5.1.1. SYNTHETIC MODEL,[0],[0]
"Using the setup in Section 5.1.1, we conducted the following Monte Carlo simulations to verify our theoretical findings and highlight the merits of our NSGP model.
",5.1.2. EXPERIMENTS AND RESULTS,[0],[0]
"• Verifying Theorems 1 and 2: In order to check the validity of the results of Theorems 1 and 2, we use a NSGP Matérn prior GP(0,Kβ), with length-scale parameters β0 and β1 that are matched exactly with the regularities of the Brownian paths f0 and f1 (i.e. β0 = 2.5 and β1 = 5.5).",5.1.2. EXPERIMENTS AND RESULTS,[0],[0]
"According to Theorem 1, the optimal rate for estimating the CATE T = f1 − f0 is n −5 6 , and from Theorem 2, the NSGP with β0 = 2.5 and β1 = 5.5 should achieve that rate.
",5.1.2. EXPERIMENTS AND RESULTS,[0],[0]
Figure 2a provides a scatter-plot for the PEHE achieved by the NSGP with respect to the number of samples on a loglog scale for different settings of η.,5.1.2. EXPERIMENTS AND RESULTS,[0],[0]
We fit a linear regression model that describes the PEHE behavior in the log-log scale.,5.1.2. EXPERIMENTS AND RESULTS,[0],[0]
"We found the slope of the linear fit to be 0.8437, which is very close2 to the slope of 56 ≈ 0.833 predicted by Theorem 1.",5.1.2. EXPERIMENTS AND RESULTS,[0],[0]
"Moreover, by changing the magnitude of η from 0 to 12 , the PEHE curve did not exhibit any significant change in its slope, and was only moved upwards by a constant offset.",5.1.2. EXPERIMENTS AND RESULTS,[0],[0]
"On the contrary, Figure 2b shows the PEHE behavior when the NSGP prior is over-smoothed (β0 > α0) for η = 0: as predicted by Theorem 2, learning becomes sluggish (slopes become less steep) as β0 increase since the matching condition in (10) does not hold any more.
",5.1.2. EXPERIMENTS AND RESULTS,[0],[0]
"• NSGPs do not leave any money on the table: In this experiment, we show that the different components of the NSGP model allow it to perform well in small and large sample regimes.",5.1.2. EXPERIMENTS AND RESULTS,[0],[0]
"We set a strong selection bias of η = 12 and compare the log(PEHE) characteristic of NSGP with a model that uses the same non-stationary kernel as NSGP, and another model that uses a standard stationary kernel, but both models are tuned using marginal likelihood maximization.",5.1.2. EXPERIMENTS AND RESULTS,[0],[0]
"As we can see in Figure 2c, the model with the non-stationary kernel achieves the same learning rate as NSGP, but exhibits a large offset as it does not account for selection bias, whereas the stationary model fails to learn the smoothness of the rougher Brownian motion since it assigns the same length-scale to both surfaces, and hence it over-smooths the prior, achieving a suboptimal rate.
",5.1.2. EXPERIMENTS AND RESULTS,[0],[0]
2The minor discrepancy is a result of the residual error in the linear regression fit.,5.1.2. EXPERIMENTS AND RESULTS,[0],[0]
"We evaluated the performance of the NSGP model presented in Section 4.1 using the standard semi-synthetic experimental setup designed by Hill in (Hill, 2011).",5.2. The Infant Health and Development Program,[0],[0]
"We report a state-of-the-art result in this setup, and draw connections between our experimental results and our analyses.",5.2. The Infant Health and Development Program,[0],[0]
"The Infant Health and Development Program (IHDP) is an interventional program intended to enhance the health of premature infants (Hill, 2011).",5.2.1. DATA AND BENCHMARKS,[0],[0]
"(Hill, 2011) extracted features and treatment assignments from a real-world clinical trial, and introduced selection bias to the data artificially by removing a subset of the patients.",5.2.1. DATA AND BENCHMARKS,[0],[0]
"The potential outcomes are simulated according to the standard non-linear ”Response Surface B” setting in (Hill, 2011).",5.2.1. DATA AND BENCHMARKS,[0],[0]
"The dataset comprised 747 subjects, with 25 features for each subject.",5.2.1. DATA AND BENCHMARKS,[0],[0]
"Our experimental setup is identical to (Hill, 2011; Johansson et al., 2016; Shalit et al., 2017; Alaa & van der Schaar, 2017): we run 1000 experiments in which we compute the in-sample and out-of-sample √ PEHE (with 80/20 training/testing splits), and report average results in Table 1.
",5.2.1. DATA AND BENCHMARKS,[0],[0]
We compared the performance of NSGP with a total of 23 CATE estimation benchmarks.,5.2.1. DATA AND BENCHMARKS,[0],[0]
"We considered: tree-based algorithms (BART (Hill, 2011), Causal forests (Wager & Athey, 2017), Bayesian causal forests (Hahn et al., 2017)), methods based on deep learning (CFR Wass., CFR MMD, BNN, TARnet (Shalit et al., 2017)), multivariate additive regression splines (MARS) (Powers et al., 2017), Gaussian processes (CMGP) (Alaa & van der Schaar, 2017), nearest neighbor matching (k-NN), propensity score matching (PSM), and targeted maximum likelihood (TMLE) (Porter et al., 2011).",5.2.1. DATA AND BENCHMARKS,[0],[0]
"We also composed a number of T-learners and S-learners as in (Künzel et al., 2017), using a variety of baseline machine learning algorithms (DNN stands for deep networks and OLS stands for linear regression).",5.2.1. DATA AND BENCHMARKS,[0],[0]
"As we can see in Table 1, the proposed NSGP model significantly outperforms all competing benchmarks.",5.2.2. RESULTS AND CONCLUSIONS,[0],[0]
The combined benefit of the two components of an NSGP (nonstationary kernel and doubly-robust hyperparameters) is highlighted by comparing its performance to a vanilla SGP (stationary GP) with marginal likelihood maximization.,5.2.2. RESULTS AND CONCLUSIONS,[0],[0]
"The gain with respect to such a model is a 2-fold improvement in the PEHE.
",5.2.2. RESULTS AND CONCLUSIONS,[0],[0]
"Because the IHDP dataset has a “moderate” sample size, both selection bias and learning rate seem to impact the performance.",5.2.2. RESULTS AND CONCLUSIONS,[0],[0]
"Thus, our method took advantage of having addressed modeling questions [Q1] and [Q2] appropriately by being both “rate-optimal” and “bias-aware”.
",5.2.2. RESULTS AND CONCLUSIONS,[0],[0]
The check marks in columns [Q1] and [Q2] designate methods that address modeling questions,5.2.2. RESULTS AND CONCLUSIONS,[0],[0]
[Q1] and [Q2] “appropriately” in the light of the analysis presented in Section 3.,5.2.2. RESULTS AND CONCLUSIONS,[0],[0]
"Methods with [Q1] checked use a regression structure with “outcome-specific” hyperparameters, and methods with [Q2] checked adjust for selection bias.",5.2.2. RESULTS AND CONCLUSIONS,[0],[0]
A general observation is that the structure of the regression model seem to matter much more than the strategy for handling selection bias.,5.2.2. RESULTS AND CONCLUSIONS,[0],[0]
"This is evident from the fact that the TARnet model (does not handle bias but models outcomes separately) significantly outperforms BNN (handles bias but uses a single-surface model (Shalit et al., 2017)), and that all T-learners (models 2 separate response surfaces) outperformed their S-shaped counterparts (models a single surface).",5.2.2. RESULTS AND CONCLUSIONS,[0],[0]
"For parametric models, such as OLS, the issue of selecting the right regression structure is even more crucial.
",5.2.2. RESULTS AND CONCLUSIONS,[0],[0]
"To sum up, the results in Table 1 imply that selecting the right regression structure is crucial for rate-optimality in sufficiently large dataset, whereas handling selection bias provides an extra bonus.",5.2.2. RESULTS AND CONCLUSIONS,[0],[0]
"In Table 1, methods that address both [Q1] and [Q2] (NSGP, CMGP, and CFR.",5.2.2. RESULTS AND CONCLUSIONS,[0],[0]
Wass and MMD) displayed a superior performance.,5.2.2. RESULTS AND CONCLUSIONS,[0],[0]
The authors would like to thank the reviewers for their helpful comments.,Acknowledgements,[0],[0]
"The research presented in this paper was supported by the Office of Naval Research (ONR) and the NSF (Grant number: ECCS1462245, ECCS1533983, and ECCS1407712).",Acknowledgements,[0],[0]
Estimating heterogeneous treatment effects from observational data is a central problem in many domains.,abstractText,[0],[0]
"Because counterfactual data is inaccessible, the problem differs fundamentally from supervised learning, and entails a more complex set of modeling choices.",abstractText,[0],[0]
"Despite a variety of recently proposed algorithmic solutions, a principled guideline for building estimators of treatment effects using machine learning algorithms is still lacking.",abstractText,[0],[0]
"In this paper, we provide such guidelines by characterizing the fundamental limits of estimating heterogeneous treatment effects, and establishing conditions under which these limits can be achieved.",abstractText,[0],[0]
Our analysis reveals that the relative importance of the different aspects of observational data vary with the sample size.,abstractText,[0],[0]
"For instance, we show that selection bias matters only in small-sample regimes, whereas with a large sample size, the way an algorithm models the control and treated outcomes is what bottlenecks its performance.",abstractText,[0],[0]
"Guided by our analysis, we build a practical algorithm for estimating treatment effects using a non-stationary Gaussian processes with doubly-robust hyperparameters.",abstractText,[0],[0]
"Using a standard semi-synthetic simulation setup, we show that our algorithm outperforms the state-of-the-art, and that the behavior of existing algorithms conforms with our analysis.",abstractText,[0],[0]
Limits of Estimating Heterogeneous Treatment Effects: Guidelines for Practical Algorithm Design,title,[0],[0]
"Phase retrieval refers to the problem of recovering an unknown N -dimensional signal vector x 2 HN , with H being the set of either real (R) or complex (C) numbers, from the following nonlinear measurement process:
y = f(Ax+ e z ) + e y .",1. Introduction,[0],[0]
"(1)
Here, the measurement vector y 2 RM contains M realvalued observations, for example measured through the nonlinear function f(z) = |z|2 that operates element-wise on vectors, A 2 HM⇥N is a given measurement matrix, and the vectors ez 2 HM and ey 2 RN model signal and measurement noises, respectively.",1. Introduction,[0],[0]
"In contrast to the majority of
1School of Electrical and Computer Engineering, Cornell University, Ithaca, NY 2Department of EE, Princeton University 3University of Maryland.",1. Introduction,[0],[0]
"Correspondence to: Ramina Ghods <rg548@cornell.edu>, Christoph Studer <studer@cornell.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"existing results on phase retrieval that assume randomness in the measurement matrix A, we focus on the practical scenario in which the measurement matrix A is deterministic, but the signal vector x to be recovered as well as the two noise sources ez and ey are random.",1. Introduction,[0],[0]
"Phase retrieval has been studied extensively over the last decades (Gerchberg & Saxton, 1972; Fienup, 1982) and finds use in a range of applications, including imaging (Fogel et al., 2016; Yeh et al., 2015; Holloway et al., 2016), microscopy (Kou et al., 2010; Faulkner & Rodenburg, 2004), and X-ray crystallography (Harrison, 1993; Miao et al., 2008; Pfeiffer et al., 2006).",1.1. Phase Retrieval,[0],[0]
"Phase retrieval problems were solved traditionally using alternating projection methods, such as the Gerchberg-Saxton (Gerchberg & Saxton, 1972) and Fienup (Fienup, 1982) algorithms.",1.1. Phase Retrieval,[0],[0]
"More recent results have shown that semidefinite programming enables the design of algorithms with performance guarantees (Candès et al., 2013; Candès & Li, 2014; Candès et al., 2015a; Waldspurger et al., 2015).",1.1. Phase Retrieval,[0],[0]
"These methods lift the problem to a higher dimension, resulting in excessive complexity and memory requirements.",1.1. Phase Retrieval,[0],[0]
"To perform phase retrieval for highdimensional problems with performance guarantees, a range of convex (Bahmani & Romberg, 2017; Goldstein & Studer, 2017; Hand & Voroninski, 2016; Dhifallah et al., 2017; Dhifallah & Lu, 2017; Yuan & Wang, 2017; Salehi et al., 2018) and nonconvex methods (Netrapalli et al., 2013; Schniter & Rangan, 2015; Candès et al., 2015b; Chen & Candès, 2015; Zhang & Liang, 2016; Wang et al., 2017a; Zhang et al., 2016; Wei, 2015; Sun et al., 2016; Zeng & So, 2017; Lu & Li, 2017; Ma et al., 2018) have been proposed recently.",1.1. Phase Retrieval,[0],[0]
All of the above non-lifting-based phase retrieval methods rely on accurate initial estimates of the signal vector to be recovered.,1.2. Spectral Initializers,[0],[0]
"Such estimates are typically obtained by means of so-called spectral initializers put forward in (Netrapalli et al., 2013).",1.2. Spectral Initializers,[0],[0]
"Spectral initializers first compute a Hermitian matrix of the following form:
D =
MX
m=1
T (ym)amaHm, (2)
",1.2. Spectral Initializers,[0],[0]
"where > 0 is a suitably-chosen scaling factor, ym denotes the mth measurement, aHm corresponds to the mth row of the measurement matrix A and T : R !",1.2. Spectral Initializers,[0],[0]
R is a (possibly nonlinear) preprocessing function.,1.2. Spectral Initializers,[0],[0]
"While the identity T (y) = y was used originally in (Netrapalli et al., 2013), recent results revealed that carefully crafted preprocessing functions yield more accurate estimates (Chen & Candès, 2015; Chen et al., 2015; Wang et al., 2017a;b; Lu & Li, 2017; Mondelli & Montanari, 2017).",1.2. Spectral Initializers,[0],[0]
"From the matrix D in (2), one then extracts the (scaled) eigenvector ˆx associated with the largest eigenvalue, which serves as an initial estimate of the solution to the phase retrieval problem.
",1.2. Spectral Initializers,[0],[0]
"As shown in (Netrapalli et al., 2013; Chen & Candès, 2015; Chen et al., 2015; Wang et al., 2017a;b; Lu & Li, 2017; Mondelli & Montanari, 2017), for i.i.d.",1.2. Spectral Initializers,[0],[0]
"Gaussian measurement matrices A, sufficiently large measurement ratios = M/N , and carefully crafted preprocessing functions T , spectral initializers provide accurate initialization vectors.",1.2. Spectral Initializers,[0],[0]
"In fact, the results in (Mondelli & Montanari, 2017) for the large-system limit with fixed and M ! 1 show that spectral initializers in combination with an optimal preprocessing function T achieve the fundamental informationtheoretic limits of phase retrieval.",1.2. Spectral Initializers,[0],[0]
"However, the assumption of having i.i.d.",1.2. Spectral Initializers,[0],[0]
"Gaussian measurement matrices A is impractical—it is more natural to assume that the signal vector x is random and the measurement matrix A is deterministic and structured (Bendory & Eldar, 2017).",1.2. Spectral Initializers,[0],[0]
"We propose a novel class of estimators, called linear spectral estimators (LSPEs), that provide accurate estimates for general nonlinear measurement systems of the form (1) and enable a nonasymptotic mean-squared error (MSE) analysis.",1.3. Contributions,[0],[0]
"We showcase the efficacy of LSPEs by applying them to phase retrieval problems, where we compute initialization vectors for real- and complex-valued systems with deterministic and finite-dimensional measurement matrices.",1.3. Contributions,[0],[0]
"For the proposed LSPEs, we derive nonasymptotic and sharp bounds on the MSE for signal estimation from phaseless measurements.",1.3. Contributions,[0],[0]
We use synthetic and real-world phase retrieval problems to demonstrate that LSPEs are able to significantly outperform existing spectral initializers on systems that acquire structured measurements.,1.3. Contributions,[0],[0]
We furthermore show that preprocessing the phaseless measurements enables LSPEs to generate improved initialization vectors for an even broader class of measurement systems.,1.3. Contributions,[0],[0]
"Lowercase and uppercase boldface letters represent column vectors and matrices, respectively.",1.4. Notation,[0],[0]
"For a matrix A, its transpose and Hermitian conjugate is AT and AH , respectively, and the kth row and `th column entry is [A]k,` = Ak,`.",1.4. Notation,[0],[0]
"For
a vector a, the kth entry is [a]k = ak.",1.4. Notation,[0],[0]
The `2-norm of a is denoted by kak2 and the Frobenius norm of A by kAkF .,1.4. Notation,[0],[0]
"The Kronecker product is ⌦, the Hadamard product is , the Hadamard division is ↵, and the trace operator is tr(·).",1.4. Notation,[0],[0]
"The N ⇥N identity matrix is denoted by IN ; the M ⇥N all-zeros and all-ones matrices are denoted by 0M⇥N and 1M⇥N , respectively.",1.4. Notation,[0],[0]
"For a vector a, diag(a) is a square matrix with a on the main diagonal; for a matrix A, diag(A) is a column vector containing the diagonal elements of A.",1.4. Notation,[0],[0]
"We start by reviewing the essentials of spectral initializers and then, introduce linear spectral estimators (LSPEs) for measurement systems of the form (1) with general nonlinearities f .",2. Linear Spectral Estimators,[0],[0]
"We furthermore provide nonasymptotic expressions for the associated estimation error, and we compare our analytical results to that of conventional spectral initializers in (2).",2. Linear Spectral Estimators,[0],[0]
"In Section 3, we will apply LSPEs to phase retrieval.",2. Linear Spectral Estimators,[0],[0]
"One of the key issues of the phase retrieval problem is the fact that if x is a solution to (1), then ej x for any 2 [0, 2⇡) is also a valid solution (assuming H = C).",2.1. Spectral Estimation and Initializers,[0],[0]
"Put simply, the solution is nonunique up to a global phase shift.",2.1. Spectral Estimation and Initializers,[0],[0]
"One way of combating this issue is to directly recover the outer product xxH instead of x, which is unaffected by phase shifts; this insight is the key underlying lifting-based phase retrieval methods (Candès et al., 2013; Candès & Li, 2014; Candès et al., 2015a; Waldspurger et al., 2015).",2.1. Spectral Estimation and Initializers,[0],[0]
"With this in mind, one could envision the design of an estimator that directly minimizes the conditional MSE:
˙ x = arg min x̃2HN E ⇥kxxH ˜x˜xHk2F | y ⇤ .",2.1. Spectral Estimation and Initializers,[0],[0]
"(3)
Here, expectation is with respect to the signal vector x and the two noise sources ez and ey .",2.1. Spectral Estimation and Initializers,[0],[0]
"This optimization problem resembles that of a posterior mean estimator (PME) which is, in general, difficult to derive, even for simple observation models—for phase retrieval, we have two additional challenges: (i) nonlinear phaseless measurements as in (1) and (ii) the quantity ˜x˜xH has rank-1.
",2.1. Spectral Estimation and Initializers,[0],[0]
Spectral initializers avoid the issues of the estimator in (3) by first replacing the true outer product xxH with a socalled spectral estimator matrix D as in (2) that depends on the measurement vector y.,2.1. Spectral Estimation and Initializers,[0],[0]
"In a second step, one then computes the best rank-1 approximation as follows:
ˆ x = arg min x̃2HN kD ˜x˜xHk2F (4)
from which the estimate ˆx can be extracted.",2.1. Spectral Estimation and Initializers,[0],[0]
"By performing an eigenvalue decomposition D = U⇤UH with U H U = IM and the eigenvalues in the diagonal matrix
⇤ = diag([ 1, . . .",2.1. Spectral Estimation and Initializers,[0],[0]
", M ] T ) are sorted in descending order of their magnitudes, a spectral initializer is given by the scaled leading eigenvector ˆx = p 1u1.",2.1. Spectral Estimation and Initializers,[0],[0]
"In practice, one can use power iterations to efficiently compute ˆx.",2.1. Spectral Estimation and Initializers,[0],[0]
"We now propose a novel class of estimators, which we call linear spectral estimators (LSPEs), that provide accurate estimates for general nonlinear measurement systems of the form (1).",2.2. Linear Spectral Estimators,[0],[0]
"To this end, we borrow ideas from the spectral initializer, the PME in (3), and the linear phase retrieval algorithm put forward in (Ghods et al., 2018).",2.2. Linear Spectral Estimators,[0],[0]
"In the first step, LSPEs apply a linear estimator to the nonlinear observations in T (y) to construct a spectral estimator matrix D
y
for which the spectral MSE (or matrix MSE) defined as
S-MSE = E h D
y xxH 2 F
i (5)
is minimal.",2.2. Linear Spectral Estimators,[0],[0]
"We restrict ourselves to spectral estimator matrices D
y
that are affine in T (y), i.e., are of the form
D
y = W0 +
MX
m=1
T (ym)Wm (6)
with Wm 2 HN⇥N , m = 0, . . .",2.2. Linear Spectral Estimators,[0],[0]
",M .",2.2. Linear Spectral Estimators,[0],[0]
"In the second step, we use the spectral estimator matrix D
y to extract a (scaled) leading eigenvector as in (3), which is the linear spectral estimate of the signal vector x. Intuitively, if we can construct a matrix D
y from the preprocessed measurements in T (y) for which the S-MSE in (5) is minimal, then we expect that computing its best rank-1 approximation would yield an accurate estimate of the signal vector x up to a global phase shift.",2.2. Linear Spectral Estimators,[0],[0]
"We will justify this claim in Section 2.3.
",2.2. Linear Spectral Estimators,[0],[0]
"Mathematically, we wish to compute a matrix D y of the form (6) that is the solution to the following problem:
minimize
f Wm2HN⇥N m=0,...,M
E
2
4 f W0 +
MX
m=1
T (ym)fWm xxH
2
F
3
5 .",2.2. Linear Spectral Estimators,[0],[0]
"(7)
Clearly, the spectral estimator matrix D y will depend on the measurement matrix A, the statistics of the signal to be estimated x and the two noise sources ez and ey, the nonlinearity f , as well as the preprocessing function T .",2.2. Linear Spectral Estimators,[0],[0]
"For this setting, we have the following general result which summarizes the LSPE; the proof is given in Appendix A.
Theorem 1 (Linear Spectral Estimator).",2.2. Linear Spectral Estimators,[0],[0]
Let the measurement vector y be a result of the general measurement model in (1) and select a preprocessing function T .,2.2. Linear Spectral Estimators,[0],[0]
"Define the vector T (y) = E[T (y)] and assume the matrix
T = E ⇥",2.2. Linear Spectral Estimators,[0],[0]
"(T (y) T (y))(T (y) T (y))T ⇤
is full rank.",2.2. Linear Spectral Estimators,[0],[0]
Let t 2 RM satisfy Tt = T (y) T (y) and Vm = E ⇥,2.2. Linear Spectral Estimators,[0],[0]
"(T (ym) T (ym))(xxH Kx) ⇤
for m = 1, . . .",2.2. Linear Spectral Estimators,[0],[0]
",M with K x = E ⇥",2.2. Linear Spectral Estimators,[0],[0]
xx H ⇤ .,2.2. Linear Spectral Estimators,[0],[0]
"Then, the LSPE matrix that minimizes the S-MSE in (5) is given by
D
y
= K
x
+
MX
m=1
tmVm.",2.2. Linear Spectral Estimators,[0],[0]
"(8)
The linear spectral estimate ˆx is then given by the scaled leading eigenvector of the matrix D
y
in (8).
",2.2. Linear Spectral Estimators,[0],[0]
"The vector t is the only quantity in Theorem 1 that depends on the actual (nonlinear) observations contained in the measurement vector y. All other quantities depend only on the first two moments of xxH as well as the considered signal, noise, and measurement models.",2.2. Linear Spectral Estimators,[0],[0]
The key features of the LSPE are as follows: (i) the involved quantities can often be computed in closed form (see Section 3 for two applications to phase retrieval) and (ii) LSPEs enable a nonasymptotic and sharp analysis of the associated estimation error.,2.2. Linear Spectral Estimators,[0],[0]
Remark 1.,2.2. Linear Spectral Estimators,[0],[0]
Theorem 1 requires the matrix T to be invertible.,2.2. Linear Spectral Estimators,[0],[0]
This condition is satisfied in most practical situations with nondegenerate measurement matrices A or in situations with nonzero measurement noise.,2.2. Linear Spectral Estimators,[0],[0]
The remaining piece of the proposed LSPE is to show that the result of this two-step estimation procedure indeed yields a vector that is close to the signal vector x.,2.3. Estimation Error Analysis of LSPEs,[0],[0]
We start with the following result; the proof is given in Appendix B. Theorem 2 (S-MSE of the LSPE).,2.3. Estimation Error Analysis of LSPEs,[0],[0]
Let the assumptions of Theorem 1 hold.,2.3. Estimation Error Analysis of LSPEs,[0],[0]
"Then, the S-MSE in (5) for the LSPE matrix in (8) is given by
S-MSELSPE = C xx
H MX
m=1
MX
m0=1
[T 1 ]m,m0 tr V H mVm0
(9)
with C xx
H = E",2.3. Estimation Error Analysis of LSPEs,[0],[0]
h,2.3. Estimation Error Analysis of LSPEs,[0],[0]
xx,2.3. Estimation Error Analysis of LSPEs,[0],[0]
"H K x 2 F i .
",2.3. Estimation Error Analysis of LSPEs,[0],[0]
"With this result, we are ready to establish a bound on the estimation error of the LSPE.",2.3. Estimation Error Analysis of LSPEs,[0],[0]
The proof of the following result follows from Theorem 2 and is given in Appendix C. Corollary 1 (LSPE Estimation Error).,2.3. Estimation Error Analysis of LSPEs,[0],[0]
Let the assumptions of Theorem 1 hold.,2.3. Estimation Error Analysis of LSPEs,[0],[0]
"Then, the estimation error (EER) of the LSPE satisfies the following inequality:
EERLSPE = E ⇥kˆxˆxH",2.3. Estimation Error Analysis of LSPEs,[0],[0]
xxHk2F,2.3. Estimation Error Analysis of LSPEs,[0],[0]
⇤  4 S-MSELSPE.,2.3. Estimation Error Analysis of LSPEs,[0],[0]
"(10)
",2.3. Estimation Error Analysis of LSPEs,[0],[0]
"This result implies that by minimizing the S-MSE in (5) via (7), we are also reducing the EER of the LSPE.",2.3. Estimation Error Analysis of LSPEs,[0],[0]
"In other words, if the spectral error E = D
y ˆxˆxH is small, then the EER of the LSPE (10) will be small.
",2.3. Estimation Error Analysis of LSPEs,[0],[0]
Remark 2.,2.3. Estimation Error Analysis of LSPEs,[0],[0]
Corollary 1 is nonasymptotic and depends on the instance of measurement matrix A.,2.3. Estimation Error Analysis of LSPEs,[0],[0]
"This result is in stark contrast to existing performance bounds for spectral initializers (Netrapalli et al., 2013; Chen & Candès, 2015; Chen et al., 2015; Wang et al., 2017a;b) that strongly rely on randomness in the measurement matrix.",2.3. Estimation Error Analysis of LSPEs,[0],[0]
"In addition to randomness, the sharp performance guarantees in (Lu & Li, 2017; Mondelli & Montanari, 2017) focus on the asymptotic regime for which = M/N is fixed and M ! 1.",2.3. Estimation Error Analysis of LSPEs,[0],[0]
We can also derive an exact expression for the S-MSE of the conventional spectral initializer in (2).,2.4. S-MSE of Spectral Initializers,[0],[0]
"We assume optimal scaling, i.e., the parameter is set to minimize the S-MSE.",2.4. S-MSE of Spectral Initializers,[0],[0]
The following result characterizes the S-MSE of such a scaled spectral initializer; the proof is given in Appendix D. Proposition 1 (S-MSE of the Spectral Initializer).,2.4. S-MSE of Spectral Initializers,[0],[0]
Let D be the conventional spectral initializer matrix in (2).,2.4. S-MSE of Spectral Initializers,[0],[0]
"Then, the optimally-scaled S-MSE defined as
S-MSESI = min 2H
E ⇥kD xxHk2F",2.4. S-MSE of Spectral Initializers,[0],[0]
"⇤ (11)
is given by
S-MSESI = R xx
H PM m=1 a H m e Vmam 2
PM m=1 PM m0=1",2.4. S-MSE of Spectral Initializers,[0],[0]
"e Tm,m0 |aHmam0 |2 ,
(12)
where R xx H = E ⇥kxxHk2F",2.4. S-MSE of Spectral Initializers,[0],[0]
"⇤ , eVm = E ⇥T (ym)xxH ⇤ , m = 1, . . .",2.4. S-MSE of Spectral Initializers,[0],[0]
",M , and eT = E ⇥T (y)T (y)T ⇤.
",2.4. S-MSE of Spectral Initializers,[0],[0]
"Since the matrix in (2) is a special case of the LSPE matrix in (6), we have the following simple yet important property:
S-MSELSPE  S-MSESI.",2.4. S-MSE of Spectral Initializers,[0],[0]
"In words, the spectral MSE of the LSPE cannot be worse than that of a spectral initializer.",2.4. S-MSE of Spectral Initializers,[0],[0]
"As we will show in Section 4, LSPEs are able to outperform spectral initializers on both synthetic and real-world phase retrieval problems given that the same preprocessing function T is used.",2.4. S-MSE of Spectral Initializers,[0],[0]
The LSPE provides a framework for estimating signal vectors from the general observation model in (1).,3. LSPEs for Phase Retrieval Problems,[0],[0]
"To make the concept of LSPEs explicit and to demonstrate their efficacy in practice, we now show two application examples to phase retrieval in complex-valued systems.",3. LSPEs for Phase Retrieval Problems,[0],[0]
The LSPE for real-valued phase retrieval can be found in Appendix E.,3. LSPEs for Phase Retrieval Problems,[0],[0]
"We first focus on the case where the signal vector x to be estimated and the measurement matrix A are both complex-
valued.",3.1. Phase Retrieval without Preprocessing,[0],[0]
"The phaseless measurements y, however, remain real-valued.",3.1. Phase Retrieval without Preprocessing,[0],[0]
"We need the following assumptions.
",3.1. Phase Retrieval without Preprocessing,[0],[0]
Assumptions 1.,3.1. Phase Retrieval without Preprocessing,[0],[0]
Let H = C. Assume square absolute measurements f(z) = |z|2 and the identity preprocessing function T (y),3.1. Phase Retrieval without Preprocessing,[0],[0]
= y. Assume that the signal vector x 2 CN is i.i.d.,3.1. Phase Retrieval without Preprocessing,[0],[0]
"circularly-symmetric complex Gaussian with covariance matrix C
x
= 2 xIN , i.e., x ⇠ CN (0N⇥1, 2xIN ).",3.1. Phase Retrieval without Preprocessing,[0],[0]
"As-
sume that the signal noise vector ez is circularly-symmetric complex Gaussian with covariance matrix C
e z , i.e., ez ⇠ CN (0M⇥1,Cez ), and the measurement noise vector ey is a real-valued Gaussian vector with mean ¯ey and covariance matrix C
e y , i.e., ey ⇠ N (¯ey,C e y ).",3.1. Phase Retrieval without Preprocessing,[0],[0]
"Furthermore assume
that x, ez , and ey are independent.
",3.1. Phase Retrieval without Preprocessing,[0],[0]
"Under these assumptions, we can derive the following LSPE which we call LSPE-C; the detailed derivations of this spectral estimator are given in Appendix G.
Estimator 1 (LSPE-C).",3.1. Phase Retrieval without Preprocessing,[0],[0]
Let Assumptions 1 hold.,3.1. Phase Retrieval without Preprocessing,[0],[0]
"Then, the spectral estimation matrix is given by
D C y = K x +
MX
m=1
tmVm, (13)
",3.1. Phase Retrieval without Preprocessing,[0],[0]
"where K x = 2 xIN , the vector t 2 RM is given by the solution to the linear system Tt = y y with
y = diag(C
z
)",3.1. Phase Retrieval without Preprocessing,[0],[0]
"+
¯ e
y
C
z
= 2 xAA",3.1. Phase Retrieval without Preprocessing,[0],[0]
"H +C e z
T = C
z C",3.1. Phase Retrieval without Preprocessing,[0],[0]
"⇤ z +C e y
and Vm = 4xamaHm, m = 1, . . .",3.1. Phase Retrieval without Preprocessing,[0],[0]
",M .",3.1. Phase Retrieval without Preprocessing,[0],[0]
"The spectral estimate ˆx is given by the (scaled) leading eigenvector of DC
y
in (13).",3.1. Phase Retrieval without Preprocessing,[0],[0]
"Furthermore, the S-MSE is given by Theorem 2.
",3.1. Phase Retrieval without Preprocessing,[0],[0]
We emphasize that the spectral estimator matrix in (13) resembles that of the conventional spectral initializer matrix (2) with the following key differences.,3.1. Phase Retrieval without Preprocessing,[0],[0]
"First and foremost, each outer product contained in Vm = 4xamaHm in Estimator 1 is weighted by tm, which is a function of all phaseless measurements in y and of the covariance matrix C
x .",3.1. Phase Retrieval without Preprocessing,[0],[0]
"In contrast, each outer product in the conventional spectral initializer matrix in (2) is only weighted by the associated measurement ym.",3.1. Phase Retrieval without Preprocessing,[0],[0]
"This difference enables the LSPE to weight each outer product depending on correlations in the phaseless measurements caused by structure in the matrix A. Second, the spectral estimator matrix includes a mean term K
x , which is absent in the spectral initializer matrix.",3.1. Phase Retrieval without Preprocessing,[0],[0]
"As we will show in Section 4, for the same preprocessing function T , Estimator 1 is able to outperform spectral initializers for systems with structured measurement matrices A.",3.1. Phase Retrieval without Preprocessing,[0],[0]
For large i.i.d.,3.1. Phase Retrieval without Preprocessing,[0],[0]
"Gaussian measurement matrices, there is no particular correlation structure to exploit and LSPEs perform on par with spectral initializers.",3.1. Phase Retrieval without Preprocessing,[0],[0]
"To demonstrate the flexibility and generality of our framework, we now design an LSPE with an exponential preprocessing function for complex-valued phase retrieval.",3.2. Phase Retrieval with Exponential Preprocessing,[0],[0]
We derive the LSPE under the following assumptions.,3.2. Phase Retrieval with Exponential Preprocessing,[0],[0]
Assumptions 2.,3.2. Phase Retrieval with Exponential Preprocessing,[0],[0]
"Let H = C. Assume square absolute measurements f(z) = |z|2 and the exponential preprocessing function T (y) = exp( y) with > 0, i.e., we consider
T (y) = exp (|z|2 + ey) and z = Ax+",3.2. Phase Retrieval with Exponential Preprocessing,[0],[0]
"ez, where the exponential function is applied element-wise to vectors.",3.2. Phase Retrieval with Exponential Preprocessing,[0],[0]
"The remaining assumptions are the same as in Assumptions 1.
",3.2. Phase Retrieval with Exponential Preprocessing,[0],[0]
We now derive the following LSPE called LSPE-Exp; the derivation of this spectral estimator is given in Appendix H. Estimator 2 (LSPE-Exp).,3.2. Phase Retrieval with Exponential Preprocessing,[0],[0]
Let Assumptions 2 hold.,3.2. Phase Retrieval with Exponential Preprocessing,[0],[0]
"Then, the spectral estimation matrix is given by
D",3.2. Phase Retrieval with Exponential Preprocessing,[0],[0]
"Exp y = K x +
MX
m=1
tmVm, (14)
",3.2. Phase Retrieval with Exponential Preprocessing,[0],[0]
"where K x = 2 xIN , the vector t 2 RM is given by the solution to the linear system Tt = T (y) T (y) with T (y) = p ↵ q
T =",3.2. Phase Retrieval with Exponential Preprocessing,[0],[0]
"(p p T ) exp( 2Cey )↵(q qT 2Cz C⇤z)
(p pT )",3.2. Phase Retrieval with Exponential Preprocessing,[0],[0]
"↵ (q qT )
",3.2. Phase Retrieval with Exponential Preprocessing,[0],[0]
Vm = 4 x[p,3.2. Phase Retrieval with Exponential Preprocessing,[0],[0]
"]m
( [C
z",3.2. Phase Retrieval with Exponential Preprocessing,[0],[0]
"]m,m + 1) 2 ama
H m, m = 1, . . .",3.2. Phase Retrieval with Exponential Preprocessing,[0],[0]
",M,
where we use the following definitions:
q = diag(Cz) + 1M⇥1 p = exp
¯ey + 2 12 diag(Cey )
C
z
= 2 xAA",3.2. Phase Retrieval with Exponential Preprocessing,[0],[0]
"H +C e z .
",3.2. Phase Retrieval with Exponential Preprocessing,[0],[0]
"The spectral estimate ˆx is given by the (scaled) leading eigenvector of DExp
y in (14).",3.2. Phase Retrieval with Exponential Preprocessing,[0],[0]
"Furthermore, the S-MSE of this estimator is given by Theorem 2.
",3.2. Phase Retrieval with Exponential Preprocessing,[0],[0]
"At first sight, the choice of the exponential preprocessing function used in Estimator 2 seems to be arbitrary.",3.2. Phase Retrieval with Exponential Preprocessing,[0],[0]
"We emphasize, however, that this particular function is inspired by the asymptotically-optimal preprocessing function for properly-normalized Gaussian measurement ensembles proposed in (Mondelli & Montanari, 2017) which is given by
Topt(y) = y 1 y + p 1 .",3.2. Phase Retrieval with Exponential Preprocessing,[0],[0]
"(15)
As it turns out, we can scale, negate, and shift the exponential preprocessing function T (y) = exp( y) to make it
take a similar shape as the function in (15).",3.2. Phase Retrieval with Exponential Preprocessing,[0],[0]
"More concretely, exponential preprocessing as well as Topt(y) enables one to attenuate the effect of measurements with large magnitude, which is also the idea underlying the class of orthogonal spectral initializers, as proposed in (Chen et al., 2015; Wang et al., 2017a;b), that perform well in practice.",3.2. Phase Retrieval with Exponential Preprocessing,[0],[0]
We now compare the performance of our LSPEs against existing spectral initializers proposed for phase retrieval on synthetic and real image data.,4. Numerical Results,[0],[0]
"All our results use the spectral initializers and experimental setups provided by PhasePack (Chandra et al., 2017).",4. Numerical Results,[0],[0]
"We start by comparing the normalized MSE (N-MSE) defined as (Chandra et al., 2017)
N-MSE = min↵2H kx ↵ˆxk2
kxk2 for a range of spectral initializers on different measurement ensembles.",4.1. Impact of Measurement Ensemble,[0],[0]
"Specifically, we focus on the complex-valued case and consider (i) an i.i.d.",4.1. Impact of Measurement Ensemble,[0],[0]
"Gaussian measurement matrix with signal dimension N = 16, (ii) an i.i.d.",4.1. Impact of Measurement Ensemble,[0],[0]
"Gaussian measurement matrix with N = 256, and (iii) the structured “transmission matrix” used for image recovery through multiple scattering media as detailed in (Metzler et al., 2017).",4.1. Impact of Measurement Ensemble,[0],[0]
"We vary the oversampling ratio = M/N and compare the N-MSE of the proposed complex-valued LSPEs, LSPE-C (Estimator 1) and LSPE-Exp (Estimator 2 with = 0.001), to the following spectral initializers: the original spectral initializer (Netrapalli et al., 2013; Candès et al., 2015a) called “spectral,” truncated spectral initializer (Chen & Candès, 2015) called “truncated,” weighted spectral initializer (Wang et al., 2017b) called “weighted,” amplitude spectral initializer (Wang et al., 2017a) called “amplitude,” orthogonal spectral initializer (Chen et al., 2015)",4.1. Impact of Measurement Ensemble,[0],[0]
"called “orthogonal,” and the asymptotically-optimal spectral initializer (Mondelli & Montanari, 2017) called “optimal.”",4.1. Impact of Measurement Ensemble,[0],[0]
"For the following synthetic experiments, we generate the signals to be recovered according to Assumptions 1 and Assumptions 2 for LSPE-C and LSPE-Exp, respectively.
",4.1. Impact of Measurement Ensemble,[0],[0]
Figure 1a shows that the proposed LSPEs significantly outperform all existing spectral initializers for small problem dimensions with Gaussian measurements; this improvement is even more pronounced for large oversampling ratios.,4.1. Impact of Measurement Ensemble,[0],[0]
"The reason is that since we randomly generate a low-dimensional sensing matrix, the system will exhibit strong correlations among the measurements that can be exploited by LSPEs.",4.1. Impact of Measurement Ensemble,[0],[0]
"For larger dimensions with Gaussian measurements, we see in Figure 1b that the proposed LSPEs do not provide an advantage over other methods.",4.1. Impact of Measurement Ensemble,[0],[0]
"In fact, only LSPE-Exp is
able to perform as well as the orthogonal spectral initializer, which achieves the best performance in this scenario.",4.1. Impact of Measurement Ensemble,[0],[0]
This behavior can be attributed to the facts that (i) for large random matrices there is no particular correlation structure among the measurements to exploit and (ii) ignoring measurements associated to large values in ym is increasingly important.,4.1. Impact of Measurement Ensemble,[0],[0]
"For structured measurements, as it is the case for the transmission matrix from (Metzler et al., 2017), we see in Figure 1c that LSPEs significantly outperform existing methods that are designed for random measurement ensembles.",4.1. Impact of Measurement Ensemble,[0],[0]
"In this scenario, exponential preprocessing does not improve performance since correlations in the transmission matrix are dominating the performance.",4.1. Impact of Measurement Ensemble,[0],[0]
"We now validate our theoretical S-MSE expressions in Theorem 2 and Proposition 1, and confirm the accuracy of the EER bound given in Corollary 1.",4.2. S-MSE Expressions and Approximation Error,[0],[0]
"In the following experiment, we set M = 8N and vary the dimension N from 8 to 64.",4.2. S-MSE Expressions and Approximation Error,[0],[0]
"For each pair (M,N), we randomly generate one instance of an i.i.d.",4.2. S-MSE Expressions and Approximation Error,[0],[0]
"circularly symmetric complex Gaussian measurement matrix and average the different errors (S-MSE and EER) over 10, 000 Monte-Carlo trials.",4.2. S-MSE Expressions and Approximation Error,[0],[0]
"We consider a noiseless setting and assume identity preprocessing, i.e., T (y) = y.",4.2. S-MSE Expressions and Approximation Error,[0],[0]
The signal vectors are generated according to an i.i.d.,4.2. S-MSE Expressions and Approximation Error,[0],[0]
circularly complex Gaussian random vector.,4.2. S-MSE Expressions and Approximation Error,[0],[0]
"From Figure 2, we see that our analytical S-MSE expressions for the LSPE-C and spectral initializers match their empirical values.",4.2. S-MSE Expressions and Approximation Error,[0],[0]
We furthermore see that the empirical EER is only about 6 dB to 10 dB lower than our non-asymptotic upper bound given in Corollary 1.,4.2. S-MSE Expressions and Approximation Error,[0],[0]
We finally illustrate the efficacy of LSPEs in a more realistic scenario.,4.3. Real-World Image Recovery,[0],[0]
"In particular, we show results for a real image reconstruction task by using LSPEs and spectral initializers
only, i.e., we are not using any additional phase retrieval algorithm.",4.3. Real-World Image Recovery,[0],[0]
"Our goal is to recover a 16⇥16-pixel and a 40⇥40- pixel image that was captured through a multiple scattering media using the deterministic and highly-structured transmission matrix as detailed in (Metzler et al., 2017).",4.3. Real-World Image Recovery,[0],[0]
We compare the proposed LSPEs to the same set of spectral initializers as in Section 4.1.,4.3. Real-World Image Recovery,[0],[0]
"The signal priors are as in Assumptions 1 (LSPE-C) and Assumptions 2 (LSPE-Exp).
",4.3. Real-World Image Recovery,[0],[0]
Figures 3 and 4 show the recovered images along with the N-MSE values.,4.3. Real-World Image Recovery,[0],[0]
The proposed LSPEs (often significantly) outperform all spectral initializers in terms of visual quality as well as the N-MSE.,4.3. Real-World Image Recovery,[0],[0]
This result confirms the observations made in Figure 1c that LSPEs outperform existing spectral initializers for structured measurement matrices.,4.3. Real-World Image Recovery,[0],[0]
We note that exponential preprocessing for LSPEs does not noticeably improve the N-MSE (over LSPE-C) in this setting since correlations in the transmission measurement matrix are dominating the recovery performance.,4.3. Real-World Image Recovery,[0],[0]
"We have proposed a novel class of estimators, called linear spectral estimators (LSPEs), which are suitable for the recovery of signals from general nonlinear measurement systems.",5. Conclusions,[0],[0]
"We have developed nonasymptotic and deterministic performance guarantees for LSPEs that provide accurate bounds on the estimation error, especially for structured or low-dimensional measurement systems.",5. Conclusions,[0],[0]
"To demonstrate the efficacy of LSPEs in practice, we have applied them to complex-valued phase retrieval problems, in which LSPEs can be used to compute accurate signal estimates or initialization vectors for other convex or nonconvex phase retrieval algorithms.",5. Conclusions,[0],[0]
We have shown that properly preprocessing the nonlinear measurements can further improve the performance of LSPEs in practical scenarios.,5. Conclusions,[0],[0]
"Our simulations with synthetic and real data have shown that LSPEs are able to significantly outperform existing spectral initializers, especially for low-dimensional problems, for structured measurement matrices, or for large oversampling ratios.
",5. Conclusions,[0],[0]
There are many avenues for future work.,5. Conclusions,[0],[0]
"First, one could derive LSPEs for the asymptotically-optimal preprocessing function in (15) or for other commonly used functions, which may lead to further performance improvements.",5. Conclusions,[0],[0]
"Second, the proposed error analysis could be used to generate improved measurement matrices.",5. Conclusions,[0],[0]
"Third, an exploration of LSPEs for other nonlinearities that arise in machine learning and signal processing applications is left for future work.",5. Conclusions,[0],[0]
"R. Ghods and C. Studer were supported in part by Xilinx, Inc. and by the US National Science Foundation (NSF) under grants ECCS-1408006, EECS-1740286, CCF-1535897, CCF-1652065, and CNS-1717559.",Acknowledgments,[0],[0]
"T. Goldstein was supported by the US NSF under grant CCF-1535902, the US ONR under grant N00014-15-1-2676, the DARPA Lifelong Learning Machines program, and the Sloan Foundation.",Acknowledgments,[0],[0]
"The proof proceeds in two steps detailed as follows.
",A. Proof of Theorem 1,[0],[0]
Mean Matrix We first compute the mean matrix W0.,A. Proof of Theorem 1,[0],[0]
"Since (7) is a quadratic form, we can take the derivative in fWH0 and set it to zero, i.e.,
d
d f W
H 0
E
2
4 f W0 +
MX
m=1
T (ym)fWm xxH
2
F
3
5 = 0.
",A. Proof of Theorem 1,[0],[0]
"Basic matrix calculus yields
f W0 = Kx PM m=1 T (ym)fWm (16)
with T (ym) = E[T (ym)] and Kx = E ⇥",A. Proof of Theorem 1,[0],[0]
"xx H ⇤ .
",A. Proof of Theorem 1,[0],[0]
"Linear Estimation Matrix With (16) and the fact that (7) is a quadratic form in the matrices Wm, m = 1, . . .",A. Proof of Theorem 1,[0],[0]
",M ,
we take the derivatives in WHm and setting them to zero:
d dfWHm
E "" MX
m=1
(T (ym) T (ym))fWm (xxH Kx) 2
F
# =0.
",A. Proof of Theorem 1,[0],[0]
"By interchanging the derivative with expectation and with basic manipulations, we obtain the following set of optimality conditions for Wm for m = 1, . . .",A. Proof of Theorem 1,[0],[0]
",M : PM
m0=1 f Wm0 E ⇥",A. Proof of Theorem 1,[0],[0]
(T (ym) T (ym))(T (ym0) T (ym0)),A. Proof of Theorem 1,[0],[0]
"⇤
= E ⇥",A. Proof of Theorem 1,[0],[0]
(T (ym) T (ym))(xxH Kx) ⇤ .,A. Proof of Theorem 1,[0],[0]
"(17)
In compact matrix form, the above condition reads
(T⌦ IN⇥N )",A. Proof of Theorem 1,[0],[0]
"W = V, (18) where we used the following shortcuts:
T = E ⇥",A. Proof of Theorem 1,[0],[0]
"(T (y) T (y))(T (y) T (y))T ⇤
W =",A. Proof of Theorem 1,[0],[0]
"[ f W T 1 , . . .",A. Proof of Theorem 1,[0],[0]
", f W T m, . . .",A. Proof of Theorem 1,[0],[0]
", f W T M ] T
Vm= E ⇥",A. Proof of Theorem 1,[0],[0]
"(T (ym) T (ym))(xxH Kx) ⇤ ,m = 1, . . .",A. Proof of Theorem 1,[0],[0]
",M
V =",A. Proof of Theorem 1,[0],[0]
"[V T 1 , . . .",A. Proof of Theorem 1,[0],[0]
",V T m, . . .",A. Proof of Theorem 1,[0],[0]
",V T M ] T .
",A. Proof of Theorem 1,[0],[0]
"The condition in (18) can be solved for the estimation matrices in W leading to W = (T 1 ⌦ IN⇥N )V, where we require the matrix T to be full rank.",A. Proof of Theorem 1,[0],[0]
"To obtain the linear spectral estimator matrix, we simplify as
D
y
= K
x + ((T (y) T (y))T ⌦ IN⇥N )",A. Proof of Theorem 1,[0],[0]
"W = K
x
+ PM m=1 tmVm,
where we define the vector t = T 1(T (y) T (y)).",A. Proof of Theorem 1,[0],[0]
"To compute the spectral MSE in (5), we simplify
S-MSE = E  PM m=1 tmVm (xxH Kx) 2
F
.
",B. Proof of Theorem 2,[0],[0]
"We expand this expression into four terms
E  PM m=1 tmVm (xxH Kx) 2
F
= E  PM m=1 tmVm 2
F
(19)
",B. Proof of Theorem 2,[0],[0]
+,B. Proof of Theorem 2,[0],[0]
E h,B. Proof of Theorem 2,[0],[0]
xx,B. Proof of Theorem 2,[0],[0]
"H K x 2 F i
E h tr ⇣ (xx H K x )",B. Proof of Theorem 2,[0],[0]
"H ⇣PM
m=1 tmVm
⌘⌘i (20)
E  tr ✓⇣PM m=1 tmVm ⌘",B. Proof of Theorem 2,[0],[0]
H,B. Proof of Theorem 2,[0],[0]
(,B. Proof of Theorem 2,[0],[0]
"xx H K x ) ◆ (21)
and simplify each expression individually.",B. Proof of Theorem 2,[0],[0]
"We start with (19) and use the fact that
PM m=1 tmVm = ((T (y) T (y))TT 1 ⌦ IN⇥N )V
and rewrite the quantity within expectation as follows:
V H (T 1 (T (y) T (y))⌦ IN⇥N )
⇥",B. Proof of Theorem 2,[0],[0]
"((T (y) T (y))TT 1 ⌦ IN⇥N )V = V H ((T 1 (T (y) T (y))
⇥",B. Proof of Theorem 2,[0],[0]
(T (y) T (y))TT 1)⌦ IN⇥N ),B. Proof of Theorem 2,[0],[0]
"V. We now evaluate the expectation which leads to
E  PM m=1 tmVm 2
F
= tr ⇣ V H (T 1 ⌦ IN⇥N )V ⌘
or, equivalently, to E  PM m=1tmVm 2
F
=
MX
m=1
MX
m0=1
[T 1 ]m,m0 tr V H mVm0 .
",B. Proof of Theorem 2,[0],[0]
We next will simplify (20).,B. Proof of Theorem 2,[0],[0]
"Recall that
tm = PM m0=1[T 1
]m,m0(T (ym0) T (ym0)), which enables us to write (20) as
E h tr ⇣ (xx H K x )",B. Proof of Theorem 2,[0],[0]
"H ⇣PM
m=1 tmVm
⌘⌘i
= PM m=1 PM m0=1[T 1 ]m,m0
⇥ tr E⇥(xxH K x ) H (T (ym0) T (ym0))",B. Proof of Theorem 2,[0],[0]
"⇤ Vm
= PM m=1 PM m0=1[T 1 ]m,m0 tr V H m0Vm .",B. Proof of Theorem 2,[0],[0]
"(22)
Seeing as (21) is the Hermitian conjugate of (20), we have
E  tr ✓⇣PM m=1 tmVm ⌘",B. Proof of Theorem 2,[0],[0]
"H (xx H K x ) ◆
= PM m=1 PM m0=1[T 1 ]",B. Proof of Theorem 2,[0],[0]
"⇤ m,m0 tr V H mVm0 .",B. Proof of Theorem 2,[0],[0]
"(23)
Combining all these terms yield the spectral MSE
S-MSE = E  PM m=1 tmVm (xxH Kx) 2
F
= C
xx
H tr ⇣ V H (T 1 ⌦ IN⇥N )V ⌘ .
with C xx
H = E",B. Proof of Theorem 2,[0],[0]
h xx H K x 2 F i .,B. Proof of Theorem 2,[0],[0]
We bound the estimation error with the spectral MSE of the LSPE as follows.,C. Proof of Corollary 1,[0],[0]
"For a given instance, we have
kˆxˆxH xxHk2F",C. Proof of Corollary 1,[0],[0]
= kˆxˆxH,C. Proof of Corollary 1,[0],[0]
Dy,C. Proof of Corollary 1,[0],[0]
"+Dy xxHk2F (a) 2kˆxˆxH D
y k2F +",C. Proof of Corollary 1,[0],[0]
2kDy xxHk2F,C. Proof of Corollary 1,[0],[0]
(,C. Proof of Corollary 1,[0],[0]
"b) 4kD
y xxHk2F , where (a) follows from the squared triangle inequality and (b) because ˆxˆxH is the best rank-1 approximation of D
y .",C. Proof of Corollary 1,[0],[0]
"Averaging over all instances finally yields
E ⇥kˆxˆxH xxHk2F",C. Proof of Corollary 1,[0],[0]
⇤  4 S-MSELSPE.,C. Proof of Corollary 1,[0],[0]
Phase retrieval refers to the problem of recovering realor complex-valued vectors from magnitude measurements.,abstractText,[0],[0]
The best-known algorithms for this problem are iterative in nature and rely on so-called spectral initializers that provide accurate initialization vectors.,abstractText,[0],[0]
"We propose a novel class of estimators suitable for general nonlinear measurement systems, called linear spectral estimators (LSPEs), which can be used to compute accurate initialization vectors for phase retrieval problems.",abstractText,[0],[0]
"The proposed LSPEs not only provide accurate initialization vectors for noisy phase retrieval systems with structured or random measurement matrices, but also enable the derivation of sharp and nonasymptotic mean-squared error bounds.",abstractText,[0],[0]
"We demonstrate the efficacy of LSPEs on synthetic and real-world phase retrieval problems, and show that our estimators significantly outperform existing methods for structured measurement systems that arise in practice.",abstractText,[0],[0]
Linear Spectral Estimators and an Application to Phase Retrieval,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 477–483 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
477",text,[0],[0]
"Span-based neural constituency parsing (Cross and Huang, 2016; Stern et al., 2017a) has attracted attention due to its high accuracy and extreme simplicity.",1 Introduction,[0],[0]
"Compared with other recent neural constituency parsers (Dyer et al., 2016; Liu and Zhang, 2016; Durrett and Klein, 2015) which use neural networks to model tree structures, the spanbased framework is considerably simpler, only using bidirectional RNNs to model the input sequence and not the output tree.",1 Introduction,[0],[0]
"Because of this factorization, the output space is decomposable
which enables efficient dynamic programming algorithm such as CKY.",1 Introduction,[0],[0]
"But existing span-based parsers suffer from a crucial limitation in terms of search: on the one hand, a greedy span parser (Cross and Huang, 2016) is fast (linear-time) but only explores one single path in the exponentially large search space, and on the other hand, a chartbased span parser (Stern et al., 2017a) performs exact search and achieves state-of-the-art accuracy, but in cubic time, which is too slow for longer sentences and for applications that go beyond sentence boundaries such as end-to-end discourse parsing (Hernault et al., 2010; Zhao and Huang, 2017) and integrated sentence boundary detection and parsing (Björkelund et al., 2016).
",1 Introduction,[0],[0]
We propose to combine the merits of both greedy and chart-based approaches and design a linear-time span-based neural parser that searches over exponentially large space.,1 Introduction,[0],[0]
"Following Huang and Sagae (2010), we perform left-to-right dynamic programming in an action-synchronous style, with (2n − 1) actions (i.e., steps) for a sentence of nwords.",1 Introduction,[0],[0]
"While previous non-neural work in this area requires sophisticated features (Huang and Sagae, 2010; Mi and Huang, 2015) and thus high time complexity such as O(n11), our states are as simple as ` : (i, j) where ` is the step index and (i, j) is the span, modeled using bidirectional RNNs without any syntactic features.",1 Introduction,[0],[0]
"This gives a running time ofO(n4), with the extraO(n) for step index.",1 Introduction,[0],[0]
We further employ beam search to have a practical runtime of O(nb2) at the cost of exact search where b is the beam size.,1 Introduction,[0],[0]
"However, on the Penn Treebank, most sentences are less than 40 words (n < 40), and even with a small beam size of b = 10, the observed complexity of an O(nb2) parser is not exactly linear in n (see Experiments).",1 Introduction,[0],[0]
"To solve this problem, we apply cube pruning (Chiang, 2007; Huang and Chiang, 2007) to improve the runtime toO(nb log b) which
renders an observed complexity that is linear in n (with minor extra inexactness).
",1 Introduction,[0],[0]
"We make the following contributions:
• We design the first neural parser that is both linear time and capable of searching over exponentially large space.1
•",1 Introduction,[0],[0]
"We are the first to apply cube pruning to incremental parsing, and achieves, for the first time, the complexity of O(nb log b), i.e., linear in sentence length and (almost) linear in beam size.",1 Introduction,[0],[0]
"This leads to an observed complexity strictly linear in sentence length n.
•",1 Introduction,[0],[0]
"We devise a novel loss function which penalizes wrong spans that cross gold-tree spans, and employ max-violation update (Huang et al., 2012) to train this parser with structured SVM and beam search.
",1 Introduction,[0],[0]
•,1 Introduction,[0],[0]
"Compared with chart parsing baselines, our parser is substantially faster for long sentences on the Penn Treebank, and orders of magnitude faster for end-to-end discourse parsing.",1 Introduction,[0],[0]
"It also achieves the highest F1 score on the Penn Treebank among single model end-to-end systems.
",1 Introduction,[0],[0]
"• We devise a new formulation of graphstructured stack (Tomita, 1991) which requires no extra bookkeeping, proving a new theorem that gives deep insight into GSS.",1 Introduction,[0],[0]
"A span-based shift-reduce constituency parser (Cross and Huang, 2016) maintains a stack of spans (i, j), and progressively adds a new span each time it takes a shift or reduce action.",2.1 Span-Based Shift-Reduce Parsing,[0],[0]
"With (i, j) on top of the stack, the parser can either shift to push the next singleton span (j, j + 1) on the stack, or it can reduce to combine the top two spans, (k, i) and (i, j), forming the larger span (k, j).",2.1 Span-Based Shift-Reduce Parsing,[0],[0]
"After each shift/reduce action, the top-most span is labeled as either a constituent or with a null label ∅, which means that the subsequence is not a subtree in the final decoded parse.",2.1 Span-Based Shift-Reduce Parsing,[0],[0]
"Parsing initializes with an empty stack and continues until (0, n) is formed, representing the entire sentence.
",2.1 Span-Based Shift-Reduce Parsing,[0],[0]
1 https://github.com/junekihong/beam-span-parser,2.1 Span-Based Shift-Reduce Parsing,[0],[0]
"To get the feature representation of a span (i, j), we use the output sequence of a bi-directional LSTM (Cross and Huang, 2016; Stern et al., 2017a).",2.2 Bi-LSTM features,[0],[0]
"The LSTM produces f0, ..., fn forwards and bn, ...,b0 backwards outputs, which we concatenate the differences of (fj−fi) and (bi−bj) as the representation for span (i, j).",2.2 Bi-LSTM features,[0],[0]
"This eliminates the need for complex feature engineering, and can be stored for efficient querying during decoding.",2.2 Bi-LSTM features,[0],[0]
"Like Stern et al. (2017a), we also decompose the score of a tree t to be the sum of the span scores:
s(t) = ∑
(i,j,X)∈t
s(i, j,X) (1)
= ∑
(i,j)∈t
max X
s((fj − fi;bi − bj), X) (2)
Note that X is a nonterminal label, a unary chain (e.g., S-VP), or null label ∅.2 In a shift-reduce setting, there are 2n − 1 steps (n shifts and n − 1 reduces) and after each step we take the best label for the resulting span; therefore there are exactly
2The actual code base of Stern et al. (2017b) forces s(i, j,∅) to be 0, which simplifies their CKY parser and slightly improves their parsing accuracy.",3.1 Score Decomposition,[0],[0]
"However, in our incremental parser, this change favors shift over reduce and degrades accuracy, so our parser keeps a learned score for ∅.
2n−1 such (labeled) spans (i, j,X) in tree t. Also note that the choice of the label for any span (i, j) is only dependent on (i, j) itself (and not depending on any subtree information), thus the max over label X is independent of other spans, which is a nice property of span-based parsing (Cross and Huang, 2016; Stern et al., 2017a).",3.1 Score Decomposition,[0],[0]
We now reformulate this DP parser in the above section as a shift-reduce parser.,3.2 Graph-Struct. Stack w/o Bookkeeping,[0],[0]
We maintain a step index ` in order to perform action-synchronous beam search (see below).,3.2 Graph-Struct. Stack w/o Bookkeeping,[0],[0]
"Figure 1 shows how to represent a parsing stack using only the top span (i, j).",3.2 Graph-Struct. Stack w/o Bookkeeping,[0],[0]
"If the top span (i, j) shifts, it produces (j, j + 1), but if it reduces, it needs to know the second last span on the stack, (k, i), which is not represented in the current state.",3.2 Graph-Struct. Stack w/o Bookkeeping,[0],[0]
"This problem can be solved by graph-structure stack (Tomita, 1991; Huang and Sagae, 2010), which maintains, for each state p, a set of predecessor states π(p) that p can combine with on the left.
",3.2 Graph-Struct. Stack w/o Bookkeeping,[0],[0]
"This is the way our actual code works (π(p) is implemented as a list of pointers, or “left pointers”), but here for simplicity of presentation we devise a novel but easier-to-understand formulation in Fig. 1, where we explicitly represent the set of predecessor states that state ` : (i, j) can combine with as `′ : (k, i) where `′ =",3.2 Graph-Struct. Stack w/o Bookkeeping,[0],[0]
"`−2(j− i) + 1, i.e., (i, j) at step ` can combine with any (k, i) for any k at step `′. The rationale behind this new formulation is the following theorem:
Theorem 1",3.2 Graph-Struct. Stack w/o Bookkeeping,[0],[0]
"The predecessor states π(` : (i, j)) are all in the same step `′ =",3.2 Graph-Struct. Stack w/o Bookkeeping,[0],[0]
`− 2(j − i) + 1.,3.2 Graph-Struct. Stack w/o Bookkeeping,[0],[0]
Proof.,3.2 Graph-Struct. Stack w/o Bookkeeping,[0],[0]
"By induction.
",3.2 Graph-Struct. Stack w/o Bookkeeping,[0],[0]
This Theorem bring new and deep insights and suggests an alternative implementation that does not require any extra bookkeeping.,3.2 Graph-Struct. Stack w/o Bookkeeping,[0],[0]
The time complexity of this algorithm is O(n4) with the extra O(n) due to step index.3,3.2 Graph-Struct. Stack w/o Bookkeeping,[0],[0]
The incremental nature of our parser allows us to further lower the runtime complexity at the cost of inexact search.,3.3 Action-Synchronous Beam Search,[0],[0]
"At each time step, we maintain the top b parsing states, pruning off the rest.",3.3 Action-Synchronous Beam Search,[0],[0]
"Thus, a candidate parse that made it to the end of decoding had to survive within the top b at every step.
",3.3 Action-Synchronous Beam Search,[0],[0]
"3The word-synchronous alternative does not need the step index ` and enjoys a cubic time complexity, being almost identical to CKY.",3.3 Action-Synchronous Beam Search,[0],[0]
"However, beam search becomes very tricky.
",3.3 Action-Synchronous Beam Search,[0],[0]
With O(n) parsing actions our time complexity becomes linear in the length of the sentence.,3.3 Action-Synchronous Beam Search,[0],[0]
"However, Theorem 1 suggests that a parsing state p can have up to b predecessor states (“left pointers”), i.e., |π(p)| ≤ b because π(p) are all in the same step, a reduce action can produce up to b subsequent new reduced states.",3.4 Cube Pruning,[0],[0]
"With b items on a beam and O(n) actions to take, this gives us an overall complexity of O(nb2).",3.4 Cube Pruning,[0],[0]
"Even though b2 is a constant, even modest values of b can make b2 dominate the length of the sentence.",3.4 Cube Pruning,[0],[0]
"4
To improve this at the cost of additional inexactness, we introduce cube pruning to our beam search, where we put candidate actions into a heap and retrieve the top b states to be considered in the next time-step.",3.4 Cube Pruning,[0],[0]
We heapify the top b shiftmerged states and the top b reduced states.,3.4 Cube Pruning,[0],[0]
"To avoid inserting all b2 reduced states from the previous beam, we only consider each state’s highest scoring left pointer,5 and whenever we pop a reduced state from the heap, we iterate down its left pointers to insert the next non-duplicate reduced state back into the heap.",3.4 Cube Pruning,[0],[0]
This process finishes when we pop b items from the heap.,3.4 Cube Pruning,[0],[0]
"The initialization of the heap takes O(b) and popping b items takes O(b log b), giving us an overall improved runtime of O(nb log b).",3.4 Cube Pruning,[0],[0]
"We use a Structured SVM approach for training (Stern et al., 2017a; Shi et al., 2017).",4 Training,[0],[0]
"We want the model to score the gold tree t∗ higher than any other tree t by at least a margin ∆(t, t∗):
∀t, s(t∗)− s(t) ≥ ∆(t, t∗).
",4 Training,[0],[0]
"Note that ∆(t, t) = 0 for any t and ∆(t, t∗)",4 Training,[0],[0]
> 0,4 Training,[0],[0]
for any t 6= t∗.,4 Training,[0],[0]
"At training time we perform lossaugmented decoding:
t̂ = arg max t s∆(t)",4 Training,[0],[0]
"= arg max t s(t) + ∆(t, t∗).
",4 Training,[0],[0]
4The average length of a sentence in the Penn Treebank training set is about 24.,4 Training,[0],[0]
"Even with a beam size of 10, we already have b2 = 100, which would be a significant factor in our runtime.",4 Training,[0],[0]
"In practice, each parsing state will rarely have the maximum b left pointers so this ends up being a loose upper-bound.",4 Training,[0],[0]
"Nevertheless, the beam search should be performed with the input length in mind, or else as b increases we risk losing a linear runtime.
",4 Training,[0],[0]
"5If each previous beam is sorted, and if the beam search is conducted by going top-to-bottom, then each state’s left pointers will implicitly be kept in sorted order.
",4 Training,[0],[0]
where s∆(·) is the loss-augmented score.,4 Training,[0],[0]
"If t̂ = t∗, then all constraints are satisfied (which implies arg maxt s(t) = t
∗), otherwise we perform an update by backpropagating from s∆(t̂)− s(t∗).",4 Training,[0],[0]
"The baseline loss function from Stern et al. (2017a) counts the incorrect labels (i, j,X) in the predicted tree:
∆base(t, t ∗)",4.1 Cross-Span Loss,[0],[0]
"= ∑ (i,j,X)∈t 1 ( X 6= t∗(i,j) ) .
",4.1 Cross-Span Loss,[0],[0]
"Note that X can be null ∅, and t∗(i,j) denotes the gold label for span (i, j), which could also be ∅.6 However, there are two cases where t∗(i,j) = ∅: a subspan (i, j) due to binarization (e.g., a span combining the first two subtrees in a ternary branching node), or an invalid span in t that crosses a gold span in t∗.",4.1 Cross-Span Loss,[0],[0]
"In the baseline function above, these two cases are treated equivalently; for example, a span (3, 5,∅",4.1 Cross-Span Loss,[0],[0]
") ∈ t is not penalized even if there is a gold span (4, 6,VP)",4.1 Cross-Span Loss,[0],[0]
∈ t∗.,4.1 Cross-Span Loss,[0],[0]
"So we revise our loss function as:
∆new(t, t ∗) =",4.1 Cross-Span Loss,[0],[0]
"∑ (i,j,X)∈t 1 ( X 6= t∗(i,j)
∨ cross(i, j, t∗) )
6Note that the predicted tree t has exactly 2n − 1 spans but t∗ has much fewer spans (only labeled spans without ∅).
",4.1 Cross-Span Loss,[0],[0]
"where cross(i, j, t∗) = ∃ (k, l) ∈ t∗, and i <",4.1 Cross-Span Loss,[0],[0]
k,4.1 Cross-Span Loss,[0],[0]
< j,4.1 Cross-Span Loss,[0],[0]
< l or k,4.1 Cross-Span Loss,[0],[0]
< i,4.1 Cross-Span Loss,[0],[0]
< l < j.,4.1 Cross-Span Loss,[0],[0]
"Given that we maintain loss-augmented scores even for partial trees, we can perform a training update on a given example sentence by choosing to take the loss where it is the greatest along the parse trajectory.",4.2 Max Violation Updates,[0],[0]
"At each parsing time-step `, the violation is the difference between the highest augmented-scoring parse trajectory up to that point and the gold trajectory (Huang et al., 2012; Yu et al., 2013).",4.2 Max Violation Updates,[0],[0]
Note that computing the violation gives us the max-margin loss described above.,4.2 Max Violation Updates,[0],[0]
Taking the largest violation from all time-steps gives us the max-violation loss.,4.2 Max Violation Updates,[0],[0]
"We present experiments on the Penn Treebank (Marcus et al., 1993) and the PTB-RST discourse treebank (Zhao and Huang, 2017).",5 Experiments,[0],[0]
"In both cases, the training set is shuffled before each epoch, and dropout (Hinton et al., 2012) is employed with probability 0.4 to the recurrent outputs for regularization.",5 Experiments,[0],[0]
Updates with minibatches of size 10 and 1 are used for PTB and the PTB-RST respectively.,5 Experiments,[0],[0]
"We use Adam (Kingma and Ba, 2014) with default settings to schedule learning rates for all the weights.",5 Experiments,[0],[0]
"To address unknown words during training, we adopt the strategy described by Kiperwasser and Goldberg (Kiperwasser and Goldberg, 2016); words in the training set are replaced with the unknown word symbol UNK with probability punk = 1 1+f(w) , with f(w) being the number of
occurrences of word w in the training corpus.",5 Experiments,[0],[0]
"Our system is implemented in Python using the DyNet neural network library (Neubig et al., 2017).",5 Experiments,[0],[0]
"We use the Wall Street Journal portion of the Penn Treebank, with the standard split of sections 2-21 for training, 22 for development, and 23 for testing.",5.1 Penn Treebank,[0],[0]
"Tags are provided using the Stanford tagger with 10-way jackknifing.
",5.1 Penn Treebank,[0],[0]
"Table 1 shows our development results and overall speeds, while Table 2 compares our test results.",5.1 Penn Treebank,[0],[0]
We show that a beam size of 20 can be fast while still achieving state-of-the-art performances.,5.1 Penn Treebank,[0],[0]
"To measure the tractability of parsing on longer sequences, we also consider experiments on the
PTB-RST discourse Treebank, a joint discourse and constituency dataset with a combined representation, allowing for parsing at either level (Zhao and Huang, 2017).",5.2 Discourse Parsing,[0],[0]
We compare our runtimes out-of-the-box in Figure 3.,5.2 Discourse Parsing,[0],[0]
"Without any pre-processing, and by treating discourse examples as constituency trees with thousands of words, our trained models represent end-to-end discourse parsing systems.
",5.2 Discourse Parsing,[0],[0]
"For our overall constituency results in Table 3, and for discourse results in Table 4, we adapt the split-point feature described in (Zhao and Huang, 2017) in addition to the base parser.",5.2 Discourse Parsing,[0],[0]
We find that larger beamsizes are required to achieve good discourse scores.,5.2 Discourse Parsing,[0],[0]
"We have developed a new neural parser that maintains linear time, while still searching over an exponentially large space.",6 Conclusions,[0],[0]
We also use cube pruning to further improve the runtime to O(nb log b).,6 Conclusions,[0],[0]
"For training, we introduce a new loss function, and achieve state-of-the-art results among singlemodel end-to-end systems.",6 Conclusions,[0],[0]
We thank Dezhong Deng who contributed greatly to Secs.,Acknowledgments,[0],[0]
"3.2 and 4 (he deserves co-authorship), and Mitchell Stern for releasing his code and and suggestions.",Acknowledgments,[0],[0]
This work was supported in part by NSF IIS-1656051 and DARPA N66001-17-2-4030.,Acknowledgments,[0],[0]
"Recently, span-based constituency parsing has achieved competitive accuracies with extremely simple models by using bidirectional RNNs to model “spans”.",abstractText,[0],[0]
"However, the minimal span parser of Stern et al. (2017a) which holds the current state of the art accuracy is a chart parser running in cubic time, O(n3), which is too slow for longer sentences and for applications beyond sentence boundaries such as end-toend discourse parsing and joint sentence boundary detection and parsing.",abstractText,[0],[0]
"We propose a linear-time constituency parser with RNNs and dynamic programming using graph-structured stack and beam search, which runs in time O(nb2) where b is the beam size.",abstractText,[0],[0]
We further speed this up to O(nb log b) by integrating cube pruning.,abstractText,[0],[0]
"Compared with chart parsing baselines, this linear-time parser is substantially faster for long sentences on the Penn Treebank and orders of magnitude faster for discourse parsing, and achieves the highest F1 accuracy on the Penn Treebank among single model end-to-end systems.",abstractText,[0],[0]
Linear-Time Constituency Parsing with RNNs and Dynamic Programming,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 1941–1950 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics",text,[0],[0]
"Deception detection is a critical problem studied by psychologists, criminologists, and computer scientists.",1 Introduction,[0],[0]
In recent years the NLP and speech communities have increased their interest in deception detection.,1 Introduction,[0],[0]
"Language cues are inexpensive and easy to collect, and research examining text-based and speech-based cues to deception has been quite promising.",1 Introduction,[0],[0]
"Prior work has examined deceptive language in several domains, including fake reviews, mock crime scenes, and opinions about topics such as abortion or the death penalty.",1 Introduction,[0],[0]
"In this work we explore the domain of interview dialogues, which are similar to many real-world deception conditions.
",1 Introduction,[0],[0]
"Previous work has presented the results of classification experiments using linguistic features, attempting to identify which features contribute most to classification accuracy.",1 Introduction,[0],[0]
"However, studies often do not include an empirical analysis of features.",1 Introduction,[0],[0]
"We might know that a particular feature
set (e.g. LIWC categories) is useful for deception classification, but we lack insight about the nature of the deceptive and truthful language that makes the feature set useful, and whether the differences in language use are statistically significant.",1 Introduction,[0],[0]
In this work we conduct an empirical analysis of feature sets and report on the different characteristics of truthful and deceptive language.,1 Introduction,[0],[0]
"In addition, previous work has focused on the characteristics of deceptive language, and not on the characteristics of perceived deceptive language.",1 Introduction,[0],[0]
"We are also interested in human perception of deception; that is, what are the characteristics of language that listeners perceive as truthful or deceptive?",1 Introduction,[0],[0]
"We examine a unique dataset that includes information about both the deceiver and the interviewer, along with interviewer judgments of deception.",1 Introduction,[0],[0]
"Along with an analysis of deceptive and truthful speech, we analyze the believed and disbelieved speech, according to reported interviewer judgments.",1 Introduction,[0],[0]
"Finally, previous work has focused on general inferences about deception; here we include analysis of gender and native language, to study their effect on deceptive behavior, and also their effect on perception of deception.",1 Introduction,[0],[0]
"This work contributes to the critical problem of automatic deception detection, and increases our scientific understanding of deception, deception perception, and speaker differences in deceptive behavior.
",1 Introduction,[0],[0]
The paper is organized as follows:,1 Introduction,[0],[0]
In Section 2 we review related work in language-based cues to deception.,1 Introduction,[0],[0]
"Section 3 describes the dataset used for this work, and Section 4 details the different feature sets we employ.",1 Introduction,[0],[0]
"In Section 5, we report on the results of our empirical study of indicators of deception and perceived deception, as well as gender and native language differences.",1 Introduction,[0],[0]
Section 6 presents our machine learning classification results using the deception indicator feature sets.,1 Introduction,[0],[0]
"We conclude in Section 7 with a discussion and ideas
1941
for future work.",1 Introduction,[0],[0]
Language-based cues to deception have been analyzed in many genres.,2 Related Work,[0],[0]
"Ott et al. (2011) compared approaches to automatically detecting deceptive opinion spam, using a crowdsourced dataset of fake hotel reviews.",2 Related Work,[0],[0]
"Several studies use a fake opinion paradigm for collecting data, instructing subjects to write or record deceptive and truthful opinions about controversial topics such as the death penalty or abortion, or about a person that they like/dislike (Newman et al., 2003; Mihalcea and Strapparava, 2009).",2 Related Work,[0],[0]
"Other research has focused on real-world data obtained from court testimonies and depositions (Fornaciari and Poesio, 2013; Bachenko et al., 2008; Pérez-Rosas et al., 2015).",2 Related Work,[0],[0]
"Real-world deceptive situations are highstakes, where there is much to be gained or lost if deception succeeds or fails; it is hypothesized that these conditions are more likely to elicit strong cues to deception.",2 Related Work,[0],[0]
"However, working with such data requires extensive research to annotate each utterance for veracity, so such datasets are often quite small and not always reliable.
",2 Related Work,[0],[0]
"Linguistic features such as n-grams and language complexity have been analyzed as cues to deception (Pérez-Rosas and Mihalcea, 2015; Yancheva and Rudzicz, 2013).",2 Related Work,[0],[0]
"Syntactic features such as part of speech tags have also been found to be useful for structured data (Ott et al., 2011; Feng et al., 2012).",2 Related Work,[0],[0]
"Statement Analysis (Adams, 1996) is a text-based deception detection approach that combines lexical and syntactic features.",2 Related Work,[0],[0]
"An especially useful resource for text-based deception detection is the Linguistic Inquiry and Word Count (LIWC) (Pennebaker and King, 1999), which groups words into psychologically motivated categories.",2 Related Work,[0],[0]
"In addition to lexical features, some studies have examined acousticprosodic cues to deception (Rockwell et al., 1997; Enos, 2009; Mendels et al., 2017).",2 Related Work,[0],[0]
"(Benus et al., 2006) studied pause behavior in deceptive speech.",2 Related Work,[0],[0]
"This work is very promising, but it is more difficult to obtain large, cleanly recorded speech corpora with deception annotations than to obtain text corpora.",2 Related Work,[0],[0]
"An excellent meta-study of verbal cues to deception can be found in (DePaulo et al., 2003).",2 Related Work,[0],[0]
"For this work, we examined the Columbia XCultural Deception (CXD) Corpus (Levitan et al., 2015a) a collection of within-subject deceptive and non-deceptive speech from native speakers of Standard American English (SAE) and Mandarin Chinese (MC), all speaking in English.",3.1 Corpus,[0],[0]
The corpus contains dialogues between 340 subjects.,3.1 Corpus,[0],[0]
A variation of a fake resume paradigm was used to collect the data.,3.1 Corpus,[0],[0]
Previously unacquainted pairs of subjects played a ”lying game” with each other.,3.1 Corpus,[0],[0]
Each subject filled out a 24-item biographical questionnaire and were instructed to create false answers for a random half of the questions.,3.1 Corpus,[0],[0]
"They also reported demographic information including gender and native language, and completed the NEO-FFI personality inventory (Costa and McCrae, 1989).
",3.1 Corpus,[0],[0]
The lying game was recorded in a sound booth.,3.1 Corpus,[0],[0]
"For the first half of the game, one subject assumed the role of the interviewer, while the other answered the biographical questions, lying for half and telling the truth for the other; questions chosen in each category were balanced across the corpus.",3.1 Corpus,[0],[0]
"For the second half of the game, the subjects roles were reversed, and the interviewer became the interviewee.",3.1 Corpus,[0],[0]
"During the game, the interviewer was allowed to ask the 24 questions in any order s/he chose; the interviewer was also encouraged to ask follow-up questions to aid them in determining the truth of the interviewees answers.",3.1 Corpus,[0],[0]
"Interviewers recorded their judgments for each of the 24 questions, providing information about human perception of deception.",3.1 Corpus,[0],[0]
"The entire corpus was orthographically transcribed using the Amazon Mechanical Turk (AMT)1 crowd-sourcing platform, and the speech was segmented into inter-pausal units (IPUs), defined as pause-free segments of speech separated by a minimum pause length of 50 ms.",3.1 Corpus,[0],[0]
"The speech was also segmented into turn units, where a turn is defined as a maximal sequence of IPUs from a single speaker without any interlocutor speech that is not a backchannel.",3.1 Corpus,[0],[0]
There are two forms of deception annotations in the corpus: local and global.,3.1 Corpus,[0],[0]
Interviewees labeled their responses with local annotations by pressing a ”T” or ”F” key for each utterance as they spoke.,3.1 Corpus,[0],[0]
These keypresses were automatically aligned with speaker IPUs and turns.,3.1 Corpus,[0],[0]
"Global la-
1https://www.mturk.com/mturk/
bels were provided by the biographical questionnaire, where each of the 24 questions was labeled as truthful or deceptive.
",3.1 Corpus,[0],[0]
Consider the following dialogue:,3.1 Corpus,[0],[0]
Interviewer: What is your mother’s job?,3.1 Corpus,[0],[0]
Interviewee:,3.1 Corpus,[0],[0]
My mother is a doctor (F).,3.1 Corpus,[0],[0]
"She has always worked very late hours and I felt neglected as a child (T).
",3.1 Corpus,[0],[0]
Is the interviewee response true or false?,3.1 Corpus,[0],[0]
We differentiate between global and local deception.,3.1 Corpus,[0],[0]
"Globally, the response to the question is deceptive.",3.1 Corpus,[0],[0]
"However, it contains local instances of both truth and deception.",3.1 Corpus,[0],[0]
"In this work we focus on dialoguebased deception, using global deception labels.",3.1 Corpus,[0],[0]
"Previous work with the CXD corpus has focused on IPU-level and turn-level analysis and classification of local deception, mostly with acousticprosodic features (Levitan et al., 2015b; Mendels et al., 2017).",3.2 Global Segmentation,[0],[0]
Here we are interested in exploring global deception at the dialogue-level for the first time in this corpus.,3.2 Global Segmentation,[0],[0]
We define response-segments as sets of turns that are related to a single question (of the 24 interview questions).,3.2 Global Segmentation,[0],[0]
"In order to annotate these segments, we first used a question detection and identification system (Maredia et al., 2017) that uses word embeddings to match semantically similar variations of questions to a target question list.",3.2 Global Segmentation,[0],[0]
This was necessary because interviewers asked the 24 questions using different wording from the original list of questions.,3.2 Global Segmentation,[0],[0]
"On this corpus, (Maredia et al., 2017) obtained an F1score of .95%.
",3.2 Global Segmentation,[0],[0]
"After tagging interviewer turns with this system, we labeled the set of interviewee turns between two interviewer questions q1 and q2 as corresponding to question q1.",3.2 Global Segmentation,[0],[0]
"The intuition behind this was that those turns were responses to follow up questions related to q1, and while the question detection and identification system discussed above did not identify follow up questions, we found that most of the follow up questions after an interviewer question q1 would be related to q1 in our hand annotation.",3.2 Global Segmentation,[0],[0]
"We evaluated this global segmentation on a hand-annotated test set of 17 interviews (about 10% of the corpus) consisting of 2,671 interviewee turns, 408 interviewer questions, and 977 follow up questions.",3.2 Global Segmentation,[0],[0]
"Our global segmentation approach resulted in 77.8% accuracy on our hand-labeled test set (errors were mostly
due to turns that were unrelated to any question).",3.2 Global Segmentation,[0],[0]
"We performed our analysis and classification on two segmentations of the data using this tagging method: (1) first turn: we analyzed only the single interviewee turn directly following the original question, and (2) multiple turns we analyzed the entire segment of interviewee turns that were responding to the original interviewer question and subsequent follow-up questions.",3.2 Global Segmentation,[0],[0]
"In our classification experiments, we explore whether a deceptive answer is be better classified by the interviewee’s initial response or by all of the follow-up conversation between interviewer and interviewee.",3.2 Global Segmentation,[0],[0]
"LIWC Previous work has found that deceivers tend to use different word usage patterns when they are lying (Newman et al., 2003).",4 Features,[0],[0]
"We used LIWC (Pennebaker et al., 2001) to extract semantic features from each utterance.",4 Features,[0],[0]
LIWC is a text analysis program that computes features consisting of normalized word counts for 93 semantic classes.,4 Features,[0],[0]
"LIWC dimensions have been used in many studies to predict outcomes including personality (Pennebaker and King, 1999), deception (Newman et al., 2003), and health (Pennebaker et al., 1997).",4 Features,[0],[0]
"We extracted a total of 93 features using LIWC 2015 2, including standard linguistic dimensions (e.g. percentage of words that are pronouns, articles), markers of psychological processes (e.g. affect, social, cognitive), punctuation categories (e.g periods, commas), and formality measures (e.g. fillers, swear words).",4 Features,[0],[0]
"Linguistic We extracted 23 linguistic features 3 which we adopted from previous deception studies such as (Enos, 2009; Bachenko et al., 2008).",4 Features,[0],[0]
"Included in this list are binary and numeric features capturing hedge words, filled pauses, laughter, complexity, contractions, and denials.",4 Features,[0],[0]
"We include Dictionary of Affect Language (DAL) (Whissell et al., 1986) scores that measure the emotional meaning of texts, and a specificity score which measures level of detail (Li and Nenkova, 2015).",4 Features,[0],[0]
"The full list of features is: ’hasAbsolutelyReally’, ’hasContraction’, ’hasI’, ’hasWe’, ’hasYes’, ’hasNAposT’ (turns
2A full description of the features is found here: https: //s3-us-west-2.amazonaws.com/downloads.",4 Features,[0],[0]
"liwc.net/LIWC2015_OperatorManual.pdf
3A detailed explanation of these linguistic features and how they were computed is found here: http://www.cs.",4 Features,[0],[0]
"columbia.edu/speech/cxd/features.html
that contain words with the contraction ”n’t”), ’hasNo’, ’hasNot’, ’isJustYes’, ’isJustNo’, ’noYesOrNo’, ’specificDenial’, ’thirdPersonPronouns’, ’hasFalseStart’, ’hasFilledPause’, ’numFilledPauses’, ’hasCuePhrase’, ’numCuePhrases’, ’hasHedgePhrase’, ’numHedgePhrases’, ’hasLaugh’, ’complexity’, ’numLaugh’, ’DALwc’, ’DAL-pleasant’, ’DAL-activate’, ’DALimagery’, ’specScores’ (specificity score).",4 Features,[0],[0]
"Response Length Previous work has found that response length, in seconds, is shorter in deceptive speech, and that the difference in number of words in a segment of speech is insignificant between deceptive and truthful speech (DePaulo et al., 2003).",4 Features,[0],[0]
"For our question-level analysis, we used four different measures for response length: the total number of seconds of an interviewee responsesegment, the total number of words in an interviewee response-segment, the average response time of a turn in an interviewee response-segment, and the average number of words per turn in an interviewee response-segment.",4 Features,[0],[0]
Individual Traits,4 Features,[0],[0]
We analyzed gender and native language of the speakers to determine if these traits were related to ability to deceive and to detect deception.,4 Features,[0],[0]
"We also analyzed linguistic cues to deception across gender and native language, and used gender and native language information in our classification experiments.",4 Features,[0],[0]
"All speakers were either male or female, and their native language was either Standard American English or Mandarin Chinese.",4 Features,[0],[0]
"In addition, we used the NEO-FFI (5 factor) personality inventory scores as features in classification experiments, but not for the statistical analysis in this paper.",4 Features,[0],[0]
Follow-up Questions Follow-up questions are questions that an interviewer asks after they ask a question from the original prescribed set of questions.,4 Features,[0],[0]
"We hypothesized that if an interviewer asked more follow-up questions, they were more likely to identify deceptive responses, because asking follow-up questions indicated interviewer doubt of the interviewee’s truthfulness.",4 Features,[0],[0]
"For each interviewee response-segment, we counted the number of follow-up questions interviewees were asked by the interviewer.",4 Features,[0],[0]
"In order to analyze the differences between deceptive and truthful speech, we extracted the above features from each question response-segment,
and calculated a series of paired t-tests between the features of truthful speech and deceptive speech.",5 Analysis,[0],[0]
All tests for significance correct for family-wise Type I error by controlling the false discovery rate (FDR) at α = 0.05.,5 Analysis,[0],[0]
The kth smallest p value is considered significant if it is less than k∗α n .,5 Analysis,[0],[0]
Table 1 shows the features that were statistically significant indicators of truth and deception in interviewee response-segments consisting of multiple turns.,5.1 Interviewee Responses,[0],[0]
"Below, we highlight some interesting findings.
",5.1 Interviewee Responses,[0],[0]
"In contrast to (DePaulo et al., 2003), we found that the total duration of an interviewee responsesegment was longer for deceptive speech than for truthful speech.",5.1 Interviewee Responses,[0],[0]
"Additionally, while (DePaulo et al., 2003) showed that the number of words in a segment of speech was not significantly different between deceptive and truthful speech, we found that deceptive response-segments had more words than truthful response-segments.",5.1 Interviewee Responses,[0],[0]
"Furthermore, we found that longer average response time per turn and more words per sentence were significant indicators of deception.",5.1 Interviewee Responses,[0],[0]
"These results show that when interviewees are trying to deceive, not only is their aggregate response longer in duration and number of words, but their individual responses to each follow-up question are also longer.",5.1 Interviewee Responses,[0],[0]
"Consistent with (DePaulo et al., 2003), we found that more filled pauses in an interviewee responsesegment was a significant indicator of deception.",5.1 Interviewee Responses,[0],[0]
"Deceivers are hypothesized to experience an increase in cognitive load (Vrij et al., 1996), and this can result in difficulties in speech planning, which can be signaled by filled pauses.",5.1 Interviewee Responses,[0],[0]
"Although (Benus et al., 2006) found that, in general, the use of pauses correlates more with truthful than with deceptive speech, we found that filled pauses such as ”um” were correlated with deceptive speech.",5.1 Interviewee Responses,[0],[0]
"The LIWC cogproc (cognitive processes) dimension, which includes words such as ”cause”, ”know”, ”ought” was significantly more frequent in truthful speech, also supporting the theory that cognitive load is increased while practicing deception.
",5.1 Interviewee Responses,[0],[0]
"We found that increased DALimagery scores, which compute words often used in speech to create vivid descriptions, were indicators of deception.",5.1 Interviewee Responses,[0],[0]
"We also found that the LIWC language summary variables of authenticity and adjectives
were indicators of deception: in an effort to sound more truthful and authentic, interviewees may have provided a level of detail that is uncharacteristic of truthful speech.",5.1 Interviewee Responses,[0],[0]
"Similarly, the specificity metric was indicative of deception: deceptive responses contained more detailed language.",5.1 Interviewee Responses,[0],[0]
"Words in the LIWC clout category - a category describing words that indicate power of influence - were more prevalent in deceptive responses, suggesting that subjects sounded more confident while lying.",5.1 Interviewee Responses,[0],[0]
Interrogatives were an indicator of deception.,5.1 Interviewee Responses,[0],[0]
"In the context of the interviewerinterviewee paradigm, these are interviewee questions to the interviewer.",5.1 Interviewee Responses,[0],[0]
"Perhaps this was a technique used to stall so that they had more time to
develop an answer (e.g. ”Can you repeat the question?”), or to deflect the interviewer’s attention from their deception and put the interviewer on the spot.",5.1 Interviewee Responses,[0],[0]
"We observed that hedge words and phrases, which speakers use to distance themselves from a proposition, were more frequent in deceptive speech.",5.1 Interviewee Responses,[0],[0]
"This is consistent with Statement Analysis (Adams, 1996), which posits that hedge words are used in deceptive statements to intentionally create vagueness that obscures facts.",5.1 Interviewee Responses,[0],[0]
"Consistent with this finding, certainty in language (words such as ”always” or ”never”) was a strong indicator of truthfulness.
",5.1 Interviewee Responses,[0],[0]
"It is also interesting to note the features that were not significant indicators of truth or decep-
tion.",5.1 Interviewee Responses,[0],[0]
"For example, there was no significant difference in laughter frequency or apostrophes (used for contractions in this corpus) between truthful and deceptive responses.
",5.1 Interviewee Responses,[0],[0]
"When we compared indicators of truth vs. deception across multiple turns to indicators of truth vs. deception in just the first turns of interviewee response-segments, we found that, generally, indicators in first turns are a subset of indicators across multiple turns.",5.1 Interviewee Responses,[0],[0]
In some cases there were interesting differences.,5.1 Interviewee Responses,[0],[0]
"For example, although tone (emotional tone - higher numbers indicate more positive, and lower indicate negative) was not a significant indicator of deception for the entire interviewee response-segment, negative tone was a moderate indicator of deception in first turns.",5.1 Interviewee Responses,[0],[0]
"This suggests that the tone of interviewees, when they have just started their lie, is different from when they are given the opportunity to expand on that lie.",5.1 Interviewee Responses,[0],[0]
The findings from our analysis of first turns suggest that there might be enough information in the first response alone to distinguish between deceptive and truthful speech; we test this in our classification experiments in Section 6.,5.1 Interviewee Responses,[0],[0]
"In addition to analyzing the linguistic differences between truthful and deceptive speech, we were interested in studying the characteristics of speech that is believed or disbelieved.",5.2 Interviewer Judgments of Deception,[0],[0]
"Since the CXD corpus includes interviewer judgments of deception for each question asked, we have the unique opportunity to study human perception of deception on a large scale.",5.2 Interviewer Judgments of Deception,[0],[0]
Table 2 shows the features that were statistically significant indicators of truth and deception in interviewee responses - consisting of multiple turns - that were perceived as true or false by interviewers.,5.2 Interviewer Judgments of Deception,[0],[0]
Here we highlight some interesting findings.,5.2 Interviewer Judgments of Deception,[0],[0]
"There were many features that were prevalent in speech that interviewers perceived as deceptive, which were in fact cues to deception.",5.2 Interviewer Judgments of Deception,[0],[0]
"For example, speech containing more words in a response-segment and more words per sentence was generally perceived as deceptive by interviewers, and indeed, this perception was correct.",5.2 Interviewer Judgments of Deception,[0],[0]
"Disbelieved answers had a greater frequency of filled pauses and hedge words, and greater specificity, all of which were increased in deceptive speech.
",5.2 Interviewer Judgments of Deception,[0],[0]
"There were also several features that were indicators of deception, but were not found in higher rates in statements that were perceived
as false.",5.2 Interviewer Judgments of Deception,[0],[0]
"For example, the LIWC dimensions clout and certain were not significantly different in believed vs. disbelieved interviewee responses, but clout was increased in deceptive speech and certain language was increased in truthful speech.",5.2 Interviewer Judgments of Deception,[0],[0]
"There were also features that were significantly different between believed and disbelieved statements, but were not indicators of deception.",5.2 Interviewer Judgments of Deception,[0],[0]
"For example, statements that were perceived as false by interviewers had a greater proportion of specificDenials (e.g. ”I did not”) than those that were perceived as true; this was not a valid cue to deception.",5.2 Interviewer Judgments of Deception,[0],[0]
Number of turns was increased in dialogue segments where the interviewer did not ultimately believe the interviewee response.,5.2 Interviewer Judgments of Deception,[0],[0]
"That is, more follow up questions were asked when an interviewer did not believe their interlocutor’s response, which is an intuitive behavior.",5.2 Interviewer Judgments of Deception,[0],[0]
"When we compared indicators of speech that was perceived as deceptive across multiple turns to indicators of speech that was perceived as deceptive in just the first turns, we found that, generally, indicators in first turns are a subset of indicators across multiple turns.
",5.2 Interviewer Judgments of Deception,[0],[0]
"On average, human accuracy at judging truth and deception in the CXD corpus was 56.75%, and accuracy at judging deceptive statements only was 47.93%.",5.2 Interviewer Judgments of Deception,[0],[0]
The average F1-score for humans was 46.,5.2 Interviewer Judgments of Deception,[0],[0]
"Thus, although some cues were correctly perceived by interviewers, humans were generally poor at deception perception.",5.2 Interviewer Judgments of Deception,[0],[0]
"Nonetheless, characterizing the nature of speech that is believed or not believed is useful for applications where we would ultimately like to synthesize speech that is trustworthy.",5.2 Interviewer Judgments of Deception,[0],[0]
"Having discovered many differences between deceptive and truthful language across all speakers, we were interested in analyzing differences in deceptive language across groups of speakers.",5.3 Gender and Native Language Differences in Deception Behavior,[0],[0]
"Using gender and native language (English or Mandarin Chinese) as group traits, we conducted two types of analysis.",5.3 Gender and Native Language Differences in Deception Behavior,[0],[0]
"First, we directly compared deception performance measures (ability to deceive as interviewee, and ability to detect deception as interviewer) between speakers with different traits, to assess the effect of individual characteristics on deception abilities.",5.3 Gender and Native Language Differences in Deception Behavior,[0],[0]
"In addition, we compared the features of deceptive and truthful language in sub-
sets of the corpus, considering only people with a particular trait, in order to determine groupspecific patterns of deceptive language.",5.3 Gender and Native Language Differences in Deception Behavior,[0],[0]
"As before, tests for significance correct for family-wise Type I error by controlling the false discovery rate (FDR) at α = 0.05.",5.3 Gender and Native Language Differences in Deception Behavior,[0],[0]
The kth smallest p value is considered significant if it is less than k∗αn .,5.3 Gender and Native Language Differences in Deception Behavior,[0],[0]
There were no significant differences in deception ability between male and female speakers.,5.3.1 Gender,[0],[0]
"However, there were many differences in language between male and female speakers.",5.3.1 Gender,[0],[0]
"Further, some features were only discriminative between deception and truth for a specific gender.",5.3.1 Gender,[0],[0]
"Table 3 shows linguistic features that were significantly different between truthful and deceptive speech, but only for one gender.",5.3.1 Gender,[0],[0]
"In some cases the feature was found in different proportions in male and females, and in other cases there was no significant difference.",5.3.1 Gender,[0],[0]
"For example, family words were indicative of deception only in female speakers, and these words were also used more frequently by female speakers than male speakers.
",5.3.1 Gender,[0],[0]
"The LIWC category of compare was also indicative of deception for females only, and this feature was generally found more frequently in female speech.",5.3.1 Gender,[0],[0]
"Article usage was only significantly different between truthful and deceptive speech in females (more articles were found in deceptive speech), but articles were used more frequently in male speech.",5.3.1 Gender,[0],[0]
"On the other hand, the LIWC category of posemo (positive emotion) was increased in truthful speech for male speakers only, and there
was no significant difference of posemo frequency across gender.",5.3.1 Gender,[0],[0]
"Interviewees were more successful at deceiving native Chinese speakers than at deceiving native English speakers (t(170) = −2.13, p = 0.033).",5.3.2 Native Language,[0],[0]
"This was true regardless of interviewee gender and native language, and slightly stronger for female interviewers (t(170) = −2.22, p = 0.027).",5.3.2 Native Language,[0],[0]
"When considering only female interviewers, interviewees were more successful at deceiving nonnative speakers than native speakers, but this difference was not significant when considering only male interviewers.",5.3.2 Native Language,[0],[0]
"As with gender, there were several features that were discriminative between deception and truth for only native speakers of English, or only native speakers of Mandarin.",5.3.2 Native Language,[0],[0]
"Table 3 shows LIWC categories and their relation to deception, broken down by native language.",5.3.2 Native Language,[0],[0]
"For example, power words were found more frequently in deception statements, when considering native English speakers only.",5.3.2 Native Language,[0],[0]
"In general, power words were used more by native Mandarin speakers than by native English speakers.",5.3.2 Native Language,[0],[0]
"LIWC categories of compare, relative, and swear were more prevalent in deceptive speech, only for English speakers.",5.3.2 Native Language,[0],[0]
"On the other hand, feel and perception dimensions were only indicators of deception for native Mandarin speakers, although there was no significant difference in the use of these word categories across native language.",5.3.2 Native Language,[0],[0]
"Informal and netspeak word dimensions tended to be more frequent in truthful speech for native Chinese speakers only (approaching significance), and these word categories were generally more frequent in native Mandarin speech.",5.3.2 Native Language,[0],[0]
"Finally, filler words tended to be more frequent in deceptive speech (approaching significance) only for native Mandarin speakers, and these were used more frequently by native Mandarin speakers than native English speakers.
",5.3.2 Native Language,[0],[0]
"Overall, our findings suggest that deceptive behavior in general, and deceptive language in particular, are affected by a person’s individual characteristics, including gender and native language.",5.3.2 Native Language,[0],[0]
"When building a deception classification system, it is important to account for this variation across speaker groups.",5.3.2 Native Language,[0],[0]
"Motivated by our analysis showing many significant differences in the language of truthful and deceptive responses to interview questions, we trained machine learning classifiers to automatically distinguish between truthful and deceptive text, using the feature sets described in section 4.",6 Deception Classification,[0],[0]
We compared classification performance for the two segmentation methods described in section 3.2: first turn and multiple turns.,6 Deception Classification,[0],[0]
This allowed us to explore the role of context in automatic deception detection.,6 Deception Classification,[0],[0]
"When classifying interviewee response-segments, should the immediate response only be used for classification, or is inclusion of surrounding turns helpful?",6 Deception Classification,[0],[0]
"This has implications not only for deception classification, but for practitioners as well.",6 Deception Classification,[0],[0]
"Should human interviewers make use of responses to follow up questions when determining response veracity, or should the initial response receive the most consideration?
",6 Deception Classification,[0],[0]
"We compared the performance of 3 classification algorithms: Random Forest, Logistic Regression, and SVM (sklearn implementation).",6 Deception Classification,[0],[0]
"In total, there were 7,792 question segments for both single turn and multiple turns segmentations.",6 Deception Classification,[0],[0]
"We divided this into 66% train and 33% test, and used the same fixed test set in experiments for both segmentations in order to directly compare results.",6 Deception Classification,[0],[0]
"The random baseline performance is 50, since the dataset is balanced for truthful and deceptive statements.",6 Deception Classification,[0],[0]
"Another baseline is human performance, which is 46.0 F1 in this corpus.",6 Deception Classification,[0],[0]
"The Random For-
est classifier was consistently the best performing, and we only report those results due to space constraints.",6 Deception Classification,[0],[0]
"Table 4 displays the classification performance for each feature set individually, as well as feature combinations, for both single turn and multiple turn segmentations.",6 Deception Classification,[0],[0]
"It also shows the human baseline performance, obtained from the interviewers’ judgments of deception in the corpus, which were made after asking each question along with related follow-up questions (i.e. multiple turn segmentation).
",6 Deception Classification,[0],[0]
The best performance (72.74 F1-score) was obtained using LIWC features extracted from multiple turns.,6 Deception Classification,[0],[0]
"This is a 22.74% absolute increase over the random baseline of 50, and a 26.74% absolute increase over the human baseline of 46.",6 Deception Classification,[0],[0]
"The performance of classifiers trained on multiple turns was consistently better than those trained on single turns, for all feature sets.",6 Deception Classification,[0],[0]
"For multiple turns, LIWC features were better than the lexical feature set, and combining lexical with LIWC features did not improve over the performance of LIWC features alone.",6 Deception Classification,[0],[0]
Adding individual traits information was also not beneficial.,6 Deception Classification,[0],[0]
"However, when considering the first turn only, the best results (70.87 F1-score) were obtained using a combination of LIWC+lexical+individual features.",6 Deception Classification,[0],[0]
"Using the first turns segmentation, lexical features were slightly better than LIWC features, and interestingly, adding individual traits helped both feature sets.",6 Deception Classification,[0],[0]
"A combination of LIWC and lexical features was better than each on its own.
",6 Deception Classification,[0],[0]
"These results suggest that contextual informa-
tion, in the form of follow up questions, is beneficial for deception classification.",6 Deception Classification,[0],[0]
"It seems that individual traits, including gender, native language, and personality scores, are helpful in deception classification under the condition where contextual information is not available.",6 Deception Classification,[0],[0]
"When the contextual information is available, the the additional lexical content is more useful than individual traits.",6 Deception Classification,[0],[0]
In this paper we presented a study of deceptive language in interview dialogues.,7 Conclusions and Future Work,[0],[0]
Our analysis of linguistic characteristics of deceptive and truthful speech provides insight into the nature of deceptive language.,7 Conclusions and Future Work,[0],[0]
"We also analyzed the linguistic characteristics of speech that is perceived as deceptive and truthful, which is important for understanding the nature of trustworthy speech.",7 Conclusions and Future Work,[0],[0]
"We explored variation across gender and native language in linguistic cues to deception, highlighting cues that are specific to particular groups of speakers.",7 Conclusions and Future Work,[0],[0]
We built classifiers that use combinations of linguistic features and individual traits to automatically identify deceptive speech.,7 Conclusions and Future Work,[0],[0]
"We compared the performance of using cues from the single first turn of an interviewee response-segment with using cues from the full context of multiple interviewee turns, achieving performance as high as 72.74% F1-score (about 27% better than human detection performance).
",7 Conclusions and Future Work,[0],[0]
"This work contributes to the critical problem of automatic deception detection, and increases our scientific understanding of deception, deception perception, and individual differences in deceptive behavior.",7 Conclusions and Future Work,[0],[0]
"In future work, we plan to conduct similar analysis in additional deception corpora in other domains, in order to identify consistent domain-independent deception indicators.",7 Conclusions and Future Work,[0],[0]
"In addition, we plan to conduct cross-corpus machine learning experiments, to evaluate the robustness of these and other feature sets in deception detection.",7 Conclusions and Future Work,[0],[0]
"We also would like to explore additional feature combinations, such as adding acoustic-prosodic features.",7 Conclusions and Future Work,[0],[0]
"Finally, we plan to conduct an empirical analysis of deception behavior across personality types.",7 Conclusions and Future Work,[0],[0]
"This work was partially funded by AFOSR FA9550-11-1-0120 and by NSF DGE-11-44155.
",Acknowledgments,[0],[0]
Thank you to Bingyan Hu for her assistance with feature extraction.,Acknowledgments,[0],[0]
We thank the anonymous reviewers for their helpful comments.,Acknowledgments,[0],[0]
We explore deception detection in interview dialogues.,abstractText,[0],[0]
We analyze a set of linguistic features in both truthful and deceptive responses to interview questions.,abstractText,[0],[0]
"We also study the perception of deception, identifying characteristics of statements that are perceived as truthful or deceptive by interviewers.",abstractText,[0],[0]
"Our analysis show significant differences between truthful and deceptive question responses, as well as variations in deception patterns across gender and native language.",abstractText,[0],[0]
This analysis motivated our selection of features for machine learning experiments aimed at classifying globally deceptive speech.,abstractText,[0],[0]
"Our best classification performance is 72.74 F1-Score (about 27% better than human performance), which is achieved using a combination of linguistic features and individual traits.",abstractText,[0],[0]
Linguistic Cues to Deception and Perceived Deception in Interview Dialogues,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 5027–5038 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
5027",text,[0],[0]
"Semantic role labeling (SRL) extracts a high-level representation of meaning from a sentence, labeling e.g. who did what to whom.",1 Introduction,[0],[0]
"Explicit representations of such semantic information have been
shown to improve results in challenging downstream tasks such as dialog systems (Tur et al., 2005; Chen et al., 2013), machine reading (Berant et al., 2014; Wang et al., 2015) and translation (Liu and Gildea, 2010; Bazrafshan and Gildea, 2013).
",1 Introduction,[0],[0]
"Though syntax was long considered an obvious prerequisite for SRL systems (Levin, 1993; Punyakanok et al., 2008), recently deep neural network architectures have surpassed syntacticallyinformed models (Zhou and Xu, 2015; Marcheggiani et al., 2017; He et al., 2017; Tan et al., 2018; He et al., 2018), achieving state-of-the art SRL performance with no explicit modeling of syntax.",1 Introduction,[0],[0]
"An additional benefit of these end-to-end models is that they require just raw tokens and (usually) detected predicates as input, whereas richer linguistic features typically require extraction by an auxiliary pipeline of models.
",1 Introduction,[0],[0]
"Still, recent work (Roth and Lapata, 2016; He et al., 2017; Marcheggiani and Titov, 2017) indicates that neural network models could see even higher accuracy gains by leveraging syntactic information rather than ignoring it.",1 Introduction,[0],[0]
"He et al. (2017) indicate that many of the errors made by a syntaxfree neural network on SRL are tied to certain syntactic confusions such as prepositional phrase attachment, and show that while constrained inference using a relatively low-accuracy predicted parse can provide small improvements in SRL accuracy, providing a gold-quality parse leads to substantial gains.",1 Introduction,[0],[0]
"Marcheggiani and Titov (2017) incorporate syntax from a high-quality parser (Kiperwasser and Goldberg, 2016) using graph convolutional neural networks (Kipf and Welling, 2017), but like He et al. (2017) they attain only small increases over a model with no syntactic parse, and even perform worse than a syntax-free model on out-of-domain data.",1 Introduction,[0],[0]
"These works suggest that though syntax has the potential to improve neural network SRL models, we have not
yet designed an architecture which maximizes the benefits of auxiliary syntactic information.
",1 Introduction,[0],[0]
"In response, we propose linguistically-informed self-attention (LISA): a model that combines multi-task learning (Caruana, 1993) with stacked layers of multi-head self-attention (Vaswani et al., 2017); the model is trained to: (1) jointly predict parts of speech and predicates; (2) perform parsing; and (3) attend to syntactic parse parents, while (4) assigning semantic role labels.",1 Introduction,[0],[0]
"Whereas prior work typically requires separate models to provide linguistic analysis, including most syntaxfree neural models which still rely on external predicate detection, our model is truly end-to-end: earlier layers are trained to predict prerequisite parts-of-speech and predicates, the latter of which are supplied to later layers for scoring.",1 Introduction,[0],[0]
"Though prior work re-encodes each sentence to predict each desired task and again with respect to each predicate to perform SRL, we more efficiently encode each sentence only once, predict its predicates, part-of-speech tags and labeled syntactic parse, then predict the semantic roles for all predicates in the sentence in parallel.",1 Introduction,[0],[0]
"The model is trained such that, as syntactic parsing models improve, providing high-quality parses at test time will improve its performance, allowing the model to leverage updated parsing models without requiring re-training.
",1 Introduction,[0],[0]
In experiments on the CoNLL-2005 and CoNLL-2012 datasets we show that our linguistically-informed models out-perform the syntax-free state-of-the-art.,1 Introduction,[0],[0]
"On CoNLL-2005 with predicted predicates and standard word embeddings, our single model out-performs the previous state-of-the-art model on the WSJ test set by 2.5 F1 points absolute.",1 Introduction,[0],[0]
"On the challenging out-of-domain Brown test set, our model improves substantially over the previous state-of-the-art by more than 3.5 F1, a nearly 10% reduction in error.",1 Introduction,[0],[0]
"On CoNLL-2012, our model gains more than 2.5 F1 absolute over the previous state-of-the-art.",1 Introduction,[0],[0]
"Our models also show improvements when using contextually-encoded word representations (Peters et al., 2018), obtaining nearly 1.0 F1 higher than the state-of-the-art on CoNLL-2005 news and more than 2.0 F1 improvement on out-of-domain text.1
1Our implementation in TensorFlow (Abadi et al., 2015) is available at : http://github.com/strubell/",1 Introduction,[0],[0]
LISA,1 Introduction,[0],[0]
Our goal is to design an efficient neural network model which makes use of linguistic information as effectively as possible in order to perform endto-end SRL.,2 Model,[0],[0]
"LISA achieves this by combining: (1) A new technique of supervising neural attention to predict syntactic dependencies with (2) multi-task learning across four related tasks.
",2 Model,[0],[0]
Figure 1 depicts the overall architecture of our model.,2 Model,[0],[0]
"The basis for our model is the Transformer encoder introduced by Vaswani et al. (2017): we transform word embeddings into contextually-encoded token representations using stacked multi-head self-attention and feedforward layers (§2.1).
",2 Model,[0],[0]
"To incorporate syntax, one self-attention head is trained to attend to each token’s syntactic parent, allowing the model to use this attention head as an oracle for syntactic dependencies.",2 Model,[0],[0]
"We introduce this syntactically-informed self-attention (Figure 2) in more detail in §2.2.
",2 Model,[0],[0]
Our model is designed for the more realistic setting in which gold predicates are not provided at test-time.,2 Model,[0],[0]
"Our model predicts predicates and integrates part-of-speech (POS) information into earlier layers by re-purposing representations closer to the input to predict predicate and POS tags us-
ing hard parameter sharing (§2.3).",2 Model,[0],[0]
"We simplify optimization and benefit from shared statistical strength derived from highly correlated POS and predicates by treating tagging and predicate detection as a single task, performing multi-class classification into the joint Cartesian product space of POS and predicate labels.
",2 Model,[0],[0]
"Though typical models, which re-encode the sentence for each predicate, can simplify SRL to token-wise tagging, our joint model requires a different approach to classify roles with respect to each predicate.",2 Model,[0],[0]
"Contextually encoded tokens are projected to distinct predicate and role embeddings (§2.4), and each predicted predicate is scored with the sequence’s role representations using a bilinear model (Eqn. 6), producing per-label scores for BIO-encoded semantic role labels for each token and each semantic frame.
",2 Model,[0],[0]
The model is trained end-to-end by maximum likelihood using stochastic gradient descent (§2.5).,2 Model,[0],[0]
"The basis for our model is a multi-head selfattention token encoder, recently shown to achieve state-of-the-art performance on SRL (Tan et al., 2018), and which provides a natural mechanism
for incorporating syntax, as described in §2.2.",2.1 Self-attention token encoder,[0],[0]
"Our implementation replicates Vaswani et al. (2017).
",2.1 Self-attention token encoder,[0],[0]
The input to the network is a sequence X of T token representations xt.,2.1 Self-attention token encoder,[0],[0]
"In the standard setting these token representations are initialized to pretrained word embeddings, but we also experiment with supplying pre-trained ELMo representations combined with task-specific learned parameters, which have been shown to substantially improve performance of other SRL models (Peters et al., 2018).",2.1 Self-attention token encoder,[0],[0]
"For experiments with gold predicates, we concatenate a predicate indicator embedding pt following previous work (He et al., 2017).
",2.1 Self-attention token encoder,[0],[0]
We project2 these input embeddings to a representation that is the same size as the output of the self-attention layers.,2.1 Self-attention token encoder,[0],[0]
"We then add a positional encoding vector computed as a deterministic sinusoidal function of t, since the self-attention has no innate notion of token position.
",2.1 Self-attention token encoder,[0],[0]
We feed this token representation as input to a series of J residual multi-head self-attention layers with feed-forward connections.,2.1 Self-attention token encoder,[0],[0]
"Denoting the jth self-attention layer as T (j)(·), the output of that layer s(j)t , and LN(·) layer normalization, the following recurrence applied to initial input c(p)t :
s (j) t = LN(s (j 1) t + T (j)(s(j 1)t ))",2.1 Self-attention token encoder,[0],[0]
"(1)
gives our final token representations s(j)t .",2.1 Self-attention token encoder,[0],[0]
Each T (j)(·) consists of: (a) multi-head self-attention and (b) a feed-forward projection.,2.1 Self-attention token encoder,[0],[0]
"The multi-head self attention consists of H attention heads, each of which learns a distinct attention function to attend to all of the tokens in the sequence.",2.1 Self-attention token encoder,[0],[0]
"This self-attention is performed for each token for each head, and the results of the H self-attentions are concatenated to form the final self-attended representation for each token.
",2.1 Self-attention token encoder,[0],[0]
"Specifically, consider the matrix S(j 1) of T token representations at layer j 1.",2.1 Self-attention token encoder,[0],[0]
"For each attention head h, we project this matrix into distinct key, value and query representations K(j)h , V (j) h and Q(j)h of dimensions T⇥dk, T⇥dq, and T⇥dv, respectively.",2.1 Self-attention token encoder,[0],[0]
We can then multiply Q(j)h by K (j) h to obtain a T ⇥ T matrix of attention weights A(j)h between each pair of tokens in the sentence.,2.1 Self-attention token encoder,[0],[0]
"Following Vaswani et al. (2017) we perform scaled dot-product attention: We scale the weights by the inverse square root of their embedding dimension
2All linear projections include bias terms, which we omit in this exposition for the sake of clarity.
and normalize with the softmax function to produce a distinct distribution for each token over all the tokens in the sentence:
A (j) h = softmax(d 0.5 k Q (j) h K (j) h
T ) (2)
",2.1 Self-attention token encoder,[0],[0]
"These attention weights are then multiplied by V
(j) h for each token to obtain the self-attended to-
ken representations M (j)h :
M (j) h = A (j) h V (j) h (3)
Row t of M (j)h , the self-attended representation for token t at layer j, is thus the weighted sum with respect to t (with weights given by A(j)h ) over the token representations in V (j)h .
",2.1 Self-attention token encoder,[0],[0]
"The outputs of all attention heads for each token are concatenated, and this representation is passed to the feed-forward layer, which consists of two linear projections each followed by leaky ReLU activations (Maas et al., 2013).",2.1 Self-attention token encoder,[0],[0]
"We add the output of the feed-forward to the initial representation and apply layer normalization to give the final output of self-attention layer j, as in Eqn. 1.",2.1 Self-attention token encoder,[0],[0]
"Typically, neural attention mechanisms are left on their own to learn to attend to relevant inputs.",2.2 Syntactically-informed self-attention,[0],[0]
"Instead, we propose training the self-attention to attend to specific tokens corresponding to the syntactic structure of the sentence as a mechanism for passing linguistic knowledge to later layers.
",2.2 Syntactically-informed self-attention,[0],[0]
"Specifically, we replace one attention head with the deep bi-affine model of Dozat and Manning (2017), trained to predict syntactic dependencies.",2.2 Syntactically-informed self-attention,[0],[0]
"Let Aparse be the parse attention weights, at layer i.",2.2 Syntactically-informed self-attention,[0],[0]
Its input is the matrix of token representations S (i 1).,2.2 Syntactically-informed self-attention,[0],[0]
"As with the other attention heads, we project S(i 1) into key, value and query representations, denoted Kparse, Qparse, Vparse.",2.2 Syntactically-informed self-attention,[0],[0]
"Here the key and query projections correspond to parent and dependent representations of the tokens, and we allow their dimensions to differ from the rest of the attention heads to more closely follow the implementation of Dozat and Manning (2017).",2.2 Syntactically-informed self-attention,[0],[0]
"Unlike the other attention heads which use a dot product to score key-query pairs, we score the compatibility between Kparse and Qparse using a bi-affine operator Uheads to obtain attention weights:
Aparse = softmax(QparseUheadsK T parse) (4)
These attention weights are used to compose a weighted average of the value representations Vparse as in the other attention heads.
",2.2 Syntactically-informed self-attention,[0],[0]
"We apply auxiliary supervision at this attention head to encourage it to attend to each token’s parent in a syntactic dependency tree, and to encode information about the token’s dependency label.",2.2 Syntactically-informed self-attention,[0],[0]
"Denoting the attention weight from token t to a candidate head q as Aparse[t, q], we model the probability of token t having parent q as:
P (q = head(t) | X ) = Aparse[t, q] (5)
using the attention weights Aparse[t] as the distribution over possible heads for token t.",2.2 Syntactically-informed self-attention,[0],[0]
We define the root token as having a self-loop.,2.2 Syntactically-informed self-attention,[0],[0]
"This attention head thus emits a directed graph3 where each token’s parent is the token to which the attention Aparse assigns the highest weight.
",2.2 Syntactically-informed self-attention,[0],[0]
"We also predict dependency labels using perclass bi-affine operations between parent and dependent representations Qparse and Kparse to produce per-label scores, with locally normalized probabilities over dependency labels ydept given by the softmax function.",2.2 Syntactically-informed self-attention,[0],[0]
"We refer the reader to Dozat and Manning (2017) for more details.
",2.2 Syntactically-informed self-attention,[0],[0]
"This attention head now becomes an oracle for syntax, denoted P , providing a dependency parse to downstream layers.",2.2 Syntactically-informed self-attention,[0],[0]
"This model not only predicts its own dependency arcs, but allows for the injection of auxiliary parse information at test time by simply setting Aparse to the parse parents produced by e.g. a state-of-the-art parser.",2.2 Syntactically-informed self-attention,[0],[0]
"In this way, our model can benefit from improved, external parsing models without re-training.",2.2 Syntactically-informed self-attention,[0],[0]
"Unlike typical multi-task models, ours maintains the ability to leverage external syntactic information.",2.2 Syntactically-informed self-attention,[0],[0]
We also share the parameters of lower layers in our model to predict POS tags and predicates.,2.3 Multi-task learning,[0],[0]
"Following He et al. (2017), we focus on the end-toend setting, where predicates must be predicted on-the-fly.",2.3 Multi-task learning,[0],[0]
"Since we also train our model to predict syntactic dependencies, it is beneficial to give the model knowledge of POS information.",2.3 Multi-task learning,[0],[0]
"While much previous work employs a pipelined approach to both POS tagging for dependency parsing and predicate detection for SRL, we take a multi-task learning (MTL) approach (Caruana,
3Usually the head emits a tree, but we do not enforce it here.
1993), sharing the parameters of earlier layers in our SRL model with a joint POS and predicate detection objective.",2.3 Multi-task learning,[0],[0]
"Since POS is a strong predictor of predicates4 and the complexity of training a multi-task model increases with the number of tasks, we combine POS tagging and predicate detection into a joint label space: For each POS tag TAG which is observed co-occurring with a predicate, we add a label of the form TAG:PREDICATE.
",2.3 Multi-task learning,[0],[0]
"Specifically, we feed the representation s(r)t from a layer r preceding the syntacticallyinformed layer p to a linear classifier to produce per-class scores rt for token t.",2.3 Multi-task learning,[0],[0]
"We compute locally-normalized probabilities using the softmax function: P (yprpt | X ) / exp(rt), where y prp t is a label in the joint space.",2.3 Multi-task learning,[0],[0]
Our final goal is to predict semantic roles for each predicate in the sequence.,2.4 Predicting semantic roles,[0],[0]
"We score each predicate against each token in the sequence using a bilinear operation, producing per-label scores for each token for each predicate, with predicates and syntax determined by oracles V and P .
",2.4 Predicting semantic roles,[0],[0]
"First, we project each token representation s(J)t to a predicate-specific representation spredt and a role-specific representation srolet .",2.4 Predicting semantic roles,[0],[0]
We then provide these representations to a bilinear transformation U for scoring.,2.4 Predicting semantic roles,[0],[0]
"So, the role label scores sft for the token at index t with respect to the predicate at index f (i.e. token t and frame f ) are given by:
sft = (s pred f )",2.4 Predicting semantic roles,[0],[0]
"T Us role t (6)
which can be computed in parallel across all semantic frames in an entire minibatch.",2.4 Predicting semantic roles,[0],[0]
"We calculate a locally normalized distribution over role labels for token t in frame f using the softmax function: P (yroleft | P,V,X ) / exp(sft).
",2.4 Predicting semantic roles,[0],[0]
"At test time, we perform constrained decoding using the Viterbi algorithm to emit valid sequences of BIO tags, using unary scores sft and the transition probabilities given by the training data.",2.4 Predicting semantic roles,[0],[0]
We maximize the sum of the likelihoods of the individual tasks.,2.5 Training,[0],[0]
"In order to maximize our model’s ability to leverage syntax, during training we clamp P to the gold parse (PG) and V to gold predicates VG when passing parse and predicate
4All predicates in CoNLL-2005 are verbs; CoNLL-2012 includes some nominal predicates.
representations to later layers, whereas syntactic head prediction and joint predicate/POS prediction are conditioned only on the input sequence X .",2.5 Training,[0],[0]
"The overall objective is thus:
1
T
TX
t=1
h FX
f=1
log P (yroleft | PG,VG,X )
+ log P",2.5 Training,[0],[0]
(,2.5 Training,[0],[0]
yprpt | X ),2.5 Training,[0],[0]
"+ 1 log P (head(t) | X )
",2.5 Training,[0],[0]
"+ 2 log P (y dep t | PG,X )
",2.5 Training,[0],[0]
"i (7)
where 1 and 2 are penalties on the syntactic attention loss.
",2.5 Training,[0],[0]
"We train the model using Nadam (Dozat, 2016)",2.5 Training,[0],[0]
SGD combined with the learning rate schedule in Vaswani et al. (2017).,2.5 Training,[0],[0]
"In addition to MTL, we regularize our model using dropout (Srivastava et al., 2014).",2.5 Training,[0],[0]
"We use gradient clipping to avoid exploding gradients (Bengio et al., 1994; Pascanu et al., 2013).",2.5 Training,[0],[0]
Additional details on optimization and hyperparameters are included in Appendix A.,2.5 Training,[0],[0]
"Early approaches to SRL (Pradhan et al., 2005; Surdeanu et al., 2007; Johansson and Nugues, 2008; Toutanova et al., 2008) focused on developing rich sets of linguistic features as input to a linear model, often combined with complex constrained inference e.g. with an ILP (Punyakanok et al., 2008). Täckström",3 Related work,[0],[0]
et al. (2015) showed that constraints could be enforced more efficiently using a clever dynamic program for exact inference.,3 Related work,[0],[0]
"Sutton and McCallum (2005) modeled syntactic parsing and SRL jointly, and Lewis et al. (2015) jointly modeled SRL and CCG parsing.
",3 Related work,[0],[0]
"Collobert et al. (2011) were among the first to use a neural network model for SRL, a CNN over word embeddings which failed to out-perform non-neural models.",3 Related work,[0],[0]
FitzGerald et al. (2015) successfully employed neural networks by embedding lexicalized features and providing them as factors in the model of Täckström,3 Related work,[0],[0]
"et al. (2015).
",3 Related work,[0],[0]
More recent neural models are syntax-free.,3 Related work,[0],[0]
"Zhou and Xu (2015), Marcheggiani et al. (2017) and He et al. (2017) all use variants of deep LSTMs with constrained decoding, while Tan et al. (2018) apply self-attention to obtain state-ofthe-art SRL with gold predicates.",3 Related work,[0],[0]
"Like this work, He et al. (2017) present end-to-end experiments, predicting predicates using an LSTM, and He et al.
(2018) jointly predict SRL spans and predicates in a model based on that of Lee et al. (2017), obtaining state-of-the-art predicted predicate SRL.",3 Related work,[0],[0]
"Concurrent to this work, Peters et al. (2018) and He et al. (2018) report significant gains on PropBank SRL by training a wide LSTM language model and using a task-specific transformation of its hidden representations (ELMo) as a deep, and computationally expensive, alternative to typical word embeddings.",3 Related work,[0],[0]
"We find that LISA obtains further accuracy increases when provided with ELMo word representations, especially on out-of-domain data.
",3 Related work,[0],[0]
Some work has incorporated syntax into neural models for SRL.,3 Related work,[0],[0]
"Roth and Lapata (2016) incorporate syntax by embedding dependency paths, and similarly Marcheggiani and Titov (2017) encode syntax using a graph CNN over a predicted syntax tree, out-performing models without syntax on CoNLL-2009.",3 Related work,[0],[0]
These works are limited to incorporating partial dependency paths between tokens whereas our technique incorporates the entire parse.,3 Related work,[0],[0]
"Additionally, Marcheggiani and Titov (2017) report that their model does not out-perform syntax-free models on out-of-domain data, a setting in which our technique excels.
",3 Related work,[0],[0]
"MTL (Caruana, 1993) is popular in NLP, and others have proposed MTL models which incorporate subsets of the tasks we do (Collobert et al., 2011; Zhang and Weiss, 2016; Hashimoto et al., 2017; Peng et al., 2017; Swayamdipta et al., 2017), and we build off work that investigates where and when to combine different tasks to achieve the best results (Søgaard and Goldberg, 2016; Bingel and Søgaard, 2017; Alonso and Plank, 2017).",3 Related work,[0],[0]
"Our specific method of incorporating supervision into self-attention is most similar to the concurrent work of Liu and Lapata (2018), who use edge marginals produced by the matrix-tree algorithm as attention weights for document classification and natural language inference.
",3 Related work,[0],[0]
"The question of training on gold versus predicted labels is closely related to learning to search (Daumé III et al., 2009; Ross et al., 2011; Chang et al., 2015) and scheduled sampling (Bengio et al., 2015), with applications in NLP to sequence labeling and transition-based parsing (Choi and Palmer, 2011; Goldberg and Nivre, 2012; Ballesteros et al., 2016).",3 Related work,[0],[0]
"Our approach may be interpreted as an extension of teacher forcing (Williams and Zipser, 1989) to MTL.",3 Related work,[0],[0]
"We leave exploration of more advanced scheduled sampling techniques to
future work.",3 Related work,[0],[0]
"We present results on the CoNLL-2005 shared task (Carreras and Màrquez, 2005) and the CoNLL-2012 English subset of OntoNotes 5.0 (Pradhan et al., 2006), achieving state-of-the-art results for a single model with predicted predicates on both corpora.",4 Experimental results,[0],[0]
"We experiment with both standard pre-trained GloVe word embeddings (Pennington et al., 2014) and pre-trained ELMo representations with fine-tuned task-specific parameters (Peters et al., 2018) in order to best compare to prior work.",4 Experimental results,[0],[0]
"Hyperparameters that resulted in the best performance on the validation set were selected via a small grid search, and models were trained for a maximum of 4 days on one TitanX GPU using early stopping on the validation set.",4 Experimental results,[0],[0]
"We convert constituencies to dependencies using the Stanford head rules v3.5 (de Marneffe and Manning, 2008).",4 Experimental results,[0],[0]
"A detailed description of hyperparameter settings and data pre-processing can be found in Appendix A.
We compare our LISA models to four strong baselines:",4 Experimental results,[0],[0]
"For experiments using predicted predicates, we compare to He et al. (2018) and the ensemble model (PoE) from He et al. (2017), as well as a version of our own self-attention model which does not incorporate syntactic information (SA).",4 Experimental results,[0],[0]
"To compare to more prior work, we present additional results on CoNLL-2005 with models given gold predicates at test time.",4 Experimental results,[0],[0]
"In these experiments we also compare to Tan et al. (2018), the previous state-of-the art SRL model using gold predicates and standard embeddings.
",4 Experimental results,[0],[0]
"We demonstrate that our models benefit from injecting state-of-the-art predicted parses at test time (+D&M) by fixing the attention to parses predicted by Dozat and Manning (2017), the winner of the 2017 CoNLL shared task (Zeman et al., 2017) which we re-train using ELMo embeddings.",4 Experimental results,[0],[0]
"In all cases, using these parses at test time improves performance.
",4 Experimental results,[0],[0]
"We also evaluate our model using the gold syntactic parse at test time (+Gold), to provide an upper bound for the benefit that syntax could have for SRL using LISA.",4 Experimental results,[0],[0]
"These experiments show that despite LISA’s strong performance, there remains substantial room for improvement.",4 Experimental results,[0],[0]
In §4.3 we perform further analysis comparing SRL models using gold and predicted parses.,4 Experimental results,[0],[0]
"Table 1 lists precision, recall and F1 on the CoNLL-2005 development and test sets using predicted predicates.",4.1 Semantic role labeling,[0],[0]
"For models using GloVe embeddings, our syntax-free SA model already achieves a new state-of-the-art by jointly predicting predicates, POS and SRL.",4.1 Semantic role labeling,[0],[0]
"LISA with its own parses performs comparably to SA, but when supplied with D&M parses LISA out-performs the previous state-of-the-art by 2.5 F1 points.",4.1 Semantic role labeling,[0],[0]
"On the out-ofdomain Brown test set, LISA also performs comparably to its syntax-free counterpart with its own parses, but with D&M parses LISA performs exceptionally well, more than 3.5 F1 points higher than He et al. (2018).",4.1 Semantic role labeling,[0],[0]
"Incorporating ELMo em-
beddings improves all scores.",4.1 Semantic role labeling,[0],[0]
"The gap in SRL F1 between models using LISA and D&M parses is smaller due to LISA’s improved parsing accuracy (see §4.2), but LISA with D&M parses still achieves the highest F1: nearly 1.0 absolute F1 higher than the previous state-of-the art on WSJ, and more than 2.0 F1 higher on Brown.",4.1 Semantic role labeling,[0],[0]
"In both settings LISA leverages domain-agnostic syntactic information rather than over-fitting to the newswire training data which leads to high performance even on out-of-domain text.
",4.1 Semantic role labeling,[0],[0]
To compare to more prior work we also evaluate our models in the artificial setting where gold predicates are provided at test time.,4.1 Semantic role labeling,[0],[0]
"For fair comparison we use GloVe embeddings, provide predicate indicator embeddings on the input and reencode the sequence relative to each gold predicate.",4.1 Semantic role labeling,[0],[0]
"Here LISA still excels: with D&M parses, LISA out-performs the previous state-of-the-art by more than 2 F1 on both WSJ and Brown.
",4.1 Semantic role labeling,[0],[0]
"Table 3 reports precision, recall and F1 on the CoNLL-2012 test set.",4.1 Semantic role labeling,[0],[0]
We observe performance similar to that observed on ConLL-2005:,4.1 Semantic role labeling,[0],[0]
Using GloVe embeddings our SA baseline already out-performs He et al. (2018) by nearly 1.5 F1.,4.1 Semantic role labeling,[0],[0]
"With its own parses, LISA slightly under-performs our syntax-free model, but when provided with stronger D&M parses LISA outperforms the state-of-the-art by more than 2.5 F1.",4.1 Semantic role labeling,[0],[0]
"Like CoNLL-2005, ELMo representations improve all models and close the F1 gap between models supplied with LISA and D&M parses.",4.1 Semantic role labeling,[0],[0]
"On this dataset ELMo also substantially narrows the
difference between models with- and without syntactic information.",4.1 Semantic role labeling,[0],[0]
"This suggests that for this challenging dataset, ELMo already encodes much of the information available in the D&M parses.",4.1 Semantic role labeling,[0],[0]
"Yet, higher accuracy parses could still yield improvements since providing gold parses increases F1 by 4 points even with ELMo embeddings.",4.1 Semantic role labeling,[0],[0]
"We first report the labeled and unlabeled attachment scores (LAS, UAS) of our parsing models on the CoNLL-2005 and 2012 test sets (Table 4) with GloVe (G) and ELMo (E) embeddings.","4.2 Parsing, POS and predicate detection",[0],[0]
D&M achieves the best scores.,"4.2 Parsing, POS and predicate detection",[0],[0]
"Still, LISA’s GloVe UAS is comparable to popular off-the-shelf dependency parsers such as spaCy,5 and with ELMo
5spaCy reports 94.48 UAS on WSJ using Stanford dependencies v3.3: https://spacy.io/usage/
embeddings comparable to the standalone D&M parser.","4.2 Parsing, POS and predicate detection",[0],[0]
"The difference in parse accuracy between LISAG and D&M likely explains the large increase in SRL performance we see from decoding with D&M parses in that setting.
","4.2 Parsing, POS and predicate detection",[0],[0]
"In Table 5 we present predicate detection precision, recall and F1 on the CoNLL-2005 and 2012 test sets.","4.2 Parsing, POS and predicate detection",[0],[0]
SA and LISA with and without ELMo attain comparable scores so we report only LISA+GloVe.,"4.2 Parsing, POS and predicate detection",[0],[0]
"We compare to He et al. (2017) on CoNLL-2005, the only cited work reporting comparable predicate detection F1.","4.2 Parsing, POS and predicate detection",[0],[0]
"LISA attains high predicate detection scores, above 97 F1, on both in-domain datasets, and out-performs He et al. (2017) by 1.5-2 F1 points even on the out-ofdomain Brown test set, suggesting that multi-task learning works well for SRL predicate detection.","4.2 Parsing, POS and predicate detection",[0],[0]
First we assess SRL F1 on sentences divided by parse accuracy.,4.3 Analysis,[0],[0]
"Table 6 lists average SRL F1 (across sentences) for the four conditions of LISA and D&M parses being correct or not (L±, D±).",4.3 Analysis,[0],[0]
"Both parsers are correct on 26% of sentences.
facts-figures
Here there is little difference between any of the models, with LISA models tending to perform slightly better than SA.",4.3 Analysis,[0],[0]
"Both parsers make mistakes on the majority of sentences (57%), difficult sentences where SA also performs the worst.",4.3 Analysis,[0],[0]
"These examples are likely where gold and D&M parses improve the most over other models in overall F1: Though both parsers fail to correctly parse the entire sentence, the D&M parser is less wrong (87.5 vs. 85.7 average LAS), leading to higher SRL F1 by about 1.5 average F1.
",4.3 Analysis,[0],[0]
"Following He et al. (2017), we next apply a series of corrections to model predictions in order to understand which error types the gold parse resolves: e.g. Fix Labels fixes labels on spans matching gold boundaries, and Merge Spans merges adjacent predicted spans into a gold span.6
In Figure 3 we see that much of the performance gap between the gold and predicted parses is due to span boundary errors (Merge Spans, Split Spans and Fix Span Boundary), which supports the hypothesis proposed by He et al. (2017) that incorporating syntax could be particularly helpful for resolving these errors.",4.3 Analysis,[0],[0]
"He et al. (2017) also point out
6Refer to He et al. (2017) for a detailed explanation of the different error types.
that these errors are due mainly to prepositional phrase (PP) attachment mistakes.",4.3 Analysis,[0],[0]
We also find this to be the case: Figure 4 shows a breakdown of split/merge corrections by phrase type.,4.3 Analysis,[0],[0]
"Though the number of corrections decreases substantially across phrase types, the proportion of corrections attributed to PPs remains the same (approx. 50%) even after providing the correct PP attachment to the model, indicating that PP span boundary mistakes are a fundamental difficulty for SRL.",4.3 Analysis,[0],[0]
We present linguistically-informed self-attention: a multi-task neural network model that effectively incorporates rich linguistic information for semantic role labeling.,5 Conclusion,[0],[0]
"LISA out-performs the state-ofthe-art on two benchmark SRL datasets, including out-of-domain.",5 Conclusion,[0],[0]
"Future work will explore improving LISA’s parsing accuracy, developing better training techniques and adapting to more tasks.",5 Conclusion,[0],[0]
"We are grateful to Luheng He for helpful discussions and code, Timothy Dozat for sharing his code, and to the NLP reading groups at Google and UMass and the anonymous reviewers for feedback on drafts of this work.",Acknowledgments,[0],[0]
"This work was supported in part by an IBM PhD Fellowship Award to E.S., in part by the Center for Intelligent Information Retrieval, and in part by the National Science Foundation under Grant Nos. DMR-1534431 and IIS-1514053.",Acknowledgments,[0],[0]
"Any opinions, findings, conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect those of the sponsor.",Acknowledgments,[0],[0]
Current state-of-the-art semantic role labeling (SRL) uses a deep neural network with no explicit linguistic features.,abstractText,[0],[0]
"However, prior work has shown that gold syntax trees can dramatically improve SRL decoding, suggesting the possibility of increased accuracy from explicit modeling of syntax.",abstractText,[0],[0]
"In this work, we present linguistically-informed self-attention (LISA): a neural network model that combines multi-head self-attention with multi-task learning across dependency parsing, part-ofspeech tagging, predicate detection and SRL.",abstractText,[0],[0]
"Unlike previous models which require significant pre-processing to prepare linguistic features, LISA can incorporate syntax using merely raw tokens as input, encoding the sequence only once to simultaneously perform parsing, predicate detection and role labeling for all predicates.",abstractText,[0],[0]
Syntax is incorporated by training one attention head to attend to syntactic parents for each token.,abstractText,[0],[0]
"Moreover, if a high-quality syntactic parse is already available, it can be beneficially injected at test time without re-training our SRL model.",abstractText,[0],[0]
"In experiments on CoNLL-2005 SRL, LISA achieves new state-of-the-art performance for a model using predicted predicates and standard word embeddings, attaining 2.5 F1 absolute higher than the previous state-of-the-art on newswire and more than 3.5 F1 on outof-domain data, nearly 10% reduction in error.",abstractText,[0],[0]
On ConLL-2012 English SRL we also show an improvement of more than 2.5 F1.,abstractText,[0],[0]
"LISA also out-performs the state-of-the-art with contextually-encoded (ELMo) word representations, by nearly 1.0 F1 on news and more than 2.0 F1 on out-of-domain text.",abstractText,[0],[0]
Linguistically-Informed Self-Attention for Semantic Role Labeling,title,[0],[0]
"Recent advances in deep reinforcement learning, supported by the ability of generating and processing large amounts of data, allowed impressive achievements such as playing Atari at human level (Mnih et al., 2015) or mastering the game of Go (Silver et al., 2016).",1. Introduction,[0],[0]
"In robotics however, sample complexity is paramount as sample generation on physical systems cannot be sped up and can cause wear and damage to the robot when excessive (Kober et al., 2013).",1. Introduction,[0],[0]
"Relying on a simulator to carry the learning will inevitably result in a reality gap, since mechanical forces such as stiction are hard to accurately model.",1. Introduction,[0],[0]
"However, a policy learned in a simulated environment can still be valuable provided the availability of a sample efficient algorithm to
1CLAS/IAS, TU Darmstadt, Darmstadt, Germany 2Max Planck Institute for Intelligent Systems, Tübingen, Germany 3LCAS, University of Lincoln, Lincoln, United Kingdom.",1. Introduction,[0],[0]
"Correspondence to: Riad Akrour <riad@robot-learning.de>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
carry an additional optimization phase on the physical system.
",1. Introduction,[0],[0]
"Bayesian optimization is best known as a black-box global optimizer (Brochu et al., 2010; Shahriari et al., 2016).",1. Introduction,[0],[0]
"It was shown to be efficient for several function landscapes (Jones, 2001), real world scenarios such as the automatic tuning of machine learning algorithms (Bergstra et al., 2011; Snoek et al., 2012; Feurer et al., 2015) or robotics and control (Lizotte et al., 2007; Wilson et al., 2014; Calandra et al., 2016) and several of its variants have convergence guaranties to a global optimum (Vazquez & Bect, 2010; Bull, 2011).",1. Introduction,[0],[0]
Its efficiency stems from two key principles: a probabilistic modeling of the objective function and a sampling procedure that fully exploits this model.,1. Introduction,[0],[0]
"However, as the dimensionality of the task increases, non-stationarity effects of the objective or the noise function (see Shahriari et al. (2016), Sec. V.D. for a discussion of these effects) are exacerbated, rendering the modeling of the objective function challenging.",1. Introduction,[0],[0]
"An additional difficulty stemming from the increase in dimensionality is the tendency of Bayesian optimization to over-explore, which was experimentally observed in e.g. Brochu et al. (2007).",1. Introduction,[0],[0]
Several recent approaches trying to scale Bayesian optimization to higher dimensions assume additional structure of the objective function.,1. Introduction,[0],[0]
"In Snoek et al. (2014), it is assumed that stationarity of the objective function can be recovered through the use of a parametric family of mappings.",1. Introduction,[0],[0]
"While it is assumed that the objective function has a lower intrinsic dimension in Djolonga et al. (2013); Wang et al. (2016), can be decomposable into a sum of lower dimensional functions in Kandasamy et al. (2015) or a combination of both hypothesis in Li et al. (2016).
",1. Introduction,[0],[0]
"In this paper, we assume prior knowledge on the location of the optimum—given by an initial solution and a confidence on the optimality thereof—and leverage Bayesian optimization in a local manner to improve over this solution.",1. Introduction,[0],[0]
"We are especially interested in the application of our algorithm to the optimization of motor skills since i) evaluating the policy return is expensive on physical systems and will likely dominate the computational budget of the optimization process; as such, sample efficient algorithms such as Bayesian optimization are desirable ii) robotics applications are typically high dimensional and global optimization might be prohibitively expensive iii) an initial solution
can often be obtained through the use of imitation learning (Argall et al., 2009) or by a preliminary optimization on a surrogate model such as a simulator.",1. Introduction,[0],[0]
"Our algorithm can be seen as a local stochastic search algorithm akin to Covariance Matrix Adaptation (CMAES) (Hansen & Ostermeier, 2001), cross-entropy (Mannor et al., 2003) or MOdel-based Relative Entropy (MORE) (Abdolmaleki et al., 2015).",2. Related work,[0],[0]
"Local stochastic search algorithms typically maintain a Gaussian search distribution from which samples are generated, the objective function is evaluated and the search distribution is updated.",2. Related work,[0],[0]
"As in Bayesian optimization, they are of particular use when the gradient of the objective function is unknown.",2. Related work,[0],[0]
"Their use as a black-box optimization routine is gaining popularity in the machine learning community, e.g. in reinforcement learning (Thomas et al., 2015) or even for hyperparameter tuning (Bergstra et al., 2011) and the optimization of the acquisition function (Wang et al., 2016) of global Bayesian optimization.
",2. Related work,[0],[0]
Our algorithm shares the same general structure as local stochastic search algorithms and additionally learns a (probabilistic) model of the objective function.,2. Related work,[0],[0]
Modeling the objective function was already explored in the stochastic search literature.,2. Related work,[0],[0]
"A surrogate function is learned in (Loshchilov et al., 2013) using SVM-Rank, and is optimized using CMA-ES for a few iterations, yielding an update of the search distribution without requiring additional function evaluations.",2. Related work,[0],[0]
"While in MORE (Abdolmaleki et al., 2015), a local quadratic approximation of the objective function yields the new mean and covariance of the Gaussian search distribution upon an information-theoretic update.",2. Related work,[0],[0]
"Unlike these algorithms, we do not optimize the learned (probabilistic) model, but derive from it p(x = x?|D), the probability of x being optimal.",2. Related work,[0],[0]
Our search distribution is then updated such as to minimize the KullbackLeibler (KL) divergence to p(x = x?|D).,2. Related work,[0],[0]
"Compared to these surrogate assisted local stochastic search algorithms (Loshchilov et al., 2013; Abdolmaleki et al., 2015), the transformation of the optimization landscape (minimizing the KL-divergence to p(x = x?|D) instead of the objective function) facilitates learning of the surrogate model by lowering the variance in poorly performing regions, as illustrated in Fig. 1.
",2. Related work,[0],[0]
To approximate p(x = x?|D),2. Related work,[0],[0]
we rely on a probabilistic modeling of the objective function and to select the next point to sample we locally optimize an acquisition function.,2. Related work,[0],[0]
"As such, our algorithm can also be seen as Bayesian optimization where the usual box constraint is moved towards a high value area of the objective function to restrict exploration.
",2. Related work,[0],[0]
"Algorithm 1 Local Bayesian Optimization of Motor Skills
Input: Initial policy π0 = N (µ0, σ20I), step-size , entropy reduction rate β Output: Policy πN for n = 1 to N do
Fit: Gaussian p̂n from local samples of p?n (Sec. 3.2)",2. Related work,[0],[0]
"Optimize: (η∗, ω∗) = arg min gn(η, ω) (Sec. 3.1.1)",2. Related work,[0],[0]
"Bayesian Update: (πn+1)
η?+ω?",2. Related work,[0],[0]
∝,2. Related work,[0],[0]
πη?n p?n (Sec. 3.1.1),2. Related work,[0],[0]
Evaluate: xn from local samples of p?n (Sec. 3.3),2. Related work,[0],[0]
"Dn ←− Dn−1 ∪ {(xn, yn)}
end for
In reinforcement learning, probabilistic modeling was used to e.g. learn a transition model (Deisenroth & Rasmussen, 2011) or the policy gradient (Ghavamzadeh et al., 2016) with Gaussian processes.",2. Related work,[0],[0]
"Closer to our work, the use of an adaptive box constraint was explored in Bayesian optimization to ensure a safe optimization of a robot controller (Berkenkamp et al., 2016; Englert & Toussaint, 2016).",2. Related work,[0],[0]
Considering safety is crucial for motor skill learning on physical systems to prevent the evaluation of ’dangerous’ parameters.,2. Related work,[0],[0]
Both approaches restrict exploration to an initial safe region of the parameter space that is incrementally expanded using additional problem assumptions.,2. Related work,[0],[0]
Without such assumptions our algorithm cannot guarantee safety but its local nature is expected to dampen the potential risk of global Bayesian optimization.,2. Related work,[0],[0]
Let f : Rd 7→ R be an objective function.,3. Local Bayesian optimization,[0],[0]
For example f(x) can be the expected reward of a robot controller parameterized by x ∈ Rd.,3. Local Bayesian optimization,[0],[0]
"We assume that the algorithm only has access to noisy evaluations y = f(x) + , where ∼ N (0, σ2s) is Gaussian noise of unknown deviation σs.",3. Local Bayesian optimization,[0],[0]
"The algorithm will produce a sequence {(x1, y1) . . .",3. Local Bayesian optimization,[0],[0]
"(xN , yN )} of parameter-evaluation pairs and the goal is to minimize the cumulative regret 1N ∑ i f(x
?)",3. Local Bayesian optimization,[0],[0]
− yi for some global maximizer x? of f .,3. Local Bayesian optimization,[0],[0]
"The cumulative regret emphasizes the inherent cost in evaluating a bad parameter, potentially causing wear and damage to the robot.
",3. Local Bayesian optimization,[0],[0]
"Prior knowledge on an optimum’s location x? is given to the algorithm by a Gaussian distribution π0 = N (µ0, σ20I).",3. Local Bayesian optimization,[0],[0]
In what follows we will indistinctly refer to π as a search distribution or a policy following the terminology of the stochastic search and reinforcement learning (RL) communities.,3. Local Bayesian optimization,[0],[0]
"In an RL context, an informative prior can often be obtained from human generated data or from a simulator.",3. Local Bayesian optimization,[0],[0]
"Specifically, we assume that the mean µ0 of π0 is obtained by imitation learning if near-optimal demonstrations are available or by a preliminary optimization on a less accurate but inexpensive model of the system dy-
namics.",3. Local Bayesian optimization,[0],[0]
"Whereas σ0 is a hyper-parameter of the algorithm, manually set in our experiments, and expressing the confidence in the optimality of µ0.
",3. Local Bayesian optimization,[0],[0]
The search distribution πn is updated by solving the optimization problem formally defined in Sec.,3. Local Bayesian optimization,[0],[0]
3.1.1.,3. Local Bayesian optimization,[0],[0]
"The objective of the optimization problem is to minimize the KL divergence between πn and p(x = x?|Dn), the probability of x? being optimal according to the data set of parameter-evaluation pairs Dn.",3. Local Bayesian optimization,[0],[0]
"Solving this problem results in a Bayesian update, as shown in Alg. 1, where the prior πn(x) on the optimality of x is weighted by the likelihood p(x = x?|Dn) of x being optimal according to Dn.",3. Local Bayesian optimization,[0],[0]
"Letting the likelihood p(x = x?|Dn) be denoted by p?n(x), the first step of the algorithm is to fit p̂n, a Gaussian approximation of p?n (Sec. 3.2).",3. Local Bayesian optimization,[0],[0]
"Subsequently, a dual function is optimized (Sec. 3.1.1) to make sure that the search distribution moves slowly towards p?",3. Local Bayesian optimization,[0],[0]
as new evaluations are collected.,3. Local Bayesian optimization,[0],[0]
Modulating the Bayesian update with the dual parameters η∗ and ω∗ is important sinceDn is initially empty and p?n not initially informative.,3. Local Bayesian optimization,[0],[0]
"Finally, a new evaluations of f is requested by selecting xn from the previously generated samples of p?n and the process is iterated.
",3. Local Bayesian optimization,[0],[0]
The next subsections give a detailed presentation of both the search distribution update and the sampling procedure from p?n.,3. Local Bayesian optimization,[0],[0]
The search distribution in our algorithm is updated such as to minimize the KL divergence between πn and p?n.,3.1. Search distribution update,[0],[0]
"The resulting optimization problem is closely related to the one solved by the MORE algorithm (Abdolmaleki et al., 2015).",3.1. Search distribution update,[0],[0]
"In the next subsections, we will first formalize our search distribution update before briefly describing the search distribution update of MORE and showing how their deriva-
tions can be used to obtain our search distribution update.",3.1. Search distribution update,[0],[0]
The search distribution is updated such that its KL divergence w.r.t. p?n is minimized.,3.1.1. THE OPTIMIZATION PROBLEM,[0],[0]
"Since future evaluations of f will be performed around the updated search distribution, it becomes critical to control the change of distribution between iterations by constraining the aforementioned minimization problem.",3.1.1. THE OPTIMIZATION PROBLEM,[0],[0]
These constraints will ensure that the exploration is not reduced too fast or that the mean is not moved too quickly from the initial solution µ0.,3.1.1. THE OPTIMIZATION PROBLEM,[0],[0]
"The resulting optimization problem is given by
arg min π
KL(π ‖ p?n),
subject to KL(π ‖ πn) ≤ , (1) H(πn)−H(π) ≤",3.1.1. THE OPTIMIZATION PROBLEM,[0],[0]
"β, (2)
where KL(p ‖ q) = ∫ p(x) log p(x)q(x)dx is the KL diver-
gence between p and q andH(p) =",3.1.1. THE OPTIMIZATION PROBLEM,[0],[0]
− ∫ p(x) log(p(x))dx is the entropy of p.,3.1.1. THE OPTIMIZATION PROBLEM,[0],[0]
"The hyper-parameters and β respectively bound the change in distribution and the reduction in entropy between successive iterations.
",3.1.1. THE OPTIMIZATION PROBLEM,[0],[0]
"The use of the KL divergence to constrain the update is widespread in the reinforcement learning community (Peters et al., 2010; Schulman et al., 2015).",3.1.1. THE OPTIMIZATION PROBLEM,[0],[0]
"When the search distributions π and πn are of Gaussian form, the KL divergence in Eq.",3.1.1. THE OPTIMIZATION PROBLEM,[0],[0]
(1) is impacted by three factors.,3.1.1. THE OPTIMIZATION PROBLEM,[0],[0]
"On one side, by the change in entropy between the two distributions— having a direct impact on the exploration rate.",3.1.1. THE OPTIMIZATION PROBLEM,[0],[0]
"On the other side, by the displacement of the mean and the rotation of the covariance matrix—not impacting the exploration rate.",3.1.1. THE OPTIMIZATION PROBLEM,[0],[0]
"To better control the exploration, we choose to decouple
the reduction in entropy from the KL constraint.",3.1.1. THE OPTIMIZATION PROBLEM,[0],[0]
"It was shown in (Abdolmaleki et al., 2015) that the additional entropy constraint can lead to significantly better solutions at the expense of a slower start.
",3.1.1. THE OPTIMIZATION PROBLEM,[0],[0]
The optimization problem defined in this section is closely related to the one solved by MORE.,3.1.1. THE OPTIMIZATION PROBLEM,[0],[0]
"In fact, when the inequality (2) is replaced by the equality constraintH(πn)− H(π) = β for both algorithms then the two problems coincide; while only a small modification of the dual function is necessary otherwise.",3.1.1. THE OPTIMIZATION PROBLEM,[0],[0]
"For the sake of clarity and to keep the paper self-contained, we will briefly introduce MORE before showing how we can reuse their derivation of the search distribution update in our algorithm.",3.1.1. THE OPTIMIZATION PROBLEM,[0],[0]
"MORE (Abdolmaleki et al., 2015) is a local stochastic search algorithm where the search distribution πn(x) is updated by solving the following constrained problem
arg max π
∫ π(x)f(x)dx
subject to KL(π ‖ πn) ≤ , (3) H(πn)−H(π) ≤",3.1.2. MODEL-BASED RELATIVE ENTROPY SEARCH,[0],[0]
"β, (4)
",3.1.2. MODEL-BASED RELATIVE ENTROPY SEARCH,[0],[0]
"An analytic solution of the problem is obtained by locally approximating f with the quadratic model
Rn(x) =",3.1.2. MODEL-BASED RELATIVE ENTROPY SEARCH,[0],[0]
"− 1
2 xTRnx+ x Trn + rn,
learned by linear regression from the data set Dn.",3.1.2. MODEL-BASED RELATIVE ENTROPY SEARCH,[0],[0]
"Letting the search distribution πn(x) = N (x|µn,Σn) at iteration n be parameterized by the mean µn and covariance matrix Σn, the aforementioned optimization problem yields the closed form update where the new mean and covariance are given by
Σ−1n+1 = (η ?",3.1.2. MODEL-BASED RELATIVE ENTROPY SEARCH,[0],[0]
"+ ω?)−1 ( η?Σ−1n +Rn ) , (5) µn+1",3.1.2. MODEL-BASED RELATIVE ENTROPY SEARCH,[0],[0]
= (η ? + ω?)−1Σn+1,3.1.2. MODEL-BASED RELATIVE ENTROPY SEARCH,[0],[0]
"( η?Σ−1n µn + rn ) , (6)
where η? and ω?",3.1.2. MODEL-BASED RELATIVE ENTROPY SEARCH,[0],[0]
"are the Lagrange multipliers of the constraints (3) and (4) respectively, and are obtained by minimizing the dual function gn(η, ω) by gradient descent (Abdolmaleki et al., 2015).
",3.1.2. MODEL-BASED RELATIVE ENTROPY SEARCH,[0],[0]
"As can be seen in Eq. 5, the new covariance matrix is a trade-off between the old covariance and the local curvature of the objective function f—where the trade-off parameters are computed in order to satisfy both constraints of the optimization problem.",3.1.2. MODEL-BASED RELATIVE ENTROPY SEARCH,[0],[0]
"As such, it is appropriate to use the covariance matrix of the search distribution in the kernel function for the local approximation of f when using GP regression.
",3.1.2. MODEL-BASED RELATIVE ENTROPY SEARCH,[0],[0]
"We additionally define MORE with equality constraint as a variant of MORE where the inequality constraint in (4)
is replaced with the equality constraint H(πn) − H(π) = β, forcing the reduction in entropy at each iteration to be exactly β.",3.1.2. MODEL-BASED RELATIVE ENTROPY SEARCH,[0],[0]
"This modification will not change the shape of the update but only the Lagrange multipliers, that can be obtained by simply alleviating the constraint ω",3.1.2. MODEL-BASED RELATIVE ENTROPY SEARCH,[0],[0]
≥ 0,3.1.2. MODEL-BASED RELATIVE ENTROPY SEARCH,[0],[0]
"in the minimization of gn(η, ω).",3.1.2. MODEL-BASED RELATIVE ENTROPY SEARCH,[0],[0]
We now show that the optimization problem in our algorithm can be phrased as the optimization problem solved by MORE for the equality entropy constraint; while only a small modification of the dual minimization is required for the inequality entropy constraint.,3.1.3. OPTIMIZATION PROBLEMS’ EQUIVALENCE,[0],[0]
"The equivalence of the optimization problems will allow us to use Eq. 5 and 6 to update our search distribution.
",3.1.3. OPTIMIZATION PROBLEMS’ EQUIVALENCE,[0],[0]
Proposition 1.,3.1.3. OPTIMIZATION PROBLEMS’ EQUIVALENCE,[0],[0]
The optimization problem in Sec.,3.1.3. OPTIMIZATION PROBLEMS’ EQUIVALENCE,[0],[0]
"3.1.1 can be reduced to the optimization problem in 3.1.2 for the objective function f = log p?n when both problems enforce an exact entropy reduction constraint on π.
",3.1.3. OPTIMIZATION PROBLEMS’ EQUIVALENCE,[0],[0]
Proof.,3.1.3. OPTIMIZATION PROBLEMS’ EQUIVALENCE,[0],[0]
We first rephrase the problem in Sec.,3.1.3. OPTIMIZATION PROBLEMS’ EQUIVALENCE,[0],[0]
"3.1.1 as the maximization over π of
−KL(π ‖ p?n)",3.1.3. OPTIMIZATION PROBLEMS’ EQUIVALENCE,[0],[0]
"+ β −H(πn),
where we switched the sign of the KL divergence term and added the constant term β − H(πn).",3.1.3. OPTIMIZATION PROBLEMS’ EQUIVALENCE,[0],[0]
These modifications will not change the value of the stationary points of the Lagrangian.,3.1.3. OPTIMIZATION PROBLEMS’ EQUIVALENCE,[0],[0]
"The resulting Lagrangian is
L(π, η, ω) = ∫",3.1.3. OPTIMIZATION PROBLEMS’ EQUIVALENCE,[0],[0]
"π(x) log p?n(x)dx+η( −KL(π ‖ πn))
+ (ω + 1)(H(π)−H(πn) + β),
with dual variables η ≥ 0 and ω ∈ R and where we have split the term KL(π ‖ p?n) into the expected log-density of p?n and the entropy H(π) of π.",3.1.3. OPTIMIZATION PROBLEMS’ EQUIVALENCE,[0],[0]
"A MORE formulation with similar entropy and KL divergence constraints and where the objective is to maximize the log-density log p?n yields the Lagrangian
L′(π, η, ω) = ∫",3.1.3. OPTIMIZATION PROBLEMS’ EQUIVALENCE,[0],[0]
"π(x) log p?n(x)dx+η( −KL(π ‖ πn))
+ ω(H(π)−H(πn) + β).
",3.1.3. OPTIMIZATION PROBLEMS’ EQUIVALENCE,[0],[0]
"Since we have no constraint on ω, it is easy to see that the dual variable minimizing the dual of the first problem ω?",3.1.3. OPTIMIZATION PROBLEMS’ EQUIVALENCE,[0],[0]
and of the second (MORE) problem ω′∗ are related by ω? = ω′∗,3.1.3. OPTIMIZATION PROBLEMS’ EQUIVALENCE,[0],[0]
"− 1 and both problems will result in the same update of π.
",3.1.3. OPTIMIZATION PROBLEMS’ EQUIVALENCE,[0],[0]
"Intuitively, the minimization of KL(π ‖ p?n) can be reduced to the maximization (in expectation of π) of the log-density
log p?n because the equality constraintH(π) =",3.1.3. OPTIMIZATION PROBLEMS’ EQUIVALENCE,[0],[0]
"H(πn)− β annihilates the effect of the additional entropy term H(π) coming from the KL objective.
",3.1.3. OPTIMIZATION PROBLEMS’ EQUIVALENCE,[0],[0]
"From Proposition 1 and following the derivations in (Abdolmaleki et al., 2015), the search distribution πn+1 solution of the optimization problem in Sec.",3.1.3. OPTIMIZATION PROBLEMS’ EQUIVALENCE,[0],[0]
"3.1.1 is given by
πn+1 ∝",3.1.3. OPTIMIZATION PROBLEMS’ EQUIVALENCE,[0],[0]
(πn) η? η?+ω?,3.1.3. OPTIMIZATION PROBLEMS’ EQUIVALENCE,[0],[0]
(p?n) 1 η?+ω?,3.1.3. OPTIMIZATION PROBLEMS’ EQUIVALENCE,[0],[0]
", (7)
where η? and ω?",3.1.3. OPTIMIZATION PROBLEMS’ EQUIVALENCE,[0],[0]
"are the Lagrange multipliers related to the KL and entropy constraints respectively and minimizing the dual function gn(η, ω).",3.1.3. OPTIMIZATION PROBLEMS’ EQUIVALENCE,[0],[0]
"We refer the reader to Sec. 2.1 in (Abdolmaleki et al., 2015) for the definition of gn(η, ω).
",3.1.3. OPTIMIZATION PROBLEMS’ EQUIVALENCE,[0],[0]
"When the entropy constraint is the inequality in (2) instead of an equality, the Lagrange multipliers for our update and the MORE update may differ.",3.1.3. OPTIMIZATION PROBLEMS’ EQUIVALENCE,[0],[0]
"However, η? and ω? can still be obtained by the minimization of the same gn(η, ω) with the additional constraint ω ≥ 1.
",3.1.3. OPTIMIZATION PROBLEMS’ EQUIVALENCE,[0],[0]
Note that the new search distribution πn+1 as defined in Eq.,3.1.3. OPTIMIZATION PROBLEMS’ EQUIVALENCE,[0],[0]
(7) is not necessarily Gaussian because of the multiplication by p?n.,3.1.3. OPTIMIZATION PROBLEMS’ EQUIVALENCE,[0],[0]
"However, by approximating p ? n",3.1.3. OPTIMIZATION PROBLEMS’ EQUIVALENCE,[0],[0]
"by a Gaussian distribution p̂n, log p̂n will be a quadratic model and Eq. 5 and 6 can be used to obtain a Gaussian πn+1.",3.1.3. OPTIMIZATION PROBLEMS’ EQUIVALENCE,[0],[0]
To obtain a closed form update of the Gaussian search distribution in Eq.,3.2. Approximating the argmax distribution,[0],[0]
"(7), we will approximate p?n by fitting a Gaussian p̂n to samples of p?n as shown in Fig. 1e.",3.2. Approximating the argmax distribution,[0],[0]
"To generate samples from p?n, we use Thompson sampling (Chapelle & Li, 2011; Russo & Roy, 2014) from a probabilistic model of the objective function f .
",3.2. Approximating the argmax distribution,[0],[0]
The probabilistic model of f follows from both a Gaussian process (GP) prior and a Gaussian likelihood assumption.,3.2. Approximating the argmax distribution,[0],[0]
"We use in this paper the squared exponential kernel kn(xi,xj) = θ0 exp(−θ1(xi −",3.2. Approximating the argmax distribution,[0],[0]
xj)TΣ−1n (xi − xj)) with hyper-parameters θ0 and θ1 and Σn the covariance matrix of πn.,3.2. Approximating the argmax distribution,[0],[0]
"The resulting model has hyper-parameter vector φ = (θ0, θ1, σs), where σ2s is the noise variance of the likelihood function as previously defined.",3.2. Approximating the argmax distribution,[0],[0]
"Samples from p?n are generated by i) sampling a hyper-parameter vector φ from the posterior distribution p(φ|Dn) using slice sampling (Murray & Adams, 2010), ii) sampling a function from the GP posterior p(f̃ |Dn,φ) and iii) returning the argmax of f̃ .
",3.2. Approximating the argmax distribution,[0],[0]
The computational complexity of evaluating f̃ is cubical in the number of requested evaluations as it involves a matrix inversion.,3.2. Approximating the argmax distribution,[0],[0]
"As such, the exact maximization of f̃ can prove to be challenging.",3.2. Approximating the argmax distribution,[0],[0]
"Prior work in the literature considered approximating f̃ with a linear function (see for example Hernández-Lobato et al. (2014), Sec. 2.1) and globally
maximizing the linear surrogate.",3.2. Approximating the argmax distribution,[0],[0]
"In our local optimization context, we follow a more straightforward approach by generating samples from πn, and returning the sample with maximal value of f̃ .",3.2. Approximating the argmax distribution,[0],[0]
The rational behind searching the argmax of f̃ in the vicinity of πn is that samples from πn are likely to have high f̃ value since πn is updated such that the KL divergence w.r.t. p?n is minimized.,3.2. Approximating the argmax distribution,[0],[0]
"The repeated process of drawing points from πn, drawing their value from the GP posterior and selecting the point with highest value will constitute a data set D?n containing local samples from p?n.
",3.2. Approximating the argmax distribution,[0],[0]
"Once samples from p?n are generated and stored in D?n, we set p̂n = N (µ?n,Σ?n) where µ?n and Σ?n are the sample mean and covariance of the samples in D?n.",3.2. Approximating the argmax distribution,[0],[0]
"Because p̂n is Gaussian, log p̂n is quadratic and the search distribution update in Eq.",3.2. Approximating the argmax distribution,[0],[0]
(7) yields a Gaussian distribution πn+1 with covariance and mean as defined in Eq.,3.2. Approximating the argmax distribution,[0],[0]
(5) and Eq. (6) respectively withRn = Σ?n −1,3.2. Approximating the argmax distribution,[0],[0]
and rn = Σ?n −1µ?n.,3.2. Approximating the argmax distribution,[0],[0]
The function f is initially evaluated at a point x0 drawn from the prior distribution π0.,3.3. Sample generation,[0],[0]
"In subsequent iterations, a point xn is randomly selected from D?n, the set of samples used in the computation of p̂n (Sec. 3.2).
",3.3. Sample generation,[0],[0]
"Experimentally, we noticed that the exploration in our algorithm is heavily influenced by the centering of the values {yi}n1 in Dn.",3.3. Sample generation,[0],[0]
Three variants of our algorithm are initially evaluated with different target values of the GP.,3.3. Sample generation,[0],[0]
The target values are obtained by subtracting from yi either the max the min or the mean of {yi}n1 .,3.3. Sample generation,[0],[0]
"Since the GP modeling of f has a zero mean prior, the extreme case where the max (resp.",3.3. Sample generation,[0],[0]
the min) is subtracted from the data results in an optimistic (resp. pessimistic) exploration strategy considering that the objective function in unexplored areas have values higher (resp. lower) in expectation than the best (resp. worst) evaluation so far.,3.3. Sample generation,[0],[0]
We initially investigate in this section the impact of the target centering (Sec. 3.3) on the exploration-exploitation trade-off of our algorithm.,4. Experiments,[0],[0]
"We then compare our algorithm to two state-of-the-art model based optimizers: the global Bayesian optimizer and the local Model-Based Relative Entropy Search (Abdolmaleki et al., 2015).",4. Experiments,[0],[0]
"The algorithms are compared on several continuous function benchmarks as well as a simulated robotics task.
Benchmarks.",4. Experiments,[0],[0]
Variants of our algorithm are first compared on randomly generated smooth 2 dimensional objective functions.,4. Experiments,[0],[0]
"We then conduct a comparison to the state-ofthe-art on the COmparing COntinuous optimisers (COCO)
testbed on the 20 functions f5 to f24 (we refer the reader to http://coco.gforge.inria.fr/ for an illustration and the mathematical definition of each function).",4. Experiments,[0],[0]
We chose to split the experimentation between the uni-modal and the multi-modal categories of the testbed.,4. Experiments,[0],[0]
The unimodal category is representative of the informed initialization hypothesis that only requires local improvements.,4. Experiments,[0],[0]
While the multi-modal category assesses the robustness of our algorithm to more complex function landscapes— which can be encountered in practice despite the informed initialization if e.g. a too wide variance σ20 is initially set.,4. Experiments,[0],[0]
"We vary the dimension of the COCO functions from 3 to 30 while the robotics task evaluates our algorithm on a 70 dimensional setting.
",4. Experiments,[0],[0]
Algorithms.,4. Experiments,[0],[0]
"In what follows, we will refer to our algorithm as L-BayesOpt.",4. Experiments,[0],[0]
"We rely on the GPStuff library (Vanhatalo et al., 2013) for the GP implementation and the posterior sampling of hyper-parameters.",4. Experiments,[0],[0]
"We use the BayesOpt library (Martinez-Cantin, 2014) for global Bayesian optimization with a similar to L-BayesOpt squared exponential kernel and MCMC sampling of hyper-parameters and an additional Automatic Relevance Determination step executed every 50 samples.",4. Experiments,[0],[0]
"In the experiments we evaluate BayesOpt with both Expected Improvement and Thompson Sampling acquisition functions.
",4. Experiments,[0],[0]
"In all of the experiments, L-BayesOpt and MORE will share the same initial policy, step-size , entropy reduction β and will sample ten points per iteration.",4. Experiments,[0],[0]
We choose to use an equality constraint for the entropy reduction for both algorithms.,4. Experiments,[0],[0]
"As a result, both L-BayesOpt and MORE will have the same entropy at every iteration and any difference in performance will be attributed to a better location of the mean, adaptation of the covariance matrix or sampling procedure rather than a faster reduction in exploration.",4. Experiments,[0],[0]
"In all but the last experiment = β = .05 while for the robotics experiment with an initial solution learned by imitation learning we set a more aggressive step size and entropy reduction = β = 1.
Evaluation criterion.",4. Experiments,[0],[0]
The performance metric in RL is typically given by the average return J(πn) =∫ πn(x)f(x)dx while in Bayesian optimization it is typically determined by the minimal evaluation min1≤i≤n yi reached at iteration n. When the evaluations are noisy the minimum evaluation is not a robust performance metric— nor an appropriate criterion for the algorithm to select the returned optimizer.,4. Experiments,[0],[0]
"In order to have a common evaluation criterion, all the approaches are seen as multi-armed bandit algorithms and we use the cumulative regret 1n ∑ i f(x
?)",4. Experiments,[0],[0]
− yi as the evaluation criterion.,4. Experiments,[0],[0]
The cumulative regret of (global),4. Experiments,[0],[0]
"Bayesian optimizers is expected to be asymptotically lower than that of local optimizers as it always finds the global maximum given sufficiently many evaluations.
",4. Experiments,[0],[0]
"Conversely, trading-off global optimality for fast local improvements might result in a lower regret for local optimizers when the evaluation budget is moderate.",4. Experiments,[0],[0]
"In this first set of experiments, we evaluate the different exploration strategies resulting from three different centering methods of the y values in Dn.",4.1. Exploration variants,[0],[0]
We compare these three variants of L-BayesOpt on 11 randomly generated two dimensional Gaussian mixture objective functions (see Fig.,4.1. Exploration variants,[0],[0]
2a for an illustration).,4.1. Exploration variants,[0],[0]
"We chose these functions as they are cheap to evaluate, easy to approximate by a GP and their multi-modal nature is appropriate for evaluating the exploration-exploitation trade-off of the three variants.
",4.1. Exploration variants,[0],[0]
"As hypothesized in Sec. 3.3, the cumulative regret in Fig.",4.1. Exploration variants,[0],[0]
2b shows that the min variant exhibits the lowest exploration and reduces the regret faster than the other optimizers.,4.1. Exploration variants,[0],[0]
"Yet, when compared to MORE it manages to converge to better local optima in 5 out of the 11 randomly generated objectives while MORE converges to a better optimum in one of the 6 remaining objectives.",4.1. Exploration variants,[0],[0]
Note that MORE manages to decrease the regret faster than our algorithm during the first 100 evaluations.,4.1. Exploration variants,[0],[0]
"However, the sampling scheme relying on the Thompson sampling acquisition function and the convergence to higher modes gives the advantage to the L-BayesOpt variants after the initial 100 evaluations.",4.1. Exploration variants,[0],[0]
In the remainder of the experimental section only the min variant of our algorithm will be considered.,4.1. Exploration variants,[0],[0]
We compare our algorithm to MORE and Bayesian optimization on the COCO testbed.,4.2. State-of-the-art benchmark comparisons,[0],[0]
We form two sets each containing 10 objective functions.,4.2. State-of-the-art benchmark comparisons,[0],[0]
The first one includes unimodal functions (f5 to f14) while the second one includes multi-modal function with an adequate (f15 to f19) and a weak (f20 to f24) global structure.,4.2. State-of-the-art benchmark comparisons,[0],[0]
"Each function has a global optimum in [−5, 5]D, where D is the dimension of the objective function that we vary in the set {3, 10, 30}.
",4.2. State-of-the-art benchmark comparisons,[0],[0]
"The bounding box [−5, 5]D is provided to Bayesian optimization while for the local stochastic search algorithms we set the initial distribution to π0 = N (0, 3I).",4.2. State-of-the-art benchmark comparisons,[0],[0]
"Note that this is not an informed initialization and none of the functions had their optimum on the null vector.
",4.2. State-of-the-art benchmark comparisons,[0],[0]
Fig. 3 shows the performance of the four algorithms on the multi-modal (top row) and uni-modal (bottom row) function sets.,4.2. State-of-the-art benchmark comparisons,[0],[0]
"On the multi-modal set of functions and when D = 3, Bayesian optimization with Thompson sampling proves to be an extremely efficient bandit algorithm for uncovering the highest reward point with a minimal number of evaluations.",4.2. State-of-the-art benchmark comparisons,[0],[0]
"On the contrary, both local stochastic search algorithms struggle to improve over the initial performance.",4.2. State-of-the-art benchmark comparisons,[0],[0]
"Upon closer inspection, this appears to be especially true for functions with weak global structure such as f23.",4.2. State-of-the-art benchmark comparisons,[0],[0]
"We hypothesize that for these highly multi-modal functions, both model based stochastic search algorithms learn poor quadratic models (when either approximating f or p?n).",4.2. State-of-the-art benchmark comparisons,[0],[0]
"The performance gap between Bayesian optimization and our algorithm reduces however as the dimensionality of the problem increases.
",4.2. State-of-the-art benchmark comparisons,[0],[0]
"On the uni-modal functions set, our algorithm reduces significantly faster the regret than Bayesian optimization.",4.2. State-of-the-art benchmark comparisons,[0],[0]
"As
the dimension of the objective function increases from D = 10 to D = 30, more evaluations are required by Bayesian optimization to reach our algorithm.",4.2. State-of-the-art benchmark comparisons,[0],[0]
"Compared to MORE, and since the objectives are uni-modal, the use of an acquisition function is the main driving factor for the faster decrease of the regret.",4.2. State-of-the-art benchmark comparisons,[0],[0]
"Note that even if the functions are uni-modal, both local search algorithms are not necessarily zero if the decrease in entropy is too fast.
",4.2. State-of-the-art benchmark comparisons,[0],[0]
Both L-BayesOpt and BayesOpt/TS rely on the Thompson sampling acquisition function for selecting the next point to evaluate.,4.2. State-of-the-art benchmark comparisons,[0],[0]
"While the acquisition function is maximized on the full support of the objective in the case of Bayesian optimization, it is only optimized in the vicinity of the current search distribution by our algorithm.",4.2. State-of-the-art benchmark comparisons,[0],[0]
"The experiments on the COCO testbed show that when the function landscape enables the learning of an appropriate update direction for moving the search distribution, the adaptive strategy employed by our algorithm can be more efficient than the global search performed by Bayesian optimization.",4.2. State-of-the-art benchmark comparisons,[0],[0]
The task’s objective is for the Barrett robot arm to swing the ball upward and place it in the cup (Fig. 4a).,4.3. Robot ball in the cup,[0],[0]
"The
optimization is performed on the 70 weights of the forcing function of a Dynamical Movement Primitive (DMP, Ijspeert & Schaal 2003) controlling the 7 joints of the robot.",4.3. Robot ball in the cup,[0],[0]
The initial forcing function weights µ0 are learned by linear regression from a single demonstrated trajectory that successfully swings the ball up but where the ball lands at circa 20cm from the cup.,4.3. Robot ball in the cup,[0],[0]
"We compare the performance of MORE and L-BayesOpt in optimizing the initial policy π0 = N (µ0, I) using the same hyper-parameters.",4.3. Robot ball in the cup,[0],[0]
"The challenge of the task, in addition to the dimension of the action space, stems from the two exploration regimes required by the exploration scheme.",4.3. Robot ball in the cup,[0],[0]
"While initially a significant amount of noise needs to be introduced to the parameters to get the ball closer to the cup; successfully getting the ball in the cup requires a more careful tuning of the forcing function.
",4.3. Robot ball in the cup,[0],[0]
Fig.,4.3. Robot ball in the cup,[0],[0]
4b shows the performance of both MORE and LBayesOpt on the robot ball in a cup task.,4.3. Robot ball in the cup,[0],[0]
MORE has a better initial sample efficiency and gets the ball closer to the cup at a faster pace than L-BayesOpt.,4.3. Robot ball in the cup,[0],[0]
"However, the acquisition function based sampling scheme of our algorithm was more efficient for discovering parameters that successfully put the ball in the cup and results in a lower regret (averaged over 5 runs) after 1000 evaluations.",4.3. Robot ball in the cup,[0],[0]
"The experiment shows that for such high dimensional tasks, our algorithm was better at tuning the policy only when the entropy of the search distribution was significantly reduced.",4.3. Robot ball in the cup,[0],[0]
This might be due to the low correlation between Euclidean distance between parameters and difference in reward.,4.3. Robot ball in the cup,[0],[0]
"One promising direction for future work in a reinforcement learning context is to use kernels based on trajectory data distance instead of parameter distance in euclidian space (Wilson et al., 2014).",4.3. Robot ball in the cup,[0],[0]
"The algorithm presented in this paper can be seen as Bayesian optimization where the usual box constraint is rotated, shrunk and moved at each iteration towards the most
promising region of the objective function.",5. Discussion,[0],[0]
The constant reduction of the entropy of the search distribution ensures that the objective function is not modeled and optimized on the entirety of its domain.,5. Discussion,[0],[0]
"Compared to (global) Bayesian optimization, we experimentally demonstrated on several continuous optimization benchmarks that it results in faster improvements over the initial solution, at the expense of global optimality.",5. Discussion,[0],[0]
"This property is especially useful when an initial informative solution is available and only requires to be locally improved.
",5. Discussion,[0],[0]
The computational cost of the search distribution update in our algorithm is significantly higher than most local stochastic search algorithms.,5. Discussion,[0],[0]
This cost mainly arises from the full Bayesian treatment of the modeling of the objective function f .,5. Discussion,[0],[0]
"If the evaluation of f is cheap, a better performance per second is obtained by less expensive stochastic search algorithms where the additional computational budget can be spent in running additional randomized restarts of the algorithms (Auger & Hansen, 2005).",5. Discussion,[0],[0]
"However, if the optimization cost is dominated by the evaluation of f , the probabilistic modeling proved to be more sample efficient on several benchmarks by actively selecting the next point to evaluate.",5. Discussion,[0],[0]
"As a result, when f is expensive to evaluate our algorithm is expected to have better per second performance than state-of-the-art stochastic search algorithms.
",5. Discussion,[0],[0]
The search distribution update proposed in this paper is well founded and results in an interpretable update.,5. Discussion,[0],[0]
"At each iteration the current search distribution is simply weighted by p(x = x?|Dn), the probability of x being optimal according to the current data set.",5. Discussion,[0],[0]
Future work can further improve the sample efficiency of our algorithm in at least three ways.,5. Discussion,[0],[0]
"First, if the objective function is upper bounded and the bound is known, we expect that the integration of an additional constraint f(x) < f(x∗) for all x to lead to a more accurate probabilistic modeling and a better exploration-exploitation trade-off.",5. Discussion,[0],[0]
"Secondly, the search distribution update is phrased as the minimization of the I-projection of p(x = x?|Dn), which has the property of focusing on one mode of the distribution (Bishop, 2006).",5. Discussion,[0],[0]
"However, the Gaussian approximation of p(x = x?|Dn) can average over multiple modes if the GP is unsure about which of them is the highest.",5. Discussion,[0],[0]
We expected that a better update direction can be obtained if a clustering algorithm can detect the highest mode from samples of p(x = x?|Dn).,5. Discussion,[0],[0]
"Finally and perharps most interestingly, we expect our algorithm to be able to scale to significantly higher dimensional policies in an RL setting if a trajectory data kernel is used (Wilson et al., 2014).",5. Discussion,[0],[0]
"Specifically, distance between policies can be measured by the similarity of actions taken in similar states.",5. Discussion,[0],[0]
The local nature of our algorithm will additionally ensure that such similarity is evaluated on states that are likely to be reached by the evaluated policies.,5. Discussion,[0],[0]
The research leading to these results was funded by the DFG Project LearnRobotS under the SPP 1527 Autonomous Learning.,Acknowledgments,[0],[0]
Bayesian optimization is renowned for its sample efficiency but its application to higher dimensional tasks is impeded by its focus on global optimization.,abstractText,[0],[0]
"To scale to higher dimensional problems, we leverage the sample efficiency of Bayesian optimization in a local context.",abstractText,[0],[0]
The optimization of the acquisition function is restricted to the vicinity of a Gaussian search distribution which is moved towards high value areas of the objective.,abstractText,[0],[0]
The proposed informationtheoretic update of the search distribution results in a Bayesian interpretation of local stochastic search: the search distribution encodes prior knowledge on the optimum’s location and is weighted at each iteration by the likelihood of this location’s optimality.,abstractText,[0],[0]
We demonstrate the effectiveness of our algorithm on several benchmark objective functions as well as a continuous robotic task in which an informative prior is obtained by imitation learning.,abstractText,[0],[0]
Local Bayesian Optimization of Motor Skills,title,[0],[0]
"In this work, we study a basic question that arises in the study of high dimensional vector representations: given a dataset D of vectors and a query q, estimate the number of points within a specified distance threshold of q. Such density estimates are important building blocks in non-parametric clustering, determining the popularity of topics, search and recommendation systems, the analysis of the neighborhoods of nodes in social networks, and in outlier detection, where geometric representations of data are frequently used.",1. Introduction,[0],[0]
"Yet for high dimensional datasets, we still lack simple, practical, experimentally verified and theoretically justified solutions to tackle this question.
",1. Introduction,[0],[0]
Our questions have been studied in the context of spherical range counting.,1. Introduction,[0],[0]
"One class of solution methods arising in the computational geometry literature, such as hierarchical splitting via trees, (Arya et al., 2010) have performance guarantees that depend exponentially on dimension.",1. Introduction,[0],[0]
"These are unsuitable for the higher dimensional models that ma-
1Stanford University, USA 2Laserlike Inc, USA.",1. Introduction,[0],[0]
"Correspondence to: Xian Wu <xwu20@stanford.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"chine learning methods are increasingly shifting towards e.g. word embeddings (Pennington et al., 2014; Mikolov et al., 2013) and graph embeddings (Perozzi et al., 2014; Tang et al., 2015; Cao et al., 2015; Grover & Leskovec, 2016; Yang et al., 2016; Wang et al., 2017; Hamilton et al., 2017).",1. Introduction,[0],[0]
"Over-parameterized models are oftentimes easier to train (Livni et al., 2014), and perform just as well, if not better (Zhang et al., 2016).",1. Introduction,[0],[0]
"Word embeddings is one example where rigorous evaluation has shown increased performance with higher dimensionality (Melamud et al., 2016) (Lai et al., 2016).
",1. Introduction,[0],[0]
"In this paper, we develop an estimation scheme for high dimensional datasets to count the number of elements around a query that are in a given radius of cosine similarity.",1. Introduction,[0],[0]
"Angular distance, which corresponds to Euclidean distance for data points on the unit sphere is commonly used in applications related to word and document embeddings, and image and video search (Jegou et al., 2011)",1. Introduction,[0],[0]
"(Huang et al., 2012).",1. Introduction,[0],[0]
"Brute force search requires a linear scan over the entire dataset, which is prohibitively expensive.",1. Introduction,[0],[0]
"Our approach uses indexing and search via locality sensitive hashing (LSH) functions in order to estimate the size of the neighborhood in a more efficient manner than retrieving the neighbors within the given radius of similarity.
",1. Introduction,[0],[0]
Recent work has also explored LSH techniques for spherical range counting and related questions around density estimation for high-dimensional models.,1. Introduction,[0],[0]
"For example (Aumüller et al., 2017) generalizes nearest neighbor LSH hash functions to be sensitive to custom distance ranges.",1. Introduction,[0],[0]
"(Ahle et al., 2017) builds many different parameterized versions of the prototypical LSH hash tables and adaptively probes them for spherical range reporting.",1. Introduction,[0],[0]
"The closest works to ours in terms of solution method that we are aware of is that of (Spring & Shrivastava, 2017), giving an LSH based estimator to compute the partition function of a log-linear model, and (Charikar & Siminelakis, 2017), adapting LSH to solve a class of kernel density estimation problems.",1. Introduction,[0],[0]
"Both works produce an unbiased estimator, using LSH to implement a biased sampling scheme that lowers the variance of this estimator.",1. Introduction,[0],[0]
"However their technique leverages only one hash bucket per table, and hence requires a large number of tables for an accurate estimate.",1. Introduction,[0],[0]
"The biggest drawback to these works is the very high storage (hash tables) and query complexities – their techniques, as presented, are impractical for
adoption.
",1. Introduction,[0],[0]
Our approach improves upon the storage and sample complexities of previous methods using a combination of extracting information from multiple buckets per table (hence reducing table complexity) and importance sampling (hence reducing sample complexity).,1. Introduction,[0],[0]
"As we show in our experimental study on GLOVE embeddings, our estimate of the number of elements that are 60 degrees from a query q (which corresponds to synonyms and/or related words to q in the English vocabulary), achieves multiple orders of magnitude improved accuracy over competing methods, subject to reasonable and practical resource constraints.",1. Introduction,[0],[0]
Our theoretical analysis develops a rigorous understanding of our technique and offers practitioners further insight on optimizing our solution method for their particular datasets.,1. Introduction,[0],[0]
"Given a dataset D of vectors v1, . . .",2. Problem Formulation and Approach,[0],[0]
"vn ∈ Rd on the unit sphere, a query q ∈ Rd also on the unit sphere, and a range of angles of interestA, for example 0-60 degrees, how many elements v in D are such that the angle between q and v, denoted θqv, are within range A?",2. Problem Formulation and Approach,[0],[0]
We use Aq to denote the set of data vectors v that are within angle A to q (that have angular distance to query q that is in the range of interest A).,2. Problem Formulation and Approach,[0],[0]
"Our goal is to preprocess D in order to estimate the cardinality of this set, denoted |Aq|, efficiently for any given q.
One final note is that our scheme is conceptualized using bit-wise LSH functions; functions that hash vectors to 0-1 bits, and where the hamming distance between the hash sequences of two data points captures information about their angular distance.",2. Problem Formulation and Approach,[0],[0]
"For their simplicity, easy implementation, and high performance in practice, bit hashes such as hyperplane LSH (Charikar, 2002) are the standard hash functions used in practice for angular distance (Andoni et al., 2015).",2. Problem Formulation and Approach,[0],[0]
"Our technique and results can be extended for other hash functions; however, we will use hamming distance and other implementation details specific to bit-wise LSH functions in this work.",2. Problem Formulation and Approach,[0],[0]
Our overall estimation scheme is an implementation of importance sampling.,2.1. Approach Overview,[0],[0]
"It consists of two steps, a preprocessing step that applies locality sensitive hash functions to our dataset to produce hash tables.",2.1. Approach Overview,[0],[0]
"After this preprocessing step, we sample from our hash tables to produce our final estimate.
",2.1. Approach Overview,[0],[0]
"To help guide the reader through the technical details of our implementation, we first offer an intuitive explanation of our approach.",2.1. Approach Overview,[0],[0]
"Our importance sampling scheme achieves 2 main objectives: we concentrate the elements of interest
in our overall dataset into a few buckets that we can easily sample from, and we sample from these buckets to produce our estimate.",2.1. Approach Overview,[0],[0]
"In order to compensate for the concentrated sampling, we adjust the value of each sample by the inverse of the probability that the sample lands in the target buckets.
",2.1. Approach Overview,[0],[0]
Our technique relies on the key insight that LSH functions can effectively implement both of these objectives.,2.1. Approach Overview,[0],[0]
"Using LSH functions to index our dataset ensures that for a given query q, elements that are close to q in angular distance have a comparative higher probability of hashing to q’s bucket and to buckets that are of small hamming distance to q’s bucket, thereby concentrating the elements of interest into certain buckets that we can selectively sample from.
",2.1. Approach Overview,[0],[0]
"Additionally, the hamming distance collision probabilities for bit-wise LSH functions are well expressed in terms of angular distance.",2.1. Approach Overview,[0],[0]
"Consider random hyperplane LSH (Charikar, 2002), where each hash vector is chosen uniformly at random from the d-dimensional unit sphere.",2.1. Approach Overview,[0],[0]
"Each hash vector r contributes one bit to the hash sequence of a data point v, based on the rule:
hr(v) =",2.1. Approach Overview,[0],[0]
"{ 0 if r · v ≤ 0 1 otherwise.
",2.1. Approach Overview,[0],[0]
"It is well-known that for any particular hamming distance i, and any data point x,
P(dqx = i|θqx) =",2.1. Approach Overview,[0],[0]
"( t
i
)( 1− θqx
π )t−i( θqx π )i where dqx is the hamming distance between the hash for query q and the hash for data vector x, θqx denotes the angle between the 2 vectors, and t is the total number of bits in the hash sequence.
",2.1. Approach Overview,[0],[0]
"Thus, the choice of t affects the sensitivity of the LSH scheme – the correlation between the hamming distances of two hash sequences and the angle between the two underlying data points.",2.1. Approach Overview,[0],[0]
"Moreover, depending on the design choice for t, the set of hamming distances I that contains most of the probability mass for collision with elements of angular distance in range",2.1. Approach Overview,[0],[0]
A is different.,2.1. Approach Overview,[0],[0]
This is also a consideration in our sampling scheme; we want to sample from buckets of hamming distances,2.1. Approach Overview,[0],[0]
"I that have a high probability of containing elements that are within angle A of q.
",2.1. Approach Overview,[0],[0]
"Our sampling scheme picks elements over K hash tables from buckets that are at hamming distance I to the query, where I is tuned to A.",2.1. Approach Overview,[0],[0]
"Given a sample, x, we compute the angular distance θqx = cos−1(q · x).",2.1. Approach Overview,[0],[0]
"Let p(x) = P(dqx ∈ I|θqx), the collision probability that x lands in a bucket that is hamming distance I from q over the random choice of hash functions.
",2.1. Approach Overview,[0],[0]
"We define a random variable Z as a function of sample x as follows:
Z =
{∑K k=1 C k q",2.1. Approach Overview,[0],[0]
"(I)
K·p(x)",2.1. Approach Overview,[0],[0]
if θqx ∈,2.1. Approach Overview,[0],[0]
"A 0 otherwise.
",2.1. Approach Overview,[0],[0]
"(1)
where Ckq (I) is the total number of elements in buckets of hamming distance I from q’s bucket in table",2.1. Approach Overview,[0],[0]
"k.
We take S samples and construct Z1, Z2, . . .",2.1. Approach Overview,[0],[0]
ZS .,2.1. Approach Overview,[0],[0]
We report∑S i=1,2.1. Approach Overview,[0],[0]
"Zi S as our estimate for |Aq|.
",2.1. Approach Overview,[0],[0]
Comparison to Related Work: Note that our problem can be viewed as kernel density estimation problem for a specific kernel function that has value 1 for pairs of points within the required angle range of interest and 0 outside.,2.1. Approach Overview,[0],[0]
"However the analysis of (Charikar & Siminelakis, 2017) does not apply to our setting because they need a scale free hash function (with collision probabilities related to the kernel value) and there is no such function for our 0-1 kernel.",2.1. Approach Overview,[0],[0]
"The work of (Spring & Shrivastava, 2017) does not make such an assumption on the hash function, but they do not give an analysis that gives meaningful bounds in our setting.",2.1. Approach Overview,[0],[0]
"As noted previously, both works only look at a single hash bucket in each hash table, leading to a high storage overhead.",2.1. Approach Overview,[0],[0]
We establish the following theoretical bounds on the storage and sample complexity of our estimator in order to achieve a (1±ε)-approximation to the true count with high probability.,2.2. Main Result,[0],[0]
Theorem 2.1 (Main Result).,2.2. Main Result,[0],[0]
"For a given angular distance range of interest A and a given query q, with probability 1 − δ, our estimator returns a (1 ± ε)approximation to |Aq|, the true number of elements within
angle A to q using O
( 1
ε2 min x∈Aq
p(x) log( 1 δ )
) tables and
O
( E(Cq(I))
ε2|Aq|· min x∈Aq
p(x) log( 1 δ )
) samples.
",2.2. Main Result,[0],[0]
"To help the reader digest this result, we briefly compare this statement to the sample complexity of naive random sampling.",2.2. Main Result,[0],[0]
"It can be shown through a standard BernoulliChernoff argument that the sample complexity for random sampling is O( n|Aq|ε2 ln ( 1 δ ) ), where n|Aq| is the inverse proportion of elements of interest in the overall population.",2.2. Main Result,[0],[0]
"Intuitively this says that you need to take more random samples if |Aq| is very small compared to n.
Our sample complexity replaces the n|Aq| term with E(Cq(I)) |Aq|· min x∈Aq p(x) , where |Aq| · minx∈Aq p(x) is a measure of the expected number of elements from the set of interest Aq that will land in hamming distance I to q, and E(Cq(I)) is
the expected size of the overall sampling pool of elements in hamming distance I.",2.2. Main Result,[0],[0]
This ratio of expectations seems intuitive – one would expect to get such an expression if our scheme took one sample per table.,2.2. Main Result,[0],[0]
"Surprisingly, we achieve this same type of sample complexity bound while sampling from relatively few hash tables.
",2.2. Main Result,[0],[0]
"Just like random sampling, our sample complexity bound is also based on the proportion of elements of interest in hamming distance I to the total number of elements in hamming distance I.",2.2. Main Result,[0],[0]
"However, it is easy to see that applying LSH to our dataset will increase this proportion to yield a smaller sample complexity.",2.2. Main Result,[0],[0]
"We choose I so that min
x∈Aq p(x) is high
(this probability can be high even for a small set of hamming distances I, since p(x) is the cumulative probability mass of I successes in t trials, and binomial distributions in t concentrate in an O( √ t) sized interval around the mean), and E(Cq(I)) to be small (to filter out elements that are not interesting).
",2.2. Main Result,[0],[0]
There are certain tradeoffs to choosing I .,2.2. Main Result,[0],[0]
"If more hamming distances are included in I, then min
x∈Aq p(x) is higher, how-
ever, E(Cq(I)) is also larger.",2.2. Main Result,[0],[0]
The optimal choice for I is to choose the hamming distances that substantially increase min x∈Aq p(x) yet do not substantially increase E(Cq(I)),2.2. Main Result,[0],[0]
"(so not too many uninteresting elements are infiltrating those buckets).
",2.2. Main Result,[0],[0]
"In the following sections, we explain our scheme further and present our experimental results.",2.2. Main Result,[0],[0]
"The preprocessing step contributes 3 key ingredients to the overall estimation scheme:
Hash Tables:",3. Preprocessing,[0],[0]
"Given a family of bit-wise hash functions H, define a function family G = {g : D → {0, 1}t} such that g(v) = (h1(v), . . .",3. Preprocessing,[0],[0]
"ht(v)), where hj ∈ H.",3. Preprocessing,[0],[0]
"To construct K tables, we choose K functions g1, g2, . . .",3. Preprocessing,[0],[0]
gK from G independently and uniformly at random.,3. Preprocessing,[0],[0]
"We store each v ∈ D in bucket gk(v) for k = 1, 2 . .",3. Preprocessing,[0],[0]
.K.,3. Preprocessing,[0],[0]
"This step sets up the hash tables that we will sample from in our scheme.
",3. Preprocessing,[0],[0]
"Counts Vector: We create a counts vector, denoted Cki ∈ Rt+1 for each hash address ik for each table k ∈",3. Preprocessing,[0],[0]
"{1, . . .",3. Preprocessing,[0],[0]
",K}, whereCki (d) is the count of the total number of items in buckets that are at hamming distance d = 0, 1, . . .",3. Preprocessing,[0],[0]
"t away from ik in table k.
Sampler: We create a sampler that given a separate hash address ik for each table k ∈",3. Preprocessing,[0],[0]
"{1, . . .",3. Preprocessing,[0],[0]
",K} and set of hamming distances",3. Preprocessing,[0],[0]
"I, returns a data point uniformly at random from the union of elements that were hashed to buckets of hamming distance I from ik across the K tables.
",3. Preprocessing,[0],[0]
We describe in greater detail the 3 contributions of the preprocessing step.,3. Preprocessing,[0],[0]
"For the rest of this paper, all omitted proofs appear in Appendix C.",3. Preprocessing,[0],[0]
Setting up quality hash tables to enable accurate and efficient importance sampling is vital to our scheme.,3.1. Hash Tables,[0],[0]
"Since we are importance sampling from buckets of hamming distance I acrossK tables, we need to make enough tables to guarantee unbiasedness or near-unbiasedness for our sampling-based estimator; due to the variance of the randomly generated hash functions, if we make too few tables we may not find enough elements of interest contained in those tables within hamming distance I.",3.1. Hash Tables,[0],[0]
"We want to characterize the bias of our importance sampling scheme in relation to the contents of the buckets of our hash tables.
",3.1. Hash Tables,[0],[0]
"We let Bkq (I) denote the set of hash buckets that are at hamming distance I from the hash address of query q for table k. Next, we introduce an intermediate random variable:
W = 1
K K∑ k=1 ∑ x∈Aq 1(x",3.1. Hash Tables,[0],[0]
∈ Bkq (I)),3.1. Hash Tables,[0],[0]
"p(x) .
where p(x) = P(dqx ∈ I|θqx).
",3.1. Hash Tables,[0],[0]
"W is a random variable that represents the sum of the elements of interest |Aq| that are hashed to the buckets of sampling focus Bkq (I), weighted by their probabilities p(x).",3.1. Hash Tables,[0],[0]
"It is clear that once the set of hash functions is fixed, W becomes deterministic.
",3.1. Hash Tables,[0],[0]
"We first show that the random variable Z, as defined in Equation (1), is an unbiased estimator.",3.1. Hash Tables,[0],[0]
Lemma 3.1 (Expectation of Z).,3.1. Hash Tables,[0],[0]
"The expectation of Z over the random choice of hash functions is |Aq|, i.e. E(Z)",3.1. Hash Tables,[0],[0]
= |Aq|.,3.1. Hash Tables,[0],[0]
"The expectation of Z given a specific realization of hash functions, or equivalently, given W , is E(Z|W ) =W .
",3.1. Hash Tables,[0],[0]
"As a consequence, it is immediately clear that E(W )",3.1. Hash Tables,[0],[0]
= |Aq|.,3.1. Hash Tables,[0],[0]
It is important to understand the implications of this lemma.,3.1. Hash Tables,[0],[0]
"In particular, the expression for E(Z|W ) says that in a specific realization of a choice of hash functions (or a set of tables), the estimator Z is biased if W 6= |Aq|.",3.1. Hash Tables,[0],[0]
"Therefore K is essential for helping concentrate the realized value of W around its mean.
",3.1. Hash Tables,[0],[0]
"Since in expectation, our estimator Z gives W , we want to understand how many tables K are required to ensure that W concentrates around its mean, |Aq|.",3.1. Hash Tables,[0],[0]
"This is related to the variance of W .
",3.1. Hash Tables,[0],[0]
"We also introduce a new quantity p(x, y) =",3.1. Hash Tables,[0],[0]
P(dqx ∈,3.1. Hash Tables,[0],[0]
"I ∩ dqy ∈ I|θqx, θqy), the collision probability that x and y both land in buckets that are hamming distance I from q over the random choice of hash functions.
",3.1. Hash Tables,[0],[0]
Lemma 3.2 (Variance of W ).,3.1. Hash Tables,[0],[0]
σ2(W ),3.1. Hash Tables,[0],[0]
"= 1 K ∑ x,y∈Aq ( p(x,y) p(x)p(y)",3.1. Hash Tables,[0],[0]
− 1 ),3.1. Hash Tables,[0],[0]
We want to put these pieces together to make a statement about the number of tables K we should create to guarantee low inherent bias in our estimator.,3.1. Hash Tables,[0],[0]
We use Chebyshev’s Inequality to bound W ’s deviation from its mean as a function of K with a constant failure probability 18 .,3.1. Hash Tables,[0],[0]
"For simplicity, we fix a constant failure probability that we will boost later by average over several sets of estimators.",3.1. Hash Tables,[0],[0]
"This analysis is without loss of generality, as the bounds can be adjusted for any desired failure probability δ.",3.1. Hash Tables,[0],[0]
We will use this piece again when we analyze our overall estimator.,3.1. Hash Tables,[0],[0]
Lemma 3.3 (Bound on Number of Tables).,3.1. Hash Tables,[0],[0]
"It suffices to make K ≥ 8ε2 min
x∈Aq p(x) tables to guarantee that W is within
ε of |Aq| (relatively) with probability 78 .
",3.1. Hash Tables,[0],[0]
Proof.,3.1. Hash Tables,[0],[0]
Chebyshev’s inequality states: P(|W − |Aq|| ≥ ε|Aq|) ≤ σ,3.1. Hash Tables,[0],[0]
2(W ),3.1. Hash Tables,[0],[0]
"ε2|Aq|2 .
",3.1. Hash Tables,[0],[0]
"Therefore, to achieve a constant failure probability δ = 18 , it suffices to create enough tables so that
σ2(W )",3.1. Hash Tables,[0],[0]
"= 1
K ∑ x,y∈Aq ( p(x, y) p(x)p(y)",3.1. Hash Tables,[0],[0]
− 1 ) ≤ ε 2|Aq|2,3.1. Hash Tables,[0],[0]
"8
",3.1. Hash Tables,[0],[0]
"Hence K needs to be large enough so that: K ≥ 8 ∑ x,y∈Aq ( p(x,y) p(x)p(y)",3.1. Hash Tables,[0],[0]
"− 1 ) ε2|Aq|2
Since p(x, y) ≤ min{p(x), p(y)}, we see that it is sufficient for K to satisfy
K ≥ 8|Aq|2
( minx∈Aq 1 p(x)",3.1. Hash Tables,[0],[0]
"− 1 ) ε2|Aq|2
Therefore we conclude with the following bound on K:
K ≥ 8 ε2 min
x∈Aq p(x)
(2)
We emphasize that the joint probability p(x, y) ≤ min{p(x), p(y)} is a very loose worst-case bound assuming high correlation between data points.",3.1. Hash Tables,[0],[0]
"The final bound for K, Equation (2), is also a worst-case bound in the sense that it is possible that a very minuscule fraction of x ∈ Aq have small values for p(x).",3.1. Hash Tables,[0],[0]
"In the experimental section of the paper, we do an empirical analysis of the inherent bias for different values of K and demonstrate that for real datasets the number of tables needed can be far fewer than what is theoretically required in the worst case scenario.",3.1. Hash Tables,[0],[0]
"Query q maps to a bucket ik for each table k = 1, 2 . .",3.2. Counts Vector,[0],[0]
.K.,3.2. Counts Vector,[0],[0]
"The preprocessing step produces an average counts vector corresponding to bucket ik, denoted Ckq , where C k q",3.2. Counts Vector,[0],[0]
"(i) is the count of the total number of items in buckets that are at hamming distance i = 0, 1, . . .",3.2. Counts Vector,[0],[0]
t away from the hash address for q in,3.2. Counts Vector,[0],[0]
table k.,3.2. Counts Vector,[0],[0]
"For the hamming distances of interest I , we let Ckq (I) = ∑ d∈I C k",3.2. Counts Vector,[0],[0]
q,3.2. Counts Vector,[0],[0]
"(d).
",3.2. Counts Vector,[0],[0]
Ckq (I) is an integral part of our weighted importance sampling scheme.,3.2. Counts Vector,[0],[0]
"In Appendix A, we show how to compute these vectors efficiently.
",3.2. Counts Vector,[0],[0]
Theorem 3.1 (Aggregate-Counts).,3.2. Counts Vector,[0],[0]
"Given a set of K hash tables, each with 2t hash buckets with addresses in {0, 1}t, Aggregate-Counts (Algorithm 1) computes, for each hash address i, the number of elements in buckets that are hamming distance 0, 1, . . .",3.2. Counts Vector,[0],[0]
"t away from i, in each of the K tables, in time O(Kt22t).
",3.2. Counts Vector,[0],[0]
"Note that the t in our hashing scheme is the length of the hash sequence; as a general rule of thumb, for bit-wise hash functions, implementers choose t",3.2. Counts Vector,[0],[0]
"≈ log(n), so as to average out to one element per hash bucket.",3.2. Counts Vector,[0],[0]
"Therefore, the preprocessing runtime of a reasonable hashing implementation for Aggregate-Counts (Algorithm 1) is approximately O(nK log2(n)).
",3.2. Counts Vector,[0],[0]
"The key benefit of Aggregate-Counts is that it computes via a message-passing or dynamic programming strategy that is much more efficient than a naive brute-force approach that would take time O(K22t), or O(Kn2) if t ≈ log(n).",3.2. Counts Vector,[0],[0]
"We create a sampler that, given a hash address ik for each table, and a set of hamming distances I that we want to sample from, generates a sample uniformly at random from the union of elements that were hashed to hamming distance I across the K tables.",3.3. Sampler,[0],[0]
"For an implementation and analysis, please consult Appendix B.
Theorem 3.2 (Sampler).",3.3. Sampler,[0],[0]
"Given a set of K hash tables, each with 2t hash buckets with addresses in {0, 1}t, a sampling scheme consisting of a data structure and a sampling algorithm can generate a sample uniformly at random from any fixed hash table k, an element at hamming distance d to hash address i.",3.3. Sampler,[0],[0]
"The data structure is a counts matrix that can be precomputed in preprocessing time O(Kt32t), and the sampling algorithm Hamming-Distance-Sampler (Algorithm 2) generates a sample in time O(t).
",3.3. Sampler,[0],[0]
"Again, if we follow t ≈ log(n), the preprocessing time comes out to roughly O(nK log3(n)).",3.3. Sampler,[0],[0]
"Also we expect the O(t) online sample generation cost to be negligible compared to, say, the inner product computation cost for q · x,
which our method and all competing methods use.",3.3. Sampler,[0],[0]
We describe the importance sampling scheme in the next section.,3.3. Sampler,[0],[0]
We now analyze our sampling algorithm.,4. Sampling,[0],[0]
Recall that our sampling scheme works in the following way.,4. Sampling,[0],[0]
"Given query q, we generate the hash for q in each of our K tables, by solving for ik = gk(q) for k = 1, . .",4. Sampling,[0],[0]
.K.,4. Sampling,[0],[0]
"Given the hash for q in each of our K tables and the set of hamming distances I that we want to sample from, we invoke our sampler to generate a sample from across the K tables.
",4. Sampling,[0],[0]
"Given this sample, x, we compute the angular distance θqx = cos
−1(q · x).",4. Sampling,[0],[0]
"Let p(x) = P(dqx ∈ I|θqx), the collision probability that x lands in a bucket that is hamming distance I from q over the random choice of hash functions; p(x) is an endogenous property of an LSH function.
",4. Sampling,[0],[0]
"We score each sample as in Equation (1).
",4. Sampling,[0],[0]
"We take S samples and construct Z1, Z2, . . .",4. Sampling,[0],[0]
ZS .,4. Sampling,[0],[0]
We report∑S i=1,4. Sampling,[0],[0]
"Zi S as our estimate for |Aq|.
",4. Sampling,[0],[0]
"As an immediate consequence of Lemma 3.1, it is clear that
E",4. Sampling,[0],[0]
[∑S i=1,4. Sampling,[0],[0]
"Zi S ] = |Aq| .
",4. Sampling,[0],[0]
"Now we analyze the variance of our estimator:
Lemma 4.1 (Variance of Estimator).
",4. Sampling,[0],[0]
"E (∑Si=1 Zi S − |Aq| )2 ≤ E[Z2] S + σ2(W )
",4. Sampling,[0],[0]
This decomposition of the variance into the two terms indicates that the variance is coming from two sources.,4. Sampling,[0],[0]
"The first source is the variance of the samples, E[Z
2] S .",4. Sampling,[0],[0]
"If we don’t take
enough samples, we do not get a good estimate.",4. Sampling,[0],[0]
"The second source is the variance from the random variable W , σ2(W ), which corresponds to the contents in the tables.",4. Sampling,[0],[0]
"As we have shown, it is crucial to create enough tables so that W is concentrated around its expectation, |Aq|.",4. Sampling,[0],[0]
"Therefore, this second source of variance of the overall estimator comes from the variance of the hash functions that underlie table creation and composition.
",4. Sampling,[0],[0]
"The σ2(W ) term has already been analyzed in Section 3.1, see Lemma 3.2.",4. Sampling,[0],[0]
"Now we analyze the second moment of Z.
Lemma 4.2 (Variance of Z).
",4. Sampling,[0],[0]
"E[Z2] = ∑ x∈Aq ∑ y∈D [ p(x, y) K · p(x)2 +",4. Sampling,[0],[0]
"( 1− 1 K ) p(y) p(x) ]
Now that we have all the components, we are ready to put together the final sample and storage complexities for our estimator.",4. Sampling,[0],[0]
"We want a final estimate that concentrates with at most error around its mean, |Aq| with probability 1− δ.",4. Sampling,[0],[0]
"To do this, we make several sets 1, 2, . .",4. Sampling,[0],[0]
.M,4. Sampling,[0],[0]
of our estimator (one estimator consists of a set of K tables and S samples).,4. Sampling,[0],[0]
"We choose K and S so that the failure probability of our estimator is a constant, say 14 .",4. Sampling,[0],[0]
"Each estimator produces an estimate, call it Em, for m ∈ {1, . .",4. Sampling,[0],[0]
.M},4. Sampling,[0],[0]
.,4. Sampling,[0],[0]
We report our final estimate as the median of these estimates.,4. Sampling,[0],[0]
"This is the classic Median-of-Means technique.
",4. Sampling,[0],[0]
Let Fm be the indicator variable indicating if the estimator Em fails to concentrate.,4. Sampling,[0],[0]
Clearly E(Fm) ≤ 14 .,4. Sampling,[0],[0]
"Moreover, E(F = ∑M m=1 Fm) ≤",4. Sampling,[0],[0]
M 4 .,4. Sampling,[0],[0]
"The probability that the median estimate is bad, P(median of Emfails) ≤",4. Sampling,[0],[0]
P(half of Em fails) =,4. Sampling,[0],[0]
P(F ≥ M2 ).,4. Sampling,[0],[0]
"By a simple Chernoff bound, we see that: P(F ≥ M2 ) ≤",4. Sampling,[0],[0]
"e
−(2 ln 2−1)M4 ≤ e−M11 .",4. Sampling,[0],[0]
"So to satisfy a desired failure probability δ, it suffices to have e
−M 11 ≤ δ, therefore M ∈ O(log( 1δ )).
",4. Sampling,[0],[0]
"In the rest of the section, we establish bounds on K and S so that one estimator fails with probability at most 14 .",4. Sampling,[0],[0]
"We appeal again to Chebyshev’s Inequality:
P (∣∣∣∣∣ ∑S i=1",4. Sampling,[0],[0]
Zi S,4. Sampling,[0],[0]
− |Aq| ∣∣∣∣∣,4. Sampling,[0],[0]
≥ ε|Aq| ) ≤ σ2( ∑S i=1,4. Sampling,[0],[0]
Zi S ),4. Sampling,[0],[0]
"ε2|Aq|2
In Lemma 4.1, we analyze the variance of our estimator, and show that σ2( ∑S i=1",4. Sampling,[0],[0]
"Zi S ) ≤ E[Z2] S + σ
2(W ).",4. Sampling,[0],[0]
"Therefore, in order so that the failure probability is less than 14 , it suffices
to have σ2( ∑S
i=1",4. Sampling,[0],[0]
Zi S ),4. Sampling,[0],[0]
"≤ ε2|Aq|2 4 , which can be obtained by
letting E[Z 2] S ≤ ε2|Aq|2 8 and σ 2(W ) ≤ ε",4. Sampling,[0],[0]
"2|Aq|2 8 .
",4. Sampling,[0],[0]
"Focusing on the σ2(W ) term, which depends on the number of tables K created, we show in Lemma 3.3 from Section 3.1 that it suffices to take K ≥ 8ε2",4. Sampling,[0],[0]
"min
x∈Aq p(x) .
",4. Sampling,[0],[0]
"Now that we have our table complexity, we can analyze our sampling complexity S to bound E[Z
2] S .
Lemma 4.1.",4. Sampling,[0],[0]
Suppose K ≥ 8ε2 min x∈Aq p(x) .,4. Sampling,[0],[0]
"Then S ∈
O
( E(Cq(I))
ε2|Aq|· min x∈Aq p(x)
) suffices to achieve E[Z
2] S ≤ ε2|Aq|2 8 .
",4. Sampling,[0],[0]
Proof.,4. Sampling,[0],[0]
"By Lemma 4.2 we have:
E[Z2] S = 1 S ∑ x∈Aq ∑ y∈D [ p(x, y) K · p(x)2 +",4. Sampling,[0],[0]
"( 1− 1 K ) p(y) p(x) ]
Substituting for K ≥ 8ε2",4. Sampling,[0],[0]
"min x∈Aq p(x) gives:
E[Z2] S ≤ 1 S ∑ x∈Aq ∑ y∈D ε2p(x, y) minx∈Aq p(x) 8p(x)2 + p(y) p(x)  ≤ 1 S ∑ x∈Aq ∑ y∈D [ ε2p(x, y) 8p(x) + p(y) p(x) ]
≤ 1 S ∑ x∈Aq ∑ y∈D",4. Sampling,[0],[0]
"[ (1 + ε2) p(y) p(x) ]
",4. Sampling,[0],[0]
"In order to guarantee E[Z 2] S ≤ ε2|Aq|2 8 , we need:
S ≥
∑ x∈Aq ∑",4. Sampling,[0],[0]
y∈D,4. Sampling,[0],[0]
[ (1 + ε2) p(y)p(x) ],4. Sampling,[0],[0]
"ε2|Aq|2
= (1 + ε2)
∑ x∈Aq 1 p(x) ∑ y∈D p(y)
",4. Sampling,[0],[0]
"ε2|Aq|2
= (1 + 1
ε2 )
∑ x∈Aq
1 p(x) E(Cq(I))",4. Sampling,[0],[0]
"|Aq|2
Therefore, we conclude that
S ∈ O  E(Cq(I)) ε2|Aq| · min
x∈Aq p(x)  is sufficient.
",4. Sampling,[0],[0]
"Putting together Lemmas 3.3 and 4.1 with the median of means strategy yields our main result, Theorem 2.1.
",4. Sampling,[0],[0]
In the rest of this paper we discuss the results of our experiments on real datasets.,4. Sampling,[0],[0]
We describe our experiments using the GLOVE dataset.,5. Experiments,[0],[0]
"We use the set of 400,000 pre-trained 50-dimensional word embedding vectors trained from Wikipedia 2014 + Gigaword 5, provided by (Pennington et al., 2014).",5. Experiments,[0],[0]
"We normalize the embeddings, as is standard in many word embedding applications (Sugawara et al., 2016)",5. Experiments,[0],[0]
"We choose 3 query words with different neighborhood profiles: “venice”, “cake”, “book”.",5. Experiments,[0],[0]
"Venice has the smallest neighborhood, with 206 elements with angular distance less than 60 degrees, cake has a medium sized neighborhood with about 698 elements, book has the largest neighborhood with 1275 elements.",5. Experiments,[0],[0]
"The histogram for these 3 queries are shown in Figure 1.
",5. Experiments,[0],[0]
"We also choose our angle range of interest, A, to be 0- 60 degrees.",5. Experiments,[0],[0]
"A search through our dataset gave “florence”, “cannes”, “rome” as representative elements that are 40-50
degrees from “venice”, and “renaissance”, “milan”, “tuscany”, “italy” in the 50-60 degree range.",5. Experiments,[0],[0]
"Terms such as “cheesecake”, “desserts”, “ganache”, and “bakes” appear in the 40-50 degree annulus around “cake”, while terms such as “fruitcake”, “cupcake”, “confections”, “poundcake”, and “eggs” appear in the 50-60 degree histogram.",5. Experiments,[0],[0]
"For “book”: “character”, “chronicles”, “paperback”, “authors”, and “text” are in the 40-50 degree range while “bestseller”, “protagonist”, “publishers”, “booklet”, “publishes”, “editing”, “monograph”, and “chapter” are in the 50-60 degree range.",5. Experiments,[0],[0]
"This particular experiment shows that while elements in the 40-50 degree range are extremely related, words in the 50-60 degree range are also relevant, and so we fix A to be 0-60 degrees in all of our experiments.",5. Experiments,[0],[0]
"We also fix t = 20 in all of our experiments, since we have 400,000 embeddings in total and 20 ≈ log2(400, 000).
",5. Experiments,[0],[0]
"As Table 1 illustrates, the biggest challenge for this estimation problem is the fact that the count of the number of elements within 0-60 degrees is dwarfed by the number of elements 60-120 degrees away from the queries.",5. Experiments,[0],[0]
"This issue makes locality sensitive techniques necessary for efficient search and retrieval in high dimensions.
",5. Experiments,[0],[0]
Table 1:,5. Experiments,[0],[0]
"Statistics of Queries
QUERY #",5. Experiments,[0],[0]
"WITHIN 60 DEGREES % OF POPULATION
VENICE 206 .0515",5. Experiments,[0],[0]
CAKE 698 .1745,5. Experiments,[0],[0]
"BOOK 1275 .31875
As we have previously mentioned in section 3.1, the number of tables K theoretically required for (near) unbiased estimation relies on a worst-case variance bound; real-world data do not necessarily exhibit worst-case behavior.",5. Experiments,[0],[0]
"In our studies of our 3 queries see Figures 2, the inherent bias of our estimator decreases as we increase the sampling ham-
ming threshold.",5. Experiments,[0],[0]
"This is as expected, using a larger range of hamming distances helps concentrate the count of the elements of interest Aq that fall into the specified range of hamming distances around the mean, which means that a smaller K is required to achieve small bias.
",5. Experiments,[0],[0]
"Moreover, the empirical bias of our estimator at hamming threshold 5 is around 5% for 20 hash tables, with very little improvement with 40 hash tables.",5. Experiments,[0],[0]
This is consistent with our 3 queries.,5. Experiments,[0],[0]
"With this in mind, we compare our estimator against the benchmark estimator introduced by (Spring & Shrivastava, 2017).",5. Experiments,[0],[0]
"Though their work originally intended to solve a different problem, their technique can solve our problem by adapting the weight function appropriately.",5. Experiments,[0],[0]
"The key differences between their work and ours is that they only probe the 0 hamming distance bucket in each table, similar to the classic LSH literature, and instead of sampling, they simply enumerate the elements in the hamming distance 0 bucket for each table.",5. Experiments,[0],[0]
"For higher values of K, which our experiments demonstrate that their estimator needs in order to get good results, enumeration might not be so efficient.
",5. Experiments,[0],[0]
"In Figure 3, we compare (Spring & Shrivastava, 2017)’s technique of enumerating and importance-weighting hamming distance 0 elements to our technique of importance sampling from different hamming thresholds.",5. Experiments,[0],[0]
"Our experiments use random hyperplane LSH and we report relative error averaged over 25 trials, where in each trial we generate a new set of K tables.",5. Experiments,[0],[0]
"Panel (b) experiments with (Spring & Shrivastava, 2017)’s technique for the 3 queries, with different choices of K, the number of tables.",5. Experiments,[0],[0]
"Our results show that even for K = 40 tables, the relative error of their technique can still be higher than 50%, particularly for queries with small neighborhoods such as “venice”.",5. Experiments,[0],[0]
For “venice” the increase in table allocation from 20 to 40 made a very small difference to the overall estimation error.,5. Experiments,[0],[0]
"“book” and “cake” fared better at 40 tables, however, the error was still around 25 %, while our estimator (panel a) estimated to within about 10% error using only 20 tables.
",5. Experiments,[0],[0]
Panel (a) of Figure 3 shows that utilizing any hamming threshold greater than 0 gives superior estimation performance to staying only within the 0 hamming distance bucket.,5. Experiments,[0],[0]
"In this experiment, we fix our sampling budget to 1000 samples and the table budget to 20 tables.",5. Experiments,[0],[0]
The hamming distance 0 error reported in this figure uses enumeration; all other hamming thresholds use the 1000 sampling budget.,5. Experiments,[0],[0]
"In our experiments for the 3 queries, one can expect about 80 points in total in the hamming distance 0 buckets across 20 tables.",5. Experiments,[0],[0]
"In this experiment, our technique uses 1000 samples vs 80 points, however, this (somewhat negligible in today’s computing infrastructure) sample complexity trades off against a large improvement in precision, as well as a much lower storage cost in the number of tables K.
Finally, we note that panel (a) of Figure 3 shows the smallest
error for “venice” at hamming threshold 3.",5. Experiments,[0],[0]
This is related to the characteristics of this query and the sampling budget.,5. Experiments,[0],[0]
"We see in this example that for “venice”, which is a fairly isolated data point compared to the other 2 queries, going to further hamming distances actually hurts the quality of the estimate because we actually dilute the proportion of interesting elements.",5. Experiments,[0],[0]
"Using higher thresholds typically requires more samples, as shown in Figure 4.",5. Experiments,[0],[0]
"However, higher thresholds typically lowers the inherent bias in the importance sampling scheme, as demonstrated in Figure 2.",5. Experiments,[0],[0]
Implementers should consider this tradeoff in their algorithmic design choices.,5. Experiments,[0],[0]
"Given the case study of our estimator achieving the smallest estimation error for “venice” at hamming threshold 3, whereas for the more popular queries “cake” and “book” performance improves steadily at higher hamming thresholds, it would be interesting to, from the practitioner’s point of view, understand what is the best hamming threshold to sample from, and given a hamming threshold, how many samples should be taken for a quality estimate.",6. Discussion,[0],[0]
"The optimal
sample complexity is data-dependent, and cannot be known without a sense of |Aq|, the very quantity we aim to estimate.",6. Discussion,[0],[0]
"But instead of fixing the sample complexity up-front, is there a way we can iteratively, in an on-line fashion, determine whether we should keep sampling or stop, based on a current belief of |Aq|?",6. Discussion,[0],[0]
"This work was initiated while the authors were visiting Laserlike, Inc.",Acknowledgements,[0],[0]
Xian Wu was supported by a Harold Thomas Hahn Jr. Fellowship from the Department of Management Science and Engineering at Stanford University.,Acknowledgements,[0],[0]
Moses Charikar was supported by NSF grant CCF-1617577 and a Simons Investigator Award.,Acknowledgements,[0],[0]
"An important question that arises in the study of high dimensional vector representations learned from data is: given a set D of vectors and a query q, estimate the number of points within a specified distance threshold of q. Our algorithm uses locality sensitive hashing to preprocess the data to accurately and efficiently estimate the answers to such questions via an unbiased estimator that uses importance sampling.",abstractText,[0],[0]
A key innovation is the ability to maintain a small number of hash tables via preprocessing data structures and algorithms that sample from multiple buckets in each hash table.,abstractText,[0],[0]
"We give bounds on the space requirements and query complexity of our scheme, and demonstrate the effectiveness of our algorithm by experiments on a standard word embedding dataset.",abstractText,[0],[0]
Local Density Estimation in High Dimensions,title,[0],[0]
"Hypothesis testing is a widely applied statistical tool used to test whether given models should be rejected, or not, based on sampled data from a population.",1. Introduction,[0],[0]
"Hypothesis testing was initially developed for scientific and survey data, but today it is also an essential tool to test models over collections of social network, mobile, and crowdsourced data (American Statistical Association, 2014; Hunter et al., 2008; Steele et al., 2017).",1. Introduction,[0],[0]
"Collected data samples may contain highly sensitive information about the subjects, and the privacy of individuals can be compromised when the results of a data analysis are released.",1. Introduction,[0],[0]
A way to address this concern is by developing new techniques to support privacy-preserving data analysis.,1. Introduction,[0],[0]
"Among the different approaches, differential privacy (Dwork et al., 2006b) has emerged as a viable solution: it provides strong privacy guarantees and it allows to release accurate statistics.",1. Introduction,[0],[0]
A standard way to achieve differential privacy is by injecting some statistical noise in the computation of the data analysis.,1. Introduction,[0],[0]
"When the noise is carefully chosen, it helps to protect the individual privacy without compromising the utility of the data analysis.",1. Introduction,[0],[0]
"Several recent works have studied differentially private hypothesis tests
*Equal contribution 1 University at Buffalo, Buffalo, NY, USA 2University of Pennsylvania, Philadelphia, PA, USA.",1. Introduction,[0],[0]
"Correspondence to: Marco Gaboardi <gaboardi@buffalo.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"that can be used in place of the standard, non-private hypothesis tests (Uhler et al., 2013; Yu et al., 2014; Sheffet, 2015; Karwa & Slavković, 2016; Wang et al., 2015; Gaboardi et al., 2016; Kifer & Rogers, 2017; Cai et al., 2017).",1. Introduction,[0],[0]
These tests work in the curator model of differential privacy.,1. Introduction,[0],[0]
"In this model, the data is centrally stored and the curator carefully injects noise in the computation of the data analysis in order to satisfy differential privacy.
",1. Introduction,[0],[0]
"In this work we instead address the local model of privacy, formally introduced by Raskhodnikova et al. (2008).",1. Introduction,[0],[0]
"The first differentially private algorithm called randomized response – in fact it predates the definition of differential privacy by more than 40 years – guarantees differential privacy in the local model (Warner, 1965).",1. Introduction,[0],[0]
"In this model, there is no trusted centralized entity that is responsible for the noise injection.",1. Introduction,[0],[0]
"Instead, each individual adds enough noise to guarantee differential privacy for their own data, which provides a stronger privacy guarantee than the curator model.",1. Introduction,[0],[0]
The data analysis is then run over the collection of the individually sanitized data.,1. Introduction,[0],[0]
"The local model of differential privacy is a convenient model for several applications: for example it is used to collect statistics about the activity of the Google Chrome Web browser users (Erlingsson et al., 2014), and to collect statistics about the typing patterns of Apple’s iPhone users (Apple Press Info, 2016).",1. Introduction,[0],[0]
"Despite these applications, the local model has received far less attention than the centralized curator model.",1. Introduction,[0],[0]
"This is in part due to the more firm requirements imposed by this model, which make the design of effective data analysis harder.
",1. Introduction,[0],[0]
Our main contribution is in designing chi-square hypothesis tests for the local model of differential privacy.,1. Introduction,[0],[0]
Similar to previous works we focus on goodness of fit and independence hypothesis tests.,1. Introduction,[0],[0]
"Most of the private chi-square tests proposed so far are based on mechanisms that add noise in some form to the aggregate data, e.g. the cells of the contingency tables, or the resulting chi-square statistics value.",1. Introduction,[0],[0]
"These approaches cannot be used in the local model, since noise needs to be added at the individual’s data level.",1. Introduction,[0],[0]
"We then consider instead general privatizing techniques in the local model, and we study how to build new hypothesis tests with them.",1. Introduction,[0],[0]
Each test we present is characterized by a specific local model mechanism.,1. Introduction,[0],[0]
"The main technical challenge for designing each test is to create statistics, which incorporate the local model mechanisms, that converge as
we collect more data to a chi-square distribution, as in the classical chi-square tests.",1. Introduction,[0],[0]
"We then use these statistics to find the critical value to correctly bound the Type I error.
",1. Introduction,[0],[0]
"We present three different goodness of fit tests: LocalNoiseGOF presents a statistic that guarantees the convergence to a chi-square distribution under the null hypothesis so that we can use the correct critical values when local (concentrated) differential privacy is guaranteed by adding Laplace or Gaussian noise to the individual data; LocalGenRRGOF also provides a statistic that converges to a chi-square under the null hypothesis when a private value for each individual is selected by using a generalized form of randomized response, which can also be thought of as an instantiation of the exponential mechanism (McSherry & Talwar, 2007); finally, LocalBitFlipGOF introduces a statistic that converges to a chi-square distribution when the data is privatized using a bit flipping algorithm (Bassily & Smith, 2015), which provide better accuracy for higher dimensional data.",1. Introduction,[0],[0]
"Further, we develop corresponding independence tests: LocalNoiseIND (see supplementary file), LocalGenRRIND, and LocalBitFlipIND.",1. Introduction,[0],[0]
For all these tests we study their asymptotic behavior.,1. Introduction,[0],[0]
"A desiderata for private hypothesis tests is to have a guaranteed upper bound on the probability of a false discovery (or Type I error) – rejecting a null hypothesis or model when the data was actually generated from it – and to minimize the probability of a Type II error, which is failing to reject the null hypothesis when the model is indeed false.",1. Introduction,[0],[0]
This latter criteria corresponds to the power of the statistical test.,1. Introduction,[0],[0]
We then present experimental results showing the power of the different tests which demonstrates that no single local differentially private algorithm is best across all data dimensions and privacy parameter regimes.,1. Introduction,[0],[0]
"However, this evaluation also shows a relation between the power of the test and the noncentral parameter of the test statistic that is used.",1. Introduction,[0],[0]
"This suggests that besides looking at the parameters of the test, a data analyst may need also to consider which test statistic results in the largest noncentral parameter.",1. Introduction,[0],[0]
"There have been several works in developing private hypothesis test for categorical data, but all look at the traditional model of (concentrated) differential privacy instead of the local model, which we consider here.",2. Related Works,[0],[0]
"Several works have explored private statistical inference for GWAS data, (Uhler et al., 2013; Yu et al., 2014; Johnson & Shmatikov, 2013).",2. Related Works,[0],[0]
"Following these works, there has also been general work in private chi-square hypothesis tests, where the main tests are for goodness of fit and independence testing, although some do extend to more general tests (Wang et al., 2015; Gaboardi et al., 2016; Kifer & Rogers, 2017; Cai et al., 2017; Kakizaki et al., 2017).",2. Related Works,[0],[0]
"Among these, the works most related to
ours are the ones by Gaboardi et al. (2016); Kifer & Rogers (2017).",2. Related Works,[0],[0]
"One of our mechanisms, LocalNoiseGOF, can be seen as an adaptation of their techniques to the local model.",2. Related Works,[0],[0]
"However, the other mechanisms we introduce differ substantially and require novel asymptotic analyses.",2. Related Works,[0],[0]
"There has also been work in private hypothesis testing for ordinary least squares regression (Sheffet, 2015).
",2. Related Works,[0],[0]
Duchi et al. (2013b;a) focus on controlling disclosure risk in statistical estimation and inference by ensuring the analysis satisfies local differential privacy.,2. Related Works,[0],[0]
"In their work, they show that a generalized version of randomized response gives optimal sample complexity for estimating the multinomial probability vector.",2. Related Works,[0],[0]
We use this idea as the basis for our hypothesis test LocalBitFlipGOF.,2. Related Works,[0],[0]
"Kairouz et al. (2014) also considers hypothesis testing in the local model, although they measure utility in terms of f -divergences and do not give a decision rule, i.e. when to reject a given null hypothesis.",2. Related Works,[0],[0]
"We provide statistics whose distributions asymptotically follow a chi-square distribution, which allows for approximating statistical p-values that can be used in a decision rule.",2. Related Works,[0],[0]
We consider their extremal mechanisms and empirically confirm their result that for small privacy regimes (small ) one mechanism has higher utility than other mechanisms and for large privacy regimes (large ) a different mechanism outperforms the other.,2. Related Works,[0],[0]
"However, we measure utility in terms of the power of a locally private hypothesis test subject to a given Type I error bound.",2. Related Works,[0],[0]
"Other notable works in the local privacy model include Pastore & Gastpar (2016); Kairouz et al. (2016); Ye & Barg (2017)
Independent of this work, another paper (Sheffet, 2018) has addressed local private hypothesis testing.",2. Related Works,[0],[0]
Sheffet (2018) considers finite sample complexity by showing certain test quantities take different values under the null- and alternative-hypothesis.,2. Related Works,[0],[0]
"In this work, we design and analyze asymptotic statistical tests and empirically evaluate the performance of each test for finite samples.",2. Related Works,[0],[0]
"We consider datasets x = (x1, · · · , xn) ∈",3. Preliminaries,[0],[0]
"Xn in some data universe X , typically X = {0, 1}d where d is the dimensionality.",3. Preliminaries,[0],[0]
"We first present the standard definition of differential privacy, as well as its variant concentrated differential privacy.",3. Preliminaries,[0],[0]
"We say that two datasets x,x′ ∈ Xn are neighboring if they differ in at most one element, i.e. ∃i ∈",3. Preliminaries,[0],[0]
[n] such that xi 6= x′i and ∀j 6=,3. Preliminaries,[0],[0]
"i, xj = x′j .",3. Preliminaries,[0],[0]
Definition 3.1 (Dwork et al. (2006b;a)).,3. Preliminaries,[0],[0]
"An algorithm M : Xn → Y is ( , δ)-differentially private (DP)",3. Preliminaries,[0],[0]
"if for all neighboring datasets x,x′ ∈ Xn and for all outcomes S ⊆ Y , we have Pr [M(x) ∈ S] ≤",3. Preliminaries,[0],[0]
e,3. Preliminaries,[0],[0]
Pr [M(x′) ∈ S] + δ.,3. Preliminaries,[0],[0]
Definition 3.2 (Bun & Steinke (2016)).,3. Preliminaries,[0],[0]
"An algorithm M : Xn → Y is ρ-zero-mean concentrated differentially private (zCDP) if for all neighboring datasets
x,",3. Preliminaries,[0],[0]
"x′ ∈ Xn, we have the following bound for all t > 0",3. Preliminaries,[0],[0]
"where the expectation is over outcomes y ∼ M(x), E [ exp ( t ( ln (
Pr[M(x)=y] Pr[M(x′)=y]
)",3. Preliminaries,[0],[0]
− ρ ))],3. Preliminaries,[0],[0]
"≤ et2ρ.
Note that in both of these privacy definitions, it is assumed that all the data is stored in a central location and the algorithm M can access all the data.",3. Preliminaries,[0],[0]
Most of the work in differential privacy has been in this trusted curator model.,3. Preliminaries,[0],[0]
"We then define local differential privacy, formalized by Raskhodnikova et al. (2008) and Dwork & Roth (2014), which does not require the subjects to release their raw data, rather each data entry is perturbed to prevent the true entry from being stored.",3. Preliminaries,[0],[0]
"Thus, local differential privacy ensures one of the strongest privacy guarantees.",3. Preliminaries,[0],[0]
Definition 3.3 (LR Oracle).,3. Preliminaries,[0],[0]
"Given a dataset x, a local randomizer oracle LRx(·, ·) takes as input an index i ∈",3. Preliminaries,[0],[0]
"[n] and an -DP algorithm R, and",3. Preliminaries,[0],[0]
"outputs y ∈ Y chosen according to the distribution of R(xi), i.e. LRx(i, R) = R(xi).
",3. Preliminaries,[0],[0]
Definition 3.4 (Raskhodnikova et al. (2008)).,3. Preliminaries,[0],[0]
"An algorithm M : Xn → Y is ( , δ)-local differentially private (LDP) if it accesses the input database x via the LR oracle LRx with the following restriction: if LR(i, Rj) for j ∈",3. Preliminaries,[0],[0]
"[k] areM’s invocations of LRx on index i, then each Rj for j ∈",3. Preliminaries,[0],[0]
"[k] is ( j , δj)- DP and ∑k j=1 j ≤ , ∑k j=1 δj ≤ δ.
",3. Preliminaries,[0],[0]
"From this we have that a ( , δ)-LDP algorithm is also ( , δ)DP.",3. Preliminaries,[0],[0]
Note that these definitions can be extended to include ρ-local zCDP (LzCDP) where each local randomizer is ρjzCDP and ∑k j=1 ρj ≤ ρ.,3. Preliminaries,[0],[0]
"We point out the following connection between LzCDP and LDP , which follows directly from results in (Bun & Steinke, 2016) Lemma 3.5.",3. Preliminaries,[0],[0]
"If M : Xn → Y is ( , 0)-LDP then it is also 2/2-LzCDP.",3. Preliminaries,[0],[0]
"If M is ρ-LzCDP, then it is also(( ρ+ √ 2ρ ln(2/δ) ) , δ )",3. Preliminaries,[0],[0]
-LDP for any δ > 0.,3. Preliminaries,[0],[0]
"As was studied in (Gaboardi et al., 2016), (Wang et al., 2015), and (Kifer & Rogers, 2017), we will study hypothesis tests with categorical data.",4. Chi-Square Hypothesis Tests,[0],[0]
"A null hypothesis, or model H0 is how we might expect the data to be generated.",4. Chi-Square Hypothesis Tests,[0],[0]
The goal for hypothesis testing is to reject the null hypothesis if the data is not likely to have been generated from the given model.,4. Chi-Square Hypothesis Tests,[0],[0]
"As is common in statistical inference, we want to design hypothesis tests to bound the probability of a false discovery (or Type I error), i.e. rejecting a null hypothesis when the data was actually generated from it, by at most some amount α, such as 5%.",4. Chi-Square Hypothesis Tests,[0],[0]
"However, designing tests that achieve this is easy, because we can just ignore the data and always fail to reject the null hypothesis, i.e. have an inconclusive test.",4. Chi-Square Hypothesis Tests,[0],[0]
"Thus, we want additionally to design our tests so that they can reject H0 if the data was not actually generated from the given model.",4. Chi-Square Hypothesis Tests,[0],[0]
"We then want to minimize
the probability of a Type II error, which is failing to reject H0 when the model is false, subject to a given Type I error.
",4. Chi-Square Hypothesis Tests,[0],[0]
"For goodness of fit testing, we assume that each individual’s dataX i for i ∈",4. Chi-Square Hypothesis Tests,[0],[0]
[n] is sampled i.i.d.,4. Chi-Square Hypothesis Tests,[0],[0]
"from Multinomial(1, p) where p ∈ Rd>0 and pᵀ · 1 = 1.",4. Chi-Square Hypothesis Tests,[0],[0]
The classical chi-square hypothesis test (without privacy) forms the histogramH =,4. Chi-Square Hypothesis Tests,[0],[0]
"(H1, · · · , Hd) = ∑n i=1X i and computes the chi-square
statistic T = ∑d j=1 (Hj−np0j) 2
np0j .",4. Chi-Square Hypothesis Tests,[0],[0]
"The reason for using this
statistic is that it converges in distribution to χ2d−1 as more data is collected, i.e. n → ∞, when H0 : p = p0 holds.",4. Chi-Square Hypothesis Tests,[0],[0]
"Hence, we can ensure the probability of false discovery to be close to α as long as we only reject H0 when T > χ2d−1,1−α where the critical value χ2d−1,1−α is defined as the following
quantity Pr [ χ2d−1 > χ 2 d−1,1−α ] = α.
",4. Chi-Square Hypothesis Tests,[0],[0]
Prior Private Chi-square Tests in the Curator Model.,4. Chi-Square Hypothesis Tests,[0],[0]
"One approach for chi-square private hypothesis tests is to add noise (Gaussian or Laplace) directly to the histogram to ensure privacy and then use the classical test statistic (Gaboardi et al., 2016; Wang et al., 2015) .",4. Chi-Square Hypothesis Tests,[0],[0]
Note that the resulting asymptotic distribution needs to be modified for such changes to the statistic – it is no longer a chi-square random variable.,4. Chi-Square Hypothesis Tests,[0],[0]
"To introduce the different statistics, we will consider goodness of fit testing after adding noise Z from distribution Dn to the histogram of counts H̃ = H + Z , which ensures ρ-zCDP when D = N (0, 1/ρ) and -DP whenD = Lap(2/ ).",4. Chi-Square Hypothesis Tests,[0],[0]
"The chi-square statistic then becomes
T̃ (D) =",4. Chi-Square Hypothesis Tests,[0],[0]
"d∑ i=1
",4. Chi-Square Hypothesis Tests,[0],[0]
( Hi + Zi,4. Chi-Square Hypothesis Tests,[0],[0]
− np0i )2 np0i where Z ∼ Dn.,4. Chi-Square Hypothesis Tests,[0],[0]
"(1)
The previous works then show that this statistic converges in distribution to a linear combination of chi-squared variables, when D ∼ N (0, 1/ρ) and ρ is also decreasing with n.
Kifer & Rogers (2017) showed that modifying the chisquare statistic to account for the additional noise leads to tests with better empirical power.",4. Chi-Square Hypothesis Tests,[0],[0]
The projected statistic from Kifer & Rogers (2017) is the following where we use projection matrix Π,4. Chi-Square Hypothesis Tests,[0],[0]
"defn= ( Id − 1d11 ᵀ ) , middle ma-
trix Mσ = Π ( Diag ( p0 + σ )",4. Chi-Square Hypothesis Tests,[0],[0]
"− p0 ( p0 )ᵀ)−1
Π, and sample noise Z ∼ Dn, with Ĥ = H +Z
T (n) KR (σ;D) = n
( Ĥ
n",4. Chi-Square Hypothesis Tests,[0],[0]
"− p0
)ᵀ",4. Chi-Square Hypothesis Tests,[0],[0]
"Mσ ( Ĥ
n",4. Chi-Square Hypothesis Tests,[0],[0]
"− p0
) (2)
We use D = Lap(2/ ) with σ = 8n 2 for an -DP claim or D = N (0, 1/ρ) with σ = 1nρ for a ρ-zCDP claim.",4. Chi-Square Hypothesis Tests,[0],[0]
"When comparing the power of all our tests, we will be considering the alternate H1 : p = p1n where p1n = p 0 + ∆√ n where 1ᵀ∆ = 0.
",4. Chi-Square Hypothesis Tests,[0],[0]
Theorem 4.1 (Kifer & Rogers (2017)).,4. Chi-Square Hypothesis Tests,[0],[0]
"Under the null hypothesis H0 : p = p0, the statistic T (n) KR ( 1 nρ ; N (0, 1/ρ) ) given in (2) for ρ > 0 converges in distribution to χ2d−1.",4. Chi-Square Hypothesis Tests,[0],[0]
"Further, under the alternate hypothesis H1 : p = p1n, the resulting asymptotic distribution is a noncentral chi-square random variable with d− 1 degrees of freedom and noncentral parameter ∆ᵀ ( Diag(p0)− p0 ( p0 )ᵀ + 1/ρId )−1 ∆
When D = Lap(2/ ), Gaboardi et al. (2016) showed that we can still obtain the null hypothesis distribution using Monte Carlo simulations to estimate the critical value, since the asymptotic distribution will no longer be chi-square.",4. Chi-Square Hypothesis Tests,[0],[0]
"That is, we can obtainm samples from the statistic under the null hypothesis with Laplace noise added to the histogram of counts.",4. Chi-Square Hypothesis Tests,[0],[0]
We can then guarantee that the probability of a false discovery is at most α as long as m > d1/αe.,4. Chi-Square Hypothesis Tests,[0],[0]
We now turn to designing local private goodness of fit tests.,5. Local Private Goodness of Fit,[0],[0]
"We first show how the existing statistics from the previous section can be adapted to the local setting and then develop new tests based on the generalized randomized response mechanism that returns one of d > 1 categories and bit flipping (Bassily & Smith, 2015).",5. Local Private Goodness of Fit,[0],[0]
Each test is locally private because it perturbs each individual’s data through a local randomizer.,5. Local Private Goodness of Fit,[0],[0]
"However, each of them has a different asymptotic behavior and so we need different analyses to identify the different critical values.",5. Local Private Goodness of Fit,[0],[0]
We empirically check the power of each test to see which tests outperform others in different parameter regimes.,5. Local Private Goodness of Fit,[0],[0]
"An interesting result of this analysis is that the power of a test is directly related to the size of the noncentral parameter of the chi-square statistic under the alternate distribution.
",5. Local Private Goodness of Fit,[0],[0]
Testing with Noise Addition.,5. Local Private Goodness of Fit,[0],[0]
"In the local model we can add Z i ∼ N ( 0, 1ρ Id ) independent noise to each individual’s data X i to ensure ρ-LzCDP or Z i i.i.d.∼ Lap ( 2 ) independent noise toX i to ensure -LDP.",5. Local Private Goodness of Fit,[0],[0]
"In either case, the resulting noisy histogram Ĥ = H +Z where Z = ∑ iZ i will have variance that scales with n for fixed privacy parameters , ρ > 0.",5. Local Private Goodness of Fit,[0],[0]
"Consider the case where we add Gaussian noise, which results in the following histogram, Ĥ = H+Z where Z ∼ N ( 0, nρ Id ) .",5. Local Private Goodness of Fit,[0],[0]
"Thus, we can use either statistic T̃ (ρ/n) or T(n)KR (ρ/n), with the latter statistic typically having better empirical power (Kifer & Rogers, 2017).",5. Local Private Goodness of Fit,[0],[0]
"We then give our first local private hypothesis test in Algorithm 1.
Theorem 5.1.",5. Local Private Goodness of Fit,[0],[0]
"LocalNoiseGOF is ρ-LzCDP when D = N (0, 1/ρ) and -LDP when D = Lap(2/ ).
",5. Local Private Goodness of Fit,[0],[0]
"Although we cannot guarantee the probability of a Type I error at most α due to the fact that we use the asymptotic
Algorithm 1 Locally Private GOF Test:LocalNoiseGOF
Input: x = (x1, · · · ,xn), ρ, α, H0 : p = p0. LetH = ∑n `=1 x`
if D = N (0, n/ρ) then Set q = T(n)KR (n/ρ;D) given in (2).",5. Local Private Goodness of Fit,[0],[0]
"if q > χ2d−1,1−α Decision←",5. Local Private Goodness of Fit,[0],[0]
Reject.,5. Local Private Goodness of Fit,[0],[0]
else Decision←,5. Local Private Goodness of Fit,[0],[0]
Fail to Reject.,5. Local Private Goodness of Fit,[0],[0]
end if if D = ∑n i=1 Lap(2/ ),5. Local Private Goodness of Fit,[0],[0]
"then
Set q = T(n)KR ( 8n/ 2;D ) given in (2).",5. Local Private Goodness of Fit,[0],[0]
"Sample m > d1/αe from the distribution of T
(n) KR
( 8n/ 2;D ) assuming H0
Set τ to be the d(m+ 1)(1− α)eth largest sample.",5. Local Private Goodness of Fit,[0],[0]
if q > τ,5. Local Private Goodness of Fit,[0],[0]
Decision←,5. Local Private Goodness of Fit,[0],[0]
Reject.,5. Local Private Goodness of Fit,[0],[0]
else Decision←,5. Local Private Goodness of Fit,[0],[0]
"Fail to Reject.
end if Output: Decision
distribution (as in the tests from prior work and the classical chi-square tests without privacy), we expect the Type I errors to be similar to those from the nonprivate test.",5. Local Private Goodness of Fit,[0],[0]
"Note that the test can be modified to accommodate arbitrary noise distributions, e.g. Laplace to ensure differential privacy.",5. Local Private Goodness of Fit,[0],[0]
"In this case, we can use a Monte Carlo (MC) approach to estimate the critical value τ that ensures the probability of a Type I error is at most α if we reject H0 when the statistic is larger than τ .",5. Local Private Goodness of Fit,[0],[0]
"For the local setting, if each individual perturbs each coordinate by adding Lap (2/ ) then this will ensure our test is -LDP.",5. Local Private Goodness of Fit,[0],[0]
"However, the sum of independent Laplace random variables is not Laplace, so we will need to estimate a sum of n independent Laplace random variables using MC.",5. Local Private Goodness of Fit,[0],[0]
We can do this by sampling m entries from the exact distribution under H0 to find the critical value.,5. Local Private Goodness of Fit,[0],[0]
"In the experiments section we will use this method to compare the power of the other local private tests with the one of the version of LocalNoiseGOF using Laplace noise, which has a better power than the one using Gaussian noise.
",5. Local Private Goodness of Fit,[0],[0]
Testing with Generalized Randomized Response.,5. Local Private Goodness of Fit,[0],[0]
"Rather than having to add noise to each component of the original histogram, we consider applying randomized response to obtain a LDP hypothesis test.",5. Local Private Goodness of Fit,[0],[0]
"We will use a generalized form of randomized response given in Algorithm 2 which takes a single data entry from the set {e1, · · · , ed}, where ej ∈ Rd is the standard basis element with a 1 in the jth coordinate and is zero elsewhere, and reports the original entry with probability slightly more than uniform and otherwise reports a different element with equal probability.",5. Local Private Goodness of Fit,[0],[0]
"Note thatMGenRR is -DP.
",5. Local Private Goodness of Fit,[0],[0]
"We have the following result when we useMGenRR on each data entry to obtain a private histogram.
",5. Local Private Goodness of Fit,[0],[0]
"Algorithm 2 Generalized Randomized Response:MGenRR Input: x ∈ {e1, · · · , ed}, .
",5. Local Private Goodness of Fit,[0],[0]
"Let q(x,z) = 1{x = z} Select x̌ with probability exp[ q(x,x̌)]e −1+d
Output: x̌
Lemma 5.2.",5. Local Private Goodness of Fit,[0],[0]
"If we have histogram H = ∑n i=1X i, where {X i} i.i.d.∼ Multinomial(1, p) and we write Ȟ =∑n
i=1MGenRR(X",5. Local Private Goodness of Fit,[0],[0]
"i, ) for each",5. Local Private Goodness of Fit,[0],[0]
i ∈,5. Local Private Goodness of Fit,[0],[0]
"[n], then Ȟ ∼ Multinomial(n, p̌) where
p̌ = p
( e
e + d− 1
) + (1 − p) ( 1
e + d− 1
) .",5. Local Private Goodness of Fit,[0],[0]
"(3)
Once we have Ȟ , we can create a chi-square statistic by subtracting Ȟ by its expectation and dividing the difference by the expectation.",5. Local Private Goodness of Fit,[0],[0]
"Hence testing H0 : p = p0 after the generalized randomized response mechanism, is equivalent to testing H0 : p = p̌0 with data Ȟ .
",5. Local Private Goodness of Fit,[0],[0]
We can then form a chi-square statistic using the histogram Ȟ which will have the correct asymptotic distribution.,5. Local Private Goodness of Fit,[0],[0]
Theorem 5.3.,5. Local Private Goodness of Fit,[0],[0]
"Let H ∼ Multinomial(n,p) and Ȟ be given in Theorem 5.2 with privacy parameter > 0.",5. Local Private Goodness of Fit,[0],[0]
"Under the null hypothesis H0 : p = p0, we have for p̌0 = 1e",5. Local Private Goodness of Fit,[0],[0]
"+d−1 ( e p0 + (1− p0) ) ,
T (n) GenRR ( ) = d∑ j=1 (Ȟj − np̌0j )2 np̌0j D→ χ2d−1. (4)
",5. Local Private Goodness of Fit,[0],[0]
"Further, with alternate H1 : p = p1n, the resulting asymptotic distribution is a noncentral chi-square distribution with d − 1 degrees of freedom and noncentral parameter,(
e −1",5. Local Private Goodness of Fit,[0],[0]
e +d−1 )2∑d j=1 ∆2j,5. Local Private Goodness of Fit,[0],[0]
"p̌0j .
",5. Local Private Goodness of Fit,[0],[0]
We then base our LDP goodness of fit test on this result to obtain the correct critical value to reject the null hypothesis based on a chi-square distribution.,5. Local Private Goodness of Fit,[0],[0]
The test is presented in Algorithm 3.,5. Local Private Goodness of Fit,[0],[0]
"The following result is immediate from the
Algorithm 3 Local DP GOF Test: LocalGenRRGOF
Input: x = (x1, · · · ,xn), , α, H0 : p = p0.",5. Local Private Goodness of Fit,[0],[0]
Let p̌0 = 1e,5. Local Private Goodness of Fit,[0],[0]
"+d−1 ( e p0 + (1− p0) ) .
",5. Local Private Goodness of Fit,[0],[0]
Let,5. Local Private Goodness of Fit,[0],[0]
"Ȟ = ∑n i=1MGenRR(xi, ).
",5. Local Private Goodness of Fit,[0],[0]
"Set q = ∑d j=1 (Ȟj−np̌0j ) 2
np̌0j
if q > χ2d−1,1−α Decision←",5. Local Private Goodness of Fit,[0],[0]
Reject.,5. Local Private Goodness of Fit,[0],[0]
else Decision←,5. Local Private Goodness of Fit,[0],[0]
"Fail to Reject.
",5. Local Private Goodness of Fit,[0],[0]
"Output: Decision
generalized randomized response mechanism being -DP and the fact that we use it as a local randomizer.
",5. Local Private Goodness of Fit,[0],[0]
Theorem 5.4.,5. Local Private Goodness of Fit,[0],[0]
"LocalGenRRGOF is -LDP.
",5. Local Private Goodness of Fit,[0],[0]
Testing with Bit Flipping.,5. Local Private Goodness of Fit,[0],[0]
"Note that the noncentral parameter in Theorem 5.3 goes to zero as d grows large due
to the coefficient being (
e −1 e +d−1
)2 .",5. Local Private Goodness of Fit,[0],[0]
"Thus, for large dimen-
sional data the generalized randomized response cannot reject a false null hypothesis.",5. Local Private Goodness of Fit,[0],[0]
"We next consider another differentially private algorithmM : {e1, · · · , ed} → {0, 1}d, given in Algorithm 4 used in (Bassily & Smith, 2015) that flips each bit with some biased probability.",5. Local Private Goodness of Fit,[0],[0]
"1
Algorithm 4 Bit Flip Local Randomizer:Mbit Input: x ∈ {e1, · · · , ed}, .
for j ∈",5. Local Private Goodness of Fit,[0],[0]
"[d] do Set zj = xj with probability e /2
e /2+1 , otherwise zj =
(1− xj).",5. Local Private Goodness of Fit,[0],[0]
"end for
Output: z
Theorem 5.5.",5. Local Private Goodness of Fit,[0],[0]
"The algorithmMbit is -DP.
",5. Local Private Goodness of Fit,[0],[0]
"We then want to form a statistic based on the output z ∈ {0, 1}d that is asymptotically distributed as a chi-square under the null hypothesis.",5. Local Private Goodness of Fit,[0],[0]
"We defer the proof to the supplementary material.
",5. Local Private Goodness of Fit,[0],[0]
Lemma 5.6.,5. Local Private Goodness of Fit,[0],[0]
"Consider X i ∼ Multinomial(1, p) for each",5. Local Private Goodness of Fit,[0],[0]
i ∈,5. Local Private Goodness of Fit,[0],[0]
[n].,5. Local Private Goodness of Fit,[0],[0]
We define the following covariance matrix Σ(p) and mean vector p̃ =,5. Local Private Goodness of Fit,[0],[0]
"[(
e /2−1)p+1] e /2+1 , in terms of α = ( e /2−1 e /2+1 ) Σ(p) =α2 [Diag (p)− p (p) ᵀ ]",5. Local Private Goodness of Fit,[0],[0]
"+
e /2( e /2 + 1 )2",5. Local Private Goodness of Fit,[0],[0]
Id (5),5. Local Private Goodness of Fit,[0],[0]
"The histogram H̃ = ∑n i=1Mbit(X i) has the following
asymptotic distribution √ n",5. Local Private Goodness of Fit,[0],[0]
( H̃ n,5. Local Private Goodness of Fit,[0],[0]
"− p̃ ) D→ N (0,Σ(p)) .",5. Local Private Goodness of Fit,[0],[0]
"Further, Σ(p) is invertible for any > 0 and p > 0.
",5. Local Private Goodness of Fit,[0],[0]
"Following a similar analysis in (Kifer & Rogers, 2017), we can form the following statistic for null hypothesis H0 : p = p0 in terms of the histogram H̃ and projection matrix Π = Id − 1d11 ᵀ, as well as the covariance Σ = Σ ( p0 )
and mean p̃0 both given in (5) where we replace p with p0:
T (n)",5. Local Private Goodness of Fit,[0],[0]
"BitFlip ( ) = n
( H̃
n",5. Local Private Goodness of Fit,[0],[0]
"− p̃0
)ᵀ ΠΣ−1Π ( H̃
n",5. Local Private Goodness of Fit,[0],[0]
"− p̃0
) (6)
We can then design a hypothesis test based on the outputs fromMbit in Algorithm 5 Theorem 5.7.",5. Local Private Goodness of Fit,[0],[0]
"LocalBitFlipGOF is -LDP.
",5. Local Private Goodness of Fit,[0],[0]
"1Special thanks to Adam Smith for recommending to use this particular algorithm.
",5. Local Private Goodness of Fit,[0],[0]
"Algorithm 5 Local DP GOF Test: LocalBitFlipGOF
Input: x = (x1, · · · ,xn), , α, H0 : p = p0.",5. Local Private Goodness of Fit,[0],[0]
"Let H̃ = ∑n i=1Mbit(xi, ).
",5. Local Private Goodness of Fit,[0],[0]
"Set q = T(n)BitFlip ( ) if q > χ2d−1,1−α",5. Local Private Goodness of Fit,[0],[0]
Decision← Reject.,5. Local Private Goodness of Fit,[0],[0]
else Decision←,5. Local Private Goodness of Fit,[0],[0]
"Fail to Reject.
",5. Local Private Goodness of Fit,[0],[0]
"Output: Decision
We now show that the statistic in (6) is asymptotically distributed as χ2d−1, with proof in the supplementary file.",5. Local Private Goodness of Fit,[0],[0]
Theorem 5.8.,5. Local Private Goodness of Fit,[0],[0]
"If the null hypothesis H0 : p = p0 holds, then the statistic T(n)BitFlip ( ) is asymptotically distributed as a chisquare, i.e. T(n)BitFlip ( ) D→ χ2d−1.",5. Local Private Goodness of Fit,[0],[0]
"Further, if we consider the alternate H1 : p = p1 then T (n) BitFlip ( ) converges in distribution to a noncentral chi-square with d−1 degrees of freedom and noncentral parameter ( e /2−1 e /2+1 )2 ·∆ᵀΣ(p0)−1∆.
Comparison of Noncentral Parameters.",5. Local Private Goodness of Fit,[0],[0]
"We now compare the noncentral parameters of the three local private tests we presented in Algorithms 1, 3 and 5.",5. Local Private Goodness of Fit,[0],[0]
"We consider the null hypothesis p0 = (1/d, · · · , 1/d) for d > 2, and alternate H1 : p = p
0 + ∆√ n .",5. Local Private Goodness of Fit,[0],[0]
"In this case, we can easily compare the various noncentral parameters for various privacy parameters and dimensions d.",5. Local Private Goodness of Fit,[0],[0]
In Figure 1 we give the coefficient to the term ∆ᵀ∆ in the noncentral parameter of the asymptotic distribution for each local private test presented thus far.,5. Local Private Goodness of Fit,[0],[0]
"The larger this coefficient is, the better the power will be for any alternate ∆ vector.",5. Local Private Goodness of Fit,[0],[0]
"Note that in LocalNoiseGOF, we set ρ = 2/8 which makes the variance the same as for a random variable distributed as Lap(2/ ) for an -DP guarantee – recall that LocalNoiseGOF with Gaussian noise does not satisfy -DP for any > 0.",5. Local Private Goodness of Fit,[0],[0]
"We give results for ∈ {1, 2, 3, 4} which are all in the range of privacy parameters that have been considered in actual locally differentially private algorithms used in practice.2 From
2In (Erlingsson et al., 2014), we know that Google uses = ln(3) in RAPPOR and from Aleksandra Korolova’s Twitter post on Sept. 13, 2016 https://twitter.com/korolova/
the plots, we see how LocalGenRRGOF may outperform LocalBitFlipGOF depending on the privacy parameter and dimension of the data.",5. Local Private Goodness of Fit,[0],[0]
We can use these plots to determine which test to use given and the dimension of data d.,5. Local Private Goodness of Fit,[0],[0]
"When H0 is not uniform, we can use the noncentral parameters given for each test to find the test with the largest noncentral parameter for a particular privacy budget .
",5. Local Private Goodness of Fit,[0],[0]
Empirical Results.,5. Local Private Goodness of Fit,[0],[0]
"We then empirically compare the power between LocalNoiseGOF with Laplace noise in Algorithm 1, LocalGenRRGOF in Algorithm 3, and LocalBitFlipGOF in Algorithm 5.",5. Local Private Goodness of Fit,[0],[0]
Recall that all three of these tests have the same privacy benchmark of local differential privacy.,5. Local Private Goodness of Fit,[0],[0]
"For LocalNoiseGOF with Laplace noise, we will use m = 999 samples in our Monte Carlo simulations.",5. Local Private Goodness of Fit,[0],[0]
"In our experiments we fix α = 0.05 and ∈ {1, 2, 4}.",5. Local Private Goodness of Fit,[0],[0]
"We then consider null hypotheses of the form p0 = (1/d, 1/d, · · · , 1/d) and alternate H1 : p = p0 + η(1,−1, · · · , 1,−1) for some η > 0.",5. Local Private Goodness of Fit,[0],[0]
"In Figure 2, we plot the number of times our tests correctly rejects the null hypothesis in 1000 independent trials for various sample sizes n and privacy parameters .",5. Local Private Goodness of Fit,[0],[0]
"From Figure 2, we can see that the test statistics that have the largest noncentral parameter for a particular dimension d and privacy parameter will have the best empirical power.",5. Local Private Goodness of Fit,[0],[0]
"When d = 4, we see that LocalGenRRGOF performs the best.",5. Local Private Goodness of Fit,[0],[0]
"However, for d = 40 it is not so clear cut.",5. Local Private Goodness of Fit,[0],[0]
"When = 4, we can see that LocalGenRRGOF does the best, but then when = 2, LocalBitFlipGOF does best.",5. Local Private Goodness of Fit,[0],[0]
"Thus, the best Local DP Goodness of Fit test depends on the noncentral parameter, which is a function of , the null hypothesis p0, and alternate p = p0 + ∆. Note that the worst local DP test also depends on the privacy parameter and the dimension d. Based on our empirical results, we see that no single locally private test is best for all data dimensions.",5. Local Private Goodness of Fit,[0],[0]
"However, knowing the corresponding noncentral parameter for a given problem is useful in determining which tests to use.",5. Local Private Goodness of Fit,[0],[0]
"Indeed, the larger the noncentral parameter is the higher the power will be.
",5. Local Private Goodness of Fit,[0],[0]
"status/775801259504734208, Apple uses = 1, 4.",5. Local Private Goodness of Fit,[0],[0]
"Our techniques can be extended to include composite hypothesis tests, where we test whether the data comes from a whole family of probability distributions.",6. Local Private Independence Tests,[0],[0]
"We will focus on independence testing, but much of the theory can be extended to general chi-square tests.",6. Local Private Independence Tests,[0],[0]
"We will closely follow the presentation and notation as in (Kifer & Rogers, 2017).
",6. Local Private Independence Tests,[0],[0]
"We consider two multinomial random variables {U `}n`=1
i.i.d.∼ Multinomial(1,π(1)) for π(1) ∈",6. Local Private Independence Tests,[0],[0]
"Rr, {V `}n`=1
i.i.d.∼ Multinomial(1,π(2)) for π(2) ∈",6. Local Private Independence Tests,[0],[0]
Rc and no component of π(1) or π(2) is zero and each sums to 1.,6. Local Private Independence Tests,[0],[0]
"Without loss of generality, we will consider an individual to be in one of r groups who reports a data record that is in one of c categories.",6. Local Private Independence Tests,[0],[0]
"The collected data consists of n joint outcomes H whose (i, j)th coordinate is Hi,j = ∑n `=1 1{U`,i = 1 & V`,j = 1}.",6. Local Private Independence Tests,[0],[0]
Note that H is then the contingency table over the joint outcomes.,6. Local Private Independence Tests,[0],[0]
"Under the null hypothesis of independence between {U `}n`=1 and {V `}n`=1, for probability vector p(π(1),π(2)) = π(1) ( π(2) )ᵀ , we have
H ∼ Multinomial ( n,p(π(1),π(2)) )",6. Local Private Independence Tests,[0],[0]
"What makes this test difficult is that the analyst does not know the data distribution p(π(1),π(2)) and so cannot simply plug it into the chi-square statistic.",6. Local Private Independence Tests,[0],[0]
"Rather, we use the data to estimate the best guess for the unknown probability distribution that satisfies the null hypothesis.",6. Local Private Independence Tests,[0],[0]
"Note that without privacy, each individual ` ∈",6. Local Private Independence Tests,[0],[0]
[n] is reporting a r × c matrixX ` which would be 1 in exactly one location.,6. Local Private Independence Tests,[0],[0]
Thus we can alternatively write the contingency table as H = ∑n `=1X `.,6. Local Private Independence Tests,[0],[0]
We then use the three local private algorithms we presented earlier to see how we can form a private chi-square statistic for independence testing.,6. Local Private Independence Tests,[0],[0]
We want to be able to ensure the privacy of both the group and the category that each individual belongs to.,6. Local Private Independence Tests,[0],[0]
"Due to space we will only cover private independence tests that use the generalized randomized response mechanism from Algorithm 2 and the
bit flipping local randomizer from Algorithm 4.",6. Local Private Independence Tests,[0],[0]
"We defer our independence test with noise addition in the local setting to the supplementary file.
",6. Local Private Independence Tests,[0],[0]
Testing with Generalized Randomized Response.,6. Local Private Independence Tests,[0],[0]
We want to design an independence test when the data is generated from MGenRR given in Algorithm 2.,6. Local Private Independence Tests,[0],[0]
"In this case our contingency table can be written as Ȟ ∼ Multinomial ( n, p̌(π(1),π(2)) )",6. Local Private Independence Tests,[0],[0]
where β = 1e,6. Local Private Independence Tests,[0],[0]
"+rc−1 and we use (3) to get
p̌(π(1),π(2))",6. Local Private Independence Tests,[0],[0]
= β,6. Local Private Independence Tests,[0],[0]
"( (e − 1)π(1) ( π(2) )ᵀ + 1 ) (7)
We then obtain an estimate for the unknown parameters,
π̌(1) = 1
β (e − 1) ( Ȟi,· n",6. Local Private Independence Tests,[0],[0]
− cβ : i ∈,6. Local Private Independence Tests,[0],[0]
"[r] ) ,
π̌(2) = 1
β (e − 1) ( Ȟ·,j n",6. Local Private Independence Tests,[0],[0]
− rβ :,6. Local Private Independence Tests,[0],[0]
j ∈,6. Local Private Independence Tests,[0],[0]
"[c] )
Ť (n)GenRR ( ) = ∑",6. Local Private Independence Tests,[0],[0]
"i,j
( Ȟi,j − np̌i,j ( π̌(1), π̌(2) ))",6. Local Private Independence Tests,[0],[0]
"2 np̌i,j(π̌ (1), π̌(2)) (8)
We can then prove the following result, where the full proof is in the supplementary file.
",6. Local Private Independence Tests,[0],[0]
Theorem 6.1.,6. Local Private Independence Tests,[0],[0]
"Assuming U and V are independent with true probability vectors π(1),π(2) > 0 respectively, then as n→∞ we have Ť (n)GenRR ( ) D→ χ2(r−1)(c−1).
",6. Local Private Independence Tests,[0],[0]
"We then use this result to design Algorithm 6.
Theorem 6.2.",6. Local Private Independence Tests,[0],[0]
"LocalGenRRIND is -LDP.
",6. Local Private Independence Tests,[0],[0]
Testing with Bit Flipping.,6. Local Private Independence Tests,[0],[0]
"Lastly, we design an independence test when the data is reported via Mbit in Algorithm 4.",6. Local Private Independence Tests,[0],[0]
"Assuming that H = ∑n `=1X ` ∼
Algorithm 6 Local DP IND Test: LocalGenRRIND
Input: x = (x1, · · · ,xn), , α, H0 : p = p0.",6. Local Private Independence Tests,[0],[0]
"Let Ȟ = ∑n i=1MGenRR(xi, ).
",6. Local Private Independence Tests,[0],[0]
"Set q = Ť (n)GenRR ( ) from (8) if q > χ2d−1,1−α, Decision← Reject.",6. Local Private Independence Tests,[0],[0]
else Decision←,6. Local Private Independence Tests,[0],[0]
"Fail to Reject.
",6. Local Private Independence Tests,[0],[0]
"Output: Decision
Multinomial ( n,p(π(1),π(2)) )",6. Local Private Independence Tests,[0],[0]
", then we know that replacing p0 with p(π(1),π(2))",6. Local Private Independence Tests,[0],[0]
"in Section 5 gives us the following asymptotic distribution (treating the contingency table of values as a vector) with covariance matrix Σ(·) given in (5)
",6. Local Private Independence Tests,[0],[0]
√ n H̃n −  ( e /2,6. Local Private Independence Tests,[0],[0]
− 1 e /2,6. Local Private Independence Tests,[0],[0]
+ 1 ) π(1) ( π(2) )ᵀ,6. Local Private Independence Tests,[0],[0]
"+
1
e /2",6. Local Private Independence Tests,[0],[0]
"+ 1︸ ︷︷ ︸ p̃(π(1),π(2))
 
",6. Local Private Independence Tests,[0],[0]
"D→ N ( 0,Σ ( π(1) ( π(2) )ᵀ)) (9)
Similar to analysis for Theorem 6.1, we start with a rough estimate for the unknown parameters which converges in probability to the true estimates, so we use α =",6. Local Private Independence Tests,[0],[0]
"( e /2−1 e /2+1 ) to get
π̃ (1) =
( 1
α )( H̃i,· n",6. Local Private Independence Tests,[0],[0]
− c e /2,6. Local Private Independence Tests,[0],[0]
+ 1 : i ∈,6. Local Private Independence Tests,[0],[0]
"[r] )
π̃ (2) =
( 1
α )( H̃·,j n",6. Local Private Independence Tests,[0],[0]
− r e /2,6. Local Private Independence Tests,[0],[0]
+ 1,6. Local Private Independence Tests,[0],[0]
: j ∈,6. Local Private Independence Tests,[0],[0]
"[c] ) (10)
We then give the resulting statistic, parameterized by the unknown parameters π(`), for ` ∈ {1, 2}.",6. Local Private Independence Tests,[0],[0]
"For middle matrix
M̃ = ΠΣ ( π̃ (1) ( π̃ (2) )",6. Local Private Independence Tests,[0],[0]
"ᵀ)−1 Π, we have
T̃ (n)
",6. Local Private Independence Tests,[0],[0]
"BitFlip
( θ(1), θ(2); )",6. Local Private Independence Tests,[0],[0]
"= 1
n
( H̃ − np̃ ( θ(1), θ(2) ))",6. Local Private Independence Tests,[0],[0]
"ᵀ M̃ ( H̃ − np̃ ( θ(1), θ(2) ))",6. Local Private Independence Tests,[0],[0]
"(11)
Minimizing T̃ (n)
",6. Local Private Independence Tests,[0],[0]
"BitFlip
( θ(1), θ(2); ) over (θ(1), θ(2)) results in
a statistic that is distributed as a chi-square random variable, we defer the full proof to the supplementary file.",6. Local Private Independence Tests,[0],[0]
Theorem 6.3.,6. Local Private Independence Tests,[0],[0]
"Under the null hypothesis where U and V are independent with true probability vectors π(1),π(2) > 0 respectively, then we have as n → ∞,
minθ(1),θ(2)
{ T̃ (n)
BitFlip
( θ(1), θ(2); )}",6. Local Private Independence Tests,[0],[0]
D→ χ2(r−1)(c−1).,6. Local Private Independence Tests,[0],[0]
We present the test in Algorithm 7.,6. Local Private Independence Tests,[0],[0]
The following result follows from same privacy analysis as before.,6. Local Private Independence Tests,[0],[0]
Theorem 6.4.,6. Local Private Independence Tests,[0],[0]
"LocalBitFlipIND is -LDP.
",6. Local Private Independence Tests,[0],[0]
Algorithm 7 Local DP IND Test: LocalBitFlipIND,6. Local Private Independence Tests,[0],[0]
"Input: (x1, · · · ,xn), , α.
Let H̃ = ∑n i=1Mbit(xi, ).
",6. Local Private Independence Tests,[0],[0]
"q = minπ(1),π(2)
{ T̃ (n)
BitFlip
( π(1),π(2); )} from (11).
",6. Local Private Independence Tests,[0],[0]
"if q > χ2(r−1)(c−1),1−α Decision← Reject.",6. Local Private Independence Tests,[0],[0]
else Decision←,6. Local Private Independence Tests,[0],[0]
"Fail to Reject.
",6. Local Private Independence Tests,[0],[0]
"Output: Decision
Empirical Results.",6. Local Private Independence Tests,[0],[0]
"As we did for the goodness of fit tests, we empirically compare the power for our various tests for independence.",6. Local Private Independence Tests,[0],[0]
We consider the null hypothesis that the two sequences of categorical random variables {U `}n`=1 and {V `}n`=1 are independent of one another.,6. Local Private Independence Tests,[0],[0]
"Under an alternate hypothesis, we generate the contingency data according to a non-product distribution.",6. Local Private Independence Tests,[0],[0]
"We fix the distribution p1 for the contingency table to be of the following form, where π(1) ∈",6. Local Private Independence Tests,[0],[0]
"Rr is the unknown distribution for {U `}n`=1, π(2) ∈",6. Local Private Independence Tests,[0],[0]
"Rc is the unknown distribution for {V `}n`=1, and r, c are even
p1 = π(1) ( π(2) )ᵀ + η(1,−1, · · · ,−1, 1)ᵀ(1,−1, · · · ,−1, 1) (12)
Note that the hypothesis test does not know the underlying π(i) for i ∈ {1, 2}, but to generate the data we must fix these distributions.",6. Local Private Independence Tests,[0],[0]
We show power results when the marginal distributions satisfy π(1) =,6. Local Private Independence Tests,[0],[0]
"(1/r, · · · , 1/r) and π(2) =",6. Local Private Independence Tests,[0],[0]
"(1/c, · · · , 1/c).",6. Local Private Independence Tests,[0],[0]
"In Figure 2, we give results for various n and ∈ {1, 2, 4} .",6. Local Private Independence Tests,[0],[0]
"We have designed several hypothesis tests, each depending on different local differentially private algorithms.",7. Conclusion,[0],[0]
We showed that each statistic has a noncentral chi-square distribution when the data is drawn from some alternate hypothesis H1.,7. Conclusion,[0],[0]
"Depending on the form of the alternate probability distribution, the dimension of the data, and the privacy parameter, either LocalGenRRGOF or LocalBitFlipGOF gave the best power.",7. Conclusion,[0],[0]
"This corroborates the results from Kairouz et al. (2014) who showed that in hypothesis testing, different privacy regimes have different optimal local differentially private mechanisms, although utility in their work was in terms of KL divergence.",7. Conclusion,[0],[0]
Our results show that the power of the test is directly related to the noncentral parameter of the test statistic that is used.,7. Conclusion,[0],[0]
"This requires the data analyst to carefully consider alternate hypotheses, as well as the data dimension and privacy parameter for a particular test and then see which test statistic results in the largest noncentral parameter.",7. Conclusion,[0],[0]
Marco Gaboardi has been partially supported by NSF under grant TWC-1565365.,Acknowledgements,[0],[0]
The local model for differential privacy is emerging as the reference model for practical applications of collecting and sharing sensitive information while satisfying strong privacy guarantees.,abstractText,[0],[0]
"In the local model, there is no trusted entity which is allowed to have each individual’s raw data as is assumed in the traditional curator model.",abstractText,[0],[0]
Individuals’ data are usually perturbed before sharing them.,abstractText,[0],[0]
"We explore the design of private hypothesis tests in the local model, where each data entry is perturbed to ensure the privacy of each participant.",abstractText,[0],[0]
"Specifically, we analyze locally private chi-square tests for goodness of fit and independence testing.",abstractText,[0],[0]
Local Private Hypothesis Testing: Chi-Square Tests,title,[0],[0]
"Bayesian networks have been used in classification (Aliferis et al., 2010), feature selection (Gao et al., 2015), latent variable discovery (Lazic et al., 2013; Gao & Ji, 2016a), and knowledge discovery (Spirtes et al., 1999; Gao & Ji, 2015) in various domains (Ott et al., 2004).",1. Introduction,[0],[0]
"However, due to its NP-hard nature (Chickering et al., 2012), exact BN structure learning on directed acyclic graphs (DAG) faces scalability issues.
",1. Introduction,[0],[0]
"In this paper, we consider a local-to-global approach to learn the Bayesian network structure, starting from the local graph structure of one node and then gradually expanding the graph based on already learned structures.
",1. Introduction,[0],[0]
"1IBM Thomas J. Watson Research Center, Yorktown Heights, NY 10598 USA.",1. Introduction,[0],[0]
"Correspondence to: Tian Gao <tgao@us.ibm.com>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"The predominant exact score-based structure learning algorithms adopt the global approach and focus on better scoring criteria (Acid et al., 2005; Brenner & Sontag, 2013) or more efficient search procedures (Chickering, 2002; Koivisto & Sood, 2004; Silander & Myllymaki, 2006; Jaakkola et al., 2010; Cussens, 2011; Yuan & Malone, 2013) to navigate the intractable search space of possible directed acyclic graphs over all the variables present.",1. Introduction,[0],[0]
"Despite such progress, the practical usage of these algorithms is still limited when there are large numbers of variables.",1. Introduction,[0],[0]
"Many approximations (Scanagatta et al., 2015), constraints (de Campos et al., 2009; Chen et al., 2016), and assumptions (Nie et al., 2014) are utilized to alleviate time and memory complexity.
",1. Introduction,[0],[0]
"Instead of searching the entire DAG space for all the variables at the same time, the local-to-global approach limits the size of the space by learning a local structure with only a limited number of variables.",1. Introduction,[0],[0]
"These variables consists of potential candidates for local structures, usually defined by the parent-child (PC) or the Markov Blanket (MB) (Pearl, 1988) set of a target node in a DAG.",1. Introduction,[0],[0]
"Many local learning algorithms (Koller & Sahami, 1996; Tsamardinos et al., 2003; Fu & Desmarais, 2008) iteratively query new variables to update and learn the local structure, either PC, MB set or both, for one specific target variable.",1. Introduction,[0],[0]
"Many constraint-based and score-based local learning algorithms have been proposed and shown to have promising performances in practice (Aliferis et al., 2010).",1. Introduction,[0],[0]
"Using learned local structures, some prior works have proposed to combine the local structures for the global structure.",1. Introduction,[0],[0]
"Several works (Margaritis & Thrun, 1999; Pellet & Ellisseeff, 2008) have proposed algorithms to identify MBs of every node in the graph first, and then connect the MBs in a maximally consistent way to learn the global structure of a BN.",1. Introduction,[0],[0]
"Both constraint-based (Tsamardinos et al., 2006) and score-based local-to-global structure learning methods (Niinimaki & Parviainen, 2012) have been proposed.",1. Introduction,[0],[0]
"This local-to-global approach has the benefit of improving the exact structure learning efficiency, as at each step only a small number of variables are expected to be used, although the accuracy has not been very competitive.
",1. Introduction,[0],[0]
We aim to improve the accuracy of the local-to-global approach and propose a new local-to-global structure learning algorithm.,1. Introduction,[0],[0]
"The algorithm starts the local learning at one
variable first, and then iteratively applies the local learning procedure to its neighbors and so on, gradually expanding the learned graph with minimal repeated learning.",1. Introduction,[0],[0]
"GGSL efficiently grows local graphs to global graphs without considering the traditional the AND-rule, or a consistency check on learned local neighborhoods.",1. Introduction,[0],[0]
"It uses only the necessary variables for each local learning step to learn and resolve any possible conflicts among local structures, hence improving efficiency over global learning algorithms and improving accuracy over existing local-to-global algorithms with the AND-rule.
",1. Introduction,[0],[0]
"Notation: We use capital letters (such asX,Y ) to represent variables, small letters (such as x, y) to represent values of variables, and bold letters (such as V,MB) to represent variable sets.",1. Introduction,[0],[0]
"|V| represents the size of a set V. X ⊥ Y and X ⊥\⊥ Y represent independence and dependence between X and Y , respectively.",1. Introduction,[0],[0]
Let V denote a set of random variables.,2. Technical Preliminaries,[0],[0]
"A Bayesian Network for V is represented by a pair (G, θ).",2. Technical Preliminaries,[0],[0]
"The network structure G is a directed acyclic graph with nodes corresponding to the random variables in V. If a directed edge exists from node X to node Y in G, X is a parent of Y and Y is a child of X .",2. Technical Preliminaries,[0],[0]
The parameters θ indicate the conditional probability distribution of each node X ∈ V given its parents.,2. Technical Preliminaries,[0],[0]
"Moreover, let a path between two nodes X and Y in G be any sequence of nodes between them such that any successive nodes are connected by a directed edge, and no node appears in the sequence twice.",2. Technical Preliminaries,[0],[0]
"A directed path of a DAG is a path with nodes (V1, ..., Vn) such that, for 1 ≤",2. Technical Preliminaries,[0],[0]
"i < n, Vi is a parent of Vi+1.",2. Technical Preliminaries,[0],[0]
"If there is a directed path from X to Y , then X is an ancestor of Y and Y is a descendant of X .",2. Technical Preliminaries,[0],[0]
"If X and Y have a common child and they are not adjacent, X and Y are spouses of each other.",2. Technical Preliminaries,[0],[0]
"Three nodes X , Y , and Z form a V-structure if node Y has two incoming edges from X and Z, forming X → Y ← Z, and X is not adjacent to Z. Y is a collider if Y has two incoming edges from X and Z in a path.",2. Technical Preliminaries,[0],[0]
"A path J from node X to Y is blocked by a set of nodes Z, if any of following holds true: 1)",2. Technical Preliminaries,[0],[0]
There is a non-collider node in J belonging to Z. 2),2. Technical Preliminaries,[0],[0]
"There is a collider node C on J such that neither C nor any of its descendants belong to Z. Otherwise, J from X to Y is unblocked or active.
",2. Technical Preliminaries,[0],[0]
"The Local Markov Condition (Pearl, 1988) states a node in a BN is independent of its non-descendant nodes, given its parents.",2. Technical Preliminaries,[0],[0]
"It enables the recovery of a distribution P (in term of independence relationships) from a known DAG G. A DAG G and a joint distribution P are faithful to each other if all and only the conditional independencies true in P are entailed by G (Pearl, 1988).",2. Technical Preliminaries,[0],[0]
"The faithfulness condition enables us to recover a DAG G from a distribution P
to completely characterize P .
",2. Technical Preliminaries,[0],[0]
"A Markov Blanket of a target variable T , MBT , is the minimal set of nodes conditioned on which all other nodes are independent of T , denoted as X ⊥ T |MBT ,∀X ∈ {V \ T \MBT }.",2. Technical Preliminaries,[0],[0]
Given independently and identically distributed (i.i.d.),2. Technical Preliminaries,[0],[0]
"samples D from an unknown distribution P , represented by a faithful but unknown DAG G0 to P , local structure learning is to find the PC or MB of a target node inG0.",2. Technical Preliminaries,[0],[0]
"To avoid symbol confusion, we useG to represent any learned DAG and use G0 to represent the ground truth DAG.",2. Technical Preliminaries,[0],[0]
"Under the faithfulness assumption between G0 and P , the PC and MB of a target node is uniquely identifiable (Pearl, 1988).",2. Technical Preliminaries,[0],[0]
"For example, in Figure 1a, nodes A and D form PCB .",2. Technical Preliminaries,[0],[0]
"MBB contains its parent node A, its child D, and its spouse C. All other nodes E, F , and H are independent of B, given MBB , due to blocked paths.
",2. Technical Preliminaries,[0],[0]
"Score-based structure learning algorithms rely on some score criteria s to learn a best-fitting DAG G for data D. Score s(G,D) of a BN DAG structure G measures the goodness of fit of G on D. Let G be any BN structure and G′ be the same structure as G but with an edge from a node T to a node X .",2. Technical Preliminaries,[0],[0]
"Let PaGX be the parent set of X in G. Score s is locally consistent if, as the size of the data D goes to infinity, the following two properties hold true: 1) if X ⊥\⊥ T |PaGX , then s(G,D) < s(G′, D), and 2) if X ⊥ T |PaGX , then s(G,D) > s(G′, D).",2. Technical Preliminaries,[0],[0]
"In addition, s is score equivalent if Markov equivalent DAGs have the same score.",2. Technical Preliminaries,[0],[0]
s is decomposable if it is a sum of each node’s individual score that depends on only this node and its parents.,2. Technical Preliminaries,[0],[0]
"Commonly used Bayesian score criteria, such as BDeu, are decomposable, consistent, locally consistent (Chickering, 2002), and score equivalent (Heckerman et al., 1995).",2. Technical Preliminaries,[0],[0]
"We assume the Markov condition, faithfulness condition, and the infinite data size hold in the theoretical analysis part of
the paper.
",2. Technical Preliminaries,[0],[0]
"Lastly, one of the main concepts in the topology-based MB algorithms is the symmetry constraint, or the AND-rule.
",2. Technical Preliminaries,[0],[0]
Lemma 1.,2. Technical Preliminaries,[0],[0]
AND-Rule.,2. Technical Preliminaries,[0],[0]
"For a node X to be adjacent to T in G, both of the following statements hold true: X must be in the PC set of T and T must be in the PC set ofX , i.e.,",2. Technical Preliminaries,[0],[0]
"X ∈ PCGT and T ∈ PC G X .
",2. Technical Preliminaries,[0],[0]
"The local-to-global BN structure learning algorithms generally use the AND-rule to enforce consistency between different learned local structures to obtain a global DAG (Margaritis & Thrun, 1999).",2. Technical Preliminaries,[0],[0]
"Local structure learning algorithms also employ it to guarantee soundness (Niinimaki & Parviainen, 2012).",2. Technical Preliminaries,[0],[0]
"We will first introduce local BN structure learning and provide some new theoretical guarantees, then propose a novel procedure to expand the local graph to the global graph, including some consistency guarantee and the proposed GGSL algorithm.",3. Local-to-Global BN Structure Learning,[0],[0]
"The local-to-global learning approach first uses local structure learning algorithms, either constraint-based (Tsamardinos et al., 2006) or score-based (Niinimaki & Parviainen, 2012), to discover the PC set or the Markov Blanket of the target.",3.1. Local Structure Learning,[0],[0]
"The arguably state-of-art algorithms to find the local structure of Bayesian network use a scorebased framework (Gao & Ji, 2017), shown in Algorithm 1, LocalLearn.
",3.1. Local Structure Learning,[0],[0]
"In Algorithm 1, subroutine BNStructLearn learns an optimal DAG over a set of variables in the data, and can use any exact global BN structure learning algorithm.",3.1. Local Structure Learning,[0],[0]
"Subroutine findPC and findSpouse extract a variable T ’s PC set (by finding parent set P and children set C) and spouse set given the adjacency matrix of a graph G. LocalLearn first sequentially learns the PC set by repeatedly using BNStructLearn on a set of nodes Z containing the target node T , its current PC set PCT , and one new query variable X .",3.1. Local Structure Learning,[0],[0]
Then it uses a similar procedure to learn the spouse set and update the PC set.,3.1. Local Structure Learning,[0],[0]
"PCGT is guaranteed to contain all the true positive PC nodes of T .
",3.1. Local Structure Learning,[0],[0]
Lemma 2.,3.1. Local Structure Learning,[0],[0]
"Preservation of True Positive PCs (Niinimaki & Parviainen, 2012).",3.1. Local Structure Learning,[0],[0]
"Let G0 be the faithful DAG of distribution P over V, and G be the DAG learned by exact BN structure learning algorithms over the subset of variables ZL ⊆ V at the last iteration of Step 1 of Algorithm 1.",3.1. Local Structure Learning,[0],[0]
Let PCGT be the learned PC set of the target T in G and PC 0 T be the PC set of T inG0.,3.1. Local Structure Learning,[0],[0]
"Under the faithfulness and infinite data assumption, PC0T ⊆ PC G T .
",3.1. Local Structure Learning,[0],[0]
"Algorithm 1 LocalLearn Input: dataset D, target node T {step 1: find the PC set } PCT ← ∅, O← V \ {T}; while O is nonempty do
choose X ∈",3.1. Local Structure Learning,[0],[0]
"O, O← O \ {X}; Z← {T,X} ∪PCT ; G← BNStructLearn (Z, DZ); PCT ,PT ,CT ← findPC(G,T ) ;
end while {step 2: remove false PC nodes and find spouses} ST ← ∅, O← V \PCT ; while O is nonempty do
choose X ∈",3.1. Local Structure Learning,[0],[0]
"O, O← O \ {X}; Z← {T,X} ∪PCT ∪ ST ; G← BNStructLearn (Z, DZ); PCT ,PT ,CT ← findPC(G,T ) ; ST ← findSpouse(G,T ) ;
end while Return: MB← PT ∪CT ∪ ST ;
However, PCGT may contain false positive PC nodes (Aliferis et al., 2010), as shown in Figure 1 of (Niinimaki & Parviainen, 2012).",3.1. Local Structure Learning,[0],[0]
"The iterative nature of Algorithm 1 can potentially violate the faithfulness assumption during the learning, due to absent variables.",3.1. Local Structure Learning,[0],[0]
"Previous analysis (Niinimaki & Parviainen, 2012; Gao & Ji, 2017) conjectured the soundness and completeness of LocalLearn.",3.1. Local Structure Learning,[0],[0]
"Here we provide a new theoretical proofs of these results in the LocalLearn .
",3.1. Local Structure Learning,[0],[0]
Lemma 3.,3.1. Local Structure Learning,[0],[0]
Preservation of Dependence Relationships between T and the Learned PC Set.,3.1. Local Structure Learning,[0],[0]
"Let G0 be the global faithful DAG of P for the entire variable set V, and G be the DAG learned by exact BN structure learning algorithms over a subset of variables of V, VG, present at the last iteration of Step 1 of Algorithm 1.",3.1. Local Structure Learning,[0],[0]
"Then inG0 every variable in the learned PC set PCGT is dependent of the target T, conditioned on any subset of the ground truth PC set: i.e., X ⊥\⊥ T |Z,∀X ∈ PCGT ,∀Z ⊆ PC",3.1. Local Structure Learning,[0],[0]
0 T,3.1. Local Structure Learning,[0],[0]
\,3.1. Local Structure Learning,[0],[0]
"{X}.
",3.1. Local Structure Learning,[0],[0]
Proof.,3.1. Local Structure Learning,[0],[0]
"If X ∈ PC0T , then the lemma holds automatically.",3.1. Local Structure Learning,[0],[0]
"Else if X 6∈ PC0T , assuming ∃X ∈ S such that X ⊥ T |S \ X , where S = VG \ {T}.",3.1. Local Structure Learning,[0],[0]
"Then, one of the following two cases must hold in G: T → X or X → T .",3.1. Local Structure Learning,[0],[0]
"If T → X , since each node in ChildrenX ∪ SpousesX is either 1) not saved during the iterative procedure, or 2) saved as a node of PCGT , in which case it forms a fully connected subgraph with X and T and can be changed to a ParentX .",3.1. Local Structure Learning,[0],[0]
"Then, P (X|S\X) = P (X|PaGX) by MB definition.",3.1. Local Structure Learning,[0],[0]
"Since P (X|S\X,T ) = P (X|S\X) by assumption X ⊥ T |S \ X , then T 6∈ PaX since {S \ X} must contain PaGX .",3.1. Local Structure Learning,[0],[0]
"Then by local consistency removing the edge T → X will increase the score, which contradicts the as-
sumptions.",3.1. Local Structure Learning,[0],[0]
"IfX → T , since P (T |X,S\X) = P (T |S\X) by assumption, then using a similar argument, X 6∈ PaGT and removing the edge X → T will increase the score, which contradicts the assumption.",3.1. Local Structure Learning,[0],[0]
"Hence, X ⊥\⊥ T |S \X .",3.1. Local Structure Learning,[0],[0]
"Since Z ⊆ PC0T \ {X} ⊆ S \ {X}, the lemma holds.
",3.1. Local Structure Learning,[0],[0]
"Lemma 3 shows that the false PC nodes consist of only descendents of T , which is the same as Lemma 3 of (Gao & Ji, 2017) but without conjectured results:
Lemma 4.",3.1. Local Structure Learning,[0],[0]
PC False Positive Identity.,3.1. Local Structure Learning,[0],[0]
"Let PCGT be the learned PC set of the target T in the learned graph G from Step 1 of Algorithm 1, and PC0T be the ground truth PC set in G0.",3.1. Local Structure Learning,[0],[0]
"The false positives F in PCGT consist of only descendants of T inG0, denoted as Des0T , i.e., F ⊆ Des 0 T , F = PCGT \PC 0 T .
",3.1. Local Structure Learning,[0],[0]
Proof.,3.1. Local Structure Learning,[0],[0]
"By Lemma 2, PCGT consists of the entire PC 0 T and some false positives F. We show F ⊆ Des0T .",3.1. Local Structure Learning,[0],[0]
"According to Lemma 3, a node X ∈ F is conditionally dependent of T given any Z ⊆ PC0T",3.1. Local Structure Learning,[0],[0]
\ {X} in G0.,3.1. Local Structure Learning,[0],[0]
"In the last iteration of Step 1, PCGT must contain the true positive parents of T Pa0T , as Pa 0 T ⊆ PC 0 T ⊆ PC G T by Lemma 2.",3.1. Local Structure Learning,[0],[0]
"Therefore, X ⊥\⊥ T |Pa0T .",3.1. Local Structure Learning,[0],[0]
"However, by the Markov condition, all the non-descendant nodes X are independent of T given Pa0T inG0.",3.1. Local Structure Learning,[0],[0]
Hence non-descendantsX cannot be in PCGT by the last iteration.,3.1. Local Structure Learning,[0],[0]
"Thus, F ⊆ Des0T .
",3.1. Local Structure Learning,[0],[0]
"For the sake of complete discussion, we include the following property, showing the existence of unblocked paths:
Lemma 5.",3.1. Local Structure Learning,[0],[0]
Coexistence Between Descendants and Spouses in Score-Based PC Search.,3.1. Local Structure Learning,[0],[0]
"In the learnedG from Step 1 of Algorithm 1, the only false positives F in PCGT belong to the descendants of T , Des0T, due to an unblocked path between T and its descendants via a V-structure T → Child← Spouse in G0.
",3.1. Local Structure Learning,[0],[0]
Proof.,3.1. Local Structure Learning,[0],[0]
"Lemma 4 shows the first part of the lemma is true, and we just need to show the second part holds.",3.1. Local Structure Learning,[0],[0]
"Assuming false positive PC nodes F exist, let X ∈ F ⊆ Des0T , then Lemma 4 shows that X ⊥\⊥ T |Z,∀Z ⊆ PC0T .",3.1. Local Structure Learning,[0],[0]
"For F to exist, X ⊥\⊥ T |PC0T must be true.",3.1. Local Structure Learning,[0],[0]
"Since PC 0 T must be present in all paths from T to X in G0, in the last iteration of the score-based PC search the dependence between T and X occurs only if PC0T unblocks some paths from T to X .",3.1. Local Structure Learning,[0],[0]
This can only happen when there is a collider node in PC0T .,3.1. Local Structure Learning,[0],[0]
"Hence, the only wayX can exist in PC G T is through an unblocked path that contains a V-structure T → child← spouse in G0.
",3.1. Local Structure Learning,[0],[0]
"We show the consistency results of LocalLearn:
Theorem 1.",3.1. Local Structure Learning,[0],[0]
"Under the infinite data and faithfulness assumption, LocalLearn finds all and only the Markov Blanket nodes of the target node.
",3.1. Local Structure Learning,[0],[0]
Proof.,3.1. Local Structure Learning,[0],[0]
"Step 1 of Algorithm 1 returns all of the true positive parents, children, and some descendants, if they exist, by Lemma 4 and Lemma 5.",3.1. Local Structure Learning,[0],[0]
"The tasks left are to add the true positive spouses and remove false positive PC nodes, i.e. the non-child descendants, from PCT .
",3.1. Local Structure Learning,[0],[0]
"First, we show LocalLearn will find all of the true positive spouses.",3.1. Local Structure Learning,[0],[0]
"In Step 2, LocalLearn learns a structure with the target, the current PC set, the current spouse set, and one query variable X ∈",3.1. Local Structure Learning,[0],[0]
O = V \ PCT .,3.1. Local Structure Learning,[0],[0]
"At each step, PCT is a set that has been found to be dependent or conditionally dependent of the target.",3.1. Local Structure Learning,[0],[0]
"Since PCT includes and will always include the true positive PC set by Lemma 2, true positive spouses are conditionally dependent of T given PCT .",3.1. Local Structure Learning,[0],[0]
"Following a similar logic as Lemma 2, S0T must directly connect to the true positive children of T .",3.1. Local Structure Learning,[0],[0]
"Because Step 2 of Algorithm 1 queries every variable in V and S0T must be dependent of nonadjacent T given PC0T , to capture the correct independence relationships with the locally consistent score, S0T must be included in ST .
",3.1. Local Structure Learning,[0],[0]
"Secondly, we show false positive PCs and spouses will be removed.",3.1. Local Structure Learning,[0],[0]
"Since all the true positive PC nodes and spouses are present in the last iteration, the false positive PC nodes (the non-MB descendants by Lemma 4), if exist, should be adjacent to the true positive PC nodes and spouses in G. However, the DAG obtained from G by removing the edge from false positives PC to T would score higher by capturing the same independence relationships (i.e., the descendants are dependent of children and spouse nodes of T and independent of T given the true positive MB set) and the dependence relationships between the true positive MB set and T , but with fewer edges.",3.1. Local Structure Learning,[0],[0]
"Therefore, all false positive PC nodes will be removed from PCT .",3.1. Local Structure Learning,[0],[0]
"Similarly, since all the true positive PC nodes and spouses are present in the last iteration, if there exist false positive spouses F ⊆ SGT \ S0T , F would be parents to some true positive children nodes C0T in G and F ⊥\⊥ T |C.",3.1. Local Structure Learning,[0],[0]
"If so, F should be adjacent to S0T as well in G as every path between C0 and F must go through S0T .",3.1. Local Structure Learning,[0],[0]
"However, the DAG obtained from G by removing the edge from C to F would score higher than G by capturing the same independence relationships but with less edges.",3.1. Local Structure Learning,[0],[0]
"Therefore, there will not be any false positive spouse nodes.
",3.1. Local Structure Learning,[0],[0]
"Thus, PCT and S will contain all and only the true PC and spouses.",3.1. Local Structure Learning,[0],[0]
Their union contains all and only the MB nodes.,3.1. Local Structure Learning,[0],[0]
"Therefore, LocalLearn is sound and complete.
",3.1. Local Structure Learning,[0],[0]
"Note that the learned parent set P and children set C from LocalLearn themselves may not be sound or complete, due to Markov equivalence, even though their joint set is sound and complete.",3.1. Local Structure Learning,[0],[0]
"Using the local structures, one alternative approach to global structure learning is to learn the local structures of all nodes and then combine them to construct the global graph structure from the existing local graphs.",3.2. Local-to-Global Learning,[0],[0]
"Many algorithms (Margaritis & Thrun, 1999; Niinimaki & Parviainen, 2012) first use the AND-rule to resolve the potential conflicts among different local structures between adjacent variables, and then use the Meek rules (Meek, 1995) to obtain the final DAG.",3.2. Local-to-Global Learning,[0],[0]
"The AND-rule seems arbitrary in the learning results and can introduce errors if one of the neighbors learns a wrong local graph, hence affecting the accuracy of the final global graph.",3.2. Local-to-Global Learning,[0],[0]
One naive way to solve such conflicts is to re-run the subroutine BNStructLearn on the variable set containing both neighbor sets to redetermine the existence of the edges.,3.2. Local-to-Global Learning,[0],[0]
"However, the procedure is inefficient as it repeats learning for local structures of every edge after repeating for every node, relearning the same parts of the graph multiple times.
",3.2. Local-to-Global Learning,[0],[0]
"We propose to anchor the learning at one target variable T , and then grow the graph by gradually expanding it.",3.2. Local-to-Global Learning,[0],[0]
"It is made possible as the LocalLearn does not require neighbors’ local structure to learn T ’s neighborhood correctly, unlike previous algorithms.",3.2. Local-to-Global Learning,[0],[0]
We only use the necessary variables at each iteration to expand the graph while keeping other parts of the learned graph fixed.,3.2. Local-to-Global Learning,[0.9523051635463442],['We first propose one simple method to get around the assumption of complete annotation – train separate CRFs for the label set of each dataset.']
The proposed graph growing structure learning (GGSL) algorithm is shown in Algorithm 2.,3.2. Local-to-Global Learning,[0],[0]
"Starting from an empty graph, GGSL iteratively updates the global graph by using LocalLearn to learn the local structure of one target variable T at a time.",3.2. Local-to-Global Learning,[0],[0]
Each local learning uses the set consisting of the current local variables of the target variable in the learned graph G and variables that are not in the local structures of any variable.,3.2. Local-to-Global Learning,[0],[0]
Then GGSL updates G with learned results using updateGraph.,3.2. Local-to-Global Learning,[0],[0]
"It runs until all but one variable is not learned and has four main steps:
",3.2. Local-to-Global Learning,[0],[0]
"Step 1: GGSL chooses one target variable T at each iteration, first chosen randomly and then based on query set Q, which contains adjacent nodes of the already queried variables in the graph G. Q can be maintained as a regular queue (first in, first out).",3.2. Local-to-Global Learning,[0],[0]
"Queried variable set A keeps all the learned T s and prevents repeated learning.
",3.2. Local-to-Global Learning,[0],[0]
Step 2:,3.2. Local-to-Global Learning,[0],[0]
"GGSL uses LocalLearn shown in Algorithm 1 to find the local structure of the target variable over the query set Z. This step resolves the potential edge conflicts through efficient learning, avoiding the simple AND-rule used by other local-to-global structure learning algorithms The main difference between each run of LocalLearn is that the previous T ’s will not be considered, unless they are in the local structure of the current target variable.",3.2. Local-to-Global Learning,[0],[0]
"Hence the max possible variable set size decreases over iterations, improving the memory efficiency.
",3.2. Local-to-Global Learning,[0],[0]
"Algorithm 2 Graph Growing Structure Learning Input: data D, size m, variable set V Q← ∅; A← ∅; G← zeros(|V |, |V |) repeat
if Q 6=",3.2. Local-to-Global Learning,[0],[0]
∅ & Q[0] 6∈,3.2. Local-to-Global Learning,[0],[0]
"A then T ← Q.pop(0) else T ← the next unqueried variable in V end if G← GGSL(D,T,G,A,V) add adjacent nodes of T in G to Q A← A ∪ T
until |S| = |V",3.2. Local-to-Global Learning,[0],[0]
| − 1 G←,3.2. Local-to-Global Learning,[0],[0]
"PDAG-to-DAG(G) Return: G
Algorithm 3 GGSL Subroutine Input: data D, target variable T , current DAG G, variable set A, variable set V PC,P,C← findPC(G,T ); Sp← findSpouse(G,T )",3.2. Local-to-Global Learning,[0],[0]
Z←,3.2. Local-to-Global Learning,[0],[0]
"T ∪PC ∪ Sp ∪V \ {T,PC,Sp,A} DZ ← D of the set Z MB,P,C,Sp← LocalLearn(DZ,",3.2. Local-to-Global Learning,[0],[0]
"T ) G← updateGraph(G,T,P,C,Sp) Return: G
Step 3: Subroutine updateGraph, shown in Algorithm 3, performs the following check to enforce graph consistency: First, it checks if any directed parent in the existing G is learned as a child from the local learned children set C.",3.2. Local-to-Global Learning,[0],[0]
"If so, it corrects the children into parents.",3.2. Local-to-Global Learning,[0],[0]
"Secondly, it checks if any directed child in the existing G is wrongly learned as a parent from P. If so, it corrects the parents into children.",3.2. Local-to-Global Learning,[0],[0]
"Lastly, the algorithm checks if any P and C nodes can have a different edge direction without introducing new or destroying existing V-structures; if so, all these P and C are marked as undirected.",3.2. Local-to-Global Learning,[0],[0]
"Otherwise, they are marked as directed edges.",3.2. Local-to-Global Learning,[0],[0]
"There checks are needed to ensure the already-oriented edges remain unchanged, as the earlier runs of local structure learning uses more variables and hence are more likely to be correct.",3.2. Local-to-Global Learning,[0],[0]
"Lastly, to orient the newly learned spouse set Sp is straightforward, due to the definitive nature of V-structures.
",3.2. Local-to-Global Learning,[0],[0]
"Step 4: After repeating the first three steps for all but one variable, the last step of GGSL is to obtain a DAG given all the directed and undirected edges in the graph.",3.2. Local-to-Global Learning,[0],[0]
"Applying the conventional rules (Meek, 1995) to convert a partial directed acyclic graph (PDAG) to completely directed acyclic graph is sufficient, with an option to convert to DAG if desired.
",3.2. Local-to-Global Learning,[0],[0]
Algorithm 4 updateGraph,3.2. Local-to-Global Learning,[0],[0]
"Input: current DAGG, target T , learned parent P, child set C, spouse set",3.2. Local-to-Global Learning,[0],[0]
"Sp {Step 1. update the PC set} for all C in C do
if C conflicts with directed edge C → T in G then add C into P and remove C from C
end if end for for all P in P do
if P conflicts with directed edge T → P in G then add P into C and remove P from P
end if end for if |P| ≥ 2 then
orient P and C accordingly as a directed edge in G else if directed edge T -A, ∀A ∈ {P ∪ C} cannot be reversed without destroying existing or introducing new V-structures then
orient T -A accordingly as a directed edge in G else
orient T -A accordingly as a undirected edge in G end if {Step 2.",3.2. Local-to-Global Learning,[0],[0]
"update the spouse set} Orient Sp and T to their children accordingly as directed edges in G Return: G
Lemma 6.",3.2. Local-to-Global Learning,[0],[0]
Requirement of Post-processing .,3.2. Local-to-Global Learning,[0],[0]
"Subroutine PDAG-to-DAG is required in a local-to-global learning system to correctly orient DAG G to its Markov equivalent class in Algorithm 2.
",3.2. Local-to-Global Learning,[0],[0]
"A simple example, shown in Figure 2 would justify Lemma 6.",3.2. Local-to-Global Learning,[0],[0]
"If the target T is chosen with the following order: F,E,D,C, and A, then the direction of edges C −D, D −E, and E − F can be set in both directions and hence are labeled as undirected edges by Algorithm 2.",3.2. Local-to-Global Learning,[0],[0]
"When node C becomes the target, then edge C − D is known.",3.2. Local-to-Global Learning,[0],[0]
Other edges D−E and E−F have to be checked and corrected.,3.2. Local-to-Global Learning,[0],[0]
"Without subroutine PDAG-to-DAG to propagate the changes back, the learned DAG is not guaranteed to be the correct completely partially directed DAG (CPDAG).
",3.2. Local-to-Global Learning,[0],[0]
We show Algorithm 2 is sound and complete: Theorem 2.,3.2. Local-to-Global Learning,[0],[0]
Soundness and Completeness.,3.2. Local-to-Global Learning,[0],[0]
"Under the infinite data and faithfulness assumption, Algorithm 2 GGSL learns and directs all and only the correct edges in the underlying DAGG0, up to the Markov equivalent class ofG0.
",3.2. Local-to-Global Learning,[0],[0]
Proof.,3.2. Local-to-Global Learning,[0],[0]
"For the first target variable T1, GGSL finds the correct local structure of one target variable by Theorem 1.",3.2. Local-to-Global Learning,[0],[0]
The updated DAG G is sound and complete for T1.,3.2. Local-to-Global Learning,[0],[0]
"Starting from the second iteration i ≥ 2, since the learned graph
G is shown to be correct, if any variable in the target variable Ti’s MB set has been queried or saved, they must exist in the PC and Sp variable, hence in Z of Algorithm 3.",3.2. Local-to-Global Learning,[0],[0]
"With the rest of variables complementing the PC and Sp variables, all the true positive PC set and spouse set of Ti must be included in the set Z of Algorithm 3.",3.2. Local-to-Global Learning,[0],[0]
"By Theorem 1 again, the local structure learned must be sound and complete.",3.2. Local-to-Global Learning,[0],[0]
"Hence, at each iteration of Algorithm 2, the updated DAG G must be sound and complete for all Tis as well.",3.2. Local-to-Global Learning,[0],[0]
"Since the PDAG-to-DAG subroutine is also proven to orient the correct DAG from PDAG (Meek, 1995), the result DAG G at the end of Algorithm 2 must be in the Markov equivalent class of G0.",3.2. Local-to-Global Learning,[0],[0]
"Applying Algorithm 2 to Figure 1a would result in the following procedure, assuming the query order for target T is A ⇒ B ⇒ C ⇒",3.3. Case Study,[0],[0]
D ⇒ E ⇒ F .,3.3. Case Study,[0],[0]
"When T1 = A, LocalLearn finds B and C in the local structure of A with the query set of all variables, with undirected edges between them , and update G. With T2 = B, the query set of variables contains its local structure A from G and the rest of variables.",3.3. Case Study,[0],[0]
"LocalLearn finds D and C as B’s local structure, and updates G. With T3 = C, LocalLearn finds the same A and D and does not make new update of G. With T4 = D, LocalLearn finds E and update G with directed edge D − E in G. Similarly, LocalLearn finds the directed edge E−F and H−F due to the definitive V-structure and update G accordingly, shown in Figure 1b, when Ti = E and F .",3.3. Case Study,[0],[0]
PDAG-to-DAG takes G and produces a possible DAG in Figure 1a.,3.3. Case Study,[0],[0]
"While Algorithm 2 is theoretically sound and complete, in practice further optimizations in the algorithmic procedure can be implemented.",3.4. Implementation Optimization,[0],[0]
"First, inside the iterative LocalLearn procedure, variables in the existing PC and Sp set of Ti should be queried first.",3.4. Implementation Optimization,[0],[0]
These true positive MB set variables could potentially reduce the queried set size to BNStructLearn at each iteration by removing non-MB set of variables early in the process.,3.4. Implementation Optimization,[0],[0]
"Using this procedure is similar to the idea behind an improved version of LocalLearn (Gao & Ji, 2017), which is shown to improve accuracy and reduce computational time.",3.4. Implementation Optimization,[0],[0]
"Secondly, using the same concept, one can also keep track of which variables are removed from Ti’s local structure after adding each queried variable X for target Ti’s local learning procedure, hence forming a separation set, or sepset, of X from T .",3.4. Implementation Optimization,[0],[0]
"Querying variables from the sepset first when X becomes the target could also reduce the potential query set variable size to LocalLearn, as sepset variables are more likely to be adjacent variables of X .",3.4. Implementation Optimization,[0],[0]
"The exact global learning complexity varies depending on the algorithm, but is exponential in the worst case.",3.5. Complexity and Performance Discussion,[0],[0]
"For example, Dynamic programming approaches (Silander & Myllymaki, 2006) cost O(N22N ), where N is the total number of variables present.",3.5. Complexity and Performance Discussion,[0],[0]
"The most expensive step of local-to-global approach is each iteration of local learning using LocalLearn, which costs O(N32N ) using the same dynamic programming approach.",3.5. Complexity and Performance Discussion,[0],[0]
"Repeating for all the variable present, the local-to-global approach takes O(N42N ) in the worst case (Niinimaki & Parviainen, 2012; Gao & Ji, 2017).",3.5. Complexity and Performance Discussion,[0],[0]
"As one can see, in the case where the local structure of one target variable includes all other variable (such as in the Naive Bayesian model), the local-to-global approach would match the complexity of the global approach.",3.5. Complexity and Performance Discussion,[0],[0]
"However, by the iterative nature of the learning and the fact that the number of query variables decreases at later stages of learning, the expected running time is much lower for the local-to-global learning approach.",3.5. Complexity and Performance Discussion,[0],[0]
"If we assume a uniform distribution on the local neighbor size of each node in a network of N nodes, then the expected time complexity of the proposed GGSL approach is O( ∑N i=1",3.5. Complexity and Performance Discussion,[0],[0]
"i
32i) = O(N32N ).",3.5. Complexity and Performance Discussion,[0],[0]
"If we assume l to be the maximum size of local neighbors, then the average complexity would be O(l32l), which can lead to a big performance gain O(2N−l).
",3.5. Complexity and Performance Discussion,[0],[0]
"Our algorithm is a score-based algorithm, as it can use any one of existing score-based optimal learner as the BNStructLearn subroutine.",3.5. Complexity and Performance Discussion,[0],[0]
Theoretical optimality of the proposed algorithm holds only under standard assumptions.,3.5. Complexity and Performance Discussion,[0],[0]
"In real datasets, when the faithfulness assumption
is violated or estimated probabilistic distributions are estimated incorrectly due to insufficient data, the performances of all the algorithms (global and local) are not guaranteed.",3.5. Complexity and Performance Discussion,[0],[0]
"During the learning procedure of the GGSL algorithm, even with a smaller query set of variables, the information about edge existence and orientation with sufficient data does not decrease compared to the global learning methods, if the local variables around each edge are all present.",3.5. Complexity and Performance Discussion,[0],[0]
"Hence, reducing the query set size would not affect performance with sufficient data, although the information loss does happen in practice.",3.5. Complexity and Performance Discussion,[0],[0]
"On the other hand, the estimation performance on the number of data samples is known to be sensitive to the number of parameters.",3.5. Complexity and Performance Discussion,[0],[0]
"The standard error of estimation is σ/ 2 √ N , where σ is the standard deviation.",3.5. Complexity and Performance Discussion,[0],[0]
"Due to the smaller set of variable present, the computation of Bayesian scores could be more accurate in practice when the sample size is limited.",3.5. Complexity and Performance Discussion,[0],[0]
The trade-off between the information loss and estimation error varies among different datasets.,3.5. Complexity and Performance Discussion,[0],[0]
We compare the proposed algorithms with both global and local-to-global learning methods.,4. Experiments,[0],[0]
"Specifically, we compare our results with global methods, Dynamic Programming (DP) structure learning (Silander & Myllymaki, 2006), Constrained Structure Learning (CSL) (de Campos et al., 2009), GOBNILP (Cussens et al., 2016), and local methods Score-based Local Learning (SLL+C) (Niinimaki & Parviainen, 2012) with three different BNStructLearn as above (DP, CSL, and GOBNILP), denoted as SLL+C-DP, SLL+C-CSL, and SLL+C-GOBNILP.",4. Experiments,[0],[0]
"We use the existing implementation of DP (in MATLAB), CSL (in C), and GOBNILP (in C), and implement our algorithms in MATLAB.",4. Experiments,[0],[0]
"We test the algorithms on benchmark BN datasets from the BN repository1, using the datasets provided from existing works(Tsamardinos et al., 2006).",4. Experiments,[0],[0]
"We run the algorithms with 1000 samples of each dataset 10 times, and compare BDeu scores of each algorithm, along with the standard deviation, shown in Table 1.",4. Experiments,[0],[0]
We also compare the algorithms on a synthetic 7-node network for DP as BNStructLearn so algorithms can return results within the time limit.,4. Experiments,[0],[0]
"We report the running time (the entire algorithmic time, including data access, score computation and structure search) of each algorithm2, along with the standard deviation, shown in Table 2, with the maximum running time of 24 hours.",4. Experiments,[0],[0]
The experiments are conducted on a machine with Intel i5-3320M 2.6GHz with 8 GB memory.,4. Experiments,[0],[0]
"Due to memory limitation, the DP method can fail to finish.",4. Experiments,[0],[0]
"CSL and GOBNILP have parameters that can control
1http://www.bnlearn.com/bnrepository/ 2 The time results are different from results on the GOBNILP website, which represent the times of finding the optimal structure given already computed scores.
",4. Experiments,[0],[0]
"DATA SET VARIABLE SIZE DP SLL+C-DP GGSL-DP
7BN 7 -13854.6± 133 -14224.6± 143",4. Experiments,[0],[0]
"-13781.2 ± 133 ALARM 37 OOM -14774.1± 210 -11557.8± 379 CHILDREN 20 OOM -13548.0±172 -12690.0± 106 HAILFINDER 56 OOM -62281.5±213 -54551.6 ± 404 CHILDREN3 60 OOM -38713.2±255 -37271.2± 315
DATA SET VARIABLE SIZE CSL SLL+C-CSL GGSL-CSL
ALARM 37 -10989.8 ± 196",4. Experiments,[0],[0]
"-11437.0.1±268 -11033.4± 382 CHILDREN 20 -12690.0 ± 104 -12811.4±153 -12600.0± 106 HAILFINDER 56 -54375.6 ±111 -58138.1±523 -57794.1± 623 CHILDREN3 60 -37407.5± 228 -38634.8± 249 -37258.3± 340
DATA SET VARIABLE SIZE",4. Experiments,[0],[0]
"GOBNILP SLL+C-GOB GGSL-GOB
ALARM 37 DNF -10337.1± 410 -10575.0±269 CHILDREN 20 -12690.0 ± 104 -12811.4±153 -12600.0± 106",4. Experiments,[0],[0]
"HAILFINDER 56 DNF -54192.5± 781 -53411.7± 844 CHILDREN3 60 DNF -38303.0±402 -36950.1± 382
memory usages.
",4. Experiments,[0],[0]
"As one can see from Table 1, GGSL improves the learning scores by a significant margin over the SLL+C algorithm, with different BNStructLearn in all four datasets tested, except one case in ALARM with GOBNILP.",4. Experiments,[0],[0]
It can even compete with global structure learning approaches in some cases.,4. Experiments,[0],[0]
GGSL outperforms the global learning methods in CHILDREN datasets with CSL and GOBNILP.,4. Experiments,[0],[0]
"Efficiency-wise, from Table 2, using DP, GGSL is more ef-
ficient than SLL+C and can achieve one than one order of speedup.",4. Experiments,[0],[0]
"Using CSL and GOBNILP, GGSL has more than one order of magnitude speed-ups in 3 out of 4 datasets when compared with global learning method.",4. Experiments,[0],[0]
"However, GGSL’s running time is generally slower to SLL+C algorithm using CSL and GOBNILP.",4. Experiments,[0],[0]
"It is faster than SLL+C on HAILFINDER with CSL, and is slightly slower in the other testing cases.",4. Experiments,[0],[0]
"We speculate that the difference in speed gains across different algorithms is mainly the code base of BNStructLearn, where the extra checking Step 3 in GGSL can take proportionally longer time if BNStructLearn is implemented in C.",4. Experiments,[0],[0]
We have proposed a novel graph expanding learning algorithm to learn BN structure.,5. Discussion and Conclusion,[0],[0]
"We strengthen the existing local structure learning analysis, justifying its soundness when the traditional faithfulness condition fails with absent variables, and propose a new local-to-global approach to combine the local structures efficiently.",5. Discussion and Conclusion,[0],[0]
"Experiments have shown that the proposed GGSL improves the accuracy over existing local-to-global algorithms and improves efficiency over existing global algorithms, both by a significant margin.",5. Discussion and Conclusion,[0],[0]
"In addition, GGSL can work with any exact score-based BN learning algorithm and achieve consistent performance gain.",5. Discussion and Conclusion,[0],[0]
"The iterative nature of GGSL can have many applications, such as online BN structure learning with streaming data.",5. Discussion and Conclusion,[0],[0]
"Future work could study how GGSL would work with constraint-based (van Beek & Hoffmann, 2015; Gao & Ji, 2016b) and approximated BN structure learning algorithms as the BNStructLearn routines.",5. Discussion and Conclusion,[0],[0]
We thank Dennis Wei and anonymous reviewers for inspiration and helpful comments.,Acknowledgements,[0],[0]
"We introduce a new local-to-global structure learning algorithm, called graph growing structure learning (GGSL), to learn Bayesian network (BN) structures.",abstractText,[0],[0]
GGSL starts at a (random) node and then gradually expands the learned structure through a series of local learning steps.,abstractText,[0],[0]
"At each local learning step, the proposed algorithm only needs to revisit a subset of the learned nodes, consisting of the local neighborhood of a target, and therefore improves on both memory and time efficiency compared to traditional global structure learning approaches.",abstractText,[0],[0]
"GGSL also improves on the existing local-to-global learning approaches by removing the need for conflictresolving AND-rules, and achieves better learning accuracy.",abstractText,[0],[0]
"We provide theoretical analysis for the local learning step, and show that GGSL outperforms existing algorithms on benchmark datasets.",abstractText,[0],[0]
"Overall, GGSL demonstrates a novel direction to scale up BN structure learning while limiting accuracy loss.",abstractText,[0],[0]
Local-to-Global Bayesian Network Structure Learning,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 1380–1390 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
1380",text,[0],[0]
Consider the video and natural language query in Figure 1 where we seek to localize the desired moment in the video specified by the query.,1 Introduction,[0],[0]
"Queries like “the girl bends down” require understanding objects and actions, but do not require reasoning about different video moments.",1 Introduction,[0],[0]
"In contrast, queries like “the little girl talks after bending down” require reasoning about the temporal relationship between different actions (“talk” and “bend down”).",1 Introduction,[0],[0]
"Localizing natural language queries in video is an important challenge, recently studied in Hendricks et al. (2017) and Gao et al. (2017) with applications in areas such as video search and retrieval.",1 Introduction,[0],[0]
"We argue that to
∗Work done at Adobe during LAH’s summer internship.
properly localize queries with temporal language, models must understand and reason about intravideo context.
",1 Introduction,[0],[0]
Reasoning about intra-video context is difficult as we do not know a priori which moments should be involved in the contextual reasoning and different queries may require reasoning about different contextual moments.,1 Introduction,[0],[0]
"For example, in “the little girl talks after bending down”, the relevant contextual moment “bending down” occurs just before the target moment “the little girl talks”.",1 Introduction,[0],[0]
This is in contrast to the query “the little girl talks before bending down” where the relevant contextual moment occurs just after.,1 Introduction,[0],[0]
"A limitation of current moment-localization models (Hendricks et al., 2017; Gao et al., 2017) is they consider query-independent video context when localizing moments.",1 Introduction,[0],[0]
"For example, when determining whether a proposed temporal region matches a natural language query, Gao et al. (2017) considers the proposed temporal region, as well as video regions just before and after the proposed region.",1 Introduction,[0],[0]
"Similarly, Hendricks et al. (2017) considers video context in the form of a global-context feature which represents the entire video.",1 Introduction,[0],[0]
"While both may implicitly include the appropriate contextual moment in their context feature, they do not explicitly determine the relevant context for the query.
",1 Introduction,[0],[0]
"To address this difficulty, we propose Moment
Localization with Latent Context (MLLC) which models video context as a latent variable.",1 Introduction,[0],[0]
"The latent variable enables the model to attend to different video contexts conditioned on the specific query/video pair, offering flexibility in the location and length of the contextual moment and overcoming the limitation of query-independent contextual reasoning.",1 Introduction,[0],[0]
We validate the importance of latent context by showing that our model performs well both on simple queries without temporal words and more complex queries requiring temporal reasoning.,1 Introduction,[0],[0]
"Moreover, our formulation is generic and unifies approaches in Hendricks et al. (2017) and Gao et al. (2017), allowing us to ablate model component choices, as well as which kind of video context is best for localizing moments described with temporal language.
",1 Introduction,[0],[0]
"Though datasets used for moment localization in video (Hendricks et al., 2017; Regneri et al., 2013; Sigurdsson et al., 2016) include temporal language, as we will show, there is not enough temporal language to effectively train and evaluate models.",1 Introduction,[0],[0]
"We seek to extensively study this aspect, particularly with respect to temporal prepositions (Pratt-Hartmann, 2004).",1 Introduction,[0],[0]
"Thus, we collect the TEMPOral reasoning in video and language (TEMPO) dataset which builds off the recently collected DiDeMo dataset (Hendricks et al., 2017).",1 Introduction,[0],[0]
"The dataset consists of two parts: a dataset with real videos and sentences created with a template model (TEMPO - Template Language (TL)), and a dataset with real videos and newly collected user-provided temporal annotations (TEMPO - Human Language (HL)).",1 Introduction,[0],[0]
Considering template sentences allows us to create a large dataset of sentences quickly for study of temporal language in a controlled setting.,1 Introduction,[0],[0]
The human language data then allows us to see these trends transfer to more complex human-language queries.,1 Introduction,[0],[0]
"For data collection, we focus on the most common temporal referring words naturally occurring in language-and-video datasets.
",1 Introduction,[0],[0]
Our contributions are twofold.,1 Introduction,[0],[0]
(i),1 Introduction,[0],[0]
We are the first to study models for temporal language in video moment retrieval with natural language queries.,1 Introduction,[0],[0]
"To this end, we introduce TEMPO which includes examples of how humans use temporal language to refer to video moments.",1 Introduction,[0],[0]
(ii) We propose MLLC for moment localization which treats video context as a latent variable and unifies prior approaches for moment localization.,1 Introduction,[0],[0]
"Our
model outperforms prior work on TEMPO-TL and TEMPO-HL as well as the original DiDeMo dataset.",1 Introduction,[0],[0]
Localizing Video Segments with Natural Language.,2 Related Work,[0],[0]
"Prior work has considered aligning natural language with video, e.g., instructional videos with transcribed text (Kiddon et al., 2015; Huang et al., 2017; Malmaud et al., 2014, 2015).",2 Related Work,[0],[0]
"Our work is most related to recent work in video moment retrieval with natural language (Gao et al., 2017; Hendricks et al., 2017).",2 Related Work,[0],[0]
"Both works take a natural language query and candidate video segment as input, and output a score for how well the natural language phrase aligns with the video segment.",2 Related Work,[0],[0]
"Gao et al. (2017) includes an additional loss to regress to start and end-points, whereas Hendricks et al. (2017) simplifies the problem by choosing from a discrete set of video segments.",2 Related Work,[0],[0]
"Importantly, to represent a proposed video segment, both models consider context features around a moment: Hendricks et al. (2017) uses global context by averaging features over an entire input video, and Gao et al. (2017) incorporates features adjacent to the proposed video segment.",2 Related Work,[0],[0]
"We argue that to do proper temporal reasoning, pre-determined, query independent context features may not cover all possible temporal relations.",2 Related Work,[0],[0]
"Thus, we propose to model the context as a latent variable, allowing our method to learn which context moments to consider as a function of the video and importantly, the query.
",2 Related Work,[0],[0]
Both Gao et al. (2017) and Hendricks et al. (2017) collect data to test their models; Gao et al.,2 Related Work,[0],[0]
"(2017) considers the Charades (Sigurdsson et al., 2016) and TACoS (Regneri et al., 2013) datasets.",2 Related Work,[0],[0]
"While TACoS includes localized sentences, Charades only has sentences and activity detection localizations, so a semi-automatic method is used to align action detection annotations to visual descriptions in Charades.",2 Related Work,[0],[0]
"Hendricks et al. (2017) collected the Distinct Describable Moment (DiDeMo) dataset, which consists of Flickr (Thomee et al., 2016) videos with localized referring expressions.",2 Related Work,[0],[0]
"Both Charades and DiDeMo contain a large set of diverse videos (approximately 10,000 videos each).",2 Related Work,[0],[0]
"We chose to base TEMPO on DiDeMo because it contains more clip/sentence pairs (40,000 vs. 13,000), and is focused on general videos which we believe is
an interesting and useful scenario, rather than being restricted to indoor activities.
",2 Related Work,[0],[0]
Temporal Language.,2 Related Work,[0],[0]
"Prior work on temporal language processing has considered building explicit logical frameworks to process temporal prepositions like “during” or “until” (Pratt-Hartmann (2004), Konur (2008)).",2 Related Work,[0],[0]
"We do not derive a particular temporal logic, but rather learn to understand temporal language in a data driven fashion.",2 Related Work,[0],[0]
"Furthermore, we specifically consider how to understand temporal words commonly used when referring to video content.",2 Related Work,[0],[0]
"Other work has modeled dynamics for words which represent a change of state (e.g., “pick up”)",2 Related Work,[0],[0]
"( Siskind (2001), Yu et al. (2015)) in limited environments.",2 Related Work,[0],[0]
"Though we limit the selection of temporal words in our study, the natural language in our data is open-world describing diverse events and how they relate to each other in video.",2 Related Work,[0],[0]
"Interpretation of temporal expressions in text (“The game happened on the 19th”) is a widely studied task (Angeli et al. (2012), Zhong et al. (2017)).",2 Related Work,[0],[0]
"Our work is distinctly different from this line of work as we specifically study temporal prepositions and how they refer to video.
",2 Related Work,[0],[0]
Modeling Visual Relationships.,2 Related Work,[0],[0]
"A variety of papers have considered modeling spatial relationships in natural images (Dai et al., 2017; Hu et al., 2017; Peyre et al., 2017; Plummer et al., 2017).",2 Related Work,[0],[0]
Our approach is analogous to this in the temporal domain; we hope to localize moments in videos.,2 Related Work,[0],[0]
"CLEVR, a synthetic visual question answering (VQA) dataset (Johnson et al., 2016), was created to allow researchers to systematically study the ability of models to perform complex reasoning.",2 Related Work,[0],[0]
Our dataset is partially motivated by the success of CLEVR to enable researchers to study reasoning abilities of different models in a controlled setting.,2 Related Work,[0],[0]
"In contrast to CLEVR we consider a more diverse visual input in the form of real videos.
",2 Related Work,[0],[0]
"In the video domain, the TGIF-QA (Jang et al., 2017) and Mario-QA (Mun et al., 2016) datasets provide opportunities to study temporal reasoning for the task of VQA.",2 Related Work,[0],[0]
"The TGIF-QA dataset considers three types of temporal questions: before/after questions, repetition count, and determining a repeating action.",2 Related Work,[0],[0]
Each question is accompanied by multiple choice answers.,2 Related Work,[0],[0]
Videos we consider are much longer (25-30s as opposed to an average of 3.1s) which makes the use of temporal reasoning much more important.,2 Related Work,[0],[0]
"The MarioQA dataset is an additional VQA dataset de-
signed to gauge temporal reasoning of VQA systems.",2 Related Work,[0],[0]
Both TGIF-QA and MarioQA datasets include template-based natural language queries.,2 Related Work,[0],[0]
"In this paper, we consider synthetic queries similar to TGIF-QA and MarioQA, but also include human language queries.",2 Related Work,[0],[0]
"In addition, unlike the MarioQA dataset, that consists of synthetic data constructed from gameplay videos, our dataset consists of real visual inputs, and includes temporal grounding of natural language phrases.",2 Related Work,[0],[0]
"Finally, neither TGIFQA nor MarioQA include temporal localization.",2 Related Work,[0],[0]
"Given a video v and natural-language query q describing a moment in the video, our goal is to output the moment τ =",3 Moment Localization with Latent Context,[0],[0]
"( τ (s), τ (e) )",3 Moment Localization with Latent Context,[0],[0]
"where τ (s) and τ (e) are temporal start and end points in the video, respectively.",3 Moment Localization with Latent Context,[0],[0]
"In the following, we formulate a generic, unified model which encompasses prior approaches (Hendricks et al., 2017; Gao et al., 2017).",3 Moment Localization with Latent Context,[0],[0]
This allows us to explore and evaluate trade offs for different model components and extensions which then leads to higher performance.,3 Moment Localization with Latent Context,[0],[0]
"Unlike prior work, we consider a latent context variable which enables our model to better reason about temporal language.
",3 Moment Localization with Latent Context,[0],[0]
Let the moment τ corresponding to the text query be the base moment and the set of other video moments Tτ be possible context moments for τ .,3 Moment Localization with Latent Context,[0],[0]
"We define a scoring function between the video moment and natural-language query by maximizing over all possible context moments
τ ′",3 Moment Localization with Latent Context,[0],[0]
"∈ Tτ ,
sφ (v, q, τ) = max τ ′∈Tτ
fS ( fV ( v, τ, τ ′ ) , fL (q) ) ,
(1) where fV and fL are functions computing features over the video and language query, fS is a similarity function, and φ are model parameters.",3 Moment Localization with Latent Context,[0],[0]
This formulation is generic and trivially encompasses the MCN and TALL formulations by letting the set of possible context moments Tτ be their respective single-context moment.,3 Moment Localization with Latent Context,[0],[0]
"Figure 2 shows the generic structure of our model.
",3 Moment Localization with Latent Context,[0],[0]
"With this formulation, we seek to answer the following questions: (i) Which combination of model components performs best for the momentretrieval task?",3 Moment Localization with Latent Context,[0],[0]
"Though our primary goal is localizing moments with temporal language, we believe a good base moment retrieval model is important for localizing moments with temporal language.",3 Moment Localization with Latent Context,[0],[0]
(ii) How best to incorporate context for moment retrieval with temporal language?,3 Moment Localization with Latent Context,[0],[0]
"We first detail the different terms and outline different model design choices, where design choices marked with bolditalic font is ablated in Section 5.",3 Moment Localization with Latent Context,[0],[0]
"Components which are used in our final proposed Moment Localization with Latent Context (MLLC) model and prior models are summarized in Table 3.
Video feature fV .",3 Moment Localization with Latent Context,[0],[0]
"The video feature fV = (g (v, τ) , g (v, τ ′) , fT (τ, τ
′)) is a concatenation of visual features for the base g (v, τ) and context g (v, τ ′) moments and endpoint features fT (τ, τ
′).",3 Moment Localization with Latent Context,[0],[0]
"To compute visual features g for a temporal region τ , per-frame features are averaged over the temporal region.",3 Moment Localization with Latent Context,[0],[0]
"Note that if the context moment consists of more than one contiguous temporal region, then the visual features are computed over each contiguous temporal region and then concatenated (c.f., before/after context in TALL, explained below).",3 Moment Localization with Latent Context,[0],[0]
There are many choices for visual features.,3 Moment Localization with Latent Context,[0],[0]
"TALL (Gao et al., 2017) compares average fc7 features (extracted from (Simonyan and Zisserman, 2014)) to features extracted with C3D (Tran et al., 2015) and LSTM features (Donahue et al., 2015).",3 Moment Localization with Latent Context,[0],[0]
"Surprisingly, C3D features only outperform average fc7 features by a small margin.",3 Moment Localization with Latent Context,[0],[0]
"We use the visual features used in the MCN model (Hendricks et al., 2017), which are similar to the fc7 features from (Gao et al., 2017), but included motion features as well, computed from optical flow (extracted with (Wang et al., 2016)).",3 Moment Localization with Latent Context,[0],[0]
"We then pass the extracted visual
features through a MLP.",3 Moment Localization with Latent Context,[0],[0]
"Note that we learn separate embedding functions for RGB and optical flow inputs and combine scores from different input modalities using a late-fusion approach (Hendricks et al., 2017).
",3 Moment Localization with Latent Context,[0],[0]
Endpoint feature fT .,3 Moment Localization with Latent Context,[0],[0]
Modeling temporal context requires understanding how different temporal segments relate in time.,3 Moment Localization with Latent Context,[0],[0]
"Hendricks et al. (2017) suggest including temporal endpoint features (TEF) fT = ( τ (s), τ (e) ) for the base moment which encode when the moment starts and ends to better localize sentences which include words like “first” and “last”.",3 Moment Localization with Latent Context,[0],[0]
"Note that TALL (Gao et al., 2017) does not incorporate TEFs.",3 Moment Localization with Latent Context,[0],[0]
"In order to understand temporal relationships, it is important that models also include features which indicate when a context moment occurs.",3 Moment Localization with Latent Context,[0],[0]
"In addition to providing TEFs for base moments, we also experiment with concatenating TEFs for context moments (conTEF) fT = ( τ (s), τ (e), τ ′(s), τ ′(e) ) .
",3 Moment Localization with Latent Context,[0],[0]
"Language feature fL. Text queries are transformed into a fixed-length vector with an LSTM (Hochreiter and Schmidhuber, 1997).",3 Moment Localization with Latent Context,[0],[0]
"Before inputting words into the LSTM, they are embedded in the Glove (Pennington et al., 2014) embedding space.",3 Moment Localization with Latent Context,[0],[0]
The final layer of the LSTM is projected into the shared video-language embedding space with a fully connected layer.,3 Moment Localization with Latent Context,[0],[0]
Gao et al. (2017) considers LSTM language features and Skip-thought encoders.,3 Moment Localization with Latent Context,[0],[0]
"Our main goal is to study how context impacts moment localization with temporal language, so we use the LSTM features used on the original DiDeMo dataset.
",3 Moment Localization with Latent Context,[0],[0]
Similarity fS .,3 Moment Localization with Latent Context,[0],[0]
"Given video fV and language fL features, we consider three ways to encode similarity between the features.",3 Moment Localization with Latent Context,[0],[0]
"Like Hendricks et al. (2017), we consider a distance-based similarity fS = ( |fV − fL|2 ) .",3 Moment Localization with Latent Context,[0],[0]
"Second, we consider a fused-feature similarity (mult) where the Hadamard product fV fL between the two features are passed to a MLP.",3 Moment Localization with Latent Context,[0],[0]
We also explore unit normalizing features before the Hadamard product (normalized mult).,3 Moment Localization with Latent Context,[0],[0]
"Finally, we consider the similarity (TALL similarity) which consists of the concatenation (fV , fL, fV fL, fV + fL) and then passed to a MLP.
",3 Moment Localization with Latent Context,[0],[0]
Context moments,3 Moment Localization with Latent Context,[0],[0]
Tτ .,3 Moment Localization with Latent Context,[0],[0]
We consider three sets of context moments.,3 Moment Localization with Latent Context,[0],[0]
"First, we consider the entire video as the context moment (global) following Hendricks et al. (2017).",3 Moment Localization with Latent Context,[0],[0]
"Second, we consider us-
ing the moments just before and after the base moment (before/after).",3 Moment Localization with Latent Context,[0],[0]
"Finally, we consider using the set of all possible moments (latent context) which offers greatest flexibility in contextual reasoning.
",3 Moment Localization with Latent Context,[0],[0]
Training loss.,3 Moment Localization with Latent Context,[0],[0]
We consider two training losses.,3 Moment Localization with Latent Context,[0],[0]
The first loss is the MCN ranking loss which encourages positive moment/query pairs to have a smaller distance in a shared embedding space than negative moment/query pairs.,3 Moment Localization with Latent Context,[0],[0]
"To sample negative moment/sentence pairs, they consider negative moments within a specific video (called intravideo negative moments) and negative moments in different videos (called inter-video negative moments).",3 Moment Localization with Latent Context,[0],[0]
This sampling strategy leads to a small improvement in performance (approximately one point on all metrics) when compared to just using intra-video negative moments.,3 Moment Localization with Latent Context,[0],[0]
"We also consider the alignment loss used in TALL (TALL loss) which is the sum of two log-logistic functions over positive and negative training query/moment pairs (intra-video negatives are used).
",3 Moment Localization with Latent Context,[0],[0]
Supervising context moments.,3 Moment Localization with Latent Context,[0],[0]
"For the temporal sentences in our newly collected dataset (Section 4), we have access to the ground-truth context moment during training.",3 Moment Localization with Latent Context,[0],[0]
"Thus, we can contrast a weakly supervised setting in which we optimize over the unknown latent context moments during learning and inference to a strongly supervised setting.",3 Moment Localization with Latent Context,[0],[0]
Implementation details.,3 Moment Localization with Latent Context,[0],[0]
Candidate base and context moments coincide to the pre-segmented fivesecond segments used when annotating DiDeMo.,3 Moment Localization with Latent Context,[0],[0]
Moments may consist of any contiguous set of five-second segments.,3 Moment Localization with Latent Context,[0],[0]
"For a 30-second video partitioned into six five-second segments, there are 21 possible moments.",3 Moment Localization with Latent Context,[0],[0]
"All models were implemented in Caffe (Jia et al., 2014) and optimized with SGD.",3 Moment Localization with Latent Context,[0],[0]
"Models were trained for ∼ 90 epochs with an initial learning rate of 0.05, which decreases every 30 epochs.",3 Moment Localization with Latent Context,[0],[0]
Code is publicly released∗.,3 Moment Localization with Latent Context,[0],[0]
We collect the TEMPOral reasoning in video and language (TEMPO) dataset based off the recently released DiDeMo dataset.,4 The TEMPO Dataset,[0],[0]
Our dataset consists of two parts: TEMPO - Template Language (TL) and TEMPO - Human Language (HL).,4 The TEMPO Dataset,[0],[0]
"We create TEMPO - TL using language templates to augment the original sentences in DiDeMo with tem∗https://people.eecs.berkeley.edu/ ˜lisa_anne/tempo.html
poral words.",4 The TEMPO Dataset,[0],[0]
The template allows us to generate a large number of sentences with known ground truth base and context moments.,4 The TEMPO Dataset,[0],[0]
"However, template language lacks the complexity of human language, so we then collect an additional fully userconstructed dataset, TEMPO - HL, consisting of sentences that contain specific temporal words.
",4 The TEMPO Dataset,[0],[0]
Temporal Words in Current Datasets.,4 The TEMPO Dataset,[0],[0]
We first analyze temporal words which occur in current natural language moment retrieval datasets.,4 The TEMPO Dataset,[0],[0]
"We consider temporal adjectives, adverbs, and prepositions found both by closely analyzing moment-localization datasets and consulting lists containing words which belong to different parts of speech.",4 The TEMPO Dataset,[0],[0]
"In particular, we rely on the preposition project (Litkowski and Hargraves, 2005)† to scrape relevant temporal words.",4 The TEMPO Dataset,[0],[0]
"Table 2 shows example temporal words and the number of times they occur in each dataset (TACoS (Regneri et al., 2013), Charades (Gao et al., 2017), DiDeMo (Hendricks et al., 2017)).",4 The TEMPO Dataset,[0],[0]
"Though all moment localization datasets use temporal words, they do not contain enough examples to reliably train and evaluate current models.",4 The TEMPO Dataset,[0],[0]
"Additionally, we observe that temporal words which are frequently used when describing video segments are different than those commonly used in text without video grounding.",4 The TEMPO Dataset,[0],[0]
"For example, in PrattHartmann (2004), “during” is a common example, but we observe that “during” is infrequently used when describing video.",4 The TEMPO Dataset,[0],[0]
"Of temporal words, we focus on the four most common words, “before”, “after”, “then”, and “while” when creating our dataset.
",4 The TEMPO Dataset,[0],[0]
TEMPO - Template Language.,4 The TEMPO Dataset,[0],[0]
"To construct sentences in TEMPO-TL, we find adjacent moments in the DiDeMo dataset and fill in template sentences for “before”, “after”, and “then” temporal words.",4 The TEMPO Dataset,[0],[0]
"For “before”, we use two templates: “X before Y ” and “Before Y , X”, where X and Y are sentences from the original DiDeMo dataset.",4 The TEMPO Dataset,[0],[0]
"Likewise for “after”, we consider the templates “X after Y ” and “After Y , X”.",4 The TEMPO Dataset,[0],[0]
"For “then” we only consider one template, “X then Y .”
TEMPO - Human Language.",4 The TEMPO Dataset,[0],[0]
"Though the template dataset is an interesting testbed for understanding temporal language, it is difficult to replicate the interesting complexities in human language.",4 The TEMPO Dataset,[0],[0]
"For example, when writing long sen-
†http://www.clres.com/prepositions.",4 The TEMPO Dataset,[0],[0]
"html
",4 The TEMPO Dataset,[0],[0]
"The girl looks at the camera and waves
The little girl turns and waves at the camera while on her skates.",4 The TEMPO Dataset,[0],[0]
"After the girl waves at the camera she continues to skate.
",4 The TEMPO Dataset,[0],[0]
"tences with temporal prepositions, humans frequently make use of language structure such as coreference to form more cohesive statements.
",4 The TEMPO Dataset,[0],[0]
"To collect annotations, we follow the protocol in Hendricks et al. (2017) and segment videos into 5-second temporal segments.",4 The TEMPO Dataset,[0],[0]
"After collecting descriptions, we ensure descriptions are localizable by asking other workers to localize each moment.",4 The TEMPO Dataset,[0],[0]
"To collect data for “before”, “after”, and “then”, we ask annotators to describe a segment in relation to a “reference” moment from the DiDeMo dataset.",4 The TEMPO Dataset,[0],[0]
"For example, if the DiDeMo dataset includes a localized phrase like “the cat jumps”, annotators write a sentence which refers to the segment “the cat jumps” using a specific temporal word.",4 The TEMPO Dataset,[0],[0]
"We provide both the phrase (“the cat jumps”) and the reference moment to annotators, and the annotators provide a sentence describing a new moment which references the reference moment.
",4 The TEMPO Dataset,[0],[0]
TEMPO-HL includes unique properties which are hard to replicate with template data.,4 The TEMPO Dataset,[0],[0]
"Figure 3
depicts the base moment provided to workers, as well as descriptions from TEMPO-HL.",4 The TEMPO Dataset,[0],[0]
"In Figure 3, the description “The adult hands the little boy the stick then they walk away” includes an example of visual coreference (“they”).",4 The TEMPO Dataset,[0],[0]
"We note that use of pronouns is much more prevalent in TEMPO-HL, with 28.1% of sentences in TEMPOHL including pronouns (“he”, “she”, “it”) in contrast to 10.3% of sentences in the original DiDeMo dataset.",4 The TEMPO Dataset,[0],[0]
"Additionally, annotators will refer to the base moment with different language than originally used in the base moment (e.g., “the girl waves at the camera” versus the base moment “the girl looks at the camera and waves”) in order to make their sentences more fluent.",4 The TEMPO Dataset,[0],[0]
Evaluation Method.,5 Experiments,[0],[0]
"We follow the evaluation protocol defined for the DiDeMo dataset (Hendricks et al., 2017) over all possible combinations of the five-second video segments.",5 Experiments,[0],[0]
"We report rank at one (R@1), rank at five (R@5), and mean intersection over union (mIOU) using their aggregator over three out of the four human annotators.",5 Experiments,[0],[0]
"We compare our models on TEMPOTL, TEMPO-HL, and the DiDeMo dataset.",5 Experiments,[0],[0]
"When training our models, we combine the DiDeMo dataset with TEMPO-TL or TEMPO-HL.",5 Experiments,[0],[0]
"This enables our model to concurrently learn to localize the simpler DiDeMo sentences with more complex TEMPO sentences.
",5 Experiments,[0],[0]
Baselines.,5 Experiments,[0],[0]
"We compare to the two recently proposed approaches for video moment localization: MCN (Hendricks et al., 2017) and TALL (Gao et al., 2017).",5 Experiments,[0],[0]
"We adapt the implementation of TALL (Gao et al., 2017) to the DiDeMo dataset in three ways.",5 Experiments,[0],[0]
"First, we do not include the temporal localization loss required to regress to specific start and end points as DiDeMo, and thus also TEMPO, is pre-segmented, so the model does not need to compute exact start and end points.",5 Experiments,[0],[0]
"Second, the original TALL model uses C3D features.
",5 Experiments,[0],[0]
For a fair comparison we train both models with the same RGB and flow features extracted as was done for the original MCN model.,5 Experiments,[0],[0]
"Finally, the MCN model proposes temporal endpoint features (TEF) to indicate when a proposed moment occurs within a video.",5 Experiments,[0],[0]
"We train TALL with and without the TEF and show that TEF improves performance on the original DiDeMo dataset.
Ablations.",5 Experiments,[0],[0]
"To ablate our proposed latent context, we compare to other models which share the same MLLC base network.",5 Experiments,[0],[0]
We consider the MLLC model with global context and before/after context.,5 Experiments,[0],[0]
We also train a model with weakly supervised (WS) latent context and strongly supervised (SS) latent context.,5 Experiments,[0],[0]
"We also train models both with and without context TEF (conTEF).
",5 Experiments,[0],[0]
The MLLC Base Model.,5 Experiments,[0],[0]
We first ablate our MLLC base model (Table 3).,5 Experiments,[0],[0]
We train our models on TEMPO-TL and DiDeMo and evaluate on the original DiDeMo dataset.,5 Experiments,[0],[0]
All models are trained with global context.,5 Experiments,[0],[0]
We find that the ranking loss is preferable on the DiDeMo dataset (compare lines 1 and 2) and that TALL-similarity performs better than the distance based similarity of the MCN model (compare lines 1 and 5).,5 Experiments,[0],[0]
"A simpler version of the TALL-similarity, in which the concatenated element wise multiplication, element wise sum, and concatenation is replaced by a single normalized elementwise multiplication, increases R@1 by almost one point and increases mIoU by over two points (compare lines 5-7).",5 Experiments,[0],[0]
We call our best model the MLLC-Base model (line 7).,5 Experiments,[0],[0]
"Our MLLC-Base model performs better than previous models (MCN line 1 and TALL line 3).
",5 Experiments,[0],[0]
Results: TEMPO - TL.,5 Experiments,[0],[0]
We first compare different moment localization models on TEMPO - TL (Table 4).,5 Experiments,[0],[0]
"In particular, our model performs well on “before” and “after” words.",5 Experiments,[0],[0]
"Additionally,
our MLLC model with global context outperforms both the MCN model (Hendricks et al., 2017) and the TALL (Gao et al., 2017) model when considering all sentence types, verifying the strength of our base MLLC model.
",5 Experiments,[0],[0]
"Comparing MLLC with global context and MLLC with before/after context (compare row 4 and 5), we note that before/after context is important for localizing “before” and “after” moments.",5 Experiments,[0],[0]
"However, our model with strong supervision (row 9) outperforms the model trained with before and after context, suggesting that learning to reason about which context moment is correct (as opposed to being explicitly provided with the context before and after the moment) is beneficial.",5 Experiments,[0],[0]
"We note that strong supervision (SS) outperforms weak supervision (WS) (compare rows 7 and 9) and that the context TEF is important for best performance (compare rows 8 and 9).
",5 Experiments,[0],[0]
"We note that though the MLLC-global model outperforms our full model for “then” on TEMPOTL, our full model performs better on then for the TEMPO-HL (Table 6).",5 Experiments,[0],[0]
One possibility is that the “then” moments in TEMPO-TL do not require context to properly localize the moment.,5 Experiments,[0],[0]
"Because TEMPO-TL is constructed from DiDeMo sentences, constituent sentence parts are referring.",5 Experiments,[0],[0]
"For example, given an example sentence from TEMPO-TL (e.g., “The cross is seen for the first time then window is first seen in room”), the model does not need to reason about the ordering of “cross seen for the first time” and “window is seen for the first time” because both moments only happen once in the video.",5 Experiments,[0],[0]
"In contrast, when considering the sentence “The adult hands the little boy a stick then they begin to walk” (from Figure 3), “begin to walk” could refer to multiple video moments.",5 Experiments,[0],[0]
"Consequently, our model must reason about the temporal ordering of reference moments to properly localize the video moment.
",5 Experiments,[0],[0]
"On TEMPO - TL, sentences differ from original DiDeMo sentences solely because of the use of temporal words.",5 Experiments,[0],[0]
"Thus, we can do a controlled study of how well models understand temporal words.",5 Experiments,[0],[0]
"If a model has good temporal reasoning, then if it can localize a reference moment “the dog jumps” it should be easier for the model to localize the moment “the dog sits after the dog jumps”.",5 Experiments,[0],[0]
"To test whether models are capable of this, we look at only sentences in TEMPO - TL where the model has correctly localized the cor-
responding context moment in DiDeMo (Table 5).",5 Experiments,[0],[0]
We report the difference in performance when considering only sentences in which temporal context was properly localized and all sentences.,5 Experiments,[0],[0]
"On our model, performance on all three temporal word types increases when the context moment can be properly localized.",5 Experiments,[0],[0]
"When considering global context, performance on “before” and “after” actually decreases, suggesting global context does not understand temporal reasoning well.",5 Experiments,[0],[0]
"Finally, even when the context is correctly localized, there is still ample room for improvement on all three sentence types motivating future work on temporal reasoning for moment retrieval.
",5 Experiments,[0],[0]
Results: TEMPO - HL.,5 Experiments,[0],[0]
Table 6 compares performance on TEMPO - HL.,5 Experiments,[0],[0]
We compare our bestperforming model from training on the TEMPOTL (strongly supervised MLLC and conTEF) to prior work (MCN and TALL) and to MLLC with global and before/after context.,5 Experiments,[0],[0]
"Performance on TEMPO-HL is considerably lower than TEMPOTL suggesting that TEMPO-HL is harder than TEMPO-TL.
",5 Experiments,[0],[0]
"On TEMPO - HL, we observe similar trends as on TEMPO-TL.",5 Experiments,[0],[0]
"When considering all sentence
types, MLLC has the best performance across all metrics.",5 Experiments,[0],[0]
"In particular, our model has the strongest performance for all sentence types considering the mIoU metric.",5 Experiments,[0],[0]
"In addition to performing better on temporal words, our model also performs better on the original DiDeMo dataset.",5 Experiments,[0],[0]
"As was seen in TEMPO-TL, including before/after context performs better than our model trained with global context for both “before” and “after” words.
",5 Experiments,[0],[0]
The final row of Table 6 shows an upper bound in which the ground truth context is used at test time instead of the latent context.,5 Experiments,[0],[0]
"We note that results improve for “before”, “after”, and “then”, suggesting that learning to better localize context will improve results for these sentence types.
",5 Experiments,[0],[0]
Localizing Context Fragments.,5 Experiments,[0],[0]
"TEMPO-HL sentences can be broken into two parts: a basesentence fragment (which refers to the base moment), and a context-sentence fragment (which refers to the context moment).",5 Experiments,[0],[0]
"For example, for the sentence “The girl holds the ball before throwing it,”, “the girl holds the ball” is the base fragment and “throwing it” is the context fragment.",5 Experiments,[0],[0]
"A majority of the “before” and “after” sentences in TEMPO-HL are of the form “X before (or after) Y ”, so we can determine a list of sentence fragments by splitting sentences based on the temporal word.",5 Experiments,[0],[0]
"Given “before” and “after” sentences, we determine the ground truth context fragment by considering which reference moment was given to annotators.",5 Experiments,[0],[0]
We can then measure how well models localize context fragments.,5 Experiments,[0],[0]
"Table 7 compares two approaches to localizing context fragments: inputting just the context fragment into MLLC
TEMPO - Human Language (HL)
Getting up while holding baby.
",5 Experiments,[0],[0]
"Ground truth
The mother sheep leaves the babies, then the babies follow.
",5 Experiments,[0],[0]
"Ground truth
and reporting the context used by MLLC when inputting the entire query into our model.",5 Experiments,[0],[0]
"We find that our model reliably selects the correct context fragments, most likely because it can properly exploit temporal understanding of how the context fragment relates to the base fragment.
",5 Experiments,[0],[0]
Visualizing Context.,5 Experiments,[0],[0]
"In addition to a localized query, we can also visualize which context moment the temporal query refers to.",5 Experiments,[0],[0]
"Figure 4 shows predicted moments and their corresponding con-
text moments.",5 Experiments,[0],[0]
"For the query “The girl with a hat takes a drink before the girl without a hat waves”, the little girl in the hat drinks twice, but our model correctly localizes the time she drinks before the other girl waves.",5 Experiments,[0],[0]
"Likewise, for the moment “After zooming in to the dog, the dog darts across the grass and into the woods”, the dog darts towards the woods twice (at the beginning of the video and at the end).",5 Experiments,[0],[0]
"Our model properly localizes the moment when the dog runs towards the forest the second time as well as the context fragment “zooming in on dog” when localizing the moment.
",5 Experiments,[0],[0]
Discussion.,5 Experiments,[0],[0]
"We show promising results on both TEMPO-TL and TEMPO-HL, but there is potential improvement for building better frameworks for understanding temporal language.",5 Experiments,[0],[0]
"In Table 6, strongly supervising context at test time improves overall results, suggesting that models which can better localize context text will outperform our current model.",5 Experiments,[0],[0]
"Though TEMPO and DiDeMo have over 60,000 sentences combined, visual content is quite diverse.",5 Experiments,[0],[0]
"Integrating outside data sources (e.g., image retrieval and captioning) could possibly improve results on moment localization, both with and without temporal language queries.",5 Experiments,[0],[0]
"Additionally, in Table 5, even when the MLLC model can properly localize context, it does not always properly localize temporal sentences indicating that improved temporal reasoning can also improve our results.",5 Experiments,[0],[0]
"We believe our dataset, analysis, and method are an important step towards better moment retrieval models that effectively reason about temporal language.",5 Experiments,[0],[0]
We thank Anna Rohrbach for helpful feedback.,Acknowledgements,[0],[0]
"Localizing moments in a longer video via natural language queries is a new, challenging task at the intersection of language and video understanding.",abstractText,[0],[0]
"Though moment localization with natural language is similar to other language and vision tasks like natural language object retrieval in images, moment localization offers an interesting opportunity to model temporal dependencies and reasoning in text.",abstractText,[0],[0]
"We propose a new model that explicitly reasons about different temporal segments in a video, and shows that temporal context is important for localizing phrases which include temporal language.",abstractText,[0],[0]
"To benchmark whether our model, and other recent video localization models, can effectively reason about temporal language, we collect the novel TEMPOral reasoning in video and language (TEMPO) dataset.",abstractText,[0],[0]
"Our dataset consists of two parts: a dataset with real videos and template sentences (TEMPO Template Language) which allows for controlled studies on temporal language, and a human language dataset which consists of temporal sentences annotated by humans (TEMPO Human Language).",abstractText,[0],[0]
Localizing Moments in Video with Temporal Language,title,[0],[0]
Differential privacy is a mathematically rigorous notion of privacy that has become the de-facto gold-standard of privacy preserving data analysis.,1. Introduction,[0],[0]
"Informally, -differential privacy bounds the affect of a single datapoint on any result of the computation by .",1. Introduction,[0],[0]
In recent years the subject of private hypothesis testing has been receiving increasing attention (see Related Work below).,1. Introduction,[0],[0]
"However, by and large, the focus of private hypothesis testing is in the centralized model (or the curated model), where a single trusted entity holds the sensitive details of n users and runs the private hypothesis tester on the actual data.
",1. Introduction,[0],[0]
1Dept.,1. Introduction,[0],[0]
"of Computing Science, University of Alberta..",1. Introduction,[0],[0]
Correspondence to: Or Sheffet,1. Introduction,[0],[0]
"<osheffet@ualberta.ca>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"In contrast, the subject of this work is private hypothesis testing in the local-model (or the distributed model), where a -differentially private mechanism is applied independently to each datum.",1. Introduction,[0],[0]
"This model, which alleviates trust (each user can run the mechanism independently on her own and release the noisy signal from the mechanism), has gained much popularity in recent years, especially since it was adopted by Google’s Rappor (Erlingsson et al., 2014) and Apple (Apple, 2017).",1. Introduction,[0],[0]
"And yet, despite its popularity, and the fact that recent works (Bassily & Smith, 2015; Bassily et al., 2017) have shown the space of possible locally-private mechanism is richer than what was originally thought, little is known about private hypothesis testing in the local-model.",1. Introduction,[0],[0]
We view the local differentially private model as a signaling scheme.,1.1. Background: Local Differential Privacy,[0],[0]
Each datum / user has a type x taken from a predefined and publicly known set of possible types X whose size is T = |X |.,1.1. Background: Local Differential Privacy,[0],[0]
"The differentially private mechanism is merely a randomized function M : ([n],X ) → S, mapping each possible type X of the i-th datum to some set of possible signals S, which we assume to be -differentially private: for any index",1.1. Background: Local Differential Privacy,[0],[0]
"i, any pair of types x, x′ ∈ X and any signal s ∈ S",1.1. Background: Local Differential Privacy,[0],[0]
"it holds that Pr[M(i, x) = s] ≤ e Pr[M(i, x′) = s].1 In our most general results (Theorems 1 and 9), we ignore the fact thatM is -differentially private, and just refer to any signaling scheme that transforms one domain (namely, X ) into another (S).",1.1. Background: Local Differential Privacy,[0],[0]
"For example, a surveyer might unify rarely occurring types under the category of “other”, or perhaps users report their types over noisy channels, etc.
",1.1. Background: Local Differential Privacy,[0],[0]
"We differentiate between two types of signaling schemes: the symmetric (or index-oblivious) variety, and the nonsymmetric (index-aware) type.",1.1. Background: Local Differential Privacy,[0],[0]
A local signaling mechanism is called symmetric if it is independent of the index of the datum.,1.1. Background: Local Differential Privacy,[0],[0]
"Namely, if for any i 6=",1.1. Background: Local Differential Privacy,[0],[0]
"j we have that M(i, x) = M(j, x) def= M(x).",1.1. Background: Local Differential Privacy,[0],[0]
"A classic exam-
1For simplicity, we assume S, the set of possible signals, is discrete.",1.1. Background: Local Differential Privacy,[0],[0]
Note that this doesn’t exclude mechanisms such as adding Gaussian/Gamma noise to a point in Rd — such mechanisms require X to be some bounded subset of Rd and use the bound to set the noise appropriately.,1.1. Background: Local Differential Privacy,[0],[0]
"Therefore, the standard approach of discretizing X and projecting the noisy point to the closest point in the grid yields a finite set of signals S.
ple of such a mechanism is randomized-response — that actually dates back to before differential privacy was defined (Warner, 1965) and was first put to use in differential privacy in (Kasiviswanathan et al., 2008) — where each user / datum x draws her own signal from the set S = X skewing the probability ever-so-slightly in favor of the original type.",1.1. Background: Local Differential Privacy,[0],[0]
"I.e. if the user’s type is x then
M(x) =
{ x, w.p. e
T−1+e
x′, for any other x′ w.p. 1T−1+e .
",1.1. Background: Local Differential Privacy,[0],[0]
"The utility of the above-mentioned symmetric mechanism scales polynomially with T (or rather, with |S|), which motivated the question of designing local mechanisms with error scaling logarithmically in T .",1.1. Background: Local Differential Privacy,[0],[0]
"This question was recently answered in the affirmative by the works of Bassily and Smith (2015) and Bassily et al (2017), whose mechanisms are not symmetric.",1.1. Background: Local Differential Privacy,[0],[0]
"In fact, both of them work by presenting each user i with a mapping fi : X → S (the mapping itself is chosen randomly, but it is public, so we treat it as a given), and the user then runs the standard randomized response mechanism on the signals using fi(x) as the more-likely signal.",1.1. Background: Local Differential Privacy,[0],[0]
"(In fact, in both schemes, S = {1,−1}: in (Bassily & Smith, 2015) fi is merely the j-th coordinate of a hashing of the types where j and the hashing function are publicly known, and in (Bassily et al., 2017) fi maps a u.a.r chosen subset of X to 1 and its complementary to −1.2)",1.1. Background: Local Differential Privacy,[0],[0]
"So given fi, the user then tosses her own private random coins to determine what signal she broadcasts.",1.1. Background: Local Differential Privacy,[0],[0]
"Therefore, each user’s mechanism can be summarized in a |S| × |X |-matrix, where Mi(s, x) is the probability a user of type x sends the signal s.",1.1. Background: Local Differential Privacy,[0],[0]
"For example, using the mechanism of (Bassily et al., 2017), each user whose type maps to 1 sends “signal 1” with probability e
1+e and “signal −1” with probability 1 1+e .",1.1. Background: Local Differential Privacy,[0],[0]
"Namely, Mi(fi(x), x) = e 1+e andMi(−fi(x), x) = 1
1+e , where fi is the mapping X → {1,−1} set for user i.",1.1. Background: Local Differential Privacy,[0],[0]
This work initiates (to the best of our knowledge) the theory of differentially private hypothesis testing in the local model.,1.2. Our Contribution and Organization,[0],[0]
First we survey related work and preliminaries.,1.2. Our Contribution and Organization,[0],[0]
"Then, in Section 3, we examine the symmetric case and show that any mechanism (not necessarily a differentially private one) yields a distribution on the signals for which finding a maximum-likelihood hypothesis is feasible, assuming the set of possible hypotheses is convex.",1.2. Our Contribution and Organization,[0],[0]
"Then, focusing on the classic randomized-response mechanism, we show that the problem of maximizing the likelihood of the observed signals is strongly-convex and thus simpler than the original problem.",1.2. Our Contribution and Organization,[0],[0]
"More importantly, in essence
2In both works, much effort is put to first reducing T to the most frequent √ n types, and then run the counting algorithm.",1.2. Our Contribution and Organization,[0],[0]
"Regardless, the end-counts / collection of users’ signals are the ones we care for the sake of hypothesis testing.
",1.2. Our Contribution and Organization,[0],[0]
we give a characterization of hypothesis testing under randomized response: the symmetric locally-private mechanism translates the original null hypothesis,1.2. Our Contribution and Organization,[0],[0]
H0 (and the alternative H1) by a known affine translation into a different set ϕ(H0) (and resp. ϕ(H1)).,1.2. Our Contribution and Organization,[0],[0]
"Hence, hypothesis testing under randomized-response boils to discerning between two different (and considerably closer in total-variation distance) sets, but in the exact same model as in standard hypothesis testing as all signals were drawn from the same hypothesis in ϕ(H0).",1.2. Our Contribution and Organization,[0],[0]
As an immediate corollary we give bounds on identity-testing (Corollary 5) and independencetesting (Theorem 6) under randomized-response.,1.2. Our Contribution and Organization,[0],[0]
(The latter requires some manipulations and far less straightforward than the former.),1.2. Our Contribution and Organization,[0],[0]
"The sample complexity (under certain simplifying assumptions) of both problems is proportional to T 2.5.
",1.2. Our Contribution and Organization,[0],[0]
In Section 4 we move to the non-symmetric local-model.,1.2. Our Contribution and Organization,[0],[0]
"Again, we start with a general result showing that in this case too, finding an hypothesis that maximizes the likelihood of the observed signals is feasible when the hypothesis-set is convex.",1.2. Our Contribution and Organization,[0],[0]
We then focus on the mechanism of Bassily et al (2017) and show that it also makes the problem of finding a maximum-likelihood hypothesis strongly-convex.,1.2. Our Contribution and Organization,[0],[0]
"We then give a simple identity tester under this scheme whose sample complexity is proportional to T 2, and is thus more efficient than any tester under standard randomized-response.",1.2. Our Contribution and Organization,[0],[0]
"Similarly, we also give an independence-tester with a similar sample complexity.",1.2. Our Contribution and Organization,[0],[0]
"In Section 4.2 we empirically investigate alternative identitytesting and independence-testing based on Pearson’s χ2test in this non-symmetric scheme, and identify a couple of open problems in this regime.",1.2. Our Contribution and Organization,[0],[0]
"Several works have looked at the intersection of differential privacy and statistics (Dwork & Lei, 2009; Smith, 2011; Chaudhuri & Hsu, 2012; Duchi et al., 2013a; Dwork et al., 2015) mostly focusing on robust statistics; but only a handful of works study rigorously the significance and power of hypotheses testing under differential privacy.",1.3. Related Work,[0],[0]
Vu and Slavkovic (2009) looked at the sample size for privately testing the bias of a coin.,1.3. Related Work,[0],[0]
"Johnson and Shmatikov (2013), Uhler et al (2013) and Yu et al (2014) focused on the Pearson χ2-test (the simplest goodness of fit test), showing that the noise added by differential privacy vanishes asymptotically as the number of datapoints goes to infinity, and propose a private χ2-based test which they study empirically.",1.3. Related Work,[0],[0]
"Wang et al (2015) and Gaboardi et al (2016) who have noticed the issues with both of these approaches, have revised the statistical tests themselves to incorporate also the added noise in the private computation.",1.3. Related Work,[0],[0]
"Cai et al (2017) give a private identity tester based on noisy χ2-test over large bins, Sheffet (2017) studies private Ordinary Least Squares using the JL transform, and Karwa and Vadhan (2018) give
matching upper- and lower-bounds on the confidence intervals for the mean of a population.",1.3. Related Work,[0],[0]
"All of these works however deal with the centralized-model of differential privacy.
",1.3. Related Work,[0],[0]
Perhaps the closest to our work are the works of Duchi et al (2013a; 2013b) who give matching upper- and lowerbound on robust estimators in the local model.,1.3. Related Work,[0],[0]
"And while their lower bounds do inform as to the sample complexity’s dependency on −2, they do not ascertain the sample complexity dependency on the size of the domain (T ) we get in Section 3.",1.3. Related Work,[0],[0]
"Moreover, these works disregard independence testing (and in fact (Duchi et al., 2013b) focus on mean estimation so they apply randomized-response to each feature independently generating a product-distribution even when the input isn’t sampled from a product-distribution).",1.3. Related Work,[0],[0]
"And so, to the best of our knowledge, no work has focused on hypothesis testing in the local model, let alone in the (relatively new) non-symmetric local model.",1.3. Related Work,[0],[0]
"Lastly, developed concurrently to our work, Gaboardi and Rogers (2018) study the asymptotic power of a variety chi-squared based hypothesis testing in the local model.",1.3. Related Work,[0],[0]
Notation.,"2. Preliminaries, Notation and Background",[0],[0]
"We user lower-case letters to denote scalars, bold characters to denote vectors and CAPITAL letters to denote matrices.","2. Preliminaries, Notation and Background",[0],[0]
"So 1 denotes the number, 1 denotes the all-1 vector, and 1X×X denotes the all-1 matrix over a domain X .","2. Preliminaries, Notation and Background",[0],[0]
"We use ex to denote the standard basis vector with a single 1 in coordinate corresponding to x. To denote the x-coordinate of a vector v we use v(x), and to denote the (x, x′)-coordinate of a matrix M we use M(x, x′).","2. Preliminaries, Notation and Background",[0],[0]
"For a given vector v , we use diag(v) to denote the matrix whose diagonal entries are the coordinates of v .","2. Preliminaries, Notation and Background",[0],[0]
"For any natural n, we use [n] to denote the set {1, 2, ..., n}.
Distances and norms.","2. Preliminaries, Notation and Background",[0],[0]
"Unless specified otherwise ‖v‖ refers to the L2-norm of v , whereas ‖v‖1 refers to the L1-
norm.","2. Preliminaries, Notation and Background",[0],[0]
"We also denote ‖v‖ 2 3
= (∑
i |vi| 2 3
) 3 2
.","2. Preliminaries, Notation and Background",[0],[0]
"For a matrix, ‖M‖1 denotes (as usual) the maximum absolute column sum.","2. Preliminaries, Notation and Background",[0],[0]
We identify a distribution p over a domain X as a T -dimensional vector with non-negative entries that sum to 1.,"2. Preliminaries, Notation and Background",[0],[0]
"This defines the total variation distance between two distributions: dTV(p,q) = 12‖p","2. Preliminaries, Notation and Background",[0],[0]
− q‖1.,"2. Preliminaries, Notation and Background",[0],[0]
"(On occasion, we will apply dTV to vectors that aren’t distributions, but rather nearby estimations; in those cases we use the same definition: the half of the L1-norm.)","2. Preliminaries, Notation and Background",[0],[0]
It is known that the TV-distance is a metric overs distributions.,"2. Preliminaries, Notation and Background",[0],[0]
"We also use the χ2-divergence to measure difference between two distributions: dχ2(p,q) = ∑ x (p(x)−q(x))2 p(x) =","2. Preliminaries, Notation and Background",[0],[0]
(∑ x (q(x))2 p(x) ),"2. Preliminaries, Notation and Background",[0],[0]
− 1.,"2. Preliminaries, Notation and Background",[0],[0]
"The χ2-divergence is not symmetric and can be infinite, however it is non-negative and zeros only when p = q .","2. Preliminaries, Notation and Background",[0],[0]
"We refer the reader to (Sason & Verdú, 2016) for more properties of the total-variance distance the χ2-divergence.
","2. Preliminaries, Notation and Background",[0],[0]
Differential Privacy.,"2. Preliminaries, Notation and Background",[0],[0]
"An algorithm A is called - differentially private, if for any two datasets D and D′ that differ only on the details of a single user and any set of outputsO, we have that Pr[A(D) ∈","2. Preliminaries, Notation and Background",[0],[0]
O] ≤ e Pr[A(D′) ∈,"2. Preliminaries, Notation and Background",[0],[0]
O].,"2. Preliminaries, Notation and Background",[0],[0]
"The unacquainted reader is referred to the Dwork-Roth monograph (Dwork & Roth, 2014) as an introduction to the rapidly-growing field of differential privacy.
","2. Preliminaries, Notation and Background",[0],[0]
Hypothesis testing.,"2. Preliminaries, Notation and Background",[0],[0]
The problem of hypothesis testing is to test whether a given set of samples was drawn from a distribution satisfying the null-hypothesis or the alternativehypothesis.,"2. Preliminaries, Notation and Background",[0],[0]
"Thus, the null-hypothesis is merely a set of possible distributions H0 and the alternative is disjoint set H1.","2. Preliminaries, Notation and Background",[0],[0]
Hypothesis tests boils down to estimating a teststatistic θ whose distribution has been estimated under the null-hypothesis.,"2. Preliminaries, Notation and Background",[0],[0]
"We can thus reject the null-hypothesis if the value of θ is highly unlikely, or accept the nullhypothesis otherwise.","2. Preliminaries, Notation and Background",[0],[0]
We call an algorithm a tester if the acceptance (in the completeness case) or rejection (in the soundness case) happen with probability ≥ 2/3.,"2. Preliminaries, Notation and Background",[0],[0]
Standard amplification techniques (return the median of independent tests) reduce the error probability from 1/3 to any β > 0,"2. Preliminaries, Notation and Background",[0],[0]
at the expense of increasing the sample complexity by a factor of O(log(1/β)); hence we focus on achieving a constant error probability.,"2. Preliminaries, Notation and Background",[0],[0]
"One of the most prevalent and basic tests is the identity-testing, where the null-hypothesis is composed of a single distribution H0 = {p} and our goal is to accept if the samples are drawn from p and reject if they were drawn from any other α-far (in dTV) distribution.","2. Preliminaries, Notation and Background",[0],[0]
"Another extremely common tester is for independence when X is composed of several features (i.e., X = X 1 ×X 2 × ...×X d) and the null-hypothesis is composed of all product distributions H0 = {p1 × ...","2. Preliminaries, Notation and Background",[0],[0]
"× pd} where each pj is a distribution on the jth feature X j .
Miscellaneous.","2. Preliminaries, Notation and Background",[0],[0]
"We use M 0 to denote that M is a positive semi-definite (PSD) matrix, and M N to denote that (M − N) 0.","2. Preliminaries, Notation and Background",[0],[0]
We use M† to denote M ’s pseudoinverse.,"2. Preliminaries, Notation and Background",[0],[0]
"We emphasize that we made no effort to minimize constants in our proofs, and only strived to obtain asymptotic bounds (O(·),Ω(·)).","2. Preliminaries, Notation and Background",[0],[0]
"Recall, in the symmetric signaling scheme, each user’s type is mapped through a random functionM into a set of signals S.",3. Symmetric Signaling Scheme,[0],[0]
"This mapping is index-oblivious — each user of type x ∈ X , sends the signal s with the same probability Pr[M(x) = s].",3. Symmetric Signaling Scheme,[0],[0]
"We denote the matrixG as the (|S|×|X |)- matrix whose entries are Pr[M(x) = s], and its sth-row by gs.",3. Symmetric Signaling Scheme,[0],[0]
Note that all entries of G are non negative and that for each x we have ‖Gex‖1 = 1.,3. Symmetric Signaling Scheme,[0],[0]
"By garbling each datum i.i.d, we observe the new dataset (y1, y2, ...,",3. Symmetric Signaling Scheme,[0],[0]
"yn) ∈ Sn.
Theorem 1.",3. Symmetric Signaling Scheme,[0],[0]
"For any convex setH of hypotheses, the problem of finding the max-likelihood p ∈ H generating the observed signals (y1, .., yn) is poly-time solvable.
",3. Symmetric Signaling Scheme,[0],[0]
Proof.,3. Symmetric Signaling Scheme,[0],[0]
"Since G(s, x) describes the probability that a user of type x sends the signal s, any distribution p ∈ H over the types in X yields a distribution on S where Pr[user sends s] = ∑ x∈X G(s, x) · p(x) = gTsp.",3. Symmetric Signaling Scheme,[0],[0]
"Therefore, given signals (y1, ..., yn) summarized as a signalshistogram 〈ns〉s∈S , the likelihood of these signals is given by: L(p; y1, ..., yn) = ∏",3. Symmetric Signaling Scheme,[0],[0]
"i g T yip = ∏ s∈S(g T s p) ns =
exp (∑ s ns log(g T sp) ) .",3. Symmetric Signaling Scheme,[0],[0]
"Thus, the gradient of the negative
log-loss function is∇f = − 1n ∑ s∈S ns gTsp ·gs, and its Hes-
sian is given by the matrix 1n ∑ s∈S ns (gTsp) 2gsg T s .",3. Symmetric Signaling Scheme,[0],[0]
"Clearly, as a non-negative sum of rank-1 matrices, the Hessian is a PSD matrix.so our loss-function is convex.",3. Symmetric Signaling Scheme,[0],[0]
"Known polytime algorithms for minimizing a convex function over a convex set (e.g. (Zinkevich, 2003)) conclude the proof.
",3. Symmetric Signaling Scheme,[0],[0]
"Unfortunately, in general the solution to this problem has no closed form (to the best of our knowledge).",3. Symmetric Signaling Scheme,[0],[0]
"However, we can find a close-form solution under the assumption that G isn’t just any linear transformation but rather one that induces probability distribution over S, the assumption that |S| ≤ |X | (in all applications we are aware of use fewer signals than user-types) and one extra-condition.
",3. Symmetric Signaling Scheme,[0],[0]
Corollary 2.,3. Symmetric Signaling Scheme,[0],[0]
Let q∗ be the |S|-dimensional vector given by 〈nsn 〉.,3. Symmetric Signaling Scheme,[0],[0]
"Given that |S| ≤ |X |, that G is a full-rank matrix satisfying ‖G‖1 = 1 and assuming that ( G†q∗+ker(G) ) ∩",3. Symmetric Signaling Scheme,[0],[0]
H 6=,3. Symmetric Signaling Scheme,[0],[0]
"∅, then any vector inH of the form p∗+u where p∗ = G†q∗",3. Symmetric Signaling Scheme,[0],[0]
"and u ∈ ker(G) is an hypothesis that maximizes the likelihood of the given signals (y1, ..., yn).",3. Symmetric Signaling Scheme,[0],[0]
"Proof deferred to the supplementary material, Section B.",3. Symmetric Signaling Scheme,[0],[0]
"We now aim to check the affect of a particular G, the one given by the randomized-response mechanism.",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"In this case S = X and we denote G as the matrix whose entries are
G(x, x′) = {",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"ρ+ γ , if x′ = x ρ , otherwise where ρ def= 1T−1+e
and γ def= e −1
T−1+e .",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
We get that G = ρ · 1X×X + γI (where 1X×X is the all-1 matrix).,3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"In particular, all vectors gs = gx, which correspond to the rows of G, are of the form: gx = ρ1 + γex.",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
It follows that for any probability distribution p ∈ H we have that Pr[seeing signal x] = gTxp = ρ+ γp(x).,3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"We have therefore translated any p ∈ H (over X ) to an hypothesis q over S (which in this case S = X ), using the affine transformation ϕ(p) = ρ1 +γp = TρuX +γp when uX denotes the uniform distribution over X .",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"(Indeed, γ = 1 − Tρ, an identity we will often apply.)",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"At the risk of overburdening notation, we use ϕ to denote the same transformation over scalars, vectors and even sets (applying ϕ to each vector in the set).",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"Since ϕ is injective, we have therefore discovered the following theorem.
",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
Theorem 3.,3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"Under the classic randomized response mechanism, testing for any hypothesis H0 (or for comparing H0 against the alternative H1) of the original distribution,
translates into testing for hypothesis ϕ(H0) (or ϕ(H0) against ϕ(H1)) for generating the signals y1, ..., yn.",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"Theorem 3 seems very natural and simple, and yet (to the best of our knowledge)",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"it was never put to words.
",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"Moreover, it is simple to see that under standardrandomized response, our log-loss function is in fact strongly-convex, and therefore finding p∗ becomes drastically more efficient (see, for example (Hazan et al., 2006)).
",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
Claim 4.,3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"Given signals y1, ..., yn generated using standard randomized response with parameter < 1, we have that our log-loss function is Θ( 2 · minx{nx}n )-strongly convex.",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"Note that in expectation nx ≥ ρn, hence with overwhelming probability we have minx nx ≥ n/(2T ).",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"The proof is fairly straight-forward and is deferred to the supplementary material, Section B.
A variety of corollaries follow from Theorem 3.",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"In particular, a variety of detailing matching sample complexity upper- and lower-bounds translate automatically into the realm of making such hypothesis-tests over the outcomes of the randomized-response mechanism.",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"We focus here on two of the most prevalent tests: identity testing and independence testing.
",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
Identity Testing.,3.1. Hypothesis Testing under Randomized-Response,[0],[0]
Perhaps the simplest of the all hypothesis testing is to test whether a given sample was generated according to a given distribution or not.,3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"Namely, the null hypothesis is a single hypothesis H0 = {p}, and the alternative is H1 = {q : dTV(p,q) ≥ α} for a given parameter α.",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"The seminal work of Valiant and Valiant (2014) discerns that (roughly) Θ(‖p‖ 2
3 /α2)",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"samples are sufficient
and are necessary for correctly rejecting or accepting the null-hypothesis w.p.≥ 2/3.3
Here, the problem of identity testing under standard randomized response reduces to the problem of hypothesis testing between ϕ(H0) = {ρ1 + γp : p ∈",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
H0} and ϕ(H1),3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"= {ϕ(q) : q satisfying dTV(p,q) ≥ α}.",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
Corollary 5.,3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"In order to do identity testing under standard randomized response with confidence and power ≥ 2/3, it is necessary and sufficient that we get Θ( T 2.5
2α2 ) samples.",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"The proof uses the results of (Valiant & Valiant, 2014) as a black-box and is mainly composed of calculations, so it is deferred to supplementary material, Section B.
Independence Testing.",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
Another prevalent hypothesis testing over a domain X where each type is composed of multiple feature is independence testing.,3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"Denoting X = X 1 × X 2 × ... × X d as a domain with d possible features (hence T = |X | = ∏ j |X j | def = ∏ j T
j), our goal is to discern whether an observed sample is drawn from a product distribution or a distribution α-far from any product distri-
3For the sake of brevity, we ignore pathological examples where by removing α probability mass from p we obtain a vector of significantly smaller 2
3 -norm.
bution.",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"In particular, the null-hypothesis in this case is a complex one:",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"H0 = {p̄ = p1×p2× ...×pd} and the alternative is H1 = {q : minp̄∈H0 dTV(q, p̄) ≥ α}.",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"To the best of our knowledge, the (current) tester with smallest sample complexity is of Acharya et al (2015), which requires Ω ( ( √ T + ∑ j T j)/α2 ) iid samples.
",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
We now consider the problem of testing for independence under standard randomized response.,3.1. Hypothesis Testing under Randomized-Response,[0],[0]
Our goal is to prove the following theorem.,3.1. Hypothesis Testing under Randomized-Response,[0],[0]
Theorem 6.,3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"There exists an algorithm that takes n =
Ω̃( T 2
α2 2
( d2(max
j {T j})2",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"+
√ T ) )",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"signals generated by
applying standard randomized response (with < 1) on n samples drawn from a distribution p and with probability ≥ 2/3 accepts if p ∈ H0, or rejects if p ∈ H1.",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"Moreover, no algorithm can achieve such guarantee using n = o(T 5/2/(α2 2)) signals.",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"Note there are at least two types per feature, so d ≤ log2(T ).",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"Should all T
js be equal we have (T j)2 ≤ T 2d , making T 2.5/(α2 2) the leading term in the above bound.
",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
Proof.,3.1. Hypothesis Testing under Randomized-Response,[0],[0]
Theorem 3 implies we are comparing ϕ(H0) = {ρ1X+γ(p1×...×pd)} to ϕ(H1) = {ρ1X+γq : q ∈ H1}.,3.1. Hypothesis Testing under Randomized-Response,[0],[0]
Note that ϕ(H0) is not a subset of product-distributions over X but rather a convex combination (with publicly known weights) of the uniform distribution and H0; so we cannot run the independence tester of Acharya et al on the signals as a black-box.,3.1. Hypothesis Testing under Randomized-Response,[0],[0]
Luckily it holds that ϕ(H1) is far from all distributions in ϕ(H0): for each q ∈ H1 and p̄ ∈,3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"H0 we have dTV(ϕ(q), ϕ(p̄))",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"≥ γdTV(q, p̄) ≥ γα.",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"And so we leverage on the main result of Acharya et al ((2015), Theorem 2): we first find a distribution ρ1 + γz̄ ∈ ϕ(H0) such that if the signals were generated by some ρ1X + γp̄ ∈ ϕ(H0) then dχ2(ϕ(z̄), ϕ(p̄))",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"≤ γ2α2/500, and then test if indeed the signals are likely to be generated by a distribution close to ϕ(z̄) using Acharya et al’s algorithm.",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"We now give our procedure for finding the product-distribution z̄ .
",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"Per feature j, given the jth feature of the signals yj1, ..., y j n where each xj ∈ X j appears nxj times, our procedure for finding zj is as follows.
0.",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
(Preprocessing:) Denote τ = α/(10d · T j).,3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"We call any type xj where nxjn ≤ 1−γ T j + γτ as small and
otherwise we say type xj is large.",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"Ignore all small types, and learn zj only over large types.",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"(For brevity, we refer to n as the number of signals on large types and T j as the number of large types.)
",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"1. Set the distribution z̃j as the “add-1” estimator of Kamath et al (2015) for the signals: z̃j(xj) = 1+nxjT j+n .
2.",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"Compute zj = 1γ ( I − 1−γT j 1X j ) z̃j .
",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"Once zj is found for each feature j, set z̄ = z1 × ...",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"× zd run the test of Acharya et al (2015) (Theorem 2) with ϕ(z̄) looking only at the large types from each feature, setting
the distance parameter to αγ2 and confidence 1 9 , to decide whether to accept or reject.
",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"In order to successfully apply the Acharya et al’s test, a few conditions need to hold.",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"First, the provided distribution ϕ(z̄) should be close to ϕ(H0).",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"This however hold trivially, as z̄ is a product-distribution.",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"Secondly, we need that ϕ(z̄) and ϕ(p̄) to be close in χ2-divergence, as we argue next.
",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
Lemma 7.,3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"Suppose that n, the number of signals, is at least Ω( d 2
α2γ2 maxj{T j}).",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"Then the above procedure cre-
ates distributions zj such that the product distribution z̄ = z1×z2× ...×zd satisfies the following property.",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"If the signals y1, ..., yn were generated by ϕ(p̄) for some productdistribution p̄ = p1 × ...",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"× pd, then w.p. ≥ 8/9 we have that dχ2(ϕ(z̄), ϕ(p̄)) ≤ γ2α2/1000.",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
We table the proof of Lemma 7 to Section B in the supplementary material.,3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"Next, either completeness or soundness must happen: either the signals were taken from randomized-response on a product distribution, or they were generated by a distribution γα/2-far from ϕ(H0).",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"If no type of any feature was deemed as “small”, this condition clearly holds; but we need to argue this continues to hold even when we run our tester on a strict subset of X composed only of large types in each feature.",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"Completeness is straight-forward: since we remove types feature by feature, the types now come from a product distribution p̄large = p 1 large × ...",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
× pdlarge where each pjlarge is a restriction of p j to the large types of feature j. Soundness however is more intricate.,3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"We partition X into two subsets: AllLarge = {(x1, x2, ..., xd) ∈ X : ∀j, xj is large} and Rest = X \AllLarge; and break q into q = ηqRest + (1− η)qAllLarge, with η = Prq [Rest].",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
Claim 8 (proof deferred to the supplementary material) argues that η < α2 .,3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"Therefore, dTV(q, qAllLarge) ≤ α 2 , implying that dTV(ϕ(qAllLarge), ϕ(H0))",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
> α · γ− αγ2 = αγ 2 .,3.1. Hypothesis Testing under Randomized-Response,[0],[0]
Claim 8.,3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"Assume the underlying distribution of the samples is q and that the number of signals is at least n = Ω( d2(maxj T j)2
α2γ2 log(dmaxj T j)).",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"Then w.p. ≥ 8/9 our
preprocessing step marks certain types each feature as “small” such that the probability (under q) of sampling a type (x1, x2, ..., xd) such that ∃j, xj is small is ≤ α/2.",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"So, given that both Lemma 7 and Claim 8 hold, we can use the test of Acharya et al, which requires a sample of size n = Ω( √ T/(αγ)2).",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
Recall that < 1,3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"so γ = Θ( /T ), and we get that the sample size required for the last test is n = Ω( T 2.5
α2 2 ).",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"Moreover, for this last part, the lower bound in Acharya et al (2015) still holds (for the same reason it holds in the identity-testing case): the lower bound is derived from the counter example of testing whether the signals were generated from the uniform distribution (which clearly lies in ϕ(H0)) or any distribution from a collection of perturbations which all belong to ϕ(H1) (See (Paninski, 2008) for more details).",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"Each of distribution is thus γα-far from ϕ(H0) and so any tester for this particular construc-
tion requires √ T/(αγ)2-many samples.",3.1. Hypothesis Testing under Randomized-Response,[0],[0]
This proves both the upper- and lower-bounds of Theorem 6.,3.1. Hypothesis Testing under Randomized-Response,[0],[0]
"Let us recall the non-symmetric signaling schemes in (Bassily & Smith, 2015; Bassily et al., 2017).",4. Non-Symmetric Signaling Schemes,[0],[0]
"Each user, with true type x ∈ X , is assigned her own mapping (the mapping is broadcast and publicly known) fi : X → S .",4. Non-Symmetric Signaling Schemes,[0],[0]
"This sets her inherent signal to fi(x), and then she runs standard (symmetric) randomized response on the signals, making the probability of sending her true signal fi(x) to be e -times greater than any other signal s 6= fi(x).
",4. Non-Symmetric Signaling Schemes,[0],[0]
"In fact, let us allow an even broader look.",4. Non-Symmetric Signaling Schemes,[0],[0]
"Each user is given a mapping fi : X → S, and denoting (like before) T = |X | and S = |S|, we identify this mapping with a (S × T )-matrix Gi.",4. Non-Symmetric Signaling Schemes,[0],[0]
The column gxi = Giex is the probability distribution that a user of type x is going to use to pick which signal she broadcasts.,4. Non-Symmetric Signaling Schemes,[0],[0]
(And so the guarantee of differential privacy is that for any signal s ∈ S and any two types x 6=,4. Non-Symmetric Signaling Schemes,[0],[0]
x′ we have that gxi (s) ≤,4. Non-Symmetric Signaling Schemes,[0],[0]
"e gx ′
i (s).)",4. Non-Symmetric Signaling Schemes,[0],[0]
"Therefore, all entries in Gi are non-negative and ‖Gi‖1",4. Non-Symmetric Signaling Schemes,[0],[0]
"= 1 for all is.
",4. Non-Symmetric Signaling Schemes,[0],[0]
"Similarly to the symmetric case, we first exhibit the feasibility of finding a maximum-likelihood hypothesis given the signals from the non-symmetric scheme.",4. Non-Symmetric Signaling Schemes,[0],[0]
"Since we view which signal in S was sent, our likelihood mainly depends on the row vectors gsi .",4. Non-Symmetric Signaling Schemes,[0],[0]
"We prove the following theorem, proof deferred to Section C in the supplementary material.
",4. Non-Symmetric Signaling Schemes,[0],[0]
Theorem 9.,4. Non-Symmetric Signaling Schemes,[0],[0]
"For any convex set H , the problem of finding the max-likelihood p ∈ H generating the observed nonsymmetric signals (y1, .., yn) is poly-time solvable.",4. Non-Symmetric Signaling Schemes,[0],[0]
Let us recap the differentially private scheme of Bassily et al (2017).,4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"It this scheme, the mechanism uses solely two signals S = {1,−1} (so S = 2).",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"For every i the mechanism sets Gi by picking u.a.r for each x ∈ X which of the two signals in S is more likely; the chosen signal gets a probability mass of e
1+e and the other get probability mass of 11+e .",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"We denote η as the constant such that 1 2 + η = e
1+e and 1 2 − η = 1 1+e ; namely η = e −1 2(e +1) =
Θ( )",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
when < 1.,4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"Thus, for every s ∈ {1,−1} the row vector gsi is chosen such that each coordinate is chosen iid and uniformly from { 12 + η, 1 2 − η}.",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"(Obviously, there’s dependence between g1i and g −1",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"i , as g 1 i + g −1",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"i = 1, but the distribution of g1i is identical to the one of g −1",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"i .)
",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"First we argue that for any distribution p, if n is sufficiently large then w.h.p over the generation of theGis and over the signals we view from each user, then finding p̂ which maximizes the likelihood of the observed signals yields a good approximation to p. To that end, it suffices to argue that the function we optimize is Lipfshitz and strongly-convex.
",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
Lemma 10.,4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
Fix δ > 0 and assume that the number of signals we observe is n = Ω(T 3 log(1/δ)).,4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
Then w.p.≥ 1− δ,4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"it holds that the function f(p) we optimize (as given in
Equation (1)) is ( 3 √ T ) -Lipfshitz",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"and ( η2
2
) -strongly con-
vex over the subspace {x : xT1 = 0} (all vectors orthogonal to the all-1 vector).",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"The proof of Lemma 10 — which (in part) is hairy due to the dependency between the matrix Gi and the signal yi — is deferred to Section C in the supplementary material.
",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
Identity Testing.,4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"Designing an Identity Test based solely on the maximum-likelihood is feasible, due to results like Cesa-Binachi et al (2002) which allow us to compare between the risk of the result p̃ of a online gradient descent algorithm to the original distribution p which generated the signals.",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
Through some manipulations one can (eventually) infer that |f(p),4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
− f(p̃)| = O(1/ √ n).,4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"However, since strong-convexity refers to the L2-norm squared of ‖p − p̃‖, we derive the resulting bound is ‖p − p̃‖21 ≤",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"T‖p − p̃‖22 = O( 1η2√n ), which leads to a sample complexity bound proportional to T 3/(αη)4.",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"This bound is worse than the bounds in Section 3.
",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"We therefore design a different, simple, identity tester in the local non-symmetric scheme, based on the estimator given in (Bassily et al., 2017).",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"The tester itself — which takes as input a given distribution p, a distance parameter α > 0 and the n signals — is quite simple.
1.",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"Given the n matrices G1, ..., Gn and the n observed signals y1, ..., yn, compute the estimator θ = 1n ∑",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"i 1 η ( gyii − 121 ) .
2.",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"If dTV( 12ηθ,p) ≤",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"α 2 then accept, else reject.",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
Theorem 11.,4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
Assume < 1.,4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"If we observe n = Ω( ( T α )2 ) signals generated by a distribution q then w.p. ≥ 2/3 over the matrices Gi we generate and the signals we observe, it holds that dTV( 12ηθ,q) ≤ α/2.",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"The correctness of the tester now follows from checking for the two cases where either p = q or dTV(p,q) > α.
",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
Proof.,4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
In the first part of the proof we assume the types of the n users were already drawn and are now fixed.,4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
We denote xi as the type of user i.,4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"We denote the frequency vector f = 〈nxn 〉x∈X , generated by counting the number of users of type x and normalizing it by n.
",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"Given f , we examine the estimator θ.",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"For each user i we have that 1η (g yi i − 121) ∈ {−1, 1}
T .",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"Because xi, the type of user i, is fixed, then for each coordinate x′ 6= xi, the signal yi is independent of the x′-column in Gi (yi depends solely on the entries in the xi-column).",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"We thus have that gyii (x
′) is distributed uniformly among { 12 ± η} and so E[ 1 η (g yi i (x
′)",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
− 12 )] = 0.,4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"In contrast, Pr[ 1η (g yi i (xi) − 12 )",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"= 1 ]
= ∑ s∈{−1,1} Pr[ 1 η (g s i (xi) − 12 ) = 1 and yi = s] = 2 · 12 · ( 1 2 + η) = 1 2 +η.",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"Therefore, E[ 1 η (g yi i (xi)− 12 )] =
( 12 + η)− ( 1 2 − η) = 2η.",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
It follows that E[ 1 η (g yi i − 121)],4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"= 2ηexi and so E[θ] = 2ηf .
",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"Next we examine the variance of θ , and argue the following (proof deferred to supplementary material).
",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
Proposition 12.,4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
E[(θ,4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
− 2ηf ),4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
(θ − 2ηf )T] 1nI,4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"So as a result, the expectedL2-difference E[‖θ − 2ηf ‖2] = E[trace((θ − 2ηf )(θ − 2ηf )T)]",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
= trace(E[(θ − 2ηf )(θ − 2ηf )T]) ≤,4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
Tn .,4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
Chesbyshev’s inequality assures us that therefore Pr[ 12η‖θ − 2ηf ‖ >,4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"√ 6T 2η √ n ] ≤ T/n6T/n = 1 6 .
",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"So far we have assumed f is fixed, and only looked at the event that the coin-tosses of the mechanism yielded an estimator far from its expected value.",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
We now turn to bounding the distance between f and its expected value q (the distribution that generated the types).,4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"Indeed, it is clear to see that the expected value of f = 1n ∑ i exi is E[f ]",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
= q .,4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"Moreover, it isn’t hard (and has been computed before many times, e.g. Agresti (2003)) to see that E[(f − q)(f",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
− q)T] = 1n ( diag(q)− qqT ) .,4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"Thus
E[‖f −q‖2] = trace( 1n ( diag(q)− qqT ) )",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"= 1n (1−‖q‖
2).",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"Therefore, applying Chebyshev again, we get that w.p. at most 1/6 over the choice of types by q , we have that Pr[‖f − q‖ > √ 6/n]",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
≤ 1/n6/n,4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"= 1 6 .
",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
Combining both results we get that w.p. ≥ 2/3 we have that ‖ 12ηθ,4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
− q‖1 ≤,4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
√ T‖ 12ηθ,4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"− q‖ ≤√
T ( ‖ 12ηθ",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
− f ‖+ ‖f,4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
− q‖ ) ≤,4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"√ 6T 2 4η2n+ √ 6T n ≤ α since
we have n = Ω( T 2
η2α2 ).",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"Recall that η = Θ( ) and that dTV(x,y) = 1 2‖x−y‖1, and the bound of α 2 is proven.
",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
Independence Testing.,4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"Similarly to the identity tester, we propose a similar tester for independence.",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"Recall that in this case, X is composed of d features, hence X = X 1 × X 2 × ...",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"× X d, with our notation of T j = |X j",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
|,4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"for each j. Our tester should accept when the underlying distribution over the types is some product distribution p, and should reject when the underlying distribution over the types is α-far from any product distribution.",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"The tester, whose input is the n signals and a distance parameter α > 0, is as follows.
1.",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"Given the n matrices G1, ..., Gn and the n observed signals y1, ..., yn, compute the estimator θ = 1n ∑",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"i 1 η ( gyii − 121 ) .
2.",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"For each feature j compute θj — the jth marginal of 1 2ηθ (namely, for each x
j ∈ X j sum all types whose jth feature is xj).",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
Denote θ̄ = θ1 × ...×,4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"θd.
3.",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"If dTV( 12ηθ, θ̄) ≤",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"α 2 then accept, else reject.
",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
Theorem 13.,4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
Assume < 1.,4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"Given n = Ω( Tα2 2 ( T + d2 ∑ j T j )
)",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"iid drawn signals from the nonsymmetric locally-private mechanism under a dataset whose types were drawn iid from some distribution q , then
w.p. ≥ 2/3 over the matrices Gi we generate and the types in the dataset we have the following guarantee.",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"If q is a product distribution, then dTV( 12ηθ, θ̄) ≤",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"α 2 , and if q is αfar from any product distribution then dTV( 12ηθ, θ̄) >",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
α 2 .,4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"(Proof deferred to the supplementary material, Section C.)
",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
Open Problems.,4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
(1) Is there a tester with a better sample complexity?,4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
The experiment in Section 4.2 leads us to conjecture that there exists a tester with sample complexity of T 1.5/(ηα)2.,4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"There could exist better testers, of smaller sample complexity, which leads to the second question.",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"(2) Can one derive lower bounds for identity/independence testing in this model, where each sample has its own distribution, related to the original distribution over types?",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"In Section D in the supplementary material we give more details as to possible venues to tackle both problems, relating them to the problem of learning a mixture-model of product distributions.",4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms,[0],[0]
"Following the derivations in the proof of Theorem 11, we can see that Var(θ) =",4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
1n ( I − 4η2diag(f 2) ) .,4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
"As ever, we assume is a small constant and as a result the variance in 2ηf (which is approximately 4η 2
n diag(p)) is significantly smaller than the variance of θ.",4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
This allows us to use the handwavey approximation f,4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
"≈ p,",4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
and argue that we have the approximation Var(θ),4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
≈ 1 n,4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
( I − 4η2diag(p2) ),4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
def = 1nM .,4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
"Central Limit Theorem thus give that √ nM−1/2(θ − 2ηp) n→∞→ N (0, I).",4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
"Therefore, it stands to reason that the norm of the LHS is distributed like a χ2-distribution, namely,
P (θ) def = n ∑",4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
x∈X,4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
"(θ(x)− 2η · p(x))2 1− 4η2p(x)2 n→∞→ χ2T
Our experiment is aimed at determining whether P (θ) can serve as a test statistic and assessing its sample complexity.
",4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
Setting and Default Values.,4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
"We set a true ground distribution on T possible types, p.",4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
We then pick a distribution q which is α-far from p using the counter example of Paninski (2008): we pair the types and randomly move 2αT probability mess between each pair of matched types.,4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
"We then generate n samples according to q , and apply the nonsymmetric -differentially private mechanism of (Bassily et al., 2017).",4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
"Finally, we aggregate the suitable vectors to obtain our estimator θ and compute P (θ).",4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
"If we decide to accept/reject we do so based on comparison of P to the 23 -quantile of the χ 2 T -distribution, so that in the limit we reject only w.p. 1/3 under the null-hypothesis.",4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
We repeat this entire process t times.,4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
"We have set the default values T = 10, p = uT (uniform on [T ]), α = 0.2, n = 1000, = 0.25 and therefore η = 12 e −1 e +1 , and t = 10000.
",4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
Experiment 1: Convergence to the χ2-distribution in the null case.,4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
"First we ask ourself whether our approximation, denoting P (θ) ≈ χ2T is correct when indeed p is
the distribution generating the signals.",4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
"To that end, we set α = 0",4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
"(so the types are distributed according to p) and plot the t empirical values of P we in our experiment, varying both the sample size n ∈ {10, 100, 1000, 10000} and the domain size T ∈ {10, 25, 50, 100}.",4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
The results are consistent — P is distributed like a χ2T - distribution.,4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
"Indeed, the mean of the t sample points is≈ T (the mean of a χ2T -distribution).",4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
"The results themselves appear in Figure 2 in the supplementary material, Section D.
Experiment 2:",4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
Divergence from the χ2-distribution in the alternate case.,4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
"Secondly, we asked whether P can serve as a good way to differentiate between the null hypothesis (the distribution over the types is derived from p) and the alternative hypothesis (the distribution over the types if ≥ α-far from p).",4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
We therefore ran our experiment while varying α (between 0.25 and 0.05) and increasing n.,4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
"Again, the results show that the distribution does shift towards higher values as n increases.",4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
"The results are given in
Figure 3 in the supplementary material, Section D.
Experiment 3: Sample Complexity.",4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
"Next, we set to find the required sample complexity for rejection.",4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
"We fix the α-far distribution from p, and first do binary search to hone on an interval [nL, nU ] where the empirical rejection probability is between 30% − 35%; then we equipartition this interval and return the n for which the empirical rejection probability is the closest to 33%.",4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
"We repeat this experiment multiple times, each time varying just one of the 3 most important parameters, T , α and .",4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
"We maintain two parameters at default values, and vary just one parameter: T ∈ {5, 10, 15, .., 100}, α ∈ {0.05, 0.1, 0.15, ..., 0.5}, ∈ {0.05, 0.1, 0.15, ..., 0.5}.",4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
"The results are shown in Figure 1, where next to each curve we plot the curve of our conjecture in a dotted line.4 We conjecture initially that n ∝ T cT · αcα · c .",4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
"And so, for any parameter ξ ∈ {T, α, }, if we compare two experiments i, j that differ only on the value of this parameter and resulted in two empirical estimations Ni, Nj of the sample complexity, then we get that cξ ≈ log(Ni/Nj)log(ξi/ξj) .",4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
"And so for any ξ ∈ {T, α, } we take the median over of all pairs of i and j and we get the empirical estimations of c = −1.900793, cα = −1.930947 and cT",4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
= 1.486957.,4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
"This leads us to the conjecture that the actual sample complexity according to this test is T 1.5
α2 2 .
",4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
Open Problem.,4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
"Perhaps even more interesting, is the experiment we wish we could have run: a χ2-based independence testing.",4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
Assuming the distribution of the type is a product distribution p̄ = p1,4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
× ...,4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
"× pd, the proof of Theorem 13 shows that for each feature j we have Var(θj − pj)",4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
≈ 14η2n T T j IX j .,4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
Thus 4η 2nT j T ‖θ,4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
j,4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
− pj‖2 n→∞→ χ2T j .,4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
"However, the d estimators θj are not independent, so it is
4We plot the dependency on α and on the same plot, as both took the same empirical values.
not true that ∑ j 4η 2nT j T ‖θ",4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
j,4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
− pj‖2 n→∞→ χ2∑ j T j .,4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
"Moreover, even if the estimators of the marginals were independent,5 we are still unable to determine the asymptotic distribution of ‖θ̄−p̄‖2 (only a bound, scaled byO(maxj Tj), using Proposition 17 in the supplementary material), let alone the asymptotic distribution of ‖ 12ηθ − θ̄‖ 2.
",4.2. Experiment: Proposed χ2-Based Testers,[0.9570736815348534],"['Then, from (1), we get the likelihood Pi(yE ∪ yN|x), and a naive CRF trained on the concatenation of all the data will maximize this probability.']"
"Nonetheless, we did empirically measure the quantity
Q(θ) def = n ∑",4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
x,4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
( 1 2η θ(x)−θ̄(x)),4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
"2 θ̄(x) under the null (α = 0) and the alternative (α = 0.25) hypothesis with n = 25, 000 samples in each experiment.",4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
"The results (given in Figure 4 in the supplementary material) show that the distribution of Q — albeit not resembling a χ2-distribution — is different under the null- and the alternative-hypothesis, so we suspect that there’s merit to using this quantity as a tester.",4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
"We thus leave the design of a χ2-based statistics for independence in this model as an open problem.
5E.g.",4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
"by assigning each example i to one of the d estimators, costing only d = log(T ) factor in sample complexity",4.2. Experiment: Proposed χ2-Based Testers,[0],[0]
"This work was supported by the Natural Sciences and Engineering Council of Canada, Grant #2017-06701.",Acknowledgments,[0],[0]
The author is also an unpaid collaborator on NSF grant 1565387.,Acknowledgments,[0],[0]
"The authors thanks the anonymous reviewers for many helpful suggestions and ideas, as well as Marco Gaboardi and Ryan Rogers for helpful discussions illustrating the similarities and differences between our two papers.",Acknowledgments,[0],[0]
"We initiate the study of differentially private hypothesis testing in the local-model, under both the standard (symmetric) randomized-response mechanism (Warner, 1965; Kasiviswanathan et al., 2008) and the newer (non-symmetric) mechanisms (Bassily & Smith, 2015; Bassily et al., 2017).",abstractText,[0],[0]
"First, we study the general framework of mapping each user’s type into a signal and show that the problem of finding the maximum-likelihood distribution over the signals is feasible.",abstractText,[0],[0]
"Then we discuss the randomizedresponse mechanism and show that, in essence, it maps the nulland alternative-hypotheses onto new sets, an affine translation of the original sets.",abstractText,[0],[0]
We then give sample complexity bounds for identity and independence testing under randomizedresponse.,abstractText,[0],[0]
We then move to the newer nonsymmetric mechanisms and show that there too the problem of finding the maximum-likelihood distribution is feasible.,abstractText,[0],[0]
"Under the mechanism of Bassily et al (2017) we give identity and independence testers with better sample complexity than the testers in the symmetric case, and we also propose a χ-based identity tester which we investigate empirically.",abstractText,[0],[0]
Locally Private Hypothesis Testing,title,[0],[0]
Can we efficiently predict which face is in the picture amongst multiple billions of people?,1. Introduction,[0],[0]
"In a translation, can we effectively predict which word should come next amongst 105 possibilities?",1. Introduction,[0],[0]
More generally can we predict one of K classes in polylogarithmic time in K?,1. Introduction,[0],[0]
"This question gives rise to the area of extreme multiclass classification (Bengio et al., 2010; Beygelzimer et al., 2009; Bhatia et al., 2015; Choromanska & Langford, 2015; Morin & Bengio, 2005; Prabhu & Varma, 2014; Weston et al., 2013), in which K is very large.",1. Introduction,[0],[0]
"If efficiency is not a concern, the most common and generally effective representation for multiclass prediction is a one-against-all (OAA) structure.",1. Introduction,[0],[0]
"Here, inference consists of computing a score for each class and returning the class with the maximum score.",1. Introduction,[0],[0]
"If efficiency is a concern, an attractive strategy for picking one of K items is to use a tree; unfortunately, this often comes at the cost of increased error.
",1. Introduction,[0],[0]
"A general replacement for the one-against-all approach must satisfy a difficult set of desiderata.
",1. Introduction,[0],[0]
"• High accuracy: The approach should provide accuracy competitive with OAA, a remarkably strong base-
*Equal contribution 1University of Maryland 2Microsoft.",1. Introduction,[0],[0]
"Correspondence to: Paul Mineiro <pmineiro@microsoft.com>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
line (Rifkin & Klautau, 2004) which is the standard “output layer” of many learning systems such as winners of the ImageNet contest (He et al., 2015; Simonyan & Zisserman, 2014).",1. Introduction,[0],[0]
"• High speed at training time and test time: A multiclass classifier must spend at least Ω(logK) time (Choromanska & Langford, 2015))",1. Introduction,[0],[0]
so this is a natural benchmark to optimize against.,1. Introduction,[0],[0]
• Online operation: Many learning algorithms use either online updates or mini-batch updates.,1. Introduction,[0],[0]
Approaches satisfying this constraint can be easily composed into an end-to-end learning system for solving complex problems like image recognition.,1. Introduction,[0],[0]
"For algorithms which operate in batch fashion, online components can be easily used.",1. Introduction,[0],[0]
"• Linear space: In order to have a drop-in replacement for OAA, an approach must not take much more space than OAA.",1. Introduction,[0],[0]
"Memory is at a premium when K is very large, especially for models trained on GPUs, or deployed to small devices.
",1. Introduction,[0],[0]
"We use an OAA-like structure to make a final prediction, but instead of scoring every class, we only score a small subset of O(logK) classes.",1. Introduction,[0],[0]
We call this “one-againstsome” (OAS).,1. Introduction,[0],[0]
How can you efficiently determine what classes should be scored?,1. Introduction,[0],[0]
We use a dynamically built tree to efficiently whittle down the set of candidate classes.,1. Introduction,[0],[0]
The goal of the tree is to maximize the recall of the candidate set so we call this approach “The Recall Tree.”,1. Introduction,[0],[0]
"In a traditional tree-based classifier, a traversal of the tree leads to a leaf, and a leaf corresponds to a single label, In the Recall Tree, we loosen the latter requirement and allow a leaf to corresponds to a set of labels of size O(logK).",1. Introduction,[0],[0]
"At test time, when a leaf is reached, scores are computed for this small subset (see Figure 1).
",1. Introduction,[0],[0]
"The Recall Tree achieves good accuracy, improving on previous online approaches (Choromanska & Langford, 2015) and sometimes surpassing the OAA baseline.",1. Introduction,[0],[0]
The algorithm requires only poly(logK) time during training and testing.,1. Introduction,[0],[0]
"In practice, the computational benefits are substantial when K ≥ 1000.1",1. Introduction,[0],[0]
"The Recall Tree constructs a tree and learns parameters in a fully online manner as a reduction, allowing composition with systems trained via online updates.",1. Introduction,[0],[0]
"All of this requires only twice as much space as OAA approaches.
",1. Introduction,[0],[0]
"Our contributions are the following:
• We propose a new online tree construction algorithm which jointly optimizes the construction of the tree, the routers and the underlying OAS regressors (see section 3.1).",1. Introduction,[0],[0]
"• We analyze elements of the algorithm, including a new boosting bound (see section 3.3) on multiclass classification performance and a representational trick which allows the algorithm to perform well if either a tree representation does well or an OAA representation does well as discussed in section 3.2.",1. Introduction,[0],[0]
"• We experiment with the new algorithm, both to analyze its performance relative to baselines and understand the impact of design decisions via ablation experiments.
",1. Introduction,[0],[0]
The net effect is a theoretically motivated algorithm which empirically performs well providing a plausible replacement for the standard one-against-all approach for largeK.,1. Introduction,[0],[0]
"Here we present a concrete description of the Recall Tree and defer all theoretical results that motivate our design de-
1Our implementation of baseline approaches, including OAA, involve vectorized computations that increase throughput by a factor of 10 to 20, making them much more difficult to outpace than naı̈ve implementations.
",2. The Recall Tree Algorithm,[0],[0]
"Algorithm 1 Predict. n.f(x) evaluates the node’s route, scorey(x) evaluates a per-class regressor, r̂ecall(◦) is an empirical bound on the recall of a node (◦)",2. The Recall Tree Algorithm,[0],[0]
"(see Eq (1)), and x+ {(n.id : 1)} indicates the addition of a sparse feature with index n.id and value 1.
1: Input: Example x, Root Node n 2: Output: Predicted class ŷ 3: while n.leaf is false do 4: c← n.f(x) > 0 ?",2. The Recall Tree Algorithm,[0],[0]
n.left :,2. The Recall Tree Algorithm,[0],[0]
n.right 5: if r̂ecall(n) > r̂ecall(c),2. The Recall Tree Algorithm,[0],[0]
then 6: break 7: end if 8: n←,2. The Recall Tree Algorithm,[0],[0]
"c 9: x← x+ {(n.id : 1)}
10: end while 11: ŷ",2. The Recall Tree Algorithm,[0],[0]
"← argmax
y∈n.candidates scorey(x)
cisions to section 3.",2. The Recall Tree Algorithm,[0],[0]
"The Recall Tree data structure (see Figure 2) consists of two components: (1) a binary tree, described below; and (2) a scoring function scorey(x) that will evaluate the quality of a small set of candidates y to make a final prediction.",2.1. Recall Tree at Test Time,[0],[0]
"Each node n in the binary tree maintains:
• a router, denoted f , that maps an example to either a left or right child; routers are implemented as binary classifiers; • a histogram of the labels of all training examples that have been routed to, or through, n.
The primary purpose of the histogram is to generate a candidate set of labels to be scored, taken to be the most frequent labels in that histogram.",2.1. Recall Tree at Test Time,[0],[0]
"Intuitively, the goal of the candidate set is to maintain good recall, while the goal of the score function is to achieve good precision.",2.1. Recall Tree at Test Time,[0],[0]
"Crucially, the leaves of the tree do not partition the set of classes: classes can (and do) have support at multiple leaves.
",2.1. Recall Tree at Test Time,[0],[0]
"At test time, an input x is provided and a recursive computation begins at the root of the tree.",2.1. Recall Tree at Test Time,[0],[0]
The tree is descended according to the binary classification decision made at each internal node.,2.1. Recall Tree at Test Time,[0],[0]
"When the recursion ends (for instance, when a leaf is reached), the top F most frequent labels according to the node’s label counter are used as a candidate set.",2.1. Recall Tree at Test Time,[0],[0]
When F = O(logK) this does not compromise the goal of achieving logarithmic time classification.,2.1. Recall Tree at Test Time,[0],[0]
"Once this candidate set is chosen, each y in that set is scored using the score function, and the largest scoring y is returned.
",2.1. Recall Tree at Test Time,[0],[0]
"It turns out that it is advantageous to allow the recursion to end before hitting a leaf, which is a consequence of how
training happens on tree-structured classifiers.",2.1. Recall Tree at Test Time,[0],[0]
"In particular, the number of labeled examples that the root classifier “sees” is much larger than the number of labeled examples that any leaf sees.",2.1. Recall Tree at Test Time,[0],[0]
This potentially leads to: (1) high variance toward the leaves; and (2) insufficient representation complexity toward the root.,2.1. Recall Tree at Test Time,[0],[0]
"Instead of halting at a leaf, we can halt at an internal node for which the top F most frequent labels contain the true answer with a sufficiently high probability.
",2.1. Recall Tree at Test Time,[0],[0]
Algorithm 1 formalizes the test-time behavior of the Recall Tree.,2.1. Recall Tree at Test Time,[0],[0]
"The primary routing occurs in the first line of the main loop, where c is the child selected by the current node’s router.",2.1. Recall Tree at Test Time,[0],[0]
"On the next line, the recursion considers the possibility of terminating on an internal node if the bounded recall, r̂ecall, of the current node n is greater than the estimated recall of the chosen child c.",2.1. Recall Tree at Test Time,[0],[0]
"If the recursion does not end, a new “path feature” is added to x at the end of the main loop, which records the path taken in the recall tree: the benefit of adding these features is that it increases the representational capacity of the recall tree to ensure competitiveness with OAA (§3.2).",2.1. Recall Tree at Test Time,[0],[0]
"Whichever way the recursion ends, the final node n has a (small) set of candidate labels n.candidates ⊂ Y .",2.1. Recall Tree at Test Time,[0],[0]
"Each is scored according to a one-against-some rule and the label with the largest score is returned.
",2.1. Recall Tree at Test Time,[0],[0]
A natural way to estimate recall at a node n is to consider it’s empirical recall r̂n.,2.1. Recall Tree at Test Time,[0],[0]
This is simply the fraction of the mass consumed by the F most frequent labels in n’s counter.,2.1. Recall Tree at Test Time,[0],[0]
"For example, if the counter saw label 1 two times, label 4 fifty times and label 3 ten times, and if F = 2, then the empirical recall would be 60/62.",2.1. Recall Tree at Test Time,[0],[0]
"However, because, in general, a parent node will see more data than a child node, the quality of this estimate is likely to be much better for the parent than the child due to a missing mass problem (Good, 1953).",2.1. Recall Tree at Test Time,[0],[0]
"To accomodate this, we instead use an empirical Bernstein lower bound (Maurer & Pontil, 2009), which is summarized by the following proposition.",2.1. Recall Tree at Test Time,[0],[0]
Proposition 1.,2.1. Recall Tree at Test Time,[0],[0]
For all multiclass classification problems defined by a distribution D over X ×,2.1. Recall Tree at Test Time,[0],[0]
"[K], and all nodes n in a fixed tree, there exists a constant λ > 0",2.1. Recall Tree at Test Time,[0],[0]
"such that with probability 1− δ:
r̂ecall(n) = r̂n",2.1. Recall Tree at Test Time,[0],[0]
"− √ λr̂n(1− r̂n)
mn − λ mn ≤ rn (1)
where r̂n is the empirical recall of node n computed over mn = n.total items; and rn is the expected value of this recall in the population limit.
",2.1. Recall Tree at Test Time,[0],[0]
"Here, λ is a hyperparameter of the recall tree (in fact, it is the only additional hyperparameter), which controls how aggressively the tree branches.",2.1. Recall Tree at Test Time,[0],[0]
"We show in our experiments that these various design decisions (path features, Bernstein lower bounds, and early termination) are useful in practice.
",2.1. Recall Tree at Test Time,[0],[0]
Algorithm 2 Train.,2.1. Recall Tree at Test Time,[0],[0]
An input labeled example descends the tree as in Algorithm 1.,2.1. Recall Tree at Test Time,[0],[0]
"update candidates updates the set of candidate labels at each node and update regressors updates the one-against-some regressors; and r̂ecall(◦) is a an empirical bound on the recall of a node (◦) (see section 3.1).
",2.1. Recall Tree at Test Time,[0],[0]
"Input: Example (x, y), Root node n Output: Update tree with root at n while n.leaf is false do update router(x, y, n) c← n.f(x) > 0 ?",2.1. Recall Tree at Test Time,[0],[0]
n.left :,2.1. Recall Tree at Test Time,[0],[0]
"n.right update candidates(x, y, c)
if r̂ecall(n) > r̂ecall(c) then break end if n←",2.1. Recall Tree at Test Time,[0],[0]
c x←,2.1. Recall Tree at Test Time,[0],[0]
"x+ {(n.id : 1)}
end while update regressors(x, y, n.candidates)",2.1. Recall Tree at Test Time,[0],[0]
The Recall Tree maintains one regressor for each class and a tree whose purpose is to eliminate regressor from consideration.,2.2. Recall Tree at Training Time,[0],[0]
We refer to the per-class regressor as one-againstsome (OAS) regressors.,2.2. Recall Tree at Training Time,[0],[0]
The tree creates a high recall set of candidate classes and then leverages the OAS regressors to achieve precision.,2.2. Recall Tree at Training Time,[0],[0]
"Algorithm 2 outlines the learning procedures, which we now describe in more detail.
",2.2. Recall Tree at Training Time,[0],[0]
"Learning the regressors for each class In Algorithm 2, update regressors updates the candidate set regressors using the standard OAA strategy restricted to the set of eligible classes.",2.2. Recall Tree at Training Time,[0],[0]
"If the true label is not in the F most frequent classes at this node then no update occurs.
",2.2. Recall Tree at Training Time,[0],[0]
"Learning the set of candidates in each node In Algorithm 2, update candidates updates the count of the true label at this node.",2.2. Recall Tree at Training Time,[0],[0]
"At each node, the most frequent F labels are the candidate set.
",2.2. Recall Tree at Training Time,[0],[0]
"Learning the routers at each node In Algorithm 2, update router updates the router at a node by optimizing the reduction in the entropy of the label distribution (the label entropy) due to routing, as detailed in Algorithm 3.",2.2. Recall Tree at Training Time,[0],[0]
This is in accordance with our theory (Section 3.3).,2.2. Recall Tree at Training Time,[0],[0]
The label entropy for a node is estimated using the empirical counts of each class label entering the node.,2.2. Recall Tree at Training Time,[0],[0]
These counts are reliable as update router is only called for the root or nodes whose true recall bound is better than their children.,2.2. Recall Tree at Training Time,[0],[0]
"The expected label entropy after routing is estimated by averaging the estimated label entropy of each child node, weighted by the fraction of examples routing left or right.",2.2. Recall Tree at Training Time,[0],[0]
"Finally, we compute the advantage of routing left vs. right
Algorithm 3 update router.",2.2. Recall Tree at Training Time,[0],[0]
entropy computes two values: the empirical entropy of labels incident on a node without and with (respectively) an extra label y. Ĥ|left is an estimate of the average entropy if the example is routed left.,2.2. Recall Tree at Training Time,[0],[0]
"Learnn(x,w, y) is an importance-weighted update to the binary classifier f(x) for node n with features x, label y, and weight w.
Input: Example (x, y);",2.2. Recall Tree at Training Time,[0],[0]
Node n Output: Update node n,2.2. Recall Tree at Training Time,[0],[0]
"(Ĥleft, Ĥ ′ left) .",2.2. Recall Tree at Training Time,[0],[0]
"= entropy(n.left, y) (Ĥright, Ĥ ′",2.2. Recall Tree at Training Time,[0],[0]
right) .,2.2. Recall Tree at Training Time,[0],[0]
"= entropy(n.right, y) Ĥ|left .",2.2. Recall Tree at Training Time,[0],[0]
= n.left.totaln.total Ĥ ′,2.2. Recall Tree at Training Time,[0],[0]
left +,2.2. Recall Tree at Training Time,[0],[0]
n.right.total n.total Ĥright Ĥ|right .,2.2. Recall Tree at Training Time,[0],[0]
= n.left.totaln.total Ĥleft +,2.2. Recall Tree at Training Time,[0],[0]
n.right.total n.total Ĥ ′,2.2. Recall Tree at Training Time,[0],[0]
right ∆̂Hpost ← Ĥ|left,2.2. Recall Tree at Training Time,[0],[0]
"− Ĥ|right Learnn(x, |∆̂Hpost|, sign(∆̂Hpost))
",2.2. Recall Tree at Training Time,[0],[0]
"Algorithm 4 update regressors updates the OAS scoring functions for a single example.
",2.2. Recall Tree at Training Time,[0],[0]
"Input: Example (x, y); Candidate set candidates Output: Update scoring functions score if y ∈ candidates then
online update to scorey(x) with label +1 for ŷ ∈ candidates−",2.2. Recall Tree at Training Time,[0],[0]
"{y} do
online update to scoreŷ(x) with label −1 end for
end if
by taking the difference of the expected label entropies for routing left vs. right.",2.2. Recall Tree at Training Time,[0],[0]
"The sign of this difference determines the binary label for updating the router.
",2.2. Recall Tree at Training Time,[0],[0]
"Tree depth control We calculate a lower bound r̂ecall(n) on the true recall of node n (Section 3.1), halting descent as in Algorithm 2.",2.2. Recall Tree at Training Time,[0],[0]
"As we descend the tree, the bound first increases (empirical recall increases) then declines (variance increases).",2.2. Recall Tree at Training Time,[0],[0]
We also limit the maximum depth d of the tree.,2.2. Recall Tree at Training Time,[0],[0]
This parameter is typically not operative but adds an additional safety check and sees some use on datasets where multipasses are employed.,2.2. Recall Tree at Training Time,[0],[0]
Online construction of an optimal logarithmic time regressors for multiclass classification given an arbitrary fixed representation at each node appears deeply intractable.,3. Theoretical Motivation,[0],[0]
A primary difficulty is that decisions have to be hard since we cannot afford to maintain a distribution over all class labels.,3. Theoretical Motivation,[0],[0]
"Choosing a classifier so as to minimize error rate has been considered for cryptographic primitives (Blum et al., 1993)",3. Theoretical Motivation,[0],[0]
so it is plausibly hard on average rather than merely hard in the worst case.,3. Theoretical Motivation,[0],[0]
"Furthermore, the joint optimization of
all regressors does not nicely decompose into independent problems.",3. Theoretical Motivation,[0],[0]
Solving the above problems requires an implausible break-through in complexity theory which we do not achieve here.,3. Theoretical Motivation,[0],[0]
"Instead, we use learning theory to assist the design by analyzing various simplifications of the problem.",3. Theoretical Motivation,[0],[0]
"For binary classification, a simple trick can (in theory) collapse the number of leaves while preserving prediction performance.",3.1. One-Against-Some Recall,[0],[0]
"In particular, branching programs (Mansour & McAllester, 2002) result in exponentially more succinct representations than decision trees (Kearns & Mansour, 1996) by joining nodes to create directed acyclic graphs.",3.1. One-Against-Some Recall,[0],[0]
"The key observation is that nodes in the same level with a similar distribution over class labels can be joined into one node, implying that the number of nodes at one level is only θ(1/γ) where γ is the weak learning parameter rather than exponential in the depth.",3.1. One-Against-Some Recall,[0],[0]
This approach generally fails in the multiclass setting because covering the simplex of multiclass label distributions requires (K − 1)θ(1/γ) nodes.,3.1. One-Against-Some Recall,[0],[0]
One easy special case exists.,3.1. One-Against-Some Recall,[0],[0]
"When the distribution over class labels is skewed so one label is the majority class, learning an entropy minimizing binary classifier predicts whether the class is the majority or not.",3.1. One-Against-Some Recall,[0],[0]
"There are only K possible OAS regressors of this sort so maintaining one for each class label is computationally tractable.
",3.1. One-Against-Some Recall,[0],[0]
Using OAS classifiers creates a limited branching program structure over predictions.,3.1. One-Against-Some Recall,[0],[0]
"Aside from the space savings generated, this also implies that nodes deep in the tree use many more labeled examples than are otherwise available.",3.1. One-Against-Some Recall,[0],[0]
"In finite sample regimes, which are not covered by these boosting analyses, more labeled samples induce a better predictor as per standard sample complexity analysis.
",3.1. One-Against-Some Recall,[0],[0]
"As a result, we use the empirical Bernstein lower bound on recall described in §2.1.",3.1. One-Against-Some Recall,[0],[0]
Reducing the depth of the tree by using this lower bound and joining labeled examples from many leaves in a one-against-some approach both relieves data sparsity problems and allows greater error tolerance by the root node.,3.1. One-Against-Some Recall,[0],[0]
Different multiclass classification schemes give rise to different multiclass hypothesis classes.,3.2. Path Features,[0],[0]
"For example, the set of multiclass decision boundaries realizable under an OAA structure over linear regressors is fundamentally different from that realizable under a tree structure over linear regressors.",3.2. Path Features,[0],[0]
Are OAA types of representations inherently more or less powerful than a tree based representation?,3.2. Path Features,[0],[0]
"Figure 3 shows two learning problems illustrating two extremes assuming a linear representation.
",3.2. Path Features,[0],[0]
Linear OAA:,3.2. Path Features,[0],[0]
"If all the class parameter vectors happen to have the same `2 norm, then OAA classification is equivalent to finding the nearest neighbor amongst a set of vectors (one per class) which partition the space into a Voronoi diagram as in 3 on the left.",3.2. Path Features,[0],[0]
"The general case, with unequal vectors corresponds to a weighted Voronoi diagram where the magnitude of two vectors sharing a border determines the edge of the partition.",3.2. Path Features,[0],[0]
"No weighted Voronoi diagram can account for the partition on the right.
",3.2. Path Features,[0],[0]
"Trees: If the partition of a space can be represented by a sequence of conditional splits, then a tree can represent the solution accurately as in 3 on the right.",3.2. Path Features,[0],[0]
"On the other hand, extra work is generally required to represent a Voronoi diagram as on the left.",3.2. Path Features,[0],[0]
"In general, the number of edges in a multidimensional Voronoi diagram may grow at least quadratically in the number of points implying that the number of nodes required for a tree to faithfully represent a Voronoi diagram is at least Θ(n2).
",3.2. Path Features,[0],[0]
"Based on this, neither tree-based nor OAA style prediction is inherently more powerful, with the best solution being problem dependent.
",3.2. Path Features,[0],[0]
"Since we are interested in starting with a tree-based approach and ending with a OAS classifier, there is a simple representational trick which provides the best of both worlds.",3.2. Path Features,[0],[0]
We can add features which record the path through the tree.,3.2. Path Features,[0],[0]
"To be precise, let T be a tree and pathT (x) be a vector with one dimension per node in T which is set to 1 if x traverses the node and 0 otherwise.",3.2. Path Features,[0],[0]
"The following proposition holds for linear representations, which are special because they are tractably analyzed and because they are the fundamental building blocks around which many more complex representations are built.
Proposition.",3.2. Path Features,[0],[0]
For any distribution D over X ×,3.2. Path Features,[0],[0]
"[K] for which a tree T achieves error rate , a OAA classifier over linear regressors, whose input consists of x ∈ X and the corresponding routing path of x in T (as indicator features) can also achieve error rate .
",3.2. Path Features,[0],[0]
Proof.,3.2. Path Features,[0],[0]
"A linear OAA classifier is defined by a matrix wiy where i ranges over the input and y ranges over the labels.
",3.2. Path Features,[0],[0]
Let wiy = 0 by default and 1 when i corresponds to a leaf for which the tree predicts y.,3.2. Path Features,[0],[0]
"Under this representation, the prediction of OAA(x, pathT (x)) is identical to T (x), and hence achieves the same error rate.",3.2. Path Features,[0],[0]
The Shannon Entropy of class labels is optimized in the router of Algorithm 3.,3.3. Optimization Objective,[0],[0]
"Why?
Since the Recall Tree jointly optimizes over many base learning algorithms, the systemic properties of the joint optimization are important to consider.",3.3. Optimization Objective,[0],[0]
"A theory of decision tree learning as boosting (Kearns & Mansour, 1996) provides a way to understand these joint properties in a population limit (or equivalently on a training set iterated until convergence).",3.3. Optimization Objective,[0],[0]
"In essence, the analysis shows each level of the tree boosts the accuracy of the resulting tree with this conclusion holding for several common objectives.
",3.3. Optimization Objective,[0],[0]
"In boosting for multiclass classification (Choromanska et al., 2016; Choromanska & Langford, 2015; Takimoto & Maruoka, 2003), it is important to achieve a weak dependence on the number of class labels.",3.3. Optimization Objective,[0],[0]
"Shannon Entropy is particularly well-suited to this goal, because it has only a logarithmic dependence on the number of class labels.",3.3. Optimization Objective,[0],[0]
"Let πi|n be the probability that the correct label is i, conditioned on the corresponding example reaching",3.3. Optimization Objective,[0],[0]
node n.,3.3. Optimization Objective,[0],[0]
Then Hn = ∑K i=1,3.3. Optimization Objective,[0],[0]
"πi|n log2 1 πi|n
is the Shannon entropy of class labels reaching node n.
For this section, we consider a simplified algorithm which neglects concerns of finite sample analysis, how optimization is done, and the leaf predictors.",3.3. Optimization Objective,[0],[0]
What’s left is the value of optimizing the router objective.,3.3. Optimization Objective,[0],[0]
We consider an algorithm which recursively splits the leaf with the largest proportion p of all examples starting at the root and reaching the leaf.,3.3. Optimization Objective,[0],[0]
The leaf is split into two new leaves to the left l and right r.,3.3. Optimization Objective,[0],[0]
"If pl and pr are the fraction of examples going left and right (so pl +pr = 1), the split criterion minimizes the expectation over the leaves of the average class entropy, plHl + prHr.",3.3. Optimization Objective,[0],[0]
This might be achieved by update router in Algorithm 2 or by any other means.,3.3. Optimization Objective,[0],[0]
With this criterion we are in a position to directly optimize information boosting.,3.3. Optimization Objective,[0],[0]
Definition 1.,3.3. Optimization Objective,[0],[0]
(γ-Weak Learning Assumption),3.3. Optimization Objective,[0],[0]
"For all distributions D(x, y) a learning algorithm using examples (x, y)∗ IID from D finds a binary classifier c :",3.3. Optimization Objective,[0],[0]
"X → {l, r} satisfying
plHl + prHr ≤",3.3. Optimization Objective,[0],[0]
"Hn − γ .
",3.3. Optimization Objective,[0],[0]
"This approach is similar to previous (Takimoto & Maruoka, 2003) except that we boost in an additive rather than a multiplicative sense.",3.3. Optimization Objective,[0],[0]
"A multiplicative approach suppresses a necessary dependence on K. In particular, for any nontrivial γ there exists a K such that with a uniform distribution U , HU (1 − γ) > 1).",3.3. Optimization Objective,[0],[0]
"As a consequence, theorems proved
with a multiplicative γ are necessarily vacuous for large K while additive approaches do not suffer from this issue.
",3.3. Optimization Objective,[0],[0]
"As long as Weak Learning occurs, we can prove the following theorem.",3.3. Optimization Objective,[0],[0]
Theorem 2.,3.3. Optimization Objective,[0],[0]
"If γ Weak Learning holds for every node in the tree and nodes with the largest fraction of examples are split first, then after t > 2 splits the multiclass error rate of the tree is bounded by:
≤ H1 − γ ln(t+ 1)
where H1 is the entropy of the marginal distribution of class labels.
",3.3. Optimization Objective,[0],[0]
"The proof in appendix A reuses techniques from (Choromanska & Langford, 2015; Kearns & Mansour, 1996) but has a tighter result.
",3.3. Optimization Objective,[0],[0]
"The most important observation from the theorem is that as t (the number of splits) increases, the error rate is increasingly bounded.",3.3. Optimization Objective,[0],[0]
This rate depends on ln t agreeing with the intuition that boosting happens level by level in the tree.,3.3. Optimization Objective,[0],[0]
"The dependence on the initial entropy H1 shows that skewed marginal class distributions are inherently easier to learn than uniform marginal class distributions, as might be expected.",3.3. Optimization Objective,[0],[0]
"These results are similar to previous results (Choromanska et al., 2016; Choromanska & Langford, 2015; Kearns & Mansour, 1996; Takimoto & Maruoka, 2003) with advantages.",3.3. Optimization Objective,[0],[0]
"We handle multiclass rather than binary classification (Kearns & Mansour, 1996), we bound error rates instead of entropy (Choromanska et al., 2016; Choromanska & Langford, 2015), and we use additive rather than multiplicative weak learning (Takimoto & Maruoka, 2003).",3.3. Optimization Objective,[0],[0]
"We study several questions empirically.
1.",4. Empirical Results,[0],[0]
What is the benefit of using one-against-some on a recall set?,4. Empirical Results,[0],[0]
2.,4. Empirical Results,[0],[0]
What is the benefit of path features?,4. Empirical Results,[0],[0]
"3. Is the online nature of the Recall Tree useful on non-
stationary problems?",4. Empirical Results,[0],[0]
4.,4. Empirical Results,[0],[0]
"How does the Recall Tree compare to one-against-all
statistically and computationally?
5.",4. Empirical Results,[0],[0]
"How does the Recall Tree compare to LOMTree statistically and computationally?
",4. Empirical Results,[0],[0]
Throughout this section we conduct experiments using learning with a linear representation.,4. Empirical Results,[0],[0]
Table 1 overviews the data sets used for experimentation.,4.1. Datasets,[0],[0]
"These include the largest datasets where published results are available for LOMTree (Aloi, Imagenet, ODP), plus an additional language modeling data set (LTCB).",4.1. Datasets,[0],[0]
"Implementations of the learning algorithms, and scripts to reproduce the data sets and experimental results, are available on github (Mineiro, 2017).",4.1. Datasets,[0],[0]
Additional details about the datasets can be found in Appendix B.,4.1. Datasets,[0],[0]
"In our first set of experiments, we compare Recall Tree with a strong computational baseline and a strong statistical baseline.",4.2. Comparison with other Algorithms,[0],[0]
"The computational baseline is LOMTree, the only other online logarithmic-time multiclass algorithm of which we are aware.",4.2. Comparison with other Algorithms,[0],[0]
"The statistical baseline is OAA, whose statistical performance we want to match (or even exceed), and whose linear computational dependence on the number of classes we want to avoid.",4.2. Comparison with other Algorithms,[0],[0]
"Details regarding the experimental methodology are in Appendix C. Results are summarized in Figure 4.
",4.2. Comparison with other Algorithms,[0],[0]
Comparison with LOMTree,4.2. Comparison with other Algorithms,[0],[0]
The Recall Tree uses a factor of 32 less state than the LOMTree which makes a dramatic difference in feasibility for large scale applications.,4.2. Comparison with other Algorithms,[0],[0]
"Given this state reduction, the default expectation is worse prediction performance by the Recall Tree.",4.2. Comparison with other Algorithms,[0],[0]
"Instead, we observe superior or onpar statistical performance despite the state constraint.",4.2. Comparison with other Algorithms,[0],[0]
"This typically comes with an additional computational cost since the Recall Tree evaluates a number of per-class regressors.
",4.2. Comparison with other Algorithms,[0],[0]
"Comparison with OAA On one dataset (ALOI) prediction performance is superior to OAA while on the others it is somewhat worse.
",4.2. Comparison with other Algorithms,[0],[0]
Computationally OAA has favorable constant factors since it is highly amenable to vectorization.,4.2. Comparison with other Algorithms,[0],[0]
"Conversely, the
-4
0
4
8
12
ALOI Imagenet
ODP
De lta
T es
t E rr
or (% )",4.2. Comparison with other Algorithms,[0],[0]
"Fr om O
AA Statistical Performance LOMTree Recall Tree
1e-05 0.0001
0.001 0.01
0.1 1
ALOI Imagenet
ODP
In fe
re nc
e Ti
m e
Pe r E
xa m
pl e
(s ec
on ds
)
",4.2. Comparison with other Algorithms,[0],[0]
"Computational Performance
OAA Recall Tree
LOMTree
Figure 4.",4.2. Comparison with other Algorithms,[0],[0]
Empirical comparison of statistical (left) and computational (right) performance of Recall Tree against two strong competitors: OAA (statistically good) and LOMTree (computationally good).,4.2. Comparison with other Algorithms,[0],[0]
"In both graphs, lower is better.",4.2. Comparison with other Algorithms,[0],[0]
"Recall Tree has poly(log) dependence upon number of classes (like LOMTree) but can surpass OAA statistically.
",4.2. Comparison with other Algorithms,[0],[0]
conditional execution pattern of the Recall Tree frustrates vectorization even with example mini-batching.,4.2. Comparison with other Algorithms,[0],[0]
"Thus on ALOI although Recall Tree does on average 50 hyperplane evaluations per example while OAA does 1000, OAA is actually faster: larger numbers of classes are required to experience the asymptotic benefits.",4.2. Comparison with other Algorithms,[0],[0]
"For ODP with ∼ 105 classes, with negative gradient subsampling and using 24 cores in parallel, OAA is about the same wall clock time to train as Recall Tree on a single core.2 Negative gradient sampling does not improve inference times, which are ∼ 300 times slower for OAA than Recall Tree on ODP.",4.2. Comparison with other Algorithms,[0],[0]
In this experiment we leverage the online nature of the algorithm to exploit nonstationarity in the data to improve results.,4.3. Online Operation,[0],[0]
"This is not something that is easily done with batch oriented algorithms, or with algorithms that post-process a trained predictor to accelerate inference.
",4.3. Online Operation,[0],[0]
We consider two versions of LTCB.,4.3. Online Operation,[0],[0]
In both versions the task is to predict the next word given the previous 6 tokens.,4.3. Online Operation,[0],[0]
"The difference is that in one version, the Wikipedia dump is processed in the original order (“in-order”); whereas in the other version the training data is permuted prior to input to the learning algorithm (“permuted”).",4.3. Online Operation,[0],[0]
"We assess progressive validation loss (Blum et al., 1999) on the sequence.",4.3. Online Operation,[0],[0]
"The result in Figure 5a confirms the Recall Tree is able to take advantage of the sequentially revealed data; in particular, the far-right difference in accuracies is significant at a factor P < 0.0001 according to an N −1",4.3. Online Operation,[0],[0]
Chi-squared test.,4.3. Online Operation,[0],[0]
"Two differences between Recall Tree and LOMTree are the use of multiple regressors at each tree node and the aug-
2While not yet implemented, Recall Tree can presumably also leverage multicore for acceleration.
mentation of the example with path features.",4.4. Path Features and Multiple Regressors,[0],[0]
"In this experiment we explore the impact of these design choices using the ALOI dataset.
",4.4. Path Features and Multiple Regressors,[0],[0]
Figure 5b shows the effect of these two aspects on statistical performance.,4.4. Path Features and Multiple Regressors,[0],[0]
"As the candidate set size is increased, test error decreases, but with diminishing returns.",4.4. Path Features and Multiple Regressors,[0],[0]
"Disabling path features degrades performance, and the effect is more pronounced as the candidate set size increases.",4.4. Path Features and Multiple Regressors,[0],[0]
"This is expected, as a larger candidate set size decreases the difficulty of obtaining good recall (i.e., a good tree) but increases the difficulty of obtaining good precision (i.e., good class regressors), and path features are only applicable to the latter.",4.4. Path Features and Multiple Regressors,[0],[0]
"All differences here are significant at a P < 0.0001 according to an N − 1 Chi-squared test, except for when the candidate set size is 2, where there is no significant difference.",4.4. Path Features and Multiple Regressors,[0],[0]
To test this we trained on the LTCB dataset with a multiplier on the bound of either 0 (i.e. just using empirical recall directly) or 1.,4.5. Is the empirical Bernstein bound useful?,[0],[0]
"The results are stark: with a multiplier of 1, the test error was 78% while with a multiplier of 0 the test error was 91%.",4.5. Is the empirical Bernstein bound useful?,[0],[0]
"Clearly, in the few samples per class regime this form of direct regularization is very helpful.",4.5. Is the empirical Bernstein bound useful?,[0],[0]
"The LOMTree (Choromanska et al., 2016; Choromanska & Langford, 2015) is the closest prior work.",5. Related Work,[0],[0]
It misses on space requirements: up to a factor of 64 more space than OAA was used experimentally.,5. Related Work,[0],[0]
Despite working with radically less space we show the Recall Tree typically provides better predictive performance.,5. Related Work,[0],[0]
"The key differences here are algorithmic: a tighter reduction at internal nodes and the one-against-some approach yields generally better performance despite much tighter resource constraints.
",5. Related Work,[0],[0]
"70 75 80 85 90 95
100
10000 100000",5. Related Work,[0],[0]
1e+06,5. Related Work,[0],[0]
1e+07,5. Related Work,[0],[0]
"1e+08
Av er
ag e
Cu m
ul at
iv e
Pr og
re ss
iv e
Ac cu
ra cy
(% )
",5. Related Work,[0],[0]
"Examples
in-order permuted
(a) When the LTCB dataset is presented in the original order, Recall Tree is able to exploit sequential correlations for improved performance.",5. Related Work,[0],[0]
"After all examples are processed, the average progressive accuracy is 73.3% vs. 74.6%.
",5. Related Work,[0],[0]
"10 15 20 25 30 35 40
1 10 100
Te st
E rr
or (%
)
Candidate Set Size
with path features without path features
(b) Test error on ALOI for various candidate set sizes, with or without path features (all other parameters held fixed).",5. Related Work,[0],[0]
"Using multiple regressors per leaf and including path features improves performance.
",5. Related Work,[0],[0]
"Figure 5.
",5. Related Work,[0],[0]
"Our use of entropy optimization is closely related to the foundational work on decision tree learning (Quinlan, 1993), picking single features on which to split based on entropy.",5. Related Work,[0],[0]
"More recently, it is decision tree learning can be thought of as boosting (Kearns & Mansour, 1996) for multiclass learning (Takimoto & Maruoka, 2003), based on on a generalized notion of entropy, which results in low 0/1 loss.",5. Related Work,[0],[0]
Relative to these works we show how to efficiently achieve weak learning by reduction to binary classification making this approach empirically practical.,5. Related Work,[0],[0]
"We also address a structural issue in the multiclass analysis (see section 3.3).
",5. Related Work,[0],[0]
"Other approaches such as hierarchical softmax (HSM) and the the Filter Tree (Beygelzimer et al., 2009) use a fixed tree structure (Morin & Bengio, 2005).",5. Related Work,[0],[0]
"In domains in which there is no prespecified tree hierarchy, using a random tree structure can lead to considerable underperformance as shown previously (Bengio et al., 2010; Choromanska & Langford, 2015).
",5. Related Work,[0],[0]
"Most other approaches in extreme classification either do not work online (Mnih & Hinton, 2009; Prabhu & Varma, 2014) or only focus on speeding up either prediction time or training time but not both.",5. Related Work,[0],[0]
Most of the works that enjoy sublinear inference time (but (super)linear training time) are based on tree decomposition approaches.,5. Related Work,[0],[0]
"In (Mnih & Hinton, 2009) the authors try to add tree structure learning to HSM via iteratively clustering the classes.",5. Related Work,[0],[0]
"While the end result is a classifier whose inference time scales logarithmically with the number of classes, the clustering steps are batch and scale poorly with the number of classes.",5. Related Work,[0],[0]
"Similar remarks apply to (Bengio et al., 2010) where the authors propose to learn a tree by solving an eigenvalue problem after (OAA) training.",5. Related Work,[0],[0]
"The work of (Weston et al., 2013) is similar in spirit to ours, as the authors propose to learn
a label filter to reduce the number of candidate classes in an OAA approach.",5. Related Work,[0],[0]
"However they learn the tree after training the underlying OAA regressors while here we learn, and more crucially use, the tree during training of the OAS regressors.",5. Related Work,[0],[0]
"Among the approaches that speed up training time we distinguish exact ones (de Brébisson & Vincent, 2015; Vincent et al., 2015) that have only been proposed for particular loss functions and approximate ones such as negative sampling as used e.g. in (Weston et al., 2011).",5. Related Work,[0],[0]
"Though these techniques do not address inference time, separate procedures for speeding up inference (given a trained model) have been proposed (Shrivastava & Li, 2014).",5. Related Work,[0],[0]
"However, such two step procedures can lead to substantially suboptimal results.",5. Related Work,[0],[0]
"In this work we proposed the Recall Tree, a reduction of multiclass to binary classification, which operates online and scales logarithmically with the number of classes.",6. Conclusion,[0],[0]
"Unlike the LOMTree (Choromanska & Langford, 2015), we share classifiers among the nodes of the tree which alleviates data sparsity at deep levels while greatly reducing the required state.",6. Conclusion,[0],[0]
We also use a tighter analysis which is more closely followed in the implementation.,6. Conclusion,[0],[0]
These features allow us to reduce the statistical gap with OAA while still operating many orders of magnitude faster for large K multiclass datasets.,6. Conclusion,[0],[0]
In the future we plan to investigate multiway splits in the tree since O(logK)-way splits does not affect our O(poly logK) running time and they might reduce contention in the root and nodes high in the tree.,6. Conclusion,[0],[0]
We create a new online reduction of multiclass classification to binary classification for which training and prediction time scale logarithmically with the number of classes.,abstractText,[0],[0]
We show that several simple techniques give rise to an algorithm which is superior to previous logarithmic time classification approaches while competing with one-against-all in space.,abstractText,[0],[0]
"The core construction is based on using a tree to select a small subset of labels with high recall, which are then scored using a one-against-some structure with high precision.",abstractText,[0],[0]
Logarithmic Time One-Against-Some,title,[0],[0]
"Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 79–89, Baltimore, Maryland, USA, June 23-25 2014. c©2014 Association for Computational Linguistics",text,[0],[0]
"Dependency-based Compositional Semantics (DCS) provides an intuitive way to model semantics of questions, by using simple dependency-like trees (Liang et al., 2011).",1 Introduction,[0],[0]
"It is expressive enough to represent complex natural language queries on a relational database, yet simple enough to be latently learned from question-answer pairs.",1 Introduction,[0],[0]
"In this paper, we equip DCS with logical inference, which, in one point of view, is “the best way of testing an NLP system’s semantic capacity” (Cooper et al., 1996).
",1 Introduction,[0],[0]
"It should be noted that, however, a framework primarily designed for question answering is not readily suited for logical inference.",1 Introduction,[0],[0]
"Because, answers returned by a query depend on the specific database, but implication is independent of any databases.",1 Introduction,[0],[0]
"For example, answers to the question “What books are read by students?”, should always be a subset of answers to “What books are ever read by anyone?”, no matter how we store the data of students and how many records of books are there in our database.
",1 Introduction,[0],[0]
"Thus, our first step is to fix a notation which abstracts the calculation process of DCS trees, so as to clarify its meaning without the aid of any existing database.",1 Introduction,[0],[0]
"The idea is to borrow a minimal set of operators from relational algebra (Codd, 1970), which is already able to formulate the calculation in DCS and define abstract denotation, which is an abstraction of the computation of denotations guided by DCS trees.",1 Introduction,[0],[0]
Meanings of sentences then can be represented by primary relations among abstract denotations.,1 Introduction,[0],[0]
"This formulation keeps the simpleness and computability of DCS trees mostly unaffected; for example, our semantic calculation for DCS trees is parallel to the denotation computation in original DCS.
",1 Introduction,[0],[0]
An inference engine is built to handle inference on abstract denotations.,1 Introduction,[0],[0]
"Moreover, to compensate the lack of background knowledge in practical inference, we combine our framework with the idea of tree transformation (Bar-Haim et al., 2007), to propose a way of generating knowledge in logical representation from entailment rules (Szpektor et al., 2007), which are by now typically considered as syntactic rewriting rules.
",1 Introduction,[0],[0]
"We test our system on FraCaS (Cooper et al., 1996) and PASCAL RTE datasets (Dagan et al., 2006).",1 Introduction,[0],[0]
The experiments show: (i) a competitive performance on FraCaS dataset; (ii) a big impact of our automatically generated on-the-fly knowledge in achieving high recall for a logicbased RTE system; and (iii) a result that outperforms state-of-the-art RTE system on RTE5 data.,1 Introduction,[0],[0]
Our whole system is publicly released and can be downloaded from http://kmcs.nii.ac.,1 Introduction,[0],[0]
jp/tianran/tifmo/.,1 Introduction,[0],[0]
"In this section we describe the idea of representing natural language semantics by DCS trees, and achieving inference by computing logical relations among the corresponding abstract denotations.
79",2 The Idea,[0],[0]
"DCS trees has been proposed to represent natural language semantics with a structure similar to dependency trees (Liang et al., 2011) (Figure 1).",2.1 DCS trees,[0],[0]
"For the sentence “students read books”, imagine a database consists of three tables, namely, a set of students, a set of books, and a set of “reading” events (Table 1).",2.1 DCS trees,[0],[0]
"The DCS tree in Figure 1 is interpreted as a command for querying these tables, obtaining “reading” entries whose “SUBJ” field is student and whose “OBJ” field is book.",2.1 DCS trees,[0],[0]
"The result is a set {John reads Ulysses, . . .}, which is called a denotation.
",2.1 DCS trees,[0],[0]
"DCS trees can be extended to represent linguistic phenomena such as quantification and coreference, with additional markers introducing additional operations on tables.",2.1 DCS trees,[0],[0]
"Figure 2 shows an example with a quantifier “every”, which is marked as “⊂” on the edge (love)OBJ-ARG(dog) and interpreted as a division operator qOBJ⊂",2.1 DCS trees,[0],[0]
(§2.2).,2.1 DCS trees,[0],[0]
"Optimistically, we believe DCS can provide a framework of semantic representation with sufficiently wide coverage for real-world texts.
",2.1 DCS trees,[0],[0]
The strict semantics of DCS trees brings us the idea of applying DCS to logical inference.,2.1 DCS trees,[0],[0]
"This is not trivial, however, because DCS works under the assumption that databases are explicitly available.",2.1 DCS trees,[0],[0]
"Obviously this is unrealistic for logical inference on unrestricted texts, because we cannot prepare a database for everything in the world.",2.1 DCS trees,[0],[0]
"This fact fairly restricts the applicable tasks of DCS.
",2.1 DCS trees,[0],[0]
"Our solution is to redefine DCS trees without the aid of any databases, by considering each node of a DCS tree as a content word in a sentence (but may no longer be a table in a specific database), while each edge represents semantic relations between two words.",2.1 DCS trees,[0],[0]
"The labels on both ends of an edge, such as SUBJ (subject) and OBJ (object), are considered as semantic roles of the cor-
responding words1.",2.1 DCS trees,[0],[0]
"To formulate the database querying process defined by a DCS tree, we provide formal semantics to DCS trees by employing relational algebra (Codd, 1970) for representing the query.",2.1 DCS trees,[0],[0]
"As described below, we represent meanings of sentences with abstract denotations, and logical relations among sentences are computed as relations among their abstract denotations.",2.1 DCS trees,[0],[0]
"In this way, we can perform inference over formulas of relational algebra, without computing database entries explicitly.",2.1 DCS trees,[0],[0]
"Abstract denotations are formulas constructed from a minimal set of relational algebra (Codd, 1970) operators, which is already able to formulate the database queries defined by DCS trees.
",2.2 Abstract denotations,[0],[0]
"For example, the semantics of “students read books” is given by the abstract denotation:
F1 = read ∩ (studentSUBJ × bookOBJ),
where read, student and book denote sets represented by these words respectively, and wr represents the set w considered as the domain of the semantic role r (e.g. bookOBJ is the set of books considered as objects).",2.2 Abstract denotations,[0],[0]
"The operators∩ and× represent intersection and Cartesian product respectively, both borrowed from relational algebra.",2.2 Abstract denotations,[0],[0]
"It is not hard to see the abstract denotation denotes the intersection of the “reading” set (as illustrated by the “read” table in Table 1) with the product of “student” set and “book” set, which results in the same denotation as computed by the DCS tree in Figure 1, i.e. {John reads Ulysses, . . .}.",2.2 Abstract denotations,[0],[0]
"However, the point is that F1 itself is an algebraic formula that does not depend on any concrete databases.
",2.2 Abstract denotations,[0],[0]
"Formally, we introduce the following constants:
• W : a universal set containing all entities.",2.2 Abstract denotations,[0],[0]
"1The semantic role ARG is specifically defined for denot-
ing nominal predicate.
example phrase abstract denotation / statement compound noun pet fish pet ∩ fish modification nice day day ∩ (WARG × niceMOD) temporal relation boys study at night study ∩ (boySUBJ × nightTIME) relative clause books that book ∩ πOBJ(read students read ∩(studentSUBJ ×WOBJ))",2.2 Abstract denotations,[0],[0]
quantification all men die man ⊂ πSUBJ(die) hypernym dog ⊂ animal derivation all criminals commit criminal ⊂ πSUBJ(commit∩ a crime (WSUBJ × crimeOBJ)),2.2 Abstract denotations,[0],[0]
"antonym rise ‖ fall negation no dogs are hurt dog ‖ πOBJ(hurt)
",2.2 Abstract denotations,[0],[0]
An abstract denotation is then defined as finite applications of functions on either constants or other abstract denotations.,2.2 Abstract denotations,[0],[0]
"As the semantics of DCS trees is formulated by abstract denotations, the meanings of declarative sentences are represented by statements on abstract denotations.",2.3 Statements,[0],[0]
"Statements are declarations of some relations among abstract denotations, for which we consider the following set relations:
Non-emptiness",2.3 Statements,[0],[0]
A 6= ∅: the set A is not empty.,2.3 Statements,[0],[0]
"Subsumption A ⊂ B: set A is subsumed by B.3 Roughly speaking, the relations correspond to the logical concepts satisfiability and entailment.
",2.3 Statements,[0],[0]
2If,2.3 Statements,[0],[0]
"A and B has the same dimension, q⊂(A,B) is either ∅ or {∗} (0-dimension point set), depending on if A ⊂ B.
3Using division operator, subsumption can be represented by non-emptiness, since for setsA,B of the same dimension, q⊂(A,B) 6= ∅",2.3 Statements,[0],[0]
"⇔ A ⊂ B.
Abstract denotations and statements are convenient for representing semantics of various types of expressions and linguistic knowledge.",2.3 Statements,[0],[0]
Some examples are shown in Table 2.4,2.3 Statements,[0],[0]
"Based on abstract denotations, we briefly describe our process to apply DCS to textual inference.",2.4 Logical inference on DCS,[0],[0]
"To obtain DCS trees from natural language, we use Stanford CoreNLP5 for dependency parsing (Socher et al., 2013), and convert Stanford dependencies to DCS trees by pattern matching on POS tags and dependency labels.6",2.4.1 Natural language to DCS trees,[0],[0]
"Currently we use the following semantic roles: ARG, SUBJ, OBJ, IOBJ, TIME and MOD.",2.4.1 Natural language to DCS trees,[0],[0]
The semantic role MOD is used for any restrictive modifiers.,2.4.1 Natural language to DCS trees,[0],[0]
"Determiners such as “all”, “every” and “each” trigger quantifiers, as shown in Figure 2.",2.4.1 Natural language to DCS trees,[0],[0]
"A DCS tree T = (N , E) is defined as a rooted tree, where each node σ ∈ N is labeled with a content word w(σ) and each edge (σ, σ′) ∈ E ⊂",2.4.2 DCS trees to statements,[0],[0]
N,2.4.2 DCS trees to statements,[0],[0]
"× N is labeled with a pair of semantic roles (r, r′)7.",2.4.2 DCS trees to statements,[0],[0]
Here σ is the node nearer to the root.,2.4.2 DCS trees to statements,[0],[0]
"Furthermore, for each edge (σ, σ′) we can optionally assign a quantification marker.
",2.4.2 DCS trees to statements,[0],[0]
Abstract denotation of a DCS tree can be calculated in a bottom-up manner.,2.4.2 DCS trees to statements,[0],[0]
"For example, the abstract denotation of H in Figure 2 is calculated from the leaf node Mary, and then: Node love (Mary loves): F2 = love ∩ (MarySUBJ ×WOBJ) Node animal (Animal that Mary loves): F3 = animal ∩ πOBJ(F2) Node have (Tom has an animal that Mary loves): F4 = have ∩ (TomSUBJ × (F3)OBJ).",2.4.2 DCS trees to statements,[0],[0]
"Formally, suppose the root σ of a DCS tree T has children τ1, . . .",2.4.2 DCS trees to statements,[0],[0]
", τn, and edges (σ, τ1), . . .",2.4.2 DCS trees to statements,[0],[0]
", (σ, τn) labeled by (r1, r′1), . . .",2.4.2 DCS trees to statements,[0],[0]
", (rn, r′n), respectively.",2.4.2 DCS trees to statements,[0],[0]
"The abstract denotation of T is defined as:
",2.4.2 DCS trees to statements,[0],[0]
[[T ]]=w(σ) ∩ ( n⋂ i=1,2.4.2 DCS trees to statements,[0],[0]
ιri(πr′i([[Tτi,2.4.2 DCS trees to statements,[0],[0]
"]]))×WRσ\ri),
4Negation and disjointness (“‖”) are explained in §2.5.",2.4.2 DCS trees to statements,[0],[0]
"5http://nlp.stanford.edu/software/
corenlp.shtml",2.4.2 DCS trees to statements,[0],[0]
6In,2.4.2 DCS trees to statements,[0],[0]
"(Liang et al., 2011)",2.4.2 DCS trees to statements,[0],[0]
DCS trees are learned from QA pairs and database entries.,2.4.2 DCS trees to statements,[0],[0]
"We obtain DCS trees from dependency trees, to bypass the need of a concrete database.
",2.4.2 DCS trees to statements,[0],[0]
"7The definition differs slightly from the original Liang et al. (2011), mainly for the sake of simplicity and clarity.
where Tτi is the subtree of T rooted at τi, and Rσ is the set of possible semantic roles for content word w(σ)",2.4.2 DCS trees to statements,[0],[0]
"(e.g. Rlove = {SUBJ,OBJ}), and WRσ\ri is the product of W which has dimension Rσ \ ri (e.g. W{SUBJ,OBJ}\SUBJ = WOBJ).
",2.4.2 DCS trees to statements,[0],[0]
"When universal quantifiers are involved, we need to add division operators to the formula.",2.4.2 DCS trees to statements,[0],[0]
"If (σ, τi) is assigned by a quantification marker “⊂”8, then the abstract denotation is9
[[T ]]=qri⊂ (πRσ\{r1,...,ri−1}([[T ′]]), πr′i([[Tτi ]])), where T ′ is the same tree as T except that the edge (σ, τi) is removed.",2.4.2 DCS trees to statements,[0],[0]
"For example, the abstract denotation of the first sentence of T in Figure 2 (Mary loves every dog) is calculated from F2 (Mary loves) as
F5 = qOBJ⊂",2.4.2 DCS trees to statements,[0],[0]
"(πOBJ(F2),dog).
",2.4.2 DCS trees to statements,[0],[0]
"After the abstract denotation [[T ]] is calculated, the statement representing the meaning of the sentence is defined as [[T ]] 6= ∅.",2.4.2 DCS trees to statements,[0],[0]
"For example, the statement of “students read books” is read ∩ (studentSUBJ × bookOBJ) 6=",2.4.2 DCS trees to statements,[0],[0]
"∅, and the statement of “Mary loves every dog” is qOBJ⊂ (πOBJ(F2),dog) 6=",2.4.2 DCS trees to statements,[0],[0]
"∅, which is logically equivalent to dog ⊂ πOBJ(F2).10",2.4.2 DCS trees to statements,[0],[0]
"Since meanings of sentences are represented by statements on abstract denotations, logical inference among sentences is reduced to deriving new relations among abstract denotations.",2.4.3 Logical inference,[0],[0]
"This is done by applying axioms to known statements, and approximately 30 axioms are implemented (Table 3).
8Multiple quantifiers can be processed similarly.",2.4.3 Logical inference,[0],[0]
"9The result of [[T ]] depends on the order of the children τ1, . . .",2.4.3 Logical inference,[0],[0]
", τn.",2.4.3 Logical inference,[0],[0]
"Different orders correspond to readings of different quantifier scopes.
",2.4.3 Logical inference,[0],[0]
"10See Footnote 2,3.
",2.4.3 Logical inference,[0],[0]
"These are algebraic properties of abstract denotations, among which we choose a set of axioms that can be handled efficiently and enable most common types of inference seen in natural language.
",2.4.3 Logical inference,[0],[0]
"For the example in Figure 2, by constructing the following abstract denotations:
Tom has a dog: F6 = have ∩ (TomSUBJ × dogOBJ) Objects that Tom has: F7 = πOBJ(have ∩ (TomSUBJ ×WOBJ)), we can use the lexical knowledge dog ⊂ animal, the statements of T (i.e. dog ⊂ πOBJ(F2) and F6 6= ∅), and the axioms in Table 3,11 to prove the statement of H (i.e. F4 6= ∅) (Figure 3).
",2.4.3 Logical inference,[0],[0]
We built an inference engine to perform logical inference on abstract denotations as above.,2.4.3 Logical inference,[0],[0]
"In this logical system, we treat abstract denotations as terms and statements as atomic sentences, which are far more easier to handle than first order predicate logic (FOL) formulas.",2.4.3 Logical inference,[0],[0]
"Furthermore, all implemented axioms are horn clauses, hence we can employ forward-chaining, which is very efficient.",2.4.3 Logical inference,[0],[0]
"Further extensions of our framework are made to deal with additional linguistic phenomena, as briefly explained below.
",2.5 Extensions,[0],[0]
"Negation To deal with negation in our forwardchaining inference engine, we introduce one more relation on abstract denotations, namely disjointness A ‖ B, meaning that A and B are disjoint sets.",2.5 Extensions,[0],[0]
"Using disjointness we implemented two types of negations: (i) atomic negation, for each content word w we allow negation w̄ of that word, characterized by the property w ‖ w̄; and (ii) root negation, for a DCS tree T and its denotation",2.5 Extensions,[0],[0]
"[[T ]], the negation of T is represented by T ‖ T , meaning that T = ∅ in its effect.",2.5 Extensions,[0],[0]
"Selection Selection operators in relational algebra select a subset from a set to satisfy some spe-
11Algebraic identities, such as πOBJ(F4) = F3 ∩ F7 and πOBJ(F6) = dog ∩ F7, are also axioms.
cific properties.",2.5 Extensions,[0],[0]
This can be employed to represent linguistic phenomena such as downward monotonicity and generalized quantifiers.,2.5 Extensions,[0],[0]
"In the current system, we implement (i) superlatives, e.g. shighest(mountain∩ (WARG×AsiaMOD)) (the highest mountain in Asia) and (ii) numerics, e.g. stwo(pet ∩ fish) (two pet fish), where sf is a selection marker.",2.5 Extensions,[0],[0]
"Selection operators are implemented as markers assigned to abstract denotations, with specially designed axioms.",2.5 Extensions,[0],[0]
For example superlatives satisfy the following property: A ⊂ B & shighest(B) ⊂,2.5 Extensions,[0],[0]
A ⇒ shighest(B) = shighest(A).,2.5 Extensions,[0],[0]
"New rules can be added if necessary.
",2.5 Extensions,[0],[0]
"Coreference We use Stanford CoreNLP to resolve coreferences (Raghunathan et al., 2010), whereas coreference is implemented as a special type of selection.",2.5 Extensions,[0],[0]
"If a node σ in a DCS tree T belongs to a mention cluster m, we take the abstract denotation",2.5 Extensions,[0],[0]
"[[Tσ]] and make a selection sm([[Tσ]]), which is regarded as the abstract denotation of that mention.",2.5 Extensions,[0],[0]
Then all selections of the same mention cluster are declared to be equal.,2.5 Extensions,[0],[0]
"Recognizing textual entailment (RTE) is the task of determining whether a given textual statement H can be inferred by a text passage T. For this, our primary textual inference system operates as:
1.",3 Generating On-the-fly Knowledge,[0],[0]
"For a T-H pair, apply dependency parsing and coreference resolution.
2.",3 Generating On-the-fly Knowledge,[0],[0]
"Perform rule-based conversion from dependency parses to DCS trees, which are translated to statements on abstract denotations.
3.",3 Generating On-the-fly Knowledge,[0],[0]
"Use statements of T and linguistic knowledge as premises, and try to prove statements of H by our inference engine.
",3 Generating On-the-fly Knowledge,[0],[0]
"However, this method does not work for realworld datasets such as PASCAL RTE (Dagan et al., 2006), because of the knowledge bottleneck: it is often the case that the lack of sufficient linguistic knowledge causes failure of inference, thus the system outputs “no entailment” for almost all pairs (Bos and Markert, 2005).
",3 Generating On-the-fly Knowledge,[0],[0]
The transparent syntax-to-semantics interface of DCS enables us to back off to NLP techniques during inference for catching up the lack of knowledge.,3 Generating On-the-fly Knowledge,[0],[0]
"We extract fragments of DCS trees as paraphrase candidates, translate them back to linguis-
tic expressions, and apply distributional similarity to judge their validity.",3 Generating On-the-fly Knowledge,[0],[0]
"In this way, our framework combines distributional and logical semantics, which is also the main subject of Lewis and Steedman (2013) and Beltagy et al. (2013).
",3 Generating On-the-fly Knowledge,[0],[0]
"As follows, our full system (Figure 4) additionally invokes linguistic knowledge on-the-fly:
4.",3 Generating On-the-fly Knowledge,[0],[0]
"If H is not proven, compare DCS trees of T and H, and generate path alignments.
5.",3 Generating On-the-fly Knowledge,[0],[0]
Aligned paths are evaluated by a similarity score to estimate their likelihood of being paraphrases.,3 Generating On-the-fly Knowledge,[0],[0]
"Path alignments with scores higher than a threshold are accepted.
6.",3 Generating On-the-fly Knowledge,[0],[0]
"Convert accepted path alignments into statements on abstract denotations, use them in logical inference as new knowledge, and try to prove H again.",3 Generating On-the-fly Knowledge,[0],[0]
On-the-fly knowledge is generated by aligning paths in DCS trees.,3.1 Generating path alignments,[0],[0]
"A path is considered as joining two germs in a DCS tree, where a germ is defined as a specific semantic role of a node.",3.1 Generating path alignments,[0],[0]
"For example, Figure 5 shows DCS trees of the following sentences (a simplified pair from RTE2-dev):",3.1 Generating path alignments,[0],[0]
The germ OBJ(blame) and germ ARG(death) in DCS tree of T are joined by the underscored path.,H: A storm has caused loss of life.,[0],[0]
"Two paths are aligned if the joined germs are aligned, and we impose constraints on aligned germs to inhibit meaningless alignments, as described below.",H: A storm has caused loss of life.,[0],[0]
"Two germs are aligned if they are both at leaf nodes (e.g. ARG(death) in T and ARG(life) in H, Figure 5), or they already have part of their meanings in common, by some logical clues.
",3.2 Aligning germs by logical clues,[0],[0]
"To formulate this properly, we define the abstract denotation of a germ, which, intuitively, represents the meaning of the germ in the specific sentence.",3.2 Aligning germs by logical clues,[0],[0]
"The abstract denotation of a germ is defined in a top-down manner: for the root node ρ of a DCS tree T , we define its denotation",3.2 Aligning germs by logical clues,[0],[0]
[[ρ]]T as the denotation of the entire tree,3.2 Aligning germs by logical clues,[0],[0]
"[[T ]]; for a non-root node τ and its parent node σ, let the edge (σ, τ) be labeled by semantic roles (r, r′), then define
[[τ ]]T =",3.2 Aligning germs by logical clues,[0],[0]
[[Tτ ]] ∩ (ιr′(πr([[σ]]T )),3.2 Aligning germs by logical clues,[0],[0]
"×WRτ\r′).
",3.2 Aligning germs by logical clues,[0],[0]
"Now for a germ r(σ), the denotation is defined as the projection of the denotation of node σ onto the specific semantic role r:",3.2 Aligning germs by logical clues,[0],[0]
"[[r(σ)]]T = πr([[σ]]T ).
",3.2 Aligning germs by logical clues,[0],[0]
"For example, the abstract denotation of germ ARG(book) in Figure 1 is defined as πARG(book∩ πOBJ(read∩(studentSUBJ×bookOBJ))), meaning “books read by students”.",3.2 Aligning germs by logical clues,[0],[0]
"Similarly, denotation of germ OBJ(blame) in T of Figure 5 indicates the object of “blame” as in the sentence “Tropical storm Debby is blamed for death”, which is a tropical storm, is Debby, etc.",3.2 Aligning germs by logical clues,[0],[0]
"Technically, each germ in a DCS tree indicates a variable when the DCS tree is translated to a FOL formula, and the abstract denotation of the germ corresponds to the set of consistent values (Liang et al., 2011) of that variable.
",3.2 Aligning germs by logical clues,[0],[0]
"The logical clue to align germs is: if there exists an abstract denotation, other than W , that is a superset of both abstract denotations of two germs, then the two germs can be aligned.",3.2 Aligning germs by logical clues,[0],[0]
"A simple example is that ARG(storm) in T can be aligned to ARG(storm) in H, because their denotations have a common superset other than W , namely πARG(storm).",3.2 Aligning germs by logical clues,[0],[0]
"A more complicated example is that OBJ(blame) and SUBJ(cause) can be aligned, because inference can induce [[OBJ(blame)]]T = [[ARG(Debby)]]T =",3.2 Aligning germs by logical clues,[0],[0]
"[[ARG(storm)]]T, as well as [[SUBJ(cause)]]H =",3.2 Aligning germs by logical clues,[0],[0]
"[[ARG(storm)]]H, so they also have the common superset πARG(storm).",3.2 Aligning germs by logical clues,[0],[0]
"However, for example, logical clues can avoid aligning ARG(storm) to ARG(loss), which is obviously
meaningless.",3.2 Aligning germs by logical clues,[0],[0]
"Aligned paths are evaluated by a similarity score, for which we use distributional similarity of the words that appear in the paths (§4.1).",3.3 Scoring path alignments by similarity,[0],[0]
Only path alignments with high similarity scores can be accepted.,3.3 Scoring path alignments by similarity,[0],[0]
"Also, we only accept paths of length ≤ 5, to prevent too long paths to be aligned.",3.3 Scoring path alignments by similarity,[0],[0]
"Accepted aligned paths are converted into statements, which are used as new knowledge.",3.4 Applying path alignments,[0],[0]
"The conversion is done by first performing a DCS tree transformation according to the aligned paths, and then declare a subsumption relation between the denotations of aligned germs.",3.4 Applying path alignments,[0],[0]
"For example, to apply the aligned path pair generated in Figure 5, we use it to transform T into a new tree T’ (Figure 6), and then the aligned germs, OBJ(blame) in T and SUBJ(cause) in T’, will generate the on-the-fly knowledge:",3.4 Applying path alignments,[0],[0]
[[OBJ(blame)]]T ⊂,3.4 Applying path alignments,[0],[0]
"[[SUBJ(cause)]]T’.
Similar to the tree transformation based approach to RTE (Bar-Haim et al., 2007), this process can also utilize lexical-syntactic entailment rules (Szpektor et al., 2007).",3.4 Applying path alignments,[0],[0]
"Furthermore, since the on-the-fly knowledge is generated by transformed pairs of DCS trees, all contexts are preserved: in Figure 6, though the tree transformation can be seen as generated from the entailment rule “X is blamed for death→ X causes loss of life”, the generated on-the-fly knowledge, as shown above the trees, only fires with the additional condition that X is a tropical storm and is Debby.",3.4 Applying path alignments,[0],[0]
"Hence, the process can also be used to generate knowledge from context sensitive rules (Melamud et al., 2013), which are known to have higher quality (Pantel et al., 2007; Clark and Harrison, 2009).
",3.4 Applying path alignments,[0],[0]
"However, it should be noted that using on-thefly knowledge in logical inference is not a trivial
task.",3.4 Applying path alignments,[0],[0]
"For example, the FOL formula of the rule “X is blamed for death→ X causes loss of life” is:
∀x; (∃a; blame(x, a) & death(a))→ (∃b, c; cause(x, b) & loss(b, c) & life(c)),
which is not a horn clause.",3.4 Applying path alignments,[0],[0]
The FOL formula for the context-preserved rule in Figure 6 is even more involved.,3.4 Applying path alignments,[0],[0]
"Still, it can be efficiently treated by our inference engine because as a statement, the formula",3.4 Applying path alignments,[0],[0]
"[[OBJ(blame)]]T ⊂ [[SUBJ(cause)]]T’ is an atomic sentence, more than a horn clause.",3.4 Applying path alignments,[0],[0]
"In this section, we evaluate our system on FraCaS (§4.2) and PASCAL RTE datasets (§4.3).",4 Experiments,[0],[0]
"The lexical knowledge we use are synonyms, hypernyms and antonyms extracted from WordNet12.",4.1 Language Resources,[0],[0]
"We also add axioms on named entities, stopwords, numerics and superlatives.",4.1 Language Resources,[0],[0]
"For example, named entities are singletons, so we add axioms such as ∀x; (x ⊂ Tom & x 6= ∅)→",4.1 Language Resources,[0],[0]
"Tom ⊂ x.
To calculate the similarity scores of path alignments, we use the sum of word vectors of the words from each path, and calculate the cosine similarity.",4.1 Language Resources,[0],[0]
"For example, the similarity score of the path alignment “OBJ(blame)IOBJ-ARG(death)",4.1 Language Resources,[0],[0]
≈ SUBJ(cause)OBJ-ARG(loss)MOD-ARG(life)” is calculated as the cosine similarity of vectors blame+death and cause+loss+life.,4.1 Language Resources,[0],[0]
"Other structures in the paths, such as semantic roles, are ignored in the calculation.",4.1 Language Resources,[0],[0]
"The word vectors we use are from Mikolov et al. (2013)13 (Mikolov13), and additional results are also shown using Turian et al. (2010)14 (Turian10).",4.1 Language Resources,[0],[0]
"The threshold for accepted path alignments is set to 0.4, based on preexperiments on RTE development sets.",4.1 Language Resources,[0],[0]
"The FraCaS test suite contains 346 inference problems divided into 9 sections, each focused on a category of semantic phenomena.",4.2 Experiments on FraCaS,[0],[0]
"We use the data by MacCartney and Manning (2007), and experiment on the first section, Quantifiers, following Lewis and Steedman (2013).",4.2 Experiments on FraCaS,[0],[0]
This section has 44 single premise and 30 multi premise problems.,4.2 Experiments on FraCaS,[0],[0]
"Most of
12http://wordnet.princeton.edu/ 13http://code.google.com/p/word2vec/ 14http://metaoptimize.com/projects/
wordreprs/
the problems do not require lexical knowledge, so we use our primary textual inference system without on-the-fly knowledge nor WordNet, to test the performance of the DCS framework as formal semantics.",4.2 Experiments on FraCaS,[0],[0]
"To obtain the three-valued output (i.e. yes, no, and unknown), we output “yes” if H is proven, or try to prove the negation of H if H is not proven.",4.2 Experiments on FraCaS,[0],[0]
"To negate H, we use the root negation as described in §2.5.",4.2 Experiments on FraCaS,[0],[0]
"If the negation of H is proven, we output “no”, otherwise we output “unknown”.
",4.2 Experiments on FraCaS,[0],[0]
The result is shown in Table 4.,4.2 Experiments on FraCaS,[0],[0]
"Since our system uses an off-the-shelf dependency parser, and semantic representations are obtained from simple rule-based conversion from dependency trees, there will be only one (right or wrong) interpretation in face of ambiguous sentences.",4.2 Experiments on FraCaS,[0],[0]
"Still, our system outperforms Lewis and Steedman (2013)’s probabilistic CCG-parser.",4.2 Experiments on FraCaS,[0],[0]
"Compared to MacCartney and Manning (2007) and MacCartney and Manning (2008), our system does not need a pretrained alignment model, and it improves by making multi-sentence inferences.",4.2 Experiments on FraCaS,[0],[0]
"To sum up, the result shows that DCS is good at handling universal quantifiers and negations.
",4.2 Experiments on FraCaS,[0],[0]
Most errors are due to wrongly generated DCS trees (e.g. wrongly assigned semantic roles) or unimplemented quantifier triggers (e.g. “neither”) or generalized quantifiers (e.g. “at least a few”).,4.2 Experiments on FraCaS,[0],[0]
These could be addressed by future work.,4.2 Experiments on FraCaS,[0],[0]
"On PASCAL RTE datasets, strict logical inference is known to have very low recall (Bos and Markert, 2005), so on-the-fly knowledge is crucial in this setting.",4.3 Experiments on PASCAL RTE datasets,[0],[0]
"We test the effect of on-the-fly knowledge on RTE2, RTE3, RTE4 and RTE5 datasets, and compare our system with other approaches.",4.3 Experiments on PASCAL RTE datasets,[0],[0]
Results on test data are shown in Table 5.,4.3.1 Impact of on-the-fly knowledge,[0],[0]
"When only primary knowledge is used in inference (the first row), recalls are actually very low; After we activate the on-the-fly knowledge, recalls jump to over 50%, with a moderate fall of precision.",4.3.1 Impact of on-the-fly knowledge,[0],[0]
"As a result, accuracies significantly increase.",4.3.1 Impact of on-the-fly knowledge,[0],[0]
A comparison between our system and other RTE systems is shown in Table 6.,4.3.2 Comparison to other RTE systems,[0],[0]
"Bos06 (Bos and Markert, 2006) is a hybrid system combining deep features from a theorem prover and a model builder, together with shallow features such as lexical overlap and text length.",4.3.2 Comparison to other RTE systems,[0],[0]
"MacCartney08 (MacCartney and Manning, 2008) uses natural logic to calculate inference relations between two superficially aligned sentences.",4.3.2 Comparison to other RTE systems,[0],[0]
"Clark08 (Clark and Harrison, 2008) is a logic-based system utilizing various resources including WordNet and DIRT paraphrases (Lin and Pantel, 2001), and is tolerant to partially unproven H sentences in some degree.",4.3.2 Comparison to other RTE systems,[0],[0]
"All of the three systems pursue a logical approach, while combining various techniques to achieve robustness.",4.3.2 Comparison to other RTE systems,[0],[0]
The result shows that our system has comparable performance.,4.3.2 Comparison to other RTE systems,[0],[0]
"On the other hand, Wang10 (Wang and Manning, 2010) learns a treeedit model from training data, and captures entailment relation by tree edit distance.",4.3.2 Comparison to other RTE systems,[0],[0]
"Stern11 (Stern and Dagan, 2011) and Stern12 (Stern et al., 2012) extend this framework to utilize entailment rules as tree transformations.",4.3.2 Comparison to other RTE systems,[0],[0]
These are more tailored systems using machine learning with many handcrafted features.,4.3.2 Comparison to other RTE systems,[0],[0]
"Still, our unsupervised system outperforms the state-of-the-art on RTE5 dataset.",4.3.2 Comparison to other RTE systems,[0],[0]
"Summing up test data from RTE2 to RTE5, Figure 7 shows the proportion of all proven pairs and their precision.",4.3.3 Analysis,[0],[0]
"Less than 5% pairs can be proven primarily, with a precision of 77%.",4.3.3 Analysis,[0],[0]
"Over 40% pairs can be proven by one piece of on-the-fly knowledge, yet pairs do exist in which more than 2 pieces are necessary.",4.3.3 Analysis,[0],[0]
"The precisions of 1 and 2 pieces on-the-fly knowledge application are over
60%, which is fairly high, given our rough estimation of the similarity score.",4.3.3 Analysis,[0],[0]
"As a comparison, Dinu and Wang (2009) studied the proportion of proven pairs and precision by applying DIRT rules to tree skeletons in RTE2 and RTE3 data.",4.3.3 Analysis,[0],[0]
"The proportion is 8% with precision 65% on RTE2, and proportion 6% with precision 72% on RTE3.",4.3.3 Analysis,[0],[0]
"Applied by our logical system, the noisy on-the-fly knowledge can achieve a precision comparable to higher quality resources such as DIRT.
",4.3.3 Analysis,[0],[0]
A major type of error is caused by the ignorance of semantic roles in calculation of similarity scores.,4.3.3 Analysis,[0],[0]
"For example, though “Italy beats Kazakhstan” is not primarily proven from “Italy is defeated by Kazakhstan”, our system does produce the path alignment “SUBJ(beat)OBJ ≈ OBJ(defeat)SUBJ” with a high similarity score.",4.3.3 Analysis,[0],[0]
"The impact of such errors depends on the data making methodology, though.",4.3.3 Analysis,[0],[0]
"It lowers precisions in RTE2 and RTE3 data, particularly in “IE” subtask (where precisions drop under 0.5).",4.3.3 Analysis,[0],[0]
"On the other hand, it occurs less often in “IR” subtask.
",4.3.3 Analysis,[0],[0]
"Finally, to see if we “get lucky” on RTE5 data in the choice of word vectors and thresholds, we change the thresholds from 0.1 to 0.7 and draw the precision-recall curve, using two types of word vectors, Mikolov13 and Turian10.",4.3.3 Analysis,[0],[0]
"As shown in Figure 8, though the precision drops for Turian10, both curves show the pattern that our system keeps gaining recall while maintaining precision to a certain level.",4.3.3 Analysis,[0],[0]
"Not too much “magic” in Mikolov13 actually: for over 80% pairs, every node in DCS tree of H can be covered by a path of length ≤ 5 that
has a corresponding path of length ≤ 5 in T with a similarity score > 0.4.",4.3.3 Analysis,[0],[0]
"We have presented a method of deriving abstract denotation from DCS trees, which enables logical inference on DCS, and we developed a textual inference system based on the framework.",5 Conclusion and Discussion,[0],[0]
"Experimental results have shown the power of the representation that allows both strict inference as on FraCaS data and robust reasoning as on RTE data.
",5 Conclusion and Discussion,[0],[0]
Exploration of an appropriate meaning representation for querying and reasoning on knowledge bases has a long history.,5 Conclusion and Discussion,[0],[0]
"Description logic, being less expressive than FOL but featuring more efficient reasoning, is used as a theory base for Semantic Web (W3C, 2012).",5 Conclusion and Discussion,[0],[0]
"Ideas similar to our framework, including the use of sets in a representation that benefits efficient reasoning, are also found in description logic and knowledge representation community (Baader et al., 2003; Sowa, 2000; Sukkarieh, 2003).",5 Conclusion and Discussion,[0],[0]
"To our knowledge, however, their applications to logical inference beyond the use for database querying have not been much explored in the context of NLP.
",5 Conclusion and Discussion,[0],[0]
The pursue of a logic more suitable for natural language inference is not new.,5 Conclusion and Discussion,[0],[0]
"For instance, MacCartney and Manning (2008) has implemented a model of natural logic (Lakoff, 1970).",5 Conclusion and Discussion,[0],[0]
"While being computationally efficient, various inference patterns are out of the scope of their system.
",5 Conclusion and Discussion,[0],[0]
"Much work has been done in mapping natural language into database queries (Cai and Yates, 2013; Kwiatkowski et al., 2013; Poon, 2013).",5 Conclusion and Discussion,[0],[0]
"Among these, the (λ-)DCS (Liang et al., 2011; Berant et al., 2013) framework defines algorithms that transparently map a labeled tree to a database querying procedure.",5 Conclusion and Discussion,[0],[0]
"Essentially, this is because DCS trees restrict the querying process to a very limited subset of possible operations.",5 Conclusion and Discussion,[0],[0]
"Our main contribution, the abstract denotation of DCS trees,
can thus be considered as an attempt to characterize a fragment of FOL that is suited for both natural language inference and transparent syntaxsemantics mapping, through the choice of operations and relations on sets.
",5 Conclusion and Discussion,[0],[0]
We have demonstrated the utility of logical inference on DCS through the RTE task.,5 Conclusion and Discussion,[0],[0]
"A wide variety of strategies tackling the RTE task have been investigated (Androutsopoulos and Malakasiotis, 2010), including the comparison of surface strings (Jijkoun and De Rijke, 2005), syntactic and semantic structures (Haghighi et al., 2005; Snow et al., 2006; Zanzotto et al., 2009; Burchardt et al., 2009; Heilman and Smith, 2010; Wang and Manning, 2010), semantic vectors (Erk and Padó, 2009) and logical representations (Bos and Markert, 2005; Raina et al., 2005; Tatu and Moldovan, 2005).",5 Conclusion and Discussion,[0],[0]
"Acquisition of basic knowledge for RTE is also a huge stream of research (Lin and Pantel, 2001; Shinyama et al., 2002; Sudo et al., 2003; Szpektor et al., 2004; Fujita et al., 2012; Weisman et al., 2012; Yan et al., 2013).",5 Conclusion and Discussion,[0],[0]
"These previous works include various techniques for acquiring and incorporating different kinds of linguistic and world knowledge, and further fight against the knowledge bottleneck problem, e.g. by back-off to shallower representations.
",5 Conclusion and Discussion,[0],[0]
Logic-based RTE systems employ various approaches to bridge knowledge gaps.,5 Conclusion and Discussion,[0],[0]
"Bos and Markert (2005) proposes features from a model builder; Raina et al. (2005) proposes an abduction process; Tatu and Moldovan (2006) shows handcrafted rules could drastically improve the performance of a logic-based RTE system.
",5 Conclusion and Discussion,[0],[0]
"As such, our current RTE system is at a proofof-concept stage, in that many of the above techniques are yet to be implemented.",5 Conclusion and Discussion,[0],[0]
"Nonetheless, we would like to emphasize that it already shows performance competitive to state-of-the-art systems on one data set (RTE5).",5 Conclusion and Discussion,[0],[0]
Other directions of our future work include further exploitation of the new semantic representation.,5 Conclusion and Discussion,[0],[0]
"For example, since abstract denotations are readily suited for data querying, they can be used to verify newly generated assumptions by fact search in a database.",5 Conclusion and Discussion,[0],[0]
"This may open a way towards a hybrid approach to RTE wherein logical inference is intermingled with large scale database querying.
",5 Conclusion and Discussion,[0],[0]
Acknowledgments This research was supported by the Todai Robot Project at National Institute of Informatics.,5 Conclusion and Discussion,[0],[0]
Dependency-based Compositional Semantics (DCS) is a framework of natural language semantics with easy-to-process structures as well as strict semantics.,abstractText,[0],[0]
"In this paper, we equip the DCS framework with logical inference, by defining abstract denotations as an abstraction of the computing process of denotations in original DCS.",abstractText,[0],[0]
An inference engine is built to achieve inference on abstract denotations.,abstractText,[0],[0]
"Furthermore, we propose a way to generate on-the-fly knowledge in logical inference, by combining our framework with the idea of tree transformation.",abstractText,[0],[0]
Experiments on FraCaS and PASCAL RTE datasets show promising results.,abstractText,[0],[0]
Logical Inference on Dependency-based Compositional Semantics,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 732–739 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
732",text,[0],[0]
"Long short-term memory (LSTM) (Hochreiter and Schmidhuber, 1997) has become the de-facto recurrent neural network (RNN) for learning representations of sequences in NLP.",1 Introduction,[0],[0]
"Like simple recurrent neural networks (S-RNNs) (Elman, 1990), LSTMs are able to learn non-linear functions of arbitrary-length input sequences.",1 Introduction,[0],[0]
"However, they also introduce an additional memory cell to mitigate the vanishing gradient problem (Hochreiter, 1991; Bengio et al., 1994).",1 Introduction,[0],[0]
"This memory is controlled by a mechanism of gates, whose additive connections allow long-distance dependencies to be learned more easily during backpropagation.",1 Introduction,[0],[0]
"While this view is mathematically accurate, in this paper we argue that it does not provide a complete picture of why LSTMs work in practice.
",1 Introduction,[0],[0]
"∗The first two authors contributed equally to this paper.
",1 Introduction,[0],[0]
We present an alternate view to explain the success of LSTMs: the gates themselves are powerful recurrent models that provide more representational power than previously realized.,1 Introduction,[0],[0]
"To demonstrate this, we first show that LSTMs can be seen as a combination of two recurrent models: (1) an S-RNN, and (2) an element-wise weighted sum of the S-RNN’s outputs over time, which is implicitly computed by the gates.",1 Introduction,[0],[0]
"We hypothesize that, for many practical NLP problems, the weighted sum serves as the main modeling component.",1 Introduction,[0],[0]
"The SRNN, while theoretically expressive, is in practice only a minor contributor that clouds the mathematical clarity of the model.",1 Introduction,[0],[0]
"By replacing the S-RNN with a context-independent function of the input, we arrive at a much more restricted class of RNNs, where the main recurrence is via the element-wise weighted sums that the gates are computing.
",1 Introduction,[0],[0]
"We test our hypothesis on NLP problems, where LSTMs are wildly popular at least in part due to their ability to model crucial phenomena such as word order (Adi et al., 2017), syntactic structure (Linzen et al., 2016), and even long-range semantic dependencies (He et al., 2017).",1 Introduction,[0],[0]
"We consider four challenging tasks: language modeling, question answering, dependency parsing, and machine translation.",1 Introduction,[0],[0]
"Experiments show that while removing the gates from an LSTM can severely hurt performance, replacing the S-RNN with a simple linear transformation of the input results in minimal or no loss in model performance.",1 Introduction,[0],[0]
"We also show that, in many cases, LSTMs can be further simplified by removing the output gate, arriving at an even more transparent architecture, where the output is a context-independent function of the weighted sum.",1 Introduction,[0],[0]
"Together, these results suggest that the gates’ ability to compute an element-wise weighted sum, rather than the non-linear transition dynamics of S-RNNs, are the driving force behind LSTM’s success.",1 Introduction,[0],[0]
"LSTMs are typically motivated as an augmentation of simple RNNs (S-RNNs), defined as:
ht = tanh(Whhht−1",2 What Do Memory Cells Compute?,[0],[0]
"+Whxxt + bh) (1)
S-RNNs suffer from the vanishing gradient problem (Hochreiter, 1991; Bengio et al., 1994) due to compounding multiplicative updates of the hidden state.",2 What Do Memory Cells Compute?,[0],[0]
"By introducing a memory cell and an output layer controlled by gates, LSTMs enable shortcuts through which gradients can flow when learning with backpropagation.",2 What Do Memory Cells Compute?,[0],[0]
"This mechanism enables learning of long-distance dependencies while preserving the expressive power of recurrent nonlinear transformations provided by S-RNNs.
",2 What Do Memory Cells Compute?,[0],[0]
"Rather than viewing the gates as simply an auxiliary mechanism to address a learning problem, we present an alternate view that emphasizes their modeling strengths.",2 What Do Memory Cells Compute?,[0],[0]
"We argue that the LSTM should be interpreted as a hybrid of two distinct recurrent architectures: (1) the S-RNN which provides multiplicative connections across timesteps, and (2) the memory cell which provides additive connections across timesteps.",2 What Do Memory Cells Compute?,[0],[0]
"On top of these recurrences, an output layer is included that simply squashes and filters the memory cell at each step.
",2 What Do Memory Cells Compute?,[0],[0]
"Throughout this paper, let {x1, . . .",2 What Do Memory Cells Compute?,[0],[0]
",xn} be the sequence of input vectors, {h1, . . .",2 What Do Memory Cells Compute?,[0],[0]
",hn} be the sequence of output vectors, and {c1, . . .",2 What Do Memory Cells Compute?,[0],[0]
", cn} be the memory cell’s states.",2 What Do Memory Cells Compute?,[0],[0]
"Then, given the basic LSTM definition below, we can formally identify three sub-components.
",2 What Do Memory Cells Compute?,[0],[0]
"c̃t = tanh(Wchht−1 +Wcxxt + bc) (2)
it = σ(Wihht−1 +Wixxt + bi) (3)
ft = σ(Wfhht−1 +Wfxxt + bf )",2 What Do Memory Cells Compute?,[0],[0]
(4) ct = it ◦,2 What Do Memory Cells Compute?,[0],[0]
"c̃t + ft ◦ ct−1 (5) ot = σ(Wohht−1 +Woxxt + bo) (6) ht = ot ◦ tanh(ct) (7)
Content Layer (Equation 2)",2 What Do Memory Cells Compute?,[0],[0]
"We refer to c̃t as the content layer, which is the output of an SRNN.",2 What Do Memory Cells Compute?,[0],[0]
Evaluating the need for multiplicative recurrent connections in the content layer is the focus of this work.,2 What Do Memory Cells Compute?,[0],[0]
"The content layer is passed to the memory cell, which decides which parts of it to store.
",2 What Do Memory Cells Compute?,[0],[0]
Memory Cell (Equations 3-5),2 What Do Memory Cells Compute?,[0],[0]
The memory cell ct is controlled by two gates.,2 What Do Memory Cells Compute?,[0],[0]
"The input gate it controls what part of the content (c̃t) is written to the memory, while the forget gate ft controls
what part of the memory is deleted by filtering the previous state of the memory (ct−1).",2 What Do Memory Cells Compute?,[0],[0]
"Writing to the memory is done by adding the filtered content (it ◦ c̃t) to the retained memory (ft ◦ ct−1).
",2 What Do Memory Cells Compute?,[0],[0]
Output Layer (Equations 6-7),2 What Do Memory Cells Compute?,[0],[0]
"The output layer ht passes the memory cell through a tanh activation function and uses an output gate ot to read selectively from the squashed memory cell.
",2 What Do Memory Cells Compute?,[0],[0]
Our goal is to study how much each of these components contribute to the empirical performance of LSTMs.,2 What Do Memory Cells Compute?,[0],[0]
"In particular, it is worth considering the memory cell in more detail to reveal why it could serve as a standalone powerful model of long-distance context.",2 What Do Memory Cells Compute?,[0],[0]
"It is possible to show that it implicitly computes an element-wise weighted sum of all the previous content layers by expanding the recurrence relation in Equation 5:
ct = it ◦",2 What Do Memory Cells Compute?,[0],[0]
"c̃t + ft ◦ ct−1
= t∑ j=0",2 What Do Memory Cells Compute?,[0],[0]
( ij ◦,2 What Do Memory Cells Compute?,[0],[0]
t∏ k=j+1 fk ) ◦,2 What Do Memory Cells Compute?,[0],[0]
"c̃j
= t∑
j=0
wtj ◦ c̃j
(8)
Each weight wtj is a product of the input gate ij (when its respective input c̃j was read) and every subsequent forget gate fk.",2 What Do Memory Cells Compute?,[0],[0]
"An interesting property of these weights is that, like the gates, they are also soft element-wise binary filters.",2 What Do Memory Cells Compute?,[0],[0]
"The restricted space of element-wise weighted sums allows for easier mathematical analysis, visualization, and perhaps even learnability.",3 Standalone Memory Cells are Powerful,[0],[0]
"However, constrained function spaces are also less expressive, and a natural question is whether these models will work well for NLP problems that involve understanding context.",3 Standalone Memory Cells are Powerful,[0],[0]
We hypothesize that the memory cell (which computes weighted sums) can function as a standalone contextualizer.,3 Standalone Memory Cells are Powerful,[0],[0]
"To test this hypothesis, we present several simplifications of the LSTM’s architecture (Section 3.1), and show on a variety of NLP benchmarks that there is a qualitative performance difference between models that contain a memory cell and those that do not (Section 3.2).",3 Standalone Memory Cells are Powerful,[0],[0]
"We conclude that the content and output layers are relatively minor contributors, and that the space of element-wise weighted sums is sufficiently powerful to compete with fully parameterized LSTMs (Section 3.3).",3 Standalone Memory Cells are Powerful,[0],[0]
"The modeling power of LSTMs is commonly assumed to derive from the S-RNN in the content layer, with the rest of the model acting as a learning aid to bypass the vanishing gradient problem.",3.1 Simplified Models,[0],[0]
"We first isolate the S-RNN by ablating the gates (denoted as LSTM – GATES for consistency).
",3.1 Simplified Models,[0],[0]
"To test whether the memory cell has enough modeling power of its own, we take an LSTM and replace the S-RNN in the content layer from Equation 2 with a simple linear transformation (c̃t = Wcxxt) creating the LSTM – S-RNN model.
",3.1 Simplified Models,[0],[0]
"We further simplify the LSTM by removing the output gate from Equation 7 (ht = tanh(ct)), leaving only the activation function in the output layer (LSTM – S-RNN – OUT).",3.1 Simplified Models,[0],[0]
"After removing the S-RNN and the output gate from the LSTM, the entire ablated model can be written in a modular, compact form:
ht = OUTPUT ( t∑
j=0
wtj ◦ CONTENT(xj) )",3.1 Simplified Models,[0],[0]
"(9)
where the content layer CONTENT(·) and the output layer OUTPUT(·) are both context-independent functions, making the entire model highly constrained and mathematically simpler.",3.1 Simplified Models,[0],[0]
The complexity of modeling contextual information is needed only for computing the weights wtj .,3.1 Simplified Models,[0],[0]
"As we will see in Section 3.2, both of these ablations perform on par with LSTMs on several tasks.
",3.1 Simplified Models,[0],[0]
"Finally, we ablate the hidden state from the gates as well, by computing each gate gt via σ(Wgxxt+bg).",3.1 Simplified Models,[0],[0]
"In this model, the only recurrence is the additive connection in the memory cell; it has no multiplicative recurrent connections at all.",3.1 Simplified Models,[0],[0]
"It can be seen as a type of QRNN (Bradbury et al., 2016) or SRU (Lei et al., 2017b), but for consistency we label it as LSTM – S-RNN – HIDDEN.",3.1 Simplified Models,[0],[0]
"We compare model performance on four NLP tasks, with an experimental setup that is lenient towards LSTMs and harsh towards its simplifications.",3.2 Experiments,[0],[0]
"In each case, we use existing implementations and previously reported hyperparameter settings.",3.2 Experiments,[0],[0]
"Since these settings were tuned for LSTMs, any simplification that performs equally to (or better than) LSTMs under these LSTM-friendly settings provides strong evidence that the ablated component is not a contributing factor.",3.2 Experiments,[0],[0]
"For each
task we also report the mean and standard deviation of 5 runs of the LSTM settings to demonstrate the typical variance observed due to training with different random initializations.
",3.2 Experiments,[0],[0]
"Language Modeling We evaluate the models on the Penn Treebank (PTB) (Marcus et al., 1993) language modeling benchmark.",3.2 Experiments,[0],[0]
We use the implementation of Zaremba et al. (2014) from TensorFlow’s tutorial while replacing any invocation of LSTMs with simpler models.,3.2 Experiments,[0],[0]
"We test two of their configurations: medium and large (Table 1).
",3.2 Experiments,[0],[0]
"Question Answering For question answering, we use two different QA systems on the Stanford question answering dataset (SQuAD) (Rajpurkar et al., 2016): the Bidirectional Attention Flow model (BiDAF) (Seo et al., 2016) and DrQA (Chen et al., 2017).",3.2 Experiments,[0],[0]
"BiDAF contains 3 LSTMs, which are referred to as the phrase layer, the modeling layer, and the span end encoder.",3.2 Experiments,[0],[0]
Our experiments replace each of these LSTMs with their simplified counterparts.,3.2 Experiments,[0],[0]
"We directly use the implementation of BiDAF from AllenNLP (Gardner et al., 2017), and all experiments reuse the existing hyperparameters that were tuned for LSTMs.",3.2 Experiments,[0],[0]
"Likewise, we use an open-source implementation of DrQA1 and replace only the LSTMs, while leaving everything else intact.",3.2 Experiments,[0],[0]
"Table 2 shows the results.
",3.2 Experiments,[0],[0]
"Dependency Parsing For dependency parsing, we use the Deep Biaffine Dependency Parser (Dozat and Manning, 2016), which relies on stacked bidirectional LSTMs to learn contextsensitive word embeddings for determining arcs between a pair of words.",3.2 Experiments,[0],[0]
"We directly use their released implementation, which is evaluated on the Universal Dependencies English Web Treebank v1.3 (Silveira et al., 2014).",3.2 Experiments,[0],[0]
"In our experiments, we use the existing hyperparameters and only replace the LSTMs with the simplified architectures.",3.2 Experiments,[0],[0]
"Table 3 shows the results.
",3.2 Experiments,[0],[0]
"Machine Translation For machine translation, we used OpenNMT (Klein et al., 2017) to train English to German translation models on the multimodal benchmarks from WMT 2016 (used in OpenNMT’s readme file).",3.2 Experiments,[0],[0]
"We use OpenNMT’s default model and hyperparameters, replacing the stacked bidirectional LSTM encoder with the sim-
1https://github.com/hitvoice/DrQA
plified architectures.2 Table 4 shows the results.",3.2 Experiments,[0],[0]
We showed four major ablations of the LSTM.,3.3 Discussion,[0],[0]
"In the S-RNN experiments (LSTM – GATES), we ablate the memory cell and the output layer.",3.3 Discussion,[0],[0]
"In the LSTM – S-RNN and LSTM – S-RNN – OUT experiments, we ablate the S-RNN.",3.3 Discussion,[0],[0]
"In the LSTM – SRNN – HIDDEN, we remove not only the S-RNN in the content layer, but also the S-RNNs in the gates, resulting in a model whose sole recurrence is in the memory cell’s additive connection.
",3.3 Discussion,[0],[0]
"As consistent with previous literature, removing the memory cell degrades performance drastically.",3.3 Discussion,[0],[0]
"In contrast, removing the S-RNN makes little to no difference in the final performance, suggesting that the memory cell alone is largely responsible for the success of LSTMs in NLP.
",3.3 Discussion,[0],[0]
"Even after removing every multiplicative recurrence from the memory cell itself, the model’s performance remains well above the vanilla S-
2For the S-RNN baseline (LSTM – GATES), we had to tune the learning rate to 0.1 because the default value (1.0) resulted in exploding gradients.",3.3 Discussion,[0],[0]
"This is the only case where hyperparameters were modified in all of our experiments.
",3.3 Discussion,[0],[0]
"RNN’s, and falls within the standard deviation of an LSTM’s on some tasks (see Table 3).",3.3 Discussion,[0],[0]
This latter result indicates that the additive recurrent connection in the memory cell – and not the multiplicative recurrent connections in the content layer or in the gates – is the most important computational element in an LSTM.,3.3 Discussion,[0],[0]
"As a corollary, this result also suggests that a weighted sum of context words, while mathematically simple, is a powerful model of contextual information.",3.3 Discussion,[0],[0]
"Attention mechanisms are widely used in the NLP literature to aggregate over a sequence (Cho et al., 2014; Bahdanau et al., 2015) or contextualize tokens within a sequence (Cheng et al., 2016; Parikh et al., 2016) by explicitly computing weighted sums.",4 LSTM as Self-Attention,[0],[0]
"In the previous sections, we demonstrated that LSTMs implicitly compute weighted sums as well, and that this computation is central to their success.",4 LSTM as Self-Attention,[0],[0]
"How, then, are these two computations related, and in what ways do they differ?
",4 LSTM as Self-Attention,[0],[0]
"After simplifying the content layer and removing the output gate (LSTM – S-RNN – OUT), the model’s computation can be expressed as a weighted sum of context-independent functions of the inputs (Equation 9 in Section 3.1).",4 LSTM as Self-Attention,[0],[0]
"This formula abstracts over both the simplified LSTM and the family of attention mechanisms, and through this lens, the memory cell’s computation can be seen as a “cousin” of self-attention.",4 LSTM as Self-Attention,[0],[0]
"In fact, we can also leverage this abstraction to visualize the
simplified LSTM’s weights as is commonly done with attention (see Appendix A for visualization).
",4 LSTM as Self-Attention,[0],[0]
"However, there are three major differences in how the weights wtj are computed.
",4 LSTM as Self-Attention,[0],[0]
"First, the LSTM’s weights are vectors, while attention typically computes scalar weights; i.e. a separate weighted sum is computed for every dimension of the LSTM’s memory cell.",4 LSTM as Self-Attention,[0],[0]
"Multiheaded self-attention (Vaswani et al., 2017) can be seen as a middle ground between the two approaches, allocating a scalar weight for different subsets of the dimensions.
",4 LSTM as Self-Attention,[0],[0]
"Second, the weighted sum is accumulated with a dynamic program.",4 LSTM as Self-Attention,[0],[0]
"This enables a linear rather than quadratic complexity in comparison to selfattention, but reduces the amount of parallel computation.",4 LSTM as Self-Attention,[0],[0]
"This accumulation also creates an inductive bias of attending to nearby words, since the weights can only decrease over time.
",4 LSTM as Self-Attention,[0],[0]
"Finally, attention has a probabilistic interpretation due to the softmax normalization, while the sum of weights in LSTMs can grow up to the sequence length.",4 LSTM as Self-Attention,[0],[0]
"In variants of the LSTM that tie the input and forget gate, such as coupled-gate LSTMs (Greff et al., 2016) and GRUs (Cho et al., 2014), the memory cell instead computes a weighted average with a probabilistic interpretation.",4 LSTM as Self-Attention,[0],[0]
These variants compute locally normalized distributions via a product of sigmoids rather than globally normalized distributions via a single softmax.,4 LSTM as Self-Attention,[0],[0]
"Many variants of LSTMs (Hochreiter and Schmidhuber, 1997) have been previously explored.",5 Related Work,[0],[0]
"These typically consist of a different parameterization of the gates, such as LSTMs with peephole connections (Gers and Schmidhuber, 2000), or a rewiring of the connections, such as GRUs (Cho et al., 2014).",5 Related Work,[0],[0]
"However, these modifications invariably maintain the recurrent content layer.",5 Related Work,[0],[0]
"Even more systematic explorations (Józefowicz et al., 2015; Greff et al., 2016; Zoph and Le, 2017) do not question the importance of the embedded SRNN.",5 Related Work,[0],[0]
"This is the first study to provide applesto-apples comparisons between LSTMs with and without the recurrent content layer.
",5 Related Work,[0],[0]
"Several other recent works have also reported promising results with recurrent models that are vastly simpler than LSTMs, such as quasirecurrent neural networks (Bradbury et al., 2016), strongly-typed recurrent neural networks (Bal-
duzzi and Ghifary, 2016), recurrent additive networks (Lee et al., 2017), kernel neural networks (Lei et al., 2017a), and simple recurrent units (Lei et al., 2017b), making it increasingly apparent that LSTMs are over-parameterized.",5 Related Work,[0],[0]
"While these works indicate an obvious trend, they do not focus on explaining what LSTMs are learning.",5 Related Work,[0],[0]
"In our carefully controlled ablation studies, we propose and evaluate the minimal changes required to test our hypothesis that LSTMs are powerful because they dynamically compute element-wise weighted sums of content layers.",5 Related Work,[0],[0]
We presented an alternate view of LSTMs: they are a hybrid of S-RNNs and a gated model that dynamically computes weighted sums of the S-RNN outputs.,6 Conclusion,[0],[0]
Our experiments investigated whether the S-RNN is a necessary component of LSTMs.,6 Conclusion,[0],[0]
"In other words, are the gates alone as powerful of a model as an LSTM?",6 Conclusion,[0],[0]
"Results across four major NLP tasks (language modeling, question answering, dependency parsing, and machine translation) indicate that LSTMs suffer little to no performance loss when removing the S-RNN.",6 Conclusion,[0],[0]
This provides evidence that the gating mechanism is doing the heavy lifting in modeling context.,6 Conclusion,[0],[0]
"We further ablate the recurrence in each gate and find that this incurs only a modest drop in performance, indicating that the real modeling power of LSTMs stems from their ability to compute element-wise weighted sums of context-independent functions of their inputs.
",6 Conclusion,[0],[0]
This realization allows us to mathematically relate LSTMs and other gated RNNs to attention-based models.,6 Conclusion,[0],[0]
"Casting an LSTM as a dynamically-computed attention mechanism enables the visualization of how context is used at every timestep, shedding light on the inner workings of the relatively opaque LSTM.",6 Conclusion,[0],[0]
"The research was supported in part by DARPA under the DEFT program (FA8750-13-2-0019), the ARO (W911NF-16-1-0121), the NSF (IIS1252835, IIS-1562364), gifts from Google, Tencent, and Nvidia, and an Allen Distinguished Investigator Award.",Acknowledgements,[0],[0]
"We also thank Yoav Goldberg, Benjamin Heinzerling, Tao Lei, and the UW NLP group for helpful conversations and comments on the work.",Acknowledgements,[0],[0]
"Given the empirical evidence that LSTMs are effectively learning weighted sums of the content layers, it is natural to investigate what weights the model learns in practice.",A Weight Visualization,[0],[0]
"Using the more mathematically transparent simplification of LSTMs, we can visualize the weights wtj that are placed on every input j at every timestep t (see Equation 9).
",A Weight Visualization,[0],[0]
"Unlike attention mechanisms, these weights are vectors rather than scalar values.",A Weight Visualization,[0],[0]
"Therefore, we can only provide a coarse-grained visualization of the weights by rendering their L2-norm, as shown in Table 5.",A Weight Visualization,[0],[0]
"In the visualization, each column indicates the word represented by the weighted sum, and each row indicates the word over which the weighted sum is computed.",A Weight Visualization,[0],[0]
Dark horizontal streaks indicate the duration for which a word was remembered.,A Weight Visualization,[0],[0]
"Unsurprisingly, the weights on the diagonal are always the largest since it indicates the weight of the current word.",A Weight Visualization,[0],[0]
"More interesting task-specific patterns emerge when inspecting the off-diagonals that represent the weight on the context words.
",A Weight Visualization,[0],[0]
The first visualization uses the language model.,A Weight Visualization,[0],[0]
"Due to the language modeling setup, there are only non-zero weights on the current or previous words.",A Weight Visualization,[0],[0]
"We find that the common function words are quickly forgotten, while infrequent words that
signal the topic are remembered over very long distances.
",A Weight Visualization,[0],[0]
The second visualization uses the dependency parser.,A Weight Visualization,[0],[0]
"In this setting, since the recurrent architectures are bidirectional, there are non-zero weights on all words in the sentence.",A Weight Visualization,[0],[0]
"The top-right triangle indicates weights from the forward direction, and the bottom-left triangle indicates from the backward direction.",A Weight Visualization,[0],[0]
"For syntax, we see a significantly different pattern.",A Weight Visualization,[0],[0]
Function words that are useful for determining syntax are more likely to be remembered.,A Weight Visualization,[0],[0]
"Weights on head words are also likely to persist until the end of a constituent.
",A Weight Visualization,[0],[0]
"This illustration provides only a glimpse into what the model is capturing, and perhaps future, more detailed visualizations that take the individual dimensions into account can provide further insight into what LSTMs are learning in practice.
739
Language model weights Dependency parser weights
The hym n was sun g at my first inau gura
l
chu rch serv ice as gov erno
r
The hymn
was
sung
at
my first inaugural
church service
as governor
The hym n was sun g at my first inau gura
l
chu rch serv ice as gov erno
r
The hymn
was
sung
at
my first inaugural
church service
as governor
US troo",A Weight Visualization,[0],[0]
ps ther e clas hed with gue rrilla s in a figh t that left one Iraq,A Weight Visualization,[0],[0]
"i dea d
US troops there clashed with guerrillas in a
fight that left one Iraqi dead
US troo ps ther e clas",A Weight Visualization,[0],[0]
hed with gue rrilla s in a figh t that left one Iraq,A Weight Visualization,[0],[0]
"i dea d
US troops there clashed with guerrillas in a
fight that left one Iraqi dead",A Weight Visualization,[0],[0]
LSTMs were introduced to combat vanishing gradients in simple RNNs by augmenting them with gated additive recurrent connections.,abstractText,[0],[0]
We present an alternative view to explain the success of LSTMs: the gates themselves are versatile recurrent models that provide more representational power than previously appreciated.,abstractText,[0],[0]
"We do this by decoupling the LSTM’s gates from the embedded simple RNN, producing a new class of RNNs where the recurrence computes an element-wise weighted sum of context-independent functions of the input.",abstractText,[0],[0]
"Ablations on a range of problems demonstrate that the gating mechanism alone performs as well as an LSTM in most settings, strongly suggesting that the gates are doing much more in practice than just alleviating vanishing gradients.",abstractText,[0],[0]
Long Short-Term Memory as a Dynamically Computed Element-wise Weighted Sum,title,[0],[0]
"Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1197–1206, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.",text,[0],[0]
Word segmentation is a fundamental task for Chinese language processing.,1 Introduction,[0],[0]
"In recent years, Chinese word segmentation (CWS) has undergone great development.",1 Introduction,[0],[0]
"The popular method is to regard word segmentation task as a sequence labeling problem (Xue, 2003; Peng et al., 2004).",1 Introduction,[0],[0]
"The goal of sequence labeling is to assign labels to all elements in a sequence, which can be handled with supervised learning algorithms such as Maximum Entropy (ME) (Berger et al., 1996) and Conditional RandomFields (CRF) (Lafferty et al., 2001).",1 Introduction,[0],[0]
"However, the ability of these models is restricted by the design of features, and the number of features could be so large that the result models are too large for practical use and prone to overfit on training corpus.",1 Introduction,[0],[0]
"Recently, neural network models have increasingly used for NLP tasks for their ability to minimize the effort in feature engineering (Collobert
∗Corresponding author.
",1 Introduction,[0],[0]
"et al., 2011; Socher et al., 2013; Turian et al., 2010; Mikolov et al., 2013b; Bengio et al., 2003).",1 Introduction,[0],[0]
Collobert et al. (2011) developed the SENNA system that approaches or surpasses the state-of-theart systems on a variety of sequence labeling tasks for English.,1 Introduction,[0],[0]
"Zheng et al. (2013) applied the architecture of Collobert et al. (2011) to Chinese word segmentation and POS tagging, also he proposed a perceptron style algorithm to speed up the training process with negligible loss in performance.",1 Introduction,[0],[0]
"Pei et al. (2014) models tag-tag interactions, tagcharacter interactions and character-character interactions based on Zheng et al. (2013).",1 Introduction,[0],[0]
Chen et al. (2015) proposed a gated recursive neural network (GRNN) to explicitly model the combinations of the characters for Chinese word segmentation task.,1 Introduction,[0],[0]
Each neuron in GRNN can be regarded as a different combination of the input characters.,1 Introduction,[0],[0]
"Thus, the whole GRNN has an ability to simulate the design of the sophisticated features in traditional methods.",1 Introduction,[0],[0]
"Despite of their success, a limitation of them is that their performances are easily affected by the size of the context window.",1 Introduction,[0],[0]
"Intuitively, many words are difficult to segment based on the local information only.",1 Introduction,[0],[0]
"For example, the segmentation of the following sentence needs the information of the long distance collocation.",1 Introduction,[0],[0]
冬天 (winter)，能 (can) 穿 (wear) 多少 (amount) 穿 (wear) 多少 (amount)；夏天 (summer)，能 (can)穿 (wear)多 (more)少 (little)穿 (wear)多 (more)少 (little)。,1 Introduction,[0],[0]
"Without the word “夏天 (summer)” or “冬天 (winter)”, it is difficult to segment the phrase “能 穿多少穿多少”.",1 Introduction,[0],[0]
"Therefore, we usually need utilize the non-local information for more accurate word segmentation.",1 Introduction,[0],[0]
"However, it does not work by simply increasing the context window size.",1 Introduction,[0],[0]
"As reported in (Zheng et al., 2013), the performance drops smoothly when the window size is larger than 3.",1 Introduction,[0],[0]
"The reason is that the number of its parameters is so large that the trained network has
1197
overfitted on training data.",1 Introduction,[0],[0]
"Therefore, it is necessary to capture the potential long-distance dependencies without increasing the size of the context window.",1 Introduction,[0],[0]
"In order to address this problem, we propose a neural model based on Long Short-Term Memory Neural Network (LSTM) (Hochreiter and Schmidhuber, 1997) that explicitly model the previous information by exploiting input, output and forget gates to decide how to utilize and update the memory of pervious information.",1 Introduction,[0],[0]
"Intuitively, if the LSTM unit detects an important feature from an input sequence at early stage, it easily carries this information (the existence of the feature) over a long distance, hence, capturing the potential useful long-distance information.",1 Introduction,[0],[0]
"We evaluate our model on three popular benchmark datasets (PKU, MSRA and CTB6), and the experimental results show that our model achieves the state-of-the-art performance with the smaller context window size (0,2).",1 Introduction,[0],[0]
"The contributions of this paper can be summarized as follows.
",1 Introduction,[0],[0]
• We first introduce the LSTM neural network for Chinese word segmentation.,1 Introduction,[0],[0]
"The LSTM can capture potential long-distance dependencies and keep the previous useful information in memory, which avoids the limit of the size of context window.
",1 Introduction,[0],[0]
•,1 Introduction,[0],[0]
"Although there are relatively few researches of applying dropout method to the LSTM, we investigate several dropout strategies and find that dropout is also effective to avoid the overfitting of the LSTM.
",1 Introduction,[0],[0]
"• Despite Chinese word segmentation being a specific case, our model can be easily generalized and applied to the other sequence labeling tasks.",1 Introduction,[0],[0]
Chinese word segmentation is usually regarded as character-based sequence labeling.,2 Neural Model for Chinese Word Segmentation,[0],[0]
"Each character is labeled as one of {B, M, E, S} to indicate the segmentation.",2 Neural Model for Chinese Word Segmentation,[0],[0]
"{B, M, E} represent Begin, Middle, End of a multi-character segmentation respectively, and S represents a Single character segmentation.",2 Neural Model for Chinese Word Segmentation,[0],[0]
"The neural model is usually characterized by three specialized layers: (1) a character embedding
layer; (2) a series of classical neural network layers and (3) tag inference layer.",2 Neural Model for Chinese Word Segmentation,[0],[0]
An illustration is shown in Figure 1.,2 Neural Model for Chinese Word Segmentation,[0],[0]
The most common tagging approach is based on a local window.,2 Neural Model for Chinese Word Segmentation,[0],[0]
The window approach assumes that the tag of a character largely depends on its neighboring characters.,2 Neural Model for Chinese Word Segmentation,[0],[0]
"Given an input sentence c(1:n), a window of size k slides over the sentence from character c(1) to c(n), where n is the length of the sentence.",2 Neural Model for Chinese Word Segmentation,[0],[0]
"As shown in Figure 1, for each character c(t)(1 ≤",2 Neural Model for Chinese Word Segmentation,[0],[0]
"t ≤ n), the context characters (c(t−2),c(t−1),c(t),c(t+1),c(t+2)) are fed into the lookup table layer when the window size k is 5.",2 Neural Model for Chinese Word Segmentation,[0],[0]
"The characters exceeding the sentence boundaries are mapped to one of two special symbols, namely “start” and “end” symbols.",2 Neural Model for Chinese Word Segmentation,[0],[0]
"The character embeddings extracted by the lookup table layer are then concatenated into a single vector x(t) ∈ RH1 , where H1 = k × d is the size of layer 1.",2 Neural Model for Chinese Word Segmentation,[0],[0]
Then x(t) is fed into the next layer which performs linear transformation followed by an element-wise activation function g such as sigmoid function σ(x) =,2 Neural Model for Chinese Word Segmentation,[0],[0]
(1+e−x)−1 and hyperbolic tangent function ϕ(x),2 Neural Model for Chinese Word Segmentation,[0],[0]
"= ex−e−x
ex+e−x here.
",2 Neural Model for Chinese Word Segmentation,[0],[0]
"h(t) = g(W1x(t) + b1), (1)
whereW1 ∈",2 Neural Model for Chinese Word Segmentation,[0],[0]
"RH2×H1 , b1 ∈ RH2 , h(t) ∈ RH2 .",2 Neural Model for Chinese Word Segmentation,[0],[0]
H2 is a hyper-parameter which indicates the number of hidden units in layer 2.,2 Neural Model for Chinese Word Segmentation,[0],[0]
"Given a set of tags T of size |T |, a similar linear transformation is performed except that no non-linear function is followed:
y(t)",2 Neural Model for Chinese Word Segmentation,[0],[0]
"= W2h(t) + b2, (2)
where W2 ∈ R|T |×H2 , b2 ∈ R|T |. y(t) ∈ R|T",2 Neural Model for Chinese Word Segmentation,[0],[0]
| is the score vector for each possible tag.,2 Neural Model for Chinese Word Segmentation,[0],[0]
"In Chinese word segmentation, the most prevalent tag set T j T is {B, M, E, S} as mentioned above.",2 Neural Model for Chinese Word Segmentation,[0],[0]
"To model the tag dependency, a transition score Aij is introduced to measure the probability of jumping from tag i ∈ T to tag j ∈ T (Collobert et al., 2011).",2 Neural Model for Chinese Word Segmentation,[0],[0]
"Although this model works well for Chinese word segmentation and other sequence labeling tasks, it just utilizes the information of context of a limited-length window.",2 Neural Model for Chinese Word Segmentation,[0],[0]
Some useful long distance information is neglected.,2 Neural Model for Chinese Word Segmentation,[0],[0]
"In this section, we introduce the LSTM neural network for Chinese word segmentation.",3 Long Short-Term Memory Neural Network for Chinese Word Segmentation,[0],[0]
"The first step of using neural network to process symbolic data is to represent them into distributed vectors, also called embeddings (Bengio et al., 2003; Collobert and Weston, 2008).",3.1 Character Embeddings,[0],[0]
"Formally, in Chinese word segmentation task, we have a character dictionary C of size |C|.",3.1 Character Embeddings,[0],[0]
"Unless otherwise specified, the character dictionary is extracted from the training set and unknown characters are mapped to a special symbol that is not used elsewhere.",3.1 Character Embeddings,[0],[0]
Each character c ∈ C is represented as a real-valued vector (character embedding),3.1 Character Embeddings,[0],[0]
vc ∈ Rd where d is the dimensionality of the vector space.,3.1 Character Embeddings,[0],[0]
The character embeddings are then stacked into an embeddingmatrixM ∈ Rd×|C|.,3.1 Character Embeddings,[0],[0]
"For a character c ∈ C, the corresponding character embedding vc ∈ Rd is retrieved by the lookup table layer.",3.1 Character Embeddings,[0],[0]
And the lookup table layer can be regarded as a simple projection layer where the character embedding for each context character is achieved by table lookup operation according to its index.,3.1 Character Embeddings,[0],[0]
"The long short term memory neural network (LSTM) (Hochreiter and Schmidhuber, 1997) is an extension of the recurrent neural network (RNN).
",3.2 LSTM,[0],[0]
The RNN has recurrent hidden states whose output at each time is dependent on that of the previous time.,3.2 LSTM,[0],[0]
"More formally, given a sequence x(1:n) =",3.2 LSTM,[0],[0]
"(x(1), x(2), . . .",3.2 LSTM,[0],[0]
", x(t), . . .",3.2 LSTM,[0],[0]
", x(n)), the RNN updates its recurrent hidden state h(t) by
h(t) = g(Uh(t−1) +Wx(t) + b), (3)
where g is a nonlinear function as mentioned above.",3.2 LSTM,[0],[0]
"Though RNN has been proven successful on many tasks such as speech recognition (Vinyals et al., 2012), language modeling (Mikolov et al., 2010) and text generation (Sutskever et al., 2011), it can be difficult to train them to learn longterm dynamics, likely due in part to the vanishing and exploding gradient problem (Hochreiter and Schmidhuber, 1997).",3.2 LSTM,[0],[0]
The LSTM provides a solution by incorporating memory units that allow the network to learn when to forget previous information and when to update the memory cells given new information.,3.2 LSTM,[0],[0]
"Thus, it is a natural choice to apply LSTM neural network to word segmentation task since the LSTM neural network can learn from data with long range temporal dependencies (memory) due to the considerable time lag between the inputs and their corresponding outputs.",3.2 LSTM,[0],[0]
"In addition, the LSTM has been applied successfully in many NLP tasks, such as text classification (Liu et al., 2015) and machine translation (Sutskever et al., 2014).",3.2 LSTM,[0],[0]
The core of the LSTM model is a memory cell c encoding memory at every time step of what inputs have been observed up to this step (see Figure 2) .,3.2 LSTM,[0],[0]
"The behavior of the cell is controlled by three “gates”, namely input gate i, forget gate f and output gate o.",3.2 LSTM,[0],[0]
"The operations on gates are defined as element-wise multiplications, thus gate can either scale the input value if the gate is non-zero vector or omit input if the gate is zero vector.",3.2 LSTM,[0],[0]
The output of output gate will be fed into the next time step t + 1 as previous hidden state and input of upper layer of neural network at current time step t.,3.2 LSTM,[0],[0]
"The definitions of the gates, cell update and output are as follows:
i(t) = σ(Wixx(t) + Wihh(t−1) + Wicc(t−1)), (4) f(t) = σ(Wfxx(t) + Wfhh(t−1) + Wfcc(t−1)), (5) c(t) = f(t) ⊙ c(t−1) + i(t) ⊙ ϕ(Wcxx(t) + Wchh(t−1)), (6) o(t) = σ(Woxx(t)",3.2 LSTM,[0],[0]
"+Wohh(t−1) +Wocc(t)), (7)
h(t) = o(t) ⊙ ϕ(c(t)), (8)
whereσ andϕ are the logistic sigmoid function and hyperbolic tangent function respectively; i(t), f(t), o(t) and c(t) are respectively the input gate, forget gate, output gate, and memory cell activation vector at time step t, all of which have the same size as the hidden vector h(t) ∈ RH2 ; the parameter matrices W s with different subscripts are all square matrices; ⊙ denotes the element-wise product of the vectors.",3.2 LSTM,[0],[0]
"Note that Wic, Wfc and Woc are diagonal matrices.",3.2 LSTM,[0],[0]
"To fully utilize the LSTM, we propose four different structures of neural network to select the effective features via memory units.",3.3 LSTM Architectures for Chinese Word Segmentation,[0],[0]
"Figure 3 illustrates our proposed architectures.
",3.3 LSTM Architectures for Chinese Word Segmentation,[0],[0]
LSTM-1,3.3 LSTM Architectures for Chinese Word Segmentation,[0],[0]
The LSTM-1 simply replace the hidden neurons in Eq.,3.3 LSTM Architectures for Chinese Word Segmentation,[0],[0]
"(1) with LSTM units (See Figure 3a).
",3.3 LSTM Architectures for Chinese Word Segmentation,[0],[0]
The input of the LSTM unit is from a window of context characters.,3.3 LSTM Architectures for Chinese Word Segmentation,[0],[0]
"For each character, c(t), (1 ≤ t ≤ n), the input of the LSTM unit x(t),
x(t) = v(t−k1)c ⊕ · · · ⊕ v(t+k2)c , (9)
is concatenated from character embeddings of c(t−k1):(t+k2), where k1 and k2 represent the numbers of characters from left and right contexts respectively.",3.3 LSTM Architectures for Chinese Word Segmentation,[0],[0]
"The output of the LSTM unit is used in final inference function (Eq. (11) ) after a linear transformation.
",3.3 LSTM Architectures for Chinese Word Segmentation,[0],[0]
LSTM-2,3.3 LSTM Architectures for Chinese Word Segmentation,[0],[0]
"The LSTM-2 can be created by stacking multiple LSTM hidden layers on top of each other, with the output sequence of one layer forming the input sequence for the next (See Figure 3b).",3.3 LSTM Architectures for Chinese Word Segmentation,[0],[0]
Here we use two LSTM layers.,3.3 LSTM Architectures for Chinese Word Segmentation,[0],[0]
"Specifically, input of the upper LSTM layer takes h(t) from the lower LSTM layer without any transformation.",3.3 LSTM Architectures for Chinese Word Segmentation,[0],[0]
"The input of the first layer is same to LSTM-1, and the output of the second layer is as same operation as LSTM-1.
",3.3 LSTM Architectures for Chinese Word Segmentation,[0],[0]
"LSTM-3 The LSTM-3 is a extension of LSTM1, which adopts a local context of LSTM layer as input of the last layer (See Figure 3c).",3.3 LSTM Architectures for Chinese Word Segmentation,[0],[0]
"For each time step t, we concatenate the outputs of a window of the LSTM layer into a vector ĥ(t),
ĥ(t) = h(t−m1) ⊕ · · · ⊕ h(t+m2), (",3.3 LSTM Architectures for Chinese Word Segmentation,[0],[0]
"10)
wherem1 andm2 represent the lengths of time lags before and after current time step.",3.3 LSTM Architectures for Chinese Word Segmentation,[0],[0]
"Finally, ĥ(t) is used in final inference function (Eq. (11) )",3.3 LSTM Architectures for Chinese Word Segmentation,[0],[0]
"after a linear transformation.
LSTM-4 The LSTM-4 (see Figure 3d) is a mixture of the LSTM-2 and LSTM-3, which consists of two LSTM layers.",3.3 LSTM Architectures for Chinese Word Segmentation,[0],[0]
The output sequence of the lower LSTM layer forms the input sequence of the upper LSTM layer.,3.3 LSTM Architectures for Chinese Word Segmentation,[0],[0]
The final layer adopts a local context of upper LSTM layer as input.,3.3 LSTM Architectures for Chinese Word Segmentation,[0],[0]
"To model the tag dependency, previous neural network models (Collobert et al., 2011; Zheng et al., 2013; Pei et al., 2014) introduced the transition score Aij for measuring the probability of jumping from tag i ∈ T to tag j ∈ T .",3.4 Inference at Sentence Level,[0],[0]
"For a input sentence c(1:n) with a tag sequence y(1:n), a sentencelevel score is then given by the sum of tag transition scores and network tagging scores:
s(c(1:n), y(1:n), θ) = n∑ t=1 ( Ay(t−1)y(t)",3.4 Inference at Sentence Level,[0],[0]
"+ y (t) y(t) ) , (11)
where y(t) y(t) indicates the score of tag y(t), and y(t) is computed by the network as in Eq.",3.4 Inference at Sentence Level,[0],[0]
(2).,3.4 Inference at Sentence Level,[0],[0]
"The parameter set of our model θ = {M,A,Wic,Wfc,Woc,Wix,Wfx,Wox,Wih,Wfh, Woh,Wcx,Wch}.",3.4 Inference at Sentence Level,[0],[0]
We use the Max-Margin criterion to train our model.,4.1 Max-Margin criterion,[0],[0]
"Intuitively, the Max-Margin criterion provides an alternative to probabilistic, likelihood based estimation methods by concentrating directly on the robustness of the decision boundary of a model (Taskar et al., 2005).",4.1 Max-Margin criterion,[0],[0]
We use Y (xi) to denote the set of all possible tag sequences for a given sentence xi and the correct tag sequence for xi is yi.,4.1 Max-Margin criterion,[0],[0]
The parameter set of our model is θ.,4.1 Max-Margin criterion,[0],[0]
"We first define a structured margin loss ∆(yi, ŷ) for predicted tag sequence ŷ:
∆(yi, ŷ)",4.1 Max-Margin criterion,[0],[0]
"= n∑ t η1{y(t)i ̸= ŷ(t)}, (12)
where n is the length of sentence xi and η is a discount parameter.",4.1 Max-Margin criterion,[0],[0]
The loss is proportional to the number of characters with incorrect tags in the proposed tag sequence.,4.1 Max-Margin criterion,[0],[0]
"For a given training instance (xi, yi),the predicted tag sequence ŷi ∈ Y (xi) is the one with the highest score:
ŷi = argmax y∈Y (xi) s(xi, y, θ), (13)
where the function s(·) is sentence-level score and defined in equation (11).",4.1 Max-Margin criterion,[0],[0]
"Given a set of training setD, the regularized objective function is the loss function J(θ) including
a l2-norm term:
J(θ)",4.1 Max-Margin criterion,[0],[0]
"= 1 |D| ∑ (xi,yi)∈D li(θ)",4.1 Max-Margin criterion,[0],[0]
"+ λ 2 ∥θ∥22, (14)
where li(θ) = max(0, s(xi, ŷi, θ) + ∆(yi, ŷi)",4.1 Max-Margin criterion,[0],[0]
"− s(xi, yi, θ)).",4.1 Max-Margin criterion,[0],[0]
"To minimize J(θ), we use a generalization of gradient descent called subgradient method (Ratliff et al., 2007) which computes a gradientlike direction.",4.1 Max-Margin criterion,[0],[0]
"Following (Socher et al., 2013), we also use the diagonal variant of AdaGrad (Duchi et al., 2011) with minibatchs to minimize the objective.",4.1 Max-Margin criterion,[0],[0]
"The parameter update for the i-th parameter θt,i at time step t is as follows:
θt,i = θt−1,i − α√∑t τ=1 g 2 τ,i gt,i, (15)
where α is the initial learning rate and gτ ∈ R|θi| is the subgradient at time step τ for parameter θi.",4.1 Max-Margin criterion,[0],[0]
"In addition, the process of back propagation is followd Hochreiter and Schmidhuber (1997).",4.1 Max-Margin criterion,[0],[0]
"Dropout is one of prevalent methods to avoid overfitting in neural networks (Srivastava et al., 2014).",4.2 Dropout,[0],[0]
"When dropping a unit out, we temporarily remove it from the network, alongwith all its incoming and outgoing connections.",4.2 Dropout,[0],[0]
"In the simplest case, each unit is omitted with a fixed probability p independent of other units, namely dropout rate, where p is also chosen on development set.",4.2 Dropout,[0],[0]
"We use three popular datasets, PKU, MSRA and CTB6, to evaluate our model.",5.1 Datasets,[0],[0]
"The PKU
and MSRA data are provided by the second International Chinese Word Segmentation Bakeoff (Emerson, 2005), and CTB6 is from Chinese TreeBank 6.0 (LDC2007T36) (Xue et al., 2005), which is a segmented, part-of-speech tagged and fully bracketed corpus in the constituency formalism.",5.1 Datasets,[0],[0]
These datasets are commonly used by previous state-of-the-art models and neural network models.,5.1 Datasets,[0],[0]
"In addition, we use the first 90% sentences of the training data as training set and the rest 10%
sentences as development set for PKU and MSRA datasets.",5.1 Datasets,[0],[0]
"For CTB6 dataset, we divide the training, development and test sets according to (Yang and Xue, 2012)",5.1 Datasets,[0],[0]
All datasets are preprocessed by replacing the Chinese idioms and the continuous English characters and digits with a unique flag.,5.1 Datasets,[0],[0]
"For evaluation, we use the standard bake-off scoring program to calculate precision, recall, F1score and out-of-vocabulary (OOV) word recall.",5.1 Datasets,[0],[0]
Hyper-parameters of neural model impact the performance of the algorithm significantly.,5.2 Hyper-parameters,[0],[0]
"According to experiment results, we choose the hyperparameters of our model as showing in Figure 1.",5.2 Hyper-parameters,[0],[0]
The minibatch size is set to 20.,5.2 Hyper-parameters,[0],[0]
"Generally, the number of hidden units has a limited impact on the performance as long as it is large enough.",5.2 Hyper-parameters,[0],[0]
We found that 150 is a good trade-off between speed and model performance.,5.2 Hyper-parameters,[0],[0]
The dimensionality of character embedding is set to 100 which achieved the best performance.,5.2 Hyper-parameters,[0],[0]
All these hyperparameters are chosen according to their average performances on three development sets.,5.2 Hyper-parameters,[0],[0]
"For the context lengths (k1, k2) and dropout strategy, we give detailed analysis in next section.",5.2 Hyper-parameters,[0],[0]
"We first investigate the different dropout strategies, including dropout at different layers and with different dropout rate p.",5.3 Dropout and Context Length,[0],[0]
"As a result, we found that it is a good trade-off between speed and model performance to drop the input layer only with dropout rate pinput = 0.2.",5.3 Dropout and Context Length,[0],[0]
"However, it does not show any significant improvement to dropout on hidden LSTM layers.
",5.3 Dropout and Context Length,[0],[0]
"Due to space constraints, we just give the performances of LSTM-1 model on PKU dataset with different context lengths (k1, k2) and dropout rates in Figure 4 and Table 2.",5.3 Dropout and Context Length,[0],[0]
"From Figure 4, we can see that 20% dropout converges slightly slower than the one without dropout, but avoids overfitting.",5.3 Dropout and Context Length,[0],[0]
50% or higher dropout rate seems to be underfitting since its training error is also high.,5.3 Dropout and Context Length,[0],[0]
"Table 2 shows that the LSTM-1 model performs consistently well with the different context length, but the LSTM-1 model with short context length saves computational resource, and gets more efficiency.",5.3 Dropout and Context Length,[0],[0]
"At the meanwhile, the LSTM-1 model with context length (0,2) can receive the same or better performance than that with context length (2,2), which shows that the LSTM model can well model the pervious information, and it is more robust for its insensitivity of window size variation.",5.3 Dropout and Context Length,[0],[0]
"We employ context length (0,2) with the 20% dropout rate in the following experiments to balance the tradeoff between accuracy and efficiency.",5.3 Dropout and Context Length,[0],[0]
We also evaluate the our four proposed models with the hyper-parameter settings in Table 1.,5.4 Model Selection,[0],[0]
"For LSTM-3 and LSTM-4 models, the context window length of top LSTM layer is set to (2,0).",5.4 Model Selection,[0],[0]
"For LSTM-2 and LSTM-4,the number of upper hidden LSTM layer is set to 100.",5.4 Model Selection,[0],[0]
We use PKU dataset to select the best model.,5.4 Model Selection,[0],[0]
Figure 5 shows the results of the fourmodels on PKUdevelopment set from first epoch to 60-th epoch.,5.4 Model Selection,[0],[0]
"We see that the LSTM-1 is the fastest one to converge and achieves the best
performance.",5.4 Model Selection,[0],[0]
"The LSTM-2 (two LSTM layers) get worse, which shows the performance seems not to benefit from deep model.",5.4 Model Selection,[0],[0]
"The LSTM-3 and LSTM-4 models do not converge, which could be caused by the complexity of models.",5.4 Model Selection,[0],[0]
"The results on PKU test set are also shown in Table 3, which again show that the LSTM-1 achieves the best performance.",5.4 Model Selection,[0],[0]
"Therefore, in the rest of the paper we will give more analysis based on the LSTM-1with hyper-parameter settings as showing in Table 1.",5.4 Model Selection,[0],[0]
"In this section, we give comparisons of the LSTM1 with pervious neural models and state-of-the-art methods on the PKU, MSRA and CTB6 datasets.",5.5 Experiment Results,[0],[0]
"We first compare our model with two neural models (Zheng et al., 2013; Pei et al., 2014) on Chinese word segmentation task with random initialized character embeddings.",5.5 Experiment Results,[0],[0]
"As showing in Table 4, the performance is boosted significantly by utilizing LSTM unit.",5.5 Experiment Results,[0],[0]
"And more notably, our window size of the context characters is set to (0,2), while the size of the other models is (2,2).",5.5 Experiment Results,[0],[0]
Previous works found that the performance can be improved by pre-training the character embeddings on large unlabeled data.,5.5 Experiment Results,[0],[0]
"We use word2vec 1 (Mikolov et al., 2013a) toolkit to pre-train the character embeddings on the Chinese Wikipedia corpus.",5.5 Experiment Results,[0],[0]
The obtained embeddings are used to initialize the character lookup table instead of random initialization.,5.5 Experiment Results,[0],[0]
"Inspired by (Pei et al., 2014), we also utilize bigram character embeddings which is simply initialized as the average of embeddings of two consecutive characters.",5.5 Experiment Results,[0],[0]
Table 5 shows the performances with additional pre-trained and bigram character embeddings.,5.5 Experiment Results,[0],[0]
"Again, the performances boost significantly as a result.",5.5 Experiment Results,[0],[0]
"Moreover, when we use bigram embeddings only, which means we do close test without pre-training the embeddings on other extra corpus, our model still perform competitively compared
1http://code.google.com/p/word2vec/
with previous neural models with pre-trained embedding and bigram embeddings.",5.5 Experiment Results,[0],[0]
Table 6 lists the performances of our model as well as previous state-of-the-art systems.,5.5 Experiment Results,[0],[0]
"(Zhang and Clark, 2007) is a word-based segmentation algorithm, which exploit features of complete words, while the rest of the list are character-based word segmenters, whose features are mostly extracted from a window of characters.",5.5 Experiment Results,[0],[0]
"Moreover, some systems (such as Sun and Xu (2011) and Zhang et al. (2013)) also exploit kinds of extra information such as unlabeled data or other knowledge.",5.5 Experiment Results,[0],[0]
"Despite our model only uses simple bigram features, it outperforms previous state-of-the-art models which use more complex features.",5.5 Experiment Results,[0],[0]
"Since that we do not focus on the speed of the algorithm in this paper, we do not optimize the speed
a lot.",5.5 Experiment Results,[0],[0]
"On PKU dataset, it takes about 3 days to train themodel (last row of Table 5) usingCPU (Intel(R) Xeon(R) CPU E5-2665 @ 2.40GHz) only.",5.5 Experiment Results,[0],[0]
All implementation is based on Python.,5.5 Experiment Results,[0],[0]
Chinese word segmentation has been studied with considerable efforts in the NLP community.,6 Related Work,[0],[0]
"The most popular word segmentation methods is based on sequence labeling (Xue, 2003).",6 Related Work,[0],[0]
"Recently, researchers have tended to explore neural network based approaches (Collobert et al., 2011) to reduce efforts of feature engineering (Zheng et al., 2013; Pei et al., 2014; Qi et al., 2014; Chen et al., 2015).",6 Related Work,[0],[0]
The features of all these methods are extracted from a local context and neglect the long distance information.,6 Related Work,[0],[0]
"However, previous information is also crucial for word segmentation.",6 Related Work,[0],[0]
Our model adopts the LSTM to keep the previous important information in memory and avoids the limitation of ambiguity caused by limit of the size of context window.,6 Related Work,[0],[0]
"In this paper, we use LSTM to explicitly model the previous information for Chinese word segmentation, which can well model the potential long-
distance features.",7 Conclusion,[0],[0]
"Though our model use smaller context window size (0,2), it still outperforms the previous neural models with context window size (2,2).",7 Conclusion,[0],[0]
"Besides, our model can also be easily generalized and applied to other sequence labeling tasks.",7 Conclusion,[0],[0]
"Although our model achieves state-of-the-art performance, it only makes use of previous context.",7 Conclusion,[0],[0]
The future context is also useful for Chinese word segmentation.,7 Conclusion,[0],[0]
"In future work, wewould like to adopt the bidirectional recurrent neural network (Schuster and Paliwal, 1997) to process the sequence in both directions.",7 Conclusion,[0],[0]
We would like to thank the anonymous reviewers for their valuable comments.,Acknowledgments,[0],[0]
"This work was partially funded by the National Natural Science Foundation of China (61472088, 61473092), National High Technology Research and Development Program of China (2015AA015408), Shanghai Science and Technology Development Funds (14ZR1403200).",Acknowledgments,[0],[0]
"Currently most of state-of-the-art methods for Chinese word segmentation are based on supervised learning, whose features aremostly extracted from a local context.",abstractText,[0],[0]
Thesemethods cannot utilize the long distance information which is also crucial for word segmentation.,abstractText,[0],[0]
"In this paper, we propose a novel neural network model for Chinese word segmentation, which adopts the long short-term memory (LSTM) neural network to keep the previous important information inmemory cell and avoids the limit of window size of local context.",abstractText,[0],[0]
"Experiments on PKU, MSRA and CTB6 benchmark datasets show that our model outperforms the previous neural network models and state-of-the-art methods.",abstractText,[0],[0]
Long Short-Term Memory Neural Networks for Chinese Word Segmentation,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 297–302 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics",text,[0],[0]
"Entrainment, also called accommodation or alignment, is the tendency of human interlocutors to adapt their behavior to each other to become more similar.",1 Introduction,[0],[0]
"This affects many linguistic features such as referring expressions (Brennan and Clark, 1996), phonetics (Pardo, 2006), syntax (Reitter et al., 2006), linguistic style (Niederhoffer and Pennebaker, 2002), turn-taking (Levitan et al., 2011), and prosody (Levitan and Hirschberg, 2011) as well as non-linguistic behavior (Chartrand and Bargh, 1999).",1 Introduction,[0],[0]
"It has also been linked to external aspects of the conversation such as task success (Reitter and Moore, 2007; Nenkova et al., 2008) and social factors (Ireland et al., 2011; Levitan et al., 2012).
",1 Introduction,[0],[0]
"The study of entrainment thus far has been fragmented, with researchers considering numerous individual features and measuring similarity in various ways, but few searching for correlations or other structure.",1 Introduction,[0],[0]
"For instance, both Ward and Litman (2007) and Fusaroli and Tylén (2016) measured lexical as well as acoustic-prosodic entrainment but neither paper investigated correla-
tions between these measures.",1 Introduction,[0],[0]
There are two recent exceptions to this overall pattern.,1 Introduction,[0],[0]
Mukherjee et al. (2017) found a correlation between speakers’ prosodies becoming more similar over time and their fundamental frequencies varying in synchrony.,1 Introduction,[0],[0]
"Rahimi et al. (2017) also showed correlations, between lexical and acoustic-prosodic entrainment in group conversations.",1 Introduction,[0],[0]
"However, neither considered more complex structure and Rahimi et al., while including lexical features, focus on high-frequency and topic words alone.
",1 Introduction,[0],[0]
"We take a broad view of entrainment, analyzing 18 sets of measurements in four different ways on two corpora to uncover structure, hoping to find higher-level behaviors that explain observed variability between speakers.",1 Introduction,[0],[0]
This is motivated by several cognitive theories that purport to explain linguistic entrainment.,1 Introduction,[0],[0]
"Pickering and Garrod (2004), for instance, claim that it serves dialog success and that “alignment at one level leads to alignment at other levels”.",1 Introduction,[0],[0]
"According to Chartrand and Bargh (1999), entrainment is based on a link between perception and behavior and correlates with “greater perceptual activity directed at the other person”.",1 Introduction,[0],[0]
"Giles et al. (1991), lastly, argue that adaptive behavior is meant to increase or decrease “interpersonal differences” of the interlocutors.",1 Introduction,[0],[0]
All these theories implicitly postulate that entrainment can be considered a single latent behavior or a structured collection of behaviors.,1 Introduction,[0],[0]
"Here, we look for evidence that entrainment behaviors can be explained by an underlying structure, particularly one that spans multiple features.",1 Introduction,[0],[0]
"Practically, it would be useful for downstream analysis to need to consider only a small set of higher-level behaviors rather than each basic entrainment measure in the search for interactions with quality metrics.
",1 Introduction,[0],[0]
Our analysis is based on two corpora of dyadic conversation.,1 Introduction,[0],[0]
"The first is the Objects Games por-
297
tion of the Columbia Games Corpus (Gravano and Hirschberg, 2011), CGC, which comprises 12 sessions with 14 identical tasks each, a total of about four hours of speech.",1 Introduction,[0],[0]
"Second, we use the Switchboard Corpus (Godfrey and Holliman, 1993), SBC, which contains over 2000 free conversations about given topics with a total of more than 200 hours of speech.",1 Introduction,[0],[0]
"Both corpora are fully orthographically transcribed and acoustic-prosodic features were extracted using Praat (Boersma and Weenink, 2001).",1 Introduction,[0],[0]
"We consider three acoustic-prosodic features: pitch (fundamental frequency in Hz), intensity (loudness in dB), and speech rate (in syllables per second).",2.1 Acoustic-prosodic entrainment,[0],[0]
"The arithmetic mean for each feature is determined at the level of an interpausal unit (IPU), a maximal segment of speech by a single speaker without a pause of 50ms or more.",2.1 Acoustic-prosodic entrainment,[0],[0]
"A maximal sequence of IPUs by one speaker, without interruption by the other, is called a turn.
",2.1 Acoustic-prosodic entrainment,[0],[0]
The measures of acoustic-prosodic entrainment we use were defined by Levitan and Hirschberg (2011).,2.1 Acoustic-prosodic entrainment,[0],[0]
Two speakers exhibit local similarity if their feature values differ little at turn exchanges and local convergence if that difference decreases over time.,2.1 Acoustic-prosodic entrainment,[0],[0]
"Global similarity is defined by a small difference in mean feature values over an entire task or session while global convergence is a decreasing difference in means from the first to the
second half of a session.",2.1 Acoustic-prosodic entrainment,[0],[0]
"Synchrony, lastly, exists if both speakers’ feature values rise and fall together at turn exchanges.",2.1 Acoustic-prosodic entrainment,[0],[0]
Figure 1 illustrates these different types of entrainment.,2.1 Acoustic-prosodic entrainment,[0],[0]
Each allows us to numerically quantify a type of likeness of the speakers’ prosodies.,2.1 Acoustic-prosodic entrainment,[0],[0]
"Those numeric values are then normalized and finally correlated, treated as coordinates in a feature space, etc.",2.1 Acoustic-prosodic entrainment,[0],[0]
"We apply three different measures of similarity based on the lemmata, i.e., canonical forms, of the words each speaker used throughout a session.",2.2 Lexical entrainment,[0],[0]
"The first two measures were used by Gravano et al. (2014) to compare ToBI annotations of CGC but, to our knowledge, have not been used before in the context of lexical entrainment.",2.2 Lexical entrainment,[0],[0]
"The third was defined by Nenkova et al. (2008) and shown to correlate with task success in CGC and perceived naturalness in SBC.
",2.2 Lexical entrainment,[0],[0]
"For the perplexity measure, PPL, we use SRILM (Stolcke, 2002) to build a trigram language model for each speaker, predict their partner’s utterances with it, and compute the negated perplexity.",2.2 Lexical entrainment,[0],[0]
"For the second measure, KLD, we compute the negated Kullback-Leibler divergence between pairs of unigram distributions of partners’ words.",2.2 Lexical entrainment,[0],[0]
"Lastly, for the high-frequency words measure, HFW, we compute, for each word w out of the 25 most frequent words in the respective overall corpus, the fraction of each speaker’s words which are w. The sum of the negated absolute differences for the 25 pairs of fractions is our
third measure of similarity for a pair of speakers.",2.2 Lexical entrainment,[0],[0]
Table 1 gives an overview of all our entrainment measures.,2.2 Lexical entrainment,[0],[0]
We apply z-score normalization by gender to our acoustic-prosodic features.,2.3 Normalization,[0],[0]
"That is, for each feature value we subtract the gender mean and then divide by gender standard deviation.
",2.3 Normalization,[0],[0]
"We normalize local similarity at each turn exchange using similarity of either IPU at the exchange with 10 randomly chosen, non-adjacent IPUs from the same session as a baseline.",2.3 Normalization,[0],[0]
"Similarly, global similarity and the lexical measures are normalized using similarity with non-partner speech as a baseline.",2.3 Normalization,[0],[0]
"For each speaker A we compare their similarity with partner B with the similarity with all non-partners C with whom A was never paired and who had the same role (CGC) or talked about the same topic (SBC) as B.
To control for the effect of complexity of speech on the lexical measures, we weight the non-partner similarities by how closely the entropy of the nonpartner’s language model matches that of the actual partner.",2.3 Normalization,[0],[0]
The main purpose of our analysis is to look for structure in an array of entrainment measures.,2.4 Analysis,[0],[0]
"However, we first check whether similarity is significantly greater for partners than non-partners for our lexical measures since PPL and KLD have not previously been used for lexical entrainment and Nenkova et al. (2008) did not report a significance test for HFW.
",2.4 Analysis,[0],[0]
We look for structure in our entrainment measures in four different ways.,2.4 Analysis,[0],[0]
"At the simplest level, we check for pairwise linear correlations by computing Pearson’s correlation coefficient between each pair of entrainment behaviors.",2.4 Analysis,[0],[0]
"Second, we treat each entrainment behavior as binary (present if the speaker is more similar to the partner than to the baseline), and use χ2 tests to investigate whether certain behaviors are disproportionately likely to co-occur.",2.4 Analysis,[0],[0]
"Third, we represent each speaker as a point in a continuous space defined by our entrainment measures and attempt to cluster these points to identify common complex entrainment behaviors.",2.4 Analysis,[0],[0]
"Fourth, we apply principal component analysis (PCA).",2.4 Analysis,[0],[0]
"For each of our lexical entrainment measures, we use t-tests to check whether partner similarities are significantly greater than non-partner similarities, which we consider to be evidence of entrainment.",3.1 Lexical entrainment significance,[0],[0]
"For CGC, we find significance for PPL (p < .001) and KLD (p < .01) but not for HFW (p > .25) while for SBC we find all three to be highly significant (p < 10−6).",3.1 Lexical entrainment significance,[0],[0]
"It is worth mentioning that the greater significance for SBC is attributable to the size of the corpus alone, as the average differences in similarities are comparable in both corpora.",3.1 Lexical entrainment significance,[0],[0]
"That is, even though conversations in SBC are less restricted than in CGC, the partner vs. nonpartner comparison is still “fair”.",3.1 Lexical entrainment significance,[0],[0]
"To check for simple linear correlations, we compute Pearson’s r for each pair of entrainment measures.",3.2 Pearson correlation coefficients between entrainment measures,[0],[0]
"Due to the large number of correlation tests, we control for false discovery rate (FDR) (Benjamini and Hochberg, 1995) at .05 to reduce the probability of Type I error.
",3.2 Pearson correlation coefficients between entrainment measures,[0],[0]
In both corpora we find strong correlations between local similarity and synchrony for each acoustic-prosodic feature (r between +0.64 and +0.95).,3.2 Pearson correlation coefficients between entrainment measures,[0],[0]
This simply results from the measures’ definitions: close feature values at turn exchanges throughout a session imply synchronous variation.,3.2 Pearson correlation coefficients between entrainment measures,[0],[0]
"In CGC, we find no other significant correlations.
",3.2 Pearson correlation coefficients between entrainment measures,[0],[0]
"In SBC, more results are significant due to the greater number of samples.",3.2 Pearson correlation coefficients between entrainment measures,[0],[0]
"Most correlations, however, are very weak, with only a few reaching |r| > 0.1, all between pairs of measurements on the same feature.",3.2 Pearson correlation coefficients between entrainment measures,[0],[0]
"Specifically, we find correlations between local and global convergence for each prosodic feature (+0.14 ≤ r ≤ +0.47) and local and global similarity on pitch (r = +0.16) and intensity (r = +0.26).",3.2 Pearson correlation coefficients between entrainment measures,[0],[0]
"We also find our lexical measures to be correlated with each other (+0.16 ≤ r ≤ +0.58).
",3.2 Pearson correlation coefficients between entrainment measures,[0],[0]
"We conclude that, contrary to our expectations, entrainment does not correlate across features and even within features this simplest kind of structure is barely present.",3.2 Pearson correlation coefficients between entrainment measures,[0],[0]
"We note that Rahimi et al. (2017), controlling less strictly for Type I error, did find correlations between lexical and acousticprosodic measures.",3.2 Pearson correlation coefficients between entrainment measures,[0],[0]
"To check for co-occurrence of different entrainment behaviors, we note, for each conversation: whether local and global partner similarity are greater than the respective non-partner similarity; whether the Pearson r defining synchrony and convergence is positive or not; whether global similarity is greater in the second half than in the first; and whether each of the lexical similarity measures between partners is greater than between non-partners.",3.3 χ2 tests,[0],[0]
"Then we use χ2 tests to check whether some behaviors are disproportionately likely to co-occur.
",3.3 χ2 tests,[0],[0]
"For SBC, we consider all of our entrainment measures at the session level.",3.3 χ2 tests,[0],[0]
"For CGC, we analyze conversations at the task level as only this gives us a sufficient number of samples (149 usable tasks after excluding 19 with too little speech by at least one speaker).",3.3 χ2 tests,[0],[0]
"We also do not analyze local or global convergence for this corpus since they are not meaningful at the task level and do not consider the lexical measures because there are too few utterances per task to make use of them.
",3.3 χ2 tests,[0],[0]
We find significant deviations from expected frequencies only for those few pairs of measurements which we found to be correlated according to Pearson’s r in Section 3.2.,3.3 χ2 tests,[0],[0]
We conclude that there is no significant co-occurrence of entrainment across features.,3.3 χ2 tests,[0],[0]
"Next, we attempt to find structure in entrainment behavior through clustering of measurements.",3.4 Clustering of entrainment measures,[0],[0]
"We analyze the same measurements as in Section 3.3,
treating each task/session as a point in a continuous 9D/18D space, respectively, and use k-means clustering to group points in this space.",3.4 Clustering of entrainment measures,[0],[0]
"In addition to the normalization described in Section 2.3, we apply z-score normalization per measure before clustering, which is a best practice.
",3.4 Clustering of entrainment measures,[0],[0]
Figure 2a shows the silhouette scores for various numbers of clusters k (solid line) for SBC.,3.4 Clustering of entrainment measures,[0],[0]
"This score, which ranges from -1 to +1, compares the similarity of points in the same cluster with those in other clusters, with higher values for greater similarity within than across clusters.",3.4 Clustering of entrainment measures,[0],[0]
"For comparison, we compute clusters after shuffling within columns of our data to remove correlations and cluster dummy data randomly sampled from standard normal distributions, the same distribution as our real data after normalization.",3.4 Clustering of entrainment measures,[0],[0]
The silhouette score is low for all values of k but for low values of k the scores achieved for the real data are greater than for the control data.,3.4 Clustering of entrainment measures,[0],[0]
"The same pattern is present in CGC, with a maximum score for k = 2 of .165 versus .13 for the shuffled data.
",3.4 Clustering of entrainment measures,[0],[0]
"For k = 2, we find that the clusters significantly separate gender pairs, for both corpora, according to χ2 analysis.",3.4 Clustering of entrainment measures,[0],[0]
"However, the same can be achieved with many randomly chosen cluster centroids.",3.4 Clustering of entrainment measures,[0],[0]
"Because of this and the low silhouette scores, we conclude that the entrainment behaviors explored here cannot be meaningfully grouped into clusters.",3.4 Clustering of entrainment measures,[0],[0]
"Lastly, we use PCA on the same data as in Section 3.4.",3.5 Principal component analysis,[0],[0]
"We find that all nine dimensions are needed to retain 99% of the variance in CGC, seven to retain 95% and six to retain 90%.",3.5 Principal component analysis,[0],[0]
"For SBC, we find
that all 18 dimensions are needed to retain 99% of variance, 15 for 95% and 13 for 90%.",3.5 Principal component analysis,[0],[0]
These reductions can mostly be attributed to the correlations between local similarity and synchrony per feature and between the lexical measures.,3.5 Principal component analysis,[0],[0]
"Thus, the analysis again confirms a lack of correlation across features since more significant dimensionality reduction would otherwise be possible.",3.5 Principal component analysis,[0],[0]
"A plot of our SBC data in 3D, shown in Figure 2b, retains 31% of the variance and visually confirms our finding of a lack of clusters.",3.5 Principal component analysis,[0],[0]
We present a corpus analysis using four different approaches to discover an underlying structure or collection of latent behaviors in 18 measures of acoustic-prosodic and lexical entrainment across two corpora.,4 Discussion and Conclusion,[0],[0]
"We find virtually no evidence of links between entrainment on different features, whether in the form of correlations or other common, complex behaviors.
",4 Discussion and Conclusion,[0],[0]
"While it is difficult to prove a negative, our results are strong enough to rule out at least the existence of any clear and strong structure.",4 Discussion and Conclusion,[0],[0]
This is contrary to the expectations we had based on cognitive theory.,4 Discussion and Conclusion,[0],[0]
"It appears that entrainment, rather than a single behavior or a structured collection of behaviors, is a set of behaviors which are only loosely linked and perhaps independently explained by the competing theories.",4 Discussion and Conclusion,[0],[0]
"Practically, we had hoped to simplify and motivate downstream uses of entrainment measures, but our findings suggest that they must be considered separately.
",4 Discussion and Conclusion,[0],[0]
"Although we expected to find complex behavior, at least the absence of entrainment across all features simultaneously can be explained with past research.",4 Discussion and Conclusion,[0],[0]
"As far as entrainment is based on “attention”, as Chartrand and Bargh (1999) suggest, this attention seems to be targeted and does not appear to result in entrainment on several features together.",4 Discussion and Conclusion,[0],[0]
"Alternatively, the absence of correlations may be explained by the fact that not all perception necessarily leads to a change in production, as Kraljic et al. (2008) found.",4 Discussion and Conclusion,[0],[0]
"Moreover, it has long been known that “too much” entrainment can be perceived negatively as mocking or patronizing (Giles and Smith, 1979).",4 Discussion and Conclusion,[0],[0]
"Furthermore, entrainment may be constrained by the need to achieve the communicative goal.",4 Discussion and Conclusion,[0],[0]
"Fusaroli and Tylén (2016), for instance, speculate based on their findings that “interpersonal synergies such
as procedural scripts and routines [. . .",4 Discussion and Conclusion,[0],[0]
] guide and constrain other central linguistic processes such as alignment”.,4 Discussion and Conclusion,[0],[0]
"Lastly, there might be cognitive and physiological limits to speakers’ ability to vary each feature individually or all at the same time.
",4 Discussion and Conclusion,[0],[0]
"Nonetheless, it remains surprising that we find a more general lack of structure, so the potential reasons warrant discussion.",4 Discussion and Conclusion,[0],[0]
"Entrainment is measured in various ways, even with regard to the same features.",4 Discussion and Conclusion,[0],[0]
"Therefore, it would be possible to continue our search using different entrainment measures on our features.",4 Discussion and Conclusion,[0],[0]
"However, all our measures meaningfully and diversely capture entrainment.",4 Discussion and Conclusion,[0],[0]
"Thus, it seems unlikely that alternative measures would yield fundamentally different outcomes, such as strong correlations across features.",4 Discussion and Conclusion,[0],[0]
"Similarly, we believe the analytical tools we employ are wellsuited and further analysis of the same features and measures would not produce disparate results.",4 Discussion and Conclusion,[0],[0]
"Since we only considered low-level features, it is, however, conceivable that more latent structure might yet be found for entrainment at higher levels, such as emotional coloring and linguistic style.
",4 Discussion and Conclusion,[0],[0]
"Despite the fact that our result is negative, we consider it a starting point of inquiry, not an end.",4 Discussion and Conclusion,[0],[0]
We intend to investigate higher-level features and perhaps additional corpora to confirm or qualify our findings.,4 Discussion and Conclusion,[0],[0]
"Beyond that, our result raises the question which principles govern the emergence of entrainment on one feature over another in a given conversation.",4 Discussion and Conclusion,[0],[0]
"As a first attempt to find an answer, we plan to use asymmetrical, speakerspecific measures of entrainment and analyze the consistency of each individual’s entrainment behavior across sessions.",4 Discussion and Conclusion,[0],[0]
This material is based upon work supported in part by the PSC-CUNY Research Award Program under Grant No. 60604-00 48.,Acknowledgments,[0],[0]
"We would also like to thank Julia Hirschberg, Štefan Beňuš, and Agustı́n Gravano for their helpful suggestions and Alyssa Caputo for her help with the project.",Acknowledgments,[0],[0]
Entrainment has been shown to occur for various linguistic features individually.,abstractText,[0],[0]
"Motivated by cognitive theories regarding linguistic entrainment, we analyze speakers’ overall entrainment behaviors and search for an underlying structure.",abstractText,[0],[0]
"We consider various measures of both acoustic-prosodic and lexical entrainment, measuring the latter with a novel application of two previously introduced methods in addition to a standard high-frequency word measure.",abstractText,[0],[0]
"We present a negative result of our search, finding no meaningful correlations, clusters, or principal components in various entrainment measures, and discuss practical and theoretical implications.",abstractText,[0],[0]
Looking for structure in lexical and acoustic-prosodic entrainment behaviors,title,[0],[0]
"Large output spaces are ubiquitous in several machine learning problems today: for example, extreme multiclass or multilabel classification problems with many classes, language modeling with big vocabularies, or metric learning with a large number of pairwise distance constraints.",1. Introduction,[0],[0]
"In all such problems, a key bottleneck in training models is evaluation of the loss function and its gradient.",1. Introduction,[0],[0]
"The loss functions used for such problems typically require an enumeration of all the possible outputs, and thus, naı̈vely, necessitate a linear running time in the number of outputs for
1Carnegie Mellon University, Pittsburgh, USA 2Google, New York, USA.",1. Introduction,[0],[0]
Correspondence to: Ian E.H. Yen,1. Introduction,[0],[0]
"<eyan@cs.cmu.edu>, Satyen Kale <satyenkale@google.com>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
evaluation.",1. Introduction,[0],[0]
"This can be a significant bottleneck in iterative methods such as gradient descent used to train the model, since each step now requires a huge number of operations.
",1. Introduction,[0],[0]
Many approaches have been proposed to mitigate this issue.,1. Introduction,[0],[0]
"One body of work imposes structure over the output space, such as low-rank (Yu et al., 2014), treestructure (Prabhu & Varma, 2014), locally low-rank (Bhatia et al., 2015), or hierarchical factorization (Morin & Bengio, 2005; Mnih & Hinton, 2009).",1. Introduction,[0],[0]
"However, structural assumptions can be violated in many situations.",1. Introduction,[0],[0]
"For example, while the low-rank structure is typically reasonable in a recommendation problem, it is usually not true in multiclass classification as for each instance there is exactly one correct answer (i.e. classes may not be correlated with each other).",1. Introduction,[0],[0]
"Additionally, even for valid structural assumptions, constructing the correct structure from data is hard, and in practice heuristics or human annotation are required (Morin & Bengio, 2005; Mnih & Hinton, 2009).
",1. Introduction,[0],[0]
"Another approach is sampling approximation (Mikolov et al., 2013; Gutmann & Hyvärinen, 2012; Jean et al., 2014), which computes an estimate of the gradient based on the scores of only a small fraction of the negative output classes and also a small set of classes labeled as positive.",1. Introduction,[0],[0]
"The approximation, however, has large variance when the loss has a skewed distribution over classes.",1. Introduction,[0],[0]
"For example, in extreme multiclass or multilabel classification, the loss typically only concentrates on a few confusing classes, which have small probabilities of being sampled.",1. Introduction,[0],[0]
"The variance in gradient estimation often leads to slow progress of the learning algorithm.
",1. Introduction,[0],[0]
"In this paper, we consider problems with large output spaces, but with each example having only a relatively small set of correct outputs.",1. Introduction,[0],[0]
"The learning objective for such tasks typically has its gradient concentrated on a relatively small number of classes, and therefore an efficient way to learn is to search for classes of significant gradient magnitude.",1. Introduction,[0],[0]
"For example, (Yen et al., 2016; 2017) proposed a method to search classes efficiently by maintaining a sparse model during training.",1. Introduction,[0],[0]
"However, this method applies only in problems of high input dimension.",1. Introduction,[0],[0]
"Another strategy that has received a lot of attention recently is to utilize data structures to find classes efficiently through Maximum Inner-Product Search (MIPS) or Nearest-Neighbor
Search (NNS) (Yen et al., 2013; Vijayanarasimhan et al., 2014; Mussmann & Ermon, 2016; Mussmann et al., 2017; Spring & Shrivastava, 2017b;a; Wu et al., 2017; Guo et al., 2016).",1. Introduction,[0],[0]
"The main challenge here is that as dimension grows, it becomes difficult to perform MIPS or NNS with both high recall and high precision, and therefore gradient approximation through MIPS or NNS often sacrifices accuracy to achieve efficiency.
",1. Introduction,[0],[0]
"In this work, we propose an algorithm based on an application of dual decomposition (Boyd et al., 2011) to the convex-conjugate representation of the loss function.",1. Introduction,[0],[0]
This can be viewed as a complementary technique for applying search data structures to a learning problem.,1. Introduction,[0],[0]
"Essentially, the algorithm replaces the high dimensional search problem with several lower dimensional searches by decoupling the dimensions via dual decomposition.",1. Introduction,[0],[0]
"Lower dimensional search can be done much more efficiently, and the different searches are then coupled together via a greedy message passing algorithm.",1. Introduction,[0],[0]
We prove that this greedy message passing technique is guaranteed to converge and thus we can obtain good approximations to the loss and its gradient.,1. Introduction,[0],[0]
"We term our overall approach LDGS for Loss Decomposition Guided Search.
",1. Introduction,[0],[0]
"Our experiments on large-scale face recognition, document tagging and word embedding show that the proposed approach significantly improves the accuracy of the searchbased gradient approximation method and is orders of magnitude faster than other strategies of gradient approximation such as sampling.",1. Introduction,[0],[0]
"Let X denote the input space and Y the output space, and let K := |Y|.",2. Problem Setup,[0],[0]
"In this paper we focus on the situation where K is extremely large, on the order of hundreds of thousands or larger.",2. Problem Setup,[0],[0]
We are interested in learning a scoring function f :,2. Problem Setup,[0],[0]
"X → RK for a large output space Y from a given class of such functions, F .",2. Problem Setup,[0],[0]
"Labeled samples are pairs (x,P) with x ∈ X and P ⊆ Y which denotes the set of correct labels for the input point x.",2. Problem Setup,[0],[0]
We use the notation N := Y \ P to denote the set of negative labels for the example.,2. Problem Setup,[0],[0]
"Given a collection of training samples {(xi,Pi)}Ni=1, the learning objective takes the following form:
min f∈F
1
N N∑ i=1",2. Problem Setup,[0],[0]
"L(f(xi),Pi).
",2. Problem Setup,[0],[0]
"where L : RK × 2Y → R is a loss function such that L(z,P) penalizes the discrepancy between the score vector z ∈ RK and a set of positive labels P ⊆ Y .",2. Problem Setup,[0],[0]
"The evaluation of the loss function and its gradient with respect to the score vector, ∇zL(z,P), typically has cost growing linearly with the size of the output space K, and thus is
expensive for problems with huge output spaces.
",2. Problem Setup,[0],[0]
"The key to our method for reducing the complexity of loss and gradient evaluation will be the following linear structural assumption on the class of scoring functions F : there is an embedding dimension parameter D ∈ N such that for every f ∈ F , we can associate a weight matrix W ∈ RK×D and feature map φ :",2. Problem Setup,[0],[0]
"X → RD so that for all x ∈ X ,
f(x) = Wφ(x).",2. Problem Setup,[0],[0]
"(1)
We will assume that D K, say on the order of a few hundreds or thousands, so that we can explicitly evaluate φ(x).
",2. Problem Setup,[0],[0]
"The problem we consider is the following: given f and a batch of samples {xi,Pi}Ni=1, compute an approximation to the empirical loss 1N ∑N i=1",2. Problem Setup,[0],[0]
"L(f(xi),Pi)",2. Problem Setup,[0],[0]
and its gradient.,2. Problem Setup,[0],[0]
"This is an important subroutine that naturally arises in either full batch gradient descent or minibatch stochastic gradient descent.
",2. Problem Setup,[0],[0]
"The main challenge here is to construct data structures that preprocess the matrix W so that good approximations to the loss f(xi,Pi) and its gradient can be computed without computing the vector f(x) entirely: i.e. we desire sublinear (in K) time computation of such approximations given access to an appropriate data structure.
",2. Problem Setup,[0],[0]
"Before proceeding to our dual decomposition based search technique, we give a few examples of problems with large output space that fit in our framework:
1.",2. Problem Setup,[0],[0]
Extreme Classification.,2. Problem Setup,[0],[0]
"In extreme classification problems, popular classification loss functions include Cross-Entropy Loss
L(z,P) := ∑ k∈P log (∑K j=1 exp(zj) )",2. Problem Setup,[0],[0]
"− zk (2)
and Max-Margin Loss L(z,P) := [
max k∈P,j∈N zj − zk + 1 ] + .",2. Problem Setup,[0],[0]
"(3)
For multiclass problems, |P| = 1, while for multilabel problems we usually have |P| K. A typical scoring function takes the form
f(x) := Wφ(x).",2. Problem Setup,[0],[0]
"(4)
Here, φ(x) is a feature map constructed either from the domain knowledge or via learning (e.g., a neural network).",2. Problem Setup,[0],[0]
"Both of them fit the structural assumption (1).
2.",2. Problem Setup,[0],[0]
Metric Learning.,2. Problem Setup,[0],[0]
"In Metric Learning problems, during training we learn a function
f(x) =",2. Problem Setup,[0],[0]
"[−d(x,y)]y∈Y , (5)
that denotes the dissimilarities of the point x to a collection of points y ∈ Y .",2. Problem Setup,[0],[0]
"Common choices of the dissimilarity function include the squared Euclidean distance d(x,y) = ‖ψ(x)−ψ(y)‖22 parameterized by a nonlinear transformation ψ",2. Problem Setup,[0],[0]
": X → Rd for some d ∈ N, and, more generally, the squared Mahalanobis distance d(x,y) = (ψ(x)−ψ(y))>M(ψ(x)−ψ(y))",2. Problem Setup,[0],[0]
parameterized by ψ and a positive definite matrixM .,2. Problem Setup,[0],[0]
"The candidate set Y could be the whole set of training samples {xi}Ni=1, or a collection of latent proxies {yk}Kk=1 as suggested by a recent state-of-the-art method (Movshovitz-Attias et al., 2017).",2. Problem Setup,[0],[0]
"For each sample (x,P), the goal is to learn a distance function s.t.",2. Problem Setup,[0],[0]
the positive candidates P are closer to x than the negative ones.,2. Problem Setup,[0],[0]
"Common loss functions for the task are Neighborhood Component Analysis (NCA) loss (Goldberger et al., 2005)
",2. Problem Setup,[0],[0]
"L(z,P) := ∑ k∈P log (∑K j=1 exp(zj) )",2. Problem Setup,[0],[0]
"− zk (6)
and the Triplet loss (Weinberger & Saul, 2009)",2. Problem Setup,[0],[0]
"L(z,P) = ∑ k∈P ∑ j∈N",2. Problem Setup,[0],[0]
[zj − zk + 1]+.,2. Problem Setup,[0],[0]
"(7)
It is easy to see that such scoring functions satisfy the structural assumption (1): for the scoring function f given by the squared Mahalanobis distance parameterized by ψ and M , the matrix W consists of the rows 〈−ψ(y)>Mψ(y), 2ψ(y)>M ,−1〉 for each y ∈ Y , and φ(x) = 〈1,ψ(x)>,ψ(x)>Mψ(x)〉>.",2. Problem Setup,[0],[0]
"Thus the embedding dimension D = d+ 2.
3.",2. Problem Setup,[0],[0]
Word Embeddings.,2. Problem Setup,[0],[0]
"In the standard word2vec training (Mikolov et al., 2013), the input space X is the vocabulary set, and the output space Y = X ; thus K is the vocabulary size.",2. Problem Setup,[0],[0]
"The Skip-gram objective learns a scoring function f of the following form:
f(x) = 〈φ(y)>φ(x)〉y∈X , (8)
where φ(·) is a latent word embedding.",2. Problem Setup,[0],[0]
This clearly fits the structural assumption (1): the rows of the matrixW are the embeddings φ(y) for all y ∈ X .,2. Problem Setup,[0],[0]
"Then given a text corpus D, the loss function1 for a sample (x,P) where P is the set of words in the corpus appearing within a certain size window around the input word x, is given by
L(z,P) = qx ∑ y∈P qy|x·[log (∑ y′∈X exp(zy′) )",2. Problem Setup,[0],[0]
"−zy] (9) where qx is the empirical unigram frequency of x and qy|x is the empirical frequency of observing y within a window of x in the corpus D.
1This is a more compact reformulation of the loss function in (Mikolov et al., 2013).
",2. Problem Setup,[0],[0]
"Algorithm 1 Loss and Gradient Approximation via Search
input A sample (x,P), accuracy parameter τ > 0, and access to a MIPS data structure T for the rows ofW .",2. Problem Setup,[0],[0]
"output Approximations to L(f(x),P),∇L(f(x),P).",2. Problem Setup,[0],[0]
1: Query T with φ(x) and threshold τ to find S := {k | |[f(x)]k| >,2. Problem Setup,[0],[0]
"τ}.
2: Construct a sparse approximation z̃ for f(x) by setting z̃k = f(x)k for k ∈ S ∪P , and z̃k = 0 for k 6∈ S ∪P .",2. Problem Setup,[0],[0]
"3: Return L(z̃,P) and ∇L(z̃,P).",2. Problem Setup,[0],[0]
All the loss functions we considered in the applications mentioned share a key feature: their value can be well approximated by the scores of the positive labels and the largest scores of the negative labels.,2.1. Loss and Gradient Approximation via Search,[0],[0]
"Similarly, their gradients are dominated by the coordinates corresponding to the positive labels and the negative labels with the largest scores.",2.1. Loss and Gradient Approximation via Search,[0],[0]
"For example, the Max-Margin loss (3) is completely determined by the largest score of the negative labels and the lowest scores of the positive labels, and its gradient is non-zero only on the negative label with largest score and the positive label with lowest score.",2.1. Loss and Gradient Approximation via Search,[0],[0]
"Similarly, for the Cross-Entropy loss (2), the coordinates of the gradient corresponding to the negative classes are dominated by the ones with the highest score; the gradient coordinates decrease exponentially as the scores decrease.
",2.1. Loss and Gradient Approximation via Search,[0],[0]
"This key property suggests the following natural idea for approximating these losses and their gradients: since the score function f satisfies the linear structural property (1), we can compute the largest scores efficiently via a Maximum Inner Product Search (MIPS) data structure (Shrivastava & Li, 2014).",2.1. Loss and Gradient Approximation via Search,[0],[0]
"This data structure stores a large data set of vectors v1,v2, . . .",2.1. Loss and Gradient Approximation via Search,[0],[0]
",vK ∈ RD and supports queries of the following form: given a target vector u ∈ RD and a threshold τ , it returns the vectors vi stored in it that satisfy |v",2.1. Loss and Gradient Approximation via Search,[0],[0]
>i u| ≥ τ,2.1. Loss and Gradient Approximation via Search,[0],[0]
in time that is typically sublinear in K.,2.1. Loss and Gradient Approximation via Search,[0],[0]
"Thus, we can preprocess W by storing the rows of W in an efficient MIPS data structure.",2.1. Loss and Gradient Approximation via Search,[0],[0]
"Then for each sample x, we can compute the highest scores by querying this data structure with the target vector φ(x) and some reasonable threshold τ , computing approximations to the loss and gradient from the returned vectors (and treating all other scores as 0).",2.1. Loss and Gradient Approximation via Search,[0],[0]
"This method is depicted in Algorithm 1.
",2.1. Loss and Gradient Approximation via Search,[0],[0]
"The error in this approximation is naturally bounded by τ times the `∞ Lipschitz constant of L(·,P).",2.1. Loss and Gradient Approximation via Search,[0],[0]
"For most loss functions considered in this paper, the `∞ Lipschitz constant is reasonably small: 2 for Max-Margin loss, O(Pmax log(K)) for Cross-Entropy loss (here, Pmax is the maximum number of positive labels for any example), etc.
",2.1. Loss and Gradient Approximation via Search,[0],[0]
"The main difficulty in applying this approach in practice
is the curse of dimensionality: the dependence on D is exponential for exact methods, and even for approximate methods, such as Locality-Sensitive Hashing, the cost still implicitly depends on the dimension as points become far apart when the intrinsic dimensionality is high (Li & Malik, 2017).
",2.1. Loss and Gradient Approximation via Search,[0],[0]
"To deal with the curse of dimensionality, we introduce a novel search technique based on dual decomposition.",2.1. Loss and Gradient Approximation via Search,[0],[0]
"This method, and its analysis, are given in the following section.
",2.1. Loss and Gradient Approximation via Search,[0],[0]
"In order to apply and analyze the technique, we need the loss functions to be smooth (i.e. have Lipschitz continuous gradients).",2.1. Loss and Gradient Approximation via Search,[0],[0]
"For non-smooth losses like Max-Margin loss (3), we apply Nesterov’s smoothing technique (Nesterov, 2005), which constructs a surrogate loss function with guaranteed approximation quality by adding a strongly convex term to the Fenchel conjugate of the loss:
Lµ(z)",2.1. Loss and Gradient Approximation via Search,[0],[0]
":= max α 〈z,α〉 −
( L∗(α) + µ
2 ‖α‖2
) .",2.1. Loss and Gradient Approximation via Search,[0],[0]
"(10)
Here, µ is a smoothing parameter that ensures that the surrogate loss has 1µ Lipschitz continuous gradients while approximating the original loss function to withinO(µ).",2.1. Loss and Gradient Approximation via Search,[0],[0]
"This Smoothed Max-Margin loss has gradient
∇L(z) := projC(z+1Nµ ) (11)
where 1N denotes a vector containing 0 for indices k ∈ P and 1 for k ∈ N , and projC(.) denotes the projection onto the bi-simplex C = {α | ∑ k∈N αk = ∑ k∈P −αk ≤ 1, αN ≥ 0, αP ≤ 0}.",2.1. Loss and Gradient Approximation via Search,[0],[0]
The Smoothed Max-Margin loss and its gradient can again be computed using the largest few scores.,2.1. Loss and Gradient Approximation via Search,[0],[0]
We now describe our loss decomposition method.,3. Loss Decomposition,[0],[0]
Recall the linear structural assumption (1): f(x) = Wφ(x) for all x ∈ X .,3. Loss Decomposition,[0],[0]
"In this section, we will keep (x,P) fixed, and we will drop the dependence on P in L for convenience and simply use the notation L(f(x)) and∇L(f(x)).
",3. Loss Decomposition,[0],[0]
"While MIPS over the D-dimensional rows of W can be computationally expensive, we can exploit the linear structure of f by decomposing it: chunking the D coordinates of the vectors in RD into B blocks, each of size D/B. Here B ∈ N is an integer; larger B leads to easier MIPS problems but reduces accuracy of approximations produced.",3. Loss Decomposition,[0],[0]
"Let W (1),W (2), . . .",3. Loss Decomposition,[0],[0]
",W (B) be the corresponding block partitioning of W obtained by grouping together the columns corresponding to the coordinates in each block.",3. Loss Decomposition,[0],[0]
"Similarly, let φ(1)(x),φ(2)(x), . . .",3. Loss Decomposition,[0],[0]
",φ(B)(x) be the conformal partitioning of the coordinates of φ(x).
",3. Loss Decomposition,[0],[0]
"Now define the overall score vector z := f(x) = Wφ(x), and per-chunk score vectors zj = W (j)φ(j)(x), for j ∈
[B].",3. Loss Decomposition,[0],[0]
"Then we have z = ∑B j=1 zj , in other words, we have a decomposition of the score vector.",3. Loss Decomposition,[0],[0]
The following theorem states that the loss of a decomposable score vector can itself be decomposed into several parts connected through a set of message variables.,3. Loss Decomposition,[0],[0]
This theorem is key to decoupling the variables into lower dimensional chunks that can be optimized separately via an efficient MIPS data structure.,3. Loss Decomposition,[0],[0]
"While this theorem can be derived by applying dual decomposition to the convex conjugate of the loss function, here we provide a simpler direct proof by construction.",3. Loss Decomposition,[0],[0]
Theorem 1.,3. Loss Decomposition,[0],[0]
"Let L : RK → R be a convex function, and let z ∈ RK be decomposed as a sum of B vectors as follows: z = ∑B j=1 zj .",3. Loss Decomposition,[0],[0]
"Then L(z) is equal to the optimum value of the following convex minimization problem:
min λj∈RK , j∈[B]
1
B B∑ j=1 L(B(zj + λj))",3. Loss Decomposition,[0],[0]
"s.t. B∑ j=1 λj = 0.
(12)
Proof.",3. Loss Decomposition,[0],[0]
"First, for any λ1,λ2, . . .",3. Loss Decomposition,[0],[0]
",λB ∈ RK such that∑B j=1 λj = 0, by Jensen’s inequality applied to the con-
vex function L, we have L(z) ≤ 1B ∑B j=1 L(B(zj +λj)).",3. Loss Decomposition,[0],[0]
"On the other hand, if we set λj = 1Bz− zj for all j ∈",3. Loss Decomposition,[0],[0]
"[B], we have L(z) = 1B ∑B j=1 L(B(zj +",3. Loss Decomposition,[0],[0]
λj)).,3. Loss Decomposition,[0],[0]
Theorem (1) is the basis for our algorithm for computing approximations to the loss and its gradient.,3.1. Loss Decomposition Guided Search (LDGS),[0],[0]
"This approximation is computed by approximately solving the convex minimization problem (12) without computing the whole score vector z, using a form of descent method on the λj variables (which we refer to as “message passing”).",3.1. Loss Decomposition Guided Search (LDGS),[0],[0]
The gradient computations required for each step can be (approximately) done using an efficient MIPS data structure storing the D/B dimensional rows ofW,3.1. Loss Decomposition Guided Search (LDGS),[0],[0]
(j).,3.1. Loss Decomposition Guided Search (LDGS),[0],[0]
The details of the algorithm are given in Algorithm 2.,3.1. Loss Decomposition Guided Search (LDGS),[0],[0]
"It can be viewed as running a version of the Frank-Wolfe algorithm on an appropriate convex function.
",3.1. Loss Decomposition Guided Search (LDGS),[0],[0]
"A sublinear in K time implementation of step 5 in the algorithm relies on the fact that both z̃j and λj are sparse vectors, which in turn relies on the fact that gradients of the loss functions of interest are either sparse or concentrated on a few coordinates.",3.1. Loss Decomposition Guided Search (LDGS),[0],[0]
"Step 9 in the algorithm moves the current solution towards the optimal solution λ∗j that we have a closed form formula for, thanks to the constructive proof of Theorem (1).",3.1. Loss Decomposition Guided Search (LDGS),[0],[0]
"This movement is only done for the set of coordinates of the gradients of high magnitude identified in step 5 of the algorithm, thus ensuring that only a few coordinates are updated.",3.1. Loss Decomposition Guided Search (LDGS),[0],[0]
Thus essentially the algorithm is performing a greedy descent towards the optimal solution.,3.1. Loss Decomposition Guided Search (LDGS),[0],[0]
"For more details on how the data structures are maintained in the algorithm, refer to Section 4.
",3.1. Loss Decomposition Guided Search (LDGS),[0],[0]
"Algorithm 2 Greedy Message Passing
input a sample x, threshold parameters τ1, τ2 > 0, and access to B MIPS data structures Tj storing the rows ofW",3.1. Loss Decomposition Guided Search (LDGS),[0],[0]
"(j), for j ∈",3.1. Loss Decomposition Guided Search (LDGS),[0],[0]
"[B] output Approximation to ∇L(f(x)).
",3.1. Loss Decomposition Guided Search (LDGS),[0],[0]
1:,3.1. Loss Decomposition Guided Search (LDGS),[0],[0]
Query Tj with φ(j)(x) and threshold τ to find Sj := {k | |[zj ]k| > τ1}.,3.1. Loss Decomposition Guided Search (LDGS),[0],[0]
2: Construct a sparse approximation z̃j for zj by setting [z̃j ]k =,3.1. Loss Decomposition Guided Search (LDGS),[0],[0]
"[zj ]k for k ∈ Sj ∪ P , and [z̃j ]k = 0 for k 6∈ S ∪ P .",3.1. Loss Decomposition Guided Search (LDGS),[0],[0]
"3: for t = 1, 2, . . .",3.1. Loss Decomposition Guided Search (LDGS),[0],[0]
"(until converged) do 4: Compute the set
A := ⋃ j∈[B] {k | |[∇L(B(z̃j +",3.1. Loss Decomposition Guided Search (LDGS),[0],[0]
"λj))]k| > τ2}.
5: Compute [λ∗j ]k = 1 B [z̃]k",3.1. Loss Decomposition Guided Search (LDGS),[0],[0]
−,3.1. Loss Decomposition Guided Search (LDGS),[0],[0]
[z̃j ]k for all k ∈ A and all j ∈,3.1. Loss Decomposition Guided Search (LDGS),[0],[0]
[B].,3.1. Loss Decomposition Guided Search (LDGS),[0],[0]
6: Compute the step size η = 2t+2 .,3.1. Loss Decomposition Guided Search (LDGS),[0],[0]
7: For all k ∈ A and all j ∈,3.1. Loss Decomposition Guided Search (LDGS),[0],[0]
"[B], update
[λj ]k ← η[λ∗j ]k + (1− η)[λj ]k.
8: end for 9:",3.1. Loss Decomposition Guided Search (LDGS),[0],[0]
Output 1B ∑B,3.1. Loss Decomposition Guided Search (LDGS),[0],[0]
j=1∇L(B(z̃j,3.1. Loss Decomposition Guided Search (LDGS),[0],[0]
+ λj)).,3.1. Loss Decomposition Guided Search (LDGS),[0],[0]
Define z̃ = ∑B j=1 z̃j .,3.2. Error Analysis,[0],[0]
Note that ‖z,3.2. Error Analysis,[0],[0]
"− z̃‖∞ ≤ Bτ1, so the error in approximating L(z) by L(z̃) is at most Bτ1 times the `∞ Lipschitz constant of L, which is typically small as explained earlier.",3.2. Error Analysis,[0],[0]
The algorithm essentially runs a FrankWolfe type method to converge to L(z̃).,3.2. Error Analysis,[0],[0]
"In the following, we analyze the convergence rate of the greedy message passing algorithm (Algorithm 2) to L(z̃).",3.2. Error Analysis,[0],[0]
The analysis relies on smoothness of the loss function.,3.2. Error Analysis,[0],[0]
"A function is said to be 1/µ-smooth if its gradients are Lipschitz continuous with constant 1/µ. For the Cross-Entropy loss (2) we have µ = 1, and for the smoothed max-margin loss (10), µ is a tunable parameter, and we found setting µ ∈",3.2. Error Analysis,[0],[0]
"[1, 5] works well in our experiments.
",3.2. Error Analysis,[0],[0]
"To analyze the algorithm, denote by Λ the BK dimensional vector 〈λ1,λ2, . . .",3.2. Error Analysis,[0],[0]
",λB〉 in any given step in the loop of the algorithm.",3.2. Error Analysis,[0],[0]
Similarly let Λ∗ denote the BK dimensional vector composed of λ∗j .,3.2. Error Analysis,[0],[0]
"Define G(Λ) = 1 B ∑B j=1 L(B(z̃j+λj)), i.e. the objective function in (12).
",3.2. Error Analysis,[0],[0]
Theorem 2 (Greedy Message Passing).,3.2. Error Analysis,[0],[0]
Suppose the loss function L is 1/µ-smooth.,3.2. Error Analysis,[0],[0]
"Then the suboptimality gap of Λ in the t-th step of the loop can be bounded as follows:
G(Λ)−G(Λ∗) ≤ 2B‖Λ",3.2. Error Analysis,[0],[0]
"∗‖2
µ(t+ 2) + 2τ2",3.2. Error Analysis,[0],[0]
"ln(t)‖Λ∗‖1
Proof.",3.2. Error Analysis,[0],[0]
"Since the loss function L is 1/µ-smooth, it is easy to check that G is B/µ-smooth.",3.2. Error Analysis,[0],[0]
"Thus, if ∆Λ is the change in Λ in a given step of the loop in the algorithm, then
G(Λ + ∆Λ)−G(Λ) ≤ η〈∇G(Λ),∆Λ〉+ η 2B
2µ ‖∆Λ‖2.
",3.2. Error Analysis,[0],[0]
Note that ∆Λ equals Λ∗−Λ in all coordinates except those corresponding to k /∈,3.2. Error Analysis,[0],[0]
A for all j ∈,3.2. Error Analysis,[0],[0]
"[B], and the magnitude of the gradient in those coordinates is at most τ2.",3.2. Error Analysis,[0],[0]
"Thus we have 〈∇G(Λ),∆Λ〉 ≤ 〈∇G(Λ),Λ∗−Λ〉+ τ2‖Λ∗‖1.",3.2. Error Analysis,[0],[0]
"Here, we used the fact that each coordinate of Λ lies between 0 and the corresponding coordinate of Λ∗. Next, by the convexity of G, we have 〈∇G(Λ),Λ∗ − Λ〉 ≤ G(Λ∗)",3.2. Error Analysis,[0],[0]
− G(Λ).,3.2. Error Analysis,[0],[0]
"Putting all the bounds together and following some algebraic manipulations, we have
G(Λ + ∆Λ)−G(Λ∗)
≤ (1− η)(G(Λ)−G(Λ∗))",3.2. Error Analysis,[0],[0]
+ ητ2‖Λ∗‖1,3.2. Error Analysis,[0],[0]
"+ η2B
2µ ‖Λ∗‖2.
(13)
Here, we used the fact that each coordinate of Λ lies between 0 and the corresponding coordinate of Λ∗ to get the bound ‖∆Λ‖2 ≤",3.2. Error Analysis,[0],[0]
"‖Λ∗‖2.
",3.2. Error Analysis,[0],[0]
"Now, using the fact that η = 2t+2 in iteration t, a simple induction on t implies the claimed bound on G(Λ)−G(Λ∗).
",3.2. Error Analysis,[0],[0]
"Thus, to ensure that the suboptimality gap is at most , it suffices to run the greedy procedure for T =",3.2. Error Analysis,[0],[0]
"B‖Λ
∗‖2 4µ steps
with τ2 = 4 ln(T )‖Λ∗‖1 .",3.2. Error Analysis,[0],[0]
"While this theorem provides a proof of convergence for the algorithm to any desired error level, the bound it provides is quite weak.",3.2. Error Analysis,[0],[0]
"In practice, we found that running just one step of the loop suffices to improve performance over direct search-based methods.
",3.2. Error Analysis,[0],[0]
"If, in addition to being smooth, the loss function is also strongly convex (which can be achieved by adding some `22 regularization, for instance) then we can also show convergence of the gradients.",3.2. Error Analysis,[0],[0]
This is because for strongly convex functions the convergence of gradients can be bounded in terms of the convergence of the loss value.,3.2. Error Analysis,[0],[0]
"This is a very standard analysis and we omit it for the sake of clarity.
",3.2. Error Analysis,[0],[0]
Cost Analysis.,3.2. Error Analysis,[0],[0]
Exact gradient evaluation for a single sample can be computed in O(DK) time.,3.2. Error Analysis,[0],[0]
"Directly applying a search-based gradient approximation (Algorithm 1) has a cost ofO(DQD(K)),whereQD(K) is the number of classes retrieved in the MIPS data structure in order to find all classes of significant gradients.",3.2. Error Analysis,[0],[0]
"The query cost QD(K) has a strong dependency on the dimension D. Exact MIPS has a cost QD(K) exponential in D (Shrivastava & Li, 2014; Li & Malik, 2017).",3.2. Error Analysis,[0],[0]
"For approximate search methods,
such as Locality Sensitive Hashing (LSH), the costQD(K) typically only implicitly depends on the dimension.",3.2. Error Analysis,[0],[0]
Our method (Algorithm 2) dividesD,3.2. Error Analysis,[0],[0]
"intoB subproblems of dimension D/B with a cost per message passing iteration of O(DQD/B(K)+DB|A|), whereA is the set computed in step 4 of Algorithm 2.",3.2. Error Analysis,[0],[0]
Note QD/B(K) decreases with B rapidly (exponentially in the exact case) and therefore one can select B such that QD/B(K) QD(K) and balance two terms s.t. (DQD/B(K),3.2. Error Analysis,[0],[0]
+DB|A|) DK.,3.2. Error Analysis,[0],[0]
MIPS queries.,4. Practical Considerations,[0],[0]
"In practice when using the MIPS data strcuctures, instead of retrieving all classes with scores more than the threshold τ1, it is more efficient to retrieve the top Q classes with the highest scores.",4. Practical Considerations,[0],[0]
"In our implementation, we use Spherical Clustering (Auvolat et al., 2015) as the MIPS data structure, where the number of clusters C is selected such that K/C ≤ Q and C ≤ Q.",4. Practical Considerations,[0],[0]
"Note this requires Q ≥ √ K, leading to a speedup bounded by√
K. Similarly, for computing the active set A in step 4 of Algorithm 2, we can compute an appropriate threshold τ2 using the properties of the loss function.",4. Practical Considerations,[0],[0]
"In the case of margin-based losses, (3) and (7), and their smoothed versions (10), the gradient is sparse so τ2 can be set to 0 or some very small value (τ2 = 10−3 works well in our experiments).",4. Practical Considerations,[0],[0]
"Loss functions like (2), (6) typically have exponentially decayed gradient magnitudes over the nonconfusing negative classes.",4. Practical Considerations,[0],[0]
"For these losses, classes can be retrieved in decreasing order of gradient magnitude, using a lower bound on the partition function Z = ∑ k exp zk summing over only the subset of retrieved classes in order to decide whether more classes need to be retrieved or not.
",4. Practical Considerations,[0],[0]
Updates of data structures.,4. Practical Considerations,[0],[0]
"During training the model parameters determining f will change, and the data structures Tj need to be updated.",4. Practical Considerations,[0],[0]
These data structures stores rows of W and treats φ(x) as query.,4. Practical Considerations,[0],[0]
"For loss functions with a sparse gradient, such as (3) and (7), and their smoothed versions (10), the number of updated rows ofW , kr, is much smaller than K and Q (the number of classes retrieved for a query).",4. Practical Considerations,[0],[0]
"Thus the cost for re-indexing rows ofW is krC(D/B)B = krCD, where C is the number of inner products required to index each row, which is much smaller than the costs of query and updates.",4. Practical Considerations,[0],[0]
"For tasks with large number of updated rows (kr ≈ Q), the method is still effective with a larger mini-batch size Nb.",4. Practical Considerations,[0],[0]
"As the costs of query and updates grow with Nb while the number of rows to re-index is bounded by K, the cost of maintaining data structure becomes insignificant.
",4. Practical Considerations,[0],[0]
Sampling for initialization.,4. Practical Considerations,[0],[0]
"For a randomly initialized model, the early iterates of learning have gradients evenly distributed over the classes, as the scores of all classes are
close to each other.",4. Practical Considerations,[0],[0]
"Therefore, it is unnecessary to search candidates of significant gradient magnitude in the early stage.",4. Practical Considerations,[0],[0]
"In practice, one can switch from a sampling-based gradient approximation to a search-based gradient approximation after a number of mini-batch updates.",4. Practical Considerations,[0],[0]
"In our experiments of unsupervised learning of word embeddings, we initialize the algorithm with a single epoch of SGD with sampling gradient approximation.",4. Practical Considerations,[0],[0]
"In this section, we conduct experiments on three types of problems: (i) multiclass classification (face recognition), (ii) multilabel classification (document tagging), and (iii) Unsupervised Word Embedding (Skip-gram objective (9)).",5. Experiments,[0],[0]
"For multiclass and multilabel classification, we employ a Stochastic Gradient Descent (SGD) optimization algorithm, with an initial step size chosen from {1, 0.1, 0.01} for the best performance of each method, with a 1/(1 + t) cooling scheme where t is the iteration counter.",5. Experiments,[0],[0]
"The minibatch size is 10 and all methods are parallelized with 10 CPU cores in a shared-memory architecture, running on a dedicated machine.",5. Experiments,[0],[0]
All the implementation are in C++.,5. Experiments,[0],[0]
"The following loss functions and gradient evaluation methods are compared for the experiments on multiclass and multilabel classification:
• Softmax: exact gradient evaluation of the crossentropy loss (2).",5. Experiments,[0],[0]
"For multiclass, we have |P| = 1 and for multilabel, |P| K.
• Sampled-Softmax: the sampling strategy in (Jean et al., 2014; Chen et al., 2015), which includes all positive classes of the instances and uniformly subsamples from the remaining negative classes.",5. Experiments,[0],[0]
"Here we choose sample size as K/100.
",5. Experiments,[0],[0]
•,5. Experiments,[0],[0]
"Margin: exact gradient evaluation of the smoothed max-margin loss (10), where we choose µ = 1 for the case of multiclass, and µ = 5 for the case of multilabel.",5. Experiments,[0],[0]
"The bi-simplex projection (11) is computed in O(K logK) using the procedure described in (Yen et al., 2016).",5. Experiments,[0],[0]
"Note the gradient update for this loss is faster than that for cross-entropy, as the loss gradient is very sparse, making the backward pass much faster.
",5. Experiments,[0],[0]
• MIPS: search-based gradient evaluation (Algorithm 1) with smoothed max-margin loss (same setting to Margin).,5. Experiments,[0],[0]
"We use Spherical Clustering (Auvolat et al., 2015) with 100 centroids as the MIPS data structure, and a batch query of size K/100.
",5. Experiments,[0],[0]
"• Decomp-MIPS: gradient evaluation via decomposed search (Algorithm 2, T = 1 iteration).",5. Experiments,[0],[0]
We divide the inner product into B = 8 factors in the multiclass experiment and B = 4 in the multilabel case.,5. Experiments,[0],[0]
The settings for MIPS data structure are the same as above.,5. Experiments,[0],[0]
"For multiclass classification we conduct experiments on the largest publicly available facial recognition dataset MegaFace (Challenge 2)2, where each identity is considered a class, and each sample is an image cropped by a face detector.",5.1. Multiclass Classificatoin,[0],[0]
"The data set statistics are shown in Table 1.
",5.1. Multiclass Classificatoin,[0],[0]
"We employ the FaceNet architecture (Schroff et al., 2015)3 pre-trained on the MS-Celeb-1M dataset, and fine-tune its last layer on the MegaFace dataset.",5.1. Multiclass Classificatoin,[0],[0]
"The input of the last layer is an embedding of size 128, which is divided into B = 8 factors, each of dimension 16, in the Decomp-MIPS method.
",5.1. Multiclass Classificatoin,[0],[0]
"The result is shown in Figure 1, where all methods are run for more than one day.",5.1. Multiclass Classificatoin,[0],[0]
"Firstly, comparing methods
2http://megaface.cs.washington.edu/. 3github.com/davidsandberg/facenet
that optimize the (smoothed) max-margin loss (DecompMIPS, MIPS and Margin) shows that both Decomp-MIPS, MIPS speed up the iterates by 1 ∼ 2 orders of magnitude.",5.1. Multiclass Classificatoin,[0],[0]
"However, MIPS converges at an accuracy much lower than Decomp-MIPS and the gap gets bigger when running for more iterations.",5.1. Multiclass Classificatoin,[0],[0]
Note the time and epochs are in log scale.,5.1. Multiclass Classificatoin,[0],[0]
"Secondly, Softmax has a much slower progress compared to Margin.",5.1. Multiclass Classificatoin,[0],[0]
"Note both of them do not even finish one epoch (4.7M samples) after one day, while the progress of Margin is much better, presumably because its focus on the confusing identities.",5.1. Multiclass Classificatoin,[0],[0]
"Sampled-Softmax has much faster iterates, but the progress per iterate is small, leading to slower overall progress compared to the MIPS-based approaches.",5.1. Multiclass Classificatoin,[0],[0]
"For multilabel classification, we conduct experiments on WikiLSHTC (Partalas et al., 2015), a benchmark data set in the Extreme Classification Repository4, where each class is a catalog tag in the Wikipedia, and each sample is a document with bag of words representation.",5.2. Multilabel Classification,[0],[0]
"The data statistics
4manikvarma.org/downloads/XC/ XMLRepository.html
are shown in Table 2.
",5.2. Multilabel Classification,[0],[0]
We train a one-hidden-layer fully-connected feedforward network for the multilabel classification task.,5.2. Multilabel Classification,[0],[0]
The first layer has input dimension equal to the vocabulary size (1.6M) and an output of dimension 100.,5.2. Multilabel Classification,[0],[0]
"The second layer has output size equal to the number of classes (325K), with different loss functions and approximations for different methods in comparison.",5.2. Multilabel Classification,[0],[0]
The training result also produces document and work embedding as by-products.,5.2. Multilabel Classification,[0],[0]
"For Decomp-MIPS, the input of the last layer is divided into B = 4 factors, each of dimension 25.
",5.2. Multilabel Classification,[0],[0]
We run all the compared methods for more than one day and the result is shown in Figure 2.,5.2. Multilabel Classification,[0],[0]
"First, for this multilabel task, Softmax has very good per-iteration progress, significantly more than that from the other three approaches based on the smoothed max-margin loss (Margin, MIPS, Decomp-MIPS).",5.2. Multilabel Classification,[0],[0]
"However, the iterates of Softmax are much slower than the others as it has a dense loss gradient and thus a slower backpropagation, so that when comparing training time, Softmax performs similarly to Margin.",5.2. Multilabel Classification,[0],[0]
"On the other hand, when comparing Margin Decomp-MIPS, and MIPS in progress per epoch, the updates of DecompMIPS achieve almost the same progress as the exact gradient calculation of Margin, while MIPS has a significant drop in its training accuracy compared with Margin and Decomp-MIPS, since it runs for more iterations.",5.2. Multilabel Classification,[0],[0]
"Overall, the MIPS-based methods lead to an order of magnitude speedup, while Decomp-MIPS retains the accuracy of the exact method.",5.2. Multilabel Classification,[0],[0]
"On the other hand, Sampled-Softmax has an extremely slow per-iteration progress despite its fast iterates, and could not reach a comparable accuracy to other methods even after one day.",5.2. Multilabel Classification,[0],[0]
"In this section, we evaluate the proposed gradient approximation technique on the word embedding task with the Skip-gram learning objective (9) and compare it with two widely-used gradient approximation methods — Hierarchical Softmax (Word2vec-HS) and Negative Sampling (Word2vec-Neg) (Mikolov et al., 2013) implemented in the
word2vec5 package released by the authors.",5.3. Unsupervised Word Embedding,[0],[0]
"The sample size for Word2vec-Neg is selected from {5, 10, 15, 20, 25}.
",5.3. Unsupervised Word Embedding,[0],[0]
We use the benchmark data set BillonW6 of almost a half million vocabulary size.,5.3. Unsupervised Word Embedding,[0],[0]
The data statistics are provided in Table 3.,5.3. Unsupervised Word Embedding,[0],[0]
"Following (Mikolov et al., 2013), we use a window of size 8 and subsample frequent words in the corpus.",5.3. Unsupervised Word Embedding,[0],[0]
"Each word w is dropped with probability max{1 − √ t fw , 0} where fw is the relative frequency of the word in the corpus, and t = 10−4 is a threshold parameter.
",5.3. Unsupervised Word Embedding,[0],[0]
"Note that the Skip-gram objective (9) is presented in a collapsed form equivalent to the one in (Mikolov et al., 2013).",5.3. Unsupervised Word Embedding,[0],[0]
"Here, all terms of the same input-output pairs are grouped together and weighted by the frequency.",5.3. Unsupervised Word Embedding,[0],[0]
"We compute gradients from the positive outputs by summing over the empirical input-output distribution qx, qy|x in (9).",5.3. Unsupervised Word Embedding,[0],[0]
Then we perform gradient descent (GD) updates on the parameters of input words {φ(x)}x∈X and output words {φ(y)}y∈X alternately.,5.3. Unsupervised Word Embedding,[0],[0]
"We use GD, GD-MIPS and GD-Decomp-MIPS to denote the algorithm with different strategies of loss approximations.",5.3. Unsupervised Word Embedding,[0],[0]
"As mentioned in Section 4, since in the early iterates the model has quite evenly distributed gradient over candidates, we use 1 epoch of Word2vec-Neg to initialize GD, GD-MIPS and GD-Decomp-MIPS.",5.3. Unsupervised Word Embedding,[0],[0]
"For this task, we have many more negative classes of significant gradient magnitude than in the multilabel and multiclass experiments.",5.3. Unsupervised Word Embedding,[0],[0]
So we use a batch query of size K/20 instead of K/100 to the MIPS structure.,5.3. Unsupervised Word Embedding,[0],[0]
"All the compared methods are parallelized with 24 CPU cores.
",5.3. Unsupervised Word Embedding,[0],[0]
The results are shown in Figure 3.,5.3. Unsupervised Word Embedding,[0],[0]
"After the first epoch, methods based on alternating gradient descent (GD) (with the collapsed objective (9)) have faster convergence per epoch, and the iterations of GD-Deomp-MIPS are 5 times faster than those of GD while having a significantly better objective value than GD-MIPS for the same training time.
",5.3. Unsupervised Word Embedding,[0],[0]
5code.google.com/archive/p/word2vec/ 6www.statmt.org/lm-benchmark/,5.3. Unsupervised Word Embedding,[0],[0]
I.Y. and P.R. acknowledge the support of NSF via IIS1149803.,Acknowledgements,[0],[0]
"For problems with large output spaces, evaluation of the loss function and its gradient are expensive, typically taking linear time in the size of the output space.",abstractText,[0],[0]
"Recently, methods have been developed to speed up learning via efficient data structures for Nearest-Neighbor Search (NNS) or Maximum Inner-Product Search (MIPS).",abstractText,[0],[0]
"However, the performance of such data structures typically degrades in high dimensions.",abstractText,[0],[0]
"In this work, we propose a novel technique to reduce the intractable high dimensional search problem to several much more tractable lower dimensional ones via dual decomposition of the loss function.",abstractText,[0],[0]
"At the same time, we demonstrate guaranteed convergence to the original loss via a greedy message passing procedure.",abstractText,[0],[0]
"In our experiments on multiclass and multilabel classification with hundreds of thousands of classes, as well as training skip-gram word embeddings with a vocabulary size of half a million, our technique consistently improves the accuracy of search-based gradient approximation methods and outperforms sampling-based gradient approximation methods by a large margin.",abstractText,[0],[0]
Loss Decomposition for Fast Learning in Large Output Spaces,title,[0],[0]
"discrete probability distribution, or to estimate its normalizing partition function. The method relies on repeatedly applying a random perturbation to the distribution in a particular way, each time solving for the most likely configuration. We derive an entire family of related methods, of which the Gumbel trick is one member, and show that the new methods have superior properties in several settings with minimal additional computational cost. In particular, for the Gumbel trick to yield computational benefits for discrete graphical models, Gumbel perturbations on all configurations are typically replaced with socalled low-rank perturbations. We show how a subfamily of our new methods adapts to this setting, proving new upper and lower bounds on the log partition function and deriving a family of sequential samplers for the Gibbs distribution. Finally, we balance the discussion by showing how the simpler analytical form of the Gumbel trick enables additional theoretical results.",text,[0],[0]
In this work we are concerned with the fundamental problem of sampling from a discrete probability distribution and evaluating its normalizing constant.,1. Introduction,[0],[0]
A probability distribution p on a discrete sample space X is provided in terms of its potential function : X !,1. Introduction,[0],[0]
"[ 1,1), corresponding to log-unnormalized probabilities via p(x) = e (x)/Z, where the normalizing constant Z is the partition function.",1. Introduction,[0],[0]
"In this context, p is the Gibbs distribution on X associated with the potential function .",1. Introduction,[0],[0]
"The challenges of sampling from such a discrete probability distribution and estimating the partition function are fundamental problems with ubiq-
1
University of Cambridge, UK
2
MPI-IS, T¨ubingen, Germany
3
UC Berkeley, USA
4
Uber AI Labs, USA
5
Alan Turing Institute,
UK.",1. Introduction,[0],[0]
Correspondence to: Matej Balog <first.last@gmail.com>.,1. Introduction,[0],[0]
"Code: https://github.com/matejbalog/gumbel-relatives.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
uitous applications in machine learning, classical statistics and statistical physics (see, e.g., Lauritzen, 1996).",1. Introduction,[0],[0]
"Perturb-and-MAP methods (Papandreou & Yuille, 2010) constitute a class of randomized algorithms for estimating partition functions and sampling from Gibbs distributions, which operate by randomly perturbing the corresponding potential functions and employing maximum a posteriori (MAP) solvers on the perturbed models to find a maximum probability configuration.",1. Introduction,[0],[0]
"This MAP problem is NP-hard in general; however, substantial research effort has led to the development of solvers which can efficiently compute or estimate the MAP solution on many problems that occur in practice (e.g., Boykov et al., 2001; Kolmogorov, 2006; Darbon, 2009).",1. Introduction,[0],[0]
"Evaluating the partition function is a harder problem, containing for instance #P-hard counting problems.",1. Introduction,[0],[0]
"The general aim of perturb-and-MAP methods is to reduce the problem of partition function evaluation, or the problem of sampling from the Gibbs distribution, to repeated instances of the MAP problem (where each instance is on a different random perturbation of the original model).
",1. Introduction,[0],[0]
"The Gumbel trick (Papandreou & Yuille, 2011) relies on adding Gumbel-distributed noise to each configuration’s potential (x).",1. Introduction,[0],[0]
We derive a wider family of perturb-andMAP methods that can be seen as perturbing the model in different ways – in particular using the Weibull and Fr´echet distributions alongside the Gumbel.,1. Introduction,[0],[0]
"We show that the new methods can be implemented with essentially no additional computational cost by simply averaging existing Gumbel MAP perturbations in different spaces, and that they can lead to more accurate estimators of the partition function.
",1. Introduction,[0],[0]
Evaluating or perturbing each configuration’s potential with i.i.d.,1. Introduction,[0],[0]
Gumbel noise can be computationally expensive.,1. Introduction,[0],[0]
"One way to mitigate this is to cleverly prune computation in regions where the maximum perturbed potential is unlikely to be found (Maddison et al., 2014; Chen & Ghahramani, 2016).",1. Introduction,[0],[0]
"Another approach exploits the product structure of the sample space in discrete graphical models, replacing i.i.d.",1. Introduction,[0],[0]
Gumbel noise with a “low-rank” approximation.,1. Introduction,[0],[0]
"Hazan & Jaakkola (2012); Hazan et al. (2013) showed that from such an approximation, upper and lower bounds on the partition function and a sequential sampler for the Gibbs distribution can still be recovered.",1. Introduction,[0],[0]
"We show that a subfamily of our new methods, consisting of Fr´echet, Exponential and Weibull tricks, can also be used with low-
rank perturbations, and use these tricks to derive new upper and lower bounds on the partition function, and to construct new sequential samplers for the Gibbs distribution.
",1. Introduction,[0],[0]
"Our main contributions are as follows:
1.",1. Introduction,[0],[0]
"A family of tricks that can be implemented by simply
averaging Gumbel perturbations in different spaces, and which can lead to more accurate or more sample effi-
cient estimators of Z (Section 2).",1. Introduction,[0],[0]
2.,1. Introduction,[0],[0]
"New upper and lower bounds on the partition function of
a discrete graphical model computable using low-rank perturbations, and a corresponding family of sequential samplers for the Gibbs distribution (Section 3).",1. Introduction,[0],[0]
3.,1. Introduction,[0],[0]
"Discussion of advantages of the simpler analytical form
of the Gumbel trick including new links between the errors of estimating Z, sampling, and entropy estimation using low-rank Gumbel perturbations (Section 4).
",1. Introduction,[0],[0]
"Background and Related work The idea of perturbing the potential function of a discrete graphical model in order to sample from its associated Gibbs distribution was introduced by Papandreou & Yuille (2011), inspired by their previous work on reducing the sampling problem for Gaussian Markov random fields to the problem of finding the mean, using independent local perturbations of each Gaussian factor (Papandreou & Yuille, 2010).",1. Introduction,[0],[0]
"Tarlow et al. (2012) extended this perturb-and-MAP approach to sampling, in particular by considering more general structured prediction problems.",1. Introduction,[0],[0]
"Hazan & Jaakkola (2012) pointed out that MAP perturbations are useful not only for sampling the Gibbs distribution (considering the argmax of the perturbed model), but also for bounding and approximating the partition function (by considering the value of the max).
",1. Introduction,[0],[0]
"Afterwards, Hazan et al. (2013) derived new lower bounds on the partition function and proposed a new sampler for the Gibbs distribution that samples variables of a discrete graphical model sequentially, using expected values of lowrank MAP perturbations to construct the conditional probabilities.",1. Introduction,[0],[0]
"Due to the low-rank approximation, this algorithm has the option to reject a sample.",1. Introduction,[0],[0]
Orabona et al. (2014) and Hazan et al. (2016) subsequently derived measure concentration results for the Gumbel distribution that can be used to control the rejection probability.,1. Introduction,[0],[0]
"Maji et al. (2014) derived an uncertainty measure from random MAP perturbations, using it within a Bayesian active learning framework for interactive image boundary annotation.
",1. Introduction,[0],[0]
"Perturb-and-MAP was famously generalized to continuous spaces by Maddison et al. (2014), replacing the Gumbel distribution with a Gumbel process and calling the resulting algorithm A* sampling.",1. Introduction,[0],[0]
"Maddison (2016) cast this work into a unified framework together with adaptive rejection sampling techniques, based on the notion of exponential races.",1. Introduction,[0],[0]
"This recent view generally brings together perturb-
and-MAP and accept-reject samplers, exploiting the connection between the Gumbel distribution and competing exponential clocks that we also discuss in Section 2.1.
",1. Introduction,[0],[0]
"Inspired by A* sampling, Kim et al. (2016) proposed an exact sampler for discrete graphical models based on lazilyinstantiated random perturbations, which uses linear programming relaxations to prune the optimization space.",1. Introduction,[0],[0]
"Further recent applications of perturb-and-MAP include structured prediction in computer vision (Bertasius et al., 2017) and turning the discrete sampling problem into an optimization task that can be cast as a multi-armed bandit problem (Chen & Ghahramani, 2016), see Section 5.2 below.
",1. Introduction,[0],[0]
"In addition to perturb-and-MAP methods, we are aware of three other approaches to estimate the partition function of a discrete graphical model via MAP solver calls.",1. Introduction,[0],[0]
"The WISH method (weighted-integrals-and-sums-by-hashing, Ermon et al., 2013) relies on repeated MAP inference calls applied to the model after subjecting it to random hash constraints.",1. Introduction,[0],[0]
"The Frank-Wolfe method may be applied by iteratively updating marginals using a constrained MAP solver and line search (Belanger et al., 2013; Krishnan et al., 2015).",1. Introduction,[0],[0]
"Weller & Jebara (2014a) instead use just one MAP call over a discretized mesh of marginals to approximate the Bethe partition function, which itself is an estimate (which often performs well) of the true partition function.",1. Introduction,[0],[0]
"In this section, we review the Gumbel trick and state the mechanism by which it can be generalized into an entire family of tricks.",2. Relatives of the Gumbel Trick,[0],[0]
"We show how these tricks can equivalently be viewed as averaging standard Gumbel perturbations in different spaces, instantiate several examples, and compare the various tricks’ properties.
",2. Relatives of the Gumbel Trick,[0],[0]
"Notation Throughout this paper, let X be a finite sample space of size N := |X |.",2. Relatives of the Gumbel Trick,[0],[0]
Let p̃ : X !,2. Relatives of the Gumbel Trick,[0],[0]
"[0,1) be an unnormalized mass function over X and let Z := P
x2X p̃(x) be its normalizing partition function.",2. Relatives of the Gumbel Trick,[0],[0]
"Write p(x) := p̃(x)/Z for the normalized version of p̃, and (x) := ln p̃(x) for the log-unnormalized probabilities, i.e. the potential function.
",2. Relatives of the Gumbel Trick,[0],[0]
We write Exp( ) for the exponential distribution with rate (inverse mean) and Gumbel(µ) for the Gumbel distribution with location µ and scale 1.,2. Relatives of the Gumbel Trick,[0],[0]
"The latter has mean µ+ c, where c ⇡ 0.5772 is the Euler-Mascheroni constant.",2. Relatives of the Gumbel Trick,[0],[0]
"Similarly to the connection between the Gumbel trick and the Poisson process established by Maddison (2016), we introduce the Gumbel trick for discrete probability distributions using a simple and elegant construction via competing exponential clocks.",2.1. The Gumbel Trick,[0],[0]
"Consider N independent clocks,
started simultaneously, such that the j-th clock rings after a random time T
j ⇠ Exp( j ).",2.1. The Gumbel Trick,[0],[0]
"Then it is easy to show that
(1) the time until some clock rings has Exp(
P
N j=1 j ) dis-
tribution, and (2) the probability of the j-th clock ringing first is proportional to its rate
j
.",2.1. The Gumbel Trick,[0],[0]
"These properties are also
widely used in survival analysis (Cox & Oakes, 1984).",2.1. The Gumbel Trick,[0],[0]
"Consider N competing exponential clocks {T x } x2X , indexed by elements of X , with respective rates x
= p̃(x).",2.1. The Gumbel Trick,[0],[0]
"Property (1) of competing exponential clocks tells us that
min x2X {T x } ⇠ Exp(Z).",2.1. The Gumbel Trick,[0],[0]
"(1)
Property (2) says that the random variable argmin
x
T x , tak-
ing values in X , is distributed according to p:
argmin x2X {T x } ⇠ p. (2)
",2.1. The Gumbel Trick,[0],[0]
The Gumbel trick is obtained by applying the function g(x) =,2.1. The Gumbel Trick,[0],[0]
lnx c to the equalities in distribution (1) and (2).,2.1. The Gumbel Trick,[0],[0]
"When g is applied to an Exp( ) random variable, the result follows the Gumbel( c + ln ) distribution, which can also be represented as ln + , where
⇠ Gumbel( c).",2.1. The Gumbel Trick,[0],[0]
Defining { (x)} x2X i.i.d.⇠,2.1. The Gumbel Trick,[0],[0]
"Gumbel( c) and noting that g is strictly decreasing, applying the function g to equalities in distribution (1) and (2), we obtain:
max x2X { (x) +",2.1. The Gumbel Trick,[0],[0]
"(x)} ⇠ Gumbel( c+ lnZ), (1’)
argmax x2X { (x) + (x)} ⇠ p, (2’)
where we have recalled that (x) =",2.1. The Gumbel Trick,[0],[0]
ln x = ln p̃(x).,2.1. The Gumbel Trick,[0],[0]
"The distribution Gumbel( c + lnZ) has mean lnZ, and thus the log partition function can be estimated by averaging samples (Hazan & Jaakkola, 2012).",2.1. The Gumbel Trick,[0],[0]
"Given the equality in distribution (1), we can treat the problem of estimating the partition function Z as a parameter estimation problem for the exponential distribution.",2.2. Constructing New Tricks,[0],[0]
Applying the function g(x) =,2.2. Constructing New Tricks,[0],[0]
lnx c,2.2. Constructing New Tricks,[0],[0]
"as in the Gumbel trick to obtain a Gumbel( c+ lnZ) random variable, and
estimating its mean to obtain an unbiased estimator of lnZ, is just one way of inferring information about Z.
We consider applying different functions g to (1); particularly those functions g that transform the exponential distribution to another distribution with known mean.",2.2. Constructing New Tricks,[0],[0]
"As the original exponential distribution has rate Z, the transformed distribution will have mean f(Z), where f will in general no longer be the logarithm function.",2.2. Constructing New Tricks,[0],[0]
"Since we often are interested in estimating various transformations f(Z) of Z, this provides us a with a collection of unbiased estimators from which to choose.",2.2. Constructing New Tricks,[0],[0]
"Moreover, further transforming these estimators yields a collection of (biased) estimators for other transformations of Z, including Z itself.",2.2. Constructing New Tricks,[0],[0]
Example 1 (Weibull tricks).,2.2. Constructing New Tricks,[0],[0]
"For any ↵ > 0, applying the function g(x) = x↵ to an Exp( ) random variable yields a random variable with the Weibull( ↵,↵ 1) distribution with scale ↵ and shape ↵ 1, which has mean ↵ (1 + ↵) and can be also represented as ↵W , where W ⇠ Weibull(1,↵ 1).",2.2. Constructing New Tricks,[0],[0]
"Defining {W (x)} x2X
i.i.d.⇠ Weibull(1,↵ 1) and noting that g is increasing, applying g to the equality in distribution (1) gives
min x2X {p̃ ↵W (x)} ⇠Weibull(Z ↵,↵ 1).",2.2. Constructing New Tricks,[0],[0]
"(1”)
Estimating the mean of Weibull(Z ↵,↵ 1) yields an unbiased estimator of Z ↵ (1 + ↵).",2.2. Constructing New Tricks,[0],[0]
"The special case ↵ = 1 corresponds to the identity function g(x) = x; we call the resulting trick the Exponential trick.
",2.2. Constructing New Tricks,[0],[0]
Table 1 lists several examples of tricks derived this way.,2.2. Constructing New Tricks,[0],[0]
"As Example 1 shows, these tricks may not involve additive perturbation of the potential function (x); the Weibull tricks multiplicatively perturb exponentiated unnormalized probabilities",2.2. Constructing New Tricks,[0],[0]
p̃ ↵ with Weibull noise.,2.2. Constructing New Tricks,[0],[0]
"As models of interest are often specified in terms of potential functions, to be able to reuse existing MAP solvers in a black-box manner with the new tricks, we seek an equivalent formulation in terms of the potential function.",2.2. Constructing New Tricks,[0],[0]
"The following Proposition shows that by not passing the function g through the minimization in equation (1), the new tricks can be equivalently formulated as averaging additive Gumbel perturbations of the potential function in different spaces.
",2.2. Constructing New Tricks,[0],[0]
Proposition 2.,2.2. Constructing New Tricks,[0],[0]
"For any function g : [0,1)!",2.2. Constructing New Tricks,[0],[0]
"R such that f(Z) = E
T⇠Exp(Z)[g(T )] exists, we have
f(Z) =",2.2. Constructing New Tricks,[0],[0]
"E

g
✓
e c exp
✓
max x2X
{ (x) +",2.2. Constructing New Tricks,[0],[0]
"(x)} ◆◆ ,
where { (x)} x2X i.i.d.⇠",2.2. Constructing New Tricks,[0],[0]
"Gumbel( c).
",2.2. Constructing New Tricks,[0],[0]
Proof.,2.2. Constructing New Tricks,[0],[0]
As max x { (x) +,2.2. Constructing New Tricks,[0],[0]
"(x)} ⇠ Gumbel( c + lnZ), we have e c exp(max
x { (x)+ (x)}) ⇠ Exp(Z) and the result follows by the assumption relating f and g.
Proposition 2 shows that the new tricks can be implemented by solving the same MAP problems max
x { (x)+ (x)} as in the Gumbel trick, and then merely passing the solutions through the function x 7!",2.2. Constructing New Tricks,[0],[0]
g(e c,2.2. Constructing New Tricks,[0],[0]
exp(x)),2.2. Constructing New Tricks,[0],[0]
before averaging them to approximate the expectation.,2.2. Constructing New Tricks,[0],[0]
"The Delta method (Casella & Berger, 2002) is a simple technique for assessing the asymptotic variance of estimators that are obtained by a differentiable transformation of an estimator with known variance.",2.3.1. ASYMPTOTIC EFFICIENCY,[0],[0]
"The last column in Table 1 lists asymptotic variances of corresponding tricks when unbiased estimators of f(Z) are passed through the function f 1 to yield (biased, but consistent and non-negative) estimators of Z itself.",2.3.1. ASYMPTOTIC EFFICIENCY,[0],[0]
It is interesting to examine the constants that multiply Z2 in some of the obtained asymptotic variance expressions for the different tricks.,2.3.1. ASYMPTOTIC EFFICIENCY,[0],[0]
"For example, it can be shown using Gurland’s ratio (Gurland, 1956) that this constant is at least 1 for the Weibull and Fr´echet tricks, which is precisely the value achieved by the Exponential trick (which corresponds to ↵ = 1).",2.3.1. ASYMPTOTIC EFFICIENCY,[0],[0]
"Moreover, the Gumbel trick constant ⇡2/6 can be shown to be the limit as ↵ ! 0",2.3.1. ASYMPTOTIC EFFICIENCY,[0],[0]
of the Weibull and Fr´echet trick constants,2.3.1. ASYMPTOTIC EFFICIENCY,[0],[0]
.,2.3.1. ASYMPTOTIC EFFICIENCY,[0],[0]
"In particular, the constant of the Exponential trick is strictly better than that of the standard Gumbel trick: 1 < ⇡2/6 ⇡ 1.65.",2.3.1. ASYMPTOTIC EFFICIENCY,[0],[0]
This motivates us to compare the Gumbel and Exponential tricks in more detail.,2.3.1. ASYMPTOTIC EFFICIENCY,[0],[0]
"For estimators Y , their MSE(Y ) =",2.3.2. MEAN SQUARED ERROR (MSE),[0],[0]
var(Y ),2.3.2. MEAN SQUARED ERROR (MSE),[0],[0]
+ bias(Y )2 is a commonly used comparison metric.,2.3.2. MEAN SQUARED ERROR (MSE),[0],[0]
"When the Gumbel or Exponential tricks are used to estimate either Z or lnZ, the biases, variances, and MSEs of the estimators can be computed analytically using standard methods (Appendix A).
",2.3.2. MEAN SQUARED ERROR (MSE),[0],[0]
"For example, the unbiased estimator of lnZ from the Gumbel trick can be turned into a consistent non-negative estimator of Z by exponentiation: Y = exp( 1 M P M m=1 X m ), where X 1 , . . .",2.3.2. MEAN SQUARED ERROR (MSE),[0],[0]
", X M
i.i.d.⇠",2.3.2. MEAN SQUARED ERROR (MSE),[0],[0]
Gumbel( c + lnZ) are obtained using equation (1’).,2.3.2. MEAN SQUARED ERROR (MSE),[0],[0]
"The bias and variance of Y can be computed using independence and the moment generating functions of the X m ’s, see Appendix A for details.
",2.3.2. MEAN SQUARED ERROR (MSE),[0],[0]
"Perhaps surprisingly, all estimator properties only depend on the true value of Z and not on the structure of the model (distribution p), since the estimators rely only on i.i.d. samples of a Gumbel( c + lnZ) random variable.",2.3.2. MEAN SQUARED ERROR (MSE),[0],[0]
Figure 1 shows the analytically computed estimator variances and MSEs.,2.3.2. MEAN SQUARED ERROR (MSE),[0],[0]
"For estimating Z itself (left), the Exponential trick outperforms the Gumbel trick in terms of MSE for all sample sizes M 3 (for M 2 {1, 2}, both estimators have infinite variance and MSE).",2.3.2. MEAN SQUARED ERROR (MSE),[0],[0]
"The ratio of MSEs quickly approaches ⇡2/6, and in this regime the Exponential trick requires 1 6/⇡2 ⇡ 39% fewer samples than the Gumbel trick to reach the same MSE.",2.3.2. MEAN SQUARED ERROR (MSE),[0],[0]
"Also, for estimating lnZ, (Figure 1, right), the Exponential trick provides a lower MSE estimator for sample sizes M 2; only for M = 1 the Gumbel trick provides a better estimator.
",2.3.2. MEAN SQUARED ERROR (MSE),[0],[0]
"Note that as biases are available analytically, the estimators can be easily debiased (by subtracting their bias).",2.3.2. MEAN SQUARED ERROR (MSE),[0],[0]
"One then obtain estimators with MSEs equal to the variances of the original estimators, shown dashed in Figure 1.",2.3.2. MEAN SQUARED ERROR (MSE),[0],[0]
"The Exponential trick would then always outperform the Gumbel trick when estimating lnZ, even with sample size M = 1.",2.3.2. MEAN SQUARED ERROR (MSE),[0],[0]
"For Weibull tricks with ↵ 6= 1 and Fr´echet tricks, we estimated the biases and variances of estimators of Z and lnZ by constructing K = 100, 000 estimators in each case and evaluating their bias and variance.",2.3.2. MEAN SQUARED ERROR (MSE),[0],[0]
Figure 2 shows the results for varying ↵ and several sample sizes M .,2.3.2. MEAN SQUARED ERROR (MSE),[0],[0]
"We plot the
analytically computed value for the Gumbel trick at ↵ = 0, as we observe that the Weibull trick interpolates between the Gumbel trick and the Exponential trick as ↵ increases from 0 to 1.",2.3.2. MEAN SQUARED ERROR (MSE),[0],[0]
"We note that the minimum MSE estimator is obtained by choosing a value of ↵ that is close to 1, i.e. the Exponential trick.",2.3.2. MEAN SQUARED ERROR (MSE),[0],[0]
This agrees with the finding from Section 2.3.1 that ↵ = 1 is optimal as M !1.,2.3.2. MEAN SQUARED ERROR (MSE),[0],[0]
"A Bayesian approach exposes two choices when constructing estimators of Z, or of its transformations f(Z):
1.",2.4. Bayesian Perspective,[0],[0]
"A choice of prior distribution p 0 (Z), encoding prior beliefs about the value of Z before any observations.",2.4. Bayesian Perspective,[0],[0]
2.,2.4. Bayesian Perspective,[0],[0]
"A choice of how to summarize the posterior distribu-
tion p M (Z|X 1 , . . .",2.4. Bayesian Perspective,[0],[0]
", X M ) given M samples.
",2.4. Bayesian Perspective,[0],[0]
Taking the Jeffrey’s prior p 0,2.4. Bayesian Perspective,[0],[0]
"(Z) / Z 1, an improper prior that it is invariant under reparametrization, observing M samples X 1 , . . .",2.4. Bayesian Perspective,[0],[0]
", X M i.i.d.⇠ Exp(Z) yields the posterior:
p M (Z|X 1 , . . .",2.4. Bayesian Perspective,[0],[0]
", X M ) /",2.4. Bayesian Perspective,[0],[0]
"ZM 1e Z P M m=1 Xm .
",2.4. Bayesian Perspective,[0],[0]
"Recognizing the density of a Gamma(M, P M
m=1
X m ) ran-
dom variable, the posterior mean is
E[Z|X 1 , . . .",2.4. Bayesian Perspective,[0],[0]
", X M ] = M P
M m=1 X m
=
1
M
M
X
m=1
X m
!",2.4. Bayesian Perspective,[0],[0]
"1
,
coinciding with the Exponential trick estimator of Z.",2.4. Bayesian Perspective,[0],[0]
One way of exploiting perturb-and-MAP to yield computational savings is to replace independent perturbations of each configuration’s potential with an approximation.,3. Low-rank Perturbations,[0],[0]
"Such approximations are available e.g. in discrete graphical models, where the sampling space X has a product space structure X = X
1 ⇥ · · · ⇥",3. Low-rank Perturbations,[0],[0]
"X n , with X i the state space of
the i-th variable.",3. Low-rank Perturbations,[0],[0]
"Definition 3 ( (Hazan & Jaakkola, 2012)).",3. Low-rank Perturbations,[0],[0]
"The sum-unary perturbation MAP value is the random variable
U := max x2X
n",3. Low-rank Perturbations,[0],[0]
(x) + n,3. Low-rank Perturbations,[0],[0]
"X
i=1
i (x i )
o
,
where { i (x i )",3. Low-rank Perturbations,[0],[0]
"| x i 2 X i , 1  ",3. Low-rank Perturbations,[0],[0]
"i  n} i.i.d⇠ Gumbel( c).
",3. Low-rank Perturbations,[0],[0]
This definition involves |X 1 |+ · · ·+ |X n,3. Low-rank Perturbations,[0],[0]
| i.i.d.,3. Low-rank Perturbations,[0],[0]
"Gumbel random variables, rather than |X |.",3. Low-rank Perturbations,[0],[0]
(With n = 1 this coincides with full-rank perturbations and U ⇠,3. Low-rank Perturbations,[0],[0]
Gumbel( c+lnZ).),3. Low-rank Perturbations,[0],[0]
For n > 2 the distribution of U is not available analytically.,3. Low-rank Perturbations,[0],[0]
"One can similarly define the pairwise (or higher-order) perturbations, where independent Gumbel noise is added to each pairwise (or higher-order) potential.
",3. Low-rank Perturbations,[0],[0]
"Unary perturbations provide the upper bound lnZ  E[U ] on the log partition function (Hazan & Jaakkola, 2012), can be used to construct a sequential sampler for the Gibbs distribution (Hazan et al., 2013), and, if the perturbations are scaled down by a factor of n, a lower bound on lnZ can also be recovered (Hazan et al., 2013).",3. Low-rank Perturbations,[0],[0]
"In this section we show that a subfamily of tricks introduced in Section 2, consisting of Fr´echet and Weibull (and Exponential) tricks, is applicable in the low-rank perturbation setting and use them to derive new families of upper and lower bounds on lnZ and sequential samplers for the Gibbs distribution.",3. Low-rank Perturbations,[0],[0]
Please note full proofs are deferred to Appendix B and C.,3. Low-rank Perturbations,[0],[0]
The following family of upper bounds on lnZ can be derived from the Fr´echet and Weibull tricks.,3.1. Upper Bounds on the Partition Function,[0],[0]
Proposition 4.,3.1. Upper Bounds on the Partition Function,[0],[0]
"For any ↵ 2 ( 1, 0)",3.1. Upper Bounds on the Partition Function,[0],[0]
"[ (0,1), the upper bound lnZ  U(↵) holds with
U(↵) := n ln (1 + ↵) ↵ + nc 1 ↵ lnE ⇥",3.1. Upper Bounds on the Partition Function,[0],[0]
"e ↵U ⇤ .
",3.1. Upper Bounds on the Partition Function,[0],[0]
Proof.,3.1. Upper Bounds on the Partition Function,[0],[0]
(Sketch.),3.1. Upper Bounds on the Partition Function,[0],[0]
"By induction on n, with the induction step provided by our Clamping Lemma (Lemma 7) below.
",3.1. Upper Bounds on the Partition Function,[0],[0]
"To evaluate these bounds in practice, E[e ↵U ] is estimated using samples of U .",3.1. Upper Bounds on the Partition Function,[0],[0]
"Corollary 9 of Hazan et al. (2016) can be used to show that var(e ↵U ) is finite for ↵ > 1
2 p n ,
and so then the estimation is well-behaved.
",3.1. Upper Bounds on the Partition Function,[0],[0]
A natural question is how these new bounds relate to the Gumbel trick upper bound lnZ  E[U ] by Hazan & Jaakkola (2012).,3.1. Upper Bounds on the Partition Function,[0],[0]
The following result aims to answers this: Proposition 5.,3.1. Upper Bounds on the Partition Function,[0],[0]
"The limit of U(↵) as ↵ ! 0 exists and equals U(0) := E[U ], i.e. the Gumbel trick upper bound.
",3.1. Upper Bounds on the Partition Function,[0],[0]
The question remains: When is it advantageous to use a value ↵ 6= 0 to obtain a tighter bound on lnZ than the Gumbel trick bound?,3.1. Upper Bounds on the Partition Function,[0],[0]
The next result can provide guidance: Proposition 6.,3.1. Upper Bounds on the Partition Function,[0],[0]
"The function U(↵) is differentiable at ↵ = 0 and the derivative equals
d d↵ U(↵)
↵=0
=
1
2
✓
n ⇡2
6
var(U) ◆ .
",3.1. Upper Bounds on the Partition Function,[0],[0]
"While the variance of U is generally not tractable, in practice one obtains samples from U to estimate the expectation in U(↵) and these samples can be reused to assess var(U).",3.1. Upper Bounds on the Partition Function,[0],[0]
"Interestingly, var(U) equals n⇡2/6 for both the uniform distribution and the distribution concentrated on a single configuration, and in our empirical investigations always var(U)  n⇡2/6.",3.1. Upper Bounds on the Partition Function,[0],[0]
Then the derivative at 0 is non-negative and Fr´echet tricks provide tighter bounds on lnZ.,3.1. Upper Bounds on the Partition Function,[0],[0]
"However, as U(↵) is estimated with samples, the question of
estimator variance arises.",3.1. Upper Bounds on the Partition Function,[0],[0]
We investigate the trade-off between tightness of the bound lnZ  U(↵) and the variance incurred in estimating U(↵) empirically in Section 5.3.,3.1. Upper Bounds on the Partition Function,[0],[0]
"Consider the partial sum-unary perturbation MAP values, where the values of the first j 1 variables have been fixed, and only the rest are perturbed:
U j (x 1 , . . .",3.2. Clamping,[0],[0]
", x j 1) := max
x
j
,...,x
n
8 <
:
(x) + n",3.2. Clamping,[0],[0]
"X
i=j
i",3.2. Clamping,[0],[0]
"(x i )
9 =
;
.
",3.2. Clamping,[0],[0]
"The following lemma involving the U j ’s serves three purposes: (I.) it provides the induction step for Proposition 4, (II.)",3.2. Clamping,[0],[0]
"it shows that clamping never hurts partition function estimation with Fr´echet and Weibull tricks, and (III.)",3.2. Clamping,[0],[0]
it will be used to show that a sequential sampler constructed in Section 3.3 below is well-defined.,3.2. Clamping,[0],[0]
Lemma 7 (Clamping Lemma).,3.2. Clamping,[0],[0]
"For any j 2 {1, . . .",3.2. Clamping,[0],[0]
", n} and (x
1 , . . .",3.2. Clamping,[0],[0]
", x j 1) 2 X1 ⇥ · · · ⇥",3.2. Clamping,[0],[0]
"Xj 1, the following in-
equality holds with any ↵ 2 ( 1, 0)",3.2. Clamping,[0],[0]
"[ (0,1):
X
x
j 2X j
E
h e (n j) ln (1+↵) ↵(n j)c)e ↵Uj+1 i 1/↵
 E
h e (n (j 1))",3.2. Clamping,[0],[0]
"ln (1+↵) ↵(n (j 1))c)e ↵Uj i 1/↵
Proof.",3.2. Clamping,[0],[0]
"This follows directly from the Fr´echet trick (↵ 2 ( 1, 0)) or the Weibull trick (↵ > 0) and representing the Fr´echet resp.",3.2. Clamping,[0],[0]
Weibull random variables in terms of Gumbel random variables.,3.2. Clamping,[0],[0]
"See Appendix B.1 for more details.
",3.2. Clamping,[0],[0]
Corollary 8.,3.2. Clamping,[0],[0]
"Clamping never hurts lnZ estimation using any of the Fréchet or Weibull upper bounds U(↵).
",3.2. Clamping,[0],[0]
Proof.,3.2. Clamping,[0],[0]
"Applying the function x 7! ln(x) to both sides of the Clamping Lemma 7 with j = 1, the right-hand side equals U(↵), while the left-hand side is the estimate of lnZ after clamping variable x
1
.
",3.2. Clamping,[0],[0]
"This was shown previously in restricted settings (Hazan et al., 2013; Zhao et al., 2016).",3.2. Clamping,[0],[0]
"Similar results showing that clamping improves partition function estimation have been obtained for the mean field and TRW approximations (Weller & Domke, 2016), and in certain settings for the Bethe approximation (Weller & Jebara, 2014b) and LFIELD (Zhao et al., 2016).",3.2. Clamping,[0],[0]
Hazan et al. (2013) derived a sequential sampling procedure for the Gibbs distribution by exploiting the U(0) Gumbel trick upper bound on lnZ.,3.3. Sequential Sampling,[0],[0]
"In the same spirit, one
can derive sequential sampling procedures from the Fr´echet and Weibull tricks, leading to the following algorithm.
",3.3. Sequential Sampling,[0],[0]
"Algorithm 1 Sequential sampler for Gibbs distribution Input: ↵ 2 ( 1, 0)",3.3. Sequential Sampling,[0],[0]
"[ (0,1), potential function on X Output: a sample x from the Gibbs distribution / e (x)
1: for j = 1 to n do 2: for x
j 2 X j do
3: p j (x j
) e c
(1+↵)
1/↵
E
[
e
↵U j+1(x1,...,xj)
]
1/↵
E
[
e
↵U j (x1,...,x j 1)
]
1/↵
4: p j
(reject) 1 P
x
j 2X j
p j",3.3. Sequential Sampling,[0],[0]
"(x j )
5: x j
sample according to p j
6: if x j == reject then 7: RESTART (goto 1)
",3.3. Sequential Sampling,[0],[0]
"This algorithm is well-defined if p j (reject) 0 for all j, which can be shown by canceling terms in the Clamping Lemma 7.",3.3. Sequential Sampling,[0],[0]
We discuss correctness in Appendix B.2.,3.3. Sequential Sampling,[0],[0]
"As for the Gumbel sequential sampler of Hazan et al. (2013), the expected number of restarts (and hence the running time) only depend on the quality of the upper bound (U(↵) lnZ), and not on the ordering of variables.",3.3. Sequential Sampling,[0],[0]
"Similarly as in the Gumbel trick case (Hazan et al., 2013), one can derive lower bounds on lnZ by perturbing an arbitrary subset S of variables.",3.4. Lower Bounds on the Partition Function,[0],[0]
Proposition 9.,3.4. Lower Bounds on the Partition Function,[0],[0]
"Let X = X 1 ⇥ · · · X n
be a product space and a potential function on X .",3.4. Lower Bounds on the Partition Function,[0],[0]
"Let ↵ 2 ( 1, 0)[ (0,1).",3.4. Lower Bounds on the Partition Function,[0],[0]
"For any subset S ✓ {1, . . .",3.4. Lower Bounds on the Partition Function,[0],[0]
", n} of the variables x
1 , . . .",3.4. Lower Bounds on the Partition Function,[0],[0]
", x n
we have lnZ
c+ ln (1 + ↵)
↵ 1 ↵ lnE
h e ↵maxx{ (x)+ S(xS)} i ,
where x S := {x i :",3.4. Lower Bounds on the Partition Function,[0],[0]
i 2 S} and S (x S ) ⇠,3.4. Lower Bounds on the Partition Function,[0],[0]
"Gumbel( c) independently for each setting of x
S
.
",3.4. Lower Bounds on the Partition Function,[0],[0]
"By averaging n such lower bounds corresponding to singleton sets S = {i} together, we obtain a lower bound on lnZ that involves the average-unary perturbation MAP value
L := max x2X
(
(x) + 1
n
n
X
i=1
i (x i )
)
.
",3.4. Lower Bounds on the Partition Function,[0],[0]
Corollary 10.,3.4. Lower Bounds on the Partition Function,[0],[0]
"For any ↵ 2 ( 1, 0)",3.4. Lower Bounds on the Partition Function,[0],[0]
"[ (0,1), we have the lower bound lnZ L(↵), where
L(↵) := c+ ln (1 + ↵) ↵ 1 n↵ lnE",3.4. Lower Bounds on the Partition Function,[0],[0]
"[exp ( n↵L)] .
",3.4. Lower Bounds on the Partition Function,[0],[0]
"Again, L(0) := E[L] can be defined by continuity, where E[L]  lnZ is the Gumbel trick lower bound by Hazan et al. (2013).",3.4. Lower Bounds on the Partition Function,[0],[0]
"We have seen how the Gumbel trick can be embedded into a continuous family of tricks, consisting of Fr´echet, Exponential, and Weibull tricks.",4. Advantages of the Gumbel Trick,[0],[0]
"We showed that the new tricks can provide more efficient estimators of the partition function in the full-rank perturbation setting (Section 2), and in the low-rank perturbation setting lead to sequential samplers and new bounds on lnZ, which can be also more efficient, as we investigate in Section 5.3.",4. Advantages of the Gumbel Trick,[0],[0]
"To balance the discussion of merits of different tricks, in this section we briefly highlight advantages of the Gumbel trick that stem from its simpler analytical form.
",4. Advantages of the Gumbel Trick,[0],[0]
"First, by consulting Table 1 we see that the function g(x) =",4. Advantages of the Gumbel Trick,[0],[0]
"lnx c has the property that the variance of the resulting estimator (of lnZ) does not depend on the value of Z; the function g is a variance stabilizing transformation for the Exponential distribution.
",4. Advantages of the Gumbel Trick,[0],[0]
"Second, exploiting the fact that the logarithm function leads to additive perturbations, Maji et al. (2014) showed that the entropy of x⇤, the configuration with maximum potential after sum-unary perturbation in the sense of Definition 3, can be bounded as H(x⇤)  ",4. Advantages of the Gumbel Trick,[0],[0]
"B(p) := P n
i=1
",4. Advantages of the Gumbel Trick,[0],[0]
"E
i
[ i (x⇤ i )].
",4. Advantages of the Gumbel Trick,[0],[0]
"We extend this result to show how the errors of bounding lnZ, sampling, and entropy estimation are related: Proposition 11.",4. Advantages of the Gumbel Trick,[0],[0]
"Writing p for the Gibbs distribution and B(p) := E
i
[ i (x⇤ i )] for the entropy bound, we have
(U(0) lnZ)",4. Advantages of the Gumbel Trick,[0],[0]
| {z } error in lnZ bound +KL(x⇤ k p),4. Advantages of the Gumbel Trick,[0],[0]
"| {z } sampling error = B(p) H(x⇤) | {z } error in entropy estimation .
",4. Advantages of the Gumbel Trick,[0],[0]
"Third, the additive character of the Gumbel perturbations can also be used to derive a new result relating the error of the lower bound L(0) and of sampling x⇤⇤ as the configuration achieving the maximum average-unary perturbation value L, instead of sampling from the Gibbs distribution p: Proposition 12.",4. Advantages of the Gumbel Trick,[0],[0]
"Writing p for the Gibbs distribution,
lnZ L(0)",4. Advantages of the Gumbel Trick,[0],[0]
"| {z }
error in lnZ bound
KL(x⇤⇤ k p) | {z }
sampling error
0.
",4. Advantages of the Gumbel Trick,[0],[0]
Remark.,4. Advantages of the Gumbel Trick,[0],[0]
"While we knew from Hazan et al. (2013) that lnZ L(0) 0, this is a stronger result showing that the size of the gap is an upper bound on the KL divergence between the approximate sampling distribution of x⇤⇤ and the Gibbs distribution p.
",4. Advantages of the Gumbel Trick,[0],[0]
"Proofs of the new results appear in Appendix B.3 and C.2.
",4. Advantages of the Gumbel Trick,[0],[0]
"Fourth, viewed as a function of the Gumbel perturbations
, the random variable U has a bounded gradient, allowing earlier measure concentration results (Orabona et al., 2014; Hazan et al., 2016).",4. Advantages of the Gumbel Trick,[0],[0]
Proving similar measure concentration results for the expectations E[e ↵U ] appearing in U(↵) for ↵ 6= 0,4. Advantages of the Gumbel Trick,[0],[0]
may be more challenging.,4. Advantages of the Gumbel Trick,[0],[0]
"We conducted experiments with the following aims:
1.",5. Experiments,[0],[0]
"To show that the higher efficiency of the Exponential
trick in the full-rank perturbation setting is useful in practice, we compared it to the Gumbel trick in A* sampling (Maddison et al., 2014) (Section 5.1) and in the large-scale discrete sampling setting of Chen & Ghahramani (2016) (Section 5.2).",5. Experiments,[0],[0]
2.,5. Experiments,[0],[0]
"To show that non-zero values of ↵ can lead to better estimators of lnZ in the low-rank perturbation setting as well, we compare the Fr´echet and Weibull trick
bounds U(↵) to the Gumbel trick bound U(0) on a common discrete graphical model with different coupling strengths; see Section 5.3.",5. Experiments,[0],[0]
"A* sampling (Maddison et al., 2014) is a sampling algorithm for continuous distributions that perturbs the logunnormalized density with a continuous generalization of the Gumbel trick, called the Gumbel process, and uses a variant of A* search to find the location of the maximum of the perturbed .",5.1. A* Sampling,[0],[0]
"Returning the location yields an exact sample from the original distribution, as in the discrete Gumbel trick.",5.1. A* Sampling,[0],[0]
"Moreover, the corresponding maximum value also has the Gumbel( c + lnZ) distribution (Maddison et al., 2014).",5.1. A* Sampling,[0],[0]
Our analysis in Section 2.3 tells us that the Exponential trick yields an estimator with lower MSE than the Gumbel trick; we briefly verified this on the Robust Bayesian Regression experiment of Maddison et al. (2014).,5.1. A* Sampling,[0],[0]
"We constructed estimators of lnZ from the Gumbel and Exponential tricks (debiased version, see Section 2.3.2), and assessed their variances by constructing each estimator K = 1000 times and looking at the sample variance.",5.1. A* Sampling,[0],[0]
Figure 3a shows that the Exponential trick requires up to 40% fewer samples to reach a given MSE.,5.1. A* Sampling,[0],[0]
Chen & Ghahramani (2016) considered sampling from a discrete distribution of the form p(x) / f 0,5.2. Scalable Partition Function Estimation,[0],[0]
"(x) Q S
s=1
f s (x) when the number of factors S is large relative to the sample space size |X |.",5.2. Scalable Partition Function Estimation,[0],[0]
Computing i.i.d.,5.2. Scalable Partition Function Estimation,[0],[0]
"Gumbel perturbations (x) for each x 2 X is then relatively cheap compared to evaluating all potentials (x) = f
0
(x) + P S
s=1
ln f s (x).",5.2. Scalable Partition Function Estimation,[0],[0]
"Chen & Ghahramani (2016) observed that each (perturbed) potential can be estimated by subsampling the factors, and potentials that appear unlikely to yield the MAP value can be pruned off from the search early on.",5.2. Scalable Partition Function Estimation,[0],[0]
"The authors formalized the problem as a Multi-armed bandit problem with a finite reward population and derived approximate algorithms for efficiently finding the maximum perturbed potential with a probabilistic guarantee.
",5.2. Scalable Partition Function Estimation,[0],[0]
"(a)
(b)
While Chen & Ghahramani (2016) considered sampling, by modifying their procedure to return the value of the maximum perturbed potential rather than the argmax (cf equations (1) and (2)), we can estimate the partition function instead.",5.2. Scalable Partition Function Estimation,[0],[0]
"However, the approximate algorithm only guarantees to find the MAP configuration with a probability 1 .",5.2. Scalable Partition Function Estimation,[0],[0]
Figure 3b shows the results of running the Racing-Normal algorithm of Chen & Ghahramani (2016) on the synthetic dataset considered by the authors with the “very hard” noise setting = 0.1.,5.2. Scalable Partition Function Estimation,[0],[0]
"For low error bounds the Exponential trick remained close to optimal, but for a larger error bound the Weibull trick interpolation between the Gumbel and Exponential tricks proved useful to provide an estimator with lower MSE.
5.3.",5.2. Scalable Partition Function Estimation,[0],[0]
"Low-rank Perturbation Bounds on lnZ
Hazan & Jaakkola (2012) evaluated tightness of the Gumbel trick upper bound U(0) lnZ on 10⇥ 10 binary spin glass models.",5.2. Scalable Partition Function Estimation,[0],[0]
We show one can obtain more accurate estimates of lnZ on such models by choosing ↵ 6= 0.,5.2. Scalable Partition Function Estimation,[0],[0]
"To account for the fact that in practice an expectation in U(↵) is replaced with a sample average, we treat U(↵) as an estimator of lnZ with asymptotic bias equal to the bound gap (U(↵) lnZ), and estimate its MSE.",5.2. Scalable Partition Function Estimation,[0],[0]
"Figure 4 shows the MSEs of U(↵) as estimators of lnZ on 10⇥ 10 (n = 100) binary pairwise grid models with unary potentials sampled uniformly from [ 1, 1] and pairwise potentials from [0, C] (attractive models) or from [ C,C] (mixed models), for varying coupling strengths C. We replaced the expectations in U(↵)’s with sample averages of size M = 100, using libDAI (Mooij, 2010) to solve the MAP problems yielding these samples.",5.2. Scalable Partition Function Estimation,[0],[0]
We constructed each estimator 1000 times to assess its variance.,5.2. Scalable Partition Function Estimation,[0],[0]
"By casting partition function evaluation as a parameter estimation problem for the exponential distribution, we derived a family of methods of which the Gumbel trick is a special case.",6. Discussion,[0],[0]
"These methods can be equivalently seen as (1) perturbing models using different distributions, or as (2) averaging standard Gumbel perturbations in different spaces, allowing implementations with little additional cost.
",6. Discussion,[0],[0]
"We showed that in the full-rank perturbation setting, the new Exponential trick provides an estimator with lower MSE, or instead allows using up to 40% fewer samples than the Gumbel trick estimator to reach the same MSE.
",6. Discussion,[0],[0]
"In the low-rank perturbation setting, we used our Fr´echet, Exponential and Weibull tricks to derive new bounds on lnZ and sequential samplers for the Gibbs distribution, and showed that these can also behave better than the corresponding Gumbel trick results.",6. Discussion,[0],[0]
"However, the optimal trick to use (as specified by ↵) depends on the model, sample size, and MAP solver used (if approximate).",6. Discussion,[0],[0]
"Since in practice the dominant computational cost is carried by solving repeated instances of the MAP problem, one can try and assess different values of ↵ on the problem at hand.",6. Discussion,[0],[0]
"That said, we believe that investigating when different tricks yield better results is an interesting avenue for future work.
",6. Discussion,[0],[0]
"Finally, we balanced the discussion by pointing out that the Gumbel trick has a simpler analytical form which can be exploited to derive more interesting theoretical statements in the low-rank perturbation setting.",6. Discussion,[0],[0]
"Beyond existing results, we derived new connections between errors of different procedures using low-rank Gumbel perturbations.",6. Discussion,[0],[0]
"The authors thank Tamir Hazan for helpful discussions, and Mark Rowland, Maria Lomeli, and the anonymous reviewers for helpful comments.",Acknowledgements,[0],[0]
"AW acknowledges support by the Alan Turing Institute under EPSRC grant EP/N510129/1, and by the Leverhulme Trust via the CFI.",Acknowledgements,[0],[0]
"The Gumbel trick is a method to sample from a discrete probability distribution, or to estimate its normalizing partition function.",abstractText,[0],[0]
"The method relies on repeatedly applying a random perturbation to the distribution in a particular way, each time solving for the most likely configuration.",abstractText,[0],[0]
"We derive an entire family of related methods, of which the Gumbel trick is one member, and show that the new methods have superior properties in several settings with minimal additional computational cost.",abstractText,[0],[0]
"In particular, for the Gumbel trick to yield computational benefits for discrete graphical models, Gumbel perturbations on all configurations are typically replaced with socalled low-rank perturbations.",abstractText,[0],[0]
"We show how a subfamily of our new methods adapts to this setting, proving new upper and lower bounds on the log partition function and deriving a family of sequential samplers for the Gibbs distribution.",abstractText,[0],[0]
"Finally, we balance the discussion by showing how the simpler analytical form of the Gumbel trick enables additional theoretical results.",abstractText,[0],[0]
Lost Relatives of the Gumbel Trick,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 1426–1436 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
1426",text,[0],[0]
Recurrent neural networks (RNNs) are remarkably effective models of sequential data.,1 Introduction,[0],[0]
"Recent years have witnessed the widespread adoption of recurrent architectures such as LSTMs (Hochreiter and Schmidhuber, 1997) in various NLP tasks, with state of the art results in language modeling (Melis et al., 2018) and conditional generation tasks like machine translation (Bahdanau et al., 2015) and text summarization (See et al., 2017).
",1 Introduction,[0],[0]
"Here we revisit the question asked by Linzen et al. (2016): as RNNs model word sequences without explicit notions of hierarchical structure,
to what extent are these models able to learn non-local syntactic dependencies in natural language?",1 Introduction,[0],[0]
"Identifying number agreement between subjects and verbs—especially in the presence of attractors—can be understood as a cognitivelymotivated probe that seeks to distinguish hierarchical theories from sequential ones, as models that rely on sequential cues like the most recent noun would favor the incorrect verb form.",1 Introduction,[0],[0]
"We provide an example of this task in Fig. 1, where the plural form of the verb have agrees with the distant subject parts, rather than the adjacent attractors (underlined) of the singular form.
",1 Introduction,[0],[0]
"Contrary to the findings of Linzen et al. (2016), our experiments suggest that sequential LSTMs are able to capture structural dependencies to a large extent, even for cases with multiple attractors (§2).",1 Introduction,[0],[0]
Our finding suggests that network capacity plays a crucial role in capturing structural dependencies with multiple attractors.,1 Introduction,[0],[0]
"Nevertheless, we find that a strong character LSTM language model—which lacks explicit word representation and has to capture much longer sequential dependencies in order to learn non-local structural dependencies effectively—performs much worse in the number agreement task.
",1 Introduction,[0],[0]
"Given the strong performance of word-based LSTM language models, are there are any substantial benefits, in terms of number agreement accuracy, to explicitly modeling hierarchical structures as an inductive bias?",1 Introduction,[0],[0]
"We discover that a
certain class of LSTM language models that explicitly models syntactic structures, the recurrent neural network grammars (Dyer et al., 2016, RNNGs), considerably outperforms sequential LSTM language models for cases with multiple attractors (§3).",1 Introduction,[0],[0]
We present experiments affirming that this gain is due to an explicit composition operator rather than the presence of predicted syntactic annotations.,1 Introduction,[0],[0]
"Rather surprisingly, syntactic LSTM language models without explicit composition have no advantage over sequential LSTMs that operate on word sequences, although these models can nevertheless be excellent predictors of phrase structures (Choe and Charniak, 2016).
",1 Introduction,[0],[0]
"Having established the importance of modeling structures, we explore the hypothesis that how we build the structure affects the model’s ability to identify structural dependencies in English.",1 Introduction,[0],[0]
"As RNNGs build phrase-structure trees through top-down operations, we propose extensions to the structure-building sequences and model architecture that enable left-corner (Henderson, 2003, 2004) and bottom-up (Chelba and Jelinek, 2000; Emami and Jelinek, 2005) generation orders (§4).
",1 Introduction,[0],[0]
"Extensive prior work has characterized topdown, left-corner, and bottom-up parsing strategies in terms of cognitive plausibility (Pulman, 1986; Abney and Johnson, 1991; Resnik, 1992) and neurophysiological evidence in human sentence processing (Nelson et al., 2017).",1 Introduction,[0],[0]
"Here we move away from the realm of parsing and evaluate the three strategies as models of generation instead, and address the following empirical question: which generation order is most appropriately biased to model structural dependencies in English, as indicated by number agreement accuracy?",1 Introduction,[0],[0]
"Our key finding is that the top-down generation outperforms left-corner and bottom-up variants for difficult cases with multiple attractors.
",1 Introduction,[0],[0]
"In theory, the three traversal strategies approximate the same chain rule that decompose the joint probability of words and phrase-structure trees, denoted as p(x,y), differently and as such will impose different biases on the learner.",1 Introduction,[0],[0]
"In §4.3, we show that the three variants achieve similar perplexities on a held-out validation set.",1 Introduction,[0],[0]
"As we observe different patterns in number agreement, this demonstrates that while perplexity can be a useful diagnostic tool, it may not be sensitive enough for comparing models in terms of how well they capture grammatical intuitions.",1 Introduction,[0],[0]
"We revisit the number agreement task with LSTMs trained on language modeling objectives, as proposed by Linzen et al. (2016).
",2 Number Agreement with LSTM Language Models,[0],[0]
Experimental Settings.,2 Number Agreement with LSTM Language Models,[0],[0]
"We use the same parsed Wikipedia corpus, verb inflectors, preprocessing steps, and dataset split as Linzen et al. (2016).1 Word types beyond the most frequent 10,000 are converted to their respective POS tags.",2 Number Agreement with LSTM Language Models,[0],[0]
"We summarize the corpus statistics of the dataset, along with the test set distribution of the number of attractors, in Table 1.",2 Number Agreement with LSTM Language Models,[0],[0]
"Similar to Linzen et al. (2016), we only include test cases where all intervening nouns are of the opposite number forms than the subject noun.",2 Number Agreement with LSTM Language Models,[0],[0]
"All models are implemented using the DyNet library (Neubig et al., 2017).
",2 Number Agreement with LSTM Language Models,[0],[0]
Training was done using a language modeling objective that predicts the next word given the prefix; at test time we compute agreement error rates by comparing the probability of the correct verb form with the incorrect one.,2 Number Agreement with LSTM Language Models,[0],[0]
"We report performance of a few different LSTM hidden layer configurations, while other hyper-parameters are selected based on a grid search.2 Following Linzen
1The dataset and scripts are obtained from https:// github.com/TalLinzen/rnn_agreement.
",2 Number Agreement with LSTM Language Models,[0],[0]
"2Based on the grid search results, we used the following hyper-parameters that work well across different hidden layer sizes: 1-layer LSTM, SGD optimizers with an initial learning rate of 0.2, a learning rate decay of 0.10 after 10 epochs, LSTM dropout rates of 0.2, an input embedding dimension of 50, and a batch size of 10 sentences.",2 Number Agreement with LSTM Language Models,[0],[0]
"Our use of singlelayer LSTMs and 50-dimensional word embedding (learned from scratch) as one of the baselines is consistent with the experimental settings of Linzen et al. (2016).
",2 Number Agreement with LSTM Language Models,[0],[0]
"et al. (2016), we include the results of our replication3 of the large-scale language model of Jozefowicz et al. (2016) that was trained on the One Billion Word Benchmark.4 Hyper-parameter tuning is based on validation set perplexity.
Discussion.",2 Number Agreement with LSTM Language Models,[0],[0]
"Table 2 indicates that, given enough capacity, LSTM language models without explicit syntactic supervision are able to perform well in number agreement.",2 Number Agreement with LSTM Language Models,[0],[0]
"For cases with multiple attractors, we observe that the LSTM language model with 50 hidden units trails behind its larger counterparts by a substantial margin despite comparable performance for zero attractor cases, suggesting that network capacity plays an especially important role in propagating relevant structural information across a large number of steps.5 Our experiment independently derives the
3When evaluating the large-scale language model, the primary difference is that we do not map infrequent word types to their POS tags and that we subsample to obtain 500 test instances of each number of attractor due to computation cost; both preprocessing were also done by Linzen et al. (2016).
4The pretrained large-scale language model is obtained from https://github.com/tensorflow/models/ tree/master/research/lm_1b.
",2 Number Agreement with LSTM Language Models,[0],[0]
5This trend is also observed by comparing results with H=150 and H=250.,2 Number Agreement with LSTM Language Models,[0],[0]
"While both models achieve near-identical performance for zero attractor, the model with H=250 per-
same finding as the recent work of Gulordava et al. (2018), who also find that LSTMs trained with language modeling objectives are able to learn number agreement well; here we additionally identify model capacity as one of the reasons for the discrepancy with the Linzen et al. (2016) results.
",2 Number Agreement with LSTM Language Models,[0],[0]
"While the pretrained large-scale language model of Jozefowicz et al. (2016) has certain advantages in terms of model capacity, more training data, and richer vocabulary, we suspect that the poorer performance is due to differences between their training domain and the number agreement testing domain, although the model still performs reasonably well in the number agreement test set.
",2 Number Agreement with LSTM Language Models,[0],[0]
"Prior work has confirmed the notion that, in many cases, statistical models are able to achieve good performance under some aggregate metric by overfitting to patterns that are predictive in most cases, often at the expense of more difficult, infrequent instances that require deeper language understanding abilities (Rimell et al., 2009; Jia and Liang, 2017).",2 Number Agreement with LSTM Language Models,[0],[0]
"In the vast majority of cases, structural dependencies between subjects and verbs highly overlap with sequential dependencies (Table 1).",2 Number Agreement with LSTM Language Models,[0],[0]
"Nevertheless, the fact that number agreement accuracy gets worse as the number of attractors increases is consistent with a sequential recency bias in LSTMs: under this conjecture, identifying the correct structural dependency becomes harder when there are more adjacent nouns of different number forms than the true subject.
",2 Number Agreement with LSTM Language Models,[0],[0]
"If the sequential recency conjecture is correct, then LSTMs would perform worse when the structural dependency is more distant in the sequences, compared to cases where the structural dependency is more adjacent.",2 Number Agreement with LSTM Language Models,[0],[0]
"We empirically test this conjecture by running a strong character-based LSTM language model of Melis et al. (2018) that achieved state of the art results on EnWiki8 from the Hutter Prize dataset (Hutter, 2012), with 1,800 hidden units and 10 million parameters.",2 Number Agreement with LSTM Language Models,[0],[0]
"The character LSTM is trained, validated, and tested6 on the same split of the Linzen et al. (2016) number agreement dataset.
",2 Number Agreement with LSTM Language Models,[0],[0]
"A priori, we expect that number agreement is harder for character LSTMs for two reasons.",2 Number Agreement with LSTM Language Models,[0],[0]
"First, character LSTMs lack explicit word representa-
forms much better for cases with multiple attractors.",2 Number Agreement with LSTM Language Models,[0],[0]
"6For testing, we similarly evaluate number agreement accuracy by comparing the probability of the correct and incorrect verb form given the prefix, as represented by the respective character sequences.
tions, thus succeeding in this task requires identifying structural dependencies between two sequences of character tokens, while word-based LSTMs only need to resolve dependencies between word tokens.",2 Number Agreement with LSTM Language Models,[0],[0]
"Second, by nature of modeling characters, non-local structural dependencies are sequentially further apart than in the wordbased language model.",2 Number Agreement with LSTM Language Models,[0],[0]
"On the other hand, character LSTMs have the ability to exploit and share informative morphological cues, such as the fact that plural nouns in English tend to end with ‘s’.
",2 Number Agreement with LSTM Language Models,[0],[0]
"As demonstrated on the last row of Table 2, we find that the character LSTM language model performs much worse at number agreement with multiple attractors compared to its word-based counterparts.",2 Number Agreement with LSTM Language Models,[0],[0]
"This finding is consistent with that of Sennrich (2017), who find that character-level decoders in neural machine translation perform worse than subword models in capturing morphosyntactic agreement.",2 Number Agreement with LSTM Language Models,[0],[0]
"To some extent, our finding demonstrates the limitations that character LSTMs face in learning structure from language modeling objectives, despite earlier evidence that character LSTM language models are able to implicitly acquire a lexicon (Le Godais et al., 2017).",2 Number Agreement with LSTM Language Models,[0],[0]
"Given the strong performance of sequential LSTMs in number agreement, is there any further benefit to explicitly modeling hierarchical structures?",3 Number Agreement with RNNGs,[0],[0]
"We focus on recurrent neural network grammars (Dyer et al., 2016, RNNGs), which jointly model the probability of phrase-structure trees and strings, p(x,y), through structurebuilding actions and explicit compositions for representing completed constituents.
",3 Number Agreement with RNNGs,[0],[0]
"Our choice of RNNGs is motivated by the findings of Kuncoro et al. (2017), who find evidence for syntactic headedness in RNNG phrasal representations.",3 Number Agreement with RNNGs,[0],[0]
"Intuitively, the ability to learn heads is beneficial for this task, as the representation for the noun phrase “The flowers in the vase” would be similar to the syntactic head flowers rather than vase.",3 Number Agreement with RNNGs,[0],[0]
"In some sense, the composition operator can be understood as injecting a structural recency bias into the model design, as subjects and verbs that are sequentially apart are encouraged to be close together in the RNNGs’ representation.",3 Number Agreement with RNNGs,[0],[0]
"RNNGs (Dyer et al., 2016) are language models that estimate the joint probability of string terminals and phrase-structure tree nonterminals.",3.1 Recurrent Neural Network Grammars,[0],[0]
"Here we use stack-only RNNGs that achieve better perplexity and parsing performance (Kuncoro et al., 2017).",3.1 Recurrent Neural Network Grammars,[0],[0]
"Given the current stack configuration, the objective function of RNNGs is to predict the correct structure-building operation according to a top-down, left-to-right traversal of the phrasestructure tree; a partial traversal for the input sentence “The flowers in the vase are blooming” is illustrated in Fig.",3.1 Recurrent Neural Network Grammars,[0],[0]
"3(a).7
The structural inductive bias of RNNGs derives from an explicit composition operator that represents completed constituents; for instance, the constituent (NP The flowers) is represented by a single composite element on the stack, rather than as four separate symbols.",3.1 Recurrent Neural Network Grammars,[0],[0]
"During each REDUCE action, the topmost stack elements that belong to the new constituent are popped from the stack and then composed by the composition function; the composed symbol is then pushed back into the stack.",3.1 Recurrent Neural Network Grammars,[0],[0]
The model is trained in an end-to-end manner by minimizing the cross-entropy loss relative to a sample of gold trees.,3.1 Recurrent Neural Network Grammars,[0],[0]
"Here we summarize the experimental settings of running RNNGs on the number agreement dataset and discuss the empirical findings.
",3.2 Experiments,[0],[0]
Experimental settings.,3.2 Experiments,[0],[0]
"We obtain phrasestructure trees for the Linzen et al. (2016) dataset using a publicly available discriminative model8 trained on the Penn Treebank (Marcus et al., 1993).",3.2 Experiments,[0],[0]
"At training time, we use these predicted trees to derive action sequences on the training set, and train the RNNG model on these sequences.9",3.2 Experiments,[0],[0]
"At test time, we compare the probabilities of the correct and incorrect verb forms given the prefix, which now includes both nonterminal and terminal symbols.",3.2 Experiments,[0],[0]
An example of the stack contents (i.e. the prefix) when predicting the verb is provided in Fig. 3(a).,3.2 Experiments,[0],[0]
"We similarly run a grid search over the same hyper-parameter range as the sequential
7For a complete example of action sequences, we refer the reader to the example provided by Dyer et al. (2016).
",3.2 Experiments,[0],[0]
"8https://github.com/clab/rnng 9Earlier work on RNNGs (Dyer et al., 2016; Kuncoro et al., 2017) train the model on gold phrase-structure trees on the Penn Treebank, while here we train the RNNG on the number agreement dataset based on predicted trees from another parser.
LSTM and compare the results with the strongest sequential LSTM baseline from §2.
Discussion.",3.2 Experiments,[0],[0]
"Fig. 2 shows that RNNGs (rightmost) achieve much better number agreement accuracy compared to LSTM language models (leftmost) for difficult cases with four and five attractors, with around 30% error rate reductions, along with a 13% error rate reduction (from 9% to 7.8%) for three attractors.",3.2 Experiments,[0],[0]
"We attribute the slightly worse performance of RNNGs on cases with zero and one attractor to the presence of intervening structure-building actions that separate the subject and the verb, such as a REDUCE (step 6 in Fig. 3(a)) action to complete the noun phrase and at least one action to predict a verb phrase (step 15 in Fig. 3(a))",3.2 Experiments,[0],[0]
"before the verb itself is introduced, while LSTM language models benefit from shorter dependencies for zero and one attractor cases.
",3.2 Experiments,[0],[0]
The performance gain of RNNGs might arise from two potential causes.,3.2 Experiments,[0],[0]
"First, RNNGs have access to predicted syntactic annotations, while LSTM language models operate solely on word sequences.",3.2 Experiments,[0],[0]
"Second, RNNGs incorporate explicit compositions, which encourage hierarhical representations and potentially the discovery of syntactic (rather than sequential) dependencies.
",3.2 Experiments,[0],[0]
"Would LSTMs that have access to syntactic annotations, but without the explicit composition function, benefit from the same performance gain as RNNGs?",3.2 Experiments,[0],[0]
"To answer this question, we run sequential LSTMs over the same phrase-structure trees (Choe and Charniak, 2016), similarly estimating the joint probability of phrase-structure nonterminals and string terminals but without an explicit composition operator.",3.2 Experiments,[0],[0]
"Taking the example in Fig. 3(a), the sequential syntactic LSTM would
have fifteen10 symbols on the LSTM when predicting the verb, as opposed to three symbols in the case of RNNGs’ stack LSTM.",3.2 Experiments,[0],[0]
"In theory, the sequential LSTM over the phrase-structure trees (Choe and Charniak, 2016) may be able to incorporate a similar, albeit implicit, composition process as RNNGs and consequently derive similarly syntactic heads, although there is no inductive bias that explicitly encourages such process.
",3.2 Experiments,[0],[0]
"Fig. 2 suggests that the sequential syntactic LSTMs (center) perform comparably with sequential LSTMs without syntax for multiple attractor cases, and worse than RNNGs for nearly all attractors; the gap is highest for multiple attractors.",3.2 Experiments,[0],[0]
"This result showcases the importance of an explicit composition operator and hierarchical representations in identifying structural dependencies, as indicated by number agreement accuracy.",3.2 Experiments,[0],[0]
"Our finding is consistent with the recent work of Yogatama et al. (2018), who find that introducing elements of hierarchical modeling through a stackstructured memory is beneficial for number agreement, outperforming LSTM language models and attention-augmented variants by increasing margins as the number of attractor grows.",3.2 Experiments,[0],[0]
"In order to better interpret the results, we conduct further analysis into the perplexities of each model, followed by a discussion on the effect of incrementality constraints on the RNNG when predicting number agreement.
Perplexity.",3.3 Further Analysis,[0],[0]
To what extent does the success of RNNGs in the number agreement task with multiple attractors correlate with better performance under the perplexity metric?,3.3 Further Analysis,[0],[0]
"We answer this question by using an importance sampling marginalization procedure (Dyer et al., 2016) to obtain an estimate of p(x) under both RNNGs and the sequential syntactic LSTM model.",3.3 Further Analysis,[0],[0]
"Following Dyer et al. (2016), for each sentence on the validation set we sample 100 candidate trees from a discriminative model11 as our proposal distribution.",3.3 Further Analysis,[0],[0]
"As demonstrated in Table 3, the LSTM language model has the lowest validation set perplexity despite substantially worse performance than RNNGs in number agreement with multiple attractors, suggesting that lower perplexity is not neces-
10In the model of Choe and Charniak (2016), each nonterminal, terminal, and closed parenthesis symbol is represented as an element on the LSTM sequence.
",3.3 Further Analysis,[0],[0]
"11https://github.com/clab/rnng
sarily correlated with number agreement success.
",3.3 Further Analysis,[0],[0]
Incrementality constraints.,3.3 Further Analysis,[0],[0]
"As the syntactic prefix was derived from a discriminative model that has access to unprocessed words, one potential concern is that this prefix might violate the incrementality constraints and benefit the RNNG over the LSTM language model.",3.3 Further Analysis,[0],[0]
"To address this concern, we remark that the empirical evidence from Fig. 2 and Table 3 indicates that the LSTM language model without syntactic annotation outperforms the sequential LSTM with syntactic annotation in terms of both perplexity and number agreement throughout nearly all attractor settings, suggesting that the predicted syntactic prefix does not give any unfair advantage to the syntactic models.
",3.3 Further Analysis,[0],[0]
"Furthermore, we run an experiment where the syntactic prefix is instead derived from an incremental beam search procedure of Fried et al. (2017).12 To this end, we take the highest scoring beam entry at the time that the verb is generated to be the syntactic prefix; this procedure is applied to both the correct and incorrect verb forms.13 We then similarly compare the probabilities of the correct and incorrect verb form given each respective syntactic prefix to obtain number agreement accuracy.",3.3 Further Analysis,[0],[0]
"Our finding suggests that using the fully incremental tree prefix leads to even better RNNG number agreement performance for four and five attractors, achieving 7.1% and 8.2% error rates, respectively, compared to 9.4% and 12% for the RNNG error rates in Fig. 2.",3.3 Further Analysis,[0],[0]
"In this section, we propose two new variants of RNNGs that construct trees using a different con-
12As the beam search procedure is time-consuming, we randomly sample 500 cases for each attractor and compute the number agreement accuracy on these samples.
","4 Top-Down, Left-Corner, and Bottom-Up Traversals",[0],[0]
"13Consequently, the correct and incorrect forms of the sentence might have different partial trees, as the highest scoring beam entries may be different for each alternative.
struction order than the top-down, left-to-right order used above.","4 Top-Down, Left-Corner, and Bottom-Up Traversals",[0],[0]
"These are a bottom-up construction order (§4.1) and a left-corner construction order (§4.2), analogous to the well-known parsing strategies (e.g. Hale, 2014, chapter 3).","4 Top-Down, Left-Corner, and Bottom-Up Traversals",[0],[0]
"They differ from these classic strategies insofar as they do not announce the phrase-structural content of an entire branch at the same time, adopting instead a node-by-node enumeration reminescent of Markov Grammars (Charniak, 1997).","4 Top-Down, Left-Corner, and Bottom-Up Traversals",[0],[0]
"This stepby-step arrangement extends to the derived string as well; since all variants generate words from left to right, the models can be compared using number agreement as a diagnostic.14
Here we state our hypothesis on why the build order matters.","4 Top-Down, Left-Corner, and Bottom-Up Traversals",[0],[0]
"The three generation strategies represent different chain rule decompositions of the joint probability of strings and phrase-structure trees, thereby imposing different biases on the learner.","4 Top-Down, Left-Corner, and Bottom-Up Traversals",[0],[0]
"Earlier work in parsing has characterized the plausibility of top-down, left-corner, and bottom-up strategies as viable candidates of human sentence processing, especially in terms of memory constraints and human difficulties with center embedding constructions (Johnson-Laird, 1983; Pulman, 1986; Abney and Johnson, 1991; Resnik, 1992, inter alia), along with neurophysiological evidence in human sentence processing (Nelson et al., 2017).","4 Top-Down, Left-Corner, and Bottom-Up Traversals",[0],[0]
"Here we cast the three strategies as models of language generation (Manning and Carpenter, 1997), and focus on the empirical question: which generation order has the most appropriate bias in modeling non-local structural dependencies in English?
","4 Top-Down, Left-Corner, and Bottom-Up Traversals",[0],[0]
These alternative orders organize the learning problem so as to yield intermediate states in generation that condition on different aspects of the grammatical structure.,"4 Top-Down, Left-Corner, and Bottom-Up Traversals",[0],[0]
"In number agreement, this amounts to making an agreement controller, such as the word flowers in Fig. 3, more or less salient.","4 Top-Down, Left-Corner, and Bottom-Up Traversals",[0],[0]
"If it is more salient, the model should be better-able to inflect the main verb in agreement with this controller, without getting distracted by the attractors.","4 Top-Down, Left-Corner, and Bottom-Up Traversals",[0],[0]
"The three proposed build orders are compared in Fig. 3, showing the respective configurations (i.e. the prefix) when generating the main verb in a sentence with a single attractor.15 In ad-
14Only the order in which these models build the nonterminal symbols is different, while the terminal symbols are still generated in a left-to-right manner in all variants.
","4 Top-Down, Left-Corner, and Bottom-Up Traversals",[0],[0]
"15Although the stack configuration at the time of verb generation varies only slightly, the configurations encountered
dition, we show concrete action sequences for a simpler sentence in each section.","4 Top-Down, Left-Corner, and Bottom-Up Traversals",[0],[0]
"In bottom-up traversals, phrases are recursively constructed and labeled with the nonterminal type once all their daughters have been built, as illustrated in Fig. 4.",4.1 Bottom-Up Traversal,[0],[0]
Bottom-up traversals benefit from shorter stack depths compared to top-down due to the lack of incomplete nonterminals.,4.1 Bottom-Up Traversal,[0],[0]
"As the commitment to label the nonterminal type of a phrase is delayed until its constituents are complete, this means that the generation of a child node cannot condition on the label of its parent node.
",4.1 Bottom-Up Traversal,[0],[0]
"In n-ary branching trees, bottom-up completion of constituents requires a procedure for determining how many of the most recent elements on the stack should be daughters of the node that is being constructed.16 Conceptually, rather than having a single REDUCE operation as we have before, we have a complex REDUCE(X, n) operation that must determine the type of the constituent (i.e., X) as well as the number of daughters (i.e., n).
",4.1 Bottom-Up Traversal,[0],[0]
"In step 5 of Fig. 4, the newly formed NP constituent only covers the terminal worms, and neither the unattached terminal eats nor the constituent (NP The fox) is part of the new noun phrase.",4.1 Bottom-Up Traversal,[0],[0]
"We implement this extent decision using a stick-breaking construction—using the stack LSTM encoding, a single-layer feedforward network, and a logistic output layer—which decides whether the top element on the stack should be the leftmost child of the new constituent (i.e. whether or not the new constituent is complete after popping the current topmost stack element), as illustrated in Fig. 5.",4.1 Bottom-Up Traversal,[0],[0]
"If not, the process is then repeated after the topmost stack element is popped.",4.1 Bottom-Up Traversal,[0],[0]
"Once the extent of the new nonterminal has been decided, we parameterize the decision of the nonterminal label type; in Fig. 5",4.1 Bottom-Up Traversal,[0],[0]
this is an NP.,4.1 Bottom-Up Traversal,[0],[0]
"A second difference to top-down generation is that when a single constituent remains on the stack, the sentence is not necessarily complete (see step 3 of Fig. 4 for examples where this happens).",4.1 Bottom-Up Traversal,[0],[0]
"We thus introduce an explicit STOP action (step 8, Fig. 4), indicating the tree is complete, which is only assigned non-zero probability when the stack has a
during the history of the full generation process vary considerably in the invariances and the kinds of actions they predict.
",4.1 Bottom-Up Traversal,[0],[0]
"16This mechanism is not necessary with strictly binary branching trees, since each new nonterminal always consists of the two children at the top of the stack.
single complete constituent.",4.1 Bottom-Up Traversal,[0],[0]
Left-corner traversals combine some aspects of top-down and bottom-up processing.,4.2 Left-Corner Traversal,[0],[0]
"As illustrated in Fig. 6, this works by first generating the leftmost terminal of the tree, The (step 0), before proceeding bottom-up to predict its parent NP (step 1) and then top-down to predict the rest of its children (step 2).",4.2 Left-Corner Traversal,[0],[0]
A REDUCE action similarly calls the composition operator once the phrase is complete (e.g. step 3).,4.2 Left-Corner Traversal,[0],[0]
"The complete constituent (NP The fox) is the leftmost child of its parent node, thus an NT SW(S) action is done next (step 4).
",4.2 Left-Corner Traversal,[0],[0]
"The NT SW(X) action is similar to the NT(X) from the top-down generator, in that it introduces an open nonterminal node and must be matched later by a corresponding REDUCE operation, but, in addition, swaps the two topmost elements at the top of the stack.",4.2 Left-Corner Traversal,[0],[0]
This is necessary because the parent nonterminal node is not built until after its left-most child has been constructed.,4.2 Left-Corner Traversal,[0],[0]
"In step 1 of Fig. 6, with a single element The on the stack, the action NT SW(NP) adds the open nonterminal symbol NP to become the topmost stack element, but after applying the swap operator the stack now contains (NP | The (step 2).",4.2 Left-Corner Traversal,[0],[0]
We optimize the hyper-parameters of each RNNG variant using grid searches based on validation set perplexity.,4.3 Experiments,[0],[0]
Table 4 summarizes average stack depths and perplexities17 on the Linzen et al. (2016) validation set.,4.3 Experiments,[0],[0]
"We evaluate each of the variants in terms of number agreement accuracy as an evidence of its suitability to model structural dependencies in English, presented in Table 5.",4.3 Experiments,[0],[0]
"To account for randomness in training, we report the error rate summary statistics of ten different runs.
",4.3 Experiments,[0],[0]
"17Here we measure perplexity over p(x,y), where y is the presumptive gold tree on the Linzen et al. (2016) dataset.",4.3 Experiments,[0],[0]
"Dyer et al. (2016) instead used an importance sampling procedure to marginalize and obtain an estimate of p(x).
",4.3 Experiments,[0],[0]
Discussion.,4.3 Experiments,[0],[0]
"In Table 5, we focus on empirical results for cases where the structural dependencies matter the most, corresponding to cases with two, three, and four attractors.",4.3 Experiments,[0],[0]
All three RNNG variants outperform the sequential LSTM language model baseline for these cases.,4.3 Experiments,[0],[0]
"Nevertheless, the top-down variant outperforms both left-corner and bottom-up strategies for difficult cases with three or more attractors, suggesting that the top-down strategy is most appropriately biased to model difficult number agreement dependencies in English.",4.3 Experiments,[0],[0]
"We run an approximate randomization test by stratifying the output and permuting within each stratum (Yeh, 2000) and find that, for four attractors, the performance difference between the top-down RNNG and the other variants is statistically significant at p < 0.05.
",4.3 Experiments,[0],[0]
The success of the top-down traversal in the domain of number-agreement prediction is consistent with a classical view in parsing that argues top-down parsing is the most human-like parsing strategy since it is the most anticipatory.,4.3 Experiments,[0],[0]
"Only
anticipatory representations, it is said, could explain the rapid, incremental processing that humans seem to exhibit (Marslen-Wilson, 1973; Tanenhaus et al., 1995); this line of thinking similarly motivates Charniak (2010), among others.",4.3 Experiments,[0],[0]
"While most work in this domain has been concerned with the parsing problem, our findings suggest that anticipatory mechanisms are also beneficial in capturing structural dependencies in language modeling.",4.3 Experiments,[0],[0]
"We note that our results are achieved using models that, in theory, are able to condition on the entire derivation history, while earlier work in sentence processing has focused on cognitive memory considerations, such as the memory-bounded model of Schuler et al. (2010).",4.3 Experiments,[0],[0]
"Given enough capacity, LSTMs trained on language modeling objectives are able to learn syntax-sensitive dependencies, as evidenced by accurate number agreement accuracy with multiple attractors.",5 Conclusion,[0],[0]
"Despite this strong performance, we discover explicit modeling of structure does improve the model’s ability to discover non-local structural dependencies when determining the distribution over subsequent word generation.",5 Conclusion,[0],[0]
"Recurrent neural network grammars (RNNGs), which jointly model phrase-structure trees and strings and employ an explicit composition operator, substantially outperform LSTM language models and syntactic language models without explicit compositions; this highlights the importance of a hierarchical inductive bias in capturing structural dependencies.",5 Conclusion,[0],[0]
We explore the possibility that how the structure is built affects number agreement performance.,5 Conclusion,[0],[0]
"Through novel extensions to RNNGs that enable the use of left-corner and bottom-up generation strategies, we discover that this is indeed the case: the three RNNG variants have different generalization properties for number agreement, with the top-down traversal strategy performing best for cases with multiple attractors.",5 Conclusion,[0],[0]
We would like to thank Tal Linzen for his help in data preparation and answering various questions.,Acknowledgments,[0],[0]
"We also thank Laura Rimell, Nando de Freitas, and the three anonymous reviewers for their helpful comments and suggestions.",Acknowledgments,[0],[0]
"Language exhibits hierarchical structure, but recent work using a subject-verb agreement diagnostic argued that state-ofthe-art language models, LSTMs, fail to learn long-range syntax-sensitive dependencies.",abstractText,[0],[0]
"Using the same diagnostic, we show that, in fact, LSTMs do succeed in learning such dependencies—provided they have enough capacity.",abstractText,[0],[0]
"We then explore whether models that have access to explicit syntactic information learn agreement more effectively, and how the way in which this structural information is incorporated into the model impacts performance.",abstractText,[0],[0]
"We find that the mere presence of syntactic information does not improve accuracy, but when model architecture is determined by syntax, number agreement is improved.",abstractText,[0],[0]
"Further, we find that the choice of how syntactic structure is built affects how well number agreement is learned: top-down construction outperforms leftcorner and bottom-up variants in capturing long-distance structural dependencies.",abstractText,[0],[0]
"LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modeling Structure Makes Them Better",title,[0],[0]
"Probabilistic inference in complex models generally requires the evaluation of intractable, high-dimensional integrals.",1. Introduction,[0],[0]
One powerful and generic approach to inference is to use Markov chain Monte Carlo (MCMC) methods to generate asymptotically exact (but correlated) samples from a posterior distribution for inference and learning.,1. Introduction,[0],[0]
"Hamiltonian Monte Carlo (HMC) (Duane et al., 1987; Neal, 2011) is a state-of-the-art MCMC method which uses gradient information from an absolutely continuous target density to encourage efficient sampling and exploration.",1. Introduction,[0],[0]
"Crucially, HMC utilizes proposals inspired by Hamiltonian dynamics (corresponding to the classical mechanics of a point particle) which can traverse long distances in parameter space.",1. Introduction,[0],[0]
"HMC, and variants like NUTS (which eliminates the need to hand-tune the algorithm’s hyperparameters), have been successfully applied to a large class of probabilistic inference problems where they are often the gold standard for
1UC Berkeley, USA 2University of Cambridge, UK 3Uber AI Labs, USA.",1. Introduction,[0],[0]
"Correspondence to: Nilesh Tripuraneni <nileshtrip@gmail.com>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"(asymptotically) exact inference (Neal, 1996; Hoffman & Gelman, 2014; Carpenter et al., 2016).
",1. Introduction,[0],[0]
"In this paper, we first review important properties of Hamiltonian dynamics, namely energy-preservation, symplecticity, and time-reversibility, and derive a more general class of dynamics with these properties which we refer to as noncanonical Hamiltonian dynamics.",1. Introduction,[0],[0]
We then discuss the relationship of non-canonical Hamiltonian dynamics to wellknown variants of HMC and propose a novel extension of HMC.,1. Introduction,[0],[0]
We refer to this method as magnetic HMC (see Algorithm 1) since it corresponds to a particular subset of the non-canonical dynamics that in 3 dimensions map onto to the mechanics of a charged particle coupled to a magnetic field – see Figure 1 for an example of these dynamics.,1. Introduction,[0],[0]
"Furthermore, we construct an explicit, symplectic, leapfroglike integrator for magnetic HMC which allows for an efficient numerical integration scheme comparable to that of ordinary HMC.",1. Introduction,[0],[0]
"Finally, we evaluate the performance of magnetic HMC on several sampling problems where we show how its non-canonical dynamics can lead to improved mixing.",1. Introduction,[0],[0]
The proofs of all results in this paper are presented in the corresponding sections of the Appendix.,1. Introduction,[0],[0]
"Given an unnormalized target density ρ(θ) defined on Rd, an MCMC algorithm constructs an ergodic Markov chain (Θn)n∈N such that the distribution of Θn converges to ρ (e.g. in total variation) (Robert & Casella, 2004).",2. Markov chain Monte Carlo,[0],[0]
"Often, the transition kernel of such a Markov chain is specified by the Metropolis-Hastings (MH) algorithm which (i) given the
ar X
iv :1
60 7.
02 73
8v 2
[ st
at .M
L ]
1 9
A ug
2 01
7
current state Θn = θ, proposes a new state θ̃ by sampling from a proposal distribution Q(·|θ), and (ii) sets Θn+1 =",2. Markov chain Monte Carlo,[0],[0]
"θ̃ with probability min ( 1, ρ(θ̃)Q(θ|θ̃)
ρ(θ)Q(θ̃|θ)
) and Θn+1",2. Markov chain Monte Carlo,[0],[0]
"= θ oth-
erwise.",2. Markov chain Monte Carlo,[0],[0]
"The role of the acceptance step is to enforce reversibility (or detailed balance) of the Markov chain with respect to ρ – which implies ρ is a stationary distribution of the transition kernel.
",2. Markov chain Monte Carlo,[0],[0]
"Heuristically, a good MH algorithm should have low intersample correlation while maintaining a high acceptance ratio.",2. Markov chain Monte Carlo,[0],[0]
"Hamiltonian Monte Carlo provides an elegant mechanism to do this by simulating a particle moving along the contour lines of a dynamical system, constructed from the target density, to use as a MCMC proposal.",2. Markov chain Monte Carlo,[0],[0]
"In Hamiltonian Monte Carlo, the target distribution is augmented with “momentum” variables p which are independent of the θ variables but of equal dimension.",2.1. Hamiltonian Monte Carlo,[0],[0]
"For the remainder of the paper, we take the distribution over the momentum variables to be Gaussian, as is common in the literature (indeed, there is evidence that in many cases, the choice of a Gaussian distribution may be optimal (Betancourt, 2017)).",2.1. Hamiltonian Monte Carlo,[0],[0]
"The joint target distribution is therefore:
ρ(θ,p) ∝",2.1. Hamiltonian Monte Carlo,[0],[0]
"e−U(θ)−p>p/2 ≡ e−H(θ,p).",2.1. Hamiltonian Monte Carlo,[0],[0]
"(1)
Crucially, this augmentation allows Hamiltonian dynamics to be used as a proposal for an MCMC algorithm over the space (θ,p), where we interpret θ (resp., p) as position (resp., momentum) coordinates of a physical particle with total energy H(θ,p), given by the sum of its potential energy U(θ) and kinetic energy p>p/2.",2.1. Hamiltonian Monte Carlo,[0],[0]
"We briefly review the Markov chain construction below; see (Neal, 2011) or (Duane et al., 1987) for a more detailed description.",2.1. Hamiltonian Monte Carlo,[0],[0]
"Given the Markov chain state (θn,pn) at time n, the new state for time n + 1 is obtained by first resampling momentum pn ∼ N (0, I), and then proposing a new state according to the following steps: (i) Simulate the deterministic Hamiltonian flow defined by the differential equation
d
dt [ θ(t) p(t) ]",2.1. Hamiltonian Monte Carlo,[0],[0]
"= [ 0 I −I 0 ] ︸ ︷︷ ︸
A
[ ∇θH(p(t), θ(t))",2.1. Hamiltonian Monte Carlo,[0],[0]
"∇pH(p(t), θ(t))",2.1. Hamiltonian Monte Carlo,[0],[0]
"]
≡",2.1. Hamiltonian Monte Carlo,[0],[0]
"[
p(t) −∇θU(θ(t))
] .",2.1. Hamiltonian Monte Carlo,[0],[0]
"(2)
for time τ , with initial condition (θn,pn), to obtain (θ′n,p ′ n) =",2.1. Hamiltonian Monte Carlo,[0],[0]
"Φτ,H(θn,pn)
1; (ii) Flip the resulting momentum component with the map Φp(θ,p) =",2.1. Hamiltonian Monte Carlo,[0],[0]
"(θ,−p) to ob-
1Throughout this paper, we use Φτ,H to denote the map that takes a given position-momentum pair as initial conditions for the
tain (θ̃n+1, p̃n+1) = Φp(θ′n,p ′ n) = Φ̃τ,H(θn,pn); (iii) Apply a MH-type accept/reject step to enforce detailed balance with respect to the target distribution; (iv) Flip the momentum again with Φp so it points in the original direction.
",2.1. Hamiltonian Monte Carlo,[0],[0]
"Note that because the map Φτ,H is time-reversible (in the sense that if the path (θ(t),p(t)) is a solution to (2) then the path with negated momentum traversed in reverse (θ(−t),−p(−t)) is also a solution), the map Φ̃τ,H is selfinverse.",2.1. Hamiltonian Monte Carlo,[0],[0]
"From this, the acceptance ratio in step (iii) enforcing detailed balance can be shown (see e.g. (Green, 1995))",2.1. Hamiltonian Monte Carlo,[0],[0]
"to have the form:
min ( 1,
exp(−H(θ̃n+1, p̃n+1))",2.1. Hamiltonian Monte Carlo,[0],[0]
"exp(−H(θn,pn)) ∣∣∣det∇θ,pΦ̃τ,H(θn,pn)∣∣∣) .",2.1. Hamiltonian Monte Carlo,[0],[0]
"(3) Note that the Hamiltonian flow & momentum flip operator Φ̃τ,H is volume-preserving2, which immediately yields that the Jacobian term in the acceptance ratio (3) is simply 1.",2.1. Hamiltonian Monte Carlo,[0],[0]
"The acceptance probability therefore reduces to min(1, exp(H(θn,pn)",2.1. Hamiltonian Monte Carlo,[0],[0]
"− H(θ̃n+1, p̃n+1)))",2.1. Hamiltonian Monte Carlo,[0],[0]
.,2.1. Hamiltonian Monte Carlo,[0],[0]
"Furthermore, since the Hamiltonian flow defined in (2) is energypreserving (i.e. H(θ̃n+1, p̃n+1) = H(θn,pn)) – the acceptance ratio is identically 1.",2.1. Hamiltonian Monte Carlo,[0],[0]
"Moreover, the momentum resampling in (i) and momentum flip in (iv) both leave the joint distribution invariant.
",2.1. Hamiltonian Monte Carlo,[0],[0]
"While the momentum resampling ensures the Markov chain explores the joint (θ,p) space, the proposals inspired by Hamiltonian dynamics can traverse long distances in parameter space θ, reducing the random-walk behavior of MH that often results in highly correlated samples (Neal, 2011).",2.1. Hamiltonian Monte Carlo,[0],[0]
"Unfortunately, it is rarely possible to integrate the flow defined in (2) analytically; instead an efficient numerical integration scheme must be used to generate a proposal for the MH-type accept/reject test.",2.2. Symplectic Numerical Integration,[0],[0]
"Typically, the leapfrog (Störmer-Verlet) integrator is used since it is an explicit method that is both symplectic and time-reversible (Neal, 2011).",2.2. Symplectic Numerical Integration,[0],[0]
"One elegant way to motivate this integrator is by decomposing the Hamiltonian into a symmetric splitting:
H(θ,p) = U(θ)/2︸ ︷︷ ︸ H1(θ) +",2.2. Symplectic Numerical Integration,[0],[0]
"p>p/2︸ ︷︷ ︸ H2(p) +U(θ)/2︸ ︷︷ ︸ H1(θ)
(4)
and then defining Φ ,H1(θ) and Φ ,H2(p) to be the exactlyintegrated flows for the sub-Hamiltonians H1(θ) and
Hamiltonian flow associated withH for time τ .",2.2. Symplectic Numerical Integration,[0],[0]
"In addition, Φ̃τ,H denotes the composition of Φτ,H with the momentum flip map Φp.
2In fact the Hamiltonian flow satisfies the stronger condition of symplecticity with respect to the A matrix ([∇θ,pΦτ,H(θ,p)]>A−1[∇θ,pΦτ,H(θ,p)] = A−1) which immediately implies it is volume-preserving by taking determinants of this relation.
H2(p), respectively.",2.2. Symplectic Numerical Integration,[0],[0]
"These updates (which are equivalent to Euler translations) can be written:
Φ ,H1(θ)",2.2. Symplectic Numerical Integration,[0],[0]
[ θ p ] =,2.2. Symplectic Numerical Integration,[0],[0]
"[ θ
p− 2∇θU(θ) ]",2.2. Symplectic Numerical Integration,[0],[0]
"Φ ,H2(p)",2.2. Symplectic Numerical Integration,[0],[0]
[ θ p ] =,2.2. Symplectic Numerical Integration,[0],[0]
"[ θ + p p ] (5)
since the Hamilton equations (2) for the sub-Hamiltonians H1(θ) and H2(p) are linear, and hence analytically integrable.",2.2. Symplectic Numerical Integration,[0],[0]
"One leapfrog step is then defined as:
Φfrog ,H(θ,p) =",2.2. Symplectic Numerical Integration,[0],[0]
"Φ ,H1(θ) ◦",2.2. Symplectic Numerical Integration,[0],[0]
"Φ ,H2(p) ◦",2.2. Symplectic Numerical Integration,[0],[0]
"Φ ,H1(θ) (6)
with the overall proposal given by L leapfrog steps, followed by the momentum flip operator Φp as before:
Φ̃frogL, ,H = Φp ◦ ( Φfrog ,H(θ,p) )L .
",2.2. Symplectic Numerical Integration,[0],[0]
"As each of the flows Φ ,H1(θ), Φ ,H2(p) exactly integrates a sub-Hamiltonian, they inherit the symplecticity, volumepreservation, and time-reversibility of the exact dynamics.",2.2. Symplectic Numerical Integration,[0],[0]
"Moreover, since the composition of symplectic flows is also symplectic and the splitting scheme is symmetric (implying the composition of time-reversible flows is also timereversible), the Jacobian term in the acceptance probability (3) is exactly 1 as in the case of perfect simulation.
",2.2. Symplectic Numerical Integration,[0],[0]
"The leapfrog scheme will not exactly preserve the Hamiltonian H , so the remaining acceptance ratio exp(H(θn,pn) − H(θ̃n+1, p̃n+1)) must be calculated.",2.2. Symplectic Numerical Integration,[0],[0]
"However, the leapfrog integrator has error O( 3) in one leapfrog step (Hairer et al., 2006).",2.2. Symplectic Numerical Integration,[0],[0]
"This error scaling will lead to good energy conservation properties (and thus high acceptance rates in the MH step), even when simulating over long trajectories.",2.2. Symplectic Numerical Integration,[0],[0]
"In Section 2, we noted the role time-reversibility, volumepreservation, and energy conservation of canonical Hamiltonian dynamics play in making them useful candidates for MCMC.",3. Non-Canonical Hamiltonian Monte Carlo,[0],[0]
"In this section, we develop the properties of a general class of flows we refer to as non-canonical Hamiltonian systems that parallel these properties, we use to construct our method magnetic HMC (see Algorithm 1):
Lemma 1.",3. Non-Canonical Hamiltonian Monte Carlo,[0],[0]
"The map ΦAτ,H(θ,p) defined by integrating the non-canonical Hamiltonian system
d
dt [ θ(t) p(t)",3. Non-Canonical Hamiltonian Monte Carlo,[0],[0]
],3. Non-Canonical Hamiltonian Monte Carlo,[0],[0]
"= A∇θ,pH(θ(t),p(t))",3. Non-Canonical Hamiltonian Monte Carlo,[0],[0]
"(7)
with initial conditions (θ,p) for time τ , where A ∈ M2n×2n is any invertible, antisymmetric matrix induces a flow on the coordinates (θ,p) that is still energyconserving (∂τH(ΦAτ,H(θ,p))",3. Non-Canonical Hamiltonian Monte Carlo,[0],[0]
"= 0) and symplectic with
respect to A ([∇θ,pΦτ,H(θ,p)]>A−1[∇θ,pΦτ,H(θ,p)] = A−1) which also implies volume-preservation of the flow.
",3. Non-Canonical Hamiltonian Monte Carlo,[0],[0]
"Within the formal construction of classical mechanics, it is known that any Hamiltonian flow defined on the cotangent bundle (θ,p) of a configuration manifold, which is equipped with an arbitrary symplectic 2-form, will preserve its symplectic structure and admit the corresponding Hamiltonian as a first integral invariant (Arnold, 1989).",3. Non-Canonical Hamiltonian Monte Carlo,[0],[0]
The statement of Lemma 1 is simply a restatement of this fact grounded in a coordinate system.,3. Non-Canonical Hamiltonian Monte Carlo,[0],[0]
"Similar arbitrary, antisymmetric terms have also appeared in the study of MCMC algorithms based on diffusion processes; such samplers often do not enforce detailed balance with respect to the target density and are often implemented as discretizations of stochastic differential equations (Rey-Bellet & Spiliopoulos, 2015; Ma et al., 2015), in contrast to the approach taken here.
",3. Non-Canonical Hamiltonian Monte Carlo,[0],[0]
Our second observation is that the dynamics in (17) are not time-reversible in the traditional sense.,3. Non-Canonical Hamiltonian Monte Carlo,[0],[0]
"Instead, if we consider the parametrization of A as:
A = [ E F −F> G ] (8)
where E, G are antisymmetric and F is taken to be general such that A is invertible, then the non-canonical dynamics have a (pseudo) time-reversibility symmetry:
Lemma 2.",3. Non-Canonical Hamiltonian Monte Carlo,[0],[0]
"If (θ(t),p(t)) is a solution to the non-canonical dynamics:
d
dt [ θ(t) p(t) ]",3. Non-Canonical Hamiltonian Monte Carlo,[0],[0]
"= [ E F −F> G ] ︸ ︷︷ ︸
A
[ ∇θH(θ(t),p(t)) ∇pH(θ(t),p(t)) ]",3. Non-Canonical Hamiltonian Monte Carlo,[0],[0]
"(9)
then (θ̃(t), p̃(t))",3. Non-Canonical Hamiltonian Monte Carlo,[0],[0]
=,3. Non-Canonical Hamiltonian Monte Carlo,[0],[0]
"(θ(−t),−p(−t)) is a solution to the modified non-canonical dynamics:
d
dt [ θ̃(t) p̃(t) ]",3. Non-Canonical Hamiltonian Monte Carlo,[0],[0]
"= [ −E F −F> −G ] ︸ ︷︷ ︸
Ã
[ ∇θ̃H(θ̃(t),p(t)) ∇p̃H(θ̃(t), p̃(t)) ]",3. Non-Canonical Hamiltonian Monte Carlo,[0],[0]
"(10)
if H(θ,p) = H(θ,−p).",3. Non-Canonical Hamiltonian Monte Carlo,[0],[0]
"In particular if E = G = 0 then A = Ã, which reduces to the traditional time-reversal symmetry of canonical Hamiltonian dynamics.
",3. Non-Canonical Hamiltonian Monte Carlo,[0],[0]
Lemma 1 suggests a generalization of HMC that can utilize an arbitrary invertible antisymmetric A matrix in its dynamics; however Lemma 2 indicates the non-canonical dynamics lack a traditional time-reversibility symmetry which poses a potential difficulty to satisfying detailed balance.,3. Non-Canonical Hamiltonian Monte Carlo,[0],[0]
"In particular, we cannot compose Φp with an exact/approximate simulation of ΦAτ,H to make Φ̃ A τ,H = Φp ◦ΦAτ,H self-inverse.
",3. Non-Canonical Hamiltonian Monte Carlo,[0],[0]
Our solution to obtaining a time-reversible proposal is simply to flip the elements of the E and G matrices just as ordinary HMC flips the auxiliary variable p i) at the end of Hamiltonian flow in the proposal and ii) once again after the MH acceptance step to return p to its original direction.,3. Non-Canonical Hamiltonian Monte Carlo,[0],[0]
"In this vein, we view the parameters E and G as auxiliary variables in the state space, and simultaneously flip p, E, and G after having simulated the dynamics, rendering the proposal time-reversible according to Lemma 2 – see Section 2 in the Appendix for full details of this construction.",3. Non-Canonical Hamiltonian Monte Carlo,[0],[0]
This ensures that detailed balance is satisfied for this entire proposal.,3. Non-Canonical Hamiltonian Monte Carlo,[0],[0]
"To avoid “random walk” behaviour in the resulting Markov chain, we can apply a sign flip to E and G, in addition to p, to return them to their original directions after the MH acceptance step.
",3. Non-Canonical Hamiltonian Monte Carlo,[0],[0]
The validity of this construction relies on equipping E and G with symmetric auxiliary distributions.,3. Non-Canonical Hamiltonian Monte Carlo,[0],[0]
"For the remainder of this paper, we further restrict to binary symmetric auxiliary distributions supported on a given antisymmetric matrix V0 and its sign flip −V0 – see Appendix 1.1 for full details.",3. Non-Canonical Hamiltonian Monte Carlo,[0],[0]
"This restriction is not necessary, but gives rise to a simple and interpretable class of algorithms, which is in spirit closest to using fixed parameters E and G, whilst ensuring the proposal satisfies detailed balance.",3. Non-Canonical Hamiltonian Monte Carlo,[0],[0]
"This construction is also reminiscent of lifting constructions prevalent in the discrete Markov chain literature (Chen et al., 1999); heuristically, the signed variables E and G favour proposals in opposing directions.",3. Non-Canonical Hamiltonian Monte Carlo,[0],[0]
"As with standard HMC, exactly simulating the flow ΦAτ,H is rarely tractable, and a numerical integrator is required to approximate the flow.",3.1. Symplectic Numerical Integration for Non-Canonical Dynamics,[0],[0]
"It is not absolutely necessary to use an explicit, symplectic integration scheme; indeed implicit integrators are used in Riemannian HMC to maintain symplecticity of the proposal which comes at a greater complexity and computational cost (Girolami et al., 2009).",3.1. Symplectic Numerical Integration for Non-Canonical Dynamics,[0],[0]
"However explicit, symplectic integrators are simple, have good energy-conservation properties, and are volumepreserving/time-reversible (Hairer et al., 2006), so for the present discussion we restrict our attention to investigating leapfrog-like schemes.
",3.1. Symplectic Numerical Integration for Non-Canonical Dynamics,[0],[0]
"We begin, as in Section 2.2, by considering the symmetric splitting (34), yielding the sub-Hamiltonians H1(θ) = U(θ)/2, H2(p) = p>p/2.",3.1. Symplectic Numerical Integration for Non-Canonical Dynamics,[0],[0]
"The corresponding noncanonical dynamics for the sub-Hamiltonians H1(θ) and H2(p) are:
d
dt",3.1. Symplectic Numerical Integration for Non-Canonical Dynamics,[0],[0]
[ θ p ] =,3.1. Symplectic Numerical Integration for Non-Canonical Dynamics,[0],[0]
"[ E F −F> G ] ︸ ︷︷ ︸
A
[ ∇θU(θ)/2
0
] =",3.1. Symplectic Numerical Integration for Non-Canonical Dynamics,[0],[0]
"[ E∇θU(θ)/2 −F>∇θU(θ)/2 ]
and:
d
dt [ θ p ] =",3.1. Symplectic Numerical Integration for Non-Canonical Dynamics,[0],[0]
"[ E F −F> G ] ︸ ︷︷ ︸
A
[ 0 p ] =",3.1. Symplectic Numerical Integration for Non-Canonical Dynamics,[0],[0]
"[ Fp Gp ] .
",3.1. Symplectic Numerical Integration for Non-Canonical Dynamics,[0],[0]
"We denote the corresponding flows by ΦA ,H1(θ) and ΦA ,H2(p) respectively.",3.1. Symplectic Numerical Integration for Non-Canonical Dynamics,[0],[0]
"The flow Φ A ,H1(θ)
is generally not explicitly tractable unless we take E = 0 – in which case it is solved by an Euler translation as before.",3.1. Symplectic Numerical Integration for Non-Canonical Dynamics,[0],[0]
"Crucially, the flow in ΦA ,H2(p) is a linear differential equation and hence analytically integrable.",3.1. Symplectic Numerical Integration for Non-Canonical Dynamics,[0],[0]
"If G is invertible (and F = I) then:
Φ ,H2(p)",3.1. Symplectic Numerical Integration for Non-Canonical Dynamics,[0],[0]
[ θ p ] =,3.1. Symplectic Numerical Integration for Non-Canonical Dynamics,[0],[0]
[ θ + G−1(exp(G ),3.1. Symplectic Numerical Integration for Non-Canonical Dynamics,[0],[0]
− I)p exp(G )p ] .,3.1. Symplectic Numerical Integration for Non-Canonical Dynamics,[0],[0]
"(11)
See the Appendix for a detailed derivation which also handles the general case where G is not invertible.",3.1. Symplectic Numerical Integration for Non-Canonical Dynamics,[0],[0]
"Thus when E = 0, the flows ΦA ,H1(θ) and Φ A ,H2(p)
are analytically tractable and will inherit the generalized symplecticity and (pseudo) time-reversibility of the exact dynamics in (17).",3.1. Symplectic Numerical Integration for Non-Canonical Dynamics,[0],[0]
"Therefore if we use the symmetric splitting (34) to construct a leapfrog-like step:
Φfrog,A ,H(θ,p) =",3.1. Symplectic Numerical Integration for Non-Canonical Dynamics,[0],[0]
"Φ A ,H1(θ) ◦ΦA ,H2(p) ◦",3.1. Symplectic Numerical Integration for Non-Canonical Dynamics,[0],[0]
"Φ A ,H1(θ)
(12)
we can construct a total proposal that consists of several leapfrog steps, followed by a flip of the momentum and G, Φp ◦ΦG, which will be a volume-preserving, self-inverse map:
Φ̃ frog,A ,H(θ,p) =",3.1. Symplectic Numerical Integration for Non-Canonical Dynamics,[0],[0]
Φp ◦ΦG ◦,3.1. Symplectic Numerical Integration for Non-Canonical Dynamics,[0],[0]
"(ΦA ,H1(θ) ◦",3.1. Symplectic Numerical Integration for Non-Canonical Dynamics,[0],[0]
"Φ A ,H2(p) ◦ΦA ,H1(θ))",3.1. Symplectic Numerical Integration for Non-Canonical Dynamics,[0],[0]
L .,3.1. Symplectic Numerical Integration for Non-Canonical Dynamics,[0],[0]
"(13)
Henceforth we will always take E = 0",3.1. Symplectic Numerical Integration for Non-Canonical Dynamics,[0],[0]
"when we use Φfrog,A ,H(θ,p) to generate leapfrog proposals, which interestingly corresponds to a magnetic dynamics as discussed in Lemma 4.",3.1. Symplectic Numerical Integration for Non-Canonical Dynamics,[0],[0]
A full description of the magnetic HMC algorithm using this numerical integrator is described in Section 5.,3.1. Symplectic Numerical Integration for Non-Canonical Dynamics,[0],[0]
"Here, we describe several tractable subcases of the general formulation of non-canonical Hamiltonian dynamics since these they have interesting physical interpretations.",4. Special Cases,[0],[0]
"One simple variant of HMC is preconditioned HMC where p ∼ N (0,M)",4.1. Mass Preconditioned Dynamics,[0],[0]
"(Neal, 2011), and can be implemented nearly identically to ordinary HMC.",4.1. Mass Preconditioned Dynamics,[0],[0]
"We note that preconditioning can be recovered within our framework using a simple form for the non-canonical A matrix:
Lemma 3.",4.1. Mass Preconditioned Dynamics,[0],[0]
"i) Preconditioned HMC with momentum variable p ∼ N (0,M) in the (θ,p) coordinates is exactly equivalent to simulating non-canonical HMC with p′ = M−1/2p ∼ N",4.1. Mass Preconditioned Dynamics,[0],[0]
"(0, I) and the non-canonical matrix A =
Magnetic Hamiltonian Monte Carlo[ 0 M1/2
−(M1/2)",4.1. Mass Preconditioned Dynamics,[0],[0]
"> 0
] , and then transforming back to
(θ,p) coordinates using p = M1/2p′. Here M1/2 is a Cholesky factor for M.
ii)",4.1. Mass Preconditioned Dynamics,[0],[0]
"On the other hand if we apply a change of basis (via an invertible matrix F) to our coordinates θ′ = F−1θ, simulate HMC in the (θ′,p) coordinates, and transform back to the original basis using F, this is exactly equivalent to
non-canonical HMC with A = [
0 F −F> 0
] .
",4.1. Mass Preconditioned Dynamics,[0],[0]
"Lemma 3 illustrates a fact alluded to in (Neal, 2011); using a mass preconditioning matrix M and a change of basis given by matrix −(M−1/2)",4.1. Mass Preconditioned Dynamics,[0],[0]
> acting on θ leaves the HMC algorithm invariant.,4.1. Mass Preconditioned Dynamics,[0],[0]
"The primary focus of this paper is to investigate the subcase of the dynamics where:
A = ( 0 I −I G ) (14)
for two important reasons3.",4.2. Magnetic Dynamics,[0],[0]
"Firstly for this choice of A we can construct an explicit, symplectic, leapfrog-like integration scheme which is important for developing an efficient HMC sampler as discussed in Section 3.1.",4.2. Magnetic Dynamics,[0],[0]
"Secondly, the dynamics have an interesting physical interpretation quite distinct from mass preconditioning and other HMC variants like Riemannian HMC (Girolami et al., 2009):
Lemma 4.",4.2. Magnetic Dynamics,[0],[0]
"In 3 dimensions the non-canonical Hamiltonian dynamics corresponding to the Hamiltonian H(θ,p) = U(θ) + 12p
>p and A matrix as in (14) are equivalent to the Newtonian mechanics of a charged particle (with unit mass and charge) coupled to a magnetic field ~B (given by a particular function of G - see Appendix): d
2θ dt2 =
−∇θU(θ) + dθdt × ~B.
",4.2. Magnetic Dynamics,[0],[0]
"This interpretation is perhaps surprising since Hamiltonian formulations of classical magnetism are uncommon, although the quantum mechanical treatment naturally incorporates a Hamiltonian framework.",4.2. Magnetic Dynamics,[0],[0]
"However, in light of Lemma 3 we might wonder if by a clever rewriting of the Hamiltonian we can reproduce this system of ODEs using the canonical A matrix (i.e. E = G = 0, F = I).",4.2. Magnetic Dynamics,[0],[0]
"This is not the case:
Lemma 5.",4.2. Magnetic Dynamics,[0],[0]
"The non-canonical Hamiltonian dynamics with magnetic A and Hamiltonian H(θ,p) = U(θ) + 12p
>p cannot be obtained using canonical Hamiltonian dynamics for any choice of smooth Hamiltonian.",4.2. Magnetic Dynamics,[0],[0]
"(See Appendix).
3Note that the effect of a non-identity F matrix can be achieved by simply composing these magnetic dynamics with a coordinate-transformation as suggested in Lemma 3.",4.2. Magnetic Dynamics,[0],[0]
"Using the results discussed in Section 3 and Section 3.1 we can now propose Magnetic HMC – see Algorithm 1.
",5. The Magnetic HMC (MHMC) Algorithm,[0],[0]
Algorithm 1 Magnetic HMC (MHMC),5. The Magnetic HMC (MHMC) Algorithm,[0],[0]
"Initialize (θ0,p0), and set G0 ← G for n = 1, . . .","Input: H , G, L,",[0],[0]
", N do
Resample pn−1 ∼ N(0, I)","Input: H , G, L,",[0],[0]
"Set (θ̃n, p̃n) ← LF(H,L, , (θn−1,pn−1,Gn−1)) with ΦA ,H2(p) as in (11) Flip momentum (θ̃n, p̃n) ← (θ̃n,−p̃n) and set G̃n ← −Gn−1 if Unif([0, 1]) < min(1, exp(H(θn−1,pn−1)","Input: H , G, L,",[0],[0]
"− H(θ̃n, p̃n)))","Input: H , G, L,",[0],[0]
"then
Set (θn,pn,Gn)← (θ̃n, p̃n, G̃n) else
Set (θn,pn,Gn)← (θn−1,pn−1,Gn−1) end if Flip momentum pn ← −pn and flip Gn ← −Gn
end for Output: (θn)Nn=0
One further remark is that by construction the integrator for magnetic HMC is expected to have similarly good energy conservation properties to the integrator of standard HMC:
Lemma 6.","Input: H , G, L,",[0],[0]
"The symplectic leapfrog-like integrator for magnetic HMC will have the same local (∼ O( 3)) and global (∼ O( 2)) error scaling (over τ ∼ L steps), as the canonical leapfrog integrator of standard HMC if the Hamiltonian is separable.","Input: H , G, L,",[0],[0]
(See Appendix).,"Input: H , G, L,",[0],[0]
It is worthwhile to contrast the algorithmic differences between magnetic HMC and ordinary HMC.,"Input: H , G, L,",[0],[0]
"Intuitively, the role of the flow ΦA ,H2(p) – which reduces to the standard Euler translation update of ordinary HMC when G = 0 – is to introduce a rotation into the momentum space of the flow.","Input: H , G, L,",[0],[0]
"In particular, a non-zero element Gij will allow momentum to periodically flow between pi and pj .","Input: H , G, L,",[0],[0]
"If we regard G as an element in the Lie algebra of antisymmetric matrices, which can be thought of as infinitesimal rotations, then the exponential map exp(G ) will project this transformation into the Lie group of real orthogonal linear maps.
","Input: H , G, L,",[0],[0]
"With respect to computational cost, although magnetic HMC requires matrix exponentiation/diagonalization to simulate ΦA ,H2(p), this only needs to be computed once upfront for ±G and cached; moreover, as ±G is diagonalizable, the exact exponential can be calculated inO(d3) time.","Input: H , G, L,",[0],[0]
"Additionally, there is an O(d2) cost for the matrix-vector products needed to implement the flow ΦA ,H2(p) as with preconditioning.","Input: H , G, L,",[0],[0]
"However, it is possible to design sparsi-
fied matrix representations of A which will translate into sparsified rotations if we only wish to ”curl” in a specific subspace of dimension d0 – which will translate into a computational cost of O(d30) and O(d20) respectively.","Input: H , G, L,",[0],[0]
"An important problem to address is the selection of the G matrix, which affords a great deal of flexibility to MHMC relative to HMC; this point is further discussed in the Experiments section, where we argue that in certain cases intuitive heuristics can be used to select the G matrix.","Input: H , G, L,",[0],[0]
Here we investigate the performance of magnetic HMC against standard HMC in several examples; in each case commenting on our choice of the magnetic field term G. Step sizes ( ) and number of leapfrog steps (L) were tuned to achieve an acceptance rate between .7,6. Experiments,[0],[0]
"− .8, after which the norm of the non-zero elements in G was set to∼ .1−.2",6. Experiments,[0],[0]
"which was found to work well.
",6. Experiments,[0],[0]
In the Appendix we also display illustrations of different MHMC proposals across several targets in order to provide more intuition for MHMC’s dynamics.,6. Experiments,[0],[0]
Further experimental details and an additional experiment on a Gaussian funnel target are also provided in the Appendix.,6. Experiments,[0],[0]
"We consider two highly ill-conditioned Gaussians similar to as in (Sohl-Dickstein et al., 2014) to illustrate a heuristic for G matrix selection and demonstrate properties of the magnetic dynamics.",6.1. Multiscale Gaussians,[0],[0]
"In particular we consider a centered, uncorrelated 2D Gaussian with covariance eigenvalues of 106 and 1 as well as a centered, uncorrelated 10D Gaussian with two large covariance eigenvalues of 106 and remaining eigenvalues of 1.",6.1. Multiscale Gaussians,[0],[0]
"We denote their coordinates as x = (x1, x2) ∈ R2 and x = (x1, . . .",6.1. Multiscale Gaussians,[0],[0]
", x10) ∈ R10 respectively.",6.1. Multiscale Gaussians,[0],[0]
"HMC will have difficulty exploring the directions of
0 5× 104 Lag
0
1
A u to co rr e la ti o n
HMC
MHMC
0 5× 104 Lag
0
1
A u to co rr e la ti o n
HMC
MHMC
Figure 2.",6.1. Multiscale Gaussians,[0],[0]
"Averaged Autocorrelation of HMC vs MHMC on a 10D ill-conditioned Gaussian (left) and Averaged Autocorrelation of HMC vs MHMC on a 2D ill-conditioned Gaussian.
",6.1. Multiscale Gaussians,[0],[0]
large marginal variance since its exploration will often be limited by the smaller variance directions.,6.1. Multiscale Gaussians,[0],[0]
"Accordingly, in order to induce a periodic momentum flow between the directions of small and large variance, we introduce nonzero components Gij into the subspaces spanned directly between the large and small eigenvalues.",6.1. Multiscale Gaussians,[0],[0]
"Indeed, we find that magnetic G term is encouraging more efficient exploration as we can see from the averaged autocorrelation of samples generated from the HMC/MHMC chains – see Figure 2.",6.1. Multiscale Gaussians,[0],[0]
"Further, by running the 50 parallel chains for 107 timesteps, we computed both the bias and Monte Carlo standard errors (MCSE) of the estimators of the target moments as shown in Table 1 and Table 2.",6.1. Multiscale Gaussians,[0],[0]
"We compare MHMC vs. HMC on a simple, but interesting, 2D density over x = (x, y) ∈ R2 comprised of an evenly weighted mixture of isotropic Gaussians: p(x) = 12N (x;µ,Σ)",6.2. Mixture of Gaussians,[0],[0]
"+ 12N (x;−µ,Σ) for σ2x = σ2y = 1, ρxy = 0 and µ = (2.5,−2.5).",6.2. Mixture of Gaussians,[0],[0]
This problem is challenging for HMC because the gradients in canonical Hamiltonian dynamics force it to one of the two modes.,6.2. Mixture of Gaussians,[0],[0]
"We tuned HMC to achieve an acceptance rate of ∼ .75 and used the same , L for MHMC, generating 15000 samples from both HMC and MHMC with these settings.",6.2. Mixture of Gaussians,[0],[0]
The addition of the magnetic field term G – which has one degree of freedom in this case – introduces an asymmetric “curl” into the dynamics that pushes the sampler across the saddlepoint to the other mode allowing it to efficiently mix around both modes and between them – see Figure 3.,6.2. Mixture of Gaussians,[0],[0]
"The maximum mean discrepancy between exact samples generated from the target density and samples generated from both HMC and MHMC chains was also estimated for various magnitudes of G, using a quadratic ker-
nel k(x,x′) =",6.2. Mixture of Gaussians,[0],[0]
"(1 + 〈x,x′〉)2 and averaged over 100 runs of the Markov chains (Borgwardt et al., 2006).",6.2. Mixture of Gaussians,[0],[0]
"Here, we clearly see that for various values of the nonzero component of G, denoted g, the samples generated by MHMC more faithfully reflect the structure of the posterior.",6.2. Mixture of Gaussians,[0],[0]
"As before, we ran 50 parallel chains for 107 timesteps to compute both the bias and Monte Carlo standard errors (MCSE) of the estimators of the target moments as shown in Table 3.",6.2. Mixture of Gaussians,[0],[0]
"Additional experiments over a range of , L (and corre-
MHMC .00239",6.2. Mixture of Gaussians,[0],[0]
"± .012 0.000596 ± 0.00365
sponding acceptance rates) and details are included in the Appendix for this example, demonstrating similar behavior.",6.2. Mixture of Gaussians,[0],[0]
"Finally, we consider the problem of Bayesian inference over the parameters of the FitzHugh-Nagumo model (a set of nonlinear ordinary differential equations, originally developed to model the behavior of axial spiking potentials in neurons) as in (Ramsay et al., 2007; Girolami & Calderhead, 2011).",6.3. FitzHugh-Nagumo model,[0],[0]
"The FitzHugh-Nagumo model is a dynamical system (V (t), R(t)) defined by the following coupled differential equations:
V̇ (t) = c(V (t)− V (t)3/3 +R(t)) Ṙ(t)",6.3. FitzHugh-Nagumo model,[0],[0]
= −(V,6.3. FitzHugh-Nagumo model,[0],[0]
"(t)− a+ bR(t))/c (15)
We consider the problem where the initial conditions
(V (0), R(0)) of the system (15) are known, and a set of noise-corrupted observations (Ṽ (tn), R̃(tn))Nn=0 = (Va,b,c(tn)+ε V n , Ra,b,c(tn)+ε R n ) N",6.3. FitzHugh-Nagumo model,[0],[0]
"n=0 at discrete time points 0 = t0 < t1 < · · · < tN , are available - note that we illustrate dependence of the trajectories on the model parameters explicitly via subscripts.",6.3. FitzHugh-Nagumo model,[0],[0]
"It is not possible to recover the true parameter values of the model from these observations, but we can obtain a posterior distribution over them by specifying a model for the observation noise and a prior distribution over the model parameters.
",6.3. FitzHugh-Nagumo model,[0],[0]
"Similar to (Ramsay et al., 2007; Girolami & Calderhead, 2011), we assume that the observation noise variables (εVn ) N",6.3. FitzHugh-Nagumo model,[0],[0]
n=0 and (ε V n ) N,6.3. FitzHugh-Nagumo model,[0],[0]
"n=0 are iid N (0, 0.12), and take an independent N (0, 1) prior over each parameter a, b, and c. This yields a posterior distribution of the form
p(a, b, c) ∝",6.3. FitzHugh-Nagumo model,[0],[0]
"N (a; 0, 1)N (b; 0, 1)N (c; 0, 1) × N∏ n=0 N",6.3. FitzHugh-Nagumo model,[0],[0]
"(Ṽ (tn);Va,b,c(tn), 0.12) (16)
",6.3. FitzHugh-Nagumo model,[0],[0]
"Importantly, the highly non-linear dependence of the trajectory on the parameters a, b and c yields a complex posterior distribution - see Figure 4.",6.3. FitzHugh-Nagumo model,[0],[0]
"Full details of the model set-up can be found in (Ramsay et al., 2007; Girolami & Calderhead, 2011).
",6.3. FitzHugh-Nagumo model,[0],[0]
"For our experiments, we used fixed parameter settings of a = 0.2, b = 0.2, c = 3.0 to generate 200 evenlyspaced noise-corrupted observations over the time interval t =",6.3. FitzHugh-Nagumo model,[0],[0]
"[0, 20] (as in (Ramsay et al., 2007; Girolami & Calderhead, 2011)).",6.3. FitzHugh-Nagumo model,[0],[0]
"We performed inference over the posterior distribution of parameters (a, b, c) with this set of observations using both the HMC and MHMC algorithms, which was perturbed with a magnetic field in each of the 3 axial planes of parameters – along the ab, ac, and bc axes with magnitude g = 0.1.",6.3. FitzHugh-Nagumo model,[0],[0]
"The chains were run to gener-
ate 1000 samples over 100 repetitions with settings of = 0.015, L = 10, which resulted in an average acceptance rate of∼ .8.",6.3. FitzHugh-Nagumo model,[0],[0]
"The effective sample size of each of the chains normalized per unit time was then computed for each chain.
",6.3. FitzHugh-Nagumo model,[0],[0]
"Since each query to the posterior log-likelihood or posterior gradient log-likelihood requires solving an augmented set of differential equations as in (15), the computation time (∼ 238s) of all the methods was nearly identical.",6.3. FitzHugh-Nagumo model,[0],[0]
"Moreover,
note that all methods achieved nearly perfect mixing over the first coordinate so their effective sample size were truncated at 1000 for the a coordinate.",6.3. FitzHugh-Nagumo model,[0],[0]
"In this example, we can see that all magnetic perturbations slightly increase the mixing rate of the sampler over each of the (b, c) coordinates with the ab perturbation performing best.",6.3. FitzHugh-Nagumo model,[0],[0]
"We have investigated a framework for MCMC algorithms based on non-canonical Hamiltonian dynamics and have given a construction for an explicit, symplectic integrator that is used to implement a generalization of HMC we refer to as magnetic HMC.",7. Discussion and Conclusion,[0],[0]
We have also shown several examples where the non-canonical dynamics of MHMC can improve upon the sampling performance of standard HMC.,7. Discussion and Conclusion,[0],[0]
"Important directions for further research include finding more automated, adaptive mechanisms to set the matrix G, as well as investigating positionally-dependent magnetic field components, similar to how Riemannian HMC corresponds to local preconditioning.",7. Discussion and Conclusion,[0],[0]
We believe that exploiting more general deterministic flows (such as also maintaining a non-zero E in the top left-block of a general A matrix) could form a fruitful area for further research on MCMC methods.,7. Discussion and Conclusion,[0],[0]
"The authors thank John Aston, Adrian Weller, Maria Lomeli, Yarin Gal and the anonymous reviewers for helpful comments.",Acknowledgements,[0],[0]
"MR acknowledges support by the UK Engineering and Physical Sciences Research Council (EPSRC) grant EP/L016516/1 for the University of Cambridge Centre for Doctoral Training, the Cambridge Centre for Analysis.",Acknowledgements,[0],[0]
RET thanks EPSRC grants EP/M0269571 and EP/L000776/1 as well as Google for funding.,Acknowledgements,[0],[0]
Here we provide proofs for results discussed in Section 3 of the main text regarding non-canonical dynamics.,A. Section 3 and 4 Proofs,[0],[0]
Lemma 1.,A. Section 3 and 4 Proofs,[0],[0]
"The map ΦAτ,H(θ,p) defined by integrating the non-canonical Hamiltonian system
d
dt [ θ(t) p(t)",A. Section 3 and 4 Proofs,[0],[0]
],A. Section 3 and 4 Proofs,[0],[0]
"= A∇θ,pH(θ(t),p(t))",A. Section 3 and 4 Proofs,[0],[0]
"(17)
with initial conditions (θ,p) for time τ , where A ∈ M2n×2n is any invertible, antisymmetric matrix induces a flow on the coordinates (θ,p) that is still energy-conserving (∂τH(ΦAτ,H(θ,p))",A. Section 3 and 4 Proofs,[0],[0]
"= 0) and symplectic with respect to A ([∇θ,pΦτ,H(θ,p)]>A−1[∇θ,pΦτ,H(θ,p)] = A−1) which also implies volume-preservation of the flow.
",A. Section 3 and 4 Proofs,[0],[0]
Proof.,A. Section 3 and 4 Proofs,[0],[0]
"The proofs of both results simply uses the antisymmetry of A.
Energy-Conservation – Simply, we have that:
∂τH(Φτ,H(θ,p))",A. Section 3 and 4 Proofs,[0],[0]
"= ∇θ,pH(Φτ,H(θ,p))∂τΦτ,H(θ,p) =",A. Section 3 and 4 Proofs,[0],[0]
"(18) ∇θ,pH(Φτ,H(θ,p))>A∇θ,pH(Φτ,H(θ,p))",A. Section 3 and 4 Proofs,[0],[0]
"= 0 (19)
using the antisymmetry of A and symmetry of∇θ,pH(Φτ,H(θ,p))∇θ,pH(Φτ,H(θ,p))",A. Section 3 and 4 Proofs,[0],[0]
>.,A. Section 3 and 4 Proofs,[0],[0]
"Symplecticness – We must show that the Jacobian of the flow generated by the dynamics preserves the non-canonical structure matrix A, which amounts to showing:
",A. Section 3 and 4 Proofs,[0],[0]
"[∇θ,pΦτ,H(θ,p)]>︸ ︷︷ ︸ F (τ)>",A. Section 3 and 4 Proofs,[0],[0]
A−1,A. Section 3 and 4 Proofs,[0],[0]
"[∇θ,pΦτ,H(θ,p)]︸ ︷︷ ︸ F (τ) =",A. Section 3 and 4 Proofs,[0],[0]
"A−1 (20)
where we define F (τ) = ∇θ,pΦτ,H(θ,p) as the time-evolving Jacobian of the flow.",A. Section 3 and 4 Proofs,[0],[0]
"First, note that F (τ) can be equivalently described as the solution to the differential equation:
d
dτ F (τ) = A∇θ,p∇θ,pH(Φτ,H(θ,p))F (τ) (21)
with the initial condition F (0) =",A. Section 3 and 4 Proofs,[0],[0]
I2d (the Jacobian for the identity map at t = 0),A. Section 3 and 4 Proofs,[0],[0]
.,A. Section 3 and 4 Proofs,[0],[0]
"Trivially, we have:
F (0)A−1F (0) =",A. Section 3 and 4 Proofs,[0],[0]
"A−1 (22)
Then note that:
d
dτ (F (τ)>A−1F (τ))",A. Section 3 and 4 Proofs,[0],[0]
"= F (τ)>A−1A∇θ,p∇θ,pH(Φτ,H(θ,p))F (τ) + F (τ)>∇θ,p∇θ,pH(Φτ,H(θ,p))A>A−1F (τ) = F (τ)>∇θ,p∇θ,pH(Φτ,H(θ,p))F (τ)− F (τ)>∇θ,p∇θ,pH(Φτ,H(θ,p))F (τ) = 0
as desired by simply using A> = −A.
Time-Reversibility – However, crucially it is not the case that the Hamilton equations are time-reversible in the traditional sense of canonical Hamiltonian dynamics.",A. Section 3 and 4 Proofs,[0],[0]
Lemma 2.,A. Section 3 and 4 Proofs,[0],[0]
"If (θ(t),p(t)) is a solution to the non-canonical dynamics:
d
dt [ θ(t) p(t) ]",A. Section 3 and 4 Proofs,[0],[0]
"= [ E F −F> G ] ︸ ︷︷ ︸
A
[ ∇θH(θ(t),p(t)) ∇pH(θ(t),p(t)) ]",A. Section 3 and 4 Proofs,[0],[0]
"(23)
then (θ̃(t), p̃(t))",A. Section 3 and 4 Proofs,[0],[0]
"= (θ(−t),−p(−t)) is a solution to the modified non-canonical dynamics:
d
dt [ θ̃(t) p̃(t) ] =",A. Section 3 and 4 Proofs,[0],[0]
"[ −E F −F> −G ] ︸ ︷︷ ︸
Ã
[ ∇θ̃H(θ̃(t),p(t)) ∇p̃H(θ̃(t), p̃(t))",A. Section 3 and 4 Proofs,[0],[0]
"] (24)
ifH(θ,p) = H(θ,−p).",A. Section 3 and 4 Proofs,[0],[0]
"In particular if E = G = 0 then A = Ã, which reduces to the traditional time-reversal symmetry of canonical Hamiltonian dynamics.
",A. Section 3 and 4 Proofs,[0],[0]
Proof.,A. Section 3 and 4 Proofs,[0],[0]
"A direct calculation yields
d
dt [ θ̃(t) p̃(t) ] =",A. Section 3 and 4 Proofs,[0],[0]
"[ − ddtθ(−t)
d dtp(−t)
] = [ −E∇θH(θ(−t))− F∇pH(θ(−t))",A. Section 3 and 4 Proofs,[0],[0]
−F>∇θH(θ(−t)),A. Section 3 and 4 Proofs,[0],[0]
+ G∇pH(θ(−t)) ],A. Section 3 and 4 Proofs,[0],[0]
"=
[ −E∇θ̃H(θ̃(t)) + F∇p̃H(θ̃(t)) −F>∇θ̃H(θ̃(t))−G∇p̃H(θ̃(t))",A. Section 3 and 4 Proofs,[0],[0]
] =,A. Section 3 and 4 Proofs,[0],[0]
"[ −E F −F> −G ] ︸ ︷︷ ︸
Ã
[ ∇θ̃H(θ̃(t)) ∇p̃H(θ̃(t))",A. Section 3 and 4 Proofs,[0],[0]
],A. Section 3 and 4 Proofs,[0],[0]
As remarked in the main text it is necessary to flip the E and G matrices at the end of a deterministic simulation of the Hamiltonian dynamics in order to render the proposal time-reversible which is in turn necessary to satisfy detailed balance.,A.1. Non-Canonical Dynamics Variable Augmentation,[0],[0]
"This is crucial for the correctness of the algorithm especially when an approximate simulation of the dynamics is used (as is always often the case).
",A.1. Non-Canonical Dynamics Variable Augmentation,[0],[0]
"In particular, say that we wish to use ΦAτ,H(θ,p) as a transition kernel with fixed, non-zero values of E = E0 and G = G0.",A.1. Non-Canonical Dynamics Variable Augmentation,[0],[0]
"We first augment the state-space by placing a symmetric, binary distribution independently over E and G such that p(E = E0) = p(E = −E0) = 1/2 and p(G = G0) = p(G = −G0) = 1/2, independently of θ,p:
ρ(θ,p,E,G) ∝",A.1. Non-Canonical Dynamics Variable Augmentation,[0],[0]
"e−H(θ,p)p(E)p(G).",A.1. Non-Canonical Dynamics Variable Augmentation,[0],[0]
"(25)
Importantly, this augmentation leaves the distribution over θ,p intact when E and G are marginalized out.",A.1. Non-Canonical Dynamics Variable Augmentation,[0],[0]
"Just as applying the momentum flip operator, Φp : (θ,p,E,G)→ (θ,−p,E,G), is a deterministic, energy-preserving, volume-preserving transformation, the E, G flip operators, ΦE : (θ,p,E,G)",A.1. Non-Canonical Dynamics Variable Augmentation,[0],[0]
"→ (θ,p,−E,G) and ΦG : (θ,p,E,G) → (θ,p,E,−G), are also deterministic, energy-preserving, volume-preserving transformations that leave (25) invariant for this particular augmentation with p(E) and p(G).",A.1. Non-Canonical Dynamics Variable Augmentation,[0],[0]
"We can now build a self-inverse operator Φ̃Aτ,H(θ,p), composed of simulating the Hamiltonian flow as ΦAτ,H(θ,p) plus ΦE ◦ΦG ◦Φp, a flip of p, E, G, as:
Φ̃Aτ,H(θ,p) = ΦE ◦ΦG ◦Φp ◦ΦAτ,H(θ,p) (26)
Now we have constructed a deterministic, self-inverse map Φ̃Aτ,H(θ,p).",A.1. Non-Canonical Dynamics Variable Augmentation,[0],[0]
"Φ̃ A τ,H(θ,p) can now be used as the proposal for a reversible MCMC algorithm.
",A.1. Non-Canonical Dynamics Variable Augmentation,[0],[0]
"An important point to note is that our choice of variable augmentation strategy, namely augmenting with binary distribution, is certainly not unique.",A.1. Non-Canonical Dynamics Variable Augmentation,[0],[0]
"However, it is perhaps the most natural and simplest choice which avoids the repetitive computation of matrix exponentials/diagonalizations since the approximate flow detailed in Section B.2 will only need to compute matrix exponentials once upfront for ±G.",A.1. Non-Canonical Dynamics Variable Augmentation,[0],[0]
"A common variation on standard HMC dynamics is to set the kinetic energy term in the HamiltonianH(θ,p) to 12p >M−1p for some symmetric positive-definite matrix M, and sample the initial momentum variable p from the corresponding distribution N (0,M).",A.2. Mass Preconditioning Proofs,[0],[0]
"However, we can contextualize preconditioning using a non-canonical A matrix in the following manner:
Lemma 3.",A.2. Mass Preconditioning Proofs,[0],[0]
"i) Preconditioned HMC with momentum variable p ∼ N (0,M) in the (θ,p) coordinates, is exactly equivalent to simulating non-canonical HMC with p′ = M−1/2p ∼ N (0, I) and the non-canonical matrix:
A =
[ 0 M1/2
−(M1/2)",A.2. Mass Preconditioning Proofs,[0],[0]
> 0,A.2. Mass Preconditioning Proofs,[0],[0]
] and,A.2. Mass Preconditioning Proofs,[0],[0]
"then transforming back to (θ,p) coordinates using p = M1/2p′. Here M1/2 is a Cholesky factor for M.
ii)",A.2. Mass Preconditioning Proofs,[0],[0]
"On the other hand if we apply a change of basis (via an invertible matrix F) to our coordinates θ′ = F−1θ, simulate HMC in the (θ′,p) coordinates, and transform back to the original basis using F, this is exactly equivalent to noncanonical HMC with
A = [ 0 F −F> 0",A.2. Mass Preconditioning Proofs,[0],[0]
],A.2. Mass Preconditioning Proofs,[0],[0]
Proof.,A.2. Mass Preconditioning Proofs,[0],[0]
We first prove the equivalence regarding the change of basis in momentum space.,A.2. Mass Preconditioning Proofs,[0],[0]
"Under the M mass matrix variant of HMC, p is drawn from a N (0,M) distribution, and the dynamics of θ,p are then given by
d
dt",A.2. Mass Preconditioning Proofs,[0],[0]
[ θ p ] = [ M−1p −∇θU(θ) ],A.2. Mass Preconditioning Proofs,[0],[0]
"Denoting the upper-triangular Cholesky factor of M−1 by M−1/2, and introducing a new variable p′ = M−1/2p, we obtain the following dynamics for the joint variable (θ,p′):
d
dt",A.2. Mass Preconditioning Proofs,[0],[0]
[ θ p′ ] = d dt [ θ M−1/2p ] =,A.2. Mass Preconditioning Proofs,[0],[0]
[ (M−1/2)>p′ −M−1/2∇θU(θ) ],A.2. Mass Preconditioning Proofs,[0],[0]
= [ 0 (M−1/2)> −M−1/2 0 ],A.2. Mass Preconditioning Proofs,[0],[0]
[ ∇θU(θ) p′ ],A.2. Mass Preconditioning Proofs,[0],[0]
"Further, note that if the marginal distribution of p is N (0,M), then under this change of variables p′ has the marginal distributionN (0, I).",A.2. Mass Preconditioning Proofs,[0],[0]
"Thus, simulating canonical HMC with a non-identity mass matrix is equivalent to making a change of basis in momentum space, simulating non-canonical HMC with a particular choice of non-canonical A matrix, and finally reverting back to the original basis.
",A.2. Mass Preconditioning Proofs,[0],[0]
"We now prove the equivalence regarding the change of basis in θ space, which follows similarly.",A.2. Mass Preconditioning Proofs,[0],[0]
"Consider non-canonical HMC on the state-momentum pair (θ,p), with the antisymmetric matrix A taking the particular form
A = ( 0 F −F> 0 )",A.2. Mass Preconditioning Proofs,[0],[0]
"The states θ,p obtained from this algorithm are equal to those obtained by first changing basis to θ′",A.2. Mass Preconditioning Proofs,[0],[0]
"= F−1θ, then simulating standard HMC dynamics for the pair (θ′,p) with respect to the Hamiltonian
H ′(θ′,p)",A.2. Mass Preconditioning Proofs,[0],[0]
"= U ′(θ′) + 1
2 p>p
= U(Fθ) + 1
2 p>p
and then reverting to the original basis as θ = Fθ′. To see this, first note that if we denote the distribution on the coordinates θ corresponding to the potential U by π(θ) = e−U(θ), then the corresponding distribution on the coordinates θ′ is given by π′, where
π′(θ′) = det(F)π(Fθ′)
",A.2. Mass Preconditioning Proofs,[0],[0]
"The corresponding potential U ′ is therefore given by
U ′(θ′) = U(Fθ′)
",A.2. Mass Preconditioning Proofs,[0],[0]
Running canonical HMC dynamics targeting the Hamiltonian H ′,A.2. Mass Preconditioning Proofs,[0],[0]
"yields the dynamics:
d
dt
[ θ′
p
] =",A.2. Mass Preconditioning Proofs,[0],[0]
"[ p
−∇θ′U(θ′) ]",A.2. Mass Preconditioning Proofs,[0],[0]
"But note then that the dynamics of the original coordinates are then given by:
d
dt [ θ p ] = d dt [ Fθ′ p ] =",A.2. Mass Preconditioning Proofs,[0],[0]
[ Fp −∇θ′U(θ′) ] =,A.2. Mass Preconditioning Proofs,[0],[0]
[ Fp −∇θ′U(Fθ) ] =,A.2. Mass Preconditioning Proofs,[0],[0]
[ Fp −(F>)∇θU(θ) ] = [ 0 F −F> 0 ],A.2. Mass Preconditioning Proofs,[0],[0]
"[ ∇θU(θ) p
] which are exactly a special case of non-canonical HMC dynamics described above.",A.2. Mass Preconditioning Proofs,[0],[0]
Here we provide proofs related to the dynamics of magnetic HMC and it’s symplectic integration scheme.,B. Magnetic HMC (MHMC),[0],[0]
"We first establish the connection between the particular subcase of non-canonical Hamiltonian dynamics where
A = [ 0 I −I G ]
and Newton’s law for a charged particle coupled to a magnetic field.
",B.1. Non-Canonical Dynamics and Magnetism,[0],[0]
Lemma 4.,B.1. Non-Canonical Dynamics and Magnetism,[0],[0]
"In 3-dimensions the non-canonical Hamiltonian dynamics, with Hamiltonian H(θ,p) = U(θ) + 12p >p, correspond to simulating the differential equations:
d
dt",B.1. Non-Canonical Dynamics and Magnetism,[0],[0]
"[ θ p ] = [ 0 I −I G ] ︸ ︷︷ ︸
A
[ ∇θH ∇pH ] ≡",B.1. Non-Canonical Dynamics and Magnetism,[0],[0]
"[ 0 I −I G ] ︸ ︷︷ ︸
A
[ ∇θU(θ)
p
] (27)
where
G =  0 −b3 b2b3 0 −b1 −b2 b1 0  are equivalent to the Newtonian mechanics of a charged particle (with unit mass and charge) coupled to a magnetic field
~B = b1b2 b3  which take the form: d2θ
dt2 = −∇θU(θ)",B.1. Non-Canonical Dynamics and Magnetism,[0],[0]
"+
dθ dt × ~B (28)
where θ is simply a 3-dimensional vector and × the cross-product.
",B.1. Non-Canonical Dynamics and Magnetism,[0],[0]
Proof.,B.1. Non-Canonical Dynamics and Magnetism,[0],[0]
"If we let θ and p denote our position and momentum coordinates in 3 dimensions then Newton’s law for a charged particle in a magnetic field (with m = q = 1) is:
d2θ dt2 = −∇θU(θ) +",B.1. Non-Canonical Dynamics and Magnetism,[0],[0]
dθ dt × ~B,B.1. Non-Canonical Dynamics and Magnetism,[0],[0]
"(29)
Defining momentum canonically as dθdt = p we have:
d
dt [ θ p ] =",B.1. Non-Canonical Dynamics and Magnetism,[0],[0]
"[ p
−∇θU(θ) +",B.1. Non-Canonical Dynamics and Magnetism,[0],[0]
"dθdt × ~B
] =",B.1. Non-Canonical Dynamics and Magnetism,[0],[0]
"[ p
−∇θU(θ)",B.1. Non-Canonical Dynamics and Magnetism,[0],[0]
+,B.1. Non-Canonical Dynamics and Magnetism,[0],[0]
"Gp
] ≡",B.1. Non-Canonical Dynamics and Magnetism,[0],[0]
"[
0 I −I G ] ︸ ︷︷ ︸
A
[ ∇θU(θ)
p
] (30)
We now show that the dynamics used in magnetic HMC cannot be reproduced by simply choosing a different smooth Hamiltonian, H ′(θ,p) and using the canonical A matrix:
A = [ 0 I −I 0 ] to generate the dynamics.
",B.1. Non-Canonical Dynamics and Magnetism,[0],[0]
Lemma 5.,B.1. Non-Canonical Dynamics and Magnetism,[0],[0]
"The non-canonical Hamiltonian dynamics with magnetic A and HamiltonianH(θ,p) =",B.1. Non-Canonical Dynamics and Magnetism,[0],[0]
"U(θ)+ 12p >p cannot be obtained using canonical Hamiltonian dynamics for any choice of smooth Hamiltonian.
",B.1. Non-Canonical Dynamics and Magnetism,[0],[0]
Proof.,B.1. Non-Canonical Dynamics and Magnetism,[0],[0]
"Consider the ODEs corresponding to non-canonical dynamics with magnetic A and H(θ,p) = U(θ) + 12p",B.1. Non-Canonical Dynamics and Magnetism,[0],[0]
">p:
d
dt",B.1. Non-Canonical Dynamics and Magnetism,[0],[0]
[ θ p ] = [ 0 I −I G ],B.1. Non-Canonical Dynamics and Magnetism,[0],[0]
[ ∇θU(θ) p ] =,B.1. Non-Canonical Dynamics and Magnetism,[0],[0]
[ p −∇θU(θ) +,B.1. Non-Canonical Dynamics and Magnetism,[0],[0]
Gp ] .,B.1. Non-Canonical Dynamics and Magnetism,[0],[0]
"(31)
Assume, to obtain a contradiction, that these canonical Hamiltonian dynamics can be reproduced for some choice of smooth H ′(θ,p) and canonical A matrix (i.e. E = G = 0, F = I):
d
dt",B.1. Non-Canonical Dynamics and Magnetism,[0],[0]
[ θ p ] = [ 0 I −I 0 ],B.1. Non-Canonical Dynamics and Magnetism,[0],[0]
"[ ∇θH ′(θ,p) ∇pH ′(θ,p) ]",B.1. Non-Canonical Dynamics and Magnetism,[0],[0]
= [ p −∇θU(θ) +,B.1. Non-Canonical Dynamics and Magnetism,[0],[0]
Gp ] .,B.1. Non-Canonical Dynamics and Magnetism,[0],[0]
"(32)
",B.1. Non-Canonical Dynamics and Magnetism,[0],[0]
"This implies: [ ∇pH ′(θ,p) ∇θH ′(θ,p) ] =",B.1. Non-Canonical Dynamics and Magnetism,[0],[0]
[ p ∇θU(θ)−Gp ] =⇒,B.1. Non-Canonical Dynamics and Magnetism,[0],[0]
"[ ∇θ∇pH ′(θ,p) ∇p∇θH ′(θ,p) ]",B.1. Non-Canonical Dynamics and Magnetism,[0],[0]
= [ 0 −G ] .,B.1. Non-Canonical Dynamics and Magnetism,[0],[0]
"(33)
However, as long as the 2nd-order mixed partial derivatives are continuous they must be equal; so the conclusion follows.",B.1. Non-Canonical Dynamics and Magnetism,[0],[0]
"We begin by considering the symmetric splitting:
H(θ,p) = U(θ)/2︸ ︷︷ ︸ H1(θ) + pTp/2︸ ︷︷ ︸ H2(p) +U(θ)/2︸ ︷︷ ︸ H1(θ)
(34)
",B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
"The corresponding non-canonical dynamics for the sub-Hamiltonians H1(θ) and H2(p) are:
d
dt",B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
[ θ p ] =,B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
"[ E F −F> G ] ︸ ︷︷ ︸
A
[ ∇θU(θ)/2
0
] =",B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
[ E∇θU(θ)/2 −F>∇θU(θ)/2 ],B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
"(35)
and
d
dt [ θ p ] =",B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
"[ E F −F> G ] ︸ ︷︷ ︸
A
[ 0 p ] =",B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
[ Fp Gp ] .,B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
"(36)
We denote the corresponding flows by ΦA ,H1(θ) and Φ A ,H2(p) respectively.",B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
"The flow in (35) is generally not explicitly tractable unless we take E = 0 – in which case it is solved by an Euler translation as for standard Hamiltonian dynamics.
",B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
"Crucially, the flow in (36) is a linear differential equation and hence analytically integrable.",B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
"Without loss of generality, we restrict ourselves to the case F = I (the case for general F follows similarly).",B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
"The dynamics associated with the flow H2(p) introduced in Lemma 4 become
d
dt [ θ(t) p(t) ]",B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
"= [ p(t) Gp(t) ] with initial condition (θ0,p0).",B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
"Using the power series representation of the matrix exponential, the second differential equation for p may be integrated analytically to yield the following flow in p-space:
p(t)",B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
"= exp(Gt)p0
Substituting this result into the differential equation for θ yields
dθ dt = exp(Gt)p0
If G is invertible then once again using the power series representation of the matrix exponential and rearranging yields the solution
Φ ,H2(p)",B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
[ θ p ] =,B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
[ θ + G−1(exp(G ),B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
"− I)p exp(G )p ]
If G is not invertible, then slightly more care must be taken to first diagonalize G and separate its invertible/singular components.",B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
Since G is strictly antisymmetric it can be written as iH where H is a Hermitian matrix.,B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
"Thus it can be diagonalized over C as:
G = [ UΛ U0 ]",B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
[Λ 0 0 0 ],B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
"[ U>Λ U>0 ]
where Λ is a diagonal submatrix consisting of the nonzero eigenvalues of G. [ UΛ U0 ] and [ U>Λ U>0 ] are unitary matrices where the columns of UΛ are the eigenvectors of G corresponding to its nonzero eigenvalues while the columns of U0 are the eigenvectors of G corresponding to its zero eigenvalues.",B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
"Even if G is not invertible we still have:
p(t)",B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
"= exp(Gt)p0
However it is more convenient to represent the matrix exponential as:
exp(Gt) =",B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
[ UΛ U0 ],B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
[exp(Λt) 0 0 I ],B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
"[ U>Λ U>0 ] Substituting this result into the differential equation for θ, this representation of exp(Gt) implies the non-identity block can be handled as in the invertible case while the I block follows trivially to give:
θ(t) = θ0 + [ UΛ U0 ]",B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
[Λ−1(exp(Λt)− I) 0 0 tI ],B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
"[ U>Λ U>0 ] p0
Note that if G = 0 then the flow map will simply reduce to an Euler translation as in ordinary HMC.",B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
"We can also combine the ideas of Section A.2 to obtain a preconditioned, magnetic HMC algorithm corresponding to a general A-matrix of the form (
0 F −F> G
)
Dealing with a non-zero E becomes more subtle, since the corresponding sub-Hamiltonian is no longer exactly integrable under the splitting construction.",B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
"In order to exactly integrate this sub-block a more costly implicit integrator is needed.
",B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
B.3.,B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
"Integration Error of Magnetic HMC
Since we are using a symmetric, leapfrog splitting scheme for magnetic HMC that exactly integrates each sub-Hamiltonian we obtain identical error scaling to the leapfrog integrator applied to canonical HMC.",B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
"Indeed, symplectic integrators are well-known to have many nice error properties in general and so perhaps this result is not so surprising (Hairer et al., 2006).
",B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
Lemma 6.,B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
"The symplectic leapfrog-like integrator for magnetic HMC will have the same local (∼ O( 3)) and global (∼ O( 2)) error scaling (over τ ∼ L steps), as the canonical leapfrog integrator of standard HMC if the Hamiltonian is separable.
",B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
Proof.,B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
Note that for the parametrization of A corresponding to magnetic HMC the Hamiltonian vector field ~H = ∇pH∇θ + (−∇θ + G∇pH)∇p ≡ ~A,B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
+ ~B will generate the exact flow corresponding to exactly simulating the dynamics.,B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
We obtain an O( 3) local error by simply exploiting the separability of the Hamiltonian.,B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
"The leapfrog integration scheme splits the Hamiltonian as: H(θ,p) = H1(θ) +H2(p) +H1(θ) and exactly integrates each sub-Hamiltonian so:
Φfrog ,H = Φ ,H1(θ) ◦",B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
"Φ ,H2(p) ◦",B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
"Φ ,H1(θ) = exp ( 2 ~B ) ◦ exp ( ~A ) ◦",B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
"exp ( 2 ~B )
(37)
(38)
",B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
"Via repeated applications of the Baker-Campbell-Hausdorff formula (Hairer et al., 2006) obtain:
exp ( 2 ~B ) ◦",B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
"exp ( ~A + 2 ~B + 2 2 [~A, ~B] )",B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
+O( 3) =,B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
"(39)
exp
(
2 ~B + ~A",B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
"+ 2 ~B +
2
2",B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
"[~A, ~B] +
1 2 [ 2 ~B, ~A + 2 ~B +
2
2 [~A, ~B]]
)",B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
+O( 3) =,B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
"(40)
exp ( ~H + 2
4 [~A, ~B] +
2
4 [~B, ~A] +
2
8 [~B, ~B]
)",B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
+O( 3) = exp ( ~H ),B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
"+O( 3) (41)
where we have used the antisymmetry of the commutator.",B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
"The global error scaling, for an integration time of τ = L follows straightforwardly:
Φfrogτ,H = ( exp ( 2 ~B ) ◦",B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
exp ( ~A ) ◦,B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
exp ( 2 ~B )),B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
"L
(42) = ( exp ( ~H )",B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
+O( 3) ),B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
"L (43)
= exp ( L~H ) + L O( 2) (44)
= exp ( τ ~H )",B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
"+ τO( 2) (45)
= exp ( τ ~H )",B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
"+O( 2) (46)
as desired.",B.2. Symplectic Integrator for Magnetic Dynamics,[0],[0]
Here we provide relevant experimental details for some of the Experiments presented in the main text.,C. Section 6 Experimental Details,[0],[0]
"In both experiments the reported autocorrelation measures are averaged over all coordinates as well as over 100 independent runs of the HMC/MHMC chains.
",C.1. Gaussians,[0],[0]
C.1.1.,C.1. Gaussians,[0],[0]
"2D GAUSSIAN
",C.1. Gaussians,[0],[0]
"For the uncorrelated, ill-conditioned 2D Gaussian experiment presented in the main text the magnetic G component only has one non-zero parameter which was set to g = .2.
",C.1. Gaussians,[0],[0]
C.1.2. 10D,C.1. Gaussians,[0],[0]
"GAUSSIAN
For the uncorrelated, ill-conditioned 10D Gaussian experiment presented in the main text, the G matrix was set to encourage the flow of momentum between the directions of large marginal variance with covariance eigenvalues 106 and the remaining 8 directions of directions of small marginal variance with covariance eigenvalues of 1.",C.1. Gaussians,[0],[0]
"We denote the directions of large marginal variance as x1, x2, and the other 8 directions of directions of small marginal variance as xi. G was set such that G1i = G2i = g, Gi1 = Gi2 = −g and G12 = G21 = 0 for g = .2.",C.1. Gaussians,[0],[0]
"The superior mixing of MHMC relative to HMC in this example holds true for a wide range of ( , L) settings as we can see by looking at the maximum mean discrepancy as a function of the number of samples in both Figures 5 and 6.
",C.2. Mixture of Gaussians,[0],[0]
"We found that tuning the parameters ( , L) via Bayesian optimization often resulted in worse performance for ordinary HMC since the values found for ( , L) were too conservative to encourage exploration between both modes.",C.2. Mixture of Gaussians,[0],[0]
"Moreover, more aggressive choices for ( , L) for ordinary HMC led to a sharp drop in acceptance rate and significantly worse performance.",C.2. Mixture of Gaussians,[0],[0]
"In this additional experiment, we consider the Gaussian funnel of (Neal, 2003) with density
p(x, v) = Πni=1N (xi|0, e−v)N (v|0, 32)
in 10+1 dimensions (i.e. n = 10).",C.3. Gaussian Funnel,[0],[0]
"This density illustrates the pathological correlation present in many hierarchical models between x, a vector of low-level parameters, and v, a hyperparameter controlling their variability.",C.3. Gaussian Funnel,[0],[0]
"As noted in (Betancourt & Girolami, 2015; Zhang & Sutton, 2014), Riemannian HMC methods, which incorporate local curvature information of the target, are well-suited to this problem as they help the dynamics traverse the energy surface which rapidly changes as a v varies.",C.3. Gaussian Funnel,[0],[0]
"HMC (as well as MHMC) do not exploit curvature information and will have more difficulty exploring the v direction due to the rapid variation in density – see (Betancourt & Girolami, 2015) for a detailed discussion.",C.3. Gaussian Funnel,[0],[0]
"Despite this difficulty, we might intuitively expect that introducing a “curl” term into the entries of G which couple each xi and v could increase exploration of the dynamics since these variables are nonlinearly correlated.",C.3. Gaussian Funnel,[0],[0]
"In order to encourage the periodic flow of momentum between the marginal direction v and the coordinates xi the G matrix was set such that Gvi = g, Giv = −g, Gij = 0 with g = .2.",C.3. Gaussian Funnel,[0],[0]
"To investigate this, we generated 10000 samples from both HMC and MHMC, discarding 1000 burn-in samples and computed the minimum effective sample size across x and v and bias in the moments of the v parameter similar to the set-up in (Zhang & Sutton, 2014) for various , L (see Table 5).",C.3. Gaussian Funnel,[0],[0]
"We report results averaged over 100 different runs of the Markov chains.
",C.3. Gaussian Funnel,[0],[0]
"We find that adding the magnetic field component decreases the bias in the moments and marginally increases the ESS,
although both samplers struggle to explore the full target density, as the relatively low ESS figures indicate.",C.3. Gaussian Funnel,[0],[0]
"Further details and experiments are provided in the Appendix.
",C.3. Gaussian Funnel,[0],[0]
"Recall the density of the Gaussian funnel p(x, v) = Πni=1N",C.3. Gaussian Funnel,[0],[0]
"(xi|0, e−v)N (v|0, 32).",C.3. Gaussian Funnel,[0],[0]
"In order to encourage the periodic flow of momentum between the marginal direction v and the coordinates xi the G matrix was set such that Gvi = g, Giv = −g, Gij = 0 with g = .2.",C.3. Gaussian Funnel,[0],[0]
Moreover the reported results were averaged over 100 different runs of the Markov chains.,C.3. Gaussian Funnel,[0],[0]
"In this section, we provide illustrations of the proposal distributions of MHMC in simple low-dimensional settings, to aid intuition and demonstrate the divergence of its behaviour from standard HMC.",D. MHMC Proposals and Dynamics,[0],[0]
"We first consider the case of an isotropic Gaussian target, and illustrate the proposal distribution of standard HMC, as well as MHMC with a variety of settings for the skew-symmetric matrix A = (
E F F G
) - see Figure 7.",D.1. Gaussian Densities,[0],[0]
"As in previous sections,
we denote the off-diagonal element of the G matrix by g. We also provide proposal plots for an anisotropic Gaussian target distribution - see Figure 8.",D.1. Gaussian Densities,[0],[0]
"We also provide proposal illustrations for the banana density of (Haario et al., 1999), as shown in Figure 9.",D.2. Banana Density,[0],[0]
Hamiltonian Monte Carlo (HMC) exploits Hamiltonian dynamics to construct efficient proposals for Markov chain Monte Carlo (MCMC).,abstractText,[0],[0]
"In this paper, we present a generalization of HMC which exploits non-canonical Hamiltonian dynamics.",abstractText,[0],[0]
"We refer to this algorithm as magnetic HMC, since in 3 dimensions a subset of the dynamics map onto the mechanics of a charged particle coupled to a magnetic field.",abstractText,[0],[0]
"We establish a theoretical basis for the use of non-canonical Hamiltonian dynamics in MCMC, and construct a symplectic, leapfrog-like integrator allowing for the implementation of magnetic HMC.",abstractText,[0],[0]
"Finally, we exhibit several examples where these non-canonical dynamics can lead to improved mixing of magnetic HMC relative to ordinary HMC.",abstractText,[0],[0]
Magnetic Hamiltonian Monte Carlo,title,[0],[0]
"√ T .
It is well known that minor variants of standard algorithms satisfy first-order regret bounds in the full information and multi-armed bandit settings. In a COLT 2017 open problem (Agarwal et al., 2017), Agarwal, Krishnamurthy, Langford, Luo, and Schapire raised the issue that existing techniques do not seem sufficient to obtain first-order regret bounds for the contextual bandit problem. In the present paper, we resolve this open problem by presenting a new strategy based on augmenting the policy space.1",text,[0],[0]
The contextual bandit problem is an influential extension of the classical multi-armed bandit.,1 Introduction,[0],[0]
It can be described as follows.,1 Introduction,[0],[0]
"Let K be the number of actions, E a set of experts (or “policies”), T the time horizon, and denote ∆K = {x ∈",1 Introduction,[0],[0]
"[0, 1]K : ∑K i=1 x(i) = 1}.",1 Introduction,[0],[0]
"At each time step t = 1, . . .",1 Introduction,[0],[0]
", T ,
• The player receives from each expert e ∈ E an “advice” ξet ∈ ∆K .
",1 Introduction,[0],[0]
"• Using advices and previous feedbacks, the player selects a probability distribution pt ∈ ∆K .
",1 Introduction,[0],[0]
*Equal contribution 1Microsoft Research AI 2Princeton University.,1 Introduction,[0],[0]
"Correspondence to: Zeyuan Allen-Zhu <zeyuan@csail.mit.edu>, Sébastien Bubeck <sebubeck@microsoft.com>, Yuanzhi Li <yuanzhil@cs.princeton.edu>.
",1 Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1 Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1 Introduction,[0],[0]
1The full version of this paper can be found at https:// arxiv.org/abs/1802.03386.,1 Introduction,[0],[0]
"The work was done when Yuanzhi Li was a summer intern at Microsoft Research in 2017.
",1 Introduction,[0],[0]
• The adversary selects a loss function `t :,1 Introduction,[0],[0]
"[K]→ [0, 1].",1 Introduction,[0],[0]
• The player plays an action at ∈,1 Introduction,[0],[0]
"[K] at random from pt
(and independently of the past).
",1 Introduction,[0],[0]
• The player’s suffered loss is `t(at) ∈,1 Introduction,[0],[0]
"[0, 1], which is also the only feedback the player receives about the loss function `t.
The player’s performance at the end of the T rounds is measured through the regret with respect to the best expert:
",1 Introduction,[0],[0]
"RT def = max
e∈E { E",1 Introduction,[0],[0]
"[ T∑ t=1 `t(at)− 〈ξet , `t〉 ]}
= max e∈E { E",1 Introduction,[0],[0]
"[ T∑ t=1 〈pt − ξet , `t〉 ]} .",1 Introduction,[0],[0]
"(1.1)
",1 Introduction,[0],[0]
A landmark result by Auer et al. (2002) is that a regret of order O( √ TK log(|E|)) is achievable in this setting.,1 Introduction,[0],[0]
The general intuition captured by regret bounds is that the player’s performance is equal to the best expert’s performance up to a term of lower order.,1 Introduction,[0],[0]
However the aforementioned bound might fail to capture this intuition if T L∗T def,1 Introduction,[0],[0]
"= mine∈E E ∑T t=1〈ξet , `t〉.",1 Introduction,[0],[0]
It is thus natural to ask whether one could obtain a stronger guarantee where T is essentially replaced by L∗T .,1 Introduction,[0],[0]
"This question was posed as a COLT 2017 open problem (Agarwal et al., 2017).",1 Introduction,[0],[0]
"Such bounds are called first-order regret bounds, and they are known to be possible with full information (Auer et al., 2002), as well as in the multi-armed bandit setting (Allenberg et al., 2006) (see also (Foster et al., 2016) for a different proof) and the semi-bandit framework (Neu, 2015; Lykouris et al., 2017).",1 Introduction,[0],[0]
"Our main contribution is a new algorithm for contextual bandit, which we call MYGA (see Section 2), and for which we prove the following first-order regret bound, thus resolving the open problem.",1 Introduction,[0],[0]
Theorem 1.1.,1 Introduction,[0],[0]
"For any loss sequence such that mine∈E E ∑T t=1〈ξet , `t〉 ≤ L∗ one has that MYGA
with γ = Θ(η) and η = Θ ( min { 1 K , √ log(|E|+T ) KL∗ })",1 Introduction,[0],[0]
"satisfies
RT",1 Introduction,[0],[0]
≤ O (√ K log(|E|+ T )L∗,1 Introduction,[0],[0]
+K log(|E|+ T ) ) .,1 Introduction,[0],[0]
In this section we describe the MYGA algorithm.,2 Algorithm Description,[0],[0]
We introduce a truncation operator T ks that takes as input an index k ∈,2.1 Truncation,[0],[0]
[K] and a threshold s ∈,2.1 Truncation,[0],[0]
"[0, 12 ].",2.1 Truncation,[0],[0]
"Then, treating the first k arms as “majority arms” and the last K − k arms as “minority arms,” T ks redistributes “multiplicatively” the probability mass of all minority arms below threshold s to the majority arms.
",2.1 Truncation,[0],[0]
Definition 2.1.,2.1 Truncation,[0],[0]
For k ∈,2.1 Truncation,[0],[0]
"[K] and s ∈ (0, 12 ], the truncation operator T ks : ∆K → ∆K is defined as follows.",2.1 Truncation,[0],[0]
"Given any q ∈ ∆K , then we set T ks q(i) = 0, i > k and q(i) ≤ s; q(i), i > k and q(i) > s; q(i) · ( 1 + ∑ j:j>k∧ q(j)≤s q(j)∑
j≤k q(j)
) , i ≤ k.
Equivalently one can define T ks q(i) for the majority arms",2.1 Truncation,[0],[0]
i ≤ k,2.1 Truncation,[0],[0]
"with the following implicit formula:
T ks q(i) = q(i)∑ j≤k q(j) ∑ j≤k T ks q(j) .",2.1 Truncation,[0],[0]
"(2.1)
To see this it suffices to note that the amount of mass in the majority arms is given by∑ j≤k T ks q(j) = 1− ∑ j>k T ks q(j) = 1− ∑ j:j>k∧ q(j)>s q(j)
= ∑ j≤k q(j) + ∑ j:j>k∧ q(j)≤s q(j) .
",2.1 Truncation,[0],[0]
"If K = 2, then T 1s q simply adds q(2) into q(1)",2.1 Truncation,[0],[0]
if q(2) ≤,2.1 Truncation,[0],[0]
s.,2.1 Truncation,[0],[0]
"For an example with K = 11, see Figure 1.",2.1 Truncation,[0],[0]
"MYGA is parameterized by two parameters: a classical learning rate η > 0, and a thresholding parameter γ ∈ 12T N = { 12T , 2 2T , 3 2T , . . .",2.2 Informal description,[0],[0]
}.,2.2 Informal description,[0],[0]
"Also let S = (γ, 1/2] ∩ 1 2T N =",2.2 Informal description,[0],[0]
"(γ, 1/2] ∩ { 12T , 2 2T , 3 2T , . . . }",2.2 Informal description,[0],[0]
"At a high level, a key feature of MYGA is to introduce a set of auxiliary experts, one for each s ∈ S. More precisely, in each round t, after receiving expert advices {ξet }e∈E ,
MYGA calculates a distribution ξst ∈ ∆K for each s ∈ S.",2.2 Informal description,[0],[0]
"Then, MYGA uses the standard exponential weight updates on E′ = E ∪ S with learning rate η > 0, to calculate a weight functionwt ∈ RE∪S+ —see (2.3).",2.2 Informal description,[0],[0]
"Then, it computes • ζt ∈ ∆K , the weighted average of expert advices in E:
ζt = 1∑
e∈E wt(e) ∑ e∈E wt(e) · ξet .
",2.2 Informal description,[0],[0]
"• qt ∈ ∆K , the weighted average of expert advices in E′:
qt = 1
‖wt‖1 ∑ e∈E′ wt(e) · ξet .
",2.2 Informal description,[0],[0]
"Using these information, MYGA calculates the probability distribution pt ∈ ∆K from which the arm is played at round t.
Let us now explain how pt and ξst , s ∈ S are defined.",2.2 Informal description,[0],[0]
"First we remark that in the contextual bandit setting, the arm index has no real meaning since in each round t we can permute the arms by some πt : [K] → [K] and permute the expert’s advices and the loss vector by the same πt.",2.2 Informal description,[0],[0]
"For this reason, throughout this paper, we shall assume
∀t ∈",2.2 Informal description,[0],[0]
[T ] : ζt(1) ≥ ζt(2) ≥ · · · ζt(K) .,2.2 Informal description,[0],[0]
Let us define the “pivot” index kt = min{i ∈,2.2 Informal description,[0],[0]
[K] :∑ j≤i ζt(j) ≥ 1/2}.,2.2 Informal description,[0],[0]
"Then, in order to perform truncation, MYGA views the first kt arms as “majority arms” and the last K − kt arms as “minority arms” of the current round t. At a high level we will have:
• the distribution to play from is pt = T ktγ qt.",2.2 Informal description,[0],[0]
"• each auxiliary expert s ∈ S is defined by ξst = T kts qt.
",2.2 Informal description,[0],[0]
We now give a more precise description in Algorithm 1.,2.2 Informal description,[0],[0]
Definition 3.1.,3 Preliminaries,[0],[0]
"For analysis purpose, let us define the truncated loss ¯̀t(i) def = `t(i)1{pt(i) > 0}, so that
Eat [ 〈˜̀t, pt〉] = 〈¯̀t, pt〉 = 〈`t, pt〉 .
",3 Preliminaries,[0],[0]
"We next derive two lemmas that will prove useful to isolate
Algorithm 1 MYGA (Make the minoritY Great Again)
",3 Preliminaries,[0],[0]
"Input: learning rate η > 0, threshold parameter γ ∈ 12T N 1: S ← (γ, 1/2] ∩ 12T N and w1 ← (1, . . .",3 Preliminaries,[0],[0]
", 1) ∈ R E∪S
2: for t = 1 to T do 3: receive advices ξet ∈ ∆K from each expert e ∈ E 4: weighted average ζt ← ∑ e∈E wt(e)ξ e t∑
e∈E wt(e) ∈ ∆K
5: assume ζt(1) ≥ ζt(2) ≥ · · · ζt(K) wlog.",3 Preliminaries,[0],[0]
by permuting the arms 6: kt ← min{i ∈,3 Preliminaries,[0],[0]
"[K] : ∑ j≤i ζt(j) ≥ 1/2} the first kt arms are majority arms 7: find qt ∈ ∆K such that qt can be found in time O(K|S|) = O(KT ), see Lemma 6.1
qt = 1∑ e∈E wt(e)+ ∑ s∈S wt(s) (∑ e∈E wt(e)ξ e t + ∑ s∈S wt(s)T kts qt ) .",3 Preliminaries,[0],[0]
"(2.2)
8: ξst ← T kts qt for every s ∈ S and pt ← T ktγ",3 Preliminaries,[0],[0]
qt 9: draw an arm at ∈,3 Preliminaries,[0],[0]
"[K] from probability distribution pt and receive feedback `t(at)
10: compute loss estimator ˜̀t ∈ RK+ as ˜̀t(i)",3 Preliminaries,[0],[0]
=,3 Preliminaries,[0],[0]
"`t(i)pt(i)1i=at 11: update the exponential weights for any e ∈ E ∪ S:
wt+1(e) =",3 Preliminaries,[0],[0]
"exp ( − η ∑t r=1〈ξer , ˜̀r〉) .",3 Preliminaries,[0],[0]
"(2.3)
12: end for
the properties of the truncation operator T ks that are needed to obtain a first-order regret bound.",3 Preliminaries,[0],[0]
Lemma 3.2.,3 Preliminaries,[0],[0]
Let γ ∈,3 Preliminaries,[0],[0]
"[0, 1] and assume",3 Preliminaries,[0],[0]
that for all i ∈,3 Preliminaries,[0],[0]
"[K], (1− cKγ)pt(i) ≤ qt(i) for some universal constant c > 0, and that pt(i) 6=",3 Preliminaries,[0],[0]
0⇒ pt(i) ≥ qt(i).,3 Preliminaries,[0],[0]
"Then one has
(1− cKγ)LT −L∗T ≤ log(|E′|) η + η 2 E T∑ t=1 ‖¯̀t‖22 .",3 Preliminaries,[0],[0]
"(3.1)
Proof.",3 Preliminaries,[0],[0]
"Using 〈pt, `t〉 = 〈pt, ¯̀t〉, 〈−ξet , `t〉 ≤ 〈−ξet , ¯̀t〉, and (1− cKγ)pt(i) ≤ qt(i), we have
(1− cKγ)LT",3 Preliminaries,[0],[0]
− L∗T ≤ max e∈E′ E T∑ t=1,3 Preliminaries,[0],[0]
"〈(1− cKγ)pt − ξet , ¯̀t〉
≤ max e∈E′ E T∑ t=1 〈qt − ξet , ¯̀t〉 .
",3 Preliminaries,[0],[0]
"The rest of the proof follows from standard argument to bound the regret of Exp4, see e.g., (Bubeck & CesaBianchi, 2012, Theorem 4.2) (with the minor modification that the assumption on pt implies that ˜̀t(i) ≤",3 Preliminaries,[0],[0]
"`t(i)qt(i)1{i = at}).
",3 Preliminaries,[0],[0]
The next lemma is straightforward.,3 Preliminaries,[0],[0]
Lemma 3.3.,3 Preliminaries,[0],[0]
"In addition to the assumptions in Lemma 3.2, assume that there exists some numerical constants c′, c′′ ≥ 0 such that
γ E T∑ t=1 ‖¯̀t‖22 ≤ 2 c′ (η + γ) K LT + 2 c′′ log(|E′|) η .
(3.2)
",3 Preliminaries,[0],[0]
"Then one has( 1− cKγ − ( η + η2
γ
) c′K) )",3 Preliminaries,[0],[0]
"(LT − L∗T )
≤",3 Preliminaries,[0],[0]
"( 1
η + c′′ γ
) log(|E′|)",3 Preliminaries,[0],[0]
"+ ( cKγ + ( η + η2
γ
) c′K )",3 Preliminaries,[0],[0]
"L∗T .
",3 Preliminaries,[0],[0]
"We now see that it suffices to show that MYGA satisfies the assumptions of Lemma 3.2 and Lemma 3.3 for γ ' η, and η ' min { 1 K , √ log(|E′|) KL∗T } (assume that L∗T is
known), in which case one obtains a bound of order√ K log(|E′|)L∗T",3 Preliminaries,[0],[0]
"+K log(|E′|).
",3 Preliminaries,[0],[0]
"In fact the assumption of Lemma 3.2 will be easily verified, and the real difficulty will be to prove (3.2).",3 Preliminaries,[0],[0]
"We observe that the standard trick of thresholding the arms with probability below γ would yield (3.2) with the right hand side replaced by LT , and in turn this leads to a regret of order (L∗T ) 2/3.",3 Preliminaries,[0],[0]
"Our goal is to improve over this naive argument.
",3 Preliminaries,[0],[0]
4 Proof of the 2-Armed Case The goal of this section is to explain how our MYGA algorithm arises naturally.,3 Preliminaries,[0],[0]
To focus on the main ideas we restrict to the case K = 2.,3 Preliminaries,[0],[0]
"The complete formal proof of Theorem 1.1 is given in Section 5.
",3 Preliminaries,[0],[0]
Recall we have assumed without loss of generality that ζt(1),3 Preliminaries,[0],[0]
≥ ζt(2) for each round t ∈,3 Preliminaries,[0],[0]
[T ].,3 Preliminaries,[0],[0]
This implies kt = 1 because ζt(1) ≥ 12 .,3 Preliminaries,[0],[0]
"In this simple case, for s ∈",3 Preliminaries,[0],[0]
"[0, 1/2], we abbreviate our truncation operator T kts as Ts, and it acts as
follows.",3 Preliminaries,[0],[0]
Given q ∈ ∆2 if q(2) ≤,3 Preliminaries,[0],[0]
s,3 Preliminaries,[0],[0]
"we have Tsq = (1, 0); and if q(2) > s we have Tsq = q.
",3 Preliminaries,[0],[0]
"In particular, we have qt(1) ≥ qt(2) and pt(1) ≥ pt(2) for all t ∈",3 Preliminaries,[0],[0]
[T ].,3 Preliminaries,[0],[0]
We refer to arm 1 as the majority arm and arm 2 as the minority arm.,3 Preliminaries,[0],[0]
"We denote M = E ∑T t=1 ¯̀ t(1) as
the loss of the majority arm and m = E ∑T t=1 ¯̀ t(2) as the loss of the minority arm.",3 Preliminaries,[0],[0]
Since `t ∈,3 Preliminaries,[0],[0]
"[0, 1]K and K = 2, we have E ∑T t=1",3 Preliminaries,[0],[0]
‖¯̀t‖22 ≤,3 Preliminaries,[0],[0]
E ∑T t=1 ¯̀ t(1) +,3 Preliminaries,[0],[0]
¯̀t(2),3 Preliminaries,[0],[0]
= M +m .,3 Preliminaries,[0],[0]
"(4.1) Observe also that one always has LT ≥ 12M (indeed pt(1) ≥ qt(1) ≥ 1/2), and thus the whole game to prove (3.2) is to upper bound the minority’s loss m.",3 Preliminaries,[0],[0]
Assume that m ≤ (c′ − 1)M for some constant c′ > 0.,4.1 When the minority suffers small loss,[0],[0]
"Then, because M ≤ 2LT , one can directly obtain (3.2) from (4.1) with c′′ = 0.",4.1 When the minority suffers small loss,[0],[0]
"In words, when the minority arm has a total loss comparable to the majority arm, simply playing from ζt would satisfy a first-order regret bound.
",4.1 When the minority suffers small loss,[0],[0]
Our main idea is to somehow enforce this relation m .M,4.1 When the minority suffers small loss,[0],[0]
"between the minority and majority losses, by “truncating” probabilities appropriately.",4.1 When the minority suffers small loss,[0],[0]
"Indeed, recall that if after some truncation we have pt(2) = 0, then it satisfies ¯̀t(2) = 0",4.1 When the minority suffers small loss,[0],[0]
so the minority loss m can be improved.,4.1 When the minority suffers small loss,[0],[0]
"Our key new insight is captured by the following lemma which is proved using an integral averaging argument.
",4.2 Make the minority great again,[0],[0]
Definition 4.1.,4.2 Make the minority great again,[0],[0]
"For each s ≥ γ, let Lst def = E ∑T t=1〈Tsqt, `t〉 be the expected loss if the truncated strategy Tsqt ∈ ∆K is played at each round.",4.2 Make the minority great again,[0],[0]
Lemma 4.2.,4.2 Make the minority great again,[0],[0]
"As long as m−M > 0,
∃s ∈ (γ, 1/2] : m−M ≤ LT − L s T
γ .
",4.2 Make the minority great again,[0],[0]
"In words, ifm is large, then smust be a much better threshold compared to γ, that is LT − LsT is large.
",4.2 Make the minority great again,[0],[0]
Proof of Lemma 4.2.,4.2 Make the minority great again,[0],[0]
"For any s ≥ γ, define the function f(s) def = E ∑T t=1 1{qt(2) ≤ s}(¯̀t(1)− ¯̀t(2)) .",4.2 Make the minority great again,[0],[0]
Let us pick s ∈,4.2 Make the minority great again,[0],[0]
"[γ, 1/2] to minimize f(s), and breaking ties by choosing the smaller value of s. We make several observations:
• f(γ) ≥ 0",4.2 Make the minority great again,[0],[0]
"because for any t with qt(2) ≤ γ we must have ¯̀t(2) = 0.
• f(1/2)",4.2 Make the minority great again,[0],[0]
= M −m < 0.,4.2 Make the minority great again,[0],[0]
• s > γ because f(s) ≤ f(1/2),4.2 Make the minority great again,[0],[0]
"< 0.
Let us define the points s0 def = γ and
{s1 < . . .",4.2 Make the minority great again,[0],[0]
"< sm} def = (γ, s] ∩ {q1(2), . . .",4.2 Make the minority great again,[0],[0]
", qT (2)}.
Note that the tie-breaking rule for the choice of s ensures sm = s (if sm < s then it must satisfy f(sm) = f(s) giving a contradiction).",4.2 Make the minority great again,[0],[0]
"Using the identity T∑ t=1 〈Tsqt − qt, ¯̀t〉 = 1{qt(2) ≤ s}qt(2)(¯̀t(1)− ¯̀t(2)) , (4.2) we calculate that
LT − LsT
= E T∑ t=1 〈Tγqt − Tsqt, `t〉 = E T∑ t=1 〈Tγqt − Tsqt, ¯̀t〉
= E T∑ t=1",4.2 Make the minority great again,[0],[0]
(1{qt(2) ≤,4.2 Make the minority great again,[0],[0]
"γ} − 1{qt(2) ≤ s})
",4.2 Make the minority great again,[0],[0]
"× qt(2)(¯̀t(1)− ¯̀t(2))
= E T∑ t=1",4.2 Make the minority great again,[0],[0]
m∑ i=1 −si1{qt(2) =,4.2 Make the minority great again,[0],[0]
"si}(¯̀t(1)− ¯̀t(2))
",4.2 Make the minority great again,[0],[0]
= m∑ i=1,4.2 Make the minority great again,[0],[0]
"si(f(si−1)− f(si))
",4.2 Make the minority great again,[0],[0]
= m−1∑ i=1,4.2 Make the minority great again,[0],[0]
"(si+1 − si)f(si) + s1f(s0)− smf(sm) .
",4.2 Make the minority great again,[0],[0]
"Since f(s0) ≥ 0, f(si) ≥ f(s) and s = sm, we conclude that
LT − LsT ≥ (sm − s1)f(sm)− smf(sm) = −s1f(sm) ≥ γ(m−M) .
",4.2 Make the minority great again,[0],[0]
"Given Lemma 4.2, a very intuitive strategy start to emerge.",4.2 Make the minority great again,[0],[0]
"Suppose we can somehow get an upper bound of the form
LT − LsT ≤",4.2 Make the minority great again,[0],[0]
O,4.2 Make the minority great again,[0],[0]
( log(|E′|) η + η(m+M) + γLT ) .,4.2 Make the minority great again,[0],[0]
"(4.3) Then, putting this into Lemma 4.2 and using M ≤ 2LT , we have for any γ ≥ 2η,
γm ≤",4.2 Make the minority great again,[0],[0]
"O ( log(|E′|) η + γLT ) .
",4.2 Make the minority great again,[0],[0]
"In words, the minority arm also suffers from a small loss (and thus is great again!)",4.2 Make the minority great again,[0],[0]
"Putting this into (4.1), we immediately get (3.2) as desired and finish the proof of Theorem 1.1 in the case K = 2.
",4.2 Make the minority great again,[0],[0]
"Thus, we are left with showing (4.3).",4.2 Make the minority great again,[0],[0]
The main idea is to add the truncated strategy Tsqt as an additional auxiliary expert.,4.2 Make the minority great again,[0],[0]
"If we can achieve this, then (4.3) can be obtained from the regret formula in Lemma 3.2.",4.2 Make the minority great again,[0],[0]
Assume for a moment that we somehow expand the set of experts into E′ ⊃,4.3 Expanding the set of experts,[0],[0]
E so that: ∀s ∈,4.3 Expanding the set of experts,[0],[0]
"(γ, 1/2],∃e ∈ E′ such that for all t ∈",4.3 Expanding the set of experts,[0],[0]
"[T ], ξet = Tsqt .",4.3 Expanding the set of experts,[0],[0]
"(4.4) Then clearly (4.3) would be satisfied using Lemma 3.2, (4.1) and",4.3 Expanding the set of experts,[0],[0]
"L∗T ≤ LsT (the loss of an expert should be no
better than the loss of the best expert L∗T ).
",4.3 Expanding the set of experts,[0],[0]
"There are two issues with condition (4.4): first, it selfreferential, in the sense that it assumes {ξet }e∈E′ satisfies a certain form depending on qt while qt is defined via {ξet }e∈E′ (recall (2.2)); and second, it potentially requires to have an infinite number of experts (one for each s ∈ (γ, 1/2]).",4.3 Expanding the set of experts,[0],[0]
"Let us first deal with the second issue via discretization.
",4.3 Expanding the set of experts,[0],[0]
Lemma 4.3.,4.3 Expanding the set of experts,[0],[0]
"In the same setting as Lemma 4.2, there exists s ∈ S def=",4.3 Expanding the set of experts,[0],[0]
"(γ, 1/2] ∩ 12T N such that
m−M ≤ 1 + LT − L s T
γ .
",4.3 Expanding the set of experts,[0],[0]
Proof.,4.3 Expanding the set of experts,[0],[0]
"For x ∈ R let x be the smallest element in [x,+∞) ∩ 12T N.",4.3 Expanding the set of experts,[0],[0]
For any s ∈ S we can rewrite (4.2) as (note that x ≤,4.3 Expanding the set of experts,[0],[0]
"s⇔ x ≤ s) 〈Tsqt− qt, ¯̀t〉 = 1{qt(2) ≤ s}qt(2)(¯̀t(1)− ¯̀t(2))",4.3 Expanding the set of experts,[0],[0]
"+ εt,s , where |εt,s| ≤ 1/2T .",4.3 Expanding the set of experts,[0],[0]
"Using the same proof of Lemma 4.2, and redefining
f(s) def = E ∑T t=1 1{qt(2) ≤ s}(¯̀t(1)− ¯̀t(2)) .
",4.3 Expanding the set of experts,[0],[0]
"we get that there exists s1, . . .",4.3 Expanding the set of experts,[0],[0]
", sm ∈ S def =",4.3 Expanding the set of experts,[0],[0]
"(γ, 12 ] ∩ 1 2T N and ε ∈",4.3 Expanding the set of experts,[0],[0]
"[−1, 1] such that
LT − LsT = ε+ m∑ i=1 si(f(si−1)− f(si)) .
",4.3 Expanding the set of experts,[0],[0]
"The rest of the proof now follows from the same proof of Lemma 4.2, except that we minimize f(s) over s ∈ S instead of s ∈",4.3 Expanding the set of experts,[0],[0]
"[γ, 12 ].
Thus, instead of (4.4), we only need to require
∀s ∈ S, ∃e ∈ E′ such that for all t ∈",4.3 Expanding the set of experts,[0],[0]
"[T ], ξet = Tsqt .",4.3 Expanding the set of experts,[0],[0]
"(4.5)
We now resolve the self-referentiality of (4.5) by defining simultaneously qt and ξet , e ∈ S as follows.",4.3 Expanding the set of experts,[0],[0]
"Consider the map Ft : [0, 1/2]→",4.3 Expanding the set of experts,[0],[0]
"[0, 1/2] defined by:
Ft(x)",4.3 Expanding the set of experts,[0],[0]
"= 1∑ e∈E wt(e) + ∑ s∈S wt(s)
× (∑ e∈E wt(e)ξ e t (2) + ∑ s∈S",4.3 Expanding the set of experts,[0],[0]
"wt(s)x1{x > s} ) .
",4.3 Expanding the set of experts,[0],[0]
"It suffices to find a fixed point x = Ft(x): indeed, setting qt def = (1− x, x) and
ξst (2) def = x1{x > s} = Tsqt for s ∈ S, we have both (4.5) holds and qt = 1‖wt‖1 ∑ e∈E′ wt(e) · ξet is the correct weighted average of expert advices in E′ = E ∪ S Finally, Ft has a fixed point since it is a nondecreasing function from a closed interval to itself.",4.3 Expanding the set of experts,[0],[0]
"It is also not hard to find such a point algorithmically.
",4.3 Expanding the set of experts,[0],[0]
This concludes the (slightly informal) proof forK = 2.,4.3 Expanding the set of experts,[0],[0]
We give the complete proof for arbitrary K in the next section.,4.3 Expanding the set of experts,[0],[0]
"In this section, we assume qt ∈ ∆K satisfies (2.2) and we defer the constructive proof of finding qt to Section 6.",5 Proof of Theorem 1.1,[0],[0]
"Recall the arm index has no real meaning so without loss of generality we have permuted the arms so that
ζt(1) ≥ ζt(2) ≤ . . .",5 Proof of Theorem 1.1,[0],[0]
≥ ζt(K),5 Proof of Theorem 1.1,[0],[0]
"for each t = 1, 2, . . .",5 Proof of Theorem 1.1,[0],[0]
", T .",5 Proof of Theorem 1.1,[0],[0]
"We refer to {1, 2, . . .",5 Proof of Theorem 1.1,[0],[0]
", kt} the set of majority arms and {kt+1, . . .",5 Proof of Theorem 1.1,[0],[0]
",K} the set of minority arms at round t.2",5 Proof of Theorem 1.1,[0],[0]
We let M def = ∑T t=1,5 Proof of Theorem 1.1,[0],[0]
E ∑ i≤kt ¯̀ t(i) and m def = ∑T t=1,5 Proof of Theorem 1.1,[0],[0]
E ∑,5 Proof of Theorem 1.1,[0],[0]
i>kt ¯̀ t(i) respectively be the total loss of the majority and minority arms.,5 Proof of Theorem 1.1,[0],[0]
"We again have
E ∑T t=1 ‖¯̀t‖22 ≤",5 Proof of Theorem 1.1,[0],[0]
E ∑T t=1 ∑ i∈[K] ¯̀ t(i) = M +m .,5 Proof of Theorem 1.1,[0],[0]
"(5.1)
",5 Proof of Theorem 1.1,[0],[0]
"Thus, the whole game to prove (3.2) is to upper bound M and m.",5 Proof of Theorem 1.1,[0],[0]
"We state a few properties about qt and its truncations.
",5.1 Useful properties,[0],[0]
Lemma 5.1.,5.1 Useful properties,[0],[0]
"In each round t = 1, 2, . . .",5.1 Useful properties,[0],[0]
", T , if qt satisfies (2.2), then for every s ∈ S and i ≤ kt:
ξst (i) = ζt(i)∑",5.1 Useful properties,[0],[0]
"j≤k ζt(j)
· ( 1− ∑ j>k ξst (j) )
",5.1 Useful properties,[0],[0]
Proof.,5.1 Useful properties,[0],[0]
Let i ≤ kt,5.1 Useful properties,[0],[0]
and,5.1 Useful properties,[0],[0]
s ∈ S.,5.1 Useful properties,[0],[0]
"By (2.1) and since ξst = T kts qt one has
ξst (i) = qt(i)∑ j≤k qt(j) ∑ j≤k ξst (j) .
",5.1 Useful properties,[0],[0]
"Moreover qt is a mixture of ζt and truncated versions of ζt so similarly using (2.1) one has
qt(i) = ζt(i)∑ j≤k ζt(j) ∑ j≤k qt(j) .
",5.1 Useful properties,[0],[0]
"Putting the two above displays together concludes the proof.
",5.1 Useful properties,[0],[0]
Lemma 5.2.,5.1 Useful properties,[0],[0]
"In each round t = 1, 2, . . .",5.1 Useful properties,[0],[0]
", T , if qt satisfies (2.2), then
• for every i > kt",5.1 Useful properties,[0],[0]
"it satisfies qt(i) ≤ ζt(i), and • for every i ≤",5.1 Useful properties,[0],[0]
kt,5.1 Useful properties,[0],[0]
"it satisfies qt(i) ≥ ζt(i) ≥ 12K .
",5.1 Useful properties,[0],[0]
Proof.,5.1 Useful properties,[0],[0]
For sake of notation we drop the index t in this proof.,5.1 Useful properties,[0],[0]
Recall q = ∑ e∈E∪S w(e) ‖w‖1 · ξ,5.1 Useful properties,[0],[0]
"e.
• For every minority arm i > k, every s ∈ S, we have ξs(i) =",5.1 Useful properties,[0],[0]
( T ks q ) (i) ≤ q(i),5.1 Useful properties,[0],[0]
"according to Definition 2.1.
2We stress that in the K-arm setting, although kt is the minimum index such that ζt(1) + · · ·+ ζt(kt) ≥ 12 , it may not be the minimum index so that qt(1) + · · ·+ qt(kt) ≥ 12 .
",5.1 Useful properties,[0],[0]
"Therefore, we must have q(i) = ∑ e∈E∪S w(e) ‖w‖1 ·
ξe(i) ≤ ∑ e∈E w(e)ξ
e(i)∑ e∈E w(e) = ζ(i).
",5.1 Useful properties,[0],[0]
• For every majority arm i ≤,5.1 Useful properties,[0],[0]
"k, we have (using Lemma 5.1)
ξe(i) = ζ(i)∑",5.1 Useful properties,[0],[0]
j≤k ζ(j) ·,5.1 Useful properties,[0],[0]
"(1− ∑ j>k ξs(j))
",5.1 Useful properties,[0],[0]
"≥ ζ(i)∑ j≤k ζ(j) · (1− ∑ j>k ζ(j)) = ζ(i)
",5.1 Useful properties,[0],[0]
From the definition of k = min{i ∈,5.1 Useful properties,[0],[0]
"[K] : ∑ j≤i ζ(j) ≥ 1 2}, we can also conclude ζ(i) ≥ ζ(k)",5.1 Useful properties,[0],[0]
≥ 12K .,5.1 Useful properties,[0],[0]
This is because 1 2 ≤ ∑,5.1 Useful properties,[0],[0]
"j>k ζ(j) ≤ Kζ(k).
",5.1 Useful properties,[0],[0]
The next lemma shows that setting pt = T ktγ,5.1 Useful properties,[0],[0]
"qt satisfies the assumption of Lemma 3.2.
",5.1 Useful properties,[0],[0]
Lemma 5.3.,5.1 Useful properties,[0],[0]
"If qt satisfies (2.2), γ ∈ (0, 12 ] and pt = T ktγ qt, then for every arm i ∈",5.1 Useful properties,[0],[0]
[K]: (1−2Kγ)pt(i) ≤ qt(i) and pt(i) 6=,5.1 Useful properties,[0],[0]
"0⇒ pt(i) ≥ qt(i) .
",5.1 Useful properties,[0],[0]
Proof.,5.1 Useful properties,[0],[0]
"For sake of notation we drop the index t in this proof.
",5.1 Useful properties,[0],[0]
"By Definition 2.1 and Lemma 5.2, we have for every i ∈",5.1 Useful properties,[0],[0]
"[K]:
p(i) ≤",5.1 Useful properties,[0],[0]
q(i),5.1 Useful properties,[0],[0]
"( 1 + ∑ j:j>k∧ q(j)≤γ q(j)∑
j≤k q(j) ) ≤",5.1 Useful properties,[0],[0]
"q(i) ( 1 +
∑ j:q(j)≤γ q(j)∑",5.1 Useful properties,[0],[0]
"j≤k ζ(j) ) ≤ q(i)(1 + 2Kγ) .
",5.1 Useful properties,[0],[0]
"The other statement follows because whenever p(i) 6= 0, Definition 2.1 says it must satisfy p(i) ≥ q(i).",5.1 Useful properties,[0],[0]
"We first upper bound M and then upper bound m.
Lemma 5.4.",5.2 Bounding m and M,[0],[0]
"If qt satisfies (2.2), then M ≤ 2KLT .
",5.2 Bounding m and M,[0],[0]
Proof.,5.2 Bounding m and M,[0],[0]
Using Lemma 5.2 we have qt(i) ≥ 12K for any i ≤ kt.,5.2 Bounding m and M,[0],[0]
"Also, pt(i) ≥ qt(i) for every i satisfying ¯̀t(i) > 0",5.2 Bounding m and M,[0],[0]
(owing to Definition 3.1 and Lemma 5.3).,5.2 Bounding m and M,[0],[0]
"Therefore,
M = T∑ t=1 E ∑ i≤kt ¯̀ t(i) ≤ 2K T∑ t=1",5.2 Bounding m and M,[0],[0]
"E ∑ i≤kt qt(i) · ¯̀t(i)
≤ 2K T∑ t=1 E ∑ i≤kt pt(i) · ¯̀t(i) ≤",5.2 Bounding m and M,[0],[0]
2K T∑ t=1,5.2 Bounding m and M,[0],[0]
"E〈pt, ¯̀t〉
= 2K T∑ t=1",5.2 Bounding m and M,[0],[0]
"E〈pt, `t〉 = 2KLT .
",5.2 Bounding m and M,[0],[0]
Lemma 5.5.,5.2 Bounding m and M,[0],[0]
"Suppose qt satisfies (2.2), and denote by Lst def = E ∑T",5.2 Bounding m and M,[0],[0]
t=1〈T,5.2 Bounding m and M,[0],[0]
"kts qt, `t〉 = E ∑T",5.2 Bounding m and M,[0],[0]
"t=1〈ξst , `t〉 the total
expected loss of qt truncated to s. Then, as long as m− 2KLT > 0,
∃s ∈ (γ, 1/2] ∩ 1 2T N : m− 2KLT ≤ 1 +",5.2 Bounding m and M,[0],[0]
"LT − LsT γ .
",5.2 Bounding m and M,[0],[0]
Proof.,5.2 Bounding m and M,[0],[0]
The proof is a careful generalization of the proof of Lemma 4.3 (which in turn is just a discretization of the proof of Lemma 4.2).,5.2 Bounding m and M,[0],[0]
"Recall the notation x for the smallest element in [x,+∞) ∩ 12T N, and observe that for s ∈ 1 2T N, x ≤",5.2 Bounding m and M,[0],[0]
"s⇔ x ≤ s. Denote by
`majt def = ∑ i≤kt qt(i)∑ j≤kt qt(j) ¯̀ t(i) .
",5.2 Bounding m and M,[0],[0]
the weighted loss of the majority arms at round t. We have∑T t=1 ` maj t ≤ 2LT because ∑ j≤kt qt(j) ≥ ∑ j≤kt ζt(j) ≥ 1 2 and qt(i) ≤ pt(i) whenever ¯̀t(i) > 0,5.2 Bounding m and M,[0],[0]
"(owing to Definition 3.1 and Lemma 5.3).
",5.2 Bounding m and M,[0],[0]
"Now, for any s ≥ γ, define the function
f(s) def = E ∑T t=1",5.2 Bounding m and M,[0],[0]
∑,5.2 Bounding m and M,[0],[0]
i>kt 1{qt(i) ≤ s}(`majt,5.2 Bounding m and M,[0],[0]
"− ¯̀t(i)) .
",5.2 Bounding m and M,[0],[0]
Let us pick s ∈,5.2 Bounding m and M,[0],[0]
"[γ, 1/2] ∩ 12T N to minimize f(s), and breaking ties by choosing the smaller value of s. We make several observations:
• f(γ) ≥ 0",5.2 Bounding m and M,[0],[0]
because for any t and i > kt with qt(i) ≤ γ we must have pt(i),5.2 Bounding m and M,[0],[0]
= (T ktγ qt)(i) = 0 and thus ¯̀t(i),5.2 Bounding m and M,[0],[0]
= 0,5.2 Bounding m and M,[0],[0]
"by the definition of ¯̀t in Definition 3.1.
• f(1/2) =",5.2 Bounding m and M,[0],[0]
∑T t=1(K − kt)` maj t −m ≤,5.2 Bounding m and M,[0],[0]
"2KLT −m < 0.
",5.2 Bounding m and M,[0],[0]
• s > γ because f(s) ≤ f(1/2),5.2 Bounding m and M,[0],[0]
"< 0.
Let us define the points s0 def = γ and
{s1 < . . .",5.2 Bounding m and M,[0],[0]
"< sm} def = (γ, s] ∩ ⋃ i∈[K] {q1(i), . . .",5.2 Bounding m and M,[0],[0]
", qT (i)}.
Note that the tie-breaking rule for the choice of s ensures sm = s (if sm < s then it must satisfy f(sm) = f(s) giving a contradiction).
",5.2 Bounding m and M,[0],[0]
"Observe that by definition of the truncation operator, one has
〈T kts qt − qt, ¯̀t〉 = ∑ i>kt 1{qt(i) ≤ s}qt(i)(`majt − ¯̀t(i))
",5.2 Bounding m and M,[0],[0]
"In fact, after rounding, one can rewrite the above for some εs,t ∈",5.2 Bounding m and M,[0],[0]
"[− 12T , 1 2T ] as
〈T kts qt−qt, ¯̀t〉 = εs,t+ ∑ i>kt 1{qt(i) ≤ s}qt(i)(`majt −¯̀t(i))
",5.2 Bounding m and M,[0],[0]
"Then, for some ε ∈",5.2 Bounding m and M,[0],[0]
"[−1, 1], one has
LT − LsT = E T∑ t=1 〈T ktγ",5.2 Bounding m and M,[0],[0]
qt,5.2 Bounding m and M,[0],[0]
"− T kts qt, `t〉
= E T∑ t=1",5.2 Bounding m and M,[0],[0]
〈T ktγ,5.2 Bounding m and M,[0],[0]
qt,5.2 Bounding m and M,[0],[0]
"− T kts qt, ¯̀t〉
= ε+",5.2 Bounding m and M,[0],[0]
E T∑ t=1,5.2 Bounding m and M,[0],[0]
∑ i>kt (1{qt(i) ≤,5.2 Bounding m and M,[0],[0]
γ} − 1{qt(i) ≤,5.2 Bounding m and M,[0],[0]
"s})qt(i)(`majt − ¯̀t(i))
",5.2 Bounding m and M,[0],[0]
=,5.2 Bounding m and M,[0],[0]
ε+ E m∑ j=1 T∑ t=1,5.2 Bounding m and M,[0],[0]
∑ i>kt −sj1{qt(i) = sj}(`majt,5.2 Bounding m and M,[0],[0]
"− ¯̀t(i))
= ε+ m∑ j=1 sj(f(sj−1)− f(sj))
",5.2 Bounding m and M,[0],[0]
"= ε+ m−1∑ j=1 (sj+1 − sj)f(sj) + s1f(s0)− smf(sm) .
",5.2 Bounding m and M,[0],[0]
"Since f(s0) = f(γ) ≥ 0, f(si) ≥ f(s) and s = sm, we conclude that
LT − LsT ≥ ε+ (sm − s1)f(sm)− smf(sm) = ε− s1f(sm) ≥ γ(m− 2KLT ) .",5.2 Bounding m and M,[0],[0]
"Finally, using Lemma 3.2 (which applies thanks to Lemma 5.3), (5.1) and L∗T ≤ LsT (the loss of an expert is no better than the loss of the best expert L∗T ), we have
LT − LsT ≤",5.3 Putting all together,[0],[0]
O ( log(|E′|) η + η(m+M) + γKLT ) .,5.3 Putting all together,[0],[0]
"(5.2) Putting this into Lemma 5.5 and then using M ≤ 2KLT from Lemma 5.4, we have for any γ ≥ 2η,
γ(m+M) ≤",5.3 Putting all together,[0],[0]
"O ( log(|E′|) η + γKLT ) .
",5.3 Putting all together,[0],[0]
"Putting this into (5.1), we immediately get (3.2) as desired.",5.3 Putting all together,[0],[0]
This finishes the proof of Theorem 1.1.,5.3 Putting all together,[0],[0]
It only remains to ensure that qt verifying (2.2) indeed exists.,5.3 Putting all together,[0],[0]
We provide an algorithm for this in Section 6.,5.3 Putting all together,[0],[0]
"In this section, we answer the question of how to algorithmically find qt satisfying the implicitly definition (2.2).",6 Algorithmic Process to Find qt,[0],[0]
"We recall (2.2):
qt = 1∑ e∈E wt(e) + ∑ s∈S wt(s)
× (∑
e∈E wt(e)ξ e t + ∑ s∈S wt(s)T kts qt ) .",6 Algorithmic Process to Find qt,[0],[0]
"(2.2)
We show the following general lemma: Lemma 6.1.",6 Algorithmic Process to Find qt,[0],[0]
Given k ∈,6 Algorithmic Process to Find qt,[0],[0]
"[K], a finite subset S ⊂",6 Algorithmic Process to Find qt,[0],[0]
"[ 0, 12 ] , ζ ∈ ∆K with ζ(1) ≥ · · · ≥ ζ(K), and W ∈ ∆1+|S|, Algorithm 2 finds some q ∈ ∆K such that
q = W (1)ζ + ∑ s∈SW (s)T ks q .
",6 Algorithmic Process to Find qt,[0],[0]
"Furthermore, Algorithm 2 runs in time O(K · |S|).
",6 Algorithmic Process to Find qt,[0],[0]
"We observe that by setting k = kt, ζ = ζt = ∑ e∈E wt(e)·ξ e t∑
e∈E wt(e) , W (1) =
∑ e∈E wt(e)
",6 Algorithmic Process to Find qt,[0],[0]
"‖wt‖1
and ∀s ∈ S : W (s) = wt(s)‖wt‖1 in Lemma 6.1, we immediately obtain a vector q ∈ ∆K that we can use as qt.
Intuition for Lemma 6.1.",6 Algorithmic Process to Find qt,[0],[0]
We only search for q that is monotonically non-increasing for minority arms.,6 Algorithmic Process to Find qt,[0],[0]
This implies T ks q is also non-increasing for minority arms.,6 Algorithmic Process to Find qt,[0],[0]
"In symbols: q(k + 1) ≥ · · · ≥ q(K) and
(T ks q)(k + 1) ≥ · · · ≥ (T ks q)(K) .",6 Algorithmic Process to Find qt,[0],[0]
"Due to such monotonicity, when computing T ks q for each s ∈ S, there must exist some index πs ∈ {k + 1, k + 2, . . .",6 Algorithmic Process to Find qt,[0],[0]
",K + 1} such that the entry q(i) gets zeroed out for all i ≥ πs or in symbols, (T ks q)(i) = 0",6 Algorithmic Process to Find qt,[0],[0]
for all i ≥ πs.,6 Algorithmic Process to Find qt,[0],[0]
"Now, the main idea of Algorithm 2 is to search for such non-increasing function π : S →",6 Algorithmic Process to Find qt,[0],[0]
[K+1].,6 Algorithmic Process to Find qt,[0],[0]
"It initializes itself with πs = k + 1 for all s ∈ S, and then tries to increase π coordinate by coordinate.
",6 Algorithmic Process to Find qt,[0],[0]
"For each choice of π, Algorithm 2 computes a candidate distribution qπ ∈ ∆K which satisfies
qπ = W (1)ζ + ∑ s∈S W (s)us (6.1)
where each us is qπ but truncated so that its probabilities after πs are redistributed to the first k arms, or in symbols,
us(i) =  0, i ≥ πs; qπ(i),",6 Algorithmic Process to Find qt,[0],[0]
"πs > i > k; qπ(i) · ( 1 + ∑ j:j≥πs qπ(j)∑ j≤k qπ(j) ) , i ≤ k.
One can verify that the distribution qπ ∈ ∆K defined in Line 3 of Algorithm 2 is an explicit solution to (6.1).",6 Algorithmic Process to Find qt,[0],[0]
"Unfortunately, each us may not satisfy T ks qπ = us.",6 Algorithmic Process to Find qt,[0],[0]
"In particular, there may exist
some s ∈ S and i > k such that qπ(i) > s but us(i) = 0.",6 Algorithmic Process to Find qt,[0],[0]
"This means, we may have truncated too much for expert s in defining us, and we must increase πs.
",6 Algorithmic Process to Find qt,[0],[0]
"Perhaps not very surprisingly, if each iteration we only increase one πs by exactly 1, then we never overshoot and there exists a moment when q = qπ exactly satisfies
q",6 Algorithmic Process to Find qt,[0],[0]
"= W (1)ζ + ∑ s∈SW (s)T ks q .
",6 Algorithmic Process to Find qt,[0],[0]
We now give a formal proof of Lemma 6.1.,6 Algorithmic Process to Find qt,[0],[0]
Claim 6.2.,6.1 Proof details,[0],[0]
We claim some properties about Algorithm 2 (a) The process finishes after at most K · |S| iterations.,6.1 Proof details,[0],[0]
(b) We always have qπ(k + 1) ≥ · · · ≥ qπ(K).,6.1 Proof details,[0],[0]
(c),6.1 Proof details,[0],[0]
"As π changes, for each minority arm i > k, qπ(i) never
decreases.
",6.1 Proof details,[0],[0]
"(d) When the while loop ends, for each i > k and s ∈ S, we have qπ(i)",6.1 Proof details,[0],[0]
"> s⇐⇒ πs > i.
",6.1 Proof details,[0],[0]
"The proof of Claim 6.2 can be found in the full version.
",6.1 Proof details,[0],[0]
Proof of Lemma 6.1.,6.1 Proof details,[0],[0]
Suppose in the end of Algorithm 2 we obtain q = qπ for some π : S → [K+1].,6.1 Proof details,[0],[0]
"Let ξs = T ks q
Algorithm 2",6.1 Proof details,[0],[0]
Input: k ∈,6.1 Proof details,[0],[0]
"[K], a finite set S ⊆ [ 0, 12 ] , ζ ∈ ∆K with ζ(1) ≥ · · · ≥ ζ(K), and W ∈ ∆1+|S|
Output: q ∈ ∆K such that q",6.1 Proof details,[0],[0]
= W (1)ζ + ∑ s∈SW (,6.1 Proof details,[0],[0]
"s)T ks q.
1: initialize π : S →",6.1 Proof details,[0],[0]
"[K + 1] as πs = k + 1; will ensure πs ∈ {k + 1, k + 2, . .",6.1 Proof details,[0],[0]
.,6.1 Proof details,[0],[0]
",K + 1} 2: while true do
3: qπ(i)←  W (1) 1− ∑ s∈S∧πs>iW",6.1 Proof details,[0],[0]
"(s)
· ζ(i), if i > k; ζ(i)∑ j≤k ζ(j) · (1− ∑ j>k qπ(j)), if i ≤ k.
qπ ∈ ∆K
4: Pick any s ∈ S with πs ≤ K such that qπ(πs) >",6.1 Proof details,[0],[0]
"s. 5: if s is not found then break 6: else πs ← πs + 1. 7: end while 8: return qπ .
for each s ∈ S and q′",6.1 Proof details,[0],[0]
= W (1)ζ + ∑ s∈SW (,6.1 Proof details,[0],[0]
s)T ks q.,6.1 Proof details,[0],[0]
We need to show q = q′.,6.1 Proof details,[0],[0]
"For every minority arm i > k:
q′(i) ¬ = W (1) · ζ(i) + ∑ s∈S W (s) · ξs(i)
 ",6.1 Proof details,[0],[0]
"= W (1) · ζ(i) + ( ∑ s∈S∧q(i)>s W (s) ) · q(i)
® = W (1) · ζ(i) + ( ∑ s∈S∧πs>i W (s) ) · q(i) ¯= q(i) .
",6.1 Proof details,[0],[0]
"Above, equality ¬ is by the definition of q′, equality  is by the definition of ξs = T",6.1 Proof details,[0],[0]
"ks q, equality ® follows from Claim 6.2.d, and equality ¯ is by definition of q(i) = qπ(i)",6.1 Proof details,[0],[0]
= W (1) 1− ∑ s∈S∧πs>iW,6.1 Proof details,[0],[0]
(s) · ζ(i).,6.1 Proof details,[0],[0]
"For every majority arm i ≤ k, q′(i)
ζ(i)
¬ = W (1) · ζ(i)ζ(i) + ∑ s∈SW (s) · ξs(i) ζ(i)
 = W (1) + ∑ s∈SW (s) · ∑ j≤k ξ s(j)∑ j≤k ζ(j)
(6.2)
where equality ¬ is by the definition of q′ and equality  is because for every i ≤ k",6.1 Proof details,[0],[0]
"it satisfies ξ
s(i) q(i) =
∑ j≤k ξ
s(j)∑ j≤k q(j)
(using definition of ξs = T ks q) and for every i ≤",6.1 Proof details,[0],[0]
k,6.1 Proof details,[0],[0]
"it satisfies ζ(i)q(i) = ∑ j≤k ζ(j)∑ j≤k q(j)
(using definition of q = qπ Line 3 of Algorithm 2).
",6.1 Proof details,[0],[0]
"Now, the right hand side of (6.2) is independent of i. Therefore, we can write q′(i) = C1 · ζ(i) for each i ≤ k with some constant C1 > 0.",6.1 Proof details,[0],[0]
Our definition of q = qπ,6.1 Proof details,[0],[0]
(see Line 3 of Algorithm 2) ensures that we can also write q(i) = C2 · ζ(i) for each i ≤ k with some constant C2 > 0.,6.1 Proof details,[0],[0]
"Therefore, since for every i > k we have already shown q′(i) = q(i), it must satisfy C1 = C2 and therefore q′(i) = q(i) for all i ∈",6.1 Proof details,[0],[0]
[K].,6.1 Proof details,[0],[0]
"After proving q′ = q, we only need to argue about the running time.
",6.1 Proof details,[0],[0]
"If Algorithm 2 is implemented naively, then the total running time is O((K · |S|)2) because there are at most K · |S|
iterations (see Claim 6.2.a) and in each iteration we can compute qπ in time O(K · |S|).",6.1 Proof details,[0],[0]
In fact it is rather easy to find implicit update rules to make each iteration of Algorithm 2 run in O(1) time.,6.1 Proof details,[0],[0]
"We give some hints below.
",6.1 Proof details,[0],[0]
"Indeed, if in an iteration some πs is changed from i to i+ 1 (recalling i > k), then we can update qπ(i) in O(1) time.",6.1 Proof details,[0],[0]
For each j > k where j 6=,6.1 Proof details,[0],[0]
"i, we have qπ(j) is unchanged.",6.1 Proof details,[0],[0]
"The values of qπ(j) for j ≤ k all need to be changed, but they are only changed altogether by the same multiplicative factor (which can again be calculated in O(1) time).
",6.1 Proof details,[0],[0]
"Finally, to search for s ∈ S with πs ≤ K and qπ(πs) > s, we do not need to go through all s ∈ S. Instead, for each",6.1 Proof details,[0],[0]
"i > k, we maintain “the smallest si ∈ S so that qπ(i) > si.”",6.1 Proof details,[0],[0]
"Then, whenever πsi ≤",6.1 Proof details,[0],[0]
"i, that means we can pick s = si because qπ(πs) = qπ(πsi) ≥ qπ(i)",6.1 Proof details,[0],[0]
> si = s.,6.1 Proof details,[0],[0]
"For such reason, one can maintain a first-in-first-out list to store all values of i where qπ(i) > si.",6.1 Proof details,[0],[0]
In each iteration of Algorithm 2 we simply pick the first element in list and perform the update.,6.1 Proof details,[0],[0]
"This changes exactly one qπ(j) for j > k, and thus may additionally insert one element to list.",6.1 Proof details,[0],[0]
"Therefore, in each iteration we only needO(1) time to find some πs to increase.",6.1 Proof details,[0],[0]
"Regret bounds in online learning compare the player’s performance to L∗, the optimal performance in hindsight with a fixed strategy.",abstractText,[0],[0]
Typically such bounds scale with the square root of the time horizon T .,abstractText,[0],[0]
"The more refined concept of first-order regret bound replaces this with a scaling √ L∗, which may be much smaller than √ T .",abstractText,[0],[0]
It is well known that minor variants of standard algorithms satisfy first-order regret bounds in the full information and multi-armed bandit settings.,abstractText,[0],[0]
"In a COLT 2017 open problem (Agarwal et al., 2017), Agarwal, Krishnamurthy, Langford, Luo, and Schapire raised the issue that existing techniques do not seem sufficient to obtain first-order regret bounds for the contextual bandit problem.",abstractText,[0],[0]
"In the present paper, we resolve this open problem by presenting a new strategy based on augmenting the policy space.1",abstractText,[0],[0]
Make the Minority Great Again:  First-Order Regret Bound for Contextual Bandits,title,[0],[0]
"Math word problems form a natural abstraction to a range of quantitative reasoning problems, such as understanding financial news, sports results, and casualties of war. Solving such problems requires the understanding of several mathematical concepts such as dimensional analysis, subset relationships, etc. In this paper, we develop declarative rules which govern the translation of natural language description of these concepts to math expressions. We then present a framework for incorporating such declarative knowledge into word problem solving. Our method learns to map arithmetic word problem text to math expressions, by learning to select the relevant declarative knowledge for each operation of the solution expression. This provides a way to handle multiple concepts in the same problem while, at the same time, support interpretability of the answer expression. Our method models the mapping to declarative knowledge as a latent variable, thus removing the need for expensive annotations. Experimental evaluation suggests that our domain knowledge based solver outperforms all other systems, and that it generalizes better in the realistic case where the training data it is exposed to is biased in a different way than the test data.",text,[0],[0]
"Many natural language understanding situations require reasoning with respect to numbers or quanti-
∗Most of the work was done when the authors were at the University of Illinois, Urbana Champaign.
ties – understanding financial news, sports results, or the number of casualties in a bombing.",1 Introduction,[0],[0]
Math word problems form a natural abstraction to a lot of these quantitative reasoning problems.,1 Introduction,[0],[0]
"Consequently, there has been a growing interest in developing automated methods to solve math word problems (Kushman et al., 2014; Hosseini et al., 2014; Roy and Roth, 2015).
",1 Introduction,[0],[0]
"Understanding and solving math word problems involves interpreting natural language description of mathematical concepts, as well as understanding their interaction with the physical world.",1 Introduction,[0],[0]
Consider the elementary school level arithmetic word problem shown in Fig 1.,1 Introduction,[0],[0]
"To solve the problem, one needs to understand that “apple pies” and “pecan pies” are kinds of “pies”, and hence, the number of
ar X
iv :1
71 2.
09 39
1v 1
[ cs
.C L
] 2
6 D
ec 2
apple pies and pecan pies needs to be summed up to get the total number of pies.",1 Introduction,[0],[0]
"Similarly, detecting that “5” represents “the number of pies per row” and applying dimensional analysis or unit compatibility knowledge, helps us infer that the total number of pies needs to be divided by 5 to get the answer.",1 Introduction,[0],[0]
"Besides part-whole relationship and dimensional analysis, there are several other concepts that are needed to support reasoning in math word problems.",1 Introduction,[0],[0]
"Some of these involve understanding comparisons, transactions, and the application of math or physics formulas.",1 Introduction,[0],[0]
"Most of this knowledge can be encoded as declarative rules, as illustrated in this paper.
",1 Introduction,[0],[0]
This paper introduces a framework for incorporating this “declarative knowledge” into word problem solving.,1 Introduction,[0],[0]
"We focus on arithmetic word problems, whose solution can be obtained by combining the numbers in the problem with basic operations (addition, subtraction, multiplication or division).",1 Introduction,[0],[0]
"For combining a pair of numbers or math subexpressions, our method first predicts the math concept that is needed for it (e.g., subset relationship, dimensional analysis, etc.), and then predicts a declarative rule under that concept to infer the mathematical operation.",1 Introduction,[0],[0]
"We model the selection of declarative rules as a latent variable, which removes the need for expensive annotations for the intermediate steps.
",1 Introduction,[0],[0]
The proposed approach has some clear advantages compared to existing work on word problem solving.,1 Introduction,[0],[0]
"First, it provides interpretability of the solution, without expensive annotations.",1 Introduction,[0],[0]
Our method selects a declarative knowledge based inference rule for each operation needed in the solution.,1 Introduction,[0],[0]
These rules provide an explanation for the operations performed.,1 Introduction,[0],[0]
"In particular, it learns to select relevant rules without explicit annotations for them.",1 Introduction,[0],[0]
"Second, each individual operation in the solution expression can be generated independently by a separate mathematical concept.",1 Introduction,[0],[0]
"This allows our method to handle multiple concepts in the same problem.
",1 Introduction,[0],[0]
"We show that existing datasets of arithmetic word problems suffer from significant vocabulary biases and, consequently, existing solvers do not do well on conceptually similar problems that are not biased in the same way.",1 Introduction,[0],[0]
"Our method, on the other hand, learns the right abstractions even in the presence of biases in the data.",1 Introduction,[0],[0]
"We also introduce a novel approach to gather word problems without these biases, creating
a new dataset of 1492 problems.",1 Introduction,[0],[0]
The next section discusses related work.,1 Introduction,[0],[0]
"We next introduce the mathematical concepts required for arithmetic word problems, as well as the declarative rules for each concept.",1 Introduction,[0],[0]
Section 4 describes our model – how we predict answers using declarative knowledge – and provides the details of our training paradigm.,1 Introduction,[0],[0]
"Finally, we provide experimental evaluation of our proposed method in Section 6, and then conclude with a discussion of future work.",1 Introduction,[0],[0]
"Our work is primarily related to three major strands of research - automatic word problem solving, semantic parsing, as well as approaches incorporating background knowledge in learning.",2 Related Work,[0],[0]
"There has been a growing interest in automatically solving math word problems, with various systems focusing on particular types of problems.",2.1 Automatic Word Problem Solving,[0],[0]
These can be broadly categorized into two types: arithmetic and algebra.,2.1 Automatic Word Problem Solving,[0],[0]
"Arithmetic Word Problems Arithmetic problems involve combining numbers with basic operations (addition, subtraction, multiplication and division), and are generally directed towards elementary school students.",2.1 Automatic Word Problem Solving,[0],[0]
"Roy and Roth (2015), Roy and Roth (2017) as well as this work focus on this class of word problems.",2.1 Automatic Word Problem Solving,[0],[0]
The works of Hosseini et al. (2014) and Mitra and Baral (2016) focus on arithmetic problems involving only addition and subtraction.,2.1 Automatic Word Problem Solving,[0],[0]
Some of these approaches also try to incorporate some form of declarative or domain knowledge.,2.1 Automatic Word Problem Solving,[0],[0]
Hosseini et al. (2014) incorporates the transfer phenomenon by classifying verbs; Mitra and Baral (2016) maps problems to a set of formulas.,2.1 Automatic Word Problem Solving,[0],[0]
"Both require extensive annotations for intermediate steps (verb classification for Hosseini et al. (2014), alignment of numbers to formulas for Mitra and Baral (2016), etc).",2.1 Automatic Word Problem Solving,[0],[0]
"In contrast, our method can handle a more general class of problems, while training only requires problem-equation pairs coupled with rate component annotations.",2.1 Automatic Word Problem Solving,[0],[0]
"Roy and Roth (2017) focuses only on using dimensional analysis knowledge, and handles the same class of problems as we do.",2.1 Automatic Word Problem Solving,[0],[0]
"In contrast, our method provides a framework
for including any form of declarative knowledge, exemplified here by incorporating common concepts required for arithmetic problems.",2.1 Automatic Word Problem Solving,[0],[0]
Algebra Word Problems Algebra word problems are characterized by the use of (one or more) variables in contructing (one or more) equations.,2.1 Automatic Word Problem Solving,[0],[0]
These are typically middle or high school problems.,2.1 Automatic Word Problem Solving,[0],[0]
"Koncel-Kedziorski et al. (2015) looks at single equation problems, and Shi et al. (2015) focuses on number word problems.",2.1 Automatic Word Problem Solving,[0],[0]
"Kushman et al. (2014) introduces a template based approach to handle general algebra word problems and several works have later proposed improvements over this approach (Zhou et al., 2015; Upadhyay et al., 2016; Huang et al., 2017).",2.1 Automatic Word Problem Solving,[0],[0]
"There has also been work on generating rationale for word problem solving (Ling et al., 2017).",2.1 Automatic Word Problem Solving,[0],[0]
"More recently, some focus turned to pre-university exam questions (Matsuzaki et al., 2017; Hopkins et al., 2017), which requires handling a wider range of problems and often more complex semantics.",2.1 Automatic Word Problem Solving,[0],[0]
"Our work is also related to learning semantic parsers from indirect supervision (Clarke et al., 2010; Liang et al., 2011).",2.2 Semantic Parsing,[0],[0]
"The general approach here is to learn a mapping of sentences to logical forms, with the only supervision being the response of executing the logical form on a knowledge base.",2.2 Semantic Parsing,[0],[0]
"Similarly, we learn to select declarative rules from supervision that only includes the final operation (and not which rule generated it).",2.2 Semantic Parsing,[0],[0]
"However, in contrast to the semantic parsing work, in our case the selection of each declarative rule usually requires reasoning across multiple sentences.",2.2 Semantic Parsing,[0],[0]
"Also, we do not require an explicit grounding of words or phrases to logical variables.",2.2 Semantic Parsing,[0],[0]
"Approaches to incorporate knowledge in learning started with Explanation based Learning (EBL) (DeJong, 1993; DeJong, 2014).",2.3 Background Knowledge in Learning,[0],[0]
"EBL uses domain knowledge based on observable predicates, whereas we learn to map text to predicates of our declarative knowledge.",2.3 Background Knowledge in Learning,[0],[0]
"More recent approaches tried to incorporate knowledge in the form of constraints or expectations from the output (Roth and tau Yih, 2004; wei Chang et al., 2007; Chang et al., 2012; Ganchev et al., 2010; Smith and Eisner, 2006; Naseem et al., 2010; Bisk and Hockenmaier, 2012; Gimpel and
Bansal, 2014).",2.3 Background Knowledge in Learning,[0],[0]
"Finally, we note that there has been some work in the context of Question Answering on perturbing questions or answers as a way to test or assure the robustness of the approach or lack of (Khashabi et al., 2016; Jia and Liang, 2017).",2.3 Background Knowledge in Learning,[0],[0]
We make used of similar ideas in order to generate an unbiased test set for Math word problems (Sec. 6).,2.3 Background Knowledge in Learning,[0],[0]
We introduce here our representation of domain knowledge.,3 Knowledge Representation,[0],[0]
We organize the knowledge hierarchically in two levels – concepts and declarative rules.,3 Knowledge Representation,[0],[0]
A math concept is a phenomenon which needs to be understood to apply reasoning over quantities.,3 Knowledge Representation,[0],[0]
"Examples of concepts include part-whole relations, dimensional analysis, etc.",3 Knowledge Representation,[0],[0]
"Under each concept, there are a few declarative rules, which dictate which operation is needed in a particular context.",3 Knowledge Representation,[0],[0]
"An example of a declarative rule under part-whole concept can be that “if two numbers quantify “parts” of a larger quantity, the operation between them must be addition”.",3 Knowledge Representation,[0],[0]
"These rules use concept specific predicates, which we exemplify in the following subsections.
",3 Knowledge Representation,[0],[0]
"Since this work focuses on arithmetic word problems, we consider 4 math concepts which are most common in these problems, as follows:
1.",3 Knowledge Representation,[0],[0]
Transfer:,3 Knowledge Representation,[0],[0]
This involves understanding the transfer of objects from one person to another.,3 Knowledge Representation,[0],[0]
"For example, the action described by the sentence “Tim gave 5 apples to Jim”, results in Tim losing “5 apples” and Jim gaining “5 apples”.
2.",3 Knowledge Representation,[0],[0]
Dimensional Analysis:,3 Knowledge Representation,[0],[0]
This involves understanding compatibility of units or dimensions.,3 Knowledge Representation,[0],[0]
"For example, “30 pies” can be divided by “5 pies per row” to get the number of rows.
3.",3 Knowledge Representation,[0],[0]
Part-Whole Relation:,3 Knowledge Representation,[0],[0]
"This includes asserting that if two numbers quantify parts of a larger quantity, they are to be added.",3 Knowledge Representation,[0],[0]
"For example, the problem in Section 1 involves understanding “pecan pies” and “apple pies” are parts of “pies”, and hence must be added.
4.",3 Knowledge Representation,[0],[0]
Explicit Math:,3 Knowledge Representation,[0],[0]
Word problems often mention explicit math relationships among quantities or entities in the problem.,3 Knowledge Representation,[0],[0]
"For example, “Jim is 5
inches taller than Tim”.",3 Knowledge Representation,[0],[0]
"This concept captures the reasoning needed for such relationships.
",3 Knowledge Representation,[0],[0]
Each of these concepts comprises a small number of declarative rules which determine the math operations; we describe them below.,3 Knowledge Representation,[0],[0]
Consider the following excerpt of a word problem exhibiting a transfer phenomenon: “Stephen owns 5 books.,3.1 Transfer,[0],[0]
Daniel gave him 4 books.,3.1 Transfer,[0],[0]
"The goal of the declarative rules is to determine which operation is required between 5 and 4, given that we know that a transfer is taking place.",3.1 Transfer,[0],[0]
"We note that a transfer usually involves two entities, which occur as subject and indirect object in a sentence.",3.1 Transfer,[0],[0]
"Also, the direction of transfer is determined by the verbs associated with the entities.",3.1 Transfer,[0],[0]
"We define a set of variables to denote these properties; we define as Subj1, Verb1, IObj1 the subject, verb and indirect object associated with the first number, and as Subj2, Verb2, IObj2 the subject, verb and indirect object related to the second number.",3.1 Transfer,[0],[0]
"For the above example, the assignment of the variables are shown below:
[Stephen]Subj1 [owns]V erb1 5 books.",3.1 Transfer,[0],[0]
"[Daniel]Subj2 [gave]V erb2 [him]IObj2 4 books.
",3.1 Transfer,[0],[0]
"In order to determine the direction of transfer, we require some classification of verbs.",3.1 Transfer,[0],[0]
"In particular, we classify each verb into one of five classes: HAVE, GET, GIVE, CONSTRUCT and DESTROY.",3.1 Transfer,[0],[0]
"The HAVE class consists of all verbs which signify the state of an entity, such as “have”, “own”, etc.",3.1 Transfer,[0],[0]
The GET class contains verbs which indicate the gaining of things for the subject.,3.1 Transfer,[0],[0]
"Examples of such verbs are “acquire”, “borrow”, etc.",3.1 Transfer,[0],[0]
The GIVE class contains verbs which indicate the loss of things for the subject.,3.1 Transfer,[0],[0]
"Verbs like “lend”, “give” belong to this class.",3.1 Transfer,[0],[0]
"Finally CONSTRUCT class constitutes verbs indicating construction or creation, like “build”, “fill”, etc., while DESTROY verbs indicate destruction related verbs like “destroy”, “eat”, “use”, etc.",3.1 Transfer,[0],[0]
"This verb classification is largely based on the work of (Hosseini et al., 2014).
",3.1 Transfer,[0],[0]
"Finally, the declarative rules for this concept have the following form:
[Verb1 ∈ HAVE] ∧",3.1 Transfer,[0],[0]
[Verb2 ∈ GIVE] ∧,3.1 Transfer,[0],[0]
"[Coref(Subj1, IObj2)]⇒ Addition
where Coref(A,B) is true when A and B represent the same entity or are coreferent, and is false otherwise.",3.1 Transfer,[0],[0]
"In the examples above, Verb1 is “own” and hence [Verb1 ∈ HAVE] is true.",3.1 Transfer,[0],[0]
Verb2 is “give” and hence [Verb2 ∈ GIVE] is true.,3.1 Transfer,[0],[0]
"Finally, Subj1 and IObj2 both refer to Stephen, so [Coref(Subj1, IObj2)] returns true.",3.1 Transfer,[0],[0]
"As a result, the above declarative rule dictates that addition should be performed between 5 and 4.
",3.1 Transfer,[0],[0]
"We have 18 such inference rules for transfer, covering all combinations of verb classes and Coref() values.",3.1 Transfer,[0],[0]
All these rules generate addition or subtraction operations.,3.1 Transfer,[0],[0]
We now look at the use of dimensional analysis knowledge in word problem solving.,3.2 Dimensional Analysis,[0],[0]
"To use dimensional analysis, one needs to extract the units of numbers as well as the relations between the units.",3.2 Dimensional Analysis,[0],[0]
Consider the following excerpt of a word problem: “Stephen has 5 bags.,3.2 Dimensional Analysis,[0],[0]
Each bag has 4 apples.,3.2 Dimensional Analysis,[0],[0]
"Knowing that the unit of 5 is “bag” and the effective unit of 4 is “apples per bag”, allows us to infer that the numbers can be multiplied to obtain the total number of apples.
",3.2 Dimensional Analysis,[0],[0]
"To capture these dependencies, we first introduce a few terms.",3.2 Dimensional Analysis,[0],[0]
"Whenever a number has a unit of the form “A per B”, we refer to “A” as the unit of the number, and refer to “B” as the rate component of the number.",3.2 Dimensional Analysis,[0],[0]
"In our example, the unit of 4 is “apple”, and the rate component of 4 is “bag”.",3.2 Dimensional Analysis,[0],[0]
We define variables Unit1 and Rate1 to denote the unit and the rate component of the first number respectively.,3.2 Dimensional Analysis,[0],[0]
We similarly define Unit2 and Rate2.,3.2 Dimensional Analysis,[0],[0]
"For the above example, the assignment of variables are shown below:
Stephen has 5 [bags]Unit1.",3.2 Dimensional Analysis,[0],[0]
"Each [bag]Rate2 has 4 [apples]Unit2.
",3.2 Dimensional Analysis,[0],[0]
"Finally, the declarative rule applicable for our example has the following form:
",3.2 Dimensional Analysis,[0],[0]
"[Coref(Unit1,Rate2)]⇒ Multiplication
We only have 3 rules for dimensional analysis.",3.2 Dimensional Analysis,[0],[0]
They generate multiplication or division operations.,3.2 Dimensional Analysis,[0],[0]
"In this subsection, we want to capture the reasoning behind explicit math relationships expressed in word problems such as the one described in: “Stephen has 5 apples.",3.3 Explicit Math,[0],[0]
Daniel has 4 more apples than Stephen”.,3.3 Explicit Math,[0],[0]
We define by Math1 and Math2 any explicit math term associated with the first and second numbers respectively.,3.3 Explicit Math,[0],[0]
"As was the case for transfers, we also define Subj1, IObj1, Subj2, and IObj2 to denote the entities participating in the math relationship.",3.3 Explicit Math,[0],[0]
"The assignment of these variables in our example is:
[Stephen]Subj1 has 5 apples.",3.3 Explicit Math,[0],[0]
[Daniel]Subj2 has 4 [more apples than]Math2,3.3 Explicit Math,[0],[0]
"[Stephen]IObj2.
",3.3 Explicit Math,[0],[0]
"We classify explicit math terms into one of three classes - ADD, SUB and MUL.",3.3 Explicit Math,[0],[0]
"ADD comprises terms for addition, like “more than”, “taller than” and “heavier than”.",3.3 Explicit Math,[0],[0]
"SUB consists of terms for subtraction like“less than”, “shorter than”, etc., and MUL contains terms indicating multiplication, like “times”, “twice” and “thrice”.",3.3 Explicit Math,[0],[0]
"Finally, the declarative rule that applies for our example is:
[Coref(Subj1, IObj2)]",3.3 Explicit Math,[0],[0]
∧ [Math2 ∈ ADD] ⇒,3.3 Explicit Math,[0],[0]
"Addition
We have only 7 rules for explicit math.",3.3 Explicit Math,[0],[0]
"Understanding part-whole relationship entails understanding whether two quantities are hyponym, hypernym or siblings (that is, co-hyponym, or parts of the same quantity).",3.4 Part-Whole Relation,[0],[0]
"For example, in the excerpt “Mrs. Hilt has 5 pecan pies and 4 apple pies”, determining that pecan pies and apple pies are parts of all pies, helps inferring that addition is needed.",3.4 Part-Whole Relation,[0],[0]
"We have 3 simple rules which directly map from Hyponym, Hypernym or Sibling detection to the corresponding math operation.",3.4 Part-Whole Relation,[0],[0]
"For the above example, the applicable declarative rule is:
[Sibling(Number1,Number2)]⇒ Addition
The rules for part-whole concept can generate addition and subtraction operations.",3.4 Part-Whole Relation,[0],[0]
Table 1 gives a list of all the declarative rules.,3.4 Part-Whole Relation,[0],[0]
Note that all the declarative rules are designed to determine an operation between two numbers only.,3.4 Part-Whole Relation,[0],[0]
"We introduce a strategy in Section 4, which facilitates combining subexpressions with these rules.",3.4 Part-Whole Relation,[0],[0]
"Given an input arithmetic word problem x, the goal is to predict the math expression y, which generates the correct answer.",4 Mapping of Word Problems to Declarative Knowledge,[0],[0]
"In order to derive the expression y from the word problem x, we leverage math concepts and declarative rules that we introduced in Section 3.",4 Mapping of Word Problems to Declarative Knowledge,[0],[0]
"In order to combine two numbers mentioned in x, we first predict a concept k, and then we choose a declarative knowledge rule r from k.",4 Mapping of Word Problems to Declarative Knowledge,[0],[0]
The rule r generates the math operation needed to combine the two numbers.,4 Mapping of Word Problems to Declarative Knowledge,[0],[0]
Consider the first example in Table 2.,4 Mapping of Word Problems to Declarative Knowledge,[0],[0]
"To combine 6 and 9, we first decide on the transfer concept, and then choose an appropriate rule under transfer to generate the operation.
",4 Mapping of Word Problems to Declarative Knowledge,[0],[0]
Next we need to combine the sub-expression (6+ 9) with the number 3.,4 Mapping of Word Problems to Declarative Knowledge,[0],[0]
"However, our inference rules were designed for the combination of two numbers only.",4 Mapping of Word Problems to Declarative Knowledge,[0],[0]
"In order to combine a sub-expression, we choose a representative number from the subexpression, and use that number to determine the operation.",4 Mapping of Word Problems to Declarative Knowledge,[0],[0]
"In our example, we choose the number 6 as the representative number for (6 + 9), and decide the operation between 6 and 3, following a similar procedure as before.",4 Mapping of Word Problems to Declarative Knowledge,[0],[0]
"This operation is now used to combine (6 + 9) and 3.
",4 Mapping of Word Problems to Declarative Knowledge,[0],[0]
The representative number for a sub-expression is chosen such that it preserves the reasoning needed for the combination of this sub-expression with other numbers.,4 Mapping of Word Problems to Declarative Knowledge,[0],[0]
"We follow a heuristic to choose a representative number from a sub-expression:
1.",4 Mapping of Word Problems to Declarative Knowledge,[0],[0]
"For transfers and part-whole relationship, we choose the representative number of the left subtree.
2.",4 Mapping of Word Problems to Declarative Knowledge,[0],[0]
"In case of rate relationship, we choose the number which does not have a rate component.
3.",4 Mapping of Word Problems to Declarative Knowledge,[0],[0]
"In case of explicit math, we choose the number which is not directly associated with the explicit math expression.",4 Mapping of Word Problems to Declarative Knowledge,[0],[0]
"Given the input word problem x, the solution math expression y is constructed by combining numbers in x with operations.",4.1 Scoring Answer Derivations,[0],[0]
We refer to the set of operations used in an expression y as (y).,4.1 Scoring Answer Derivations,[0],[0]
"Each operation o in (y) is generated by first choosing a concept ko, and then selecting a declarative rule ro from that concept.
",4.1 Scoring Answer Derivations,[0],[0]
"In order to discriminate between multiple candidate solution expressions of a word problem x, we
score them using a linear model over features extracted from the derivation of the solution.",4.1 Scoring Answer Derivations,[0],[0]
"Our scoring function has the following form:
SCORE(x, y) = ∑
o∈ (y)
wkφk(x, k o) + wrφr(x, r o)
where φk(x, ko) and φr(x, ro) are feature vectors related to concept ko, and declarative rule ro, respectively, and wk and wr are the corresponding weight vectors.",4.1 Scoring Answer Derivations,[0],[0]
"The term wkφk(x, ko) is the score for the selection of ko, and the termwrφr(x, ro) is the score for the selection of ro.",4.1 Scoring Answer Derivations,[0],[0]
"Finally, the total score is the sum of the scores of all concepts and rule choices, over all operations of y.",4.1 Scoring Answer Derivations,[0],[0]
"We wish to estimate the parameters of the weight vectors wk and wr, such that our scoring function assigns a higher score to the correct math expression, and a lower score to other competing math expressions.",4.2 Learning,[0],[0]
"For learning the parameters, we assume access to word problems paired with the correct math expression.",4.2 Learning,[0],[0]
We show in Section 5 that certain simple heuristics and rate component annotations can be used to create somewhat noisy annotations for the concepts needed for individual operations.,4.2 Learning,[0],[0]
"Hence, we will assume for our formulation access to concept supervision as well.",4.2 Learning,[0],[0]
"We thus assume access to m examples of the following form: {(x1, y1, {ko}o∈ (y1)), (x2, y2, {ko}o∈ (y2)), . . .",4.2 Learning,[0],[0]
", (xm, ym, {ko}o∈ (ym))}.
",4.2 Learning,[0],[0]
"We do not have any supervision for declarative rule selection, which we model as a latent variable.",4.2 Learning,[0],[0]
Two Stage Learning: A straightforward solution for our learning problem could be to jointly learn wk and wr using latent structured SVM.,4.2 Learning,[0],[0]
"However, we found that this model does not perform well.",4.2 Learning,[0],[0]
"Instead, we chose a two stage learning protocol.",4.2 Learning,[0],[0]
"At the first stage, we only learn wr, the weight vector for
scoring the declarative rule choice.",4.2 Learning,[0],[0]
"Once learned, we fix the parameters for wr, and then learn the parameters for wk.
",4.2 Learning,[0],[0]
"In order to learn the parameters for wr, we solve:
min wr
1 2 ||wr||2 + C m∑ i=1",4.2 Learning,[0],[0]
∑,4.2 Learning,[0],[0]
"o∈ (yi) [ max r̂∈ko,r̂⇒ô wr · φr(x, r̂)+
∆(ô, o) ]",4.2 Learning,[0],[0]
"− max
r̂∈ko,r̂⇒o wr · φr(x, r̂),
where r̂ ∈ ko implies that r̂ is a declarative rule for concept ko, r̂ ⇒",4.2 Learning,[0],[0]
o,4.2 Learning,[0],[0]
"signify that the declarative rule r̂ generates operation o, and ∆(ô, o) represents a measure of dissimilarity between operations o and ô. The above objective is similar to that of latent structured SVM.",4.2 Learning,[0],[0]
"For each operation o in the solution expression yi, the objective tries to minimize the difference between the highest scoring rule from its concept ko, and highest scoring rule from ko which explains or generates the operation o.
Next we fix the parameters of wr, and solve:
min wk
1 2 ||wk||2 + C m∑ i=1
max y∈Y
[SCORE(xi, y) + ∆(y, yi)]− SCORE(xi, yi).
",4.2 Learning,[0],[0]
This is equivalent to a standard structured SVM objective.,4.2 Learning,[0],[0]
"We use a 0 − 1 loss for ∆(ô, o).",4.2 Learning,[0],[0]
"Note that fixing the parameters of wr determines the scores for rule selection, removing the need for any latent variables at this stage.",4.2 Learning,[0],[0]
"Given an input word problem x, inferring the best math expression involves computing arg maxy∈Y SCORE(x, y), where Y is the set of all math expressions that can be created by combining the numbers in x with basic math operations.
",4.3 Inference,[0],[0]
"The size of Y is exponential in the number of quantities mentioned in x. As a result, we perform approximate inference using beam search.",4.3 Inference,[0],[0]
We initialize the beam with the set E of all numbers mentioned in the problem x.,4.3 Inference,[0],[0]
"At each step of the beam search, we choose two numbers (or sub-expressions) e1 and e2 fromE, and then select a math concept and a declarative rule to infer an operation o.",4.3 Inference,[0],[0]
We create a new sub-expression e3 by combining the subexpressions e1 and e2 with operation o.,4.3 Inference,[0],[0]
"We finally create a new set E′ from E, by removing e1 and e2 from it, and adding e3 to it.",4.3 Inference,[0],[0]
"We remove E from the beam, and add all such modified sets E′ to the beam.",4.3 Inference,[0],[0]
We continue this process until all sets in the beam have only one element in them.,4.3 Inference,[0],[0]
We choose the highest scoring expression among these elements as the solution expression.,4.3 Inference,[0],[0]
"Each word problem in our dataset is annotated with the solution math expression, along with alignment of numbers from the problem to the solution expression.",5.1 Supervision,[0],[0]
"In addition, we also have annotations for the numbers which possess a rate component.",5.1 Supervision,[0],[0]
An example is shown in Fig 2.,5.1 Supervision,[0],[0]
"This is the same level of supervision used in (Roy and Roth, 2017).",5.1 Supervision,[0],[0]
Many of the annotations can be extracted semi-automatically.,5.1 Supervision,[0],[0]
"The number list is extracted automatically by a number detector, the alignments require human supervision only when the same numeric value is mentioned multiple times in the problem.",5.1 Supervision,[0],[0]
"Most of the rate component annotations can also be extracted automatically, see (Roy and Roth, 2017) for details.
",5.1 Supervision,[0],[0]
"We apply a few heuristics to obtain noisy anno-
tations for the math concepts for operations.",5.1 Supervision,[0],[0]
"Consider the case for combining two numbers num1 and num2, by operation o.",5.1 Supervision,[0],[0]
"We apply the following rules:
1.",5.1 Supervision,[0],[0]
"If we detect an explicit math pattern in the neighborhood of num1 or num2, we assign concept ko to be Explicit Math.
2.",5.1 Supervision,[0],[0]
"If o is multiplication or division, and one of num1 or num2 has a rate component, we assign ko to be Dimensional Analysis.
3.",5.1 Supervision,[0],[0]
"If o is addition or subtraction, we check if the dependent verb of both numbers are identical.",5.1 Supervision,[0],[0]
"If they are, we assign ko to be Part-Whole relationship, otherwise, we assign it to be Transfer.",5.1 Supervision,[0],[0]
"We extract the dependent verb using the Stanford dependency parser (Chen and Manning, 2014).
",5.1 Supervision,[0],[0]
The annotations obtained via these rules are of course not perfect.,5.1 Supervision,[0],[0]
"We could not detect certain uncommon rate patterns like “dividing the cost 4 ways”, and “I read same number of books 4 days running”.",5.1 Supervision,[0],[0]
"There were part-whole relationships exhibited with complementary verbs, as in “I won 4 games, and lost 3.”.",5.1 Supervision,[0],[0]
"Both these cases lead to noisy math concept annotations.
",5.1 Supervision,[0],[0]
"However, we tested a small sample of these annotations, and found less than 5% of them to be wrong.",5.1 Supervision,[0],[0]
"As a result, we assume these annotations to be correct in our problem formulation.",5.1 Supervision,[0],[0]
"We use dependency parse labels and a small set of rules to extract subject, indirect object, dependent verb, unit and rate component of each number
mentioned in the problem.",5.2 Features,[0],[0]
Details of these extractions can be found in the released codebase.,5.2 Features,[0],[0]
"Using these extractions, we define two feature functions φk(x, ko) and φr(x, ro), where x is the input word problem, and ko and ro are the concept and the declarative rule for operation o respectively.",5.2 Features,[0],[0]
"φr(x, r o) constitutes the following features:
1.",5.2 Features,[0],[0]
"If ro contains Coref(·) function, we add features related to similarity of the arguments of Coref(·) (jaccard similarity score and presence of pronoun in one of the arguments).
2.",5.2 Features,[0],[0]
"For part-whole relationships, we add indicators for a list of words like “remaining”, “rest”, “either”, “overall”, “total”, conjoined with the part-whole function in ro (Hyponymy, Hypernymy, Sibling).
3.",5.2 Features,[0],[0]
"Unigrams from the neighborhood of numbers being combined.
",5.2 Features,[0],[0]
"Finally, φk(x, ko) generates the following features:
1.",5.2 Features,[0],[0]
"If ko is related to dimensional analysis, we add features indicating the presence of a rate component in the combining numbers.
2.",5.2 Features,[0],[0]
"If ko is part-whole, we add features indicating whether the verbs of combining numbers are identical.
",5.2 Features,[0],[0]
"Note that these features capture several interpretable functions like coreference, hyponymy, etc.
",5.2 Features,[0],[0]
"We do not learn three components of our system – verb classification for transfer knowledge, categorization of explicit math terms, and irrelevant number detection.",5.2 Features,[0],[0]
"For verb classification, we use a seed list of around 10 verbs for each category.",5.2 Features,[0],[0]
"Given a new verb v, we choose the most similar verb v′ from the seed lists according to Glove vector (Pennington et al., 2014) based similarity .",5.2 Features,[0],[0]
We assign v the category of v′.,5.2 Features,[0],[0]
"This can be replaced by a learned component (Hosseini et al., 2014).",5.2 Features,[0],[0]
However we found seed list based categorization to work well in most cases.,5.2 Features,[0],[0]
"For explicit math, we check for a small list of patterns to detect and categorize math terms.",5.2 Features,[0],[0]
"Note that for both the cases above, we still have to learn Coref(·) function to determine the final operation.",5.2 Features,[0],[0]
"Finally, to detect irrelevant numbers (numbers which
are not used in the solution), we use a set of rules based on the units of numbers.",5.2 Features,[0],[0]
"Again, this can be replaced by a learned model (Roy and Roth, 2015).",5.2 Features,[0],[0]
"We first evaluate our approach on the existing datasets of AllArith, AllArithLex, and AllArithTmpl (Roy and Roth, 2017).",6.1 Results on Existing Dataset,[0],[0]
"AllArithLex and AllArithTmpl are subsets of the AllArith dataset, created to test the robustness to new vocabulary, and new equation forms respectively.",6.1 Results on Existing Dataset,[0],[0]
We compare to the top performing systems for arithmetic word problems.,6.1 Results on Existing Dataset,[0],[0]
"They are as follows:
1.",6.1 Results on Existing Dataset,[0],[0]
TEMPLATE :,6.1 Results on Existing Dataset,[0],[0]
"Template based algebra word problem solver of (Kushman et al., 2014).
",6.1 Results on Existing Dataset,[0],[0]
2.,6.1 Results on Existing Dataset,[0],[0]
"LCA++ : System of (Roy and Roth, 2015) based on lowest common ancestors of math expression trees.
3.",6.1 Results on Existing Dataset,[0],[0]
UNITDEP:,6.1 Results on Existing Dataset,[0],[0]
"Unit dependency graph based solver of (Roy and Roth, 2017).
",6.1 Results on Existing Dataset,[0],[0]
We refer to our approach as KNOWLEDGE.,6.1 Results on Existing Dataset,[0],[0]
"For all solvers, we use the system released by the respective authors.",6.1 Results on Existing Dataset,[0],[0]
"The system of TEMPLATE expects an equation as the answer, whereas our dataset contains only math expressions.",6.1 Results on Existing Dataset,[0],[0]
"We converted expressions to equations by introducing a single variable, and assigning the math expression to it.",6.1 Results on Existing Dataset,[0],[0]
"For example, an expression “(2 + 3)” gets converted to “X = (2 + 3)”.
",6.1 Results on Existing Dataset,[0],[0]
The first few columns of Table 3 shows the performance of the systems on the aforementioned datasets1.,6.1 Results on Existing Dataset,[0],[0]
The performance of KNOWLEDGE is on par or lower than some of the existing systems.,6.1 Results on Existing Dataset,[0],[0]
"We analyzed the systems, and found most of them to be not robust to perturbations of the problem text; Table 4 shows a few examples.",6.1 Results on Existing Dataset,[0],[0]
"We further analyzed the datasets, and identified several biases in the problems (in both train and test).",6.1 Results on Existing Dataset,[0],[0]
Systems which remember these biases get an undue advantage in evaluation.,6.1 Results on Existing Dataset,[0],[0]
"For example, the verb “give” only appears with subtraction, and hence the models are
1Results on the AllArith datasets are slightly different from (Roy and Roth, 2017), since we fixed several ungrammatical sentences in the dataset
learning an erroneous correlation of “give” with subtraction.",6.1 Results on Existing Dataset,[0],[0]
"Since the test also exhibit the same bias, these systems get all the “give”-related questions correct.",6.1 Results on Existing Dataset,[0],[0]
"However, they fail to solve the problem in Table 4, where “give” results in addition.",6.1 Results on Existing Dataset,[0],[0]
"We also tested KNOWLEDGE on the addition subtraction problems dataset released by (Hosseini et al., 2014).",6.1 Results on Existing Dataset,[0],[0]
"It achieved a cross validation accuracy of 77.19%, which is competitive with the state of the art accuracy of 78% achieved with the same level of supervision.",6.1 Results on Existing Dataset,[0],[0]
"The system of (Mitra and Baral, 2016) achieved 86.07% accuracy on this dataset, but requires rich annotations for formulas and alignment of numbers to formulas.",6.1 Results on Existing Dataset,[0],[0]
"In order to remove the aforementioned biases from the dataset, we augment it with new word problems collected via a crowdsourcing platform.",6.2 New Dataset Creation,[0],[0]
"These new word problems are created by perturbing the original problems minimally, such that the answer is different from the original problem.",6.2 New Dataset Creation,[0],[0]
"For each word problem p with an answer expression a in our original dataset AllArith, we replace one operation in a to create a new math expression a′.",6.2 New Dataset Creation,[0],[0]
"We ask annotators to modify problem p minimally, such that a′ is now the solution to the modified word problem.
",6.2 New Dataset Creation,[0],[0]
"We create a′ from a either by replacing an addition with subtraction or vice versa, or by replacing multiplication with division or vice versa.",6.2 New Dataset Creation,[0],[0]
"We do not replace addition and subtraction with multiplication or division, since there might not be an easy perturbation that supports this conversion.",6.2 New Dataset Creation,[0],[0]
We only allowed perturbed expressions which evaluate to values greater than 1.,6.2 New Dataset Creation,[0],[0]
"For example, we generate the expression “(3+2)” from “(3-2)”, we generated expressions “(10+2)/4” and “(10-2)*4” for the expression “(10-2)/4”.",6.2 New Dataset Creation,[0],[0]
"We generate all possible perturbed expressions for a given answer expression, and ask for problem text modification for each one of them.
",6.2 New Dataset Creation,[0],[0]
We show the annotators the original problem text p paired with a perturbed answer a′.,6.2 New Dataset Creation,[0],[0]
"The instructions advised them to copy over the given problem text, and modify it as little as possible so that the given math expression is now the solution to this modified problem.",6.2 New Dataset Creation,[0],[0]
They were also instructed to not add or delete the numbers mentioned in the problem.,6.2 New Dataset Creation,[0],[0]
"If the original problem mentions two “3”s and one “2”, the
modified problem should also contain two “3”s and one “2”.
",6.2 New Dataset Creation,[0],[0]
"We manually pruned problems which did not yield the desired solution a′, or were too different from the input problem p.",6.2 New Dataset Creation,[0],[0]
"This procedure gave us a set of 661 new word problems, which we refer to as Perturb.",6.2 New Dataset Creation,[0],[0]
"Finally we augment AllArith with the problems of Perturb, and call this new dataset Aggregate.",6.2 New Dataset Creation,[0],[0]
"Aggregate has a total of 1492 problems.
",6.2 New Dataset Creation,[0],[0]
The addition of the Perturb problems ensures that the dataset now has problems with similar lexical items generating different answers.,6.2 New Dataset Creation,[0],[0]
This minimizes the bias that we discussed in subsection 6.1.,6.2 New Dataset Creation,[0],[0]
"To quantify this, consider the probability distribution over operations for a quantity q, given that word w is present in the neighborhood of q. For an unbiased dataset, you will expect the entropy of this distribution to be high, since the presence of a single word in a number neighborhood will seldom be completely informative for the operation.",6.2 New Dataset Creation,[0],[0]
We compute the average of this entropy value over all numbers and neighborhood words in our dataset.,6.2 New Dataset Creation,[0],[0]
"AllArith and Perturb have an average entropy of 0.34 and 0.32 respectively, whereas Aggregate’s average entropy is 0.54, indicating that, indeed, the complete data set is significantly less biased.",6.2 New Dataset Creation,[0],[0]
"First, we evaluate the ability of systems to generalize from biased datasets.",6.3 Generalization from Biased Dataset,[0],[0]
"We train all systems on AllArith, and test them on Perturb (which was created by perturbing AllArith problems).",6.3 Generalization from Biased Dataset,[0],[0]
The last column of Table 3 shows the performance of systems in this setting.,6.3 Generalization from Biased Dataset,[0],[0]
KNOWLEDGE outperforms all other systems in this setting with around 19% absolute improvement over UNITDEP.,6.3 Generalization from Biased Dataset,[0],[0]
"This shows that declarative knowledge allows the system to learn the correct abstractions, even from biased datasets.",6.3 Generalization from Biased Dataset,[0],[0]
"Finally, we evaluate the systems on the Aggregate dataset.",6.4 Results on the New Dataset,[0],[0]
"Following previous work (Roy and Roth, 2017), we compute two subsets of Aggregate comprising 756 problems each, using the MAWPS (Koncel-Kedziorski et al., 2016) system.",6.4 Results on the New Dataset,[0],[0]
"The first, called AggregateLex, is one with low lexical repetitions, and the second called AggregateTmpl is one with low repetitions of equation forms.",6.4 Results on the New Dataset,[0],[0]
"We
also evaluate on these two subsets on a 5-fold crossvaliation.",6.4 Results on the New Dataset,[0],[0]
Columns 4-6 of Table 3 show the performance of systems on this setting.,6.4 Results on the New Dataset,[0],[0]
"KNOWLEDGE significantly outperforms other systems on Aggregate and AggregateLex, and is similar to UNITDEP on AggregateTmpl.",6.4 Results on the New Dataset,[0],[0]
"There is a 9% absolute improvement on AggregateLex, showing that KNOWLEDGE is significantly more robust to low lexical overlap between train and test.",6.4 Results on the New Dataset,[0],[0]
"The last column of Table 4 also shows that the other systems do not learn the right abstraction, even when trained on Aggregate.",6.4 Results on the New Dataset,[0],[0]
Coverage of the Declarative Rules We chose math concepts and declarative rules based on their prevalance in arithmetic word problems.,6.5 Analysis,[0],[0]
We found that the four concepts introduced in this paper cover almost all the problems in our dataset; only missing 4 problems involving application of area formulas.,6.5 Analysis,[0],[0]
"We also checked earlier arithmetic problem datasets from the works of (Hosseini et al., 2014; Roy and Roth, 2015), and found that the math concepts and declarative rules introduced in this paper cover all their problems.
",6.5 Analysis,[0],[0]
A major challenge in applying these concepts and rules to algebra word problems is the use of variables in constructing equations.,6.5 Analysis,[0],[0]
"Variables are often implicitly described, and it is difficult to extract units, dependent verbs, associated subjects and objects for the variables.",6.5 Analysis,[0],[0]
"However, we need these extractions in order to apply our declarative rules to combine variables.",6.5 Analysis,[0],[0]
"There has been some work to extract meaning of variables (Roy et al., 2016) in algebra word problems; an extension of this can possibly support the application of rules in algebra word problems.",6.5 Analysis,[0],[0]
"We leave this exploration to future work.
",6.5 Analysis,[0],[0]
"Higher standard word problems often require application of math formulas like ones related to area, interest, probability, etc.",6.5 Analysis,[0],[0]
"Extending our approach to handle such problems will involve encoding math formulas in terms of concepts and rules, as well as adding concept specific features to the learned predictors.",6.5 Analysis,[0],[0]
"The declarative rules under the Explicit Math category currently handles simple cases, this set needs to be augmented to handle complex number word problems found in algebra datasets.
",6.5 Analysis,[0],[0]
"Gains achieved by Declarative Rules Table 5 shows examples of problems which KNOWLEDGE
gets right, but UNITDEP does not.",6.5 Analysis,[0],[0]
The gains can be attributed to the injection of declarative knowledge.,6.5 Analysis,[0],[0]
Earlier systems like UNITDEP try to learn the reasoning required for these problems from the data alone.,6.5 Analysis,[0],[0]
"This is often difficult in the presence of limited data, and noisy output from NLP tools.",6.5 Analysis,[0],[0]
"In contrast, we learn probabilistic models for interpretable functions like coreference, hyponymy, etc., and then use declarative knowledge involving these functions to perform reasoning.",6.5 Analysis,[0],[0]
"This considerably reduces the complexity of the target function to be learnt, and hence we end up with a more robust model.",6.5 Analysis,[0],[0]
Effect of Beam Size We used a beam size of 1000 in all our experiments.,6.5 Analysis,[0],[0]
"However, we found that varying the beam size does not effect the performance significantly.",6.5 Analysis,[0],[0]
Even lowering the beam size to 100 reduced performance by only 1%.,6.5 Analysis,[0],[0]
Weakness of Approach A weakness of our method is the requirement to have all relevant declarative knowledge during training.,6.5 Analysis,[0],[0]
Many of the component functions (like coreference) are learnt through latent alignments with no explicit annotations.,6.5 Analysis,[0],[0]
"If too many problems are not explained by the knowledge, the model will learn noisy alignments for the component functions.
",6.5 Analysis,[0],[0]
Table 6 shows the major categories of errors with examples.,6.5 Analysis,[0],[0]
26% of the errors are due to extraneous number detection.,6.5 Analysis,[0],[0]
"We use a set of rules based on units of numbers, to detect such irrelevant numbers.",6.5 Analysis,[0],[0]
"As a result, we fail to detect numbers which are irrelevant due to other factors, like associated entities, or associated verb.",6.5 Analysis,[0],[0]
"We can potentially expand our rule based system to detect those, or replace it by a learned module like (Roy and Roth, 2015).",6.5 Analysis,[0],[0]
"Another major source of errors is parsing of rate components,
that is, understanding “earns $46 cleaning a home” should be normalized to “46$ per home”.",6.5 Analysis,[0],[0]
"Although we learn a model for coreference function, we make several mistakes related to coreference.",6.5 Analysis,[0],[0]
"For the example in Table 6, we fail to detect the coreference between “team member” and “people”.",6.5 Analysis,[0],[0]
"In this paper, we introduce a framework for incorporating declarative knowledge in word problem solving.",7 Conclusion,[0],[0]
"Our knowledge based approach outperforms all other systems, and also learns better abstractions from biased datasets.",7 Conclusion,[0],[0]
"Given that the variability in text is much larger than the number of declarative rules that governs Math word problems, we believe that this is a good way to introduce Math knowledge to a natural language understanding system.",7 Conclusion,[0],[0]
"Consequently, future work will involve extending our approach to handle a wider range of word problems, possibly by supporting better grounding of implicit variables and including a larger number of math concepts and declarative rules.",7 Conclusion,[0],[0]
"An orthogonal exploration direction is to apply these techniques to generate summaries of financial or sports news, or generate statistics of war or gun violence deaths from news corpora.",7 Conclusion,[0],[0]
"A straightforward approach can be to augment news documents with a question asking for the required information, and treating this augmented news document as a math word problem.
",7 Conclusion,[0],[0]
Code and dataset are available at https:// github.com/CogComp/arithmetic.,7 Conclusion,[0],[0]
"This work is funded by DARPA under agreement number FA8750-13-2-0008, and a grant from the Allen Institute for Artificial Intelligence (allenai.org).",Acknowledgments,[0],[0]
"Math word problems form a natural abstraction to a range of quantitative reasoning problems, such as understanding financial news, sports results, and casualties of war.",abstractText,[0],[0]
"Solving such problems requires the understanding of several mathematical concepts such as dimensional analysis, subset relationships, etc.",abstractText,[0],[0]
"In this paper, we develop declarative rules which govern the translation of natural language description of these concepts to math expressions.",abstractText,[0],[0]
We then present a framework for incorporating such declarative knowledge into word problem solving.,abstractText,[0],[0]
"Our method learns to map arithmetic word problem text to math expressions, by learning to select the relevant declarative knowledge for each operation of the solution expression.",abstractText,[0],[0]
"This provides a way to handle multiple concepts in the same problem while, at the same time, support interpretability of the answer expression.",abstractText,[0],[0]
"Our method models the mapping to declarative knowledge as a latent variable, thus removing the need for expensive annotations.",abstractText,[0],[0]
"Experimental evaluation suggests that our domain knowledge based solver outperforms all other systems, and that it generalizes better in the realistic case where the training data it is exposed to is biased in a different way than the test data.",abstractText,[0],[0]
Mapping to Declarative Knowledge for Word Problem Solving,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2824–2829 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
2824",text,[0],[0]
"Identifying entities in text is a vital component in language understanding, facilitating knowledge base construction (Riedel et al., 2013), question answering (Bordes et al., 2015), and search.",1 Introduction,[0],[0]
Identifying these entities are particularly important in biomedical data.,1 Introduction,[1.0],['Identifying these entities are particularly important in biomedical data.']
"While large scale Named Entity Recognition (NER) datasets exist in news and web data (Tjong Kim Sang and De Meulder, 2003; Hovy et al., 2006), biomedical NER datasets are typically smaller and contain only one or two types per dataset.",1 Introduction,[1.0],"['While large scale Named Entity Recognition (NER) datasets exist in news and web data (Tjong Kim Sang and De Meulder, 2003; Hovy et al., 2006), biomedical NER datasets are typically smaller and contain only one or two types per dataset.']"
"Ultimately, we would like to identify all entity types present across the union of the label sets during inference while leveraging all the available annotations to train our models.
",1 Introduction,[0],[0]
"While one may train a single model across the union of all the datasets available, this training
procedure assumes that all labels (from the union of the tag set) are correctly annotated in every training instance – which is incorrect.",1 Introduction,[0],[0]
"On the other hand, training separate models on each available dataset does not take advantage of shared statistical strength from the multiple sources of information, and requires resolution of the conflicting predictions output by the different models.
",1 Introduction,[0],[0]
"To remedy these problems, we propose methods to train a joint model across the multiple tag-sets of the different datasets, sharing statistical strength by using a single feature encoder across datasets while respecting the incompleteness of the labels during training.",1 Introduction,[0],[0]
"Thus, our single model can take full advantage of all the available annotated resources and predict the full set of relevant types given a piece of text.
",1 Introduction,[0],[0]
"In experiments on three datasets, we show our methods outperform models that do not consider the incomplete annotations.",1 Introduction,[0],[0]
We also show that jointly training on multiple datasets improves performance further and achieves state-of-the-art performance on the Biocreative V CDR dataset.,1 Introduction,[0],[0]
"Our models build on state-of-the-art NER systems (Lample et al., 2016) based on bi-directional Long Short Term Memory (BiLSTM) feature extractors fed into a conditional random field (CRF).
",2 Model,[1.000000041489316],"['Our models build on state-of-the-art NER systems (Lample et al., 2016) based on bi-directional Long Short Term Memory (BiLSTM) feature extractors fed into a conditional random field (CRF).']"
"The data consists of input sequence of tokens x = {x1, . . .",2 Model,[0],[0]
", xT } where each token is a sequence of characters xt",2 Model,[0],[0]
"= {c1, . . .",2 Model,[0],[0]
", cKt}.",2 Model,[0],[0]
"The output consists of labels for each token in the sequence y = {y1, . . .",2 Model,[0.986070007338169],"['The output consists of labels for each token in the sequence y = {y1, .']"
", yT }.",2 Model,[0],[0]
"Labeling is done using the BILOU tagging scheme, following previous observations that it outperforms the BIO tagging scheme (Ratinov and Roth, 2009).",2 Model,[0],[0]
We have D such datasets of input tokens and output labels.,2 Model,[0],[0]
Our model takes a sequence of tokens from a single abstract as input.,2.1 Feature Encoder BiLSTM,[0],[0]
"Tokens are generated using byte-pair encodings (BPE) (Gage, 1994; Sennrich et al., 2016), which have recently been shown to be effective for tokenization of biological texts by addressing the issue of rare or out-of-vocabulary tokens (Verga et al., 2018).",2.1 Feature Encoder BiLSTM,[0],[0]
BPE starts from white space tokenization and breaks down the tokens further.,2.1 Feature Encoder BiLSTM,[0],[0]
"Because all of the evaluations are on the span level rather than the token level, the use of BPE does not impact any numerical performance.",2.1 Feature Encoder BiLSTM,[0],[0]
"Each token t produced from BPE is mapped to a d dimensional word embedding w.
Character level features have been shown to improve NER accuracy (Lafferty et al., 2001; Lample et al., 2016; Passos et al., 2014).",2.1 Feature Encoder BiLSTM,[0],[0]
"We encode characters in a word using another BiLSTM, similar to Lample et al. (2016), and obtain a character based embedding for every word by concatenating the last hidden state of the forward and backward character LSTM.",2.1 Feature Encoder BiLSTM,[0],[0]
We concatenate this character based embedding with the d-dimensional word embedding and input it to the word-level BiLSTM.,2.1 Feature Encoder BiLSTM,[0],[0]
"This feature representation is then projected to the label dimension L using a linear layer, giving a matrix of scores [fil] where fil is the score for predicting label l ∈",2.1 Feature Encoder BiLSTM,[0],[0]
[L] for token,2.1 Feature Encoder BiLSTM,[0],[0]
i ∈,2.1 Feature Encoder BiLSTM,[0],[0]
[T ].,2.1 Feature Encoder BiLSTM,[0],[0]
"BiLSTM-CRF models used for named entity recognition add a CRF layer (Lafferty et al., 2001)
on the output representations from the BiLSTM model described.",2.2 Conditional Random Field (CRF),[0],[0]
The CRF layer scores all possible labelings to give a probability of the correct label sequence under the model.,2.2 Conditional Random Field (CRF),[0],[0]
"Given an input sequence of tokens x = {x1, . . .",2.2 Conditional Random Field (CRF),[0],[0]
", xT }",2.2 Conditional Random Field (CRF),[0],[0]
"and the output matrix of scores [fil], the score for an output labeling y = {y1, . . .",2.2 Conditional Random Field (CRF),[0],[0]
", yT } is given by: s(x,y) = ∑T t=1",2.2 Conditional Random Field (CRF),[0],[0]
"( Ayt−1,yt + ft,yt ) , where A is an L × L matrix of parameters for transitioning between output labels.",2.2 Conditional Random Field (CRF),[0],[0]
"The CRF then generates the likelihood for the correct labeling by normalizing this score over all possible output labelings:
logP (y|x) = s(x,y)− logsumexp y′
s(x,y′) (1)
",2.2 Conditional Random Field (CRF),[0],[0]
"The log normalization term here is: logsumexp
y′ s(x,y′) = log
∑ y′ exp s(x,y ′)
where the sum goes over all possible labelings y′ of the sequence and is computed efficiently using dynamic programming (Lafferty et al., 2001).",2.2 Conditional Random Field (CRF),[0],[0]
One way to tag multiple datasets is to concatenate all the datasets with all the output labels and train a single BiLSTM-CRF model.,2.3 Tagging Multiple Datasets,[0],[0]
"However, this assumes that each text snippet is completely annotated across the label sets, which is not true.",2.3 Tagging Multiple Datasets,[0],[0]
We now discuss two models which do not make this assumption.,2.3 Tagging Multiple Datasets,[0],[0]
We first propose one simple method to get around the assumption of complete annotation – train separate CRFs for the label set of each dataset.,2.3.1 Multiple CRFs,[0],[0]
"In particular, to share statistical strengths on the input tokens, we share the BiLSTM feature encoder across the datasets but use separate CRF layers for each of the datasets.",2.3.1 Multiple CRFs,[0],[0]
"This is a multi-task learning model (Caruana, 1998) and is expected to perform better than the naive model as it no longer makes the strict assumption of complete annotation (by using separate CRFs), and shares statistical strength across datasets.",2.3.1 Multiple CRFs,[0],[0]
"However, given a new abstract to tag, this model will generate multiple possible labelings from the different CRFs.",2.3.1 Multiple CRFs,[0],[0]
"Moreover, the labelings output by the different CRFs may be inconsistent, and how to combine these multiple labelings is not obvious.",2.3.1 Multiple CRFs,[0],[0]
We propose and evaluate a simple heuristic procedure for merging the outputs of the different CRF predictions.,2.3.1 Multiple CRFs,[0],[0]
"Whenever the different CRF predictions disagree on a span
of tokens, we choose the prediction from the CRF that has higher marginal probability of predicting that span of tokens (Alg. 1 in supplementary).",2.3.1 Multiple CRFs,[0],[0]
We also propose an alternative principled approach that does not require a heuristic merging process.,2.3.2 EM Marginal CRF,[0],[0]
"In order to label D datasets with some disjoint labels, we only consider the probability of the “observed labels” and allow the “unobserved” tokens to be free.",2.3.2 EM Marginal CRF,[0],[0]
"Thus, when tagging dataset",2.3.2 EM Marginal CRF,[0],[0]
i ∈,2.3.2 EM Marginal CRF,[0],[0]
"[D], we treat the non-entity tokens as potentially taking any entity type label from any of the other datasets as well as the ‘O’ label.
",2.3.2 EM Marginal CRF,[0.9897646727883143],"['Thus, when tagging dataset i ∈ [D], we treat the non-entity tokens as potentially taking any entity type label from any of the other datasets as well as the ‘O’ label.']"
For a particular input x of length T from a dataset i ∈,2.3.2 EM Marginal CRF,[0],[0]
"[D] with label set Si, let y be the gold output label.",2.3.2 EM Marginal CRF,[0],[0]
Let E ⊂,2.3.2 EM Marginal CRF,[0],[0]
[T ] be the index of tokens with any entity type label in Si and N ⊂,2.3.2 EM Marginal CRF,[0.9567442821539788],"['Let E ⊂ [T ] be the index of tokens with any entity type label in Si and N ⊂ [T ] be the index of tokens with ‘O’ label, and let yE be the output sequence corresponding to indices in E, and similarly yN be the output sequence for indices in N .']"
"[T ] be the index of tokens with ‘O’ label, and let yE be the output sequence corresponding to indices in E, and similarly yN be the output sequence for indices in N .",2.3.2 EM Marginal CRF,[0],[0]
"Then, from (1), we get the likelihood Pi(yE ∪ yN|x), and a naive CRF trained on the concatenation of all the data will maximize this probability.",2.3.2 EM Marginal CRF,[0],[0]
"However, since we cannot make the complete annotation assumption, we should instead maximize only the marginal probability of the observed entities on the dataset",2.3.2 EM Marginal CRF,[0],[0]
"i, Pi(yE|x), allowing yN to take any values from the labels of the other datasets: ∪Dj 6=iSj .",2.3.2 EM Marginal CRF,[0],[0]
"Thus,
logPi(yE|x) = log ∑
yN∈∪j 6=iSj
Pi(yE,yN|x)
logPi(yE|x) = logsumexp yN∈∪j 6=iSj s(x,yE ,yN )",2.3.2 EM Marginal CRF,[0],[0]
"− logZ
where logZ is the log normalization term which is the same as in (1).",2.3.2 EM Marginal CRF,[0],[0]
"Note that since the normalization term is the same here as for a standard CRF, we can still use the same dynamic programming algorithm as for a regular CRF to compute this logZ.",2.3.2 EM Marginal CRF,[0],[0]
"Now, in order to compute the first term, we note that it is similar to the computation required to compute logZ – whereas logZ is obtained by summing over all possible output sequences, this term is obtained by summing over all possible output sequences which have indices in E fixed to the correct label and indices in N taking values from ∪j 6=iSj .",2.3.2 EM Marginal CRF,[0],[0]
"Thus, this can be computed using the same dynamic programming algorithm (Tsuboi et al., 2008), and the implementation of training this model is compatible with modern automatic differentiation libraries.",2.3.2 EM Marginal CRF,[0],[0]
"We perform experiments on two benchmark Biocreative datasets as well as the recently introduced MedMentions data (Murty et al., 2018).",3 Experimental Results,[1.0],"['We perform experiments on two benchmark Biocreative datasets as well as the recently introduced MedMentions data (Murty et al., 2018).']"
Our experiments consider three types of models.,3 Experimental Results,[1.0],['Our experiments consider three types of models.']
"The single CRF model naively concatenates all training datasets together and assumes complete labeling, multi CRF has a single Bi-LSTM feature encoder with a separate CRF for each dataset (Section 2.3.1), and EM CRF has a single feature encoder and a single CRF trained with EM marginalization (Section 2.3.2).",3 Experimental Results,[0],[0]
For full dataset statistics and specific implementation details see supplementary material.,3 Experimental Results,[0],[0]
"Biocreative V Chemical Disease Relation (CDR): consists of 1,500 titles and abstracts from PubMed, human annotated with chemical and disease mentions (Li et al., 2016), and has been used in previous NER evluations (Fries et al., 2017; Leaman and Lu, 2016).",3.1 Biocreative V / VI,[0],[0]
"Biocreative VI ChemProt (CP): consists of 2,432 PubMed titles and abstracts, and contains human annotated mentions of both chemicals and proteins (Krallinger et al., 2017)1.
",3.1 Biocreative V / VI,[0],[0]
Our results are shown in Table 1.,3.1 Biocreative V / VI,[0],[0]
"The top portion of the table shows models trained on single datasets, and the bottom portion shows models trained on both CDR and CP.",3.1 Biocreative V / VI,[1.0],"['The top portion of the table shows models trained on single datasets, and the bottom portion shows models trained on both CDR and CP.']"
"Comparing the top and bottom portions of the table, we can see that models trained on both CP and CDR outperform training on either in isolation.",3.1 Biocreative V / VI,[0],[0]
"Further, we see in the bottom section that our EM CRF outperforms the single CRF model and is generally better than the multi CRF model.",3.1 Biocreative V / VI,[0],[0]
"Weakly Labeled data The addition of weakly labeled data has been used recently to improve the performance of relation extraction systems (Peng et al., 2016; Verga et al., 2018).",3.2 Adding Additional Data,[0],[0]
"In these approaches, titles and abstracts from PubMed are annotated using Pubtator, a state of the art entity tagging and linking/normalization system (Wei et al., 2013).",3.2 Adding Additional Data,[0],[0]
"We use the same weakly labeled data from Verga et al. (2018).
Results when adding in the additional weakly labeled data is shown in Table 2.",3.2 Adding Additional Data,[0],[0]
"Our models
1To the best of our knowledge, there is no benchmark result for this dataset
improve further, outperforming the state-of-the-art TaggerOne model (Leaman and Lu, 2016).",3.2 Adding Additional Data,[0],[0]
"MedMentions (Murty et al., 2018) is a recently introduced large dataset of PubMed abstracts containing entity linked mentions of many different semantic types.",3.3 MedMentions,[0],[0]
We used this data to create an artificially extreme example where two training sets contain 9 and 10 entity types each.,3.3 MedMentions,[1.0],['We used this data to create an artificially extreme example where two training sets contain 9 and 10 entity types each.']
"The two type sets are fully disjoint (further details in supplementary).
",3.3 MedMentions,[0.9999999737529618],['The two type sets are fully disjoint (further details in supplementary).']
"In Table 3, we see that the single CRF model performs very poorly in this extreme setting due to the large amount of missing annotations.",3.3 MedMentions,[0],[0]
"The multi CRF and EM CRF both perform well and come close to the performance of a single CRF trained on the full data, which is approximately twice as much annotated data.",3.3 MedMentions,[0],[0]
"Until recently, feature engineered machine learning models were the highest performing approaches to NER (Ratinov and Roth, 2009; Passos et al., 2014).",4 Related Work,[0],[0]
"More recently, neural network based approaches have become state-of-the-art (Lample et al., 2016; Strubell et al., 2017; Peters et al., 2017).",4 Related Work,[0],[0]
"In BioNLP, many highest performing systems still use engineered features fed into a CRF (Wei et al., 2015; Leaman et al., 2015; Leaman and Lu, 2016).",4 Related Work,[0],[0]
"In addition to the two datasets we explored in this work, there are several other popular bio NER datasets for chemicals (Krallinger et al., 2015), species (Wang et al., 2010), diseases
(Doğan et al., 2014), and genes (Tanabe et al., 2005).
",4 Related Work,[0],[0]
"In concurrent work, Wang et al. (2018) train a model very similar to our multi-CRF model on multiple biological NER datasets with non-fully overlapping labels.",4 Related Work,[0],[0]
"Additionally, they experiment with different ways of sharing the parameters of the BiLSTM encoder.",4 Related Work,[0],[0]
"We believe this work is complementary to ours, and in many ways deals with a simpler subset of the tasks we address.",4 Related Work,[0],[0]
"Wang et al. assumes complete labeling in each of their datasets, and does not attempt to merge the final results of the multiple CRFS.",4 Related Work,[0],[0]
"On the other hand, we focus on the problem of cohesively labeling a dataset with the joint set of the different label sets, either directly through the EM model or by the merging process of the multi-CRF model.
",4 Related Work,[0],[0]
"Our method of training via marginal likelihood is the same as Tsuboi et al. (2008), who trained CRF models for Japanese word segmentation and POS tagging where only partial annotations of sentences are available.",4 Related Work,[0],[0]
"In comparison, we use the marginal likelihood training in conjunction with state-of-the art deep learning models for NER and use it to tag across multiple disjoint labels sets.",4 Related Work,[0],[0]
We’ve introduced a method for training NER models on multiple datasets containing disjoint label sets.,5 Conclusions and Future Work,[1.0],['We’ve introduced a method for training NER models on multiple datasets containing disjoint label sets.']
"We show experimentally that this joint training improves performance and that our EM CRF methods outperform models using a single CRF.
",5 Conclusions and Future Work,[0],[0]
One interesting problem that our models do not account for is the existence of overlapping and non-continuous entity spans.,5 Conclusions and Future Work,[1.0],['One interesting problem that our models do not account for is the existence of overlapping and non-continuous entity spans.']
"Particularly when annotating using disjoint label sets, a token could belong to multiple entity spans from different label sets.",5 Conclusions and Future Work,[1.0],"['Particularly when annotating using disjoint label sets, a token could belong to multiple entity spans from different label sets.']"
We are interested in investigating this problem in future work.,5 Conclusions and Future Work,[0],[0]
"This work was supported in part by the Center for Intelligent Information Retrieval and the Center for Data Science, in part by the Chan Zuckerberg Initiative under the project Scientific Knowledge Base Construction., and in part by the National Science Foundation under Grant No. IIS1514053.",Acknowledgments,[0],[0]
"Any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect those of the sponsor.",Acknowledgments,[0],[0]
Extracting typed entity mentions from text is a fundamental component to language understanding and reasoning.,abstractText,[0],[0]
"While there exist substantial labeled text datasets for multiple subsets of biomedical entity types—such as genes and proteins, or chemicals and diseases— it is rare to find large labeled datasets containing labels for all desired entity types together.",abstractText,[0],[0]
This paper presents a method for training a single CRF extractor from multiple datasets with disjoint or partially overlapping sets of entity types.,abstractText,[0],[0]
"Our approach employs marginal likelihood training to insist on labels that are present in the data, while filling in “missing labels”.",abstractText,[0],[0]
This allows us to leverage all the available data within a single model.,abstractText,[0],[0]
"In experimental results on the Biocreative V CDR (chemicals/diseases), Biocreative VI ChemProt (chemicals/proteins) and MedMentions (19 entity types) datasets, we show that joint training on multiple datasets improves NER F1 over training in isolation, and our methods achieve state-of-the-art results.",abstractText,[0],[0]
Marginal Likelihood Training of BiLSTM-CRF for Biomedical Named Entity Recognition from Disjoint Label Sets,title,[0],[0]

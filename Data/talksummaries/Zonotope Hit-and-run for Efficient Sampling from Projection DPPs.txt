29	29	, n} with kernel K if P [I ⇢ X] = detK I , 8I ⇢ E. (1) Existence of the DPP described by (1) is guaranteed provided K has all its eigenvalues in [0, 1], see e.g., Kulesza & Taskar (2012, Theorem 2.3).
31	59	In particular, for any distinct i, j 2 [n], P [{i, j} ⇢ X] = K ii K ij K ji K jj = P [{i} 2 X]P [{j} 2 X] K2 ij  P [{i} 2 X]P [{j} 2 X] .
32	32	In other words, K ij encodes departure from independence.
35	20	Projection DPPs are also sometimes called elementary DPPs (Kulesza & Taskar, 2012).
36	24	One can show that samples from a projection DPP with kernel matrix K almost surely contain r = Tr(K) points and that general DPPs are mixtures of projection DPPs, see e.g., Kulesza & Taskar (2012, Theorem 2.3).
37	14	Let r < n, and let A be a full-rank r ⇥ n real matrix with columns (a j ) j2[n].
40	14	Because of this analogy, elements of B are called bases of the matroid M [A].
44	24	Lyons (2003) defines a projection DPP as the probability measure on B that assigns to B 2 B a mass proportional to | detB|2, where B , A :B is the square matrix formed by the r columns of A indexed by B.
49	10	A fundamental example of DPP defined by a matroid is the random set of edges obtained from a uniform spanning tree (Lyons, 2003).
51	16	Let now A be the first r rows of the vertex-edge incidence matrix of G. Then B ⇢ [n] is a basis of M [A] if and only if {e i } i2B form a spanning tree of G (Oxley, 2003).
63	14	That is, for each data item i 2 [n], a normalized vector of features i 2 Rr is chosen, a marginal relevance q i is assigned to item i, and a matrix L is defined as L ij = p q i i j p q j .
64	19	(5) In text summarization, for instance, items i, j could be sentences, q i the marginal relevance of sentence i to the user’s query, and i features such as tf-idf frequencies of a choice of words, and one could draw from a k-DPP associated to L through P [X = I] / detL I , see e.g., Kulesza & Taskar (2012, Section 4.2.1).
65	16	Alternately, let A be the matrix with columns ( p q i i ) i2[r], and assume r < n and A is full-rank.
66	44	The latter can be ensured in practice by adding a small i.i.d.
69	10	Thus, if the application requires an output of length p, one can pick r = p, as we do in Section A. Alternatively, if we want an output of size approximately p, we can pick r p and independently thin the resulting sample, which preserves the DPP structure (Lavancier et al., 2015).
92	48	If the uniform distribution on B is not the DPP we want to sample from, 1 we can add an accept-reject step after each move to make the desired DPP the limiting distribution of the walk.
93	67	Adding such an acceptance step and a probability to stay at the current basis, Anari et al. (2016); Li et al. (2016b) give precise polynomial bounds on the mixing time of the resulting Markov chains.
95	37	Note that we use the acceptance ratio of Li et al. (2016b).
107	8	In the latter case, the exchange move in Algorithm 1 will never be accepted and the state space of the corresponding Markov chain is indeed B.
111	11	In short, for a good choice of c 2 Rn, Dyer & Frieze (1994) consider for any x 2 Z(A), the following linear program (LP) noted P x (A, c), min y2Rn c T y s.t.
112	8	(9) Standard LP results (Luenberger & Ye, 2008) yield that the unique optimal solution y ⇤ of P x (A, c) takes the form y ⇤ = A⇠(x) +B x u, (10) with u 2 [0, 1]r and ⇠(x) 2 {0, 1}n such that ⇠(x) i = 0 for i 2 B x .
113	25	In case the choice of B x is ambiguous, Dyer & Frieze (1994) take the smallest in the lexicographic order.
116	11	This allows to write Z(A) as the tiling of all Z(B), B 2 B, with disjoint interiors.
117	27	Note that c is used to fix the tiling of the zonotope, but the map x 7!
127	8	We describe the Markov kernel P (x, z) of the hit-and-run Markov chain for a generic target distribution ⇡ supported on a convex set C. Sample a point y uniformly on the unit sphere centered at x.
130	13	In particular, MetropolisHastings kernel (MH, Robert & Casella 2004) is often used with uniform proposal on D x , which favors large moves across the support C of the target, see Figure 1(b).
132	16	Furthermore, the hit-and-run Markov chain has polynomial mixing time for log concave ⇡ (Lov´asz & Vempala, 2003, Theorem 2.1).
135	21	In fact, zonotopes are tricky convex sets, as even an oracle saying whether a point belongs to the zonotope requires solving LPs (basically, it is Phase I of the simplex algorithm).
136	11	As noted by Lov´asz & Vempala (2003, Section 4.4), hit-and-run with LP is the state-of-the-art for computing the volume of large-scale zonotopes.
140	47	Algorithm 2 unifZonoHitAndRun Input: A Initialization: i 0 x 0 Au with u ⇠ U [0,1] n while Not converged do Draw d ⇠ USr 1 and let Dx i , x i + Rd Draw ex ⇠ UD x i \Z(A) #Solve 2 LPs, see (11) x i+1 ex i i+ 1 end while Algorithm 3 extractBasis Input: A, c, x 2 Z(A) Compute y ⇤ the opt.

0	154	Open relation extraction (open RE) is the task of extracting new facts for a potentially unbounded set of relations from various sources such as knowledge bases or natural language text.
1	58	The task is closely related to targeted information extraction (IE), which aims to populate a knowledge base (KB) with new facts for the KB’s relations, such as wasBornIn(Sepp Herberger, Mannheim).
2	17	Existing methods either reason within the KB itself (Franz et al., 2009; Nickel et al., 2011; Drumond et al., 2012) or leverage large text corpora to learn patterns that are indicative of KB relations (Mintz et al., 2009; Surdeanu et al., 2012; Min et al., 2013).
6	40	Open RE combines the above tasks by predicting new facts for an open set of relations.
8	33	A number of matrix or tensor factorization models have recently been proposed in the context of relation extraction (Nickel et al., 2012; Riedel et al., 2013; Huang et al., 2014; Chang et al., 2014).
11	17	Targeted models are used for within-KB reasoning; they rely on the closed-world assumption and often do not scale with the number of relations.
14	20	Consider for example the sentence “Tom Peloso joined Modest Mouse to record their fifth studio album”.
100	26	To address these points, our model aggregates the context of relevant observations for each fact; this approach allows us to provide comprehensive contextual information for both observed and unobserved facts.
107	22	We capture information such as that the tuple (Caesar, Rome) has only been seen in articles on history or that tuple (Fermi, Rome) is mentioned in both physics and history articles (slightly more often in the former).
108	17	Since context is associated with tuples, facts 2 and 4 on (Fermi, Sapienza) share contextual information.
114	17	Our model associates with training point x ∈ X a score s(x) computed as follows: s(x) = ∑ v∈V xvbv + ∑ v1∈V ∑ v2∈V \{v1} xv1xv2f T v1 fv2 (1) Here the bias terms models the contribution of each individual variable to the final score, whereas the latent feature vectors model the contribution of all pairwise interactions between variables.
124	30	The resulting ranking constitutes the list Tr of predicted facts for relation r. Bayesian personalized ranking.
125	21	The parameters of our model are given by Θ = { bv,fv | v ∈ V }.
129	27	This closed-world approach essentially assumes that all unobserved facts are false, which may not be a suitable assumption for the sparsely observed relations of open RE.
148	40	In more detail, we (conceptually) build a negative sample set X−r for each relation r ∈ R. We include into X−r all facts r(t)—again, along with their context—such that t ∈ T is an observed tuple but r(t) is an unobserved fact.
151	17	Note that we do not actually construct the negative sample sets; see below.
168	19	Using the metadata3 of each New York Times article, we enriched each surface fact by the following contextual information: news desk (e.g., sports desk, foreign desk), descriptors (e.g., finances, elections), online section (e.g., sports, business), section (e.g., a, d), publication year, and bag-of-words of the sentence from which the surface fact has been extracted.
190	21	The basic CORE model uses relations, tuples and entities as variables.
191	35	We additionally consider the CORE+t, CORE+w, CORE+mt, and CORE+mtw models, where the suffix indicates which contextual information has been included.
203	23	Note that our definition of MAP100# differs slightly from Riedel et al. (2013); our metric is more robust because it is based on completely labeled evaluation data.
210	18	Each entry shows the number of true facts in the top-100 predictions and, in parentheses, the MAP100# value.
219	26	The CORE+mtw model performed best overall; it increased the average MAP100# by four points (six points weighted) compared to the best contextunware model.
225	154	One reason for this boost is that related surface relations often share semantically related words (e.g., “professor at” and “scientist at”) and may occur in similar sentences (e.g., mentioning “university”, “research”, ...).
226	40	2 shows the top test-set predictions of CORE+mtw for the author and “scientist at” relations.
228	38	Note that semantic similarity of relations is one aspect of our model; predictions incorporate other aspects such as context (i.e., two “similar” relations in different contexts are treated differently).
229	29	We used a machine with 16- cores Intel Xeon processor and 128GB of memory.
231	51	Our implementation can handle reasonably large data, but an investigation of faster, more scalable training methods appears worthwhile.
232	57	We proposed CORE, a matrix factorization model for open RE that incorporates contextual information.
233	40	Our model is based on factorization machines and the open-world assumption, integrates various forms of contextual information, and is extensible.
234	38	Our experimental study suggests that exploiting context can significantly improve prediction performance.

0	30	Conventional spoken dialogue systems (SDS) are expensive to build because many of the processing components require a substantial amount of handcrafting (Ward and Issar, 1994; Bohus and Rudnicky, 2009).
2	37	However, due to the difficulty of collecting semantically-annotated corpora, the use of data-driven NLG for SDS remains relatively unexplored and rule-based generation remains the norm for most systems (Cheyer and Guzzoni, 2007; Mirkovic and Cavedon, 2011).
3	40	The goal of the NLG component of an SDS is to map an abstract dialogue act consisting of an act type and a set of attribute-value pairs1 into an appropriate surface text (see Table 1 below for some examples).
4	75	An early example of a statistical NLG system is HALOGEN by Langkilde and Knight (1998) which uses an n-gram language model (LM) to rerank a set of candidates generated by a handcrafted generator.
5	100	In order to reduce the amount of handcrafting and make the approach more useful in SDS, Oh and Rudnicky (2000) replaced the handcrafted generator with a set of word-based n-gram LM-based generators, one for each dialogue type and then reranked the generator outputs using a set of rules to produce the final response.
13	13	While generating, the RNN generator is conditioned on an auxiliary dialogue act feature and a controlling gate to over-generate candidate utterances for subsequent reranking.
20	33	The results show that our approach can produce high quality utterances that are considered to be more natural than a rule-based generator.
44	27	The generation model proposed in this paper is based on an RNNLM architecture (Mikolov et al., 2010) in which a 1-hot encoding wt of a token2 wt is input at each time step t conditioned on a recurrent hidden layer ht and outputs the probability distribution of the next token wt+1.
45	38	Therefore, by sampling input tokens one by one from the output distribution of the RNN until a stop sign is generated (Karpathy and Fei-Fei, 2014) or some required constraint is satisfied (Zhang and Lapata, 2014), the network can produce a sequence of tokens which can be lexicalised to form the required utterance.
49	16	In detail, the recurrent generator shown in Figure 1 is defined as follows: ht = sigmoid(Whhht−1 + Wwhwt + Wfhft) (1) P (wt+1|wt, wt−1, ...w0, ft) = softmax(Whoht) (2) wt+1 ∼ P (wt+1|wt, wt−1, ...w0, ft) (3) where Whh, Wwh, Wfh, and Who are the learned network weight matrices.
50	53	ft is a gated version of f designed to discourage duplication of information in the generated output in which each segment fs of the control vector f corresponding to slot s is replaced by fs,t = fs δt−ts (4) where ts is the time at which slot s first appears in the output, δ ≤ 1 is a decay factor, and denotes element-wise multiplication.
52	25	The tokenisation resulting from delexicalising slots and values does not work for all cases.
53	42	For example, some slot-value pairs such as food=dont care or kids allowed=false cannot be directly modelled using this technique because there is no explicit value to delexicalise in the training corpus.
69	51	Hence instead of integrating the bidirectional information into a single unified network, the forward and backward contexts are utilised separately by firstly generating candidates using the forward RNN generator, then using the log-likelihood computed by a backward RNNLM to rerank the candidates.
79	43	In the reranking phase, the hamming loss costCNN of each candidate is computed using the CNN sentence model and the log-likelihood costbRNN is computed using the backward RNN.
81	38	(8) This is the reranking criterion used to analyse each individual model in Section 4.4.
86	17	The target application area for our generation system is a spoken dialogue system providing information about restaurants in San Francisco.
94	21	The system was trained by partitioning the 5193 utterances into a training set, validation set, and testing set in the ratio 3:1:1, respectively.
98	23	Multiple references for each test dialogue act were obtained by mapping them back to the 228 distinct dialogue acts, merging those delexicalised templates that have the same dialogue act specification, and then lexicalising those templates back to Table 1: The 8 system dialogue acts with example realisations # Dialogue act and example realisations of our system, by sampling from top-5 candidates 1 inform(name=”stroganoff restaurant”,pricerange=cheap,near=”fishermans wharf”) stroganoff restaurant is a cheap restaurant near fishermans wharf .
100	20	2 reject(kidsallowed=yes,food=”basque”) unfortunately there are 0 restaurants that allow kids and serve basque .
109	33	In addition, the slot error (ERR) as described in Section 3.4, out of 1848 slots in 1039 testing examples, was computed alongside the BLEU score.
110	28	As can be seen in Table 2, we compare our proposed RNN-based method with three baselines: a handcrafted generator, a k-nearest neighbour method (kNN), and Oh and Rudnicky (2000)’s n-gram based approach (O&R).
112	35	We found its performance is reliable and robust.
128	62	At each turn, two utterances were generated from two different systems and presented to the judge who was asked to score each utterance in terms of informativeness and naturalness (rating out of 5), and also asked to state a preference between the two taking account of the given dialogue act and the dialogue context.
130	47	The trial was run pairwise across four systems: the RNN system using 1-best utterance RNN1, the RNN system sampling from the top 5 utterances RNN5, the O&R approach sampling from top 5 utterances O&R5, and a handcrafted baseline.
132	58	As can be seen, the human judges preferred both RNN1 and RNN5 compared to the rule-based generator and the preference is statistically significant.
135	11	Even though the preference is not statistically significant, it echoes previous findings (Pon-Barry et al., 2006; Mairesse and Young, 2014) that showed that language variability by paraphrasing in dialogue systems is generally beneficial.
136	248	Lastly, RNN5 was thought to be significantly better than O&R in terms of informativeness.
137	20	This result verified our findings in Section 4.2 that O&R suffers from high slot error rates compared to the RNN system.
138	76	In order to better understand the relative contribution of each component in the RNN-based generation process, a system was built in stages training first only the forward RNN generator, then adding the CNN reranker, and finally the whole model including the backward RNN reranker.

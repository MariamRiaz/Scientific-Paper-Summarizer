59	4	Specifically, Zinkevich (2003) proved that for any sequence of convex functions, the dynamic regret of online gradient descent can be upper bounded by O( √ TP(u1, .
60	5	Another regularity of the comparator sequence, which is similar to the path-length, is defined as P ′(u1, .
73	5	,w∗T )) (Mokhtari et al., 2016).
79	14	,w ∗ T ) is on the order of min(P(w∗1, .
80	6	,w∗T )) for (semi-) strongly convex and smooth functions.
99	9	Let Et be the expert that starts to work at time t. To control the computational complexity, we will associate an ending time et for eachEt.
100	4	The expertEt is alive during the period [t, et − 1].
107	5	In Step 17, we submit the weighted average of wjt with coefficient p j t as the output wt, and suffer the loss ft(wt).
110	4	The difference between our IFLH and the original FLH is how to decide the ending time et of expert Et.
114	4	Then, the base-K ending time of t is defined as EK(t) = ∑ τ≥k+1 βτK τ +Kk+1.
122	5	An example of St in the decimal system is given below.
123	19	The second part of Lemma 1 implies that for any interval I = [r, s], we can find O(log s/ logK) experts such that their survival periods cover I .
125	11	Recall that E10(111) = 120, E10(120) = 200, and E10(200) = 1000.
134	7	If online Newton step is used as the subroutine in Algorithm 1, we have s∑ t=r ft(wt)− min w∈Ω s∑ t=r ft(w) ≤ ( (5d+ 1)m+ 2 α + 5dmGB ) log T where [r, s] ⊆ [T ] and m ≤ dlogK(s− r + 1)e+ 1.
163	4	According to Theorem 2 of Besbes et al. (2015), we know that the minimax dynamic regret of convex functions is O(T 2/3V 1/3 T ).
166	7	In contrast, the metaalgorithm of Jun et al. (2017) does not need any prior knowledge of VT .
168	7	We proceed to consider exp-concave functions, defined in Definition 2.
170	6	It can be used to model many popular losses used in machine learning, such as the square loss in regression, logistic loss in classification and negative logarithm loss in portfolio management (Koren, 2013).
172	6	Based on Theorems 1 and 3, we derive the dynamic regret of the proposed algorithm.
180	12	According to Lemma 2, we know that strongly convex functions with bounded gradients are also exp-concave.
181	6	Thus, Corollary 6 can be directly applied to strongly convex functions, and yields a dynamic regret of O(d √ TVT log T ).
185	7	Algorithm 1, with online gradient descent as its subroutine, is strongly adaptive with SA-Regret(T, τ) ≤G 2 2λ ( γ + 1 + (3γ + 7) log T ) =O (γ log T ) = O (log T ) and its dynamic regret satisfies D-Regret(w∗1, .
188	8	By comparison, the restarted online gradient descent of Besbes et al. (2015) has a dynamic regret of O(log T √ TVT ), but it requires to know an upper bound of VT .
191	55	First, we upper bound the dynamic regret in the following way D-Regret(w∗1, .
192	17	,w ∗ T ) = k∑ i=1 ( qi∑ t=si ft(wt)− qi∑ t=si min w∈Ω ft(w) ) = k∑ i=1  qi∑ t=si ft(wt)− min w∈Ω qi∑ t=si ft(w)︸ ︷︷ ︸ :=ai + min w∈Ω qi∑ t=si ft(w)− qi∑ t=si min w∈Ω ft(w)︸ ︷︷ ︸ :=bi  .
198	10	Since the above inequality holds for any partition of [1, T ], we can take minimization to get a tight bound.
201	10	Moreover, we provide a unified approach for minimizing the adaptive regret of exp-concave functions, as well as strongly convex functions.
202	25	The adaptive-to-dynamic conversion leads to a series of dynamic regret bounds in terms of the functional variation.
203	96	As we mentioned before, dynamic regret can also be upper bounded by other regularities such as the path-length.
204	97	It is interesting to investigate whether those kinds of upper bounds can also be established for strongly adaptive algorithms.

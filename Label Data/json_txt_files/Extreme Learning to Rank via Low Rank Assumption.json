{"sections": [{"heading": "1. Introduction", "text": "Learning a ranking function based on pairwise comparisons has been studied extensively in recent years, with many successful applications in building search engines and other information retrieval tasks. Given a set of training instances with features x1, ...,xn and pairwise comparisons, the goal is to find the optimal decision function f(\u00b7) such that f(xi) > f(xj) if i is preferred over j. This is usually referred to as a learning-to-rank problem, and several algorithms have been proposed, including RankSVM (Herbrich et al., 1999), gradient boosting decision tree (Li et al., 2007), and many others (Cao et al., 2007; Yue et al., 2007;\n1Department of Computer Science, University of California Davis, USA. 2Department of Statistics, University of California Davis, USA . Correspondence to: Minhao Cheng <mhcheng@ucdavis.edu>.\nProceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).\nNegahban et al., 2012; Wauthier et al., 2013).\nHowever, in many modern applications, a single global ranking is not sufficient to represent the variety of individual users preferences. For example, in movie ranking systems, it is preferable to learn an individual ranking function for each user since users\u2019 tastes can vary largely. The issue also arises in many other applications such as product recommendation, and personalized web search ranking.\nMotivated by these real scenarios, we consider the problem of learning hundreds of thousands of ranking functions jointly, one for each user. Our target problem is different from collaborative ranking and BPR (Rendle et al., 2009; Wu et al., 2017a) since they only aim to recover ranking over existing items without using item features, while our goal is to obtain the ranking functions (taking item features as input) that can generalize to unseen items. This is also different from existing work on learning multiple ranking functions (i.e. (Qian et al., 2014)) because in that setting they are learning only several ranking functions. Here we focus on problems where the number of ranking functions T is very large (e.g.,100K) but the amount of data to learn each ranking function is limited. The naive extensions of learning to rank algorithms fail since the training time grows dramatically, and also due to the over-fitting problem because of insufficient number of pairs for training.\nTo resolve this dilemma, we propose the Factorization RankSVM model for learning multiple ranking functions jointly. The main idea is to assume the T ranking functions can be represented by a dictionary of k ranking functions with k T . In the linear RankSVM case, this assumption implies a low-rank structure when we stack all the T linear hyper-planes together into a matrix. By exploiting this low rank structure, our algorithm can be efficient for both time and sample complexity.\nOur contributions can be summarized as follows:\n\u2022 We propose the Factorization RankSVM model for learning a large number of different ranking functions on different sets of data simultaneously. By exploiting the low-rank structure, we show that the gradient can be calculated very efficiently, and the resulting algorithm can scale to problems with large number of tasks. \u2022 We derive the generalization error bound of our model,\nshowing that by training all the T tasks jointly, the sample complexity is much better than training individual rankSVMs under the low rank assumption. \u2022 We conduct experiments on real world datasets, showing that the algorithm achieves higher accuracy and faster training time compared with state-of-the-art methods. This is a critical result as it shows the low rank ranking conjecture that underlies our research does occur. \u2022 We further visualize the basic ranking functions learned by our algorithm, which has some interesting and meaningful patterns."}, {"heading": "2. Related Work", "text": "Learning to rank. Given a set of pairwise comparisons between instances and the feature vectors associated with each instance, the goal of learning to rank is to discover the ranking function. There are three main categories of learning to rank algorithms: pointwise (Li et al., 2007), listwise (Cao et al., 2007; Yue et al., 2007), and pairwise methods (Herbrich et al., 2000; Cao et al., 2006). In this paper, we mainly focus on pairwise methods, which process a pair of documents or entries at a time. Among all the pairwise methods, rankSVM is a very popular one, so we choose it as our basic model.\nWe focus on the problem of solving T learning-to-rank problems jointly when the problems share the same feature space and there is some hidden correlation between tasks. Obviously, we could apply existing learning-to-rank algorithms to solve each task independently, but this approach has several major drawbacks, as will be discussed in next section.\nCollaborative filtering and matrix factorization Lowrank approximation has been widely used in matrix completion and collaborative filtering (Koren et al., 2009), and there are several extensions for matrix completion (Weimer et al., 2007). However, these methods cannot be applied in our setting, since our predictions are based on item features, and the corresponding items may not even appear in the training data. To conduct prediction based on item features, the inductive matrix factorization model has been recently proposed in (Jain & Dhillon, 2013; Xu et al., 2013), and factorization machine (Rendle, 2010) also uses a similar model. However, this model only allows input to be user-item ratings, not the pairwise comparisons used in our problem. In the experiments, we observe that even if the rating data is available, our model still outperforms inductive matrix completion significantly.\nBayesian Personalized Ranking (Rendle et al., 2009) proposes Bayesian Personalized Ranking(BPR) method to solve personalized ranking task. However, there are several major differences with our work. First, our target problem\nis different from BPR. We consider problems given both pairwise comparisons and \u201cexplicit\u201d item features, and the goal is to learn the personalized ranking \u201cfunctions\u201d that can generalize to unseen items as long as we know their features. In comparison, the BPR does not take item features into account, and the goal of BPR is to recover the ranking among existing items. Also, the ranking cannot generalize to unseen items. Moreover, BPR considers implicit (0/1) feedback instead of explicit feedback.\nCollaborative Ranking is another line of research that incorporates ranking loss in collaborative filtering. (Park et al., 2015; Weimer et al., 2007; Wu et al., 2017a) combines the ranking loss with matrix completion model, and (Yun et al., 2014) also uses a low-rank model with ranking loss given a binary observed matrix. However, similar to matrix completion and BPR, these collaborative ranking approaches do not use the item features. So they are not able to predict the preferences for unseen items. Also in this category, (Barjasteh et al., 2015) uses a trace norm to constraint ranking function, which is similar with our idea. However, they use implicit feedback which will lose certain information.\nMulti-task Learning: has been extensively studied, especially in computer vision application. To model the shared information across tasks, a low-rank structure is widely assumed (Chen et al., 2012; 2009). (Hwang et al., 2011; Su et al., 2015) takes the attributes correlation as low-rank embeddings to learn SVM. However, our approach of learning basic ranking functions has not been discussed in the literature.\nA summary of the differences between our algorithm with others are showed in Table 1."}, {"heading": "3. Problem Setting", "text": "Our goal is to learn multiple ranking functions together, one for each user. Assume there are in total T ranking functions to be learned (each one can be viewed as a task), and we are given pairwise comparisons for these ranking functions among n items with features x1,x2, . . . ,xn \u2208 Rd. For each task i, the pairwise comparisons are denoted as \u2126i = {(j, k)}, where (j, k) \u2208 \u2126i means task i compares item j with k, and yijk \u2208 {+1,\u22121} is the observed outcome. For convenience, we use \u2126 to denote the union of all \u2126i. Given these pairwise comparisons, we aim to learn a set of linear ranking functions w1,w2, . . . ,wT \u2208 Rd such that\nsign(wTi (xj\u2212xk)) \u2248 yijk, \u2200(j, k) \u2208 \u2126i, \u2200i = 1, . . . , T\nThe only assumption we make for these T ranking tasks is that the items involved in each task share the same feature space with d features. Note that our algorithm allows each task has non-overlapping items\u2014in that case we can still gather all the items together, and define \u2126i to be the comparisons within each task\u2019s own item block.\nThis model can be easily deployed into recommendation systems where each user i has a corresponding ranking function and the items could be movies, music, goods etc. Then the objective of the task is to learn a ranking function for each user i. Note that after obtaining wi for each i, we can predict the preference for any pairs of items xj ,xk even when they are \u201cunseen items\u201d that are not in the training set. And most collaborative filtering approaches such as matrix completion cannot solve this problem. We are able to predict preferences on unseen items because we try to learn ranking functions based on features instead of just completing the rating matrix over \u201cseen\u201d items.\nNaive approaches: For a single ranking function, (Herbrich et al., 1999) proposes the following RankSVM algorithm:\nmin w\u2208Rd\n1 2 \u2016w\u20162 + C \u2211 (i,j,k)\u2208\u2126 \u03be2ijk\ns.t. yijkwT (xj \u2212 xk) \u2265 1\u2212 \u03beijk, \u03beijk \u2265 0. \u2200i, j, k.\nHere we use L2 hinge loss in our model, however it could be extended to L1 loss as well. We can take RankSVM into multiple-user case by simply assuming that all ranking functions share a common w. We denote this method as RANKSVM JOINTLY. (Evgeniou & Pontil, 2004) provides a variation by assuming each ranking function to be wi = w + vi, where w is the centralized model and vi is the task-dependent variance. However, this algorithm follows the strong assumption that T ranking functions {wi}d1i=1 are all close to a single base function w. We call this algorithm RANKSVM VAR. This assumption is not always true in practice so that it will cause the model to under-fit training data (see our experimental results).\nOn the other hand, we can treat every user separately, which means we train every ranking function wi independently by solving the following problem for every i = 1, . . . , T :\nmin wi\n1 2 \u2016wi\u20162 + C \u2211 (j,k)\u2208\u2126i \u03be2ijk\ns.t. yijkwTi (xj \u2212 xk) \u2265 1\u2212 \u03beijk, \u03beijk \u2265 0,\u2200(j, k) \u2208 \u2126i\nWe call this method as RANKSVM SEPARATELY. It is obvious that this model has more freedom to fit the training data. However, due to the limited number of observed pairs \u2126i per user, each wi has poor prediction quality due to over-fitting. We will analyze the sample complexity of RANKSVM SEPARATELY in Section 4, and experimental results in Section 5 also support our analysis."}, {"heading": "4. Proposed Algorithm", "text": "Our low rank personalized ranking conjecture assumes that all the T ranking functions can be well-approximated by a linear combination of k basic ranking functions, where k T . This makes sense in many real applications; for example, in personalized recommender systems, there are group of users who have similar preferences. Let {uj}kj=1 to be the basic (linear) ranking functions, we can linearly combine weight then using vi to obtain a ranking function for user i as follows: wi = \u2211k j=1 vijuj for all i. This can be written as W = UV T , where columns of W,U are wi and uj respectively, and V is the coefficients. Therefore, W will be a rank-k matrix, which leads to the following nuclear norm regularized problem to enforce the low-rankness of W :\nmin W\u2208Rd\u00d7T\n\u2016W\u2016\u2217 + C \u2211\n(i,j,k)\u2208\u2126\n\u03be2ijk\ns.t. yijkw T i (xj \u2212 xk) \u2265 1\u2212 \u03beijk,\n\u03beijk \u2265 0, \u2200(i, j, k) \u2208 \u2126.\nwhere || \u00b7 ||\u2217 is the nuclear norm of matrix, defined by summation of singular values. We could use some recent developed nuclear norm solvers to solve (4) (see (Cai et al., 2010; Hsieh & Olsen, 2014)).\nWhile the nuclear norm regularized formulation is statistically near optimal for recovering the underlying low-rank model, it cannot be efficiently solved since there are dT parameters in the problem. Therefore, we solve the following\nequivalent non-convex formulation:\nmin U,V\nC \u2211\n(i,j,k)\u2208\u2126\n\u03be2ijk + 1\n2 (\u2016U\u20162F + \u2016V \u20162F )\ns.t. yijkv\u0304Ti U T (xj \u2212 xk) \u2265 1\u2212 \u03beijk,\n\u03beijk \u2265 0,\u2200(i, j, k) \u2208 \u2126. (1)\nwhere we replace the nuclear norm regularization in Equation (4) using the property \u2016W\u2016\u2217 = minW=UV T 12 (\u2016U\u2016 2 F+ \u2016V \u20162F ), U \u2208 Rd\u00d7k, V \u2208 RT\u00d7k, and v\u0304Ti is the i-th row of V . With this non-convex relaxation, there are only (d+T )k parameters involved. So it is preferred over the convex form.\nHowever, developing a fast solver for (1) is still nontrivial. Although RankSVM is often solved in the dual space using stochastic dual coordinate ascent (SDCA) (ShalevShwartz & Zhang, 2013), in our case, it is not suitable because there are |\u2126|k dual variables, where each corresponds to one constraint. So applying a dual coordinate ascent will take O(|\u2126k|) time complexity (to go through all dual variables) and the same order of memory complexity to store all of them. Therefore, we solve the problem in the primal space using alternating minimization. Instead of solving the constrained form, we solve the following equivalent unconstrained problem:\nmin U,V\n{ C \u2211 (i,j,k)\u2208\u2126 max(0, 1\u2212 yijkv\u0304Ti UT (xj \u2212 xk))2\n+ 1\n2 (\u2016U\u20162F + \u2016V \u20162F )\n} := f(U, V ).\n(2)\nFollowing the alternating minimization scheme, our algorithm iteratively updates one ofU, V while keeping the other one fixed. When updating U with V fixed, the subproblem becomes:\nU = argmin U\u2208Rd\u00d7k\nC \u2211\n(i,j,k)\u2208\u2126\nmax(0, 1\u2212 yijkv\u0304Ti UT (xj \u2212 xk))2\n+ 1\n2 \u2016U\u20162F .\n(3) To solve the problem in the primal space, the main bottleneck is the gradient computation when we apply gradient descent. The gradient can be written as\n\u2207Uf(U, V ) = U+ T\u2211 i=1 \u2211 (j,k)\u2208\u2126i \u22122Cyijk max ( 0, 1\u2212 yijkv\u0304Ti UT (xj \u2212 xk) ) (xj \u2212 xk)v\u0304Ti\n(4) Computing (4) naively takes O(|\u2126|kd) time, since we need to go through the summation, and each term requires O(kd) computing time for computing (xj \u2212 xk)v\u0304Ti . However, by re-organizing the computation using a book-keeping technique, we are able to do this in O(T n\u0304k + dkn + |\u2126|)\nAlgorithm 1 Factorization RankSVM: Computing \u2207Uf(U, V )\nInput: X,V,\u2126, Y Compute pj = U\nTxj and set zj = 0 for all j = 1, . . . , n for i = 1, 2, . . . , T do\nCompute qj = v\u0304 T i pj for all j \u2208 \u2126i Set sj = 0 for all j \u2208 \u2126i for (j, k) \u2208 \u2126i do sj \u2190 sj \u2212 2Cyijk max(0, 1\u2212 yijk(qj \u2212 qk)) sk \u2190 sk + 2Cyijk max(0, 1\u2212 yijk(qj \u2212 qk)) end for zj \u2190 zj + sjvi for all j \u2208 \u2126i\nend for for j = 1, 2, . . . , n do \u2207Uf(U, V )\u2190 \u2207Uf(U, V ) + xjzTj end for Output \u2207Uf(U, V ) + U\ntime, where n\u0304 is the average number of ratings per user. The details are presented in Algorithm 1.\nFor updating V , the objective function (1) can be decomposed into T subproblems:\nv\u0304i = argmin v\u0304i\u2208Rk\nC \u2211\n(j,k)\u2208\u2126i\nmax(0, 1\u2212 yijkv\u0304Ti UT (xj \u2212 xk))2\n+ 1\n2 \u2016vi\u201622,\n(5) where each of them is just an RankSVM problem that can be easily solved by gradient descent or Newton method (Chapelle & Keerthi, 2010). The details are omitted here, but the time complexity for this part isO(T n\u0304k+dkn+ |\u2126|), which is exactly the same with the U part.\nTo sum up, our algorithm has an overall time complexity O(T n\u0304k + dkn+ |\u2126|) per iteration, which is quite small because the dominated term |\u2126| (number of pairs) is separated from rest of the terms. Also, k (rank) and n\u0304 (averaged items involves in a ranking task) are usually small. Furthermore, we could adapt Newton method proposed by (Wu et al., 2017b) to further speed up the optimization. As a result, we are able to scaleto very large datasets."}, {"heading": "5. Sample Complexity Analysis", "text": "Now we analyze the sample complexity of the proposed model. If we keep growing T (number of ranking functions), under the low-rank assumptionW = O(T 1/2), the samples needed for Factorization RankSVM to achieve the same -error is approximately O(T 1/2), which is much better than training T individual RankSVMs which requires O(T ) samples. Detailed proofs can be found in the appendix.\nSample complexity of our model\nAssume we observe a set of (i, j, k) pairs and comparison results yijk \u2208 {+1,\u22121} from a fixed but unknown distribution. To recover the underlying model, we proposed to solve (4), and it is equivalent to the constraint form:\nW\u0302 = arg min W\u2208Rd\u00d7T \u2211 (i,j,k)\u2208\u2126 `((ITi W T (xj \u2212 xk)), yijk),\ns.t. \u2016W\u2016\u2217 \u2264 W, (6)\nwhere I \u2208 RT\u00d7T is the indicator matrix, each column Ii is [0, 0, ..., 1, 0, 0] where the i-th element equals to one. Without loss of generality, we assume \u2016xj\u2016 \u2264 1 for all j. The prediction function we want to learn is\nfW (i, j, k) = I T i W T (xj \u2212 xk) = \u3008W, (xj \u2212 xk)ITi \u3009,\nand in our formulation (6), we search within the function class FW := {fW : \u2016W\u2016\u2217 \u2264 W}.\nThe quality of any ranking function fW can be measured by the following expected ranking error (where 1(\u00b7) is the indicator function):\nR(f) := Ei,j,k[1 ( sign(f(i, j, k)) 6= sign(yijk) ) ]. (7)\nWe denote R\u2217 = minf R(f) to be the optimal risk we can get. Since optimizing 0/1 loss is hard, our algorithm uses a convex surrogate loss `, and the following concepts of `-risk will be used in our analysis:\n\u2022 Expected `-risk: R`(f) = Ei,j,k[`(f(i, j, k), yijk)] \u2022 Empirical `-risk: R\u0302`(f) = 1 m \u2211 (i,j,k)\u2208\u2126 `(f(i, j, k), yijk)\nWe begin with the following lemma to bound the expected `-risk:\nLemma 1 (Bound on Expected `-risk (Bartlett & Mendelson, 2002)). Assume `(\u00b7, \u00b7) is a loss function upper bounded by B and with Lipschitz constant L` with respect to its first argument. Let R(FW ) be the model complexity of the function class FW (w.r.t \u2126 and associated with `) defined as:\nR(FW ) = E\u03c3[ sup f\u2208FW\n1\nm \u2211 (i,j,k)\u2208\u2126 \u03c3\u03b1`(f(i, j, k), yijk)],\n(8) where each \u03c3\u03b1 takes values {\u00b11} with equal probability. Then with probability at least 1 \u2212 \u03b4, for all f \u2208 FW , we have\nR`(f) \u2264 R\u0302`(f) + 2E\u2126[R(FW )] + B \u221a log 1\u03b4 2m .\nTo achieve an upper bound for R`(f), we derive a bound of the Radamacker complexity E\u2126[R(FW )]:\nLemma 2. The model complexity of (6) can be upper bounded by:\nE\u2126[R(FW )] \u2264 min { 2L`W \u221a log 2d\nm ,\n\u221a 9L`BCW( \u221a T + n)\nm\n} ,\n(9) where L` is the Lipchitz constant of loss function and C is a universal constant.\nWith the above lemma, we now derive the following theorem to bound the expected ranking error:\nTheorem 1. With probability 1\u2212 \u03b4, the expected error of the optimal solution of our model (6) is:\nR(fW\u0302 )\u2212R \u2217 \u2264O(R\u0302`(fW\u0302 )\u2212R \u2217 ` ) +O(B\n\u221a log(1/\u03b4)\nm )\n+O( min(\n\u221a WB(\n\u221a T + n),W log d) \u221a m ),\n(10) where R\u2217 = inff R(f) and R\u2217` := inff R`(f).\nNote that all the hidden constants can be found in the appendix. In general, the first term on the right hand side will be small since fW\u0302 minimizes the empirical error. This is a standard generalization error bound (as shown in (Kakade et al., 2009)) that works for any distribution of yijk.\nIf we further assume the yijk is generated from an unseen groudtruth W \u2217 with \u2016W\u2217\u2016\u2217 \u2264 W , then the following theorem shows that the error is small when m goes to infinity:\nLemma 3. If the observed yijk = xTj w\u2217i \u2212 xTkw\u2217i for all i, j, k, and loss function satisfies `(a, b) = 0 if sign(a) = sign(b), then we have R(fW\u0302 ) \u2264\nO( min( \u221a WB( \u221a T+n),W log d)\u221a m ) +O(B \u221a log(1/\u03b4) m ).\nNote that the loss `(a, y) = max(\u2212ay, 0)2 satisfies the assumption of Lemma 3, but in practice adding a margin will improve the performance (using `(a, y) = max(1\u2212ay, 0)2). From Theorem 1 and Lemma 3, we can conclude that the error of our model decreases roughly with 1/ \u221a m (m is number of samples), and increases with \u221a W (nuclear norm of the underlying model).\nComparison with RANKSVM SEPARATELY.\nTraining T independent RankSVMs separately can also achieve arbitrary small error under similar condition, so the main question is whether our model can reduce the number of samplesm needed. In RANKSVM SEPARATELY, it is equivalent to solving problem (6) with the constraint replaced by \u2016wi\u2016 \u2264 w for all i. Assume there are m/T pairs per ranking function, then we can prove the following sample complexity based on standard analysis from (Kakade et al., 2009):\nLemma 4. Under the same condition of Lemma 3, the RANKSVM SEPARATELY solution f\u0303 satisfies\nR(f\u0303) = O( w\u221a m/T ) +O(B\n\u221a log(1/\u03b4)\nm/T ).\nNote that we assumeW := \u2016W \u2217\u2016\u2217 and w := maxi \u2016W \u2217:,i\u2016 where W \u2217 is the underlying matrix. Clearly, if the nuclear norm W is small constant, our sample complexity (Lemma 3) is much better than the bound for RANKSVM SEPARATELY (Lemma 4), since our dependency to T is O(T 1/4) while it is O( \u221a T ) for rankSVM. Moreover, in another setting (see, for example, (Shamir & Shalev-Shwartz, 2014)), if each element of W \u2217 is bounded and rank of W \u2217 is a constant,W = O( \u221a Td) and w = O( \u221a d), our bound in Lemma 3 is still better than Lemma 4. Although a better sample complexity upper bound doesnt directly imply our method is always better, however, by obtaining a smaller Rademacher complexity, it is clear that our formulation has benefits to achieve a tighter upper bounds, which leads to better performance in practice."}, {"heading": "6. Experimental Results", "text": "In this section, we show our method outperforms other algorithms on both synthetic and real datasets. All the experiments are conducted on a server with an Intel E7-4820 CPU and 256G memory.\nExperimental Setting. For each ranking task, we randomly split the items into training items and testing items. In the training phase, we use all the pairs between training items to train the model, and in the testing phase we evaluate the prediction accuracy for all the testing-testing item pairs and testing-training item pairs, which is similar with BPR (Rendle et al., 2009). The accuracy is defined to be the correctly predicted pairs divided by total number of predicted pairs.\nWe mainly compare our algorithm with RANKSVM JOINTLY (training a single rankSVM model), RANKSVM SEPARATELY (training an individual rankSVM model for each task), and RANKSVM VAR (the multi-task rankSVM model proposed in (Evgeniou & Pontil, 2004)). All the algorithm above are using square hinge loss in the experiments. We choose the best regularization parameter for each method by a validation set.\nSynthetic Data. For synthetic dataset, we assume there are 1, 000 tasks, 10, 000 items and each item has 64 features. The underlying ranking models are generated by W \u2217 = U\u2217(V \u2217)T , where U\u2217 \u2208 R64\u00d720, V \u2217 \u2208 R1000,20, and U, V \u223c N (0, 1). The feature matrix is generated by X \u2208 R64\u00d710,000, X \u223c N (0, 1). We sample 800 pairs for each user as training data, with labels based on underlying\nrating R = (W \u2217)TX .\nTable 2 shows that our algorithms outperform other rankSVM algorithms on synthetic datasets. Also, as showed in Figure 1, We observe that RANKSVM JOINTLY suffers from under-fitting (low training and test accuracy). On the other hand, RANKSVM SEPARATELY has the over-fitting problem (high training accuracy but low test accuracy) since it does not have enough samples for learning each individual task. Since the underlying U, V have rank 20, our model with rank 20 performs the best. However, even if we choose rank to be 10 or 30, our model still significantly outperforms the other models.\nReal World Datasets. We use recommender system as an application to compare our algorithm with other ranking algorithms. Each user is treated as a \u201cranking task\u201d, and the observed pairs are generated from training ratings. Note that we are also given item features x1, . . . ,xn, and the goal is to learn a personalized ranking model wi for each user. The testing items are unseen in the training phase, which is different from classical matrix completion problem\u2014the goal of classical matrix completion is to complete the matrix, while our goal is to learn the function that can generalize to unseen items. The only matrix completion work that can utilize the feature information to predict unseen items is inductive matrix completion (Jain & Dhillon, 2013) (IMC), which is a special case of factorization machine (Rendle, 2010). Although they do not allow pairwise comparisons as input, for the completeness of comparison, we still include them into comparison and give them the original rating data as input.\nWe choose three datasets in our real-world application experiments: (1) Yahoo! Movies User Ratings and Descriptive Content Information V1 01 (2) HetRec2011-MovieLens-2K (Cantador et al., 2011). (3) MovieLens 20M Dataset (Harper\n1http://research.yahoo.com/Academic Relations\n& Konstan, 2016). For the first dataset, we use the title and abstract of each movie and combine them as the feature matrix X . For the second and third datasets, we take the genres information of each movie as features. See Table3 for more information.\nThe results for datasets (1) and (2) are presented in Table4. Clearly, our method outperforms other algorithms both in accuracy and in speed. Note that dataset (1) has dense features and dataset (2) has sparse features, and our algorithm performs well in both cases. For dataset (3), there are more than 100,000 ranking tasks and other algorithms take more than 1000 seconds per epoch. However, our algorithm only takes about 100 seconds per epoch, and converges to a solution with 63.4% testing accuracy.\nWe also plot the time vs accuracy curves in Figure Our algorithms consistently get better accuracy compared to all other methods. Note that sometimes RANKSVM JOINTLY is fast in the beginning, but eventually it cannot converge to a good solution."}, {"heading": "6.1. Feature Embedding", "text": "Visualize basic ranking functions. Finally, we visualize the basic ranking functions learned by our model. We take the Yahoo! movie dataset, where each feature corresponds\nto a word in movie title and abstract. We select a basic ranking function (a column of U ) from our model and show the top 25 features with most positive weights and bottom 25 features with most negative weights in Figure 2, 3. The visualization of ranking function clearly demonstrates interesting common patterns of users\u2019 tastes."}, {"heading": "7. Conclusions", "text": "We propose a new algorithm for learning multiple ranking functions based on the combination of RankSVM and matrix factorization. We show that the model can be solved efficiently, has good statistical guarantee, and outperforms other methods on real datasets in both training time and prediction accuracy. Our algorithm can be used in many online personalized ranking systems. An interesting direction is to introduce non-linearity (e.g., neural networks) in the feature side of our model and learn U, V with neural network weights jointly."}, {"heading": "Acknowledgments", "text": "Cho-Jui Hsieh and Minhao Cheng acknowledge the support of NSF via IIS-1719097 and the computing resources provided by Google cloud and Nvidia."}], "year": 2018, "references": [{"title": "Semi-supervised collaborative ranking with push at top", "authors": ["I. Barjasteh", "R. Forsati", "Esfahanian", "A.-H", "H. Radha"], "venue": "arXiv preprint arXiv:1511.05266,", "year": 2015}, {"title": "Rademacher and gaussian complexities: Risk bounds and structural results", "authors": ["P.L. Bartlett", "S. Mendelson"], "venue": "Journal of Machine Learning Research,", "year": 2002}, {"title": "A singular value thresholding algorithm for matrix completion", "authors": ["Cai", "J.-F", "E.J. Cand\u00e8s", "Z. Shen"], "venue": "SIAM Journal on Optimization,", "year": 1956}, {"title": "2nd workshop on information heterogeneity and fusion in recommender systems (hetrec", "authors": ["I. Cantador", "P. Brusilovsky", "T. Kuflik"], "venue": "In Proceedings of the 5th ACM conference on Recommender systems,", "year": 2011}, {"title": "Adapting ranking svm to document retrieval", "authors": ["Y. Cao", "J. Xu", "Liu", "T.-Y", "H. Li", "Y. Huang", "Hon", "H.-W"], "venue": "In Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval,", "year": 2006}, {"title": "Learning to rank: from pairwise approach to listwise approach", "authors": ["Z. Cao", "T. Qin", "Liu", "T.-Y", "Tsai", "M.-F", "H. Li"], "venue": "In Proceedings of the 24th international conference on Machine learning,", "year": 2007}, {"title": "Efficient algorithms for ranking with svms", "authors": ["O. Chapelle", "S.S. Keerthi"], "venue": "Information Retrieval,", "year": 2010}, {"title": "A convex formulation for learning shared structures from multiple tasks", "authors": ["J. Chen", "L. Tang", "J. Liu", "J. Ye"], "venue": "In Proceedings of the 26th Annual International Conference on Machine Learning,", "year": 2009}, {"title": "Learning incoherent sparse and low-rank patterns from multiple tasks", "authors": ["J. Chen", "J. Liu", "J. Ye"], "venue": "ACM Transactions on Knowledge Discovery from Data (TKDD),", "year": 2012}, {"title": "Regularized multi\u2013task learning", "authors": ["T. Evgeniou", "M. Pontil"], "venue": "In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining,", "year": 2004}, {"title": "The movielens datasets: History and context", "authors": ["F.M. Harper", "J.A. Konstan"], "venue": "ACM Transactions on Interactive Intelligent Systems (TiiS),", "year": 2016}, {"title": "Support vector learning for ordinal regression", "authors": ["R. Herbrich", "T. Graepel", "K. Obermayer"], "venue": "In Artificial Neural Networks,", "year": 1999}, {"title": "Large margin rank boundaries for ordinal regression", "authors": ["R. Herbrich", "T. Graepel", "K. Obermayer"], "year": 2000}, {"title": "Nuclear norm minimization via active subspace selection", "authors": ["Hsieh", "C.-J", "P.A. Olsen"], "venue": "In ICML,", "year": 2014}, {"title": "Sharing features between objects and their attributes", "authors": ["S.J. Hwang", "F. Sha", "K. Grauman"], "venue": "In Computer Vision and Pattern Recognition (CVPR),", "year": 2011}, {"title": "Provable inductive matrix completion", "authors": ["P. Jain", "I.S. Dhillon"], "venue": "arXiv preprint arXiv:1306.0626,", "year": 2013}, {"title": "On the complexity of linear prediction: Risk bounds, margin bounds, and regularization", "authors": ["S.M. Kakade", "K. Sridharan", "A. Tewari"], "venue": "In Advances in neural information processing systems,", "year": 2009}, {"title": "Matrix factorization techniques for recommender systems", "authors": ["Y. Koren", "R. Bell", "C. Volinsky"], "year": 2009}, {"title": "Mcrank: Learning to rank using multiple classification and gradient boosting", "authors": ["P. Li", "C.J. Burges", "Q. Wu", "J. Platt", "D. Koller", "Y. Singer", "S. Roweis"], "venue": "In NIPS,", "year": 2007}, {"title": "Iterative ranking from pair-wise comparisons", "authors": ["S. Negahban", "S. Oh", "D. Shah"], "venue": "In Advances in Neural Information Processing Systems,", "year": 2012}, {"title": "Preference completion: Large-scale collaborative ranking from pairwise comparisons", "authors": ["D. Park", "J. Neeman", "J. Zhang", "S. Sanghavi", "I. Dhillon"], "venue": "In International Conference on Machine Learning,", "year": 1907}, {"title": "Learning multiple relative attributes with humans in the loop", "authors": ["B. Qian", "X. Wang", "N. Cao", "Jiang", "Y.-G", "I. Davidson"], "venue": "IEEE Transactions on Image Processing,", "year": 2014}, {"title": "Bpr: Bayesian personalized ranking from implicit feedback", "authors": ["S. Rendle", "C. Freudenthaler", "Z. Gantner", "L. SchmidtThieme"], "venue": "In Proceedings of the twenty-fifth conference on uncertainty in artificial intelligence,", "year": 2009}, {"title": "Stochastic dual coordinate ascent methods for regularized loss minimization", "authors": ["S. Shalev-Shwartz", "T. Zhang"], "venue": "Journal of Machine Learning Research,", "year": 2013}, {"title": "Matrix completion with the trace norm: learning, bounding, and transducing", "authors": ["O. Shamir", "S. Shalev-Shwartz"], "venue": "Journal of Machine Learning Research,", "year": 2014}, {"title": "Multi-task learning with low rank attribute embedding for person re-identification", "authors": ["C. Su", "F. Yang", "S. Zhang", "Q. Tian", "L.S. Davis", "W. Gao"], "venue": "In Proceedings of the IEEE International Conference on Computer Vision,", "year": 2015}, {"title": "Efficient ranking from pairwise comparisons", "authors": ["F.L. Wauthier", "M.I. Jordan", "N. Jojic"], "venue": "ICML (3),", "year": 2013}, {"title": "Maximum margin matrix factorization for collaborative ranking", "authors": ["M. Weimer", "A. Karatzoglou", "Q.V. Le", "A. Smola"], "venue": "Advances in neural information processing systems,", "year": 2007}, {"title": "Large-scale collaborative ranking in near-linear time", "authors": ["L. Wu", "Hsieh", "C.-J", "J. Sharpnack"], "venue": "In KDD,", "year": 2017}, {"title": "Large-scale collaborative ranking in near-linear time", "authors": ["L. Wu", "Hsieh", "C.-J", "J. Sharpnack"], "venue": "In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,", "year": 2017}, {"title": "Speedup matrix completion with side information: Application to multi-label learning", "authors": ["M. Xu", "R. Jin", "Zhou", "Z.-H"], "venue": "In Advances in Neural Information Processing Systems,", "year": 2013}, {"title": "A support vector method for optimizing average precision", "authors": ["Y. Yue", "T. Finley", "F. Radlinski", "T. Joachims"], "venue": "In Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval,", "year": 2007}, {"title": "Ranking via robust binary classification", "authors": ["H. Yun", "P. Raman", "S. Vishwanathan"], "venue": "In Advances in Neural Information Processing Systems,", "year": 2014}], "id": "SP:ebc6ae9f41a8e3d96c81504914cf45c98268e539", "authors": [{"name": "Minhao Cheng", "affiliations": []}, {"name": "Ian Davidson", "affiliations": []}, {"name": "Cho-Jui Hsieh", "affiliations": []}], "abstractText": "We consider the setting where we wish to perform ranking for hundreds of thousands of users which is common in recommender systems and web search ranking. Learning a single ranking function is unlikely to capture the variability across all users while learning a ranking function for each person is time-consuming and requires large amounts of data from each user. To address this situation, we propose a Factorization RankSVM algorithm which learns a series of k basic ranking functions and then constructs for each user a local ranking function that is a combination of them. We develop a fast algorithm to reduce the time complexity of gradient descent solver by exploiting the low-rank structure, and the resulting algorithm is much faster than existing methods. Furthermore, we prove that the generalization error of the proposed method can be significantly better than training individual RankSVMs. Finally, we present some interesting patterns in the principal ranking functions learned by our algorithms.", "title": "Extreme Learning to Rank via Low Rank Assumption"}
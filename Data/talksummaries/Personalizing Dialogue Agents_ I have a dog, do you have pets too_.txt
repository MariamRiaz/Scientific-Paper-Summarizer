3	141	Common issues with chit-chat models include: (i) the lack of a consistent personality (Li et al., 2016a) as they are typically trained over many dialogs each with different speakers, (ii) the lack of an explicit long-term memory as they are typically trained to produce an utterance given only the recent dialogue history (Vinyals and Le, 2015); and (iii) a tendency to produce non-specific answers like “I don’t know” (Li et al., 2015).
7	20	Instead, the research community has focused on task-oriented communication, such as airline or restaurant booking (Bordes and Weston, 2016), or else single-turn information seeking, i.e. question answering (Rajpurkar et al., 2016).
10	91	In this work we make a step towards more engaging chit-chat dialogue agents by endowing them with a configurable, but persistent persona, encoded by multiple sentences of textual description, termed a profile.
12	20	Using the same mechanism, any existing information about the persona of the dialogue partner can also be used in the same way.
18	28	We show experimentally that in either the generative or ranking case conditioning the agent with persona information gives improved prediction of the next dialogue utterance.
62	45	To alleviate this problem, we presented the original personas we collected to a new set of crowdworkers and asked them to rewrite the sentences so that a new sentence is about “a related characteristic that the same person may have”, hence the revisions could be rephrases, generalizations or specializations.
63	18	For example “I like basketball” can be revised as “I am a big fan of Michael Jordan” not because they mean the same thing but because the same persona could contain both.
66	25	For example, “My father worked for Ford.” can be revised to “My dad worked in the car industry”, but not “My dad was employed by Ford.” due to word overlap.
68	35	After collecting personas, we then collected the dialogues themselves, conditioned on the personas.
78	28	We focus on the standard dialogue task of predicting the next utterance given the dialogue history, but consider this task both with and without the profile information being given to the learning agent.
87	18	Note one can still evaluate the latter as ranking models by computing the probability of generating a given candidate, and ranking candidates by those scores.
99	24	One can then rank the candidates c′ using sim(q+, c′).
100	21	One can also perform multiple “hops” of attention over the profile rather than one, as shown here, although that did not bring significant gains in our parameter sweeps.
101	35	The key-value (KV) memory network (Miller et al., 2016) was proposed as an improvement to the memory network by performing attention over keys and outputting the values (instead of the same keys as in the original), which can outperform memory networks dependent on the task and definition of the key-value pairs.
102	30	Here, we apply this model to dialogue, and consider the keys as dialog histories (from the training set), and the values as the next dialogue utterances, i.e., the replies from the speaking partner.
104	43	The model we choose is identical to the profile memory network just described in the first hop over profiles, while in the second hop, q+ is used to attend over the keys and output a weighted sum of values as before, producing q++.
116	49	Finally, we introduce a generative model that encodes each of the profile entries as individual memory representations in a memory network.
122	20	If the model has no profile information, and hence no memory, it becomes equivalent to the Seq2Seq model.
146	20	Here, from the Turker’s point of view everything looks the same except instead of being paired with a Turker they are paired with one of our models instead (they do not know this).
149	143	We ask them to evaluate fluency, engagingness and consistency (scored between 1- 5).
152	19	The results are reported in Table 4 for the best performing generative and ranking models, in both the No Persona and Self Persona categories, 100 dialogues each.
153	34	We also evaluate the scores of human performance by replacing the chatbot with a human (another Turker).
156	46	Example chats from a few of the models are shown in the Appendix in Tables 7, 8, 9, 10, 11 and 12.
157	234	Firstly, we see a difference in fluency, engagingness and consistency between all PERSONACHAT models and the models trained on OpenSubtitles and Twitter.
158	189	PERSONA-CHAT is a resource that is particularly strong at providing training data for the beginning of conversations, when the two speakers do not know each other, focusing on asking and answering questions, in contrast to other resources.
159	161	We also see suggestions of more subtle differences between the models, although these differences are obscured by the high variance of the human raters’ evaluations.
160	172	For example, in both the generative and ranking model cases, models endowed with a persona can be detected by the human conversation partner, as evidenced by the persona detection accuracies, whilst maintaining fluency and consistency compared to their nonpersona driven counterparts.
161	121	Finding the balance between fluency, engagement, consistency, and a persistent persona remains a strong challenge for future research.
162	34	Two tasks could naturally be considered using PERSONACHAT: (1) next utterance prediction during dialogue, and (2) profile prediction given dialogue history.
165	51	While a full study is beyond the scope of this paper, we conducted some preliminary experiments, the details of which are in Appendix D. They show (i) human speaker’s profiles can be predicted from their dialogue with high accuracy (94.3%, similar to human performance in Table 4) or even from the model’s dialogue (23% with KV Profile Memory) showing the model is paying attention to the human’s interests.

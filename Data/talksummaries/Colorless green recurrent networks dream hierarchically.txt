2	13	More recently, RNNs have achieved impressive results in large-scale tasks such as language modeling for speech recognition and machine translation, and are by now standard tools for sequential natural language tasks (e.g., Mikolov et al., 2010; Graves, 2012; Wu et al., 2016).
3	29	This suggests that RNNs may learn to track grammatical structure even when trained on noisier natural data.
4	24	The conjecture is supported by the success of RNNs as feature extractors for syntactic parsing (e.g., Cross and Huang, 2016; Kiperwasser and Goldberg, 2016; Zhang et al., 2017).
6	22	They tested whether RNNs can learn to predict English subject-verb agreement, a task thought to require hierarchical structure in the general case (“the girli lri l the boys like.
8	24	However, in their study RNNs could only succeed when provided with explicit supervision on the target task.
9	27	Linzen and colleagues argued that the unsupervised language modeling objective is not sufficient for RNNs to induce the syntactic knowledge necessary to cope with long-distance agreement.
13	34	In “dogss in the neighbourhood often barkr ”, an RNN might get the right agreement by encoding information 1195 about what typically barks (dogs, not neighbourhoods), without relying on more abstract structural cues.
16	146	Inspired by Chomsky’s (1957) insight that “grammaticalness cannot be identified with meaningfulness” (p. 106), we test long-distance agreement both in standard corpus-extracted examples and in comparable nonce sentences that are grammatical but completely meaningless, e.g., (paraphrasing Chomsky): “The colorless green ideasi si I ate with the chair sleeplsl furiously”.
18	16	First, alongside English, which has few morphological cues to agreement, we examine Italian, Hebrew and Russian, which have richer morphological systems.
27	14	We construct our number agreement test sets as follows.
30	28	An LM is evaluated on its predictions for the target (second) word in the dependency, in both the original and nonce sentences.
47	22	For each candidate construction, we collected all of the contexts in the corpus that intervene between the cue and the target (we define contexts as the sequence of POS tags of the top-level nodes in the dependency subtrees).
49	12	1a, the context is defined by VERB (head of the relative clause) and ADV (adverbial modifier of the target verb), which together dominate the sequence “the boys like often”.
50	16	For the Russian adjective-noun agreement construction in Fig.
62	12	When applied to the treebanks we used (see Section 3), this step resulted in between two (English) and 21 (Russian) constructions per lan- guage.
69	19	Our “original” sentence test set included all sentences from each construction where all words from the cue and up to and including the target occurred in the LM vocabulary (Section 3), and where the singular/plural counterpart of the target occurred in the treebank and in the language model vocabulary (this is required by the evaluation procedure outlined below).
72	11	We generated nine nonce variants of each original sentence as follows.
81	15	Given a sentence with prefix p up to and excluding the target, we then compute the probabilities P (t1|p) and P (t2|p) for the singular and plural variants of the target, t1 and t2, based on the language model.
93	13	We use the PyTorch RNN implementation.6 We trained the models with two hidden layer dimensionalities (650 and 200 units), and a range of batch sizes, learning rates and dropout rates.
97	27	We consider three baselines: first, a unigram baseline, which picks the most frequent form in the training corpus out of the two candidate target forms (singular or plural); second, a 5-gram model with Kneser-Ney smoothing (KN, Kneser and Ney, 1995) trained using the IRSTLM package (Federico et al., 2008) and queried using KenLM (Heafield, 2011); and third, a 5-gram LSTM, which only had access to windows of five tokens (Chelba et al., 2017).
113	13	We report results averaged across the five models with the lowest validation perplexity, as well as standard deviations across these models.
114	12	In summary, the LSTM clearly outperformed the other LMs.
115	17	Rather surprisingly, its performance on nonce sentences was only moderately lower than on original ones; in Italian this gap was only 6.6%.
135	12	To put our results in context and provide a reasonable upper bound on the LM performance, in particular for nonce sentences, we next compare model performance to that of human subjects in Italian.
137	48	The gap in accuracy between the human subjects and the model was quite small, and was similar for original and nonce sentences (2.4% and 2.9%, respectively).
141	29	This indicates that humans were more likely to select the correct form in sentences in which the models were more confident in a correct prediction.
148	13	We define attractors as words with the same POS as the cue but the opposite number, which intervene in the linear order of the sentence between the cue and the target.
149	138	Attractors constitute an obvious challenge for agreement processing (Bock and Miller, 1991).
150	78	We show how their presence affects human and model behavior in Fig.
154	44	Our results suggest that the LSTM is quite robust to the presence of attractors, in contrast to what was reported by Linzen et al. (2016).

0	15	We consider the problem of sampling or inference using a complex probability distribution p∗(x) = p̃∗(x)/Z for which we can evaluate p̃∗(x) but not the normalization constant Z = ∫ x p̃∗(x)dx.
2	15	For example, in Bayesian Inference, p̃∗(x) corresponds to the product of prior and likelihood.
3	58	As we can not sample directly from distribution p∗(x) or use it for inference, a common approach is to use Variational Inference (VI) to approximate the target distribution p∗(x) with a tractable distribution p such as multi-variate Gaussians (Blei et al., 2017; Regier et al., 2017) or Gaussian Mixture Models (GMM) (Miller et al., 2017; Guo et al., 2016; Zobay, 2014).
8	20	Our approach focuses on learning multivariate Gaussian Mixture Models (GMMs) with full covariance matrices for approximating the target distribution.
13	104	The algorithms need to explore the sample space in order to ensure that all relevant areas are covered while they also need to exploit the current approximation p(x;θ) in order to fine tune p(x;θ) in areas of high density.
23	18	As stated above, we want to minimize the KL divergence between the approximation p and the target distribution p∗.
24	23	This direct minimization is infeasible as the normalization constant of p∗ is unknown, however, it can be easily shown that the objective can be rewritten as KL(p||p∗) = ∫ x p(x;θ) log p(x;θ) p̃∗(x) dx︸ ︷︷ ︸ −ELBO + logZ, (2) where the term logZ can be ignored as it does not depend on θ.
39	14	The optimization problem can be solved using Lagrangian multipliers.
49	29	Interpreting VI as search problem, the current approximation p(x;θ) is used to search in the space of x.
59	23	The number of components is automatically adapted by deleting components that have low weight and by creating new components in promising regions.
60	56	We approximate the target distribution p∗(x) by minimizing L(θ) given in Equation 3 on the current set of samples.
61	27	As we will use local approximations of the reward function around each component, we introduce individual trust regions for each component and for the coefficients.
62	47	The resulting optimization problem has the form maximize p(x|o),p(o) ∫ x p(x) ( R(x)− log p(x) ) dx, subject to ∀o : ∫ x p(x|o) log p(x|o) q(x|o) ≤ (o),∑ o p(o) log p(o) q(o) ≤ w, where q(o) and q(x|o) are the old mixture weights and components, respectively, and w and (o) upper-bound the corresponding KL-divergences.
74	25	Consequently, improving the lower bound also improves the original objective J(θ) at each EM iteration.
75	76	It can be easily seen that the lower bound does not contain the term log p(x) anymore and decomposes into individual terms for the weight distribution and the single components such that the updates can be performed independently.
102	23	In order to adapt the complexity of the GMM to the complexity of the target distribution, we initialize our algorithm with only one mixture component with high variance and gradually increase the number of mixture components.
106	23	As we want the new component to eventually achieve high weight, we want to add it at an area where its componentspecific reward ro(x) will become large.
112	22	In order to add components without impairing the stability of the optimization, we initialize them with very low weight such that their effect on the approximation is negligible.
113	53	As we draw the same number of samples from each component irrespective of their weight, such low weight components can still improve and eventually contribute to the approximation.
114	24	However, keeping unnecessary components is costly in terms of computational cost and sample efficiency.
118	112	Algorithm 1 Variational Inference by Policy Search 1: Input: initial parameters θ0 2: for j = 1 to maxIter do 3: Add and delete components according to heuristics.
149	29	We evaluate VIPS with respect to efficiency of the optimization as well as quality of the learned approximations.
150	13	For assessing efficiency, we focus on the number of function evaluations, but also include a comparison with respect to the wall-clock time.
151	20	As the ELBO objective is hard to use for comparisons as it depends on the current sample set, we assess the quality of the approximation by comparing samples drawn from the learned model with groundtruth samples based on their Maximum Mean Discrepancy (MMD) (Gretton et al., 2012).
173	18	Figure 2a shows that the sample quality achieved by VIPS is unmatched by any variational inference method and ESS needs more than two orders of magnitude more function evaluation to achieve a similar MMD to VIPS1.
184	14	We want to sample joint configurations such that the end-effector of the robot is close to a desired position at x = 7 and y = 0.
189	44	Figure 4 visualizes the learned models of NPVI, VBOOST and VIPS and compares the ground-truth samples with the samples obtained by VIPS.
192	18	VIPS achieves a high sample quality that is comparable to MCMC methods in order of magnitude less function evaluations than MCMC.
195	18	The covariance matrices are given by Σ = A>A + I20 where each entry of the 20 × 20-dimensional matrix A is sampled from a normal distribution with mean 0 and variance 20.
200	139	Although parallel computing is not the focus of this paper, the possibility of performing independent updates of the mixture components suggests that the method can make good use of multi-threading.

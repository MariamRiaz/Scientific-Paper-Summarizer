1	31	exhibit an increasing fraction of misleading and manipulative content, from questionable claims and “alternative facts” to completely faked news.
5	16	To keep up with the scale and speed at which misinformation spreads, we need tools to automate this debunking process.
6	21	State of the Art and Limitations: Prior work on “truth discovery” (see Li et al. (2016) for survey)1 largely focused on structured facts, typically in the form of subject-predicate-object triples, or on social media platforms like Twitter, Sina Weibo, etc.
11	32	These approaches also do not offer any explanation of their verdicts.
16	16	Approach and Contribution: To overcome the limitations of the prior works, we present DeClarE2, an end-to-end neural network model for assessing and explaining the credibility of arbitrary claims in natural-language text form.
20	19	Rashkin et al. (2017); Wang (2017) also develop an end-to-end model, but DeClarE goes far beyond in terms of considering external evidence and joint interactions between several factors, and also in its ability to generate userinterpretable explanations in addition to highly accurate assessments.
21	66	For example, given the natural-language input claim “the gun epidemic is the leading cause of death of young AfricanAmerican men, more than the next nine causes put together” by Hillary Clinton, DeClarE draws on evidence from the Web to arrive at its verdict credible, and returns annotated snippets like the one in Table 6 as explanation.
25	28	DeClarE then aggregates all the information about claim source, web article contexts, attention weights, and trustworthiness of the underlying sources to assess the claim.
27	17	Key contributions of this paper are: • Model: An end-to-end neural network model which automatically assesses the credibility of natural-language claims, without any handcrafted features or lexicons.
30	14	Consider a set of N claims 〈Cn〉 from the respective origins/sources 〈CSn〉, where n ∈ [1, N ].
36	53	The source/origin of the claim CSn is represented by a ds-dimensional embedding vector csn ∈ <ds .
38	13	The claim and article word embeddings have shared parameters.
39	27	The source of the reporting article ASm,n is represented as a dsdimensional vector, asm,n ∈ <ds .
51	18	Following Wieting et al. (2015), the overall representation of an input claim is generated by taking an average of the word embeddings of all the words therein: c̄ = 1 l ∑ l cl We combine this overall representation of the claim with each article term: âk = ak ⊕ c̄ where, âk ∈ <d+d and ⊕ denotes the concatenate operation.
55	34	In order to create an attention-focused representation of the article considering both the claim and the article’s language, we calculate a weighted average of the hidden state representations for all article tokens based on their corresponding attention scores: g = 1 k ∑ k αk · hk (2) We then combine all the different feature representations: the claim source embedding (cs), the attention-focused article representation (g), and the article source embedding (as).
62	28	We evaluate our approach and demonstrate its generality by performing experiments on four different datasets: a general fact-checking website, a political fact-checking website, a news review community, and a SemEval Twitter rumour dataset.
71	13	To retrieve the reporting articles for each claim (similar to Popat et al. (2017)), we issue each claim as a query to a search engine4 and retrieve the top 30 search results with their respective web sources.
117	37	However, the advantage of DeClarE over Distant Supervision approach is that it does not rely on hand crafted features and lexicons, and can generalize well to arbitrary domains without requiring any seed vocabulary.
118	68	It is also to be noted that both of these approaches use external evidence in the form of reporting articles discussing the claim, which are not available to the LSTM-text and CNN-text baselines.
119	30	This demonstrates the value of external evidence for credibility assessment.
139	38	We sample a few popular news sources from Snopes and claim sources from PolitiFact.
142	107	from mainstream news sources like nytimes, cnn, wsj, foxnews, washingtonpost, etc.
143	17	Similarly, from Figure 2c we observe that DeClarE locates politicians with similar ideologies and opinions close to each other in the embedding space.
146	48	Darker shades indicate higher weights given to the corresponding words.
147	21	As illustrated in the table, DeClarE gives more attention to important words in the reporting article that are relevant to the claim and also play a major role in deciding the corresponding claim’s credibility.
148	92	In the first example on Table 6, highlighted words such as “..barely true...” and “..sketchy evidence...” help our system to identify the claim as not credible.
149	25	On the other hand, highlighted words in the last example, like, “..reveal...” and “..documenting reports...” help our system to assess the claim as credible.
167	22	In this work, we propose a completely automated end-to-end neural network model, DeClarE, for evidence-aware credibility assessment of natural language claims without requiring hand-crafted features or lexicons.
168	194	DeClarE captures signals from external evidence articles and models joint interactions between various factors like the context of a claim, the language of reporting articles, and trustworthiness of their sources.
169	18	Extensive experiments on real world datasets demonstrate our effectiveness over state-of-the-art baselines.

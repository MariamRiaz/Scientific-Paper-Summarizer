{"sections": [{"heading": "1. Introduction", "text": "Given a dataset, similarity relationship between examples can be represented by a graph in which each example is represented by a vertex. While pairwise relationship between two vertices can be represented by an edge in a normal graph, a higher order relationship involving multiple vertices can be captured by a hyperedge, which means that all the corresponding examples are similar to one another. Hypergraphs have been used in several learning applications such as clustering of categorical data (Gibson et al., 1998), multi-label classification (Sun et al., 2008), Laplacian sparse coding (Gao et al., 2013), image classification (Yu et al., 2012), image retrieval (Huang et al., 2010), mapping users across different social networks (Tan et al., 2014) and predicting edge labels in hypernode graphs (Ricatte et al., 2014).\n*Equal contribution 1University of Hong Kong, Hong Kong. 2This research was partially supported by the Hong Kong RGC under the grant 17200214. Correspondence to: T-H. Hubert Chan <hubert@cs.hku.hk>.\nProceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s).\nIn this paper, we consider semi-supervised learning on an edge-weighted hypergraph H = (V,E,w), with a set L of labeled vertices, whose labels are given by f\u2217L \u2208 {\u22121,+1}L. The task is to predict the labels of the unlabeled vertices N , with the working principle that vertices contained in a hyperedge e \u2208 E are more similar to one another if the edge weight we is larger. This problem is also known as transductive inference and has been studied in (Zhou et al., 2006) and (Hein et al., 2013).\nHowever, the methods in (Zhou et al., 2006) have been criticized by (Agarwal et al., 2006), because essentially a hypergraph is converted into a normal graph. For instance, given a hyperedge e containing vertices S, either (i) a clique is added between the vertices in S, or (ii) a star is formed by adding a new vertex ve connecting every vertex in S to ve. Then, a standard convex program using a regularization potential function for normal graphs can be applied (Zhu et al., 2003). By choosing appropriate edge weights, it was shown in (Agarwal et al., 2006) that the two approaches are equivalent to the following convex program relaxation:\nmin \u03a6old(f) := 1\n2 \u2211 e\u2208E we \u2211\n{u,v}\u2208(e2)\n(fu \u2212 fv)2\nsubject to fu \u2208 [\u22121, 1], \u2200u \u2208 V fu = f \u2217 u , \u2200u \u2208 L.\nOn the other hand, it was proposed in (Hein et al., 2013) that the following regularization function is more suitable to capture hyperedge expansion:\n\u03a6new(f) := 1\n2 \u2211 e\u2208E we \u00b7 (max u\u2208e fu \u2212min v\u2208e fv) 2.\nIndeed, it was shown in (Hein et al., 2013) that their approach outperforms (Zhou et al., 2006) on several datasets from the UCI Machine Learning Repository (Lichman, 2013).\nLoss Function. In (Hein et al., 2013), a squared loss function was added by considering the convex program with objective function \u03a6new(f) + \u00b5 \u2016f \u2212 f\u2217\u201622 on f \u2208 [\u22121, 1]V , where \u00b5 > 0 is a parameter to be tuned, f\u2217L is given by the labeled vertices L, and for the unlabeled vertices f\u2217N = 0.\nThe loss function allows errors in the labeled vertices, and also ensures that the minimizer is unique. However, as a result, unlabeled vertices have a tendency to acquire f values close to 0. This might remove useful information as illustrated in the following example.\nExample. In Figure 1.1, vertices a, b \u2208 L are labeled as +1 and c \u2208 L is labeled as \u22121. Vertices x, y \u2208 N are unlabeled. There are three (undirected) edges: {a, x}, {b, x} and {x, y, c}, each with unit weight.\nBy choosing \u00b5 = 12 for squared loss function, the unique minimizer gives fx = 15 and fy = 0. Hence, this solution gives no useful information regarding the label for vertex y.\nOn the other hand, if we just use the objective function \u03a6new(f) with the constraints fL = f\u2217L, then in an optimal solution, fx = 13 , but fy could be anywhere in the confidence interval [\u22121, 13 ]. Hence, in this case, we could use the average value \u2212 13 to predict \u22121 for vertex y.\nOur Contributions. In this paper, we revisit the approach used in (Hein et al., 2013) and consider several extensions and simplifications. We summarize our results and give an outline of the paper as follows.\n1. Unified Framework for Directed Hypergraphs. Inspired also from the recent result on Laplacians for directed normal graphs (Yoshida, 2016), we introduce a semisupervised learning framework using directed hypergraphs that can capture higher order causal relationships. This notion of directed hypergraph was first introduced in (Gallo et al., 1993), who considered applications in propositional logic, analyzing dependency in relational database, and traffic analysis. On a high level, a directed hyperedge e consists of a tail set Te pointing to a head set He such that a vertex in Te labeled +1 implies that a vertex in He is more likely to be labeled +1. (Equivalently in terms of its contrapositive, a vertex in He labeled \u22121 implies that a vertex in Te is more likely to be labeled \u22121.) In Section 2, we formally define the model and the corresponding potential function \u03a6. An additional advantage of our potential function is that there is no need to tune any parameters.\n2. Confidence Interval for Unlabeled Vertices. Observe that the minimizer for our convex program might not be unique. In Section 3, we introduce the concept of confidence interval for each unlabeled vertex that can be useful for predicting its label. Furthermore, we provide an algorithm to calculate the confidence interval given an optimal solution.\n3. Simpler Subgradient Method. Since the new potential function is not everywhere differentiable but still convex, we use the subgradient method (Shor et al., 1985) to obtain an estimated minimizer for label prediction. Inspired by the diffusion processes used for defining Laplacians in hypergraphs (Louis, 2015) and directed graphs (Yoshida, 2016), in Section 4, we define a simple Markov operator that returns a subgradient for \u03a6, which is used to solve the underlying convex program. We remark that our framework is very easy to understand, because it is a variation on the well-known gradient descent.\nIn contrast, the primal-dual approach in (Hein et al., 2013) considers the convex conjugate of the primal objective and involves complicated update operations on the primal and dual variables. The subgradient used in our approach gives the update direction, and we can actually solve exactly the same convex program with a much simpler method."}, {"heading": "4. Experimental Results on Real-World Datasets. In", "text": "Section 5, we revisit some datasets in the UCI Machine Learning Repository (Lichman, 2013), and experiments confirm that our prediction model based on confidence interval gives better accuracy than that in (Hein et al., 2013). Our simpler subgradient method takes more iterations than the primal-dual method (Hein et al., 2013), but each iteration is much faster. Experiments show that overall both methods have similar running times, and the subgradient method has an advantage when the number of vertices is much larger than the number of edges.\nMoreover, using the DBLP dataset (Ley, 2009), our experiments also support that using directed hypergraphs to capture causal relationships can improve the prediction accuracy. The experiments for directed hypergraphs are described in the full version."}, {"heading": "2. Preliminaries", "text": "We consider an edge-weighted directed hypergraph H = (V,E,w) with vertex set V (with n = |V |), edge set E and weight function w : E \u2192 R+. Each hyperedge e \u2208 E consists of a tail set Te \u2286 V and a head set He \u2286 V (which are not necessarily disjoint); we use the convention that the direction is from tail to head. For x \u2208 R, we denote [x]+ := max{x, 0}.\nIn our application, each vertex v \u2208 V is supposed to have a label in {\u22121,+1}. Intuitively, the directed hypergraph attempts to capture the rule that for each edge e \u2208 E, if there is a vertex in Te having label +1, then it is more likely for vertices in He to receive label +1. In terms of its contrapositive, if there is a vertex in He having label \u22121, then it is more likely for vertices in Te to receive label \u22121.\nWe use f \u2208 RV to denote a vector, where the coordi-\nnates are labeled by vertices in V . For U \u2286 V , we use fU \u2208 RU to denote the vector restricting f to coordinates inU . In semi-supervised learning, we consider a setL \u2286 V of labeled vertices, which have labels f\u2217L \u2208 {\u22121,+1}L. Typically, |L| |V | and the task is to assign a label in {\u22121,+1} to each unlabeled vertex in N := V \\ L, using information from the directed hypergraph H .\nBy relaxing labels to be in the interval [\u22121, 1], we consider the following regularization potential function \u03a6 : RV \u2192 R:\n\u03a6(f) = 1\n2 \u2211 e\u2208E we \u00b7 ([\u2206e(f)]+)2,\nwhere \u2206e(f) := max(u,v)\u2208Te\u00d7He(fu \u2212 fv) = maxu\u2208Te fu \u2212minv\u2208He fv .\nIn particular, there is a penalty due to edge e only if some vertex in Te receives a label larger than that of some vertex in He. The convexity of \u03a6 is proved in the full version.\nOur approach is to consider the following convex program to obtain an estimated minimizer f \u2208 [\u22121, 1]V , which can be rounded to an integer solution for labeling all vertices.\nmin \u03a6(f) (CP1) subject to fu \u2208 [\u22121, 1], \u2200u \u2208 V\nfu = f \u2217 u , \u2200u \u2208 L\nSince the f values for the labeled vertices L are fixed in (CP1), we also view \u03a6 : RN \u2192 R as a function on the f values of unlabeled vertices N . We use OPT \u2282 RV to denote the set of optimal solutions to (CP1).\nTrivial Edges. An edge e \u2208 E is trivial if there exist vertices u \u2208 Te \u2229 L and v \u2208 He \u2229 L such that f\u2217u = +1 and f\u2217v = \u22121. As trivial edges contribute constant towards the objective function \u03a6, we shall assume that there are no trivial edges in the convex program (CP1).\nSpecial Cases. Our directed hypergraph model can capture other graph models as follows.\n1. Undirected Hypergraphs. For each hyperedge e, we can set Te = He to the corresponding subset of vertices. 2. Undirected Normal Graphs. For each edge e = {u, v}, we can set Te = He = e. Observe that in this case, the potential function becomes \u03a6(f) =\u2211\n(u,v)\u2208E wuv(fu\u2212 fv)2, which is differentiable, and hence, (CP1) can be solved by standard techniques like gradient descent.\nSoft Constraints. In (Hein et al., 2013), each labeled vertex u \u2208 L can also have some weight \u00b5u \u2208 R+, which can, for instance, indicate how trustworthy the label\nf\u2217u \u2208 {\u22121,+1} is. The following relaxation is considered.\nmin \u03a6\u0302(f) := \u03a6(f) + 1\n2 \u2211 u\u2208L \u00b5u(fu \u2212 f\u2217u)2 (CP2)\nsubject to fu \u2208 [\u22121, 1],\u2200u \u2208 V.\nObserve that (CP2) can also be expressed in the framework of (CP1). We simply consider an augmented hypergraph H\u0302 such that all vertices V are treated as unlabeled, and for each u \u2208 L, we add a new vertex u\u0302 with label f\u2217u and a new undirected edge {u, u\u0302} with weight \u00b5u. Then, it follows that the convex program (CP1) for the augmented instance for H\u0302 is exactly the same as (CP2).\nChallenges Ahead. We next outline how we resolve the encountered challenges when we use (CP1) for semisupervised learning.\n\u2022 Unlike the case for normal graphs, the set OPT can contain more than one optimal solution for (CP1). In Section 3, we prove some structural properties of the convex program, and illustrate that each u \u2208 N has some confidence interval from which we can predict its label. \u2022 The function \u03a6 is not everywhere differentiable. Hence, we use the subgradient method (Shor et al., 1985). In Section 4, we give a method to generate a subgradient, which is inspired by the continuous diffusion processes for hypergraphs (Louis, 2015) and directed graphs (Yoshida, 2016), and our method can in fact be viewed as a discretized version."}, {"heading": "3. Confidence Interval for Semi-supervised Learning", "text": "In general, a minimizer for (CP1) might not be unique. Hence, we introduce the concept of confidence interval.\nDefinition 3.1 (Confidence Interval) For each u \u2208 V , we define its confidence interval to be [mu,Mu], where mu := minf\u2208OPT fu and Mu := maxf\u2208OPT fu. The confidence intervals induce the lower and the upper confidence vectors, ~m and ~M \u2208 RV , respectively.\nIn Section 3.1, we give the proof of the following lemma, which states that the confidence vectors ~m and ~M are optimal solutions, and so are their convex combinations.\nLemma 3.1 (Confidence Vectors Give Optimal Solutions) For any \u03bb \u2208 [0, 1], the convex combination \u03bb~m + (1\u2212 \u03bb) ~M \u2208 OPT is optimal for (CP1).\nSemi-supervised Learning via Confidence Interval. Lemma 3.1 suggests what one can do when (CP1) has more than one optimal solution. Specifically, in Algorithm 1, the\naverage vector 12 (~m + ~M) \u2208 OPT can be used for label prediction. We show that the confidence vectors ~m and ~M can be recovered from any optimal solution f \u2208 OPT, which in turn can be estimated by the subgradient method described in Section 4. Algorithm 1 Semi-Supervised Learning\n1: Input: Directed hypergraph H = (V,E,w), labels f\u2217L for labeled vertices L 2: Compute (estimated) confidence vectors (~m, ~M) \u2208 RN \u00d7 RN , either by Algorithm 2 or 3. 3: Compute average vector fN \u2190 12 (~m+ ~M). 4: Compute threshold \u03b8 \u2190 1|N | \u2211 u\u2208N fu. 5: for each u \u2208 N do 6: if fu \u2265 \u03b8 then 7: f\u0302u \u2190 +1; 8: else 9: f\u0302u \u2190 \u22121;\n10: end if 11: end for 12: return f\u0302N\nFine-Tuning Parameters. In view of Lemma 3.1, one could further optimize the choice of \u03bb \u2208 [0, 1] in defining fN \u2190 \u03bb~m+ (1\u2212\u03bb) ~M in Line 3. Similarly, one could pick the threshold \u03b8 to be the \u03d1-percentile of the sorted coordinates of fN , for some choice of \u03d1 \u2208 [0, 1]. The parameters \u03bb and \u03d1 can be tuned using standard techniques like cross-validation. However, to illustrate our concepts, we keep the description simple without introducing too many free parameters."}, {"heading": "3.1. Properties of Confidence Vectors", "text": "We derive some properties of the confidence vectors to prove Lemma 3.1. The full proofs of Lemma 3.2 and 3.3 are given in the full version.\nGiven a feasible solution f \u2208 RV to (CP1), we define the following:\n1. Se(f) := arg maxu\u2208Te fu \u2286 Te and Ie(f) := arg minv\u2208He fv \u2286 He. 2. f(Se) := maxu\u2208Te fu and f(Ie) := minv\u2208He fv . Hence, we have \u2206e(f) = f(Se)\u2212 f(Ie). 3. The set of active edges with respect to f is E(f) := {e \u2208 E : \u2206e(f) > 0}.\nThe following lemma states even though a minimizer for (CP1) might not be unique, there are still some structural properties for any optimal solution.\nLemma 3.2 (Active Edges in an Optimal Solution) Suppose f and g are optimal solutions to (CP1). Then, for all e \u2208 E, [\u2206e(f)]+ = [\u2206e(g)]+. In particular, this implies that the set of active edges E\u2217 := E(f) = E(g) in any op-\ntimal solution is uniquely determined. Hence, for e \u2208 E\u2217, we can define the corresponding \u2206\u2217e = \u2206e(f).\nDefinition 3.2 (Pinned Vertex) An unlabeled vertex u is pinned in a solution f \u2208 RV if there exist active edges e and e\u2032 \u2208 E(f) such that u \u2208 Se(f)\u2229 Ie\u2032(f), in which case we say that the edges e and e\u2032 pin the vertex u under f .\nLemma 3.3 (Extending an Active Edge) Suppose edge e \u2208 E(f) is active in an optimal solution f . If He does not contain a vertex labeled with \u22121, then there exist u \u2208 Ie(f) and another active edge e\u2032 \u2208 E(f) such that the following holds.\n(a) The edges e and e\u2032 pin u under f , i.e., u \u2208 Se\u2032(f). (b) If g is an optimal solution, then Ie(f) \u2229 Se\u2032(f) =\nIe(g) \u2229 Se\u2032(g) and fu = gu."}, {"heading": "An analogous result holds when Te does not contain any", "text": "vertex labeled with +1."}, {"heading": "In particular, for any active edge e \u2208 E\u2217, the extremal values f\u2217(Se) := maxu\u2208Te fu and f", "text": "\u2217(Ie) := minu\u2208He fu are uniquely determined by any optimal solution f .\nCorollary 3.1 (Pinned Vertices) In any optimal solution, the set of pinned vertices is uniquely determined. We use L\u2217 to denote the set of labeled or pinned vertices in an optimal solution. Then, for each u \u2208 L\u2217, its value f\u2217u in any optimal solution is also uniquely determined.\nFrom Corollary 3.1, the confidence interval for any u \u2208 L\u2217 contains exactly one value, namely the unique value f\u2217u in any optimal solution. The following lemma gives a characterization of an optimal solution.\nLemma 3.4 Characterization of Optimal Solutions A solution f to (CP1) is optimal iff the following conditions hold.\n(a) For each u \u2208 L\u2217, fu = f\u2217u . (b) For each active edge e \u2208 E\u2217, both the maximum\nmaxu\u2208Te fu and the minimum minv\u2208He fv are attained by vertices in L\u2217. (c) For each inactive edge e /\u2208 E\u2217, for all u \u2208 Te and v \u2208 He, fu \u2264 fv .\nProof: We first observe that Corollary 3.1 states that the values of the vertices in L\u2217 are uniquely determined in any optimal solution. Hence, any optimal solution must satisfy the three conditions. We next show that the three conditions implies that the objective value is optimal.\nOnce the values for vertices in L\u2217 are fixed, Lemma 3.3 and condition (b) implies that the contribution of all active edges E\u2217 are determined and are the same as any optimal solution.\nFinally, condition (c) implies that edges not in E\u2217 do not have any contribution towards the objective function. Hence, any solution satisfying the three conditions must be optimal.\nDeriving Confidence Vectors. To prove Lemma 3.5, we define a procedure that returns a vector ~m \u2208 V R such that for any optimal f \u2208 OPT, we have f \u2265 ~m. Moreover, we shall show that ~m \u2208 OPT and hence ~m is the lower confidence vector. The argument for the upper confidence vector ~M is similar. For the special case of undirected hypergraphs, the procedure can be simplified to Algorithm 2 in Section 3.2.\nLemma 3.5 (Confidence Vectors are Optimal: Proof of Lemma 3.1) The confidence vectors ~m and ~M defined in Definition 3.1 are optimal solutions to (CP1). This implies that any of their convex combination is also optimal.\nProof: We give a procedure that returns a vector ~m such that at any moment during the procedure, the following invariant is maintained: for any f \u2208 OPT, f \u2265 ~m.\nThe following steps correspond to maintaining the conditions in Lemma 3.4.\n(a) Initialization. For v \u2208 L\u2217, set mv := f\u2217v ; for v /\u2208 L\u2217, set mv := \u22121. This satisfies the invariant, because for any f \u2208 OPT and any v \u2208 L\u2217, fv = f\u2217v .\n(b) Preserving Active Edges. For each v /\u2208 L\u2217, set mv \u2190 max{mv,maxe\u2208E\u2217:v\u2208He f\u2217(Ie)}. Observe that Lemma 3.4(b) implies that for any optimal f \u2208 OPT, any e \u2208 E\u2217 and any v \u2208 He, fv \u2265 f\u2217(Ie). Hence, the invariant is maintained.\n(c) Preserving Inactive Edges. While there is an inactive edge e /\u2208 E\u2217 such that u \u2208 Te, v \u2208 He and mu > mv , set mv \u2190 mu. We argue why each such update preserves the invariant. Consider any optimal f \u2208 OPT. Before this update, the invariant holds. Hence, we have mu \u2264 fu. Moreover, Lemma 3.4 implies that fu \u2264 fv . Therefore, after setting mv \u2190 mu, we still have mv \u2264 fv .\nFinally, observe that after step (b), the coordinates of ~m can take at most n distinct values. Moreover, after each update in step (c), one coordinate of ~m must increase strictly. Hence, this procedure will terminate.\nWe next argue that ~m is an optimal solution by checking that it satisfies the conditions in Lemma 3.4.\nCondition (a). Observe that for each v \u2208 L\u2217, mv is initialized to f\u2217v . Afterwards the value mv could only be increased. However, because the invariant holds when the procedure terminates, it must be the case that mv = f\u2217v at the end.\nCondition (b). The procedure makes sure that at the end of\nstep (b), for every active edge e \u2208 E\u2217, minv\u2208He mv can be attained by some vertex in L\u2217. Since only mv for v /\u2208 L\u2217 can be increased in step (c), it follows that in the end, the minimum can still be attained by some vertex in L\u2217.\nNext, consider u \u2208 Te, where e \u2208 E\u2217. For any optimal solution f , Lemma 3.3 implies that fu \u2264 f\u2217(Se). Hence, the invariant implies thatmu \u2264 fu \u2264 f\u2217(Se). Since condition (a) holds, this means that maxv\u2208Te mv can be attained by some vertex in L\u2217.\nCondition (c). This is clearly satisfied because of the while-termination condition.\nTherefore, we have ~m \u2208 OPT, as required.\nThe proof for the upper confidence vector ~M is similar. We omit the detailed proof and just give the corresponding procedure to return ~M .\n(a) Initialization. For v \u2208 L\u2217, set Mv := f\u2217v ; for v /\u2208 L\u2217, set Mv := +1.\n(b) Preserving Active Edges. For each v /\u2208 L\u2217, set Mv \u2190 min{Mv,mine\u2208E\u2217:v\u2208Te f\u2217(Se)}.\n(c) Preserving Inactive Edges. While there is an inactive edge e /\u2208 E\u2217 such that u \u2208 Te, v \u2208 He and Mu > Mv , set Mu \u2190Mv .\nThe same argument can show that for any optimal f \u2208 OPT, we have f \u2264 ~M . Moreover, we also have ~M \u2208 OPT."}, {"heading": "3.2. Computing the Confidence Interval", "text": "As mentioned before, the proof of Lemma 3.5 implicitly gives a procedure to compute the confidence vectors from any optimal solution. For the special case of undirected hypergraphs, a simplified version of the procedure is given in Algorithm 2.\nAlternatively, we can try to solve the convex program (CP1), for example using Algorithm 5 in Section 4, from two initial feasible solutions to heuristically estimate the confidence vectors. In Algorithm 3, one instance approaches an optimal solution from high f values and the other from low f values."}, {"heading": "4. Subgradient Method via Markov Operator", "text": "Resolving Ties. Observe that \u03a6 : RN \u2192 R is differentiable at fN \u2208 RN that has distinct coordinates. For the purpose of computing a subgradient, we assume that there is some global ordering \u03c0 on V to resolve ties among coordinates with the same value. In particular, the vertices in L having label +1 are the highest, and those in L labeled \u22121 are the lowest. Hence, in this section, we may assume that any arg max or arg min operator over a subset of vertices\nAlgorithm 2 Confidence Intervals for Undirected Hypergraphs\n1: Input: Undirected hypergraph H = (V,E,w), label vector f\u2217L and tolerance \u2265 0. 2: Let f be a solution of (CP1), either by Algorithm 5 or by PDHG method (Hein et al., 2013) 3: For all v \u2208 V , set p(v)\u2190 v, mv \u2190 \u22121, Mv \u2190 +1. 4: E\u0302 := {e \u2208 E : \u2206e(f) \u2264 } 5: while \u2203e1 6= e2 \u2208 E\u0302, e1 \u2229 e2 6= \u2205 do 6: E\u0302 \u2190 (E\u0302 \\ {e1, e2}) \u222a {e1 \u222a e2} 7: end while 8: for each e \u2208 E\u0302 do 9: x\u2190 an arbitrary vertex in e\n10: for each vertex v \u2208 e do 11: p(v)\u2190 p(x) 12: end for 13: end for 14: for each vertex v \u2208 L do 15: mp(v) \u2190 f\u2217v , Mp(v) \u2190 f\u2217v 16: end for 17: for each edge e \u2208 E such that \u2206e(f) > do 18: for each vertex v \u2208 e do 19: mp(v) \u2190 max{mp(v), f(Ie)} 20: Mp(v) \u2190 min{Mp(v), f(Se)} 21: end for 22: end for 23: for each vertex v \u2208 V do 24: mv \u2190 mp(v), Mv \u2190Mp(v) 25: end for 26: return vectors (~m, ~M)\nwill return a unique vertex.\nWe next define a Markov operator that is inspired from the diffusion processes on hypergraphs (Louis, 2015) and directed graphs (Yoshida, 2016) in the context of defining Laplacians. We denote the projection operator \u03a0N : RV \u2192 RN that takes f \u2208 RV and returns the restricted vector fN \u2208 RN .\nLemma 4.1 For f \u2208 [\u22121, 1]V that is feasible in (CP1), the Markov operator Mf given in Algorithm 4 returns a subgradient of \u03a6 : RN \u2192 R at fN .\nProof: (Sketch) Observe that if fN \u2208 RN has distinct coordinates, then \u03a6 is differentiable at fN , and Mf gives exactly the gradient (which is the only possible subgradient in this case). Observe that in our subgradient method application, we could imagine that at every iteration, infinitesimal perturbation is performed on the current solution to ensure that all coordinates are distinct, and ties are resolved according to our global ordering \u03c0.\nAlgorithm 3 Estimate confidence interval 1: Input: Directed hypergraph H = (V,E,w), labels f\u2217L\nfor labeled vertices L 2: Construct feasible f (0,+)N \u2190 +1 \u2208 RN with all entries\nbeing +1; 3: Construct feasible f (0,\u2212)N \u2190 \u22121 \u2208 RN with all entries\nbeing \u22121; 4: ~M \u2190 SGM(f (0,+)N ); 5: ~m\u2190 SGM(f (0,\u2212)N ); 6: return the vectors (~m, ~M)\nAlgorithm 4 Markov Operator M : RV \u2192 RN\n1: Input: Directed hypergraph H = (V,E,w), feasible f \u2208 RV for (CP1) 2: Construct symmetric matrix A \u2208 RV\u00d7V ; set A\u2190 0. 3: for each e \u2208 E such that \u2206e(f) > 0 do 4: u\u2190 arg maxu\u2208Te fu; 5: v \u2190 arg minv\u2208He fv; 6: Auv \u2190 Auv + we; 7: (The same is done forAvu becauseA is symmetric.) 8: end for 9: Construct diagonal matrix W \u2208 RN\u00d7N ; set W \u2190 0.\n10: for each u \u2208 N do 11: Wuu \u2190 \u2211 v\u2208V Auv; 12: end for 13: return (W\u03a0N \u2212\u03a0NA)f\nHence, as the magnitude of the perturbation tends to zero, if the global ordering \u03c0 is preserved, then the gradient remains the same, which implies that the gradient is also the subgradient when the perturbation reaches 0.\nUsing the Markov operator M as a subroutine to generate a subgradient, we have the following subgradient method (SGM) (Shor et al., 1985).\nAlgorithm 5 Subgradient Method SGM(f (0)N \u2208 RN ) 1: Input: Directed hypergraph H = (V,E,w) with la-\nbels f\u2217L for labeled vertices L, initial feasible solution f (0) N \u2208 RN , step size {\u03b7t := 1 t }t\u22651\n2: t\u2190 1; 3: (Throughout the algorithm, f (t)L = f \u2217 L is given by the\nlabeled vertices.) 4: while Solution f (t)N has not \u201cstabilized\u201d do 5: g(t)N \u2190 Mf (t\u22121) \u2208 RN ; 6: f (t)N = f (t\u22121) N \u2212 \u03b7t \u00b7\ng (t) N\u2225\u2225\u2225g(t)N \u2225\u2225\u2225\n2\n;\n7: t\u2190 t+ 1; 8: end while 9: return f (t)\nStabilizing Condition. Our experiments in Section 5 suggest that it suffices to run the solver for a short time, after which a better feasible solution f does not improve the prediction accuracy."}, {"heading": "5. Experimental Results", "text": "Our experiments are run on a standard PC. In our graphs, each point refers to a sample mean, and the height of the vertical bar is the standard error of the mean."}, {"heading": "5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods", "text": "We show that our treatment of hypergraphs performs better than the previously best method in (Hein et al., 2013).\nHypergraph Model. We use three datasets from the UCI Machine Learning Repository (Lichman, 2013): mushroom, covertype45 and covertype67. As in (Hein et al., 2013), each dataset fits into the hypergraph learning model in the following way. Each entry in the dataset corresponds to a vertex, which is labeled either +1 or \u22121. Moreover, each entry has some categorical attributes. For each attribute and each realized value for that attribute, we form a unit-weight hyperedge containing all the vertices corresponding to entries having that attribute value. To summarize, below are the properties of the resulting hypergraphs.\nDataset mushroom covertype45 covertype67\nn = |V | 8124 12240 37877 m = |E| 112 104 123 k =\u2211\ne\u2208E |e| m\n1523 1412 3695\nSemi-supervised Learning Framework. We compare our semi-supervised learning framework with that in (Hein et al., 2013), which was previously the best (compared to (Zhou et al., 2006), for instance). Specifically, we compare the prediction accuracy of the following two prediction algorithms.\n1. Confidence Interval (CI). We use hard constraints (CP1) and confidence intervals for prediction, as described in Algorithm 1 in Section 3. 2. Hein et al. We implement the method described in (Hein et al., 2013), which uses soft constraints (regularized version), plus 5-fold cross validation to determine the regularization parameter.\nTesting Methodology. Since we focus on prediction accuracy, using either subgradient method or PDHG (Hein et al., 2013) for solving the underlying convex programs in each algorithm produces the same results. For each algorithm candidate, we try different sizes of labeled vertices L, where l = |L| ranges from 20 to 200. For each size l\nof labeled vertices, we randomly pick l vertices from the dataset to form the set L and treat the rest as unlabeled vertices; we re-sample if only one label (+1 or \u22121) appears in L. For each size l, we perform 100 trials to report the average error rate together with its standard error.\nResults. Our experiment can recover the results reported in (Hein et al., 2013). The test error for the two algorithms on the three datasets is presented in Figure 5.1, which shows that our CI method consistently has lower test error than the one in (Hein et al., 2013)."}, {"heading": "5.2. Comparing Running Times of Solvers", "text": "Different Solvers. We compare the running times of the following two convex program solvers:\n\u2022 Subgradient Method (SG), proposed by us. Empirically, the step size \u03b7t := 1\n(t+1) min( 0.16t 105 ,1)\ngives good\nperformance. For large t, \u03b7t grows like 1t and so the method converges; however, for small t, we would like a larger step size to speed up convergence. \u2022 Primal-Dual Hybrid Gradient (PDHG), proposed in (Hein et al., 2013). We choose \u03c3 = \u03c4 = 1\u221a\n1+d ,\nwhere d is the maximum degree.\nTheoretical Analysis. Given a hypergraph with n vertices and m edges, where the average size of an edge is k, each vertex on average appears in mkn edges. For SG, we use a heap-based data structure to maintain the vertices within a hyperedge. Vertices attaining the maximum and the minimum value within a hyperedge can be retrieved in O(1) time, and a value update takes O(log k) time. In each iteration, at most 2m vertices will have their values updated. Hence, in each iteration, SG takes time 2m\u00b7mkn \u00b7O(log k) = O(m\n2k n log k). In the description of PDHG in (Hein et al., 2013), each iteration takesO(mk log k) time. Hence, when n m, each iteration of SG will be significantly faster, although in general, the number of iterations required by the subgradient method can be larger than that for PDHG.\nTesting Methodology. In each experiment, we consider the hypergraph from one of the above three datasets. We pick l = 160 vertices at random as the labeled vertices L, and form the corresponding convex program (CP1) for the two solvers, where the initial values for unlabeled vertices are chosen independently to be uniformly at random from [\u22121, 1]. To compare the performance, we run the two solvers on the same convex program, and record each trajectory of the objective value versus the time duration. According to experience, 100 seconds is good enough for either solver to reach an almost optimal solution, and we use the minimum value achieved by the two solvers after 100 seconds as an estimate for the true optimal value OPT. Then, we scan each trajectory, and for each relative gap\n\u2208 {10\u2212i : i = 1, 2, . . . , 6}, we find the smallest time T ( ) after which the objective value is at most OPT away from the estimate OPT. Each instance of the experiment is repeated 100 times (with different sets of labeled vertices) to obtain an average of those T ( )\u2019s and their standard error. For each relative gap , we also report the test error for using a feasible solution that is OPT away from the presumed optimal value OPT.\nResults. Both solvers have similar performance. As predicted by our theoretical analysis, we see in Figure 5.2 that SG has an advantage when the number n of vertices is much larger than the number m of edges, which is the case for the the last dataset covertype67. Moreover, in Figure 5.3, we see that achieving a relative gap smaller than 10\u22124 has almost no effect on improving the prediction accuracy. Hence, we can conclude that for either solver, it takes roughly 10 to 20 seconds to produce a solution for the underlying convex program that can give good predic-\ntion accuracy."}, {"heading": "5.3. Directed Hypergraph: More Powerful", "text": "DBLP Dataset. We use the DBLP (Ley, 2009) dataset. Each paper is represented by a vertex. We include papers from year 2000 to 2015 from conferences belonging to the following research areas to conduct our experiments:\n\u2022 7049 papers from machine learning (ML): NIPS, ICML \u2022 2539 papers from theoretical computer science (TCS): STOC, FOCS \u2022 3374 papers from database (DB): VLDB, SIGMOD\nWe perform the following prediction tasks: (a) ML (+1) vs TCS (-1), and (b) ML (+1) vs DB (-1).\nThe details of the experiment setup and the results are given in the full version."}], "year": 2017, "references": [{"title": "Higher order learning with graphs", "authors": ["Agarwal", "Sameer", "Branson", "Kristin", "Belongie", "Serge"], "venue": "In Proceedings of the 23rd international conference on Machine learning,", "year": 2006}, {"title": "Directed hypergraphs and applications", "authors": ["Gallo", "Giorgio", "Longo", "Giustino", "Pallottino", "Stefano", "Nguyen", "Sang"], "venue": "Discrete applied mathematics,", "year": 1993}, {"title": "Laplacian sparse coding, hypergraph laplacian sparse coding, and applications", "authors": ["Gao", "Shenghua", "Tsang", "Ivor Wai-Hung", "Chia", "LiangTien"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,", "year": 2013}, {"title": "Clustering categorical data: An approach based on dynamical systems", "authors": ["Gibson", "David", "Kleinberg", "Jon", "Raghavan", "Prabhakar"], "year": 1998}, {"title": "The total variation on hypergraphs-learning on hypergraphs revisited", "authors": ["Hein", "Matthias", "Setzer", "Simon", "Jost", "Leonardo", "Rangapuram", "Syama Sundar"], "venue": "In Advances in Neural Information Processing Systems,", "year": 2013}, {"title": "Image retrieval via probabilistic hypergraph ranking", "authors": ["Huang", "Yuchi", "Liu", "Qingshan", "Zhang", "Shaoting", "Metaxas", "Dimitris N"], "venue": "In Computer Vision and Pattern Recognition (CVPR),", "year": 2010}, {"title": "Dblp: some lessons learned", "authors": ["Ley", "Michael"], "venue": "Proceedings of the VLDB Endowment,", "year": 2009}, {"title": "Hypergraph markov operators, eigenvalues and approximation algorithms", "authors": ["Louis", "Anand"], "venue": "In Proceedings of the Forty-Seventh Annual ACM on Symposium on Theory of Computing,", "year": 2015}, {"title": "Hypernode graphs for spectral learning on binary relations over sets", "authors": ["Ricatte", "Thomas", "Gilleron", "R\u00e9mi", "Tommasi", "Marc"], "venue": "In Joint European Conference on Machine Learning and Knowledge Discovery in Databases,", "year": 2014}, {"title": "Minimization Methods for Non-differentiable Functions", "authors": ["N.Z. Shor", "Kiwiel", "Krzysztof C", "Ruszcay\u01f9ski", "Andrzej"], "year": 1985}, {"title": "Hypergraph spectral learning for multi-label classification", "authors": ["Sun", "Liang", "Ji", "Shuiwang", "Ye", "Jieping"], "venue": "In Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining,", "year": 2008}, {"title": "Mapping users across networks by manifold alignment on hypergraph", "authors": ["Tan", "Shulong", "Guan", "Ziyu", "Cai", "Deng", "Qin", "Xuzhen", "Bu", "Jiajun", "Chen", "Chun"], "venue": "In AAAI,", "year": 2014}, {"title": "Nonlinear laplacian for digraphs and its applications to network analysis", "authors": ["Yoshida", "Yuichi"], "venue": "In Proceedings of the Ninth ACM International Conference on Web Search and Data Mining,", "year": 2016}, {"title": "Adaptive hypergraph learning and its application in image classification", "authors": ["Yu", "Jun", "Tao", "Dacheng", "Wang", "Meng"], "venue": "IEEE Transactions on Image Processing,", "year": 2012}, {"title": "Learning with hypergraphs: Clustering, classification, and embedding", "authors": ["Zhou", "Dengyong", "Huang", "Jiayuan", "Sch\u00f6lkopf", "Bernhard"], "venue": "In Advances in neural information processing systems,", "year": 2006}, {"title": "Semi-supervised learning using gaussian fields and harmonic functions", "authors": ["Zhu", "Xiaojin", "Ghahramani", "Zoubin", "Lafferty", "John D"], "venue": "In ICML,", "year": 2003}], "id": "SP:247d928063a419f32ac86f18c774e4a34bb40ca0", "authors": [{"name": "Chenzi Zhang", "affiliations": []}, {"name": "Shuguang Hu", "affiliations": []}, {"name": "Zhihao Gavin Tang", "affiliations": []}, {"name": "Hubert Chan", "affiliations": []}], "abstractText": "We revisit semi-supervised learning on hypergraphs. Same as previous approaches, our method uses a convex program whose objective function is not everywhere differentiable. We exploit the non-uniqueness of the optimal solutions, and consider confidence intervals which give the exact ranges that unlabeled vertices take in any optimal solution. Moreover, we give a much simpler approach for solving the convex program based on the subgradient method. Our experiments on real-world datasets confirm that our confidence interval approach on hypergraphs outperforms existing methods, and our sub-gradient method gives faster running times when the number of vertices is much larger than the number of edges.", "title": "Re-revisiting Learning on Hypergraphs:  Confidence Interval and Subgradient Method"}
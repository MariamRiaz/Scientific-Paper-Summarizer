16	55	In other words, assuming that the author of statement (1) is truthful, event contracted occurred with AGENT John and THEME the disease, but the MANNER (or TIME) may not have been when a mouse bit him in the Adirondacks.
17	54	A key feature of the work presented in this paper is that the interpretations extracted from modal constructions are not tied to any syntactic or semantic representation.
65	15	OntoNotes is a large corpus containing 63,918 sentences.
77	17	Convert negated verb-argument structures into their positive counterparts.
89	25	We remove all tokens in the original sentence except verb and tokens belonging to the roles in sem roles.
92	16	Generate additional normalizations.
93	49	If verb is followed by TO + verb2 (e.g., want to go, like to play, intend to pass), we generate an additional normalization for verb2 after merging the semantic roles of verb and verb2.
94	28	Table 1 exemplifies the automatic normalization step by step with 2 modal constructions.
99	38	The total number of potential interpretations for the 324 selected modal construction is 1,756 (average: 5.4).
112	37	Semantic roles toggled off are replaced with a semantically related substitute (Turney and Pantel, 2010) for the original role, e.g., give: take, customer: sales associate.
113	33	The total number of modal constructions selected is 324 and the number of potential interpretations automatically generated in 1,756 (average: 5.4 interpretation per modal construction).
114	42	39.4% of interpretations are scored with a high degree of certainty.
119	21	The percentage of interpretations annotated with a score different than 0 depends greatly on the number of roles toggled off (Table 2): 0: 87.25%, 1: 48.50%, 2: 20.46%, 3: 5.83%.
121	48	Most interpretations have either ARG0 or ARG1 toggled off (Table 3), and the percentages of interpretations not scored zero range from 20% to 32.84% depending on the semantic role.
129	51	After reading the three sentences, it is clear that they are making wild statements, and are hoping to get attention for it.
132	23	This low score is justified by item (3) in our annotation guidelines: replacing wild statements with a semantically (different but) related substitute, e.g., But they chose reasonable statements / good manners to get our attention and that of the international community, yields an unlikely interpretation.
134	146	Interpretation 2.1, We will find them one day receives a high score (4/5), as given the context (and assuming that Rumsfeld is truthful), it is very likely that they will find the weapons of mass destruction, but it is not guaranteed.
140	53	In interpretation 3.1, {ARG0} will act in the interests of the minority holders, ARG0 can be replaced with a company with several minority holders, yielding a valid interpretation scored 4 (out of 5).
141	39	Similarly, in interpretation 3.2, A company with a big majority holder will act {ARG1}, ARG1 can be replaced with in the interests of the big majority holder, yielding another valid interpretation also scored 4 (out of 5).
142	23	Finally, Example (4) shows Step 5 in the automatic normalization procedure (Section 4).
159	16	We include the number of roles toggled off to generate the potential interpretation, and binary flags indicating which roles.
160	22	Additionally, for each role toggled off, we include the distance from the verb (number of tokens), whether it occurs before or after the verb, the syntactic path to the verb and the length of the path.
163	34	They yield Pearson correlations of −0.029 and 0.025 individually, and −0.013 combined.
171	24	First, we automatically generate potential interpretations using syntactic dependencies and semantic roles, and then assign to them a factuality score.
172	35	The most important conclusion of the work presented here is that several interpretations automatically generated from a single modal construction often receive scores indicating high certainty.
173	49	Indeed, on average, modal constructions have 2.13 interpretations scored lower or equal than −3, or higher or equal than 3.
174	22	This contrast with previous work, which only assess factuality of one normalization per proposition.
175	22	Experimental results using supervised machine learning and relatively simple features show that the task is challenging but can be automated.
176	35	We believe better results could be obtained by incorporating features capturing knowledge in the context of the modal construction, including other clauses in the same sentence, and the previous and next sentences.
177	23	Another extension of the current work is to investigate a similar approach for other modality markers such as nouns (e.g., possibility, chance), adjectives (e.g.necessary, probable, ) and certain verbs (e.g., claim, suggests).

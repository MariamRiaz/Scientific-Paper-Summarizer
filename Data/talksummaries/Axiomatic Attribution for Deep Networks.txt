0	17	We study the problem of attributing the prediction of a deep network to its input features.
3	33	, an) ∈ Rn where ai is the contribution of xi to the prediction F (x).
4	24	For instance, in an object recognition network, an attribution method could tell us which pixels of the image were responsible for a certain label being picked (see Figure 2).
5	20	The attribution problem was previously studied by various papers (Baehrens et al., 2010; Simonyan et al., 2013; Shrikumar et al., 2016; Binder et al., 2016; Springenberg et al., 2014).
99	15	(This is less of a concern with linear or logistic models where the simplicity of the model ensures that ablating a feature does not cause strange interactions.)
104	23	This was why we turned to an axiomatic approach in designing a good attribution method (Section 2).
132	20	Integrated gradients correspond to a cost-sharing method called AumannShapley (Aumann & Shapley, 1974).
140	24	For instance, x and y are symmetric w.r.t.
156	36	Even if one samples few paths randomly, evaluating the attributions for a single path takes n calls to the deep network.
158	157	Further, the Shapley-Shubik computation visit inputs that are combinations of the input and the baseline.
160	39	We speculate that this could lead to attribution artifacts.
161	37	A key step in applying integrated gradients is to select a good baseline.
163	47	But there is more to a good baseline: For instance, for an object recogntion network it is possible to create an adversarial example that has a zero score for a given input label (say elephant), by applying a tiny, carefully-designed perturbation to an image with a very different label (say microscope) (cf.
164	14	The attributions can then include undesirable artifacts of this adversarially constructed baseline.
165	25	So we would additionally like the baseline to convey a complete absence of signal, so that the features that are apparent from the attributions are properties only of the input, and not of the baseline.
177	14	For instance, in TensorFlow, it amounts to calling tf.gradients in a loop over the set of inputs (i.e., x′ + km × (x − x ′) for k = 1, .
179	28	In practice, we find that somewhere between 20 and 300 steps are enough to approximate the integral (within 5%); we recommend that developers check that the attributions approximately adds up to the difference beween the score at the input and that at the baseline (cf.
185	22	The gradients are computed for the output of the highest-scoring class with respect to pixel of the input image.
186	30	The baseline input is the black image, i.e., all pixel intensities are zero.
195	27	Feature importance explanations are important for this network as retina specialists may use it to build trust in the network’s predictions, decide the grade for borderline cases, and obtain insights for further testing and screening.
198	29	We aggregate integrated gradients along the color channel and overlay them on the actual image in gray scale with positive attribtutions along the green channel and negative attributions along the red channel.
211	28	The baseline input is the all zero embedding vector.
222	23	“und” is mostly attributed to “and”, and “morgen” is mostly attributed to “morning”.
223	22	Section 5) in the integrated gradient approximation; we need this because the network is highly nonlinear.
238	32	This is surprising as one would expect two atoms with different neighborhoods to be treated differently by the network.
239	41	On investigating the problem further, in the network architecture, the atoms and atom-pair features were not fully convolved.
261	24	The axiomatic approach rules out artifacts of the last type.
262	20	While our and other works have made some progress on understanding the relative importance of input features in a deep network, we have not addressed the interactions between the input features or the logic employed by the network.
263	16	So there remain many unanswered questions in terms of debugging the I/O behavior of a deep network.
264	127	We would like to thank Samy Bengio, Kedar Dhamdhere, Scott Lundberg, Amir Najmi, Kevin McCurley, Patrick Riley, Christian Szegedy, Diane Tang for their feedback.

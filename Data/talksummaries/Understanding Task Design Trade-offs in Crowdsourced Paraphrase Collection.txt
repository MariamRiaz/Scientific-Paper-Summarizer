8	7	We have released all 2,600 paraphrases along with accuracy annotations.
18	7	The only prior work regarding incentives we are aware of is by Chklovski (2005), who collected paraphrases in a game where the goal was to match an existing paraphrase, with extra points awarded for doing so with fewer hints.
22	14	This priming can result in systematic variations in the resulting paraphrases.
32	15	We conducted a series of experiments to investigate factors in crowdsourced paraphrase creation.
35	66	We consider two sentences paraphrases if they would have equivalent interpretations when represented as a structured query, i.e., ”a pair of units of text deemed to be interchangeable” (Dras, 1999).
37	7	Are there any four credit upper-level classes?
42	16	We used Amazon Mechanical Turk, presenting workers with the instructions and examples in Figure 1.
46	25	Workers were paid 5 cents per paraphrase they wrote plus, once all workers were done, a 5 cent bonus for paraphrases that matched another worker’s paraphrase in the same condition.
49	20	Examples We provided workers with an example prompt sentence and two paraphrases, as shown in Figure 1.
50	12	We showed either: no examples (No Examples), two examples with lexical changes only (Lexical Examples), one example with lexical changes and one with syntactic changes (Mixed Examples), or two examples that each contained both lexical and syntactic changes (Baseline).
52	42	Incentive The 5 cent bonus payment per paraphrase was either not included (No Bonus), awarded for each sentence that was a duplicate at the end of the task (Baseline), or awarded for each sentence that did not match any other worker’s paraphrase (Novelty Bonus).
53	14	Bonuses that depend on other workers’ actions may encourage either creativity or conformity.
55	25	Workflow We considered three variations to workflow.
56	31	First, for each sentence, we either asked workers to provide two paraphrases (Baseline), or one (One Paraphrase).
59	11	Third, we started all conditions with the same set of prompt sentences, but once workers had produced paraphrases, we had the option to either prompt future workers with the original prompt, or to use paraphrase from another worker.
61	26	We prompted workers with either the original sentences only (Baseline), or formed a chain structured graph by randomly choosing a sentence that was (1) not a duplicate, and (2) furthest from the original sentence (Chain).
62	34	These changes could impact paraphrasing because the prompt sentence is a form of priming.
63	97	Data domains We ran with five data sources: questions about university courses (Baseline), messages from dialogues between two students in a simulated academic advising session (ADVISING), questions about US geography (GEOQUERY Tang and Mooney, 2001), text from the Wall Street Journal section of the Penn Treebank (WSJ Marcus et al., 1993), and discussions on the Ubuntu IRC channel (UBUNTU).
64	68	We randomly selected 20 sentences as prompts from each data source with the lengths representative of the sentence length distribution in that source.
65	72	Semantic Equivalence For a paraphrase to be valid, its meaning must match the original sentence.
66	26	To assess this match, two of the authors— one native speaker and one non-native but fluent speaker—rated every sentence independently, then discussed every case of disagreement to determine a consensus judgement.
68	23	For the results in Table 1, we used a χ2 test to measure significance, since this is a binary classification process.
72	12	We measured the time between when a worker submitted one pair of paraphrases and the next.
73	95	The first paraphrase was excluded since it would skew the data by including the time spent reading the instructions and understanding the task.
74	43	We report the median time to avoid skewing due to outliers, e.g. a value of five minutes when a worker probably took a break.
76	11	Diversity We use two metrics for diversity, measured over correct sentences only.
78	19	Second, a measure of n-gram diversity (PINC Chen and Dolan, 2011)1.
81	11	We collected 2600 paraphrases: 10 paraphrases per sentence, for 20 sentences, for each of the 13 conditions.
83	27	Table 1 shows the results for all metrics.
84	64	Qualitatively, we observed a wide variety of lexical and syntactic changes, as shown by these example prompts and paraphrases (one low PINC and one high PINC in each case): Prompt: How long has EECS 280 been offered for?

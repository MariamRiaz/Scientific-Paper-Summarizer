{"sections": [{"heading": "1. Introduction", "text": "Hypothesis testing is a widely applied statistical tool used to test whether given models should be rejected, or not, based on sampled data from a population. Hypothesis testing was initially developed for scientific and survey data, but today it is also an essential tool to test models over collections of social network, mobile, and crowdsourced data (American Statistical Association, 2014; Hunter et al., 2008; Steele et al., 2017). Collected data samples may contain highly sensitive information about the subjects, and the privacy of individuals can be compromised when the results of a data analysis are released. A way to address this concern is by developing new techniques to support privacy-preserving data analysis. Among the different approaches, differential privacy (Dwork et al., 2006b) has emerged as a viable solution: it provides strong privacy guarantees and it allows to release accurate statistics. A standard way to achieve differential privacy is by injecting some statistical noise in the computation of the data analysis. When the noise is carefully chosen, it helps to protect the individual privacy without compromising the utility of the data analysis. Several recent works have studied differentially private hypothesis tests\n*Equal contribution 1 University at Buffalo, Buffalo, NY, USA 2University of Pennsylvania, Philadelphia, PA, USA. Correspondence to: Marco Gaboardi <gaboardi@buffalo.edu>.\nProceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).\nthat can be used in place of the standard, non-private hypothesis tests (Uhler et al., 2013; Yu et al., 2014; Sheffet, 2015; Karwa & Slavkovic\u0301, 2016; Wang et al., 2015; Gaboardi et al., 2016; Kifer & Rogers, 2017; Cai et al., 2017). These tests work in the curator model of differential privacy. In this model, the data is centrally stored and the curator carefully injects noise in the computation of the data analysis in order to satisfy differential privacy.\nIn this work we instead address the local model of privacy, formally introduced by Raskhodnikova et al. (2008). The first differentially private algorithm called randomized response \u2013 in fact it predates the definition of differential privacy by more than 40 years \u2013 guarantees differential privacy in the local model (Warner, 1965). In this model, there is no trusted centralized entity that is responsible for the noise injection. Instead, each individual adds enough noise to guarantee differential privacy for their own data, which provides a stronger privacy guarantee than the curator model. The data analysis is then run over the collection of the individually sanitized data. The local model of differential privacy is a convenient model for several applications: for example it is used to collect statistics about the activity of the Google Chrome Web browser users (Erlingsson et al., 2014), and to collect statistics about the typing patterns of Apple\u2019s iPhone users (Apple Press Info, 2016). Despite these applications, the local model has received far less attention than the centralized curator model. This is in part due to the more firm requirements imposed by this model, which make the design of effective data analysis harder.\nOur main contribution is in designing chi-square hypothesis tests for the local model of differential privacy. Similar to previous works we focus on goodness of fit and independence hypothesis tests. Most of the private chi-square tests proposed so far are based on mechanisms that add noise in some form to the aggregate data, e.g. the cells of the contingency tables, or the resulting chi-square statistics value. These approaches cannot be used in the local model, since noise needs to be added at the individual\u2019s data level. We then consider instead general privatizing techniques in the local model, and we study how to build new hypothesis tests with them. Each test we present is characterized by a specific local model mechanism. The main technical challenge for designing each test is to create statistics, which incorporate the local model mechanisms, that converge as\nwe collect more data to a chi-square distribution, as in the classical chi-square tests. We then use these statistics to find the critical value to correctly bound the Type I error.\nWe present three different goodness of fit tests: LocalNoiseGOF presents a statistic that guarantees the convergence to a chi-square distribution under the null hypothesis so that we can use the correct critical values when local (concentrated) differential privacy is guaranteed by adding Laplace or Gaussian noise to the individual data; LocalGenRRGOF also provides a statistic that converges to a chi-square under the null hypothesis when a private value for each individual is selected by using a generalized form of randomized response, which can also be thought of as an instantiation of the exponential mechanism (McSherry & Talwar, 2007); finally, LocalBitFlipGOF introduces a statistic that converges to a chi-square distribution when the data is privatized using a bit flipping algorithm (Bassily & Smith, 2015), which provide better accuracy for higher dimensional data. Further, we develop corresponding independence tests: LocalNoiseIND (see supplementary file), LocalGenRRIND, and LocalBitFlipIND. For all these tests we study their asymptotic behavior. A desiderata for private hypothesis tests is to have a guaranteed upper bound on the probability of a false discovery (or Type I error) \u2013 rejecting a null hypothesis or model when the data was actually generated from it \u2013 and to minimize the probability of a Type II error, which is failing to reject the null hypothesis when the model is indeed false. This latter criteria corresponds to the power of the statistical test. We then present experimental results showing the power of the different tests which demonstrates that no single local differentially private algorithm is best across all data dimensions and privacy parameter regimes. However, this evaluation also shows a relation between the power of the test and the noncentral parameter of the test statistic that is used. This suggests that besides looking at the parameters of the test, a data analyst may need also to consider which test statistic results in the largest noncentral parameter."}, {"heading": "2. Related Works", "text": "There have been several works in developing private hypothesis test for categorical data, but all look at the traditional model of (concentrated) differential privacy instead of the local model, which we consider here. Several works have explored private statistical inference for GWAS data, (Uhler et al., 2013; Yu et al., 2014; Johnson & Shmatikov, 2013). Following these works, there has also been general work in private chi-square hypothesis tests, where the main tests are for goodness of fit and independence testing, although some do extend to more general tests (Wang et al., 2015; Gaboardi et al., 2016; Kifer & Rogers, 2017; Cai et al., 2017; Kakizaki et al., 2017). Among these, the works most related to\nours are the ones by Gaboardi et al. (2016); Kifer & Rogers (2017). One of our mechanisms, LocalNoiseGOF, can be seen as an adaptation of their techniques to the local model. However, the other mechanisms we introduce differ substantially and require novel asymptotic analyses. There has also been work in private hypothesis testing for ordinary least squares regression (Sheffet, 2015).\nDuchi et al. (2013b;a) focus on controlling disclosure risk in statistical estimation and inference by ensuring the analysis satisfies local differential privacy. In their work, they show that a generalized version of randomized response gives optimal sample complexity for estimating the multinomial probability vector. We use this idea as the basis for our hypothesis test LocalBitFlipGOF. Kairouz et al. (2014) also considers hypothesis testing in the local model, although they measure utility in terms of f -divergences and do not give a decision rule, i.e. when to reject a given null hypothesis. We provide statistics whose distributions asymptotically follow a chi-square distribution, which allows for approximating statistical p-values that can be used in a decision rule. We consider their extremal mechanisms and empirically confirm their result that for small privacy regimes (small ) one mechanism has higher utility than other mechanisms and for large privacy regimes (large ) a different mechanism outperforms the other. However, we measure utility in terms of the power of a locally private hypothesis test subject to a given Type I error bound. Other notable works in the local privacy model include Pastore & Gastpar (2016); Kairouz et al. (2016); Ye & Barg (2017)\nIndependent of this work, another paper (Sheffet, 2018) has addressed local private hypothesis testing. Sheffet (2018) considers finite sample complexity by showing certain test quantities take different values under the null- and alternative-hypothesis. In this work, we design and analyze asymptotic statistical tests and empirically evaluate the performance of each test for finite samples."}, {"heading": "3. Preliminaries", "text": "We consider datasets x = (x1, \u00b7 \u00b7 \u00b7 , xn) \u2208 Xn in some data universe X , typically X = {0, 1}d where d is the dimensionality. We first present the standard definition of differential privacy, as well as its variant concentrated differential privacy. We say that two datasets x,x\u2032 \u2208 Xn are neighboring if they differ in at most one element, i.e. \u2203i \u2208 [n] such that xi 6= x\u2032i and \u2200j 6= i, xj = x\u2032j . Definition 3.1 (Dwork et al. (2006b;a)). An algorithm M : Xn \u2192 Y is ( , \u03b4)-differentially private (DP) if for all neighboring datasets x,x\u2032 \u2208 Xn and for all outcomes S \u2286 Y , we have Pr [M(x) \u2208 S] \u2264 e Pr [M(x\u2032) \u2208 S] + \u03b4. Definition 3.2 (Bun & Steinke (2016)). An algorithm M : Xn \u2192 Y is \u03c1-zero-mean concentrated differentially private (zCDP) if for all neighboring datasets\nx,x\u2032 \u2208 Xn, we have the following bound for all t > 0 where the expectation is over outcomes y \u223c M(x), E [ exp ( t ( ln (\nPr[M(x)=y] Pr[M(x\u2032)=y]\n) \u2212 \u03c1 ))] \u2264 et2\u03c1.\nNote that in both of these privacy definitions, it is assumed that all the data is stored in a central location and the algorithm M can access all the data. Most of the work in differential privacy has been in this trusted curator model. We then define local differential privacy, formalized by Raskhodnikova et al. (2008) and Dwork & Roth (2014), which does not require the subjects to release their raw data, rather each data entry is perturbed to prevent the true entry from being stored. Thus, local differential privacy ensures one of the strongest privacy guarantees. Definition 3.3 (LR Oracle). Given a dataset x, a local randomizer oracle LRx(\u00b7, \u00b7) takes as input an index i \u2208 [n] and an -DP algorithm R, and outputs y \u2208 Y chosen according to the distribution of R(xi), i.e. LRx(i, R) = R(xi).\nDefinition 3.4 (Raskhodnikova et al. (2008)). An algorithm M : Xn \u2192 Y is ( , \u03b4)-local differentially private (LDP) if it accesses the input database x via the LR oracle LRx with the following restriction: if LR(i, Rj) for j \u2208 [k] areM\u2019s invocations of LRx on index i, then each Rj for j \u2208 [k] is ( j , \u03b4j)- DP and \u2211k j=1 j \u2264 , \u2211k j=1 \u03b4j \u2264 \u03b4.\nFrom this we have that a ( , \u03b4)-LDP algorithm is also ( , \u03b4)DP. Note that these definitions can be extended to include \u03c1-local zCDP (LzCDP) where each local randomizer is \u03c1jzCDP and \u2211k j=1 \u03c1j \u2264 \u03c1. We point out the following connection between LzCDP and LDP , which follows directly from results in (Bun & Steinke, 2016) Lemma 3.5. If M : Xn \u2192 Y is ( , 0)-LDP then it is also 2/2-LzCDP. If M is \u03c1-LzCDP, then it is also(( \u03c1+ \u221a 2\u03c1 ln(2/\u03b4) ) , \u03b4 ) -LDP for any \u03b4 > 0."}, {"heading": "4. Chi-Square Hypothesis Tests", "text": "As was studied in (Gaboardi et al., 2016), (Wang et al., 2015), and (Kifer & Rogers, 2017), we will study hypothesis tests with categorical data. A null hypothesis, or model H0 is how we might expect the data to be generated. The goal for hypothesis testing is to reject the null hypothesis if the data is not likely to have been generated from the given model. As is common in statistical inference, we want to design hypothesis tests to bound the probability of a false discovery (or Type I error), i.e. rejecting a null hypothesis when the data was actually generated from it, by at most some amount \u03b1, such as 5%. However, designing tests that achieve this is easy, because we can just ignore the data and always fail to reject the null hypothesis, i.e. have an inconclusive test. Thus, we want additionally to design our tests so that they can reject H0 if the data was not actually generated from the given model. We then want to minimize\nthe probability of a Type II error, which is failing to reject H0 when the model is false, subject to a given Type I error.\nFor goodness of fit testing, we assume that each individual\u2019s dataX i for i \u2208 [n] is sampled i.i.d. from Multinomial(1, p) where p \u2208 Rd>0 and p\u1d40 \u00b7 1 = 1. The classical chi-square hypothesis test (without privacy) forms the histogramH = (H1, \u00b7 \u00b7 \u00b7 , Hd) = \u2211n i=1X i and computes the chi-square\nstatistic T = \u2211d j=1 (Hj\u2212np0j) 2\nnp0j . The reason for using this\nstatistic is that it converges in distribution to \u03c72d\u22121 as more data is collected, i.e. n \u2192 \u221e, when H0 : p = p0 holds. Hence, we can ensure the probability of false discovery to be close to \u03b1 as long as we only reject H0 when T > \u03c72d\u22121,1\u2212\u03b1 where the critical value \u03c72d\u22121,1\u2212\u03b1 is defined as the following\nquantity Pr [ \u03c72d\u22121 > \u03c7 2 d\u22121,1\u2212\u03b1 ] = \u03b1.\nPrior Private Chi-square Tests in the Curator Model. One approach for chi-square private hypothesis tests is to add noise (Gaussian or Laplace) directly to the histogram to ensure privacy and then use the classical test statistic (Gaboardi et al., 2016; Wang et al., 2015) . Note that the resulting asymptotic distribution needs to be modified for such changes to the statistic \u2013 it is no longer a chi-square random variable. To introduce the different statistics, we will consider goodness of fit testing after adding noise Z from distribution Dn to the histogram of counts H\u0303 = H + Z , which ensures \u03c1-zCDP when D = N (0, 1/\u03c1) and -DP whenD = Lap(2/ ). The chi-square statistic then becomes\nT\u0303 (D) = d\u2211 i=1\n( Hi + Zi \u2212 np0i )2 np0i where Z \u223c Dn. (1)\nThe previous works then show that this statistic converges in distribution to a linear combination of chi-squared variables, when D \u223c N (0, 1/\u03c1) and \u03c1 is also decreasing with n.\nKifer & Rogers (2017) showed that modifying the chisquare statistic to account for the additional noise leads to tests with better empirical power. The projected statistic from Kifer & Rogers (2017) is the following where we use projection matrix \u03a0 defn= ( Id \u2212 1d11 \u1d40 ) , middle ma-\ntrix M\u03c3 = \u03a0 ( Diag ( p0 + \u03c3 ) \u2212 p0 ( p0 )\u1d40)\u22121\n\u03a0, and sample noise Z \u223c Dn, with H\u0302 = H +Z\nT (n) KR (\u03c3;D) = n\n( H\u0302\nn \u2212 p0\n)\u1d40 M\u03c3 ( H\u0302\nn \u2212 p0\n) (2)\nWe use D = Lap(2/ ) with \u03c3 = 8n 2 for an -DP claim or D = N (0, 1/\u03c1) with \u03c3 = 1n\u03c1 for a \u03c1-zCDP claim. When comparing the power of all our tests, we will be considering the alternate H1 : p = p1n where p1n = p 0 + \u2206\u221a n where 1\u1d40\u2206 = 0.\nTheorem 4.1 (Kifer & Rogers (2017)). Under the null hypothesis H0 : p = p0, the statistic T (n) KR ( 1 n\u03c1 ; N (0, 1/\u03c1) ) given in (2) for \u03c1 > 0 converges in distribution to \u03c72d\u22121. Further, under the alternate hypothesis H1 : p = p1n, the resulting asymptotic distribution is a noncentral chi-square random variable with d\u2212 1 degrees of freedom and noncentral parameter \u2206\u1d40 ( Diag(p0)\u2212 p0 ( p0 )\u1d40 + 1/\u03c1Id )\u22121 \u2206\nWhen D = Lap(2/ ), Gaboardi et al. (2016) showed that we can still obtain the null hypothesis distribution using Monte Carlo simulations to estimate the critical value, since the asymptotic distribution will no longer be chi-square. That is, we can obtainm samples from the statistic under the null hypothesis with Laplace noise added to the histogram of counts. We can then guarantee that the probability of a false discovery is at most \u03b1 as long as m > d1/\u03b1e."}, {"heading": "5. Local Private Goodness of Fit", "text": "We now turn to designing local private goodness of fit tests. We first show how the existing statistics from the previous section can be adapted to the local setting and then develop new tests based on the generalized randomized response mechanism that returns one of d > 1 categories and bit flipping (Bassily & Smith, 2015). Each test is locally private because it perturbs each individual\u2019s data through a local randomizer. However, each of them has a different asymptotic behavior and so we need different analyses to identify the different critical values. We empirically check the power of each test to see which tests outperform others in different parameter regimes. An interesting result of this analysis is that the power of a test is directly related to the size of the noncentral parameter of the chi-square statistic under the alternate distribution.\nTesting with Noise Addition. In the local model we can add Z i \u223c N ( 0, 1\u03c1 Id ) independent noise to each individual\u2019s data X i to ensure \u03c1-LzCDP or Z i i.i.d.\u223c Lap ( 2 ) independent noise toX i to ensure -LDP. In either case, the resulting noisy histogram H\u0302 = H +Z where Z = \u2211 iZ i will have variance that scales with n for fixed privacy parameters , \u03c1 > 0. Consider the case where we add Gaussian noise, which results in the following histogram, H\u0302 = H+Z where Z \u223c N ( 0, n\u03c1 Id ) . Thus, we can use either statistic T\u0303 (\u03c1/n) or T(n)KR (\u03c1/n), with the latter statistic typically having better empirical power (Kifer & Rogers, 2017). We then give our first local private hypothesis test in Algorithm 1.\nTheorem 5.1. LocalNoiseGOF is \u03c1-LzCDP when D = N (0, 1/\u03c1) and -LDP when D = Lap(2/ ).\nAlthough we cannot guarantee the probability of a Type I error at most \u03b1 due to the fact that we use the asymptotic\nAlgorithm 1 Locally Private GOF Test:LocalNoiseGOF\nInput: x = (x1, \u00b7 \u00b7 \u00b7 ,xn), \u03c1, \u03b1, H0 : p = p0. LetH = \u2211n `=1 x`\nif D = N (0, n/\u03c1) then Set q = T(n)KR (n/\u03c1;D) given in (2). if q > \u03c72d\u22121,1\u2212\u03b1 Decision\u2190 Reject. else Decision\u2190 Fail to Reject. end if if D = \u2211n i=1 Lap(2/ ) then\nSet q = T(n)KR ( 8n/ 2;D ) given in (2). Sample m > d1/\u03b1e from the distribution of T\n(n) KR\n( 8n/ 2;D ) assuming H0\nSet \u03c4 to be the d(m+ 1)(1\u2212 \u03b1)eth largest sample. if q > \u03c4 Decision\u2190 Reject. else Decision\u2190 Fail to Reject.\nend if Output: Decision\ndistribution (as in the tests from prior work and the classical chi-square tests without privacy), we expect the Type I errors to be similar to those from the nonprivate test. Note that the test can be modified to accommodate arbitrary noise distributions, e.g. Laplace to ensure differential privacy. In this case, we can use a Monte Carlo (MC) approach to estimate the critical value \u03c4 that ensures the probability of a Type I error is at most \u03b1 if we reject H0 when the statistic is larger than \u03c4 . For the local setting, if each individual perturbs each coordinate by adding Lap (2/ ) then this will ensure our test is -LDP. However, the sum of independent Laplace random variables is not Laplace, so we will need to estimate a sum of n independent Laplace random variables using MC. We can do this by sampling m entries from the exact distribution under H0 to find the critical value. In the experiments section we will use this method to compare the power of the other local private tests with the one of the version of LocalNoiseGOF using Laplace noise, which has a better power than the one using Gaussian noise.\nTesting with Generalized Randomized Response. Rather than having to add noise to each component of the original histogram, we consider applying randomized response to obtain a LDP hypothesis test. We will use a generalized form of randomized response given in Algorithm 2 which takes a single data entry from the set {e1, \u00b7 \u00b7 \u00b7 , ed}, where ej \u2208 Rd is the standard basis element with a 1 in the jth coordinate and is zero elsewhere, and reports the original entry with probability slightly more than uniform and otherwise reports a different element with equal probability. Note thatMGenRR is -DP.\nWe have the following result when we useMGenRR on each data entry to obtain a private histogram.\nAlgorithm 2 Generalized Randomized Response:MGenRR Input: x \u2208 {e1, \u00b7 \u00b7 \u00b7 , ed}, .\nLet q(x,z) = 1{x = z} Select x\u030c with probability exp[ q(x,x\u030c)]e \u22121+d\nOutput: x\u030c\nLemma 5.2. If we have histogram H = \u2211n i=1X i, where {X i} i.i.d.\u223c Multinomial(1, p) and we write H\u030c =\u2211n\ni=1MGenRR(X i, ) for each i \u2208 [n], then H\u030c \u223c Multinomial(n, p\u030c) where\np\u030c = p\n( e\ne + d\u2212 1\n) + (1 \u2212 p) ( 1\ne + d\u2212 1\n) . (3)\nOnce we have H\u030c , we can create a chi-square statistic by subtracting H\u030c by its expectation and dividing the difference by the expectation. Hence testing H0 : p = p0 after the generalized randomized response mechanism, is equivalent to testing H0 : p = p\u030c0 with data H\u030c .\nWe can then form a chi-square statistic using the histogram H\u030c which will have the correct asymptotic distribution. Theorem 5.3. Let H \u223c Multinomial(n,p) and H\u030c be given in Theorem 5.2 with privacy parameter > 0. Under the null hypothesis H0 : p = p0, we have for p\u030c0 = 1e +d\u22121 ( e p0 + (1\u2212 p0) ) ,\nT (n) GenRR ( ) = d\u2211 j=1 (H\u030cj \u2212 np\u030c0j )2 np\u030c0j D\u2192 \u03c72d\u22121. (4)\nFurther, with alternate H1 : p = p1n, the resulting asymptotic distribution is a noncentral chi-square distribution with d \u2212 1 degrees of freedom and noncentral parameter,(\ne \u22121 e +d\u22121 )2\u2211d j=1 \u22062j p\u030c0j .\nWe then base our LDP goodness of fit test on this result to obtain the correct critical value to reject the null hypothesis based on a chi-square distribution. The test is presented in Algorithm 3. The following result is immediate from the\nAlgorithm 3 Local DP GOF Test: LocalGenRRGOF\nInput: x = (x1, \u00b7 \u00b7 \u00b7 ,xn), , \u03b1, H0 : p = p0. Let p\u030c0 = 1e +d\u22121 ( e p0 + (1\u2212 p0) ) .\nLet H\u030c = \u2211n i=1MGenRR(xi, ).\nSet q = \u2211d j=1 (H\u030cj\u2212np\u030c0j ) 2\nnp\u030c0j\nif q > \u03c72d\u22121,1\u2212\u03b1 Decision\u2190 Reject. else Decision\u2190 Fail to Reject.\nOutput: Decision\ngeneralized randomized response mechanism being -DP and the fact that we use it as a local randomizer.\nTheorem 5.4. LocalGenRRGOF is -LDP.\nTesting with Bit Flipping. Note that the noncentral parameter in Theorem 5.3 goes to zero as d grows large due\nto the coefficient being (\ne \u22121 e +d\u22121\n)2 . Thus, for large dimen-\nsional data the generalized randomized response cannot reject a false null hypothesis. We next consider another differentially private algorithmM : {e1, \u00b7 \u00b7 \u00b7 , ed} \u2192 {0, 1}d, given in Algorithm 4 used in (Bassily & Smith, 2015) that flips each bit with some biased probability. 1\nAlgorithm 4 Bit Flip Local Randomizer:Mbit Input: x \u2208 {e1, \u00b7 \u00b7 \u00b7 , ed}, .\nfor j \u2208 [d] do Set zj = xj with probability e /2\ne /2+1 , otherwise zj =\n(1\u2212 xj). end for\nOutput: z\nTheorem 5.5. The algorithmMbit is -DP.\nWe then want to form a statistic based on the output z \u2208 {0, 1}d that is asymptotically distributed as a chi-square under the null hypothesis. We defer the proof to the supplementary material.\nLemma 5.6. Consider X i \u223c Multinomial(1, p) for each i \u2208 [n]. We define the following covariance matrix \u03a3(p) and mean vector p\u0303 = [(\ne /2\u22121)p+1] e /2+1 , in terms of \u03b1 = ( e /2\u22121 e /2+1 ) \u03a3(p) =\u03b12 [Diag (p)\u2212 p (p) \u1d40 ] +\ne /2( e /2 + 1 )2 Id (5) The histogram H\u0303 = \u2211n i=1Mbit(X i) has the following\nasymptotic distribution \u221a n ( H\u0303 n \u2212 p\u0303 ) D\u2192 N (0,\u03a3(p)) . Further, \u03a3(p) is invertible for any > 0 and p > 0.\nFollowing a similar analysis in (Kifer & Rogers, 2017), we can form the following statistic for null hypothesis H0 : p = p0 in terms of the histogram H\u0303 and projection matrix \u03a0 = Id \u2212 1d11 \u1d40, as well as the covariance \u03a3 = \u03a3 ( p0 )\nand mean p\u03030 both given in (5) where we replace p with p0:\nT (n) BitFlip ( ) = n\n( H\u0303\nn \u2212 p\u03030\n)\u1d40 \u03a0\u03a3\u22121\u03a0 ( H\u0303\nn \u2212 p\u03030\n) (6)\nWe can then design a hypothesis test based on the outputs fromMbit in Algorithm 5 Theorem 5.7. LocalBitFlipGOF is -LDP.\n1Special thanks to Adam Smith for recommending to use this particular algorithm.\nAlgorithm 5 Local DP GOF Test: LocalBitFlipGOF\nInput: x = (x1, \u00b7 \u00b7 \u00b7 ,xn), , \u03b1, H0 : p = p0. Let H\u0303 = \u2211n i=1Mbit(xi, ).\nSet q = T(n)BitFlip ( ) if q > \u03c72d\u22121,1\u2212\u03b1 Decision\u2190 Reject. else Decision\u2190 Fail to Reject.\nOutput: Decision\nWe now show that the statistic in (6) is asymptotically distributed as \u03c72d\u22121, with proof in the supplementary file. Theorem 5.8. If the null hypothesis H0 : p = p0 holds, then the statistic T(n)BitFlip ( ) is asymptotically distributed as a chisquare, i.e. T(n)BitFlip ( ) D\u2192 \u03c72d\u22121. Further, if we consider the alternate H1 : p = p1 then T (n) BitFlip ( ) converges in distribution to a noncentral chi-square with d\u22121 degrees of freedom and noncentral parameter ( e /2\u22121 e /2+1 )2 \u00b7\u2206\u1d40\u03a3(p0)\u22121\u2206.\nComparison of Noncentral Parameters. We now compare the noncentral parameters of the three local private tests we presented in Algorithms 1, 3 and 5. We consider the null hypothesis p0 = (1/d, \u00b7 \u00b7 \u00b7 , 1/d) for d > 2, and alternate H1 : p = p\n0 + \u2206\u221a n . In this case, we can easily compare the various noncentral parameters for various privacy parameters and dimensions d. In Figure 1 we give the coefficient to the term \u2206\u1d40\u2206 in the noncentral parameter of the asymptotic distribution for each local private test presented thus far. The larger this coefficient is, the better the power will be for any alternate \u2206 vector. Note that in LocalNoiseGOF, we set \u03c1 = 2/8 which makes the variance the same as for a random variable distributed as Lap(2/ ) for an -DP guarantee \u2013 recall that LocalNoiseGOF with Gaussian noise does not satisfy -DP for any > 0. We give results for \u2208 {1, 2, 3, 4} which are all in the range of privacy parameters that have been considered in actual locally differentially private algorithms used in practice.2 From\n2In (Erlingsson et al., 2014), we know that Google uses = ln(3) in RAPPOR and from Aleksandra Korolova\u2019s Twitter post on Sept. 13, 2016 https://twitter.com/korolova/\nthe plots, we see how LocalGenRRGOF may outperform LocalBitFlipGOF depending on the privacy parameter and dimension of the data. We can use these plots to determine which test to use given and the dimension of data d. When H0 is not uniform, we can use the noncentral parameters given for each test to find the test with the largest noncentral parameter for a particular privacy budget .\nEmpirical Results. We then empirically compare the power between LocalNoiseGOF with Laplace noise in Algorithm 1, LocalGenRRGOF in Algorithm 3, and LocalBitFlipGOF in Algorithm 5. Recall that all three of these tests have the same privacy benchmark of local differential privacy. For LocalNoiseGOF with Laplace noise, we will use m = 999 samples in our Monte Carlo simulations. In our experiments we fix \u03b1 = 0.05 and \u2208 {1, 2, 4}. We then consider null hypotheses of the form p0 = (1/d, 1/d, \u00b7 \u00b7 \u00b7 , 1/d) and alternate H1 : p = p0 + \u03b7(1,\u22121, \u00b7 \u00b7 \u00b7 , 1,\u22121) for some \u03b7 > 0. In Figure 2, we plot the number of times our tests correctly rejects the null hypothesis in 1000 independent trials for various sample sizes n and privacy parameters . From Figure 2, we can see that the test statistics that have the largest noncentral parameter for a particular dimension d and privacy parameter will have the best empirical power. When d = 4, we see that LocalGenRRGOF performs the best. However, for d = 40 it is not so clear cut. When = 4, we can see that LocalGenRRGOF does the best, but then when = 2, LocalBitFlipGOF does best. Thus, the best Local DP Goodness of Fit test depends on the noncentral parameter, which is a function of , the null hypothesis p0, and alternate p = p0 + \u2206. Note that the worst local DP test also depends on the privacy parameter and the dimension d. Based on our empirical results, we see that no single locally private test is best for all data dimensions. However, knowing the corresponding noncentral parameter for a given problem is useful in determining which tests to use. Indeed, the larger the noncentral parameter is the higher the power will be.\nstatus/775801259504734208, Apple uses = 1, 4."}, {"heading": "6. Local Private Independence Tests", "text": "Our techniques can be extended to include composite hypothesis tests, where we test whether the data comes from a whole family of probability distributions. We will focus on independence testing, but much of the theory can be extended to general chi-square tests. We will closely follow the presentation and notation as in (Kifer & Rogers, 2017).\nWe consider two multinomial random variables {U `}n`=1\ni.i.d.\u223c Multinomial(1,\u03c0(1)) for \u03c0(1) \u2208 Rr, {V `}n`=1\ni.i.d.\u223c Multinomial(1,\u03c0(2)) for \u03c0(2) \u2208 Rc and no component of \u03c0(1) or \u03c0(2) is zero and each sums to 1. Without loss of generality, we will consider an individual to be in one of r groups who reports a data record that is in one of c categories. The collected data consists of n joint outcomes H whose (i, j)th coordinate is Hi,j = \u2211n `=1 1{U`,i = 1 & V`,j = 1}. Note that H is then the contingency table over the joint outcomes. Under the null hypothesis of independence between {U `}n`=1 and {V `}n`=1, for probability vector p(\u03c0(1),\u03c0(2)) = \u03c0(1) ( \u03c0(2) )\u1d40 , we have\nH \u223c Multinomial ( n,p(\u03c0(1),\u03c0(2)) ) What makes this test difficult is that the analyst does not know the data distribution p(\u03c0(1),\u03c0(2)) and so cannot simply plug it into the chi-square statistic. Rather, we use the data to estimate the best guess for the unknown probability distribution that satisfies the null hypothesis. Note that without privacy, each individual ` \u2208 [n] is reporting a r \u00d7 c matrixX ` which would be 1 in exactly one location. Thus we can alternatively write the contingency table as H = \u2211n `=1X `. We then use the three local private algorithms we presented earlier to see how we can form a private chi-square statistic for independence testing. We want to be able to ensure the privacy of both the group and the category that each individual belongs to. Due to space we will only cover private independence tests that use the generalized randomized response mechanism from Algorithm 2 and the\nbit flipping local randomizer from Algorithm 4. We defer our independence test with noise addition in the local setting to the supplementary file.\nTesting with Generalized Randomized Response. We want to design an independence test when the data is generated from MGenRR given in Algorithm 2. In this case our contingency table can be written as H\u030c \u223c Multinomial ( n, p\u030c(\u03c0(1),\u03c0(2)) ) where \u03b2 = 1e +rc\u22121 and we use (3) to get\np\u030c(\u03c0(1),\u03c0(2)) = \u03b2 ( (e \u2212 1)\u03c0(1) ( \u03c0(2) )\u1d40 + 1 ) (7)\nWe then obtain an estimate for the unknown parameters,\n\u03c0\u030c(1) = 1\n\u03b2 (e \u2212 1) ( H\u030ci,\u00b7 n \u2212 c\u03b2 : i \u2208 [r] ) ,\n\u03c0\u030c(2) = 1\n\u03b2 (e \u2212 1) ( H\u030c\u00b7,j n \u2212 r\u03b2 : j \u2208 [c] )\nT\u030c (n)GenRR ( ) = \u2211 i,j\n( H\u030ci,j \u2212 np\u030ci,j ( \u03c0\u030c(1), \u03c0\u030c(2) ))2 np\u030ci,j(\u03c0\u030c (1), \u03c0\u030c(2)) (8)\nWe can then prove the following result, where the full proof is in the supplementary file.\nTheorem 6.1. Assuming U and V are independent with true probability vectors \u03c0(1),\u03c0(2) > 0 respectively, then as n\u2192\u221e we have T\u030c (n)GenRR ( ) D\u2192 \u03c72(r\u22121)(c\u22121).\nWe then use this result to design Algorithm 6.\nTheorem 6.2. LocalGenRRIND is -LDP.\nTesting with Bit Flipping. Lastly, we design an independence test when the data is reported via Mbit in Algorithm 4. Assuming that H = \u2211n `=1X ` \u223c\nAlgorithm 6 Local DP IND Test: LocalGenRRIND\nInput: x = (x1, \u00b7 \u00b7 \u00b7 ,xn), , \u03b1, H0 : p = p0. Let H\u030c = \u2211n i=1MGenRR(xi, ).\nSet q = T\u030c (n)GenRR ( ) from (8) if q > \u03c72d\u22121,1\u2212\u03b1, Decision\u2190 Reject. else Decision\u2190 Fail to Reject.\nOutput: Decision\nMultinomial ( n,p(\u03c0(1),\u03c0(2)) ) , then we know that replacing p0 with p(\u03c0(1),\u03c0(2)) in Section 5 gives us the following asymptotic distribution (treating the contingency table of values as a vector) with covariance matrix \u03a3(\u00b7) given in (5)\n\u221a n H\u0303n \u2212  ( e /2 \u2212 1 e /2 + 1 ) \u03c0(1) ( \u03c0(2) )\u1d40 +\n1\ne /2 + 1\ufe38 \ufe37\ufe37 \ufe38 p\u0303(\u03c0(1),\u03c0(2))\n \nD\u2192 N ( 0,\u03a3 ( \u03c0(1) ( \u03c0(2) )\u1d40)) (9)\nSimilar to analysis for Theorem 6.1, we start with a rough estimate for the unknown parameters which converges in probability to the true estimates, so we use \u03b1 = ( e /2\u22121 e /2+1 ) to get\n\u03c0\u0303 (1) =\n( 1\n\u03b1 )( H\u0303i,\u00b7 n \u2212 c e /2 + 1 : i \u2208 [r] )\n\u03c0\u0303 (2) =\n( 1\n\u03b1 )( H\u0303\u00b7,j n \u2212 r e /2 + 1 : j \u2208 [c] ) (10)\nWe then give the resulting statistic, parameterized by the unknown parameters \u03c0(`), for ` \u2208 {1, 2}. For middle matrix\nM\u0303 = \u03a0\u03a3 ( \u03c0\u0303 (1) ( \u03c0\u0303 (2) )\u1d40)\u22121 \u03a0, we have\nT\u0303 (n)\nBitFlip\n( \u03b8(1), \u03b8(2); ) = 1\nn\n( H\u0303 \u2212 np\u0303 ( \u03b8(1), \u03b8(2) ))\u1d40 M\u0303 ( H\u0303 \u2212 np\u0303 ( \u03b8(1), \u03b8(2) )) (11)\nMinimizing T\u0303 (n)\nBitFlip\n( \u03b8(1), \u03b8(2); ) over (\u03b8(1), \u03b8(2)) results in\na statistic that is distributed as a chi-square random variable, we defer the full proof to the supplementary file. Theorem 6.3. Under the null hypothesis where U and V are independent with true probability vectors \u03c0(1),\u03c0(2) > 0 respectively, then we have as n \u2192 \u221e,\nmin\u03b8(1),\u03b8(2)\n{ T\u0303 (n)\nBitFlip\n( \u03b8(1), \u03b8(2); )} D\u2192 \u03c72(r\u22121)(c\u22121). We present the test in Algorithm 7. The following result follows from same privacy analysis as before. Theorem 6.4. LocalBitFlipIND is -LDP.\nAlgorithm 7 Local DP IND Test: LocalBitFlipIND Input: (x1, \u00b7 \u00b7 \u00b7 ,xn), , \u03b1.\nLet H\u0303 = \u2211n i=1Mbit(xi, ).\nq = min\u03c0(1),\u03c0(2)\n{ T\u0303 (n)\nBitFlip\n( \u03c0(1),\u03c0(2); )} from (11).\nif q > \u03c72(r\u22121)(c\u22121),1\u2212\u03b1 Decision\u2190 Reject. else Decision\u2190 Fail to Reject.\nOutput: Decision\nEmpirical Results. As we did for the goodness of fit tests, we empirically compare the power for our various tests for independence. We consider the null hypothesis that the two sequences of categorical random variables {U `}n`=1 and {V `}n`=1 are independent of one another. Under an alternate hypothesis, we generate the contingency data according to a non-product distribution. We fix the distribution p1 for the contingency table to be of the following form, where \u03c0(1) \u2208 Rr is the unknown distribution for {U `}n`=1, \u03c0(2) \u2208 Rc is the unknown distribution for {V `}n`=1, and r, c are even\np1 = \u03c0(1) ( \u03c0(2) )\u1d40 + \u03b7(1,\u22121, \u00b7 \u00b7 \u00b7 ,\u22121, 1)\u1d40(1,\u22121, \u00b7 \u00b7 \u00b7 ,\u22121, 1) (12)\nNote that the hypothesis test does not know the underlying \u03c0(i) for i \u2208 {1, 2}, but to generate the data we must fix these distributions. We show power results when the marginal distributions satisfy \u03c0(1) = (1/r, \u00b7 \u00b7 \u00b7 , 1/r) and \u03c0(2) = (1/c, \u00b7 \u00b7 \u00b7 , 1/c). In Figure 2, we give results for various n and \u2208 {1, 2, 4} ."}, {"heading": "7. Conclusion", "text": "We have designed several hypothesis tests, each depending on different local differentially private algorithms. We showed that each statistic has a noncentral chi-square distribution when the data is drawn from some alternate hypothesis H1. Depending on the form of the alternate probability distribution, the dimension of the data, and the privacy parameter, either LocalGenRRGOF or LocalBitFlipGOF gave the best power. This corroborates the results from Kairouz et al. (2014) who showed that in hypothesis testing, different privacy regimes have different optimal local differentially private mechanisms, although utility in their work was in terms of KL divergence. Our results show that the power of the test is directly related to the noncentral parameter of the test statistic that is used. This requires the data analyst to carefully consider alternate hypotheses, as well as the data dimension and privacy parameter for a particular test and then see which test statistic results in the largest noncentral parameter."}, {"heading": "Acknowledgements", "text": "Marco Gaboardi has been partially supported by NSF under grant TWC-1565365."}], "year": 2018, "references": [{"title": "Local, private, efficient protocols for succinct histograms", "authors": ["R. Bassily", "A. Smith"], "venue": "In Proceedings of the Forty-seventh Annual ACM Symposium on Theory of Computing,", "year": 2015}, {"title": "Concentrated differential privacy: Simplifications, extensions, and lower bounds", "authors": ["M. Bun", "T. Steinke"], "venue": "In Theory of Cryptography - 14th International Conference, TCC 2016-B, Beijing, China, October", "year": 2016}, {"title": "Priv\u2019it: Private and sample efficient identity testing", "authors": ["B. Cai", "C. Daskalakis", "G. Kamath"], "venue": "In International Conference on Machine Learning,", "year": 2017}, {"title": "Local privacy and statistical minimax rates", "authors": ["J.C. Duchi", "M.I. Jordan", "M.J. Wainwright"], "venue": "In 54th Annual IEEE Symposium on Foundations of Computer Science,", "year": 2013}, {"title": "Local privacy and minimax bounds: Sharp rates for probability estimation", "authors": ["J.C. Duchi", "M.J. Wainwright", "M.I. Jordan"], "venue": "In Advances in Neural Information Processing Systems 26: 27th Annual Conference on Neural Information Processing Systems", "year": 2013}, {"title": "The algorithmic foundations of differential privacy", "authors": ["C. Dwork", "A. Roth"], "venue": "Foundations and TrendsA\u0302o\u030b in Theoretical Computer Science,", "year": 2014}, {"title": "Our data, ourselves: Privacy via distributed noise generation", "authors": ["C. Dwork", "K. Kenthapadi", "F. McSherry", "I. Mironov", "M. Naor"], "venue": "In Advances in Cryptology - EUROCRYPT", "year": 2006}, {"title": "Calibrating noise to sensitivity in private data analysis", "authors": ["C. Dwork", "F. Mcsherry", "K. Nissim", "A. Smith"], "venue": "Proceedings of the 3rd Theory of Cryptography Conference,", "year": 2006}, {"title": "Rappor: Randomized aggregatable privacy-preserving ordinal response", "authors": ["U. Erlingsson", "V. Pihur", "A. Korolova"], "venue": "In Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security, CCS", "year": 2014}, {"title": "Goodness of fit of social network models", "authors": ["D.R. Hunter", "S.M. Goodreau", "M.S. Handcock"], "venue": "Journal of the American Statistical Association,", "year": 2008}, {"title": "Privacy-preserving data exploration in genome-wide association studies", "authors": ["A. Johnson", "V. Shmatikov"], "venue": "In Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,", "year": 2013}, {"title": "Extremal mechanisms for local differential privacy", "authors": ["P. Kairouz", "S. Oh", "P. Viswanath"], "venue": "Advances in Neural Information Processing Systems", "year": 2014}, {"title": "Discrete distribution estimation under local privacy", "authors": ["P. Kairouz", "K. Bonawitz", "D. Ramage"], "venue": "In Proceedings of the 33nd International Conference on Machine Learning,", "year": 2016}, {"title": "Inference using noisy degrees: Differentially private \u03b2-model and synthetic graphs", "authors": ["V. Karwa", "A. Slavkovi\u0107"], "venue": "Ann. Statist., 44(P1):87\u2013112,", "year": 2016}, {"title": "Mechanism design via differential privacy", "authors": ["F. McSherry", "K. Talwar"], "venue": "In Annual IEEE Symposium on Foundations of Computer Science (FOCS),", "year": 2007}, {"title": "Locally differentially-private distribution estimation", "authors": ["A. Pastore", "M. Gastpar"], "venue": "IEEE International Symposium on Information Theory (ISIT),", "year": 2016}, {"title": "What can we learn privately? 2013", "authors": ["S. Raskhodnikova", "A. Smith", "H.K. Lee", "K. Nissim", "S.P. Kasiviswanathan"], "venue": "IEEE 54th Annual Symposium on Foundations of Computer Science,", "year": 2008}, {"title": "Differentially private least squares: Estimation, confidence and rejecting the null hypothesis", "authors": ["O. Sheffet"], "venue": "arXiv preprint arXiv:1507.02482,", "year": 2015}, {"title": "Locally private hypothesis testing", "authors": ["O. Sheffet"], "venue": "CoRR, abs/1802.03441,", "year": 2018}, {"title": "Privacypreserving data sharing for genome-wide association studies", "authors": ["C. Uhler", "A. Slavkovic", "S.E. Fienberg"], "venue": "Journal of Privacy and Confidentiality,", "year": 2013}, {"title": "Differentially private hypothesis testing, revisited", "authors": ["Y. Wang", "J. Lee", "D. Kifer"], "venue": "arXiv preprint arXiv:1511.03376,", "year": 2015}, {"title": "Randomized response: A survey technique for eliminating evasive answer bias", "authors": ["S.L. Warner"], "venue": "Journal of the American Statistical Association,", "year": 1965}, {"title": "Optimal schemes for discrete distribution estimation under local differential privacy", "authors": ["M. Ye", "A. Barg"], "venue": "IEEE International Symposium on Information Theory (ISIT),", "year": 2017}, {"title": "Scalable privacy-preserving data sharing methodology for genome-wide association studies", "authors": ["F. Yu", "S.E. Fienberg", "A.B. Slavkovic", "C. Uhler"], "venue": "Journal of Biomedical Informatics,", "year": 2014}], "id": "SP:a61f2d266eaa3665c3255d422e25e9d6b17dd102", "authors": [{"name": "Marco Gaboardi", "affiliations": []}, {"name": "Ryan Rogers", "affiliations": []}], "abstractText": "The local model for differential privacy is emerging as the reference model for practical applications of collecting and sharing sensitive information while satisfying strong privacy guarantees. In the local model, there is no trusted entity which is allowed to have each individual\u2019s raw data as is assumed in the traditional curator model. Individuals\u2019 data are usually perturbed before sharing them. We explore the design of private hypothesis tests in the local model, where each data entry is perturbed to ensure the privacy of each participant. Specifically, we analyze locally private chi-square tests for goodness of fit and independence testing.", "title": "Local Private Hypothesis Testing: Chi-Square Tests"}
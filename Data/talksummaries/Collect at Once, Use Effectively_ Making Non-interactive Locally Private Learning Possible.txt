74	1	None of these existing results extends directly to non-interactive LDP setting.
75	1	Vectors are written in bold symbol, such as x,w.
76	1	x represents univariate number, which has no relation with x.
81	1	Here we adopt the LDP definition given in (Bassily & Smith, 2015).
83	1	Lemma 2 (Composition Theorem1).
84	1	Let Qi : V → Zi be an ( i, δi)-LDP mechanism for i ∈ [k].
98	1	for User i do Collect yi = Gxi + ri, with ri ∼ i.i.d.N (0, 2 log(1.25/δ) 2 Ip) end for for j ∈ {1, 2, · · · ,m} do Sj = { 1 + (j−1)nm , 2 + (j−1)n m , · · · , jn m } .
105	1	Though the distribution has bounded support, the concentration for mean estimation is dimension-dependent, while dimension-independent Markov Inequalities hold.
117	1	The vector u constructed in Algorithm 2 satisfies the following with probability 1− δ: ‖u−Gµ‖1 ≤ O ( p log(nd/δ) √ m n ) (3) Then we turn to the recovery of original mean estimator.
121	1	Noisy vector ν ∈ Rp with ‖ν‖1 ≤ σ.
125	1	In this section, we consider empirical loss of sparse linear regression, i.e. L(w;D) = 12n ∑n i=1(x T i w − yi)2, where D = {(xi, yi)|i ∈ [n]}, ‖xi‖2 6 1, yi ∈ [−1, 1].
128	1	Having obtained private synopsis, the server then reconstruct an unbiased estimator for objective function according to these private synopsis.
131	1	As the loss function is determined by inner products between w and data, it could be uniformly preserved in projected space, which guarantees the accuracy of solution estimated with local privacy.
135	1	Algorithm 3 LDP `1 Constrained Linear Regression Input: Personal data (x, y), parameter , δ, projection ma- trix Φ ∈ Rd×m Output: Learned classifier wpriv ∈ Rd 1: for Each user i = 1, .
137	1	Denote the true objective function in low dimensional space L̄(w; X̄,y) := 12n ∥∥X̄ΦTw∥∥2 − 1nyT X̄ΦTw, where X̄ = [x1, · · · ,xn]TΦ,w ∈ C. Let ŵ∗ := argminw∈C L̄(w; X̄,y).
143	1	However, it is common to use kernel trick in practice.
149	1	Given a subset X ⊂ Rd and data D = {(xi, yi)|xi ∈ X , i ∈ [n]}, for any f ∈ H, g ∈ Ĥ , define loss functions in H and Ĥ as follows: LH(f) := C 2n ∑ i ∥∥fTΦ(xi)− yi∥∥22 + 12 ‖f‖2H (6) LĤ(g) := C 2n ∑ i ∥∥∥gT Φ̂(xi)− yi∥∥∥2 2 + 1 2 ‖g‖2Ĥ (7) where C is the regularization parameter.
153	1	Lemma 7 ((Rubinstein et al., 2012)).
154	1	Suppose dual variables with respect to f∗, g∗ are L1 norm bounded by some r > 0, and supx1,x2∈X |Φ(x1) TΦ(x2) − (Φ̂(x1)) T Φ̂(x2)| 6 γ, then there is supx∈X |Φ(x)T f∗ − (Φ̂(x))T g∗| 6 rγ + 2 √ (CG+ r/2)rγ.
156	1	In this section, we consider learning smooth generalized linear model in non-interactive LDP setting.
165	1	Our definition could be shown with connection to exponential family GLM, which is commonly used in machine learning.
195	1	Algorithm 6 LDP SGLD Mechanism - Learning Input: Private synopsis b = {zy, zj |j ∈ {0} ∪ [p(p + 1)/2]} of each user, public coefficients {c1k, c2k|k ∈ {0} ∪ [p]}, initial point w1 Output: Learned classifier wpriv 1: for s = 1, .
196	1	, n do 2: \\ Construct stochastic inexact gradient 3: \\ Denote the private synopsis of user s as b above for abbreviation 4: Set t0 = 1 5: for j = 1, .
211	1	In particular, for sparse linear regression and mean estimation problem, we propose efficient algorithms and prove the polynomial dependence of excess risk or square error over log d and 1n , which is exactly to be expected in high dimensional case.
212	1	We also extend our methods to nonparametric case and show good bounds for Kernel Ridge Regression.
213	1	For more difficult smooth generalized linear loss optimization problems, we use private Chebyshev approximations to estimate gradients of the objective loss, combined with existing inexact gradient descent methods to obtain final outputs.
214	1	The sample complexity of our mechanism is quasi-polynomial with respect to 1α , where α is the desired population excess risk.
215	11	An interesting open problem is whether our theoretical guarantees are optimal.
216	60	If not, how to improve them while preserving the efficiency in non-interactive LDP model.
217	58	We think these problems are critical to understand LDP in the future.

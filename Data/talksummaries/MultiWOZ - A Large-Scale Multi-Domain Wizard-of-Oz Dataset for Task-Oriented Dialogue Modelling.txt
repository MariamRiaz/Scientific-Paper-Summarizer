0	92	Conversational Artificial Intelligence (Conversational AI) is one of the long-standing challenges in computer science and artificial intelligence since the Dartmouth Proposal (McCarthy et al., 1955).
2	18	As a consequence, instead of focusing on creating ambitious conversational agents that can reach human-level intelligence, industrial practice has focused on building task-oriented dialogue systems (Young et al., 2013) that can help with specific tasks such as flight reservation (Seneff and Polifroni, 2000) or bus information (Raux et al., 2005).
4	29	Dialogues systems are inherently hard to build because there are several layers of complexity: the noise and uncertainty in speech recognition (Black et al., 2011); the ambiguity when understanding human language (Williams et al., 2013); the need to integrate third-party services and dialogue context in the decision-making (Traum and Larsson, 2003; Paek and Pieraccini, 2008); and finally, the ability to generate natural and engaging responses (Stent et al., 2005).
5	52	These difficulties have led to the same solution of using statistical framework and machine learning for various system components, such as natural language understanding (Henderson et al., 2013; Mesnil et al., 2015; Mrkšić et al., 2017a), dialogue management (Gašić and Young, 2014; Tegho et al., 2018), language generation (Wen et al., 2015; Kiddon et al., 2016), and even end-to-end dialogue modelling (Zhao and Eskenazi, 2016; Wen et al., 2017; Eric et al., 2017).
14	18	This work presents the data collection approach, a summary of the data structure, as well as a series of analyses of the data statistics.
15	15	To show the potential and usefulness of the proposed MultiWOZ corpus, benchmarking baselines of belief tracking, natural language generation and end-toend response generation have been conducted and reported.
16	17	The dataset and baseline models will be freely available online.1
50	54	To overcome the need of relying the data collection to a small set of trusted workers2, the collection set-up was designed to provide an easy-to-operate system interface for the Wizards and easy-to-follow goals for the users.
51	14	This resulted in a bigger diversity and semantical richness of the collected data (see Section 4.3).
54	18	Subsequently, we show how the crowdsourcing scheme can also be employed to annotate the collected dialogues with dialogue acts.
72	19	The wizard is asked to perform a role of a clerk by providing information required by the user.
76	31	Thus, the annotation of a belief state is performed implicitly while the wizard is allowed to fully focus on providing the required information.
79	15	To ensure coherence and consistency, the wizard and the user alike first need to go through the dialogue history to establish the respective context.
88	14	Although the weighted kappa value averaged over dialogue acts was at a high level of 0.704, we have observed many cases of very poor annotations and an unsatisfactory coverage of dialogue acts.
101	30	As a result, many errors could be corrected.
105	14	The main goal of the data collection was to acquire highly natural conversations between a tourist and a clerk from an information center in a touristic city.
113	16	Following data collection process from the previous section, a total of 10, 438 dialogues were collected.
128	20	There are 3, 406 single-domain dialogues that include booking if the domain allows for that and 7, 032 multi-domain dialogues consisting of at least 2 up to 5 domains.
133	39	Each dialogue consists of a goal, multiple user and system utterances as well as a belief state and set of dialogue acts with slots per turn.
141	14	A robust natural language understanding and dialogue state tracking is the first step towards building a good conversational system.
144	29	Furthermore, the model parameters are independent of the ontology and belief states, therefore the number of the parameters does not increase with the size of the domain itself.4 The same model was trained on both the WOZ2.0 and the proposed MultiWOZ datasets, where the WOZ2.0 corpus consists of 1200 single domain dialogues in the restaurant domain.
149	13	In order to establish a clear benchmark where the performance of the composite of dialogue management and response generation is completely independent of the belief tracking, we experimented with a baseline neural response generation model with an oracle beliefstate obtained from the wizard annotations as discussed in Section 3.3.5 Following Wen et al. (2017) which frames the dialogue as a context to response mapping problem, a sequence-to-sequence model (Sutskever et al., 2014) is augmented with a belief tracker and a discrete database accessing component as additional features to inform the word decisions in the decoder.
150	17	Note, in the original paper the belief tracker was pre-trained while in this work the annotations of the dialogue state are used as an oracle tracker.
153	28	Among them, the first two metrics relate to the dialogue task completion - whether the system has provided an appropriate entity (Inform rate) and then answered all the requested attributes (Success rate); while fluency is measured via BLEU score (Papineni et al., 2002).
160	44	However, even with the perfect dialogue state tracking of the user intent, the baseline models obtain almost 30% lower score on the Inform metric on the new corpus.
162	47	Nevertheless, as expected, the best model on MultiWOZ is still falling behind by a large margin in comparison to the results on the Cam676 corpus taking into account both Inform and Success metrics.
163	35	As most of dialogues span over at least two domains, the model has to be much more effective in order to execute a successful dialogue.
164	41	Moreover, the BLEU score on the MultiWOZ is lower than the one reported on the Cam676 dataset.
166	50	Natural Language Generation from a structured meaning representation (Oh and Rudnicky, 2000; Bohus and Rudnicky, 2005) has been a very popular research topic in the community, and the lack of data has been a long standing block for the field to adopt more machine learning methods.
167	20	Due to the additional annotation of the system acts, the MultiWOZ dataset serves as a new benchmark for studying natural language generation from a structured meaning representation.

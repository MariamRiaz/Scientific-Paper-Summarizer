5	91	The potential advantage of unlimited history, however, is not commonly used to its full benefit, since the language model (LM) is typically “reset” at the start of each utterance in current stateof-the-art recognition systems (Saon et al., 2017; Xiong et al., 2018).
6	69	This presumes that each utterance is independent of the others, and clearly violates what we know about how language and conversation works, as discussed in the next section.
11	28	We start by discussing linguistic phenomena that could potentially help in conversational LM (Section 2), followed by a description of the LSTM model we propose to capture them (Section 3).
18	26	Another phenomenon that could lead to words reoccurring is lexical entrainment (Brennan and Clark, 1996), or the tendency of conversants to adopt the same words and phrases.
19	42	Entrainment can also apply to speaking style, so the use of common discourse particles, syntactic patterns (like question tags), or even disfluencies could be triggered across speakers.
21	40	Linguistic conversation analysis has long noted that utterance types come in adjacency pairs (Schegloff, 1968), with preferences for certain pairs over others (like a statement is preferentially followed by agreement rather than disagreement).
22	11	Therefore, words in an utterance should be more predicable based on the previous utterance.
25	18	Speakers use special discourse devices, such as backchannel words and pause fillers, to signal when they want to take the floor, or to signal that the other party should keep the floor.
26	14	Conversants also anticipate the ends of turns and jump in before the other speaker is completely done, making for very efficient use of time.
28	37	It was shown (Shriberg et al., 2001) that such overlap locations can be partly predicted by word-based language models.
29	17	This suggests reversing the modeling and using overlap (the tim- ing of utterances) to help predict the words.
30	22	Our baseline language model is a standard LSTM that models utterances independently from one another, i.e., the history at the onset of each utterance is the start-of-sentence token.
32	13	Both types of LSTM-LMs use three 1000- dimensional hidden layers with recurrence.
33	30	The word embedding layer is also of size 1000, and the letter-trigram encoding has size 7190 (the number of unique trigrams in our vocabulary).
34	14	The main addition for session-level modeling is that the LSTM history consists of all the utterances preceding the current utterance, followed by all words in the current utterance preceding the word to be predicted.
35	35	The preceding utterances are serialized in the order of their onset times, so that the flow of words within an utterance is not disrupted.
38	27	Several of the conversational phenomena described in Section 2 refer to turn-taking between speakers; to capture this in the model we augment the word input encoding with an extra bit that indicates whether a speaker change occurred.
42	17	As a first proof of concept we chose to encode only one type of overlap, i.e., when the utterance in question is completely overlapped temporally by the other speaker’s turn.
45	60	We used a single bidirectional LSTM acoustic model in experiments reported here, trained on the commonly used conversational telephone speech corpora (Switchboard, Fisher, CallHome English), estimating frame-level posterior probabilities for 9000 context-dependent phone units.
50	10	Language model training uses the Switchboard1, BBN Switchboard-2, Fisher, and English CallHome transcripts (about 23 million words in total) as well as the UW conversational Web corpus (Bulyko et al., 2003) for pre-training (see below).
53	15	Evaluation is carried out on the NIST 2000 CTS test set, consisting of Switchboard (SWB) and CallHome (CH) subsets.
66	33	We see a large perplexity reduction of 17- 21% by conditioning on session history words, with smaller incremental reductions from adding speaker change and overlap information.
67	12	The last two table rows show that some of the perplexity gain over the baseline is negated by the use of errorful recognition output for the conversation history.
69	13	Using recognition output as history, the perplexity degrades about 6% relative for SWB, and 11% on CH, relative to using the true word histories.
70	15	Even with the more errorful recognition on CH, the session-based LM still gives a perplexity reduction of 14% relative to the baseline.
71	14	Table 2 presents recognition results, comparing baseline LSTM-LMs to the full session-based LSTM-LMs.
76	66	When the two word encoding types are combined by log- linear combination of model scores, the gain from session-based modeling is preserved.
81	27	To capture non-local conditioning information, the LSTM-LM is trained to read the entire sequence of utterances making up a conversation, along with side information encoding speaker changes and overlap of utterances.
84	71	It would be worthwhile to investigate which conversational phenomena are actually being exploited by the session LSTM model.
85	36	The ease with which additional information can be input to the LSTM-LM also suggests encoding other conditioning information, such a more details about utterance timing, as well as semantic features that capture topical coherence.

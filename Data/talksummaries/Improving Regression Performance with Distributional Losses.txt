0	38	The choice of problem formulation for regression has a large impact on prediction performance on new data— generalization performance.
1	22	There is an extensive literature on problem formulations to promote generalization, including robust losses (Huber, 2011; Ghosh et al., 2017; Barron, 2017); proxy losses and reductions between problems (Langford et al., 2006); the addition of regularization to impose constraints or preferences on the solution; the addition of label noise (Szegedy et al., 2016); and even ensuring multiple tasks are learned simultaneously, rather than separately, as in multi-task learning (Caruana, 1998).
2	27	There is typically a goal in mind—such as classification accuracy or absolute error for regression—but those losses are not necessarily directly minimized.
3	70	In recent years, there has been a particular focus on learning representations with neural networks that generalize better.
4	49	With fixed representations, the loss or problem formulation can only have so much impact, because the learned function is a linear function of inputs.
7	40	An extensive empirical study on classification and age prediction (Gao et al., 2017), under label ambiguity, showed that data augmentation on the label side—putting a distribution over an ambiguous label—significantly improved test accuracy, validated also by other work on age estimation (Rothe et al., 2018).
9	42	In general, there is a growing literature on data augmentation and label smoothing, that advocates for reduced overfitting and improved generalization from modifying the outputs (Norouzi et al., 2016; Szegedy et al., 2016; Xie et al., 2016; Miyato et al., 2016; Pereyra et al., 2017) and in reinforcement learning where learning distributional outputs, rather than means, improves performance (Bellemare et al., 2017).
12	4	Though not the focus in data augmentation, there have been some insights about loss properties.
13	36	Gao et al. (2017) showed that their data augmentation approach provided a faster convergence rate (see their Figure 8).
14	13	Pereyra et al. (2017) showed that label smoothing and their regularizer penalizing confident predictions for classification provided smoother gradient norms than without regularization.
15	94	Bellemare et al. (2017) hypothesized that the properties of the KL-divergence could have improved learning performance, in a reinforcement learning setting.
16	307	These papers hint at something deeper occurring with the loss, and motivate investigation into not just the conversion of the problem but into the loss itself.
17	52	In this work, we show that the properties of the loss have a significant effect, and better explain the resulting increase in performance than preventing overfitting.
18	150	We first propose a new loss for regression, called a Histogram Loss (HL).
19	127	The targets are converted to a target distribution, and the KL-divergence taken between a histogram density and this target distribution.
20	39	The choice of histogram density provides a relatively flexible prediction distribution, that nonetheless enables the KL-divergence to be computed efficiently.
21	39	The prediction is then the expected value of this histogram density.
23	10	We show that instead of this hypothesis, the (optimization) properties of the HL seem to be the key factor in the resulting improved accuracy.
25	5	We also characterize the norm of the gradient of the HL which directly relates to sample complexity (Hardt et al., 2015).
26	29	The bounds on the variability of the gradient help explain the positive empirical performance of the HL, and further motivate the use of this loss as an alternative for the standard loss for regression.

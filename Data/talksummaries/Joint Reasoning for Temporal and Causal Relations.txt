0	55	Understanding events is an important component of natural language understanding.
1	19	An essential step in this process is identifying relations between events, which are needed in order to support applications such as story completion, summarization, and timeline construction.
2	37	Among the many relation types that could exist between events, this paper focuses on the joint extraction of temporal and causal relations.
4	60	In Example 1, identifying the temporal relation between e1:died and e2:exploded is in fact a very hard case: There are no explicit temporal markers (e.g., “before”, “after”, or “since”); the events are in separate sentences so their syntactic connection is weak; although the occurrence time of e2:exploded is given (i.e., Friday) in text, it is not given for e1:died.
8	23	More than 10 people (e1:died) on their way to the nearest hospital, police said.
9	17	A suicide car bomb (e2:exploded) on Friday in the middle of a group of men playing volleyball in northwest Pakistan.
10	32	Since e2:exploded is the reason of e1:died, the temporal relation is thus e2 being before e1.
13	15	Since e3:raged is temporally after e4:stifle, e4 should be the cause of e3.
14	26	On the other hand, causal relation extraction can also benefit from knowing temporal relations.
15	36	In Example 2, it is unclear whether the government stifled people because people raged, or people raged because the government stifled people: both situations are logically reasonable.
17	36	In this case, the causal relation is dictated by the temporal relation.
18	33	The first contribution of this work is proposing a joint framework for Temporal and Causal Reasoning (TCR), inspired by these examples.
23	17	These constraints originate from the one-dimensional nature of time and the physical nature of causality and build connections between temporal and causal relations, making CCM a natural choice for this problem.
68	33	Let RT be the label set of temporal relations and E and T be the set of all events and the set of all time expressions (a.k.a.
72	12	Then the inference formulation for all the temporal relations within this document is: Ŷ = argmax Y ∈Y ∑ i∈EE see{i 7→ Yi}+ ∑ j∈ET set{j 7→ Yj} (1) where Yk ∈ RT is the temporal label of pair k ∈ MM (Let M = E ∪ T be the set of all temporal nodes), “k 7→ Yk” represents the case where the label of pair k is predicted to be Yk, Y is a vectorization of all these Yk’s in one document, and Y is the constrained space that Y lies in.
74	19	We impose these relations via equality constraints denoted as Y0.
94	12	This explains why a vague relation (v) is always added in Table 1 if more than one label in Trans(r1, r2) is possible.
102	31	In this work, we used the same set of rules designed by CAEVO for fair comparison.
103	40	Now we have presented the joint inference framework for temporal relations in Eq.
106	17	Specifically, the full inference formulation is now: Ŷ , Ŵ = arg max Y ∈Y,W∈WY ∑ i∈EE see{i 7→ Yi} (3) + ∑ j∈ET set{j 7→ Yj}+ ∑ k∈EE sc{k 7→ Wk} whereWY is the search space forW .
107	55	WY depends on the temporal labels Y in the sense that WY = {W ∈ RmC |∀i, j ∈ E , if W(i,j) = c, (4) then W(j,i) = c̄, and Y(i,j) = b} where m is the dimension of W (i.e., the total number of causal pairs), RC = {c, c̄, null} is the label set for causal relations (i.e., “causes”, “caused by”, and “no relation”), and W(i,j) is the causal label for pair (i, j).
108	23	The constraint represented byWY means that if a pair of events i and j are labeled to be “causes”, then the causal relation between j and imust be “caused by”, and the temporal relation between i and j must be “before”.
109	88	In the above, we have built the joint framework on top of scoring functions see(·), set(·) and sc(·).
110	125	To get see(·) and set(·), we trained classifiers using the averaged perceptron algorithm (Freund and Schapire, 1998) and the same set of features used in (Do et al., 2012; Ning et al., 2017), and then used the soft-max scores in those scoring functions.
114	44	In addition to these existing features, we also use prior statistics retrieved using our temporal system from a large corpus3, so as to know probabilistically which event happens before another event.
116	80	The prior knowledge we retrieved from that large corpus is that die happens before explode with probability 15% and happens after explode with probability 85%.
123	17	Then let pri = see{i 7→ r} if i ∈ EE , or pri = s et{i 7→ r} if i ∈ ET ; similarly, let wrj = I{Wi = r} be the indicator variables forWj and qrj be the score for Wj = r ∈ RC .
131	22	(4) can be done as following: WY : wci,j = wc̄j,i ≤ ybi,j , ∀i, j ∈ E .
138	137	Annotators of TB-Dense were forced to look at each pair of events or timexes within the same sentence or contiguous sentences, so that much fewer links were missed.
141	42	The “+” signs on lines 2-5 refer to adding a new source of information on top of its preceding system, with which the inference has to be global and done via ILP.

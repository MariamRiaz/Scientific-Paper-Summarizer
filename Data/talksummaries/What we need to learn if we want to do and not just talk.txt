0	78	Many commercial applications of artificial agents require task-oriented conversational agents that help customers achieve a specific goal, such as making or cancelling a payment or reservation (Zue et al., 2000; Bennacef et al., 1996).
1	62	These chatbots must extract relevant information from the user, provide relevant knowledge to her, and issue appropriate system calls to achieve the goal.
2	163	Supervised approaches such as seq2seq models (Vinyals and Le, 2015; Shang et al., 2015; Serban et al., 2015; Sordoni et al., 2015b), have recently gained attention in non-task oriented dialog, due to their ability to perform end-to-end learning from expert dialogues1, removing the need for many of the independent modules in traditional systems such as, natural language understanding, dialog state tracker and natural language generator.
3	125	Seq2Seq models have also shown promising results on small domain or synthetic task-oriented dialog datasets.
5	50	This is in part because end-to-end methods, in general, require large amounts of data before they are able to generate fluent textual responses.
6	67	In real world settings, words chosen by human users and agents are not constrained to a fixed vocabulary, and hence we see many lexical variations even among semantically similar dialogs.
7	23	To ensure that information is both conveyed and understood, we want responses to be fluent as well as coherent.
9	40	Table 1 shows responses generated by a variant of the seq2seq model, when trained on real customeragent chat transcripts.
10	22	The response of the chatbot during the fourth turn2 in Table 1, accepting the customerâ€™s expression of gratitude, is coherent and fluent.
11	12	Coherence of a response does not necessarily guarantee fluency.
12	15	The generated response during the second turn is coherent but not fluent.
15	26	(Koehn and Knowles, 2017) use beam search decoding in Neural Machine Translation to mitigate fluency issues on larger translation datasets.
18	14	This removes the need for the models to learn the grammar of the language, and allows the models to focus on learning what to say, rather than how to say it.
20	14	However, our results in Table 3 show that they perform poorly in predicting external actions and at ensuring dialogue level coherency.
44	32	Complete automation of customer service is still not possible as chatbots are not perfect yet.
45	35	However, automation where possible in the workflow could still result in considerable savings.
46	26	In order to ensure that the end user experience is not substandard, in live user testing, we ask a human agent to play intermediary role between the chatbot and the user.
48	23	The chatbot responds with 5 diverse responses.
49	8	The agent selects the most relevant response, and may choose to modify it.
50	12	If the response is not relevant, she may type a different response.
56	8	This is not a suitable strategy for our application, since in practice knowledge bases undergo frequent changes, making this infeasible.
59	10	We used 80% of the data for training (of which 10% was used for validation) and the remaining 20% for testing.
60	22	We also evaluate our models on an internal customer support dataset of 160k chat transcripts containing 3 million interactions.
63	16	We perform spell correction, deidentification to remove customer sensitive information, lexical normalization particularly of lingo words such as, lol and ty.
65	27	The values must be reinserted, currently by a human in the loop.
66	9	We have also masked product and the organization name in the examples.
72	22	Obtaining and aligning api calls with the chat transcripts is often complex as such information is typically stored in multiple confidential logs.
73	20	In order to measure coherency with respect to api calls, we randomly sampled 1000 chat tran- scripts and asked human agents to hand annotate the api calls wherever appropriate.
74	8	We will refer to this labeled dataset as CS small.
76	32	We unroll the basic seq2seq model and make one copy for each turn.

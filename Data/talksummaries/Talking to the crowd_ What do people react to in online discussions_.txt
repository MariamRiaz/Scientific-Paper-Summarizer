11	28	The primary contributions of this work include findings about the role of author reputation and variation across communities in terms of aspects of language use that matter, as well as the problem formulation, associated data collection, and development of a variety of features for characterizing informativeness, community response, relevance and mood.
12	16	Reddit1 is the largest public online discussion forum with a wide variety of subreddits, which makes it a good data source for studying how textual content in a discussion impacts the response of the crowd.
13	59	On Reddit, people initiate a discussion thread with a post (a question, a link to a news item, etc.
18	57	Karma points are also accumulated by members of the discussion forum as a function of the karma associated with their comments.
29	18	Previous studies on Twitter show that the reputation of the author substantially increases the chances of the retweet (Suh et al., 2010; Cha et al., 2010), and reputation is also raised as a factor in Slashdot (Lampe and Resnick, 2004).
30	41	On Reddit most users are anonymous, but it is possible that members of a forum become familiar with particular usernames associated with high karma comments.
32	20	Since an individual’s karma can be skewed by a few very popular posts, we measure reputation instead using a measure we call the k-index, defined to be equal to the number of comments in each user’s history that have karma ≥ k. The k-index is analgous to the h-index (Hirsch, 2005) and arguably a better indicator of extended impact than total karma.
37	29	If we consider whether any one of the multiple comments that the top k-index person made is the top karma comment in the discussion, then the frequency is even lower.
38	96	Having shown that the reputation of the author of a post is not a dominating factor in predicting high karma comments, we propose to control for topic and timing by ranking a set of 10 comments that were made consecutively in a short window of time within one discussion thread according to the karma they finally received.
43	17	Here, feature selection is based on mean precision of the top-ranked comment (P@1), so as to emphasize learning the rare high karma events.
46	18	In addition, for analysis purposes, we report results for three surrogate tasks that can be used in the ranking problem: i) the binary ranker trained on all comment pairs within each list, in which low karma comments dominate, ii) a positive vs. negative karma classifier, and iii) a high vs. medium karma classifier.
56	12	• Graph and Timing (G&T): A baseline that captures discourse history (response structure) and comment timing, but no text content.
65	15	For example, projecting words to a two dimensional space of positive vs. negative and likelihood of reply showed that self-oriented pronouns were more likely to have no response and secondperson pronouns were more likely to have a negative response.
70	39	We present three sets of experiments on comment karma ranking, all of which show very different behavior for the different subreddits.
71	69	1 shows the relative gain in P@1 over the G&T baseline associated with using different feature groups.
72	14	The importance of the different features reflect the nature of the different communities.
74	12	Informativeness and relevance help all subreddits except ASKMEN and WORLDNEWS.
75	57	Lexical, mood and community style features are useful in some cases, but hurt others.
77	10	Tables 3 and 4 summarize the results for the P@1 and NDCG criteria using the greedy selection procedure (which optimizes P@1) compared to a random baseline and the G&T baseline.
78	12	The random baseline for P@1 is greater than 10% because of ties.
86	13	Alternatively, it may be that language cues are mainly useful for identifying distinguishing the negative or mid-level karma comments, and that the very high karma comments are a matter of timing.
87	118	To better understand the role of language for these different types, we trained classifiers on balanced data for positive vs. negative karma and high vs. mid levels of karma.
88	61	For these models, the training pairs could come from different threads, but topic is controlled for in that all topic features are relative (similarity to original post, parent, etc.).
90	13	In all three cases, random chance accuracy is 50%.
92	19	We find that distinguishing positive from negative classes is fairly easy, with the notable exception of the more information-oriented subreddit ASKSCIENCE.
109	90	This paper addresses the problem of how language affects the reaction of community in Reddit comments.
111	23	We introduce a new task of ranking comments based on karma in Reddit discussions, which controls for topic and timing of comments.
112	12	Our results show that using language features improve the comment ranking task in most of the subreddits.
113	25	Informativeness and relevance are the most broadly useful feature categories; reputation matters for ASKSCIENCE, and other categories could either help or hurt depending on the community.
114	20	Future work involves improving the classification algorithm by using new approaches to learning about rare events.

0,1,label2,summary_sentences
"Given a dataset, similarity relationship between examples can be represented by a graph in which each example is represented by a vertex.",1. Introduction,[0],[0]
"While pairwise relationship between two vertices can be represented by an edge in a normal graph, a higher order relationship involving multiple vertices can be captured by a hyperedge, which means that all the corresponding examples are similar to one another.",1. Introduction,[0],[0]
"Hypergraphs have been used in several learning applications such as clustering of categorical data (Gibson et al., 1998), multi-label classification (Sun et al., 2008), Laplacian sparse coding (Gao et al., 2013), image classification (Yu et al., 2012), image retrieval (Huang et al., 2010), mapping users across different social networks (Tan et al., 2014) and predicting edge labels in hypernode graphs (Ricatte et al., 2014).
",1. Introduction,[0.9999999232113772],"['Hypergraphs have been used in several learning applications such as clustering of categorical data (Gibson et al., 1998), multi-label classification (Sun et al., 2008), Laplacian sparse coding (Gao et al., 2013), image classification (Yu et al., 2012), image retrieval (Huang et al., 2010), mapping users across different social networks (Tan et al., 2014) and predicting edge labels in hypernode graphs (Ricatte et al., 2014).']"
"*Equal contribution 1University of Hong Kong, Hong Kong.",1. Introduction,[0],[0]
2This research was partially supported by the Hong Kong RGC under the grant 17200214.,1. Introduction,[0],[0]
"Correspondence to: T-H. Hubert Chan <hubert@cs.hku.hk>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"In this paper, we consider semi-supervised learning on an edge-weighted hypergraph H = (V,E,w), with a set L of labeled vertices, whose labels are given by f∗L ∈ {−1,+1}L. The task is to predict the labels of the unlabeled vertices N , with the working principle that vertices contained in a hyperedge e ∈ E are more similar to one another if the edge weight we is larger.",1. Introduction,[1.0],"['In this paper, we consider semi-supervised learning on an edge-weighted hypergraph H = (V,E,w), with a set L of labeled vertices, whose labels are given by f∗L ∈ {−1,+1}L. The task is to predict the labels of the unlabeled vertices N , with the working principle that vertices contained in a hyperedge e ∈ E are more similar to one another if the edge weight we is larger.']"
"This problem is also known as transductive inference and has been studied in (Zhou et al., 2006) and (Hein et al., 2013).
",1. Introduction,[0.999999941191063],"['This problem is also known as transductive inference and has been studied in (Zhou et al., 2006) and (Hein et al., 2013).']"
"However, the methods in (Zhou et al., 2006) have been criticized by (Agarwal et al., 2006), because essentially a hypergraph is converted into a normal graph.",1. Introduction,[1.0],"['However, the methods in (Zhou et al., 2006) have been criticized by (Agarwal et al., 2006), because essentially a hypergraph is converted into a normal graph.']"
"For instance, given a hyperedge e containing vertices S, either (i) a clique is added between the vertices in S, or (ii) a star is formed by adding a new vertex ve connecting every vertex in S to ve.",1. Introduction,[1.0],"['For instance, given a hyperedge e containing vertices S, either (i) a clique is added between the vertices in S, or (ii) a star is formed by adding a new vertex ve connecting every vertex in S to ve.']"
"Then, a standard convex program using a regularization potential function for normal graphs can be applied (Zhu et al., 2003).",1. Introduction,[1.0],"['Then, a standard convex program using a regularization potential function for normal graphs can be applied (Zhu et al., 2003).']"
"By choosing appropriate edge weights, it was shown in (Agarwal et al., 2006) that the two approaches are equivalent to the following convex program relaxation:
min Φold(f) := 1
2 ∑ e∈E we ∑
{u,v}∈(e2)
(fu − fv)2
subject to fu ∈",1. Introduction,[0.9815320787192796],"['By choosing appropriate edge weights, it was shown in (Agarwal et al., 2006) that the two approaches are equivalent to the following convex program relaxation: min Φold(f) := 1 2 ∑ e∈E we ∑ {u,v}∈(e2) (fu − fv)2 subject to fu ∈ [−1, 1], ∀u ∈ V fu = f ∗ u , ∀u ∈ L. On the other hand, it was proposed in (Hein et al., 2013) that the following regularization function is more suitable to capture hyperedge expansion: Φnew(f) := 1 2 ∑ e∈E we · (max u∈e fu −min v∈e fv) 2.']"
"[−1, 1], ∀u ∈ V fu = f ∗ u , ∀u ∈",1. Introduction,[0],[0]
"L.
On the other hand, it was proposed in (Hein et al., 2013) that the following regularization function is more suitable to capture hyperedge expansion:
Φnew(f) := 1
2 ∑ e∈E we · (max u∈e fu −min v∈e fv) 2.
",1. Introduction,[0],[0]
"Indeed, it was shown in (Hein et al., 2013) that their approach outperforms (Zhou et al., 2006) on several datasets from the UCI Machine Learning Repository (Lichman, 2013).
",1. Introduction,[0],[0]
Loss Function.,1. Introduction,[0],[0]
"In (Hein et al., 2013), a squared loss function was added by considering the convex program with objective function Φnew(f) + µ ‖f − f∗‖22 on f ∈",1. Introduction,[0],[0]
"[−1, 1]V , where µ > 0 is a parameter to be tuned, f∗L is given by the labeled vertices L, and for the unlabeled vertices f∗N = 0.
",1. Introduction,[0],[0]
"The loss function allows errors in the labeled vertices, and also ensures that the minimizer is unique.",1. Introduction,[0],[0]
"However, as a result, unlabeled vertices have a tendency to acquire f values close to 0.",1. Introduction,[1.0],"['However, as a result, unlabeled vertices have a tendency to acquire f values close to 0.']"
"This might remove useful information as illustrated in the following example.
",1. Introduction,[0.9999999743597022],['This might remove useful information as illustrated in the following example.']
Example.,1. Introduction,[0],[0]
"In Figure 1.1, vertices a, b ∈ L are labeled as +1 and c ∈ L is labeled as −1.",1. Introduction,[1.0],"['In Figure 1.1, vertices a, b ∈ L are labeled as +1 and c ∈ L is labeled as −1.']"
"Vertices x, y ∈ N are unlabeled.",1. Introduction,[0],[0]
"There are three (undirected) edges: {a, x}, {b, x} and {x, y, c}, each with unit weight.
",1. Introduction,[1.0000000539692782],"['There are three (undirected) edges: {a, x}, {b, x} and {x, y, c}, each with unit weight.']"
"By choosing µ = 12 for squared loss function, the unique minimizer gives fx = 15 and fy = 0.",1. Introduction,[0],[0]
"Hence, this solution gives no useful information regarding the label for vertex y.
On the other hand, if we just use the objective function Φnew(f) with the constraints fL = f∗L, then in an optimal solution, fx = 13 , but fy could be anywhere in the confidence interval",1. Introduction,[0.9651331517362017],"['On the other hand, if we just use the objective function Φnew(f) with the constraints fL = f∗L, then in an optimal solution, fx = 13 , but fy could be anywhere in the confidence interval [−1, 13 ].']"
"[−1, 13 ].",1. Introduction,[0],[0]
"Hence, in this case, we could use the average value − 13 to predict −1 for vertex y.
Our Contributions.",1. Introduction,[0.9852017832122496],"['Hence, in this case, we could use the average value − 13 to predict −1 for vertex y.']"
"In this paper, we revisit the approach used in (Hein et al., 2013) and consider several extensions and simplifications.",1. Introduction,[1.0],"['In this paper, we revisit the approach used in (Hein et al., 2013) and consider several extensions and simplifications.']"
"We summarize our results and give an outline of the paper as follows.
1.",1. Introduction,[0.9765065327763353],['We summarize our results and give an outline of the paper as follows.']
Unified Framework for Directed Hypergraphs.,1. Introduction,[0],[0]
"Inspired also from the recent result on Laplacians for directed normal graphs (Yoshida, 2016), we introduce a semisupervised learning framework using directed hypergraphs that can capture higher order causal relationships.",1. Introduction,[1.0],"['Inspired also from the recent result on Laplacians for directed normal graphs (Yoshida, 2016), we introduce a semisupervised learning framework using directed hypergraphs that can capture higher order causal relationships.']"
"This notion of directed hypergraph was first introduced in (Gallo et al., 1993), who considered applications in propositional logic, analyzing dependency in relational database, and traffic analysis.",1. Introduction,[1.0],"['This notion of directed hypergraph was first introduced in (Gallo et al., 1993), who considered applications in propositional logic, analyzing dependency in relational database, and traffic analysis.']"
"On a high level, a directed hyperedge e consists of a tail set Te pointing to a head set He such that a vertex in Te labeled +1 implies that a vertex in He is more likely to be labeled +1.",1. Introduction,[0],[0]
"(Equivalently in terms of its contrapositive, a vertex in He labeled −1 implies that a vertex in Te is more likely to be labeled −1.)",1. Introduction,[0],[0]
"In Section 2, we formally define the model and the corresponding potential function Φ. An additional advantage of our potential function is that there is no need to tune any parameters.
2.",1. Introduction,[0],[0]
Confidence Interval for Unlabeled Vertices.,1. Introduction,[1.0],['Confidence Interval for Unlabeled Vertices.']
Observe that the minimizer for our convex program might not be unique.,1. Introduction,[0],[0]
"In Section 3, we introduce the concept of confidence interval for each unlabeled vertex that can be useful for predicting its label.",1. Introduction,[0],[0]
"Furthermore, we provide an algorithm to calculate the confidence interval given an optimal solution.
3.",1. Introduction,[0],[0]
Simpler Subgradient Method.,1. Introduction,[0],[0]
"Since the new potential function is not everywhere differentiable but still convex, we use the subgradient method (Shor et al., 1985) to obtain an estimated minimizer for label prediction.",1. Introduction,[0],[0]
"Inspired by the diffusion processes used for defining Laplacians in hypergraphs (Louis, 2015) and directed graphs (Yoshida, 2016), in Section 4, we define a simple Markov operator that returns a subgradient for Φ, which is used to solve the underlying convex program.",1. Introduction,[0],[0]
"We remark that our framework is very easy to understand, because it is a variation on the well-known gradient descent.
",1. Introduction,[0.999999917651659],"['We remark that our framework is very easy to understand, because it is a variation on the well-known gradient descent.']"
"In contrast, the primal-dual approach in (Hein et al., 2013) considers the convex conjugate of the primal objective and involves complicated update operations on the primal and dual variables.",1. Introduction,[1.0],"['In contrast, the primal-dual approach in (Hein et al., 2013) considers the convex conjugate of the primal objective and involves complicated update operations on the primal and dual variables.']"
"The subgradient used in our approach gives the update direction, and we can actually solve exactly the same convex program with a much simpler method.",1. Introduction,[1.0],"['The subgradient used in our approach gives the update direction, and we can actually solve exactly the same convex program with a much simpler method.']"
"Section 5, we revisit some datasets in the UCI Machine Learning Repository (Lichman, 2013), and experiments confirm that our prediction model based on confidence interval gives better accuracy than that in (Hein et al., 2013).",4. Experimental Results on Real-World Datasets. In,[1.0],"['Section 5, we revisit some datasets in the UCI Machine Learning Repository (Lichman, 2013), and experiments confirm that our prediction model based on confidence interval gives better accuracy than that in (Hein et al., 2013).']"
"Our simpler subgradient method takes more iterations than the primal-dual method (Hein et al., 2013), but each iteration is much faster.",4. Experimental Results on Real-World Datasets. In,[1.0],"['Our simpler subgradient method takes more iterations than the primal-dual method (Hein et al., 2013), but each iteration is much faster.']"
"Experiments show that overall both methods have similar running times, and the subgradient method has an advantage when the number of vertices is much larger than the number of edges.
",4. Experimental Results on Real-World Datasets. In,[1.0000000410405734],"['Experiments show that overall both methods have similar running times, and the subgradient method has an advantage when the number of vertices is much larger than the number of edges.']"
"Moreover, using the DBLP dataset (Ley, 2009), our experiments also support that using directed hypergraphs to capture causal relationships can improve the prediction accuracy.",4. Experimental Results on Real-World Datasets. In,[1.0],"['Moreover, using the DBLP dataset (Ley, 2009), our experiments also support that using directed hypergraphs to capture causal relationships can improve the prediction accuracy.']"
The experiments for directed hypergraphs are described in the full version.,4. Experimental Results on Real-World Datasets. In,[0],[0]
"We consider an edge-weighted directed hypergraph H = (V,E,w) with vertex set V (with n = |V |), edge set E and weight function",2. Preliminaries,[0.9910738677280672],"['We consider an edge-weighted directed hypergraph H = (V,E,w) with vertex set V (with n = |V |), edge set E and weight function w : E → R+.']"
w : E → R+.,2. Preliminaries,[0],[0]
Each hyperedge e ∈ E consists of a tail set Te ⊆ V and a head set He ⊆ V (which are not necessarily disjoint); we use the convention that the direction is from tail to head.,2. Preliminaries,[0],[0]
"For x ∈ R, we denote [x]+ := max{x, 0}.
",2. Preliminaries,[0],[0]
"In our application, each vertex v ∈ V is supposed to have a label in {−1,+1}.",2. Preliminaries,[1.0],"['In our application, each vertex v ∈ V is supposed to have a label in {−1,+1}.']"
"Intuitively, the directed hypergraph attempts to capture the rule that for each edge e ∈ E, if there is a vertex in Te having label +1, then it is more likely for vertices in He to receive label +1.",2. Preliminaries,[1.0],"['Intuitively, the directed hypergraph attempts to capture the rule that for each edge e ∈ E, if there is a vertex in Te having label +1, then it is more likely for vertices in He to receive label +1.']"
"In terms of its contrapositive, if there is a vertex in He having label −1, then it is more likely for vertices in Te to receive label −1.
",2. Preliminaries,[0],[0]
"We use f ∈ RV to denote a vector, where the coordi-
nates are labeled by vertices in V .",2. Preliminaries,[0],[0]
"For U ⊆ V , we use fU ∈ RU to denote the vector restricting f to coordinates inU .",2. Preliminaries,[0],[0]
"In semi-supervised learning, we consider a setL ⊆ V of labeled vertices, which have labels f∗L ∈",2. Preliminaries,[0],[0]
"{−1,+1}L. Typically, |L| |V | and the task is to assign a label in {−1,+1} to each unlabeled vertex in N := V \ L, using information from the directed hypergraph H .
",2. Preliminaries,[0],[0]
"By relaxing labels to be in the interval [−1, 1], we consider the following regularization potential function Φ : RV → R:
Φ(f)",2. Preliminaries,[0],[0]
"= 1
2 ∑ e∈E we · ([∆e(f)]+)2,
where ∆e(f) := max(u,v)∈Te×He(fu − fv) = maxu∈Te fu −minv∈He fv .
",2. Preliminaries,[0],[0]
"In particular, there is a penalty due to edge e only if some vertex in Te receives a label larger than that of some vertex in He.",2. Preliminaries,[0],[0]
"The convexity of Φ is proved in the full version.
",2. Preliminaries,[0],[0]
Our approach is to consider the following convex program to obtain an estimated minimizer f ∈,2. Preliminaries,[0],[0]
"[−1, 1]V , which can be rounded to an integer solution for labeling all vertices.
min Φ(f) (CP1) subject to fu ∈",2. Preliminaries,[0],[0]
"[−1, 1], ∀u ∈ V
fu = f ∗ u , ∀u",2. Preliminaries,[0],[0]
"∈ L
Since the f values for the labeled vertices L are fixed in (CP1), we also view Φ : RN → R as a function on the f values of unlabeled vertices N .",2. Preliminaries,[0],[0]
"We use OPT ⊂ RV to denote the set of optimal solutions to (CP1).
",2. Preliminaries,[0],[0]
Trivial Edges.,2. Preliminaries,[0],[0]
An edge e ∈ E is trivial if there exist vertices u ∈ Te ∩ L and v ∈,2. Preliminaries,[0],[0]
He ∩ L such that f∗u = +1 and f∗v = −1.,2. Preliminaries,[0],[0]
"As trivial edges contribute constant towards the objective function Φ, we shall assume that there are no trivial edges in the convex program (CP1).
",2. Preliminaries,[0],[0]
Special Cases.,2. Preliminaries,[0],[0]
"Our directed hypergraph model can capture other graph models as follows.
1.",2. Preliminaries,[0],[0]
Undirected Hypergraphs.,2. Preliminaries,[0],[0]
"For each hyperedge e, we can set Te = He to the corresponding subset of vertices.",2. Preliminaries,[0],[0]
2.,2. Preliminaries,[0],[0]
Undirected Normal Graphs.,2. Preliminaries,[0],[0]
"For each edge e = {u, v}, we can set Te = He = e. Observe that in this case, the potential function becomes Φ(f) =∑
(u,v)∈E wuv(fu− fv)2, which is differentiable, and hence, (CP1) can be solved by standard techniques like gradient descent.
",2. Preliminaries,[0],[0]
Soft Constraints.,2. Preliminaries,[0],[0]
"In (Hein et al., 2013), each labeled vertex u ∈ L can also have some weight µu ∈ R+, which can, for instance, indicate how trustworthy the label
f∗u ∈ {−1,+1} is.",2. Preliminaries,[0],[0]
"The following relaxation is considered.
",2. Preliminaries,[0],[0]
"min Φ̂(f) := Φ(f) + 1
2 ∑ u∈L µu(fu",2. Preliminaries,[0],[0]
"− f∗u)2 (CP2)
subject to fu ∈",2. Preliminaries,[0],[0]
"[−1, 1],∀u ∈ V.
Observe that (CP2) can also be expressed in the framework of (CP1).",2. Preliminaries,[0],[0]
"We simply consider an augmented hypergraph Ĥ such that all vertices V are treated as unlabeled, and for each u ∈ L, we add a new vertex û with label f∗u and a new undirected edge {u, û} with weight µu.",2. Preliminaries,[0],[0]
"Then, it follows that the convex program (CP1) for the augmented instance for Ĥ is exactly the same as (CP2).
",2. Preliminaries,[0],[0]
Challenges Ahead.,2. Preliminaries,[0],[0]
"We next outline how we resolve the encountered challenges when we use (CP1) for semisupervised learning.
",2. Preliminaries,[0],[0]
"• Unlike the case for normal graphs, the set OPT can contain more than one optimal solution for (CP1).",2. Preliminaries,[0],[0]
"In Section 3, we prove some structural properties of the convex program, and illustrate that each u ∈ N has some confidence interval from which we can predict its label.",2. Preliminaries,[0],[0]
• The function Φ is not everywhere differentiable.,2. Preliminaries,[0],[0]
"Hence, we use the subgradient method (Shor et al., 1985).",2. Preliminaries,[0],[0]
"In Section 4, we give a method to generate a subgradient, which is inspired by the continuous diffusion processes for hypergraphs (Louis, 2015) and directed graphs (Yoshida, 2016), and our method can in fact be viewed as a discretized version.",2. Preliminaries,[0],[0]
"In general, a minimizer for (CP1) might not be unique.",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"Hence, we introduce the concept of confidence interval.
",3. Confidence Interval for Semi-supervised Learning,[0],[0]
Definition 3.1 (Confidence Interval),3. Confidence Interval for Semi-supervised Learning,[0],[0]
"For each u ∈ V , we define its confidence interval to be [mu,Mu], where mu := minf∈OPT fu and Mu := maxf∈OPT fu.",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"The confidence intervals induce the lower and the upper confidence vectors, ~m and ~M ∈ RV , respectively.
",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"In Section 3.1, we give the proof of the following lemma, which states that the confidence vectors ~m and ~M are optimal solutions, and so are their convex combinations.
",3. Confidence Interval for Semi-supervised Learning,[0],[0]
Lemma 3.1 (Confidence Vectors Give Optimal Solutions),3. Confidence Interval for Semi-supervised Learning,[0],[0]
For any λ ∈,3. Confidence Interval for Semi-supervised Learning,[0],[0]
"[0, 1], the convex combination λ~m + (1− λ) ~M",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"∈ OPT is optimal for (CP1).
",3. Confidence Interval for Semi-supervised Learning,[0],[0]
Semi-supervised Learning via Confidence Interval.,3. Confidence Interval for Semi-supervised Learning,[0],[0]
Lemma 3.1 suggests what one can do when (CP1) has more than one optimal solution.,3. Confidence Interval for Semi-supervised Learning,[0],[0]
"Specifically, in Algorithm 1, the
average vector 12 (~m + ~M) ∈ OPT can be used for label prediction.",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"We show that the confidence vectors ~m and ~M can be recovered from any optimal solution f ∈ OPT, which in turn can be estimated by the subgradient method described in Section 4.",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"Algorithm 1 Semi-Supervised Learning
1: Input: Directed hypergraph H = (V,E,w), labels f∗L for labeled vertices L 2: Compute (estimated) confidence vectors (~m, ~M) ∈",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"RN × RN , either by Algorithm 2 or 3.",3. Confidence Interval for Semi-supervised Learning,[0],[0]
3: Compute average vector fN ← 12 (~m+ ~M).,3. Confidence Interval for Semi-supervised Learning,[0],[0]
4: Compute threshold θ ← 1|N | ∑ u∈N fu.,3. Confidence Interval for Semi-supervised Learning,[0],[0]
"5: for each u ∈ N do 6: if fu ≥ θ then 7: f̂u ← +1; 8: else 9: f̂u ← −1;
10: end if 11: end for 12: return f̂N
Fine-Tuning Parameters.",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"In view of Lemma 3.1, one could further optimize the choice of λ ∈",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"[0, 1] in defining fN ← λ~m+ (1−λ) ~M in Line 3.",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"Similarly, one could pick the threshold θ to be the ϑ-percentile of the sorted coordinates of fN , for some choice of ϑ ∈",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"[0, 1].",3. Confidence Interval for Semi-supervised Learning,[0],[0]
The parameters λ and ϑ can be tuned using standard techniques like cross-validation.,3. Confidence Interval for Semi-supervised Learning,[0],[0]
"However, to illustrate our concepts, we keep the description simple without introducing too many free parameters.",3. Confidence Interval for Semi-supervised Learning,[0],[0]
We derive some properties of the confidence vectors to prove Lemma 3.1.,3.1. Properties of Confidence Vectors,[0],[0]
"The full proofs of Lemma 3.2 and 3.3 are given in the full version.
",3.1. Properties of Confidence Vectors,[0],[0]
"Given a feasible solution f ∈ RV to (CP1), we define the following:
1. Se(f) := arg maxu∈Te fu ⊆ Te and Ie(f) := arg minv∈He fv ⊆ He.",3.1. Properties of Confidence Vectors,[0],[0]
2. f(Se),3.1. Properties of Confidence Vectors,[0],[0]
:= maxu∈Te fu and f(Ie) := minv∈He fv .,3.1. Properties of Confidence Vectors,[0],[0]
"Hence, we have ∆e(f) = f(Se)− f(Ie).",3.1. Properties of Confidence Vectors,[0],[0]
3.,3.1. Properties of Confidence Vectors,[0],[0]
"The set of active edges with respect to f is E(f) := {e ∈ E : ∆e(f) > 0}.
",3.1. Properties of Confidence Vectors,[0],[0]
"The following lemma states even though a minimizer for (CP1) might not be unique, there are still some structural properties for any optimal solution.
",3.1. Properties of Confidence Vectors,[0],[0]
Lemma 3.2 (Active Edges in an Optimal Solution) Suppose f and g are optimal solutions to (CP1).,3.1. Properties of Confidence Vectors,[0],[0]
"Then, for all e ∈ E, [∆e(f)]+ = [∆e(g)]+.",3.1. Properties of Confidence Vectors,[0],[0]
"In particular, this implies that the set of active edges E∗",3.1. Properties of Confidence Vectors,[0],[0]
":= E(f) = E(g) in any op-
timal solution is uniquely determined.",3.1. Properties of Confidence Vectors,[0],[0]
"Hence, for e ∈ E∗, we can define the corresponding ∆∗e = ∆e(f).
",3.1. Properties of Confidence Vectors,[0],[0]
"Definition 3.2 (Pinned Vertex) An unlabeled vertex u is pinned in a solution f ∈ RV if there exist active edges e and e′ ∈ E(f) such that u ∈ Se(f)∩ Ie′(f), in which case we say that the edges e and e′ pin the vertex u under f .
",3.1. Properties of Confidence Vectors,[0],[0]
Lemma 3.3 (Extending an Active Edge),3.1. Properties of Confidence Vectors,[0],[0]
Suppose edge e ∈ E(f) is active in an optimal solution f .,3.1. Properties of Confidence Vectors,[0],[0]
"If He does not contain a vertex labeled with −1, then there exist u ∈ Ie(f) and another active edge e′ ∈ E(f) such that the following holds.
",3.1. Properties of Confidence Vectors,[0],[0]
(a) The edges e and e′,3.1. Properties of Confidence Vectors,[0],[0]
"pin u under f , i.e., u ∈ Se′(f).",3.1. Properties of Confidence Vectors,[0],[0]
(b),3.1. Properties of Confidence Vectors,[0],[0]
"If g is an optimal solution, then Ie(f) ∩ Se′(f) =
Ie(g) ∩ Se′(g) and fu = gu.",3.1. Properties of Confidence Vectors,[0],[0]
vertex labeled with +1.,An analogous result holds when Te does not contain any,[0],[0]
∗(Ie),"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
":= minu∈He fu are uniquely determined by any optimal solution f .
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
Corollary 3.1 (Pinned Vertices),"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"In any optimal solution, the set of pinned vertices is uniquely determined.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
We use L∗ to denote the set of labeled or pinned vertices in an optimal solution.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Then, for each u ∈ L∗, its value f∗u in any optimal solution is also uniquely determined.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"From Corollary 3.1, the confidence interval for any u ∈ L∗ contains exactly one value, namely the unique value f∗u in any optimal solution.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"The following lemma gives a characterization of an optimal solution.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
Lemma 3.4 Characterization of Optimal Solutions,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"A solution f to (CP1) is optimal iff the following conditions hold.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"(a) For each u ∈ L∗, fu = f∗u .","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"(b) For each active edge e ∈ E∗, both the maximum
maxu∈Te fu and the minimum minv∈He fv are attained by vertices in L∗. (c) For each inactive edge e /∈","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"E∗,","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
for all u ∈ Te and v ∈,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"He, fu ≤ fv .
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
Proof: We first observe that Corollary 3.1 states that the values of the vertices in L∗ are uniquely determined in any optimal solution.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Hence, any optimal solution must satisfy the three conditions.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"We next show that the three conditions implies that the objective value is optimal.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Once the values for vertices in L∗ are fixed, Lemma 3.3 and condition (b) implies that the contribution of all active edges E∗ are determined and are the same as any optimal solution.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Finally, condition (c) implies that edges not in E∗ do not have any contribution towards the objective function.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Hence, any solution satisfying the three conditions must be optimal.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
Deriving Confidence Vectors.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"To prove Lemma 3.5, we define a procedure that returns a vector ~m ∈ V R such that for any optimal f ∈ OPT, we have f ≥ ~m.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Moreover, we shall show that ~m ∈ OPT and hence ~m is the lower confidence vector.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
The argument for the upper confidence vector ~M is similar.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"For the special case of undirected hypergraphs, the procedure can be simplified to Algorithm 2 in Section 3.2.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
Lemma 3.5 (Confidence Vectors are Optimal: Proof of Lemma 3.1),"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
The confidence vectors ~m and ~M defined in Definition 3.1 are optimal solutions to (CP1).,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"This implies that any of their convex combination is also optimal.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Proof: We give a procedure that returns a vector ~m such that at any moment during the procedure, the following invariant is maintained: for any f ∈ OPT, f ≥ ~m.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"The following steps correspond to maintaining the conditions in Lemma 3.4.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
(a) Initialization.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"For v ∈ L∗, set mv := f∗v ; for v /∈ L∗, set mv := −1.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"This satisfies the invariant, because for any f ∈ OPT and any v ∈ L∗, fv = f∗v .
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
(b) Preserving Active Edges.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"For each v /∈ L∗, set mv ← max{mv,maxe∈E∗:v∈He f∗(Ie)}.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Observe that Lemma 3.4(b) implies that for any optimal f ∈ OPT, any e ∈ E∗ and any v ∈","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"He, fv ≥ f∗(Ie).","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Hence, the invariant is maintained.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
(c) Preserving Inactive Edges.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
While there is an inactive edge e /∈ E∗,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"such that u ∈ Te, v ∈","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"He and mu > mv , set mv ← mu.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
We argue why each such update preserves the invariant.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
Consider any optimal f ∈ OPT.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Before this update, the invariant holds.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Hence, we have mu ≤ fu.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Moreover, Lemma 3.4 implies that fu ≤ fv .","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Therefore, after setting mv ← mu, we still have mv ≤ fv .
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Finally, observe that after step (b), the coordinates of ~m can take at most n distinct values.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Moreover, after each update in step (c), one coordinate of ~m must increase strictly.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Hence, this procedure will terminate.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"We next argue that ~m is an optimal solution by checking that it satisfies the conditions in Lemma 3.4.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
Condition (a).,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Observe that for each v ∈ L∗, mv is initialized to f∗v .","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
Afterwards the value mv could only be increased.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"However, because the invariant holds when the procedure terminates, it must be the case that mv = f∗v at the end.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
Condition (b).,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"The procedure makes sure that at the end of
step (b), for every active edge e ∈ E∗, minv∈He mv can be attained by some vertex in L∗. Since only mv for v /∈ L∗ can be increased in step (c), it follows that in the end, the minimum can still be attained by some vertex in L∗.
Next, consider u ∈ Te, where e ∈ E∗. For any optimal solution f , Lemma 3.3 implies that fu ≤ f∗(Se).","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Hence, the invariant implies thatmu ≤ fu ≤ f∗(Se).","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Since condition (a) holds, this means that maxv∈Te mv can be attained by some vertex in L∗.
Condition (c).","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"This is clearly satisfied because of the while-termination condition.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Therefore, we have ~m ∈ OPT, as required.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
The proof for the upper confidence vector ~M is similar.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"We omit the detailed proof and just give the corresponding procedure to return ~M .
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
(a) Initialization.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"For v ∈ L∗, set Mv := f∗v ; for v /∈ L∗, set Mv := +1.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
(b) Preserving Active Edges.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"For each v /∈ L∗, set Mv ← min{Mv,mine∈E∗:v∈Te f∗(Se)}.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
(c) Preserving Inactive Edges.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
While there is an inactive edge e /∈ E∗,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"such that u ∈ Te, v ∈","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"He and Mu > Mv , set Mu ←Mv .
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"The same argument can show that for any optimal f ∈ OPT, we have f ≤ ~M .","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Moreover, we also have ~M ∈ OPT.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"As mentioned before, the proof of Lemma 3.5 implicitly gives a procedure to compute the confidence vectors from any optimal solution.",3.2. Computing the Confidence Interval,[0],[0]
"For the special case of undirected hypergraphs, a simplified version of the procedure is given in Algorithm 2.
",3.2. Computing the Confidence Interval,[0],[0]
"Alternatively, we can try to solve the convex program (CP1), for example using Algorithm 5 in Section 4, from two initial feasible solutions to heuristically estimate the confidence vectors.",3.2. Computing the Confidence Interval,[0],[0]
"In Algorithm 3, one instance approaches an optimal solution from high f values and the other from low f values.",3.2. Computing the Confidence Interval,[0],[0]
Resolving Ties.,4. Subgradient Method via Markov Operator,[0],[0]
Observe that Φ : RN → R is differentiable at fN ∈ RN that has distinct coordinates.,4. Subgradient Method via Markov Operator,[0],[0]
"For the purpose of computing a subgradient, we assume that there is some global ordering π on V to resolve ties among coordinates with the same value.",4. Subgradient Method via Markov Operator,[0],[0]
"In particular, the vertices in L having label +1 are the highest, and those in L labeled −1 are the lowest.",4. Subgradient Method via Markov Operator,[0],[0]
"Hence, in this section, we may assume that any arg max or arg min operator over a subset of vertices
Algorithm 2 Confidence Intervals for Undirected Hypergraphs
1: Input: Undirected hypergraph H = (V,E,w), label vector f∗L and tolerance ≥ 0.",4. Subgradient Method via Markov Operator,[0],[0]
"2: Let f be a solution of (CP1), either by Algorithm 5 or by PDHG method (Hein et al., 2013) 3: For all v ∈ V , set p(v)← v, mv ← −1, Mv ← +1.",4. Subgradient Method via Markov Operator,[0],[0]
"4: Ê := {e ∈ E : ∆e(f) ≤ } 5: while ∃e1 6= e2 ∈ Ê, e1 ∩ e2 6= ∅",4. Subgradient Method via Markov Operator,[0],[0]
"do 6: Ê ← (Ê \ {e1, e2}) ∪ {e1 ∪ e2} 7: end while 8: for each e ∈ Ê do 9: x← an arbitrary vertex in e
10: for each vertex v ∈ e do 11: p(v)← p(x) 12: end for 13: end for 14: for each vertex v ∈ L do 15: mp(v) ← f∗v , Mp(v) ← f∗v 16: end for 17: for each edge e ∈ E such that ∆e(f) >",4. Subgradient Method via Markov Operator,[0],[0]
do 18: for each vertex v ∈,4. Subgradient Method via Markov Operator,[0],[0]
e,4. Subgradient Method via Markov Operator,[0],[0]
"do 19: mp(v) ← max{mp(v), f(Ie)} 20: Mp(v) ← min{Mp(v), f(Se)} 21: end for 22: end for 23: for each vertex v ∈ V do 24: mv ← mp(v), Mv ←Mp(v) 25: end for 26: return vectors (~m, ~M)
will return a unique vertex.
",4. Subgradient Method via Markov Operator,[0],[0]
"We next define a Markov operator that is inspired from the diffusion processes on hypergraphs (Louis, 2015) and directed graphs (Yoshida, 2016) in the context of defining Laplacians.",4. Subgradient Method via Markov Operator,[0],[0]
"We denote the projection operator ΠN : RV → RN that takes f ∈ RV and returns the restricted vector fN ∈ RN .
",4. Subgradient Method via Markov Operator,[0],[0]
Lemma 4.1 For f ∈,4. Subgradient Method via Markov Operator,[0],[0]
"[−1, 1]V that is feasible in (CP1), the Markov operator Mf given in Algorithm 4 returns a subgradient of Φ : RN → R at fN .
",4. Subgradient Method via Markov Operator,[0],[0]
"Proof: (Sketch) Observe that if fN ∈ RN has distinct coordinates, then Φ is differentiable at fN , and Mf gives exactly the gradient (which is the only possible subgradient in this case).",4. Subgradient Method via Markov Operator,[0],[0]
"Observe that in our subgradient method application, we could imagine that at every iteration, infinitesimal perturbation is performed on the current solution to ensure that all coordinates are distinct, and ties are resolved according to our global ordering π.
",4. Subgradient Method via Markov Operator,[0],[0]
"Algorithm 3 Estimate confidence interval 1: Input: Directed hypergraph H = (V,E,w), labels f∗L
for labeled vertices L 2: Construct feasible f (0,+)N ← +1 ∈ RN with all entries
being +1; 3: Construct feasible f (0,−)N ← −1 ∈",4. Subgradient Method via Markov Operator,[0],[0]
"RN with all entries
being −1; 4: ~M ← SGM(f (0,+)N ); 5: ~m← SGM(f (0,−)N ); 6: return the vectors (~m, ~M)
",4. Subgradient Method via Markov Operator,[0],[0]
"Algorithm 4 Markov Operator M : RV → RN
1: Input: Directed hypergraph H = (V,E,w), feasible f ∈ RV for (CP1) 2: Construct symmetric matrix A ∈ RV×V ; set A← 0.",4. Subgradient Method via Markov Operator,[0],[0]
3: for each e ∈ E such that ∆e(f) > 0,4. Subgradient Method via Markov Operator,[0],[0]
do 4: u← arg maxu∈Te fu; 5: v ← arg minv∈He fv; 6: Auv ← Auv + we; 7: (The same is done forAvu becauseA is symmetric.),4. Subgradient Method via Markov Operator,[0],[0]
"8: end for 9: Construct diagonal matrix W ∈ RN×N ; set W ← 0.
10: for each u ∈ N",4. Subgradient Method via Markov Operator,[0],[0]
do 11:,4. Subgradient Method via Markov Operator,[0],[0]
"Wuu ← ∑ v∈V Auv; 12: end for 13: return (WΠN −ΠNA)f
Hence, as the magnitude of the perturbation tends to zero, if the global ordering π is preserved, then the gradient remains the same, which implies that the gradient is also the subgradient when the perturbation reaches 0.
",4. Subgradient Method via Markov Operator,[0],[0]
"Using the Markov operator M as a subroutine to generate a subgradient, we have the following subgradient method (SGM) (Shor et al., 1985).
",4. Subgradient Method via Markov Operator,[0],[0]
"Algorithm 5 Subgradient Method SGM(f (0)N ∈ RN ) 1: Input: Directed hypergraph H = (V,E,w) with la-
bels f∗L for labeled vertices L, initial feasible solution f (0) N ∈",4. Subgradient Method via Markov Operator,[0],[0]
"RN , step size {ηt := 1 t }t≥1
2: t← 1; 3: (Throughout the algorithm, f (t)L = f ∗ L is given by the
labeled vertices.)",4. Subgradient Method via Markov Operator,[0],[0]
4: while Solution f (t)N has not “stabilized” do 5: g(t)N ← Mf (t−1) ∈ RN ; 6: f (t)N = f (t−1) N,4. Subgradient Method via Markov Operator,[0],[0]
"− ηt ·
g (t)",4. Subgradient Method via Markov Operator,[0],[0]
"N∥∥∥g(t)N ∥∥∥
2
;
7: t← t+ 1; 8: end while 9: return f (t)
",4. Subgradient Method via Markov Operator,[0],[0]
Stabilizing Condition.,4. Subgradient Method via Markov Operator,[0],[0]
"Our experiments in Section 5 suggest that it suffices to run the solver for a short time, after which a better feasible solution f does not improve the prediction accuracy.",4. Subgradient Method via Markov Operator,[0],[0]
Our experiments are run on a standard PC.,5. Experimental Results,[0],[0]
"In our graphs, each point refers to a sample mean, and the height of the vertical bar is the standard error of the mean.",5. Experimental Results,[0],[0]
"We show that our treatment of hypergraphs performs better than the previously best method in (Hein et al., 2013).
",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
Hypergraph Model.,5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"We use three datasets from the UCI Machine Learning Repository (Lichman, 2013): mushroom, covertype45 and covertype67.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"As in (Hein et al., 2013), each dataset fits into the hypergraph learning model in the following way.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"Each entry in the dataset corresponds to a vertex, which is labeled either +1 or −1.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"Moreover, each entry has some categorical attributes.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"For each attribute and each realized value for that attribute, we form a unit-weight hyperedge containing all the vertices corresponding to entries having that attribute value.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"To summarize, below are the properties of the resulting hypergraphs.
",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"Dataset mushroom covertype45 covertype67
n = |V",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"| 8124 12240 37877 m = |E| 112 104 123 k =∑
e∈E |e| m
1523 1412 3695
Semi-supervised Learning Framework.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"We compare our semi-supervised learning framework with that in (Hein et al., 2013), which was previously the best (compared to (Zhou et al., 2006), for instance).",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"Specifically, we compare the prediction accuracy of the following two prediction algorithms.
1.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
Confidence Interval (CI).,5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"We use hard constraints (CP1) and confidence intervals for prediction, as described in Algorithm 1 in Section 3. 2.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"Hein et al. We implement the method described in (Hein et al., 2013), which uses soft constraints (regularized version), plus 5-fold cross validation to determine the regularization parameter.
",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
Testing Methodology.,5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"Since we focus on prediction accuracy, using either subgradient method or PDHG (Hein et al., 2013) for solving the underlying convex programs in each algorithm produces the same results.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"For each algorithm candidate, we try different sizes of labeled vertices L, where l = |L| ranges from 20 to 200.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"For each size l
of labeled vertices, we randomly pick l vertices from the dataset to form the set L and treat the rest as unlabeled vertices; we re-sample if only one label (+1 or −1) appears in L. For each size",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"l, we perform 100 trials to report the average error rate together with its standard error.
Results.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"Our experiment can recover the results reported in (Hein et al., 2013).",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"The test error for the two algorithms on the three datasets is presented in Figure 5.1, which shows that our CI method consistently has lower test error than the one in (Hein et al., 2013).",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
Different Solvers.,5.2. Comparing Running Times of Solvers,[0],[0]
"We compare the running times of the following two convex program solvers:
• Subgradient Method (SG), proposed by us.",5.2. Comparing Running Times of Solvers,[0],[0]
"Empirically, the step size ηt := 1
(t+1) min( 0.16t 105 ,1)
gives good
performance.",5.2. Comparing Running Times of Solvers,[0],[0]
"For large t, ηt grows like 1t and so the method converges; however, for small t, we would like a larger step size to speed up convergence.",5.2. Comparing Running Times of Solvers,[0],[0]
"• Primal-Dual Hybrid Gradient (PDHG), proposed in (Hein et al., 2013).",5.2. Comparing Running Times of Solvers,[0],[0]
"We choose σ = τ = 1√
1+d ,
where d is the maximum degree.
",5.2. Comparing Running Times of Solvers,[0],[0]
Theoretical Analysis.,5.2. Comparing Running Times of Solvers,[0],[0]
"Given a hypergraph with n vertices and m edges, where the average size of an edge is k, each vertex on average appears in mkn edges.",5.2. Comparing Running Times of Solvers,[0],[0]
"For SG, we use a heap-based data structure to maintain the vertices within a hyperedge.",5.2. Comparing Running Times of Solvers,[0],[0]
"Vertices attaining the maximum and the minimum value within a hyperedge can be retrieved in O(1) time, and a value update takes O(log k) time.",5.2. Comparing Running Times of Solvers,[0],[0]
"In each iteration, at most 2m vertices will have their values updated.",5.2. Comparing Running Times of Solvers,[0],[0]
"Hence, in each iteration, SG takes time 2m·mkn ·O(log k) = O(m
2k n log k).",5.2. Comparing Running Times of Solvers,[0],[0]
"In the description of PDHG in (Hein et al., 2013), each iteration takesO(mk log k) time.",5.2. Comparing Running Times of Solvers,[0],[0]
"Hence, when n m, each iteration of SG will be significantly faster, although in general, the number of iterations required by the subgradient method can be larger than that for PDHG.
",5.2. Comparing Running Times of Solvers,[0],[0]
Testing Methodology.,5.2. Comparing Running Times of Solvers,[0],[0]
"In each experiment, we consider the hypergraph from one of the above three datasets.",5.2. Comparing Running Times of Solvers,[0],[0]
"We pick l = 160 vertices at random as the labeled vertices L, and form the corresponding convex program (CP1) for the two solvers, where the initial values for unlabeled vertices are chosen independently to be uniformly at random from [−1, 1].",5.2. Comparing Running Times of Solvers,[0],[0]
"To compare the performance, we run the two solvers on the same convex program, and record each trajectory of the objective value versus the time duration.",5.2. Comparing Running Times of Solvers,[0],[0]
"According to experience, 100 seconds is good enough for either solver to reach an almost optimal solution, and we use the minimum value achieved by the two solvers after 100 seconds as an estimate for the true optimal value OPT.",5.2. Comparing Running Times of Solvers,[0],[0]
"Then, we scan each trajectory, and for each relative gap
∈ {10−i : i = 1, 2, . . .",5.2. Comparing Running Times of Solvers,[0],[0]
", 6}, we find the smallest time T ( ) after which the objective value is at most OPT away from the estimate OPT.",5.2. Comparing Running Times of Solvers,[0],[0]
Each instance of the experiment is repeated 100 times (with different sets of labeled vertices) to obtain an average of those T ( )’s and their standard error.,5.2. Comparing Running Times of Solvers,[0],[0]
"For each relative gap , we also report the test error for using a feasible solution that is OPT away from the presumed optimal value OPT.
Results.",5.2. Comparing Running Times of Solvers,[0],[0]
Both solvers have similar performance.,5.2. Comparing Running Times of Solvers,[0],[0]
"As predicted by our theoretical analysis, we see in Figure 5.2 that SG has an advantage when the number n of vertices is much larger than the number m of edges, which is the case for the the last dataset covertype67.",5.2. Comparing Running Times of Solvers,[0],[0]
"Moreover, in Figure 5.3, we see that achieving a relative gap smaller than 10−4 has almost no effect on improving the prediction accuracy.",5.2. Comparing Running Times of Solvers,[0],[0]
"Hence, we can conclude that for either solver, it takes roughly 10 to 20 seconds to produce a solution for the underlying convex program that can give good predic-
tion accuracy.",5.2. Comparing Running Times of Solvers,[0],[0]
DBLP Dataset.,5.3. Directed Hypergraph: More Powerful,[0],[0]
"We use the DBLP (Ley, 2009) dataset.",5.3. Directed Hypergraph: More Powerful,[0],[0]
Each paper is represented by a vertex.,5.3. Directed Hypergraph: More Powerful,[0],[0]
"We include papers from year 2000 to 2015 from conferences belonging to the following research areas to conduct our experiments:
• 7049 papers from machine learning (ML): NIPS, ICML • 2539 papers from theoretical computer science (TCS): STOC, FOCS • 3374 papers from database (DB): VLDB, SIGMOD
We perform the following prediction tasks: (a) ML (+1) vs TCS (-1), and (b) ML (+1) vs DB (-1).
",5.3. Directed Hypergraph: More Powerful,[0],[0]
The details of the experiment setup and the results are given in the full version.,5.3. Directed Hypergraph: More Powerful,[0],[0]
We revisit semi-supervised learning on hypergraphs.,abstractText,[0],[0]
"Same as previous approaches, our method uses a convex program whose objective function is not everywhere differentiable.",abstractText,[0],[0]
"We exploit the non-uniqueness of the optimal solutions, and consider confidence intervals which give the exact ranges that unlabeled vertices take in any optimal solution.",abstractText,[0],[0]
"Moreover, we give a much simpler approach for solving the convex program based on the subgradient method.",abstractText,[0],[0]
"Our experiments on real-world datasets confirm that our confidence interval approach on hypergraphs outperforms existing methods, and our sub-gradient method gives faster running times when the number of vertices is much larger than the number of edges.",abstractText,[0],[0]
Re-revisiting Learning on Hypergraphs:  Confidence Interval and Subgradient Method,title,[0],[0]

1	46	At the level of syntax, one attractive hypothesis for such regularities is that any grammars of languages have evolved under the pressures, or biases, to avoid structures that are difficult to process.
3	31	Such syntactic regularities can also be useful in applications, in particular in unsupervised (Klein and Manning, 2004; Mareček and Žabokrtský, 2012; Bisk and Hockenmaier, 2013) or weaklysupervised (Garrette et al., 2015) grammar induction tasks, where the models try to recover the syntactic structure of language without access to the syntactically annotated data, e.g., from raw or partof-speech tagged text only.
4	61	In these settings, finding better syntactic regularities universal across languages is essential, as they work as a small cue to the correct linguistic structures.
5	37	A preference exploited in many previous works is favoring shorter dependencies, which has been encoded in various ways, e.g., initialization of EM (Klein and Manning, 2004), or model parameters (Smith and Eisner, 2006), and this has been the key to success of learning (Gimpel and Smith, 2012).
11	16	Intuitively during learning our models explore the restricted search space, which excludes linguistically implausible trees, i.e., those with deeper levels of center-embedding.
17	15	Our main empirical finding is that though two biases, avoiding center-embedding and favoring shorter dependencies, are conceptually similar (both favor simpler grammars), often they capture different aspects of syntax, leading to different grammars.
25	14	PDA Let us assume a CFG is given, and it is in CNF.
28	22	We use a vertical bar to signify the append operation, e.g., σ = σ′|σ1 denotes σ1 is the topmost symbol of σ.
48	44	That is, the tree in Figure 4(a) is the minimal, one degree of centerembedded tree, where the constituent rooted at A is embedded into a larger constituent rooted at D. Multiple, or degree ≥ 2 of center-embedding occurs if this constituent is also embedded into another larger constituent.
49	25	Note that it is only COMP that consumes the top two symbols on the stack.
67	20	As shown in Smith (2006), when training with EM we can increase the likelihood of p′(z, x|θ) by just using the expected counts from an E-step on the unnormalized distribution p(z, x|θ)f(z, x).
70	23	For example, when δ = 1 the model only explores trees without centerembedding, i.e., right- or left-linear trees.
73	36	Specifically, we relax the depth calculation in COMP (Eq.
86	14	For this particular model, we take the following approach to formulate it in LC parsing: 1) converting a dependency tree into a binary CFG parse; 2) applying LC transform on it; and 3) encoding DMV parameters into each CFG rule of the transformed grammar.3 Below we discuss a problem for (1) and (2), and then consider parameterization.4 Spurious ambiguity The central issue for applying LC parsing is the spurious ambiguity in dependency grammars.
91	17	Naive method Let us begin with the grammar below, which suffers from the spurious ambiguity: SHIFT: X[wh]d → wh SCAN: X[wh]d → X[wh/wp]d wp L-PRED: X[wp/wp]d → X[wh]d (wxh wp); R-PRED: X[wh/wp]d → X[wh]d (wyh wp); L-COMP: X[wh/wp]d → X[wh/wp]dX[wa]d ′ (wxa wp); R-COMP: X[wh/wa]d → X[wh/wp]dX[wp]d ′ (wyp wa).
93	12	Note that only PRED and COMP create new dependency arcs and we divide them depending on the direction of the created arcs (L and R).
103	13	In summary, our method detects center-embedding for a dependency tree, but the degree is determined based on the structure of the binarized CFG parse.
110	13	For example, Universal dependencies (UD) is the recent standard in annotation and prefers content words to be heads, but as shown below this is very different from the conventional style, e.g., the one in CoNLL shared tasks (Johansson and Nugues, 2007): Ivan is the best dancer nsbj cop det amod sbj nmod nmod prd UD CONLL The problem is that both trees are correct under some linguistic theories but the standard metric, unlabeled attachment score (UAS), only takes into account the annotation of the current gold data.
112	27	To this end, we try to eliminate such arbitrariness in our evaluation as much as possible in the following way: • We experiment on UD, in which every treebank follows the consistent UD style annotation.
140	16	For this, we use the WSJ data, which we obtain in UD style from the Stanford CoreNLP (ver.
142	26	Both DEP and LEN have one parameter: the maximum depth δ, and γ (Eq.
147	56	When we see “No root constraint” block, we notice that our DEP boosts the performance in many languages (e.g., Bulgarian, French, Indonesian, and Portuguese), though LEN performs equally well and in average, LEN performs slightly better.
150	33	Interestingly, in these settings DEP performs the best.
151	73	The model competes with Naseem et al.’s system in average, and outperforms it in many languages, e.g., Bulgarian, Czech, etc.
152	31	LEN, on the other hand, decreases the average score.
154	13	To shed light on this, we inspected the output parses of English with no root constraints, and found that the types of errors are very different across constraints.
156	30	One difference between trees is in the constructions of phrase “On ... pictures”.
159	17	These observations may partially answer the question above.
163	49	Thus the effect of the length bias seems somewhat overlapped with the root POS constraints, which may be the reason why they do not well collaborate with each other.
165	14	To this end, we convert both the predicted and gold dependency trees into the unlabeled bracket structures, and then compare them on the standard PARSEVAL metrics.

0	38	Humans appear to organize and remember everyday experiences by imposing a narrative structure on them (Nelson, 1989; Thorne and Nam, 2009; Bruner, 1991; McAdams et al., 2006), and many genres of natural language text are therefore narratively structured, e.g. dinner table conversations, news articles, user reviews and blog posts (Polanyi, 1989; Jurafsky et al., 2014; Bell, 2005; Gordon et al., 2011).
2	33	To date, there has been limited work on computational models for recognizing the expression of the protagonist’s goals and desires in narrative texts, and tracking their corresponding narrative outcomes.
3	85	We introduce a new corpus DesireDB of∼3,500 first-person informal narratives with annotations for desires and their fulfillment status, available online.1 Because first-person narratives often revolve around the narrator’s private states and goals (Labov, 1972), this corpus is highly suitable as a testbed for identifying human desires and their outcomes.
9	128	Our approach builds on seminal work on a computational model of Lehnert’s plot units, that applied modern NLP tools to tracking narrative affect states in Aesop’s Fables (Goyal et al., 2010; Lehnert, 1981; Goyal and Riloff, 2013).
10	19	Our framing of the problem is also inspired by recent work that identifies three forms of desire expressions in short narratives from MCTest and SimpleWiki and develops models to predict whether desires are fulfilled or unfulfilled (Chaturvedi et al., 2016).
45	43	We develop a systematic method to identify desire and goal statements, and then collect annotations to create goldstandard labels of fulfillment status as well as spans of text marked as evidence.
46	95	Our corpus is a subset of the Spinn3r corpus (Burton et al., 2011, 2009), consisting of firstperson narratives from six personal blog domains: livejournal.com, wordpress.com, blogspot.com, spaces.live.com, typepad.com, travelpod.com.
47	31	To create our dataset, we select only desire expressions involving some version of the first-person.
48	44	In first-person narratives, the narrator and protagonist naturally align which makes it much easier to identify and track the protagonist than in fiction or historical genre.
50	109	Put simply, zooming in on first-person desires means that desire and its aftermath are more likely to be highly topical for the narrative.
52	53	Human desires and goals can be expressed linguistically in many different ways, including both explicit verbal and nominal markers of desire or necessity (e.g., want, hope) and more general markers of urges (e.g., craving, hunger, thirst).
54	36	We then selected 100 representative instances of that frame in English Gigaword (Parker et al., 2011) by first selecting the 10 most frequent lexical units in that frame, and then selecting 10 random instances per lexical unit.
64	31	We extract stories containing the verbal patterns of desire, with five sentences before and after the desire expression sentence as context (See Fig.
66	27	We also study the effect of prior and post context in understanding desire fulfillment in our experiments (Section 4) and show that using the narrative context preceding the desire statement improves the results.
73	44	The annotators were selected from a list of prequalified workers who had successfully passed a test on a textual entailment task with 100% correct answers.
79	26	About half of the desire expressions (53%) were labeled Fulfilled and about one third (31%) were labeled Unfulfilled.
82	28	For in- stance, decided to and couldn’t wait are highly skewed towards Fulfilled as opposed to hoped to which includes 68% Unfulfilled instances.
88	38	The first part is the extracted data including the desire expression with prior and post context, and the second part is the gold-standard annotations.
96	28	We conducted a range of experiments on predicting fulfillment status of desires and goals, using different features and models, including LSTM architectures that can encode the sequential structure of the narratives.
117	51	From a desire expression of the form ‘X Ved S’, we extract the lexical feature Desire-Verb, the lemma for V. We also extract a list of focal words, the content words in embedded sentence S. In Figure 4, these are ‘do’, ‘go’, and ‘run’.
122	26	For the classes, we manually coded all overt discourse relation markers in the Penn Discourse Treebank three ways(violation, meeting, or neutral), leading to 15 meeting markers (‘accordingly’, ‘so’, ‘ultimately’, ‘finally’) and 31 violating (‘although’, ‘rather’, ‘yet’, ‘but’).
124	29	Beyond the use of WordNet expansion for Focal-Word-Mention-i, we also used the Connotation Lexicon (Feng et al., 2013), a lexical resource marking very general connotation polarities (positive or negative) of words (as opposed to more specific sentiment lexicons).
130	21	We thus apply neural network models suitable for sequence learning, in order to directly encode the order of the sentences in the story and distinguish between prior and post context.
131	55	We use two different architectures of LSTM (Long Short-Term Memory) (Hochreiter and Schmidhuber, 1997) models to generate sentence embeddings and then apply a three-layer RNN (Recurrent Neural Network) for classification.
135	18	That single representation is then concatenated with embedding-feature concatenation of desire sentence and is fed into a multi-layer network to yield a single binary output.
148	22	The results indicate that adding features from prior context alone improves the results.
154	57	4.3, indicates that Discourse features are better predictors of fulfillment status, so we present results using only Discourse features in addition to BOW and ALL.
188	89	Finally, we hope to turn to automatically detecting instances of desire expressions that give rise to the kind of goal-oriented narratives DesireDB contains.
189	59	Here we have used highprecision search patterns but our annotations show that such patterns still admitted 134 hypothetical desires (e.g., ‘If I had wanted to buy a book’).
190	187	It would appear that distinguishing hypothetical vs. real desires itself could be an interesting problem.

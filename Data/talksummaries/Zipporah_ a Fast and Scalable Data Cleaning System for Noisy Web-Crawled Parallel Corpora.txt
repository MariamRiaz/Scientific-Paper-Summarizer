2	7	To acquire a massive parallel corpus, many researchers have been using the Internet as a resource, but the quality of data acquired from the Internet usually has no guarantee, and data cleaning/data selection is needed before the data is used in actual systems.
5	9	In this paper we introduce Zipporah1, a fast and scalable system which can select an arbitrary size of good data from a large noisy data pool to be used in SMT model training.
10	14	XenC (Rousseau, 2013), an open-source tool, also selects data based on cross-entropy scores on language models.
13	22	Lü et al. (2007) redistributed different weights for sentence pairs/predefined sub-models.
15	26	The qeclean system (Denkowski et al., 2012; Dyer et al., 2010; Heafield, 2011) uses word alignments and language models to select sentence pairs that are likely to be good translations of one another.
17	42	Taghipour et al. (2011) proposed an outlier detection algorithm which leads to an improved translation quality when trimming a small portion of data.
23	19	Once the model is trained, it is used to score sentence pairs in the noisy data pool.
25	85	Since good adequacy and fluency are the major two elements that constitute a good parallel sentence pair, we propose separate features to address both of them.
26	19	For adequacy, we propose bag-ofwords translation scores, and for fluency we use ngram language model scores.
28	20	In designing the features, we prioritize efficiency as well as performance since we could be dealing with corpora of huge sizes.
35	45	Then we “translate” vf into v′e, based on the probabilistic f2e dictionary, where v′e[we] = ∑ wf vf [wf ]p(we|wf ) For a French word w that does not appear in the dictionary, we keep it as it is in the translated vector, i.e. assume there is an entry of (w, w, 1.0) in the dictionary.
36	32	Since the dictionary is probabilistic, the elements in v′e also add up to 1, and v′e represents another probability distribution on the English vocabulary.
38	15	We perform similar procedures for English-toFrench, and compute xent(vf , v′f ).
40	36	We train two n-gram language models with a clean French and English corpus, and then for each sentence pair (sf , se), we score each sentence with the corresponding model, Fngram(sf ) and Fngram(se), each computed as the ratio between the sentence negative log-likelihood and the sentence length.
41	17	We define the fluency score as the sum of the two: fluency(sf , se) = Fngram(sf ) + Fngram(se)
42	148	We generate synthetic noisy data from good data, and make sure the generated noisy data include sentence pairs with a) good fluency and bad adequacy, b) good adequacy and bad fluency and c) bad both.
43	109	Respectively, we generate 3 types of “noisy” sentence pairs from a good corpus: a) shuffle the sentences in the target language file (each sentence in the source language would be aligned to a random sentence in the target language); b) shuffle the words within each sentence (each sentence will be bad but the pairs are good translations in the “bagof-words” sense); c) shuffle both the sentences and words.
44	23	We emphasize that, while the synthetic data might not represent “real” noisy data, it has the following advantages: 1) each type of noisy data is equally represented so the classifier has to do well on all of them; 2) the data generated this way would be among the hardest to classify, especially type a and type b, so if a classifier separates such hard data with good performance, we expect it to also be able to do well in real world situations.
46	11	We observe that the clusters are quite separable, though the decision function would not be linear.
47	25	We map the features into higher order forms of (xn, yn) in order for logistic regression to train a non-linear decision boundary.2 We use n = 8 in this work since it gives the best classification performance on the newstest09 fr-en corpus.
50	19	We set different values of c and use the adequacy scores to pick the better half, and compute the retrieval accuracy.
55	8	To generate the dictionaries for computing the adequacy scores, we use fast align (Dyer et al., 2013) to align the Europarl (Koehn, 2005) corpus and generate probabilistic dictionaries from the alignments.
57	48	For each language pair, we use scikit-learn (Pedregosa et al., 2011) to train a logistic regression model to classify between the original and the synthetic noisy corpus of newstest09, and the trained model is used to score all sentence pairs in the data pool.
58	15	We keep selecting the best ones until the desired number of words is reached.
59	18	To evaluate the quality, we train a Moses (Koehn et al., 2007) SMT system on selected data, and evaluate each trained SMT system on 3 test corpora: newstest2011 which contains 3003 sentence pairs, and a random subset of the TED-talks corpus and the movie-subtitle corpus from OPUS (Tiedemann, 2012), each of which contains 3000 sentence pairs.
60	31	Tables 2, 3 and 4 show the BLEU performance of the selected subsets of the Zipporah system compared to the baseline, which selects sentence pairs at random; for comparison, we also give the BLEU performance of systems trained on Europarl.
62	12	Peak performance is achieved when selecting 100 million words, where an improvement of 2.1 BLEU score over all data is achieved on the movie-subtitle dataset, despite only using less than 1/5 of the data.
64	23	We use the same data when running qeclean, with Europarl for training and newstest09 for dev.
65	47	While they both perform comparably and better than the baseline, Zipporah achieves a better peak in all the datasets, and the peak is usually achieved when selecting a smaller number of words compared to qe-clean, Another advantage of Zipporah is it allows the user to select an arbi- subsets of the Zipporah system can surpass that of Europarl, although the Europarl corpus acts like an “oracle” in the system, upon which the dictionaries and language models for feature computations are trained.
67	13	In this paper we introduced Zipporah, a fast data selection system for noisy parallel corpora.

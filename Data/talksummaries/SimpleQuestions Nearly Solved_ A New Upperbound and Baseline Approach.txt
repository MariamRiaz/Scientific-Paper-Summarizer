1	13	First, we show that ambiguity in the data bounds performance; there are often questions have more than one equally plausible interpretation.
4	29	The simple questions task involves mapping an English question (e.g. “Who wrote Gulliver’s travels?”) to an analogous Freebase (Bollacker et al., 2008) query, used to answer the question.
5	8	The query consists of a Freebase relation (e.g. /film/film/story by) and subject (e.g. 090s 0 [gulliver’s travels]).
13	9	Our approach includes (1) a CRF used to tag the mention of the subject in a question and (2) a BiLSTM used to classify the Freebase relation.
14	38	Despite its simplicity, this approach achieves 78.1% accuracy for predicting Freebase subject-relation queries, surpassing all previous models.
15	44	Finally, we present an empirical error analysis of this model which shows the upperbound is loose and that there is likely not much more than 4% of performance to be gained with future work on the data.
16	21	Together, these results suggest that the SimpleQuestions dataset is nearly solved.
17	49	Our code and pretrained models are available at github.com/PetrochukM/ Simple-Question-Answering.
18	41	Single-relation factoid questions (simple questions) are common in many settings (e.g. Microsoft’s search query logs (Yih et al., 2014) and WikiAnswers web questions (Fader et al., 2013)).
19	47	The SimpleQuestions dataset is one of the most commonly used benchmarks for studying such questions.
20	22	The Freebase knowledge graph (KG) provides the facts for answering the questions in the SimpleQuestions dataset.
21	63	It includes 3 billion triples of the form (subject, relation, object) (e.g. [04b5zb (Fires Creek), location/location/containedby, 0f80hy (Nantahala National Forest)]).
22	62	We denote such triples as (s, r, o).
23	6	The SimpleQuestions task is to rewrite questions into subject-relation pairs of the form (subject, relation), denoted in this paper as (s, r).
26	4	Freebase objects also typically include one or more string aliases (e.g. MID 04b5zb is named “Fires Creek”), which we will use later when computing our upper bounds.
29	41	Finally, the SimpleQuestions task is evaluated on subject-relation pair accuracy.
31	7	This dataset also provides two subsets of Freebase: FB2M and FB5M.1
32	15	The ambiguity in the SimpleQuestions dataset likely comes from the way the data was created.
33	47	Annotators were shown a single Freebase triple and asked to write a question.
34	85	For example, given any of the following triples: • (0btc7 [Gulliver’s Travels, Book], book/written work/author, o3 dj [Dean Swift]) • (06znpjr [Gulliver’s Travels, American film], film/film/written by, 03whnyn [Nicholas Stroller]) • (06znpjr [Gulliver’s Travels, American film], film/film/story by, o3 dj [Dean Swift]) The annotator might reasonably contribute the question “who wrote gulliver’s travels?” However, adding all of these pairs to the data is problematic.
35	24	Systems are evaluated on producing the correct subject-relation pair, and cannot learn a deterministic mapping that would get these three examples correct.
36	18	In this section, we present a simple heuristic method for finding many such instances of ambiguity, and use it to upper bound performance on this benchmark.
38	44	We first determine a string alias a for the subject by matching a phrase in q with a Freebase alias for s, in our example yielding “gulliver’s travels”.
39	19	For 97% of questions q, some string alias a exactly matched a question q phrase.
41	13	We define an abstract predicate p (e.g. “who wrote e?”) as q with alias a abstracted.
43	47	Finally, if there exists a subject-relation pair (s, r) ∈ KG such that r ∈ R ∧ s ∈ S we de- fine that as an accurate semantic interpretation of q. q is unanswerable if there exists multiple valid subject-relation pairs (s, r).
44	6	In our example above, the question is unanswerable because of the many different subject, relation pairs that co-occur with “gulliver’s travels” and “who wrote e?”
46	24	In these cases, we can predict a majority baseline (i.e. always guess the most commonly seen Freebase entity or relation), yielding an upperbound of 85.2%.

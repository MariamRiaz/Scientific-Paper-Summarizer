0	37	In this paper, we focus on the task of Natural Language Inference (NLI), which is known as a significant yet challenging task for natural language understanding.
3	31	Recently, performance on NLI(Chen et al., 2017b; Gong et al., 2018; Chen et al., 2017c) has been significantly boosted since the release of some high quality large-scale benchmark datasets such as SNLI(Bowman et al., 2015) and MultiNLI(Williams et al., 2017).
7	53	These words, such as “but” or “and”, are denoted as discourse markers.
8	25	These discourse markers have deep connections with the intrinsic relations of two sentences and intuitively correspond to the intent of NLI, such as “but” to “contradiction”, “so” to “entailment”, etc.
9	17	Very few NLI works utilize this information revealed by discourse markers.
10	44	Nie et al. (2017) proposed to use discourse markers to help represent the meanings of the sentences.
12	52	In this paper, we propose a Discourse Marker Augmented Network for natural language inference, where we transfer the knowledge from the existing supervised task: Discourse Marker Prediction (DMP)(Nie et al., 2017), to an integrated NLI model.
18	21	We propose the Discourse Marker Augmented Network to combine the learned encoder of the sentences with the integrated NLI model.
21	19	In the natural language inference tasks, we are given a pair of sentences (P,H), which respectively means the premise and hypothesis.
22	94	Our goal is to judge whether their logical relationship between their meanings by picking a label from a small set: entailment (The hypothesis is definitely a true description of the premise), neutral (The hypothesis might be a true description of the premise), and contradiction (The hypothesis is definitely a false description of the premise).
23	33	For DMP, we are given a pair of sentences (S1, S2), which is originally the first half and second half of a complete sentence.
24	14	The model must predict which discourse marker was used by the author to link the two ideas from a set of candidates.
28	42	We first use Glove(Pennington et al., 2014) to transform {St}2t=1 into vectors word by word and subsequently input them to a bi-directional LSTM: −→ hit = −−−−→ LSTM(Glove(Sit)), i = 1, ..., |St| ←− hit = ←−−−− LSTM(Glove(Sit)), i = |St|, ..., 1 (1) where Glove(w) is the embedding vector of the word w from the Glove lookup table, |St| is the length of the sentence St. We apply max pooling on the concatenation of the hidden states from both directions, which provides regularization and shorter back-propagation paths(Collobert and Weston, 2008), to extract the features of the whole sequences of vectors: −→rt = Maxdim([ −→ h1t ; −→ h2t ; ...; −−→ h |St| t ]) ←−rt = Maxdim([ ←− h1t ; ←− h2t ; ...; ←−− h |St| t ]) (2) where Maxdim means that the max pooling is performed across each dimension of the concatenated vectors, [; ] denotes concatenation.
33	12	To encode the words, we use the concatenation of following parts: Word Embedding: Similar to the previous section, we map each word to a vector space by using pre-trained word vectors GloVe.
41	28	We use three binary features to indicate whether the word can be exactly matched to any question word, which respectively means original form, lowercase and lemma form.
43	26	In this section, we feed the results of the encoding layer and the learned sentence encoder into the attention mechanism, which is responsible for linking and fusing information from the premise and the hypothesis words.
44	42	We first obtain a similarity matrix A ∈ Rn×m between the premise and hypothesis by Aij = v > 1 [pi;uj ;pi ◦ uj ; rp; rh] (6) where v1 is the trainable parameter, rp and rh are sentences representations from the equation (3) learned in the Section 3, which denote the premise and hypothesis respectively.
51	16	We compute the representation of the whole sentence by the weighted average of each word: pM = ∑ i exp(v>2 p M i )∑ i′ exp(v > 2 p M i′ ) pMi uM = ∑ j exp(v>3 u M j )∑ j′ exp(v > 3 u M j′ ) uMj (11) where v2,v3 are trainable vectors.
56	25	As shown in Table 2, many examples from our datasets are labeled by several people, and the choices of the annotators are not always consistent.
60	24	The most widely used objective function for the natural language inference is to minimize the negative log cross-entropy loss: JCE(Θ) = − 1 N N∑ k log(dkl ) (13) where Θ are all the parameters to optimize, N is the number of examples in the dataset, dl is the probability of the ground-truth label l. However, directly using the final label to train the model might be difficult in some situations, where the example is confusing and the labels from the annotators are different.
61	70	For instance, consider an example from the SNLI dataset: • P : “A smiling costumed woman is holding an umbrella.” • H: “A happy woman in a fairy costume holds an umbrella.” The final label is neutral, but the original labels from the five annotators are neural, neural, entailment, contradiction, neural, in which case the relation between “smiling” and “happy” might be under different comprehension.
63	51	To simulate the thought of human being more closely, in this paper, we tackle this problem by using the REINFORCE algorithm(Williams, 1992) to minimize the negative expected reward, which is defined as: JRL(Θ) = −El∼π(l|P,H)[R(l, {l∗})] (14) where π(l|P,H) is the previous action policy that predicts the label given P and H , {l∗} is the set of annotated labels, and R(l, {l∗}) = number of l in {l ∗} |{l∗}| (15) is the reward function defined to measure the distance to all the ideas of the annotators.
102	12	We then remove the sentence encoder model, which means we don’t use the knowledge transferred from the DMP task and thus the representations rp and rh are set to be zero vectors in the equation (6) and the equation (12).
107	14	Finally, we ablate the reinforcement learning part, in other words, we only use the original loss function to optimize the model (set λ = 1).
114	56	Compared to the other two categories, the “contradiction” label examples seem to benefit the most from the pre-trained sentence encoder.
115	20	In Figure 3, we also provide a visualized analysis of the hidden representation from similarity matrix A (computed in the equation (6)) in the situations that whether we use the discourse markers or not.
116	17	We pick a sentence pair whose premise is “3 young man in hoods standing in the middle of a quiet street facing the camera.” and hypothesis is “Three people sit by a busy street bareheaded.” We observe that the values are highly correlated among the synonyms like “people” with “man”, “three” with “3” in both situations.
117	27	However, words that might have contradictory meanings like “hoods” with “bareheaded”, “quiet” with “busy” perform worse without the discourse markers augmentation, which conforms to the conclusion that the “contradiction” label examples benefit a lot which is observed in the Section 5.5.
138	60	Moreover, we take the various views of the annotators into consideration and employ reinforcement learning to help optimize the model.
139	16	The experimental evaluation shows that our model achieves the state-of-the-art results on SNLI and MultiNLI datasets.

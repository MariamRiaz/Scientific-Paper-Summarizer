0	65	The success of automatic image captioning (Farhadi et al., 2010; Mitchell et al., 2012; Karpathy and Fei-Fei, 2015; Vinyals et al., 2015) demonstrates compellingly that end-to-end statistical models can align visual information with language.
1	69	However, high-quality captions are not merely true, but also pragmatically informative in the sense that they highlight salient properties and help distinguish their inputs from similar images.
3	2	In this paper, we present a neural image captioning system1 that is a pragmatic speaker as defined by the Rational Speech Acts (RSA) model (Frank and Goodman, 2012; Goodman and Stuhlmüller, 2013).
5	62	For instance, the literal caption in Figure 1 could describe both the target and the top two distractors, whereas the pragmatic caption mentions something that is most salient of the target.
6	171	Intuitively, the RSA speaker achieves this by reasoning not only about what is true but also about what it’s like to be a listener in this context trying to identify the target.
7	24	This core idea underlies much work in referring expression generation (Dale and Reiter, 1995; Monroe and Potts, 2015; Andreas and Klein, 2016; Monroe et al., 2017) and image captioning (Mao et al., 2016a; Vedantam et al., 2017), but these models do not fully confront the fact that the agents must reason about all possible utterances, which is intractable.
8	92	We fully address this problem by implementing RSA at the level of characters rather than the level of utterances or words: the neural language model emits individual characters, choosing them to balance pragmatic informativeness with overall well-formedness.
9	16	Thus, the agents reason not about full utterances, but rather only about all possible character choices, a very small space.
10	88	The result is that the information encoded recurrently in the neural model allows us 439 to obtain global pragmatic effects from local decisions.
12	28	In applying RSA to image captioning, we think of captioning as a kind of reference game.
13	153	The speaker and listener are in a shared context consisting of a set of images W , the speaker is privately assigned a target image w⇤ 2 W , and the speaker’s goal is to produce a caption that will enable the listener to identify w⇤.
14	20	U is the set of possible utterances.
15	48	In its simplest form, the literal speaker is a conditional distribution S0(u|w) assigning equal probability to all true utterances u 2 U and 0 to all others.
16	25	The pragmatic listener L0 is then defined in terms of this literal agent and a prior P (w) over possible images: L0(w|u) / S0(u|w) ⇤ P (w)P w02W S0(u|w0) ⇤ P (w0) (1) The pragmatic speaker S1 is then defined in terms of this pragmatic listener, with the addition of a rationality parameter ↵ > 0 governing how much it takes into account the L0 distribution when choosing utterances.
17	6	P (u) is here taken to be a uniform distribution over U : S1(u|w) / L0(w|u)↵ ⇤ P (u)P u02U L0(w|u0)↵ ⇤ P (u0) (2) As a result of this back-and-forth, the S1 speaker is reasoning not merely about what is true, but rather about a listener reasoning about a literal speaker who reasons about truth.
18	13	To illustrate, consider the pair of images 2a and 2b in Figure 2.
19	225	Suppose that U = {bus, red bus}.
20	26	Then the literal speaker S0 is equally likely to produce bus and red bus when the left image 2a is the target.
23	23	To apply the RSA model to image captioning, we first train a neural model with a CNN-RNN architecture (Karpathy and Fei-Fei, 2015; Vinyals et al., 2015).
26	134	The main challenge for this application is that the space of utterances (captions) U will be very large for any suitable captioning system, making the calculation of S1 intractable due to its normalization over all utterances.
34	54	This is now our S0: given a partially generated caption and an image, it returns a distribution over which character should next be added to the caption.
35	9	The advantage of using a character-level LSTM over a word-level one is that U is much smaller for the former (⇡30 vs. ⇡20, 000), making the ensuing RSA model much more efficient.
37	23	The S1, in turn, given a target image w⇤, performs an inference over the set of possible characters to determine which is best with respect to the listener choosing w⇤.
39	2	The idea is that as we proceed with the unrolling, the L0 priors on which image is being referred to may change, which in turn should affect the speaker’s actions.
41	28	In our incremental RSA, speaker models take both a target image and a partial caption pc.

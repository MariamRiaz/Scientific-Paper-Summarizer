0	98	The problem of recovering a ranking over n items from noisy outcomes of pairwise comparisons has attracted, in the last century, much research interest, driven by applications in sports (Elo, 1978), social sciences (Thurstone, 1927; Salganik & Levy, 2015) and—more recently—recommender systems (Houlsby et al., 2012).
1	17	Whereas pairwise comparison models and related inference algorithms have been extensively studied, the issue of which pairwise comparisons to sample, also known as active learning, has received significantly less attention.
2	25	To understand the potential benefits of adaptively selecting samples, consider the case where comparison outcomes are noiseless, i.e., consistent with a linear order on a set of n items.
3	64	If pairs of items are selected at random, it is necessary to collect Ω(n2) comparisons to recover the ranking (Alon et al., 1994).
4	80	In contrast, by using an efficient sorting algorithm, O(n log n) adaptively chosen comparisons are sufficient.
5	65	In this work, we demonstrate that sorting algorithms can also be helpful in the noisy setting, where some comparison outcomes are inconsistent with the ranking: despite errors, sorting algorithms tend to select informative samples.
6	18	We focus on the Bradley–Terry (BT) model, a widely-used probabilistic model of comparison outcomes.
8	14	First, we study the output of a single execution of Quicksort when comparison outcomes are generated from a BT model, under the assumption that the distance between adjacent parameters is (stochastically) uniform across the ranking.
9	61	We measure the quality of a ranking estimate by its displacement with respect to the ground truth, i.e., the sum of rank differences.
22	14	In most of the paper, pairwise comparison outcomes follow a Bradley–Terry model with parameters θ = [ θ1 · · · θn ] ∈ Rn, denoted BT(θ).
25	25	The probability of observing an inconsistent comparison decreases with the distance between the items.
98	39	We can show that the displacement is bounded by ∆(σ) ≤ ∆L(σ) + ∆R(σ) + 2 ∑ (i,j)∈E1 |i− j|, where ∆L(σ) and ∆R(σ) represent the displacement of the ordering induced by σ on L and R, respectively.
102	25	Lemma 3 is a crucial component of our subsequent analysis of BT noise, and we believe that it can be useful in order to investigate Quicksort under a wide variety of other noise generating processes.
104	27	Clearly, any results on the displacement of a ranking estimated from samples of a BT model will depend on θ; it is easy to construct a model instance for which it is arbitrarily hard to recover the ranking, by choosing parameters sufficiently close to each other.
105	24	We postulate a family of distributions over θ, and we give bounds on the displacement that hold with high probability.
107	11	This means that the probability distribution over parameters θ1, .
108	39	, θn results in (random) distances |θi+k−θi| that depend only on k. One such distribution arises if the parameters are drawn from a Poisson point process of rate λ.
109	19	(1) The average distance between two items separated by k positions in the ordering is E [θi+k − θi] = k/λ.
110	24	Although the distance between adjacent items is constant in expectation, we allow some parameters to be arbitrarily close4.
113	24	Although the precise choice of this Poisson model is driven by tractability concerns, in Section 3.2 we argue that it is essentially equivalent to choosing the parameters independently and uniformly at random in the interval [0, (n+1)/λ], when λ is fixed and n is large.
116	16	Let σ be the output of Quicksort using comparison outcomes sampled from BT(θ).
181	18	In the noiseless setting, Mergesort is known to use on average≈ 39 % fewer comparisons than Quicksort per run (Knuth, 1998), but it does not benefit from the theoretical guarantees developed in Section 3.
196	15	We now investigate three datasets and measure the displacement of rankings estimated from adaptively-chosen samples, as a function of the budget c. Note that in order to use uncertainty sampling and Bayesian methods, it is necessary to choose a regularization strength or prior variance in the inference step.
216	30	Once again, active learning performs noticeably better than random sampling.
219	44	methods, after completing one entire call to the sorting procedure (slightly less than 1000 comparisons).
230	35	We fit a BT model by using all the available comparisons and use the induced ranking as ground truth.
234	23	We try a simplified, computationally less expensive version of uncertainty sampling where, at every iteration, each item is compared to its two closest neighbors, but this heuristic fails spectacularly: The resulting displacement is over 5× larger than random sampling for c = 106, and is therefore not reported here (see supplementary material, Section C).
238	29	In this work, we demonstrate that active learning can substantively speed up the task of learning a ranking from noisy comparisons gains—both in theory and in practice.
241	17	We show that a deceptively simple idea—repeatedly sorting the items—is able to bring in all the benefits of active learning, is trivial to implement, and is computationally no more expensive that random sampling.
242	75	Therefore, we believe that our method can be broadly useful for machine-learning practitioners interested in ranking problems.

1	28	A typical semantic parsing task is question answering against a database, which is accomplished by translating questions into executable logical forms (i.e., programs) that output their answers.
2	46	Recent work has shown that recurrent neural networks can be used for semantic parsing by encoding the question then predicting each token of the logical form in sequence (Jia and Liang, 2016; Dong and Lapata, 2016).
3	54	These approaches, while effective, have two major limitations.
6	28	This paper introduces a novel neural semantic parsing model that addresses these limitations of prior work.
12	19	We evaluate our parser on WIKITABLEQUESTIONS, a challenging data set for question answering against semi-structured Wikipedia tables (Pasupat and Liang, 2015).
40	39	First, the encoder includes a special entity embedding and linking module that produces a link embedding for each question token that represents the table entities it links to (Section 3.2).
41	89	Second, the action space of the decoder is defined by a type-constrained grammar which guarantees that generated logical forms satisfy type constraints (Section 3.3).
42	28	We train the parser using question-answer pairs as supervision using an approximation of marginal loglikelihood based on enumerating logical forms via dynamic programming on denotations (Pasupat and Liang, 2016) (Section 3.4).
45	47	In this representation, tables are expressed as knowledge graphs over 6 types of entities: cells, cell parts, rows, columns, numbers and dates.
46	21	Each entity also has a name, which is typically a string value in the table.
51	16	Columns are treated as functions from cells to their rows, e.g., (country united states) generates the rows whose country column contains “united states”.
54	18	Our parser also assigns a type to every λ-DCS expression, which is used to enforce type constraints on generated logical forms.
55	65	The base types are cells c, parts p, rows r, numbers i, and dates d. Columns such as country have the functional type 〈c, r〉, representing functions from cells c to rows r. Other operations have more complex functional types, e.g., reverse has type 〈〈c, r〉, 〈r, c〉〉, which enables us to write (reverse country).1 The parser assigns every λ-DCS constant a type, then applies standard programming language type inference algorithms (Pierce, 2002) to automatically assign types to larger expressions.
56	45	The encoder is a bidirectional LSTM augmented with an entity embedding and linking module.
65	29	Each entity’s embedding re is a nonlinear projection of a type vector vτ(e) and a neighbor vector vN(e): vN(e) = 1 |N(e)| ∑ e′∈N(e) 1 |W (e′)| ∑ w∈W (e′) vw re = tanh ( Pτvτ(e) + PNvN(e) ) The type vector vτ(e) is a one-hot vector for τ(e), with dimension equal to the number of entity types in the grammar.
70	21	The first represents similarity in word embedding space between the token and entity name, computed as function of the embeddings of words in e’s name, W (e), and the word embedding of the ith token, vqi .
77	16	The scores s(e, i) are then fed into a softmax layer over all entities e of the same type, and the link embedding li is an average of entity vectors re weighted by the resulting distribution, then summed over all types.
140	33	Our approach makes it tractable to maximize marginal loglikelihood with a neural model by using DPD to enumerate correct logical forms beforehand.
161	18	This Scala library combines ideas from dy- namic neural network frameworks (Neubig et al., 2017) and probabilistic programming (Goodman and Stuhlmüller, 2014) to simplify the implementation of complex neural structured prediction models.
167	41	We distinguish between single models and ensembles, as we expect ensembling to improve accuracy, but not all prior work has used it.
174	18	Our second experiment measures the importance of type constraints on the decoder by comparing it to sequence-to-sequence (seq2seq) and sequenceto-tree (seq2tree) models.
178	41	These models were implemented by preprocessing logical forms and applying a different type system.
196	31	To better understand the mistakes made by our system, we analyzed a randomly selected set of 100 questions that were answered incorrectly.
198	33	A large number of these errors (15%) occur on questions that require selecting an answer from a given list of options, as in Who had more silvers, Colombia or The Bahamas?
201	56	Representation failures (25%): The knowledge graph representation makes certain assumptions about the table structure and cell values which are sometimes wrong.
202	67	One common problem is that the graph lacks some cell parts necessary to answer the question (15%).
208	84	We present a new semantic parsing model for answering compositional questions against semistructured Wikipedia tables.
209	44	Our semantic parser extends recent neural semantic parsers by enforcing type constraints during logical form generation, and by including an explicit entity embedding and linking module that enables it to identify entity mentions while generalizing across tables.
210	106	An evaluation on WIKITABLEQUESTIONS demonstrates that our parser achieves state-of-theart results, and furthermore that both type constraints and entity linking make significant contributions to accuracy.
211	24	Analyzing the errors made by our parser suggests that improving entity linking and using the table structure are two directions for future work.

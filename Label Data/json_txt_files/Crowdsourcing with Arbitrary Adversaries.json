{"sections": [{"heading": "1. Introduction", "text": "Crowdsourcing is an omnipresent phenomenon: it has emerged as an integral part of the machine learning pipeline in recent years, and one reason for the great advances in deep learning is the presence of large data sets that have been labeled by the crowd (e.g., Deng et al., 2009; Krizhevsky, 2009). Crowdsourcing is also at the heart of peer grading systems (e.g., Alfaro & Shavlovsky, 2014), which help with rising enrollment at universities, and online rating systems (e.g., Liao et al., 2014), which many of us rely on when choosing the next restaurant, to provide just a few examples.\nA crowdsourcing scenario consists of a set of workers and a set of tasks that need to be solved. A data curator utilizing crowdsourcing can aim at estimating various quantities of interest. The first goal might be to estimate the true labels or answers for the tasks at hand. Typically, additional constraints are involved here such as a worker not being willing\n1Department of Computer Science, Rutgers University, Piscataway Township, New Jersey, USA. Correspondence to: Mattha\u0308us Kleindessner <matthaeus.kleindessner@rutgers.edu>, Pranjal Awasthi <pranjal.awasthi@rutgers.edu>.\nProceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).\nto solve too many tasks and the data curator wanting to get high-quality labels at a low price. The canonical example of this case is the Amazon Mechanical TurkTM. There one cannot track specific workers as they are fleeting. However, in scenarios such as peer grading or online rating systems, a second goal might be to estimate worker qualities, especially if workers can be reused at a later time.\nIn a seminal paper, Dawid & Skene (1979) proposed a formal model that involves worker quality parameters for crowdsourcing scenarios in the context of classification. The Dawid-Skene model has become a standard theoretical framework and has led to a flurry of research over the past few years (Liu et al., 2012; Raykar & Yu, 2012; Li et al., 2013; Gao et al., 2016; Zhang et al., 2016; Khetan et al., 2017), in particular in its special symmetric form usually referred to as one-coin model (Ghosh et al., 2011; Karger et al., 2011a;b; Dalvi et al., 2013; Gao & Zhou, 2013; Karger et al., 2014; Bonald & Combes, 2017; Ma et al., 2017). In its general form for binary classification problems, the DawidSkene model assumes that for each worker, the probability of providing the wrong label only depends on the true label of the task, but not on the task itself. Moreover, given the true label, the responses provided by different workers are independent. The one-coin model additionally assumes that for each worker, the probability of providing the wrong label is the same for both classes. We will formally introduce the one-coin model in Section 2. A discussion of prior work work is provided in Section 5 and Appendix A.\nThe crucial limitation of the Dawid-Skene and one-coin model is the assumption that workers\u2019 error probabilities are task-independent. In particular, this excludes the possibility of colluding adversaries (other than those that provide the wrong label all of the time), which might make these models a poor approximation of the real world encountered in such applications as peer grading or online rating. In this paper, we study a significant extension of the one-coin model that allows for arbitrary, highly colluding adversaries. We provide an algorithm for estimating the workers\u2019 error probabilities and prove that it asymptotically recovers the true error probabilities. Using our estimates of the error probabilities in weighted majority votes, we also provide strategies to estimate ground-truth labels of the tasks. Experiments on both synthetic and real data show that our approach clearly outperforms existing methods in the presence of adversaries."}, {"heading": "2. Setup and problem formulation", "text": "We first describe a general model for crowdsourcing with non-adaptive workers and binary classification tasks: there are n workers w1, . . . , wn and an i.i.d. sample of m tasklabel pairs ((xi, yi))mi=1 \u223c Dm, where D is a joint probability distribution over tasks x \u2208 X and corresponding labels y \u2208 {\u22121,+1}. There is a variable gij \u2208 {0, 1}, i \u2208 [m], j \u2208 [n], indicating whether worker wj is presented with task xi (for k \u2208 N, we use [k] to denote the set {1, . . . , k}). If wj is presented with xi, that is gij = 1, wj provides an estimate wj(xi) \u2208 {\u22121,+1} of the ground-truth label yi. Let A \u2208 {\u22121, 0,+1}m\u00d7n be a matrix that stores all the responses collected from the workers: Aij = wj(xi) if gij = 1 and Aij = 0 if gij = 0.\nWe assume that each worker wj follows some (probabilistic or deterministic) strategy such that wj(xi) only depends on xi. In particular, given xi, any two different workers\u2019 responses wj(xi) and wk(xi) and the ground-truth label yi are independent. Let \u03b5wj (x, y) \u2208 [0, 1] be the conditional error probability that, given x and y, wj(x) does not equal y, that is\n\u03b5wj (x, y) := Prwj |(x,y)[wj(x) 6= y | (x, y)]. (1)\nNote that the unconditional probability of wj(x) being incorrect, before seeing x and y, is given by\nPr(x,y)\u223cD,wj [wj(x) 6= y] = E(x,y)\u223cD[\u03b5wj (x, y)] =: \u03b5wj .\nNow one may study the following questions:\n(i) Given only the matrix A, how can we estimate the ground-truth labels y1, . . . , ym?\n(ii) Given only the matrix A, how can we estimate the workers\u2019 unconditional error probabilities \u03b5w1 , . . . , \u03b5wn?\n(iii) If we can choose gij (either in advance of collecting workers\u2019 responses or adaptively while doing so), how should we choose it such that we can achieve (i) or (ii) with a minimum number of collected responses?\nIn case of \u03b5wj (x, y) as defined in (1) being constant on X \u00d7 {\u22121,+1}, that is \u03b5wj (x, y) \u2261 \u03b5wj , for all j \u2208 [n], our model boils down to what is usually referred to as the one-coin model (e.g., Szepesvari, 2015), for which (i) to (iii) have been studied extensively (see Section 5 and Appendix A for references and a detailed discussion). With this paper we initiate the study of a significant extension of the one-coin model. We will allow almost half of the workers to deviate from the one-coin model and for such a worker wj , the conditional error probability \u03b5wj (x, y) to be a completely arbitrary random variable. In other words, we will allow for arbitrary adversaries, for which not only error\nprobabilities can be high, but for which error probabilities can be arbitrarily correlated. We mainly study (ii) in this scenario. We then make use of existing results for the onecoin model to answer (i) satisfactorily for our purposes. We do not deal with (iii), but instead assume that gij has been specified in advance."}, {"heading": "3. General outline of our approach", "text": "In this section we want to present the general outline of our approach. A key insight is that the unconditional probability of workers wj and wk being agreeing is given by\nPr(x,y)\u223cD,wj ,wk [wj(x) = wk(x)] = 1\u2212 \u03b5wj \u2212 \u03b5wk+ 2\u03b5wj\u03b5wk + 2 Cov(x,y)\u223cD[\u03b5wj (x, y), \u03b5wk(x, y)].\n(2)\nCov(x,y)\u223cD[\u03b5wj (x, y), \u03b5wk(x, y)] denotes the covariance between random variables \u03b5wj (x, y) and \u03b5wk(x, y), that is\nCov(x,y)\u223cD[\u03b5wj (x, y), \u03b5wk(x, y)] = E(x,y)\u223cD[(\u03b5wj (x, y)\u2212 \u03b5wj ) \u00b7 (\u03b5wk(x, y)\u2212 \u03b5wk)].\nA proof of (2) can be found in Appendix B. The probability on the left-hand side of (2) can be easily estimated from A by the ratio of the number of tasks that wj and wk agreed on to the number of tasks they were both presented with:\nPr[wj(x) = wk(x)] \u2248 \u2211m i=1 gijgik1{Aij = Aik}\u2211m\ni=1 gijgik =: pjk.\n(3)\nThis suggests to solve the system of equations\n1\u2212 \u03b5j \u2212 \u03b5k + 2\u03b5j\u03b5k + 2cjk = pjk, 1 \u2264 j < k \u2264 n, (4)\nin the unknowns \u03b5l, l \u2208 [n], and cjk, 1 \u2264 j < k \u2264 n, in order to obtain estimates of the workers\u2019 unconditional error probabilities \u03b5w1 , . . . , \u03b5wn . However, there is a catch: in general, the system (4) is not identifiable and has several solutions. We will assume that at least n2 + 2 of the workers follow the one-coin model and have error probabilities smaller than one half. A worker wj following the one-coin model implies\nCov(x,y)\u223cD[\u03b5wj (x, y), \u03b5wk(x, y)] = 0, \u2200k 6= j, (5)\nand hence under this assumption we can restrict the search for solutions of (4) to \u03b5l, l \u2208 [n], and cjk, 1 \u2264 j < k \u2264 n, with the property that1\n\u2203L \u2286 [n] with |L| \u2265 n/2 + 2 such that \u2200j \u2208 L : (\u03b5j < 1/2 \u2227 [\u2200k 6= j : cjk = 0]) . (6)\n1Throughout the paper, we set cjk = ckj if j > k. We also assume pjk = pkj .\nNote that we never assume to know which workers follow the one-coin model, which corresponds to using the existential quantifier for the set L in (6) rather than considering a \u201cfixed\u201d L. We can show that the system (4) has at most one solution with property (6). We also provide evidence that our assumption of n2 + 2 of the workers following the one-coin model and having error probabilities smaller than one half is a necessary condition for guaranteeing the identifiability of system (4). If the workers satisfy our assumption and pjk on the right-hand side of (4) are actually true agreement probabilities, then \u03b5l = \u03b5wl and cjk = Cov[\u03b5wj (x, y), \u03b5wk(x, y)] is the unique solution of (4) that satisfies (6). But if pjk are not exactly true agreement probabilities, there might be no solution of (4) with property (6) at all. We prove that if estimates pjk are not too bad, we can solve (4) together with (6) approximately, and our approximate solution is guaranteed to be close to true error probabilities \u03b5w1 , . . . , \u03b5wn and covariances Cov[\u03b5wj (x, y), \u03b5wk(x, y)], j < k. This answers (ii) from Section 2 and is the main contribution of our paper: Main result. Assume that at least n2 + 2 of the workers follow the one-coin model and have error probabilities not greater than \u03b3TR < 12 . If |Pr[wj(x) = wk(x)] \u2212 pjk| \u2264 \u03b2 for all j 6= k and \u03b2 sufficiently small, we can compute estimates \u03b5\u0302w1 , . . . , \u03b5\u0302wn of \u03b5w1 , . . . , \u03b5wn such that\n|\u03b5wi \u2212 \u03b5\u0302wi | \u2264 C(\u03b3TR) \u00b7 \u03b21/4.\nWe answer (i) from Section 2 and provide two ways to predict ground-truth labels y1, . . . , ym by taking weighted majority votes over the responses provided by the workers. In these majority votes, the weights depend on our estimates of true error probabilities \u03b5w1 , . . . , \u03b5wn ."}, {"heading": "4. Details and analysis", "text": ""}, {"heading": "4.1. Estimating agreement probabilities", "text": "If gij has been specified in advance, we have the following guarantee on the quality of the estimates pjk (see (3)): Lemma 1. Assume \u2211m i=1 gijgik > 0, j 6= k. Let \u03b4 > 0 and\n\u03b2jk = min\n{ 1, [ ln(2n2/\u03b4)/ ( 2 \u2211m\ni=1 gijgik\n)]1/2} .\nThen we have with probability at least 1\u2212 \u03b4 over the sample ((xi, yi)) m i=1 and the randomness in workers\u2019 strategies that\n|Pr[wj(x) = wk(x)]\u2212 pjk| \u2264 \u03b2jk, 1 \u2264 j < k \u2264 n.\nProof. A straightforward application of Hoeffding\u2019s inequality and the union bound yields the result."}, {"heading": "4.2. Identifiability and approximate solution", "text": "If all workers follow the one-coin model, that is \u03b5wj (x, y) \u2261 \u03b5wj for all j \u2208 [n], we have\nCov(x,y)\u223cD[\u03b5wj (x, y), \u03b5wk(x, y)] = 0, 1 \u2264 j < k \u2264 n, and system (4) reduces to\n1\u2212 \u03b5j \u2212 \u03b5k + 2\u03b5j\u03b5k = pjk, 1 \u2264 j < k \u2264 n, (7)\nin the unknowns \u03b5l, l \u2208 [n]. It is well known that, in general, even (7) is not identifiable. For example, if pjk = 1 for all 1 \u2264 j < k \u2264 n, there are the two solutions \u03b5l = 0, l \u2208 [n], and \u03b5l = 1, l \u2208 [n], corresponding to either all perfect or all completely erroneous workers. On the other hand, the system (7) is identifiable if we assume that on average workers are better than random guessing, that is 1 n \u2211n j=1 \u03b5wj < 1 2 , and there are at least three informative workers with \u03b5wj 6= 12 (Bonald & Combes, 2017).\nClearly, these two conditions do not guarantee identifiability of the general system (4). The next lemma shows that even if we additionally assume half of the workers to follow the one-coin model, the system (4) is not identifiable. Here we only state an informal version of the lemma. A detailed version and its proof can be found in Appendix B.\nLemma 2. There exists an instance of the system (4), where n is even, that has two different solutions. In both solutions, it holds that \u03b5l < 12 , l \u2208 [n]. Furthermore:\n(a) In the first solution, cjk = 0 for all j \u2208 [n2 ] and k 6= j, and \u03b5l is small if l \u2208 [n2 ] and big if l \u2208 [n] \\ [ n 2 ]. (b) In the second solution, cjk = 0 for all j \u2208 [n]\\ [n2 ] and k 6= j, and \u03b5l is small if l \u2208 [n] \\ [n2 ] and big if l \u2208 [ n 2 ].\nWe want to mention that a solution of (4) does not necessarily correspond to actual workers, that is given \u03b5l, l \u2208 [n], and cjk, 1 \u2264 j < k \u2264 n, there might be no collection of workers w1, . . . , wn such that \u03b5wl = \u03b5l and Cov[\u03b5wj (x, y), \u03b5wk(x, y)] = cjk. By the BhatiaDavis inequality (Bhatia & Davis, 2010) it holds that Var[\u03b5wj (x, y)] \u2264 \u03b5wj \u2212 \u03b5 2wj . Hence, a necessary condition for a solution to correspond to actual workers is that |cjk| \u2264 (\u03b5j\u2212\u03b5 2j )1/2(\u03b5k\u2212\u03b5 2k )1/2 (in addition to \u03b5l \u2208 [0, 1]). The two solutions in Lemma 2 correspond to actual workers.\nFrom now on we assume that at least n2 + 2 workers follow the one-coin model and have error probabilities smaller than one half:2\nAssumption A. There exists L \u2286 [n] with |L| \u2265 n/2 + 2 such that for all j \u2208 L, the worker wj follows the one-coin model with error probability \u03b5wj < 1/2.\nThis corresponds to considering (4) together with the constraint (6). The system (4) together with (6) is identifiable:\nProposition 1. There exists at most one solution of system (4) that has property (6).\n2All results of Section 4.2 hold true if we assume, more generally, the existence of L \u2286 [n] with |L| \u2265 n\n2 + 2 such that (5)\ntogether with \u03b5wj < 1 2 holds for all j \u2208 L.\nProof. Assuming there are two solutions (\u03b5S1l )l\u2208[n], (c S1jk )1\u2264j<k\u2264n and (\u03b5 S2 l )l\u2208[n], (c S2 jk )1\u2264j<k\u2264n with L1 and L2 satisfying (6), there have to be pairwise different i1, i2, i3 \u2208 L1 \u2229 L2. It is easy to see that (\u03b5S1i1 , \u03b5 S1 i2 , \u03b5S1i3 ) and (\u03b5S2i1 , \u03b5 S2 i2 , \u03b5S2i3 ) and consequently also all the other components of the two solutions have to coincide. Details can be found in Appendix B.\nIf pjk at the right-hand side of (4) are true agreement probabilities, the true error probabilities \u03b5w1 , . . . , \u03b5wn and covariances Cov[\u03b5wj (x, y), \u03b5wk(x, y)], j < k, make up the unique solution of (4) that satisfies (6), but if pjk are not exactly true agreement probabilities, there might be no solution of (4) that satisfies (6) at all. Our goal is then to find a solution of (4) that satisfies (6) approximately and to show that our approximate solution has to be close to \u03b5w1 , . . . , \u03b5wn and Cov[\u03b5wj (x, y), \u03b5wk(x, y)], j < k. As a first step towards this goal we need a generalization of Proposition 1:\nProposition 2. Let \u03b3 < 1/2 and \u03bd < 1/8\u2212 \u03b3/2 + \u03b32/2. If there exist two solutions (\u03b5Sil )l\u2208[n], (c Si jk )1\u2264j<k\u2264n, i \u2208 {1, 2}, of system (4) (where pjk \u2208 [0, 1]) with the property that \u03b5Sil \u2208 [0, 1], l \u2208 [n], and\n\u2203Li \u2286 [n] with |Li| \u2265 n/2 + 2 such that \u2200j \u2208 Li : ( \u03b5Sij \u2264 \u03b3 \u2227 [ \u2200k 6= j : |c Sijk | \u2264 \u03bd ]) , (8)\nthen\u2223\u2223\u03b5S1l \u2212 \u03b5S2l \u2223\u2223 \u2264 G(\u03b3, \u03bd)\u221a\u03bd, \u2223\u2223c S1jk \u2212 c S2jk \u2223\u2223 \u2264 3G(\u03b3, \u03bd)\u221a\u03bd for l \u2208 [n], j < k, where G(\u03b3, \u03bd)\u2192 G(\u03b3) > 0 as \u03bd \u2192 0.\nThe proof of Proposition 2, which provides an explicit expression for G(\u03b3, \u03bd), can be found in Appendix B.\nIn a next step, we assume that we are given pairwise different i1, i2, i3 \u2208 [n] such that wi1 , wi2 , wi3 follow the onecoin model with \u03b5wi1 , \u03b5wi2 , \u03b5wi3 < 1/2. In this case, assuming that estimates pjk are close to true agreement probabilities, we can construct a solution of (4) that is guaranteed to be close to the true error probabilities and covariances (and hence approximately satisfies (6)). This is made precise in the next lemma (its proof can be found in Appendix B).\nLemma 3. Let \u03b3TR < 1/2 and consider the system (4) with p TRjk \u2208 [0, 1] as right-hand side. Assume there exists a solution3 (\u03b5TRl )l\u2208[n], (c TR jk )1\u2264j<k\u2264n with the property that \u03b5TRl \u2208 [0, 1] and\n\u2203LTR \u2286 [n] with |LTR| \u2265 n/2 + 2 such that \u2200j \u2208 LTR : ( \u03b5TRj \u2264 \u03b3TR \u2227 [ \u2200k 6= j : c TRjk = 0 ]) . (9)\nNow consider the system (4) with pjk \u2208 [0, 1] as right-hand side. Assume that |p TRjk \u2212 pjk| \u2264 \u03b2 for all j 6= k, where\n3By Proposition 1, this solution is unique.\n\u03b2 satisfies \u03b2 < 1/2\u2212 2\u03b3TR + 2\u03b32TR. Let i1, i2, i3 \u2208 [n] be pairwise different and set\nB := \u22122 + 4pi1i3 , C := 1 + 2pi1i2pi2i3 \u2212 pi1i2 \u2212 pi1i3 \u2212 pi2i3 ,\n\u03b5Ri2 := 1 2 \u2212 \u221a B + 4C 2 \u221a B , \u03b5Si2 := min(\u03b3TR,max(0, \u03b5 R i2))\n(10)\nand for all l 6= i2 and for all 1 \u2264 j < k \u2264 n\n\u03b5Rl := pi2l \u2212 1 + \u03b5Si2\n2\u03b5Si2 \u2212 1 ,\n\u03b5Sl :=\n{ min(\u03b3TR,max(0, \u03b5 R l )) if l \u2208 {i1, i3}\nmin(1,max(0, \u03b5Rl )) if l /\u2208 {i1, i3} ,\nc Sjk := pjk \u2212 (1\u2212 \u03b5Sj \u2212 \u03b5Sk + 2\u03b5Sj \u03b5Sk )\n2 .\n(11)\nIf all expressions are defined (i.e., B > 0, B + 4C \u2265 0 and \u03b5Si2 6= 1 2 ), then (\u03b5 S l )l\u2208[n], (c S jk)1\u2264j<k\u2264n is a solution of (4) with pjk as right-hand side. If i1, i2, i3 \u2208 LTR, then all expressions are defined and\u2223\u2223\u03b5TRl \u2212 \u03b5Sl \u2223\u2223 \u2264 H(\u03b3TR, \u03b2)\u221a\u03b2, l \u2208 [n],\u2223\u2223c TRjk \u2212 c Sjk\u2223\u2223 \u2264 3H(\u03b3TR, \u03b2)\u221a\u03b2 + \u03b2/2, j < k, (12) where H(\u03b3TR, \u03b2)\u2192 H(\u03b3TR) > 0 as \u03b2 \u2192 0.\nIn Lemma 3, for constructing the solution (\u03b5Sl )l\u2208[n], (c Sjk)1\u2264j<k\u2264n as defined in (10) and (11) we need to know \u03b3TR < 1/2, which is an upper bound on the error probabilities of at least n2 + 2 workers that follow the one-coin model. In practice, we might choose \u03b3TR depending on the difficulty of the tasks or simply set it conservatively, for example as \u03b3TR = 0.45. If i1, i2, i3 \u2208 LTR, then (12) implies that (\u03b5Sl )l\u2208[n], (c S jk)1\u2264j<k\u2264n satisfies (8) with\n\u03b3 = \u03b3TR +H(\u03b3TR, \u03b2) \u221a \u03b2, \u03bd = 3H(\u03b3TR, \u03b2) \u221a \u03b2 + \u03b2/2.\n(13)\nIf we know the value of \u03b2 (using Lemma 1, we easily obtain an upper bound \u03b2 that holds with high probability), we can compute these quantities. This suggests the following strategy for obtaining estimates of \u03b5w1 , . . . , \u03b5wn and Cov[\u03b5wj (x, y), \u03b5wk(x, y)], j < k: we sample pairwise different i1, i2, i3 \u2208 [n] uniformly at random and construct (\u03b5Sl )l\u2208[n], (c S jk)1\u2264j<k\u2264n as defined in (10) and (11). If one of the expressions is not defined, we can immediately discard (i1, i2, i3). Otherwise, we check whether (\u03b5Sl )l\u2208[n], (c Sjk)1\u2264j<k\u2264n satisfies (8) with \u03b3 and \u03bd as specified in (13). If it does, since (\u03b5TRl )l\u2208[n], (c TR jk + (pjk\u2212 p TRjk )/2)1\u2264j<k\u2264n is a solution of (4) with pjk as right-hand side that satisfies\nproperty (8) too, Proposition 2 guarantees that \u2223\u2223\u03b5TRl \u2212 \u03b5Sl \u2223\u2223 \u2264\u221a3H(\u03b3TR, \u03b2)\u221a\u03b2 + \u03b22 \u00b7 G ( \u03b3TR +H(\u03b3TR, \u03b2) \u221a \u03b2, 3H(\u03b3TR, \u03b2) \u221a \u03b2 + \u03b2\n2\n) \u223c \u03b21/4\n(14)\nfor all l \u2208 [n] and a similar bound on |c TRjk \u2212 c Sjk|, j < k. If (\u03b5Sl )l\u2208[n], (c S jk)1\u2264j<k\u2264n does not satisfy (8), we discard (i1, i2, i3) and start anew. Note that under our Assumption A, the probability of choosing i1, i2, i3 such that i1, i2, i3 \u2208 LTR is greater than 1/8. In expectation we have to discard (i1, i2, i3) for not more than eight times before finding a solution that satisfies (8) and hence (14).\nAssuming that every worker is presented with every task, that is gij = 1 for all i \u2208 [m] and j \u2208 [n], it follows from Lemma 1 and (14) that m has to scale as ln(n2/\u03b4)/\u03c18 in order that the described strategy is guaranteed to yield, with probability at least 1 \u2212 \u03b4, estimates \u03b5S1 , . . . , \u03b5Sn satisfying |\u03b5TRl \u2212 \u03b5Sl\n\u2223\u2223 \u2264 \u03c1, l \u2208 [n]. This is significantly larger than the rate m \u223c ln(n2/\u03b4)/\u03c12 required by the TE algorithm, which solves the estimation problem for the error probabilities in the one-coin model and is claimed to be minimax optimal (Bonald & Combes, 2017). We suspect that our rate with its dependence on \u03c1\u22128 is not optimal and consider it to be an interesting follow-up question to study the minimax rate for our extension of the one-coin model.\nAlthough the convergence rate that we can guarantee for the described strategy is slow, we might still hope that the strategy performs better in practice. However, there is an issue that we have to overcome. Unless \u03b2 is very small, \u03b3 and \u03bd as specified in (13) are too big for being meaningful, that is any solution (\u03b5Sl )l\u2208[n], (c S jk)1\u2264j<k\u2264n as defined in (10) and (11) will satisfy (8) with these values. We will not discard any (i1, i2, i3), regardless of whether i1, i2, i3 \u2208 LTR holds or not. We deal with this issue by adapting the strategy as follows: let P \u2286 {(i1, i2, i3) : i1, i2, i3 \u2208 [n] pairwise different}. For every p = (i1, i2, i3) \u2208 P , we construct (\u03b5Sl (p))l\u2208[n], (c Sjk(p))1\u2264j<k\u2264n as defined in (10) and (11). We set Qp = [n] unless \u03b3 as specified in (13) is smaller than one, in which case we set Qp = {l \u2208 [n] : \u03b5Sl (p) \u2264 \u03b3} and discard any solution (\u03b5Sl (p))l\u2208[n], (c S jk(p))1\u2264j<k\u2264n for which |Qp| < n2 + 2. Let \u03bd p be the dn2 + 2e-th smallest element of {maxk\u2208[n]\\{l} |c Slk (p)| : l \u2208 Qp}. Then we finally return the solution (\u03b5Sl (p0))l\u2208[n], (c S jk(p0)))1\u2264j<k\u2264n for which \u03bdp is smallest, that is p0 = argminp \u03bd p.\nIf \u03b3 is small enough, it follows from Proposition 2 that\u2223\u2223\u03b5TRl \u2212 \u03b5Sl (p0)\u2223\u2223 \u2264\u221amax{\u03bdp0 , \u03b2/2} \u00b7 G ( \u03b3TR +H(\u03b3TR, \u03b2) \u221a \u03b2,max{\u03bdp0 , \u03b2/2} ) . (15)\nNote that if P contains at least one triple of indices i1, i2, i3 \u2208 LTR, then \u03bdp0 \u2264 3H(\u03b3TR, \u03b2) \u221a \u03b2 + \u03b22 , so that the guarantee (15) is at least as good as (14). We also expect \u03bdp0 to be smaller the larger P is. Hence, we should choose P as large as we can afford due to computational reasons, but in practice, there is one more aspect that we have to consider. Depending on how gij has been chosen, there might be workers wj and wk that were presented with only a few common tasks or no common tasks at all. In this case, the estimate pjk of the agreement probability between wj and wk is only poor and there is no uniform bound \u03b2 on |p TRjk \u2212pjk| (where p TRjk are true agreement probabilities). We can deal with this aspect by choosing P in a way such that for all p \u2208 P , all estimates pjk that are involved in the computation of (\u03b5Sl (p))l\u2208[n] are somewhat reliable. We present a concrete implementation of this in Algorithm 1 below."}, {"heading": "4.3. Predicting ground-truth labels", "text": "Once we have estimates \u03b5\u0302w1 , . . . , \u03b5\u0302wn of the true error probabilities \u03b5w1 , . . . , \u03b5wn , we predict ground-truth labels yi by taking a weighted majority vote over the responses collected for the task xi. Our estimate for yi is given by\ny\u0302i = sign {\u2211n\nl=1 f(\u03b5\u0302wl) \u00b7Ail\n} , (16)\nwhere f : [0, 1]\u2192 [\u2212\u221e,+\u221e]. Ties are broken uniformly at random. We consider two choices for the function f .\nIt is well-known that if all workers follow the one-coin model with known error probabilities \u03b5w1 , . . . , \u03b5wn , groundtruth labels are balanced, that is Pr(x,y)\u223cD[y = +1] = Pr(x,y)\u223cD[y = \u22121], and gij are independent Bernoulli random variables with common success probability \u03b1 > 0, then the optimal estimator for the ground-truth label yi is given by the weighted majority vote (16) with f(\u03b5\u0302wl) replaced by f(\u03b5wl) = ln ((1\u2212 \u03b5wl)/\u03b5wl) (Nitzan & Paroush, 1982; Berend & Kontorovich, 2015; Bonald & Combes, 2017). Hence, a common approach for the one-coin model is to first estimate the true error probabilities and then to estimate ground-truth labels by using the majority vote (16) with f(\u03b5\u0302wl) = ln ((1\u2212 \u03b5\u0302wl)/\u03b5\u0302wl) (Bonald & Combes, 2017; Ma et al., 2017). We propose to use the same majority vote, but restricted to answers from workers that we believe to follow the one-coin model. Using the notation from Section 4.2, this means that we set f(\u03b5\u0302wl) = ln ((1\u2212 \u03b5\u0302wl)/\u03b5\u0302wl) for l \u2208 Qp0 with maxk\u2208[n]\\{l} |c Slk (p0)| \u2264 \u03bdp0 and f(\u03b5\u0302wl) = 0 otherwise.\nAlternatively, we suggest to set f(\u03b5\u0302wl) = 1 \u2212 2\u03b5\u0302wl for l \u2208 [n]. With this choice of f we make use of the responses provided by all workers. The same choice has been used for the one-coin model too (Dalvi et al., 2013). A third option would be to set f(\u03b5\u0302wl) = 1\u2212 2\u03b5\u0302wl for l \u2208 Qp0 with maxk\u2208[n]\\{l} |c Slk (p0)| \u2264 \u03bdp0 and f(\u03b5\u0302wl) = 0 otherwise, but we do not consider this choice any further."}, {"heading": "4.4. Algorithm", "text": "In the interests of clarity, we present our approach as self contained Algorithm 1. Choosing P as the set of triples such that involved pairs of workers have been provided with at least ten or three common tasks might seem somewhat arbitrary here. Indeed, one could introduce two parameters to the algorithm instead. Without optimizing for these parameters, we chose them as ten and three in all our experiments on real data, and hence we state Algorithm 1 as is.\nOur analysis best applies to the setting of a full matrix A (or variables gij that are independent Bernoulli random variables with common success probability, as it is assumed by Bonald & Combes, 2017, for example). In this case, which we consider in our experiments on synthetic data, choosing P as stated in Algorithm 1 reduces to choosing P as the set of all triples of pairwise different indices. If the number of workers n is small, this is the best one can do. If n is large, it is infeasible to choose P as the set of all triples though since the running time of Algorithm 1 is in O(n2(m + |P |)). If n is large and A full, one should sample P uniformly at random. For |P | \u2265 ln \u03b4/ ln(7/8) our error guarantee (14) holds with probability at least 1\u2212 \u03b4 then (compare with Section 4.2)."}, {"heading": "5. Related work", "text": "We briefly survey related work here. A complete discussion can be found in Appendix A. As discussed in Sections 1 and 2, in crowdsourcing one might be interested in estimating ground-truth labels and/or worker qualities given the response matrix A, but also in optimal task assignment. In their seminal paper, Dawid & Skene (1979) proposed an EM based algorithm to address the first two goals. Since then numerous works have followed addressing all three goals for the Dawid-Skene and one-coin model (Ghosh et al., 2011; Karger et al., 2011a;b; 2013; 2014; Dalvi et al., 2013; Gao & Zhou, 2013; Gao et al., 2016; Zhang et al., 2016; Bonald & Combes, 2017; Ma et al., 2017). There have also been efforts to study generalizations of the Dawid-Skene model (Jaffe et al., 2016; Khetan & Oh, 2016; Shah et al., 2016) as well as to explicitly deal with adversaries (Raykar & Yu, 2012; Jagabathula et al., 2017). However, none of the prior work can handle a number of arbitrary adversaries almost as large as the number of reliable workers as we do."}, {"heading": "6. Experiments", "text": "On both synthetic and real data, we compared our proposed Algorithm 1 to straightforward majority voting for predicting labels (referred to as Maj) and the following methods from the literature: the spectral algorithms by Ghosh et al. (2011) (GKM), Dalvi et al. (2013) (RoE and EoR) and Karger et al. (2013) (KOS), the two-stage procedure by\nAlgorithm 1 Input: crowdsourced labels stored in A \u2208 {\u22121, 0,+1}m\u00d7n, upper bound 0 < \u03b3TR < 12 on the error probabilities of dn2 + 2e workers that follow the one-coin model, confidence parameter 0 < \u03b4 < 1 Output: estimates (\u03b5Fl )l\u2208[n], (c Fjk )j<k, (y\u0302i)i\u2208[m] of error probabilities, covariances and ground-truth labels\nI Estimating agreement probabilities set gij = 1{Aij 6= 0}, i \u2208 [m], j \u2208 [n] set qjk = \u2211m i=1 gijgik, j, k \u2208 [n] set pjk as in (3), j, k \u2208 [n] (pjk = NaN if qjk = 0)\nI Estimating error probabilities and covariances set \u03b2 = [ ln(2n2/\u03b4)/ ( 2 minj,k\u2208[n] qjk )]1/2 \u2208 (0,+Inf ] set \u03b3 as in (13) if \u03b3 /\u2208 [0, 1] then\nset \u03b3 = 1 end if set P = { (i1, i2, i3) : i1, i2, i3 \u2208 [n] pairwise different\nand qjk \u2265 10, j, k \u2208 {i1, i2, i3}, and qi2j \u2265 3, j 6= i2 }\nset \u03bdold = Inf, (\u03b5Fl )l\u2208[n] = 0, (c F jk )1\u2264j<k\u2264n = 0, L = \u2205 for (i1, i2, i3) \u2208 P do if not all expressions in (10) or (11) are defined then\nbreak end if compute (\u03b5Sl )l\u2208[n], (c S jk)1\u2264j<k\u2264n as in (10) and (11) set Q = {l \u2208 [n] : \u03b5Sl \u2264 \u03b3} set \u03bd = dn2 + 2e-th smallest element of {maxk\u2208[n]\\{l} |c Slk | : l \u2208 Q} (\u03bd = NaN ifQ = \u2205) if |Q| \u2265 n2 + 2 AND \u03bd < \u03bdold then set (\u03b5Fl )l\u2208[n] = (\u03b5 S l )l\u2208[n], (c F jk )j<k = (c S jk)j<k\nset L = {l \u2208 Q : maxk\u2208[n]\\{l} |c Slk | \u2264 \u03bd} set \u03bdold = \u03bd\nend if end for\nI Estimating ground-truth labels set f(\u03b5\u0302wl) = ln ((1\u2212 \u03b5\u0302wl)/\u03b5\u0302wl) \u2208 [\u2212Inf,+Inf], l \u2208 L,\nand f(\u03b5\u0302wl) = 0, l \u2208 [n] \\ L (alternatively set f(\u03b5\u0302wl) = 1\u2212 2\u03b5\u0302wl , l \u2208 [n]) set y\u0302i as in (16), i \u2208 [m]\nZhang et al. (2016) (S-EM1 and S-EM10, where we run one or ten iterations of the EM algorithm) and the recent method by Bonald & Combes (2017) (TE). We used the Matlab implementation of KOS, S-EM1 and S-EM10 made available by Zhang et al. (2016). In our implementations of the other methods, we adapted GKM, RoE and EoR as to assume that the average error of the workers is smaller than one half rather than assuming that the error of the first worker is. We always called Algorithm 1 with parameters \u03b3TR = 0.4 and \u03b4 = 0.1, which resulted in \u03b3 being set to 1\nin the execution of the algorithm in all our experiments. We refer to Algorithm 1 with the logarithmic weights in (16) as Alg. 1 and and with the linear weights as Alt-Alg. 1. In the following, all results are average results obtained from running an experiment for 100 times."}, {"heading": "6.1. Synthetic data", "text": "In our first experiment, we consider n = 50 workers and m = 5000 tasks with balanced ground-truth labels. Every worker is presented with every task. For 0 \u2264 t \u2264 25, we choose t workers at random. These workers are corrupted workers that all provide the same random response to every task, which is incorrect with error probability 0.5. The remaining n \u2212 t workers provide responses according to the one-coin model, where the error probability of each of these workers is 0.4. Figure 1 shows the prediction error for estimating ground-truth labels and the estimation error for estimating error probabilities in both the maximum norm and the normalized 1-norm for the various methods as a function of t. The prediction error is given by 1m \u2211m i=1 1{yi 6= y\u0302i} for ground-truth labels yi and estimates y\u0302i and the estimation error is given by maxl\u2208[n] |\u03b5wl \u2212 \u03b5\u0302wl | or 1n \u2211n l=1 |\u03b5wl \u2212 \u03b5\u0302wl | for true error probabilities \u03b5wl and estimates \u03b5\u0302wl . The methods Maj and KOS, by default, do not provide estimates of the workers\u2019 error probabilities. We adapt these two methods in order to return estimates of the error probabilities too as follows: if the method returns label estimates y\u03021, . . . , y\u0302m and worker wl provides responses A1l, . . . , Aml 6= 0, then the method\nreturns 1m \u2211m i=1 1{y\u0302i 6= Ail} as estimate \u03b5\u0302wl of \u03b5wl .\nOur Algorithm 1 is the only method that can handle up to 23 = n2 \u2212 2 corrupted workers (in accordance with our theoretical results). Its estimation error is constant as the number of corrupted workers increases from 0 to 23. Its prediction error depends on which weights we use in (16): the prediction error of Alg. 1 is constant in this range too, the one of Alt-Alg. 1 is slightly increasing. If only a few workers are corrupted, Alt-Alg.1 performs better than Alg. 1, while it is the other way round if more than 13 workers are corrupted. The methods from the literature predict ground-truth labels as badly as random guessing already in the presence of only six corrupted workers. All these methods are outperformed by majority voting. We do not have an explanation for the non-monotonic behavior of the estimation error of SEM10 in the maximum norm. In Appendix C we present similar experiments, in which the error probability of the workers following the one-coin model is smaller or the error probabilities of the corrupted workers are less correlated. Still, the overall picture there is the same.\nOne might wonder whether one can combine the considered methods from the literature with one of the algorithms by Jagabathula et al. (2017) in order to first sort the corrupted workers out and then apply the method only to the remaining workers and their responses. However, those algorithms cannot deal with the corrupted workers considered in this experiment, which are perfectly colluding, at all. Even though provided with the correct number t of corrupted workers as input, when t \u2265 3, the soft-penalty algorithm by Jagabathula et al. (2017) was not able to identify any of the corrupted workers in any of the 100 runs of the experiment.\nIn our next experiment, we study the convergence rate of Algorithm 1. We consider n = 50 workers, out of which t = 23 are corrupted in the same way as above. Figure 2 shows the prediction and estimation error of Algorithm 1 as a function of the number of tasks m varying from 5000 to 20000. The prediction error of Alg. 1 decreases only slightly as m increases, the prediction error of Alt-Alg. 1 decreases more significantly. Most interesting is the decay of the estimation error. Apparently, in this experiment it\ndecreases at a rate ofm\u22121/2 rather than at a rate ofm\u22121/8 as suggested by our upper bound (compare with Section 4.2)."}, {"heading": "6.2. Real data", "text": "We performed experiments on six publicly available data sets that are are commonly used in the literature (cf. Snow et al., 2008, Zhang et al., 2016, and Bonald & Combes, 2017). All six data sets come with ground truth labels for each task. For most of the data sets the matrix A, which stores the collected responses, is highly sparse. In order to reduce sparseness, we removed workers that provided fewer than 50 labels. For two of the data sets, we merged classes in order to end up with binary classification problems in the same way as Bonald & Combes (2017) did (Dog: {0, 2} vs {1, 3}; Web: {0, 1, 2} vs {3, 4}). Table 2 in Appendix C provides the characteristic values of the data sets. Note that only for the Bird data set every worker provided a label for every task whereas for the other ones A is still rather sparse. Figure 5 in Appendix C shows for each data set a histogram of the error probabilities of the workers (computed over those tasks that a worker was presented with). Figure 6 shows a heat map of the matrix (|Cov[\u03b5wj (x, y), \u03b5wk(x, y)]|)nj,k=1 (computed over those tasks that two workers were jointly presented with).\nTable 1 shows the prediction error for the various methods and data sets. There is no method that performs best on all data sets. Overall, S-EM10 seems to be the method of choice. Our Algorithm 1 can compete with the other methods, and on four out of the six data sets, the prediction error of Alt-Alg. 1 is smaller or larger only by 0.01 than the prediction error of S-EM10. Alg. 1 performs slightly worse than Alt-Alg. 1. The poor performance of our method on\nthe Bird data set might be explained by the fact that there the workers clearly deviate from our model: as Figure 6 shows, there are no n2 + 2 workers that follow the one-coin model.\nWe performed another experiments on these data sets by corrupting some of the workers (chosen at random). Like in the experiments of Section 6.1, the corrupted workers provide the same random response to every task. Figure 3 shows the prediction errors for the various methods and the first three data sets as functions of the number of corrupted workers. Similar plots for the other data sets are shown in Figure 7 in Appendix C. On none of the data sets, any method can handle more corrupted workers than Alt-Alg. 1."}, {"heading": "7. Discussion", "text": "In this work, we studied an extension of the well-known one-coin model for crowdsourcing that allows for colluding adversaries. Our results show that even if almost half of the workers are adversarial, one can consistently estimate the workers\u2019 error probabilities with an efficient algorithm.\nFor future work, it would be interesting to relax the assumption that the reliable workers follow the one-coin model and to allow for task-dependent error probabilities also for them. It would also be interesting to see whether our approach can be extended to multiclass classification problems. Another direction concerns improving the sufficient rate m \u223c \u03c1\u22128 , which we obtained for our algorithm for recovering worker qualities up to error \u03c1. In the absence of adversaries one can achieve a rate m \u223c \u03c1\u22122, and we would like to understand whether this gap is inherent or an artifact of our algorithm/proof. Finally, we wonder about the role of adaptive task assignment in our extension of the one-coin model."}, {"heading": "Acknowledgements", "text": "This research is supported by a Rutgers Research Council Grant and a Center for Discrete Mathematics and Theoretical Computer Science (DIMACS) postdoctoral fellowship."}], "year": 2018, "references": [{"title": "Crowdgrader: A tool for crowdsourcing the evaluation of homework assignments", "authors": ["L. Alfaro", "M. Shavlovsky"], "venue": "Technical Symposium on Computer Science Education (SIGCSE),", "year": 2014}, {"title": "A finite sample analysis of the naive bayes classifier", "authors": ["D. Berend", "A. Kontorovich"], "venue": "Journal of Machine Learning Research (JMLR),", "year": 2015}, {"title": "A better bound on the variance", "authors": ["R. Bhatia", "C. Davis"], "venue": "The American Mathematical Monthly,", "year": 2010}, {"title": "A minimax optimal algorithm for crowdsourcing", "authors": ["T. Bonald", "R. Combes"], "venue": "In Neural Information Processing Systems (NIPS),", "year": 2017}, {"title": "Aggregating crowdsourced binary ratings", "authors": ["N. Dalvi", "A. Dasgupta", "R. Kumar", "V. Rastogi"], "venue": "In World Wide Web Conference (WWW),", "year": 2013}, {"title": "Maximum likelihood estimation of observer error-rates using the EM algorithm", "authors": ["A. Dawid", "A. Skene"], "venue": "Applied Statistics,", "year": 1979}, {"title": "Imagenet: A large-scale hierarchical image database", "authors": ["J. Deng", "W. Dong", "R. Socher", "Li", "L.-J", "K. Li", "L. Fei-Fei"], "venue": "In Conference on Computer Vision and Pattern Recognition (CVPR),", "year": 2009}, {"title": "Minimax optimal convergence rates for estimating ground truth from crowdsourced labels", "authors": ["C. Gao", "D. Zhou"], "venue": "[stat.ML],", "year": 2013}, {"title": "Exact exponent in optimal rates for crowdsourcing", "authors": ["C. Gao", "Y. Lu", "D. Zhou"], "venue": "In International Conference on Machine Learning (ICML),", "year": 2016}, {"title": "Who moderates the moderators? Crowdsourcing abuse detection in usergenerated content", "authors": ["A. Ghosh", "S. Kale", "P. McAfee"], "venue": "In Conference on Electronic Commerce (EC),", "year": 2011}, {"title": "Unsupervised ensemble learning with dependent classifiers", "authors": ["A. Jaffe", "E. Fetaya", "B. Nadler", "T. Jiang", "Y. Kluger"], "venue": "In International Conference on Artificial Intelligence and Statistics (AISTATS),", "year": 2016}, {"title": "Identifying unreliable and adversarial workers in crowdsourced labeling tasks", "authors": ["S. Jagabathula", "L. Subramanian", "A. Venkataraman"], "venue": "Journal of Machine Learning Research,", "year": 2017}, {"title": "Iterative learning for reliable crowdsourcing systems", "authors": ["D. Karger", "S. Oh", "D. Shah"], "venue": "In Neural Information Processing Systems (NIPS),", "year": 2011}, {"title": "Budget-optimal crowdsourcing using low-rank matrix approximations", "authors": ["D. Karger", "S. Oh", "D. Shah"], "venue": "In Allerton Conference on Communication, Control, and Computing,", "year": 2011}, {"title": "Efficient crowdsourcing for multi-class labeling", "authors": ["D. Karger", "S. Oh", "D. Shah"], "venue": "In ACM Sigmetrics,", "year": 2013}, {"title": "Budget-optimal task allocation for reliable crowdsourcing systems", "authors": ["D. Karger", "S. Oh", "D. Shah"], "venue": "Operations Research,", "year": 2014}, {"title": "Learning from noisy singly-labeled data", "authors": ["A. Khetan", "Z. Lipton", "A. Anandkumar"], "venue": "[cs.LG],", "year": 2017}, {"title": "Learning multiple layers of features from tiny images", "authors": ["A. Krizhevsky"], "venue": "Technical report, University of Toronto,", "year": 2009}, {"title": "Ensuring quality in crowdsourced search relevance evaluation: The effects of training question distribution", "authors": ["J. Le", "A. Edmonds", "V. Hester", "L. Biewald"], "venue": "In SIGIR workshop on crowdsourcing for search evaluation (CSE),", "year": 2010}, {"title": "Error rate bounds in crowdsourcing models", "authors": ["H. Li", "B. Yu", "D. Zhou"], "venue": "[stat.ML],", "year": 2013}, {"title": "Ranking reputation and quality in online rating systems", "authors": ["H. Liao", "A. Zeng", "R. Xiao", "Ren", "Z.-M", "Chen", "D.-B", "Zhang", "Y.-C"], "venue": "PLoS ONE,", "year": 2014}, {"title": "Variational inference for crowdsourcing", "authors": ["Q. Liu", "J. Peng", "A. Ihler"], "venue": "In Neural Information Processing Systems (NIPS),", "year": 2012}, {"title": "Optimal decision rules in uncertain dichotomous choice situations", "authors": ["S. Nitzan", "J. Paroush"], "venue": "International Economic Review,", "year": 1982}, {"title": "Eliminating spammers and ranking annotators for crowdsourced labeling tasks", "authors": ["V. Raykar", "S. Yu"], "venue": "Journal of Machine Learning Research,", "year": 2012}, {"title": "A permutation-based model for crowd labeling: Optimal estimation and robustness", "authors": ["N. Shah", "S. Balakrishnan", "M. Wainwright"], "venue": "[cs.LG],", "year": 2016}, {"title": "Cheap and fast \u2014 but is it good? Evaluating non-expert annotations for natural language tasks", "authors": ["R. Snow", "B. O\u2019Connor", "D. Jurafsky", "A. Ng"], "venue": "In Conference on Empirical Methods in Natural Language Processing (EMNLP),", "year": 2008}, {"title": "A statistical analysis of the aggregation of crowdsourced labels", "authors": ["D. Szepesvari"], "venue": "Master\u2019s thesis, University of Waterloo,", "year": 2015}, {"title": "Spectral methods meet EM: A provably optimal algorithm for crowdsourcing", "authors": ["Y. Zhang", "X. Chen", "D. Zhou", "M. Jordan"], "venue": "Journal of Machine Learning Research,", "year": 2016}, {"title": "Learning from the wisdom of crowds by minimax entropy", "authors": ["D. Zhou", "S. Basu", "Y. Mao", "J. Platt"], "venue": "In Neural Information Processing Systems (NIPS),", "year": 2012}], "id": "SP:8423bffcadb398119aad7987fbb92096362ec297", "authors": [{"name": "Matth\u00e4us Kleindessner", "affiliations": []}, {"name": "Pranjal Awasthi", "affiliations": []}], "abstractText": "Most existing works on crowdsourcing assume that the workers follow the Dawid-Skene model, or the one-coin model as its special case, where every worker makes mistakes independently of other workers and with the same error probability for every task. We study a significant extension of this restricted model. We allow almost half of the workers to deviate from the one-coin model and for those workers, their probabilities of making an error to be task-dependent and to be arbitrarily correlated. In other words, we allow for arbitrary adversaries, for which not only error probabilities can be high, but which can also perfectly collude. In this adversarial scenario, we design an efficient algorithm to consistently estimate the workers\u2019 error probabilities.", "title": "Crowdsourcing with Arbitrary Adversaries"}
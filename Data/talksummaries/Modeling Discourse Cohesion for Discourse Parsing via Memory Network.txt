2	19	However, the performance of discourse parsing is still far from perfect, especially for EDUs that are distant to each other in the discourse.
4	31	The reason may be twofold: Firstly, as discussed in previous works (Joty et al., 2013), it is important to address discourse structure characteristics, e.g., through modeling lexical chains in a discourse, for discourse parsing, especially in dealing with long span scenarios.
7	27	Discourse cohesion includes five situations, including reference, substitution, ellipsis, conjunction and lexical cohesion (Halliday and Hasan, 1989).
10	9	Morris and Hirst (1991) proposes to utilize Roget thesauri to form lexical chains (sequences of semantically related words that can reflect the topic shifts within a discourse), which are used to extract features to characterize discourse structures.
16	35	As shown in Figure 1, the 12 EDUs in the given discourse talk about different topics, marked with 3 different colors, which could be captured by a memory network that maintains several memory slots.
21	35	2) We choose bidirectional long-short term memory (LSTM) (Hochreiter and Schmidhuber, 1997) with an attention mechanism to represent EDUs directly from embeddings, and use simple position features to capture shallow discourse structures, without relying on off-the-shelf tools or resources.
22	6	Experiments on the RST corpus show that the memory based discourse cohesion model can help better capture discourse structure information and lead to significant improvement over traditional feature based discourse parsing methods.
23	21	Our parser is an arc-eager style transition system (Nivre, 2003) with 2 stacks and a queue as shown in Figure 2, which is similar in spirit with (Dyer et al., 2015; Ballesteros et al., 2015).
24	35	We follow the conventional data structures in transition-based dependency parsing, i.e., a queue (B) of EDUs to be processed, a stack (S) to store the partially constructed discourse trees, and a stack (A) to represent the history of transitions (actions combined with discourse relations).
25	7	In our parser, the transition actions include Shift, Reduce, Left-arc and Right-arc.
27	65	Shift pushes the first EDU in queue B to the top of the stack S, while Reduce pops the top item of S. Left-arc connects the first EDU (head) in B to the top EDU (dependent) in S and then pops the top item of S, while Right-arc connects the top EDU (head) of S to the first EDU (dependent) in B and then pushes B’s first EDU to the top of S. A parse tree can be finally constructed until B is empty and S only contains a complete discourse tree.
28	11	For more details, please refer to (Nivre, 2003).
29	6	As shown in Figure 2, at time t, we characterize the current parsing process by preserving the top two elements in B, top three elements in A and the root EDU in the partially constructed tree at the top of S. We first concatenate the embeddings of the preserved elements in each data structure to obtain the embeddings of S, B and A.
34	6	... ... ... l1 l2 Pt Word ... a1 a2 an POS Position1 slotj match{ weighted sum ReLU FC1(ReLU) FC2(ReLU) S B A ... ... wi softmax RA(Li)SH ... sloti ... wi } match weighted sum Bi-LSTM RA(Li) SH （1） （2） （2） Position2 Memory network1 Memory network2 SRefined BRefined ... Bi-LSTM ...
37	11	As mentioned in previous work (Jia et al., 2018), when the top EDUs in S and B are far from each other in the discourse, i.e., with a long span, the parser will be prone to making wrong decisions.
40	53	The first one describes the position of an EDU alone, while the second represents the spatial relationship between the top EDUs of S and B.
41	24	(1) Position1: the positions of the EDU in the sentence, paragraph and discourse, respectively.
43	16	Basic EDU representation: In our model, the EDUs in both S and B follow the same representation method, and we take an EDU in B as an example as shown in Figure 2.
49	11	The Position1 feature vectors are randomly initialized and we expect them to work as a proxy to capture the shallow discourse structure information.
60	26	In our experiments, each memory contains 20 slots, which are randomly initialized and optimized during training.
61	17	Dataset: We use the RST Discourse Treebank (Carlson et al., 2001) with the same split as in (Li et al., 2014), i.e., 312 for training, 30 for development and 38 for testing.
64	42	We adopt unlabeled accuracy UAS (the ratio of EDUs that correctly identify their heads) and labeled accuracy LAS (the ratio of EDUs that have both correct heads and relations) as our evaluation metrics.
65	85	Baselines: We compare our method with the following baselines and models: (1) Perceptron: We re-implement the perceptron based arc-eager style dependency discourse parser as mentioned in (Jia et al., 2018) with coarse-grained relation.
66	23	The Perceptron model chooses words, POS tags, positions and length features, totally 100 feature templates, with the early update strategy (Collins and Roark, 2004).
70	11	(5) MST-full (Li et al., 2014): a graph-based dependency discourse parser with carefully selected 6 sets of features including words, POS tags, positions, length, syntactic and semantic similarity features, which achieves the state-of-art performance on the RST Treebank.
72	13	Here, Jia18, a stack LSTM based method (Jia et al., 2018), outperforms the traditional Perceptron method, but falls behind our Basic model with word, POS tags and Position features.
74	24	We can also see that Basic(word+pos+position) significantly outperforms Basic(word+pos), as the Position features may play a crucial role in providing useful structural clues to our parser.
75	40	Such position information can also be considered as a shallow treatment to capture the discourse cohesion, especially for long span scenarios.
76	54	When using the memory network, our Refined method achieves better performance than the Basic(word+pos+position) in both UAS and LAS.
77	59	The reason may come from the ability of the memory networks in simulating the lexical chains within a discourse, where the memory networks can model the discourse cohesion so as to provide topical or structural clues to our parser.

0	22	Chemical space is huge: it is estimated to contain over 1060 molecules.
1	30	Among these, fewer than 100 million compounds can be found in public repositories or databases (Reymond et al., 2012).
2	30	This discrepancy between known compounds and possible compounds indicates the potential for discoverying many new compounds with highly desirable functionality (e.g., new energy materials, pharmaceuticals, dyes, etc.).
3	14	While the vast size of chemical space makes this an enormous opportunity, it also presents a significant difficulty in the identification of new relevant compounds among the many unimportant ones.
5	24	To accelerate the search, high-throughput approaches can be used in a combinatorial exploration of small specific areas of chemical space (Rajan, 2008).
6	58	These have led to the development of high-throughput virtual screening (Pyzer-Knapp et al., 2015; Gómez-Bombarelli et al., 2016) in which large libraries of molecules are created and then analyzed using theoretical and computational techniques, typically by running a large number of parallel simulations in a computer cluster.
10	40	Bayesian optimization (BO) (Jones et al., 1998) can speed up the discovery process by using machine learning to guide the search and make improved decisions about what molecules to analyze next given the data collected so far.
11	23	However, current BO methods cannot scale to the large number of parallel measurements and the massive libraries of candidate molecules currently used in high-throughput screening (Pyzer-Knapp et al., 2015).
12	26	While there are BO methods that allow parallel data collection, these methods have typically been limited to tens of data points per batch (Snoek et al., 2012; Shahriari et al., 2014; Gonzlez et al., 2016).
27	48	Bayesian optimization methods can be used to identify the inputs that maximize an expensive objective function f by performing only a reduced number of function evaluations.
33	33	Given the data DI and a prior distribution p(θ), the model also specifies a posterior distribution p(θ|DI) ∝ p(θ) ∏ i∈I p(yi|xi,θ).
53	38	So far we have considered the sequential evaluation setting, where BO methods collect just a single data point in each iteration.
55	14	For example, when we run S parallel simulations in a computer cluster and each simulation performs one evaluation of f .
60	12	Therefore, at any point, the next evaluation location is obtained by optimizing the AF αparallel(xj |DI ,K) = Ep({yk}k∈K|{xk}k∈K,DI) [α(xj |DI ∪ DK)] , (2) where DK = {(yk,xk)}k∈K and α(xj |DI ∪ DK) is given by (1).
77	24	In the following section we describe an algorithm for batch BO which can be implemented in a fully parallel and distributed manner and which, consequently, can take full advantage of multiple processors in a computer cluster.
78	19	This novel method is based on a parallel implementation of the Thompson sampling heuristic.
79	41	Algorithm 2 Parallel and distributed Thompson sampling Input: initial data DI(1) = {xi, yi}i∈I(1), batch size S for t = 1 to T do Compute current posterior p(θ|DI(t)) for s = 1 to S do Sample θ from p(θ|DI(t)) Select k(s)← argmaxj 6∈I(t)E[yj |xj ,θ] Collect yk(s) by evaluating f at xk(s) end for DI(t+1) = DI(t) ∪ {xk(s), yk(s)}Ss=1 end for E xe cu te d in pa ra lle l in no de s
81	16	In particular, we propose to apply to (2) the same approximation that TS applied to (1).
82	26	For this, we choose in (2) the same utility function used by TS in the sequential setting, that is, U(yj |xj ,DI ∪DK) = yj .
83	34	Then, we approximate the expectation with respect to {yk}k∈K in (2) by Monte Carlo, averaging across just one sample of {yk}k∈K drawn from p({yk}k∈K|{xk}k∈K,DI).
86	81	The reason for this is that updating a posterior distribution with synthetic data sampled from the model’s predictive distribution produces on average the same initial posterior distribution.
87	29	The result is that parallel TS with batch size S is the same as running sequential TS S times without updating the current posterior p(θ|DI), where each execution of sequential TS produces one of the evaluation locations in the batch.
158	12	To compare with these methods, we also adopt a GP as the model in PDTS.
177	12	The differences between parallel EI and PDTS are much smaller, with both obtaining very similar results.
181	32	We describe the molecule data sets used in our experiments.
199	21	In the Malaria and One-dose data sets we use batches of size 200.
205	16	The first one, greedy, is a sampling strategy that only considers exploitation and does not perform any exploration.
209	22	These two baselines are comparable to PDTS in that they can be easily implemented in a large scale setting in which the library of candidate molecules contains millions of elements and data is sampled using large batch sizes.
214	67	PDTS significantly outperforms the Monte Carlo approach, and also offers better performance than greedy sampling.
220	31	We estimate that, with BO, the CEP virtual screening process would have taken 1,500 CPU years instead of the 30,000 that were actually used.

0,1,label2,summary_sentences
"Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2357–2366, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.",text,[0],[0]
"As science advances, scientists around the world continue to produce a large number of research articles, which provide the technological basis for worldwide dissemination of scientific discoveries.",1 Introduction,[0],[0]
"Online digital libraries such as Google Scholar, CiteSeerx, and PubMed store and index millions of such research articles and their metadata, and make it easier for researchers to search for scientific information.",1 Introduction,[0],[0]
These libraries require effective and efficient methods for topic classification of research articles in order to facilitate the retrieval of content that is tailored to the interests of specific individuals or groups.,1 Introduction,[0],[0]
"Supervised approaches for topic classification of research articles have been developed, which generally use either the content of the articles (Caragea et al., 2011), or take into account the citation relation between research articles (Lu and Getoor, 2003).
",1 Introduction,[0],[0]
"To be successful, these supervised approaches assume the availability of large amounts of labeled
data, which require intensive human labeling effort.",1 Introduction,[0],[0]
"In this paper, we explore a semi-supervised approach that can exploit large amounts of unlabeled data together with small amounts of labeled data for accurate topic classification of research articles, while minimizing the human effort required for data labeling.",1 Introduction,[0],[0]
"In the scholarly domain, research articles (or papers) are highly interconnected in giant citation networks, in which papers cite or are cited by other papers.",1 Introduction,[0],[0]
"We posit that, in addition to a document’s textual content and its local neighborhood in the citation network, other information exists that has the potential to improve topic classification.",1 Introduction,[0],[0]
"For example, in a citation network, information flows from one paper to another via the citation relation (Shi et al., 2010).",1 Introduction,[0],[0]
"This information flow and the topical influence of one paper on another are specifically captured by means of citation contexts, i.e., short text segments surrounding a citation’s mention.
",1 Introduction,[0],[0]
"These contexts are not arbitrary, but they often serve as brief summaries of a cited paper.",1 Introduction,[0],[0]
"We therefore hypothesize that these micro-summaries can be successfully used as an independent view of a research article in a co-training framework to reduce the amount of labeled data needed for the task of topic classification.
",1 Introduction,[0],[0]
"The idea of using terms from citation contexts stems from the analysis of hyperlinks and the graph structure of the Web, which are instrumental in Web search (Manning et al., 2008).",1 Introduction,[0],[0]
"Many search engines follow the intuition that the anchor text pointing to a page is a good descriptor of its content, and thus anchor text terms are used as additional index terms for a target webpage.",1 Introduction,[0],[0]
"The use of links and anchor text was thoroughly researched for information retrieval (Koolen and Kamps, 2010), broadening a user’s search (Chakrabarti et al., 1998), query refinement (Kraft and Zien, 2004), and enriching document representations (Metzler et al., 2009).",1 Introduction,[0],[0]
"Blum and
2357
Mitchell (1998) introduced the co-training algorithm using hyperlinks and anchor text as a second, independent view of the data for classifying webpages, in addition to a webpage content.
",1 Introduction,[0],[0]
Contributions and Organization.,1 Introduction,[0],[0]
"We present a co-training approach to topic classification of research papers that effectively incorporates information from a citation network, in addition to the information contained in each paper.",1 Introduction,[0],[0]
"The result of this classification task will aid indexing of documents in digital libraries, and hence, will lead to improved organization, search, retrieval, and recommendation of scientific documents.",1 Introduction,[0],[0]
"Our contributions are as follows:
• We propose the use of citation contexts as an additional view in a co-training approach, which results in high accuracy classifiers.",1 Introduction,[0],[0]
"To our knowledge, this has not been addressed in the literature.",1 Introduction,[0],[0]
"• We show experimentally that our co-training
classifiers significantly outperform: (1) supervised classifiers trained using either content or citation contexts independently, for the same fraction of labeled data; and (2) several other semi-supervised classifiers, trained on the same fractions of labeled and unlabeled data as co-training.",1 Introduction,[0],[0]
"• We also show that using the citation context
information available in citation networks, the human effort involved in data labeling for training accurate classifiers can be largely reduced.",1 Introduction,[0],[0]
"Our co-training classifiers trained on a very small sample of labeled data and a large sample of unlabeled data yield accurate topic classification of research articles.
",1 Introduction,[0],[0]
The rest of the paper is organized as follows.,1 Introduction,[0],[0]
"In Section 2, we discuss related work.",1 Introduction,[0],[0]
"Section 3 describes our data and its characteristics, followed by the presentation of our proposed co-training approach in Section 4.",1 Introduction,[0],[0]
"We present experiments and results in Section 5, and conclude the paper and present future directions of our work in Section 6.",1 Introduction,[0],[0]
We discuss here the most relevant works to our study.,2 Related Work,[0],[0]
A large variety of methods have been proposed in the literature with regard to automatic text classification and topic prediction.,2 Related Work,[0],[0]
"Different classifiers have been applied on the Vector Space Model (VSM), in which a document is represented as a vector of words or phrases asso-
ciated with their TF-IDF score, i.e. term frequency - inverse document frequency (Zhang et al., 2011; Kansheng et al., 2011).",2 Related Work,[0],[0]
"VSM is the most used method due to its simple, efficient and easy to understand implementation.",2 Related Work,[0],[0]
"Another widely used model is the Latent Semantic Indexing (LSI) where co-occurrences are analyzed to find semantic relationships between words or phrases (Zhang et al., 2011; Ganiz et al., 2011).",2 Related Work,[0],[0]
"Moreover, a great range of classifiers were used for this task, including: Naı̈ve Bayes (Lewis and Ringuette, 1994), Knearest neighbors (Yang, 1999) and Support Vector Machines (Joachims, 1998).",2 Related Work,[0],[0]
"These techniques, however, all require a large number of labeled documents in order to build accurate classifiers.",2 Related Work,[0],[0]
"In contrast, we propose a co-training algorithm that only requires a small amount of labeled data in order to make accurate topic classification.
Semi-supervised methods essentially involve different means of transferring labels from labeled to unlabeled samples in the process of learning a classifier that can generalize well on new unseen data.",2 Related Work,[0],[0]
"Co-training was originally introduced in (Blum and Mitchell, 1998) where it was used to classify web pages into academic course home page or not.",2 Related Work,[0],[0]
"This approach has two views of the data as follows: the content of a web page, and the words found in the anchor text of the hyperlinks that point to the web page.",2 Related Work,[0],[0]
"Wan (2009) used co-training for cross-lingual sentiment classification of product reviews, where English and Chinese features were considered as two independent views of the data.",2 Related Work,[0],[0]
"Furthermore, Gollapalli et al. (2013) used co-training to identify authors’ homepages from the current-day university websites.",2 Related Work,[0],[0]
"The paper presents novel features, extracted from the URL of a page, that were used in conjunction with content features, forming two complementary views of the data.
",2 Related Work,[0],[0]
Citation networks have been used before in other problems.,2 Related Work,[0],[0]
Caragea et al. (2014) used citation contexts to extract informative features for keyphrase extraction.,2 Related Work,[0],[0]
"Lu and Getoor (2003) proposed an approach for document classification that used only citation links, without any textual data from the citation contexts.",2 Related Work,[0],[0]
Ritchie et al. (2006) used a combination of terms from citation contexts and existing index terms of a paper to improve indexing of cited papers.,2 Related Work,[0],[0]
"Citation contexts were also used to improve the performance of citation recommendation systems (Kataria et al., 2010) and to study author influence in document networks
(Kataria et al., 2011).",2 Related Work,[0],[0]
"Moreover, citation contexts were used for scientific paper summarization (Abu-Jbara and Radev, 2011; Qazvinian et al., 2010; Qazvinian and Radev, 2008; Mei and Zhai, 2008; Lehnert et al., 1990)",2 Related Work,[0],[0]
"For example, in Qazvinian et al. (2010), a set of important keyphrases is extracted first from the citation contexts in which the paper to be summarized is cited by other papers and then the “best” subset of sentences that contain such keyphrases is returned as the summary.",2 Related Work,[0],[0]
Mei and Zhai (2008) used information from citation contexts to determine what sentences of a paper are of high impact (as measured by the influence of a target paper on further studies of similar or related topics).,2 Related Work,[0],[0]
"These sentences constitute the impact-based summary of the paper.
",2 Related Work,[0],[0]
"Despite the use of citation contexts and anchor text in many information retrieval and natural language processing tasks, to our knowledge, we are the first to propose the incorporation of citation context information available in citation networks in a co-training framework for topic classification of research papers.",2 Related Work,[0],[0]
The dataset used in our experiments is a subset sampled from the CiteSeerx digital library1 and labeled by Dr. Lise Getoor’s research group at the University of Maryland.,3 Data,[0],[0]
"This subset was previously used in several studies including (Lu and Getoor, 2003) and (Kataria et al., 2010).",3 Data,[0],[0]
"The dataset consists of 3186 labeled papers, with each paper being categorized into one of six classes: Agents, Artificial Intelligence (AI), Information Retrieval (IR), Machine Learning (ML), HumanComputer Interaction (HCI) and Databases (DB).",3 Data,[0],[0]
"For each paper, we acquire the citation contexts directly from CiteSeerx.",3 Data,[0],[0]
A citation context is defined as a window of n words surrounding a citation mention.,3 Data,[0],[0]
"We differentiate between cited and citing contexts for a paper as follows: let d be a target paper and C be a citation network such that d ∈ C. A cited context for d is a context in which d is cited by some paper di in C. A citing context for d is a context in which d is citing some paper dj in C. If a paper is cited in multiple contexts within another paper, the contexts are aggregated into a single context.",3 Data,[0],[0]
"For each paper in the dataset, we have at least one cited or one citing context.",3 Data,[0],[0]
"A summary of the dataset is provided in Table 1.
",3 Data,[0],[0]
"1http://citeseerx.ist.psu.edu/
As expected, we have a higher number of cited contexts than citing contexts.",3 Data,[0],[0]
This is due to the page restrictions often imposed to research articles that can limit the number of papers each article can cite.,3 Data,[0],[0]
"On the other hand, a good research paper can accumulate hundreds of citations, and hence, cited contexts over the years.
",3 Data,[0],[0]
Context lengths.,3 Data,[0],[0]
"In CiteSeerx, citation contexts have about 50 words on each side of a citation mention.",3 Data,[0],[0]
A previous study by Ritchie et al. (2008) shows that a fixed window length of about 100 words around a citation mention is generally effective for information retrieval tasks.,3 Data,[0],[0]
"For this reason, we use the contexts provided by CiteSeerx directly.",3 Data,[0],[0]
"In future, it would be interesting to study more sophisticated approaches to identifying the text that is relevant to a target citation (Abu-Jbara and Radev, 2012; Teufel, 1999) and study the influence of context lengths on our task.
",3 Data,[0],[0]
"For all experiments, our labeled dataset is split in train, validation and test sets.",3 Data,[0],[0]
The validation and test sets have about 200 papers each.,3 Data,[0],[0]
"We sampled another set of papers from the labeled dataset in order to simulate the existence of unlabeled data, with a fixed size of around 2000 papers.",3 Data,[0],[0]
The remaining 786 papers are used as labeled training data.,3 Data,[0],[0]
Each experiment was repeated 10 times with 10 different random seeds and the results were averaged.,3 Data,[0],[0]
Blum and Mitchell (1998) proposed the cotraining algorithm in the context of webpage classification.,4 Co-Training for Topic Classification,[0],[0]
"In co-training, the idea is that two classifiers trained on two different views of the data teach one another by re-training each classifier on the data enriched with predicted examples that the other classifier is most confident about.",4 Co-Training for Topic Classification,[0],[0]
"In Blum and Mitchell (1998), webpages are represented using two different views: (1) using terms from webpages’ content and (2) using terms from the anchor text of hyperlinks pointing to these pages.
",4 Co-Training for Topic Classification,[0],[0]
"Algorithm 1 Co-Training Input: L, U , ‘s’
L1 ← L, L2 ← L while U 6= ∅",4 Co-Training for Topic Classification,[0],[0]
"do
Train classifier C1 on L1 Train classifier C2 on L2 S ← ∅",4 Co-Training for Topic Classification,[0],[0]
"Move ‘s’ examples from U to S U ← U\S S1, S2 ← GetMostConfidentExamples(S,
C1, C2) L1 ← L1 ∪ S1, L2 ← L2 ∪ S2 U ← U ∪",4 Co-Training for Topic Classification,[0],[0]
"[S\(S1 ∪ S2)]
end while Ouput: The combined classifier C of C1 and C2
In this paper, we study the applicability and extension of the co-training algorithm to the task of topic classification of research papers, which are embedded in large citation networks.",4 Co-Training for Topic Classification,[0],[0]
"Here, in addition to the information contained in a paper itself, citing and cited papers capture different aspects (e.g., topicality, domain of study,",4 Co-Training for Topic Classification,[0],[0]
"algorithms used) about the target paper (Teufel et al., 2006), with citation contexts playing an instrumental role.",4 Co-Training for Topic Classification,[0],[0]
"We conjecture that citation contexts, which act as brief summaries about a cited paper, provide important clues in predicting the topicality of a target paper.",4 Co-Training for Topic Classification,[0],[0]
These clues give rise to the design of our co-training based model for topic classification of research papers.,4 Co-Training for Topic Classification,[0],[0]
"In our model, we use the content of a paper as one view and the citation contexts as another view of our data.",4 Co-Training for Topic Classification,[0],[0]
"In particular, for the content of a paper, we use its title and abstract as it is commonly used in the literature (Lu and Getoor, 2003); for the citation contexts, we use both the cited and citing contexts, as described in the previous section.
",4 Co-Training for Topic Classification,[0],[0]
Our co-training procedure is described in Algorithm 1.,4 Co-Training for Topic Classification,[0],[0]
L and U represent the labeled and unlabeled datasets and contain instances from both views.,4 Co-Training for Topic Classification,[0],[0]
The fractions of the training set are obtained from the 786 papers by selecting k% random examples from each class.,4 Co-Training for Topic Classification,[0],[0]
"For a round of co-training, we train classifiers C1 and C2 on the two views.",4 Co-Training for Topic Classification,[0],[0]
"Next, s examples are sampled from the unlabeled data into S, and C1, C2 are used to obtain predictions for these s examples.",4 Co-Training for Topic Classification,[0],[0]
"The GetMostConfidentExamples method is a generic placeholder that stands for a function that deter-
mines what examples from S are chosen to be added into training.",4 Co-Training for Topic Classification,[0],[0]
"Finally, at the end of an iteration, the examples left into S are moved back to U , and the algorithm iterates until there are no more unlabeled examples in U .",4 Co-Training for Topic Classification,[0],[0]
The final classifier C is obtained by combining C1 and C2 using the product of their class probability distributions.,4 Co-Training for Topic Classification,[0],[0]
"The class with the highest posterior probability (of the product of the two distributions) is chosen as the predicted class.
",4 Co-Training for Topic Classification,[0],[0]
"Unlike the original co-training algorithm described by Blum and Mitchell (1998), which tackled a binary classification task (course vs. noncourse page classification), we address a multiclass classification problem, where each example (i.e., research paper) is classified into one of six different classes.",4 Co-Training for Topic Classification,[0],[0]
"Moreover, in Blum and Mitchell (1998), the co-training algorithm moves p highest confidence positive examples and n highest confidence negative examples from S to L, where p : n represents the class distribution in the original labeled training set (i.e., if there are 10 positive examples and 90 negative examples in the labeled set L, then p = 1 positive and n = 9 negative examples are moved to the labeled set at each iteration of co-training).",4 Co-Training for Topic Classification,[0],[0]
"Unlike, this approach that preserves the class distribution of the original labeled training set, we move into L all examples that are classified with a confidence above a certain threshold.",4 Co-Training for Topic Classification,[0],[0]
"First, the proposed method is evaluated on the validation set.",5 Results and Discussion,[0],[0]
We first compare it against various supervised and semi-supervised baselines.,5 Results and Discussion,[0],[0]
"Next, we report the performance of our co-training algorithm under different scenarios, where either cited or citing contexts are used.",5 Results and Discussion,[0],[0]
We also show the most informative words for each classifier.,5 Results and Discussion,[0],[0]
"Finally, with the best parameters obtained on the validation set, we report the precision, recall and F1-score, obtained by each method, on the test set.
",5 Results and Discussion,[0],[0]
"In experiments, the sample size ‘s’ from Algorithm 1 is set to 300, i.e. the number of documents sampled from the unlabeled pool at each iteration; the confidence threshold is set to 0.95, i.e. if both classifiers agree on the class label and have a confidence ≥ 0.95, the instance is labeled and moved into the labeled training set.",5 Results and Discussion,[0],[0]
"These parameters are estimated on the validation set, but the results are not shown due to space limitation.
",5 Results and Discussion,[0],[0]
Evaluation Measures.,5 Results and Discussion,[0],[0]
We report results averaged over ten different runs with random splits.,5 Results and Discussion,[0],[0]
"For each random split, we return the weighted average precision, recall and F1-score.",5 Results and Discussion,[0],[0]
"In all the experiments, we use the Naı̈ve Bayes Multinomial classifier and its Weka implementation2, with term-frequencies as feature values.",5 Results and Discussion,[0],[0]
"We experimented with both TF and TF-IDF scores, using different classifiers (Support Vector Machine, Naı̈ve Bayes Multinomial, and simple Naı̈ve Bayes classifiers), but Naive Bayes Multinomial with TF performed best.",5 Results and Discussion,[0],[0]
How does co-training compare with supervised learning techniques?,5.1 Baseline Comparisons,[0],[0]
"In this experiment, we compare our co-training method with two supervised baselines: (1) when only document content is used and (2) when only citation contexts are used.
",5.1 Baseline Comparisons,[0],[0]
Figure 1 shows the F1-scores achieved using different initial training sizes.,5.1 Baseline Comparisons,[0],[0]
"We can see that overall, the citation contexts are better at predicting the topic of a document compared with the content, outperforming them in 9 out of 10 experimental settings.",5.1 Baseline Comparisons,[0],[0]
"The only exception to this trend is when a small number (5%) of training instances is available, in which case the supervised content view performs better, reaching an F1-score of 0.534.",5.1 Baseline Comparisons,[0],[0]
"Regardless, the co-training method shows significant improvement over both baselines, in all experiments.",5.1 Baseline Comparisons,[0],[0]
"Starting with an F1-score of 0.572, it continues to improve its performance as the training percentage is increasing.",5.1 Baseline Comparisons,[0],[0]
"The maximum F1score, i.e. 0.742, is reached when 30% of the labeled training set is used.",5.1 Baseline Comparisons,[0],[0]
"Note that the difference in performance between co-training and the two supervised baselines is statistically significant for
2http://www.cs.waikato.ac.nz/ml/weka/
a p value of 0.05.
",5.1 Baseline Comparisons,[0],[0]
A fully supervised baseline that uses 100% of the training set achieves an F1-score of 0.720 (using content) and 0.738 (using citation contexts).,5.1 Baseline Comparisons,[0],[0]
"In contrast, co-training requires only 15% of the labeled training set to outperform the fully supervised content baseline and 30% of the training set to outperform the fully supervised citation contexts baseline.",5.1 Baseline Comparisons,[0],[0]
"Consequently, using a co-training approach that includes citation contexts as well as the document content can not only increase the performance, but will also significantly reduce the need of expensive labeled instances.
",5.1 Baseline Comparisons,[0],[0]
"Figure 2 illustrates the confusion matrices of three experiments: (a) supervised content view, i.e. the title and abstract, (b) supervised citation contexts view, and (c) co-training that uses both views.",5.1 Baseline Comparisons,[0],[0]
These experiments use 10% of the training set.,5.1 Baseline Comparisons,[0],[0]
"Each of the matrices are represented by a heat map, i.e. the redder the color, the higher the value assigned to that position.",5.1 Baseline Comparisons,[0],[0]
An accuracy of 1 will be represented by a matrix with red blocks on the main diagonal and white blocks everywhere else.,5.1 Baseline Comparisons,[0],[0]
"This experiment was performed 10 times with 10 different seeds and the results have been averaged.
",5.1 Baseline Comparisons,[0],[0]
"As can be seen, the matrix that uses only titles and abstracts, i.e. left side, is showing the highest percentage of misclassified documents, classifying correctly about 58.8% instances, on average.",5.1 Baseline Comparisons,[0],[0]
"Using only citation contexts in a supervised framework, i.e. center matrix, we reach a higher accuracy of 60.7%.",5.1 Baseline Comparisons,[0],[0]
"The co-training method, which uses the content of the paper and citations as two independent views, significantly increases the average accuracy to 67.3%.",5.1 Baseline Comparisons,[0],[0]
This experiment shows that citation contexts are better than titles and abstracts at predicting the topic of a document.,5.1 Baseline Comparisons,[0],[0]
"Furthermore, our proposed approach, which uses the content of the paper as well as citation contexts, achieves higher results than each view used separately.",5.1 Baseline Comparisons,[0],[0]
"The difference in accuracy is statistically significant across all three experiments for a p value of 0.05.
",5.1 Baseline Comparisons,[0],[0]
"Overall, the Agents class seem to be the easiest to classify, reaching an accuracy value of 91.6% when using co-training.",5.1 Baseline Comparisons,[0],[0]
"On the other hand, the AI class is the hardest to classify.",5.1 Baseline Comparisons,[0],[0]
One reason for this is that the AI class contains the lowest number of instances in the dataset.,5.1 Baseline Comparisons,[0],[0]
"Another can be that the AI class is the most general among all classes and therefore, classifying documents with this la-
Left: using titles and abstracts; Center: using citation contexts;",5.1 Baseline Comparisons,[0],[0]
"Right: using co-training.
bel can be a difficult task even for a human.",5.1 Baseline Comparisons,[0],[0]
"Other common misclassifications occur between classes like HCI and Agents, ML and IR or AI and ML, due to their similarity.
",5.1 Baseline Comparisons,[0],[0]
How does our co-training method compare with other supervised approaches?,5.1 Baseline Comparisons,[0],[0]
"In this experiment, we compare the performance of co-training against two other methods: early and late fusion.",5.1 Baseline Comparisons,[0],[0]
"In early fusion, the feature vectors of the two views are concatenated, creating a single representation of the data.",5.1 Baseline Comparisons,[0],[0]
"In contrast, late fusion trains two separate classifiers and then combines them by taking the label with the highest confidence.
",5.1 Baseline Comparisons,[0],[0]
Figure 3 shows this comparison over different training sizes.,5.1 Baseline Comparisons,[0],[0]
"The results show that the cotraining method is more accurate than all others, performing best in all 10 experimental settings.",5.1 Baseline Comparisons,[0],[0]
"Late fusion has an overall lower performance compared with co-training, but is in a tight correlation with it.",5.1 Baseline Comparisons,[0],[0]
"On the other hand, early fusion achieves the lowest F1-score across the experiments.",5.1 Baseline Comparisons,[0],[0]
"The reported results are statistically significant at p value of 0.05, when the training percentage is between 5 and 35.",5.1 Baseline Comparisons,[0],[0]
"Therefore, we can say that train-
ing two separate classifiers, one of each view, yields higher performance compared with training a single classifier that incorporates both views.",5.1 Baseline Comparisons,[0],[0]
"Moreover, using a co-training approach that incorporates information from unlabeled data into the model, will help the two classifiers increase their confidences and minimize the error rate.
",5.1 Baseline Comparisons,[0],[0]
How does co-training compare with semisupervised methods?,5.1 Baseline Comparisons,[0],[0]
"Here, we present results comparing co-training with two other wellknown semi-supervised techniques: self-training and Naı̈ve Bayes with Expectation Maximization.
Self-Training.",5.1 Baseline Comparisons,[0],[0]
"First, we show results of the comparison of co-training with two variations of selftraining: (1) self-training using only document content, and (2) self-training using only citation contexts.",5.1 Baseline Comparisons,[0],[0]
Figure 4 shows the results of this experiment.,5.1 Baseline Comparisons,[0],[0]
"Self-training is similar to co-training, except that it uses only one view of the data (Zhu, 2005).",5.1 Baseline Comparisons,[0],[0]
"Self-training parameters, e.g., sample size ‘s’ or number of iterations, are estimated as in cotraining.
",5.1 Baseline Comparisons,[0],[0]
"Although the document content version of selftraining outperforms co-training when using 5%
of the training instances, we can see that overall, there is a significant difference in terms of F1score values in the favor of co-training.",5.1 Baseline Comparisons,[0],[0]
"In 9 out of 10 experiments, our co-training approach is superior to both self-training methods.",5.1 Baseline Comparisons,[0],[0]
"The results are statistically significant across all experimental setups for a p value of 0.05.
",5.1 Baseline Comparisons,[0],[0]
Expectation Maximization.,5.1 Baseline Comparisons,[0],[0]
"Figure 5 shows the F1-score values obtained after running NBM with EM with the same training, unlabeled and test sets.",5.1 Baseline Comparisons,[0],[0]
"The EM algorithm uses the same classifier, i.e. NBM, and the weight for each unlabeled instance is set to 1, as this setting achieved the highest results.",5.1 Baseline Comparisons,[0],[0]
"Two different experiments were performed using EM: (1) using only document content, and (2) using only citation contexts.",5.1 Baseline Comparisons,[0],[0]
"As can be seen in the figure, overall, the co-training approach significantly outperforms both variations of EM.",5.1 Baseline Comparisons,[0],[0]
"However, the co-training method falls short when using 5% of the training instances, where EM Content and EM Citations methods are achieving higher F1-score values.",5.1 Baseline Comparisons,[0],[0]
"Nonetheless, both EM variations tend to achieve an F1-score value below or equal to 0.710, whereas co-training reaches performance values of 0.74 or higher.",5.1 Baseline Comparisons,[0],[0]
"Again, the comparison results between co-training and both variations of EM are statistically significant for training sizes between 10% and 50%, for a p value of 0.05.",5.1 Baseline Comparisons,[0],[0]
Which of the two types of citation contexts (cited or citing) help the task of topic classification more and how does co-training perform in the absence of either one?,5.2 Using Different Citation Context Types,[0],[0]
The answer to this question is important as there are cases in which citation contexts are not readily available.,5.2 Using Different Citation Context Types,[0],[0]
"One frequently encountered example includes newly published research papers that have no cited contexts.
",5.2 Using Different Citation Context Types,[0],[0]
"In this case, it is important to know how our method performs when we only have one type of citation contexts.",5.2 Using Different Citation Context Types,[0],[0]
"Figure 6 shows the difference in performance when using: (1) only cited contexts, (2) only citing contexts, and (3) both context types.",5.2 Using Different Citation Context Types,[0],[0]
"Note that the content view remains the same across all three experiments.
",5.2 Using Different Citation Context Types,[0],[0]
The plot is showing that citing contexts are bringing in a significantly higher margin of knowledge compared with cited contexts.,5.2 Using Different Citation Context Types,[0],[0]
"This is consistent over different training set sizes, as shown in the figure, with a more prominent impact when a small training size is used, i.e. 5-30%.",5.2 Using Different Citation Context Types,[0],[0]
"The fact that the citing contexts achieve higher F1-score than cited contexts is consistent with the intuition that when citing a paper y, an author generally summarizes the main ideas from y using important words from a target paper x, making the citing contexts to have higher overlap with words from x.",5.2 Using Different Citation Context Types,[0],[0]
"In turn, a paper z that cites x may use paraphrasing to summarize ideas from x with words more similar to those from the content of z.
When the two types of contexts are used, cotraining achieves higher results compared with cases when only one context type is used.",5.2 Using Different Citation Context Types,[0],[0]
This experiment shows that our method can be applied for both old and new research articles.,5.2 Using Different Citation Context Types,[0],[0]
Citing contexts will be available in the text of the target paper and are independent of the existence of the cited contexts.,5.2 Using Different Citation Context Types,[0],[0]
What are the most informative words from each view: document content and citation contexts?,5.3 Informative Features,[0],[0]
Figure 7 shows the words from each view that are most useful for our topic classification task.,5.3 Informative Features,[0],[0]
"The larger the word, the more informative is for our
task.",5.3 Informative Features,[0],[0]
"To determine the informativeness of a word, we used its Information Gain score.",5.3 Informative Features,[0],[0]
"For these experiments, we used training sets consisting of 30% of the instances, setting in which we achieved the best results on the validation and test sets using our proposed co-training approach.
",5.3 Informative Features,[0],[0]
"As can be seen, the two word clouds have a high word overlap.",5.3 Informative Features,[0],[0]
"Words such as agent, database or query are almost equally important in the two views, dominating both clouds.",5.3 Informative Features,[0],[0]
"However, differences can be observed.",5.3 Informative Features,[0],[0]
"For example, words like learning, multi-agent or interface are more important in the content view.",5.3 Informative Features,[0],[0]
"On the other hand, words such as document or text achieve a higher information gain score for the citation contexts view.",5.3 Informative Features,[0],[0]
"Table 2 summarizes the results obtained by all the baselines used so far, in comparison with our proposed co-training method.",5.4 Co-Training vs. All Other Approaches,[0],[0]
"For this experiment, we show the training percentage used, the precision, recall and F1-score for each method, in the setting in which it returned the best results.",5.4 Co-Training vs. All Other Approaches,[0],[0]
"All mea-
sures were averaged after 10 runs with 10 different seeds.
",5.4 Co-Training vs. All Other Approaches,[0],[0]
"The results in Table 2 show that the proposed co-training method outperforms all compared models, reaching the highest F1-score of 0.742, while using the smallest amount of labeled documents, i.e. 30%.",5.4 Co-Training vs. All Other Approaches,[0],[0]
"Using only the citing contexts, the performance is similar to that of co-training when both context types are used.",5.4 Co-Training vs. All Other Approaches,[0],[0]
"However, using only the cited contexts, the performance decreases compared to that of the full model that uses both context types.",5.4 Co-Training vs. All Other Approaches,[0],[0]
"We see that the citing contexts perform better, reaching an F1-score value of 0.740 compared against 0.714 when only cited contexts are used.",5.4 Co-Training vs. All Other Approaches,[0],[0]
"Moreover, the method that uses only the citing contexts is using 10% less labeled data.
",5.4 Co-Training vs. All Other Approaches,[0],[0]
Self-training and EM show decreased performance compared with co-training.,5.4 Co-Training vs. All Other Approaches,[0],[0]
"Late Fusion outperforms Early Fusion, i.e., 0.738 vs. 0.714, both obtaining lower results than co-training, while using significantly more labeled data.
",5.4 Co-Training vs. All Other Approaches,[0],[0]
"The last two lines of the table show the results when all documents (except those in the validation and test), are used for training, in a supervised framework.",5.4 Co-Training vs. All Other Approaches,[0],[0]
"As can be seen, a supervised method that uses only citations will achieve a higher performance, compared against a method that uses titles and abstracts.",5.4 Co-Training vs. All Other Approaches,[0],[0]
"Nonetheless, co-training obtains higher results than both fully supervised approaches, while using only 30% of the labeled data.",5.4 Co-Training vs. All Other Approaches,[0],[0]
"In this paper, we studied the problem of using citation contexts in order to predict more accurately the topic of a research article.",6 Conclusion and Future Work,[0],[0]
"We showed that a co-training technique, which uses the paper content and its citation contexts as two conditionally independent and sufficient views of the data, can effectively incorporate cheap, unlabeled data to improve the classification performance and to reduce the need of labeled examples to only a fraction.",6 Conclusion and Future Work,[0],[0]
"The results of the experiments showed that the proposed approach performs better than other semi-supervised and supervised methods.
",6 Conclusion and Future Work,[0],[0]
This study also shows that citation contexts are rich sources of information that can be successfully used in various IR and NLP tasks.,6 Conclusion and Future Work,[0],[0]
We showed that document content and citation contexts unified under the same algorithm can dramatically decrease the annotation costs as well.,6 Conclusion and Future Work,[0],[0]
"In the future, we plan to extend co-training to include active learning for more robust classification.",6 Conclusion and Future Work,[0],[0]
"Moreover, it would be interesting to extend the co-training approach to multi-views that could potentially handle more than two feature spaces, e.g., it could include topics by Latent Dirichlet Allocation (Blei et al., 2003) as an additional view.",6 Conclusion and Future Work,[0],[0]
We are thankful to Dr. Lise Getoor for making the Citeseerx labeled subset publicly available.,Acknowledgments,[0],[0]
"We are also grateful to Dr. C. Lee Giles for the CiteSeerx data, which helped extract the citation contexts of the research papers in the collection.",Acknowledgments,[0],[0]
We very much thank our anonymous reviewers for their constructive feedback.,Acknowledgments,[0],[0]
This research is supported in part by the NSF award #1423337 to Cornelia Caragea.,Acknowledgments,[0],[0]
"Any opinions, findings, and conclusions expressed here are those of the authors and do not necessarily reflect the views of NSF.",Acknowledgments,[0],[0]
"With the exponential growth of scholarly data during the past few years, effective methods for topic classification are greatly needed.",abstractText,[0],[0]
Current approaches usually require large amounts of expensive labeled data in order to make accurate predictions.,abstractText,[0],[0]
"In this paper, we posit that, in addition to a research article’s textual content, its citation network also contains valuable information.",abstractText,[0],[0]
We describe a co-training approach that uses the text and citation information of a research article as two different views to predict the topic of an article.,abstractText,[0],[0]
"We show that this method improves significantly over the individual classifiers, while also bringing a substantial reduction in the amount of labeled data required for training accurate classifiers.",abstractText,[0],[0]
Co-Training for Topic Classification of Scholarly Data,title,[0],[0]
"Combinatorial optimization is a important topic of computer science and discrete mathematics, with a wide spectrum of applications ranging from resource allocation and job scheduling, to automated planning and configuration softwares.",1. Introduction,[0],[0]
"A common problem is to minimize a modular loss function ` over a discrete space S ⊆ {0, 1}d of feasible solutions represented in a concise manner by a set of combinatorial constraints.",1. Introduction,[0],[0]
"In the offline version of this problem, all information necessary to define the optimization task is available beforehand, and the challenge is to develop algorithms which are provably or practically better than enumerating all feasible solutions.",1. Introduction,[0],[0]
"Contrastingly, in the online version of this problem (Audibert et al., 2014), the objective function ` is subject to change over time.",1. Introduction,[0],[0]
"The challenge here is more acute, since the optimization algorithm is required to perform repeated choices on S so as to minimize their average cost in the long run.
",1. Introduction,[0],[0]
"*Equal contribution 1CRIL, CNRS UMR 8188, Université d’Artois, France.",1. Introduction,[0],[0]
"Correspondence to: Frederic Koriche <koriche@cril.fr>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"Conceptually, an online combinatorial optimization problem can be cast as a repeated prediction game between a learning algorithm and its environment (Audibert et al., 2011; 2014).",1. Introduction,[0],[0]
"During each trial t, the learner chooses a feasible solution st from its decision set S and, simultaneously, the environment selects a loss vector `t ∈",1. Introduction,[0],[0]
"[0, 1]d.",1. Introduction,[0],[0]
"Then, the learner incurs the loss 〈`t, st〉 = ∑d i=1",1. Introduction,[0],[0]
"`t(i)st(i) and, in light of the feedback provided by its environment, updates its strategy in order to improve the chance of selecting better solutions on subsequent trials.
",1. Introduction,[0],[0]
"Several classes of combinatorial prediction games can be distinguished, depending on the type of decision set, and the type of observed feedback.",1. Introduction,[0],[0]
"In this paper, we focus on full information games in which it is assumed that the feedback supplied at trial t by the environment is the entire vector `t. On the other hand, we make very few assumptions about the decision set: S may be described by an arbitrary SAT formula, that is, any set of combinatorial constraints representable by Boolean clauses.",1. Introduction,[0],[0]
"As SAT encodings of discrete solution spaces are frequently used in academic and industrial applications (Biere et al., 2009), our setting covers an important class of combinatorial prediction games.
",1. Introduction,[0],[0]
"As usual, the performance of an online learning algorithm is measured according to two metrics.",1. Introduction,[0],[0]
"The first, called regret, measures the difference in cumulative loss between the algorithm and the best solution in hindsight.",1. Introduction,[0],[0]
"In this study, we make no assumption about the sequence of loss vectors; in particular `t may depend on the previous decisions s1, · · · , st−1 made by the learner.",1. Introduction,[0],[0]
"In such non-oblivious or adversarial environments, the learner is generally allowed to make decisions in a randomized way, and its predictive performance is measured by the expected regret:
RT = E",1. Introduction,[0],[0]
"[ T∑ t=1 〈`t, st〉 ] −min",1. Introduction,[0],[0]
"s∈S T∑ t=1 〈`t, s〉
The second metric is computational complexity, i.e. the amount of resources required to compute st at each round t, given the sequence of feedbacks observed so far.
",1. Introduction,[0],[0]
Related Work.,1. Introduction,[0],[0]
"In the literature of combinatorial prediction games, three main strategies have been proposed to attain an expected regret that is sublinear in the game horizon T and polynomial in the input dimension d. The
first, and arguably simplest strategy, is to Follow the Perturbed Leader (FPL): on each trial t, the learner draws at random a perturbation vector zt ∈ Rd, and then selects in S a minimizer of ηLt + zt, where η ∈ (0, 1] is a step-size parameter, andLt is the cumulative lossLt = `1 + · · ·+`t−1.",1. Introduction,[0],[0]
"Based on the pioneering work of Hannan (1957), refined in (Hutter & Poland, 2005; Kalai & Vempala, 2005), the FPL algorithm achieves an expected regret of O(d 32 √ T ).
",1. Introduction,[0],[0]
"The second strategy is based on the popular exponentially weighted average forecaster in the framework of prediction with expert advice (Cesa-Bianchi & Lugosi, 2006).",1. Introduction,[0],[0]
"The overall idea is to maintain a weight for each feasible solution s ∈ S, which decays exponentially according to the estimated cumulative loss of s. Specifically, on each trial t, the learner draws a solution st ∈ S at random from the exponential family pt(s) ∼ exp(−η〈Lt, s〉).",1. Introduction,[0],[0]
"This strategy, referred to as Expanded Hedge (EH) in (Koolen et al., 2010), attains an expected regret of O(d 32 √ T ).
",1. Introduction,[0],[0]
"Finally, the third strategy is to Follow the Regularized Leader, a paradigm often advocated in online convex optimization (Hazan, 2016).",1. Introduction,[0],[0]
"Here, the learner operates on the convex hull of S, denoted conv(S).",1. Introduction,[0],[0]
"On each trial t, the learner starts by choosing a point pt ∈ conv(S) that minimizes η〈L̂t,p〉 + F (p), where F is a regularization function.",1. Introduction,[0],[0]
"Next, pt is decomposed as a convex composition of feasible solutions in S, and then, a decision st is picked at random according to the resulting distribution.",1. Introduction,[0],[0]
"For modular loss functions, this strategy is equivalent to the Online Stochastic Mirror Descent (OSMD) algorithm (Audibert et al., 2014; Rajkumar & Agarwal, 2014), which iteratively performs a gradient descent in the dual space of conv(S) under F , and projects back to the primal space according to the Bregman divergence defined from F .",1. Introduction,[0],[0]
"Notably, when F is the Euclidean regularizer, OSMD coincides with the popular stochastic gradient descent (SGD) algorithm (Robbins & Monro, 1951).",1. Introduction,[0],[0]
"Alternatively, when F is the entropic regularizer, OSMD corresponds to the Component Hedge (CH) algorithm (Koolen et al., 2010), which achieves an optimal expected regret of O(d √ T ).
",1. Introduction,[0],[0]
"From the viewpoint of regret, the results outlined above indicate that few improvements remain to be made in full information games.",1. Introduction,[0],[0]
"However, we get a different picture if computational considerations are taken into account: all aforementioned algorithms rely on powerful oracles for making decisions in spaces S represented by combinatorial constraints.",1. Introduction,[0],[0]
"Namely, the EH algorithm is required, at each iteration, to sample a solution according to an exponential family over S , a problem which is generally #P-hard (Dyer et al., 2009).",1. Introduction,[0],[0]
"Similarly, the FPL strategy has to repeatedly solve a linear optimization task over S, which is generally NP-hard (Creignou et al., 2001).",1. Introduction,[0],[0]
"For the OSMD algorithm, and its specializations SGD and CH, the computational issue
is exacerbated by the fact that, even if the learner has access to a linear optimization oracle, it still has to perform, at each trial, a Bregman projection step for which the best known algorithms run in O(d6) time (Suehiro et al., 2012).
",1. Introduction,[0],[0]
"Although combinatorial prediction games are generally intractable, efficient implementations of sampling and optimization oracles may be obtained for several decision sets S. For example, when the feasible solutions in S coincide with the bases of a binary matroid, or the perfect matchings of a bipartite graph, linear optimization can be performed in polynomial time, and tractable forms of FPL and OSMD may be derived (Helmbold & Warmuth, 2009; Koolen et al., 2010; Takimoto & Hatano, 2013; Rajkumar & Agarwal, 2014).",1. Introduction,[0],[0]
"On the other hand, when the feasible solutions in S correspond to the paths or multi-paths of a rooted Directed Acyclic Graph (DAG), the sampling oracle may be implemented by the weight pushing technique (Mohri, 1998), that recursively evaluates the partition function of an exponential family over the edges of the input DAG.",1. Introduction,[0],[0]
"Based on this technique, tractable forms of EH can be derived (Takimoto & Warmuth, 2003; Rahmanian & Warmuth, 2017).
",1. Introduction,[0],[0]
Our Results.,1. Introduction,[0],[0]
Viewing feasible solutions as paths in a DAG is only one of many abstractions that have been proposed in the literature of circuit complexity for representing combinatorial spaces.,1. Introduction,[0],[0]
"In the related field of knowledge compilation (Darwiche & Marquis, 2002), various classes of Boolean circuits have been identified, each associated with a set of inference tasks which can be performed in polynomial time.",1. Introduction,[0],[0]
These theoretical results naturally motivate the following question: can we compile a set of constraints representing a combinatorial space S into a compact and Boolean circuit for which both solution sampling and linear optimization are tractable?,1. Introduction,[0],[0]
"By viewing the compilation process as a “pre-processing step”, we may get for free efficient implementations of sampling and optimization oracles, provided that the size of the resulting circuit is not too large.
",1. Introduction,[0],[0]
"The present study aims at solving combinatorial prediction games, by compiling decision sets into deterministic Decomposable Negation Normal Form (dDNNF) circuits (Darwiche, 2001).",1. Introduction,[0],[0]
"This class comes with generic compilers which take as input a SAT formula representing a decision set S, and return a dDNNF circuit C that encodes S (Darwiche, 2002; Lagniez & Marquis, 2017).",1. Introduction,[0],[0]
"Although the size of C may grow exponentially in the treewidth of the input formula, it is usually much smaller in practice; existing compilers are able to compress combinatorial spaces defined over thousands of variables and constraints.
",1. Introduction,[0],[0]
"With these compilation tools in hand, our contributions are threefold: (i) we show that for dDNNF circuits, the sampling oracle in EH and the linear optimization oracle in FPL, run in linear time using a simple variant of the weight-
pushing technique; (ii) for the SGD and CH strategies, we develop a Bregman projection-decomposition method that uses O(d2 ln(dT ))",1. Introduction,[0],[0]
"calls to the linear optimization oracle; (iii) we experimentally show on online configuration and planning tasks that EH and FPL are fast, but our variants of SGD and CH are more efficient to minimize the empirical regret.
",1. Introduction,[0],[0]
"Before proceeding to the core of the paper, we emphasize that the compilation approach to online optimization is not entirely new.",1. Introduction,[0],[0]
"Recently, Sakaue et.",1. Introduction,[0],[0]
"al. (2018) used the class of Ordered Binary Decision Diagrams (OBDDs) (Bryant, 1986) for implementing the EWA forecaster in combinatorial bandits.",1. Introduction,[0],[0]
"Here, S is described by a graph over d edges, together with a constraint specifying the type of objects we desire (e.g. paths or cliques).",1. Introduction,[0],[0]
"By contrast, our study assumes that S is described with an arbitrary set of Boolean constraints.",1. Introduction,[0],[0]
"So, both studies are targeting different classes of combinatorial prediction games.",1. Introduction,[0],[0]
"Moreover, it is known that dDNNF is strictly more succinct than OBDD (Darwiche & Marquis, 2002).",1. Introduction,[0],[0]
"Namely, any OBDD can be transformed in linear time and space into an equivalent dDNNF circuit, but the converse is not true: dDNNF includes simple circuits which require an exponential size representation in OBDD.",1. Introduction,[0],[0]
"In fact, the key point of compiling combinatorial prediction games is to use both tractable and succinct languages, for allowing prediction strategies to be efficient on a wide variety of combinatorial domains.",1. Introduction,[0],[0]
"For the combinatorial prediction games considered in this paper, we assume that the input decision space S is defined from a set of n binary-valued attributes, and we use X = {x1, · · · , xd}, where d = 2n, to denote the set of all “attribute-value” pairs, called literals.",2. Tractable Inference via Compilation,[0],[0]
"A solution is a vector s ∈ {0, 1}d such that s(i) + s(j) = 1 for every pair of distinct literals xi, xj ∈ X defined on the same attribute.",2. Tractable Inference via Compilation,[0],[0]
"Thus, ‖s‖1 = n for any feasible solution s ∈ S.
An NNF circuit over X is a rooted DAG, whose internal nodes are labeled by ∨ (or-node) or ∧ (and-node), and whose leaves are labeled by either a literal in X , or a constant in {0, 1}.",2. Tractable Inference via Compilation,[0],[0]
"The size of C, denoted |C|, is given by the number of its edges.",2. Tractable Inference via Compilation,[0],[0]
"The set of attributes occurring in the subgraph of C rooted at some node c is denoted att(c).
",2. Tractable Inference via Compilation,[0],[0]
"For the sake of clarity, we assume that any NNF circuit C satisfies two basic properties, namely (i) any internal node c in C has exactly two children, denoted cl and cr, and (ii) att(cl) = att(cr) 6=",2. Tractable Inference via Compilation,[0],[0]
∅ for any or-node c of C. An NNF circuit satisfying both conditions is called smooth.,2. Tractable Inference via Compilation,[0],[0]
"As shown in (Darwiche, 2001), any Boolean circuitC can be transformed in to an equivalent smooth NNF circuit of size linear in |C|.
",2. Tractable Inference via Compilation,[0],[0]
"By viewing literals as “input gates”, and nodes as “output gates”, we may specify various inference tasks on Boolean
circuits, depending on the type of input values and the semantics of nodes.",2. Tractable Inference via Compilation,[0],[0]
"As suggested by Friesen & Domingos for sum-product functions (2016), inference tasks can be captured through semiring operations.",2. Tractable Inference via Compilation,[0],[0]
"To this point, recall that a commutative semiring is a tuple (R,⊕,⊗,⊥,>) such that R is a set including the elements ⊥ and >, ⊕ is a associative and commutative binary operation on R with identity element ⊥, ⊗ is an associative binary operation on R with identity element > and absorbing element ⊥, and the operator ⊗ left and right distributes over the operator ⊕.
Inference tasks on an NNF circuit C are defined using a commutative semiring Q = (R,⊕,⊗,⊥,>) and an input vector w ∈ Rd.",2. Tractable Inference via Compilation,[0],[0]
"The output of a node c in C for Q given w is denoted Q(c |w), and recursively defined by
Q(c |w) =  w(i) if c is the literal xi, > if c is the constant 1, ⊥ if c is the constant 0, Q(cl |w)⊕Q(cr |w) if c is a node ∨, and Q(cl |w)⊗Q(cr |w) if c is a node ∧
By Q(C |w), we denote the output of the root of C for Q givenw.",2. Tractable Inference via Compilation,[0],[0]
"Of particular interest in this study are the semirings described in Table 1; maxmin, minsum, and sumprod, and used to capture the inference tasks of model checking, linear optimization, and model sampling, respectively.",2. Tractable Inference via Compilation,[0],[0]
"Given an NNF circuit C over X , the task of model checking is to decide whether a Boolean input s ∈ {0, 1}d is true in C according to the propositional semantics of nodes.",2.1. Model Checking,[0],[0]
"Obviously, s is a model of C iff maxmin(C | s) = 1, which can be determined in O(|C|) time.",2.1. Model Checking,[0],[0]
"An NNF circuit C is called a representation of a set of feasible solutions S ⊆ {0, 1}d if sol(C) = S, where sol(C) is the set of models of C.
Apart from model checking, virtually all inference tasks in NNF circuits are NP-hard.",2.1. Model Checking,[0],[0]
"Indeed, the NNF language covers the class of SAT formulas.",2.1. Model Checking,[0],[0]
"So, we need to refine this class in order to get tractable forms of optimization and sampling.",2.1. Model Checking,[0],[0]
"A Boolean circuit C is decomposable if for every and-node c of C, we have att(cl) ∩ att(cr) = ∅.",2.2. Decomposability and Optimization,[0],[0]
The class of decomposable NNF circuits is denoted DNNF.,2.2. Decomposability and Optimization,[0],[0]
"For such circuits, which are similar to Boolean sum-product networks (Poon & Domingos, 2011), we can get an efficient implementation of the linear optimization oracle.
",2.2. Decomposability and Optimization,[0],[0]
Proposition 1.,2.2. Decomposability and Optimization,[0],[0]
"Let S ⊆ {0, 1}d be a (nonempty) decision set represented by a DNNF circuit C, and let w ∈ Rd be a modular objective.",2.2. Decomposability and Optimization,[0],[0]
"Then, finding a minimizer of w in S can be done in O(|C|) time.
",2.2. Decomposability and Optimization,[0],[0]
Proof.,2.2. Decomposability and Optimization,[0],[0]
"Based on the minsum semiring, we have
min s∈S 〈w, s〉 = min s∈sol(C) 〈w, s〉 = minsum(C |w)
",2.2. Decomposability and Optimization,[0],[0]
This observation suggests a two-pass weight pushing method for finding a minimizer s of w in S in O(|C|) time.,2.2. Decomposability and Optimization,[0],[0]
"Given a topological ordering of C, the first pass stores the value Q(c |w) of each node c ∈ C, using Q = minsum.",2.2. Decomposability and Optimization,[0],[0]
"The second pass performs a top-down search over C, by selecting all children of a visited and-node, and by selecting exactly one child c′ ∈ {cl, cr} of a visited or-node c such that Q(c′ | w) = Q(c | w).",2.2. Decomposability and Optimization,[0],[0]
"Let T be the corresponding search tree, and let s ∈ {0, 1}d be the indicator vector of the set of literals occurring in T .",2.2. Decomposability and Optimization,[0],[0]
"By construction, we have Q(T |w) = Q(C |w), which implies that s is a minimizer ofw.",2.2. Decomposability and Optimization,[0],[0]
"Since S is not empty, we know that Q(C |w) <",2.2. Decomposability and Optimization,[0],[0]
"+∞. This, together with the fact",2.2. Decomposability and Optimization,[0],[0]
that minmax(T,2.2. Decomposability and Optimization,[0],[0]
| s) = 1,2.2. Decomposability and Optimization,[0],[0]
"whenever Q(T |w) < +∞, implies that s ∈ S.",2.2. Decomposability and Optimization,[0],[0]
"As the problem of counting the number of models in a DNNF circuit is #P-hard (Darwiche & Marquis, 2002), we need to refine this class in order to get an efficient implementation of the sampling oracle.",2.3. Determinism and Sampling,[0],[0]
"To this end, an NNF circuit C is called deterministic if minmax(cl | s) +",2.3. Determinism and Sampling,[0],[0]
minmax(cr | s) ≤ 1 for every or-node c ∈ C and every feasible solution s.,2.3. Determinism and Sampling,[0],[0]
"The class of deterministic DNNF circuits is denoted dDNNF.
",2.3. Determinism and Sampling,[0],[0]
Proposition 2.,2.3. Determinism and Sampling,[0],[0]
"Let S ⊆ {0, 1}d be a decision set represented by a dDNNF circuit C, and for a vector w ∈ Rd, let Pw be the exponential family on S given by:
Pw(s) = exp〈w, s〉∑
s′∈S exp〈w, s′〉
Then, sampling s ∼ Pw can be done in O(|C|) time.
",2.3. Determinism and Sampling,[0],[0]
Proof.,2.3. Determinism and Sampling,[0],[0]
"Based on the sumprod semiring, we have
Pw(s) = exp〈w, s〉∑
s′∈sol(C) exp〈w, s′〉 =
exp〈w, s〉 sumprod(C |w′)
wherew′",2.3. Determinism and Sampling,[0],[0]
"= (ew(1), · · · , ew(d)).",2.3. Determinism and Sampling,[0],[0]
"Again, such an equivalence suggests a two-pass weight pushing method for sampling a solution s according to Pw in O(|C|) time.",2.3. Determinism and Sampling,[0],[0]
"Using a topological ordering of C, the first pass stores the values Q(c |w′), where Q = sumprod.",2.3. Determinism and Sampling,[0],[0]
"The second pass performs a top-down randomized search over C, by selecting all children of a visited and-node, and by drawing at random one of the children of a visited or-node c according to the distribution p(cl) =",2.3. Determinism and Sampling,[0],[0]
Q(cl | w′)/Q(c | w′) and p(cr),2.3. Determinism and Sampling,[0],[0]
= 1− p(cl).,2.3. Determinism and Sampling,[0],[0]
"Let T be the tree of visited nodes, and s be the indicator vector of the literals in T .",2.3. Determinism and Sampling,[0],[0]
"Since S 6= ∅, we must have Q(C |w) > 0.",2.3. Determinism and Sampling,[0],[0]
"Thus, each Bernoulli test performed in T is valid, and hence, s ∈ S .",2.3. Determinism and Sampling,[0],[0]
"For any literal xi occurring in T , let p(xi) denote the probability of the (unique) path connecting the root to xi.",2.3. Determinism and Sampling,[0],[0]
"By a telescoping product of Bernoulli distributions, we get that p(xi) = ew(i)/Q(C |w′).",2.3. Determinism and Sampling,[0],[0]
"Therefore, p(s) = ∏",2.3. Determinism and Sampling,[0],[0]
"i:s(i)=1 p(xi) = Pw(s), as desired.
",2.3. Determinism and Sampling,[0],[0]
We close this section by highlighting some interesting subclasses of dDNNF.,2.3. Determinism and Sampling,[0],[0]
"A decision node is an or-node of the form (xi ∧ c′l) ∨ (xi ∧ c′r), where xi and xi are opposite literals, and c′l and c ′",2.3. Determinism and Sampling,[0],[0]
r are arbitrary nodes.,2.3. Determinism and Sampling,[0],[0]
"The class of Free Binary Decision Diagrams (FBDD) is the subset of dDNNF in which every or-node is a decision node, and at least one child of any and-node is a literal (Wegener, 2000).",2.3. Determinism and Sampling,[0],[0]
"For example, if in the dDNNF circuit of Figure 1, we replace the or-node (in blue) by a simple literal, say x3, then we get an FBDD circuit.",2.3. Determinism and Sampling,[0],[0]
The family of Ordered Binary Decision Diagrams (OBDD) is the subclass of FBDD obtained by imposing a fixed ordering on the decision variables.,2.3. Determinism and Sampling,[0],[0]
"Alternatively, the well-known family of (Binary) Decision Trees (DT) is the subclass of FBDD circuits for which the primal graph is cycle-free.",2.3. Determinism and Sampling,[0],[0]
"Since all these classes are (strict) subsets of dDNNF, they admit linear-time algorithms for linear optimization and model sampling.",2.3. Determinism and Sampling,[0],[0]
"After an excursion into compilation languages, we are now ready to provide efficient characterizations of combinatorial prediction strategies.",3. Tractable Prediction via Compilation,[0],[0]
"Our results are summarized in Table 2.
",3. Tractable Prediction via Compilation,[0],[0]
"Notably, using the fact that ‖s‖1 = d/2, the regret bounds for EH and FPL can easily be derived from (Audibert et al., 2011) and (Hutter & Poland, 2005), respectively.",3. Tractable Prediction via Compilation,[0],[0]
Both strategies are straightforward to implement on dDNNF circuits.,3. Tractable Prediction via Compilation,[0],[0]
"Indeed, recall that EH draws, at each trial t, a feasible solution st ∈ S at random according to the distribution P−ηLt , where Lt = `1 + · · ·+ `t−1.",3. Tractable Prediction via Compilation,[0],[0]
"So, by direct application of Proposition 2, this strategy runs in O(|C|) time per round, using a dDNNF representation C of the decision set S. For the FPL strategy, each round t is performed by choosing a minimizer st ∈ S of the objective function ηLt − zt, where zt ∈ Rd is a perturbation vector whose components are independent exponentially distributed random variables.",3. Tractable Prediction via Compilation,[0],[0]
"By Proposition 1, the FPL strategy also runs inO(|C|) time per round, using a dDNNF encoding C of S, and the fact that |C| is in Ω(d).
",3. Tractable Prediction via Compilation,[0],[0]
"However, the OSMD strategy and its specializations, SGD and CH, require more attention, due to the projectiondecomposition step involved at each iteration.",3. Tractable Prediction via Compilation,[0],[0]
"The overall idea of Online Mirror Descent (OMD) is to “follow the regularized leader” through a primal-dual approach (Nemirovski & Yudin, 1983; Beck & Teboulle, 2003).",3.1. Online Stochastic Mirror Descent,[0],[0]
"Let K be a convex set, and let int(K) denotes its interior.",3.1. Online Stochastic Mirror Descent,[0],[0]
"Given a regularization function F defined on K, OMD iteratively performs a gradient descent in the interior of the dual space K∗, and projects back the dual point into the primal space K.",3.1. Online Stochastic Mirror Descent,[0],[0]
"The connection between K and K∗ is ensured using the gradients ∇F and ∇F ∗, where F ∗ is the convex conjugate of F , defined on K∗.",3.1. Online Stochastic Mirror Descent,[0],[0]
"The projection step is captured by the Bregman divergence of F , which is a function BF : K × int(K)→ R given by:
BF (p, q) = F (p)− F (q)− 〈∇F (q),p− q〉
In the stochastic variant of OMD, introduced by Audibert et.",3.1. Online Stochastic Mirror Descent,[0],[0]
"al. (2011; 2014), and specified in Algorithm 1, each projection is performed onto the subset conv(S) of K, and the resulting point pt is decomposed into a convex combination of feasible solutions in S, from which one is picked at random for the prediction task.
",3.1. Online Stochastic Mirror Descent,[0],[0]
"Algorithm 1 OSMD
Input: decision set S ⊆ {0, 1}d, horizon T ∈ Z+ Parameters: regularizer F on K ⊇ conv(S), step-size η ∈ (0, 1]
set u1 = 0 for t",3.1. Online Stochastic Mirror Descent,[0],[0]
"= 1 to T do
set pt ∈ Argminp∈conv(S)BF (p,∇F ∗(ut))",3.1. Online Stochastic Mirror Descent,[0],[0]
"play st ∼ pt and observe `t set ut+1 = ∇F (pt)− η`t
end for
For common regularizers, the gradient∇F (pt) and its dual ∇F ∗(ut) are easily calculable, and we shall assume that the time spent for their construction is negligible compared with the running time of the linear optimization oracle.",3.1. Online Stochastic Mirror Descent,[0],[0]
"In fact, the computational bottleneck of OSMD is to find a minimizer pt of BF (p,∇F ∗(ut)) in the convex hull of S, and to decompose pt into a convex combination of solutions in S. Fortunately, under reasonable assumptions about the curvature of BF , this projection-decomposition step can be efficiently computed, using recent results in projection-free convex optimization algorithms.
",3.1. Online Stochastic Mirror Descent,[0],[0]
"To this end, we need additional definitions.",3.1. Online Stochastic Mirror Descent,[0],[0]
"For a convex set K, a differentiable function f : K → R is called α-strongly convex with respect to a norm ‖ · ‖ if
f(p′)− f(p) ≥ 〈∇f(p),p′ − p〉+ α 2 ‖p′",3.1. Online Stochastic Mirror Descent,[0],[0]
"− p‖2
",3.1. Online Stochastic Mirror Descent,[0],[0]
"Furthermore, f is called β-smooth1 with respect to ‖ · ‖ if
f(p′)− f(p) ≤",3.1. Online Stochastic Mirror Descent,[0],[0]
"〈∇f(p),p′ − p〉+ β 2 ‖p′",3.1. Online Stochastic Mirror Descent,[0],[0]
"− p‖2
Based on these notions, we say that a Bregman divergence BF has the condition number β/α if BF is both α-strongly convex and β-smooth with respect to the Euclidean norm ‖ · ‖2 in its first argument.",3.1. Online Stochastic Mirror Descent,[0],[0]
"For such regularizers, the next result states that the projection-decomposition step can be approximated in low polynomial time, by exploiting the Pairwise Conditional Gradient (PCG) method, a variant of the Frank-Wolfe convex optimization algorithm, whose convergence rate has been analyzed in (Lacoste-Julien & Jaggi, 2015; Garber & Meshi, 2016; Bashiri & Zhang, 2017).
",3.1. Online Stochastic Mirror Descent,[0],[0]
Lemma 1.,3.1. Online Stochastic Mirror Descent,[0],[0]
"Let S ⊆ {0, 1}d be a decision set represented by a dDNNF circuit C, and F be a regularizer onK ⊇ conv(S) such that BF has condition number β/α.",3.1. Online Stochastic Mirror Descent,[0],[0]
"Then, for any q ∈ int(K) and ∈ (0, 1), one can find inO(βαd
2|C|ln βd ) time a convex decomposition of p ∈ conv(S) such that
BF (p, q)− min p′∈conv(C) BF (p ′, q) ≤
1This notion of geometric smoothness should not be confused with the structural smoothness of NNF circuits in Section 2.
",3.1. Online Stochastic Mirror Descent,[0],[0]
"Algorithm 2 PCG
Input: S ⊆ {0, 1}d, f : K → R, m ∈ Z+",3.1. Online Stochastic Mirror Descent,[0],[0]
"Parameters: step-sizes {ηj}mj=1
let p1 be some point in S for j",3.1. Online Stochastic Mirror Descent,[0],[0]
"= 1 to m do
let ∑j i=1",3.1. Online Stochastic Mirror Descent,[0],[0]
"αisi be the convex decomposition of pj set s+j ∈ Argminp∈conv(S)〈∇f(pj),p〉 set s−j ∈ Argmins∈{s1,···,sj}〈−∇f(pj), s〉 set pj+1 = pj +",3.1. Online Stochastic Mirror Descent,[0],[0]
"ηj(s+j − s − j )
end for
Proof.",3.1. Online Stochastic Mirror Descent,[0],[0]
"Observe that conv(S) is a simplex-like polytope (Bashiri & Zhang, 2017), defined by the linear constraints p ≥ 0, ∑N i=1",3.1. Online Stochastic Mirror Descent,[0],[0]
"αisi = p, α ≥ 0, and ∑N i=1",3.1. Online Stochastic Mirror Descent,[0],[0]
"αi = 1, where N = |S|.",3.1. Online Stochastic Mirror Descent,[0],[0]
"So, conv(S) and BF satisfy the conditions of Theorem 1 in (Garber & Meshi, 2016), and using the step-sizes advocated by the authors, we get that
BF (pm, q)−BF (p∗, q) ≤ βd
2 exp
( − α
8βd2 m ) where pm is the point obtained at the last iteration of PCG, and p∗ is the (unique) minimizer of BF (p, q) on conv(S).",3.1. Online Stochastic Mirror Descent,[0],[0]
"Therefore, after m ≥ (8d2β/α) ln(βd/(2 )) iterations, we haveBF (pm, q)−BF (p∗, q) ≤ .",3.1. Online Stochastic Mirror Descent,[0],[0]
"Finally, since each iteration of PCG makes one call to the linear optimization oracle, the runtime complexity follows from Proposition 1.
",3.1. Online Stochastic Mirror Descent,[0],[0]
"By OSMD+PCG, we denote the refined version of the OSMD algorithm that uses the PCG method at each trial t in order to approximate the Bregman projection-decomposition step.",3.1. Online Stochastic Mirror Descent,[0],[0]
"In addition to a regularizer F and a step-size η, OSMD+PCG takes as parameters a sequence { t}Tt=1 such that
BF (pt, qt)−BF (p∗t , qt) ≤ t
where pt is the point returned by PCG, qt = ∇F ∗(ut), and p∗t is the minimizer of BF (p, qt) over conv(S).
",3.1. Online Stochastic Mirror Descent,[0],[0]
Theorem 1.,3.1. Online Stochastic Mirror Descent,[0],[0]
"Suppose that OSMD+PCG takes as input a dDNNF representation C of a decision set S ⊆ {0, 1}d, and a horizon T , and uses a regularizer F on K ⊇ conv(S) such thatBF has condition number β/α, together with a stepsize η ∈ (0, 1] and a sequence of { t}Tt=1 such that t = γ/t2 for γ > 0.",3.1. Online Stochastic Mirror Descent,[0],[0]
"Then, OSMD+PCG attains the expected regret
(1) RT ≤
√ 2γd
α (lnT + 1) +
1 η max s∈S BF (s,p ∗ 1)
+ 1
η T∑ t=1 BF∗(∇F (p∗t )− η`t,∇F (pt))
with a per-round running time in O ( β
α d2|C|ln βdT γ
) .
",3.1. Online Stochastic Mirror Descent,[0],[0]
Proof.,3.1. Online Stochastic Mirror Descent,[0],[0]
Let s∗ ∈ S be the optimal solution chosen with the benefit of hindsight.,3.1. Online Stochastic Mirror Descent,[0],[0]
"By decomposing the regret, we have
RT = T∑ t=1 〈`t,p∗t − s∗〉+ T∑ t=1",3.1. Online Stochastic Mirror Descent,[0],[0]
"E〈`t, st − p∗t 〉 (2)
",3.1. Online Stochastic Mirror Descent,[0],[0]
"By Theorem 2 in (Audibert et al., 2014), the first term in (2) is bounded by the last two terms in (1).",3.1. Online Stochastic Mirror Descent,[0],[0]
"For the second term in (2), we get from the Cauchy-Schwarz inequality that
E〈`t, st − p∗t 〉 ≤ ‖`t‖2‖pt − p∗t ‖2≤",3.1. Online Stochastic Mirror Descent,[0],[0]
"√ d‖pt − p∗t ‖2
Moreover, by applying the Generalized Pythagorean Theorem (Cesa-Bianchi & Lugosi, 2006), we know that BF (p, qt) ≥ BF (p,p∗t ) + BF (p∗t , qt), for any p ∈ conv(S).",3.1. Online Stochastic Mirror Descent,[0],[0]
"Using p = pt and rearranging,
BF (pt,p ∗ t ) ≤ BF (pt, qt)−BF (p∗t , qt) ≤ t (3)
Since BF is α-strongly convex with respect to ‖ · ‖2 in its first argument, we also have α2 ‖pt",3.1. Online Stochastic Mirror Descent,[0],[0]
"− p ∗ t ‖22≤ BF (pt,p∗t ).",3.1. Online Stochastic Mirror Descent,[0],[0]
"Thus by plugging this inequality into (3), we get that E〈`t, st − p∗t 〉 ≤ √ 2d t/α.",3.1. Online Stochastic Mirror Descent,[0],[0]
"Finally, by substituting t with ρ/t2, summing other T , and applying the logarithmic bound on harmonic series, we obtain the desired result.",3.1. Online Stochastic Mirror Descent,[0],[0]
The (online) SGD algorithm is derived from OSMD using the Euclidean regularizer F (p) = 12 ‖p‖ 2 2.,3.2. Stochastic Gradient Descent,[0],[0]
"In this simple framework, the primal and dual spaces coincide with Rd, and hence, F ∗(u) = u, ∇F (p) = p, and ∇F ∗(u) =",3.2. Stochastic Gradient Descent,[0],[0]
"u. Furthermore, BF has the condition number 1/1, since BF (p, q) = 1 2 ‖p− q‖ 2 2.",3.2. Stochastic Gradient Descent,[0],[0]
"We denote by SGD+PCG the instance of OSMD+PCG defined on the Euclidean regularizer.
",3.2. Stochastic Gradient Descent,[0],[0]
Proposition 3.,3.2. Stochastic Gradient Descent,[0],[0]
"The SGD+PCG algorithm achieves an expected regret bounded by d( √ T + lnT + 1) with a per-round runtime complexity in O(d2|C|ln(dT )) using η = 1/ √ T and γ = d/2.
Proof.",3.2. Stochastic Gradient Descent,[0],[0]
"This simply follows from Theorem 1, together with the fact that maxs∈S BF (s,p∗1) ≤",3.2. Stochastic Gradient Descent,[0],[0]
d and ‖`t‖22≤ d.,3.2. Stochastic Gradient Descent,[0],[0]
The CH algorithm is derived from OSMD using the entropic regularizer F (p) = ∑d i=1,3.3. Component Hedge,[0],[0]
"p(i)(ln p(i)− 1), for which the
conjugate is F ∗(u) = ∑d i=1",3.3. Component Hedge,[0],[0]
expu(i).,3.3. Component Hedge,[0],[0]
"Here, we cannot find a finite condition number for the associated divergence BF (p, q) = ∑d i=1",3.3. Component Hedge,[0],[0]
p(i),3.3. Component Hedge,[0],[0]
ln p(i) q(i),3.3. Component Hedge,[0],[0]
− (p(i),3.3. Component Hedge,[0],[0]
"− q(i)), since its gradient is unbounded.",3.3. Component Hedge,[0],[0]
"This issue may, however, be circumvented using a simple trick advocated in (Krichene et al., 2015), which consists in replacing the entropic regularizer with the function Fδ(p) = F (p + δ), where
δ ∈ (0, 1) and δ = (δ, · · · , δ).",3.3. Component Hedge,[0],[0]
"For this function, the primal space is (−δ,+∞), and since F ∗δ (u) = F ∗(u) − 〈u, δ〉, the dual space is Rd.",3.3. Component Hedge,[0],[0]
"It is easy to show that
∂Fδ(p)
∂p(i) = ln(p(i)",3.3. Component Hedge,[0],[0]
"+ δ)
∂F ∗δ",3.3. Component Hedge,[0],[0]
"(u)
∂u(i) = eu(i)",3.3. Component Hedge,[0],[0]
"− δ
BFδ(p, q) = BF (p+δ, q+δ) B ∗",3.3. Component Hedge,[0],[0]
"Fδ (u,v) =",3.3. Component Hedge,[0],[0]
"B∗F (u,v)
where B∗F (u,v) = ∑d i=1",3.3. Component Hedge,[0],[0]
"e
v(i)(ev(i)−u(i) +v(i)−u(i)−1).",3.3. Component Hedge,[0],[0]
"Furthermore, since the first and second order partial derivatives of B∗Fδ(p, q) at the coordinate p(i) are
∂BFδ(p, q)
∂p(i) =",3.3. Component Hedge,[0],[0]
"ln
p(i)",3.3. Component Hedge,[0],[0]
"+ δ
q(i) + δ
∂2BFδ(p, q)
∂2p(i)",3.3. Component Hedge,[0],[0]
"= ln
1
p(i)",3.3. Component Hedge,[0],[0]
"+ δ
it follows that BFδ has the condition number 1+δ/δ.",3.3. Component Hedge,[0],[0]
"Indeed, given an arbitrary point q ∈ int(−δ,+∞), let Hq(p) denote the the Hessian matrix of BFδ(p, q) at p ∈ conv(S).",3.3. Component Hedge,[0],[0]
"Then, for any z ∈ Rd, the diagonal entries of Hq(p) satisfy
1 1 + δ ≤ ∂
2BF (p, q)
∂2p(i) z(i)2 ≤ 1 δ
using the fact that p(i) ∈",3.3. Component Hedge,[0],[0]
"[0, 1].",3.3. Component Hedge,[0],[0]
"Thus, αI 4 Hq(p) 4 βI for α = 1/1+δ and β = 1/δ.",3.3. Component Hedge,[0],[0]
"In what follows, the instance of OSMD+PCG that uses Fδ as regularizer is called δ-CH+PCG.
Proposition 4.",3.3. Component Hedge,[0],[0]
"The δ-CH+PCG algorithm achieves an expected regret bounded by d(1 + 2δ)( √ T + lnT + 1)
with a per-round runtime complexity in O ( d2|C|/δ ln dT/δ ) using η = 1/√T and γ = 2d(1/2 + δ)/(1 + δ).
",3.3. Component Hedge,[0],[0]
Proof.,3.3. Component Hedge,[0],[0]
The runtime complexity simply follows from Theorem 1.,3.3. Component Hedge,[0],[0]
"The regret bound is obtained by bounding the second and third terms of (1), and using the above values for η and γ.",3.3. Component Hedge,[0],[0]
"Using s∗1 as a maximizer of the second term of (1), we have BFδ(s ∗ 1,p ∗ 1) = Fδ(s ∗ 1)",3.3. Component Hedge,[0],[0]
− Fδ(p∗1).,3.3. Component Hedge,[0],[0]
"Using the notation p̃1 = p∗1 + δ and r = d(1/2 + δ), we get that
Fδ(s ∗ 1)− Fδ(p∗1) ≤ d∑ i=1",3.3. Component Hedge,[0],[0]
p̃1(i),3.3. Component Hedge,[0],[0]
ln 1 p̃1(i) ≤,3.3. Component Hedge,[0],[0]
"r ln d r
which is bounded by r.",3.3. Component Hedge,[0],[0]
"For the third term of (1), observe that Fδ is 1(1+δ)d -strongly convex with respect to the norm ‖ · ‖1, since ‖p",3.3. Component Hedge,[0],[0]
− p′‖21≤ d‖p,3.3. Component Hedge,[0],[0]
− p′‖22.,3.3. Component Hedge,[0],[0]
"By Theorem 3 in (Kakade et al., 2012), it follows that F ∗δ is (1 + δ)d-smooth with respect to the norm ‖ · ‖∞.",3.3. Component Hedge,[0],[0]
"Therefore,
1 η BF∗(∇F (p∗t )− η`t,∇F (pt)) ≤",3.3. Component Hedge,[0],[0]
η 2,3.3. Component Hedge,[0],[0]
d(1,3.3. Component Hedge,[0],[0]
"+ δ)‖`t‖2∞
",3.3. Component Hedge,[0],[0]
which is bounded by ηr.,3.3. Component Hedge,[0],[0]
"In order to evaluate the performance of the different online combinatorial optimization strategies examined in Section 3, we have considered 16 instances of the SAT Library,2 described in Table 3.",4. Experiments,[0],[0]
"Namely, the first six rows of the table are (car) configuration tasks, while the remaining rows are planning problems.",4. Experiments,[0],[0]
"In the first four columns of the table are reported the name of the SAT instance, the number of attributes (d/2), the number of constraints (|SAT|), and the number |S| of feasible solutions.",4. Experiments,[0],[0]
"We have used the recent D4 compiler 3 (Lagniez & Marquis, 2017) for transforming SAT instances into dDNNF circuits.",4. Experiments,[0],[0]
"The size |C| of the compiled circuit is reported in the fifth column.
",4. Experiments,[0],[0]
"In order to simulate combinatorial prediction games, we have used the following protocol.",4. Experiments,[0],[0]
"Suppose that the set X = {x1, · · · , xd} of literals is sorted in a lexicographic way, so that for each odd integer i, the pair (xi, xi+1) encodes both configurations of the same binary attribute.",4. Experiments,[0],[0]
"First, we construct a vector µ0 of d/2 independent Bernoulli variables.",4. Experiments,[0],[0]
"At each round t ∈ {1, · · · , T}, µt is set to µt−1 with probability 0.9, or picked uniformly at random from [0, 1]d/2 with probability 0.1.",4. Experiments,[0],[0]
"Then, the feedback supplied to the learner is a vector `t ∈ {0, 1}d such that `t(i) + `t(i + 1) = 1, and `t(i) = 1 with probability µt(i+1/2) for each odd integer i.",4. Experiments,[0],[0]
"So, `t(i + 1) = 1 with probability 1 − µt(i+1/2).",4. Experiments,[0],[0]
"Although this protocol is essentially stochastic, the environment secretly resets µt with probability 0.1 at each round to foil the learner.
",4. Experiments,[0],[0]
"The combinatorial prediction strategies were implemented in C++ and tested on a six-core Intel i7-5930K with 32 GiB RAM.4 For the FPL and EH algorithms, we used the step-size η reported in (Audibert et al., 2011) and (Hutter & Poland, 2005), respectively.",4. Experiments,[0],[0]
"Concerning the SGD+PCG and δ-CH+PCG algorithms, we used for η and γ the values determined by our theoretical analysis; the step-sizes {ηt} of PCG were computed from binary search as advocated by Garber & Meshi (2016) in their experiments, and the value of δ was fixed to 1/ln d",4. Experiments,[0],[0]
in order to keep a quadratic runtime complexity for δ-CH+PCG.,4. Experiments,[0],[0]
"Finally, the horizon T was set to 103, and a timeout of one day was fixed for learning.
",4. Experiments,[0],[0]
"In our experiments, the regret is measured by the difference in cumulative loss between the algorithm and the best feasible solution in hindsight, which is obtained using the linear optimization oracle at horizon T .",4. Experiments,[0],[0]
"This measure is averaged on 10 simulations, and divided by T to yield an average empirical regret.",4. Experiments,[0],[0]
"Similarly, the per-round runtimes (in seconds) are averaged on 10 simulations.",4. Experiments,[0],[0]
"The corresponding results are reported in the last four columns of Table 3.
2www.cs.ubc.ca/˜hoos/SATLIB/ 3www.cril.univ-artois.fr/KC/d4.html 4www.github.com/frederic-koriche/ccpg.git
Here, the symbol “−” indicates that the learner was not able to perform the T rounds in one day.",4. Experiments,[0],[0]
"From the viewpoint of regret, SGD+PCG and δ-CH+PCG outperform EH and FPL, which confirms our theoretical results.",4. Experiments,[0],[0]
We mention in passing that SGD+PCG and δ-CH+PCG are remarkably stable.,4. Experiments,[0],[0]
"Contrastingly, FPL exhibits a larger variance.
",4. Experiments,[0],[0]
"Concerning runtimes, EH and FPL are unsurprisingly faster than SGD+PCG and δ-CH+PCG.",4. Experiments,[0],[0]
"Notably, for the hard-to-compile instances c140-fc and c163-fw, both EH and FPL were able to perform each trial in few tens of seconds, while OSMD+PCG algorithms took several minutes per-round (and hence, they were unable to process 103 rounds in one day), due to the time spent in approximating the Bregman projection step.",4. Experiments,[0],[0]
"Yet, it is important to emphasize that the convergence rate of PCG is, in practice, much faster than the theoretical bound of Õ(d2|C|).",4. Experiments,[0],[0]
Both SGD+PCG and δ-CH+PCG were able to process nearly all instances in few seconds per round.,4. Experiments,[0],[0]
"For circuits of moderate size, all algorithms run in less than one second per trial.",4. Experiments,[0],[0]
"We also observed that SGD+PCG is slightly faster than δ-CH+PCG, especially for large domains where small values of δ have a significant impact on the the runtime complexity.",4. Experiments,[0],[0]
"In essence, SGD+PCG offers the best compromise between predictive performance and running time; since all feasible solutions are dense (‖s‖1= d/2), there is no significant difference in accuracy between SGD+PCG and δ-CH+PCG.",4. Experiments,[0],[0]
"We have proposed a general framework for compiling online combinatorial optimization problems, whose space of feasible solutions is described using a set of Boolean constraints.",5. Conclusions,[0],[0]
"Namely, we have focused on the class of dDNNF circuits which is endowed with fast inference algorithms for the linear optimization oracle and the sampling oracle.",5. Conclusions,[0],[0]
"Based on
this framework, we have shown than both EH and FPL admit fast implementation for tackling large scale online combinatorial problems.",5. Conclusions,[0],[0]
"A particular attention was devoted to the generic OSMD strategy, which involves a computationally expensive projection-decomposition step at each iteration.",5. Conclusions,[0],[0]
"To this point, we made use of projection-free algorithms, and in particular the PCG method, for approximating this operation.",5. Conclusions,[0],[0]
"The resulting algorithms, SGD+PCG and δ-CH-PCG, are inevitably slower than EH and FPL, but achieve a better regret performance, as corroborated by our experiments.
",5. Conclusions,[0],[0]
We conclude with a few remarks.,5. Conclusions,[0],[0]
"In light of the current results, a natural perspective of research is to extend our framework to other classes of combinatorial prediction games.",5. Conclusions,[0],[0]
"Notably, the semi-bandit setting seems within reach.",5. Conclusions,[0],[0]
"Indeed, the semi-bandit variant of EH, often referred to as EXP2 (Audibert et al., 2014), uses importance weights for estimating the loss at each iteration.",5. Conclusions,[0],[0]
"By simple adaptation of Proposition 2, such weights can be computed in linear time.",5. Conclusions,[0],[0]
"Similarly, the semi-bandit extension of FPL exploits the geometric sampling method for estimating loss vectors (Neu & Bartók, 2016).",5. Conclusions,[0],[0]
"Again, this iterative method can be implemented in linear time (per iteration) using Proposition 1.",5. Conclusions,[0],[0]
"Less obvious, however, is the extension of OSMD to semi-bandits: although the extension of CH achieves an optimal expected regret in this setting, its practical use remain limited due to projection-decomposition step.",5. Conclusions,[0],[0]
"An interesting open question is to determine whether a combination of CH with PCG is able, in the semi-bandit case, to achieve a quasi-optimal regret in low-polynomial time.",5. Conclusions,[0],[0]
"Of course, the bandit setting is even more challenging.",5. Conclusions,[0],[0]
"To this point, Sakaue et.",5. Conclusions,[0],[0]
"al. (2018) have paved the way using OBDDs for an efficient implementation of the COMBBAND algorithm (Cesa-Bianchi & Lugosi, 2012), Extending their approach to dDNNF, which is more succinct than OBDD, is a promising direction of future research.",5. Conclusions,[0],[0]
"In online optimization, the goal is to iteratively choose solutions from a decision space, so as to minimize the average cost over time.",abstractText,[0],[0]
"As long as this decision space is described by combinatorial constraints, the problem is generally intractable.",abstractText,[0],[0]
"In this paper, we consider the paradigm of compiling the set of combinatorial constraints into a deterministic and Decomposable Negation Normal Form (dDNNF) circuit, for which the tasks of linear optimization and solution sampling take linear time.",abstractText,[0],[0]
"Based on this framework, we provide efficient characterizations of existing combinatorial prediction strategies, with a particular attention to mirror descent techniques.",abstractText,[0],[0]
These strategies are compared on several real-world benchmarks for which the set of Boolean constraints is preliminarily compiled into a dDNNF circuit.,abstractText,[0],[0]
Compiling Combinatorial Prediction Games,title,[0],[0]
"Researchers have demonstrated impressive successes in building agents that can achieve excellent performance in difficult tasks, e.g. (Mnih et al., 2015; Silver et al., 2016).",1. Introduction,[0],[0]
"However, these successes have mostly been confined to situations where it is possible to train a large number of times on a single known task.",1. Introduction,[0],[0]
"On the other hand, in some situations, the tasks of interest are not known at training time or the space of tasks is so large that an agent will not realistically be able to train many times on any single task in the space.
",1. Introduction,[0],[0]
"We might hope that the tasks of interest are compositional: for example, cracking an egg is the same whether one is
*Equal contribution 1Facebook AI Research, New York, NY, USA 2New York University, New York, NY, USA.",1. Introduction,[0],[0]
"Correspondence to: Adam Lerer <alerer@fb.com>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
making pancakes or an omelette.",1. Introduction,[0],[0]
"If the space of tasks we want an agent to be able to solve has compositional structure, then a state abstraction that exposes this structure could be used both to specify instructions to the agent, and to plan through sub-tasks that allow the agent to complete its instructions.
",1. Introduction,[0],[0]
In this work we show how to train agents that can solve complex tasks by planning over a sequence of previously experienced simpler ones.,1. Introduction,[0],[0]
"The training protocol relies on a state abstraction that is manually specified, consisting of a set of binary attributes designed to capture properties of the environment we consider important.",1. Introduction,[0],[0]
"These attributes, learned at train time from a set of (state, attribute) pairs, provide a natural way to specify tasks, and a natural state abstraction for planning.",1. Introduction,[0],[0]
"Once the agent learns how its actions affect the environment in terms of the attribute representation, novel tasks can be solved compositionally by executing a plan consisting of a sequence of transitions between abstract states defined by those attributes.",1. Introduction,[0],[0]
"Thus, as in (Dayan & Hinton, 1992; Dietterich, 2000; Vezhnevets et al., 2017), temporal abstractions are explicitly linked with state abstractions.
",1. Introduction,[0],[0]
"Our approach is thus a form of model-based planning, where the agent first learns a model of its environment (the mapping from states to attributes, and the attribute transition graph), and then later uses that model for planning.",1. Introduction,[0],[0]
"There is no supervision or reward given for completing the tasks of interest; outside of the (state, attribute) pairs, the agent receives no other reward or extrinsic supervision.",1. Introduction,[0],[0]
"In the experiments below, we will show empirically that this kind of approach can be useful on problems that can be challenging for standard reinforcement learning.
",1. Introduction,[0],[0]
We evaluate compositional planning in several environments.,1. Introduction,[0],[0]
"We first consider 3D block stacking, and show that we can compose single-action tasks seen during training to perform multi-step tasks.",1. Introduction,[0],[0]
"Second, we plan over multi-step policies in 2-D grid world tasks.",1. Introduction,[0],[0]
"Finally, we see how our approach scales to a unit-building task in StarCraft.
2.",1. Introduction,[0],[0]
The Attribute Planner Model,1. Introduction,[0],[0]
"We consider an agent in a Markov environment, i.e. at each time the agent observes the state s and takes action
a, which uniquely determines the probability P (s, a, s0) of transitioning from s to s0.",1. Introduction,[0],[0]
We augment the environment with a map f : S ! {⇢} from states to a set of userdefined attributes ⇢.,1. Introduction,[0],[0]
"We assume that either f is provided or a small set of hand-labeled (s, ⇢) pairs are provided in order to learning a mapping f̂ .",1. Introduction,[0],[0]
"Hence, the attributes are human defined and constitute a form of supervision.",1. Introduction,[0],[0]
Here we consider attributes that are sets of binary vectors.,1. Introduction,[0],[0]
"These user-specified attributes parameterize the set of goals that can be specified at test time.
",1. Introduction,[0],[0]
"The agent’s objective at test time is, given a set of goal attributes ⇢g , to take a sequence of actions in the environment that end with the agent in a state that maps to ⇢g. During training, the agent constructs a model with three parts:
1.",1. Introduction,[0],[0]
"a neural-net based attribute detector f̂ , which maps states s to a set of attributes ⇢, i.e. ⇢ = f̂(s).
2.",1. Introduction,[0],[0]
"a neural net-based policy ⇡(s, ⇢g) which takes a pair of inputs: the current state s and attributes of an (intermediate) goal state ⇢g , and outputs a distribution over actions.
",1. Introduction,[0],[0]
3.,1. Introduction,[0],[0]
"a transition table c⇡(⇢i, ⇢j) that records the empirical probability that ⇡(s⇢i , ⇢j) can succeed at transiting successfully from ⇢i to ⇢j in a small number of steps.
",1. Introduction,[0],[0]
The transition table c⇡ can be interpreted as a graph where the edge weights are probabilities.,1. Introduction,[0],[0]
"This high-level attribute graph is then searched at test time to find a path to the goal with maximum probability of success, with the policy network performing the low-level actions to transition between adjacent attribute sets.",1. Introduction,[0],[0]
"The first step in training the Attribute Planner is to fit the neural network detector f̂ that maps states s to attributes ⇢, using the labeled states provided.",2.1. Training the Attribute Planner,[0],[0]
"If a hardcoded function f is provided, then this step can be elided.
",2.1. Training the Attribute Planner,[0],[0]
"In the second step, the agent explores its environment using an exploratory policy.",2.1. Training the Attribute Planner,[0],[0]
"Every time an attribute transition (⇢i, ⇢j) is observed, it is recorded in an intermediate transition table c⇡e .",2.1. Training the Attribute Planner,[0],[0]
"This table will be used in later steps to keep track of which transitions are possible.
",2.1. Training the Attribute Planner,[0],[0]
"The most naive exploratory policy takes random actions, but the agent can explore more efficiently if it performs count-based exploration in attribute space.",2.1. Training the Attribute Planner,[0],[0]
"We use a neural network exploration policy that we train via reinforcement learning with a count-based reward1 proportional to c⇡e(⇢i, ⇢j) 0.5 upon every attribute transition (⇢i, ⇢j), where c⇡e(⇢i, ⇢j) is the visit count of this transition during exploration.",2.1. Training the Attribute Planner,[0],[0]
"This bonus is as in (Strehl & Littman, 2008), but with no empirical reward from the environment.",2.1. Training the Attribute Planner,[0],[0]
The precise choice of exploration bonus is discussed in App.,2.1. Training the Attribute Planner,[0],[0]
"A.
",2.1. Training the Attribute Planner,[0],[0]
"Now that we have a graph of possible transitions, we next train the low-level goal-conditional policy ⇡ and the main transition table c⇡ .",2.1. Training the Attribute Planner,[0],[0]
"From state s with attributes ⇢, the model picks an attribute set ⇢g randomly from the neighbors of ⇢ in c⇡e weighted by their visit count in the Explore phase and sets that as the goal for ⇡.",2.1. Training the Attribute Planner,[0],[0]
"Once the goal is achieved or a timeout is reached, the policy is updated and the main transition table c⇡ is updated to reflect the success or failure.",2.1. Training the Attribute Planner,[0],[0]
"⇡ is updated via reinforcement learning, with a reward r of
1Although the reward is non-stationary, we find (as in the literature) that it is empirically effective.
1 if ⇢g was reached and 0 otherwise2.",2.1. Training the Attribute Planner,[0],[0]
"See Algorithm 1 for pseudocode of AP training.
",2.1. Training the Attribute Planner,[0],[0]
"In the case of block stacking (Sec. 4.1), the attribute transitions consist of a single step, so we treat ⇡ as an “inverse model” in the style of (Agrawal et al., 2016; Andrychowicz et al., 2017), and rather than using reinforcement learning, we can train ⇡ in a supervised fashion by taking random actions and training ⇡ to predict the action taken given the initial state and final attributes.
",2.1. Training the Attribute Planner,[0],[0]
"Algorithm 1 Attribute Planner Training Input: Labeled pairs {(si, ⇢i)}, exploratory policy ⇡e, N1, N2, tmax.
//",2.1. Training the Attribute Planner,[0],[0]
"Step 1: Train attribute detector Fit f̂ on {(si, ⇢i)} with supervised learning.
",2.1. Training the Attribute Planner,[0],[0]
"// Step 2: Explore
for t = 1 ...",2.1. Training the Attribute Planner,[0],[0]
N1 do Act according to ⇡e(st 1).,2.1. Training the Attribute Planner,[0],[0]
"Compute attributes ⇢t f̂(st) if ⇢t 6= ⇢t 1 then
Record the transition: c⇡e(⇢t 1, ⇢t) +",2.1. Training the Attribute Planner,[0],[0]
"= 1 Optional: Update ⇡e with count-based reward.
//",2.1. Training the Attribute Planner,[0],[0]
"Step 3: Train policy ⇡ and c⇡ tlast 0, ⇢s ;, ⇢e RandNeighbor(c⇡e , ⇢s) for t = 1 ...",2.1. Training the Attribute Planner,[0],[0]
"N2 do
Compute attributes ⇢t f̂(st)",2.1. Training the Attribute Planner,[0],[0]
"if t = 1 or ⇢t 6= ⇢s or t tlast tmax then
r 1 if ⇢t = ⇢e, otherwise 0.",2.1. Training the Attribute Planner,[0],[0]
"UpdatePolicy(⇡, r) Record attempt: A⇡(⇢t 1, ⇢t) += 1 Record success: S⇡(⇢t 1, ⇢t) += r ⇢s ⇢t, ⇢e RandNeighbor(c⇡e , ⇢s) tlast t
Take an action according to ⇡(st 1, ⇢e)
for (⇢i, ⇢j) 2",2.1. Training the Attribute Planner,[0],[0]
"A⇡ do c⇡(⇢i, ⇢j) S⇡(⇢i, ⇢j)/A⇡(⇢i, ⇢j).",2.1. Training the Attribute Planner,[0],[0]
Once the model has been built we can use it for planning.,2.2. Evaluating the model,[0],[0]
"That is, given an input state s and target set of attributes ⇢T , we find a path [⇢0, ⇢1, ..., ⇢m] on the graph G with ⇢0 = f(s) and ⇢m = ⇢T minimizing Pm 1 i=0 log c⇡(⇢i, ⇢i+1) which maximizes the probability of success of the path (assuming independence).",2.2. Evaluating the model,[0],[0]
"The probability c⇡ is computed in Algorithm 1 as the ratio of observed successes and attempts
2Since c⇡ is collecting statistics about ⇡ which is nonstationary.",2.2. Evaluating the model,[0],[0]
"So c⇡ should really be updated only after a burn-in period of ⇡, or a moving average should be used for the statistics.
during training.
",2.2. Evaluating the model,[0],[0]
"The optimal path can be found using Dijkstra’s algorithm with a distance metric of log(c⇡(⇢i, ⇢i+1)).",2.2. Evaluating the model,[0],[0]
"The policy is then used to move along the resulting path between attribute set, i.e. we take actions according to a = ⇡(s, ⇢1), then once f(s) = ⇢1, we change to a = ⇡(s, ⇢2) and so on.",2.2. Evaluating the model,[0],[0]
"At each intermediate step, if the current attributes don’t match the attributes on the computed path, then a new path is computed using the current attributes as a starting point (or, equivalently, the whole path is recomputed at each step).
",2.2. Evaluating the model,[0],[0]
"Algorithm 2 Attribute Planner Inference Input: Low-level policy ⇡, graph c⇡, attribute detector f̂ , target attributes ⇢T .",2.2. Evaluating the model,[0],[0]
"do
⇢ f̂(s)",2.2. Evaluating the model,[0],[0]
"[⇢0, ..., ⇢m] ShortestPath(c⇡, ⇢, ⇢g) Act according to ⇡(st 1, ⇢1).
",2.2. Evaluating the model,[0],[0]
"while ⇢ 6= ⇢T
2.3.",2.2. Evaluating the model,[0],[0]
"An Aside: Which attributes should we include?
",2.2. Evaluating the model,[0],[0]
"Since we use user-specified attributes for planning, which attributes are important to include?",2.2. Evaluating the model,[0],[0]
"The set of attributes must be able to specify our goals of interest, and should be parsimonious since extra attributes will increase the size of the graph and thus degrade the statistics on each edge/.
On the other hand, the attributes should have a property that we will call “ignorability” which says that the probability of being able to transition from ⇢i to ⇢j should only depend on the attributes ⇢i, not the exact state; i.e. P⇡(f(st0) = ⇢j |f(st))",2.2. Evaluating the model,[0],[0]
=,2.2. Evaluating the model,[0],[0]
P⇡(f(st0) = ⇢j |st) 3.,2.2. Evaluating the model,[0],[0]
"To the extent that this condition is violated, then transitions are aliased, and a planned transition may not be achievable by the policy from the particular state s even though it’s achievable from other states with the same properties, causing the model to fail to achieve its goal.",2.2. Evaluating the model,[0],[0]
"For example, in the block stacking task in 4.1, there will be nontrivial aliasing; we will show that some amount of aliasing is not deadly for our model.",2.2. Evaluating the model,[0],[0]
"Many researchers have recognized the importance of methods that can divide a MDP into subprocesses (Thrun & Schwartz, 1994; Parr & Russell, 1998; Sutton et al., 1999; Dietterich, 2000).",3. Related work,[0],[0]
"Perhaps the most standard formalism today is the options framework of (Sutton et al., 1999), which deals with multistep “macro-actions” in the setting of reinforcement learning.",3. Related work,[0],[0]
"Recent works, like (Kulkarni et al., 2016; Harb et al., 2017), have shown how options can be used (and even discovered in (Harb et al., 2017)) with
3The particular sequence of actions that effects the transition from ⇢i to ⇢j may still be conditional on the state.
function approximation via deep learning.
",3. Related work,[0],[0]
Our work is also a hierarchical approach to controlling an agent in a Markovian environment.,3. Related work,[0],[0]
"However, the paradigm we consider differs from reinforcement learning: we consider a setup where no reward or supervision is provided other than the (s, f(s)) pairs, and show than an agent can learn to decompose a transition between far away ⇢, ⇢0 into a sequence of short transitions.",3. Related work,[0],[0]
"If we were to frame the problem as HRL, considering each ⇡(·, ⇢) as a macro action4, in order for the agent to learn to sequence the ⇡(·, ⇢i), the environment would need to give reward for the completion of complex tasks, not just simple ones.
",3. Related work,[0],[0]
"As in (Sutton et al., 2011; Schaul et al., 2015; Dosovitskiy & Koltun, 2016; Fern et al., 2004), we have policies parameterized by state and target attributes.",3. Related work,[0],[0]
"In (Dosovitskiy & Koltun, 2016), an agent is given supervision of future values of attributes of the state considered important for describing tasks.",3. Related work,[0],[0]
"Unlike in that work, our attributes are functions of the current state, and the model uses its own estimator to learn the dynamics at the level of attributes as a graph.",3. Related work,[0],[0]
"Thus, our model gets no extrinsic supervision of environment dynamics or goal attainment at the level of attributes.",3. Related work,[0],[0]
"Our training of c⇡ and then using cpi for task generation recalls (Fern et al., 2004).",3. Related work,[0],[0]
"In that work, as training progresses, goals are farther and farther away (as measured by the steps of a random walk on attributes); but in our work the goals are always one attribute away.",3. Related work,[0],[0]
"This is because our ⇡ only needs to know how to transition between nearby attribute sets, thanks to the planner.",3. Related work,[0],[0]
"In contrast (Fern et al., 2004) aims to train a reactive policy that can handle long transitions too, obviating the need for a planner.",3. Related work,[0],[0]
"Moreover, (Fern et al., 2004) works entirely in the symbolic space, whereas we interfaces the perceptual space with the symbolic space.",3. Related work,[0],[0]
"In (van Seijen et al., 2017), human provided attributes are used as a general value function (GVF) in Ms. Pacman, showing that using a weighted combination of these can lead to higher scores than standard rewards; but again, in contrast to our work, their goal is a better reactive policy.
",3. Related work,[0],[0]
"Our approach is closely related to factored MDP (Boutilier et al., 1995; 2000; Guestrin et al., 2003b).",3. Related work,[0],[0]
"In these works, it is assumed that the environment can be represented by discrete attributes, and that transitions between the attributes by an action can be modeled as a Bayesian network.",3. Related work,[0],[0]
The value of each attribute after an action is postulated to depend in a known way on attributes from before the action.,3. Related work,[0],[0]
The present work differs from these in that the attributes do not determine the state and the dependency graph is not assumed to be known.,3. Related work,[0],[0]
"More importantly, the focus in this work is on
4All the “macro actions’ in our examples in 4.1 are degenerate in the sense that they return after one step, but we still are able to show generalization to long trajectories from (unsupervised) training only on short ones
organizing the space of tasks through the attributes rather than being able to better plan a specific task; and in particular being able to generalize to new, more complex tasks at test time.
",3. Related work,[0],[0]
"Our approach is also related to Relational MDP and Object Oriented MDP (Hernandez-Gardiol & Kaelbling, 2003; van Otterlo, 2005; Diuk et al., 2008; Abel et al., 2015), where states are described as a set of objects, each of which is an instantiation of canonical classes, and each instantiated object has a set of attributes.",3. Related work,[0],[0]
"Our work is especially related to (Guestrin et al., 2003a), where the aim is to show that by using a relational representation of an MDP, a policy from one domain can generalize to a new domain.",3. Related work,[0],[0]
"However, in the current work, the attributes are taken directly as functions of the state, as opposed to defined for object classes, and we do not have any explicit encoding of how objects interact.",3. Related work,[0],[0]
"The model is given some examples of various attributes, and builds a parameterized model that maps into the attributes.
",3. Related work,[0],[0]
"The Programmable Agents of (Denil et al., 2017) put the notions of objects and attributes (as in relational MDP) into an end-to-end differentiable neural architecture.",3. Related work,[0],[0]
"Their model also learns mappings from states to attributes, and is evaluated on a block manipulation task.",3. Related work,[0],[0]
"In their work, the attributes are used to generalize to different combinations of object properties at test time, while we use it to generalize compositionally to more complex tasks.",3. Related work,[0],[0]
"Also, while our model uses explicit search to reason over attributes, they use an end-to-end neural architecture.
",3. Related work,[0],[0]
There is a large literature on quickly adapting to a new learning problem given a set or a history of related learning problems.,3. Related work,[0],[0]
"Our approach in this work has a similar motivation to (Isele et al., 2016), where tasks are augmented with descriptors and featurized, and the coefficients of the task features in a sparse dictionary are used to weight a set of vectors defining the model for the associated task.",3. Related work,[0],[0]
"Similarly, the task is specified by a feature as an input into a model in (Lopez-Paz & Ranzato, 2017).",3. Related work,[0],[0]
"However, in our work, although the attributes are used to parameterize tasks, rather than directly featurize the tasks, they are features of a state; and we learn the mapping from state to attributes.",3. Related work,[0],[0]
"This allows our agent to learn how to transit between sets of attributes unsupervised, and plan in that space.
",3. Related work,[0],[0]
Several recent deep reinforcement learning works have used modular architectures and hierarchy to achieve generalization to new tasks.,3. Related work,[0],[0]
"For example, (Tessler et al., 2017) uses pre-trained skills for transfer.",3. Related work,[0],[0]
"(Oh et al., 2017) uses a metacontroller that selects parameterized skills and analogical supervision on outer-product structured tasks.",3. Related work,[0],[0]
"However, our “meta-controller” is the search over attributes, rather than a reactive model, which allows explicit planning.",3. Related work,[0],[0]
"Furthermore, although our assignments of attributes serves a similar purpose to their analogical supervision (and outer-
product task structure),the methods are complementary; we can imagine augmenting our attributes with analogical supervision.
",3. Related work,[0],[0]
"In (Andreas et al., 2017), generalization is achieved through supervision in the form of “policy sketches”, which are symbolic representations of the high level steps necessary to complete a given task.",3. Related work,[0],[0]
The low level steps in executing modules in the sketches are composable.,3. Related work,[0],[0]
"Our work is similar in that high level annotation is used to enable generalization, but the mechanism in this work is different.",3. Related work,[0],[0]
"Note that the approaches in (Andreas et al., 2017) is also complementary to the one described here; in future work we wish to explore combining them.
",3. Related work,[0],[0]
In this work we use an explicit memory of sets of attributes the model has seen.,3. Related work,[0],[0]
"Several previous works have used nonparametric memories for lowering the sample complexity of learning, e.g. (Blundell et al., 2016; Pritzel et al., 2017).",3. Related work,[0],[0]
"Like these, we lean on the fact that with a good representation of a state, it can be useful to memorize what to do in given situation (having only done it a small number of times) and explicitly look it up.",3. Related work,[0],[0]
"In our case, the “good representation” is informed by the user-specified attributes.
",3. Related work,[0],[0]
"Our approach is also related to (Machado et al., 2017), which builds up a multiscale representation of an MDP using Eigenvectors of the transition matrix of the MDP, in the sense that we collect data on possible transitions between attributes in a first phase of training, and then use this knowledge at test time.
",3. Related work,[0],[0]
"There is a large literature on using symbolic representations for planning, for example the STRIPS formalism (Fikes & Nilsson, 1971).",3. Related work,[0],[0]
"In (Konidaris et al., 2018), the authors propose a model that learns the symbols for a STRIPS-style representation.",3. Related work,[0],[0]
"Like in our work, their model learns the interface between the raw state observations and the planner.",3. Related work,[0],[0]
"However, in that work, the abstract structure is given by a set of pre-defined options with fixed policies.",3. Related work,[0],[0]
We perform experiments with the Attribute Planner (AP) in three environments.,4. Experiments,[0],[0]
"First, we consider a 3D block stacking environment.",4. Experiments,[0],[0]
"Here, we demonstrate that AP allows compositional generalization by training a low level policy on single-action tasks in a supervised fashion and showing that with the AP algorithm it can perform multi-step tasks at test time.
",4. Experiments,[0],[0]
"Second, we consider 2D grid worlds in Mazebase (Sukhbaatar et al., 2015), where we evaluate AP’s performance when the low-level policy is temporally extended and must be learned via RL.
",4. Experiments,[0],[0]
"Finally, we evaluate AP on a build order planning task in
Starcraft to see how AP scales to a more complex task that is of broader interest We further show that an exploratory policy over attributes allows the agent to explore attribute transitions where random search fails.
",4. Experiments,[0],[0]
Baselines:,4. Experiments,[0],[0]
"In all experiments, we compare against baseline policies trained with reinforcement learning.",4. Experiments,[0],[0]
"These baseline policies take the state and goal as inputs, and use the same neural network architecture as the policy used for the Attribute Planner.",4. Experiments,[0],[0]
We consider several training regimes for the baseline policies: (i) training only with nearby goals like AP; (ii) training on the multi-step evaluation tasks; and (iii) training on a curriculum that transitions from nearby goals to evaluation tasks.,4. Experiments,[0],[0]
"Policies (ii) and (iii) are trained on full sequences, thus have an inherent advantage over our model.
",4. Experiments,[0],[0]
"In the block stacking task, we further compare against a state-of-the-art algorithm for hierarchical RL: Option-Critic with deliberation cost (Harb et al., 2017), as well as an inverse model trained by supervised learning.",4. Experiments,[0],[0]
"We consider a 3D block stacking environment in Mujoco (Todorov et al., 2012).",4.1. Block Stacking,[0],[0]
"In this experiment, we train AP only on single-action trajectories and evaluate on multi-step tasks, in order to evaluate AP’s ability to generalize using planning.",4.1. Block Stacking,[0],[0]
"We compare AP with baselines trained on both single-action, multi-action, and curriculum tasks.
",4.1. Block Stacking,[0],[0]
"In this environment, there are 4 blocks of different colors, and actions consist of dropping a block in a 3 ⇥ 3 grid of positions, resulting in 36 total actions.",4.1. Block Stacking,[0],[0]
"A block cannot be moved when it is underneath another block, so some actions have no effect.
",4.1. Block Stacking,[0],[0]
"The input to the model is the observed image, and there are a total of 36 binary properties corresponding to the relative x and y positions of the blocks and whether blocks are stacked on one another.",4.1. Block Stacking,[0],[0]
"For example, one property corresponds to “blue is on top of yellow”.",4.1. Block Stacking,[0],[0]
"Each training episode is initiated from a random initial state and lasts only one step, i.e. dropping a single block in a new location.",4.1. Block Stacking,[0],[0]
"Further model and training details and results on a continuous variant of this environment are provided in Appendix B.
Table 1 compares the performance of different models on several block stacking tasks.",4.1. Block Stacking,[0],[0]
"In the multi-step task, the goal is chosen as the properties of a new random initialization.",4.1. Block Stacking,[0],[0]
These tasks typically require 3 8 steps to complete.,4.1. Block Stacking,[0],[0]
"In the 4-stack task, the goal is a vertical stack of blocks in the order red, green, blue, yellow.",4.1. Block Stacking,[0],[0]
"In the underspecified task, we consider a multi-step goal where only 70% of the attributes are provided at random.",4.1. Block Stacking,[0],[0]
"The AP model handles these naturally by finding the shorted path to any satisfactory attribute set.
",4.1. Block Stacking,[0],[0]
"The single-step reactive policies perform similarly to AP when evaluated on the single-step tasks it sees during training (see Table 5 in the Appendix), but perform poorly when transferred to multi-step tasks, while AP generalizes well to complex task.",4.1. Block Stacking,[0],[0]
"The AP model also solves underspecified tasks even though they are not seen explicitly during training.
",4.1. Block Stacking,[0],[0]
The attribute detector f̂ predicts the full attribute set with < 0.1% error when trained on the full dataset of 1 million examples.,4.1. Block Stacking,[0],[0]
"If trained on only 10,000 examples, the attribute detector has an error rate of 1.4%.",4.1. Block Stacking,[0],[0]
"Training the AP model with this less-accurate attribute detector degrades multi-step performance by only 0.9%.
",4.1. Block Stacking,[0],[0]
"We also consider a variant of the block stacking task with a continuous action space, in which an action consists of dropping a block at any x-y position.",4.1. Block Stacking,[0],[0]
"While performance degrades substantially for all models in the continuous action space, AP continues to outperform reactive policies on multi-step tasks.",4.1. Block Stacking,[0],[0]
"See Appendix B for the full results.
",4.1. Block Stacking,[0],[0]
Property Aliasing: The “ignorability” assumption we made in Section 2 is violated in the block stacking task.,4.1. Block Stacking,[0],[0]
"To see why, consider a transition from “red left of blue and yellow” to “red right of blue and yellow”.",4.1. Block Stacking,[0],[0]
"This can typically be accomplished in one step, but if blue and yellow are already on the far right, it cannot.",4.1. Block Stacking,[0],[0]
"Thus, states where this transition are possible and impossible are aliased with the same properties.",4.1. Block Stacking,[0],[0]
"Table 2 shows that the performance is nearly perfect for individual transitions (1-step tasks), and the graph is well-connected after 1 million training examples, so the main source of error on these tasks is in fact
aliasing.",4.1. Block Stacking,[0],[0]
"Figure 3 shows an example plan that becomes stuck due to aliasing.
",4.1. Block Stacking,[0],[0]
The transition table c⇡ is important for mitigating the effects of aliasing in the block stacking task.,4.1. Block Stacking,[0],[0]
"The graph search finds the path with the highest probability of success (i.e. the product of probabilities on each edge), so it avoids edges that have high aliasing.",4.1. Block Stacking,[0],[0]
"In Table 1, we consider an ablation of c⇡ from the AP model, in which the probability of transitioning from an edge (⇢i, ⇢j) is estimated as the fraction of transitions from ⇢i that ended in ⇢j during the Explore phase.",4.1. Block Stacking,[0],[0]
This ablation performs substantially worse than the full AP model.,4.1. Block Stacking,[0],[0]
"We next consider tasks in which a multi-step low-level policy is required to transition between neighboring attributes.
",4.2. Grid Worlds,[0],[0]
"We consider two classes of small 2-D environments in Mazebase (Sukhbaatar et al., 2015), where the worlds are randomly generated for each episode.",4.2. Grid Worlds,[0],[0]
"The action space for each consists of movements in the four cardinal directions plus additional environment-specific actions.
",4.2. Grid Worlds,[0],[0]
"Colored Switches The first environment consists of four switches, each with four possible colors.",4.2. Grid Worlds,[0],[0]
An extra toggle action cycles the color of a switch if the agent is standing on it.,4.2. Grid Worlds,[0],[0]
"The attributes for this environment are the states of the switches and the tasks are to change the switches into
a specified configuration, as shown in Fig. 4(right).",4.2. Grid Worlds,[0],[0]
"The locations and colors of the switches are randomly initialized for each episode.
",4.2. Grid Worlds,[0],[0]
"Crafting In the second environment, similar to the one used in (Andreas et al., 2017), an agent needs to collect resources and combine them to form items.",4.2. Grid Worlds,[0],[0]
"In addition to moving in the cardinal directions, the agent has a “grab” action that allows it to pick up a resource from the current location and add it to its inventory.",4.2. Grid Worlds,[0],[0]
The agent also has a “craft” action that combines a set of items to create a new item if the agent has the prerequisite items in its inventory and the agent is standing on a special square (a “crafting table”) corresponding to the item to be crafted.,4.2. Grid Worlds,[0],[0]
"The attributes for this environment are the items in the inventory, and the task is to add a specified (crafted) item to the inventory.",4.2. Grid Worlds,[0],[0]
"In the environment, there are three types of resources and three types of products (see Fig. 4(left)).",4.2. Grid Worlds,[0],[0]
"The game always starts with three resources and an empty inventory.
+ !",4.2. Grid Worlds,[0],[0]
"=
+ !",4.2. Grid Worlds,[0],[0]
"=
+ !",4.2. Grid Worlds,[0],[0]
"=
+ + !",4.2. Grid Worlds,[0],[0]
"=
1
+ !",4.2. Grid Worlds,[0],[0]
"=
+ !",4.2. Grid Worlds,[0],[0]
"=
+ !",4.2. Grid Worlds,[0],[0]
"=
+ + !",4.2. Grid Worlds,[0],[0]
"=
1
+ !",4.2. Grid Worlds,[0],[0]
"=
+ !",4.2. Grid Worlds,[0],[0]
"=
+ !",4.2. Grid Worlds,[0],[0]
"=
+ + !",4.2. Grid Worlds,[0],[0]
"=
1
+ !",4.2. Grid Worlds,[0],[0]
"=
+ !",4.2. Grid Worlds,[0],[0]
"=
+ !",4.2. Grid Worlds,[0],[0]
"=
+ + !",4.2. Grid Worlds,[0],[0]
"=
1
+ !",4.2. Grid Worlds,[0],[0]
"=
+ !",4.2. Grid Worlds,[0],[0]
"=
+ !",4.2. Grid Worlds,[0],[0]
"=
+ + !",4.2. Grid Worlds,[0],[0]
"=
1
+ !",4.2. Grid Worlds,[0],[0]
"=
+ !",4.2. Grid Worlds,[0],[0]
"=
+ !",4.2. Grid Worlds,[0],[0]
"=
+ + !",4.2. Grid Worlds,[0],[0]
"=
1
+ !",4.2. Grid Worlds,[0],[0]
"=
+ !",4.2. Grid Worlds,[0],[0]
"=
+ !",4.2. Grid Worlds,[0],[0]
"=
+ + !",4.2. Grid Worlds,[0],[0]
"=
1
+ !",4.2. Grid Worlds,[0],[0]
"=
+ !",4.2. Grid Worlds,[0],[0]
"=
+ !",4.2. Grid Worlds,[0],[0]
"=
+ + !",4.2. Grid Worlds,[0],[0]
"=
1
+ !",4.2. Grid Worlds,[0],[0]
"=
+ !",4.2. Grid Worlds,[0],[0]
"=
+ !",4.2. Grid Worlds,[0],[0]
"=
+ + !",4.2. Grid Worlds,[0],[0]
"=
1
+ !",4.2. Grid Worlds,[0],[0]
"=
+ !",4.2. Grid Worlds,[0],[0]
"=
+ !",4.2. Grid Worlds,[0],[0]
"=
+ + !",4.2. Grid Worlds,[0],[0]
"=
1
Goal:
Crafting key:
Switch color gameCrafting game
Goal:
Figure 4.",4.2. Grid Worlds,[0],[0]
Left: Crafting mazebase game.,4.2. Grid Worlds,[0],[0]
Right: Colored switches game.,4.2. Grid Worlds,[0],[0]
"See text for details.
",4.2. Grid Worlds,[0],[0]
"In both environments, the agent’s observation consists of a bag of words, where the words correspond to (feature, location).",4.2. Grid Worlds,[0],[0]
"Features consist of item types, names, and their other properties.",4.2. Grid Worlds,[0],[0]
"The locations include position relative to the agent in the maze, and also a few special slots for inventory, current, and target attributes.
",4.2. Grid Worlds,[0],[0]
Training proceeds according to Algorithm 1.,4.2. Grid Worlds,[0],[0]
"During the explore phase, an exploratory policy is trained with reinforcement learning using a count-based reward proportional
to c⇡e(⇢i, ⇢j)P",4.2. Grid Worlds,[0],[0]
"i,j c⇡e(⇢i, ⇢j) + 0.001 !",4.2. Grid Worlds,[0],[0]
"0.5
for making a transition (⇢i, ⇢j), where c⇡e(⇢i, ⇢j) is the number of times transition (⇢i, ⇢j) has been seen so far.",4.2. Grid Worlds,[0],[0]
"We discuss this exploration bonus in Appendix A.
During the final phase of training we simultaneously compute ⇡ and c⇡ , so we use an exponentially decaying average of the success rate of ⇡ to deal with it’s nonstationarity:
c⇡(⇢i, ⇢j) =
PT t=1
T tSt⇡(⇢i, ⇢j)PT t=1 T tAt⇡(⇢i, ⇢j) ,
where T is the number of training epochs, At⇡ is the number of attempted transitions (⇢i, ⇢j) during epoch t, and St⇡ is the number of successful transitions.",4.2. Grid Worlds,[0],[0]
A decay rate of = 0.9 is used.,4.2. Grid Worlds,[0],[0]
"More details of the model and training are provided in Appendix C.
In the switches environment, multi-step test tasks are generated by setting a random attribute as target, which can require up to 12 attribute transitions.",4.2. Grid Worlds,[0],[0]
"In the crafting environment, test tasks are generated by randomly selecting a (crafted) item as a target.",4.2. Grid Worlds,[0],[0]
"Since we do not care about other items in the inventory, the target state is underspecified.
",4.2. Grid Worlds,[0],[0]
We produce a curriculum baseline by gradually increase the upper bound on the difficulty of tasks during training.,4.2. Grid Worlds,[0],[0]
"In the switches environment, the difficulty corresponds to the number of toggles necessary for solving the task.",4.2. Grid Worlds,[0],[0]
"The craft environment has two levels of difficulty: tasks can be completed by a single grab or craft action, and tasks that require multiple such actions.
",4.2. Grid Worlds,[0],[0]
Table 3 compares our Attribute Planner (AP) to a reinforcement learning baseline on the mazebase tasks.,4.2. Grid Worlds,[0],[0]
"The AP planning outperforms purely reactive training regardless of whether one-step, multi-step, or a curriculum of training examples is provided.",4.2. Grid Worlds,[0],[0]
"Finally, we test our approach for planning a build order in StarCraft: Brood War (Synnaeve et al., 2016).",4.3. StarCraft,[0],[0]
"We consider the space of tasks of building particular units in a fixed time of 500 steps, e.g. “build 1 barracks and 2 marines“.
",4.3. StarCraft,[0],[0]
"This task is challenging for RL because the agent must complete a number of distinct steps, e.g. mine enough ore, then build a barracks, and finally train marines using the barracks, before receiving a reward.",4.3. StarCraft,[0],[0]
Each of these steps requires the agent have to control multiple units of different types using low-level actions similar to how a human plays the game.,4.3. StarCraft,[0],[0]
"See Appendix D for more details.
",4.3. StarCraft,[0],[0]
"As in (Sukhbaatar et al., 2017), we restrict the game to the Terran race and only allow construction of certain units.",4.3. StarCraft,[0],[0]
"In the small version, the agent can mine ore and build SCVs, supply depots, barracks, and marines.",4.3. StarCraft,[0],[0]
"In the large version, an engineering bay and missile turrets are included as well.",4.3. StarCraft,[0],[0]
"The attributes are chosen to be the number of units and resources of each type, specifically
{min(bNore/25c, 40), NSCV , Ndepot, Nbarracks, Nmarine}
where Nx is the number of x present in the game, including units under construction.",4.3. StarCraft,[0],[0]
"The large version also include {Neng.bay, Nturrets}.
",4.3. StarCraft,[0],[0]
Models are trained for a total of 30 million steps.,4.3. StarCraft,[0],[0]
AP uses 16 million steps for exploration and 14 million steps for training ⇡.,4.3. StarCraft,[0],[0]
"Table 4 shows the final performance of the AP model and reactive RL baselines on this task after 30 million steps of training.
",4.3. StarCraft,[0],[0]
"AP exploration finds 120,000 and 420,000 edges for the small and large versions, respectively.",4.3. StarCraft,[0],[0]
The size and scaling of this graph show the limitations of a fully explicit graph.,4.3. StarCraft,[0],[0]
"In fact, we represent the ore attribute as bNore/25c because it decreases the size of the graph by a factor of 25: otherwise for each transition w.r.t.",4.3. StarCraft,[0],[0]
"the other attributes, the graph would have a separate edge for each valid value of total ore.
",4.3. StarCraft,[0],[0]
Count-based exploration over attributes is vital during the Explore phase in StarCraft.,4.3. StarCraft,[0],[0]
"If a random policy is used in the small version, only 2047 edges are discovered as opposed to 120,000 using count-based exploration, and the final performance is reduced from 31.7% to 6.4%.",4.3. StarCraft,[0],[0]
Our results show that structuring the space of tasks with high level attributes allows an agent to compose policies for simple tasks into solutions of more complex tasks.,5. Discussion,[0],[0]
"The agent plans a path to the final goal at the level of the attributes, and executes the steps in this path with a reactive policy.",5. Discussion,[0],[0]
"Thus, supervision of an agent by labeling attributes can lead to generalization from simple tasks at train time to more complex tasks at test time.",5. Discussion,[0],[0]
"There are several fronts for further work:
Sample complexity of the planning module: In Table 2 we can see both the benefits and the liabilities of the explicit non-parametric form for c⇡ .",5. Discussion,[0],[0]
"By 10K samples, the parametric lower level policy is already able to have a reasonable success rate.",5. Discussion,[0],[0]
"However, because in this environment, there are over 200K edges in the graph, most of the edges have not been seen, and without any weight-sharing, our model cannot estimate these transition probabilities.",5. Discussion,[0],[0]
"On the other hand, by 100K samples the model has seen enough of the graph to make nontrivial plans; and the non-parametric form of the graph makes planning straightforward.
",5. Discussion,[0],[0]
"In future work, we hope to combine parametric models for c⇡ with search to increase the sample efficiency of the planning module.",5. Discussion,[0],[0]
"Alternatively, we might hope to make progress on dynamic abstraction (projecting out some of the attributes) depending on the current state and goal, which would make the effective number of edges of the graph smaller.
",5. Discussion,[0],[0]
"Exploration We have shown that the attributes ⇢ and counts c⇡, in addition to their usefulness for planning, provide a framework for incentivizing exploration.",5. Discussion,[0],[0]
"In this work we considered a simple count-based exploration strategy, which achieved better exploration in attribute space than random exploration.",5. Discussion,[0],[0]
"However, this setting of pure exploration where there are no empirical rewards is different from the classic problem of exploration in an MDP, and warrants further exploration (see Appendix A).
",5. Discussion,[0],[0]
Learning the attributes: Discovering the attributes automatically would remove much of the need for human supervision.,5. Discussion,[0],[0]
"Recent work, such as (Thomas et al., 2017), demonstrates how this could be done.",5. Discussion,[0],[0]
"Another avenue for discovering attributes is to use a few “seed” attributes, which is necessary for task specification anyway, and use aliasing as a signal that some attributes need to be refined.",5. Discussion,[0],[0]
The tasks that an agent will need to solve often are not known during training.,abstractText,[0],[0]
"However, if the agent knows which properties of the environment are important then, after learning how its actions affect those properties, it may be able to use this knowledge to solve complex tasks without training specifically for them.",abstractText,[0],[0]
"Towards this end, we consider a setup in which an environment is augmented with a set of user defined attributes that parameterize the features of interest.",abstractText,[0],[0]
"We propose a method that learns a policy for transitioning between “nearby” sets of attributes, and maintains a graph of possible transitions.",abstractText,[0],[0]
"Given a task at test time that can be expressed in terms of a target set of attributes, and a current state, our model infers the attributes of the current state and searches over paths through attribute space to get a high level plan, and then uses its low level policy to execute the plan.",abstractText,[0],[0]
"We show in 3D block stacking, gridworld games, and StarCraft that our model is able to generalize to longer, more complex tasks at test time by composing simpler learned policies.",abstractText,[0],[0]
Composable Planning with Attributes,title,[0],[0]
"Clustering is one of the most widely used techniques in data analysis (Xu & Wunsch, 2005; Jain, 2010).",1. Introduction,[0],[0]
"Despite a rich literature on pure continuous data or pure categorical data, the clustering problem remains challenging for mixed-type data, i.e., data with both types of attributes (Everitt et al., 2001).",1. Introduction,[0],[0]
"Mixed-type data are ubiquitous in real world domains, e.g., social science, biomedicine and finance, where categorical attributes often describe demographic information or questionnaire responses, and continuous attributes often correspond to quantitative measurements.",1. Introduction,[0],[0]
"However, only a very limited number of clustering methods have been proposed for such data (Everitt et al., 2001; Huang, 1998).",1. Introduction,[0],[0]
"The major challenge is the lack of a good geometric intuition of data on the mixed-type domain;
1City University of New York (CUNY), New York, USA 2University of Sussex, Falmer, United Kingdom 3National Research University Higher School of Economics, Moscow, Russia 4Ohio State University, Columbus, USA.",1. Introduction,[0],[0]
"Correspondence to: Chao Chen <chao.chen.cchen@gmail.com>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"such intuition is the important basis of many successful geometric clustering methods, e.g., k-means (MacQueen et al., 1967), Ward’s method (Ward Jr, 1963), DBSCAN (Ester et al., 1996), to name a few.",1. Introduction,[0],[0]
"In practice, what usually being done is to convert mixed-type data to either pure continuous or pure categorical domain, and subsequently use existing geometric clustering methods.",1. Introduction,[0],[0]
"A metric for directly dealing with mixed-type data is also available, based on Gower’s coefficient (1971).",1. Introduction,[0],[0]
The uptake of geometric clustering methods is mostly driven by their lightweight computational requirements.,1. Introduction,[0],[0]
"However, these methods lack a well justified underlying probabilistic model, are sensitive to the choice of underlying metric, and do not give a principled answer to the fundamental question of required number of clusters for the data at hand.
",1. Introduction,[0],[0]
"In this paper, we propose a probabilistic clustering method for mixed-type data, which admits at least four attractive properties.",1. Introduction,[0],[0]
"First, our probabilistic method goes beyond the widely-adopted class conditional independence assumption of feature variables, e.g., as in the latent class model (McCutcheon, 1987).",1. Introduction,[0],[0]
"Second, our method is based on the global topographical features, i.e., peaks and mountains, of the density function, rather than the distances between data points.",1. Introduction,[0],[0]
The argument for topographical features is to sidestep a premature specification of the metric space in which our mixed-type data will achieve the best grouping.,1. Introduction,[0],[0]
"Third, our method is able to utilize a persistent homology theory to automatically determine the number of clusters in the data.",1. Introduction,[0],[0]
"Fourth, the proposed method can be easily parallelized to achieve a competitive running time with respect to many lightweight geometric clustering methods.
",1. Introduction,[0],[0]
"From the modeling perspective, we compose tree graphical models with topographical features to achieve a probabilistic mixed-type clustering model.",1. Introduction,[0],[0]
Graphical models provide a way of factorizing a joint probability distribution into a product of local interactions.,1. Introduction,[0],[0]
These local interactions capture dependency among feature variables.,1. Introduction,[0],[0]
While a Bayesian network or a Markov random field can be built with a set of nodes representing each feature variable.,1. Introduction,[0],[0]
The graph structure and parameter estimation can be computationally expensive.,1. Introduction,[0],[0]
"By constraining the graph to be a tree, the structure and parameter can be learned efficiently.",1. Introduction,[0],[0]
"Other than computational benefits, tree-structured
graphical models also provide a modeling elegance; with a tree structure, we have a factorization that explicitly corresponds to empirical univariate and bivariate marginal distributions.",1. Introduction,[0],[0]
"For the bivariate distributions, we can then adapt the product kernel density estimation (Scott, 2015) to capture interaction between continuous-continuous variables, between categorical-categorical variables, and between categorical-continuous variables.
",1. Introduction,[0],[0]
"Having modeled the data generation process via a tree graphical model, we are left with finding a robust approach for assigning each data point to its cluster.",1. Introduction,[0],[0]
"To achieve this, we adopt a topological perspective, namely, we view a probability distribution as a terrain function, called the density landscape, and capture its topographical features as the basis for defining clusters.",1. Introduction,[0],[0]
The topographical features include modes (peaks) and their attractive basins.,1. Introduction,[0],[0]
"For high-dimension and sparse data, it is natural to have many modes.",1. Introduction,[0],[0]
"To avoid over-segmentation of the data and generation of many clusters with only few members, we employ a persistent homology theory (Edelsbrunner & Harer, 2010) to measure the saliency of all modes and merge the trivial ones.",1. Introduction,[0],[0]
Our principled method for clustering mixed-type data respects the underlying topographical features of the density landscape and achieves competitive performance on real data.,1. Introduction,[0],[0]
Clustering has been extensively studied in machine learning and data mining.,1.1. Related Work,[0],[0]
Many comprehensive surveys have been produced detailing the landscape of clustering problems and models.,1.1. Related Work,[0],[0]
"Here we will review related work in the context of geometric versus probabilistic clustering methods for mixed-type data and clustering methods that rely on topographical features such as modes and their attractive basins.
",1.1. Related Work,[0],[0]
Geometric clustering methods A straightforward approach for mixed-type data clustering is to map them into either pure continuous or pure categorical domains before applying a standard clustering method.,1.1. Related Work,[0],[0]
"A metric based on Gower’s coefficient (Gower, 1971) has been proposed for mixed-type data, which rescales the difference in all dimensions, continuous or categorical, and take the average.",1.1. Related Work,[0],[0]
One can apply any distance based method using these metrics.,1.1. Related Work,[0],[0]
"However, all these methods are heuristic; there is no good justification for the underlying geometric intuition of these methods on such a counter-intuitive metric space, despite some successful stories in practice.",1.1. Related Work,[0],[0]
"For example, K-Prototypes algorithm (Huang, 1998) uses a weighted sum of the Euclidean distance and Hamming distance and adopts the K-Means method (Faber, 1994), which iteratively finds the mean of each cluster and re-associates data to different clusters.",1.1. Related Work,[0],[0]
"When the data is pure categorical, the method is called K-Modes (Huang, 1997).",1.1. Related Work,[0],[0]
"Chiu et al. (2001) proposed a hierarchical clustering method, in
which distance between clusters are measured using their log-likelihood, which treat continuous and categorical domain separately.
",1.1. Related Work,[0],[0]
Probabilistic clustering methods Graphical models have been applied to clustering before.,1.1. Related Work,[0],[0]
"Zhang (2004) proposed a latent tree model, i.e., a Bayesian tree whose leaf nodes correspond to all observed dimensions and internal nodes are latent variables determining different clusters.",1.1. Related Work,[0],[0]
"Such tree structure can be learned using efficient algorithms (Chen et al., 2012; Liu et al., 2015).",1.1. Related Work,[0],[0]
"However, this method is only restricted to categorical data.",1.1. Related Work,[0],[0]
Lee & Hastie (2015) proposed a loopy graphical model to model mixed-type data.,1.1. Related Work,[0],[0]
"Their model reduces to a discrete Markov random field when all attributes are categorical, and a Gaussian graphical model when all attributes are continuous.",1.1. Related Work,[0],[0]
"Parameters are learned using pseudo-likelihood estimation (Besag, 1975) and edges are selected using group sparsity penalties (Yuan & Lin, 2006; Huang & Zhang, 2010).",1.1. Related Work,[0],[0]
"However, an efficient inference model is missing in order to apply such model to clustering.
",1.1. Related Work,[0],[0]
Clustering by mode-seeking The density landscape has been exploited before to extract global properties of the data and to achieve better clustering quality.,1.1. Related Work,[0],[0]
"Mode-seeking methods, i.e., associating data to modes representing clusters, have been proposed before in continuous domain (Cheng, 1995; Comaniciu & Meer, 2002b).",1.1. Related Work,[0],[0]
"But such methods rely on a kernel density estimation, which suffers from the curse of dimensionality and thus do not scale to high dimensions (Wasserman, 2013, chap. 20).",1.1. Related Work,[0],[0]
Chen & Quadrianto (2016) proposed a mode-seeking method for categorical data clustering.,1.1. Related Work,[0],[0]
"However, their method tends to produce trivial modes/clusters and thus over-segments the data, mainly due to the lack a principled way to merge modes into clusters of proper size.
",1.1. Related Work,[0],[0]
"Persistent homology for merging clusters In recent years, novel approaches have been proposed to merge modes/clusters based on the topographical landscape of the density function.",1.1. Related Work,[0],[0]
Chazal et al. (2013) used topological persistence to guide the merging of data into clusters.,1.1. Related Work,[0],[0]
"Their method, although theoretically sound, relies on a k-nearest neighbor graph of the data and a given density function, e.g., a kernel density estimation (Silverman, 1986) or a distance from measure (Chazal et al., 2011).",1.1. Related Work,[0],[0]
This method assumes that the data is a high quality sample of the domain and the k-nearest neighbor graph faithfully captures the topographical characteristics of the distribution.,1.1. Related Work,[0],[0]
"However, this condition is often too strong to assume in practice, where most datasets are relatively sparse.",1.1. Related Work,[0],[0]
"In this paper, we propose to start with mode-seeking, and leverage these modes and the gradient paths as a more accurate account of the density landscape.",1.1. Related Work,[0],[0]
Our idea proves to be a better solution and a good complement to the theoretical tool.,1.1. Related Work,[0],[0]
"We also refer to other topological and geometrical studies into the
global structures of hierarchical clustering (Eldridge et al., 2015; Carlsson & Mémoli, 2010).",1.1. Related Work,[0],[0]
"A probabilistic graphical model (Koller & Friedman, 2009) consists of a set of inter-dependent random variables X = (X1, . . .",2. Background,[0],[0]
", XD), a potential function f , and a graph G = (V, E).",2. Background,[0],[0]
Each element in the node set V represents one random variable from X .,2. Background,[0],[0]
The edges represents the dependence relations between pairs of variables.,2. Background,[0],[0]
There are two different kinds of variables in our setting: continuous ones and discrete ones variables.,2. Background,[0],[0]
"For simplification, we assume each discrete variable takes discrete values Xi ∈ L = {1, . . .",2. Background,[0],[0]
", L}.",2. Background,[0],[0]
"In this paper, we use discrete and categorical interchangeably and focus on non-ordinal discrete variables, although ordinal discrete variables are of interest in practice as well.",2. Background,[0],[0]
"In our setting, only Hamming distance can be used for discrete variables.
",2. Background,[0],[0]
"A value assignment to all random variables x = (x1, . . .",2. Background,[0],[0]
", xD) is called a configuration.",2. Background,[0],[0]
"A potential function f : x → R assigns to each configuration a real value, which is inversely proportional to the logarithm of the probability distribution, p(x) = exp(−f(x)",2. Background,[0],[0]
"− A), where A is the log-partition function.",2. Background,[0],[0]
"In this paper, we focus on tree structured graphical models, represented by T = (V, E).",2. Background,[0],[0]
"For a tree model, the probability and potential of a configuration can be factorized into a product (Bach & Jordan, 2003):
p(x) = ∏
(i,j)∈E
p(xi, xj)
p(xi)p(xj)",2. Background,[0],[0]
"∏ k∈V p(xk), (2.1)
where p(xi, xj) is the bivariate marginal density of the variable Xi and Xj , and p(xk) is the univariate marginal density of the variable Xk.
",2. Background,[0],[0]
"When the true distribution can be represented by a tree, we can use the algorithm by Chow & Liu (1968) to reconstruct the tree model.",2. Background,[0],[0]
"First, we compute the mutual information between all pairs of variables:
MIij = ∫ xi,xj p(xi, xj) log p(xi, xj) p(xi)p(xj)",2. Background,[0],[0]
"dxidxj ,
using empirical univariate and bivariate marginals.",2. Background,[0],[0]
The integral is replaced by sum when Xi and Xj have discrete values.,2. Background,[0],[0]
"Next, we compute the maximum spanning tree of a complete graph with D nodes, using the mutual information as edge weights.",2. Background,[0],[0]
"The computed tree is the desired tree model with the optimal KL-divergence from the true tree distribution (Liu et al., 2011).",2. Background,[0],[0]
More details of the selection of the models for univariate and bivariate densities will be given in Section 3.,2. Background,[0],[0]
Our method first estimates the underlying probabilistic density function from given data.,3. Method,[0],[0]
We choose tree-models as they strike a elegant balance between computational efficiency and flexibility of the model.,3. Method,[0],[0]
"Next, we propose to cluster data based on the density landscape: associating data with modes/peaks of the density, and merge them based on advanced persistent homology theory.",3. Method,[0],[0]
"First, we formalize the definition of modes in the mixed-type domain.",3. Method,[0],[0]
"Then we present algorithms for modes-seeking (Section 3.2) and for modes-merging (Section 3.3).
",3. Method,[0],[0]
We first formalize what a mode is in a D-dimensional mixed-type data domain.,3. Method,[0],[0]
Our definition is not restricted to the underlying model.,3. Method,[0],[0]
Denote by Id and Ic the index sets of discrete- and continuous-valued random variables.,3. Method,[0],[0]
"Denote by distH(x, x′) the Hamming distance between x and x′ within the discrete dimensions, and distL2(x, x′) the L2 distance within the continuous dimensions.",3. Method,[0],[0]
We call a discrete neighborhood of x with radius δ > 0,3. Method,[0],[0]
"as all elements with no more than δ Hamming distance and zero Euclidean distance from x, formally,
N dδ (x) = {x′ | distd(x, x′) ≤ δ ∧ distc(x, x′) = 0}.
",3. Method,[0],[0]
"Similarly, we define a continuous neighborhood of x with radius > 0",3. Method,[0],[0]
"as
N c (x) = {x′ | distd(x, x′) = 0 ∧ distc(x, x′) ≤ }.
",3. Method,[0],[0]
"Given a probability density function, p(X), a mode is a local maximum in both the continuous neighborhood and discrete neighborhood, formally: Definition 1 (Modes).",3. Method,[0],[0]
A point x ∈ X is a mode if and only if there exists positive numbers > 0,3. Method,[0],[0]
and δ > 0 such that (1) p(x) ≥ p(x′) for any x′ ∈ N c (x); and (2) p(x) ≥ p(x′) for any x′ ∈ N dδ,3. Method,[0],[0]
(x).,3. Method,[0],[0]
"It suffices to use the smallest positive integer for the discrete neighborhood, δ = 1.",3. Method,[0],[0]
"In this paper, we focus on a tree-structured graphical model.",3. Method,[0],[0]
"Next, we describe our tree model in details within the mixed-type setting.",3. Method,[0],[0]
"We formalize the univariate and bivariate marginal densities p(xi) and p(xi, xj) in the tree model (Eq. (2.1)).",3.1. Instantiating the Tree Model,[0],[0]
"We assume a set of N data {y1, y2, · · · , yN} is given.",3.1. Instantiating the Tree Model,[0],[0]
"For discrete dimensions, we use Multinoulli distribution with Dirichlet prior α = 1, ∀i, j ∈",3.1. Instantiating the Tree Model,[0],[0]
"Id:
p(xi) = Nxi + 1
N + L , with Nxi = N∑ n=1 Jyni = xiK,
p(xi, xj) = Nxi,xj + 1
N + L2 ,
with Nxi,xj = N∑ n=1 Jyni = xi ∧ ynj = xjK.
For continuous variables, we use one-dimensional kernel density estimation for univariate density, and product kernel (Scott, 2015) for univariate and bivariate marginal density.",3.1. Instantiating the Tree Model,[0],[0]
"Formally, ∀i, j ∈ Ic,
p(xi) = 1
N N∑ n=1 Kh1i(y n",3.1. Instantiating the Tree Model,[0],[0]
i,3.1. Instantiating the Tree Model,[0],[0]
"− xi), and
",3.1. Instantiating the Tree Model,[0],[0]
"p(xi, xj) = 1
N N∑ n=1",3.1. Instantiating the Tree Model,[0],[0]
{,3.1. Instantiating the Tree Model,[0],[0]
Kh2i(y n,3.1. Instantiating the Tree Model,[0],[0]
i,3.1. Instantiating the Tree Model,[0],[0]
"− xi)Kh2j (ynj − xj) } ,
(3.1)
We use a one-dimensional Gaussian kernel, denoted as Kh(z) =
1√ 2πh
exp ( − z 2
2h2
) .",3.1. Instantiating the Tree Model,[0],[0]
"Following standard non-
parametric statistics literature (Fan & Gijbels, 1996; Tsybakov, 2009), the kernel bandwidths for univariate and bivariate density are chosen as
hti = 1.06·min { σ∗i , q∗i,0.75 − q∗i,0.25 1.34 } ·N− 1 2β+t , t = 1, 2,
where σ∗i , q ∗ i,0.75 and q ∗ i,0.25 are the standard deviation, the 75% and 25% sample quantiles of Xi, respectively.",3.1. Instantiating the Tree Model,[0],[0]
"The variable β is the order of the kernel (Fan & Gijbels, 1996) and is set to 2 by default.
",3.1. Instantiating the Tree Model,[0],[0]
The choice of a product kernel is justified by two reasons.,3.1. Instantiating the Tree Model,[0],[0]
"First, a product kernel reduces to the product of onedimensional kernels, which are more reliable that a direct 2D kernel density estimation.",3.1. Instantiating the Tree Model,[0],[0]
"Second, the product kernel proves to be convenient to be adopt to bivariate densities for variables with mixed-type as follows.",3.1. Instantiating the Tree Model,[0],[0]
"For a mixed-type pair of variables, (Xi, Xj), i ∈ Ic, j ∈",3.1. Instantiating the Tree Model,[0],[0]
"Id, we take the limit of h2i to zero in the product kernel formula (Equation (3.1)).",3.1. Instantiating the Tree Model,[0],[0]
"The first kernel becomes the Dirac-delta function, leading to the following bivariate marginal
p(xi, xj) = 1
N N∑ n=1",3.1. Instantiating the Tree Model,[0],[0]
{,3.1. Instantiating the Tree Model,[0],[0]
Jynj = xjKKh2i(yni,3.1. Instantiating the Tree Model,[0],[0]
"− xi) } .
",3.1. Instantiating the Tree Model,[0],[0]
Building the tree model.,3.1. Instantiating the Tree Model,[0],[0]
"Using these empirical univariate and bivariate marginal densities, we estimate all pairwise mutual information, and then compute the tree (V, E) using the Chow-Liu algorithm.",3.1. Instantiating the Tree Model,[0],[0]
Plugging the univariate and bivariate marginal densities into Eq.,3.1. Instantiating the Tree Model,[0],[0]
"(2.1), we have the complete density distribution (the tree model).",3.1. Instantiating the Tree Model,[0],[0]
"Next, we present our algorithm for finding the modes over the density landscape of the computed model.",3.1. Instantiating the Tree Model,[0],[0]
Our algorithm assigns each data to a mode via a gradient ascent procedure.,3.2. Mode-Seeking Algorithm,[0],[0]
"For a mixed-domain, a gradient is not well defined.",3.2. Mode-Seeking Algorithm,[0],[0]
"Following the definition of modes (Def. 1), we formulate a gradient step as an optimization within either the continuous neighborhood N c (x) or the discrete
neighborhood N dδ (x), with δ = 1.",3.2. Mode-Seeking Algorithm,[0],[0]
"The two procedures have to be taken alternatively in order to continue increasing the probability until a mode is reached.
",3.2. Mode-Seeking Algorithm,[0],[0]
"Our algorithm starts at each data, s, iteratively walks to a nearby point with bigger probability until convergence.",3.2. Mode-Seeking Algorithm,[0],[0]
"The final position is the mode of interest and will be associated with the data, s. For ease of computation, we use the potential function f(x) instead of the probability density function:
f(x) =",3.2. Mode-Seeking Algorithm,[0],[0]
"− ∑
(i,j)∈E log p(xi, xj)− ∑ i∈V (1− di) log p(xi),
(3.2) in which di is the degree of node i in the tree.",3.2. Mode-Seeking Algorithm,[0],[0]
It is easy to verify that p(x) ∝ −f(x).,3.2. Mode-Seeking Algorithm,[0],[0]
"Therefore, modes of p(x) are the local minima of f(x), following the same definition in Def. 1.",3.2. Mode-Seeking Algorithm,[0],[0]
"We follow the aforementioned iterative procedure, except at each step, we find a nearby point with smaller potential.
",3.2. Mode-Seeking Algorithm,[0],[0]
"At each step of the algorithm, we first update all discrete variables until no better elements exist within the discrete neighborhood N dδ",3.2. Mode-Seeking Algorithm,[0],[0]
(x),3.2. Mode-Seeking Algorithm,[0],[0]
with δ = 1.,3.2. Mode-Seeking Algorithm,[0],[0]
"Next, we update all continuous variables using gradient descent, until the gradient of f at continuous dimensions∇cf becomes zero.",3.2. Mode-Seeking Algorithm,[0],[0]
"Our main algorithm is summarized in Alg. 1.
",3.2. Mode-Seeking Algorithm,[0],[0]
Algorithm 1 Mode-Seeking Algorithm 1,3.2. Mode-Seeking Algorithm,[0],[0]
": Input: Data D = {si | i = 1, · · · , N}; a potential
function f .",3.2. Mode-Seeking Algorithm,[0],[0]
"2: Output: A set of modes,M; mode indices associated
to each data {ci | i = 1, · · · , N} 3: M← ∅ 4: for i = 1 to N do 5: x← si 6: repeat 7: repeat 8: x← argminz∈Nd1 (x) f(z) 9: until x converges
10: repeat 11: x← x− η∇cf 12: until x converges 13: until x converges 14: if x /∈M then 15: M←M∪ {x} 16: end if 17: ci ← the index of x inM 18: end for
Here η is the stepsize.",3.2. Mode-Seeking Algorithm,[0],[0]
"The best neighbor within Hamming distance one, argminz∈Nd1 (x) f(z), can be computed using dynamic programming.",3.2. Mode-Seeking Algorithm,[0],[0]
"This can be achieved by directly adapting the algorithm by (Chen & Quadrianto, 2016).
",3.2. Mode-Seeking Algorithm,[0],[0]
"It remains to compute the gradient of f in the contin-
uous domain, ∇cf .",3.2. Mode-Seeking Algorithm,[0],[0]
For each continuous variable,3.2. Mode-Seeking Algorithm,[0],[0]
"i ∈ Ic, relevant terms in the energy function (Eq. (3.2)) can be divided into three groups, the univariate term, the bivariate terms with a continuous neighbor, j ∈ Ic, and the bivariate terms with a discrete neighbor, j ∈ Id. Treating them differently, the partial derivative:
∂f(x)
∂xi = −(1− di)
∑N n=1 Kh1i(y n",3.2. Mode-Seeking Algorithm,[0],[0]
"i − xi)
yni",3.2. Mode-Seeking Algorithm,[0],[0]
"−xi h21i∑N
n=1 Kh1i(y n",3.2. Mode-Seeking Algorithm,[0],[0]
i,3.2. Mode-Seeking Algorithm,[0],[0]
"− xi)
",3.2. Mode-Seeking Algorithm,[0],[0]
"− ∑
j∈Ic:(i,j)∈E
∑N n=1 Kh2i(y n",3.2. Mode-Seeking Algorithm,[0],[0]
i,3.2. Mode-Seeking Algorithm,[0],[0]
"− xi)Kh2j (ynj − xj)
",3.2. Mode-Seeking Algorithm,[0],[0]
yni,3.2. Mode-Seeking Algorithm,[0],[0]
"−xi h22i∑N
n=1 Kh2i(y n i",3.2. Mode-Seeking Algorithm,[0],[0]
"− xi)Kh2j (ynj − xj)
",3.2. Mode-Seeking Algorithm,[0],[0]
"− ∑
k∈Id:(i,j)∈E
∑N n=1 Kh2i(y n",3.2. Mode-Seeking Algorithm,[0],[0]
i,3.2. Mode-Seeking Algorithm,[0],[0]
"− xi)Jynk = xkK
yni",3.2. Mode-Seeking Algorithm,[0],[0]
"−xi h22i∑N
n=1 Kh2i(y n i − xi)
(3.3)
",3.2. Mode-Seeking Algorithm,[0],[0]
"Algorithm 2 Merging Data Using Topological Persistence
1: Input: Ĝ = (V̂, Ê), density function p : V̂ → R+, persistence threshold τ 2: Output: Clusters C 3: C ← ∅ 4: Sort elements in V̂ according to the density function
values, so that p(vi) ≥ p(vi+1), ∀vi, vi+1 ∈ V̂ .",3.2. Mode-Seeking Algorithm,[0],[0]
"5: for i = 1 to |V̂| do 6: nbd← {vj | (vi, vj) ∈ Ê ∧ j < i} 7: // neighbors of vi with smaller indices (bigger p) 8: if nbd = ∅",3.2. Mode-Seeking Algorithm,[0],[0]
"then 9: create a new cluster c = {vi}
10: birth(c)← p(vi) 11: C ← C ∪ {c} 12: else 13:",3.2. Mode-Seeking Algorithm,[0],[0]
Cnbd ← all clusters containing nodes in nbd 14: cmax ← argmaxc∈Cnbd birth(c) 15: for all c ∈ Cnbd and c 6= cmax do 16: persistence(c)← birth(c)− p(vi) 17: if persistence(c) < τ,3.2. Mode-Seeking Algorithm,[0],[0]
then 18: // merge c into cmax 19: cmax ← cmax ∪ c 20: C ← C\{c} 21: end if 22: end for 23: // assign vi to cmax 24: cmax ← cmax ∪ {vi} 25: end if 26: end for,3.2. Mode-Seeking Algorithm,[0],[0]
The modes computed in Alg. 1 provide a clustering of the data.,3.3. Merging Clusters Using Topological Persistence,[0],[0]
"However, in practice, the data is often relatively sparse.",3.3. Merging Clusters Using Topological Persistence,[0],[0]
"In such cases, the method tends to produce a large
number of modes, and thus over-segments the data into small clusters.",3.3. Merging Clusters Using Topological Persistence,[0],[0]
"There are ways to merge these small clusters (Ward Jr, 1963; Day & Edelsbrunner, 1984).",3.3. Merging Clusters Using Topological Persistence,[0],[0]
But they rely on a distance metric to measure similarities between clusters.,3.3. Merging Clusters Using Topological Persistence,[0],[0]
"Instead, we propose a principled approach that is only based on the density landscape, i.e., the topographical features such as peaks, ridges, valleys.",3.3. Merging Clusters Using Topological Persistence,[0],[0]
Our method is built on the theory of persistent homology.,3.3. Merging Clusters Using Topological Persistence,[0],[0]
"We focus on zerodimensional topological structures in this paper, although the theory is much more general.
",3.3. Merging Clusters Using Topological Persistence,[0],[0]
Persistence of modes.,3.3. Merging Clusters Using Topological Persistence,[0],[0]
"We estimate the saliency of a peak (mode) using its “relative height”, namely, the difference between its height and the level at which its basin of attraction meets the one of another higher mode.",3.3. Merging Clusters Using Topological Persistence,[0],[0]
"Formally, we filter the domain using a function value threshold t from +∞ to −∞. As t decreases, we monitor the topological changes of the progressively growing superlevel set, X t = {x ∈ X | p(x) ≥ t}, that is, the domain whose probability density value is no smaller than t. Each mode attributes to the birth of a new connected component in the superlevel set and the component is killed when it meets another component created by a higher mode.",3.3. Merging Clusters Using Topological Persistence,[0],[0]
"The density value of the creating mode and the density value of the point at which the two components meet (called a saddle) are called the birth and death times, and their difference, called the persistence, measures the saliency of this mode.",3.3. Merging Clusters Using Topological Persistence,[0],[0]
"See Figure 1 for an illustration.
",3.3. Merging Clusters Using Topological Persistence,[0],[0]
"The merging of connected components as we decrease the threshold t provides a natural way to merge modes; when two connected components meet, we merge them if one of them has≤ τ",3.3. Merging Clusters Using Topological Persistence,[0],[0]
persistence (Figure 1).,3.3. Merging Clusters Using Topological Persistence,[0],[0]
This gives us a principled way to merge modes.,3.3. Merging Clusters Using Topological Persistence,[0],[0]
"Based on the convergence of tree-model estimation (Liu et al., 2011) and the stability
of persistent homology (Cohen-Steiner et al., 2007), this method is guaranteed to be robust to noise and L∞ perturbation of the density function.
",3.3. Merging Clusters Using Topological Persistence,[0],[0]
Sample-based persistence computation.,3.3. Merging Clusters Using Topological Persistence,[0],[0]
"Given a dense uniform sampling of the whole domain X , we can trust these samples will describe the density landscape faithfully.",3.3. Merging Clusters Using Topological Persistence,[0],[0]
"In practice, however, a uniform sampling will have exponential size to the dimension.",3.3. Merging Clusters Using Topological Persistence,[0],[0]
"Chazal et al. (2013) used the k-nearest neighbor graph of the input data, D, assuming they are good samples from the density function.",3.3. Merging Clusters Using Topological Persistence,[0],[0]
"However, in practice, the data is often relatively sparse and cannot represent the landscape well enough to produce a high quality mode-merging hierarchy.",3.3. Merging Clusters Using Topological Persistence,[0],[0]
"In fact, it is very likely that the modes are not included in the data and thus the birth time (as well as the persistence) will be under-estimated.",3.3. Merging Clusters Using Topological Persistence,[0],[0]
"See Figure 2(left) for an illustration.
",3.3. Merging Clusters Using Topological Persistence,[0],[0]
"In this paper, we propose to compute persistence based on all points we encountered during the mode-seeking procedure.",3.3. Merging Clusters Using Topological Persistence,[0],[0]
"In Algorithm 1, we collect the point x computed after each iteration (after line 12).",3.3. Merging Clusters Using Topological Persistence,[0],[0]
The gradient step also provides a natural edge connecting these points.,3.3. Merging Clusters Using Topological Persistence,[0],[0]
This tree structured graph give us a high-quality description of the attractive basin of each mode.,3.3. Merging Clusters Using Topological Persistence,[0],[0]
This provides us a well-suited underlying graph describing the density landscape.,3.3. Merging Clusters Using Topological Persistence,[0],[0]
See Figure 2(right).,3.3. Merging Clusters Using Topological Persistence,[0],[0]
"Finally, to ensure the graph is fully connected, and the space between modes are well described, we add edges (green edges) connecting points from neighboring attractive basins, as well as the lowest point along these edges (green markers).",3.3. Merging Clusters Using Topological Persistence,[0],[0]
Note that this is the only time when the distance metric plays a role in our model.,3.3. Merging Clusters Using Topological Persistence,[0],[0]
"We use a sum of the Hamming distance and Euclidean distance.
Algorithm.",3.3. Merging Clusters Using Topological Persistence,[0],[0]
"Given a graph Ĝ = (V̂, Ê), in which each node is assigned a probability density, we compute the persistence-based merge tree as follows.",3.3. Merging Clusters Using Topological Persistence,[0],[0]
Sort all nodes in decreasing order of their density function values.,3.3. Merging Clusters Using Topological Persistence,[0],[0]
Add them into the superlevel set one-by-one.,3.3. Merging Clusters Using Topological Persistence,[0],[0]
"To add a node vi, we check whether it is adjacent to any nodes that have been included.",3.3. Merging Clusters Using Topological Persistence,[0],[0]
"If not, vi, which must be a mode itself, creates a new connected component with the birth time p(vi).",3.3. Merging Clusters Using Topological Persistence,[0],[0]
"If vi is connected to multiple existing connected components, we keep the one with the earliest birth time, cmax, and merge some others into cmax.",3.3. Merging Clusters Using Topological Persistence,[0],[0]
"In particular, for each other adjacent connected component, we check whether its life length so far is less than τ .",3.3. Merging Clusters Using Topological Persistence,[0],[0]
The ones with ≤ τ,3.3. Merging Clusters Using Topological Persistence,[0],[0]
life length will be merged into cmax.,3.3. Merging Clusters Using Topological Persistence,[0],[0]
We add vi into,3.3. Merging Clusters Using Topological Persistence,[0],[0]
the connected component cmax See Figure 3 for an illustration.,3.3. Merging Clusters Using Topological Persistence,[0],[0]
See Alg. 2 for the pseudocode.,3.3. Merging Clusters Using Topological Persistence,[0],[0]
"We compare our methods with existing clustering methods on several real world mixed-type datasets from UCI repository (Lichman, 2013): Contraceptive Method Choice dataset (CMC), Credit Approval dataset (CRX),
German Credit Approval (German), and Statlog Heart Disease dataset (Heart).",4. Experiments,[0],[0]
See the table below for more details.,4. Experiments,[0],[0]
"All datasets have 60% to 70% of the features being discrete.
",4. Experiments,[0],[0]
Table 1.,4. Experiments,[0],[0]
"Datasets
Data # of samples Dimension # of clusters CMC 1473 9 3 Heart 297 13 5 CRX 653 15 2
German 1000 20 2",4. Experiments,[0],[0]
Our method can be straightforwardly parallelized.,4. Experiments,[0],[0]
We run the mode-seeking for all data points (the for-loop in Alg. 1) in parallel.,4. Experiments,[0],[0]
"On average, the mode-seeking of a single data takes 6 gradient ascent steps and 5.87 seconds.",4. Experiments,[0],[0]
"On a cluster with 48 cores, our program finishes within 3 minutes for any of the datasets.",4. Experiments,[0],[0]
"If running in a sequential manner, the time will be linear to the dataset size.",4. Experiments,[0],[0]
"After all data are processed, we collect all relevant points and run a persistence-based merging sequentially.",4. Experiments,[0],[0]
This step takes less than 20 seconds for any of the datasets.,4. Experiments,[0],[0]
The persistence-based merging depends on a threshold τ .,4. Experiments,[0],[0]
It is hard to select a universal one due to the large variation among datasets.,4. Experiments,[0],[0]
"Instead, we choose the τ for each dataset so that the desired the nubmer of clusters remain after merging.",4. Experiments,[0],[0]
This is a fair comparison; all clustering methods we compare with use an oracle number of clusters.,4. Experiments,[0],[0]
We empirically set the parameter δ to one.,4. Experiments,[0],[0]
"Using a bigger δ hurts the performance as it would try to ‘smooth’ the landscape in the categorical domain.
",4. Experiments,[0],[0]
"All methods can be grouped into five different groups, based on the underlying domain and the approach.",4. Experiments,[0],[0]
The first group assumes a continuous domain and an Euclidean metric.,4. Experiments,[0],[0]
"We project the mixed-type data into the continuous domain and directly apply such methods, including k-means (Faber, 1994), Affinity Propagation (Frey & Dueck, 2007), Mean Shift (Cheng, 1995; Comaniciu & Meer, 2002a), Spectral Clustering (Kamvar et al., 2003), Ward’s algorithm (Ward Jr, 1963), Agglomerative clustering (Day & Edelsbrunner, 1984) and DBSCAN (Ester et al., 1996).
",4. Experiments,[0],[0]
"The second group are methods designed for pure categorical domain, e.g., K-Modes (Huang, 1997), ROCK (Guha et al., 1999), mixture of multinoulli (latent class analysis) (McCutcheon, 1987).",4. Experiments,[0],[0]
We convert mixed-type data into categorical data by thresholding continuous values at the median.,4. Experiments,[0],[0]
"We also include Affinity Propagation, Spectral Clustering and DBSCAN in this group; these methods can be applied to any distance metrics.",4. Experiments,[0],[0]
"We compute pairwise Hamming distance between data as the input of these three methods.
",4. Experiments,[0],[0]
"For the third group, we use these three methods, but using a distance matrix based on Gower’s coefficient (Gower, 1971), which was designed specifically for mixed-domain.",4. Experiments,[0],[0]
The fourth group uses a simply sum of the Euclidean distance (restricted to continuous dimensions) and Hamming distance (restricted to categorical dimensions).,4. Experiments,[0],[0]
"A good rep-
resentative in such group is K-Prototypes (Huang, 1998).",4. Experiments,[0],[0]
"We again applied the three methods (Affinity, Spectral and DBSCAN) on this new metric.
",4. Experiments,[0],[0]
"In the last group, we compare our method and a few other topological methods.",4. Experiments,[0],[0]
We compare to the method using only modes for clustering.,4. Experiments,[0],[0]
"This is essentially an adaptation of (Chen & Quadrianto, 2016) to the mixed-type domain.",4. Experiments,[0],[0]
"We also compare to (Chazal et al., 2013) by computing the persistence on the k-nearest neighbor graph, using our tree-model as the underlying density estimation.",4. Experiments,[0],[0]
"Finally, we also show the result of our method.
",4. Experiments,[0],[0]
The results are listed in Table 2.,4. Experiments,[0],[0]
"We use the Adjusted Mutual Information (AMI) (Vinh et al., 2010) and Adjusted Rand Score (ARS) (Hubert & Arabie, 1985) to evaluate all
methods.",4. Experiments,[0],[0]
"For all methods requiring random initializations, we run each one for 10 times and take the average performance.",4. Experiments,[0],[0]
"When necessary, we provide a true number of clusters as an oracle.",4. Experiments,[0],[0]
The cells with N/A correspond to the cases when the program crashes.,4. Experiments,[0],[0]
"It is most likely because the Gower’s coefficient and Hamming distance does not give us a well-conditioned distance matrix for the spectral clustering method.
",4. Experiments,[0],[0]
Discussion.,4. Experiments,[0],[0]
"Our method outperforms most methods from all other four groups, using different types of metrics.",4. Experiments,[0],[0]
We also observe that a few methods based on pure categorical domain are quite competitive.,4. Experiments,[0],[0]
"Similarly, K-prototype, a popular tool for mixed-type data, has good performance on some data.",4. Experiments,[0],[0]
"Outperforming other topological methods (modes only and persistence only) demonstrate the significance of our contribution.
",4. Experiments,[0],[0]
Our current experiments assume the correct number of clusters is given.,4. Experiments,[0],[0]
"It is possible to prove that with sufficient samples and the correct threshold τ , the persistence-based clustering can find the correct number of cluster and the right clustering for most data points in a sense similar to the elegant result in (Chazal et al., 2013).",4. Experiments,[0],[0]
"A closely related theoretical result is in (Eldridge et al., 2015), which shows that the hierarchical clustering tree constructed by a similar merging procedure is consistent for points sampled from a nice density distribution over RD.",4. Experiments,[0],[0]
"In this paper, we propose a probabilistic clustering method for mixed-type data.",5. Conclusions,[0],[0]
We design a tree-structured graphical model for the mixed-type domain.,5. Conclusions,[0],[0]
We also develop methods based on a topographical view of the density landscape.,5. Conclusions,[0],[0]
"We design algorithms to capture modes of the density landscape and merge trivial modes based on the theory of persistent homology.
Acknowledgments.",5. Conclusions,[0],[0]
XN and CC have been partly funded by the grant PSC-CUNY 69844-00 47.,5. Conclusions,[0],[0]
NQ has been partly funded by the Russian Academic Excellence Project ‘5- 100’.,5. Conclusions,[0],[0]
YW has been partly supported by the grant NSF DMS-1547357.,5. Conclusions,[0],[0]
The authors gratefully acknowledge use of the services and facilities of CUNY Queens Colleges Center for Computational Infrastructure for the Sciences (CCIS).,5. Conclusions,[0],[0]
Clustering data with both continuous and discrete attributes is a challenging task.,abstractText,[0],[0]
Existing methods often lack a principled probabilistic formulation.,abstractText,[0],[0]
"In this paper, we propose a clustering method based on a tree-structured graphical model to describe the generation process of mixed-type data.",abstractText,[0],[0]
"Our tree-structured model factorizes into a product of pairwise interactions, and thus localizes the interaction between feature variables of different types.",abstractText,[0],[0]
"To provide a robust clustering method based on the tree-model, we adopt a topographical view and compute peaks of the density function and their attractive basins for clustering.",abstractText,[0],[0]
"Furthermore, we leverage the theory from topology data analysis to adaptively merge trivial peaks into large ones in order to achieve meaningful clusterings.",abstractText,[0],[0]
Our method outperforms state-of-the-art methods on mixed-type data.,abstractText,[0],[0]
Composing Tree Graphical Models with Persistent Homology Features for Clustering Mixed-Type Data,title,[0],[0]
"How to model rank data and how to make optimal statistical inferences from rank data are important topics at the interface of statistics, computer science, and economics.",1. Introduction,[0],[0]
"Random utility models (RUMs) (Thurstone, 1927) are one of the most widely-applied statistical models for rank data.",1. Introduction,[0],[0]
"In an RUM, each alternative ai is parameterized by a utility distribution µi.",1. Introduction,[0],[0]
Agents’ rankings are generated in two steps.,1. Introduction,[0],[0]
"In the first step, a latent utility ui for each alternative ai is generated from µi.",1. Introduction,[0],[0]
"In the second step, the alternatives are ranked w.r.t.",1. Introduction,[0],[0]
their utilities ui in descending order.,1. Introduction,[0],[0]
"The logit model and the probit model, which are very popular in statistics and economics, both have random utility interpretations.
",1. Introduction,[0],[0]
"While providing better fitness to the rank data (Azari Soufiani et al., 2012; Zhao et al., 2018b), general RUMs are computationally hard to tackle due to the lack of closed-form formulas for the likelihood function.",1. Introduction,[0],[0]
"The only known exception is the Plackett-Luce model (Plackett, 1975; Luce, 1959),
1Computer Science Department, Rensselaer Polytechnic Institute, Troy, NY, USA.",1. Introduction,[0],[0]
Correspondence to:,1. Introduction,[0],[0]
"Zhibing Zhao <zhaoz6@rpi.edu>, Lirong Xia <xial@cs.rpi.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
which is the RUM with Gumbel distributions.",1. Introduction,[0],[0]
"RUMs, especially the Plackett-Luce model, have been widely applied to model and predict human behavior (McFadden, 2000), where the standard case of discrete choice models can be viewed as the Plackett-Luce model restricted to top choices.",1. Introduction,[0],[0]
"Other notable recent applications include elections (Gormley & Murphy, 2008), crowdsourcing (Pfeiffer et al., 2012), recommender systems (Wang et al., 2016), preference elicitation (Azari Soufiani et al., 2013b; Zhao et al., 2018a), marketing (Berry et al., 1995), health care (Bockstael, 1999), transportation (Bhat et al., 2007), and security (Yang et al., 2011).
",1. Introduction,[0],[0]
Recently there has been a growing interest in designing faster and more accurate algorithms for RUMs.,1. Introduction,[0],[0]
Many algorithms in previous work share the following rank-breakingthen-optimization architecture.,1. Introduction,[0],[0]
"First, rank data are converted to pairwise comparison data.",1. Introduction,[0],[0]
"Second, based on the pairwise comparisons, various optimization algorithms are designed to estimate the ground truth (Negahban et al., 2012; Azari Soufiani et al., 2013a; 2014; Chen & Suh, 2015; Khetan & Oh, 2016b;a).
",1. Introduction,[0],[0]
"Pairwise data are often obtained from rank data by applying rank-breaking, which allows for a smooth tradeoff between computational efficiency and statistical efficiency (Azari Soufiani et al., 2013a; 2014; Khetan & Oh, 2016b;a).",1. Introduction,[0],[0]
"Given m alternatives, a rank-breaking scheme is modeled by a weighted undirected graph G (see Figure 1 for an example) over {1, . . .",1. Introduction,[0],[0]
",m} (the vertices are positions in a ranking), such that for any ranking R over the m alternatives and any distinct i1, i2 ≤ m, we obtain gi1i2 (the weight on the edge {i1, i2} in G) pairwise comparisons between alternatives at positions i1 and i2 of R.
Our Contributions.",1. Introduction,[0],[0]
"By leveraging the celebrated composite marginal likelihood (CML) methods (Lindsay, 1988; Varin, 2008), we propose a novel and flexible rank-breakingthen-CML framework.",1. Introduction,[0],[0]
"Given an RUM, our framework, denoted by RBCML(G,W), is defined by a weighted rankbreaking graph G and a CML-weight vectorW = {",1. Introduction,[0],[0]
"wi1i2 : i1, i2 ≤ m, i1 6= i2}, which contains one non-negative weight for each pair of alternatives (ai1 , ai2).",1. Introduction,[0],[0]
We note that both G andW are the algorithm designer’s choices.,1. Introduction,[0],[0]
"Given rank data P , we compute ~θ to maximize the following com-
posite log-likelihood function.",1. Introduction,[0],[0]
"CLLM(~θ, P ) = ∑ i1 6=i2",1. Introduction,[0],[0]
(,1. Introduction,[0],[0]
"κi1i2wi1i2 ln pi1i2( ~θ))
",1. Introduction,[0],[0]
Here ~θ represents the parameters of RUM.,1. Introduction,[0],[0]
"Given G, κi1i2 is the percentage of pairwise comparisons ai1 ai2 in the data.",1. Introduction,[0],[0]
"pi1i2(~θ) is the probability of ai1 ai2 under RUM with ~θ, which is the total probability of generating a ranking with ai1 ai2 given ~θ.",1. Introduction,[0],[0]
We note that the RBCML framework is very general because any combination of G andW can be used.,1. Introduction,[0],[0]
"A breaking graph G is uniform, if all edges have the same weight.",1. Introduction,[0],[0]
Let Gu denote the breaking graph whose weights are all 1.,1. Introduction,[0],[0]
"A CML-weight vectorW is symmetric, if for all i1 6= i2, we have wi1i2 = wi2i1 .",1. Introduction,[0],[0]
"W is uniform, if all weights are 1, denoted byWu.
",1. Introduction,[0],[0]
Theoretical contributions.,1. Introduction,[0],[0]
"For convenience we let position-k breaking denote the breaking that consists of all unit-weight edges between position k and all positions after k. E.g. the position-1 breaking consists of all unit-weight pairwise comparisons in positions {(1, 2), (1, 3), . . .",1. Introduction,[0],[0]
", (1,m)}.",1. Introduction,[0],[0]
A weighted union of position-k breakings is a breaking that has the same weight (possibly zero) for each k.,1. Introduction,[0],[0]
"An example is shown in Figure 1, which is the union of 1/3 position-1 breaking and 1/2 position-2 breaking.",1. Introduction,[0],[0]
"Our theoretical results carry the following message about “good"" RBCMLs.
",1. Introduction,[0],[0]
"We should use RBCML(G,W) with connected and symmetricW .",1. Introduction,[0],[0]
"For Plackett-Luce model, we should use a breaking G that is the weighted union of multiple position-k breakings.",1. Introduction,[0],[0]
"For RUMs with symmetric utility distributions, we should use Gu.
",1. Introduction,[0],[0]
"The message is established via a series of theorems (Theorems 1, 2, 5, 8, and 9).",1. Introduction,[0],[0]
"Theorems 1 and 2, which prove that strict log-concavity is preserved under convolution and under marginalization, are of independent interest.
",1. Introduction,[0],[0]
Algorithmic contributions.,1. Introduction,[0],[0]
"Experiments on synthetic data for Gaussian RUMs, where each utility distribution is Gaussian, show that RBCML(Gu,Wu) achieves better statistical efficiency and computational efficiency than the GMM algorithm by Azari Soufiani et al. (2014).",1. Introduction,[0],[0]
"For the Plackett-Luce model, we propose an RBCML with a heuristicWH .",1. Introduction,[0],[0]
"We compare our RBCML for the Plackett-Luce model with the consistent rank-breaking algorithm by Khetan & Oh (2016b) and the I-LSR algorithm by Maystre & Grossglauser (2015) via experiments on synthetic data and show that our RBCML provides a tradeoff between statistical efficiency and computational efficiency.
",1. Introduction,[0],[0]
Related Work and Discussions.,1. Introduction,[0],[0]
Our RBCML framework leverages the strengths of rank breaking and CML.,1. Introduction,[0],[0]
"The major advantage of CML is that often marginal likelihood functions are much easier to optimize than the full likeli-
hood function.",1. Introduction,[0],[0]
"However, for RUMs, even computing the marginal likelihood may take too much time, as CML needs to count the number of pairwise comparisons between alternatives in the rankings, which takes O(m2n) time, where m is the number of alternatives and n is the number of rankings.",1. Introduction,[0],[0]
"Therefore, standard CML becomes inefficient when m or n are large.",1. Introduction,[0],[0]
RBCML overcomes such inefficiency by applying rank-breaking.,1. Introduction,[0],[0]
"The computational complexity of rank-breaking can be O(kmn) for any k ≤ m. Often a tradeoff between computational efficiency and statistical efficiency must be made.
",1. Introduction,[0],[0]
"RBCML generalizes the algorithm proposed by Khetan & Oh (2016b), which focused on the Plackett-Luce model and whose optimization technique turns out to be CML with Wu.1",1. Introduction,[0],[0]
"The comparison between RBCML and other related work is summarized in Table 1.
",1. Introduction,[0],[0]
"Our theorems on strict log-concavity of composite likelihood function generalize Hunter (2004)’s result, which was proved for Plackett-Luce with Gu andWu.",1. Introduction,[0],[0]
"Our results can be applied to not only otherW’s under Plackett-Luce, but also other RUMs where the PDFs of utility distributions are strictly log-concave, e.g. Gaussians.",1. Introduction,[0],[0]
"Technically, proving our results for general RUMs is much more challenging due to the lack of closed-form formulas for the likelihood function.",1. Introduction,[0],[0]
"Another line of previous work proved (non-strict) log-concavity for special cases of RBCML (Azari Soufiani et al., 2012; Khetan & Oh, 2016a;b).",1. Introduction,[0],[0]
"Again, our theorems are stronger because (1) our theorems work for a more general class of RBCML, and (2) strict log-concavity is more desirable than log-concavity because the formal implies the uniqueness of the solution.
",1. Introduction,[0],[0]
The key step in our proofs is the preservation of strict logconcavity under convolution (Theorem 1) and marginalization (Theorem 2).,1. Introduction,[0],[0]
"Surprisingly, we were not able to find these theorems in the literature, despite that it is well-known that (non-strict) log-concavity and strong log-concavity are preserved under convolution and marginalization (Saumard & Wellner, 2014).",1. Introduction,[0],[0]
Our proofs of Theorems 1 and 2 are based on a careful examination of the condition for equality in the Prékopa-Leindler inequality proved by Dubuc (1977).,1. Introduction,[0],[0]
"We believe that Theorems 1 and 2 are of independent interest.
",1. Introduction,[0],[0]
Xu & Reid (2011) provided sufficient conditions for general CML methods to satisfy consistency and asymptotic normality.,1. Introduction,[0],[0]
"Unfortunately, some of the conditions by Xu & Reid (2011) do not hold for RBCML.",1. Introduction,[0],[0]
"Therefore, we derive new proof of consistency and asymptotic normality for RBCML.
Khetan & Oh (2016b;a) provide sufficient conditions on rank-breakings for CML with Wu to be consistent under
1Khetan & Oh (2016b)’s algorithm works for special partial orders.",1. Introduction,[0],[0]
"In this paper, we only focus on comparisons between RBCML and their algorithms restricted to linear orders.
",1. Introduction,[0],[0]
the Plackett-Luce model.,1. Introduction,[0],[0]
"It is an open question what are all consistent rank-breakings for CML, even withWu.",1. Introduction,[0],[0]
"We answer this question for Plackett-Luce (Theorem 8), as well as a large class of other RUMs (Theorem 9), and for all W’s.",1. Introduction,[0],[0]
"Let A = {a1, a2, · · · , am} denote the set of m alternatives.",2. Preliminaries,[0],[0]
Let L(A) denote the set of all linear orders (rankings) over A. A ranking R ∈ L(A) is denoted by ai1 ai2 . . .,2. Preliminaries,[0],[0]
"aim , where ai1 is ranked at the top, ai2 is ranked at the second position, etc.",2. Preliminaries,[0],[0]
"We write a R b if a is ranked higher than b in R. Let P = {R1, R2, . . .",2. Preliminaries,[0],[0]
", Rn} denote the collection of n rankings, called a preference profile.
",2. Preliminaries,[0],[0]
Definition 1 (Random utility models (RUMs)),2. Preliminaries,[0],[0]
A random utility modelM over A associates each alternative ai with a utility distribution µi(·|~θi).,2. Preliminaries,[0],[0]
"The parameter space is Θ = {~θ = {~θi|i = 1, 2, . . .",2. Preliminaries,[0],[0]
",m}}.",2. Preliminaries,[0],[0]
The sample space is L(A)n.,2. Preliminaries,[0],[0]
Each ranking is generated i.i.d.,2. Preliminaries,[0],[0]
in two steps.,2. Preliminaries,[0],[0]
"First, for each i ≤ m, a latent utility ui is generated from µi(·|~θi) independently, and second, the alternatives are ranked according to their utilities in the descending order.",2. Preliminaries,[0],[0]
"Given a parameter ~θ, the probability of generating R = ai1 ai2 . . .",2. Preliminaries,[0],[0]
"aim is
PrM(R|~θ) = ∫ ∞ −∞ ∫ ∞ uim · · · ∫ ∞ ui2 µim(uim |~θim) · · ·
µi1(ui1 |~θi1)dui1dui2 · · · duim
In this paper, we focus on the location family, where the shapes of the utility distributions are fixed and each utility distribution µi is only parameterized by its mean, denoted by θi.",2. Preliminaries,[0],[0]
Let πi denote the distribution obtained from µi(·|θi) by shifting the mean to 0.,2. Preliminaries,[0],[0]
"For the location family, we have πi(ui|θi) = π(ui − θi).",2. Preliminaries,[0],[0]
"Because shifting the means of all alternatives by the same distance will not affect the distribution of the rankings, w.l.o.g.",2. Preliminaries,[0],[0]
we let θm = 0 throughout the paper.,2. Preliminaries,[0],[0]
"Moreover, we assume that the PDF of each utility distribution is continuous and positive everywhere.",2. Preliminaries,[0],[0]
We further say that an RUM is symmetric if the PDF of each utility distribution is symmetric around its mean.,2. Preliminaries,[0],[0]
"We use Gaussian RUMs to denote the RUMs where all utility distributions are Gaussian.
",2. Preliminaries,[0],[0]
"For any combination of m probability distributions π1, . . .",2. Preliminaries,[0],[0]
", πm whose means are 0, we let RUM(π1, . .",2. Preliminaries,[0],[0]
.,2. Preliminaries,[0],[0]
", πm) denote the RUM location family where the shapes of utility distributions are π1, . . .",2. Preliminaries,[0],[0]
", πm.",2. Preliminaries,[0],[0]
"For any probability distribution π whose mean is 0, let RUM(π) denote the RUM where the shapes of all utility distributions are π.
",2. Preliminaries,[0],[0]
"Given a profile P and a parameter ~θ, we have PrM(P |~θ) = ∏n j=1 PrM(Rj |~θ).",2. Preliminaries,[0],[0]
"Because all utilities are drawn independently, the probability of pairwise comparison is PrM(ai1 ai2 |~θ) =∫∞ −∞ ∫∞",2. Preliminaries,[0],[0]
"ui2 µi1(ui1 |~θ)µi2(ui2 |~θ)dui1dui2 .
",2. Preliminaries,[0],[0]
Example 1 (Plackett-Luce model as an RUM) Let µi(·|θi) be the Gumbel distribution where µi(xi|θi) =,2. Preliminaries,[0],[0]
"e−(xi−θi)−e
−(xi−θi) .",2. Preliminaries,[0],[0]
For any ranking R = ai1 ai2 . . .,2. Preliminaries,[0],[0]
"aim , we have PrPL(R|~θ) = ∏m−1 t=1",2. Preliminaries,[0],[0]
"e θit∑m
l=t e θil
.",2. Preliminaries,[0],[0]
"The probability
of ai1 ai2 under the Plackett-Luce model is PrPL(ai1 ai2 |~θ) =",2. Preliminaries,[0],[0]
"e θi1
e θi1 +e θi2 .
",2. Preliminaries,[0],[0]
"A weighted (rank-)breaking G = {gii′ : i < i′ ≤ m} can be represented by a weighted undirected graph over positions {1, . . .",2. Preliminaries,[0],[0]
",m}, such that for any gii′ > 0, there is an edge between i and i′ whose weight is gii′ .",2. Preliminaries,[0],[0]
"We say that G is uniform, if all weights are the same.",2. Preliminaries,[0],[0]
Let Gu denote the the uniform breaking where all weights are 1.,2. Preliminaries,[0],[0]
"For any 1 ≤ k ≤ m− 1, the position-k breaking is the graph where for any l > k, there is an edge with weight 1 between k and l. For any ~θ ∈ Rm−1, any weighted rank-breaking G, any pair of alternatives ai1 , ai2 , let Gai1 ai2 (R) = gii′ such that ai1 and ai2 are ranked at the ith position and the i
′th position in R, respectively.",2. Preliminaries,[0],[0]
"Given a profile P , we define
κi1i2 = ∑n j=1 Gai1 ai2 (Rj)
n , and let κ̄i1i2 = E[κi1i2 |~θ].",2. Preliminaries,[0],[0]
We note that κi1i2 is a function of the preference profile.,2. Preliminaries,[0],[0]
"κ̄i1i2 is the expected κi1i2 value for perfect data given ~θ, which means that it is a function of the ground truth parameter ~θ.
",2. Preliminaries,[0],[0]
Example 2,2. Preliminaries,[0],[0]
"Let m = 3, n = 2.",2. Preliminaries,[0],[0]
"The profile P = {a1 a2 a3, a3 a2 a1}.",2. Preliminaries,[0],[0]
"Let G = {g12 = g13 = 13 , g23 = 1 2} as shown in Figure 1 (a).",2. Preliminaries,[0],[0]
"Then we have κ12 = κ13 = 1 3/n = 1 6 , κ23 = 1 2/n = 1 4 , κ32 = κ31 = 1 3/n = 1 6 , κ21 = 1 2/n = 1 4 .
",2. Preliminaries,[0],[0]
"Position 1
Position 2
Position 3
 
 
 
1 1
2 2
a1 a2
a3
Position 1
Position 2
Position 3
 
 
 
1 1
2 2
a1 a2
a3
(a) G. (b)W .
",2. Preliminaries,[0],[0]
Figure 1.,2. Preliminaries,[0],[0]
A rank-breaking G and a CML-weight vectorW .,2. Preliminaries,[0],[0]
"LetW = {wii′ : ai,",3. Composite Marginal Likelihood Methods,[0],[0]
ai′ ∈ A} denote a CML-weight vector.,3. Composite Marginal Likelihood Methods,[0],[0]
"We say thatW is symmetric, if for any pair of alternatives ai, ai′ , we have wii′ = wi′i > 0.",3. Composite Marginal Likelihood Methods,[0],[0]
"We say thatW is uniform, if all wii′ ’s are equal.",3. Composite Marginal Likelihood Methods,[0],[0]
"LetWu denote a uniformW .
",3. Composite Marginal Likelihood Methods,[0],[0]
We note that vertices inW corresponds to the alternatives while vertices in G corresponds to positions in a ranking.,3. Composite Marginal Likelihood Methods,[0],[0]
"For example, vertex i inW corresponds to ai, while vertex i in G corresponds to the ith position in a ranking.
",3. Composite Marginal Likelihood Methods,[0],[0]
Example 3,3. Composite Marginal Likelihood Methods,[0],[0]
"A symmetricW is shown in Figure 1 (b), where w12 = w21 = 1 and w23 = w32 = 2.
",3. Composite Marginal Likelihood Methods,[0],[0]
"Given G andW , we propose the rank-breaking-then-CML framework for RUMs, denoted by RBCML(G,W), to be the maximizer of composite log-marginal likelihood, which is defined below.
",3. Composite Marginal Likelihood Methods,[0],[0]
Definition 2 (Composite marginal likelihood for RUMs),3. Composite Marginal Likelihood Methods,[0],[0]
"Given an RUMM, for any preference profile P and any θ, let pi1i2(~θ)",3. Composite Marginal Likelihood Methods,[0],[0]
= PrM(ai1 ai2 |~θ).,3. Composite Marginal Likelihood Methods,[0],[0]
"The composite marginal likelihood is CLM(~θ, P ) = ∏ i1 6=i2(pi1i2(
~θ))κi1i2wi1i2 .",3. Composite Marginal Likelihood Methods,[0],[0]
"The composite log-marginal likelihood becomes:
CLLM(~θ, P ) = ∑ i1 6=i2 κi1i2wi1i2 ln pi1i2( ~θ) (1)
We let RBCML(G,W)(P )",3. Composite Marginal Likelihood Methods,[0],[0]
"= arg max~θ CLLM(~θ, P ).",3. Composite Marginal Likelihood Methods,[0],[0]
"For the Plackett-Luce model the composite (log-)marginal likelihood has a closed-form formula.
",3. Composite Marginal Likelihood Methods,[0],[0]
Definition 3 (CML for Plackett-Luce),3. Composite Marginal Likelihood Methods,[0],[0]
"For any ~θ and preference profile P , the composite marginal likelihood for the Plackett-Luce model is CLPL(~θ, P ) =∏ i1<i2 ( e θi1
e θi1 +e θi2 )",3. Composite Marginal Likelihood Methods,[0],[0]
"κi1i2wi1i2 ( e
θi2 e θi1 +e θi2 )",3. Composite Marginal Likelihood Methods,[0],[0]
κi2i1wi2i1 .,3. Composite Marginal Likelihood Methods,[0],[0]
"The
composite log-marginal likelihood is
CLLPL(~θ, P ) =",3. Composite Marginal Likelihood Methods,[0],[0]
"∑ i1<i2 (κi1i2wi1i2θi1 + κi2i1wi2i1θi2
− (κi1i2wi1i2 + κi2i1wi2i1) ln(eθi1 + eθi2 ))",3. Composite Marginal Likelihood Methods,[0],[0]
"(2)
The first order conditions are, for all i, ∂CLLPL( ~θ,P )",3. Composite Marginal Likelihood Methods,[0],[0]
"∂θi =∑
i′ 6=i(κii′wii′ − (κii′wii′ + κi′iwi′i)",3. Composite Marginal Likelihood Methods,[0],[0]
"eθi eθi+eθi′ ).
",3. Composite Marginal Likelihood Methods,[0],[0]
"Example 4 Continuing Example 2 and Example 3,
CLLPL(~θ, P )",3. Composite Marginal Likelihood Methods,[0],[0]
"= 1
6 θ1 +
1 4 θ2 − ( 1 6 + 1 4 ) ln(eθ1",3. Composite Marginal Likelihood Methods,[0],[0]
"+ eθ2)
+ 1
2 θ2 − (
1 2 + 1 3 ) ln(eθ2",3. Composite Marginal Likelihood Methods,[0],[0]
"+ 1)
",3. Composite Marginal Likelihood Methods,[0],[0]
"By solving the first order conditions, we have eθ1 = 1 and eθ2 = 1.5.",3. Composite Marginal Likelihood Methods,[0],[0]
"So the outcome of RBCML is θ1 = 0, θ2 = ln 1.5.",3. Composite Marginal Likelihood Methods,[0],[0]
We recall that θ3 = 0 in this paper.,3. Composite Marginal Likelihood Methods,[0],[0]
Definition 4 (Log-concavity and strict log-concavity),4. Preservation of Strict Log-Concavity,[0],[0]
A function f(~x) > 0 is log-concave if ∀0 < λ,4. Preservation of Strict Log-Concavity,[0],[0]
"< 1, we have f(λ~x +",4. Preservation of Strict Log-Concavity,[0],[0]
(,4. Preservation of Strict Log-Concavity,[0],[0]
1 − λ)~y) ≥ f(~x)λf(~y)1−λ.,4. Preservation of Strict Log-Concavity,[0],[0]
"If the inequality is always strict, then f is strictly log-concave.
",4. Preservation of Strict Log-Concavity,[0],[0]
"Theorem 1 (Preservation under convolution) Let f(x) and g(x) be two continuous and strictly log-concave functions on R. Then f ∗ g is also strictly log-concave.
",4. Preservation of Strict Log-Concavity,[0],[0]
Proof: The proof is done by examining the equality condition for the Prékopa-Leindler inequality.,4. Preservation of Strict Log-Concavity,[0],[0]
"Let h = f ∗ g, namely, for any y ∈ R, h(y) = ∫ R f(y",4. Preservation of Strict Log-Concavity,[0],[0]
− x)g(x)dx.,4. Preservation of Strict Log-Concavity,[0],[0]
"Because f and g are continuous, so does h. To prove the strict log-concavity of h, it suffices to prove that for any different y1, y2 ∈ R, h(y1+y22 )",4. Preservation of Strict Log-Concavity,[0],[0]
>,4. Preservation of Strict Log-Concavity,[0],[0]
"√ h(y1)h(y2).
",4. Preservation of Strict Log-Concavity,[0],[0]
Suppose for the sake of contradiction that this is not true.,4. Preservation of Strict Log-Concavity,[0],[0]
"Since log-concavity preserves under convolution (Saumard & Wellner, 2014), h is log-concave.",4. Preservation of Strict Log-Concavity,[0],[0]
"So, there exist y1 < y2 such that h(y1+y22 )",4. Preservation of Strict Log-Concavity,[0],[0]
=,4. Preservation of Strict Log-Concavity,[0],[0]
√ h(y1)h(y2).,4. Preservation of Strict Log-Concavity,[0],[0]
"Let Λ(x, y) = f(y",4. Preservation of Strict Log-Concavity,[0],[0]
− x)g(x).,4. Preservation of Strict Log-Concavity,[0],[0]
"We further define
H(x) = Λ(x, y1 + y2
2 ) =",4. Preservation of Strict Log-Concavity,[0],[0]
f( y1 + y2 2,4. Preservation of Strict Log-Concavity,[0],[0]
"− x)g(x)
F (x) = Λ(x, y1) = f(y1",4. Preservation of Strict Log-Concavity,[0],[0]
− x)g(x) G(x),4. Preservation of Strict Log-Concavity,[0],[0]
"= Λ(x, y2) =",4. Preservation of Strict Log-Concavity,[0],[0]
"f(y2 − x)g(x)
",4. Preservation of Strict Log-Concavity,[0],[0]
"Because (non-strict) log-concavity is preserved under convolution, Λ(x, y) is log-concave.",4. Preservation of Strict Log-Concavity,[0],[0]
"We have that for any x ∈ R, H(x) ≥ √ F (x)G(x).",4. Preservation of Strict Log-Concavity,[0],[0]
"The Prékopa-Leindler inequality asserts that∫ R H(x)dx ≥ √∫ R F (x)dx ∫ R G(x)dx (3) Because h(y1+y22 ) = ∫ RH(x)dx, h(y1) = ∫ R F (x)dx,
h(y2) = ∫",4. Preservation of Strict Log-Concavity,[0],[0]
"RG(x)dx, and h( y1+y2 2 ) =",4. Preservation of Strict Log-Concavity,[0],[0]
"√ h(y1)h(y2), (3) becomes an equation.",4. Preservation of Strict Log-Concavity,[0],[0]
It was proved by Dubuc (1977) that: there exist a > 0 and b ∈ R such that the following conditions hold almost everywhere for x ∈ R (see the translation of Dubuc’s result in English by Ball & Böröczky (2010)).,4. Preservation of Strict Log-Concavity,[0],[0]
1.,4. Preservation of Strict Log-Concavity,[0],[0]
"F (x) = aH(x+ b), 2. G(x)",4. Preservation of Strict Log-Concavity,[0],[0]
"= a−1H(x− b).
",4. Preservation of Strict Log-Concavity,[0],[0]
"The first condition means that for almost every x ∈ R,
f(y1 − x)g(x) = af( y1 + y2
2 − x−",4. Preservation of Strict Log-Concavity,[0],[0]
"b)g(x+ b)
⇐⇒ g(x) g(x+",4. Preservation of Strict Log-Concavity,[0],[0]
"b)
",4. Preservation of Strict Log-Concavity,[0],[0]
"= a f(y1+y22 − x− b)
f(y1 − x) (4)
",4. Preservation of Strict Log-Concavity,[0],[0]
"The second condition means that for almost all x ∈ R, f(y2 − x)g(x) = a−1f(y1+y22",4. Preservation of Strict Log-Concavity,[0],[0]
− x + b)g(x − b) ⇐⇒ g(x−b) g(x) = a f(y2−x) f,4. Preservation of Strict Log-Concavity,[0],[0]
( y1+y2 2 −x+b) .,4. Preservation of Strict Log-Concavity,[0],[0]
"Therefore, for almost all x ∈ R,
g(x)
g(x+ b) = a f(y2 − x− b) f(y1+y22",4. Preservation of Strict Log-Concavity,[0],[0]
"− x)
(5)
Combining (4) and (5), for almost every x ∈ R we have
g(x)
g(x+ b) = a f(y2 − x− b) f(y1+y22",4. Preservation of Strict Log-Concavity,[0],[0]
− x) = a f(y1+y22 − x− b) f(y1,4. Preservation of Strict Log-Concavity,[0],[0]
"− x) (6)
",4. Preservation of Strict Log-Concavity,[0],[0]
"Because f(x) is strictly log-concave, for any fixed c 6= 0, f(x+c) f(x) is strictly monotonic.",4. Preservation of Strict Log-Concavity,[0],[0]
Because y1 6= y2 and y2−x− b− (y1+y22 − x) = y1+y2 2,4. Preservation of Strict Log-Concavity,[0],[0]
− x− b− (y1− x) = y2−y1 2,4. Preservation of Strict Log-Concavity,[0],[0]
"− b, we must have that y2−y12",4. Preservation of Strict Log-Concavity,[0],[0]
"− b = 0, namely b = y2−y1
2 .",4. Preservation of Strict Log-Concavity,[0],[0]
"Therefore, (6) becomes g(x)
g(x+ y2−y1",4. Preservation of Strict Log-Concavity,[0],[0]
2 ) =,4. Preservation of Strict Log-Concavity,[0],[0]
"a for almost every
x ∈ R, which contradicts the strict log-concavity of g.",4. Preservation of Strict Log-Concavity,[0],[0]
This means that h = f ∗,4. Preservation of Strict Log-Concavity,[0],[0]
"g is strictly log-concave.
",4. Preservation of Strict Log-Concavity,[0],[0]
"Theorem 2 (Preservation under marginalization) Let h(x, y) be a strictly log-concave function on R2.",4. Preservation of Strict Log-Concavity,[0],[0]
"Then∫ R h(x, y)dx is strictly log-concave on R.
Again, the proof is done by examining the equality condition for the Prékopa-Leindler inequality.",4. Preservation of Strict Log-Concavity,[0],[0]
All missing proofs can be found in the supplementary material.,4. Preservation of Strict Log-Concavity,[0],[0]
"For any profile P , let G(P ) denote the weighted directed graph where each represents an alternative.",5. Strict Log-Concavity of CML,[0],[0]
"For any 1 ≤ i 6= i′ ≤ m, the weight on the edge from i to i′ is κii′ .",5. Strict Log-Concavity of CML,[0],[0]
"A weighted directed graph is (weakly) connected, if after removing the directions on all edges, the resulting undirected graph is connected.",5. Strict Log-Concavity of CML,[0],[0]
"A weighted directed graph is strongly connected, if there is a directed path with positive weights between any pair of vertices.",5. Strict Log-Concavity of CML,[0],[0]
"Given any pair of weighted graphs G1 and G2, we let G1 ⊗ G2 denote the weighted graph where the weights on each edge is the multiplication of the weights of same edge in G1 and G2.
Theorem 3",5. Strict Log-Concavity of CML,[0],[0]
"Given any profile P , the composite likelihood function for Plackett-Luce, i.e. CLPL(~θ, P ), is strictly logconcave if and only if W ⊗ G(P ) is weakly connected.",5. Strict Log-Concavity of CML,[0],[0]
"arg max~θ CLPL(
~θ, P ) is bounded if and only ifW ⊗G(P ) is strongly connected.
",5. Strict Log-Concavity of CML,[0],[0]
"The proof is similar to the log-concavity of likelihood for BTL by (Hunter, 2004).",5. Strict Log-Concavity of CML,[0],[0]
"For general RUMs we prove a similar theorem.
",5. Strict Log-Concavity of CML,[0],[0]
Theorem 4 Let M be an RUM where the CDF of each utility distribution is strictly log-concave.,5. Strict Log-Concavity of CML,[0],[0]
"Given any profile P , the composite likelihood function forM, i.e. CLM(~θ, P ), is strictly log-concave if and only ifW ⊗G(P ) is weakly connected.",5. Strict Log-Concavity of CML,[0],[0]
"arg max~θ CLM(
~θ, P ) is bounded if and only if W ⊗G(P ) is strongly connected.
",5. Strict Log-Concavity of CML,[0],[0]
"Proof sketch: It is not hard to check that whenW ⊗G(P ) is not connected, there exist ~θ(1) and ~θ(2) such that for any 0 <",5. Strict Log-Concavity of CML,[0],[0]
"λ < 1 we have CLLPL(~θ(1), P ) = CLLPL(~θ(2), P ) = λCLLPL(~θ(1), P ) +",5. Strict Log-Concavity of CML,[0],[0]
"(1−λ)CLLPL(~θ(2), P ), which violates strict log-concavity.",5. Strict Log-Concavity of CML,[0],[0]
"Suppose W ⊗ G(P ) is weakly connected, it suffices to prove for any i1 6= i2, Pr(ai1 ai2 |~θ) is strictly log-concave.",5. Strict Log-Concavity of CML,[0],[0]
We can write this as an integral over ui2 − ui1 : Pr(ui1,5. Strict Log-Concavity of CML,[0],[0]
> ui2 |~θ) =,5. Strict Log-Concavity of CML,[0],[0]
∫∞ 0,5. Strict Log-Concavity of CML,[0],[0]
Pr(ui2,5. Strict Log-Concavity of CML,[0],[0]
"− ui1 = s|~θ)ds.
",5. Strict Log-Concavity of CML,[0],[0]
"Let π∗i2(·|~θ) denote the flipped distribution of πi2(·|~θ) around x = s, then we have π∗i2(s − x|~θ)",5. Strict Log-Concavity of CML,[0],[0]
= πi2(s + x|~θ).,5. Strict Log-Concavity of CML,[0],[0]
"Further we have Pr(ui1 > ui2 |~θ) =∫∞
0 ∫∞ −∞ πi1(x|θi1)πi2(x+ s|θi2)dxds = ∫∞ 0 πi1 ∗ π∗i2ds.",5. Strict Log-Concavity of CML,[0],[0]
"By Theorem 1, πi1 ∗ π∗i2 is strictly log-concave.",5. Strict Log-Concavity of CML,[0],[0]
"Then we prove that tail probability of a strictly log-concave distribution is also strictly log-concave.
",5. Strict Log-Concavity of CML,[0],[0]
The proof for boundedness is similar to the proof of a similar condition for BTL by Hunter (2004).,5. Strict Log-Concavity of CML,[0],[0]
"Given any RUM M and any parameter ~θ, we define ELLM(~θ)",6. Asymptotic Properties of RBCML,[0],[0]
"= E[CLLM(~θ,R)] and let ∇ELLM(~θ) be the gradient of ELLM(~θ), whose ith element is∇iELLM(~θ) =∑ i′ 6=i( κ̄ii′wii′
pii′ ( ~θ)
∂pii′ ( ~θ)
∂θi + κ̄i′iwi′i
pi′i( ~θ)
∂pi′i( ~θ)
∂θi ).",6. Asymptotic Properties of RBCML,[0],[0]
"Let H(~θ, P ) be
the Hessian matrix evaluated at ~θ.",6. Asymptotic Properties of RBCML,[0],[0]
"And let H0(~θ0) denote the expected Hessian of CLLM(~θ, P ) at ~θ0, where ~θ0 is the ground truth parameter.
",6. Asymptotic Properties of RBCML,[0],[0]
Theorem 5 (Consistency and asymptotic normality),6. Asymptotic Properties of RBCML,[0],[0]
"Given any RUM M, any ~θ0 and any profile P with n rankings.",6. Asymptotic Properties of RBCML,[0],[0]
"Let ~θ∗ be the output of RBCML(G,W).",6. Asymptotic Properties of RBCML,[0],[0]
"When n→∞, we have ~θ∗ p−→ ~θ0 and √ n(~θ∗",6. Asymptotic Properties of RBCML,[0],[0]
"− ~θ0) d−→ N(0, H−10 (~θ0)Var[∇CLLM(~θ0, R)]H −1 0 ( ~θ0))",6. Asymptotic Properties of RBCML,[0],[0]
"if and only if ~θ0 is the only solution to
∇ELLM(~θ) = ~0, (7)
Proof: The “only if"" direction is straightforward.",6. Asymptotic Properties of RBCML,[0],[0]
"The solution to (7) is unique because CLLM(~θ, P ) is strictly concave.",6. Asymptotic Properties of RBCML,[0],[0]
"Suppose ~θ1, other than ~θ0, is the solution to (7), then
when n → ∞, ~θ1 will be the estimate of RBCML(G,W), which means RBCML(G,W) is not consistent.
",6. Asymptotic Properties of RBCML,[0],[0]
"Now we prove the “if"" direction.",6. Asymptotic Properties of RBCML,[0],[0]
First we prove consistency.,6. Asymptotic Properties of RBCML,[0],[0]
"It is required by Xu & Reid (2011) that for different parameters, the probabilities for any composite likelihood event are different, which is not true in our case.",6. Asymptotic Properties of RBCML,[0],[0]
"A simple counterexample is θ(1)1 = 1, θ (2) 1 = 2, θ (1) 2 = θ (1) 3 = θ (2) 2 = θ (2) 3 = 0.",6. Asymptotic Properties of RBCML,[0],[0]
Then Pr(a2 a3|~θ(1)),6. Asymptotic Properties of RBCML,[0],[0]
"= Pr(a2 a3|~θ(2)).
",6. Asymptotic Properties of RBCML,[0],[0]
"By the law of large numbers, we have for any , Pr(|CLLM(~θ, P )",6. Asymptotic Properties of RBCML,[0],[0]
− ELLM(~θ)| ≤ /2),6. Asymptotic Properties of RBCML,[0],[0]
→ 1 as n → ∞.,6. Asymptotic Properties of RBCML,[0],[0]
"This implies limn→∞ Pr(CLLM(~θ∗, P ) ≤ ELLM(~θ∗) + /2)",6. Asymptotic Properties of RBCML,[0],[0]
= 1.,6. Asymptotic Properties of RBCML,[0],[0]
Similarly we have limn→∞ Pr(ELLM(~θ0) ≤,6. Asymptotic Properties of RBCML,[0],[0]
"CLLM(~θ0, P ) + /2)",6. Asymptotic Properties of RBCML,[0],[0]
= 1.,6. Asymptotic Properties of RBCML,[0],[0]
"Since ~θ∗ maximize CLLM(~θ, P ), we have Pr(CLLM(~θ0, P ) ≤",6. Asymptotic Properties of RBCML,[0],[0]
"CLLM(~θ∗, P ))",6. Asymptotic Properties of RBCML,[0],[0]
= 1.,6. Asymptotic Properties of RBCML,[0],[0]
The above three equations imply that limn→∞ Pr(ELLM(~θ0)− ELLM(~θ∗) ≤ ),6. Asymptotic Properties of RBCML,[0],[0]
"= 1.
",6. Asymptotic Properties of RBCML,[0],[0]
Let Θ be the subset of parameter space s.t.,6. Asymptotic Properties of RBCML,[0],[0]
"∀~θ ∈ Θ , ELLM(~θ0)− ELLM(~θ) ≤ .",6. Asymptotic Properties of RBCML,[0],[0]
"Because ELLM(~θ) is strictly concave, Θ is compact and has a unique maximum at ~θ0.",6. Asymptotic Properties of RBCML,[0],[0]
"Thus for any > 0, limn→∞ Pr(~θ∗ ∈ Θ ) = 1.",6. Asymptotic Properties of RBCML,[0],[0]
"This implies consistency, i.e., ~θ∗ p−→ ~θ0.
",6. Asymptotic Properties of RBCML,[0],[0]
Now we prove asymptotic normality.,6. Asymptotic Properties of RBCML,[0],[0]
"By mean value theorem, we have 0 = ∇CLLM(~θ∗, P ) = ∇CLLM(~θ0, P ) + H(α~θ∗ + (1 − α)~θ0, P )(~θ∗ − ~θ0), where 0 ≤ α ≤ 1.",6. Asymptotic Properties of RBCML,[0],[0]
"Therefore, we have √ n(~θ∗",6. Asymptotic Properties of RBCML,[0],[0]
"− ~θ) = −H−1(α~θ∗ + (1 − α)~θ0, P )( √ n∇CLLM(~θ0, P )).",6. Asymptotic Properties of RBCML,[0],[0]
"Since ∇CLLM(~θ0, P ) = 1 n ∑n j=1∇CLLM(~θ0, Rj), by the central limit theorem, we have √ n∇CLLM(~θ0, P )",6. Asymptotic Properties of RBCML,[0],[0]
"d−→ N(0,Var[∇CLLM(~θ0, R)])
",6. Asymptotic Properties of RBCML,[0],[0]
"Because ~θ∗ p−→ ~θ0 and H is continuous, we have H(α~θ∗ + (1 − α)~θ0, P ) p−→ H(~θ0, P ).",6. Asymptotic Properties of RBCML,[0],[0]
"Since H(~θ, P ) = 1 n ∑n j=1H",6. Asymptotic Properties of RBCML,[0],[0]
"( ~θ,Rj), by law of large numbers, we have H(~θ, P ) p−→ H0(~θ0).",6. Asymptotic Properties of RBCML,[0],[0]
"Therefore, we have
√ n(~θ∗",6. Asymptotic Properties of RBCML,[0],[0]
"− ~θ) = −H−10 (~θ0)( √ n∇CLLM(~θ0, P )),
which implies that Var[ √ n(~θ∗",6. Asymptotic Properties of RBCML,[0],[0]
"− ~θ)] = H−10 ( ~θ0)Var[∇CLLM(~θ0, R)]H−10 (~θ0).",6. Asymptotic Properties of RBCML,[0],[0]
"Formal proofs of theorems in this section depends on a series of lemmas, which can be found in the appendix.",7. Consistency of RBCML,[0],[0]
"The full proofs can also be found in the appendix.
",7. Consistency of RBCML,[0],[0]
"Theorem 6 RBCML(G,Wu) is consistent for PlackettLuce if and only if the breaking is weighted union of positionk breakings.
",7. Consistency of RBCML,[0],[0]
Proof sketch:,7. Consistency of RBCML,[0],[0]
"The “if"" direction is proved in (Khetan & Oh,
2016b).",7. Consistency of RBCML,[0],[0]
"We only prove the “only if"" direction by induction on m. When m = 2, the only breaking is the comparison between the two alternatives.",7. Consistency of RBCML,[0],[0]
"The conclusion holds.
",7. Consistency of RBCML,[0],[0]
"Suppose it holds for m = l, then when m = l + 1, we first prove a lemma which says that by restricting G to any set of continuous positions, the theorem must hold for the subgraph.",7. Consistency of RBCML,[0],[0]
"Then, we focus on G[2,m], which is the subgraph of G on {2,. . .",7. Consistency of RBCML,[0],[0]
",m}.",7. Consistency of RBCML,[0],[0]
"G[2,m] must be a weighted union of position-k breakings.",7. Consistency of RBCML,[0],[0]
"Then we focus on G[1,m−1].",7. Consistency of RBCML,[0],[0]
"The only remaining case is to prove that the weight on edge {1,m} is the same as the weight on edges {1, i} for all i ≤ m− 1.
",7. Consistency of RBCML,[0],[0]
"Suppose for the sake of contradiction this is not true, then we can subtract a weighted union of position-k breakings from the graph, so that the remaining graph has a single edge {1,m}.",7. Consistency of RBCML,[0],[0]
"We then prove that such an single-edge breaking is inconsistent by proving that (7) is not satisfied, which leads to a contradiction.
",7. Consistency of RBCML,[0],[0]
"Theorem 7 Let π1, π2, . . .",7. Consistency of RBCML,[0],[0]
", πm denote the utility distributions for a symmetric RUM.",7. Consistency of RBCML,[0],[0]
"Suppose there exists πi s.t. (1) (lnπi(x))′ is monotonically decreasing, and (2) limx→−∞(lnπi(x))
′ →∞.",7. Consistency of RBCML,[0],[0]
"Then, RBCML(G,Wu) is consistent if and only if G is uniform.
",7. Consistency of RBCML,[0],[0]
Proof sketch: Define the single-edge breaking G1 = {g1m = 1}.,7. Consistency of RBCML,[0],[0]
"We first prove RBCML(G1,Wu) is not consistent.",7. Consistency of RBCML,[0],[0]
Then we prove the theorem by induction on m. m = 2 is trivial because the only breaking is uniform.,7. Consistency of RBCML,[0],[0]
"For m = 3, we first prove that the single-edge breaking G1 = {g13 = 1} is not consistent.",7. Consistency of RBCML,[0],[0]
"Suppose the breaking is G = {g12 = x, g23 = y, g13 = z}.",7. Consistency of RBCML,[0],[0]
"Let G∗ = {g12 = y, g23 = x, g13 = z}.",7. Consistency of RBCML,[0],[0]
"We prove that RBCML(G∗,Wu) is consistent forM∗, which is the RUM obtained fromM by flipping the shapes of the utility distributions.",7. Consistency of RBCML,[0],[0]
"BecauseM is symmetric, we haveM∗ = M.",7. Consistency of RBCML,[0],[0]
"Then we prove that RBCML(G + G∗,Wu) is consistent.",7. Consistency of RBCML,[0],[0]
"If x+ y < 2z, We subtract (x+ y)Gu from G + G∗",7. Consistency of RBCML,[0],[0]
"and get a consistent breaking (2z − (x+ y))G1, which is a contradiction.",7. Consistency of RBCML,[0],[0]
"For the case where x+ y = 2z we use the premise in the theorem statement to directly prove that the breaking is inconsistent.
",7. Consistency of RBCML,[0],[0]
Suppose the theorem holds for m = k.,7. Consistency of RBCML,[0],[0]
"When m = k + 1, W.l.o.g.",7. Consistency of RBCML,[0],[0]
"we let π2 satisfy the conditions that (lnπi(x))′ is monotonically decreasing and limx→−∞(lnπi(x))′ →∞. Let θ1 = L, θm = −L, and θ2 = . . .",7. Consistency of RBCML,[0],[0]
= θm−1 = 0.,7. Consistency of RBCML,[0],[0]
"So when L→∞, with probability goes to 1, a1 is ranked at the top and am is ranked at the bottom.",7. Consistency of RBCML,[0],[0]
"We then focus on G[2,m] and G[1,m−1].",7. Consistency of RBCML,[0],[0]
"By induction hypothesis, G[2,m] (respectively, G[1,m−1]) is either uniform or empty.",7. Consistency of RBCML,[0],[0]
"If G[2,m] is empty, then G[1,m−1] is also empty.",7. Consistency of RBCML,[0],[0]
"Because G is nonempty, we must have G = CG1, where C > 0.",7. Consistency of RBCML,[0],[0]
This is a contradiction.,7. Consistency of RBCML,[0],[0]
"If G[2,m] is uniform but G is not uniform, then the single edge breaking G1 must be consistent, which is a contradiction.
",7. Consistency of RBCML,[0],[0]
"Corollary 1 Theorem 7 holds for any RUM with symmetric distributions where any single distribution is Gaussian.
",7. Consistency of RBCML,[0],[0]
"The following two theorems give stronger characterizations by leveraging Theorems 6 and 7.
",7. Consistency of RBCML,[0],[0]
"Theorem 8 RBCML(G,W) for Plackett-Luce is consistent if and only if G is the weighted union of position-k breakings andW is connected and symmetric.
",7. Consistency of RBCML,[0],[0]
Theorem 9 Let π be any symmetric distribution that satisfies the condition in Theorem 7.,7. Consistency of RBCML,[0],[0]
"Then RBCML(G,W) is consistent for RUM(π) if and only if G is uniform andW is connected and symmetric.
",7. Consistency of RBCML,[0],[0]
The proofs for Theorems 8 and 9 are similar.,7. Consistency of RBCML,[0],[0]
"The “if"" direction can be proved by verifying that the ground truth parameter is the solution to (7).",7. Consistency of RBCML,[0],[0]
"For the “only if"" direction, we first prove that consistency of RBCML(G,W) implies consistency of RBCML(G,Wu), which further implies G is the weighted union of position-k breakings for PLs (Theorem 6) or uniform breaking for RUMs (Theorem 7).",7. Consistency of RBCML,[0],[0]
"Given this condition on G, we prove that W must be connected and symmetric.",7. Consistency of RBCML,[0],[0]
The asymptotic covariance of RBCML depends on G and W .,8. The RBCML Framework,[0],[0]
"The optimal G and W depend on the ground truth parameter ~θ02, which is exactly what we want.",8. The RBCML Framework,[0],[0]
"To tackle this problem, we propose the adaptive RBCML framework, guided by our Theorems 8 and 9 and shown as Algorithm
2Khetan & Oh (2016b) proposed a breaking G, which is not a function of ~θ0.
1.",8. The RBCML Framework,[0],[0]
"In this algorithm, G andW are iteratively updated given the estimate of ~θ from the previous iteration.",8. The RBCML Framework,[0],[0]
"Algorithm 1 Adaptive RBCML Input: Profile P of n rankings, the number of iterations T , the heuristics of breaking G(~θ) and the weightsW(~θ).",8. The RBCML Framework,[0],[0]
"Output: Estimated parameter ~θ∗. Initialize ~θ(0) = ~0
1: for t = 1 to T do 2: Compute G(~θ(t−1))",8. The RBCML Framework,[0],[0]
andW(~θ(t−1)).,8. The RBCML Framework,[0],[0]
"3: Estimate ~θ(t) using G(~θ(t−1)) and W(~θ(t−1)) by maximizing (1) (or (2) for Plackett-Luce) 4: end for
No efficient way of computing the optimal G(~θ) andW(~θ) is known since the asymptotic covariance is generally hard to compute, where an expectation is taken over m! rankings.",8. The RBCML Framework,[0],[0]
How to efficiently compute the optimal G andW is a promising future direction.,8. The RBCML Framework,[0],[0]
"In the experiments of this paper, we use Gu andWu for Gaussian RUMs since Gu is the only consistent breaking.",8. The RBCML Framework,[0],[0]
"For the Plackett-Luce model, we use the G proposed by Khetan & Oh (2016b) and a heuristic W(~θ) (See Section 9).",8. The RBCML Framework,[0],[0]
We compare RBCML with state-of-the-art algorithms for both Gaussian RUMs (GMM algorithm by Azari Soufiani et al. (2014)) and the Plackett-Luce model (the I-LSR algorithm by Maystre & Grossglauser (2015) and the consistent rank-breaking algorithm by Khetan & Oh (2016b)).,9. Experiments,[0],[0]
"In both experiments, we generate synthetic datasets of full rankings over m = 10 alternatives.",9. Experiments,[0],[0]
"The ground truth parameter is generated uniformly at random between 0 and 5 and shifted
s.t. θ10 = 0.",9. Experiments,[0],[0]
"For Gaussian RUMs, the utility distribution of ai is N(θi, 1).",9. Experiments,[0],[0]
"The results are averaged over 50000 trials.
",9. Experiments,[0],[0]
Metrics.,9. Experiments,[0],[0]
"We measure statistical efficiency by n × MSE, where n is the number of rankings in the dataset.",9. Experiments,[0],[0]
"We use n×MSE rather than the standard MSE, because it is easier to see the difference between algorithms w.r.t.",9. Experiments,[0],[0]
the former.,9. Experiments,[0],[0]
"The reason is that n×MSE approaches a positive constant as n → ∞, due to asymptotic normality of RBCML.",9. Experiments,[0],[0]
"We use running time to measure computational efficiency of each algorithm.
",9. Experiments,[0],[0]
Gaussian RUMs.,9. Experiments,[0],[0]
"We use a one-step (T = 1 in Algorithm 1) RBCML(Gu,Wu) for Gaussian RUMs and the results are shown in Figure 3.",9. Experiments,[0],[0]
"We use uniform breaking rather than other breakings because it is the only consistent breaking according to our theoretical results.
",9. Experiments,[0],[0]
We observe that our RBCML outperforms the GMM algorithm by Azari Soufiani et al. (2014) w.r.t.,9. Experiments,[0],[0]
"both statistical efficiency and computational efficiency.
",9. Experiments,[0],[0]
The Plackett-Luce Model.,9. Experiments,[0],[0]
"We use a two-step (T = 2 in Algorithm 1) RBCML, where the first step is exactly the algorithm by Khetan & Oh (2016b) (denoted by K-O Breaking).",9. Experiments,[0],[0]
"In the second step, we still use the breaking by Khetan & Oh (2016b) but propose a heuristicW(~θ).",9. Experiments,[0],[0]
"For any pair of alternatives ai1 and ai2 , we let wi1i2 =",9. Experiments,[0],[0]
"wi2i1 = 1 |θi1−θi2 |+4
.",9. Experiments,[0],[0]
The intuition is that we should put a higher weight on the pair of alternatives that are closer to each other.,9. Experiments,[0],[0]
"Moreover, we use the output of the first step as the starting point of the second step optimization to improve computational efficiency.
",9. Experiments,[0],[0]
The results are shown in Figure 2.,9. Experiments,[0],[0]
We use 2-LSR to denote the two-iteration I-LSR algorithms by Maystre & Grossglauser (2015).,9. Experiments,[0],[0]
"LSR (one-iteration I-LSR) results are not
shown because of the high n×MSE and runtime for large n.",9. Experiments,[0],[0]
"The “CR bound"" line is n times the trace of Cramér-Rao bound (Cramér, 1946; Rao, 1945), which is the lower bound of the covariance matrix of any unbiased estimator.",9. Experiments,[0],[0]
"Because Cramér-Rao bound decreases at the rate of 1/n, the CR bound line is horizontal.",9. Experiments,[0],[0]
"Since RBCML is not necessarily unbiased, the Cramér-Rao bound is not a lower bound for RBCML.
",9. Experiments,[0],[0]
"We observe that on datasets with large numbers of rankings (“ "" means “is better than""): • Statistical efficiency: 2-LSR RBCML K-O Breaking.",9. Experiments,[0],[0]
"• Runtime: K-O Breaking RBCML 2-LSR.
",9. Experiments,[0],[0]
Beyond the experiments.,9. Experiments,[0],[0]
We have only shown the RBCML with simple G andW .,9. Experiments,[0],[0]
Other configurations of G andW can potentially have better performances or achieve other tradeoffs.,9. Experiments,[0],[0]
"Exploring RBCMLs for Gaussian RUMs, the Plackett-Luce model, as well as other RUMs is an interesting direction for future work.",9. Experiments,[0],[0]
We propose a flexible rank-breaking-then-compositemarginal-likelihood (RBCML) framework for learning RUMs.,10. Summary and Future Work,[0],[0]
"We characterize conditions for the objective function to be strictly log-concave, and for RBCML to be consistent and asymptotically normal.",10. Summary and Future Work,[0],[0]
"Experiments show that RBCML for Gaussian RUMs improve both statistical efficiency and computational efficiency, and the proposed RBCML for the Plackett-Luce model is competitive against state-of-the-art algorithms in that it provides a tradeoff between statistical efficiency and computational efficiency.",10. Summary and Future Work,[0],[0]
"For future work we plan to find efficient ways to compute optimal choices of G andW , and to extend the algorithm to partial orders.",10. Summary and Future Work,[0],[0]
We thank all anonymous reviewers for helpful comments and suggestions.,Acknowledgments,[0],[0]
This work is supported by NSF #1453542 and ONR #N00014-17-1-2621.,Acknowledgments,[0],[0]
"We propose a novel and flexible rank-breakingthen-composite-marginal-likelihood (RBCML) framework for learning random utility models (RUMs), which include the Plackett-Luce model.",abstractText,[0],[0]
We characterize conditions for the objective function of RBCML to be strictly log-concave by proving that strict log-concavity is preserved under convolution and marginalization.,abstractText,[0],[0]
We characterize necessary and sufficient conditions for RBCML to satisfy consistency and asymptotic normality.,abstractText,[0],[0]
Experiments on synthetic data show that RBCML for Gaussian RUMs achieves better statistical efficiency and computational efficiency than the state-of-the-art algorithm and our RBCML for the Plackett-Luce model provides flexible tradeoffs between running time and statistical efficiency.,abstractText,[0],[0]
Composite Marginal Likelihood Methods for Random Utility Models,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 185–196 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
185",text,[0],[0]
"Grammar, as per a common metaphor, gives speakers of a language a shared toolbox to construct and deconstruct meaningful and fluent utterances.",1 Introduction,[0],[0]
"Being highly analytic, English relies heavily on word order and closed-class function words like prepositions, determiners, and conjunctions.",1 Introduction,[0],[0]
"Though function words bear little semantic content, they are nevertheless crucial to the meaning.",1 Introduction,[0],[0]
"Consider prepositions: they serve, for example, to convey place and time (We met at/in/outside the restaurant for/after an hour), to express configurational relationships like quantity, possession, part/whole, and membership (the coats of dozens of children in the class), and to indicate semantic roles in argument structure (Grandma cooked dinner for the children
∗nathan.schneider@georgetown.edu
vs. Grandma cooked the children for dinner).",1 Introduction,[0],[0]
"Frequent prepositions like for are maddeningly polysemous, their interpretation depending especially on the object of the preposition—I rode the bus for 5 dollars/minutes—and the governor of the prepositional phrase (PP): I Ubered/asked for $5.",1 Introduction,[0],[0]
Possessives are similarly ambiguous: Whistler’s mother/painting/hat/death.,1 Introduction,[0],[0]
"Semantic interpretation requires some form of sense disambiguation, but arriving at a linguistic representation that is flexible enough to generalize across usages and types, yet simple enough to support reliable annotation, has been a daunting challenge (§2).
",1 Introduction,[0],[0]
This work represents a new attempt to strike that balance.,1 Introduction,[0],[0]
"Building on prior work, we argue for an approach to describing English preposition and possessive semantics with broad coverage.",1 Introduction,[0],[0]
"Given the semantic overlap between prepositions and possessives (the hood of the car vs. the car’s hood or its hood), we analyze them using the same inventory of semantic labels.1",1 Introduction,[0],[0]
"Our contributions include:
• a new hierarchical inventory (“SNACS”) of 50 supersense classes, extensively documented in guidelines for English (§3); • a gold-standard corpus with comprehensive annotations: all types and tokens of prepositions and possessives are disambiguated (§4; example sentences appear in figure 1); • an interannotator agreement study that
1Some uses of certain other closed-class markers— intransitive particles, subordinators, infinitive to—are also included (§3.1).
shows the scheme is reliable and generalizes across genres—and for the first time demonstrating empirically that the lexical semantics of a preposition can sometimes be detached from the PP’s semantic role (§5); • disambiguation experiments with two supervised classification architectures to establish the difficulty of the task (§6).",1 Introduction,[0],[0]
"Studies of preposition semantics in linguistics and cognitive science have generally focused on the domains of space and time (e.g., Herskovits, 1986; Bowerman and Choi, 2001; Regier, 1996; Khetarpal et al., 2009; Xu and Kemp, 2010; Zwarts and Winter, 2000) or on motivated polysemy structures that cover additional meanings beyond core spatial senses (Brugman, 1981; Lakoff, 1987; Tyler and Evans, 2003; Lindstromberg, 2010).",2 Background: Disambiguation of Prepositions and Possessives,[0],[0]
"Possessive constructions can likewise denote a number of semantic relations, and various factors—including semantics—influence whether attributive possession in English will be expressed with of, or with ’s and possessive pronouns (the ‘genitive alternation’; Taylor, 1996; Nikiforidou, 1991; Rosenbach, 2002; Heine, 2006; Wolk et al., 2013; Shih et al., 2015).
",2 Background: Disambiguation of Prepositions and Possessives,[0],[0]
"Corpus-based computational work on semantic disambiguation specifically of prepositions and possessives2 falls into two categories: the lexicographic/word sense disambiguation approach (Litkowski and Hargraves, 2005, 2007; Litkowski, 2014; Ye and Baldwin, 2007; Saint-Dizier, 2006; Dahlmeier et al., 2009; Tratz and Hovy, 2009; Hovy et al., 2010, 2011; Tratz and Hovy, 2013), and the semantic class approach (Moldovan et al., 2004; Badulescu and Moldovan, 2009; O’Hara and Wiebe, 2009; Srikumar and Roth, 2011, 2013; Schneider et al., 2015, 2016; Hwang et al., 2017, see also Müller et al., 2012 for German).",2 Background: Disambiguation of Prepositions and Possessives,[0],[0]
"The lexicographic approach can capture finer-grained meaning distinctions, at a risk of relying upon idiosyncratic and potentially incomplete dictionary definitions.",2 Background: Disambiguation of Prepositions and Possessives,[0],[0]
"The semantic class approach, which we follow here, focuses on commonalities in meaning across multiple lexical items, and aims to general-
2Of course, meanings marked by prepositions/possessives are to some extent captured in predicate-argument or graphbased meaning representations (e.g., Palmer et al., 2005; Fillmore and Baker, 2009; Oepen et al., 2016; Banarescu et al., 2013) and domain-centric representations like TimeML and ISO-Space (Pustejovsky et al., 2003, 2012).
ize more easily to new types and usages.",2 Background: Disambiguation of Prepositions and Possessives,[0],[0]
"The most recent class-based approach to prepositions was our initial framework of 75 preposition supersenses arranged in a multiple inheritance taxonomy (Schneider et al., 2015, 2016).",2 Background: Disambiguation of Prepositions and Possessives,[0],[0]
"It was based largely on relation/role inventories of Srikumar and Roth (2013) and VerbNet (Bonial et al., 2011; Palmer et al., 2017).",2 Background: Disambiguation of Prepositions and Possessives,[0],[0]
"The framework was realized in version 3.0 of our comprehensively annotated corpus, STREUSLE3 (Schneider et al., 2016).",2 Background: Disambiguation of Prepositions and Possessives,[0],[0]
"However, several limitations of our approach became clear to us over time.
",2 Background: Disambiguation of Prepositions and Possessives,[0],[0]
"First, as pointed out by Hwang et al. (2017), the one-label-per-token assumption in STREUSLE is flawed because it in some cases puts into conflict the semantic role of the PP with respect to a predicate, and the lexical semantics of the preposition itself.",2 Background: Disambiguation of Prepositions and Possessives,[0],[0]
"Hwang et al. (2017) suggested a solution, discussed in §3.3, but did not conduct an annotation study or release a corpus to establish its feasibility empirically.",2 Background: Disambiguation of Prepositions and Possessives,[0],[0]
"We address that gap here.
",2 Background: Disambiguation of Prepositions and Possessives,[0],[0]
"Second, 75 categories is an unwieldy number for both annotators and disambiguation systems.",2 Background: Disambiguation of Prepositions and Possessives,[0],[0]
"Some are quite specialized and extremely rare in STREUSLE 3.0, which causes data sparseness issues for supervised learning.",2 Background: Disambiguation of Prepositions and Possessives,[0],[0]
"In fact, the only published disambiguation system for preposition supersenses collapsed the distinctions to just 12 labels (Gonen and Goldberg, 2016).",2 Background: Disambiguation of Prepositions and Possessives,[0],[0]
Hwang et al. (2017) remarked that solving the aforementioned problem could remove the need for many of the specialized categories and make the taxonomy more tractable for annotators and systems.,2 Background: Disambiguation of Prepositions and Possessives,[0],[0]
"We substantiate this here, defining a new hierarchy with just 50 categories (SNACS, §3) and providing disambiguation results for the full set of distinctions.
",2 Background: Disambiguation of Prepositions and Possessives,[0],[0]
"Finally, given the semantic overlap of possessive case and the preposition of, we saw an opportunity to broaden the application of the scheme to include possessives.",2 Background: Disambiguation of Prepositions and Possessives,[0],[0]
"Our reannotated corpus, STREUSLE 4.0, thus has supersense annotations for over 1000 possessive tokens that were not semantically annotated in version 3.0.",2 Background: Disambiguation of Prepositions and Possessives,[0],[0]
We include these in our annotation and disambiguation experiments alongside reannotated preposition tokens.,2 Background: Disambiguation of Prepositions and Possessives,[0],[0]
"Apart from canonical prepositions and possessives, there are many lexically and semantically overlap-
3https://github.com/nert-gu/streusle/
ping closed-class items which are sometimes classified as other parts of speech, such as adverbs, particles, and subordinating conjunctions.",3.1 Lexical Categories of Interest,[0],[0]
"The Cambridge Grammar of the English Language (Huddleston and Pullum, 2002) argues for an expansive definition of ‘preposition’ that would encompass these other categories.",3.1 Lexical Categories of Interest,[0],[0]
"As a practical measure, we decided to encourage annotators to focus on the semantics of these functional items rather than their syntax, so we take an inclusive stance.
",3.1 Lexical Categories of Interest,[0],[0]
Another consideration is developing annotation guidelines that can be adapted for other languages.,3.1 Lexical Categories of Interest,[0],[0]
"This includes languages which have postpositions, circumpositions, or inpositions rather than prepositions; the general term for such items is adpositions.4 English possessive marking (via ’s or possessive pronouns like my) is more generally an example of case marking.",3.1 Lexical Categories of Interest,[0],[0]
"Note that prepositions (4a–4c) differ in word order from possessives (4d), though semantically the object of the preposition and the possessive nominal pattern together:
(4) a. eat in a restaurant b. the man in a blue shirt c. the wife of the ambassador d. the ambassador’s wife
Cross-linguistically, adpositions and case marking are closely related, and in general both grammatical strategies can express similar kinds of semantic relations.",3.1 Lexical Categories of Interest,[0],[0]
"This motivates a common semantic inventory for adpositions and case.
",3.1 Lexical Categories of Interest,[0],[0]
"We also cover multiword prepositions (e.g., out_of, in_front_of), intransitive particles (He flew away), purpose infinitive clauses (Open the door to let in some air5), prepositions with clausal complements (It rained before the party started), and idiomatic prepositional phrases (at_large).",3.1 Lexical Categories of Interest,[0],[0]
Our annotation guidelines give further details.,3.1 Lexical Categories of Interest,[0],[0]
"The hierarchy of preposition and possessive supersenses, which we call Semantic Network of Adposition and Case Supersenses (SNACS), is shown in figure 2.",3.2 The SNACS Hierarchy,[0],[0]
"It is simpler than its predecessor— Schneider et al.’s (2016) preposition supersense hierarchy—in both size and structural complexity.
",3.2 The SNACS Hierarchy,[0],[0]
"4In English, ago is arguably a postposition because it follows rather than precedes its complement: five minutes ago, not *ago five minutes.
",3.2 The SNACS Hierarchy,[0],[0]
"5 To can be rephrased as in_order_to and have prepositional
counterparts like in Open the door for some air.
",3.2 The SNACS Hierarchy,[0],[0]
"Circumstance 77
Temporal 0
Time 371
StartTime 28 EndTime 31
Frequency 9
Duration 91 Interval 35
Locus 846
Source 189 Goal 419
Path 49
Direction 161 Extent 42
Means",3.2 The SNACS Hierarchy,[0],[0]
"17 Manner 140 Explanation 123
Purpose 401
Participant 0
Causer 15
Agent 170
Co-Agent 65
Theme 238
Co-Theme 14",3.2 The SNACS Hierarchy,[0],[0]
"Topic 296
Stimulus 123 Experiencer 107
Originator 134
Recipient 122
Cost 48 Beneficiary 110
Instrument 30
Configuration 0
Identity 85
Species 39
Gestalt 709
Possessor 492 Whole 250 Characteristic 140
Possession 21",3.2 The SNACS Hierarchy,[0],[0]
"PartPortion 57
Stuff 25
Accompanier 49
InsteadOf 10 ComparisonRef 215
RateUnit 5 Quantity 191
Approximator 76
SocialRel 240
OrgRole 103
Figure 2: SNACS hierarchy of 50 supersenses and their token counts in the annotated corpus described in §4.",3.2 The SNACS Hierarchy,[0],[0]
"Counts are of direct uses of labels, excluding uses of subcategories.",3.2 The SNACS Hierarchy,[0],[0]
"Role and function positions are not distinguished (so if a token has different role and function labels, it will count toward two supersense frequencies).
",3.2 The SNACS Hierarchy,[0],[0]
SNACS has 50 supersenses at 4 levels of depth; the previous hierarchy had 75 supersenses at 7 levels.,3.2 The SNACS Hierarchy,[0],[0]
"The top-level categories are the same:
• CIRCUMSTANCE:",3.2 The SNACS Hierarchy,[0],[0]
"Circumstantial information, usually non-core properties of events (e.g., location, time, means, purpose) •",3.2 The SNACS Hierarchy,[0],[0]
PARTICIPANT: Entity playing a role in an event • CONFIGURATION:,3.2 The SNACS Hierarchy,[0],[0]
"Thing, usually an entity or property, involved in a static relationship to some other entity The 3 subtrees loosely parallel adverbial adjuncts, event arguments, and adnominal complements, respectively.",3.2 The SNACS Hierarchy,[0],[0]
"The PARTICIPANT and CIRCUMSTANCE subtrees primarily reflect semantic relationships prototypical to verbal arguments/adjuncts and were inspired by VerbNet’s thematic role hierarchy (Palmer et al., 2017; Bonial et al., 2011).",3.2 The SNACS Hierarchy,[0],[0]
"Many CIRCUMSTANCE subtypes, like LOCUS (the concrete or abstract location of something), can be governed by eventive and non-eventive nominals as well as verbs: eat in the restaurant, a party in the restaurant, a table in the restaurant.",3.2 The SNACS Hierarchy,[0],[0]
"CONFIGURATION mainly encompasses non-spatiotemporal relations holding between entities, such as quantity, possession, and part/whole.",3.2 The SNACS Hierarchy,[0],[0]
"Unlike the previous hierarchy, SNACS does not use multiple inheritance, so there is no overlap between the 3 regions.
",3.2 The SNACS Hierarchy,[0],[0]
"The supersenses can be understood as roles in fundamental types of scenes (or schemas) such as: LOCATION—THEME is located at LO-
CUS; MOTION—THEME moves from SOURCE along PATH to GOAL; TRANSITIVE ACTION— AGENT acts on THEME, perhaps using an INSTRUMENT;",3.2 The SNACS Hierarchy,[0],[0]
"POSSESSION—POSSESSION belongs to POSSESSOR; TRANSFER—THEME changes possession from ORIGINATOR to RECIPIENT, perhaps with COST;",3.2 The SNACS Hierarchy,[0],[0]
"PERCEPTION—EXPERIENCER is mentally affected by STIMULUS; COGNITION— EXPERIENCER contemplates TOPIC; COMMUNICATION—information (TOPIC) flows from ORIGINATOR to RECIPIENT, perhaps via an INSTRUMENT.",3.2 The SNACS Hierarchy,[0],[0]
"For AGENT, CO-AGENT, EXPERIENCER, ORIGINATOR, RECIPIENT, BENEFICIARY, POSSESSOR, and SOCIALREL, the object of the preposition is prototypically animate.
",3.2 The SNACS Hierarchy,[0],[0]
"Because prepositions and possessives cover a vast swath of semantic space, limiting ourselves to 50 categories means we need to address a great many nonprototypical, borderline, and special cases.",3.2 The SNACS Hierarchy,[0],[0]
"We have done so in a 75-page annotation manual with over 400 example sentences (Schneider et al., 2018).
",3.2 The SNACS Hierarchy,[0],[0]
"Finally, we note that the Universal Semantic Tagset (Abzianidze and Bos, 2017) defines a crosslinguistic inventory of semantic classes for content and function words.",3.2 The SNACS Hierarchy,[0],[0]
"SNACS takes a similar approach to prepositions and possessives, which in Abzianidze and Bos’s (2017) specification are simply tagged REL, which does not disambiguate the nature of the relational meaning.",3.2 The SNACS Hierarchy,[0],[0]
Our categories can thus be understood as refinements to REL.,3.2 The SNACS Hierarchy,[0],[0]
Hwang et al. (2017) have pointed out the perils of teasing apart and generalizing preposition semantics so that each use has a clear supersense label.,3.3 Adopting the Construal Analysis,[0],[0]
One key challenge they identified is that the preposition itself and the situation as established by the verb may suggest different labels.,3.3 Adopting the Construal Analysis,[0],[0]
"For instance:
(5) a. Vernon works at Grunnings.",3.3 Adopting the Construal Analysis,[0],[0]
"b. Vernon works for Grunnings.
",3.3 Adopting the Construal Analysis,[0],[0]
"The semantics of the scene in (5a, 5b) is the same: it is an employment relationship, and the PP contains the employer.",3.3 Adopting the Construal Analysis,[0],[0]
"SNACS has the label ORGROLE for this purpose.6 At the same time, at in (5a) strongly suggests a locational relationship, which would correspond to the label LOCUS; consistent with this
6ORGROLE is defined as “Either a party in a relation between an organization/institution and an individual who has a stable affiliation with that organization, such as membership or a business relationship.”
",3.3 Adopting the Construal Analysis,[0],[0]
"hypothesis, Where does Vernon work? is a perfectly good way to ask a question that could be answered by the PP.",3.3 Adopting the Construal Analysis,[0],[0]
"In this example, then, there is overlap between locational meaning and organizationalbelonging meaning.",3.3 Adopting the Construal Analysis,[0],[0]
(5b) is similar except the for suggests a notion of BENEFICIARY:,3.3 Adopting the Construal Analysis,[0],[0]
the employee is working on behalf of the employer.,3.3 Adopting the Construal Analysis,[0],[0]
Annotators would face a conundrum if forced to pick a single label when multiple ones appear to be relevant.,3.3 Adopting the Construal Analysis,[0],[0]
"Schneider et al. (2016) handled overlap via multiple inheritance, but entertaining a new label for every possible case of overlap is impractical, as this would result in a proliferation of supersenses.
",3.3 Adopting the Construal Analysis,[0],[0]
"Instead, Hwang et al. (2017) suggest a construal analysis in which the lexical semantic contribution, or henceforth the function, of the preposition itself may be distinct from the semantic role or relation mediated by the preposition in a given sentence, called the scene role.",3.3 Adopting the Construal Analysis,[0],[0]
The notion of scene role is a widely accepted idea that underpins the use of semantic or thematic roles: semantics licensed by the governor7 of the prepositional phrase dictates its relationship to the prepositional phrase.,3.3 Adopting the Construal Analysis,[0],[0]
"The innovative claim is that, in addition to a preposition’s relationship with its head, the prepositional choice introduces another layer of meaning or construal that brings additional nuance, creating the difficulty we see in the annotation of (5a, 5b).",3.3 Adopting the Construal Analysis,[0],[0]
Construal is notated by ROLE;FUNCTION.,3.3 Adopting the Construal Analysis,[0],[0]
"Thus, (5a) would be annotated ORGROLE;LOCUS and (5b) as ORGROLE;BENEFICIARY to expose their common truth-semantic meaning but slightly different portrayals owing to the different prepositions.
",3.3 Adopting the Construal Analysis,[0],[0]
"Another useful application of the construal analysis is with the verb put, which can combine with any locative PP to express a destination:
(6) Put it on/by/behind/on_top_of/. . .",3.3 Adopting the Construal Analysis,[0],[0]
the door.,3.3 Adopting the Construal Analysis,[0],[0]
"GOAL;LOCUS
I.e., the preposition signals a LOCUS, but the door serves as the GOAL with respect to the scene.",3.3 Adopting the Construal Analysis,[0],[0]
"This approach also allows for resolution of various se-
7By “governor” of the preposition or prepositional phrase, we mean the head of the phrase to which the PP attaches in a constituency representation.",3.3 Adopting the Construal Analysis,[0],[0]
"In a dependency representation, this would be the head of the preposition itself or of the object of the preposition depending on which convention is used for PP headedness: e.g., the preposition heads the PP in CoNLL and Stanford Dependencies whereas the object is the head in Universal Dependencies.",3.3 Adopting the Construal Analysis,[0],[0]
The governor is most often a verb or noun.,3.3 Adopting the Construal Analysis,[0],[0]
"Where the PP is a predicate complement (e.g. Vernon is with Grunnings), there is no governor to specify the nature of the scene, so annotators must rely on world knowledge and context to determine the scene.
",3.3 Adopting the Construal Analysis,[0],[0]
"mantic phenomena including perceptual scenes (e.g., I care about education, where about is both the topic of cogitation and perceptual stimulus of caring: STIMULUS;TOPIC), and fictive motion (Talmy, 1996), where static location is described using motion verbiage (as in The road runs through the forest: LOCUS;PATH).
",3.3 Adopting the Construal Analysis,[0],[0]
Both role and function slots are filled by supersenses from the SNACS hierarchy.,3.3 Adopting the Construal Analysis,[0],[0]
Annotators have the option of using distinct supersenses for the role and function; in general it is not a requirement (though we stipulate that certain SNACS supersenses can only be used as the role).,3.3 Adopting the Construal Analysis,[0],[0]
"When the same label captures both role and function, we do not repeat it: Vernon lives in/LOCUS England.",3.3 Adopting the Construal Analysis,[0],[0]
"Figure 1 shows some real examples from our corpus.
",3.3 Adopting the Construal Analysis,[0],[0]
We apply the construal analysis in SNACS annotation of our corpus to test its feasibility.,3.3 Adopting the Construal Analysis,[0],[0]
"It has proved useful not only for prepositions, but also possessives, where the general sense of possession may overlap with other scene relations, like creator/initial-possessor (ORIGINATOR): Da Vinci’s/ORIGINATOR;POSSESSOR sculptures.",3.3 Adopting the Construal Analysis,[0],[0]
"We applied the SNACS annotation scheme (§3) to prepositions and possessives in the STREUSLE corpus (§2), a collection of online consumer reviews taken from the English Web Treebank (Bies et al., 2012).",4 Annotated Reviews Corpus,[0],[0]
"The sentences from the English Web Treebank also comprise the primary reference treebank for English Universal Dependencies (UD; Nivre et al., 2016), and we bundle the UD version 2 syntax alongside our annotations.",4 Annotated Reviews Corpus,[0],[0]
Table 1 shows the total number of tokens present and those that we annotated.,4 Annotated Reviews Corpus,[0],[0]
"Altogether, 5,455 tokens were annotated for scene role and function.
",4 Annotated Reviews Corpus,[0],[0]
Table 2 shows the most and least common labels occurring as scene role and function.,4 Annotated Reviews Corpus,[0],[0]
"Three labels never appear in the annotated corpus: TEMPORAL from the CIRCUMSTANCE hierarchy, and PARTICIPANT and CONFIGURATION which are both the highest supersense in their respective hierarchies.",4 Annotated Reviews Corpus,[0],[0]
"While all remaining supersenses are attested as scene roles, there are some that never occur as functions, such as ORIGINATOR, which is most often realized as POSSESSOR or SOURCE, and EXPERIENCER.",4 Annotated Reviews Corpus,[0],[0]
"It is interesting to note that every subtype of CIRCUMSTANCE (except TEMPORAL) appears as both scene role and function, whereas many of the subtypes of the other two hierarchies are lim-
8Blodgett and Schneider (2018) detail the extension of the scheme to possessives.
",4 Annotated Reviews Corpus,[0],[0]
"9In the corpus, lexical expression tokens appear alongside a lexical category indicating which inventory of supersenses, if any, applies.",4 Annotated Reviews Corpus,[0],[0]
"SNACS-annotated units are those with ADP (adposition), PP, PRON.POSS (possessive pronoun), etc., whereas DISC (discourse) and CCONJ expressions do not receive any supersense.",4 Annotated Reviews Corpus,[0],[0]
"Refer to the STREUSLE README for details.
ited to either role or function.",4 Annotated Reviews Corpus,[0],[0]
"This reflects our view that prepositions primarily capture circumstantial notions such as space and time, but have been extended to cover other semantic relations.10",4 Annotated Reviews Corpus,[0],[0]
"Because the online reviews corpus was so central to the development of our guidelines, we sought to estimate the reliability of the annotation scheme on a new corpus in a new genre.",5 Interannotator Agreement Study,[0],[0]
"We chose SaintExupéry’s novella The Little Prince, which is readily available in many languages and has been annotated with semantic representations such as AMR (Banarescu et al., 2013).",5 Interannotator Agreement Study,[0],[0]
"The genre is markedly different from online reviews—it is quite literary, and employs archaic or poetic figures of speech.",5 Interannotator Agreement Study,[0],[0]
"It is also a translation from French, contributing to the markedness of the language.",5 Interannotator Agreement Study,[0],[0]
This text is therefore a challenge for an annotation scheme based on colloquial contemporary English.,5 Interannotator Agreement Study,[0],[0]
"We addressed this issue by running 3 practice rounds of annotation on small passages from The Little Prince, both to assess whether the scheme was applicable without major guidelines changes and to prepare the annotators for this genre.",5 Interannotator Agreement Study,[0],[0]
"For the final annotation study, we chose chapters 4 and 5, in which 242 markables of 52 types were identified heuristically (§6.2).",5 Interannotator Agreement Study,[0],[0]
"The types of, to, in, as, from, and for, as well as possessives, occurred at least 10 times.",5 Interannotator Agreement Study,[0],[0]
"Annotators had the option to mark units as false positives using special labels (see §4) in addition to expressing uncertainty about the unit.
",5 Interannotator Agreement Study,[0],[0]
"For the annotation process, we adapted the open source web-based annotation tool UCCAApp (Abend et al., 2017) to our workflow, by extending it with a type-sensitive ranking module for the list of categories presented to the annotators.",5 Interannotator Agreement Study,[0],[0]
Annotators.,5 Interannotator Agreement Study,[0],[0]
"Five annotators (A, B, C, D, E), all authors of this paper, took part in this study.",5 Interannotator Agreement Study,[0],[0]
All are computational linguistics researchers with advanced training in linguistics.,5 Interannotator Agreement Study,[0],[0]
"Their involvement in the development of the scheme falls on a spectrum, with annotator A being the most active figure in guidelines development, and annotator E not being
10All told, 41 supersenses are attested as both role and function for the same token, and there are 136 unique construal combinations where the role differs from the function.",5 Interannotator Agreement Study,[0],[0]
"Only four supersenses are never found in such a divergent construal: EXPLANATION, SPECIES, STARTTIME, RATEUNIT.",5 Interannotator Agreement Study,[0],[0]
"Except for RATEUNIT which occurs only 5 times, their narrow use does not arise because they are rare.",5 Interannotator Agreement Study,[0],[0]
"EXPLANATION, for example, occurs over 100 times, more than many labels which often appear in construal.
involved in developing the guidelines and learning the scheme solely from reading the manual.",5 Interannotator Agreement Study,[0],[0]
"Annotators A, B, and C are native speakers of English, while Annotators D and E are nonnative but highly fluent speakers.
",5 Interannotator Agreement Study,[0],[0]
Results.,5 Interannotator Agreement Study,[0],[0]
"In the Little Prince sample, 40 out of 47 possible supersenses were applied at least once by some annotator; 36 were applied at least once by a majority of annotators; and 33 were applied at least once by all annotators.",5 Interannotator Agreement Study,[0],[0]
"APPROXIMATOR, COTHEME, COST, INSTEADOF, INTERVAL, RATEUNIT, and SPECIES were not used by any annotator.
",5 Interannotator Agreement Study,[0],[0]
"To evaluate interannotator agreement, we excluded 26 tokens for which at least one annotator has assigned a non-semantic label, considering only the 216 tokens that were identified correctly as SNACS targets and were clear to all annotators.",5 Interannotator Agreement Study,[0],[0]
"Despite varying exposure to the scheme, there is no obvious relationship between annotators’ backgrounds and their agreement rates.11
Table 3 shows the interannotator agreement rates, averaged across all pairs of annotators.",5 Interannotator Agreement Study,[0],[0]
"Average agreement is 74.4% on the scene role and 81.3% on the function (row 1).12 All annotators agree on the role for 119, and on the function for 139 tokens.",5 Interannotator Agreement Study,[0],[0]
"Agreement is higher on the function slot than on the scene role slot, which implies that the former is an easier task than the latter.",5 Interannotator Agreement Study,[0],[0]
"This is expected considering the definition of construal: the function of an adposition is more lexical and less contextdependent, whereas the role depends on the context (the scene) and can be highly idiomatic (§3.3).
",5 Interannotator Agreement Study,[0],[0]
"The supersense hierarchy allows us to analyze agreement at different levels of granularity (rows
11See table 7 in appendix A for a more detailed description of the annotators’ backgrounds and pairwise IAA results.
",5 Interannotator Agreement Study,[0],[0]
"12Average of pairwise Cohen’s k is 0.733 and 0.799 on, respectively, role and function, suggesting strong agreement.",5 Interannotator Agreement Study,[0],[0]
"However, it is worth noting that annotators selected labels from a ranked list, with the ranking determined by preposition type.",5 Interannotator Agreement Study,[0],[0]
"The model of chance agreement underlying k does not take the identity of the preposition into account, and thus likely underestimates the probability of chance agreement.
",5 Interannotator Agreement Study,[0],[0]
2–4 in table 3; see also confusion matrix in supplement).,5 Interannotator Agreement Study,[0],[0]
"Coarser-grained analyses naturally give better agreement, with depth-1 coarsening into only 3 categories.",5 Interannotator Agreement Study,[0],[0]
Results show that most confusions are local with respect to the hierarchy.,5 Interannotator Agreement Study,[0],[0]
We now describe systems that identify and disambiguate SNACS-annotated prepositions and possessives in two steps.,6 Disambiguation Systems,[0],[0]
Target identification heuristics (§6.2) first determine which tokens (single-word or multiword) should receive a SNACS supersense.,6 Disambiguation Systems,[0],[0]
A supervised classifier then predicts a supersense analysis for each identified target.,6 Disambiguation Systems,[0],[0]
"The research objectives are (a) to study the ability of statistical models to learn roles and functions of prepositions and possessives, and (b) to compare two different modeling strategies (feature-rich and neural), and the impact of syntactic parsing.",6 Disambiguation Systems,[0],[0]
Our experiments use the reviews corpus described in §4.,6.1 Experimental Setup,[0],[0]
We adopt the official training/development/ test splits of the Universal Dependencies (UD) project; their sizes are presented in table 1.,6.1 Experimental Setup,[0],[0]
All systems are trained on the training set only and evaluated on the test set; the development set was used for tuning hyperparameters.,6.1 Experimental Setup,[0],[0]
Gold tokenization was used throughout.,6.1 Experimental Setup,[0],[0]
"Only targets with a semantic supersense analysis involving labels from figure 2 were included in training and evaluation—i.e., tokens with special labels (see §4) were excluded.
",6.1 Experimental Setup,[0],[0]
"To test the impact of automatic syntactic parsing, models in the auto syntax condition were trained and evaluated on automatic lemmas, POS tags, and Basic Universal Dependencies (according to the v1 standard) produced by Stanford CoreNLP version 3.8.0",6.1 Experimental Setup,[0],[0]
"(Manning et al., 2014).13 Named entity tags from the default 12-class CoreNLP model were used in all conditions.",6.1 Experimental Setup,[0],[0]
"§3.1 explains that the categories in our scheme apply not only to (transitive) adpositions in a very narrow definition of the term, but also to lexical items that traditionally belong to variety of syntactic classes (such as adverbs and particles), as
13The CoreNLP parser was trained on all 5 genres of the English Web Treebank—i.e., a superset of our training set.",6.2 Target Identification,[0],[0]
"Gold syntax follows the UDv2 standard, whereas the classifiers in the auto syntax conditions are trained and tested with UDv1 parses produced by CoreNLP.
",6.2 Target Identification,[0],[0]
well as possessive case markers and multiword expressions.,6.2 Target Identification,[0],[0]
"61.2% of the units annotated in our corpus are adpositions according to gold POS annotation, 20.2% are possessives, and 18.6% belong to other POS classes.",6.2 Target Identification,[0],[0]
"Furthermore, 14.1% of tokens labeled as adpositions or possessives are not annotated because they are part of a multiword expression (MWE).",6.2 Target Identification,[0],[0]
"It is therefore neither obvious nor trivial to decide which tokens and groups of tokens should be selected as targets for SNACS annotation.
",6.2 Target Identification,[0],[0]
"To facilitate both manual annotation and automatic classification, we developed heuristics for identifying annotation targets.",6.2 Target Identification,[0],[0]
"The algorithm first scans the sentence for known multiword expressions, using a blacklist of non-prepositional MWEs that contain preposition tokens (e.g., take_care_of ) and a whitelist of prepositional MWEs (multiword prepositions like out_of and PP idioms like in_town).",6.2 Target Identification,[0],[0]
Both lists were constructed from the training data.,6.2 Target Identification,[0],[0]
"From segments unaffected by the MWE heuristics, single-word candidates are identified by matching a high-recall set of parts of speech, then filtered through 5 different heuristics for adpositions, possessives, subordinating conjunctions, adverbs, and infinitivals.",6.2 Target Identification,[0],[0]
"Most of these filters are based on lexical lists learned from the training portion of the STREUSLE corpus, but there are some specific rules for infinitivals that handle forsubjects (I opened the door for Steve to take out the trash—to, but not for, should receive a supersense) and comparative constructions with too and enough (too short to ride).",6.2 Target Identification,[0],[0]
The next step of disambiguation is predicting the role and function labels.,6.3 Classification,[0],[0]
We explore two different modeling strategies.,6.3 Classification,[0],[0]
Feature-rich Model.,6.3 Classification,[0],[0]
"Our first model is based on the features for preposition relation classification developed by Srikumar and Roth (2013), which were themselves extended from the preposition sense disambiguation features of Hovy et al. (2010).",6.3 Classification,[0],[0]
"We briefly describe the feature set here, and refer the reader to the original work for further details.",6.3 Classification,[0],[0]
"At a high level, it consists of features extracted from selected neighboring words in the dependency tree (i.e., heuristically identified governor and object) and in the sentence (previous verb, noun and adjective, and next noun).",6.3 Classification,[0],[0]
"In addition, all these features are also conjoined with the lemma of the rightmost word in the preposition token to capture
target-specific interactions with the labels.",6.3 Classification,[0],[0]
"The features extracted from each neighboring word are listed in the supplementary material.
",6.3 Classification,[0],[0]
"Using these features extracted from targets, we trained two multi-class SVM classifiers to predict the role and function labels using the LIBLINEAR library (Fan et al., 2008).
",6.3 Classification,[0],[0]
Neural Model.,6.3 Classification,[0],[0]
Our second classifier is a multilayer perceptron (MLP) stacked on top of a BiLSTM.,6.3 Classification,[0],[0]
"For every sentence, tokens are first embedded using a concatenation of fixed pre-trained word2vec (Mikolov et al., 2013) embeddings of the word and the lemma, and an internal embedding vector, which is updated during training.14 Token embeddings are then fed into a 2-layer BiLSTM encoder, yielding a list of token representations.
",6.3 Classification,[0],[0]
"For each identified target unit u, we extract its first token, and its governor and object headword.",6.3 Classification,[0],[0]
"For each of these tokens, we construct a feature vector by concatenating its token representation with embeddings of its (1) language-specific POS tag, (2) UD dependency label, and (3) NER label.",6.3 Classification,[0],[0]
"We additionally concatenate embeddings of u’s lexical category, a syntactic label indicating whether u is predicative/stranded/subordinating/none of these, and an indicator of whether either of the two tokens following the unit is capitalized.",6.3 Classification,[0],[0]
"All these embeddings, as well as internal token embedding vectors, are considered part of the model parameters and are initialized randomly using the Xavier initialization (Glorot and Bengio, 2010).",6.3 Classification,[0],[0]
"A NONE label is used when the corresponding feature is not given, both in training and at test time.",6.3 Classification,[0],[0]
"The concatenated feature vector for u is fed into two separate 2-layered MLPs, followed by a separate softmax layer that yields the predicted probabilities for the role and function labels.
",6.3 Classification,[0],[0]
We tuned hyperparameters on the development set to maximize F-score (see supplementary material).,6.3 Classification,[0],[0]
"We used the cross-entropy loss function, optimizing with simple gradient ascent for 80 epochs with minibatches of size 20.",6.3 Classification,[0],[0]
Inverted dropout was used during training.,6.3 Classification,[0],[0]
"The model is implemented with the DyNet library (Neubig et al., 2017).
",6.3 Classification,[0],[0]
"The model architecture is largely comparable to that of Gonen and Goldberg (2016), who experimented with a coarsened version of STREUSLE 3.0.",6.3 Classification,[0],[0]
"The main difference is their use of unlabeled multilingual datasets to improve pre-
14Word2vec is pre-trained on the Google News corpus.",6.3 Classification,[0],[0]
"Zero vectors are used where vectors are not available.
diction by exploiting the differences in preposition ambiguities across languages.",6.3 Classification,[0],[0]
"Following the two-stage disambiguation pipeline (i.e. target identification and classification), we separate the evaluation across the phases.",6.4 Results & Analysis,[0],[0]
"Table 4 reports the precision, recall, and F-score (P/R/F) of the target identification heuristics.",6.4 Results & Analysis,[0],[0]
Table 5 reports the disambiguation performance of both classifiers with gold (left) and automatic target identification (right).,6.4 Results & Analysis,[0],[0]
"We evaluate each classifier along three dimensions—role and function independently, and full (i.e. both role and function together).",6.4 Results & Analysis,[0],[0]
"When we have the gold targets, we only report accuracy because precision and recall are equal.",6.4 Results & Analysis,[0],[0]
"With automatically identified targets, we report P/R/F for each dimension.",6.4 Results & Analysis,[0],[0]
Both tables show the impact of syntactic parsing on quality.,6.4 Results & Analysis,[0],[0]
The rest of this section presents analyses of the results along various axes.,6.4 Results & Analysis,[0],[0]
Target identification.,6.4 Results & Analysis,[0],[0]
The identification heuristics described in §6.2 achieve an F1 score of 89.2% on the test set using gold syntax.15,6.4 Results & Analysis,[0],[0]
Most false positives (47/54=87%) can be ascribed to tokens that are part of a (non-adpositional or larger adpositional) multiword expression.,6.4 Results & Analysis,[0],[0]
"9 of the 50 false negatives (18%) are rare multiword expressions not occurring in the training data and there are 7 partially identified ones, which are counted as both false positives and false negatives.
",6.4 Results & Analysis,[0],[0]
Automatically generated parse trees slightly decrease quality (table 4).,6.4 Results & Analysis,[0],[0]
"Target identification, being the first step in the pipeline, imposes an upper bound on disambiguation scores.",6.4 Results & Analysis,[0],[0]
"We observe this degradation when we compare the Gold ID and the Auto ID blocks of table 5, where automatically identified targets decrease F-score by about 10 points in all settings.16
Classification.",6.4 Results & Analysis,[0],[0]
"Along with the statistical classifier results in table 5, we also report performance
15Our evaluation script counts tokens that received special labels in the gold standard (see §4) as negative examples of SNACS targets, with the exception of the tokens labeled as unintelligible/nonnative/etc., which are not counted toward or against target ID performance.
16A variant of the target ID module, optimized for recall, is used as preprocessing for the agreement study discussed in §5.",6.4 Results & Analysis,[0],[0]
"With this setting, the heuristic achieves an F1 score of 90.2% (P=85.3%, R=95.6%) on the test set.
for the most frequent baseline, which selects the most frequent role–function label pair given the (gold) lemma according to the training data.",6.4 Results & Analysis,[0],[0]
"Note that all learned classifiers, across all settings, outperform the most frequent baseline for both role and function prediction.",6.4 Results & Analysis,[0],[0]
"The feature-rich and the neural models perform roughly equivalently despite the significantly different modeling strategies.
",6.4 Results & Analysis,[0],[0]
Function and scene role performance.,6.4 Results & Analysis,[0],[0]
"Function prediction is consistently more accurate than role prediction, with roughly a 10-point gap across all systems.",6.4 Results & Analysis,[0],[0]
"This mirrors a similar effect in the interannotator agreement scores (see §5), and may be due to the reduced ambiguity of functions compared to roles (as attested by the baseline’s higher accuracy for functions than roles), and by the more literal nature of function labels, as opposed to role labels that often require more context to determine.
Impact of automatic syntax.",6.4 Results & Analysis,[0],[0]
"Automatic syntactic analysis decreases scores by 4 to 7 points, most likely due to parsing errors which affect the identification of the preposition’s object and governor.",6.4 Results & Analysis,[0],[0]
"In the auto ID/auto syntax condition, the worse target ID performance with automatic parses (noted above) contributes to lower classification scores.",6.4 Results & Analysis,[0],[0]
We can use the structure of the SNACS hierarchy to probe classifier performance.,6.5 Errors & Confusions,[0],[0]
"As with the interannotator study, we evaluate the accuracy of predicted labels when they are coarsened post hoc by moving up the hierarchy to a specific depth.",6.5 Errors & Confusions,[0],[0]
"Table 6 shows this for the feature-rich classifier for different depths, with depth-1 representing the coarsening of the labels into the 3 root labels.",6.5 Errors & Confusions,[0],[0]
Depth-4 (Exact) represents the full results in table 5.,6.5 Errors & Confusions,[0],[0]
These results show that the classifiers often mistake a label for another that is nearby in the hierarchy.,6.5 Errors & Confusions,[0],[0]
"Examining the most frequent confusions of both models, we observe that LOCUS is overpredicted
(which makes sense as it is most frequent overall), and SOCIALROLE–ORGROLE and GESTALT– POSSESSOR are often confused (they are close in the hierarchy: one inherits from the other).",6.5 Errors & Confusions,[0],[0]
"This paper introduced a new approach to comprehensive analysis of the semantics of prepositions and possessives in English, backed by a thoroughly documented hierarchy and annotated corpus.",7 Conclusion,[0],[0]
We found good interannotator agreement and provided initial supervised disambiguation results.,7 Conclusion,[0],[0]
"We expect that future work will develop methods to scale the annotation process beyond requiring highly trained experts; bring this scheme to bear on other languages; and investigate the relationship of our scheme to more structured semantic representations, which could lead to more robust models.",7 Conclusion,[0],[0]
"Our guidelines, corpus, and software are available at https://github.com/nert-gu/streusle/ blob/master/ACL2018.md.",7 Conclusion,[0],[0]
"We thank Oliver Richardson, whose codebase we adapted for this project; Na-Rae Han, Archna Bhatia, Tim O’Gorman, Ken Litkowski, Bill Croft, and Martha Palmer for helpful discussions and support; and anonymous reviewers for useful feedback.",Acknowledgments,[0],[0]
This research was supported in part by DTRA HDTRA116-1-0002/,Acknowledgments,[0],[0]
"Project #1553695, by DARPA 15-18- CwC-FP-032, and by grant 2016375 from the United States–Israel Binational Science Foundation (BSF), Jerusalem, Israel.",Acknowledgments,[0],[0]
Semantic relations are often signaled with prepositional or possessive marking—but extreme polysemy bedevils their analysis and automatic interpretation.,abstractText,[0],[0]
"We introduce a new annotation scheme, corpus, and task for the disambiguation of prepositions and possessives in English.",abstractText,[0],[0]
"Unlike previous approaches, our annotations are comprehensive with respect to types and tokens of these markers; use broadly applicable supersense classes rather than fine-grained dictionary definitions; unite prepositions and possessives under the same class inventory; and distinguish between a marker’s lexical contribution and the role it marks in the context of a predicate or scene.",abstractText,[0],[0]
"Strong interannotator agreement rates, as well as encouraging disambiguation results with established supervised methods, speak to the viability of the scheme and task.",abstractText,[0],[0]
Comprehensive Supersense Disambiguation of English Prepositions and Possessives,title,[0],[0]
"In many real-world domains, data acquisition is costly.",1. Introduction,[0],[0]
"For instance, magnetic resonance imaging (MRI) requires scan times proportional to the number of measurements, which can be significant for patients (Lustig et al., 2008).",1. Introduction,[0],[0]
"Geophysical applications like oil drilling require expensive simulation of seismic waves (Qaisar et al., 2013).",1. Introduction,[0],[0]
"Such appli-
1Computer Science Department, Stanford University, CA, USA.",1. Introduction,[0],[0]
"Correspondence to: Manik Dhar <dmanik@cs.stanford.edu>, Aditya Grover",1. Introduction,[0],[0]
"<adityag@cs.stanford.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
cations, among many others, can benefit significantly from compressed sensing techniques to acquire signals efficiently (Candès & Tao, 2005; Donoho, 2006; Candès et al., 2006).
",1. Introduction,[0],[0]
"In compressed sensing, we wish to acquire an n-dimensional signal x ∈ Rn using only m n measurements linear in x.",1. Introduction,[0],[0]
"The measurements could potentially be noisy, but even in the absence of any noise we need to impose additional structure on the signal to guarantee unique recovery.",1. Introduction,[0],[0]
"Classical results on compressed sensing impose structure by assuming the underlying signal to be approximately l-sparse in some known basis, i.e., the l-largest entries dominate the rest.",1. Introduction,[0],[0]
"For instance, images and audio signals are typically sparse in the wavelet and Fourier basis respectively (Mallat, 2008).",1. Introduction,[0],[0]
"If the matrix of linear vectors relating the signal and measurements satisfies certain mild conditions, then one can provably recover x with only m = O(l log nl ) measurements using LASSO (Tibshirani, 1996; Candès & Tao, 2005; Donoho, 2006; Candès et al., 2006; Bickel et al., 2009).
",1. Introduction,[0],[0]
"Alternatively, structural assumptions on the signals being sensed can be learned from data, e.g., using a dataset of typical signals (Baraniuk et al., 2010; Peyre, 2010; Chen et al., 2010; Yu & Sapiro, 2011).",1. Introduction,[0],[0]
"Particularly relevant to this work, Bora et al. (2017) proposed an approach where structure is provided by a deep generative model learned from data.",1. Introduction,[0],[0]
"Specifically, the underlying signal x being sensed is assumed to be close to the range of a deterministic function expressed by a pretrained, latent variable modelG : Rk → Rn such that x ≈ G(z) where z ∈ Rk denote the latent variables.",1. Introduction,[0],[0]
"Consequently, the signal x is recovered by optimizing for a latent vector z that minimizes the `2 distance between the measurements corresponding to G(z) and the actual ones.",1. Introduction,[0],[0]
"Even though the objective being optimized in this case is non-convex, empirical results suggest that the reconstruction error decreases much faster than LASSO-based recovery as we increase the number of measurements.
",1. Introduction,[0],[0]
"A limitation of the above approach is that the recovered signal is constrained to be in the range of the generator function G. Hence, if the true signal being sensed is not in the range of G, the algorithm cannot drive the reconstruction error to zero even when m ≥ n",1. Introduction,[0],[0]
(even if we ignore error due to measurement noise and non-convex optimization).,1. Introduction,[0],[0]
"This is also observed empirically, as the reconstruction error of generative model-based recovery saturates as we keep
increasing the number of measurements m. On the other hand, LASSO-based recovery continues to shrink the error with increasing number of measurements, eventually outperforming the generative model-based recovery.
",1. Introduction,[0],[0]
"To overcome this limitation, we propose a framework that allows recovery of signals with sparse deviations from the set defined by the range of the generator function.",1. Introduction,[0],[0]
"The recovered signals have the general form of G(ẑ) + ν̂, where ν̂ ∈ Rn is a sparse vector.",1. Introduction,[0],[0]
This allows the recovery algorithm to consider signals away from the range of the generator function.,1. Introduction,[0],[0]
"Similar to LASSO, we relax the hardness in optimizing for sparse vectors by minimizing the `1 norm of the deviations.",1. Introduction,[0],[0]
"Unlike LASSO-based recovery, we can exploit the rich structure imposed by a (deep) generative model (at the expense of solving a hard optimization problem if G is non-convex).",1. Introduction,[0],[0]
"In fact, we show that LASSO-based recovery is a special case of our framework if the generator function G maps all z to the origin.",1. Introduction,[0],[0]
"Unlike generative model-based recovery, the signals recovered by our algorithm are not constrained to be in the range of the generator function.
",1. Introduction,[0],[0]
"Our proposed algorithm, referred to as Sparse-Gen, has desirable theoretical properties and empirical performance.",1. Introduction,[0],[0]
"Theoretically, we derive upper bounds on the reconstruction error for an optimal decoder with respect to the proposed model and show that this error vanishes with m = n measurements.",1. Introduction,[0],[0]
"We confirm our theory empirically, wherein we find that recovery using Sparse-Gen with variational autoencoders (Kingma & Welling, 2014) as the underlying generative model outperforms both LASSO-based and generative model-based recovery in terms of the reconstruction errors for the same number of measurements for MNIST and Omniglot datasets.",1. Introduction,[0],[0]
"Additionally, we observe significant improvements in the more practical and novel task of transfer compressed sensing where a generative model on a data-rich, source domain provides a prior for sensing a data-scarce, target domain.",1. Introduction,[0],[0]
"In this section, we review the necessary background and prior work in modeling domain specific structure in compressed sensing.",2. Preliminaries,[0],[0]
"We are interested in solving the following system of equations,
y = Ax (1)
where x ∈ Rn is the signal of interest being sensed through measurements y ∈ Rm, and A ∈ Rm×n is a measurement matrix.",2. Preliminaries,[0],[0]
"For efficient acquisition of signals, we will design measurement matrices such that m n. However, the system is under-determined whenever rank(A) <",2. Preliminaries,[0],[0]
"n. Hence, unique recovery requires additional assumptions on x. We now discuss two ways to model the structure of x.
Sparsity.",2. Preliminaries,[0],[0]
Sparsity in a well-chosen basis is natural in many domains.,2. Preliminaries,[0],[0]
"For instance, natural images are sparse in the wavelet basis whereas audio signals exhibit sparsity in the Fourier basis (Mallat, 2008).",2. Preliminaries,[0],[0]
"Hence, it is natural to assume the domain of signals x we are interested in recovering is
Sl(0) = {x : ‖x− 0‖0 ≤",2. Preliminaries,[0],[0]
l}.,2. Preliminaries,[0],[0]
"(2)
This is the set of l-sparse vectors with the `0 distance measured from the origin.",2. Preliminaries,[0],[0]
"Such assumptions dominate the prior literature in compressed sensing and can be further relaxed to recover approximately sparse signals (Candès & Tao, 2005; Donoho, 2006; Candès et al., 2006).
",2. Preliminaries,[0],[0]
Latent variable generative models.,2. Preliminaries,[0],[0]
"A latent variable model specifies a joint distribution Pθ(x, z) over the observed data x (e.g., images) and a set of latent variables z ∈",2. Preliminaries,[0],[0]
"Rk (e.g., features).",2. Preliminaries,[0],[0]
"Given a training set of signals {x1, · · · , xM}, we can learn the parameters θ of such a model, e.g., via maximum likelihood.",2. Preliminaries,[0],[0]
"When Pθ(x, z) is parameterized using deep neural networks, such generative models can effectively model complex, high-dimensional signal distributions for modalities such as images and audio (Kingma & Welling, 2014; Goodfellow et al., 2014).
",2. Preliminaries,[0],[0]
"Given a pretrained latent variable generative model with parameters θ, we can associate a generative model function G : Rk → Rn mapping a latent vector z to the mean of the conditional distribution Pθ(x|z).",2. Preliminaries,[0],[0]
"Thereafter, the space of signals that can be recovered with such a model is given by the range of the generator function,
SG = {G(z) : z ∈ Rk}.",2. Preliminaries,[0],[0]
"(3)
Note that the set is defined with respect to the latent vectors z, and we omit the dependence of G on the parameters θ (which are fixed for a pretrained model) for brevity.",2. Preliminaries,[0],[0]
"Signal recovery in compressed sensing algorithm typically involves solving an optimization problem consistent with the modeling assumptions on the domain of the signals being sensed.
",2.1. Recovery algorithms,[0],[0]
Sparse vector recovery using LASSO.,2.1. Recovery algorithms,[0],[0]
"Under the assumptions of sparsity, the signal x can be recovered by solving an `0 minimization problem (Candès & Tao, 2005; Donoho, 2006; Candès et al., 2006).
",2.1. Recovery algorithms,[0],[0]
"min x ‖x‖0
s.t.",2.1. Recovery algorithms,[0],[0]
"Ax = y. (4)
",2.1. Recovery algorithms,[0],[0]
"The objective above is however NP-hard to optimize, and hence, it is standard to consider a convex relaxation,
min x ‖x‖1
s.t.",2.1. Recovery algorithms,[0],[0]
"Ax = y. (5)
",2.1. Recovery algorithms,[0],[0]
"In practice, it is common to solve the Lagrangian of the above problem.",2.1. Recovery algorithms,[0],[0]
We refer to this method as LASSO-based recovery due to similarities of the objective in Eq.,2.1. Recovery algorithms,[0],[0]
"(5) to the LASSO regularization used broadly in machine learning (Tibshirani, 1996).",2.1. Recovery algorithms,[0],[0]
"LASSO-based recovery is the predominant technique for recovering sparse signals since it involves solving a tractable convex optimization problem.
",2.1. Recovery algorithms,[0],[0]
In order to guarantee unique recovery to the underdetermined system in Eq.,2.1. Recovery algorithms,[0],[0]
"(1), the measurement matrix A is designed to satisfy the Restricted Isometry Property (RIP) or the Restricted Eigenvalue Condition (REC) for l-sparse matrices with high probability (Candès & Tao, 2005; Bickel et al., 2009).",2.1. Recovery algorithms,[0],[0]
We define these conditions below.,2.1. Recovery algorithms,[0],[0]
Definition 1.,2.1. Recovery algorithms,[0],[0]
Let Sl(0) ⊂,2.1. Recovery algorithms,[0],[0]
Rn be the set of l-sparse vectors.,2.1. Recovery algorithms,[0],[0]
"For some parameter α ∈ (0, 1), a matrix A ∈ Rm×n is said to satisfy RIP(l, α) if ∀ x ∈ Sl(0),
(1− α)‖x‖2 ≤ ‖Ax‖2 ≤ (1 + α)‖x‖2.
",2.1. Recovery algorithms,[0],[0]
Definition 2.,2.1. Recovery algorithms,[0],[0]
Let Sl(0) ⊂,2.1. Recovery algorithms,[0],[0]
Rn be the set of l-sparse vectors.,2.1. Recovery algorithms,[0],[0]
"For some parameter γ > 0, a matrix A ∈ Rm×n is said to satisfy REC(l, γ) if ∀ x ∈ Sl(0),
‖Ax‖2 ≥ γ‖x‖2.
",2.1. Recovery algorithms,[0],[0]
"Intuitively, RIP implies that A approximately preserves Euclidean norms for sparse vectors and REC implies that sparse vectors are far from the nullspace of A. Many classes of matrices satisfy these conditions with high probability, including random Gaussian and Bernoulli matrices where every entry of the matrix is sampled from a standard normal and uniform Bernoulli distribution respectively (Baraniuk et al., 2008).
",2.1. Recovery algorithms,[0],[0]
Generative model vector recovery using gradient descent.,2.1. Recovery algorithms,[0],[0]
If the signals being sensed are assumed to lie close to the range SG of a generative model function G as defined in Eq.,2.1. Recovery algorithms,[0],[0]
"(3) , then we can recover the best approximation to the true signal by `2-minimization over z,
min z ‖AG(z)− y‖22.",2.1. Recovery algorithms,[0],[0]
"(6)
The function G is typically expressed as a deep neural network which makes the overall objective non-convex, but differentiable almost everywhere w.r.t z.",2.1. Recovery algorithms,[0],[0]
"In practice, good reconstructions can be recovered by gradient-based optimization methods.",2.1. Recovery algorithms,[0],[0]
"We refer to this method proposed by Bora et al. (2017) as generative model-based recovery.
",2.1. Recovery algorithms,[0],[0]
"To guarantee unique recovery, generative model-based recovery makes two key assumptions.",2.1. Recovery algorithms,[0],[0]
"First, the generator functionG is assumed to be L-Lipschitz, i.e., ∀ z1, z2 ∈ Rk,
‖G(z1)−G(z2)‖2 ≤ L‖z1",2.1. Recovery algorithms,[0],[0]
"− z2‖2.
",2.1. Recovery algorithms,[0],[0]
"Secondly, the measurement matrix A is designed to satisfy the Set-Restricted Eigenvalue Condition (S-REC) with high probability (Bora et al., 2017).
",2.1. Recovery algorithms,[0],[0]
Definition 3.,2.1. Recovery algorithms,[0],[0]
Let S ⊆ Rn.,2.1. Recovery algorithms,[0],[0]
"For some parameters γ > 0, δ ≥ 0, a matrix A ∈ Rm×n is said to satisfy the SREC(S, γ, δ) if ∀ x1, x2 ∈ S,
‖A(x1 − x2)‖2 ≥",2.1. Recovery algorithms,[0],[0]
γ‖x1,2.1. Recovery algorithms,[0],[0]
− x2‖2,2.1. Recovery algorithms,[0],[0]
"− δ.
",2.1. Recovery algorithms,[0],[0]
S-REC generalizes REC to an arbitrary set of vectors S as opposed to just considering the set of approximately sparse vectors Sl(0) and allowing an additional slack term δ.,2.1. Recovery algorithms,[0],[0]
"In particular, S is chosen to be the range of the generator function G for generative model-based recovery.",2.1. Recovery algorithms,[0],[0]
The modeling assumptions based on sparsity and generative modeling discussed in the previous section can be limiting in many cases.,3. The Sparse-Gen framework,[0],[0]
"On one hand, sparsity assumes a relatively weak prior over the signals being sensed.",3. The Sparse-Gen framework,[0],[0]
"Empirically, we observe that the recovered signals xL have large reconstruction error ‖xL− x‖22 especially when the number of measurements m is small.",3. The Sparse-Gen framework,[0],[0]
"On the other hand, generative models imposes a very strong, but rigid prior which works well when the number of measurements is small.",3. The Sparse-Gen framework,[0],[0]
"However, the performance of the corresponding recovery methods saturates with increasing measurements since the recovered signal xG = G(zG) is constrained to lie in the range of the generator function G. If zG ∈ Rk is the optimum value returned by an optimization procedure for Eq.",3. The Sparse-Gen framework,[0],[0]
"(6), then the reconstruction error ‖xG − x‖22 is limited by the dimensionality of the latent space and the quality of the generator function.
",3. The Sparse-Gen framework,[0],[0]
"To sidestep the above limitations, we consider a strictly more expressive class of signals by allowing sparse deviations from the range of a generator function.",3. The Sparse-Gen framework,[0],[0]
"Formally, the domain of the recovered signals is given by,
Sl,G = ∪z∈Dom(G)Sl(G(z)) (7)
where Sl(G(z)) denotes the set of sparse vectors centered on G(z) and z varies over the domain of G (typically Rk).",3. The Sparse-Gen framework,[0],[0]
"We refer to this modeling assumption and the consequent algorithmic framework for recovery as Sparse-Gen.
Based on this modeling assumption, we will recover signals of the form G(z) + ν for some ν ∈",3. The Sparse-Gen framework,[0],[0]
Rn that is preferably sparse.,3. The Sparse-Gen framework,[0],[0]
"Specifically, we consider the optimization of a hybrid objective,
min z,ν ‖ν‖0
s.t.",3. The Sparse-Gen framework,[0],[0]
"A (G(z) + ν) = y. (8)
In the above optimization problem the objective is nonconvex and non-differentiable, while the constraint is nonconvex (for general G), making the above optimization
problem hard to solve.",3. The Sparse-Gen framework,[0],[0]
"To ease the optimization problem, we propose two modifications.",3. The Sparse-Gen framework,[0],[0]
"First, we relax the `0 minimization to an `1 minimization similar to LASSO.
",3. The Sparse-Gen framework,[0],[0]
"min z,ν",3. The Sparse-Gen framework,[0],[0]
"‖ν‖1
s.t.",3. The Sparse-Gen framework,[0],[0]
"A (G(z) + ν) = y. (9)
",3. The Sparse-Gen framework,[0],[0]
"Next, we square the non-convex constraint on both sides and consider the Lagrangian of the above problem to get the final unconstrained optimization problem for Sparse-Gen,
min z,ν ‖ν‖1 + λ‖A (G(z) + ν)− y‖22 (10)
where λ is the Lagrange multiplier.
",3. The Sparse-Gen framework,[0],[0]
The above optimization problem is non-differentiable w.r.t.,3. The Sparse-Gen framework,[0],[0]
ν and non-convex w.r.t.,3. The Sparse-Gen framework,[0],[0]
z,3. The Sparse-Gen framework,[0],[0]
(if G is non-convex).,3. The Sparse-Gen framework,[0],[0]
"In practice, it can be solved in practice using gradient descent (since the non-differentiability is only at a finite number of points) or using sequential convex programming (SCP).",3. The Sparse-Gen framework,[0],[0]
"SCP is an effective heuristic for non-convex problems where the convex portions of the problem are solved using a standard convex optimization technique (Boyd & Vandenberghe, 2004).",3. The Sparse-Gen framework,[0],[0]
"In the case of Eq. (10), the optimization w.r.t. ν (for fixed z) is a convex optimization problem whereas the non-convexity typically involves differentiable terms (w.r.t. z) if G is a deep neural network.",3. The Sparse-Gen framework,[0],[0]
"Empirically, we find excellent recovery by standard first order gradient-based methods (Duchi et al., 2011; Tieleman & Hinton, 2012; Kingma & Ba, 2015).
",3. The Sparse-Gen framework,[0],[0]
"Unlike LASSO-based recovery which recovers only sparse signals, Sparse-Gen can impose a stronger domain-specific prior using a generative model.",3. The Sparse-Gen framework,[0],[0]
"If we fix the generator function to map all z to the origin, we recover LASSO-based recovery as a special case of Sparse-Gen. Additionally, Sparse-Gen is not constrained to recover signals over the range of G, as in the case of generative model-based recovery.",3. The Sparse-Gen framework,[0],[0]
"In fact, it can recover signals with sparse deviations from the range of G. Note that the sparse deviations can be
defined in a basis different from the canonical basis.",3. The Sparse-Gen framework,[0],[0]
"In such cases, we consider the following optimization problem,
min z,ν ‖Bν‖1 + λ‖A",3. The Sparse-Gen framework,[0],[0]
"(G(z) + ν)− y‖22 (11)
where B is a change of basis matrix that promotes sparsity of the vector Bν",3. The Sparse-Gen framework,[0],[0]
.,3. The Sparse-Gen framework,[0],[0]
Figure 1 illustrates the differences in modeling assumptions between Sparse-Gen and other frameworks.,3. The Sparse-Gen framework,[0],[0]
The proofs for all results in this section are given in the Appendix.,4. Theoretical Analysis,[0],[0]
"Our analysis and experiments account for measurement noise in compressed sensing, i.e.,
y = Ax+ .",4. Theoretical Analysis,[0],[0]
"(12)
Let ∆ :",4. Theoretical Analysis,[0],[0]
Rm → Rn denote an arbitrary decoding function used to recover the true signal x from the measurements y ∈ Rm.,4. Theoretical Analysis,[0],[0]
"Our analysis will upper bound the `2-error in recovery incurred by our proposed framework using mixed norm guarantees (in particular, `2/`1).",4. Theoretical Analysis,[0],[0]
"To this end, we first state some key definitions.",4. Theoretical Analysis,[0],[0]
"Define the least possible `1 error for recovering x under the Sparse-Gen modeling as,
σSl,G(x) = inf x̂∈Sl,G
‖x− x̂‖1
where the optimal x̂ is the closest point to x in the allowed domain Sl,G. We now state the main lemma guiding the theoretical analysis.",4. Theoretical Analysis,[0],[0]
Lemma 1.,4. Theoretical Analysis,[0],[0]
"Given a function G : Rk → Rn and measurement noise with ‖ ‖2 ≤ max, let A be any matrix that satisfies S-REC(S1.5l,G, (1− α), δ) and RIP(2l, α) for some α ∈ (0, 1), l > 0.",4. Theoretical Analysis,[0],[0]
"Then, there exists a decoder ∆ :",4. Theoretical Analysis,[0],[0]
"Rm → Rn such that,
‖x−∆(Ax+ )‖2 ≤ (2l)−1/2C0σl,G(x) +",4. Theoretical Analysis,[0],[0]
"C1 max + δ′
for all x ∈ Rn, where C0 = 2((1+α)(1−α)−1 +1), C1 = 2(1− α)−1, and δ′ = δ(1− α)−1.
",4. Theoretical Analysis,[0],[0]
The above lemma shows that there exists a decoder such that the error in recovery can be upper bounded for measurement matrices satisfying S-REC and RIP.,4. Theoretical Analysis,[0],[0]
Note that Lemma 1 only guarantees the existence of such a decoder and does not prescribe an optimization algorithm for recovery.,4. Theoretical Analysis,[0],[0]
"Apart from the errors due to the bounded measurement noise max and a scaled slack term appearing in the S-REC condition δ′, the major term in the upper bound corresponds to (up to constants) the minimum possible error incurred by the best possible recovery vector in Sl,G given by σl,G(x).",4. Theoretical Analysis,[0],[0]
"Similar terms appear invariably in the compressed sensing literature and are directly related to the modeling assumptions regarding x (for example, Theorem 8.3 in Cohen et al. (2009)).
",4. Theoretical Analysis,[0],[0]
"Our next lemma shows that random Gaussian matrices satisfy the S-REC (over the range of Lipschitz generative model functions) and RIP conditions with high probability for G with bounded domain, both of which together are sufficient conditions for Lemma 1 to hold.
",4. Theoretical Analysis,[0],[0]
Lemma 2.,4. Theoretical Analysis,[0],[0]
LetG : Bk(r)→ Rn be anL-Lipschitz function where Bk(r) = {z | z ∈,4. Theoretical Analysis,[0],[0]
"Rk, ‖z‖2 ≤ r} is the `2-norm ball in Rk.",4. Theoretical Analysis,[0],[0]
"For α ∈ (0, 1), if
m = O
( 1
α2
( k log ( Lr
δ
)",4. Theoretical Analysis,[0],[0]
+,4. Theoretical Analysis,[0],[0]
l log(n/l) )),4. Theoretical Analysis,[0],[0]
"then a random matrix A ∈ Rm×n with i.i.d. entries such that Aij ∼ N ( 0, 1m ) satisfies the S-REC(S1.5l,G, 1− α, δ) and RIP(2l, α) with 1− e−Ω(α2m) probability.
",4. Theoretical Analysis,[0],[0]
"Using Lemma 1 and Lemma 2, we can bound the error due to decoding with generative models and random Gaussian measurement matrices in the following result.
",4. Theoretical Analysis,[0],[0]
Theorem 1.,4. Theoretical Analysis,[0],[0]
Let G : Bk(r)→,4. Theoretical Analysis,[0],[0]
Rn be an L-Lipschitz function.,4. Theoretical Analysis,[0],[0]
"For any α ∈ (0, 1), l > 0, let A ∈ Rm×n be a random Gaussian matrix with
m = O
( 1
α2
( k log ( Lr
δ
) +",4. Theoretical Analysis,[0],[0]
l log(n/l) )),4. Theoretical Analysis,[0],[0]
rows of i.i.d.,4. Theoretical Analysis,[0],[0]
"entries scaled such that Ai,j ∼ N(0, 1/m).",4. Theoretical Analysis,[0],[0]
Let ∆ be the decoder satisfying Lemma 1.,4. Theoretical Analysis,[0],[0]
"Then, we have with 1− e−Ω(α2m) probability,
‖x−∆(Ax+ )",4. Theoretical Analysis,[0],[0]
"‖2 ≤ (2l)−1/2C0σl,G(x) +",4. Theoretical Analysis,[0],[0]
"C1 max + δ′
for all x ∈ Rn, ‖ ‖2 ≤ max, where C0, C1, γ, δ′ are constants defined in Lemma 1.
",4. Theoretical Analysis,[0],[0]
"From the above lemma, we see that the number of measurements needed to guarantee upper bounds on the reconstruction error of any signal with high probability depends on two terms.",4. Theoretical Analysis,[0],[0]
"The first term includes dependence on the Lipschitz constant L of the generative model function G. A high Lipschitz constant makes recovery harder (by requiring a larger
number of measurements), but only contributes logarithmically.",4. Theoretical Analysis,[0],[0]
"The second term, typical of results in sparse vector recovery, shows a logarithmic growth on the dimensionality n of the signals.",4. Theoretical Analysis,[0],[0]
"Ignoring logarithmic dependences and constants, recovery using Sparse-Gen requires about O(k + l) measurements for recovery.",4. Theoretical Analysis,[0],[0]
Note that Theorem 1 assumes access to an optimization oracle for decoding.,4. Theoretical Analysis,[0],[0]
"In practice, we consider the solutions returned by gradient-based optimization methods to a non-convex objective defined in Eq.",4. Theoretical Analysis,[0],[0]
"(11) that are not guaranteed to correspond to the optimal decoding in general.
",4. Theoretical Analysis,[0],[0]
"Finally, we obtain tighter bounds for the special case when G is expressed using a neural network with only ReLU activations.",4. Theoretical Analysis,[0],[0]
"These bounds do not rely explicitly on the Lipschitz constant L or require the domain of G to be bounded.
",4. Theoretical Analysis,[0],[0]
Theorem 2.,4. Theoretical Analysis,[0],[0]
"If G : Rk → Rn is a neural network of depth d with only ReLU activations and at most c nodes in each layer, then the guarantees of Theorem 1 hold for
m = O
( 1
α2
( (k + l)d log",4. Theoretical Analysis,[0],[0]
c+,4. Theoretical Analysis,[0],[0]
(k + l),4. Theoretical Analysis,[0],[0]
"log(n/l) )) .
",4. Theoretical Analysis,[0],[0]
"Our theoretical analysis formalizes the key properties of recovering signals using Sparse-Gen. As shown in Lemma 1, there exists a decoder for recovery based on such modeling assumptions that extends recovery guarantees based on vanilla sparse vector recovery and generative model-based recovery.",4. Theoretical Analysis,[0],[0]
Such recovery requires measurement matrices that satisfy both the RIP and S-REC conditions over the set of vectors that deviate in sparse directions from the range of a generative model function.,4. Theoretical Analysis,[0],[0]
"In Theorems 1-2, we observed that the number of measurements required to guarantee recovery with high probability grow almost linearly (with some logarithmic terms) with the latent space dimensionality k of the generative model and the permissible sparsity l for deviating from the range of the generative model.",4. Theoretical Analysis,[0],[0]
We evaluated Sparse-Gen for compressed sensing of highdimensional signals from the domain of benchmark image datasets.,5. Experimental Evaluation,[0],[0]
"Specifically, we considered the MNIST dataset of handwritten digits (LeCun et al., 2010) and the OMNIGLOT dataset of handwritten characters (Lake et al., 2015).",5. Experimental Evaluation,[0],[0]
"Both these datasets have the same data dimensionality (28× 28), but significantly different characteristics.",5. Experimental Evaluation,[0],[0]
The MNIST dataset has fewer classes (10 digits from 0-9) as opposed to Omniglot which shows greater diversity (1623 characters across 50 alphabets).,5. Experimental Evaluation,[0],[0]
"Additional experiments with generative adversarial networks on the CelebA dataset are reported in the Appendix.
Baselines.",5. Experimental Evaluation,[0],[0]
"We considered methods based on sparse vector recovery using LASSO (Tibshirani, 1996; Candès & Tao,
2005) and generative model based recovery using variational autoencoders (VAE) (Kingma & Welling, 2014; Bora et al., 2017).",5. Experimental Evaluation,[0],[0]
"For VAE training, we used the standard train/held-out splits of both datasets.",5. Experimental Evaluation,[0],[0]
Compressed sensing experiments that we report were performed on the entire test set of images.,5. Experimental Evaluation,[0],[0]
"The architecture and other hyperparameter details are given in the Appendix.
",5. Experimental Evaluation,[0],[0]
Experimental setup.,5. Experimental Evaluation,[0],[0]
"For the held-out set of instances, we artificially generated measurements y through a random matrix A ∈ Rm×n with entries sampled i.i.d.",5. Experimental Evaluation,[0],[0]
from a Gaussian with zero mean and standard deviation of 1/m. Measurement noise is sampled from zero mean and diagonal scalar covariance matrix with entries as 0.01.,5. Experimental Evaluation,[0],[0]
"For evaluation, we report the reconstruction error measured as ‖x̂− x‖p where x̂ is the recovered signal and p is a norm of interest, varying the number of measurementsm from 50 to the highest value of 750.",5. Experimental Evaluation,[0],[0]
"We report results for the p = {1, 2,∞} norms.
",5. Experimental Evaluation,[0],[0]
"We evaluated sensing of both continuous signals (MNIST) with pixel values in range [0, 1] and discrete signals (Omniglot) with binary pixel values {0, 1}.",5. Experimental Evaluation,[0],[0]
"For all algorithms considered, recovery was performed by optimizing over a continuous space.",5. Experimental Evaluation,[0],[0]
"In the case of sparse recovery methods (including Sparse-Gen) it is possible that unconstrained optimization returns signals outside the domain of interest, in which case they are projected to the required domain by simple clipping, i.e., any signal less than zero is clipped to 0 and similarly any signal greater than one is clipped to 1.
Results and Discussion.",5. Experimental Evaluation,[0],[0]
The reconstruction errors for varying number of measurements are given in Figure 2.,5. Experimental Evaluation,[0],[0]
"Consistent with the theory, the strong prior in generative modelbased recovery methods outperforms the LASSO-based methods for sparse vector recovery.",5. Experimental Evaluation,[0],[0]
"In the regime of low measurements, the performance of algorithms that can incorporate the generative model prior dominates over methods modeling sparsity using LASSO.",5. Experimental Evaluation,[0],[0]
"The performance of plain generative model-based methods however saturates with increasing measurements, unlike Sparse-Gen and LASSO which continue to shrink the error.",5. Experimental Evaluation,[0],[0]
"The trends are consistent for both MNIST and Omniglot, although we observe the relative magnitudes of errors in the case of Omniglot are much higher than that of MNIST.",5. Experimental Evaluation,[0],[0]
This is expected due to the increased diversity and variations of the structure of the signals being sensed in the case of Omniglot.,5. Experimental Evaluation,[0],[0]
We also observe the trends to be consistent across the various norms considered.,5. Experimental Evaluation,[0],[0]
One of the primary motivations for compressive sensing is to directly acquire the signals using few measurements.,5.1. Transfer compressed sensing,[0],[0]
"On the contrary, learning a deep generative model requires access to large amounts of training data.",5.1. Transfer compressed sensing,[0],[0]
"In several applications, getting the data for training a generative model might not be feasible.",5.1. Transfer compressed sensing,[0],[0]
"Hence, we test the generative model-based recovery on the novel task of transfer compressed sensing.
",5.1. Transfer compressed sensing,[0],[0]
Experimental setup.,5.1. Transfer compressed sensing,[0],[0]
We train the generative model on a source domain (assumed to be data-rich) and related to a data-hungry target domain we wish to sense.,5.1. Transfer compressed sensing,[0],[0]
"Given the matching dimensions of MNIST and Omniglot, we conduct experiments transferring from MNIST (source) to Omniglot (target) and vice versa.
Results and Discussion.",5.1. Transfer compressed sensing,[0],[0]
The reconstruction errors for the norms considered are given in Figure 3.,5.1. Transfer compressed sensing,[0],[0]
"For both the sourcetarget pairs, we observe that the Sparse-Gen consistently performs well.",5.1. Transfer compressed sensing,[0],[0]
Vanilla generative model-based recovery shows hardly an improvements with increasing measurements.,5.1. Transfer compressed sensing,[0],[0]
We can qualitatively see this phenomena for transferring from MNIST (source) to Omniglot (target) in Figure 4.,5.1. Transfer compressed sensing,[0],[0]
"With only m = 100 measurements, all models perform poorly and generative model based methods particularly continue to sense images similar to MNIST.",5.1. Transfer compressed sensing,[0],[0]
"On the other hand, there is a noticeable transition at m = 200 measurements for SparseVAE where it adapts better to the domain being sensed than plain generative model-based recovery and achieves lower reconstruction error.",5.1. Transfer compressed sensing,[0],[0]
"Since the introduction of compressed sensing over a decade ago, there has been a vast body of research studying various extensions and applications (Candès & Tao, 2005; Donoho,
2006; Candès et al., 2006).",6. Related Work,[0],[0]
"This work explores the effect of modeling different structural assumptions on signals in theory and practice.
",6. Related Work,[0],[0]
Themes around sparsity in a well-chosen basis has driven much of the research in this direction.,6. Related Work,[0],[0]
"For instance, the paradigm of model-based compressed sensing accounts for the interdependencies between the dimensions of a sparse data signal (Baraniuk et al., 2010; Duarte & Eldar, 2011; Gilbert et al., 2017).",6. Related Work,[0],[0]
"Alternatively, adaptive selection of basis vectors from a dictionary that best capture the structure of the particular signal being sensed has also been explored (Peyre, 2010; Tang et al., 2013).",6. Related Work,[0],[0]
"Many of these methods have been extended to recovery of structured tensors (Zhang et al., 2013; 2014).",6. Related Work,[0],[0]
"In another prominent line of research involving Bayesian compressed sensing, the sparseness assumption is formalized by placing sparsenesspromoting priors on the signals (Ji et al., 2008; He & Carin, 2009; Babacan et al., 2010; Baron et al., 2010).
",6. Related Work,[0],[0]
Research exploring structure beyond sparsity is relatively scarce.,6. Related Work,[0],[0]
Early works in this direction can be traced to Baraniuk & Wakin (2009) who proposed algorithms for recovering signals lying on a smooth manifold.,6. Related Work,[0],[0]
The generative model-based recovery methods consider functions that do not necessarily define manifolds since the range of a generator function could intersect with itself.,6. Related Work,[0],[0]
"Yu & Sapiro (2011) coined the term statistical compressed sensing and proposed
algorithms for efficient sensing of signals from a mixture of Gaussians.",6. Related Work,[0],[0]
The recent work in deep generative model-based recovery differs in key theoretical aspects as well in the use of a more expressive family of models based on neural networks.,6. Related Work,[0],[0]
A related recent work by Hand & Voroninski (2017) provides theoretical guarantees on the solution recovered for solving non-convex linear inverse problems with deep generative priors.,6. Related Work,[0],[0]
"Empirical advances based on well-designed deep neural network architectures that sacrifice many of the theoretical guarantees have been proposed for applications such as MRI (Mardani et al., 2017; 2018).",6. Related Work,[0],[0]
"Many recent methods propose to learn mappings of signals to measurements using neural networks, instead of restricting them to be linear, random matrices (Mousavi et al., 2015; Kulkarni et al., 2016; Chang et al., 2017; Lu et al., 2018).
",6. Related Work,[0],[0]
"Our proposed framework bridges the gap between algorithms that model structure using sparsity and enjoy good theoretical properties with advances in deep generative models, in particular their use for compressed sensing.",6. Related Work,[0],[0]
"The use of deep generative models as priors for compressed sensing presents a new outlook on algorithms for inexpen-
sive data acquisition.",7. Conclusion and Future Work,[0],[0]
"In this work, we showed that these priors can be used in conjunction with classical modeling assumptions based on sparsity.",7. Conclusion and Future Work,[0],[0]
"Our proposed framework, Sparse-Gen, generalizes both sparse vector recovery and recovery using generative models by allowing for sparse deviations from the range of a generative model function.",7. Conclusion and Future Work,[0],[0]
"The benefits of using such modeling assumptions are observed both theoretically and empirically.
",7. Conclusion and Future Work,[0],[0]
"In the future, we would like to design algorithms that can better model the structure within sparse deviations.",7. Conclusion and Future Work,[0],[0]
"Followup work in this direction can benefit from the vast body of prior work in structured sparse vector recovery (Duarte & Eldar, 2011).",7. Conclusion and Future Work,[0],[0]
"From a theoretical perspective, a better understanding of the non-convexity resulting from generative model-based recovery can lead to stronger guarantees and consequently better optimization algorithms for recovery.",7. Conclusion and Future Work,[0],[0]
"Finally, it would be interesting to extend Sparse-Gen for compressed sensing of other data modalities such as graphs for applications in network tomography and reconstruction (Xu et al., 2011).",7. Conclusion and Future Work,[0],[0]
"Real-world graph networks are typically sparse in the canonical basis and can be modeled effectively using deep generative models (Grover et al., 2018), which is consistent with the modeling assumptions of the Sparse-Gen framework.",7. Conclusion and Future Work,[0],[0]
"We are thankful to Tri Dao, Jonathan Kuck, Daniel Levy, Aditi Raghunathan, and Yang Song for helpful comments on early drafts.",Acknowledgements,[0],[0]
"This research was supported by Intel Corporation, TRI, a Hellman Faculty Fellowship, ONR, NSF (#1651565, #1522054, #1733686 ) and FLI (#2017-158687).",Acknowledgements,[0],[0]
AG is supported by a Microsoft Research PhD Fellowship.,Acknowledgements,[0],[0]
"In compressed sensing, a small number of linear measurements can be used to reconstruct an unknown signal.",abstractText,[0],[0]
"Existing approaches leverage assumptions on the structure of these signals, such as sparsity or the availability of a generative model.",abstractText,[0],[0]
A domain-specific generative model can provide a stronger prior and thus allow for recovery with far fewer measurements.,abstractText,[0],[0]
"However, unlike sparsity-based approaches, existing methods based on generative models guarantee exact recovery only over their support, which is typically only a small subset of the space on which the signals are defined.",abstractText,[0],[0]
"We propose Sparse-Gen, a framework that allows for sparse deviations from the support set, thereby achieving the best of both worlds by using a domain specific prior and allowing reconstruction over the full space of signals.",abstractText,[0],[0]
"Theoretically, our framework provides a new class of signals that can be acquired using compressed sensing, reducing classic sparse vector recovery to a special case and avoiding the restrictive support due to a generative model prior.",abstractText,[0],[0]
"Empirically, we observe consistent improvements in reconstruction accuracy over competing approaches, especially in the more practical setting of transfer compressed sensing where a generative model for a data-rich, source domain aids sensing on a data-scarce, target domain.",abstractText,[0],[0]
Modeling Sparse Deviations for Compressed Sensing using Generative Models,title,[0],[0]
"Proceedings of the SIGDIAL 2018 Conference, pages 391–399, Melbourne, Australia, 12-14 July 2018. c©2018 Association for Computational Linguistics
391",text,[0],[0]
"The language understanding (LU) module is a key component of dialogue system (DS), parsing user’s utterances into corresponding semantic concepts (or semantic slots 1).",1 Introduction,[0],[0]
"For example, the utterance “Show me flights from Boston to New York” can be parsed into (from city=Boston, to city=New York) (Pieraccini et al., 1992).",1 Introduction,[0],[0]
"Typically, the LU is seen as a plain slot filling task.
",1 Introduction,[0],[0]
∗The corresponding author is Kai Yu.,1 Introduction,[0],[0]
1Slot and concept are equal in LU.,1 Introduction,[0],[0]
"They will be mixed in
the rest of this paper to some extent.
",1 Introduction,[0],[0]
"With sufficient in-domain data and deep learning models (e.g. recurrent neural networks, bidirectional long-short term memory network), statistical methods have achieved satisfactory performance in the slot filling task recently (Kurata et al., 2016; Vu, 2016; Liu and Lane, 2016).
",1 Introduction,[0],[0]
"However, retrieving sufficient in-domain data for training LU model (Tur et al., 2010) is unrealistic, especially when the semantic slot extends or dialogue domain changes.",1 Introduction,[0],[0]
"The ability of LU approaches to cope with changed domains and limited data is a key to the deployment of commercial dialogue systems (e.g. Apple Siri, Amazon Alexa, Google Home, Microsoft Cortana etc).
",1 Introduction,[0],[0]
"In this paper, we investigate substructure of semantic slots to find out slot relations and promote data reuse.",1 Introduction,[0],[0]
"We represent semantic slots with a hierarchical structure based on atomic concept tuple, as shown in Figure 1.",1 Introduction,[0],[0]
"Each semantic slot is composed of different atomic concepts, e.g. slot “from city” can be defined as a tuple of atoms [“from location”,“city name”],
and “date of birth” can be defined as [“date”,“birth”].
",1 Introduction,[0],[0]
"Unlike the traditional slot definition on a plain level, modeling on the atomic concepts helps identify linguistic patterns of related slots by atom sharing, and even decrease the required amount of training data.",1 Introduction,[0],[0]
"For example, the training and test sets are unmatched in Figure 2, whereas the patterns of atomic concepts (e.g. “from”, “to”, “city”) can be shared.
",1 Introduction,[0],[0]
"In this paper, we investigate the slot filling task switching from plain slots to hierarchical structures by proposing the novel atomic concept tuples which are constructed manually.",1 Introduction,[0],[0]
"For comparison, we also introduce a competitive method which automatically learns slot representation from the word sequence of each slot name.",1 Introduction,[0],[0]
"Our methods are applied to value set mismatch and domain adaptation problems on ATIS (Hemphill et al., 1995) and DSTC 2&3 (Henderson et al., 2013) respectively.",1 Introduction,[0],[0]
"As shown in the experimental results, the slot-filling based on concept transfer learning is effective in solving the value set mismatch and domain adaptation problems.",1 Introduction,[0],[0]
"The concept transfer learning method especially achieves state-of-theart performance (F1-score 96.08%) on the ATIS task.
",1 Introduction,[0],[0]
The rest of the paper is organized as follows.,1 Introduction,[0],[0]
The next section is about the relation to prior work.,1 Introduction,[0],[0]
The atomic concept tuple is introduced in section 3.,1 Introduction,[0],[0]
The proposed concept transfer learning is then described in section 4.,1 Introduction,[0],[0]
Section 5 describes a competitive method with slot embedding derived from the literal descriptions of slot names.,1 Introduction,[0],[0]
"In section 6, the proposed approach is evaluated on the value set mismatch and domain adaptation problems.",1 Introduction,[0],[0]
"Finally, our conclusions are presented in section 7.",1 Introduction,[0],[0]
Slot Filling in LU Zettlemoyer and Collins (2007) proposed a grammar induction method by learning a Probabilistic Combinatory Categorial Grammar (PCCG) from logical-form annotations.,2 Related Work,[0],[0]
"As a
grammar-based method, PCCG is close to a hierarchical concepts structure in grammar generation and combination.",2 Related Work,[0],[0]
"But this grammar-based method does not possess high generalization capability for atomic concept sharing, and heavily depends on a well-defined lexicon set.
",2 Related Work,[0],[0]
Recent research on statistical slot filling in LU has been focused on the Recurrent Neural Network (RNN) and its extensions.,2 Related Work,[0],[0]
"At first, RNN outperformed CRF (Conditional Random Field) on the ATIS dataset (Yao et al., 2013; Mesnil et al., 2013).",2 Related Work,[0],[0]
"Long-short term memory network (LSTM) was introduced to obtain a marginal improvement over RNN (Yao et al., 2014).",2 Related Work,[0],[0]
"After that, many RNN variations were proposed: encoder-labeler model (Kurata et al., 2016), attention model (Liu and Lane, 2016; Zhu and Yu, 2017) etc.",2 Related Work,[0],[0]
"However, these work only predicted the plain semantic slot, not the structure of atomic concepts.
",2 Related Work,[0],[0]
"Domain Adaptation in LU For the domain adaptation in LU, Zhu et al. (2014) proposed generating spoken language surface forms by using patterns of the source domain and the ontology of the target domain.",2 Related Work,[0],[0]
"With regard to the unsupervised LU, Heck and Hakkani-Tur (2012) exploited the structure of semantic knowledge graphs from the web to create natural language surface forms of entity-relation-entity portions of knowledge graphs.",2 Related Work,[0],[0]
"For the zero-shot learning of LU, Ferreira et al. (2015); Yazdani and Henderson (2015) proposed a model to calculate similarity scores between an input sentence and semantic items.",2 Related Work,[0],[0]
"In this paper, we focus on the extension of slots with limited seed data.",2 Related Work,[0],[0]
"Although concept definition is one of the most crucial problems of LU, there is no unified surface form for the domain ontology.",3 Atomic Concept Tuples,[0],[0]
"Even for the same semantic slot, names of this slot may be quite different.",3 Atomic Concept Tuples,[0],[0]
"For example, the city where the flight departs may be called “from city”, “depart city” or “from loc.city name”.",3 Atomic Concept Tuples,[0],[0]
"Ontology definitions from different groups may be similar but not consistent, which is not convenient for data reuse.",3 Atomic Concept Tuples,[0],[0]
"Meanwhile, semantic slots defined in traditional LU systems are on a plain level, while there is no structure to indicate their relation.
",3 Atomic Concept Tuples,[0],[0]
"To solve this problem, we propose to use atomic concepts to represent the semantic slots.",3 Atomic Concept Tuples,[0],[0]
Atomic concepts are exploited to break down the slots.,3 Atomic Concept Tuples,[0],[0]
"We
represent the semantic slots as atomic concept tuples (Figure 1 is an example).",3 Atomic Concept Tuples,[0],[0]
"The semantic slot composed of these atomic concepts can keep a unified resource for concept definition and extend the semantic knowledge flexibly.
",3 Atomic Concept Tuples,[0],[0]
We propose a criteria to construct atomic concept manually.,3 Atomic Concept Tuples,[0],[0]
"For a given vocabulary C of the atomic concepts, a semantic slot s can be represented by a tuple",3 Atomic Concept Tuples,[0],[0]
"[c1, c2, ..., ck], where ci ∈ C is in the i-th dimension and k is tuple length.",3 Atomic Concept Tuples,[0],[0]
"In particular, a “null” atom is introduced for each dimension.",3 Atomic Concept Tuples,[0],[0]
Table 1 illustrates an example of slot representation on the ATIS task.,3 Atomic Concept Tuples,[0],[0]
"To avoid a scratch concept branch, we make a constraint:
Ci ∩ Cj = {null}, 1 ≤ i 6= j ≤ k
where Ci (1 ≤ i ≤ k) denotes all possible atomic concepts which exist in dimension i (i.e. ci ∈ Ci).",3 Atomic Concept Tuples,[0],[0]
"The concept tuple is ordered.
",3 Atomic Concept Tuples,[0],[0]
"In general, atomic concepts can be classified into two categories, one is value-aware and the other is context-aware.",3 Atomic Concept Tuples,[0],[0]
The principle for defining slot as a concept branch is: lower dimension less context-aware.,3 Atomic Concept Tuples,[0],[0]
"For example, “city name” and “airport name” depend on rare context (valueaware).",3 Atomic Concept Tuples,[0],[0]
They should be located in the first dimension.,3 Atomic Concept Tuples,[0],[0]
"“from location” depends on the context like a pattern of “a flight leaves [city name]”, which should be in the second dimension.",3 Atomic Concept Tuples,[0],[0]
"The atomic concept tuple shows the inner relation between different semantic slots explicitly.
",3 Atomic Concept Tuples,[0],[0]
"Therefore, the procedure of constructing atomic concept tuples for slots can be divided into the following steps.
",3 Atomic Concept Tuples,[0],[0]
"• Firstly, we build a vocabularyC of the atomic concepts for all the slots.",3 Atomic Concept Tuples,[0],[0]
"By analyzing the conceptual intersection of different slots, we can split the slots into smaller ones which are called atomic concepts.",3 Atomic Concept Tuples,[0],[0]
"After that, each slot is represented as a set of atomic concepts which are not ordered.
",3 Atomic Concept Tuples,[0],[0]
"• Secondly, we gather the atoms into different groups.",3 Atomic Concept Tuples,[0],[0]
Atomic concepts from the same group should be mutually exclusive.,3 Atomic Concept Tuples,[0],[0]
"Therefore we can investigate the inner relation and outer relation of these groups.
",3 Atomic Concept Tuples,[0],[0]
"• Finally, each group is associated with one dimension (Ci) of the atomic concept tuple.",3 Atomic Concept Tuples,[0],[0]
The groups are ordered depending on whether they are value-aware or contextaware.,3 Atomic Concept Tuples,[0],[0]
The slot filling is typically considered as a sequence labelling problem.,4 Concept Transfer Learning,[0],[0]
"In this paper, we only consider the sequence-labelling based slot filling task.",4 Concept Transfer Learning,[0],[0]
"The input (word) sequence is denoted by w = (w1, w2, ..., wN ), and the output (slot tag) sequence is denoted by s = (s1, s2, ..., sN ).",4 Concept Transfer Learning,[0],[0]
"Since a slot may be mapped to several continuous words, we follow the popular in/out/begin (IOB) representation (e.g. an example in Figure 3).
",4 Concept Transfer Learning,[0],[0]
"The typical slot filling task predicts a plain slot sequence given a word sequence, dubbed as plain slot-filling (PS).
",4 Concept Transfer Learning,[0],[0]
"In this paper, the popular bidirectional LSTMRNN (BLSTM) is used to model the sequence labeling problem (Graves, 2012).",4 Concept Transfer Learning,[0],[0]
It can be exploited to capture both past and future features for a specific time frame.,4 Concept Transfer Learning,[0],[0]
"The BLSTM reads the input sentence w and generates N hidden states hi = ←− hi ⊕ −→ hi , i ∈ {1, .., N}:
←−",4 Concept Transfer Learning,[0],[0]
hi = b,4 Concept Transfer Learning,[0],[0]
"( ←−− hi+1, ewi);",4 Concept Transfer Learning,[0],[0]
−→ hi = f,4 Concept Transfer Learning,[0],[0]
"( −−→ hi−1, ewi)
where ←− hi is the hidden vector of the backward pass in BLSTM and −→ hi is the hidden vector of the forward pass in BLSTM at time i, b and f are LSTM units of the backward and forward passes respectively, ew denotes the word embedding for each word w, and ⊕ denotes the vector concatenation operation.",4 Concept Transfer Learning,[0],[0]
We write the entire operation as a mapping BLSTMΘw,4 Concept Transfer Learning,[0],[0]
"(Θw refers to the parameters):
(h1...hN ) = BLSTMΘw(w1...wN ) (1)
Therefore, the plain slot filling defines a distribution over slot tag sequences given an input word
sequence:
p(s|w) = N∏ i=1 p(si|hi)
= N∏ i=1",4 Concept Transfer Learning,[0],[0]
"softmax(Wo · hi)T δsi
(2)
where the matrix Wo (output layer) consists of the vector representations of each slot tag, the symbol",4 Concept Transfer Learning,[0],[0]
"δd is a Kronecker delta with a dimension for each slot tag, and the softmax function is used to estimate the probability distribution over all possible plain slots.",4 Concept Transfer Learning,[0],[0]
The slot is indicated as an atomic concept tuple based on hierarchical concept structure.,4.1 Atomic-Concepts Based Slot Filling,[0],[0]
"Slot filling is considered as a concept-tuple labelling task.
",4.1 Atomic-Concepts Based Slot Filling,[0],[0]
"(a) Atomic concept independent Slot filling can be transferred to a multi-task sequence labelling problem, regarding these atomic concepts independently (i.e. AC).",4.1 Atomic-Concepts Based Slot Filling,[0],[0]
Each task predicts one atomic concept by a respective output layer.,4.1 Atomic-Concepts Based Slot Filling,[0],[0]
"Thus, the slot filling problem can be formulated as
p(s|w) = N∏ i=1",4.1 Atomic-Concepts Based Slot Filling,[0],[0]
"[p(IOBi|hi) k∏ j=1 p(cij |hi)]
where the semantic slot si is represented by an atomic concept branch [ci1, ci2, ..., cik], and IOBi is the IOB schema tag at time i. As illustrated in Figure 4(a), the semantic slot “from city” can be represented as [“city name”,“from loc”].",4.1 Atomic-Concepts Based Slot Filling,[0],[0]
"The
prediction of IOB is regarded as another task specifically.",4.1 Atomic-Concepts Based Slot Filling,[0],[0]
"All tasks share the same parameters except for the output layers.
",4.1 Atomic-Concepts Based Slot Filling,[0],[0]
(b) Atomic concept dependent Atomic concepts can also be regarded dependently (i.e. ACD) so that atomic concept prediction depends on the former predicted results.,4.1 Atomic-Concepts Based Slot Filling,[0],[0]
"The slot filling problem can be formulated as
p(s|w)
= N∏ i=1",4.1 Atomic-Concepts Based Slot Filling,[0],[0]
"[p(IOBi|hi)p(ci1|hi) k∏ j=2 p(cij |hi, ci,1:j−1)]
where ci,1:j−1 = (ci,1, ..., ci,j−1) is the predicted result of former atomic concepts of slot tag si, indicating a structured multi-task learning framework.
",4.1 Atomic-Concepts Based Slot Filling,[0],[0]
"In this paper, we make some simplifications on concept dependence.",4.1 Atomic-Concepts Based Slot Filling,[0],[0]
"We predict atomic concept only based on the last atomic concept, as shown in Figure 4(b).",4.1 Atomic-Concepts Based Slot Filling,[0],[0]
"Since our approach is a structured multi-task learning problem, the model loss is summed over each task during training.",4.2 Training and Decoding,[0],[0]
"For the domain adaptation, we firstly gather training data from the source domain and seed data from the target domain to be a union set.",4.2 Training and Decoding,[0],[0]
"Subsequently, the union data is fed into the slot filling model.
",4.2 Training and Decoding,[0],[0]
"During the decoding stage, we combine predicted atomic concepts with probability multiplication.",4.2 Training and Decoding,[0],[0]
The evaluation is made on the top-best hypothesis.,4.2 Training and Decoding,[0],[0]
"Although the atomic-concepts based slot
filling may predict an unseen slot.",4.2 Training and Decoding,[0],[0]
We didn’t perform any post-processing but considered the unseen slot as a wrong prediction.,4.2 Training and Decoding,[0],[0]
"In the section, we introduce a competitive system which uses the literal description of the slot as an input of the slot filling model.",5 Literal Description of Slot Name,[0],[0]
"The literal description of slot used in this paper is the word sequence of each slot name, which can be obtained automatically.",5 Literal Description of Slot Name,[0],[0]
"As the names of relative slots may include the same or similar word, the word sequence of slot name can also help reveal the relation between different slots.",5 Literal Description of Slot Name,[0],[0]
"Therefore, it is very meaningful to compare this method with the atomic concept tuples involving human knowledge.
",5 Literal Description of Slot Name,[0],[0]
The architecture of this competitive system is illustrated in Figure 5.,5 Literal Description of Slot Name,[0],[0]
"First, it assumes that each slot name is a meaningful natural language description so that the slot filling task is tractable from the input word sequence and slot name.",5 Literal Description of Slot Name,[0],[0]
"Second, another BLSTM model is applied to derive softmax embedding from the slot names.",5 Literal Description of Slot Name,[0],[0]
"In this method, we also split the slot filling task into IOB tag prediction and slot name prediction.",5 Literal Description of Slot Name,[0],[0]
"In other words, the slot tag si is broken down into IOBi and slot name SNi, e.g. the slot tag “B-from city” is split into “B” and “from city”.",5 Literal Description of Slot Name,[0],[0]
"The details are indicated below.
",5 Literal Description of Slot Name,[0],[0]
"With the BLSTM applied on the input sequence, we have hidden vectors hi, i ∈ {1, .., N} as shown in Eqn.",5 Literal Description of Slot Name,[0],[0]
(1).,5 Literal Description of Slot Name,[0],[0]
"This model redefines the distribution
over slot tag sequences given an input word sequence, compared with Eqn.",5 Literal Description of Slot Name,[0],[0]
"(2):
p(s|w) = N∏ i=1 p(IOBi|hi)p(SNi|hi)
where p(IOBi|hi) predicts the IOB tag and p(SNi|hi) makes a prediction for the slot name.",5 Literal Description of Slot Name,[0],[0]
"We define
p(SNi|hi) =",5 Literal Description of Slot Name,[0],[0]
"softmax(W · hi)T δSNi
where W ∈ RA×B is a matrix, hi ∈ RB is a vector, A is the number of all different slot names.",5 Literal Description of Slot Name,[0],[0]
"The matrix W consists of the embedding of each slot name (i.e. each row vector of W with length B).
",5 Literal Description of Slot Name,[0],[0]
"To capture the slot relation within different slot names, we apply another BLSTM model (as shown in the orange dotted circle of Figure 5) onto the word sequence (literal description) of each slot name.",5 Literal Description of Slot Name,[0],[0]
"For the j-th slot name (j ∈ {1, .., A}) with a word sequence xj = (xj1, ..., x j Nj ), we have
←− vjn = lstm b( ←−− vjn+1, exjn);",5 Literal Description of Slot Name,[0],[0]
"−→ vjn = lstm f ( −−→ vjn−1, exjn)
where ←− vjn is the hidden vector of the backward pass and −→ vjn is the hidden vector of the forward pass at time n",5 Literal Description of Slot Name,[0],[0]
"(n ∈ {1, .., Nj}), ex denotes the word embedding for each word x.",5 Literal Description of Slot Name,[0],[0]
"We take the tails of both backward and forward pass as the slot embedding, i.e.
Wj = ←− vj1 ⊕ −→ vjNj
where Wj is the j-th row vector of matrix W .",5 Literal Description of Slot Name,[0],[0]
The relative slots using the same or similar word in slot naming will be close in the space of slot embedding inherently.,5 Literal Description of Slot Name,[0],[0]
"Therefore, this method is a competitive system to the atomic concept tuples.",5 Literal Description of Slot Name,[0],[0]
We will show the comparison in the following section.,5 Literal Description of Slot Name,[0],[0]
"We evaluate our atomic-concept methods on two tasks: value set mismatch and domain adaptation.
",6 Experiments,[0],[0]
Value set mismatch task evaluates the generalization capability of different slot filling models.,6 Experiments,[0],[0]
"In a language understanding (LU) system, each slot has a value set with all possible values which can be assigned to it.",6 Experiments,[0],[0]
"Since the semantically annotated data is always limited, only a part of values
is seen in the training data.",6 Experiments,[0],[0]
Will the slot filling model perform well on the unseen values?,6 Experiments,[0],[0]
"To answer this question, we synthesize a test set by the values mismatched with the training set of ATIS corpus.",6 Experiments,[0],[0]
"Our methods may take advantages of the prior knowledge about slot relations based on the atomic concepts and the literal descriptions of slot names.
",6 Experiments,[0],[0]
Domain adaptation task evaluates the adaptation capability of our methods when they meet new slots in the target domain.,6 Experiments,[0],[0]
"In this task, a seed training set of the target domain is provided.",6 Experiments,[0],[0]
"However, it is very limited: 1) some new slots may not be covered; 2) not all contexts are covered for each new slot.",6 Experiments,[0],[0]
The atomic-concepts based method would alleviate this problem.,6 Experiments,[0],[0]
Each slot is defined as a tuple of atomic concepts in our method.,6 Experiments,[0],[0]
"Therefore, it is possible to learn an unseen slot of the target domain if its atomic concepts exist in the data of the source domain and the seed data of the target domain.",6 Experiments,[0],[0]
It is also possible to see more contexts for a new slot if its atomic concepts exist in the source domain which has much more data.,6 Experiments,[0],[0]
ATIS corpus has been widely used as a benchmark by the LU community.,6.1 Value Set Mismatch,[0],[0]
"The training data consists of 4978 sentences and the test data consists of 893 sentences.
",6.1 Value Set Mismatch,[0],[0]
"In this task, we perform an adaptation for unmatched training and test sets, in which there are many unseen slot-value pairs in the test set (Figure 2 is an example).",6.1 Value Set Mismatch,[0],[0]
It is a common problem in the development of commercial dialogue system since it is impossible to collect data covering all possible slot-value pairs.,6.1 Value Set Mismatch,[0],[0]
"We simulate this problem on the ATIS dataset (Hemphill et al., 1995) by creating an unmatched test set (ATIS X test).
",6.1 Value Set Mismatch,[0],[0]
ATIS X test is synthesized from the standard ATIS test set by randomly replacing the value of each slot with an unseen one.,6.1 Value Set Mismatch,[0],[0]
"The unseen value sets are collected from the training set according to bottom-level concepts (e.g. “city name”, “airport name”).",6.1 Value Set Mismatch,[0],[0]
"For example, if the value set of “from city” is {“New York”, “Boston”} and the value set of “to city” is {“Boston”}, then the unseen value for “to city” is “New York”.",6.1 Value Set Mismatch,[0],[0]
The test sentence “Flights to [xx:to city]” can be replaced to “Flights to [New York:to city]”.,6.1 Value Set Mismatch,[0],[0]
"Finally, the ATIS X test gets the same sentence number to the standard ATIS test set.",6.1 Value Set Mismatch,[0],[0]
We randomly selected 80% of the training data for model training and the remaining 20% for validation.,6.1.1 Experimental Settings,[0],[0]
We deal with unseen words in the test set by marking any words with only one single occurrence in the training set as 〈unk〉.,6.1.1 Experimental Settings,[0],[0]
"We also converted sequences of numbers to the string DIGIT, e.g. 1990 is converted to DIGIT*4 (Zhang and Wang, 2016).",6.1.1 Experimental Settings,[0],[0]
"Regarding BLSTM model, we set the dimension of word embeddings to 100 and the number of hidden units to 100.",6.1.1 Experimental Settings,[0],[0]
"For training, the network parameters are randomly initialized in accordance with the uniform distribution (-0.2, 0.2).",6.1.1 Experimental Settings,[0],[0]
Stochastic gradient descent (SGD) is used for updating parameters.,6.1.1 Experimental Settings,[0],[0]
"The dropout with a probability of 0.5 is applied to the non-recurrent connections during the training stage.
",6.1.1 Experimental Settings,[0],[0]
"We try different learning rates by grid-search in range of [0.008, 0.04].",6.1.1 Experimental Settings,[0],[0]
We keep the learning rate for 100 epochs and save the parameters that give the best performance on the validation set.,6.1.1 Experimental Settings,[0],[0]
"Finally, we report the F1-score of the semantic slots on the test set with parameters that have achieved the best F1-score on the validation set.",6.1.1 Experimental Settings,[0],[0]
The F1-score is calculated using CoNLL evaluation script.,6.1.1 Experimental Settings,[0],[0]
2,6.1.1 Experimental Settings,[0],[0]
Table 2 summarizes the recently published results on the ATIS slot filling task and compares them with the results of our proposed methods on the standard ATIS test set.,6.1.2 Experimental Results and Analysis,[0],[0]
We can see that RNN outperforms CRF because of the ability to capture long-term dependencies.,6.1.2 Experimental Results and Analysis,[0],[0]
LSTM beats RNN by solving the problem of vanishing or exploding gradients.,6.1.2 Experimental Results and Analysis,[0],[0]
BLSTM further improves the result by considering both the past and future features.,6.1.2 Experimental Results and Analysis,[0],[0]
Encoder-decoder achieves the state-of-theart performance by modeling the label dependencies.,6.1.2 Experimental Results and Analysis,[0],[0]
Encoder-labeler is a similar method to the Encoder-decoder.,6.1.2 Experimental Results and Analysis,[0],[0]
"These systems are designed to predict the plain semantic slots traditionally.
",6.1.2 Experimental Results and Analysis,[0],[0]
"Compared with the published results, our method outperforms the previously published F1score, illustrated in Table 2.",6.1.2 Experimental Results and Analysis,[0],[0]
AC gets a marginal improvement (+0.15%) over PS by predicting the atomic concepts independently instead of the plain slots.,6.1.2 Experimental Results and Analysis,[0],[0]
"Moreover, ACD predicts the atomic concepts dependently, gains 0.50% (significant level 95%) over the AC.",6.1.2 Experimental Results and Analysis,[0],[0]
"Worth to mention that ACD achieves a new state-of-the-art performance of the
2http://www.cnts.ua.ac.be/conll2000/chunking/output.html
standard slot-tagging task on the ATIS dataset, with only the lexicon features 3.
",6.1.2 Experimental Results and Analysis,[0],[0]
Our methods are also tested on the ATIS X test to measure the ability of generalization.,6.1.2 Experimental Results and Analysis,[0],[0]
"For comparison, we also apply dictionary features (ngram indication) of value sets (e.g. some kind of gazetteers) collected from training data into the PS model (i.e. PS+dict-feats in Table 2).",6.1.2 Experimental Results and Analysis,[0],[0]
"From Table 2, we can see that: 1) The plain slot filling models (PS, Encoder-decoder) are not on par with other models.",6.1.2 Experimental Results and Analysis,[0],[0]
2),6.1.2 Experimental Results and Analysis,[0],[0]
"The atomic-concepts based slot filling gets a slight improvement over the PS with dict-feats, considering the concepts independently (AC).",6.1.2 Experimental Results and Analysis,[0],[0]
3),6.1.2 Experimental Results and Analysis,[0],[0]
"The atomic-concepts based slot fillings (ACD gains a large margin over AC, considering the concepts dependently.",6.1.2 Experimental Results and Analysis,[0],[0]
"4) The method based on slot name embedding (described in Section 5) achieves a slight improvement than AC, which implies that it is possible to reveal the relationship between slots automatically.
",6.1.2 Experimental Results and Analysis,[0],[0]
"3There are other published results that achieved better performance by using Name Entity features, e.g. Mesnil et al. (2013) got 96.24% F1-score.",6.1.2 Experimental Results and Analysis,[0],[0]
The NE features are manually annotated and strong information.,6.1.2 Experimental Results and Analysis,[0],[0]
So it would be more meaningful to use only lexicon features.,6.1.2 Experimental Results and Analysis,[0],[0]
"Meanwhile, several other works can obtain competitive results by using the intent classification as another task for joint training, e.g. Liu and Lane (2016) achieved 95.98% F1-score.",6.1.2 Experimental Results and Analysis,[0],[0]
"In this paper, we consider the slot filling task only.
",6.1.2 Experimental Results and Analysis,[0],[0]
"Case study: As illustrated in Table 3, the plain slot filling (PS) predicts the label of “late” wrongly, whereas the atomic-concepts based slot fillings (i.e. AC and ACD) get the accurate annotation.",6.1.2 Experimental Results and Analysis,[0],[0]
The word of “late” is never covered by the slot “period of day” in the training set.,6.1.2 Experimental Results and Analysis,[0],[0]
It is hard for the plain slot filling (PS) to predict an unseen mapping correctly.,6.1.2 Experimental Results and Analysis,[0],[0]
"Luckily, the “late” is covered by the family of the slot “period of day” in the training set, e.g. “arrive time.period of day”.",6.1.2 Experimental Results and Analysis,[0],[0]
"Therefore, AC and ACD can learn this by modeling the atomic concepts separately.",6.1.2 Experimental Results and Analysis,[0],[0]
"Our methods are also evaluated on the DSTC 2&3 task (Henderson et al., 2013) which is considered to be a realistic domain adaptation problem.
",6.2 Domain Adaptation,[0],[0]
DSTC 2 (source domain) comprises of dialogues from the restaurant information domain in Cambridge.,6.2 Domain Adaptation,[0],[0]
"We use the dstc2 train set (1612 dialogues) for training and the dstc2 dev (506 dialogues) for validation.
",6.2 Domain Adaptation,[0],[0]
"DSTC 3 (target domain) introduces the tourist information domain about restaurant, pubs and coffee shops in Cambridge, which is an extension of DSTC 2.",6.2 Domain Adaptation,[0],[0]
"We use seed data dstc3 seed (only 11 dialogues) as the training set of the target domain.
",6.2 Domain Adaptation,[0],[0]
"DSTC3 S test: In this paper, we focus on three new semantic slots: “has tv, has internet, children allowed”.",6.2 Domain Adaptation,[0],[0]
4 They only exist in the DSTC 3 dataset and have few appearances in the seed data.,6.2 Domain Adaptation,[0],[0]
"A test set is chosen for specific evaluation on these new semantic slots, by gathering all the sentences (688 sentences) whose annotation contains these three slots and randomly selecting 1000 sentences irrelevant to these three slots from the dstc3 test set.",6.2 Domain Adaptation,[0],[0]
"This test set is named as DSTC3 S test (1688 sentences).
",6.2 Domain Adaptation,[0],[0]
"The union of a slot and action is taken as a plain semantic slot (e.g. “confirm.food=Chinese”), since each slot is tied with an action (e.g. “inform”, “deny” and “confirm”) in DSTC 2&3.",6.2 Domain Adaptation,[0],[0]
The slot and action are taken as atomic concepts.,6.2 Domain Adaptation,[0],[0]
"For the slot filling task, only the semantic annotation with aligned information is kept, e.g. the semantic tuple “request(phone)” is ignored.",6.2 Domain Adaptation,[0],[0]
"We use transcripts as input, and make slot-value alignment by
4For each slot of “has tv, has internet, children allowed”, the semantic annotation “request(slot)” is replaced with “confirm(slot=True)”.",6.2 Domain Adaptation,[0],[0]
"Then we have the slot-tagging format, e.g. ”does it have [television:confirm.has tv]”.
string matching simply.",6.2 Domain Adaptation,[0],[0]
"The experimental settings are similar to the ATIS’s, whereas the seed data in DSTC 3 is also used for validation.
",6.2.1 Experimental Results and Analysis,[0],[0]
The performance of our methods in the DSTC 2&3 task is illustrated in Table 4.,6.2.1 Experimental Results and Analysis,[0],[0]
"We can see that: 1) By incorporating the data of the source domain (dstc2 train), PS and AC achieve improvements respectively.",6.2.1 Experimental Results and Analysis,[0],[0]
2) AC gains more than PS by modeling the plain semantic slot as atomic concepts.,6.2.1 Experimental Results and Analysis,[0],[0]
The atomic concepts promote the associated slots to share input features for the same atoms.,6.2.1 Experimental Results and Analysis,[0],[0]
3),6.2.1 Experimental Results and Analysis,[0],[0]
The atomic-concepts based slot filling considering the concepts dependently (ACD) gains little (0.17%) over AC considering the concepts independently.,6.2.1 Experimental Results and Analysis,[0],[0]
"It may be due to the small size of dstc3 seed.
",6.2.1 Experimental Results and Analysis,[0],[0]
"Case study: Several cases from these models (trained on the union set of dstc2 train and dstc3 seed) are also chosen to explain why the atomic-concepts based slot filling outperforms the typical plain slot filling, as shown in Table 5.",6.2.1 Experimental Results and Analysis,[0],[0]
"From the above part of Table 5, we can see PS predicts a wrong slot.",6.2.1 Experimental Results and Analysis,[0],[0]
Because the grammar “does it have [something]” is only for the plain slot “confirm.hastv” in the seed data.,6.2.1 Experimental Results and Analysis,[0],[0]
"From the below part of Table 5, we can see that only ACD which considers the concepts dependently predicts the right slot.",6.2.1 Experimental Results and Analysis,[0],[0]
"Since “confirm.childrenallowed” never exists in the seed data, PS can’t learn patterns about it.",6.2.1 Experimental Results and Analysis,[0],[0]
"Limited by the quantity of the seed data, AC also doesn’t extract the semantics correctly.",6.2.1 Experimental Results and Analysis,[0],[0]
"To address data sparsity problem of language understanding (LU) task, we present a novel method of concept definition based on well-defined atomic concepts.",7 Conclusion,[0],[0]
We present the concept transfer learning for slot filling on the atomic concept level to solve the problem of adaptive LU.,7 Conclusion,[0],[0]
"The experiments on the ATIS and DSTC 2&3 datasets show our method obtains promising results and outperforms the traditional slot filling, due to the knowledge sharing of atomic concepts.
",7 Conclusion,[0],[0]
The atomic concepts are constructed manually in this paper.,7 Conclusion,[0],[0]
"In future work, we want to explore more flexible concept definition for concept transfer learning of LU.",7 Conclusion,[0],[0]
"Moreover, we also propose a competitive method based on slot name embedding which can be extracted from the literal description of the slot name automatically.",7 Conclusion,[0],[0]
The experimental result shows that it lays foundation for finding a more flexible concept definition method for adaptive LU.,7 Conclusion,[0],[0]
"This work has been supported by the China NSFC project (No. 61573241), Shanghai International Science and Technology Cooperation Fund (No. 16550720300) and the JiangSu NSFC project (BE2016078).",Acknowledgments,[0],[0]
Experiments have been carried out on the PI supercomputer at Shanghai Jiao Tong University.,Acknowledgments,[0],[0]
We also thank Tianfan Fu for comments that greatly improved the manuscript.,Acknowledgments,[0],[0]
Concept definition is important in language understanding (LU) adaptation since literal definition difference can easily lead to data sparsity even if different data sets are actually semantically correlated.,abstractText,[0],[0]
"To address this issue, in this paper, a novel concept transfer learning approach is proposed.",abstractText,[0],[0]
"Here, substructures within literal concept definition are investigated to reveal the relationship between concepts.",abstractText,[0],[0]
"A hierarchical semantic representation for concepts is proposed, where a semantic slot is represented as a composition of atomic concepts.",abstractText,[0],[0]
"Based on this new hierarchical representation, transfer learning approaches are developed for adaptive LU.",abstractText,[0],[0]
"The approaches are applied to two tasks: value set mismatch and domain adaptation, and evaluated on two LU benchmarks: ATIS and DSTC 2&3.",abstractText,[0],[0]
Thorough empirical studies validate both the efficiency and effectiveness of the proposed method.,abstractText,[0],[0]
"In particular, we achieve state-ofthe-art performance (F1-score 96.08%) on ATIS by only using lexicon features.",abstractText,[0],[0]
Concept Transfer Learning for Adaptive Language Understanding,title,[0],[0]
"Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 2153–2162, Austin, Texas, November 1-5, 2016. c©2016 Association for Computational Linguistics
Recently a variety of LSTM-based conditional language models (LM) have been applied across a range of language generation tasks. In this work we study various model architectures and different ways to represent and aggregate the source information in an endto-end neural dialogue system framework. A method called snapshot learning is also proposed to facilitate learning from supervised sequential signals by applying a companion cross-entropy objective function to the conditioning vector. The experimental and analytical results demonstrate firstly that competition occurs between the conditioning vector and the LM, and the differing architectures provide different trade-offs between the two. Secondly, the discriminative power and transparency of the conditioning vector is key to providing both model interpretability and better performance. Thirdly, snapshot learning leads to consistent performance improvements independent of which architecture is used.",text,[0],[0]
"Recurrent Neural Network (RNN)-based conditional language models (LM) have been shown to be very effective in tackling a number of real world problems, such as machine translation (MT) (Cho et al., 2014) and image caption generation (Karpathy and Fei-Fei, 2015).",1 Introduction,[0],[0]
"Recently, RNNs were applied to task of generating sentences from an explicit semantic representation (Wen et al., 2015a).",1 Introduction,[0],[0]
"Attention-based methods (Mei et al., 2016) and Long Short-term Memory (LSTM)-like (Hochreiter
and Schmidhuber, 1997) gating mechanisms (Wen et al., 2015b) have both been studied to improve generation quality.",1 Introduction,[0],[0]
"Although it is now clear that LSTMbased conditional LMs can generate plausible natural language, less effort has been put in comparing the different model architectures.",1 Introduction,[0],[0]
"Furthermore, conditional generation models are typically tested on relatively straightforward tasks conditioned on a single source (e.g. a sentence or an image) and where the goal is to optimise a single metric (e.g. BLEU).",1 Introduction,[0],[0]
"In this work, we study the use of conditional LSTMs in the generation component of neural network (NN)-based dialogue systems which depend on multiple conditioning sources and optimising multiple metrics.
",1 Introduction,[0],[0]
"Neural conversational agents (Vinyals and Le, 2015; Shang et al., 2015) are direct extensions of the sequence-to-sequence model (Sutskever et al., 2014) in which a conversation is cast as a source to target transduction problem.",1 Introduction,[0],[0]
"However, these models are still far from real world applications because they lack any capability for supporting domain specific tasks, for example, being able to interact with databases (Sukhbaatar et al., 2015; Yin et al., 2016) and aggregate useful information into their responses.",1 Introduction,[0],[0]
"Recent work by Wen et al. (2016a), however, proposed an end-to-end trainable neural dialogue system that can assist users to complete specific tasks.",1 Introduction,[0],[0]
"Their system used both distributed and symbolic representations to capture user intents, and these collectively condition a NN language generator to generate system responses.",1 Introduction,[0],[0]
"Due to the diversity of the conditioning information sources, the best way to represent and combine them is non-trivial.
2153
",1 Introduction,[0],[0]
"In Wen et al. (2016a), the objective function for learning the dialogue policy and language generator depends solely on the likelihood of the output sentences.",1 Introduction,[0],[0]
"However, this sequential supervision signal may not be informative enough to learn a good conditioning vector representation resulting in a generation process which is dominated by the LM.",1 Introduction,[0],[0]
"This can often lead to inappropriate system outputs.
",1 Introduction,[0],[0]
"In this paper, we therefore also investigate the use of snapshot learning which attempts to mitigate this problem by heuristically applying companion supervision signals to a subset of the conditioning vector.",1 Introduction,[0],[0]
"This idea is similar to deeply supervised nets (Lee et al., 2015) in which the final cost from the output layer is optimised together with the companion signals generated from each intermediary layer.",1 Introduction,[0],[0]
We have found that snapshot learning offers several benefits: (1) it consistently improves performance; (2) it learns discriminative and robust feature representations and alleviates the vanishing gradient problem; (3) it appears to learn transparent and interpretable subspaces of the conditioning vector.,1 Introduction,[0],[0]
"Machine learning approaches to task-oriented dialogue system design have cast the problem as a partially observable Markov Decision Process (POMDP) (Young et al., 2013) with the aim of using reinforcement learning (RL) to train dialogue policies online through interactions with real users (Gašić et al., 2013).",2 Related Work,[0],[0]
"In order to make RL tractable, the state and action space must be carefully designed (Young et al., 2010) and the understanding (Henderson et al., 2014; Mrkšić et al., 2015) and generation (Wen et al., 2015b; Wen et al., 2016b) modules were assumed available or trained standalone on supervised corpora.",2 Related Work,[0],[0]
"Due to the underlying hand-coded semantic representation (Traum, 1999), the conversation is far from natural and the comprehension capability is limited.",2 Related Work,[0],[0]
"This motivates the use of neural networks to model dialogues from end to end as a conditional generation problem.
",2 Related Work,[0],[0]
"Interest in generating natural language using NNs can be attributed to the success of RNN LMs for large vocabulary speech recognition (Mikolov et al., 2010; Mikolov et al., 2011).",2 Related Work,[0],[0]
"Sutskever et al. (2011) showed that plausible sentences can be
obtained by sampling characters one by one from the output layer of an RNN.",2 Related Work,[0],[0]
"By conditioning an LSTM on a sequence of characters, Graves (2013) showed that machines can synthesise handwriting indistinguishable from that of a human.",2 Related Work,[0],[0]
"Later on, this idea has been tried in several research fields, for example, generating image captions by conditioning an RNN on a convolutional neural network (CNN) output (Karpathy and Fei-Fei, 2015; Xu et al., 2015); translating a source to a target language by conditioning a decoder LSTM on top of an encoder LSTM (Cho et al., 2014; Bahdanau et al., 2015); or generating natural language by conditioning on a symbolic semantic representation (Wen et al., 2015b; Mei et al., 2016).",2 Related Work,[0],[0]
"Among all these methods, attention-based mechanisms (Bahdanau et al., 2015; Hermann et al., 2015; Ling et al., 2016) have been shown to be very effective improving performance using a dynamic source aggregation strategy.
",2 Related Work,[0],[0]
"To model dialogue as conditional generation, a sequence-to-sequence learning (Sutskever et al., 2014) framework has been adopted.",2 Related Work,[0],[0]
Vinyals and Le (2015) trained the same model on several conversation datasets and showed that the model can generate plausible conversations.,2 Related Work,[0],[0]
"However, Serban et al. (2015b) discovered that the majority of the generated responses are generic due to the maximum likelihood criterion, which was latter addressed by Li et al. (2016a) using a maximum mutual information decoding strategy.",2 Related Work,[0],[0]
"Furthermore, the lack of a consistent system persona was also studied in Li et al. (2016b).",2 Related Work,[0],[0]
"Despite its demonstrated potential, a major barrier for this line of research is data collection.",2 Related Work,[0],[0]
"Many works (Lowe et al., 2015; Serban et al., 2015a; Dodge et al., 2016) have investigated conversation datasets for developing chat bot or QA-like general purpose conversation agents.",2 Related Work,[0],[0]
"However, collecting data to develop goal oriented dialogue systems that can help users to complete a task in a specific domain remains difficult.",2 Related Work,[0],[0]
"In a recent work by Wen et al. (2016a), this problem was addressed by designing an online, parallel version of Wizard-of-Oz data collection (Kelley, 1984) which allows large scale and cheap in-domain conversation data to be collected using Amazon Mechanical Turk.",2 Related Work,[0],[0]
"An NNbased dialogue model was also proposed to learn from the collected dataset and was shown to be able to assist human subjects to complete specific tasks.
",2 Related Work,[0],[0]
"Snapshot learning can be viewed as a special form of weak supervision (also known as distant- or self supervision) (Craven and Kumlien, 1999; Snow et al., 2004), in which supervision signals are heuristically labelled by matching unlabelled corpora with entities or attributes in a structured database.",2 Related Work,[0],[0]
"It has been widely applied to relation extraction (Mintz et al., 2009) and information extraction (Hoffmann et al., 2011) in which facts from a knowledge base (e.g. Freebase) were used as objectives to train classifiers.",2 Related Work,[0],[0]
"Recently, self supervision was also used in memory networks (Hill et al., 2016) to improve the discriminative power of memory attention.",2 Related Work,[0],[0]
"Conceptually, snapshot learning is related to curriculum learning (Bengio et al., 2009).",2 Related Work,[0],[0]
"Instead of learning easier examples before difficult ones, snapshot learning creates an easier target for each example.",2 Related Work,[0],[0]
"In practice, snapshot learning is similar to deeply supervised nets (Lee et al., 2015) in which companion objectives are generated from intermediary layers and optimised altogether with the output objective.",2 Related Work,[0],[0]
The testbed for this work is a neural network-based task-oriented dialogue system proposed by Wen et al. (2016a).,3 Neural Dialogue System,[0],[0]
"The model casts dialogue as a source to target sequence transduction problem (modelled by a sequence-to-sequence architecture (Sutskever et al., 2014))",3 Neural Dialogue System,[0],[0]
"augmented with the dialogue history (modelled by a belief tracker (Henderson et al., 2014)) and the current database search outcome (modelled by a database operator).",3 Neural Dialogue System,[0],[0]
The model consists of both encoder and decoder modules.,3 Neural Dialogue System,[0],[0]
The details of each module are given below.,3 Neural Dialogue System,[0],[0]
"At each turn t, the goal of the encoder is to produce a distributed representation of the system action mt, which is then used to condition a decoder to generate the next system response in skeletal form1.",3.1 Encoder Module,[0],[0]
"It consists of four submodules: intent network, belief tracker, database operator, and policy network.",3.1 Encoder Module,[0],[0]
Intent Network,3.1 Encoder Module,[0],[0]
"The intent network takes a sequence of tokens1 and converts it into a sentence embedding representing the user intent using an LSTM
1Delexicalisation: slots and values are replaced by generic tokens (e.g. keywords like Chinese food are replaced by [v.food] [s.food] to allow weight sharing.
network.",3.1 Encoder Module,[0],[0]
The hidden layer of the LSTM at the last encoding step zt is taken as the representation.,3.1 Encoder Module,[0],[0]
"As mentioned in Wen et al. (2016a), this representation can be viewed as a distributed version of the speech act (Traum, 1999) used in traditional systems.",3.1 Encoder Module,[0],[0]
"Belief Trackers In addition to the intent network, the neural dialogue system uses a set of slot-based belief trackers (Henderson et al., 2014; Mrkšić et al., 2015) to track user requests.",3.1 Encoder Module,[0],[0]
"By taking each user input as new evidence, the task of a belief tracker is to maintain a multinomial distribution p over values v ∈",3.1 Encoder Module,[0],[0]
"Vs for each informable slot2 s, and a binary distribution for each requestable slot2.",3.1 Encoder Module,[0],[0]
These probability distributions pst are called belief states of the system.,3.1 Encoder Module,[0],[0]
"The belief states pst , together with the intent vector zt, can be viewed as the system’s comprehension of the user requests up to turn t. Database Operator Based on the belief states pst , a DB query is formed by taking the union of the maximum values of each informable slot.",3.1 Encoder Module,[0],[0]
"A vector xt representing different degrees of matching in the DB (no match, 1 match, ... or more than 5 matches) is produced by counting the number of matched entities and expressing it as a 6-bin 1-hot encoding.",3.1 Encoder Module,[0],[0]
"If xt is not zero, an associated entity pointer is maintained which identifies one of the matching DB entities selected at random.",3.1 Encoder Module,[0],[0]
The entity pointer is updated if the current entity no longer matches the search criteria; otherwise it stays the same.,3.1 Encoder Module,[0],[0]
"Policy Network Based on the vectors zt, pst , and xt from the above three modules, the policy network combines them into a single action vector mt by a three-way matrix transformation,
mt = tanh(Wzmzt + Wxmxt + ∑ s∈G W s pmp s t ) (1)
where matrices Wzm, Wspm, and Wxm are parameters and G is the domain ontology.",3.1 Encoder Module,[0],[0]
"Conditioned on the system action vector mt provided by the encoder module, the decoder module uses a conditional LSTM LM to generate the required system output token by token in skeletal form1.",3.2 Decoder Module,[0],[0]
"The final system response can then be formed
2Informable slots are slots that users can use to constrain the search, such as food type or price range; Requestable slots are slots that users can ask a value for, such as phone number.",3.2 Decoder Module,[0],[0]
"This information is specified in the domain ontology.
by substituting the actual values of the database entries into the skeletal sentence structure.",3.2 Decoder Module,[0],[0]
"In this paper we study and analyse three different variants of LSTM-based conditional generation architectures: Language Model Type The most straightforward way to condition the LSTM network on additional source information is to concatenate the conditioning vector mt together with the input word embedding wj and previous hidden layer hj−1,
 
ij fj",3.2.1 Conditional Generation Network,[0],[0]
"oj ĉj
  =  
sigmoid sigmoid sigmoid tanh
 W4n,3n  
",3.2.1 Conditional Generation Network,[0],[0]
"mt wj hj−1
 
cj = fj cj−1 +",3.2.1 Conditional Generation Network,[0],[0]
"ij ĉj hj = oj tanh(cj)
where index j is the generation step, n is the hidden layer size, ij , fj ,oj ∈",3.2.1 Conditional Generation Network,[0],[0]
"[0, 1]n are input, forget, and output gates respectively, ĉj and cj are proposed cell value and true cell value at step j, and W4n,3n are the model parameters.",3.2.1 Conditional Generation Network,[0],[0]
The model is shown in Figure 1a.,3.2.1 Conditional Generation Network,[0],[0]
"Since it does not differ significantly from the original LSTM, we call it the language model type (lm) conditional generation network.",3.2.1 Conditional Generation Network,[0],[0]
Memory Type,3.2.1 Conditional Generation Network,[0],[0]
"The memory type (mem) conditional generation network was introduced by Wen et al. (2015b), shown in Figure 1b, in which the conditioning vector mt is governed by a standalone reading gate rj .",3.2.1 Conditional Generation Network,[0],[0]
"This reading gate decides how much information should be read from the conditioning vector and directly writes it into the memory cell cj ,
 
ij",3.2.1 Conditional Generation Network,[0],[0]
fj,3.2.1 Conditional Generation Network,[0],[0]
"oj rj
  =  
sigmoid sigmoid sigmoid sigmoid
 W4n,3n  
mt wj hj−1
 
ĉj = tanh ( Wc(wj ⊕ hj−1) )
",3.2.1 Conditional Generation Network,[0],[0]
cj = fj cj−1 +,3.2.1 Conditional Generation Network,[0],[0]
ij ĉj,3.2.1 Conditional Generation Network,[0],[0]
+,3.2.1 Conditional Generation Network,[0],[0]
"rj mt
hj = oj tanh(cj)
where Wc is another weight matrix to learn.",3.2.1 Conditional Generation Network,[0],[0]
The idea behind this is that the model isolates the conditioning vector from the LM so that the model has more flexibility to learn to trade off between the two.,3.2.1 Conditional Generation Network,[0],[0]
"Hybrid Type Continuing with the same idea as the memory type network, a complete separation of conditioning vector and LM (except for the gate controlling the signals) is provided by the hybrid type network shown in Figure 1c,
 
ij fj",3.2.1 Conditional Generation Network,[0],[0]
"oj rj
  =  
sigmoid sigmoid sigmoid sigmoid
 W4n,3n  
mt wj hj−1
 
ĉj = tanh ( Wc(wj ⊕ hj−1) )
",3.2.1 Conditional Generation Network,[0],[0]
"cj = fj cj−1 + ij ĉj
hj = oj tanh(cj) +",3.2.1 Conditional Generation Network,[0],[0]
"rj mt
This model was motivated by the fact that long-term dependency is not needed for the conditioning vector because we apply this information at every step j anyway.",3.2.1 Conditional Generation Network,[0],[0]
The decoupling of the conditioning vector and the LM is attractive because it leads to better interpretability of the results and provides the potential to learn a better conditioning vector and LM.,3.2.1 Conditional Generation Network,[0],[0]
Attention,3.2.2 Attention and Belief Representation,[0],[0]
An attention-based mechanism provides an effective approach for aggregating multiple information sources for prediction tasks.,3.2.2 Attention and Belief Representation,[0],[0]
"Like Wen et al.
(2016a), we explore the use of an attention mechanism to combine the tracker belief states in which the policy network in Equation 1 is modified as
mjt =",3.2.2 Attention and Belief Representation,[0],[0]
"tanh(Wzmzt + Wxmxt + ∑ s∈G α j sWspmp s t )
where the attention weights αjs are calculated by,
αjs = softmax ( rᵀ tanh ( Wr · (vt ⊕ pst ⊕wtj ⊕ htj−1) ))
",3.2.2 Attention and Belief Representation,[0],[0]
where vt = zt + xt and matrix Wr and vector r are parameters to learn.,3.2.2 Attention and Belief Representation,[0],[0]
Belief Representation The effect of different belief state representations on the end performance are also studied.,3.2.2 Attention and Belief Representation,[0],[0]
"For user informable slots, the full belief state pst is the original state containing all categorical values; the summary belief state contains only three components: the summed value of all categorical probabilities, the probability that the user said they “don’t care” about this slot and the probability that the slot has not been mentioned.",3.2.2 Attention and Belief Representation,[0],[0]
"For user requestable slots, on the other hand, the full belief state is the same as the summary belief state because the slot values are binary rather than categorical.",3.2.2 Attention and Belief Representation,[0],[0]
"Learning conditional generation models from sequential supervision signals can be difficult, because it requires the model to learn both long-term word dependencies and potentially distant source encoding functions.",3.3 Snapshot Learning,[0],[0]
"To mitigate this difficulty, we introduce a novel method called snapshot learning to create a vector of binary labels Υjt ∈",3.3 Snapshot Learning,[0],[0]
"[0, 1]d, d < dim(mjt )",3.3 Snapshot Learning,[0],[0]
"as the snapshot of the remaining part of the output sentence Tt,j:|Tt| from generation step",3.3 Snapshot Learning,[0],[0]
"j. Each element of the snapshot vector is an indicator function of a certain event that will happen in the future, which can be obtained either from the system response or dialogue context at training time.",3.3 Snapshot Learning,[0],[0]
"A companion cross entropy error is then computed to force a subset of the conditioning vector m̂jt ⊂ mjt to be close to the snapshot vector,
Lss(·) =",3.3 Snapshot Learning,[0],[0]
"− ∑
t ∑ j E[H(Υ j t , m̂ j t )]",3.3 Snapshot Learning,[0],[0]
"(2)
whereH(·) is the cross entropy function, Υjt and m̂jt are elements of vectors",3.3 Snapshot Learning,[0],[0]
"Υjt and m̂ j t , respectively.",3.3 Snapshot Learning,[0],[0]
"In order to make the tanh activations of m̂jt compatible with the 0-1 snapshot labels, we squeeze each
value of m̂jt by adding 1 and dividing by 2 before computing the cost.
",3.3 Snapshot Learning,[0],[0]
"The indicator functions we use in this work have two forms: (1) whether a particular slot value (e.g., [v.food]1) is going to occur, and (2) whether the system has offered a venue3, as shown in Figure 2.",3.3 Snapshot Learning,[0],[0]
The offer label in the snapshot is produced by checking the delexicalised name token ([v.name]) in the entire dialogue.,3.3 Snapshot Learning,[0],[0]
"If it has occurred, every label in subsequent turns is labelled with 1.",3.3 Snapshot Learning,[0],[0]
Otherwise it is labelled with 0.,3.3 Snapshot Learning,[0],[0]
"To create snapshot targets for a particular slot value, the output sentence is matched with the corresponding delexicalised token turn by turn, per generation step.",3.3 Snapshot Learning,[0],[0]
"At each generation step, the target is labelled with 0 if that delexicalised token has been generated; otherwise it is set to 1.",3.3 Snapshot Learning,[0],[0]
"However, for the models without attention, the targets per turn are set to the same because the condition vector will not be able to learn the dynamically changing behaviour without attention.",3.3 Snapshot Learning,[0],[0]
"Dataset The dataset used in this work was collected in the Wizard-of-Oz online data collection described by Wen et al. (2016a), in which the task of the system is to assist users to find a restaurant in Cambridge, UK area.",4 Experiments,[0],[0]
"There are three informable slots (food, pricerange, area) that users can use to constrain the search and six requestable slots (address, phone, postcode plus the three informable
3Details of the specific application used in this study are given in Section 4 below.
slots) that the user can ask a value for once a restaurant has been offered.",4 Experiments,[0],[0]
There are 676 dialogues in the dataset (including both finished and unfinished dialogues) and approximately 2750 turns in total.,4 Experiments,[0],[0]
The database contains 99 unique restaurants.,4 Experiments,[0],[0]
Training The training procedure was divided into two stages.,4 Experiments,[0],[0]
"Firstly, the belief tracker parameters θb were pre-trained using cross entropy errors between tracker labels and predictions.",4 Experiments,[0],[0]
"Having fixed the tracker parameters, the remaining parts of the model θ\b are trained using the cross entropy errors from the generation network LM,
L(θ\b) =",4 Experiments,[0],[0]
"− ∑
t ∑ j H(y t j ,p t j) + λLss(·) (3)
where ytj and p t j are output token targets and predictions respectively, at turn t of output step j, Lss(·) is the snapshot cost from Equation 2, and λ is the tradeoff parameter in which we set to 1 for all models trained with snapshot learning.",4 Experiments,[0],[0]
We treated each dialogue as a batch and used stochastic gradient descent with a small l2 regularisation term to train the model.,4 Experiments,[0],[0]
"The collected corpus was partitioned into a training, validation, and testing sets in the ratio 3:1:1.",4 Experiments,[0],[0]
Early stopping was implemented based on the validation set considering only LM log-likelihoods.,4 Experiments,[0],[0]
Gradient clipping was set to 1.,4 Experiments,[0],[0]
"The hidden layer sizes were set to 50, and the weights were randomly
initialised between -0.3 and 0.3 including word embeddings.",4 Experiments,[0],[0]
"The vocabulary size is around 500 for both input and output, in which rare words and words that can be delexicalised have been removed.
",4 Experiments,[0],[0]
"Decoding In order to compare models trained with different recipes rather than decoding strategies, we decode all the trained models with the average log probability of tokens in the sentence.",4 Experiments,[0],[0]
"We applied beam search with a beamwidth equal to 10, the search stops when an end-of-sentence token is generated.",4 Experiments,[0],[0]
"In order to consider language variability, we ran decoding until 5 candidates were obtained and performed evaluation on them.
",4 Experiments,[0],[0]
Metrics We compared models trained with different recipes by performing a corpus-based evaluation in which the model is used to predict each system response in the held-out test set.,4 Experiments,[0],[0]
"Three evaluation metrics were used: BLEU score (on top-1 and top5 candidates) (Papineni et al., 2002), slot matching rate and objective task success rate (Su et al., 2015).",4 Experiments,[0],[0]
"The dialogue is marked as successful if both: (1) the offered entity matches the task that was specified to the user, and (2) the system answered all the associated information requests (e.g. what is the address?) from the user.",4 Experiments,[0],[0]
"The slot matching rate is the percentage of delexicalised tokens (e.g. [s.food] and [v.area]1) appear in the candidate also appear in the
reference.",4 Experiments,[0],[0]
We computed the BLEU scores on the skeletal sentence forms before substituting with the actual entity values.,4 Experiments,[0],[0]
All the results were averaged over 10 random initialised networks.,4 Experiments,[0],[0]
Results Table 1 shows the evaluation results.,4 Experiments,[0],[0]
The numbers to the left and right of each table cell are the same model trained w/o and w/ snapshot learning.,4 Experiments,[0],[0]
The first observation is that snapshot learning consistently improves on most metrics regardless of the model architecture.,4 Experiments,[0],[0]
This is especially true for BLEU scores.,4 Experiments,[0],[0]
"We think this may be attributed to the more discriminative conditioning vector learned through the snapshot method, which makes the learning of the conditional LM easier.
",4 Experiments,[0],[0]
"In the first block belief state representation, we compare the effect of two different belief representations.",4 Experiments,[0],[0]
"As can be seen, using a succinct representation is better (summary>full) because the identity of each categorical value in the belief state does not help when the generation decisions are done in skeletal form.",4 Experiments,[0],[0]
"In fact, the full belief state representation may encourage the model to learn incorrect coadaptation among features when the data is scarce.
",4 Experiments,[0],[0]
"In the conditional architecture block, we compare the three different conditional generation architectures as described in section 3.2.1.",4 Experiments,[0],[0]
"This result shows that the language model type (lm) and memory type (mem) networks perform better in terms of BLEU score and slot matching rate, while the hybrid type (hybrid) networks achieve higher task success.",4 Experiments,[0],[0]
"This is probably due to the degree of separation be-
tween the LM and conditioning vector: a coupling approach (lm, mem) sacrifices the conditioning vector but learns a better LM and higher BLEU; while a complete separation (hybrid) learns a better conditioning vector and offers a higher task success.
",4 Experiments,[0],[0]
"Lastly, in the attention-based model block we train the three architectures with the attention mechanism and compare them again.",4 Experiments,[0],[0]
"Firstly, the characteristics of the three models we observed above also hold for attention-based models.",4 Experiments,[0],[0]
"Secondly, we found that the attention mechanism improves all the three architectures on task success rate but not BLEU scores.",4 Experiments,[0],[0]
"This is probably due to the limitations of using n-gram based metrics like BLEU to evaluate the generation quality (Stent et al., 2005).",4 Experiments,[0],[0]
Gate Activations We first studied the average activation of each individual gate in the models by averaging them when running generation on the test set.,5 Model Analysis,[0],[0]
We analysed the hybrid models because their reading gate to output gate activation ratio (rj/oj) shows clear tradeoff between the LM and the conditioning vector components.,5 Model Analysis,[0],[0]
"As can be seen in Ta-
ble 2, we found that the average forget gate activations (fj) and the ratio of the reading gate to the output gate activation (rj/oj) have strong correlations to performance: a better performance (row 3>row 2>row 1) seems to come from models that can learn a longer word dependency (higher forget gate ft activations) and a better conditioning vector (therefore higher reading to output gate ratio rj/oj).",5 Model Analysis,[0],[0]
Learned Attention We have visualised the learned attention heat map of models trained with and without snapshot learning in Figure 3.,5 Model Analysis,[0],[0]
The attention is on both the informable slot trackers (first three columns) and the requestable slot trackers (the other columns).,5 Model Analysis,[0],[0]
We found that the model trained with snapshot learning (Figure 3b) seems to produce a more accurate and discriminative attention heat map comparing to the one trained without it (Figure 3a).,5 Model Analysis,[0],[0]
This may contribute to the better performance achieved by the snapshot learning approach.,5 Model Analysis,[0],[0]
Snapshot Neurons,5 Model Analysis,[0],[0]
"As mentioned earlier, snapshot learning forces a subspace of the conditioning vector m̂jt to become discriminative and interpretable.",5 Model Analysis,[0],[0]
Three example generated sentences together with the snapshot neuron activations are shown in Figure 4.,5 Model Analysis,[0],[0]
"As can be seen, when generating words one by one, the neuron activations were changing to detect different events they were assigned by the snapshot training signals: e.g. in Figure 4b the light blue and orange neurons switched their domination role when the token [v.address] was generated; the offered neuron is in a high activation state in Figure 4b because the system was offering a venue, while in Figure 4a it is not activated because the system was still helping the user to find a venue.",5 Model Analysis,[0],[0]
This paper has investigated different conditional generation architectures and a novel method called snapshot learning to improve response generation in a neural dialogue system framework.,6 Conclusion and Future Work,[0],[0]
The results showed three major findings.,6 Conclusion and Future Work,[0],[0]
"Firstly, although the hybrid type model did not rank highest on all metrics, it is nevertheless preferred because it achieved the highest task success and also it provided more interpretable results.",6 Conclusion and Future Work,[0],[0]
"Secondly, snapshot learning provided gains on virtually all metrics regardless of the architecture used.",6 Conclusion and Future Work,[0],[0]
"The analysis suggested that the benefit of snapshot learning mainly comes from the more discriminative and robust subspace representation learned from the heuristically labelled companion signals, which in turn facilitates optimisation of the final target objective.",6 Conclusion and Future Work,[0],[0]
"Lastly, the results suggested that by making a complex system more interpretable at different levels not only helps our understanding but also leads to the highest success rates.
",6 Conclusion and Future Work,[0],[0]
"However, there is still much work left to do.",6 Conclusion and Future Work,[0],[0]
This work focused on conditional generation architectures and snapshot learning in the scenario of generating dialogue responses.,6 Conclusion and Future Work,[0],[0]
It would be very helpful if the same comparison could be conducted in other application domains such as machine translation or image caption generation so that a wider view of the effectiveness of these approaches can be assessed.,6 Conclusion and Future Work,[0],[0]
"Furthermore, removing slot-value delexicalisation and learning confirmation behaviour in noisy speech conditions are also main research problems from the system development prospective.",6 Conclusion and Future Work,[0],[0]
"Tsung-Hsien Wen and David Vandyke are supported by Toshiba Research Europe Ltd, Cambridge Research Laboratory.",Acknowledgments,[0],[0]
Recently a variety of LSTM-based conditional language models (LM) have been applied across a range of language generation tasks.,abstractText,[0],[0]
In this work we study various model architectures and different ways to represent and aggregate the source information in an endto-end neural dialogue system framework.,abstractText,[0],[0]
A method called snapshot learning is also proposed to facilitate learning from supervised sequential signals by applying a companion cross-entropy objective function to the conditioning vector.,abstractText,[0],[0]
"The experimental and analytical results demonstrate firstly that competition occurs between the conditioning vector and the LM, and the differing architectures provide different trade-offs between the two.",abstractText,[0],[0]
"Secondly, the discriminative power and transparency of the conditioning vector is key to providing both model interpretability and better performance.",abstractText,[0],[0]
"Thirdly, snapshot learning leads to consistent performance improvements independent of which architecture is used.",abstractText,[0],[0]
Conditional Generation and Snapshot Learning in Neural Dialogue Systems,title,[0],[0]
"We consider the problem of estimating the parameters θ ∈ RM of an unnormalised statistical model φ(u;θ) : X 7→ R+ from observed data X = {x1, . . .",1. Introduction,[0],[0]
",xN}, where the
*Equal contribution 1UMIC, RWTH Aachen University, Aachen, Germany (affiliated with KTH Royal Institute of Technology and University of Edinburgh during project timespan) 2School of Informatics, University of Edinburgh, Edinburgh, United Kingdom.",1. Introduction,[0],[0]
"Correspondence to: Ciwan Ceylan <ceylan@vision.rwthaachen.de>, Michael Gutmann <michael.gutmann@ed.ac.uk>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
xi ∈ X are independently sampled from the unknown data distribution pd.,1. Introduction,[0],[0]
"Unnormalised models output non-negative numbers but do not integrate or sum to one, i.e. they are statistical models that are defined up to the partition function Z(θ) = ∫ φ(u;θ) du.",1. Introduction,[0],[0]
"Unnormalised models are widely used, e.g. to model images (Köster & Hyvärinen, 2010; Gutmann & Hyvärinen, 2013), natural language (Mnih & Teh, 2012; Zoph et al., 2016), or memory (Hopfield, 1982).
",1. Introduction,[0],[0]
"If the partition function Z(θ) can be evaluated analytically in closed form, the unnormalised model φ(u;θ) can be easily converted to a (normalised) statistical model p(u;θ) = φ(u;θ)/Z(θ) that can be estimated by maximising the likelihood.",1. Introduction,[0],[0]
"However, for most unnormalised models the integral defining the partition function is analytically intractable and computationally expensive to approximate.
",1. Introduction,[0],[0]
"Several methods have been proposed in the literature to estimate unnormalised models including Monte Carlo maximum likelihood (Geyer, 1994), contrastive divergence (Hinton, 2002), score matching (Hyvärinen, 2005), and noisecontrastive estimation (Gutmann & Hyvärinen, 2010; 2012) and its generalisations (Pihlaja et al., 2010; Gutmann & Hirayama, 2011).",1. Introduction,[0],[0]
The basic idea of noise-contrastive estimation (NCE) is to formulate the density estimation problem as a classification problem where the model is trained to distinguish between the observed data and some reference (noise) data.,1. Introduction,[0],[0]
"NCE is used in several application domains (Mnih & Teh, 2012; Chen et al., 2015; Tschiatschek et al., 2016) and similar “learning by comparison” ideas are employed for learning with generative latent variable models (Gutmann et al., 2014; Goodfellow et al., 2014).
",1. Introduction,[0],[0]
"In NCE, the choice of the auxiliary noise distribution is left to the user.",1. Introduction,[0],[0]
"While simple distributions, e.g. uniform or Gaussian distributions, have successfully been used (Gutmann & Hyvärinen, 2012; Mnih & Teh, 2012), the estimation performance of NCE depends on the distribution chosen and more tailored distributions were found to typically yield better results, see e.g. (Ji et al., 2016).",1. Introduction,[0],[0]
"Intuitively, the noise samples in NCE ought to resemble the observed data in order for the classification problem not to be too easy.",1. Introduction,[0],[0]
"To alleviate the burden on the user to generate such noise, we here propose conditional noise-contrastive estimation that semiautomatically generates the noise based on the observed data.
",1. Introduction,[0],[0]
The rest of the paper is structured as follows.,1. Introduction,[0],[0]
"In Section 2, we present the theory of conditional noise-contrastive estimation (CNCE), establish basic properties, and prove that a limiting case yields score matching.",1. Introduction,[0],[0]
"In Section 3, we validate the theory on synthetic data and compare the estimation performance of CNCE with NCE.",1. Introduction,[0],[0]
"In Section 4, we apply CNCE to real data and show that it can handle complex models by estimating a four-layer neural network model of natural images, and Section 5 concludes the paper.",1. Introduction,[0],[0]
Conditional noise-contrastive estimation (CNCE) turns an unsupervised estimation problem into a supervised learning problem by training the model to distinguish between data and noise samples.,2. Conditional noise-contrastive estimation,[0],[0]
"This is the same high-level approach as NCE takes, but in contrast to NCE, the novel idea of CNCE is to generate the noise samples with the aid of the observed data samples.",2. Conditional noise-contrastive estimation,[0],[0]
"Therefore, unlike NCE, CNCE does not assume the noise samples to be generated independently of the data samples, but rather to be drawn from a conditional noise distribution pc.",2. Conditional noise-contrastive estimation,[0],[0]
"The generated noise samples are paired with the data samples, with κ noise samples yij ∈ Y, j = 1, . . .",2. Conditional noise-contrastive estimation,[0],[0]
", κ per observed data point xi.",2. Conditional noise-contrastive estimation,[0],[0]
"Thus, a total of N · κ noise samples yij ∼ pc(yij |xi) are generated from pc.",2. Conditional noise-contrastive estimation,[0],[0]
We denote the collection of all noise samples by Y.,2. Conditional noise-contrastive estimation,[0],[0]
"In what follows, we assume that X = Y, but this assumption can be relaxed to X ⊆ Y (see Supplementary Materials A).",2. Conditional noise-contrastive estimation,[0],[0]
"In any case, we denote the union of X and Y by U.
We derive the loss function for CNCE in analogy to the derivation of the loss function for NCE.",2. Conditional noise-contrastive estimation,[0],[0]
"We divide all pairs of data and noise samples into two classes, Cα and Cβ, of equal size.",2. Conditional noise-contrastive estimation,[0],[0]
"Class Cα is formed by tuples (u1,u2) with u1 ∈ X and u2 ∈ Y, whileCβ is formed by tuples (u1,u2) with u1 ∈ Y and u2 ∈ X.",2. Conditional noise-contrastive estimation,[0],[0]
"Consequently, the probability distributions for the classes Cα and Cβ are given by
pα(u1,u2) = pd(u1)pc(u2|u1), (1) pβ(u1,u2) = pd(u2)pc(u1|u2), (2)
where pd denotes the distribution of the xi.",2. Conditional noise-contrastive estimation,[0],[0]
"The class conditional distributions can be obtained by Bayes’ rule,
pCα|u(u1,u2) = pα(u1,u2)
pα(u1,u2) + pβ(u1,u2) (3)
",2. Conditional noise-contrastive estimation,[0],[0]
"= 1
1 + pd(u2)pc(u1|u2)pd(u1)pc(u2|u1) , (4)
pCβ|u(u1,u2) = 1
1 + pd(u1)pc(u2|u1)pd(u2)pc(u1|u2) .",2. Conditional noise-contrastive estimation,[0],[0]
"(5)
The prior class probabilities cancel because there are equally many samples in each class.
",2. Conditional noise-contrastive estimation,[0],[0]
"By replacing pd(·) with the model φ( · ;θ)/Z(θ), the partition functions cancel and the following parametrised ver-
sions of the class conditional distributions are obtained
pCα|u(u1,u2;θ) = 1
1 + φ(u2;θ)pc(u1|u2)φ(u1;θ)pc(u2|u1) , (6)
pCβ|u(u1,u2;θ) = 1
1 + φ(u1;θ)pc(u2|u1)φ(u2;θ)pc(u1|u2) .",2. Conditional noise-contrastive estimation,[0],[0]
"(7)
The CNCE loss function is now formed as the negative log likelihood over the conditional class probabilities, in the same manner as in NCE (Gutmann & Hyvärinen, 2012),
JN (θ) = 2
κN κ∑ j=1 N∑ i=1 log",2. Conditional noise-contrastive estimation,[0],[0]
"[1 + exp(−G(xi,yij ;θ))] , (8)
G(u1,u2;θ) = log φ(u1;θ)pc(u2|u1) φ(u2;θ)pc(u1|u2) .",2. Conditional noise-contrastive estimation,[0],[0]
"(9)
The CNCE loss function JN is the sample version of J (θ) = 2Exy log (1 + exp(−G(x,y;θ))), which is obtained by taking both N and κ to the∞ limit.",2. Conditional noise-contrastive estimation,[0],[0]
"To further develop the theory, it is helpful to write J (θ) as a functional of G, which gives
J̃",2. Conditional noise-contrastive estimation,[0],[0]
"[G] = 2Exy log (1 + exp(−G(x,y))) .",2. Conditional noise-contrastive estimation,[0],[0]
"(10)
We then obtain the following theorem:
Theorem (Nonparametric estimation).",2. Conditional noise-contrastive estimation,[0],[0]
"LetG : U×U→ R be a function of the form
G(u1,u2) =",2. Conditional noise-contrastive estimation,[0],[0]
f(u1)− f(u2) +,2. Conditional noise-contrastive estimation,[0],[0]
"log pc(u2|u1) pc(u1|u2) , (11)
where f is a function from U to R. Under the assumption X = Y, J̃ attains a unique minimum at
G∗(u1,u2) = log pd(u1)pc(u2|u1) pd(u2)pc(u1|u2)
(12)
for (u1,u2) ∈ X×X with pd(u1) > 0",2. Conditional noise-contrastive estimation,[0],[0]
and pc(u1|u2),2. Conditional noise-contrastive estimation,[0],[0]
"> 0.
",2. Conditional noise-contrastive estimation,[0],[0]
The proof of a more general version is given in Supplementary Materials A.,2. Conditional noise-contrastive estimation,[0],[0]
"The theorem shows that in the limit of large N and κ, the optimal function f equals log pd up to an additive constant.",2. Conditional noise-contrastive estimation,[0],[0]
"For parametrisations that are flexible enough so thatG(u1,u2;θ∗) = G∗(u1,u2) for some value θ∗, the theorem together with the definition of G(u1,u2;θ) in (9) implies that φ(u;θ∗) ∝ pd(u).",2. Conditional noise-contrastive estimation,[0],[0]
"We have here the proportionality sign because the normalising constant is not estimated in CNCE.
",2. Conditional noise-contrastive estimation,[0],[0]
"While the theorem above concerns nonparametric estimation, and hence does not take into account how G is parametrised, it forms the basis for a consistency proof of CNCE.",2. Conditional noise-contrastive estimation,[0],[0]
"A standard approach is to identify conditions under which JN (θ) converges uniformly in probability to J (θ) and then to appeal to e.g. Theorem 5.7 of (van der Vaart,
1998).",2. Conditional noise-contrastive estimation,[0],[0]
A similar approach where the Kullback-Leibler divergence takes the role of J can be used to prove consistency of maximum likelihood estimation.,2. Conditional noise-contrastive estimation,[0],[0]
"The conditions for uniform convergence are typically fairly technical and we here forego this endeavour and instead provide empirical evidence for consistency in Section 3.
",2. Conditional noise-contrastive estimation,[0],[0]
"The generic CNCE algorithm generally takes two steps: obtain the noise samples by sampling from the conditional noise distribution pc, and then minimise the loss function JN over the parameters θ.",2. Conditional noise-contrastive estimation,[0],[0]
"The user decides the trade-off between precision and computational expenditures via κ and also needs to provide pc.
",2. Conditional noise-contrastive estimation,[0],[0]
There are two advantages to choosing pc over choosing the noise distribution in NCE.,2. Conditional noise-contrastive estimation,[0],[0]
"First, the observed data samples can be leveraged for sampling the noise, meaning that a resemblance to pd is easier to achieve than it would be for NCE.",2. Conditional noise-contrastive estimation,[0],[0]
"Indeed, all simulations in the paper were performed with the simple Gaussian specified below.",2. Conditional noise-contrastive estimation,[0],[0]
"Second, if pc is known to be symmetric, i.e. pc(u1|u2) = pc(u2|u1), it does not need to be evaluated because the densities cancel out in Equation (9).
",2. Conditional noise-contrastive estimation,[0],[0]
"A simple symmetric choice of pc when x and y ∈ RD is
pc(y|x; ε) = N (y;x, ε21), yij = xi + εξij .",2. Conditional noise-contrastive estimation,[0],[0]
"(13)
Here 1 is the identity matrix, ξij ∈",2. Conditional noise-contrastive estimation,[0],[0]
RD is a multivariate standard normal random variable and ε ∈,2. Conditional noise-contrastive estimation,[0],[0]
"[0,∞) a scalar parameter that corresponds to the standard deviation of each dimension, and which therefore controls the similarity between Y and X. It is here assumed that the data have been standardised (Murphy, 2012, Chaper 4) so that the empirical variances of the data are one for each dimension.",2. Conditional noise-contrastive estimation,[0],[0]
"Otherwise, different values of ε ought to be used for each dimension.
",2. Conditional noise-contrastive estimation,[0],[0]
"CNCE is also applicable to discrete random variables, e.g. by using a multinoulli distribution over y conditioned on x, and non-negative data (see Supplementary Materials C).
",2. Conditional noise-contrastive estimation,[0],[0]
"In our simulations, we adjust ε using simple heuristics so that the gradients of the loss function are not too small.",2. Conditional noise-contrastive estimation,[0],[0]
"This typically occurs when ε is too large so that the noise and data are easily distinguishable, but also when ε is too small.",2. Conditional noise-contrastive estimation,[0],[0]
It can be verified that the loss function attains the value 2 log(2) for ε = 0 independent of the model and θ.,2. Conditional noise-contrastive estimation,[0],[0]
"In brief, the heuristic algorithm starts with a small ε that is incremented until the value of the loss function is sufficiently far away from 2 log(2).
",2. Conditional noise-contrastive estimation,[0],[0]
"While small ε cause the gradients to be small in absolute terms, the following theorem shows that the loss function remains meaningful and that CNCE then corresponds to score matching (Hyvärinen, 2005).
",2. Conditional noise-contrastive estimation,[0],[0]
Theorem (Connection to score matching).,2. Conditional noise-contrastive estimation,[0],[0]
"Assume that φ(u;θ) is an unnormalised probability density and that
fθ(u) = log φ(u;θ) is twice differentiable.",2. Conditional noise-contrastive estimation,[0],[0]
"If y = x + εξ where ξ is a vector of uncorrelated random variables of mean zero and variance one that are independent from x and have a symmetric density, then
J (θ) =ε 2 2 Ex [∑
i
∂2fθ(x)
∂x2i +
1 2 ||∇xfθ(x)||22 ]",2. Conditional noise-contrastive estimation,[0],[0]
+ 2 log(2),2. Conditional noise-contrastive estimation,[0],[0]
+O(ε3).,2. Conditional noise-contrastive estimation,[0],[0]
"(14)
The term in the brackets is the loss function that is minimised in score matching (Hyvärinen, 2005).",2. Conditional noise-contrastive estimation,[0],[0]
"The theorem is proved in Supplementary Materials B. Note that pc in (13) fulfills the conditions in the theorem.
",2. Conditional noise-contrastive estimation,[0],[0]
The theorem can be understood as follows:,2. Conditional noise-contrastive estimation,[0],[0]
Score matching consists in finding parameter values so that the slope of the model pdf matches the slope of the data pdf.,2. Conditional noise-contrastive estimation,[0],[0]
"For symmetric conditional noise distributions pc, the nonlinearity G in Equation (9) equals G(u1,u2;θ) = log φ(u1;θ) − log φ(u2;θ) = fθ(u1) − fθ(u2).",2. Conditional noise-contrastive estimation,[0],[0]
"From (12), we know that at the optimum of J (θ), G(u1,u2;θ) matches log pd(u1) − log pd(u2).",2. Conditional noise-contrastive estimation,[0],[0]
The values which the arguments u1 and u2 take during the minimisation are determined by the conditional noise distribution.,2. Conditional noise-contrastive estimation,[0],[0]
"For small ε, the arguments are always close to each other, so that G(u1,u2;θ) is approximately proportional to a directional derivative of fθ(u) = log φ(u;θ) along a random direction.",2. Conditional noise-contrastive estimation,[0],[0]
"This means that for small ε, J (θ) is minimised when the slope of the model pdf matches the slope of the data pdf, as in score matching.",2. Conditional noise-contrastive estimation,[0],[0]
We here validate consistency and compare CNCE with NCE on synthetic data.,3. Empirical validation of the theory,[0],[0]
The models below were used in unnormalised form for CNCE and NCE.,3. Empirical validation of the theory,[0],[0]
"For the results with MLE, the models were first normalised.",3. Empirical validation of the theory,[0],[0]
Additional results for nonnegative and discrete data are provided in Supplementary Materials C.,3. Empirical validation of the theory,[0],[0]
"The Gaussian model is an unnormalised multivariate Gaussian model in five dimensions with zero mean and parametrised precision matrix Λ. As the precision matrix is symmetric, the Gaussian model has 15 parameters,
log φ(u;Λ) = −1",3.1. Models,[0],[0]
"2 uTΛu, u ∈ R5.",3.1. Models,[0],[0]
"(15)
",3.1. Models,[0],[0]
"The estimation error was measured as the Euclidean distance between the true and estimated parameters.
",3.1. Models,[0],[0]
"The ICA model is commonly used in signal possessing for blind source separation (Hyvärinen & Oja, 2000).",3.1. Models,[0],[0]
"Assuming equally many sources as data dimensions, D = 4, and a
Laplacian distribution for the sources, the unnormalised ICA model is
log φ(u;B) =",3.1. Models,[0],[0]
− √ 2 D∑ j=1 |bj ·,3.1. Models,[0],[0]
"u|, u ∈ R4.",3.1. Models,[0],[0]
"(16)
",3.1. Models,[0],[0]
The model is parametrised by the demixing matrix B and has D2 = 16 free parameters.,3.1. Models,[0],[0]
"The (normalised) ICA model can be estimated using MLE (Hyvärinen & Oja, 2000, 4.4.1).",3.1. Models,[0],[0]
"The estimation error was calculated as the Euclidean distance between true and estimated parameter vector after accounting for the sign and order ambiguity of the ICA model (Hyvärinen & Oja, 2000, 2.2) in the same manner as in (Gutmann & Hyvärinen, 2012).
",3.1. Models,[0],[0]
"Both the Gaussian and the ICA model were previously used to validate the consistency of NCE, and a Gaussian noise distribution achieved good estimation performance (Gutmann & Hyvärinen, 2012).",3.1. Models,[0],[0]
"In order to investigate the potential benefit of the adaptive noise of CNCE, we used the following more challenging “ring model” where the data lie in lower dimensional manifold.
",3.1. Models,[0],[0]
"The Ring model is given by
log φ(u;µr, γr) =",3.1. Models,[0],[0]
"− γr 2 (‖u‖2 − µr)2, u ∈ R5.",3.1. Models,[0],[0]
"(17)
",3.1. Models,[0],[0]
The model is best understood in polar coordinates: the angular components are uniformly distributed and the radial direction is Gaussian with mean µr and precision,3.1. Models,[0],[0]
γr.,3.1. Models,[0],[0]
"The mean is assumed known, and the task is to estimate the precision parameter γr.",3.1. Models,[0],[0]
"Figure 1 shows the (normalised) pdf for the ring model in two dimensions, as well as the NCE noise and the CNCE noise generated according to Equation (13).",3.1. Models,[0],[0]
"As often done in NCE, a Gaussian noise is chosen to match the mean and covariance of the data distribution.",3.1. Models,[0],[0]
"Because of the manifold structure of the data, the NCE noise is concentrated in areas where the data distribution takes small values, which is in contrast to the CNCE noise that well covers the data manifold.",3.1. Models,[0],[0]
Figures 2a and 2b show the estimation error as a function of the number of data points N .,3.2. Results,[0],[0]
"For both the Gaussian and ICA models, the CNCE error decreases linearly in the loglog domain as the sample size increases, which indicates convergence in quadratic mean, and hence consistency.",3.2. Results,[0],[0]
"Furthermore, as the number of noise-per-data points κ grows, the error appears to approach the MLE error.
",3.2. Results,[0],[0]
The MLE of the ICA model had a tendency to get stuck in local minima for a small part of the estimations (13 out of 100).,3.2. Results,[0],[0]
"Consequently, the 0.9 quantile for MLE in Figure 2b shows a high and relatively constant error corresponding to such local minima.",3.2. Results,[0],[0]
"While this also occurred for CNCE, it is not visible in Figure 2b as it occurred less often (7/100 simulations).
",3.2. Results,[0],[0]
"As shown in Figure 2c, NCE performs better than CNCE for the Gaussian model given the same number of noise and data samples.",3.2. Results,[0],[0]
"For the ICA model, they are roughly onpar for sufficiently many data samples, see Figure 2d.",3.2. Results,[0],[0]
An advantage for NCE on these models may not be surprising given that the NCE noise distribution already covers the data distribution very well.,3.2. Results,[0],[0]
"Furthermore, Figures 2e and 2f show that the difference between NCE and CNCE decreases as ratio of noise to data samples increases.
",3.2. Results,[0],[0]
Figure 3 shows the results for the ring model using κ = 10.,3.2. Results,[0],[0]
CNCE achieves about one order of magnitude lower estimation error compared to NCE.,3.2. Results,[0],[0]
"With reference to Figure 1, this vast improvement over NCE can be understood as follows: For the noise distribution used in NCE, the majority of the noise samples end up inside the ring where the data sample probability is low, so that they are not useful for learning (the classification problem is too easy, with the noise not providing enough contrast).",3.2. Results,[0],[0]
"CNCE, on the other hand, automatically generates suitably contrastive noise on (or close to) the data manifold, which facilitates learning.",3.2. Results,[0],[0]
"To show that CNCE can be used to estimate complex unnormalised models, we used it for unsupervised deep learning and estimated a four-layer feed-forward neural network model from natural images.",4. Neural image model,[0],[0]
"The model extends the two- and three-layer models of natural images previously estimated with NCE (Gutmann & Hyvärinen, 2012; 2013).",4. Neural image model,[0],[0]
We here focus on the learned features.,4. Neural image model,[0],[0]
"In Supplementary Materials D, we present a qualitative comparison with NCE.
",4. Neural image model,[0],[0]
"The data X are image patches of size 32× 32 px, sampled from 11 different monochrome images depicting wild life scenes (van Hateren & van der Schaaf, 1998) in the same manner as (Gutmann & Hyvärinen, 2013).",4. Neural image model,[0],[0]
Figure 4a shows examples of the extracted image patches.,4. Neural image model,[0],[0]
The sampled image patches were vectorised and both the ensemble mean and local mean (DC component) were subtracted.,4. Neural image model,[0],[0]
"The resulting data were then whitened and their dimensionality reduced to D = 600 by principal component analysis (Murphy, 2012, Chapter 12.2), retaining 98% of the variance.",4. Neural image model,[0],[0]
We denote the data (random vector) after preprocessing by u(1).,4. Neural image model,[0],[0]
The unnormalised image model φ defined below consist of a “structured” part φ̃ that models the non-Gaussianity of the natural image data and a Gaussian part that accounts for the covariance structure.,4.1. Model specification,[0],[0]
"In the PCA space, the model is
log φ(u(1);θ) = log φ̃(u(1);θ)− 1 2 u(1) · u(1), (18)
where · denotes the inner product between two vectors.",4.1. Model specification,[0],[0]
"This corresponds to a model for images defined in the subspace spanned by the first D principle component directions.
",4.1. Model specification,[0],[0]
The Gaussian term in (18) tends to mask the non-Gaussian structure that we are primarily interested in.,4.1. Model specification,[0],[0]
"In order to better learn about the non-Gaussian properties of natural images, we define the conditional noise distribution as
log pc(u2|u1) = log p̃c(u2|u1)− 1
2 u2 · u2 + const, (19)
where p̃c is the Gaussian noise distribution in (13).",4.1. Model specification,[0],[0]
"With this choice, the two Gaussian terms of the model and noise cancel in the nonlinearity G(u1,u2;θ), so that
G(u1,u2;θ) = log φ̃(u1;θ)p̃c(u2|u1) φ̃(u2;θ)p̃c(u1|u2) .",4.1. Model specification,[0],[0]
"(20)
Due to the cancelling, φ̃ in Equation (18) is considered the effective model and p̃c the effective conditional noise distribution.",4.1. Model specification,[0],[0]
"Examples of noise patches sampled from p̃c are shown in Figure 4b.
",4.1. Model specification,[0],[0]
"We next define the (effective) model φ̃ via a four layers deep, fully connected, feed-forward neural network.",4.1. Model specification,[0],[0]
"The general idea is that we iterate between feature extraction and pooling layers (Gutmann & Hyvärinen, 2013).",4.1. Model specification,[0],[0]
"Unlike in many image models, we here do not impose translation invariance by using convolutional networks; neither do we fix the pooling layers but learn them from data.",4.1. Model specification,[0],[0]
"The input and output dimensions of each layer are provided in Supplementary Materials D.
The preprocessed image patches u(1) are first passed through a gain-control stage where they are centred and rescaled to cancel out some effects of the lighting conditions (Gutmann & Hyvärinen, 2012),
ũ(u) =",4.1. Model specification,[0],[0]
"√ D − 1 u− 〈u〉
‖u− 〈u〉‖2 , 〈u〉 = 1 D D∑ k=1 uk.",4.1. Model specification,[0],[0]
"(21)
Then they are passed through a feature extraction and a pooling layer,
z",4.1. Model specification,[0],[0]
"(1) j = w (1) j · ũ(u (1)), (22)
z",4.1. Model specification,[0],[0]
(2) j = log ( q (2) j · ( z(1) )2 + 1 ) .,4.1. Model specification,[0],[0]
"(23)
Both the features w(1)j and pooling weights q (2) j are free parameters; we thus learn which 1st layer outputs to pool together.",4.1. Model specification,[0],[0]
"The pooling weights are restricted to be nonnegative, which we enforce by writing them as q(2)j = (w (2) j )
2, with element-wise squaring.",4.1. Model specification,[0],[0]
"The log nonlinearity counteracts the squaring, leading to an approximation of the max operation (Gutmann & Hyvärinen, 2013).
",4.1. Model specification,[0],[0]
"We then repeat this processing block of gain control, feature extraction, and pooling: The outputs z(2)j of the 2
nd layer are passed through the same gain control stage as the image patches, i.e. whitening, dimensionality reduction and rescaling, in line with previous work (Gutmann & Hyvärinen, 2013), followed by feature extraction and pooling,
z (3) j = w (3) j · ũ (3), z (4) j = q",4.1. Model specification,[0],[0]
(4) j · z (3).,4.1. Model specification,[0],[0]
"(24)
The pooling weights q(4)j are restricted to be non-negative, which is enforced as for the second layer.",4.1. Model specification,[0],[0]
We here work with a simpler pooling model than in Equation (23).,4.1. Model specification,[0],[0]
"An output z (4) j of the pooling layer is large if q (4) j pools over units that are concurrently active, which is related to detecting sign congruency (Gutmann & Hyvärinen, 2009).
",4.1. Model specification,[0],[0]
"The unnormalised model φ̃ is then given by the total activation of the units in each layer, which means that the overall population activity indicates how likely an input is.",4.1. Model specification,[0],[0]
"Following (Gutmann & Hyvärinen, 2012; 2013) we used
log φ̃(L)(u(1);θ) = K(L)∑",4.1. Model specification,[0],[0]
"j=1 fth ( z (L) j + b (L) j ) (25)
for L = 2, 3, 4 where fth is a smooth rectifying linear unit1 and b(L)j threshold parameters that are also learned from the data.",4.1. Model specification,[0],[0]
"The thresholding causes only strongly active units to contribute to log φ̃(L)(u(1);θ), which is related to sparse coding (Gutmann & Hyvärinen, 2012).",4.1. Model specification,[0],[0]
"In the case L = 1, the outputs z(1)j were passed through the additional nonlinearity log((·)2 + 1) prior to thresholding.",4.1. Model specification,[0],[0]
"This corresponds to computing the 2nd layer outputs with the 2nd layer weights fixed to correspond together to the identity matrix.
",4.1. Model specification,[0],[0]
"We learned the weights hierarchically one layer at a time, e.g. after learning of the 1st layer weights, we kept them fixed and learned the second layer weight vector w(2)j etc.",4.1. Model specification,[0],[0]
"The learned features, i.e receptive fields (RFs) of the 1st layer neurons, can be visualised as images.",4.2. Estimation results,[0],[0]
The learned 2nd layer weight vectors are sparse and the non-zero weights indicate over which 1st layer units the pooling happens.,4.2. Estimation results,[0],[0]
"In Figure 5, we visualise randomly selected 2nd layer units,
1fth(u) = 0.25 log(cosh(2u))",4.2. Estimation results,[0],[0]
"+ 0.5u+ 0.17
and the 1st layer units that they pool together.",4.2. Estimation results,[0],[0]
"The 1st layer has learned Gabor features (Hyvärinen et al., 2009, Chapter 3) and the 2nd layer tends to pool these features according to frequency, orientation and locality, in line with previous models of natural images (Hyvärinen et al., 2009).
",4.2. Estimation results,[0],[0]
"To visualise the learned weights on the 3rd layer, we followed (Gutmann & Hyvärinen, 2013) and visualised them as space-orientation receptive fields.",4.2. Estimation results,[0],[0]
"That is, we probed the learned neural network with Gabor stimuli at different locations, orientations, and frequency, and visualised the response of the 3rd layer units as a polar plot.",4.2. Estimation results,[0],[0]
"The polar plot is centred on the probing location, and the maximal radius is an indicator of the envelope and hence spatial frequency of the Gabor stimulus (larger circles correspond to lower spatial frequencies).",4.2. Estimation results,[0],[0]
"We visualised the pooling on the 4th layer as for the 2nd layer by indicating the pooling strength with bars underneath the space-orientation receptive fields.
",4.2. Estimation results,[0],[0]
Figure 6 shows examples of the learned 3rd and 4th layer units as well natural image inputs that elicit strong responses for the 4th layer units shown.,4.2. Estimation results,[0],[0]
"The learned 3rd layer units detect longer straight or bended contours, which is largely in line with previous findings (Gutmann & Hyvärinen, 2013).",4.2. Estimation results,[0],[0]
The learned 4th layer unit on the top in the figure (unit 4) has learned to pool together 3rd layer units that share the same spatial orientation preference but are tuned to different spatial frequencies.,4.2. Estimation results,[0],[0]
"This is line with previous modelling results (Hyvärinen et al., 2005) where similar pooling emerged in a model with more restrictive assumptions.",4.2. Estimation results,[0],[0]
"The learned 4th layer unit shown on the bottom (unit 19) is tuned to vertical and horizontal low-frequency structure that bend around the southwest corner, which corresponds to a low-frequency corner detector.",4.2. Estimation results,[0],[0]
"The full set of learned units is shown in the same way in Supplementary Materials D. Overall, the results show that CNCE both yields results that are in line with previous work and further finds novel and intuitively reasonable pooling patterns on the newly considered fourth layer.",4.2. Estimation results,[0],[0]
"In this paper, we addressed the problem of density estimation for unnormalised models where the normalising partition function cannot be computed.",5. Conclusions,[0],[0]
We proposed a new method that follows the principles of noise-contrastive estimation and “learning by comparison”.,5. Conclusions,[0],[0]
"In contrast to noisecontrastive estimation (NCE), in the proposed conditional noise-contrastive estimation (CNCE), the contrastive noise is allowed to depend on the data.
",5. Conclusions,[0],[0]
"The main advantage of allowing the noise distribution to depend on the data is that the information in the data can be leveraged to produce, with rather simple conditional noise distributions as for example a Gaussian, noise samples that are well adapted to a wide range of different data and model
2 4 6 8 10 12 14 16 18 20 22
types.",5. Conclusions,[0],[0]
"A second advantage is that for symmetric conditional noise distributions, a closed form expression for the conditional noise is not needed, which both enables a wider choice of distributions and has computational benefits.",5. Conclusions,[0],[0]
"If the value of the normalisation constant is not of interest, a third advantage of the proposed approach is that the intractable partition function cancels out.",5. Conclusions,[0],[0]
"Unlike in noise-contrastive estimation, there is thus never a need to introduce an additional parameter for the scaling of the model.
",5. Conclusions,[0],[0]
We provided theoretical and empirical arguments that CNCE provides a consistent estimator and proved that score matching emerges as a limiting case.,5. Conclusions,[0],[0]
"As score matching makes more stringent assumptions but does not rely on sampling, it is an open question whether we can use this result to e.g. devise a hybrid approach where parts of the model are automatically estimated with the more suitable method.
",5. Conclusions,[0],[0]
"We further found that the relative performances of NCE and CNCE are model dependent, but that CNCE has an
advantage in the important case where the data lie in a lower dimensional manifold.
",5. Conclusions,[0],[0]
"An inherent limitation of empirical comparisons, and hence also those performed here, is that the results depend on the models and noise distributions used.",5. Conclusions,[0],[0]
"However, given the adaptive nature of CNCE, simple Gaussian conditional noise distributions are likely widely useful, as exemplified by our results on unsupervised deep learning of a neural image model.
",5. Conclusions,[0],[0]
"The proposed method further allows one to iteratively adapt the conditional noise distribution to make the classification task successively more challenging, as it was done in some simulations for NCE (Gutmann & Hyvärinen, 2010), and generally for learning in generative latent variable models (Gutmann et al., 2014; Goodfellow et al., 2014).",5. Conclusions,[0],[0]
This is an interesting direction of future work on CNCE.,5. Conclusions,[0],[0]
"MUG would like to thank Jun-ichiro Hirayama at ATR and RIKEN AIP, Japan, for helpful discussions.",Acknowledgements,[0],[0]
We thank the anonymous reviewers for their insightful comments.,Acknowledgements,[0],[0]
"Many parametric statistical models are not properly normalised and only specified up to an intractable partition function, which renders parameter estimation difficult.",abstractText,[0],[0]
"Examples of unnormalised models are Gibbs distributions, Markov random fields, and neural network models in unsupervised deep learning.",abstractText,[0],[0]
"In previous work, the estimation principle called noise-contrastive estimation (NCE) was introduced where unnormalised models are estimated by learning to distinguish between data and auxiliary noise.",abstractText,[0],[0]
An open question is how to best choose the auxiliary noise distribution.,abstractText,[0],[0]
We here propose a new method that addresses this issue.,abstractText,[0],[0]
"The proposed method shares with NCE the idea of formulating density estimation as a supervised learning problem but in contrast to NCE, the proposed method leverages the observed data when generating noise samples.",abstractText,[0],[0]
The noise can thus be generated in a semiautomated manner.,abstractText,[0],[0]
"We first present the underlying theory of the new method, show that score matching emerges as a limiting case, validate the method on continuous and discrete valued synthetic data, and show that we can expect an improved performance compared to NCE when the data lie in a lower-dimensional manifold.",abstractText,[0],[0]
Then we demonstrate its applicability in unsupervised deep learning by estimating a four-layer neural image model.,abstractText,[0],[0]
Conditional Noise-Contrastive Estimation of Unnormalised Models,title,[0],[0]
"Ensemble methods have played a critical role in the machine learning community to obtain better predictive performance than what could be obtained from any of the constituent learning models alone, e.g., Bayesian model/parameter averaging (Domingos, 2000), boosting (Freund et al., 1999) and bagging (Breiman, 1996).",1. Introduction,[0],[0]
"Recently, they have been successfully applied to enhancing the power of many deep neural networks, e.g., 80% of
1School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Repulic of Korea.",1. Introduction,[0],[0]
"Correspondence to: Jinwoo Shin <jinwoos@kaist.ac.kr>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
top-5 best-performing teams on ILSVRC challenge 2016 (Krizhevsky et al., 2012) employ ensemble methods.",1. Introduction,[0],[0]
They are easy and trustworthy to apply for most scenarios.,1. Introduction,[0],[0]
"While there exists a long history on ensemble methods, the progress on developing more advanced ensembles specialized for deep neural networks has been slow.",1. Introduction,[0],[0]
"Despite continued efforts that apply various ensemble methods such as bagging and boosting to deep models, it has been observed that traditional independent ensembles (IE) which train models independently with random initialization achieve the best performance (Ciregan et al., 2012; Lee et al., 2015).",1. Introduction,[0],[0]
"In this paper, we focus on developing more advanced ensembles for deep models utilizing the concept of multiple choice learning (MCL).
",1. Introduction,[0],[0]
"The MCL concept was originally proposed in (GuzmanRivera et al., 2012) under the scenario when inference procedures are cascaded:
(a) First, generate a set of plausible outputs.
",1. Introduction,[0],[0]
"(b) Then, pick the correct solution form the set.
",1. Introduction,[0],[0]
"For example, (Park & Ramanan, 2011; Batra et al., 2012) proposed human-pose estimation methods which produce multiple predictions and then refine them by employing a temporal model, and (Collins & Koo, 2005) proposed a sentence parsing method which re-ranks the output of an initial system which produces a set of plausible outputs (Huang & Chiang, 2005).",1. Introduction,[0],[0]
"In such scenarios, the goal of the first stage (a) is generating a set of plausible outputs such that at least one of them is correct for the second stage (b), e.g., human operators.",1. Introduction,[0],[0]
"Under this motivation, MCL has been studied (Guzman-Rivera et al., 2014; 2012; Lee et al., 2016), where various applications have been demonstrated, e.g., image classification (Krizhevsky & Hinton, 2009), semantic segmentation (Everingham et al., 2010) and image captioning (Lin et al., 2014b).",1. Introduction,[0],[0]
"It trains an ensemble of multiple models by minimizing the so-called oracle loss, only focusing on the most accurate prediction produced by them.",1. Introduction,[0],[0]
"Consequently, it makes each model specialized for a certain subset of data, not for the entire one similarly as mixture-of-expert schemes (Jacobs et al., 1991).
",1. Introduction,[0],[0]
"Although MCL focuses on the first stage (a) in cascaded scenarios and thus can produce diverse/plausible outputs, it might be not useful if one does not have a good scheme for
the second stage (b).",1. Introduction,[0],[0]
"One can use a certain average/voting scheme of the predictions made by models for (b), but MCL using deep neural networks often fails to make a correct decision since each network tends to be overconfident in its prediction.",1. Introduction,[0],[0]
"Namely, the oracle error/loss of MCL is low, but its top-1 error rate might be very high.
",1. Introduction,[0],[0]
Contribution.,1. Introduction,[0],[0]
"To address the issue, we develop the concept of confident MCL (CMCL) that does not lose any benefit of the original MCL, while its target loss and architecture are redesigned for making the second stage (b) easier.",1. Introduction,[0],[0]
"Specifically, it targets to generate a set of diverse/plausible confident predictions from which one can pick the correct one using a simple average/voting scheme.",1. Introduction,[0],[0]
"To this end, we first propose a new loss function, called confident oracle loss, for relaxing the overconfidence issue of MCL.",1. Introduction,[0],[0]
Our key idea is to additionally minimize the Kullback-Leibler divergence from a predictive distribution to the uniform one in order to give confidence to non-specialized models.,1. Introduction,[0],[0]
"Then, CMCL that minimizes the new loss can be efficiently trained like the original MCL for certain classes of models including neural networks, via stochastic alternating minimization (Lee et al., 2016).",1. Introduction,[0],[0]
"Furthermore, when CMCL is applied to deep models, we propose two additional regularization techniques for boosting its performance: feature sharing and stochastic labeling.",1. Introduction,[0],[0]
"Despite the new components, we note that the training complexity of CMCL is almost same to that of MCL or IE.
We apply the new ensemble model trained by the new training scheme for several convolutional neural networks (CNNs) including VGGNet (Simonyan & Zisserman, 2015), GoogLeNet (Szegedy et al., 2015), and ResNet (He et al., 2016) for image classification on the CIFAR (Krizhevsky & Hinton, 2009) and SVHN (Netzer et al., 2011) datasets, and fully-convolutional neural networks (FCNs) (Long et al., 2015) for foreground-background segmentation on the iCoseg dataset (Batra et al., 2010).",1. Introduction,[0],[0]
"First, for the image classification task, CMCL outperforms all baselines, i.e., the traditional IE and the original MCL, in top-1 error rates.",1. Introduction,[0],[0]
"In particular, CMCL of 5 ResNet with 20 layers provides 14.05% and 6.60% relative reductions in the top-1 error rates from the corresponding IE on CIFAR-10 and SVHN, respectively.",1. Introduction,[0],[0]
"Second, for the foreground-background segmentation task, CMCL using multiple FCNs with 4 layers also outperforms all baselines in top-1 error rates.",1. Introduction,[0],[0]
Each model trained by CMCL generates high-quality solutions by specializing for specific images while each model trained by IE does not.,1. Introduction,[0],[0]
"We believe that our new approach should be of broader interest for many deep learning tasks requiring high accuracy.
Organization.",1. Introduction,[0],[0]
"In Section 2, we introduce necessary backgrounds for multiple choice learning and the corresponding loss function.",1. Introduction,[0],[0]
"We describe the proposed loss and the corre-
sponding training scheme in Section 3.",1. Introduction,[0],[0]
Section 4 provides additional techniques for the proposed ensemble model.,1. Introduction,[0],[0]
Experimental results are reported in Section 5.,1. Introduction,[0],[0]
"In this section, we describe the basic concept of multiple choice learning (MCL) (Guzman-Rivera et al., 2014; 2012).",2.1. Multiple Choice Learning,[0],[0]
"Throughout this paper, we denote the set {1, . . .",2.1. Multiple Choice Learning,[0],[0]
", n} by [n] for positive integer n.",2.1. Multiple Choice Learning,[0],[0]
The MCL scheme is a type of ensemble learning that produces diverse outputs of high quality.,2.1. Multiple Choice Learning,[0],[0]
"Formally, given a training dataset D = {(xi, yi) | i ∈",2.1. Multiple Choice Learning,[0],[0]
"[N ], xi ∈ X , yi ∈ Y}, we consider an ensemble ofM models f , i.e., (f1, . . .",2.1. Multiple Choice Learning,[0],[0]
", fM ).",2.1. Multiple Choice Learning,[0],[0]
"For some task-specific loss function ` (y, f (x)), the oracle loss over the dataset D is defined as follows:
LO (D) = N∑ i=1",2.1. Multiple Choice Learning,[0],[0]
"min m∈[M ] ` (yi, fm (xi)) , (1)
while the traditional independent ensemble (IE) loss is
LE (D) =",2.1. Multiple Choice Learning,[0],[0]
N∑ i=1,2.1. Multiple Choice Learning,[0],[0]
"∑ m∈[M ] ` (yi, fm (xi)) .",2.1. Multiple Choice Learning,[0],[0]
"(2)
If all models have the same capacity and one can obtain the (global) optimum of the IE loss with respect to the model parameters, then all trained models should produce the same outputs, i.e., f1 = . . .",2.1. Multiple Choice Learning,[0],[0]
= fM .,2.1. Multiple Choice Learning,[0],[0]
"On the other hand, the oracle loss makes the most accurate model optimize the loss function ` (y, f (x)) for each data x. Therefore, MCL produces diverse outputs of high quality by forcing each model to be specialized on a part of the entire dataset.
",2.1. Multiple Choice Learning,[0],[0]
Minimizing the oracle loss (1) is harder than minimizing the independent ensemble loss (2) since the min function is a non-continuous function.,2.1. Multiple Choice Learning,[0],[0]
"To address the issue, (GuzmanRivera et al., 2012) proposed an iterative block coordinate decent algorithm and (Dey et al., 2015) reformulated this problem as a submodular optimization task in which ensemble models are trained sequentially in a boosting-like manner.",2.1. Multiple Choice Learning,[0],[0]
"However, when one considers an ensemble of deep neural networks, it is challenging to apply these methods since they require either costly retraining or sequential training.",2.1. Multiple Choice Learning,[0],[0]
"Recently, (Lee et al., 2016) overcame this issue by proposing a stochastic gradient descent (SGD) based algorithm.",2.1. Multiple Choice Learning,[0],[0]
"Throughout this paper, we primarily focus on ensembles of deep neural networks and use the SGD algorithm for optimizing the oracle loss (1) or its variants.",2.1. Multiple Choice Learning,[0],[0]
"The oracle loss (1) used for MCL is useful for producing diverse/plausible outputs, but it is often inappropriate for ap-
plications requiring a single choice, i.e., top-1 error.",2.2. Oracle Loss for Top-1 Choice,[0],[0]
"This is because ensembles of deep neural networks tend to be overconfident in their predictions, and it is hard to judge a better solution from their outputs.",2.2. Oracle Loss for Top-1 Choice,[0],[0]
"To explain this in more detail, we evaluate the performance of ensembles of convolutional neural networks (CNNs) for the image classification task on the CIFAR-10 dataset (Krizhevsky & Hinton, 2009).",2.2. Oracle Loss for Top-1 Choice,[0],[0]
We train ensembles of 5 CNNs (two convolutional layers followed by a fully-connected layer) using MCL.,2.2. Oracle Loss for Top-1 Choice,[0],[0]
We also train the models using traditional IE which trains each model independently under different random initializations.,2.2. Oracle Loss for Top-1 Choice,[0],[0]
Figure 1 summarizes the class-wise test set accuracy of each ensemble member.,2.2. Oracle Loss for Top-1 Choice,[0],[0]
"In the case of MCL, most models become specialists for certain classes (see Figure 1(a)), while they are generalized in the case of traditional IE as shown in Figure 1(c).",2.2. Oracle Loss for Top-1 Choice,[0],[0]
"However, as expected, each model trained by MCL significantly outperforms for its specialized classes than that trained by IE.",2.2. Oracle Loss for Top-1 Choice,[0],[0]
"For choosing a single output, similar to (Wan et al., 2013; Ciregan et al., 2012), one can average the output probabilities from ensemble members trained by MCL, but the corresponding top-1 classification error rate is often very high (e.g., see Table 1 in Section 5).",2.2. Oracle Loss for Top-1 Choice,[0],[0]
This is because each model trained by MCL is overconfident for its non-specialized classes.,2.2. Oracle Loss for Top-1 Choice,[0],[0]
"To quantify this, we also compute the entropy of the predictive distribution on the test data and use this to evaluate the quality of confidence/uncertainty level.",2.2. Oracle Loss for Top-1 Choice,[0],[0]
Figure 2(a) reports the entropy extracted from the predictive distribution of one of ensemble models trained by MCL.,2.2. Oracle Loss for Top-1 Choice,[0],[0]
"One can observe that it has low entropy as expected for its specialized classes (i.e., classes that the model has a test accuracy higher than 90%).",2.2. Oracle Loss for Top-1 Choice,[0],[0]
"However, even for non-specialized classes, it also has low entropy.",2.2. Oracle Loss for Top-1 Choice,[0],[0]
"Due to this, with respect to top-1 error rates, simple averaging of models trained by MCL performs much worse than that of IE.",2.2. Oracle Loss for Top-1 Choice,[0],[0]
"Such issue typically occurs in deep neural networks since it is well known that they are poor at quantifying predictive uncertainties, and tend to be easily overconfident (Nguyen et al., 2015).",2.2. Oracle Loss for Top-1 Choice,[0],[0]
"In this section, we propose a modified oracle loss for relaxing the issue of MCL described in the previous section.",3.1. Confident Oracle Loss,[0],[0]
"Suppose that the m-th model outputs the predictive distribution Pθm (y | x) given input x, where θm denotes the model parameters.",3.1. Confident Oracle Loss,[0],[0]
"Then, we define the confident oracle loss as the following integer programming variant of (1):
LC(D) = min vmi N∑ i=1 M∑ m=1",3.1. Confident Oracle Loss,[0],[0]
"( vmi ` (yi, Pθm (y | xi))
",3.1. Confident Oracle Loss,[0],[0]
+ β,3.1. Confident Oracle Loss,[0],[0]
(1− vmi )DKL (U (y) ‖,3.1. Confident Oracle Loss,[0],[0]
Pθm (y | xi)) ),3.1. Confident Oracle Loss,[0],[0]
"(3a)
subject to M∑ m=1 vmi = 1, ∀i, (3b)
vmi ∈ {0, 1}, ∀i,m (3c)
whereDKL denotes the Kullback-Leibler (KL) divergence, U (y) is the uniform distribution, β is a penalty parameter, and vmi is a flag variable to decide the assignment of xi to the m-th model.",3.1. Confident Oracle Loss,[0],[0]
"By minimizing the KL divergence from the predictive distribution to the uniform one, the new loss forces the predictive distribution to be closer to the uniform one, i.e., zero confidence, on non-specialized data, while those for specialized data still follow the correct one.",3.1. Confident Oracle Loss,[0],[0]
"For example, for classification tasks, the most accurate model for each data is allowed to optimize the classification loss, while others are forced to give less confident predictions by minimizing the KL divergence.",3.1. Confident Oracle Loss,[0],[0]
"We remark that although we optimize the KL divergence only for non-specialized data, one can also do it even for specialized data to regularize each model (Pereyra et al., 2017).",3.1. Confident Oracle Loss,[0],[0]
"In order to minimize the confident oracle loss (3) efficiently, we use the following procedure (Guzman-Rivera et al., 2012), which optimizes model parameters {θm} and assignment variables {vmi } alternatively:
1.",3.2. Stochastic Alternating Minimization for Training,[0],[0]
"Fix {θm} and optimize {vmi }.
",3.2. Stochastic Alternating Minimization for Training,[0],[0]
"Under fixed model parameters {θm}, the objective (3a) is decomposable with respect to assignments {vmi } and it is easy to find optimal {vmi }.
2.",3.2. Stochastic Alternating Minimization for Training,[0],[0]
"Fix {vmi } and optimize {θm}.
",3.2. Stochastic Alternating Minimization for Training,[0],[0]
"Under fixed assignments {vmi }, the objective (3a) is decomposable with respect to model parameters {θm}, and it requires each model to be trained independently.
",3.2. Stochastic Alternating Minimization for Training,[0],[0]
The above scheme iteratively assigns each data to a particular model and then independently trains each model only using its assigned data.,3.2. Stochastic Alternating Minimization for Training,[0],[0]
"Even though it monotonically decreases the objective, it is still highly inefficient since it requires training each model multiple times until assignments {vmi } converge.",3.2. Stochastic Alternating Minimization for Training,[0],[0]
"To address the issue, we propose deciding assignments and update model parameters to the gradient directions once per each batch, similarly to (Lee et al., 2016).",3.2. Stochastic Alternating Minimization for Training,[0],[0]
"In other words, we perform a single gradientupdate on parameters in Step 2, without waiting for their convergence to a (local) optimum.",3.2. Stochastic Alternating Minimization for Training,[0],[0]
"In fact, (Lee et al., 2016) show that such stochastic alternating minimization works well for the oracle loss (1).",3.2. Stochastic Alternating Minimization for Training,[0],[0]
"We formally describe a detailed training procedure as the ‘version 0’ of Algorithm 1, and we will introduce the alternative ‘version 1’ later.",3.2. Stochastic Alternating Minimization for Training,[0],[0]
"This direction is complementary to ours, and we do not explore in this paper.
",3.2. Stochastic Alternating Minimization for Training,[0],[0]
"Algorithm 1 Confident MCL (CMCL) Input: Dataset D = {(xi, yi) | xi ∈ X , yi ∈ Y} and penalty parameter β Output: Ensemble of M trained models repeat
Let U (y) be a uniform distribution Sample random batch B ⊂ D for m = 1 to M do
Compute the loss of the m-th model:
Lmi ←β ∑ m̂ 6=m DKL (U (y) ‖",3.2. Stochastic Alternating Minimization for Training,[0],[0]
"Pθm̂ (y | xi))
+ ` (yi, Pθm (yi | xi)) , ∀(xi, yi) ∈ B
end for for m = 1 to M do
for i = 1 to |B| do if the m-th model has the lowest loss then
Compute the gradient of the training loss ` (yi, Pθm (yi | xi))",3.2. Stochastic Alternating Minimization for Training,[0],[0]
w.r.t θm else /∗,3.2. Stochastic Alternating Minimization for Training,[0],[0]
version 0: exact gradient ∗/ Compute the gradient of the KL divergence βDKL,3.2. Stochastic Alternating Minimization for Training,[0],[0]
(U (y) ‖,3.2. Stochastic Alternating Minimization for Training,[0],[0]
Pθm (y | xi)),3.2. Stochastic Alternating Minimization for Training,[0],[0]
w.r.t θm /∗ version 1: stochastic labeling ∗/ Compute the gradient of the cross entropy loss −β logPθm (ŷi | xi) using ŷi,3.2. Stochastic Alternating Minimization for Training,[0],[0]
"w.r.t θm where ŷi ∼ U (y)
end if end for Update the model parameters
end for until convergence",3.2. Stochastic Alternating Minimization for Training,[0],[0]
"Similar to Section 2.2, we evaluate the performance of the proposed training scheme using 5 CNNs for image classification on the CIFAR-10 dataset.",3.3. Effect of Confident Oracle Loss,[0],[0]
"As shown in Figure 1(b), ensemble models trained by CMCL using the exact gradient (i.e., version 0 of Algorithm 1) become specialists for certain classes.",3.3. Effect of Confident Oracle Loss,[0],[0]
"For specialized classes, they show the similar performance compared to the models trained by MCL, i.e., minimizing the oracle loss (1), which considers only specialization (see Figure 1(a)).",3.3. Effect of Confident Oracle Loss,[0],[0]
"For non-specialized classes, ensemble members of CMCL are not overconfident, which makes it easy to pick a correct output via simple voting/averaging.",3.3. Effect of Confident Oracle Loss,[0],[0]
"We indeed confirm that each model trained by CMCL has not only low entropy for its specialized classes, but also exhibits high entropy for nonspecialized classes as shown in Figure 2(b).
",3.3. Effect of Confident Oracle Loss,[0],[0]
"We also evaluate the quality of confidence/uncertainty level on unseen data using SVHN (Netzer et al., 2011).",3.3. Effect of Confident Oracle Loss,[0],[0]
"Somewhat surprisingly, each model trained by CMCL only using CIFAR-10 training data exhibits high entropy for SVHN test data, whereas models trained by MCL and IE are overconfident on it (see Figure 2(a) and 2(c)).",3.3. Effect of Confident Oracle Loss,[0],[0]
"We emphasize that our method can produce confident predictions significantly better than the proposed method by (Lakshminarayanan et al., 2016), which uses the averaged probability of ensemble models trained by IE to obtain high quality uncertainty estimates (see Figure 2(c)).",3.3. Effect of Confident Oracle Loss,[0],[0]
"In this section, we introduce advanced techniques for reducing the overconfidence and improving the performance.",4. Regularization Techniques,[0],[0]
We first propose a feature sharing scheme that stochastically shares the features among member models of CMCL to further address the overconfidence issue.,4.1. Feature Sharing,[0],[0]
The primary reason why deep learning models are overconfident is that they do not always extract general features from data.,4.1. Feature Sharing,[0],[0]
"For examples, assume that some deep model only trains frogs and roses for classifying them.",4.1. Feature Sharing,[0],[0]
"Although there might exist many kinds of features on their images, the model might make a decision based only on some specific features, e.g., colors.",4.1. Feature Sharing,[0],[0]
"In this case, ‘red’ apples can be classified as rose with high confidence.",4.1. Feature Sharing,[0],[0]
Such an issue might be more severe in CMCL (and MCL) compared to IE since members of CMCL are specialized to certain data.,4.1. Feature Sharing,[0],[0]
"To address the issue, we suggest the feature ensemble approach that encourages each model to generate meaningful abstractions from rich features extracted from other models.
",4.1. Feature Sharing,[0],[0]
"Formally, consider an ensemble ofM neural networks with L hidden layers.",4.1. Feature Sharing,[0],[0]
"We denote the weight matrix for layer
` of model m ∈",4.1. Feature Sharing,[0],[0]
"[M ] and `-th hidden feature of model m by W`m and h ` m, respectively.",4.1. Feature Sharing,[0],[0]
"Instead of sharing the whole units of a hidden feature, we introduce random binary masks determining which units to be shared with other models.",4.1. Feature Sharing,[0],[0]
"We denote the mask for layer ` from model n to m as σ`nm ∼ Bernoulli(λ), which has the same dimension with h`n (we use λ = 0.7 in all experiments).",4.1. Feature Sharing,[0],[0]
"Then, the `-th hidden feature of model m with sharing (`− 1)-th hidden features is defined as follows:
h`m (x) = φ W`m h`−1m (x) + ∑
n 6=m
σ`nm ?",4.1. Feature Sharing,[0],[0]
h,4.1. Feature Sharing,[0],[0]
`−1 n,4.1. Feature Sharing,[0],[0]
"(x)  , where ? denotes element-wise multiplication and φ is the activation function.",4.1. Feature Sharing,[0],[0]
Figure 2(d) illustrates the proposed feature sharing scheme in an ensemble of deep neural networks.,4.1. Feature Sharing,[0],[0]
It makes each model learn more generalized features by sharing the features among them.,4.1. Feature Sharing,[0],[0]
"However, one might expect that it might make each model overfitted due to the increased number of parameters that induces a single prediction, i.e., the statistical dependencies among outputs of models increase, which would hurt the ensemble effect.",4.1. Feature Sharing,[0],[0]
"In order to handle this issue, we introduce the randomness in sharing across models in a similar manner to DropOut (Srivastava et al., 2014) using the random binary masks σ .",4.1. Feature Sharing,[0],[0]
"In addition, we propose sharing features at lower layers since sharing the higher layers might overfit the overall networks more.",4.1. Feature Sharing,[0],[0]
"For example, in all experiments with CNNs in this paper, we commonly apply feature sharing for hidden features just before the first pooling layer.",4.1. Feature Sharing,[0],[0]
"We also remark that such feature sharing strategies for better generalization have also been investigated in the literature for different purposes (Misra et al., 2016; Rusu et al., 2016).",4.1. Feature Sharing,[0],[0]
"For more efficiency in minimizing the confident oracle loss, we also consider a noisy unbiased estimator of gradients of the KL divergence with Monte Carlo samples from the uniform distribution.",4.2. Stochastic Labeling,[0],[0]
"The KL divergence from the predictive distribution to the uniform distribution can be written as follows:
DKL (U (y) ‖",4.2. Stochastic Labeling,[0],[0]
Pθ (y | x)),4.2. Stochastic Labeling,[0],[0]
= ∑ y U (y) log U (y),4.2. Stochastic Labeling,[0],[0]
"Pθ (y | x)
= ∑ y U (y)",4.2. Stochastic Labeling,[0],[0]
"logU (y)− ∑ y U (y) logPθ (y | x).
",4.2. Stochastic Labeling,[0],[0]
"Hence, the gradient of the above KL divergence with respect to the model parameter θ becomes
5θDKL (U (y) ‖",4.2. Stochastic Labeling,[0],[0]
Pθ (y | x)),4.2. Stochastic Labeling,[0],[0]
"= −EU(y)[5θlogPθ (y | x)].
",4.2. Stochastic Labeling,[0],[0]
"From the above, we induce the following noisy unbiased estimator of gradients with Monte Carlo samples from the uniform distribution:
− EU(y)[5θlogPθ (y | x)]",4.2. Stochastic Labeling,[0],[0]
"w − 1
S ∑ s 5θlogPθ (ys | x),
where ys ∼ U (y) and S is the number of samples.",4.2. Stochastic Labeling,[0],[0]
This random estimator takes samples from the uniform distribution U (y) and constructs estimates of the gradient using them.,4.2. Stochastic Labeling,[0],[0]
"In other words, 5θlogPθ (ys | x) is the gradient of the cross entropy loss under assigning a random label to x.",4.2. Stochastic Labeling,[0],[0]
This stochastic labeling provides efficiency in implementation/computation and stochastic regularization effects.,4.2. Stochastic Labeling,[0],[0]
"We formally describe detailed procedures, as the version 1 of Algorithm 1.",4.2. Stochastic Labeling,[0],[0]
"We evaluate our algorithm for both classification and foreground-background segmentation tasks using CIFAR10 (Krizhevsky & Hinton, 2009), SVHN (Netzer et al., 2011) and iCoseg (Batra et al., 2010) datasets.",5. Experiments,[0],[0]
"In all experiments, we compare the performance of CMCL with those of traditional IE and MCL using deep models.",5. Experiments,[0],[0]
We provide the more detailed experimental setups including model architectures in the supplementary material.1,5. Experiments,[0],[0]
Setup.,5.1. Image Classification,[0],[0]
"The CIFAR-10 dataset consists of 50,000 training and 10,000 test images with 10 image classes where each image consists of 32× 32 RGB pixels.",5.1. Image Classification,[0],[0]
"The SVHN dataset consists of 73,257 training and 26,032 test images.2 We pre-process the images with global contrast normalization and ZCA whitening following (Ian J. Goodfellow & Bengio, 2013; Zagoruyko & Komodakis, 2016), and do not use any data augmentation.",5.1. Image Classification,[0],[0]
"Using these datasets, we train various CNNs, e.g., VGGNet (Simonyan & Zisserman, 2015), GoogLeNet",5.1. Image Classification,[0],[0]
"(Szegedy et al., 2015), and ResNet (He et al., 2016).",5.1. Image Classification,[0],[0]
"Similar to (Zagoruyko & Komodakis, 2016), we use the softmax classifier, and train each model by minimizing the cross-entropy loss using the stochastic gradient descent method with Nesterov momentum.
",5.1. Image Classification,[0],[0]
"For evaluation, we measure the top-1 and oracle error rates on the test dataset.",5.1. Image Classification,[0],[0]
The top-1 error rate is calculated by averaging output probabilities from all models and predicting the class of the highest probability.,5.1. Image Classification,[0],[0]
"The oracle error rate is the rate of classification failure over all outputs of individual ensemble members for a given input, i.e., it measures whether none of the members predict the correct class for
1Our code is available at https://github.com/ chhwang/cmcl.
2We do not use the extra SVHN dataset for training.
an input.",5.1. Image Classification,[0],[0]
"While a lower oracle error rate suggests higher diversity, a lower oracle error rate does not always bring a higher top-1 accuracy as this metric does not reveal the level of overconfidence of each model.",5.1. Image Classification,[0],[0]
"By collectively measuring the top-1 and oracle error rates, one can grasp the level of specialization and confidence of a model.
",5.1. Image Classification,[0],[0]
Contribution by each technique.,5.1. Image Classification,[0],[0]
Table 1 validates contributions of our suggested techniques under comparison with other ensemble methods IE and MCL.,5.1. Image Classification,[0],[0]
We evaluate an ensemble of five simple CNN models where each model has two convolutional layers followed by a fully-connected layer.,5.1. Image Classification,[0],[0]
We incrementally apply our optimizations to gauge the stepwise improvement by each component.,5.1. Image Classification,[0],[0]
One can note that CMCL significantly outperforms MCL in the top1 error rate even without feature sharing or stochastic labeling while it still provides a comparable oracle error rate.,5.1. Image Classification,[0],[0]
"By sharing the 1st ReLU activated features, the top-1 error rates are improved compared to those that employ only confident oracle loss.",5.1. Image Classification,[0],[0]
Stochastic labeling further improves both error rates.,5.1. Image Classification,[0],[0]
"This implies that stochastic labeling not only reduces computational burdens but also provides regularization effects.
",5.1. Image Classification,[0],[0]
Overlapping.,5.1. Image Classification,[0],[0]
"As a natural extension of CMCL, we also consider picking K specialized models instead of having only one specialized model, which was investigated for original MCL (Guzman-Rivera et al., 2012; Lee et al., 2016).",5.1. Image Classification,[0],[0]
"This is easily achieved by modifying the constraint (3b) as ∑M m=1 v m i = K, where K is an overlap parameter that controls training data overlap between the models.",5.1. Image Classification,[0],[0]
This simple but natural scheme brings extra gain in top-1 performance by generalizing each model better.,5.1. Image Classification,[0],[0]
"Table 2 compares the performance of various ensemble methods with varying values of K. Under the choice of K = 4, CMCL of 10 CNNs provides 9.13% relative reduction in the top-1 error rates from the corresponding IE.",5.1. Image Classification,[0],[0]
"Somewhat interestingly, IE has similar error rates on ensembles of both 5 and 10 CNNs, which implies that the performance of CMCL might be impossible to achieve using IE even if one increases the number of models in IE.
",5.1. Image Classification,[0],[0]
Large-scale CNNs.,5.1. Image Classification,[0],[0]
"We now evaluate the performance of our ensemble method when it is applied to larger-scale CNN models for image classification tasks on CIFAR-10
and SVHN datasets.",5.1. Image Classification,[0],[0]
"Specifically, we test VGGNet (Simonyan & Zisserman, 2015), GoogLeNet (Szegedy et al., 2015), and ResNet (He et al., 2016).",5.1. Image Classification,[0],[0]
"We share the nonlinear activated features right before the first pooling layer, i.e., the 6th, 2nd, and 1st ReLU activations for ResNet with 20 layers, VGGNet with 17 layers, and GoogLeNet with 18 layers, respectively.",5.1. Image Classification,[0],[0]
This choice is for maximizing the regularization effect of feature sharing while minimizing the statistical dependencies among the ensemble models.,5.1. Image Classification,[0],[0]
"For all models, we choose the best hyperparameters for confident oracle loss among the penalty parameter β ∈ {0.5, 0.75, 1, 1.25, 1.5} and the overlapping parameter K ∈ {2, 3, 4}.",5.1. Image Classification,[0],[0]
Table 3 shows that CMCL consistently outperforms all baselines with respect to the top-1 error rate while producing comparable oracle error rates to those of MCL.,5.1. Image Classification,[0],[0]
We also apply the feature sharing to IE as reported in Figure 4(a).,5.1. Image Classification,[0],[0]
"Even though the feature sharing also improves the performance of IE, CMCL still outperforms IE: CMCL provides 6.11% relative reduction of the top-1
error rate from the IE with feature sharing under the choice of M = 10.",5.1. Image Classification,[0],[0]
"We also remark that IE with feature sharing has similar error rates as the ensemble size increases, while CMCL does not (i.e., the gain is more significant for CMCL).",5.1. Image Classification,[0],[0]
This implies that feature sharing is more effectively working for CMCL.,5.1. Image Classification,[0],[0]
"In this section, we evaluate if ensemble models trained with CMCL produce high-quality segmentation of foreground and background of an image with the iCoseg dataset.",5.2. Foreground-Background Segmentation,[0],[0]
"The foreground-background segmentation is formulated as a pixel-level classification problem with 2 classes, i.e., 0 (background) or 1 (foreground).",5.2. Foreground-Background Segmentation,[0],[0]
"To tackle the problem, we design fully convolutional networks (FCNs) model (Long et al., 2015) based on the decoder architecture presented in (Radford et al., 2016).",5.2. Foreground-Background Segmentation,[0],[0]
The dataset consists of 38 groups of related images with pixel-level ground truth on foregroundbackground segmentation of each image.,5.2. Foreground-Background Segmentation,[0],[0]
"We only use im-
ages that are larger than 300 × 500 pixels.",5.2. Foreground-Background Segmentation,[0],[0]
"For each class, we randomly split 80% and 20% of the data into training and test sets, respectively.",5.2. Foreground-Background Segmentation,[0],[0]
"We train on 75 × 125 resized images using the bicubic interpolation (Keys, 1981).",5.2. Foreground-Background Segmentation,[0],[0]
"Similar to (Guzman-Rivera et al., 2012; Lee et al., 2016), we initialize the parameters of FCNs with those trained by IE for MCL and CMCL.",5.2. Foreground-Background Segmentation,[0],[0]
"For all experiments, CMCL is used with both feature sharing and stochastic labeling.
",5.2. Foreground-Background Segmentation,[0],[0]
"Similar to (Guzman-Rivera et al., 2012), we define the percentage of incorrectly labeled pixels as prediction error rate.",5.2. Foreground-Background Segmentation,[0],[0]
"We measure the oracle error rate (i.e., the lowest error rate over all models for a given input) and the top-1 error rate.",5.2. Foreground-Background Segmentation,[0],[0]
"The top-1 error rate is measured by following the predictions of the member model that has a lower pixel-wise entropy, i.e., picking the output of a more confident model.",5.2. Foreground-Background Segmentation,[0],[0]
"For each ensemble method, we vary the number of ensemble models and measure the oracle error rate and test error rate.",5.2. Foreground-Background Segmentation,[0],[0]
Figure 4(b) and 4(c) show both top-1 and oracle error rates for all ensemble methods.,5.2. Foreground-Background Segmentation,[0],[0]
We remark that the ensemble models trained by CMCL consistently improves the top-1 error rate over baselines.,5.2. Foreground-Background Segmentation,[0],[0]
"In an ensemble of 5 models, we find that CMCL achieve up to 6.77% relative reduction
in the top-1 error rate from the corresponding IE.",5.2. Foreground-Background Segmentation,[0],[0]
"As shown in Figure 3, an individual model trained by CMCL generates high-quality solutions by specializing itself in specific images (e.g., model 1 is specialized for ‘lobster’",5.2. Foreground-Background Segmentation,[0],[0]
while model 2 is specialized for ‘duck’) while each model trained by IE does not.,5.2. Foreground-Background Segmentation,[0],[0]
"This paper proposes CMCL, a novel ensemble method of deep neural networks that produces diverse/plausible confident prediction of high quality.",6. Conclusion,[0],[0]
"To this end, we address the over-confidence issues of MCL, and propose a new loss, architecture and training method.",6. Conclusion,[0],[0]
"In our experiments, CMCL outperforms not only the known MCL, but also the traditional IE, with respect to the top-1 error rates in classification and segmentation tasks.",6. Conclusion,[0],[0]
The recent trend in the deep learning community tends to make models bigger and wider.,6. Conclusion,[0],[0]
We believe that our new ensemble approach brings a refreshing angle for developing advanced large-scale deep neural networks in many related applications.,6. Conclusion,[0],[0]
"This work was supported in part by the ICT R&D Program of MSIP/IITP, Korea, under [2016-0-00563, Research on Adaptive Machine Learning Technology Development for Intelligent Autonomous Digital Companion], R0190-162012, [High Performance Big Data Analytics Platform Performance Acceleration Technologies Development], and by the National Research Council of Science & Technology (NST) grant by the Korea government (MSIP) (No. CRC-15-05-ETRI).",Acknowledgements,[0],[0]
Ensemble methods are arguably the most trustworthy techniques for boosting the performance of machine learning models.,abstractText,[0],[0]
"Popular independent ensembles (IE) relying on naı̈ve averaging/voting scheme have been of typical choice for most applications involving deep neural networks, but they do not consider advanced collaboration among ensemble models.",abstractText,[0],[0]
"In this paper, we propose new ensemble methods specialized for deep neural networks, called confident multiple choice learning (CMCL): it is a variant of multiple choice learning (MCL) via addressing its overconfidence issue.",abstractText,[0],[0]
"In particular, the proposed major components of CMCL beyond the original MCL scheme are (i) new loss, i.e., confident oracle loss, (ii) new architecture, i.e., feature sharing and (iii) new training method, i.e., stochastic labeling.",abstractText,[0],[0]
"We demonstrate the effect of CMCL via experiments on the image classification on CIFAR and SVHN, and the foregroundbackground segmentation on the iCoseg.",abstractText,[0],[0]
"In particular, CMCL using 5 residual networks provides 14.05% and 6.60% relative reductions in the top-1 error rates from the corresponding IE scheme for the classification task on CIFAR and SVHN, respectively.",abstractText,[0],[0]
Confident Multiple Choice Learning,title,[0],[0]
"Real-world applications of binary classification to complex decision problems have led to the design of a wide range of evaluation metrics (Choi & Cha, 2010).",1. Introduction,[0],[0]
"Prominent examples include area under the ROC curve (AUC) for imbalanced labels (Menon et al., 2013), F-measure for information retrieval (Lewis, 1995), and precision at the top (Kar et al., 2014; 2015; Jasinska et al., 2016).",1. Introduction,[0],[0]
"To this end, several algorithms have been proposed for optimizing many of these metrics, primarily focusing on large-scale learning, without a conscious emphasis on statistical consequences of choosing models and their asymptotic behavior (Kar et al., 2015; Joachims, 2005).",1. Introduction,[0],[0]
"Wide use of such complex metrics has also re-invigorated research into their theoretical properties, which can then serve as a guide to prac-
Authors listed in the alphabetical order 1Institute of Computing Science, Poznan University of Technology, Poland 2Department of Computer Science, University of Illinois at UrbanaChampaign, USA 3Microsoft Research, India.",1. Introduction,[0],[0]
"Correspondence to: Wojciech Kotłowski <wkotlowski@cs.put.poznan.pl>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"tice (Koyejo et al., 2014a; Narasimhan et al., 2014a; Dembczyński et al., 2012; Waegeman et al., 2014; Natarajan et al., 2016).
",1. Introduction,[0],[0]
"Complex evaluation metrics for binary classification are best described as set metrics, or non-decomposable metrics – as, in general, the evaluation for a set of predictions cannot be decomposed into the average of individual instance evaluations.",1. Introduction,[0],[0]
This is in contrast to decomposable metrics such as accuracy which are defined as the empirical average of the instance evaluations.,1. Introduction,[0],[0]
"This property is the primary source of difficulty in theoretical analysis, and interestingly has led to two distinct settings and notions of consistency.",1. Introduction,[0],[0]
"On one hand, Population Utility (PU) focuses on estimation – so a consistent PU classifier is one which correctly estimates the population optimal utility as the size of the training set (equiv.",1. Introduction,[0],[0]
test set) increases.,1. Introduction,[0],[0]
The PU approach has strongest roots in classical statistical analysis which often deals with asymptotically optimal estimation.,1. Introduction,[0],[0]
"On the other hand, Expected Test Utility (ETU) focuses on generalization.",1. Introduction,[0],[0]
"Thus, the consistent ETU classifier is one which optimizes the expected prediction error over test sets of a pre-defined size.",1. Introduction,[0],[0]
The ETU approach has strongest roots in statistical machine learning which prizes generalization as the primary goal.,1. Introduction,[0],[0]
"Importantly, these distinctions are irrelevant when the metric is a linear function of the confusion matrix e.g. (weighted) accuracy and other linear metrics.",1. Introduction,[0],[0]
"To the best of our knowledge, this dichotomy was first explicitly noted by Ye et al. (2012) in the context of F-measure.1 Like in Ye et al. (2012), our goal is not to adjudicate the correctness of either approach, but instead to explore deep connections, and highlight significant differences between both approaches for a wide range of metrics.
",1. Introduction,[0],[0]
"Contributions: We present a variety of results comparing and contrasting the PU and ETU approaches for consistent classification:
• We show that for a wide range of metrics, PU and ETU are asymptotically equivalent with respect to the size of the test set, subject to a certain p-Lipschitzness
1Note that Ye et al. (2012) termed the two approaches Empirical Utility Maximization (EUM) and Decision Theoretic Approach (DTA), respectively.",1. Introduction,[0],[0]
"We have instead chosen the more descriptive names Population Utility (PU) and Expected Test Utility (ETU).
condition which is satisfied by many metrics of interest.",1. Introduction,[0],[0]
This further implies asymptotic equivalence of the Bayes optimal classifiers (Section 3.1).,1. Introduction,[0],[0]
"Similar results were previously only known for F-measure.
",1. Introduction,[0],[0]
"• We provide lower bounds for the difference between PU and ETU metrics for finite test sets, and for certain metrics – thereby highlighting the difference between PU and ETU consistent classifiers with small test sets (Section 3.2).
",1. Introduction,[0],[0]
"• We analyze approximate ETU classification using low order Taylor approximations, showing that the approximation can be computed with effectively linear complexity, yet achieves low error under standard assumptions (Section 4.1).
",1. Introduction,[0],[0]
"• We consider the effects of model mis-specification and find that ETU may be more sensitive than PU, but this may be alleviated by properly calibrating the estimated probabilities (Section 4.2).
",1. Introduction,[0],[0]
"In addition, we present experimental results using simulated and real data to evaluate our theoretical claims (Section 5).",1. Introduction,[0],[0]
"We consider the binary classification problem, where the input is a feature vector x ∈ X , and the output is a label y ∈ {0, 1}.",2. Preliminaries and Problem Setup,[0],[0]
"We assume the examples (x, y) are generated i.i.d.",2. Preliminaries and Problem Setup,[0],[0]
"according to P(x, y).",2. Preliminaries and Problem Setup,[0],[0]
"A classifier is a mapping h : X → {0, 1}.",2. Preliminaries and Problem Setup,[0],[0]
"We let 1C denote the indicator function i.e. equal to one if C is satisfied, and zero otherwise.
",2. Preliminaries and Problem Setup,[0],[0]
"Given a distribution P and a binary classifier h, define:
TP(h) =",2. Preliminaries and Problem Setup,[0],[0]
"P(h = 1, y = 1), TN(h) = P(h = 0, y = 0), FP(h) =",2. Preliminaries and Problem Setup,[0],[0]
"P(h = 1, y = 0), FN(h) =",2. Preliminaries and Problem Setup,[0],[0]
"P(h = 0, y = 1),
which are entries of the so-called confusion matrix, namely true positives, true negatives, false positives and false negatives.",2. Preliminaries and Problem Setup,[0],[0]
"In this paper, we are interested in optimizing performance metrics Φ(h,P) (we use explicit dependence on P because we will also consider the empirical version of Φ) that are functions of the above four quantities.",2. Preliminaries and Problem Setup,[0],[0]
"However, since the entries of the confusion matrix are interdependent, it suffices to only use their three independent combinations.",2. Preliminaries and Problem Setup,[0],[0]
"Following Natarajan et al. (2016), we parametrize Φ(h,P) = Φ(u(h), v(h), p) by means of:
u(h) = TP(h), v(h) =",2. Preliminaries and Problem Setup,[0],[0]
"P(h = 1), and p = P(y = 1).
",2. Preliminaries and Problem Setup,[0],[0]
"As argued by Natarajan et al. (2016), any metric being a function of the confusion matrix can be parameterized in this way.",2. Preliminaries and Problem Setup,[0],[0]
"Table 1 lists popular examples of such metrics
with explicit parameterization Φ(u, v, p).",2. Preliminaries and Problem Setup,[0],[0]
"Throughout the paper we assume Φ(u, v, p) is bounded from above and from below.2",2. Preliminaries and Problem Setup,[0],[0]
Definition 1 (Population Utility (PU)).,2.1. Formal Definitions of PU and ETU,[0],[0]
"Given a distribution P and classifier h, the PU of h for a performance metric Φ is defined as Φ(u(h), v(h), p).",2.1. Formal Definitions of PU and ETU,[0],[0]
"We let h∗PU denote any maximizer of the PU,
h∗PU ∈ argmax h Φ(u(h), v(h), p) .
",2.1. Formal Definitions of PU and ETU,[0],[0]
"In words, the PU is obtained by taking the value of metric Φ evaluated at the expected confusion matrix of h over P. Thus, one can think of the PU as evaluating the classifier h on a “single test set of infinite size” drawn i.i.d.",2.1. Formal Definitions of PU and ETU,[0],[0]
"from P.
",2.1. Formal Definitions of PU and ETU,[0],[0]
"In contrast, ETU evaluates the expected utility for a fixedsize test set.",2.1. Formal Definitions of PU and ETU,[0],[0]
"Formally, given a sample S = {(xi, yi)}ni=1 of size n, generated i.i.d.",2.1. Formal Definitions of PU and ETU,[0],[0]
"from P, we let û(h), v̂(h), p̂ denote the corresponding empirical quantities:
û(h)",2.1. Formal Definitions of PU and ETU,[0],[0]
"= 1
n n∑ i=1",2.1. Formal Definitions of PU and ETU,[0],[0]
"h(xi)yi, v̂(h) = 1 n n∑ i=1",2.1. Formal Definitions of PU and ETU,[0],[0]
"h(xi), p̂ = 1 n",2.1. Formal Definitions of PU and ETU,[0],[0]
"n∑ i=1 yi,
and the empirical value of metric Φ is then Φ(û(h), v̂(h), p̂).
",2.1. Formal Definitions of PU and ETU,[0],[0]
Definition 2 (Expected Test Utility (ETU)).,2.1. Formal Definitions of PU and ETU,[0],[0]
"Let x = (x1, . . .",2.1. Formal Definitions of PU and ETU,[0],[0]
", xn) ∈ Xn be an arbitrary sequence of inputs.",2.1. Formal Definitions of PU and ETU,[0],[0]
"Given a distribution P and a classifier h, the ETU of h for a performance metric Φ conditioned on x is defined as:3
Ey|x",2.1. Formal Definitions of PU and ETU,[0],[0]
"[ Φ ( û(h), v̂(h), p̂ )] ,
2In fact, for essentially all metrics used in practice it holds 0 ≤ Φ(u, v, p) ≤ 1.
3The conditional expectation y|x is defined up to a zeromeasure set (over x), but this does not create any problems as we always consider x being sampled from the data distribution.
where the expectation over y = (y1, . . .",2.1. Formal Definitions of PU and ETU,[0],[0]
", yn) is with respect to the conditional distribution P(y|x)",2.1. Formal Definitions of PU and ETU,[0],[0]
i.i.d.,2.1. Formal Definitions of PU and ETU,[0],[0]
over the examples.,2.1. Formal Definitions of PU and ETU,[0],[0]
"We let h∗ETU(x) denote any maximizer of the ETU,
h∗ETU(x) ∈ argmax h
Ey|x",2.1. Formal Definitions of PU and ETU,[0],[0]
"[ Φ ( û(h), v̂(h), p̂ )] .
",2.1. Formal Definitions of PU and ETU,[0],[0]
One can think of ETU as evaluating the classifier h on “infinitely many test sets of size n” drawn i.i.d.,2.1. Formal Definitions of PU and ETU,[0],[0]
from P. We will see (in Section 4) that the optimal predictions (in both PU and ETU approaches) can be accurately estimated using the conditional probabilities P(yi|xi).,2.1. Formal Definitions of PU and ETU,[0],[0]
"In practice, we first obtain an estimator of the conditional probability and then compute the optimal predictions on test data based on their conditional probability estimates.
",2.1. Formal Definitions of PU and ETU,[0],[0]
Remark 1.,2.1. Formal Definitions of PU and ETU,[0],[0]
"More generally, ETU optimizes the expected utility Ey,x [ Φ ( û(h), v̂(h), p̂ )] .",2.1. Formal Definitions of PU and ETU,[0],[0]
"However, clearly, it is suf-
ficient to analyze the predictions at any given x (Natarajan et al., 2016) as in Definition 2.",2.1. Formal Definitions of PU and ETU,[0],[0]
"The two frameworks treat the metrics as utility measures (i.e., they are to be maximized).",2.2. Well-behaved Performance Metrics,[0],[0]
"Further, it is reasonable to expect that Φ(h,P) is non-decreasing in true positive and true negative rates (and indeed, virtually all performance measures used in practice behave this way).",2.2. Well-behaved Performance Metrics,[0],[0]
"As shown by Natarajan et al. (2016), such monotonicity in true positive and true negative rates implies another property, called TP monotonicity, which is better suited to the parameterization employed here.
",2.2. Well-behaved Performance Metrics,[0],[0]
Definition 3 (TP monotonicity).,2.2. Well-behaved Performance Metrics,[0],[0]
"Φ(u,",2.2. Well-behaved Performance Metrics,[0],[0]
"v, p) is said to be TP monotonic if for any v, p and u1 > u2, it holds that Φ(u1, v, p)",2.2. Well-behaved Performance Metrics,[0],[0]
>,2.2. Well-behaved Performance Metrics,[0],[0]
"Φ(u2, v, p).
",2.2. Well-behaved Performance Metrics,[0],[0]
"It is easy to verify that all measures in Table 1 are TP monotonic.
",2.2. Well-behaved Performance Metrics,[0],[0]
"A contribution in this work is to develop a notion of regularity for metrics, that helps establish statistical connections between the two frameworks and their optimal classifiers.",2.2. Well-behaved Performance Metrics,[0],[0]
"We call it p-Lipschitzness, defined next.
",2.2. Well-behaved Performance Metrics,[0],[0]
"Definition 4 (p-Lipschitzness). Φ(u, v, p) is said to be p-Lipschitz if:
|Φ(u, v, p)−Φ(u′, v′, p′)| ≤ Up|u−u′|+Vp|v−v′|+Pp|p−p′|,
for any feasible u, v, p, u′, v′, p′. The Lipschitz constants Up, Vp, Pp are allowed to depend on p, in contrast to the standard Lipschitz functions.
",2.2. Well-behaved Performance Metrics,[0],[0]
"The rationale behind p-Lipschitzness is that we want to control the change in value of the measure under small
changes in their arguments.",2.2. Well-behaved Performance Metrics,[0],[0]
This property turns out to be essential to show equivalence between ETU and PU approaches.,2.2. Well-behaved Performance Metrics,[0],[0]
"On the other hand, if we simply used a standard definition of Lipschitz function (with global constants), it would not be satisfied by many interesting measures.",2.2. Well-behaved Performance Metrics,[0],[0]
"Hence, we weaken the Lipschitz property by allowing the constant to vary as a function of p.",2.2. Well-behaved Performance Metrics,[0],[0]
"One can also show that general linear-fractional performance metrics studied in (Koyejo et al., 2014a; Narasimhan et al., 2015; Kotłowski & Dembczyński, 2016) satisfy p-Lipschitzness under mild conditions (Appendix A).
Proposition 1.",2.2. Well-behaved Performance Metrics,[0],[0]
"All measures in Table 1 are p-Lipschitz.
Proof.",2.2. Well-behaved Performance Metrics,[0],[0]
We only give a proof for Fβ-measure here (See Appendix A for the rest).,2.2. Well-behaved Performance Metrics,[0],[0]
"For ease, let us denote Fβ(u, v, p) by Fβ and Fβ(u′, v′, p′) by F ′β .",2.2. Well-behaved Performance Metrics,[0],[0]
"Let ∆u = u−u′, ∆v = v−v′, ∆p = p− p′. We have:
|Fβ",2.2. Well-behaved Performance Metrics,[0],[0]
− F ′β | = (1 + β2),2.2. Well-behaved Performance Metrics,[0],[0]
"|u(β2p′ + v′)− u′(β2p+ v)|
(β2p+ v)(β2p′ + v′)
=",2.2. Well-behaved Performance Metrics,[0],[0]
(1 + β2),2.2. Well-behaved Performance Metrics,[0],[0]
|∆u(β2p′ + v′)−,2.2. Well-behaved Performance Metrics,[0],[0]
"u′β2∆p− u′∆v|
(β2p+ v)(β2p′ + v′)
≤ 1 + β 2
β2p+v
( |∆u|+ β 2u′
β2p′+v′ |∆p|+",2.2. Well-behaved Performance Metrics,[0],[0]
"u
′
β2p′+v′ |∆v|
) .
",2.2. Well-behaved Performance Metrics,[0],[0]
"Since u′ ≤ min{p′, v′}, we have β 2u′ β2p′+v′ ≤ 1, u′
β2p′+v′ ≤ 1, and thus we can choose Up = Vp = Pp = 1+β 2
β2p .
",2.2. Well-behaved Performance Metrics,[0],[0]
"As for an example of a metric which is not p-Lipschitz, consider the precision defined as Φ(u, v, p) = uv .",2.2. Well-behaved Performance Metrics,[0],[0]
"Indeed, if v is close to zero, choosing v′ =",2.2. Well-behaved Performance Metrics,[0],[0]
"2v, u′ = u and p′ = p gives:
Φ(u, v, p)− Φ(u′, v′, p′) =",2.2. Well-behaved Performance Metrics,[0],[0]
"u 2v ,
which can be arbitrarily large for sufficiently small v, while the difference |v",2.2. Well-behaved Performance Metrics,[0],[0]
− v′| = v is small.,2.2. Well-behaved Performance Metrics,[0],[0]
"As it turns out in Section 3.2, this pathological behavior of the precision metric is responsible for a large deviation between PU and ETU, which suggests that p-Lipschitzness is in some sense necessary to establish connections.",2.2. Well-behaved Performance Metrics,[0],[0]
Most of the existing literature on optimizing nondecomposable classification metrics focus on one of the two approaches in isolation.,3. Equivalence of PU and ETU,[0],[0]
"In this section, we show that the two approaches are in fact asymptotically equivalent, for a range of well-behaved metrics.",3. Equivalence of PU and ETU,[0],[0]
"Informally, given a distribution P and a performance metric Φ, our first result is that for sufficiently large n, the PU of the associated h∗ETU is arbitrarily close to that of h∗PU, and likewise, the ETU of h∗PU is arbitrarily close to that of h ∗ ETU.",3. Equivalence of PU and ETU,[0],[0]
"In contrast, we also
show that the PU and ETU optimal classifiers may suffer differences for small samples.",3. Equivalence of PU and ETU,[0],[0]
"The intuition behind the equivalence lies in the observation that the optimal classifiers under the two approaches exhibit a very simple, similar form, under mild assumptions on the distribution (Koyejo et al., 2014b; Narasimhan et al., 2014b; Natarajan et al., 2016).",3.1. Asymptotic Equivalence,[0],[0]
Let η(x) := P(y = 1|x) denote the conditional probability of positive class as a function of x.,3.1. Asymptotic Equivalence,[0],[0]
"The following lemma shows that for any fixed classifier h that thresholds η(x), and sufficiently large sample size n, its performance measured with respect to PU and ETU are close, in particular, differ by a factor that decays as fast as Õ(1/ √ n).",3.1. Asymptotic Equivalence,[0],[0]
"In fact, the result holds uniformly over all such binary classifiers.
",3.1. Asymptotic Equivalence,[0],[0]
Lemma 1.,3.1. Asymptotic Equivalence,[0],[0]
"Let H = {h | h = 1η(x)≥τ , τ ∈",3.1. Asymptotic Equivalence,[0],[0]
"[0, 1]}, be the class of thresholded binary decision functions.",3.1. Asymptotic Equivalence,[0],[0]
Let Φ be a performance metric which is p-Lipschitz.,3.1. Asymptotic Equivalence,[0],[0]
"Then, with probability at least 1 − δ over a random sample S = {(xi, yi)}ni=1 of size n generated i.i.d.",3.1. Asymptotic Equivalence,[0],[0]
"from P, it holds uniformly over all h ∈ H,∣∣∣Φ(u(h),v(h), p(h))− Ey|x",3.1. Asymptotic Equivalence,[0],[0]
"[Φ(û(h), v̂(h), p̂(h))]",3.1. Asymptotic Equivalence,[0],[0]
"∣∣∣
≤",3.1. Asymptotic Equivalence,[0],[0]
"4Lp
√ 2 log(n+ 1)
n + 3Lp √ log 4δ 2n + Lp√",3.1. Asymptotic Equivalence,[0],[0]
"n ,
where û(h), v̂(h), p̂(h) are empirical quantities evaluated on S, and Lp = max{Up, Vp, Pp}.",3.1. Asymptotic Equivalence,[0],[0]
Remark 2.,3.1. Asymptotic Equivalence,[0],[0]
Lemma 1 generalizes the result obtained by Ye et al. (2012) for Fβ-measure to arbitrary p-Lipschitz metrics.,3.1. Asymptotic Equivalence,[0],[0]
"Furthermore, using more careful bounding technique, we are able to get a better dependence on the sample size n, essentially Õ(1/ √ n)",3.1. Asymptotic Equivalence,[0],[0]
(neglecting logarithmic terms).,3.1. Asymptotic Equivalence,[0],[0]
"In fact, this dependence cannot be improved any further in general (See Appendix B).
",3.1. Asymptotic Equivalence,[0],[0]
The uniform convergence result in Lemma 1 enables the first main result of this work.,3.1. Asymptotic Equivalence,[0],[0]
"In particular, the convergence holds when the optimal classifiers with respect to ETU and PU are of the thresholded form, i.e. h∗PU ∈ H, and h∗ETU(x) ∈ H almost surely (with respect to random sample of inputs x), where H = {h | h = 1η(x)≥τ , τ ∈",3.1. Asymptotic Equivalence,[0],[0]
"[0, 1]} is the class of threshold functions on function η(x).",3.1. Asymptotic Equivalence,[0],[0]
"Several recent results have shown that the optimal classifier for many popular metrics (including all metrics in Table 1) indeed has the thresholded form (Narasimhan et al., 2014a; Lewis, 1995), under a mild condition related to continuity of the distribution of η(x) (See the proof of Theorem 1 in Appendix B.2 for details):
Assumption 1.",3.1. Asymptotic Equivalence,[0],[0]
"The random variable η(x) has a density (with respect to the Lebesgue measure) on [0, 1].
",3.1. Asymptotic Equivalence,[0],[0]
We are now ready to state the result.,3.1. Asymptotic Equivalence,[0],[0]
"Proofs omitted in the main text are supplied in the Appendix.
Theorem 1.",3.1. Asymptotic Equivalence,[0],[0]
"Let Φ be a performance metric that is TP monotonic and p-Lipschitz, and P be a distribution satisfying Assumption 1.",3.1. Asymptotic Equivalence,[0],[0]
Consider the ETU optimal classifier h∗ETU (Definition 2) and,3.1. Asymptotic Equivalence,[0],[0]
the PU optimal classifier h ∗ PU (Definition 1).,3.1. Asymptotic Equivalence,[0],[0]
"Then, for any given and δ, we can choose n large enough (in Definition 2 of ETU), such that, with probability at least 1 − δ over the random choice of the sample of inputs x, we have:∣∣∣Φ(u(h∗ETU(x)),v(h∗ETU(x)), p)
− Φ ( u(h∗PU), v(h ∗ PU), p )∣∣∣ ≤ .",3.1. Asymptotic Equivalence,[0],[0]
"Similarly, for large enough n, with probability 1− δ,∣∣∣Ey|x[Φ(û(h∗ETU(x)), v̂(h∗ETU(x)), p̂)]
−Ey|x [ Φ ( û(h∗PU), v̂(h ∗ PU), p̂ )] ∣∣∣ ≤ .",3.1. Asymptotic Equivalence,[0],[0]
Remark 3.,3.1. Asymptotic Equivalence,[0],[0]
"In essence, Theorem 1 suggests that, for large sample sizes, the optimal in the sense of one approach gives an accurate estimate (or a proxy) of the optimal in the sense of the other approach.",3.1. Asymptotic Equivalence,[0],[0]
Our characterization of p-Lipschitzness is key to showing the equivalence.,3.1. Asymptotic Equivalence,[0],[0]
"The aforementioned result is asymptotic; to elucidate the point, we now give an example where optimal classifiers corresponding to PU and ETU differ.",3.2. Finite Sample Regime,[0],[0]
"It is important to be aware of such extremities, especially when one applies a learned model to test data of modest sample sizes.",3.2. Finite Sample Regime,[0],[0]
"The way we argue a lower bound is by specifying a metric and a distribution, such that on a randomly obtained test set of modest size, say m, the gap in the empirical metric computed on the test data for the two optimal classifiers can be large.",3.2. Finite Sample Regime,[0],[0]
"As one is typically primarily interested in the empirical metric on a given test set, focusing on the empirical metric ensures fairness and forbids favoring either definition.
",3.2. Finite Sample Regime,[0],[0]
Example.,3.2. Finite Sample Regime,[0],[0]
"For some constant α > 0, consider the (adjusted) empirical precision metric defined as:
ΦPrec(û(h(x)), v̂(h(x)), p) = û(h(x))
v̂(h(x))",3.2. Finite Sample Regime,[0],[0]
"+ α .
Note that ΦPrec ∈",3.2. Finite Sample Regime,[0],[0]
"[0, 11+α ]; Furthermore, it is p-Lipschitz, with Lipschitz constant Vp ∝",3.2. Finite Sample Regime,[0],[0]
1α (see Definition 4).,3.2. Finite Sample Regime,[0],[0]
"Thus, choosing very small values of α implies very high Lipschitz constant, and in turn the metric becomes less “stable”.",3.2. Finite Sample Regime,[0],[0]
"To establish the desired lower bound, we choose a small 0 <
α 1.",3.2. Finite Sample Regime,[0],[0]
"Let {X1,X2,X3} denote a partition of the instance space X , i.e. ∪3i=1Xi = X and Xi ∩ Xj = 0, for any pair (i, j).",3.2. Finite Sample Regime,[0],[0]
"Consider the joint distribution P defined as:
P(y = 1|x ∈ X1) = 1 , P(y = 1|x ∈ X3) = 0, P(y = 1|x ∈ X2) = 1− = 1− √ α, (1)
P(X1) + P(X3) = 2 , P(X2) = 1− 2.
for some 1 2 > 0 and note that the distribution is defined to be dependent on our choice of α.",3.2. Finite Sample Regime,[0],[0]
"The last line in the above set of equations suggests that the distribution has a small region where labels are deterministically positive or negative, but overwhelmingly positive elsewhere.",3.2. Finite Sample Regime,[0],[0]
Theorem 2.,3.2. Finite Sample Regime,[0],[0]
"Let x = {x1, x2, . . .",3.2. Finite Sample Regime,[0],[0]
", xn} denote a set of instances drawn i.i.d.",3.2. Finite Sample Regime,[0],[0]
"from the distribution P. Let y = {y1, y2, . . .",3.2. Finite Sample Regime,[0],[0]
", yn} denote their labels drawn from the same distribution.",3.2. Finite Sample Regime,[0],[0]
"With probability at least (1− 2 − n),
ΦPrec(û(h ∗ ETU(x)), v̂(h ∗ ETU(x)), p̂)",3.2. Finite Sample Regime,[0],[0]
"−
ΦPrec(û(h ∗ PU(x)), v̂(h ∗ PU(x)), p̂) ≥
1
n(1 + α) .",3.2. Finite Sample Regime,[0],[0]
Characterization of the optimal classifier as a thresholding of the conditional probability yields simple and efficient PU consistent estimators.,4. Algorithms: Optimization and Conditional Probability Estimation,[0],[0]
"The idea is to first obtain an estimator for the conditional probability using training data, and then search for an optimal threshold on a separate validation set (Narasimhan et al., 2014b; Koyejo et al., 2014b).",4. Algorithms: Optimization and Conditional Probability Estimation,[0],[0]
Threshold search can be efficiently implemented in linear time (assuming probabilities are pre-sorted).,4. Algorithms: Optimization and Conditional Probability Estimation,[0],[0]
"In contrast, although a similar thresholding characterization exists for ETU (Natarajan et al., 2016), evaluation and prediction require the computation of an expensive expectation (Definition 2).",4. Algorithms: Optimization and Conditional Probability Estimation,[0],[0]
"For general metrics, there is an O(n3) procedure to determine the optimal test set labeling (Jansche, 2007; Chai, 2005; Natarajan et al., 2016), and the procedure can be sped up to O(n2) in some special cases (Ye et al., 2012; Natarajan et al., 2016).",4. Algorithms: Optimization and Conditional Probability Estimation,[0],[0]
"Here, we consider an approximation to ETU that requires only O(n) computation, yet achieves error O(n−3/2) compared to exact optimization.",4. Algorithms: Optimization and Conditional Probability Estimation,[0],[0]
"Recall that ETU seeks to find the classifier of the form:
h∗ETU(x) =",4.1. Approximation Algorithms,[0],[0]
"argmax h
Ey|x",4.1. Approximation Algorithms,[0],[0]
"[ Φ(û(h), v̂(h), p̂) ] .
",4.1. Approximation Algorithms,[0],[0]
"Following (Lewis, 1995; Natarajan et al., 2016) we know that when Φ is TP monotonic, it suffices to sort observations in decreasing order according to η(x) and assign positive labels to top k of them, for k = 0, . . .",4.1. Approximation Algorithms,[0],[0]
", n. Unfortunately, for each k, we need to calculate the expected utility
Algorithm 1 Approximate ETU Consistent Classifier 1: Input: Φ and sorted estimates of ηi, i = 1, 2, . . .",4.1. Approximation Algorithms,[0],[0]
", n 2:",4.1. Approximation Algorithms,[0],[0]
"Init s∗i = 0,∀i ∈",4.1. Approximation Algorithms,[0],[0]
"[n], p̂ = 1n",4.1. Approximation Algorithms,[0],[0]
"∑n i=1 yi, û0 = 0
3: Set Φ0 = Φ(0, 0, p̂) 4: for k = 1, 2, . . .",4.1. Approximation Algorithms,[0],[0]
", n",4.1. Approximation Algorithms,[0],[0]
"do 5: Set ûk = (k−1)ûk−1+ηk k , v̂k = k n 6: Set Φk = Φ(ûk, v̂k, p̂) (via Lemmas 2 or 3) 7: end for 8:",4.1. Approximation Algorithms,[0],[0]
"k∗ ← arg maxk=0,...,n Φk. 9: return s∗ s.t. s∗i",4.1. Approximation Algorithms,[0],[0]
← 1 for i ∈,4.1. Approximation Algorithms,[0],[0]
"[k∗].
measure, which is time consuming – requiring O(n2) in general.",4.1. Approximation Algorithms,[0],[0]
"Our goal here is to approximate this term, so that it can be computed in O(n) time, then the whole procedure can be implemented in amortized time O(n).
",4.1. Approximation Algorithms,[0],[0]
"Fix a binary classifier h : X → {0, 1} and the input sample x = (x1, . . .",4.1. Approximation Algorithms,[0],[0]
", xn).",4.1. Approximation Algorithms,[0],[0]
"Let û(h), v̂(h), p̂ denote the empirical quantities, as defined in Section 3.1.",4.1. Approximation Algorithms,[0],[0]
"Furthermore, we define semi-empirical quantities:
ũ(h) = 1
n n∑ i=1 h(xi)η(xi), and p̃ = 1 n n∑ i=1 η(xi)
(there is no need to define ṽ(h)).",4.1. Approximation Algorithms,[0],[0]
Note that ũ(h) = Ey|x,4.1. Approximation Algorithms,[0],[0]
"[ û(h) ] , and p̃ = Ey|x [p̂].
",4.1. Approximation Algorithms,[0],[0]
Zeroth-order approximation.,4.1. Approximation Algorithms,[0],[0]
"Our first approximation is based on Taylor-expanding the measure up to the second order:
Lemma 2.",4.1. Approximation Algorithms,[0],[0]
"If Φ is twice-differentiable in (u, p) and all its second-order derivatives are bounded by constant A, then:∣∣Ey|x [Φ(û(h), v̂(h), p̂)]− Φ(ũ(h), v̂(h), p̃)∣∣ ≤",4.1. Approximation Algorithms,[0],[0]
"A
2n .
",4.1. Approximation Algorithms,[0],[0]
We note that the first order terms vanish in the Taylor approximation (proof in Appendix).,4.1. Approximation Algorithms,[0],[0]
"This constitutes a simple, yet powerful method for approximating ETU utility.",4.1. Approximation Algorithms,[0],[0]
Algorithm 1 outlines the resulting algorithm.,4.1. Approximation Algorithms,[0],[0]
"As shown, the classifier can be computed inO(n) time overall, assuming the data is already sorted according to η(xi) (otherwise, the procedure is dominated by sorting time O(n log n)).",4.1. Approximation Algorithms,[0],[0]
"We note that (Lewis, 1995) proposed a similar first order approximation, albeit without any rigorous guarantee.
",4.1. Approximation Algorithms,[0],[0]
Second order approximation.,4.1. Approximation Algorithms,[0],[0]
"Naturally, we can get a better approximation by Taylor-expanding the measure up to the third order.
",4.1. Approximation Algorithms,[0],[0]
Lemma 3.,4.1. Approximation Algorithms,[0],[0]
Assume,4.1. Approximation Algorithms,[0],[0]
"Φ is three times differentiable in (u, p) and assume all its third-order derivatives are bounded by constant B. Let ∇2uu,∇2up,∇2pp denote the second-order
derivative terms evaluated at (ũ, p̃), and likewise define ∇2up,∇2pp.",4.1. Approximation Algorithms,[0],[0]
We then have:∣∣Ey|x,4.1. Approximation Algorithms,[0],[0]
"[Φ(û(h), v̂(h), p̂)]− Φappr(h)∣∣ ≤",4.1. Approximation Algorithms,[0],[0]
"B
3n3/2 ,
where:
Φappr(h) = Φ(ũ(h), v̂(h), p̃)
+ 1
2 (∇2uu + 2∇2up)su +∇2ppsp,
and
sp := 1
n2 n∑ i=1",4.1. Approximation Algorithms,[0],[0]
"η(xi)(1− η(xi)),
",4.1. Approximation Algorithms,[0],[0]
"su := 1
n2 n∑ i=1 h(xi)η(xi)(1− η(xi)).
",4.1. Approximation Algorithms,[0],[0]
Theorem 3 (Consistency).,4.1. Approximation Algorithms,[0],[0]
Given n instances x =,4.1. Approximation Algorithms,[0],[0]
"(x1, x2, . . .",4.1. Approximation Algorithms,[0],[0]
", xn), sort them in decreasing order of η(xi).",4.1. Approximation Algorithms,[0],[0]
"For 0 ≤ k ≤ n, let s(k) denote the vector with positions corresponding to top k of the sorted instances set to 1, and 0 otherwise.",4.1. Approximation Algorithms,[0],[0]
"(a) Suppose first order derivatives are bounded by A, let:
h∗a = arg max s(k) Φ(ũ(s(k)), v̂(s(k)), p̃),
We have:
Φ(h∗ETU)− Φ(ũ(h∗a), v̂(h∗a), p̃) ≤",4.1. Approximation Algorithms,[0],[0]
"A
2n .
",4.1. Approximation Algorithms,[0],[0]
"(b) Suppose second order derivatives are bounded by B, let:
h∗b = arg max s(k)",4.1. Approximation Algorithms,[0],[0]
"Φappr(s (k)),
where Φappr(h) is defined in Lemma 3.",4.1. Approximation Algorithms,[0],[0]
"We have:
Φ(h∗ETU)− Φappr(h∗b) ≤ 2B
3n3/2 .
",4.1. Approximation Algorithms,[0],[0]
"As before, the approximation can be computed in O(n) total time.",4.1. Approximation Algorithms,[0],[0]
"We could also expand the function up to orders higher than the third order, and get better approximations (still with O(n) computation if the order of the expansion is independent of n) at the cost of an even more complicated approximation formula.",4.1. Approximation Algorithms,[0],[0]
"In experiments, we find that on real datasets with test data sets of size 100 or more, even the zeroth order approximation is highly accurate.",4.1. Approximation Algorithms,[0],[0]
"So far, we assumed that we have access to the true class conditional density η(x) = P(y = 1|x) and the resulting
classifier is a threshold function on η(x).",4.2. Conditional Probability Estimation and Model Misspecification,[0],[0]
"In practice, one employs some probability estimation procedure and gets η̂(x), which we call a",4.2. Conditional Probability Estimation and Model Misspecification,[0],[0]
"model.4 Then, one uses η̂(x) as if it were a true conditional probability η(x) to obtain PU or ETU classifiers.",4.2. Conditional Probability Estimation and Model Misspecification,[0],[0]
"Note that since η(x) is unknown, and we only have access to η̂(x), the best we can hope for is to choose the optimal threshold on η̂(x) (for PU) or choose the optimal number of test set observations k to be classified as positive after sorting them according to η̂(x) (for ETU).",4.2. Conditional Probability Estimation and Model Misspecification,[0],[0]
"Next, we investigate these finite sample effects in practical PU and ETU procedures.",4.2. Conditional Probability Estimation and Model Misspecification,[0],[0]
"For this analysis, we treat η̂(x) as given and fixed, make no other assumptions on how it was obtained.",4.2. Conditional Probability Estimation and Model Misspecification,[0],[0]
"Let Ĥ = {h | h = 1η̂(x)≥τ , τ ∈",4.2. Conditional Probability Estimation and Model Misspecification,[0],[0]
"[0, 1]} denote the class of binary threshold functions on η̂(x).
",4.2. Conditional Probability Estimation and Model Misspecification,[0],[0]
"Consider PU first, and let h∗ be the PU-optimal classifier from Ĥ, i.e.:
h∗",4.2. Conditional Probability Estimation and Model Misspecification,[0],[0]
"= argmax h∈Ĥ Φ(u(h), v(h), p).
",4.2. Conditional Probability Estimation and Model Misspecification,[0],[0]
"In practice, however, one does not have access to P, and thus u(h), v(h), p cannot be computed.",4.2. Conditional Probability Estimation and Model Misspecification,[0],[0]
"Instead, given η̂(x), one uses a validation sample S = {(xi, yi)}ni=1 to choose a threshold on η̂(x) (and thus, a classifier from Ĥ), by directly optimizing the empirical version of the metric on S:
ĥ = argmax h∈Ĥ Φ(û(h), v̂(h), p̂).
",4.2. Conditional Probability Estimation and Model Misspecification,[0],[0]
"We would like to assess how close is ĥ to h∗. By following the proof of Lemma 1 (which never assumes the class H is based on thresholding η(x)), it is easy to show that with high probability,∣∣Φ(u(ĥ), v(ĥ), p)− Φ(u(h∗), v(h∗),",4.2. Conditional Probability Estimation and Model Misspecification,[0],[0]
"p)∣∣ ≤ O( 1√
n
) .
",4.2. Conditional Probability Estimation and Model Misspecification,[0],[0]
"Thus, if we have a sufficiently large validation sample at our disposal, we can set the threshold which maximizes the empirical version of the metric, and our performance is guaranteed to be Õ(1/ √ n)",4.2. Conditional Probability Estimation and Model Misspecification,[0],[0]
close to the performance of the Φ-optimal classifier from Ĥ.,4.2. Conditional Probability Estimation and Model Misspecification,[0],[0]
"In other words, PU does not require to know the true distribution in order to select the best classifier in Ĥ, only a sufficiently large validation sample is required.
",4.2. Conditional Probability Estimation and Model Misspecification,[0],[0]
"In contrast, ETU procedure is inherently based on using η̂(x) as a replacement for η(x) (which we do not know) to decide upon label assignments.",4.2. Conditional Probability Estimation and Model Misspecification,[0],[0]
"Let x = (x1, . . .",4.2. Conditional Probability Estimation and Model Misspecification,[0],[0]
", xn) be the input sample of size n. Assume for simplicity the distribution of η(x) and η̂(x) are continuous on",4.2. Conditional Probability Estimation and Model Misspecification,[0],[0]
"[0, 1], so that for any i 6= j, η(xi) 6= η(xj) with probability one, and
4For instance, η̂(x) could be obtained from logistic regression or neural network with soft-max function on the final layer.
similarly for η̂. Then, given x and η̂, the ETU procedure chooses the classifier of the form:
ĥ = argmax h∈Ĥ
Ey∼η̂(x)",4.2. Conditional Probability Estimation and Model Misspecification,[0],[0]
"[ Φ(û(h), v̂(h), p̂) ] .
",4.2. Conditional Probability Estimation and Model Misspecification,[0],[0]
"Likewise, the optimal ETU classifier in Ĥ is given by:
h∗ = argmax h∈Ĥ
Ey∼η(x) [ Φ(û(h), v̂(h), p̂) ] ,
i.e. by definition, the optimal classifier in the restricted class H involves the expectation with respect to the true η.",4.2. Conditional Probability Estimation and Model Misspecification,[0],[0]
Let us denote ΦETU = Ey∼η(x),4.2. Conditional Probability Estimation and Model Misspecification,[0],[0]
"[ Φ(û(h), v̂(h), p̂) ] , so that h∗ maximizes ΦETU.",4.2. Conditional Probability Estimation and Model Misspecification,[0],[0]
"In the supplementary material, we show that under some mild assumptions on Φ:
Ex [∣∣ΦETU(ĥ)− ΦETU(h∗)∣∣] ≤",4.2. Conditional Probability Estimation and Model Misspecification,[0],[0]
"Õ( 1√
n
)",4.2. Conditional Probability Estimation and Model Misspecification,[0],[0]
+,4.2. Conditional Probability Estimation and Model Misspecification,[0],[0]
"Pp|p− pη̂|
+ sup h∈Ĥ
Up|u(h)− uη̂(h)|,
where pη̂ = E [ η̂(x) ] and uη̂(h) =",4.2. Conditional Probability Estimation and Model Misspecification,[0],[0]
"E [ h(x)η̂(x) ] , are the quantities corresponding to p and u(h), which were calculated by replacing the conditional probability η with its estimate η̂.",4.2. Conditional Probability Estimation and Model Misspecification,[0],[0]
"Thus, while for the PU procedure, the difference between ĥ and h∗ diminishes as n grows, it is not the case of ETU, as there are two bias terms |p − pη̂| and |u(h)−uη̂(h)|which do not depend on n.",4.2. Conditional Probability Estimation and Model Misspecification,[0],[0]
"These terms correspond to using incorrect conditional probability η̂ while selecting the classifier, and are present even if the sample size tends to infinity.",4.2. Conditional Probability Estimation and Model Misspecification,[0],[0]
"Thus, it seems crucial for the success of ETU procedure to have η̂ calibrated with respect to the true distribution.
",4.2. Conditional Probability Estimation and Model Misspecification,[0],[0]
A popular choice for class probability estimation is to use logistic regression.,4.2. Conditional Probability Estimation and Model Misspecification,[0],[0]
"However, if the model is misspecified, which happens often in practice, the aforementioned discussion suggests that the desired ETU solution may not be achieved.",4.2. Conditional Probability Estimation and Model Misspecification,[0],[0]
"Therefore, we need to learn the class probability function more carefully.",4.2. Conditional Probability Estimation and Model Misspecification,[0],[0]
"Here, we consider two variants.
",4.2. Conditional Probability Estimation and Model Misspecification,[0],[0]
The first is to use the Isotron algorithm.,4.2. Conditional Probability Estimation and Model Misspecification,[0],[0]
"In case of the generalized linear model, i.e. P(y|x) = γ(w∗, x) for some unknown link function γ and model w∗, Kalai & Sastry (2009) proposed a simple and elegant algorithm (see Appendix E) that alternatively learns w∗ and the link function γ (approximated by a piecewise linear function).",4.2. Conditional Probability Estimation and Model Misspecification,[0],[0]
"It provably learns the model under certain assumptions on P. The model w∗ and link function γ are learned using training data, and at prediction time, the link function and the scores of training data (i.e., xTi w) are used to calibrate the class probabilities η(x) of test instances.
",4.2. Conditional Probability Estimation and Model Misspecification,[0],[0]
"We also consider using a recalibrated logistic model, i.e., we first estimate the class probabilities via standard logistic regression, and recalibrate the probabilities by running one update of the γ function in Isotron algorithm (which
essentially solves a quadratic problem known as the Pool of Adjacent Violators).",4.2. Conditional Probability Estimation and Model Misspecification,[0],[0]
"At test time, we use the learnt γ and the logistic model to estimate η(x) for test instances.",4.2. Conditional Probability Estimation and Model Misspecification,[0],[0]
"We empirically evaluate the effectiveness and accuracy of ETU approximations introduced in Section 4.1, on synthetic as well as real datasets.",5. Experiments,[0],[0]
"We also show on several benchmark datasets that, by carefully calibrating the conditional probabilities in ETU, we can improve the classification performance.",5. Experiments,[0],[0]
We consider F1 and Jaccard metrics from Table 1.,5.1. Convergence of Approximations,[0],[0]
We sample conditional probabilities ηi for n instances from the uniform distribution.,5.1. Convergence of Approximations,[0],[0]
"The optimal predictions (see Definition 2) are obtained using Algorithm 1 of (Natarajan et al., 2016) (which is equivalent to searching over 2n possible label vectors).",5.1. Convergence of Approximations,[0],[0]
Then we compute the approximate optimal predictions using the first and the second order approximations discussed in Section 4.1.,5.1. Convergence of Approximations,[0],[0]
"For each metric, we measure the deviation between the true and the approximate optimal values with increasing sample size in Figure 1.",5.1. Convergence of Approximations,[0],[0]
We observe linear convergence for the first order approximation and quadratic convergence for the second order approximation.,5.1. Convergence of Approximations,[0],[0]
"This suggests that the bounds in Theorem 3 indeed can be improved for some metrics, if not in general.",5.1. Convergence of Approximations,[0],[0]
"We report results on seven multiclass and multilabel benchmark datasets: (1) LETTERS: 16000 train, 4000 test instances, (2) SCENE: 1137 train, 1093 test (3) YEAST: 1500 train, 917 test (4) WEBPAGE: 6956 train, 27824 test (5) IMAGE: 1300 train, 1010 test (6) BREAST CANCER: 463 train, 220 test instances, (7) SPAMBASE: 3071 train, 1530 test",5.2. Approximations on Real Data,[0],[0]
instances.5,5.2. Approximations on Real Data,[0],[0]
"In case of multiclass datasets, we report results (using one-vs-all classifiers) averaged over classes (as
5See (Koyejo et al., 2014b; Ye et al., 2012) for details.
in Natarajan et al. (2016)).
",5.2. Approximations on Real Data,[0],[0]
"We compare the exact ETU optimal, computed using the algorithm of Natarajan et al. (2016), with the approximations.",5.2. Approximations on Real Data,[0],[0]
The results for F1 and Jaccard metrics are presented in Table 2.,5.2. Approximations on Real Data,[0],[0]
"The results convincingly show that the approximations are highly accurate, and almost always indistinguishable from optimizing true metrics, on real datasets.",5.2. Approximations on Real Data,[0],[0]
"Note that even the first-order approximation (in fact, this is zeroth-order, as the first order term is zero; see Section 4) achieves high accuracy, as the test set sizes are relatively large.",5.2. Approximations on Real Data,[0],[0]
"We now study how class probability estimation (CPE) and model misspecification affects the performances of PU and ETU approaches, on the seven benchmark datasets.",5.3. Model Misspecification,[0],[0]
"We compare four methods: (a) ETU with logistic regression based CPE, (b) ETU with Isotron based CPE (discussed in Section 4.1), (c) ETU with recalibrated logistic regression based CPE (discussed in Section 4.1), and (d) PU using logistic regression based CPE followed by threshold tuning on validation set (Koyejo et al., 2014b).",5.3. Model Misspecification,[0],[0]
"Additional comparisons to structured SVM (Joachims, 2005) and other classifiers are available in previously published work by others (Koyejo et al., 2014b; Natarajan et al., 2016), and are omitted here.
",5.3. Model Misspecification,[0],[0]
The results are presented in Table 3.,5.3. Model Misspecification,[0],[0]
We observe that the logistic model (column 1) is insufficient for many of the datasets.,5.3. Model Misspecification,[0],[0]
The results improve in several cases using the estimated generalized linear model with Isotron (column 2).,5.3. Model Misspecification,[0],[0]
"However, there is a confounding factor that the two algorithms are very different, and noticed improvement may not necessarily be due to better CPE.",5.3. Model Misspecification,[0],[0]
"To isolate this, recalibrated logistic model results are presented in column 3.",5.3. Model Misspecification,[0],[0]
"The results are in general much better than the standard logistic model, which suggests that it is indeed the case of model misspecification in these datasets.",5.3. Model Misspecification,[0],[0]
"Finally, we present the results with PU algorithm in column 4.",5.3. Model Misspecification,[0],[0]
"We find that the results closely match that of the recalibrated logistic model (except in the case of SCENE dataset); thus, correcting for model misspecification helps demonstrate the theorized asymptotic equivalence of PU and ETU approaches in practice.",5.3. Model Misspecification,[0],[0]
We have presented new results which elucidate the relationship between the two notions of consistency for complex binary classification metrics.,6. Conclusions and Future Work,[0],[0]
"Next, we plan to explore surrogates to further improve training efficiency nondecomposable metrics.",6. Conclusions and Future Work,[0],[0]
"We will also extend to more complex prediction problems such as multilabel classification, where a similar dichotomy exists.",6. Conclusions and Future Work,[0],[0]
W. Kotłowski has been supported by the Polish National Science Centre under Grant No. 2013/11/D/ST6/03050.,Acknowledgments,[0],[0]
Statistical learning theory is at an inflection point enabled by recent advances in understanding and optimizing a wide range of metrics.,abstractText,[0],[0]
Of particular interest are non-decomposable metrics such as the F-measure and the Jaccard measure which cannot be represented as a simple average over examples.,abstractText,[0],[0]
"Non-decomposability is the primary source of difficulty in theoretical analysis, and interestingly has led to two distinct settings and notions of consistency.",abstractText,[0],[0]
"In this manuscript we analyze both settings, from statistical and algorithmic points of view, to explore the connections and to highlight differences between them for a wide range of metrics.",abstractText,[0],[0]
"The analysis complements previous results on this topic, clarifies common confusions around both settings, and provides guidance to the theory and practice of binary classification with complex metrics.",abstractText,[0],[0]
Consistency Analysis for Binary Classification Revisited,title,[0],[0]
Competitive analysis of online algorithms has been an area of spirited research with beautiful results over the past two decades.,1. Introduction,[0],[0]
"At its heart, this area is about decision making under uncertainty about the future—the input is revealed in an online manner, and at every point in time the algorithm must make an irrevocable choice.",1. Introduction,[0],[0]
"A standard example is that of caching algorithms—at every time step the algorithm must make a choice about which elements to keep in the cache, and which elements to evict (Fiat et al., 1991).",1. Introduction,[0],[0]
"The generalization of caching to metric spaces is encapsu-
*Equal contribution 1Google, Zurich, Switzerland 2Google, New York, New York, USA.",1. Introduction,[0],[0]
Correspondence to: Silvio Lattanzi <silviol@google.com,1. Introduction,[0],[0]
">, Sergei Vassilvitskii <sergeiv@google.com>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
lated in the k-server problem, which has been the subject of intense study (Bansal et al., 2015; Manasse et al., 1990).
",1. Introduction,[0],[0]
The key metric in online algorithms is the competitive ratio.,1. Introduction,[0],[0]
"It measures the quality of the solution obtained by an online algorithm versus an offline optimum, which has the luxury of seeing the whole input before making any decisions.",1. Introduction,[0],[0]
"In situations where the competitive ratio is relatively small, for example, the list update problem (Sleator & Tarjan, 1985), this is a great measure by which we can compare different algorithms.",1. Introduction,[0],[0]
"However, in some scenarios strong lower bounds on the competitive ratio imply that any algorithm that makes irrevocable choices will necessarily perform poorly when compared to an offline optimum.
",1. Introduction,[0],[0]
Online clustering is one such example.,1. Introduction,[0],[0]
"In this setting points x1, x2, . . .",1. Introduction,[0],[0]
"arrive one at a time, and must be instantly given one of k cluster labels.",1. Introduction,[0],[0]
"As is typical, the goal is to have the highest quality clustering (under some pre-specified objective function, like k-CENTER or k-MEDIAN) at every point in time.",1. Introduction,[0],[0]
"As Liberty et al. (2016) showed, not only do online clustering algorithms have an unbounded competitive ratio, but one must use bi-criteria approximations to have any hope of a constant approximate solution.
",1. Introduction,[0],[0]
Another approach to evade strong lower bounds is to make additional assumptions about the input to the problem.,1. Introduction,[0],[0]
"For example, one may assume that the input comes in a random (or partially random) order.",1. Introduction,[0],[0]
"This assumption has been a fruitful avenue when studying online problems in different contexts, as the classic secretary problem (Ferguson, 1989; Kesselheim et al., 2015; Kleinberg, 2005) or matching (Karp et al., 1990; Mahdian & Yan, 2011).",1. Introduction,[0],[0]
"Another alternative is to assume some additional structure on the distribution that points are coming from (Feldman et al., 2009).",1. Introduction,[0],[0]
"A big downside of both of these assumptions is that they are hard to test and validate in practice, which is why we take a different approach in this work.",1. Introduction,[0],[0]
"While the irrevocability of past choices makes sense from a theoretical standpoint, for some practical problems this requirement is unrealistically draconian.",1.1. Consistency,[0],[0]
"For example, consider a load balancer, which, when faced with requests arriving online, assigns them to different machines.",1.1. Consistency,[0],[0]
"Better cache performance dictates that similar requests should be
assigned to the same machine, thus the load balancer is essentially performing online clustering.",1.1. Consistency,[0],[0]
"However, fundamentally, nothing is preventing the load balancer from reassigning some of the past jobs to other machines.",1.1. Consistency,[0],[0]
"In this situation, a re-clustering—a reassignment of jobs to machines to increase performance—is not an impossible operation.
",1.1. Consistency,[0],[0]
"Another common example of a costly, but not prohibitive recomputation comes from standard applications of unsupervised clustering: feature engineering for large scale machine learned systems.",1.1. Consistency,[0],[0]
"In this setting a feature vector x, is augmented with the id of a cluster it falls in, x′, and the full vector (x, x′) is given as input to the learner.",1.1. Consistency,[0],[0]
This is mainly done to introduce expressiveness and non-linearity to simple systems.,1.1. Consistency,[0],[0]
"In this situation, changing the clustering would entail changing the set of features passed to the learner, and retraining the whole system; thus one certainly does not want to do it at every time step, but it can be done if the gains are worthwhile.
",1.1. Consistency,[0],[0]
"From a theoretical perspective, the ability to correct for past mistakes offers the ability for much better solutions.",1.1. Consistency,[0],[0]
"In particular for clustering problems, it avoids the lower bounds introduced by Liberty et al. (2016).",1.1. Consistency,[0],[0]
"As we will show, the option to recluster dramatically improves the quality of the solution, even if it is taken rarely.",1.1. Consistency,[0],[0]
"More formally, we will introduce a parameter β which controls the number of times the solution changes.",1.1. Consistency,[0],[0]
"Setting β = 0 is equivalent to online algorithms, whereas a large value of β is equivalent to recomputing the answer from scratch at every time step.",1.1. Consistency,[0],[0]
"In this paper we focus on exploring the trade-off between the approximation ratio of clustering algorithms, and the number of times we must recompute the results.
",1.2. Our Contributions,[0],[0]
"We begin by formally defining the notion of (α, β)consistent clustering in Section 3.",1.2. Our Contributions,[0],[0]
"Then we prove a lower bound, showing that any constant competitive algorithm must change its cluster centers at least Ω(k log n) times (Section 3.1).",1.2. Our Contributions,[0],[0]
"Then we show that a known algorithm by Charikar et al. (2004) achieves this bound for the kCENTER problem, and we develop a new algorithm for other clustering objectives, and show that it requires at most O(k2 log4 n) reclusterings, an exponential improvement over the naive solution (Section 5).",1.2. Our Contributions,[0],[0]
"Finally, we show that the proposed algorithms perform well on real world datasets (Section 7).",1.2. Our Contributions,[0],[0]
There are two avenues for related work that we build on in this paper.,1.3. Related Work,[0],[0]
"The first is clustering algorithms, particularly the online clustering variants.",1.3. Related Work,[0],[0]
"In their seminal work Charikar et al. (2004) gave algorithms for the k-CENTER
problem.",1.3. Related Work,[0],[0]
The case of k-MEDIAN and k-MEANS proved more complex.,1.3. Related Work,[0],[0]
"For the former, Meyerson (2001) gave an O(log n) competitive ration for closely related online facility location problem.",1.3. Related Work,[0],[0]
This result was further improved by Fotakis (2008) and Anagnostopoulos et al. (2004).,1.3. Related Work,[0],[0]
The latter was recently studied by Liberty et al. (2016) who gave bicriteria approximations and showed that these are necessary in an online setting.,1.3. Related Work,[0],[0]
"For the soft partition version of the k-clustering problem, an Expectation Maximization algorithm was suggested by Liang & Klein (2009).
",1.3. Related Work,[0],[0]
"The second, closely related area, is that of streaming algorithms.",1.3. Related Work,[0],[0]
"The literature of clustering in the streaming model is very rich, we highlight the most relevant results.",1.3. Related Work,[0],[0]
The first paper to study clustering problem is by Charikar et al. (2004) studying the k-CENTER problem.,1.3. Related Work,[0],[0]
Guha et al. (2000) give the first single pass constant approximation algorithm to the k-MEDIAN variant.,1.3. Related Work,[0],[0]
Subsequently their result has been is improved by Charikar et al. (2003).,1.3. Related Work,[0],[0]
"Finally, the best algorithm for the closely related variant of facility location is due to Czumaj et al. (2013), who gave a (1 + )- approximation for the problem.",1.3. Related Work,[0],[0]
"Let X be a set of n points, and d : X × X → R a distance function.",2. Preliminaries,[0],[0]
"We assume that d is symmetric and that (X, d) form a metric space, that is d(x, x) = 0 for any x ∈ X; d(x, y) = d(y, x) ≥ 0 for any x, y ∈ X; and, for any x, y, z ∈ X , d(x, y) ≤ d(x, z) + d(z, x).",2. Preliminaries,[0],[0]
"Finally, by scaling d, let minx,y d(x, y) = 1 and denote by ∆ the maximum pairwise distance, maxx,y d(x, y).",2. Preliminaries,[0],[0]
"We will assume that ∆ is bounded by a polynomial in n, therefore log ∆ = O(log n).
",2. Preliminaries,[0],[0]
Consider a set of k points,2. Preliminaries,[0],[0]
c,2. Preliminaries,[0],[0]
"= {c1, c2, . . .",2. Preliminaries,[0],[0]
", ck} ⊆ X,which we will refer to as centers.",2. Preliminaries,[0],[0]
"For each ci, let Ci ⊆ X be the set of points in X closer to ci than to any other center c ∈",2. Preliminaries,[0],[0]
"C. 1 Formally, Ci = {x ∈ X | d(x, ci) ≤ minc∈c d(x, c)}.
",2. Preliminaries,[0],[0]
"Given a p > 0, in the rest of the paper we refer to the cost of a point x with to respect to a set of centers as: costp(x, c) = minci d(x, ci)
",2. Preliminaries,[0],[0]
p.,2. Preliminaries,[0],[0]
"And cost of a cluster Ci as: costp(X,Ci) = ∑ x∈Ci d(x, ci)",2. Preliminaries,[0],[0]
"p.
",2. Preliminaries,[0],[0]
Now we are ready to define our problem.,2. Preliminaries,[0],[0]
"For any p > 0 we can define the cost of clustering of pointsX with respect to the centers c ⊆ X as: costp(X, c) = ∑",2. Preliminaries,[0],[0]
"x∈X costp(x, c) =∑k
i=1 ∑",2. Preliminaries,[0],[0]
"x∈Ci d(x, ci) p.
",2. Preliminaries,[0],[0]
"The k-clustering family of problems asks to find the set of centers c that minimize costp for a specific p. When p = 1, cost1(X, c) is precisely the k-MEDIAN clustering
1 For clarity of the exposition we will assume that all of the pairwise distances are unique.",2. Preliminaries,[0],[0]
"The results still hold when ties are broken lexicographically.
objective.",2. Preliminaries,[0],[0]
Setting p = 2 is equivalent to the k-MEDOIDS problem2.,2. Preliminaries,[0],[0]
"Finally, with p =∞, we recover the k-CENTER problem, which asks to minimize the maximum distance of any point to its nearest cluster center.
",2. Preliminaries,[0],[0]
"Observe that although d(·, ·) satisfies the triangle inequality, when raised to p-th power we need to relax the condition.",2. Preliminaries,[0],[0]
"In particular we have that for any x, y, z ∈ X: d(x, y)p ≤ 2p−1(d(x, z)p + d(z, y)p).
",2. Preliminaries,[0],[0]
"When p is clear from the context, we will refer to costp(X, c) as the cost of the clustering and denote it cost(X, c).",2. Preliminaries,[0],[0]
"We will us optp(X) to denote the optimum cost for the metric space (X, d).",2. Preliminaries,[0],[0]
"We will use c∗ = {c∗1, c∗2, . . .",2. Preliminaries,[0],[0]
", c∗k} to denote the optimal solution.
",2. Preliminaries,[0],[0]
"The k clustering problem is NP-hard to solve exactly, thus we consider approximate solutions.",2. Preliminaries,[0],[0]
"We say that a clustering generated from a set of centers c is α-approximate if costp(X, c) ≤ α ·optp(X).",2. Preliminaries,[0],[0]
"The best known approximation factors are 2 for the k-CENTER problem (Gonzalez, 1985), 1 + √
3 + for the k-MEDIAN problem (Li & Svensson, 2016), and 9 + for the k-MEDOIDS problem (Kanungo et al., 2004).",2. Preliminaries,[0],[0]
"As noted in the introduction, in many online clustering applications the choices made by the online algorithm are not irrevocable, but simply expensive to change.",3. Consistency,[0],[0]
"Moreover, by allowing a small number of full recomputations, we can circumvent the stringent lower bounds on competitive ratio for online clustering.
",3. Consistency,[0],[0]
"To this end, our goal in this work is to better understand the trade-off between the approximation ratio of online clustering algorithms, and the number of times the representative centers change.
",3. Consistency,[0],[0]
We focus on a dynamic setting where the points arrive sequentially.,3. Consistency,[0],[0]
"Let xt denote the point that arrives at time t, and denote by Xt the set of points that has arrived from the beginning.",3. Consistency,[0],[0]
"Thus X0 = ∅, and Xi+1",3. Consistency,[0],[0]
"= Xi ∪ {xi+1} = {x1, x2, . . .",3. Consistency,[0],[0]
", xi+1}.
",3. Consistency,[0],[0]
"For any two sets of centers c, c′ let |c−c′| denote the number of elements present in c, but not in c′: |c − c′| = |c \",3. Consistency,[0],[0]
(c ∩ c′)|.,3. Consistency,[0],[0]
"Observe that when c and c′ have the same cardinality, |c− c′| = |c′ − c|.",3. Consistency,[0],[0]
Definition 3.1.,3. Consistency,[0],[0]
"Given a sequence of sets of centers, c0, c1, . . .",3. Consistency,[0],[0]
", ct and a positive monotone non-decreasing function β : Z → R, we say that the sequence is β-consistent if for all T , ∑T t=1 |ct − ct−1| ≤ β(T ).
",3. Consistency,[0],[0]
"In other words, a sequence is β-consistent, if at time T at
2In the Euclidean space if the centers do not need to be part of the input, setting p = 2 recovers the k-MEANS problem.
most β(T ) centers have changed between successive sets.
",3. Consistency,[0],[0]
Definition 3.2.,3. Consistency,[0],[0]
"Given a sequence of points x1, x2, . . .",3. Consistency,[0],[0]
", xT , and a parameter p, a sequence of centers c1, c2, . . .",3. Consistency,[0],[0]
", cT is (α, β)-consistent if: (i) Approximation.",3. Consistency,[0],[0]
"At every time t, the centers ct form an α approximate solution to the optimum solution at that time: costp(Xt, ct) ≤ α · optp(Xt) for all t ≤ T .",3. Consistency,[0],[0]
(ii) Consistency.,3. Consistency,[0],[0]
The sets of centers form a β-consistent sequence.,3. Consistency,[0],[0]
"Before we look for (α, β) consistent algorithms it is useful to understand what values are possible.",3.1. A lower bound,[0],[0]
We show that it is impossible to get a constant approximation and achieve consistency of o(log n) for any of the k clustering problems.,3.1. A lower bound,[0],[0]
"Later, in Section 6 we will give a non-constructive result that shows that there is always a sequence of clusterings that is simultaneously constant-approximate and O(k log2 n) consistent.3
Lemma 3.3.",3.1. A lower bound,[0],[0]
"There exists a sequence of points such that for any constant α > 0, any algorithm that returns an α-approximate solution while processing n points must be Ω(k log n)-consistent.
Proof.",3.1. A lower bound,[0],[0]
"For ease of exposition, assume that p = 1, and consider points lying in (k − 1)-dimensional Euclidean space, Rk−1.",3.1. A lower bound,[0],[0]
"We begin by adding a point x0 at the origin, and points x1, . . .",3.1. A lower bound,[0],[0]
", xk−1 in positions e1, e2, . . .",3.1. A lower bound,[0],[0]
", ek−1, where ej is the standard basis vector that is 1 in the j-th dimension, and 0 everywhere else.
",3.1. A lower bound,[0],[0]
"We then proceed in phases, where in phase 1 ≤",3.1. A lower bound,[0],[0]
i < log n,3.1. A lower bound,[0],[0]
we add points at position (γ)i · ej for each j ∈,3.1. A lower bound,[0],[0]
"[1, k − 1], for some γ > 0 that we will set later.",3.1. A lower bound,[0],[0]
"In phase log n we add the remaining n− (k− 1) log n− 1 points at arbitrary positions within the convex hull of already added points.
",3.1. A lower bound,[0],[0]
Let Pi be the set of points at the end of phase i. Consider any algorithm that returns anα-approximate solution onPi.,3.1. A lower bound,[0],[0]
"Let p1, p2, . . .",3.1. A lower bound,[0],[0]
", pk−1 be the points added to the input during phase",3.1. A lower bound,[0],[0]
"i, pj = γi · ej .",3.1. A lower bound,[0],[0]
"Then Pi = Pi−1 ∪ {p1, . . .",3.1. A lower bound,[0],[0]
", pk−1}.",3.1. A lower bound,[0],[0]
"One feasible solution choses as centers the points added in phase i as well as the origin, C = {p1, p2, . . .",3.1. A lower bound,[0],[0]
", pk−1, 0}.
",3.1. A lower bound,[0],[0]
"For every point in Pi−1 the origin is closer than any of the other centers, therefore the total cost is: opt(Pi) ≤",3.1. A lower bound,[0],[0]
"cost(Pi, C) =",3.1. A lower bound,[0],[0]
(k − 1) ∑i−1,3.1. A lower bound,[0],[0]
z=1 γ z ≤,3.1. A lower bound,[0],[0]
(k − 1)γ i−1 γ−1 .,3.1. A lower bound,[0],[0]
"On the other hand, consider a set of centers c′ that does not include some pj = γiej .",3.1. A lower bound,[0],[0]
"The closest point to pj is at γi−1ej , which is at distance γi−1(γ − 1) away.",3.1. A lower bound,[0],[0]
"There-
3Note that we assume throughout the paper that the maximum distance between any two points, ∆, is polynomial in n. Alternatively we can restate the lower bound in this section as a Ω(k log ∆) upper bound in section 6 as a O(k log2 ∆).
",3.1. A lower bound,[0],[0]
"fore, cost(Pi, c′) ≥ cost({pj}, c′) = γi−1(γ − 1).",3.1. A lower bound,[0],[0]
"If γ ≥ (2 + kα) then we can bound the approximation ratio as: cost(Pi,c
′) opt(Pi)",3.1. A lower bound,[0],[0]
≥ γ i−1(γ−1) (k−1) γi−1γ−1,3.1. A lower bound,[0],[0]
≥,3.1. A lower bound,[0],[0]
"γ i−1(γ−1)2 (k−1)γi ≥ γ−2 k−1 > α
so c′ cannot be an α-approximate solution.",3.1. A lower bound,[0],[0]
Therefore at the end of phase 1 ≤,3.1. A lower bound,[0],[0]
"i < log n, any α-approximate set of centers, must include all points added in phase i.",3.1. A lower bound,[0],[0]
"Thus any sequence of sets of centers must be Ω(k log n)-consistent.
",3.1. A lower bound,[0],[0]
"Note that considering any p > 1 only makes any omission of point pj even more costly, as compared to the optimum solution.
",3.1. A lower bound,[0],[0]
4.,3.1. A lower bound,[0],[0]
"Warm up: k-CENTER Clustering To gain some intuition about consistent clustering, we begin with the k-CENTER objective.",3.1. A lower bound,[0],[0]
"Given a dataset X , the goal is to identify k centers",3.1. A lower bound,[0],[0]
"c = {c1, . . .",3.1. A lower bound,[0],[0]
", ck} that minimize: maxx∈X minc∈c d(x, c).",3.1. A lower bound,[0],[0]
"This problem is known to be NP-hard, but a simple 2-approximation algorithm exists in the batch setting (Gonzalez, 1985).",3.1. A lower bound,[0],[0]
"In the streaming setting, when points arrive one at a time, the DOUBLING algorithm by Charikar et al. (2004) was the first algorithm discovered for this problem.",3.1. A lower bound,[0],[0]
The algorithm maintains an 8-approximation.,3.1. A lower bound,[0],[0]
"Furthermore, it works in O(log ∆) = O(log n) phases and the total consistency cost of each phase is k; thus we get the following lemma.
",3.1. A lower bound,[0],[0]
Lemma 4.1.,3.1. A lower bound,[0],[0]
"The DOUBLING algorithm for the k-CENTER problem is (8, O(k log n))-consistent.",3.1. A lower bound,[0],[0]
"In this section we present our main result, an algorithm that achieves a polylogarithmic consistency factor.",5. Main Algorithm,[0],[0]
"More precisely, we show that for every constant p ≥ 1, it is possible to design an algorithm for the Consistent k-clustering problem under costp that is constant approximate, and O(k2 log4 n)-consistent.
",5. Main Algorithm,[0],[0]
"In the remainder of the section we first present the main ideas behind our algorithm, then prove some useful technical lemmas, and finally present the full algorithm.",5. Main Algorithm,[0],[0]
"Before delving into the details, we highlight the three main building blocks of our algorithm.
",5.1. Main ideas,[0],[0]
"The first is the Meyerson sketch for online facility location (Meyerson, 2001).",5.1. Main ideas,[0],[0]
This sketch has already been used by Charikar et al. (2003) to solve the k-median problem on data streams.,5.1. Main ideas,[0],[0]
"We show that the main ingredients of the sketch continue to work under costp objectives, and use it to generally reduce the number of points under considerations from n to k · poly log n.
One caveat of this sketch is that to use it we need to have access to a good lower bound on the cost of the optimal solution at any point in time.",5.1. Main ideas,[0],[0]
We obtain it by running the Θ(p) approximation algorithm described by Gupta & Tangwongsan (2008) on all available points.,5.1. Main ideas,[0],[0]
"In this way, at any point in time we have a good approximation of the optimum solution.",5.1. Main ideas,[0],[0]
"Then we divide the progress of our algorithm into log n phases based on this lower bound and in each phase we use a different sketch.
",5.1. Main ideas,[0],[0]
"Finally, while the Meyerson sketch maintains O(k log2 n) possible centers, to computer the k-clustering, we have to reduce these points into exactly k final centers.",5.1. Main ideas,[0],[0]
We first show that this is possible and then we prove that we do not need to recluster frequently.,5.1. Main ideas,[0],[0]
"In fact we will do it only when either a new point is added to the Meyerson sketch— O(k log2 n) times—or when the number of points assigned to one of these elements of the Meyerson sketch doubles— O(k log n) events per sketch.
",5.1. Main ideas,[0],[0]
"By putting all of these ingredients together, we show that the number of times we need to fully recluster is at most O(k log3 n) per phase, or that we haveO(k2 log4 n)",5.1. Main ideas,[0],[0]
cluster changes in total.,5.1. Main ideas,[0],[0]
We present the Meyerson sketch and prove some useful properties.,5.2. The Meyerson sketch,[0],[0]
"We assume to have access to a lower bound to the cost of the optimal solution L, such that Lp ≥ βoptp, for some constant 0 ≤ β ≤ 1.",5.2. The Meyerson sketch,[0],[0]
(We will remove the assumption later.),5.2. The Meyerson sketch,[0],[0]
"Then the algorithm works in phases, such that at any time in phase j, L ∈",5.2. The Meyerson sketch,[0],[0]
"[2j−1, 2j).",5.2. The Meyerson sketch,[0],[0]
"So in each phase j we can use the same lower bound Lpj = 2 j−1 and have Lpj ≥ βoptp 2 .
",5.2. The Meyerson sketch,[0],[0]
In each phase j we create 2 log n Meyerson sketches as described in Algorithm 1.,5.2. The Meyerson sketch,[0],[0]
"Then we combine them in a single sketch as described in Algorithm 2.
",5.2. The Meyerson sketch,[0],[0]
"Algorithm 1 Single Meyerson sketch 1: Input: A sequence of points x0, x1, x2, . . .",5.2. The Meyerson sketch,[0],[0]
", xn.",5.2. The Meyerson sketch,[0],[0]
"A finite p. 2: Output: A set S that is a constant bi-criteria approximate
solution for the k-clustering problem.",5.2. The Meyerson sketch,[0],[0]
"3: S ← ∅ 4: Let X be a set of points and let L be such that L ≥ γoptp(X), for some constant γ > 0 5: for x ∈ X do 6: if S == ∅ then 7: S ← {x} 8: else 9: Let δ = d(x, S)p
10: With probability min ( δk(1+logn)",5.2. The Meyerson sketch,[0],[0]
"Lp , 1 ) add x to S
11: Return S
For simplicity we first analyze the property of a single Meyerson sketch.",5.2. The Meyerson sketch,[0],[0]
"In particular we give a bound on both the
number of points selected by a single sketch, as well as the quality of the approximation.",5.2. The Meyerson sketch,[0],[0]
"The Lemma generalizes the results in (Charikar et al., 2003; Meyerson, 2001) to all finite p and follows the general structure their proof so it is deferred to the extended version of the paper.
",5.2. The Meyerson sketch,[0],[0]
Lemma 5.1.,5.2. The Meyerson sketch,[0],[0]
"For a constant γ ∈ (0, 1), with probability at least 12 the set S computed by Algorithm 1 has: (i)
size at most 4k(1 + log n)",5.2. The Meyerson sketch,[0],[0]
"( 22p+1 γp + 1 )
; (ii) costp(S) ≤ 64optp(X).
",5.2. The Meyerson sketch,[0],[0]
From Lemma 5.1 we know that with constant probability a single Meyerson sketch is of size O(k log n) and contains a set of points that give a good solution to our problem.,5.2. The Meyerson sketch,[0],[0]
"Thus, if we construct 2 log n single Meyerson sketches in parallel, at least one of them gives a constant approximation to the optimum at every point in time with probability at least 1 − O(n−1).",5.2. The Meyerson sketch,[0],[0]
"The observation inspired the design of Algorithm 2, whose properties are formalized next.
",5.2. The Meyerson sketch,[0],[0]
Lemma 5.2.,5.2. The Meyerson sketch,[0],[0]
"For a constant γ ∈ (0, 1), with probability 1 − O(n−1) the set M = ∪2 logni=1 Mi computed by Algorithm 2 has: size at most O(k log2 n) and costp(M) ≤ 64optp(X).
",5.2. The Meyerson sketch,[0],[0]
Proof.,5.2. The Meyerson sketch,[0],[0]
"As mentioned above, Lemma 5.1 implies that if we construct 2 log n single Meyerson sketches in parallel, with probability 1 − O(n−1), at least one of them gives a constant approximation to the optimum at every point in time.",5.2. The Meyerson sketch,[0],[0]
Furthermore in total it contains only 4k(1 + log n),5.2. The Meyerson sketch,[0],[0]
"( 22p+1 γp + 1 ) points.
",5.2. The Meyerson sketch,[0],[0]
Now in Algorithm 2 we are almost building 2 log n Meyerson sketches; the only difference is that we stop adding points to a single sketch when it becomes too large.,5.2. The Meyerson sketch,[0],[0]
This modification does not change the probability that there exist at least one single sketch that gives a constant approximation to the optimum at every point in time and has at most 4k(1 + log n),5.2. The Meyerson sketch,[0],[0]
"( 22p+1 γp + 1 ) points.
",5.2. The Meyerson sketch,[0],[0]
Thus with probability 1 − O(n−1) at least one of the sketches constructed in Lemma 5.1 gives a constant approximation to the optimum at every point in time.,5.2. The Meyerson sketch,[0],[0]
Merging other sketches to this sketch does not affect this property.,5.2. The Meyerson sketch,[0],[0]
Furthermore the number of points in each sketch is explicitly bounded by 4k(1 + log n),5.2. The Meyerson sketch,[0],[0]
"( 22p+1 γp + 1 )
so the total number of points in M is bounded by 8k log n(1 + log n)",5.2. The Meyerson sketch,[0],[0]
"( 22p+1 γp + 1 )
Note that in some cases we do not need to recompute all the sketches from scratch but we need only to update them, so we can define a faster update function described in Algorithm 3.
",5.2. The Meyerson sketch,[0],[0]
"Algorithm 2 ComputeMeyerson(Xt, φ) 1: Input: A sequence of points Xt, a lower bound to the opti-
mum φ.",5.2. The Meyerson sketch,[0],[0]
"2: Output: 2 logn independent Meyerson sketches M1, . . .",5.2. The Meyerson sketch,[0],[0]
",M2 logn 3:",5.2. The Meyerson sketch,[0],[0]
"Lp = φ γ
, 4: for i ∈",5.2. The Meyerson sketch,[0],[0]
[2 logn] do: .,5.2. The Meyerson sketch,[0],[0]
Initialize all Meyerson sketches 5: Mi ← x0 6: for x ∈,5.2. The Meyerson sketch,[0],[0]
Xt do: 7: for i ∈,5.2. The Meyerson sketch,[0],[0]
[2 logn] do: .,5.2. The Meyerson sketch,[0],[0]
"If Mi is not too large, analyze x 8: if |Mi| ≤ 4k(1 + logn) ( 22p+1
γp + 1
) then:
9: Let δ = d(x,Mi)p 10: p̂ = min ( δk(1+logn)",5.2. The Meyerson sketch,[0],[0]
"Lp , 1 ) 11: Add x to Mi with probability p̂ 12: Return M1, . . .",5.2. The Meyerson sketch,[0],[0]
",M2 logn
Algorithm 3 UpdateMeyerson(M1, . . .",5.2. The Meyerson sketch,[0],[0]
",Ms, xt, φ) 1: Input: A point xt, a lower bound to the optimum φ and s
independent Meyerson sketches M1, . . .",5.2. The Meyerson sketch,[0],[0]
",Ms. 2: Output: s independent Meyerson sketches M1, . . .",5.2. The Meyerson sketch,[0],[0]
",Ms 3:",5.2. The Meyerson sketch,[0],[0]
"Lp = φ
γ ,
4: for i ∈",5.2. The Meyerson sketch,[0],[0]
[s] do: .,5.2. The Meyerson sketch,[0],[0]
"If Mi is not too large, analyze xt 5: if |Mi| ≤ 4k(1 + logn)
( 22p+1
γp + 1
) then:
6: Let δ = d(xt,Mi)p 7: p̂ = min ( δk(1+logn)",5.2. The Meyerson sketch,[0],[0]
"Lp , 1 ) 8: Add xt to Mi with probability p̂ 9: Return M1, . . .",5.2. The Meyerson sketch,[0],[0]
",Ms
In the rest of the paper we refer to a single Meyerson sketch as Mi and to their union as M .",5.2. The Meyerson sketch,[0],[0]
Our next step is to show that in the Meyerson sketch there exists a subset of k centers that gives an approximately optimal solution.,5.3. From Meyerson to k clusters,[0],[0]
"We follow the approach in Guha et al. (2000) and show that by weighing the points in the Meyerson sketch with the number of original data points assigned to them, and then running a weighted k-clustering algorithm to recluster them into k clusters, we can achieve a constant approximate solution.
",5.3. From Meyerson to k clusters,[0],[0]
Before formalizing this observation we give some additional notation.,5.3. From Meyerson to k clusters,[0],[0]
"In the remainder of the section we denote the weight of a point x in the Meyerson sketch with w(x), the cost of the centers used in Meyerson sketch with costM, and the cost of the aforementioned weighted clustering instance with costL. Finally we refer to the optimal set of centers for the weighted k-clustering instance as c′.
We begin with two technical Lemmas.
",5.3. From Meyerson to k clusters,[0],[0]
Lemma 5.3.,5.3. From Meyerson to k clusters,[0],[0]
"For any constant p ≥ 1, costp(X, c′) ≤ 2p−1 (costM + costL)
Lemma 5.4.",5.3. From Meyerson to k clusters,[0],[0]
"For any constant p ≥ 1, costL ≤
22p−1 ( costM + optp )",5.3. From Meyerson to k clusters,[0],[0]
Note that combining Lemmas 5.3 and 5.4 the following Corollary follows.,5.3. From Meyerson to k clusters,[0],[0]
Corollary 5.5.,5.3. From Meyerson to k clusters,[0],[0]
"For any constant p ≥ 1, costp(c′) ≤ 23p−1 ( costM + optp
)",5.3. From Meyerson to k clusters,[0],[0]
We defer the proofs of lemma 5.3 and lemma 5.4 to the extended version of the paper.,5.3. From Meyerson to k clusters,[0],[0]
"Those proofs are similar in spirit to those in (Bateni et al., 2014; Guha et al., 2000), but are generalized here for all p.
Thanks to Corollary 5.5 we know that by using a Meyerson sketch, M contains a good approximation for our problem.",5.3. From Meyerson to k clusters,[0],[0]
"In the next subsection we show how to use this to obtain a solution for the consistency problem.
",5.3. From Meyerson to k clusters,[0],[0]
"Before doing this we define two algorithms that allow us to construct a weighted clustering instance starting from a Meyerson sketch (Algorithm 4) and to update the weights for a weighted instance (Algorithm 5).
",5.3. From Meyerson to k clusters,[0],[0]
"Algorithm 4CreateWeightedInstance(M1, . .",5.3. From Meyerson to k clusters,[0],[0]
.,5.3. From Meyerson to k clusters,[0],[0]
",Ms, φ,Xt) 1: Input: A sequence of points Xt, a lower bound to the opti-
mum φ and s independent Meyerson sketches M1, . . .",5.3. From Meyerson to k clusters,[0],[0]
",Ms. 2: Output: A weighted k-clustering instance (M,w).",5.3. From Meyerson to k clusters,[0],[0]
3: Let M = ∪iMi 4:,5.3. From Meyerson to k clusters,[0],[0]
Assign points in Xt to the closest point in M 5: Let w(y) to be equal to the number of points assigned to y ∈ M 6:,5.3. From Meyerson to k clusters,[0],[0]
"Return (M,w)
Algorithm 5 UpdateWeights(M,w, x) 1: Input: A point x, the current weights w and the Meyerson
sketch M .",5.3. From Meyerson to k clusters,[0],[0]
"2: Output: A weighted k-clustering instance (M,w).",5.3. From Meyerson to k clusters,[0],[0]
3: Assign x to the closest point in M 4: Let mx be the closest point to x in M 5: w(mx) = w(mx),5.3. From Meyerson to k clusters,[0],[0]
"+ 1 6: Return (M,w)",5.3. From Meyerson to k clusters,[0],[0]
"We are now ready to formally state and prove the correctness of our main algorithm, which we present in Algorithm 6.",5.4. The algorithm,[0],[0]
"The input of our algorithm is a sequence of points x0, x1, x2, . . .",5.4. The algorithm,[0],[0]
", xn. Recall, that we denote the prefix up to t as Xt, and the cost of the solution using centers c as costp(Xt, c).",5.4. The algorithm,[0],[0]
"Finally we assume to have access to a γapproximation algorithm A for the weighted k-clustering problem for any constant p-norm (we can use for example the local search algorithm described by Gupta & Tangwongsan (2008)).
",5.4. The algorithm,[0],[0]
We can now state our main theorem.,5.4. The algorithm,[0],[0]
Theorem 5.6.,5.4. The algorithm,[0],[0]
"For any constant p ≥ 1, with probability 1 − O(n−1), Algorithm 6 returns a sequence of
Algorithm 6",5.4. The algorithm,[0],[0]
"Consistent k-clustering algorithm 1: Input: A sequence of points x0, x1, x2, . . .",5.4. The algorithm,[0],[0]
", xn. 2: Output: A sequence of centers c0, c1, c2, . . .",5.4. The algorithm,[0],[0]
", cn 3: Select the first k points as centers c0 = {x0, x1, x2, . . .",5.4. The algorithm,[0],[0]
", xk} 4: t← 0 5: while costp(c0, Xt) = 0",5.4. The algorithm,[0],[0]
do: 6: ct ← c0; Output ct; t← t+ 1 7: φ← 0 .,5.4. The algorithm,[0],[0]
"Initialize lower bound to the optimum M1, ...,M2 logn ← ComputeMeyerson(X0, φ)
8: c← ∅; s← 2 logn 9: while t ≤ n",5.4. The algorithm,[0],[0]
"do:
10: Run A on Xt to get approximated solution c′ 11: if costp(Xt, c′) ≥",5.4. The algorithm,[0],[0]
2φ then: .,5.4. The algorithm,[0],[0]
New l.b.,5.4. The algorithm,[0],[0]
"for φ 12: φ← costp(Xt, c′), 13: M1, ...,Ms ← ComputeMeyerson(Xt, φ) 14: (M,w)← GetWeightedProb(M1, ...,Ms, φ,Xt) 15: Solve (M,w) using algorithm A 16: Let ct be the set of centers computed by A 17: else: .",5.4. The algorithm,[0],[0]
"Update Meyerson and recluster if needed 18: M1,M2, ..← UpdateMeyerson(M1, ..,Ms, xt, φ) 19: Let M = ∪iMi, 20: if xt ∈M then: .",5.4. The algorithm,[0],[0]
"xt is in Meyerson sketch 21: (M,w)← GetWeightedProb(M1, ...,Ms, φ,Xt) 22:",5.4. The algorithm,[0],[0]
"Solve (M,w) using algorithm A 23: Let ct be the set of centers computed by A 24: else: 25: (M,w)← UpdateWeights(M,w, x) 26: Let mt be the closest point to xt in M 27: if w(mt) is a power of 2 then: 28: .",5.4. The algorithm,[0],[0]
Weight of a point “doubled” 29:,5.4. The algorithm,[0],[0]
"Solve (M,w) using algorithm A 30: Let ct be the set of computed centers 31: else: 32: ct = ct−1 33: Output ct; t← t+ 1
centers c0, c1, c2, . . .",5.4. The algorithm,[0],[0]
", cn such that at any point in time t costp(ct, Xt) ≤ αpoptp(Xt) for a constant α and the total inconsistency factor of the solution is O(k2 log4 n)
",5.4. The algorithm,[0],[0]
Proof.,5.4. The algorithm,[0],[0]
"We start by bounding the inconsistency factor,∑n−1 i=1",5.4. The algorithm,[0],[0]
|ci+1,5.4. The algorithm,[0],[0]
"− ci|.
During the execution of Algorithm 6 the set of centers changes if and only if one of the three following conditions is met: (i) the cost of the clustering on Xt computed byA increases by a factor of 2, (ii) we add a new point to a Meyerson sketch, (iii) a new point is assigned to a point of the Meyerson sketch, mt, and the weight of mt is a power of 2 after this addition.",5.4. The algorithm,[0],[0]
"Note that every time we change the centers, we fully recluster, and so increase the consistency factor by k in the worst case.",5.4. The algorithm,[0],[0]
"Therefore to prove the theorem we need to show that one of these conditions is met at most O(k log4 n) times.
",5.4. The algorithm,[0],[0]
"From our assumptions we know that the spread of the point set is polynomial in n, which implies the same bound on the cost of the optimum solution.",5.4. The algorithm,[0],[0]
"Therefore, the cost of the solution computed by A doubles at most O(log n) times.
",5.4. The algorithm,[0],[0]
"For the same reason we update the lower bounds, φ at most O(log n) times during the execution of our algorithm.",5.4. The algorithm,[0],[0]
This in turn implies that we rebuild the Meyerson sketches from scratch at mostO(log n) times.,5.4. The algorithm,[0],[0]
Given that we runO(log n),5.4. The algorithm,[0],[0]
"Meyerson sketches in parallel, during the execution of the algorithm we use at most O(log2 n)",5.4. The algorithm,[0],[0]
Meyerson sketches.,5.4. The algorithm,[0],[0]
"Furthermore each Meyerson sketch has at most O(k log n) centers, thus in total we can add at most O(k log3 n) points under condition (ii).
",5.4. The algorithm,[0],[0]
"Finally note that while a Meyerson sketch is fixed, the weight of every point in the sketch can only grow.",5.4. The algorithm,[0],[0]
"In addition, the weight is always is bounded by n, and therefore can double at most log n times per sketch point, resulting in O(k log2 n) changes under a fixed Meyerson sketch.",5.4. The algorithm,[0],[0]
Therefore condition (iii) holds at most O(k log4 n) times.,5.4. The algorithm,[0],[0]
"So overall at least one of the conditions is satisfied at most O(k log4 n) times, thus the algorithm is O(k2 log4 n)-consistent.
",5.4. The algorithm,[0],[0]
To finish our proof we need to show that at any point in time our algorithm returns with probability 1−o(n−1) a constant approximation to the optimum.,5.4. The algorithm,[0],[0]
Note that by corollary 5.5 we know that for any constant p ≥ 1 the cost of a solution computed on the Meyerson sketch can be bounded by costp(c ′) ≤ 23p−1 ( costM + optp ) .,5.4. The algorithm,[0],[0]
From Lemma 5.2 we know that the Meyerson sketch guarantees with probability 1− o(n−1) that costM ≤ 16optp(X).,5.4. The algorithm,[0],[0]
So we have the cost of the optimal set of centers in the Meyerson sketch at any point in time is at mostO(αpoptp),5.4. The algorithm,[0],[0]
w.h.p.,5.4. The algorithm,[0],[0]
"for a constant α4.
",5.4. The algorithm,[0],[0]
"While we cannot compute the optimal set of centers in the Meyerson sketch, we can find an O(p) approximation for every constant p by relying on the local search algorithm of Gupta & Tangwongsan (2008).",5.4. The algorithm,[0],[0]
"Therefore, every time we recompute the centers usingA we are sure that we obtain a constant approximation.
",5.4. The algorithm,[0],[0]
"Finally it remains to show that when none of the three conditions are met, and we simply add a point to the solution without recomputing the centers we retain an approximately optimal solution.",5.4. The algorithm,[0],[0]
"By Lemma 5.3 we know that for any constant p ≥ 1, costp(c′) ≤ 2p−1",5.4. The algorithm,[0],[0]
"(costM + costL) .
",5.4. The algorithm,[0],[0]
"Moreover, we can always bound the cost of Meyerson sketch with 16optp(X).
",5.4. The algorithm,[0],[0]
It remains to get a bound on costL. Note that the number of points assigned to any point in M did not double since the previous reclustering.,5.4. The algorithm,[0],[0]
"Therefore, in the weighted reclustering formulation the weight of all points increased by a factor less than 2.",5.4. The algorithm,[0],[0]
"Therefore, costL at this point is bounded by at most twice costL computed when we last reclustered.",5.4. The algorithm,[0],[0]
"Therefore, costp(c′) ≤ 24p−1 ( costM + optp ) and the cur-
4We do not make an attempt to optimize the constant factors.",5.4. The algorithm,[0],[0]
"As we show in the experimental section, in practice the algorithm gives a very good approximation.
rent solution remains approximately optimal.",5.4. The algorithm,[0],[0]
How many times do we need to change the centers to obtain a good k-clustering at any point in time?,6. Optimizing Consistency,[0],[0]
"In Section 5 we presented an algorithm that is O(k2 log4 n)-consistent, while in Subsection 3.1 we showed that at least Ω(k log n) changes are needed (assuming that ∆ is polynomial in n).",6. Optimizing Consistency,[0],[0]
"We give an existential result, we show that for any input sequence there exist a solution that is constant approximate and O(k log2 n)-consistent.",6. Optimizing Consistency,[0],[0]
"In interest of space we deferred the proof of the lemma to the extended version of the paper.
",6. Optimizing Consistency,[0],[0]
Theorem 6.1.,6. Optimizing Consistency,[0],[0]
"For any sequence x0, x1, . . .",6. Optimizing Consistency,[0],[0]
", xn there exists a sequence of solutions c0, c1, . . .",6. Optimizing Consistency,[0],[0]
", cn such that ∀i, costp(Xi, ci) ≤ αoptp(Xi) for some constant α, and the∑ i |ci+1 − ci‖ = O(k log 2 n).",6. Optimizing Consistency,[0],[0]
We demonstrate the efficacy of our algorithm by tracking both the quality of the solution and the number of reclusterings needed to maintain it on a number of diverse datasets.,7. Experiments,[0],[0]
"As we will show, the theoretical guarantees that we prove in the previous section provide a loose bound on the number of reclusterings; in practice the number of times we recompute the solution grows logarithmically with time.
",7. Experiments,[0],[0]
"Data We evaluate our algorithm on three datasets from the UCI Repository (Lichman, 2013) that vary in data size and dimensionality.",7. Experiments,[0],[0]
"(i) SKINTYPE has 245, 057 points lying in 4-dimensions.",7. Experiments,[0],[0]
"(ii) SHUTTLE has 58, 000 points in 9 dimensions.",7. Experiments,[0],[0]
"(iii) COVERTYPE has 581, 012 points in 54 dimensions.",7. Experiments,[0],[0]
"For each of the datasets we try values of k in {10, 50, 100}, and observe that the qualitative results are consistent across datasets and values of k.
Algorithm Modifications In the development of the algorithm we made a number of decisions to obtain high probability results.",7. Experiments,[0],[0]
"The key among them was to run O(log n) copies of the Meyerson sketch, since each sketch succeeds only with constant probability.",7. Experiments,[0],[0]
"We eschew this change in the implementation, and maintain just a single sketch, at the cost of incurring a worse solution quality.
",7. Experiments,[0],[0]
"Metrics and results The goal of this work is to give algorithms that maintain a good clustering, but only recluster judiciously, when necessary.",7. Experiments,[0],[0]
"To that end, we focus on two main metrics: number of reclusterings and solution quality.
",7. Experiments,[0],[0]
Reclustering We plot the number of reclusterings as a function of time for the three different datasets in Figure 1.,7. Experiments,[0],[0]
"Note that the x-axis is on log-scale, and thus a straight line
represents number of reclusterings that grows logarithmically with time.",7. Experiments,[0],[0]
"Qualitatively we make two observations, across all datasets, and values of k.
First, the rate of reclustering (defined as the fraction of time the algorithm recomputes the solution) is approximately logn/n, which tends to 0 as the dataset size grows.",7. Experiments,[0],[0]
"Further, the rate is higher for higher values of k, a fact also suggested by our theoretical analysis.
",7. Experiments,[0],[0]
"Unlike the SHUTTLE and COVERTYPE datasets, the SKINTYPE dataset exhibits a change in behavior, where initially the reclustering rate is relatively high, but then it sharplly drops after about O(2k) steps.",7. Experiments,[0],[0]
This is explained by the fact that the order of the points in this data set is not random.,7. Experiments,[0],[0]
"Therefore initially the algorithm reclusters at a high rate, once all of the parts of the input space are explored, the rate of reclustering slows.",7. Experiments,[0],[0]
"When we run the algorithm on a randomly permuted instance of SKINTYPE, this phase transition in behavior disappears.
",7. Experiments,[0],[0]
"Approximation Ratio We plot the approximation ratio of the solution (as compared to the best obtained by ten runs of k-means++ (Arthur & Vassilvitskii, 2007)) in Figure 2.
",7. Experiments,[0],[0]
"For the SKIN and COVERTYPE datasets, the approximation ratio stays relatively low, largely bounded by 4, after an initial period.",7. Experiments,[0],[0]
"A more careful examination of the plots shows exactly the times when the consistent algorithm allows the solution to degrade, and when it decides to recompute the solution from scratch.",7. Experiments,[0],[0]
"The latter are indicated by sharp drops in the approximation ratio, whereas the former are the relatively flat patterns.
",7. Experiments,[0],[0]
"It is interesting to note that the additional points sometimes worsen the approximation (as indicated by the lines sloping upwards), but sometimes actually improve the approximation.",7. Experiments,[0],[0]
"This is due to the fact that decisions made by the online algorithm balance optimality at that point in time, with the potential location of points arriving in the future.",7. Experiments,[0],[0]
"The latter is most apparent in the k = 100 experiment of the SHUTTLE dataset.
",7. Experiments,[0],[0]
All of the datasets sometimes exhibit large fluctuations in the approximation ratio.,7. Experiments,[0],[0]
"This is an artifact of using a single Myerson sketch, which does not capture the structure of the points with small, but constant probability.",7. Experiments,[0],[0]
We introduced the notion of consistent clustering: a variant of online clustering which balances the need for maintaining an approximately optimal solution with the cost of reclustering.,8. Conclusions and Future Work,[0],[0]
"We proved Ω(klog n) lower bounds, and gave algorithms for all k-clustering variants that come close to achieving this bound.
",8. Conclusions and Future Work,[0],[0]
The notion of quantifying the worst case number of changes necessary to maintain a constant approximate solution in an online setting is interesting to study in contexts other than k-clustering.,8. Conclusions and Future Work,[0],[0]
"For example, one can consider online graph problems, such as online matching and online densest subgraph, or other types of clustering problems, such as hierarchical or correlation clustering.",8. Conclusions and Future Work,[0],[0]
The study of online algorithms and competitive analysis provides a solid foundation for studying the quality of irrevocable decision making when the data arrives in an online manner.,abstractText,[0],[0]
"While in some scenarios the decisions are indeed irrevocable, there are many practical situations when changing a previous decision is not impossible, but simply expensive.",abstractText,[0],[0]
In this work we formalize this notion and introduce the consistent k-clustering problem.,abstractText,[0],[0]
"With points arriving online, the goal is to maintain a constant approximate solution, while minimizing the number of reclusterings necessary.",abstractText,[0],[0]
"We prove a lower bound, showing that Ω(k log n) changes are necessary in the worst case for a wide range of objective functions.",abstractText,[0],[0]
"On the positive side, we give an algorithm that needs onlyO(k log n) changes to maintain a constant competitive solution, an exponential improvement on the naive solution of reclustering at every time step.",abstractText,[0],[0]
"Finally, we show experimentally that our approach performs much better than the theoretical bound, with the number of changes growing approximately as O(log n).",abstractText,[0],[0]
Consistent k-Clustering,title,[0],[0]
"Reinforcement Learning (RL) techniques were successfully applied in fields such as robotics, games, marketing and more (Kober et al., 2013; Al-Rawi et al., 2015; Barrett et al., 2013).",1. Introduction,[0],[0]
We consider the problem of off-policy evaluation (OPE) – assessing the performance of a complex strategy without applying it.,1. Introduction,[0],[0]
An OPE formulation is often considered in domains with limited sampling capability.,1. Introduction,[0],[0]
"For example, marketing and recommender systems (Theocharous and Hallak, 2013; Theocharous et al., 2015) directly relate policies to revenue.",1. Introduction,[0],[0]
"A more extreme example is drug administration, as there are only few patients in
1The Technion, Haifa, Israel.",1. Introduction,[0],[0]
"Correspondence to: Assaf Hallak <ifogph@gmail.com>, Shie Mannor <shie@ee.technion.ac.il>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"the testing population, and sub-optimal policies can have life threatening effects (Hochberg et al., 2016).",1. Introduction,[0],[0]
"OPE can also be useful as a module for policy optimization in a policy improvement scheme (Thomas et al., 2015a).
",1. Introduction,[0],[0]
"In this paper, we consider the OPE problem in an on-line setup where each new sample is immediately used to update our current value estimate of some previously unseen policy.",1. Introduction,[0],[0]
"We propose and analyze a new algorithm called COP-TD(λ,β) for estimating the value of the target policy; COP-TD(λ,β) has the following properties:
1.",1. Introduction,[0],[0]
"Easy to understand and implement on-line.
",1. Introduction,[0],[0]
2.,1. Introduction,[0],[0]
"Allows closing the gap to consistency such that the limit point is the same that would have been obtained by on-policy learning with the target policy.
",1. Introduction,[0],[0]
3.,1. Introduction,[0],[0]
"Empirically comparable to state-of-the art algorithms.
",1. Introduction,[0],[0]
"Our algorithm resembles (Sutton et al., 2015)’s Emphatic TD that was extended by (Hallak et al., 2015) to the general parametric form ETD(λ,β).",1. Introduction,[0],[0]
We clarify the connection between the algorithms and compare them empirically.,1. Introduction,[0],[0]
"Finally, we introduce an additional related heuristic called Log-COP-TD(λ,β) and motivate it.",1. Introduction,[0],[0]
"We consider the standard discounted Markov Decision Process (MDP) formulation (Bertsekas and Tsitsiklis, 1996) with a single long trajectory.",2. Notations and Background,[0],[0]
"Let M = (S,A,P,R, ζ, γ) be an MDP where S is the finite state space and A is the finite action space.",2. Notations and Background,[0],[0]
"The parameter P sets the transition probabilities Pr(s′|s, a) given the previous state s ∈ S and action a ∈ A, where the first state is determined by the distribution ζ.",2. Notations and Background,[0],[0]
"The parameter R sets the reward distribution r(s, a) obtained by taking action a in state s and γ is the discount factor specifying the exponential reduction in reward with time.",2. Notations and Background,[0],[0]
"The process advances as follows:
A state s0 is sampled according to the distribution ζ(s).",2. Notations and Background,[0],[0]
"Then, at each time step t starting from t = 0 the agent draws an action at according to the stochastic behavior policy µ(a|st), a reward rt .",2. Notations and Background,[0],[0]
"= r(st, at) is accumulated by the agent, and the next state st+1 is sampled using the transition probability Pr(s′|st, at).
",2. Notations and Background,[0],[0]
"The expected discounted accumulated reward starting from a specific state and choosing an action by some policy π is called the value function, which is also known to satisfy the Bellman equation in a vector form:
V π(s) =",2. Notations and Background,[0],[0]
"Eπ [ ∞∑ t=0 γtrt ∣∣∣ s0 = s] , TπV .=",2. Notations and Background,[0],[0]
"Rπ + γPπV, where [Rπ]s .",2. Notations and Background,[0],[0]
=,2. Notations and Background,[0],[0]
"Eπ [r(s, π(s))]",2. Notations and Background,[0],[0]
"and [Pπ]s,s′ .",2. Notations and Background,[0],[0]
=,2. Notations and Background,[0],[0]
"Eπ [Pr(s′|s, π(s))] are the policy induced reward vector and transition probability matrix respectively; Tπ is called the Bellman operator.",2. Notations and Background,[0],[0]
The problem of estimating V π(s) from samples is called policy evaluation.,2. Notations and Background,[0],[0]
"If the target policy π is different than the behavior policy µ which generated the samples, the problem is called off-policy evaluation (OPE).",2. Notations and Background,[0],[0]
"The TD(λ) (Sutton, 1988) algorithm is a standard solution to on-line on-policy evaluation: Each time step the temporal difference error updates the current value function estimate, such that eventually the stochastic approximation process will converge to the true value function.",2. Notations and Background,[0],[0]
"The standard form of TD(λ) is given by:
R (n) t,st = n−1∑ i=0 γirt+i",2. Notations and Background,[0],[0]
"+ γ nV̂t(st+n),
Rλt,st =(1− λ) ∞∑ n=0 λnR(n+1)st ,
V̂t+1(st) =V̂t(st) +",2. Notations and Background,[0],[0]
"αt ( Rλt,st − V̂t(st) ) ,
(1)
where αt is the step size.",2. Notations and Background,[0],[0]
"The value R (n) t,st is an estimate of the current state’s V (st), looking forward n steps, and Rλt,st is an exponentially weighted average of all of these estimates going forward till infinity.",2. Notations and Background,[0],[0]
"Notice that Equation 1 does not specify an on-line implementation since R(n)t,st depends on future observations, however there exists a compact on-line implementation using eligibility traces (Bertsekas and Tsitsiklis (1996) for on-line TD(λ), and Sutton et al. (2014), Sutton et al. (2015) for off-policy TD(λ)).",2. Notations and Background,[0],[0]
"The underlying operator of TD(λ) is given by:
Tλπ V = (1− λ) ∞∑ n=0 λn ( n∑ i=0 γiP",2. Notations and Background,[0],[0]
iπRπ + γ n+1Pn+1π V ) =,2. Notations and Background,[0],[0]
(1− λ)(I,2. Notations and Background,[0],[0]
"− λTπ)−1TπV,
and is a γ(1−λ)1−λγ -contraction (Bertsekas, 2012).
",2. Notations and Background,[0],[0]
We denote by dµ(s) the stationary distribution over states induced by taking the policy µ and mark Dµ = diag(dµ).,2. Notations and Background,[0],[0]
"Since we are concerned with the behavior at infinite horizon, we assume ζ(s) = dµ(s).",2. Notations and Background,[0],[0]
"In addition, we assume that the MDP is ergodic for the two specified policies µ,",2. Notations and Background,[0],[0]
"π so ∀s ∈ S : dµ(s) > 0, dπ(s) > 0 and that the OPE problem is proper – π(a|s) >",2. Notations and Background,[0],[0]
"0⇒ µ(a|s) > 0.
",2. Notations and Background,[0],[0]
"When the state space is too large to hold V π(s), a linear function approximation scheme is used: V π(s)",2. Notations and Background,[0],[0]
≈,2. Notations and Background,[0],[0]
"θ>π φ(s), where θ is the optimized weight vector and φ(s) is the feature vector of state s composed of k features.",2. Notations and Background,[0],[0]
"We denote by Πdπ the projection to the subspace spanned by the features with respect to the dπ-weighted norm, and by Φ ∈ RS,k the matrix whose lines consist of the feature vectors for each state and assume its columns are linearly independent.
TD(λ) can be adjusted to find the fixed point of ΠdπT λ π (Sutton and Barto, 1998):
R (n) t,st = n−1∑ i=0 γirt+i",2. Notations and Background,[0],[0]
"+ γ nθ>t φ(st+n),
Rλt,st =(1− λ) ∞∑",2. Notations and Background,[0],[0]
"n=0 λnR(n+1)st ,
θt+1 =θt +",2. Notations and Background,[0],[0]
αt,2. Notations and Background,[0],[0]
"( Rλt,st − θ > t φ(st) ) φ(st).
",2. Notations and Background,[0],[0]
"Finally, we define OPE-related quantities:
ρt .",2. Notations and Background,[0],[0]
"= π(at|st) µ(at|st) , Γnt .",2. Notations and Background,[0],[0]
"= n−1∏ i=0 ρt−1−i, ρd(s) .",2. Notations and Background,[0],[0]
"= dπ(s) dµ(s) ,
we call ρd the covariate shift ratio (as denoted under different settings by (Hachiya et al., 2012)).
",2. Notations and Background,[0],[0]
"We summarize the assumptions used in the proofs:
1.",2. Notations and Background,[0],[0]
"For both policies the induced Markov chain is ergodic.
2.",2. Notations and Background,[0],[0]
"The first state s0 is distributed according to the stationary distribution of the behavior policy dµ(s).
3.",2. Notations and Background,[0],[0]
The problem is proper: π(a|s) >,2. Notations and Background,[0],[0]
"0⇒ µ(a|s) > 0.
4.",2. Notations and Background,[0],[0]
"The feature matrix Φ has full rank k.
Assumption 1 is commonly used for convergence theorems as it verifies the value function is well defined on all states regardless of the initial sampled state.",2. Notations and Background,[0],[0]
Assumption 2 can be relaxed since we are concerned with the long-term properties of the algorithm past its mixing time – we require it for clarity of the proofs.,2. Notations and Background,[0],[0]
Assumption 3 is required so the importance sampling ratios will be well defined.,2. Notations and Background,[0],[0]
Assumption 4 guarantees the optimal θ is unique which greatly simplifies the proofs.,2. Notations and Background,[0],[0]
We can roughly categorize previous OPE algorithms to two main families.,3. Previous Work,[0],[0]
Gradient based methods that perform stochastic gradient descent on error terms they want to minimize.,3. Previous Work,[0],[0]
"These include GTD (Sutton et al., 2009a), GTD-2,
TDC (Sutton et al., 2009b) and HTD (White and White, 2016).",3. Previous Work,[0],[0]
"The main disadvantages of gradient based methods are (A) they usually update an additional error correcting term, which means another time-step parameter needs to be controlled; and (B) they rely on estimating non-trivial terms, an estimate that tends to converge slowly.",3. Previous Work,[0],[0]
The other family uses importance sampling (IS) methods that correct the gains between on-policy and off-policy updates using the IS-ratios ρt’s.,3. Previous Work,[0],[0]
"Among these are full IS (Precup et al., 2001) and ETD(λ,β) (Sutton et al., 2015).",3. Previous Work,[0],[0]
"These methods are characterized by the bias-variance trade-off they resort to – navigating between biased convergent values (or even divergent), and very slow convergence stemming from the high variance of IS correcting factors (the ρt products).",3. Previous Work,[0],[0]
"There are also a few algorithms that fall between the two, for example TO-GTD (van Hasselt et al., 2014) and WISTD(λ) (Mahmood and Sutton, 2015).
",3. Previous Work,[0],[0]
"A comparison of these algorithms in terms of convergence rate, synergy with function approximation and more is available in (White and White, 2016; Geist and Scherrer, 2014).",3. Previous Work,[0],[0]
We focus in this paper on the limit point of the convergence.,3. Previous Work,[0],[0]
"For most of the aforementioned algorithms, the process was shown to converge almost surely to the fixed point of the projected Bellman operator ΠdTπ where d is some stationary distribution (usually dµ), however the d in question was never1 dπ as we would have obtained from running on-policy TD with the target policy (also see (Kolter, 2011) for relevant discussion).",3. Previous Work,[0],[0]
"The algorithm achieving the closest result is ETD(λ,β) which replaced d with f =",3. Previous Work,[0],[0]
( I − βP>π )−1,3. Previous Work,[0],[0]
"dµ, where β trades-off some of the process’ variance with the bias in the limit point.",3. Previous Work,[0],[0]
"Hence, our main contribution is a consistent algorithm which can converge to the same value that would have been obtained by running an on-policy scheme with the same policy.",3. Previous Work,[0],[0]
"Here we provide a motivating example showing that even in simple cases with “close” behavior and target policies, the two induced stationary distributions can differ greatly.",4. Motivation,[0],[0]
"Choosing a specific linear parameterization further emphasizes the difference between applying on-policy TD with the target policy, and applying inconsistent off-policy TD.
",4. Motivation,[0],[0]
"Assume a chain MDP with numbered states 1, 2, ..|S|, where from each state s you can either move left to state s − 1, or right to state s + 1.",4. Motivation,[0],[0]
If you’ve reached the beginning or the end of the chain (states 1 or |S|) then taking a step further does not affect your location.,4. Motivation,[0],[0]
"Assume the behavior policy moves left with probability 0.5 + , while the target policy moves right with probability 0.5+ .",4. Motivation,[0],[0]
"It is easy
1Except full IS, however its variance is too high to be applicable in practice.
",4. Motivation,[0],[0]
to see that the stationary distributions are given by: dµ(s) ∝,4. Motivation,[0],[0]
"(
0.5− 0.5 +
)s , dπ(s) ∝",4. Motivation,[0],[0]
"( 0.5 +
0.5−
)s .
",4. Motivation,[0],[0]
"For instance, if we have a length 100 chain with = 0.01, for the rightmost state we have dµ(|S|) ≈ 8 · 10−4, dπ(|S|) ≈ 0.04.",4. Motivation,[0],[0]
"Let’s set the reward to be 1 for the right half of the chain, so the target policy is better since it spends more time in the right half.",4. Motivation,[0],[0]
"The value of the target policy in the edges of the chain for γ = 0.99 is V π(1) = 0.21, V π(100) = 99.97.
",4. Motivation,[0],[0]
Now what happens if we try to approximate the value function using one constant feature φ(s) ≡ 1?,4. Motivation,[0],[0]
"The fixed point of ΠdµTπ is θ = 11.92, while the fixed point of ΠdπTπ is θ = 88.08 – a substantial difference.",4. Motivation,[0],[0]
"The reason for this difference lies in the emphasis each projection puts on the states: according to Πdµ , the important states are in the left half of the chain – these with low value function, and therefore the value estimation of all states is low.",4. Motivation,[0],[0]
"However, according to Πdπ the important states are concentrated on the right part of the chain since the target policy will visit these more often.",4. Motivation,[0],[0]
"Hence, the estimation error is emphasized on the right part of the chain and the value estimation is higher.",4. Motivation,[0],[0]
"When we wish to estimate the value of the target policy, we want to know what will happen if we deploy it instead of the behavior policy, thus taking the fixed point of ΠdπTπ better represents the off-policy evaluation solution.
5.",4. Motivation,[0],[0]
"COP-TD(λ, β) Most off-policy algorithms multiply the TD summand of TD(λ) with some value that depends on the history and the current state.",4. Motivation,[0],[0]
"For example, full IS-TD by (Precup et al., 2001) examines the ratio between the probabilities of the trajectory under both policies:
Pπ(s0, a0, s1, . . .",4. Motivation,[0],[0]
", st, at) Pµ(s0, a0, s1, . . .",4. Motivation,[0],[0]
", st, at) =",4. Motivation,[0],[0]
t∏ m=0,4. Motivation,[0],[0]
ρm,4. Motivation,[0],[0]
= Γ t tρt.,4. Motivation,[0],[0]
"(2)
In problems with a long horizon, or these that start from the stationary distribution, we suggest using the time-invariant covariate shift ρd multiplied by the current ρt.",4. Motivation,[0],[0]
"The intuition is the following: We would prefer using the probabilities ratio given in Equation 2, but it has very high variance, and after many time steps we might as well look at the stationary distribution ratio instead.",4. Motivation,[0],[0]
"This direction leads us to the following update equations:
θt+1 = θt + αtρd(st)ρt ( rt + θ > t (γφ(st+1)− φ(st)) ) φ(st).
",4. Motivation,[0],[0]
(3) Lemma 1.,4. Motivation,[0],[0]
If the αt satisfy ∑∞ t=0,4. Motivation,[0],[0]
"αt =∞, ∑∞ t=0",4. Motivation,[0],[0]
α 2 t <∞ then the process described by Eq.,4. Motivation,[0],[0]
"(3) converges almost surely to the fixed point of ΠπTπV = V .
",4. Motivation,[0],[0]
"The proof follows the ODE method (Kushner and Yin, 2003) similarly to Tsitsiklis and Van Roy (1997) (see the appendix for more details).
",4. Motivation,[0],[0]
"Since ρd(s) is generally unknown, it is estimated using an additional stochastic approximation process.",4. Motivation,[0],[0]
"In order to do so, we note the following Lemma:
Lemma 2.",4. Motivation,[0],[0]
"Let ρ̂d be an unbiased estimate of ρd, and for every n = 0, 1, . . .",4. Motivation,[0],[0]
", t define Γ̃nt .",4. Motivation,[0],[0]
= ρ̂d(st−n)Γ n t .,4. Motivation,[0],[0]
"Then:
Eµ [ Γ̃nt |st ] = ρd(st).
",4. Motivation,[0],[0]
"For any state st there are t→∞ such quantities {Γ̃nt }tn=0, where we propose to weight them similarly to TD(λ):
Γ̃βt = (1− β) ∞∑ n=0 βnΓ̃n+1t .
",4. Motivation,[0],[0]
"Note that ρd(s), unlike V (s), is restricted to a close set since its dµ-weighted linear combination is equal to 1 and all of its entries are non-negative; We denote this dµweighted simplex by ∆dµ , and let Π∆dµ be the (non-linear) projection to this set with respect to the Euclidean norm (Π∆dµ can be calculated efficiently, (Chen and Ye, 2011)).",4. Motivation,[0],[0]
"Now, we can devise a TD algorithm which estimates ρd and uses it to find θ, which we call COP-TD(0, β) (Consistent Off-Policy TD).
",4. Motivation,[0],[0]
"Algorithm 1 COP-TD(0,β), Input: θ0, ρ̂d,0,
1: Init: F0 = 0, n β 0 = 1, N(s) = 0 2: for t = 1, 2, ... do 3: Observe st, at, rt, st+1 4: Update normalization terms: 5: N(st) = N(st) + 1, ∀s ∈ S : d̂µ(s) =",4. Motivation,[0],[0]
"N(s)t 6: nβt = βn β t + 1 7: Update Γnt ’s weighted average: 8: Ft = ρt−1(βFt−1 + est−1) 9: Update & project by ρd’s TD error:
10: δdt = F>t ρ̂d,t
nβt︸ ︷︷ ︸ →Γ̃βt
−ρ̂d,t(st)
11: ρ̂d,t+1 = Π∆d̂µ",4. Motivation,[0],[0]
"( ρ̂d,t + α d t δ",4. Motivation,[0],[0]
d t est ) 12: Off-policy TD(0): 13: δt = rt,4. Motivation,[0],[0]
"+ θ>t (γφ(st+1)− φ(st)) 14: θt+1 = θt + αtρ̂d,t+1(st)ρtδtφ(st) 15: end for
Similarly to the Bellman operator for TD-learning, we define the underlying COP-operator Y and its β extension:
Y u = D−1µ P > π",4. Motivation,[0],[0]
"Dµu,
Y βu = (1− β)D−1µ P>π (I − βP>π )−1Dµu.
",4. Motivation,[0],[0]
The following Lemma may give some intuition on the convergence of the ρd estimation process: Lemma 3.,4. Motivation,[0],[0]
"Under the ergodicity assumption, denote the eigenvalues of Pπ by 0 ≤ · · · ≤ |ξ2| < ξ1 = 1.",4. Motivation,[0],[0]
"Then Y β is a maxi 6=1
(1−β)|ξi| |1−βξi| < 1-contraction in the L2-norm on the
orthogonal subspace to ρd, and ρd is a fixed point of Y β .
",4. Motivation,[0],[0]
The technical proof is given in the appendix.,4. Motivation,[0],[0]
Theorem 1.,4. Motivation,[0],[0]
"If the step sizes satisfy ∑ t αt = ∑ t α d t =
∞, ∑ t(α 2 t +",4. Motivation,[0],[0]
"(α d t )
",4. Motivation,[0],[0]
"2) < ∞, αt αdt → 0, tαdt → 0, and E [ (βnΓnt ) 2|st ] ≤",4. Motivation,[0],[0]
"C for some constant C and every t and n, then after applying COP-TD(0, β), ρ̂d,t converges to ρd almost surely, and θt converges to the fixed point of ΠπTπV .
",4. Motivation,[0],[0]
"Notice that COP-TD(0, β) given in Alg.",4. Motivation,[0],[0]
1 is infeasible in problems with large state spaces since ρd ∈ R|S|.,4. Motivation,[0],[0]
"Like TD(λ), we can introduce linear function approximation: represent ρd(s) ≈ θ>ρ φρ(s) where θρ is a weight vector and φρ(s) is the off-policy feature vector and adjust the algorithm accordingly.",4. Motivation,[0],[0]
"For ρ̂d to still be contained in the set ∆dµ , we pose the requirement on the feature vectors: φρ(s) ∈",4. Motivation,[0],[0]
"Rk+, and ∑ s dµ(s)θ > ρ φρ(s) = 1 ( noted as
the simplex projection Π∆Eµ[φρ(s)] ) .",4. Motivation,[0],[0]
"In practice, the latter
requirement can be approximated: ∑ s dµ(s)θ > ρ φρ(s)",4. Motivation,[0],[0]
≈ 1 t θ,4. Motivation,[0],[0]
>,4. Motivation,[0],[0]
"ρ ∑ t φρ(st) = 1 resulting in an extension of the previously applied dµ estimation (step 5 in COP-TD(0, β)).",4. Motivation,[0],[0]
"We provide the full details in Algorithm 2, which also incorporates non-zero λ ( similarly to ETD(λ,β) ) .
",4. Motivation,[0],[0]
"Algorithm 2 COP-TD(λ,β) with Function Approximation, Input: θ0, θρ,0
1: Init: F0 = 0, n β 0 = 1, Nφ = 0, e0 = 0 2: for t = 1, 2, ... do 3: Observe st, at, rt, st+1 4: Update normalization terms: 5: nβt = βn β t + 1, Nφ = Nφ + φρ(st), d̂φρ =",4. Motivation,[0],[0]
"Nφ t 6: Update Γnt ’s weighted average: 7: Ft = ρt−1(βFt−1 + φρ(st−1)) 8: Update & project by ρd’s TD error: 9: δdt = θ > ρ,t−1 ( Ft nβt − φρ(st)
) 10: θρ,t+1 = Π∆d̂φρ",4. Motivation,[0],[0]
"( θρ,t + α d t δ",4. Motivation,[0],[0]
d,4. Motivation,[0],[0]
"t φρ(st)
)",4. Motivation,[0],[0]
11:,4. Motivation,[0],[0]
"Off-policy TD(λ): 12: Mt = λ+ (1− λ)θ>ρ,t+1φρ(st) 13:",4. Motivation,[0],[0]
et = ρt (λγet +Mtφ(st+1)),4. Motivation,[0],[0]
"14: δt = rt + θ>t (γφ(st+1)− φ(st)) 15: θt+1 = θt + αtδtet 16: end for
Theorem 2.",4. Motivation,[0],[0]
"If the step sizes satisfy ∑ t αt = ∑ t α d t =
∞, ∑ t(α 2 t +",4. Motivation,[0],[0]
"(α d t )
",4. Motivation,[0],[0]
"2) < ∞, αt αdt → 0, tαdt → 0, and E [ (βnΓnt ) 2|st ] ≤",4. Motivation,[0],[0]
"C for some constant C and every t, n,
then after applying COP-TD(0, β) with function approximation satisfying φρ(s) ∈",4. Motivation,[0],[0]
"Rk+, ρ̂d,t converges to the fixed point of Π∆Eµ[φρ]ΠφρY
β denoted by ρCOPd almost surely, and if θt converges it is to the fixed point of Πdµ◦ρCOPd TπV , where ◦ is a coordinate-wise product of vectors.
",4. Motivation,[0],[0]
The proof is given in the appendix and also follows the ODE method.,4. Motivation,[0],[0]
"Notice that a theorem is only given for λ = 0, convergence results for general λ should follow the work by Yu (2015).
",4. Motivation,[0],[0]
"A possible criticism on COP-TD(0,β) is that it is not actually consistent, since in order to be consistent the original state space has to be small, in which case every off-policy algorithm is consistent as well.",4. Motivation,[0],[0]
"Still, the dependence on another set of features allows to trade-off accuracy with computational power in estimating ρd and subsequently V .",4. Motivation,[0],[0]
"Moreover, smart feature selection may further reduce this gap, and COP-TD(0, β) is still the first algorithm addressing this issue.",4. Motivation,[0],[0]
"We conclude with linking the error in ρd’s estimate with the difference in the resulting θ, which suggests that a well estimated ρd results in consistency: Corollary 1.",4. Motivation,[0],[0]
Let 0,4. Motivation,[0],[0]
< < 1.,4. Motivation,[0],[0]
If (1 − )ρd ≤ ρCOPd ≤ (1 + ),4. Motivation,[0],[0]
"ρd, then the fixed point of COP-TD(0,β) with function approximation θCOP satisfies the following, where ‖ · ‖∞ is the L∞ induced norm:
‖θ∗",4. Motivation,[0],[0]
− θCOP‖∞ ≤ ‖A−1π Φ>‖∞,4. Motivation,[0],[0]
"( Rmax + (1 + γ)‖Φ‖∞‖θCOP‖∞ ) ,
whereAπ = Φ>Dπ(I−γPπ)Φ, and θ∗ sets the fixed point of the operator ΠdπTπV .",4. Motivation,[0],[0]
"Recently, Sutton et al. (2015) had suggested an algorithm for off-policy evaluation called Emphatic TD.","5.1. Relation to ETD(λ, β)",[0],[0]
"Their algorithm was later on extended by Hallak et al. (2015) and renamed ETD(λ, β), which was shown to perform extremely well empirically by White and White (2016).","5.1. Relation to ETD(λ, β)",[0],[0]
"ETD(0, β) can be represented as:
Ft = (1− β) ∞∑ n=0 βnΓnt ,
θt+1 = θt + αtFtρt ( rt + θ >","5.1. Relation to ETD(λ, β)",[0],[0]
t (γφ(st+1)− φ(st)) ) .,"5.1. Relation to ETD(λ, β)",[0],[0]
"(4)
As mentioned before, ETD(λ, β) converges to the fixed point of ΠfTλπ (Yu, 2015), where f = E","5.1. Relation to ETD(λ, β)",[0],[0]
"[Ft|st] = (I − βPπ)
−1dµ.","5.1. Relation to ETD(λ, β)",[0],[0]
"Error bounds can be achieved by showing that the operator ΠfTλπ is a contraction under certain requirements on β and that the variance of Ft is directly related to β as well (Hallak et al., 2015) (and thus affects the convergence rate of the process).
","5.1. Relation to ETD(λ, β)",[0],[0]
"When comparing ETD(λ,β)’s form to COP-TD(λ,β)’s, instead of spending memory and time resources on a
state/feature-dependent Ft, ETD(λ,β) uses a one-variable approximation.","5.1. Relation to ETD(λ, β)",[0],[0]
"The resulting Ft is in fact a one-step estimate of ρd, starting from ρ̂d(s) ≡ 1 (see Equations 9, 4), up to a minor difference: F ETDt = βF","5.1. Relation to ETD(λ, β)",[0],[0]
"COP-TD t + 1 (which following our logic adds bias to the estimate 2).
","5.1. Relation to ETD(λ, β)",[0],[0]
"Unlike ETD(λ, β), COP-TD(λ,β)’s effectiveness depends on the available resources.","5.1. Relation to ETD(λ, β)",[0],[0]
The number of features φρ(s) can be adjusted accordingly to provide the most affordable approximation.,"5.1. Relation to ETD(λ, β)",[0],[0]
"The added cost is fine-tuning another stepsize, though β’s effect is less prominent.","5.1. Relation to ETD(λ, β)",[0],[0]
"We now present a heuristic algorithm which works similarly to COP-TD(λ, β).",6. The Logarithm Approach for Handling Long Products,[0],[0]
"Before presenting the algorithm, we explain the motivation behind it.",6. The Logarithm Approach for Handling Long Products,[0],[0]
Konidaris et al. (2011) suggested a statistical interpretation of TD(λ).,6.1. Statistical Interpretation of TD(λ),[0],[0]
"They show that under several assumptions the TD(λ) estimate Rλst is the maximum likelihood estimator of V (st) given Rnst : (1) Each R n st is an unbiased estimator of V (st); (2) The random variables Rnst are independent and specifically uncorrelated; (3) The random variables Rnst are jointly normally distributed; and (4) The variance of each Rnst is proportional to λ n.
Under Assumptions 1-3 the maximum likelihood estimator of V (s) given its previous estimate can be represented as a linear convex combination of Rnst with weights:
wn =
[ Var ( R (n) st )]−1 ∑∞ m=0",6.1. Statistical Interpretation of TD(λ),[0],[0]
"[ Var ( R (m) st
)]−1 .",6.1. Statistical Interpretation of TD(λ),[0],[0]
"Subsequently, in Konidaris et al. (2011) Assumption 4 was relaxed and instead a closed form approximation of the variance was proposed.",6.1. Statistical Interpretation of TD(λ),[0],[0]
"In a follow-up paper by Thomas et al. (2015b), the second assumption was also removed and the weights were instead given as: wn = 1>cov(Rst )",6.1. Statistical Interpretation of TD(λ),[0],[0]
"en 1>cov(Rst )1
, where the covariance matrix can be estimated from the data, or otherwise learned through some parametric form.
",6.1. Statistical Interpretation of TD(λ),[0],[0]
"While both the approximated variance and learned covariance matrix solutions improve performance on several benchmarks, the first uses a rather crude approximation, and the second solution is both state-dependent and based on noisy estimates of the covariance matrix.",6.1. Statistical Interpretation of TD(λ),[0],[0]
"In addition, there aren’t efficient on-line implementations since all past
2We have conducted several experiments with an altered ETD and indeed obtained better results compared with the original, these experiments are outside the scope of the paper.
",6.1. Statistical Interpretation of TD(λ),[0],[0]
weights should be recalculated to match a new sample.,6.1. Statistical Interpretation of TD(λ),[0],[0]
"Still, the suggested statistical justification is a valuable tool in assessing the similar role of β in ETD(λ, β).",6.1. Statistical Interpretation of TD(λ),[0],[0]
"As was shown by Konidaris et al. (2011), we can use statedependent weights instead of β exponents to obtain better estimates.",6.2. Variance Weighted Γnt,[0],[0]
"The second moments are given explicitly as
follows3: E [ (Γnt ) 2 |st ] = d>µ P̃ n−1est dµ(st) , where [ P̃ ] s,s′
=∑ a∈A π2(a|s) µ(a|s) P (s ′|s, a).
",6.2. Variance Weighted Γnt,[0],[0]
These can be estimated for each state separately.,6.2. Variance Weighted Γnt,[0],[0]
"Notice that the variances increase exponentially depending on the largest eigenvalue of P̃ (as Assumption 4 dictates), but this is merely an asymptotic behavior and may be relevant only when the weights are already negligible.",6.2. Variance Weighted Γnt,[0],[0]
"Hence, implementing this solution on-line should not be a problem with the varying weights, as generally only the first few of these are non-zero.",6.2. Variance Weighted Γnt,[0],[0]
While this solution is impractical in problems with large state spaces parameterizing or approximating these variances (similarly to Thomas et al. (2015b)) could improve performance in specific applications.,6.2. Variance Weighted Γnt,[0],[0]
"Assumption 3 in the previous section is that the sampled estimators (R(n),Γnt ) are normally distributed.","6.3. Log-COP-TD(λ, β)",[0],[0]
"For on policy TD(λ), this assumption might seem not too harsh as the estimators R(n) represent growing sums of random variables.","6.3. Log-COP-TD(λ, β)",[0],[0]
"However, in our case the estimators Γnt are growing products of random variables.","6.3. Log-COP-TD(λ, β)",[0],[0]
"To correct this issue we can define new estimators using a logarithm on each Γ̃nt :
log [ρd(st)]","6.3. Log-COP-TD(λ, β)",[0],[0]
"= log
[ E [ ρ̂d(st−m)
t−1∏ k=t−m
ρk ∣∣ st]]
≈ log [ρ̂d(st−m)]","6.3. Log-COP-TD(λ, β)",[0],[0]
"+ t−1∑
k=t−m
E","6.3. Log-COP-TD(λ, β)",[0],[0]
"[log [ρk] |st] .
(5)
","6.3. Log-COP-TD(λ, β)",[0],[0]
"This approximation is crude – we could add terms reducing the error through Taylor expansion, but these would be complicated to deal with.","6.3. Log-COP-TD(λ, β)",[0],[0]
"Hence, we can relate to this method mainly as a well-motivated heuristic.
","6.3. Log-COP-TD(λ, β)",[0],[0]
"Notice that this formulation resembles the standard MDP formulation, only with the corresponding ”reward” terms log[ρt] going backward instead of forward, and no discount factor.","6.3. Log-COP-TD(λ, β)",[0],[0]
"Unfortunately, without a discount factor we
3The covariances can be expressed analytically as well, for clarity we drop this immediate result.
cannot expect the estimated value to converge, so we propose using an artificial one γlog.","6.3. Log-COP-TD(λ, β)",[0],[0]
We can incorporate function approximation for this formulation as well.,"6.3. Log-COP-TD(λ, β)",[0],[0]
"Unlike COP-TD(λ, β), we can choose the features and weights as we wish with no restriction, besides the linear constraint on the resulting ρd through the weight vector θρ.","6.3. Log-COP-TD(λ, β)",[0],[0]
This can be approximately enforced by normalizing θρ using X t .,"6.3. Log-COP-TD(λ, β)",[0],[0]
= 1t ∑ t exp(θ,"6.3. Log-COP-TD(λ, β)",[0],[0]
>,"6.3. Log-COP-TD(λ, β)",[0],[0]
"ρ,tφ(st))","6.3. Log-COP-TD(λ, β)",[0],[0]
(which should equal 1 if we were exactly correct).,"6.3. Log-COP-TD(λ, β)",[0],[0]
"We call the resulting algorithm LogCOP-TD(λ,β).
","6.3. Log-COP-TD(λ, β)",[0],[0]
"Algorithm 3 Log-COP-TD(λ,β) with Function Approximation, Input: θ0,θρ,0
1: Init: F0 = 0, n0(β) = 1, N(s) = 0 2: for t = 1, 2, ... do 3: Observe st, at, rt, st+1 4: Update normalization terms: 5: nβt = βn β t + 1, Nφ = γlog(βNφ +
φρ(st)), X = X + exp(θ","6.3. Log-COP-TD(λ, β)",[0],[0]
>,"6.3. Log-COP-TD(λ, β)",[0],[0]
"ρ,tφ(st))
","6.3. Log-COP-TD(λ, β)",[0],[0]
6: Update log(Γnt )’s weighted average: 7: Ft = βγlogFt−1 + n,"6.3. Log-COP-TD(λ, β)",[0],[0]
β,"6.3. Log-COP-TD(λ, β)",[0],[0]
"t log[ρ(st−1)] 8: Update & project by log(ρd)’s TD error: 9: δdt =
Ft nβt + θ>ρ,t
( Nφ
nβt − φρ(st) )","6.3. Log-COP-TD(λ, β)",[0],[0]
"10: θρ,t+1 = θρ,t + αdt δ d t φρ(st) 11:","6.3. Log-COP-TD(λ, β)",[0],[0]
"Off-policy TD(λ): 12: Mt = λ+ (1− λ) exp ( θ>ρ,t+1φρ(st) )","6.3. Log-COP-TD(λ, β)",[0],[0]
/(X/t),"6.3. Log-COP-TD(λ, β)",[0],[0]
15: θt+1 = θt + αtδtet 16: end for,14: δt = rt + θ>t (γφ(st+1)− φ(st)),[0],[0]
"An interesting phenomenon occurs when the behavior and target policies employ a feature based Boltzmann distribution for choosing the actions: µ(a|s) = exp ( θ>a,µφ(s) ) ,
and π(a|s) = exp ( θ>a,πφ(s) ) , where a constant feature is added to remove the (possibly different) normalizing constant.",6.4. Using the Original Features,[0],[0]
"Thus, log(ρt) = (θa,π − θa,µ)>φ(st), and LogCOP-TD(λ,β) obtains a parametric form that depends on the original features instead of a different set.",6.4. Using the Original Features,[0],[0]
"As we propose to use linear function approximation for ρd(s) and log (ρd(s)) one cannot help but wonder how hard it is to approximate these quantities, especially compared to the value function.",6.5. Approximation Hardness,[0],[0]
"The comparison between V (s) and ρd(s) is problematic for several reasons:
1.",6.5. Approximation Hardness,[0],[0]
"The ultimate goal is estimating V π(s), approximation errors in ρd(s) are second order terms.
",6.5. Approximation Hardness,[0],[0]
2.,6.5. Approximation Hardness,[0],[0]
"The value function V π(s) depends on the policy-
induced reward function and transition probability matrix, while ρd(s) depends on the stationary distributions induced by both policies.",6.5. Approximation Hardness,[0],[0]
Since each depends on at least one distinct factor - we can expect different setups to result in varied approximation hardness.,6.5. Approximation Hardness,[0],[0]
"For example, if the reward function has a poor approximation then so will V π(s), while extremely different behavior and target policies can cause ρd(s) to behave erratically.
3.",6.5. Approximation Hardness,[0],[0]
"Subsequently, the choice of features for approximating V π(s) and ρd(s) can differ significantly depending on the problem at hand.
",6.5. Approximation Hardness,[0],[0]
"If we would still like to compare V π(s) and ρd(s), we could think of extreme examples:
• When π = µ, ρd(s) ≡ 1, when R(s) ≡ 0",6.5. Approximation Hardness,[0],[0]
"then V π(s) ≡ 0.
",6.5. Approximation Hardness,[0],[0]
• In the chain MDP example in Section 4 we saw that ρd(s) is an exponential function of the location in the chain.,6.5. Approximation Hardness,[0],[0]
Setting reward in one end to 1 will result in an exponential form for V π(s) as well.,6.5. Approximation Hardness,[0],[0]
"Subsequently, in the chain MDP example approximating log (ρd(s)) is easier than ρd(s) as we obtain a linear function of the position; This is not the general case.",6.5. Approximation Hardness,[0],[0]
We have performed 3 types of experiments.,7. Experiments,[0],[0]
"Our first batch of experiments (Figure 1) demonstrates the accuracy of predicting ρd by both COP-TD(λ, β) and Log-COP-TD(λ, β).",7. Experiments,[0],[0]
"We show two types of setups in which visualization of ρd is relatively clear - the chain MDP example mentioned in Section 4 and the mountain car domain (Sutton and Barto, 1998) in which the state is determined by only two continuous variables - the car’s position and speed.",7. Experiments,[0],[0]
"The parameters λ and β exhibited low sensitivity in these tasks so they were simply set to 0, we show the estimated ρd after 106 iterations.",7. Experiments,[0],[0]
"For the chain MDP (top two plots, notice the logarithmic scale) we first approximate ρd without any function approximation (top-left) and we can see COP-TD manages to converge to the correct value while Log-COPTD is much less exact.",7. Experiments,[0],[0]
When we use linear feature space (constant parameter and position),7. Experiments,[0],[0]
Log-COP-TD captures the true behavior of ρd much better as expected.,7. Experiments,[0],[0]
The two lower plots show the error (in color) in ρd estimated for the mountain car with a pure exploration behavior policy vs. a target policy oriented at moving right.,7. Experiments,[0],[0]
The z-axis is the same for both plots and it describes a much more accurate estimate of ρd obtained through simulations.,7. Experiments,[0],[0]
The features used were local state aggregation.,7. Experiments,[0],[0]
"We can see that both algorithms succeed similarly on the position-speed pairs which are sampled often due to the behavior policy and the
mountain.",7. Experiments,[0],[0]
"When looking at more rarely observed states, the estimate becomes worse for both algorithms, though Log-COP-TD seems to be better performing on the spike at position > 0.
",7. Experiments,[0],[0]
"Next we test the sensitivity of COP-TD(λ, β) and LogCOP-TD(λ,β) to the parameters β and γlog (Figure 2) on two distinct toy examples - the chain MDP introduced before but with only 30 states with the position-linear features, and a random MDP with 32 states, 2 actions and a 5-bit binary feature vector along with a free parameter (this compact representation was suggested by White and White (2016) to approximate real world problems).",7. Experiments,[0],[0]
"The policies on the chain MDP were taken as described before, and on the random MDP a state independent 0.75/0.25 probability to choose an action by the behavior/target policy.",7. Experiments,[0],[0]
"As we can see, larger values of β cause noisier estimations in the random MDP for COP-TD(λ, β), but has little effect in other venues.",7. Experiments,[0],[0]
"As for γlog - we can see that if it is too large or too small the error behaves sub-optimally, as expected for the crude approximation of Equation 5.",7. Experiments,[0],[0]
"In conclusion, unlike ETD(λ, β), Log/COP-TD(λ, β) are much less effected by β, though γlog should be tuned to improve results.
",7. Experiments,[0],[0]
"Our final experiment (Figure 3) compares our algorithms to ETD(λ, β) and GTD(λ, β) over 4 setups: chain MDP with 100 states with right half rewards 1 with linear features, a 2 action random MDP with 256 states and binary features, acrobot (3 actions) and cart-pole balancing (21 actions) (Sutton and Barto, 1998) with reset at success and state aggregation to 100 states.",7. Experiments,[0],[0]
"In all problems we used the same features for ρd and V π(s) estimation, γ = 0.99, constant step size 0.05 for the TD process and results were averaged over 10 trajectories, other parameters (λ, β, other step sizes, γlog) were swiped over to find the best ones.",7. Experiments,[0],[0]
"To
reduce figure clutter we have not included standard deviations though the noisy averages still reflect the variance in the process.",7. Experiments,[0],[0]
"Our method of comparison on the first 2 setups estimates the value function using the suggested algorithm, and finds the dπ weighted average of the error between V and the on-policy fixed point ΠπTVπ:
‖V̂ −ΠπTVπ‖2dπ = ∑ s dπ(s) [ (θ∗ − θ̂)>φ(s) ]2 ,
where θ∗ is the optimal θ obtained by on-policy TD using the target policy.",7. Experiments,[0],[0]
"On the latter continuous state problems we applied on-line TD on a different trajectory following the target policy, used the resulting θ value as ground truth and taken the sum of squared errors with respect to it.",7. Experiments,[0],[0]
The behavior and target policies for the chain MDP and random MDP are as specified before.,7. Experiments,[0],[0]
"For the acrobot problem the behavior policy is uniform over the 3 actions and the target policy chooses between these with probabilities ( 16 , 1 3 , 1 2 ).",7. Experiments,[0],[0]
"For the cart-pole the action space is divided to 21 actions from -1 to 1 equally, the behavior policy chooses among these uniformly while the target policy is 1.5 times more prone to choosing a positive action than a negative one.
",7. Experiments,[0],[0]
"The experiments show that COP-TD(λ, β) and Log-COPTD(λ, β) have comparable performance to ETD(λ, β) where at least one is better in every setup.",7. Experiments,[0],[0]
The advantage in the new algorithms is especially seen in the chain MDP corresponding to a large discrepancy between the stationary distribution of the behavior and target policy.,7. Experiments,[0],[0]
"GTD(λ) is consistently worse on the tested setups, this might be due to the large difference between the chosen behavior and target policies which affects GTD(λ) the most.",7. Experiments,[0],[0]
Research on off-policy evaluation has flourished in the last decade.,8. Conclusion,[0],[0]
"While a plethora of algorithms were suggested so far, ETD(λ, β) by Hallak et al. (2015) has perhaps the simplest formulation and theoretical properties.",8. Conclusion,[0],[0]
"Unfortunately, ETD(λ, β) does not converge to the same point achieved by on-line TD when linear function approximation is applied.
",8. Conclusion,[0],[0]
"We address this issue with COP-TD(λ,β) and proved it can achieve consistency when used with a correct set of features, or at least allow trading-off some of the bias by adding or removing features.",8. Conclusion,[0],[0]
"Despite requiring a new set of features and calibrating an additional update function, COP-TD(λ,β)’s performance does not depend as much on β as ETD(λ,β), and shows promising empirical results.
",8. Conclusion,[0],[0]
We offer a connection to the statistical interpretation of TD(λ) that motivates our entire formulation.,8. Conclusion,[0],[0]
This interpretation leads to two additional approaches: (a) weight the Γnt using estimated variances instead of β exponents and (b) approximating log[ρd] instead of ρd; both approaches deserve consideration when facing a real application.,8. Conclusion,[0],[0]
This Research was supported in part by the Israel Science Foundation (grant No. 920/12) and by the European Research Council under the European Union’s Seventh Framework Programme (FP/2007-2013)/ ERC Grant Agreement n.306638.,9. Acknowledgments,[0],[0]
The problem of on-line off-policy evaluation (OPE) has been actively studied in the last decade due to its importance both as a stand-alone problem and as a module in a policy improvement scheme.,abstractText,[0],[0]
"However, most Temporal Difference (TD) based solutions ignore the discrepancy between the stationary distribution of the behavior and target policies and its effect on the convergence limit when function approximation is applied.",abstractText,[0],[0]
"In this paper we propose the Consistent Off-Policy Temporal Difference (COP-TD(λ, β)) algorithm that addresses this issue and reduces this bias at some computational expense.",abstractText,[0],[0]
"We show that COP-TD(λ, β) can be designed to converge to the same value that would have been obtained by using on-policy TD(λ) with the target policy.",abstractText,[0],[0]
"Subsequently, the proposed scheme leads to a related and promising heuristic we call logCOP-TD(λ, β).",abstractText,[0],[0]
Both algorithms have favorable empirical results to the current state of the art online OPE algorithms.,abstractText,[0],[0]
"Finally, our formulation sheds some new light on the recently proposed Emphatic TD learning.",abstractText,[0],[0]
Consistent On-Line Off-Policy Evaluation,title,[0],[0]
"Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 1115–1124 Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics",text,[0],[0]
"When annotators are asked for objective judgments about a text (e.g., POS tags), the broader context in which the text is situated is often irrelevant.",1 Introduction,[0],[0]
"However, many NLP tasks focus on inference of factors beyond words and syntax.",1 Introduction,[0],[0]
"For example, the present work addresses the task of detecting political stance on Twitter.",1 Introduction,[0],[0]
"We ask an-
notators to determine whether a given Twitter user supports Donald Trump or Hillary Clinton.",1 Introduction,[0],[0]
"However, inferring something about a user from a single tweet that she writes may prove difficult.",1 Introduction,[0],[0]
"Prior work on stance has relied on annotations collected this way (Mohammad et al., 2016b), but individual tweets do not always contain clear indicators.
",1 Introduction,[0],[0]
One solution to this issue is to supply the annotator with more information about the user.,1 Introduction,[0],[0]
"For example, for the similar task of classifying a Twitter user’s political affiliation, Cohen and Ruths (2013) display the user’s last 10 tweets.",1 Introduction,[0],[0]
"Nguyen et al. (2013), studying gender and age, ask annotators to label users by leveraging all information available in their profile.",1 Introduction,[0],[0]
"Thus, researchers have provided a range of contexts (or more broadly, information conditions) to annotators in an attempt to balance annotators’ exposure to the data needed for accuracy with reasonable costs in terms of time, money and cognitive load.
",1 Introduction,[0],[0]
"However, while scholars routinely make such decisions about what information to show annotators, they rarely examine how such decisions actually impact annotations.",1 Introduction,[0],[0]
"The first contribution of this paper (Section 3) is to show that, at least for political stance detection on Twitter, displaying different kinds of context to annotators yields significantly different annotations for the same user.",1 Introduction,[0],[0]
"As a result of these discrepancies, the accuracy of models trained on these annotations varies widely.
",1 Introduction,[0],[0]
"While it is possible one could select a “best” context for a given task, our results suggest that doing so a priori is difficult and that, moreover, different contexts provide complementary information.",1 Introduction,[0],[0]
"What we would prefer, instead, is a model that learns how contexts affect annotators and combines annotations from multiple contexts to create gold standard labels.
",1 Introduction,[0],[0]
"Fortunately, prior work suggests mechanisms for such a model.",1 Introduction,[0],[0]
"Typically in annotation tasks,
1115
each item is judged by several annotators, and the resulting labels are aggregated, usually by majority vote, to create a gold standard.",1 Introduction,[0],[0]
"As an alternative to majority vote, Raykar et al. (2010) develop an elegant probabilistic approach for learning to aggregate labels produced by annotators of varying quality.",1 Introduction,[0],[0]
"Their model jointly estimates gold standard labels (in the form of probability scores), infers annotator error rates, and learns a classifier for use on out-of-sample data.
",1 Introduction,[0],[0]
"Our second contribution (Section 4) is an extension of Raykar et al.’s model to handle labels not only created by annotators of varying quality, but also produced under information conditions of varying quality.",1 Introduction,[0],[0]
We call this model ConStance1.,1 Introduction,[0],[0]
"Like Raykar et al. (2010), who find that even lowquality annotators are useful, we find that lowquality contexts can be useful.",1 Introduction,[0],[0]
"Specifically, we find that the classifier produced from our model performs better than any classifier trained by majority vote from the same labels.",1 Introduction,[0],[0]
"Furthermore, the model provides an unsupervised method for comparing the information conditions by examining their respective error patterns.
",1 Introduction,[0],[0]
"Intuitively, ConStance performs a role analogous to boosting for annotations: for an arbitrary task, it permits collection of labels that capture different aspects of the instances at hand, then combines them automatically to determine which are more reliable and to produce a classifier that takes all this into account.",1 Introduction,[0],[0]
"Stance detection is defined as the task of determining whether an individual is in favor of, against, or neutral towards a target concept based on the content they have generated (Mohammad et al., 2016b).",2.1 Political Stance Detection,[0],[0]
"It is related to but distinct from sentiment analysis: a given document can have negative sentiment but a positive stance towards a particular target, or vice versa.",2.1 Political Stance Detection,[0],[0]
"Further, for stance detection, the target need not be explicitly mentioned.",2.1 Political Stance Detection,[0],[0]
"These points are best illustrated via example: the tweet “I hope that the Democrats get destroyed in this election!” has a negative sentiment (towards Democrats), and (therefore, most likely) implies a
1 Replication materials for this work, including code for ConStance, are available at https://github.com/ kennyjoseph/constance.",2.1 Political Stance Detection,[0],[0]
"The paper’s Supplementary Material can also be accessed there.
positive stance towards Donald Trump.",2.1 Political Stance Detection,[0],[0]
"As a case study for how context impacts annotations, we focus on political stance detection on Twitter—specifically, determining stance towards Hillary Clinton and Donald Trump during the 2016 U.S. election season.",2.1 Political Stance Detection,[0],[0]
"This task illustrates the challenges of annotation, since individual tweets are often ambiguous with respect to stance, contexts on Twitter are inherently fractured, and differing contexts can make annotators lean in different directions.
",2.1 Political Stance Detection,[0],[0]
"Note that a user’s stance, as we use the term in this paper, is a latent (and stable) property of the user.",2.1 Political Stance Detection,[0],[0]
"However, short of interviewing the user, we can never be completely certain of her stance.",2.1 Political Stance Detection,[0],[0]
"As such, the examples here and evaluations later rely on the authors’ best estimates of stance, using all available information.
",2.1 Political Stance Detection,[0],[0]
"A user’s tweets, in turn, may or may not reveal her stance.",2.1 Political Stance Detection,[0],[0]
"This means that, by our definitions, an annotator might accurately perceive no stance in a tweet, yet have their annotation be considered incorrect with respect to the user’s true stance.",2.1 Political Stance Detection,[0],[0]
"We would consider this case an annotator error caused by lack of context.
",2.1 Political Stance Detection,[0],[0]
"As examples of the task, consider annotating the following three tweets: (i) “crooked Hillary - #lockHerUp,” (ii) “Lester thinks he can control the crowd when he can’t even keep Trump on topic lmao,” and (iii) “Settling in for #debatenight Hoping to hear an adult conversation.”",2.1 Political Stance Detection,[0],[0]
"In the case of (i), a passing familiarity with American politics gives us high confidence that the author is pro-Trump.",2.1 Political Stance Detection,[0],[0]
"The tweets in (ii) and (iii) are more ambiguous, but the authors’ stances become clearer with access to varying forms of context.",2.1 Political Stance Detection,[0],[0]
"For (ii), a Pepe the frog image (a symbol used by the American alt-right movement) in the user profile reveals that the user is probably a Trump supporter.",2.1 Political Stance Detection,[0],[0]
"Similarly, for (iii), a profile description that reads “Stereotypical Iowan who enjoys Hillary Clinton, progressive politics.",2.1 Political Stance Detection,[0],[0]
Chair of CYDIWomen.,2.1 Political Stance Detection,[0],[0]
Previously @HillaryForIA and @NARAL.”,2.1 Political Stance Detection,[0],[0]
"suggests support for Clinton and distaste for Trump.
",2.1 Political Stance Detection,[0],[0]
"In order to explore the effects on annotation quality of providing these kinds of context to annotators, we crowd-source annotations for a set of tweets and vary the additional information provided to annotators.",2.1 Political Stance Detection,[0],[0]
"For ease of comparison with related work and within our own study, we associate each user with a single anchor tweet.",2.1 Political Stance Detection,[0],[0]
"Thus, both annotators and classifiers are asked to deter-
mine the stance of a user using data from one particular time window.",2.1 Political Stance Detection,[0],[0]
"We collected tweets during the general election season (7/29/2016–11/7/2016) from over 40,000 Twitter users we had previously matched to voter registration records.",2.2 Data,[0],[0]
"Matching Twitter users to voter registrations (using methods similar to Barberá, 2016; Hobbs et al., 2017) helps ensure that the accounts we study are controlled by humans, and it supplies additional demographic variables: gender, race and party registered with.
",2.2 Data,[0],[0]
"We identified as a political tweet any tweet that mentioned the official handle for Donald Trump (@realDonaldTrump) or Hillary Clinton (@HillaryClinton), or that contained one or more of the following terms or hashtags: Hillary, Clinton, Trump, Donald, #maga, #imwithher, #debatenight, #election2016, #electionnight.",2.2 Data,[0],[0]
"We removed all reply tweets, quote tweets and tweets that directly retweeted the candidates.",2.2 Data,[0],[0]
"Finally, we kept only those users who posted at least three political tweets.
",2.2 Data,[0],[0]
"From these users, we sampled 562 political tweets for crowd-sourced stance annotation, selecting at most one tweet per user.",2.2 Data,[0],[0]
These tweets were all sampled from users who were registered Democrats or Republicans.,2.2 Data,[0],[0]
"Half the tweets were paired with Hillary Clinton as the target, the other half with Donald Trump.",2.2 Data,[0],[0]
"We also sampled and set aside an additional 250 + 318 tweet/target pairs to use as development and validation data, respectively (see Section 2.5).",2.2 Data,[0],[0]
We used Amazon Mechanical Turk (AMT) for annotation.,2.3 Annotation Task,[0],[0]
"Annotators were presented a triplet of {tweet, target, context} and were asked to make their decisions on a 5-point Likert scale, ranging from “Definitely Opposes [target]” to “Definitely Supports [target]”.",2.3 Annotation Task,[0],[0]
"Both prior work (Mohammad et al., 2016b) and our pilot studies suggested confusion between options for a tweet’s irrelevance towards a target and the tweet’s neutrality towards the target, so we used the center of the scale for both options.",2.3 Annotation Task,[0],[0]
"For this paper, we use a narrower three-point scale formed by merging the “Definitely” and “Probably” options.
",2.3 Annotation Task,[0],[0]
"Further, while tweets were annotated with respect to different targets, we combine all annotations into a single task by assuming that “anti-
Trump” means “pro-Clinton”, and vice-versa.",2.3 Annotation Task,[0],[0]
"This assumption seems reasonable given that the voting population was strongly polarized during the general (post-primary) election season, and it doubles the amount of data we can use to train the models.",2.3 Annotation Task,[0],[0]
"Thus, throughout this work the labels we use are taken from the set {“Support Trump / Oppose Clinton” = −1, “Neutral / I don’t know” = 0, “Oppose Trump / Support Clinton” = 1}.",2.3 Annotation Task,[0],[0]
Each of the 562 “anchor” tweets was annotated under six different contexts (also referred to as information conditions) described in Table 1.,2.4 Contexts Studied,[0],[0]
(The Supplementary Material provides visual examples of each.),2.4 Contexts Studied,[0],[0]
We collected at least three annotations for each tweet/condition pair.,2.4 Contexts Studied,[0],[0]
"Every AMT worker was shown 40 different tweets, one by one, randomly distributed across contexts.",2.4 Contexts Studied,[0],[0]
"Two additional artificial tweets were used to control for task competency.
",2.4 Contexts Studied,[0],[0]
We selected the conditions in Table 1 based on two factors.,2.4 Contexts Studied,[0],[0]
"First, we included conditions that varied in how much we expected them to impact annotations.",2.4 Contexts Studied,[0],[0]
"For example, we expected the partial profile information to have a relatively small effect, and political party a larger one.",2.4 Contexts Studied,[0],[0]
"Second, we restricted our options to sets of information that we believed would minimally impact task completion times.",2.4 Contexts Studied,[0],[0]
"We confirmed this empirically by regressing the (logged) time to completion for each annotator on the number of tweets she saw for each context, finding no significant effects from any context.",2.4 Contexts Studied,[0],[0]
"Ideally, we would evaluate annotation quality and downstream performance by comparing to ground truth.",2.5 Gold Standard Labels,[0],[0]
"Unfortunately, ground truth is difficult to
characterize for tasks as subjective as stance detection or sentiment analysis (Passonneau and Carpenter, 2014; DiMaggio, 2015).",2.5 Gold Standard Labels,[0],[0]
"In light of this, we constructed our own labels, using all available information about users, and we use them as an approximation of ground truth.
",2.5 Gold Standard Labels,[0],[0]
"We constructed these labels in order to evaluate downstream classification performance, and they cover a set of users not shown to the AMT workers.",2.5 Gold Standard Labels,[0],[0]
"Given our resource constraints and the numerous (at least 18), often conflicting labels already available for tweets shown to AMT workers, we did not create definitive labels for that set.
",2.5 Gold Standard Labels,[0],[0]
"To create these “gold standard” (GS) labels, we considered all information found on the user’s Twitter timeline, including everything AMT annotators could see, plus friend/following relationships, all of their previous tweets, demographics from the voter file, etc.",2.5 Gold Standard Labels,[0],[0]
"Anecdotally, we found certain cases time-consuming to investigate, which argues for continuing to limit how much information we ask annotators to consider.",2.5 Gold Standard Labels,[0],[0]
"All gold standard labels were agreed upon by at least two authors, who first labeled the data independently and then came together to discuss disagreements.
",2.5 Gold Standard Labels,[0],[0]
Our GS set consists of 318 users (with their associated anchor tweets).,2.5 Gold Standard Labels,[0],[0]
Each user is assigned a label from the tertiary Trump/Neutral/Clinton scale.,2.5 Gold Standard Labels,[0],[0]
Another 250 manually labeled accounts were used for model development but are not part of reported results.,2.5 Gold Standard Labels,[0],[0]
"The GS is approximately equally divided among registered Democrats, registered Republicans, and people not registered with either party; the last category includes selfdeclared Independents and voters not affiliated with any party.",2.5 Gold Standard Labels,[0],[0]
We include this third set in order to ensure the models generalize beyond registered Democrats and Republicans.,2.5 Gold Standard Labels,[0],[0]
"In this section, we examine how annotator agreement varies depending on the context in which the labels were obtained, and how classifiers trained on majority-vote labels from each individual context, as well as on labels from all contexts combined, perform on the GS.",3 Annotation Quality For Individual Contexts,[0],[0]
"First, we introduce the classifier and features used for the latter task, then discuss results for agreement and classifier performance.",3 Annotation Quality For Individual Contexts,[0],[0]
"For each of the six contexts separately, we construct labels with which to train a classifier.","3.1 Classifier, Labels, Features, & Evaluation",[0],[0]
"Training labels are constructed using majority vote; we also tried weighting the training instances to match the distribution of labels, but it did not perform as well.","3.1 Classifier, Labels, Features, & Evaluation",[0],[0]
We also construct a seventh set of labels using all annotations from all conditions.,"3.1 Classifier, Labels, Features, & Evaluation",[0],[0]
We then train a classifier on each set of labels.,"3.1 Classifier, Labels, Features, & Evaluation",[0],[0]
"We use Random Forest models, as they outperformed regularized logistic regression and SVMs with linear kernels on the development set.","3.1 Classifier, Labels, Features, & Evaluation",[0],[0]
"Note that the only difference among the models in this section is the labels they are trained on.
","3.1 Classifier, Labels, Features, & Evaluation",[0],[0]
"The feature set used, shown in Table 2, is meant as a straightforward representation of the information seen by annotators; parts of it follow Ebrahimi et al. (2016).","3.1 Classifier, Labels, Features, & Evaluation",[0],[0]
"We construct three types of features for each tweet: text, sentiment and user features.","3.1 Classifier, Labels, Features, & Evaluation",[0],[0]
"For text features, we collapse the anchor tweet plus all additional textual context seen by any annotator into a single string, then compute various n-grams from it.","3.1 Classifier, Labels, Features, & Evaluation",[0],[0]
"For sentiment, we compute various scores from the anchor tweet alone.","3.1 Classifier, Labels, Features, & Evaluation",[0],[0]
"For user features, we include the user’s race and gender, which annotators might have learned from the user’s profile picture.","3.1 Classifier, Labels, Features, & Evaluation",[0],[0]
"Note that because we want models to generalize beyond registered Democrats or Republicans, we do not include a feature for political party.
","3.1 Classifier, Labels, Features, & Evaluation",[0],[0]
"Classifier performance on the GS is measured, following prior work (Mohammad et al., 2016a; Ebrahimi et al., 2016), on the average of the F1 scores on the two classes of interest (“Clinton” and “Trump”).","3.1 Classifier, Labels, Features, & Evaluation",[0],[0]
"Additionally, we report the average log-loss (the negative log-likelihood, according to the classifier, of the true label).","3.1 Classifier, Labels, Features, & Evaluation",[0],[0]
"Log-loss and F1 can be seen as complementary measures: whereas F1 evaluates the quality of the ranking of test instances, log-loss evaluates the quality of their individual probability estimates.","3.1 Classifier, Labels, Features, & Evaluation",[0],[0]
"To compute the probability estimate from a Random Forest, we compute mean class probabilities across all trees.
","3.1 Classifier, Labels, Features, & Evaluation",[0],[0]
"To assess the statistical significance of differences between two models, we first obtain probability estimates for all GS items.","3.1 Classifier, Labels, Features, & Evaluation",[0],[0]
"For log-loss, we use a Mann-Whitney test on the scores from the two models being compared.","3.1 Classifier, Labels, Features, & Evaluation",[0],[0]
"For F1, we create 1000 bootstrap iterations of the sample, compute the average F1 of each, and run a non-parametric difference-in-means test, using 95% confidence
intervals.","3.1 Classifier, Labels, Features, & Evaluation",[0],[0]
"Before evaluating classification results, we consider annotator agreement within each context, calculated like Mohammad et al. (2016b) as the average, across tweets, of the percentage of annotations that match the majority vote.",3.2 Effects of the Contexts,[0],[0]
"As shown in Table 3, annotators shown No Context achieve an agreement score of 0.84, similar to the 0.8185 reported by Mohammad et al. (2016b).",3.2 Effects of the Contexts,[0],[0]
"Relative to this baseline, some contexts increase agreement more than others.",3.2 Effects of the Contexts,[0],[0]
"As one might expect, Previous Political Tweets and Political Party show the strongest signals.",3.2 Effects of the Contexts,[0],[0]
"Their effects are statistically (p < .01, Mann-Whitney test) and practically significant, increasing the number of labels having full agreement by 15% and 10%, respectively.
",3.2 Effects of the Contexts,[0],[0]
"However, annotators shown different contexts did not necessarily converge to the same labels.",3.2 Effects of the Contexts,[0],[0]
Notice the low agreement for the All Combined condition: the majority labels held stronger majorities within any individual context than across all of them.,3.2 Effects of the Contexts,[0],[0]
"In fact, if we look at the six majority vote labels for each tweet, only in 43% of the tweets are these labels in full agreement.",3.2 Effects of the Contexts,[0],[0]
"At the end of Section 5, we return to the question of why agreement was so low across conditions, with the help of parameters estimated by ConStance.
",3.2 Effects of the Contexts,[0],[0]
"In the classification task, the results in Table 3 further suggest that Previous Political Tweets
serves as the strongest single context.",3.2 Effects of the Contexts,[0],[0]
"There is a good case to be made for choosing this individual context, which is statistically significantly better than many others.",3.2 Effects of the Contexts,[0],[0]
"For example, providing annotators with Previous Political Tweets provides a statistically significant increase in both average F1 scores and log-loss (with p < .01) over both the No Context and Full Profile conditions.",3.2 Effects of the Contexts,[0],[0]
"Perhaps most noteworthy is that the All Combined classifier, created from the naive combination of all annotations, is no better than the classifiers from the individual conditions.
",3.2 Effects of the Contexts,[0],[0]
"To summarize, results suggest that providing annotators with appropriate additional context can improve annotation quality, as measured via annotator agreement and downstream classification performance.",3.2 Effects of the Contexts,[0],[0]
"However, it was not obvious in advance which context would be most helpful, and performing such an analysis as this requires the time-intensive construction of better “gold standard” labels against which to check the labels already being outsourced to annotators.",3.2 Effects of the Contexts,[0],[0]
"In addition, the heterogeneity of the labels produced in different contexts suggests that the contexts provide diverse signals we might be able to leverage; however, simply combining all the annotations does not result in improvements.",3.2 Effects of the Contexts,[0],[0]
The prior section thus suggests that it may be better to limit a priori decisions and instead to leverage multiple kinds of context during annotation.,4 ConStance: General Unified Model,[0],[0]
Like Raykar et al.,4 ConStance: General Unified Model,[0],[0]
"(2010) assumes for annotators, we might expect (and indeed find) that even those contexts that turn out to be worse on some metrics still might be useful for other purposes.",4 ConStance: General Unified Model,[0],[0]
"Here, we present a model for such an approach.
",4 ConStance: General Unified Model,[0],[0]
ConStance learns a classifier for items.,4 ConStance: General Unified Model,[0],[0]
"For our purposes here, an item is a user together with their anchor tweet and the additional information from which features were derived (see Table 2); more broadly, it is whatever we choose to put into the feature vector.",4 ConStance: General Unified Model,[0],[0]
"One could choose a differ-
ent setup; for example, an item could be a user and ten anchor tweets.",4 ConStance: General Unified Model,[0],[0]
"However, the current arrangement allows for straightforward comparison to prior stance work on Twitter (Mohammad et al., 2016a).
",4 ConStance: General Unified Model,[0],[0]
"Note that in general, the features need not be restricted to those annotators could have seen.",4 ConStance: General Unified Model,[0],[0]
"Rather, they could include anything useful to a classifier.",4 ConStance: General Unified Model,[0],[0]
Note also that the feature set provided to ConStance is the same used by the baseline models; only the models themselves differ.,4 ConStance: General Unified Model,[0],[0]
The model we develop is shown in Figure 1.,4.1 Overview,[0],[0]
There are N items to be labeled.,4.1 Overview,[0],[0]
Each item can be viewed in up toC different contexts.,4.1 Overview,[0],[0]
"Finally, there are A total annotators labeling the items; each annotator sees multiple items.",4.1 Overview,[0],[0]
"Each item can have a different number of annotations, produced by any assignment of annotators and information conditions to items.",4.1 Overview,[0],[0]
"In our dataset, every item is labeled
in 6 conditions (every |Ci| = 6), and within every context, every item is labeled by at least 3 annotators (every |Aci | ≥ 3).
",4.1 Overview,[0],[0]
The model’s generative story works as follows.,4.1 Overview,[0],[0]
Item i has feature vector Xi and a “true” label Yi ∈ V .,4.1 Overview,[0],[0]
"The relationship between Xi and Yi can be described by some model M, which we will ultimately learn.",4.1 Overview,[0],[0]
"When the item is viewed with context c, the item’s true label Yi is transformed by noise into a “context-specific” label Sci ∈ V .",4.1 Overview,[0],[0]
"In other words, the true label may appear differently when seen through the lens of each context.",4.1 Overview,[0],[0]
"The variable Sci represents what an ideal annotator would say about item i given only as much information as is preserved by context c.
The “noise” introduced by context c is described by parameter γc.",4.1 Overview,[0],[0]
The parameter γc is a V × V matrix of transition probabilities from true labels to context-specific labels.,4.1 Overview,[0],[0]
"These probabilities depend only on Yi and γc, not on the item’s features Xi.
",4.1 Overview,[0],[0]
"Importantly, annotators themselves are also imperfect.",4.1 Overview,[0],[0]
"When annotator a sees item i, she may also distort the label she sees, Sci , into the observed annotation Rcai ∈ V .",4.1 Overview,[0],[0]
"The annotator-specific noise process is described by parameter αa, another V × V transition matrix.
",4.1 Overview,[0],[0]
"For a better understanding of the role of γc (and by anology, αa), consider the depictions in Figure 2.",4.1 Overview,[0],[0]
The matrix on the top left refers to the No Context condition.,4.1 Overview,[0],[0]
"Its top row describes what an annotator with perfect judgment would think about a user whose true label is Trump [supporter], with no context.",4.1 Overview,[0],[0]
"The top left cell, with a value around 0.65, is the probability the annotator would think Trump; the lighter middle cell, with a value around 0.35, is the probability she would think Neutral/Don’t know; and the probability she would think Clinton is almost 0.",4.1 Overview,[0],[0]
"Like Raykar et al. (2010), we perform inference using Expectation Maximization (EM).",4.2 Learning,[0],[0]
"A full derivation is provided in the Supplementary Material; here, we sketch the main steps.
",4.2 Learning,[0],[0]
"The model’s incomplete data likelihood function, Eq. (1), describes the joint probability, across all items, of Yi, all values of Sci , and all values of Rcai assuming Xi is known and fixed.",4.2 Learning,[0],[0]
"Uppercase denotes random variables; lowercase, specific values.",4.2 Learning,[0],[0]
"In line (2), we substitute in the equivalent
model parameters.
p(D|θ,X) = N∏
i=1 V∑",4.2 Learning,[0],[0]
"y p(Yi = y|xi,M) Ci∏ c
V∑ s p(Sci = s|y, γ) Aci∏ a p(rcai |s, α) (1) = N∏
i=1 V∑",4.2 Learning,[0],[0]
y My(xi),4.2 Learning,[0],[0]
"Ci∏ c V∑ s γcys Aci∏ a αasr
(2)
",4.2 Learning,[0],[0]
The EM derivation is difficult because both Yi and Si are unobserved.,4.2 Learning,[0],[0]
"Our solution is to treat the latent variables as a block, describing their joint configuration with a single term Ti = (Yi, Si).",4.2 Learning,[0],[0]
"In our data, since |Ci| = 6, Ti can take on 7|V | possible values, a number small enough to enumerate over when we need to marginalize out Ti.
",4.2 Learning,[0],[0]
"We define membership indicator variables Ti(ys) ∈ {0, 1} such that Ti(ys)",4.2 Learning,[0],[0]
"= 1 if Ti has the specific values (y, s).",4.2 Learning,[0],[0]
"During learning, we use analogous variables τi(ys) ∈",4.2 Learning,[0],[0]
"[0, 1] to represent the posterior probabilities of each configuration: τi(ys)",4.2 Learning,[0],[0]
"= p(Ti(ys) = 1 | D, θ).",4.2 Learning,[0],[0]
"The expected value of the complete data log-likelihood is: EZ [`(D, Z|θ,X)]",4.2 Learning,[0],[0]
"= N∑
i=1 V∑ y  V∑ s1i . . .",4.2 Learning,[0],[0]
V∑ s Ci i  τi(ys)(log p(Ti(ys),4.2 Learning,[0],[0]
"| xi,M, γ) +
Ci∑ c",4.2 Learning,[0],[0]
"Aci∑ a logαasr)
(3)
",4.2 Learning,[0],[0]
"For the E step, we update the membership estimates τi(ys) using the current parameters θ.",4.2 Learning,[0],[0]
"With Bayes’ rule, each item’s new value of τi(ys) is shown to be the full joint likelihood of item",4.2 Learning,[0],[0]
i (see Eq. (2)),4.2 Learning,[0],[0]
"when setting Yi = y and Si = s, divided by the sum, over all possible settings of Yi and Si, of that same joint likelihood.
",4.2 Learning,[0],[0]
"For the M step, we update the model parameters using the current membership estimates.",4.2 Learning,[0],[0]
"To update the classifier M, following the guidance of Raykar et al. (2010), we retrain the classifier using the current estimates of Yi as weights for items.",4.2 Learning,[0],[0]
"The estimates of Yi can be obtained from τiys by marginalizing out Si, thus EZ [Yi = y] =∑V
s1i . . .",4.2 Learning,[0],[0]
∑V s Ci i τiys.,4.2 Learning,[0],[0]
"We then use sampling to construct a discrete set of labels for model training based on these weights.
To update γ and α, we maximize them with respect to Eq.",4.2 Learning,[0],[0]
(3).,4.2 Learning,[0],[0]
"For γ, the entry γcys (i.e., row y, column s of matrix γc) denotes p(Sci = s | Yi = y).",4.2 Learning,[0],[0]
Each matrix entry can be updated individually by taking the partial derivative of Eq.,4.2 Learning,[0],[0]
"(3) and using, as a Lagrange multiplier term, the constraint that the row must sum to 1.",4.2 Learning,[0],[0]
"The updated value for γcys turns out to be a fraction in which the numerator is the weighted (by τ ) number of items having Yi = y and Sci = s, and the denominator is the weighted number of items having Yi = y (and any value for Sci ).",4.2 Learning,[0],[0]
"For α, a similar derivation yields the following update to αasr: the weighted number of labels by annotator a, in any context, having Sci = s and R ca i = r, divided by the weighted number of labels by annotator a, in any context, having Sci = s.",4.2 Learning,[0],[0]
The top portion of Table 5 displays ConStance’s performance compared to the best results from Section 3.,5 Model Results and Discussion,[0],[0]
"Using the same experimental setup as Section 3—the model type and features, M and X respectively, are the same as in the baselines— ConStance improves over the best baseline models for each metric.",5 Model Results and Discussion,[0],[0]
This improvement is statistically significant for both metrics (at the p < .05 level for log-loss).,5 Model Results and Discussion,[0],[0]
"Further, the model converges rapidly, within 5-7 iterations of the EM algorithm and 3-5 minutes on a single machine.2
In addition to comparing to the baselines provided in Section 3, we investigate which information the model is leveraging to be successful.",5 Model Results and Discussion,[0],[0]
We do so by exploring three ablations of the model.,5 Model Results and Discussion,[0],[0]
"Variation #1 (“Only Political Tweets” in Table 5)
",5 Model Results and Discussion,[0],[0]
"2As above, a development set is used for coarse hyperparameter tuning; see the Supplementary Material for details.
uses the full model, but only gives it the annotations from the Political Tweets condition.",5 Model Results and Discussion,[0],[0]
"This tests whether simply modeling differences in annotators’ error rates, as Raykar et al. (2010) do, with a single (“best”) context is helpful.",5 Model Results and Discussion,[0],[0]
"We find that it is: the performance of this variation is significantly better on both metrics than the Political Tweets baseline from Table 3.
",5 Model Results and Discussion,[0],[0]
"In the second and third variations, we check whether the effectiveness of ConStance stems from modeling differences between annotators rather than differences in contexts, or vice versa.",5 Model Results and Discussion,[0],[0]
"Variation #2 (“Context Labels Masked”), like #1, models only annotator effects; however, it instead uses the entire set of annotations, treating them as if from a single context (i.e., “masking” context information from the model).",5 Model Results and Discussion,[0],[0]
"Variation #3 (“Annotator Labels Masked”) is the complement of Variation #2: it models differences in contexts, and it uses the entire set of annotations, treating them as if from a single annotator.
",5 Model Results and Discussion,[0],[0]
The results of the model ablation experiments are three-fold.,5 Model Results and Discussion,[0],[0]
"First, we see that each piece of the model on its own is effective in moving beyond baseline approaches that use only one context or naively combine labels across contexts and annotators (the “All Combined” baseline).",5 Model Results and Discussion,[0],[0]
All model variations achieve significantly higher Avg.,5 Model Results and Discussion,[0],[0]
"F1 than the baselines, and Variations #1 and #2 improve on log-loss.",5 Model Results and Discussion,[0],[0]
"Second, we see that modeling annotators alone is clearly better than not: not only does Variation #1 outperform the Political Tweets baseline (significantly), but also Variation #2 outperforms the All Combined baseline (significantly) and ConStance outperforms Variation #3 (with significance in one measure).",5 Model Results and Discussion,[0],[0]
"Finally, the best results come from using the full model.",5 Model Results and Discussion,[0],[0]
"Even if the differences between ConStance and the variations are not all statistically significant, modeling both annotators and contexts appears to be the most complete and effective approach.
",5 Model Results and Discussion,[0],[0]
"In addition to model performance, we can also examine what ConStance has learned about the quality of labels from each context.",5 Model Results and Discussion,[0],[0]
"Recall that the model produces a parameter matrix for each context, γc, which describes how a context distorts the “true” labels the model assumes.",5 Model Results and Discussion,[0],[0]
"Each γc is a transition matrix, so a context that perfectly preserves true labels would show up as the identity matrix; off-diagonal entries show error patterns.
",5 Model Results and Discussion,[0],[0]
"Figure 2 visualizes parameter estimates for γ.
",5 Model Results and Discussion,[0],[0]
"Previous Tweets Political Tweets Political Party
No Context Partial Profile Full Profile
Trump Neutral Clinton",5 Model Results and Discussion,[0],[0]
Trump Neutral Clinton,5 Model Results and Discussion,[0],[0]
"Trump Neutral Clinton
Clinton
Neutral
Trump
Clinton
Neutral
Trump
Context−Specific Label of Tweet
O ve
ra",5 Model Results and Discussion,[0],[0]
"ll
La be
l o f T
w ee
t
0.25
0.50
0.75
Value
Figure 2:",5 Model Results and Discussion,[0],[0]
Parameter matrices γc learned by ConStance for each context.,5 Model Results and Discussion,[0],[0]
"Darker shading indicates higher values.
",5 Model Results and Discussion,[0],[0]
"We see that in the No Context, Partial Profile and Full Profile conditions, annotators often selected the “Neutral” option (x-axis) when the model inferred the true label was “Clinton” or “Trump” (yaxis).",5 Model Results and Discussion,[0],[0]
"This finding is in line with intuitions; annotators who saw these conditions simply lacked enough information to determine any label.
",5 Model Results and Discussion,[0],[0]
"On the other extreme, in the Political Party context, annotators selected “Trump” or “Clinton” too often when the model settled on the “Neutral” option.",5 Model Results and Discussion,[0],[0]
"That is, even when a user’s stance was not clear to annotators in other conditions, annotators who saw political party still inferred stance from the text.",5 Model Results and Discussion,[0],[0]
"Here, one could argue annotators were shown “too much” or “too strong” a context—they saw stance even where the content produced by the user did not suggest one.",5 Model Results and Discussion,[0],[0]
"Indeed, further manual inspection of 90 tweets on which annotations disagreed across contexts implies that annotators who saw political affiliation were often wrong because they focused too little on text content relative to the provided political affiliations.
",5 Model Results and Discussion,[0],[0]
"In presenting these findings, a key point to highlight is that unlike the results of Section 3, Figure 2 was produced without access to any full information labels, which depend on a significant level of manual effort beyond annotations gathered on AMT.",5 Model Results and Discussion,[0],[0]
"Recent work has shown that cognitive biases such as stereotypes (Carpenter et al., 2016) and anchoring (Berzak et al., 2016) can negatively impact text annotation and resulting models, even for objective tasks like POS tagging (Blodgett et al., 2016).",6 Related Work,[0],[0]
"Still, researchers often decide what context to show annotators without rigorously evalu-
ating how their decisions will affect annotations, on tasks from gender identification to political leanings (Chen et al., 2015; Nguyen et al., 2014; Burger et al., 2011; Cohen and Ruths, 2013).",6 Related Work,[0],[0]
"Our work suggests an interesting avenue of development towards reducing annotation bias by explicitly modeling it and reducing the need for a priori decisions on which context is best for which particular task.
",6 Related Work,[0],[0]
"In doing so, we draw on a large body of work around improving annotation quality for NLP data.",6 Related Work,[0],[0]
"Our work aligns with efforts to improve task design (e.g. Schneider et al., 2013; Morstatter and Liu, 2016; Schneider, 2015), and to develop better models of annotation.",6 Related Work,[0],[0]
"With respect to the former and specific to Twitter, Frankenstein et al. (2016) show that for the task of labeling the sentiment of reply tweets, annotations vary depending on whether or not the original tweet (being replied to) is also shown.",6 Related Work,[0],[0]
"With respect to the latter, several recent models beyond Raykar et al. (2010) have been proposed (Guan et al., 2017; Tian and Zhu, 2012; Wauthier and Jordan, 2011; Passonneau and Carpenter, 2014).",6 Related Work,[0],[0]
"However, our work is most similar to efforts outside the domain of NLP, where Dai et al. (2013) have developed a method of switching between task workflows based on annotation quality for particular items, and Nguyen et al. (2016) have developed a Bayesian model similar to ours to study annotation quality for other kinds of slightly subjective tasks.
",6 Related Work,[0],[0]
"In a closely related vein, recent work has also considered how text annotations may vary in important ways based on the characteristics of annotators (rather than how the task is posed, as we study here)",6 Related Work,[0],[0]
"(Sen et al., 2015).",6 Related Work,[0],[0]
An interesting avenue of future work is to understand the intersection between the design of NLP annotation tasks and the characteristics of the annotating population.,6 Related Work,[0],[0]
Annotated data serves as a foundational layer for many NLP tasks.,7 Conclusion and Future Work,[0],[0]
"While some annotation tasks only require information from short texts, in many others, we can elicit higher-quality labels by providing annotators with additional contextual information.",7 Conclusion and Future Work,[0],[0]
"However, asking annotators to consider too much information would make their task slow and burdensome.
",7 Conclusion and Future Work,[0],[0]
"In this paper we demonstrate how exposing an-
notators to short contextual information leads to better labels and better classification results.",7 Conclusion and Future Work,[0],[0]
"However, different contexts lead to results of different quality, and it is not obvious a priori which context is best, nor—even given ground truth—how to combine labels produced across contexts to exploit the information present in each.",7 Conclusion and Future Work,[0],[0]
"We then propose ConStance, a generalizable model that learns the effects of both individual contexts and individual annotators on the labeling process.",7 Conclusion and Future Work,[0],[0]
"The model infers (probability estimates for) ground truth labels, plus learns a classifier that can be applied to new instances.",7 Conclusion and Future Work,[0],[0]
"We show that this classifier significantly improves classification of political stance compared to the standard practice of training models on majority vote labels.
",7 Conclusion and Future Work,[0],[0]
"The focus of this work is on improving both the annotation process for nuanced, contextdependent tasks and the use of the resulting labels.",7 Conclusion and Future Work,[0],[0]
"While ConStance’s label estimation can be used in conjunction with any classification method, this paper does not address the optimization of the classifier itself.",7 Conclusion and Future Work,[0],[0]
"Thus, while we consider an assortment of contexts and use a rich feature representation, using additional contexts or different features may lead to better performance on stance detection.",7 Conclusion and Future Work,[0],[0]
"Finally, the model is versatile enough we could consider treating different tweets as different “contexts” for the same user, augmenting the extensively annotated tweets with other types of data, and, naturally, applying the same framework to other annotation tasks.",7 Conclusion and Future Work,[0],[0]
Manual annotations are a prerequisite for many applications of machine learning.,abstractText,[0],[0]
"However, weaknesses in the annotation process itself are easy to overlook.",abstractText,[0],[0]
"In particular, scholars often choose what information to give to annotators without examining these decisions empirically.",abstractText,[0],[0]
"For subjective tasks such as sentiment analysis, sarcasm, and stance detection, such choices can impact results.",abstractText,[0],[0]
"Here, for the task of political stance detection on Twitter, we show that providing too little context can result in noisy and uncertain annotations, whereas providing too strong a context may cause it to outweigh other signals.",abstractText,[0],[0]
"To characterize and reduce these biases, we develop ConStance, a general model for reasoning about annotations across information conditions.",abstractText,[0],[0]
"Given conflicting labels produced by multiple annotators seeing the same instances with different contexts, ConStance simultaneously estimates gold standard labels and also learns a classifier for new instances.",abstractText,[0],[0]
"We show that the classifier learned by ConStance outperforms a variety of baselines at predicting political stance, while the model’s interpretable parameters shed light on the effects of each context.",abstractText,[0],[0]
ConStance: Modeling Annotation Contexts to Improve Stance Classification,title,[0],[0]
"Constituent parsing is a core problem in NLP where the goal is to obtain the syntactic structure of sentences expressed as a phrase structure tree.
",1 Introduction,[0],[0]
"Traditionally, constituent-based parsers have been built relying on chart-based, statistical models (Collins, 1997; Charniak, 2000; Petrov et al., 2006), which are accurate but slow, with typical speeds well below 10 sentences per second on modern CPUs (Kummerfeld et al., 2012).
",1 Introduction,[0],[0]
Several authors have proposed more efficient approaches which are helpful to gain speed while preserving (or even improving) accuracy.,1 Introduction,[0],[0]
"Sagae and Lavie (2005) present a classifier for constituency parsing that runs in linear time by relying on a shift-reduce stack-based algorithm, instead of a grammar.",1 Introduction,[0],[0]
"It is essentially an extension of transition-based dependency parsing
1This is a revision with improved results of our paper originally published in EMNLP 2018.",1 Introduction,[0],[0]
"The previous version contained a bug where the script EVALB was not considering the COLLINS.prm parameter file.
",1 Introduction,[0],[0]
"(Nivre, 2003).",1 Introduction,[0],[0]
"This line of research has been polished through the years (Wang et al., 2006; Zhu et al., 2013; Dyer et al., 2016; Liu and Zhang, 2017; Fernández-González and GómezRodrı́guez, 2018).
",1 Introduction,[0],[0]
"With an aim more related to our work, other authors have reduced constituency parsing to tasks that can be solved faster or in a more generic way.",1 Introduction,[0],[0]
Fernández-González and Martins (2015) reduce phrase structure parsing to dependency parsing.,1 Introduction,[0],[0]
They propose an intermediate representation where dependency labels from a head to its dependents encode the nonterminal symbol and an attachment order that is used to arrange nodes into constituents.,1 Introduction,[0],[0]
Their approach makes it possible to use off-the-shelf dependency parsers for constituency parsing.,1 Introduction,[0],[0]
"In a different line, Vinyals et al. (2015) address the problem by relying on a sequence-to-sequence model where trees are linearized in a depth-first traversal order.",1 Introduction,[0],[0]
Their solution can be seen as a machine translation model that maps a sequence of words into a parenthesized version of the tree.,1 Introduction,[0],[0]
Choe and Charniak (2016) recast parsing as language modeling.,1 Introduction,[0],[0]
"They train a generative parser that obtains the phrasal structure of sentences by relying on the Vinyals et al. (2015) intuition and on the Zaremba et al. (2014) model to build the basic language modeling architecture.
",1 Introduction,[0],[0]
"More recently, Shen et al. (2018) propose an architecture to speed up the current state-of-theart chart parsers trained with deep neural networks (Stern et al., 2017; Kitaev and Klein, 2018).",1 Introduction,[0],[0]
"They introduce the concept of syntactic distances, which specify the order in which the splitting points of a sentence will be selected.",1 Introduction,[0],[0]
"The model learns to predict such distances, to then recursively partition the input in a top-down fashion.
",1 Introduction,[0],[0]
"Contribution We propose a method to transform constituent parsing into sequence labeling.
",1 Introduction,[0],[0]
"1314 Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 1314–1324
Brussels, Belgium, October 31 - November 4, 2018.",1 Introduction,[0],[0]
"c©2018 Association for Computational Linguistics
This reduces it to the complexity of tasks such as part-of-speech (PoS) tagging, chunking or namedentity recognition.",1 Introduction,[0],[0]
"The contribution is two-fold.
",1 Introduction,[0],[0]
"First, we describe a method to linearize a tree into a sequence of labels (§2) of the same length of the sentence minus one.2 The label generated for each word encodes the number of common ancestors in the constituent tree between that word and the next, and the nonterminal symbol associated with the lowest common ancestor.",1 Introduction,[0],[0]
We prove that the encoding function is injective for any tree without unary branchings.,1 Introduction,[0],[0]
"After applying collapsing techniques, the method can parse unary chains.
",1 Introduction,[0],[0]
"Second, we use such encoding to present different baselines that can effectively predict the structure of sentences (§3).",1 Introduction,[0],[0]
"To do so, we rely on a recurrent sequence labeling model based on BILSTM’s (Hochreiter and Schmidhuber, 1997; Yang and Zhang, 2018).",1 Introduction,[0],[0]
"We also test other models inspired in classic approaches for other tagging tasks (Schmid, 1994; Sha and Pereira, 2003).",1 Introduction,[0],[0]
"We use the Penn Treebank (PTB) and the Penn Chinese Treebank (CTB) as testbeds.
",1 Introduction,[0],[0]
"The comparison against Vinyals et al. (2015), the closest work to ours, shows that our method is able to train more accurate parsers.",1 Introduction,[0],[0]
"This is in spite of the fact that our approach addresses constituent parsing as a sequence labeling problem, which is simpler than a sequence-to-sequence problem, where the output sequence has variable/unknown length.",1 Introduction,[0],[0]
"Despite being the first sequence labeling method for constituent parsing, our baselines achieve decent accuracy results in comparison to models coming from mature lines of research, and their speeds are the fastest reported to our knowledge.
",1 Introduction,[0],[0]
"2 Linearization of n-ary trees
Notation and Preliminaries In what follows, we use bold style to refer to vectors and matrices (e.g x and W).",1 Introduction,[0],[0]
"Let w=[w1, w2, ..., w|w|] be an input sequence of words, where wi ∈ V .",1 Introduction,[0],[0]
Let T|w| be the set of constituent trees with |w| leaf nodes that have no unary branches.,1 Introduction,[0],[0]
"For now, we will assume that the constituent parsing problem consists in mapping each sentence w to a tree in T|w|, i.e., we assume that correct parses have no unary branches.",1 Introduction,[0],[0]
"We will deal with unary branches later.
",1 Introduction,[0],[0]
"To reduce the problem to a sequence labeling
2A last dummy label is generated to fulfill the properties of sequence labeling tasks.
",1 Introduction,[0],[0]
"task, we define a set of labels L that allows us to encode each tree in T|w| as a unique sequence of labels in L(|w|−1), via an encoding function Φ|w| : T|w| → L(|w|−1).",1 Introduction,[0],[0]
"Then, we can reduce the constituent parsing problem to a sequence labeling task where the goal is to predict a function F|w|,θ : V
|w| → L|w|−1, where θ are the parameters to be learned.",1 Introduction,[0],[0]
"To parse a sentence, we label it and then decode the resulting label sequence into a constituent tree, i.e., we apply F|w|,θ ◦ Φ−1|w|.
",1 Introduction,[0],[0]
"For the method to be correct, we need the encoding of trees to be complete (every tree in T|w| must be expressible as a label sequence, i.e., Φ|w| must be a function, so we have full coverage of constituent trees) and injective (so that the inverse function Φ−1|w| is well-defined).",1 Introduction,[0],[0]
"Surjectivity is also desirable, so that the inverse is a function on L|w|−1, and the parser outputs a tree for any sequence of labels that the classifier can generate.
",1 Introduction,[0],[0]
We now define our Φ|w| and show that it is total and injective.,1 Introduction,[0],[0]
Our encoding is not surjective per se.,1 Introduction,[0],[0]
We handle ill-formed label sequences in §2.3.,1 Introduction,[0],[0]
"Let wi be a word located at position i in the sentence, for 1 ≤ i ≤ |w| − 1.",2.1 The Encoding,[0],[0]
"We will assign it a 2-tuple label li = (ni, ci), where: ni is an integer that encodes the number of common ancestors between wi and wi+1, and ci is the nonterminal symbol at the lowest common ancestor.
",2.1 The Encoding,[0],[0]
"Basic encodings The number of common ancestors may be encoded in several ways.
1.",2.1 The Encoding,[0],[0]
"Absolute scale: The simplest encoding is to make ni directly equal to the number of ancestors in common between wi and wi+1.
2.",2.1 The Encoding,[0],[0]
Relative scale: A second and better variant consists in making ni represent the difference with respect to the number of ancestors encoded in ni−1.,2.1 The Encoding,[0],[0]
"Its main advantage is that the size of the label set is reduced considerably.
",2.1 The Encoding,[0],[0]
"Figure 1 shows an example of a tree linearized according to both absolute and relative scales.
",2.1 The Encoding,[0],[0]
"Encoding for trees with exactly k children For trees where all branchings have exactly k children, it is possible to obtain a even more efficient linearization in terms of number of labels.",2.1 The Encoding,[0],[0]
"To do so, we take the relative scale encoding as our starting
point.",2.1 The Encoding,[0],[0]
"If we build the tree incrementally in a leftto-right manner from the labels, if we find a negative ni, we will need to attach the word wi+1 (or a new subtree with that word as its leftmost leaf) to the (−ni + 2)th node in the path going from wi to the root.",2.1 The Encoding,[0],[0]
"If every node must have exactly k children, there is only one valid negative value of ni: the one pointing to the first node in said path that has not received its kth child yet.",2.1 The Encoding,[0],[0]
"Any smaller value would leave this node without enough children (which cannot be fixed later due to the leftto-right order in which we build the tree), and any larger value would create a node with too many children.",2.1 The Encoding,[0],[0]
"Thus, we can map negative values to a single label.",2.1 The Encoding,[0],[0]
"Figure 2 shows an example for the case of binarized trees (k = 2).
",2.1 The Encoding,[0],[0]
"Links to root Another variant emerged from the empirical observation that some tokens that are
usually linked to the root node (such as the final punctuation in Figure 1) were particularly difficult to learn for the simpler baselines.",2.1 The Encoding,[0],[0]
"To successfully deal with these cases in practice, it makes sense to consider a simplified annotation scheme where a node is assigned a special tag (ROOT, ci) when it is directly linked to the root of the tree.
",2.1 The Encoding,[0],[0]
"From now on, unless otherwise specified, we use the relative scale without the simplification for exactly k children.",2.1 The Encoding,[0],[0]
"This will be the encoding used in the experiments (§4), because the size of the label set is significantly lower than the one obtained by relying on the absolute one.",2.1 The Encoding,[0],[0]
"Also, it works directly with non-binarized trees, in contrast to the encoding that we introduce for trees with exactly k children, which is described only for completeness and possible interest for future work.",2.1 The Encoding,[0],[0]
"For the experiments (§4), we also use the special tag (ROOT, ci) to further reduce the size of the label set and to simplify the classification of tokens connected to the root, where |ni| is expected to be large.",2.1 The Encoding,[0],[0]
We now prove that Φ|w| is a total function and injective for any tree in T|w|.,2.2 Theoretical correctness,[0],[0]
We remind that trees in this set have no unary branches.,2.2 Theoretical correctness,[0],[0]
Later (in §2.3) we describe how we deal with unary branches.,2.2 Theoretical correctness,[0],[0]
"To prove correctness, we use the relative scale.",2.2 Theoretical correctness,[0],[0]
"Correctness for the other scales follows trivially.
",2.2 Theoretical correctness,[0],[0]
"Completeness Every pair of nodes in a rooted tree has at least one common ancestor, and a unique lowest common ancestor.",2.2 Theoretical correctness,[0],[0]
"Hence, for any tree in T|w|, the label li = (ni, ci) defined in Section 2.1 is well-defined and unique for each word wi, 1 ≤",2.2 Theoretical correctness,[0],[0]
"i ≤ |w| − 1; and thus Φ|w| is a total function from T|w| to L(|w|−1).
",2.2 Theoretical correctness,[0],[0]
Injectivity The encoding method must ensure that any given sequence of labels corresponds to exactly one tree.,2.2 Theoretical correctness,[0],[0]
"Otherwise, we have to deal with ambiguity, which is not desirable.
",2.2 Theoretical correctness,[0],[0]
"For simplicity, we will prove injectivity in two steps.",2.2 Theoretical correctness,[0],[0]
"First, we will show that the encoding is injective if we ignore nonterminals (i.e., equivalently, that the encoding is injective for the set of trees resulting from replacing all the nonterminals in trees in T|w| with a generic nonterminal X).",2.2 Theoretical correctness,[0],[0]
"Then, we will show that it remains injective when we take nonterminals into account.
",2.2 Theoretical correctness,[0],[0]
"For the first part, let τ ∈",2.2 Theoretical correctness,[0],[0]
"T|w| be a tree where
nonterminals take a generic value X .",2.2 Theoretical correctness,[0],[0]
We represent the label of the ith leaf node as •i.,2.2 Theoretical correctness,[0],[0]
"Consider the representation of τ as a bracketed string, where a single-node tree with a node labeled A is represented by (A), and a tree rooted at R with child subtrees C1 . . .",2.2 Theoretical correctness,[0],[0]
Cn is represented as (R(C1 . . .,2.2 Theoretical correctness,[0],[0]
"Cn)).
",2.2 Theoretical correctness,[0],[0]
Each leaf node will appear in this string as a substring (•i).,2.2 Theoretical correctness,[0],[0]
"Thus, the parenthesized string has the form α0(•1)α1(•2) . . .",2.2 Theoretical correctness,[0],[0]
"α|w|−1(•|w|)αw, where the αis are strings that can only contain brackets and nonterminals, as by construction there can be no leaf nodes between (•i) and (•i+1).
",2.2 Theoretical correctness,[0],[0]
We now observe some properties of this parenthesized string.,2.2 Theoretical correctness,[0],[0]
"First, note that each of the substrings αi must necessarily be composed of zero or more closing parentheses followed by zero or more opening parentheses with their corresponding nonterminal, i.e., it must be of the form",2.2 Theoretical correctness,[0],[0]
"[)]∗[(X]∗. This is because an opening parenthesis followed by a closing parenthesis would represent a leaf node, and there are no leaf nodes between (•i) and (•i+1) in the tree.
",2.2 Theoretical correctness,[0],[0]
"Thus, we can write αi as αi)αi(, where αi) is a string matching the expression [)]∗ and αi( a string matching the expression",2.2 Theoretical correctness,[0],[0]
"[(X]∗. With this, we can write the parenthesized string for τ as
α0)α0((•1)α1)α1((•2)α2)α2( . . .",2.2 Theoretical correctness,[0],[0]
"(•|w|)α|w|)α|w|(.
Let us now denote by βi the string αi−1((•i)αi).",2.2 Theoretical correctness,[0],[0]
"Then, and taking into account that α0) and αw( are trivially empty in the previous expression due to bracket balancing, the expression for the tree becomes simply β1β2 . . .",2.2 Theoretical correctness,[0],[0]
"β|w|, where we know, by construction, that each βi is of the form",2.2 Theoretical correctness,[0],[0]
"[(X]∗(•i)[)]∗.
Since we have shown that each tree in T|w| uniquely corresponds to a string β1β2 . . .",2.2 Theoretical correctness,[0],[0]
"β|w|, to show injectivity of the encoding, it suffices to show that different values for a βi generate different label sequences.
",2.2 Theoretical correctness,[0],[0]
"To show this, we can say more about the form of βi: it must be either of the form [(X]∗(•i) or of the form (•i)[)]∗, i.e., it is not possible that βi contains both opening parenthesis before the leaf node and closing parentheses after the leaf node.",2.2 Theoretical correctness,[0],[0]
"This could only happen if the tree had a subtree of the form (X(•i)), but this is not possible since we are forbidding unary branches.
",2.2 Theoretical correctness,[0],[0]
"Hence, we can identify each βi with an integer number δ(βi): 0",2.2 Theoretical correctness,[0],[0]
"if βi has neither opening nor closing parentheses outside the leaf node,
+k if it has k opening parentheses, and −k if it has k closing parentheses.",2.2 Theoretical correctness,[0],[0]
It is easy to see that δ(β1)δ(β2) . . .,2.2 Theoretical correctness,[0],[0]
δ(β|w|−1) corresponds to the values ni in the relative-scale label encoding of the tree τ .,2.2 Theoretical correctness,[0],[0]
"To see this, note that the number of unclosed parentheses at the point right after βi in the string exactly corresponds to the number of common ancestors between the ith and (i + 1)th leaf nodes.",2.2 Theoretical correctness,[0],[0]
A positive δ(βi),2.2 Theoretical correctness,[0],[0]
"= k corresponds to opening k parentheses before βi, so the number of common ancestors of wi and wi+1 will be k more than that of wi−1 and wi.",2.2 Theoretical correctness,[0],[0]
A negative δ(βi),2.2 Theoretical correctness,[0],[0]
"= −k corresponds to closing k parentheses after βi, so the number of common ancestors will conversely decrease by k. A value of zero means no opening or closing parentheses, and no change in the number of common ancestors.
",2.2 Theoretical correctness,[0],[0]
"Thus, different parenthesized strings β1β2 . . .",2.2 Theoretical correctness,[0],[0]
"β|w| generate different label sequences, which proves injectivity ignoring nonterminals (note that δ(β|w|) does not affect injectivity as it is uniquely determined by the other values: it corresponds to closing all the parentheses that remain unclosed at that point).
",2.2 Theoretical correctness,[0],[0]
It remains to show that injectivity still holds when nonterminals are taken into account.,2.2 Theoretical correctness,[0],[0]
"Since we have already proven that trees with different structure produce different values of ni in the labels, it suffices to show that trees with the same structure, but different nonterminals, produce different values of ci.",2.2 Theoretical correctness,[0],[0]
"Essentially, this reduces to showing that every nonterminal in the tree is mapped into a concrete ci.",2.2 Theoretical correctness,[0],[0]
"That said, consider a tree τ ∈ T|w|, and some nonterminal X in τ .",2.2 Theoretical correctness,[0],[0]
"Since trees in Tw do not have unary branches, X has at least two children.",2.2 Theoretical correctness,[0],[0]
"Consider the rightmost word in the first child subtree, and call it wi.",2.2 Theoretical correctness,[0],[0]
"Then, wi+1 is the leftmost word in the second child subtree, and X is the lowest common ancestor of wi and wi+1.",2.2 Theoretical correctness,[0],[0]
"Thus, ci = X , and a tree with identical structure but a different nonterminal at that position will generate a label sequence with a different value of ci.",2.2 Theoretical correctness,[0],[0]
This concludes the proof of injectivity.,2.2 Theoretical correctness,[0],[0]
"We have shown that our proposed encoding is a total, injective function from trees without unary branches with yield of length |w| to sequences of |w| − 1 labels.",2.3 Limitations,[0],[0]
This will serve as the basis for our reduction of constituent parsing to sequence labeling.,2.3 Limitations,[0],[0]
"However, to go from theory to practice, we
need to overcome two limitations of the theoretical encoding: non-surjectivity and the inability to encode unary branches.",2.3 Limitations,[0],[0]
"Fortunately, both can be overcome with simple techniques.
",2.3 Limitations,[0],[0]
"Handling of unary branches The encoding function Φ|w| cannot directly assign the nonterminal symbols of unary branches, as there is not any pair of words (wi, wi+1) that have those in common.",2.3 Limitations,[0],[0]
"Figure 3 illustrates it with an example.
",2.3 Limitations,[0],[0]
"It is worth remarking that this is not a limitation of our encoding, but of any encoding that would facilitate constituent parsing as sequence labeling, as the number of nonterminal nodes in a tree with unary branches is not bounded by any function of |w|.",2.3 Limitations,[0],[0]
"The fact that our encoding works for trees without unary branches owes to the fact that such a tree cannot have more than |w|−1 non-leaf nodes, and therefore it is always possible to encode all of them in labels associated with |w| − 1 leaf nodes.
",2.3 Limitations,[0],[0]
"To overcome this issue, we follow a collapsing approach, as is common in parsers that need special treatment of unary chains (Finkel et al., 2008; Narayan and Cohen, 2016; Shen et al., 2018).",2.3 Limitations,[0],[0]
"For clarity, we use the name intermediate unary chains
to refer to unary chains that end up into a nonterminal symbol (e.g. X → Y in Figure 3) and leaf unary chains to name those that yield a PoS tag (e.g. Z → T5).",2.3 Limitations,[0],[0]
"Intermediate unary chains are collapsed into a chained single symbol, which can be encoded by Φ|w| as any other nonterminal symbol.",2.3 Limitations,[0],[0]
"On the other hand, leaf unary chains are collapsed together with the PoS tag, but these cannot be encoded and decoded by relying on Φ|w|, as our encoding assumes a fixed sequence of leaf nodes and does not encode them explicitly.",2.3 Limitations,[0],[0]
"To overcome this, we propose two methods:
1.",2.3 Limitations,[0],[0]
To use an extra function to enrich the PoS tags before applying our main sequence labeling function.,2.3 Limitations,[0],[0]
"This function is of the form Ψ|w| : V
|w| → U |w|, where U is the set of labels of the leaf unary chains (without including the PoS tags) plus a dummy label ∅. Ψ|w| maps wi to ∅ if there is no leaf unary chain at wi, or to the collapsed label otherwise.
2.",2.3 Limitations,[0],[0]
"To extend our encoding function to predict them as a part of our labels li, by transforming them into 3-tuples (ni, ci, ui) where ui encodes the leaf unary chain collapsed label for wi, if there is any, or none otherwise.",2.3 Limitations,[0],[0]
"We call this extended encoding function Φ ′|w|.
",2.3 Limitations,[0],[0]
The former requires to run two passes of sequence labeling to deal with leaf unary chains.,2.3 Limitations,[0],[0]
"The latter avoids this, but the number of labels is larger and sparser.",2.3 Limitations,[0],[0]
"In §4 we discuss how these two approaches behave in terms of accuracy and speed.
",2.3 Limitations,[0],[0]
Non,2.3 Limitations,[0],[0]
-surjectivity,2.3 Limitations,[0],[0]
"Our encoding, as defined formally in Section 2.1, is injective but not surjective, i.e., not every sequence of |w| − 1 labels of the form (ni, ci) corresponds to a tree in T|w|.",2.3 Limitations,[0],[0]
"In particular, there are two situations where a label sequence formally has no tree, and thus Φ−1|w| is not formally defined and we have to use extra heuristics or processing to define it:
• Sequences with conflicting nonterminals.",2.3 Limitations,[0],[0]
A nonterminal can be the lowest common ancestor of more than two pairs of contiguous words when branches are non-binary.,2.3 Limitations,[0],[0]
"For example, in the tree in Figure 1, the lowest common ancestor of both “the” and “red” and of “red” and “toy” is the same NP node.",2.3 Limitations,[0],[0]
"This translates into c4 = NP , c5 = NP in the label sequence.",2.3 Limitations,[0],[0]
"If we take that sequence and set c5 = VP , we obtain a label sequence that
does not strictly correspond to the encoding of any tree, as it contains a contradiction: two elements referencing the same node indicate different nonterminal labels.",2.3 Limitations,[0],[0]
"In practice, this problem is trivial to solve: when a label sequence encodes several conflicting nonterminals at a given position in the tree, we compute Φ−1|w| using the first such nonterminal and ignoring the rest.
",2.3 Limitations,[0],[0]
• Sequences that produce unary structures.,2.3 Limitations,[0],[0]
"There are sequences of values ni that do not correspond to a tree in T|w| because the only tree structure satisfying the common ancestor conditions of their values (the one built by generating the string of βis in the injectivity proof) contains unary branchings, causing the problem described above where we do not have a specification for every nonterminal.",2.3 Limitations,[0],[0]
"An example of this is the sequence (1, S), (3, Y ), (1, S), (1, S) in absolute scaling, that was introduced in Figure 3.",2.3 Limitations,[0],[0]
"In practice, as unary chains have been previously collapsed, any generated unary node is considered as not valid and removed.",2.3 Limitations,[0],[0]
"Sequence labeling is an structured prediction task that generates an output label for every token in an input sequence (Rei and Søgaard, 2018).",3 Sequence Labeling,[0],[0]
"Examples of practical tasks that can be formulated under this framework in natural language processing are PoS tagging, chunking or named-entity recognition, which are in general fast.",3 Sequence Labeling,[0],[0]
"However, to our knowledge, there is no previous work on sequence labeling methods for constituent parsing, as an encoding allowing it was lacking so far.
",3 Sequence Labeling,[0],[0]
"In this work, we consider a range of methods ranging from traditional models to state-of-theart neural models for sequence labeling, to test whether they are valid to train constituency-based parsers following our approach.",3 Sequence Labeling,[0],[0]
"We give the essential details needed to comprehend the core of each approach, but will mainly treat them as black boxes, referring the reader to the references for a careful and detailed mathematical analysis of each method.",3 Sequence Labeling,[0],[0]
Appendix ??,3 Sequence Labeling,[0],[0]
"specifies additional hyperparameters for the tested models.
",3 Sequence Labeling,[0],[0]
Preprocessing We add to every sentence both beginning and end tokens.,3 Sequence Labeling,[0],[0]
"We consider two baselines to train our prediction function F|w|,θ, based on popular sequence labeling methods used in NLP problems, such as PoS tagging or shallow parsing (Schmid, 1994; Sha and Pereira, 2003).
",3.1 Traditional Sequence Labeling Methods,[0],[0]
"Conditional Random Fields (Lafferty et al., 2001) Let CRF|w|,θ be its prediction function, a CRF model computes conditional probability distributions of the form p(l,w) such that CRFθ(w) = l = arg maxl′ p(l
′,w).",3.1 Traditional Sequence Labeling Methods,[0],[0]
"In our work, the inputs to the CRF are words and PoS tags.",3.1 Traditional Sequence Labeling Methods,[0],[0]
"To represent a word wi, we are using information of the word itself and also contextual information from w[i−1:i+1].3 In particular:
• We extract the word form (lowercased), the PoS tag and its prefix of length 2, from w[i−1:i+1].",3.1 Traditional Sequence Labeling Methods,[0],[0]
"For these words we also include binary features: whether it is the first word, the last word, a number, whether the word is capitalized or uppercased.
",3.1 Traditional Sequence Labeling Methods,[0],[0]
"• Additionally, for wi we look at the suffixes of both length 3 and 2 (i.e. wi[−3:] and wi[−2:]).
",3.1 Traditional Sequence Labeling Methods,[0],[0]
"To build our CRF models, we relied on the sklearn-crfsuite library4.
MultiLayer Perceptron (Rosenblatt, 1958)",3.1 Traditional Sequence Labeling Methods,[0],[0]
We use one hidden layer.,3.1 Traditional Sequence Labeling Methods,[0],[0]
"Let MLP|w|,θ be its prediction function, it treats sequence labeling as a set of independent predictions, one per word.",3.1 Traditional Sequence Labeling Methods,[0],[0]
The prediction for a word is computed as softmax(W2 · relu(W1 ·,3.1 Traditional Sequence Labeling Methods,[0],[0]
"x + b1) + b2), where x is the input vector and Wi and bi the weights and biases to be learned at layer i.",3.1 Traditional Sequence Labeling Methods,[0],[0]
We consider both a discrete (MLPd) and an embedded (MLPe) perceptron.,3.1 Traditional Sequence Labeling Methods,[0],[0]
"For the former, we use as inputs the same set of features as for the CRF.",3.1 Traditional Sequence Labeling Methods,[0],[0]
"For the latter, the vector x for wi is defined as a concatenation of word and PoS tag embeddings from w[i−2:i+2].5
To build our MLPs, we relied on keras.6",3.1 Traditional Sequence Labeling Methods,[0],[0]
"We are using NCRFpp7, a sequence labeling framework based on recurrent neural networks (RNN)
3We tried contextual information beyond the immediate previous and next word, but the performance was similar.
4https://sklearn-crfsuite.readthedocs.io/en/latest/ 5In contrast to the discrete input, larger contextual infor-
mation was useful.",3.2 Sequence Labeling Neural Models,[0],[0]
"6https://keras.io/ 7https://github.com/jiesutd/NCRFpp, with PyTorch.
",3.2 Sequence Labeling Neural Models,[0],[0]
"(Yang and Zhang, 2018), and more specifically on bidirectional short-term memory networks (Hochreiter and Schmidhuber, 1997), which have been successfully applied to problems such as PoS tagging or dependency parsing (Plank et al., 2016; Kiperwasser and Goldberg, 2016).",3.2 Sequence Labeling Neural Models,[0],[0]
Let LSTM(x) be an abstraction of a standard long short-term memory network that processes the sequence x =,3.2 Sequence Labeling Neural Models,[0],[0]
"[x1, ...,x|x|], then a BILSTM encoding of its ith element, BILSTM(x, i) is defined as:
BILSTM(x, i) =",3.2 Sequence Labeling Neural Models,[0],[0]
hi = hli ◦ hri = LSTMl(x[1,3.2 Sequence Labeling Neural Models,[0],[0]
:,3.2 Sequence Labeling Neural Models,[0],[0]
i]) ◦,3.2 Sequence Labeling Neural Models,[0],[0]
"LSTMr(x[|x|:i])
In the case of multilayer BILSTM’S, the timestep outputs of the BILSTMm are fed as input to the BILSTMm+1.",3.2 Sequence Labeling Neural Models,[0],[0]
"The output label for each wi is finally predicted as softmax(W · hi + b).
",3.2 Sequence Labeling Neural Models,[0],[0]
"Given a sentence [w1, w2, ..., w|w|], the input to the sequence model is a sequence of embeddings [w1,w2, ...,w|w|] where each wi = wi ◦ pi ◦ chi, such that wi and pi are a word and a PoS tag embedding, and chi is a word embedding obtained from an initial character embedding layer, also based on a BILSTM.",3.2 Sequence Labeling Neural Models,[0],[0]
Figure 4 shows the architecture of the network.,3.2 Sequence Labeling Neural Models,[0],[0]
"We report results on models trained using the relative scale encoding and the special tag (ROOT,ci).",4 Experiments,[0],[0]
"As a reminder, to deal also with leaf unary chains, we proposed two methods in §2.3: to predict them relying both on the encoding functions Φ|w| and Ψ|w|, or to predict them as a part of an enriched label predicted by the function Φ ′|w|.",4 Experiments,[0],[0]
"For clarity, we are naming these models with the superscripts Ψ,Φ and Φ ′ , respectively.
",4 Experiments,[0],[0]
"Datasets We use the Penn Treebank (Marcus et al., 1994) and its official splits: Sections 2 to 21
for training, 22 for development and 23 for testing.",4 Experiments,[0],[0]
"For the Chinese Penn Treebank (Xue et al., 2005): articles 001- 270 and 440-1151 are used for training, articles 301-325 for development, and articles 271-300 for testing.",4 Experiments,[0],[0]
We use the version of the corpus with the predicted PoS tags of Dyer et al. (2016).,4 Experiments,[0],[0]
"We train the Φ models based on the predicted output by the corresponding Ψ model.
",4 Experiments,[0],[0]
Metrics We use the F-score from the EVALB script using COLLINS.prm as the parameter file.,4 Experiments,[0],[0]
Speed is measured in sentences per second.,4 Experiments,[0],[0]
"We briefly comment on the accuracy (percentage of correctly predicted labels, no symbol excluded here) of our baselines.
",4 Experiments,[0],[0]
"Source code It can be found at https:// github.com/aghie/tree2labels
Hardware The models are run on a single thread of a CPU8 and on a consumer-grade GPU9.",4 Experiments,[0],[0]
"In sequence-to-sequence work (Vinyals et al., 2015)",4 Experiments,[0],[0]
"the authors use a multi-core CPU (the number of threads was not specified), while we provide results on a single core for easier comparability.",4 Experiments,[0],[0]
"Parsing sentences on a CPU can be framed as an “embarrassingly parallel” problem (Hall et al., 2014), so speed can be made to scale linearly with the number of cores.",4 Experiments,[0],[0]
We use the same batch size as Vinyals et al. (2015) for testing (128).10,4 Experiments,[0],[0]
Table 1 shows the performance of our baselines on the PTB development set.,4.1 Results,[0],[0]
"It is worth noting that since we are using different libraries to train the models, these might show some differences in terms of performance/speed beyond those expected in theory.",4.1 Results,[0],[0]
"For the BILSTM model we test:
• BILSTMm=1: It does not use pretrained word embeddings nor character embeddings.",4.1 Results,[0],[0]
"The number of layers m is set to 1.
",4.1 Results,[0],[0]
"• BILSTMm=1,e:",4.1 Results,[0],[0]
"It adds pretrained word embeddings from GloVe (Pennington et al., 2014) for English and from the Gigaword corpus for Chinese (Liu and Zhang, 2017).
",4.1 Results,[0],[0]
"• BILSTMm=1,e,ch: It includes character embeddings processed through a BILSTM.
8An Intel(R) Core(TM) i7-7700 CPU @ 3.60GHz.",4.1 Results,[0],[0]
"9A GeForce GTX 1080.
10A larger batch will likely result in faster parsing when executing the model on a GPU, but not necessarily on a CPU.
",4.1 Results,[0],[0]
"• BILSTMm=2,e: m is set to 2.",4.1 Results,[0],[0]
"No character embeddings.
",4.1 Results,[0],[0]
"• BILSTMm=2,e,ch: m is set to 2.
",4.1 Results,[0],[0]
"The Ψ,Φ and the Φ ′ models obtain similar Fscores.",4.1 Results,[0],[0]
"When it comes to speed, the BILSTMsΦ ′ are notably faster than the BILSTMsΨ,Φ. Φ ′",4.1 Results,[0],[0]
"models are expected to be more efficient, as leaf unary chains are handled implicitly.",4.1 Results,[0],[0]
"In practice, Φ ′ is a more expensive function to compute than the original Φ, since the number of output labels is significantly larger, which reduces the expected gains with respect to the Ψ,Φ models.",4.1 Results,[0],[0]
"It is worth noting that our encoding is useful to train an MLPe with a decent sense of phrase structure, while being very fast.",4.1 Results,[0],[0]
"Paying attention to the differences between F-score and Accuracy for each baseline, we notice the gap between them is larger for CRFs and MLPs.",4.1 Results,[0],[0]
"This shows the difficulties that these methods have, in comparison to the BILSTM approaches, to predict the correct label when a word wi+1 has few common ancestors with wi.",4.1 Results,[0],[0]
"For example, let -10X be the right (relative scale) label between wi and wi+1, and let l1=-1X and l2=-9X be two possible wrong labels.",4.1 Results,[0],[0]
"In terms of accuracy it is the same that a model predicts l1 or l2, but in terms of constituent F-score, the first will be much worse, as many closed parentheses will remain unmatched.
",4.1 Results,[0],[0]
Tables 2 and 3 compare our best models against the state of the art on the PTB and CTB test sets.,4.1 Results,[0],[0]
"The performance corresponds to models without reranking strategies, unless otherwise specified.",4.1 Results,[0],[0]
We are not aware of work that reduces constituency parsing to sequence labeling.,5 Discussion,[0],[0]
"The work that can be considered as the closest to ours is that of Vinyals et al. (2015), who address it as a sequence-to-sequence problem, where the output sequence has variable/unknown length.",5 Discussion,[0],[0]
"In this context, even a one hidden layer perceptron outperforms their 3-layer LSTM model without attention, while parsing hundreds of sentences per second.",5 Discussion,[0],[0]
Our best models also outperformed their 3-layer LSTM model with attention and even a simple BILSTM model with pretrained GloVe embeddings obtains a similar performance.,5 Discussion,[0],[0]
"In terms of F-score, the proposed sequence labeling baselines still lag behind mature shift-reduce and chart parsers.",5 Discussion,[0],[0]
"In terms of speed, they are clearly faster than both CPU and GPU chart parsers and are at least on par with the fastest shift-reduce ones.",5 Discussion,[0],[0]
"Although with significant loss of accuracy, if phrase-representation is needed in large-scale tasks where the speed of current systems makes parsing infeasible (Gómez-Rodrı́guez, 2017; Gómez-Rodrı́guez et al., 2017), we can use the simpler, less accurate models to get speeds well above any parser reported to date.
",5 Discussion,[0],[0]
"It is also worth noting that in their recent work, published while this manuscript was under review, Shen et al. (2018) developed a mapping of binary trees with n leaves to sequences of n− 1 integers (Shen et al., 2018, Algorithm 1).",5 Discussion,[0],[0]
"This encoding is different from the ones presented here, as it is based on the height of lowest common ancestors in the tree, rather than their depth.",5 Discussion,[0],[0]
"While their purpose is also different from ours, as they use this mapping to generate training data for a parsing algorithm based on recursive partitioning using realvalued distances, their encoding could also be applied with our sequence labeling approach.",5 Discussion,[0],[0]
"However, it has the drawback that it only supports binarized trees, and some of its theoretical properties are worse for our goal, as the way to define the inverse of an arbitrary label sequence can be highly ambiguous: for example, a sequence of n−1 equal labels in this encoding can represent any binary tree with n leaves.",5 Discussion,[0],[0]
"We presented a new parsing paradigm, based on a reduction of constituency parsing to sequence labeling.",6 Conclusion,[0],[0]
"We first described a linearization function
to transform a constituent tree (with n leaves) into a sequence of n",6 Conclusion,[0],[0]
− 1 labels that encodes it.,6 Conclusion,[0],[0]
We proved that this encoding function is total and injective for any tree without unary branches.,6 Conclusion,[0],[0]
"We also discussed its limitations: how to deal with unary branches and non-surjectivity, and showed how these can be solved.",6 Conclusion,[0],[0]
We finally proposed a set of fast and strong baselines.,6 Conclusion,[0],[0]
"This work has received funding from the European Research Council (ERC), under the European Union’s Horizon 2020 research and innovation programme (FASTPARSE, grant agreement No 714150), from the TELEPARESUDC project (FFI2014-51978-C2-2-R) and the ANSWER-ASAP project (TIN2017-85160-C2-1R) from MINECO, and from Xunta de Galicia
(ED431B 2017/01).",Acknowledgments,[0],[0]
We gratefully acknowledge NVIDIA Corporation for the donation of a GTX Titan X GPU.,Acknowledgments,[0],[0]
We introduce a method to reduce constituent parsing to sequence labeling.,abstractText,[0],[0]
"For each word wt, it generates a label that encodes: (1) the number of ancestors in the tree that the words wt andwt+1 have in common, and (2) the nonterminal symbol at the lowest common ancestor.",abstractText,[0],[0]
We first prove that the proposed encoding function is injective for any tree without unary branches.,abstractText,[0],[0]
"In practice, the approach is made extensible to all constituency trees by collapsing unary branches.",abstractText,[0],[0]
We then use the PTB and CTB treebanks as testbeds and propose a set of fast baselines.,abstractText,[0],[0]
"We achieve 90.7% F-score on the PTB test set, outperforming the Vinyals et al. (2015) sequence-to-sequence parser.",abstractText,[0],[0]
"In addition, sacrificing some accuracy, our approach achieves the fastest constituent parsing speeds reported to date on PTB by a wide margin.1",abstractText,[0],[0]
Constituent Parsing as Sequence Labeling,title,[0],[0]
"In recent years, submodular functions (Fujishige, 2005) have been used to address an increasingly wide variety of problems in machine learning and artificial intelligence.",1. Introduction,[0],[0]
"This includes energy functions in probabilistic models (Kohli et al., 2007; Gotovos et al., 2015; Djolonga et al., 2016), influence in social network (Kempe et al., 2003; Mossel & Roch, 2007), crowd teaching (Singla et al., 2014), non-parametric
1Google AI 2Kakao Mobility 3University of Washington, Seattle, work done while at Google AI.",1. Introduction,[0],[0]
"Correspondence to: Andrew Cotter <acotter@google.com>, Jeff Bilmes <bilmes@uw.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"Bayesian estimation (Reed & Ghahramani, 2013), document and speech summarization (Lin et al., 2009; Lin & Bilmes, 2011; Li et al., 2012), image summarization (Tschiatschek et al., 2014; Singla et al., 2016), and clustering (Narasimhan et al., 2005).
",1. Introduction,[0],[0]
"In this paper, we introduce and apply a new submodular optimization problem related to partitioning, covering, and packing (Schrijver, 2003).",1. Introduction,[0],[0]
"Given a set function f : 2V → R+, it may be normalized (i.e., f(∅) = 0), monotone non-decreasing (i.e., f(A) ≤ f(B)",1. Introduction,[0],[0]
"whenever A ⊆ B), and/or submodular (i.e., ∀A,B ⊆ V , f(A) + f(B) ≥ f(A ∪ B) + f(A ∩ B)).",1. Introduction,[0],[0]
A function g is said to be supermodular if −g is submodular.,1. Introduction,[0],[0]
A function m is modular if it is both submodular and supermodular.,1. Introduction,[0],[0]
"An m-partition of V is a set of m subsets, called blocks, that are non-intersecting (Aπi ∩Aπj = ∅ for all i 6= j) and covering (∪iAπi = V ).",1. Introduction,[0],[0]
An m-covering is a set of blocks that is required only to be covering.,1. Introduction,[0],[0]
"In an m-covering, we might also have a multiplicity constraint which is expressed as a positive integer valued vector k = (kv : v ∈ V ) where kv ∈ Z+.",1. Introduction,[0],[0]
"To be a (k,m)covering, we must have an m-covering with no multiplicity violations, i.e., |{i ∈",1. Introduction,[0],[0]
[m] : v ∈,1. Introduction,[0],[0]
Aπi }| ≤,1. Introduction,[0],[0]
"kv,∀v ∈ V .",1. Introduction,[0],[0]
A packing is a set of blocks that is required only to be nonintersecting.,1. Introduction,[0],[0]
"When we wish to refer collectively either to a partition, a covering, or a packing, we use the term grouping.
",1. Introduction,[0],[0]
Given a finite set V of size n = |V,1. Introduction,[0],[0]
"|, a non-negative integer m ∈",1. Introduction,[0],[0]
"[1, n], and m monotone non-decreasing submodular functions fi : 2V → R+ for i ∈",1. Introduction,[0],[0]
"[m], the problem we study finds a feasible m-partition, or m-covering, or m-packing π of V into m blocks Aπ1 , A π 2 , . . .",1. Introduction,[0],[0]
", A π m that are “good” in a way to be described below.
",1. Introduction,[0],[0]
"Feasibility of our groupings is expressed using matroids, which are powerful combinatorial objects that can express many useful constraints over sets.",1. Introduction,[0],[0]
"A matroid (Oxley, 2006)",1. Introduction,[0],[0]
"M = (V, I) consists of a finite countable set V and a non-empty set of “independent” subsets I = {I1, I2, . . .}, where Ii ⊆ V , that is down-closed (A ⊆ B ∈",1. Introduction,[0],[0]
I ⇒,1. Introduction,[0],[0]
"A ∈ I) and where all maximally independent sets have the same size (i.e., ∀A,B ∈",1. Introduction,[0],[0]
"I with |A| < |B|, ∃v ∈ B \",1. Introduction,[0],[0]
A having A+ v ∈,1. Introduction,[0],[0]
"I).
",1. Introduction,[0],[0]
"For a feasible grouping to be good, it must have several properties.",1. Introduction,[0],[0]
"First, the blocks in the grouping should both be individually highly diverse and also all be highly diverse
on average, where diversity is measured by the functions {fi}i∈[m].",1. Introduction,[0],[0]
"For example, suppose the elements of the ground set include animal names: “goldfish” and “carp” have a similar meaning, as do “crow” and “raven”.",1. Introduction,[0],[0]
"But fish are very different from birds, so each of the sets {goldfish, crow} and {carp, raven} are diverse.",1. Introduction,[0],[0]
"Second, and more importantly, different blocks should not be redundant w.r.t.",1. Introduction,[0],[0]
each other.,1. Introduction,[0],[0]
"This avoids the case where two different blocks convey the same information but in different ways, something that might happen even if the two blocks are disjoint.",1. Introduction,[0],[0]
"For example, the sets A1 = {goldfish, crow} and A2 = {carp, raven} are similar and hence redundant, despite being disjoint, and thus would be undesirable blocks when chosen together.",1. Introduction,[0],[0]
"This distinction between disjointedness and nonredundancy is particularly relevant in the context of submodular scoring functions where, as measured by a submodular function f , redundancy between A1 and A2 would mean that f(A1 ∪ A2) ≈ f(A1) and/or f(A1 ∪ A2)",1. Introduction,[0],[0]
≈ f(A2).,1. Introduction,[0],[0]
"We show below that this idea has a number of natural applications, one of which we evaluate in our case study section.
",1. Introduction,[0],[0]
The paper is organized as follows.,1. Introduction,[0],[0]
"In the remainder of this section, we formally define our contributions (Section 1.1) and outline their utility in practice (Section 1.2).",1. Introduction,[0],[0]
"This section also defines objectives that, when constrainedly optimized, achieve our stated grouping goals.",1. Introduction,[0],[0]
"Section 2 places this paper in the context of previous work, and demonstrates that our contributions are novel.",1. Introduction,[0],[0]
Section 3 formally outlines our approach and Section 4 details how we achieve cross-block diversity.,1. Introduction,[0],[0]
Section 5 provides algorithms for constrainedly optimizing our objectives.,1. Introduction,[0],[0]
"Notably, we show a bi-criterion multiplicative approximation ratio guarantee for a fast polynomial time deterministic algorithm (Theorem 1), and also provide a randomized version of the algorithm giving a guarantee with high probability (using Lemma 4).",1. Introduction,[0],[0]
"The guarantees themselves are rather complex, and they are best appreciated in context, so we refer the reader to Theorem 1 and Lemma 4 for their statement.",1. Introduction,[0],[0]
"Lastly, Section 6 explores a case study application where we show our approach can be used to produce ensembles of machine learning models.",1. Introduction,[0],[0]
We demonstrate that our approach improves on previous state-of-the-art results and moreover the groupings achieve the aforementioned desired properties.,1. Introduction,[0],[0]
"Our starting point is a recently introduced objective (Wei et al., 2015) that takes a convex combination of a robust and an average objective and finds a grouping π that scores highly w.r.t.",1.1. Contributions and Objectives,[0],[0]
":
Fra(π) = λ1 min i∈[m]
fi(A π i ) +",1.1. Contributions and Objectives,[0],[0]
λ2 m ∑ i∈[m] fi(A π,1.1. Contributions and Objectives,[0],[0]
"i ), (1)
where the λis are non-negative coefficients and the fis may be distinct submodular functions.",1.1. Contributions and Objectives,[0],[0]
"Our first contribution is
that, unlike Wei et al. (2015), which only handles partitions, we also handle coverings and packings.",1.1. Contributions and Objectives,[0],[0]
"Our second contribution is the inclusion of more general block-specific constraints, expressed as intersections of matroids on an expanded ground set.",1.1. Contributions and Objectives,[0],[0]
"For example, we may wish for blocks to not exceed a certain size, or for each block to correspond to a sub-tree of some graph (Section 3).
",1.1. Contributions and Objectives,[0],[0]
"Our third contribution, and the most significant, is the introduction of cross-block interaction terms, enabling us to avoid groupings containing pairs of blocks that jointly score poorly.",1.1. Contributions and Objectives,[0],[0]
"Our final objective is:
F (π) =Fra(π) + λ3 min",1.1. Contributions and Objectives,[0],[0]
"i,j∈[m],i<j
Fi,j(A π i , A π j ) (2)
+ λ4 1( m 2 ) ∑ i,j∈[m],i<j Fi,j(A π i , A π j ).
",1.1. Contributions and Objectives,[0],[0]
"While there are four λis in this objective, typically only two—one for scoring individual blocks, and the other for pairwise interactions—will be nonzero.",1.1. Contributions and Objectives,[0],[0]
"We interpret the extra cross-block terms Fi,j as rewarding inter-block diversity.",1.1. Contributions and Objectives,[0],[0]
"For example, we could cause our objective function to prefer blocks with large pairwise symmetric differences by taking Fi,j(Aπi , A π j ) =
∣∣Aπi4Aπj ∣∣. Alternatively, in the partitioning or packing setting, we could define Fi,j(A π i , A π j ) = f(A π i ∪ Aπj ), in which case if there are two blocks Aπi , A π j with either f(A π i ∪ Aπj )",1.1. Contributions and Objectives,[0],[0]
≈ f(Aπi ) or f(Aπi ∪Aπj ),1.1. Contributions and Objectives,[0],[0]
"≈ f(Aπj ), then, under an interpretation of f as a diversity measure, the two blocks would be redundant, a situation we would prefer to avoid.",1.1. Contributions and Objectives,[0],[0]
"We study several possible cross-block interactions, based on unions, intersections and symmetric differences, and {sub,super}modular functions thereof, and show that cross-block diversity preserves submodularity in an expanded ground set under various set-to-set mappings (Section 4).
",1.1. Contributions and Objectives,[0],[0]
"Finally, we offer an approach that reduces the above problem to either non-monotone (without robust terms, i.e. λ1 = 0 and λ3 = 0) or iterative monotone (with one robust term, i.e. only one of λ1 or λ3 is nonzero) submodular maximization subject to multiple matroid constraints (Section 5).",1.1. Contributions and Objectives,[0],[0]
"There are several applications in machine learning and data science that fit naturally into this setting, two of which we outline here.
",1.2. Applications,[0],[0]
"Constructing ensembles of machine learning models: Let V index a set of features, with subsets of V corresponding to subsets of features on which a model will be trained.",1.2. Applications,[0],[0]
The classical feature selection problem would be to choose a single set of features that result in a good model.,1.2. Applications,[0],[0]
"We’re interested instead in the problem of finding an ensemble of models, each trained on a different subset of features, that together achieve good performance (Canini et al., 2016).
",1.2. Applications,[0],[0]
"This can be done by grouping V into Aπ1 , A π 2 , . . .",1.2. Applications,[0],[0]
", A π m, from which we form an ensemble of m models, the results of which are aggregated together e.g. by averaging, voting, or taking the minimum.",1.2. Applications,[0],[0]
"Given a submodular function f : V → R+ measuring the “quality” of a single feature subset, one natural goal would be to choose each Aπi to be individually high-quality, according to f .",1.2. Applications,[0],[0]
"However, since the ensemble outputs are being aggregated, it would be purposeless to have redundant models—many results (e.g. Kittler et al., 1998) suggest that when aggregating models, it is best for them to be as diverse as possible (so that the errors they make are independent, thereby improving accuracy and reducing variance).",1.2. Applications,[0],[0]
This motivates us to seek blocks that are as different from each other as possible.,1.2. Applications,[0],[0]
Individual model quality combined with diversity is exactly what maximizing Eq.,1.2. Applications,[0],[0]
(2) encourages.,1.2. Applications,[0],[0]
"Our case study (Section 6) was performed in this setting and supports the benefits of aggregating diverse models.
",1.2. Applications,[0],[0]
Multiple mutually diverse summaries: Data summarization involves finding a small but representative subset of a large set.,1.2. Applications,[0],[0]
"There are some cases where it is useful to have multiple mutually diverse summaries, each of which is representative of the whole.",1.2. Applications,[0],[0]
"For example, in parallel machine learning, where training data might need to be partitioned onto multiple machines distributed across a network, it can be useful to ensure that each subset is representative (so that local computations are accurate) but also diverse (since if two subsets are redundant, than so will the work that each processor performs).",1.2. Applications,[0],[0]
"As another example, consider the problem of document summarization.",1.2. Applications,[0],[0]
"It can be useful to produce multiple representative but distinct summaries of a collection of documents, as this ensures all concepts are covered but different perspectives are preserved.",1.2. Applications,[0],[0]
Special cases of our problem have previously been studied.,2. Previous Work,[0],[0]
"For example, maximizing Eq.",2. Previous Work,[0],[0]
(1) with 1 = λ1 = 1 − λ2 over the space of all otherwise unconstrained partitions corresponds to the submodular fair allocation (SFA) problem.,2. Previous Work,[0],[0]
It is possible to achieve a O(1/( √ m log3m)),2. Previous Work,[0],[0]
"approximation (Asadpour & Saberi, 2010) via iteratively rounding an LP solution when the fi’s are all modular, although the problem is NP-hard to 1/2 + approximate for any > 0",2. Previous Work,[0],[0]
"(Golovin, 2005).",2. Previous Work,[0],[0]
"For submodular fi’s, (Golovin, 2005) also gives a matching-based algorithm with a factor 1/(n −m + 1) approximation.",2. Previous Work,[0],[0]
"A binary search algorithm (Khot & Ponnuswami, 2007) has a better factor of 1/(2m − 1) that is independent of n. A less practical approach uses an ellipsoid approximation (Goemans et al., 2009) of each submodular function and reduces SFA to its modular version yielding an approximation factor of 1/( √ nm1/4 log n log3/2m).",2. Previous Work,[0],[0]
"(Wei et al., 2015) shows that
a greedy algorithm has a 1/m approximation when all fi’s are the same.",2. Previous Work,[0],[0]
"Fair allocation problems are also studied with sometimes non-submodular objectives (Ghodsi et al., 2017).",2. Previous Work,[0],[0]
"Maximizing Eq. (1) with 0 = λ1 = 1 − λ2 over the space of all partitions corresponds to the submodular welfare problem (SW), which can be reduced to submodular maximization on an expanded ground set under a partition matroid constraint (Vondrák, 2008) using a greedy algorithm, an approach having a 1/2 guarantee (Fisher et al., 1978).",2. Previous Work,[0],[0]
"The multi-linear extension of a submodular function can be used in a continuous greedy approach that solves SW with a (1− 1/e) tight approximation factor (Vondrák, 2008).",2. Previous Work,[0],[0]
"When λ1 > 0, λ2 > 0, (Wei et al., 2015) offers two approaches.",2. Previous Work,[0],[0]
The first takes the best of the two solutions computed under λ1 = 1 = 1 − λ2 and λ1 = 0 = 1,2. Previous Work,[0],[0]
"− λ2 to provide a max( βα(λ1)β+α , λ2β) guarantee, where α is the approximation factor for the SFA problem and β the factor for the SW problem.",2. Previous Work,[0],[0]
"A second binary-search approach, the inspiration for Algorithm 1, finds a partition whose block objective value is at least max( δ1−α+δ , λ2α)(OPT− ) for an α−δ fraction of the blocks, where α is the approximation factor of a SW solver and 0 < δ",2. Previous Work,[0],[0]
"< α.
",2. Previous Work,[0],[0]
"The novelty of our optimization problem is that: (i) we may form not only partitions but also (k,m)-coverings and packings; (ii) we utilize a set of m matroids to define the feasibility of the individual blocks in a grouping; and (iii) we explicitly incorporate cross-block interaction terms.",2. Previous Work,[0],[0]
"As with the strategy for the submodular welfare problem (Vondrák, 2008), our approach to maximizing Eq. (2) starts by defining an expanded ground set V× (Figure 1), consisting of m disjoint unions of the original ground set V , i.e., the product set, defined as:
V× , m⊎ i=1",3. Approach,[0],[0]
"V (i) = ⊎ v∈V R(v) = {(v, i) : v ∈ V, i ∈",3. Approach,[0],[0]
"[m]}
where |V×| = nm and where ] is the disjoint union operator.",3. Approach,[0],[0]
"V× can be viewed as indexing into a n ×m matrix with V (i) (isomorphic to V ) being the ith column, and R(v) (isomorphic to [m]) being the vth row.
",3. Approach,[0],[0]
"We also define a mapping from subsets S ⊆ V× to the original ground set, and another mapping that selects the original ground set elements corresponding to those in the ith column as follows:
abs (S) ,{v ∈ V : ∃i ∈",3. Approach,[0],[0]
"[m] with (v, i) ∈ S} col (S, i) , abs ( S ∩ V (i) )",3. Approach,[0],[0]
"Given S ⊆ V×, a grouping π is obtained by setting Aπi = col (S, i) for all",3. Approach,[0],[0]
i ∈,3. Approach,[0],[0]
"[m].
",3. Approach,[0],[0]
"Using these mappings, we will ultimately (Eq. (5)) define a new objective F× : 2V
× → R on the expanded ground set that produces the valuation of a set S ⊆ V× indirectly, via submodular functions defined on the original ground set, using col (S, i) to map subsets of V× to subsets of V .",3. Approach,[0],[0]
"During optimization, we will take the feasible set F× ⊆ 2V ×
to be the intersection of the independent sets of zero or more matroids over V×. Such matroid independence constraints can be used to ensure that any feasible solution maps back to a partitioning, packing, or covering over V .","3.1. Partitionings, Packings, and Coverings",[0],[0]
"When we wish for a partition, we can maximize F× subject to a partition matroid on V× whose independent sets are defined based on the “rows”.","3.1. Partitionings, Packings, and Coverings",[0],[0]
"That is, the independent sets are defined as follows:
Ik = { S ⊆ V× : ∀v ∈ V, ∣∣∣S ∩R(v)∣∣∣","3.1. Partitionings, Packings, and Coverings",[0],[0]
"≤ kv}, (3) where k = (kv1 , kv2 , . . .","3.1. Partitionings, Packings, and Coverings",[0],[0]
", kvn) and ∀v, kv = 1.","3.1. Partitionings, Packings, and Coverings",[0],[0]
"In words, at most one “copy” of each element of the original ground set may be present.","3.1. Partitionings, Packings, and Coverings",[0],[0]
"To express (k,m)-covering constraints on V , we allow ∀v, kv ≥ 1.","3.1. Partitionings, Packings, and Coverings",[0],[0]
"A covering and partition is obtained when maximizing a monotone F×, since any candidate solution that is not yet a covering or partition can be made so by adding elements until all constraints are met with equality.
","3.1. Partitionings, Packings, and Coverings",[0],[0]
"Likewise, a packing constraint can be expressed using a `-uniform matroid with independent sets:
I` = { S ⊆ V× : |S| ≤ ` } .","3.1. Partitionings, Packings, and Coverings",[0],[0]
"(4)
If we set F× = I` ∩Ik, where k = 1 is the vector of all 1s, this expresses a packing constraint, and is the intersection of two matroids defined on V×.","3.1. Partitionings, Packings, and Coverings",[0],[0]
"In fact, the intersection of a matroid and a `-uniform matroid is still a single matroid, called its `-truncation (Schrijver, 2003), and hence I` ∩ Ik constitutes only a single matroid.","3.1. Partitionings, Packings, and Coverings",[0],[0]
"Having discussed how matroid constraints on the rows of V× can be used to express the partitioning, packing and covering problems, we now turn our attention to how matroid constraints on the columns can be used to represent more general constraints on the blocks.",3.2. Block Constraints,[0],[0]
"Imagine that each block is required to satisfy its own matroid independence constraint: we are given m matroids {(V, Ii)}i∈[m] with independent sets Ii for i ∈",3.2. Block Constraints,[0],[0]
"[m], where each matroid is defined over the original ground set V .",3.2. Block Constraints,[0],[0]
"Using the expanded ground set and taking S ⊆ V×, we have that Aπi ∈ Ii if and only if col (S,",3.2. Block Constraints,[0],[0]
"i) ∈ Ii.
",3.2. Block Constraints,[0],[0]
"Given a size-m set of matroids {Mi}i∈[m] where Mi = (V, Ii), the matroid union theorem (Schrijver, 2003, Thm. 42.1a) states that a new matroid can be defined on V× with independent sets Ib = {I1 ] I2 ] . . .",3.2. Block Constraints,[0],[0]
],3.2. Block Constraints,[0],[0]
Im :,3.2. Block Constraints,[0],[0]
"Ii ∈ Ii,∀i ∈",3.2. Block Constraints,[0],[0]
[m]}.,3.2. Block Constraints,[0],[0]
"Despite there being a matroid for each block, the disjoint union of these matroids is a single matroid on V×.
One of the simplest examples of such constraints, and the one that we use in our case study (Section 6), simply places an upper bound on the number of elements within each block.",3.2. Block Constraints,[0],[0]
The resulting matroid is a column-based analogue of Eq.,3.2. Block Constraints,[0],[0]
(3).,3.2. Block Constraints,[0],[0]
"In order to define the expanded objective F× in terms of submodular functions on the original ground set V , we will define set functions via mappings from subsets of an expanded ground set to subsets of the original ground set.",4. Cross-block Interaction,[0],[0]
"The next result shows that in some cases, composition and setto-set mappings preserve submodularity or supermodularity.
",4. Cross-block Interaction,[0],[0]
Lemma 1.,4. Cross-block Interaction,[0],[0]
"Let V ′, V be two ground sets and define a set-toset mapping functionG :",4. Cross-block Interaction,[0],[0]
"2V
′",4. Cross-block Interaction,[0],[0]
→ 2V .,4. Cross-block Interaction,[0],[0]
"Also, let f : 2V → R+ be monotone non-decreasing and submodular, and let g : 2V → R+ be monotone non-decreasing and supermodular.",4. Cross-block Interaction,[0],[0]
"Then:
1.",4. Cross-block Interaction,[0],[0]
"If G is monotone non-decreasing (i.e. G(S) ⊆ G(T ) whenever S ⊆ T ), then f ◦ G and g ◦",4. Cross-block Interaction,[0],[0]
"G are both
monotone non-decreasing.1
2.",4. Cross-block Interaction,[0],[0]
"If ∀S, T ⊆ V ′, G(S ∪T ) = G(S)∪G(T ) and G(S ∩ T ) ⊆ G(S) ∩ G(T ), then f ◦ G : 2V ′",4. Cross-block Interaction,[0],[0]
"→ R+ is submodular.
",4. Cross-block Interaction,[0],[0]
3.,4. Cross-block Interaction,[0],[0]
"If ∀S, T ⊆ V ′, G(S ∪T ) ⊇ G(S)∪G(T ) and G(S ∩ T ) = G(S) ∩ G(T ), then g ◦ G : 2V ′",4. Cross-block Interaction,[0],[0]
"→ R+ is supermodular.
",4. Cross-block Interaction,[0],[0]
Proof.,4. Cross-block Interaction,[0],[0]
In Appendix C. The objective defined in Eq.,4. Cross-block Interaction,[0],[0]
"(2) involves cross block interaction terms via Fi,j(Aπi , A π j ) for all i, j ∈",4. Cross-block Interaction,[0],[0]
[m].,4. Cross-block Interaction,[0],[0]
"The ground set expansion defined in Section 3, combined with the above lemma, surprisingly allows many such interaction terms to be handled in a way that preserves submodularity.",4. Cross-block Interaction,[0],[0]
"To this end, we define three additional set-to-set (i.e. 2V × → 2V ) mappings corresponding to union, intersection, or symmetric difference of the ith and jth mapped subsets:
G i,j (S) , col (S, i) col (S, j)
where = ∪,∩ or4.",4. Cross-block Interaction,[0],[0]
"The following lemma, which largely follows from Lemma 1, shows that these can be used in a way that preserves sub/supermodularity:
Lemma 2.",4. Cross-block Interaction,[0],[0]
"Let f : 2V → R be monotone non-decreasing submodular, m : 2V → R be non-negative modular, and g : 2V → R be monotone non-decreasing supermodular.",4. Cross-block Interaction,[0],[0]
"Then f ◦G∪i,j : 2V
× → R is monotone non-decreasing submodular, g ◦G∩i,j : 2V
× → R is monotone non-decreasing supermodular, and m ◦",4. Cross-block Interaction,[0],[0]
"G4i,j : 2V
× → R is non-negative submodular.
",4. Cross-block Interaction,[0],[0]
Proof.,4. Cross-block Interaction,[0],[0]
"In Appendix C.
If one wishes to reduce the number of common elements in pairs of blocks, a useful cross-block interaction term is |V | − ∣∣G∩i,j (S)∣∣. Because the cardinality function is non-decreasing and modular,
∣∣G∩i,j (S)∣∣ is non-decreasing supermodular by Lemma 2.",4. Cross-block Interaction,[0],[0]
"A submodular function (including the constant |V |) minus a supermodular function is submodular, and thus, the above interaction function is submodular and non-increasing.
",4. Cross-block Interaction,[0],[0]
"In the partitioning and packing settings, if we have a nondecreasing submodular function f that measures the diversity of a set, one could use f ( G∪i,j (S) ) , which is both submodular and non-decreasing, as the cross-block interaction term, to encourage pairwise diversity.",4. Cross-block Interaction,[0],[0]
"If one wants blocks to have large pairwise differences, then a natural cross-block interaction term is |G4i,j (S)|.",4. Cross-block Interaction,[0],[0]
"This function is again submodular, but is non-monotone (it is neither non-increasing nor non-decreasing).
",4. Cross-block Interaction,[0],[0]
1Note that “◦” denotes function composition.,4. Cross-block Interaction,[0],[0]
"Unfortunately, f ◦G4i,j is not necessarily submodular, even for a submodular f , and has no obvious difference representation (Iyer & Bilmes, 2012).","4.1. Submodular Approximation of f ◦G4i,j",[0],[0]
"However, we can derive (non-monotone) submodular bounds based on the curvature.","4.1. Submodular Approximation of f ◦G4i,j",[0],[0]
A normalized monotone submodular function f :,"4.1. Submodular Approximation of f ◦G4i,j",[0],[0]
2V → R has curvature c if f(v|S) ≥ (1 − c)f(v) for all S ⊆ V and V 3 v /∈,"4.1. Submodular Approximation of f ◦G4i,j",[0],[0]
"S, where f(v|S) , f(S ∪ {v})","4.1. Submodular Approximation of f ◦G4i,j",[0],[0]
− f(S) is the gain.,"4.1. Submodular Approximation of f ◦G4i,j",[0],[0]
"Curvature is easily computed in O(n) time since c = 1 −minv∈V f(v|V \ v)/f(v), where c ∈","4.1. Submodular Approximation of f ◦G4i,j",[0],[0]
"[0, 1].","4.1. Submodular Approximation of f ◦G4i,j",[0],[0]
"Modular functions have c = 0, fully curved functions have c = 1, and submodular function classes can be restricted to those having a particular c, since many useful submodular functions have non-extreme curvature, e.g. sums of nonasymptoting concave functions composed with non-negative modular functions (Stobbe & Krause, 2010).
","4.1. Submodular Approximation of f ◦G4i,j",[0],[0]
"Given a set X ⊆ V , a normalized monotone submodular function f with curvature c, and any ordering σ =","4.1. Submodular Approximation of f ◦G4i,j",[0],[0]
"(σ1, σ2, . . .","4.1. Submodular Approximation of f ◦G4i,j",[0],[0]
", σn) of V such that X = { σ1, σ2, . . .","4.1. Submodular Approximation of f ◦G4i,j",[0],[0]
", σ|X| } , a modular subgradient mXf of f can be obtained (Fujishige, 2005)","4.1. Submodular Approximation of f ◦G4i,j",[0],[0]
"where mXf (X) = f(X), ∀Y,mXf (Y ) ≤ f(Y ), and where mXf (σi) = f(σi|σ1, σ2,","4.1. Submodular Approximation of f ◦G4i,j",[0],[0]
. .,"4.1. Submodular Approximation of f ◦G4i,j",[0],[0]
.,"4.1. Submodular Approximation of f ◦G4i,j",[0],[0]
", σi−1).","4.1. Submodular Approximation of f ◦G4i,j",[0],[0]
"Since f is monotone, the subgradient is non-negative.","4.1. Submodular Approximation of f ◦G4i,j",[0],[0]
"Also, for any Y , submodularity ensures that mXf (v) ≥ (1 − c)f(v) and hence f(Y ) ≥","4.1. Submodular Approximation of f ◦G4i,j",[0],[0]
mXf (Y ) ≥,"4.1. Submodular Approximation of f ◦G4i,j",[0],[0]
"(1 − c)f(Y ) for any X,Y , where the second inequality follows since f is normalized submodular.","4.1. Submodular Approximation of f ◦G4i,j",[0],[0]
"This enables us to obtain a non-monotone submodular lower bound via f ◦G4i,j(S) ≥ mXf ◦G 4 i,j(S) ≥ (1−c)f ◦G 4 i,j(S) for any X ∈ V that approximates the original problem: Lemma 3.","4.1. Submodular Approximation of f ◦G4i,j",[0],[0]
"Given any algorithm that produces a solution Ŝ having the property that F (Ŝ) + mXf ◦ G 4 i,j(Ŝ) ≥
αmaxS∈F× ( F (S) +mXf ◦G 4 i,j(S) ) for α > 0, then Ŝ also has the property that F (Ŝ)","4.1. Submodular Approximation of f ◦G4i,j",[0],[0]
+,"4.1. Submodular Approximation of f ◦G4i,j",[0],[0]
f ◦,"4.1. Submodular Approximation of f ◦G4i,j",[0],[0]
"G4i,j(Ŝ) ≥ α(1","4.1. Submodular Approximation of f ◦G4i,j",[0],[0]
− c) maxS∈F×,"4.1. Submodular Approximation of f ◦G4i,j",[0],[0]
"( F (S) + f ◦G4i,j(S) )","4.1. Submodular Approximation of f ◦G4i,j",[0],[0]
"= α(1− c)OPT.
Proof.","4.1. Submodular Approximation of f ◦G4i,j",[0],[0]
In Appendix C.,"4.1. Submodular Approximation of f ◦G4i,j",[0],[0]
"Eq. (2) can now be written in terms of the expanded ground set as F× : 2V × → R:
F×(S) =",5. Algorithms and Optimization,[0],[0]
"(5)
λ1 min i fi (col (S, i))",5. Algorithms and Optimization,[0],[0]
+,5. Algorithms and Optimization,[0],[0]
"λ2 m ∑ i∈[m] fi (col (S, i))
+ λ3",5. Algorithms and Optimization,[0],[0]
min,5. Algorithms and Optimization,[0],[0]
"i,j∈[m],i<j F×i,j(S) + λ4( m 2 ) ∑ i,j∈[m],i<j F×i,j(S)
",5. Algorithms and Optimization,[0],[0]
Our approach in maximizing Eq.,5. Algorithms and Optimization,[0],[0]
(2) subject to grouping constraints is to optimize Eq.,5. Algorithms and Optimization,[0],[0]
"(5) subject to the intersection
Algorithm 1 Adaptation of the GeneralGreedSAT algorithm of Wei et al. (2015) to handle matroid constraints, crossblock interactions, and coverings/packings as well as partitions.",5. Algorithms and Optimization,[0],[0]
"The functions f×1 , . . .",5. Algorithms and Optimization,[0],[0]
", f × m : 2
V× → R are monotone non-decreasing, non-negative and submodular, ηf× is a uniform upper bound on the f",5. Algorithms and Optimization,[0],[0]
"× i ’s, each I1, . . .",5. Algorithms and Optimization,[0],[0]
", Ik ⊆ 2V × is the set of independent sets of a matroid on V×, and CALLBACK is a helper function that returns an α-approximation to the submodular maximization problem argmaxS∈⋂ki=1 Ii F×c (S) in polynomial time.
",5. Algorithms and Optimization,[0],[0]
"Bisection ( , V×,m, f×1 , . . .",5. Algorithms and Optimization,[0],[0]
", f × m, ηf× , k, I1, . . .",5. Algorithms and Optimization,[0],[0]
", Ik,CALLBACK, α ) :
1 Define F×c (S) =",5. Algorithms and Optimization,[0],[0]
(∑m i=1,5. Algorithms and Optimization,[0],[0]
"min { c, f×i (S) }) /m",5. Algorithms and Optimization,[0],[0]
"2 Initialize cmin = 0, cmax = ηf× , S = ∅ 3",5. Algorithms and Optimization,[0],[0]
While cmax − cmin > : 4 Let c = (cmax − cmin) /2,5. Algorithms and Optimization,[0],[0]
"and Sc = CALLBACK (V×, F×c , k, I1, . . .",5. Algorithms and Optimization,[0],[0]
", Ik) 5",5. Algorithms and Optimization,[0],[0]
"If F×c (Sc) < αc, then let cmax = c, else let cmin = c and S = Sc 6 Return S
of multiple matroid constraints defined on the expanded ground set.",5. Algorithms and Optimization,[0],[0]
"The matroid constraints ensure that the solution can be transformed back to the original ground set, while preserving the approximation ratio.",5. Algorithms and Optimization,[0],[0]
"The algorithm used depends both on which terms are present (i.e. have nonzero associated λs), and whether the submodular functions are monotone.
",5. Algorithms and Optimization,[0],[0]
"When the overall objective is non-monotone submodular (so λ1 = 0 and λ3 = 0), the problem of maximizing Eq.",5. Algorithms and Optimization,[0],[0]
(5) becomes one of non-monotone submodular maximization subject to matroid constraints.,5. Algorithms and Optimization,[0],[0]
"One can use algorithms such as Lee et al. (2010); Ward (2012), or the more recent, faster, and scalable approach given in Feldman et al. (2017).",5. Algorithms and Optimization,[0],[0]
"When using f ◦G4i,j(S) as a non-submodular block pair reward for non-robust coverings, a modular approximation adjusts any guarantees by 1 − c (Lemma 3).",5. Algorithms and Optimization,[0],[0]
"The non-robust packing or partitioning problem reduces to monotone submodular maximization subject to two matroid constraints, for which there are a variety of good solutions.",5. Algorithms and Optimization,[0],[0]
"For example, the efficient greedy algorithm (Nemhauser & Wolsey, 1978) solves this problem with a 1/3 guarantee while more recent but also more complicated approaches, such as Ward (2012), can solve this with an approximation ratio of (k + 3)/2 + for ` matroids (here k = 2).
",5. Algorithms and Optimization,[0],[0]
"When all of the involved submodular functions are monotone non-decreasing, a single robust term can be handled (one of λ1 or λ3 may be nonzero).",5. Algorithms and Optimization,[0],[0]
"Here, we are inspired by an approach originally used for robust submodular optimization (Krause et al., 2008) where the goal is to find the max of the min over a set of submodular functions subject to a cardinality constraint.",5. Algorithms and Optimization,[0],[0]
"In Wei et al. (2015), this was extended to apply to a mixed robust/average objective over partitions.",5. Algorithms and Optimization,[0],[0]
"It turns out that essentially the same idea—this is Algorithm 1—applies to the more general case of coverings and packings, as well as when there are matroids constraining each block individually, and also when the blocks’ scores interact.
",5. Algorithms and Optimization,[0],[0]
"In brief, this algorithm proceeds by iteratively optimizing inner submodular optimization problems using a provided CALLBACK function, which is assumed to run in polynomial time, and return an α-approximation.",5. Algorithms and Optimization,[0],[0]
The final algorithm achieves a nearly constant-factor approximation for a constant fraction of the blocks.,5. Algorithms and Optimization,[0],[0]
"As the fraction of the blocks shrinks, the guarantee for those blocks grows, and the guarantee holds simultaneously for a range over the fractions.
",5. Algorithms and Optimization,[0],[0]
Theorem 1.,5. Algorithms and Optimization,[0],[0]
"A call to Algorithm 1 will perform dlog2 (ηf/ )e calls to CALLBACK, each of which will perform polynomially many evaluations of F×c , each of which evaluates all m f×i s once.
",5. Algorithms and Optimization,[0],[0]
"The resulting set S will satisfy the constraints, and for any γ ∈ (0, α) there will exist at least dm (α− γ) /",5. Algorithms and Optimization,[0],[0]
(1− γ)e indices,5. Algorithms and Optimization,[0],[0]
i ∈,5. Algorithms and Optimization,[0],[0]
[m] for which f×i (S) >,5. Algorithms and Optimization,[0],[0]
"γ (OPT− ), where OPT = maxS∈⋂ki=1 Ii F× (S) is the optimum.",5. Algorithms and Optimization,[0],[0]
Proof.,5. Algorithms and Optimization,[0],[0]
"The proof technique follows that of Wei et al. (2015, Theorem 11), but we include it in Appendix C for completeness, and to show that it applies to our more general case (i.e., covers, packings, block-specific matroid constraints, and cross-block interactions).
",5. Algorithms and Optimization,[0],[0]
This algorithm depends on a CALLBACK that deterministically returns an α-approximation to an inner submodular optimization problem.,5. Algorithms and Optimization,[0],[0]
"However, many submodular maximization algorithms are randomized, and have approximation guarantees that hold only in expectation.",5. Algorithms and Optimization,[0],[0]
"With a bit of extra work, such an algorithm can be used as well.",5. Algorithms and Optimization,[0],[0]
"First, we must convert the in-expectation guarantee into a high-probability guarantee using the following lemma that requires only an approximation bound:
Lemma 4.",5. Algorithms and Optimization,[0],[0]
"Let A be a randomized algorithm for submodular maximization that has an α-approximation guarantee in expectation, i.e. for which E [f (S)]",5. Algorithms and Optimization,[0],[0]
"≥ αf (S∗), where f is the submodular function we wish to maximize, S is the result of algorithm A, and S∗ is the maximizer of f .",5. Algorithms and Optimization,[0],[0]
"For
parameters β, δ ∈ (0, 1), suppose that we run algorithm A k times, where k = ⌈( ln 1δ ) /",5. Algorithms and Optimization,[0],[0]
"( ln 1−αβ1−α )⌉ , yielding results S1, S2, . . .",5. Algorithms and Optimization,[0],[0]
", Sk. Take S = argmaxSi:i∈[k] f (Si) to be the best of these results.",5. Algorithms and Optimization,[0],[0]
"Then S will have an approximation ratio of αβ, i.e. f (S) ≥ αβf (S∗), with probability 1− δ.
Proof.",5. Algorithms and Optimization,[0],[0]
"In Appendix C.
As was shown in Theorem 1, CALLBACK will be called at most dlog2 (ηf/ )e times, so it follows from the union bound that if we use the procedure of Lemma 4, then, with probability 1 − δ dlog2 (ηf/ )e, every call to CALLBACK will return an αβ-approximation, and the result of Theorem 1 will hold (with αβ substituted for α).
",5. Algorithms and Optimization,[0],[0]
"The ability to handle a mixed robust/average objective, however, comes at a cost.",5. Algorithms and Optimization,[0],[0]
"Because Theorem 1 only applies when all of the involved submodular functions are monotone non-decreasing, we cannot use the intersection and symmetric-difference-based cross-block interaction terms— only the union-based terms are possible.",5. Algorithms and Optimization,[0],[0]
Non-monotone interaction terms can only be used with a non-robust objective.,5. Algorithms and Optimization,[0],[0]
Finding an algorithm that can handle both robustness and non-monotone interactions is therefore an interesting open problem that we leave to future work.,5. Algorithms and Optimization,[0],[0]
"We validate our proposed approach with a case study in the setting of Canini et al. (2016), in which the task is to construct an ensemble-of-lattices machine learning model.",6. Case Study,[0],[0]
"Each lattice model (Gupta et al., 2016) in the ensemble is defined on a subset of the features—intuitively, two features interact non-linearly if they are included in the same lattice, and interact only linearly if they are not—so our primary goal is to choose subsets of features that interact well with each other, with our secondary goal being to reduce redundancy in pairs of subsets.",6. Case Study,[0],[0]
"Notice that this is not a feature selection problem—typically, every feature will be included in at least one lattice—the task is to determine which features should interact non-linearly.",6. Case Study,[0],[0]
"For more details, please see Appendix A.
Our goals are to demonstrate that (i) we can successfully find good approximate maximizers of the proposed objective function, and (ii) the inclusion of pairwise diversity terms results in improved diversity.
",6. Case Study,[0],[0]
"We compare to two baselines, the “Crystals” and “Random Tiny Lattice (RTL)” algorithms of Canini et al. (2016).",6. Case Study,[0],[0]
"The first of these—the current state-of-the-art—is essentially a heuristic for choosing diverse ensembles, while the second simply chooses each lattice’s features uniformly at random.
",6. Case Study,[0],[0]
"The dataset contains 463 154 samples with 29 informative
features plus a binary label indicating whether a particular visual element should be displayed on a web page.",6. Case Study,[0],[0]
"The dataset was randomly partitioned into training, validation and testing subsets containing 80%, 10% and 10% of the data, respectively (the validation set was only used for hyperparameter optimization of the baseline Crystals algorithm).",6. Case Study,[0],[0]
Our ground set V consists of the n = 29 features.,6.1. Choice of f,[0],[0]
We began by finding a submodular function f :,6.1. Choice of f,[0],[0]
2V → R+ for which f (S) represents roughly how well a single lattice model on the features in S would perform.,6.1. Choice of f,[0],[0]
"To this end, we chose f to have the form f (S) = β + ∑ A∈A αA √ |A ∩ S|, where A consists of all 1- and 2-element subsets of V .",6.1. Choice of f,[0],[0]
"Observe that √ |A ∩ S| is submodular, non-negative, and monotone non-decreasing, so if β and αA are non-negative, then f will likewise be submodular, non-negative, and monotone.
",6.1. Choice of f,[0],[0]
"Based on 9 191 random subsets of sizes between two and ten, we learned the β and αA parameters to minimize the squared error between f (S) and the training accuracy of a lattice model trained on the features contained in S. The result is the f that we use throughout.",6.1. Choice of f,[0],[0]
"Our goal here is essentially identical to Canini et al. (2016)— we seek to choose m = 8 lattices, each containing up to 8 features (via a matroid constraint), by finding the S ⊆ V× maximizing:∑
i∈[m]
f (col (S, i))",6.2. Covering,[0],[0]
"+ λ4 |V | ∑ i,j∈[m]∧i 6=j ∣∣∣G4i,j(S)∣∣∣ (6)",6.2. Covering,[0],[0]
"The 8 lattices together should have good performance (the first term), and the feature subsets should be relatively pairwise distinct, i.e. have large symmetric differences (this is the second term).",6.2. Covering,[0],[0]
"We henceforth refer to the first (intrablock diversity) term, representing the individual quality of the lattices, as the “quality” term, and the second (not including the λ4-scaling), representing the inter-block diversity, as the “diversity” term.
",6.2. Covering,[0],[0]
We optimized Eq.,6.2. Covering,[0],[0]
"(6) for various choices of λ4 using the randomized algorithm of Feldman et al. (2017) combined with the procedure of Lemma 4, with β = 0.5 and δ = 0.1.",6.2. Covering,[0],[0]
Each optimization took between 2 and 30 seconds on a Xeon E5-2690.,6.2. Covering,[0],[0]
The results are shown in Figure 2.,6.2. Covering,[0],[0]
"The left-hand plot shows that, as the trade-off parameter λ4 increases, the relative magnitude of the quality term decreases, and of the diversity term increases, as expected.",6.2. Covering,[0],[0]
"The right-hand plot shows that, when the λ4 parameter is sufficiently large, the diversity term is “balanced” with the quality term (or is larger), and the ensembles found by our approach outperform those of both the state-of-the-
art Crystals algorithm (which uses heuristics to encourage diversity) and the 90th percentile of RTLs, albeit by a small amount.",6.2. Covering,[0],[0]
"More importantly, the leftmost points in the righthand plot of Figure 2, in which the diversity portion of the objective is essentially zero, have significantly worse testing accuracies than those with larger λ4s.",6.2. Covering,[0],[0]
This indicates that the use of pairwise diversity terms may be broadly beneficial to submodular grouping problems.,6.2. Covering,[0],[0]
"Appendix B contains additional case studies exploring the efficacy of the mixed robust/average objective for partitioning and packing, where the task is to maximize:∑
i∈[m]
f (col (S, i))",6.3. Partitioning and Packing,[0],[0]
+,6.3. Partitioning and Packing,[0],[0]
λ3 min,6.3. Partitioning and Packing,[0],[0]
"i,j∈[m]∧i 6=j
f ( G∪i,j(S) ) (7)
Unlike in Eq. (6), the “diversity” term is a minimum over monotone non-decreasing submodular functions, instead of a sum over non-monotone submodular functions.",6.3. Partitioning and Packing,[0],[0]
"The results demonstrate that Algorithm 1 is effective at optimizing this objective, but also reveal that, for this problem and data set, the above diversity term is not helpful—and can be harmful if the quality term is overpowered.",6.3. Partitioning and Packing,[0],[0]
The lesson is that cross-block diversity is not a magic bullet—it must be chosen appropriately for the problem.,6.3. Partitioning and Packing,[0],[0]
"We have introduced a new class of submodular optimization problems involving grouping ground elements together into multiple sets and the first, as far as we know, to involve
block-block interaction terms as well as general (matroid intersection) block constraints.
",6.4. Discussion,[0],[0]
"Another potential application of our method is sensitivity analysis of machine learning systems (i.e., does an ML model vary greatly when trained on different representative but mutually diverse subsets of the training data?) and also a form of robustness analysis (i.e., how does an ML system perform when tested on different representative but mutually diverse subsets of test data?).",6.4. Discussion,[0],[0]
"These are important questions, considering for example the recent interest in adversarial examples in ML.
",6.4. Discussion,[0],[0]
"Also, since convex combinations of submodular components preserve submodularity, it might also in the future be interesting to consider some form of Pareto frontier of solution sets for different convex mixtures.
",6.4. Discussion,[0],[0]
Acknowledgments: This work was done in part during a time when author Bilmes was visiting Google AI research and also visiting the Simons Institute for the Theory of Computing.,6.4. Discussion,[0],[0]
"This material is based upon work supported by the National Science Foundation under Grant No. IIS1162606, the National Institutes of Health under award R01GM103544, and by a Google, a Microsoft, a Facebook, and an Intel research award.",6.4. Discussion,[0],[0]
"This work was supported in part by TerraSwarm, one of six centers of STARnet, a Semiconductor Research Corporation program sponsored by MARCO and DARPA",6.4. Discussion,[0],[0]
"We introduce the problem of grouping a finite set V into m blocks where each block is a subset of V and where: (i) the blocks are individually highly valued by a submodular function f (both robustly and in the average case) while satisfying block-specific matroid constraints; and (ii) block scores interact where blocks are jointly scored highly via f , thus making the blocks mutually non-redundant.",abstractText,[0],[0]
"Submodular functions are good models of information and diversity; thus, the above can be seen as grouping V into matroid constrained blocks that are both intraand inter-diverse.",abstractText,[0],[0]
"Potential applications include forming ensembles of classification/regression models, partitioning data for parallel processing, and summarization.",abstractText,[0],[0]
"In the non-robust case, we reduce the problem to non-monotone submodular maximization subject to multiple matroid constraints.",abstractText,[0],[0]
"In the mixed robust/average case, we offer a bicriterion guarantee for a polynomial time deterministic algorithm and a probabilistic guarantee for randomized algorithm, as long as the involved submodular functions (including the inter-block interaction terms) are monotone.",abstractText,[0],[0]
"We close with a case study in which we use these algorithms to find high quality diverse ensembles of classifiers, showing good results.",abstractText,[0],[0]
Constrained Interacting Submodular Groupings,title,[0],[0]
Modern machine learning methods have demonstrated stateof-art performance in representing complex functions in a variety of applications.,1. Introduction,[0],[0]
"Nevertheless, the translation of complex learning methods in natural sciences and in the clinical domain is still challenged by the need of interpretable solutions.",1. Introduction,[0],[0]
"To this end, several approaches have been proposed in order to constrain the solution dynamics to plausible forms such as boundedness (Da Veiga & Marrel, 2012), monotonicity (Riihimäki & Vehtari, 2010), or mechanistic behaviors (Alvarez et al., 2013).",1. Introduction,[0],[0]
"This is a crucial require-
*Equal contribution 1University of Cote d’Azur, INRIA Sophia Antipolis, EPIONE research group, France 2EURECOM, Department of Data Science, Sophia Antipolis, France.",1. Introduction,[0],[0]
"Correspondence to: Marco Lorenzi <marco.lorenzi@inria.fr>, Maurizio Filippone <maurizio.filippone@eurecom.fr>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
ment to provide a more precise and realistic description of natural phenomena.",1. Introduction,[0],[0]
"For example, monotonicity of the interpolating function is a common assumption when modeling disease progression in neurodegenerative diseases (Lorenzi et al., 2017; Donohue et al., 2014), while bio-physical or mechanistic models are necessary when analyzing and simulating experimental data in bio-engineering (Vyshemirsky & Girolami, 2007; Konukoglu et al., 2011).
",1. Introduction,[0],[0]
"However, accounting for the complex properties of biological systems in data-driven modeling approaches poses important challenges.",1. Introduction,[0],[0]
"For example, functions are often non-smooth and characterized by nonstationaries which are difficult to encode in “shallow” models.",1. Introduction,[0],[0]
"Complex cases can arise already in classical ODE systems for certain configurations of the parameters, where functions can exhibit sudden temporal changes (Goel et al., 1971; FitzHugh, 1955).",1. Introduction,[0],[0]
"Within this context, approaches based on stationary models, even when relaxing the smoothness assumptions, may lead to suboptimal results for both data modeling (interpolation), and estimation of dynamics parameters.",1. Introduction,[0],[0]
To provide insightful illustrations of this problem we anticipate the results of Section 4.4.1 and Figure 5.,1. Introduction,[0],[0]
"Moreover, the application to real data requires to account for the uncertainty of measurements and underlying model parameters, as well as for the – often large – dimensionality characterizing the experimental data.",1. Introduction,[0],[0]
"Within this context, deep probabilistic approaches may represent a promising modeling tool, as they combine the flexibility of deep models with a systematic way to reason about uncertainty in model parameters and predictions.",1. Introduction,[0],[0]
"The flexibility of these approaches stems from the fact that deep models implement compositions of functions, which considerably extend the complexity of signals that can be represented with “shallow” models (LeCun et al., 2015).",1. Introduction,[0],[0]
"Meanwhile, their probabilistic formulation introduces a principled approach to quantify uncertainty in parameters estimation and predictions, as well as to model selection problems (Neal, 1996; Ghahramani, 2015).
",1. Introduction,[0],[0]
"In this work, we aim at extending deep probabilistic models to account for constraints on their dynamics.",1. Introduction,[0],[0]
"In particular, we focus on a general and flexible formulation capable of imposing a rich set of constraints on functions and derivatives of any order.",1. Introduction,[0],[0]
"We focus on: i) equality constraints on the function and its derivatives, required when the model should satisfy given physical laws implemented through
a mechanistic description of a system of interest; and ii) inequality constraints, arising in problems where the class of suitable functions is characterized by specific properties, such as monotonicity or convexity/concavity (Riihimäki & Vehtari, 2010).
",1. Introduction,[0],[0]
"In case of equality constraints, we tackle the challenge of parameters inference in Ordinary Differential Equations (ODE).",1. Introduction,[0],[0]
Exact parameter inference of ODE models is computationally expensive due to the need for repeatedly solving ODEs within the Bayesian setting.,1. Introduction,[0],[0]
"To this end, previous works attempted to recover tractability by introducing approximate solutions of ODEs (see, e.g., Macdonald & Husmeier (2015) for a review).",1. Introduction,[0],[0]
"Following these ideas, we introduce “soft” constraints through a probabilistic formulation that penalizes functions violating the ODE on a set of virtual inputs.",1. Introduction,[0],[0]
"Note that this is in contrast to previous approaches, such as the ones proposed with probabilistic ODE solvers (Wheeler et al., 2014; Schober et al., 2014), where a given dynamics is strictly enforced to the model posterior.",1. Introduction,[0],[0]
"By deriving a lower bound on the model evidence, we enable the use of stochastic variational inference to achieve end-to-end posterior inference over model and constraint parameters.
",1. Introduction,[0],[0]
"In what follows we shall focus on a class of deep probabilistic models implementing a composition of Gaussian processes (GPs) (Rasmussen & Williams, 2006) into Deep Gaussian Processes (DGPs) (Damianou & Lawrence, 2013).",1. Introduction,[0],[0]
"More generally, our formulation can be straightforwardly extended to probabilistic Deep Neural Networks (DNNs) (Neal, 1996).",1. Introduction,[0],[0]
"On the practical side, our formulation allows us to take advantage of automatic differentiation tools, leading to flexible and easy-to-implement methods for inference in constrained deep probabilistic models.",1. Introduction,[0],[0]
"As a result, our method scales linearly with the number of observations and constraints.",1. Introduction,[0],[0]
"Furthermore, in the case of mean-field variational inference, it also scales linearly with the number of parameters in the constraints.",1. Introduction,[0],[0]
"Finally, it can easily be parallelized/distributed and exploit GPU computing.
",1. Introduction,[0],[0]
"Through an in-depth series of experiments, we demonstrate that our proposal achieves state-of-the-art performance in a number of constrained modeling problems while being characterized by attractive scalability properties.",1. Introduction,[0],[0]
"The paper is organized as follows: Section 2 reports on related work, whereas the core of the methodology is presented in Section 3.",1. Introduction,[0],[0]
Section 4 contains an in-depth validation of the proposed model against the state-of-the-art.,1. Introduction,[0],[0]
"We demonstrate the application of equality constraints in the challenging problem of parameter inference in ODE, while we showcase the application of inequality constraints in the monotonic regression of count data.",1. Introduction,[0],[0]
Additional insights and conclusions are given in Section 5.,1. Introduction,[0],[0]
Results that we could not fit in the manuscript are deferred to the supplementary material.,1. Introduction,[0],[0]
"Equality constraints where functions are enforced to model the solution of ODE systems have been considered in a variety of problems, particularly in the challenging task of accelerated inference of ODE parameters.",2. Related Work,[0],[0]
Previous approaches to accelerate ODE parameter optimization involving interpolation date back to Varah (1982).,2. Related Work,[0],[0]
"This idea has been developed in several ways, including splines, GPs, and Reproducing Kernel Hilbert spaces.",2. Related Work,[0],[0]
"Works that employ GPs as interpolants have been proposed in Ramsay et al. (2007), Liang & Wu (2008), Calderhead et al. (2009), and Campbell & Steele (2012).",2. Related Work,[0],[0]
"Such approaches have been extended to introduce a novel formulation to regularize the interpolant based on the ODE system, notably Dondelinger et al. (2013); Barber & Wang (2014).",2. Related Work,[0],[0]
An in-depth analysis of the model in Barber & Wang (2014) is provided by Macdonald et al. (2015).,2. Related Work,[0],[0]
"Recently, Gorbach et al. (2017) extended previous works by proposing mean-field variational inference to obtain an approximate posterior over ODE parameters.",2. Related Work,[0],[0]
"Our work improves previous approaches by considering a more general class of interpolants than “shallow” GPs, and proposes a scalable framework for inferring the family of interpolating functions jointly with the parameters of the constraint, namely ODE parameters.
",2. Related Work,[0],[0]
Another line of research that builds on gradient matching approaches uses a Reproducing Kernel Hilbert space formulation.,2. Related Work,[0],[0]
"For example, González et al. (2014) proposes to exploit the linear part of ODEs to accelerate the interpolation, while Niu et al. (2016) exploits the quadratic dependency of the objective with respect to the parameters of the interpolant to improve the computational efficiency of the ODE regularization.",2. Related Work,[0],[0]
"Interestingly, inspired by Calandra et al. (2016), the latter approach was extended to handle nonstationarity in the interpolation through warping (Niu et al., 2018).",2. Related Work,[0],[0]
"The underlying idea is to estimate a transformation of the input domain to account for nonstationarity of the signal, in order to improve the fitting of stationary GP interpolants.",2. Related Work,[0],[0]
"A key limitation of this approach is the lack of a probabilistic formulation, which prevents one from approximating the posterior over ODE parameters.",2. Related Work,[0],[0]
"Moreover, the warping approach is tailored to periodic functions, thus limiting the generalization to more complex signals.",2. Related Work,[0],[0]
"In our work, we considerably improve on these aspects by effectively modeling the warping through GPs/DGPs that we infer jointly with ODE parameters.
",2. Related Work,[0],[0]
Inequality constraints on the function derivatives have been considered in several works such as in Meyer (2008); Groeneboom & Jongbloed (2014); Mašić et al. (2017); Riihimäki & Vehtari (2010); Da Veiga & Marrel (2012); Salzmann & Urtasun (2010).,2. Related Work,[0],[0]
"In particular, the GP setting provides a solid and elegant theoretical background for tackling this problem; thanks to the linearity of differentiation,
both mean and covariance functions of high-order derivatives of GPs can be expressed in closed form, leading to exact formulations for linearly-constrained GPs (Da Veiga & Marrel, 2012).",2. Related Work,[0],[0]
"In case of inequality constraints on the derivatives, instead, this introduces non-conjugacy between the likelihood imposing the derivative constraint and the GP prior, thus requiring approximations (Riihimäki & Vehtari, 2010).",2. Related Work,[0],[0]
"Although this problem can be tackled through sampling schemes or variational inference methods, such as Expectation Propagation (Minka, 2001), scalability to large dimensions and sample size represents a critical limitation.",2. Related Work,[0],[0]
"In this work, we extend these methods by considering a more general class of functions based on DGPs, and develop scalable inference that makes our method applicable to large data and dimensions.",2. Related Work,[0],[0]
In this section we provide a derivation of the posterior distribution of our model when we introduce equality constraints in the dynamics.,3.1. Equality constraints in probabilistic modeling,[0],[0]
Let Y be a set of n observed multivariate variables yi ∈ Rs associated with measuring times t collected into t; the extension where the n variables are measured at different times is notationally heavier but straightforward.,3.1. Equality constraints in probabilistic modeling,[0],[0]
"Let f(t) be a multivariate interpolating function with associated noise parameters ψ, and define F similarly to Y to be the realization of f at t.",3.1. Equality constraints in probabilistic modeling,[0],[0]
"In this work, f(t) will be either modeled using a GP, or deep probabilistic models based on DGPs.",3.1. Equality constraints in probabilistic modeling,[0],[0]
"We introduce functional constraints on the dynamics of the components of f(t) by specifying a family of admissible functions whose derivatives of order h evaluated at the inputs t satisfy some given constraint
Chi = { f(t) ∣∣∣∣∣dhfi(t)dth = Hhi ( t, f , df dt , . . .",3.1. Equality constraints in probabilistic modeling,[0],[0]
", dqf dtq ,θ )∣∣∣∣∣",3.1. Equality constraints in probabilistic modeling,[0],[0]
"t } .
",3.1. Equality constraints in probabilistic modeling,[0],[0]
"Here the constraint is expressed as a function of the input, the function itself, and high-order derivatives up to order q.",3.1. Equality constraints in probabilistic modeling,[0],[0]
The constraint also includes θ as dynamics parameters that should be inferred.,3.1. Equality constraints in probabilistic modeling,[0],[0]
"We are going to consider the intersection of all the constraints for a set of indices I comprising pairs (h, i) of interest
C = ⋂
(h,i)∈I
Chi
To keep the notation uncluttered, and without loss of generality, in the following we will assume that all the terms are evaluated at t; we can easily relax this by allowing for the constraints to be evaluated at different sampling points than t. As a concrete example, consider the constraints induced by the Lotka-Volterra ODE system (more details in the experiments section); for this system, θ = {α, β, γ, δ},
and the family of functions is identified by the conditions
dg1(t)
",3.1. Equality constraints in probabilistic modeling,[0],[0]
dt ∣∣∣∣∣,3.1. Equality constraints in probabilistic modeling,[0],[0]
t = H11 (f(t)),3.1. Equality constraints in probabilistic modeling,[0],[0]
∣∣∣∣∣,3.1. Equality constraints in probabilistic modeling,[0],[0]
"t = αf1(t)− βf1(t)f2(t),
dg2(t)
dt",3.1. Equality constraints in probabilistic modeling,[0],[0]
∣∣∣∣∣ t = H12 (f(t)),3.1. Equality constraints in probabilistic modeling,[0],[0]
∣∣∣∣∣,3.1. Equality constraints in probabilistic modeling,[0],[0]
t = −γf2(t),3.1. Equality constraints in probabilistic modeling,[0],[0]
+,3.1. Equality constraints in probabilistic modeling,[0],[0]
"δf1(t)f2(t),
where the products f1(t)f2(t) are element-wise.
",3.1. Equality constraints in probabilistic modeling,[0],[0]
"Denote by F̃ = {fhi} the set of realizations of f and of its derivatives at any required order h evaluated at timed t. We define the constrained regression problem through two complementary likelihood-based elements: a data attachment term p(Y |F,ψ), and a term quantifying the constraint on the dynamics, p(C|F̃ ,θ,ψD), where ψD is the associated noise parameter.",3.1. Equality constraints in probabilistic modeling,[0],[0]
"To solve the inference problem, we shall determine a lower bound for the marginal
p(Y, C|t,ψ,ψD) =",3.1. Equality constraints in probabilistic modeling,[0],[0]
"(1)∫ p(Y |F,ψ)p(C|F̃ ,θ,ψD)p(F, F̃ |t,ψ)p(θ)dFdF̃dθ,
where p(F, F̃ |t,ψ) = p(F̃ |F )p(F |t,ψ).
",3.1. Equality constraints in probabilistic modeling,[0],[0]
"Note that F̃ is in fact completely identified by F .
",3.1. Equality constraints in probabilistic modeling,[0],[0]
Equation (1) requires specifying suitable models for both likelihood and functional constraints.,3.1. Equality constraints in probabilistic modeling,[0],[0]
This problem thus implies the definition of noise models for both observations and model dynamics.,3.1. Equality constraints in probabilistic modeling,[0],[0]
"In the case of continuous observations, the likelihood can be assumed to be Gaussian:
p(Y |F,ψ) = N (Y |F,Σ(ψ)), (2)
where Σ(ψ) is a suitable multivariate covariance.",3.1. Equality constraints in probabilistic modeling,[0],[0]
"Extensions to other likelihood functions are possible, and in the experiments we show an application to regression on counts where the likelihood is Poisson with rates equal to the exponential of the elements of F .
",3.1. Equality constraints in probabilistic modeling,[0],[0]
"Concerning the noise model for the derivative observations, we assume independence across the constraints Chi so that
p(C|F̃ , θ,ψD) = ∏
(h,i)∈I
p(Chi|F̃ , θ,ψD).",3.1. Equality constraints in probabilistic modeling,[0],[0]
"(3)
We can again assume a Gaussian likelihood: p(Chi|F̃ , θ,ψD) = ∏ t N (fhi(t)|Hhi(t, F̃ , θ),ψD), (4)
or, in order to account for potentially heavy-tailed error terms on the derivative constraints, we can assume a Studentt distribution:
p(Chi|F̃ , θ,ψD) = ∏ t T (fhi(t)|Hhi(t, F̃ , θ),ψD, ν),
(5) where T (z|µ, λ, ν) ∝",3.1. Equality constraints in probabilistic modeling,[0],[0]
1λ,3.1. Equality constraints in probabilistic modeling,[0],[0]
"[1+ (z−µ)2 νλ2 ]
−(ν+1)/2.",3.1. Equality constraints in probabilistic modeling,[0],[0]
We test these two noise models for F̃ in the experiments.,3.1. Equality constraints in probabilistic modeling,[0],[0]
In the case of inequality constraints we can proceed analogously as in the previous section.,3.2. Inequality constraints in probabilistic modeling,[0],[0]
"In particular, we are interested in the class of functions satisfying the following conditions:
Chi = { f(t) ∣∣∣∣∣dhfi(t)dth > Hhi ( t, f , df dt , . . .",3.2. Inequality constraints in probabilistic modeling,[0],[0]
", dqf dtq ,θ )∣∣∣∣∣",3.2. Inequality constraints in probabilistic modeling,[0],[0]
"t } .
",3.2. Inequality constraints in probabilistic modeling,[0],[0]
"For example, a monotonic univariate regression problem can be obtained with a constraint of the form dfdt > 0.
",3.2. Inequality constraints in probabilistic modeling,[0],[0]
"In this case, the model dynamics can be enforced by a logistic function:
p(Chi|F̃ , ψD) =",3.2. Inequality constraints in probabilistic modeling,[0],[0]
"n∏ j=1
1
1 +",3.2. Inequality constraints in probabilistic modeling,[0],[0]
exp(−ψD,3.2. Inequality constraints in probabilistic modeling,[0],[0]
"dfdt (tj)) , (6)
where the parameter ψD controls the strength of the monotonicity constraint.",3.2. Inequality constraints in probabilistic modeling,[0],[0]
"After recalling the necessary methodological background, in this section we derive an efficient inference scheme for the model posterior introduced in Section 3.1.
To recover tractability, our scheme leverages on recent advances in modeling and inference in DGPs through approximation via random feature expansions (Rahimi & Recht, 2008; Cutajar et al., 2017).",3.3. Optimization and inference in constrained regression with DGPs,[0],[0]
"Denoting with F (l) the GP random variables at layer l, an (approximate) DGP is obtained by composing GPs approximated by Bayesian linear models, F (l)",3.3. Optimization and inference in constrained regression with DGPs,[0],[0]
≈ Φ(l)W,3.3. Optimization and inference in constrained regression with DGPs,[0],[0]
(l).,3.3. Optimization and inference in constrained regression with DGPs,[0],[0]
The so-called random features Φ(l) are obtained by multiplying the layer input by a random matrix Ω(l) and by applying a nonlinear transformation h(·).,3.3. Optimization and inference in constrained regression with DGPs,[0],[0]
"For example, in case of the standard RBF covariance, the elements in Ω(l) are Gaussian distributed with covariance function parameterized through the length-scale of the RBF covariance.",3.3. Optimization and inference in constrained regression with DGPs,[0],[0]
"The nonlinearity is obtained through trigonometric functions, h(·) =",3.3. Optimization and inference in constrained regression with DGPs,[0],[0]
"(cos(·), sin(·)), while the prior over the elements of W (l) is standard normal.",3.3. Optimization and inference in constrained regression with DGPs,[0],[0]
"As a result, the interpolant becomes a Bayesian Deep Neural Network (DNN), where for each layer we have weights Ω(l) and W (l), and activation functions h(·) applied to the input of each layer multiplied by the weights Ω(l).",3.3. Optimization and inference in constrained regression with DGPs,[0],[0]
"To account for function derivatives consistently with the theory developed in Cutajar et al. (2017), we need to extend the random feature expansion formulation of DGPs to highorder derivatives.",3.3.1. DERIVATIVES IN DGPS WITH RANDOM FEATURE EXPANSIONS,[0],[0]
"Fortunately, this is possible thanks to the chain rule and to the closure under linear operations of
the approximated GPs.",3.3.1. DERIVATIVES IN DGPS WITH RANDOM FEATURE EXPANSIONS,[0],[0]
"More precisely, the derivatives of a “shallow” GP model with form F = h(tΩ)W can still be expressed through linear composition of matrix-valued operators depending on W and Ω only: dFdt = dh(tΩ)",3.3.1. DERIVATIVES IN DGPS WITH RANDOM FEATURE EXPANSIONS,[0],[0]
dt W .,3.3.1. DERIVATIVES IN DGPS WITH RANDOM FEATURE EXPANSIONS,[0],[0]
The computational tractability is thus preserved and the GP function and derivatives are identified by the same sets of weights Ω and W .,3.3.1. DERIVATIVES IN DGPS WITH RANDOM FEATURE EXPANSIONS,[0],[0]
The same principle clearly extends to DGP architectures where the derivatives at each layer can be combined following the chain rule to obtain the derivatives of the output function with respect to the input.,3.3.1. DERIVATIVES IN DGPS WITH RANDOM FEATURE EXPANSIONS,[0],[0]
"In the constrained DGP setting, we are interested in carrying out inference of the functions F (l) and of the associated covariance parameters at all layers.",3.3.2. VARIATIONAL LOWER BOUND,[0],[0]
"Moreover, we may want to infer any dynamics parameters θ that parameterize the constraint on the derivatives.",3.3.2. VARIATIONAL LOWER BOUND,[0],[0]
"Within this setting, the inference of the latent variables F (l) in the marginal (1) is generally not tractable.",3.3.2. VARIATIONAL LOWER BOUND,[0],[0]
"Nevertheless, the Bayesian DNN structure provided by the random feature approximation allows the efficient estimation of its parameters, and the tractability of the inference is thus recovered.
",3.3.2. VARIATIONAL LOWER BOUND,[0],[0]
"In particular, let Ω, W, and ψ be the collections of all Ω(l), W (l), and covariance and likelihood parameters, respectively.",3.3.2. VARIATIONAL LOWER BOUND,[0],[0]
"Recalling that we can obtain random features at each layer by sampling the elements in Ω from a given prior distribution, we propose to tackle the inference problem through variational inference of the parameters W and θ.",3.3.2. VARIATIONAL LOWER BOUND,[0],[0]
"We could also attempt to infer Ω, although in this work we are going to assume them sampled from the prior with fixed randomness, which allows us to optimize covariance parameters using the reparameterization trick (option PRIORFIXED in Cutajar et al. (2017)).",3.3.2. VARIATIONAL LOWER BOUND,[0],[0]
"We also note that we could infer, rather than optimize, ψ; we leave this for future work.
",3.3.2. VARIATIONAL LOWER BOUND,[0],[0]
"Using Jensen’s inequality, the variational approach allows us to obtain a lower bound on the log-marginal likelihood L := log [p(Y, C|t,Ω,ψ,ψD)] of equation (1), as follows:
L ≥ Eq(W) (log[p(Y |Ω,W,ψ)])",3.3.2. VARIATIONAL LOWER BOUND,[0],[0]
"+ Eq(W)q(θ) (log[p(C|Ω,W,ψD,θ)])",3.3.2. VARIATIONAL LOWER BOUND,[0],[0]
− DKL(q(W)‖p(W))−DKL(q(θ)‖p(θ)).,3.3.2. VARIATIONAL LOWER BOUND,[0],[0]
"(7)
The distribution q(W) acts as a variational approximation and is assumed to be Gaussian, factorizing completely across weights and layers (l):
q(W) = ∏ j,k,l p(W",3.3.2. VARIATIONAL LOWER BOUND,[0],[0]
"(l) jk ) = ∏ j,k,l N",3.3.2. VARIATIONAL LOWER BOUND,[0],[0]
"( m (l) jk , (s 2) (l) jk ) .",3.3.2. VARIATIONAL LOWER BOUND,[0],[0]
"(8)
Extensions to approximations where we relax the factorization assumption are possible.",3.3.2. VARIATIONAL LOWER BOUND,[0],[0]
"Similarly, we are going to assume q(θ) to be Gaussian, and will assume no factorization, so that q(θ) = N (µθ,Σθ).",3.3.2. VARIATIONAL LOWER BOUND,[0],[0]
This section reports an in-depth validation of the proposed method on a variety of benchmarks.,4. Experiments,[0],[0]
"We are going to study the proposed variational framework for constrained dynamics in DGP models for ODE parameter estimates using equality constraints, and compare it against state-of-the-art methods.",4. Experiments,[0],[0]
"We will then consider the application of inequality constraints for a regression problem on counts, which was previously considered in the literature of monotonic GPs.",4. Experiments,[0],[0]
We report here the configuration that we used across all benchmarks for the proposed method.,4.1. Settings for the proposed constrained DGP,[0],[0]
"Due to the generally low sample size n used across experiments (in most cases n < 50), unless specified otherwise the tests were performed with a two-layer DGP f(t) = f (2) ◦",4.1. Settings for the proposed constrained DGP,[0],[0]
"f (1)(t), with dimension of the “hidden” GP layer f (1)(t) equal to 2, and RBF kernels.",4.1. Settings for the proposed constrained DGP,[0],[0]
"The length-scale of the RBF covariances was initialized to λ0 = log(tmax − tmin), while the marginal standard deviation to α0 = log(ymax",4.1. Settings for the proposed constrained DGP,[0],[0]
− ymin),4.1. Settings for the proposed constrained DGP,[0],[0]
"; the initial likelihood noise was set to σ20 = α0/10
5.",4.1. Settings for the proposed constrained DGP,[0],[0]
"Finally, the initial ODE parameters were set to the value of 0.1.",4.1. Settings for the proposed constrained DGP,[0],[0]
"The optimization was carried out through stochastic gradient descent with Adaptive moment Estimation (Adam) (Kingma & Ba, 2017), through the alternate optimization of i) the approximated posterior over W and likelihood/covariance parameters (q(W) and ψ), and ii) likelihood parameters of ODE constraints and the approximate posterior over ODE parameters (ψD and q(θ)).",4.1. Settings for the proposed constrained DGP,[0],[0]
"We note that the optimization of the ODE constraints parameters (the noise and scale parameters for Gaussian and Student-t likelihoods, respectively) is aimed at identifying in a fully data-driven manner the optimal trade-off between data attachment (likelihood term) and regularity (constraints on the dynamics).",4.1. Settings for the proposed constrained DGP,[0],[0]
"In what follows, DGP-t and DGP-G respectively denote the model tested with Student-t and Gaussian noise models on the ODE constraints.",4.1. Settings for the proposed constrained DGP,[0],[0]
"The proposed framework was tested on a set of ODE systems extensively studied in previous works: Lotka-Volterra (Goel et al., 1971), FitzHugh-Nagumo (FitzHugh, 1955), and protein biopathways from Vyshemirsky & Girolami (2007).",4.2. Equality constraints from ODE systems,[0],[0]
"For each experiment, we used the experimental setting proposed in previous studies (Niu et al., 2016; Macdonald & Husmeier, 2015).",4.2. Equality constraints from ODE systems,[0],[0]
"In particular, for each test, we identified two experimental configurations with increasing modeling difficulty (e.g. less samples, lower signal-to-noise ratio, . . .).",4.2. Equality constraints from ODE systems,[0],[0]
A detailed description of the models and testing parameters is provided in the supplementary material.,4.2. Equality constraints from ODE systems,[0],[0]
The experimental results are reported for parameter inference and model estimation performed on 5 different realizations of the noise.,4.2. Equality constraints from ODE systems,[0],[0]
"We tested the proposed method against several reference approaches from the state-of-art to infer parameters of ODE systems.
",4.2.1. BENCHMARK,[0],[0]
RKG3: We tested the method presented in Niu et al. (2016) using the implementation in the R package KGode.,4.2.1. BENCHMARK,[0],[0]
"This method implements gradient matching, where the interpolant is modeled using functions in Reproducing Kernel Hilbert spaces.",4.2.1. BENCHMARK,[0],[0]
"This approach, for which ODE parameters are estimated and not inferred, was shown to achieve state-of-the-art performance on a variety of ODE estimation problems.",4.2.1. BENCHMARK,[0],[0]
"We used values ranging from 10−4 to 1 for the parameter λ that the method optimizes using cross-validation.
",4.2.1. BENCHMARK,[0],[0]
Warp: In the R package KGode there is also an implementation of the warping approach presented in Niu et al. (2018).,4.2.1. BENCHMARK,[0],[0]
This method extends gradient matching techniques by attempting to construct a warping of the input where smooth Reproducing Kernel Hilbert spaces-based interpolants can effectively model nonstationary observations.,4.2.1. BENCHMARK,[0],[0]
The warping attempts to transform the original signal via assumptions on periodicity and regularity conditions.,4.2.1. BENCHMARK,[0],[0]
We used the default parameters and initialized the optimization of the warping function from a period equal to the interval where observations are available.,4.2.1. BENCHMARK,[0],[0]
"Similarly to RKG3, ODE parameters are estimated and not inferred.
",4.2.1. BENCHMARK,[0],[0]
AGM:,4.2.1. BENCHMARK,[0],[0]
"We report results on the Approximate Gradient Matching (AGM) approach in Dondelinger et al. (2013), implemented in the recently released R package deGradInfer.",4.2.1. BENCHMARK,[0],[0]
AGM implements a population Markov chain Monte Carlo approach tempering from the prior to the approximate posterior of ODE parameters based on an interpolation with GPs.,4.2.1. BENCHMARK,[0],[0]
In the experiments we use 10 parallel chains and we run them for 104 iterations.,4.2.1. BENCHMARK,[0],[0]
"In the implementation of AGM, the variance of the noise on the observations is assumed known and it is fixed; we expect this to give a slight advantage to this method.
",4.2.1. BENCHMARK,[0],[0]
MCMC:,4.2.1. BENCHMARK,[0],[0]
In the R package deGradInfer there is also an implementation of a population Markov chain Monte Carlo sampler where the ODE is solved explicitly.,4.2.1. BENCHMARK,[0],[0]
In this case too we use 10 parallel chains that we run for 104 iterations.,4.2.1. BENCHMARK,[0],[0]
"In contrast to AGM, in this implementation, the variance of the noise on the observations is learned together with ODE parameters.",4.2.1. BENCHMARK,[0],[0]
Figure 4.2.2 shows the distribution of the root mean squared error (RMSE) across folds for each experimental setting (see supplement for details).,4.2.2. RESULTS,[0],[0]
"We note that the proposed method consistently leads to better RMSE values compared to the reference approaches (except some folds in one of the Fitz-Hugh-Nagumo experiments, according to a Mann-
Whitney nonparametric test), and that DGP-t provides more consistent parameter estimates than DGP-G. This latter result may indicate a lower sensitivity to outliers derivatives involved in the functional constraint term.",4.2.2. RESULTS,[0],[0]
This is a crucial aspect due to the generally noisy derivative terms of nonparametric regression models.,4.2.2. RESULTS,[0],[0]
"The distribution of the parameters for all the datasets tested in this study, which we report in the supplementary material, reveals that, unlike the nonprobabilistic methods RKG3 and WARP, our approach is capable of inferring ODE parameters yielding meaningful uncertainty estimation.
",4.2.2. RESULTS,[0],[0]
Lotka-Volterra,4.2.2. RESULTS,[0],[0]
We tested the scalability of the proposed method with respect to sample size.,4.3. Scalability test - large n,[0],[0]
"To this end, we repeated the test on the Lotka-Volterra system with n = 20, 40, 80, 150, 500, 103, and 104 observations.",4.3. Scalability test - large n,[0],[0]
"For each instance of the model, the execution time was recorded and compared with the competing methods.",4.3. Scalability test - large n,[0],[0]
All the experiments were performed on a 1.3GHz Intel Core i5 MacBook.,4.3. Scalability test - large n,[0],[0]
The proposed method scales linearly with n,4.3. Scalability test - large n,[0],[0]
"(Figure 2), while it has an almost constant execution when n < 500; we attribute this effect to overheads in the framework we used to code our method.",4.3. Scalability test - large n,[0],[0]
"For small n, the running time of our method is comparable with competing methods, and it is considerably faster in case of large n.",4.3. Scalability test - large n,[0],[0]
"In order to assess the ability of the framework to scale to a large number of ODEs, we tested our method on the Lorenz96 system with increasing number of equations, s = 125 to s = 1000 (Lorenz & Emanuel, 1998).",4.4. Scalability test - large s,[0],[0]
"To the best of our knowledge, the solution of this challenging problem via gradient matching approaches has only been previously attempted in Gorbach et al. (2017).",4.4. Scalability test - large s,[0],[0]
"We could not find an implementation of their method to carry out a direct comparison, so we are going to refer to the results reported in their paper.",4.4. Scalability test - large s,[0],[0]
"The system consists of a set of drift states functions (f1(x(t), θ), f2(x(t), θ), . . .",4.4. Scalability test - large s,[0],[0]
", fs(x(t), θ)) recursively linked by the relationship:
fi(x(t), θ) =",4.4. Scalability test - large s,[0],[0]
(xi+1(t)− xi−2(t))xi−1(t)− xi(t) +,4.4. Scalability test - large s,[0],[0]
"θ,
where θ ∈ R is the drift parameter.",4.4. Scalability test - large s,[0],[0]
"Consistently with the setting proposed in Gorbach et al. (2017); Vrettas et al. (2015), we set θ = 8 and generated 32 equally spaced observations over the interval",4.4. Scalability test - large s,[0],[0]
"[0, 4] seconds, with additive Gaussian noise σ2 = 1.",4.4. Scalability test - large s,[0],[0]
"We performed two tests by training (i) on all the states, and (ii) by keeping one third of the states as unobserved, and by applying our method to identify model dynamics on both observed and unobserved states.
",4.4. Scalability test - large s,[0],[0]
Figure 3 shows the average RMSE in the different experimental settings.,4.4. Scalability test - large s,[0],[0]
"As expected, the modeling accuracy is
sensibly higher when trained on the full set of equations.",4.4. Scalability test - large s,[0],[0]
"Moreover, the RMSE is lower on observed states compared to unobserved ones.",4.4. Scalability test - large s,[0],[0]
This is confirmed by visual inspection of the modeling results for sample training and testing states (Figure 4).,4.4. Scalability test - large s,[0],[0]
"The observed states are generally associated with lower uncertainty in the predictions and by an accurate fitting of the solutions (Figure 4, top).",4.4. Scalability test - large s,[0],[0]
"The model still provides remarkable modeling results on unobserved states (Figure 4, bottom), although with decreased accuracy and higher uncertainty.",4.4. Scalability test - large s,[0],[0]
We are investigating the reasons for the posterior distribution over θ not covering the true value of the parameter across different experimental conditions.,4.4. Scalability test - large s,[0],[0]
We explore here the capability of a DGP to accommodate for the data nonstationarity typical of ODE systems.,4.4.1. DEEP VS SHALLOW,[0],[0]
"In particular, the tests are performed in two different settings with large and small sample size n. By using the same experimental setting of Section 4.1, we sampled 80 and 1000 points, respectively, from the FitzHugh-Nagumo equations.",4.4.1. DEEP VS SHALLOW,[0],[0]
"The data is modeled with DGPs composed by one (“shallow” GP), two and three layers, all with RBF covariances.
",4.4.1. DEEP VS SHALLOW,[0],[0]
Figure 5 shows the modeling results obtained on the two configurations.,4.4.1. DEEP VS SHALLOW,[0],[0]
We note that the shallow GP consistently underfits the complex dynamics producing smooth interpolants.,4.4.1. DEEP VS SHALLOW,[0],[0]
"On the contrary, DGPs provide a better representation of the nonstationarity.",4.4.1. DEEP VS SHALLOW,[0],[0]
"As expected, the three-layer DGP leads to sub-optimal results in the low-sample size
Lorenz96 - Observed
Lorenz 96 - Unobserved
setting.",4.4.1. DEEP VS SHALLOW,[0],[0]
"Furthermore, in order to motivate the importance of nonstationarity, which we implement through DGPs, we further compared against shallow GPs with lower degrees of smoothness through the use of Matérn covariances with degrees ν = 1/2, 1, 3/2, 5/2.
",4.4.1. DEEP VS SHALLOW,[0],[0]
The overall performance in parameter estimation and data fit is reported in Table 1.,4.4.1. DEEP VS SHALLOW,[0],[0]
"According to the results, a two-layer DGP provides the best solution overall in terms of modeling accuracy and complexity.",4.4.1. DEEP VS SHALLOW,[0],[0]
"Interestingly, the Matérn covariance, with an appropriate degree of smoothness, achieves superior performance in parameter estimation in case of low sample size.",4.4.1. DEEP VS SHALLOW,[0],[0]
"However, the nonstationarity implemented by the DGP outperforms the stationary Matérn in the data fit, as well as in the parameter estimation when the sample size is large.",4.4.1. DEEP VS SHALLOW,[0],[0]
For an illustration of the data fit of the Matérn GP we refer the reader to the supplementary material.,4.4.1. DEEP VS SHALLOW,[0],[0]
"Crucially, these results indicate that our approach provides a practical and scalable way to learn nonstationarity within the framework of variational inference for deep probabilistic models.",4.4.1. DEEP VS SHALLOW,[0],[0]
We conclude our experimental validation by applying monotonic regression on counts as an illustration of the proposed framework for inequality constrains in DGP models dynamics.,4.5. Inequality constraints,[0],[0]
"We applied our approach to the mortality dataset from (Broffitt, 1988), with a two-layer DGP initialized with an analogous setting to the one proposed in Section 4.1.",4.5. Inequality constraints,[0],[0]
"In
particular, the sample rates were modeled with with a Poisson likelihood of the form p(yi|µi) = exp(−µi)µ yi",4.5. Inequality constraints,[0],[0]
"i
yi! , and
link function µi = exp(f(ti)).",4.5. Inequality constraints,[0],[0]
Monotonicity on the solution was strictly enforced by setting ψD = 5.,4.5. Inequality constraints,[0],[0]
Figure 6 shows the regression results without (top) and with (bottom) monotonicity constraint.,4.5. Inequality constraints,[0],[0]
The effect of the constraint on the dynamics can be appreciated by looking at the distribution of the derivatives (right panel).,4.5. Inequality constraints,[0],[0]
In the monotonic case the GP derivatives lie on the positive part of the plane.,4.5. Inequality constraints,[0],[0]
"This experiment leads to results compatible with those obtained with the monotonic GP proposed in (Riihimäki & Vehtari, 2010), and implemented in the GPstuff toolbox (Vanhatalo et al., 2013).",4.5. Inequality constraints,[0],[0]
"However, our approach is characterized by appealing scalability properties and can implement monotonic constraints on DGPs, which offer a more general class of functions than GPs.",4.5. Inequality constraints,[0],[0]
We introduced a novel generative formulation of deep probabilistic models implementing “soft” constraints on functions dynamics.,5. Conclusions,[0],[0]
"The proposed approach was extensively tested in several experimental settings, leading to highly competitive results in challenging modeling applications, and favorably comparing with the state-of-the-art in terms of modeling accuracy and scalability.",5. Conclusions,[0],[0]
"Furthermore, the proposed variational formulation allows for a meaningful uncertainty quantification of both model parameters and predictions.",5. Conclusions,[0],[0]
"This is an important aspect intimately related to the application of our proposal in real scenarios, such as in biology and epidemiology, where data is often noisy and scarce.
",5. Conclusions,[0],[0]
"Although in this study we essentially focused on the problem of ODE parameters inference and monotonic regression, the generality of our approach enables several other applications that will be subject of future investigations.",5. Conclusions,[0],[0]
"We will focus on the extension to manifold valued data, such as spatiotemporal observations represented by graphs, meshes, and 3D volumes, occurring for example in medical imaging and system biology.",5. Conclusions,[0],[0]
"This work has been supported by the French government, through the UCAJEDI Investments in the Future project managed by the National Research Agency (ANR) with the reference number ANR-15-IDEX-01 (project MetaImaGen).",Acknowledgements,[0],[0]
"MF gratefully acknowledges support from the AXA Research Fund.
",Acknowledgements,[0],[0]
This work is dedicated to Mattia Filippone.,Acknowledgements,[0],[0]
We introduce a novel generative formulation of deep probabilistic models implementing “soft” constraints on their function dynamics.,abstractText,[0],[0]
"In particular, we develop a flexible methodological framework where the modeled functions and derivatives of a given order are subject to inequality or equality constraints.",abstractText,[0],[0]
We then characterize the posterior distribution over model and constraint parameters through stochastic variational inference.,abstractText,[0],[0]
"As a result, the proposed approach allows for accurate and scalable uncertainty quantification on the predictions and on all parameters.",abstractText,[0],[0]
"We demonstrate the application of equality constraints in the challenging problem of parameter inference in ordinary differential equation models, while we showcase the application of inequality constraints on the problem of monotonic regression of count data.",abstractText,[0],[0]
"The proposed approach is extensively tested in several experimental settings, leading to highly competitive results in challenging modeling applications, while offering high expressiveness, flexibility and scalability.",abstractText,[0],[0]
Constraining the Dynamics of Deep Probabilistic Models,title,[0],[0]
"Content selection is a central component in many natural language generation tasks, where, given a generation goal, the system must determine which information should be expressed in the output text (Gatt and Krahmer, 2018).",1 Introduction,[0],[0]
"In summarization, content selection is usually accomplished through sentence (and, occasionally, phrase) extraction.",1 Introduction,[0],[0]
"Despite being a key component of both extractive and abstractive summarization systems, it is is not well understood how deep learning models perform content selection with only word and sentence embedding based features as input.",1 Introduction,[0],[0]
"Nonneural network approaches often use frequency and information theoretic measures as proxies for content salience (Hong and Nenkova, 2014), but these are not explicitly used in most neural network summarization systems.
",1 Introduction,[0],[0]
"In this paper, we seek to better understand how deep learning models of summarization perform content selection across multiple domains (§ 4):
news, personal stories, meetings, and medical articles (for which we collect a new corpus).1 We analyze several recent sentence extractive neural network architectures, specifically considering the design choices for sentence encoders (§ 3.1) and sentence extractors (§ 3.2).",1 Introduction,[0],[0]
We compare Recurrent Neural Network (RNN) and Convolutional Neural Network (CNN),1 Introduction,[0],[0]
based sentence representations to the simpler approach of word embedding averaging to understand the gains derived from more sophisticated architectures.,1 Introduction,[0],[0]
"We also question the necessity of auto-regressive sentence extraction (i.e. using previous predictions to inform future predictions), which previous approaches have used (§ 2), and propose two alternative models that extract sentences independently.
",1 Introduction,[0],[0]
Our main results (§ 5) reveal: 1.,1 Introduction,[0],[0]
"Sentence position bias dominates the learn-
ing signal for news summarization, though not for other domains.2 Summary quality for news is only slightly degraded when content words are omitted from sentence embeddings.",1 Introduction,[0],[0]
2.,1 Introduction,[0],[0]
Word embedding averaging is as good or better than either RNNs or CNNs for sentence embedding across all domains.,1 Introduction,[0],[0]
3.,1 Introduction,[0],[0]
"Pre-trained word embeddings are as good, or better than, learned embeddings in five of six datasets.",1 Introduction,[0],[0]
4.,1 Introduction,[0],[0]
"Non auto-regressive sentence extraction performs as good or better than auto-regressive extraction in all domains.
",1 Introduction,[0],[0]
"Taken together, these and other results in the paper suggest that we are over-estimating the abil-
1Data preprocessing and implementation code can be found here: https://github.com/kedz/nnsum/ tree/emnlp18-release
2This is a known bias in news summarization (Nenkova, 2005).
",1 Introduction,[0],[0]
ity of deep learning models to learn robust and meaningful content features for summarization.,1 Introduction,[0],[0]
"In one sense, this might lessen the burden of applying neural network models of content to other domains; one really just needs in-domain word embeddings.",1 Introduction,[0],[0]
"However, if we want to learn something other than where the start of the article is, we will need to design other means of sentence representation, and possibly external knowledge representations, better suited to the summarization task.",1 Introduction,[0],[0]
The introduction of the CNN-DailyMail corpus by Hermann et al. (2015) allowed for the application of large-scale training of deep learning models for summarization.,2 Related Work,[0],[0]
Cheng and Lapata (2016) developed a sentence extractive model that uses a word level CNN to encode sentences and a sentence level sequence-to-sequence model to predict which sentences to include in the summary.,2 Related Work,[0],[0]
"Subsequently, Nallapati et al. (2017) proposed a different model using word-level bidirectional RNNs along with a sentence level bidirectional RNN for predicting which sentences should be extracted.",2 Related Work,[0],[0]
"Their sentence extractor creates representations of the whole document and computes separate scores for salience, novelty, and location.",2 Related Work,[0],[0]
"These works represent the state-of-the-art for deep learningbased extractive summarization and we analyze them further in this paper.
",2 Related Work,[0],[0]
"Other recent neural network approaches include, Yasunaga et al. (2017), who learn a graphconvolutional network (GCN) for multi-document summarization.",2 Related Work,[0],[0]
"They do not closely examine the choice of sentence encoder, which is one of the focuses of the present paper; rather, they study the best choice of graph structure for the GCN, which is orthogonal to this work.
",2 Related Work,[0],[0]
Non-neural network learning-based approaches have also been applied to summarization.,2 Related Work,[0],[0]
"Typically they involve learning n-gram feature weights in linear models along with other non-lexical word or structural features (Berg-Kirkpatrick et al., 2011; Sipos et al., 2012; Durrett et al., 2016).",2 Related Work,[0],[0]
"In this paper, we study representation learning in neural networks that can capture more complex word level feature interactions and whose dense representations are more compatible with current practices in NLP.
",2 Related Work,[0],[0]
The previously mentioned works have focused on news summarization.,2 Related Work,[0],[0]
"To further understand the
content selection process, we also explore other domains of summarization.",2 Related Work,[0],[0]
"In particular, we explore personal narrative summarization based on stories shared on Reddit (Ouyang et al., 2017), workplace meeting summarization (Carletta et al., 2005), and medical journal article summarization (Mishra et al., 2014).
",2 Related Work,[0],[0]
"While most work on these summarization tasks often exploit domain-specific features (e.g. speaker identification in meeting summarization (Galley, 2006; Gillick et al., 2009)), we purposefully avoid such features in this work in order to understand the extent to which deep learning models can perform content selection using only surface lexical features.",2 Related Work,[0],[0]
"Summarization of academic literature (including medical journals), has long been a research topic in NLP (Kupiec et al., 1995; Elhadad et al., 2005), but most approaches have explored facet-based summarization (Jaidka et al., 2017), which is not the focus of our work.",2 Related Work,[0],[0]
"The goal of extractive text summarization is to select a subset of a document’s text to use as a summary, i.e. a short gist or excerpt of the central content.",3 Methods,[0],[0]
"Typically, we impose a budget on the length of the summary in either words or bytes.",3 Methods,[0],[0]
"In this work, we focus on sentence extractive summarization, where the basic unit of extraction is a sentence and impose a word limit as the budget.
",3 Methods,[0],[0]
"We model the sentence extraction task as a sequence tagging problem, following (Conroy and O’Leary, 2001).",3 Methods,[0],[0]
"Specifically, given a document containing n sentences s1, . . .",3 Methods,[0],[0]
", sn we generate a summary by predicting a corresponding label sequence y1, . . .",3 Methods,[0],[0]
", yn ∈ {0, 1}n, where yi = 1 indicates the i-th sentence is to be included in the summary.",3 Methods,[0],[0]
"Each sentence is itself a sequence of word embeddings si = w (i) 1 , . . .",3 Methods,[0],[0]
", w (i) |si| where |si| is the length of the sentence in words.",3 Methods,[0],[0]
The word budget c ∈ N enforces a constraint that the total summary word length ∑n i=1,3 Methods,[0],[0]
"yi · |si| ≤ c.
For a typical deep learning model of extractive summarization there are two main design decisions: a) the choice of sentence encoder which maps each sentence si to an embedding hi, and b) the choice of sentence extractor which maps a sequence of sentence embeddings h = h1, . . .",3 Methods,[0],[0]
", hn to a sequence of extraction decisions y = y1, . . .",3 Methods,[0],[0]
", yn.",3 Methods,[0],[0]
"We experiment with three architectures for mapping sequences of word embeddings to a fixed length vector: averaging, RNNs, and CNNs.",3.1 Sentence Encoders,[0],[0]
"Hyperparameter settings and implementation details can be found in Appendix A.
Averaging Encoder Under the averaging encoder, a sentence embedding h is simply the average of its word embeddings, i.e. h = 1|s| ∑|s| i=1wi.
",3.1 Sentence Encoders,[0],[0]
"RNN Encoder When using the RNN sentence encoder, a sentence embedding is the concatenation of the final output states of a forward and backward RNN over the sentence’s word embeddings.",3.1 Sentence Encoders,[0],[0]
"We use a Gated Recurrent Unit (GRU) for the RNN cell (Chung et al., 2014).
",3.1 Sentence Encoders,[0],[0]
CNN Encoder The CNN sentence encoder uses a series of convolutional feature maps to encode each sentence.,3.1 Sentence Encoders,[0],[0]
This encoder is similar to the convolutional architecture of Kim (2014) used for text classification tasks and performs a series of “one-dimensional” convolutions over word embeddings.,3.1 Sentence Encoders,[0],[0]
The final sentence embedding h is a concatenation of all the convolutional filter outputs after max pooling over time.,3.1 Sentence Encoders,[0],[0]
Sentence extractors take sentence embeddings h1:n and produce an extract y1:,3.2 Sentence Extractors,[0],[0]
n. The sentence extractor is essentially a discriminative classifier p(y1:n|h1:n).,3.2 Sentence Extractors,[0],[0]
"Previous neural network approaches to sentence extraction have assumed
an auto-regressive model, leading to a semiMarkovian factorization of the extractor probabilities p(y1:n|h) = ∏n i=1",3.2 Sentence Extractors,[0],[0]
"p(yi|y<i, h), where each prediction yi is dependent on all previous yj for all j < i.",3.2 Sentence Extractors,[0],[0]
We compare two such models proposed by Cheng and Lapata (2016) and Nallapati et al. (2017).,3.2 Sentence Extractors,[0],[0]
"A simpler approach that does not allow interaction among the y1:n is to model p(y1:n|h) = ∏n i=1 p(yi|h), which we explore in two proposed extractor models that we refer to as the RNN and Seq2Seq extractors.",3.2 Sentence Extractors,[0],[0]
"Implementation details for all extractors are in Appendix B.
Previously Proposed Sentence Extractors We consider two recent state-of-the-art extractors.
",3.2 Sentence Extractors,[0],[0]
"The first, proposed by Cheng and Lapata (2016), is built around a sequence-to-sequence model.",3.2 Sentence Extractors,[0],[0]
"First, each sentence embedding3 is fed into an encoder side RNN, with the final encoder state passed to the first step of the decoder RNN.",3.2 Sentence Extractors,[0],[0]
"On the decoder side, the same sentence embeddings are fed as input to the decoder and decoder outputs are used to predict each yi.",3.2 Sentence Extractors,[0],[0]
"The decoder input is weighted by the previous extraction probability, inducing the dependence of yi on y<i.",3.2 Sentence Extractors,[0],[0]
"See Figure 1.c for a graphical layout of the extractor.
",3.2 Sentence Extractors,[0],[0]
"Nallapati et al. (2017) proposed a sentence extractor, which we refer to as the SummaRunner Extractor, that factorizes the extraction probability into contributions from different sources.",3.2 Sentence Extractors,[0],[0]
"First, a bidirectional RNN is run over the sentence em-
3Cheng and Lapata (2016) used an CNN sentence encoder with this extractor architecture; in this work we pair the Cheng & Lapata extractor with several different encoders.
beddings4 and the output is concatenated.",3.2 Sentence Extractors,[0],[0]
A representation of the whole document is made by averaging the RNN output.,3.2 Sentence Extractors,[0],[0]
A summary representation is also constructed by taking the sum of the previous RNN outputs weighted by their extraction probabilities.,3.2 Sentence Extractors,[0],[0]
"Extraction predictions are made using the RNN output at the i-th step, the document representation, and i-th version of the summary representation, along with factors for sentence location in the document.",3.2 Sentence Extractors,[0],[0]
"The use of the iteratively constructed summary representation creates a dependence of yi on all y<i. See Figure 1.d for a graphical layout.
",3.2 Sentence Extractors,[0],[0]
"Proposed Sentence Extractors We propose two sentence extractor models that make a stronger conditional independence assumption p(y|h) = ∏ni=1 p(yi|h), essentially making independent predictions conditioned on h.
RNN Extractor Our first proposed model is a very simple bidirectional RNN based tagging model.",3.2 Sentence Extractors,[0],[0]
As in the RNN sentence encoder we use a GRU cell.,3.2 Sentence Extractors,[0],[0]
The forward and backward outputs of each sentence are passed through a multi-layer perceptron with a logsitic sigmoid output to predict the probability of extracting each sentence.,3.2 Sentence Extractors,[0],[0]
"See Figure 1.a for a graphical layout.
",3.2 Sentence Extractors,[0],[0]
Seq2Seq Extractor One shortcoming of the RNN extractor is that long range information from one end of the document may not easily be able to affect extraction probabilities of sentences at the other end.,3.2 Sentence Extractors,[0],[0]
"Our second proposed model, the Seq2Seq extractor mitigates this problem with an attention mechanism commonly used for neural machine translation (Bahdanau et al., 2014) and abstractive summarization (See et al., 2017).",3.2 Sentence Extractors,[0],[0]
The sentence embeddings are first encoded by a bidirectional GRU.,3.2 Sentence Extractors,[0],[0]
A separate decoder GRU transforms each sentence into a query vector which attends to the encoder output.,3.2 Sentence Extractors,[0],[0]
The attention weighted encoder output and the decoder GRU output are concatenated and fed into a multi-layer perceptron to compute the extraction probability.,3.2 Sentence Extractors,[0],[0]
See Figure 1.b for a graphical layout.,3.2 Sentence Extractors,[0],[0]
"We perform our experiments across six corpora from varying domains to understand how differ-
4Nallapati et al. (2017) use an RNN sentence encoder with this extractor architecture; in this work we pair the SummaRunner extractor with different encoders.
ent biases within each domain can affect content selection.",4 Datasets,[0],[0]
"The corpora come from the news domain (CNN-DailyMail, New York Times, DUC), personal narratives domain (Reddit), workplace meetings (AMI), and medical journal articles (PubMed).",4 Datasets,[0],[0]
"See Table 1 for dataset statistics.
",4 Datasets,[0],[0]
"CNN-DailyMail We use the preprocessing and training, validation, and test splits of See et al. (2017).",4 Datasets,[0],[0]
"This corpus is a mix of news on different topics including politics, sports, and entertainment.
",4 Datasets,[0],[0]
"New York Times The New York Times (NYT) corpus (Sandhaus, 2008) contains two types of abstracts for a subset of its articles.",4 Datasets,[0],[0]
The first summary is an archival abstract and the second is a shorter online teaser meant to entice a viewer of the webpage to click to read more.,4 Datasets,[0],[0]
"From this collection, we take all articles that have a concatenated summary length of at least 100 words.",4 Datasets,[0],[0]
"We create training, validation, and test splits by partitioning on dates; we use the year 2005 as the validation data, with training and test partitions including documents before and after 2005 respectively.
",4 Datasets,[0],[0]
"DUC We use the single document summarization data from the 2001 and 2002 Document Understanding Conferences (DUC) (Over and Liggett, 2002).",4 Datasets,[0],[0]
"We split the 2001 data into training and validation splits and reserve the 2002 data for testing.
",4 Datasets,[0],[0]
"AMI The AMI corpus (Carletta et al., 2005) is a collection of real and staged office meetings annotated with text transcriptions, along with abstractive summaries.",4 Datasets,[0],[0]
"We use the prescribed splits.
",4 Datasets,[0],[0]
Reddit Ouyang et al. (2017) collected a corpus of personal stories shared on Reddit5 along with multiple extractive and abstractive summaries.,4 Datasets,[0],[0]
"We randomly split this data using roughly three and five percent of the data validation and test respectively.
",4 Datasets,[0],[0]
"PubMed We created a corpus of 25,000 randomly sampled medical journal articles from the PubMed Open Access Subset6.",4 Datasets,[0],[0]
We only included articles if they were at least 1000 words long and had an abstract of at least 50 words in length.,4 Datasets,[0],[0]
We used the article abstracts as the ground truth human summaries.,4 Datasets,[0],[0]
"Since we do not typically have ground truth extract summaries from which to create the labels yi, we construct gold label sequences by greedily optimizing ROUGE-1, using the algorithm in Appendix C. We choose to optimize for ROUGE-1 rather than ROUGE-2 similarly to other optimization based approaches to summarization (Sipos et al., 2012; Durrett et al., 2016) which found this to be the easier target to learn.
",4.1 Ground Truth Extract Summaries,[0],[0]
"5www.reddit.com 6https://www.ncbi.nlm.nih.gov/pmc/
tools/openftlist/",4.1 Ground Truth Extract Summaries,[0],[0]
"We evaluate summary quality using ROUGE-2 recall (Lin, 2004); ROUGE-1 and ROUGE-LCS trend similarity in our experiments.",5 Experiments,[0],[0]
"We use target word lengths of 100 words for news, and 75, 290, and 200 for Reddit, AMI, and PubMed respectively.",5 Experiments,[0],[0]
"We also evaluate using METEOR (Denkowski and Lavie, 2014).7 Summaries are generated by extracting the top ranked sentences by model probability p(yi =",5 Experiments,[0],[0]
"1|y<i, h), stopping when the word budget is met or exceeded.",5 Experiments,[0],[0]
We estimate statistical significance by averaging each document level score over the five random initializations.,5 Experiments,[0],[0]
"We then test the difference between the best system on each dataset and all other systems using the approximate randomization test (Riezler and Maxwell, 2005) with the Bonferroni correction for multiple comparisons, testing for significance at the 0.05 level.",5 Experiments,[0],[0]
"We train all models to minimize the weighted negative log-likelihood
L = − ∑ s,y∈D h=enc(s) n∑ i=1 ω(yi)",5.1 Training,[0],[0]
"log p (yi|y<i, h)
",5.1 Training,[0],[0]
"7We use the default settings for METEOR and use remove stopwords and no stemming options for ROUGE, keeping defaults for all other parameters.
over the training data D using stochastic gradient descent with the ADAM optimizer (Kingma and Ba, 2014).",5.1 Training,[0],[0]
ω(0) = 1 and ω(1) = N0/N1 where Ny is the number of training examples with label y.,5.1 Training,[0],[0]
We trained for a maximum of 50 epochs and the best model was selected with early stopping on the validation set according to ROUGE-2.,5.1 Training,[0],[0]
Each epoch constitutes a full pass through the dataset.,5.1 Training,[0],[0]
"The average stopping epoch was: CNN-DailyMail, 16.2; NYT, 21.36; DUC, 37.11; Reddit, 36.59; AMI, 19.58; PubMed, 19.84.",5.1 Training,[0],[0]
All experiments were repeated with five random initializations.,5.1 Training,[0],[0]
"Unless specified, word embeddings were initialized using pretrained GloVe embeddings (Pennington et al., 2014) and we did not update them during training.",5.1 Training,[0],[0]
Unknown words were mapped to a zero embedding.,5.1 Training,[0],[0]
See Appendix D for more optimization and training details.,5.1 Training,[0],[0]
"Lead As a baseline we include the lead summary, i.e. taking the first x words of the document as summary, where x is the target summary length for each dataset (see the first paragraph of § 5).",5.2 Baselines,[0],[0]
"While incredibly simple, this method is still a competitive baseline for single document summa-
rization, especially on newswire.
",5.2 Baselines,[0],[0]
"Oracle To measure the performance ceiling, we show the ROUGE/METEOR scores using the extractive summary which results from greedily optimizing ROUGE-1.",5.2 Baselines,[0],[0]
"I.e., if we had clairvoyant knowledge of the human reference summary, the oracle system achieves the (approximate) maximum possible ROUGE scores.",5.2 Baselines,[0],[0]
See Appendix C for a detailed description of the oracle algorithm.,5.2 Baselines,[0],[0]
The results of our main experiment comparing the different extractors/encoders are shown in Table 2.,5.3 Results,[0],[0]
"Overall, we find no major advantage when using the CNN and RNN sentence encoders over the averaging encoder.",5.3 Results,[0],[0]
"The best performing encoder/extractor pair either uses the averaging encoder (five out of six datasets) or the differences are not statistically significant.
",5.3 Results,[0],[0]
"When looking at extractors, the Seq2Seq extractor is either part of the best performing system (three out of six datasets) or is not statistically distinguishable from the best extractor.
",5.3 Results,[0],[0]
"Overall, on the news and medical journal domains, the differences are quite small with the dif-
ferences between worst and best systems on the CNN/DM dataset spanning only .56 of a ROUGE point.",5.3 Results,[0],[0]
"While there is more performance variability in the Reddit and AMI data, there is less distinction among systems: no differences are significant on Reddit and every extractor has at least one configuration that is indistinguishable from the best system on the AMI corpus.",5.3 Results,[0],[0]
"This is probably due to the small test size of these datasets.
",5.3 Results,[0],[0]
Word Embedding Learning,5.3 Results,[0],[0]
"Given that learning a sentence encoder (averaging has no learned parameters) does not yield significant improvement, it is natural to consider whether learning word embeddings is also necessary.",5.3 Results,[0],[0]
"In Table 3 we compare the performance of different extractors using the averaging encoder, when the word embeddings are held fixed or learned during training.",5.3 Results,[0],[0]
"In both cases, word embeddings are initialized with GloVe embeddings trained on a combination of Gigaword and Wikipedia.",5.3 Results,[0],[0]
"When learning embeddings, words occurring fewer than three times in the training data are mapped to an unknown token (with learned embedding).
",5.3 Results,[0],[0]
"In all but one case, fixed embeddings are as good or better than the learned embeddings.",5.3 Results,[0],[0]
"This is a somewhat surprising finding on the CNN/DM data since it is reasonably large, and learning embeddings should give the models more flexibility to identify important word features.8",5.3 Results,[0],[0]
"This sug-
8The AMI corpus is an exception here where learning
gests that we cannot extract much generalizable learning signal from the content other than what is already present from initialization.",5.3 Results,[0],[0]
"Even on PubMed, where the language is quite different from the news/Wikipedia articles the GloVe embeddings were trained on, learning leads to significantly worse results.
",5.3 Results,[0],[0]
POS Tag Ablation It is also not well explored what word features are being used by the encoders.,5.3 Results,[0],[0]
"To understand which classes of words were most important we ran an ablation study, selectively removing nouns, verbs (including participles and auxiliaries), adjectives & adverbs, and function words (adpositions, determiners, conjunctions).",5.3 Results,[0],[0]
All datasets were automatically tagged using the spaCy part-of-speech (POS) tagger9.,5.3 Results,[0],[0]
"The embeddings of removed words were replaced with a zero vector, preserving the order and position of the non-ablated words in the sentence.",5.3 Results,[0],[0]
"Ablations were performed on training, validation, and test partitions, using the RNN extractor with averaging encoder.",5.3 Results,[0],[0]
Table 4 shows the results of the POS tag ablation experiments.,5.3 Results,[0],[0]
"While removing any word class from the representation generally hurts performance (with statistical significance), on the news domains, the absolute values of the
does lead to small performance boosts, however, only in the Seq2Seq extractor is this diference significant; it is quite possible that this is an artifact of the very small test set size.
",5.3 Results,[0],[0]
"9https://github.com/explosion/spaCy
differences are quite small (.18 on CNN/DM, .41 on NYT, .3 on DUC) suggesting that the model’s predictions are not overly dependent on any particular word types.",5.3 Results,[0],[0]
"On the non-news datasets, the ablations have a larger effect (max differences are 1.89 on Reddit, 2.56 on AMI, and 1.3 on PubMed).",5.3 Results,[0],[0]
Removing nouns leads to the largest drop on AMI and PubMed.,5.3 Results,[0],[0]
"Removing adjectives and adverbs leads to the largest drop on Reddit, suggesting the intensifiers and descriptive words are useful for identifying important content in personal narratives.",5.3 Results,[0],[0]
"Curiously, removing the function word POS class yields a significant improvement on DUC 2002 and AMI.
",5.3 Results,[0],[0]
"Document Shuffling Sentence position is a well known and powerful feature for news summarization (Hong and Nenkova, 2014), owing to the intentional lead bias in the news article writing10; it also explains the difficulty in beating the lead baseline for single-document summarization (Nenkova, 2005; Brandow et al., 1999).",5.3 Results,[0],[0]
"In examining the generated summaries, we found most of the selected sentences in the news domain came from the lead paragraph of the document.",5.3 Results,[0],[0]
"This is despite the fact that there is a long tail of sentence extractions from later in the document in the ground truth extract summaries (31%, 28.3%, and 11.4% of DUC, CNN/DM, and NYT training extract labels come from the second half of the document).",5.3 Results,[0],[0]
"Because this lead bias is so strong, it is questionable whether the models are learning to identify important content or just find the start of the document.",5.3 Results,[0],[0]
We conduct a sentence order experiment where each document’s sentences are randomly shuffled during training.,5.3 Results,[0],[0]
"We then evaluate each model performance on the unshuffled test data, comparing to the model trained on unshuffled data; if the models trained on shuffled data drop in performance, then this indicates the lead bias is the relevant factor.
",5.3 Results,[0],[0]
Table 5 shows the results of the shuffling experiments.,5.3 Results,[0],[0]
The news domains and PubMed suffer a significant drop in performance when the document order is shuffled.,5.3 Results,[0],[0]
"By comparison, there is no significant difference between the shuffled and inorder models on the Reddit domain, and shuffling actually improves performance on AMI.",5.3 Results,[0],[0]
"This suggest that position is being learned by the models in the news/journal article domain even when the
10https://en.wikipedia.org/wiki/ Inverted_pyramid_(journalism)
model has no explicit position features, and that this feature is more important than either content or function words.",5.3 Results,[0],[0]
Learning content selection for summarization in the news domain is severely inhibited by the lead bias.,6 Discussion,[0],[0]
The summaries generated by all systems described here–the prior work and our proposed simplified models–are highly similar to each other and to the lead baseline.,6 Discussion,[0],[0]
"The Cheng & Lapata and Seq2Seq extractors (using the averaging encoder) share 87.8% of output sentences on average on the CNN/DM data, with similar numbers for the other news domains (see Table 6 for a typical example).",6 Discussion,[0],[0]
"Also on CNN/DM, 58% of the Seq2Seq selected sentences also occur in the lead summary, with similar numbers for DUC, NYT, and Reddit.",6 Discussion,[0],[0]
"Shuffling reduces lead overlap to 35.2% but the overall system performance drops significantly; the models are not able to identify important information without position.
",6 Discussion,[0],[0]
"The relative robustness of the news domain to part of speech ablation also suggests that models are mostly learning to recognize the stylistic features unique to the beginning of the article, and not the content.",6 Discussion,[0],[0]
"Additionally, the drop in performance when learning word embeddings on the news domain suggests that word embeddings alone do not provide very generalizable content features compared to recognizing the lead.
",6 Discussion,[0],[0]
The picture is rosier for non-news summarization where part of speech ablation leads to larger performance differences and shuffling either does not inhibit content selection significantly or leads to modest gains.,6 Discussion,[0],[0]
"Learning better word-level representations on these domains will likely require much larger corpora, something which might remain unlikely for personal stories and meetings.
",6 Discussion,[0],[0]
"The lack of distinction among sentence encoders is interesting because it echoes findings in the generic sentence embedding literature where word embedding averaging is frustratingly difficult to outperform (Iyyer et al., 2015; Wieting et al., 2015; Arora et al., 2016; Wieting and Gimpel, 2017).",6 Discussion,[0],[0]
"The inability to learn useful sentence representations is also borne out in the SummaRunner model, where there are explicit similarity computations between document or summary representations and sentence embeddings; these computations do not seem to add much to the per-
formance as the Cheng & Lapata and Seq2Seq models which lack these features generally perform as well or better.",6 Discussion,[0],[0]
"Furthermore, the Cheng & Lapata and SummaRunner extractors both construct a history of previous selection decisions to inform future choices but this does not seem to significantly improve performance over the Seq2Seq extractor (which does not).",6 Discussion,[0],[0]
"This suggests that we need to rethink or find novel forms of sentence representation for the summarization task.
",6 Discussion,[0],[0]
"A manual examination of the outputs revealed some interesting failure modes, although in general it was hard to discern clear patterns of behaviour other than lead bias.",6 Discussion,[0],[0]
"On the news domain, the models consistently learned to ignore quoted material in the lead, as often the quotes provide color to the story but are unlikely to be included in the summary (e.g. “It was like somebody slugging a punching bag.”).",6 Discussion,[0],[0]
"This behavior was most likely triggered by the presence of quotes, as the quote attributions, which were often tokenized as separate sentences, would subsequently be included in the summary despite also not containing much information (e.g. Gil Clark of the National Hurricane Center said Thursday).",6 Discussion,[0],[0]
We have presented an empirical study of deep learning based content selection algorithms for summarization.,7 Conclusion,[0],[0]
Our findings suggest such models face stark limitations on their ability to learn robust features for this task and that more work is needed on sentence representation for summarization.,7 Conclusion,[0],[0]
The authors would like to thank the anonymous reviewers for their valuable feedback.,8 Acknowledgements,[0],[0]
Thanks goes out as well to Chris Hidey for his helpful comments.,8 Acknowledgements,[0],[0]
"We would also like to thank Wen Xiao for identifying an error in the oracle results for the AMI corpus, which as since been corrected.
",8 Acknowledgements,[0],[0]
"This research is based upon work supported in part by the Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via contract # FA865017-C-9117.",8 Acknowledgements,[0],[0]
"The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of ODNI, IARPA, or the U.S. Government.",8 Acknowledgements,[0],[0]
"The U.S. Gov-
ernment is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright annotation therein.",8 Acknowledgements,[0],[0]
We use 200 dimenional word embeddingswi in all models.,A Details on Sentence Encoders,[0],[0]
Dropout is applied to the embeddings during training.,A Details on Sentence Encoders,[0],[0]
"Wherever dropout is applied, the drop probability is .25.
A.1 Details on RNN Encoder Under the RNN encoder, a sentence embedding is defined as h =",A Details on Sentence Encoders,[0],[0]
"[ −→ h |s|; ←− h 1] where
−→ h 0",A Details on Sentence Encoders,[0],[0]
"= 0; −→ h i = −−−→ GRU(wi, −→ h i−1) (1)
←−",A Details on Sentence Encoders,[0],[0]
h |s|+1 = 0;,A Details on Sentence Encoders,[0],[0]
"←− h i = ←−−− GRU(wi, ←− h i+1), (2)
and −−−→ GRU amd ←−−− GRU indicate the forward and backward GRUs respectively, each with separate parameters.",A Details on Sentence Encoders,[0],[0]
We use 300 dimensional hidden layers for each GRU.,A Details on Sentence Encoders,[0],[0]
"Dropout is applied to GRU during training.
",A Details on Sentence Encoders,[0],[0]
"A.2 Details on CNN Encoder
The CNN encoder has hyperparameters associated with the window sizes K ⊂ N of the convolutional filters (i.e. the number of words associated with each convolution) and the number of feature maps Mk ∈ N associated with each filter (i.e. the output dimension of each convolution).",A Details on Sentence Encoders,[0],[0]
"The CNN sentence embedding h is computed as follows:
a (m,k)",A Details on Sentence Encoders,[0],[0]
i = b,A Details on Sentence Encoders,[0],[0]
"(m,k) +",A Details on Sentence Encoders,[0],[0]
k∑ j=1,A Details on Sentence Encoders,[0],[0]
"W (m,k) j · wi+j−1 (3)
",A Details on Sentence Encoders,[0],[0]
"h(m,k) = max i∈1,...,|s|−k+1
ReLU ( a (m,k) i ) (",A Details on Sentence Encoders,[0],[0]
"4)
h = [ h(m,k)|m ∈ {1, . . .",A Details on Sentence Encoders,[0],[0]
",Mk}, k ∈ K ] (5)
where b(m,k) ∈ R and W (m,k) ∈ Rk×n′ are learned bias and filter weight parameters respectively, and ReLU(x) = max(0, x) is the rectified linear unit activation.",A Details on Sentence Encoders,[0],[0]
"We use window sizes K = {1, 2, 3, 4, 5, 6} with corresponding feature maps sizes M1 = 25,M2 = 25,M3 = 50,M4 = 50,M5 = 50,M6 = 50, giving h a dimensionality of 250.",A Details on Sentence Encoders,[0],[0]
Dropout is applied to the CNN output during training.,A Details on Sentence Encoders,[0],[0]
"B.1 Details on RNN Extractor
−→z 0 = 0; −→z i = −−−→ GRU(hi, −→z i−1) (6) ←−z n+1",B Details on Sentence Extractors,[0],[0]
"= 0; ←−z i = ←−−− GRU(hi,
←−z i+1) (7) ai = ReLU (U ·",B Details on Sentence Extractors,[0],[0]
[−→z i;←−z,B Details on Sentence Extractors,[0],[0]
"i] + u) (8)
p(yi = 1|h) = σ",B Details on Sentence Extractors,[0],[0]
"(V · ai + v) (9)
where −−−→ GRU and ←−−− GRU indicate the forward and backward GRUs respectively, and each have separate learned parameters; U, V and u, v are learned weight and bias parameters.",B Details on Sentence Extractors,[0],[0]
The hidden layer size of the GRU is 300 for each direction and the MLP hidden layer size is 100.,B Details on Sentence Extractors,[0],[0]
"Dropout is applied to the GRUs and to ai.
",B Details on Sentence Extractors,[0],[0]
"B.2 Details on Seq2Seq Extrator
−→z 0 = 0; −→z i = −−−→ GRUenc(hi, −→z i−1) (10) ←−z n+1",B Details on Sentence Extractors,[0],[0]
"= 0; ←−z i = ←−−− GRUenc(hi,
←−z i+1) (11)",B Details on Sentence Extractors,[0],[0]
"−→q i = −−−→ GRUdec(hi,
−→q i−1) (12) ←−q",B Details on Sentence Extractors,[0],[0]
"i = ←−−− GRUdec(hi, ←−q i+1) (13)
qi =",B Details on Sentence Extractors,[0],[0]
[ −→q i;←−q,B Details on Sentence Extractors,[0],[0]
"i], zi =",B Details on Sentence Extractors,[0],[0]
[−→z i;←−z,B Details on Sentence Extractors,[0],[0]
"i] (14)
αi,j = exp (qi · zj)∑n j=1 exp (qi · zj) , z̄i = n∑ j=1 αi,jzj (15)
ai = ReLU (U ·",B Details on Sentence Extractors,[0],[0]
[z̄i; qi] + u) (16) p(yi = 1|h) = σ (V · ai + v) .,B Details on Sentence Extractors,[0],[0]
"(17)
The final outputs of each encoder direction are passed to the first decoder steps; additionally, the first step of the decoder GRUs are learned “begin decoding” vectors −→q 0",B Details on Sentence Extractors,[0],[0]
and←−q 0,B Details on Sentence Extractors,[0],[0]
(see Figure 1.b).,B Details on Sentence Extractors,[0],[0]
"Each GRU has separate learned parameters; U, V and u, v are learned weight and bias parameters.",B Details on Sentence Extractors,[0],[0]
The hidden layer size of the GRU is 300 for each direction and MLP hidden layer size is 100.,B Details on Sentence Extractors,[0],[0]
"Dropout with drop probability .25 is applied to the GRU outputs and to ai.
",B Details on Sentence Extractors,[0],[0]
B.3 Details on Cheng & Lapata Extractor.,B Details on Sentence Extractors,[0],[0]
"The basic architecture is a unidirectional sequence-to-sequence model defined as follows:
z0 = 0; zi = GRUenc(hi, zi−1) (18) q1 =",B Details on Sentence Extractors,[0],[0]
"GRUdec(h∗, zn) (19)
qi = GRUdec(pi−1 · hi−1, qi−1) (20) ai = ReLU (U ·",B Details on Sentence Extractors,[0],[0]
"[zi; qi] + u) (21)
",B Details on Sentence Extractors,[0],[0]
"pi = p(yi = 1|y<i, h) = σ",B Details on Sentence Extractors,[0],[0]
"(V · ai + v) (22)
where h∗ is a learned “begin decoding” sentence embedding (see Figure 1.c).",B Details on Sentence Extractors,[0],[0]
"Each GRU has separate learned parameters; U, V and u, v are learned weight and bias parameters.",B Details on Sentence Extractors,[0],[0]
"Note in Equation 20 that the decoder side GRU input is the sentence embedding from the previous time step weighted by its probabilitiy of extraction (pi−1) from the previous step, inducing dependence of each output yi on all previous outputs y<i.",B Details on Sentence Extractors,[0],[0]
The hidden layer size of the GRU is 300 and the MLP hidden layer size is 100.,B Details on Sentence Extractors,[0],[0]
"Dropout with drop probability .25 is applied to the GRU outputs and to ai.
",B Details on Sentence Extractors,[0],[0]
"Note that in the original paper, the Cheng & Lapata extractor was paired with a CNN sentence encoder, but in this work we experiment with a variety of sentence encoders.
",B Details on Sentence Extractors,[0],[0]
B.4 Details on SummaRunner Extractor.,B Details on Sentence Extractors,[0],[0]
"Like the RNN extractor it starts with a bidrectional GRU over the sentence embeddings
−→z 0 = 0; −→z",B Details on Sentence Extractors,[0],[0]
"i = −−−→ GRU(hi, −→z i−1) (23) ←−z n+1",B Details on Sentence Extractors,[0],[0]
"= 0; ←−z i = ←−−− GRU(hi, ←−z i+1), (24)
",B Details on Sentence Extractors,[0],[0]
"It then creates a representation of the whole document q by passing the averaged GRU output states through a fully connected layer:
q = tanh",B Details on Sentence Extractors,[0],[0]
"( bq +Wq 1
n n∑ i=1
",B Details on Sentence Extractors,[0],[0]
[−→z i;←−z,B Details on Sentence Extractors,[0],[0]
"i] )
(25)
A concatentation of the GRU outputs at each step are passed through a separate fully connected layer to create a sentence representation zi, where
zi = ReLU (bz +Wz[ −→z i;←−z i]) .",B Details on Sentence Extractors,[0],[0]
"(26)
",B Details on Sentence Extractors,[0],[0]
"The extraction probability is then determined by contributions from five sources:
content",B Details on Sentence Extractors,[0],[0]
"a(con)i = W (con)zi, (27)
salience a(sal)i =",B Details on Sentence Extractors,[0],[0]
z T,B Details on Sentence Extractors,[0],[0]
"i W (sal)q, (28)
novelty a(nov)i",B Details on Sentence Extractors,[0],[0]
"= −zTi W (nov) tanh(gi), (29) position a(pos)i = W (pos)li, (30) quartile a(qrt)i = W (qrt)ri, (31)
where li and ri are embeddings associated with the i-th sentence position and the quarter of the document containing sentence i respectively.",B Details on Sentence Extractors,[0],[0]
"In Equation 29, gi is an iterative summary representation computed as the sum of the previous z<i weighted by their extraction probabilities,
gi = i−1∑ j=1 p(yj = 1|y<j , h) ·",B Details on Sentence Extractors,[0],[0]
zj .,B Details on Sentence Extractors,[0],[0]
"(32)
Note that the presence of this term induces dependence of each yi to all y<i similarly to the Cheng & Lapata extractor.
",B Details on Sentence Extractors,[0],[0]
"The final extraction probability is the logistic sigmoid of the sum of these terms plus a bias,
p(yi = 1|y<i, h) = σ",B Details on Sentence Extractors,[0],[0]
( a (con) i + a (sal) i + a (nov),B Details on Sentence Extractors,[0],[0]
"i
+a (pos) i + a (qrt) i + b
) .",B Details on Sentence Extractors,[0],[0]
"(33)
The weight matrices Wq, Wz , W (con), W (sal), W (nov), W (pos), W (qrt) and bias terms bq, bz , and b are learned parameters",B Details on Sentence Extractors,[0],[0]
; The GRUs have separate learned parameters.,B Details on Sentence Extractors,[0],[0]
"The hidden layer size of the GRU is 300 for each direction zi, q, and gi have 100 dimensions.",B Details on Sentence Extractors,[0],[0]
The position and quartile embeddings are 16 dimensional each.,B Details on Sentence Extractors,[0],[0]
"Dropout with drop probability .25 is applied to the GRU outputs and to zi.
",B Details on Sentence Extractors,[0],[0]
"Note that in the original paper, the SummaRunner extractor was paired with an RNN sentence encoder, but in this work we experiment with a variety of sentence encoders.",B Details on Sentence Extractors,[0],[0]
"Algorithm 1: ORACLEEXTRACTSUMMARYLABELS Data: input document sentences s1, s2, . . .",C Ground Truth Extract Summary Algorithm,[0],[0]
", sn,
human reference summary R, summary word budget c.
1 yi := 0 ∀i ∈ 1, . . .",C Ground Truth Extract Summary Algorithm,[0],[0]
",",C Ground Truth Extract Summary Algorithm,[0],[0]
n,C Ground Truth Extract Summary Algorithm,[0],[0]
//,C Ground Truth Extract Summary Algorithm,[0],[0]
Initialize extract labels to be 0.,C Ground Truth Extract Summary Algorithm,[0],[0]
2 S :=,C Ground Truth Extract Summary Algorithm,[0],[0]
[ ] // Initialize summary as empty list.,C Ground Truth Extract Summary Algorithm,[0],[0]
3 while ∑ s∈S WORDCOUNT(s) ≤,C Ground Truth Extract Summary Algorithm,[0],[0]
c,C Ground Truth Extract Summary Algorithm,[0],[0]
do //,C Ground Truth Extract Summary Algorithm,[0],[0]
While summary word count ≤ word budget.,C Ground Truth Extract Summary Algorithm,[0],[0]
"4
/* Add the next best sentence to the summary if it will improve the ROUGE
score otherwise no improvement can be made so break.",C Ground Truth Extract Summary Algorithm,[0],[0]
"*/
5
6 î = arg maxi∈{1,...,n}, yi 6=1 ROUGE(S",C Ground Truth Extract Summary Algorithm,[0],[0]
+,C Ground Truth Extract Summary Algorithm,[0],[0]
"[si], R) 7 8",C Ground Truth Extract Summary Algorithm,[0],[0]
if ROUGE(S,C Ground Truth Extract Summary Algorithm,[0],[0]
+,C Ground Truth Extract Summary Algorithm,[0],[0]
"[sî], R) > ROUGE(S,R) then 9 S := S +",C Ground Truth Extract Summary Algorithm,[0],[0]
[sî] //,C Ground Truth Extract Summary Algorithm,[0],[0]
Add sî to the summary sentence list.,C Ground Truth Extract Summary Algorithm,[0],[0]
10 yî := 1 // Set the î-th extract label to indicate extraction.,C Ground Truth Extract Summary Algorithm,[0],[0]
"11 else 12 break
Result: extract summary labels y1, . . .",C Ground Truth Extract Summary Algorithm,[0],[0]
", yn",C Ground Truth Extract Summary Algorithm,[0],[0]
We use a learning rate of .0001 and a dropout rate of .25 for all dropout layers.,D Optimizer and initialization settings.,[0],[0]
We also employ gradient clipping (−5 <,D Optimizer and initialization settings.,[0],[0]
∇θ,D Optimizer and initialization settings.,[0],[0]
< 5),D Optimizer and initialization settings.,[0],[0]
.,D Optimizer and initialization settings.,[0],[0]
"Weight matrix parameters are initialized using Xavier initialization with the normal distribution (Glorot and Bengio, 2010) and bias terms are set to 0.",D Optimizer and initialization settings.,[0],[0]
"We use a batch size of 32 for all datasets except AMI and PubMed, which are often longer and consume more memory, for which we use sizes two and four respectively.",D Optimizer and initialization settings.,[0],[0]
"For the Cheng & Lapata model, we train for half of the maximum epochs with teacher forcing, i.e. we set pi = 1 if yi = 1 in the gold data and 0 otherwise when computing the decoder input pi · hi; we revert to the predicted model probability during the second half training.",D Optimizer and initialization settings.,[0],[0]
"We carry out experiments with deep learning models of summarization across the domains of news, personal stories, meetings, and medical articles in order to understand how content selection is performed.",abstractText,[0],[0]
We find that many sophisticated features of state of the art extractive summarizers do not improve performance over simpler models.,abstractText,[0],[0]
"These results suggest that it is easier to create a summarizer for a new domain than previous work suggests and bring into question the benefit of deep learning models for summarization for those domains that do have massive datasets (i.e., news).",abstractText,[0],[0]
"At the same time, they suggest important questions for new research in summarization; namely, new forms of sentence representations or external knowledge sources are needed that are better suited to the sumarization task.",abstractText,[0],[0]
Content Selection in Deep Learning Models of Summarization,title,[0],[0]
"Neural machine translation (NMT) (Kalchbrenner and Blunsom, 2013; Sutskever et al., 2014; Bahdanau et al., 2015) has made significant progress in the past several years.",1 Introduction,[0],[0]
Its goal is to construct and utilize a single large neural network to accomplish the entire translation task.,1 Introduction,[0],[0]
"One great advantage of NMT is that the translation system can be completely constructed by learning from data without human involvement (cf., feature engineering in statistical machine translation (SMT)).",1 Introduction,[0],[0]
"The encoderdecoder architecture is widely employed (Cho et al.,
2014; Sutskever et al., 2014), in which the encoder summarizes the source sentence into a vector representation, and the decoder generates the target sentence word-by-word from the vector representation.",1 Introduction,[0],[0]
"The representation of the source sentence and the representation of the partially generated target sentence (translation) at each position are referred to as source context and target context, respectively.",1 Introduction,[0],[0]
"The generation of a target word is determined jointly by the source context and target context.
",1 Introduction,[0],[0]
"Several techniques in NMT have proven to be very effective, including gating (Hochreiter and Schmidhuber, 1997; Cho et al., 2014) and attention (Bahdanau et al., 2015) which can model long-distance dependencies and complicated align-
ar X
iv :1
60 8.
06 04
3v 3
[ cs
.C",1 Introduction,[0],[0]
"L
] 8
M ar
ment relations in the translation process.",1 Introduction,[0],[0]
"Using an encoder-decoder framework that incorporates gating and attention techniques, it has been reported that the performance of NMT can surpass the performance of traditional SMT as measured by BLEU score (Luong et al., 2015).
",1 Introduction,[0],[0]
"Despite this success, we observe that NMT usually yields fluent but inadequate",1 Introduction,[0],[0]
"translations.1 We attribute this to a stronger influence of target context on generation, which results from a stronger language model than that used in SMT.",1 Introduction,[0],[0]
"One question naturally arises: what will happen if we change the ratio of influences from the source or target contexts?
",1 Introduction,[0],[0]
"Table 1 shows an example in which an attentionbased NMT system (Bahdanau et al., 2015) generates a fluent yet inadequate translation (e.g., missing the translation of “guǎngdōng”).",1 Introduction,[0],[0]
"When we halve the contribution from the source context, the result further loses its adequacy by missing the partial translation “in the first two months of this year”.",1 Introduction,[0],[0]
One possible explanation is that the target context takes a higher weight and thus the system favors a shorter translation.,1 Introduction,[0],[0]
"In contrast, when we halve the contribution from the target context, the result completely loses its fluency by repeatedly generating the translation of “chūkǒu” (i.e., “the export of”) until the generated translation reaches the maximum length.",1 Introduction,[0],[0]
"Therefore, this example indicates that source and target contexts in NMT are highly correlated to translation adequacy and fluency, respectively.
",1 Introduction,[0],[0]
"In fact, conventional NMT lacks effective control on the influence of source and target contexts.",1 Introduction,[0],[0]
"At each decoding step, NMT treats the source and target contexts equally, and thus ignores the different needs of the contexts.",1 Introduction,[0],[0]
"For example, content words in the target sentence are more related to the translation adequacy, and thus should depend more on the source context.",1 Introduction,[0],[0]
"In contrast, function words in the target sentence are often more related to the translation fluency (e.g., “of” after “is fond”), and thus should depend more on the target context.
",1 Introduction,[0],[0]
"In this work, we propose to use context gates to control the contributions of source and target contexts on the generation of target words (decoding)
1Fluency measures whether the translation is fluent, while adequacy measures whether the translation is faithful to the original sentence (Snover et al., 2009).
in NMT.",1 Introduction,[0],[0]
Context gates are non-linear gating units which can dynamically select the amount of context information in the decoding process.,1 Introduction,[0],[0]
"Specifically, at each decoding step, the context gate examines both the source and target contexts, and outputs a ratio between zero and one to determine the percentages of information to utilize from the two contexts.",1 Introduction,[0],[0]
"In this way, the system can balance the adequacy and fluency of the translation with regard to the generation of a word at each position.
",1 Introduction,[0],[0]
"Experimental results show that introducing context gates leads to an average improvement of +2.3 BLEU points over a standard attention-based NMT system (Bahdanau et al., 2015).",1 Introduction,[0],[0]
An interesting finding is that we can replace the GRU units in the decoder with conventional RNN units and in the meantime utilize context gates.,1 Introduction,[0],[0]
"The translation performance is comparable with the standard NMT system with GRU, but the system enjoys a simpler structure (i.e., uses only a single gate and half of the parameters) and a faster decoding (i.e., requires only half the matrix computations for decoding).2",1 Introduction,[0],[0]
"Suppose that x = x1, . . .",2 Neural Machine Translation,[0],[0]
"xj , . . .",2 Neural Machine Translation,[0],[0]
"xJ represents a source sentence and y = y1, . . .",2 Neural Machine Translation,[0],[0]
"yi, . . .",2 Neural Machine Translation,[0],[0]
yI a target sentence.,2 Neural Machine Translation,[0],[0]
"NMT directly models the probability of translation from the source sentence to the target sentence word by word:
P (y|x) = I∏
i=1
P (yi|y<i,x) (1)
2Our code is publicly available at https://github.",2 Neural Machine Translation,[0],[0]
"com/tuzhaopeng/NMT.
",2 Neural Machine Translation,[0],[0]
"where y<i = y1, . . .",2 Neural Machine Translation,[0],[0]
", yi−1.",2 Neural Machine Translation,[0],[0]
"As shown in Figure 1, the probability of generating the i-th word yi is computed by using a recurrent neural network (RNN) in the decoder:
P (yi|y<i,x) = g(yi−1, ti, si) (2)
where g(·) first linearly transforms its input then applies a softmax function, yi−1 is the previously generated word, ti is the i-th decoding hidden state, and si is the i-th source representation.",2 Neural Machine Translation,[0],[0]
"The state ti is computed as follows:
ti = f(yi−1, ti−1, si)
= f(We(yi−1) + Uti−1 + Csi) (3)
where
• f(·) is a function to compute the current decoding state given all the related inputs.",2 Neural Machine Translation,[0],[0]
"It can be either a vanilla RNN unit using tanh function, or a sophisticated gated RNN unit such as GRU (Cho et al., 2014) or LSTM (Hochreiter and Schmidhuber, 1997).
",2 Neural Machine Translation,[0],[0]
"• e(yi−1) ∈ Rm is an m-dimensional embedding of the previously generated word yi−1.
",2 Neural Machine Translation,[0],[0]
• si is a vector representation extracted from the source sentence by the encoder.,2 Neural Machine Translation,[0],[0]
"The encoder usually uses an RNN to encode the source sentence x into a sequence of hidden states h = h1, . . .",2 Neural Machine Translation,[0],[0]
"hj , . . .",2 Neural Machine Translation,[0],[0]
"hJ , in which hj is the hidden state of the j-th source word xj .",2 Neural Machine Translation,[0],[0]
"si can be either a static vector that summarizes the whole sentence (e.g., si ≡ hJ )",2 Neural Machine Translation,[0],[0]
"(Cho et al., 2014; Sutskever et al., 2014), or a dynamic vector that selectively summarizes certain parts of the source sentence at each decoding step (e.g., si = ∑J j=1 αi,jhj in which αi,j
is alignment probability calculated by an attention model) (Bahdanau et al., 2015).
• W ∈ Rn×m, U ∈ Rn×n, C ∈ Rn×n′ are matrices with n and n′ being the numbers of units of decoder hidden state and source representation, respectively.
",2 Neural Machine Translation,[0],[0]
"The inputs to the decoder (i.e., si, ti−1, and yi−1) represent the contexts.",2 Neural Machine Translation,[0],[0]
"Specifically, the source representation si stands for source context, which embeds the information from the source sentence.",2 Neural Machine Translation,[0],[0]
"The
previous decoding state ti−1 and the previously generated word yi−1 constitute the target context.3",2 Neural Machine Translation,[0],[0]
We first empirically investigate our hypothesis: whether source and target contexts correlate to translation adequacy and fluency.,2.1 Effects of Source and Target Contexts,[0],[0]
"Figure 2(a) shows the translation lengths with various scaling ratios (a, b)
",2.1 Effects of Source and Target Contexts,[0],[0]
"3In a recent implementation of NMT (https: //github.com/nyu-dl/dl4mt-tutorial), ti−1 and yi−1 are combined together with a GRU before being fed into the decoder, which can boost translation performance.",2.1 Effects of Source and Target Contexts,[0],[0]
"We follow the practice and treat both of them as target context.
for source and target contexts:
ti = f(b⊗ (We(yi−1) + Uti−1) + a⊗ Csi)
",2.1 Effects of Source and Target Contexts,[0],[0]
"For example, the pair (1.0, 0.5) means fully leveraging the effect of source context while halving the effect of target context.",2.1 Effects of Source and Target Contexts,[0],[0]
"Reducing the effect of target context (i.e., the lines (1.0, 0.8) and (1.0, 0.5)) results in longer translations, while reducing the effect of source context (i.e., the lines (0.8, 1.0) and (0.5, 1.0)) leads to shorter translations.",2.1 Effects of Source and Target Contexts,[0],[0]
"When halving the effect of the target context, most of the generated translations reach the maximum length, which is three times the length of source sentence in this work.
",2.1 Effects of Source and Target Contexts,[0],[0]
Figure 2(b) shows the results of manual evaluation on 200 source sentences randomly sampled from the test sets.,2.1 Effects of Source and Target Contexts,[0],[0]
"Reducing the effect of source context (i.e., (0.8, 1.0) and (0.5, 1.0)) leads to more fluent yet less adequate translations.",2.1 Effects of Source and Target Contexts,[0],[0]
"On the other hand, reducing the effect of target context (i.e., (1.0, 0.5) and (1.0, 0.8)) is expected to yield more adequate but less fluent translations.",2.1 Effects of Source and Target Contexts,[0],[0]
"In this setting, the source words are translated (i.e., higher adequacy) while the translations are in wrong order (i.e., lower fluency).",2.1 Effects of Source and Target Contexts,[0],[0]
"In practice, however, we observe the side effect that some source words are translated repeatedly until the translation reaches the maximum length (i.e., lower fluency), while others are left untranslated (i.e., lower adequacy).",2.1 Effects of Source and Target Contexts,[0],[0]
"The reason is two fold:
1.",2.1 Effects of Source and Target Contexts,[0],[0]
NMT lacks a mechanism that guarantees that each source word is translated.4,2.1 Effects of Source and Target Contexts,[0],[0]
The decoding state implicitly models the notion of “coverage” by recurrently reading the time-dependent source context si.,2.1 Effects of Source and Target Contexts,[0],[0]
"Lowering its contribution weakens the “coverage” effect and encourages the decoder to regenerate phrases multiple times to achieve the desired translation length.
2.",2.1 Effects of Source and Target Contexts,[0],[0]
The translation is incomplete.,2.1 Effects of Source and Target Contexts,[0],[0]
"As shown in Table 1, NMT can get stuck in an infinite loop repeatedly generating a phrase due to the overwhelming influence of the source context.",2.1 Effects of Source and Target Contexts,[0],[0]
"As a result, generation terminates early because
4The recently proposed coverage based technique can alleviate this problem (Tu et al., 2016).",2.1 Effects of Source and Target Contexts,[0],[0]
"In this work, we consider another approach, which is complementary to the coverage mechanism.
",2.1 Effects of Source and Target Contexts,[0],[0]
"the translation reaches the maximum length allowed by the implementation, even though the decoding procedure is not finished.
",2.1 Effects of Source and Target Contexts,[0],[0]
"The quantitative (Figure 2) and qualitative (Table 1) results confirm our hypothesis, i.e., source and target contexts are highly correlated to translation adequacy and fluency.",2.1 Effects of Source and Target Contexts,[0],[0]
"We believe that a mechanism that can dynamically select information from source context and target context would be useful for NMT models, and this is exactly the approach we propose.",2.1 Effects of Source and Target Contexts,[0],[0]
"Inspired by the success of gated units in RNN (Hochreiter and Schmidhuber, 1997; Cho et al., 2014), we propose using context gates to dynamically control the amount of information flowing from the source and target contexts and thus balance the fluency and adequacy of NMT at each decoding step.
",3.1 Architecture,[0],[0]
"Intuitively, at each decoding step i, the context gate looks at input signals from both the source (i.e., si) and target (i.e., ti−1 and yi−1) sides, and outputs a number between 0 and 1 for each element in the input vectors, where 1 denotes “completely transferring this” while 0 denotes “completely ignoring this”.",3.1 Architecture,[0],[0]
"The corresponding input signals are then processed with an element-wise multiplication before being fed to the activation layer to update the decoding state.
",3.1 Architecture,[0],[0]
"Formally, a context gate consists of a sigmoid neural network layer and an element-wise multiplication operation, as illustrated in Figure 3.",3.1 Architecture,[0],[0]
"The context gate assigns an element-wise weight to the input
signals, computed by
zi = σ(Wze(yi−1) + Uzti−1 + Czsi) (4)
",3.1 Architecture,[0],[0]
"Here σ(·) is a logistic sigmoid function, and Wz ∈ Rn×m, Uz ∈ Rn×n, Cz ∈ Rn×n ′",3.1 Architecture,[0],[0]
are the weight matrices.,3.1 Architecture,[0],[0]
"Again, m, n and n′ are the dimensions of word embedding, decoding state, and source representation, respectively.",3.1 Architecture,[0],[0]
"Note that zi has the same dimensionality as the transferred input signals (e.g., Csi), and thus each element in the input vectors has its own weight.",3.1 Architecture,[0],[0]
"Next, we consider how to integrate context gates into an NMT model.
",3.2 Integrating Context Gates into NMT,[0],[0]
The context gate can decide the amount of context information used in generating the next target word at each step of decoding.,3.2 Integrating Context Gates into NMT,[0],[0]
"For example, after obtaining the partial translation “. . .",3.2 Integrating Context Gates into NMT,[0],[0]
"new high level technology product”, the gate looks at the translation contexts and decides to depend more heavily on the source context.",3.2 Integrating Context Gates into NMT,[0],[0]
"Accordingly, the gate assigns higher weights to the source context and lower weights to the target context and then feeds them into the decoding activation layer.",3.2 Integrating Context Gates into NMT,[0],[0]
"This could correct inadequate translations, such as the missing translation of “guǎngdōng”, due to greater influence from the target context.
",3.2 Integrating Context Gates into NMT,[0],[0]
"We have three strategies for integrating context gates into NMT that either affect one of the translation contexts or both contexts, as illustrated in Figure 4.",3.2 Integrating Context Gates into NMT,[0],[0]
"The first two strategies are inspired by output gates in LSTMs (Hochreiter and Schmidhuber,
1997), which control the amount of memory content utilized.",3.2 Integrating Context Gates into NMT,[0],[0]
"In these kinds of models, zi only affects either source context (i.e., si) or target context (i.e., yi−1 and ti−1):
• Context Gate (source)
",3.2 Integrating Context Gates into NMT,[0],[0]
"ti = f ( We(yi−1) + Uti−1 + zi ◦ Csi ) • Context Gate (target)
",3.2 Integrating Context Gates into NMT,[0],[0]
"ti = f ( zi ◦ (We(yi−1) + Uti−1) + Csi ) where ◦ is an element-wise multiplication, and zi is the context gate calculated by Equation 4.",3.2 Integrating Context Gates into NMT,[0],[0]
"This is also essentially similar to the reset gate in the GRU, which decides what information to forget from the previous decoding state before transferring that information to the decoding activation layer.",3.2 Integrating Context Gates into NMT,[0],[0]
"The difference is that here the “reset” gate resets the context vector rather than the previous decoding state.
",3.2 Integrating Context Gates into NMT,[0],[0]
"The last strategy is inspired by the concept of update gate from GRU, which takes a linear sum between the previous state ti−1 and the candidate new state t̃i.",3.2 Integrating Context Gates into NMT,[0],[0]
"In our case, we take a linear interpolation between source and target contexts:
• Context Gate (both)
",3.2 Integrating Context Gates into NMT,[0],[0]
ti = f,3.2 Integrating Context Gates into NMT,[0],[0]
( (1− zi) ◦,3.2 Integrating Context Gates into NMT,[0],[0]
(We(yi−1) + Uti−1) + zi ◦ Csi ),3.2 Integrating Context Gates into NMT,[0],[0]
"Comparison to (Xu et al., 2015): Context gates are inspired by the gating scalar model proposed by Xu et al. (2015) for the image caption generation task.",4 Related Work,[0],[0]
"The essential difference lies in the task requirement:
• In image caption generation, the source side (i.e., image) contains more information than the target side (i.e., caption).",4 Related Work,[0],[0]
"Therefore, they employ a gating scalar to scale only the source context.
",4 Related Work,[0],[0]
"• In machine translation, both languages should contain equivalent information.",4 Related Work,[0],[0]
Our model jointly controls the contributions from the source and target contexts.,4 Related Work,[0],[0]
"A direct interaction between input signals from both sides is useful for balancing adequacy and fluency of NMT.
",4 Related Work,[0],[0]
"Other differences in the architecture include:
1 Xu et al. (2015) uses a scalar that is shared by all elements in the source context, while we employ a gate with a distinct weight for each element.",4 Related Work,[0],[0]
"The latter offers the gate a more precise control of the context vector, since different elements retain different information.
",4 Related Work,[0],[0]
"2 We add peephole connections to the architecture, by which the source context controls the gate.",4 Related Work,[0],[0]
"It has been shown that peephole connections make precise timings easier to learn (Gers and Schmidhuber, 2000).
",4 Related Work,[0],[0]
3,4 Related Work,[0],[0]
Our context gate also considers the previously generated word yi−1 as input.,4 Related Work,[0],[0]
"The most recently generated word can help the gate to better estimate the importance of target context, especially for the generation of function words in translations that may not have a corresponding word in the source sentence (e.g., “of” after “is fond”).
",4 Related Work,[0],[0]
"Experimental results (Section 5.4) show that these modifications consistently improve translation quality.
",4 Related Work,[0],[0]
"Comparison to Gated RNN: State-of-the-art NMT models (Sutskever et al., 2014; Bahdanau et al., 2015) generally employ a gated unit (e.g., GRU or LSTM) as the activation function in the decoder.",4 Related Work,[0],[0]
"One might suspect that the context gate proposed in this work is somewhat redundant, given the existing gates that control the amount of information carried over from the previous decoding state si−1 (e.g., reset gate in GRU).",4 Related Work,[0],[0]
"We argue that they are in fact complementary: the context gate regulates the contextual information flowing into the decoding state, while the gated unit captures long-term dependencies between decoding states.",4 Related Work,[0],[0]
"Our experiments confirm the correctness of our hypothesis: the context gate not only improves translation quality when compared to a conventional RNN unit (e.g., an element-wise tanh), but also when compared to a gated unit of GRU, as shown in Section 5.2.
",4 Related Work,[0],[0]
"Comparison to Coverage Mechanism: Recently, Tu et al. (2016) propose adding a coverage mechanism into NMT to alleviate over-translation and under-translation problems, which directly affect translation adequacy.",4 Related Work,[0],[0]
They maintain a coverage vector to keep track of which source words have been translated.,4 Related Work,[0],[0]
The coverage vector is fed to the attention model to help adjust future attention.,4 Related Work,[0],[0]
This guides NMT to focus on the un-translated source words while avoiding repetition of source content.,4 Related Work,[0],[0]
"Our approach is complementary: the coverage mechanism produces a better source context representation, while our context gate controls the effect of the source context based on its relative importance.",4 Related Work,[0],[0]
Experiments in Section 5.2 show that combining the two methods can further improve translation performance.,4 Related Work,[0],[0]
"There is another difference
as well: the coverage mechanism is only applicable to attention-based NMT models, while the context gate is applicable to all NMT models.
",4 Related Work,[0],[0]
"Comparison to Exploiting Auxiliary Contexts in Language Modeling: A thread of work in language modeling (LM) attempts to exploit auxiliary sentence-level or document-level context in an RNN LM (Mikolov and Zweig, 2012; Ji et al., 2015; Wang and Cho, 2016).",4 Related Work,[0],[0]
"Independent of our work, Wang and Cho (2016) propose “early fusion” models of RNNs where additional information from an intersentence context is “fused” with the input to the RNN.",4 Related Work,[0],[0]
"Closely related to Wang and Cho (2016), our approach aims to dynamically control the contributions of required source and target contexts for machine translation, while theirs focuses on integrating auxiliary corpus-level contexts for language modelling to better approximate the corpus-level probability.",4 Related Work,[0],[0]
"In addition, we employ a gating mechanism to produce a dynamic weight at different decoding steps to combine source and target contexts, while they do a linear combination of intra-sentence and inter-sentence contexts with static weights.",4 Related Work,[0],[0]
"Experiments in Section 5.2 show that our gating mechanism significantly outperforms linear interpolation when combining contexts.
",4 Related Work,[0],[0]
"Comparison to Handling Null-Generated Words in SMT: In machine translation, there are certain syntactic elements of the target language that are missing in the source (i.e., null-generated words).",4 Related Work,[0],[0]
In fact this was the preliminary motivation for our approach: current attention models lack a mechanism to control the generation of words that do not have a strong correspondence on the source side.,4 Related Work,[0],[0]
"The model structure of NMT is quite similar to the traditional word-based SMT (Brown et al., 1993).",4 Related Work,[0],[0]
"Therefore, techniques that have proven effective in SMT may also be applicable to NMT.",4 Related Work,[0],[0]
Toutanova et al. (2002) extend the calculation of translation probabilities to include null-generated target words in word-based SMT.,4 Related Work,[0],[0]
These words are generated based on both the special source token null and the neighbouring word in the target language by a mixture model.,4 Related Work,[0],[0]
We have simplified and generalized their approach: we use context gates to dynamically control the contribution of source context.,4 Related Work,[0],[0]
"When producing null-generated words, the context gate can as-
sign lower weights to the source context, by which the source-side information have less influence.",4 Related Work,[0],[0]
"In a sense, the context gate relieves the need for a null state in attention.",4 Related Work,[0],[0]
We carried out experiments on Chinese-English translation.,5.1 Setup,[0],[0]
"The training dataset consisted of 1.25M sentence pairs extracted from LDC corpora5, with 27.9M Chinese words and 34.5M English words respectively.",5.1 Setup,[0],[0]
"We chose the NIST 2002 (MT02) dataset as the development set, and the NIST 2005 (MT05), 2006 (MT06) and 2008 (MT08) datasets as the test sets.",5.1 Setup,[0],[0]
"We used the case-insensitive 4-gram NIST BLEU score (Papineni et al., 2002) as the evaluation metric, and sign-test (Collins et al., 2005) for the statistical significance test.
",5.1 Setup,[0],[0]
"For efficient training of the neural networks, we limited the source and target vocabularies to the most frequent 30K words in Chinese and English, covering approximately 97.7% and 99.3% of the data in the two languages respectively.",5.1 Setup,[0],[0]
All out-ofvocabulary words were mapped to a special token UNK.,5.1 Setup,[0],[0]
We trained each model on sentences of length up to 80 words in the training data.,5.1 Setup,[0],[0]
The word embedding dimension was 620 and the size of a hidden layer was 1000.,5.1 Setup,[0],[0]
"We trained our models until the BLEU score on the development set stops improving.
",5.1 Setup,[0],[0]
"We compared our method with representative SMT and NMT6 models:
• Moses (Koehn et al., 2007): an open source phrase-based translation system with default configuration and a 4-gram language model trained on the target portion of training data;
• GroundHog (Bahdanau et al., 2015): an open source attention-based NMT model with default setting.",5.1 Setup,[0],[0]
"We have two variants that differ in the activation function used in the decoder
5The corpora include LDC2002E18, LDC2003E07, LDC2003E14, Hansards portion of LDC2004T07, LDC2004T08 and LDC2005T06.
",5.1 Setup,[0],[0]
"6There is some recent progress on aggregating multiple models or enlarging the vocabulary(e.g.,, in (Jean et al., 2015)), but here we focus on the generic models.
",5.1 Setup,[0],[0]
"RNN: 1) GroundHog (vanilla) uses a simple tanh function as the activation function, and 2)",5.1 Setup,[0],[0]
"GroundHog (GRU ) uses a sophisticated gate function GRU ;
• GroundHog-Coverage (Tu et al., 2016)7: an improved attention-based NMT model with a coverage mechanism.",5.1 Setup,[0],[0]
Table 2 shows the translation performances in terms of BLEU scores.,5.2 Translation Quality,[0],[0]
We carried out experiments on multiple NMT variants.,5.2 Translation Quality,[0],[0]
"For example, “2 + Context Gate (both)” in Row 3 denotes integrating “Context Gate (both)” into the baseline in Row 2 (i.e., GroundHog (vanilla)).",5.2 Translation Quality,[0],[0]
"For baselines, we found that the gated unit (i.e., GRU , Row 4) indeed surpasses its vanilla counterpart (i.e., tanh, Row 2), which is consistent with the results in other work (Chung et al., 2014).",5.2 Translation Quality,[0],[0]
"Clearly the proposed context gates significantly improve the translation quality in all cases, although there are still considerable differences among the variants:
Parameters Context gates introduce a few new parameters.",5.2 Translation Quality,[0],[0]
"The newly introduced parameters include Wz ∈ Rn×m, Uz ∈ Rn×n, Cz ∈ Rn×n ′",5.2 Translation Quality,[0],[0]
"in
7https://github.com/tuzhaopeng/ NMT-Coverage.
Equation 4.",5.2 Translation Quality,[0],[0]
"In this work, the dimensionality of the decoding state is n = 1000, the dimensionality of the word embedding is m = 620, and the dimensionality of context representation is n′ = 2000.",5.2 Translation Quality,[0],[0]
"The context gates only introduce 3.6M additional parameters, which is quite small compared to the number of parameters in the existing models (e.g., 84.3M in the “GroundHog (GRU )”).
",5.2 Translation Quality,[0],[0]
Over GroundHog (vanilla),5.2 Translation Quality,[0],[0]
"We first carried out experiments on a simple decoder without gating function (Rows 2 and 3), to better estimate the impact of context gates.",5.2 Translation Quality,[0],[0]
"As shown in Table 2, the proposed context gate significantly improved translation performance by 4.2 BLEU points on average.",5.2 Translation Quality,[0],[0]
"It is worth emphasizing that context gate even outperforms a more sophisticated gating function (i.e., GRU in Row 4).",5.2 Translation Quality,[0],[0]
"This is very encouraging, since our model only has a single gate with half of the parameters (i.e., 3.6M versus 7.2M) and less computations (i.e., half the matrix computations to update the decoding state8).
",5.2 Translation Quality,[0],[0]
8We only need to calculate the context gate once via Equation 4 and then apply it when updating the decoding state.,5.2 Translation Quality,[0],[0]
"In contrast, GRU requires the calculation of an update gate, a reset gate, a proposed updated decoding state and an interpolation between the previous state and the proposed state.",5.2 Translation Quality,[0],[0]
"Please refer to (Cho et al., 2014) for more details.
",5.2 Translation Quality,[0],[0]
Over GroundHog (GRU) We then investigated the effect of the context gates on a standard NMT with GRU as the decoding activation function (Rows 4-7).,5.2 Translation Quality,[0],[0]
Several observations can be made.,5.2 Translation Quality,[0],[0]
"First, context gates also boost performance beyond the GRU in all cases, demonstrating our claim that context gates are complementary to the reset and update gates in GRU.",5.2 Translation Quality,[0],[0]
"Second, jointly controlling the information from both translation contexts consistently outperforms its single-side counterparts, indicating that a direct interaction between input signals from the source and target contexts is useful for NMT models.
",5.2 Translation Quality,[0],[0]
"Over GroundHog-Coverage (GRU) We finally tested on a stronger baseline, which employs a coverage mechanism to indicate whether or not a source word has already been translated (Tu et al., 2016).",5.2 Translation Quality,[0],[0]
"Our context gate still achieves a significant improvement of 1.6 BLEU points on average, reconfirming our claim that the context gate is complementary to the improved attention model that produces a better source context representation.",5.2 Translation Quality,[0],[0]
"Finally, our best model (Row 7) outperforms the SMT baseline system using the same data (Row 1) by 3.3 BLEU points.
",5.2 Translation Quality,[0],[0]
"From here on, we refer to “GroundHog” for “GroundHog (GRU )”, and “Context Gate” for “Context Gate (both)”",5.2 Translation Quality,[0],[0]
"if not otherwise stated.
",5.2 Translation Quality,[0],[0]
Subjective Evaluation We also conducted a subjective evaluation of the benefit of incorporating context gates.,5.2 Translation Quality,[0],[0]
Two human evaluators were asked to compare the translations of 200 source sentences randomly sampled from the test sets without knowing which system produced each translation.,5.2 Translation Quality,[0],[0]
Table 3 shows the results of subjective evaluation.,5.2 Translation Quality,[0],[0]
"The two human evaluators made similar judgments: in adequacy, around 30% of GroundHog translations are worse, 52% are equal, and 18% are better; while in
fluency, around 29% are worse, 52% are equal, and 19% are better.",5.2 Translation Quality,[0],[0]
Table 4 lists the alignment performances.,5.3 Alignment Quality,[0],[0]
"Following Tu et al. (2016), we used the alignment error rate (AER) (Och and Ney, 2003) and its variant SAER to measure the alignment quality:
SAER = 1− |MA ×MS |+ |MA ×MP",5.3 Alignment Quality,[0],[0]
"| |MA|+ |MS |
where A is a candidate alignment, and S and P are the sets of sure and possible links in the reference alignment respectively (S ⊆ P ).",5.3 Alignment Quality,[0],[0]
"M denotes the alignment matrix, and for both MS and MP we assign the elements that correspond to the existing links in S and P probability 1 and the other elements probability 0.",5.3 Alignment Quality,[0],[0]
"In this way, we are able to better evaluate the quality of the soft alignments produced by attention-based NMT.
",5.3 Alignment Quality,[0],[0]
We find that context gates do not improve alignment quality when used alone.,5.3 Alignment Quality,[0],[0]
"When combined with coverage mechanism, however, it produces better alignments, especially one-to-one alignments by selecting the source word with the highest alignment probability per target word (i.e., AER score).",5.3 Alignment Quality,[0],[0]
"One possible reason is that better estimated decoding states (from the context gate) and coverage information help to produce more concentrated alignments, as shown in Figure 6.",5.3 Alignment Quality,[0],[0]
Table 5 shows a detailed analysis of architecture components measured in BLEU scores.,5.4 Architecture Analysis,[0],[0]
"Several observations can be made:
• Operation Granularity (Rows 2 and 3): Element-wise multiplication (i.e., Context Gate (source)) outperforms the vector-level scalar (i.e., Gating Scalar), indicating that precise control of each element in the context vector boosts translation performance.
",5.4 Architecture Analysis,[0],[0]
"• Gate Strategy (Rows 3 and 4): When only fed with the previous decoding state ti−1, Context Gate (both) consistently outperforms Context Gate (source), showing that jointly controlling information from both source and target sides
is important for judging the importance of the contexts.
",5.4 Architecture Analysis,[0],[0]
"• Peephole connections (Rows 4 and 5): Peepholes, by which the source context si controls the gate, play an important role in the context gate, which improves the performance by 0.57 in BLEU score.
",5.4 Architecture Analysis,[0],[0]
"• Previously generated word (Rows 5 and 6): Previously generated word yi−1 provides a more explicit signal for the gate to judge the importance of contexts, leading to a further improvement on translation performance.",5.4 Architecture Analysis,[0],[0]
We follow Bahdanau et al. (2015) and group sentences of similar lengths together.,5.5 Effects on Long Sentences,[0],[0]
"Figure 7 shows
the BLEU score and the averaged length of translations for each group.",5.5 Effects on Long Sentences,[0],[0]
"GroundHog performs very well on short source sentences, but degrades on long source sentences (i.e., > 30), which may be due to the fact that source context is not fully interpreted.",5.5 Effects on Long Sentences,[0],[0]
"Context gates can alleviate this problem by balancing the source and target contexts, and thus improve decoder performance on long sentences.",5.5 Effects on Long Sentences,[0],[0]
"In fact, incorporating context gates boost translation performance on all source sentence groups.
",5.5 Effects on Long Sentences,[0],[0]
We confirm that context gate weight zi correlates well with translation performance.,5.5 Effects on Long Sentences,[0],[0]
"In other words, translations that contain higher zi (i.e., source context contributes more than target context) at many time steps are better in translation performance.",5.5 Effects on Long Sentences,[0],[0]
"We used the mean of the sequence z1, . . .",5.5 Effects on Long Sentences,[0],[0]
", zi, . . .",5.5 Effects on Long Sentences,[0],[0]
", zI as the gate weight of each sentence.",5.5 Effects on Long Sentences,[0],[0]
"We calculated the Pearson Correlation between the sentence-level gate weight and the corresponding improvement on translation performance (i.e., BLEU, adequacy, and fluency scores),9 as shown in Table 6.",5.5 Effects on Long Sentences,[0],[0]
"We observed that context gate weight is positively correlated with translation performance improvement and that the correlation is higher on long sentences.
",5.5 Effects on Long Sentences,[0],[0]
"As an example, consider this source sentence from the test set:
9We use the average of correlations on subjective evaluation metrics (i.e., adequacy and fluency) by two evaluators.
",5.5 Effects on Long Sentences,[0],[0]
"zhōuliù zhèngshı̀ yı̄ngguó mı́nzhòng dào chāoshı̀ cǎigòu de gāofēng shı́kè, dāngshı́ 14 jiā",5.5 Effects on Long Sentences,[0],[0]
chāoshı̀ de guānbı̀ lı̀ng yı̄ngguó zhè jiā,5.5 Effects on Long Sentences,[0],[0]
zuı̀,5.5 Effects on Long Sentences,[0],[0]
dà de liánsuǒ,5.5 Effects on Long Sentences,[0],[0]
chāoshı̀ sǔnshı̄ shùbǎiwàn,5.5 Effects on Long Sentences,[0],[0]
yı̄ngbàng,5.5 Effects on Long Sentences,[0],[0]
"de xiāoshòu shōurù .
",5.5 Effects on Long Sentences,[0],[0]
"GroundHog translates it into:
twenty - six london supermarkets were closed at a peak hour of the british population in the same period of time .
which almost misses all the information of the source sentence.",5.5 Effects on Long Sentences,[0],[0]
"Integrating context gates improves the translation adequacy:
this is exactly the peak days British people buying the supermarket .",5.5 Effects on Long Sentences,[0],[0]
"the closure
of the 14 supermarkets of the 14 supermarkets that the largest chain supermarket in england lost several million pounds of sales income .
",5.5 Effects on Long Sentences,[0],[0]
"Coverage mechanisms further improve the translation by rectifying over-translation (e.g., “of the 14 supermarkets”) and under-translation (e.g., “saturday” and “at that time”):
saturday is the peak season of british people ’s purchases of the supermarket .",5.5 Effects on Long Sentences,[0],[0]
"at that time , the closure of 14 supermarkets made the biggest supermarket of britain lose millions of pounds of sales income .",5.5 Effects on Long Sentences,[0],[0]
"We find that source and target contexts in NMT are highly correlated to translation adequacy and fluency, respectively.",6 Conclusion,[0],[0]
"Based on this observation, we propose using context gates in NMT to dynamically control the contributions from the source and target contexts in the generation of a target sentence, to enhance the adequacy of NMT.",6 Conclusion,[0],[0]
"By providing NMT the ability to choose the appropriate amount of information from the source and target contexts, one can alleviate many translation problems from which NMT suffers.",6 Conclusion,[0],[0]
"Experimental results show that NMT with context gates achieves consistent and significant improvements in translation quality over different NMT models.
",6 Conclusion,[0],[0]
Context gates are in principle applicable to all sequence-to-sequence learning tasks in which information from the source sequence is transformed to the target sequence (corresponding to adequacy) and the target sequence is generated (corresponding to fluency).,6 Conclusion,[0],[0]
"In the future, we will investigate the effectiveness of context gates to other tasks, such as dialogue and summarization.",6 Conclusion,[0],[0]
"It is also necessary to validate the effectiveness of our approach on more language pairs and other NMT architectures (e.g., using LSTM as well as GRU, or multiple layers).",6 Conclusion,[0],[0]
This work is supported by China National 973 project 2014CB340301.,Acknowledgement,[0],[0]
"Yang Liu is supported by the National Natural Science Foundation of China (No. 61522204) and the 863 Program
(2015AA015407).",Acknowledgement,[0],[0]
We thank action editor Chris Quirk and three anonymous reviewers for their insightful comments.,Acknowledgement,[0],[0]
"In neural machine translation (NMT), generation of a target word depends on both source and target contexts.",abstractText,[0],[0]
We find that source contexts have a direct impact on the adequacy of a translation while target contexts affect the fluency.,abstractText,[0],[0]
"Intuitively, generation of a content word should rely more on the source context and generation of a functional word should rely more on the target context.",abstractText,[0],[0]
"Due to the lack of effective control over the influence from source and target contexts, conventional NMT tends to yield fluent but inadequate translations.",abstractText,[0],[0]
"To address this problem, we propose context gates which dynamically control the ratios at which source and target contexts contribute to the generation of target words.",abstractText,[0],[0]
"In this way, we can enhance both the adequacy and fluency of NMT with more careful control of the information flow from contexts.",abstractText,[0],[0]
Experiments show that our approach significantly improves upon a standard attentionbased NMT system by +2.3 BLEU points.,abstractText,[0],[0]
Context Gates for Neural Machine Translation,title,[0],[0]
"Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 325–335, Baltimore, Maryland, USA, June 23-25 2014. c©2014 Association for Computational Linguistics",text,[0],[0]
"The ability to extract sentiment from text is crucial for many opinion-mining applications such as opinion summarization, opinion question answering and opinion retrieval.",1 Introduction,[0],[0]
"Accordingly, extracting sentiment at the fine-grained level (e.g. at the sentence- or phrase-level) has received increasing attention recently due to its challenging nature and its importance in supporting these opinion analysis tasks (Pang and Lee, 2008).
",1 Introduction,[0],[0]
"In this paper, we focus on the task of sentencelevel sentiment classification in online reviews.",1 Introduction,[0],[0]
"Typical approaches to the task employ supervised
machine learning algorithms with rich features and take into account the interactions between words to handle compositional effects such as polarity reversal (e.g. (Nakagawa et al., 2010; Socher et al., 2013)).",1 Introduction,[0],[0]
"Still, their methods can encounter difficulty when the sentence on its own does not contain strong enough sentiment signals (due to the lack of statistical evidence or the requirement for background knowledge).",1 Introduction,[0],[0]
"Consider the following review for example,
1.",1 Introduction,[0],[0]
"Hearing the music in real stereo is a true reve-
lation.",1 Introduction,[0],[0]
2.,1 Introduction,[0],[0]
"You can feel that the music is no longer
constrained by the mono recording.",1 Introduction,[0],[0]
3.,1 Introduction,[0],[0]
"In fact, it
is more like the players are performing on a stage
in front of you ...
",1 Introduction,[0],[0]
"Existing feature-based classifiers may be effective in identifying the positive sentiment of the first sentence due to the use of the word revelation, but they could be less effective in the last two sentences due to the lack of explicit sentiment signals.",1 Introduction,[0],[0]
"However, if we examine these sentences within the discourse context, we can see that: the second sentence expresses sentiment towards the same aspect – the music – as the first sentence; the third sentence expands the second sentence with the discourse connective",1 Introduction,[0],[0]
In fact.,1 Introduction,[0],[0]
"These discourse-level relations help indicate that sentence 2 and 3 are likely to have positive sentiment as well.
",1 Introduction,[0],[0]
The importance of discourse for sentiment analysis has become increasingly recognized.,1 Introduction,[0],[0]
"Most existing work considers discourse relations between adjacent sentences or clauses and incorporates them as constraints (Kanayama and Nasukawa, 2006; Zhou et al., 2011) or features in classifiers Trivedi and Eisenstein (2013; Lazaridou et al. (2013).",1 Introduction,[0],[0]
Very little work has explored long-distance discourse relations for sentiment analysis.,1 Introduction,[0],[0]
"Somasundaran et al. (2008) defines coreference relations on opinion targets and applies them to constrain the polarity of sentences.
",1 Introduction,[0],[0]
"325
However, the discourse relations were obtained from fine-grained annotations and implemented as hard constraints on polarity.
",1 Introduction,[0],[0]
Obtaining sentiment labels at the fine-grained level is costly.,1 Introduction,[0],[0]
"Semi-supervised techniques have been proposed for sentence-level sentiment classification (Täckström and McDonald, 2011a; Qu et al., 2012).",1 Introduction,[0],[0]
"However, they rely on a large amount of document-level sentiment labels that may not be naturally available in many domains.
",1 Introduction,[0],[0]
"In this paper, we propose a sentence-level sentiment classification method that can (1) incorporate rich discourse information at both local and global levels; (2) encode discourse knowledge as soft constraints during learning; (3) make use of unlabeled data to enhance learning.",1 Introduction,[0],[0]
"Specifically, we use the Conditional Random Field (CRF) model as the learner for sentence-level sentiment classification, and incorporate rich discourse and lexical knowledge as soft constraints into the learning of CRF parameters via Posterior Regularization (PR) (Ganchev et al., 2010).",1 Introduction,[0],[0]
"As a framework for structured learning with constraints, PR has been successfully applied to many structural NLP tasks (Ganchev et al., 2009; Ganchev et al., 2010; Ganchev and Das, 2013).",1 Introduction,[0],[0]
Our work is the first to explore PR for sentiment analysis.,1 Introduction,[0],[0]
"Unlike most previous work, we explore a rich set of structural constraints that cannot be naturally encoded in the feature-label form, and show that such constraints can improve the performance of the CRF model.
",1 Introduction,[0],[0]
We evaluate our approach on the sentencelevel sentiment classification task using two standard product review datasets.,1 Introduction,[0],[0]
Experimental results show that our model outperforms state-ofthe-art methods in both the supervised and semisupervised settings.,1 Introduction,[0],[0]
We also show that discourse knowledge is highly useful for improving sentence-level sentiment classification.,1 Introduction,[0],[0]
"There has been a large amount of work on sentiment analysis at various levels of granularity (Pang and Lee, 2008).",2 Related Work,[0],[0]
"In this paper, we focus on the study of sentence-level sentiment classification.",2 Related Work,[0],[0]
Existing machine learning approaches for the task can be classified based on the use of two ideas.,2 Related Work,[0],[0]
"The first idea is to exploit sentiment signals at the sentence level by learning the relevance of sentiment and words while taking into account the context in which they occur: Nakagawa et
al. (2010) uses tree-CRF to model word interactions based on dependency tree structures; Choi and Cardie (2008) applies compositional inference rules to handle polarity reversal; Socher et al. (2011) and Socher et al. (2013) compute compositional vector representations for words and phrases and use them as features in a classifier.
",2 Related Work,[0],[0]
The second idea is to exploit sentiment signals at the inter-sentential level.,2 Related Work,[0],[0]
Polanyi and Zaenen (2006) argue that discourse structure is important in polarity classification.,2 Related Work,[0],[0]
"Various attempts have been made to incorporate discourse relations into sentiment analysis: Pang and Lee (2004) explored the consistency of subjectivity between neighboring sentences; Mao and Lebanon (2007),McDonald et al. (2007), and Täckström and McDonald (2011a) developed structured learning models to capture sentiment dependencies between adjacent sentences; Kanayama and Nasukawa (2006) and Zhou et al. (2011) use discourse relations to constrain two text segments to have either the same polarity or opposite polarities; Trivedi and Eisenstein (2013) and Lazaridou et al. (2013) encode the discourse connectors as model features in supervised classifiers.",2 Related Work,[0],[0]
Very little work has explored long-distance discourse relations.,2 Related Work,[0],[0]
Somasundaran et al. (2008) define opinion target relations and apply them to constrain the polarity of text segments annotated with target relations.,2 Related Work,[0],[0]
"Recently, Zhang et al. (2013) explored the use of explanatory discourse relations as soft constraints in a Markov Logic Network framework for extracting subjective text segments.
",2 Related Work,[0],[0]
"Leveraging both ideas, our approach exploits sentiment signals from both intra-sentential and inter-sentential context.",2 Related Work,[0],[0]
"It has the advantages of utilizing rich discourse knowledge at different levels of context and encoding it as soft constraints during learning.
",2 Related Work,[0],[0]
Our approach is also semi-supervised.,2 Related Work,[0],[0]
"Compared to the existing work on semi-supervised learning for sentence-level sentiment classification (Täckström and McDonald, 2011a; Täckström and McDonald, 2011b; Qu et al., 2012), our work does not rely on a large amount of coarse-grained (document-level) labeled data, instead, distant supervision mainly comes from linguisticallymotivated constraints.
",2 Related Work,[0],[0]
"Our work also relates to the study of posterior regularization (PR) (Ganchev et al., 2010).",2 Related Work,[0],[0]
"PR has been successfully applied to many structured NLP
tasks such as dependency parsing, information extraction and cross-lingual learning tasks (Ganchev et al., 2009; Bellare et al., 2009; Ganchev et al., 2010; Ganchev and Das, 2013).",2 Related Work,[0],[0]
Most previous work using PR mainly experiments with featurelabel constraints.,2 Related Work,[0],[0]
"In contrast, we explore a rich set of linguistically-motivated constraints which cannot be naturally formulated in the feature-label form.",2 Related Work,[0],[0]
We also show that constraints derived from the discourse context can be highly useful for disambiguating sentence-level sentiment.,2 Related Work,[0],[0]
"In this section, we present the details of our proposed approach.",3 Approach,[0],[0]
We formulate the sentence-level sentiment classification task as a sequence labeling problem.,3 Approach,[0],[0]
"The inputs to the model are sentencesegmented documents annotated with sentencelevel sentiment labels (positive, negative or neutral) along with a set of unlabeled documents.",3 Approach,[0],[0]
"During prediction, the model outputs sentiment labels for a sequence of sentences in the test document.",3 Approach,[0],[0]
"We utilize conditional random fields and use Posterior Regularization (PR) to learn their parameters with a rich set of context-aware constraints.
",3 Approach,[0],[0]
"In what follows, we first briefly describe the framework of Posterior Regularization.",3 Approach,[0],[0]
Then we introduce the context-aware constraints derived based on intuitive discourse and lexical knowledge.,3 Approach,[0],[0]
Finally we describe how to perform learning and inference with these constraints.,3 Approach,[0],[0]
"PR is a framework for structured learning with constraints (Ganchev et al., 2010).",3.1 Posterior Regularization,[0],[0]
"In this work, we apply PR in the context of CRFs for sentencelevel sentiment classification.
",3.1 Posterior Regularization,[0],[0]
Denote x as a sequence of sentences within a document and y as a vector of sentiment labels associated with x.,3.1 Posterior Regularization,[0],[0]
"The CRF model the following conditional probabilities:
pθ(y|x) = exp(θ · f(x,y)) Zθ(x)
where f(x,y) are the model features, θ are the model parameters, and Zθ(x)",3.1 Posterior Regularization,[0],[0]
"= ∑ y exp(θ · f(x,y)) is a normalization constant.",3.1 Posterior Regularization,[0],[0]
"The objective function for a standard CRF is to maximize the log-likelihood over a collection of labeled doc-
uments plus a regularization term:
max θ L(θ) = max θ ∑ (x,y) log pθ(y|x)− ||θ|| 2 2 2δ2
PR makes the assumption that the labeled data we have is not enough for learning good model parameters, but we have a set of constraints on the posterior distribution of the labels.",3.1 Posterior Regularization,[0],[0]
"We can define the set of desirable posterior distrbutions as
Q = {q(Y) : Eq[φ(X,Y)]",3.1 Posterior Regularization,[0],[0]
"= b} (1) where φ is a constraint function, b is a vector of desired values of the expectations of the constraint functions under the distribution q 1.",3.1 Posterior Regularization,[0],[0]
"Note that the distribution q is defined over a collection of unlabeled documents where the constraint functions apply, and we assume independence between documents.
",3.1 Posterior Regularization,[0],[0]
"The PR objective can be written as the original model objective penalized with a regularization term, which minimizes the KL-divergence between the desired model posteriors and the learned model posteriors with an L2 penalty 2 for the constraint violations.
",3.1 Posterior Regularization,[0],[0]
"max θ L(θ)−min q∈Q {KL(q(Y)||pθ(Y|X))
+ β||Eq[φ(X,",3.1 Posterior Regularization,[0],[0]
"Y)]− b||22} (2)
",3.1 Posterior Regularization,[0],[0]
The objective can be optimized by an EM-like scheme that iteratively solves the minimization problem and the maximization problem.,3.1 Posterior Regularization,[0],[0]
Solving the minimization problem is equivalent to solving its dual since the objective is convex.,3.1 Posterior Regularization,[0],[0]
"The dual problem is
arg max λ λ · b− logZλ(X)− 14β",3.1 Posterior Regularization,[0],[0]
"||λ|| 2 2 (3)
",3.1 Posterior Regularization,[0],[0]
"We optimize the objective function 2 using stochastic projected gradient, and compute the learning rate using AdaGrad (Duchi et al., 2010).",3.1 Posterior Regularization,[0],[0]
We develop a rich set of context-aware posterior constraints for sentence-level sentiment analysis by exploiting lexical and discourse knowledge.,3.2 Context-aware Posterior Constraints,[0],[0]
"Specifically, we construct the lexical constraints by extracting sentiment-bearing patterns
1In general, inequality constraints can also be used.",3.2 Context-aware Posterior Constraints,[0],[0]
"We focus on the equality constraints since we found them to express the sentiment-relevant constraints well.
",3.2 Context-aware Posterior Constraints,[0],[0]
2Other convex functions can be used for the penalty.,3.2 Context-aware Posterior Constraints,[0],[0]
We use L2 norm because it works well in practice.,3.2 Context-aware Posterior Constraints,[0],[0]
"β is a regularization constant
within sentences and construct the discourse-level constraints by extracting discourse relations that indicate sentiment coherence or sentiment changes both within and across sentences.",3.2 Context-aware Posterior Constraints,[0],[0]
Each constraint can be formulated as equality between the expectation of a constraint function value and a desired value set by prior knowledge.,3.2 Context-aware Posterior Constraints,[0],[0]
The equality is not strictly enforced (due to the regularization in the PR objective 2).,3.2 Context-aware Posterior Constraints,[0],[0]
Therefore all the constraints are applied as soft constraints.,3.2 Context-aware Posterior Constraints,[0],[0]
"Table 1 provides intuitive description and examples for all the constraints used in our model.
",3.2 Context-aware Posterior Constraints,[0],[0]
Lexical Patterns,3.2 Context-aware Posterior Constraints,[0],[0]
"The existence of a polaritycarrying word alone may not correctly indicate the polarity of the sentence, as the polarity can be reversed by other polarity-reversing words.",3.2 Context-aware Posterior Constraints,[0],[0]
"We extract lexical patterns that consist of polar words and negators 3, and apply the heuristics based on compositional semantics (Choi and Cardie, 2008) to assign a sentiment value to each pattern.
",3.2 Context-aware Posterior Constraints,[0],[0]
We encode the extracted lexical patterns along with their sentiment values as feature-label constraints.,3.2 Context-aware Posterior Constraints,[0],[0]
"The constraint function can be written as
φw(x, y) = ∑ i fw(xi, yi)
where fw(xi, yi) is a feature function which has value 1 when sentence xi contains the lexical pattern w and its sentiment label yi equals to the expected sentiment value and has value 0 otherwise.",3.2 Context-aware Posterior Constraints,[0],[0]
The constraint expectation value is set to be the prior probability of associating w with its sentiment value.,3.2 Context-aware Posterior Constraints,[0],[0]
Note that sentences with neutral sentiment can also contain such lexical patterns.,3.2 Context-aware Posterior Constraints,[0],[0]
Therefore we allow the lexical patterns to be assigned a neutral sentiment with a prior probability r0 (we compute this value as the empirical probability of neutral sentiment in the training documents).,3.2 Context-aware Posterior Constraints,[0],[0]
Using the polarity indicated by lexical patterns to constrain the sentiment of sentences is quite aggressive.,3.2 Context-aware Posterior Constraints,[0],[0]
Therefore we only consider lexical patterns that are strongly discriminative (many opinion words in the lexicon only indicate sentiment with weak strength).,3.2 Context-aware Posterior Constraints,[0],[0]
"The selected lexical patterns include a handful of seed patterns (such as “pros” and “cons”) and the lexical patterns that have high precision (larger then 0.9) of predicting sentiment in the training data.
",3.2 Context-aware Posterior Constraints,[0],[0]
"3The polar words are identified using the MPQA lexicon and the negators are identified using a handful of seed words extended by the General Inquirer dictionary and WordNet as described in (Choi and Cardie, 2008).
",3.2 Context-aware Posterior Constraints,[0],[0]
Discourse Connectives.,3.2 Context-aware Posterior Constraints,[0],[0]
Lexical patterns can be limited in capturing contextual information since they only look at interactions between words within an expression.,3.2 Context-aware Posterior Constraints,[0],[0]
"To capture context at the clause or sentence level, we consider discourse connectives, which are cue phrases or words that indicate discourse relations between adjacent sentences or clauses.",3.2 Context-aware Posterior Constraints,[0],[0]
"To identify discourse connectives, we apply a discourse tagger trained on the Penn Discourse Treebank",3.2 Context-aware Posterior Constraints,[0],[0]
"(Prasad et al., 2008) 4 to our data.",3.2 Context-aware Posterior Constraints,[0],[0]
"Discourse connectives are tagged with four senses: Expansion, Contingency, Comparison, Temporal.
Discourse connectives can operate at both intrasentential and inter-sentential level.",3.2 Context-aware Posterior Constraints,[0],[0]
"For example, the word “although” is often used to connect two polar clauses within a sentence, while the word “however” is often used to at the beginning of the sentence to connect two polar sentences.",3.2 Context-aware Posterior Constraints,[0],[0]
It is important to distinguish these two types of discourse connectives.,3.2 Context-aware Posterior Constraints,[0],[0]
We consider a discourse connective to be intra-sentential if it has the Comparison sense and connects two polar clauses with opposite polarities (determined by the lexical patterns).,3.2 Context-aware Posterior Constraints,[0],[0]
"We construct a feature-label constraint for each intra-sentential discourse connective and set its expected sentiment value to be neutral.
",3.2 Context-aware Posterior Constraints,[0],[0]
"Unlike the intra-sentential discourse connectives, the inter-sentential discourse connectives can indicate sentiment transitions between sentences.",3.2 Context-aware Posterior Constraints,[0],[0]
"Intuitively, discourse connectives with the senses of Expansion (e.g. also, for example, furthermore) and Contingency (e.g. as a result, hence, because) are likely to indicate sentiment coherence; discourse connectives with the sense of Comparison (e.g. but, however, nevertheless) are likely to indicate sentiment changes.",3.2 Context-aware Posterior Constraints,[0],[0]
This intuition is reasonable but it assumes the two sentences connected by the discourse connective are both polar sentences.,3.2 Context-aware Posterior Constraints,[0],[0]
"In general, discourse connectives can also be used to connect non-polar (neutral) sentences.",3.2 Context-aware Posterior Constraints,[0],[0]
"Thus it is hard to directly constrain the posterior expectation for each type of sentiment transitions using inter-sentential discourse connectives.
",3.2 Context-aware Posterior Constraints,[0],[0]
"Instead, we impose constraints on the model posteriors by reducing constraint violations.",3.2 Context-aware Posterior Constraints,[0],[0]
"We
4http://www.cis.upenn.edu/˜epitler/ discourse.html
define the following constraint function:
φc,s(x, y) =",3.2 Context-aware Posterior Constraints,[0],[0]
"∑ i fc,s(xi, yi, yi−1)
",3.2 Context-aware Posterior Constraints,[0],[0]
"where c denotes a discourse connective, s indicates its sense, and fc,s is a penalty function that takes value 1.0 when yi and yi−1 form a contradictory sentiment transition, that is, yi 6=polar yi−1 if s ∈ {Expansion,Contingency}, or yi =polar yi−1 if s = Comparison.",3.2 Context-aware Posterior Constraints,[0],[0]
"The desired value for the constraint expectation is set to 0 so that the model is encouraged to have less constraint violations.
",3.2 Context-aware Posterior Constraints,[0],[0]
"Opinion Coreference Sentences in a discourse can be linked by many types of coherence relations (Jurafsky et al., 2000).",3.2 Context-aware Posterior Constraints,[0],[0]
Coreference is one of the commonly used relations in written text.,3.2 Context-aware Posterior Constraints,[0],[0]
"In this work, we explore coreference in the context of sentence-level sentiment analysis.",3.2 Context-aware Posterior Constraints,[0],[0]
We consider a set of polar sentences to be linked by the opinion coreference relation if they contain coreferring opinion-related entities.,3.2 Context-aware Posterior Constraints,[0],[0]
"For example, the following sentences express opinions towards “the speaker phone”, “The speaker phone” and “it” respectively.",3.2 Context-aware Posterior Constraints,[0],[0]
"As these opinion targets are coreferential (referring to the same entity “the speaker phone”), they are linked by the opinion coreference relation 5.
",3.2 Context-aware Posterior Constraints,[0],[0]
My favorite features are the speaker phone and the radio.,3.2 Context-aware Posterior Constraints,[0],[0]
The speaker phone is very functional.,3.2 Context-aware Posterior Constraints,[0],[0]
"I use it in the car, very audible even with freeway noise.
",3.2 Context-aware Posterior Constraints,[0],[0]
"5In general, the opinion-related entities include both the opinion targets and the opinion holders.",3.2 Context-aware Posterior Constraints,[0],[0]
"In this work, we only consider the targets since we experiment with singleauthor product reviews.",3.2 Context-aware Posterior Constraints,[0],[0]
"The opinion holders can be included in a similar way as the opinion targets.
",3.2 Context-aware Posterior Constraints,[0],[0]
"Our coreference relations indicated by opinion targets overlap with the same target relation introduced in (Somasundaran et al., 2009).",3.2 Context-aware Posterior Constraints,[0],[0]
"The differences are: (1) we encode the coreference relations as soft constraints during learning instead of applying them as hard constraints during inference time; (2) our constraints can apply to both polar and non-polar sentences; (3) our identification of coreference relations is automatic without any fine-grained annotations for opinion targets.
",3.2 Context-aware Posterior Constraints,[0],[0]
"To extract coreferential opinion targets, we apply Stanford’s coreference system (Lee et al., 2013) to extract coreferential mentions in the document, and then apply a set of syntactic rules to identify opinion targets from the extracted mentions.",3.2 Context-aware Posterior Constraints,[0],[0]
The syntactic rules correspond to the shortest dependency paths between an opinion word and an extracted mention.,3.2 Context-aware Posterior Constraints,[0],[0]
We consider the 10 most frequent dependency paths in the training data.,3.2 Context-aware Posterior Constraints,[0],[0]
"Example dependency paths include nsubj(opinion, mention), nobj(opinion, mention), and amod(mention, opinion).
",3.2 Context-aware Posterior Constraints,[0],[0]
"For sentences connected by the opinion coreference relation, we expect their sentiment to be consistent.",3.2 Context-aware Posterior Constraints,[0],[0]
"To encode this intuition, we define the following constraint function:
φcoref (x, y) =",3.2 Context-aware Posterior Constraints,[0],[0]
"∑
i,ant(i)=j,j≥0 fcoref (xi, xj , yi, yj)
where ant(i) denotes the index of the sentence which contains an antecedent target of the target mentioned in sentence",3.2 Context-aware Posterior Constraints,[0],[0]
"i (the antecedent relations over pairs of opinion targets can be constructed using the coreference resolver), and fcoref is a penalty function which takes value 1.0 when the expected sentiment coherency is violated, that is, yi 6=polar yj .",3.2 Context-aware Posterior Constraints,[0],[0]
"Similar to the inter-sentential dis-
course connectives, modeling opinion coreference via constraint violations allows the model to handle neutral sentiment.",3.2 Context-aware Posterior Constraints,[0],[0]
"The expected value of the constraint functions is set to 0.
",3.2 Context-aware Posterior Constraints,[0],[0]
"Listing Patterns Another type of coherence relations we observe in online reviews is listing, where a reviewer expresses his/her opinions by listing a series of statements followed by a sequence of numbers.",3.2 Context-aware Posterior Constraints,[0],[0]
"For example, “1.",3.2 Context-aware Posterior Constraints,[0],[0]
It’s smaller than the ipod mini .... 2.,3.2 Context-aware Posterior Constraints,[0],[0]
It has a removable battery ....”.,3.2 Context-aware Posterior Constraints,[0],[0]
We expect sentences connected by a listing to have consistent sentiment.,3.2 Context-aware Posterior Constraints,[0],[0]
"We implement this constraint in the same form as the coreference constraint (the antecedent assignments are constructed from the numberings).
",3.2 Context-aware Posterior Constraints,[0],[0]
"Global Sentiment Previous studies have demonstrated the value of document-level sentiment in guiding the semi-supervised learning of sentence-level sentiment (Täckström and McDonald, 2011b; Qu et al., 2012).",3.2 Context-aware Posterior Constraints,[0],[0]
"In this work, we also take into account this information and encode it as posterior constraints.",3.2 Context-aware Posterior Constraints,[0],[0]
"Note that these constraints are not necessary for our model and can be applied when the document-level sentiment labels are naturally available.
",3.2 Context-aware Posterior Constraints,[0],[0]
"Based on an analysis of the Amazon review data, we observe that sentence-level sentiment usually doesn’t conflict with the document-level sentiment in terms of polarity.",3.2 Context-aware Posterior Constraints,[0],[0]
"For example, the proportion of negative sentences in the positive documents is very small compared to the proportion of positive sentences.",3.2 Context-aware Posterior Constraints,[0],[0]
"To encode this intuition, we define the following constraint function:
φg(x, y) =",3.2 Context-aware Posterior Constraints,[0],[0]
"n∑ i δ(yi 6=polar g)/n
where g ∈ {positive, negative} denotes the sentiment value of a polar document, n is the total number of sentences in x, and δ is an indicator function.",3.2 Context-aware Posterior Constraints,[0],[0]
We hope the expectation of the constraint function takes a small value.,3.2 Context-aware Posterior Constraints,[0],[0]
"In our experiments, we set the expected value to be the empirical estimate of the probability of “conflicting” sentiment in polar documents using the training data.",3.2 Context-aware Posterior Constraints,[0],[0]
"During training, we need to compute the constraint expectations and the feature expectations under the auxiliary distribution q at each gradient step.
",3.3 Training and Inference,[0],[0]
"We can derive q by solving the dual problem in 3:
q(y|x) = exp(θ · f(x,y) + λ · φ(x,y))",3.3 Training and Inference,[0],[0]
"Zλ,θ(X) (4)
where Zλ,θ(X) is a normalization constant.",3.3 Training and Inference,[0],[0]
"Most of our constraints can be factorized in the same way as factorizing the model features in the firstorder CRF model, and we can compute the expectations under q very efficiently using the forwardbackward algorithm.",3.3 Training and Inference,[0],[0]
"However, some of our discourse constraints (opinion coreference and listing) can break the tractable structure of the model.",3.3 Training and Inference,[0],[0]
"For constraints with higher-order structures, we use Gibbs Sampling (Geman and Geman, 1984) to approximate the expectations.",3.3 Training and Inference,[0],[0]
"Given a sequence x, we sample a label yi at each position i by computing the unnormalized conditional probabilities p(yi = l|y−i) ∝",3.3 Training and Inference,[0],[0]
"exp(θ · f(x,yi = l,y−i)",3.3 Training and Inference,[0],[0]
"+ λ · φ(x,yi = l,y−i)) and renormalizing them.",3.3 Training and Inference,[0],[0]
"Since the possible label assignments only differ at position i, we can make the computation efficient by maintaining the structure of the coreference clusters and precomputing the constraint function for different types of violations.
",3.3 Training and Inference,[0],[0]
"During inference, we find the best label assignment by computing arg maxy q(y|x).",3.3 Training and Inference,[0],[0]
"For documents where the higher-order constraints apply, we use the same Gibbs sampler as described above to infer the most likely label assignment, otherwise, we use the Viterbi algorithm.",3.3 Training and Inference,[0],[0]
"We experimented with two product review datasets for sentence-level sentiment classification: the Customer Review (CR) data (Hu and Liu, 2004)6 which contains 638 reviews of 14 products such as cameras and cell phones, and the Multi-domain Amazon (MD) data from the test set of Täckström and McDonald (2011a) which contains 294 reivews from 5 different domains.",4 Experiments,[0],[0]
"As in Qu et al. (2012), we chose the books, electronics and music domains for evaluation.",4 Experiments,[0],[0]
"Each domain also comes with 33,000 extra reviews with only document-level sentiment labels.
",4 Experiments,[0],[0]
We evaluated our method in two settings: supervised and semi-supervised.,4 Experiments,[0],[0]
"In the supervised setting, we treated the test data as unlabeled data and performed transductive learning.",4 Experiments,[0],[0]
"In the semisupervised setting, our unlabeled data consists of
6Available at http://www.cs.uic.edu/˜liub/ FBS/sentiment-analysis.html.
both the available unlabeled data and the test data.",4 Experiments,[0],[0]
"For each domain in the MD dataset, we made use of no more than 100 unlabeled documents in which our posterior constraints apply.",4 Experiments,[0],[0]
We adopted the evaluation schemes used in previous work: 10- fold cross validation for the CR dataset and 3-fold cross validation for the MD dataset.,4 Experiments,[0],[0]
"We also report both two-way classification (positive vs. negative) and three-way classification results (positive, negative or neutral).",4 Experiments,[0],[0]
We use accuracy as the performance measure.,4 Experiments,[0],[0]
"In our tables, boldface numbers are statistically significant by paired t-test for p < 0.05 against the best baseline developed in this paper 7.
",4 Experiments,[0],[0]
We trained our model using a CRF incorporated with the proposed posterior constraints.,4 Experiments,[0],[0]
"For the CRF features, we include the tokens, the partof-speech tags, the prior polarities of lexical patterns indicated by the opinion lexicon and the negator lexicon, the number of positive and negative tokens and the output of the vote-flip algorithm (Choi and Cardie, 2009).",4 Experiments,[0],[0]
"In addition, we include the discourse connectives as local or transition features and the document-level sentiment labels as features (only available in the MD dataset).
",4 Experiments,[0],[0]
We set the CRF regularization parameter σ = 1 and set the posterior regularization parameter β and γ (a trade-off parameter we introduce to balance the supervised objective and the posterior regularizer in 2) by using grid search 8.,4 Experiments,[0],[0]
"For approximation inference with higher-order constraints, we perform 2000 Gibbs sampling iterations where the first 1000 iterations are burn-in iterations.",4 Experiments,[0],[0]
"To make the results more stable, we construct three Markov chains that run in parallel, and select the sample with the largest objective value.
",4 Experiments,[0],[0]
All posterior constraints were developed using the training data on each training fold.,4 Experiments,[0],[0]
"For the MD dataset, we also used the dvd domain as additional labeled data for developing the constraints.
",4 Experiments,[0],[0]
Baselines.,4 Experiments,[0],[0]
We compared our method to a number of baselines: (1) CRF: CRF with the same set of model features as in our method.,4 Experiments,[0],[0]
(2) CRFINF: CRF augmented with inference constraints.,4 Experiments,[0],[0]
"We can incorporate the proposed constraints (constraints derived from lexical patterns and discourse connectives) as hard constraints into CRF during
7Significance test was not conducted over the previous methods as we do not have their results for each fold.
8We conducted 10-fold cross-validation on each training fold with the parameter space: β :",4 Experiments,[0],[0]
"[0.01, 0.05, 0.1, 0.5, 1.0] and γ : [0.1, 0.5, 1.0, 5.0, 10.0].
inference by manually setting λ in equation 4 to a large value,9.",4 Experiments,[0],[0]
"When λ is large enough, it is equivalent to adding hard constraints to the viterbi inference.",4 Experiments,[0],[0]
"To better understand the different effects of lexical and discourse constraints, we report results for applying only the lexical constraints (CRFINFlex) as well as results for applying only the discourse constraints (CRF-INFdisc).",4 Experiments,[0],[0]
(3) PRlex: a variant of our PR model which only applies the lexical constraints.,4 Experiments,[0],[0]
"For the three-way classification task on the MD dataset, we also implemented the following baselines: (4) VOTEFLIP: a rulebased algorithm that leverages the positive, negative and neutral cues along with the effect of negation to determine the sentence sentiment (Choi and Cardie, 2009).",4 Experiments,[0],[0]
(5) DOCORACLE: assigns each sentence the label of its corresponding document.,4 Experiments,[0],[0]
We first report results on a binary (positive or negative) sentence-level sentiment classification task.,4.1 Results,[0],[0]
"For this task, we used the supervised setting and performed transductive learning for our model.",4.1 Results,[0],[0]
Table 2 shows the accuracy results.,4.1 Results,[0],[0]
"We can see
9We set λ to 1000 for the lexical constraints and -1000 to the discourse connective constraints in the experiments
that PR significantly outperforms all other baselines in both the CR dataset and the MD dataset (average accuracy across domains is reported).",4.1 Results,[0],[0]
The poor performance of CRF-INFlex indicates that directly applying lexical constraints as hard constraints during inference could only hurt the performance.,4.1 Results,[0],[0]
CRF-INFdisc slightly outperforms CRF but the improvement is not significant.,4.1 Results,[0],[0]
"In contrast, both PRlex and PR significantly outperform CRF, which implies that incorporating lexical and discourse constraints as posterior constraints is much more effective.",4.1 Results,[0],[0]
"The superior performance of PR over PRlex further suggests that the proper use of discourse information can significantly improve accuracy for sentence-level sentiment classification.
",4.1 Results,[0],[0]
We also analyzed the model’s performance on a three-way sentiment classification task.,4.1 Results,[0],[0]
"By introducing the “neutral” category, the sentiment classification problem becomes harder.",4.1 Results,[0],[0]
Table 4 shows the results in terms of accuracy for each domain in the MD dataset.,4.1 Results,[0],[0]
We can see that both PR and PRlex significantly outperform all other baselines in all domains.,4.1 Results,[0],[0]
The rule-based baseline VOTEFLIP gave the weakest performance because it has no prediction power on sentences with no opinion words.,4.1 Results,[0],[0]
DOCORACLE performs much better than VOTEFLIP and performs especially well on the Music domain.,4.1 Results,[0],[0]
This indicates that the documentlevel sentiment is a very strong indicator of the sentence-level sentiment label.,4.1 Results,[0],[0]
"For the CRF baseline and its invariants, we observe a similar performance trend as in the two-way classification task: there is nearly no performance improvement from applying the lexical and discourseconnective-based constraints during CRF inference.",4.1 Results,[0],[0]
"In contrast, both PRlex and PR provide substantial improvements over CRF.",4.1 Results,[0],[0]
"This con-
firms that encoding lexical and discourse knowledge as posterior constraints allows the featurebased model to gain additional learning power for sentence-level sentiment prediction.",4.1 Results,[0],[0]
"In particular, incorporating discourse constraints leads to consistent improvements to our model.",4.1 Results,[0],[0]
This demonstrates that our modeling of discourse information is effective and that taking into account the discourse context is important for improving sentence-level sentiment analysis.,4.1 Results,[0],[0]
We also compare our results to the previously published results on the same dataset.,4.1 Results,[0],[0]
"HCRF (Täckström and McDonald, 2011a) and MEM (Qu et al., 2012) are two state-of-the-art semi-supervised methods for sentence-level sentiment classification.",4.1 Results,[0],[0]
"We can see that our best model PR gives the best results in most categories.
",4.1 Results,[0],[0]
"Table 4 shows the results in terms of F1 scores for each sentiment category (positive, negative and neutral).",4.1 Results,[0],[0]
We can see that the PR models are able to provide improvements over all the sentiment categories compared to all the baselines in general.,4.1 Results,[0],[0]
"We observe that the DOCORACLE baseline provides very strong F1 scores on the positive and negative categories especially in the Books and Music domains, but very poor F1 on the neutral category.",4.1 Results,[0],[0]
"This is because it over-predicts the polar sentences in the polar documents, and predicts no polar sentences in the neutral documents.",4.1 Results,[0],[0]
"In contrast, our PR models provide more balanced F1 scores among all the sentiment categories.",4.1 Results,[0],[0]
"Compared to the CRF baseline and its variants, we found that the PR models can greatly improve the precision of predicting positive and negative sentences, resulting in a significant improvement on the positive/negative F1 scores.",4.1 Results,[0],[0]
"However, the improvement on the neutral category is modest.",4.1 Results,[0],[0]
A plausible explanation is that most of our constraints focus on discriminating polar sentences.,4.1 Results,[0],[0]
"They can help reduce the errors of misclassifying polar sentences, but the model needs more constraints in order to distinguish neutral sentences from polar sentences.",4.1 Results,[0],[0]
We plan to address this issue in future work.,4.1 Results,[0],[0]
We analyze the errors to better understand the merits and limitations of the PR model.,4.2 Discussion,[0],[0]
We found that the PR model is able to correct many CRF errors caused by the lack of labeled data.,4.2 Discussion,[0],[0]
"The first row in Table 5 shows an example of such errors.
",4.2 Discussion,[0],[0]
The lexical features return and exchange may be good indicators of negative sentiment for the sentence.,4.2 Discussion,[0],[0]
"However, with limited labeled data, the CRF learner can only associate very weak sentiment signals to these features.",4.2 Discussion,[0],[0]
"In contrast, the PR model is able to associate stronger sentiment signals to these features by leveraging unlabeled data for indirect supervision.",4.2 Discussion,[0],[0]
A simple lexicon-based constraint during inference time may also correct this case.,4.2 Discussion,[0],[0]
"However, hard-constraint baselines can hardly improve the performance in general because the contributions of different constraints are not learned and their combination may not lead to better predictions.",4.2 Discussion,[0],[0]
"This is also demonstrated by the limited performance of CRF-INF in our experiments.
",4.2 Discussion,[0],[0]
We also found that the discourse constraints play an important role in improving the sentiment prediction.,4.2 Discussion,[0],[0]
The lexical constraints alone are often not sufficient since their coverage is limited by the sentiment lexicon and they can only constrain sentiment locally.,4.2 Discussion,[0],[0]
"On the contrary, discourse constraints are not dependent on sentiment lexicons, and more importantly, they can provide sentiment preferences on multiple sentences at the same time.",4.2 Discussion,[0],[0]
"When combining discourse constraints with features from different sentences, the PR model becomes more powerful in disambiguating sentiment.",4.2 Discussion,[0],[0]
"The second example in Table 5 shows that the PR model learned with discourse constraints correctly predicts the sentiment of two sentences where no lexical constraints apply.
",4.2 Discussion,[0],[0]
"However, discourse constraints are not always helpful.",4.2 Discussion,[0],[0]
One reason is that they do not constrain the neutral sentiment.,4.2 Discussion,[0],[0]
"As a result they could not help disambiguate neutral sentiment from polar sentiment, such as the third example in Table 5.",4.2 Discussion,[0],[0]
This is also a problem for most of our lexical constraints.,4.2 Discussion,[0],[0]
"In general, it is hard to learn reliable indicators for the neutral sentiment.",4.2 Discussion,[0],[0]
"In the MD dataset, a neutral label may be given because the sentence
contains mixed sentiment or no sentiment or it is off-topic.",4.2 Discussion,[0],[0]
We plan to explore more refined constraints that can deal with the neutral sentiment in future work.,4.2 Discussion,[0],[0]
Another limitation of the discourse constraints is that they could be affected by the errors of the discourse parser and the coreference resolver.,4.2 Discussion,[0],[0]
A potential way to address this issue is to learn discourse constraints jointly with sentiment.,4.2 Discussion,[0],[0]
We plan to study this in future research.,4.2 Discussion,[0],[0]
"In this paper, we propose a context-aware approach for learning sentence-level sentiment.",5 Conclusion,[0],[0]
Our approach incorporates intuitive lexical and discourse knowledge as expressive constraints while training a conditional random field model via posterior regularization.,5 Conclusion,[0],[0]
"We explore a rich set of context-aware constraints at both intra- and intersentential levels, and demonstrate their effectiveness in the analysis of sentence-level sentiment.",5 Conclusion,[0],[0]
"While we focus on the sentence-level task, our approach can be easily extended to handle sentiment analysis at finer levels of granularity.",5 Conclusion,[0],[0]
Our experiments show that our model achieves better accuracy than existing supervised and semi-supervised models for the sentence-level sentiment classification task.,5 Conclusion,[0],[0]
This work was supported in part by DARPA-BAA12-47 DEFT grant #12475008 and NSF grant BCS-0904822.,Acknowledgments,[0],[0]
We thank Igor Labutov for helpful discussion and suggestions; Oscar Täckström and Lizhen Qu for providing their Amazon review datasets; and the anonymous reviewers for helpful comments and suggestions.,Acknowledgments,[0],[0]
This paper proposes a novel context-aware method for analyzing sentiment at the level of individual sentences.,abstractText,[0],[0]
Most existing machine learning approaches suffer from limitations in the modeling of complex linguistic structures across sentences and often fail to capture nonlocal contextual cues that are important for sentiment interpretation.,abstractText,[0],[0]
"In contrast, our approach allows structured modeling of sentiment while taking into account both local and global contextual information.",abstractText,[0],[0]
"Specifically, we encode intuitive lexical and discourse knowledge as expressive constraints and integrate them into the learning of conditional random field models via posterior regularization.",abstractText,[0],[0]
The context-aware constraints provide additional power to the CRF model and can guide semi-supervised learning when labeled data is limited.,abstractText,[0],[0]
Experiments on standard product review datasets show that our method outperforms the state-of-theart methods in both the supervised and semi-supervised settings.,abstractText,[0],[0]
Context-aware Learning for Sentence-level Sentiment Analysis with Posterior Regularization,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 1264–1274 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
1264",text,[0],[0]
"It has long been argued that handling discourse phenomena is important in translation (Mitkov, 1999; Hardmeier, 2012).",1 Introduction,[0],[0]
"Using extended context, beyond the single source sentence, should in principle be beneficial in ambiguous cases and also ensure that generated translations are coherent.",1 Introduction,[0],[0]
"Nevertheless, machine translation systems typically ignore discourse phenomena and translate sentences in isolation.
",1 Introduction,[0],[0]
"Earlier research on this topic focused on handling specific phenomena, such as translating pronouns (Le Nagard and Koehn, 2010; Hardmeier and Federico, 2010; Hardmeier et al., 2015), discourse connectives (Meyer et al., 2012), verb tense (Gong et al., 2012), increasing lexical consistency (Carpuat, 2009; Tiedemann, 2010; Gong et al., 2011), or topic adaptation (Su et al., 2012; Hasler et al., 2014), with special-purpose features engineered to model these phenomena.",1 Introduction,[0],[0]
"However, with traditional statistical machine translation being largely supplanted with neural machine translation (NMT) models trained in an end-toend fashion, an alternative is to directly provide additional context to an NMT system at training time and hope that it will succeed in inducing relevant predictive features (Jean et al., 2017; Wang et al., 2017; Tiedemann and Scherrer, 2017; Bawden et al., 2018).
",1 Introduction,[0],[0]
"While the latter approach, using context-aware NMT models, has demonstrated to yield performance improvements, it is still not clear what kinds of discourse phenomena are successfully handled by the NMT systems and, importantly, how they are modeled.",1 Introduction,[0],[0]
"Understanding this would inform development of future discourse-aware NMT models, as it will suggest what kind of inductive biases need to be encoded in the architecture or which linguistic features need to be exploited.
",1 Introduction,[0],[0]
In our work we aim to enhance our understanding of the modelling of selected discourse phenomena in NMT.,1 Introduction,[0],[0]
"To this end, we construct a simple discourse-aware model, demonstrate that it achieves improvements over the discourse-agnostic baseline on an English-Russian subtitles dataset (Lison et al., 2018) and study which context information is being captured in the model.",1 Introduction,[0],[0]
"Specifically, we start with the Trans-
former (Vaswani et al., 2017), a state-of-the-art model for context-agnostic NMT, and modify it in such way that it can handle additional context.",1 Introduction,[0],[0]
"In our model, a source sentence and a context sentence are first encoded independently, and then a single attention layer, in a combination with a gating function, is used to produce a context-aware representation of the source sentence.",1 Introduction,[0],[0]
The information from context can only flow through this attention layer.,1 Introduction,[0],[0]
"When compared to simply concatenating input sentences, as proposed by Tiedemann and Scherrer (2017), our architecture appears both more accurate (+0.6 BLEU) and also guarantees that the contextual information cannot bypass the attention layer and hence remain undetected in our analysis.
",1 Introduction,[0],[0]
We analyze what types of contextual information are exploited by the translation model.,1 Introduction,[0],[0]
"While studying the attention weights, we observe that much of the information captured by the model has to do with pronoun translation.",1 Introduction,[0],[0]
"It is not entirely surprising, as we consider translation from a language without grammatical gender (English) to a language with grammatical gender (Russian).",1 Introduction,[0],[0]
"For Russian, translated pronouns need to agree in gender with their antecedents.",1 Introduction,[0],[0]
"Moreover, since in Russian verbs agree with subjects in gender and adjectives also agree in gender with pronouns in certain frequent constructions, mistakes in translating pronouns have a major effect on the words in the produced sentences.",1 Introduction,[0],[0]
"Consequently, the standard cross-entropy training objective sufficiently rewards the model for improving pronoun translation and extracting relevant information from the context.
",1 Introduction,[0],[0]
We use automatic co-reference systems and human annotation to isolate anaphoric cases.,1 Introduction,[0],[0]
We observe even more substantial improvements in performance on these subsets.,1 Introduction,[0],[0]
"By comparing attention distributions induced by our model against co-reference links, we conclude that the model implicitly captures coreference phenomena, even without having any kind of specialized features which could help it in this subtask.",1 Introduction,[0],[0]
These observations also suggest potential directions for future work.,1 Introduction,[0],[0]
"For example, effective co-reference systems go beyond relying simply on embeddings of contexts.",1 Introduction,[0],[0]
"One option would be to integrate ‘global’ features summarizing properties of groups of mentions predicted as linked in a document (Wiseman et al., 2016), or to use latent relations to trace en-
tities across documents (Ji et al., 2017).",1 Introduction,[0],[0]
"Our key contributions can be summarized as follows:
• we introduce a context-aware neural model, which is effective and has a sufficiently simple and interpretable interface between the context and the rest of the translation model;
• we analyze the flow of information from the context and identify pronoun translation as the key phenomenon captured by the model;
• by comparing to automatically predicted or human-annotated coreference relations, we observe that the model implicitly captures anaphora.",1 Introduction,[0],[0]
Given a source sentence x =,2 Neural Machine Translation,[0],[0]
"(x1, x2, . . .",2 Neural Machine Translation,[0],[0]
", xS) and a target sentence y = (y1, y2, . . .",2 Neural Machine Translation,[0],[0]
", yT ), NMT models predict words in the target sentence, word by word.
",2 Neural Machine Translation,[0],[0]
Current NMT models mainly have an encoderdecoder structure.,2 Neural Machine Translation,[0],[0]
"The encoder maps an input sequence of symbol representations x to a sequence of distributed representations z = (z1, z2, . . .",2 Neural Machine Translation,[0],[0]
", zS).",2 Neural Machine Translation,[0],[0]
"Given z, a neural decoder generates the corresponding target sequence of symbols y one element at a time.
",2 Neural Machine Translation,[0],[0]
Attention-based NMT The encoder-decoder framework with attention has been proposed by Bahdanau et al. (2015) and has become the defacto standard in NMT.,2 Neural Machine Translation,[0],[0]
The model consists of encoder and decoder recurrent networks and an attention mechanism.,2 Neural Machine Translation,[0],[0]
"The attention mechanism selectively focuses on parts of the source sentence during translation, and the attention weights specify the proportions with which information from different positions is combined.
",2 Neural Machine Translation,[0],[0]
Transformer Vaswani et al. (2017) proposed an architecture that avoids recurrence completely.,2 Neural Machine Translation,[0],[0]
The Transformer follows an encoder-decoder architecture using stacked self-attention and fully connected layers for both the encoder and decoder.,2 Neural Machine Translation,[0],[0]
"An important advantage of the Transformer is that it is more parallelizable and faster to train than recurrent encoder-decoder models.
",2 Neural Machine Translation,[0],[0]
"From the source tokens, learned embeddings are generated and then modified using positional encodings.",2 Neural Machine Translation,[0],[0]
"The encoded word embeddings are then used as input to the encoder which consists of N
layers each containing two sub-layers: (a) a multihead attention mechanism, and (b) a feed-forward network.
",2 Neural Machine Translation,[0],[0]
"The self-attention mechanism first computes attention weights: i.e., for each word, it computes a distribution over all words (including itself).",2 Neural Machine Translation,[0],[0]
This distribution is then used to compute a new representation of that word: this new representation is set to an expectation (under the attention distribution specific to the word) of word representations from the layer below.,2 Neural Machine Translation,[0],[0]
"In multi-head attention, this process is repeated h times with different representations and the result is concatenated.
",2 Neural Machine Translation,[0],[0]
The second component of each layer of the Transformer network is a feed-forward network.,2 Neural Machine Translation,[0],[0]
"The authors propose using a two-layered network with the ReLU activations.
",2 Neural Machine Translation,[0],[0]
"Analogously, each layer of the decoder contains the two sub-layers mentioned above as well as an additional multi-head attention sub-layer that receives input from the corresponding encoding layer.
",2 Neural Machine Translation,[0],[0]
"In the decoder, the attention is masked to prevent future positions from being attended to, or in other words, to prevent illegal leftward information flow.",2 Neural Machine Translation,[0],[0]
"See Vaswani et al. (2017) for additional details.
",2 Neural Machine Translation,[0],[0]
"The proposed architecture reportedly improves over the previous best results on the WMT 2014 English-to-German and English-to-French translation tasks, and we verified its strong performance on our data set in preliminary experiments.",2 Neural Machine Translation,[0],[0]
"Thus, we consider it a strong state-of-the-art baseline for our experiments.",2 Neural Machine Translation,[0],[0]
"Moreover, as the Transformer is attractive in practical NMT applications because of its parallelizability and training efficiency, integrating extra-sentential information in Transformer is important from the engineering perspective.",2 Neural Machine Translation,[0],[0]
"As we will see in Section 4, previous techniques developed for recurrent encoderdecoders do not appear effective for the Transformer.",2 Neural Machine Translation,[0],[0]
"Our model is based on Transformer architecture (Vaswani et al., 2017).",3 Context-aware model architecture,[0],[0]
"We leave Transformer’s decoder intact while incorporating context information on the encoder side (Figure 1).
",3 Context-aware model architecture,[0],[0]
Source encoder: The encoder is composed of a stack of N layers.,3 Context-aware model architecture,[0],[0]
"The first N − 1 layers are identical and represent the original layers of Trans-
former’s encoder.",3 Context-aware model architecture,[0],[0]
The last layer incorporates contextual information as shown in Figure 1.,3 Context-aware model architecture,[0],[0]
In addition to multi-head self-attention it has a block which performs multi-head attention over the output of the context encoder stack.,3 Context-aware model architecture,[0],[0]
The outputs of the two attention mechanisms are combined via a gated sum.,3 Context-aware model architecture,[0],[0]
"More precisely, let c(s−attn)i be the output of the multi-head self-attention, c(c−attn)i the output of the multi-head attention to context, ci their gated sum, and σ the logistic sigmoid function, then
gi = σ",3 Context-aware model architecture,[0],[0]
( Wg [ c (s−attn),3 Context-aware model architecture,[0],[0]
"i , c (c−attn) i ] + bg ) (1)
ci = gi c(s−attn)i + (1− gi) c (c−attn)",3 Context-aware model architecture,[0],[0]
"i (2)
Context encoder: The context encoder is composed of a stack of N identical layers and replicates the original Transformer encoder.",3 Context-aware model architecture,[0],[0]
"In contrast to related work (Jean et al., 2017; Wang et al., 2017), we found in preliminary experiments that using separate encoders does not yield an accurate model.",3 Context-aware model architecture,[0],[0]
"Instead we share the parameters of the first N − 1 layers with the source encoder.
",3 Context-aware model architecture,[0],[0]
"Since major proportion of the context encoder’s parameters are shared with the source encoder, we add a special token (let us denote it <bos>) to the beginning of context sentences, but not source
sentences, to let the shared layers know whether it is encoding a source or a context sentence.",3 Context-aware model architecture,[0],[0]
"We use the publicly available OpenSubtitles2018 corpus (Lison et al., 2018) for English and Russian.1 As described in the appendix, we apply data cleaning and randomly choose 2 million training instances from the resulting data.",4.1 Data and setting,[0],[0]
"For development and testing, we randomly select two subsets of 10000 instances from movies not encountered in training.2 Sentences were encoded using byte-pair encoding (Sennrich et al., 2016), with source and target vocabularies of about 32000 tokens.",4.1 Data and setting,[0],[0]
"We generally used the same parameters and optimizer as in the original Transformer (Vaswani et al., 2017).",4.1 Data and setting,[0],[0]
"The hyperparameters, preprocessing and training details are provided in the supplementary material.",4.1 Data and setting,[0],[0]
"We start by experiments motivating the setting and verifying that the improvements are indeed genuine, i.e. they come from inducing predictive features of the context.",5 Results and analysis,[0],[0]
"In subsequent section 5.2, we analyze the features induced by the context encoder and perform error analysis.",5 Results and analysis,[0],[0]
"We use the traditional automatic metric BLEU on a general test set to get an estimate of the overall performance of the discourse-aware model, before turning to more targeted evaluation in the next section.",5.1 Overall performance,[0],[0]
We provide results in Table 1.3 The ‘baseline’ is the discourse-agnostic version of the Transformer.,5.1 Overall performance,[0],[0]
"As another baseline we use the standard Transformer applied to the concatenation of the previous and source sentences, as proposed by Tiedemann and Scherrer (2017).",5.1 Overall performance,[0],[0]
Tiedemann and Scherrer (2017) only used a special symbol to mark where the context sentence ends and the source sentence begins.,5.1 Overall performance,[0],[0]
"This technique performed badly with the non-recurrent Transformer architecture in preliminary experiments, resulting in
1http://opus.nlpl.eu/ OpenSubtitles2018.php
2The resulting data sets are freely available at http:// data.statmt.org/acl18_contextnmt_data/
3We use bootstrap resampling (Riezler and Maxwell, 2005) for significance testing
a substantial degradation of performance (over 1 BLEU).",5.1 Overall performance,[0],[0]
"Instead, we use a binary flag at every word position in our concatenation baseline telling the encoder whether the word belongs to the context sentence or to the source sentence.
",5.1 Overall performance,[0],[0]
"We consider two versions of our discourseaware model: one using the previous sentence as the context, another one relying on the next sentence.",5.1 Overall performance,[0],[0]
"We hypothesize that both the previous and the next sentence provide a similar amount of additional clues about the topic of the text, whereas for discourse phenomena such as anaphora, discourse relations and elliptical structures, the previous sentence is more important.
",5.1 Overall performance,[0],[0]
"First, we observe that our best model is the one using a context encoder for the previous sentence: it achieves 0.7 BLEU improvement over the discourse-agnostic model.",5.1 Overall performance,[0],[0]
"We also notice that, unlike the previous sentence, the next sentence does not appear beneficial.",5.1 Overall performance,[0],[0]
"This is a first indicator that discourse phenomena are the main reason for the observed improvement, rather than topic effects.",5.1 Overall performance,[0],[0]
"Consequently, we focus solely on using the previous sentence in all subsequent experiments.
",5.1 Overall performance,[0],[0]
"Second, we observe that the concatenation baseline appears less accurate than the introduced context-aware model.",5.1 Overall performance,[0],[0]
"This result suggests that our model is not only more amendable to analysis but also potentially more effective than using concatenation.
",5.1 Overall performance,[0],[0]
"In order to verify that our improvements are genuine, we also evaluate our model (trained with the previous sentence as context) on the same test set with shuffled context sentences.",5.1 Overall performance,[0],[0]
It can be seen that the performance drops significantly when a real context sentence is replaced with a random one.,5.1 Overall performance,[0],[0]
"This confirms that the model does rely on context information to achieve the improvement in translation quality, and is not merely better regularized.",5.1 Overall performance,[0],[0]
"However, the model is robust towards being shown a random context and obtains a performance similar to the context-agnostic baseline.",5.1 Overall performance,[0],[0]
In this section we investigate what types of contextual information are exploited by the model.,5.2 Analysis,[0],[0]
We study the distribution of attention to context and perform analysis on specific subsets of the test data.,5.2 Analysis,[0],[0]
"Specifically the research questions we seek to answer are as follows:
• For the translation of which words does the model rely on contextual history most?
",5.2 Analysis,[0],[0]
"• Are there any non-lexical patterns affecting attention to context, such as sentence length and word position?
",5.2 Analysis,[0],[0]
"• Can the context-aware NMT system implicitly learn coreference phenomena without any feature engineering?
",5.2 Analysis,[0],[0]
"Since all the attentions in our model are multihead, by attention weights we refer to an average over heads of per-head attention weights.
",5.2 Analysis,[0],[0]
"First, we would like to identify a useful attention mass coming to context.",5.2 Analysis,[0],[0]
"We analyze the attention maps between source and context, and find that the model mostly attends to <bos> and <eos> context tokens, and much less often attends to words.",5.2 Analysis,[0],[0]
"Our hypothesis is that the model has found a way to take no information from context by looking at uninformative tokens, and it attends to words only when it wants to pass some contextual information to the source sentence encoder.",5.2 Analysis,[0],[0]
"Thus we define useful contextual attention mass as sum of attention weights to context words, excluding <bos> and <eos> tokens and punctuation.",5.2 Analysis,[0],[0]
We analyze the distribution of attention to context for individual source words to see for which words the model depends most on contextual history.,5.2.1 Top words depending on context,[0],[0]
We compute the overall average attention to context words for each source word in our test set.,5.2.1 Top words depending on context,[0],[0]
We do the same for source words at positions higher than first.,5.2.1 Top words depending on context,[0],[0]
We filter out words that occurred less than 10 times in a test set.,5.2.1 Top words depending on context,[0],[0]
"The top 10 words with the highest average attention to context words are provided in Table 2.
",5.2.1 Top words depending on context,[0],[0]
"An interesting finding is that contextual attention is high for the translation of “it”, “yours”, “ones”, “you” and “I”, which are indeed very ambiguous out-of-context when translating into Russian.",5.2.1 Top words depending on context,[0],[0]
"For example, “it” will be translated as third person singular masculine, feminine or neuter, or third person plural depending on its antecedent.
",5.2.1 Top words depending on context,[0],[0]
"“You” can be second person singular impolite or polite, or plural.",5.2.1 Top words depending on context,[0],[0]
"Also, verbs must agree in gender and number with the translation of “you”.
",5.2.1 Top words depending on context,[0],[0]
"It might be not obvious why “I” has high contextual attention, as it is not ambiguous itself.",5.2.1 Top words depending on context,[0],[0]
"However, in past tense, verbs must agree with “I” in gender, so to translate past tense sentences properly, the source encoder must predict speaker gender, and the context may provide useful indicators.
",5.2.1 Top words depending on context,[0],[0]
"Most surprising is the appearance of “yes”, “yeah”, and “well” in the list of context-dependent words, similar to the finding by Tiedemann and Scherrer (2017).",5.2.1 Top words depending on context,[0],[0]
"We note that these words mostly appear in sentence-initial position, and in relatively short sentences.",5.2.1 Top words depending on context,[0],[0]
"If only words after the first are considered, they disappear from the top-10 list.",5.2.1 Top words depending on context,[0],[0]
"We hypothesize that the amount of attention to context not only depends on the words themselves, but also on factors such as sentence length and position, and we test this hypothesis in the next section.",5.2.1 Top words depending on context,[0],[0]
We compute useful attention mass coming to context by averaging over source words.,5.2.2 Dependence on sentence length and position,[0],[0]
Figure 2 illustrates the dependence of this average attention mass on sentence length.,5.2.2 Dependence on sentence length and position,[0],[0]
"We observe a disproportionally high attention on context for short sentences, and a positive correlation between the average contextual attention and context length.
",5.2.2 Dependence on sentence length and position,[0],[0]
"It is also interesting to see the importance given to the context at different positions in the source
sentence.",5.2.2 Dependence on sentence length and position,[0],[0]
We compute an average attention mass to context for a set of 1500 sentences of the same length.,5.2.2 Dependence on sentence length and position,[0],[0]
"As can be seen in Figure 3, words at the beginning of a source sentence tend to attend to context more than words at the end of a sentence.",5.2.2 Dependence on sentence length and position,[0],[0]
"This correlates with standard view that English sentences present hearer-old material before hearer-new.
",5.2.2 Dependence on sentence length and position,[0],[0]
"There is a clear (negative) correlation between sentence length and the amount of attention placed on contextual history, and between token position and the amount of attention to context, which suggests that context is especially helpful at the beginning of a sentence, and for shorter sentences.",5.2.2 Dependence on sentence length and position,[0],[0]
"However, Figure 4 shows that there is no straightforward dependence of BLEU improvement on source length.",5.2.2 Dependence on sentence length and position,[0],[0]
"This means that while attention on context is disproportionally high for short sentences, context does not seem disproportionally more useful for these sentences.",5.2.2 Dependence on sentence length and position,[0],[0]
The analysis of the attention model indicates that the model attends heavily to the contextual history for the translation of some pronouns.,5.3 Analysis of pronoun translation,[0],[0]
"Here, we investigate whether this context-aware modelling results in empirical improvements in translation
quality, and whether the model learns structures related to anaphora resolution.",5.3 Analysis of pronoun translation,[0],[0]
"Ambiguous pronouns are relatively sparse in a general-purpose test set, and previous work has designed targeted evaluation of pronoun translation (Hardmeier et al., 2015; Miculicich Werlen and Popescu-Belis, 2017; Bawden et al., 2018).",5.3.1 Ambiguous pronouns and translation quality,[0],[0]
"However, we note that in Russian, grammatical gender is not only marked on pronouns, but also on adjectives and verbs.",5.3.1 Ambiguous pronouns and translation quality,[0],[0]
"Rather than using a pronoun-specific evaluation, we present results with BLEU on test sets where we hypothesize context to be relevant, specifically sentences containing co-referential pronouns.",5.3.1 Ambiguous pronouns and translation quality,[0],[0]
"We feed Stanford CoreNLP open-source coreference resolution system (Manning et al., 2014a) with pairs of sentences to find examples where there is a link between one of the pronouns under consideration and the context.",5.3.1 Ambiguous pronouns and translation quality,[0],[0]
"We focus on anaphoric instances of “it” (this excludes, among others, pleonastic uses of ”it”), and instances of the pronouns “I”, “you”, and “yours” that are coreferent with an expression in the previous sentence.",5.3.1 Ambiguous pronouns and translation quality,[0],[0]
"All these pronouns express ambiguity in the translation into Russian, and the model has learned to attend to context for their translation (Table 2).",5.3.1 Ambiguous pronouns and translation quality,[0],[0]
"To combat data sparsity, the test sets are extracted from large amounts of held-out data of OpenSubtitles2018.",5.3.1 Ambiguous pronouns and translation quality,[0],[0]
"Table 3 shows BLEU scores for the resulting subsets.
",5.3.1 Ambiguous pronouns and translation quality,[0],[0]
"First of all, we see that most of the antecedents in these test sets are also pronouns.",5.3.1 Ambiguous pronouns and translation quality,[0],[0]
Antecedent pronouns should not be particularly informative for translating the source pronoun.,5.3.1 Ambiguous pronouns and translation quality,[0],[0]
"Nevertheless, even with such contexts, improvements are generally larger than on the overall test set.
",5.3.1 Ambiguous pronouns and translation quality,[0],[0]
"When we focus on sentences where the antecedent for pronoun under consideration contains
a noun, we observe even larger improvements (Table 4).",5.3.1 Ambiguous pronouns and translation quality,[0],[0]
"Improvement is smaller for “I”, but we note that verbs with first person singular subjects mark gender only in the past tense, which limits the impact of correctly predicting gender.",5.3.1 Ambiguous pronouns and translation quality,[0],[0]
"In contrast, different types of “you” (polite/impolite, singular/plural) lead to different translations of the pronoun itself plus related verbs and adjectives, leading to a larger jump in performance.",5.3.1 Ambiguous pronouns and translation quality,[0],[0]
"Examples of nouns co-referent with “I” and “you” include names, titles (“Mr.”, “Mrs.”, “officer”), terms denoting family relationships (“Mom”, “Dad”), and terms of endearment (“honey”, “sweetie”).",5.3.1 Ambiguous pronouns and translation quality,[0],[0]
"Such nouns can serve to disambiguate number and gender of the speaker or addressee, and mark the level of familiarity between them.
",5.3.1 Ambiguous pronouns and translation quality,[0],[0]
"The most interesting case is translation of “it”, as “it” can have many different translations into Russian, depending on the grammatical gender of the antecedent.",5.3.1 Ambiguous pronouns and translation quality,[0],[0]
"In order to disentangle these cases, we train the Berkeley aligner on 10m sentences and use the trained model to divide the test set with “it” referring to a noun into test sets specific to each gender and number.",5.3.1 Ambiguous pronouns and translation quality,[0],[0]
"Results are in Table 5.
",5.3.1 Ambiguous pronouns and translation quality,[0],[0]
We see an improvement of 4-5 BLEU for sentences where “it” is translated into a feminine or plural pronoun by the reference.,5.3.1 Ambiguous pronouns and translation quality,[0],[0]
"For cases where “it” is translated into a masculine pronoun, the improvement is smaller because the masculine gender is more frequent, and the context-agnostic baseline tends to translate the pronoun “it” as masculine.",5.3.1 Ambiguous pronouns and translation quality,[0],[0]
The results in Tables 4 and 5 suggest that the context-aware model exploits information about the antecedent of an ambiguous pronoun.,5.3.2 Latent anaphora resolution,[0],[0]
"We hypothesize that we can interpret the model’s attention mechanism as a latent anaphora resolution, and perform experiments to test this hypothesis.
",5.3.2 Latent anaphora resolution,[0],[0]
"For test sets from Table 4, we find an antecedent noun phrase (usually a determiner or a possessive pronoun followed by a noun) using Stanford CoreNLP",5.3.2 Latent anaphora resolution,[0],[0]
"(Manning et al., 2014b).",5.3.2 Latent anaphora resolution,[0],[0]
We select only examples where a noun phrase contains a single noun to simplify our analysis.,5.3.2 Latent anaphora resolution,[0],[0]
Then we identify which token receives the highest attention weight (excluding <bos> and <eos> tokens and punctuation).,5.3.2 Latent anaphora resolution,[0],[0]
"If this token falls within the antecedent span, then we treat it as agreement (see Table 6).
",5.3.2 Latent anaphora resolution,[0],[0]
"One natural question might be: does the attention component in our model genuinely learn to perform anaphora resolution, or does it capture some simple heuristic (e.g., pointing to the last noun)?",5.3.2 Latent anaphora resolution,[0],[0]
"To answer this question, we consider several baselines: choosing a random, last or first
noun from the context sentence as an antecedent.",5.3.2 Latent anaphora resolution,[0],[0]
Note that an agreement of the last noun for “it” or the first noun for “you” and “I” is very high.,5.3.2 Latent anaphora resolution,[0],[0]
This is partially due to the fact that most context sentences have only one noun.,5.3.2 Latent anaphora resolution,[0],[0]
"For these examples a random and last predictions are always correct, meanwhile attention does not always pick a noun as the most relevant word in the context.",5.3.2 Latent anaphora resolution,[0],[0]
To get a more clear picture let us now concentrate only on examples where there is more than one noun in the context (Table 7).,5.3.2 Latent anaphora resolution,[0],[0]
We can now see that the attention weights are in much better agreement with the coreference system than any of the heuristics.,5.3.2 Latent anaphora resolution,[0],[0]
"This indicates that the model is indeed performing anaphora resolution.
",5.3.2 Latent anaphora resolution,[0],[0]
"While agreement with CoreNLP is encouraging, we are aware that coreference resolution by CoreNLP is imperfect and partial agreement with it may not necessarily indicate that the attention is particularly accurate.",5.3.2 Latent anaphora resolution,[0],[0]
"In order to control for this, we asked human annotators to manually evaluate 500 examples from the test sets where CoreNLP predicted that “it” refers to a noun in the context sentence.",5.3.2 Latent anaphora resolution,[0],[0]
"More precisely, we picked random 500 examples from the test set with “it” from Table 7.",5.3.2 Latent anaphora resolution,[0],[0]
We marked the pronoun in a source which CoreNLP found anaphoric.,5.3.2 Latent anaphora resolution,[0],[0]
Assessors were given the source and context sentences and were asked to mark an antecedent noun phrase for a marked pronoun in a source sentence or say that there is no antecedent at all.,5.3.2 Latent anaphora resolution,[0],[0]
We then picked those examples where assessors found a link from “it” to some noun in context (79% of all examples).,5.3.2 Latent anaphora resolution,[0],[0]
Then we evaluated agreement of CoreNLP and our model with the ground truth links.,5.3.2 Latent anaphora resolution,[0],[0]
We also report the performance of the best heuristic for “it” from our previous analysis (i.e. last noun in context).,5.3.2 Latent anaphora resolution,[0],[0]
"The results are provided in Table 8.
",5.3.2 Latent anaphora resolution,[0],[0]
The agreement between our model and the ground truth is 72%.,5.3.2 Latent anaphora resolution,[0],[0]
"Though 5% below the coreference system, this is a lot higher than the best
heuristic (+18%).",5.3.2 Latent anaphora resolution,[0],[0]
This confirms our conclusion that our model performs latent anaphora resolution.,5.3.2 Latent anaphora resolution,[0],[0]
"Interestingly, the patterns of mistakes are quite different for CoreNLP and our model (Table 9).",5.3.2 Latent anaphora resolution,[0],[0]
We also present one example (Figure 5) where the attention correctly predicts anaphora while CoreNLP fails.,5.3.2 Latent anaphora resolution,[0],[0]
"Nevertheless, there is room for improvement, and improving the attention component is likely to boost translation performance.",5.3.2 Latent anaphora resolution,[0],[0]
Our analysis focuses on how our context-aware neural model implicitly captures anaphora.,6 Related work,[0],[0]
"Early work on anaphora phenomena in statistical machine translation has relied on external systems for coreference resolution (Le Nagard and Koehn, 2010; Hardmeier and Federico, 2010).",6 Related work,[0],[0]
"Results
were mixed, and the low performance of coreference resolution systems was identified as a problem for this type of system.",6 Related work,[0],[0]
"Later work by Hardmeier et al. (2013) has shown that cross-lingual pronoun prediction systems can implicitly learn to resolve coreference, but this work still relied on external feature extraction to identify anaphora candidates.",6 Related work,[0],[0]
"Our experiments show that a contextaware neural machine translation system can implicitly learn coreference phenomena without any feature engineering.
Tiedemann and Scherrer (2017) and Bawden et al. (2018) analyze the attention weights of context-aware NMT models.",6 Related work,[0],[0]
"Tiedemann and Scherrer (2017) find some evidence for aboveaverage attention on contextual history for the translation of pronouns, and our analysis goes further in that we are the first to demonstrate that our context-aware model learns latent anaphora resolution through the attention mechanism.",6 Related work,[0],[0]
"This is contrary to Bawden et al. (2018), who do not observe increased attention between a pronoun and its antecedent in their recurrent model.",6 Related work,[0],[0]
"We deem our model more suitable for analysis, since it has no recurrent connections and fully relies on the attention mechanism within a single attention layer.",6 Related work,[0],[0]
We introduced a context-aware NMT system which is based on the Transformer architecture.,7 Conclusions,[0],[0]
"When evaluated on an En-Ru parallel corpus, it outperforms both the context-agnostic baselines and a simple context-aware baseline.",7 Conclusions,[0],[0]
We observe that improvements are especially prominent for sentences containing ambiguous pronouns.,7 Conclusions,[0],[0]
We also show that the model induces anaphora relations.,7 Conclusions,[0],[0]
"We believe that further improvements in handling anaphora, and by proxy translation, can be achieved by incorporating specialized features in the attention model.",7 Conclusions,[0],[0]
Our analysis has focused on the effect of context information on pronoun translation.,7 Conclusions,[0],[0]
"Future work could also investigate whether context-aware NMT systems learn other discourse phenomena, for example whether they improve the translation of elliptical constructions, and markers of discourse relations and information structure.",7 Conclusions,[0],[0]
"We would like to thank Bonnie Webber for helpful discussions and annonymous reviewers for their
comments.",Acknowledgments,[0],[0]
The authors also thank David Talbot and Yandex Machine Translation team for helpful discussions and inspiration.,Acknowledgments,[0],[0]
Ivan Titov acknowledges support of the European Research Council (ERC StG BroadSem 678254) and the Dutch National Science Foundation (NWO VIDI 639.022.518).,Acknowledgments,[0],[0]
Rico Sennrich has received funding from the Swiss National Science Foundation (105212 169888).,Acknowledgments,[0],[0]
"Standard machine translation systems process sentences in isolation and hence ignore extra-sentential information, even though extended context can both prevent mistakes in ambiguous cases and improve translation coherence.",abstractText,[0],[0]
We introduce a context-aware neural machine translation model designed in such way that the flow of information from the extended context to the translation model can be controlled and analyzed.,abstractText,[0],[0]
"We experiment with an English-Russian subtitles dataset, and observe that much of what is captured by our model deals with improving pronoun translation.",abstractText,[0],[0]
We measure correspondences between induced attention distributions and coreference relations and observe that the model implicitly captures anaphora.,abstractText,[0],[0]
It is consistent with gains for sentences where pronouns need to be gendered in translation.,abstractText,[0],[0]
"Beside improvements in anaphoric cases, the model also improves in overall BLEU, both over its context-agnostic version (+0.7) and over simple concatenation of the context and source sentences (+0.6).",abstractText,[0],[0]
Context-Aware Neural Machine Translation Learns Anaphora Resolution,title,[0],[0]
"Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1437–1447, Baltimore, Maryland, USA, June 23-25 2014. c©2014 Association for Computational Linguistics",text,[0],[0]
Time expressions present a number of challenges for language understanding systems.,1 Introduction,[0],[0]
"They have rich, compositional structure (e.g., “2nd Friday of July”), can be easily confused with non-temporal phrases (e.g., the word “May” can be a month name or a verb), and can vary in meaning in different linguistic contexts (e.g., the word “Friday” refers to different dates in the sentences “We met on Friday” and “We will meet on Friday”).",1 Introduction,[0],[0]
"Recovering the meaning of time expressions is therefore challenging, but provides opportunities to study context-dependent language use.",1 Introduction,[0],[0]
"In this paper, we present the first context-dependent semantic parsing approach for learning to identify and interpret time expressions, addressing all three challenges.
",1 Introduction,[0],[0]
"Existing state-of-the-art methods use handengineered rules for reasoning about time expressions (Strötgen and Gertz, 2013).",1 Introduction,[0],[0]
"This includes both detection, identifying a phrase as a time expression, and resolution, mapping such a phrase into a standardized time value.",1 Introduction,[0],[0]
"While rule-based approaches provide a natural way to express expert knowledge, it is relatively difficult to en-
∗Work conducted at the University of Washington.
code preferences between similar competing hypotheses and provide prediction confidence.",1 Introduction,[0],[0]
"Recently, methods for learning probabilistic semantic parsers have been shown to address such limitations (Angeli et al., 2012; Angeli and Uszkoreit, 2013).",1 Introduction,[0],[0]
"However, these approaches do not account for any surrounding linguistic context and were mainly evaluated with gold standard mentions.
",1 Introduction,[0],[0]
We propose to use a context-dependent semantic parser for both detection and resolution of time expressions.,1 Introduction,[0],[0]
"For both tasks, we make use of a hand-engineered Combinatory Categorial Grammar (CCG) to construct a set of meaning representations that identify the time being described.",1 Introduction,[0],[0]
"For example, this grammar maps the phrase “2nd Friday of July” to the meaning representation intersect(nth(2 , friday), july), which encodes the set of all such days.",1 Introduction,[0],[0]
"Detection is then performed with a binary classifier to prune the set of text spans that can be parsed with the grammar (e.g., to tell that “born in 2000” has a time expression but “a 2000 piece puzzle” does not).",1 Introduction,[0],[0]
"For resolution, we consider mentions sequentially and use a log-linear model to select the most likely meaning for each.",1 Introduction,[0],[0]
"This choice depends on contextual cues such as previous time expressions and the tense of the governing verb (e.g., as required to correctly resolve cases like “We should meet on the 2nd Friday of July”).
",1 Introduction,[0],[0]
Such an approach provides a good balance between hand engineering and learning.,1 Introduction,[0],[0]
"For the relatively closed-class time expressions, we demonstrate that it is possible to engineer a high quality CCG lexicon.",1 Introduction,[0],[0]
"We take a data-driven approach for grammar design, preferring a grammar with high coverage even if it results in parsing ambiguities.",1 Introduction,[0],[0]
"We then learn a model to accurately select between competing parses and incorporate signals from the surrounding context, both more difficult to model with deterministic rules.
",1 Introduction,[0],[0]
"For both problems, we learn from TimeML an-
1437
notations (Pustejovsky et al., 2005), which mark mentions and the specific times they reference.",1 Introduction,[0],[0]
"Training the detector is a supervised learning problem, but resolution is more challenging, requiring us to reason about latent parsing and context-dependent decisions.
",1 Introduction,[0],[0]
"We evaluate performance in two domains: the TempEval-3 corpus of newswire text (Uzzaman et al., 2013) and the WikiWars corpus of Wikipedia history articles (Mazur and Dale, 2010).",1 Introduction,[0],[0]
"On these benchmark datasets, we present new state-of-theart results, with error reductions of up to 28% for the detection task and 21% for the end-to-end task.",1 Introduction,[0],[0]
"Time Expressions We follow the TIMEX3 standard (Pustejovsky et al., 2005) for defining time expressions within documents.",2 Formal Overview,[0],[0]
"Let a document D = 〈w1, . . .",2 Formal Overview,[0],[0]
", wn〉 be a sequence of n words wi and a mention m = (i, j) indicate start and end indices for a phrase 〈wi, . . .",2 Formal Overview,[0],[0]
", wj〉 in D. Define a time expression e = (t, v) to include both a temporal type t and value v.1",2 Formal Overview,[0],[0]
"The temporal type t ∈ {Date, Time, Duration, Set} can take one of four possible values, indicating if the expression e is a date (e.g., “January 10, 2014”), time (e.g., “11:59 pm”), duration (e.g., “6 months”), or set (e.g., “every year”).",2 Formal Overview,[0],[0]
"The value v is an extension of the ISO 8601 standard, which encodes the time that mentionm refers to in the context provided by document D. For example, in a document written on Tuesday, January 7, 2014, “Friday,” “three days later,” and “January 10th” would all resolve to the value 2014-01-10.",2 Formal Overview,[0],[0]
"The time values are similarly defined for a wide range of expressions, such as underspecified dates (e.g., XXXX-01-10 for “Janunary 10th” when the year is not inferable from context) and durations (P2D for “two days”).
",2 Formal Overview,[0],[0]
Tasks Our goal is to find all time expressions in an input document.,2 Formal Overview,[0],[0]
We divide the problem into two parts: detection and resolution.,2 Formal Overview,[0],[0]
The detection problem is to take an input documentD and output a mention set M = {mi | i = 1 . . .,2 Formal Overview,[0],[0]
n,2 Formal Overview,[0],[0]
} of phrases in D that describe time expressions.,2 Formal Overview,[0],[0]
"The resolution problem (often also called normalization) is, given a document D and a set of mentions M , to
1Time expressions also have optional modifier values for non-TIMEX properties (e.g., the modifier would contain EARLY for the phrase “early march”).",2 Formal Overview,[0],[0]
"We do recover these modifiers but omit them from the discussion since they are not part of the official evaluation metrics.
",2 Formal Overview,[0],[0]
"map each m ∈ M to the referred time expression e. This paper addresses both of these tasks.
",2 Formal Overview,[0],[0]
"Approach We learn separate, but related, models for detection and resolution.",2 Formal Overview,[0],[0]
"For both tasks, we define the space of possible compositional meaning representations Z , where each z ∈ Z defines a unique time expression e. We use a log-linear CCG (Steedman, 1996; Clark and Curran, 2007) to rank possible meanings z ∈ Z for each mention m in a document D, as described in Section 4.",2 Formal Overview,[0],[0]
Both detection (Section 5) and resolution (Section 6) rely on the semantic parser to identify likely mentions and resolve them within context.,2 Formal Overview,[0],[0]
For learning we assume access to TimeML data containing documents labeled with time expressions.,2 Formal Overview,[0],[0]
"Each document D has a set {(mi, ei)|i = 1 . . .",2 Formal Overview,[0],[0]
"n}, where each mention mi marks a phrase that resolves to the time",2 Formal Overview,[0],[0]
"expression ei.
Evaluation We evaluate performance (Section 8) for both newswire text and Wikipedia articles.",2 Formal Overview,[0],[0]
"We compare to the state-of-the-art systems for end-to-end resolution (Strötgen and Gertz, 2013) and resolution given gold mentions (Bethard, 2013b), both of which do not use any machine learning techniques.",2 Formal Overview,[0],[0]
We use simply typed lambda calculus to represent time expressions.,3 Representing Time,[0],[0]
"Our representation draws heavily from the representation proposed by Angeli et al. (2012), who introduced semantic parsing for this task.",3 Representing Time,[0],[0]
"There are five primitive types: duration d, sequence s, range r, approximate reference a, and numeral n, as described below.",3 Representing Time,[0],[0]
"Table 1 lists the available constants for each type.
",3 Representing Time,[0],[0]
Duration A period of time.,3 Representing Time,[0],[0]
"Each duration is a multiple of one of a closed set of possible base durations (e.g., hour, day, and quarter), which we refer to as its granularity.",3 Representing Time,[0],[0]
"Table 1 includes the complete set of base durations used.
",3 Representing Time,[0],[0]
"Range A specific interval of time, following an interval-based theory of time (Allen, 1981).",3 Representing Time,[0],[0]
"The interval length is one of the base durations, which is the granularity of the range.",3 Representing Time,[0],[0]
"Given two ranges R and R′, we say that R ⊆ R′ if the endpoints of R lie on or within R′.
Sequence A set of ranges with identical granularity.",3 Representing Time,[0],[0]
The granularity of the sequence is that of its members.,3 Representing Time,[0],[0]
"For example, thursday , which has a
day granularity, denotes the set of all day-granular ranges enclosing specific Thursdays.",3 Representing Time,[0],[0]
"Given a range R and sequence S, we say that R ∈ S if R is a member of S. Given two sequences S and S′ we say that S ⊆ S′ if R ∈ S implies R ∈ S′. Approximate Reference An approximate time relative to the reference time.",3 Representing Time,[0],[0]
"For example, past and future.",3 Representing Time,[0],[0]
"To handle mentions such as “a while,” we add the constant unknown .
",3 Representing Time,[0],[0]
"Numeral An integer, for example, 5 or 1990 .",3 Representing Time,[0],[0]
"Numerals are used to denote specific ranges, such as the year 2001, or to modify a duration’s length.
",3 Representing Time,[0],[0]
"Functions We also allow for functional types, for example 〈s, r〉 is assigned to a function that maps from sequences to ranges.",3 Representing Time,[0],[0]
"Table 2 lists all supported functions with example mentions.
",3 Representing Time,[0],[0]
"Context Dependent Constants To mark places where context-dependent choices will need to be made during resolution, we use two placeholder constants.",3 Representing Time,[0],[0]
"First, ref time denotes the mention reference time, which is later set to either the document time or a previously resolved mention.",3 Representing Time,[0],[0]
"Second, temp d is used in the shift function to determine its return granularity, as described in Table 2, and is later replaced with the granularity of either the first or second argument of the enclosing shift function.",3 Representing Time,[0],[0]
Section 4.3 describes how these decisions are made.,3 Representing Time,[0],[0]
We define a three-step derivation to resolve mentions to their TIMEX3 value.,4 Parsing Time Expressions,[0],[0]
"First, we use a CCG to generate an initial logical form for the mention.",4 Parsing Time Expressions,[0],[0]
"Next, we apply a set of operations that modify the
initial logical form, as appropriate for its context.",4 Parsing Time Expressions,[0],[0]
"Finally, the logical form is resolved to a TIMEX3 value using a deterministic process.",4 Parsing Time Expressions,[0],[0]
"CCG is a linguistically motivated categorial formalism for modeling a wide range of language phenomena (Steedman, 1996; Steedman, 2000).",4.1 Combinatory Categorial Grammars,[0],[0]
A CCG is defined by a lexicon and a set of combinators.,4.1 Combinatory Categorial Grammars,[0],[0]
"The lexicon pairs words with categories and the combinators define how to combine categories to create complete parse trees.
",4.1 Combinatory Categorial Grammars,[0],[0]
"For example, Figure 1 shows a CCG parse tree for the phrase “one week ago.”",4.1 Combinatory Categorial Grammars,[0],[0]
"The parse tree is read top to bottom, starting from assigning categories to words using the lexicon.",4.1 Combinatory Categorial Grammars,[0],[0]
The lexical entry ago ` NP\NP : λx.shift(ref,4.1 Combinatory Categorial Grammars,[0],[0]
"time,−1 × x, temp d) for the word “ago” pairs it with a category that has syntactic type NP\NP and semantics λx.shift(ref time,−1 × x, temp d).",4.1 Combinatory Categorial Grammars,[0],[0]
"Each intermediate parse node is then constructed by applying one of a small set of binary or unary operations (Steedman, 1996; Steedman, 2000), which modify both the syntax and semantics.",4.1 Combinatory Categorial Grammars,[0],[0]
We use backward (<) and forward (>) application and several unary type-shifting rules to handle number combinations.,4.1 Combinatory Categorial Grammars,[0],[0]
"For example, in Figure 1 the category of the span “one week” is combined with the category of “ago” using backward application (<).",4.1 Combinatory Categorial Grammars,[0],[0]
"Parsing concludes with a logical form representing the meaning of the complete mention.
",4.1 Combinatory Categorial Grammars,[0],[0]
"Hand Engineered Lexicon To parse time expressions, we use a CCG lexicon that includes 287 manually designed entries, along with automatically generated entries such as numbers and common formats of dates and times.",4.1 Combinatory Categorial Grammars,[0],[0]
Figure 2 shows example entries from our lexicon.,4.1 Combinatory Categorial Grammars,[0],[0]
"To correctly resolve mentions to TIMEX3 values, the system must account for contextual in-
formation from various sources, including previous mentions in the document, the document creation time, and the sentence containing the mention.",4.2 Context-dependent Operations,[0],[0]
"We consider three types of context operations, each takes as input a logical form z′, modifies it and returns a new logical form z.",4.2 Context-dependent Operations,[0],[0]
"Each context-dependent parse y specifies one operator of each type, which are applied to the logical form constructed by the CCG grammar, to produce the final, context-dependent logical form LF(y).
",4.2 Context-dependent Operations,[0],[0]
"Reference Time Resolution The logical constant ref time is replaced by either dct , representing the document creation time, or last range, the last r-typed mention resolved in the document.",4.2 Context-dependent Operations,[0],[0]
"For example, consider the mention “the following year”, which is represented using the logical form next(seq(year), ref time).",4.2 Context-dependent Operations,[0],[0]
"Within the sentence “1998 was colder than the following year”, the resolution of “the following year” depends on the previous mention “1998”.",4.2 Context-dependent Operations,[0],[0]
"In contrast, in “The following year will be warmer”, its resolution depends on the document creation time.
",4.2 Context-dependent Operations,[0],[0]
"Directionality Resolution If z′ is s-typed we modify it to nearest forward(z′, ref time), nearest backward(z′, ref time), or z′.",4.2 Context-dependent Operations,[0],[0]
"For example, given the sentence “. . .",4.2 Context-dependent Operations,[0],[0]
"will be launched in april”, the mention “april”, and its logical form april , we would like to resolve it to the coming April, and therefore modify it to nearest forward(april , ref time).
",4.2 Context-dependent Operations,[0],[0]
"Shifting Granularity Every occurrence of the logical constant temp d , which is used as an argument to the function shift (see Table 2), is replaced with the granularity of either the first argument, the origin of the shift, or the second argument, the delta of the shift.",4.2 Context-dependent Operations,[0],[0]
This determines the final granularity of the output.,4.2 Context-dependent Operations,[0],[0]
"For example, if the reference time is 2002-01, the mention “two years earlier” would resolve to either a month (since the reference time is of month granularity) or a year (since the delta is of year granularity).",4.2 Context-dependent Operations,[0],[0]
"For a context-dependent parse y, we compute the TIMEX3 value TM(y) from the logical form z = LF(y) with a deterministic step that performs a single traversal of z. Each primitive logical constant from Table 1 contributes to setting part of the TIMEX3 value (for example, specifying the day of the week) and the functional constants in Table 2 dictate transformations on the TIMEX3 values (for example, shifting forward or backward in time).2",4.3 Resolving Logical Forms,[0],[0]
"The detection problem is to take an input document D and output a mention set M = {mi | i = 1, . . .",5 Detection,[0],[0]
",",5 Detection,[0],[0]
"n}, where each mention mi indexes a specific phrase in D that delimits a time expression.
",5 Detection,[0],[0]
Algorithm,5 Detection,[0],[0]
"The detection algorithm considers all phrases that our CCG grammar Λ (Section 4) can parse, uses a learned classifier to further filter this set, and finally resolves conflicts between any overlapping predictions.",5 Detection,[0],[0]
"We use a CKY algorithm to efficiently determine which phrases the CCG grammar can parse and only allow logical forms for which there exists some context in which they would produce a valid time expression, e.g. ruling out intersect(monday , tuesday).",5 Detection,[0],[0]
"Finally, we build the set M of non-overlapping mentions using a step similar to non-maximum suppression:
2The full details are beyond the scope of this paper, but an implementation is available on the author’s website.
",5 Detection,[0],[0]
"the mentions are sorted by length (longest first) and iteratively added to M , as long as they do not overlap with any mention already in M .
",5 Detection,[0],[0]
Filtering Model,5 Detection,[0],[0]
"Given a mention m, its document D, a feature function φ, the CCG lexicon Λ, and feature weights θ, we use a logistic regression model to define the probability distribution:
P (t|m,D; Λ, θ) = e θ·φ(m,D,Λ)
1 + eθ·φ(m,D,Λ)
where t indicates whether m is a time expression.
",5 Detection,[0],[0]
"Features We use three types of indicator features that test properties of the words in and around the potential mention m.
Context tokens Indicate the presence of a set of manually specified tokens near the mention.",5 Detection,[0],[0]
"These include quotations around the mention, the word “old” after the mention, and prepositions of time (such as “in”, “until”, and “during”) before.
",5 Detection,[0],[0]
"Part of speech Indicators that pair each word with its part of speech, as assigned by the Stanford tagger (Toutanova et al., 2003).
",5 Detection,[0],[0]
Lexical group Each lexical entry belongs to one of thirteen manually defined lexical groups which cluster entries that contribute to the final time expression similarly.,5 Detection,[0],[0]
"These groups include numbers, days of the week, months, seasons, etc.",5 Detection,[0],[0]
"For each group, we include a feature indicating whether the parse includes a lexical entry from that group.
Determiner dependency Indicates the presence of a determiner in the mention and whether its parent in the dependency tree (generated by the Stanford parser (de Marneffe et al., 2006)) also resides within the mention.
",5 Detection,[0],[0]
"Learning Finally, we construct the training data by considering all spans that (1) the CCG temporal grammar can parse and (2) are not strict subspans of an annotated mention.",5 Detection,[0],[0]
All spans that exactly matched the gold labels are used as positive examples and all others are negatives.,5 Detection,[0],[0]
"Given this relaxed data, we learn the feature weights θ with L1-regularization.",5 Detection,[0],[0]
We set the probability threshold for detecting a time expression by optimizing the F1 score over the training data.,5 Detection,[0],[0]
"The resolution problem is to, given a document D and a set of mentions M , map each m ∈ M to the correct time expression e. Section 4 defined
the space of possible time expression that can be constructed for an input mention m in the context of a document D. In general, there will be many different possible derivations, and we will learn a model for selecting the best one.
",6 Resolution,[0],[0]
"Model Let y be a context-dependent CCG parse, which includes a parse tree TR(y), a set of context operations CNTX(y) applied to the logical form at the root of the tree, a final context-dependent logical form LF(y) and a TIMEX3 value TM(y).",6 Resolution,[0],[0]
"Define φ(m,D, y) ∈ Rd to be a d-dimensional feature–vector representation and θ ∈ Rd to be a parameter vector.",6 Resolution,[0],[0]
"The probability of a parse y for mention m and document D is:
P (y|m,D; θ,Λ) = e θ·φ(m,D,y)∑
y′",6 Resolution,[0],[0]
"e θ·φ(m,D,y′)
",6 Resolution,[0],[0]
"The inference problem at test time requires finding the best resolution by solving y∗(m,D) = arg maxy P (y|m,D; θ,Λ), where the final output TIMEX3 value is TM(y∗(m,D)).
",6 Resolution,[0],[0]
"Inference We find the best context-dependent parse y by enumeration, as follows.",6 Resolution,[0],[0]
"We first parse the input mention m with a CKY-style algorithm, following previous work (Zettlemoyer and Collins, 2005).",6 Resolution,[0],[0]
"Due to the short length of time expressions and the manually constructed lexicon, we can perform exact inference.",6 Resolution,[0],[0]
"Given a parse, we then enumerate all possible outcomes for the context resolution operators.",6 Resolution,[0],[0]
"In practice, there are never more than one hundred possibilities.
",6 Resolution,[0],[0]
"Features The resolution features test properties of the linguistic context surrounding the mention m, relative to the context-dependent CCG parse y.
Governor verb We define the governor verb to be the nearest ancestor verb in the dependency parse of any token in m. We include features indicating the concatenation of the part-of-speech of the governor verb, its auxiliary verb if present, and the selected direction resolution operator (see Section 4.2).",6 Resolution,[0],[0]
"This feature helps to distinguish “They met on Friday” from “They will meet on Friday.”
Temporal offset If the final logical form LF (y) is a range, we define t to be the time difference between TM(y) and the reference time.",6 Resolution,[0],[0]
"For example, if the reference time is 2000-01-10 and the mention resolves to 2000-01-01, then t is -9 days.",6 Resolution,[0],[0]
"This feature indicates one of eleven bucketed values for t, including same day, less than a week,
less than a month, etc.",6 Resolution,[0],[0]
It allows the model to encode the likely temporal progression of a narrative.,6 Resolution,[0],[0]
"This feature is ignored if the granularity of TM(y) or the reference time is greater than a year.
",6 Resolution,[0],[0]
"Shift granularity The logical constant shift (Table 2) takes three arguments: the origin (range), the delta (duration), and the output granularity (duration).",6 Resolution,[0],[0]
This indicator feature is the concatenation of each argument’s granularity for every shift in LF (y).,6 Resolution,[0],[0]
"It allows the model to determine whether “a year ago” refers to a year or a day.
",6 Resolution,[0],[0]
Reference type Let r denote whether the reference time is the document creation time dct or the last range last range.,6 Resolution,[0],[0]
Let gl,6 Resolution,[0],[0]
"and gr denote the granularities of LF (y) and the reference time, respectively.",6 Resolution,[0],[0]
"We include features indicating the concatenations: r+gl, r+gr, and r+gl+gr.",6 Resolution,[0],[0]
"Additionally, we include features indicating the concatenation of r with each lexical entry used in the parse TR(y).",6 Resolution,[0],[0]
"These features allow the model to encode preferences in selecting the correct reference time.
",6 Resolution,[0],[0]
"Fine-grained type These features indicate the fine-grained type of TM(y), such as day of the month or week of the year.",6 Resolution,[0],[0]
We also include a feature indicating the concatenation of each of these features with the direction resolution operator that was used.,6 Resolution,[0],[0]
"These features allow the model to represent, for example, that minutes of the year are less likely than days of the month.
",6 Resolution,[0],[0]
"Intersections These features indicate the concatenation of the granularities of any two sequences that appear as arguments to an intersect constant.
",6 Resolution,[0],[0]
"Learning To estimate the model parameters θ we assume access to a set of training examples {(mi, di, ei) : i = 1, . .",6 Resolution,[0],[0]
.,6 Resolution,[0],[0]
",",6 Resolution,[0],[0]
"n},",6 Resolution,[0],[0]
where each mention mi is paired with a document di and a TIMEX3 value ei.,6 Resolution,[0],[0]
"We use the AdaGrad algorithm (Duchi et al., 2011) to optimize the conditional, marginal log-likelihood of the data.",6 Resolution,[0],[0]
"For each mention, we marginalize over all possible context-dependent parses, using the predictions from the model on the previous gold mentions to fill in missing context, where necessary.",6 Resolution,[0],[0]
"After parameter estimation, we set a probability threshold for retaining a resolved time expression by optimizing value F1 (see Section 8) over the training data.",6 Resolution,[0],[0]
"Semantic parsers map sentences to logical representations of their underlying meaning, e.g., Zelle
and Mooney (1996), Zettlemoyer and Collins (2005), and Wong and Mooney (2007).",7 Related Work,[0],[0]
"Recently, research in this area has focused on learning for various forms of relatively weak but easily gathered supervision.",7 Related Work,[0],[0]
"This includes learning from question-answer pairs (Clarke et al., 2010; Liang et al., 2011; Kwiatkowski et al., 2013), from conversational logs (Artzi and Zettlemoyer, 2011), with distant supervision (Krishnamurthy and Mitchell, 2012; Cai and Yates, 2013), and from sentences paired with system behavior (Goldwasser and Roth, 2011; Chen and Mooney, 2011; Artzi and Zettlemoyer, 2013b).",7 Related Work,[0],[0]
"Recently, Angeli et al. introduced the idea of learning semantic parsers to resolve time expressions (Angeli et al., 2012) and showed that the approach can generalize to multiple languages (Angeli and Uszkoreit, 2013).",7 Related Work,[0],[0]
"Similarly, Bethard demonstrated that a hand-engineered semantic parser is also effective (Bethard, 2013b).",7 Related Work,[0],[0]
"However, these approaches did not use the semantic parser for detection and did not model linguistic context during resolution.
",7 Related Work,[0],[0]
"We build on a number of existing algorithmic ideas, including using CCGs to build meaning representations (Zettlemoyer and Collins, 2005; Zettlemoyer and Collins, 2007; Kwiatkowski et al., 2010; Kwiatkowski et al., 2011), building derivations to transform the output of the CCG parser based on context (Zettlemoyer and Collins, 2009), and using weakly supervised parameter updates (Artzi and Zettlemoyer, 2011; Artzi and Zettlemoyer, 2013b).",7 Related Work,[0],[0]
"However, we are the first to use a semantic parsing grammar within a mention detection algorithm, thereby avoiding the need to represent the meaning of complete sentences, and the first to develop a context-dependent model for semantic parsing of time expressions.
",7 Related Work,[0],[0]
"Time expressions have been extensively studied as part of the TimeEx task, including 9 teams who competed in the 2013 TempEval-3 competition (Uzzaman et al., 2013).",7 Related Work,[0],[0]
"This line of work builds on ideas from TimeBank (Pustejovsky et al., 2003) and a number of different formal models for temporal reasoning, e.g. Allen (1983), Moens and Steedman (1988).",7 Related Work,[0],[0]
"In 2013, HeidelTime (Strötgen and Gertz, 2013) was the top performing system.",7 Related Work,[0],[0]
"It used deterministic rules defined over regular expressions to perform both detection and resolution, and will provide a comparison system for our evaluation in Section 9.",7 Related Work,[0],[0]
"In
general, many different rule-based systems, e.g. NavyTime (Chambers, 2013) and SUTime (Chang and Manning, 2012), and learning systems, e.g. ClearTK (Bethard, 2013a) and MANTime (Filannino et al., 2013), did well for detection.",7 Related Work,[0],[0]
"However, rule-based approaches dominated in resolution; none of the top performers attempted to learn to do resolution.",7 Related Work,[0],[0]
"Our approach is a hybrid of rule based and learning, by using latent-variable learning techniques to estimate CCG parsing and context resolution models from the provided data.",7 Related Work,[0],[0]
"Data We evaluate performance on the TempEval-3 (Uzzaman et al., 2013) and WikiWars (Mazur and Dale, 2010) datasets.",8 Experimental Setup,[0],[0]
Figure 3 shows summary statistics for both datasets.,8 Experimental Setup,[0],[0]
"For the TempEval-3 corpus, we use the given training and testing set splits.",8 Experimental Setup,[0],[0]
"Since the training set has lower inter-annotator agreement than the testing set (Uzzaman et al., 2013)",8 Experimental Setup,[0],[0]
", we manually corrected all of the mistakes we found in the training data.3",8 Experimental Setup,[0],[0]
The original training set is denoted Dev* and the corrected Dev.,8 Experimental Setup,[0],[0]
"We report (1) cross-validation development results on Dev*, (2) cross-validation development and ablation results for Dev, and (3) held-out test results after training with Dev.",8 Experimental Setup,[0],[0]
"For WikiWars, we randomly assigned the data to include 17 training documents (2,228 time expressions) and 5 test documents (363 time expressions).",8 Experimental Setup,[0],[0]
We use cross-validation on the training data for development.,8 Experimental Setup,[0],[0]
"All cross-validation experiments used 10 folds.
",8 Experimental Setup,[0],[0]
"Implementation Our system was implemented using the open source University of Washington Semantic Parsing Framework (Artzi and Zettlemoyer, 2013a).",8 Experimental Setup,[0],[0]
"We used LIBLINEAR (Fan et al., 2008) to learn the detection model.
",8 Experimental Setup,[0],[0]
Parameter Settings,8 Experimental Setup,[0],[0]
"We use the same set of parameters for both datasets, chosen based on development experiments.",8 Experimental Setup,[0],[0]
"For detection, we set the regularization parameter to 10 with a stopping crite-
3We modified the annotations for 18% of the mentions.",8 Experimental Setup,[0],[0]
"This relabeled corpus is available on the author’s website.
",8 Experimental Setup,[0],[0]
rion of 0.01.,8 Experimental Setup,[0],[0]
"For resolution, we set the learning rate to 0.25 and ran AdaGrad for 5 iterations.",8 Experimental Setup,[0],[0]
"All features are initialized to have zero weights.
",8 Experimental Setup,[0],[0]
Evaluation Metrics,8 Experimental Setup,[0],[0]
We use the official TempEval-3 scoring script and report the standard metrics.,8 Experimental Setup,[0],[0]
"We report detection precision, recall and F1 with relaxed and strict metrics; a gold mention is considered detected for the relaxed metric if any of the output candidates overlap with it and is detected for the strict metric if the extent of any output candidates matches exactly.",8 Experimental Setup,[0],[0]
"For resolution, we report value accuracy, measuring correctness of time expressions detected according to the relaxed metric.",8 Experimental Setup,[0],[0]
"We also report value precision, recall, and F1, which score an expression as correct if it is both correctly detected (relaxed) and resolved.",8 Experimental Setup,[0],[0]
"For end-to-end performance, value F1 is the primary metric.",8 Experimental Setup,[0],[0]
"Finally, we report accuracy and F1 for temporal types, as defined in Section 2, for the TempEval dataset (WikiWars does not include type labels).
",8 Experimental Setup,[0],[0]
"Comparison Systems We compare our system primarily to HeidelTime (Strötgen and Gertz, 2013), which is state of the art in the end-toend task.",8 Experimental Setup,[0],[0]
"For the TempEval-3 dataset, we also compare to two other strong participants of the shared task.",8 Experimental Setup,[0],[0]
"These include NavyTime (Chambers, 2013), which had the top relaxed detection score, and ClearTK (Bethard, 2013a), which had the top strict detection score and type F1 score.",8 Experimental Setup,[0],[0]
"We also include a comparison with Bethard’s synchronous
context free grammar (SCFG) (Bethard, 2013b), which is state-of-the-art in the task of resolution with gold mention boundaries.",8 Experimental Setup,[0],[0]
End-to-end results Figure 4 shows development and test results for TempEval-3.,9 Results,[0],[0]
Figure 5 shows these numbers for WikiWars.,9 Results,[0],[0]
"In both datasets, we achieve state-of-the-art test scores.",9 Results,[0],[0]
"For detection, we show up to 3-point improvements in strict and relaxed F1 scores.",9 Results,[0],[0]
"These numbers outperform all systems participating in the shared task, which used a variety of techniques including hand-engineered rules, CRF tagging models, and SVMs.",9 Results,[0],[0]
"For resolution, we show up to 4-point improvements in the value F1 score, also outperforming participating systems, all of which used hand-engineered rules for resolution.
",9 Results,[0],[0]
Gold Mentions Figure 6 reports development and test results with gold mentions.4,9 Results,[0],[0]
"Our approach outperforms the state of the art, SCFG (Bethard, 2013b), which also used a hand engineered grammar, but did not use machine learning techniques.
",9 Results,[0],[0]
"4These numbers vary slightly from those reported; we did not count the document creation times as mentions.
",9 Results,[0],[0]
Precision vs. Recall Our probabilistic model of time expression resolution allows us to easily tradeoff precision and recall for end-to-end performance by varying the resolution probability threshold.,9 Results,[0],[0]
Figure 7 shows the precision vs. recall of the resolved values from 10-fold cross validation of TempEval-3 Dev and WikiWars Dev.,9 Results,[0],[0]
"We are able to achieve precision at or above 90% with reasonable recall, nearly 70% for WikiWars and over 85% for TempEval-3.
",9 Results,[0],[0]
Ablation Study Figures 4-5 also show comparisons for our system with no context.,9 Results,[0],[0]
"We ablate the ability to refer to the context during resolution by removing contextual information from the resolution features and only allowing the document creation time to be the reference time.
",9 Results,[0],[0]
We see an interesting asymmetry in the effect of modeling context across the two domains.,9 Results,[0],[0]
We find that context is much more important in WikiWars (19 point difference) than in TempEval (2 point difference).,9 Results,[0],[0]
This result reaffirms the difference in domains that Strötgen and Gertz (2012) noted during the development of HeidelTime: history articles have narrative structure that moves back and forth through time while newspaper text typically describes events happening near the document creation time.,9 Results,[0],[0]
"This difference helps us to understand why previous learning systems have been able to ignore context and perform well on newswire text.
",9 Results,[0],[0]
"Error Analysis To investigate the source of error, we compute oracle results for resolving gold mentions over the TempEval-3 Dev dataset.",9 Results,[0],[0]
"We found that our system produces a correct candidate derivation for 96% of the mentions.
",9 Results,[0],[0]
"We also manually categorized all resolution errors for end-to-end performance with 10-fold cross validation of the TempEval-3 Dev dataset,
shown in Figure 8.",9 Results,[0],[0]
"The lexicon allows for effective parsing, contributing to only 2% of the overall errors.",9 Results,[0],[0]
"However, context is more challenging.",9 Results,[0],[0]
"The three largest categories, responsible for 64.7% of the errors, were incorrect use of the context operators.",9 Results,[0],[0]
More expressive modeling will be required to fully capture the complex pragmatics involved in understanding time expressions.,9 Results,[0],[0]
We presented the first context-dependent semantic parsing system to detect and resolve time expressions.,10 Conclusion,[0],[0]
Both models used a Combinatory Categorial Grammar (CCG) to construct a set of possible temporal meaning representations.,10 Conclusion,[0],[0]
This grammar defined the possible phrases for detection and the inputs to a context-dependent reasoning step that was used to construct the output time expression during resolution.,10 Conclusion,[0],[0]
"Experiments demonstrated that our approach outperforms state-of-the-art systems.
",10 Conclusion,[0],[0]
"In the future, we aim to develop joint models for reasoning about events and time expressions, including detection and resolution of temporal relations.",10 Conclusion,[0],[0]
We are also interested in testing coverage in new domains and investigating techniques for semi-supervised learning and learning with noisy data.,10 Conclusion,[0],[0]
"We hypothesize that semantic parsing techniques could help in all of these settings, providing a unified mechanism for compositional analysis within temporal understanding problems.",10 Conclusion,[0],[0]
"The research was supported in part by DARPA under the DEFT program through the AFRL (FA8750-13-2-0019) and the CSSG (N11AP20020), and the NSF (IIS-1115966, IIS1252835).",Acknowledgments,[0],[0]
"The authors thank Nicholas FitzGerald, Tom Kwiatkowski, and Mark Yatskar for helpful discussions, and the anonymous reviewers for helpful comments.",Acknowledgments,[0],[0]
We present an approach for learning context-dependent semantic parsers to identify and interpret time expressions.,abstractText,[0],[0]
"We use a Combinatory Categorial Grammar to construct compositional meaning representations, while considering contextual cues, such as the document creation time and the tense of the governing verb, to compute the final time values.",abstractText,[0],[0]
"Experiments on benchmark datasets show that our approach outperforms previous stateof-the-art systems, with error reductions of 13% to 21% in end-to-end performance.",abstractText,[0],[0]
Context-dependent Semantic Parsing for Time Expressions,title,[0],[0]
"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 873–883 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics
https://doi.org/10.18653/v1/P17-1081",text,[0],[0]
"Sentiment analysis is a ‘suitcase’ research problem that requires tackling many NLP sub-tasks, e.g., aspect extraction (Poria et al., 2016a), named entity recognition (Ma et al., 2016), concept extraction (Rajagopal et al., 2013), sarcasm detection (Poria et al., 2016b), personality recognition (Majumder et al., 2017), and more.
",1 Introduction,[0],[0]
"Sentiment analysis can be performed at different granularity levels, e.g., subjectivity detection simply classifies data as either subjective (opinionated) or objective (neutral), while polarity detection focuses on determining whether subjective data indicate positive or negative sentiment.",1 Introduction,[0],[0]
"Emotion recognition further breaks down the inferred polarity into a set of emotions conveyed by the subjective data, e.g., positive sentiment can be caused by joy or anticipation, while negative sentiment can be caused by fear or disgust.
",1 Introduction,[0],[0]
"Even though the primary focus of this paper is to classify sentiment in videos, we also show the performance of the proposed method for the finergrained task of emotion recognition.
",1 Introduction,[0],[0]
"Emotion recognition and sentiment analysis have become a new trend in social media, helping users and companies to automatically extract the opinions expressed in user-generated content, especially videos.",1 Introduction,[0],[0]
"Thanks to the high availability of computers and smartphones, and the rapid rise of social media, consumers tend to record their reviews and opinions about products or films and upload them on social media platforms, such as YouTube and Facebook.",1 Introduction,[0],[0]
"Such videos often contain comparisons, which can aid prospective buyers make an informed decision.
",1 Introduction,[0],[0]
The primary advantage of analyzing videos over text is the surplus of behavioral cues present in vocal and visual modalities.,1 Introduction,[0],[0]
"The vocal modulations and facial expressions in the visual data, along with textual data, provide important cues to better identify affective states of the opinion holder.",1 Introduction,[0],[0]
"Thus, a combination of text and video data helps to create a more robust emotion and sentiment analysis model (Poria et al., 2017a).
",1 Introduction,[0],[0]
"An utterance (Olson, 1977) is a unit of speech bound by breathes or pauses.",1 Introduction,[0],[0]
Utterance-level sentiment analysis focuses on tagging every utterance of a video with a sentiment label (instead of assigning a unique label to the whole video).,1 Introduction,[0],[0]
"In particular, utterance-level sentiment analysis is useful to understand the sentiment dynamics of different aspects of the topics covered by the speaker throughout his/her speech.
",1 Introduction,[0],[0]
"Recently, a number of approaches to multimodal sentiment analysis, producing interesting results, have been proposed (Pérez-Rosas et al., 2013; Wollmer et al., 2013; Poria et al., 2015).",1 Introduction,[0],[0]
"However, there are major issues that remain unaddressed.",1 Introduction,[0],[0]
Not considering the relation and dependencies among the utterances is one of such issues.,1 Introduction,[0],[0]
"State-of-the-art approaches in this area treat utterances independently and ignore the order of utterances in a video (Cambria et al., 2017b).
",1 Introduction,[0],[0]
"873
Every utterance in a video is spoken at a distinct time and in a particular order.",1 Introduction,[0],[0]
"Thus, a video can be treated as a sequence of utterances.",1 Introduction,[0],[0]
"Like any other sequence classification problem (Collobert et al., 2011), sequential utterances of a video may largely be contextually correlated and, hence, influence each other’s sentiment distribution.",1 Introduction,[0],[0]
"In our paper, we give importance to the order in which utterances appear in a video.
",1 Introduction,[0],[0]
We treat surrounding utterances as the context of the utterance that is aimed to be classified.,1 Introduction,[0],[0]
"For example, the MOSI dataset (Zadeh et al., 2016) contains a video, in which a girl reviews the movie ‘Green Hornet’.",1 Introduction,[0],[0]
"At one point, she says “The Green Hornet did something similar”.",1 Introduction,[0],[0]
"Normally, doing something similar, i.e., monotonous or repetitive might be perceived as negative.",1 Introduction,[0],[0]
"However, the nearby utterances “It engages the audience more”, “they took a new spin on it”, “and I just loved it” indicate a positive context.
",1 Introduction,[0],[0]
"The hypothesis of the independence of tokens is quite popular in information retrieval and data mining, e.g., bag-of-words model, but it has a lot limitations (Cambria and White, 2014).",1 Introduction,[0],[0]
"In this paper, we discard such an oversimplifying hypothesis and develop a framework based on long shortterm memory (LSTM) that takes a sequence of utterances as input and extracts contextual utterancelevel features.
",1 Introduction,[0],[0]
"The other uncovered major issues in the literature are the role of speaker-dependent versus speaker-independent models, the impact of each modality across the dataset, and generalization ability of a multimodal sentiment classifier.",1 Introduction,[0],[0]
Leaving these issues unaddressed has presented difficulties in effective comparison of different multimodal sentiment analysis methods.,1 Introduction,[0],[0]
"In this work, we address all of these issues.
",1 Introduction,[0],[0]
"Our model preserves the sequential order of utterances and enables consecutive utterances to share information, thus providing contextual information to the utterance-level sentiment classification process.",1 Introduction,[0],[0]
"Experimental results show that the proposed framework has outperformed the state of the art on three benchmark datasets by 5-10%.
",1 Introduction,[0],[0]
"The paper is organized as follows: Section 2 provides a brief literature review on multimodal sentiment analysis; Section 3 describes the proposed method in detail; experimental results and discussion are shown in Section 4; finally, Section 5 concludes the paper.",1 Introduction,[0],[0]
"The opportunity to capture people’s opinions has raised growing interest both within the scientific community, for the new research challenges, and in the business world, due to the remarkable benefits to be had from financial market prediction.
",2 Related Work,[0],[0]
"Text-based sentiment analysis systems can be broadly categorized into knowledge-based and statistics-based approaches (Cambria et al., 2017a).",2 Related Work,[0],[0]
"While the use of knowledge bases was initially more popular for the identification of polarity in text (Cambria et al., 2016; Poria et al., 2016c), sentiment analysis researchers have recently been using statistics-based approaches, with a special focus on supervised statistical methods (Socher et al., 2013; Oneto et al., 2016).
",2 Related Work,[0],[0]
"In 1974, Ekman (Ekman, 1974) carried out extensive studies on facial expressions which showed that universal facial expressions are able to provide sufficient clues to detect emotions.",2 Related Work,[0],[0]
"Recent studies on speech-based emotion analysis (Datcu and Rothkrantz, 2008) have focused on identifying relevant acoustic features, such as fundamental frequency (pitch), intensity of utterance, bandwidth, and duration.
",2 Related Work,[0],[0]
"As for fusing audio and visual modalities for emotion recognition, two of the early works were (De Silva et al., 1997) and (Chen et al., 1998).",2 Related Work,[0],[0]
Both works showed that a bimodal system yielded a higher accuracy than any unimodal system.,2 Related Work,[0],[0]
"More recent research on audio-visual fusion for emotion recognition has been conducted at either feature level (Kessous et al., 2010) or decision level (Schuller, 2011).",2 Related Work,[0],[0]
"While there are many research papers on audio-visual fusion for emotion recognition, only a few have been devoted to multimodal emotion or sentiment analysis using textual clues along with visual and audio modalities.",2 Related Work,[0],[0]
"(Wollmer et al., 2013) and (Rozgic et al., 2012) fused information from audio, visual, and textual modalities to extract emotion and sentiment.
",2 Related Work,[0],[0]
"Poria et al. (Poria et al., 2015, 2016d, 2017b) extracted audio, visual and textual features using convolutional neural network (CNN); concatenated those features and employed multiple kernel learning (MKL) for final sentiment classification.",2 Related Work,[0],[0]
"(Metallinou et al., 2008) and (Eyben et al., 2010a) fused audio and textual modalities for emotion recognition.",2 Related Work,[0],[0]
Both approaches relied on a featurelevel fusion.,2 Related Work,[0],[0]
"(Wu and Liang, 2011) fused audio and textual clues at decision level.",2 Related Work,[0],[0]
"In this work, we propose a LSTM network that takes as input the sequence of utterances in a video and extracts contextual unimodal and multimodal features by modeling the dependencies among the input utterances.",3 Method,[0],[0]
"M number of videos, comprising of its constituent utterances, serve as the input.",3 Method,[0],[0]
"We represent the dataset as U = u1, u2, u3..., uM and each ui = ui,1, ui,2, ..., ui, Li where Li is the number of utterances in video ui.",3 Method,[0],[0]
"Below, we present an overview of the proposed method in two major steps.
",3 Method,[0],[0]
"A. Context-Independent Unimodal UtteranceLevel Feature Extraction
Firstly, the unimodal features are extracted without considering the contextual information of the utterances (Section 3.1).
",3 Method,[0],[0]
"B. Contextual Unimodal and Multimodal Classification
Secondly, the context-independent unimodal features (from Step A) are fed into a LSTM network (termed contextual LSTM) that allows consecutive utterances in a video to share information in the feature extraction process (Section 3.2).
",3 Method,[0],[0]
We experimentally show that this proposed framework improves the performance of utterance-level sentiment classification over traditional frameworks.,3 Method,[0],[0]
"Initially, the unimodal features are extracted from each utterance separately, i.e., we do not consider the contextual relation and dependency among the utterances.",3.1 Extracting Context-Independent Unimodal Features,[0],[0]
"Below, we explain the textual, audio, and visual feature extraction methods.",3.1 Extracting Context-Independent Unimodal Features,[0],[0]
The source of textual modality is the transcription of the spoken words.,3.1.1 text-CNN: Textual Features Extraction,[0],[0]
"For extracting features from the textual modality, we use a CNN (Karpathy et al., 2014).",3.1.1 text-CNN: Textual Features Extraction,[0],[0]
"In particular, we first represent each utterance as the concatenation of vectors of the constituent words.",3.1.1 text-CNN: Textual Features Extraction,[0],[0]
"These vectors are the publicly available 300-dimensional word2vec vectors trained on 100 billion words from Google News (Mikolov et al., 2013).
",3.1.1 text-CNN: Textual Features Extraction,[0],[0]
The convolution kernels are thus applied to these concatenated word vectors instead of individual words.,3.1.1 text-CNN: Textual Features Extraction,[0],[0]
Each utterance is wrapped to a window of 50 words which serves as the input to the CNN.,3.1.1 text-CNN: Textual Features Extraction,[0],[0]
"The CNN has two convolutional layers; the first layer has two kernels of size 3 and 4, with 50 feature maps each and the second layer has a kernel of size 2 with 100 feature maps.
",3.1.1 text-CNN: Textual Features Extraction,[0],[0]
The convolution layers are interleaved with max-pooling layers of window 2 × 2.,3.1.1 text-CNN: Textual Features Extraction,[0],[0]
This is followed by a fully connected layer of size 500 and softmax output.,3.1.1 text-CNN: Textual Features Extraction,[0],[0]
"We use a rectified linear unit (ReLU) (Teh and Hinton, 2001) as the activation function.",3.1.1 text-CNN: Textual Features Extraction,[0],[0]
The activation values of the fullyconnected layer are taken as the features of utterances for text modality.,3.1.1 text-CNN: Textual Features Extraction,[0],[0]
"The convolution of the CNN over the utterance learns abstract representations of the phrases equipped with implicit semantic information, which with each successive layer spans over increasing number of words and ultimately the entire utterance.",3.1.1 text-CNN: Textual Features Extraction,[0],[0]
Audio features are extracted at 30 Hz frame-rate and a sliding window of 100 ms.,3.1.2 openSMILE: Audio Feature Extraction,[0],[0]
"To compute the features, we use openSMILE (Eyben et al., 2010b), an open-source software that automatically extracts audio features such as pitch and voice intensity.",3.1.2 openSMILE: Audio Feature Extraction,[0],[0]
Voice normalization is performed and voice intensity is thresholded to identify samples with and without voice.,3.1.2 openSMILE: Audio Feature Extraction,[0],[0]
"Z-standardization is used to perform voice normalization.
",3.1.2 openSMILE: Audio Feature Extraction,[0],[0]
"The features extracted by openSMILE consist of several low-level descriptors (LLD), e.g., MFCC, voice intensity, pitch, and their statistics, e.g., mean, root quadratic mean, etc.",3.1.2 openSMILE: Audio Feature Extraction,[0],[0]
"Specifically, we use IS13-ComParE configuration file in openSMILE.",3.1.2 openSMILE: Audio Feature Extraction,[0],[0]
"Taking into account all functionals of each LLD, we obtained 6373 features.",3.1.2 openSMILE: Audio Feature Extraction,[0],[0]
"We use 3D-CNN (Ji et al., 2013) to obtain visual features from the video.",3.1.3 3D-CNN: Visual Feature Extraction,[0],[0]
"We hypothesize that 3D-CNN will not only be able to learn relevant features from each frame, but will also learn the changes among given number of consecutive frames.
",3.1.3 3D-CNN: Visual Feature Extraction,[0],[0]
"In the past, 3D-CNN has been successfully applied to object classification on tridimensional data (Ji et al., 2013).",3.1.3 3D-CNN: Visual Feature Extraction,[0],[0]
"Its ability to achieve stateof-the-art results motivated us to adopt it in our framework.
",3.1.3 3D-CNN: Visual Feature Extraction,[0],[0]
"Let vid ∈ Rc×f×h×w be a video, where c = number of channels in an image (in our case c = 3, since we consider only RGB images), f = number of frames, h = height of the frames, and w = width of the frames.",3.1.3 3D-CNN: Visual Feature Extraction,[0],[0]
"Again, we consider the 3D convolutional filter filt ∈ Rfm×c×fd×fh×fw , where fm = number of feature maps, c = number of channels, fd = number of frames (in other words depth of the filter), fh = height of the filter, and fw = width of the filter.",3.1.3 3D-CNN: Visual Feature Extraction,[0],[0]
"Similar to 2D-CNN, filt slides across video vid and generates output convout ∈ Rfm×c×(f−fd+1)×(h−fh+1)×(w−fw+1).",3.1.3 3D-CNN: Visual Feature Extraction,[0],[0]
"Next, we apply max pooling to convout to select only relevant features.",3.1.3 3D-CNN: Visual Feature Extraction,[0],[0]
"The pooling will be applied only to the last three dimensions of the array convout.
",3.1.3 3D-CNN: Visual Feature Extraction,[0],[0]
"In our experiments, we obtained best results with 32 feature maps (fm) with the filter-size of 5 × 5 × 5 (or fd × fh × fw).",3.1.3 3D-CNN: Visual Feature Extraction,[0],[0]
"In other words, the dimension of the filter is 32 × 3 × 5 × 5 × 5 (or fm × c × fd ×",3.1.3 3D-CNN: Visual Feature Extraction,[0],[0]
fh × fw).,3.1.3 3D-CNN: Visual Feature Extraction,[0],[0]
"Subsequently, we apply max pooling on the output of convolution operation, with window-size being 3 × 3 × 3.",3.1.3 3D-CNN: Visual Feature Extraction,[0],[0]
This is followed by a dense layer of size 300 and softmax.,3.1.3 3D-CNN: Visual Feature Extraction,[0],[0]
The activation values of this dense layer are finally used as the video features for each utterance.,3.1.3 3D-CNN: Visual Feature Extraction,[0],[0]
"In sequence classification, the classification of each member is dependent on the other members.",3.2 Context-Dependent Feature Extraction,[0],[0]
Utterances in a video maintain a sequence.,3.2 Context-Dependent Feature Extraction,[0],[0]
"We hypothesize that, within a video, there is a high probability of inter-utterance dependency with respect to their sentimental clues.
",3.2 Context-Dependent Feature Extraction,[0],[0]
"In particular, we claim that, when classifying one utterance, other utterances can provide important contextual information.",3.2 Context-Dependent Feature Extraction,[0],[0]
This calls for a model which takes into account such inter-dependencies and the effect these might have on the target utterance.,3.2 Context-Dependent Feature Extraction,[0],[0]
"To capture this flow of informational triggers across utterances, we use a LSTM-based recurrent neural network (RNN) scheme (Gers, 2001).",3.2 Context-Dependent Feature Extraction,[0],[0]
"LSTM (Hochreiter and Schmidhuber, 1997) is a kind of RNN, an extension of conventional feedforward neural network.",3.2.1 Long Short-Term Memory,[0],[0]
"Specifically, LSTM cells are capable of modeling long-range dependencies, which other traditional RNNs fail to do given the vanishing gradient issue.",3.2.1 Long Short-Term Memory,[0],[0]
"Each LSTM cell consists of an input gate i, an output gate o, and a forget gate f , to control the flow of information.
",3.2.1 Long Short-Term Memory,[0],[0]
"Current research (Zhou et al., 2016) indicates the benefit of using such networks to incorporate contextual information in the classification process.",3.2.1 Long Short-Term Memory,[0],[0]
"In our case, the LSTM network serves the purpose of context-dependent feature extraction by modeling relations among utterances.",3.2.1 Long Short-Term Memory,[0],[0]
We term our architecture ‘contextual LSTM’.,3.2.1 Long Short-Term Memory,[0],[0]
We propose several architectural variants of it later in the paper.,3.2.1 Long Short-Term Memory,[0],[0]
"Let unimodal features have dimension k, each utterance is thus represented by a feature vector xi,t ∈ Rk, where t represents the tth utterance of the video i. For a video, we collect the vectors for all the utterances in it, to get Xi =[xi,1,xi,2, ...,xi,Li] ∈ RLi×k, where Li represents the number of utterances in the video.",3.2.2 Contextual LSTM Architecture,[0],[0]
This matrix Xi serves as the input to the LSTM.,3.2.2 Contextual LSTM Architecture,[0],[0]
"Figure 1 demonstrates the functioning of this LSTM module.
",3.2.2 Contextual LSTM Architecture,[0],[0]
"In the procedure, getLstmFeatures(Xi) of Algorithm 1, each of these utterance xi,t is passed through a LSTM cell using the equations mentioned in line 32 to 37.",3.2.2 Contextual LSTM Architecture,[0],[0]
"The output of the LSTM cell hi,t is then fed into a dense layer and finally into a softmax layer (line 38 to 39).",3.2.2 Contextual LSTM Architecture,[0],[0]
"The activations of the dense layer zi,t are used as the contextdependent features of contextual LSTM.",3.2.2 Contextual LSTM Architecture,[0],[0]
"The training of the LSTM network is performed using categorical cross-entropy on each utterance’s softmax output per video, i.e.,
loss = − 1(∑Mi=1Li) M∑ i=1",3.2.3 Training,[0],[0]
Li∑ j=1 C∑ c=1,3.2.3 Training,[0],[0]
"y j i,c log2(ŷji,c),
where M = total number of videos, Li = number of utterances for ith video, yji,c = original output of class c, and ŷji,c = predicted output for jth utterance of ith video.
",3.2.3 Training,[0],[0]
"As a regularization method, dropout between the LSTM cell and dense layer is introduced to avoid overfitting.",3.2.3 Training,[0],[0]
"As the videos do not have the same number of utterances, padding is introduced to serve as neutral utterances.",3.2.3 Training,[0],[0]
"To avoid the proliferation of noise within the network, bit masking is done on these padded utterances to eliminate their effect in the network.",3.2.3 Training,[0],[0]
"Hyper-parameters tuning is done on the training set by splitting it into train and validation components with 80/20% split.
",3.2.3 Training,[0],[0]
"RMSprop has been used as the optimizer which is known to resolve Adagrad’s radically diminishing learning rates (Duchi et al., 2011).",3.2.3 Training,[0],[0]
"After feeding the training set to the network, the test set is passed through it to generate their contextdependent features.",3.2.3 Training,[0],[0]
"These features are finally passed through an SVM for the final classification.
",3.2.3 Training,[0],[0]
"Different Network Architectures We consider the following variants of the contextual LSTM architecture in our experiments.
",3.2.3 Training,[0],[0]
sc-LSTM This variant of the contextual LSTM architecture consists of unidirectional LSTM cells.,3.2.3 Training,[0],[0]
"As this is the simple variant of the contextual LSTM, we termed it as simple contextual LSTM (sc-LSTM1).
",3.2.3 Training,[0],[0]
h-LSTM We also investigate an architecture where the dense layer after the LSTM cell is omitted.,3.2.3 Training,[0],[0]
"Thus, the output of the LSTM cell hi,t provides our context-dependent features and the softmax layer provides the classification.",3.2.3 Training,[0],[0]
"We call this architecture hidden-LSTM (h-LSTM).
",3.2.3 Training,[0],[0]
bc-LSTM Bi-directional LSTMs are two unidirectional LSTMs stacked together having opposite directions.,3.2.3 Training,[0],[0]
"Thus, an utterance can get information from utterances occurring before and after itself in the video.",3.2.3 Training,[0],[0]
We replaced the regular LSTM with a bi-directional LSTM and named the resulting architecture as bi-directional contextual LSTM (bc-LSTM).,3.2.3 Training,[0],[0]
"The training process of this architecture is similar to sc-LSTM.
",3.2.3 Training,[0],[0]
"1http://github.com/senticnet/sc-lstm
uni-SVM",3.2.3 Training,[0],[0]
"In this setting, we first obtain the unimodal features as explained in Section 3.1, concatenate them and then send to an SVM for the final classification.",3.2.3 Training,[0],[0]
It should be noted that using a gated recurrent unit (GRU) instead of LSTM did not improve the performance.,3.2.3 Training,[0],[0]
"We accomplish multimodal fusion through two different frameworks, described below.",3.3 Fusion of Modalities,[0],[0]
"In this framework, we concatenate contextindependent unimodal features (from Section 3.1) and feed that into the contextual LSTM networks, i.e., sc-LSTM, bc-LSTM, and h-LSTM.",3.3.1 Non-hierarchical Framework,[0],[0]
Contextual unimodal features can further improve performance of the multimodal fusion framework explained in Section 3.3.1.,3.3.2 Hierarchical Framework,[0],[0]
"To accomplish this, we propose a hierarchical deep network which consists of two levels.
",3.3.2 Hierarchical Framework,[0],[0]
Level-1 Context-independent unimodal features (from Section 3.1) are fed to the proposed LSTM network to get context-sensitive unimodal feature representations for each utterance.,3.3.2 Hierarchical Framework,[0],[0]
"Individual LSTM networks are used for each modality.
",3.3.2 Hierarchical Framework,[0],[0]
Level-2,3.3.2 Hierarchical Framework,[0],[0]
This level consists of a contextual LSTM network similar to Level-1 but independent in training and computation.,3.3.2 Hierarchical Framework,[0],[0]
"Output from each LSTM network in Level-1 are concatenated and fed into this LSTM network, thus providing an inherent fusion scheme (see Figure 2).
",3.3.2 Hierarchical Framework,[0],[0]
"The performance of the second level banks on the quality of the features from the previous level, with better features aiding the fusion process.",3.3.2 Hierarchical Framework,[0],[0]
Algorithm 1 describes the overall computation for utterance classification.,3.3.2 Hierarchical Framework,[0],[0]
"For the hierarchical framework, we train Level-1 and Level-2 successively but separately, i.e., the training is not performed “end-to-end”.",3.3.2 Hierarchical Framework,[0],[0]
Most of the research in multimodal sentiment analysis is performed on datasets with speaker overlap in train and test splits.,4.1 Dataset details,[0],[0]
"Because each individual has a unique way of expressing emotions and sentiments, however, finding generic, personindependent features for sentiment analysis is very important.
",4.1 Dataset details,[0],[0]
"Algorithm 1 Proposed Architecture 1: procedure TRAINARCHITECTURE( U, V) 2: Train context-independent models with U 3: for i:[1,M] do ▷ extract baseline features 4: for j:[1,Li] do 5: xi,j ← TextFeatures(ui,j) 6: x ′",4.1 Dataset details,[0],[0]
"i,j ← V ideoFeatures(ui,j)
7: x”i,j ← AudioFeatures(ui,j) 8:",4.1 Dataset details,[0],[0]
"Unimodal: 9: Train LSTM at Level-1 with X,X ′ andX”.
10: for i:[1,M] do ▷ unimodal features 11: Zi ← getLSTMFeatures(Xi) 12: Z ′",4.1 Dataset details,[0],[0]
"i ← getLSTMFeatures(X ′i)
13: Z”i ← getLSTMFeatures(X”i ) 14:",4.1 Dataset details,[0],[0]
"Multimodal: 15: for i:[1,M] do 16: for j:[1,Li] do 17: if Non-hierarchical fusion then 18: x∗i,j ← (xi,j ∣∣x′i,j ∣∣x”i,j) ▷
concatenation 19: else 20: if Hierarchical fusion then 21: x∗i,j ← (zi,j ∣∣z′i,j ∣∣z”i,j) ▷
concatenation 22: Train LSTM at Level-2 with X∗. 23: for i:[1,M] do ▷ multimodal features 24: Z∗i ← getLSTMFeatures(X∗i ) 25: testArchitecture( V) 26: return Z∗ 27: procedure TESTARCHITECTURE( V) 28: Similar to training phase.",4.1 Dataset details,[0],[0]
"V is passed through the
learnt models to get the features and classification outputs.",4.1 Dataset details,[0],[0]
Table 1 shows the trainable parameters.,4.1 Dataset details,[0],[0]
"29: procedure GETLSTMFEATURES(Xi) ▷ for ith video 30: Zi ← φ 31: for t:[1,Li] do ▷ Table 1 provides notation 32: it ← σ(Wixi,t + Pi.ht−1",4.1 Dataset details,[0],[0]
"+ bi) 33: C̃t ← tanh(Wcxi,t + Pcht−1 + bc) 34: ft ← σ(Wfxt",4.1 Dataset details,[0],[0]
+,4.1 Dataset details,[0],[0]
Pfht−1 + bf) 35:,4.1 Dataset details,[0],[0]
Ct ← it ∗ C̃t + ft ∗Ct−1 36: ot ← σ(Woxt + Poht−1,4.1 Dataset details,[0],[0]
+ VoCt + bo) 37: ht ← ot ∗ tanh(Ct),4.1 Dataset details,[0],[0]
"▷ output of lstm cell 38: zt ← ReLU(Wzht + bz) ▷ dense layer 39: prediction← softmax(Wsftzt + bsft) 40: Zi ← Zi ∪ zt 41: return Zi
In real-world applications, the model should be robust to person idiosyncrasy",4.1 Dataset details,[0],[0]
but it is very difficult to come up with a generalized model from the behavior of a limited number of individuals.,4.1 Dataset details,[0],[0]
"To this end, we perform person-independent experiments to study generalization of our model, i.e., our train/test splits of the datasets are completely disjoint with respect to speakers.
",4.1 Dataset details,[0],[0]
"Multimodal Sentiment Analysis Datasets
MOSI The MOSI dataset (Zadeh et al., 2016) is a dataset rich in sentimental expressions where 93 people review topics in English.",4.1 Dataset details,[0],[0]
"The videos
are segmented with each segments sentiment label scored between +3 (strong positive) to -3 (strong negative) by 5 annotators.",4.1 Dataset details,[0],[0]
"We took the average of these five annotations as the sentiment polarity and, hence, considered only two classes (positive and negative).",4.1 Dataset details,[0],[0]
The train/validation set consists of the first 62 individuals in the dataset.,4.1 Dataset details,[0],[0]
The test set contains opinionated videos by rest 31 speakers.,4.1 Dataset details,[0],[0]
"In particular, 1447 and 752 utterances are used in training and test, respectively.
MOUD",4.1 Dataset details,[0],[0]
"This dataset (Pérez-Rosas et al., 2013) contains product review videos provided by 55 persons.",4.1 Dataset details,[0],[0]
The reviews are in Spanish (we used Google Translate API2 to get the English transcripts).,4.1 Dataset details,[0],[0]
"The utterances are labeled to be either positive, negative or neutral.",4.1 Dataset details,[0],[0]
"However, we drop the neutral label to maintain consistency with previous work.",4.1 Dataset details,[0],[0]
"Out of 79 videos in the dataset, 59 videos are considered in the train/val set.
",4.1 Dataset details,[0],[0]
"Multimodal Emotion Recognition Datasets
IEMOCAP The IEMOCAP (Busso et al., 2008) contains the acts of 10 speakers in a twoway conversation segmented into utterances.",4.1 Dataset details,[0],[0]
The medium of the conversations in all the videos is English.,4.1 Dataset details,[0],[0]
"The database contains the following categorical labels: anger, happiness, sadness, neutral, excitement, frustration, fear, surprise, and other, but we take only the first four so as to compare with the state of the art (Rozgic et al., 2012).",4.1 Dataset details,[0],[0]
Videos by the first 8 speakers are considered in the training set.,4.1 Dataset details,[0],[0]
"The train/test split details are provided in Table 2, which provides information regarding train/test split of all the datasets.",4.1 Dataset details,[0],[0]
"Table 2 also provides cross-dataset split details where the datasets MOSI and MOUD are used for training and testing, respectively.",4.1 Dataset details,[0],[0]
The proposed model being used on reviews from different languages allows us to analyze its robustness and generalizability.,4.1 Dataset details,[0],[0]
"In order to evaluate the robustness of our proposed method, we employ it on multiple datasets of different kinds.",4.1.1 Characteristic of the Datasets,[0],[0]
"Both MOSI and MOUD are used for the sentiment classification task but they consist of review videos spoken in different languages, i.e., English and Spanish, respectively.
",4.1.1 Characteristic of the Datasets,[0],[0]
"2http://translate.google.com
IEMOCAP dataset is different from MOSI and MOUD since it is annotated with emotion labels.",4.1.1 Characteristic of the Datasets,[0],[0]
"Apart from this, IEMOCAP dataset was created using a different method than MOSI and MOUD.",4.1.1 Characteristic of the Datasets,[0],[0]
These two datasets were developed by crawling consumers’ spontaneous online product review videos from popular social websites and later labeled with sentiment labels.,4.1.1 Characteristic of the Datasets,[0],[0]
"To curate the IEMOCAP dataset, instead, subjects were provided affect-related scripts and asked to act.
",4.1.1 Characteristic of the Datasets,[0],[0]
"As pointed out by Poria et al. (Poria et al., 2017a), acted dataset like IEMOCAP can suffer from biased labeling and incorrect acting which can further cause the poor generalizability of the models trained on the acted datasets.
",4.1.1 Characteristic of the Datasets,[0],[0]
"It should be noted that the datasets’ individual configuration and splits are same throughout all the experiments (i.e., context-independent unimodal feature extraction, LSTM-based contextdependent unimodal and multimodal feature extraction and classification).",4.1.1 Characteristic of the Datasets,[0],[0]
"In this section, we present unimodal and multimodal sentiment analysis performance of different LSTM network variants as explained in Section 3.2.3 and comparison with the state of the art.
",4.2 Performance of Different Models,[0],[0]
"Hierarchical vs Non-hierarchical Fusion Framework As expected, trained contextual unimodal features help the hierarchical fusion framework to outperform the non-hierarchical framework.",4.2 Performance of Different Models,[0],[0]
"Table 3 demonstrates this by comparing the hierarchical and the non-hierarchical frameworks using the bc-LSTM network.
",4.2 Performance of Different Models,[0],[0]
"For this reason, we the rest of the analysis only leverages on the hierarchical framework.",4.2 Performance of Different Models,[0],[0]
"The non-hierarchical model outperforms the baseline uni-SVM, which confirms that it is the contextsensitive learning paradigm that plays the key role in improving performance over the baseline.
",4.2 Performance of Different Models,[0],[0]
Comparison of Different Network Variants It is to be noted that both sc-LSTM and bc-LSTM perform quite well on the multimodal emotion recognition and sentiment analysis datasets.,4.2 Performance of Different Models,[0],[0]
"Since bc-LSTM has access to both the preceding and following information of the utterance sequence, it performs consistently better on all the datasets over sc-LSTM.",4.2 Performance of Different Models,[0],[0]
The usefulness of the dense layer in increasing the performance is evident from the experimental results shown in Table 3.,4.2 Performance of Different Models,[0],[0]
The performance improvement is in the range of 0.3% to 1.5% on MOSI and MOUD datasets.,4.2 Performance of Different Models,[0],[0]
"On the IEMOCAP dataset, the performance improvement of bc-LSTM and sc-LSTM over h-LSTM is in the range of 1% to 5%.
",4.2 Performance of Different Models,[0],[0]
Comparison with the Baselines Every LSTM network variant has outperformed the baseline uni-SVM on all the datasets by the margin of 2% to 5% (see Table 3).,4.2 Performance of Different Models,[0],[0]
These results prove our initial hypothesis that modeling the contextual dependencies among utterances (which uniSVM cannot do) improves the classification.,4.2 Performance of Different Models,[0],[0]
"The higher performance improvement on the IEMOCAP dataset indicates the necessity of modeling long-range dependencies among the utterances as continuous emotion recognition is a multiclass sequential problem where a person does not frequently change emotions (Wöllmer et al., 2008).",4.2 Performance of Different Models,[0],[0]
"We have implemented and compared with the current state-of-the-art approach proposed by (Poria et al., 2015).",4.2 Performance of Different Models,[0],[0]
"In their method, they extracted features from each modality and fed these to a MKL classifier.",4.2 Performance of Different Models,[0],[0]
"However, they did not conduct the experiment in a speaker-independent manner and also did not consider the contextual relation among the utterances.",4.2 Performance of Different Models,[0],[0]
"In Table 3, the results in bold are statistically significant (p < 0.05) in compare to uni-SVM.",4.2 Performance of Different Models,[0],[0]
"Experimental results in Table 4 show that the proposed method outperformes (Poria et al., 2015) by a significant margin.",4.2 Performance of Different Models,[0],[0]
"For the emotion recognition task, we have compared our method with the current state of the art (Rozgic et al., 2012), who extracted features in a similar fashion to (Poria et al., 2015) (although they used SVM trees (Yuan et al., 2006) for the fusion).",4.2 Performance of Different Models,[0],[0]
"As expected, in all kinds of experiments, bimodal and trimodal models have outperformed unimodal models.",4.3 Importance of the Modalities,[0],[0]
"Overall, audio modality has performed better than visual on all the datasets.
",4.3 Importance of the Modalities,[0],[0]
"On MOSI and IEMOCAP datasets, the textual classifier achieves the best performance over other unimodal classifiers.",4.3 Importance of the Modalities,[0],[0]
"On IEMOCAP dataset, the unimodal and multimodal classifiers obtained poor performance to classify neutral utterances.",4.3 Importance of the Modalities,[0],[0]
"The textual modality, combined with non-textual modes, boosts the performance in IEMOCAP by a large margin.",4.3 Importance of the Modalities,[0],[0]
"However, the margin is less in the other datasets.
",4.3 Importance of the Modalities,[0],[0]
"On the MOUD dataset, the textual modality performs worse than audio modality due to the noise introduced in translating Spanish utterances to English.",4.3 Importance of the Modalities,[0],[0]
Using Spanish word vectors3 in text-CNN results in an improvement of 10%.,4.3 Importance of the Modalities,[0],[0]
"Nonetheless, we report results using these translated utterances as opposed to utterances trained on Spanish word vectors, in order to make fair comparison with (Poria et al., 2015).",4.3 Importance of the Modalities,[0],[0]
"To test the generalizability of the models, we have trained our framework on complete MOSI dataset and tested on MOUD dataset (Table 5).",4.4 Generalization of the Models,[0],[0]
"The performance was poor for audio and textual modality as the MOUD dataset is in Spanish while the model is trained on MOSI dataset, which is in English language.",4.4 Generalization of the Models,[0],[0]
"However, notably the visual modality performs better than the other two modalities in this experiment, which means that in cross-lingual scenarios facial expressions carry more generalized, robust information than audio and textual modalities.",4.4 Generalization of the Models,[0],[0]
We could not carry out a similar experiment for emotion recognition as no other utterance-level dataset apart from the IEMOCAP was available at the time of our experiments.,4.4 Generalization of the Models,[0],[0]
The need for considering context dependency (see Section 1) is of prime importance for utterancelevel sentiment classification.,4.5 Qualitative Analysis,[0],[0]
"For example, in the utterance “What would have been a better name for the movie”, the speaker is attempting to comment the quality of the movie by giving an appropriate name.",4.5 Qualitative Analysis,[0],[0]
"However, the sentiment is expressed implicitly and requires the contextual knowledge about the mood of the speaker and his/her general opinion about the film.",4.5 Qualitative Analysis,[0],[0]
"The baseline unimodalSVM and state of the art fail to classify this utterance correctly4.
",4.5 Qualitative Analysis,[0],[0]
3http://crscardellino.me/SBWCE 4RNTN classifies it as neutral.,4.5 Qualitative Analysis,[0],[0]
"It can be seen here
http://nlp.stanford.edu:8080/sentiment/rntnDemo.html
However, information from neighboring utterances, e.g., “And I really enjoyed it” and “The countryside which they showed while going through Ireland was astoundingly beautiful” indicate its positive context and help our contextual model to classify the target utterance correctly.",4.5 Qualitative Analysis,[0],[0]
"Such contextual relationships are prevalent throughout the dataset.
",4.5 Qualitative Analysis,[0],[0]
"In order to have a better understanding of the roles of each modality for the overall classification, we have also done some qualitative analysis.",4.5 Qualitative Analysis,[0],[0]
"For example, the utterance “who doesn’t have
any presence or greatness at all” was classified as positive by the audio classifier (as “presence and greatness at all” was spoken with enthusiasm).",4.5 Qualitative Analysis,[0],[0]
"However, the textual modality caught the negation induced by “doesn’t” and classified it correctly.",4.5 Qualitative Analysis,[0],[0]
"The same happened to the utterance “amazing special effects”, which presented no jest of enthusiasm in the speaker’s voice nor face, but was correctly classified by the textual classifier.
",4.5 Qualitative Analysis,[0],[0]
"On other hand, the textual classifier classified the utterance “that like to see comic book characters treated responsibly” as positive (for the presence of “like to see” and “responsibly”) but the high pitch of anger in the person’s voice and the frowning face helps to identify this as a negative utterance.",4.5 Qualitative Analysis,[0],[0]
"In some cases, the predictions of the proposed method are wrong because of face occlusion or noisy audio.",4.5 Qualitative Analysis,[0],[0]
"Also, in cases where sentiment is very weak and non contextual, the proposed approach shows some bias towards its surrounding utterances, which further leads to wrong predictions.",4.5 Qualitative Analysis,[0],[0]
The contextual relationship among utterances in a video is mostly ignored in the literature.,5 Conclusion,[0],[0]
"In this paper, we developed a LSTM-based network to extract contextual features from the utterances of a video for multimodal sentiment analysis.",5 Conclusion,[0],[0]
"The proposed method has outperformed the state of the art and showed significant performance improvement over the baseline.
",5 Conclusion,[0],[0]
"As future work, we plan to develop a LSTMbased attention model to determine the importance of each utterance and its specific contribution to each modality for sentiment classification.",5 Conclusion,[0],[0]
"Multimodal sentiment analysis is a developing area of research, which involves the identification of sentiments in videos.",abstractText,[0],[0]
"Current research considers utterances as independent entities, i.e., ignores the interdependencies and relations among the utterances of a video.",abstractText,[0],[0]
"In this paper, we propose a LSTM-based model that enables utterances to capture contextual information from their surroundings in the same video, thus aiding the classification process.",abstractText,[0],[0]
Our method shows 5-10% performance improvement over the state of the art and high robustness to generalizability.,abstractText,[0],[0]
Context-Dependent Sentiment Analysis in User-Generated Videos,title,[0],[0]
"In this paper, we study reinforcement learning (RL) problems where the agent receives rich sensory observations from the environment, forms complex contexts from sensorimotor streams, uses function approximation to generalize to unseen contexts, and must perform systematic exploration to learn efficiently.",1. Introduction,[0],[0]
"Such problems are at the core of empirical RL research (e.g., Mnih et al., 2015; Bellemare et al., 2016), yet no existing theory provides rigorous and satisfactory guarantees in a general setting.",1. Introduction,[0],[0]
"This situation motivates an important question: how can we solve RL problems where exploration is critical and the agent receives rich observations, in a sample-efficient manner?
",1. Introduction,[0],[0]
"To answer the question, we propose a new formulation, Contextual Decision Processes (CDPs), to capture a large class of sequential decision-making problems: CDPs gen-
1University of Michigan, Ann Arbor 2University of Massachusetts, Amherst 3Microsoft Research, New York.",1. Introduction,[0],[0]
"Correspondence to: Nan Jiang <nanjiang@umich.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
eralize MDPs where the state forms the context (Ex. 1) and POMDPs where the history forms the context (Ex. 2), and can be much more concise than alternative formulations based on sufficient statistics (e.g., Hutter, 2005).",1. Introduction,[0],[0]
"We define CDPs in Section 2, and the learning goal is to find a nearoptimal policy for a CDP with the help of a value-function approximator in a sample-efficient manner.1
A structural assumption: When the context space is very large or infinite, as is common in practice, lower bounds that are exponential in the problem horizon preclude efficient learning in CDPs, even when simple function approximators are used.",1. Introduction,[0],[0]
"However, RL problems arising in applications are often far more benign than the pathological lower bound instances, and we identify a structural assumption capturing this intuition.",1. Introduction,[0],[0]
"As our first major contribution, we define a notion of Bellman factorization (Definition 5) in Section 3, and focus on problems with low Bellman rank.
",1. Introduction,[0],[0]
"At a high level, Bellman rank is an algebraic dimension capturing the interplay between the CDP and the valuefunction approximator that we show is small for many previously-studied settings.",1. Introduction,[0],[0]
"For example, every MDP with a tabular value-function has Bellman rank bounded by the rank of its transition matrix, which is at most the number of states but can be considerably smaller.",1. Introduction,[0],[0]
"For a POMDP with reactive value-functions, the Bellman rank is at most the number of hidden states and has no dependence on the observation space.",1. Introduction,[0],[0]
We provide other instances of low Bellman rank including Linear Quadratic Regulators and Predictive State Representations.,1. Introduction,[0],[0]
"Overall, CDPs with a small Bellman rank yield a unified framework for a large class of sequential decision making problems.
",1. Introduction,[0],[0]
A new algorithm:,1. Introduction,[0],[0]
"Our second contribution is a new algorithm for episodic RL called OLIVE (Optimism Led Iterative Value-function Elimination), detailed in Section 4.1.",1. Introduction,[0],[0]
OLIVE iteratively refines a space of candidate Q-value functions F .,1. Introduction,[0],[0]
"At each iteration, it chooses a value function f using an optimistic criterion and collects trajectories from the corresponding greedy policy πf .",1. Introduction,[0],[0]
"If πf attains a high-value, the algorithm terminates and outputs f .",1. Introduction,[0],[0]
"Other-
1Throughout the paper, by sample-efficient we mean a number of trajectories that is polynomial in the problem horizon, number of actions, Bellman rank (to be introduced), and polylogarithmic in the number of candidate value-functions.
",1. Introduction,[0],[0]
"wise, it eliminates all g ∈ F which violate certain Bellman equations under trajectories generated by πf and performs the next iteration with this refined class of functions.
",1. Introduction,[0],[0]
A PAC guarantee: We prove that OLIVE performs sample-efficient learning in CDPs with a small Bellman rank (Section 4.2).,1. Introduction,[0],[0]
"Concretely, when the Q?function for the CDP is contained in F , OLIVE requires Õ(M2H3K log(N/δ)/ 2) trajectories to find an - suboptimal policy,2 where M is the Bellman rank, H is the length of a trajectory, K is the number of actions, N is the cardinality of F , and δ is the failure probability.
",1. Introduction,[0],[0]
"Importantly, the sample complexity bound has a logarithmic dependence on N , enabling powerful function approximation, and no direct dependence on the size of the context space, which can be very large or infinite.",1. Introduction,[0],[0]
"As many existing models, including the ones highlighted in Table 1, have low Bellman rank, the result immediately implies sampleefficient learning in all of these settings.3
The main PAC-guarantee can be extended in several ways, discussed in Appendix A. Specifically, OLIVE is robust to the failure of our assumptions, can adapt to unknown Bellman rank, and can handle infinite function classes with bounded statistical complexity.",1. Introduction,[0],[0]
"These extensions demonstrate that the Bellman rank robustly captures the difficulty of exploration in sequential-decision making problems.
",1. Introduction,[0],[0]
"To summarize, this work advances our understanding of RL with complex observations where long-term planning and exploration are critical.",1. Introduction,[0],[0]
"While OLIVE represents an exponential advance in statistical efficiency, its computational complexity, which is polynomial in N , is intractable for the powerful function classes of interest.",1. Introduction,[0],[0]
This computational issue must be addressed before we can empirically evaluate the effectiveness of the proposed algorithm.,1. Introduction,[0],[0]
"We discuss this and other future directions in Section 6.
",1. Introduction,[0],[0]
Related work.,1. Introduction,[0],[0]
"There is rich theoretical literature on RL in tabular settings, including MDPs (Kearns & Singh, 2002; Brafman & Tennenholtz, 2003; Strehl et al., 2006) and POMDPs (Azizzadenesheli et al., 2016) with small state
2A logarithmic dependence on a norm parameter ζ is omitted here, as ζ is polynomial in most cases.
",1. Introduction,[0],[0]
"3Our algorithm requires discrete action spaces and does not immediately apply to LQRs; see more discussion in Section 3.
and observation spaces, with an emphasis on sophisticated exploration to find near-optimal policies in a sampleefficient manner.",1. Introduction,[0],[0]
"While there have been extensions to large state spaces (Kakade et al., 2003; Jong & Stone, 2007; Pazis & Parr, 2016), these approaches fail to be a good fit for practical scenarios where the environment is typically perceived through complex observations such as image, text, or audio signals.",1. Introduction,[0],[0]
"Alternatively, Monte Carlo Tree Search (MCTS) methods can handle large state spaces, but only at the cost of exponential dependence on the planning horizon (Kearns et al., 2002; Kocsis & Szepesvári, 2006).
",1. Introduction,[0],[0]
"Closest to our work are the results of Wen & Van Roy (2013) and Krishnamurthy et al. (2016), which also obtain sample complexity independent of the number of unique contexts, but only under deterministic dynamics and other special structures.",1. Introduction,[0],[0]
"In contrast, we study a much broader class of problems with relatively mild conditions.
",1. Introduction,[0],[0]
"On the empirical side, recent successes on both the Atari platform (Mnih et al., 2015; Wang et al., 2015) and Go (Silver et al., 2016) have sparked a flurry of research interest.",1. Introduction,[0],[0]
"These approaches leverage advances in deep learning for powerful function approximation, but typically use simple strategies, such as -greedy, for exploration.",1. Introduction,[0],[0]
"Better exploration strategies, such as pseudo-counts in Bellemare et al. (2016), and combining MCTS with function approximation (e.g., Silver et al. (2016)), typically require strong domain knowledge and large amounts of data to be successful.
",1. Introduction,[0],[0]
"Hallak et al. (2015) have proposed Contextual MDPs, where each context parametrizes an MDP.",1. Introduction,[0],[0]
"In contrast, our use of contexts is in analogy with contextual bandits (Langford & Zhang, 2008), and is similar to state features in RL.",1. Introduction,[0],[0]
"In this section, we introduce a new model, called a Contextual Decision Process, as a unified framework for reinforcement learning with rich observations.",2. Contextual Decision Processes (CDPs),[0],[0]
"CDPs make minimal assumptions to capture a general class of RL problems and are defined as follows.
",2.1. Model and Examples,[0],[0]
Definition 1 (Contextual Decision Process (CDP)).,2.1. Model and Examples,[0],[0]
"A
(finite-horizon) CDP is defined as a tuple (X ,A, H, P ), where X is the context space, A is the action space, and H is the horizon of the problem.",2.1. Model and Examples,[0],[0]
P =,2.1. Model and Examples,[0],[0]
"(P∅, P+) is the system descriptor, where P∅ ∈ ∆(X ) is a distribution over initial contexts, that is x1 ∼ P∅, and P+",2.1. Model and Examples,[0],[0]
": (X × A × R)∗ × X × A → ∆(R × X ) elicits the next reward and context from the interactions so far x1, a1, r1, . .",2.1. Model and Examples,[0],[0]
.,2.1. Model and Examples,[0],[0]
", xh, ah:
(rh, xh+1)",2.1. Model and Examples,[0],[0]
"∼ P+(x1, a1, r1, . .",2.1. Model and Examples,[0],[0]
.,2.1. Model and Examples,[0],[0]
", xh, ah).
",2.1. Model and Examples,[0],[0]
"In a CDP, the agent interacts with the environment in episodes.",2.1. Model and Examples,[0],[0]
"In an episode, the agent observes a context x1, takes action a1, receives reward r1 and observes x2, repeating H times.",2.1. Model and Examples,[0],[0]
"A policy π : X → A specifies the agent’s decision-making strategy, i.e. ah = π(xh), ∀h ∈",2.1. Model and Examples,[0],[0]
"[H],",2.1. Model and Examples,[0],[0]
"and induces a distribution over trajectories (x1, a1, r1, . .",2.1. Model and Examples,[0],[0]
.,2.1. Model and Examples,[0],[0]
", xH , aH , rH , xH+1) via the system descriptor P .",2.1. Model and Examples,[0],[0]
"The value of a policy, V π , is defined as
V π = EP",2.1. Model and Examples,[0],[0]
[∑H h=1 rH ∣∣∣,2.1. Model and Examples,[0],[0]
"a1:H ∼ π] , (1) where a1:H ∼ π abbreviates for a1 = π(x1), . . .",2.1. Model and Examples,[0],[0]
", aH = π(xH).",2.1. Model and Examples,[0],[0]
"Throughout, the expectation is always taken over contexts and rewards drawn according to the system descriptor P , so we suppress the subscript P .",2.1. Model and Examples,[0],[0]
"The goal of the agent is to find a policy π that attains the largest value.
",2.1. Model and Examples,[0],[0]
"CDPs capture classical RL models, like MDPs and POMDPs, with appropriately chosen contexts:
Example 1 (MDPs with states as contexts).",2.1. Model and Examples,[0],[0]
"Consider a finite-horizon MDP (S,A, H,Γ1,Γ, R), where S is the state space, A is the action space, H is the horizon, Γ1 ∈ ∆(S) is the initial state distribution, Γ : S × A → ∆(S) is the state transition function, R : S ×",2.1. Model and Examples,[0],[0]
"A → ∆([0, 1]) is the reward function, and an episode takes the form of (s1, a1, r1, . . .",2.1. Model and Examples,[0],[0]
", sH",2.1. Model and Examples,[0],[0]
", aH , rH).",2.1. Model and Examples,[0],[0]
"We can convert the MDP to a CDP (X ,A, H, P ) by letting X = S ×",2.1. Model and Examples,[0],[0]
"[H] and xh = (sh, h), which allows the set of policies {X → A} to contain the optimal policy (Puterman, 1994).",2.1. Model and Examples,[0],[0]
"The system descriptor is P = (P∅, P+), where P∅(x1) = Γ1(s1), and P+(rh, xh+1 |x1, a1, r1, . . .",2.1. Model and Examples,[0],[0]
", xh, ah) = R(rh|sh, ah) Γ(sh+1|sh, ah).
",2.1. Model and Examples,[0],[0]
"As above, the system descriptor for a model is usually obvious and we omit its specification in the following examples.",2.1. Model and Examples,[0],[0]
"Turning to POMDPs, it might seem that a CDP limits the agent’s decision-making strategies to memoryless (or reactive) policies, as we only consider policies in {X → A}.",2.1. Model and Examples,[0],[0]
This is not true.,2.1. Model and Examples,[0],[0]
"We clarify this issue by showing that we can use the history as context, and the induced CDP suffers no loss in the ability to represent optimal policies.
",2.1. Model and Examples,[0],[0]
Example 2 (POMDPs with histories as contexts).,2.1. Model and Examples,[0],[0]
"Consider a finite-horizon POMDP with a hidden state space S, an observation spaceO, and an emission processDs specifying a distribution overO. We can convert the POMDP to
a CDP (X ,A, H, P ) by lettingX = (O×A×R)∗×O and xh = (o1, a1, r1, . . .",2.1. Model and Examples,[0],[0]
", oh) is the observed history at level h.
Our next example considers a POMDP where the context can be substantially more concise than the full history.",2.1. Model and Examples,[0],[0]
"As will be formalized in Section 2.2, all we need is that the context can express a good value function, which is significantly weaker than requiring it be a sufficient statistic (unlike e.g., Hutter 2005).",2.1. Model and Examples,[0],[0]
"Therefore, it is important to separate the context in a CDP from any precise notion of state in the process, and instead keep it as a modeling choice.
",2.1. Model and Examples,[0],[0]
Example 3 (POMDPs with sliding windows of observations as contexts).,2.1. Model and Examples,[0],[0]
"Sometimes partial observability can be resolved by using a small history: for example, in Atari games, it is common to keep track of the last 4 images (Mnih et al., 2015).",2.1. Model and Examples,[0],[0]
"In this case, we can represent the problem as a CDP by letting xh = (oh−3, oh−2, oh−1, oh).
",2.1. Model and Examples,[0],[0]
We hope the above examples demonstrate the generality and flexibility of the CDP framework.,2.1. Model and Examples,[0],[0]
"Finally, we introduce a regularity assumption on the rewards.
",2.1. Model and Examples,[0],[0]
Assumption 1 (Boundedness of rewards).,2.1. Model and Examples,[0],[0]
"We assume that regardless of how actions are chosen, for any h = 1, . . .",2.1. Model and Examples,[0],[0]
",H , rh ≥ 0 and ∑H h=1",2.1. Model and Examples,[0],[0]
rh ≤ 1 almost surely.4,2.1. Model and Examples,[0],[0]
"A CDP makes no assumptions on the cardinality of the context space, which makes it critical to generalize across contexts, since an agent might not observe the same context twice.",2.2. Value-based RL and Function Approximation,[0],[0]
"Hence, we consider value-based RL with function approximation.",2.2. Value-based RL and Function Approximation,[0],[0]
"That is, the agent is given a set of functions F ⊆ X ×",2.2. Value-based RL and Function Approximation,[0],[0]
A,2.2. Value-based RL and Function Approximation,[0],[0]
"→ [0, 1] and uses it to approximate an action-value function (or Q-function).",2.2. Value-based RL and Function Approximation,[0],[0]
"To avoid imposing boundary-conditions, we set f(xH+1) ≡ 0 w.l.o.g.",2.2. Value-based RL and Function Approximation,[0],[0]
"For ease of presentation, we assume that F is finite with |F| =",2.2. Value-based RL and Function Approximation,[0],[0]
N < ∞ throughout the paper.,2.2. Value-based RL and Function Approximation,[0],[0]
"In Appendix A.3 we allow infinite function classes with bounded complexity.
",2.2. Value-based RL and Function Approximation,[0],[0]
"As in typical value-based RL, the goal is to identify f ∈ F which respects a particular set of Bellman equations and achieves a high value with its greedy policy",2.2. Value-based RL and Function Approximation,[0],[0]
"πf (x) = argmaxa∈A f(x, a).",2.2. Value-based RL and Function Approximation,[0],[0]
We next set up the appropriate extensions of Bellman equations to CDPs and the optimal value V ?F through a series of definitions.,2.2. Value-based RL and Function Approximation,[0],[0]
"Unlike MDPs, these involve both the CDP and function approximator F .",2.2. Value-based RL and Function Approximation,[0],[0]
Definition 2 (Average Bellman error).,2.2. Value-based RL and Function Approximation,[0],[0]
"Given a policy π : X → A and a function f : X × A → [0, 1], the average Bellman error of f under π at level h is defined as
E(f, π, h) =",2.2. Value-based RL and Function Approximation,[0],[0]
"E [ f(xh,ah)− rh − f(xh+1, ah+1)∣∣ a1:h−1 ∼ π, ah:h+1 ∼",2.2. Value-based RL and Function Approximation,[0],[0]
πf ].,2.2. Value-based RL and Function Approximation,[0],[0]
"(2)
4The bound of 1 is w.l.o.g.",2.2. Value-based RL and Function Approximation,[0],[0]
"More generally, we may simply replace with /R in all the sample complexity results when the bound isR.",2.2. Value-based RL and Function Approximation,[0],[0]
"See more discussion in Kakade (2003, Section 2.2.3).
",2.2. Value-based RL and Function Approximation,[0],[0]
"The average Bellman error measures the self-consistency of f between its predictions at levels h and h+ 1, when all the previous actions are taken according to some policy π.",2.2. Value-based RL and Function Approximation,[0],[0]
"We now define a set of Bellman equations.
",2.2. Value-based RL and Function Approximation,[0],[0]
Definition 3 (Bellman equations and validity of f ).,2.2. Value-based RL and Function Approximation,[0],[0]
"Given an (f, π, h) triple, a Bellman equation posits E(f, π, h) = 0.",2.2. Value-based RL and Function Approximation,[0],[0]
"We say f ∈ F is valid if the Bellman equation on (f, πf ′ , h) holds for every f ′ ∈ F , h ∈",2.2. Value-based RL and Function Approximation,[0],[0]
"[H].
Note that the validity assumption only considers roll-ins according to the greedy policies πf , which is the natural policy class given F .",2.2. Value-based RL and Function Approximation,[0],[0]
"In MDPs, each Bellman equation can be viewed as the linear combination of the standard Bellman optimality equations for Q?,5 where the coefficients are the probabilities with which the roll-in policy π visits each state.",2.2. Value-based RL and Function Approximation,[0],[0]
"This leads to the following consequence.
",2.2. Value-based RL and Function Approximation,[0],[0]
Fact 1 (Q? is always valid).,2.2. Value-based RL and Function Approximation,[0],[0]
Given an MDP and a space of functions F : S ×,2.2. Value-based RL and Function Approximation,[0],[0]
"[H]×A → [0, 1], if Q? ∈ F , then in the corresponding CDP with X = S ×",2.2. Value-based RL and Function Approximation,[0],[0]
"[H], Q? is valid.
",2.2. Value-based RL and Function Approximation,[0],[0]
"While Q? satisfies the Bellman equations and yields the optimal policy π? = πQ? , there can be other functions which also satisfy the equations while yielding suboptimal policies.",2.2. Value-based RL and Function Approximation,[0],[0]
"For instance, if f(x, πf (x)) correctly predicts the long-term reward of πf , then f is always valid.",2.2. Value-based RL and Function Approximation,[0],[0]
"Since validity alone does not imply that we get a good policy, it is natural to search for a valid value function which also induces a high-value policy.",2.2. Value-based RL and Function Approximation,[0],[0]
"We formalize this goal next.
",2.2. Value-based RL and Function Approximation,[0],[0]
Definition 4 (Optimal value).,2.2. Value-based RL and Function Approximation,[0],[0]
"Define
f? = argmax f∈F : f is valid V πf , and V ?F = V πf? .
",2.2. Value-based RL and Function Approximation,[0],[0]
Fact 2.,2.2. Value-based RL and Function Approximation,[0],[0]
"In the setting of Fact 1, we have f? = Q? ∈ F , and V ?F = V ?, which is the optimal long-term value.
",2.2. Value-based RL and Function Approximation,[0],[0]
Definition 4 implicitly assumes that there is at least one valid f ∈ F .,2.2. Value-based RL and Function Approximation,[0],[0]
"This is weaker than the realizability assumption made in the value-based RL literature, that F contains Q? of an MDP (e.g., Krishnamurthy et al., 2016) (see Facts 1 and 2).",2.2. Value-based RL and Function Approximation,[0],[0]
"While some works only require Q? to be approximately captured (e.g., Antos et al., 2008), our algorithm can also be adapted to work with an approximate notion of validity as discussed in Appendix A.4.",2.2. Value-based RL and Function Approximation,[0],[0]
"CDPs are general models for sequential decision making, but are there efficient RL algorithms for them?
",3. Bellman Factorization and Bellman Rank,[0],[0]
"Unfortunately, without further assumptions, learning in CDPs is generally hard, since they subsume MDPs and
5We refer the readers who are not familiar with the definition of Q? to standard texts, such as (Sutton & Barto, 1998).
",3. Bellman Factorization and Bellman Rank,[0],[0]
POMDPs with arbitrarily large state/observation spaces.,3. Bellman Factorization and Bellman Rank,[0],[0]
"Formally, the sample complexity of learning CDPs in the worst-case is Ω(KH) when K = |A|, even when the complexity of the function class, measured by log |F|, is small.",3. Bellman Factorization and Bellman Rank,[0],[0]
"The result is due to Krishnamurthy et al. (2016) and is included in Appendix F.1 for completeness.
",3. Bellman Factorization and Bellman Rank,[0],[0]
Of course the lower bound instances are quite pathological and devoid of any structure that is often present in real problems.,3. Bellman Factorization and Bellman Rank,[0],[0]
"To capture these realistic scenarios, we propose a new complexity measure and restrict our attention to settings where this measure is low.",3. Bellman Factorization and Bellman Rank,[0],[0]
"As we will see, this measure is naturally small for many existing models, and, when it is small, efficient reinforcement learning is possible.
",3. Bellman Factorization and Bellman Rank,[0],[0]
"The complexity measure we propose is a structural characterization of the set of Bellman equations induced by the CDP and the class F (recall Definitions 2 and 3), that we need to check to find valid functions.",3. Bellman Factorization and Bellman Rank,[0],[0]
"Checking validity by enumeration is statistically intractable for large F , since it requires Ω(|F|) samples to perform all roll-ins.",3. Bellman Factorization and Bellman Rank,[0],[0]
"However, observe that the Bellman equations are structured in tabular MDPs: the average Bellman error under any roll-in policy is a stochastic combination of the single-state errors, and checking the single-state errors (which is tractable) is sufficient to guarantee validity.",3. Bellman Factorization and Bellman Rank,[0],[0]
"This observation hints toward a more general phenomenon: whenever the collection of Bellman errors across all roll-in policies can be concisely represented, we may be able to check the validity of all functions in a tractable way.
",3. Bellman Factorization and Bellman Rank,[0],[0]
This intuition motivates a new complexity measure that we call the Bellman rank.,3. Bellman Factorization and Bellman Rank,[0],[0]
"Define the Bellman error matrices, one for each h, to be |F|× |F|",3. Bellman Factorization and Bellman Rank,[0],[0]
"matrices where the (f, f ′)th entry is the Bellman error E(f, πf ′ , h).",3. Bellman Factorization and Bellman Rank,[0],[0]
"Informally, the Bellman rank for a CDP and a given value-function class F is a uniform upper bound on the rank of these H Bellman error matrices.
",3. Bellman Factorization and Bellman Rank,[0],[0]
Definition 5 (Bellman factorization and Bellman rank).,3. Bellman Factorization and Bellman Rank,[0],[0]
"We say that a CDP (X ,A, H, P ) and F ⊂ X ×A → [0, 1] admit Bellman factorization with Bellman rank M and norm parameter ζ, if there exists νh : F → RM , ξh : F → RM for each h ∈",3. Bellman Factorization and Bellman Rank,[0],[0]
"[H], such that for any f, f ′ ∈ F , h ∈",3. Bellman Factorization and Bellman Rank,[0],[0]
"[H],
E(f, πf ′ , h) = 〈νh(f ′), ξh(f)〉, (3)
and ‖νh(f ′)‖2 · ‖ξh(f)‖2 ≤ ζ <∞.
The exact factorization in Eq.",3. Bellman Factorization and Bellman Rank,[0],[0]
(3) can be relaxed to an approximate version as is discussed in Appendix A.4.,3. Bellman Factorization and Bellman Rank,[0],[0]
"Unlike rank-based notions in PSRs (Littman et al., 2001) and multiplicity automata (Schützenberger, 1961), Bellman rank depends both on the process and the class F .",3. Bellman Factorization and Bellman Rank,[0],[0]
In the remainder of this section we showcase the generality of Definition 5 by describing a number of common RL settings that have a small Bellman rank.,3. Bellman Factorization and Bellman Rank,[0],[0]
"Throughout, we see how
the Bellman rank captures the process-specific structures that allow for efficient exploration.",3. Bellman Factorization and Bellman Rank,[0],[0]
"Proofs of all claims in this section are deferred to Appendix B.
We start with the tabular MDP setting, and show that the Bellman rank is at most the number of states.
",3. Bellman Factorization and Bellman Rank,[0],[0]
Proposition 1 (Bellman rank bounded by number of states in MDPs).,3. Bellman Factorization and Bellman Rank,[0],[0]
Consider the setting of Example 1 with the corresponding CDP.,3. Bellman Factorization and Bellman Rank,[0],[0]
"With any class F , this model admits a Bellman factorization with M = |S| and ζ = 2 √ M .
",3. Bellman Factorization and Bellman Rank,[0],[0]
"The MDP example is particularly simple as each coordinate of the M -dimensional space corresponds to a state, which is observable.",3. Bellman Factorization and Bellman Rank,[0],[0]
"Our next few examples show that this is not necessary, and that the Bellman factorization can be based on latent properties of the process.",3. Bellman Factorization and Bellman Rank,[0],[0]
We next consider large MDPs whose transition dynamics have a low-rank structure.,3. Bellman Factorization and Bellman Rank,[0],[0]
"A closely related setting has been considered by Barreto et al. (2011; 2014) where the low-rank structure is exploited to speed up MDP planning, but no sample-efficient RL algorithms were previously known for this setting.
",3. Bellman Factorization and Bellman Rank,[0],[0]
"Proposition 2 (Bellman rank in low-rank MDPs, informally).",3. Bellman Factorization and Bellman Rank,[0],[0]
Consider the setting of Example 1 with a transition matrix Γ having rank at most M .,3. Bellman Factorization and Bellman Rank,[0],[0]
The induced CDP along with any F ⊂ X ×,3. Bellman Factorization and Bellman Rank,[0],[0]
"A → [0, 1] admits a Bellman factorization with Bellman rank M .
",3. Bellman Factorization and Bellman Rank,[0],[0]
"The next example considers POMDPs with large observations spaces and reactive value functions, where the Bellman rank is at most the number of hidden states.
",3. Bellman Factorization and Bellman Rank,[0],[0]
Proposition 3 (Bellman rank bounded by hidden states in reactive POMDPs).,3. Bellman Factorization and Bellman Rank,[0],[0]
Consider the setting of Example 3 with |S| < ∞ and a sliding window of size 1.,3. Bellman Factorization and Bellman Rank,[0],[0]
"Given any F ⊂ X ×A → [0, 1], this model admits a Bellman factorization with M = |S| and ζ = 2 √ M .
",3. Bellman Factorization and Bellman Rank,[0],[0]
Propositions 2 and 3 can be proved under a unified model that generalizes POMDPs by allowing the transition and reward functions to depend on the observation (Figure 1).,3. Bellman Factorization and Bellman Rank,[0],[0]
"This model captures the experimental settings considered in state-of-the-art empirical RL work, where agents act in a grid-world (|S| is small) and receives complex and rich observations such as raw pixel images (|O| is large); see e.g., Johnson et al. (2016).",3. Bellman Factorization and Bellman Rank,[0],[0]
"The model also subsumes and generalizes the setting of Krishnamurthy et al. (2016) which requires deterministic transitions in the underlying MDP.
",3. Bellman Factorization and Bellman Rank,[0],[0]
"Next, we consider Predictive State Representations (PSRs), which are models of partially observable systems with parameters grounded in observable quantities (Littman et al., 2001).",3. Bellman Factorization and Bellman Rank,[0],[0]
"Similar to the case of POMDPs, we can bound the Bellman rank in terms of the rank of the PSR6 when the candidate value functions are reactive.
",3. Bellman Factorization and Bellman Rank,[0],[0]
"6Every POMDP has an equivalent PSR whose rank is bounded by the number of hidden states (Singh et al., 2004).
",3. Bellman Factorization and Bellman Rank,[0],[0]
"Proposition 4 (Bellman rank in PSRs, informally).",3. Bellman Factorization and Bellman Rank,[0],[0]
"Consider a partially observable system with observation space O and the induced CDP (X ,A, H, P ) with xh = (oh, h).",3. Bellman Factorization and Bellman Rank,[0],[0]
"If the linear dimension of the system (i.e., rank of its PSR model) is at most L, then given any F :",3. Bellman Factorization and Bellman Rank,[0],[0]
"X × A → [0, 1], the Bellman rank is bounded by LK.
",3. Bellman Factorization and Bellman Rank,[0],[0]
The last example considers a class of linear control problems called Linear Quadratic Regulators (LQRs).,3. Bellman Factorization and Bellman Rank,[0],[0]
We show that the Bellman rank in LQRs is bounded by the dimension of the state space.,3. Bellman Factorization and Bellman Rank,[0],[0]
"Unlike previous examples, here we crucially use structure of the quadratic value functions, which is the form Q? takes.",3. Bellman Factorization and Bellman Rank,[0],[0]
Exploration in this class of problems has been previously considered by Osband & Van Roy (2014).,3. Bellman Factorization and Bellman Rank,[0],[0]
"Note that the algorithm to be introduced in the next section does not directly apply to LQRs due to the continuous action space, and adaptations that exploit the structure of the action space may be needed.
",3. Bellman Factorization and Bellman Rank,[0],[0]
"Proposition 5 (Bellman rank in LQRs, informally).",3. Bellman Factorization and Bellman Rank,[0],[0]
"An LQR can be viewed as an MDP with continuous state space Rd and action space RK , where the dynamics are described by some linear equations.",3. Bellman Factorization and Bellman Rank,[0],[0]
"Given the function class F which consists of non-stationary quadratic functions of the state, the Bellman rank is bounded by d2 + 1.",3. Bellman Factorization and Bellman Rank,[0],[0]
"In this section we present our algorithm for learning CDPs that have a Bellman factorization with small Bellman rank, along with the main sample complexity guarantee.",4. Algorithm and Main Results,[0],[0]
"To aid presentation and help convey the main ideas, we make three simplifying assumptions.",4. Algorithm and Main Results,[0],[0]
"We assume that (1) the agent knows the Bellman rank M and the corresponding norm bound, (2) the function class F is finite with cardinality N , and (3) the validity and Bellman factorization conditions (Definitions 3 and 5) hold exactly.",4. Algorithm and Main Results,[0],[0]
"We relax these assumptions in Section 5 and Appendix A.
We are interested in designing an algorithm for PAC Learning CDPs.",4. Algorithm and Main Results,[0],[0]
"We say that an algorithm PAC learns a
CDP if given F , two parameters , δ ∈ (0, 1), and access to the CDP, the algorithm outputs a policy π̂ with V π̂ ≥ V ?F",4. Algorithm and Main Results,[0],[0]
− with probability at least 1 − δ.,4. Algorithm and Main Results,[0],[0]
"The sample complexity is the number of episodes needed to achieve such a guarantee, and is typically expressed in terms of , δ, and other relevant parameters.",4. Algorithm and Main Results,[0],[0]
"The goal is to design an algorithm with sample complexity that is Poly(M,K,H, 1/ , log(N), log(1/δ)) where M is the Bellman rank, K is the number of actions, and H is the time horizon.",4. Algorithm and Main Results,[0],[0]
"Importantly, the bound allows no dependence on the number of unique contexts |X |.",4. Algorithm and Main Results,[0],[0]
"Pseudocode for our algorithm, OLIVE (Optimism Led Iterative Value-function Elimination), is displayed in Algorithm 1.",4.1. Algorithm,[0],[0]
"Theorem 1 describes how to set the parameters nest, neval, n, and φ.",4.1. Algorithm,[0],[0]
"For brevity, we introduce a shorthand for empirical Bellman errors given a tuple (x, a, r, x′):
σ(f, x, a, r, x′)",4.1. Algorithm,[0],[0]
":= f(x, a)− r",4.1. Algorithm,[0],[0]
"− f(x′, πf (x′)).",4.1. Algorithm,[0],[0]
"(4)
At a high level, the algorithm aims to eliminate functions f ∈ F that fail to satisfy the validity condition in Definition 3.",4.1. Algorithm,[0],[0]
This is done by Lines 13 and 14 inside the loop of the algorithm.,4.1. Algorithm,[0],[0]
"Line 13 uses importance weighting to get an unbiased estimate of E(f, πt, ht), the average Bellman error for function f on roll-in policy πt at time ht.",4.1. Algorithm,[0],[0]
"Thus, Line 14 eliminates functions that have high average Bellman error under πt and hence are not valid.
",4.1. Algorithm,[0],[0]
The other major component of the algorithm involves choosing the roll-in policy πt and level ht on which to do the learning step.,4.1. Algorithm,[0],[0]
"At iteration t, we choose the roll-in policy πt optimistically, by choosing ft that predicts the highest value at the starting context distribution and setting πt = πft .",4.1. Algorithm,[0],[0]
"To pick ht, we compute ft’s average Bellman error on its own roll-in distribution (Line 7), and set ht to be any level for which this average Bellman error is high (See Line 11).",4.1. Algorithm,[0],[0]
"As we will show, these choices ensure that substantial learning happens on each iteration, guaranteeing that the algorithm uses polynomially many episodes.
",4.1. Algorithm,[0],[0]
The last component is the termination criterion.,4.1. Algorithm,[0],[0]
The algorithm terminates if ft has small average Bellman error on its own roll-in distribution at all levels.,4.1. Algorithm,[0],[0]
"This criteria guarantees that πt is near optimal.
",4.1. Algorithm,[0],[0]
"Computationally, the algorithm requires enumeration of the value-function class, which we expect to be extremely large or infinite in practice.",4.1. Algorithm,[0],[0]
"A computationally efficient implementation is essential for a practical algorithm, which remains an open question.",4.1. Algorithm,[0],[0]
"We focus on the sample efficiency of the algorithm in this paper.
",4.1. Algorithm,[0],[0]
Intuition for OLIVE.,4.1. Algorithm,[0],[0]
"To convey intuition, it is helpful to ignore any sampling effects by replacing all empirical esti-
mates with population values and set to 0.",4.1. Algorithm,[0],[0]
"The first important fact is that the algorithm never eliminates a valid function, since the learning step in Line 14 only eliminates a function f if we can find a distribution on which it has a large average Bellman error.",4.1. Algorithm,[0],[0]
"If f is valid, then E(f, π, h) = 0 for all π, h, so f is never eliminated.
",4.1. Algorithm,[0],[0]
"The second fact is that if a function f is valid, then its predicted value is exactly the value achieved by the greedy policy πf , that is Vf = E[f(x1, πf (x1))]",4.1. Algorithm,[0],[0]
= V πf .,4.1. Algorithm,[0],[0]
"This is based on the following lemma.
",4.1. Algorithm,[0],[0]
Lemma 1 (Value-function error decomposition).,4.1. Algorithm,[0],[0]
"Define Vf = E[f(x1, πf (x1))",4.1. Algorithm,[0],[0]
].,4.1. Algorithm,[0],[0]
Then ∀f,4.1. Algorithm,[0],[0]
": X ×A → [0, 1],
Vf − V πf = H∑ h=1",4.1. Algorithm,[0],[0]
"E(f, πf , h).",4.1. Algorithm,[0],[0]
"(5)
Therefore, since ft is chosen optimistically as the maximizer of the value prediction among the surviving functions, and since we never eliminate valid functions, if OLIVE terminates, it must output a policy with value V ?F .",4.1. Algorithm,[0],[0]
"In the analysis, we incorporate sampling effects to derive robust versions of these facts so the algorithm always outputs a policy that is at most -suboptimal.
",4.1. Algorithm,[0],[0]
"The more challenging component is bounding the number of iterations of the algorithm, which is critical for obtaining a polynomial sample complexity bound.",4.1. Algorithm,[0],[0]
"This argument crucially relies on the Bellman factorization (Definition 5), which enables us to embed the distributions over contexts for any roll-in policy intoM dimensions and measure progress in this low-dimensional space.
",4.1. Algorithm,[0],[0]
"For now, fix some h and focus on the iterations where ht = h.",4.1. Algorithm,[0],[0]
If we ignore sampling effects we can set φ = 0.,4.1. Algorithm,[0],[0]
"By using the Bellman factorization to write E(f, πft , h) as an inner product, we can think of the learning step in Line 14 as introducing a homogeneous linear constraint on the set of ξh(f) vectors: 〈νh(ft), ξh(f)〉 = 0.",4.1. Algorithm,[0],[0]
"Now, if we execute the learning step at h again in a later iteration t′, we have 〈νh(ft′), ξh(ft′)〉 6= 0",4.1. Algorithm,[0],[0]
from Line 11.,4.1. Algorithm,[0],[0]
"Importantly, this means that νh(ft′) must be linearly independent from previous νh(ft) since 〈νh(ft), ξh(ft′)〉 = 0.",4.1. Algorithm,[0],[0]
"Since every time ht = h, the number of linearly independent constraints increases by 1, the number of iterations where ht = h is at most M , the dimension of the space.",4.1. Algorithm,[0],[0]
"Thus the Bellman rank (times H) upper-bounds the number of iterations.
",4.1. Algorithm,[0],[0]
"The above heuristic reasoning, despite relying on the brittle notion of linear independence, can be made robust.",4.1. Algorithm,[0],[0]
"With sampling effects, rather than homogeneous linear equalities, the learning step for level h introduces linear inequality constraints to the ξh(f) vectors.",4.1. Algorithm,[0],[0]
"But if f ′ is a surviving function that forces us to train at h, it means that 〈νh(f ′), ξh(f ′)",4.1. Algorithm,[0],[0]
"〉 is very large, while 〈νh(·), ξh(f ′)〉 is very small for all previous νh(·) vectors used in the learning
Algorithm 1 OLIVE (F ,M, ζ, , δ) – Optimism Led Iterative Value-function Elimination
1: Collect nest trajectories with actions taken in an arbitrary manner; save initial contexts {x(i)1 } nest i=1.",4.1. Algorithm,[0],[0]
2: Estimate the predicted value for each f ∈ F : V̂f = 1nest ∑nest i=1,4.1. Algorithm,[0],[0]
"f(x (i) 1 , πf (x (i) 1 )).",4.1. Algorithm,[0],[0]
3: F0 ← F .,4.1. Algorithm,[0],[0]
"4: for t = 1, 2, . . .",4.1. Algorithm,[0],[0]
"do 5: Choose policy ft = argmaxf∈Ft−1 V̂f , πt = πft . 6:",4.1. Algorithm,[0],[0]
Collect neval trajectories by following πt (i.e. a (i) h = πt(x (i) h ),4.1. Algorithm,[0],[0]
"for all h and i = 1, . . .",4.1. Algorithm,[0],[0]
", neval).
",4.1. Algorithm,[0],[0]
7: Estimate ∀h ∈,4.1. Algorithm,[0],[0]
"[H], Ẽ(ft, πt, h) := 1neval ∑neval i=1",4.1. Algorithm,[0],[0]
"σ(f, x (i) h , a (i) h ,",4.1. Algorithm,[0],[0]
"r (i) h , x (i) h+1).
",4.1. Algorithm,[0],[0]
"8: if ∑H h=1 Ẽ(ft, πt, h) ≤ 5 /8 then
9: Terminate and output πt. 10: end if 11:",4.1. Algorithm,[0],[0]
Pick ht ∈,4.1. Algorithm,[0],[0]
"[H] such that Ẽ(ft, πt, ht) ≥ 5 /(8H).",4.1. Algorithm,[0],[0]
12: Collect n trajectories where a(i)h = πt(x (i) h ) for all h 6= ht,4.1. Algorithm,[0],[0]
"and a (i) ht is drawn uniformly at random.
",4.1. Algorithm,[0],[0]
13: Estimate ∀f ∈,4.1. Algorithm,[0],[0]
"F , Ê(f, πt, ht) :",4.1. Algorithm,[0],[0]
= 1n,4.1. Algorithm,[0],[0]
∑n i=1,4.1. Algorithm,[0],[0]
"1[a (i) ht =πf (x (i) ht )] 1/K σ(f, x (i) ht , a (i) ht , r (i) ht , x (i) ht+1 ).",4.1. Algorithm,[0],[0]
"(see Eq. (4))
14: Learn Ft = { f ∈ Ft−1 : ∣∣∣Ê(f, πt, ht)∣∣∣ ≤ φ} .",4.1. Algorithm,[0],[0]
"15: end for
step.",4.1. Algorithm,[0],[0]
Intuitively this means that the new νh(f ′) vector is quite different from all of the previous ones.,4.1. Algorithm,[0],[0]
Our proof uses a volumetric argument to show that this suffices to guarantee substantial learning takes place.,4.1. Algorithm,[0],[0]
"In more detail, we track the volume of an enclosing ellipsoid of the surviving ξh(f) functions and show that each time we learn at level h this volume shrinks multiplicatively, which results in an iteration complexity that is linear in MH .
",4.1. Algorithm,[0],[0]
The optimistic choice for ft is critical for driving the agent’s exploration.,4.1. Algorithm,[0],[0]
"With this choice, if ft is valid, then the algorithm terminates correctly, and if ft is not valid, then substantial progress is made.",4.1. Algorithm,[0],[0]
"Thus the agent does not get stuck exploring with many valid but suboptimal functions, which could result in exponential sample complexity.",4.1. Algorithm,[0],[0]
"We now turn to the main result, which guarantees that OLIVE PAC-learns Contextual Decision Processes with polynomial sample complexity.
",4.2. Sample Complexity,[0],[0]
Theorem 1.,4.2. Sample Complexity,[0],[0]
"For any , δ ∈ (0, 1), any CDP and function classF that admit a Bellman factorization with parameters M and ζ, run OLIVE with the following parameters:
φ = 12H √ M , nest =
32
2 log(6N/δ),
neval = 288H2
2 log
( 12H2M log(6H √ Mζ/ )
δ
) ,
n = 4608H2MK
2 log
( 12NHM log(6H √ Mζ/ )
δ
) .
",4.2. Sample Complexity,[0],[0]
"Then, with probability at least 1−δ, OLIVE returns a policy
π̂ that satisfies V π̂ ≥ V ?F",4.2. Sample Complexity,[0],[0]
"− (recall Definition 3 for V ?F ), and the number of episodes required is at most7
Õ ( M2H3K
2 log(Nζ/δ)
) .",4.2. Sample Complexity,[0],[0]
"(6)
Thus, if a CDP and function class F admit a Bellman factorization with small Bellman rank and F contains valid functions, OLIVE is guaranteed to find a near optimal valid function using only polynomially many episodes.",4.2. Sample Complexity,[0],[0]
"To our knowledge, this is the most general polynomial sample complexity bound for RL with rich observations and function approximation, as many popular models are shown to admit small Bellman rank (see Section 3, Table 1).",4.2. Sample Complexity,[0],[0]
"The result also certifies that the notion of Bellman factorization, which is quite general, is sufficient for efficient exploration and learning in sequential decision making problems.
",4.2. Sample Complexity,[0],[0]
"It is worth briefly comparing this result with prior work.
",4.2. Sample Complexity,[0],[0]
1.,4.2. Sample Complexity,[0],[0]
"The most closely related result is the recent work of Krishnamurthy et al. (2016), who also consider episodic RL with infinite observation spaces and function approximation.",4.2. Sample Complexity,[0],[0]
"The model studied there is a CDP with Bellman rankM , so our result applies as is to that setting.",4.2. Sample Complexity,[0],[0]
"Importantly, we eliminate the need for deterministic transitions in that work, while improving the dependence on H and , although with worse scaling in M .",4.2. Sample Complexity,[0],[0]
"We emphasize that our result applies to a much more general class of models.
2.",4.2. Sample Complexity,[0],[0]
"Several works provide sample complexity bounds for fitted value/policy iteration methods (e.g., Munos
7We use Õ(·) notation to suppress poly-logarithmic dependence on everything except N and δ.
(2003); Antos et al. (2008); Munos & Szepesvári (2008)).",4.2. Sample Complexity,[0],[0]
"While these results are relevant, they do not address the exploration issue, which is our main focus, and circumvent it by impliciting assuming an exploratory policy for data collection.
3.",4.2. Sample Complexity,[0],[0]
"Ng & Jordan (2000) proposed a policy search method for POMDPs called PEGASUS, with a sample complexity that scales polynomially with the statistical complexity of the policy class and the horizon.",4.2. Sample Complexity,[0],[0]
"Despite the powerful result, the algorithm requires careful control over the random numbers that determine the state transitions.",4.2. Sample Complexity,[0],[0]
"While the assumption can hold for certain simulated environments, the scope of applications is relatively limited.
4.",4.2. Sample Complexity,[0],[0]
"Since CDPs include small-state MDPs (Kearns & Singh, 2002; Brafman & Tennenholtz, 2003; Strehl et al., 2006), the algorithm can be applied as is to these problems.",4.2. Sample Complexity,[0],[0]
"Unfortunately, our sample complexity is polynomially worse than the state of the art Õ(Mpoly(H)K 2 log(1/δ)) bounds for PAC-learning MDPs (Dann & Brunskill, 2015).",4.2. Sample Complexity,[0],[0]
"On the other hand, the algorithm also applies to MDPs with infinite state spaces with Bellman factorizations, which cannot be handled by tabular approaches.
5.",4.2. Sample Complexity,[0],[0]
"Finally, Contextual Decision Processes also encompass contextual bandits, where the sample complexity is Θ(K log(N)/ 2) (Agarwal et al., 2014).",4.2. Sample Complexity,[0],[0]
"As contextual bandits have M = H = 1, OLIVE achieves the optimal sample complexity in this case.
",4.2. Sample Complexity,[0],[0]
"Turning briefly to lower bounds, since the CDP setting with Bellman factorization is new, general lower bounds for the broad class do not exist.",4.2. Sample Complexity,[0],[0]
"However, we can use MDP lower bounds for guidance on the question of optimality, since the small-state MDPs in Example 1 are a special case.",4.2. Sample Complexity,[0],[0]
"While no existing MDP lower bounds apply as is (because formulations vary), in Appendix F.2 we adapt ideas from Auer et al. (2002) to obtain a Ω(MKH/ 2) sample complexity lower bound for learning the MDPs in Example 1.
",4.2. Sample Complexity,[0],[0]
"In comparison, the sample complexity in Theorem 1 is worse in M,H , and log(N) factors, but of course the small-state MDP is a significantly simpler special case.",4.2. Sample Complexity,[0],[0]
We leave as future work the question of optimal sample complexity for learning CDPs with low Bellman rank.,4.2. Sample Complexity,[0],[0]
"The basic result presented here is quite robust and admits many extensions, some of which we briefly describe here; the details are deferred to Appendix A.
1.",5. Extensions,[0],[0]
Handling infinite function classes with dependence on VC-dimension like quantities.,5. Extensions,[0],[0]
"This result uses a
context-value function class G ⊂ X →",5. Extensions,[0],[0]
"[0, 1] and",5. Extensions,[0],[0]
a policy class Π ⊂ X,5. Extensions,[0],[0]
"→ A instead of a context-action value class as in OLIVE, with sample complexity depending on the pseudo-dimension of G and the Natarajan dimension of Π. These are standard measures for regression and multi-class classification, and several natural classes have known bounds.
",5. Extensions,[0],[0]
2.,5. Extensions,[0],[0]
Competing with approximately valid value-functions with inexact Bellman factorization.,5. Extensions,[0],[0]
"For this result, we extend the definition of validity and V ?F (Defs. 3 and 4) to allow small but non-zero Bellman errors, and also only require that the Bellman error matrices have a low rank approximation with small `∞ error.",5. Extensions,[0],[0]
3.,5. Extensions,[0],[0]
Adapting to unknown Bellman rank.,5. Extensions,[0],[0]
Here we run OLIVE with choices of M growing at a doubling schedule and show that the PAC-guarantee is preserved without loss in sample complexity.,5. Extensions,[0],[0]
"In this paper, we presented a new model for RL with rich observations, called Contextual Decision Processes, and a structural property, the Bellman factorization, of these models that enables sample-efficient learning.",6. Discussion,[0],[0]
The unified approach allows us to address several settings of practical interest that have largely eluded RL theory to date.,6. Discussion,[0],[0]
"Our work also elicits several further questions:
1.",6. Discussion,[0],[0]
Can we obtain a computationally efficient algorithm for some form of this setting?,6. Discussion,[0],[0]
"Prior related work (for instance in contextual bandits (Dudik et al., 2011; Agarwal et al., 2014)) used supervised learning oracles for computationally efficient approaches.",6. Discussion,[0],[0]
"Is there a suitable oracle for this setting?
2.",6. Discussion,[0],[0]
The sample complexity depends polynomially on the cardinality of the action space.,6. Discussion,[0],[0]
"Can we extend the results to handle large or continuous action spaces (e.g., by incorporating concepts such as Eluder dimension (Russo & Van Roy, 2013))?
3.",6. Discussion,[0],[0]
Can we address sample-efficient RL given only a policy class rather than a value function class?,6. Discussion,[0],[0]
"Empirical approaches often rely on policy gradients, which are subject to local optima.",6. Discussion,[0],[0]
"Are there parallel results to this work, without access to value functions?
",6. Discussion,[0],[0]
Resolutions to these questions are important for further connecting RL theory with practice.,6. Discussion,[0],[0]
Part of this work was completed while NJ and AK were at Microsoft Research.,Acknowledgements,[0],[0]
NJ was partially supported by Rackham Predoctoral Fellowship in University of Michigan.,Acknowledgements,[0],[0]
This paper studies systematic exploration for reinforcement learning (RL) with rich observations and function approximation.,abstractText,[0],[0]
"We introduce contextual decision processes (CDPs), that unify most prior RL settings.",abstractText,[0],[0]
"Our first contribution is a complexity measure, the Bellman rank, that we show enables tractable learning of near-optimal behavior in CDPs and is naturally small for many well-studied RL models.",abstractText,[0],[0]
Our second contribution is a new RL algorithm that does systematic exploration to learn near-optimal behavior in CDPs with low Bellman rank.,abstractText,[0],[0]
The algorithm requires a number of samples that is polynomial in all relevant parameters but independent of the number of unique contexts.,abstractText,[0],[0]
Our approach uses Bellman error minimization with optimistic exploration and provides new insights into efficient exploration for RL with function approximation.,abstractText,[0],[0]
Contextual Decision Processes with low Bellman rank are PAC-Learnable,title,[0],[0]
"Artificial neural networks (ANNs) have become an indispensable asset for applied machine learning, rivaling human performance in a variety of domain-specific tasks (LeCun et al., 2015).",1. Introduction,[0],[0]
"Although originally inspired by biology (Rosenblatt, 1958; Fukushima & Miyake, 1982), the underlying design principles and learning methods differ substantially from biological neural networks.",1. Introduction,[0],[0]
"For instance, parameters of ANNs are learned on a dataset in the training phase, and then frozen and used statically on new data in the deployment or recall phase.",1. Introduction,[0],[0]
"To accommodate changes in the data distribution, ANNs typically have to be retrained on the entire dataset to avoid overfitting and catastrophic forgetting (Choy et al., 2006; Goodfellow et al., 2013).
",1. Introduction,[0],[0]
"On the other hand, biological neural networks exhibit continual learning in which they acquire new knowledge over
*Equal contribution 1Stanford University.",1. Introduction,[0],[0]
"Correspondence to: Friedemann Zenke <fzenke@stanford.edu>, Ben Poole <poole@cs.stanford.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
a lifetime.,1. Introduction,[0],[0]
It is therefore difficult to draw a clear line between a learning and recall phase.,1. Introduction,[0],[0]
"Somehow, our brains have evolved to learn from non-stationary data and to update internal memories or beliefs on-the-fly.",1. Introduction,[0],[0]
"While it is unknown how this feat is accomplished in the brain, it seems possible that the unparalleled biological performance in continual learning could rely on specific features implemented by the underlying biological wetware that are not currently implemented in ANNs.
",1. Introduction,[0],[0]
Perhaps one of the greatest gaps in the design of modern ANNs versus biological neural networks lies in the complexity of synapses.,1. Introduction,[0],[0]
"In ANNs, individual synapses (weights) are typically described by a single scalar quantity.",1. Introduction,[0],[0]
"On the other hand, individual biological synapses make use of complex molecular machinery that can affect plasticity at different spatial and temporal scales (Redondo & Morris, 2011).",1. Introduction,[0],[0]
"While this complexity has been surmised to serve memory consolidation (Fusi et al., 2005; Lahiri & Ganguli, 2013; Zenke et al., 2015; Ziegler et al., 2015; Benna & Fusi, 2016), few studies have illustrated how it benefits learning in ANNs.
",1. Introduction,[0],[0]
Here we study the role of internal synaptic dynamics to enable ANNs to learn sequences of classification tasks.,1. Introduction,[0],[0]
"While simple, scalar one-dimensional synapses suffer from catastrophic forgetting, in which the network forgets previously learned tasks when trained on a novel task, this problem can be largely alleviated by synapses with a more complex three-dimensional state space.",1. Introduction,[0],[0]
"In our model, the synaptic state tracks the past and current parameter value, and maintains an online estimate of the synapse’s “importance” toward solving problems encountered in the past.",1. Introduction,[0],[0]
"Our importance measure can be computed efficiently and locally at each synapse during training, and represents the local contribution of each synapse to the change in the global loss.",1. Introduction,[0],[0]
"When the task changes, we consolidate the important synapses by preventing them from changing in future tasks.",1. Introduction,[0],[0]
"Thus learning in future tasks is mediated primarily by synapses that were unimportant for past tasks, thereby avoiding catastrophic forgetting of these past tasks.",1. Introduction,[0],[0]
The problem of alleviating catastrophic forgetting has been addressed in many previous studies.,2. Prior work,[0],[0]
"These studies can be
broadly partitioned into (1) architectural, (2) functional, and (3) structural approaches.
",2. Prior work,[0],[0]
Architectural approaches to catastrophic forgetting alter the architecture of the network to reduce interference between tasks without altering the objective function.,2. Prior work,[0],[0]
"The simplest form of architectural regularization is freezing certain weights in the network so that they stay exactly the same (Razavian et al., 2014).",2. Prior work,[0],[0]
"A slightly more relaxed approach reduces the learning rate for layers shared with the original task while fine-tuning to avoid dramatic changes in the parameters (Donahue et al., 2014; Yosinski et al., 2014).",2. Prior work,[0],[0]
"Approaches using different nonlinearities like ReLU, MaxOut, and local winner-take-all have been shown to improve performance on permuted MNIST and sentiment analysis tasks (Srivastava et al., 2013; Goodfellow et al., 2013).",2. Prior work,[0],[0]
"Moreover, injecting noise to sparsify gradients using dropout also improves performance (Goodfellow et al., 2013).",2. Prior work,[0],[0]
Recent work from Rusu et al. (2016) proposed more dramatic architectural changes where the entire network for the previous task is copied and augmented with new features while solving a new task.,2. Prior work,[0],[0]
"This entirely prevents forgetting on earlier tasks, but causes the architectural complexity to grow with the number of tasks.
",2. Prior work,[0],[0]
Functional approaches to catastrophic forgetting add a regularization term to the objective that penalizes changes in the input-output function of the neural network.,2. Prior work,[0],[0]
"In Li & Hoiem (2016), the predictions of the previous task’s network and the current network are encouraged to be similar when applied to data from the new task by using a form of knowledge distillation (Hinton et al., 2014).",2. Prior work,[0],[0]
"Similarly, Jung et al. (2016) regularize the `2 distance between the final hidden activations instead of the knowledge distillation penalty.",2. Prior work,[0],[0]
Both of these approaches to regularization aim to preserve aspects of the input-output mapping for the old task by storing or computing additional activations using the old task’s parameters.,2. Prior work,[0],[0]
"This makes the functional approach to catastrophic forgetting computationally expensive as it requires computing a forward pass through the old task’s network for every new data point.
",2. Prior work,[0],[0]
"The third technique, structural regularization, involves penalties on the parameters that encourage them to stay close to the parameters for the old task.",2. Prior work,[0],[0]
"Recently, Kirkpatrick et al. (2017) proposed elastic weight consolidation (EWC), a quadratic penalty on the difference between the parameters for the new and the old task.",2. Prior work,[0],[0]
They used a diagonal weighting proportional to the diagonal of the Fisher information metric over the old parameters on the old task.,2. Prior work,[0],[0]
Exactly computing the diagonal of the Fisher requires summing over all possible output labels and thus has complexity linear in the number of outputs.,2. Prior work,[0],[0]
This limits the application of this approach to low-dimensional output spaces.,2. Prior work,[0],[0]
"To tackle the problem of continual learning in neural networks, we sought to build a simple structural regularizer that could be computed online and implemented locally at each synapse.",3. Synaptic framework,[0],[0]
"Specifically, we aim to endow each individual synapse with a local measure of “importance” in solving tasks the network has been trained on in the past.",3. Synaptic framework,[0],[0]
When training on a new task we penalize changes to important parameters to avoid old memories from being overwritten.,3. Synaptic framework,[0],[0]
"To that end, we developed a class of algorithms which keep track of an importance measure ωµk which reflects past credit for improvements of the task objective Lµ for task µ to individual synapses θk.",3. Synaptic framework,[0],[0]
"For brevity we use the term “synapse” synonymously with the term “parameter”, which includes weights between layers as well as biases.
",3. Synaptic framework,[0],[0]
The process of training a neural network is characterized by a trajectory θ(t) in parameter space (Fig. 1).,3. Synaptic framework,[0],[0]
The feat of successful training lies in finding learning trajectories for which the endpoint lies close to a minimum of the loss function L on all tasks.,3. Synaptic framework,[0],[0]
"Let us first consider the change in loss for an infinitesimal parameter update δ(t) at time t.
In this case the change in loss is well approximated by the gradient g = ∂L∂θ",3. Synaptic framework,[0],[0]
"and we can write
L(θ(t) + δ(t))− L(θ(t))",3. Synaptic framework,[0],[0]
"≈ ∑ k gk(t)δk(t) , (1)
which illustrates that each parameter change δk(t) = θ′k(t) contributes the amount gk(t)δk(t) to the change in total loss.
",3. Synaptic framework,[0],[0]
To compute the change in loss over an entire trajectory through parameter space we have to sum over all infinitesimal changes.,3. Synaptic framework,[0],[0]
"This amounts to computing the path integral of the gradient vector field along the parameter trajectory from the initial point (at time t0) to the final point (at time t1): ∫
C
g(θ(t))dθ = ∫ t1 t0 g(θ(t)) ·",3. Synaptic framework,[0],[0]
θ′(t)dt.,3. Synaptic framework,[0],[0]
"(2)
As the gradient is a conservative field, the value of the integral is equal to the difference in loss between the end point and start point: L(θ(t1))",3. Synaptic framework,[0],[0]
− L(θ(t0)).,3. Synaptic framework,[0],[0]
"Crucial to our approach, we can decompose Eq. 2 as a sum over the individual parameters∫ tµ
tµ−1 g(θ(t)) · θ′(t)dt",3. Synaptic framework,[0],[0]
= ∑ k ∫,3. Synaptic framework,[0],[0]
tµ tµ−1 gk(θ(t))θ ′,3. Synaptic framework,[0],[0]
"k(t)dt
≡",3. Synaptic framework,[0],[0]
− ∑ k ωµk .,3. Synaptic framework,[0],[0]
"(3)
The ωµk now have an intuitive interpretation as the parameter specific contribution to changes in the total loss.",3. Synaptic framework,[0],[0]
"Note that we have introduced the minus sign in the second line, because we are typically interested in decreasing the loss.
",3. Synaptic framework,[0],[0]
"In practice, we can approximate ωµk online as the running sum of the product of the gradient gk(t) = ∂L∂θk with the parameter update θ′k(t) =",3. Synaptic framework,[0],[0]
∂θk ∂t .,3. Synaptic framework,[0],[0]
"For batch gradient descent with an infinitesimal learning rate, ωµk can be directly interpreted as the per-parameter contribution to changes in the total loss.",3. Synaptic framework,[0],[0]
"In most cases the true gradient is approximated by stochastic gradient descent (SGD), resulting in an approximation that introduces noise into the estimate of gk.",3. Synaptic framework,[0],[0]
"As a direct consequence, the approximated per-parameter importances will typically overestimate the true value of ωµk .
",3. Synaptic framework,[0],[0]
How can the knowledge of ωµk be exploited to improve continual learning?,3. Synaptic framework,[0],[0]
"The problem we are trying to solve is to minimize the total loss function summed over all tasks, L = ∑ µ Lµ, with the limitation that we do not have access to loss functions of tasks we were training on in the past.",3. Synaptic framework,[0],[0]
"Instead, we only have access to the loss function Lµ for a single task µ at any given time.",3. Synaptic framework,[0],[0]
"Catastrophic forgetting arises when minimizing Lµ inadvertently leads to substantial increases of the cost on previous tasks Lν with ν < µ
(Fig. 1).",3. Synaptic framework,[0],[0]
"To avoid catastrophic forgetting of all previous tasks (ν < µ) while training task µ, we want to avoid drastic changes to weights which were particularly influential in the past.",3. Synaptic framework,[0],[0]
The importance of a parameter θk for a single task is determined by two quantities: 1) how much an individual parameter contributed to a drop in the loss ωνk over the entire trajectory of training (cf.,3. Synaptic framework,[0],[0]
Eq. 3) and 2) how far it moved ∆νk ≡ θk(tν),3. Synaptic framework,[0],[0]
− θk(tν−1).,3. Synaptic framework,[0],[0]
"To avoid large changes to important parameters, we use a modified cost function L̃µ in which we introduced a surrogate loss which approximates the summed loss functions of previous tasks",3. Synaptic framework,[0],[0]
Lν (ν < µ).,3. Synaptic framework,[0],[0]
"Specifically, we use a quadratic surrogate loss that has the same minimum as the cost function of the previous tasks and yields the same ωνk over the parameter distance ∆k.",3. Synaptic framework,[0],[0]
"In other words, if learning were to be performed on the surrogate loss instead of the actual loss function, it would result in the same final parameters and change in loss during training (Fig. 2).",3. Synaptic framework,[0],[0]
"For two tasks this is achieved exactly by the following quadratic surrogate loss
L̃µ = Lµ + c",3. Synaptic framework,[0],[0]
"∑ k Ωµk ( θ̃k − θk )2 ︸ ︷︷ ︸
surrogate loss
(4)
where we have introduced the dimensionless strength parameter c, the reference weight corresponding to the parameters at the end of the previous task θ̃k = θk(tµ−1),
and the per-parameter regularization strength: Ωµk = ∑ ν<µ ωνk (∆νk) 2 + ξ .",3. Synaptic framework,[0],[0]
"(5)
Note that the term in the denominator (∆νk) 2 ensures that the regularization term carries the same units as the loss L. For practical reasons we also introduce an additional damping parameter, ξ, to bound the expression in cases where ∆νk → 0.",3. Synaptic framework,[0],[0]
"Finally, c is a strength parameter which trades off old versus new memories.",3. Synaptic framework,[0],[0]
"If the path integral (Eq. 3) is evaluated precisely, c = 1 would correspond to an equal weighting of old and new memories.",3. Synaptic framework,[0],[0]
"However, due to noise in the evaluation of the path integral (Eq. 3), c typically has to be chosen smaller than one to compensate.",3. Synaptic framework,[0],[0]
"Unless otherwise stated, the ωk are updated continuously during training, whereas the cumulative importance measures, Ωµk , and the reference weights, θ̃, are only updated at the end of each task.",3. Synaptic framework,[0],[0]
"After updating the Ωµk , the ωk are set to zero.",3. Synaptic framework,[0],[0]
"Although our motivation for Eq. 4 as a surrogate loss only holds in the case of two tasks, we will show empirically that our approach leads to good performance when learning additional tasks.
",3. Synaptic framework,[0],[0]
To understand how the particular choices of Eqs.,3. Synaptic framework,[0],[0]
"4 and 5 affect learning, let us consider the example illustrated in Figure 1 in which we learn two tasks.",3. Synaptic framework,[0],[0]
We first train on Task 1.,3. Synaptic framework,[0],[0]
At time t1 the parameters have approached a local minimum of the Task 1 loss L1.,3. Synaptic framework,[0],[0]
"But, the same parameter configuration is not close to a minimum for Task 2.",3. Synaptic framework,[0],[0]
"Consequently, when training on Task 2 without any additional precautions, the L1 loss may inadvertently increase (Fig. 1, black trajectory).",3. Synaptic framework,[0],[0]
"However, when θ2 “remembers” that it was important to decreasing L1, it can exploit this knowledge during training on Task 2 by staying close to its current value (Fig. 1, orange trajectory).",3. Synaptic framework,[0],[0]
"While this will almost inevitably result in a decreased performance on Task 2, this decrease could be negligible, whereas the gain in performance on both tasks combined can be substantial.
",3. Synaptic framework,[0],[0]
"The approach presented here is similar to EWC (Kirkpatrick et al., 2017) in that more influential parameters are pulled back more strongly towards a reference weight with which good performance was achieved on previous tasks.",3. Synaptic framework,[0],[0]
"However, in contrast to EWC, here we are putting forward a method which computes an importance measure online and along the entire learning trajectory, whereas EWC relies on a point estimate of the diagonal of the Fisher information metric at the final parameter values, which has to be computed during a separate phase at the end of each task.",3. Synaptic framework,[0],[0]
In the following we illustrate that our general approach recovers sensible Ωµk in the case of a simple and analytically tractable training scenario.,4. Theoretical analysis of special cases,[0],[0]
"To that end, we analyze what
the parameter specific path integral ωuk and its normalized version Ωµk (Eq. (5)), correspond to in terms of the geometry of a simple quadratic error function
E(θ) = 1
2 (θ − θ∗)TH(θ − θ∗), (6)
with a minimum at θ∗ and a Hessian matrix H .",4. Theoretical analysis of special cases,[0],[0]
Further consider batch gradient descent dynamics on this error function.,4. Theoretical analysis of special cases,[0],[0]
"In the limit of small discrete time learning rates, this descent dynamics is described by the continuous time differential equation
τ dθ dt = −∂E",4. Theoretical analysis of special cases,[0],[0]
"∂θ = −H(θ − θ∗), (7)
where τ is related to the learning rate.",4. Theoretical analysis of special cases,[0],[0]
"If we start from an initial condition θ(0) at time t = 0, an exact solution to the descent path is given by
θ(t) = θ∗ + e−H t τ",4. Theoretical analysis of special cases,[0],[0]
"(θ(0)− θ∗), (",4. Theoretical analysis of special cases,[0],[0]
"8)
yielding the time dependent update direction
θ′(t) = dθ dt = −1 τ He−H",4. Theoretical analysis of special cases,[0],[0]
t τ,4. Theoretical analysis of special cases,[0],[0]
(θ(0)− θ∗).,4. Theoretical analysis of special cases,[0],[0]
"(9)
Now, under gradient descent dynamics, the gradient obeys g = τ dθdt , so the ω µ k in (3) are computed as the diagonal elements of the matrix
Q = τ ∫",4. Theoretical analysis of special cases,[0],[0]
∞ 0 dt dθ dt dθ dt T .,4. Theoretical analysis of special cases,[0],[0]
"(10)
An explicit formula for Q can be given in terms of the eigenbasis of the Hessian H .",4. Theoretical analysis of special cases,[0],[0]
"In particular, let λα and uα denote the eigenvalues and eigenvectors of H , and let dα = uα · (θ(0)−θ∗) be the projection of the discrepancy between initial and final parameters onto the α’th eigenvector.",4. Theoretical analysis of special cases,[0],[0]
"Then inserting (9) into (10), performing the change of basis to the eigenmodes ofH , and doing the integral yields
Qij = ∑ αβ uαi d α",4. Theoretical analysis of special cases,[0],[0]
λ,4. Theoretical analysis of special cases,[0],[0]
αλβ,4. Theoretical analysis of special cases,[0],[0]
λα,4. Theoretical analysis of special cases,[0],[0]
+ λβ dβuβj .,4. Theoretical analysis of special cases,[0],[0]
"(11)
Note that as a time-integrated steady state quantity, Q no longer depends on the time constant τ governing the speed of the descent path.
",4. Theoretical analysis of special cases,[0],[0]
"At first glance, the Q matrix elements depend in a complex manner on both the eigenvectors and eigenvalues of the Hessian, as well as the initial condition θ(0).",4. Theoretical analysis of special cases,[0],[0]
"To understand this dependence, let’s first consider averaging Q over random initial conditions θ(0), such that the collection of discrepancies dα constitute a set of zero mean iid random variables with variance σ2.",4. Theoretical analysis of special cases,[0],[0]
Thus we have the average 〈dαdβ〉 = σ2δαβ .,4. Theoretical analysis of special cases,[0],[0]
"Performing this average overQ then yields
〈Qij〉 = 1 2 σ2 ∑ α uαi λ αuβj = 1 2 σ2Hij .",4. Theoretical analysis of special cases,[0],[0]
"(12)
",4. Theoretical analysis of special cases,[0],[0]
"Thus remarkably, after averaging over initial conditions, the Q matrix, which is available simply by correlating parameter updates across pairs of synapses and integrating over time, reduces to the Hessian, up to a scale factor dictating the discrepancy between initial and final conditions.",4. Theoretical analysis of special cases,[0],[0]
"Indeed, this scale factor theoretically motivates the normalization in (5); the denominator in (5), at zero damping, ξ averages to σ2, thereby removing the scale factor σ2 in (12)
",4. Theoretical analysis of special cases,[0],[0]
"However, we are interested in what Qij computes for a single initial condition.",4. Theoretical analysis of special cases,[0],[0]
There are two scenarios in which the simple relationship between Q and the Hessian H is preserved without averaging over initial conditions.,4. Theoretical analysis of special cases,[0],[0]
"First, consider the case when the Hessian is diagonal, so that uαi = δαiei where ei is the i’th coordinate vector.",4. Theoretical analysis of special cases,[0],[0]
Then α and i indices are interchangeable and the eigenvalues of the Hessian are the diagonal elements of the Hessian: λi = Hii.,4. Theoretical analysis of special cases,[0],[0]
"Then (11) reduces to
Qij = δij(d i)2Hii.",4. Theoretical analysis of special cases,[0],[0]
"(13)
",4. Theoretical analysis of special cases,[0],[0]
"Again the normalization in (5), at zero damping, removes the scale of movement in parameter space (di)2, and so the normalizedQ matrix becomes identical to the diagonal Hessian.",4. Theoretical analysis of special cases,[0],[0]
"In the second scenario, consider the extreme limit where the Hessian is rank 1 so that λ1 is the only nonzero eigenvalue.",4. Theoretical analysis of special cases,[0],[0]
"Then (11) reduces to
Qij = 1
2 (d1)2u1iλ1u 1 j =
1 2 (d1)2Hij .",4. Theoretical analysis of special cases,[0],[0]
"(14)
Thus again, the Q matrix reduces to the Hessian, up to a scale factor.",4. Theoretical analysis of special cases,[0],[0]
The normalized importances then become the diagonal elements of the non-diagonal but low rank Hessian.,4. Theoretical analysis of special cases,[0],[0]
"We note that the low rank Hessian is the interesting case for continual learning; low rank structure in the error function leaves many directions in synaptic weight space
unconstrained by a given task, leaving open excess capacity for synaptic modification to solve future tasks without interfering with performance on an old task.
",4. Theoretical analysis of special cases,[0],[0]
It is important to stress that the path integral for importance is computed by integrating information along the entire learning trajectory (cf.,4. Theoretical analysis of special cases,[0],[0]
Fig. 2).,4. Theoretical analysis of special cases,[0],[0]
"For a quadratic loss function, the Hessian is constant along this trajectory, and so we find a precise relationship between the importance and the Hessian.",4. Theoretical analysis of special cases,[0],[0]
"But for more general loss functions, where the Hessian varies along the trajectory, we cannot expect any simple mathematical correspondence between the importance Ωµk and the Hessian at the endpoint of learning, or related measures of parameter sensitivity (Pascanu & Bengio, 2013; Martens, 2016; Kirkpatrick et al., 2017) at the endpoint.",4. Theoretical analysis of special cases,[0],[0]
"In practice, however, we find that our importance measure is correlated to measures based on such endpoint estimates, which may explain their comparable effectiveness as we will see in the next section.",4. Theoretical analysis of special cases,[0],[0]
"We evaluated our approach for continual learning on the split and permuted MNIST (LeCun et al., 1998; Goodfellow et al., 2013), and split versions of CIFAR-10 and CIFAR-100 (Krizhevsky & Hinton, 2009).",5. Experiments,[0],[0]
We first evaluated our algorithm on a split MNIST benchmark.,5.1. Split MNIST,[0],[0]
For this benchmark we split the full MNIST training data set into 5 subsets of consecutive digits.,5.1. Split MNIST,[0],[0]
The 5 tasks correspond to learning to distinguish between two consecutive digits from 0 to 10.,5.1. Split MNIST,[0],[0]
"We used a small multi-layer perceptron (MLP) with only two hidden layers consisting of 256 units each with ReLU nonlinearities, and a standard
categorical cross-entropy loss function plus our consolidation cost term (with damping parameter ξ = 1× 10−3).",5.1. Split MNIST,[0],[0]
"To avoid the complication of crosstalk between digits at the readout layer due to changes in the label distribution during training, we used a multi-head approach in which the categorical cross entropy loss at the readout layer was computed only for the digits present in the current task.",5.1. Split MNIST,[0],[0]
"Finally, we optimized our network using a minibatch size of 64 and trained for 10 epochs.",5.1. Split MNIST,[0],[0]
"To achieve good absolute performance with a smaller number of epochs we used the adaptive optimizer Adam (Kingma & Ba, 2014) (η = 1× 10−3, β1 = 0.9, β2 = 0.999).",5.1. Split MNIST,[0],[0]
"In this benchmark the optimizer state was reset after training each task.
",5.1. Split MNIST,[0],[0]
"To evaluate the performance, we computed the average classification accuracy on all previous tasks as a function of number of tasks trained.",5.1. Split MNIST,[0],[0]
We now compare this performance between networks in which we turn consolidation dynamics on (c = 1) against cases in which consolidation was off (c = 0).,5.1. Split MNIST,[0],[0]
During training of the first task the consolidation penalty is zero for both cases because there is no past experience that synapses could be regularized against.,5.1. Split MNIST,[0],[0]
"When trained on the digits “2” and “3” (Task 2), both the model with and without consolidation show accuracies close to 1 on Task 2.",5.1. Split MNIST,[0],[0]
"However, on average the networks without synaptic consolidation show substantial loss in accuracy on Task 1 (Fig. 3).",5.1. Split MNIST,[0],[0]
"In contrast to that, networks with consolidation only undergo minor impairment with respect to accuracy on Task 1 and the average accuracy for both tasks stays close to 1.",5.1. Split MNIST,[0],[0]
"Similarly, when the network has seen all MNIST digits, on average, the accuracy on the first two tasks, corresponding to the first four digits, has dropped back to chance levels in the cases without consolidation whereas the model with consolidation only shows minor degradation in performance on these tasks (Fig. 3).",5.1. Split MNIST,[0],[0]
"In this benchmark, we randomly permute all MNIST pixels differently for each task.",5.2. Permuted MNIST benchmark,[0],[0]
We trained a MLP with two hidden layers with 2000 ReLUs each and softmax loss.,5.2. Permuted MNIST benchmark,[0],[0]
We used Adam with the same parameters as before.,5.2. Permuted MNIST benchmark,[0],[0]
"However, here we used ξ = 0.1 and the value for c = 0.1 was determined via a coarse grid search on a heldout validation set.",5.2. Permuted MNIST benchmark,[0],[0]
The mini batch size was set to 256 and we trained for 20 epochs.,5.2. Permuted MNIST benchmark,[0],[0]
In contrast to the split MNIST benchmark we obtained better results by maintaining the state of the Adam optimizer between tasks.,5.2. Permuted MNIST benchmark,[0],[0]
The final test error was computed on data from the MNIST test set.,5.2. Permuted MNIST benchmark,[0],[0]
"Performance is measured by the ability of the network to solve all tasks.
",5.2. Permuted MNIST benchmark,[0],[0]
To establish a baseline for comparison we first trained a network without synaptic consolidation (c = 0) on all tasks sequentially.,5.2. Permuted MNIST benchmark,[0],[0]
"In this scenario the system exhibits catastrophic forgetting, i.e. it learns to solve the most recent task, but
rapidly forgets about previous tasks (blue line, Fig. 4).",5.2. Permuted MNIST benchmark,[0],[0]
"In contrast to that, when enabling synaptic consolidation, with a sensible choice for c > 0, the same network retains high classification accuracy on Task 1 while being trained on 9 additional tasks (Fig. 4).",5.2. Permuted MNIST benchmark,[0],[0]
"Moreover, the network learns to solve all other tasks with high accuracy and performs only slightly worse than a network which had trained on all data simultaneously (Fig. 4).",5.2. Permuted MNIST benchmark,[0],[0]
"Finally, these results were consistent across training and validation error and comparable to the results reported with EWC (Kirkpatrick et al., 2017).
",5.2. Permuted MNIST benchmark,[0],[0]
"To gain a better understanding of the synaptic dynamics during training, we visualized the pairwise correlations of the ωµk across the different tasks µ (Fig. 5b).",5.2. Permuted MNIST benchmark,[0],[0]
"We found that without consolidation, the ωµk in the second hidden layer are correlated across tasks which is likely to be the cause of catastrophic forgetting.",5.2. Permuted MNIST benchmark,[0],[0]
"With consolidation, however, these sets of synapses contributing to decreasing the loss are largely uncorrelated across tasks, thus avoiding interference when updating weights to solve new tasks.",5.2. Permuted MNIST benchmark,[0],[0]
"To evaluate whether synaptic consolidation dynamics would also prevent catastrophic forgetting in more complex datasets and larger models, we experimented with a continual learning task based on CIFAR-10 and CIFAR100.",5.3. Split CIFAR-10/CIFAR-100 benchmark,[0],[0]
"Specifically, we trained a CNN (4 convolutional, followed by 2 dense layers with dropout; see Appendix for details).",5.3. Split CIFAR-10/CIFAR-100 benchmark,[0],[0]
"We used the same multi-head setup as in the case of split MNIST using Adam (η = 1 × 10−3, β1 = 0.9, β2 = 0.999, minibatch size 256).",5.3. Split CIFAR-10/CIFAR-100 benchmark,[0],[0]
"First, we trained the network for 60 epochs on the full CIFAR-10 dataset (Task 1) and sequentially on 5 additional tasks each corresponding to 10 consecutive classes from the CIFAR-100 dataset (Fig. 6).",5.3. Split CIFAR-10/CIFAR-100 benchmark,[0],[0]
"To determine the best c, we performed this experiment for different values in the parameter range 1×10−3 < c < 0.1.",5.3. Split CIFAR-10/CIFAR-100 benchmark,[0],[0]
Between tasks the state of the optimizer was reset.,5.3. Split CIFAR-10/CIFAR-100 benchmark,[0],[0]
"Moreover, we obtained values for two specific control cases.",5.3. Split CIFAR-10/CIFAR-100 benchmark,[0],[0]
On the one hand we trained the same network with c = 0 on all tasks consecutively.,5.3. Split CIFAR-10/CIFAR-100 benchmark,[0],[0]
On the other hand we trained the same network from scratch on each task individually to assess generalization across tasks.,5.3. Split CIFAR-10/CIFAR-100 benchmark,[0],[0]
"Finally, to assess the magnitude of statistical fluctuations in accuracy, all runs were repeated n = 5 times.
",5.3. Split CIFAR-10/CIFAR-100 benchmark,[0],[0]
"We found that after training on all tasks, networks with consolidation showed similar validation accuracy across all tasks, whereas accuracy in the network without consolidation showed a clear age dependent decline in which old tasks were solved with lower accuracy (Fig. 6).",5.3. Split CIFAR-10/CIFAR-100 benchmark,[0],[0]
"Importantly, the performance of networks trained with consolidation was always better than without consolidation, except on the last task.",5.3. Split CIFAR-10/CIFAR-100 benchmark,[0],[0]
"Finally, when comparing the performance of networks trained with consolidation on all tasks with net-
works trained from scratch only on a single task (Fig. 6; green vs gray), the former either significantly outperformed the latter or yielded the same validation accuracy, while this trend was reversed in training accuracy.",5.3. Split CIFAR-10/CIFAR-100 benchmark,[0],[0]
This suggests that networks without consolidation are more prone to over fitting.,5.3. Split CIFAR-10/CIFAR-100 benchmark,[0],[0]
"The only exception to that rule was Task 1, CIFAR-10 which is presumably due to its 10× larger number of examples per class.",5.3. Split CIFAR-10/CIFAR-100 benchmark,[0],[0]
"In summary, we found that consolidation not only protected old memories from being slowly forgotten over time, but also allowed networks to generalize better on new tasks with limited data.",5.3. Split CIFAR-10/CIFAR-100 benchmark,[0],[0]
We have shown that the problem of catastrophic forgetting commonly encountered in continual learning scenarios can be alleviated by allowing individual synapses to estimate their importance for solving past tasks.,6. Discussion,[0],[0]
"Then by penalizing changes to the most important synapses, novel tasks can be learned with minimal interference to previously learned tasks.
",6. Discussion,[0],[0]
The regularization penalty is similar to EWC as recently introduced by Kirkpatrick et al. (2017).,6. Discussion,[0],[0]
"However, our approach computes the per-synapse consolidation strength in an online fashion and over the entire learning trajectory in parameter space, whereas for EWC synaptic importance is computed offline as the Fisher information at the minimum of the loss for a designated task.",6. Discussion,[0],[0]
"Despite this difference, these two approaches yielded similar performance on the permuted MNIST benchmark which may be due to correlations between the two different importance measures.
",6. Discussion,[0],[0]
"Our approach requires individual synapses to not simply correspond to single scalar synaptic weights, but rather act as higher dimensional dynamical systems in their own right.",6. Discussion,[0],[0]
Such higher dimensional state enables each of our synapses to intelligently accumulate task relevant information during training and retain a memory of previous parameter values.,6. Discussion,[0],[0]
"While we make no claim that biological synapses behave like the intelligent synapses of our model, a wealth of experimental data in neurobiology suggests that biological synapses act in much more complex ways than the artificial scalar synapses that dominate current machine learning models.",6. Discussion,[0],[0]
"In essence, whether synaptic changes occur, and whether they are made permanent, or left to ultimately decay, can be controlled by many different biological factors.",6. Discussion,[0],[0]
"For instance, the induction of synaptic plasticity may depend on the history and the synaptic state of individual synapses (Montgomery & Madison, 2002).",6. Discussion,[0],[0]
"Moreover, recent synaptic changes may decay on the timescale of hours unless specific plasticity related chemical factors are released.",6. Discussion,[0],[0]
"These chemical factors are thought to encode the valence or novelty of a recent change (Redondo & Morris, 2011).",6. Discussion,[0],[0]
"Finally, recent synaptic changes can be reset by stereotypical neural activity, whereas older synaptic memories become increasingly insensitive to reversal (Zhou et al., 2003).
",6. Discussion,[0],[0]
"Here, we introduced one specific higher dimensional synaptic model to tackle a specific problem: catastrophic forgetting in continual learning.",6. Discussion,[0],[0]
"However, this suggests new directions of research in which we mirror neurobiology to endow individual synapses with potentially complex dynamical properties, that can be exploited to intelligently control learning dynamics in neural networks.",6. Discussion,[0],[0]
"In essence, in machine learning, in addition to adding depth to our networks, we may need to add intelligence to our synapses.",6. Discussion,[0],[0]
The authors thank Subhaneil Lahiri for helpful discussions.,Acknowledgements,[0],[0]
FZ was supported by the SNSF (Swiss National Science Foundation) and the Wellcome Trust.,Acknowledgements,[0],[0]
BP was supported by a Stanford MBC IGERT Fellowship and Stanford Interdisciplinary Graduate Fellowship.,Acknowledgements,[0],[0]
"SG was supported by the Burroughs Wellcome, McKnight, Simons and James S. McDonnell foundations and the Office of Naval Research.",Acknowledgements,[0],[0]
"While deep learning has led to remarkable advances across diverse applications, it struggles in domains where the data distribution changes over the course of learning.",abstractText,[0],[0]
"In stark contrast, biological neural networks continually adapt to changing domains, possibly by leveraging complex molecular machinery to solve many tasks simultaneously.",abstractText,[0],[0]
"In this study, we introduce intelligent synapses that bring some of this biological complexity into artificial neural networks.",abstractText,[0],[0]
"Each synapse accumulates task relevant information over time, and exploits this information to rapidly store new memories without forgetting old ones.",abstractText,[0],[0]
"We evaluate our approach on continual learning of classification tasks, and show that it dramatically reduces forgetting while maintaining computational efficiency.",abstractText,[0],[0]
Continual Learning Through Synaptic Intelligence,title,[0],[0]
"Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 167–176 Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics",text,[0],[0]
"Geolocation is an essential component of applications such as traffic monitoring (Emadi et al., 2017), human mobility pattern analysis (McNeill et al., 2016; Dredze et al., 2016) and disaster response (Ashktorab et al., 2014; Wakamiya et al., 2016), as well as targeted advertising (Anagnostopoulos et al., 2016) and local recommender systems (Ho et al., 2012).",1 Introduction,[0],[0]
"Although Twitter provides users with the means to geotag their messages, less than 1% of users opt to turn on geotagging, so thirdparty service providers tend to use profile data, text content and network information to infer the location of users.",1 Introduction,[0],[0]
"Text content is the most widely used source of geolocation information, due to its prevalence across social media services.
",1 Introduction,[0],[0]
Text-based geolocation systems use the geographical bias of language to infer the location of a user or message using models trained on geotagged posts.,1 Introduction,[0],[0]
"The models often use a representation of text (e.g. based on a bag-of-words, convolutional or recurrent model) to predict the location either in real-valued latitude/longitude coordinate space or
in discretised region-based space, using regression or classification, respectively.",1 Introduction,[0],[0]
"Regression models, as a consequence of minimising squared loss for a unimodal distribution, predict inputs with multiple targets to lie between the targets (e.g. a user who mentions content in both NYC and LA is predicted to be in the centre of the U.S.).",1 Introduction,[0],[0]
"Classification models, while eliminating this problem by predicting a more granular target, don’t provide fine-grained predictions (e.g. specific locations in NYC), and also require heuristic discretisation of locations into regions (e.g. using clustering).
",1 Introduction,[0],[0]
Mixture Density Networks (“MDNs”: Bishop (1994)) alleviate these problems by representing location as a mixture of Gaussian distributions.,1 Introduction,[0],[0]
"Given a text input, an MDN can generate a mixture model in the form of a probability distribution over all location points.",1 Introduction,[0],[0]
"In the example of a user who talks about both NYC and LA, e.g., the model will predict a strong Gaussian component in NYC and another one in LA, and also provide an estimate of uncertainty over all the coordinate space.
",1 Introduction,[0],[0]
"Although MDNs are not new, they have not found widespread use in inverse regression problems where for a single input, multiple correct outputs are possible.",1 Introduction,[0],[0]
"Given the integration of NLP technologies into devices (e.g. phones or robots with natural language interfaces) is growing quickly, there is a potential need for interfacing language with continuous variables as input or target.",1 Introduction,[0],[0]
"MDNs can also be used in general text regression problems such as risk assessment (Wang and Hua, 2014), sentiment analysis (Joshi et al., 2010) and loan rate prediction (Bitvai and Cohn, 2015), not only to improve prediction but also to use the mixture model as a representation for the continuous variables.",1 Introduction,[0],[0]
"We apply MDNs to geotagged Twitter data in two different settings: (a) predicting location given text; and (b) predicting text given location.
167
Geotagged text content is not only useful in geolocation, but can also be used in lexical dialectology.",1 Introduction,[0],[0]
"Lexical dialectology is (in part) the converse of text-based geolocation (Eisenstein, 2015): instead of predicting location from language, language (e.g. dialect terms) are predicted from a given location.",1 Introduction,[0],[0]
"This is a much more challenging task as the lexical items are not known beforehand, and there is no notion of dialect regions in the continuous space of latitude/longitude coordinates.",1 Introduction,[0],[0]
"A lexical dialectology model should not only be able to predict dialect terms but also be able to automatically learn dialect regions.
",1 Introduction,[0],[0]
"In this work, we use bivariate Gaussian mixtures over geotagged Twitter data in two different settings, and demonstrate their use for geolocation and lexical dialectology.",1 Introduction,[0],[0]
"Our contributions are as follows: (1) we propose a continuous representation of location using bivariate Gaussian mixtures; (2) we show that our geolocation model outperforms regression-based models and achieves comparable results with classification models, but with added uncertainty over the continuous output space; (3) we show that our lexical dialectology model is able to predict geographical dialect terms from latitude/longitude input with state-of-the-art accuracy; and (4) we show that the automatically learned Gaussian regions match expert-generated dialect regions of the U.S.1",1 Introduction,[0],[0]
Text-based geolocation models are defined as either a regression or a classification problem.,2.1 Text-based Geolocation,[0],[0]
"In regression geolocation, the model learns to predict a real-valued latitude/longitude from a text input.",2.1 Text-based Geolocation,[0],[0]
"This is a very challenging task for data types such as Twitter, as they are often heavily biased toward population centres and urban areas, and far from uniform.",2.1 Text-based Geolocation,[0],[0]
"As an example, Norwalk is the name of a few cities in the U.S among which Norwalk, California (West Coast) and Norwalk, Connecticut (East Coast) are the two most populous cities.",2.1 Text-based Geolocation,[0],[0]
"Assuming that occurrences of the city’s name are almost equal in both city regions within the training set, a trained regression-based geolocation model given Norwalk as input, would geolocate it to a point in the middle of the U.S. instead of choosing one of the cities.",2.1 Text-based Geolocation,[0],[0]
"In the machine learning literature,
1Code available at https://github.com/afshinrahimi/geomdn
regression problems where there are multiple realvalued outputs for a given input are called inverse problems (Bishop, 1994).",2.1 Text-based Geolocation,[0],[0]
"Here, standard regression models predict an average point in the middle of all training target points to minimise squared error loss.",2.1 Text-based Geolocation,[0],[0]
"Bishop (1994) proposes density mixture networks to model such inverse problems, as we discuss in detail in Section 3.
",2.1 Text-based Geolocation,[0],[0]
"In addition, non-Bayesian interpretations of regression models, which are often used in practice, don’t produce any prediction of uncertainty, so other than the predicted point, we have little idea where else the term could have high or low probability.",2.1 Text-based Geolocation,[0],[0]
"Priedhorsky et al. (2014) propose a Gaussian Mixture Model (GMM) approach instead of squared loss regression, whereby they learn a mixture of bivariate Gaussian distributions for each individual n-gram in the training set.",2.1 Text-based Geolocation,[0],[0]
"During prediction, they add the Gaussian mixture of each ngram in the input text, resulting in a new Gaussian mixture which can be used to predict a coordinate with associated uncertainty.",2.1 Text-based Geolocation,[0],[0]
"To add the mixture components they use a weighted sum, where the weight of each n-gram is assigned by several heuristic features.",2.1 Text-based Geolocation,[0],[0]
"Learning a GMM for each n-gram is resource-intensive if the size of the training set — and thus the number of n-grams — is large.
",2.1 Text-based Geolocation,[0],[0]
"Assuming sufficient training samples containing the term Norwalk in the two main, a trained classification model would, given this term as input, predict a probability distribution over all regions, and assign higher probabilities to the regions containing the two major cities.",2.1 Text-based Geolocation,[0],[0]
"The challenge, though, is that the coordinates in the training data must first be partitioned into regions using administrative regions (Cheng et al., 2010; Hecht et al., 2011; Kinsella et al., 2011; Han et al., 2012, 2014), a uniform grid (Serdyukov et al., 2009), or a clustering method such as a k-d tree (Wing and Baldridge, 2011) or K-means (Rahimi et al., to appear).",2.1 Text-based Geolocation,[0],[0]
The cluster/region labels can then be used as targets.,2.1 Text-based Geolocation,[0],[0]
"Once we have a prediction about where a user is more likely to be from, there is no more information about the coordinates inside the predicted region.",2.1 Text-based Geolocation,[0],[0]
"If a region that contains Wyoming is predicted as the home location of a user, we have no idea which city or county within Wyoming the user might be from, unless we retrain the model using a more fine-grained discretisation or a hierarchical discretisation (Wing and Baldridge, 2014), which is both time-consuming and challenging due to data
sparseness.",2.1 Text-based Geolocation,[0],[0]
"The traditional linguistic approach to lexical dialectology is to find the geographical distributions of known contrast sets such as {you, yall, yinz}: (Labov et al., 2005; Nerbonne et al., 2008; Gonçalves and Sánchez, 2014; Doyle, 2014; Huang et al., 2015; Nguyen and Eisenstein, to appear).",2.2 Lexical Dialectology,[0],[0]
This usually involves surveying a large geographically-uniform sample of people from different locations and analysing where each known alternative is used more frequently.,2.2 Lexical Dialectology,[0],[0]
"Then, the coordinates are clustered heuristically into dialect regions, based on the lexical choices of users in each region relative to the contrast set.",2.2 Lexical Dialectology,[0],[0]
"This processing is very costly and time-consuming, and relies critically on knowing the lexical alternatives a priori.",2.2 Lexical Dialectology,[0],[0]
"For example, it would require a priori knowledge of the fact that people in different regions of the US use pop and soda to refer to the same type of drink, and a posteriori analysis of the empirical geographical distribution of the different terms.",2.2 Lexical Dialectology,[0],[0]
"Language, particularly in social media and among younger speakers, is evolving so quickly, in ways that can be measured over large-scale data samples such as Twitter, that we ideally want to be able to infer such contrast sets dynamically.",2.2 Lexical Dialectology,[0],[0]
The first step in automatically collecting dialect words is to find terms that are disproportionately distributed in different locations.,2.2 Lexical Dialectology,[0],[0]
"The two predominant approaches to this problem are model-based (Eisenstein et al., 2010; Ahmed et al., 2013; Eisenstein, 2015) and through the use of statistical metrics (Monroe et al., 2008; Cook et al., 2014).",2.2 Lexical Dialectology,[0],[0]
"Model-based approaches use a topic model, e.g., to extract region-specific topics, and from this, predict the probability of seeing a word given a geographical region (Eisenstein et al., 2010).",2.2 Lexical Dialectology,[0],[0]
"However, there are scalability issues, limiting the utility of such models.
",2.2 Lexical Dialectology,[0],[0]
"In this paper, we propose a neural network architecture that learns a mixture of Gaussian distributions as its activation function, and predicts both locations from word-based inputs (geolocation), and words from location-based inputs (lexical dialectology).",2.2 Lexical Dialectology,[0],[0]
"A bivariate Gaussian distribution is a probability distribution over 2d space (in our case, a lat-
itude/longitude coordinate pair).",3.1 Bivariate Gaussian Distribution,[0],[0]
"The probability mass function is given by:
N (x|µ,Σ)",3.1 Bivariate Gaussian Distribution,[0],[0]
"= 1 (2π) 1 |Σ|1/2
exp { −1
2 (x− µ)ᵀΣ−1(x− µ) } where µ is the 2-dimensional mean vector, the matrix Σ = ( σ12 ρ12σ1σ2
ρ12σ1σ2 σ22
) is the covariance ma-
trix, and |Σ| is its determinant.",3.1 Bivariate Gaussian Distribution,[0],[0]
"σ1 and σ2 are the standard deviations of the two dimensions, and ρ12 is the covariance.",3.1 Bivariate Gaussian Distribution,[0],[0]
x is a latitude/longitude coordinate whose probability we are seeking to predict.,3.1 Bivariate Gaussian Distribution,[0],[0]
"A mixture of Gaussians is a probabilistic model to represent subpopulations within a global population in the form of a weighted sum of K Gaussian distributions, where a higher weight with a component Gaussian indicates stronger association with that component.",3.2 Mixtures of Gaussians,[0],[0]
"The probability mass function of a Gaussian mixture model is given by:
P(x) = K∑ k=1 πkN",3.2 Mixtures of Gaussians,[0],[0]
"(x|µk,Σk)
where ∑K
k=1 πk = 1, and the number of components K is a hyper-parameter.
",3.2 Mixtures of Gaussians,[0],[0]
3.3 Mixture Density Network (MDN),3.2 Mixtures of Gaussians,[0],[0]
"A mixture density network (“MDN”: Bishop (1994)) is a latent variable model where the conditional probability of p(y|x) is modelled as a mixture of K Gaussians where the mixing coefficients π and the parameters of Gaussian distributions µ and Σ are computed as a function of input using a neural network:
P(y|x) = K∑ k=1",3.2 Mixtures of Gaussians,[0],[0]
"πk(x)N ( y|µk(x),Σk(x) )",3.2 Mixtures of Gaussians,[0],[0]
"In the bivariate case of latitude/longitude, the number of parameters of each Gaussian is 6 (πk(x), µ1k(x), µ2k(x), ρk(x), σ1k(x), σ2k(x)), which are learnt in the output layer of a regular neural network as a function of input x.",3.2 Mixtures of Gaussians,[0],[0]
The output size of the network for K components would be 6 × K.,3.2 Mixtures of Gaussians,[0],[0]
"The output of an MDN for N samples (e.g. where N is the mini-batch size) is an N × 6K matrix which is then sliced and reshaped into (N × 2 × K), (N × 2 × K), (N × 1 × K)
and (N × 1 × K) matrices, providing the model parameters µ, σ, ρ and π.",3.2 Mixtures of Gaussians,[0],[0]
"Each parameter type has its own constraints: σ (the standard deviation) should be positive, ρ (the correlation) should be in the interval",3.2 Mixtures of Gaussians,[0],[0]
"[−1, 1] and π should be positive and sum to one, as a probability distribution.",3.2 Mixtures of Gaussians,[0],[0]
"To force these constraints, the following transformations are often applied to each parameter set:
σ ∼ SoftPlus(σ′) = log(exp(σ′) + 1) ∈ (0,+∞) π ∼ SoftMax(π′) ρ ∼ SoftSign(ρ′) = ρ′
1 + |ρ′| ∈",3.2 Mixtures of Gaussians,[0],[0]
"[−1, 1]
As an alternative, it’s possible to use transformations like exp for σ and tanh for ρ.",3.2 Mixtures of Gaussians,[0],[0]
"After applying the transformations to enforce the range constraints, the negative log likelihood loss of each sample x given a 2d coordinate label y is computed as:
L(y|x) =",3.2 Mixtures of Gaussians,[0],[0]
"− log { K∑ k=1 πk(x)N ( y|µk(x),Σk(x) )}",3.2 Mixtures of Gaussians,[0],[0]
"To predict a location, given an unseen input, the output of the network is reshaped into a mixture of Gaussians and µk, one of the K components’ µ is chosen as the prediction.",3.2 Mixtures of Gaussians,[0],[0]
"The selection criteria is either based on the strongest component with highest π, or the component that maximises the overall mixture probability:
max µi∈{µ1...µK} K∑ k=1 πkN (µi|µk,Σk)
For further details on selection criteria, see Bishop (1994).",3.2 Mixtures of Gaussians,[0],[0]
"Parameters (MDN-SHARED)
",3.4 Mixture Density Network with Shared,[0],[0]
"In the original MDN model proposed by Bishop (1994), the parameters of the mixture model are separate functions of input, which is appropriate when the inputs and outputs directly relate to each other, but in the case of geolocation or lexical dialectology, the relationship between inputs and outputs is not so obvious.",3.4 Mixture Density Network with Shared,[0],[0]
"As a result, it might be a difficult task for the model to learn all the parameters of each sample correctly.",3.4 Mixture Density Network with Shared,[0],[0]
"Instead of using the output to predict all the parameters, we share µ and Σ among all samples as parameters of the output layer, and only use the input to predict π, the mixture probabilities, using a SoftMax layer.",3.4 Mixture Density Network with Shared,[0],[0]
"We
initialise µ by applying K-means clustering to the training coordinates and setting each value of µ to the centroids of the K clusters; we initialise Σ randomly between 0 and 10.",3.4 Mixture Density Network with Shared,[0],[0]
"We use the original cost function to update the weight matrices, biases and the global shared parameters of the mixture model through backpropagation.",3.4 Mixture Density Network with Shared,[0],[0]
Prediction is performed in the same way as for MDN.,3.4 Mixture Density Network with Shared,[0],[0]
Gaussian mixtures are usually used as the output layer in neural networks (as in MDN) for inverse regression problems.,3.5 Continuous Representation of Location,[0],[0]
We extend their application by using them as an input representation when the input is a multidimensional continuous variable.,3.5 Continuous Representation of Location,[0],[0]
"In problems such as lexical dialectology, the input is real-valued 2d coordinates, and the goal is to predict dialect words from a given location.",3.5 Continuous Representation of Location,[0],[0]
Small differences in latitude/longitude may result in big shifts in language use (e.g. in regions such as Switzerland or Gibraltar).,3.5 Continuous Representation of Location,[0],[0]
"One way to model this is to discretise the input space (similar to the discretisation of the output space in classification), with the significant downside that the model is not able to learn/fine-tune regions in a data-driven way.",3.5 Continuous Representation of Location,[0],[0]
"A better solution is to use aK component Gaussian mixture representation of location, where µ and Σ are shared among all samples, and the output of the layer is the probability of input in each of the mixture components.",3.5 Continuous Representation of Location,[0],[0]
"Note that in this representation, there is no need for π parameters as we just need to represent the association of an input location to K regions, which will then be used as input to the next layer of a neural network and used to predict the targets.",3.5 Continuous Representation of Location,[0],[0]
We use this continuous representation of location to predict dialect words from location input.,3.5 Continuous Representation of Location,[0],[0]
"We apply the two described MDN models on two widely-used geotagged Twitter datasets for geolocation, and compare the results with state-of-the-art classification and regression baselines.",4 Experiments,[0],[0]
"Also, we use the mixture of Gaussian representation of location to predict dialect terms from coordinates.",4 Experiments,[0],[0]
"In our experiments, we use two existing Twitter user geolocation datasets: (1) GEOTEXT (Eisenstein et al., 2010), and (2) TWITTER-US (Roller et al., 2012).",4.1 Data,[0],[0]
"Each dataset has fixed training, devel-
opment and test partitions, and a user is represented by the concatenation of their tweets, and labelled with the latitude/longitude of the first collected geotagged tweet.2 GEOTEXT and TWITTER-US cover the continental US with 9k, 449k users, respectively.3
DARE is a dialect-term dataset derived from the Dictionary of American Regional English (Cassidy, 1985) by Rahimi et al. (to appear).",4.1 Data,[0],[0]
"DARE consists of dialect regions, terms and the meaning of each term.4 It represents the aggregation of a number of dialectal surveys over different regions of the U.S., to identify shared dialect regions.",4.1 Data,[0],[0]
"Because the dialect regions in DARE maps are not machine readable, populous cities within each dialect region are manually extracted and associated with their dialect region terms.",4.1 Data,[0],[0]
"The dataset is made up of around 4.3k dialect terms across 99 U.S. dialect regions.
",4.1 Data,[0],[0]
"2This geolocation representation is naive, but was made by the creators of the original datasets and has been used by others.",4.1 Data,[0],[0]
"It has been preserved in this work for comparability with the results of others, despite misgivings about whether this is a faithful representation of the location for a given user.
3The datasets can be obtained from https://github. com/utcompling/textgrounder.
",4.1 Data,[0],[0]
4http://www.daredictionary.com/,4.1 Data,[0],[0]
"We use a 3-layer neural network as shown in Figure 1a where the input is the l2 normalised bag-ofwords model of a given user with stop words, @- mentions and words with document frequency less than 10 removed.",4.2 Geolocation,[0],[0]
The input is fed to a hidden layer with tanh nonlinearity that produces the output of the network (with no nonlinearity applied).,4.2 Geolocation,[0],[0]
"The output is the collection of Gaussian mixture parameters (µ,Σ, π) from MDN.",4.2 Geolocation,[0],[0]
"For prediction, the µk of the mixture component which has the highest probability within the mixture component is selected.",4.2 Geolocation,[0],[0]
"In the case of MDN-SHARED, the output is only π, a vector with size K, but the output layer contains extra global parameters µ and Σ (σlat, σlon, ρ) which are shared between all the samples.",4.2 Geolocation,[0],[0]
"The negative log likelihood objective is optimised using Adam (Kingma and Ba, 2014) and early stopping is used to prevent overfitting.",4.2 Geolocation,[0],[0]
The hidden layer is subject to drop-out and elastic net regularisation (with equal l1 and l2 shares).,4.2 Geolocation,[0],[0]
"As our baseline, we used a multilayer perceptron regressor with the same input and hidden architecture but with a 2d output with linear activation that predicts the location from text input.",4.2 Geolocation,[0],[0]
"The regularisation and drop-out rate, hidden layer size and the number of Gaussian components K (for MDN and MDN-SHARED) are tuned over the development set of each dataset, as shown in Table 1.
",4.2 Geolocation,[0],[0]
"We evaluate the predictions of the geolocation models based on three measures (following Cheng et al. (2010) and Eisenstein et al. (2010)):
1.",4.2 Geolocation,[0],[0]
"the classification accuracy within a 161km (= 100 mile) radius of the actual location (“Acc@161”); i.e., if the predicted location is within 161km of the actual location, it is considered to be correct 2.",4.2 Geolocation,[0],[0]
"the mean error (“Mean”) between the predicted location and the actual location of the user, in kilometres 3.",4.2 Geolocation,[0],[0]
"the median error (“Median”) between the predicted location and the actual location of the user, in kilometres",4.2 Geolocation,[0],[0]
"To predict dialect words from location, we use a 4-layer neural network as shown in Figure 1b.",4.3 Lexical Dialectology,[0],[0]
"The input is a latitude/longitude coordinate, the first hidden layer is a Gaussian mixture with K components which has µ and Σ as its parameters and produces a probability for each component as an
activation function, the second hidden layer with tanh nonlinearity captures the association between different Gaussians, and the output is a SoftMax layer which results in a probability distribution over the vocabulary.",4.3 Lexical Dialectology,[0],[0]
"For a user label, we use an l1 normalised bag-of-words representation of its text content and use binary tf and idf for term-weighting.",4.3 Lexical Dialectology,[0],[0]
The model should learn to predict the probability distribution over the vocabulary and so be capable of predicting dialect words with a higher probability.,4.3 Lexical Dialectology,[0],[0]
"It also learns regions (parameters of K Gaussians) that represent dialect regions.
",4.3 Lexical Dialectology,[0],[0]
"We evaluate the lexical dialectology model (MDN-layer) using perplexity of the predicted unigram distribution, and compare it with a baseline where the Gaussian mixture layer is replaced with a tanh hidden layer (tanh-layer).",4.3 Lexical Dialectology,[0],[0]
"Also we retrieve words given points within a region from the DAREDS dataset, and measure recall with respect to relevant dialect terms from DAREDS.",4.3 Lexical Dialectology,[0],[0]
"To do that, we randomly sample P = 10000 latitude/longitude points from the training set and predict the corresponding word distribution.",4.3 Lexical Dialectology,[0],[0]
"To come up with a ranking over words given region r as query, we use the following measure:
score(wi|r) = 1 N ∑ pj∈r log(P",4.3 Lexical Dialectology,[0],[0]
"(wi|pj))
",4.3 Lexical Dialectology,[0],[0]
− 1 P P∑ j=1 log(P,4.3 Lexical Dialectology,[0],[0]
"(wi|pj))
",4.3 Lexical Dialectology,[0],[0]
whereN equals the number of points (out of 10000) inside the query dialect region r and P equals the total number of points (here 10000).,4.3 Lexical Dialectology,[0],[0]
"For example, if we are querying dialect terms from dialect region South (r), N is the number of randomly selected points that fall within the constituent states of South.",4.3 Lexical Dialectology,[0],[0]
"score(wi|r) measures the (log) probability ratio of a word wi inside region r compared to its global score: if a word is local to region r, the ratio will be higher.",4.3 Lexical Dialectology,[0],[0]
We use this measure to create a ranking over the vocabulary from which we measure precision and recall at k given gold-standard dialect terms in DAREDS.,4.3 Lexical Dialectology,[0],[0]
"The performance of Regression, MDN and MDN-SHARED, along with several state-of-the-art classification models, is shown in Table 2.",5.1 Geolocation,[0],[0]
"The
MDN and MDN-SHARED models clearly outperform Regression, and achieve competitive or slightly worse results than the classification models but provide uncertainty over the whole output space.",5.1 Geolocation,[0],[0]
"The geographical distribution of error for MDN-SHARED over the development set of TWITTER-US is shown in Figure 3, indicating larger errors in MidWest and particularly in North Pacific regions (e.g. Oregon).",5.1 Geolocation,[0],[0]
"The perplexity of the lexical dialectology model using Gaussian mixture representation (MDN-layer) is 840 for the 54k vocabulary of TWITTER-US dataset, 1% lower than a similar network architecture with a tanh hidden layer (tanh-layer), which is not a significant improvement.",5.2 Dialectology,[0],[0]
Also we evaluated the model using recall at k and compared it to the tanh-layer model which again is competitive with tanh-layer but with the advantage of learning dialect regions simultaneously.,5.2 Dialectology,[0],[0]
"Because the DARE dialect terms are not used frequently in Twitter, many of the words are not covered in our dataset, despite its size.",5.2 Dialectology,[0],[0]
"However, our model is able to retrieve dialect terms that are distinctly associated with regions.",5.2 Dialectology,[0],[0]
"The top dialect words for regions New York, Louisiana, Illinois and Pennsylvania are shown in Table 3, and include named entities, dialect words and local hashtags.",5.2 Dialectology,[0],[0]
"We also visualised the learned Gaussians of the dialectology model in Figure 2, which as expected show several smaller regions (Gaussians with higher σ) and larger regions in lower populated areas.",5.2 Dialectology,[0],[0]
"It is interesting to see that the shape of the learned Gaussians matches natural borders such as coastal regions.
",5.2 Dialectology,[0],[0]
"We also visualised the log probability of dialect terms hella (an intensifier mainly used in Northern California) and yall (means “you all”, used in Southern U.S.) resulting from the Gaussian representation model.",5.2 Dialectology,[0],[0]
"As shown in Figure 5, the heatmap matches the expected regions.",5.2 Dialectology,[0],[0]
"We proposed a continuous representation of location using mixture of Gaussians and applied it to geotagged Twitter data in two different settings: (1) geolocation of social media users, and (2) lexical dialectology.",6 Conclusion,[0],[0]
"We used MDN (Bishop, 1994) in a multilayer neural network as a geolocation model
GEOTEXT TWITTER-US
regul.",6 Conclusion,[0],[0]
dropout hidden K regul.,6 Conclusion,[0],[0]
"dropout hidden K
Baseline (Regression) 0 0",6 Conclusion,[0],[0]
"(100, 50) — 10−5 0 (100, 50) — Proposed method (MDN) 0 0.5 100 100 10−5 0 300 100 Proposed method (MDN-SHARED) 0 0 100 300 0 0 900 900
CLASSIFICATION METHODS
and showed that it outperforms regression models by a large margin.",6 Conclusion,[0],[0]
"There is also very recent work (Iso et al., 2017) in tweet-level geolocation that shows the effectiveness of MDN.
",6 Conclusion,[0],[0]
"We modified MDN by sharing the parameters of
the Gaussian mixtures in MDN-SHARED and improved upon MDN, achieving competetive results with state-of-the-art classification models.",6 Conclusion,[0],[0]
"We also applied the Gaussian mixture representation to predict dialect words from location, and showed that it
MNWA MT ID ND MEWIOR SD MI NHVT
NYWY IANE MA IL PA CTRI
CA
NV UT OHIN NJCO WVMOKS DEMDVAKY DC
AZ OKNM TN NC
TX
AR SC AL GAMSLA
FL
0 600 1200 1800 2400 3000 3600 4200 4800 er ro ri n km
(a) hella (an intensifier) mostly used in Northern California, also the name of a company in Illinois.
",6 Conclusion,[0],[0]
is competitive with simple tanh activation in terms of both perplexity of the predicted unigram model and also recall at k at retrieving DARE dialect words by location input.,6 Conclusion,[0],[0]
"Furthermore we showed that the learned Gaussian mixtures have intereting properties such as covering high population density regions (e.g. NYC and LA) with a larger number of small Gaussians, and a smaller number of larger
Gaussians in low density areas (e.g. the midwest).",6 Conclusion,[0],[0]
"Although we applied the mixture of Gaussians to location data, it can be used in other settings where the input or output are from a continuous multivariate distribution.",6 Conclusion,[0],[0]
"For example it can be applied to predict financial risk (Wang and Hua, 2014) and sentiment (Joshi et al., 2010) given text.",6 Conclusion,[0],[0]
"We showed that when a global structure exists (e.g. population centres, in the case of geolocation) it is better to share the global parameters of the mixture model to improve generalisation.",6 Conclusion,[0],[0]
"In this work, we used the bivariate Gaussian distribution in the MDN’s mixture leaving the use of other distributions which might better suit the geolocation task for future research.",6 Conclusion,[0],[0]
We thank the anonymous reviewers for their valuable feedback.,Acknowledgments,[0],[0]
This work was supported in part by the Australian Research Council.,Acknowledgments,[0],[0]
"We propose a method for embedding twodimensional locations in a continuous vector space using a neural network-based model incorporating mixtures of Gaussian distributions, presenting two model variants for text-based geolocation and lexical dialectology.",abstractText,[0],[0]
"Evaluated over Twitter data, the proposed model outperforms conventional regression-based geolocation and provides a better estimate of uncertainty.",abstractText,[0],[0]
"We also show the effectiveness of the representation for predicting words from location in lexical dialectology, and evaluate it using the DARE dataset.",abstractText,[0],[0]
Continuous Representation of Location for Geolocation and Lexical Dialectology using Mixture Density Networks,title,[0],[0]
Efficient inference and robust density estimation are two important goals in unsupervised learning.,1. Introduction,[0],[0]
"In fact, they can be unified from the perspective of learning desired target distributions.",1. Introduction,[0],[0]
"In inference problems, one targets to learn a tractable distribution for a latent variable that is close to a given unnormalized distribution (e.g., a posterior distribution in a Bayesian model).",1. Introduction,[0],[0]
"In density estimation, one tries to learn an unknown data distribution only based on the samples from it.",1. Introduction,[0],[0]
"It is also helpful to make a distinction between two types of representations for learning distributions: explicit and implicit methods (Mohamed & Lakshminarayanan, 2017).",1. Introduction,[0],[0]
"Explicit methods provide a prescribed parametric form for the distribution, while implicit methods
1SUNY at Buffalo 2Duke University.",1. Introduction,[0],[0]
"Correspondence to: Changyou Chen <cchangyou@gmail.com>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
learn a stochastic procedure to directly generate samples from the unknown distribution.
",1. Introduction,[0],[0]
Existing deep generative models can easily be identified from this taxonomy.,1. Introduction,[0],[0]
"For example, the standard variational autoencoder (VAE) (Kingma & Welling, 2014; Rezende et al., 2014) is an important example of an explicit inference method.",1. Introduction,[0],[0]
"Within the inference arm (encoder) of a VAE, recent research has focused on improving the accuracy of the approximation to the posterior distribution on latent variables (codes) using normalizing flow (NF) (Rezende & Mohamed, 2015).",1. Introduction,[0],[0]
"NF is particularly interesting due to its ability to approximate the posterior distribution arbitrarily well, while maintaining explicit parametric forms.",1. Introduction,[0],[0]
"On the other hand, Stein VAE (Feng et al., 2017; Pu et al., 2017) is an implicit inference method, as it only learns to draw samples to approximate posteriors, without assuming an explicit form for the distribution..",1. Introduction,[0],[0]
"For density estimation on observed data, the generative adversarial network (GAN) can be regarded as an implicit density estimation method (Ranganath et al., 2016; Huszár, 2017; Mohamed & Lakshminarayanan, 2017), in the sense that one may sample from the distribution (regarded as a representation of the unknown distribution), but an explicit form for the distribution is not estimated.",1. Introduction,[0],[0]
"GAN has recently been augmented by Flow-GAN (Grover et al., 2017) to incorporate a likelihood term for explicit density estimation.",1. Introduction,[0],[0]
"Further, the real-valued non-volume preserving (real NVP) transformations algorithm (Dinh et al., 2017) was proposed to perform inference within the implicit density estimation framework.
",1. Introduction,[0],[0]
Some aforementioned methods rely on the concept of flows.,1. Introduction,[0],[0]
"A flow defines a series of transformations for a random variable (RV), such that the distribution of the RV evolves from a simple distribution to a more complex distribution.",1. Introduction,[0],[0]
"When the sequence of transformations are indexed on a discrete-time domain (e.g., indexed with integers) with a finite number of transformations, this method is referred to as a normalizing flow (Rezende & Mohamed, 2015).",1. Introduction,[0],[0]
"Various efficient implementations of NFs have been proposed, such as the planar, radial (Rezende & Mohamed, 2015), Householder (Tomczak & Welling, 2016), and inverse autoregressive flows (Kingma et al., 2016).",1. Introduction,[0],[0]
"One theoretical limitation of existing normalizing flows is that there is no guarantee on the approximation accuracy due to the finite number of transformations.
",1. Introduction,[0],[0]
"By contrast, little work has explored the applicability of continuous-time flows (CTFs) in deep generative models, where a sequence of transformations are indexed on a continuous-time domain (e.g., indexed with real numbers).",1. Introduction,[0],[0]
"There are at least two reasons encouraging research in this direction: i) CTFs are more general than traditional normalizing flows in terms of modeling flexibility, due to the intrinsic infinite number of transformations; ii) CTFs are more theoretically grounded, in the sense that they are guaranteed to approach a target distribution asymptotically (details provided in Section 2.2).
",1. Introduction,[0],[0]
"In this paper, we propose efficient ways to apply CTFs for the two motivating tasks.",1. Introduction,[0],[0]
"Based on the CTF, our framework learns to drawn samples directly from desired distributions (e.g., the unknown posterior and data distributions) for both inference and density estimation tasks via amortization.",1. Introduction,[0],[0]
"In addition, we are able to learn an explicit form of the unknown data distribution for density estimation⇤.",1. Introduction,[0],[0]
"The core idea of our framework is the amortized learning, where knowledge in a CTF is distilled sequentially into another neural network (called inference network in the inference task, and generator in density estimation).",1. Introduction,[0],[0]
"The distillation relies on the distribution matching technique proposed recently via adversarial lerning (Li et al., 2017a).",1. Introduction,[0],[0]
"We conduct various experiments on both synthetic ad real datasets, demonstrating excellent performance of the proposed framework, relative to representative approaches.",1. Introduction,[0],[0]
Efficient inference with normalizing flows Consider a probabilistic generative model with observation x 2 RD and latent variable z 2 RL such that x | z ⇠ p✓(x | z) with z ⇠ p(z).,2.1. Efficient inference and density estimation,[0],[0]
"For efficient inference of z, the VAE (Kingma & Welling, 2014) introduces the concept of an inference network (recognition model or encoder), q (z |x), as a variational distribution in the VB framework.",2.1. Efficient inference and density estimation,[0],[0]
"An inference network is typically a stochastic (nonlinear) mapping from the input x to the latent z, with associated parameters .",2.1. Efficient inference and density estimation,[0],[0]
"For example, one of the simplest inference networks is defined as q (z |x) = N",2.1. Efficient inference and density estimation,[0],[0]
"(z;µ (x), diag( 2 (x))), where the mean function µ (x) and the standard-derivation function (x) are specified via deep neural networks parameterized by .",2.1. Efficient inference and density estimation,[0],[0]
"Parameters are learned by minimizing the negative evidence lower bound (ELBO), i.e., the KL divergence between p✓(x, z) and q (z |x): KL (q (z |x)kp✓(x, z)) ,",2.1. Efficient inference and density estimation,[0],[0]
Eq (z |x),2.1. Efficient inference and density estimation,[0],[0]
"[log q (z |x) log p✓(x, z)], via stochastic gradient descent (Bottou, 2012).
",2.1. Efficient inference and density estimation,[0],[0]
"One limitation of the VAE framework is that q (z |x) is ⇤Although the density is represented as an energy-based distribution with an intractable normalizer.
often restricted to simple distributions for feasibility, e.g., the normal distribution discussed above, and thus the gap between q (z |x) and p✓(z |x) is typically large for complicated posterior distributions.",2.1. Efficient inference and density estimation,[0],[0]
"NF is a recently proposed VB-based technique designed to mitigate this problem (Rezende & Mohamed, 2015).",2.1. Efficient inference and density estimation,[0],[0]
The idea is to augment z via a sequence of deterministic invertible transformations {Tk : RL !,2.1. Efficient inference and density estimation,[0],[0]
"RL}Kk=1, such that: z0 ⇠ q (·|x), z1 = T1(z0), · · · , zK = TK(zK 1).",2.1. Efficient inference and density estimation,[0],[0]
"Note the transformations {Tk} are typically endowed with different parameters, and we absorb them into .",2.1. Efficient inference and density estimation,[0],[0]
"Because the transformations are deterministic, the distribution of zK can be written as q(zK) = q",2.1. Efficient inference and density estimation,[0],[0]
(z0 |x),2.1. Efficient inference and density estimation,[0],[0]
QK k=1 det @Tk@,2.1. Efficient inference and density estimation,[0],[0]
"zk 1
via the change of variable formula.",2.1. Efficient inference and density estimation,[0],[0]
"As a result, the negative ELBO for normalizing flows becomes: KL (q (zK |x)kp✓(x, z))",2.1. Efficient inference and density estimation,[0],[0]
= Eq (z0 |x),2.1. Efficient inference and density estimation,[0],[0]
[log q (z0 |x)],2.1. Efficient inference and density estimation,[0],[0]
"(1)
Eq (z0 |x)",2.1. Efficient inference and density estimation,[0],[0]
"[log p✓(x, zK)]",2.1. Efficient inference and density estimation,[0],[0]
"Eq (z0 |x)[ KX
k=1
log |det @Tk @ zk |].
",2.1. Efficient inference and density estimation,[0],[0]
"Typically, transformations Tk of a simple parametric form are employed to make the computations tractable (Rezende & Mohamed, 2015).",2.1. Efficient inference and density estimation,[0],[0]
"Our method generalizes these discretetime transformations to continuous-time ones, ensuring convergence of the transformations to a target distribution.",2.1. Efficient inference and density estimation,[0],[0]
Related density-estimation methods There exist implicit and explicit density-estimation methods.,2.1. Efficient inference and density estimation,[0],[0]
"Implicit density models such as GAN provide a flexible way to draw samples directly from unknown data distributions (via a deep neural network (DNN) called a generator with stochastic inputs) without explicitly modeling their density forms; whereas explicit models such as the pixel RNN/CNN (van den Oord et al., 2016) define and learn explicit forms of the unknown data distributions.",2.1. Efficient inference and density estimation,[0],[0]
This gives the advantage that the likelihood for a test data point can be explicitly evaluated.,2.1. Efficient inference and density estimation,[0],[0]
"However, the generation of samples is typically time-consuming due to the sequential generation nature.
",2.1. Efficient inference and density estimation,[0],[0]
"Similar to Wang & Liu (2017), our CTF-based approach in Section 4 provides an alternative way for this problem, by simultaneously learning an explicit energy-based data distribution (estimated density) and a generator whose generated samples match the learned data distribution.",2.1. Efficient inference and density estimation,[0],[0]
This not only gives us the advantage of explicit density modeling but also provides an efficient way to generate samples.,2.1. Efficient inference and density estimation,[0],[0]
"Note that our technique differs from that of Wang & Liu (2017) in that distribution matching is adopted to learn an accurate generator, which is a key component in our framework.",2.1. Efficient inference and density estimation,[0],[0]
"We notice two potential limitations with traditional normalizing flows: i) given specified transformations {Tk}, there is no guarantee that the distribution of zK could exactly match p✓(x, z); ii) the randomness is only introduced in z0 (from the inference network), limiting the representation
power.",2.2. Continuous-time flows,[0],[0]
"We specify CTFs where transformations are indexed by real numbers, thus they could be considered as consisting of infinite transformations.",2.2. Continuous-time flows,[0],[0]
"Further, we consider stochastic flows where randomness is injected in a continuous-time manner.",2.2. Continuous-time flows,[0],[0]
"In fact, the concept of CTFs (such as the Hamiltonian flow) has been introduced by Rezende & Mohamed (2015), without further development on efficient inference.
",2.2. Continuous-time flows,[0],[0]
"We consider a flow on RL, defined as the mapping† T : RL ⇥",2.2. Continuous-time flows,[0],[0]
R !,2.2. Continuous-time flows,[0],[0]
"RL such that‡ we have T (Z, 0) =",2.2. Continuous-time flows,[0],[0]
"z and T (T (Z, t), s) = T (Z, s + t), for all Z 2 RL and s, t 2 R. A specific form consider here is defined as T (Z, t) =",2.2. Continuous-time flows,[0],[0]
"Zt, where Zt is driven by a diffusion of the form: dZt = F (Zt)dt + V (Zt)dW . (2)",2.2. Continuous-time flows,[0],[0]
Here F : RL !,2.2. Continuous-time flows,[0],[0]
"RL, V : RL⇥L !",2.2. Continuous-time flows,[0],[0]
"RL are called the drift term and diffusion term, respectively; W is the standard L-dimensional Brownian motion.",2.2. Continuous-time flows,[0],[0]
"In the context of inference, we seek to make the stationary distribution of Zt approach p✓(z |x).",2.2. Continuous-time flows,[0],[0]
"One solution for this is to set F (Zt) = 1 2rz log p✓(x, z = Zt) and V (Zt) =",2.2. Continuous-time flows,[0],[0]
IL with IL the L ⇥ L identity matrix.,2.2. Continuous-time flows,[0],[0]
"The resulting diffusion is called Langevin dynamics (Welling & Teh, 2011).",2.2. Continuous-time flows,[0],[0]
"Denoting the distribution of Zt as ⇢t, it is well known (Risken, 1989) that ⇢t is characterized by the Fokker-Planck (FP) equation:
@t⇢t = rz · (⇢tF (Zt) +rz · (⇢tV (Zt)V >(Zt)))",2.2. Continuous-time flows,[0],[0]
", (3)
where a ·b , a> b for vectors a and b.",2.2. Continuous-time flows,[0],[0]
"For simplicity, we consider the flow defined by the Langevin dynamics specified above, though our results generalize to other stochastic flows (Dorogovtsev & Nishchenko, 2014).",2.2. Continuous-time flows,[0],[0]
"In fact, CTF has been applied for scalable Bayesian sampling (Ding et al., 2014; Li et al., 2016a; Chen et al., 2016; Li et al., 2016b; Zhang et al., 2017).",2.2. Continuous-time flows,[0],[0]
"In this paper, we generalize it by specifying an ELBO under a CTF, which can then be readily solved by a discretized numerical scheme, based on the results from Jordan et al. (1998).",2.2. Continuous-time flows,[0],[0]
An approximation error bound for the scheme is also derived.,2.2. Continuous-time flows,[0],[0]
We defer proofs of our theoretical results to the Supplementary Material (SM) for conciseness.,2.2. Continuous-time flows,[0],[0]
"For this task, we adopt the VAE/normalizing-flow framework with an encoder-decoder structure.",3. Continuous-Time Flows for Inference,[0],[0]
"An important difference is that instead of feeding data to an encoder and sampling a latent representation in the output as in VAE, we concatenate the data with independent noise as input and directly generate output samples§, constituting an implicit
†We reuse the notation T as transformations from the discrete case above for simplicity, and use Z instead of z (reserved for the discrete-time setting) to denote the random variable in the continuous-time setting.
",3. Continuous-Time Flows for Inference,[0],[0]
‡Note we define continuous-time flows in terms of latent variable Z in order to incorporate it into the setting of inference.,3. Continuous-Time Flows for Inference,[0],[0]
"However, the same description applies when we define the flow in data space, which is the setting of density estimation in Section 4.
",3. Continuous-Time Flows for Inference,[0],[0]
"§Such structure can represent much more complex distributions than a parametric form, useful for the follow up procedures.",3. Continuous-Time Flows for Inference,[0],[0]
"In
model.",3. Continuous-Time Flows for Inference,[0],[0]
These outputs are then driven by the CTF to approach the true posterior distribution.,3. Continuous-Time Flows for Inference,[0],[0]
"In the following, we first show that directly optimizing the ELBO is infeasible.",3. Continuous-Time Flows for Inference,[0],[0]
We then propose an amortized-learning process that sequentially distills the implicit transformations from the CTF an inference network by distribution matching in Section 3.2.,3. Continuous-Time Flows for Inference,[0],[0]
We first incorporate CTF into the NF framework by writing out the corresponding ELBO.,3.1. The ELBO and discretized approximation,[0],[0]
Note that there are two steps in the inference process.,3.1. The ELBO and discretized approximation,[0],[0]
"First, an initial z0 is drawn from the inference network q (·|x); second, z0 is evolved via a diffusion such as (2) for time T (via the transformation ZT = T (z0, T )).",3.1. The ELBO and discretized approximation,[0],[0]
"Consequently, the negative ELBO for CTF can be written as
F(x) = Eq (z0 |x)E⇢T [log ⇢T log p✓(x,ZT )
+",3.1. The ELBO and discretized approximation,[0],[0]
"log det @ ZT @ z0 , Eq (z0 |x)",3.1. The ELBO and discretized approximation,[0],[0]
"[F1(x, z0)] .",3.1. The ELBO and discretized approximation,[0],[0]
"(4)
Note the term F1(x, z0) is intractable to calculate, in that i) ⇢T does not have an explicit form; ii) the Jacobian @ ZT@ z0 is generally infeasible.",3.1. The ELBO and discretized approximation,[0],[0]
"In the following, we propose an approximate solution for problem i).",3.1. The ELBO and discretized approximation,[0],[0]
"Learning by avoiding problem ii) is presented in Section 3.2 via amortization.
",3.1. The ELBO and discretized approximation,[0],[0]
"For problem i), a reformulation of the results from Jordan et al. (1998) leads to a nice way to approximate ⇢t in Lemma 1.",3.1. The ELBO and discretized approximation,[0],[0]
"Note in practice we adopt an implicit method which uses samples to approximate the solution in Lemma 1 for feasibility, detailed in (6).
",3.1. The ELBO and discretized approximation,[0],[0]
"Lemma 1 Assume that log p✓(x, z)  ",3.1. The ELBO and discretized approximation,[0],[0]
"C1 is infinitely differentiable, and krz log p✓(x, z)k  C2 (1 + C1 log p✓(x, z))",3.1. The ELBO and discretized approximation,[0],[0]
"(8x, z) for some constants {C1, C2}.",3.1. The ELBO and discretized approximation,[0],[0]
Let T = hK,3.1. The ELBO and discretized approximation,[0],[0]
"(h is the stepsize and K is the number of transformations), ⇢0 , q (z0 |x), and {⇢̃k}Kk=1 be the solution of the functional optimization problem:
⇢̃k = arg min ⇢2K
KL (⇢kp✓(x, z))",3.1. The ELBO and discretized approximation,[0],[0]
"+ 1
2h",3.1. The ELBO and discretized approximation,[0],[0]
"W
2 2 (⇢̃k 1, ⇢) , (5)
with W 2 2 (µ1, µ2) , infp2P(µ1,µ2) R kx yk22 p(dx, dy) the square of 2nd-order Wasserstein distance, and P(µ1, µ2) the set of joint distributions on {µ1, µ2}.",3.1. The ELBO and discretized approximation,[0],[0]
K is the space of distributions with finite 2nd-order moment.,3.1. The ELBO and discretized approximation,[0],[0]
"Then ⇢̃K converges to ⇢T in the limit of h ! 0, i.e., limh!0 ⇢̃K = ⇢T , where ⇢T is the solution of the FP equation (3) at time T .
",3.1. The ELBO and discretized approximation,[0],[0]
Lemma 1 reveals an interesting way to compute ⇢T via a sequence of functional optimization problems.,3.1. The ELBO and discretized approximation,[0],[0]
"By comparing it with the objective of the traditional NF, which minimizes the KL-divergence between ⇢K and p✓(x, z), at each sub-optimization-problem in Lemma 1, it minimizes the KL-divergence between ⇢̃k and p✓(x, z), plus a regularization term as the Wasserstein distance between ⇢̃k 1
contrast, we will define an explicit energy-based distribution for the density in density-estimation tasks.
and ⇢̃k.",3.1. The ELBO and discretized approximation,[0],[0]
"The extra Wasserstein-distance term arises naturally due to the fact that the Langevin diffusion can be explained as a gradient flow whose geometry is equipped with the Wasserstein distance (Otto, 1998).
",3.1. The ELBO and discretized approximation,[0],[0]
"The optimization problem in Lemma 1 is, however, difficult to deal with directly.",3.1. The ELBO and discretized approximation,[0],[0]
"In practice, we instead approximate the discretization in an equivalent way by simulation from the CTF.",3.1. The ELBO and discretized approximation,[0],[0]
"Starting from z0, each zk (k = 0, · · · , K 1) is fed into a transformation Tk (specified below), resulting in zk+1 whose distribution coincides with ⇢̃k+1 in Lemma 1.",3.1. The ELBO and discretized approximation,[0],[0]
The discretization procedure is illustrated in Figure 1.,3.1. The ELBO and discretized approximation,[0],[0]
We must specify the transformations Tk.,3.1. The ELBO and discretized approximation,[0],[0]
"For each k, let t = hk; we can conclude from Lemma 1 that limh!0 ⇢̃k = ⇢t. From FP theory, ⇢t is obtained by solving the diffusion (2) with initial condition Z0 = z0.",3.1. The ELBO and discretized approximation,[0],[0]
It is thus reasonable to specify the transformation Tk as the k-th step of a numerical integrator for (2).,3.1. The ELBO and discretized approximation,[0],[0]
"Specifically, we specify Tk stochastically:
zk = Tk(zk 1) , zk 1 +F (zk 1)h + V",3.1. The ELBO and discretized approximation,[0],[0]
(,3.1. The ELBO and discretized approximation,[0],[0]
"zk 1)⇣k , (6)
where ⇣k ⇠ N (0, hIL) is drawn from an isotropic normal.",3.1. The ELBO and discretized approximation,[0],[0]
"Note the transformation defined here is stochastic, thus we only get samples from ⇢̃K at the end.",3.1. The ELBO and discretized approximation,[0],[0]
"A natural way to approximate ⇢̃K is to use the empirical sample distribution, i.e., ⇢̃K ⇡ 1K PK k=1 zk , ⇢̄T with z a point mass at z. Afterwards, ⇢̃K (thus ⇢̄T ) will be used to approximate the true ⇢T from (3).
",3.1. The ELBO and discretized approximation,[0],[0]
"Better ways to approximate ⇢T might be possible, e.g., by assigning more weights to the more recent samples.",3.1. The ELBO and discretized approximation,[0],[0]
"However, the problem becomes more challenging in theoretical analysis, an interesting point left for future work.",3.1. The ELBO and discretized approximation,[0],[0]
"In the following, we study how well ⇢̄T approximates ⇢T .",3.1. The ELBO and discretized approximation,[0],[0]
"Following literature on numerical approximation for Itô diffusions (Vollmer et al., 2016; Chen et al., 2015), we consider a 1-Lipschitz test function : RL !",3.1. The ELBO and discretized approximation,[0],[0]
"R, and use the mean square error (MSE) bound to measure the closeness of ⇢̄T and ⇢T , defined as: MSE(⇢̄T , ⇢T ; ) , E R (z)(⇢̃T ⇢T )(z)d z
2, where the expectation is taken over all the randomness in the construction of ⇢̃T .",3.1. The ELBO and discretized approximation,[0],[0]
"Note that our goal is related but different from the standard setup as in (Vollmer et al., 2016; Chen et al., 2015), which studies the closeness of ⇢̄T to p✓(x, z).",3.1. The ELBO and discretized approximation,[0],[0]
"We need to adopt the assumptions from Vollmer et al. (2016); Chen et al. (2015), which are described in the SM.",3.1. The ELBO and discretized approximation,[0],[0]
"The assumptions are somewhat involved but essentially require
coefficients of the diffusion (2) to be well-behaved.",3.1. The ELBO and discretized approximation,[0],[0]
"We derive the following bound for the MSE of the sampled approximation, ⇢̄T , and the true distribution.
",3.1. The ELBO and discretized approximation,[0],[0]
Theorem 2,3.1. The ELBO and discretized approximation,[0],[0]
"Under Assumption 1 in the SM, assume thatR ⇢T (z)p 1 ✓ (x, z)d z",3.1. The ELBO and discretized approximation,[0],[0]
< 1,3.1. The ELBO and discretized approximation,[0],[0]
"and there exists a constant C such that dW 22 (⇢T ,p✓(x,z))
",3.1. The ELBO and discretized approximation,[0],[0]
"dt CW 2 2 (⇢T , p✓(x, z)), the MSE
is bounded as
MSE(⇢̄T , ⇢T ; )",3.1. The ELBO and discretized approximation,[0],[0]
=,3.1. The ELBO and discretized approximation,[0],[0]
"O
✓ 1
hK + h2 + e 2ChK
◆ .
",3.1. The ELBO and discretized approximation,[0],[0]
"The last assumption in Theorem 2 requires ⇢T to evolve fast through the FP equation, which is a standard assumption used to establish convergence to equilibrium for FP equations (Bolley et al., 2012).",3.1. The ELBO and discretized approximation,[0],[0]
"The MSE bound consists of three terms, the first two terms come from numerical approximation of the continuous-time diffusion, whereas the third term comes from the convergence bound of the FP equation in terms of the Wasserstein distance (Bolley et al., 2012).",3.1. The ELBO and discretized approximation,[0],[0]
"When the time T = hK is large enough, the third term may be ignored due to its exponential-decay rate.",3.1. The ELBO and discretized approximation,[0],[0]
"Moreover, in the infinite-time limit, the bound endows a bias proportional to h; this, however, can be removed by adopting a decreasing-step-size scheme in the numerical method, as in standard stochastic gradient MCMC methods (Teh et al., 2016; Chen et al., 2015).
",3.1. The ELBO and discretized approximation,[0],[0]
"Remark 3 To examine the optimal bound in Theorem 2, we drop out the term e 2ChK in the long-time case (when hK
is large enough) for simplicity because it is in a much lower
order term than the other terms.",3.1. The ELBO and discretized approximation,[0],[0]
"The optimal MSE bound
(over h) decreases at a rate of O K 2/3 , meaning that O ✏ 3/2 steps of transformations in Figure 1 (right) are needed to reach an ✏-accurate approximation, i.e., MSE  ✏.",3.1. The ELBO and discretized approximation,[0],[0]
This is computationally expensive.,3.1. The ELBO and discretized approximation,[0],[0]
"An efficient way for
inference is thus imperative, developed in the next section.",3.1. The ELBO and discretized approximation,[0],[0]
"Even though we approximate ⇢T with ⇢̄T , it is still infeasible to directly apply it to the ELBO in (4) as ⇢̄T is discrete.",3.2. Efficient inference via amortization,[0],[0]
"To deal with this problem, we adopt the idea of “amortized learning” (Gershman & Goodman, 2014) for inference, by alternatively optimizing the two sets of parameters and ✓.
",3.2. Efficient inference via amortization,[0],[0]
"Updating To explain the idea, first note that the negative ELBO can be equivalently written as F(x) = E⇢0,q (z0 |x)E⇢T [log ⇢0 log p✓(x,ZT )] .",3.2. Efficient inference via amortization,[0],[0]
"(7)
When ⇢0 = ⇢T , it is easy to see that: F(x) = E⇢0",3.2. Efficient inference via amortization,[0],[0]
"[log ⇢0 log p✓(ZT |x)]+log p(x) = log p(x), which essentially makes the gap between q (z0 |x) and",3.2. Efficient inference via amortization,[0],[0]
p✓(ZT |x) vanished.,3.2. Efficient inference via amortization,[0],[0]
"As a result, our goal is to learn such that q (z0 |x) approaches p✓(ZT |x).",3.2. Efficient inference via amortization,[0],[0]
"This is a distribution matching problem (Li et al., 2017a).",3.2. Efficient inference via amortization,[0],[0]
"As mentioned previously, we will learn an implicit distribution of q (z0 |x)
(i.e., learn how to draw samples from q (z0 |x) instead of its explicit form), as it allows us to chose a candidate distribution from a much larger distribution space, compared to explicitly defining q ¶. Consequently, q (z0 |x) is implemented by a stochastic generator (a DNN parameterized by ) Q (x,!)",3.2. Efficient inference via amortization,[0],[0]
"with input as the concatenation of x and !, where ! is a sample from an isotropic Gaussian distribution q0(!).",3.2. Efficient inference via amortization,[0],[0]
"Our goal is now translated to update the parameter of Q (x,!)",3.2. Efficient inference via amortization,[0],[0]
"to 0 such that the distribution of {z00 = Q 0(x,!)} with !",3.2. Efficient inference via amortization,[0],[0]
⇠ q0(!) matches that of z1 in the original generating process with in Figure 1.,3.2. Efficient inference via amortization,[0],[0]
"In this way, the generating process of z1 via T1 is distilled into the parameterized generator Q (·), eliminating the need to do a specific transformation via T1 in testing, and thus is very efficient.",3.2. Efficient inference via amortization,[0],[0]
"Specifically, we update 0 such that
0 = arg min D({z0(i)0 }, {z (i) 1 }) , (8)
where {z0(i)0 }Si=1 are a set of samples generated from q 0(z00 |x) via Q (·), and {z (i) 1 }Si=1 are samples drawn by !",3.2. Efficient inference via amortization,[0],[0]
"i ⇠ q0(!), z̃i0 = Q (x,!i), z (i) 1 ⇠ T1(z̃ i 0); D(·, ·) is a metric between samples specified below.",3.2. Efficient inference via amortization,[0],[0]
We call this procedure distilling knowledge from T1 to Q (·).,3.2. Efficient inference via amortization,[0],[0]
"In practice, one can choose to distill knowledge for several steps (e.g., Tk) instead of one step (e.g., T1) to Q (·) each time.",3.2. Efficient inference via amortization,[0],[0]
"Note the distillation idea is related to Bayesian dark knowledge (Korattikara et al., 2015), but with different goal and approach.
",3.2. Efficient inference via amortization,[0],[0]
"After distilling knowledge from T1, we apply the same procedure for other transformations Tk(k > 1) sequentially.",3.2. Efficient inference via amortization,[0],[0]
"The final inference network, represented by q (·|x), can then well approximate the CTF, e.g., the distribution of z0 ⇠ q (·|x) is close to ⇢T from the CTF.",3.2. Efficient inference via amortization,[0],[0]
This concept is illustrated in Figure 2.,3.2. Efficient inference via amortization,[0],[0]
We note choosing an appropriate D in (8) is important in order to make Theorem 2 applicable.,3.2. Efficient inference via amortization,[0],[0]
"Amortized SVGD (Wang & Liu, 2017) defines D as standard Euclidean distance between samples.",3.2. Efficient inference via amortization,[0],[0]
"We show in Proposition 4 that this would induce a large error in terms of approximation accuracy.
",3.2. Efficient inference via amortization,[0],[0]
Proposition 4 Fix ✓.,3.2. Efficient inference via amortization,[0],[0]
"If D in (8) is defined as the summation of pairwise Euclidean distance between samples, then
samples generated from Q converge to local modes of log p✓(z |x).",3.2. Efficient inference via amortization,[0],[0]
"¶This is distinct from our density-estimation framework described in the next section, where an explicit form is assumed at the beginning for practical needs.
",3.2. Efficient inference via amortization,[0],[0]
"Consequently, it is crucial to impose more general distance for D. As GAN has been interpreted as distribution matching (Li et al., 2017a), we define D using the Wasserstein distance, implemented as a discriminator parameterized by a neural network.",3.2. Efficient inference via amortization,[0],[0]
"Specifically, we adopt the ALICE framework (Li et al., 2017a), and use {(x, z0(i)0 )} as fake data and {(z(i)1 ,xi ⇠ p✓(·| z (i) 1 ))} as real data to train a discriminator.",3.2. Efficient inference via amortization,[0],[0]
"More details are discussed in Section C of the SM.
",3.2. Efficient inference via amortization,[0],[0]
"Updating ✓ Given , ✓ can be updated by simply optimizing the ELBO in (7), where ⇢T is approximated by ⇢̄T from the discretized CTF.",3.2. Efficient inference via amortization,[0],[0]
"Specifically, the expectation w.r.t. ⇢T in (7) is approximated by a sample average from:
z0 ⇠ q (z0 |x), z1 ⇠ T1(z0), z2 ⇠ T2(z1), · · · , zK ⇠ TK(zK 1)
To sum up, there are three steps to learn a CTF-based VAE:
1.",3.2. Efficient inference via amortization,[0],[0]
"Generate (z0, · · · , zK) according to q (z0 |x) and the discretized flow with transformations {Tk}; 2.",3.2. Efficient inference via amortization,[0],[0]
Update according to (8); 3.,3.2. Efficient inference via amortization,[0],[0]
"Optimize ✓ by minimizing the ELBO (7) with the gen-
erated sample path.
",3.2. Efficient inference via amortization,[0],[0]
"In testing, we use only the finally learned q (z0 |x) for inference (into which the CTF has been distilled), and hence testing is like the standard VAE.",3.2. Efficient inference via amortization,[0],[0]
"Since the discretized-CTF model is essentially a Markov chain, we call our model Markov-chain-based VAE (MacVAE).",3.2. Efficient inference via amortization,[0],[0]
"We assume that the density of the observation x is characterized by a parametric Gibbsian-style probability model p✓(x) = 1 Z(✓) p̃✓(x) , 1Z(✓)eU(x;✓), where p̃✓(x) is an unnormalized version of p✓(x) with parameter ✓, U(x;✓) , log p̃✓(x) is called the energy function (Zhao et al., 2017), and Z(✓) , R p̃✓(x)dx is the normalizer.",4. CTFs for Energy-based Density Estimation,[0],[0]
Note this form of distributions constitutes a very large class of distributions as long as the capacity of the energy function is large enough.,4. CTFs for Energy-based Density Estimation,[0],[0]
"This can be easily achieved by adopting a DNN to implement U(x;✓), the setting we considered in this paper.",4. CTFs for Energy-based Density Estimation,[0],[0]
"Note our model can be placed in between existing implicit and explicit density estimation methods, because we model the data density with an explicit distribution form up to an intractable normalizer.",4. CTFs for Energy-based Density Estimation,[0],[0]
"Such distributions have been proved to be useful in real applications, e.g., (Haarnoja et al., 2017) used them to model policies in deep reinforcement learning.
",4. CTFs for Energy-based Density Estimation,[0],[0]
"The optimization can be achieved by standard stochastic gradient descent (SGD), with the following gradient formula:
@M @✓ = 1 N
NX
i=1
@U(xi;✓) @✓ Ep✓(x)  @U(x;✓) @✓
(9)
",4. CTFs for Energy-based Density Estimation,[0],[0]
"The above formula requires an integration over the model distribution p✓(x), which can be approximated by Monte Carlo integration with samples.",4. CTFs for Energy-based Density Estimation,[0],[0]
"Here we adopt the idea of CTFs and propose to use a DNN guided by a CTF, which we call a generator, to generate approximate samples from the original model p✓(x).",4. CTFs for Energy-based Density Estimation,[0],[0]
"Specifically, we require that samples from the generator should well approximate the target p✓(x).",4. CTFs for Energy-based Density Estimation,[0],[0]
"This can be done by adopting the CTF idea above, i.e., distilling knowledge of a CTF (which approaches p✓(x)) to the generator.",4. CTFs for Energy-based Density Estimation,[0],[0]
"In testing, instead of generating samples from p✓(x) via MCMC (which is complicated and time consuming), we generate samples from the generator directly.",4. CTFs for Energy-based Density Estimation,[0],[0]
"Furthermore, when evaluating the likelihood for test data, the constant Z(✓) can also be approximated by Monte Carlo integration with samples drawn from the generator.
",4. CTFs for Energy-based Density Estimation,[0],[0]
"Note the first term on the RHS of (9) is a model fit to observed data, and the second term is a model fit to synthetic data drawn from p✓(x); this is similar to the discriminator in GANs (Arjovsky et al., 2017), but derived directly from the MLE.",4. CTFs for Energy-based Density Estimation,[0],[0]
More connections are discussed below.,4. CTFs for Energy-based Density Estimation,[0],[0]
"Our goal is to learn a generator whose generated samples match those from the original model p✓(x).Similar to inference setting, the generator is learned implicitly.",4.1. Learning via Amortization,[0],[0]
"However, we also learn an explicit density model for the data by SGD, with samples from the implicit generator to estimate gradients in (9).",4.1. Learning via Amortization,[0],[0]
"Note that in this case, the CTF is performed directly on the data space, instead of on latent-variable space as in previous sections.",4.1. Learning via Amortization,[0],[0]
"Specifically, the sampling procedure from the generator plus a CTF are written as:
x0 ⇠ q (x0),xT ⇠ T (x0, T ) .
",4.1. Learning via Amortization,[0],[0]
"Here T (·, ·) is the continuous-time flow; a sample x0 from q (·) is implemented by a deep neural network (generator) G (!) with input !",4.1. Learning via Amortization,[0],[0]
"⇠ q0(!), where q0 is a simple distribution for a noise random variable, e.g., the isotropic normal distribution.",4.1. Learning via Amortization,[0],[0]
"The procedure is illustrated in Figure 3.
",4.1. Learning via Amortization,[0],[0]
"Specifically, denote the parameters in the k-th step with subscript “(k)”.",4.1. Learning via Amortization,[0],[0]
"For efficient sample generation, in the k-th step, we again adopt the amortization idea from Section 3.2 to update (k 1) of the generator network G (·), such that samples from the updated generator match those from the current generator followed by a one-step transformation T1(·).",4.1. Learning via Amortization,[0],[0]
"After that, ✓ is updated by drawing samples from q (·) to estimate the expectation in (9).",4.1. Learning via Amortization,[0],[0]
The algorithm is presented in Algorithm 1 in Section E of the SM.,4.1. Learning via Amortization,[0],[0]
"There is an interesting relation between our model and the WGAN framework (Arjovsky et al., 2017).",4.2. Connections to WGAN and MLE,[0],[0]
"To see this, let pr be the data distribution.",4.2. Connections to WGAN and MLE,[0],[0]
"Substituting p✓(x) with q (x) for the expectation in the gradient formula (9) and integrating out ✓, we have that our objective is
maxEx⇠pr [U(x;✓)]",4.2. Connections to WGAN and MLE,[0],[0]
"Ex⇠q [U(x;✓)] (10)
This is an instance of the integral probability metrics (Arjovsky & Bottou, 2017).",4.2. Connections to WGAN and MLE,[0],[0]
"When U is chosen to be 1-Lipschitz functions, it recovers WGAN.",4.2. Connections to WGAN and MLE,[0],[0]
"This connection motivates us to introduce weight clipping (Arjovsky et al., 2017) or alternative regularizers (Gulrajani et al., 2017) when updating ✓ for a better theoretical property.",4.2. Connections to WGAN and MLE,[0],[0]
"For this reason, we call our model Markov-chain-based GAN (MacGAN).
",4.2. Connections to WGAN and MLE,[0],[0]
"Furthermore, it can be shown by Jensen’s inequality that the MLE is bounded by (detailed derivations are provided in Section F of the SM)
max 1 N
NX
i=1
log p✓(xi) (11)
 ",4.2. Connections to WGAN and MLE,[0],[0]
maxEx⇠pr [U(x;✓)],4.2. Connections to WGAN and MLE,[0],[0]
Ex⇠q [U(x;✓)],4.2. Connections to WGAN and MLE,[0],[0]
"Ex⇠q [log q ] .
",4.2. Connections to WGAN and MLE,[0],[0]
"By inspecting (10) and (11), it is clear that: i) when learning the energy-based model parameters ✓, the objective can be interpreted as maximizing an upper bound of the MLE shown in (11); ii) when optimizing the parameter of the inference network, we adopt the amortized learning procedure presented in Algorithm 1, whose objective is min KL (q kp✓), coinciding with the last two terms in (11).",4.2. Connections to WGAN and MLE,[0],[0]
"In other words, both ✓ and are optimized by maximizing the same upper bound of the MLE, guaranteeing convergence of the algorithm, although previous work has pointed out maximizing an upper bound is not a well-posed problem in general (Salakhutdinov & Hinton, 2012).
",4.2. Connections to WGAN and MLE,[0],[0]
Proposition 5,4.2. Connections to WGAN and MLE,[0],[0]
"The optimal solution of MacGAN is the max-
imum likelihood estimator.
",4.2. Connections to WGAN and MLE,[0],[0]
"Note another difference between MacGAN and standard GAN framework is the way of learning the generator q .
",4.2. Connections to WGAN and MLE,[0],[0]
"We adopt the amortization idea, which directly guides q to approach p✓; whereas in GAN, the generator is optimized via a min-max procedure to make it approach the empirical data distribution pr.",4.2. Connections to WGAN and MLE,[0],[0]
"By explicitly learning p✓ , MacGAN is able to evaluate likelihood for test data up to a constant.",4.2. Connections to WGAN and MLE,[0],[0]
"Our framework extends the idea of normalizing flows (Rezende & Mohamed, 2015) and gradient flows (Altieri & Duvenaud, 2015) to continuous-time flows, by developing theoretical properties on the convergence behavior.",5. Related Work,[0],[0]
"Inference based on CTFs has been studied in (Sohl-Dickstein et al., 2015) based on maximum likelihood and (Salimans et al., 2015) based on the auxiliary-variable technique.",5. Related Work,[0],[0]
"However, they directly uses discrete approximations for the flow, and the approximation accuracy is unclear.",5. Related Work,[0],[0]
"Moreover, the inference network requires simulating a long Markov chain for the auxiliary model, thus is less efficient than ours.",5. Related Work,[0],[0]
"Finally, the inference network is implemented as a parametric distribution (e.g., the Gaussian distribution), limiting the representation power, a common setting in existing auxiliaryvariable based models (Tran et al., 2016).",5. Related Work,[0],[0]
"The idea of amortization (Gershman & Goodman, 2014) has recently been explored in various research topics for Bayesian inference such as in variational inference (Kingma & Welling, 2014; Rezende et al., 2014) and Markov chain Monte Carlo (Wang & Liu, 2017; Li et al., 2017b; Pu et al., 2017).",5. Related Work,[0],[0]
"Both (Wang & Liu, 2017) and (Pu et al., 2017) extend the idea of Stein variational gradient descent (Liu & Wang, 2016) with amortized inference for a GAN-based and a VAE-based model, respectively, which resemble our proposed MacVAE and MacGAN in concept.",5. Related Work,[0],[0]
Li et al. (2017b) applies amortization to distill knowledge from MCMC to learn a student network.,5. Related Work,[0],[0]
"The ideas in (Li et al., 2017b) are similar to ours, but the motivation and underlying theory are different from that developed here.",5. Related Work,[0],[0]
"Remarkably, the authors endowed standard Euclidean distance in (8) for distribution matching, which is inappropriate as will be shown in our experiments.",5. Related Work,[0],[0]
"We conduct experiments to test our CTF-based framework for efficient inference and density estimation problems, and compared them with related methods.",6. Experiments,[0],[0]
"Some experiments are based on the excellent code for SteinGANk (Wang & Liu, 2017), where their default parameter setting are adopted.",6. Experiments,[0],[0]
"The discretization stepsize h is robust as long as it is set in a reasonable range, e.g., we set it the same as the stepsize in SGD.",6. Experiments,[0],[0]
"More experimental results are given in the SM, including a sensitiveness experiment on model parameters in Section G.4.
khttps://github.com/DartML/SteinGAN",6. Experiments,[0],[0]
Synthetic experiment We examine our amortized learning framework with three toy experiments.,6.1. CTFs for inference,[0],[0]
"Particularly, we want to verify the necessity of distribution matching defined in (8), i.e., we test D implemented as a discriminator for Wasserstein distance (adversarial-CTF) against that implemented with standard Euclidean distance (`2-CTF), which can be considered as an instance of the amortized MCMC (Li et al., 2017b) with a Langevin-dynamic transition function and a Euclidean-distance-based divergence measure for samples.",6.1. CTFs for inference,[0],[0]
"Two 2D distributions similar to (Rezende & Mohamed, 2015) are considered, defined in Section D of the SM.",6.1. CTFs for inference,[0],[0]
The inference network q is defined to be a 2-layer MLP with isotropic normal random variables as input.,6.1. CTFs for inference,[0],[0]
"Figure 4 plots the densities estimated with the samples from transformations {TK=100} (before optimizing ), as well as with samples generated directly from q (after optimizing ).",6.1. CTFs for inference,[0],[0]
"It is clear that the amortized learning with Wasserstein distance is able to distill knowledge from the CTF to the inference network, while the algorithm fails when Euclidean distance is adopted.
",6.1. CTFs for inference,[0],[0]
"Next, we test MacVAE on a VAE setting on a simple synthetic dataset containing 4 data points, each is a 4D one-hot vector, with the non-zero elements at different positions.",6.1. CTFs for inference,[0],[0]
The prior of latent code is a 2D standard Normal.,6.1. CTFs for inference,[0],[0]
"Figure 5 plots the distribution of the learned latent code for VAE, adversarial-CTF and `2-CTF.",6.1. CTFs for inference,[0],[0]
Each color means the codes for one particular observation.,6.1. CTFs for inference,[0],[0]
"It is observed that VAE divides the space into a mixture of 4 Gaussians (consistent with VAE theory), the adversarial-CTF learns complex posteriors, while the `2-CTF converges to the mode of each posterior (consistent with Proposition 4).
MacVAE on MNIST Following (Rezende & Mohamed, 2015; Tomczak & Welling, 2016), we define the inference network as a deep neural network with two fully connected layers of size 300 with softplus activation functions.",6.1. CTFs for inference,[0],[0]
"We compare MacVAE with the standard VAE and the VAE with normalizing flow, where testing ELBOs are reported (Section G.1 of the SM describes how to calculate the ELBO).",6.1. CTFs for inference,[0],[0]
"We do not compare with other state-of-the-art methods such as the inverse autoregressive flow (Kingma et al., 2016), because they typically endowed more complicated inference networks (with more parameters), unfair for comparison.",6.1. CTFs for inference,[0],[0]
We use the same inference network architecture for all the models.,6.1. CTFs for inference,[0],[0]
Figure 7 (left) plots the testing ELBO versus training epochs.,6.1. CTFs for inference,[0],[0]
MacVAE outperforms VAE and normalizing flows with a better ELBO (around -85.62).,6.1. CTFs for inference,[0],[0]
"We test MacGAN on three datasets: MNIST, CIFAR-10 and CelabA. Following GAN-related methods, the model is evaluated by observing its ability to draw samples from the learned data distribution.",6.2. CTFs for density estimation,[0],[0]
"Inspiring by (Wang & Liu, 2017),
(a) Standard VAE (b) Adversarial CTF (c) L2 CTFFigure 5.",6.2. CTFs for density estimation,[0],[0]
"Comparison of the learned latent space with standard VAE (left), adversarial-CTF (middle) and `2-CTF (right).
",6.2. CTFs for density estimation,[0],[0]
"we define a parametric form of the energy-based model as p✓(x) / exp{ kx DEC✓ (ENC✓(x))k2}, where ENC✓(·) and DEC✓(·) are encoder and decoder defined by using deep convolutional neural networks and deconvolutional neural networks, respectively, parameterized by ✓.",6.2. CTFs for density estimation,[0],[0]
"For simplicity, we adopt the popular DCGAN architecture (Radford et al., 2016) for the encoder and decoder.",6.2. CTFs for density estimation,[0],[0]
"The generator G is defined as a 3-layer CNN with the ReLU activation function (except for the top layer which uses tanh as the activation function, see SM G for details).",6.2. CTFs for density estimation,[0],[0]
"Following (Wang & Liu, 2017), the stepsizes are set to (me e)⇥lrme 50 , where e indexes the epoch, me is the total number of epochs, lr = 1e-4 when updating ✓, and lr = 1e-3 when updating .",6.2. CTFs for density estimation,[0],[0]
"The stepsize in L1 is set to 1e-3.
",6.2. CTFs for density estimation,[0],[0]
"We compare MacGAN with DCGAN (Radford et al., 2016), the improved WGAN (WGAN-I) (Gulrajani et al., 2017) and SteinGAN (Wang & Liu, 2017).",6.2. CTFs for density estimation,[0],[0]
We plot images generated with MacGAN and its most related method SteinGAN in Figure 6 for CelebA and CIFAR-10 datasets.,6.2. CTFs for density estimation,[0],[0]
More results are provided in SM Section G. We observe that visually MacGAN is able to generate clear-looking images.,6.2. CTFs for density estimation,[0],[0]
"Following (Wang & Liu, 2017), we also plot the images generated by a random walk in the ! space in Figure 6.
",6.2. CTFs for density estimation,[0],[0]
Qualitatively evaluating a GAN-like model is challenging.,6.2. CTFs for density estimation,[0],[0]
"We follow literature and use the inception score (Salimans et al., 2016) to measure the quantity of the generated images.",6.2. CTFs for density estimation,[0],[0]
Figure 7 (right) plots inception scores vs epochs for different models.,6.2. CTFs for density estimation,[0],[0]
MacGAN obtains competitive inception scores with the popular DCGAN model.,6.2. CTFs for density estimation,[0],[0]
"Quantitatively, we get a final inception score of 6.49 for MacGAN, compared to 6.35 for
SteinGAN, 6.25 for WGAN-I and 6.58 for DCGAN.",6.2. CTFs for density estimation,[0],[0]
"We study the problem of applying CTFs for efficient inference and explicit density estimation in deep generative models, two important tasks in unsupervised learning.",7. Conclusion,[0],[0]
"Compared to discrete-time NFs, CTFs are more general and flexible due to the fact that their stationary distributions can be controlled without extra flow parameters.",7. Conclusion,[0],[0]
We develop theory on the approximation accuracy when adopting a CTF to approximate a target distribution.,7. Conclusion,[0],[0]
"We apply CTFs on two classes of deep generative models, a variational autoencoder for efficient inference, and a GAN-like density estimator for explicit density estimation and efficient data generation.",7. Conclusion,[0],[0]
Experiments show encouraging results of our framework in both models compared to existing techniques.,7. Conclusion,[0],[0]
One interesting direction of future work is to explore more efficient learning algorithms for the proposed CTF-based framework.,7. Conclusion,[0],[0]
We thank the anonymous reviewers for their useful comments.,Acknowledgements,[0],[0]
"This research was supported in part by DARPA, DOE, NIH, ONR and NSF.",Acknowledgements,[0],[0]
Two fundamental problems in unsupervised learning are efficient inference for latent-variable models and robust density estimation based on large amounts of unlabeled data.,abstractText,[0],[0]
"Algorithms for the two tasks, such as normalizing flows and generative adversarial networks (GANs), are often developed independently.",abstractText,[0],[0]
"In this paper, we propose the concept of continuous-time flows (CTFs), a family of diffusion-based methods that are able to asymptotically approach a target distribution.",abstractText,[0],[0]
"Distinct from normalizing flows and GANs, CTFs can be adopted to achieve the above two goals in one framework, with theoretical guarantees.",abstractText,[0],[0]
"Our framework includes distilling knowledge from a CTF for efficient inference, and learning an explicit energy-based distribution with CTFs for density estimation.",abstractText,[0],[0]
Both tasks rely on a new technique for distribution matching within amortized learning.,abstractText,[0],[0]
"Experiments on various tasks demonstrate promising performance of the proposed CTF framework, compared to related techniques.",abstractText,[0],[0]
Continuous-Time Flows for Efficient Inference and Density Estimation,title,[0],[0]
"Proceedings of the SIGDIAL 2018 Conference, pages 180–190, Melbourne, Australia, 12-14 July 2018. c©2018 Association for Computational Linguistics
180",text,[0],[0]
The primary aim of natural language generators (NLGs) for task-oriented dialogue is to effectively realize system dialogue actions and their associated content parameters.,1 Introduction,[0],[0]
"This requires training data that allows the NLG to learn how to map
semantic representations for system dialogue acts to one or more possible outputs (see Figure 1, (Novikova et al., 2016)).",1 Introduction,[0],[0]
"Because neural generators often make semantic errors such as deleting, repeating or hallucinating content, to date previous work on task-oriented neural generation has primarily focused on faithfully rendering the meaning of the system’s dialogue act (Dusek and Jurcı́cek, 2016b; Lampouras and Vlachos, 2016; Mei et al., 2015; Wen et al., 2015).
",1 Introduction,[0],[0]
"However, in many applications it is also desirable for generators to control the style of an utterance independently of its content.",1 Introduction,[0],[0]
"For example, in Figure 1, the first output uses more formal language and complex syntactic structures, as one might see in written language, while the other uses simpler syntax and pragmatic markers characteristic of oral language (Biber, 1991).",1 Introduction,[0],[0]
"In this paper, we create several different sequenceto-sequence models and compare how well they can disentangle content and style.",1 Introduction,[0],[0]
"Controlling the style of the output requires disentangling the content from the style, but previous neural models aimed at achieving stylistic goals have not focused on task-oriented dialogue where specific semantic attributes and values must be communicated (as per the MR in Figure 1), and where semantic fi-
delity can be precisely measured.1
One of the main challenges is the lack of parallel corpora realizing the same content with different styles.",1 Introduction,[0],[0]
"Thus we create a large, novel parallel corpus with specific style parameters and specific semantics, by using an existing statistical generator, PERSONAGE (Mairesse and Walker, 2010), to synthesize over 88,000 utterances in the restaurant domain that vary in style according to psycholinguistic models of personality.2",1 Introduction,[0],[0]
"PERSONAGE can generate a very large number of stylistic variations for any given dialogue act, thus yielding, to our knowledge, the largest style-varied NLG training corpus in existence.",1 Introduction,[0],[0]
"The strength of this new corpus is that: (1) we can use the PERSONAGE generator to generate as much training data as we want; (2) it allows us to systematically vary a specific set of stylistic parameters and the network architectures; (3) it allows us to systematically test the ability of different models to generate outputs that faithfully realize both the style and content of the training data.3
We develop novel neural models that vary the amount of explicit stylistic supervision given to the network, and we explore, for the first time, explicit control of multiple interacting stylistic parameters.",1 Introduction,[0],[0]
"We show that the no-supervision (NO-SUP) model, a baseline sequence-to-sequence model (Sutskever et al., 2014; Dusek and Jurcı́cek, 2016b), produces semantically correct outputs, but
1We leave a detailed review of related work to Section 6. 2Our stylistic variation for NLG corpus is available at:
nlds.soe.ucsc.edu/stylistic-variation-nlg 3 Section 4 quantifies the naturalness of PERSONAGE outputs.
eliminates much of the stylistic variation that it saw in the training data.",1 Introduction,[0],[0]
"MODEL TOKEN provides minimal supervision by allocating a latent variable in the encoding as a label for each style, similar to the use of language labels in machine translation (Johnson et al., 2017).",1 Introduction,[0],[0]
"This model learns to generate coherent and stylistically varied output without explicit exposure to language rules, but makes more semantic errors.",1 Introduction,[0],[0]
MODEL CONTEXT adds another layer to provide an additional encoding of individual stylistic parameters to the network.,1 Introduction,[0],[0]
We show that it performs best on both measures of semantic fidelity and stylistic variation.,1 Introduction,[0],[0]
"The results suggest that neural architectures can benefit from explicit stylistic supervision, even with a large training set.",1 Introduction,[0],[0]
"We aim to systematically create a corpus that can be used to test how different neural architectures affect the ability of the trained model to disentangle style from content, and faithfully produce semantically correct utterances that vary style.",2 Corpus Creation,[0],[0]
"We use PERSONAGE, an existing statistical generator: due to space, we briefly explain how it works, referring the interested reader to Mairesse and Walker (2010, 2011) for details.
",2 Corpus Creation,[0],[0]
"PERSONAGE requires as input: (1) a meaning representation (MR) of a dialogue act and its content parameters, and (2) a parameter file that tells it how frequently to use each of its stylistic parameters.",2 Corpus Creation,[0],[0]
"Sample model outputs are shown in the second row of Figure 1 and in Table 1, illustrating some stylistic variations PERSONAGE produces.
",2 Corpus Creation,[0],[0]
"To generate our novel corpus, we utilize the
MRs from the E2E Generation Challenge.4 The MR in Figure 1 illustrates all 8 available attributes.",2 Corpus Creation,[0],[0]
We added a dictionary entry for each attribute to PERSONAGE so that it can express that attribute.5,2 Corpus Creation,[0],[0]
"These dictionary entries are syntactic representations for very simple sentences: the NO-AGG/NOPRAG row of Table 1 shows a sample realization of each attribute in its own sentence based on its dictionary entry.
",2 Corpus Creation,[0],[0]
"We took advantage of the setup of the E2E Generation Challenge and used their MRs, exactly duplicating their split between training, dev and test MRs, because they ensured that the dev and test MRs had not been seen in training.",2 Corpus Creation,[0],[0]
"The frequencies of longer utterances (more attribute MRs) vary across train and test, with actual distributions in Table 2, showing how the test set was designed to be challenging, while the test set in Wen et al. (2015) averages less than 2 attributes per MR (Nayak et al., 2017).",2 Corpus Creation,[0],[0]
"We combine their dev and training MRs resulting in 3784 unique MRs in the training set, and generate 17,771 reference utterances per personality for a training set size of 88,855 utterances.",2 Corpus Creation,[0],[0]
"The test set consists of 278 unique MRs and we generate 5 references per personality for a test size of 1,390 utterances.
",2 Corpus Creation,[0],[0]
The experiments are based on two types of parameters provided with PERSONAGE: aggregation parameters and pragmatic parameters.6 The NOAGG/NO-PRAG row of Table 1 shows what PERSONAGE would output if it did not use any of its stylistic parameters.,2 Corpus Creation,[0],[0]
"The top half of Table 3 illustrates the aggregation parameters: these parameters control how the NLG combines attributes into sentences, e.g., whether it tries to create complex sentences by combining attributes into phrases and
4http://www.macs.hw.ac.uk/ InteractionLab/E2E/
5PERSONAGE supports a one-to-many mapping from attributes to elementary syntactic structures for expressing that attribute, but here we use only one dictionary entry.",2 Corpus Creation,[0],[0]
"PERSONAGE also allows for discourse relations such as justification or contrast to hold between content items, but the E2E MRs do not include such relations.
",2 Corpus Creation,[0],[0]
"6We disable parameters related to content selection, syntactic template selection and lexical choice.
",2 Corpus Creation,[0],[0]
what types of combination operations it uses.,2 Corpus Creation,[0],[0]
The pragmatic operators are shown in the second half of Table 3.,2 Corpus Creation,[0],[0]
"Each parameter value can be set to high, low, or don’t care.
",2 Corpus Creation,[0],[0]
"To use PERSONAGE to create training data mapping the same MR to multiple personality-based variants, we set values for all of the parameters in Table 3 using the stylistic models defined by Mairesse and Walker (2010) for the following Big Five personality traits: agreeable, disagreeable, conscientiousness, unconscientiousness, and extravert.",2 Corpus Creation,[0],[0]
Figure 2 shows that each personality produces data that represents a stylistically distinct distribution.,2 Corpus Creation,[0],[0]
"These models are probabilistic and specified values are automatically broadened within a range, thus each model can produce 10’s of variations for each MR.",2 Corpus Creation,[0],[0]
"Note that while each personality type distribution can be characterized by a single stylistic label (the personality), Figure 2 illustrates that each distribution is characterized by multiple interacting stylistic parameters.
",2 Corpus Creation,[0],[0]
Each parameter modifies the linguistic structure in order to create distributionally different subcorpora.,2 Corpus Creation,[0],[0]
"To see the effect of each personality using a different set of aggregation operators, crossreference the aggregation operations in Table 3 with an examination of the outputs in Table 1.",2 Corpus Creation,[0],[0]
"The
simplest choice for aggregation does not combine attributes at all: this is represented by the PERIOD operator, which, if used persistently, results in an output with each content item in its own sentence as in the NO-AGG/NO-PRAG row, or the content being realized over multiple sentences as in the DISAGREEABLE row (5 sentences).",2 Corpus Creation,[0],[0]
"However, if the other aggregation operations have a high value, PERSONAGE prefers to combine simple sentences into complex ones whenever it can, e.g., the EXTRAVERT personality example in Table 1 combines all the attributes into a single sentence by repeated use of the ALL MERGE and CONJUNCTION operations.",2 Corpus Creation,[0],[0]
"The CONSCIENTIOUS row in Table 1 illustrates the use of the WITH-CUE aggregation operation, e.g., with a decent rating.",2 Corpus Creation,[0],[0]
Both the AGREEABLE and CONSCIENTIOUS rows in Table 1 provide examples of the ALSO-CUE aggregation operation.,2 Corpus Creation,[0],[0]
"In PERSONAGE, the aggregation operations are defined as syntactic operations on the dictionary entry’s syntactic tree.",2 Corpus Creation,[0],[0]
"Thus to mimic these operations correctly, the neural model
must derive latent representations that function as though they also operate on syntactic trees.
",2 Corpus Creation,[0],[0]
"The pragmatic operators in the second half of Table 3 are intended to achieve particular pragmatic effects in the generated outputs: for example the use of a hedge such as sort of softens a claim and affects perceptions of friendliness and politeness (Brown and Levinson, 1987), while the exaggeration associated with emphasizers like actually, basically, really influences perceptions of extraversion and enthusiasm (Oberlander and Gill, 2004; Dewaele and Furnham, 1999).",2 Corpus Creation,[0],[0]
"In PERSONAGE, the pragmatic parameters are attached to the syntactic tree at insertion points defined by syntactic constraints, e.g., EMPHASIZERS are adverbs that can occur sentence initially or before a scalar adjective.",2 Corpus Creation,[0],[0]
Each personality model uses a variety of pragmatic parameters.,2 Corpus Creation,[0],[0]
"Figure 2 shows how these markers distribute differently across personality models, with examples in Table 1.",2 Corpus Creation,[0],[0]
"Our neural generation models build on the opensource sequence-to-sequence (seq2seq) TGen system (Dusek and Jurcı́cek, 2016a)7, implemented in Tensorflow (Abadi et al., 2016).",3 Model Architectures,[0],[0]
"The system is based on seq2seq generation with attention (Bahdanau et al., 2014; Sutskever et al., 2014), and uses a sequence of LSTMs (Hochreiter and Schmidhuber, 1997) for the encoder and decoder, combined with beam-search and reranking for output tuning.
",3 Model Architectures,[0],[0]
The input to TGen are dialogue acts for each system action (such as inform) and a set of attribute slots (such as rating) and their values (such as high for attribute rating).,3 Model Architectures,[0],[0]
The system integrates sentence planning and surface realization into a single step to produce natural language outputs.,3 Model Architectures,[0],[0]
"To preprocess the corpus of MR/utterance pairs, attributes that take on proper-noun values are delexicalized during training i.e., name and near.",3 Model Architectures,[0],[0]
"During the generation phase on the test set, a post-processing step re-lexicalizes the outputs.",3 Model Architectures,[0],[0]
"The MRs (and resultant embeddings) are sorted internally by dialogue act tag and attribute name.
",3 Model Architectures,[0],[0]
"The models are designed to systematically test the effects of increasing the level of supervision, with novel architectural additions to accommodate these changes.",3 Model Architectures,[0],[0]
"We use the default parameter settings from TGen (Dusek and Jurcı́cek, 2016a) with batch size 20 and beam size 10, and use 2,000
7https://github.com/UFAL-DSG/tgen
training instances for parameter tuning to set the number of training epochs and learning rate.",3 Model Architectures,[0],[0]
"Figure 3 summarizes the architectures.
",3 Model Architectures,[0],[0]
MODEL NOSUPERVISION.,3 Model Architectures,[0],[0]
"The simplest model follows the baseline TGen architecture (Dusek and Jurcı́cek, 2016b), with training using all 88K utterances in a single pool for up to 14 epochs based on loss monitoring for the decoder and reranker.",3 Model Architectures,[0],[0]
MODEL TOKEN.,3 Model Architectures,[0],[0]
"The second model adds a token of additional supervision by introducing a new dialogue act, convert, to encode personality, inspired by the use of a language token for machine translation (Johnson et al., 2017).",3 Model Architectures,[0],[0]
"Unlike other work that uses a single token to control generator output (Fan et al., 2017; Hu et al., 2017), the personality token encodes a constellation of different parameters that define the style of the matching reference.",3 Model Architectures,[0],[0]
"Uniquely here, the model attempts to simultaneously control multiple style variables that may interact in different ways.",3 Model Architectures,[0],[0]
"Again, we monitor loss on the validation set and training continues for up to 14 epochs for the decoder and reranker.",3 Model Architectures,[0],[0]
MODEL CONTEXT.,3 Model Architectures,[0],[0]
"The most complex model introduces a context vector, as shown at the top right of Figure 3.",3 Model Architectures,[0],[0]
The vector explicitly encodes a set of 36 style parameters from Table 3.,3 Model Architectures,[0],[0]
"The parameters for each reference text are encoded as a boolean vector, and a feed-forward network is added as a context encoder, taking the vector as input to the hidden state of the encoder and making the parameters available at every time step to a multiplicative attention unit.",3 Model Architectures,[0],[0]
"The activations of the fully connected nodes are represented as an additional
time step of the encoder of the seq2seq architecture (Sutskever et al., 2014).",3 Model Architectures,[0],[0]
"The attention (Bahdanau et al., 2014) is computed over all of the encoder states and the hidden state of the fully connected network.",3 Model Architectures,[0],[0]
"Again, we set the learning rate, alpha decay, and maximum training epochs (up to 20) based on loss monitoring on the validation set.",3 Model Architectures,[0],[0]
"Here, we present results on controlling stylistic variation while maintaining semantic fidelity.",4 Quantitative Results,[0],[0]
"It is widely agreed that new evaluation metrics are needed for NLG (Langkilde-Geary, 2002; Belz and Reiter, 2006; Bangalore et al., 2000; Novikova et al., 2017a).",4.1 Evaluating Semantic Quality,[0],[0]
"We first present automated metrics used in NLG to measure how well model outputs compare to PERSONAGE input, then introduce novel metrics designed to fill the gap left by current evaluation metrics.",4.1 Evaluating Semantic Quality,[0],[0]
Automatic Metrics.,4.1 Evaluating Semantic Quality,[0],[0]
"The automatic evaluation uses the E2E generation challenge script.8 Table 4 summarizes the results for BLEU (n-gram precision), NIST (weighted n-gram precision), METEOR (n-grams with synonym recall), and ROUGE (n-gram recall).",4.1 Evaluating Semantic Quality,[0],[0]
"Although the differences in metrics are small, MODEL CONTEXT shows a slight improvement across all of the metrics.
",4.1 Evaluating Semantic Quality,[0],[0]
"Deletions, Repetitions, and Substitutions.",4.1 Evaluating Semantic Quality,[0],[0]
"Automated evaluation metrics are not informative about the quality of the outputs, and penalize models for introducing stylistic variation.",4.1 Evaluating Semantic Quality,[0],[0]
"We thus develop new scripts to automatically evaluate the types common types of neural generation errors: deletions (failing to realize a value), repeats (repeating a value), and substitutions (mentioning an attribute with an incorrect value).
",4.1 Evaluating Semantic Quality,[0],[0]
"Table 5 shows ratios for the number of deletions, repeats, and substitutions for each model for the test set of 1,390 total realizations (278 unique MRs, each realized once for each of the 5 personalities).",4.1 Evaluating Semantic Quality,[0],[0]
"The error counts are split by personality, and normalized by the number of unique MRs
8https://github.com/tuetschek/ e2e-metrics
(278).",4.1 Evaluating Semantic Quality,[0],[0]
"Smaller ratios are preferable, indicating fewer errors.",4.1 Evaluating Semantic Quality,[0],[0]
"Note that because MODEL NOSUP does not encode a personality parameter, the error values are the same across each personality (averages across the full test set).
",4.1 Evaluating Semantic Quality,[0],[0]
The table shows that MODEL NOSUP makes very few semantic errors (we show later that this is at the cost of limited stylistic variation).,4.1 Evaluating Semantic Quality,[0],[0]
"Across all error types, MODEL CONTEXT makes significantly fewer errors than MODEL TOKEN, suggesting that its additional explicit parameters help avoid semantic errors.",4.1 Evaluating Semantic Quality,[0],[0]
"The last row quantifies whether some personalities are harder to model: it shows that across all models, DISAGREEABLE and EXTRAVERT have the most errors, while CONSCIENTIOUS has the fewest.",4.1 Evaluating Semantic Quality,[0],[0]
Here we characterize the fidelity of stylistic variation across different model outputs.,4.2 Evaluating Stylistic Variation,[0],[0]
Entropy.,4.2 Evaluating Stylistic Variation,[0],[0]
Shannon text entropy quantifies the amount of variation in the output produced by each model.,4.2 Evaluating Stylistic Variation,[0],[0]
"We calculate entropy as − ∑ x∈S freq total ∗ log2( freq total ), where S is the set of unique words in all outputs generated by the model, freq is the frequency of a term, and total counts the number of terms in all references.",4.2 Evaluating Stylistic Variation,[0],[0]
"Table 6 shows that the training data has the highest entropy, but MODEL CONTEXT performs the best at preserving the variation seen in the training data.",4.2 Evaluating Stylistic Variation,[0],[0]
"Row NOSUP shows that MODEL NOSUP makes the fewest semantic errors, but produces the least varied output.",4.2 Evaluating Stylistic Variation,[0],[0]
"MODEL CONTEXT, informed by the explicit stylistic context encoding, makes comparably few semantic errors, while producing stylistically varied output with high entropy.
",4.2 Evaluating Stylistic Variation,[0],[0]
Pragmatic Marker Usage.,4.2 Evaluating Stylistic Variation,[0],[0]
"To measure whether
the trained models faithfully reproduce the pragmatic markers for each personality, we count each pragmatic marker in Table 3 in the output, average the counts and compute the Pearson correlation between the PERSONAGE references and the outputs for each model and personality.",4.2 Evaluating Stylistic Variation,[0],[0]
"See Table 7 (all correlations significant with p ≤ 0.001).
",4.2 Evaluating Stylistic Variation,[0],[0]
"Table 7 shows that MODEL CONTEXT has the highest correlation with the training data, for all personalities (except AGREEABLE, with significant margins, and CONSCIENTIOUS, which is the easiest personality to model, with a margin of 0.01).",4.2 Evaluating Stylistic Variation,[0],[0]
"While MODEL NOSUP shows positive correlation with AGREEABLE and CONSCIENTIOUS, it shows negative correlation with the PERSONAGE inputs for DISAGREEABLE, EXTRAVERT, and UNCONSCIENTIOUS.",4.2 Evaluating Stylistic Variation,[0],[0]
"The pragmatic marker distributions for PERSONAGE train in Figure 2 indicates that the CONSCIENTIOUS personality most frequently uses acknowledgement-justify (i.e., “well”, “i see”), and request confirmation (i.e., “did you say X?”), which are less complex to introduce into a realization since they often lie at the beginning or end of a sentence, allowing the simple MODEL NOSUP to learn them.9 Aggregation.",4.2 Evaluating Stylistic Variation,[0],[0]
"To measure the ability of each model to aggregate, we average the counts of each aggregation operation for each model and personality and compute the Pearson correlation between the output and the PERSONAGE training data.
",4.2 Evaluating Stylistic Variation,[0],[0]
"The correlations in Table 8 (all significant with p ≤ 0.001) show that MODEL CONTEXT has a higher correlation with PERSONAGE than the two simpler models (except for DISAGREE-
9We verified that there is not a high correlation between every set of pragmatic markers: different personalities do not correlate, e.g., -0.078 for PERSONAGE DISAGREEABLE and MODEL TOKEN AGREEABLE.
",4.2 Evaluating Stylistic Variation,[0],[0]
"ABLE, where MODEL TOKEN is higher by 0.02).",4.2 Evaluating Stylistic Variation,[0],[0]
"Here, MODEL NOSUP actually frequently outperforms the more informed MODEL TOKEN.",4.2 Evaluating Stylistic Variation,[0],[0]
"Note that all personalities use aggregation, even thought not all personalities use pragmatic markers, and so even without a special personality token, MODEL NOSUP is able to faithfully reproduce aggregation operations.",4.2 Evaluating Stylistic Variation,[0],[0]
"In fact, since the correlations are frequently higher than those for MODEL TOKEN, we hypothesize that is able to more accurately focus on aggregation (common to all personalities) than stylistic differences, which MODEL TOKEN is able to produce.",4.2 Evaluating Stylistic Variation,[0],[0]
"Here, we present two evaluations aimed at qualitative analysis of our outputs.",5 Qualitative Analysis,[0],[0]
"Based on our quantitative results, we select MODEL CONTEXT as the best-performing model and conduct an evaluation to test if humans can distinguish the personalities exhibited.",Crowdsourcing Personality Judgements.,[0],[0]
"We randomly select a set of 10 unique MRs from the PERSONAGE training data along with their corresponding reference texts for each personality (50 items in total), and 30 unique MRs MODEL CONTEXT outputs (150 items in total).10 We construct a HIT on Mechanical Turk, presenting a single output (either PERSONAGE or MODEL CONTEXT), and ask 5 Turkers to label the output using the Ten Item Personality Inventory (TIPI)",Crowdsourcing Personality Judgements.,[0],[0]
"(Gosling et al., 2003).",Crowdsourcing Personality Judgements.,[0],[0]
"The TIPI is a ten-item measure of the Big Five personality dimensions, consisting of two items for each of the five dimensions, one that matches the dimension, and one that is the reverse of it, and a scale that ranges from 1 (disagree strongly) to 7 (agree strongly).",Crowdsourcing Personality Judgements.,[0],[0]
"To qualify Turkers for the task, we ask that they first complete a TIPI on themselves, to help ensure that they understand it.
",Crowdsourcing Personality Judgements.,[0],[0]
"Table 9 presents results as aggregated counts for the number of times at least 3 out of the 5
10Note that we use fewer PERSONAGE references simply to validate that our personalities are distinguishable in training, but will more rigorously evaluate our model in future work.
",Crowdsourcing Personality Judgements.,[0],[0]
"Turkers rated the matching item for that personality higher than the reverse item (Ratio Correct), the average rating the correct item received (range between 1-7), and an average “naturalness” score for the output (also rated 1-7).",Crowdsourcing Personality Judgements.,[0],[0]
"From the table, we can see that for PERSONAGE training data, all of the personalities have a correct ratio that is higher than 0.5.",Crowdsourcing Personality Judgements.,[0],[0]
"The MODEL CONTEXT outputs exhibit the same trend except for UNCONSCIENTIOUS and AGREEABLE, where the correct ratio is only 0.17 and 0.50, respectively (they also have the lowest correct ratio for the original PERSONAGE data).
",Crowdsourcing Personality Judgements.,[0],[0]
"Table 9 also presents results for naturalness for both the reference and generated utterances, showing that both achieve decent scores for naturalness (on a scale of 1-7).",Crowdsourcing Personality Judgements.,[0],[0]
"While human utterances would probably be judged more natural, it is not at all clear that similar experiments could be done with human generated utterances, where it is difficult to enforce the same amount of experimental control.
",Crowdsourcing Personality Judgements.,[0],[0]
Generalizing to Multiple Personalities.,Crowdsourcing Personality Judgements.,[0],[0]
A final experiment explores whether the models learn additional stylistic generalizations not seen in training.,Crowdsourcing Personality Judgements.,[0],[0]
"We train a version of MODEL TOKEN, as before on instances with single personalities, but such that it can be used to generate output with a combination of two personalities.",Crowdsourcing Personality Judgements.,[0],[0]
"The experiment uses the original training data for MODEL TOKEN, but uses an expanded test set where the MR includes two personality CONVERT tags.",Crowdsourcing Personality Judgements.,[0],[0]
"We pair each personality with all personalities except its exact opposite.
",Crowdsourcing Personality Judgements.,[0],[0]
"Sample outputs are given in Table 10 for the DISAGREEABLE personality, which is one of the most distinct in terms of aggregation and pragmatic marker insertion, along with occurrence counts (frequency shown scaled down by 100) of the operations that it does most frequently: specifically, period aggregation and expletive pragmatic markers.",Crowdsourcing Personality Judgements.,[0],[0]
"Rows 1-2 shows the counts and an exam-
ple of each personality on its own.",Crowdsourcing Personality Judgements.,[0],[0]
The combined personality output is shown in Row 3.,Crowdsourcing Personality Judgements.,[0],[0]
"We can see from the table that while CONSCIENTIOUS on its own realizes the content in two sentences, period aggregation is much more prevalent in the DISAGREEABLE + CONSCIENTIOUS example, with the same content being realized in 5 sentences.",Crowdsourcing Personality Judgements.,[0],[0]
"Also, we see that some of the expletives originally in DISAGREEABLE are dropped in the combined output.",Crowdsourcing Personality Judgements.,[0],[0]
"This suggests that the model learns a combined representation unlike what it has seen in train, which we will explore in future work.",Crowdsourcing Personality Judgements.,[0],[0]
"The restaurant domain has long been a testbed for conversational agents with much earlier work on NLG (Howcroft et al., 2013; Stent et al., 2004; Devillers et al., 2004; Gašic et al., 2008; Mairesse et al., 2010; Higashinaka et al., 2007), so it is not surprising that recent work using neural generation methods has also focused on the restaurant domain (Wen et al., 2015; Mei et al., 2015; Dusek and Jurcı́cek, 2016b; Lampouras and Vlachos, 2016; Juraska et al., 2018).",6 Related Work and Conclusion,[0],[0]
"The restaurant domain is ideal for testing generation models because sentences can range from extremely simple to more complex forms that exhibit discourse relations such as justification or contrast (Stent et al., 2004).",6 Related Work and Conclusion,[0],[0]
"Most recent work focuses on achieving semantic fidelity for simpler syntactic structures, although there has also been a focus on crowdsourcing or harvesting training data that exhibits more stylistic variation (Novikova et al., 2017; Nayak et al., 2017; Oraby et al., 2017).
",6 Related Work and Conclusion,[0],[0]
"Most previous work on neural stylistic generation has been carried out in the framework of “style transfer”: this work is hampered by the
lack of parallel corpora, the difficulty of evaluating content preservation (semantic fidelity), and the challenges with measuring whether the outputs realize a particular style.",6 Related Work and Conclusion,[0],[0]
"Previous experiments attempt to control the sentiment and verb tense of generated movie review sentences (Hu et al., 2017), the content preservation and style transfer of news headlines and product review sentences (Fu et al., 2018), multiple automatically extracted style attributes along with sentiment and sentence theme for movie reviews (Ficler and Goldberg, 2017), sentiment, fluency and semantic equivalence (Shen et al., 2017), utterance length and topic (Fan et al., 2017), and the personality of customer care utterances in dialogue (Herzig et al., 2017).",6 Related Work and Conclusion,[0],[0]
"However, to our knowledge, no previous work evaluates simultaneous achievement of multiple targets as we do.",6 Related Work and Conclusion,[0],[0]
"Recent work introduces a large parallel corpus that varies on the formality dimension, and introduces several novel evaluation metrics, including a custom trained model for measuring semantic fidelity (Rao and Tetreault).
",6 Related Work and Conclusion,[0],[0]
"Other work has also used context representations, but not in the way that we do here.",6 Related Work and Conclusion,[0],[0]
"In general, these have been used to incorporate a representation of the prior dialogue into response generation.",6 Related Work and Conclusion,[0],[0]
Sordoni et al. (2015) propose a basic approach where they incorporate previous utterances as a bag of words model and use a feed-forward neural network to inject a fixed sized context vector into the LSTM cell of the encoder.,6 Related Work and Conclusion,[0],[0]
Ghosh et al. (2016) proposed a modified LSTM cell with an additional gate that incorporates the previous context as input during encoding.,6 Related Work and Conclusion,[0],[0]
"Our context representation encodes stylistic parameters.
",6 Related Work and Conclusion,[0],[0]
This paper evaluates the ability of different neural architectures to faithfully render the semantic content of an utterance while simultaneously exhibiting stylistic variations characteristic of Big Five personalities.,6 Related Work and Conclusion,[0],[0]
"We created a novel parallel training corpus of over 88,000 meaning representations in the restaurant domain, and matched reference outputs by using an existing statistical natural language generator, PERSONAGE (Mairesse and Walker, 2010).",6 Related Work and Conclusion,[0],[0]
"We design three neural models that systematically increase the stylistic encodings given to the network, and show that MODEL CONTEXT benefits from the greatest explicit stylistic supervision, producing outputs that both preserve semantic fidelity and exhibit distinguishable personality styles.",6 Related Work and Conclusion,[0],[0]
Natural language generators for taskoriented dialogue must effectively realize system dialogue actions and their associated semantics.,abstractText,[0],[0]
"In many applications, it is also desirable for generators to control the style of an utterance.",abstractText,[0],[0]
"To date, work on task-oriented neural generation has primarily focused on semantic fidelity rather than achieving stylistic goals, while work on style has been done in contexts where it is difficult to measure content preservation.",abstractText,[0],[0]
Here we present three different sequence-to-sequence models and carefully test how well they disentangle content and style.,abstractText,[0],[0]
"We use a statistical generator, PERSONAGE, to synthesize a new corpus of over 88,000 restaurant domain utterances whose style varies according to models of personality, giving us total control over both the semantic content and the stylistic variation in the training data.",abstractText,[0],[0]
We then vary the amount of explicit stylistic supervision given to the three models.,abstractText,[0],[0]
"We show that our most explicit model can simultaneously achieve high fidelity to both semantic and stylistic goals: this model adds a context vector of 36 stylistic parameters as input to the hidden state of the encoder at each time step, showing the benefits of explicit stylistic supervision, even when the amount of training data is large.",abstractText,[0],[0]
Controlling Personality-Based Stylistic Variation with Neural Natural Language Generators,title,[0],[0]
"Many problems in machine learning, data mining, and signal processing can be formulated as the following composite minimization problem
min x∈Rd F (x) = f(x) + g(x).",1. Introduction,[0],[0]
"(P)
Typically, f : Rd → R captures the loss of data fitting and can be written as f = 1n",1. Introduction,[0],[0]
∑n l=1 fl with each fl corresponding to the loss of one sample.,1. Introduction,[0],[0]
"The second term g : Rd → R is the regularizer that promotes desired structures on the solution based on prior knowledge of the problem.
",1. Introduction,[0],[0]
"1Syracuse University, NY, USA.",1. Introduction,[0],[0]
Correspondence to:,1. Introduction,[0],[0]
"Qunwei Li <qli33@syr.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"Algorithm 1 APG
Input: y1 =",1. Introduction,[0],[0]
"x1 = x0, t1 = 1, t0 = 0, η < 1L .",1. Introduction,[0],[0]
"for k = 1, 2, · · · do yk = xk +
tk−1−1 tk
(xk − xk−1).",1. Introduction,[0],[0]
"xk+1 = proxηg(yk − η∇f(yk)).
",1. Introduction,[0],[0]
"tk+1 =
√ 4t2k+1+1
2 .",1. Introduction,[0],[0]
"end for
In practice, many problems of (P) are formulated, either naturally or intensionally, into a convex model to guarantee the tractability of algorithms.",1. Introduction,[0],[0]
"In particular, such convex problems can be efficiently minimized by many firstorder algorithms, among which the accelerated proximal gradient (APG) method (also referred to as FISTA (Beck & Teboulle, 2009b)) is proven to be the best for minimizing such class of convex functions.",1. Introduction,[0],[0]
We present one of its basic forms in Algorithm 1.,1. Introduction,[0],[0]
"Compared to the usual proximal gradient step, the APG algorithm takes an extra linear extrapolation step for acceleration.",1. Introduction,[0],[0]
"It has been shown (Beck & Teboulle, 2009b) that the APG method reduces the function value gap at a rate of O(1/k2) where k denotes the number of iterations.",1. Introduction,[0],[0]
This convergence rate meets the theoretical lower bound of first-order gradient methods for minimizing smooth convex functions.,1. Introduction,[0],[0]
"The reader can refer to (Tseng, 2010) for other variants of APG.
",1. Introduction,[0],[0]
"Algorithm 2 Monotone APG (mAPG)
",1. Introduction,[0],[0]
"Input: y1 = x1 = x0, t1 = 1, t0 = 0, η < 1L .",1. Introduction,[0],[0]
"for k = 1, 2, · · · do yk = xk +
tk−1 tk (zk − xk) + tk−1−1tk (xk − xk−1).",1. Introduction,[0],[0]
zk+1 =,1. Introduction,[0],[0]
proxηg(yk − η∇f(yk)).,1. Introduction,[0],[0]
"vk+1 = proxηg(xk − η∇f(xk)).
",1. Introduction,[0],[0]
"tk+1 =
√ 4t2k+1+1
2 .",1. Introduction,[0],[0]
"if F (zk+1) ≤ F (vk+1) then xk+1 = zk+1, else if F (vk+1) ≤",1. Introduction,[0],[0]
"F (zk+1) then xk+1 = vk+1.
end if end for
Although convex problems are tractable and can be glob-
Algorithm 3 APG non-convex problem (",1. Introduction,[0],[0]
"APGnc)
Input: y1 = x0, βk = kk+3 , η < 1 L .",1. Introduction,[0],[0]
"for k = 1, 2, · · · do xk = proxηg(yk − η∇f(yk)).",1. Introduction,[0],[0]
vk = xk,1. Introduction,[0],[0]
+ βk(xk,1. Introduction,[0],[0]
− xk−1).,1. Introduction,[0],[0]
"if F (xk) ≤ F (vk) then yk+1 = xk,
else if F (vk) ≤",1. Introduction,[0],[0]
"F (xk) then yk+1 = vk.
end if end for
ally minimized, many applications naturally require to solve nonconvex optimization problems of (P).",1. Introduction,[0],[0]
"Recently, several variants of the APG method have been proposed for nonconvex problems, and two major ones are presented in Algorithm 2 and Algorithm 3, respectively.",1. Introduction,[0],[0]
"The major difference to the original APG is that the modified methods only accept the new iterate when the corresponding function value is sufficiently decreased, which leads to a more stable convergence behavior.",1. Introduction,[0],[0]
"In particular, (Li & Lin, 2015) analyzed mAPG (Algorithm 2) by exploiting the KurdykaŁojasiewicz (KŁ) property, which is a local geometrical structure very generally held by a large class of nonconvex objective functions, and has been successfully exploited to characterize the asymptotic convergence behavior of many first order methods.",1. Introduction,[0],[0]
"It was shown in (Li & Lin, 2015) that mAPG achieves the O(1/k2) convergence rate for convex problems of (P), and converges to a critical point at sublinear and linear rates under different cases of the KL property for nonconvex problems.",1. Introduction,[0],[0]
"Despite the desirable convergence rate, mAPG requires two proximal steps, which doubles the computational complexity of the original APG.",1. Introduction,[0],[0]
"In comparison, the APGnc (Algorithm 3) requires only one proximal step, and hence computes faster than mAPG in each iteration.",1. Introduction,[0],[0]
"However, the analysis of APGnc in (Yao & Kwok, 2016) does not exploit the KL property and no convergence rate of the function value is established.",1. Introduction,[0],[0]
"Hence, there is still no formal theoretical comparison of the overall performance (which depends on both computation per iteration and convergence rate) between mAPG and APGnc.",1. Introduction,[0],[0]
"It is unclear whether the computational saving per iteration in APGnc is at the cost of lower convergence rate.
",1. Introduction,[0],[0]
"The goal of this paper is to provide a comprehensive analysis of the APGnc algorithm under the KL framework, thus establishing a rigorous comparison between mAPG and APGnc and formally justifying the overall advantage of APGnc.",1. Introduction,[0],[0]
This paper provides the convergence analysis of APGnc type algorithms for nonconvex problems of (P) under the KL framework as well as the inexact situation.,1.1. Main Contributions,[0],[0]
We also study the stochastic variance reduced APGnc algorithm and its inexact situation.,1.1. Main Contributions,[0],[0]
"Our analysis requires novel technical treatments to exploit the KŁ property due to the joint appearance of the following ingredients in the algorithms including momentum terms, inexact errors, and stochastic variance reduced gradients.",1.1. Main Contributions,[0],[0]
"Our contributions are summarized as follows.
",1.1. Main Contributions,[0],[0]
"For APGnc applied to nonconvex problems of (P), we show that the limit points of the sequences generated by APGnc are critical points of the objective function.",1.1. Main Contributions,[0],[0]
"Then, by exploiting different cases of the Kurdyka-Łojasiewicz property of the objective function, we establish the linear and sub-linear convergence rates of the function value sequence generated by APGnc.",1.1. Main Contributions,[0],[0]
"Our results formally show that APGnc (with one proximal map per iteration) achieves the same convergence properties as well as the convergence rates as mAPG (with two proximal maps per iteration) for nonconvex problems, thus establishing its overall computational advantage.
",1.1. Main Contributions,[0],[0]
"We further propose an APGnc+ algorithm, which is an improved version of APGnc by adapting the momentum stepsize (see Algorithm 4), and shares the same theoretical convergence rate as APGnc but numerically performs better than APGnc.
",1.1. Main Contributions,[0],[0]
"Furthermore, we study the inexact APGnc in which the computation of the gradient and the proximal mapping may have errors.",1.1. Main Contributions,[0],[0]
We show that the algorithm still achieves the convergence rate at the same order as the exact case as long as the inexactness is properly controlled.,1.1. Main Contributions,[0],[0]
"We also explicitly characterize the impact of errors on the constant factors that affect the convergence rate.
",1.1. Main Contributions,[0],[0]
"To facilitate the solution to large-scale optimization problems, we study the stochastic variance reduced APGnc (SVRG-APGnc), and show that such an algorithm achieves linear convergence rate under a certain case of the KŁ property.",1.1. Main Contributions,[0],[0]
We further analyze the inexact SVRG-APGnc and show that it also achieves the linear convergence under the same KŁ property as long as the error in the proximal mapping is bounded properly.,1.1. Main Contributions,[0],[0]
"This is the first analysis of the SVRG proximal algorithm with momentum that exploits the KŁ structure to establish linear convergence rate for nonconvex programming.
",1.1. Main Contributions,[0],[0]
Our numerical results further corroborate the theoretic analysis.,1.1. Main Contributions,[0],[0]
"We demonstrate that APGnc/APGnc+ outperforms APG and mAPG for nonconvex problems in both exact and inexact cases, and in both deterministic and stochastic variants of the algorithms.",1.1. Main Contributions,[0],[0]
"Furthermore,
APGnc+ outperforms APGnc due to properly chosen momentum stepsize.",1.1. Main Contributions,[0],[0]
"APG algorithms: The original accelerated gradient method for minimizing a single smooth convex function dates back to (Nesterov, 1983), and is further extended as APG in the composite minimization framework in (Beck & Teboulle, 2009b; Tseng, 2010).",1.2. Comparison to Related Work,[0],[0]
"While these APG variants generate a sequence of function values that may oscillate, (Beck & Teboulle, 2009a) proposed another variant of APG that generates a non-increasing sequence of function values.",1.2. Comparison to Related Work,[0],[0]
"Then, (Li & Lin, 2015) further proposed an mAPG that generates a sufficiently decreasing sequence of function values, and established the asymptotic convergence rates under the KŁ property.",1.2. Comparison to Related Work,[0],[0]
"Recently, (Yao & Kwok, 2016) proposed APGnc, which is a more efficient version of APG for nonconvex problems, but the analysis only characterizes fixed points and did not exploit the KŁ property to characterize the convegence rate.",1.2. Comparison to Related Work,[0],[0]
"A unified treatment of accelerated gradient method for nonconvex stochastic optimization is presented in (Ghadimi & Lan, 2016).",1.2. Comparison to Related Work,[0],[0]
"But the discussion does not exploit the KŁ property, and requires function g to be convex.",1.2. Comparison to Related Work,[0],[0]
"Our study establishes the convergence rate analysis of APGnc under the KŁ property.
",1.2. Comparison to Related Work,[0],[0]
"Nonconvex optimization under KŁ: The KŁ property (Bolte et al., 2007) is an extension of the Łojasiewicz gradient inequality (Łojasiewicz, 1965) to the nonsmooth case.",1.2. Comparison to Related Work,[0],[0]
"Many first-order descent methods, under the KŁ property, can be shown to converge to a critical point (Attouch & Bolte, 2009; Attouch et al., 2010; Bolte et al., 2014) with different types of asymptotic convergence rates.",1.2. Comparison to Related Work,[0],[0]
"(Li & Lin, 2015) and our paper focuses on the first-order algorithms with momentum, and respectively analyze mAPG and APGnc by exploiting the KŁ property.
",1.2. Comparison to Related Work,[0],[0]
"Inexact algorithms under KŁ: (Attouch et al., 2013; Frankel et al., 2015) studied the inexact proximal algorithm under the KŁ property.",1.2. Comparison to Related Work,[0],[0]
"This paper studies the inexact proximal algorithm with momentum (i.e., APGnc) under the KŁ property.",1.2. Comparison to Related Work,[0],[0]
"While (Yao & Kwok, 2016) also studied the inexact APGnc, the analysis did not exploit the KŁ property to characterize the convergence rate.
",1.2. Comparison to Related Work,[0],[0]
"Nonconvex SVRG: SVRG was first proposed in (Johnson & Zhang, 2013), to accelerate the stochastic gradient method for strongly convex objective functions, and was studied for the convex case in (Zhu & Yuan, 2016).",1.2. Comparison to Related Work,[0],[0]
"Recently, SVRG was further studied for smooth nonconvex optimization in Reddi et al. (2016a).",1.2. Comparison to Related Work,[0],[0]
"Then in (Reddi et al., 2016b), the proximal SVRG was proposed and studied for nonsmooth and nonconvex optimization.",1.2. Comparison to Related Work,[0],[0]
Our paper further incorporates SVRG for the proximal gradient with momentum in the nonconvex case.,1.2. Comparison to Related Work,[0],[0]
"Furthermore, we exploit a cer-
tain KŁ property in our analysis that is very different from the PL property exploited in (Reddi et al., 2016a), and requires special technical treatment in convergence analysis.",1.2. Comparison to Related Work,[0],[0]
"In this section, we first introduce some technical definitions that are useful later on, and then describe the assumptions on the problem (P) that we take in this paper.
",2. Preliminaries and Assumptions,[0],[0]
"Throughout this section, h : Rd → (−∞,+∞] is an extended real-valued function that is proper, i.e., its domain domh := {x ∈ Rd : h(x) < ∞} is nonempty, and is closed, i.e., its sublevel sets {x ∈",2. Preliminaries and Assumptions,[0],[0]
"Rd : h(x) ≤ α} are closed for all α ∈ R. Note that a proper and closed function h can be nonsmooth and nonconvex, hence we consider the following generalized notion of derivative.
",2. Preliminaries and Assumptions,[0],[0]
"Definition 1 (Subdifferential, (Rockafellar & Wets, 1997)).",2. Preliminaries and Assumptions,[0],[0]
"The Frechét subdifferential ∂̂h of h at x ∈ domh is the set of u ∈ Rd such that
lim inf z6=x,z→x
h(z)−h(x)−u>(z−x)",2. Preliminaries and Assumptions,[0],[0]
"‖z−x‖ ≥ 0,
while the (limiting) subdifferential",2. Preliminaries and Assumptions,[0],[0]
∂h,2. Preliminaries and Assumptions,[0],[0]
"at x ∈ domh is the graphical closure of ∂̂h:
{u : ∃(xk, h(xk))→ (x, h(x)), ∂̂h(xk) 3 uk → u}.
",2. Preliminaries and Assumptions,[0],[0]
"In particular, this generalized derivative reduceds to ∇h when h is continuously differentiable, and reduces to the usual subdifferential when h is convex.
",2. Preliminaries and Assumptions,[0],[0]
Definition 2 (Critical point).,2. Preliminaries and Assumptions,[0],[0]
A point x ∈ Rd is a critical point of h iff 0 ∈ ∂h(x).,2. Preliminaries and Assumptions,[0],[0]
Definition 3 (Distance).,2. Preliminaries and Assumptions,[0],[0]
"The distance of a point x ∈ Rd to a closed set Ω ⊆ Rd is defined as:
distΩ(x) := miny∈Ω ‖y",2. Preliminaries and Assumptions,[0],[0]
"− x‖. (1)
",2. Preliminaries and Assumptions,[0],[0]
"Definition 4 (Proximal map, e.g. (Rockafellar & Wets, 1997)).",2. Preliminaries and Assumptions,[0],[0]
"The proximal map of a point x ∈ Rd under a proper and closed function h with parameter η > 0 is defined as:
proxηh(x) := argminz h(z)",2. Preliminaries and Assumptions,[0],[0]
"+ 1 2η‖z− x‖ 2, (2)
where ‖ · ‖ is the Euclidean l2 norm.
",2. Preliminaries and Assumptions,[0],[0]
"We note that when h is convex, the corresponding proximal map is the minimizer of a strongly convex function, i.e., a singleton.",2. Preliminaries and Assumptions,[0],[0]
"But for nonconvex h, the proximal map can be set-valued, in which case proxηh(x) stands for an arbitrary element from that set.",2. Preliminaries and Assumptions,[0],[0]
"The proximal map is a popular tool to handle the nonsmooth part of the objective function, and is the key component of proximal-like algorithms (Beck & Teboulle, 2009b; Bolte et al., 2014).
",2. Preliminaries and Assumptions,[0],[0]
"Definition 5 (Uniformized KŁ property, (Bolte et al., 2014)).",2. Preliminaries and Assumptions,[0],[0]
"Function h is said to satisfy the uniformized KŁ property if for every compact set Ω ⊂ domh on which h is constant, there exist ε, λ > 0 such that for all x̄ ∈ Ω and all x ∈ {x ∈",2. Preliminaries and Assumptions,[0],[0]
Rd : distΩ(x) < ε} ∩,2. Preliminaries and Assumptions,[0],[0]
[x : h(x̄) < h(x),2. Preliminaries and Assumptions,[0],[0]
"< h(x̄) + λ], one has
ϕ′ (h(x)− h(x̄)) · dist∂h(x)(0) ≥ 1, (3)
where the function ϕ",2. Preliminaries and Assumptions,[0],[0]
": [0, λ)→ R+ takes the form ϕ(t) =",2. Preliminaries and Assumptions,[0],[0]
"c θ t θ for some constants c > 0, θ ∈ (0, 1].
",2. Preliminaries and Assumptions,[0],[0]
"The above definition is a modified version of the original KŁ property (Bolte et al., 2010; Kurdyka, 1998), and is more convenient for our analysis later.",2. Preliminaries and Assumptions,[0],[0]
"The KŁ property is a generalization of the Łojasiewicz gradient inequality to nonsmooth functions (Bolte et al., 2007), and it is a powerful tool to analyze a class of first-order descent algorithms (Attouch & Bolte, 2009; Attouch et al., 2010; Bolte et al., 2014).",2. Preliminaries and Assumptions,[0],[0]
"In particular, the class of semi-algebraic functions satisfy the above KŁ property.",2. Preliminaries and Assumptions,[0],[0]
"This function class covers most objective functions in real applications, for instance, all lp where p ≥ 0 and is rational, real polynomials, rank, etc.",2. Preliminaries and Assumptions,[0],[0]
"For a more detailed discussion and a list of examples of KŁ functions, see (Bolte et al., 2014) and (Attouch et al., 2010).
",2. Preliminaries and Assumptions,[0],[0]
We adopt the following assumptions on the problem (P) in this paper.,2. Preliminaries and Assumptions,[0],[0]
Assumption 1.,2. Preliminaries and Assumptions,[0],[0]
"Regarding the functions f, g (and F = f+ g) in (P)",2. Preliminaries and Assumptions,[0],[0]
infx∈Rd F (x) > −∞; the sublevel set {x ∈,1. They are proper and lower semicontinous;,[0],[0]
Rd : F (x) ≤ α} is bounded for all α ∈ R; 2.,1. They are proper and lower semicontinous;,[0],[0]
They satisfy the uniformized KŁ property; 3.,1. They are proper and lower semicontinous;,[0],[0]
"Function f is continuously differentiable and the gradi-
ent ∇f is L-Lipschitz continuous.
",1. They are proper and lower semicontinous;,[0],[0]
"Note that the sublevel set of F is bounded when either f or g has bounded sublevel set, i.e., f(x) or g(x) → +∞ as ‖x‖ → +∞. Of course, we do not assume convexity on either f or g, and the KŁ property serves as an alternative in this general setting.",1. They are proper and lower semicontinous;,[0],[0]
"In this section, we provide our main results on the convergence analysis of APGnc and SVRG-APGnc as well as inexact variants of these algorithms.",3. Main Results,[0],[0]
All proofs of the theorems are provided in supplemental materials.,3. Main Results,[0],[0]
"In this subsection, we characterize the convergence of APGnc.",3.1. Convergence Analysis,[0],[0]
"Our first result characterizes the behavior of the limit points of the sequence generated by APGnc.
Theorem 1.",3.1. Convergence Analysis,[0],[0]
"Let Assumption 1.{1,3} hold for the problem (P).",3.1. Convergence Analysis,[0],[0]
Then with stepsize η,3.1. Convergence Analysis,[0],[0]
"< 1L , the sequence {xk} generated by APGnc satisfies
1.",3.1. Convergence Analysis,[0],[0]
{xk} is a bounded seuqence; 2.,3.1. Convergence Analysis,[0],[0]
"The set of limit points Ω of {xk} forms a compact set,
on which the objective function F is constant; 3.",3.1. Convergence Analysis,[0],[0]
"All elements of Ω are critical points of F .
",3.1. Convergence Analysis,[0],[0]
"Theorem 1 states that the sequence {xk} generated by APGnc eventually approaches a compact set (i.e., a closed and bounded set in Rd) of critical points, and the objective function remains constant on it.",3.1. Convergence Analysis,[0],[0]
"Here, approaching critical points establishes the first step for solving general nonconvex problems.",3.1. Convergence Analysis,[0],[0]
"Moreover, the compact set Ω meets the requirements of the uniform KŁ property, and hence provides a seed to exploit the KŁ property around it.",3.1. Convergence Analysis,[0],[0]
"Next, we further utilize the KŁ property to establish the asymptotic convergence rate for APGnc.",3.1. Convergence Analysis,[0],[0]
"In the following theorem, θ is the parameter in the uniformized KŁ property via the function ϕ",3.1. Convergence Analysis,[0],[0]
that takes the form ϕ(t) =,3.1. Convergence Analysis,[0],[0]
"cθ t
θ for some c > 0, θ ∈ (0, 1].
",3.1. Convergence Analysis,[0],[0]
Theorem 2.,3.1. Convergence Analysis,[0],[0]
"Let Assumption 1.{1,2,3} hold for the problem (P).",3.1. Convergence Analysis,[0],[0]
Let F (x) ≡,3.1. Convergence Analysis,[0],[0]
"F ∗ for all x ∈ Ω (the set of limit points), and denote rk := F (xk)− F ∗. Then with stepsize η <",3.1. Convergence Analysis,[0],[0]
"1L , the sequence {rk} satisfies for k0 large enough",3.1. Convergence Analysis,[0],[0]
2.,"1. If θ = 1, then rk reduces to zero in finite steps;",[0],[0]
"If θ ∈ [ 12 , 1), then rk ≤ ( c2d1 1+c2d1 )k−k0rk0 ; 3.","1. If θ = 1, then rk reduces to zero in finite steps;",[0],[0]
"If θ ∈ (0, 12 ), then rk ≤","1. If θ = 1, then rk reduces to zero in finite steps;",[0],[0]
"( c (k−k0)d2(1−2θ) ) 1 1−2θ ,
where d1 = ( 1η + L) 2/( 12η − L 2 ) and d2 = min{ 12cd1 , c 1−2θ (2 2θ−1 2θ−2 − 1)r2θ−1k0 }.
","1. If θ = 1, then rk reduces to zero in finite steps;",[0],[0]
"Theorem 2 characterizes three types of convergence behaviors of APGnc, depending on θ that parameterizes the KŁ property that the objective function satisfies.","1. If θ = 1, then rk reduces to zero in finite steps;",[0],[0]
An illustrative example for the first kind (θ = 1) can take a form similar to F (x) = |x| for x ∈ R around the critical points.,"1. If θ = 1, then rk reduces to zero in finite steps;",[0],[0]
The function is ‘sharp’ around its critical point x = 0 and thus the iterates slide down quickly onto it within finite steps.,"1. If θ = 1, then rk reduces to zero in finite steps;",[0],[0]
"For the second kind (θ ∈ [ 12 , 1)), example functions can take a form similar to F (x) =","1. If θ = 1, then rk reduces to zero in finite steps;",[0],[0]
x2 around the critical points.,"1. If θ = 1, then rk reduces to zero in finite steps;",[0],[0]
"That is, the function is strongly convex-like and hence the convergence rate is typically linear.","1. If θ = 1, then rk reduces to zero in finite steps;",[0],[0]
"Lastly, functions of the third kind are ‘flat’ around its critical points and thus the convergence is slowed down to sub-linear rate.","1. If θ = 1, then rk reduces to zero in finite steps;",[0],[0]
"We note that characterizing the value of θ for a given function is a highly non-trivial problem that takes much independent effort (Kurdyka & Spodzieja, 2011; Li & Kei, 2016).","1. If θ = 1, then rk reduces to zero in finite steps;",[0],[0]
"Nevertheless, KŁ property provides a general picture of the asymptotic convergence behaviors of APGnc.
Algorithm 4 APGnc with adaptive momentum (","1. If θ = 1, then rk reduces to zero in finite steps;",[0],[0]
"APGnc+)
Input: y1 = x0, β, t ∈ (0, 1), η < 1L .","1. If θ = 1, then rk reduces to zero in finite steps;",[0],[0]
"for k = 1, 2, · · · do xk = proxηg(yk − η∇f(yk)).","1. If θ = 1, then rk reduces to zero in finite steps;",[0],[0]
vk = xk + β(xk − xk−1).,"1. If θ = 1, then rk reduces to zero in finite steps;",[0],[0]
"if F (xk) ≤ F (vk) then yk+1 = xk, β ← tβ.
else if F (vk) ≤ F (xk) then yk+1 = vk, β ← min{βt , 1}.
end if end for","1. If θ = 1, then rk reduces to zero in finite steps;",[0],[0]
"The original APGnc sets the momentum parameter βk = k k+3 , which can be theoretically justified only for convex problems.",3.2. APGnc with Adaptive Momentum,[0],[0]
"We here propose an alternative choice of the momentum stepsize that is more intuitive for nonconvex problems, and refer to the resulting algorithm as APGnc+ (See Algorithm 4).",3.2. APGnc with Adaptive Momentum,[0],[0]
The idea is to enlarge the momentum β to further exploit the opportunity of acceleration when the extrapolation step vk achieves a lower function value.,3.2. APGnc with Adaptive Momentum,[0],[0]
"Since the proofs of Theorem 1 and Theorem 2 do not depend on the exact value of the momentum stepsize, APGnc and APGnc+ have the same order-level convergence rate.",3.2. APGnc with Adaptive Momentum,[0],[0]
"However, we show in Section 4 that APGnc+ improves upon APGnc numerically.",3.2. APGnc with Adaptive Momentum,[0],[0]
"We further consider inexact APGnc, in which computation of the proximal gradient step may be inexact, i.e.,
xk = prox k ηg(yk",3.3. Inexact APGnc,[0],[0]
"− η(∇f(yk) + ek)),
where ek captures the inexactness of computation of ∇f(yk), and k captures the inexactness of evaluation of the proximal map as given by
x = prox ηg(y)
",3.3. Inexact APGnc,[0],[0]
"= {u | g(u) + 12η‖u− y‖ 2
≤ + g(v) + 12η‖v",3.3. Inexact APGnc,[0],[0]
"− y‖ 2, ∀v ∈ Rd}.",3.3. Inexact APGnc,[0],[0]
"(4)
The inexact proximal algorithm has been studied in (Attouch et al., 2013) for nonconvex functions under the KŁ property.",3.3. Inexact APGnc,[0],[0]
"Our study here is the first treatment of inexact proximal algorithms with momentum (i.e., APG-like algorithms).",3.3. Inexact APGnc,[0],[0]
"Furthermore, previous studies addressed only the inexactness of gradient computation for nonconvex problems, but our study here also includes the inexactness of the proximal map for nonconvex problems requiring only g to be convex as the second case we specify below.
",3.3. Inexact APGnc,[0],[0]
"We study the following two cases.
1.",3.3. Inexact APGnc,[0],[0]
g is convex; 2.,3.3. Inexact APGnc,[0],[0]
"g is nonconvex, and = 0.
",3.3. Inexact APGnc,[0],[0]
"In the first case, ∂g(x) reduces to the usual subdifferential of convex functions, and the inexactness naturally induces the following -subdifferential
∂ g(x) = {u | g(y) ≥ g(x) +",3.3. Inexact APGnc,[0],[0]
"〈y − x,u〉 − ,∀y ∈ Rd}.
",3.3. Inexact APGnc,[0],[0]
"Moreover, since the KŁ property utilizes the information of ∂F , we then need to characterize the perturbation of ∂g under the inexactness .",3.3. Inexact APGnc,[0],[0]
"This leads to the following definition.
",3.3. Inexact APGnc,[0],[0]
Definition 6.,3.3. Inexact APGnc,[0],[0]
"For any x ∈ Rd, let u′ ∈ ∂ g(x) such that ∇f(x) + u′ has the minimal norm.",3.3. Inexact APGnc,[0],[0]
"Then the perturbation between ∂g and ∂ g is defined as ξ := dist∂g(x)(u′).
",3.3. Inexact APGnc,[0],[0]
"The following theorem states that for nonconvex functions, as long as the inexactness parameters ek, k and ξk are properly controlled, then the inexact APGnc converges at the same order-level rate as the corresponding exact algorithm.
",3.3. Inexact APGnc,[0],[0]
Theorem 3.,3.3. Inexact APGnc,[0],[0]
"Consider the above two cases for inexact APGnc under Assumption 1.{1,2,3}.",3.3. Inexact APGnc,[0],[0]
"If for all k ∈ N
‖ek‖ ≤",3.3. Inexact APGnc,[0],[0]
"γ‖xk − yk‖, (5) k ≤",3.3. Inexact APGnc,[0],[0]
δ‖xk,3.3. Inexact APGnc,[0],[0]
"− yk‖2, (6) ξk ≤",3.3. Inexact APGnc,[0],[0]
"λ‖xk − yk‖, (7)
then all the statements in Theorem 1 remain true and the convergence rates in Theorem 2 remain at the same order with the constants d1 = ( 1η + L + C) 2/( 12η",3.3. Inexact APGnc,[0],[0]
"− L 2 − C), where C > 0 depends on γ, δ and λ, and d2 = min{ 12cd1 , c 1−2θ (2 2θ−1 2θ−2 − 1)r2θ−1k0 }.",3.3. Inexact APGnc,[0],[0]
"Correspondingly, a smaller stepsize η < 12C+L should be used.
",3.3. Inexact APGnc,[0],[0]
"It can be seen that, due to the inexactness, the constant factor d1 in Theorem 2 is enlarged, which further leads to a smaller d2 in Theorem 2.",3.3. Inexact APGnc,[0],[0]
"Hence, the corresponding convergence rates are slower compared to the exact case, but remain at the same order.",3.3. Inexact APGnc,[0],[0]
"In this subsection, we study the stochastic variance reduced APGnc algorithm, referred to as SVRG-APGnc.",3.4. Stochastic Variance Reduced APGnc,[0],[0]
The main steps are presented in Algorithm 5.,3.4. Stochastic Variance Reduced APGnc,[0],[0]
"The major difference from APGnc is that the single proximal gradient step is replaced by a loop of stochastic proximal gradient steps using variance reduced gradients.
",3.4. Stochastic Variance Reduced APGnc,[0],[0]
"Due to the stochastic nature of the algorithm, the iterate sequence may not stably stay in the local KŁ region, and hence the standard KŁ approach fails.",3.4. Stochastic Variance Reduced APGnc,[0],[0]
"We then focus on the analysis of the special but important case of the global KŁ
Algorithm 5 SVRG-APGnc
Input: y0 = x00, βk = kk+3 ,m, η < 1 2mL .",3.4. Stochastic Variance Reduced APGnc,[0],[0]
"for k = 0, 1, 2, · · · do
x0k = yk,gk = ∇f(yk).",3.4. Stochastic Variance Reduced APGnc,[0],[0]
"for t = 0, 1, · · · ,m− 1 do
sample ξ from {1, 2, · · · , n}.",3.4. Stochastic Variance Reduced APGnc,[0],[0]
vtk = ∇fξ(xtk)−∇fξ(yk),3.4. Stochastic Variance Reduced APGnc,[0],[0]
+,3.4. Stochastic Variance Reduced APGnc,[0],[0]
gk. xt+1k =,3.4. Stochastic Variance Reduced APGnc,[0],[0]
"proxηg(x t k − ηvtk).
end for zk = x",3.4. Stochastic Variance Reduced APGnc,[0],[0]
m k + βk(x,3.4. Stochastic Variance Reduced APGnc,[0],[0]
m k − xmk−1).,3.4. Stochastic Variance Reduced APGnc,[0],[0]
if F (xmk ) ≤,3.4. Stochastic Variance Reduced APGnc,[0],[0]
"F (zk) then yk+1 = x m k , else if F (zk) ≤",3.4. Stochastic Variance Reduced APGnc,[0],[0]
"F (xmk ) then yk+1 = zk.
end if end for
property with θ = 12 .",3.4. Stochastic Variance Reduced APGnc,[0],[0]
"In fact, if g = 0, the KŁ property in such a case reduces to the well known Polyak-Łojasiewicz (PL) inequality studied in (Karimi et al., 2016).",3.4. Stochastic Variance Reduced APGnc,[0],[0]
"Various nonconvex problems have been shown to satisfy this property such as quadratic phase retrieval loss function (Zhou et al., 2016) and neural network loss function (Hardt & Ma, 2016).",3.4. Stochastic Variance Reduced APGnc,[0],[0]
The following theorem characterizes the convergence rate of SVRG-APGnc under the KŁ property with θ = 12 .,3.4. Stochastic Variance Reduced APGnc,[0],[0]
Theorem 4.,3.4. Stochastic Variance Reduced APGnc,[0],[0]
"Let η = ρ/L, where ρ < 1/2 and satisfies 4ρ2m2 +ρ ≤ 1.",3.4. Stochastic Variance Reduced APGnc,[0],[0]
"If the problem (P) satisfies the KŁ property globally with θ = 1/2, then the sequence {yk} generated by Algorithm 5 satisfies
E",3.4. Stochastic Variance Reduced APGnc,[0],[0]
"[F (yk)− F ∗] ≤ ( d d+1 )k (F (y0)− F ∗) , (8)
where d = c2(L+ 1η ) 2 +ηL2m
1 2η−L
, and F ∗ is the optimal function
value.
",3.4. Stochastic Variance Reduced APGnc,[0],[0]
"Hence, SVRG-APGnc also achieves the linear convergence rate under the KŁ property with θ = 12 .",3.4. Stochastic Variance Reduced APGnc,[0],[0]
"We note that Theorem 4 differs from the linear convergence result established in (Reddi et al., 2016b) for the SVRG proximal gradient in two folds: (1) we analyze proximal gradient with momentum but (Reddi et al., 2016b) studied proximal gradient algorithm; (2) the KŁ property with θ = 12 here is different from the generalized PL inequality for composite functions adopted by (Karimi et al., 2016).",3.4. Stochastic Variance Reduced APGnc,[0],[0]
"In order to exploit the KŁ property, our analysis of the convergence rate requires novel treatments of bounds, which can be seen in the proof of Theorem 4 in ??.",3.4. Stochastic Variance Reduced APGnc,[0],[0]
"We further study the inexact SVRG-APGnc algorithm, and the setting of inexactness is the same as that in Section 3.3.
",3.5. Inexact SVRG-APGnc,[0],[0]
"Here, we focus on the case where g is convex and ek = 0.",3.5. Inexact SVRG-APGnc,[0],[0]
"The following theorem characterizes the convergence rate under such an inexact case.
",3.5. Inexact SVRG-APGnc,[0],[0]
Theorem 5.,3.5. Inexact SVRG-APGnc,[0],[0]
Let g be convex and consider only the inexactness in the proximal map.,3.5. Inexact SVRG-APGnc,[0],[0]
Assume the KŁ property is globally satisfied with θ = 1/2.,3.5. Inexact SVRG-APGnc,[0],[0]
Set η = ρ/L where ρ < 1/2 and satisfies 8ρ2m2 + ρ ≤ 1.,3.5. Inexact SVRG-APGnc,[0],[0]
Assume that m−1∑ t=0 3E,3.5. Inexact SVRG-APGnc,[0],[0]
[ tk] ≤ α m−1∑ t=0 E,3.5. Inexact SVRG-APGnc,[0],[0]
[ ‖x̄t+1k,3.5. Inexact SVRG-APGnc,[0],[0]
"− xtk‖2 ] for some α > 0, and define x̄t+1k = proxηg(x t k − η∇f(xtk)).",3.5. Inexact SVRG-APGnc,[0],[0]
"Then the sequence {yk} satisfies
E",3.5. Inexact SVRG-APGnc,[0],[0]
"[F (yk)− F ∗] ≤ ( d d+1 )k (F (y0)− F ∗) , (9)
where d = c2(L+ 1η ) 2 +2ηL2m+ 12η
1 2η−L−α
, and F ∗ is the optimal
function value.
",3.5. Inexact SVRG-APGnc,[0],[0]
The convergence analysis for stochastic methods in inexact case has never been addressed before.,3.5. Inexact SVRG-APGnc,[0],[0]
"To incorporate the KŁ property in deriving the convergence rate, we use a reference sequence generated by exact proximal mapping.",3.5. Inexact SVRG-APGnc,[0],[0]
"Even though this sequence is not actually generated by the algorithm, we can reach to the convergence rate by analyzing the relation between the reference sequence and the actual sequence generated by the algorithm.
",3.5. Inexact SVRG-APGnc,[0],[0]
"Compared to the exact case, the convergence rate remains at the same order, i.e., the linear convergence, but the convergence is slower due to the larger parameter d caused by the error parameter α.",3.5. Inexact SVRG-APGnc,[0],[0]
"In this section, we compare the efficiency of APGnc and SVRG-APGnc with other competitive methods via numerical experiments.",4. Experiments,[0],[0]
"In particular, we focus on the nonnegative principle component analysis (NN-PCA) problem, which can be formulated as
min x≥0 −1",4. Experiments,[0],[0]
2 xT ( n∑ i=1,4. Experiments,[0],[0]
ziz T i ),4. Experiments,[0],[0]
x,4. Experiments,[0],[0]
+ γ‖x‖2.,4. Experiments,[0],[0]
"(10)
It can be equivalently written as
min x −1 2 xT",4. Experiments,[0],[0]
( n∑ i=1,4. Experiments,[0],[0]
ziz T i ),4. Experiments,[0],[0]
x,4. Experiments,[0],[0]
+ γ‖x‖2 + 1{x≥0}.,4. Experiments,[0],[0]
"(11)
Here, f corresponds to the first two terms, and g is the indicator of the nonnegative orthant, i.e., 1{x≥0}.",4. Experiments,[0],[0]
This problem is nonconvex due to the negative sign and satisfies Assumption 1.,4. Experiments,[0],[0]
"In particular, it satisfies the KŁ property since it is quadratic.
",4. Experiments,[0],[0]
"For the experiment, we set n = 2000, γ = 10−3 and randomly generate the samples zi from normal distribution.
",4. Experiments,[0],[0]
All samples are then normalized to have unit norm.,4. Experiments,[0],[0]
"The initialization is randomly generated, and is applied to all the methods.",4. Experiments,[0],[0]
We then compare the function values versus the number of effective passes through n samples.,4. Experiments,[0],[0]
We first compare among the deterministic APG-like methods in Algorithms 2 - 4 and the standard proximal gradient method.,4.1. Comparison among APG variants,[0],[0]
The original APG in Algorithm 1 is not considered since it is not a descent method and does not have convergence guarantee in nonconvex cases.,4.1. Comparison among APG variants,[0],[0]
"We tuned a fixed step size η = 0.05/L, where L is the spectral norm of
the sample matrix n∑ i=1",4.1. Comparison among APG variants,[0],[0]
ziz T i .,4.1. Comparison among APG variants,[0],[0]
We set t = 1/2 for APGnc +.,4.1. Comparison among APG variants,[0],[0]
The results are shown in Figures 1 and 2.,4.1. Comparison among APG variants,[0],[0]
"In Figure 1 (a), we show the performance comparison of the methods when there is no error in gradient or proximal calculation.",4.1. Comparison among APG variants,[0],[0]
One can see that APGnc and APGnc+ outperform all other APG variants.,4.1. Comparison among APG variants,[0],[0]
"In particular, APGnc+ performs the best with our adaptive momentum strategy, justifying its empirical advantage.",4.1. Comparison among APG variants,[0],[0]
"We note that the mAPG requires two passes over all samples at each iteration, and is, therefore, less data efficient compared to other APG variants.",4.1. Comparison among APG variants,[0],[0]
"We further note that other choices of stepsize less than the standard choice 0.5/L does not change the relative comparison of the performance among the algorithms, and we observed that the adaptive momentum performs practically well for
t ∈ (1/3, 2/3).
",4.1. Comparison among APG variants,[0],[0]
"We further study the inexact case in Figure 1 (b), where we introduce the proximal error k =",4.1. Comparison among APG variants,[0],[0]
1100k3 at the kth iteration.,4.1. Comparison among APG variants,[0],[0]
One can see that inexact APGnc+ and inexact APGnc also outperform other two inexact algorithms.,4.1. Comparison among APG variants,[0],[0]
"Furthermore, in Figure 2 (a) and (b), we compare exact and inexact algorithms respectively for APGnc+ and APGnc.",4.1. Comparison among APG variants,[0],[0]
"It can been that even with a reasonable amount of inexactness, both methods converge comparably to their corresponding exact methods.",4.1. Comparison among APG variants,[0],[0]
"Although initially the function value drops faster in exact algorithms, both exact and inexact algorithms converge to the optimal point almost at the same time.",4.1. Comparison among APG variants,[0],[0]
Such a fact demonstrates the robustness of the algorithms.,4.1. Comparison among APG variants,[0],[0]
"We note that the relative comparison of the performance among the algorithms does not change under other choices like k = 1/100k 2, 1/100k4.",4.1. Comparison among APG variants,[0],[0]
"We then compare the performance among SVRG-APGnc, SVRG-APGnc+ and the original proximal SVRG methods, and pick the stepsize η = 1/8mL with m = n.",4.2. Comparison among SVRG-APG variants,[0],[0]
The results are presented in Figures 3 and 4.,4.2. Comparison among SVRG-APG variants,[0],[0]
"In the error free case in Figure 3 (a), one can see that SVRG-AGPnc+ method outperforms the others due to the adaptive momentum, and the SVRG-APGnc method also performs better than the original proximal SVRG method.
",4.2. Comparison among SVRG-APG variants,[0],[0]
"For the inexact case, we set the proximal error as k =
min( 1100k3 , 10 −7), where 10−7 is chosen to suppress the large inexactness during the initial few iterations.",4.2. Comparison among SVRG-APG variants,[0],[0]
"One can see from Figure 3 (b) that the performance is degraded compared to the exact case, and converges to a different local minimum.",4.2. Comparison among SVRG-APG variants,[0],[0]
"In this result, all the methods are no longer monotone due to the inexactness and the stochastic nature of SVRG.",4.2. Comparison among SVRG-APG variants,[0],[0]
"Nevertheless, the SVRG-APGnc+ still yields the best performance.
",4.2. Comparison among SVRG-APG variants,[0],[0]
"We also compare the results corresponding to SVRGAPGnc+ and SVRG-APGnc, with and without the proximal error, in Figure 4 (a) and (b), respectively.",4.2. Comparison among SVRG-APG variants,[0],[0]
It is clear that the SVRG-based algorithms are much more sensitive to the error comparing with APG-based ones.,4.2. Comparison among SVRG-APG variants,[0],[0]
"Even though the error is set to be smaller than in the inexact case with APG-based methods, one can observe more significant performance gaps than those in Figure 2.",4.2. Comparison among SVRG-APG variants,[0],[0]
"In this paper, we provided comprehensive analysis of the convergence properties of APGnc as well as its inexact and stochastic variance reduced forms by exploiting the KŁ property.",5. Conclusion,[0],[0]
We also proposed an improved algorithm APGnc+ by adapting the momentum parameter.,5. Conclusion,[0],[0]
"We showed that APGnc shares the same convergence guarantee and the same order of convergence rate as the mAPG, but is computationally more efficient and more amenable to adaptive momentum.",5. Conclusion,[0],[0]
"In order to exploit the KŁ property for accelerated algorithms in the situations with inexact errors and/or with stochastic variance reduced gradients, we developed novel convergence analysis techniques, which can be useful for exploring other algorithms for nonconvex problems.",5. Conclusion,[0],[0]
This work was supported in part by the NSF grant ECCS 1609916.,Acknowledgements,[0],[0]
"In this work, we investigate the accelerated proximal gradient method for nonconvex programming (APGnc).",abstractText,[0],[0]
"The method compares between a usual proximal gradient step and a linear extrapolation step, and accepts the one that has a lower function value to achieve a monotonic decrease.",abstractText,[0],[0]
"In specific, under a general nonsmooth and nonconvex setting, we provide a rigorous argument to show that the limit points of the sequence generated by APGnc are critical points of the objective function.",abstractText,[0],[0]
"Then, by exploiting the Kurdyka-Łojasiewicz (KŁ) property for a broad class of functions, we establish the linear and sub-linear convergence rates of the function value sequence generated by APGnc.",abstractText,[0],[0]
"We further propose a stochastic variance reduced APGnc (SVRG-APGnc), and establish its linear convergence under a special case of the KŁ property.",abstractText,[0],[0]
We also extend the analysis to the inexact version of these methods and develop an adaptive momentum strategy that improves the numerical performance.,abstractText,[0],[0]
Convergence Analysis of Proximal Gradient with Momentum for Nonconvex Optimization,title,[0],[0]
"This paper presents a novel approach for modeling threaded discussions on social media using a graph-structured bidirectional LSTM (long-short term memory) which represents both hierarchical and temporal conversation structure. In experiments with a task of predicting popularity of comments in Reddit discussions, the proposed model outperforms a node-independent architecture for different sets of input features. Analyses show a benefit to the model over the full course of the discussion, improving detection in both early and late stages. Further, the use of language cues with the bidirectional tree state updates helps with identifying controversial comments.",text,[0],[0]
Social media provides a convenient and widely used platform for discussions among users.,1 Introduction,[0],[0]
"When the comment-response links are preserved, those conversations can be represented in a tree structure where comments represent nodes, the root is the original post, and each new reply to a previous comment is added as a child of that comment.",1 Introduction,[0],[0]
"Some examples of popular services with tree-like structures include Facebook, Reddit, Quora, and StackExchange.",1 Introduction,[0],[0]
"Figure 1 shows an example conversation on Reddit, where bigger nodes indicate higher upvoting of a comment.1 In services like Twitter,
1The tool https://whichlight.github.io/ reddit-network-vis was used to obtain this visualization.
tweets and their retweets can also be viewed as forming a tree structure.",1 Introduction,[0],[0]
"When time stamps are available with a contribution, the nodes of the tree can be ordered and annotated with that information.",1 Introduction,[0],[0]
"The tree structure is useful for seeing how a discussion unfolds into different subtopics and showing differences in the level of activity in different branches of the discussion.
",1 Introduction,[0],[0]
Predicting popularity of comments in social media is a task of growing interest.,1 Introduction,[0],[0]
"Popularity has been defined in terms of the volume of the response, but when the social media platform has a mechanism for readers to like or dislike comments (or, upvote/downvote), then the difference in positive/negative votes provides a more informative score for popularity prediction.",1 Introduction,[0],[0]
"This definition of
121
Transactions of the Association for Computational Linguistics, vol. 6, pp. 121–132, 2018.",1 Introduction,[0],[0]
Action Editor: Ani Nenkova.,1 Introduction,[0],[0]
"Submission batch: 11/2016; Revision batch: 3/2017; Published 2/2018.
",1 Introduction,[0],[0]
c©2018 Association for Computational Linguistics.,1 Introduction,[0],[0]
"Distributed under a CC-BY 4.0 license.
popularity, which has also been called community endorsement (Fang et al., 2016), is the task of interest in our work on tree-structured modeling of discussions.
",1 Introduction,[0],[0]
"Previous studies found that the time when the comment/post was published has a big impact on its popularity (Lakkaraju et al., 2013).",1 Introduction,[0],[0]
"In addition, the number of immediate responses can be predictive of the popularity, but some comments with a high number of replies can be either controversial or have a highly negative score.",1 Introduction,[0],[0]
Language should be extremely important for distinguishing these cases.,1 Introduction,[0],[0]
"Indeed, community style matching is shown to be correlated to comment popularity in Reddit (Tran and Ostendorf, 2016).",1 Introduction,[0],[0]
"However, learning useful language cues can be difficult due to the low frequency of these events and the dominance of time, topic and other factors.",1 Introduction,[0],[0]
"Thus, in several prior studies, authors constrained the problem to reduce the effect of those factors (Lakkaraju et al., 2013; Tan et al., 2014; Jaech et al., 2015).",1 Introduction,[0],[0]
"In this study, we have no such constraints, but attempt to use the tree structure to capture the flow of information in order to better model the context in which a comment is submitted, including both the history it responds to as well as the subsequent response to that comment.
",1 Introduction,[0],[0]
"To capture discussion dynamics, we introduce a novel approach to modeling the discussion using a bidirectional graph-structured LSTM, where each comment in the tree corresponds to a single LSTM
unit.",1 Introduction,[0],[0]
"In one direction, we capture the prior history of contributions leading up to a node, and in the other, we characterize the response to that comment.",1 Introduction,[0],[0]
"Motivated by prior findings that both response structure and timing are important in predicting popularity (Fang et al., 2016), the LSTM units include both hierachical and temporal components to the update, which distinguishes this work from prior treestructured LSTM models.",1 Introduction,[0],[0]
"We assess the utility of the model in experiments on popularity prediction with Reddit discussions, comparing to a neural network baseline that treats comments independently but leverages information about the graph context and timing of the comment.",1 Introduction,[0],[0]
"We analyze the results to show that the graph LSTM provides a useful summary representation of the language context of the comment.
",1 Introduction,[0],[0]
"As in Fang et al. (2016), but unlike other work (He et al., 2016), our model makes use of the full discussion thread in predicting popularity.",1 Introduction,[0],[0]
"While knowledge of the full discussion is only useful for posthoc analysis of past discussions, it is reasonable to consider initial responses to a comment, particularly given that many responses occur within minutes of someone posting a comment.",1 Introduction,[0],[0]
"Comments are often popular because of witty analogies made, which requires knowledge of the world beyond what is captured in current models.",1 Introduction,[0],[0]
"Responses to these comments, as well as to controversial comments, can improve popularity prediction.",1 Introduction,[0],[0]
"Responses of others
clearly influence the likelihood of someone to like or dislike a comment, but also whether they even read a comment.",1 Introduction,[0],[0]
"By introducing a forward-backward treestructured model, we provide a mechanism for leveraging early responses in predicting popularity, as well as a framework for better understanding the relative importance of these responses.
",1 Introduction,[0],[0]
"The main contributions of this paper include: a novel approach for representing tree-structured language processes (e.g., social media discussions) with LSTMs; evaluation of the model on the popularity prediction task using Reddit discussions; and analysis of the performance gains, particularly with respect to the role of language context.",1 Introduction,[0],[0]
"The proposed model is a bidirectional graph LSTM that characterizes a full threaded discussion, assuming a tree-structured response network and accounting for the relative order of the comments.",2 Method,[0],[0]
"Each comment in a conversation corresponds to a node in the tree, where its parent is the comment that it is responding to and its children are the responding comments that it spurs ordered in time.",2 Method,[0],[0]
"Each node in the tree is represented with a single recurrent neural network (RNN) unit that outputs a vector (embedding) that characterizes the interim state of the discussion, analogous to the vector output of an RNN unit which characterizes the word history in a sentence.",2 Method,[0],[0]
"In the forward direction, the state vector can be thought of as a summary of the discussion pursued in a particular branch of the tree, while in the backward direction the state vector summarizes the full response subtree that followed a particular comment.",2 Method,[0],[0]
The state vectors for the forward and backward directions are concatenated for the purpose of predicting comment karma.,2 Method,[0],[0]
"The RNN updates – both forward and backward – incorporate both temporal and hierarchical (tree-structured) dependencies, since commenters typically consider what has already been said in response to a parent comment.",2 Method,[0],[0]
"Hence, we refer to it as a graph-structured RNN rather than a tree-structured RNN.",2 Method,[0],[0]
"Figures 2(a) and 2(b) show an example of the state connections associated with hierarchical and timing structures for the forward and backward RNNs, respectively.
",2 Method,[0],[0]
"The supervision signal in training will impact the
character of the state vector, and the forward and backward state sub-vectors are likely to capture different phenomena.",2 Method,[0],[0]
"Here, the objective is to predict quantized comment karma.",2 Method,[0],[0]
"We anticipate that the forward state will capture relevance and informativeness of the comment, and the backward process will capture sentiment and richness of the ensuing discussion.
",2 Method,[0],[0]
The specific form of the RNN used in this work is an LSTM.,2 Method,[0],[0]
The detailed implementation of the model is described in the sections to follow.,2 Method,[0],[0]
Each node in the tree is associated with an LSTM unit.,2.1 Graph-structured LSTM,[0],[0]
"The input xt is an embedding that can incorporate both comment text and local submission context features associated with thread structure and timing, described further in section 2.2.",2.1 Graph-structured LSTM,[0],[0]
The node state vector ht is generated using a modification of the standard LSTM equations to include both hierarchical and timing structures for each comment.,2.1 Graph-structured LSTM,[0],[0]
"Specifically, we use two forget gates - one for the previous (or subsequent) hierarchical layer, and one for the previous (or subsequent) timing layer.
",2.1 Graph-structured LSTM,[0],[0]
"In order to describe the update equations, we introduce notation for the hierarchical and timing structure.",2.1 Graph-structured LSTM,[0],[0]
"In Figure 2, the nodes in the tree are numbered in the order that the comments are contributed in time.",2.1 Graph-structured LSTM,[0],[0]
"To characterize graph structure, let π(t) denote the parent of t and κ(t) its first child.",2.1 Graph-structured LSTM,[0],[0]
"Time structure is represented only among a set of siblings: p(t) is the sibling predecessor in time, and s(t) is the sibling successor.",2.1 Graph-structured LSTM,[0],[0]
"The pointers κ(t), p(t) and s(t) are set to ∅ when t has no child, predecessor, or successor, respectively.",2.1 Graph-structured LSTM,[0],[0]
"For example, in Figure 2(a), the node t2 will have π(t2) = t1, κ(t2) = t4, p(t2) = ∅ and s(t2) = t3, and the node t3 will have π(t3) = t1, κ(t3) = ∅, p(t3) = t2 and s(t3) = t5.
",2.1 Graph-structured LSTM,[0],[0]
"Below we provide the update equations for the forward process, using the subscripts",2.1 Graph-structured LSTM,[0],[0]
"i, f, g, c, and o for the input gate, temporal forget gate, hierarchichal forget gate, cell, and output, respectively.",2.1 Graph-structured LSTM,[0],[0]
"The vectors it, ft, and gt are the weights for new information, remembering old information from siblings, and remembering old information from the parent, respectively.",2.1 Graph-structured LSTM,[0],[0]
"σ is a sigmoid function, and ◦ indicates the Hadamard product.",2.1 Graph-structured LSTM,[0],[0]
"If p(t) = ∅, then
hp(t) and cp(t) are set to the initial state value.
",2.1 Graph-structured LSTM,[0],[0]
"it = σ(Wixt + Uihp(t) + Vihπ(t) + bi)
ft = σ(Wfxt + Ufhp(t) + Vfhπ(t) + bf )
gt = σ(Wgxt + Ughp(t)",2.1 Graph-structured LSTM,[0],[0]
"+ Vghπ(t) + bg)
c̃t =Wcxt + Uchp(t) + Vchπ(t) + bc ct = ft ◦ cp(t)",2.1 Graph-structured LSTM,[0],[0]
+ gt ◦ cπ(t),2.1 Graph-structured LSTM,[0],[0]
"+ it ◦ c̃t ot = σ(Woxt + Uohp(t) + Vohπ(t) + bo) ht = ot ◦ tanh(ct)
",2.1 Graph-structured LSTM,[0],[0]
"When the whole tree structure is known, we can take advantage of the full response subtree to better represent the node state.",2.1 Graph-structured LSTM,[0],[0]
"To that end, we define a backward LSTM that has a similar set of update equations except that only the first child will pass the hidden state to its parent.",2.1 Graph-structured LSTM,[0],[0]
"Specifically, the update equations are the same except that π(t) is replaced with κ(t), p(t) is replaced with s(t), and a different set of weight matrices and bias vectors are learned.
",2.1 Graph-structured LSTM,[0],[0]
Let + and − indicate forward and backward embeddings respectively.,2.1 Graph-structured LSTM,[0],[0]
"On top of the LSTM unit, the forward and backward state vectors are concatenated and passed to a softmax layer to predict 8 quantized karma levels:
P (yt = j|x, h) =",2.1 Graph-structured LSTM,[0],[0]
exp(W js,2.1 Graph-structured LSTM,[0],[0]
[h + t ;,2.1 Graph-structured LSTM,[0],[0]
h − t ]),2.1 Graph-structured LSTM,[0],[0]
"∑8
k=1 exp(W k s",2.1 Graph-structured LSTM,[0],[0]
"[h + t ;h − t ])
where x and h correspond to the set of input features and state vectors (respectively) for all nodes in the discussion.",2.1 Graph-structured LSTM,[0],[0]
"The full model includes two types of features in the input vector, including non-textual features associated with the submission context and the textual features of the comment at that node.
",2.2 Input Features,[0],[0]
"The submission context features are extracted from the graph and metadata associated with the comment, motivated by prior work showing that context factors such as the forum, timing and author of a post are very useful in predicting popularity.",2.2 Input Features,[0],[0]
"The submission context features include:
• Timing: time since root, time since parent (in hours), number of later comments, and number of previous comments
• Author: a binary indicator as to whether the author is the original poster, and number of comments made by the author in the conversation
• Graph-location: depth of the comment (distance from the root), and number of siblings
• Graph-response: number of children (direct replies to the comment), height of the subtree rooted from the node, size of that subtree, number of children normalized for each thread (2 normalization techniques), subtree size normalized for each thread (2 normalization techniques).
",2.2 Input Features,[0],[0]
"Two methods are used to normalize the subtree size and number of children to compensate for variation associated with the size of the discussion, specifically: i) subtract the mean feature value in the thread, and ii) divide by the square root of the rank of the feature value in the thread.
",2.2 Input Features,[0],[0]
These features are a superset of those used in Fang et al. (2016).,2.2 Input Features,[0],[0]
"The subvector including all these features is denoted xst .
",2.2 Input Features,[0],[0]
"The comment text features, denoted xct , are generated using a simple average bag-of-words representation learned during the training:
xct = 1
N
N∑
i=1
W ie
where W ie is an embedding of the i-th word in the comment, and N is the number of words in the comment.",2.2 Input Features,[0],[0]
"Comments longer than 100 words were truncated to reduce noise associated with long comments, assuming that the early portion carries the most information.",2.2 Input Features,[0],[0]
The percentage of the comments that exceed 100 words is around 11%− 14% for the subreddits used in the study.,2.2 Input Features,[0],[0]
"In all experiments, the word embedding dimension is d = 100, and the vocabulary includes only words that occurred at least 10 times in the dataset.
",2.2 Input Features,[0],[0]
"The input vector xt is set to either xst or [x s t ;x c t ],
depending on whether the experiment uses text.",2.2 Input Features,[0],[0]
"Often the number of comments in a single subtree can be large, which leads to high training costs.",2.3 Pruning,[0],[0]
"A large percentage of the comments are low karma and
minimally relevant for predicting karma of neighbors, and many can be easily identified with simple graph and timing features (e.g. having no replies or contributed late in the discussion).",2.3 Pruning,[0],[0]
"Therefore, we introduce a preprocessing step that identifies comments that are highly likely to be low karma to decrease the computation cost.",2.3 Pruning,[0],[0]
"We then assign these nodes to be level 0 and prune them out of the tree, but retain a count of nodes pruned for use in a countweighted bias term in the update to capture information about response volume.
",2.3 Pruning,[0],[0]
"For detecting low karma comments, we train a simple SVM classifier to identify comments at the 0 karma level based on the submission context features.",2.3 Pruning,[0],[0]
"If a pruned comment leads to a disconnected graph (e.g., an internal node is pruned but not its children), then the comment is retained in the tree.",2.3 Pruning,[0],[0]
"In testing, all pruned comments are given a predicted level of 0 and accounted for in the evaluation.
",2.3 Pruning,[0],[0]
The state updates have an additional bias term for any nodes that have subsequent sibling or children comments pruned.,2.3 Pruning,[0],[0]
"For example, consider Figure 2, if nodes {t5, t6, t7, t9} are pruned, then t8 will have a modified forward update, and t3, t4 will have a modified backwards update.",2.3 Pruning,[0],[0]
"At node t, define Mκt to be the number of levels pruned below it, Mpt as the number of immediately preceeding comments pruned in its subgroup (responding to the same parent), andM st as the number of subsequent comments pruned in its subgroup plus the non-initial comments in the associated subtrees.",2.3 Pruning,[0],[0]
"In the example above, Mκ3 = 1, M s 3 = 2, M s 4 = 1, M p 8 = 1, and all other M∗t = 0.",2.3 Pruning,[0],[0]
"The pointers are updated reflect the structure of the pruned tree, so p(8) = 4, s(4) = 8, s(3) = ∅.",2.3 Pruning,[0],[0]
"The bias vectors rκ, rp and rs are associated with the different sets of nodes pruned.
",2.3 Pruning,[0],[0]
"Let + and − indicate forward and backward embeddings, respectively.",2.3 Pruning,[0],[0]
The forward update has an adjusted predecessor contribution (h+p(t) + M p t rp).,2.3 Pruning,[0],[0]
"The backward update adds M st rs +M κ t rκ to either h−s(t) or h − κ(t), depending on whether it is a time or hierarchical update, respectively.",2.3 Pruning,[0],[0]
The objective function is minimum cross-entropy over the quantized levels.,2.4 Training,[0],[0]
"All model parameters are jointly trained using the adadelta optimization algorithm (Zeiler, 2012).",2.4 Training,[0],[0]
"Word embeddings
are initialized using word2vec skip-gram embeddings (Mikolov et al., 2013) trained on all comments from the corresponding subreddit.",2.4 Training,[0],[0]
"The code is implemented in Theano (Team et al., 2016) and is available at https://github.",2.4 Training,[0],[0]
"com/vickyzayats/graph-LSTM.We tune the model over different dimensions of the LSTM unit, and use the performance on the development set as a stopping criteria for the training.",2.4 Training,[0],[0]
Reddit2 is a popular discussion forum platform consisting of a large number of subreddits focusing on different topics and interests.,3.1 Data,[0],[0]
"In our study, we experimented with 3 subreddits: askwomen, askmen, and politics.",3.1 Data,[0],[0]
"All the data consists of discussions made in the period between January 1, 2014 and January 31, 2015.",3.1 Data,[0],[0]
Table 1 shows the total amount of data used for each of the subreddits.,3.1 Data,[0],[0]
"For each subreddit, the threads were randomly distributed between training, development (dev) and test sets with the proportions of 6:2:2.",3.1 Data,[0],[0]
The performance of the pruning classifier on the dev set is presented in Table 2.,3.1 Data,[0],[0]
"Reddit karma has a Zipfian distribution, highly skewed toward the low-karma comments.",3.2 Task and Evaluation Metrics,[0],[0]
"Since the rare high karma comments are of greatest interest in popularity prediction, Fang et al. (2016) proposes a
2https://reddit.com
task of predicting quantized karma (using a nonlinear head-tail break rule for binning) with evaluation using a macro average of the F1 scores for predicting whether a comment exceeds each different level.",3.2 Task and Evaluation Metrics,[0],[0]
"Experiments reported here use this framework.
",3.2 Task and Evaluation Metrics,[0],[0]
"Specifically, all the comments with karma lower than 1 are assigned to level 0, and each subsequent level corresponds to karma less than or equal to the median karma in the rest of the comments based on the training data statistics.",3.2 Task and Evaluation Metrics,[0],[0]
Each subreddit has 8 quantized karma levels based on its karma distribution.,3.2 Task and Evaluation Metrics,[0],[0]
"There are 7 binary subtasks (does the comment have karma at level j or higher for j = 1, . . .",3.2 Task and Evaluation Metrics,[0],[0]
", 7), and the scoring metric is the macro average of F1(j).",3.2 Task and Evaluation Metrics,[0],[0]
"For tuning hyperparameters and as a stopping criterion, we use a linearly weighted average of F1 scores to increase the weight on high karma comments, which gives slightly better performance for the high karma cases but has only a small effect on the macro average.",3.2 Task and Evaluation Metrics,[0],[0]
"We compare the graph LSTM to a node-independent baseline, which is a feedforward neural network model consisting of input, hidden and softmax layers.",3.3 Baseline and Contrast Systems,[0],[0]
This model is a simplification of the graphLSTM model where there is no connection between nodes.,3.3 Baseline and Contrast Systems,[0],[0]
The node-independent model characterizes a comment without reference to either the text of the comment that it is responding to or the comments reacting to it.,3.3 Baseline and Contrast Systems,[0],[0]
"However, the model does have information on the size of the response subtree via the submission context input features.",3.3 Baseline and Contrast Systems,[0],[0]
"Both nodeindependent and graph-structured models are trained with the same cost function and tuned over the same set of hidden layer dimensions.
",3.3 Baseline and Contrast Systems,[0],[0]
We contrast performance of both architectures with and without using the text of the comment itself.,3.3 Baseline and Contrast Systems,[0],[0]
"As shown in Fang et al. (2016), simply using submission context features (graph, timing, author) gives a strong baseline.",3.3 Baseline and Contrast Systems,[0],[0]
"In order to evaluate the role of each direction (forward or backward) in the graph-structured model, we also present results using only the forward direction graph-LSTM for comparison to the bidirectional model.",3.3 Baseline and Contrast Systems,[0],[0]
"In addition, in order to evaluate the importance of the language of the comment itself vs. the language used in the rest of the tree, we perform an interpolation
between the graph-LSTM with no language features and the node-independent model with language features.",3.3 Baseline and Contrast Systems,[0],[0]
The relative weight for the two models is tuned on the development set.,3.3 Baseline and Contrast Systems,[0],[0]
The results for the average F1 scores on the test set are presented in Table 3.,3.4 Karma Level Prediction,[0],[0]
"In experiments for all the subreddits, graph-structured models outperform the corresponding node-independent models both with and without language features.",3.4 Karma Level Prediction,[0],[0]
Language features also give a greater performance gain when used in the graph-LSTM models.,3.4 Karma Level Prediction,[0],[0]
The fact that the forward graph improves over the interpolated models shows that it is not simply the information in the current node that matters for karma of that node.,3.4 Karma Level Prediction,[0],[0]
"Finally, while the full model outperforms the forward-only version for all the subreddits, the gain is smaller than that obtained by the forward direction alone over the node-independent model, so the forward direction seems to be more important.
",3.4 Karma Level Prediction,[0],[0]
The karma prediction results (F1 score) at the different levels is shown in Figure 3.,3.4 Karma Level Prediction,[0],[0]
"While in askmen and askwomen subreddits the overall performance decreases for higher levels, the politics subreddit has an opposite trend.",3.4 Karma Level Prediction,[0],[0]
"This may be due in part to the lower pruning recall in the politics subreddit, but Fang et al. (2016) also observe higher performance for high karma levels in the politics subreddit.",3.4 Karma Level Prediction,[0],[0]
"Here, we present analyses aimed at better understanding the behavior of the graph-structured model and the role of language in prediction.",4 Analysis,[0],[0]
All analyses are performed on the development set.,4 Analysis,[0],[0]
"The analyses are motivated by considering possible scenarios that are exceptions to the easy cases, which are: i) comments that are contributed early in the discussion and spawn large subtrees, likely to have high karma, and ii) comments with small subtrees that typically have low karma.",4 Analysis,[0],[0]
We hypothesized three scenarios where the bidirectional graph-LSTM with text might be useful.,4 Analysis,[0],[0]
"One case is controversial comments, which have large subtrees but do not have high karma because of downvotes; these tend to have overprediction of karma when using only submission context.",4 Analysis,[0],[0]
The other two scenarios involve underprediction of karma when using only submission context.,4 Analysis,[0],[0]
"Early comments associated with few children and a more narrow subtree (see the downward chain in Figure 1) may spawn popular new threads and benefit from the popularity of other comments in the thread (more readers attracted), thus having
higher popularity than the number of children suggests.",4 Analysis,[0],[0]
"Lastly, comments that are clever or humorous discussion endpoints might have high popularity but small subtrees.",4 Analysis,[0],[0]
These two cases tend to differ in their relative timing in the discussion.,4 Analysis,[0],[0]
The first study looked at where the graph-LSTM provides benefits in terms of timing.,4.1 Karma Prediction vs. Time,[0],[0]
We plot the average F1 score as a function of the contribution time in Figure 4.,4.1 Karma Prediction vs. Time,[0],[0]
"As an approximation for time, we use the quantized number of comments made prior to the current comment.",4.1 Karma Prediction vs. Time,[0],[0]
The plots show that the graph-structured model improves over the nodeindependent model throughout the discussion.,4.1 Karma Prediction vs. Time,[0],[0]
Relative gains are larger towards the end of discussions where the node-independent performance is lower.,4.1 Karma Prediction vs. Time,[0],[0]
"A similar trend is observed when plotting average F1 as a function of depth in the discussion tree.
",4.1 Karma Prediction vs. Time,[0],[0]
"While the use of text in the graph-LSTM seems to help throughout the discussion, we hypothesized that there would be different cases where it might help, and these would occur at different times.",4.1 Karma Prediction vs. Time,[0],[0]
"Indeed, 93% of the comments that are overpredicted
by more than 2 levels by the node-independent model without text (controversial comments) occur in the first 20% of the discussion.",4.1 Karma Prediction vs. Time,[0],[0]
"Comments that are underpredicted by more than 2 occur throughout the discussion and are roughly uniform (13-19%) over the first half of the discussion, but then quickly ramp down.",4.1 Karma Prediction vs. Time,[0],[0]
High-karma comments are rare at the end of the discussion; less than 5% of the underpredicted comments are in the last 30%.,4.1 Karma Prediction vs. Time,[0],[0]
"In order to see how the model benefits from using the language cues in underpredicted and overpredicted scenarios, we look at the size of errors made by the graph-LSTM model with and without text features.",4.2 Importance of Responses,[0],[0]
"In Figure 5, the x-axis indicates the error between the actual karma level and the karma level predicted by the graph-LSTM using submission context features only.",4.2 Importance of Responses,[0],[0]
"The negative errors represent the overpredicted comments, and the positive errors represent the underpredicted comments.",4.2 Importance of Responses,[0],[0]
The y-axis represents the average error between the actual karma level and the karma level predicted by the model using both submission context and language features.,4.2 Importance of Responses,[0],[0]
The x=y identity line corresponds to no benefit from language features.,4.2 Importance of Responses,[0],[0]
"Results are presented for
the politics subreddit; other subreddits have similar trends but smaller differences for the underpredicted cases.
",4.2 Importance of Responses,[0],[0]
We compare two models – bidirectional and forward direction graph-structured LSTM – in order to understand the role of the language of the replies vs. the comment and its history.,4.2 Importance of Responses,[0],[0]
"We find that, for the bidirectional graph-LSTM model, language is helping identify overpredicted cases more than underpredicted ones.",4.2 Importance of Responses,[0],[0]
"The forward direction model also outperforms the node-independent model, but has less benefit in overpredicted cases, consistent with our intuition that controversy is identifiable based on the responses.",4.2 Importance of Responses,[0],[0]
"Although the comment text input is simply a bag of words, it can capture the mixed sentiment of the responses.
",4.2 Importance of Responses,[0],[0]
"While it is not represented in the plot, larger errors are much less frequent.",4.2 Importance of Responses,[0],[0]
"Looking at average F1 as a function of the number of children (direct responses), we found that the graph-LSTM mainly benefits nodes that have a small number of children, consistent with the two underprediction scenarios hypothesized.",4.2 Importance of Responses,[0],[0]
"However, many underpredicted cases are not impacted, since errors due to pruning contribute to 15-40% of the underpredicted cases, depending on the subreddit (highest for politics).",4.2 Importance of Responses,[0],[0]
This explains the smaller gains for the positive side of Figure 5.,4.2 Importance of Responses,[0],[0]
"To provide insights into what the model is learning about language, we looked at individual words associated with different categories of comments, as well as examples of the different error cases.
",4.3 Language Use Analysis,[0],[0]
"For the word level analysis, we classified words in two different ways, again using the politics subreddit.",4.3 Language Use Analysis,[0],[0]
"First, we associate words in comments with zero or positive karma.",4.3 Language Use Analysis,[0],[0]
"For each word in the vocabulary, we calculate the probability of a single-word comment being level zero using the trained model with a simplified graph structure (a post and a comment) where all the inputs were set to zero except the comment text.",4.3 Language Use Analysis,[0],[0]
"The lists of positive-karma and zerokarma correspond to the 300 words associated with the lowest and highest probability of zero-karma, respectively.",4.3 Language Use Analysis,[0],[0]
"We identified 300 positive-karma and zero-karma reply words in a similar fashion, using a simplified graph with individual words us as inputs
for the reply while predicting the comment karma.",4.3 Language Use Analysis,[0],[0]
"Second, we identified words that may be indicative of comments that are over- and underpredicted by the graph-structured model without text and for which the graph-LSTM model with text reduced the error by more than 2 levels.",4.3 Language Use Analysis,[0],[0]
"Specifically, we choose those words w in comments having the highest ratio r = p(w|t)/p(w), where t indicates an over- or underpredicted comment, subject to minimum occurrence constraints (5 for overpredicted comments, 15 for underpredicted comments).",4.3 Language Use Analysis,[0],[0]
"The 50 words with the highest ratio were chosen for each case and any words in both over- and underpredicted sets were eliminated, leaving 47 words.",4.3 Language Use Analysis,[0],[0]
"Again, this was repeated for words in replies to over vs. underpredicted comments, but with a minimum count threshold of 20, resulting in 45 words.
",4.3 Language Use Analysis,[0],[0]
"The lists are noisy, similar to what is often found with the topic model, and colored by the language of the subreddit community, but a few trends can be observed.",4.3 Language Use Analysis,[0],[0]
"Looking at the list of words associated with replies to positive-karma comments we noticed words that indicate humor (“LOL”, “hilarious”), positive feedback (“Like”, “Right”), and emotion indicators (“!!”, swearing).",4.3 Language Use Analysis,[0],[0]
"Words in comments and replies associated with overpredicted (controversial) cases are related to controversial topics (sexual, regulate, liberals), named political parties, and mentions of downvoting or indication that the comment has been edited with the word “Edit.”
",4.3 Language Use Analysis,[0],[0]
"Since the two sets of lists were generated separately, there are words in the over/under-predicted lists that overlap with the zero/non-zero karma lists (12 in the reply lists, 20 in the comment lists).",4.3 Language Use Analysis,[0],[0]
"The majority of the overlap (26/32 words) is consistent
with the intuition that words on the underpredicted list should be associated with positive-karma, and words on the overpredicted list might overlap with the zero-karma list.
",4.3 Language Use Analysis,[0],[0]
"Rather than providing word lists, many neural network studies illustrate trends using word embedding visualization.",4.3 Language Use Analysis,[0],[0]
"The embeddings of the words from the union of lists for positive-karma, zerokarma, underpredicted and overpredicted comments and replies were together used to learn a t-SNE mapping.",4.3 Language Use Analysis,[0],[0]
"The results are plotted for comments in Figure 6, which shows that the words that are associated with underpredicted comments (red) are aligned with positive-karma words (green) for both comment text and text in replies.",4.3 Language Use Analysis,[0],[0]
"Words associated
with overpredicted comments (blue) are more scattered, but they are somewhat more like the zerokarma words (yellow).",4.3 Language Use Analysis,[0],[0]
"The trends for words in replies are similar.
",4.3 Language Use Analysis,[0],[0]
"Table 4 lists examples of the different error scenarios with the reference karma and predictions of different models (node-independent without text, feedforward graph-LSTM with text, and the full biLSTM).",4.3 Language Use Analysis,[0],[0]
"The first two examples are overpredicted (controversial) cases, where ignoring text leads to a high karma prediction, but the reference is zero.",4.3 Language Use Analysis,[0],[0]
"In the first case, the forward model incorrectly predicts high karma because “Republican” tends to be associated with positive karma.",4.3 Language Use Analysis,[0],[0]
The model leveraging reply text correctly predicts the low karma.,4.3 Language Use Analysis,[0],[0]
"In the second case, the forward model captures reduces the prediction, but again having the replies is more helpful.",4.3 Language Use Analysis,[0],[0]
The next two cases are examples of underprediction due to small subtrees.,4.3 Language Use Analysis,[0],[0]
"Example 3 is incorrectly labeled as level 0 by the forward and no-text models, but because the responses mention “nice joke” and “accurate analogy,” the bidirectional model is able to identify it as level 7.",4.3 Language Use Analysis,[0],[0]
"Example 4 has only one child, but both models using language correctly predict level 7, probably because the model has learned that references to “Colbert” are popular.",4.3 Language Use Analysis,[0],[0]
"The next two examples are underpredicted cases from early in the discussion, many of which expressed an opinion that in some way provided multiple perspectives.",4.3 Language Use Analysis,[0],[0]
"Finally, the last two examples represent instances where neither model successfully identifies a high karma comment, which often involve analogies.",4.3 Language Use Analysis,[0],[0]
"Unlike the “titanic” analogy, these did not have sufficient cues in the replies.",4.3 Language Use Analysis,[0],[0]
The problem of predicting popularity in social media platforms has been the subject of several studies.,5 Related Work,[0],[0]
"Popularity as defined in terms of volume of response has been explored for shares on Facebook (Cheng et al., 2014) and Twitter (Bandari et al., 2012) and Twitter retweets (Tan et al., 2014; Zhao et al., 2015; Bi and Cho, 2016).",5 Related Work,[0],[0]
"Studies on Reddit predict karma as popularity (Lakkaraju et al., 2013; Jaech et al., 2015; He et al., 2016) or as community endorsement (Fang et al., 2016).",5 Related Work,[0],[0]
"Popularity prediction is a difficult task where many factors can play a role, which
is why most prior studies control for specific factors, including topic (Tan et al., 2014; Weninger et al., 2013), timing (Tan et al., 2014; Jaech et al., 2015), and/or comment content (Lakkaraju et al., 2013).",5 Related Work,[0],[0]
"Controlling for specific factors is useful in understanding the components of a successful post, but it does not reflect a realistic scenario.",5 Related Work,[0],[0]
"Studies that do not include such constraints have looked at Twitter retweets (Bi and Cho, 2016) and Reddit karma (He et al., 2016; Fang et al., 2016).
",5 Related Work,[0],[0]
"The work in (He et al., 2016) uses reinforcement learning to identify popular threads to track given the past comment history, so it is learning language cues relevant to high karma but it does not explicitly predict karma.",5 Related Work,[0],[0]
"In addition, it models relevance via an inner-product of past and new comment embeddings, and uses an LSTM to model inter-comment dependencies among a collection of comments irrespective of their sibling-parent relationship, whereas the LSTM in our work is over a graph that accounts for this relationship.
",5 Related Work,[0],[0]
The work most closely related to our study is Fang et al. (2016).,5 Related Work,[0],[0]
"The node-independent baseline implemented in our study is equivalent to their feedforward network baseline, but the results are not directly comparable because of differences in training (we use more data) and input features.",5 Related Work,[0],[0]
"The most important difference in our approach is the representation of textual context using a bidirectional graphLSTM, including the history behind and responses to a comment.",5 Related Work,[0],[0]
"Other differences are: i) Fang et al. (2016) use an LSTM to characterize comments, while our model uses a simple bag-of-words approach, and ii) they learn latent submission context models to determine the relative importance of textual cues, while our approach uses a submission context SVM to prune low karma comments (ignoring their text).",5 Related Work,[0],[0]
"Allowing for differences in baselines, we note that the absolute gain in performance from using text features is larger for our model, which represents language context.
",5 Related Work,[0],[0]
"Tree LSTMs are a modification of sequential LSTMs that have been proposed for a variety of sentence-level NLP tasks (Tai et al., 2015; Zhu et al., 2015; Zhang et al., 2016; Le and Zuidema, 2015).",5 Related Work,[0],[0]
The architecture of tree LSTMs varies depending on the task.,5 Related Work,[0],[0]
"Some options include summarizing over the children, adding a separate forget gate for each
child (Tai et al., 2015), recurrent propagation among siblings (Zhang et al., 2016), or use of stack LSTMs (Dyer et al., 2015).",5 Related Work,[0],[0]
Our work differs from these studies in two respects: the tree structure here characterizes a discussion rather than a single sentence; and our architecture incorporates both hierarchical and temporal recursions in one LSTM unit.,5 Related Work,[0],[0]
"In summary, this paper presents a novel approach for modeling threaded discussions on social media using a graph-structured bidirectional LSTM which represents both hierarchical and temporal conversation structure.",6 Conclusion,[0],[0]
"The propagation of hidden state information in the graph provides a mechanism for representing contextual language, including the history that a comment is responding to as well as the ensuing discussion it spawns.",6 Conclusion,[0],[0]
Experiments on Reddit discussions show that the graph-structured LSTM leads to improved results in predicting comment popularity compared to a node-independent model.,6 Conclusion,[0],[0]
"Analyses show that the model benefits prediction over the extent of the discussion, and that language cues are particularly important for distinguishing controversial comments from those that are very positively received.",6 Conclusion,[0],[0]
"Responses from even a small number of comments seem to be useful, so it is likely that the bidirectional model would still be useful with a short-time lookahead for early predic-
tion of popularity.
",6 Conclusion,[0],[0]
"While we evaluate the model on predicting the popularity of comments in specific forums on Reddit, it can be applied to other social media platforms that maintain a threaded structure or possibly to citation networks.",6 Conclusion,[0],[0]
"In addition to popularity prediction, we expect the model would be useful for other tasks for which the responses to comments are informative, such as detecting topic or opinion shift, influence or trolls.",6 Conclusion,[0],[0]
"With the more fine-grained feedback increasingly available on social media platforms (e.g. laughter, love, anger, tears), it may be possible to distinguish different types of popularity as well as levels, e.g. shared sentiment vs. humor.
",6 Conclusion,[0],[0]
"In this study, the model uses a simple bag-ofwords representation of the text in a comment; more sophisticated attention-based models and/or feature engineering may improve performance.",6 Conclusion,[0],[0]
"In addition, performance of the model on underpredicted comments appears to be limited by the pruning mechanism that we introduced.",6 Conclusion,[0],[0]
It would be useful to explore the tradeoffs of reducing the amount of pruning vs. using a more complex classifier for pruning.,6 Conclusion,[0],[0]
"Finally, it would be useful to evaluate performance using a short window lookahead for responses, rather than the full discussion tree.",6 Conclusion,[0],[0]
This paper is based on work supported by the DARPA DEFT Program.,Acknowledgments,[0],[0]
Views expressed are those of the authors and do not reflect the official policy or position of the Department of Defense or the U.S. Government.,Acknowledgments,[0],[0]
We thank the reviewers for their helpful feedback.,Acknowledgments,[0],[0]
This paper presents a novel approach for modeling threaded discussions on social media using a graph-structured bidirectional LSTM (long-short term memory) which represents both hierarchical and temporal conversation structure.,abstractText,[0],[0]
"In experiments with a task of predicting popularity of comments in Reddit discussions, the proposed model outperforms a node-independent architecture for different sets of input features.",abstractText,[0],[0]
"Analyses show a benefit to the model over the full course of the discussion, improving detection in both early and late stages.",abstractText,[0],[0]
"Further, the use of language cues with the bidirectional tree state updates helps with identifying controversial comments.",abstractText,[0],[0]
Conversation Modeling on Reddit Using a Graph-Structured LSTM,title,[0],[0]
"Proceedings of the SIGDIAL 2018 Conference, pages 284–295, Melbourne, Australia, 12-14 July 2018. c©2018 Association for Computational Linguistics
284",text,[0],[0]
"The development of digital photography has led to the advancement of digital image editing, where professionals as well as hobbyists use software tools such as Adobe Photoshop, Microsoft Photos, and so forth, to change and improve certain characteristics (brightness, contrast, etc.) of an image.
",1 Introduction,[0],[0]
Image editing is a hard task due to a variety of reasons: (1) The task requires a sense of artistic creativity.,1 Introduction,[0],[0]
"(2) The task is time consuming, and requires patience and experimenting with various features before settling on the final image edit.",1 Introduction,[0],[0]
(3) Sometimes users know at an abstract level what changes they want but are unaware of the image editing steps and parameters that will result in the desired image.,1 Introduction,[0],[0]
"For example, a person’s face in
a photo may look flushed, but the users may not know that adjusting the saturation and the temperature settings to some specific values will change the photo to match their expectations.",1 Introduction,[0],[0]
(4) Users are not sure what changes to perform on a given image.,1 Introduction,[0],[0]
"(5) Users are not fully aware of the features and the functionality that are supported by the given image editing tool.
",1 Introduction,[0],[0]
Users can often benefit from conversing with experts to edit images.,1 Introduction,[0],[0]
"This can be seen in action in web services such as the Reddit Photoshop Request forum1, Zhopped2, etc.",1 Introduction,[0],[0]
"These web services include two types of users: expert editors who know how to edit the photographs, and novice users who post their photographs and request changes to be made.",1 Introduction,[0],[0]
"If the editor needs further clarification regarding the requested change, they post their query and wait for a response from the user.",1 Introduction,[0],[0]
The conversational exchanges also happen through edit feedback where the editor interprets the user request and posts the edited photographs.,1 Introduction,[0],[0]
The user can reply with further requests for changes until they are fully satisfied.,1 Introduction,[0],[0]
"Due to this message-forum-like setup, users do not have the freedom to request changes in real time (at the same time as the changes are actually being performed), and hence often end up with edited images that do not fully match their requests.",1 Introduction,[0],[0]
"Furthermore, the editors are often unable to provide suggestions that could make the photograph fit better the user’s narrative for image editing.
",1 Introduction,[0],[0]
"In this setup the users can benefit greatly from conversing with an expert image editor in real time who can understand the requests, perform the editing, and provide feedback or suggestions as the editing is being performed.",1 Introduction,[0],[0]
"Our ultimate goal is to build a dialogue system with such capabilities.
",1 Introduction,[0],[0]
"1https://www.reddit.com/r/PhotoshopRequest/ 2https://zhopped.com
Conversational image editing is a task particularly well suited for incremental dialogue processing.",1 Introduction,[0],[0]
"It requires a lot of fine-grained changes (e.g., changing brightness to a specific value), which often cannot be just narrated with a command.",1 Introduction,[0],[0]
"In order to perform such fine-grained changes to the user’s liking, it is necessary that the editor understands the user utterances incrementally (word-byword) and in real time, instead of waiting until the user has finished their utterance.",1 Introduction,[0],[0]
"For example, if the user wants to increase the brightness, they could utter “more, more, more” until the desired change has been achieved.",1 Introduction,[0],[0]
"The changes should occur as soon as the user has uttered “more” and continue happening while the user keeps saying “more, more”.
",1 Introduction,[0],[0]
"In this paper, our contributions are as follows: (1) We introduce “conversational image editing”, a novel dialogue application that combines natural language dialogue with visual information and computer vision.",1 Introduction,[0],[0]
"Ultimately a dialogue system that can perform image editing should be able to understand what part of the image the user is referring to, e.g., when the user says “remove the tree”.",1 Introduction,[0],[0]
(2) We provide a new annotation scheme for incremental dialogue intentions.,1 Introduction,[0],[0]
"(3) We perform intent identification experiments, and show that a convolutional neural network model outperforms other state-of-the-art models based on deep learning and traditional classification algorithms.",1 Introduction,[0],[0]
"Furthermore, embeddings trained on image-related corpora lead to better performance than generic out-of-the-box embeddings.",1 Introduction,[0],[0]
(4) We calculate the impact of varying confidence thresholds (above which the classifier’s prediction is considered) on classification accuracy and savings in terms of number of words.,1 Introduction,[0],[0]
Our analysis provides evidence that incremental intent processing may be more efficient for the user and save time in accomplishing tasks.,1 Introduction,[0],[0]
To the best of our knowledge this is the first time in the literature that the impact of incremental intent understanding on savings in terms of number of words (or time) is explicitly measured.,1 Introduction,[0],[0]
DeVault et al. (2011) measured the stability of natural language understanding results as a function of time but did not explicitly measure savings in terms of number of words or time.,1 Introduction,[0],[0]
"Combining computer vision and language is a topic that has recently drawn much attention.
",2 Related Work,[0],[0]
"Some approaches assume that there are manual annotations available for mapping words or phrases to image regions or features, while other approaches employ computer vision techniques.",2 Related Work,[0],[0]
"Research is facilitated by publicly available data sets such as MS COCO (Lin et al., 2014) and Visual Genome (Krishna et al., 2017).",2 Related Work,[0],[0]
"Typically image and language corpora consist of digital photographs paired with crowdsourced captions, and sometimes mappings of words and captions to specific parts of an image.
",2 Related Work,[0],[0]
Yao et al. (2010) is an example of a work relying on manual input.,2 Related Work,[0],[0]
They developed a semiautomatic method for parsing images from the Internet to build visual knowledge representation graphs.,2 Related Work,[0],[0]
"On the other hand, the following works did not rely on manual annotations.",2 Related Work,[0],[0]
Feng and Lapata (2013) generated captions from news articles and their corresponding images.,2 Related Work,[0],[0]
"Mitchell et al. (2012) and Kulkarni et al. (2013) built systems for understanding and generating image descriptions.
",2 Related Work,[0],[0]
"Due to space constraints, below we focus on work that combines computer vision or visual references (enabled through manual annotations) and language in the context of a dialogue task, which is most relevant to our work.",2 Related Work,[0],[0]
Antol et al. (2015) introduced the “visual question answering” task.,2 Related Work,[0],[0]
"Here the goal is to provide a natural language answer, given an image and a natural language question about the image.",2 Related Work,[0],[0]
"Convolutional neural networks (CNNs) were employed for encoding the images (Krizhevsky et al., 2012).",2 Related Work,[0],[0]
This was later modeled as a dialogue-based question-answering task in Das et al. (2017).,2 Related Work,[0],[0]
These works used images from the MS COCO data set.,2 Related Work,[0],[0]
de Vries et al. (2017) introduced “GuessWhat?!”,2 Related Work,[0],[0]
", a two-player game where the goal is to find an unknown object in a rich image scene by asking a series of questions.",2 Related Work,[0],[0]
"They used images from MS COCO and CNNs for image recognition.
",2 Related Work,[0],[0]
"Paetzel et al. (2015) built an incremental dialogue system called “Eve”, which could guess the correct image, out of a set of possible candidates, based on descriptions given by a human.",2 Related Work,[0],[0]
The system was shown to perform nearly as well as humans.,2 Related Work,[0],[0]
"Then in the same domain, Manuvinakurike et al. (2017) used reinforcement learning to learn an incremental dialogue policy, which outperformed the high performance baseline policy of Paetzel et al. (2015) in offline simulations based on real user data.",2 Related Work,[0],[0]
"Each image was
associated with certain descriptions and the game worked for a specific data set of images without actually using computer vision.
",2 Related Work,[0],[0]
Manuvinakurike et al. (2016a) developed a model for incremental understanding of the described scenes among a set of complex configurations of geometric shapes.,2 Related Work,[0],[0]
"Kennington and Schlangen (2015) learned perceptually grounded word meanings for incremental reference resolution in the same domain of geometric shape descriptions, using visual features.
",2 Related Work,[0],[0]
Huang et al. (2016) built a data set of sequential images with corresponding descriptions that could potentially be used for the task of visual storytelling.,2 Related Work,[0],[0]
"Mostafazadeh et al. (2016) introduced the task of “visual question generation” where the system generates natural language questions when given an image, and then Mostafazadeh et al. (2017) extended this work to natural language question and response generation in the context of image-grounded conversations.
",2 Related Work,[0],[0]
"Some recent work has started investigating the potential of building dialogue systems that can help users efficiently explore data through visualizations (Kumar et al., 2017).
",2 Related Work,[0],[0]
The problem of intent recognition or dialogue act detection has been extensively studied.,2 Related Work,[0],[0]
Below we focus on recent work on dialogue act detection that employs deep learning.,2 Related Work,[0],[0]
"People have used recurrent neural networks (RNNs) including long short term memory networks (LSTMs), and CNNs (Kalchbrenner and Blunsom, 2013; Li and Wu, 2016; Khanpour et al., 2016; Shen and Lee, 2016; Ji et al., 2016; Tran et al., 2017).",2 Related Work,[0],[0]
The works that are most similar to ours are by Lee and Dernoncourt (2016) and Ortega and Vu (2017) who compared LSTMs and CNNs on the same data sets.,2 Related Work,[0],[0]
"However, neither Lee and Dernoncourt (2016) nor Ortega and Vu (2017) experimented with incremental dialogue act detection as we do.
",2 Related Work,[0],[0]
"Regarding incrementality in dialogue, there has been a lot of work on predicting the next user action, generating fast system responses, and turntaking (Schlangen et al., 2009; Schlangen and Skantze, 2011; Dethlefs et al., 2012; Baumann and Schlangen, 2013; Selfridge et al., 2013; Ghigi et al., 2014; Kim et al., 2014; Khouzaimi et al., 2015).",2 Related Work,[0],[0]
Recently Skantze (2017) presented a general continuous model of turn-taking based on LSTMs.,2 Related Work,[0],[0]
"Most related to our work, DeVault et al. (2011) built models for incremental interpreta-
tion and prediction of utterance meaning, while Manuvinakurike et al. (2016b) and Petukhova and Bunt (2014) built models for incremental dialogue act recognition.",2 Related Work,[0],[0]
We use a Wizard of Oz setup to collect a dialogue corpus in our image edit domain.,3 Data,[0],[0]
The Wizard-user conversational session is set up over Skype and the conversation recorded on the Wizard’s system.,3 Data,[0],[0]
The screen share feature is enabled on the Wizard’s screen so that the user can see in real time the changes requested.,3 Data,[0],[0]
"There are no time constraints, and the Wizard and the user can talk freely until the user is happy with the changes performed.",3 Data,[0],[0]
"Users may have varying levels of image editing expertise and knowledge of the image editing tool used during the interaction (Adobe Lightroom).
",3 Data,[0],[0]
Each user is given 4–6 images and time to think of ways to edit them to make them look better.,3 Data,[0],[0]
The conversation typically begins with the step called image location.,3 Data,[0],[0]
The user describes the image in a unique manner so that it can be located in the library of photos by the Wizard.,3 Data,[0],[0]
If the descriptions are not clear the Wizard can ask clarification questions.,3 Data,[0],[0]
"Once the image is located, the user conveys to the Wizard the changes they desire.",3 Data,[0],[0]
The user and the Wizard have a conversation until the user is happy with the final outcome.,3 Data,[0],[0]
"In order to capture all the changes that the user wants to achieve in spoken language, the image editing tool is controlled only by the Wizard.",3 Data,[0],[0]
Figure 4 in the Appendix shows the Adobe Lightroom interface as seen by the user and the Wizard.,3 Data,[0],[0]
Note that users were not explicitly told that they would interact with another human and could not see who they interacted with because the Wizard and the user were in different locations.,3 Data,[0],[0]
"However, the naturalness of the conversation made it obvious that they were conversing with another human.
",3 Data,[0],[0]
"The photographs chosen for the study are sampled from the Visual Genome data set (Krishna et al., 2017).",3 Data,[0],[0]
For the dialogue to be reflective of a real-world scenario the images sampled should be representative of the images regularly edited by the users.,3 Data,[0],[0]
"We sampled 200 photoshop requests from the Reddit Photoshop Request forum and Zhopped, and found that the images in those posts fell into eight high-level categories: animals, city scenes, food, nature/landscapes, indoor scenes, people, sports, and vehicles.
",3 Data,[0],[0]
"Figure 1 shows a sample conversation between the user and the Wizard, and Table 1 shows the statistics of the data.",3 Data,[0],[0]
Details of the semantics of the conversation are discussed in Section 4.,3 Data,[0],[0]
"Each dialogue session ranges between 2–30 min (7 min
on average).",3 Data,[0],[0]
The dialogues were transcribed via crowdsourcing (Amazon Mechanical Turk).,3 Data,[0],[0]
We intend to publicly release the data.,3 Data,[0],[0]
The data collected were annotated with dialogue acts.,4 Dialogue Semantics,[0],[0]
User utterances were segmented at the word level into utterance segments.,4 Dialogue Semantics,[0],[0]
An utterance is defined as a portion of speech preceded and/or followed by a silence interval greater than 300 msec.,4 Dialogue Semantics,[0],[0]
Each utterance segment was then assigned a dialogue act.,4 Dialogue Semantics,[0],[0]
The annotations were performed by two expert annotators.,4 Dialogue Semantics,[0],[0]
"The inter-annotator agreement was measured by having our two annotators annotate the same dialogue session of 20 min, and kappa was found to be 0.81 which indicates high agreement.",4 Dialogue Semantics,[0],[0]
"Below we describe briefly our dialogue act scheme.
",4 Dialogue Semantics,[0],[0]
Image Edit Requests: The most common dialogue acts used by the user are called “Image Edit Requests (IERs)”.,4 Dialogue Semantics,[0],[0]
These are user requests concerning the changes to be made to the images.,4 Dialogue Semantics,[0],[0]
"IERs are further categorized into 4 groups: IERNew (IER-N), IER-Update (IER-U), IER-Revert (IER-R), and IER-Compare (IER-C).",4 Dialogue Semantics,[0],[0]
IER-N requests refer to utterances that are concerned with new image edit requests different from the previously requested edits.,4 Dialogue Semantics,[0],[0]
"These requested changes are either abstract (“it’s flushed out, can you fix it?”) or exact (“change the saturation to 20%”).",4 Dialogue Semantics,[0],[0]
The Wizard interprets these requests and performs the changes.,4 Dialogue Semantics,[0],[0]
IER-U labels are used for utterances that request updates to the previously mentioned IER-Ns.,4 Dialogue Semantics,[0],[0]
"These include the addition of more details (“change it to 50%”) to the IERN (“change the saturation”), issuing corrections to the IER (“can you reduce the value again?”), modifiers (more, less), etc.",4 Dialogue Semantics,[0],[0]
If the users are completely unhappy with the change they can revert the change made (IER-R).,4 Dialogue Semantics,[0],[0]
"The IER-R act is used if the user reverts the complete changes performed, compared to only changing the values.",4 Dialogue Semantics,[0],[0]
"For example, if the user is modifying the saturation of the image and across multiple turns changes the value of saturation from 20% to 30% and back to 20%, the user’s action is labeled as IER-U. If the user wants all the saturation changes to be undone, the user’s action is labeled as IER-R. Users may also want to compare the changes made across different steps (“can we compare this to the previous update?”), and this action is labeled as IER-C.
Comments: Once the changes are performed the user is typically happy with the change and issues a comment that they like the edit (COML), or they are unhappy and issues a comment that they dislike the edit (COM-D).",4 Dialogue Semantics,[0],[0]
In some cases the users are neutral and neither like nor dislike the edit.,4 Dialogue Semantics,[0],[0]
"Typically such utterances are comments on the images and are labeled as COM-I.
Requests & Responses: The user may ask the Wizard to provide suggestions on the IERs.",4 Dialogue Semantics,[0],[0]
These are labeled as “Request” acts.,4 Dialogue Semantics,[0],[0]
"“Yes” and “no” responses uttered in response to the Wizard’s suggestions are labeled as RS-Y or RS-N.
Suggestions:",4 Dialogue Semantics,[0],[0]
This is the most commonly used Wizard dialogue act after “Acknowledgments”.,4 Dialogue Semantics,[0],[0]
"When the user does not know what edits to perform, the Wizard issues suggestion utterances with the intention of providing the user with ideas about
the changes that could be performed.",4 Dialogue Semantics,[0],[0]
"The Wizard provides new suggestions (S-N), e.g., “do you want to change the sharpness on this image?”.",4 Dialogue Semantics,[0],[0]
"The Wizard could also provide update suggestions for the current request under consideration (S-U), e.g., “sharpness of about 50% was better”.
",4 Dialogue Semantics,[0],[0]
"Other user actions are labeled as questions about the features supported by the image editing tool, clarifications, greetings, and discourse markers.",4 Dialogue Semantics,[0],[0]
"In total there are 26 dialogue act labels, including the dialogue act “Other (O)” which covers all of the cases that do not belong in the other categories.",4 Dialogue Semantics,[0],[0]
"In this work we are interested in the task of understanding the user utterances only, and in particular, in classifying user utterances into one of 10 labels: IER-N, IER-U, IER-R, IER-C, RSY, RS-N, COM-L, COM-D, COM-I, and O.
An agent will eventually be developed to replace the Wizard, which means that the agent will need to interpret the user utterances.",4 Dialogue Semantics,[0],[0]
The task of understanding the user utterance happens in two phases.,4 Dialogue Semantics,[0],[0]
In the first step the goal is to identify the dialogue acts.,4 Dialogue Semantics,[0],[0]
The second step is to understand the user image edit requests IER-N and IER-U at a fine-grained level.,4 Dialogue Semantics,[0],[0]
"For example, when the user says “make the tree brighter to 100”, it is important to understand the exact user’s intent and to translate this into an action that the image editing tool can perform.",4 Dialogue Semantics,[0],[0]
"For this reason we use actionentities tuples <action, attribute, location/object, value>.",4 Dialogue Semantics,[0],[0]
The user utterances are mapped to dialogue acts and then to a pre-defined set of image action-entities tuples which are translated into image editing actions.,4 Dialogue Semantics,[0],[0]
For more information on our annotation framework for mapping IERs to actionable commands see Manuvinakurike et al. (2018).,4 Dialogue Semantics,[0],[0]
It is beyond the scope of this work to perform the image editing and we intend to pursue this in future work.,4 Dialogue Semantics,[0],[0]
Table 2 shows an example of the process of understanding the image edit requests.,4 Dialogue Semantics,[0],[0]
Table 3 shows example utterances for some of the most frequently occurring dialogue acts in the corpus.,5 Incrementality,[0],[0]
"In these examples it can be seen that, with the exception of 3, all the other dialogue acts can be identified with some degree of certainty without waiting for the user to complete the utterance.",5 Incrementality,[0],[0]
"Also, Figure 5 in the Appendix shows example IERs.",5 Incrementality,[0],[0]
"One of the motivations for our work is to identify the right dialogue act at the earliest time.
",5 Incrementality,[0],[0]
Not only is this more efficient but also more natural.,5 Incrementality,[0],[0]
"The human Wizard can begin to take action even before the utterance completion, e.g., in utterance 1 the Wizard clicks the “vignette” feature in the tool before the user has finished uttering their request.",5 Incrementality,[0],[0]
"Another goal is to measure potential savings in time gained through incremental processing, i.e., how much we save in terms of number of words when we identify the dialogue act earlier rather than waiting until the full completion of the utterance, without sacrificing performance.",5 Incrementality,[0],[0]
"For our experiments we use a training set sampled randomly from 90% of the users (116 dialogues for training, 13 dialogues for testing).",6 Model Design,[0],[0]
We use word embedding features whose construction is described in Section 6.1.,6 Model Design,[0],[0]
"There are several reasons for using word embeddings as features, e.g., unseen words have a meaningful representation and provide dimensionality reduction.3
3Figure 6 shows the visual presentation of the utterances embeddings using t-SNE (Maaten and Hinton, 2008).",6 Model Design,[0],[0]
We convert the words into vector representations to train our deep learning models (and a variation of the random forests).,6.1 Constructing Word Embeddings,[0],[0]
"We use out-of-thebox word vectors available in the form of GloVe embeddings (Pennington et al., 2014) (trained with Wikipedia data), or we employ fastText (Bojanowski et al., 2017) to construct embeddings using the data from the Visual Genome image region description phrases, the dialogue training set collected during this experiment, and other data related to image editing that we have collected (image edit requests out of a dialogue context).",6.1 Constructing Word Embeddings,[0],[0]
"From now on these embeddings trained with fastText will be referred to as “trained embeddings”.
",6.1 Constructing Word Embeddings,[0],[0]
"As we can see in Table 4, for models E (LSTMs) and I (CNNs) we use word embeddings trained with fastText on the aforementioned data sets.",6.1 Constructing Word Embeddings,[0],[0]
"The Vanilla LSTM (model D) does not use GloVe or trained embeddings, i.e., there is no dimensionality reduction.",6.1 Constructing Word Embeddings,[0],[0]
Model H (CNN) uses GloVe embeddings.,6.1 Constructing Word Embeddings,[0],[0]
The vectors used in this work (both GloVe and trained embeddings) have a dimension of 50.,6.1 Constructing Word Embeddings,[0],[0]
"For trained embeddings, the vectors were constructed using skipgrams over 50 epochs with a learning rate of 0.5.
",6.1 Constructing Word Embeddings,[0],[0]
Recent advancements in creating a vector representation for a sentence were also evaluated.,6.1 Constructing Word Embeddings,[0],[0]
"We used the Sent2Vec (Pagliardini et al., 2018) toolkit to get a vector representation of the sentence and then used these vectors as features for models G and J. Note that LSTMs are sequential models where every word needs a vector representation and thus we could not use Sent2Vec.",6.1 Constructing Word Embeddings,[0],[0]
"We use WEKA (Hall et al., 2009) for the Naive Bayes and Random Forest models, MALLET
(McCallum, 2002) for the CRF model (linear chain), and TensorFlow (Abadi et al., 2016) for the LSTM and CNN models.",6.2 Model Construction,[0],[0]
"The models B, C, D, and F in Table 4 use bag-of-words features.",6.2 Model Construction,[0],[0]
"The CNN has 2 layers, with the first layer containing 512 filters and the second layer 256 filters.",6.2 Model Construction,[0],[0]
Both layers have a kernel size of 10 and use ReLU activation.,6.2 Model Construction,[0],[0]
The layers are separated by a max pooling layer with a pool size of 10.,6.2 Model Construction,[0],[0]
The dense softmax is the final layer.,6.2 Model Construction,[0],[0]
We use the Adam optimizer with the categorical cross entropy loss function.,6.2 Model Construction,[0],[0]
The LSTM cell is made up of 2 hidden layers.,6.2 Model Construction,[0],[0]
We use a dropout with keep prob = 0.1.,6.2 Model Construction,[0],[0]
We put the logits from the last time steps through the softmax to get the prediction.,6.2 Model Construction,[0],[0]
"We use the same optimizer and loss function as for the CNN since they were found to be the best performing.
",6.2 Model Construction,[0],[0]
Table 4 shows the dialogue act classification accuracy for all models on our test set.,6.2 Model Construction,[0],[0]
Here we assume that we have the correct utterance segmentation for both the training and the test data.,6.2 Model Construction,[0],[0]
Note that because of the “Other” dialogue act all words in a sentence will belong to a segment and a dialogue act category.,6.2 Model Construction,[0],[0]
We hypothesize that the poor performance of the sequential models (CRF and LSTM) is due to the lack of adequate training data to capture large context dependencies.,6.2 Model Construction,[0],[0]
"Table 5 shows the savings in terms of overall number of words and average number of words saved
per sentence, for each dialogue act in the corpus.",6.3 Incrementality,[0],[0]
Figure 2 shows the confidence curves for predicting the dialogue act with the progression of every word.,6.3 Incrementality,[0],[0]
From this figure it is clear that after listening to the word “photo” the classifier is confident enough that the user is issuing the IER-N command.,6.3 Incrementality,[0],[0]
Here the notion of incrementality is to predict the right dialogue act as early as possible and evaluate the savings in terms of the number of words.,6.3 Incrementality,[0],[0]
"While from this example it is clear that the correct dialogue act can be identified before the user completes the utterance, it is not clear when to commit to a dialogue act.",6.3 Incrementality,[0],[0]
The trade-off involved in committing early is often not clear.,6.3 Incrementality,[0],[0]
"Table 5 shows the maximum savings that can be achieved in an ideal scenario where an oracle (an entity informing if the prediction is correct or wrong as soon as the prediction is made) identifies the earliest point of predicting the correct dialogue act.
",6.3 Incrementality,[0],[0]
The method used for calculating the savings is shown in Table 6.,6.3 Incrementality,[0],[0]
"In this example for the utterance “I think that’s good enough”, we feed the classifier the utterances one word at a time and get the classifier confidence.",6.3 Incrementality,[0],[0]
The class label with the highest score is obtained.,6.3 Incrementality,[0],[0]
"Here the oracle tells us that we could predict the correct class COM-L as soon as “I think that’s good” was uttered and thus the word savings would be 1 word.
",6.3 Incrementality,[0],[0]
"However, in real-world scenarios the oracle is not present.",6.3 Incrementality,[0],[0]
We use several confidence thresholds and measure the accuracy and the savings achieved in predicting the dialogue act without the oracle.,6.3 Incrementality,[0],[0]
For the predictions in the test set we get the accuracy for each of the thresholds.,6.3 Incrementality,[0],[0]
"Then if the
predictions are correct, we calculate the savings.",6.3 Incrementality,[0],[0]
"Thus Figure 3 shows the word savings for each confidence threshold when the predictions are correct for that threshold.
",6.3 Incrementality,[0],[0]
"So in the example of Table 6, for a confidence threshold value of 0.4, we extract the class label assigned for the utterance once the max confidence score exceeds 0.4.",6.3 Incrementality,[0],[0]
In this case once the word “good” was uttered by the user the confidence score assigned (0.5) was higher than the threshold value of 0.4 and we take the predicted class as COM-L. The word savings in this case is 1 word and our prediction is correct.,6.3 Incrementality,[0],[0]
"But for a confidence threshold value of 0.2, our prediction would be the tag O which would be wrong and there would be no time savings.",6.3 Incrementality,[0],[0]
"Figure 3 shows that as the confidence threshold values increase the accuracy of the predictions rises but the savings decrease.
",6.3 Incrementality,[0],[0]
"Researchers have used simulations (Paetzel et al., 2015) or a reinforcement learning policy (Manuvinakurike et al., 2017) to learn the right
points of interrupting the user which are dependent on the language understanding confidence scores.",6.3 Incrementality,[0],[0]
Here we do not focus on learning such policies.,6.3 Incrementality,[0],[0]
"Instead, our work is a precursor to learning an incremental system dialogue policy.",6.3 Incrementality,[0],[0]
"We presented “conversational image editing”, a novel real-world application domain, which combines dialogue, visual information, and the use of computer vision.",7 Conclusion,[0],[0]
We discussed why this is a domain particularly well suited for incremental dialogue processing.,7 Conclusion,[0],[0]
We built models for incremental intent identification based on deep learning and traditional classification algorithms.,7 Conclusion,[0],[0]
We calculated the impact of varying confidence thresholds (above which the classifier’s prediction is considered) on classification accuracy and savings in terms of number of words.,7 Conclusion,[0],[0]
Our experiments provided evidence that incremental intent processing could be more efficient for the user and save time in accomplishing tasks.,7 Conclusion,[0],[0]
"This work was supported by a generous gift of Adobe Systems Incorporated to USC/ICT, and the first author’s internship at Adobe Research.",Acknowledgments,[0],[0]
The first and last authors were also funded by the U.S. Army Research Laboratory.,Acknowledgments,[0],[0]
"Statements and opinions expressed do not necessarily reflect the position or policy of the U.S. Government, and no official endorsement should be inferred.",Acknowledgments,[0],[0]
"We present “conversational image editing”, a novel real-world application domain combining dialogue, visual information, and the use of computer vision.",abstractText,[0],[0]
"We discuss the importance of dialogue incrementality in this task, and build various models for incremental intent identification based on deep learning and traditional classification algorithms.",abstractText,[0],[0]
"We show how our model based on convolutional neural networks outperforms models based on random forests, long short term memory networks, and conditional random fields.",abstractText,[0],[0]
"By training embeddings based on image-related dialogue corpora, we outperform pre-trained out-of-the-box embeddings, for intention identification tasks.",abstractText,[0],[0]
Our experiments also provide evidence that incremental intent processing may be more efficient for the user and could save time in accomplishing tasks.,abstractText,[0],[0]
Conversational Image Editing: Incremental Intent Identification in a New Dialogue Task,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 1350–1361 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
1350
To this end, we develop a framework for capturing pragmatic devices—such as politeness strategies and rhetorical prompts—used to start a conversation, and analyze their relation to its future trajectory. Applying this framework in a controlled setting, we demonstrate the feasibility of detecting early warning signs of antisocial behavior in online discussions.",text,[0],[0]
“Or vedi l’anime di color cui vinse,1 Introduction,[0],[0]
"l’ira.”1
– Dante Alighieri, Divina Commedia, Inferno
Online conversations have a reputation for going awry (Hinds and Mortensen, 2005; Gheitasy et al., 2015): antisocial behavior (Shepherd et al., 2015) or simple misunderstandings (Churchill and Bly, 2000; Yamashita and Ishida, 2006) hamper the efforts of even the best intentioned collaborators.",1 Introduction,[0],[0]
"Prior computational work has focused on characterizing and detecting content exhibiting antisocial online behavior: trolling (Cheng et al., 2015, 2017), hate speech (Warner and Hirschberg, 2012; Davidson et al., 2017), harassment (Yin et al., 2009), personal attacks (Wulczyn et al.,
∗",1 Introduction,[0],[0]
Corresponding senior author.,1 Introduction,[0],[0]
"1“Now you see the souls of those whom anger overcame.”
2017) or, more generally, toxicity (Chandrasekharan et al., 2017; Pavlopoulos et al., 2017b).
",1 Introduction,[0],[0]
"Our goal is crucially different: instead of identifying antisocial comments after the fact, we aim to detect warning signs indicating that a civil conversation is at risk of derailing into such undesirable behaviors.",1 Introduction,[0],[0]
"Such warning signs could provide potentially actionable knowledge at a time when the conversation is still salvageable.
",1 Introduction,[0],[0]
"As a motivating example, consider the pair of conversations in Figure 1.",1 Introduction,[0],[0]
"Both exchanges took place in the context of the Wikipedia discussion page for the article on the Dyatlov Pass Incident, and both show (ostensibly) civil disagreement between the participants.",1 Introduction,[0],[0]
"However, only one of these conversations will eventually turn awry and devolve into a personal attack (“Wow, you’re coming off as a total d**k.",1 Introduction,[0],[0]
[...],1 Introduction,[0],[0]
"What the hell is wrong with you?”), while the other will remain civil.
",1 Introduction,[0],[0]
"As humans, we have some intuition about which conversation is more likely to derail.2 We may note the repeated, direct questioning with which A1 opens the exchange, and that A2 replies with yet another question.",1 Introduction,[0],[0]
"In contrast, B1’s softer, hedged approach (“it seems”, “I don’t think”) appears to invite an exchange of ideas, and B2 actually addresses the question instead of stonewalling.",1 Introduction,[0],[0]
"Could we endow artificial systems with such intuitions about the future trajectory of conversations?
",1 Introduction,[0],[0]
In this work we aim to computationally capture linguistic cues that predict a conversation’s future health.,1 Introduction,[0],[0]
"Most existing conversation modeling approaches aim to detect characteristics of an observed discussion or predict the outcome after the discussion concludes—e.g., whether it involves a present dispute (Allen et al., 2014; Wang and Cardie, 2014) or contributes to the even-
2In fact, humans achieve an accuracy of 72% on this balanced task, showing that it is feasible, but far from trivial.
",1 Introduction,[0],[0]
"tual solution of a problem (Niculae and DanescuNiculescu-Mizil, 2016).",1 Introduction,[0],[0]
"In contrast, for this new task we need to discover interactional signals of the future trajectory of an ongoing conversation.
",1 Introduction,[0],[0]
We make a first approach to this problem by analyzing the role of politeness (or lack thereof) in keeping conversations on track.,1 Introduction,[0],[0]
"Prior work has shown that politeness can help shape the course of offline (Clark, 1979; Clark and Schunk, 1980), as well as online interactions (Burke and Kraut, 2008), through mechanisms such as softening the perceived force of a message (Fraser, 1980), acting as a buffer between conflicting interlocutor goals (Brown and Levinson, 1987), and enabling all parties to save face (Goffman, 1955).",1 Introduction,[0],[0]
"This suggests the potential of politeness to serve as an indicator of whether a conversation will sustain its initial civility or eventually derail, and motivates its consideration in the present work.
",1 Introduction,[0],[0]
"Recent studies have computationally operationalized prior formulations of politeness by extracting linguistic cues that reflect politeness strategies (Danescu-Niculescu-Mizil et al., 2013; Aubakirova and Bansal, 2016).",1 Introduction,[0],[0]
"Such research has additionally tied politeness to social factors such as individual status (Danescu-NiculescuMizil et al., 2012; Krishnan and Eisenstein, 2015), and the success of requests (Althoff et al., 2014) or of collaborative projects (Ortu et al., 2015).",1 Introduction,[0],[0]
"However, to the best of our knowledge, this is the first computational investigation of the relation between politeness strategies and the future trajectory of the conversations in which they are deployed.",1 Introduction,[0],[0]
"Furthermore, we generalize beyond predefined politeness strategies by using an unsupervised method to discover additional rhetorical prompts used to initiate different types of conversations that may be specific to online collaborative settings, such as coordinating work (Kittur and Kraut, 2008) or conducting factual checks.
",1 Introduction,[0],[0]
We explore the role of such pragmatic and rhetorical devices in foretelling a particularly perplexing type of conversational failure: when participants engaged in previously civil discussion start to attack each other.,1 Introduction,[0],[0]
"This type of derailment “from within” is arguably more disruptive than other forms of antisocial behavior, such as vandalism or trolling, which the interlocutors have less control over or can choose to ignore.
",1 Introduction,[0],[0]
"We study this phenomenon in a new dataset of Wikipedia talk page discussions, which we compile through a combination of machine learning and crowdsourced filtering.",1 Introduction,[0],[0]
"The dataset consists of conversations which begin with ostensibly civil comments, and either remain healthy or derail into personal attacks.",1 Introduction,[0],[0]
"Starting from this data, we construct a setting that mitigates effects which may trivialize the task.",1 Introduction,[0],[0]
"In particular, some topical contexts (such as politics and religion) are naturally more susceptible to antisocial behavior (Kittur et al., 2009; Cheng et al., 2015).",1 Introduction,[0],[0]
"We employ techniques from causal inference (Rosenbaum, 2010) to establish a controlled framework that focuses our study on topic-agnostic linguistic cues.
",1 Introduction,[0],[0]
"In this controlled setting, we find that pragmatic cues extracted from the very first exchange in a conversation (i.e., the first comment-reply pair) can indeed provide some signal of whether the conversation will subsequently go awry.",1 Introduction,[0],[0]
"For example, conversations prompted by hedged remarks sustain their initial civility more so than those prompted by forceful questions, or by direct language addressing the other interlocutor.
",1 Introduction,[0],[0]
"In summary, our main contributions are:
•",1 Introduction,[0],[0]
"We articulate the new task of detecting early on whether a conversation will derail into personal attacks;
• We devise a controlled setting and build a labeled dataset to study this phenomenon;
• We investigate how politeness strategies and other rhetorical devices are tied to the future trajectory of a conversation.
",1 Introduction,[0],[0]
"More broadly, we show the feasibility of automatically detecting warning signs of future misbehavior in collaborative interactions.",1 Introduction,[0],[0]
"By providing a labeled dataset together with basic methodology and several baselines, we open the door to further work on understanding factors which may derail or sustain healthy online conversations.",1 Introduction,[0],[0]
"To facilitate such future explorations, we distrubute the data and code as part of the Cornell Conversational Analysis Toolkit.3",1 Introduction,[0],[0]
Antisocial behavior.,2 Further Related Work,[0],[0]
"Prior work has studied a wide range of disruptive interactions in various online platforms like Reddit and Wikipedia, examining behaviors like aggression (Kayany, 1998), harassment (Chatzakou et al., 2017; Vitak et al., 2017), and bullying (Akbulut et al., 2010; Kwak et al., 2015; Singh et al., 2017), as well as their impact on aspects of engagement like user retention (Collier and Bear, 2012; Wikimedia Support and Safety Team, 2015) or discussion quality (Arazy et al., 2013).",2 Further Related Work,[0],[0]
"Several studies have sought to develop machine learning techniques to detect signatures of online toxicity, such as personal insults (Yin et al., 2009), harassment (Sood et al., 2012) and abusive language (Nobata et al., 2016; Gambäck and Sikdar, 2017; Pavlopoulos et al., 2017a; Wulczyn et al., 2017).",2 Further Related Work,[0],[0]
"These works focus on detecting toxic behavior after it has already occurred; a notable exception is Cheng et al. (2017), which predicts future community enforcement against users in news-based discussions.",2 Further Related Work,[0],[0]
"Our work similarly aims to understand future antisocial behavior; however, our focus is on studying the trajectory of a conversation rather than the behavior of individuals across disparate discussions.",2 Further Related Work,[0],[0]
Discourse analysis.,2 Further Related Work,[0],[0]
Our present study builds on a large body of prior work in computationally modeling discourse.,2 Further Related Work,[0],[0]
"Both unsupervised (Ritter et al., 2010) and supervised (Zhang et al., 2017a) approaches have been used to categorize behavioral patterns on the basis of the language that ensues in a conversation, in the particular realm of online discussions.",2 Further Related Work,[0],[0]
"Models of conversational behavior have also been used to predict conversation outcomes, such as betrayal in games (Niculae et al.,
3http://convokit.infosci.cornell.edu
2015), and success in team problem solving settings (Fu et al., 2017) or in persuading others (Tan et al., 2016; Zhang et al., 2016).
",2 Further Related Work,[0],[0]
"While we are inspired by the techniques employed in these approaches, our work is concerned with predicting the future trajectory of an ongoing conversation as opposed to a post-hoc outcome.",2 Further Related Work,[0],[0]
"In this sense, we build on prior work in modeling conversation trajectory, which has largely considered structural aspects of the conversation (Kumar et al., 2010; Backstrom et al., 2013).",2 Further Related Work,[0],[0]
We complement these structural models by seeking to extract potential signals of future outcomes from the linguistic discourse within the conversation.,2 Further Related Work,[0],[0]
We develop our framework for understanding linguistic markers of conversational trajectories in the context of Wikipedia’s talk page discussions— public forums in which contributors convene to deliberate on editing matters such as evaluating the quality of an article and reviewing the compliance of contributions with community guidelines.,3 Finding Conversations Gone Awry,[0],[0]
"The dynamic of conversational derailment is particularly intriguing and consequential in this setting by virtue of its collaborative, goal-oriented nature.",3 Finding Conversations Gone Awry,[0],[0]
"In contrast to unstructured commenting forums, cases where one collaborator turns on another over the course of an initially civil exchange constitute perplexing pathologies.",3 Finding Conversations Gone Awry,[0],[0]
"In turn, these toxic attacks are especially disruptive in Wikipedia since they undermine the social fabric of the community as well as the ability of editors to contribute (Henner and Sefidari, 2016).
",3 Finding Conversations Gone Awry,[0],[0]
To approach this domain we reconstruct a complete view of the conversational process in the edit history of English Wikipedia by translating sequences of revisions of each talk page into structured conversations.,3 Finding Conversations Gone Awry,[0],[0]
"This yields roughly 50 million conversations across 16 million talk pages.
",3 Finding Conversations Gone Awry,[0],[0]
"Roughly one percent of Wikipedia comments are estimated to exhibit antisocial behavior (Wulczyn et al., 2017).",3 Finding Conversations Gone Awry,[0],[0]
This illustrates a challenge for studying conversational failure: one has to sift through many conversations in order to find even a small set of examples.,3 Finding Conversations Gone Awry,[0],[0]
"To avoid such a prohibitively exhaustive analysis, we first use a machine learning classifier to identify candidate conversations that are likely to contain a toxic contribution, and then use crowdsourcing to vet the resulting labels and construct our controlled dataset.
Candidate selection.",3 Finding Conversations Gone Awry,[0],[0]
Our goal is to analyze how the start of a civil conversation is tied to its potential future derailment into personal attacks.,3 Finding Conversations Gone Awry,[0],[0]
"Thus, we only consider conversations that start out as ostensibly civil, i.e., where at least the first exchange does not exhibit any toxic behavior,4 and that continue beyond this first exchange.",3 Finding Conversations Gone Awry,[0],[0]
"To focus on the especially perplexing cases when the attacks come from within, we seek examples where the attack is initiated by one of the two participants in the initial exchange.
",3 Finding Conversations Gone Awry,[0],[0]
"To select candidate conversations to include in our collection, we use the toxicity classifier provided by the Perspective API,5 which is trained on Wikipedia talk page comments that have been annotated by crowdworkers (Wulczyn et al., 2016).",3 Finding Conversations Gone Awry,[0],[0]
"This provides a toxicity score t for all comments in our dataset, which we use to preselect two sets of conversations: (a) candidate conversations that are civil throughout, i.e., conversations in which all comments (including the initial exchange) are not labeled as toxic (t < 0.4); and (b) candidate conversations that turn toxic after the first (civil) exchange, i.e., conversations in which the N -th comment (N > 2) is labeled toxic (t ≥ 0.6), but all the preceding comments are not (t < 0.4).",3 Finding Conversations Gone Awry,[0],[0]
Crowdsourced filtering.,3 Finding Conversations Gone Awry,[0],[0]
"Starting from these candidate sets, we use crowdsourcing to vet each conversation and select a subset that are perceived by humans to either stay civil throughout (“ontrack” conversations), or start civil but end with a personal attack (“awry-turning” conversations).",3 Finding Conversations Gone Awry,[0],[0]
"To inform the design of this human-filtering process and to check its effectiveness, we start from a seed set of 232 conversations manually verified by the authors to end in personal attacks (more details about the selection of the seed set and its role in the crowd-sourcing process can be found in Appendix A).",3 Finding Conversations Gone Awry,[0],[0]
"We take particular care to not over-constrain crowdworker interpretations of
4For the sake of generality, in this work we focus on this most basic conversational unit: the first comment-reply pair starting a conversation.
",3 Finding Conversations Gone Awry,[0],[0]
"5https://www.perspectiveapi.com/
what personal attacks may be, and to separate toxicity from civil disagreement, which is recognized as a key aspect of effective collaborations (Coser, 1956; De Dreu and Weingart, 2003).
",3 Finding Conversations Gone Awry,[0],[0]
"We design and deploy two filtering jobs using the CrowdFlower platform, summarized in Table 1 and detailed in Appendix A. Job 1 is designed to select conversations that contain a “rude, insulting, or disrespectful” comment towards another user in the conversation—i.e., a personal attack.",3 Finding Conversations Gone Awry,[0],[0]
"In contrast to prior work labeling antisocial comments in isolation (Sood et al., 2012; Wulczyn et al., 2017), annotators are asked to label personal attacks in the context of the conversations in which they occur, since antisocial behavior can often be contextdependent (Cheng et al., 2017).",3 Finding Conversations Gone Awry,[0],[0]
"In fact, in order to ensure that the crowdworkers read the entire conversation, we also ask them to indicate who is the target of the attack.",3 Finding Conversations Gone Awry,[0],[0]
"We apply this task to the set of candidate awry-turning conversations, selecting the 14% which all three annotators perceived as ending in a personal attack.6
Job 2 is designed to filter out conversations that do not actually start out as civil.",3 Finding Conversations Gone Awry,[0],[0]
"We run this job to ensure that the awry-turning conversations are civil up to the point of the attack—i.e., they turn awry—discarding 5% of the candidates that passed Job 1.",3 Finding Conversations Gone Awry,[0],[0]
"We also use it to verify that the candidate on-track conversations are indeed civil throughout, discarding 1% of the respective candidates.",3 Finding Conversations Gone Awry,[0],[0]
"In both cases we filter out conversations in which three annotators could identify at least one comment that is “rude, insulting, or disrespectful”.",3 Finding Conversations Gone Awry,[0],[0]
Controlled setting.,3 Finding Conversations Gone Awry,[0],[0]
"Finally, we need to construct a setting that affords for meaningful comparison between conversations that derail and those that stay on track, and that accounts for trivial topical confounds (Kittur et al., 2009; Cheng et al., 2015).",3 Finding Conversations Gone Awry,[0],[0]
"We mitigate topical confounds using matching, a technique developed for causal inference in observational studies (Rubin, 2007).",3 Finding Conversations Gone Awry,[0],[0]
"Specifically, start-
6We opted to use unanimity in this task to account for the highly subjective nature of the phenomenon.
",3 Finding Conversations Gone Awry,[0],[0]
"ing from our human-vetted collection of conversations, we pair each awry-turning conversation, with an on-track conversation, such that both took place on the same talk page.",3 Finding Conversations Gone Awry,[0],[0]
"If we find multiple such pairs, we only keep the one in which the paired conversations take place closest in time, to tighten the control for topic.",3 Finding Conversations Gone Awry,[0],[0]
"Conversations that cannot be paired are discarded.
",3 Finding Conversations Gone Awry,[0],[0]
"This procedure yields a total of 1,270 paired awry-turning and on-track conversations (including our initial seed set), spanning 582 distinct talk pages (averaging 1.1 pairs per page, maximum 8) and 1,876 (overlapping) topical categories.",3 Finding Conversations Gone Awry,[0],[0]
The average length of a conversation is 4.6 comments.,3 Finding Conversations Gone Awry,[0],[0]
We now describe our framework for capturing linguistic cues that might inform a conversation’s future trajectory.,4 Capturing Pragmatic Devices,[0],[0]
"Crucially, given our focus on conversations that start seemingly civil, we do not expect overtly hostile language—such as insults (Yin et al., 2009)—to be informative.",4 Capturing Pragmatic Devices,[0],[0]
"Instead, we seek to identify pragmatic markers within the initial exchange of a conversation that might serve to reveal or exacerbate underlying tensions that eventually come to the fore, or conversely suggest sustainable civility.",4 Capturing Pragmatic Devices,[0],[0]
"In particular, in this work we explore how politeness strategies and rhetorical prompts reflect the future health of a conversation.",4 Capturing Pragmatic Devices,[0],[0]
Politeness strategies.,4 Capturing Pragmatic Devices,[0],[0]
"Politeness can reflect a-priori good will and help navigate potentially face-threatening acts (Goffman, 1955; Lakoff, 1973), and also offers hints to the underlying intentions of the interlocutors (Fraser, 1980).",4 Capturing Pragmatic Devices,[0],[0]
"Hence, we may naturally expect certain politeness strategies to signal that a conversation is likely to stay on track, while others might signal derailment.
",4 Capturing Pragmatic Devices,[0],[0]
"In particular, we consider a set of pragmatic devices signaling politeness drawn from Brown and Levinson (1987).",4 Capturing Pragmatic Devices,[0],[0]
These linguistic features reflect two overarching types of politeness.,4 Capturing Pragmatic Devices,[0],[0]
"Positive politeness strategies encourage social connection and rapport, perhaps serving to maintain cohesion throughout a conversation; such strategies include gratitude (“thanks for your help”), greetings (“hey, how is your day so far”) and use of “please”, both at the start (“Please find sources for your edit...”) and in the middle (“Could you please help with...?”) of a sentence.",4 Capturing Pragmatic Devices,[0],[0]
"Negative politeness strategies serve to dampen an interlocutor’s imposition on an addressee, often through conveying
indirectness or uncertainty on the part of the commenter.",4 Capturing Pragmatic Devices,[0],[0]
"Both commenters in example B (Fig. 1) employ one such strategy, hedging, perhaps seeking to soften an impending disagreement about a source’s reliability (“I don’t think...”, “I would assume...”).",4 Capturing Pragmatic Devices,[0],[0]
"We also consider markers of impolite behavior, such as the use of direct questions (“Why’s there no mention of it?’) and sentenceinitial second person pronouns (“Your sources don’t matter...”), which may serve as forcefulsounding contrasts to negative politeness markers.",4 Capturing Pragmatic Devices,[0],[0]
"Following Danescu-Niculescu-Mizil et al. (2013), we extract such strategies by pattern matching on the dependency parses of comments.
",4 Capturing Pragmatic Devices,[0],[0]
Types of conversation prompts.,4 Capturing Pragmatic Devices,[0],[0]
"To complement our pre-defined set of politeness strategies, we seek to capture domain-specific rhetorical patterns used to initiate conversations.",4 Capturing Pragmatic Devices,[0],[0]
"For instance, in a collaborative setting, we may expect conversations that start with an invitation for working together to signal less tension between the participants than those that start with statements of dispute.",4 Capturing Pragmatic Devices,[0],[0]
"We discover types of such conversation prompts in an unsupervised fashion by extending a framework used to infer the rhetorical role of questions in (offline) political debates (Zhang et al., 2017b) to more generally extract the rhetorical functions of comments.",4 Capturing Pragmatic Devices,[0],[0]
The procedure follows the intuition that the rhetorical role of a comment is reflected in the type of replies it is likely to elicit.,4 Capturing Pragmatic Devices,[0],[0]
"As such, comments which tend to trigger similar replies constitute a particular type of prompt.
",4 Capturing Pragmatic Devices,[0],[0]
"To implement this intuition, we derive two different low-rank representations of the common lexical phrasings contained in comments (agnostic to the particular topical content discussed), automatically extracted as recurring sets of arcs in the dependency parses of comments.",4 Capturing Pragmatic Devices,[0],[0]
"First, we derive reply-vectors of phrasings, which reflect their propensities to co-occur.",4 Capturing Pragmatic Devices,[0],[0]
"In particular, we perform singular value decomposition on a termdocument matrix R of phrasings and replies as R ≈ R̂ = URSV TR , where rows of UR are lowrank reply-vectors for each phrasing.
",4 Capturing Pragmatic Devices,[0],[0]
"Next, we derive prompt-vectors for the phrasings, which reflect similarities in the subsequent replies that a phrasing prompts.",4 Capturing Pragmatic Devices,[0],[0]
We construct a prompt-reply matrix P = (pij) where pij = 1 if phrasing j occurred in a reply to a comment containing phrasing i.,4 Capturing Pragmatic Devices,[0],[0]
"We project P into the same space as UR by solving for P̂ in P = P̂SV TR as
P̂ = PVRS−1.",4 Capturing Pragmatic Devices,[0],[0]
"Each row of P̂ is then a promptvector of a phrasing, such that the prompt-vector for phrasing i is close to the reply-vector for phrasing j if comments with phrasing i tend to prompt replies with phrasing j. Clustering the rows of P̂ then yields k conversational prompt types that are unified by their similarity in the space of replies.",4 Capturing Pragmatic Devices,[0],[0]
"To infer the prompt type of a new comment, we represent the comment as an average of the representations of its constituent phrasings (i.e., rows of P̂) and assign the resultant vector to a cluster.7
To determine the prompt types of comments in our dataset, we first apply the above procedure to derive a set of prompt types from a disjoint (unlabeled) corpus of Wikipedia talk page conversations (Danescu-Niculescu-Mizil et al., 2012).",4 Capturing Pragmatic Devices,[0],[0]
"After initial examination of the framework’s output on this external data, we chose to extract k = 6 prompt types, shown in Table 2 along with our interpretations.8 These prompts represent signatures of conversation-starters spanning a wide range of topics and contexts which reflect core elements of Wikipedia, such as moderation disputes and coordination (Kittur et al., 2007; Kittur and Kraut, 2008).",4 Capturing Pragmatic Devices,[0],[0]
"We assign each comment in our present dataset to one of these types.9
7We scale rows of UR and P̂ to unit norm.",4 Capturing Pragmatic Devices,[0],[0]
"We assign comments whose vector representation has (ℓ2) distance ≥ 1 to all cluster centroids to an extra, infrequently-occurring null type which we ignore in subsequent analyses.
8We experimented with more prompt types as well, finding that while the methodology recovered finer-grained types, and obtained qualitatively similar results and prediction accuracies as described in Sections 5 and 6, the assignment of comments to types was relatively sparse due to the small data size, resulting in a loss of statistical power.
",4 Capturing Pragmatic Devices,[0],[0]
9While the particular prompt types we discover are spe-,4 Capturing Pragmatic Devices,[0],[0]
We are now equipped to computationally explore how the pragmatic devices used to start a conversation can signal its future health.,5 Analysis,[0],[0]
"Concretely, to quantify the relative propensity of a linguistic marker to occur at the start of awry-turning versus on-track conversations, we compute the logodds ratio of the marker occurring in the initial exchange—i.e., in the first or second comments— of awry-turning conversations, compared to initial exchanges in the on-track setting.",5 Analysis,[0],[0]
"These quantities are depicted in Figure 2A.10
Focusing on the first comment (represented as ♦s), we find a rough correspondence between linguistic directness and the likelihood of future personal attacks.",5 Analysis,[0],[0]
"In particular, comments which contain direct questions, or exhibit sentenceinitial you (i.e., “2nd person start”), tend to start awry-turning conversations significantly more often than ones that stay on track (both p < 0.001).11",5 Analysis,[0],[0]
"This effect coheres with our intuition that directness signals some latent hostility from the conversation’s initiator, and perhaps reinforces the forcefulness of contentious impositions (Brown and Levinson, 1987).",5 Analysis,[0],[0]
"This interpretation is also sug-
cific to Wikipedia, the methodology for inferring them is unsupervised and is applicable in other conversational settings.
",5 Analysis,[0],[0]
10To reduce clutter we only depict features which occur a minimum of 50 times and have absolute log-odds ≥ 0.2 in at least one of the data subsets.,5 Analysis,[0],[0]
"The markers indicated as statistically significant for Figure 2A remain so after a Bonferroni correction, with the exception of factual checks, hedges (lexicon, ♦), gratitude (♦), and opinion.
",5 Analysis,[0],[0]
"11All p values in this section are computed as two-tailed binomial tests, comparing the proportion of awry-turning conversations exhibiting a particular device to the proportion of on-track conversations.
gested by the relative propensity of the factual check prompt, which tends to cue disputes regarding an article’s factual content (p < 0.05).
",5 Analysis,[0],[0]
"In contrast, comments which initiate on-track conversations tend to contain gratitude (p < 0.05) and greetings (p < 0.001), both positive politeness strategies.",5 Analysis,[0],[0]
"Such conversations are also more likely to begin with coordination prompts (p < 0.05), signaling active efforts to foster constructive teamwork.",5 Analysis,[0],[0]
"Negative politeness strategies are salient in on-track conversations as well, reflected by the use of hedges (p < 0.01) and opinion prompts (p < 0.05), which may serve to soften impositions or factual contentions (Hübler, 1983).
",5 Analysis,[0],[0]
"These effects are echoed in the second comment—i.e., the first reply (represented as !s).",5 Analysis,[0],[0]
"Interestingly, in this case we note that the difference in pronoun use is especially marked.",5 Analysis,[0],[0]
"First replies in conversations that eventually de-
rail tend to contain more second person pronouns (p < 0.001), perhaps signifying a replier pushing back to contest the initiator; in contrast, on-track conversations have more sentenceinitial I/We (i.e., “1st person start”, p < 0.001), potentially indicating the replier’s willingness to step into the conversation and work with—rather than argue against—the initiator (Tausczik and Pennebaker, 2010).
",5 Analysis,[0],[0]
Distinguishing interlocutor behaviors.,5 Analysis,[0],[0]
"Are the linguistic signals we observe solely driven by the eventual attacker, or do they reflect the behavior of both actors?",5 Analysis,[0],[0]
"To disentangle the attacker and nonattackers’ roles in the initial exchange, we examine their language use in these two possible cases: when the future attacker initiates the conversation, or is the first to reply.",5 Analysis,[0],[0]
"In attacker-initiated conversations (Figure 2B, 608 conversations), we see that both actors exhibit a propensity for the linguistically direct markers (e.g., direct questions)
that tend to signal future attacks.",5 Analysis,[0],[0]
"Some of these markers are used particularly often by the nonattacking replier in awry-turning conversations (e.g., second person pronouns, p < 0.001, ⃝s), further suggesting the dynamic of the replier pushing back at—and perhaps even escalating—the attacker’s initial hint of aggression.",5 Analysis,[0],[0]
"Among conversations initiated instead by the non-attacker (Figure 2C, 662 conversations), the non-attacker’s linguistic behavior in the first comment (⃝s) is less distinctive from that of initiators in the on-track setting (i.e., log-odds ratios closer to 0); markers of future derailment are (unsurprisingly) more pronounced once the eventual attacker (▽s) joins the conversation in the second comment.12
More broadly, these results reveal how different politeness strategies and rhetorical prompts deployed in the initial stages of a conversation are tied to its future trajectory.",5 Analysis,[0],[0]
"We now show that it is indeed feasible to predict whether a conversation will turn awry based on linguistic properties of its very first exchange, providing several baselines for this new task.",6 Predicting Future Attacks,[0],[0]
"In doing so, we demonstrate that the pragmatic devices examined above encode signals about the future trajectory of conversations, capturing some of the intuition humans are shown to have.
",6 Predicting Future Attacks,[0],[0]
"We consider the following balanced prediction task: given a pair of conversations, which one will eventually lead to a personal attack?",6 Predicting Future Attacks,[0],[0]
"We extract all features from the very first exchange in a conversation—i.e., a comment-reply pair, like those illustrated in our introductory example (Figure 1).",6 Predicting Future Attacks,[0],[0]
"We use logistic regression and report accuracies on a leave-one-page-out cross validation, such that in each fold, all conversation pairs from a given talk page are held out as test data and pairs from all other pages are used as training data (thus preventing the use of page-specific information).",6 Predicting Future Attacks,[0],[0]
Prediction results are summarized in Table 3.,6 Predicting Future Attacks,[0],[0]
Language baselines.,6 Predicting Future Attacks,[0],[0]
"As baselines, we consider several straightforward features: word count (which performs at chance level), sentiment lexicon (Liu et al., 2005) and bag of words.",6 Predicting Future Attacks,[0],[0]
Pragmatic features.,6 Predicting Future Attacks,[0],[0]
"Next, we test the predictive power of the prompt types and politeness
12As an interesting avenue for future work, we note that some markers used by non-attacking initiators potentially still anticipate later attacks, suggested by, e.g., the relative prevalence of sentence-initial you (p < 0.05, ⃝s).
strategies features introduced in Section 4.",6 Predicting Future Attacks,[0],[0]
"The 12 prompt type features (6 features for each comment in the initial exchange) achieve 59.2% accuracy, and the 38 politeness strategies features (19 per comment) achieve 60.5% accuracy.",6 Predicting Future Attacks,[0],[0]
The pragmatic features combine to reach 61.6% accuracy.,6 Predicting Future Attacks,[0],[0]
Reference points.,6 Predicting Future Attacks,[0],[0]
"To better contextualize the performance of our features, we compare their predictive accuracy to the following reference points: Interlocutor features:",6 Predicting Future Attacks,[0],[0]
Certain kinds of interlocutors are potentially more likely to be involved in awry-turning conversations.,6 Predicting Future Attacks,[0],[0]
"For example, perhaps newcomers or anonymous participants are more likely to derail interactions than more experienced editors.",6 Predicting Future Attacks,[0],[0]
"We consider a set of features representing participants’ experience on Wikipedia (i.e., number of edits) and whether the comment authors are anonymous.",6 Predicting Future Attacks,[0],[0]
"In our task, these features perform at the level of random chance.",6 Predicting Future Attacks,[0],[0]
"Trained toxicity: We also compare with the toxicity score of the exchange from the Perspective API classifier—a perhaps unfair reference point, since this supervised system was trained on additional human-labeled training examples from the same domain and since it was used to create the very data on which we evaluate.",6 Predicting Future Attacks,[0],[0]
This results in an accuracy of 60.5%; combining trained toxicity with our pragmatic features achieves 64.9%.,6 Predicting Future Attacks,[0],[0]
Humans: A sample of 100 pairs were labeled by (non-author) volunteer human annotators.,6 Predicting Future Attacks,[0],[0]
"They were asked to guess, from the initial exchange, which conversation in a pair will lead to a personal attack.",6 Predicting Future Attacks,[0],[0]
"Majority vote across three annotators was used to determine the human labels, resulting in an accuracy of 72%.",6 Predicting Future Attacks,[0],[0]
"This confirms that humans have
some intuition about whether a conversation might be heading in a bad direction, which our features can partially capture.",6 Predicting Future Attacks,[0],[0]
"In fact, the classifier using pragmatic features is accurate on 80% of the examples that humans also got right.",6 Predicting Future Attacks,[0],[0]
Attacks on the horizon.,6 Predicting Future Attacks,[0],[0]
"Finally, we seek to understand whether cues extracted from the first exchange can predict future discussion trajectory beyond the immediate next couple of comments.",6 Predicting Future Attacks,[0],[0]
"We thus repeat the prediction experiments on the subset of conversations in which the first personal attack happens after the fourth comment (282 pairs), and find that the pragmatic devices used in the first exchange maintain their predictive power (67.4% accuracy), while the sentiment and bag of words baselines drop to the level of random chance.
",6 Predicting Future Attacks,[0],[0]
"Overall, these initial results show the feasibility of reconstructing some of the human intuition about the future trajectory of an ostensibly civil conversation in order to predict whether it will eventually turn awry.",6 Predicting Future Attacks,[0],[0]
"In this work, we started to examine the intriguing phenomenon of conversational derailment, studying how the use of pragmatic and rhetorical devices relates to future conversational failure.",7 Conclusions and Future Work,[0],[0]
"Our investigation centers on the particularly perplexing scenario in which one participant of a civil discussion later attacks another, and explores the new task of predicting whether an initially healthy conversation will derail into such an attack.",7 Conclusions and Future Work,[0],[0]
"To this end, we develop a computational framework for analyzing how general politeness strategies and domain-specific rhetorical prompts deployed in the initial stages of a conversation are tied to its future trajectory.
",7 Conclusions and Future Work,[0],[0]
"Making use of machine learning and crowdsourcing tools, we formulate a tightly-controlled setting that enables us to meaningfully compare conversations that stay on track with those that go awry.",7 Conclusions and Future Work,[0],[0]
The human accuracy on predicting future attacks in this setting (72%) suggests it is feasible at least at the level of human intuition.,7 Conclusions and Future Work,[0],[0]
"We show that our computational framework can recover some of that intuition, hinting at the potential of automated methods to identify signals of the future trajectories of online conversations.
",7 Conclusions and Future Work,[0],[0]
Our approach has several limitations which open avenues for future work.,7 Conclusions and Future Work,[0],[0]
"Our correlational analyses do not provide any insights into causal
mechanisms of derailment, which randomized experiments could address.",7 Conclusions and Future Work,[0],[0]
"Additionally, since our procedure for collecting and vetting data focused on precision rather than recall, it might miss more subtle attacks that are overlooked by the toxicity classifier.",7 Conclusions and Future Work,[0],[0]
"Supplementing our investigation with other indicators of antisocial behavior, such as editors blocking one another, could enrich the range of attacks we study.",7 Conclusions and Future Work,[0],[0]
"Noting that our framework is not specifically tied to Wikipedia, it would also be valuable to explore the varied ways in which this phenomenon arises in other (possibly noncollaborative) public discussion venues, such as Reddit and Facebook Pages.
",7 Conclusions and Future Work,[0],[0]
"While our analysis focused on the very first exchange in a conversation for the sake of generality, more complex modeling could extend its scope to account for conversational features that more comprehensively span the interaction.",7 Conclusions and Future Work,[0],[0]
"Beyond the present binary classification task, one could explore a sequential formulation predicting whether the next turn is likely to be an attack as a discussion unfolds, capturing conversational dynamics such as sustained escalation.
",7 Conclusions and Future Work,[0],[0]
"Finally, our study of derailment offers only one glimpse into the space of possible conversational trajectories.",7 Conclusions and Future Work,[0],[0]
"Indeed, a manual investigation of conversations whose eventual trajectories were misclassified by our models—as well as by the human annotators—suggests that interactions which initially seem prone to attacks can nonetheless maintain civility, by way of level-headed interlocutors, as well as explicit acts of reparation.",7 Conclusions and Future Work,[0],[0]
"A promising line of future work could consider the complementary problem of identifying pragmatic strategies that can help bring uncivil conversations back on track.
",7 Conclusions and Future Work,[0],[0]
Acknowledgements.,7 Conclusions and Future Work,[0],[0]
"We are grateful to the anonymous reviewers for their thoughtful comments and suggestions, and to Maria Antoniak, Valts Blukis, Liye Fu, Sam Havron, Jack Hessel, Ishaan Jhaveri, Lillian Lee, Alex Niculescu-Mizil, Alexandra Schofield, Laure Thompson, Andrew Wang, Leila Zia and the members of the Wikimedia Foundation anti-harassment program for extremely insightful (on-track) conversations and for assisting with data annotation efforts.",7 Conclusions and Future Work,[0],[0]
"This work is supported in part by NSF CAREER Award IIS1750615, NSF Grant SES-1741441, a Google Faculty Award, a WMF gift and a CrowdFlower AI for Everyone Award.",7 Conclusions and Future Work,[0],[0]
"One of the main challenges online social systems face is the prevalence of antisocial behavior, such as harassment and personal attacks.",abstractText,[0],[0]
"In this work, we introduce the task of predicting from the very start of a conversation whether it will get out of hand.",abstractText,[0],[0]
"As opposed to detecting undesirable behavior after the fact, this task aims to enable early, actionable prediction at a time when the conversation might still be salvaged.",abstractText,[0],[0]
"To this end, we develop a framework for capturing pragmatic devices—such as politeness strategies and rhetorical prompts—used to start a conversation, and analyze their relation to its future trajectory.",abstractText,[0],[0]
"Applying this framework in a controlled setting, we demonstrate the feasibility of detecting early warning signs of antisocial behavior in online discussions.",abstractText,[0],[0]
Conversations Gone Awry: Detecting Early Signs of Conversational Failure,title,[0],[0]
Semidefinite relaxation is the technique of replacing a broad range of non-convex optimization problems involving a vector of (possibly discrete) variables with convex problems involving matrices.,1. Introduction,[0],[0]
"The relaxed convex problem is then solved to global optimality, and the solution is used to extract a global minimizer of the original non-convex problem.",1. Introduction,[0],[0]
"Unfortunately, convexity comes at a steep cost: semidefinite relaxation squares the dimensionality of the problem, resulting in formulations that are convex but computationally intractable in many situations.",1. Introduction,[0],[0]
"In fact, the increase in dimensionality, which is called lifting, often prevents the use of this technique in machine learning and computer vision applications involving thousands to millions of variables.
",1. Introduction,[0],[0]
"This article studies convex relaxation for phase retrieval, a canonical non-convex problem that can be solved via semidefinite relaxation.",1. Introduction,[0],[0]
"We present a relaxation approach that convexifies the problem without lifting, i.e., it solves the problem in its original, low-dimensional space.
",1. Introduction,[0],[0]
*Equal contribution 1University of Maryland 2Cornell University.,1. Introduction,[0],[0]
"Correspondence to: Tom Goldstein <tomg at cs.umd.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
Copyright 2017 by the author(s).,1. Introduction,[0],[0]
Phase retrieval deals with the recovery of an n-dimensional signal x0 ∈,2. Phase Retrieval Problems,[0],[0]
"Hn, with H either R or C, from m ≥ n magnitude measurements of the form (Candès et al., 2013)
bi = |〈ai,x0〉|, i = 1, 2, . . .",2. Phase Retrieval Problems,[0],[0]
",m, (1)
where ai ∈",2. Phase Retrieval Problems,[0],[0]
"Hn, and i = 1, 2, . . .",2. Phase Retrieval Problems,[0],[0]
",m are the (known) measurement vectors.",2. Phase Retrieval Problems,[0],[0]
"Because of the nonlinearity caused by measuring the magnitude of the linear terms in (1), the phase retrieval problem is non-convex.
",2. Phase Retrieval Problems,[0],[0]
A variety of algorithms exist for finding x0 in (1).,2. Phase Retrieval Problems,[0],[0]
"Classical methods, such as the Gerchberg-Saxton and Feinup algorithms, search for a solution via alternating least-squares steps that are efficient when the measurement ensemble {ai} forms a tight frame (e.g., a collection of Fourier matrices).
",2. Phase Retrieval Problems,[0],[0]
"More recently, there has been significant interest in convex methods for phase retrieval that provably find global solutions without the danger of getting trapped in local minima.",2. Phase Retrieval Problems,[0],[0]
"These methods, including PhaseLift (Candès et al., 2013) and its dual formulation PhaseCut (Waldspurger et al., 2015), rely on semidefinite relaxation and replace the unknown n-dimensional vector x with a (much larger) n× n matrix of unknowns that is recovered using semi-definite programming.",2. Phase Retrieval Problems,[0],[0]
"While such methods come with strong theoretical guarantees and do not get trapped in local minima, they require lifting (semidefinite relaxation squares the number of unknowns), which makes this approach intractable for real-world image processing applications involving thousands or millions of variables.",2. Phase Retrieval Problems,[0],[0]
"As a result, there has been a flurry of interest in global convergence properties of nonconvex solvers that operate in the original feature space, such as the methods in (Netrapalli et al., 2013; Schniter & Rangan, 2015; Candès et al., 2015; Chen & Candès, 2015; Wang et al., 2016).",2. Phase Retrieval Problems,[0],[0]
"While these methods come with theoretical guarantees, non-convexity makes it difficult to combine them with commonly used regularizers, and typically precludes the use of sophisticated optimization methods that can handle constraints, non-differentiable terms, etc.
We note that the PhaseMax formulation has also been proposed by (Bahmani & Romberg, 2016) and was recently analyzed by (Hand & Voroninski, 2016).",2. Phase Retrieval Problems,[0],[0]
We discuss and compare these results in Section 8.2.,2. Phase Retrieval Problems,[0],[0]
"Scalars are lower-case letters, and vector quantities are boldface, lower-case letters.",3. A Word on Notation,[0],[0]
"Matrices are boldface uppercase letters, and sets are written using upper-case script font.",3. A Word on Notation,[0],[0]
"We denote the inner product between the vectors x,y ∈",3. A Word on Notation,[0],[0]
"Hn as 〈x,y〉 = xTy, and xT is the transpose in the real case or the Hermitian transpose in the complex case.",3. A Word on Notation,[0],[0]
"We denote the real part of the inner product as 〈x,y〉< = <(xTy) and the imaginary part as 〈x,y〉= so that 〈x,y〉 = 〈x,y〉< + j〈x,y〉= with j2 = −1.",3. A Word on Notation,[0],[0]
The non-negative reals are denoted R+0 .,3. A Word on Notation,[0],[0]
"We denote the unit sphere embedded in Rn as Sn−1R , and use Sn−1C for the sphere in complex space.",3. A Word on Notation,[0],[0]
"To address both of these cases at once, we will often write
Sn−1H = {x ∈",3. A Word on Notation,[0],[0]
"Hn | ‖x‖2 = 1},
whereH ∈ {R,C} is either the real or complex numbers.",3. A Word on Notation,[0],[0]
"We propose PhaseMax, a formulation of the phase retrieval problem that avoids lifting.",4. Proposed Relaxation,[0],[0]
"Put simply, PhaseMax relaxes the non-convex equality constraints |〈ai,x〉| = bi into convex inequality constraints of the form |〈ai,x〉| ≤ bi.",4. Proposed Relaxation,[0],[0]
"The resulting convex problem can then be solved using linear programming in the real case or using second-order cone programming in the complex case.
",4. Proposed Relaxation,[0],[0]
"At first glance, the proposed relaxation seems too simplistic to recover x0.",4. Proposed Relaxation,[0],[0]
"Indeed, the relaxed system of inequalities has a trivial solution: the all-zeros vector.",4. Proposed Relaxation,[0],[0]
"To obtain a meaningful solution, we need to force the solution vector to lie on the boundary of the constraint set, where the inequality constraints hold with equality.",4. Proposed Relaxation,[0],[0]
"To force the solution to lie on the boundary, we rely on some intelligent “guess” x̂ ∈",4. Proposed Relaxation,[0],[0]
Hn of the solution to (1); we will discuss methods for producing such guesses in Section 8.1.,4. Proposed Relaxation,[0],[0]
We then find the feasible point that lies as far in the direction of x̂ ∈,4. Proposed Relaxation,[0],[0]
Hn as possible.,4. Proposed Relaxation,[0],[0]
"This results in the convex optimization problem
(PhaseMax)
{ maximize
x∈Hn 〈x, x̂〉<
subject to |〈ai,x〉| ≤ bi, i = 1, . . .",4. Proposed Relaxation,[0],[0]
",m.
The key idea behind PhaseMax is that the objective forces the solution vector to lie along the boundary of the constraint set, where the constraints are active.",4. Proposed Relaxation,[0],[0]
"Evidently, if all of the constraints are active at this solution, then we have recovered a solution to the original non-convex problem (1).
",4. Proposed Relaxation,[0],[0]
"Quite surprisingly, the PhaseMax relaxation provably recovers the true solution to (1) in many situations.",4. Proposed Relaxation,[0],[0]
"In particular, we have the following main result: Theorem 1.",4. Proposed Relaxation,[0],[0]
Consider the case of recovering a signal x ∈,4. Proposed Relaxation,[0],[0]
"Hn fromm measurements of the form (1) with measure-
ment vectors ai, i = 1, 2, . . .",4. Proposed Relaxation,[0],[0]
",m, sampled independently and uniformly from the unit sphere.",4. Proposed Relaxation,[0],[0]
"Let
angle(x0, x̂)",4. Proposed Relaxation,[0],[0]
"= arccos ( 〈x0, x̂〉< ‖x0‖2‖x̂‖2 ) be the angle between the true vector x0 and the “guess” x̂, and define the constant
α = 1− 2 π angle(x0, x̂)
that measures the accuracy of our guess.",4. Proposed Relaxation,[0],[0]
"If H = C, then whenever αm >",4. Proposed Relaxation,[0],[0]
"4n − 1, the probability that PhaseMax recovers the true signal x0 is at least
1− exp ( − (αm−4n) 2
4m
) .",4. Proposed Relaxation,[0],[0]
"(2)
Similar results for the real case are derived below.",4. Proposed Relaxation,[0],[0]
"Conditions for which PhaseMax enables exact recovery can be formulated as a classical problem from geometric probability involving random hemispheres, or “caps.”",5. Formulation using Geometric Probability,[0],[0]
We begin with a few simple definitions.,5. Formulation using Geometric Probability,[0],[0]
Recall that we use Sn−1H to denote the unit sphere embedded in Hn.,5. Formulation using Geometric Probability,[0],[0]
"Given a vector a ∈ Sn−1H , the hemisphere cap centered at a is CH(a) = {δ ∈ Sn−1H",5. Formulation using Geometric Probability,[0],[0]
"| 〈a, δ〉< ≥ 0}.",5. Formulation using Geometric Probability,[0],[0]
"(3) This cap contains all vectors that form an acute angle with a.
We also need the concept of aligned vectors.",5. Formulation using Geometric Probability,[0],[0]
"A complex vector a ∈ Sn−1H is said to be aligned with x ∈ Sn−1H if 〈x,a〉 ∈ R+0 .",5. Formulation using Geometric Probability,[0],[0]
"In words, two vectors are aligned if their inner product is real valued and non-negative.",5. Formulation using Geometric Probability,[0],[0]
"Given a vector x and a measurement vector a, we have |〈ai,x〉| = |〈ωai,x0〉| for any unit-magnitude ω ∈",5. Formulation using Geometric Probability,[0],[0]
C.,5. Formulation using Geometric Probability,[0],[0]
"For this reason, we will often consider the set {ãi} = {sign ( 〈ai,x0〉 ) ai} of measurement vectors aligned with x0 without loss of generality.",5. Formulation using Geometric Probability,[0],[0]
"Note that replacing {ai} with {ãi} in PhaseMax does not change the feasible set, and thus does not impact the recovered solution.",5. Formulation using Geometric Probability,[0],[0]
"Finally, observe that a solution x? to (PM) must be aligned with x̂.",5. Formulation using Geometric Probability,[0],[0]
"This is because 〈ωx?, x̂〉 = |〈x?, x̂〉|when ω = sign(〈x?, x̂〉) .",5. Formulation using Geometric Probability,[0],[0]
"It follows that x? cannot be optimal unless sign(〈x?, x̂〉) = 1.",5. Formulation using Geometric Probability,[0],[0]
We are now ready to formulate the following exact recovery condition for PhaseMax.,5. Formulation using Geometric Probability,[0],[0]
Theorem 2.,5. Formulation using Geometric Probability,[0],[0]
"Consider the recovery of a vector x0 using PhaseMax with guess x̂. Assume, without loss of generality, that x̂ and the measurement ensemble {ai} are aligned with x0.",5. Formulation using Geometric Probability,[0],[0]
"Let D = { δ |〈δ, x̂〉 ∈ R+0 } be the set of unit vectors aligned with x̂. Then, x0 is the unique solution of PhaseMax if
D ⊂ m⋃ i=1",5. Formulation using Geometric Probability,[0],[0]
CH(ai).,5. Formulation using Geometric Probability,[0],[0]
"(4)
Proof.",5. Formulation using Geometric Probability,[0],[0]
"Suppose the conditions of this theorem hold, and let x? be a solution to (PM).",5. Formulation using Geometric Probability,[0],[0]
"Since x0 is in the feasible set, x? must produce an objective value at least as large as x0, and so 〈x?, x̂〉 ≥ 〈x0, x̂〉.",5. Formulation using Geometric Probability,[0],[0]
"We know that x? is aligned with x̂. Since x0 is assumed to be aligned with x̂, the vector ∆ = x?",5. Formulation using Geometric Probability,[0],[0]
"− x0 is also aligned with x̂, and satisfies
〈∆, x̂〉 = 〈x?, x̂〉",5. Formulation using Geometric Probability,[0],[0]
"− 〈x0, x̂〉 ≥ 0.",5. Formulation using Geometric Probability,[0],[0]
"Since x? is a feasible solution for (PM), we have
|〈ai,x0 + ∆〉|2 = |〈ai,x0〉|2+ 2[〈ai,x0〉∗〈ai,∆",5. Formulation using Geometric Probability,[0],[0]
"〉]< + |〈ai,∆〉|2 ≤ b2i , ∀i.",5. Formulation using Geometric Probability,[0],[0]
"(5)
Now, recall that |〈ai,x0〉|2 =",5. Formulation using Geometric Probability,[0],[0]
"b2i , and ai is aligned with x0.",5. Formulation using Geometric Probability,[0],[0]
"Hence, we get
〈ai,∆〉< ≤",5. Formulation using Geometric Probability,[0],[0]
"− 1
2 |〈ai,∆〉|2 ≤ 0, ∀i.",5. Formulation using Geometric Probability,[0],[0]
"(6)
",5. Formulation using Geometric Probability,[0],[0]
"If ‖∆‖2 > 0, then we see from (6) that the unit-length vector δ = ∆/‖∆‖2 satisfies δ 6∈ C(ai),∀i, which contradicts the covering condition (4).",5. Formulation using Geometric Probability,[0],[0]
It follows that ‖∆‖2 = 0 and x? = x0.,5. Formulation using Geometric Probability,[0],[0]
"Theorem 2 states that exact recovery of x0 occurs when the measurement ensemble {ai} is aligned with x0, and the set D is covered by the caps {CH(ai)}.",6. Sphere Covering Results,[0],[0]
We now study the probability that this condition holds.,6. Sphere Covering Results,[0],[0]
"To do so, we need a few elementary sphere covering results.",6. Sphere Covering Results,[0],[0]
Our proof builds on the following simple result.,6. Sphere Covering Results,[0],[0]
Lemma 1.,6. Sphere Covering Results,[0],[0]
Suppose we slice the sphere Sn−1R ⊂,6. Sphere Covering Results,[0],[0]
Rn using k planes through the origin.,6. Sphere Covering Results,[0],[0]
"Then we divide the sphere into as most
r(n, k) = 2 n−1∑ i=0",6. Sphere Covering Results,[0],[0]
"( k − 1 i ) (7)
regions.
",6. Sphere Covering Results,[0],[0]
Proof.,6. Sphere Covering Results,[0],[0]
The proof is by induction.,6. Sphere Covering Results,[0],[0]
"As a base case, we have r(n, 1) = 2 and r(2, k) = 2k for k ≥ 1.",6. Sphere Covering Results,[0],[0]
"Now suppose we have a sphere Sn−1R in n dimensions sliced by k − 1 planes into r(n, k",6. Sphere Covering Results,[0],[0]
− 1) “original” regions.,6. Sphere Covering Results,[0],[0]
"Consider the effect of adding a kth plane, pk.",6. Sphere Covering Results,[0],[0]
The number of new regions created is equal to the number of original regions that are intersected by pk.,6. Sphere Covering Results,[0],[0]
"To count the number of new regions, we project the k − 1 original normal vectors into pk, and count the minimal number of regions formed inside pk by the resulting projected planes, which is at most r(n− 1, k− 1).",6. Sphere Covering Results,[0],[0]
"Adding this to the number of original regions yields
r(n, k) = r(n, k − 1) +",6. Sphere Covering Results,[0],[0]
"r(n− 1, k − 1).",6. Sphere Covering Results,[0],[0]
"We leave it to the reader to verify that (7) satisfies this recurrence relation.
",6. Sphere Covering Results,[0],[0]
"Lemma 1 appears to have been first proved by (Schläfli, 1953), and simple induction arguments can be found in (Wendel, 1962; Gilbert, 1965; Füredi, 1986).
",6. Sphere Covering Results,[0],[0]
"Before we attack the problem of when (4) holds, we begin with a simpler question: “how often is a sphere covered by caps with centers chosen at random from the sphere?”",6. Sphere Covering Results,[0],[0]
"This question has been studied in detail by Gilbert (Gilbert, 1965) in the case n = 3.",6. Sphere Covering Results,[0],[0]
"For our purposes, we need to study the covering probability in the more general case when caps are only chosen from a subset of the sphere, and the sphere can have arbitrarily high dimension.",6. Sphere Covering Results,[0],[0]
We show below that calculating this probability is easy when the caps are chosen from a symmetric subset of the sphere.,6. Sphere Covering Results,[0],[0]
"We say that the set A is symmetric if, for all x ∈ A, we also have −x ∈ A.",6. Sphere Covering Results,[0],[0]
A probability measure defined over A is symmetric if the measure of a is the same as −a for every a ⊂ A. Lemma 2.,6. Sphere Covering Results,[0],[0]
Consider some non-empty symmetric set A ⊂ Sn−1R .,6. Sphere Covering Results,[0],[0]
Choose some set of mA measurements {ai}mAi=1 at random from A using a symmetric measure.,6. Sphere Covering Results,[0],[0]
"Then, the caps {CR(ai)} cover the sphere Sn−1R with probability
pcover(mA, n)",6. Sphere Covering Results,[0],[0]
"≥ 1− 1
2mA−1 n−1∑ k=0 ( mA − 1 k ) .
",6. Sphere Covering Results,[0],[0]
"This is the probability of getting n or more heads when flipping mA − 1 fair coins.
",6. Sphere Covering Results,[0],[0]
Proof.,6. Sphere Covering Results,[0],[0]
Let {a′i} be a collection of m i.i.d. vectors sampled from A using a symmetric measure.,6. Sphere Covering Results,[0],[0]
"Define ai = cia′i, where {ci} are i.i.d.",6. Sphere Covering Results,[0],[0]
Bernoulli variables that take value +1 or −1 with probability 12 .,6. Sphere Covering Results,[0],[0]
"Clearly, the random vectors {ai} are i.i.d.",6. Sphere Covering Results,[0],[0]
with the same distribution as {a′i}.,6. Sphere Covering Results,[0],[0]
"Consider the set⋂
i CR(−ai) =",6. Sphere Covering Results,[0],[0]
"⋂ i CR(−cia′i), (8)
which contains all points not covered by the caps {CR(ai)}.",6. Sphere Covering Results,[0],[0]
The caps {CR(ai)} cover the sphere whenever the intersection (8) is empty.,6. Sphere Covering Results,[0],[0]
"There are 2mA such intersections that can be formed, one for each choice of the sequence {ci}.",6. Sphere Covering Results,[0],[0]
"Now, from Lemma 1, we know that the mA random planes{ {x | 〈ai,x〉 = 0} } divide the sphere into at most r(n,mA) non-empty regions.",6. Sphere Covering Results,[0],[0]
Each of these regions corresponds to the intersection (8) for one possible choice of {ci}.,6. Sphere Covering Results,[0],[0]
"Therefore, of the 2mA possible intersections, at most r(n,mA) of them are non-empty.",6. Sphere Covering Results,[0],[0]
"Since each intersection is equally likely, the probability of covering the sphere is at least
pcover(mA, n)",6. Sphere Covering Results,[0],[0]
"≥ 1− r(n,mA)
2mA .
",6. Sphere Covering Results,[0],[0]
Remark: It can be shown that the bound in Lemma 1 is tight/exact when the slicing planes are chosen from a continuous probability distribution.,6. Sphere Covering Results,[0],[0]
"Similarly, the bound in Lemma 2 is exact when the set {ai} is sampled from a continuous distribution over A.",6. Sphere Covering Results,[0],[0]
We are now ready to present our main result.,6. Sphere Covering Results,[0],[0]
Exact recovery theorems for PhaseMax will follow immediately from the following geometric theorem.,6. Sphere Covering Results,[0],[0]
The result considers the case where the measurement vectors are drawn from only one hemisphere.,6. Sphere Covering Results,[0],[0]
Lemma 3.,6. Sphere Covering Results,[0],[0]
"Consider two vectors x,y ⊂ Sn−1R , and the caps CR(x) and CR(y).",6. Sphere Covering Results,[0],[0]
"Let α = 1 − 2π angle(x,y) be a measure of the similarity between the vectors x and y.Draw some collection {ai ∈ CR(x)}mi=1 of m vectors uniformly from CR(x) so that α(m− 1) > 2n.",6. Sphere Covering Results,[0],[0]
"Then,
CR(y) ⊂",6. Sphere Covering Results,[0],[0]
"⋃ i CR(ai)
holds with probability at least pcover(m,n;x,y) ≥ 1− exp",6. Sphere Covering Results,[0],[0]
"( − (αm− α− 2n) 2
2m− 2
) .
Proof.",6. Sphere Covering Results,[0],[0]
"To simplify notation, we assume y =",6. Sphere Covering Results,[0],[0]
"[1, 0, . .",6. Sphere Covering Results,[0],[0]
.,6. Sphere Covering Results,[0],[0]
", 0]T .",6. Sphere Covering Results,[0],[0]
Because of rotational symmetries this does not change the generality of our proof.,6. Sphere Covering Results,[0],[0]
Consider the reflection of x over y given by x̃ =,6. Sphere Covering Results,[0],[0]
"[x1,−x2, . . .",6. Sphere Covering Results,[0],[0]
",−xn]T .",6. Sphere Covering Results,[0],[0]
Suppose we have some collection {ai} independently and uniformly distributed on the entire sphere.,6. Sphere Covering Results,[0],[0]
"Consider the collection of vectors
a′i =  ai, if 〈ai,x〉 ≥ 0",6. Sphere Covering Results,[0],[0]
"(9) ai − 2〈ai,y〉y, if 〈ai,x〉 < 0, 〈ai, x̃〉 < 0",6. Sphere Covering Results,[0],[0]
"(10) −ai, if 〈ai,x〉 < 0, 〈ai, x̃〉 ≥ 0.",6. Sphere Covering Results,[0],[0]
"(11)
",6. Sphere Covering Results,[0],[0]
"The mapping ai → a′i maps the half sphere {a | 〈a,x〉 < 0} onto the half sphere {a | 〈a,x〉 > 0} using a combination of reflections and translations (see Figure 1).",6. Sphere Covering Results,[0],[0]
"This makes the mapping ai → a′i onto and (piecewise) isometric, and so {a′i} will be uniformly distributed over the half sphere {a | 〈a,x0〉 > 0} whenever {ai} is independently and uniformly distributed over the entire sphere.
",6. Sphere Covering Results,[0],[0]
"Consider the “hourglass” shaped, symmetric set
A = {a | 〈a,x〉 ≥ 0, 〈a, x̃〉 ≥ 0} ∪ {a | 〈a,x〉 ≤ 0, 〈a, x̃〉 ≤ 0}.
",6. Sphere Covering Results,[0],[0]
We claim that CR(y) ⊂,6. Sphere Covering Results,[0],[0]
"⋃ i CR(a′i) whenever
Sn−1R ⊂",6. Sphere Covering Results,[0],[0]
"⋃
ai∈A CR(ai).",6. Sphere Covering Results,[0],[0]
"(12)
",6. Sphere Covering Results,[0],[0]
"In words, if the caps defined by the subset of {ai} in A cover the entire sphere, then the caps {CR(a′i)} (which have
centers in CR(x))",6. Sphere Covering Results,[0],[0]
"not only cover CR(x), but also cover the nearby cap CR(y).",6. Sphere Covering Results,[0],[0]
"To justify this claim, suppose that (12) holds.",6. Sphere Covering Results,[0],[0]
Choose some δ ∈ CR(y).,6. Sphere Covering Results,[0],[0]
This point is covered by some cap CR(ai) with ai ∈ A.,6. Sphere Covering Results,[0],[0]
"If 〈ai,x〉 ≥ 0, then ai = a′i and δ is covered by CR(a′i).",6. Sphere Covering Results,[0],[0]
"If 〈ai,x〉 < 0, then
〈δ,a′i〉 = 〈δ,ai − 2〈ai,y〉y〉 = 〈δ,ai〉 − 2〈ai,y〉〈δ,y〉 ≥ 〈δ,ai〉 ≥ 0.
",6. Sphere Covering Results,[0],[0]
"Note we have used the fact that 〈δ,y〉 is real-valued and nonnegative because δ ∈ CR(y).",6. Sphere Covering Results,[0],[0]
"We have also used 〈ai,y〉 =",6. Sphere Covering Results,[0],[0]
"[ai]1 = 1 2 (〈ai,x〉 + 〈ai, x̃〉) < 0, which follows from the definition of x̃ and the definition of A. Since 〈δ,a′i〉 ≥ 0, we have δ ∈ CR(a′i), which proves our claim.",6. Sphere Covering Results,[0],[0]
We can now see that the probability that CR(y) ⊂,6. Sphere Covering Results,[0],[0]
⋃ i CR(a′i) is at least as high as the probability that (12) holds.,6. Sphere Covering Results,[0],[0]
"Let pcover(m,n;x,y |mA) denote the probability of covering C(y) conditioned on the number mA of points lying in A. From Lemma 2, we know that pcover(m,n;x,y |mA)",6. Sphere Covering Results,[0],[0]
≥,6. Sphere Covering Results,[0],[0]
"pcover(mA, n).",6. Sphere Covering Results,[0],[0]
"As noted in Lemma 2, this is the chance of turning up n or more heads when flippingmA−1 fair coins, which is one coin for every measurement ai in A.",6. Sphere Covering Results,[0],[0]
"This probability pcover(m,n;x,y) is
pcover(m,n;x,y) =",6. Sphere Covering Results,[0],[0]
"EmA [pcover(m,n;x,y |mA)]",6. Sphere Covering Results,[0],[0]
"≥ EmA [pcover(mA, n)].
Let’s evaluate this expectation.",6. Sphere Covering Results,[0],[0]
"The region A is defined by two planes that intersect at an angle of β = angle(x, x̃)",6. Sphere Covering Results,[0],[0]
"= 2 angle(x,y).",6. Sphere Covering Results,[0],[0]
"The probability of a random point ai lying in A is given by α = 2π−2β2π = 1− 2β π , which is the fraction of the unit sphere that lies either above or below both planes.",6. Sphere Covering Results,[0],[0]
"The probability of a measurement ai contributing to the heads count is half the probability of it lying in A, or 12α.
",6. Sphere Covering Results,[0],[0]
"The probability of turning up n or more heads is therefore given by
pcover(m,n;x,y) =",6. Sphere Covering Results,[0],[0]
"(13)
1− n−1∑ k=0 ( 1 2 α )",6. Sphere Covering Results,[0],[0]
"k ( 1− 1 2 α )m−k−1( m− 1 k ) .
",6. Sphere Covering Results,[0],[0]
Our final result is obtained by applying Hoeffding’s inequality to (13).,6. Sphere Covering Results,[0],[0]
"Using the covering result of Lemma 3, together with the covering formulation of the exact recovery condition (4), proving exact recovery of PhaseMax is now rather straightforward.",7. Recovery Guarantees for PhaseMax,[0],[0]
"We begin with the real-valued case.
",7. Recovery Guarantees for PhaseMax,[0],[0]
Theorem 3.,7. Recovery Guarantees for PhaseMax,[0],[0]
Consider the case of recovering a real-valued signal x0 ∈,7. Recovery Guarantees for PhaseMax,[0],[0]
Rn from m measurements of the form (1) with i.i.d. and uniform vectors {ai ∈ Sn−1R }.,7. Recovery Guarantees for PhaseMax,[0],[0]
"PhaseMax recovers the true signal x0, with probability at least
pR(m,n)",7. Recovery Guarantees for PhaseMax,[0],[0]
"≥ 1− exp (−(αm− α− 2n)2
2m− 2
) ,
where α = 1− 2π angle(x0, x̂) and α(m− 1) > 2n.
",7. Recovery Guarantees for PhaseMax,[0],[0]
Proof.,7. Recovery Guarantees for PhaseMax,[0],[0]
Consider the set of m independent and uniformly sampled measurements {ai ∈ Sn−1R }mi=1.,7. Recovery Guarantees for PhaseMax,[0],[0]
"The aligned vectors {ãi = phase(〈ai,x0〉)ai} are uniformly distributed over the half sphere CR(x0).",7. Recovery Guarantees for PhaseMax,[0],[0]
Exact reconstruction happens when the condition in Lemma 2 holds.,7. Recovery Guarantees for PhaseMax,[0],[0]
"To bound this probability, we invoke Lemma 3 with x = x0 and y = x̂.
We have an analogous result in the complex case.
",7. Recovery Guarantees for PhaseMax,[0],[0]
Theorem 4.,7. Recovery Guarantees for PhaseMax,[0],[0]
Consider the case of recovering a complexvalued signal x0 ∈,7. Recovery Guarantees for PhaseMax,[0],[0]
Rn from m measurements of the form (1) with i.i.d. and uniform vectors {ai ∈ Sn−1R }.,7. Recovery Guarantees for PhaseMax,[0],[0]
"PhaseMax recovers the true signal x0, with probability at least
pC(m,n)",7. Recovery Guarantees for PhaseMax,[0],[0]
"≥ 1− exp (−(αm− 4n)2
4m
) ,
where α = 1− 2π angle(x0, x̂) and αm > 4n+ 1.
",7. Recovery Guarantees for PhaseMax,[0],[0]
Proof.,7. Recovery Guarantees for PhaseMax,[0],[0]
"Let {ãi} = {phase(〈ai,x0〉)ai} be aligned measurement vectors.",7. Recovery Guarantees for PhaseMax,[0],[0]
"Define the half sphere of aligned ascent directions
DC = {δ ∈ Sn−1C |",7. Recovery Guarantees for PhaseMax,[0],[0]
"〈δ, x̂〉 ∈ R+0 }.
",7. Recovery Guarantees for PhaseMax,[0],[0]
"By Lemma 2, PhaseMax recovers x0 if
DC ⊂",7. Recovery Guarantees for PhaseMax,[0],[0]
⋃ i CC(ãi).,7. Recovery Guarantees for PhaseMax,[0],[0]
"(14)
Let us bound the probability of this event.",7. Recovery Guarantees for PhaseMax,[0],[0]
"Consider the set A = {δ | 〈δ,x0〉= = 0}.",7. Recovery Guarantees for PhaseMax,[0],[0]
"We now claim that (14) holds whenever
CC(x̂) ∩ A ⊂",7. Recovery Guarantees for PhaseMax,[0],[0]
⋃ i CC(ãi).,7. Recovery Guarantees for PhaseMax,[0],[0]
"(15)
To prove this claim, consider some δ ∈ DC.",7. Recovery Guarantees for PhaseMax,[0],[0]
"To keep notation light, we will assume without loss of generality that ‖x0‖2 = 1.",7. Recovery Guarantees for PhaseMax,[0],[0]
"Form the vector δ′ = δ + j〈δ,x0〉= x0, which is the projection of δ onto A.",7. Recovery Guarantees for PhaseMax,[0],[0]
Suppose now that (15) holds.,7. Recovery Guarantees for PhaseMax,[0],[0]
"Since δ′ ∈ CC(x̂) ∩ A, there is some i with δ′ ∈ CC(ãi).",7. Recovery Guarantees for PhaseMax,[0],[0]
"But then
0 ≤ 〈δ′, ãi〉< = 〈δ, ãi〉< + 〈j〈δ,x0〉= x0, ãi〉< (16) = 〈δ, ãi〉<.",7. Recovery Guarantees for PhaseMax,[0],[0]
"(17)
We have used the fact that 〈j〈δ,x0〉= x0, ãi〉 = j〈δ,x0〉=〈ãi,x0〉, which is imaginary valued and thus has no real component.",7. Recovery Guarantees for PhaseMax,[0],[0]
"We see that δ ∈ CC(ãi), and the claim is proved.
",7. Recovery Guarantees for PhaseMax,[0],[0]
We now know that exact reconstruction happens whenever condition (15) holds.,7. Recovery Guarantees for PhaseMax,[0],[0]
"Note that the sphere Sn−1C is isomorphic to S2n−1R , and the set A is isomorphic to the sphere S2n−2R .",7. Recovery Guarantees for PhaseMax,[0],[0]
The aligned vectors {ãi} are uniformly distributed over a half sphere in CC(x0) ∩,7. Recovery Guarantees for PhaseMax,[0],[0]
"A, which is isomorphic to the upper half sphere in S2n−2R .",7. Recovery Guarantees for PhaseMax,[0],[0]
The probability of these vectors covering the cap CC(x̂) ∩,7. Recovery Guarantees for PhaseMax,[0],[0]
"A is thus given by pcover(m, 2n− 1;x0, x̂) from Lemma 3, which is at least
1− exp (−(αm− α− 4n+ 2)2
4m− 4
) .
",7. Recovery Guarantees for PhaseMax,[0],[0]
We can simplify this by using the fact that α < 1.,7. Recovery Guarantees for PhaseMax,[0],[0]
"We also throw away the small constants in the numerator and denominator, which weakens the bound very slightly but tidies up the result.",7. Recovery Guarantees for PhaseMax,[0],[0]
A variety of methods exist for generating the initial guess x0.,8.1. Initialization Methods,[0],[0]
"The simplest approach is to use a random vector; see (Goldstein & Studer, 2016) for a corresponding analysis and exact recovery proof in this case.",8.1. Initialization Methods,[0],[0]
"A more powerful method is the truncated spectral initializer (Chen & Candès, 2015), which is a refinement of the method put forward in (Netrapalli et al., 2013).",8.1. Initialization Methods,[0],[0]
"A detailed analysis of such initializers is provided in (Lu & Li, 2017).",8.1. Initialization Methods,[0],[0]
"As proved in Prop. 8 of (Chen & Candès, 2015), for any δ < √ 2, there is a constant c0 such that, with probability exceeding 1 − exp(−c0m), a unit-length version of the approximation vector x̂ computed by the truncated spectral initializer satisfies 1 − δ22 ≤ |〈x0, x̂〉|, provided that m > c1n for
some constant c1 > 0.",8.1. Initialization Methods,[0],[0]
"This implies that the approximation accuracy satisfies
α =1− 2 π angle(x0, x̂)
≥ 1− 2 π arccos
( 1− δ 2
2
)",8.1. Initialization Methods,[0],[0]
"> 0 (18)
with high probability.
",8.1. Initialization Methods,[0],[0]
"This motivates the following process that recovers x0 using a number of measurements that grows linearly with n. First, choose some δ <",8.1. Initialization Methods,[0],[0]
√ 2 and calculate α from (18).,8.1. Initialization Methods,[0],[0]
"Next, generate a spectral initializer x̂ using c1 random Gaussian measurements.",8.1. Initialization Methods,[0],[0]
This initializer has accuracy α with high probability.,8.1. Initialization Methods,[0],[0]
"Finally, using 5n/α (the constant in this expression must be larger than 4 to guarantee recovery with high probability) additional random Gaussian measurements, recover the vector x0 using PhaseMax.",8.1. Initialization Methods,[0],[0]
This recovery step succeeds with high probability when n is large.,8.1. Initialization Methods,[0],[0]
"This process recovers x0 using (5/α+c1)nmeasurements, which is linear in n. For a more detailed analysis with no unspecified constants, see (Goldstein & Studer, 2016).
",8.1. Initialization Methods,[0],[0]
"A simpler recovery approach only samples max{5/α, c1}n measurements, and then uses the same set of measurements for both the initialization and recovery.",8.1. Initialization Methods,[0],[0]
"This process works well in practice, and is used in the experiments below.",8.1. Initialization Methods,[0],[0]
"Technically, our results assume the measurements {ai} are independent of x̂, and so our theory does not formally guarantee convergence in this case.",8.1. Initialization Methods,[0],[0]
"For an analysis that considers the case where {ai} and x̂ are dependent, we refer to the analysis in (Bahmani & Romberg, 2016).",8.1. Initialization Methods,[0],[0]
"We compare PhaseMax with other recovery methods, including lifted convex methods and non-convex approaches.",8.2. Comparison to Other Phase Retrieval Methods,[0],[0]
"Table 1 lists the sample complexity (measurements needed to achieve exact recovery with 0.5 probability) of various phase retrieval methods as a function of the number of un-
knowns",8.2. Comparison to Other Phase Retrieval Methods,[0],[0]
n.,8.2. Comparison to Other Phase Retrieval Methods,[0],[0]
We also list the probability of reconstruction from m measurements.,8.2. Comparison to Other Phase Retrieval Methods,[0],[0]
"We see that PhaseMax requires the same sample complexity (O(n)) as compared to PhaseLift, TWF, and TAW, when used together with the truncated spectral initializer proposed in (Candès & Li, 2014).
",8.2. Comparison to Other Phase Retrieval Methods,[0],[0]
The recovery bounds for all other methods require unspecified constants (ci in Table 1) that are generally extremely large and require a lower bound on the initialization accuracy.,8.2. Comparison to Other Phase Retrieval Methods,[0],[0]
"In contrast, the bounds for PhaseMax contain no unspecified constants, explicitly depend on the approximation factor α, and our new analytical approach yields extremely sharp bounds (see below for the details).
",8.2. Comparison to Other Phase Retrieval Methods,[0],[0]
"We also compare in Table 1 to a different analysis of the PhaseMax formulation by (Bahmani & Romberg, 2016) that appeared shortly before our own, and to a later analysis by (Hand & Voroninski, 2016).",8.2. Comparison to Other Phase Retrieval Methods,[0],[0]
"By using methods from machine learning theory, (Bahmani & Romberg, 2016) produce exact reconstruction bounds that, for a specified value of α, are uniform with respect to the initialization x̂, and thus guarantee exact signal recovery in the case that x̂ is dependent on the measurement vectors.",8.2. Comparison to Other Phase Retrieval Methods,[0],[0]
"The analysis presented here is weaker in the sense that is does not have this uniformity property, but stronger in the sense that it produces tighter bounds without unspecified constants.",8.2. Comparison to Other Phase Retrieval Methods,[0],[0]
"The bounds by (Hand & Voroninski, 2016) require unspecified constants, but the authors show that PhaseMax can be analyzed using standard concentration of measure arguments.",8.2. Comparison to Other Phase Retrieval Methods,[0],[0]
"By using strong concentration bounds for the unit sphere, our analysis produces sharp recovery guarantees that lie close to behavior observed in practice.",8.3. Tightness of Guarantees,[0],[0]
"In Figure 2, we use random Gaussian test problems and the accelerated gradientbased solver described in (Goldstein et al., 2014) to plot the empirical and theoretical probabilities of exact signal recovery for n = 100 and n = 500 measurements while varying the accuracy β = angle(x̂,x0) of the initial guess.
",8.3. Tightness of Guarantees,[0],[0]
"We declared exact recovery when the relative error of the recovered signal fell below 10−5.
",8.3. Tightness of Guarantees,[0],[0]
"Our theoretical bounds tend to agree fairly closely with observations, and generally require fewer than 50% more measurements than is needed in practice.",8.3. Tightness of Guarantees,[0],[0]
"We also observe a sharp phase transition between inaccurate and accurate recovery, as predicted by our theory.",8.3. Tightness of Guarantees,[0],[0]
"To compare PhaseMax to other phase retrieval methods, we observe the accuracy of signal reconstruction as a function of the number of measurements.",8.4. Performance Limits of PhaseMax,[0],[0]
"We emphasize that this comparison is only done in the random Gaussian problem setting, and results may differ with different types of signal, measurement, and noise models.",8.4. Performance Limits of PhaseMax,[0],[0]
"The sole purpose of this experiment is to explore the efficacy and limits of PhaseMax, and to test the tightness of the predicted recovery guarantees.",8.4. Performance Limits of PhaseMax,[0],[0]
"For an extensive comparison between existing methods, see (Waldspurger et al., 2015; Jaganathan et al., 2015)).",8.4. Performance Limits of PhaseMax,[0],[0]
"We compare the Gerchberg-Saxton algorithm (Gerchberg & Saxton, 1972), the Fienup algorithm (Fienup, 1982), the truncated Wirtinger flow (Chen & Candès, 2015), and PhaseMax.",8.4. Performance Limits of PhaseMax,[0],[0]
"All methods were initialized using the truncated spectral initializer (Chen & Candès, 2015).
",8.4. Performance Limits of PhaseMax,[0],[0]
"We also run simulations using the semidefinite relaxation method PhaseLift (Candès et al., 2013) implemented using a proximal gradient solver.",8.4. Performance Limits of PhaseMax,[0],[0]
"PhaseLift, and its equivalent dual formulation PhaseCut (Waldspurger et al., 2015), is the only convex alternative to PhaseMax.",8.4. Performance Limits of PhaseMax,[0],[0]
"However, unlike PhaseMax, PhaseLift/PhaseCut “lifts” the problem to a higher
dimension and squares the number of unknowns.
",8.4. Performance Limits of PhaseMax,[0],[0]
Figure 3 reveals that PhaseMax requires larger oversampling ratios m/n to enable faithful signal recovery compared to non-convex phase-retrieval algorithms that operate in the original signal dimension.,8.4. Performance Limits of PhaseMax,[0],[0]
This is because the truncated spectral initializer requires oversampling ratios of about six or higher to yield sufficiently accurate approximation vectors x̂ that enable PhaseMax to succeed.,8.4. Performance Limits of PhaseMax,[0],[0]
"While PhaseMax does not achieve exact reconstruction with the lowest number of measurements, it is convex, operates in the original signal dimension, can be implemented via solvers for Basis Pursuit, and comes with sharp performance guarantees that do not sweep constants under the rug (cf.",8.4. Performance Limits of PhaseMax,[0],[0]
"Figure 2).
",8.4. Performance Limits of PhaseMax,[0],[0]
"The convexity of PhaseMax enables a natural extension to sparse phase retrieval (Jaganathan et al., 2013; Shechtman et al., 2014) or other signal priors (e.g., total variation, group sparsity, or bounded infinity norm) that can be formulated with convex functions.",8.4. Performance Limits of PhaseMax,[0],[0]
"Such non-differentiable priors cannot be efficiently minimized using simple gradient descent methods (which form the basis of Wirtinger or amplitude flow, and many other methods), but can potentially be solved using standard convex solvers when combined with the PhaseMax formulation.",8.4. Performance Limits of PhaseMax,[0],[0]
We have proposed a convex relaxation for phase retrieval problems called PhaseMax that does not require lifting.,9. Conclusions,[0],[0]
"Using methods from geometric probability, we have provided tight bounds on the probability of correct signal recovery.
",9. Conclusions,[0],[0]
"The proposed problem and its analysis also represents a radical departure, both in theory and algorithms, from conventional methods for convex or semidefinite relaxation.",9. Conclusions,[0],[0]
"By providing a convex relaxation for phase retrieval in the native parameter space, our approach opens the door for using a broad range of convex optimization routines, regularizers, and priors to solve phase retrieval or related problems in machine learning, computer vision, or signal processing.
",9. Conclusions,[0],[0]
"Finally, the new analytical methods used in this paper have recently been used to prove tight reconstruction bounds for bi-convex problems outside the field of phase retrieval (Aghasi et al., 2017), and may be broadly applicable to a wide range of signal processing problems.",9. Conclusions,[0],[0]
"The work of T. Goldstein was supported in part by the US National Science Foundation (NSF) under grant CCF1535902, by the US Office of Naval Research under grant N00014-17-1-2078, and by the Sloan Foundation.",Acknowledgments,[0],[0]
"The work of C. Studer was supported in part by Xilinx, Inc. and by the US NSF under grants ECCS-1408006, CCF-1535897, and CAREER CCF-1652065.",Acknowledgments,[0],[0]
"Semidefinite relaxation methods transform a variety of non-convex optimization problems into convex problems, but square the number of variables.",abstractText,[0],[0]
"We study a new type of convex relaxation for phase retrieval problems, called PhaseMax, that convexifies the underlying problem without lifting.",abstractText,[0],[0]
"The resulting problem formulation can be solved using standard convex optimization routines, while still working in the original, lowdimensional variable space.",abstractText,[0],[0]
"We prove, using a random spherical distribution measurement model, that PhaseMax succeeds with high probability for a sufficiently large number of measurements.",abstractText,[0],[0]
We compare our approach to other phase retrieval methods and demonstrate that our theory accurately predicts the success of PhaseMax.,abstractText,[0],[0]
Convex Phase Retrieval without Lifting via PhaseMax,title,[0],[0]
"Convolutional neural networks (CNNs) (LeCun et al., 1998) have proven successful across many tasks including image classification (LeCun et al., 1998; Krizhevsky et al., 2012), face recognition (Lawrence et al., 1997), speech recognition (Hinton et al., 2012), text classification (Wang et al., 2012), and game playing (Mnih et al., 2015; Silver et al., 2016).",1. Introduction,[0],[0]
"There are two principal advantages of a CNN over a fully-connected neural network: (i) sparsity—each nonlinear convolutional filter acts only on a local patch of the input, and (ii) parameter sharing—the same filter is applied to each patch.
",1. Introduction,[0],[0]
"However, as with most neural networks, the standard approach to training CNNs is based on solving a nonconvex optimization problem that is known to be NP-hard (Blum
1Stanford University, CA, USA 2University of California, Berkeley, CA, USA.",1. Introduction,[0],[0]
"Correspondence to: Yuchen Zhang <zhangyuc@cs.stanford.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
& Rivest, 1992).",1. Introduction,[0],[0]
"In practice, researchers use some flavor of stochastic gradient method, in which gradients are computed via backpropagation (Bottou, 1998).",1. Introduction,[0],[0]
"This approach has two drawbacks: (i) the rate of convergence, which is at best only to a local optimum, can be slow due to nonconvexity (for instance, see the paper (Fahlman, 1988)), and (ii) its statistical properties are very difficult to understand, as the actual performance is determined by some combination of the CNN architecture along with the optimization algorithm.
",1. Introduction,[0],[0]
"In this paper, with the goal of addressing these two challenges, we propose a new model class known as convexified convolutional neural networks (CCNNs).",1. Introduction,[0],[0]
These models have two desirable features.,1. Introduction,[0],[0]
"First, training a CCNN corresponds to a convex optimization problem, which can be solved efficiently and optimally via a projected gradient algorithm.",1. Introduction,[0],[0]
"Second, the statistical properties of CCNN models can be studied in a precise and rigorous manner.",1. Introduction,[0],[0]
We obtain CCNNs by convexifying two-layer CNNs; doing so requires overcoming two challenges.,1. Introduction,[0],[0]
"First, the activation function of a CNN is nonlinear.",1. Introduction,[0],[0]
"In order to address this issue, we relax the class of CNN filters to a reproducing kernel Hilbert space (RKHS).",1. Introduction,[0],[0]
"This approach is inspired by the paper (Zhang et al., 2016a), which put forth a relaxation for fully-connected neural networks.",1. Introduction,[0],[0]
"Second, the parameter sharing induced by CNNs is crucial to its effectiveness and must be preserved.",1. Introduction,[0],[0]
We show that CNNs with RKHS filters can be parametrized by a low-rank matrix.,1. Introduction,[0],[0]
"Relaxing this low-rank constraint to a nuclear norm constraint leads to our final formulation of CCNNs.
",1. Introduction,[0],[0]
"On the theoretical front, we prove an oracle inequality on the generalization error achieved by our class of CCNNs, showing that it is upper bounded by the best possible performance achievable by a two-layer CNN given infinite data—a quantity to which we refer as the oracle risk—plus a model complexity term that decays to zero polynomially in the sample size.",1. Introduction,[0],[0]
"Our results suggest that the sample complexity for CCNNs is significantly lower than that of the convexified fully-connected neural network (Zhang et al., 2016a), highlighting the importance of parameter sharing.",1. Introduction,[0],[0]
"For models with more than one hidden layer, our theory does not apply, but we provide encouraging empirical results using a greedy layer-wise training heuristic.",1. Introduction,[0],[0]
"Finally, we apply CCNNs to the MNIST handwritten digit dataset
as well as four variation datasets (VariationsMNIST), and find that it achieves state-of-the-art accuracy.
",1. Introduction,[0],[0]
Related work.,1. Introduction,[0],[0]
"With the empirical success of deep neural networks, there has been an increasing interest in understanding its connection to convex optimization.",1. Introduction,[0],[0]
Bengio et al. (2005) showed how to formulate neural network training as a convex optimization problem involving an infinite number of parameters.,1. Introduction,[0],[0]
Aslan et al. (2013; 2014) propose a method for learning multi-layer latent-variable models.,1. Introduction,[0],[0]
"They showed that for certain activation functions, the proposed method is a convex relaxation for learning fullyconnected neural networks.
",1. Introduction,[0],[0]
Past work has studied learning translation-invariant features without backpropagation.,1. Introduction,[0],[0]
Mairal et al. (2014) present convolutional kernel networks.,1. Introduction,[0],[0]
"They propose a translationinvariant kernel whose feature mapping can be approximated by a composition of the convolution, non-linearity and pooling operators, obtained through unsupervised learning.",1. Introduction,[0],[0]
"However, this method is not equipped with the optimality guarantees that we provide for CCNNs in this paper, even for learning one convolutional layer.",1. Introduction,[0],[0]
"The ScatNet method (Bruna & Mallat, 2013) uses translation and deformation-invariant filters constructed by wavelet analysis; however, these filters are independent of the data, in contrast to CCNNs.",1. Introduction,[0],[0]
"Daniely et al. (2016) show that a randomly initialized CNN can extract features as powerful as kernel methods, but it is not clear how to provably improve the model from random initialization.
Notation.",1. Introduction,[0],[0]
"For any positive integer n, we use [n] as a shorthand for the discrete set {1, 2, . . .",1. Introduction,[0],[0]
", n}.",1. Introduction,[0],[0]
"For a rectangular matrix A, let ‖A‖∗ be its nuclear norm, ‖A‖2 be its spectral norm (i.e., maximal singular value), and ‖A‖F be its Frobenius norm.",1. Introduction,[0],[0]
"We use `2(N) to denote the set of countable dimensional vectors v = (v1, v2, . . . )",1. Introduction,[0],[0]
such that ∑∞,1. Introduction,[0],[0]
"`=1 v 2 ` < ∞. For any vectors u, v ∈",1. Introduction,[0],[0]
"`2(N),
the inner product 〈u, v〉 := ∑∞",1. Introduction,[0],[0]
"`=1 uivi and the `2-norm
‖u‖2",1. Introduction,[0],[0]
":= √ 〈u, u〉 are well defined.",1. Introduction,[0],[0]
"In this section, we formalize the class of convolutional neural networks to be learned and describe the associated nonconvex optimization problem.",2. Background and problem setup,[0],[0]
"At a high level, a two-layer CNN1 is a function that maps an input vector x ∈ Rd0 (e.g., an image) to an output vector in y ∈ Rd2",2.1. Convolutional neural networks,[0],[0]
"(e.g., classification scores for d2 classes).",2.1. Convolutional neural networks,[0],[0]
"This mapping is formed in the following manner:
1Average pooling and multiple channels are also an integral part of CNNs, but these do not present any new technical challenges, so that we defer these extensions to Section 4.
",2.1. Convolutional neural networks,[0],[0]
"• First, we extract a collection of P vectors {zp(x)}Pp=1 of the full input vector x. Each vector zp(x) ∈ Rd1 is referred to as a patch, and these patches may depend on overlapping components of x. • Second, given some choice of activation function σ : R→ R and a collection of weight vectors {wj}rj=1 in Rd1 , we define the functions
hj(z) := σ(w > j z) for each patch z ∈ Rd1 .",2.1. Convolutional neural networks,[0],[0]
"(1)
",2.1. Convolutional neural networks,[0],[0]
Each function hj (for j ∈,2.1. Convolutional neural networks,[0],[0]
"[r]) is known as a filter, and note that the same filters are applied to each patch—this corresponds to the parameter sharing of a CNN.",2.1. Convolutional neural networks,[0],[0]
•,2.1. Convolutional neural networks,[0],[0]
"Third, for each patch index p ∈",2.1. Convolutional neural networks,[0],[0]
"[P ], filter index j ∈",2.1. Convolutional neural networks,[0],[0]
"[r], and output coordinate k ∈",2.1. Convolutional neural networks,[0],[0]
"[d2], we introduce a coefficient αk,j,p ∈ R that governs the contribution of the filter hj on patch zp(x) to output fk(x).",2.1. Convolutional neural networks,[0],[0]
"The final form of the CNN is given by f(x) : = (f1(x), . . .",2.1. Convolutional neural networks,[0],[0]
", fd2(x)), where the kth component is given by
fk(x) := r∑ j=1 P∑ p=1 αk,j,phj(zp(x)).",2.1. Convolutional neural networks,[0],[0]
"(2)
Taking the patch functions {zp}Pp=1 and activation function σ as fixed, the parameters of the CNN are the filter vectors",2.1. Convolutional neural networks,[0],[0]
w := {wj ∈ Rd1 :,2.1. Convolutional neural networks,[0],[0]
j ∈,2.1. Convolutional neural networks,[0],[0]
"[r]} along with the collection of coefficient vectors α := {αk,j ∈ RP : k ∈",2.1. Convolutional neural networks,[0],[0]
"[d2], j ∈",2.1. Convolutional neural networks,[0],[0]
[r]}.,2.1. Convolutional neural networks,[0],[0]
We assume that all patch vectors zp(x) ∈ Rd1 are contained in the unit `2-ball.,2.1. Convolutional neural networks,[0],[0]
This assumption can be satisfied without loss of generality by normalization: By multiplying a constant γ > 0,2.1. Convolutional neural networks,[0],[0]
"to every patch zp(x) and multiplying 1/γ to the filter vectors w, this assumption holds without changing the the output of the network.
",2.1. Convolutional neural networks,[0],[0]
"Given some positive radii B1 and B2, we consider the model class
Fcnn(B1, B2) := { f of the form (2) : max
j∈[r] ‖wj‖2 ≤ B1
and max k∈[d2],j∈[r]
‖αk,j‖2 ≤ B2 } .",2.1. Convolutional neural networks,[0],[0]
"(3)
When the radii (B1, B2) are clear from context, we adopt Fcnn as a convenient shorthand.",2.1. Convolutional neural networks,[0],[0]
"Given an input-output pair (x, y) and a CNN f , we let L(f(x); y) denote the loss incurred when the output y is predicted via f(x).",2.2. Empirical risk minimization.,[0],[0]
We assume that the loss function L is convex and L-Lipschitz in its first argument given any value of its second argument.,2.2. Empirical risk minimization.,[0],[0]
"As a concrete example, for multiclass classification with d2 classes, the output vector y takes values in the discrete set [d2] = {1, 2, . .",2.2. Empirical risk minimization.,[0],[0]
.,2.2. Empirical risk minimization.,[0],[0]
", d2}.",2.2. Empirical risk minimization.,[0],[0]
"For example, given a vector f(x) = (f1(x), . . .",2.2. Empirical risk minimization.,[0],[0]
", fd2(y)) ∈ Rd2 of classification scores, the associated multiclass logistic loss for a pair (x, y) is given by L(f(x); y) := −fy(x) +
log (∑d2 y′=1 exp(fy′(x)) ) .
",2.2. Empirical risk minimization.,[0],[0]
"Given n training examples {(xi, yi)}ni=1, we would like to compute an empirical risk minimizer:
f̂cnn ∈ arg min f∈Fcnn n∑ i=1 L(f(xi); yi).",2.2. Empirical risk minimization.,[0],[0]
"(4)
Recalling that functions f ∈ Fcnn depend on the parameters w and α in a highly nonlinear way (2), this optimization problem is nonconvex.",2.2. Empirical risk minimization.,[0],[0]
"As mentioned earlier, heuristics based on stochastic gradient methods are used in practice, which makes it challenging to gain a theoretical understanding of their behavior.",2.2. Empirical risk minimization.,[0],[0]
"Thus, in the next section, we describe a relaxation of the class Fcnn for which empirical risk minimization is convex.",2.2. Empirical risk minimization.,[0],[0]
We now turn to the development of the class of convexified CNNs.,3. Convexifying CNNs,[0],[0]
We begin in Section 3.1 by illustrating the procedure for the special case of the linear activation function.,3. Convexifying CNNs,[0],[0]
"Although the linear case is not of practical interest, it provides intuition for our more general convexification procedure, described in Section 3.2, which applies to nonlinear activation functions.",3. Convexifying CNNs,[0],[0]
"In particular, we show how embedding the nonlinear problem into an appropriately chosen reproducing kernel Hilbert space (RKHS) allows us to again reduce to the linear setting.",3. Convexifying CNNs,[0],[0]
"In order to develop intuition for our approach, let us begin by considering the simple case of the linear activation function σ(t) = t.",3.1. Linear activation functions: low rank relaxations,[0],[0]
"In this case, the filter hj when applied to the patch vector zp(x) outputs a Euclidean inner product of the form hj(zp(x))",3.1. Linear activation functions: low rank relaxations,[0],[0]
"= 〈zp(x), wj〉.",3.1. Linear activation functions: low rank relaxations,[0],[0]
"For each x ∈ Rd0 , we first define the P × d1-dimensional matrix
Z(x) := z1(x) >
... zP",3.1. Linear activation functions: low rank relaxations,[0],[0]
(x) >  .,3.1. Linear activation functions: low rank relaxations,[0],[0]
"(5) We also define the P -dimensional vector αk,j := (αk,j,1, . . .",3.1. Linear activation functions: low rank relaxations,[0],[0]
", αk,j,P )
",3.1. Linear activation functions: low rank relaxations,[0],[0]
>.,3.1. Linear activation functions: low rank relaxations,[0],[0]
"With this notation, we can rewrite equation (2) for the kth output as
fk(x) = r∑ j=1 P∑ p=1 αk,j,p〈zp(x), wj〉 = r∑ j=1 α>k,jZ(x)wj
= tr ( Z(x) ( r∑ j=1 wjα > k,j ))",3.1. Linear activation functions: low rank relaxations,[0],[0]
"= tr(Z(x)Ak), (6)
where in the final step, we have defined the d1 × P - dimensional matrix",3.1. Linear activation functions: low rank relaxations,[0],[0]
"Ak := ∑r j=1 wjα > k,j .",3.1. Linear activation functions: low rank relaxations,[0],[0]
Observe that fk now depends linearly on the matrix parameter Ak.,3.1. Linear activation functions: low rank relaxations,[0],[0]
"Moreover, the matrixAk has rank at most r, due to the parameter
sharing of CNNs.",3.1. Linear activation functions: low rank relaxations,[0],[0]
"See Figure 1 for a graphical illustration of this model structure.
",3.1. Linear activation functions: low rank relaxations,[0],[0]
"Letting A := (A1, . . .",3.1. Linear activation functions: low rank relaxations,[0],[0]
", Ad2) be a concatenation of these matrices across all d2 output coordinates, we can then define a function fA : Rd1 → Rd2 of the form
fA(x) := (tr(Z(x)A1), . . .",3.1. Linear activation functions: low rank relaxations,[0],[0]
", tr(Z(x)Ad2)).",3.1. Linear activation functions: low rank relaxations,[0],[0]
"(7)
Note that these functions have a linear parameterization in terms of the underlying matrix A.",3.1. Linear activation functions: low rank relaxations,[0],[0]
"Our model class corresponds to a collection of such functions based on imposing certain constraints on the underlying matrix A: in particular, we define Fcnn(B1, B2) to be the set of functions fA which satisfies: (C1) maxj∈[r] ‖wj‖2 ≤ B1, maxk∈[d2],j∈[r] ‖αk,j‖2 ≤ B2; and (C2) rank(A) = r.",3.1. Linear activation functions: low rank relaxations,[0],[0]
This is simply an alternative formulation of our original class of CNNs defined in equation (3).,3.1. Linear activation functions: low rank relaxations,[0],[0]
"Notice that if the filter weights wj are not shared across all patches, then the constraint (C1) still holds, but constraint (C2) no longer holds.",3.1. Linear activation functions: low rank relaxations,[0],[0]
"Thus, the parameter sharing of CNNs is realized by the low-rank constraint (C2).",3.1. Linear activation functions: low rank relaxations,[0],[0]
"The matrix A of rank r can be decomposed as A = UV >, where both U and V have r columns.",3.1. Linear activation functions: low rank relaxations,[0],[0]
"The column space of matrix A contains the convolution parameters {wj}, and the row space of A contains to the output parameters {αk,j}.
",3.1. Linear activation functions: low rank relaxations,[0],[0]
The matrices satisfying constraints (C1) and (C2) form a nonconvex set.,3.1. Linear activation functions: low rank relaxations,[0],[0]
A standard convex relaxation is based on the nuclear norm ‖A‖∗,3.1. Linear activation functions: low rank relaxations,[0],[0]
corresponding to the sum of the singular values of A.,3.1. Linear activation functions: low rank relaxations,[0],[0]
It is straightforward to verify that any matrix A satisfying the constraints (C1) and (C2) must have nuclear norm bounded as ‖A‖∗ ≤,3.1. Linear activation functions: low rank relaxations,[0],[0]
B1B2r √ d2.,3.1. Linear activation functions: low rank relaxations,[0],[0]
"Consequently, if we define the function class
Fccnn := { fA : ‖A‖∗ ≤",3.1. Linear activation functions: low rank relaxations,[0],[0]
"B1B2r √ d2 } , (8)
then we are guaranteed that Fccnn ⊇ Fcnn.
We propose to minimize the empirical risk (4) over Fccnn instead of Fcnn; doing so defines a convex optimization problem over this richer class of functions
f̂ccnn := arg min fA∈Fccnn n∑ i=1 L(fA(xi); yi).",3.1. Linear activation functions: low rank relaxations,[0],[0]
"(9)
In Section 3.3, we describe iterative algorithms that can be used to solve this convex problem in the more general setting of nonlinear activation functions.",3.1. Linear activation functions: low rank relaxations,[0],[0]
"For nonlinear activation functions σ, we relax the class of CNN filters to a reproducing kernel Hilbert space (RKHS).",3.2. Nonlinear activations: RKHS filters,[0],[0]
"As we will show, this relaxation allows us to reduce the problem to the linear activation case.
",3.2. Nonlinear activations: RKHS filters,[0],[0]
Let K : Rd1 × Rd1 → R be a positive semidefinite kernel function.,3.2. Nonlinear activations: RKHS filters,[0],[0]
"For particular choices of kernels (e.g., the Gaus-
sian RBF kernel) and a sufficiently smooth activation function σ, we are able to show that the filter h : z 7→ σ(〈w, z〉) is contained in the RKHS induced by the kernel functionK.",3.2. Nonlinear activations: RKHS filters,[0],[0]
See Section 3.4 for the choice of the kernel function and the activation function.,3.2. Nonlinear activations: RKHS filters,[0],[0]
Let S := {zp(xi) :,3.2. Nonlinear activations: RKHS filters,[0],[0]
p ∈,3.2. Nonlinear activations: RKHS filters,[0],[0]
"[P ], i ∈",3.2. Nonlinear activations: RKHS filters,[0],[0]
[n]} be the set of patches in the training dataset.,3.2. Nonlinear activations: RKHS filters,[0],[0]
"The representer theorem then implies that for any patch zp(xi) ∈ S, the function value can be represented by
h(zp(xi))",3.2. Nonlinear activations: RKHS filters,[0],[0]
"= ∑
(i′,p′)∈[n]×[P ]
ci′,p′K(zp(xi), zp′(xi′))",3.2. Nonlinear activations: RKHS filters,[0],[0]
"(10)
for some coefficients {ci′,p′}(i′,p′)∈[n]×[P ].",3.2. Nonlinear activations: RKHS filters,[0],[0]
"Filters of the form (10) are members of the RKHS, because they are linear combinations of basis functions z 7→",3.2. Nonlinear activations: RKHS filters,[0],[0]
"K(z, zp′(xi′)).",3.2. Nonlinear activations: RKHS filters,[0],[0]
"Such filters are parametrized by a finite set of coefficients {ci′,p′}(i′,p′)∈[n]×[P ], which can be estimated via empirical risk minimization.
",3.2. Nonlinear activations: RKHS filters,[0],[0]
"Let K ∈ RnP×nP be the symmetric kernel matrix, where with rows and columns indexed by the example-patch index pair (i, p) ∈",3.2. Nonlinear activations: RKHS filters,[0],[0]
[n] ×,3.2. Nonlinear activations: RKHS filters,[0],[0]
[P ].,3.2. Nonlinear activations: RKHS filters,[0],[0]
"The entry at row (i, p) and column (i′, p′) of matrix K is equal to K(zp(xi), zp′(xi′)).",3.2. Nonlinear activations: RKHS filters,[0],[0]
"So as to avoid re-deriving everything in the kernelized setting, we perform a reduction to the linear setting of Section 3.1.",3.2. Nonlinear activations: RKHS filters,[0],[0]
"Consider a factorization K = QQ> of the kernel matrix, where Q ∈ RnP×m; one example is the Cholesky factorization with m = nP .",3.2. Nonlinear activations: RKHS filters,[0],[0]
"We can interpret each row Q(i,p) ∈",3.2. Nonlinear activations: RKHS filters,[0],[0]
"Rm as a feature vector in place of the original zp(xi) ∈ Rd1 , and rewrite equation (10) as
h(zp(xi))",3.2. Nonlinear activations: RKHS filters,[0],[0]
"= 〈Q(i,p), w〉 where w := ∑ (i′,p′) ci′,p′Q(i′,p′).
",3.2. Nonlinear activations: RKHS filters,[0],[0]
"In order to learn the filter h, it suffices to learn the mdimensional vector w. To do this, define patch matrices Z(xi) ∈ RP×m for each",3.2. Nonlinear activations: RKHS filters,[0],[0]
i ∈,3.2. Nonlinear activations: RKHS filters,[0],[0]
"[n] so that its p-th row is Q(i,p).",3.2. Nonlinear activations: RKHS filters,[0],[0]
"Then the problem reduces to learning a linear filter with coefficient vector w. Carrying out all of Sec-
tion 3.1, solving the ERM gives us a parameter matrix A ∈ Rm×Pd2 .",3.2. Nonlinear activations: RKHS filters,[0],[0]
The only difference is that `2-norm constraint (C1) needs to be adapted to the norm of the RKHS.,3.2. Nonlinear activations: RKHS filters,[0],[0]
"See Appendix B for details.
",3.2. Nonlinear activations: RKHS filters,[0],[0]
"At test time, given a new input x ∈ Rd0 , we can compute a patch matrix Z(x) ∈ RP×m as follows: • The p-th row of this matrix is the feature vector for
patch p, which is equal to Q†v(zp(x))",3.2. Nonlinear activations: RKHS filters,[0],[0]
"∈ Rm, where for any patch z, the vector v(z) is defined as a nP - dimensional vector whose (i, p)-th coordinate is equal to K(z, zp(xi)).",3.2. Nonlinear activations: RKHS filters,[0],[0]
"We note that if x is an instance xi in the training set, then the vector Q†v(zp(x)) is exactly equal to Q(i,p).",3.2. Nonlinear activations: RKHS filters,[0],[0]
"Thus the mapping Z(x) applies to both training and testing.
",3.2. Nonlinear activations: RKHS filters,[0],[0]
• We can then compute the predictor fk(x) = tr(Z(x)Ak) via equation (6).,3.2. Nonlinear activations: RKHS filters,[0],[0]
"Note that we do not explicitly need to compute the filter values hj(zp(x)) to compute the output under the CCNN.
",3.2. Nonlinear activations: RKHS filters,[0],[0]
Retrieving filters.,3.2. Nonlinear activations: RKHS filters,[0],[0]
"When we learn multi-layer CCNNs (Section 4), we need to compute the filters hj explicitly in order to form the inputs to the next layer.",3.2. Nonlinear activations: RKHS filters,[0],[0]
"Recall from Section 3.1 that the column space of matrix A corresponds to parameters of the convolutional layer, and the row space of A corresponds to parameters of the output layer.",3.2. Nonlinear activations: RKHS filters,[0],[0]
"Thus, once we obtain the parameter matrixA, we compute a rankr approximation A ≈ Û V̂ >.",3.2. Nonlinear activations: RKHS filters,[0],[0]
"Then set the j-th filter hj to the mapping
z 7→ 〈Ûj , Q†v(z)〉 for any patch z ∈ Rd1 , (11)
where Ûj ∈ Rm is the j-th column of matrix Û , and Q†v(z) represents the feature vector for patch z.2",3.2. Nonlinear activations: RKHS filters,[0],[0]
"The matrix V̂ > encodes parameters of the output layer, thus
2If z is a patch in the training set, namely z = zp(xi), then we have equation Q†v(z) =",3.2. Nonlinear activations: RKHS filters,[0],[0]
"Q(i,p)
Algorithm 1",3.2. Nonlinear activations: RKHS filters,[0],[0]
"Learning two-layer CCNNs Input: Data {(xi, yi)}ni=1, kernel function K, regularization parameter R > 0, number of filters r. 1.",3.2. Nonlinear activations: RKHS filters,[0],[0]
"Construct a kernel matrix K ∈ RnP×nP such that the entry
at column (i, p) and row (i′, p′) is equal to K(zp(xi), zp′(xi′)).",3.2. Nonlinear activations: RKHS filters,[0],[0]
"Compute a factorization K = QQ> or an approximation K ≈ QQ>, where Q ∈ RnP×m.
2.",3.2. Nonlinear activations: RKHS filters,[0],[0]
"For each xi, construct patch matrix Z(xi) ∈ RP×m whose p-th row is the (i, p)-th row of Q, where Z(·) is defined in Section 3.2.",3.2. Nonlinear activations: RKHS filters,[0],[0]
3.,3.2. Nonlinear activations: RKHS filters,[0],[0]
"Solve the following optimization problem to obtain a matrix Â = (Â1, . . .",3.2. Nonlinear activations: RKHS filters,[0],[0]
", Âd2):
Â ∈ argmin ‖A‖∗≤R L̃(A) where (12)
L̃(A) := n∑
i=1
L (( tr(Z(xi)A1), . . .",3.2. Nonlinear activations: RKHS filters,[0],[0]
", tr(Z(xi)Ad2) ) ; yi ) .
4.",3.2. Nonlinear activations: RKHS filters,[0],[0]
Compute a rank-r approximation Û V̂ >,3.2. Nonlinear activations: RKHS filters,[0],[0]
"≈ Â where Û ∈ Rm×r and V̂ ∈ RPd2×r .
",3.2. Nonlinear activations: RKHS filters,[0],[0]
"Output: predictor f̂ccnn(x) := ( tr(Z(x)Â1), . . .",3.2. Nonlinear activations: RKHS filters,[0],[0]
", tr(Z(x)Âd2) )",3.2. Nonlinear activations: RKHS filters,[0],[0]
"and the convolutional layer output H(x) := Û>Z(x)>.
doesn’t appear in the filter expression (11).",3.2. Nonlinear activations: RKHS filters,[0],[0]
"It is important to note that the filter retrieval is not unique, because the rank-r approximation of the matrix A is not unique.",3.2. Nonlinear activations: RKHS filters,[0],[0]
"The heuristic we suggest is to form the singular value decomposition A = UΛV >, then define Û to be the first r columns of U .
",3.2. Nonlinear activations: RKHS filters,[0],[0]
"When we apply all of the r filters to all patches of an input x ∈ Rd0 , the resulting output is H(x) := Û>Z(x)> — this is an r×P matrix whose element at row j and column p is equal to hj(zp(x)).",3.2. Nonlinear activations: RKHS filters,[0],[0]
The algorithm for learning a two-layer CCNN is summarized in Algorithm 1; it is a formalization of the steps described in Section 3.2.,3.3. Algorithm,[0],[0]
"In order to solve the optimization problem (12), the simplest approach is via projected gradient descent: At iteration t, using a step size ηt > 0, we form the new matrix At+1 based on the previous iterate At according to:
At+1 = ΠR ( At − ηt ∇AL̃(At) ) .",3.3. Algorithm,[0],[0]
"(13)
",3.3. Algorithm,[0],[0]
"Here ∇AL̃ denotes the gradient of the objective function defined in (12), and ΠR denotes the Euclidean projection onto the nuclear norm ball {A : ‖A‖∗ ≤ R}.",3.3. Algorithm,[0],[0]
"This nuclear norm projection can be obtained by first computing the singular value decomposition of A, and then projecting the vector of singular values onto the `1-ball.",3.3. Algorithm,[0],[0]
This latter projection step can be carried out efficiently by the algorithm of Duchi et al. (2008).,3.3. Algorithm,[0],[0]
"There are other efficient optimiza-
tion algorithms (Duchi et al., 2011; Xiao & Zhang, 2014) for solving the problem (12).",3.3. Algorithm,[0],[0]
"All these algorithms can be executed in a stochastic fashion, so that each gradient step processes a mini-batch of examples.
",3.3. Algorithm,[0],[0]
"The computational complexity of each iteration depends on the width m of the matrix Q. Setting m = nP allows us to solve the exact kernelized problem, but to improve the computation efficiency, we can use Nyström approximation (Drineas & Mahoney, 2005) or random feature approximation (Rahimi & Recht, 2007); both are randomized methods to obtain a tall-and-thin matrix Q ∈ RnP×m such thatK ≈ QQ>.",3.3. Algorithm,[0],[0]
"Typically, the parameterm is chosen to be much smaller than nP .",3.3. Algorithm,[0],[0]
"In order to compute the matrix Q, the Nyström approximation method takes O(m2nP ) time.",3.3. Algorithm,[0],[0]
"The random feature approximation takesO(mnPd1) time, but can be improved to O(mnP log d1) time using the fast Hadamard transform (Le et al., 2013).",3.3. Algorithm,[0],[0]
The time complexity of project gradient descent also scales with m rather than with nP .,3.3. Algorithm,[0],[0]
"In this section, we upper bound the generalization error of Algorithm 1, proving that it converges to the best possible generalization error of CNN.",3.4. Theoretical results,[0],[0]
"We focus on the binary classification case where the output dimension is d2 = 1.3
The learning of CCNN requires a kernel function",3.4. Theoretical results,[0],[0]
"K. We consider kernel functions whose associated RKHS is large enough to contain any function of the following form: z 7→ q(〈w, z〉), where q is an arbitrary polynomial function and w ∈ Rd1 is an arbitrary vector.",3.4. Theoretical results,[0],[0]
"As a concrete example, we consider the inverse polynomial kernel:
K(z, z′) :",3.4. Theoretical results,[0],[0]
"= 1 2− 〈z, z′〉 , ‖z‖2 ≤ 1, ‖z′‖2 ≤ 1.",3.4. Theoretical results,[0],[0]
"(14)
",3.4. Theoretical results,[0],[0]
"This kernel was studied by Shalev-Shwartz et al. (2011) for learning halfspaces, and by Zhang et al. (2016a) for learning fully-connected neural networks.",3.4. Theoretical results,[0],[0]
"We also consider the Gaussian RBF kernel:
K(z, z′) := e−γ‖z−z ′‖22 , ‖z‖2 = ‖z′‖2 = 1. (15)
As shown by Appendix A, the inverse polynomial kernel and the Gaussian kernel satisfy the above notion of richness.",3.4. Theoretical results,[0],[0]
"We focus on these two kernels for the theoretical analysis.
",3.4. Theoretical results,[0],[0]
Let f̂ccnn be the CCNN that minimizes the empirical risk (12) using one of the two kernels above.,3.4. Theoretical results,[0],[0]
"Our main theoretical result is that for suitably chosen activation functions, the generalization error of f̂ccnn is comparable to that of the best CNN model.",3.4. Theoretical results,[0],[0]
"In particular, we consider the following types of activation functions σ:
3We can treat the multiclass case by performing a standard one-versus-all reduction to the binary case.
",3.4. Theoretical results,[0],[0]
"(a) arbitrary polynomial functions (e.g., used by Chen & Manning (2014); Livni et al. (2014)).
",3.4. Theoretical results,[0],[0]
(b) sinusoid activation function σ(t),3.4. Theoretical results,[0],[0]
":= sin(t) (e.g., used by Sopena et al. (1999); Isa et al. (2010)).
",3.4. Theoretical results,[0],[0]
(c) erf function σerf(t) := 2/ √ π ∫ t 0,3.4. Theoretical results,[0],[0]
"e−z 2
dz, which represents a close approximation to the sigmoid function (Zhang et al., 2016a).
",3.4. Theoretical results,[0],[0]
"(d) a smoothed hinge loss σsh(t) := ∫ t −∞ 1 2 (σerf(z) +
1)dz, which represents a close approximation to the ReLU function (Zhang et al., 2016a).
",3.4. Theoretical results,[0],[0]
"To understand how these activation functions pair with our choice of kernels, we consider polynomial expansions of the above activation functions: σ(t) = ∑∞ j=0",3.4. Theoretical results,[0],[0]
"ajt
j , and note that the smoothness of these functions are characterized by the rate of their coefficients {aj}∞j=0 converging to zero.",3.4. Theoretical results,[0],[0]
"If σ is a polynomial in category (a), then the richness of the RKHS guarantees that it contains the class of filters activated by function σ.",3.4. Theoretical results,[0],[0]
"If σ is a non-polynomial function in categories (b),(c),(d), then as Appendix A shows, the RKHS contains the filter only if the coefficients {aj}∞j=0 converge quickly enough to zero (the criterion depends on the concrete choice of the kernel).",3.4. Theoretical results,[0],[0]
"Concretely, the inverse polynomial kernel is shown to capture all of the four categories of activations: thus, (a), (b), (c), and (d) are all are referred as valid activation functions for the inverse polynomial kernel.",3.4. Theoretical results,[0],[0]
"The Gaussian kernel induces a smaller RKHS, so only (a) and (b) are valid activation functions for the Gaussian kernel.",3.4. Theoretical results,[0],[0]
"In contrast, the sigmoid function and the ReLU function are not valid for either kernel, because their polynomial expansions fail to converge quickly enough, or more intuitively speaking, because they are not smooth enough to be contained in the RKHS.
",3.4. Theoretical results,[0],[0]
We are ready to state the main theoretical result.,3.4. Theoretical results,[0],[0]
"In the theorem statement, we use K(X) ∈ RP×P to denote the random kernel matrix obtained from an input vector X ∈ Rd0 drawn randomly from the population.",3.4. Theoretical results,[0],[0]
"More precisely, the (p, q)-th entry of K(X) is given by K(zp(X), zq(X)).
",3.4. Theoretical results,[0],[0]
Theorem 1.,3.4. Theoretical results,[0],[0]
Assume that the loss function L(·; y) is LLipchitz continuous for every y ∈,3.4. Theoretical results,[0],[0]
[d2] and that K is the inverse polynomial kernel or the Gaussian kernel.,3.4. Theoretical results,[0],[0]
"For any valid activation function σ, there is a constantCσ(B1) such that by choosing hyper-parameterR := Cσ(B1)B2r in Algorithm 1, the expected generalization error is at most
EX,Y [L(f̂ccnn(X);Y )]",3.4. Theoretical results,[0],[0]
"≤ inf f∈Fcnn EX,Y [L(f(X);Y )]
+ c",3.4. Theoretical results,[0],[0]
LCσ(B1)B2r √ log(nP ),3.4. Theoretical results,[0],[0]
"EX [‖K(X)‖2]√
n , (16)
",3.4. Theoretical results,[0],[0]
"where c > 0 is a universal constant.
",3.4. Theoretical results,[0],[0]
"Proof sketch The proof of Theorem 1 consists of two parts: First, we consider a larger function class that con-
tains the class of CNNs.",3.4. Theoretical results,[0],[0]
"This function class is defined as:
Fccnn := { x 7→ r∗∑ j=1 P∑ p=1 αj,phj(zp(x))",3.4. Theoretical results,[0],[0]
: r ∗ <∞,3.4. Theoretical results,[0],[0]
"(17)
and r∗∑ j=1",3.4. Theoretical results,[0],[0]
‖αj‖2‖hj‖H ≤ Cσ(B1)B2d2 } .,3.4. Theoretical results,[0],[0]
"(18)
where ‖·‖H is the norm of the RKHS associated with the kernel.",3.4. Theoretical results,[0],[0]
"This new function class relaxes the class of CNNs in two ways: 1) the filters are relaxed to belong to the RKHS, and 2) the `2-norm bounds on the weight vectors are replaced by a single constraint on ‖αj‖2 and ‖hj‖H. We prove the following property for the predictor f̂ccnn: it must be an empirical risk minimizer ofFccnn.",3.4. Theoretical results,[0],[0]
"This property holds even though equation (18) defines a non-parametric function class Fccnn, while Algorithm 1 optimizes f̂ccnn in a parametric function class.
",3.4. Theoretical results,[0],[0]
"Second, we characterize the Rademacher complexity of this new function class Fccnn, proving an upper bound for it based on the matrix concentration theory.",3.4. Theoretical results,[0],[0]
"Combining this bound with the classical Rademacher complexity theory (Bartlett & Mendelson, 2003), we conclude that the generalization loss of f̂ccnn converges to the least possible generalization error of Fccnn.",3.4. Theoretical results,[0],[0]
"The latter loss is bounded by the generalization loss of CNNs (because Fcnn ⊆ Fccnn), which establishes the theorem.",3.4. Theoretical results,[0],[0]
"See the full version of this paper (Zhang et al., 2016b) for a rigorous proof of Theorem 1.
",3.4. Theoretical results,[0],[0]
Remark on activation functions.,3.4. Theoretical results,[0],[0]
"It is worth noting that the quantity Cσ(B1) depends on the activation function σ, and more precisely, depends on the convergence rate of the polynomial expansion of σ.",3.4. Theoretical results,[0],[0]
"Appendix A shows that if σ is a polynomial function of degree `, then Cσ(B1) = O(B`1).",3.4. Theoretical results,[0],[0]
"If σ is the sinusoid function, the erf function or the smoothed hinge loss, then the quantity Cσ(B1) will be exponential in B1.",3.4. Theoretical results,[0],[0]
"From an algorithmic perspective, we don’t need to know the activation function for executing Algorithm 1.",3.4. Theoretical results,[0],[0]
"From a theoretical perspective, however, the choice of σ is relevant from the point of Theorem 1 to compare f̂ccnn with the best CNN, whose representation power is characterized by the choice of σ.",3.4. Theoretical results,[0],[0]
"Therefore, if a CNN with a low-degree polynomial σ performs well on a given task, then CCNN also enjoys correspondingly strong generalization.",3.4. Theoretical results,[0],[0]
"Empirically, this is actually borne out: in Section 5, we show that the quadratic activation function performs almost as well as the ReLU function for digit classification.
",3.4. Theoretical results,[0],[0]
Remark on parameter sharing.,3.4. Theoretical results,[0],[0]
"In order to demonstrate the importance of parameter sharing, consider a CNN without parameter sharing, so that we have filter weights wj,p for each filter index j and patch index p.",3.4. Theoretical results,[0],[0]
"With this change,
the new CNN output (2) is
f(x) = r∑ j=1 P∑ p=1 αj,pσ(w > j,pzp(x)),
where αj,p ∈ R and wj,p ∈ Rd1 .",3.4. Theoretical results,[0],[0]
Note that the hidden layer of this new network has P times more parameters than that of the convolutional neural network with parameter sharing.,3.4. Theoretical results,[0],[0]
These networks without parameter sharing can be learned by the recursive kernel method proposed by Zhang et al. (2016a).,3.4. Theoretical results,[0],[0]
Their paper shows that under the norm constraints ‖wj‖2 ≤,3.4. Theoretical results,[0],[0]
"B′1 and∑r j=1 ∑P p=1 |αj,p| ≤ B′2, the excess risk of the recur-
sive kernel method is at most O(LCσ(B′1)B′2 √ Kmax/n), where Kmax = maxz:‖z‖2≤1K(z, z) is the maximal value of the kernel function.",3.4. Theoretical results,[0],[0]
"Plugging in the norm constraints of the function class Fcnn, we have B′1 = B1 and B′2 = B2r √ P .",3.4. Theoretical results,[0],[0]
"Thus, the expected risk of the estimated f̂ is bounded by:
EX,Y [L(f̂(X);Y )]",3.4. Theoretical results,[0],[0]
"≤ inf f∈Fcnn EX,Y [L(f(X);Y )]
+ c",3.4. Theoretical results,[0],[0]
"LCσ(B1)B2r √ PKmax√
n .",3.4. Theoretical results,[0],[0]
"(19)
Comparing this bound to Theorem 1, we see that (apart from the logarithmic terms) they differ in the multiplicative factors of √ P Kmax versus √ E[‖K(X)‖2].",3.4. Theoretical results,[0],[0]
"Since the matrix K(X) is P -dimensional, we have
‖K(X)‖2 ≤ max p∈[P ] ∑ q∈[P ] |K(zp(X), zq(X))| ≤ P Kmax.
",3.4. Theoretical results,[0],[0]
"This demonstrates that √ P Kmax is always greater than√
E[‖K(X)‖2].",3.4. Theoretical results,[0],[0]
"In general, the first term can be up to factor of √ P times greater, which implies that the sample complexity of the recursive kernel method is up to P times greater than that of the CCNN.",3.4. Theoretical results,[0],[0]
This difference is intuitive given that the recursive kernel method learns a model with P times more parameters.,3.4. Theoretical results,[0],[0]
"Although comparing the upper bounds doesn’t rigorously show that one method is better than the other, it gives intuition for understanding the importance of parameter sharing.",3.4. Theoretical results,[0],[0]
"In this section, we describe a heuristic method for learning CNNs with more layers.",4. Learning multi-layer CCNNs,[0],[0]
The idea is to estimate the parameters of the convolutional layers incrementally from bottom to top.,4. Learning multi-layer CCNNs,[0],[0]
"Before presenting the multi-layer algorithm, we present two extensions, average pooling and multi-channel inputs.
",4. Learning multi-layer CCNNs,[0],[0]
Average pooling.,4. Learning multi-layer CCNNs,[0],[0]
Average pooling is a technique to reduce the output dimension of the convolutional layer from dimensions P × r to dimensions P ′,4. Learning multi-layer CCNNs,[0],[0]
× r with P ′,4. Learning multi-layer CCNNs,[0],[0]
< P .,4. Learning multi-layer CCNNs,[0],[0]
"For the CCNN model, if we apply average pooling after
Algorithm 2 Learning multi-layer CCNNs Input:Data {(xi, yi)}ni=1, kernel function K, number of layers m, regularization parameters R1, . . .",4. Learning multi-layer CCNNs,[0],[0]
", Rm, number of filters r1, . . .",4. Learning multi-layer CCNNs,[0],[0]
", rm.",4. Learning multi-layer CCNNs,[0],[0]
Define H1(x) = x.,4. Learning multi-layer CCNNs,[0],[0]
"For each layer s = 2, . .",4. Learning multi-layer CCNNs,[0],[0]
.,4. Learning multi-layer CCNNs,[0],[0]
",m: •",4. Learning multi-layer CCNNs,[0],[0]
"Train a two-layer network by Algorithm 1, taking {(Hs−1(xi), yi)}ni=1 as training examples and Rs, rs as parameters.",4. Learning multi-layer CCNNs,[0],[0]
Let Hs be the output of the convolutional layer and f̂s be the predictor.,4. Learning multi-layer CCNNs,[0],[0]
"Output: Predictor f̂m and the top layer output Hm.
the convolutional layer, then the k-th output of the CCNN model becomes tr(GZ(x)Ak) where G ∈ RP
′×P is the pooling matrix.",4. Learning multi-layer CCNNs,[0],[0]
"Thus, performing a pooling operation requires only replacing every matrix Z(xi) in problem (12) by the pooled matrix GZ(xi).",4. Learning multi-layer CCNNs,[0],[0]
"Note that the linearity of the CCNN allows us to effectively pool before convolution, even though for the CNN, pooling must be done after applying the nonlinear filters.",4. Learning multi-layer CCNNs,[0],[0]
"The resulting ERM problem is still convex, and the number of parameters have been reduced by P/P ′-fold.
",4. Learning multi-layer CCNNs,[0],[0]
Processing multi-channel inputs.,4. Learning multi-layer CCNNs,[0],[0]
"If our input has C channels (corresponding to RGB colors, for example), then the input becomes a matrix x ∈ RC×d0 .",4. Learning multi-layer CCNNs,[0],[0]
"The c-th row of matrix x, denoted by x[c] ∈ Rd0 , is a vector representing the c-th channel.",4. Learning multi-layer CCNNs,[0],[0]
"We define the multi-channel patch vector as a concatenation of patch vectors for each channel:
zp(x) := (zp(x[1]), . . .",4. Learning multi-layer CCNNs,[0],[0]
", zp(x[C])) ∈ RCd1 .",4. Learning multi-layer CCNNs,[0],[0]
Then we construct the feature matrix Z(x) using the concatenated patch vectors {zp(x)}Pp=1.,4. Learning multi-layer CCNNs,[0],[0]
"From here, everything else of Algorithm 1 remains the same.",4. Learning multi-layer CCNNs,[0],[0]
"We note that this approach learns a convex relaxation of filters taking the form σ( ∑C c=1〈wc, zp(x[c])〉), parametrized by the vectors {wc}Cc=1.
Multi-layer CCNN.",4. Learning multi-layer CCNNs,[0],[0]
"Given these extensions, we are ready to present the algorithm for learning multi-layer CCNNs, summarized in Algorithm 2.",4. Learning multi-layer CCNNs,[0],[0]
"For each layer s, we call Algorithm 1 using the output of previous convolutional layers as input—note that this consists of r channels (one from each previous filter); thus we must use the multi-channel extension.",4. Learning multi-layer CCNNs,[0],[0]
"Algorithm 2 outputs a new convolutional layer along with a prediction function, which is kept only at the last layer.",4. Learning multi-layer CCNNs,[0],[0]
We optionally use averaging pooling after each successive layer.,4. Learning multi-layer CCNNs,[0],[0]
to reduce the output dimension of the convolutional layers.,4. Learning multi-layer CCNNs,[0],[0]
"In this section, we compare the CCNN approach with other methods on the MNIST dataset and more challenging variations (VariationsMNIST), including adding white noise (rand), random rotation (rot), random image back-
ground (img) or combining the last two (img+rot).",5. Experiments,[0],[0]
"For all datasets, we use 10,000 images for training, 2,000 images for validation and 50,000 images for testing.",5. Experiments,[0],[0]
"This 10k/2k/50k partitioning is standard for MNIST variations (VariationsMNIST).
",5. Experiments,[0],[0]
"For the CCNN method and the baseline CNN method, we train two-layer and three-layer models respectively.",5. Experiments,[0],[0]
"The models with k convolutional layers are denoted by CCNNk and CNN-k. Each convolutional layer is constructed on 5 × 5 patches with unit stride, followed by 2 × 2 average pooling.",5. Experiments,[0],[0]
"The first and the second convolutional layers contains 16 and 32 filters, respectively.",5. Experiments,[0],[0]
The loss function is chosen as the 10-class logistic loss.,5. Experiments,[0],[0]
We use Gaussian kernel for the CCNN.,5. Experiments,[0],[0]
"The feature matrix Z(x) is constructed via random feature approximation (Rahimi & Recht, 2007) with dimension m = 500 for the first convolutional layer and m = 1000 for the second.",5. Experiments,[0],[0]
"Before training each CCNN layer, we preprocess the input vectors zp(xi) using local contrast normalization and ZCA whitening (Coates et al., 2010).",5. Experiments,[0],[0]
The convex optimization problem is solved by projected SGD with mini-batches of size 50.,5. Experiments,[0],[0]
"Code and reproducible experiments are available on the CodaLab platform4.
",5. Experiments,[0],[0]
"As a baseline approach, the CNN models are activated by the ReLU function σ(t) = max{0, t} or the quadratic function σ(t) = t2.",5. Experiments,[0],[0]
We train them using mini-batch SGD.,5. Experiments,[0],[0]
"The input images are preprocessed by global contrast normalization and ZCA whitening (Srivastava et al., 2014).",5. Experiments,[0],[0]
We compare our method against several alternative baselines.,5. Experiments,[0],[0]
The CCNN-1 model is compared against an SVM with the Gaussian RBF kernel (SVMrbf ) and a fully connected neural network with one hidden layer (NN1).,5. Experiments,[0],[0]
"The CCNN-2 model is compared against methods that report the state-of-the-art results on these datasets, including the translation-invariant RBM model (TIRBM) (Sohn & Lee, 2012), the stacked denoising auto-encoder with
4http://worksheets.codalab.org/ worksheets/0x1468d91a878044fba86a5446f52aacde/
three hidden layers (SDAE-3) (Vincent et al., 2010), the ScatNet-2 model (Bruna & Mallat, 2013) and the PCANet2 model (Chan et al., 2015).
",5. Experiments,[0],[0]
Table 1 shows the classification errors on the test set.,5. Experiments,[0],[0]
The models are grouped with respect to the number of layers that they contain.,5. Experiments,[0],[0]
"For models with one convolutional layer, the errors of CNN-1 are significantly lower than that of NN-1, highlighting the benefits of local filters and parameter sharing.",5. Experiments,[0],[0]
The CCNN-1 model outperforms CNN-1 on all datasets.,5. Experiments,[0],[0]
"For models with two or more hidden layers, the CCNN-2 model outperforms CNN-2 on all datasets, and is competitive against the state-of-the-art.",5. Experiments,[0],[0]
"In particular, it achieves the best accuracy on the rand, img and img+rot dataset, and is comparable to the state-of-the-art on the remaining two datasets.",5. Experiments,[0],[0]
"Further adding a third convolutional layer doesn’t notibly improve the performance on these datasets.
",5. Experiments,[0],[0]
"In Section 3.4, we showed that if the activation function σ is a polynomial function, then the CCNN (which does not depend on σ) requires lower sample complexity to match the performance of the best possible CNN using σ.",5. Experiments,[0],[0]
"More precisely, if σ is a degree-` polynomial, then Cσ(B) in the upper bound will be controlled by O(B`).",5. Experiments,[0],[0]
This motivates us to study the performance of low-degree polynomial activations.,5. Experiments,[0],[0]
"Table 1 shows that the CNN-2 model with a quadratic activation function achieves error rates comparable to that with a ReLU activation: CNN-2 (Quad) outperforms CNN2 (ReLU) on the basic and rand datasets, and is only slightly worse on the rot and img dataset.",5. Experiments,[0],[0]
"Since the performance of CCNN matches that of the best possible CNN, the good performance of the quadratic activation in part explains why the CCNN is also good.
",5. Experiments,[0],[0]
Acknowledgements.,5. Experiments,[0],[0]
MJW and YZ were partially supported by the Office of Naval Research Grant DOD ONRN00014 and the NSF Grant NSF-DMS-1612948.,5. Experiments,[0],[0]
PL and YZ were partially supported by the Microsoft Faculty Fellowship.,5. Experiments,[0],[0]
"We describe the class of convexified convolutional neural networks (CCNNs), which capture the parameter sharing of convolutional neural networks in a convex manner.",abstractText,[0],[0]
"By representing the nonlinear convolutional filters as vectors in a reproducing kernel Hilbert space, the CNN parameters can be represented in terms of a lowrank matrix, and the rank constraint can be relaxed so as to obtain a convex optimization problem.",abstractText,[0],[0]
"For learning two-layer convolutional neural networks, we prove that the generalization error obtained by a convexified CNN converges to that of the best possible CNN.",abstractText,[0],[0]
"For learning deeper networks, we train CCNNs in a layerwise manner.",abstractText,[0],[0]
"Empirically, we find that CCNNs achieve competitive or better performance than CNNs trained by backpropagation, SVMs, fully-connected neural networks, stacked denoising auto-encoders, and other baseline methods.",abstractText,[0],[0]
Convexified Convolutional Neural Networks,title,[0],[0]
"In machine learning and social network problems, information is often encoded in matrix form.",1. Introduction,[0],[0]
User profiles in social networks can be embedded into feature matrices; item profiles in recommendation systems can also be modeled as matrices.,1. Introduction,[0],[0]
"Many medical imaging modalities, such as MRI and CT, also represent data as a stack of images.",1. Introduction,[0],[0]
"These matrices have underlying connections that can come from spatial or temporal proximity, or observed similarities between the items being described, etc.",1. Introduction,[0],[0]
"A weighted graph
*Equal contribution 1Department of Mathematics, Stanford University, California, USA 2Department of Electrical Engineering, Stanford University, California, USA 3Department of Statistics, Stanford University, California, USA.",1. Introduction,[0],[0]
"Correspondence to: Qingyun Sun <qysun@stanford.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
can be built to represent the connections between matrices.",1. Introduction,[0],[0]
Therefore we propose matrix networks as a general model for data representation.,1. Introduction,[0],[0]
"A matrix network is defined by a weighted graph whose nodes are matrices.
",1. Introduction,[0],[0]
"Due to the limitations of data acquisition processes, sometimes we can only observe a subset of entries from each data matrix.",1. Introduction,[0],[0]
The fraction of entries we observe may vary from matrix to matrix.,1. Introduction,[0],[0]
"In many real problems, a subset of matrices can be completely unobserved, leaving no information for ordinary matrix completion methods to recover the missing matrices.",1. Introduction,[0],[0]
"To our knowledge, we are the first to examine this novel sampling scheme.
",1. Introduction,[0],[0]
"As an example, in the following MRI image sequence (figure 1(a)), we sample each frame of the MRI images with i.i.d.",1. Introduction,[0],[0]
"Bernoulli distribution p = 0.2, and 2 out of 88 frames are completely unobserved, shown in figure 1(b).",1. Introduction,[0],[0]
"If we perform matrix completion by nuclear norm minimization on
individual frames, we are not able to recover the completely unobserved matrices (figure 1(c)).",1. Introduction,[0],[0]
"When we build a network on the image frames, in this case, an one-dimensional chain representing the sequence, and assume that the matrices following graph Fourier transform are low-rank, we are able to recover the missing frames, as shown in figure 1(d).
",1. Introduction,[0],[0]
"The ability to recover all matrices from partial observations, especially inferring matrices that are totally unobserved, is crucial to many applications such as the cold start problem in networks.",1. Introduction,[0],[0]
"Illustrated in figure 2, new items or users in a network, which does not have much information available, need to aggregate information from the network to have an initial estimate of their feature matrices, in order to support inference and decisions.
",1. Introduction,[0],[0]
"Since we model the matrices as nodes on a graph, information from other matrices makes it possible to recover the missing ones.",1. Introduction,[0],[0]
"To use such information, we make the structural assumption that the matrix network is low-rank in spectral space, i.e., the matrix network is the graph convolution of two low-rank matrix networks.",1. Introduction,[0],[0]
"In the MRI example, we verify the spectral low-rank assumption in figure 3.",1. Introduction,[0],[0]
"For all the matrices after the graph Fourier transform, singular values quickly decrease to almost zero, demonstrating that they are in fact low-rank.
",1. Introduction,[0],[0]
"We make the following major contributions in this paper:
We define a novel modeling framework for collections of matrices using matrix network.",1. Introduction,[0],[0]
We propose a new method to complete a stack of related matrices.,1. Introduction,[0],[0]
We provide a mathematically solid exact recovery guarantee and numerically characterize the precise success regime.,1. Introduction,[0],[0]
We give a convolutional imputation algorithm to efficiently complete large scale matrix networks.,1. Introduction,[0],[0]
Low-rank matrix recovery is an important field of research.,2. Related work,[0],[0]
"(25; 26) proposed and (36; 48) improved the soft-impute
algorithm as an iterative method to solve large-scale matrix completion problems.",2. Related work,[0],[0]
The soft-impute algorithm inspired our imputation algorithm.,2. Related work,[0],[0]
There was also a long line of works building theoretical tools to analyze the recovery guarantee for matrix completion (9; 7; 10; 8; 15; 22; 32; 31).,2. Related work,[0],[0]
"Besides matrix completion, Gross analyzed the problem of efficiently recovering a low-rank matrix from a fraction of observations in any basis (24).",2. Related work,[0],[0]
"These works enlightened our exact recovery analysis.
",2. Related work,[0],[0]
Low-rank matrix recovery could be viewed as a “noncommutative analog” of compressed sensing by replacing the sparse vector with a low-rank matrix.,2. Related work,[0],[0]
"In compressed sensing, recovery of the sparse vector with a block diagonal sensing matrix was studied by the recent work (37), which demonstrated a phase transition that was different from the well-known phase transition for classical Gaussian/Fourier sensing matrices given by a series of works including (16; 3; 39).",2. Related work,[0],[0]
"In our low-rank matrices recovery problem, our novel sampling scheme also corresponded to a block diagonal operator.",2. Related work,[0],[0]
"We likewise demonstrated a new phase transition phenomenon.
",2. Related work,[0],[0]
Tensors could be considered as matrix networks when we ignored the network structure.,2. Related work,[0],[0]
Tensor completion coincides with the matrix network completion when the adjacent matrix is diagonal and the graph is just isolated points with no edge and the graph eigenbasis is the coordinate basis.,2. Related work,[0],[0]
Several works on tensor completion defined the nuclear norm for tensors as linear combinations of the nuclear norm of its unfoldings (21; 34; 19; 50; 49).,2. Related work,[0],[0]
"Besides the common CP and Tucker decompositions of tensors, the recent work (51; 30; 35) defined the t-product using convolution operators between tensor fibers, which was close to the convolution of matrix network using the discrete Fourier transform matrix, and they applied the method in indoor localization.",2. Related work,[0],[0]
"Departing from previous work, we considered a new sampling scheme in which some matrices were com-
pletely unobserved, and the undersampling ratio could be highly unbalanced for the other observed matrices.",2. Related work,[0],[0]
"This sampling scheme was not considered before, yet it is very natural under the matrix network model.",2. Related work,[0],[0]
"Under an incoherent eigenbasis, we can recover one completely unobserved measurement matrix because its information is well spread across all the spectral matrices with low-rank structure.
",2. Related work,[0],[0]
Networks is an important modelling framework for relations and interactions (29; 20; 52; 54; 53).,2. Related work,[0],[0]
Graph Laplacian based regularization has been used in semi-supervised learning in (18; 1; 2; 38) and in PCA (44) and low-rank matrix recovery (41; 23).,2. Related work,[0],[0]
"In (41; 23; 44) a regularization term is used for a single matrix, where both the row vectors and column vectors of the matrix are assumed to be connected with graphs.
",2. Related work,[0],[0]
"The notion of graph Fourier transform is rooted in spectral graph theory (11), it is the cornerstone of graph harmonic analysis(13; 12).",2. Related work,[0],[0]
"The coherence of graph Fourier transform is studied in (40; 46), and the examples of large graphs with low-coherence (non-local) eigenvectors include different classes of random graphs(14; 17; 47), and non-random regular graph(5).",2. Related work,[0],[0]
"Graph Fourier transform and graph convolution are widely used in data analysis and machine learning, for example, in (4; 55; 28; 43; 45).",2. Related work,[0],[0]
Recent advances in the field of convolutional neural networks by (6; 27) used this idea to extend neural networks from working on Euclidean grids to working on graphs.,2. Related work,[0],[0]
Matrix network.,3. Mathematical definitions,[0],[0]
"First, consider a weighted graphG with N nodes and an adjacent matrix W ∈ RN×N , where Wij is the weight on the edge between node i and j. In the following, we use J to represent the set of nodes on the graph.
",3. Mathematical definitions,[0],[0]
We define a matrix network by augmenting this weighted graph G with a matrix-valued function A on the node set.,3. Mathematical definitions,[0],[0]
The function A maps each node i in the graph to a matrix A(i) of sizem×n.,3. Mathematical definitions,[0],[0]
We define a L2 norm ‖·‖2 on the matrix network by the squared sum of all entries in all matrices of the network.,3. Mathematical definitions,[0],[0]
"And we define the sum of nuclear norm as ‖ · ‖∗,1, ‖A‖∗,1 = ∑N i=1",3. Mathematical definitions,[0],[0]
"‖A(i)‖∗.
Graph Fourier transform.",3. Mathematical definitions,[0],[0]
The graph Fourier transform is an analog of the Discrete Fourier Transform.,3. Mathematical definitions,[0],[0]
"For a weighted undirected graph G and its adjacent matrix W , the normalized graph Laplacian is defined as L = I − D−1/2WD−1/2, where D is a diagonal matrix with entries Dii = ∑ jWij .",3. Mathematical definitions,[0],[0]
"The graph Fourier transform matrix U is defined using UL = EU, where E is the diagonal matrix of the eigenvalues of L. Here, U is a unitary N ×N matrix, and the eigenvectors of L are the row vectors of U .",3. Mathematical definitions,[0],[0]
"We rank
the eigenvalues in descending order and identify the k-th eigenvalue with its index k for simplicity.
",3. Mathematical definitions,[0],[0]
"For a matrix network A, we define its graph Fourier transform Â = UA, as a stack of N matrices in the spectral space of the graph.",3. Mathematical definitions,[0],[0]
"Each matrix is a linear combination of matrices on the graph, weighted by the graph",3. Mathematical definitions,[0],[0]
Fourier basis.,3. Mathematical definitions,[0],[0]
"Â(k) = ∑ i∈J U(k, i)A(i).
",3. Mathematical definitions,[0],[0]
"Intuitively, if we view the matrix networkA as a set ofm×n scalar functions on the graph, the graph Fourier transform on matrix network is applying the graph Fourier transform on each function individually.",3. Mathematical definitions,[0],[0]
"Using tensor notation, the element of A is A(i, a, b), and the graph Fourier transform U can be represented by a big block diagonal matrix U ⊗ I where each block is U of sizeN2, and there are (mn)2 such blocks.
",3. Mathematical definitions,[0],[0]
We remark that the discrete Fourier transform is one special example of the graph Fourier transform.,3. Mathematical definitions,[0],[0]
"When the graph is a periodic grid, L is the discrete Laplacian matrix, and the eigenvectors are just the basis vectors for the discrete Fourier transform, which are sine and cosine functions with different frequencies.",3. Mathematical definitions,[0],[0]
We define the graph Fourier coherence as ν(U) =,3. Mathematical definitions,[0],[0]
"maxk,s |Uk,s|, following (40; 46).",3. Mathematical definitions,[0],[0]
We know that ν(U) ∈,3. Mathematical definitions,[0],[0]
"[ 1√
N , 1].",3. Mathematical definitions,[0],[0]
"When ν(U) is close to 1√ N , the eigenvec-
tors are non-local, for example, the discrete Fourier transform case, different classes of random graphs(14; 17; 47), and non-random regular graph(5).",3. Mathematical definitions,[0],[0]
"When µ(U) is close to 1, certain eigenvectors may be highly localized, especially when the graph has vertices whose degrees are significantly higher or lower than the average degree, say, in a star-like tree graph, or when the graph has many triangles, as discussed in (42).",3. Mathematical definitions,[0],[0]
"We will show in the following section that graphs with low coherence (close to 1√
N ) is preferred for
the imputation problem.
",3. Mathematical definitions,[0],[0]
Convolution of matrix networks.,3. Mathematical definitions,[0],[0]
We can extend the definition of convolution to matrix networks.,3. Mathematical definitions,[0],[0]
"For two matrix networks X,Y on the same graph, we define their convolution as
̂(X ?",3. Mathematical definitions,[0],[0]
Y )(k) = X̂(k)Ŷ,3. Mathematical definitions,[0],[0]
"(k).
",3. Mathematical definitions,[0],[0]
Then X̂ ?,3. Mathematical definitions,[0],[0]
Y is a stack of matrices where each matrix is the matrix multiplication of X̂(k) and Ŷ (k).,3. Mathematical definitions,[0],[0]
Convolution on a graph is defined as multiplication in the spectral space by generalizing the convolution theorem since it is not clear how to define convolution in the original space.,3. Mathematical definitions,[0],[0]
Imagine that we observe a few entries Ω(i) of each matrix A(i).,4. Completion problem with missing matrices,[0],[0]
We define the sampling rates as pi = |Ω(i)|/(mn).,4. Completion problem with missing matrices,[0],[0]
"The projection operator PΩ is defined to project the full matrix network to our partial observation by only retaining entries in the set Ω = ⋃ Ω(i).
",4. Completion problem with missing matrices,[0],[0]
The sampling rate can vary from matrix to matrix.,4. Completion problem with missing matrices,[0],[0]
"The main novel sampling scheme we include here is that a subset of matrices may be completely unobserved, namely pi = 0.",4. Completion problem with missing matrices,[0],[0]
This sampling scheme almost has not been discussed in depth in the literature.,4. Completion problem with missing matrices,[0],[0]
"The difficulty lies in the fact that if a matrix is fully unobserved, there is no information at all from itself for the recovery, therefore we must leverage the information from other observed matrices.
",4. Completion problem with missing matrices,[0],[0]
"To focus on understanding the essence of this difficulty, it is worth considering the extreme sampling scheme where each matrix is either fully observed or fully missing, which we call node undersampling.
",4. Completion problem with missing matrices,[0],[0]
"To recover missing entries, we need structural assumptions about the matrix network A.",4. Completion problem with missing matrices,[0],[0]
We propose the assumption that A can be well-approximated by the convolution X ?,4. Completion problem with missing matrices,[0],[0]
"Y of two matrix networks X,Y of size m × r and r × n, for some r much smaller than m and n.",4. Completion problem with missing matrices,[0],[0]
"We will show that under this assumption, accurate completion is possible even if a significant fraction of the matrices are completely unobserved.
",4. Completion problem with missing matrices,[0],[0]
We formulate the completion problem as follows.,4. Completion problem with missing matrices,[0],[0]
Let A0 = X0 ?,4. Completion problem with missing matrices,[0],[0]
"Y 0 be a matrix network of size m× n, as the ground truth, whereX0 and Y 0 are matrices of sizem×r and r×n on the same network.",4. Completion problem with missing matrices,[0],[0]
"After the graph Fourier transform, Â0(k) are rank r matrices.",4. Completion problem with missing matrices,[0],[0]
Our observations are AΩ = PΩ(A),4. Completion problem with missing matrices,[0],[0]
"= PΩ(A
0 + W ), each entry of W is sampled i.i.d from N(0, σ2/n).
",4. Completion problem with missing matrices,[0],[0]
We first consider the noiseless setting where σ = 0.,4. Completion problem with missing matrices,[0],[0]
"We can consider the following nuclear norm minimization problem, as a convex relaxation of rank minimization problem,
minimize M̂ ‖M̂‖∗,1, subject to AΩ = PΩ(U∗M̂)
",4. Completion problem with missing matrices,[0],[0]
"As an extension to include noise, we can consider the convex optimization problem in Lagrange form with regularization parameters λk,
Lλ(M̂)",4. Completion problem with missing matrices,[0],[0]
"= 1
2 ‖AΩ − PΩU∗M̂‖22 + N∑ k=1 λk‖M̂(k)‖∗.
We can also consider the bi-convex formulation, which is to minimize the following objective function,
Lλ(X,Y ) =",4. Completion problem with missing matrices,[0],[0]
‖AΩ,4. Completion problem with missing matrices,[0],[0]
− PΩ(X ?,4. Completion problem with missing matrices,[0],[0]
Y )‖22 + ∑N k=1 λk(‖X̂(k)‖22 + ‖Ŷ,4. Completion problem with missing matrices,[0],[0]
"(k)‖22).
",4. Completion problem with missing matrices,[0],[0]
"This formulation is non-convex but it is computationally efficient in large-scale applications.
",4. Completion problem with missing matrices,[0],[0]
"One remark is that when we choose the regularization parameter λk to be Ek, the eigenvalues of the graph Laplacian
L, and view X as a (nr)×N dimensional matrix,
N∑ k=1 Ek‖X̂(k)‖22 = Tr(X∗U∗EUX) = Tr(X∗LX),
then our regularizer is related to the graph Laplacian regularizer from (41; 23; 44).",4. Completion problem with missing matrices,[0],[0]
Let us now analyze the theoretical problem: what condition is needed for the non-uniform sampling Ω and for the rank of Â such that our algorithm is guaranteed to perform accurate recovery with high probability?,5. Exact recovery guarantee,[0],[0]
"We focus on the noiseless case, σ = 0, and for simplicity of results, we assume m = n.
We first prove that one sufficient condition is",5. Exact recovery guarantee,[0],[0]
that average sampling rate p = 1N ∑N i=1,5. Exact recovery guarantee,[0],[0]
pi = |Ω|/(Nn2) is greater than O( rn log 2(nN)).,5. Exact recovery guarantee,[0],[0]
"It is worth pointing out that the condition is only about the average sampling rate, therefore it includes the interesting case that a subset of matrices is completely unobserved.
",5. Exact recovery guarantee,[0],[0]
"Analysis on exact recovery guarantee The matrix incoherence condition is a standard assumption for low-rank matrix recovery problems.
",5. Exact recovery guarantee,[0],[0]
Let the SVD of Â(k) be Â(k) = V1(k)E(k)V ∗2 (k).,5. Exact recovery guarantee,[0],[0]
"We define P1 and P2 as the direct sum of the projection matrix, P1(k) = V1(k)V1(k)∗, P2(k) =",5. Exact recovery guarantee,[0],[0]
V2(k)V2(k)∗.,5. Exact recovery guarantee,[0],[0]
"We define the subspace T as the direct sum of the subspaces T (k), where T (k) is spanned by the column vectors of V1(k) and V2(k).",5. Exact recovery guarantee,[0],[0]
Then we define the projection onto T as PT (M̂) =,5. Exact recovery guarantee,[0],[0]
(V1V ∗1 M̂ + M̂V2V ∗ 2,5. Exact recovery guarantee,[0],[0]
− V1V ∗1 M̂V2V ∗2 ).,5. Exact recovery guarantee,[0],[0]
We define its complement as PT⊥ = I − PT .,5. Exact recovery guarantee,[0],[0]
We define sign(Â(k)),5. Exact recovery guarantee,[0],[0]
"= V1(k)V ∗ 2 (k) as the sign matrix of the singular values of Â.
In matrix completion, for a r−dimensional subspace of dimension n, spanned by V with an orthogonal projection PV , the coherence µ(V ) is defined as
µ(V ) =",5. Exact recovery guarantee,[0],[0]
"n
r max i ‖PV ei‖2.
",5. Exact recovery guarantee,[0],[0]
"Here we introduce an averaged coherence
Definition 5.1 For the graph Fourier transform U∗, let the column vector of U∗ be uk.",5. Exact recovery guarantee,[0],[0]
"We now define the incoherence condition with coherence µ for the stack of spectral subspaces V1(k), V2(k) as
max{ ∑N k=1 ‖uk‖2∞µ(V1(k)), ∑N k=1 ‖uk‖2∞µ(V2(k))} = µ.
The coherence of graph Fourier transform U∗ is defined as
ν(U∗) =",5. Exact recovery guarantee,[0],[0]
maxk ‖uk‖∞.,5. Exact recovery guarantee,[0],[0]
"We remark that
µ ≤ ν(U∗)2 max{ ∑N k=1 µ(V1(k)),",5. Exact recovery guarantee,[0],[0]
"∑N k=1 µ(V2(k))}
≤",5. Exact recovery guarantee,[0],[0]
"ν(U∗)2N maxNk=1 max{µ(V1(k)), µ(V2(k))}
In the following, we show that the sampling rate threshold is proportional to µ, which is upper bounded by ν(U∗)2N maxNk=1 max{µ(V1(k)), µ(V2(k))}.",5. Exact recovery guarantee,[0],[0]
"This upper bound suggests that for the imputation would prefer low coherence graph such that ν(U∗) is close to 1√
N .
",5. Exact recovery guarantee,[0],[0]
Theorem 1,5. Exact recovery guarantee,[0],[0]
"We assume that A is a matrix network on a graph G, and its graph Fourier transform Â(k) are a sequence of matrices, each of them is at most rank r, and Â satisfy the incoherence condition with coherence µ.",5. Exact recovery guarantee,[0],[0]
"And we observe a matrix network AΩ on the graph G, for a subset of node in Ω random sampled from the network, node i on the network is sampled with probability pi, we define the average sampling rate p = 1N ∑N i=1",5. Exact recovery guarantee,[0],[0]
"pi = |Ω|/(Nn2), and defineR = 1pPΩU ∗.
Then we prove that for any sampling probability distribution {pi}, as long as the average sampling rate",5. Exact recovery guarantee,[0],[0]
"p > Cµ rn log
2(Nn) for some constants C, the solution to the optimization problem
minimize M̂ ‖M̂‖∗,1, subject to AΩ = RM̂
is unique and is exactly Â with probability 1",5. Exact recovery guarantee,[0],[0]
"− (Nn)−γ ,where γ = log(Nn)16 .
",5. Exact recovery guarantee,[0],[0]
Proof sketch The proof of this theorem is given in the supplementary material.,5. Exact recovery guarantee,[0],[0]
"We sketch the steps of the proof here.
",5. Exact recovery guarantee,[0],[0]
"• We will prove that for any nonzero M̂ 6= Â, we define ∆ = M̂",5. Exact recovery guarantee,[0],[0]
"− Â, then we want to show either R∆ 6= 0, or ‖Â+ ∆‖∗,1 > ‖Â‖∗,1.",5. Exact recovery guarantee,[0],[0]
"We define the inner product: 〈M̂1, M̂2〉 = ∑ k〈M̂1(k), M̂2(k)〉, then
‖Â‖∗,1 = 〈sign(Â), Â〉.",5. Exact recovery guarantee,[0],[0]
We define a decomposition ∆ = PT∆ +,5. Exact recovery guarantee,[0],[0]
PT⊥∆ ∆ = ∆T + ∆ ⊥ T .,5. Exact recovery guarantee,[0],[0]
"For R∆ = 0, we show that
‖Â+ ∆‖∗,1",5. Exact recovery guarantee,[0],[0]
"≥ ‖Â‖∗,1 +",5. Exact recovery guarantee,[0],[0]
"〈sign(Â) + sign(∆⊥T ),∆〉.
",5. Exact recovery guarantee,[0],[0]
"• Now we want to estimate
s∆ ∆",5. Exact recovery guarantee,[0],[0]
"= 〈sign(Â) + sign(∆⊥T ),∆〉.
",5. Exact recovery guarantee,[0],[0]
"Since R∆ = 0, ∆ ∈ range(R)⊥. We want to construct a dual certificate K ∈ range(R), such that for k = 3 + 12 log2(r) + log2(n) + log2(N), with probability 1− (Nn)−γ ,
‖PT (K)− sign(Â)‖2 ≤ ( 12 )",5. Exact recovery guarantee,[0],[0]
k,5. Exact recovery guarantee,[0],[0]
"√ r,
‖PT⊥(K)‖ ≤ 12 .
",5. Exact recovery guarantee,[0],[0]
•,5. Exact recovery guarantee,[0],[0]
"Given the existence of the dual certificate, we have
s∆ = 〈sign(Â) + sign(∆⊥T )",5. Exact recovery guarantee,[0],[0]
"−K,∆〉
We can break down s∆ as
〈sign(∆⊥T )−PT⊥(K),∆⊥T 〉+〈sign(Â)−PT (K),∆T 〉
then with probability 1− (Nn)−γ , we get
s∆ ≥ ‖∆⊥T ‖∗,1",5. Exact recovery guarantee,[0],[0]
"− 1
2 ‖∆⊥T ‖2 − (
1 2 )k",5. Exact recovery guarantee,[0],[0]
√ r‖∆T,5. Exact recovery guarantee,[0],[0]
"‖2.
• We can show that for all ∆ ∈ range(R)⊥, with probability 1− (Nn)−γ ,
‖∆T",5. Exact recovery guarantee,[0],[0]
"‖2 < 2nN‖∆⊥T ‖2.
",5. Exact recovery guarantee,[0],[0]
"Using this fact,
s∆ ≥ 1
2 ‖∆⊥T ‖2 − (
1 2 )k",5. Exact recovery guarantee,[0],[0]
"√ r2nN‖∆⊥T ‖ ≥ 1 4 ‖∆⊥T ‖2
Therfore, when M̂ is a minimizer, we must have ∆⊥T = 0, otherwise ‖Â + ∆‖∗,1 < ‖Â‖∗,1.",5. Exact recovery guarantee,[0],[0]
"Since ‖∆T ‖2 is bounded by ‖∆⊥T ‖2, we also have ∆T = 0, then ∆ = 0.",5. Exact recovery guarantee,[0],[0]
"Therefore, M̂ is the unique mininizer, and M̂ =",5. Exact recovery guarantee,[0],[0]
"Â. This ends the proof.
",5. Exact recovery guarantee,[0],[0]
• Now we add remarks for some of the important techinical steps.,5. Exact recovery guarantee,[0],[0]
The propositions with high probability guarantee rely on a concentration result.,5. Exact recovery guarantee,[0],[0]
"Since E(PTRPT ) = PT , we control the probability of deviation P[‖PT − PTRPT ‖ > t] via operatorBernstein inequality( see theorem 6 of (24)), use the condition p = Cµ rn log
2(Nn), let t = 1/2, then with probability 1 − (nN)−γ , where γ = log(Nn)16 , ‖PT − PTRPT ‖ < 1/2.
",5. Exact recovery guarantee,[0],[0]
"• We construct a dual certificate via a method called ""golfing"", this technique was invented in (24).",5. Exact recovery guarantee,[0],[0]
We construct the dual certificate K by the following construction: We decompose Ω as the union of k subset,5. Exact recovery guarantee,[0],[0]
"Ωt, where each entry is sampled independently so that E(|Ωt| = pt = 1 − (1 − p)1/k, and define Rt = 1ptPΩtU
∗. Define H0 = sign(Â),Kt =∑t j=1RjHj−1, Ht = sign(Â) − PTKt.",5. Exact recovery guarantee,[0],[0]
Then the dual certificate is defined as K = Kk.,5. Exact recovery guarantee,[0],[0]
"Using the operator-Bernstein concentration inequality, we can verify the two conditions:
The first condition: ‖PT (K) − sign(Â)‖2 = ‖Hk‖ ≤",5. Exact recovery guarantee,[0],[0]
‖PT − PTRPT ‖‖Ht−1‖2 ≤ 12‖Ht−1‖2 ≤,5. Exact recovery guarantee,[0],[0]
( 12 ),5. Exact recovery guarantee,[0],[0]
k‖ sign(Â)‖ ≤ ( 12 ),5. Exact recovery guarantee,[0],[0]
k √ r.,5. Exact recovery guarantee,[0],[0]
"The second condition, we can apply operatorBernstein inequality again for a sequence of tj = 1/(4 √ r), so that ‖PT⊥RjHj−1‖ ≤",5. Exact recovery guarantee,[0],[0]
"ti‖Hj−1‖2,
and since ‖Hj‖2 ≤",5. Exact recovery guarantee,[0],[0]
"√ r2−j , then ‖PT⊥(K)‖",5. Exact recovery guarantee,[0],[0]
"≤∑k
j=1 ti‖Hj−1‖2 ≤",5. Exact recovery guarantee,[0],[0]
1 4 ∑k j=1 2 −(j−1) < 1/2.,5. Exact recovery guarantee,[0],[0]
"Now we propose a convolutional imputation algorithm that effectively finds the minimizer of the optimization problem for a sequence of regularization parameters.
",6. Convolutional imputation algorithm,[0],[0]
Iterative imputation algorithm.,6. Convolutional imputation algorithm,[0],[0]
"The vanilla version of our imputation algorithm iteratively performs imputation of Aimpute = PΩ(A) + P⊥Ω (A
est) and singular value softthreshold of Âimpute to solve the nuclear norm regularization problem.",6. Convolutional imputation algorithm,[0],[0]
"In the following, we denote singular value soft-threshold as Sλ(Â) = V1(Σ",6. Convolutional imputation algorithm,[0],[0]
−,6. Convolutional imputation algorithm,[0],[0]
"λI)+V ∗2 ,where (·)+ is the projection operator on the semi-definite cone, and Â = V1ΣV ∗ 2 is the singular value decomposition.
",6. Convolutional imputation algorithm,[0],[0]
"Iterative Imputation: input PΩ(A).
",6. Convolutional imputation algorithm,[0],[0]
"Initialization Aest0 = 0, t = 0.",6. Convolutional imputation algorithm,[0],[0]
for λ1 > λ2 > . . .,6. Convolutional imputation algorithm,[0],[0]
>,6. Convolutional imputation algorithm,[0],[0]
"λC , where λj = (λjk), k = 1, . . .",6. Convolutional imputation algorithm,[0],[0]
", N do
repeat Aimpute = PΩ(A)",6. Convolutional imputation algorithm,[0],[0]
"+ P ⊥ Ω (A est t ).
",6. Convolutional imputation algorithm,[0],[0]
Âimpute = UAimpute.,6. Convolutional imputation algorithm,[0],[0]
Âestt+1(k) = Sλjk (Âimpute(k)).,6. Convolutional imputation algorithm,[0],[0]
Aestt+1,6. Convolutional imputation algorithm,[0],[0]
= U−1Âestt+1.,6. Convolutional imputation algorithm,[0],[0]
"t=t+1.
until ‖Aestt −Aestt−1‖2/‖Aestt−1‖2 < .",6. Convolutional imputation algorithm,[0],[0]
"Assign Aλj = Aestt .
end for output The sequence of solutions Aλ1 , . . .",6. Convolutional imputation algorithm,[0],[0]
", AλC .
",6. Convolutional imputation algorithm,[0],[0]
"In the vanilla imputation algorithm, computing the full SVD on each iteration is very expensive for large matrices.",6. Convolutional imputation algorithm,[0],[0]
"For efficiency, we can use alternating ridge regression to compute reduced-rank SVD instead.",6. Convolutional imputation algorithm,[0],[0]
"Due to the limited space, we omit the detailed algorithm description here.
",6. Convolutional imputation algorithm,[0],[0]
Regularization path.,6. Convolutional imputation algorithm,[0],[0]
The sequence of regularization parameters is chosen such that λ1k > λ 2 k > . . .,6. Convolutional imputation algorithm,[0],[0]
>,6. Convolutional imputation algorithm,[0],[0]
λ C k for each k.,6. Convolutional imputation algorithm,[0],[0]
The solution for each iteration with λs is a warm start for the next iteration with λs+1.,6. Convolutional imputation algorithm,[0],[0]
"Our recommended choice is to choose λ1k as the largest singular value for Â
impute(k), and decay λs at a constant speed λs+1 = cλs.
",6. Convolutional imputation algorithm,[0],[0]
Convergence.,6. Convolutional imputation algorithm,[0],[0]
"Our algorithm is a natural extension of softimpute (25), which is a special case of the proximal gradient algorithm for nuclear norm minimization, as demonstrated by (48), and the convergence of the algorithm is guaranteed.
",6. Convolutional imputation algorithm,[0],[0]
Here we show that the solution of our imputation algorithm converges asymptotically to a minimizer of the objective Lλ(M̂) in an elegant argument.,6. Convolutional imputation algorithm,[0],[0]
"We show that each step of our imputation algorithm is minimizing a surro-
gate Qλ(M̂ |M̂old) = ‖AΩ + P⊥Ω U−1M̂old − U−1M̂‖2 +∑N k=1 λk‖M̂(k)‖∗.
Theorem 2",6. Convolutional imputation algorithm,[0],[0]
"The imputation algorithm produces a sequence of iterates M̂ tλ as the minimizer of the successive optimization objective
M̂ t+1λ = argmin Qλ(M̂ |M̂ t λ).
",6. Convolutional imputation algorithm,[0],[0]
"The sequence of iterates that converges to the minimizer M̂∗ of Lλ(M̂).
",6. Convolutional imputation algorithm,[0],[0]
We put the proof of the convergence theorem in the appendix.,6. Convolutional imputation algorithm,[0],[0]
"The main idea of the proof is to show that
• Qλ decreases after every iteration.
",6. Convolutional imputation algorithm,[0],[0]
"• M̂ tλ is a Cauchy sequence.
",6. Convolutional imputation algorithm,[0],[0]
"• The limit point is a stationary point of Lλ
Computational complexity.",6. Convolutional imputation algorithm,[0],[0]
Now we analyze the computational complexity of the imputation algorithm.,6. Convolutional imputation algorithm,[0],[0]
The cost of the graph Fourier transform on matrix network is O(mnN2).,6. Convolutional imputation algorithm,[0],[0]
"When the graph is a periodic lattice, using fast Fourier transform(FFT), it is reduced to O(mnN logN).",6. Convolutional imputation algorithm,[0],[0]
"The cost of SVD is O(min(mn2,m2n)N) for computing singular value soft-threshold.",6. Convolutional imputation algorithm,[0],[0]
Replacing SVD with alternating ridge regression reduces the complexity to O(r2nN).,6. Convolutional imputation algorithm,[0],[0]
"Therefore, the cost of each iteration is the sum of the cost of both parts, and the total cost would be that times total iteration steps.",6. Convolutional imputation algorithm,[0],[0]
"Numerical verification of the exact recovery To focus on the essential difficulty of the problem, we study the noiseless, node sampling setting:",7. Experimental results,[0],[0]
"In each imputation experiment, we first generate a stack of low-rank matrices in the spectral space, Â(k) = X0(k)TY 0(k) for i.i.d Gaussian random matrix X0(k), Y 0(k) ∈",7. Experimental results,[0],[0]
Rr×n.,7. Experimental results,[0],[0]
We also generate a random graph G.,7. Experimental results,[0],[0]
Then we compute the matrix network A by the inverse graph Fourier transform and obtain our observation by node undersampling of A.,7. Experimental results,[0],[0]
Then we send the observed matrices and the graph G to the imputation algorithm to get the solution M̂ .,7. Experimental results,[0],[0]
We measure the relative mean square error (rMSE) ‖M̂,7. Experimental results,[0],[0]
"− Â‖/‖Â‖.
We set (n,N) =",7. Experimental results,[0],[0]
"(50, 100) for all our experiments, and vary the undersampling ratio p and rank r.",7. Experimental results,[0],[0]
"For each set of parameters (p, r), we repeat the experiment multiple times and compute the success rate of exact recovery.",7. Experimental results,[0],[0]
In figure 4 on the upper panel we show the rMSE when the graphs are one-dimensional chains of length N .,7. Experimental results,[0],[0]
"When r/n is large and p is small, the rMSE is approximately equal to the undersampling ratio p, which means the optimization
failed to recover the ground truth matrices.",7. Experimental results,[0],[0]
"On the opposite side, when r/n is small and p is large, the rMSE is very small, indicating we have successfully recovered the missing matrices.",7. Experimental results,[0],[0]
The transition between the two regions is very sharp.,7. Experimental results,[0],[0]
"We also show the success rate on the lower panel of figure 4, which demonstrates a phase transition.
",7. Experimental results,[0],[0]
Feature matrices on Facebook network We take the ego networks from the SNAP Facebook dataset (33).,7. Experimental results,[0],[0]
The combined network forms a connected graph with 4039 nodes and 88234 edges.,7. Experimental results,[0],[0]
All the edges have equal weights.,7. Experimental results,[0],[0]
"The feature matrices on each of the nodes were generated by randomly generating X(k), Y (k) ∈ C1×50 in the spectral domain, and doing the inverse graph Fourier transform to get A = U−1(X(k)Y (k)).",7. Experimental results,[0],[0]
"The observation is generated by sampling Nobs matrices at sampling rate p, and adding i.i.d.",7. Experimental results,[0],[0]
Gaussian noise with mean 0 and variance σ2/50 to all observed entries.,7. Experimental results,[0],[0]
"Here Nobs < N = 4039 and the other matrices are completely unobserved.
",7. Experimental results,[0],[0]
"We run our iterative imputation algorithm to recover A from this observation with varying parameters Nobs, p, and σ, and calculate the MSE between our estimation and the ground truth.",7. Experimental results,[0],[0]
The results are summarized in Table 1.,7. Experimental results,[0],[0]
"When there is no additive noise, we can recover all the matrices very well even with only 20% of entries observed across the matrix network.",7. Experimental results,[0],[0]
It works well both when doing node undersampling and more uniform undersampling.,7. Experimental results,[0],[0]
"When there is additive noise, the MSE between reconstruction and the ground truth will grow proportionally.
",7. Experimental results,[0],[0]
MRI completion We use a cardiac MRI scan dataset for the completion task.,7. Experimental results,[0],[0]
The stack of MRI images scans through a human torso.,7. Experimental results,[0],[0]
"The frames are corrupted, several frames are missing, and the other frames are sampled i.i.d.",7. Experimental results,[0],[0]
from a Bernoulli distribution with p = 0.2,7. Experimental results,[0],[0]
.,7. Experimental results,[0],[0]
Our completion result is demonstrated in figure 1 at first page as the motivating example.,7. Experimental results,[0],[0]
"In the 88 frames there are 2 frames missing, and we only sampled 20% of the rest of frames i.i.d. from a Bernoulli distribution with p = 0.2.",7. Experimental results,[0],[0]
We compare with the baseline method where we solve a tensor completion problem using nuclear norm minimization.,7. Experimental results,[0],[0]
Relative MSE for all frames are plotted in figure 5.,7. Experimental results,[0],[0]
"The baseline method failed at missed frames and significantly under-performed the convolutional imputation method.
",7. Experimental results,[0],[0]
SPECT completion We imputed a cardiac SPECT scan dataset.,7. Experimental results,[0],[0]
"The SPECT scan captures the periodic movement of a heart, and we have a temporal sequence at a fixed spatial slice.",7. Experimental results,[0],[0]
"The sequence has 36 frames, capturing 4 periods of heart beats.",7. Experimental results,[0],[0]
4 consecutive frames out of the 36 frames are missing and the other frames are sampled i.i.d.,7. Experimental results,[0],[0]
from a Bernoulli distribution with p = 0.2.,7. Experimental results,[0],[0]
We try to recover the whole image stack from the observations and compare our method with two baseline methods.,7. Experimental results,[0],[0]
The first baseline method assumes each individual frame is low-rank and minimizes the sum of nuclear norms.,7. Experimental results,[0],[0]
"The second baseline method adds the graph regularizer from (41; 23; 44) , in addition to the low-rank assumption on each frame.",7. Experimental results,[0],[0]
Minimizing the sum of nuclear norm fails to recover completely missing frames.,7. Experimental results,[0],[0]
"Our algorithm performs better than tensor completion with graph regularizer on the SPECT scan, since in spectral domain we can use the periodicity to help aggregate information, while using graph regularizer only propagates information between neighbors.",7. Experimental results,[0],[0]
"This is demon-
strated in figure 6.",7. Experimental results,[0],[0]
"The first row shows the ground truth, and the second row overlays the ground truth (in red channel) with the completion result using our convolutional imputation algorithm (in green channel).",7. Experimental results,[0],[0]
The third row overlays the ground truth with the completion result using tensor completion with graph regularizer.,7. Experimental results,[0],[0]
"The completion result with our algorithm matches the ground truth very well, while the completion result with tensor completion using graph
regularizer is biased towards the average of neighboring frames, showing red and green rings on the edges.",7. Experimental results,[0],[0]
A quantitative comparison on the SPECT scan completion is given in figure 7.,7. Experimental results,[0],[0]
Our imputation algorithm’s relative MSE between reconstruction and the ground truth is significantly smaller than the baselines’.,7. Experimental results,[0],[0]
"It is worth pointing out that our method’s recovery performance at the missing frames are comparable to that at the partially observed frames, while the first baseline completely fails at the missing frames and the second baseline performs significantly worse.",7. Experimental results,[0],[0]
"In practice, when you are given a tensor or a stack of matrices, there are two ways to formulate it into a matrix network.
",8. Discussion,[0],[0]
One is to use the knowledge of physical or geometrical relation to naturally determine the graph.,8. Discussion,[0],[0]
"The graph of the matrix network is given in the facebook network and the graph is naturally constructed as a 1-d equal-weighted chain in the MRI and SPECT datasets, based on the nature of the datasets.
",8. Discussion,[0],[0]
The other is to construct the graph using an explicit constructive methods.,8. Discussion,[0],[0]
Finding a graph with good graph Fourier transform relies on problem structure and domain knowledge.,8. Discussion,[0],[0]
"One suggested universal way is to construct a lattice or a d−regular graph, then assign the weight on each edge as some distance metric of two matrices, for example, the distance metric could be computed using Gaussian kernels.",8. Discussion,[0],[0]
We suggest that the coherence µ we defined before could be used as a criterion to measure how good the graph Fourier transform is.,8. Discussion,[0],[0]
"From the bound on µ by the coherence of the graph Fourier transform and the maximum coherence over all spectral matrices, we know that we want to search for graph with low coherence.",8. Discussion,[0],[0]
"This leads to interesting dictionary learning problem where we want to learn a unitary dictionary as the graph Fourier transform.
",8. Discussion,[0],[0]
"To conclude, treating a series of matrices with relations as a matrix network is a useful modeling framework since a matrix network has operations like the graph Fourier transform and convolution.",8. Discussion,[0],[0]
"This framework allows us to complete the matrices when some of them are completely unobserved, using the spectral low-rank structural assumption.",8. Discussion,[0],[0]
We provided an exact recovery guarantee and discovered a new phase transition phenomenon for the completion algorithm.,8. Discussion,[0],[0]
"A matrix network is a family of matrices, with relatedness modeled by a weighted graph.",abstractText,[0],[0]
We consider the task of completing a partially observed matrix network.,abstractText,[0],[0]
We assume a novel sampling scheme where a fraction of matrices might be completely unobserved.,abstractText,[0],[0]
How can we recover the entire matrix network from incomplete observations?,abstractText,[0],[0]
This mathematical problem arises in many applications including medical imaging and social networks.,abstractText,[0],[0]
"To recover the matrix network, we propose a structural assumption that the matrices have a graph Fourier transform which is low-rank.",abstractText,[0],[0]
We formulate a convex optimization problem and prove an exact recovery guarantee for the optimization problem.,abstractText,[0],[0]
"Furthermore, we numerically characterize the exact recovery regime for varying rank and sampling rate and discover a new phase transition phenomenon.",abstractText,[0],[0]
Then we give an iterative imputation algorithm to efficiently solve the optimization problem and complete large scale matrix networks.,abstractText,[0],[0]
We demonstrate the algorithm with a variety of applications such as MRI and Facebook user network.,abstractText,[0],[0]
Convolutional Imputation of Matrix Networks,title,[0],[0]
"Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1153–1162, Austin, Texas, November 1-5, 2016. c©2016 Association for Computational Linguistics",text,[0],[0]
Convolutional Neural Networks (CNNs) are the family of neural network models that feature a type of layer known as the convolutional layer.,1 Introduction,[0],[0]
"This layer can extract features by convolving a learnable filter (or kernel) along different positions of a vectorial input.
",1 Introduction,[0],[0]
"CNNs have been successfully applied in Computer Vision in many different tasks, including ob-
ject recognition, scene parsing, and action recognition (Gu et al., 2015), but they have received less attention in NLP.",1 Introduction,[0],[0]
They have been somewhat explored in static classification tasks where the model is provided with a full linguistic unit as input (e.g. a sentence) and classes are treated as independent of each other.,1 Introduction,[0],[0]
"Examples of this are sentence or document classification for tasks such as Sentiment Analysis or Topic Categorization (Kalchbrenner et al., 2014; Kim, 2014), sentence matching (Hu et al., 2014), and relation extraction (Nguyen and Grishman, 2015).",1 Introduction,[0],[0]
"However, their application to sequential prediction tasks, where the input is construed to be part of a sequence (for example, language modeling or POS tagging), has been rather limited (with exceptions, such as Collobert et al. (2011)).",1 Introduction,[0],[0]
"The main contribution of this paper is a systematic evaluation of CNNs in the context of a prominent sequential prediction task, namely, language modeling.
",1 Introduction,[0],[0]
"Statistical language models are a crucial component in many NLP applications, such as Automatic Speech Recognition, Machine Translation, and Information Retrieval.",1 Introduction,[0],[0]
"Here, we study the problem under the standard formulation of learning to predict the upcoming token given its previous context.",1 Introduction,[0],[0]
"One successful approach to this problem relies on counting the number of occurrences of n-grams while using smoothing and back-off techniques to estimate the probability of an upcoming word (Kneser and Ney, 1995).",1 Introduction,[0],[0]
"However, since each individual word is treated independently of the others, n-gram models fail to capture semantic relations between words.",1 Introduction,[0],[0]
"In contrast, neural network language models (Bengio et al., 2006) learn to predict the up-
1153
coming word given the previous context while embedding the vocabulary in a continuous space that can represent the similarity structure between words.",1 Introduction,[0],[0]
"Both feed-forward (Schwenk, 2007) and recurrent neural networks (Mikolov et al., 2010) have been shown to outperform n-gram models in various setups (Mikolov et al., 2010; Hai Son et al., 2011).",1 Introduction,[0],[0]
These two types of neural networks make different architectural decisions.,1 Introduction,[0],[0]
Recurrent networks take one token at a time together with a hidden “memory” vector as input and produce a prediction and an updated hidden vector for the next time step.,1 Introduction,[0],[0]
"In contrast, feed-forward language models take as input the last n tokens, where n is a fixed window size, and use them jointly to predict the upcoming word.
",1 Introduction,[0],[0]
In this paper we define and explore CNN-based language models and compare them with both feedforward and recurrent neural networks.,1 Introduction,[0],[0]
"Our results show a 11-26% perplexity reduction of the CNN with respect to the feed-forward language model, comparable or higher performance compared to similarly-sized recurrent models, and lower performance with respect to larger, state-of-the-art recurrent language models (LSTMs as trained in Zaremba et al. (2014)).
",1 Introduction,[0],[0]
"Our second contribution is an analysis of the kind of information learned by the CNN, showing that the network learns to extract a combination of grammatical, semantic, and topical information from tokens of all across the input window, even those that are the farthest from the target.",1 Introduction,[0],[0]
"Convolutional Neural Networks (CNNs) were originally designed to deal with hierarchical representation in Computer Vision (LeCun and Bengio, 1995).",2 Related Work,[0],[0]
"Deep convolutional networks have been successfully applied in image classification and understanding (Simonyan and Zisserman, 2014; He et al., 2015).",2 Related Work,[0],[0]
"In such systems the convolutional kernels learn to detect visual features at both local and more abstract levels.
",2 Related Work,[0],[0]
"In NLP, CNNs have been mainly applied to static classification tasks for discovering latent structures in text.",2 Related Work,[0],[0]
"Kim (2014) uses a CNN to tackle sentence classification, with competitive results.",2 Related Work,[0],[0]
"The same work also introduces kernels with varying window
sizes to learn complementary features at different aggregation levels.",2 Related Work,[0],[0]
"Kalchbrenner et al. (2014) propose a convolutional architecture for sentence representation that vertically stacks multiple convolution layers, each of which can learn independent convolution kernels.",2 Related Work,[0],[0]
"CNNs with similar structures have also been applied to other classification tasks, such as semantic matching (Hu et al., 2014), relation extraction (Nguyen and Grishman, 2015), and information retrieval (Shen et al., 2014).",2 Related Work,[0],[0]
"In contrast, Collobert et al. (2011) explore a CNN architecture to solve various sequential and non-sequential NLP tasks such as part-of-speech tagging, named entity recognition and also language modeling.",2 Related Work,[0],[0]
This is perhaps the work that is closest to ours in the existing literature.,2 Related Work,[0],[0]
"However, their model differs from ours in that it uses a max-pooling layer that picks the most activated feature across time, thus ignoring temporal information, whereas we explicitly avoid doing so.",2 Related Work,[0],[0]
"More importantly, the language models trained in that work are only evaluated through downstream tasks and through the quality of the learned word embeddings, but not on the sequence prediction task itself, as we do here.
",2 Related Work,[0],[0]
"Besides being applied to word-based sequences, the convolutional layers have also been used to model sequences at the character level.",2 Related Work,[0],[0]
Kim et al. (2015) propose a recurrent language model that replaces the word-indexed projection matrix with a convolution layer fed with the character sequence that constitutes each word to find morphological patterns.,2 Related Work,[0],[0]
"The main difference between that work and ours is that we consider words as the smallest linguistic unit, and thus apply the convolutional layer at the word level.
",2 Related Work,[0],[0]
"Statistical language modeling, the task we tackle, differs from most of the tasks where CNNs have been applied before in multiple ways.",2 Related Work,[0],[0]
"First, the input typically consists of incomplete sequences of words rather than complete sentences.",2 Related Work,[0],[0]
"Second, as a classification problem, it features an extremely large number of classes (the words in a large vocabulary).",2 Related Work,[0],[0]
"Finally, temporal information, which can be safely discarded in many settings with little impact in performance, is critical here: An n-gram appearing close to the predicted word may be more informative, or yield different information, than the same n-gram appearing several tokens earlier.",2 Related Work,[0],[0]
Our model is constructed by extending a feedforward language model (FFLM) with convolutional layers.,3 Models,[0],[0]
"In what follows, we first explain the implementation of the base FFLM and then describe the CNN model that we study.",3 Models,[0],[0]
"Our baseline feed-forward language model (FFLM) is almost identical to the original model proposed by Bengio et al. (2006), with only slight changes to push its performance as high as we can, producing a very strong baseline.",3.1 Baseline FFLM,[0],[0]
"In particular, we extend it with highway layers and use Dropout as regularization.",3.1 Baseline FFLM,[0],[0]
The model is illustrated in Figure 1 and works as follows.,3.1 Baseline FFLM,[0],[0]
"First, each word in the input n-gram is mapped to a low-dimensional vector (viz. embedding) though a shared lookup table.",3.1 Baseline FFLM,[0],[0]
"Next, these word vectors are concatenated and fed to a highway layer (Srivastava et al., 2015).",3.1 Baseline FFLM,[0],[0]
Highway layers improve the gradient flow of the network by computing as output a convex combination between its input (called the carry) and a traditional non-linear transformation of it (called the transform).,3.1 Baseline FFLM,[0],[0]
"As a result, if there is a neuron whose gradient cannot flow through the transform component (e.g., because the activation is zero), it can still receive the back-propagation update signal through the carry gate.",3.1 Baseline FFLM,[0],[0]
We empirically observed the usage of a single highway layer to significantly improve the performance of the model.,3.1 Baseline FFLM,[0],[0]
"Even though a systematic evaluation of this aspect is beyond the scope of the current paper, our empirical results demonstrate that the resulting model is a very competitive one (see Section 4).
",3.1 Baseline FFLM,[0],[0]
"Finally, a softmax layer computes the model prediction for the upcoming word.",3.1 Baseline FFLM,[0],[0]
"We use ReLU for all non-linear activations, and Dropout (Hinton et al., 2012) is applied between each hidden layer.",3.1 Baseline FFLM,[0],[0]
The proposed CNN network is produced by injecting a convolutional layer right after the words in the input are projected to their embeddings (Figure 2).,3.2 CNN and variants,[0],[0]
"Rather than being concatenated into a long vector, the embeddings xi ∈",3.2 CNN and variants,[0],[0]
Rk are concatenated transversally producing a matrix x1:n ∈,3.2 CNN and variants,[0],[0]
"Rn×k, where n is
the size of the input and k is the embedding size.",3.2 CNN and variants,[0],[0]
"This matrix is fed to a time-delayed layer, which convolves a sliding window of w input vectors centered on each word vector using a parameter matrix W ∈ Rw×k.",3.2 CNN and variants,[0],[0]
Convolution is performed by taking the dot-product between the kernel matrix W and each sub-matrix xi−w/2:i+w/2 resulting in a scalar value for each position i in input context.,3.2 CNN and variants,[0],[0]
This value represents how much the words encompassed by the window match the feature represented by the filter W .,3.2 CNN and variants,[0],[0]
A ReLU activation function is applied subsequently so negative activations are discarded.,3.2 CNN and variants,[0],[0]
"This operation is repeated multiple times using various kernel matrices W , learning different features independently.",3.2 CNN and variants,[0],[0]
"We tie the number of learned kernels to be the same as the embedding dimensionality k, such that the output of this stage will be another matrix of dimensions n ×",3.2 CNN and variants,[0],[0]
k containing the activations for each kernel at each time step.,3.2 CNN and variants,[0],[0]
"The number of kernels was tied to the embedding size for two reasons, one practical, namely, to limit the hyper parameter search, one methodological, namely, to keep the network structure identical to that of the baseline feed-forward model.
",3.2 CNN and variants,[0],[0]
"Next, we add a batch normalization stage immediately after the convolutional output, which facilitates learning by addressing the internal covariate
shift problem and regularizing the learned representations (Ioffe and Szegedy, 2015).
",3.2 CNN and variants,[0],[0]
"Finally, this feature matrix is directly fed into a fully connected layer that can project the extracted features into a lower-dimensional representation.",3.2 CNN and variants,[0],[0]
"This is different from previous work, where a max-over-time pooling operation was used to find the most activated feature in the time series.",3.2 CNN and variants,[0],[0]
"Our choice is motivated by the fact that the max pooling operator loses the specific position where the feature was detected, which is important for word prediction.
",3.2 CNN and variants,[0],[0]
"After this initial convolutional layer, the network proceeds identically to the FFNN by feeding the produced features into a highway layer, and then, to a softmax output.
",3.2 CNN and variants,[0],[0]
This is our basic CNN architecture.,3.2 CNN and variants,[0],[0]
"We also experiment with three expansions to the basic model, as follows.",3.2 CNN and variants,[0],[0]
"First, we generalize the CNN by extending the shallow linear kernels with deeper multilayer perceptrons, in what is called a MLP Convolution (MLPConv) structure (Lin et al., 2013).",3.2 CNN and variants,[0],[0]
"This allows the network to produce non-linear filters, and it has achieved state-of-the-art performance in object recognition while reducing the number of total layers compared to other mainstream networks.",3.2 CNN and variants,[0],[0]
"Concretely, we implement MLPConv networks by using another convolutional layer with a 1 × 1 kernel on top of the convolutional layer output.",3.2 CNN and variants,[0],[0]
This results in an architecture that is exactly equivalent to sliding a one-hidden-layer MLP over the input.,3.2 CNN and variants,[0],[0]
"Notably, we do not include the global pooling layer in the original Network-in-Network structure (Lin et al., 2013).
",3.2 CNN and variants,[0],[0]
"Second, we explore stacking convolutional layers on top of each other (Multi-layer CNN or MLCNN) to connect the local features into broader regional representations, as commonly done in computer vision.",3.2 CNN and variants,[0],[0]
"While this proved to be useful for sentence representation (Kalchbrenner et al., 2014), here we have found it to be rather harmful for language modeling, as shown in Section 4.",3.2 CNN and variants,[0],[0]
"It is important to note that, in ML-CNN experiments, we stack convolutions with the same kernel size and number of kernels on top of each other, which is to be distinguished from the MLPConv that refers to the deeper structure in each CNN layer mentioned above.
",3.2 CNN and variants,[0],[0]
"Finally, we consider combining features learned through different kernel sizes (COM), as depicted in
Figure 3.",3.2 CNN and variants,[0],[0]
"For example, we can have a combination of kernels that learn filters over 3-grams with others that learn over 5-grams.",3.2 CNN and variants,[0],[0]
"This is achieved simply by applying in parallel two or more sets of kernels to the input and concatenating their respective outputs (Kim, 2014).",3.2 CNN and variants,[0],[0]
"We evaluate our model on three English corpora of different sizes and genres, the first two of which have been used for language modeling evaluation before.",4 Experiments,[0],[0]
The Penn Treebank contains one million words of newspaper text with 10K words in the vocabulary.,4 Experiments,[0],[0]
"We reuse the preprocessing and training/test/validation division from Mikolov et
al. (2014).",4 Experiments,[0],[0]
"Europarl-NC is a 64-million word corpus that was developed for a Machine Translation shared task (Bojar et al., 2015), combining Europarl data (from parliamentary debates in the European Union) and News Commentary data.",4 Experiments,[0],[0]
"We preprocessed the corpus with tokenization and true-casing tools from the Moses toolkit (Koehn et al., 2007).",4 Experiments,[0],[0]
The vocabulary is composed of words that occur at least 3 times in the training set and contains approximately 60K words.,4 Experiments,[0],[0]
We use the validation and test set of the MT shared task.,4 Experiments,[0],[0]
"Finally, we took a subset of the ukWaC corpus, which was constructed by crawling UK websites (Baroni et al., 2009).",4 Experiments,[0],[0]
The training subset contains 200 million words and the vocabulary consists of the 200K words that appear more than 5 times in the training subset.,4 Experiments,[0],[0]
"The validation and test sets are different subsets of the ukWaC corpus, both containing 120K words.",4 Experiments,[0],[0]
"We preprocessed the data similarly to what we did for Europarl-NC.
",4 Experiments,[0],[0]
"We train our models using Stochastic Gradient Descent (SGD), which is relatively simple to tune compared to other optimization methods that involve additional hyper parameters (such as alpha in RMSprop) while being still fast and effective.",4 Experiments,[0],[0]
"SGD is commonly used in similar work (Devlin et al., 2014; Zaremba et al., 2014; Sukhbaatar et al., 2015).",4 Experiments,[0],[0]
"The learning rate is kept fixed during a single epoch, but we reduce it by a fixed proportion every time the validation perplexity increases by the end of the epoch.",4 Experiments,[0],[0]
"The values for learning rate, learning rate shrinking and mini-batch sizes as well as context size are fixed once and for all based on insights drawn from previous work (Hai Son et al., 2011; Sukhbaatar et al., 2015; Devlin et al., 2014) as well as experimentation with the Penn Treebank validation set.
",4 Experiments,[0],[0]
"Specifically, the learning rate is set to 0.05, with mini-batch size of 128 (we do not take the average of loss over the batch, and the training set is shuffled).",4 Experiments,[0],[0]
We multiply the learning rate by 0.5 every time we shrink it and clip the gradients if their norm is larger than 12.,4 Experiments,[0],[0]
The network parameters are initialized randomly on a range from -0.01 to 0.01 and the context size is set to 16.,4 Experiments,[0],[0]
"In Section 6 we show that this large context window is fully exploited.
",4 Experiments,[0],[0]
"For the base FFNN and CNN we varied embedding sizes (and thus, number of kernels) k = 128, 256.",4 Experiments,[0],[0]
"For k = 128 we explore the simple CNN,
incrementally adding MLPConv and COM variations (in that order) and, alternatively, using a MLCNN.",4 Experiments,[0],[0]
"For k = 256, we only explore the former three alternatives (i.e. all but the ML-CNN).",4 Experiments,[0],[0]
"For the kernel size, we set it to w = 3 words for the simple CNN (out of options 3, 5, 7, 9), whereas for the COM variant we use w = 3 and 5, based on experimentation on PTB.",4 Experiments,[0],[0]
"However, we observed the models to be generally robust to this parameter.",4 Experiments,[0],[0]
Dropout rates are tuned specifically for each combination of model and dataset based on the validation perplexity.,4 Experiments,[0],[0]
"We also add small dropout (p = 0.05–0.15) when we train the networks on the smaller corpus (Penn Treebank).
",4 Experiments,[0],[0]
"The experimental results for recurrent neural network language models, such as Recurrent Neural Networks (RNN) and Long-Short Term Memory models (LSTM), on the Penn Treebank are quoted from previous work; for Europarl-NC, we train our own models (we also report the performance of these in-house trained RNN and LSTM models on the Penn Treebank for reference).",4 Experiments,[0],[0]
"Specifically, we train LSTMs with embedding size k = 256 and number of layers L = 2 as well as k = 512 with L = 1, 2.",4 Experiments,[0],[0]
We train one RNN with k = 512 and L = 2.,4 Experiments,[0],[0]
"To train these models, we use the published source code from Zaremba et al. (2014).",4 Experiments,[0],[0]
"Our own models are also implemented in Torch7 for easier comparison.1 Finally, we selected the best performing convolutional and recurrent language models on Europarl-NC and the Baseline FFLM to be evaluated on the ukWaC corpus.
",4 Experiments,[0],[0]
"For all models trained on Europarl-NC and ukWaC, we speed up training by approximating the softmax with Noise Contrastive Estimation (NCE) (Gutmann and Hyvärinen, 2010), with the parameters being set following previous work (Chen et al., 2015).",4 Experiments,[0],[0]
"Concretely, for each predicted word, we sample 10 words from the unigram distribution, and the normalization factor is such that lnZ = 9.",4 Experiments,[0],[0]
"2
For comparison, we also implemented a simpler version of the FFNN without dropout and highway layers (Bengio et al., 2006).",4 Experiments,[0],[0]
"These networks have two hidden layers (Arisoy et al., 2012) with the size
1Available at https://github.com/quanpn90/NCE CNNLM.",4 Experiments,[0],[0]
"2We also experimented with Hierarchical Softmax (Mikolov et al., 2011) and found out that the NCE gave better performance in terms of speed and perplexity.
",4 Experiments,[0],[0]
"of 2 times the embedding size (k), thus having the same number of parameters as our baseline.",4 Experiments,[0],[0]
Our experimental results are summarized in Table 1.,5 Results,[0],[0]
"First of all, we can see that, even though the FFNN gives a very competitive performance,3 the addition of convolutional layers clearly improves it even further.",5 Results,[0],[0]
"Concretely, we observe a solid 11-26% reduction of perplexity compared to the feed-forward network after using MLP Convolution, depending on the setup and corpus.",5 Results,[0],[0]
"CNN alone yields a sizable improvement (5-24%), while MLPConv, in line with our expectations, adds another approximately 2-5% reduction in perplexity.",5 Results,[0],[0]
"A final (smaller) improvement comes from combining kernels of size 3 and 5, which can be attributed to a more expressive model that can learn patterns of n-grams of different sizes.",5 Results,[0],[0]
"In contrast to the successful two variants above, the multi-layer CNN did not help in better capturing the regularities of text, but rather the opposite: the more convolutional layers were stacked, the worse the performance.",5 Results,[0],[0]
"This also stands in contrast to the tradition of convolutional networks in Computer Vision, where using very deep convolutional neural networks is key to having better models.",5 Results,[0],[0]
"Deep convolution for text representation is in contrast rather rare, and to our knowledge it has only been successfuly applied to sentence representation (Kalchbrenner et al., 2014).",5 Results,[0],[0]
"We conjecture that the reason why deep CNNs may not be so effective for language could be the effect of the convolution on the data: The convolution output for an image is akin to a new, more abstract image, which yet again can be subject to new convolution operations, whereas the textual counterpart may no longer have the same properties, in the relevant aspects, as the original linguistic input.
",5 Results,[0],[0]
"Regarding the comparison with a stronger LSTM, our models can perform competitively under the same embedding dimension (e.g. see k = 256 of k = 512) on the first two datasets.",5 Results,[0],[0]
"However, the LSTM can be easily scaled using larger models, as shown in Zaremba et al. (2014), which gives the
3In our experiments, increasing the number of fully connected layers of the FFNN is harmful.",5 Results,[0],[0]
"Two hidden layers with highway connections is the best setting we could find.
best known results to date.",5 Results,[0],[0]
"This is not an option for our model, which heavily overfits with large hidden layers (around 1000) even with very large dropout values.",5 Results,[0],[0]
"Furthermore, the experiments on the larger ukWaC corpus show an even clearer advantage for the LSTM, which seems to be more efficient at harnessing this volume of data, than in the case of the two smaller corpora.
",5 Results,[0],[0]
"To sum up, we have established that the results of our CNN model are well above those of simple feed forward networks and recurrent neural networks.",5 Results,[0],[0]
"While they are below state of the art LSTMs, they are able to perform competitively with them for small and moderate-size models.",5 Results,[0],[0]
Scaling to larger sizes may be today the main roadblock for CNNs to reach the same performances as large LSTMs in language modeling.,5 Results,[0],[0]
"In what follows, we obtain insights into the inner workings of the CNN by looking into the linguistic patterns that the kernels learn to extract and also studying the temporal information extracted by the network in relation to its prediction capacity.
",6 Model Analysis,[0],[0]
"Learned patterns To get some insight into the kind of patterns that each kernel is learning to detect, we fed trigrams from the validation set of the Penn Treebank to each of the kernels, and extracted the ones that most highly activated the kernel, similarly to what was done in Kalchbrenner et al. (2014).",6 Model Analysis,[0],[0]
Some examples are shown in Figure 4.,6 Model Analysis,[0],[0]
"Since the word windows are made of embeddings, we can expect patterns with similar embeddings to have close activation outputs.",6 Model Analysis,[0],[0]
"This is borne out in the analysis: The kernels specialize in distinct features of the data, including more syntactic-semantic constructions (cf.",6 Model Analysis,[0],[0]
the “comparative kernel” including as . . .,6 Model Analysis,[0],[0]
"as patterns, but also of more than) and more lexical or topical features (cf. the “ending-in-month-name” kernel).",6 Model Analysis,[0],[0]
"Even in the more lexicalized features, however, we see linguistic regularities at different levels being condensed in a single kernel:",6 Model Analysis,[0],[0]
"For instance, the “spokesman” kernel detects phrases consisting of an indefinite determiner, a company name (or the word company itself) and the word “spokesman”.",6 Model Analysis,[0],[0]
"We hypothesize that the convolutional layer adds an “I identify one specific feature, but at a high level of
abstraction” dimension to a feed-forward neural network, similarly to what has been observed in image classification (Krizhevsky et al., 2012).",6 Model Analysis,[0],[0]
"Temporal information To the best of our knowledge, the longest context used in feed-forward language models is 10 tokens (Hai Son et al., 2012),
where no significant change in terms of perplexity was observed for bigger context sizes, even though in that work only same-sentence contexts were considered.",6 Model Analysis,[0],[0]
"In our experiments, we use a larger context size of 16 while removing the sentence boundary limit (as commonly done in n-gram language models) such that the network can take into account the words in the previous sentences.
",6 Model Analysis,[0],[0]
"To analyze whether all this information was effectively used, we took our best model, the CNN+MLPConv+COM model with embedding size of 256 (fifth line of second block in Table 1), and we identified the weights in the model that map the convolutional output (of size n × k) to a lower dimensional vector (the “mapping” layer in Figure 2).",6 Model Analysis,[0],[0]
Recall that the output of the convolutional layer is a matrix indexed by time step and kernel index containing the activation of the kernel when convolved with a window of text centered around the word at the given time step.,6 Model Analysis,[0],[0]
"Thus, output units of the above mentioned mapping predicate over an ensemble of kernel activations for each time step.",6 Model Analysis,[0],[0]
"We can identify the patterns that they learn to detect by extracting the time-kernel combinations for which they have positive weights (since we have ReLU activations, negative weights are equivalent to ignoring a feature).",6 Model Analysis,[0],[0]
"First, we asked ourselves whether these units tend to be more focused on the time steps closer to the target or not.",6 Model Analysis,[0],[0]
"To test this, we calculated the sum of the positive weights for each position in time using an average of the mappings that correspond to each output unit.",6 Model Analysis,[0],[0]
"The results are shown in
Figure 5.",6 Model Analysis,[0],[0]
"As could be expected, positions that are close to the token to be predicted have many active units (local context is very informative; see positions 2-4).",6 Model Analysis,[0],[0]
"However, surprisingly, positions that are actually far from the target are also quite active.",6 Model Analysis,[0],[0]
"It seems like the CNN is putting quite a lot of effort on characterizing long-range dependencies.
",6 Model Analysis,[0],[0]
"Next, we checked that the information extracted from the positions that are far in the past are actually used for prediction.",6 Model Analysis,[0],[0]
"To measure this, we artificially lesioned the network so it would only read the features from a given range of time steps (words in the context).",6 Model Analysis,[0],[0]
To lesion the network we manually masked the weights of the mapping that focus on times outside of the target range by setting them to zero.,6 Model Analysis,[0],[0]
We started using only the word closest to the final position and sequentially unmasked earlier positions until the full context was used again.,6 Model Analysis,[0],[0]
"The result of this experiment is presented in Figure 6, and it confirms our previous observation that positions that are the farthest away contribute to the predictions of the model.",6 Model Analysis,[0],[0]
"The perplexity drops dramatically as the first positions are unmasked, and then decreases more slowly, approximately in the form of a power law (f(x) ∝ x−0.9).",6 Model Analysis,[0],[0]
"Even though the effect is smaller, the last few positions still contribute to the final perplexity.",6 Model Analysis,[0],[0]
"In this work, we have investigated the potential of Convolutional Neural Networks for one prominent NLP task, language modeling, a sequential predic-
tion task.",7 Conclusion,[0],[0]
We incorporate a CNN layer on top of a strong feed-forward model enhanced with modern techniques like Highway Layers and Dropout.,7 Conclusion,[0],[0]
Our results show a solid 11-26% reduction in perplexity with respect to the feed-forward model across three corpora of different sizes and genres when the model uses MLP Convolution and combines kernels of different window sizes.,7 Conclusion,[0],[0]
"However, even without these additions we show CNNs to effectively learn language patterns that allow it to significantly decrease the model perplexity.
",7 Conclusion,[0],[0]
"In our view, this improvement responds to two key properties of CNNs, highlighted in the analysis.",7 Conclusion,[0],[0]
"First, as we have shown, they are able to integrate information from larger context windows, using information from words that are as far as 16 positions away from the predicted word.",7 Conclusion,[0],[0]
"Second, as we have qualitatively shown, the kernels learn to detect specific patterns at a high level of abstraction.",7 Conclusion,[0],[0]
This is analogous to the role of convolutions in Computer Vision.,7 Conclusion,[0],[0]
"The analogy, however, has limits; for instance, a deeper model stacking convolution layers harms performance in language modeling, while it greatly helps in Computer Vision.",7 Conclusion,[0],[0]
We conjecture that this is due to the differences in the nature of visual vs. linguistic data.,7 Conclusion,[0],[0]
The convolution creates sort of abstract images that still retain significant properties of images.,7 Conclusion,[0],[0]
"When applied to language, it detects important textual features but distorts the input, such that it is not text anymore.
",7 Conclusion,[0],[0]
"As for recurrent models, even if our model outperforms RNNs, it is well below state-of-the-art LSTMs.",7 Conclusion,[0],[0]
"Since CNNs are quite different in nature, we believe that a fruitful line of future research could focus on integrating the convolutional layer into a recurrent structure for language modeling, as well as other sequential problems, perhaps capturing the best of both worlds.",7 Conclusion,[0],[0]
We thank Marco Baroni and three anonymous reviewers for fruitful feedback.,Acknowledgments,[0],[0]
"This project has received funding from the European Union’s Horizon 2020 research and innovation programme under the Marie Sklodowska-Curie grant agreement No 655577 (LOVe); ERC 2011 Starting Independent Research Grant n. 283554 (COMPOSES) and the
Erasmus Mundus Scholarship for Joint Master Programs.",Acknowledgments,[0],[0]
We gratefully acknowledge the support of NVIDIA Corporation with the donation of the GPUs used in our research.,Acknowledgments,[0],[0]
Convolutional Neural Networks (CNNs) have shown to yield very strong results in several Computer Vision tasks.,abstractText,[0],[0]
"Their application to language has received much less attention, and it has mainly focused on static classification tasks, such as sentence classification for Sentiment Analysis or relation extraction.",abstractText,[0],[0]
"In this work, we study the application of CNNs to language modeling, a dynamic, sequential prediction task that needs models to capture local as well as long-range dependency information.",abstractText,[0],[0]
Our contribution is twofold.,abstractText,[0],[0]
"First, we show that CNNs achieve 11-26% better absolute performance than feed-forward neural language models, demonstrating their potential for language representation even in sequential tasks.",abstractText,[0],[0]
"As for recurrent models, our model outperforms RNNs but is below state of the art LSTM models.",abstractText,[0],[0]
"Second, we gain some understanding of the behavior of the model, showing that CNNs in language act as feature detectors at a high level of abstraction, like in Computer Vision, and that the model can profitably use information from as far as 16 words before the target.",abstractText,[0],[0]
Convolutional Neural Network Language Models,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 912–917 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
912",text,[0],[0]
"Convolutional neural networks (CNNs) have been shown to achieve state-of-the-art results on various natural language processing (NLP) tasks, such as sentence classification (Kim, 2014), question answering (Dong et al., 2015), and machine translation (Gehring et al., 2017).",1 Introduction,[0],[0]
"In an NLP system, a convolution operation is typically a sliding window function that applies a convolution filter to every possible window of words in a sentence.",1 Introduction,[0],[0]
"Hence, the key components of CNNs are a set of convolution filters that compose low-level word features into higher-level representations.
",1 Introduction,[0],[0]
"Convolution filters are usually realized as linear systems, as their outputs are affine transformations of the inputs followed by some non-linear activation functions.",1 Introduction,[0],[0]
"Prior work directly adopts a linear convolution filter to NLP problems by utilizing a concatenation of embeddings of a window of words as the input, which leverages word order information in a shallow additive way.",1 Introduction,[0],[0]
"As early
1The code is available at https://github.com/ bloomberg/cnn-rnf.
",1 Introduction,[0],[0]
"CNN architectures have mainly drawn inspiration from models of the primate visual system, the necessity of coping with language compositionality is largely overlooked in these systems.",1 Introduction,[0],[0]
"Due to the linear nature of the convolution filters, they lack the ability to capture complex language phenomena, such as compositionality and long-term dependencies.
",1 Introduction,[0],[0]
"To overcome this, we propose to employ recurrent neural networks (RNNs) as convolution filters of CNN systems for various NLP tasks.",1 Introduction,[0],[0]
"Our recurrent neural filters (RNFs) can naturally deal with language compositionality with a recurrent function that models word relations, and they are also able to implicitly model long-term dependencies.",1 Introduction,[0],[0]
"RNFs are typically applied to word sequences of moderate lengths, which alleviates some well-known drawbacks of RNNs, including their vulnerability to the gradient vanishing and exploding problems (Pascanu et al., 2013).",1 Introduction,[0],[0]
"As in conventional CNNs, the computation of the convolution operation with RNFs can be easily parallelized.",1 Introduction,[0],[0]
"As a result, RNF-based CNN models can be 3-8x faster than their RNN counterparts.
",1 Introduction,[0],[0]
We present two RNF-based CNN architectures for sentence classification and answer sentence selection problems.,1 Introduction,[0],[0]
Experimental results on the Stanford Sentiment Treebank and the QASent and WikiQA datasets demonstrate that RNFs significantly improve CNN performance over linear filters by 4-5% accuracies and 3-6% MAP scores respectively.,1 Introduction,[0],[0]
"Analysis results suggest that RNFs perform much better than linear filters in detecting longer key phrases, which provide stronger cues for categorizing the sentences.",1 Introduction,[0],[0]
The aim of a convolution filter is to produce a local feature for a window of words.,2 Approach,[0],[0]
"We describe a novel approach to learning filters using RNNs, which is especially suitable for NLP problems.
",2 Approach,[0],[0]
We then present two CNN architectures equipped with RNFs for sentence classification and sentence matching tasks respectively.,2 Approach,[0],[0]
"We briefly review the linear convolution filter implementation by Kim (2014), which has been widely adopted in later works.",2.1 Recurrent neural filters,[0],[0]
"Consider an m-gram word sequence [xi, · · · ,xi+m−1], where xi ∈ Rk is a k-dimensional word vector.",2.1 Recurrent neural filters,[0],[0]
"A linear convolution filter is a function applied to the m-gram to produce a feature ci,j :
ci,j =f(w > j xi:i+m−1 + bj),
xi:i+m−1 =xi ⊕ xi+1 ⊕ · · · ⊕ xi+m−1, (1)
where ⊕ is the concatenation operator, bj is a bias term, and f is a non-linear activation function.",2.1 Recurrent neural filters,[0],[0]
We typically use multiple independent linear filters to yield a feature vector ci for the word sequence.,2.1 Recurrent neural filters,[0],[0]
Linear convolution filters make strong assumptions about language that could harm the performance of NLP systems.,2.1 Recurrent neural filters,[0],[0]
"First, linear filters assume local compositionality and ignore long-term dependencies in language.",2.1 Recurrent neural filters,[0],[0]
"Second, they use separate parameters for each value of the time index, which hinders parameter sharing for the same word type (Goodfellow et al., 2016).",2.1 Recurrent neural filters,[0],[0]
"The assumptions become more problematic if we increase the window size m.
We propose to address the limitations by employing RNNs to realize convolution filters, which we term recurrent neural filters (RNFs).",2.1 Recurrent neural filters,[0],[0]
"RNFs compose the words of the m-gram from left to right using the same recurrent unit:
ht = RNN(ht−1,xt), (2)
where ht is a hidden state vector that encoded information about previously processed words, and the function RNN is a recurrent unit such as Long Short-Term Memory (LSTM) unit (Hochreiter and Schmidhuber, 1997) or Gated Recurrent Unit (GRU) (Cho et al., 2014).",2.1 Recurrent neural filters,[0],[0]
We use the last hidden state hi+m−1 as the RNF output feature vector ci.,2.1 Recurrent neural filters,[0],[0]
"Features learned by RNFs are interdependent of each other, which permits the learning of complementary information about the word sequence.",2.1 Recurrent neural filters,[0],[0]
The left-to-right word composing procedure in RNFs preserves word order information and implicitly models long-term dependencies in language.,2.1 Recurrent neural filters,[0],[0]
RNFs can be treated as simple dropin replacements of linear filters and potentially adopted in numerous CNN architectures.,2.1 Recurrent neural filters,[0],[0]
Sentence encoder We use a CNN architecture with one convolution layer followed by one max pooling layer to encode a sentence.,2.2 CNN architectures,[0],[0]
"In particular, the RNFs are applied to every possible window of m words in the sentence {x1:m,x2:m+1, · · · ,xn−m+1:n} to generate feature maps C =",2.2 CNN architectures,[0],[0]
"[c1, c2, · · · , cn−m+1].",2.2 CNN architectures,[0],[0]
"Then a max-over-time pooling operation (Collobert et al., 2011) is used to produce a fixed size sentence representation: v = max{C}.
",2.2 CNN architectures,[0],[0]
Sentence classification We use a CNN architecture that is similar to the CNN-static model described in Kim (2014) for sentence classification.,2.2 CNN architectures,[0],[0]
"After obtaining the sentence representation v, a fully connected softmax layer is used to map v to an output probability distribution.",2.2 CNN architectures,[0],[0]
"The network is optimized against a cross-entropy loss function.
",2.2 CNN architectures,[0],[0]
Sentence matching We exploit a CNN architecture that is nearly identical to the CNN-Cnt model introduced by Yang et al. (2015).,2.2 CNN architectures,[0],[0]
Let v1 and v2 be the vector representations of the two sentences.,2.2 CNN architectures,[0],[0]
A bilinear function is applied to v1 and v2 to produce a sentence matching score.,2.2 CNN architectures,[0],[0]
The score is combined with two word matching count features and fed into a sigmoid layer.,2.2 CNN architectures,[0],[0]
The output of the sigmoid layer is used by binary cross-entropy loss to optimize the model.,2.2 CNN architectures,[0],[0]
We evaluate RNFs on some of the most popular datasets for the sentence classification and sentence matching tasks.,3 Experiments,[0],[0]
"After describing the experimental setup, we compare RNFs against both linear filters and conventional RNN models, and report our findings in § 3.2.",3 Experiments,[0],[0]
"Data We use the Stanford Sentiment Treebank (Socher et al., 2013) in our sentence classification experiments.",3.1 Experimental settings,[0],[0]
We report accuracy results for both binary classification and fine-grained classification settings.,3.1 Experimental settings,[0],[0]
"Two answer sentence selection datasets, QASent (Wang et al., 2007) and WikiQA (Yang et al., 2015), are adopted in our sentence matching experiments.",3.1 Experimental settings,[0],[0]
"We use MAP and MRR to evaluate the performance of answer sentence selection models.
",3.1 Experimental settings,[0],[0]
Competitive systems We consider CNN variants with linear filters and RNFs.,3.1 Experimental settings,[0],[0]
"For RNFs, we
adopt two implementations based on GRUs and LSTMs respectively.",3.1 Experimental settings,[0],[0]
"We also compare against the following RNN variants: GRU, LSTM, GRU with max pooling, and LSTM with max pooling.2",3.1 Experimental settings,[0],[0]
"We use the publicly available 300-dimensional GloVe vectors (Pennington et al., 2014) pre-trained with 840 billion tokens to initialize the word embeddings for all the models.",3.1 Experimental settings,[0],[0]
The word vectors are fixed during downstream training.,3.1 Experimental settings,[0],[0]
"Finally, we report best published results for each dataset.3
Parameter tuning For all the experiments, we tune hyperparameters on the development sets and report results obtained with the selected hyperparameters on the test sets.",3.1 Experimental settings,[0],[0]
"After the preliminary search, we choose the number of hidden units (feature maps) from {200, 300, 400}, and the filter window width from {2, 3, 4, 5} for linear filters and from {5, 6, 7, 8} for RNFs.",3.1 Experimental settings,[0],[0]
"Linear filters tend to perform well with small window widths, while RNFs work better with larger window widths.",3.1 Experimental settings,[0],[0]
"We apply dropout to embedding layers, pooling layers, RNN input layers, and RNN recurrent layers.",3.1 Experimental settings,[0],[0]
"The dropout rates are selected from {0, 0.2, 0.4}, where 0 indicates that dropout is not used for the specific layer.",3.1 Experimental settings,[0],[0]
"Optimization is performed by Adam (Kingma and Ba, 2015) with early stopping.",3.1 Experimental settings,[0],[0]
We conduct random search with a budget of 100 runs to seek the best hyperparameter configuration for each system.,3.1 Experimental settings,[0],[0]
The evaluation results on sentiment classification and answer sentence selection are shown in Table 1 and Table 2 respectively.,3.2 Results,[0],[0]
RNFs significantly outperform linear filters on both tasks.,3.2 Results,[0],[0]
"In fact, we find that CNN-RNF variants significantly outperform CNN-linear-filter on nearly every hyperparameter configuration in our experiments.",3.2 Results,[0],[0]
"On the Stanford Sentiment Treebank, CNN-RNF-LSTM outperforms CNN-linear-filter by 5.4% and 3.9% accuracies on the fine-grained and binary classification settings respectively.",3.2 Results,[0],[0]
We observe similar performance boosts by adopting RNFs for CNNs on the QASent and WikiQA test sets.,3.2 Results,[0],[0]
"CNN-RNFGRU improves upon CNN-linear-filter by 3.7% MRR score on QASent and CNN-RNF-LSTM performs better than CNN-linear-filter by 6.1%
2Max pooling performed better than mean pooling in our preliminary experiments.
",3.2 Results,[0],[0]
"3We exclude results obtained from systems using external resources beyond word embeddings.
MAP score on WikiQA.",3.2 Results,[0],[0]
"In particular, CNN-RNFLSTM achieves 53.4% and 90.0% accuracies on the fine-grained and binary sentiment classification tasks respectively, which match the state-ofthe-art results on the Stanford Sentiment Treebank.",3.2 Results,[0],[0]
"CNN-RNF-LSTM also obtains competitive results on answer sentence selection datasets, despite the simple model architecture compared to state-of-the-art systems.
",3.2 Results,[0],[0]
"Conventional RNN models clearly benefit from max pooling, especially on the task of answer sentence selection.",3.2 Results,[0],[0]
"Like RNF-based CNN models, max-pooled RNNs also consist of two essential layers.",3.2 Results,[0],[0]
"The recurrent layer learns a set of hidden states corresponding to different time steps, and the max pooling layer extracts the most salient information from the hidden states.",3.2 Results,[0],[0]
"However, a hidden state in RNNs encodes information about all the previous time steps, while RNFs focus on detecting local features from a window of words that can be more relevant to specific tasks.",3.2 Results,[0],[0]
"As a result, RNF-based CNN models perform consistently better than max-pooled RNN models.
",3.2 Results,[0],[0]
"CNN-RNF models are much faster to train than their corresponding RNN counterparts, despite they have the same numbers of parameters, as RNFs are applied to word sequences of shorter lengths and the computation is parallelizable.",3.2 Results,[0],[0]
"The training of CNN-RNF-LSTM models takes 10-20 mins on the Stanford Sentiment Treebank, which is 3-8x faster than the training of LSTM models, on an NVIDIA Tesla P100 GPU accelerator.",3.2 Results,[0],[0]
We now investigate why RNFs are more effective than linear convolution filters on the binary sentiment classification task.,4 Analysis,[0],[0]
"We perform quantitative analysis on the development set of the Stanford Sentiment Treebank (SST), in which sentiment labels for some phrases are also available.
",4 Analysis,[0],[0]
Local label consistency (LLC) ratio We first inspect whether longer phrases have a higher tendency to express the same sentiment as the entire sentence.,4 Analysis,[0],[0]
We define the local label consistency (LLC) ratio as the ratio of m-grams that share the same sentiment labels as the original sentences.,4 Analysis,[0],[0]
The LLC ratios with respect to different phrase lengths are shown in Figure 1.,4 Analysis,[0],[0]
"Longer phrases are
more likely to convey the same sentiments as the original sentences.",4 Analysis,[0],[0]
"Therefore, the ability to model long phrases is crucial to convolution filters.
",4 Analysis,[0],[0]
Key phrase hit rate We examine linear filters and RNFs on the ability to detect a key phrase in a sentence.,4 Analysis,[0],[0]
"Specifically, we define the key phrases for a sentence to be the set of phrases that are labeled with the same sentiment as the original sentence.",4 Analysis,[0],[0]
The key phrase hit rate is then defined as the ratio of filter-detected m-grams that fall into the corresponding key phrase sets.,4 Analysis,[0],[0]
The filter-detected m-gram of a sentence is the one whose convolution feature vector has the shortest Euclidean distance to the max-pooled vector.,4 Analysis,[0],[0]
The hit rate results computed on SST dev set are presented in Figure 2.,4 Analysis,[0],[0]
"As shown, RNFs consistently per-
form better than linear filters on identifying key phrases across different phrase lengths, especially on phrases of moderate lengths (4-7).",4 Analysis,[0],[0]
"The results suggest that RNFs are superior to linear filters, as they can better model longer phrases whose labels are more consistent with the sentences.4",4 Analysis,[0],[0]
Linear convolution filters are dominated in CNNbased systems for both computer vision and natural language processing tasks.,5 Related work,[0],[0]
"One exception is the work of Zoumpourlis et al. (2017), which proposes a convolution filter that is a function with quadratic forms through the Volterra kernels.",5 Related work,[0],[0]
"However, this non-linear convolution filter is developed in the context of a computational model of the visual cortex, which is not suitable for NLP problems.",5 Related work,[0],[0]
"In contrast, RNFs are specifically derived for NLP tasks, in which a different form of non-linearity, language compositionality, often plays a critical role.
",5 Related work,[0],[0]
Several works have employed neural network architectures that contain both CNN and RNN components to tackle NLP problems.,5 Related work,[0],[0]
"Tan et al. (2016) present a deep neural network for answer sentence selection, in which a convolution layer is applied to the output of a BiLSTM layer for extracting sentence representations.",5 Related work,[0],[0]
"Ma and Hovy (2016) propose to compose character representations of a word using a CNN, whose output is then fed into a BiLSTM for sequence tagging.",5 Related work,[0],[0]
Kalchbrenner and Blunsom (2013) introduce a neural architecture that uses a sentence model based on CNNs and a discourse model based on RNNs.,5 Related work,[0],[0]
Their system achieves state-of-the-art results on the task of dialogue act classification.,5 Related work,[0],[0]
"Instead of treating an RNN and a CNN as isolated components, our work directly marries RNNs with the convolution operation, which illustrates a new direction in mixing RNNs with CNNs.",5 Related work,[0],[0]
"We present RNFs, a new class of convolution filters based on recurrent neural networks.",6 Conclusion and future work,[0],[0]
"RNFs sequentially apply the same recurrent unit to words of a phrase, which naturally capture language compositionality and implicitly model long-term
4Phrases of very long lengths (8-10) are rarely annotated in SST dev data, which could explain why linear filters and RNFs achieve similar hit rates, as small data sample often leads to high variance.
dependencies.",6 Conclusion and future work,[0],[0]
Experiments on sentiment classification and answer sentence selection tasks demonstrate that RNFs give a significant boost in performance compared to linear convolution filters.,6 Conclusion and future work,[0],[0]
"RNF-based CNNs also outperform a variety of RNN-based models, as they focus on extracting local information that could be more relevant to particular problems.",6 Conclusion and future work,[0],[0]
"The quantitive analysis reveals that RNFs can handle long phrases much better than linear filters, which explains their superiority over the linear counterparts.",6 Conclusion and future work,[0],[0]
"In the future, we would like to investigate the effectiveness of RNFs on a wider range of NLP tasks, such as natural language inference and machine translation.",6 Conclusion and future work,[0],[0]
We thank Chunyang Xiao for helping us to run the analysis experiments.,7 Acknowledgments,[0],[0]
"We thank Kazi Shefaet Rahman, Ozan Irsoy, Chen-Tse Tsai, and Lingjia Deng for their valuable comments on earlier versions of this paper.",7 Acknowledgments,[0],[0]
We also thank the EMNLP reviewers for their helpful feedback.,7 Acknowledgments,[0],[0]
We introduce a class of convolutional neural networks (CNNs) that utilize recurrent neural networks (RNNs) as convolution filters.,abstractText,[0],[0]
"A convolution filter is typically implemented as a linear affine transformation followed by a nonlinear function, which fails to account for language compositionality.",abstractText,[0],[0]
"As a result, it limits the use of high-order filters that are often warranted for natural language processing tasks.",abstractText,[0],[0]
"In this work, we model convolution filters with RNNs that naturally capture compositionality and long-term dependencies in language.",abstractText,[0],[0]
We show that simple CNN architectures equipped with recurrent neural filters (RNFs) achieve results that are on par with the best published ones on the Stanford Sentiment Treebank and two answer sentence selection datasets.1,abstractText,[0],[0]
Convolutional Neural Networks with Recurrent Neural Filters,title,[0],[0]
"Sequence to sequence learning has been successful in many tasks such as machine translation, speech recognition (Sutskever et al., 2014; Chorowski et al., 2015) and text summarization (Rush et al., 2015; Nallapati et al., 2016; Shen et al., 2016) amongst others.",1. Introduction,[0],[0]
"The dominant approach to date encodes the input sequence with a series of bi-directional recurrent neural networks (RNN) and generates a variable length output with another set of decoder RNNs, both of which interface via a soft-attention mechanism (Bahdanau et al., 2014; Luong et al., 2015).",1. Introduction,[0],[0]
"In machine translation, this architecture has been demonstrated to outperform traditional phrase-based models by large margins (Sennrich et al., 2016b; Zhou et al., 2016; Wu et al., 2016; §2).
1The source code and models are available at https:// github.com/facebookresearch/fairseq.
",1. Introduction,[0],[0]
"Convolutional neural networks are less common for sequence modeling, despite several advantages (Waibel et al., 1989; LeCun & Bengio, 1995).",1. Introduction,[0],[0]
"Compared to recurrent layers, convolutions create representations for fixed size contexts, however, the effective context size of the network can easily be made larger by stacking several layers on top of each other.",1. Introduction,[0],[0]
This allows to precisely control the maximum length of dependencies to be modeled.,1. Introduction,[0],[0]
Convolutional networks do not depend on the computations of the previous time step and therefore allow parallelization over every element in a sequence.,1. Introduction,[0],[0]
"This contrasts with RNNs which maintain a hidden state of the entire past that prevents parallel computation within a sequence.
",1. Introduction,[0],[0]
Multi-layer convolutional neural networks create hierarchical representations over the input sequence in which nearby input elements interact at lower layers while distant elements interact at higher layers.,1. Introduction,[0],[0]
"Hierarchical structure provides a shorter path to capture long-range dependencies compared to the chain structure modeled by recurrent networks, e.g. we can obtain a feature representation capturing relationships within a window of n words by applying only O(nk ) convolutional operations for kernels of width k, compared to a linear number O(n) for recurrent neural networks.",1. Introduction,[0],[0]
"Inputs to a convolutional network are fed through a constant number of kernels and non-linearities, whereas recurrent networks apply up to n operations and non-linearities to the first word and only a single set of operations to the last word.",1. Introduction,[0],[0]
"Fixing the number of nonlinearities applied to the inputs also eases learning.
",1. Introduction,[0],[0]
Recent work has applied convolutional neural networks to sequence modeling such as Bradbury et al. (2016) who introduce recurrent pooling between a succession of convolutional layers or Kalchbrenner et al. (2016) who tackle neural translation without attention.,1. Introduction,[0],[0]
"However, none of these approaches has been demonstrated improvements over state of the art results on large benchmark datasets.",1. Introduction,[0],[0]
Gated convolutions have been previously explored for machine translation by Meng et al. (2015) but their evaluation was restricted to a small dataset and the model was used in tandem with a traditional count-based model.,1. Introduction,[0],[0]
"Architec-
",1. Introduction,[0],[0]
"ar X
iv :1
70 5.
03 12
2v 3
[ cs
.C",1. Introduction,[0],[0]
"L
] 2
5 Ju
l 2 01
7
tures which are partially convolutional have shown strong performance on larger tasks but their decoder is still recurrent (Gehring et al., 2016).
",1. Introduction,[0],[0]
In this paper we propose an architecture for sequence to sequence modeling that is entirely convolutional.,1. Introduction,[0],[0]
"Our model is equipped with gated linear units (Dauphin et al., 2016) and residual connections (He et al., 2015a).",1. Introduction,[0],[0]
We also use attention in every decoder layer and demonstrate that each attention layer only adds a negligible amount of overhead.,1. Introduction,[0],[0]
The combination of these choices enables us to tackle large scale problems (§3).,1. Introduction,[0],[0]
We evaluate our approach on several large datasets for machine translation as well as summarization and compare to the current best architectures reported in the literature.,1. Introduction,[0],[0]
"On WMT’16 English-Romanian translation we achieve a new state of the art, outperforming the previous best result by 1.9 BLEU.",1. Introduction,[0],[0]
On WMT’14 English-German we outperform the strong LSTM setup of Wu et al. (2016) by 0.5 BLEU and on WMT’14 English-French we outperform the likelihood trained system of Wu et al. (2016) by 1.6 BLEU.,1. Introduction,[0],[0]
"Furthermore, our model can translate unseen sentences at an order of magnitude faster speed than Wu et al. (2016) on GPU and CPU hardware (§4, §5).",1. Introduction,[0],[0]
"Sequence to sequence modeling has been synonymous with recurrent neural network based encoder-decoder architectures (Sutskever et al., 2014; Bahdanau et al., 2014).",2. Recurrent Sequence to Sequence Learning,[0],[0]
"The encoder RNN processes an input sequence x = (x1, . . .",2. Recurrent Sequence to Sequence Learning,[0],[0]
", xm) of m elements and returns state representations z = (z1. . . .",2. Recurrent Sequence to Sequence Learning,[0],[0]
", zm).",2. Recurrent Sequence to Sequence Learning,[0],[0]
"The decoder RNN takes z and generates the output sequence y = (y1, . . .",2. Recurrent Sequence to Sequence Learning,[0],[0]
", yn) left to right, one element at a time.",2. Recurrent Sequence to Sequence Learning,[0],[0]
"To generate output yi+1, the decoder computes a new hidden state hi+1 based on the previous state hi, an embedding gi of the previous target language word yi, as well as a conditional input ci derived from the encoder output z.",2. Recurrent Sequence to Sequence Learning,[0],[0]
"Based on this generic formulation, various encoder-decoder architectures have been proposed, which differ mainly in the conditional input and the type of RNN.
",2. Recurrent Sequence to Sequence Learning,[0],[0]
Models without attention consider only the final encoder state zm by setting ci,2. Recurrent Sequence to Sequence Learning,[0],[0]
"= zm for all i (Cho et al., 2014), or simply initialize the first decoder state with zm (Sutskever et al., 2014), in which case ci is not used.",2. Recurrent Sequence to Sequence Learning,[0],[0]
"Architectures with attention (Bahdanau et al., 2014; Luong et al., 2015) compute ci as a weighted sum of (z1. . .",2. Recurrent Sequence to Sequence Learning,[0],[0]
.,2. Recurrent Sequence to Sequence Learning,[0],[0]
", zm) at each time step.",2. Recurrent Sequence to Sequence Learning,[0],[0]
The weights of the sum are referred to as attention scores and allow the network to focus on different parts of the input sequence as it generates the output sequences.,2. Recurrent Sequence to Sequence Learning,[0],[0]
"Attention scores are computed by essentially comparing each encoder state zj to a combination of the previous decoder
state hi and the last prediction yi; the result is normalized to be a distribution over input elements.
",2. Recurrent Sequence to Sequence Learning,[0],[0]
"Popular choices for recurrent networks in encoder-decoder models are long short term memory networks (LSTM; Hochreiter & Schmidhuber, 1997) and gated recurrent units (GRU; Cho et al., 2014).",2. Recurrent Sequence to Sequence Learning,[0],[0]
"Both extend Elman RNNs (Elman, 1990) with a gating mechanism that allows the memorization of information from previous time steps in order to model long-term dependencies.",2. Recurrent Sequence to Sequence Learning,[0],[0]
"Most recent approaches also rely on bi-directional encoders to build representations of both past and future contexts (Bahdanau et al., 2014; Zhou et al., 2016; Wu et al., 2016).",2. Recurrent Sequence to Sequence Learning,[0],[0]
"Models with many layers often rely on shortcut or residual connections (He et al., 2015a; Zhou et al., 2016; Wu et al., 2016).",2. Recurrent Sequence to Sequence Learning,[0],[0]
Next we introduce a fully convolutional architecture for sequence to sequence modeling.,3. A Convolutional Architecture,[0],[0]
Instead of relying on RNNs to compute intermediate encoder states z and decoder states h we use convolutional neural networks (CNN).,3. A Convolutional Architecture,[0],[0]
"First, we embed input elements x = (x1, . . .",3.1. Position Embeddings,[0],[0]
", xm) in distributional space as w = (w1, . . .",3.1. Position Embeddings,[0],[0]
", wm), where wj ∈",3.1. Position Embeddings,[0],[0]
Rf is a column in an embedding matrix D ∈ RV×f .,3.1. Position Embeddings,[0],[0]
"We also equip our model with a sense of order by embedding the absolute position of input elements p = (p1, . . .",3.1. Position Embeddings,[0],[0]
", pm) where pj ∈ Rf .",3.1. Position Embeddings,[0],[0]
"Both are combined to obtain input element representations e = (w1 + p1, . . .",3.1. Position Embeddings,[0],[0]
", wm + pm).",3.1. Position Embeddings,[0],[0]
"We proceed similarly for output elements that were already generated by the decoder network to yield output element representations that are being fed back into the decoder network g = (g1, . . .",3.1. Position Embeddings,[0],[0]
", gn).",3.1. Position Embeddings,[0],[0]
Position embeddings are useful in our architecture since they give our model a sense of which portion of the sequence in the input or output it is currently dealing with (§5.4).,3.1. Position Embeddings,[0],[0]
Both encoder and decoder networks share a simple block structure that computes intermediate states based on a fixed number of input elements.,3.2. Convolutional Block Structure,[0],[0]
"We denote the output of the lth block as hl = (hl1, . . .",3.2. Convolutional Block Structure,[0],[0]
", h l n) for the decoder network, and zl = (zl1, . . .",3.2. Convolutional Block Structure,[0],[0]
", z l m) for the encoder network; we refer to blocks and layers interchangeably.",3.2. Convolutional Block Structure,[0],[0]
Each block contains a one dimensional convolution followed by a non-linearity.,3.2. Convolutional Block Structure,[0],[0]
"For a decoder network with a single block and kernel width k, each resulting state h1i contains information over k input elements.",3.2. Convolutional Block Structure,[0],[0]
Stacking several blocks on top of each other increases the number of input elements represented in a state.,3.2. Convolutional Block Structure,[0],[0]
"For instance, stacking 6 blocks with k = 5 results in an input field of 25 elements, i.e. each output depends on 25
inputs.",3.2. Convolutional Block Structure,[0],[0]
"Non-linearities allow the networks to exploit the full input field, or to focus on fewer elements if needed.
",3.2. Convolutional Block Structure,[0],[0]
"Each convolution kernel is parameterized as W ∈ R2d×kd, bw ∈ R2d and takes as input X ∈ Rk×d which is a concatenation of k input elements embedded in d dimensions and maps them to a single output element Y ∈ R2d that has twice the dimensionality of the input elements; subsequent layers operate over the k output elements of the previous layer.",3.2. Convolutional Block Structure,[0],[0]
"We choose gated linear units (GLU; Dauphin et al., 2016) as non-linearity which implement a simple gating mechanism over the output of the convolution Y =",3.2. Convolutional Block Structure,[0],[0]
"[A B] ∈ R2d:
v([A B]) = A⊗ σ(B)
where A,B ∈ Rd are the inputs to the non-linearity, ⊗ is the point-wise multiplication and the output v([A B])",3.2. Convolutional Block Structure,[0],[0]
∈ Rd is half the size of Y .,3.2. Convolutional Block Structure,[0],[0]
The gates σ(B) control which inputs A of the current context are relevant.,3.2. Convolutional Block Structure,[0],[0]
"A similar nonlinearity has been introduced in Oord et al. (2016b) who apply tanh toA but Dauphin et al. (2016) shows that GLUs perform better in the context of language modelling.
",3.2. Convolutional Block Structure,[0],[0]
"To enable deep convolutional networks, we add residual connections from the input of each convolution to the output of the block (He et al., 2015a).
",3.2. Convolutional Block Structure,[0],[0]
"hli = v(W l[hl−1i−k/2, . . .",3.2. Convolutional Block Structure,[0],[0]
", h l−1 i+k/2] +",3.2. Convolutional Block Structure,[0],[0]
b l w) +,3.2. Convolutional Block Structure,[0],[0]
h l−1,3.2. Convolutional Block Structure,[0],[0]
"i
For encoder networks we ensure that the output of the convolutional layers matches the input length by padding the input at each layer.",3.2. Convolutional Block Structure,[0],[0]
"However, for decoder networks we have to take care that no future information is available to the decoder (Oord et al., 2016a).",3.2. Convolutional Block Structure,[0],[0]
"Specifically, we pad the input by k − 1 elements on both the left and right side by zero vectors, and then remove k elements from the end of the convolution output.
",3.2. Convolutional Block Structure,[0],[0]
We also add linear mappings to project between the embedding size f and the convolution outputs that are of size 2d.,3.2. Convolutional Block Structure,[0],[0]
"We apply such a transform to w when feeding embeddings to the encoder network, to the encoder output zuj , to the final layer of the decoder just before the softmax hL, and to all decoder layers hl before computing attention scores (1).
",3.2. Convolutional Block Structure,[0],[0]
"Finally, we compute a distribution over the T possible next target elements yi+1 by transforming the top decoder output hLi via a linear layer with weights Wo and bias bo:
p(yi+1|y1, . . .",3.2. Convolutional Block Structure,[0],[0]
", yi,x) = softmax(WohLi + bo) ∈ RT",3.2. Convolutional Block Structure,[0],[0]
We introduce a separate attention mechanism for each decoder layer.,3.3. Multi-step Attention,[0],[0]
"To compute the attention, we combine the current decoder state hli with an embedding of the previous
target element gi:
dli",3.3. Multi-step Attention,[0],[0]
= W l dh,3.3. Multi-step Attention,[0],[0]
l i + b,3.3. Multi-step Attention,[0],[0]
"l d + gi (1)
",3.3. Multi-step Attention,[0],[0]
"For decoder layer l the attention alij of state i and source element j is computed as a dot-product between the decoder state summary dli and each output z u j of the last encoder block u:
alij = exp
( dli · zuj ) ∑m t=1",3.3. Multi-step Attention,[0],[0]
"exp ( dli · zut )
",3.3. Multi-step Attention,[0],[0]
"The conditional input cli to the current decoder layer is a weighted sum of the encoder outputs as well as the input element embeddings ej (Figure 1, center right):
cli",3.3. Multi-step Attention,[0],[0]
"= m∑
j=1
alij(z u j + ej) (2)
",3.3. Multi-step Attention,[0],[0]
"This is slightly different to recurrent approaches which compute both the attention and the weighted sum over zuj
only.",3.3. Multi-step Attention,[0],[0]
We found adding ej to be beneficial and it resembles key-value memory networks where the keys are the zuj and the values are the,3.3. Multi-step Attention,[0],[0]
zuj + ej,3.3. Multi-step Attention,[0],[0]
"(Miller et al., 2016).",3.3. Multi-step Attention,[0],[0]
Encoder outputs zuj represent potentially large input contexts and ej provides point information about a specific input element that is useful when making a prediction.,3.3. Multi-step Attention,[0],[0]
"Once cli has been computed, it is simply added to the output of the corresponding decoder layer hli.
",3.3. Multi-step Attention,[0],[0]
"This can be seen as attention with multiple ’hops’ (Sukhbaatar et al., 2015) compared to single step attention (Bahdanau et al., 2014; Luong et al., 2015; Zhou et al., 2016; Wu et al., 2016).",3.3. Multi-step Attention,[0],[0]
"In particular, the attention of the first layer determines a useful source context which is then fed to the second layer that takes this information into account when computing attention etc.",3.3. Multi-step Attention,[0],[0]
"The decoder also has immediate access to the attention history of the k − 1 previous time steps because the conditional inputs cl−1i−k, . . .",3.3. Multi-step Attention,[0],[0]
", c l−1 i are part of h l−1 i−k, . . .",3.3. Multi-step Attention,[0],[0]
", h l−1 i which are input to hli.",3.3. Multi-step Attention,[0],[0]
This makes it easier for the model to take into account which previous inputs have been attended to already compared to recurrent nets where this information is in the recurrent state and needs to survive several non-linearities.,3.3. Multi-step Attention,[0],[0]
"Overall, our attention mechanism considers which words we previously attended to (Yang et al., 2016) and performs multiple attention ’hops’ per time step.",3.3. Multi-step Attention,[0],[0]
"In Appendix §C, we plot attention scores for a deep decoder and show that at different layers, different portions of the source are attended to.
",3.3. Multi-step Attention,[0],[0]
"Our convolutional architecture also allows to batch the attention computation across all elements of a sequence compared to RNNs (Figure 1, middle).",3.3. Multi-step Attention,[0],[0]
We batch the computations of each decoder layer individually.,3.3. Multi-step Attention,[0],[0]
We stabilize learning through careful weight initialization (§3.5) and by scaling parts of the network to ensure that the variance throughout the network does not change dramatically.,3.4. Normalization Strategy,[0],[0]
"In particular, we scale the output of residual blocks as well as the attention to preserve the variance of activations.",3.4. Normalization Strategy,[0],[0]
We multiply the sum of the input and output of a residual block by √ 0.5 to halve the variance of the sum.,3.4. Normalization Strategy,[0],[0]
"This assumes that both summands have the same variance which is not always true but effective in practice.
",3.4. Normalization Strategy,[0],[0]
"The conditional input cli generated by the attention is a weighted sum of m vectors (2) and we counteract a change in variance through scaling by m √ 1/m; we multiply by m to scale up the inputs to their original size, assuming the attention scores are uniformly distributed.",3.4. Normalization Strategy,[0],[0]
"This is generally not the case but we found it to work well in practice.
",3.4. Normalization Strategy,[0],[0]
"For convolutional decoders with multiple attention, we scale the gradients for the encoder layers by the number
of attention mechanisms we use; we exclude source word embeddings.",3.4. Normalization Strategy,[0],[0]
We found this to stabilize learning since the encoder received too much gradient otherwise.,3.4. Normalization Strategy,[0],[0]
"Normalizing activations when adding the output of different layers, e.g. residual connections, requires careful weight initialization.",3.5. Initialization,[0],[0]
The motivation for our initialization is the same as for the normalization: maintain the variance of activations throughout the forward and backward passes.,3.5. Initialization,[0],[0]
All embeddings are initialized from a normal distribution with mean 0 and standard deviation 0.1.,3.5. Initialization,[0],[0]
"For layers whose output is not directly fed to a gated linear unit, we initialize weights from N (0, √ 1/nl) where nl is the number of input connections to each neuron.",3.5. Initialization,[0],[0]
"This ensures that the variance of a normally distributed input is retained.
",3.5. Initialization,[0],[0]
"For layers which are followed by a GLU activation, we propose a weight initialization scheme by adapting the derivations in (He et al., 2015b; Glorot & Bengio, 2010; Appendix A).",3.5. Initialization,[0],[0]
"If the GLU inputs are distributed with mean 0 and have sufficiently small variance, then we can approximate the output variance with 1/4 of the input variance (Appendix A.1).",3.5. Initialization,[0],[0]
"Hence, we initialize the weights so that the input to the GLU activations have 4 times the variance of the layer input.",3.5. Initialization,[0],[0]
"This is achieved by drawing their initial values fromN (0, √ 4/nl).",3.5. Initialization,[0],[0]
"Biases are uniformly set to zero when the network is constructed.
",3.5. Initialization,[0],[0]
We apply dropout to the input of some layers so that inputs are retained with a probability of p.,3.5. Initialization,[0],[0]
"This can be seen as multiplication with a Bernoulli random variable taking value 1/p with probability p and 0 otherwise (Srivastava et al., 2014).",3.5. Initialization,[0],[0]
The application of dropout will then cause the variance to be scaled by 1/p.,3.5. Initialization,[0],[0]
We aim to restore the incoming variance by initializing the respective layers with larger weights.,3.5. Initialization,[0],[0]
"Specifically, we useN (0, √ 4p/nl) for lay-
ers whose output is subject to a GLU and N (0, √ p/nl) otherwise (Appendix A.3).",3.5. Initialization,[0],[0]
"We consider three major WMT translation tasks as well as a text summarization task.
",4.1. Datasets,[0],[0]
WMT’16 English-Romanian.,4.1. Datasets,[0],[0]
We use the same data and pre-processing as Sennrich et al. (2016b) but remove sentences with more than 175 words.,4.1. Datasets,[0],[0]
"This results in 2.8M sentence pairs for training and we evaluate on newstest2016.2
2We followed the pre-processing of https://github.",4.1. Datasets,[0],[0]
"com/rsennrich/wmt16-scripts/blob/80e21e5/ sample/preprocess.sh and added the back-translated data from http://data.statmt.org/rsennrich/wmt16_
",4.1. Datasets,[0],[0]
We experiment with word-based models using a source vocabulary of 200K types and a target vocabulary of 80K types.,4.1. Datasets,[0],[0]
"We also consider a joint source and target byte-pair encoding (BPE) with 40K types (Sennrich et al., 2016a;b).
",4.1. Datasets,[0],[0]
WMT’14 English-German.,4.1. Datasets,[0],[0]
We use the same setup as Luong et al. (2015) which comprises 4.5M sentence pairs for training and we test on newstest2014.3,4.1. Datasets,[0],[0]
"As vocabulary we use 40K sub-word types based on BPE.
WMT’14 English-French.",4.1. Datasets,[0],[0]
"We use the full training set of 36M sentence pairs, and remove sentences longer than 175 words as well as pairs with a source/target length ratio exceeding 1.5.",4.1. Datasets,[0],[0]
This results in 35.5M sentence-pairs for training.,4.1. Datasets,[0],[0]
Results are reported on newstest2014.,4.1. Datasets,[0],[0]
"We use a source and target vocabulary with 40K BPE types.
",4.1. Datasets,[0],[0]
"In all setups a small subset of the training data serves as validation set (about 0.5-1% for each dataset) for early stopping and learning rate annealing.
",4.1. Datasets,[0],[0]
Abstractive summarization.,4.1. Datasets,[0],[0]
"We train on the Gigaword corpus (Graff et al., 2003) and pre-process it identically to Rush et al. (2015) resulting in 3.8M training examples and 190K for validation.",4.1. Datasets,[0],[0]
"We evaluate on the DUC-2004 test data comprising 500 article-title pairs (Over et al., 2007) and report three variants of recall-based ROUGE (Lin, 2004), namely, ROUGE-1 (unigrams), ROUGE-2 (bigrams), and ROUGE-L (longest-common substring).",4.1. Datasets,[0],[0]
We also evaluate on a Gigaword test set of 2000 pairs which is identical to the one used by Rush et al. (2015) and we report F1 ROUGE similar to prior work.,4.1. Datasets,[0],[0]
Similar to Shen et al. (2016) we use a source and target vocabulary of 30K words and require outputs to be at least 14 words long.,4.1. Datasets,[0],[0]
"We use 512 hidden units for both encoders and decoders, unless otherwise stated.",4.2. Model Parameters and Optimization,[0],[0]
"All embeddings, including the output produced by the decoder before the final linear layer, have dimensionality 512; we use the same dimensionalities for linear layers mapping between the hidden and embedding sizes (§3.2).",4.2. Model Parameters and Optimization,[0],[0]
"We train our convolutional models with Nesterov’s accelerated gradient method (Sutskever et al., 2013) using a momentum value of 0.99 and renormalize gradients if their norm exceeds 0.1 (Pascanu et al., 2013).",4.2. Model Parameters and Optimization,[0],[0]
"We use a learning rate of 0.25 and once the validation perplexity stops improving, we reduce the learning rate by an order of magnitude after each epoch until it falls below 10−4.
",4.2. Model Parameters and Optimization,[0],[0]
"Unless otherwise stated, we use mini-batches of 64 sentences.",4.2. Model Parameters and Optimization,[0],[0]
"We restrict the maximum number of words in a mini-batch to make sure that batches with long sentences
backtranslations/en-ro. 3http://nlp.stanford.edu/projects/nmt
still fit in GPU memory.",4.2. Model Parameters and Optimization,[0],[0]
"If the threshold is exceeded, we simply split the batch until the threshold is met and process the parts separatedly.",4.2. Model Parameters and Optimization,[0],[0]
Gradients are normalized by the number of non-padding tokens per mini-batch.,4.2. Model Parameters and Optimization,[0],[0]
"We also use weight normalization for all layers except for lookup tables (Salimans & Kingma, 2016).
",4.2. Model Parameters and Optimization,[0],[0]
"Besides dropout on the embeddings and the decoder output, we also apply dropout to the input of the convolutional blocks (Srivastava et al., 2014).",4.2. Model Parameters and Optimization,[0],[0]
"All models are implemented in Torch (Collobert et al., 2011) and trained on a single Nvidia M40 GPU except for WMT’14 EnglishFrench for which we use a multi-GPU setup on a single machine.",4.2. Model Parameters and Optimization,[0],[0]
We train on up to eight GPUs synchronously by maintaining copies of the model on each card and split the batch so that each worker computes 1/8-th of the gradients; at the end we sum the gradients via Nvidia NCCL.,4.2. Model Parameters and Optimization,[0],[0]
"We report average results over three runs of each model, where each differs only in the initial random seed.",4.3. Evaluation,[0],[0]
Translations are generated by a beam search and we normalize log-likelihood scores by sentence length.,4.3. Evaluation,[0],[0]
We use a beam of width 5.,4.3. Evaluation,[0],[0]
We divide the log-likelihoods of the final hypothesis in beam search by their length |y|.,4.3. Evaluation,[0],[0]
For WMT’14 English-German we tune a length normalization constant on a separate development set (newstest2015) and we normalize log-likelihoods by |y|α,4.3. Evaluation,[0],[0]
"(Wu et al., 2016).",4.3. Evaluation,[0],[0]
"On other datasets we did not find any benefit with length normalization.
",4.3. Evaluation,[0],[0]
"For word-based models, we perform unknown word replacement based on attention scores after generation (Jean et al., 2015).",4.3. Evaluation,[0],[0]
Unknown words are replaced by looking up the source word with the maximum attention score in a precomputed dictionary.,4.3. Evaluation,[0],[0]
"If the dictionary contains no translation, then we simply copy the source word.",4.3. Evaluation,[0],[0]
"Dictionaries were extracted from the word aligned training data that we obtained with fast align (Dyer et al., 2013).",4.3. Evaluation,[0],[0]
Each source word is mapped to the target word it is most frequently aligned to.,4.3. Evaluation,[0],[0]
In our multi-step attention (§3.3) we simply average the attention scores over all layers.,4.3. Evaluation,[0],[0]
"Finally, we compute case-sensitive tokenized BLEU, except for WMT’16 English-Romanian where we use detokenized BLEU to be comparable with Sennrich et al. (2016b).4
4https://github.com/moses-smt/ mosesdecoder/blob/617e8c8/scripts/generic/",4.3. Evaluation,[0],[0]
"{multi-bleu.perl,mteval-v13a.pl}",4.3. Evaluation,[0],[0]
We first evaluate our convolutional model on three translation tasks.,5.1. Recurrent vs. Convolutional Models,[0],[0]
"On WMT’16 English-Romanian translation we compare to Sennrich et al. (2016b) which is the winning entry on this language pair at WMT’16 (Bojar et al., 2016).",5.1. Recurrent vs. Convolutional Models,[0],[0]
Their model implements the attention-based sequence to sequence architecture of Bahdanau et al. (2014) and uses GRU cells both in the encoder and decoder.,5.1. Recurrent vs. Convolutional Models,[0],[0]
We test both word-based and BPE vocabularies (§4).,5.1. Recurrent vs. Convolutional Models,[0],[0]
Table 1 shows that our fully convolutional sequence to sequence model (ConvS2S) outperforms the WMT’16 winning entry for English-Romanian by 1.9 BLEU with a BPE encoding and by 1.3 BLEU with a word factored vocabulary.,5.1. Recurrent vs. Convolutional Models,[0],[0]
"This instance of our architecture has 20 layes in the encoder and 20 layers in the decoder, both using kernels of width 3 and hidden size 512 throughout.",5.1. Recurrent vs. Convolutional Models,[0],[0]
"Training took between 6 and 7.5 days on a single GPU.
",5.1. Recurrent vs. Convolutional Models,[0],[0]
"On WMT’14 English to German translation we compare to the following prior work: Luong et al. (2015) is based on a four layer LSTM attention model, ByteNet (Kalchbrenner et al., 2016) propose a convolutional model based on characters without attention, with 30 layers in the encoder and 30 layers in the decoder, GNMT (Wu et al., 2016) represents the state of the art on this dataset and they use eight encoder LSTMs as well as eight decoder LSTMs, we quote their result for a word-based model, such as ours, as well as a word-piece model (Schuster & Nakajima, 2012).5
The results (Table 1) show that our convolutional model outpeforms GNMT by 0.5 BLEU.",5.1. Recurrent vs. Convolutional Models,[0],[0]
"Our encoder has 15 layers and the decoder has 15 layers, both with 512 hidden units in the first ten layers and 768 units in the subsequent three layers, all using kernel width 3.",5.1. Recurrent vs. Convolutional Models,[0],[0]
The final two layers have 2048 units which are just linear mappings with a single input.,5.1. Recurrent vs. Convolutional Models,[0],[0]
We trained this model on a single GPU over a period of 18.5 days with a batch size of 48.,5.1. Recurrent vs. Convolutional Models,[0],[0]
"LSTM sparse mixtures have shown strong accuracy at 26.03 BLEU for a single run (Shazeer et al., 2016) which compares to 25.39 BLEU for our best run.",5.1. Recurrent vs. Convolutional Models,[0],[0]
"This mixture sums the output of four experts, not unlike an ensemble which sums the output of multiple networks.",5.1. Recurrent vs. Convolutional Models,[0],[0]
"ConvS2S also benefits from ensembling (§5.2), therefore mixtures are a promising direction.",5.1. Recurrent vs. Convolutional Models,[0],[0]
"Finally, we train on the much larger WMT’14 EnglishFrench task where we compare to the state of the art result of GNMT (Wu et al., 2016).",5.1. Recurrent vs. Convolutional Models,[0],[0]
Our model is trained with a simple token-level likelihood objective and we improve over GNMT in the same setting by 1.6 BLEU on average.,5.1. Recurrent vs. Convolutional Models,[0],[0]
"We also outperform their reinforcement (RL) models by 0.5
5We did not use the exact same vocabulary size because word pieces and BPE estimate the vocabulary differently.
BLEU.",5.1. Recurrent vs. Convolutional Models,[0],[0]
"Reinforcement learning is equally applicable to our architecture and we believe that it would further improve our results.
",5.1. Recurrent vs. Convolutional Models,[0],[0]
"The ConvS2S model for this experiment uses 15 layers in the encoder and 15 layers in the decoder, both with 512 hidden units in the first five layers, 768 units in the subsequent four layers, 1024 units in the next 3 layers, all using kernel width 3; the final two layers have 2048 units and 4096 units each but the they are linear mappings with kernel width 1.",5.1. Recurrent vs. Convolutional Models,[0],[0]
"This model has an effective context size of only 25 words, beyond which it cannot access any information on the target size.",5.1. Recurrent vs. Convolutional Models,[0],[0]
"Our results are based on training with 8 GPUs for about 37 days and batch size 32 on each worker.6 The same configuration as for WMT’14 EnglishGerman achieves 39.41 BLEU in two weeks on this dataset in an eight GPU setup.
",5.1. Recurrent vs. Convolutional Models,[0],[0]
Zhou et al. (2016) report a non-averaged result of 39.2 BLEU.,5.1. Recurrent vs. Convolutional Models,[0],[0]
"More recently, Ha et al. (2016) showed that one can generate weights with one LSTM for another LSTM.",5.1. Recurrent vs. Convolutional Models,[0],[0]
This approach achieves 40.03 BLEU but the result is not averaged.,5.1. Recurrent vs. Convolutional Models,[0],[0]
"Shazeer et al. (2016) compares at 40.56 BLEU to our best single run of 40.70 BLEU.
",5.1. Recurrent vs. Convolutional Models,[0],[0]
6This is half of the GPU time consumed by a basic model of Wu et al. (2016) who use 96 GPUs for 6 days.,5.1. Recurrent vs. Convolutional Models,[0],[0]
"We expect the time to train our model to decrease substantially in a multi-machine setup.
",5.1. Recurrent vs. Convolutional Models,[0],[0]
"The translations produced by our models often match the length of the references, particularly for the large WMT’14 English-French task, or are very close for small to medium data sets such as WMT’14 English-German or WMT’16 English-Romanian.",5.1. Recurrent vs. Convolutional Models,[0],[0]
"Next, we ensemble eight likelihood-trained models for both WMT’14 English-German and WMT’14 English-French and compare to previous work which also reported ensemble results.",5.2. Ensemble Results,[0],[0]
"For the former, we also show the result when ensembling 10 models.",5.2. Ensemble Results,[0],[0]
Table 2 shows that we outperform the best current ensembles on both datasets.,5.2. Ensemble Results,[0],[0]
"Next, we evaluate the inference speed of our architecture on the development set of the WMT’14 English-French task which is the concatenation of newstest2012 and newstest2013; it comprises 6003 sentences.",5.3. Generation Speed,[0],[0]
We measure generation speed both on GPU and CPU hardware.,5.3. Generation Speed,[0],[0]
"Specifically, we measure GPU speed on three generations of Nvidia cards: a GTX-1080ti, an M40 as well as an older K40 card.",5.3. Generation Speed,[0],[0]
CPU timings are measured on one host with 48 hyperthreaded cores (Intel Xeon E5-2680 @ 2.50GHz) with 40 workers.,5.3. Generation Speed,[0],[0]
"In all settings, we batch up to 128 sentences, composing batches with sentences of equal length.",5.3. Generation Speed,[0],[0]
Note that the majority of batches is smaller because of the small size of the development set.,5.3. Generation Speed,[0],[0]
"We experiment with beams of size 5 as well as greedy search, i.e beam of size 1.",5.3. Generation Speed,[0],[0]
"To make generation fast, we do not recompute convolution states that have not changed compared to the previous time step but rather copy (shift) these activations.
",5.3. Generation Speed,[0],[0]
"We compare to results reported in Wu et al. (2016) who
use Nvidia K80 GPUs which are essentially two K40s.",5.3. Generation Speed,[0],[0]
"We did not have such a GPU available and therefore run experiments on an older K40 card which is inferior to a K80, in addition to the newer M40 and GTX-1080ti cards.",5.3. Generation Speed,[0],[0]
The results (Table 3) show that our model can generate translations on a K40 GPU at 9.3 times the speed and 2.25 higher BLEU; on an M40 the speed-up is up to 13.7 times and on a GTX-1080ti card the speed is 21.3 times faster.,5.3. Generation Speed,[0],[0]
"A larger beam of size 5 decreases speed but gives better BLEU.
",5.3. Generation Speed,[0],[0]
"On CPU, our model is up to 9.3 times faster, however, the GNMT CPU results were obtained with an 88 core machine whereas our results were obtained with just over half the number of cores.",5.3. Generation Speed,[0],[0]
"On a per CPU core basis, our model is 17 times faster at a better BLEU.",5.3. Generation Speed,[0],[0]
"Finally, our CPU speed is 2.7 times higher than GNMT on a custom TPU chip which shows that high speed can be achieved on commodity hardware.",5.3. Generation Speed,[0],[0]
We do no report TPU figures as we do not have access to this hardware.,5.3. Generation Speed,[0],[0]
"In the following sections, we analyze the design choices in our architecture.",5.4. Position Embeddings,[0],[0]
The remaining results in this paper are based on the WMT’14 English-German task with 13 encoder layers at kernel size 3 and 5 decoder layers at kernel size 5.,5.4. Position Embeddings,[0],[0]
"We use a target vocabulary of 160K words as well as vocabulary selection (Mi et al., 2016; L’Hostis et al., 2016) to decrease the size of the output layer which speeds up training and testing.",5.4. Position Embeddings,[0],[0]
The average vocabulary size for each training batch is about 20K target words.,5.4. Position Embeddings,[0],[0]
"All figures are averaged over three runs (§4) and BLEU is reported on newstest2014 before unknown word replacement.
",5.4. Position Embeddings,[0],[0]
"We start with an experiment that removes the position em-
beddings from the encoder and decoder (§3.1).",5.4. Position Embeddings,[0],[0]
These embeddings allow our model to identify which portion of the source and target sequence it is dealing with but also impose a restriction on the maximum sentence length.,5.4. Position Embeddings,[0],[0]
Table 4 shows that position embeddings are helpful but that our model still performs well without them.,5.4. Position Embeddings,[0],[0]
Removing the source position embeddings results in a larger accuracy decrease than target position embeddings.,5.4. Position Embeddings,[0],[0]
"However, removing both source and target positions decreases accuracy only by 0.5 BLEU.",5.4. Position Embeddings,[0],[0]
"We had assumed that the model would not be able to calibrate the length of the output sequences very well without explicit position information, however, the output lengths of models without position embeddings closely matches models with position information.",5.4. Position Embeddings,[0],[0]
"This indicates that the models can learn relative position information within the contexts visible to the encoder and decoder networks which can observe up to 27 and 25 words respectively.
",5.4. Position Embeddings,[0],[0]
Recurrent models typically do not use explicit position embeddings since they can learn where they are in the sequence through the recurrent hidden state computation.,5.4. Position Embeddings,[0],[0]
"In our setting, the use of position embeddings requires only a simple addition to the input word embeddings which is a negligible overhead.",5.4. Position Embeddings,[0],[0]
The multiple attention mechanism (§3.3) computes a separate source context vector for each decoder layer.,5.5. Multi-step Attention,[0],[0]
The computation also takes into account contexts computed for preceding decoder layers of the current time step as well as previous time steps that are within the receptive field of the decoder.,5.5. Multi-step Attention,[0],[0]
How does multiple attention compare to attention in fewer layers or even only in a single layer as is usual?,5.5. Multi-step Attention,[0],[0]
Table 5 shows that attention in all decoder layers achieves the best validation perplexity (PPL).,5.5. Multi-step Attention,[0],[0]
"Furthermore, removing more and more attention layers decreases accuracy, both in terms of BLEU as well as PPL.
",5.5. Multi-step Attention,[0],[0]
The computational overhead for attention is very small compared to the rest of the network.,5.5. Multi-step Attention,[0],[0]
"Training with attention in all five decoder layers processes 3624 target words per second on average on a single GPU, compared to 3772 words per second for attention in a single layer.",5.5. Multi-step Attention,[0],[0]
"This is only
a 4% slow down when adding 4 attention modules.",5.5. Multi-step Attention,[0],[0]
Most neural machine translation systems only use a single module.,5.5. Multi-step Attention,[0],[0]
"This demonstrates that attention is not the bottleneck in neural machine translation, even though it is quadratic in the sequence length (cf. Kalchbrenner et al., 2016).",5.5. Multi-step Attention,[0],[0]
"Part of the reason for the low impact on speed is that we batch the computation of an attention module over all target words, similar to Kalchbrenner et al. (2016).",5.5. Multi-step Attention,[0],[0]
"However, for RNNs batching of the attention may be less effective because of the dependence on the previous time step.",5.5. Multi-step Attention,[0],[0]
Figure 2 shows accuracy when we change the number of layers in the encoder or decoder.,5.6. Kernel size and Depth,[0],[0]
The kernel width for layers in the encoder is 3 and for the decoder it is 5.,5.6. Kernel size and Depth,[0],[0]
Deeper architectures are particularly beneficial for the encoder but less so for the decoder.,5.6. Kernel size and Depth,[0],[0]
"Decoder setups with two layers already perform well whereas for the encoder accuracy keeps increasing steadily with more layers until up to 9 layers when accuracy starts to plateau.
",5.6. Kernel size and Depth,[0],[0]
"Aside from increasing the depth of the networks, we can also change the kernel width.",5.6. Kernel size and Depth,[0],[0]
Table 7 shows that encoders with narrow kernels and many layers perform better than wider kernels.,5.6. Kernel size and Depth,[0],[0]
These networks can also be faster since the amount of work to compute a kernel operating over 3 input elements is less than half compared to kernels over 7 elements.,5.6. Kernel size and Depth,[0],[0]
We see a similar picture for decoder networks with large kernel sizes (Table 8).,5.6. Kernel size and Depth,[0],[0]
Dauphin et al. (2016) shows that context sizes of 20 words are often sufficient to achieve very good accuracy on language modeling for English.,5.6. Kernel size and Depth,[0],[0]
"Finally, we evaluate our model on abstractive sentence summarization which takes a long sentence as input and outputs a shortened version.",5.7. Summarization,[0],[0]
"The current best models on this task are recurrent neural networks which either optimize the evaluation metric (Shen et al., 2016) or address specific problems of summarization such as avoiding repeated generations (Suzuki & Nagata, 2017).",5.7. Summarization,[0],[0]
"We use standard likelhood training for our model and a simple model with six layers in the encoder and decoder each, hidden size 256, batch size 128, and we trained on a single GPU in one night.",5.7. Summarization,[0],[0]
"Table 6 shows that our likelhood trained model outperforms the likelihood trained model (RNN MLE) of Shen et al. (2016) and is not far behind the best models on this task which benefit from task-specific optimization and
model structure.",5.7. Summarization,[0],[0]
We expect our model to benefit from these improvements as well.,5.7. Summarization,[0],[0]
We introduce the first fully convolutional model for sequence to sequence learning that outperforms strong recurrent models on very large benchmark datasets at an order of magnitude faster speed.,6. Conclusion and Future Work,[0],[0]
"Compared to recurrent networks, our convolutional approach allows to discover compositional structure in the sequences more easily since representations are built hierarchically.",6. Conclusion and Future Work,[0],[0]
"Our model relies on gating and performs multiple attention steps.
",6. Conclusion and Future Work,[0],[0]
We achieve a new state of the art on several public translation benchmark data sets.,6. Conclusion and Future Work,[0],[0]
"On the WMT’16 EnglishRomanian task we outperform the previous best result by 1.9 BLEU, on WMT’14 English-French translation we improve over the LSTM model of Wu et al. (2016) by 1.6 BLEU in a comparable setting, and on WMT’14 EnglishGerman translation we ouperform the same model by 0.5 BLEU.",6. Conclusion and Future Work,[0],[0]
"In future work, we would like to apply convolutional architectures to other sequence to sequence learning problems which may benefit from learning hierarchical representations as well.",6. Conclusion and Future Work,[0],[0]
"We thank Benjamin Graham for providing a fast 1-D convolution, and Ronan Collobert as well as Yann LeCun for helpful discussions related to this work.",Acknowledgements,[0],[0]
We derive a weight initialization scheme tailored to the GLU activation function similar to Glorot & Bengio (2010); He et al. (2015b) by focusing on the variance of activations within the network for both forward and backward passes.,A. Weight Initialization,[0],[0]
"We also detail how we modify the weight initialization for dropout.
A.1.",A. Weight Initialization,[0],[0]
"Forward Pass
Assuming that the inputs xl of a convolutional layer l and its weights Wl are independent and identically distributed (i.i.d.), the variance of its output, computed as yl = Wlxl+ bl, is
V ar [ yl ] =",A. Weight Initialization,[0],[0]
"nlV ar [ wlxl ] (3)
where nl is the number inputs to the layer.",A. Weight Initialization,[0],[0]
"For onedimensional convolutional layers with kernel width k and input dimension c, this is kc.",A. Weight Initialization,[0],[0]
"We adopt the notation in (He et al., 2015b), i.e. yl, wl and xl represent the random variables in yl, Wl and xl.",A. Weight Initialization,[0],[0]
"With wl and xl independent from each other and normally distributed with zero mean, this amounts to
V ar [ yl ] =",A. Weight Initialization,[0],[0]
nlV ar,A. Weight Initialization,[0],[0]
[ wl ] V ar [ xl ],A. Weight Initialization,[0],[0]
.,A. Weight Initialization,[0],[0]
"(4)
xl is the result of the GLU activation function yal−1",A. Weight Initialization,[0],[0]
σ(y b l−1) with yl−1 =,A. Weight Initialization,[0],[0]
"(y a l−1,y b l−1), and y a l−1,y b l−1 i.i.d.",A. Weight Initialization,[0],[0]
"Next, we formulate upper and lower bounds in order to approximate V ar[xl].",A. Weight Initialization,[0],[0]
"If yl−1 follows a symmetric distribution with mean 0, then
V ar [ xl ] = V ar [ yal−1 σ(y b l−1) ]",A. Weight Initialization,[0],[0]
"(5)
= E",A. Weight Initialization,[0],[0]
"[( yal−1 σ(y b l−1) )2]− E2 [ yal−1 σ(y b l−1) ]
(6)
= V ar[yal−1]E [ σ(ybl−1) 2 ] .",A. Weight Initialization,[0],[0]
"(7)
A lower bound is given by (1/4)V ar[yal−1] when expanding (6) with E2[σ(ybl−1)]",A. Weight Initialization,[0],[0]
"= 1/4:
V ar [ xl ] = V ar [ yal−1 σ(y b l−1) ]",A. Weight Initialization,[0],[0]
"(8)
= V ar [ yal−1 ] E2 [ σ(ybl−1) ]",A. Weight Initialization,[0],[0]
"+
V ar [ yal−1 ] V ar [ σ(ybl−1) ]",A. Weight Initialization,[0],[0]
"(9)
= 1
4 V ar
[ yal−1 ] + V ar [ yal−1 ] V ar [ σ(ybl−1) ]
(10)
and V ar[yal−1]V ar[σ(y b l−1)]",A. Weight Initialization,[0],[0]
> 0.,A. Weight Initialization,[0],[0]
"We utilize the relation σ(x)2 ≤ (1/16)x2 − 1/4 + σ(x) (Appendix B) to provide an upper bound on E[σ(x)2]:
E[σ(x)2]",A. Weight Initialization,[0],[0]
≤ E [ 1 16 x2,A. Weight Initialization,[0],[0]
"− 1 4 + σ(x) ] (11)
= 1 16 E[x2]− 1 4 + E[σ(x)]",A. Weight Initialization,[0],[0]
"(12)
With x ∼ N (0, std(x)), this yields
E [ σ(x)2 ] ≤ 1 16 E [ x2 ]",A. Weight Initialization,[0],[0]
"− 1 4 + 1 2 (13)
= 1
16 V ar
[ x ] + 1
4 .",A. Weight Initialization,[0],[0]
"(14)
With (7) and V ar[yal−1] = V ar[y b l−1] = V ar[yl−1], this results in
V ar [ xl ] ≤ 1
16 V ar
[ yl−1 ]2 + 1
4 V ar
[ yl−1 ] .",A. Weight Initialization,[0],[0]
"(15)
We initialize the embedding matrices in our network with small variances (around 0.01), which allows us to dismiss the quadratic term and approximate the GLU output variance with
V ar[xl] ≈ 1
4 V ar[yl−1].",A. Weight Initialization,[0],[0]
"(16)
If L network layers of equal size and with GLU activations are combined, the variance of the final output yL is given by
V ar[yL]",A. Weight Initialization,[0],[0]
"≈ V ar[y1]
  L∏
l=2
1 4 nlV ar[wl]
  .",A. Weight Initialization,[0],[0]
"(17)
Following (He et al., 2015b), we aim to satisfy the condition
1 4 nlV ar
[ wl ] = 1,∀l (18)
so that the activations in a network are neither exponentially magnified nor reduced.",A. Weight Initialization,[0],[0]
"This is achieved by initializing Wl from N (0, √ 4/nl).
",A. Weight Initialization,[0],[0]
A.2.,A. Weight Initialization,[0],[0]
"Backward Pass
The gradient of a convolutional layer is computed via backpropagation as ∆xl = Ŵlyl.",A. Weight Initialization,[0],[0]
"Considering separate gradients ∆yal and ∆y b l for GLU, the gradient of x is given by
∆xl = Ŵ",A. Weight Initialization,[0],[0]
a l ∆y a l + Ŵ,A. Weight Initialization,[0],[0]
b l ∆y b l .,A. Weight Initialization,[0],[0]
"(19)
Ŵ corresponds to W with re-arranged weights to enable back-propagation.",A. Weight Initialization,[0],[0]
"Analogously to the forward pass, ∆xl, ŵl and ∆yl represent the random variables for the values in ∆xl, Ŵl and ∆yl, respectively.",A. Weight Initialization,[0],[0]
"Note that W and Ŵ contain the same values, i.e. ŵ = w. Similar to (3), the variance of ∆xl is
V ar[∆xl] = n̂l ( V ar[wal ]V ar[∆y a l ] +",A. Weight Initialization,[0],[0]
V ar[w b l ]V ar[∆y b l ] ) .,A. Weight Initialization,[0],[0]
"(20) Here, n̂l is the number of inputs to layer l+1.",A. Weight Initialization,[0],[0]
"The gradients for the GLU inputs are:
∆yal = ∆xl+1",A. Weight Initialization,[0],[0]
σ(y b l ) and (21) ∆ybl = ∆xl+1y a l σ ′(ybl ).,A. Weight Initialization,[0],[0]
"(22)
The approximation for the forward pass can be used for V ar[∆yal ], and for estimating V ar[∆y b",A. Weight Initialization,[0],[0]
l ],A. Weight Initialization,[0],[0]
we assume an upper bound on E[σ′(ybl ) 2] of 1/16 since σ′(ybl ) ∈,A. Weight Initialization,[0],[0]
"[0, 14 ].",A. Weight Initialization,[0],[0]
"Hence,
V ar[∆yal ]− 1
4 V ar[∆xl+1] ≤
1
16 V ar[∆xl+1]V ar[y
b l )]
(23)
V ar[∆ybl ] ≤ 1
16 ∆V ar[∆xl+1]V ar[y
a l ] (24)
",A. Weight Initialization,[0],[0]
"We observe relatively small gradients in our network, typically around 0.001 at the start of training.",A. Weight Initialization,[0],[0]
"Therefore, we approximate by discarding the quadratic terms above, i.e.
V ar[∆yal ]",A. Weight Initialization,[0],[0]
"≈ 1
4 V ar[∆xl+1] (25)
V ar[∆ybl ]",A. Weight Initialization,[0],[0]
≈ 0,A. Weight Initialization,[0],[0]
"(26)
V ar[∆xl]",A. Weight Initialization,[0],[0]
"≈ 1
4 n̂lV ar[w
a l ]V ar[∆xl+1] (27)
",A. Weight Initialization,[0],[0]
"As for the forward pass, the above result can be generalized to backpropagation through many successive layers, resulting in
V ar[∆x2] ≈ V ar[∆xL+1]
  L∏
l=2
1 4 n̂lV ar[w a l ]
  (28)
and a similar condition, i.e. (1/4)n̂lV ar[wal ] = 1.",A. Weight Initialization,[0],[0]
"In the networks we consider, successions of convolutional layers usually operate on the same number of inputs so that most cases nl = n̂l.",A. Weight Initialization,[0],[0]
"Note that W bl is discarded in the approximation; however, for the sake of consistency we use the same initialization for W al and W b l .
",A. Weight Initialization,[0],[0]
"For arbitrarily large variances of network inputs and activations, our approximations are invalid; in that case, the initial values for W al and W b l would have to be balanced for the input distribution to be retained.",A. Weight Initialization,[0],[0]
"Alternatively, methods that explicitly control the variance in the network, e.g. batch normalization (Ioffe & Szegedy, 2015) or layer normalization (Ba et al., 2016) could be employed.
",A. Weight Initialization,[0],[0]
A.3.,A. Weight Initialization,[0],[0]
"Dropout
Dropout retains activations in a neural network with a probability p and sets them to zero otherwise (Srivastava et al., 2014).",A. Weight Initialization,[0],[0]
It is common practice to scale the retained activations by 1/p during training so that the weights of the network do not have to be modified at test time when p is set to 1.,A. Weight Initialization,[0],[0]
"In this case, dropout amounts to multiplying activations x by a Bernoulli random variable r",A. Weight Initialization,[0],[0]
"where Pr[r = 1/p] = p and Pr[r = 0] = 1 − p (Srivastava et al., 2014).",A. Weight Initialization,[0],[0]
It holds that E[r] = 1 and V ar[r] = (1− p)/p.,A. Weight Initialization,[0],[0]
"If x is independent
of r and E[x] = 0, the variance after dropout is
V ar[xr] = E[r]2V ar[x] + V ar[r]V ar[x] (29)
=",A. Weight Initialization,[0],[0]
"( 1 +
1− p p
) V ar[x] (30)
",A. Weight Initialization,[0],[0]
"= 1
p V ar[x] (31)
",A. Weight Initialization,[0],[0]
"Assuming that a the input of a convolutional layer has been subject to dropout with a retain probability p, the variations of the forward and backward activations from §A.1 and §A.2 can now be approximated with
V ar[xl+1]",A. Weight Initialization,[0],[0]
"≈ 1
4p nlV ar[wl]V",A. Weight Initialization,[0],[0]
"ar[xl] and (32)
V ar[∆xl]",A. Weight Initialization,[0],[0]
"≈ 1
4p nlV ar[w
a l ]V ar[∆xl+1].",A. Weight Initialization,[0],[0]
"(33)
",A. Weight Initialization,[0],[0]
"This amounts to a modified initialization of Wl from a normal distribution with zero mean and a standard deviation of√
4p/n. For layers without a succeeding GLU activation function, we initialize weights from N (0, √ p/n) to calibrate for any immediately preceding dropout application.",A. Weight Initialization,[0],[0]
The sigmoid function σ(x) can be expressed as a hyperbolic tangent by using the identity tanh(x) = 2σ(2x)− 1.,B. Upper Bound on Squared Sigmoid,[0],[0]
"The derivative of tanh is tanh′(x) = 1 − tanh2(x), and with tanh(x) ∈",B. Upper Bound on Squared Sigmoid,[0],[0]
"[0, 1], x ≥ 0",B. Upper Bound on Squared Sigmoid,[0],[0]
"it holds that
tanh′(x) ≤ 1, x ≥ 0 (34) ∫",B. Upper Bound on Squared Sigmoid,[0],[0]
"x
0
tanh′(x) dx ≤ ∫",B. Upper Bound on Squared Sigmoid,[0],[0]
"x
0
1 dx (35)
tanh(x) ≤ x, x ≥ 0 (36)
We can express this relation with σ(x) as follows:
2σ(x)− 1 ≤ 1 2 x, x ≥ 0 (37)
Both terms of this inequality have rotational symmetry w.r.t 0, and thus
( 2σ(x)− 1 )2 ≤ ( 1
2 x
)2 ∀x (38)
⇔ σ(x)2 ≤ 1 16 x2",B. Upper Bound on Squared Sigmoid,[0],[0]
− 1 4 + σ(x).,B. Upper Bound on Squared Sigmoid,[0],[0]
(39),B. Upper Bound on Squared Sigmoid,[0],[0]
Figure 3 shows attention scores for a generated sentence from the WMT’14 English-German task.,C. Attention Visualization,[0],[0]
The model used for this plot has 8 decoder layers and a 80K BPE vocabulary.,C. Attention Visualization,[0],[0]
The attention passes in different decoder layers capture different portions of the source sentence.,C. Attention Visualization,[0],[0]
"Layer 1, 3
and 6 exhibit a linear alignment.",C. Attention Visualization,[0],[0]
"The first layer shows the clearest alignment, although it is slightly off and frequently attends to the corresponding source word of the previously generated target word.",C. Attention Visualization,[0],[0]
Layer 2 and 8 lack a clear structure and are presumably collecting information about the whole source sentence.,C. Attention Visualization,[0],[0]
"The fourth layer shows high alignment scores on nouns such as “festival”, “way” and “work” for both the generated target nouns as well as their preceding words.",C. Attention Visualization,[0],[0]
"Note that in German, those preceding words depend on gender and object relationship of the respective noun.",C. Attention Visualization,[0],[0]
"Finally, the attention scores in layer 5 and 7 focus on “built”, which is reordered in the German translation and is moved from the beginning to the very end of the sentence.",C. Attention Visualization,[0],[0]
"One interpretation for this is that as generation progresses, the model repeatedly tries to perform the re-ordering.",C. Attention Visualization,[0],[0]
"“aufgebaut” can be generated after a noun or pronoun only, which is reflected in the higher scores at positions 2, 5, 8, 11 and 13.",C. Attention Visualization,[0],[0]
The prevalent approach to sequence to sequence learning maps an input sequence to a variable length output sequence via recurrent neural networks.,abstractText,[0],[0]
"We introduce an architecture based entirely on convolutional neural networks.1 Compared to recurrent models, computations over all elements can be fully parallelized during training to better exploit the GPU hardware and optimization is easier since the number of non-linearities is fixed and independent of the input length.",abstractText,[0],[0]
Our use of gated linear units eases gradient propagation and we equip each decoder layer with a separate attention module.,abstractText,[0],[0]
"We outperform the accuracy of the deep LSTM setup of Wu et al. (2016) on both WMT’14 English-German and WMT’14 English-French translation at an order of magnitude faster speed, both on GPU and CPU.",abstractText,[0],[0]
Convolutional Sequence to Sequence Learning,title,[0],[0]
"The areas of multi-agent planning and control have witnessed a recent wave of strong interest due to the practical desire to deal with complex real-world problems, such as smart-grid control, autonomous vehicles planning, managing teams of robots for emergency response, among others.",1. Introduction,[0],[0]
"From the learning perspective, (cooperative) multi-agent learning is not a new area of research (Stone & Veloso, 2000; Panait & Luke, 2005).",1. Introduction,[0],[0]
"However, compared to the progress in conventional supervised learning and singleagent reinforcement learning, the successes of multi-agent learning have remained relatively modest.",1. Introduction,[0],[0]
"Most notably, multi-agent learning suffers from extremely high dimensionality of both the state and actions spaces, as well as relative lack of data sources and experimental testbeds.
",1. Introduction,[0],[0]
"1California Institute of Technology, Pasadena, CA 2Disney Research, Pittsburgh, PA 3STATS LLC, Chicago, IL.",1. Introduction,[0],[0]
"Correspondence to: Hoang M. Le <hmle@caltech.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"The growing availability of data sources for coordinated multi-agent behavior, such as sports tracking data (Bialkowski et al., 2014), now enables the possibility of learning multi-agent policies from demonstrations, also known as multi-agent imitation learning.",1. Introduction,[0],[0]
One particularly interesting aspect of domains such as team sports is that the agents must coordinate.,1. Introduction,[0],[0]
"For example, in the professional soccer setting depicted in Figure 1, different players must coordinate to assume different roles (e.g., defend left field).",1. Introduction,[0],[0]
"However, the roles and role assignment mechanism are unobserved from the demonstrations.",1. Introduction,[0],[0]
"Furthermore, the role for a player may change during the same play sequence.",1. Introduction,[0],[0]
"In the control community, this issue is known as “index-free” multi-agent control (Kingston & Egerstedt, 2010).
",1. Introduction,[0],[0]
"Motivated by these challenges, we study the problem of imitation learning for multiple coordinating agents from demonstrations.",1. Introduction,[1.0],"['Motivated by these challenges, we study the problem of imitation learning for multiple coordinating agents from demonstrations.']"
"Many realistic multi-agent settings require coordination among collaborative agents to achieve some common goal (Guestrin et al., 2002; Kok et al., 2003).",1. Introduction,[0],[0]
"Beyond team sports, other examples include learning policies for game AI, controlling teams of multiple robots, or modeling collective animal behavior.",1. Introduction,[0],[0]
"As discussed above, we are interested in settings where agents have access to the outcome of actions from other agents, but the coordination mechanism is neither clearly defined nor observed, which makes the full state only partially observable.
",1. Introduction,[0],[0]
"We propose a semi-supervised learning framework that integrates and builds upon conventional imitation learning and unsupervised, or latent, structure learning.",1. Introduction,[0],[0]
"The latent
structure model encodes a coordination mechanism, which approximates the implicit coordination in the demonstration data.",1. Introduction,[0],[0]
"In order to make learning tractable, we develop an alternating optimization method that enables integrated and efficient training of both individual policies and the latent structure model.",1. Introduction,[0],[0]
"For learning individual policies, we extend reduction-based single-agent imitation learning approaches into multi-agent domain, utilizing powerful black-box supervised techniques such as deep learning as base routines.",1. Introduction,[0],[0]
"For latent structure learning, we develop a stochastic variational inference approach.
",1. Introduction,[0],[0]
We demonstrate the effectiveness of our method in two settings.,1. Introduction,[0],[0]
The first is a synthetic experiment based on the popular predator-prey game.,1. Introduction,[0],[0]
"The second is a challenging task of learning multiple policies for team defense in professional soccer, using a large training set1 of play sequences illustrated by Figure 1.",1. Introduction,[1.0],"['The second is a challenging task of learning multiple policies for team defense in professional soccer, using a large training set1 of play sequences illustrated by Figure 1.']"
We show that learning a good latent structure to encode implicit coordination yields significantly superior imitation performance compared to conventional baselines.,1. Introduction,[1.0],['We show that learning a good latent structure to encode implicit coordination yields significantly superior imitation performance compared to conventional baselines.']
"To the best of our knowledge, this is the first time an imitation learning approach has been applied to jointly learn cooperative multi-agent policies at large scale.",1. Introduction,[0],[0]
"In coordinated multi-agent imitation learning, we have K agents acting in coordination to achieve a common goal (or sequence of goals).",2. Problem Formulation,[1.0],"['In coordinated multi-agent imitation learning, we have K agents acting in coordination to achieve a common goal (or sequence of goals).']"
Training data D consists of multiple demonstrations of K agents.,2. Problem Formulation,[0],[0]
"Importantly, we assume the identity (or indexing) of the K experts may change from one demonstration to another.",2. Problem Formulation,[1.0],"['Importantly, we assume the identity (or indexing) of the K experts may change from one demonstration to another.']"
"Each (unstructured) set of demonstrations is denoted by U “ tU1, . . .",2. Problem Formulation,[0],[0]
", UKu, where Uk “ tut,kuTt“1 is the sequence of actions by agent k at time t. Note that each set of demonstrations can have varying sequence length T. Let C “ tctuTt“1 be the context associated with each demonstration sequence.
Policy Learning.",2. Problem Formulation,[0],[0]
"Our ultimate goal is to learn a (largely) decentralized policy, but for clarity we first present the problem of learning a fully centralized multi-agent policy.",2. Problem Formulation,[1.0],"['Our ultimate goal is to learn a (largely) decentralized policy, but for clarity we first present the problem of learning a fully centralized multi-agent policy.']"
"Following the notation of (Ross et al., 2011), let ~πp~sq :“ ~a denote the joint policy that maps the joint state, ~s “ rs1, . . .",2. Problem Formulation,[0],[0]
", sKs, of all K agents into K actions ~a “ ra1, . . .",2. Problem Formulation,[0],[0]
", aKs.",2. Problem Formulation,[0],[0]
"The goal is to minimize imitation loss:
Limitation “ E~s„d~π r`p~πp~sqqs ,
where d~π denotes the distribution of states experienced by joint policy ~π and ` is the imitation loss defined over the demonstrations (e.g., squared loss for deterministic policies, or cross entropy for stochastic policies).
",2. Problem Formulation,[0.9999999696698368],"['The goal is to minimize imitation loss: Limitation “ E~s„d~π r`p~πp~sqqs , where d~π denotes the distribution of states experienced by joint policy ~π and ` is the imitation loss defined over the demonstrations (e.g., squared loss for deterministic policies, or cross entropy for stochastic policies).']"
"The decentralized setting decomposes the joint policy ~π “ 1Data at http://www.stats.com/data-science/ and see video result at http://hoangminhle.github.io
rπ1, . . .",2. Problem Formulation,[0],[0]
", πKs into K policies, each tailored to a specific agent index or “role”.2 The loss function is then:
",2. Problem Formulation,[0],[0]
"Limitation “ K ÿ
k“1 Es„dπk r`pπkpskqqs .
",2. Problem Formulation,[0],[0]
Black-Box Policy Classes.,2. Problem Formulation,[0],[0]
"In order to leverage powerful black-box policy classes such as random forests and deep learning, we take a learning reduction approach to training ~π.",2. Problem Formulation,[0],[0]
"One consequence is that the state space representation s “ rs1, . . .",2. Problem Formulation,[0],[0]
", sKs must be consistently indexed, e.g., agent k in one instance must correspond to agent k in another instance.",2. Problem Formulation,[0],[0]
"This requirement applies for both centralized and decentralized policy learning, and is often implicitly assumed in prior work on multi-agent learning.",2. Problem Formulation,[1.0],"['This requirement applies for both centralized and decentralized policy learning, and is often implicitly assumed in prior work on multi-agent learning.']"
"A highly related issue arises in distributed control of index-free coordinating robots, e.g., to maintain a defined formation (Kloder & Hutchinson, 2006; Kingston & Egerstedt, 2010).
",2. Problem Formulation,[0],[0]
Motivating example: Soccer Domain.,2. Problem Formulation,[0],[0]
"Consider the task of imitating professional soccer players, where training data includes play sequences from different teams and games.",2. Problem Formulation,[0],[0]
Context C corresponds to the behavior of the opposing team and the ball.,2. Problem Formulation,[0],[0]
"The data includes multiple sequences of K-set of trajectories U “ tU1, U2, . . .",2. Problem Formulation,[0],[0]
", UKu, where the actual identity of player generating Uk may change from one demonstration to the next.
",2. Problem Formulation,[0],[0]
One important challenge for black-box policy learning is constructing an indexing mechanism over the agents to yield a consistent state representation.,2. Problem Formulation,[0],[0]
"For example, the same index should correspond to the “left defender” in all instances.",2. Problem Formulation,[0],[0]
"Otherwise, the inputs to the policy will be inconsistent, making learning difficult if not impossible.",2. Problem Formulation,[0],[0]
"Note that barring extensive annotations or some heuristic rulebased definitions, it is unnatural to quantitatively define what makes a player “left defender”.",2. Problem Formulation,[1.0],"['Note that barring extensive annotations or some heuristic rulebased definitions, it is unnatural to quantitatively define what makes a player “left defender”.']"
"In addition, even if we had a way to define who the “left defender” is, he may not stay in the same role during the same sequence.
",2. Problem Formulation,[0],[0]
Role-based Indexing.,2. Problem Formulation,[0],[0]
We address index-free policy learning via role learning and role-based index assignment.,2. Problem Formulation,[0],[0]
"To motivate our notion of role, let’s first consider the simplest indexing mechanism: one could equate role to agent identity.",2. Problem Formulation,[1.0],"['To motivate our notion of role, let’s first consider the simplest indexing mechanism: one could equate role to agent identity.']"
"However, the data often comes from various sequences, with heterogeneous identities and teams of agents.",2. Problem Formulation,[0],[0]
"Thus instead of learning identity-specific policies, it is more natural and data-efficient to learn a policy per role.",2. Problem Formulation,[0],[0]
"However, a key challenge in learning policies directly is that the roles are undefined, unobserved, and could change dynamically within the same sequence.",2. Problem Formulation,[1.0],"['However, a key challenge in learning policies directly is that the roles are undefined, unobserved, and could change dynamically within the same sequence.']"
"We thus view learning the coordination, via role assignment, as an unsupervised structured prediction problem.
",2. Problem Formulation,[0],[0]
"2It is straightforward to extend our formulation to settings where multiple agents can occupy the same role, and where not all roles are occupied across all execution sequences.
",2. Problem Formulation,[0],[0]
Coordination via Structured Role Assignment.,2. Problem Formulation,[0],[0]
"Instead of handcrafting the definition of roles, we learn the roles in an unsupervised fashion, without attaching any semantic labels to the roles.",2. Problem Formulation,[0],[0]
"At the same time, role transition should obey certain structural regularity, due to coordination.",2. Problem Formulation,[0],[0]
"This motivates using graphical models to represent the coordination structure.
",2. Problem Formulation,[0],[0]
Coordinated Policy Learning.,2. Problem Formulation,[0],[0]
"We formulate the indexing mechanism as an assignment function A which maps the unstructured set U and some probabilistic structured model q to an indexed set of trajectory A rearranged from U , i.e.,
A : tU1, .., UKu ˆ q ÞÑ rA1, .., AKs ,
where the set tA1, .., AKu ” tU1, .., UKu.",2. Problem Formulation,[1.0000000116140355],"['We formulate the indexing mechanism as an assignment function A which maps the unstructured set U and some probabilistic structured model q to an indexed set of trajectory A rearranged from U , i.e., A : tU1, .., UKu ˆ q ÞÑ rA1, .., AKs , where the set tA1, .., AKu ” tU1, .., UKu.']"
We view q as a latent variable model that infers the role assignments for each set of demonstrations.,2. Problem Formulation,[1.0],['We view q as a latent variable model that infers the role assignments for each set of demonstrations.']
"Thus, q drives the indexing mechanismA so that state vectors can be consistently constructed to facilitate optimizing for the imitation loss.
",2. Problem Formulation,[0],[0]
"We employ entropy regularization, augmenting the imitation loss with some low entropy penalty (Grandvalet et al., 2004; Dudik et al., 2004), yielding our overall objective:
min π1,..,πK ,A
K ÿ k“1 Esk„dπk r`pπkpskqq|A,Ds´λHpA|Dq (1)
where both imitation loss and entropy are measured with respect to the state distribution induced by the policies, and D is training data.",2. Problem Formulation,[0],[0]
"This objective can also be seen as maximizing the mutual information between latent structure and observed trajectories (Krause et al., 2010).",2. Problem Formulation,[0],[0]
Optimizing (1) is challenging for two reasons.,3. Learning Approach,[0],[0]
"First, beyond the challenges inherited from single-agent settings, multi-agent imitation learning must account for multiple simultaneously learning agents, which is known to cause non-stationarity for multi-agent reinforcement learning (Busoniu et al., 2008).",3. Learning Approach,[0],[0]
"Second, the latent role assignment model, which forms the basis for coordination, depends on the actions of the learning policies, which in turn depend on the structured role assignment.
",3. Learning Approach,[0],[0]
"Algorithm 1 Coordinated Multi-Agent Imitation Learning Input: Multiple unstructured trajectory sets U “ tU1, . . .",3. Learning Approach,[0],[0]
", UKu
with Uk “ tut,kuTt“1 and context C “ tctuTt“1.",3. Learning Approach,[0],[0]
"Input: Graphical model q with global/local parameters θ and z. Input: Initialized policies πk, k “ 1, . . .",3. Learning Approach,[0],[0]
",K Input: Step size sequence ρn, n “ 1, 2, . . .",3. Learning Approach,[0],[0]
"1: repeat 2: rA1, . . .",3. Learning Approach,[0],[0]
", AKs Ð AssigntU1, . .",3. Learning Approach,[0],[0]
.,3. Learning Approach,[0],[0]
", UK |qpθ, zqu 3: rπ1, . . .",3. Learning Approach,[0],[0]
", πKs Ð Learn rA1, . . .",3. Learning Approach,[0],[0]
", AK , Cs 4: Roll-out π1, . . .",3. Learning Approach,[0],[0]
", πK to obtain pA1, . .",3. Learning Approach,[0],[0]
.,3. Learning Approach,[0],[0]
", pAK 5: Ak Ð pAk @k
(Alternatively: Ak Ð pAk with prob η for η Ñ 1) 6: qpθ, zq Ð LearnStructuretA1, . . .",3. Learning Approach,[0],[0]
", AK , C, θ, ρnu 7: until No improvement on validation set
output K policies π1, π2, . . .",3. Learning Approach,[0],[0]
", πK
We propose an alternating optimization approach to solving (1), summarized in Figure 2.",3. Learning Approach,[0],[0]
"The main idea is to integrate imitation learning with unsupervised structure learning by taking turns to (i) optimize for imitation policies while fixing a structured model (minimizing imitation loss), and (ii) re-train the latent structure model and reassign roles while fixing the learning policies (maximizing role assignment entropy).",3. Learning Approach,[0],[0]
The alternating nature allows us to circumvent the circular dependency between policy learning and latent structure learning.,3. Learning Approach,[0],[0]
"Furthermore, for (i) we develop a stable multi-agent learning reduction approach.",3. Learning Approach,[0],[0]
Algorithm 1 outlines our framework.,3.1. Approach Outline,[0],[0]
We assume the latent structure model for computing role assignments is formulated as a graphical model.,3.1. Approach Outline,[0],[0]
"The multi-agent policy training procedure Learn utilizes a reduction approach, and can leverage powerful off-the-shelf supervised learning tools such as deep neural networks (Hochreiter & Schmidhuber, 1997).",3.1. Approach Outline,[0],[0]
The structure learning LearnStructure and role assignment Assign components are based on graphical model training and inference.,3.1. Approach Outline,[0],[0]
"For efficient training, we employ alternating stochastic optimization (Hoffman et al., 2013; Johnson & Willsky, 2014; Beal, 2003) on the same mini-batches.",3.1. Approach Outline,[1.0],"['For efficient training, we employ alternating stochastic optimization (Hoffman et al., 2013; Johnson & Willsky, 2014; Beal, 2003) on the same mini-batches.']"
"Note that batch training can be deployed similarly, as illustrated by one of our experiments.
",3.1. Approach Outline,[0],[0]
We interleave the three components described above into a complete learning algorithm.,3.1. Approach Outline,[1.0],['We interleave the three components described above into a complete learning algorithm.']
"Given an initially unstructured set of training data, an initialized set of policies, and prior parameters of the structure model, Algorithm 1 performs alternating structure optimization on each mini-batch (size 1 in Algorithm 1).
",3.1. Approach Outline,[0],[0]
"• Line 2: Role assignment is performed on trajectories tA1, . . .",3.1. Approach Outline,[0],[0]
", AKu",3.1. Approach Outline,[0],[0]
by running inference procedure (Algorithm 4).,3.1. Approach Outline,[0],[0]
"The result is an ordered set rA1, . . .",3.1. Approach Outline,[0],[0]
", AKs, where trajectory Ak corresponds to policy πk.
•",3.1. Approach Outline,[0],[0]
"Line 3-5: Each policy πk is updated using joint multiagent training on the ordered set rA1, . . .",3.1. Approach Outline,[0],[0]
", AK , Cs
(Algorithm 2).",3.1. Approach Outline,[0],[0]
"The updated models are executed to yield a rolled-out set of trajectories, which replace the previous set of trajectories tAku.
",3.1. Approach Outline,[0],[0]
"• Line 6: Parameters of latent structured model are updated from the rolled-out trajectories (Algorithm 3).
",3.1. Approach Outline,[0],[0]
"The algorithm optionally includes a mixing step on line 5, where the rolled-out trajectories may replace the training trajectories with increasing probability approaching 1, which is similar to scheduled sampling (Bengio et al., 2015), and may help stabilize learning in the early phase of the algorithm.",3.1. Approach Outline,[0],[0]
"In our main experiment, we do not notice a performance gain using this option.",3.1. Approach Outline,[0],[0]
In this section we describe the Learn procedure for multiagent imitation learning in Line 3 of Algorithm 1.,3.2. Joint Multi-Agent Imitation Learning,[0],[0]
"As background, for single agent imitation learning, reductionbased methods operate by iteratively collecting a new data set Dn at each round n of training, consisting of stateaction pairs pst, a˚t q where a˚t is some optimal or demonstrated action given state st.",3.2. Joint Multi-Agent Imitation Learning,[0],[0]
"A new policy can be formed by (i) combining a new policy from this data set Dn with previously learned policy π (Daumé III et al., 2009) or (ii) learning a new policy π directly from the data set formed by aggregating D1, . . .",3.2. Joint Multi-Agent Imitation Learning,[0],[0]
",Dn (Ross et al., 2011).",3.2. Joint Multi-Agent Imitation Learning,[0],[0]
"Other variants exist although we do not discuss them here.
",3.2. Joint Multi-Agent Imitation Learning,[0],[0]
The intuition behind the iterative reduction approach is to prevent a mismatch in training and prediction distributions due to sequential cascading errors (also called covariateshift).,3.2. Joint Multi-Agent Imitation Learning,[0],[0]
"The main idea is to use the learned policy’s own predictions in the construction of subsequent states, thus simulating the test-time performance during training.",3.2. Joint Multi-Agent Imitation Learning,[0],[0]
This mechanism enables the agent to learn a policy that is robust to its own mistakes.,3.2. Joint Multi-Agent Imitation Learning,[0],[0]
Reduction-based methods also accommodate any black-box supervised training subroutine.,3.2. Joint Multi-Agent Imitation Learning,[0],[0]
"We focus on using expressive function classes such as Long Short-Term Memory networks (LSTM) (Hochreiter & Schmidhuber, 1997) as the policy class.3
Algorithm 2 outlines the Learn procedure for stable multi-agent imitation learning.",3.2. Joint Multi-Agent Imitation Learning,[0],[0]
"Assume we are given consistently indexed demonstrations A “ rA1, . . .",3.2. Joint Multi-Agent Imitation Learning,[0],[0]
", AKs, where each Ak “ tat,kuTt“1 corresponds action of policy πk.",3.2. Joint Multi-Agent Imitation Learning,[0],[0]
"Let the corresponding expert action be a˚t,k.",3.2. Joint Multi-Agent Imitation Learning,[0],[0]
"To lighten the notation, we denote the per-agent state vector by st,k “ ϕkprat,1, . . .",3.2. Joint Multi-Agent Imitation Learning,[0],[0]
", at,k, . . .",3.2. Joint Multi-Agent Imitation Learning,[0],[0]
", at,K , ctsq4
3Note that conventional training of LSTMs does not address the cascading error problem.",3.2. Joint Multi-Agent Imitation Learning,[0],[0]
"While LSTMs are very good at sequence-to-sequence prediction tasks, they cannot naturally deal with the drifting of input state distribution drift caused by action output feedback in dynamical systems (Bengio et al., 2015).
",3.2. Joint Multi-Agent Imitation Learning,[0],[0]
"4Generally, state vector st,k of policy πk at time t can be constructed as st,k “ rφkpra1:t,1, c1:tsq, . . .",3.2. Joint Multi-Agent Imitation Learning,[0],[0]
", φkpra1:t,K , c1:",3.2. Joint Multi-Agent Imitation Learning,[0],[0]
"tsqs
Algorithm 2 Joint Multi-Agent Imitation Learning LearnpA1, A2, . . .",3.2. Joint Multi-Agent Imitation Learning,[0],[0]
", AK , Cq Input: Ordered actions Ak “ tat,kuTt“1 @k, context tctuTt“1 Input: Initialized policies π1, . . .",3.2. Joint Multi-Agent Imitation Learning,[0],[0]
", πK",3.2. Joint Multi-Agent Imitation Learning,[0],[0]
"Input: base routine TrainpS,Aq mapping state to actions 1: Set increasing prediction horizon j P t1, . . .",3.2. Joint Multi-Agent Imitation Learning,[0],[0]
", T u 2: for t “ 0, j, 2j, . . .",3.2. Joint Multi-Agent Imitation Learning,[0],[0]
", T do 3: for i “ 0, 1, . . .",3.2. Joint Multi-Agent Imitation Learning,[0],[0]
",",3.2. Joint Multi-Agent Imitation Learning,[0],[0]
"j ´ 1 do 4: Roll-out ât`i,k “ πkpŝt`i´1,kq @ agent k 5: Cross-update for each policy k P t1, . . .",3.2. Joint Multi-Agent Imitation Learning,[0],[0]
",Ku
ŝt`i,k “ ϕk prât`i,1, . . .",3.2. Joint Multi-Agent Imitation Learning,[0],[0]
", ât`i,k, . . .",3.2. Joint Multi-Agent Imitation Learning,[0],[0]
", ât`i,K , ct`isq 6: end for 7: Policy update for all agent k
πk",3.2. Joint Multi-Agent Imitation Learning,[0],[0]
"Ð Trainptŝt`i,k, a˚t`i`1,ku j i“0q
8: end for output K updated policies π1, π2, . . .",3.2. Joint Multi-Agent Imitation Learning,[0],[0]
", πK
Algorithm 2 employs a roll-out horizon j, which divides the entire trajectory into T {j segments.",3.2. Joint Multi-Agent Imitation Learning,[0],[0]
"The following happens for every segment:
• Iteratively perform roll-out at each time step i for all K policies (line 4) to obtain actions tpai,ku.
•",3.2. Joint Multi-Agent Imitation Learning,[0],[0]
"Each policy simultaneously updates its state psi,k, using the prediction from all other policies (line 5).
",3.2. Joint Multi-Agent Imitation Learning,[0],[0]
"• At the end of the current segment, all policies are updated using the error signal from the deviation between predicted pai,k versus expert action a˚i,k, for all i along the sub-segment (line 7).
",3.2. Joint Multi-Agent Imitation Learning,[0],[0]
"After policy updates, the training moves on to the next jlength sub-segment, using the freshly updated policies for subsequent roll-outs.",3.2. Joint Multi-Agent Imitation Learning,[0],[0]
The iteration proceeds until the end of the sequence is reached.,3.2. Joint Multi-Agent Imitation Learning,[0],[0]
"In the outer loop the roll-out horizon j is incremented.
",3.2. Joint Multi-Agent Imitation Learning,[0],[0]
"Two key insights behind our approach are:
•",3.2. Joint Multi-Agent Imitation Learning,[0],[0]
"In addition to the training-prediction mismatch issue in single-agent learning, each agent’s prediction must also be robust to imperfect predictions from other agents.",3.2. Joint Multi-Agent Imitation Learning,[0],[0]
"This non-stationarity issue also arises in multiagent reinforcement learning (Busoniu et al., 2008) when agents learn simultaneously.",3.2. Joint Multi-Agent Imitation Learning,[0],[0]
"We perform joint training by cross-updating each agent’s state using previous predictions from other agents.
",3.2. Joint Multi-Agent Imitation Learning,[0],[0]
• Many single-agent imitation learning algorithms assume the presence of a dynamic oracle to provide onestep corrections a˚t along the roll-out trajectories.,3.2. Joint Multi-Agent Imitation Learning,[0],[0]
"In practice, dynamic oracle feedback is very expensive to obtain and some recent work have attempted to relax this requirement (Le et al., 2016; Ho & Ermon, 2016).",3.2. Joint Multi-Agent Imitation Learning,[0],[0]
"Without dynamic oracles, the rolled-out trajectory can deviate significantly from demonstrated trajectories when the prediction horizon j is large (« T ), leading to training instability.",3.2. Joint Multi-Agent Imitation Learning,[0],[0]
"Thus j is gradually increased to allow for slowly learning to make good sequential predictions over longer horizons.
",3.2. Joint Multi-Agent Imitation Learning,[0],[0]
"For efficient training, we focus on stochastic optimization, which can invoke base routine Train multiple times and thus naturally accommodates varying j. Note that the batch-training alternatives to Algorithm 2 can also employ similar training schemes, with similar theoretical guarantees lifted to the multi-agent case.",3.2. Joint Multi-Agent Imitation Learning,[0],[0]
"The Appendix shows how to use DAgger (Ross et al., 2011) for Algorithm 2, which we used for our synthetic experiment.",3.2. Joint Multi-Agent Imitation Learning,[0],[0]
The coordination mechanism is based on a latent structured model that governs the role assignment.,3.3. Coordination Structure Learning,[0],[0]
"The training and inference procedures seek to address two main issues:
• LearnStructure:",3.3. Coordination Structure Learning,[0],[0]
"unsupervised learning a probabilistic role assignment model q.
• Assign: how q informs the indexing mechanism so that unstructured trajectories can be mapped to structured trajectories amenable to Algorithm 2.
",3.3. Coordination Structure Learning,[0],[0]
"Given an arbitrarily ordered set of trajectories U “ tU1, . . .",3.3. Coordination Structure Learning,[0],[0]
", UK , Cu, let the coordination mechanism underlying each such U be governed by a true unknown model p, with global parameters θ.",3.3. Coordination Structure Learning,[0],[0]
We suppress the agent/policy subscript and consider a generic featurized trajectory xt,3.3. Coordination Structure Learning,[0],[0]
"“ rut, cts @t.",3.3. Coordination Structure Learning,[0],[0]
Let the latent role sequence for the same agent be z “ z1:T .,3.3. Coordination Structure Learning,[0],[0]
"At any time t, each agent is acting according to a latent role zt „ Categoricalt1̄, 2̄, . . .",3.3. Coordination Structure Learning,[0],[0]
", K̄u, which are the local parameters to the structured model.
",3.3. Coordination Structure Learning,[0],[0]
"Ideally, role and index asignment can be obtained by calculating the true posterior ppz|x, θq, which is often intractable.",3.3. Coordination Structure Learning,[0],[0]
"We instead aim to approximate ppz|x, θq by a simpler distribution q via techniques from stochastic variational inference (Hoffman et al., 2013), which allows for efficient stochastic training on mini-batches that can naturally integrate with our imitation learning subroutine.
",3.3. Coordination Structure Learning,[0],[0]
"In variational inference, posterior approximation is often cast as optimizing over a simpler model classQ, via searching for parameters θ and z that maximize the evidence lower bound (ELBO)",3.3. Coordination Structure Learning,[0],[0]
"L:
L pqpz,",3.3. Coordination Structure Learning,[0],[0]
"θqq fi Eq rln ppz, θ, xqs",3.3. Coordination Structure Learning,[0],[0]
"´ Eq rln qpz, θqs ď ln ppxq
Maximizing L is equivalent to finding q P Q to minimize the KL divergence KL pqpz, θ|xq||ppz, θ|xqq.",3.3. Coordination Structure Learning,[0],[0]
"We focus on the structured mean-field variational family, which factorizes q as qpz, θq “ qpzqqpθq.",3.3. Coordination Structure Learning,[0],[0]
"This factorization breaks the dependency between θ and z, but not between single latent states zt, unlike variational inference for i.i.d data (Kingma & Welling, 2013).",3.3. Coordination Structure Learning,[0],[0]
The procedure to learn the parameter of our structured model is summarized in Algorithm 3.,3.3.1. TRAINING TO LEARN MODEL PARAMETERS,[0],[0]
"Parameter learning
Algorithm 3 Structure Learning LearnStructure tU1, . . .",3.3.1. TRAINING TO LEARN MODEL PARAMETERS,[0],[0]
", UK , C, θ, ρu ÞÑ qpθ, zq",3.3.1. TRAINING TO LEARN MODEL PARAMETERS,[0],[0]
"Input: Xk “ txt,kuTt“1 “ trut,k, ctsu @t, k.X “ tXkuKk“1
Graphical model parameters θ, stepsize ρ 1: Local update: compute qpzq via message-passing while fix-
ing θ",3.3.1. TRAINING TO LEARN MODEL PARAMETERS,[0],[0]
(See Appendix for derivations),3.3.1. TRAINING TO LEARN MODEL PARAMETERS,[0],[0]
"2: Global parameter update: via natural gradient ascent θ Ð θp1´ ρq ` ρpθprior ` bJEqpzq rtpz, xqsq
output Updated model qpθ, zq “ qpθqqpzq
proceeds via alternating updates over the factors qpθq and qpzq, while keeping other factor fixed.",3.3.1. TRAINING TO LEARN MODEL PARAMETERS,[0],[0]
Stochastic variational inference performs such updates efficiently in minibatches.,3.3.1. TRAINING TO LEARN MODEL PARAMETERS,[0],[0]
We slightly abuse notations and overload θ for the natural parameters of global parameter θ in the exponential family.,3.3.1. TRAINING TO LEARN MODEL PARAMETERS,[1.0],['We slightly abuse notations and overload θ for the natural parameters of global parameter θ in the exponential family.']
"Assuming the usual conjugacy in the exponential family, the stochastic natural gradient takes a convenient form (line 2 of Algo 3, and derivation in Appendix), where tpz, xq is the vector of sufficient statistics, b is a vector of scaling factors adjusting for the relative size of the minibatches.",3.3.1. TRAINING TO LEARN MODEL PARAMETERS,[1.0],"['Assuming the usual conjugacy in the exponential family, the stochastic natural gradient takes a convenient form (line 2 of Algo 3, and derivation in Appendix), where tpz, xq is the vector of sufficient statistics, b is a vector of scaling factors adjusting for the relative size of the minibatches.']"
"Here the global update assumes optimal local update qpzq has been computed.
",3.3.1. TRAINING TO LEARN MODEL PARAMETERS,[0],[0]
"Fixing the global parameters, the local updates are based on message-passing over the underlying graphical model.",3.3.1. TRAINING TO LEARN MODEL PARAMETERS,[0],[0]
The exact mathematical derivation depends on the specific graph structure.,3.3.1. TRAINING TO LEARN MODEL PARAMETERS,[0],[0]
"The simplest scenario is to assume independence among zt’s, which resembles naive Bayes.",3.3.1. TRAINING TO LEARN MODEL PARAMETERS,[0],[0]
"In our experiments, we instead focus on Hidden Markov Models to capture first-order dependencies in role transitions over play sequences.",3.3.1. TRAINING TO LEARN MODEL PARAMETERS,[0],[0]
"In that case, line 1 of Algorithm 3 resembles running the forward-backward algorithm to compute the update qpzq.",3.3.1. TRAINING TO LEARN MODEL PARAMETERS,[0],[0]
The forward-backward algorithm in the local update step takes OpK2T q time for a chain of length T and K hidden states.,3.3.1. TRAINING TO LEARN MODEL PARAMETERS,[0],[0]
"For completeness, derivation of parameter learning for HMMs is included in the Appendix.",3.3.1. TRAINING TO LEARN MODEL PARAMETERS,[0],[0]
"We can compute two types of inference on a learned q:
Role inference.",3.3.2. INFERENCE FOR ROLE AND INDEX ASSIGNMENT,[0],[0]
"Compute the most likely role sequence tzt,kuTt“1 P t1̄, . . .",3.3.2. INFERENCE FOR ROLE AND INDEX ASSIGNMENT,[0],[0]
", K̄uT , e.g., using Viterbi (or dynamic programming-based forward message passing for graph structures).",3.3.2. INFERENCE FOR ROLE AND INDEX ASSIGNMENT,[0],[0]
"This most likely role sequence for agent k, which is the low-dimensional representation of the coordination mechanism, can be used to augment the contextual feature tctuTt“1for each agent’s policy training.
",3.3.2. INFERENCE FOR ROLE AND INDEX ASSIGNMENT,[0],[0]
Role-based Index Assignment Transform the unstructured set U into an ordered set of trajectories A to facilitate the imitation learning step.,3.3.2. INFERENCE FOR ROLE AND INDEX ASSIGNMENT,[0],[0]
This is the more important task for the overall approach.,3.3.2. INFERENCE FOR ROLE AND INDEX ASSIGNMENT,[0],[0]
The intuitive goal of an indexing mechanism is to facilitate consistent agent trajectory to policy mapping.,3.3.2. INFERENCE FOR ROLE AND INDEX ASSIGNMENT,[0],[0]
Assume for notational convenience that we want index k assigned to an unique agent who is most likely assuming role k̄.,3.3.2. INFERENCE FOR ROLE AND INDEX ASSIGNMENT,[0],[0]
"Our inference technique rests on the
Algorithm 4 Multi-Agent Role Assignment Assign tU1, . . .",3.3.2. INFERENCE FOR ROLE AND INDEX ASSIGNMENT,[0],[0]
", UK |qu ÞÑ rA1, . . .",3.3.2. INFERENCE FOR ROLE AND INDEX ASSIGNMENT,[0],[0]
", AKs",3.3.2. INFERENCE FOR ROLE AND INDEX ASSIGNMENT,[0],[0]
"Input: Approximate inference model q. Unordered trajectories
U “ tUkuKk“1. 1: Calculate cost matrix M P RKˆK per equation 2 2: AÐ MinCostAssignmentpMq
output Ak “ UApkq @k “ 1, 2, . . .",3.3.2. INFERENCE FOR ROLE AND INDEX ASSIGNMENT,[0],[0]
",K
well-known Linear Assignment Problem (Papadimitriou & Steiglitz, 1982), which is solved optimally via the KuhnMunkres algorithm.",3.3.2. INFERENCE FOR ROLE AND INDEX ASSIGNMENT,[0],[0]
"Specifically, construct the cost matrix M as:
M “M1 dM2 (2)
M1 “ “ qptxt,ku|zt,k “ k̄q ‰ “ « T ź
t“1 qpxt,k|zt,k “ k̄q
ff
M2 “ “ ln qptxt,ku|zt,k “ k̄q ‰",3.3.2. INFERENCE FOR ROLE AND INDEX ASSIGNMENT,[0],[0]
"“ « T ÿ
t“1 ln qpxt,k|zt,k “ k̄q
ff
where k “ 1, . . .",3.3.2. INFERENCE FOR ROLE AND INDEX ASSIGNMENT,[0],[0]
",K, k̄ “ 1̄, . . .",3.3.2. INFERENCE FOR ROLE AND INDEX ASSIGNMENT,[0],[0]
", K̄,d is the Hadamard product, and matrices M1,M2 take advantage of the Markov property of the graphical model.",3.3.2. INFERENCE FOR ROLE AND INDEX ASSIGNMENT,[0],[0]
"Now solving the linear assignment problem for cost matrix M , we obtain the matching A from role k̄ to index k, such that the total cost per agent is minimized.",3.3.2. INFERENCE FOR ROLE AND INDEX ASSIGNMENT,[1.0],"['Now solving the linear assignment problem for cost matrix M , we obtain the matching A from role k̄ to index k, such that the total cost per agent is minimized.']"
"From here, we rearrange the unordered set tU1, . . .",3.3.2. INFERENCE FOR ROLE AND INDEX ASSIGNMENT,[0],[0]
", UKu to the ordered sequence rA1, . . .",3.3.2. INFERENCE FOR ROLE AND INDEX ASSIGNMENT,[0],[0]
", AKs ” rUAp1q, . . .",3.3.2. INFERENCE FOR ROLE AND INDEX ASSIGNMENT,[0],[0]
", UApKqs according to the minimum cost mapping.
",3.3.2. INFERENCE FOR ROLE AND INDEX ASSIGNMENT,[0],[0]
"To see why this index assignment procedure results in an increased entropy in the original objective (1), notice that: HpA|Dq « ´ K ÿ
k̄“1
P pk̄qqpApAkq “ k̄q log qpApAkq “ k̄q
“ ´ 1 K
K ÿ
k̄“1
Mpk̄, kq,
where we assume each latent role k̄ has equal probability.",3.3.2. INFERENCE FOR ROLE AND INDEX ASSIGNMENT,[0],[0]
The RHS increases from the linear assignment and consequent role assignment procedure.,3.3.2. INFERENCE FOR ROLE AND INDEX ASSIGNMENT,[0],[0]
Our inference procedure to perform role assignment is summarized in Algorithm 4.,3.3.2. INFERENCE FOR ROLE AND INDEX ASSIGNMENT,[0],[0]
We present empirical results from two settings.,4. Experiments,[0],[0]
"The first is a synthetic setting based on predator-prey, where the goal is to imitate a coordinating team of predators.",4. Experiments,[0],[0]
"The second is a large-scale imitation learning setting from player trajectores in professional soccer games, where the goal is to imitate defensive team play.",4. Experiments,[0],[0]
Setting.,4.1. Predator-Prey Domain,[0],[0]
"The predator-prey problem, also frequently called the Pursuit Domain (Benda, 1985), is a popular setting for
multi-agent reinforcement learning.",4.1. Predator-Prey Domain,[0],[0]
"The traditional setup is with four predators and one prey, positioned on a grid board.",4.1. Predator-Prey Domain,[0],[0]
"At each time step, each agent has five moves:
N,S,E,W or no move.",4.1. Predator-Prey Domain,[0],[0]
The world is toroidal: the agents can move off one end of the board and come back on the other end.,4.1. Predator-Prey Domain,[0],[0]
"Agents make move simultaneously, but two agents cannot occupy the same position, and
collisions are avoided by assigning a random move priority to the agents at each time step.",4.1. Predator-Prey Domain,[0],[0]
The predators can capture the prey only if the prey is surrounded by all four predators.,4.1. Predator-Prey Domain,[0],[0]
"The goal of the predators is to capture the prey as fast as possible, which necessarily requires coordination.
",4.1. Predator-Prey Domain,[0],[0]
Data.,4.1. Predator-Prey Domain,[0],[0]
"The demonstration data is collected from 1000 game instances, where four experts, indexed 1 to 4, are prescribed the consistent and coordinated role as illustrated in the capture state of Figure 3.",4.1. Predator-Prey Domain,[0],[0]
"In other words, agent 1 would attempt to capture the prey on the right hand side, which allows for one fixed role for each expert throughout the game.",4.1. Predator-Prey Domain,[0],[0]
"However, the particular role assignment is hidden from the imitation learning task.",4.1. Predator-Prey Domain,[0],[0]
"Each expert is then exhaustively trained using Value Iteration (Sutton & Barto, 1998) in the reinforcement learning setting, with the reward of 1 if the agent is in the position next to the prey according to its defined role, and 0 otherwise.",4.1. Predator-Prey Domain,[0],[0]
A separate set of 100 games was collected for evaluation.,4.1. Predator-Prey Domain,[0],[0]
A game is terminated after 50 time steps if the predators fail to capture the prey.,4.1. Predator-Prey Domain,[0],[0]
"In the test set, the experts fail to capture the prey in 2% of the games, and on average take 18.3 steps to capture the prey.
",4.1. Predator-Prey Domain,[0],[0]
Experiment Setup.,4.1. Predator-Prey Domain,[0],[0]
"For this experiment, we use the batch version of Algorithm 1 (see appendix) to learn to imitate the experts using only demonstrations.",4.1. Predator-Prey Domain,[0],[0]
"Each policy is represented by a random forest of 20 trees, and were trained over 10 iterations.",4.1. Predator-Prey Domain,[0],[0]
The expert correction for each rolled-out state is collected via Value Iteration.,4.1. Predator-Prey Domain,[0],[0]
"The experts thus act as dynamic oracles, which result in a multi-agent training setting analogous to DAgger (Ross et al., 2011).",4.1. Predator-Prey Domain,[0],[0]
"We compare two versions of multi-agent imitation learning:
• Coordinated Training.",4.1. Predator-Prey Domain,[0],[0]
"We use our algorithm, with the latent structure model represented by a discrete Hidden Markov Model with binomial emission.",4.1. Predator-Prey Domain,[0],[0]
"We use Algorithm 4 to maximize the role consistency of the dynamic oracles across different games.
",4.1. Predator-Prey Domain,[0],[0]
• Unstructured Training.,4.1. Predator-Prey Domain,[0],[0]
"An arbitrary role is assigned to each dynamic oracle for each game, i.e., the agent index is meaningless.
",4.1. Predator-Prey Domain,[0],[0]
"In both versions, training was done using the same data aggregation scheme and batch training was conducted using the same random forests configuration.
",4.1. Predator-Prey Domain,[0.9999999914106686],"['In both versions, training was done using the same data aggregation scheme and batch training was conducted using the same random forests configuration.']"
Results.,4.1. Predator-Prey Domain,[0],[0]
Figure 4 compares the test performance of our method versus unstructured multi-agent imitation learning.,4.1. Predator-Prey Domain,[1.0],['Figure 4 compares the test performance of our method versus unstructured multi-agent imitation learning.']
"Our method quickly approaches expert performance (average 22 steps with 8% failure rate in the last iteration), whereas unstructured multi-agent imitation learning performance did not improve beyond the first iteration (average 42 steps with 70% failure rate).",4.1. Predator-Prey Domain,[0],[0]
"Note that we even gave the unstructured baseline some advantage over our method, by forcing the prey to select the moves last after all predators make decisions (effectively making the prey slower).",4.1. Predator-Prey Domain,[1.0],"['Note that we even gave the unstructured baseline some advantage over our method, by forcing the prey to select the moves last after all predators make decisions (effectively making the prey slower).']"
"Without this advantage, the unstructured policies fail to capture the prey almost 100% of the time.",4.1. Predator-Prey Domain,[1.0],"['Without this advantage, the unstructured policies fail to capture the prey almost 100% of the time.']"
"Also, if the same restriction is applied to the policies obtained from our method, performance would be on par with the experts (100% success rate, with similar number of steps taken).",4.1. Predator-Prey Domain,[0],[0]
Setting.,4.2. Multi-agent Imitation Learning for Soccer,[0],[0]
Soccer is a popular domain for multi-agent learning.,4.2. Multi-agent Imitation Learning for Soccer,[0],[0]
"RoboCup, the robotic and simulation soccer platform, is perhaps the most popular testbed for multi-agent reinforcement learning research to date (Stone, 2016).",4.2. Multi-agent Imitation Learning for Soccer,[1.0],"['RoboCup, the robotic and simulation soccer platform, is perhaps the most popular testbed for multi-agent reinforcement learning research to date (Stone, 2016).']"
"The success of MARL has been limited, however, due to the extremely high dimensionality of the problem.",4.2. Multi-agent Imitation Learning for Soccer,[0],[0]
"In this experiment, we aim to learn multi-agent policies for team soccer defense, based on tracking data from real-life professional soccer (Bialkowski et al., 2014).
",4.2. Multi-agent Imitation Learning for Soccer,[1.000000044602842],"['In this experiment, we aim to learn multi-agent policies for team soccer defense, based on tracking data from real-life professional soccer (Bialkowski et al., 2014).']"
Data.,4.2. Multi-agent Imitation Learning for Soccer,[0],[0]
We use the tracking data from 45 games of real professional soccer from a recent European league.,4.2. Multi-agent Imitation Learning for Soccer,[0],[0]
The data was chunked into sequences with one team attacking and the other defending.,4.2. Multi-agent Imitation Learning for Soccer,[0],[0]
"Our goal is to learn up to 10 policies for team defense (11 players per team, minus the goal keeper).",4.2. Multi-agent Imitation Learning for Soccer,[0],[0]
"The training data consists of 7500 sets of trajectories A “ tA1, . . .",4.2. Multi-agent Imitation Learning for Soccer,[0],[0]
", A10u , where Ak “ tat,kuTt“1 is the sequence of positions of one defensive player, and C is the
context consisting of opponents and the ball.",4.2. Multi-agent Imitation Learning for Soccer,[0],[0]
"Overall, there are about 1.3 million frames at 10 frames per second.",4.2. Multi-agent Imitation Learning for Soccer,[0],[0]
"The average sequence length is 176 steps, and the maximum is 1480.
",4.2. Multi-agent Imitation Learning for Soccer,[0],[0]
Experiment Setup.,4.2. Multi-agent Imitation Learning for Soccer,[0],[0]
"Each policy is represented by a recurrent neural network structure (LSTM), with two hidden layers of 512 units each.",4.2. Multi-agent Imitation Learning for Soccer,[0],[0]
"As LSTMs generally require fixed-length input sequences, we further chunk each trajectory into sub-sequences of length 50, with overlapping window of 25 time steps.",4.2. Multi-agent Imitation Learning for Soccer,[1.0],"['As LSTMs generally require fixed-length input sequences, we further chunk each trajectory into sub-sequences of length 50, with overlapping window of 25 time steps.']"
The joint multi-agent imitation learning procedure follows Algorithm 2 closely.,4.2. Multi-agent Imitation Learning for Soccer,[0],[0]
"In this setup, without access to dynamic oracles for imitation learning in the style of SEARN (Daumé III et al., 2009) and DAgger (Ross et al., 2011), we gradually increase the horizon of the rolled-out trajectories from 1 to 10 steps lookahead.",4.2. Multi-agent Imitation Learning for Soccer,[0],[0]
"Empirically, this has the effect of stabilizing the policy networks early in training, and limits the cascading errors caused by rolling-out to longer horizons.
",4.2. Multi-agent Imitation Learning for Soccer,[0],[0]
"The structured model component is learned via stochastic variational inference on a continuous HMM, where the perstate emission distribution is a mixture of Gaussians.",4.2. Multi-agent Imitation Learning for Soccer,[1.0],"['The structured model component is learned via stochastic variational inference on a continuous HMM, where the perstate emission distribution is a mixture of Gaussians.']"
"Training and inference operate on the same mini-batches used for joint policy learning.
",4.2. Multi-agent Imitation Learning for Soccer,[0],[0]
We compare against two variations.,4.2. Multi-agent Imitation Learning for Soccer,[0],[0]
"The first employs centralized policy that aggregates the state vectors of all decentralized learner and produces the actions for all players, i.e., a multi-task policy.",4.2. Multi-agent Imitation Learning for Soccer,[0],[0]
"The centralized approach generally requires more model parameters, but is potentially much more accurate.",4.2. Multi-agent Imitation Learning for Soccer,[0],[0]
"The second variation is to not employ joint multi-agent training: we modify Algorithm 2 to not crossupdate states between agents, and each role is trained conditioned on the ground truth of the other agents.
Results.",4.2. Multi-agent Imitation Learning for Soccer,[0],[0]
Figure 5 shows the results.,4.2. Multi-agent Imitation Learning for Soccer,[0],[0]
Our coordinated learning approach substantially outperforms conventional imitation learning without structured coordination.,4.2. Multi-agent Imitation Learning for Soccer,[0],[0]
"The imitation loss measures average distance of roll-outs and ground truth in meters (note the typical size of soccer field
is 110 ˆ 70 meters).",4.2. Multi-agent Imitation Learning for Soccer,[0],[0]
"As expected, average loss increases with longer sequences, due to cascading errors.",4.2. Multi-agent Imitation Learning for Soccer,[0],[0]
"However, this error scales sub-linearly with the length of the horizon, even though the policies were trained on sequences of length 50.",4.2. Multi-agent Imitation Learning for Soccer,[0],[0]
"Note also that the performance difference between decentralized and centralized policies is insignificant compared to the gap between coordinated and unstructured policies, further highlighting the benefits of structured coordination in multi-agent settings.",4.2. Multi-agent Imitation Learning for Soccer,[0],[0]
"The loss of a single network, non-joint training scheme is very large and thus omitted from Figure 5 (see the appendix).
Visualizations.",4.2. Multi-agent Imitation Learning for Soccer,[0],[0]
"Imitation loss, of course, is not a full reflection of the quality of the learned policies.",4.2. Multi-agent Imitation Learning for Soccer,[0],[0]
"Unlike predator-prey, the long-term reward signal is not available, so we rely on visual inspection as part of evaluation.",4.2. Multi-agent Imitation Learning for Soccer,[0],[0]
Figure 6 overlays policy prediction on top of the actual game sequence from Figure 1.,4.2. Multi-agent Imitation Learning for Soccer,[0],[0]
Additional test examples are included in our supplemental video 5.,4.2. Multi-agent Imitation Learning for Soccer,[0],[0]
"We note that learned policies are qualitatively similar to the ground truth demonstrations, and can be useful for applications such as counterfactual replay analysis (Le et al., 2017).",4.2. Multi-agent Imitation Learning for Soccer,[0],[0]
Figure 7 displays the Gaussian components of the underlying HMM.,4.2. Multi-agent Imitation Learning for Soccer,[0],[0]
The components correspond to the dominant modes of the roles assigned.,4.2. Multi-agent Imitation Learning for Soccer,[0],[0]
"Unlike the predator-prey domain, roles can be switched during a sequence of play.",4.2. Multi-agent Imitation Learning for Soccer,[0],[0]
See the appendix for more details on role swap frequency.,4.2. Multi-agent Imitation Learning for Soccer,[0],[0]
"The problem of multi-agent imitation learning has not been widely considered, perhaps with the exception of (Chernova & Veloso, 2007) which focused on very different applications and technical challenges (i.e., learning a model of a joint task by collecting samples from direct interaction with teleoperating human teachers).",5. Other Related Work,[0],[0]
"The actual learning algorithm there requires the learner to collect enough data points from human teachers for confident classification of
5Watch video at http://hoangminhle.github.io
task.",5. Other Related Work,[0],[0]
"It is not clear how well the proposed method would translate to other domains.
",5. Other Related Work,[0],[0]
Index-free policy learning is generally difficult for blackbox machine learning techniques.,5. Other Related Work,[0],[0]
"Some recent work has called attention to the importance of order to learning when input or output are sets (Vinyals et al., 2015), motivated by classic algorithmic and geometric problems such as learning to sort a set of numbers, or finding convex hull for a set of points, where no clear indexing mechanism exists.",5. Other Related Work,[0],[0]
"Other permutation invariant approaches include those for standard classification (Shivaswamy & Jebara, 2006).",5. Other Related Work,[0],[0]
"In principle, the training and inference of the latent structure model can accommodate different types of graphical models.",6. Limitations and Future Work,[0],[0]
"However, the exact procedure varies depending on the graph structure.",6. Limitations and Future Work,[0],[0]
It would be interesting to find domains that can benefit from more general graphical models.,6. Limitations and Future Work,[0],[0]
"Another possible direction is to develop fully endto-end differentiable training methods that can accommodate our index-free policy learning formulation, especially deep learning-based method that could provide computational speed-up compared to traditional graphical model inference.",6. Limitations and Future Work,[0],[0]
"One potential issue with the end-to-end approach is the need to depart from a learning-reductions style approach.
",6. Limitations and Future Work,[0],[0]
"Although we addressed learning from demonstrations in this paper, the proposed framework can also be employed for generative modeling, or more efficient structured exploration for reinforcement learning.",6. Limitations and Future Work,[0],[0]
"Along that line, our proposed method could serve as a useful component of general reinforcement learning, especially in multi-agent settings where traditional exploration-based approaches such as Qlearning prove computationally intractable.
",6. Limitations and Future Work,[0],[0]
Acknowledgement.,6. Limitations and Future Work,[0],[0]
"This work was funded in part by NSF Awards #1564330 & #1637598, JPL PDF IAMS100224, a Bloomberg Data Science Research Grant, and a gift from Northrop Grumman.",6. Limitations and Future Work,[0],[0]
We study the problem of imitation learning from demonstrations of multiple coordinating agents.,abstractText,[0],[0]
"One key challenge in this setting is that learning a good model of coordination can be difficult, since coordination is often implicit in the demonstrations and must be inferred as a latent variable.",abstractText,[0],[0]
We propose a joint approach that simultaneously learns a latent coordination model along with the individual policies.,abstractText,[0],[0]
"In particular, our method integrates unsupervised structure learning with conventional imitation learning.",abstractText,[0],[0]
"We illustrate the power of our approach on a difficult problem of learning multiple policies for finegrained behavior modeling in team sports, where different players occupy different roles in the coordinated team strategy.",abstractText,[0],[0]
We show that having a coordination model to infer the roles of players yields substantially improved imitation loss compared to conventional baselines.,abstractText,[0],[0]
Coordinated Multi-Agent Imitation Learning,title,[0],[0]
